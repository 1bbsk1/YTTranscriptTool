{
  "video_id": "6l64n8t8Ivs",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Так ну я смотрю не все знают что такое exactly Once вот я могу как бы коротко ответить это некоторая мифическая птица в русских сказках которую все пытаются достать вот ну не у всех это получается и по своему опыту личному и по конференциям я вижу что многие крупные компании мучатся с этим вот Ну действительно многих бросают это и доклад посвящен гарантиям доставки где я расскажу Вообще Какие они бывают будет некоторый такой обучающий доклад и планомерно там дойдём до конца как это можно всё реализовать немного обо мне Я работаю в самом ядре разработки idb в Яндексе Вот и мы там делаем там очень сложные штуки Вот это оди из типичных пример примеров сложных вещей начнём с проблем какие у нас есть проблемы вчера уже неоднократно про это говорили сети не надж то есть какого бы у вас не было резервирования сетей то есть там пять например линий проложены к дата центру обязательно найдётся экскаватор который найдёт тот колодец где эти пять линий сходятся вместе и именно этот колодец он там раскопа ет А бывают интересные примеры что акула кусает кабели коровы копают там тоже кусают кабели хакеры как-то взаимодействуют Ну можно сойтись на том что не бывает надёжной сети и потеря сообщений - это нормальная штатная вещь с которой просто нужно уметь работать соответственно Кто знает может быть книжку с кабанчиком вот там её автор приводит классификацию сетей бывает сети надёжные когда сообщение совершенно точно будет доставлено и бывают сети ненадёжные с обычными потерями То есть когда сообщение Может быть потеряно продублированы и так далее И на самом деле от сетей ненадежных к сетям наджм Можно перейти с помою простых двух процедур есть можно делать повторы и можно делать де дупликации то есть из Плохой сети мы можем сделать хорошую сеть Что такое повторы давайте рассмотрим типичный интернет-магазин вот допустим пользователь совершил заказ он его оплатил и мы должны в какой-то микросервис доставить сообщение что А теперь передавай его в доставку и соответственно будет очень неприятная ситуация если это сообщение будет потеряно пользователь будет очень недоволен и мы каким-то образом это сообщение должны повторять должны его трать А теперь давайте обратной ситуации мы это сообщение передать товар доставку начинаем трать начинаем повторять и может получиться такая ситуация что будет дубль мы несколько раз доставим этот товар пользователю пользователь будет очень рад но как вы понимаете магазин не будет рад магазину нужно как-то с этим бороться бороться с дублями и дальше мы расскажем как это можно делать дальше я перейду к базовым гарантиям доставки которая базируется на этих примитивов повтора и дедупликация самая первая самая простая гарантия она называется at Most on я придумал своё собственное название которое мне понравилось его нигде нету это расслабленная доставка Почему расслабленная отправитель послал сообщение и о нём забыл он игнорирует любые ошибки и получатель может быть его лут может быть его обработает вот все расслабленные но тем не менее такая стратегия работать Тоже имеет место быть например мы отправляем координаты автомобиля в движение Вот если сейчас эта координата не дошла то через пару секунд будет новая попытка отправки это абсолютно нормально то есть вполне вполне этим можно пользоваться почему бы нет плю это то есть Можем не изобретать никаких лишних механизмов надёжной доставки кому-то это годится есть чуть-чуть усиленный вариант этой гарантии доставки когда смотрите получатель уже отправляет подтверждение у нас появилась новая стрелочка но он отправляет подтверждение до обработки То есть это тоже слабая гарантия Потому что если в обработке произойдёт какой-то сбой а отправите об этом не узнает Вот И поэтому это тоже забыл сказать доста в которые сообщение доставится ноль либо один раз следующая гарантия доставки более сильная где мы гарантируем уже доставку один либо более раз то есть мы точно Гарантируем доставку посмотрите что у нас со стрелочками подтверждение отправляется уже строго после обработки отправитель теперь уже ждт этого подтверждения есть ижт его в если та истк он будет делать повторы Вот и соответственно он будет повторять сообщени до тех пор пока не получит подтверждение Таким образом мы реализуем гарантию доставки один либо более раз и есть как раз та Жар птица которой все стремятся которые хотят получить это очень сильная гарантия доставки Посмотрите в ЧМ отличие пов с дум сладом щем много попыток доставки и соответственно могут быть дубли с дублями надо Бороться и на стороне получателя появляется новый блок борьба с дублями и таким образом мы гарантируем exance при котором доставляется строго одно сообщение которое было доставлено одно и ровно одно Давайте посмотрим как можно бороться с дублями два две классических стратегии Либо мы работаем с помощью и потент операций Либо мы эти дубли удаляем Что такое Идо патентная операция Ну в математике это операция которая при применении к одному и тому же объекту даёт один и тот же результат например умножение на единицу сложение с нулём нахождение максимума минимума либо из информатики классические примеры до патентной операции - это операция АСР либо слепая запись То есть когда мы делаем АСР слепую запись и у нас не было записей в таблице а ключ будет добавлен если этот ключ уже был в таблице ключ будет перезаписанный множество асетов результат будет один и тот же и второй способ борьбы с дублями - это их удаление соответственно первый способ как можно удалять мы вводим ключи идемпотентность по ключам идемпотентность заводим какую-то там большую коллекцию известных ключей и мы их удаляем и как вариант это стратегия то есть в виде такой большой коллекции может выступать СУБД в которой есть уникальный ключ первичный ключ тоже является уникальным соответственно если такой ключ есть то будет ошибка при вставке дубля Ну и итоговая Сводная таблица которая демонстрирует разли различия между этими гарантиями то есть доставим 0 раза доставим больше ли равно одного раза в первом случае возможно пропуски во втором случае воз дубли третий случай идеальный к которому все стремятся дальше я хочу перейти к паттернам микросервисной архитектуры и на их примере продемонстрировать Как можно реализовывать те или иные гарантии в частности пытаться реализовать exance а имеющимися средствами Поднимите руки Кто знает что такой кбо ровно половина аудитории замечательно вы молодцы а Молодцы по разным причинам Вот молодцы Что знаете Те кто не знает я Обязательно расскажу это очень интересный паттерн сильно рекомендую его использовать но он чуть-чуть Возможно сложновато попытаюсь его просто объяснить смотрите есть микросервис который генерирует некоторые события например создание заказа Вот и мы должны это событие положить в свою локальную базу сохранить это наша локальная база вот внизу видите Main Database tables и также это событие должно быть отправлено в другой микросервис например отправка эсэмэски отправка в доставку и так далее и важное свойство что это надо сделать атомарность это событие должно атомарность и в локальную базу и в какую-то удалённый микросервис который работает через асинхронный брокер сообщений микросервисы любят асинхронные связи и я могу тут минут 10 15 перечислять различные граничные случаи Корнер кейсы Что может пойти не так если мы пытаемся Амар сохранить локально и послать удалённо то есть то ли брокер сообщения рестарт то ли локальная база там зависнет на некоторое время то ли мы сами зависни миллион вариантов Вот и сразу Хочу перейти как люди предлагают делать правильно Мы в своей же локальной базе заводим специальную табличку outbox Table который переведём на русский язык исходящая почта просто будет журнал сообщений которые у нас появились создали заказ создали заказ зарегистрировался пользователь эти сообщения появляются в этом журнале и важные свойство что они появляются в рамках локальной транзакции с основной базой с основной таблицей то есть мы туда атомарном в восходящую табличку и заводится какой-то процесс который назовём по-русски почтальон который разгребает эту табличку и отправляет в брокер сообщений и когда брокер сообщений подтвердил что сообщение принято мы поча сообщение как отправленное то есть это действительно хороший надёжный способ гарантированно и EX Реван отправит сообщение из локального сервиса в какой-то удалённый красивый паттерн вот те кто не использует сильно рекомендую аналогичный паттен transaction inbox работает уже на стороне получателя То есть когда мы учитываем сообщения из брокера из брокера у нас заводится похожая табличка входящая почта мы регистрируем все входящие сообщения первичным ключом у нас является некоторый ключ до патентно и мы туда добавляем и когда мы обработали Входящее сообщение мы помечает мы тоже можем красиво элегантно сделать надёжную доставку в обычных микросервисах Какие тут есть я бы назвал это не то чтобы недостатки а я бы назвал это нюансы во-первых Помните я говорил про локальную транзакцию то есть чтобы реализовать або нам нужна транзакционная база данных Вот то есть какой-нибудь дис или кандр нам не подойдёт при большой нагрузке подчеркиваю при большой нагрузке то есть миллион ПС Вот но эта таблица может действительно как бы повлиять на вашу латентность тоже об этом стоит помнить Вот то есть обязательно нужно потестить важный момент нужно контролировать число запи в этой исходящей табличке при большой нагрузке Она резко может распухнуть вот и это будет явно там для вас проблемой Ну и я лично выделяю Последний пункт для меня тоже важный то есть должна быть некоторая квалификация программиста которая эту всю обвязку напишет И на самом деле Люди уже об этом задумывались и есть другой красивый подход как гарантированно доставлять сообщения из одной базы в другую это cdc change Data capt то есть когда мы захватываем изменения в какой-то базе данных формируется поток изменение передаётся в в некоторую очередь и эта очередь перекладывает это в базу данных назначения типичный пример где это красиво реализовано например тот же самый постгрес в постгрес наверняка все знаете что есть журнал транзакции бинарный вот он всегда ведётся и мы из этого журнала транзакции можем очень дёшево эффективно считывать события которые произошли мы их считали мы их можем переложить в какой-то брокер сообщений и этот брокер сообщений передаст наружу Как вы понимаете накладных расходов при этой схеме Ну действительно минимум Вот и красиво элегантные схемы и самое важное что уже есть фреймворки например самые известные это дем которые всё это поддержали которые на входе понимает большое количество баз данных на выходе тоже Вот видите большой перечень баз данных можно на текстовый поиск отправить и в кэши и в реляционную базу данных и в колоночные рекомендую использовать дальше у нас доклад там чуть-чуть про топики вот я хочу перейти к кафке как основному представителю потоковых брокеров сообщений в кафке что у нас выделяется есть топики топик - это некоторая семантическая сущность для связи двух получателей и отправителей топики в целях масштабирования делятся на партиции то есть мы можем топик поделить на 1 10.000 партиции каждой партиции - это упорядоченно распределённой Лог сообщений в рамках которого сообщение нумеруется каким-то смещением и я дальше Хочу перейти как раз к реализации различных гарантий доставки как это можно делать в кавка в Кака при запи сечас я говор про запись есть подтверждений кото мы жм от брокера если мы выставляем этот флажок равным Ну то мы отправили сообщение и ничего не ждём вспоминаем что это я это назвал расслабленная доставка более науч это то есть мы доставим сообщение ноль или один раз самая простая самая дешёвая гарантия Вот её тоже можно и то есть отправитель ждт строго одного подтверждения от брокера в данном случае он ждт его от лидера это у нас получается Ну я опять вот нафантазировал придумал свой термин с лидером потому что мы ждём подтверждения только от одного лидера и наверняка многие из вас замечают из пото выйдет из строя то последние сообщения будут в неопределённом состоянии то ли они были доставлены по репликации в другие брокеры то ли нет как с этим бороться самый простой способ мы включаем А равно All то есть мы ждём подтверждения от всех брокеров которые у нас есть обычно в этом случае включают синхрон ную репликацию А это самый надёжный способ максимальная гарантия отсутствия потерь Вот но Вы наверняка понимаете что тут есть существенный недостаток это чрезвычайно низкие гарантии доступности доступности на запись если любой из брокеров абсолютно любой выйдет из строя либо он временно будет недоступен то вся запись останавливается потому что мы ждём три подтверждения на запись а их нету я этот режим опять нази применять Не рекомендую на самом деле рекомендуемый способ - это кворум То есть когда мы ждм подтверждения не от всех брокеров А например от N - 1 либо есть другие формулы вычисления N П 1 делить на 2 и так далее То есть когда мы ждём подтверждения от некоторого кворума и это у нас баланс между гарантиями доступности и гарантиями надежности так рассказал про три гарантии дальше перехожу к кафке как они декларируют что реализует exance чтобы включить exec Lance там есть флажок а у отправителя ence True и в протоколе у нас появляется два поля producer ID - это номер отправителя уникальный и sequence Number - это порядковый номер Порядковый счётчик и и брокер проверяет простой вариант что sequence Number должен монотонно увеличиваться в рамках пары продюсер запятая партия я тут хочу заметить важная вещь что этот sequence Number спрятан внутри СДК и пользователь то есть не пользователь а отправитель который пишет не имеет к нему доступа он не имеет никакого влияния SE Number спрятан внутри СДК и посмотрите какая появляется неприятная вещь в документации вот есть propal ка это дизайн документ ка в м есть замечательны ф кото там в середине документа вставлено и не все его замечают что если А эта сессия писателя по каким-то причинам рестарт то мы счётчик просто сбрасываем в ноль то есть перезапустил отправитель перезапустил брокер поменялся Лидер что в принципе штатная ситуация произошёл Rolling Restart то есть обновление версии Кафки и у нас этот счётчик контроль к которому мы не имеем доступа он сбрасывается в ноль и таким образом никакого EX в данном случае Нет То есть он гарантируется только в рамках действующей сессии а любые Корнер кейсы они не покрываются мы в Яндексе как бы некоторое время назад Работали поверх Кафки и там выделили основные паттерны что в этом случае нам с этим делать первый паттерн вполне нормальный на стороне записи ничего не делать абсолютно нормально Вчера коллеги из большой организации ровно так делают бом СБ получателя вполне нормальная стратегия то есть стоит там какая-нибудь реляционная база данных и мы удаляем дубли по первичному ключу вторая стратегия если мы хотим это делать именно на строне записи мы можем сделать так Посмотрите записали сообщение в топик а произошёл перезапуск отправителя и мы можем обратиться в топик попытаться посмотреть последнее сообщение проверить по известному нам ключу и до патентно есть оно уже в топике или нет но тут есть очень большой недостаток а потоковые брокеры сообщения они сильно оптимизированы на быструю запись гигантского потока сообщений и они делают жутко эффективно кавка Молодцы то есть они очень быстро пишут последовательно но если Мы попытаемся почитать и отмотать чуть-чуть назад даже там на секунду на 5 секунд это жутко медленная операция и на практике То есть под нагрузкой Ну у нас может это занять например минуту вот или там 5 минут вот вполне реально и поэтому не очень хороший способ и есть некоторый промежуточный вариант как это побороть вот мы можем завести не только топик для данных а топик для смещений мы будем атомарная кавка писать данные в основной топик и смещение писать в топик для смещения топик для смещения средствами то есть компактный топик он будет хранить только последние ключи он будет сильно меньше по объёму и в случае перезапуска мы именно к нему обратимся чтобы понять есть Нужное смещение или нет и это действительно сильно дешевле и такой способ позволит нам быстрее перезапустить вот ну его нужно программировать и от ка я перей Я являюсь Кто не знает что такое idb Topic если очень просто это большая производительная очередь шина данных на которой работает весь Яндекс любопытно но до тринадцатого года Мы работали поверх кавка то есть наша шина данных работала поверх кавка Потом мы стали чувствовать ограничение кавка нас очень много чего не устраивало и были вынуждены через 4 года перейти на платформу wdb А вот этот QR код ровно пол назад на полгода назад на лот я рассказывал про то почему мы это сделали Во что мы упирались и как мы пытались с этим бороться То есть я подробно пытался описать процесс переезда А кому интересно посмотреть вот но я пойду дальше что такое платформа wdb wdb Topic - это часть платформы wdb wdb - это распределённая отказ устойчивая distributed сико база данных которая сочетает в себе как свойство но SQL решения так такие как высокая доступность и масштабируемость так и свойства классических SQL решений такие как согласованность данных и транзакции несколько слов чтобы вы понимали с чем нам приходится бороться в части гарантии данных то есть поток через нашу шину данных проходит 200 Гб в секунду 80 на запись 120 на чтение в событиях в секунду это до 20 млн событий в секунду и хочу обратить внимание Вот на Нижний квадратик 9 млрд источников в моменте в полёте Почему я на это обращаю внимание потому что для этого количество мы вынуждены гарантировать exactly мы вынуждены делать дупликации EX у нас включена по умолчанию У нас есть два режима записи то есть ослабленный без дупликации которые Ну практически никто в Яндексе не включает Вот и по умолчанию у всех как внутри Яндекса так и в ОРС мы доступ Open Source включен exance который на 9 млр источников производит дедупликация на литу и при этом замедление обработки оно минимальное потому что ну по сути дела Это дедупликация у нас сводится к поиску ш таблиц что сильно дёшево для нас дальше я объясню почему давайте я перейду как у реализована запись подход очень про сообщения идентифика отправителя и Number но существенно Отличие в том что Number доступен снаружи отправителю и более того отправитель обязан его указать то есть по сути дела Мы ввели аналог ключа до патентно который нужно указать и таким образом если сессия по каким-то причинам стартует вот отправите знает свой последний Number и он просто его подставит можете спросить например вопрос каверны А что если отправитель сам стартовал и свой sequence Number не знает А в этом случае брокер Может ему подсказать в брокере хранятся для всех известных ему отправителей последние секн набора то есть брокер разделён на партиции в партиции в среднем хранится 10.000 отправителей и для 10.000 отправителей конкретная партиции конкретная таблетка знает последние секн number и она в случае рестарта она может сказать отправителю что вот у тебя SE Number был такой-то вот продолжай с него очень просто помните вот эту картинку вот то что мы пытались делать поверх Кафки вводили второй сжатый топик и так далее То есть по сути дела Мы вот эту сложную схему а спрятали от пользователя внутрь внутр нашего брокера внутри нашего СДК и пользователь абсолютно не заботится об этом он всегда ме г о Останови более того у нас ещ внутри есть Замечательная вещь каждая партиции для каждого отправителя помнит привязку и таким образом если отправитель по какой-то причине перезапустил то он будет подключен Ровно к той же партиции к чему я веду что после перезапуска мы попадём в туже самую партию а партия - это упорядочен сообщени после рестарта У нас упорядоченность тоже сохранится и получается Замечательная вещь то есть мы гарантировали на записи внутри каждой партиции сообщения упорядоченные и попробуем перейти к чтению То есть к читателям если есть гарантии порядка и если есть на записи exance то мы можем при чтении хранить также ограниченное количество последних известных смещений и такая же аналогичная ш табличка прочтения и делать дедупликация дёшево эффективно А если например обратиться к тому же самому ткш и боксу по сути дела Мы пытаемся сделать кш inb то там есть большой недостаток в классическом кш аут боксе мы должны в худшем случае иметь размер таблицы равному нашему ретеншн А ретеншн может изменяться в часах либо днях тут такого нет то есть хранится только 10.000 последних смещений Итого мы пережили большое количество проблем которые мы имели поверх Кафки и вот эти все сложные решения мы засунули внутрь брокера и внутрь нашего СДК и таким образом шаблоны проектирование вроде transaction outbox Trans inbox они встроены внутрь а exact включен по умолчанию и таким образом довольно-таки дёшево эффективно мы это делаем на большом количестве источников и ещё есть пара возможностей которые недавно появились в idb Topic которые также касается гарантии до доставки Помните я говорил что а не нужно изобретать велосипеды а стоит пользоваться готовыми решениями вроде cdc и cdc тоже встроен в платформы А если мы пишем например в какую-то реляционную таблицу в рамках wdb то она автоматически передаст записи в топики а топики наруже передадут сообщение по протоколу cdc в систему назначения если это чуть-чуть увеличить вот у нас есть строчная таблица которая в целях масштабирования разбита на множество партиции каждая партиции - Это примерно 1 ГБ данных и у нас есть атомарный захват изменений в рамках данной партиции с помою некоторого коллектора который перет изменения по хэш от первичного ключа в партиции уже топиков в этой схеме у нас порядок гарантирован атомарность гарантирована Потому что у нас это работает внутри наших таблеток у нас это всё надёжно и таким образом получился cdc внутри платформы какие есть замечательные особенности EX включен по умолчанию можно реализовать вть большой из вместимость с дебе зумом и самая интересная и Спорная вещь для меня мы понимаем и ценим что многие привыкли к кавка действительно от стандарт дефакто и С недавнего времени мы реализовали кавка а поверх нашей платформы idb чувствуйте Иронию То есть некоторое время назад уехали с кавка А сейчас вот включили кавка потому что Клиенты приходят действительно некоторым сложно на нас переключиться и включение позволяет существенно упростить миграцию новых клиентов и интересная особенность что это кавка доступна в том числе в Облаке и доступна в том числе и в Севе L вот уникальная комбинация Севе кавка вот что действительно очень интересно можно получить маленький очень топик из одной партиции который при необходимости можно увеличить в большой топик и это было протестировано то есть работает количеством известных клиентов flit и все родные клиенты каки Итого Я попытался показать сложные ситуации в сетях связи несмотря на это современные брокеры сообщения могут дать сильные гарантии если их уметь правильно настраивать и в idb Topic мы попытались учесть весь опыт эксплуатации кавка и спрятать внутрь все сложные инструменты и включить exance по умолчанию Спасибо за внимание Саша спасибо за доклад Я думаю вопросов будет много полный зал голосуем за Александра Вот здесь по QR коду Также можно вопрос задавать в чатике зала и лично тоже за лучший вопрос дарим супрематический начнём вот оттуда А привет Спасибо за поближе микрофон Вот спасибо за обширный доклад такой вопрос в кафке есть Single mess transform Есть ли что-то подобное в idb есть есть решение вроде кавка Stream кака Connect вот мы на них пока не заходим потому что это некоторые настройки над кавка мы сейчас реализовали штатные кавка При желании можете попробовать встроить это в эти решения обще из одного формата в другой то есть в моменте у нас такого решения Нет ответ такой в моменте такого решения по автоматической перекладки из одного топика в другой нет Александр Спасибо большое за доклад на самом деле два вопроса значит Вопрос номер один вот мы в сбертехе тоже занимаемся реплика данных к нам регулярно приходят Коллеги и говорят Мы хотим вот cdc как интеграцию между системами Вот и вот лично я их от этого отговаривают ну какое-то а какое-то соглашение и есть там какие-то правила по поддержке совместимости Вот Но когда мы делаем cdc то передаётся кусок нашей таблицы вот а таблица Ну как бы внутренняя структура данных приложени она не является примером договоренности и как бы неизбежно случится ситуация когда придёт потребителю какой-то Вектор который он не знает как обрабатывать вот как вы с этим боретесь у вас замечательная организация могу чуть рассказать архитектурные требования для взаимодействия двух систем то есть рекомендуемое это через а менее рекомендуемое это асинхронно через какой-то топик то что вы говорите cdc это третий способ интеграции Когда уже доуп какие-то чужие таблицы а cdc больше касается асинхронной репликации например между разными дата-центра Когда нужно перейти там с одной базы на другую в качестве взаимодействия двух микросервисов я бы cdc не рассматривал как решение номер один это нештатный не рекомендуемый способ действительно в том числе потому что схема данных она может поменяться и это неправильно значит здесь мы согласны И второй вопрос Вы сказали что вы переложили на клиента генерацию ключа идемпотентность Но ведь тоже нет никакой гарантии что клиент не отправит то же самое сообщение с новым ключом если клиент отправит то же самое сообщение с новым ключом то мы этот ключ отбросим потому что это ключ до патентно это нормальная ситуация Ну ключи-то разные То есть как вы определяете что сообщение тоже самое это новое сообщение получается Если кли тем же сам люм наоборот Наоборот снот Наоборот второй раз отправит сообщение но там клиент упал он почему-то не понял что он это сообщение уже отправил отправит его ещё раз а Ключ уже новый нет Если у нас этого ключа нету то мы его положим А если у нас ключ нам этот известен то мы его отбросим это просто новое сообщение и всё тут как бы всё Давайте в центр зала спа вот нет дальше молодой человек первый держал очень долго вот да ему спасибо спасибо за доклад было интересно у меня на самом деле такой вопрос Ты рассказывал про SE ID которое вы указываете Извне в отличие от Кафки То есть вы отличаетесь тем самым и пытаетесь её улучшить А как вы в таком случае Работаете С так называемыми Зомби продюсерами То есть когда У вас есть ситуация когда продюсер завис по каком-то по какой-то причине А вы начали перезапускать наверное другой Ну поднимать ему на смену и тот друг оживает получается новый который был поднят он запросит у брокера свой sequence ID и получит А оживший с тем же sequence ID продолжит слать данные Вот надеюсь мой вопрос был понятен Ну во-первых УК есть так называемая там ТТ сессия вот в течение которого после которого там сессия будет закрыта Если в рамках этого таймаута писатель оживёт то соответственно мы с ним продолжим работу это нормальная ситуация с ней как бы про неё нужно знать Вот и если они в это течение этого два в течение этого таймаута поднимутся два продюсера и во второго продюсера будет новый но да будут дубли но я не могу представить такую ситуацию когда продюсер клонирует Спасибо с этой стороны Бут вопрос а то что-то Вот давайте вот в конец туда а сейчас вот молодой человек я же показал вот в центре ты нет Да так сзади есть микрофон дадада Здравствуйте Большое спасибо за доклад немножко не поня в случае реализации CK API вы говорили что sequence ID спрятан внутри СДК и соответственно там никакого EX Нет при перезагрузке этой всей истории клиента как собственно решается EX с помощью kfi и стандартных SD можно сразу вручить приз за лучший вопрос подожди может ени сно это действительно лучший вопрос потому что когда мы работаем через мы не можем сотворить волшебство и эта проблема с она будет потому что мы ничего не сможем сделать это недостаток протокола кавка хотите честный Работайте по родному протоколу вот хотите какой-то совместимости промежуточной попробовать ну попробуйте кавка Спасибо отличный вопрос замечательно так вот Давайте всё-таки поему даб доклад я смотрю всем понравился SE ID не все ещ разобрались И у меня тоже вопрос по SE ID Ну самый частый кейс хотим быстрее отправлять чуем сообщения не ждём если часть сообщений успешно доставила а часть нет Как разрешать SE ID при повторном запуске у на в сво эффективно назначать уникальный sequence Number СДК с бачу брокер тоже умеет внутри себя бачева поэтому тут проблемы не будет в плане производительности и прошлый доклад вот я QR код как раз показывал мы сильно тестировали производительность родной Кафки и wdb topix вот у нас чева очень эффективно и работаем даже быстрее спасибо рядом молодому человеку отдай прям сразу вот да так Спасибо за доклад такой вопрос Вот опять же кавка API интересует Как всё-таки реализовать полную совместимость например с той же кака Connect насколько я знаю она используется для того чтобы обеспечить гарантия exance как раз вот транзакции как Вы правильно заметили То есть это всё-таки реально реализовать на ydb Topic просто в самом wdb всё-таки есть транзакции например Ух Можно два приза за лучше начинается Да у нас пока один только Объясню почему в кафке в родной кафке транзакции они очень там ограничены там всего там есть два режима два режима то есть чтение грязных данных и пое что-то такое Вот никаких зумо сни там в принципе нету у нас как раз мы уже декларированный настоящие честны транзакции появлятся в топиках тоже это сечас в режиме и у на это будет сть с транзакциями каки мы пока не планируем делать потому что они там ну сильно более ограниченны по сравнению с нашими у нас самая настоящая распределённая транзакция которая работает на десятка тысячах на десятки тысяч узлах под большой нагрузкой вот у нас это работает Спасибо Давайте вот вперёд опять передаём Так до первого ряда дойдём Здравствуйте спасибо большое за доклад у меня очередной вопрос про Number вот допустим есть ненадёжный клиент и Давайте представим два случая случая номер раз он сам знает там он может падать но он запоминает свой SE ID и допустим у нас там не знаю машинка выключилось там он записал SE ID 4 а на диске оказалось только три он просыпается думает что SE ID и как бы сейчас нарот Допустим мы пользуемся мы запрашиваем брокера нам отда последни и клиент пересыла старое сообщение с новым ключом инно и получается что у нас в брокере могут оказа одинаковых сообщения ди вот как пост давайте я попробую прояснить частично это связано с предыдущим вопросом который я сразу не догадался Как правильно ответить sequence ID нельзя назначать просто так из из головы АК То есть по-хорошему у Вас например есть на стране отправителя реляционная табличка поэтому секн на ID нужно брать счётчик там из первичного ключа этой таблицы Либо вы отправляете данные из какого-то файлика Вы можете брать номер строки в этом файлики то есть нельзя sequence ID або какой выбирать и это вам сильно упростит тах вот ситуаций уже не будет Давайте вот на первый ряд Дмитрию и потом вот сюда вот сюда я показываю Спасибо са большое тебе спасибо за доклад поднятые проблемы актуальны не только для этого доклада для всей конференции Мне кажется вот и вопрос ты заявляв для означает ли это что это только если мы используем базу данных или ЕС я рассказал про эти шаблоны которые реализованы в в СДК и в брокере соответственно Если вы из поса пишете к нам Вы можете пользоваться этими шаблонами замечательно Вот здесь молодой человек просил наверное последний будет Вопрос Добрый день спасибо за доклад вы уже прозвучало что не полностью поддерживаете с точки зрения транзакций там есть фича позволяющая реализовывать паттерн consum Trans prod Event loop когда у тебя в рамках транзакции на продюсере можно в рамках той же транзакции сдвинуть офсет на коню группе кон сюнга собственно если Ну это не поддерживается за счёт того что транзакции не поддерживаются но ели аналогичные фича udb которые вот можно таким же образом использовать То есть это даёт фичу Ну вот именно что ты конюш из топика и просишь по результату обработки толь тогда когда Ну компле полностью отправку смешается на консумировать Ладно ещё один вопрос кто хочет Давайте вот сзади вот молодой человек вот вот вот вот прямо прямо ты ты подскажите вот у вас есть такое Готовое решение уже коробочное на замену спарка по сути и других инструментов для обработки больших данных Вот хотелось бы спросить есть ли уже внедрен ли в это короч коробочное решение и замеряли ли производительность стриминга против вот плю приводи просто просто мы сейчас активно переходим на ваше решение и хотелось бы знать получится ли Вот не только перейти но ещё получить хороший прирост по per так попытаюсь разложить по полочкам Это замечательно большой в рамках Яндекса половина Яндекса работает на wdb половина на это системы абсолютно разных классов я их Давайте разделю вот мы тут в данном случае отношения чучуть не имеем вот в плане спарка и так далее в рамках платформы idb есть такая особенность как распределённые запросы Вы можете делать один СКР Запрос к к различным сразу база данных к топика к таблицам к колоночные То есть у нас есть так называемая федеративные запросы примерно то же самое что и в спарке Вот чуть-чуть мы сейчас говорили про Разные классы решений Спасибо нет Всё Давайте теперь са выберем лучши вопрос смотри у нас на самом деле мы можем поделить приз у нас матрёшка и книжка Давай поделим ты хотел два Вроде бы да да я хотел два давай кому книжку кому матрёшку однозначно за кавка вот там товарищ там товарищ в конце Да по Маши что ему а на его выбор Он первый что хочет да Вот давайте что ты выбираешь матрёшку туда матрёшку а здесь книжечку кому Вот по-моему по-моему ты да Всё спасибо тебе большое спасибо если вос Я с удовольствием пообщаюсь Да в курах пожалуйста ловите отличный доклад и тебе призы от онтика от организаторов Приходите к нам ещё"
}