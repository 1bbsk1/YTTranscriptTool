{
  "video_id": "iY7kgGADSks",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Да как меня представили Меня зовут Ильяс Мы с моей командой делаем меж сервисное взаимодействие в Озоне Вот и соответственно в том числе мы делаем алгоритмы балансировки улучшаем и ищем тот самый наш идеальный балансировщик нагрузки вот ну Давайте обо всём по порядку уже приступим к нашему плану вот чтобы вы понимали контекст в Озоне крутится бо 7 подов Вот и каждый из них как-то создат нагрузку либо принимает либо е что-то с ней делает вот ну и Да собственно состоим Мы из порядка 10я сервисов и реже и РН Да - это тот проект который я собственно делаю вот у нас наша сегодняшняя основная цель будет рассмотреть проблемы балансировки в больших инсталляция Клин backend когда уче ного копий клиентов иче много кодов цели сегодняшние мы изначально в целом поговорим зачем нам это нужно обсудим популярные алгоритмы балансировки которые в общем-то используется повсеместно коммьюнити обсудим проблемы которые возникали Когда у нас возрастала нагрузка в компании Ну и также поговорим о решениях которые мы в итоге применили вот ну и чтобы подогреть немножко интерес начнём мы с вами с Вот таких квантилей и закончим вот такие практически ничего не поменяв ни в сервисах ни в балансировке вот вот Погнали в общем-то обо всём по порядку начнём проблема балансировки вот Ну на самом деле тут в целом всё достаточно Просто когда у вас есть ваш клиент и есть сколько-то копий бэнда равнозначных между собой вам чтобы отправить запрос нужно решить А в какой конкретно и в какой момент времени и так далее и тому подобное вот Собственно как раз таки балансировки решают эту проблему Ну и самый наверно примитивный базовый который учат все университете в школе и наверно Даже скоро в дет садике это Робин задача Робина просто слать все запросы по кругу в общем-то так первый второй третий потом опять первый ну в общем-то Я думаю вы поняли Вот и Итого мы ожидаем что нагрузка которая придёт в каждую из копие наших нашего энда она будет одинаковой Всё просто по рудали нагрузку ВТО то чтобы прямо используется но он лежит в основе многих балансировщика это Рандом собственно делаем просто выбор на угад подбросили монетку сделали запрос сначала вот сюда потом сюда Ну потом например обратно и ещё сюда Ну в общем я думаю тут в целом понятно что происходит и поскольку все наши копии равнозначны и равновероятно сны да то на каком-то большом количестве запросов мы ожидаем собственно ту же картину что мы нашу нагрузку каким-то образом между ними Лим и распределим её более-менее равномерно вот с алгоритмически как я их называю их закончили всё остальное То что я здесь не упомянул это либо частные случаи балансировщика да либо их комбинации вот идём дальше в что-то поинтереснее а именно в балансировщик который использует какую-то накопленную статистику чтобы делать следующий выбор и самый из них такой каноничный Наверно это суть балансировка в том что вы на вашем клиенте делаете счётчики запросов которые осуществляются копиям кэндо Вот соответственно мы сейчас делаем запрос первую копию написали единичку потом мы там сделаем Запрос к следующему тоже запишем ему единичку эти запросы могут совершаться параллельно и соответственно у вас будут там две единички может совершаться сразу во все копии и собственно мы ожидаем как правило то что когда у нас будут накапливаться вот эти вот inflight так называемые запросы мы будем смотреть на те копии на которых этих запросов сейчас поменьше и делать запрос в них вот ну собственно тут вот следующий например на этом слайде будет тот вот та Нижняя копия для следующего запроса это такая база канон что вот принято и используется дальше немножко поинтересней поскольку статистика - это может быть не только ваши inflight запросы а в целом на самом деле что угодно из такого и интересного что лично есть на просторах интернета и что используется большими компаниями это балансировщик пик вма у него есть точно так же ячейки для статистики Да вот Но делает он немножко более хитрую вещь он совершает запрос в какую-то копию получает от неё ответ и записывает время от начала до конца и фиксирует его записывает вместо там тех единичен Ну или секунды не дай Бог Вот Но в любом случае в какой-то момент он накапливает статистику по всем инстанса бэнда Да и основываясь на этой информации уже просто смотрит на тот на тот инстанс который отвечает быстрее всего Да вот в данном случае первый ну и в первый отправит следующий запрос вот Ну и наверное для ещё для начала нам нельзя затронуть Его Величество p2c вот если кто-то с ним сталкивался то вы наверное уже понимаете О чём речь Но для тех кто его никогда видел суть этого алгоритма заключается в том что он подшива такую небольшую щеточку рандома в ваши статистические балансировки в общем-то Прежде чем сделать запрос Мы из общего нашего списка всех бкдо выберем только какие-то два рандомных под собой под капотом он будет использовать какой-то балансировщик у которого он запросит информацию о том а какая на них нагрузка да Ну вот например там inflight запросы 10 и7 Ну и основываясь на ней уже соответственно сделает выбор вот таким образом у вас сохраняется логика отправки запросов на менее нагруженный instance но добавляется как раз-таки вот этот случайный процесс который нужен для того чтобы сгладить некоторые всплески запросов Когда например у вас поднимается новая копия все клиенты о ней узнают а нагрузка на ней ноль Ну и они там волной на неё посылают нагрузку вот есть большие статьи на них ссылочка есть на слайде также можно будет презентацию скачать и я ещ потом в конце дам список литературы вот ну такие сложные академические статьи есть которых объясняется Почему PC Хорош Вот Но сегодня не об этом и Давайте посмотрим всё-таки на то как у нас В итоге это собрано как мы это скомбинировать Ну конечно же да PC безусловно но под капотом мы используем на данный момент так называемый согласованный суть его заключается в том Что есть ваш клиент Ну то есть вы Да вот вот этот сервис конкретно копия даже вот так копия вот этого сервиса оди и её статистика Но помимо него есть ещё другие копии клиентов которые тоже осуществляют inflight запросы И для этого для этого в согласованном list connected мы просто-напросто берём и в ответ от каждого от каждого бэнда от каждой копии кладём метаданные каждый бкд точно знает сколько сейчас он обрабатывает запросов и он может нам об этом рассказать вот ну и соответственно мы фиксируем эту информацию наполняем так по всем и делаем собственно то же самое что делал Ликон выбирая там менее нагруженный Вот Ну а на нём соответственно потом уже обновляется информация на более актуальную Вот наверное сведением я думаю можем закончить и поговорить о том а что же может всё-таки пойти не так Казалось бы всё так красиво что что что что просто что вот ну и рассмотрим мы с вами две ветки которые возникают во время роста а именно Первое - это проблема отказа частей которая начинает возникать когда у вас начинается большое количество кэндо с теорией вероятности просто не попрёшь она как бы у вас на большом количестве выше вероятность того что вы откажете вот ну и второе сама по себе э само по себе увелечение инстан сов несёт некоторые проблемы которые мы обсудим вот Ну давайте об этом по порядку сначала всё-таки про отказ одной из частей как про тему попроще А собственно Рандом если у Вас если вы используете Рандом и у вас отказывает какая-то из копий то Рандом с этим ничего не сделает И даже на самом деле не попытается он просто честно потеряет пропорциональную часть трафика Ну а это очень-очень грустно особенно если у вас высоконагруженные сервисы и очень много на это завязано процессов вот list connected всё-таки попытается что-то сделать он честно начнёт посылать запросы на эту копию но в какой-то момент поскольку э копия Она не отвечает вам у вас эти запросы повисали ете статистику которая в какой-то момент начинает проигрывать всем остальным вашим копиям Да которые живые которые обрабатывают запросы вот таким образом у вас вы потеряете какую-то часть трафика да Ну вот например на слайде три запроса повисли они остались воздухе и никуда не ушли Вот Но в какой-то прекрасный момент вс-таки эти пови за декрети декрети они например из-за того что у них будет отка они будут либо по отмене декрете счётчик либо отваливаться просто по настро по настроено таймауту Да в общем-то там станет 2 о и опять ноль а ноль плох тем что вы опять начнёте выбирать этот инстанс и послать пытаться послать на него запросы что приведёт к тому что опять надо накопить статистику и ваш график график ответов статус кодов будет как-то Так ну оно сма Конечно будет какая-то просто полоса со СП интервалом и прочим Вот Но это уже сильно лучше чем Robin вот с поскольку у нас он такой особенный с ним ещё интересней он ситуацию отработает чуть получше поскольку он начнёт совершать запросы и отваливаться по таймауту и записывать время таймаута свои вот эти ячейки для статистики Ну а та поку это считается что что-то не так надо отменять он очевидно будет больше чем вся другая статистика корректных запросов Вот и соответственно вы перестанете балансировать А на вот этот вот инстанс который Вас за таймаут Вот но статистика - это точнее вот эти статистические данные у балансировщика - это вещь такая которая Тоже имеет своё время жизни и вот это время жизни Например у нас для пики вма по дефолту задано в 15 секунд и это значит что через 15 секунд вот этот тайм-аут затр и станет нулём ну а там уже в общем-то вы знаете опять пойдут запросы опять накопление статистики опять чуть-чуть потерянных данных Вот но всё же потерянных что не есть хорошо вот и оно да оно будет работать лучше всего относительно того что мы рассмотрели ранее Вот на этом что касается отказов Я думаю можем закончить поговорим про само увеличение количество инстан сов как про самую интересную тему но для этого нам придётся тут сейчас чуть-чуть по умножать поделить и сделать такой маленький расчёт нам дано миллион rps SL на Time 90 квантили 30 миллисекунд Ну инсталляция пусть у нас будет там 200 клиентов 200 копий Да и 600 бнв в целом если так прикинуть то каждый энд у нас там должен обрабатывать около полутора тысяч ПС что в целом Ну вполне валидно Неплохой такой показатель Вот Ну а каждый Клиент будет 5.000 rps в районе да и ну собственно генерировать такую нагрузку Но каждый кнд может ходить в каждый кнд вот а что это значит это значит То что у нас Вот таких вот ячеек будет на каждую такую связь для статистики Ну а их собственно если мы перемножить количество клиентов на кэндо получается 120.000 И если мы весь наш rps поделим на все эти связи на 120.000 связей то мы посчитаем получим что в каждой связи в среднем должно осуществляться около там 8-9 rps зафиксируем эту информацию отложим её оставим на слайде Вот Но что такое 89 rps это что если мы посчитаем время в раз в которое будет осуществляться то получим 120 миллисекунд вот ну и я думаю тут уже чувствуется немножко такого интересного Да с рен Time 30 а каждый запрос 120 Что это значит давайте всё-таки чуть-чуть порисуем и посмотрим Вот вы ваш инстанс конкретно вот какой-то инстанс бэнда в который вы сделаете запрос Ну и вре временная метка какая-то Вот вы начали совершать запрос Да он у вас какое-то время выполняется 30 миллисекунд напомню и завершается И следующий запрос вы осуществите получается там через ну 120 ми 30 через по нашим расм через 90 миску после того как завершился ваш Первый запрос Итого вас получатся два параметра respon Time приложение и так называемое время обращения к статистическим данным и это значит что это значит То что нашли connected от которого мы ожидали что вот у нас там должны накапливаться какие-то ста данные у нас там в ячейках должно что-то записываться и мы из них выбирать должны самый меньший это получится что вы просто-напросто будете осуществлять запрос и завершать его куда быстрее чем совершать следующий и того Вы будете баланси не между там какой-то статистикой А между нулями и единицами и спойлер там скорее всего будет нулей гораздо больше вот в этих ваших ячейках Вот потому что вы просто будете оть запрос и он не будет успевать точнее следующий запрос не будет успевать воспользоваться стат данными и в итоге ваш Выра либо в НМ либо в это зависит от конкретно ре не работает посмотрим что же с ним ну или например наш согласованный Ликон совершаем запрос параллельно у нас совершают какие-то другие копии ещё запросы ваш запрос завершается с информацией о том что ещё параллельно делаются два запроса Ну либо respons Time у вас там будет например повыше но в какой-то момент у вас завершатся и эти inflight запросы от других клиентов А следующий запрос вы сделаете с вот этой статистикой о том что на данный момент было два запроса Ну где-то вот вот здесь вот когда уже те завершились вот ну и собственно Да тут точно также такие же параметры и того получается что ваша информация с которой вы сделали выбор уже устарела на бумаге выглядит на самом деле всё довольно печально И страшно Давайте заглянем в продо сервио и посмотрим а так ли это вот который у нас работает в продакшене на НМ там 350.000 rps Time у него 90к 14 миллисекунд вот введём метрику обращения к стат данным на клиенте и посмотрим на неё Вот девяноста квантиль и мы видим что время обращения к стат данным в среднем составляет 236 миллисекунд Что это значит с точки зрения нашей теории Это значит что наши вот эти вот времена отличаются в 18 Раз и это значит что сам деле надо рисовать не вот так а скорее как-то Так что вот у вас через вот такой вот аж диапазон совершится следующий запрос А вот в этом как раз таки диапазоне нагрузка успеет 18 раз смениться Ну просто поделим 236 на 14 и получим как раз вот эти вот условные промежутки Когда у вас завершаются запросы и в общем-то получается что и в реальности у нас ситуация оставляет шего с лает выбор не из всех а Только там из двух да Но p2c точно также сработает поскольку он будет запрашивать ваши нагрузки получать нули и точно также выразиться в Рандом вот ну и логично то вопросы Что же делать И что же делать и приступим к вариантам решения первый который приходит в голову это налить фейковый трафик в общем-то Ну нам надо как-то баланси давайте-ка просто будем поть фоне какие-то запросы которые будут нам обновлять наши стат данные и Когда у нас будет приходить реальный запрос мы будем точно знать что вот нам надо его слать вот туда вот и в целом эта схема будет работать Это её преимущество основное но понятно дело что это огромное количество лишнего трафика который в общем-то хотелось бы избежать потому что А зачем он нам следующий вариант перестать сильно пилить ваше приложение на микросервис точнее даже на мелкий и вот так из вот такой вот картинки прийти к вот такой вот да и увеличить ваши поды не в количестве А в размере то есть там дать им побольше CPU памяти и прочего оно также сработает оно не добавит лишнюю нагрузку на сеть но Мы возвращаемся в эпоху монолитов и прочего и получаем Те проблемы Когда вы просто вертикально не сможете в какой-то момент расти больше вот ну и в современном мире кубер у вас большие поды большого размера очень плохо раскладываются потому что вам надо иметь сервера на которых вот этот вот огромный кусок должен быть свободен вот ну и короче то всё грустно Да вот но я бы не стоял на самом деле на этой сцене Если бы у нас не было интересной идеи и звучит она как Санг суть её заключается в том что давайте-ка мы будем отправлять нашим клиентам не все не весь вот это вот огромны ССО подов а будем отправлять какую-то часть Ведь они же между собой равноценны а другому клиенту мы отправим чуть-чуть другую часть и так далее И в итоге в общем-то мы придём к какой-то вот такой картине когда каждый клиент у нас получает не всю пачку а только конкретную её часть так называемый сасет вот из преимуществ мы сохранили все те же самые что эта штука будет работать у вас меньше вот этих ячеек для оно не будет добавлять лишнюю нагрузку на сеть но это сложно есть определенная алгоритмическая сложность которую надо решить вот ну и нас тут всех Я думаю сложные задачи не пугают поэтому рассмотрим именно этот вариант как основной вот как же мы это реализуем вот Ну и наверное стоило бы зайти наверно с самого простого давайте как-нибудь это посчитаем придумаем может какую-то формулу какую-то функцию которая всё это сделает Ну давайте тогда начнём с наших 600 кэндо и 200 клиентов Вот Но для того чтобы сразу наш алгоритм не разнёс Всё вокруг добавим на него некоторые разумные ограничения наша пачка должна быть не меньше там например 12 подов и не больше 100 просто такие вот верхнюю нижнюю границу вот ну и добавим ещ такую некоторую хитрость которая будет защищать наши бэнды а именно фактор репли поскольку у нас могут ломаться Не только энды но ещ и клиенты то в случае если у нас например один энд встречается на одном клиенте только Ну используется только одним клиентом и этот клиент выходит из строя то этот энд остаётся без нагрузки начинает простаивать Поэтому будем бэнды стараться отправлять так чтобы они были например Ну вот в случае с репликой Фактор 3 они должны повториться как минимум у ТХ клиентов каждой и вот будем это сделать за счёт того что мы будем рассматривать список кэндо не один раз да вот как например Здесь и отдавать только вот этот список а продублируйте будет у нас каждый полный список кэндо и наши клиенты будут получать пачку из какого-то своего конкретного раунда вот таким образом вот у нас если взять там просто первый инстанс нашего бэнда Он повторится на синем на Красном и на голубом клиенте вот для того чтобы это всё как-то к этому подступиться Сначала мы возьмём и целочисленное энды помноженные на этот реплика фактор делённый на клиенты в общем-то просто как-то так поделим целочисленной посмотрим что у нас получится вот ну и само собой провали что мы не пробили наши границы что у нас соблюдаются наши Lover Иуды Вот Но сталкиваемся тут с логичной проблемой что вот вся вот эта вот формула она целочисленное у нас могут быть так называемые остатки это когда у нас соответственно бэнды не делятся целочисленного клиентов и это значит что какая-то пачка будет не догруз вот как например Здесь на слайде Когда у нас одни бэнды получают 20 а другие 19 подов ой точнее клиенты вот ну и сделаем тогда что нам в общем-то когда наверное у нас одна один кнд э разница в один кнд - это не так страшно э поэтому мы просто постараемся эту вот эту разницу минимизировать а для этого мы собственно прикинем вот этот вот наш Диф за счёт того что поделим Ну прикинем короче остаток от деления и соответственно в некоторых рамках возьмём наше исходное число которое мы посчитали Да вот в общем-то нашу вот эту исходную комбинацию которую кото получилась И в диапазоне от её и удвоенного её размера в цикле переберёмся значения и посмотрим А где же у нас этот див будет минимальный вот будет это выглядеть суммарно как-то так вот такой вот у нас небольшой ээ снипет кода получился посчитаем его и получим что для нашей комбинации должен быть subset size 12 вот всё это дело собираем запускаем смотрим начинаем с этого переключаем и получаем замечательную картину мы получили улучшение респонс тайма нашего сервиса и Да я думаю можно назвать это победой и здесь сделать наши выводы Вот мы с вами Итого улучшили respon Time мы с вами снизили количество tcp соединений Ну и повлияли на работу балансировщика вот и это ровно то что мне хотелось бы вам всем здесь рассказать и закончить мой доклад если бы не одно но и это Но на самом деле выглядело как-то так это графики пса и вот ещё как-то так Ну и вот если увеличено И на самом деле если ещё кто-то не понял ужас этой картины то это ужасное разбиение ПС на группы у вас какие-то поды тут сильно перегружены какие-то существенно не догруз и в общем всё что мы с вами бились ВС это пошло прахом у меня остались архивные фото Гру В общем Наши лица выглядели как-то так вот ну а наши клиенты которые в общем-то которым мы это всё сделали они выглядели как-то так вот ну начали разбирать начали копать в чём же не так Для этого посчитали ещё раз и определили что какие-то поды вот мы старались там содержать реплика фактор равный трём но по факту получилось что наш алгоритм посчитал э так что некоторые поды стали встречаться чаще чем другие вот ну что ж вернёмся в идее и посмотрим а что же мы упустили Ведь мы Казалось бы остаток посчитали таких проблем быть не должно Но оказалось что помимо того что бэнды целочисленное не делятся на клиенты так и клиенты могут целочисленная вился остаток в виде как раз-таки вот этой последней под пачки в каком-то раунде Ну и после того как ВС вот это вот раскопали картина когда у на какие-то поды встречатся какие-то реже на клиентах она стала вполне логична вот Ну и что мы опять в самом начале опять всё по новому вот вам мем любителя разрушать Всё вокруг себя в общем-то Так мы чувствовали себя когда мы это всё получили Ну вот что ж начинаем опять с чистого листа и как показывает практика всех инженерных программистский в мире идеальный вариант алгоритмического решения на самом деле это просто численный вариант поэтому Давайте просто возьмём и посчитаем численно все комбинации Поэтому вот вам новая глава нашей книги а именно целочисленное решение задача на самом деле остаётся вся та же самая у нас есть 600 кэндо У нас есть 200 клиентов но э мы начнём учитывать не только вот этот остаток и то что этот остаток получает повышенную нагрузку а также учтём остаток в рамках раунда который в итоге получается у нас не догруз поскольку в него ходит меньше клиентов чем во все остальные кнд вот а и как раз-таки напишем такой небольшой снипет задача которого будет просто обойти всевозможные решения Посчитать все комбинации клиентов кэндо и сасет вот и соответственно прикинуть А насколько у нас в совокупности система перегружена Ну или Негру там как посмотреть Итого Нарисуем вот такую вот табличку которую наш скрипт выполнит и посчитает Ну и заодно мы здесь в скобках а пометить старые наши ну посчитай ранее subsetting нашим алгоритмическим решением и вот тут как раз-таки уже видно что здесь с цветом обозначены не догруз системы и вот видно что наш новый алгоритм весь стал позеленел Хотя в нём В некоторых комбинациях всё равно остались не очень хорошие такие ситуации Вот но видно что во многих ситуациях он стал сильно лучше чем наш прошлый алгоритм что как раз таки объяснялось вот как раз-таки есть наши раунды точнее наши сасет между клиентами и здесь алгоритм просто проходит И обсчитывают сколько каждый из них встретился вот ну и также он формирует табличку которая генерить уже вот собственно наш процент не догруз при таком-то сабс для такой-то комбинации Клинт вот ну что ж посмотрим на наши полученные результаты и в общем-то Да выглядят они как-то так вот те группы которые мы породили и те те сервисы которые мы почти разломали они вернулись в свой нормальный строй Вот но ещё оказалось что проблема эта была не только вот она выглядела не только так но также она выглядела на том что у некоторых подов была Вот такая Широкая труба по rps на ней плохо было заметно что что-то идёт не так потому что ну как бы труба ру Вот они там распределяются но они тоже вот так вот таким образом сузились Вот Ну а на квантиль само собой ничего не отразилось потому что как бы у нас всё равно пачка пачки так и остались маленького размера Вот Но тут надо немножко вернуться и поговорить о том что а что же там всё-таки С отказом одной из частей ведь та картина которую мы представляли себе изначально в начале доклада который выглядела как-то Так на самом деле в действительности она тоже выглядит как и с большим количеством исов так и по ранее посчитано формуле получается что мы точно также скорее всего будем реже успевать накапливать статистику потому что количество запросов в рамках одной связи сильно меньше и они будут быстрее успевать отваливаться по таймауту или отмене вот в итоге что будет приводить к таким колебаниям сильно чаще Ну а это потерянный трафик Ну а при сабс само собой когда мы вот так вот обре все эти бэнды и будем входить в количество кэндо поменьше у нас будет в балансировке то эта статистика будет накапливаться быстрее и соответственно вот мы получим ту картинку которую и видели вот ну и наконец-то теперь уже без обмана можем поговорить о выводах и на хайлоу в последнее время всё чаще встречаются доклады про тонкости и так сказать особенности микросервисной архитектуры и собственно это как раз-таки такой очередной тезис в эту копилку вот плюс также это методика оценки наличия Такой проблемы если она у вас имеется вот также мы с вами разобрали не очевидную особенность этих балансировщика их инертность вот эта вот задержка в накоплении стат данных ну и также их факт вырождения в НМ или Рон вот ну и Сатин в общем-то как такое неплохое решение данной проблемы которую мы внедрили у нас компании вот ну ищем закончили как я вам сказал есть всё-таки некоторые комбинации которые там из простых чисел плохо друг на друга делятся и наш дальнейший план - это рекомендательная система количества инстан сов для приложения для того чтобы обеспечивать им Вот эту вот эффективность балансировки и вот отсутствие Вот таких вот проблем Вот Ну а здесь также Да хотелось бы поговорить про небольшой чек-лист что стоит сделать а именно стоит посчитать ваш трафик по методике которую мы описали и понять а У вас такая проблема в ваших сервисах или нет ну и в случае необходимости применить одно из ранее предложенных решений вот здесь небольшой список литературы оставлю на слайде сейчас можно отсканировать либо потом на сайте скачать презентацию и посмотреть вот ну а на этом У меня в целом всё спасибо вам большое за внимание Спасибо такт немножко в зале достаём мобильные телефоны открываем камеру э сканируйте QR код э который про оценку за доклад и Оцените пожалуйста доклад Ильяса те кто онлайн находите в плеере кнопку переходите в чат э в чат в teleg чат нашего зала и задавайте там свои вопросы Сегодня мы э за два лучших вопроса дадим подарок от озона и от лода а поднимайте руки у кого уже есть вопросы Давайте вот молодой человек В первом ряду Уважаемые хелперы вот сюда Подскажите пожалуйста как часто вы делаете ребалансировка И вообще как это влияет У вас же меняется количество кодов и меняется количество клиентов безусловно хороший вопрос ту там не нет поскольку система вся это динамично Да и как правильно вы заметили количество клиентов кэндо может меняться то у нас просто система идёт в табличку Ну получает новый размер сасет новую пачку и продолжает отдавать уже пачку Ну соответственно другой сосен Вот то есть это М это Time постоянно Да только изменилась топология сразу уже новая комбинация вот СБО Привет Меня Лёша зовут у меня такой вопрос Вот про замеры н запросов это же всё должно работать если запросы однотипны абсолютно То есть когда обработка его не зависит от от размера есе забо данных точечный запрос или Full Они конечно там н в разы отличается и в этом случае балансировка не работает и вы как-то соответственно учитываете то что классы запросов разные Да да у нас в общем был Был такая итерация был такой заход когда мы в общем-то статистику натравили не на количество соединений и ий запросов А на какие-то там ну условно мнимые попугаи которые оценивали этот размер этого запроса и у нас были такие подходы Да но просто в сервисном взаимодействии как правило эти ситуации возникают реже вот ну и мы в общем какого-то перформанса от того балансировать либо между запросами просто Либо между Ну с оценкой этого размера условно говоря вес этого запроса мы не увидели вот для каких-то ситуаций да Такое возможно и у нас есть такой функционал Вот Но в общем случае в общем случае как правило запросы Ну они скорее однотипные вот по крайней мере в межсервисного Здравствуйте спасибо за доклад У меня два вопроса возникло первый - это по части падений Как раз-таки вы показывали что делать в случае падения какого-то из сервисов что делаеть в случае падения мастер на Ну который вот это распределяет получается все наши запросы сервиса один То есть Нет смотрите серс сервер сайт тут нету тут всё на клиенте то есть балансировка поется тот кто распределяет запрос вот этим Робином либо либо чем ещ вот если это мастер надо падает то что происходит Что делается Нет я так понимаю мастернода который как раз таки осуществляет алгоритм балансировки не у нас клиентская то есть это не сервер сайт балансировка А у каждого пода клиента то есть у каждого инстанса копии Он у него своя балансировка вот он напрямую ходит во все энды в нашем РСМ действий вот если рассматривать такую ситуацию когда да у вас есть там какие-то ну прокси балансировка Да там стоит Engine X там в количестве 10 штук и какой-то из них падает ну Наша система отреагирует Так что да в какой-то ну здесь всё проще он просто не посылает запросы Вот для этого нужен реплика фактор который как раз-таки э делает Так что бэнды встречаются не на Ну то есть типа не кнд на только на одном клиенте а кнд встречаются на нескольких кэндо Да в этот момент конечно типа какие-то бэнды будут немножко не догруз но здесь уже реакция системы с другой стороны будет когда просто наши наша система Ну если это в кубе развёрнуто кубер нам сообщает о том что у нас клиентов стало не 10 а дев мы пересчитывать сосен Благодарю и второй вопрос - Это про георгини То есть если у нас сервисы Ну к каски распределены регионально то что вы делаете Как раз-таки в своём сосен например чтобы клиент из Калининграда не посылал вопросы во Владивосток и что насчёт там клиентов которые например посередине которые между Калининградом и Владивостоком которые могут и туда ходить и сюда ходить Ну тут собственно на самом деле локализация трафика работает выше сабс то есть сасет уже работает на уровне Когда у вас вот если вам надо ходить только там поближе да то есть ну в рамках одного города там региона неважно то Сатин будет учитывать только вот эти вот инстансы кэндо клиентов которые находятся в этом регионе то А вот как ки с теми клиентами которые посредине которые и к тем могут эндам и к этим эндам ходить Ну если если у вас У нас можно настроить такие правила чтобы ходить во все да то есть без учта локализации тут subs это не учитывает он работает ну собственно вы ему сказали вот у меня есть все бэнды все клиенты во всех там регионах и прочем Ну да он просто посчитает для такой пачки то есть для большой для большой вот этой инсталляции Благодарю вопрос из трансляции Васильев Павел кто защитит сам балансировщик от большой нагрузки То есть как обезопасить сам балансировщик чтобы он сам не лёг ты уже частично ответил Ну да да у нас балансировки на стороне клиентов Это алгоритмы там скорее реализации алгоритмов в рамках фреймворка который использует каждый клиент Давайте во втором ряду А что вы делаете с поми подключения по типу и ть количество подключений кажется не очень хороший вариант А да Ну кстати насчёт grpc Ну если рассматривать да стримов такие запросы для них балансировки у нас другие у нас там немножко другие системы другие схемы У нас есть механизмы ребалансинг Вот это когда кнд тут уже короче балансировка уезжает так на бэнды сами бкд начинают друг с другом общаться и передавать информацию и соответственно отключать ненужные коннекты Ну то есть на какой-то другой но это уже немножко о другом разговор тут речь шла в основном только про Ури запросы вот об этом можем поговорить в кулуарах либо у нас на стенде как у нас реализовано следующий вопрос от нно FB А почему не используется чек вместе снм чтобы снизить количество отказов и при это заливам трафиком хелс ки сильно медленнее реакция хелс Che ков в даже в достаточно быстро реагирующей системе может достигать десятков секунд То есть Ну если вы конечно не шлёт там чек каждые 500 миллисекунд и там за четыре Ну там за 2-4 секунды его не отключайте но всё равно вот эти там 2 4 10-20 секунд сколько у вас Эта система Насколько быстро реагирует это всё равно потеря трафика и если это всё работает в совокупности то оно отрабатывает побыстрее и получше клиенты быстрее узнают о проблеме нежели какой-то там Watchdog внешний который ходит и проверяет живы Вы или нет спасибо есть у нас ещё вопросы Давайте Вот вот здесь в во втором ряду А добрый день спасибо за доклад Меня зовут Андрей ВК у меня возник вопрос в процессе доклада и Судя по вопросам не только у меня потому что я ожидал изначально что будет речь о серверной балансировки вы говорили про клиентскую и соответственно про серверную не было сказано ничего а соответственно вопрос Можете ли прокомментировать там Почему была выбрана клиентская балансировка А не серверная а ну в нашем в рамках нашего межсервисного взаимодействия поскольку у нас микросервисов очень много и много подов как я на первом слайде говорил у нас просто было принято решение избавиться от этого лишнего хопани настраивать кучу серверов прокси которые бы балансировать нагрузку убрав это всё на клиент Это здесь э м так сказать Ну это просто наше такое решение оно нам просто для того чтобы убрать сетевой хоп Лишний вот Ну и это микросервисы а не внешняя нагрузка они могут сами в целом отбалансировать это всё Ну то есть можно убрать фреймворк который будет работать Вот спасибо Вот молодой человек В первом ряду вопрос уже задали удивительно у нас коллизия вопросов а давайте тогда молодой человек четвёртый ряд возле колонны А у меня такой вопрос Ну вот в свете клиентской балансировки у вас кластер Discovery неоднократный же ну при старте клиента Он повторяется CL Discovery узнать какие сервисы навая модель модель не модель Ну то есть типа у нас нене не у нас собственное решение РН Я на прошлом лоде рассказывал в целом про варден как он работает но у нас собственная реализация и у нас каждый инстанс клиентов Ну то есть если вам надо осуществить какое-то межсервисного взаимодействие вы открываете подписку на Arden Ну то есть этон - это такое же приложение и там задержка Ну какие-то миллисекунды секунд Ну да Ну вы просто открываете Стрим И вам в это Стрим постоянно напивается информацию о том об изменениях в Кэн дах с одной стороны круто у меня был другой вопрос с подковыркой Ну вот когда тачка выбывает и по ней Ну какой-то алгоритм клиентской балансировки накапливает статистику и понимает что туда нужно меньше слать а не рассматривали ли такой вариант что ну там пессимизация первый же какой-то негативный код ответа вообще туда не шлём до следующего сер Discovery но видимо в этом стримом протоколе нет смысла Ну да нет смысла поскольку тут подразумевается что стримов протокол пуш модель сразу вам доставит эти обновления Вот но просто триггер на есть у нас и такая реализация это называется общепринято называть это outl детек механизм он всё равно То есть как он например работает у нас в течение там у вас есть интервальная интервальная его работа и он за 10 секунд например смотрит а сколько у вас там было плохих ответов сколько хороших от каждого из инстан сов бэнда Вот и какие-то копии плохие он на какое-то время может исключать из балансировки вот есть такие алгоритмы аэ но опять же как я говорю типа у них там 10 секунд там 20 секунд интервальное время работы они исключают их на какое-то время потом обратно возвращают Ну то есть условно говоря работает так как некоторый такой circuit брейкер но не на весь сервис А в рамках каждого коннекта каждому Кэн вот э такое Да тоже есть и оно применяется и у нас в том числе Вот но оно просто чуть-чуть помедленнее и как правило У нас вот за вот эти вот там десятки секунд Ну там 10-20 секунд э в зависимости от настроек у нас уже успеет дойти по пуш модель То есть просто пуш модель считаем что она без задержек да давайте вот здесь вот предпоследний ряд молодой человек а Спасибо за доклад У меня вопрос такой на одном из слайдов проскочил там тезис про tcp соединение лишнее Угу я правильно понимаю что это L4 балансировка и каждый этот это новый Connect tcp или используется всё-таки все плюшки http2 там мультиплексирование безусловно используется Ну ус У нас у нас используется jpc вот jpc поверх http2 там я подразумевал то что grpc работает обычно как у вас Ну на клиент вы загружаете информацию что вот у меня там 10 бэндо и он ко всем этим дети открывает tcp соединение Ну то есть tcp соединение поверх которого http и потом сам jpc Вот и одна из Да там одно из таких небольших Ну это такая типа небольшой бонус разделять бэнды на небольшие пачки Это то что у вас просто вы будете открывать коннекты Не ко всем эндам А вот ну типа к пачке Ну tcp коннекты сэкономите да и второй та вопрос сразу возникает А если я правильно помню в grpc из коробки там только Ну на уровне именно канала балансировка делается а или есть какие-то настройки ещё сверху чтобы более умную делать Вот да очень крутой вопрос jpc Гош най и Ну у нас go.net основные языки и у нас на всех них jpc чуть-чуть дописан jpc в общем позволяет использовать свои модификации и вот как раз-таки у меня есть статья на Р про то как в общем-то в jpc внедрить собственные системы резолвится в общем-то там всё описано Э как э подключать это всё в jpc и чтобы он например использовал какой-то ваш код который будет там например вот как в нашем случае подключать делать конект какому-то серверу из него подсасывать все все список всех кэндо потом он это передаёт на следующий уровень уже там есть уровень балансировщика который открывает коннекты уже да И следит за этим их Реди состояниями и третий уровень - это уровень пикера так называемого который уже реализует алгоритм балансировки в общем Это такая крутая штука которая позволяет всё это кастомизировать и Да вот то что вы правильно сказали там есть Рон по дефолту он из коробки идёт Ну и там есть надстроек First всё это можно доработать в виде своих каких-то балансировщика и прочего прочего всё это круто там клиентов у нас там мы видим сколько Этих клиентов конкретно и каждый клиент В общем ходит в свой сасет Ну то есть типа есть внешние балансе которые принимают условно говоря входящий основной трафик в Ozone Да это уже там кы Lo балансе они распределяют их по клиентам А уже соответственно у каждого клиента свой сосет вот а возможно вопрос про алгоритм разделения или там случайным образом как входной трафик А как на эти сасет Ну там на самом деле тоже будет либо Ликон либо Ну либо РАУ Robin Я честно говоря сейчас затрудняюсь ответить Спасибо у нас ещё есть время для одного вопроса Давайте вот на первом ряду А спасибо за доклад Вопрос такой родился а была ли у вас потребность балансировать сами запросы внутри коннекта Потому что А я так понял балансировка у вас идёт именно установка коннекта не к серверам а сами вот эти запросы шные Вы баланси про запросы jpc Ну то есть в смысле каждый у нари запрос Вот это балансировка и этих за то есть вы именно запросы считаете Да конечно конечно ну то есть типа вот запрос ответ вот это это балансирует Большое спасибо за вопросы Ильяс теперь самое сложное подарок от лода и подарок от озона так можно пожалуста подарок от озона вот молодому человеку на втором ряду Да у нас там машинка Давайте попло за отличный вопрос машинку можно у нас на стенде выиграть Приходите вот а подарок от хайлоу вот молодому человеку который задал замечательный вопрос про jpc нет Вот вот туда дальше Спасибо большое спасибо вам за вопрос"
}