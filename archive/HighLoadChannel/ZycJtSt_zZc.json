{
  "video_id": "ZycJtSt_zZc",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Всем привет Меня слышно отлично это не не это во значится ребят конец конференции конференция подходит к концу Спасибо вам большое что вы здесь что проявляете интерес что вы с нами вот сегодня будет несколько историй из жизни одного хорошего сервиса который мы в Яндексе подняли на в масштабах всего мира мы следовали без практи сам писали компоненты проходили код ревью архревю там всяких всячески применяли э эти бес практики которые знаем некоторые компоненты получались хорошо то есть они заезжали в облако подключались к мониторинга к логирования значится запрашивали там какими-то пробами и с ними проблем при скалирование не было с некоторыми в частности вот некоторой сложной компоненты или некоторые вещи которые мы брали из он сорса Они шли с кто-то с багажом кто-то без нужных кусочков и с ними было сложнее и вот именно это то что я называю в докладе в цель в доклада не CL об этих примерах и поговорим вот я ча свой карьеры посвятил App менеджменту и мониторингу то есть в частности в случае облаков мы прыгали С командами на сервисах чтобы они лучше легли в облако встали под нагрузку держали наш с вами продакшены и последние два уже наверное с половиной года я и моя команда занимались внедрением поддержкой разработкой Яндекс телемоста телемост - это сервис который позволяет взять камеру взять там пошарить десктоп и провести онлайн встречу Давайте с вами познакомимся доклад про есть в зале энде поднимите пожалуйста руки Слушайте это больше ползала это классно потому что доклад именно про кейсы бэнда нужен какой-то бэкграунд а ели в зале специалисты по видео конференс связи или по энкодинг я вижу сколько пять насчитал рук Да это классно Э ребят возможно вам будет ещё интереснее но этот доклад Он про сигнали то есть в видеоконференция есть Два кита на которых он стоит Первое - это как медиасервер договариваются друг с другом и второе - это как они договорившись общаются Вот и мы сегодня про первое про сигнали который более-менее Един для всех кэндо Вот в ядре телемоста у нас естественно кото к которому подключаются все клиенты и который позволяет им обмениваться Медиа потоками и запрашиваю Медиа потоки у этого самого наши с вами клиенты телемоста рисуют картинку вот значит какие ня обсудим когда прошла первая интеграция взяли результат прошла вторая интеграция взяли результат использовали третья оно займатись тра вот что делать поговорим о балансировке сессий то есть когда у нас есть одна глобальная сессия которая там дишни вашей встречи А если её балансировать более низкоуровневый сессиями на уровне медиасервер Ну в там или в Яндек на котором работает СТ и поговорим как наши медиасервер придумал в процессе подготовки доклада это Arch это то набор Паради который позволяет обч каждый раз есть берм с условно икро если там и применяем готовый мониторинги У нас есть пробки есть соответственно логи есть Деп работает вот из за нарушения этих парадигм воображаемая персонаж облачная архитектурная полиция выписывает нам абсолютно не Воображаемые штрафы Приложи вни сза до вложиться в какой-то если мы что-то там кастомное придумываем Ну что погнали посмотрим первый кейс про цепочки интеграции значится то что в Яндекс мосте можно собирать встречи и совещаться это все знают оказывается Вот следующий доклад от Яндекс 360 в Башне про это будет в версии Яндекс телемоста есть такая фича как трансляции встречи на большое количество пользователей То есть у нас собирается какой-то компонент собирает потоки из камер и микрофонов пользователей рендерит их в какой-то один видеопоток и отправляет десяткам тысяч вьюрок которая используется для использовалась для трансляции Чемпионата мира по футболу вот что для этого нужно сделать нужно компонент под встре там как-то собрать Видео инициализировать отправить Окей из чего он будет состоять Ну у нас должно быть часть этого компонента которая подключится к телемост заберёт потоки должна быть часть которая Медиа рендерит в кавас Ну то есть на Вот это на квадратик Да и должна быть часть которая закот результат и пошлёт он хрупкий то есть если что-то из этого навер то так сказать мы получим и сломанные стримы и там утечку этих контейнеров Если будем как-то их меджи вот и что вообще может на вернуться в облаки Что обычно ломается Ну обычно Может начать там пяти Соти что ещё бывает Ну там перезагрузиться он вообще во встре должен быть а если он просто будет отвечать Ты жив я жив тон может забыть что быть во встрече Вот ещё он может там недополученной как-то у нас они не должны стримить вот и эндером было в зале да то есть все помнят что бэнде любят проверять живость контейнеров пробками То есть у нас пробочка там обычная но необычная она должна ещё проверять что бродкастер во встрече с не забл что он должен делать Вот поэтому эти чеки пробки должен вызывать какой-то компонент который там у нас будет являться мастером до трансляции он ещ заодно там в календаре Планировать на трансляцию у себя хранить Вот и соответственно в связи с трансляциями два кейса рассмотрим перво это нас на заголовке кейса было то есть очень простой кейс вот буквально создать дишни трансляции и опубликовать его в календарь проайти состояние в календаре если с патентно нажать то в случае гонки мы можем получить что в базе Брока менеджер у нас один шник трансляции А в приглашении в календаре другой 10.000 юзеров наши никогда в жизни в трансляцию не зайдут вот ну кров много да понятно что такое несложно то есть мы буквально там тесты пишем там политики просчитывать Аккуратнее и всё хорошо но я начал именно про цепочки интеграции Давайте посмотрим что нужно чтобы такой бродкастер контейнер запустить ну во-первых нужно меть их пул и из Пула его достать что это контейнеры в которых тампу подготовлены потом нужно стрими платформе ровать какие-то транско ресурсы для подготовки разных разрешений не то нажал запустить подготовить определённый эпизод то есть ещё одна интеграция со мингой платформой запустить сам бродкастер ска Смотри вот конференция вот в этот эпизод надо И после этого дождаться пока он запустится вс такое проу сом буде сло поэтому Нам нужен кто-то компонент который будет следить за всем этим самым как у нас микросервис общаются Вот и давайте это у нас будет тоже вот ещ чтобы упростить себе жизнь когда мы с вами запускаем там всего два состояния там можно и но по пути к это то есть куда мы хотим привести пользователя куда пользователь изъяв желание попасть и у нас получится Вот такая вот стоит машинка в базе то есть если мы после каждой интеграции будем сохраняться в персистентное хранилище в базу вот ка устойчива соответственно рить каждую интеграцию по умному и учитывать пользователя то в принципе нам будет значительно проще просчитывать политики и защиту от падений вот сохранятся после каждой интеграции значится каждую ошибку интеграции рить потом так как у нас менеджер он же тоже там какой-то в Облаке живёт Ну тоже да его тоже так сказать сделать так чтобы второй поток подхватывают Максимум в один поток вот мы это назвали там интеграционного процесса для себя внутри и в одной из наших предыдущих публикаций прошлого лета там подробно рассказано какта штука работает внутри вот э ссылка в конце доклада можно эти ссылки забрать вот по дику Вот и вообще то что здесь происходит вот это сохранение там один там максимум поток в кластере это оче актор наю модель интереснейшая штука то есть в случае Java - это Что это а temporal в случае там wdb там она тоже на это рассчитывает на c+ Plus есть опенсорс ная реализация э рекомендую почитать хотя бы просто в академических целях А за SIM мы заканчиваем первый кейс а первую историю Ну что разм супер э Пойдёмте второй посмотрим значится СТ он как работает даётся ссылка по этой ссылке все заходят там или из браузера Или откуда и должны попасть все в одну комнату и так сказать мы столкнулись с проблемой что это редко но не всегда происходило именно так вот телемост о основан на комне Лас комы говорим плотах но на масштабах там всего мира если мы хотим на весь мир предоставить сервис то возникают проблемы сейчас вот обсудим Какие и первая проблема у нас с централизацией Вот на этом слайде Я прошу всех вот внимательно посмотреть э терминология будет важна в течение всего доклада У нас есть jits Video Bridge справа Да справа это наш медиасервер помните sfu который пересылает всем Медиа и соответственно с ни с ним все устанавливают Медиа соединения У нас есть conf foc который выделяет Медиа сервера для каждой конференции вот компонент слева это тоже компонент То есть у нас есть какой-то оркестратор вот в очень широком смысле слова оркестратор в каждом докладе оркестратор чтото своё и есть меб которые он оркестру а так как предназначен для запуска где угодно сторон система там связанности то есть у нас нет какого-то сервиса который предоставляет контейнеры Вот и в качестве системы Discovery в случаях видео конферен связи оказывается очень удобно использовать что-то похожее на чати в данном случае это проди XM движок Есть кто в зале помнит 2 3 Так ладно Ну лучше вот короче тики и вхо Чаки Медиа сервера дфш входят в чати и таким образом находят друг друга и могут развернуться в каком-то таком кластере мы это не можем исключить но проблема в том что ишки и фоки имеют сложное состояние То есть если мы их тнм то конференцию придётся сразу перебирать конференция развалится Они забудут с кем они должны были общаться вот и получается что у нас вот такие вот точки отказа в нашей архитектуре как результат внедрения там стороннего компонента кото ВМ плох вот что рекомендуют делать жи в этом случае сами авторы они говорят Ну давайте поставьте там какой-то балансер между шарда и держите несколько запасных шардов полноценных То есть у нас конференция баланси на один из кластеров Но если там что-то с ним пойдёт не так есть запасные вот мы пробовали этой рекомендации последовать и получили вот ровно то что мы видели в начале там этой истории то есть у нас начали раздваивается поте заходят и попадают в разные залы если вкратце как-то происходит то Просто после перебан сиров пользователи забывают на старых Шарх и вот это нам нужно полечить Вот а если не вкратце Ну что у нас был активный шарт к нему приходит клиент пытается переподключиться там уже кто-то есть но предположим у нативным становится Да активным становится второй на Первом всё ещё есть люди соответственно кто-то может пересел на второй кто-то не пересел но результат в общем да мы видели здесь насчёт Моего начальника образ собирательный все имена изменены совпадение случайно вот а ещё в этом сценарии есть прикольное продолжение Давайте посмотрим понимаете какое дело когда мы соа мы хотим чтобы если у кого-то сила батаре и он вха в туннель и потеряла с ним связь мы не хотим видеть его в своей раскладке в клиенте телемоста поэтому когда человек пропадает медиасервер шлёт остальным специальное сообщение типа офер ну такое же как он шлёт при инициализации соединения и важно Для нас что в оффере есть список всех участников и айпишник медиа сервера к которому нужно подключить Медиа Вот и когда у нас в старом рде стай медиасервер недополучает Кип лавов А желание совещаться из является именно там Кип лайва вот клиентов он шлёт офер всем остальным участникам и все остальные участники из новой части конференции начинают пересекать вторую Вот соответственно это нам нужно было полечить причём это так сказать фигня которая нужно залатать сервис не внося в него существенных изменений то есть мы не могли там катану всех клиентов перекатать обновить и не могли там повысить требования к железу в разы поэтому что мы приняли решение блокировать Афера старых шардов соответственно приглашать участников на новый шар то есть мы добавили компонент который это всё лечил вот какой-то если вы не занимаетесь меди серверами Вот например в кейсе коллаборативный досок например в кейсе Досов там каких-то сессий совместного редактирования ситуа Скорее всего будет балансировка двухуровневая и Здесь проблема именно в двухуровневой балансировке и что с ней делать Вот Можем ли мы рекомендовать Вот так это делать если делать с нуля но не совсем то есть есть у нас требование например что за 5 секунд нужно всех пересобрать взять переселить Ну если бы мы делали с нуля то ла раз в 10 секунд мы бы конечно сделали раз в секунду и таким образом вместо ре инвайтов сделали бы более честные более частые лайвы на клиентах соответственно рассказ о том как точно это реализовано был в одной из наших прошлых публикаций тоже опять же в конце доклада можно взять QR код забрать слайды там всё будет Мы засим закончили с кейсом вторым вот Ну что разминка как бы кому-то нужна разминка кому нет Вот это кстати норис ему нет Пойдёмте третий кейс смотреть значится кейс у нас про что кейс про деплой деплой в ПАЗ То есть сразу скажу что телемост он не на Кубе но на Яндекс Деп который вот рассказывали На прошлом Святом лоде он чем-то похож на кубер и здесь опять Вот CL у нас Что случилось У нас Принс про в качестве Вот и как нам сегодня с утра рассказывали в Башне коллеги из МД из Яндек облака У нас есть система мониторинга которая звонит и Однажды утром Онам звонит и говорит Привет мониторинг у Вале Поль подключиться не могут Вот то есть что-то мы опять там с не доделали Ну давайте разберёмся Как происходит вообще подключение к команда в инцидент на протокол на созвон там естественно в телемост И с чего всё начинается когда клиент хочет подключиться к телемост он приходит кфо и говорит Слушай дай дай медиасервер мне Медиа слайд надо фо через вот этот печати медиасервер находит и говорит Ну давай там открывай Медиа канал сейчас к тебе придут Джи Бишка медиасервер наш Медиа канал открывает И чего И мы отсылаем этот вот офер пользователю то есть что у нас какая-то процедура инициализации самих Медиа серверов вот мы на её примере посмотрим у нас за общение между и начинает отвечать проса ещё для повествования важно сейчас мы вернёмся к этому слайду что при инициализации самой шки ей нужно открыть порты там шные порты вообще Медиа переда в внешний интернет и она это делает смою туннеля То есть у нас из конфигурации пода ей выдаётся какой-то внешний ошк четвёртый и она по нему начинает пакетики принимать ОК То есть у нас есть три системы через которые так сказать пода может трафик получить после своей успешной инициализации Вот Но при этом система Discovery - это такая штука В очень опять же общем смысле которая позволяет трафику палиться именно в наш контейнер вот Да адреса правильные Да всё должно быть сигнали Ну вроде работает но подключение не происходит Ну как ну и соответственно что-то не так с адресами на А всего два соответственно у нас есть Ош конференции которые маятся в этот чатик У нас есть этот айпишник который мапи ВБ о на третьем часу гель нашей кома вот Дань если ты нас слушаешь Я те лично со сцену и так сказать много из нас в зале шлём лучки добра и благодарности вот действительно Вот если бы это произошло так то симптомы бы объяснил то есть один в чатик вошёл ска договорился а второй во второго пошли пакеты юдиш и он знать не знает что это за пакеты можем подтвердить можем то есть вот помните Здесь было пять человек в зале которые в видеоконференцсвязи Если вы именно ВКС то так сказать знаете что тамра содержит там сыры могут содержать не только один I адре а там ещ несколько других и по ней мы подтвердили что действительно это разные Тачки были разные контейнеры но Как такое возможно помните только что рассказывали про про конн вас это это делает всегда но почти всегда То есть если у нас контейнер нй например зас боил А пот уже поднят то тот поднятый пот он тот тот поднятый контейнер серенький он абсолютно не обязан ээ знать что он неправильный и не обязан знать о существовании второго Вот и Да это действительно наши получается фантомные двойники вот фанаты стартрека в зале есть Ну наверное есть А может и нет вот и один из них из параллельно Вселенной Да ну так как это инцидент то нам нужно срочно купировать проблему Да Нам нужно что пользователи не страдали копируем значится что мы сделали мы пропали Медиа бриджи так чтобы они при старте периодически спрашивали А я как бы всё ещё там правильный правильный под коци или уже нет И если нет то они просто выключали но так сказать Можем ли мы рекомендовать это делать всегда так сказать во всех деплой когда важно там хотя бы ну конечно нет в кобе уже давно об этом подумали есть которые проблему решают которые Никогда там из конфигурации не поднимут лишних подов Вот то есть вкратце что делать то есть нужно следить за сие Discovery в которых наши контейнеры регистрируются и вот здесь это важно да отдавать себе отчёт что вот xmpp чатик и IP там туннелирование это тоже Discovery Вот если бы мы это поняли Раньше у нас не было бы этого инцидента вот а чтобы так сказать с такими проблемами не сталкиваться феты пара ссылок по этой теме тоже поделюсь соответственно все ссылочки есть интерес Ну это конечно Гугли в конце доклада можно забрать зам Мы закончили с трем Надеюсь Мы закончили с разминкой тоже погнали погнали чет смотреть Вот ещё раз Про Медиа сервера То есть сегодня мы говорим про компоненты у которых стоит состояние которое надо как-то меть которые Нельзя терять и мы поговорим прой то есть оказывается эти сервера тоже надо обновлять и если их обновить состоятся с как считаем и надо что-то делать то есть надо хотя бы запланировать апдейты так чтобы не афек пользователей Нельзя просто кануть ВТА и что делать Ну у нас есть к счастью логи по которым можно потренироваться то есть не обязательно тренироваться на живых пользователях на продакшене можно взять логи там старых подключений и посмотреть как наши политики подходят которые мы считаем а е у на есть полис дата вот их считать есть дет вот если не ошибаюсь поправьте ЕС не прав 15 минут по-моему в квартал Да что такое ОК Как считать в случае инцидента берём количество пользователей пострадавших умножаем на время которое они страдали норми на общее количество пользователей таким образом получаем там суммируем девятки считаем минут еник так не делает поэтому есть механизмы вот того жесть где-то за 15 секунд юзеры переключатся на резервный шарт Ну и при этом мы считаем дата только для пользователей которые реально пострадали если они к тому времени уже ушли то ладно они нам не интересны вот мы пробовали обойтись этим и согласовывать какие-то политики раскатки иманда счастлива была мы не могли катану в Прайм Time в рабочее время наши Медиа сервера вот Ну естественно есть способ лучше Можно например это является на самом деле Бест практи в мире там видео конференс связи и там впа для G для stateful вводить Грейс Грейс периоды в течение которых сервера перестают принимать новые конференции но дают старым добежать Вот и если например там взять час то там большинство конференций не в час ну у ко длиннее Вот и старм к этому вопросу бюджеты вводим чтобы не весь кластер выводить из-под нагрузки а там маленькими кусочками то есть максимум там д там или нодов Окей значится есть логи можем продевать процесс деплоя Ну всего-то там на питон 2000 строк нормально справимся Ну справимся нормально вот Единственное надо понимать как при этом моделировании новые сервера там gits выбирают Вот и gits выбирает новые сервера Она смотрит на самом деле на их нагрузку и выбирает самый менее нагруженный внутри одного кластера А вот в глобальном так сказать масштабе между кластерами Ну там есть политики но с точки зрения вот этой задачи этого доклада предположим что это трендом случайно Ну и Давайте теперь по выбираем политику у нас на одной чаше какая Вот значи бдт их надо подбирать чтобы на другой чаше весов получить там счастливых юзеров и счастливую команду operations чтобы не катать ВТА и получать там негативные отзывы и ректы постоянные а делать это достаточно вот Единственное давайте смоделируем что истье Т очевидно мы это обсуждали что асы хотят Вот работать днм да они не хотят ночных шрифтов насчёт юзеров не настолько Понятно Вот как по мерить части пользователя но давайте обратимся к нашей модели инцидентов и будем считать первое что приходит в голову рестарт каждого пода меер инцидентом значи берм Тулу которая на вход логи Берт на вход политики берёт и на выход нам даёт сколько это всё займёт И сколько мы тайма на получали попробуем пш бюджет 2% й пед час Ну в принципе ну большинство же встреч укладывается в час да ну укладывается Ну за исключением конечно но укладываются и начинаем считать получаем 2 дня не счастливо потому что раскатка - это очень чувствительная операция нужно так сказать следить за приборами во время всей раскатки не Да бов что пойдёт не так Ну езеро залам и посмотрим Ну как бы вот часа может не хватить Давайте четыре поставим Грей период то есть будем ждать 4 часа пока люди уйдут с Медиа сервера закончат свои встречи перед тем как его катать получаем длительность раскатки 3 дня то есть если раньше о были несчастливы то сейчас они совсем несчастливы будут нас бить Вот но интересно что интересно что юзеры по нашей модели тоже менее счастливы Почему 4 часа Кому не хватает Вот оказывается в чём дело оказывается Вот на Нижнем графике у нас график количество пользователей одновременно в телемост на Верхнем графике производная там роста нашего дайма То есть если большое значение на Верхнем графике то сильно раст датам в это время ничего Когда у нас мало пользователей и кто-то сидит Там он мог там забыть закрыть свой клиент там или не знаю ну короче длинная Сессия у него э и он он такой один ночью то мы его одного покон неклик торых мы реконнект потому что остальных мало э и вот это кон контури интуитивный эффект соответственно мы пошли э обсуждать это с нашим продукт унем Техо унем э и пришли к выводу что ну вообще датам по там модели инцидентов Это не совсем честно для раскатово во-первых пользователям не важно пользователям важно чтобы их не реконнект А как бы им не важно сколько ещё пользователей страдает во-вторых нам не важно потому что мы улучшаем систему не от сервера к серверу мы улучшаем систему от недели к неделе от месяца к месяцу вот поэтому давайте для целей раскладки моделировать всё-таки собирать абсолютное количество юзер секунд которые пострадали никакого ми и что у нас получается Ну конечно абсолютного я не могу сказать потому что но могу например сказать долю от общей выборки и 5 на 10 мину п пользователей у нас пострадали при держав бюджете 4% г в периоде час и длительность получалась о день Ну что Норм норм Ну конечно не норм Да потому что ночью ВС насы работают Вот Но зато у нас по ночам перестали офек длинные аномальные сессии Ну давайте поиграемся немного с Грейс периодом То есть если его меньше до 30 минут Ну там некоторые же встреч укладываются получится как бы уок в принципе длительность 12 часов то есть поставив Асам пиццу и это и доброго пиэма пригласив Ну можно договорится Да вот ну юзеры страдают в два раза больше там было пять теперь 10 мип доля 15 минут г период Аллилуйя 7 часов уложились в рабочий день Это победа непонятно правда Победа ли это для осов потому что как бы пиццу будем теперь ставить но тем не менее но юзеры опять в два раза больше страдают было 5 18 теперь вот 51 теперь 18 видите у на есть теперь количественные Аргументы и костные подс сколько нам дополнительного железа чтобы укладываться в ээ наши м э ограничение по тайму для юзеров Вот немного сумарин эту главу то есть мы учимся это всё ещё Work in Progress выбирать политику деплоя Медиа серверов по логам плановый деплой считать инцидентом э Я теперь уверен что это ошибка вот плановый плой - Это не совсем инцидент по крайней мере так сказать нельзя подбирать такие короткие окна этого инцидента э вот насчёт пиццы для асов вопрос открыт Тулой кому интересно Если у вас похожая проблематика то можем поделиться она доступна на гитхабе и в конце доклада будет QR код чтобы забрать слайды вот доклад ещё оценить можно э а мы заканчиваем с нашими историями из жизни одного р Как мыли туда встраивается вот ссылочки по докладу И если мы парадигмы какие-то нарушаем или делаем не так или что-то сво придумываем то нужно просчитывать самим Сегодня я прис вам кейса не не стойте стойте ещё не до прин сейчас до принесу вот значится мы обсудили цепочки интеграций с вами и как система там всяких оркестратор моделей могут нам помочь значится Мы обсудили балансировку там наших stateful сесии в несколько слоёв и как это может привести к раздвоении обсудили эти система Discovery в облаках там Если кто-то ещё хохочет поднять проди Там xmpp чатик и пообщаться Подумайте как это будет дружить с остальными системами Discovery и мы учимся строить деплоймент сервиса по логам на этом мои кейсы Всё если у вас свои кейсы есть набросить то набрасывайтесь Я Дима некрылов Спасибо супрематическая матрёшка тайм и время вопросов то ради чего мы собираемся на конференцию и первый вопрос из дальней части зала прошу Дмитрий здравствуйте Спасибо за доклад А мы можем вернуться на слайд где был менеджер который деды менеджер который плот шарды в начале был но не шарды А эти деплой который ходит и проверяет по кругу что они работают так а можете Напомнить главу в которой это было в самой первой вроде самое первое Сейчас посмотрим вот говорят это есть люди которые в 300 ам умеют нажимать кнопки очень быстро вот сейчас посмотрим это киберкотлет это не про нас вово про дизай это стоит вот это вот чуть дальше во не не вперёд наоборот оп папа ещё ещё ещё ещё ещё вот который как раз бродкаст проверяет менеджер короче который пробки делает Окей я сейчас да да вово вово а по сути он из себя представляет классический reconciliation loop правильно Ну естественно Да когда мы говорим про Recon loop у них есть классические проблемы в первую очередь это когда мы Ну про жор ресурсов Я опущу это понятно самая главная проблема когда у него достаточно ну он работает классических три шага get get App так да Вопрос как боролись с тем что когда у него очень большой жирный стейт он начинает просто Ну у него же есть тайм-ауты проверки и он может просто не успеть за этот таймаут прожить всё то что ему выдал как с этим боролись Ну то есть условно есть там 000 трансляций один тоненький сервер который должен всех обойти вот отвечу в данном кесе мы с этим Потому что так сказать в Один в один сервис в один т это в принципе вле вот насчёт другого применения этого же паттерна вот по-моему пока что доклад в программу не принят вот мы решили отказаться от так сказать ограничения на то что таска может выполня только в один поток нам сте нам значительно упростить систему и ускорить перформанс ответил вот детали можно будет обсудить В кулуарах Напоминаю что у тебя два подарка поэтому Записывай все вопросы Следующий вопрос из левой части зала прошу Дмитрий Добрый день меня зовут Максим вопрос больше по пользовательской части вы сказали что пользователи были недовольны когда их переподключается на другие контейнеры вы как-то это оценивали со стороны пользователей или может быть можно было сократить время реконнект например чтобы там не за 15 секунд их пере подключали там за 3 секунды например и пользователи будут довольны тогда да а а отличный вопрос э так сказать Э на самом деле время так сказать гладкость экспириенс пользователей и это основной источник наших требований э и это был не единственный проект по улучшению там гладкости экспириенс то есть естественно мы учились в более простых случаях э либо вообще там как-то по-тихому переподключается например к Медиа а только к сигнали там всякие подписки на уведомление либо делать Это значительно быстрее э вот но с точки зрения этой модели ээ можно её усложнить и добавить что там не 15 секунд а там зависит от количества пользователей всё такое и статистику э но 15 секунд - это такая экспертная оценка которая позволит нам посчитать и сравнить разные стратегии Так а у нас есть пара вопросов из Telegram и Напоминаю что супрематическая матрёшка может отправиться любому нашему гостю в онлайн мы его найдём и отправим коробочку вопрос от Игоря как реализована безопасность соединения в закрытых конференциях телемоста безопасность соединения значится Помните я говорил что есть два так сказать слона на которых держится ВКС это соответственно Силинг и Медин там с безопасностью всё Ну в принципе Понятно Потому что мы по хттпс по веб сокету вссу дошли значится Кэн у нас там шифрованный на каждом этом самом на каждом хопе и проходим Security аудиты так сказать Бандеры знают что ну как бы процесс в принципе поставили на поток касательно Медиа э касательно Медиа значится мы пользуемся webrtc то есть ну вот именно Чем отличается webrtc от вапа это тем что VIC подразумевает п по дизайну там нельзя от него отказаться даже если Р хочет там нельзя отказаться если там разработчик хочет п будет и соответственно согласуя ключи по безопасным каналам и используя мы убеждаемся что так сказать соединения у нас безопасные Следующий вопрос от твой докладывает чтобы стать и ты довольно много рассказал про проблемы телемоста про развитие телемоста А вот можешь кратко сформулировать какие именно ключевые штуки влияли на его клау Насть так Какие ключевые вот из того что ты рассказывал Ты довольно много всего Рассказывал Ну значится он был Вполне себе Cloud наверное на старте когда у него была маленькая аудитория и мы не знали то есть мы применили Бест практис и всё стало хорошо вот но доклад он именно о том что так сказать в процессе роста эти компоненты оказалось что проблема глубже что если делать кастомные компоненты и дизайни их с нуля то так сказать возникают такие интересные кейсы что давайте это самое Давайте пере приглашать пользователей назад Вот могли знать на старте могли Могли сделать там полностью Cloud нев могли Вот и соответственно git Ну как бы вот если я в своей компании 100 человек условно хочу развернуть ВКС Я поднимаю джитси там покупаю тачку там компьютер за сколько-то тысяч рублей Э на нём поднимаю решение э работает работает обновляю ночью Да никто не замечает Вот а если мы хотим на весь мир то мы не можем просто так взять даже ночью там люди будут им пользоваться Следующий вопрос левая часть зала Дим Спасибо за доклад интересные кейсы Я если честно помню твой предыдущий вот этот доклад из которого ты кадр вставил Поэтому будем наверно ждать из следующих серий тоже А вопрос Ну который наверно не был раскрыт ни в одном кейсе У вас же явно есть какая-то фрагментация клиентских приложений Да вы не можете влиять на пользователя чтобы он там всегда обновлял клиент Как это влияет на архитектурное решение что люди могут сидеть на старых клиентах и им ВС ещё нужно пользоваться и работать отличный вопрос Андрей Не забывай я Всё записываю значится и вправду Мы очень любим мы вот как бы н Мы очень любим потому что они Обновили страничку у них всегда последняя версия вот по и Моби Мы тоже всем сердцем любим Но них обновление дольше и приходится поддерживать там вот несколько месяцев иногда может быть и год там старых клиентов то есть нам изменения в протоколе нужно вносить аккуратно чтобы у них там новые фичи может и не появлялись но старые не ломались Вот вот да да то есть мы видим по мониторингом сколько у нас там клиентов на старой версии и поддерживаем их Следующий вопрос из Средней правой части зала Да Дмитрий добрый де Меня зовут алее те уточкой смотрите у вас поднимаются поды под определённой там сессию ли моста Да но вы же ведь по идее знаете логи знаете нагрузку в день и так далее и тому подобное Вы можете по идее предиктивной сразу несколько подов для того чтобы ваши пользователи как раз могли обойти вот тот случай когда эти поды у вас там выделил под одно имя там несколько и так далее тому подобное То есть у вас уже заранее будет подготовленная среда Почему этим не воспользовались это раз и второе Когда у вас Фантом Почему вы не воспользовались тоже этой ситуацией для того чтобы решить проблему как раз именно деплоя когда у вас допустим есть Старый образ Да пода вот рядышком поднимается Новый образ пода Они между собой там допустим зацепляется и просто напросто часть клиентов потихонечку начинает переезжать на новый под как только там все уехали с этого пода он закрывается всё образа нету прекрасно здесь Новый образ и мы во-первых Ну как бы теряем датам и всё проходит очень гладко отличный вопрос Спасибо значится Можно ли сделать так чтобы сессия телемоста конференция жила не на одном медиасервер Веру в процессе раскатки вот на самом деле в случае с можно это технология называется Окта она у нас используется Вот соответственно чуть позже так сказать мы начали её опробовать после решения вот этой проблемы и у нас есть положительный опыт так сказать Я не могу сейчас поделиться статистикой к этому надо пойти посмотреть вот как бывший Телеком могу сказать что не решает проблема только е немножко отсрочивать то есть вместо одного пода проблемы будут случаться с двумя подами или с того что не всех успели мигрировать или того что под мигнул во время миграции и так далее плюс такие технологии добавляют новый уровень сложности когда вот у нас есть как Като миграция в процессе и в процессе этой миграции тоже сюрприз сюрприз много чего может пойти не так и вот без многопортовый себе ещё кучу проблем Так что это скорее перфоманс история Когда у нас вот одна уже не может тянуть Там много-много тысяч человек в конференции мы начинаем их объединять чтобы просто было больше Кати потому что только ради надёжности удобства пользователя это не то чтобы выигрышная ситуация так Ну что отдаём соматическую маку голосуем за доклад Так давайте 3Д о аплодисменты спикеру и сейчас будем раздавать подарки в начале идёт подарок от Яндекса кому вручаем вот значит что счастье пользователя так сказать в течение 15 секунд кае ри уния Что именно там Cloud native в докладе про хвосты обновлений и миграция сессий ребят все вопросы классные актуальные вот хочу за последний вопрос вот просто приз моих там не зрительских Да но моих симпатий от Яндекса Спасибо большое за вопрос про ла миграцию там на два вот этих медиасервер лай миграцию и два сервера иди выходи на сцену выходи выходи к нам специальный секретный приз от Яндекса и кому идёт супрематическая матрёшка и книга и соответственно второй вопрос об который было действительно сломано много копий на в процессе улучшения производительности вот это вот штуки которую мы на трансляциях начали это про Rec loop Изначально и соответственно про частоту запросов Как улучшить производительность Это был первый вопрос гость конференции задав вопрос приглашается на сну и обретает ука для этой супрематический"
}