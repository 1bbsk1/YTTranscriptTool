{
  "video_id": "0nwfK-WAWQE",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Я Павел Я хочу сегодня рассказать вам Зачем азон нам понадобилось написать Аж целый свой н grpc клиент для нагрузочного тестирования И как мы это сделали представлюсь Я ведущий разработчик платформы нагрузочного тестирования ра быстро люблю спускаться на уровень батиков вылезать в бинарные протоколы и в общем-то в команде Я занимаюсь тем что создаю генераторы нагрузки и создаю систему сбора трафика для целей нагрузочного тестирования Ну и в целом занимаюсь архитектурой платформы нагрузочного тестирования мой доклад делится на две части первая часть зачем я расскажу зачем мы влезли в такие дебры зачем мы начали писать свой целый клиент а вторая будет про то как мы это сделали Итак немного тезисов про нагрузочное тестирование в Ozone у меня будет совсем коротко подробно вот по QR коду есть доклад Ивана Иван сидит здесь Он рассказал всё супер подробно тезисы мы нагружая сервисы прямо на проде И это не страшно потому что у нас есть система автонов но врем в принципе безопасно для намы собираем трафик днм воспроизводили частотой ночью наш основной протокол взаимодействия это межсервисный язык разработки основной это генераторы нагрузки мы плом прямо в курне ежедневного нагрузочного тестирования а ещ У нас есть клиентская балансировка ещ один занимательный факт У нас есть сервисы которые выдерживают до 1 милна ПС я к этому сервису в течение доклада буду часто возвращаться и назовём его сервис X в Пите мы плом порядка подов с генераторами нагрузки ну и соответственно исходя из вышесказанного чтобы для того чтобы нагрузить весь наш Озон нам не потребовался ещё один дата-центр нам нужно чтобы генераторы нагрузки были максимально эффективными чтобы наше руководство тратила деньги не на железки А нам на премии Ну и как грамотные специалисты мы первым делом делаем что идём на рынок и смотрим Какие решения доступны для использования то есть чтобы не пилить свою в обм воспользоваться готовым и примерно такие решения мы видим на рынке в общем-то если вернуться к нашему сервису X Ну то есть разброс от 5 до 14000 ПС если ограничить генераторы нагрузки по CPU зажать их и в общем-то чтобы нагрузить имы нам путём нехитрых подсчётов нужно аж 143 CPU и на наш взгляд это очень много Мы хотим быстрее Как мы можем это сделать Ну Мы заметили что большинство генераторов которые имеются на рынке jpc проба сообщения реализуют в ран тайме то есть в момент подачи нагрузки происходит сериализация сообщения Ну и возникает идея Что будет если отказаться от сериализации Давайте попробуем от неё отказаться и в общем-то это супер просто нам нужно всего лишь реализовать кодек кодек который не делает ничего то есть на вход онни принимает интерфейс за которым скрывается слай с и мы просто и отдаём дальше мы этот кок регистрируем и в общем-то подаём нагрузку в цикле Ну всё это упрощённой генераторах чуть посложнее но суть и что из этого у нас получается и в общем-то таким нехитрым способом мы начали опережать рынок и в общем-то это был наш дефолтный генератор нагрузки пару лет назад он работал именно так но чтобы нагрузить наш целевой сервис X всё равно нужно h83 CPU что снова в общем-то Ну приемлемо но хочется быстрее Хочется ещё меньше тратить вычислительных ресурсов на генератор нагрузки начинаем думать куда мы упирался размер этого grpc запроса байти которые уходят по сети всего 60 байт если перемножить на наш rps который мы смогли достигнуть это по мегабайта в секунду очевидно мы не упирается в сеть куда же мы упирается в общем-то все помнят знают что grpc в качестве транспорта используют П2 Почему бы нам в нашем исследовании не выйти за рамки наших ограничений за рамки вот рынка grpc генераторов нагрузки не посмотреть А что там на нам могут предложить П2 генераторы и в общем-то берём первый попавшийся генератор нагрузки которым все генераторы нагрузки включая наш без сериализации по сравнению с ним смотрится бледно и в общем-то Мы хотим также хотим в общем-то на двух CPU выдавать такие же псы 500.000 ПС и тут мы приближаемся к главе номер два Как мы можем это сделать Как мы можем прийти к этому как нам написать свой генератор который будет работать на таких порядках первое что нам нужно сделать это из аббревиатуры grpc выкинуть rpc что это как это что что я тут надумал в чём проблема что такое rpc rpc - Это с одной стороны в одном сервисе процедурка В другом сервисе процедурка и между ними происходит магия происходит сериализация отправка Ну и с на вызывающей стороне процедурка блокируется на время пока мы не получим ответ И в чём же здесь проблема а проблема в том что на больших rps нам нужно порождать каждую секунду умы горун Ну то есть условно у нас Мы генерируем нагрузку в 10.000 РПС нам нужно каждую секунду порождать 10.000 рутин и завершать это и в общем-то горутины - это штука легковес быстрая Ну все мы знаем эти мы знаем чем они хороши но но при таких частых порождения и завершения горун шелера не хватает честности его не хватает и некоторые горутины зависают в состоянии тин дополнительное время Что приводит к не смогли Ну не пробудили она у нас осталась в состоянии йн дополнительное время соответственно мы зарегистрировали Рен та завышенный вот и в общем-то у меня в рассказе в презентации Это всего лишь один слайд Но это было самое сложное то есть для того чтобы это сделать нам пришлось закопает 2 научиться делать свои клиенты и сделать свой клиент Итого мы выкидываем rpc выкидываем в общем-то Вот эту вот парадигму и работаем с tcp сокетом какво вывод не порождаем никаких рутин То есть у нас на tcp там парочку на одно соединение дальше я вам расскажу про генератор нагрузки про его принципиальную схему самый обычный не сценарный генератор нагрузки выглядит следующим образом мы читаем Файлик запросами как-то его прогоняем через вре логику то есть преобразуем его каким-то образом сохраняем состояние в хранилище Ну как минимум нам нужно запомнить когда запрос уйдёт в сеть чтобы посчитать время ответа в общем-то записываем запрос в сеть и у нас есть поток выполнения противоположной Мы из сети ответы читаем во внутренней логике находим Ну преобразуем обрабатываем находим в хранилище состояния Превращаем его как-то добавляем статус полученный там и в завершени запроса когда он на завершился складываем полученную полученные метрики в отчётность и Сейчас я расскажу про каждый из этих этап что этапов и что мы можем здесь в этом этапе сделать чтобы ускорить процесс генерации нагрузки первый этап это чтение запросов из файла с запросами самый очевидный подход который приходит в голову - это читать сразу кучу запросов большой буфер и потом копировать их в отдельные буферы и в общем-то Ну это логично то есть по одному запросу читать из файлика Это не очень хорошо потому что запросы jpc они обычно маленькие и это приведёт уколов поэтому логично большой буфер но в чём здесь проблема Проблема здесь в копировании и аллокации памяти то есть нам для каждого запроса нужно память аллоцировать а также копирование тоже штука не быстрая вот поэтому в идеале вот этот процесс хотелось бы видеть следующим образом у нас есть пул с с буферами под запрос то есть причём они пере используются после того как запрос отправился в сеть память возвращается в пул и не нужно её заново выделять и хотелось бы чтобы у нас за один сил мы эти сразу несколько буферов наполнили и в общем-то Это реализуемо причём реализуемо достаточно просто для этого всего лишь нужно пару вещей Первое - это файл запросами определённой структуры картой то есть мы должны знать наперёд где и какой запрос искать а Для этого нам нужна индексная картка скажем перед каждой тысяче запросов мы добавляем индекс карту с длинами этих запросов то есть после того как мы эту индекс карту вычитали мы знаем где искать Каждый запрос и второе что нам нужно - это использовать CV что Он позволяет Он позволяет за один сил читать сразу данные сразу в нескольких буферов то есть мы раз и за один сил вычитали сразу четыре запроса скажем вот движемся дальше запись сеть что мы можем здесь сделать здесь я должен отвлечься и немножко прикоснуться к спе хттп 2 совсем коротенько спека длинная интересная но я о ней чуть-чуть основная суно а взаимодействие клиента и сервера по хттп 2 - это фрейм фрейм м в фрейме можно выделить две большие сущности это заголовок и payload заголовок светленький Pay жёлтенький заголовок тоже делится на составные части Но на них мы Останавливаться не будем а вот так вот выглядит э grpc запрос э на уровне байти то есть э в сеть улетает фрейм с хедера затем фрейм данными э причём сообщение имеет некий префикс с длиной и в ответ нам прилетают снова фрейм с хедера фрейм с данными и снова фй с хедера А И у нас есть некоторая структур куда мы уже вычитали байти из файлика то есть вот поле ББ имеет байти вычитай из файлика и э ещ имеем служебный буфер который нам понадобится чтобы ну об этом дальше нам в общем-то имея следующее нужно из того что мы вычитали из файлика получить то что мы отправим в сеточку причём сделать это максимально быстро и эффективно Как мы можем это сделать мы берём и из бло и служебного буфера пум создания ссылок не выделяя новую не совершая копирование формируем тот набор байти который должен уйти в сеть делаем ссылочку 9 байт Надер фрейма затем ссылочку на мету которую мы вычитали из файла запросами на имя меты назначение меты и вот у нас так таким образом примерно Получается нький рейдерами примерно таким же способом мы формируем и хедер с данными то есть хедер фрейма фрейм с данными префикс сообщения о котором я упоминал ранее непосредственно ссылочка на само сообщение и это получается у нас фрейм с данными А и на выходе это выглядит вот так вот то есть это куча ссылок на уже выделенную память э вот и соответственно если мы последовательно эти э буферы отправим в сеть то у нас в результате получится собранный полноценный grpc запрос дальше Ну то есть вот это набор чанков у нас Мы за год эти чанки складываем в очередь и знаем когда нам каждый из этих чанков отпра нужно отправить в сеть скажем вот первые че чанка впер миллисекунду после начала подачи нагрузки следущие несколько чанков Во вторую миллисекунду и так далее что мы можем оптимизировать здесь мы можем здесь сократить количество си сколов вот как мы можем это сделать Ну то есть в идеале мы хоп и сразу кучу чанков одним си сколом отправили в tcp и Чем больше тем в общем-то лучше Вот с другой стороны Чем больше тем со стороны сервера нагрузка будет более дискретный но в общем-то если этот интервал достаточно небольшой то со стороны сервера это и не будет заметно Это во-первых во-вторых стандартные клиенты так или иначе имеют механизмы бачин запросов то есть не реализация grpc при высоком потоке запросов может тоже бачить запросы и в общем-то тут мы профиль нагрузки этим не поломаем особенно если период времени для бачин будет не очень большой и это всё А в общем-то в для реализации этой штуки используется абстракция QR код на документацию в уголку и это в общем-то всё хорошо если у количество соединени не очень болье Тода можем бать если нам нужно смоделировать скажем тысячу клиентов или там десятки тысяч то это уже перестаёт работать то есть поток запросов размазывается по нескольким клиентам и батчинг уже не не случается что мы здесь можем предпринять э в идеале бы эта картина выглядела следующим образом чтобы у нас была очередь одна общая на все tcp соединение и с вместе с каждым чанко лежало как свойство времени когда мы его должны отправить в сеть так и файловый дескриптор Куда нам нужно его сложить и в общем-то это всё реализуемо и в ядре линуса есть аж целых два системных интерфейса которые нам позволяют это реализовать это м системный интерфейс IO и eo uring вот мы это ещё не реализовали но в ближайшее время намерены попробовать и питаем Большие Надежды что в нашем случае он даст некоторый бу Следующее о чём я хочу поговорить это штука под названием что это такое в принципе в чём проблема Проблема в том что для скорое на которых работает CP время необходимое длям ку это очень-очень долго то есть CPU простаивает много циклов до до того как система выделит Память из кучи и в общем-то очевидная очевидный способ оптимизации - это избегать лишних выделении памяти из кучи и как это можно сделать в нашем случае в нашем случае мы можем в общем-то память переиспользовать та же самая память под запрос мы можем её просто по кругу гонять то есть мы прочитали из файлика сделали сетап создали кучу чанков отправили эти чанки в сеть и ресетнуть также и с состоянием запроса то есть после того как мы получили ответ нам эта память уже больше не потребуется мы можем её вернуть в пул и дальше переиспользовать и в общем-то сверху вы видите бенчмарк Гош Если вы видите такие же Циферки в своём бенчмарке то есть на операцию в среднем но байт выделено и то в общем-то это вы достигли дальше чтение чтение байти ков и сети что можно оптимизировать здесь как это мы видим в идеале нам нужно байти из сети Вычитать и как-то их отпросить и было бы классно их вмэ проса ли два буфера в первый буфер мы читаем второй просим как только первый вычитали второй от просили меняем их местами во второй читаем первый процесс и вот в общем такая Карусель следующее отчётность в отчётности что мы можем попти Зро и поско квантили показват пока ти 200 миллисекунд это значит что 5% запросов имеют время ответа больше 200 миллисекунд и в общем-то подсчёт их э штука достаточно тривиальная Но если подходить в лоб то для её решения нам нужно времена ответа сложить в списочек в некоторый и на наших объёмах нашего сервиса который выживает см ЕС мы его наем в течение оно часа получается списочек в 3 милда позиций что очень много что можно сделать здесь и тут к счастью за нас уже всё придумали имеется работа по научная работа по потоковом подсчёте квантилей и в общем-то Наги куча реализации как это можно сделать забираем лю библиотеку и ВМ снизу бенчмарк то есть сверху решение в лоб потребовалось 5 Гб чтобы посчитать снизу решение используя с использованием библиотеки всего 2 МБ Ну и быстрее в общем-то э далее хранилище что в нём в общем-то нам нужно где-то хранить состояние состояние запроса и э для этого удобно использовать мапу мапу нужно защитить ксом то есть одновременная запись и чтения из мап это нельзя в чём проблема при больших ПС Мы очень много параллельно читаем и пишем в эту мапу И часто у нас один из потоков ожидает завершение работы с МАПО другого потока и на больших рпх это могут быть большие времена и как можно это решить тут всё ещ проще Вот мне кажется тут ответ супе очевиден шардирование Когда у нас и читающая рутина и пишущая рутина конкурирует за доступ в одну мапу сокращается в 36 раз Ну и в общем-то мем показывает как мы выбираем ключ для шардирование Итого мы отказались от сериализации данных отказались от rpc в слове grpc минимизировать рутины Везде где это возможно миними пото кванти диро хранилище у нас получилось и в общем-то мы смогли выйти на показатели сравнимые с H2 с с тем что с с нами сравнивать конечно не стоит потому что это П2 но наши показатели нас удовлетворяют Ну и к тому же у нас ещё есть пара точек роста которые закрыв которые мы возможно догоним А то и перегоним H2 который ша тают энжин но ну опять-таки возвращаясь к нашему сервису X теперь нам нужно чтобы его нагрузить всего лишь каких-то ше CPU Ну и в общем-то теперь в Пике нам требуется всего лишь для того ООН все наши сервисы которые проходят регулярную процесс регулярного нагрузочного тестирования всего каких-то 2300 CP Вот и на этом Казалось бы всё но нет Я тут с гостинцем скажем так наш проект сегодняшнего дня вот буквально сегодня Пару часов назад я его опубликовал инст экране там Пока Спасибо там пока одна звёздочка её поставила Моя бабуля Она сказала что будет любить меня даже если я вернусь и у меня будет по-прежнему одна звёздочка но давайте сделаем чтобы Моя бабуля мной гордилась накидай немножечко Пожалуйста а дальше есть ещё что рассказать что мы хотим сделать ещё ну то есть мы на этом не остановимся это в общем-то наш большой продукт мы его Будем двигать расширять запись фреймов чом несколько tcp соединений Об этом я говорил ранее это ещё не реализовано но в ближайшее время мы об этом Ну мы попробуем это сделать оптимизировать формат файла с запросами там есть на чемп в общем-то мы ждм ещ больший бу в этом отношении хотим сделать свою реализацию А - это система кодирования хеде в хттп 2 и в общем-то стандартная Гош ная но она неплохая но она медленная супер медленная Ну как бы для обычных приложений её скорости более чем но в общем-то нам нужно оптимизировать все горячие пути это что касается оптимизации по фича больше вариантов отчётности Мы хотим например добавить возможность чтобы отчёт можно было закинуть сразу в кликхаус в общем-то куда угодно Ну то есть любые ваши хотелки больше вариантов линга чтобы можно было сложные варианты расписаний создавать расширяемость например чтобы можно было заинжектить стратегию для генерации херов с токенами если у вас внутри организации некоторая авторизация происходит хедера авторизации и упростить установку опубликоваться в доке опубликоваться в home вот ну и в общем-то я приглашаю ыть иус приглашаю участвовать в разработке в общем-то просто пользоваться с удовольствием приносить мне обратную связь чтобы я там придумывать для меня фичи чтобы я Вам их сдела Вот Ну а с вами Ну тут я заканчиваю своё выступление и в общем-то возвращаю слово вот ну и в общем-то про вопросики Да да спасибо большое вот знаешь хочется за такой проект отдельно на камеру пожать руку поблагодарить тебя очень очень круто прям большая работа проделана спасибо а Но перед тем как перейти к вопросам А хочется поблагодарить ещё и тех кто помогает делать эту конференцию и такой масштабной и такой крутой да это наши же партнёры конечно это мир пфм это это р мир пфм это Газпромбанк это на самом деле много-много других партнёров и генеральный партнёр МТС который разрабатывает вообще цифровую экосистему кучу различных у них продуктов Вот спасибо им тоже Большое похлопайте пожалуйста и перейдём к завершающей части этого дня официальной к нашим вопросам и ответам пожалуйста начинаем вот из центра я ещё добавить хочу что у меня у меня кроме всех ещё от себя подарочек небольшой для за самый диковский вопрос от меня будет никовская клавиатура которую я спаял сам вот всего подарков будет три а Первый от онтика второй от компании озон и третий лично а от Павла от Павла Поехали Да привет Спасибо за доклад очень круто вопрос Следующий Вот ты рассказывал про какие-то оптимизация со стороны именно клиента Вот Но при этом при повышенном ПС у нас всё равно остаётся задача стерилизации там которая довольно CPU то же самое время на сервере соответственно там тот же самый Тулин Там те же самые шные декодеры соответственно задача Тяжеловес серс начать ролить Гош начинает тупить повышаться на Дулин собственно это можете повышать НН коррелирует собственно rps которую может са сер давать ну потому что такая относительно саморегулируемая история вот как такая проблема решалась была ли вообще решена Какие подходы Ну во время разработки в общем-то у меня такой проблемы не было для в общем-то моделировани нагрузки я взял свой генератор нагрузочного тестирования и просто вывернул на изнанку получи супербыстрый сервер и в общем-то на него У нас ну есть планы продать и как-нибудь его использовать например как как сервер для кэша например то будет быстро то есть вот а с точки зрения реальных клиентов Ну это реальная проблема Да и в общем-то Ну как бы но в общем-то к счастью не мне её решать как-то так понял спасибо Так давайте вот рука сразу следующая я ещё напомню что вопросы для наших онлайн зрителей напомню что вопросы можно писать в Telegram чате в чат зала мы их тоже зачитаю и ответим Да спасибо большое за доклад вот есть пара вопросов СШ идей как это можно чуть-чуть поду улучшить Вот вы не речи в сторону userspace сокетов вот я где-то 8 лет назад слышал доклад про трейдингом какую-то такую систему К сожалению я уже мало что вспомню но суть в общем в том чтобы сокеты перенести из л спейса перенести в users Space И вообще минимизировать какие-либо копирования и второе - это прокомментируйте где у вас происходит tls termination потому что http2 формально поддерживает итек Хотя не везде он реализован ну в начну со второго вопроса э-э пока что поддерживается только текст Ну то есть tls в проекте Пока нет Вот но э Добавить его должно быть несложно э но в общем-то э у меня есть опасение что используя tls Мы весь Профит из криптографии потеряем потому что криптография - это ну супер дорого вот поэтому Ну мы мы наверное добавим когда-то но Ну посмотрим что получится из этого но есть опасение что это нас уронит к производительности остальных решений на рынке вот что касается юзер сокетов мне такую идею подкидывать Вот и в общем-то поверхностный глш какого-то ответа мне не дано упоминал системный интерфейс eo uring и он в общем-то отчасти работает примерно так же это возможно что-то с родни то есть в userspace экспортируются некоторые буферы которые можно наполнять и отправлять ядру сигнал и ядро эти буферы заберёт и само всё сделает вот возможно это что-то похожее Вот но детально глубоко не погружался этот вопрос не совсем Это скорее всей драйвер который работает прямо всё равно вам надоть ядро Ну ладно я постараюсь найти спасибо да спасибо за вопрос Давайте вот с левой стороны зала Привет Э спасибо за классный доклад У меня вопрос такого плана собираетесь ли вы завозить в свой инструмент Да дело в том что когда Ну в обычном сценарии тред обстреливает соединение тестируемого сервиса обычно при больших нагрузках он начинает замедляться И тем самым это немножко противоречит тому как ведёт себя под реально боевой наруко Коре восо она не утихает в связи с тем что ПС начинает расти Ну например такие стратегии там при подсчёте отчётов реализовано таких инструментов как врк или врк плюс Будет ли у вас что-то подобное Ну я вот честно говоря мне стыдно оголить своё пробелы в знаниях но я впервые встречаюсь и в общем-то такую проблему мы ещ Не решали но в общем-то Спасибо что посвети я обязательно погружная её решить 100% Спасибо Спасибо Давайте дальше Из третьего ряда и потом вот рядом с камерой Ага спасибо большое за доклад очень классный вопрос есть два вопроса Первый про то как планируется делать Вот из дальнейших улучшений там была запись несколько tcp соединений одним силом то есть это планируется делать через там cmsg или через который вроде как позволяет бачить несколько Силов планировалось именно Ирин попробовать и второй вопрос в докладе ещё ну где-то посередине доклада было про то что планируется Арин это вот именно для этого для бачин Силов или для какой-то асинхронно дополнительной или для чего есть насколько изменится производительность если мы к нам в проект затянем этот системный интерфейс то есть изменится она в большую сторону Если да то в общем-то замечательно использовать её а не придётся ли её как-нибудь интегрировать с Гош дуром или может быть они как-то будут противоречить потому что в Гош уже же есть какая-то асинхронность И шилинг относительно запись там нужно просто наполнять некоторые буферы и в общем-то сообщать ядру что буферы можно забирать и раскидывать по файловым дескриптора вот насколько мне известно не должно быть проблем Спасибо так вот рядом с камерой Следующий вопрос Спасибо за доклад было очень интересно с метрики и соответственно потребление цпу и вс такое Если будем использовать в сервисах не обычные jpc запросы а прям по головно везде стримы так ещё раз в со стороны сервисов мы меняем вместо запросов стримы на стримы и это касается нашего продукта то есть мы обстреливает Как изменится потребление Ну в общем-то у нас режим нагрузки по стримам использовался и но там было ограничение что поддерживались только сервер Сай стримы то есть мы отправляем одно сообщение и собираем сообщение до того как сервер Стрим завершит и это вот общем для стримов Мы и Ну мы пытались за них взяться но у нас была проблема о том как считать метрики что считать респонс тайм то есть вот вот тут вот есть проблема Ну то есть мы можем это сделать реализовать но непонятна ценность для конечного пользователя с точки зрения производительности со стороны генераторов нагрузки Ну как будто каких-то провалов сильных производительности мы не видели Ну да то есть там нужно в хранилище какое-то дополнительное время держать состояние запроса то есть нам то есть память нужно держать подольше но в общем-то это никогда не было узким местом у нас и поэтому в общем-то Ну да потребление памяти Чутка увеличится не не кардинально понял спасибо Так давайте вот с другой стороны Да в синем с синей ленточкой да Да приветствую У меня вопрос вроде простой или сложный а Правильно ли я понял что это самый быстрый grpc генератор нагрузки который есть на рынке в целом Да так то есть из тех с кем мы сравнивали мы обходим всех на порядке то есть быстрее никого нет в стеке jpc но есть ещ hp2 это H А что нужно Чтобы обогнать ещё и его H2 Да ну в общем-то как я говорил у нас есть идейки и в общем-то о некоторых из них касался то есть Апа свою реализацию сделать бачить записи в общем-то Вот и вот и всё вот мы Мы надеемся что это ещё кардинально нас ускорит и мы ещё ближе приблизиться а может быть и перегоним Вот спасибо спасибо за вопрос так вот в первом ряду был я сейчас микрофон передам свой Спасибо большое за доклад такой вопрос я правильно понимаю с помощью вашего инструмента я могу аккуратно обстрелять и получить lcy диаграммы Независимо меняя число одновременных открываются Ирей который я в эти соединения отправляю Ну сейчас реализовано только константное число соединений то есть оно в течение жизни не меняется то есть мы условно 100 соединений подняли и да да имеется в виду через аргументы не нужно внутри одного теста то есть я могу обстреливать там начиная там с тысячи завади планах имеется план иметь возможность их количество ccp соединений менять в течение подачи нагрузки это несложно Вот просто мы спешили принести готовый продукт и кое-что пришлось подрезать Я хотел спросить я через аргументы могу менять это число независимо от того количества запросов которые распределяются по этим откры верно то есть скажем 100 tcp соединений и мы можем разбрасывать там 1000 на эти Извините быстрый комментарий нас Вы посмотрите именно для высоких перн это эта штука даёт максимальную ошибку вернее не учёт То есть это не в целом как бы такая проблема которая перед всеми стрелялками стоит а именно если вы смотрите очень аккуратно на центили там именно ко К сожалению очень сильно смещает все рас Спасибо В первую очередь гляну что это такое и как мы можем это решить так Следующий вопрос Давайте поднимаем руку Вот спасибо Павел за доклад было очень интересно но час на буквально твой коллега тоже Ильяс про балансировку как раз рассказывал и первый наверно вопрос я так понимаю сейчас каких-то страте балансировки Ува то что мы вытащили в паблик но в общем-то очень хороший вопрос и внутри то есть мы этот продукт уже какое-то время используем в нутри нашей организации и ну единственное для доклада для выступления мы его Оли прили немножечко ускорили е больше чтобы у Нае графики получились но балансировки там нет никакой мы её оставили у себя Вот баланси Но её можно я рассказывал про расширяемость и ещё одним аспектом расширяемость будет и планируется возможности внедрения своей балансировки то есть вот у вас есть какая-то стратегия балансировки уникальная для вашего решения и будет скорее всего инструкция как её заинжектить и в общем-то использовать вместе с нашим продуктом вот внутри Мы в общем-то именно так инжекте и используем нашу в общем-то кастомную балансировку спасибо как раз Ну второй вопрос был про это как обеспечить именно консистентность стратегии балансировки на тесте с тем что есть на проди Ну ты уже ответил Спасибо друзья у нас Время ещё есть на пару вопросов вот пожалуйста Ну да очень хорошо и доступно так доклад было в целом я вот хотела уточнить Ну получается вот эта утилита Она позволяет увеличить количество Ну запросов с учётом ограничения соединений количество соединений но как-то в рамках как будто всегда справлялись и с Ну как бы количеством соединений максимальным и получается Всё равно ж сервер к которому идут тесты Ну к которому идут запросы он ну имеет какое-то ограничение все равно даже вот какой-то там клиент Ну там миллиард запросов в 100 коннекшн как будто это не поможет серверу быть быстрее как бы и у показатели нагрузочного тестирования Ну всё так немножко поправлю у нас в общем-то цель была мочь подать максимальную нагрузку используя минимальное количество ресурсов и Да это в общем-то никак не поможет серверу быть быстрее чтобы серверу быть быстрее это нужно производить доработки со стороны сервера наш продукт и наша це выявить и показать что вот в таких вариантах использования сервер работает несколько медленнее и тут нужно Вот в общем-то внести какие-то изменения подправить в общем-то Ну мы Не решали эту проблему это немножко не Наша задача Так давайте последний вопрос и ты помнишь все давай послушаем последний будем разбираться походу Спасибо за доклад Павел а очень интересно Меня зовут Максим а у меня вопрос Вот вы сказали что нагрузочные тесты запускаются каждый день ежедневно А результат разбирается автоматически но я имею в виду какие-то Диф Ну и отчёты или Ну условно каждое утро люди смотрят какие-то отчёты и смотрят что-то произошло ухудшились улучшились показатели но какие-то такие метрики агрегированные да как я говорил я в общем-то ведущий программист платформы нагрузочного тестирования и в общем-то кроме генераторов нагрузки в нашей платформе имеется система аналитики То есть у нас ну то есть у нас это очень сложная штука мы эти генераторы нагрузки пло в отчёты из этих генераторов нагрузки складываются в систему которая их закидывает в некий агрегатор который из нескольких инстан сов Ну то есть у нас несколько дата-центров соответственно Крос DC трафик Гонять не очень хорошо мы генераторы нагрузки подсед дата-центр отчётность с каждого из этих генераторов нагрузки собираем в агрегатор этот агрегатор складывает их в проект который занимается в общем-то отчётностью и в общем-то в этом задача этого проекта уже предоставить удобный юзер интерфейс чтобы пользователь зашёл там посмотрел как менялось его э результаты нагрузочного тестирования его сервиса с течением времени то есть условно вчера так такие результаты были сегодня такие результаты были есть система сбора трафика чтобы пользователь не занимался тем чтобы придумывал профили нагрузки а просто собрали трафик и запустили То есть у нас огромен ная такая система и генератор нагрузки Это всего лишь горошинка в ней вот Спасибо у нас время на вопросы закончилось кому будет прямо интересно в глубину копнуть Можете зайти на github поставить звёздочку и посмотреть как это устроено и попытать Павла в дискуссионной зоне Ну а нам с тобой нужно ещё одну задачу большую решить с чего хочешь начать с гиков вопроса вопросов обычных Ну я мне запомнился Вопрос вот от мужчины который оголил мои пробелы в знаниях вот мы спросим у мужчины как зовут Дима Дима клавиатура или от вас от нас Матрёшка Вопрос такой это всегда на самом деле приятно когда подсвечивают что-то чего мы ещё не знаем куда мы не копали Да это Зона для развития Спасибо большое Давай подарок от азон А тут вот у меня вообще всё А Поднимите руки кто задавал вопросы пожалуйста Да вот мужчина вот в третьем ряду Да всё подарок от озона а Наверное от вас как Как зовут От от нас вас хорошо матрёшка тогда как зовут Никита я вижу отсюда А ну тогда то зон Это значит что очень большой вклад вносишь в развитие сообщества помогаешь вот людям на какие-то мысли их наталкивает Давай Последний подарок Вот ещё раз поднимите пожалуйста кто ещё не получил подарок руки вот мужчина мне чем-то запомнился В пятом ряду да да да да Супер на этом мы наверное заканчиваем почти заканчиваем у нас а для тебя подарок тоже есть за ну реально очень очень крутая работа прямо на завершение дня мне кажется это очень приятно было послушать такой доклад и о таком крутом инструменте Спасибо тебе большое с"
}