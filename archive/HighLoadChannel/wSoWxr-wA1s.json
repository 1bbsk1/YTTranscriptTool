{
  "video_id": "wSoWxr-wA1s",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "работаю в ВК Cloud руковожу там инфраструктурной Разработка и в общем-то этот доклад будет построен как раз-таки от лица инфраструктурной разработки Да мы Чем занимаемся мы строим различные решения которые нужны под облаком это програмно определяемые сети программно определяемые хранилища и другие решения также в не совсем рабочие время я ещё живу в опенсорс контрибьютор и ещё раз подсвет этот доклад будет со стороны инфраструктурной разработки мы ставим перед собой несколько целей Мы хотим чтобы наша разработка шла быстро Мы хотим чёткие понятные итерации чтобы у нас был Дофамин к от их закрытия спринтов наших любимых Да и вообще понятно как жить дальше-то при этом мы хотим чтобы эксплуатация системы была на самом деле полностью автоматической чтобы нам не нужна была большая Орда людей которые в общем-то ходят и что-то там делают Ну и в конечном итоге мы руководствуемся принципами построения архитектуры по принципу дизайна на отказ то есть система должна уметь переживать любой возможный сбой и проблему то есть обладать Так называемым селф хилинга давайте начнём с простого примера на самом деле большинство из клиентов наверняка когда-то захотят Отлично А у нас будет слайды Спасибо наверняка каждый из клиентов когда-то захочет воспользоваться такой услугой как создание контейнера Что такое контейнер это какое-то CPU под ним конечно же мы должны как-то это вычислять это внем имы Тим сходить в интернетик сходить в соседний контейнер через сеть ну и плюс какой-то сторож Мы хотим наши данные которые мы вычислили куда-то положить Давайте попробуем построить из этого сервис для начала Нам нужен хотя бы один сервер на котором будет минимум опика Да которая будет в начале получать давайте я буду рассказывать если будет мигать или что ори я буду останавливаться для за в общем-то сущности Да Нам нужно создать пожалуйста новый контейнер То есть клиент опишет имя контейнера какую-то медан плюс Он положит данные для варота то есть мы в контейнере хотим всё-таки наше по настроить как-то дальше нам нужно этот контейнер где-то запустить Давайте например возьмём Dod наверняка многие известны и он в общем-то обеспечит как раз запуск контейнера на линуксом Хосте подключит сеть подключит и вс остальное Даше в какой-то хочет полисти А что же он создал а посмотреть Да достаточно ли этого и пока что мы будем ходить к сожалению в dockerd забирать оттуда эту информацию плюс-минус это в общем-то реализуемо но есть очень важный момент мы облако большое Да отлично мы облако большое И на самом деле мы всегда будем трекать а какой же клиент к нам обратился Чья же сущность создаётся Чья же сущность листи по этой причине нам это где-то надо хранить мы теоретически можем это хранить где-то в dockerd или похожим Но это будет минимум неудобно максимум нам потребуется этот код править Так что давайте просто возьмём базу данных поставим её рядом и будем хранить информацию про этот контейнер нам будет очень удобно хранить там в общем-то всю информацию о нём и таким образом у нас будет очень приятный бонус нам больше не надо ходить в dockerd как в источник Правды и в источник истины Да и мы можем работать напрямую с базой А dockerd в конечном итоге заменить когда он нам не понадобится либо что-то написать своё что-то более удобное из этого идёт очень большой плюс приятный у нас система Вот Обязательно появится А я пока расскажу у нас система делится на два куска это Ctrl Plan То есть это управляющий кусок Где у вас Ну куда клиент обращается у вас работает там вся бизнес логика ваши хитрые бизнес сценарии биллинг всё что угодно и второй кусок - это dat Plan То есть это кусок где непосредственно байти бегают и ваши контейнеры работают да за счёт этого мы можем их очень чётко отделить dockerd он здесь в общем-то Как пример уже исчезает там может быть что угодно на самом деле это очень удобная схема для нас дальше в такой схеме за состоянием мы уже будем ходить непосредственно базу и это очень удобно Очень хорошо полистилистика отдельно то есть наша пишка наш редж но на сервере должно же всё-таки что-то существовать чтобы им управлять То есть у нас Появляется какой-то Агент No Агент мы так его и назовём да и им он будет управлять дата пном но нам надо ему ещё как-то доставлять информацию соответственно мы добавляем опишет пушим Когда что-то происходит какое-то событие например на создании сущности Вот примерно такой же запрос как он выглядел от клиента мы можем отправить на сервер только уже из Ctrl пна из управляемый нами сущности Да абстрагировать О'кей мы масштабируемых с любовью носим на руках как домашнее любимое наше животное Да но на масштабах конечно же у нас Ой извиняюсь на масштабах в первую очередь важно уметь шеду виться то есть нагрузка вот у нас есть много серверов на самом деле Многие из них могут быть уже заняты соответственно нам надо уметь определять А какой из этих серверов ещё свободен и куда можно поселить новую нагрузку в такой ситуации шедулер это выглядит как вот Отдельно ещё компоненти как квадратик Но на самом деле мы тут решаем многими любимую задачу упаковки эффективно рюкзака То есть это прямо отдельная тема для следующих разов Да мы дошли до шеринга по-настоящему вот у нас теперь очень много серверов и как домашние животные гладить и холить леть мы уже не готовы соответственно вспоминаем про подход cattle vsp То есть это домашнее животное против стадо и когда серверов у нас много очевидно это больше похоже на стадо соответственно мы должны относиться к каждому серверу как к расходному материалу он к сожалению когда-то сервер наш умрёт в конечном итоге и тут у нас появляются чёткие интерфейсы нам нужно уметь стандартизированного вводить и выводить из кластера машины дальше мы уже упоминали что система у нас работает са многими клиентами тут появляется понятие мультитест то есть проектов у нас много Ключевая особенность мультитест най системы - это жёсткая изоляция сущности одного клиента от другого и в худшем случае вот например вы хотите соединить контейнеры одного клиента друг с другом через какую-то сущность под названием сеть контейнеры клиенты могут работать на всём вашем облаке и вот вот эта вот Клякса она на самом деле так в жизни выглядит сущности одного клиента размазаны ровным слоем по вашему облаку И к сожалению когда клиент захочет что-то изменить в этой одной сущности сеть вот он делает один Запроси Пожалуйста измени меня в этой сети там я не знаю подсеть что-то Ну адресацию что-либо ещё Да сейчас обязательно появится следующий слайд А дальше к сожалению этот э один Запроси клиента он перерождается в шторм запросов на нашу систему потому что эта сеть по факту у нас на всех образных серверах Да настроена и нам мы вынуждены идти и настраивать его на всех серверах А это ещё накладывается на то что серверов у нас много и у нас получается такой ад коннекто мы должны знать какой сервер где находится уметь доставить на них наш наши настройки и так далее тут хочется задаться вопросом а как бы свести вот это общение во что-то единое и удобное и первая мысль наверное не только мне приходит да Давайте попробуем брокер сообщений Ну то есть он позволит нам как-то общаться унифицированной системой в первую очередь его плюс плюс использования брокера сообщения что это единая точка единый Интерфейс Да то есть э серве клиент и сервер просто зарегистрировались в нём и в общем-то мы живём хорошо тут появляется важная сущность обычно мы говорим про событийные про событийный обмен то есть мы события кладём в какую-то очередь то есть мы её туда пушим потом клиент может подписаться то есть законсервировать сразу много клиентов То есть у нас может быть общение One to many это в общем-то весьма удобно Ну ещё один плюсик то что когда у нас нечего делать мы ничего не делаем мы экономим цеп это выглядит очень эффективно и удобно Давайте остановимся поподробнее на таком понятии как ивент который только что появилось Да это событие то есть что-то произошло у событие обычно есть его тип либо он кладётся в конкретную очередь например событие создать новый контейнер Ну то есть создаётся новый контейнер также у него есть какая-то полезная нагрузка поло То есть это имя контейнер Ну вот вся та информация которую клиент передал с оговоркой что информация от клиента может быть на самом деле очень большой и в одно событие оно может не уместиться и в данной схеме у нас появляется компоненты ве брокер в общем-то выбираем его на наш вкус какой нам лучше подходит сервера идут на него регистрируются и у нас получается такой вот примерно однонаправленное общение то что сервер зарегистрировался он косми сообщения ивенты и вроде всё хорошо на самом деле схема весьма Рабочая у неё есть очень много плюсов она весьма интересна но мы должны в любой архитектуре говорить о том а как она умеет ошибки и давайте рассмотрим банальный пример Мы хотим создать контейнер вот у нас пришёл на сервер Event Create контейнер и возникает ошибка у нас кончилось место на этом сервере очень жизненная ситуация скажу я вам да это когда-либо произойдёт К сожалению некоторые события обработать мы не в способность Когда у нас кончилось место Ну тут уже совсем что-то плохо пошло да событий конечно же бывает очень большое количество например ну есть события которые мы на самом деле можем потрать например То есть если у нас есть запрос ходящий по http мы Ну трам скорее всего поможет и всё будет хорошо есть очень много других кейсов там отказ очереди недоступность и так далее То есть мы уже видим что ошибок может быть очень большое количество и нам по факту надо уметь их все обрабатывать А как это можно сделать Да самый очевидный вариант Ну проблема с авента Давайте его дропнется создать юзер Ну отлично это не вариант вообще второй вариант Давайте её попробовать вечно Ну там относительно вечно трать да но это тоже в общем-то не вариант потому что мы очень быстро приходим к ситуации когда мы ретра одну сущность у нас там клок растёт там тысячи миллионы уже Ну нельзя так жить и поэтому мы приходим к в общем-то третьему варианту это иметь ещё одну какую-то очередь куда мы кладём событие которые мы не смогли отработать не очень приятно Но к сожалению жизненно Также нельзя забывать про то что мы пользуемся какой-то Ну брокером сообщений к сожалению у него есть нюансы Какие гарантии даёт по доставке сообщений он может либо вам давать не очень хорошие гарантии про доставку самого сообщения про гарантию доставки либо он может на этом кейсе дублировать то есть тоже классическая ситуации Вы должны это учитывать и уметь работать со своей очередью давайте рассмотрим кейс более интересный вот с конкретными ошибками в коде мы разобрались примерно понимаем как с ними жить да но к сожалению отказать может полностью компонент то есть ваша AP ваш дап он к сожалению Может просто крашнуть и вам надо что-то с этим делать но это даже не самый худший случай дальше всё в общем-то раскручивается как в комедии диски летят вообще постоянно это каждодневная проблема на масштабах и память да то же самое в общем-то заряженная Космическая частица прилетела выбила вам битик бит Флип так называемый произошёл всё приехали ец не всегда от этого спасает и в конечном итоге тот же CPU тоже дохнет и это мы ещё другие компоненты не потрогать Да диски как-то тоже подключаются к системе у вас может быть контроллер либо что-то ещ иток система может быть не консистентной состоянии то есть в лучшем случае она просто умерла и вы знаете этот факт да тако такой бинарная логика Да в худшем случае у вас состояние системы какое-то промежуточное и с этим надо что-то делать Ну давайте на примере рассмотрим у нас должно было быть два контейнера с какими-то настройками по факту у нас на сервере сейчас живёт один контейнер недо настроенный и нам надо написать бизнес логику которая ну которая что-то с этим сделает и как-то приведёт её к нужному нам состоянию по факту мын должны иметь механизм который сможет нам это сделать на самом деле есть ещё очень интересный кейс Это ввод нового сервера к нам в кластер по факту сервер новый он для нас тоже в неизвестном для нас состоянии с оговорками и эти два события можно в общем-то схлопнуть в один единственный механизм так называемого Бут стран э нового сервера или системы да то есть первоначальные настройки Вы можете в некон систентки мы с сервера должны как-то узнать А что же должно было быть настроено мы идём из сервера в Control Plane и спрашиваем А какие у нас как контейнеры то должны были быть нам отвечают вроде всё успешно и мы делаем нашу работу если всё получилось всё прекрасно мы восстановились всё отлично но тут есть очень важный момент Вы могли обратить внимание что мы уже ходим и в другую сторону тоже То есть у нас уже шина получается двунаправленный по сути мы делаем подобие rpc процедур у кол с сервера на Control Plane и у этого К сожалению есть очень много проблем Ну примеры таких сообщений то есть мы можем запросить информацию о конкретном контейнере потому что информация не могла могла не поместиться в само событии мы могли запросить все контейнеры вот как на предыдущем примере есть более частные случаи которые обязательно появятся на слайде да это сделать хабит этому серверу То есть он же должен сообщить что он ещё жив Да какие-то ещё другие вещи например добавление в кластер либо в конечном итоге тот самый пример когда у нас кончилось Свободное пространство на сервере Он точно уже не может ничего сделать но надеемся он может Послать сообщение о том что слушайте у меня тут совсем уже всё плохо сделать с этим что-нибудь Давайте посмотрим на ситуацию чуть выше вот у нас есть какой-то проблемный сервер что-то с ним происходит первый важный момент что мы не можем гарантировать работоспособность сущности клиента соответственно мы должны его контейнеры по факту отселить на другие рабочие сервера и тут как часто это бывает на накладывается ответственность ещё и за То есть он начинает Заниматься тем что о переносит эту нагрузку тоже И тут интересный кейс который называется идеальный шторм То есть когда у вас начинает отказывать не только один сервер а что-то сильно больше Например у вас ушла целая стойка по сети например да И она недоступна либо частично доступно иногда отвечает что-то Да и вроде у нас есть этот механизм под названием res он что идёт Что делает идёт переселят наши сущности на рабочие сервера и всё вроде продолжает работать очень интересный момент что это работает пока у вас есть свободные ресурсы чтобы переселить ваши э контейнеры когда они заканчиваются вы не хотите чтобы шедулер шёл и переселяли их и напивался ты справишься а он упадёт К сожалению скорее всего из-за перегруза соответственно у решеду вера должен быть механизм так называемого стоп-крана то есть он должен понимать когда уже делать ничего не надо и стоит просто остановиться и дать всё-таки либо разобраться в системе либо начать селфи г так называемый если он есть в вашей системе И к сожалению вот у нас такая ситуация предположим вот час у нас не были доступны стойки решет для руке и понял что ему не надо ничего делать он их не трогал через час эти стойки возвращаются у них есть какое-то состояние может быть даже рабочее но проблема в том что за это время продолжительное клиент мог что-то изменить он удалял сущности он изменял их соответственно Нужно привести в актуальное состояние эти сервера а как это сделать Ну окей вспоминаем мы говорили проп который как раз позволяет нам это делать проблема в чём страп начинается у большинства ваших серверов в худшем случае у вообще всех серверов соответственно ваша шина данных которые вот мы принесли Она очень хорошо работала до этого у неё получается очень высокая нагрузка на неё которую мы даже не оценивали и не думали что она может произойти и это большая проблема тут происходит очень жизненная ситуация что к вам прибегают админы и говорят то что ребята у вас как-то кото так интересно написано что облако легло Мы вроде сеть подняли а что-то облако не не не воскрешает по кругу ходит-то делает нагрузка на брокер сообщения максимальная и вс Мы встали колом Что называется Да и вы соответственно на них смотрите Ну ребят Ну мы надеялись что вы всё-таки админы вот святы святынь что вы несёте на руках эту сеть Ну как так она у вас упала очередной раз да конечно это жизненная ситуация которую мы не хотим и не допускаем то есть мы должны системы разрабатывать так чтобы в таких ситуациях идеального шторма Мы тоже долж переживать по этой прине важно учитывать есть два кейса режи Ну два режима работы вашего брокера сообщения когда у него есть обычная стандартная нагрузка на что-то просто изменилось там какое-то событие пролетело и всё хорошо Да и второй кейс который почему-то не считается дефолтным Но на самом деле он является худшим вашим случаем да Когда у вас идёт Boot вообще всего облако если у вас тысячи сущности тысячи серверов да то это и тысячи нагрузка на вашу шину это очень много шины скорее всего не выдержат на самом деле Вот все вот эти вот архитектуры про которые мы сейчас говорили это невыдуманные специальные архитектуры под этот доклад или что-либо такое эфемерное по факту мы посмотрели на архитектуру верхнеуровнево такого решение как openstack Нейрон openstack - это такой опенсорс най комбайн который позволяет вам получить ваш облако прямо вот здесь вот на вашем железе это весьма удобно на самом деле и в любом облаке у вас должна решаться задача э подключение сети к вашим сущностям и sdn Нейтрон он как раз-таки это делает sdn - это программно определяемая сеть То есть он отвечает за то чтобы у каждого клиента изолирована была своя сеть чтобы он считал что это железо только его а не чего-либо ещё нетрон конечно же внутри устроен более хитро там есть события и много очень других компонентов тема очень интересная если вам интересно Мой коллега уже в девятнадцатом году аж в девятнадцатом году рассказывал про это вы можете посмотреть всегда очень рекомендую очень интересно потому что опыт К сожалению вы не видите Да сечас меня даже иногда не слышно что ли отлично красное утро У меня выдалась вот смотрите там закопано очень много лет человека человека лет и опыта Так что опыт в любом случае интересны и стоит того чтобы его изучить Давайте подведём итоги у нас получилась какая-то архитектура она весьма работает у неё есть очень классные плюсы да В первую очередь она ничего не делает когда ничего не надо делать это в общем-то очень хорошее свойство у нас единая точка общения это тоже очень удобно и сокращает администрирование ну и плюс вроде как плюс да то что чтобы разработать новый функционал вы пишете ещё одно событие которое тоже когда-то появится на экране и в общем-то Профит Но это же и является проблемой система в худшем случае вам нужно написать по событию на каждый чих проблема-то даже не в событии Проблема в том что логику обработки этого события вы в худшем случае размажет вообще на всю систему и на Control Plane и на dat Plane где-либо ещё Либо вы будете дописывать обработчик существующих событий То есть это весьма трудозатратно К сожалению и никто не отказывается от бустра То есть он в любом случае должен существовать потому что бутстрап - это отдельная сущность в данной архитектуре от неё просто никуда не денешься тут хочется задать вопросом а можно ли лучше как думаете хочется как-то всё-таки сделать хорошо мы разработчики мы оптимисты мы хотим идеальную архитектуру которая будет решать все наши проблемы и не иметь минусов Ну вот честно хочу да мечтаю реально ли Ну давайте подумаем Давайте попробуем критерии Да обозначить Какие Нас интересуют она должна быть ещ раз Дея это выгодно ещ раз не только потому что мы разработчики Нам всё хорошо спринты ВС такое это нужно ещ и бизнесу нашему с вами Да он должен понимать когда он получит результат За сколько за сколько человека ресурсов и так далее Это очень важно опять же мы должны уметь жить в ситуациях идеального шторма и переживать такие кейсы и ожидать чтобы сделать так чтобы нагрузка была ожидаемая на наше Системы ну и в конечном итоге эксплуатировать мы тоже хотим это без привлечения большого штата людей чтобы она была К сожалению как и вс в этом мире чем-то надо ради этого пожертвовать чтобы что-то купить надо что-то продать Да как Как в анекдоте и Давайте подумаем как это сделать тут я хочу рассказать вам про очень любимый мной принцип бритвы Ома когда когда Ну считается что лучший ответ - Это тот который наименее многословен там код это ненаписанный код Что это значит вот у вас есть требования к вашей системе Если вы можете его удовлетворить написав ноль строчек кода то это самый лучший ноль строчек кода который вы с удовольствием порев ите запушить в прот и так далее да И они будут вам вас радовать вечность и не давать проблем потому что бак в несуществующем коде Ну наверное Может быть но я не знаю Итак Давайте попробуем отсечь вот берём ту событий ную архитектуру к которой мы пришли и Давайте посмотрим А что здесь точно можно выбросить да то есть что у нас тут лишнее давайте от обратного что что здесь в любом случае не выбросим не выбросим отсюда мы Буран он в любом случае у нас в системе должен существовать мы всё равно должны уметь работать с сервером который только запустился и что-то в нём происходит Ну вот непонятное А вот всё остальное можно попробовать отбросить например ивенты Но как Только мы отбрасывая ивенты у нас в общем-то все остальные плюсы и минусы тоже отбрасываются потому что они и следовали именно из тех ивентов Давайте раскручивать дальше Да у нас есть bootstrap у него появляется обязательное требование он должен быть жёстко идемпотентный то есть неважно сколько миллионов раз мы его запустим неважно На каком проблемном оборудовании он должен нам дать один и тот же результат строго тут есть очень большой плюс так как bootstrap происходит не на не по команде клиента А по какой-то нашей логике то соответственно действие клиента теперь не равняется действию в Облаке и из этого есть маленький минус что да событие происходит теперь не сразу но теперь у нас управление идёт по сути декларативное Клиент говорит там только то что он хочет получить а не что облако должно сделать И это имеет очень большой набор своих плюсов также очень интересный момент что статус сущности в такой ситуации становится опциональный Потому что если мы гарантируем клиенту что вот за такой-то гарантированный срок твоя сущность обязательно будет создана там ну переведена в какой-то статус и так далее то в общем-то статус в общем-то не нужен и вот смотрите у нас получается ситуация что вот наш сервер он что теперь делает он постоянно по кругу начинает бу трапиться То есть он в наш получает всю информацию а что же ему надо создать получил её забрался и делает это ещ раз по кругу и в общем-то это весь интерфейс по большинству который должен быть между датам ипм То есть он даже звучит просто это просто одно предложение Да описани соответственно ваш интерфейс здесь он очень чёткий вы чётко разделяете это очень удобно но есть звёздочка сденм в общем-то это дополнительная работа в любом случает Хочу воспользоваться очень любимым многими разработчиками методом привнести ещё одну абстракцию очень удобная абстракция в лучшем случае она может точнее в самом простом случае она будет выглядеть как вот примерно четыре строчки что нам надо получить Ну вот Это пример вот из головы как можно просто сделать такой алгоритм мы получаем желаемое состояние системы из Control п это Target State мы получаем фактическое состояние сервера это Ой мы должны их в общем-то сравнить а потом из дифа мы поймём А что же надо сделать То есть что удалить что создать в переводе на псевдокод это будет в общем-то тоже четыре строчки где мы ну две сущности друг с другом сначала сравниваем одно с другим потом наоборот сравниваем получаем список к удалению и к созданию сущностей в общем-то на этом алгоритм Верхне уровневого всё тут есть момент что где-то конечно же сложность закопана здесь можно подумать что она закопана как раз-таки дифи сущности и их сравнении Да я вам приведу пример на питоне как это можно в общем-то дёшево и легко сделать делать У нас есть питон сеты это уникальное множество они строятся внутри на основе хэш маповская задача которую вы реализуете один раз и имеете Профит в нашей системе получается три основных компонента Это непосредственно система которой мы управляем это какой-то сенсор который умеет с неё собрать наш Таргет Act State и в общем-то контроллер где реализуется вся наша бизнес логика где всё происходит и он управляет Давайте пошагово пройдёмся Да мы получили Act State мы его передали в наш контроллер потом контроллер сходил в Control Plan вычитал фактическое желаемое состояние сравнил их понял что надо сделать и попробовал зать это изменение тут появляется очень интересное слово Rec коллеги поднимите пожалуста руки те кто до моего доклада сталкивался с этим словом нам ру это очень радует но руки вс-таки не все поняли Так что не зря этот доклад делаю Это тоже радует Давайте да тут смотрите - это очень интересное слово которое на русский в общем-то прямо переводится не очень удобно самое интересное слово - это примирить то есть система Ну наш контроллер идёт и пытается примирить нашу систему с тем что ну ей вс-таки надо быть в этом состоянии каком другом Давайте на примере рассмотрим у на есть умный чайним задать для е в общем стоит имеем нап мы его получаем смотрим Какая температура у нас сейчас понимаем разницу и либо добавляем мощности к нагревательному элементу Либо наоборот его уменьшаем соответственно получаем Профит система у которой есть закрытый у которой есть обратная связь называется замкнутым контуром управления если обратной связи нету это открытый либо разомкнутый контур тепер Давайте посмотрим же в такой системе обрабатывать инх Когда у нас есть новые событие о новом контейнере и мы его создаём и например ловим ошибку что место кончилось Да Первая Большая Разница в том что теперь у нас событие новый контейнер появился и создать его нету вообще у нас есть теперь единственное действие reconcile то есть привести систему к фактическому нужному нам состоянию не более то есть действие для реализации любо Ну то есть Нам нужно реализовать один раз рекон сайл всё к сожалению ошибки всё равно будут от них мы никуда не избавимся они всегда будут но здесь я хочу пойти на хитро и Для начала просто их зать вот так вот очень широко Да и записать влоги например тут вы можете посчитать меня как проф непригодного И зачем так делать и в общем-то легитимный вопрос но Давайте немножко раскрутим дальше мы говорили что система у нас работает инт в данной ситуации бун Да ошибки будут в любом случае так буп же можно попробовать ещё раз это есть й то есть Давайте делать это просто в цикле постоянно и в общем-то мы автоматически получаем на большинство возможных проблем Трай и у нас нету проблемы с какой-то застаиваться очередью с отложенной очередью и так далее тут есть важный момент что в какой-то ээ момент Извиняюсь за таталович проц просто так и Давайте добавим слип Ну то есть нечего нам делать Ну Поспали секундочку Между этим делом тут очень интересный вопрос А как правильно спать хватит ли нам слип один Достаточно ли этого или мы хотим что-то более интересное а не просто там вот раз в секунду мы что-то делаем но тема на самом деле очень глубокая и может быть даже для для отдельного доклада который мы ещё не сделали и Ключевое словов если вам интересно вы всегда можете его посмотреть Очень удобная штука многие вопросы снимают также у этой системы есть огромный плюс мы получаем несколько вариантов мониторинга которые вообще не зависят от бизнес логики первый очень простой У вас есть понятие как время сходимости вашего цикла то есть сколько ваш цикл работает бун да например он работает 5 секунд и Кле произошла ситуация что он начал работать 30 секунд То есть это Явный для нас сигнал что ребят Ну что-то не то происходит Да у нас со статистики выбивается либо у нас проблема с перформанс либо у нас баг какой-то при трам да либо что-либо ещё То есть можно посмотреть и второй кейс У нас есть количество сущностей которые мы каждый цикл создаём либо удаляем То есть изменяем если вы видите на графиках что вот количество сущностей превращается вот в такую планокур ровную то есть одно и то же количество сущности начинает создаваться удаляться да то это значит что у вас баг скорее всего то есть система Может их создать или удалить то есть что-то происходит не так мы просто идём разбираемся чиним всё проблемы нет опять же то есть абсолютно прозрачный мониторинг в этом месте На Кейс Ну то есть вы пишете новый демон Новый сервис и у вас автоматически есть уже базовый Мониторинг это очень удобно Давайте вернёмся к событийной архитектуре Вот она примерно вот так вот выглядела На чём мы остановились Да в случае когда мы говорим про архитектуру см первое отличие основное в том что у нас появляется внутренняя ошка в которую начинают ходить наши серверы за информацией о том же что им надо сделать и в общем-то у нас опять происходит очень удобное однонаправленное общение и нам нужно поддерживать только доступность одной точки это Internal App тут и плюс и минус соответственно мы можем прогнозировать нагрузку на неё и так далее на самом деле ВК Cloud мы руководствуемся этим принципом и делаем большинство наших продуктов Так что вот здесь вот в общем-то Верхне уровне представлена архитектура нашего СД личного Спрут в общем-то она чем-то похожа на Нейтрон Но вот в этом месте у нас Rec loop Это позволяет нам очень удешевить разработку и о многих проблемах Ну то есть какие-то частные ошибки которые в нетроне обрабатываются на каждый чих каждым частным случаем Мы просто не имеем их потому что reconciliation loop и rety Давайте поговорим о минусах такого подхода конечно же они есть да Но сначала надо поговорить А как же этот подход называется потому что проблема здесь в терминологии она называется по-разному минутка терминологии обычно Вы можете встретить эти вещи под названием cled либо Open loop то есть в переводе на русский это Замкнутый либо открытый контур управления и второй второе название оно более актуально для информационных технологий это Recon loop тот самый все эти термины на самом деле родом из теории автоматического управления и местами Они уже давно разобраны больше 50 лет назад и так далее начнём с плюсов конечно же у системы Есть плюсы с одной стороны она вас ограничивает по интерфейсам чётко как разработчика и бьёт по рукам Но с другой стороны наличие чётких интерфейсов это очень хорошо Да мы работаем постоянно по циклу Из этого же и плюса то что у нас по сути автоматически автоматический сехи мы просто каждый цикл проверяем Всё ли хорошо пришёл админ что-то изменил не больше так не работает оно автоматически поменяется обратно как логике логика написана ну и соответственно работа у нас постоянная то есть Ctrl Plan грузится идентично в любой момент времени В зависимости от количества сущности То есть вы можете чётко прогнозировать а как его масштабировать либо вниз либо вверх из этоже нейтраль моменты стран у нас здесь более требовательный мы должны его делать абсолютно честно плюс мы должны делать честные сенсоры про которые мы говорили ранее на самом деле в любой архитектуре это по-хорошему надо делать Просто в некоторых вам не нужно настолько качественно это делать сразу но всё равно вы к этому придёте Ну и второй момент да мы постоянно делаем работу из этого исходят нюансы Да у нас появляется такое понятие как время сходимости то есть время вот это вот время работы нашего цикла - Это то время в которое новые сущности вот созданы за время работы этого цикла созданы не будут но плюс они будут созданы в следующий цикл абсолютно все у нас нет понятия вот бэклога на работы Да мы всегда делаем всё это и плюс и минус Ну и делаем работу каждый цикл из этого очевидно что мы тратим цпу очень-очень много и сильно на серверах конечных на сравнение наших стейтон пна и как-то с ним поработать Да у нас изза этого получается заж на создание суно но она абсолютно понятна и трее то есть это кий на вашей системе вы понимаете За сколько секунд вам надо не выходить и так далее ну и момент что если вам всё-таки нужны статусы чтобы клиент понимал что происходит в системе их можно конечно же реализовать просто это уже в целом отчуждать рядышком хочется всё-таки получить идеальную архитектуру которой мы говори приходим вопросу можно вариант есть это те самые ивенты про которые я пол презентации говорил о том как от них избавиться И что же с этим делать тут вы закономерно можете покрутить у и сказать Георгий Ну ты что мы уже в цикл уходим мы сейчас это будем отказываться по кругу отказываться приносить их обратно и так далее тут я хочу поднять вопрос а можно ли вообще архитектуру делить на типы и хочу я посмотреть на это с точки зрения Вот таких вот двух градаций первая градация - Это стоимость разработки дешевле дороже вторая градация обратно пропорционально Я считаю это количество ресурсов которые вы должны вложить вашу систему ну ресурсов на которых она будет исполняться Да соответственно от дороже к дешевли Rec здесь логично находится с левой стороны он весьма дёшево к реализации но весьма дорог по железу событий напротив она весьма дешева по железу по крайней мере сначала То есть вы можете обработать каждый частный случай сделать по событию это будет на самом деле работать но вопрос в том что вы должны потратить на это ваши ресурсы Это очень дорого работ и тут вырисовывается вот та самая золотая середина посерединке Да можно ли её достичь вообще можно попробовать совместить и прикинуть что в общем-то Мы можем взять лучше от Rec потому что нам всё равно нужен от него мы никуда не денемся и попробовать оптимизировать как раз процесс Фания и получения информации с Колпна то есть мы можем зать либо кэш либо версион версионность нашей информации важный момент что версия не равна событию самом при х систем есть это тот самый кубернетес который я кликбейт вставил название этой презентации Потому что его контроллеры работают ровно по этому принципу любой контроллер - это reconciliation loop который в какой-то период должен уметь обработать вообще всё и привести состоянию к нормальному Да там есть оптимизации которые ускоряют эту работу но в общем-то кубернетес - это очень интересный пример такого подхода пора кажется подводить итоги всё начнём что Серебряной пули до сих пор не существует и кубернетес не исключение к сожалению Я надеюсь что мне удалось показать вам что подход с loop он с одной стороны накладывает какие-то ограничения изначально на вас то есть разработка в начале более строго с другой стороны Он позволяет за счёт этого много где удешевить процесс и заложи сразу на очень большое количество проблем автоматически от них просто открестился потому что Даже те же самые автор кубернетес они честно говорят что истина в эволюции систем то есть на на место кубернетес когда-то придёт следующий кубернетес который будет написан скорее всего не ими и кем-то и считаю что эволюция В разработке - Это очень важный момент мы должны быть готовы что наши системы будут переписана с нуля нами или не нами - это другой вопрос и тут я тоже хочу эволюционировать и попросить вас оставить обязательно фидбек о том что вам очень понравилось Либо наоборот очень не понравилось и о чём не стоит говорить в следующий на хайде Спасибо большое буду рад ответить на ваши комментарии ой на вопросы Спасибо огромное так Я уже вижу руки пожалуйста хэпер помогите с микрофоном прям много рук вижу Вот спасибо за классный доклад И на самом деле за спокойствие когда всё это мигалово обще отлично огонь Так микрофончик дадите вот здесь руки так и напоминаю пока ещё не начался первый вопрос Если вы слушаете нас в онлайне Пожалуйста задавайте вопросы если вы в зале но по каким причинам стесняетесь задавать вопросы Вы можете писать в чат я буду зачитывать Итак прошу я в зале немножко стесняюсь задавать вопрос Привет Георгий спасибо за доклад было очень интересно сначала небольшой комментарий и потом вопрос комментарий такой что действительно такие вот подходы имеют место быть мы тоже их но они хороши там где делает не очень много работы а где там нужно большой над большим количеством данных работать такой подход уже начинает носить проблемы нужно как-то шардирование Get config Get config и собственно вопрос А что поменялось дефолтный случай поменялся это Ключевое То есть когда ты работаешь в парадигме что у тебя getconfig - это норма И он происходит постоянно Ты просто на него рассчитываешь ты на него тестирует проверяешь К сожалению Когда вы работаете в режиме что вот у вас дефолтный случай когда всё спокойно и нагрузка минимальна обычно вы в тестах это начинаете либо упускать либо там ну О'кей там я человек там и у меня начинается какая-то лень иногда К сожалению да что вот этот кейс частный мы его там верим раз там в и времени в сиай Да а вот основной кейс чтобы оно работало там без нагрузки да А когда у вас основной кейс худший у вас очень многие проблемы уходят из-за этого супер Ну и вот проблема про которые ты говорил это я называю очень интересным челленджем Я хочу такой Хало и я мечтаю чтобы решить такие проблемы у нас и мы в общем-то с ними эффективно боремся плюс тут очень интересный момент ты нагрузку нуту тут появляется следующий некоторый момент например шардирование да то есть вот Мы заметили что у нас было очень много серверов на моих слайдах и многие нагрузки у нас специально размазаны то есть задача спустить работу как можно ниже и вы получаете очень классное размазывания пожалуйста вот вижу ещё руку так Спасибо за доклад У меня два связанных вопроса и они про то на вашей смет ны НУП и агенты которые реконт собственно вот эту сущность которую нам надо развернуть на машинах а общаются ли вот эти агенты между собой например в случае миграции каких-то сущностей с одной машины на другую и второй момент Каким образом решаются проблемы Сплит Брейна То есть если одна машина вдруг не имеет связанности с илем Ну СПМ и вторая тоже не имеет кто из них главный когда они вдруг появятся это на уровне котл плейна решается или они сами между собой должны договориться Спасибо смотри случай когда машины знают друг про друга и начинают общаться друг с другом на самом деле он такой очень чреватый местами хочется пойти в него Да он какие-то плюсы имеет но он имеет и большое количество минусов То есть пока вы можете позволить себе централизованно что-то делать часто лучше делать это централизованно на уровне Колпна и тут же и ответ на второй вопрос вытекает что машина здесь расходный материал сервер конкретно соответственно два сервера ушло даже если они связаны на уровне Контрол плейна Это задача Контрол плейна решить как отреагировать на их уход а Короп соответственно их скорее всего обоих не будет видеть и так далее да и он может на уровне например шедуле решить что пора развозить то есть конкретная машина в данной ситуации получает всегда конфиг только для себя вот в том и прелесть что ей не надо собирать информацию о соседях вот в событий это больно на самом деле бывает что вот особенно в сдх основная боль снов что у вас сущность размазана на сервера и вот от этого их и проблема вот мы с этим страдали мы от этого уходили я постарался рассказать про это супер спасибо большое вижу руку пожалуйста Сергей теньков очень интересный доклад Спасибо Вопрос такой на рынке уже есть Очень мощное решение для решения для задач автоматизации управления ресурсами именно в парадигме Rec loop это кубес там уже за вас решены все проблемы с шардирование с выбором ма собственные механизмы достаточно просто написать свои серди и контроллеры которые будут управлять вот не использовали ли вы кубернетес для этих целей например пристени сво Если нет то почему я можно начну немножко с другого конца А сколько Как много публичных облаков вы знаете основа которых кубернетес вот прям крупных масштабных на большое количество нот Я тут могу просто немножко ещё ответить вперёд то что вот автор кубернетес Google у Гугла Облако на кубернетес коллеги Ну я смотрите я не пытаюсь здесь говорить что кубернетес плохой я наоборот считаю его очень классным Мне очень нравится его интерфейсы и взаимодействия Колпна и дата пна там вот прямо есть очень Что посмотреть мне единственное Жалко что там вопрос отладки немножко они усложнили из-за того что там обязательно теперь но это тоже решаемо вот вопрос в том что с одной стороны Вы можете взять Готовое решение но вы на него завязывается тут вопрос что вы планируете с этим делать если вам прямо хватает функционала который он даёт в общем-то Да это хорошее решение мы хотим делать в частности новый функционал и делать масштабные решения то есть одна из наших проблем Мы делаем большие масштабы на которых осные решения просто перестают Ну то есть они не то что не заточены под это да но у них начинаются проблемы которые индивидуальны то есть тот же самый Open Да если смотрите как его используют обычно это всё вырождается в то что у каждого появляется свой форк который все внутри тащат Вот то же самое с кубиком боюсь произойдёт плюс важный момент кубернетес сеть например да Сам кубернетес проблемы сети за вас не решает то есть мы должны говорить про конкретное решение рядом с кубернетес который используя его очень классные пишки делают это за это вам работу да я тут из последнего могу сказать Не знаю Может кто-то знает Андрей валс очень классный товарищ он сейчас пытается делать Облако на куб вирте Вот как раз таки подход похожий на ваш и вот одно из че ну вот у него есть прекрасная статья на хаб где он говорит чётко что куб вирт всем считай подходит но то как он работает с сетью нам не подходит Так что давайте делать своё и вот такие нюансы они вот на масштабах и вылазят так есть ли у нас ещё вопросы вижу руку пожалуйста Георгий спасибо большое за доклад интересная тема опять-таки если просто уходить в практику то есть зачастую Ну люди используют кубернетес для всего этого да и используют для своих микросервисов которых много и возможно вы сталкивались с такой проблемой допустим когда Ну недостаточно какими-то или Ну пробами в общем востановить контейнер необходимо востановить общую логику то есть чтобы разные по сути поды они были перезагружен в определённом порядке например или у них какая-то логика между собой и хотелось бы вот наверное вот я сейчас просто думаю у нас быва бывают такие проблемы Когда возникает случаи когда необходимо Вот именно вот сначала один микросервис потом другой потом третий вот как бы вы решили бы эту проблему потому что я вижу что нам необходимо смотреть на состояние всей системы всех микросервисов и уже там предпринимать какие-то действия для их перезагрузки смотрите Сразу говорю что пример с контейнерами он здесь был привед как самый тако очевидный и понятные всем большинству Потому что есть очень много других кейсов облачных например наш основной кейс в первую очередь - это виртуализация потому что к сожалению контейнеры не совсем про изоляцию то есть любое публичное Облако на контейнерах по сути построено быть не может в принципе тот же самый Amazon avs Да вот классный пример у них есть эти лямбда функции по идее вот самое оно для для контейнеров быстро запустить и так далее что они сделали они запили максимально быстро запускаемые мки и живут в них уже вот это я извиняюсь немножко отошёл вопроса а-а Я живу немножко Вот на стека ниже Так что у меня прямо готового ответа для вас нет но здесь можно на самом деле о многом подумать мы в частности думали уже о таком подходе Когда у вас э состояние системы на самом деле э является таким оно не то что у вас есть слепок во времени во-первых а во-вторых у вас есть версионность с переходом состояния внутри и у нас есть определённые мысли именно на том о том как это на Control пне делать но мы пока в работе тут я сильно не расскажу можем наверное в кулуарах на эту тему ещё поболтать может что-то ещё расскажу Так ну что есть ли у нас ещё вопросы не вижу руки Ну тогда у меня главный вопрос к тебе Я знаю что у нас есть Два подарка один подарка от вас а от вашей компании второй подарок от Газпромнефть и нам нужно выбрать кому дарить Два подарка очень сложный выбор слушайте Ну первый хочу вот коллеги из крока потому что Да он это как наш коллега знает все боли и задаёт очень классные вопросы больные Да второй вопрос наверное ой второй подарочек хочу вот коллеге последнему потому что Да тоже больная тема которую мы хотим решать Ну то есть это вот как раз то о чём мы считаем тоже сделать не в рамках Вот таких вот составных решений что что-то сверху отдельно мониторить что-то снизу Да вот что-то более интересное составное спасибо супер Спасибо огромное Георгий Тебе тоже спасибо за очень интересный доклад за классную подготовку за а то как ты реагировал на технические сложности от лица онтика хотим тоже тебе подарить подарок спасибо Спасибо Спасибо благодарю коллеги Оцените Пожалуйста Обязательно всё что не понравилось всё что понравилось спасибо"
}