{
  "video_id": "Mmnzo1kpmDg",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "приглашаю следующего докладчика Дениса Антюх с Темой внедрения гигачад Лем виртуального ассистента Техническая реализация пожалуйста Спасибо всем привет Меня зовут Денис антихот про то как мы внедряли большую языковую модель чат в виртуального ассистента сбера и что у нас получилось и к чему это привело вот план доклада следующий расскажу сперва про то зачем мы вообще этим занимались Да расскажу о том с какими проблемами в первую очередь нам пришлось столкнуться расскажу примерно как происходит обработка запроса упрощённую диаграмму посмотрим некоторые нюансы обсудим про то как мы используем роли чтобы укротить генеративную модель Да и сделать её более управляемой и довольно подробно посмотрим на то как именно устроен наш промт с помощью которого мы добиваемся того о чём я сейчас буду рассказывать вот в конце будет немножко деталей про непосредственно обучение модели но не очень много вот ну для начала гат наверно вы знаете Это такая большая языковая модель похожая на по архитектуре она генеративная она мультимодальная мы её обучили и разработали в 2023 году ээ особенностью её является то что она заточена в первую очередь под русский язык 90% датасета на которых она обучалась была именно на русском языке всего 10% - это другие языки ээ что она умеет это в первую очередь разговаривать поддерживать диалог отвечать на вопросы Обычные такие opened фактологический задачи писать код генерировать картинки Ну в общем всё то что мы привыкли умеют делать большие языковые модели Ну и в целом мы понимаем что эта модель она как бы хорошо умеет в целом помогать пользователю Ну и тут естественно наша цель - это все вот эти вот возможности которые в общем-то постоянно добавляются Да так как развитие модели не стоит на месте постоянно добавляются новы новое обучение Мы хотим чтобы вот все эти возможности модели были доступны пользователям наших умных устройств и что важно Они должны быть доступны без какого-то специального там захода в навык кодового слово как это часто работает да чтобы включить там языковую модель Мы хотим чтобы это работало Как говорится нативно да то есть без каких-то дополнительных действий от пользователя все эти возможности они у него просто работали Вот почему это ну не тривиальная задача Да вообще Как устроены виртуальные ассистенты обычно обычный виртуальный ассистент - это множество таких сервисов каждый из которых умеет решать какую-нибудь полезную для пользователя задачу ну вот в случае с Допустим салютом мы умеем естественно там включать музыку видео включать делать перево и да подобно дест который его собственно умеет выполнять эти сервисы для простоты мы будем называть дальше навыками вот ну в общем для разных действий есть разные навыки сейчас в салюте больше 400 уже по-моему даже может быть больше 500 вот ну Суть в том что мы просто значит когда обычно ведём диалог мы запускаем некий машино обученый классификатор он понимает что запрос пользователь задал и выбирает Самый подходящий навык для выполнения задач соответственно в чём как бы заключается Челлендж Да у нас получается есть модель у которой есть большое количество таких неявных Да внутренних навыков которые в общем-то имплицитные да для для нас и есть целая куча внешних сервисов Да которые тоже в общем-то должны работать и мы должны вот эти вот две вещи как бы скомбинировать таким образом чтобы у нас во-первых не отвалились те навыки которые уже сечас работают потому что это было бы неправильно и с другой стороны у нас должны заработать те функции которые мы добавляем за счёт активации м непосредственно вот в этом собственно заключается основной Челлендж этой задачи и решаем мы её следующим образом значит подход называется to LM суть его заключается в том что мы учим непосредственно саму модель пользоваться внешними то есть мы имеем некоторое описание этих внешних сервисов с точки зрения API с точки зрения их функциональности понимаем что они умеют делать и соответственно модели даём эту информацию и она уже сама в процессе ведения диалога с пользователем выбирает те или иные навыки Ну опираясь в первую очередь на их описание Да текстово тут важно понять что описание оно написано на русском языке есть человеко читаемая веь для каждого навыка написано что он умеет делать и как его вызвать Да ну такой подход он довольно удобен для нас потому что он ничего не меняет с точки зрения интеграции для навыков да То есть им в общем-то ничего не надо делать со своей стороны чтобы как бы перейти на новый формат взаимодействия подключать новые навыки есть нам неза чтобы значит добавить десяток новых навыков в модель вот и что наверное немаловажно у нас появляется такой мощный фулбек то есть наша модель она если ни один навык не подходит нету его Да не разработали то она отвечает просто самостоятельно ээ причём для этого не нужна какая-то явная там не знаю корзина запросов или класс в классификаторе это работает Просто по принципу исключения ни один навык не подошёл значит отвечает модель вот ну вкратце так схематически посмотрим как устроена обработка запроса для вот такой схемы значит первым делом мы получаем новый запрос запускаем там всяческий пере процессинг исполняем наш классификатор который выделяет нам топк топ несколько наиболее подходящих навыков для текущего состояния диалога вот ну там ничего сложного не происходит Да это простой классификатор на традиционном уже сейчас трансформере не слишком большом работает он быстро и в общем его задача отдать топ-3 в котором значит будет с максимальной вероятностью самые подходящие навыки на втором этапе мы используем эту информацию чтобы сгенерировать промт в котором во-первых будет лежать состояние сессии во-вторых описание собственно навыков которые мы решили предложить модель на выбор Ну и всякие дополнительные метаданные для модели которые могли бы ей помочь более хорошо справиться с задаче выбора и вызова этих навыков на третьем этапе мы отправляем промт модель модель нам генерирует что-нибудь Да может сгенерировать вызов навыка или сгенерировать непосредственно ответ который этого вызова не будет содержать и наконец на четвёртом этапе Значит мы комбинируем результат вызова навыка ответ моде у нас получается уже итоговый ответ для пользователя Ну вот основные шаги схематично выглядят так скажу Пару слов про базовый классификатор Да собственно в его архитектуре Ничего необычного уже сейчас я думаю нет то есть это в основе своей двачер слойной кажется трансформер Да архитектура Роберта в НМ всего 300 млн параметров Вот и в общем-то он достаточно хорошо справляется с тем чтобы выдавать нам кандидатов Ну и тут опять же есть два варианта его обучить да то есть мы можем допустим обучать полностью трансформер Как говорится да тогда у нас соответственно обучается вся модель полностью и мы получаем максимально качество кото можно с можем захотеть сэкономить время да и при обучении классификатора на самом деле заморозить энкодер в этом случае у нас количество обучаемых параметров уменьшается на три порядка и таким образом мы можем обучать наш классификатор хоть каждые 10 минут настолько это быстро вот дополнительная быстрота она достигается за счёт того что у нас в случае когда заморожена голова заморожен собственно энкодер мы можем кэшировать динги для запросов Да из которых состоит обучающий датасет и таким образом ещё сильнее ускориться вот обучать модель ещё быстрее вот естественно когда мы обучаем только голову Да замороженным энкодером за это приходится обычно платить некоторым количеством точности да то есть за счёт того что у нас не обучается энкодер мы немного теряем но как выясняется не слишком много на самом деле да В первую очередь потому что энкодер уже на момент того когда мы начали учить он достаточно хорошо предоброе эффективных им бедин для предложений вот поэтому на самом деле потеря в качестве относительно варианта классификатора который обучается ту она не слишком большая Да вот видно что по F1 микро просадка ещё есть более-менее чувствительная Но что очень важно значит вот Топ 3 который отдаёт модель Он практически не меняется если мы там обучили end модель или если мы обучили замороженный энкодер вот так как в новой схеме значит модель всё равно получает топ и выраже изних или большого профита от более точного классификатора который Значит на первой позиции немного точнее работает он практически отсутствует потому что мы всё равно используем топ-3 А по Rec 3 Да мы видим что точность практически не отличается у двух классификаторов там статистически значимой разницы между ними нет поэтому на самом деле мы можем себе позволить чуть-чуть менее точный классификатор за счёт того что мы всё равно используем всех трёх кандидатов от модели которые есть и в общем-то Нет проблемы в потере топ-1 качества Вот ну как я уже сказал соответственно в процессе ведения диалога модель она решает две основные задачи для себя в первую очередь это ранжирование внешних навыков Вот и во вторую очередь если навыки внешние не подошли она берёт управление на себя и общается с пользователем полностью самостоятельно Вот это довольно разные функции и для удобства управления моделью мы их реализуем через две два отдельных таких режима работы модели каждый из которых привязан к конкретной роли Да роль это привязано всегда к какому-то конкретному специальному токену который вмте фигурирует и таким достаточно очевидным образом привязывает каже который генерирует модель к конкретной функции которая в данный момент исполняется Ну то есть иными словами классификатор сообщения для классификатора у нас всегда начинаются с classifier token сообщения для роли assist Assistant token вот сейчас объясню зачем это нужно Да ну в первую очередь расскажу про то что это за роли вообще такие значит роль класика - это дефолтная роль при которой работает модель и задача модели в этой роли соответственно заключается в том чтобы выбрать из ранжированного списка навыков один наиболее подходящий да то есть она анализирует описание анализирует контекст диалога и опираясь на эти вещи собственно понимает подходит навык или не подходит вот ну пример понятный Да человек пользователь просит включить Мадонну мы понимаем что для этого есть у нас два подходящих навыка вот ну модель решает что модо скорее музыка и включает её и генерирует какую-нибудь присказку которую Неплохо бы добавить непосредственно к вызову навыка чтобы озвучить пользователю вот следующий запрос пользователя уже ни к какому конкретному навыку не относится соответственно управление переходит на роль ассистент и соответственно ассистент отвечает полностью самостоятельно теперь про роль ассистент Когда у нас ни один навык не подол Да у нас срабатывает такой модель переключается автоматически в режим ассистента и в этом режиме отвечает полностью уже самостоятельно не опираясь на Результаты работы каких-то внешних навыков в этом режиме соответственно нам доступно все возможности L модели Да которую обычно мы можем получить допустим зайдя в веб версию гача Вот такие дела соответственно Ну и в этом же режиме модель может поболтать пользователем в м в диалоге явно нет какого-то указания на запрос или соответственно поддержать диалог Вот про промт Да значит промт удобно разделить на такие Логические блоки чтобы понять что в нём происходит начинается промт всегда с система так называемого да в котором для модели описываются прави и работает Ну и тут вкратце вот описана схема которую я сейчас изложил да то есть два режима toen для классификатора если он не подходит то Assistant toen дальше идёт блок с непосредственно историе общения с пользователем Да тут у нас сообщение пользователя ответы ассистента и всё остальное для последнего сообщения Ну вот здесь У пользователя Включи хочу его послушать да сгенерировал бло SK это как раз блок который создан вот этим вот классификатором навыков Ну в данном случае он отдал нам топ-2 навыка который похоже подходит под последний запрос соответственно последний блок это уже то что сгенерировал модель в ответ на вот такой контекст вид из Непосредственно текста ответа и специального блока который обозначает для нас тот факт что модель решила вызвать навык Ну вот в данном случае музыку Да теперь про роли Да значит как я уже сказал роли они привязаны к конкретным токенам которые вмте фигурируют вот и естественно модель она обуче генерировать и определять роли автоматически включить конкретную роль несмотря на мнение модели для данного конкретного случая Вот и такие кейсы есть в общем-то Это довольно удобно Например у нас есть команда аналитики которая занимается автоматизацией разметки и им вот не нужна роль ассистента они не интересуются там значит генеративными ответа значит увеличивает эффективность разметки повышает там точность некоторых процессов вот что же они делают они просто в свом пром уже ставят самостоятельно и модели ничего не остатся кроме как выбрать из тех навыков которые ей предложили И всё да то есть она уже не может сгенерировать ответ который не содержит непосредственно вызова навыка Вот и напротив Да работает и риант когда Допустим мы не знаю у нас отработал движок грамматик Да мы допустим знаем что для фразы Поговори со мной Мы всегда хотим отвечать диалоговой моделью точно не хотим запускать навык вот в этом случае мы опять-таки можем значит пропустить классификацию модели проставить ей Assistant token и соответственно это приведёт к тому что модель всегда будет не вызывать навык а отвечать самостоятельно из своих весов Вот это Довольно простой но удивительно полезный механизм которым мы можем управлять Да генеративной моделью и избегать того чтобы она делала то что ей захочется в общем-то Да так как виртуальным ассистенте полно различной бизнес логики которые завязаны там на грамматике или какие-то а тесты или в общем различные вещи такой вот орган управления моделью он нам очень помогает с внедрением про да то есть мы можем довольно-таки гранулярна отвечает в тех или иных случаях вот поговорим про то как собственно учится такая модель Ну начинается всё с предобзор Ну вот например конкретно наша модель которую мы сейчас запустили она обучалась там помоему 2 месяца на кластере ГПУ из там нескольких сотен нот соответственно это первый этап который мы никак не затрагивая на самом деле второй этап - это сун в котором уже участвуют вручную написаны дан эв ответы на вопросы и всё это дело попадает в обучение модели при этом на данном этапе уже требуется на порядок меньше ГПУ часов меньше ресурсов да То есть в принципе всё сфт можно сделать там на восьми нода приблизительно за полдня Вот то есть этот этап уже гораздо более быстрый и результатом этого этапа является та модель которую можно получить чит через веб интерфейс То есть это получается у нас публичный чат наконец данные которых я говорил раньше да то есть вот эти вот сессии обогащённые кандидатами обогащённые различными метаданными пользователей они появляются Уже на второй стадии Файн тюнинга и на ней ещё в 10 раз меньше нужно ресурсов то есть на самом деле вот такую модель про которую я сегодня рассказывал можно получить всего на одной ноде с Во а 100 Ну приблизительно там часов за 10 15 и объём данных тоже приблизительно в 10 раз меньше чем на предыдущем этапе вот так что на самом деле Вот такой вот гигачад для салюта мы можем себе позволить обучать достаточно часто и это не супер дорого Да по железу просто потому что мы основы уже на достаточно хорошем сильном вот Ну и к чему это ВС привело Значит мы запустили месяц назад данную фичу на сберб мах пока на ограниченной части пользователей Вот но видим что это достаточно позитивный эффект даёт в первую очередь хороший результат мы получили на карзи раньше они в основном не работали да потому что для них просто не было специального навыка А теперь мы эти запросы обрабатываем м моделью и всё замечательно работает так как у нас есть классный фолк и все эти запросы попадают прямо в него Вот так что мы на этой корзине получили прям хороший прирост релевантности также мы видим хороший эффект на диалогах пришёл поболтать пообщаться с виртуальным ассистентом может поченкова Метрика тоже приятно подросла То есть 99% теншен у нас увеличился пользователи стали больше общаться с колонкой стали больше взаимодействовать конечно это позитивно сказывается на продукте в целом вот так что естественно мы будем масштабировать эксперимент и раскатывать гига Chat solute на другие поверхности про что я надеюсь мы расскажем Уже совсем скоро Вот такие дела На этом мой доклад заканчивается Спасибо за доклад А теперь вопросы Спасибо большое за доклад очень интересно Меня зовут Рома такой вопрос а сколько навыков может активироваться в ответе такой мй один или больше мы прорабатываем историю с тем чтобы можно было активировать в одном запросе больше одного навыка но как будто это не очень частый кейс на самом деле то есть в общем Сейчас активируется только один навык или ни одного отли вот следующий за ним вопрос э насколько умные сами по себе могут быть у вас навыки выходите какие-нибудь может быть внешние сервисы которые Ну там не знаю перепаять интернет может быть Google какой-нибудь ну строго говоря навыки могут быть любые Да у нас есть допустим навык который ходит в поисковой индекс для Википедии и значит возвращает релевантные знания для модели чтобы она могла там более качественно ответить например в этом смысле он очень умный вот ну большинство навыков Они конечно довольно простые То есть это всегда какая-то атомарная функция вроде там Поставить будильник или там сделать какое-то действия то есть они не предполагают какого-то большого ума Это обычно какой-то сценарий или что-то такое достаточно простое Вот Ну вообще да есть как бы алае в этой истории есть умные навыки Но в основном навыки конечно довольно простые по суво яви понимаю что сеча зада нету в космос отправить Ну как бы end диалоговый ассистент без костылей вроде навыков Ну да мы вот как бы от чего мы хотели уйти чтобы у нас М не была закрыта там вот в отдельном загонке в отдельном навыке чтобы мы говорили там Эй хочу поговорить с гача тамм А чтобы он у нас был прям в корне ассистента да то есть чтобы он работал на любой запрос если у нас просто навыка нет вот ну и собственно Вот все вот эти вот решения про которые я тут говорил они именно на это направлены чтобы у нас как бы безшовна функционал уже который сейчас есть с новым он как бы срастается Да потому что естественно никто не будет рад если вдруг его навык который он разрабатывал там годы взяли и заменили там на ЛМ Да и как бы и всё вот мы конечно это сделаем но может быть позже Отлично спасибо а как вы решаете проблему с эреном То есть как писать вот такие запросы в котором участвуют новые навыки и так далее Ну выборку как собирать правильно вы имеете в виду Как сделать так чтобы новые навыки активировали Для новых пользователей При этом они не знали даже про них ну и при этом МКА которая собственно будет делать эти вызовы она это понимала Ну да ну смотрите рекомендации в случаях когда запрос как бы явно не требует их Да они осуществляются скорее пум там изменений в интерфейсе да то есть скажем там есть всякие подсказки которые говорят вот я могу это ещё сделать или вот то да то есть модель она непосредственно сама не занимается рекомендациями она исключительно ранжиру ет то что ей предложил классификатор вот При этом если есть необходимость можем в вот это вот ранжированы список Даже те навыки которые как бы классификатор Ты не нашл просто мы хотим их поднять по какой-то причине Да дать им трафик это тоже можно делать Вот но как бы это к модели не совсем относится Это скорее уже про продукт Да история Вот то есть модель она не не занимается рекомендацией навыков новых Окей Ладно спасибо не буду у других врем забирать Да спасибо большое за доклад ой ко возник да может я не заметил но как у вас идёт шина общения Ну то есть вывода мки с самим продуктом то есть каким-то Хард вы показали промт где моделька выводит classification и говорит типа я включаю музыку какую-то как имен музыка включается в станции Да ну я намеренно опустил этот вопрос потому что там на самом деле много чего ещё происходит между генерирования вот этой строки и непосредственно вызовом наков Ну давайте скажем что у нас есть сервис который значит парсит Результаты работы модели Да они превращаются в текст и команду дальше есть е один сервис который эту команду перекладывает на конкретный вызов и потом всё это дело сшивается уже в Единый ответ то есть ну естественно это не модель непосредственно делает есть отдельный сервис который получает название навыка параметры которые нужно к этому навыку отправить Да и в общем-то делает непосредственно вызов получает ответ вот ну он на слайде не показан потому что он немножко не про то вот понятно А вот для этого наверное нужно чтобы МКА выводила какой-то структурированный ответ Ну например какую-то Джей сонку были ли у вас проблемы с тем что он иногда выдаёт невалидный или невалидные структуры данных Угу Ну начнём с того что не у всех навыков есть параметры для которых необходимо вот это вот Слот филинг осуществлять Да и какие-то параметры подставлять в случаях Когда всё-таки нужно У нас конечно есть как бы процедуры которые позволяют значит починить невалидный ДСО да то есть там для некоторых навыков есть Понятно значит старый режим работы да который был до м соответственно если мы не смогли распарсить нормальный ответ мы просто флм на него Вот но на самом деле Вот сейчас мы уже почти избавились от ошибок с Ну такими неправильными какими-то результатами генерации то есть в общем-то и там меньше доли процента именно кейсов когда биты J невалидный навык или что-то в таком духе то есть Ну в целом это решилось более чистыми данными более правильным обучением вот Ну если это всё-таки происходит у нас всегда есть вариант фолк нуться на предыдущую версию Понятно спасибо Добрый день Я являюсь активным пользователем будучи сотрудником Сбербанка устройствами сбе соответственно расскажу вам такой пайплайн когда только начали раскатывать вот эту прошивку для работы с чатом при запросе плейлист дня он частенько вместо запуска из звука обращался именно к Дига чату и выдавал в принципе достаточно интересную подборку музыки которую я вот хотел бы запустить и послушать я специально Проверял что данные треки они доступны в звуке но заставить колонку запустить их я не мог в принципе По всем вопросам которые я не могу продолжить этот пайплайн совместно там с ассистентом либо с навыком прорабатывают подскажите Вы На каком устройстве это запускали сбм Ага ну наверное это некоторое время назад было Ну в общем Суть в том что скорее всего Вот когда это происходило Да вы как раз действовали через отдельный навык Да в ЧМ проблема того что чат в отдельном навыке контекст в котором живёт гигачад внутри навыка и контекст в котором живёт весь остальной виртуальный ассистент он не один и тот же да то есть это разные контексты Вот в тот момент когда мы вывели значит гача в корень Сбер бума у нас контекст стал общий соответственно мы теперь можем скажем включить Мадонну потом спросить как она тебе так как контекст один и тот же модель сможет подхватить из контекста то о чём идт речь и собственно включить Это должно работать и в обратную сторону да то есть если мы поболтали с моделью допустим спросили Какой у тебя любимый там американский исполнитель Да она нам что-то сказала мы потом говорим а давай включи-ка это мне да не указывая Конкретно что именно вот Соответственно в этом случае вот эта модель Конкретно она умеет сгенерировать непосредственно ьз с вызовом музыки и подставить туда исполнителя изго чтож В общем Ну скоро это заработает у всех таким образом есть интеграция со всеми сервисами Сбербанка То есть если я там спрошу о каком-то кредитном портфеле и так далее я смогу обратиться там сделай перевод туда-то и так далее ну мы к этому идём С банковскими интен Тами конечно немножко усложняется интеграция по понятным причинам Да там всё всегда немножко сложнее чем со всем остальным вот в общем-то да то есть у на идея в том на вот этот Фин работу с большинством навыков и тогда действительно у нас будет возможность подхватывает слоты из диалога и отправлять их в навыки чтобы всё работало собственно так как хотелось бы Спасибо Да добрый день Я хотел спросить такой наверное немного организационный момент вы там указывали что в Файн тюнинге миллион вручную написанных диалогов был да хотел спросить кому вы делегированы 2 часа в день использовал не разработчик делали то есть вот на 1ф Да там где на слайде было написано в общем привлекались специальные люди которые каждый для своей там области знаний писали диалоги И это всё попадало централизовано в обучение чата да то есть это не разработчики делают это делают ди нанятые и оплаченные Сбербанком чтобы просто публичная модель гача была умнее во всех направлениях да то есть там есть специальные Люди под разные индустрии которые конкретно писали вот диалоги чтобы соответственно модель могла лучше отвечать ну то есть у них должно быть понимание именно того как языковая модель работает или или это были там условно музыканты писали навыки про музыку или Ну вроде того то я точно не знаю честно говоря Как они это делали но в общем там вряд ли у них было прямо понимание работы непосредственно ЛМ у них просто были правила инструкции Как писать эти диалоги правильно и они следуя е и создавали вот эти ДТ сайты для обучения и сколько занял времени такой сбор Ну вот весь двадцать третий год практически они этим занимались Спасибо Спасибо за доклад А вопрос такой вот если я правильно понял схему то вот эти навыки они выглядят как будто бы там сценарий работает на один запрос Наверняка есть навыки которые подразумевают некий контекст и внутри которых пользователь как-то взаимодействует вот ну мини вопрос да или нет Если да то как тогда продумать этот сценарий выхода из этого навыка чтобы вернуться в общение с гача самим Да хороший вопрос безусловно есть навыки которые не зарядные да то есть они когда вы в них попадаете включается какой-то сценарий и Ну вот яркий пример допустим перевод денег да то есть там пока этот перевод не завершится успешно соответственно из навыка выйти нельзя будет Ну в общем таких навыков не очень много для каждого из них реализованы свои условия выхода из вот этого вот сценария как бы захвата сессии навыком обычно несколько да то есть либо если сценарий завершился успешно либо если прошло достаточно количество времени либо если пользователь явно сказал что он хочет закончить навык Да вот то есть ну для этих навыков там никакой магии в данный момент нет это всегда такие руло вые штуки которые в общем держат вас до тех пор пока навык не закончится Ну или пока вы сами не скажете хватит вот Ну да на уровне гача мы сейчас прорабатываем историю нач того чтобы присылать навыкам хинты насчёт того что Слушай навык вот сейчас вопрос точно уже явно не похож на кусок твоего сценария Так что если ты ещё не вышел то пожалуйста выйди и отдай управление Вот но эта история пока в проработки то есть на данный момент там Всё достаточно жёстко заколочено для таких навыков Ну радует только то что их не очень много на самом деле Таких вот Спасибо ели вопро е о задать Ну там один ещ есть Спасибо за доклад Вопрос два вопроса на самом деле один по поводу классификаторов и вот этой части классификации где топ-3 забирается вот у этой модели какой-то оценка по количеству интов У вас есть Ну информация просто Дада поч всегда Да с 99,3 вероятностью попадает тот навык который наши разметчики посчитали что действительно должен был вызвать мы берём топ три в данный момент потому что мы могли брать и больше но у нас бы тратилась гораздо больше места на промт Да пришлось бы более длинный SE L использовать для Ирен Короче говоря топ-3 оно нам даёт хороший баланс между длиной промтайм классификации вот поэтому мы берём три а всего классов там сотни Ну вот я писал там раньше всего навыков там где-то четыре с чем-то сотни суммарно Ну вот если четыре сотни навыков то на сам навык в среднем интен всё равно может быть там больше то есть если там плюс порядок наверно да больше чего Ну то есть мы Включаем музыку Включаем музыку это два раз ра сла музы включить музыку Это один интент выключить Ну да Ну если так накидать то получается там классов наверно плюс порядок и вот эту модель никак не разбивали то есть просто бывает что там ну если говорит Роберто то у него на большом количестве классов там дисбаланс происходит илито эту проб классификатора там эти вопросы уже в общем-то давно решены То есть у нас есть хороший такой пайплайн обучения который сейчас работает на замороженном энкодер и в результате этого его практически невозможно переобучить да то есть там так как параметров в самой голове классификации очень мало то даже если у вас там дисбаланс классов это не слишком сильно влияет на результат Ну таким вот образом Да так как Надер сам на его веса дисбаланс не влияет А сам сама голова Она Ну не переобуться на таком объёме данных которые мы их обучаем его вот так что ну честно говоря нет такой проблемы сейчас на самом деле плю на какой-то предел там пока не натыкались вот ну то есть в предел количества навыков Мы ещё точно не упёрлись и как будто не упр в ближайшее время вот хорошо спасибо и второй короткий вопрос э-э вот если там взять пример навык даты время чек поставил будильник и потом этот будильник срабатывает тоже с каким-то Ну а проговори им текстом который по идее должен пройти через мку вот этот пайплайн работает через просто инструктирования запрос да Ну да то есть мы в момент когда срабатывает будильник Обращаемся к лемки протом с инструкциями и потом генерируем ответ который идёт уже в приложение пользователя Да можно так Ну на самом деле когда срабатывает будильник там по-моему в Будильнике есть просто заготовленные ответы то есть они не ходят в мку Чтобы ещё что-то доге нери да то есть вот тот пайплайн который сейчас он относится именно к Ну вот вызову первичного навыка А вот эти вот всякие действия которые происходят отложено Да они уже идут по другому пайла то есть не через то есть в целом токо Поль сессии живые которые ходят Ну некоторые навыки некоторые навыки Они отдельно у себя делают отдельную интеграцию с гача Да чтобы там как-то аугментином друзья Давайте продолжим сессию вопросов и ответов в кулуарах и перейдём к части награждения прошу тебя выбрать самый интересный вопрос Ну вот молодой человек спрашивал прот не настоящие Джейсона невалидные давайте наверное ему Ну что Аплодисменты Большое спасибо докладчику спасибо"
}