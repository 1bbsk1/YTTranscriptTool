{
  "video_id": "ON9HMhzfJVY",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Али расскажет про движки распознавания я речи ВКонтакте и мы узнаем для чего это нужно и почему Али ждём тебя на сцене Привет Как настроение отлично Давай жги Всем привет Меня зовут Софи темо моего доклада - это движки распознавания речи во ВКонтакте прежде чем мы непосредственно начнём доклад пара слов обо мне Я работаю в машинном обучении уже 5 лет два из которых я работаю во ВКонтакте где занимаюсь разработкой распознавание речи и обработка речевых сигналов А план нашего доклада будет построен Таким образом мы с вами поговорим про технологию распознавания речи проговори про базовый isr pipel из чего он строит а также обсудим как его обучать обсудим тонкости онлан и офлайн распознавания речи а также обсудим Какие компоненты необходимо добавить в базовый чтобы улучшить качество восприятия пользователя ваших текстов полученных с а также как сделать его эффективнее Давайте перейдём непосредственно технотех сценариев использования она может быть как промежуточный этап вашего продукта так и непосредственно полноценным продуктом Во ВКонтакте например мы используем технологию распознавания рещ для того чтобы улучшить восприятие пользователя контента например вы едете в метро у вас вы получаете сообщение аудиосообщения от друга и нет возможности его прослушать так как вокруг шумно вы нажимаете на кнопку получаете расшифровку вашего сообщения и продолжаете беседу с вашим другом во ВКонтакте мы реализовали три движка это онлайновый он же стрий он же работающий на литу это недавний движок который у нас появился а также два других движка оффлайновый речь другой под спонтан спонтанная ре - это речь в основном которая обогащена нецензурной лексикой и возможно некоторые бранью но не будем об этом перейдём дальше где можно потрогать наши технология в ВК клипах и ВК видео они реализованы в виде субтитров под видео в ВК мессенджере - это расшифровки ваших аудиосообщений А в ВК звонках - это стенограмма и онлайн СУБД которые вы непосредственно будете видеть во время вашего разговор когда же стоит делать ваш движок первый момент Давайте обсудим представим ситуацию мы с с вами маленький стартап которому непосредственно потребовалась технология распознавание речи У нас есть два пути первый путь - это купить движ купить AP у какого-нибудь вендора у какой-нибудь битек компании второй путь - это разработать движок самим проинвестировать в какие-то деньги ресурсы непосредственно потребуются какая-то команда а также поддержка вашего решения то есть в целом Это вопрос денег вопрос ширины нашего ка и вопрос объёмов который мы будем обрабатывать Второй второй случай это очень тоже важный Это непосредственно качество предоставляемого вендору если Пошли по пути первого предположим мы с вами делаем распознавание речи для очень узко специализированного домена например какие-нибудь медицинские хто качество которое предоставляет вен может не отвечать для шего продукта например Это возникает из-за того что например в медицинских тех токах речь очень богата специфичной лексикой а также терминологией и обычные движки они могут скажем так плохо работать на таком специфическом Дани поэтому Стоит задуматься о разработке в данной ситуации своего собственного движка Как же всё-таки сделать ели Мы решили это ВС достаточно просто нужно реализовать компонента акустическая модель лингвистическая модель изар как это будет работать Вы просто пода ва ау аудио и прогоняете непосредственно через компоненты на слайде в порядке указано также на с собственно Давайте обсудим каждый компонент По отдельности начнём с танито танито в целом бывают разные основная идея это в том что низация это юним является слово То есть у вас идёт низация по словам есть charter подход основная идея в том что мы берём и дробим наше предложение на символы и символы являются нашим непосредственным токеном есть Более сложный подход его основная идея состоит в том чтобы составить наиболее часто встречающиеся сочетание букв А это называется бпе И тем самым мы Составляем так сказать словарь наиболее частотно встречах сочетаний бук так в этом словаре в основном у нас будут встречаться приставки суффиксы частицы местоимения то есть появляется такой скажем так морфемно некоторые знания русском языке в технологиях распознавания речи в основном используют подход и но в более современных технологиях использует низа и мы обсудим далее Почему сдуй комне фичер экстрактор а собственно задача фичер экстрактора - выделить признаки локального характера А можно воспользоваться так сказать древнейшим опытом человечества и воспользоваться спектральным анализом и выделять признаки из аудио из аудио на основе например спектры л спектры и другие можно воспользоваться скажем так передовыми знаниями и воспользоваться нейронной сеткой которая в основно в основе которой компоненты в основе которых будут компоненты свёртки и может быть нормы мотивация использования данного подхода это в том чтобы выделить не человека интерпретируемый интерпретируемые фичи а фичи которые нейронная сетка сама обучит поймёт и сделает всё за вас и такой подход часто встречается в использовании лых Нейро сете Давайте перем следующему компоненту это акустические модели в целом здесь можно говорить достаточно много но мы с вами обсудим их в использовании в палай что он из себе представляет это в целом скажем задача которая решается Просто большой большой сетко Как такие появлялись коллеги просто смотрели Что происходит в других областях где используются нейроны сетки это компьютерное зрение и обработки текстов и адаптировали решение непосредственно в Voice так например появились qun это СВЧ эффективна свёрточная сетка И решение на основе Трансформеров какие-нибудь конформеры в авто веке в как же выбрать акустическую модель можно поступить жадно и вы будете в целом относительно правы то есть наме выбрать посмотреть на какой-нибудь либо зайти на и выбрать модель которая Дат наиболее наибольшее качество такой подход может быть до тех пор вы пока не наступите на продакшн грабля и обнаружите что ваша модель может не обрабатывает в достаточном объ текстов аудиосообщений которые вы посылаете тем самым Вам необходимо балансировать между качеством которое вы можете сделать и скоростью обработки ваших аудиосообщений которые вы будете непосредственно делать на продакшене обсудим следующий компонент - это лингвистические модели их идея заключается в том чтобы внести некую зависимость между токенами в основном они решают задачу по предсказани следующего слова по левому контексту Какие они бывают просто подход это использование ных моделей в реалиях интернета очень много реализаций очень быстро просто завести подаете текст и у вас уже на выходе будет готовая модель но так сказать не только статистика Бога богатая есть ещё всякие нетки в основно непосредствено будут интегрированы Стис модели ши компонент как декодеры но в целом Вы можете использовать и Трансформеры и другие сетки как ры для ваших нужд о которых мы поговорим далее Как использовать их собственно они будут давать чуть лучше качество Однако будут требовать оче больших ресурсов для обработки как их использовать собственно можно воспользоваться Бим серм но он не такой простой как в NLP Да а с некоторой оговоркой о том что вам нужно будет клеить префиксы по по бланк символу скажем так и далее вы просто скори дополнительный Лос который Вы получили с ctc вы Добавляйте Лос ри скоринга от вашей лингвистической модели данных префиксов собственно теперь обсудим Как обучать такие штуки таких Монстров первый подход - это CC его основная задача - это выравнивать ваши предложения текста на аудиодорожку а именно выход акустического тензора преимущество данного подхода это в том что он быстро учится Однако он делает гипотезу о том что ваши токены независи при проне акустического тензора Тем самым у него нет встроенной лингвистической модели также из плюсов его можно использовать в стримингового Сити силоса заключающееся в том что если мы говорим например скороговорку очень-очень быстро а выравнивание может скажем так облома а именно ваш акустический тензор будет короче чем токенизация вашего предложения тем самым вы просто не сможете посчитать Лос а более того проблема усугубляется тем что более современных подходах а именно вот этих акустических моделях происходит сильнее сворачивание вашего тензора по оси времени Тем самым у вас ещё становится короче ваш тензор выходной как с этим бороться просто воспользоваться низа тем самым вы Сократите число токе в вашем предложении обсудим следующий это и другие авторен подходы в чём идея У нас есть прогоняем через аудио получаем некое скрытое состояние которые мы передам в декодер с помою чем-то напоминает задачу нейролингвистического перевода только в качестве входа нас какой-нибудь там тек Из плюсов это в том что он чуть лучше работает чем ctc подход на таких Берка работает только в офлайн встроена лингвистическая моделька в непосредственно декодер Однако длительное обучение из авторегрессии и inf есть скажем так некий баланс между использованием ctc подхода и авторе походит встроена лингвистическая моделька Однако некие проблемы с обучением и инсо а именно они достаточно длительные из-за того что Вам приходится нить больший нзр как это всё немножко ускорить эти обучения Ну можно например воспользоваться мульти например использовать комбинацию ctc и авторегрессионная Всё понятно у нас быстрее начинает учиться сетка улучшается сходимость а использовать мы будем например более жадный декодинг То есть это ннт или авторегрессионная речи собственно Давайте обсудим некую проблематику вначале Зачем вообще в целом нужен оффлайн онлайн распознавание речи смотрите предположим Наша задача сделать онлайн распознавание речи в ВК звонках мы можем поступить скажем так используя олайн подход а именно давайте я скажу какую-то фразу мы её обре можем как-то Умно и передадим в офлайн движок а далее отдадим это пользователю есть некая проблема заключающаяся в том что обработка до юзера вашего сообщения дойдёт порядка там 2-т секунд вни Бут зае шего о который говорит спикер а также от того как будете его хитроумно резать О'кей Давайте подумаем над следующим подходом это оффлайн ой онлайн В чём его идея А вы подаёт чанк ваш Ар движок и этот на основе этого чанка моделька принимает решение о предсказании следующего токена используя контекст который вы подавали ранее собственно задержка получается намного меньше порядка 200 миллисекунд как же таких скажем так монстров обучать в чём идея смотрите когда вы используете его вашей модели недоступен правый контекст и это нужно отразить в архитектуре и в методе обучения а именно м Если вы используете свёрточные слои в вашем сетке Вам необходимо их заменить на каузальные это свёртки которая Просто смотрит на левый контекст Аналогично поступить в а слоях а именно добавить маскирование тем самым вы запретите модели смотреть на правый контекст и далее для того чтобы финализировать скажем так ваш модель Вам необходимо написать inference с прокиды контекста в лингвистической модели и прикидывая слоёв в атен слоях контекста в ан слоях собственно что мы используем ВКонтакте мы используем для используем л спектры Ой мы используем некоторую вариацию конформеры обученную на ctc НЛО А в качестве дата сетов мы используем открытые Open sst а также собственные Которые мы получали с помощью а крада внутренним платформы разметки данных а есть некая оговорка а в плане обучения мы а обучали только впоследствии на речевых фрагментах используя Т для нарез для того чтобы вы выкинуть неречевые фрагменты и об этом объясним почему так далее в качестве офлайн движка мы используем тоже вариацию конформеры обуче на сети силосе а мы используем такие же данные в качестве лингвистической модели мы используем грану соответственно под нейтральную речь и под спонтан ную То есть у нас две лингвистические модели Почему такой подход они и другие ВС достаточно Просто такая м будет постоянно не хватать данных сного датасета аудио и расшифровки к ней под определённый домен Зато текстов хоть отбавляй пожалуйста парте ту ой господи Википедии статьи медицинские и вы можете получать лингвистические модели под определённый скажем так контекст данных под определённый работать вы получаете вы обучается какую-то ctc модель которая хорошо умеет А в звуках А дальше Вы вносите контекст за счёт контекст речевого домена за счёт использования лингвистической модели собственно поэтому мы такой подход и выбрали Давайте обсудим Какие компоненты вам нужно добавить для того чтобы улучшить качество а также сделать ваш движок более эффективнее мы обсудим четыре компонента это т акустические события confidence и текстовый рендер Давайте начнём с Вада Это технология которая позволяет выделять речевые фреймы фреймы бывают разных размеров это может быть 10 20 30 миллисекунд в зависимости от вашей потребности в качестве решения можно использовать классические методы vtc либо обучить сетку какую-то легковес ную и использовать её скажем так самим Как использовать т в ваших движках Давайте обсудим про оффлайн скажем так давайте обсудим некую для начала проблему смотрите предположим нам нужно сделать распознавание речи какого-то очень большого видео там порядка 3 часов есть некая проблема что весь скажем так весь аудиотрек не поместится на ва ГПУ поэтому м прид каким-то образом если поступите жадно по 20 миллисекунд есть по 20 секунд нарезания принудительно есть вероятность того что вы возьмёте и обре можете по какой-то речи спикера на аудио тем самым качество распознавания очень сильно ухудшится Давайте поступим скажем так более Умно более хитро воспользуемся м и будем вырезки нев у нас будет скажем так регулироваться в целом длина она будет там порядка 20 секунд потому что в целом человек столько не говорит Ну и в целом у нас формируются такие Бачи которые мы потом отправим в движок Как использовать т в онлайне смотрите предположим нам поступил какой-то чанк длиной там 10 миску есть реч мы его скажем так собираем в некоторые ба которые мы Дале отправим в с движок Если нет то мы его просто будем выбрасывать выкидывать он нам не нужен На данном этапе следующий компонент - это акустические события в чём идея кажется что хочет Ну точнее так хочется сделать суб более богатыми более скажем широкого спет Амен США шум аплодисментов выдавать в субтитрах там шум Аплодисменты музыку и другие звуки которые встречаются скажем так повсеместно в видео как мы это делаем мы обучили мо сетку на задачу муль классификации подавая просто данные собственно Вот давайте обсудим сй ко ВМ Не идеально и часто он за речевые фреймы может принять неречевые То есть например звук телефона он может вибрацию телефона и шум телефона он может воспринять как речь тем самым после распознавания речи оффлайновый а именно CC п лингвистическая модель подходе у вас сго появи втек с этим бороться как это делать можно посмотреть на акустический тензор и Понять насколько уверена ваша модели в предсказаниях как эту уверенность померить первый подход - это просто взять посмотреть максимум вероятности в вашем максимум вероятности встретить токен в вашем акустическом Тен поход доста проработает более сложные по основаны на том чтобы посчитать энтропию на вашем фрейме а далее агрегировать по оси времени подход работает чуть лучше за счёт того что у вас Коин становится более выв по там от нуля до единиц то есть имеет более равномерное распределение тем самым Вы можете лучше регулировать качество выдаваемого вашей акустической моделью и в целом смотрите на данный момент мы умеем делать хорошо распознавать текст то есть Low русский текст Давайте как-нибудь научимся расставлять знаки припинания и делать капитализацию как это сделать Ну давайте возьмём Берт и обучим на задачу такую Стоит ли после данного токена ставить какую-нибудь знак прия точку запятую тельный знак знак вопроса дефис и другие То есть такую задачу классификации токена а также на задачу капитализации то есть Стоит ли писать данный токен с большой буквы собственно Мы научились решать задачу расстановки знак пинания и капитализации как В целом это всё должно работать Давайте обсудим с онлайна То есть Вам подаётся некий далее вы принимаете рение на осно т подавать в онлай ASR pipeline а именно есть ли там речь Если есть речь то вы подаётся и далее online ASR движок вам основываясь на контексте будет предсказывать следующий токен а перфоманс данной данного пайплайн у нас порядка 200 Реал таймов по поводу офлайна несколько сложнее А работает следующим образом давайте мы возьмём аудиозапись порежем с помощью Вада и речевые скажем так точки фреймы непрерывности Будем подавать в на распознавание речи далее с помощью конденса отсеивать звуки типа вибрации телефона и подавать в текстовый рендер для того чтобы получать сообщение а неречевые сегменты мы будем подавать в акустические события тем самым мы будем давать более полные субтитры performance данной скажем так пайплайн у нас порядка 100 рел таймов собственно что вы должны извлечь из моего доклада в целом прежде чем выбирать акустическую модель Оцените ваши возможности производственное мощи амины а возможно вам требуется взять скажем так подход попроще в целом начинайте с более простого подхода это касается не только акустической выбора акустической модели а в целом вашего движка И постепенно его улучшайте тем самым решая его проблемы скажем так интерактивно на этом всё спасибо вам что были хорошими слушателями и я готов ответить на ваш вопрос Али агроман тебе спасибо за интересный доклад хоть понимаем Как это работает маленький подарок от от спонсоров и от организаторов чтобы ты про нас вспоминал всё остальное время когда будешь думать о новом докладе и у нас вопросы Из зала Привет Спасибо за доклад у меня сразу два вопроса Первый - это видите ли вы потенциал в применении диффузионных моделей в задаче распознавания речи и второй вопрос сталкивались ли вы с проблемой наличия баса при распознавании разных диалектов речи русского языка спасибо да спасибо за вопрос смотрите Я пока не добрался до статьи использования диффузионных моделей Возможно как-то они применяются Но пока ещё не разбирался глубоко по поводу диалектов в целом Вы можете регулировать диалекты за счёт использования скажем так текста то есть в ctc п лингвистическая модель подходе в этом скажем так вся мощь этого подхода в том что вы можете регулировать ваши контексты за данных текстов забывайте оставлять отзыв о докладе это реально важно и нужно и спикеру и организаторам и программного комитета чтобы мы знали что надо улучшить а что-то наоборот ухудшить и у нас следующий вопрос Спасибо за доклад у меня такой мерки вопрос Можно сказать Вот я услышал что мы сначала Разбираем речь слова да потом слова интерпретируем Почему нет не россети который Ну как человеческий мозг из звуков смысл пытается собрать Да смотрите в целом она вы пытаетесь непосредственно получить текст то есть это уже в целом готовый То есть вы поёте аудиосигнал а Далее вам сетка уже на самом деле уже полноценные сетки пытаются вам не только они выдают вам только текст то есть скажем так они пытаются его непосредственно обработать добавить нею нче смы за ческой модем Саня связь токенов Вот и за счёт этого вы можете получать текста далее Как работать с этими текстами Вы можете там воспользоваться сетками по обработке речи использовать там Различные nlu подходы для того чтобы выделять например в разных движках типа Алисы для того чтобы выделять решать задачу там Нера а далее там использовать скажем так ин классификацию для того чтобы далее использовать её в таких вот голосовых помощниках Это потому что более универсальный становится подход допустим если у нас будет специфическая задача Мы сможем сразу из звука э выдёргивать то что нам нужно выпуская вот текстовую модель я понял А да смотрите э в целом пока такие подходы не распространены в основном решают задачу раздельно Спасибо и в вопрос от меня А как вы решаете эти ситуацию когда смешано е речь русско-английская тем более для айтишников это актуально очень да смотрите в целом мы сейчас решали задачу в контексте распознавания речи только русского языка но в целом а можно решать различные мультилистинг один язык для распознавания Вот это не его коварство Если вы хотите например делать распознавание речи для скажем так в мульти подходе Например я купил новый iPhone и вы хотите отрендерить iPhone английскими символами то вам потребуется дополнительный модуль который на основе текстов сможет вам переписать iPhone с русского на английский и скорее всего так будет работать хорошо и нас вопрос да спасибо большое за доклад хотел задать такой вопрос замеряли СНР по текущему isr и какие методы может быть борьбы использовали для его улучшения А смотрите в целом мы использовали по поводу аргументации наверное в целом смотрите мы в качестве данных там будут всякие нарезки звуко видео поэтому там достаточно шумные данные используются а по поводу аргументации мы добавляли различные там шумы в целом то есть там порядка 53 по-моему децибел разница между шумом и речью А так Кстати по поводу онлайн распознавание мы делали неку обучение скажем так если Вы заметили то мы использовали о вместе с вам и есть скажем небольшого домена мы дополнительно обучали нашу сетку на то чтобы на выходах вот этих речевых фрагментов сда Спасибо И у нас следующий вопрос Да здравствуйте такой вопрос для оффлайн распознавание не пробовали ли вы перед вам ставить рек модели чтобы отсечь всякие звуки которые вы там консом пытаетесь потом заглушить Да смотрите у нас в целом так есть момент Тай что скажем так есть отдельный много разных команд работают над скажем так своими продуктами и в целом некоторые команды ставят перед подачей в наш непосредственный движок который мы используем рек модель а в целом Так сейчас и работает но хочется улучшать перфоманс моделе и ставить норек после Вада потому что это будет эффективнее Спасибо за ответ и у нас следующий вопрос Да здравствуйте Спасибо за доклад было интересно хотел узнать может ли ваша модель делать риза текста то есть разделение по ролям А смотрите в конкретно сейчас момент нет то есть а Например если в оффлайн движке это так не будет работать в онлайн Вике у нас получается много каналов изза чего мы можем на каждый канал генерировать свои собственные субтитры пока это работает так то есть если будет больше одного спикера то модель распознает всё как один спикер Да понял спасибо А вы думали прикрутить туда ещ переводчик чтобы можно было говорить множеству спикеров и оно сразу переводил это хорошая дальнейшая Ду и у нас следующий вопрос Здравствуйте меня зовут Алексей компания вкусвил автомакон А заранее извинюсь за вопросы Потому что я не сильно технически погружён всё что знаю что Вада - Это всемирная антидопинговая ассоциация А вопрос такой Ну вот тут коллега спрашивал по-моему про качество но он спросил так что я не сильно понял а соответственно с точки зрения бизнеса там условно я понял есть два бизнес кейса вы внедряли это в поддержку и этим пользуются пользователи есть субтитры и так далее всё-таки Как реально измеряется качество Да вот вы можете сказать там у нас реально 50% вот работы модели они полезны там 50 бесполезно и так далее Это первое Ну и второе Наверное это есть ли интеграция какая-то того что вы сделали с какими-то другими продуктами потому что всё-таки пока так понял это внутри ВКонтакте и работает всё внутри ВКонтакте вот такой вопрос да Смотрите по поводу оценки качества Ну смотри для олайн распознавания использует меру качества это там число перестановок замен смещений в словах среднее скажем так Непосредственно как мы оцениваем качество мы дополнительно для того чтобы понять скажем так бизнес составляющую мы дам ам ние Какое скажем так лучше располо типа там у нас или там какой-нибудь другой модель И тем самым мы принимаем решение о том чтобы там менять модели и так далее по поводу скажем так интеграции с другими продуктами У нас есть Первое это скажем так открытый I который мы тоже постоянно модернизируем модели и улучшаем и предоставляем открытый доступ Спасибо И у нас ещ один вопрос Спасибо огромное за доклад А вот цифры которые прозвучали по скорости очень интересные Да они обычно в привязке к железу какому-то дела пояснить Да смотрите у нас мы используем для в целом для на кластерах Тесла T4 Ага спасибо и ещё вопрос по реализации это тоже важно это микросервисы или это Монолит в котором Смотрите по поводу интеграции с в лом сер у на это реализована как c+ Plus движок который мы непосредственно делаем C обёртку и вызываем различных скажем так все а продукты могут интегрировать наш движок а скажем так используя C обёртку в различных языках там Go Java зависимости от там продукта Да спасибо И вот ещё один вопросик вот предыдущий вопрос касался качество Но вот Метрика понятна V а цифры какие-нибудь вы можете привести или это Да смотрите Мы пообщались с коллегами и решили не публиковать пока что цифры Спасибо большое И у нас последний вопрос Да здравствуйте ещё один вопрос хотел узнать А что сильнее влияет на Вер архитектура модели или данные на которых обучают Просто когда я изучал эту тему было такое некоторое мнение что на открытых ASR dat сетах невозможно обучить модель с вером приближенным к коммерческой смотрите в целом Да это в общем есть такая проблема что для русского языка достаточно мало данных скажем так чистовых но есть некие подходы которые скажем так называются Self Super для них они решают скажем так задачу маскировать весь YouTube подать туда моделька как-то обучится извлекать какие-то скажем так сама скажем так научится какие-то там буквы что-то там внутри Господи модель сама научится вовлекать какие-то акустические признаки а далее Вы можете её Файн тюнить на задачу вот ctc или ннт в зависимости от вашего потребности тем самым для того чтобы обучить э скажем так идеальную сетку можно в целом обойтись мизерный а идеальным датасета размеченный Ну то есть в принципе если у меня есть доступ к железу на открытых СР датасета Я могу научить что-то Ну хотя бы приближены к коммерческому продукту Да я думаю что сможете использовать там аргументации и скажем так передовые подходы спасибо Ну друзья мы это сможем подробно всё обсудить в секции луара в Q возле выхода и у меня в Тебе два вопроса Выбери Два лучших вопроса один подарок от спикера другой подарок от нашего генерального спонсора Да вот молодой человек про вопросы бизнеса а выйдите пожа выйдите Пожалуй на сцену и вот молодой человек который задавал два вопроса по поводу распознавания речи непосредственно Это от спикера это от нас идеа Спасибо большое всегда таком мечта Поздравляю Спасибо Вам спасибо заклад N"
}