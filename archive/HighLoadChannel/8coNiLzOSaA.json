{
  "video_id": "8coNiLzOSaA",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "я приглашаю на сцену Александра который расскажет нам про использование каденции Всем привет Меня зовут Александр Я представляю компанию рама немного о себе Я несколько лет программировал на занимался компьютерной лингвистикой в частности из ключевых слов из русскоязычных текстов сейчас я го разработчик в компании рама и также являюсь одним из авторов курса по гоу для школьников в Яндексе компания барам - это глобальная компания по работе с аудиторным данными в СНГ представлено российским юридическим лицом с 2012 года если простыми словами то Наша компания помогает рекламодателям работать с данными о пользователях Я знаю что многие не любят рекламу но мы делаем так чтобы вам отображалась та реклама которая вам интересна один из видов аудиторных данных с которыми Мы работаем это CRM данные это по сути это данные о пользователях А например если у вас есть какой-то веб-сайт или интернет-магазин и там регистрируются пользователи А вы можете поделиться этими данными с нами мы поможем вам найти похожие аудитории и выстроить рекламные стратегии А эти данные сем данные поступают к нам от клиентов мы их загружаем себе обогащаем ищем аудиторию и происходит это следующим образом а у клиентов есть доступ к Google басам куда они заливают эти данные в разных форматах но Внутри там везде CSV В итоге эти данные а нам нужно преобразовать в J записать в другой Бакет предварительно о богати информации из нашей локальной базы данных и затем мы это всё импортируем в стороннюю базу данных snowflake а пару слов о сноуфлейк сноуфлейк - это база данных обёрнутый в сас модель а то есть база данных как сервис мы ничего не устанавливаем ничего не настраиваем всё делает команд snowflake мы платим за использование вычислительных ресурсов и за само хранилище но вернёмся к нашей задаче то есть нам надо взять CSV файл обогатить и записать J и затем в snowflake особенность у нашей задачи файлы не известного размера мы не накладываем никаких ограничений для пользователей обычно файлы у нас от нескольких гиба неско Киба до нескольких сот гиб с ще по соглашению об уровне услуг с клиентами данные должны обрабатываться параллельно то есть мы не можем Всё в одну кучу свалить и обрабатывать это всё де должно делаться Независимо а далее если файл пришёл нам на вход то мы должны его доставить снова Флек в любом случае если у нас будут какие-то фейлы мы должны забивать это руками конечно это шутка но такие случаи были и следующее несмотря на жёсткие временные рамки наши ресурсы тоже ограничены поэтому мы должны уметь поставить обработку в очередь в случае пиковых нагрузок Давайте разделим наши задачи на этапы первое нам нужно как-то узнать о новом файле варианта здесь два мы либо периодически сканируем бакеты наличи новых файлов либо настраиваем оповещение так как у нас Google настроить пап оповещение о новых файлах а следующее - это получить информацию из нашей локальной базы данных мы здесь получаем информацию о разделителя информацию о клиенте нужен вообще ли импорт snowflake и некоторые другие данные а далее непосредственно чтение преобразование и запись финальный Бакет И последнее - это импорт snowflake на первый взгляд это лёгкая задача я уверен что многие делали что-то похожее мы рассматривали три решения как это сделать Первое это всё делать самим с нуля то есть реализовать какую-то систему которая всё это будет делать Какие сложности у этого решения во-первых это долго потому что учитывая требования к нашей системе реализация будет представлять функционал некоторых интерпрайз систем а сама бизнес будет занимать крошечную часть А как пример А в случае фейла на одном из этапов на одном из этапов Мы хотели бы перезапустить только этот этап а а не весь workflow с начала до конца Потом мы хотели бы мониторить что у нас происходит вообще если у нас задача выполняется несколько часов на самом деле она выполняется или может быть уже Всё висит А вот под такие сложности мы прикинули что займёт у нас это всё на реализацию 2-3 месяца в команды из трёх разработчиков поэтому практически сразу мы решили рассмотреть какие-то готовые системы которые нам упростят жизнь в данном случае первое что мы рассматривали это bentos это средство построения Панов написан на Go у нас уже есть его опыт использования в проде у нас используется Мы решили сделать некий пок на коленке чтобы вообще попробовать подойдёт ли он нам для данной задачи Кстати это не наше отношение к нему это официальный логотип бенса в bentos конфигурация пайла строится с помощью я файлов и своего языка BL Я приведу несколько этапов слайдов с этапами обработки но финальный листинг будет не сильно больше м слайде мы получаем информацию о новом файле по подписке Bent feeder то есть предварительно настроив её поса подписку а затем проверяем Бакет из которого к нам пришёл файл получаем информацию из нашей локальной базы данных проверяем Нужно ли вообще обрабатывать файл дальше само получение информации о файле это обычный SQL запрос где мы указываем драйвер и получаем по имени файла необходимую нам информацию далее преобразуем То есть некий маппинг из CSV в J мы указываем кодек CSV по умолчанию либо gip если у нас сжатые файлы по сути на этом файле почти вся наша логика то есть нам надо спить C И именно поэтому нам не хотелось реализовать что-то сво потому что нам сделать надо вот этом слайде практически следующий этап - это запись финальный Бакет и на этом этапе у нас возникли сложности Обратите внимание вот на эти две настройки это collision Mode и batching collision Mode - это настройка которая отвечает за разрешение коллизии при записи в уже существующий файл то есть мы можем добавлять данный файл перезаписывать игнорировать новые данные либо бачин это формат не формат настройка сброса буфера на диск то есть Bent копит себе данные мы можем настроить либо через промежуток времени он будет скидывать данные либо по предельному объёму то есть наша настройка означает что раз в минуту мы добавляем данные уже существующий файл но bentos не умеет держать в бате файл открытым он создаёт кучу временных файлов и потом их это нас не устраивало в части импорта snowflake Нам нужен был один файл сразу готовый другой вариант это копить всё в памяти то есть весь файл но учитывая объёмы файлов которые к нам приходят это достаточно дорогое решение наши услуги стоили бы дороже тогда для клиентов мы не хотели тратить время на написание фич для бенса Несмотря на то что проект очень живой а и реквесты там авит очень быстро а мы решили рассмотреть другое средство А вкратце про импорт в snpe в snowflake как у нас устроен А там есть такой механизм называется snowpipe А то есть мы готовим файл в баке даём права сноуфлейк на этот файл и вызываем оху для импорта snowflake и он сам это импортирует себе в табличку А там есть и другие варианты импорта а но мы потестить и использование сно пай показало наилучшее соотношение стоимости ко времени я напомню что мы платим здесь за использование а bentos хорошая штука но не устроил нас для этого проекта А мы решили взять более продвинутое средство это cence средство построение конвейеров обработки с очень гибкими настройками поддерживает масштабирование тоже написано на Go А мы здесь запускаем потоки по AP или по крону потоки обработки а рассмотрим что нам нужно чтобы bentos работал а bentos представляет себя Извините не bentos cadence представляет себя несколько сервисов каждый из которых можно развёрнуто на нескольких нода для масштабирования на этом слайде тёмным светом обозначено сервисы нса а всё остальное нам нужно поднять либо реализовать самим по сути - это йт машина которая отвечает за состояние наших Фло хранит их в себе некоторые таймеры также там содержатся и очереди для масштабирования нагрузки так пройдёмся по сервисам это сервис с котом вст Линс приложения они содержат написаны над то есть FR - Это некая прослойка между внешним миром и внутренними сервиса пробрасывается запросы к внутренним сервисам hist содержит в себе основную логику оркестрация Ман серс у нас нужен для Манга соответственно зада которые надо выполнить СМИ кото доступны для работы и Internal workers - это внутренние керы нужны для сервисных целей нса так при запуске workflow мы передаём нду workflow ID frontend связывается с history сервисом history Service по frontend ID вычисляет машину которая обратится ВД чтобы получить информацию текущем workflow дальше history связывается с мачин и матчи уже смотрит если есть доступные сервисы воркеры для обработки данной задачи то задача сразу запускается на выполнение если доступных воркеров нет мачин сохраняет в стод эту задачу А frontend может также напрямую взаимодействовать со Режем для отображения ЮА вот так выглядит пример изменения состояния workflow от начала запуска До завершения то есть всё это проходит через matching Service А посмотрим на воркеры воркеры содержат написанный нами код а то есть Они получают от кейнса от фронт энда соответственно команду что нужно выполнить такую-то задачу выполняют её и сообщают результат обратно в cadence А теоретически воркеры могут быть написаны на любом языке готовые Клиенты есть у нса для Go и джавы Атак что должны содержать воркеры они должны содержать код workflow и код Activity workflow у нас служит для организации запуска одного или нескольких активити то есть workflow не содержит в себе никакого другого кода кроме как организация запуска активити а в активити происходит связь с внешним миром то есть мы там можем запрашивать данные с базы взаимодействовать с какими-то другими сервисами хранилищами с очередями всё это происходит в активити а также стоит отметить что код воркеров workflow Activity код запуска workflow всё можно разносить на различные машины рассмотрим пример кода здесь простой пример запуска простой пример кода workflow А здесь мы указываем некие опции для Activity указываем tasklist обязательно для Activity а спускаем Activity и ждём результат и получаем его далее код запуска workflow Обратите внимание что здесь тоже нужен указать tasklist для workflow очень гибкая политика трая то есть на примере данной настройки в случае фейла активити перезапустить это активити через одну секунду коэффициент 2 означает что каждая следующая попытка будет через время 2x от предыдущей максимальное время между попытками будет 2 минуты он будет в течение 10 минут Максимальное количество попыток п Также можно указать ошибки при которых не надо пробовать заново Как видите очень гибкая настройка Рав и она удовлетворяет всяким всяческим изысканным требованиям и всё это делается на Go посмотрим что у нас получилось мы сделали главный поток в котором запускаются Work Нам нужен для администрирования базы данных То есть у нас здесь выполняются такие задачи как создание таблиц в внутри сноф Далее активити для получения информации о новых файлах в батах просто сканирование Далее для каждого файла соответственно конвертация в J обогащение и отдель для и может показа что было бы проще сделать один с несколькими а но это не так Потому что когда мы делаем несколько workflow нам проще перезапускать в случае файлов всё это отслеживать и на данное решение у нас ушло порядка д недель далее есть UI здесь можно посмотреть на состояние Work на данном слайде можете обратить внимание на и endtime данные workflow как раз-таки нужны для администрирования базы данных и они выполняются достаточно быстро 2-3 секунды с момента запуска До завершения а от наших клиентов файлы у нас приходят в разное время Поэтому в случае пиковых нагрузок нам надо оперативно масштабироваться а C предоставляет много достаточно метрик мы их используем для масштабирования с помощью кеды Вот сам запрос мы здесь указываем TAS далее смотрим задачи которые нужно выполнить минус те задачи которые уже выполнились соответственно масштабируется 200 Гб данных в cence или 14 400 мл запи в баз данных это без учта пиковых нагрузок Work до нескольких часов Это так долго из-за импорта snowflake как я говорил мы платим за использование если мы хотим делать быстрее это будет стоить дороже далее Что вас может остановить от использования кейнса первое его нужно разворачивать у нас уже он использовался до этого поэтому мы сразу приступили к реализации на его разворачивание потребуется в любом случае какое-то время потом UI ВН одновременно перегружен и ограничен многого там не хватает И это всё выглядит громоздко следующее у нса есть требование к коду То есть если у вас есть какие-то готовые скрипты или программы Вы хотите это перенести в код а то скорее всего ру для этого всего есть обёртки также с каналами и лоер можно использовать только за он идт из коробки снова Вы можете теоретически написать свой Но это того не стоит требовани коду я отнёс к недостатком Но на самом деле если мы захотим реализовать что-то подобное похожее средство для периодического запуска чего-то рано прило делать какието обт для для каналов чтобы знать когда у нас всё это завершится И последнее это обновление версий для нса нормально Когда workflow длится несколько дней Если вы хотите при этом обновиться вам нужно изначально продумать эту логику там есть система обновления версий Но ваш Work должны содержать дополнительный код для этого этот онные сложности из жиз так сказать которые кейс которые нам сначала показались не очевидными когда мы использ если вы запускаете с одним таслим затем внутри запускаете А и указываете разные для может так получиться что воркеры готовы обработать зададут для одного которых йн берёт сдачи вот если у вас не будет готовых свободных воркеров Вы можете получить куча протухших активити или workflow потому что их Просто некому будет выполнять следующее вернёмся к ret polic это очень гибко но в случае длительных воркфлоу если у вас все воркеры будут заняты может так получится что А когда у вас будет травиться активити они трается несколько раз допустим у вас максимальное количество попыток пять но так и не успеют выполниться потому что никакие воркеры так и не освободились А чтобы этого избежать при настройке изначально указываете заведомо больше интервалы и потом уже в случае необходимости сокращай их для ваших значений далее Тау очень много таймаутов на примере этой настройки Мы здесь указываем что для Activity максимальный Тайт от регистрации до старта Activity 10 минут Start to Close это продолжительность исполнения Activity schedule to Close Это от регистрации До завершения Activity и снова если у вас будут длительный workflow ваши активити могут не выполниться поэтому опять сначала планируйте запас и смотрите как у вас всё выполняется и уже затем уменьшать значение если вам необходимо подытожим обработка больших файлов - Это задача которая обладает своими особенностями А мы выбрали C как средство обработки больших файлов Bent могу порекомендовать для автоматизации рутины также стоит упомянуть что у есть Fork он называется temporal или temporal разные версии произношения А у них есть Облачное решение по сути Вы можете использовать его это сэкономит вам средства и средства время для развёртывание кейнса а разработчики там часть разработчиков по-моему из кейнса ушли туда в temporal Но оба проекта развиваются то есть НС не заброшен А на этом У меня всё супер спасибо большое за доклад Есть ли вопросы в зале Если у вас есть вопрос Пожалуйста поднимайте руку также напоминаю вопросы можно задавать в чат зала с хэштегом вопрос и в этом случае я их зачитаю выдайте пожалуйста человеку На предпоследнем ряду первому микрофон для вопроса мы начинаем Ну самый простой вопрос почему решили тащить если вы сидите в не взять их workflows который там бесплатно какие-то лимиты умеет поддерживать не надо Раз уж вы любите менедж решение Ответ простой потому что cadence у нас уже используется и в принципе он нам нравится у нас всё настроено под его мониторинг Я согласен что возможно можно рассмотреть другие решения может быть мы их рассмотрим но здесь больше скажем так потому что был опыт и знали что от него ждать Спасибо большое за вопрос да Привет Спасибо что опытом поделился я не до конца разобрался а Можем ли мы наш workflow workflow разделить между разными приложениями на разных языках программирования то есть представим что у нас какая-то долгая там история из десяти вот этих элементов я хочу первый элементов сделать на go в каком-то приложении А дальше у меня там идёт какой-то Data Science Мне нужно наше приложение на питоне вот можно ли их как-то удобно разделять таким образом в можно разделять можно активити делать на разных машинах и на любых языках Главное чтобы удовлетворять анса То есть вы когда запускается Work вы регистрируйте как бы активити которые будет выполняться на этой машине пожалуйста Такое возможно Да Окей спасибо еты указывал Простите я вынуждена ва вопросов но не подряд пожалуйста отдавайте обратно микрофон девушкам для того чтобы они могли позволить другим людям тоже задать вопрос Пожалуйста поднимите руку У кого есть вопрос Ну смотрите как какое какое везение Давайте вернём микрофон молодому человеку я решил что нас немного Поэтому понаглей в сутки а можете примерные цифры накинуть сколько у вас именно задач Ну выполнении вот kons тянет или в принципе вы сталкивались с тем что он не справляется не знаю вот именно сам кол Plane нса Он поддерживает я даже не помню там тысячи workflow как-то или десятки тысяч мы далеко не используем его максимум потому что всё зависит на самом деле От количества подов А если вы его хорошо замас Он может большие объёмы тянуть у нас такой нагрузки нет О'кей спасибо супер спасибо Есть ещё вопросы в зале У меня есть вопрос А во-первых я хотела спросить есть ли какой-то автоматический мониторинг для workflow когда что-то идёт не так и каким образом вы реагируете на на то когда не знаю workflow Застрял на 4 часа или просто фейли безостановочно да спасибо за вопрос есть Так называе настройка До недавнего времени нам нужно нам надо было самим периодически это реализовывать они реализовали такую фичу как автоматический хабит То есть он сам периодически связывается с своими сервисами и сообщает Что окей Я работаю всё нормально Если этого не происходит то мы по как я сказал там много метрик всё это настраивается Как вы хотите там всё это делается да Круто Спасибо есть вопросы в зале или я продолжу задавать свои отлично люблю когда можно задать вопрос А ещё хотела спросить про workflow когда пишешь их есть ли какие-то линтер можно ли локально их тестировать перед тем как Паши куда-то А вот у тела Кстати у них в библиотеке готово есть решение которое вы запускаете там и он вам сразу пишет что код содержит допустим запуск обычный у нса средства из коробки нет но есть линтер написан какой-то отдельным человеком или команда Я не знаю который можно настроить под это дело Да можно такое использовать А вы используете нет Хорошо я поняла Я люблю такие вопрос сегодня что когда выбирали Несмотря на то что он был в вашей компании Вы оценивали какие-то другие решения возможно посмотрели на рынок Каким образом определить что для моей задачи хорошо подойдёт н какие На какие критерии смотреть вообще кейсов много для кейнса у них на сайте целый список как рекомендаций Для чего вы можете его использовать Я считаю что самое основное это если надо выполнять что-то периодически то есть какие-то задачи которые периодически выполняются Да и вам нужно что-то большее чем просто запускать таски вот в кубернетес да То есть Вам нужен какой-то повышенный мониторинг вам нужна какая-то политика трая что если вот такие требования есть то уже это будет хорошее средство То есть когда просто крон это недостаточно иногда достаточно вижу руку вопрос из зала дава пово молодо человеку его задать Здравствуйте Очень интересно послушать было мня просто Вопрос такой вот это конкретно такое средство для для языка получается то есть вы говорите что вы хотите сделать какие-то таски больше чем просто таски то есть есть например да почему вот именно так задачи от как бы бизнеса Да нашей команде у нас все Гош и А ну это конкретно потому что вот ваш профиль именно Go Поэтому вот выбран был такой да это было самое скажем так быстрое решение которое мы могли сделать Окей спасибо что прочитали мой вопрос который я не успел задать в голове у себя даже спасибо супер спасибо Есть ли ещё вопросы в зале ещё хотел спросить всё Что нужно предусмотреть чтобы обновить сохранение состояния активити А если о там разойдётся к примеру как-то иначе потребуется Ну видите если у вас выполняется какая-то задача то есть cence во время выполнения он как бы не знает что у вас творится с текущим состоянием вашего воркфлоу И чтобы ему это корректно завершить вам надо это реализовать сохранение что у вас в текущем чтобы после обновления он мог это прочитать у себя из хранилища и вернуться к тому состоянию которое она было до этого и продолжать ваш workflow Это опять-таки это понадобится если у вас длительный workflow и вы не можете так всё остановить допустим и перезапустить заново То есть у нас как я сказал выполняется всего несколько часов то есть мы можем себе позволить там несколько минут Всё остановить обновить и дальше запускать запускать workflow Но если несколько дней то уже реализовывать это придётся самому сохранение именно состояния супер спасибо Есть ли ещё вопросы в зале нету давайте выберем вопрос который вам понравился больше всего а понравился больше всего Кто был первый а вот человек Да тот же самый человек который давайте ему дадим м мне понравится сразу решение Что можно сделать вот так да это всегда полезно знать как ещё можно сделать не покидайте пожалуйста зал Мы хотим вручить вам подарок от нашего партнёра газпромнефти вас Я тоже хочу поблагодарить большое спасибо что пришли это было круто я узнала много нового У меня там ещё осталось три вопроса но я их уже в дискуссионной зоне обсужу А мы хотим вам подарить тоже подарок от компании уже от самой конференции А спасибо С вами я пока прощаюсь Возвращайтесь к нам"
}