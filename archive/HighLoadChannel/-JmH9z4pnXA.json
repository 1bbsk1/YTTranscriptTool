{
  "video_id": "-JmH9z4pnXA",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Меня зовут Данил Я работаю в Яндексе и занимаюсь а тестированием И вот сегодня я расскажу как мы из нашей внутренней ашнико назвали ва Cub А из чего будет состоять мой доклад так не работает кликер кажется секундочку угу вот а Ну сначала кратко расскажу что такое куб и как он относится к КБ как он работает после этого поговорим о том как меняются требования к продукту на внешнем рынке Ну расскажу так достаточно тоже кратко и основная часть моего рассказа будет про то как же мы поменяли технологию для того чтобы выполнить эти требования и разберу два конкретных кейса это разбиение пользователя на группы и подсчёт мерик в каждом кейсе собственно поговорим детальные требования и сосредоточимся на техническо лизации Ну поехали краткое введение если кто не знает Вот это атест делим делим Поль на две группы и смотрим Какой вариант лучше на какие этапы делятся тесты Ну во-первых генерация гипотезы потом показываем функциональность пользователям И после этого анализируем результаты принимаем решение о выходке на инфраструктуру оно ложится Примерно вот так есть Есть основные комне есть некоторая админка экспериментов да то есть это сайт в котором много логики продуктовой вот есть компонент разбиения она работает в режиме реального времени разбивает пользователь на группы То есть это такой лоуд и есть подсчёт метрик который собственно нужно чтобы проанализировать результаты что происходит когда мы берём нашу внутреннюю ашнико 200 клиентов если говорить про интернет то это десятки тысяч клиентов То есть сразу видно что их гораздо на порядке больше но при этом они ещё и по своему качеству Ну отличаются то есть здесь очень много таких сервисов уникальных То есть например там поиск реклама это некоторые штучные такие сервисы которые Ну достаточно редко можно Ну встретить в мире Да такого масштаба Вот и у них есть какие-то специфические бизнес-требования А вот на внешнем рынке а очень много клиентов каких то есть это лендинги это сайт интернет-магазинов это э сайт организаций банков и так далее И вот чтобы внутри нам подстроиться под Ну уметь выполнить любые бизнес-требования то мы делаем упор в гибкость и универсальность то есть а на внешнем рынке мы наоборот концентрируется на том что всё было просто то есть получить конкурентное преимущество чтобы было просто строиться просто включить эксперимент просто проанализировать и чтобы всё это работало очень быстро клика выкатить он выкатывается и смотришь метрики очень быстро Ну соответственно меняются требования меняются технологии сегодня об этом поговорим Так вот что же такое что у нас В итоге получилось это сервис который можете найти в Яндекс метрике и Яндек метрике то есть любой сайт и любое приложение можете подключить эксперименты да Как оно устроено для сайтов чтобы подключить Эксперименты нужно поставить скрипти себе на сат этот скрипти будет применять функциональность И после этого логировать разметку экспериментов Яндекс метрику соответственно Яндекс Метрика загит данные это система аналитики Да вот и по ним можно будет посмотреть отчёт это получает информацию о функциональности из нашей разбивалки То есть это вот в НМ содержатся все заве эе мо открыть свой сайт и накликать изменения и сразу же запустить их в прок вот есть то есть это когда у нас есть разные версии страниц и мы пере направляем трафик Ну там допустим 50 на на разные версии Ну и есть более такой универсальный способ это флаги когда вы в коде и можете интегрироваться у нас вместо скрипка в приложении ставится СДК оно также от разбивалки получает информацию об экспериментах и о выходка и логит информацию о Ну о разметке экспериментов в Яндекс АП метрику то есть по Америке потом считаются ри отчёты а значит а функциональность конечно здесь визуального редактора нет а но зато у нас здесь есть конфиг флагов То есть можно прям даже без экспериментов Ну конфигурировать выкатки на 100% В общем включать функциональность просто конфиге приложение можно провести эксперимент и сразу его короче включить на всех а здесь описал наиболее такие простые способ подключения естественно мы здесь делаем упор в простоту но не забываем о кастомизации но она больше силами пользователя делается то есть допустим подключить для сайтов на бэнде тоже возможно ну короче давайте перейдём тогда к разбиения такая Техническая задача и посмотрим как поменялась её реализация в зависимости от от требо что мы знаем про разние на групп то есть какая у нас задача У нас есть сервис или приложение оно делает поход в разбивал чтобы ну передаёт данные о пользователей данные о запросе нарген опиш и так далее в ответ возвращает одини эктов которые мы логи Ну для подсчёта метрик и флаги по которым включается функциональность например для сайтов эта штука она стоит на ческом пу потому пока рабо применить свою основную бизнес логику поэтому она должна работать быстро а ещё на неё нагрузка как минимум такая же как на Сам сервис То есть это прямо такая производительная Воско наружная штука Ну опять же как меняются требования Понятно больше клиентов А ну у них как правило в среднем поменьше экспериментов А если внутри Нам очень важно встраиваться в структуры обеспечивать гибкость то есть где-то а подключаться как сервис где-то использовать библиотеку например там супер снх сервисах или для оффлайн разметки там например коммуникаций Да вот здесь же нам важна проста подключение там важна кастомизация выкат например раскатывать эксперименты постепенно по локациям то есть выкатить сначала на потом на один дата-центр потом на второй и так далее вот здесь же в основном происходит подключение с фронтенда чаще всего хотя есть другие возможности из бэнда Да и поэтому здесь важна скорость Ну и в Яндексе ещ один важный пот в Яндексе ча проводить эксперименты кроссервисный то есть когда меняешь один сервис а нужно ещё посчитать а метрики на другом Да например внедряем что-то на поиск считаем метрики там не знаю рекламы Маркета и каких-то других сервисов вот а иногда делают ещё такие сквозные которые меняют и тут и там А поэтому здесь есть некоторые взаимосвязи и это вот важно учитывать в нашей структуре как А на внешнем рынке мы как правило Делаем всё изолированными кусочками так как же выкатить эксперимент Да ну здесь возникает слово config то есть мы создаём заявку там могут быть после него какие-то тесты авы экспертов и так далее когда заявка выкатывается она попадает в некоторый конфиг вот этот конфиг необходимо доставить на разбивал Давайте поймём что же такое конфиг Сначала да то есть понятно чтобы развалка работала быстро необходимо ну быстро делить на группы как известно чаще всего это делается смою ше а которые с солью Да используется когда мы добавляем соль в ши мы получаем вот разбиение как примерно картинки да то есть видим что вот запустили два эксперимента А B Они вроде пересекаются но при этом равномерно между друг другом Это значит что они влияют а как-то одинаково Ну типа C и D на А и Б влияют одинаково и такой многомерной схеме можно а мерный куб короче запускать достаточно много экспериментов вот Ну и что такое config по большому счёту У нас есть много экспериментов много сервисов их нужно как-то вот нарезать на экспериментальные группы верхний уровни можно на него посмотреть Это как Вот конфиг состоящий из нескольких веток то есть во-первых там например вот есть поиск да в нём есть какие-то свои разбиения свои эксперименты там есть Алиса в нём тоже есть какие-то свои структуры разбиения и есть ещё там две сотни сервисов вот и это дерево фактически мы можем представить в виде Ну таких нот например некоторым могут брать хш от солью то есть разделить на проценты некоторые проверять какие-то ограничения регионы платформы и так далее браузеры Ну и в лих у нас собственно сами эксперименты разбивал обходит это дерево иногда Она может расправиться когда нужно зайти несколько веток сразу да то есть тоже есть такая нода и включить собственно один или несколько экспериментов И что здесь видно видно что на самом деле каждый серс это некото такая ветка есть какой-то под Ева да то есть это какой-то кусочек общего графа который как-то может Независимо меняться Ну давайте посмотрим В чём у нас задача вот у нас есть админка в ней есть это вот мы говорим про ту как внутри Яндекса Да дело в ней есть значит наши конфиги они там как-то версионирование схему от простого сложному А ну во-первых сразу вспоминаем что у нас не только есть развивалка у нас есть ещё развивалка как библиотека Да которую мы встраиваем в другие сервисы и сразу же появляется такая сущность как сервис конфигурации То есть это такая Такой специальный сервис который умеет раздавать вот эти единую конфигурацию в разные кусочки то есть и в наше и в наш НТА и врата ещё других сервисов Ну на этом всё не заканчивается помните говорил что нужно уметь короче выкатывать эксперименты ещё например там как-то кастомизированные интеграция C системами То есть это вот такой тёмно-зелёный прямоугольник вот слева внизу а Ну видно что схема немножко усложнилась но это произошло Почему Потому что мы тесно интегрируем с Да с пайплайн выкатки наших сервисов То есть например есть поиск он хочет выкатить свой фи экспериментов мы отправляем нотификации в c там создаётся Граф который описывает пала выд например сначала выкатывается на настаивается например там 20 минут Да смотрим Что всё хорошо и раскатываем по локаций дальше уже на все локации и э C система Ну мы сделали Там ещё специальный такой контур конфигурации Да Независимо обмин то есть В3 у нас лежат конфигов и в некоторых называется у меня на слайдах но можно считать что во внешнем мире это аналог кипера то есть сервис координации Вот и кубики они могут там переключать собственно строчки зависимости Дант вот Ну на самом деле это ещё далеко не всё то есть получается поскольку у нас есть такая тесная интеграция и много требований да то есть достаточно такая развесистая схема получается прот коду здесь применяем принцип 20 на 80 то есть 20% усилий 80% Профит Да и сразу что мы говорим то есть на на внешний рынок мы допустим можем сделать разбивал как сервис А а разбивал как библиотеку Ну в первое время не делать а подумать об этом Потом например да сразу же отпадает необходимость в Едином сервисе конфигурации то есть вот этот Stage и и вообще мы хотим сделать некоторую такую систему которая то есть не сильно не переплетена с какими-то кастомизация Да Под каждый конкретный сервис а представляет собой какую-то коробочное решение вот поэтому мы здесь почвам несколько кусочков что в итоге мы можем здесь получить Ну вернее мы ходим думаем Какие какие системы доставки ресурсо можно использовать общаемся с разными людьми и выясняем что на самом деле достаточно относительно несложного решения пос конфигов много десятки они достаточно изолированные и чаще всего небольшие нам здесь вот подходит порционная доставка То есть у нас фактически есть некоторое хранилище А и очередь нотификации то есть да а ещё важный момент что мы пользователям не показываем конфигурации Потому что потому что хочем хотим как можно больше упростить интерфейс и сценарий пользователя то есть что происходит пользователь запускает эксперимент и он сразу идёт в этот пайплайн то есть он включается в config создаётся новая версия она кладётся в хранилище и через очередь идентификации наши инстансы разбивалки понимают что есть новая версия они её получают ещё к себе локально и на диск прикапывать И там в память в памяти держат и начинают уже там через несколько секунд раздавать эксперимент то есть Мы перешли от идеологии какого-то единого конфига где взаимосвязаны между собой сервисы с россервис экспериментами да к таким к такой ционной доставке Окей та Ну помимо этого что ещё в разбиении сделали ну избавились от большого количества вот кастомизации способов подключения Да сделали единый какой-то API и ну простый способ подключения то есть эксперименты без написания кода визуальный редактор и простой единый СДК для мобильных приложени отлично с первой частью с первым примером закончили Давайте теперь двинемся ко второй части это подсчёт метрик посмотрим как он устроен то есть в чём вообще задача подсчёта метрик вот на входе мы получаем какие-то логи да сервис этих логов достаточно много То есть это там питай данных в день это вот если говорить про Яндекс ну как бы про всю вместе систему внутренне внешни да а это достаточно само по себе большое число а но нам нужно посчитать что что нам нужно посчитать по этим данным Ну во-первых много метрик что такое много То есть это десятки тысяч могут быть да А много срезов То есть каждый эксперимент в разрезе например там а определённых браузеров определённых там городов или каких-то свойств запросов клиентов вот а ещё помимо этого у нас 1.000 экспериментов одновременно крутятся и короче Вотс все вот эти числа боши перемножить получается такая одна большая вычислительная задача Вот которую саму по себе достаточно тяжело как-то решить вот а Наша задача сделать так чтобы это ещё можно было Быстро отобразить Да и показать пользователям Так в чём различаются требования То есть когда мы говорим про Яндекс и говорим про внешний рынок опять же количество клиентов да а и опять же те же самые гибкость кастомизация против скорости простоты как правило а э сервисы в Яндексе хотят очень часто какие-то кастомные очень сложные метрики например там есть метрики счастья пользователя Да Верхне уровня Метрика счастья пользователя на поиске там в рекламе есть Э не только заработанные деньги но и счастье рекламодатель да то есть это всё какие-то сложные сложные разовые истории такие метрики Да поэтому здесь важно обеспечим Диз чтобы любую сложную задачу можно было с помощью наших фарков реализовать поэтому здесь есть разнообразные данные здесь очень много меток А на внешний рынок мы опять же делаем Ну то есть смотрим наших клиентов и делаем выделяем какие-то базовые сценарии которые чаще всего клиенты хотят Да и делаем какую-то единую модель данных единая ДХ и Единый набор метрик Ну чаще всего например пользователи что хотят померить хотят померить там конверсии хотят померить там и ком метрики да там деньги Ну там глубина просмотра страниц и так далее и так далее тан например в приложениях вот мы обеспечиваем базовый набор параметру емы И за счёт единообразия получаем ну какую-то простоту а ну давайте посмотрим как как можно решать задачу под счёта метрику Вот вот так выглядит исходная задача У нас есть логов Что можно сделать можно взять запустить короче разовый расчёт на Map подождать и получить результаты то есть но они у нас будут сколько готовиться допустим несколько часов могут это долго делать так для каждого эксперимента это неэффективно и Ну во-первых много работы дублируется ещё долго ждать А давайте ускорим скажем что мы будем делать какие-то регулярные например ежедневные выжимки то есть будем запускать один регулярный расчёт который будет плива часть работы например парсинг логов да Да вот и потом построит какие-то относительно компактные выжимки вместо там пба десятки гигабайт например да они могут весить Вот и по этим выжимка положим их в qv хранилище и будем очень быстро отображать результаты для любого эксперимента то есть вот как только посчитали результат в выжимка А кликаем на эксперименте посмотреть результат и получаем табличку там за несколько секунд так вернёмся ещё раз на этот слайд и вот на самом деле вот эти этапы можно можно назвать коллект и фч мы их называем то есть одно подготовка данных и фч - это собственно экстрактивных выжимок чтобы понять что что мы положим выжимки что нам нужно нам нужно собственно вернуться к той задаче статистической которую мы решаем Ну понятно ВБ тестинг что хотят отделить эффект от шума То есть если допустим эксперименте заработали на 100 руб Больше Как понять что это что это будет заметно при выходке на 100% но нужно оценить шум и соотнести эту Дельту с шумом это делается с помощью стат критериев тут есть разные подходы это вообще на самом деле большая Тема мы считаем мы считаем Бакет мавит как Миша уже сегодня с утра на докладе про Яндекс рассказывал в ВМ заключается осно иде Бакета вот когда мы запускаем эксперимент мы его запускаем 50 на 50 да то есть делаем такой Сплит на две группы на самом деле чтобы оценить тот самый шум че нам не хватает нам не хватает то что в каждой в каждой из этих выборок по одной чисел да то есть там за одно значение метрик нужно сделать их много что мы можем сделать мы можем на этапе разбиения просто взять и побить там не на две выборки например А на 200 То есть это абсолютно одинаковые 200 таких микро эксперимента которые мы называем бакеты и уже Ну если считать что каждый этот маленький кусочек презента общей какой-то совокупности да то можно применить тест взять здесь 100 чисел здесь 100 чисел посчитать там метрики и соответственно вычислить результат почему это круто да смотрите представим две ситуации когда у нас в эксперименте нет изменения и когда есть какой-то смещение обусловлены экс мы Нарисуем вот эти бакеты наслово пря видим они располагаются как-то вперемешку друг с другом если же изменения есть то мы видим Что Ну они как-то кластери то есть их можно как-то разделить то есть и это можно определить с помощью разных критериев тот же тест например Здесь применить но мы применяем манви поскольку сточик выбросом и ещё здесь есть одна Классная штука у него очень простая интуиция то есть что фактически проверяет манви он проверяет насколько чаще вот эти кружочки оказываются правее или левее чем кружочки а то есть и он говорит фактически С какой вероятностью привык на 100% мы окажемся выше Лайна или ниже То есть он примерно то есть на более мелком эксперименте проверяет то то что мы хотели узнать то есть будет больше или меньше Да ну в чём преимущество Бакет подхода Ну это первое то что его легко вычислять он масштабируемый есть можно поке для нго и срезов этот подход он совместим с разными платформами про это Я чуть-чуть позже ещё расскажу Вот и на нём можно применять различные стат критерии Да вот собственно вот эту диалоги Мы заложили в в нашем фреймворке кофе если соберём всю эту схему воедино что мы получим то есть наш расчёт фактически состоит из нескольких этапов то есть Нам нужно первое взять какие-то данные сделать с ними произвольное преобразование Да это вот называется такой кусочек кусочек ДХ потом нам нужно из получившегося агрегата как-то вычислить фичи и раскидать их по по экспериментам и по срем которые мы считаем То есть это какой-то там первый редс который мы делаем на данных и после этого нам нужно просуммировать просуммировать все наши Все наши вот эти корзинки Да эксперименты срезы между и на итоге и в итоге получаем какие-то простые выжимки то есть мы просто складываем тесты де срезы фичи наши то есть это там числитель знаменатель метрик например и и бакеты Ну вот и всё чем чем такой подход крут да то есть Почему я о нём рассказываю в контексте Вари Куба тем что он на самом деле ложится на разные платформы Ну представьте вот мы изначально всё это написали на мапри дюсе то есть пайплайн работает как то есть копим данные за день получаем бач данных запускаем вот вот этот вот экстракт следующего дня все метрики готовы читаем выжимки получаем результат он ложится на Ну изначально мы вообще написали всё на c+ Plus после того как мы стали масштабироваться на большое количество сервисов мы сделали такую удобную питон обвязку Так что у нас любой аналитик может прийти и написать метрики Да а вот здесь выделен кусочек который реализует сам сервис То есть это ДХ и собственно вычисление фиче оста всё делается из коробки и также он ложится на realtime то есть прямо сейчас очень активно работать над тем чтобы всё вот это уметь читать уметь читать в Реал тайме именно этот этот же подход использовать А да Ну вот собственно пример такой результатов на самом деле здесь метрик может быть 10.000 такая большая простыня Да с большим количеством разнообразных метрик вот а ну давайте посмотрим а что же что же меняется когда мы делаем продукт для внешних клиентов А если мы посмотрим на продюс то получать данные на следующий день это долго то есть это прямо заставляет пользователей ждать если внутри мы можем себе это позволить за счёт ну взамен получив гибкость то здесь это очень очень плохо а но чем мы можем пожертвовать ради скорости Ну единообразие данных то есть мы как раз вот это гибкость и жертвуем то есть у нас единая модель данных которую можно положить в какую-то одну табличку да Единая система Рик и не надо отображать прям огромный ворог мерик сразу там на одной странице и оказывается что для этих нужд отлично подходит кликхаус то есть смотрите уже перешли от мадса к кликхаус вроде бы совершенно такие разные технологии но наши методологии подружились это там какие-то сессии посещение нескольких страниц и события из мобильных приложений об Метрика свои кликхаус складывает Вот как это выглядит В итоге то есть есть у нас сайты приложения в них стоят изд кашки как я ранее говорил данные логи ется в ха и в нашей админке уже тот же самый фреймворк работает который задаёт запросы А и отображает результаты поскольку мы не рисуем большую простыню метрик мы можем делать on demand запрос То есть фактически откры открывает пользователь там отчёт Да по эксперименту мы сразу генерируем какой-то скель запрос задаём е в хаус и там через несколько секунд Ну иногда там может быть 10 тире 20 секунд это не так критично уже можем отобразить результат и данные там до кли Хауса доезжают тоже достаточно ну то есть могут Ну там минуты короче Это недолго А да здесь я привёл очень упрощённый пример запроса понятно с помощью Батов можно сделать простой груба но это не всё что мы на самом деле там применяем потому что мы ещё умеем валидировать всякие определять аномалии Да в разбиении вот с помощью как раз баке тов Но это немножко отдельная тема А ну и вот получившийся наш вот итоговый отчёт А здесь мы рисуем график значит метрики по времени сравниваем наши варианты Да рисуем собственно значение метрик в и в B результат работы стат критерия и Красим в зелёный или красный зависи от изменения метрики Ну видно что мы не отобра опять же большое количество метрик за раз хотя мы идём к тому чтобы отображать несколько но всё равно здесь я думаю нам кликхаус будет очень полезен так Друзья давайте подведём итоги смотрите то есть мы масштабировать нашу платформу на внешний рынок и у нас поменялись условия то есть нас стало гораздо больше клиентов Ну в принципе изменился их состав и из-за чего нам простота стала важнее гибкости и вследствие этого мы поменяли свои технологические подходы то есть смысл идеи у нас остались теми же самыми но поменялось инфраструктурное исполнение то есть с одной стороны мы как-то поменяли а сделали более простой и быстрый механизм Выка ток Да экспериментов и А в почёте метрик вообще переехали считать на другую платформу применяет Ту же самую методологию которую мы используем и внутри Всем спасибо вопросы да спасибо это было классно поднимайте руки а задавайте вопросы Сейчас микрофончик вам будет Привет Спасибо за доклад очень интересно Скажи пожалуйста а как вы выбирали количество баке тов и обосновали его количество багетов на выбирали на синтетических теста на самом деле Вот то есть оно На что влияет То есть если баке тов слишком мало будет не информативно то есть мы ничего не просим если возьмём два Бакета это вообще как бы ни очм если возьмём баке тов много то мы получаем Ну какой-то лиш больше шума Поэтому просто выбираем какой-то баланс Ну можно там 20 выбрать 100 вот какие-то такие оптимальные для нас диапазон количество баке тов в Арио кубе сдаётся ну оно predefined или о э вся штука скрыта от пользователя то есть спасибо спасибо за доклад Букин Артём викей А как решается этот вопрос связанный Когда у нас есть бюджеты Ну например есть какой-то сервис с определённым бюджетом этот бюджет на всех узлах сервиса Ну общий грубо говоря и мы хотим катить 50 на 50 соответственно этот эксперимент нужно учесть и деление бюджетов по идее и статистики биллинга Вот как это можно решать с помощью вашей системы или Он общий а про про про Какой бюджет идёт речь Ну вот например там ну в частности возьмём там рекламный сервис тот же самый у нас получается что есть или там например личный кабинет там с каким-то баллами чем-то ещё и нам необходимо вот эти баллы списывать за какие-то там помы катим эксперимент и соответственно от эксперимента будет влиять открутка этих бюджетов и они могут на разных узлах Ну разойтись чтобы как бы как учесть эти я понял прос Ну у нас я говорил то есть мы делаем простоту и гибкость но не забываем о кастомизации то есть на самом деле в платной версии У нас есть возможность передавать кастомные параметры в наше разбиение и всевозможные какие-то Ну такие вот штуки какие-то кастомные сценарии можно с помощью них реализовывать То есть если какие-то есть показатели статистики по которым нужно что-то отфильтровать и так далее их можно просто в разбиение передавать То есть это такая кастомизация на уровне сервиса Ну то есть это нужен разработчик у себя иметь разработчика который будет эту кастомизацию пилить Или это заказывается у Яндекса это это нужно на своей стороне пилить то есть мы Цем в базовые сценарии основные Да но даём возможность кастомизировать самостоятельно И уже потом или чему-то ещё мы или по там фич флагам надо как бы делить самим на своём на своей стороне в том числе можно так то есть опять же для платных там пользователей даём возможность выгружать данные Ну типа и анализировать как-то самостоятельно если есть такая пость Спасибо Давайте так Да Данил Спасибо большое Николаев Павел Альфабанк А вот работает ли это решение для платформ моделей машинного обучения Вот то есть конкретно Ну два вопроса если вот работает сплитом вот в том числе интересно мнение прол второй версии и второе в принципе были ли у вас кейсы прикручивания вот этой бэнда связанными с метриками как раз к ai какой-нибудь составляющей спасибо Ну у нас разные есть Клиенты Конечно я не могу там весь список огласить но мы делим здесь фактически Шами да то есть вот вот и а конизацию даём Ну как я опять же сказал с помощью каких-то клиентских параметров не знаю ответил на вопрос или нет классный доклад Спасибо Смотри ты сравниваешь куб и внутреннюю Ани и как будто бы у куба есть некие особенности которые и для внутренних сервисов Яндекса могли бы быть полезными например более быстрый доезд Трик Вот и скажи пожалуйста есть ли внутри Яндекса сервис которые сни перешли на Если да то как это проходило Почему нет ну честный ответ Конечно какие-то есть это в основном там например могут быть лендинги да Потому что им очень просто можно взять и подключиться да то есть вот прямо скрипти поставить но как только появляется необходимость в какой-то кастомизации то есть здесь уже нужно интегрироваться то есть писать писать писать метрики и отвечаю на вопрос Ну и какой-то кастом може идентификатор разведения Вот Но а Отвечая на вопрос про скорость Я вот тоже говорил что мы здесь внутри сейчас прямо вот делаем realtime конр да то есть это некоторая более сложная история чем просто ну там положить данные в Хаус в единой модели да потом и запрос сдать А это Ну то есть ретай обработка есть инстансы которые читают там из очереди данные их как-то агрегирующие Вопрос такой э Если я правильно понял Навари CB вы используете только кликхаус и скармливать ему уже подготовленные скель запросы которые на лету и считают какие-то метрики а используется ли помимо вот такого подхода ещё например до агрегация там aggregate merge 3 ещё какие-то такие штуки которые досчитаю в как бы в потоке или запрос только вот и реалтай вот он сейчас посчитает и вернёт и всё Ну используем SQL запросы в кликхаус А ну матюх и соответственно уже вытекающие там таблицы хранением Ну да таблица шардирование поэтому достаточно всё эффективно выполняется у нас клиенты клиенты они не не настолько большие например как в Яндексе поэтому Ну ну типа да задаём запрос в SQL Спасибо Привет Я тут у меня есть два вопроса Первый как раз про особенность сервиса которого интернет смотрит да предположим что вам в аку пришёл крупный игрок из рунета И вам сразу 50 к rps дал Вот вы как боретесь с этим А у нас есть Рей лимите и они разные для бесплатной и платной версии Ну то есть просто Рей лимитер конфиг просто не придёт и всё да Ну да мы перестанем на э часть трафика отдавать эксперименты понял И второй вопрос Вы тесно связаны с Яндекс метрикой Понятно рассматриваете варианты других источников Google аналитика например А ничего не могу исключать больше ничего наверно сказать не могу понял спасибо Привет Спасибо за доклад Ну как я понял вы даёте какой-то стандартный набор метрик да и это на кто заводит эксперимент они могут только такие выбрать А есть ли возможность завести какие-то свои меки потому что у всех Я так понимаю конверсии разные могут быть и всё вот такое и как это происходит Это первый вопрос а второй Есть ли какие-то инструменты для валидации этих метрик ну потому что я могу какую-то метрику завести и она не факт что для тестов например подходит спасибо Ну смотри во-первых вот поговорим про конверсии да то есть метрики их небольшой набор но они параметри емы То есть например в Яндекс метрики можно завести цели то есть это какие-то целевые действия например клики по кнопки там посещение страниц и так далее вот так можно кастомизировать Да вот потом Если нужны какие-то более сложные метрики Ну есть конечно опции написать в поддержку мы на неё Ну посмотрим на обращение и мы регулярно какие-то метрики допили вот если прям нужны совсем сложные кейсы то опять же в платной версии есть возможность выгрузить данные Яндекс метрики с разметкой экспериментам и уже провести собственную какую-то аналитику собственные расчёты то есть здесь вот такую кастомизацию даём А про валидацию Ну мы регулярно сами смотрим на те метрики которые мы сами запили вот ну и любой пользователь тоже может их проверить завести контрольные эксперименты завести ещё какие-то эксперименты функциональностью посмотреть как метрики будут себя вести Да привет Спасибо за доклад и вопрос будет не совсем по теме доклада но в общем он интересен ты сказал что у вас много клиентов которые пользуются вот этим внешним решением а берёте ли вы какие-то гипотезы Может вы же можете посмотреть как в разных разрезах работают разные гипотезы от ваших собственно клиентов Ну то есть вот эти пробуют на фронте делать Вот это а и Затем вы можете эти гипотезы если они выигрывают регулярно пытаться имплементировать в Яндекс в общем делаете ли вы такое Ну я понимаю что провокационный но Ну мы серьёзно относимся к данным пользователя это прямо серьёзная тема Я понимаю поэтому я говорю только лишь о гипотезах мы к данным пользователя относимся очень серьёзно мы их не обм хорошо Привет Данил интересный доклад был Я Марк услышал ответ про нагрузку по поводу РПС А вот интересно как вы справляетесь если у вас там большое количество экспериментов и сервисам нужны прям большие конфиги То есть я понял то есть много экспериментов да типа Много всего это делается тем что это доступно п платным клиентам Вот какие там лимиты есть что ещё раз то есть есть какие-то лимиты по Да конечно то есть есть лимиты То есть например допустим два одновременно запущенных для бесплатных там и 100 запущенных для платных там и в конфиге флагов там тоже есть свой лимит естественно То есть у платных они там значительно выше Конечно есть защита от переполнения а порядок примерно а порядок можно вот я сказал пример для экспериментов всё остальное Ну вот можно зайти посмотреть в документации у нас второй вопрос я так понимаю большая часть завязана вот таргеты сбор данных из потока с Яндекс метрики и только из него или есть возможность или вы планируете в будущем дополнительный какой-нибудь очередь тире датастрим от заказчика имеется в виду чтобы он уже проходил также на кликхаус и дальше уже обогащался ну то есть дополнительное обогащение данных не из Яндекс метрики Ну ничего не могу исключать прямо сейчас такого нет но что можно сделать То есть сейчас опять же р у нас Мы отдаём из разбивалки Ну как бы разметку саму то есть её можно самостоятельно Загирова например в свои какие-то логи и сделать самостоятельный расчёт это вот можно сделать прямо сейчас Ну кроме выгрузки именно вгруди насколько у вас будет сильно отличаться тенси если допустим порядка 100 ашек или флагов и там 100.000 Ну вот прям просто 100.000 не скажу но должно быть не сильно но понятно что 100.000 если включаешь Ну во-первых мы такого не позволяем по лимитам Вот но там что будет е там будет сетка е Да понятно что пользователь же как-то посетить данные получат как-то как-то изменится но должно быть не супер сильно в пределах лимитов так ещё последний шанс задать вопросы и кажется мы подходим к завершению и здесь самый сложный вопрос чей вопрос понравился больше всего Ой сейчас поду Да все вопросы хорошие Слушай давай выберем какой-нибудь один который особо запомнился А ну вот мне понравились вопросы как раз связанные с не знаю с кастомизацией как-то вот счёт метрик ой вопросы с кастомизацией поднимите пожалуйста руку кто их задавал ей отлично А вам подарок Спасибо огромное за доклад спасибо спасибо А вам всем Угу что пришли послушали"
}