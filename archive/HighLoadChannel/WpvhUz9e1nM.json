{
  "video_id": "WpvhUz9e1nM",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Да Всем привет меня и правда зовут Дима Я из Яндекс 360 и там делаю сервис диск про одну из фич его сегодня вам и расскажу как мы пришли к такому решению Как сделать у вас похожее и может быть даже получше Ну первый слайд классического о себе Я более 5 лет работаю в it основное опыт из этого в диске и последние полтора года руковожу командой бэнда и активно вот поддерживаю вот эту фичу про которую буду говорить как любой проект э фича начинается с задачи задача звучит Ну расплывчато Как и любая большой проект э и у нас была задача такая нам нужна какая-то Лента со всеми фотографиями в диске она должна выглядеть примерно как локальная рели на телефоне пользователь должен мочь её там скролить перематывать на нужные места Ну и все плюшечки должны быть что и в современных телефонах ээ в их галереях конечно к задаче прикладываются макеты они выглядели примерно так нам нужно было сделать версию для браузера слева на скриншоте и версию для мобилки тоже должна бы быть поддержана в таком варианте требования Это замечательно но Давайте попробуем их как-то формализовать во-первых нам нужно чтобы в этой галерее у нас были все фотографии с диска пользователя и они должны быть отсортированы по дате их создания по дате именно настоящего создания а не там дате загрузки в диск или ещё какой-то дате изменения должна быть возможность смотреть эту галерею в вебе и в мобильной версии приложения и Кроме этого в мобильной версии должна быть дополнительная возможность синхронизации чтобы пользователь сразу заходил в приложение и не видел никакой Робер сразу мог смотреть свои фоточки и наслаждаться контентом должна быть возможность этой галереи проты на любую дату чтобы пользователь бесконечно не пытался до скролить до своих старых фотографий там 2017 год э прям тыкал на панели навигации Вот который справа на скриншоте вы видите на нужную точку и фотографии оттуда подгружать Ну и последнее но там не по значению требования вот панель навигации что вот я говорил справа она должна показывать За какие даты Сколько фотографий вообще сделано например вот это фотография из моего диска видно что за 2024 год я уже успел сделать больше фоток чем за 2023 и это должно быть ээ пользователю Понятно Вот такие были требования О чём же будет этот доклад в этом докладе всю фичу охватить не получится она сильно масштабная и можно сделать ещё несколько докладов про другие её аспекты но я расскажу Подробно как мне кажется самой интересной части про синхронизацию метаданных для этого раздела фото как у нас всё это устроено почему выбрали именно такие решения и про это будет основная часть немножко затронуть тему кластеризации фотографии по дате что это такое зачем мы это делаем И как это нам помогает синхронизацией и опять же все эти пункты будут привязаны к синхронизации на устройство и затронули на клиентах ну без неё никак тоже Пару слов про неё скажу и как раз привязано к синхронизации чтобы отметить полностью охватить наш подход когда начинаем проект Т оценить нагрузки ретроспективно по данным Ну вот тогда мы прикинули что вот мы цели и пытаемся построить систему под Такие показатели у нас будут тысячи фотографий новых каждую секунду появляться у пользователей rps на синхронизацию тоже будут измеряться тысячами хотим построить систему в которой у пользователей могут быть сотни тысяч фотографий и она корректно с ними работает Они корректно отображаются быстро синхронизируется и ну выглядят примерно так же как и не знаю там 100 фотографий У пользователя и почитаем обм данных который нам потребуется дополнительно для синхронизации почитали нам потребуется десятки раба метаданных поранить чтобы это синхронизация работала Ну и это всё Мы положим в десятки шардов постгрес про него оговорочка сделаю Чуть позже это дополнительны и данные для синхронизации а не там метаданные самого диска перед тем как всё это делать нужно разобрать как же работает Зару идам чтобы делать нашу фичу Ну всё начинается с того что приходит пользователь он говорит Вот я хочу загрузить файл приходит он на наши сервера загрузки который называется алор дальше когда файл загружен алор присылает события в файловую систему что файл загружен файловая система - это отдельный сервис в диске он стоит сво хранит в базе в постгрес и сервис на питоне который обслуживает все события загрузки скачивания перемещения и все такие действия с файловой системой туда приходят события и файловая система сохраняет всё это дело в базу основная база диска она тоже У нас шардирование файла дата в которою файл был загружен и вот и информация она у нас уже была это я думаю Многие знают действительная дата когда сделана фотография Вот именно по ней мы будем сортировать тут сделаю оговорку что про шардирование э в этом докладе ничего говорить не буду мы рассказывали Андрей кол научен рассказывал на предыдущем хайлоу де Подробно как у нас устроено шардирование А все базы у нас по шардирование таким же образом Единственное что скажу что у нас шардирование по пользователю э ну и наверное всё для доклада остальное Неважно а начнём же наконец пытаться проектировать ээ вот эту систему э которую мы запланировали э начнём с последнего требования которое я ээ отмечал с панели навигации Вот она выделена рамкой э справа на скриншоте и для того чтобы её сделать мы сразу понимаем несколько вещей во-первых нам нужно понимать ээ сколько у нас фотографий За какие даты У пользователя чтобы её построить намм когда мы смотрим макеты понимаем что рисовать эту панель нам вообще нужно до загрузки первых фотографий потому что пользователь сразу может захотеть снаги в какое-то место не дожидаясь э загрузки первой фотографий и смотреть там за старое время фоточки Ну это нас всё приводит к тому что нам нужна какая-то структура которая хранит количество файлов за разные даты ну Давайте попробуем такую структуру придумать первое что приходит в голову Ну давайте возьмём статистику за день вот там возьмём допустим у меня 1 января 10 фотографий 2 января пять фотографий за 4 января я там ни одной не сделал и попробуем поранить Вот в такой простой структуре Но тогда мы столкнемся проблемой что мы планируем что сервис просуществует долгие годы и за долгие годы скопи 1.000 дней со статистикой у активных пользователей и нам все эти там тысячи десятки тысяч записей придётся каждый раз отдавать на фронт энд чтобы эту панель отрисовать и всё это усугубляется тем что есть ещё старые архивные фотографии которые там пользователи загружают которые были сделаны до там старта диска и это количество будет расти и расти и в какой-то момент сломается и будет плохо работать такого мы не хотим допускать Ну раз ээ за оди день плохо Давайте попробуем статистику за месяц может быть станет получше будет она выглядеть примерно как в таблички с правой части слайда Но тогда мы столк с новой проблемой если фотографий за один месяц очень много то внутри нам достаточно тяжело навить скажем там у нас 100000 фотографий пользователь сделал за оди месяц и когда он нажимает на диапазон Рон я 100000 фотографий нам нужно как-то рассчитать какие именно показать там нужно ли какой-то лимит of Set или какую-то интересную пагинацию городить Чего делать не хочется это вызывает дополнительные проблемы Ну и если вам показалось что Ну за один месяц количество фотографий которые может сделать один пользователь ограничено каким-то разумным числом там скажем 10.000 что это не так Потому что есть всеми нами любимая дата 1 января 970 года за которую Ну бесконечное число фотографий и новые будут появляться потому что эта дата проставляется когда слетает информация там Тулы С багами частенько могут её проставлять и это ну не секрет что это самая частая дата фотографии в диске эти фотографии будут появляться и появляться и их количество просто безграничное и никакими разумными оценками не ограничивается Ну хорошо попробовали сде статистику за день и статистику за месяц на ничего не получило но мы вынесли классный Вывод что нам нужен динамический размер окна за который мы будем подсчитывать Сколько фотографий У пользователя Чтобы избежать проблемы и с большим диапазоном и с маленьким фотографий за одно время и набор такой фотографии я буду называть кластером а процесс их составлением кластеризации поговорим про сами кластера нам нужны определённые правила по которыми они будут формироваться чтобы мы смогли избежать проблем о которых мы говорили выше и вот Первое правило оно самое понятное Каждая фотография должна попадать только в один кластер Ну это логично Мы хотим каждую фотографию показывать только один раз а следующее правило э может показаться интуитивно не очень понятны но сейчас я про него расскажу Вообще даты фотографии в кластерах у нас должны быть не дальше 5 дней друг от друга Мы хотим рядом складывать только фотографии которые сделаны за одно время чтобы когда пользователь ээ нажимал на какой-то диапазон мы однозначно могли определить какой кластер грузить если скажем у нас будет там кластер известно что за весь год У пользователя 10 фотографий и он нажмёт там в середину достаточно проблематично отрисовать панель навигации там сколько За какой месяц если у нас будет такая большая дискретность наших кластеров следующее - это то что фотография в кластере должно быть не очень много вот не очень много мы выбрали как 10.000 мы посчитали что на этом Об Нет проблемы Что у нас много фотографий в кластере и в нём сложно навить и тут мы без проблем можем сделать навигацию внутри а Чтобы избежать проблем вот сильно больших кластеров и последнее фотографий в кластере должно быть много э хотя бы не меньше десяти Потому что если у нас там на каждую фотографию мы сделаем по одному кластеру Это вроде не противоречит всем предыдущим условиям но в этом смысла Никакого не будет мы же хотим э как можно меньше информации отдавать на фронтенд как можно быстрее рисовать панель навигации значит фотографий должно быть в десятки сотни ты Ой ну да фотографий должно быть в десятки сотни тысяч раз больше чем кластеров чтобы это хорошо работало это правило для юзеров у которых много фотографий Понятно есть там крайние случаи когда фотографий мало но их оть не буду можем обсудить там после доклада если будет интересно посмотрим как концептуально выглядит наше решение Мы помним что файл загружается на диск новый попадает в файловую систему файловая система может понять что это фотография у неё есть вся информация про метаданные и добавляется Новый сервис который называется кластеризатор его Задача будет составлять кластера по правилам которые мы посмотрели на предыдущем слайде и если они уже есть то актуализировать информацию чтобы контракты с предыдущего слайда были соблюдены хорошо нам потребуется ещ один сервис серс будет Нава это будет сервис для синхронизации данных Зачем нам отдельный сервис мы сейчас выясним по ходу повествования но верхний уровень его Нам нужен чтобы удобно разложить данные для клиентов и быстро мочь их отдавать и тогда кластеризатор обновит кластера у себя отправит события в срш что они изменились SM обновит и прит на клиент что вот новый раздел фото появись новые фотографии можно их отображать начнём с первого сервиса кластеризатор У нас тут есть две больших задачи которые нужно решить первая задача Ну мы делаем фичу Когда уже у пользователей в диске существуют фотографии они расстроятся если они не попадут в наш раздел фото поэтому все эти фотографии нам нужно кластеризованный способом например самым простым Давайте загрузим фотографии одного пользователя в память кластери их и запишем результат Да это затратно по ресурсам Но такую задачу мы делаем ровно один раз и Ну ничего страшного не случится если мы потратим больше железа на неё но сэкономим время разработки хорошо есть вторая более интересная задача - это поддержание инвариантов кластеров про неё можно вот наверно сделать отдельный доклад по каким принципам лучше выбирать алгоритм по которым составлять кластера и как их обновлять может Что можно сделать такой же вариант как в инициализации действительно можно но он будет хорошо работать там на десятках тысяч фотографий а если у нас их станет сотни тысяч как мы планируем то у нас начнутся большие проблемы начнутся большие задержки для пользователей фотографии Бут дольше попадать в раздел фото и всё это будет работать не очень хорошо тут лишь скажу что нужно выбирать баланс между там сложностью реализации которая возникает у нас при более сложных вариантах и потреблением ресурсов а что же такое сами кластера сами кластера у нас выглядят примерно следующим образом э вот допустим есть кластер оди в нём есть Мета информация про первую фотографию про её дату про последнюю и количество фотографий внутри собственно вот этих трёх данных нам достаточно чтобы построить панель навигации Если мы будем знать про каждый кластер Ну и внутри каждого кластера содержатся фотографии у них много параметров но основные перечислены на слайде ID Понятно зачем чтобы запросить оригинал фотографии и отобразить его пользователю а ширина и высота нужны чтобы фронтенд мог заранее узнать какие фотографии с какими размерами будут отображаться и отрисовать сетку и она не прыгала у пользователей в момент подгрузки фотографии и был плавный и Гладкий User experi и пользователи были довольны перейдём к следующему сервису к сервису SM сервису низации и чтобы разобраться как он устроен нам нужно ввести два новых понятия первое понятие - Это сшт снапшота я буду называть слепок состояния базы с некоторой версией Ну и в нашем случае спш будет выглядеть как набор кластеров вот как на картинке справа есть кластер оди с набором фотографий есть кластер 2 с таким-то набором фотографий и так далее Это будет наш спш для клиентов Это просто будет выглядеть как некая Джена в которой всё вот это перечислено и второе определение которое нам потребуется это Дельта Дельта я буду называть итеративности о и в нём удалилась фотография о и добавилась фотография 5 и это мы будем считать назвать дель зам же это нам ставим что у на Лите формация про первый кластер мы получили энда Дельту допустим такую же что удалилась фотография о добавилась фотографию 5 мы можем применить её локально и получить СШ следующей версии не перекачивает мы будем использовать Ну зачем это нам нужно допустим у меня в диске 10.000 фотографий нужно доста ного информации выть чтобы пользователю весь раздел фото скажем Наде сегодня познакомился с де людьми как обычно сделал с ними фотографиями скинул им в Telegram у меня появилось на диске 10 новых фоточек Ну и 10 новых фоточек отправить дельтами сильно проще собственно в раз чем перекачивать все данные поэтому это в нашем случае на больших объёмах фотографий будет супер эффектив птах должны быть супер простые операции которые на клиентах легко повторить желательно в них должно быть невозможно на бажи и хорошо бы чтобы они покрывали больше сценариев ээ чем наш Этот проект потому что нам захочется их переиспользовать в других проектах мы выбрали следующие три что у нас создано новое Поле или объект изменено существующее поле или удалено какое-то поле собственно эти дельты покрывают почти все возможные сценарии А и их можно переиспользовать в других проектах чем мы и занялись дальше пойм как у нас со всем этим работают клиенты потому что мы разобрали только часть клиент логика на клиенте немалая составляющая всего этого проекта всё начинается с того что пользователь устанавливает приложение скачивает скачивает диск устанавливает приложение заходит и хочет посмотреть раздел фото получить актуальные на что ему срш отвечает хорошо Вот snapshot у него версия такая-то Вот тебе данные дальше клиент переходит в следующее состояние что у него есть snapshot некоторой версии N и он хочет получить обновление он приходит с таким запросом говорит У меня есть такая версия хочу получить обновление Ну и срш присылает ему дельты с версии n по актуальную клиент их применяет локально как мы говорили ранее и получает актуальную версию данных у себя тут стоит отметить что если мы хотим чтобы данные У пользователя новые появлялись во время использования приложения то в такой схеме нам придётся бесконечно полить наш энд что создаст немалую нагрузку от всех активных пользователей диска а всё-таки подгружать данные онлайн когда пользователь находится в приложении Мы хотим Ну для этого давайте сделаем следующую вещь Пусть клиент придёт и скажет знаешь я хочу получать все уведомления об изменении этих данных если что-то изменится обязательно Пришли мне пуш и установить соединение с сервером пушей срш скажет хорошо И когда действительно что-то изменится срш пришлёт пуш клиент поймёт так появились новые данные Мне нужно сходить с тем же запросом что и на прошлом слайде также говорит У меня есть сшт версия N получает дельты применяет их локально тут может произойти такое что соединение с сервером P порвётся Ну тогда мы не можем гарантировать что новых данных не появилось в этот момент и мы переходим в последнее состояние мы запрашиваем актуальные данные если они есть и начинаем эту схему сначала устанавливаем соединение с сервером pus подписываемся на изменения и поехали по кругу и Вот так мы получаем что прямо во время использования приложения У пользователя будут появляться новые фоточки и это огромную нагрузку на наш Кэн не создаст пропорционально число пользователей а только пропорционально число загрузок есть ещё один сценарий который Нужно рассмотреть может быть такое что придёт клиент С тем же запросом что мы видели уже несколько раз говорит Хочу получить обновление а срш ему на это ответит знаешь версия такая старая что у меня Дельт к ней нет Или может быть знаешь так много всего изменилось что тебе проще пере выкачать спш чем Взять все эти дельты скачать их и применить локально Ну или ещ одна из множества таких причин Ну тогда клиент сбросит у себя всё состояние и начнёт с самого начала с первой картинки пару слайдов назад этой диаграммы скажет удалит все локальные данные и придёт таким запросом У меня нет данных и всё начнётся это по кругу диаграмму клиентов разобрали но у нас есть проблема здесь что мы все изменения как минимум дублируем записывая в дельты иногда дельты будет занимать ещё больше места потому что у нас произошёл апдейт основные данные мы Обновили а Дельту которая к нему привела всё равно придётся записать в базу и эти дельты начнут занимать у нас основное место в базе если мы ничего не предпримем а такого делать не хочется это нас приведёт к тому что нужно делать новый шарды нужно будет пользователей между шарда перевозить А это дело непростое возможно слушали сегодня доклад в Башне который про это Рассказывал Ну и поэтому мы решили что дарите нужно чистить основной вариант возьмём оптимистичный на чистку Дельт мы знаем какие пользователи к нам приходят мы знаем за какими версиями они приходили Ну и мы без проблем можем посчитать за какими дельтами точно уже никто не придёт что все устройства пользователя уже получили эти дельты и они никому не нужны и их можно удалить и постараемся чтобы это стало нашим Основным способом чистки Конечно есть варианты что пользователь приложение Может просто не запускает приложение почему-то не обновляется Ну тогда давайте выставим Т на время де и сделаем ограничение по количеству де ИТ ограничение на количество сделаем очень большими чтобы у нас в основном срабатывал первый сценарий оптимистичный вторые два как раз будет у нас лком если пользователь удалил приложение или у нас произошло так много изменений что проще перекачать спш и эти Тогда смысла хранить нет хорошо с читкой разобрались но у нас есть е пару пробле кото решают нашей вот этой системе успешно лететь в продакшене одна из них это то что вообще у пользователей фотографий очень много их сотни тысяч как я говорил в начале мы планируем чтобы у нас всё с этим работало А значит сшт будет очень большой на сотни тысяч фотографий это много Мета информации А если спш большой он может измениться в процессе его нельзя там получить быстро за один запрос нам нужна какая-то пагинация при пагинации если что-то изменяется в процессе у нас становится ВС плохо данные разъезжаются теряется консистентность этого хочется избежать избежать можно достаточно стандартными для такой задачи средствами давайте сделаем несколько контрольных точек будем хранить для каждого пользователя несколько Слепков сшов в базе иногда делать такие чекпоинты чтобы если клиент начал получать какую-то версию он мог её до конца СМИ проблеми нел все в и эффективно получать с клиента За один запрос без проблем ть или получать их по частям то есть мы туда будем класть такую жену как получает клиент он просто е скачивает И для него ничем этот ответ не будет отличаться от на нашем хорошо это по такой что пользователи загружают фотографии пачками Прим пачками За одно и тоже время допустим сейчас пользователь сделал там 10 фотографий они за одно время они скорее всего попадут в один кластер и создадут много апдейт по одному и тому же кластеру в базе или там другой сценарий может быть Вам ближе знакомый сейчас закончится конференция будут фотографии с конференции Возможно вы получите индекс нить к себе и вот у вас уже плюс 2.000 новых фотографий там заодно нажатие кнопки которые нужно добавить Ну кластеризованный синхронизация раздела фото А и всё это приведёт если ничего не делать Вот там к 2.000 апдейта скажем по одному и тому же кластеру этого хочется избегать потому что апдейты одного и того же кластера это дорого Ну и решение тут тоже понятное мы можем агрегировать такие обновления и применять за одну Дельту Ведь мы знаем какие кластера изменились и можем по ним делать отложенное обновление на пользователя это не сильно повлияет А нам очень сэкономит нагрузку на базу и на наше приложение замечательно мы сделали отдельно кластеризации и синхронизацию Давайте посмотрим как получилось вроде получилось хорошо и поймём почему во-первых хорошо потому что мы отправляем только то что изменилось и там для типичных дисков польз которых много фотографий это в сся раз меньше данных мы отправляем чтобы синхронизировать данные на клиенте кластеризация нам вообще позволила реализовать панель навигации достаточно задёшево Ну в целом этого мы её и затевали Но кроме этого она ещё помогла наше синхронизации Достаточно неплохая Синергия получилась потому что у нас кластера небольшие и мы можем внутри нашей системы гонять допустим обновлять делать обновление только кластерами и это вот как мы смотрели на предыдущем слайде позволило сделать оптимизацию и уменьшить нагрузку на базу хорошо с энной частью более-менее разобрались осталось нашу фичу поддержать на клиентах понять что нам делать Давайте начнём с Веба там было меньше требований алгоритм у нас примерно следующий пользователь заходит на страничку мы первым делом забираем Мета информацию о кластерах это там э список кластеров даты начала конца в нём и количество фотографий э э информация кластеров у нас не очень много информация весит мало всего там три Полюшка э очень быстро получаем и отрисовывать панель навигацию то что справа на скриншоте дальше мы понимаем пользователь никуда не листает ээ берём последний подать кластер запрашиваем Какие фотки в нём есть получаем Мета информацию о них знаем там ширину высоту и дишни отрисовывать все кто сетку начинаем запрашивать контент пользователь видит свои первые фотографии Если вдруг пользователь нажимает на какую-то часть панели навигации то мы без проблем можем определить что это за кластер в этом кластере все фотографии рядом для этого мы их и клали и без проблем можем понять Какие из них нужно отрисовывать соответственно доливаем до этого места также рисуем сетку рисуем фотографии из нужного кластера замечательно на поддержали Давайте пом на мобилках там у нас было больше требований были требования про синхронизацию Ну и начнём всё с того что когда пользователь устанавливать приложение запустим синхронизацию метаданных О кластерах это вот всё то что мы смотрели на трёх слайдах про схемы запрашиваем Snap запрашиваем Дельта если пользователь находится в приложении устанавливаем соединение с сервером P если что-то изменилось в реалтай покачивание показываем пользователю если появились новые фотографии Если вдруг у нас случилось такое Что синхронизация ещё в процессе или там почему-то не может выполниться или что-то ещё с ней случилось то мы можем ться на работу как и пользователь у нас тогда не будет видеть там долгий трор мы сработаемся подгрузка новых фоточек Но это у нас к сценарио не должен срабатывать часто в основном у нас будет первый вариант поэтому ничего страшного тем более Ну это лучше чем показывать бесконечный Робер пользователю Теперь соберём всё что у нас было в одно единое мы разобрали по кусочкам всё начинается с того что пользователь загружает файл на наш сервер загрузки файл попадает на файловую систему файловая система понимает что э фотография идт в кластеризатор говорит что нужно обновить кластера кластеризатор обновляет кластера соответствуя тем правилам что мы обсудили и про обновлённые кластера пролил вперёд Но ничего страшного про обновлённые кластера отправляет информацию в Smart что кластера обновились СШ подготавливает у себя информацию для клиентов то есть обновляет спш пишет дельты которые к нему привели и если есть подписанные на пуши клиенты отправляют им пуш о том что нужно данные обновить хорошо Всё мы собрали какие выводы из всего этого можно сделать Ну во-первых подход с такой синхронизации в нашем случае Очень эффективен потому что у нас много данных изменяется данных не очень много и там в тысячи десятки тысяч раз меньше данных мы пересылаем от сервера клиенту для обновления раздела фото и вообще для того чтобы это реализовать нам потребовалось не так-то много нужно написать серс который делать для него опиш поддержать на клиентах пяток сценариев и вот у вас уже есть синхронизация Прим которую можно переиспользовать и в других проектах и в некоторых мы её переиспользовать сделали кластеризации позво оперировать небольшими дан ци достаточно безопасно и быстро Ну и третий совет он универсальный для многих докладов вообще вот эту задачу и многие другие можно решать с разной степенью эффективности и затрат и всегда смотрите на ваши объёмы на ваши требования возможно вам не нужно часть того что я здесь рассказал или наоборот Нужно больше или там можно сэкономить ресурсы разработки и сделать систему попроще которую не только проще разрабатывать но и проще поддерживать а на этом У меня всё спасибо за внимание так смотри тебе нужно выбрать Два лучших вопроса за один ты подаришь подарок от Яндекса и за второй нашу супрематический делай пометки иначе это будет неподъёмная задача и начнём мы с ближней правой части зала Привет Спасибо за доклад и за фичу сам пользо очень нравится но хотел бы спросить про такую боль свою небольшую с этой фий связанную она заключается в том что Ну вот у меня это не так сильно проявляется но допустим у подруги по работе приходится очень много фоток загружать на диск которые не е и она не хотела бы их просматривать и хотелось бы иметь возможность какие-то фолдер ставить галочку типа не загружай Мне в Ленту вот эти штуки а рассматривали ли вы такое думали про это или может что-нибудь такое Да спасибо за вопрос э в целом такие фич реквесты иногда мы рассматриваем принимаем но чтобы про них там узнали нужно написать к нам Ну в суппорт можно написать такой фич реквест ели таких реквест будет достаточно много то я думаю мы можем сделать такую фичу но сейчас такой в активной разработке такой нету Следующий вопрос центральной части зала Дим Спасибо доклад классный функциональный супер Вопрос вот у нас самая популярная дата фоток семидесятый год 1 января наверняка там больше 10.000 фоток А из доклада Я понял что сортировка у нас делается именно по датам то есть внутри 1 января как мы сортируем кластера которых Там должно быть много Да Ну вот как раз за 1 января фотографий может быть очень много поэтому мы делаем динамическую чтобы это 970 год разбить на кусочки и синхронизировать их чтобы в них было меньше 10.000 элементов и их удобно было синхронизировать и навить внутри а внутри одной даты за одно время Ну можно сортировать как угодно обычно для этого использовать там какой-то второй ключ допустим по названию файла если у вас дата одинаковая следующий кластер вопросов из дальней части зала прошу Дмитрий Спасибо за доклад у меня такой вопрос про Smart cash дельты бывают разные спш тоже какой алгоритм определяет отдавать сшт или Ну вот вы сказали что Дельт может быть слишком много и проще отдать сшт вот какой алгоритм это определяет насколько он сложен Да спасибо за сказал спасибо за вопрос Да хороший вопрос не забудь помечать Хорошие вопросы а то забудешь помечают запроса точно оценить мы знаем размер снапшота кото нас лежит в базе мы знаем примерно размер дельты Да дельты бывают разные Но в среднем они примерно одинакового размера и поэтому можем во время за что выгодней Ну и в целом там у нас есть такая оценка что если де очень много вот как и говорил про чистку то мы их начинаем почищу кейсов которые мы оптимизировать не хотим А наверное так вот мы если очень много Дельт почищу во время запроса можем определить теоритически что больше снапшота или там эн Дельт которые нужно отдать Спасибо подробности Обсудим в кулуарах следующий вопрос снова В центральной части зала Привет Да спасибо за доклад очень хорошая пушка Резник из МТС Смотри такой вопрос прояснить недопонимание видимо некоторое на телефоне у меня в Яндекс клауде появляется фильтрация хочу получить фотки 9 на1 либо хочу получить все фотки Ну с моим лицом допустим да Если я правильно понял кластеризация у вас происходит на когда фотография добавляется формируется некоторые кластеры а при отдаче фотографии берутся уже готовые кластеры Да сформированные считаешь ли Ты что при фильтрации нужно переформировать кластер на основе отфильтрованных данных и как бы ваша система отработала в данном случае да спасибо за вопрос ты говоришь немножко про другую задачу У нас кластеризация именно для Ну вот подати для раздела фото есть всякие там фичи льные допустим с распознаванием лиц там и с альбомами по лицам людей они у нас тоже работают или с оценкой красивости фотографии чтобы одни показывать больше другие меньше они нас тоже работают при загрузке Ну и мне кажется тоже они должны работать при загрузке формировать там кластера по человеку и на запрос отдавать эту информацию чтобы было быстро Следующий вопрос всё ещ с нй сти зам сну вво доклада упомянул о некоторых ограничениях которые накладываются на кластеры в частности о 10.000 фотографий которые в нём есть а и вопрос Это строгое ограничение или нет объясню что я имею в виду допустим некий кластер охватывает 3 дня а двадцать пятое дцать чет 23 июня этого года и распределение 45 10 и 45% наконец-то я добрался загрузить фотографии за двадцать четвёртое А их там порядка пятиста А ну и 10.000 Я уже выел их порядка 500 сейчас если я их загружу у меня верхние фотографии с сегодня должны переч куда-то ещё те оттуда ещё куда-то и так далее перестроить кластеры полностью вот или Мне проще легче запихнуть эти 500 в кластер который уже содержит 10.000 и сказать Ну 10500 тоже норм ну нет всё-таки должно быть какое-то строгое ограничение Потому что так мы будем бесконечно бесконечно раздавать лае в какой-то момент нач проблема много Ну это небольшая проблема там посп кластер на две части и фотографии запихнуть в один из них скорее вот такой алгоритм что мы кластер разделим на два кусочка эти фотографии положим в один из этих кусочков Да это ну выталкивание вверх вот как ты описал это есть с ним проблемы очевидные вот а со сплитом чуть получше ситуация начинаем смещаться вправо относительно нас и влево относительно спикера Следующий вопрос при доклад очень круто Вопрос такой кластеризация даже если это ну как бы кластеризация в любом случае это СБА задача И когда у нас огромный там поток изменений апдейт проблема с тем что может быть недостаток ресурсов вопрос в том как вы эту проблему решаете потому что кластеризации ну придётся очень много раз запускать Да спасибо за вопрос Ну мы тут проблему решаем стандартным способом У нас есть очеред Ну на обновление кластеров и Ну она ба правда задача но не всегда можно за квадрат делать условно загружая всё в память и кластери А можно там более Умно допустим понимать какой Ну в какой кластер эти фотографии попадут и там загружать только соседние и делать ним нужные операции там или Сплит или добавление фотографии в нужный кластер Ну и решаем что если есть какие-то проблемы у нас есть очередь входящих и она начинает немножко копили проблемы на кластере А ну доки железо в общем как стандартные инциденты решаются Следующий вопрос ещё левее прошу Здравствуйте спасибо за доклад э вопрос по поводу превью фотографий делаете ли вы какое-то сжатие их на стороне клиента или бэнда А Или вы отдаёте их в РАУ формате которые были загружены Например если загрузить там фотографию снимка космоса размером 1 ГБ Будет ли будете ли вы что-то с этим делать спасибо да спасибо Да ты правильно отметил Что обычно в таких системах не показываются оригиналы фотографии а показывается там некое превью мы при загрузке делаем э превью разных размеров под там разное качество сети и устройства и показываем э ну кропнутая версию фотографии ээ которую запрашивает клиент под его настройки там сети э возможности экрана и всё с ним связано так Давайте ещё три вопроса Ладно четыре вопроса и остальные Обсудим в кулуарах в левой части зала прошу Спасибо за доклад Меня зовут Евгений Я хочу задать вопрос точнее два один маленький какой тип баз Нет давай только один очень много вопросов какой тип баз данных вы используете под кластеры Спасибо Какой тип баз данных да Да давай синхронизация у нас лежит в постгрес вот данные про синхронизацию в шардирование он так же как все наши другие постгрес где вот я показывал кор кодик можно посмотреть как Угу нюансы Обсудим в кулуарах второй вопрос из четырёх О'кей привет от Яндекса э Каким образом на в интерфейсе на панели навигации решается проблема нулевого тайм смпа то есть там человеку показывается 1970 год или там показывается минус например зайдя туда не зная о такой проблеме Я бы испугался увидев там семидесятый год что там нарисовано В таких случаях У меня нет таких фотографий я делаю фотографии за современность но я думаю там написано 970 год а потом идёт там 2000 идёт третий вопрос из четырёх Спасибо за доклад У меня вопрос про спш и Диф Ну ты рассказывал есть проблемка когда фов слишком много и нужно Как чистить по ТТ и так да рассматривали ли вы кейс Когда можно Диф по мержить и Ну тем самым количество уменьшить Да вот решали и Не решали Да спасибо это тоже очень хороший вопрос действительно не забывай их записывать всё я записываю да есть второе решение этой проблемы можно как-то дельты уметь бачева куда-то там складывать в услов чтобы они там в басе место не занимали и уметь отдавать для себ варин чисткой потому что для этого проекта Ну получалось избыточно эть там достаточно сложная логика Кроме того как вать нужно уметь отдавать ответы клиентам если они запросили какой-то этот диапазон и в целом это чуть сложнее сделать поэтому выбрали вариант в пользу простоты реализации и наконец завершающий вопрос этой сессии справа от спикера в дальней сти зала доклад хотел развить тему насчёт превью То есть вы сказали что вы их нарезает новае Ну новые размеры которые надо нарезать Что вы делаете со старыми фотографиями Да давай про превью тогда более полный ответ мы делаем как все примерно превью сначала нарезается какой-то там ну назовём его мастер превью самого большого размера который занимает не очень много места и и под все остальные размеры мы не прямо сразу нарезаем А если нужно дорем в Реал тайме и сохраняем в кашик чтобы быстро давать следующие версии такой фоточки если нам нужно разрезать новые версии Ну мы просто в Реал тайме кроп нем побольше Спасибо тебе большое И сейчас мы будем дарить призы в количестве двух штук я попрошу моих помощников принести эти призы А тебя я попрошу в начале выбрать Кому мы подарим приз от Яндекса стате у вас будет подарок от Яндекса за вклад в конференцию это круто Это приятно за какой вопрос Да мне понравился вотт человек в розовом был сбоку сидящий человек в розовом Поднимайся на сцену Яндекса и второй приз наша супрематическая матрёшка от онтика которая будет с уникальным дизайном для каждой конференции кому мне тоже челок воро толь теперь вот здесь понравился е один гость в розовом Аплодисменты и супрематическая мат решает наш спикер матрёшка сувениры диплом о том что ты выступил дарите Спасибо тебе"
}