{
  "video_id": "CW5YybMziRM",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "привет мив привет привет Слушай а для чего вы так растёте вй раз у вас постоянно потому что можем Но отлично Я начало доклада прошу тебя за трибуну и друзья не забывайте переходить по QR коду У нас есть чат где можно задать вопросы и пообщаться с спикером позже Спасибо Всем привет Меня зовут Женя я работаю в Авито и руковожу командой которая разрабатывает продукт Авита автозагрузка это инструмент для продавцов с помощью которого они могут массово управлять своими объявлениями на наших площадки в следующем году нас нам исполнится 10 лет и семь из них график нашего роста выглядел примерно Вот так мы привыкли к таким темпам потому что каждый год автозагрузка где-то в полтора-два роза мы следили за тем чтобы у нас был какой-то запас прочности на год-два вперёд но никогда не пытались полностью раскрыть весь потенциал системы потому что с таком с такими темпами этого просто не требовалось но всё изменилось когда в конце двадцать первого года компания готовилась к запуску новой модели за размещение объявлений и по прогнозам за тре год мы должны были вырасти больше чем в 20 раз мы точно не были готовы к таким цифрам и самое ужасное что мы даже не знали на какой отметке всё сломается на Питере я рассказывал как мы готовили к такому росту один из наших сервисов который скачивают фотографии тогда я показал его архитектуру рассказал про её основные проблемы и решения которые нам тогда помогли Но прежде чем решать проблемы их нужно было сначала найти и в этом докладе я чу рассказать о том как мы вообще лись найб меша нам вырасти в 20 раз я расскажу о том как мы пытались определить запас прочности самой автозагрузки о том как мы искали проблемы которые мешают нам расти и почему нам удалось сделать это чуть больше чем за квартал а не за год в котором мы изначально ВС эти работы оценили Потом я расскажу как мы искали проблемы уже на уровне всего Вита и в конце расскажу про концепт для по эти работы я не буду рассказывать про какие-то конкретные проблемы нашей архитектуры это хорошая тема для отдельного доклада но в этом я хочу сосредоточиться именно на поиске проблем и Для начала я должен вам рассказать что такое автозагрузка вообще если коротко то это инструмент для массовой публикации объявлений его идея очень проста у клиента есть файл с каталогом его товаров и любое изменение в НМ должно отображаться на нашей площадке Если он добавил объявление мы должны его публиковать если отредактировал отредактировать если удалил то снять публикации он может загрузить нам этот файл разово через личный кабинет или или выложить его на хостинг и настроить режим автоматической выгрузки по расписанию соответствии с ним автозагрузка будет приходить забирать этот Файлик и применять изменения чтобы объявление попало на сайт нам нужно скачать и распарсить Смитом для кания в из есть их нужно продива а паралельно скачать фотографии которые мы е не успели скачать только после того как мы всё это сделаем объявление можно попытаться отправить на и всё это мы должны успеть сделать за один час Ведь именно с такой частотой могут выгружаться клиенты которые используют расписание А ещё у нас есть продуктовое требование мы своеобразный пиковый профиль нагрузки на всю нашу систему в начале каждого часа волна трафика сначала приходится на скачивание парсинг каталогов потом на валидацию скачиваем фотографии и так далее и на текущий момент пиковые значения В некоторых компонентах нашей системы могут достигать отметок в несколько сотен тысяч м технически автозагрузка состоит из нескольких десятков сервисов у каждого из под которых под капотом может быть множество разных компонентов большая сть взаимодействи происходит асинхронно Вот на этом слайде только самые критичные наши сервисы и его цель показать вам сложность нашей системы Ну давайте вернёмся в конец двадцать первого года когда я описал вам все масштабы автозагрузки Я думаю что вы понимаете что даже ответить на вопрос А насколько Вы готовы вырасти уже сейчас было ну не так уж и просто и это Не говоря уже о вопросе что нужно сделать для того чтобы поддержать но стояли нам нужно было определить насколько Мы готовы вырасти уже сейчас какие проблемы есть в автозагрузки для того чтобы поддержать рост x20 найти блокеры для роста автозагрузки в инфраструктуре Авито и обеспечить всей этой системе запас прочности хотя бы ещё на пару лет вперёд и когда мы говорим про запас прочности мы имеем в виду две характеристи производительно нагрузку которую компонент способен выдержать на определённых ресурсах для того чтобы её измерить обычно проводят нагрузочное тестирование дают нагрузку на компонент и плавно увеличит её до тех пор пока он не начнёт деградировать этой деградации может быть нарушение тех или иных нефункциональных требований например для А это может быть увеличение Максима превышение максимально допустимой доли ошибок а для различных асинхронных компонентов это может быть лак в очередях или увеличение времени Их обработки вторая характеристика - Это масштабируемость она отвечает на вопрос А во сколько раз способна вырасти система чтобы держать повышенную нагрузку Когда наш компонент начал деградировать Мы можем взять и увеличить количество его реплик А после того как его состояние придёт в норму мы можем снова плавно увеличивать нагрузку пока он снова не начнёт деградировать и в теории весь этот цикл можно повторять бесконечно или до тех пор пока не закончится Лео на этом графике показано распространенное заблуждение при увеличении количества реплик мы получаем линейный рост производительность а в реальности график обычно выглядит вот так при увеличении количества реплик мы не получаем линейный рост А в какой-то момент производительность системы и вовсе начинает падать эти градации связаны с тем что в любой системе есть накладные расходы на согласованную работу можеть база или даже сеть Давайте вернёмся к нашим задачам по сути они все сводятся к тому что нужно было определить эти две характеристики для нашей системы нач с рассказа о том как мы пытались их вычислить для самой автозагрузки мы пошли По классическому пути и решили провести полномасштабное нагрузочное тестирование первым шагом была подготовка плана такого тестирования для этого Выдели основны бизнес сценарии которые есть в нашей симе каждого из сценариев мы определили список сервисов которые в нём участвуют а каждый из сервисов разбили на компоненты которые обслуживают сценарий и у нас получилась такая масштабная схема автозагрузки где все сценарии были разбиты на кубиками А идея была в том чтобы провести тестирование снизу вверх начать с компонентов и плавно двигаться на уровень выше такой подход позволил бы нам найти все возможные точки отказа в нашей системе Да ещё и оценить потенциал от их исправления и для примера Давайте посмотрим на схему на ней представлен какой-то абстрактный сценарий и компонент из которых он состоит у каждого из них есть собственная характеристика производительности это время его работы время работы всего сценария будет равно сумме времени работы всех его компонентов А если они работают параллельно то время работа самого медленного на этой вот схеме рке 1 и 2 работают параллельно а крону нужны результа от них обоих для того чтобы начать свою работу 2 работает в раз оди и получается что из-за него тормозит вся система и если у нас получится его как-то взять и ускорить то мы можем повысить производительность всего сценария почти в два раза здесь может возникнуть вопрос А зачем тестировать ещё и сценарий если мы можем взять и для каждого компонента вычислить характеристику его производительности но важно вспомнить тот график который я показал даже если все компоненты работают параллельно Независимо друг от друга могут может существовать какой-то общий ресурс в который они упираются и бывают ситуации когда по отдельности у нас всё работает прекрасно А когда мы запускаем всю систему вместе то получаем какие-то дикие тормоза после того как мы определили со списком того что мы хотим тестировать нужно было понять определиться А как мы вообще поймём что результаты тестирования нас устраивают Основным требованием к автозагрузке является время её работа мы должны успевать завершить все запущенные выгрузки за оди час и мы просто взяли этот час и разделили его между этапами автозагрузки а ври внутри каждого из этапов между компонентами из которых он состоит и у каждого из них появились собственные нефункциональные требования на которые мы и планировали опираться Когда будем проводить тестирование но при этом эти требования могут меняться если какой-то из этапов вдруг начнёт тормозить но нам каким-то чудом удастся ускорить другой этап то в целом ничего страшного то и не произойдёт Главное чтобы все наши выгрузки успевали пройти за один час отдельно стоит поговорить про базы у нас используется мо db качестве основной базы И в качестве кша такие характеристики как дисковая утилизация нагрузка на сеть и прочее метрики Мы планировали исследовать в ходе самого тестирования Но вот объём места который нам понадобилось понадобится требовалось посчитать заранее для этого среди всех баз и коллекций Кост обни мы посчитали среднее количество таких документов на одно объявление и средний размер такого документа а на основе этих данных мы уже вычислили объём мест который нам понадобится чтобы поддержать 80 млн у как и у любого подхода у полномасштабного тестирования есть свои плюсы и минусы оно поможет нам определить сколько Мы готовы выдержать и какие мощности для Для этого нам понадобятся найти всевозможные точки отказа в нашей системе и для всех оценить эффект от их исправления но всё это очень сложно и дорого у нас получился список из пче сценариев каждый из которых состоял из десятка различных компонентов А всего нам требовалось протестировать несколько сотен компонентов мы оценили примерно трудозатраты И у нас получилось что Для такого тестирования потребовался бы примерно год работы всей команды только через год мы смогли бы сказать А насколько Мы готовы вырасти и что нам нужно чтобы поддержать рост x20 И вообще это эпичный фе нам нужно было что-то придумать чтобы сократить обм работ и тогда нам в голову пришла идея если мы не можем позволить себе полномасштабное тестирование Давайте ограничимся тестированием основных бизнес сценариев и проведём его прямо на проводе возьмём и создадим тестовых пользователей раздадим им каталоги реальных клиентов так чтобы в сумме у нас получилось 80 мно объявлений а потом будем аккуратно и плавно запуска Выру в возни какие-то проб такой подход позволит нам определить насколько Мы готовы вырасти уже сейчас и даже найти основные точки отказа в нашей системе Но в отличие от полномасштабного тестирования мы не сможем изу детально изучить все её части поэтому найдём только самые критичные проблемы и может быть так что после и иит какието меньшего масштаба которые пули так и Мы решили остановиться именно на этом варианте потому что времени у нас было мало работы впереди ещё очень много но прежде чем приступать к тестированию нужно было решить несколько проблем и Первое - это сервисы с которыми мы как-то взаимодействуем было бы неловко если бы мы положили их в ходе нашего тестирования Ну да И нужно было придумать какой-то механизм который помог бы нам экстренно снять с них нагрузку от тестовых пользователей Но в идеале сде чтобы тестирование не останавливалось а вторая проблема - Это наши собственные компоненты у нас большая часть взаимодействия в системе происходит асинхронно а автозагрузка представляет в себя такой конвейер по обработке и доставке данных если какой-то из этапов этого конвейера начнёт тормозить то мы не сможем должным образом нагрузить следующее его части А если очередь в какой-то из этапов забьётся слишком большим количеством сообщений то мы можем вообще положить сервис очередей здесь тоже нужно было что-то придумать чтобы наше тестирование не устроило Апокалипсис нужно было разобраться с этими проблемами но ещё и сделать так чтобы оно не сворачивалось после каждого отказа в системе Ведь если мы будем останавливать его то есть риск что Количество попыток его проведения начнёт стремиться к бесконечности в нашей системе есть как синхронные так и асинхронные виды взаимодействия и для каждого из них нужно было придумать какое-то Общее решение кото могло бы снимать нагрузку но при этом не останавливать тестирование для каждой из синхронных зависимостей мы реализовали тогл при включении которого для всех тестовых пользователей вместо реального похода в сервис вызывается МОК который эмулировать задержку и возвращает данные которые мы заранее подготовили и похожий тол мы реализовали и на стране всех компонентов которые что-то публикуют в очередь при его включении данные тестовых пользователей просто никуда не отправляются а нужен он для того чтобы иметь возможность гибко настраивать сценарии проведения нагрузочного тестирования отключая те или иные компоненты системы Например если мы хотим протестировать только скачивание парсинг каталогов то мы можем включить такие то Оглы чтобы отключить отправку на валидацию и скачивание фотографии и последний тогл мы реализовали на стороне всех компонентов которые читают какие-то данные из очереди при его включени они просто игнорируют данные тестовых пользователей они нужны для того чтобы иметь возможность быстро очистить если что-то пошло не по плану после того как мы ВС это реализовали у нас получился стенд который состоял из компонентов кубиков и позволял гибко настраивать сценарии проведения нагрузочного тестирования отключая те или иные компоненты и этапы автозагрузки и при этом ещё и контролировать нагрузку на внешни сервис с нагрузкой на внешние сервисы мы разобрались механизмы для очистки воркеров сделались решить послед проб будет мешать нам проводить нагрузочное тестирование на самом деле у этой задачи есть очень простое решение нужно просто взять и уменьшить количество реплик или вообще выключить воркеры которые идут после тормозящего Пусть он пыхтит и как может накидывает сообщение в очередь А после того как там накопится нужное количество данных мы просто вернём их назад И вот после того как мы разобрались со всеми этими проблемами прило время проводить само тестирование мыли э и с этим нам помогли толы которы мы на прошлом шаге реализовали в качестве первого эта мы тестировали только запуск выгрузка каталогов отключив отправку в парсер А на следующем этапе добавили ещ и парсе включив отправку на валидации и скаче фотографии и в итоге команде чуть больше чем за квартал удалось СОБРа сти дальше результаты тестирования показали что у нас был где-то год в запасе прежде чем система перестанет справляться с новым профилем нагрузки здесь я хочу напомнить что полномасштабное тестирование стоило бы нам год работы и если бы мы вложились в него то времени на фикс проблем у нас бы почти не осталось параллельно с тестированием автозагрузке Мы пытались найти проблемы в инфраструктуре Авито эти проблемы были вле Я сказал что за 2 года мы бы вы но если мы посмотрим на график роста количество активных объявлений во всм Авито то мы увидим что за этот период они выросли всего лишь в два раза именно к таким темпам и готовились многие команды а в реальности компанию ожидала резкое изменение профиля нагрузки и Наша доля должна была вырасти с че почти до 50% в отличие от других платформ Мы генерируем в разы больше трафика часто редактируют наши клиенты могут иметь до 100.000 активных объявлений и редактировать их чуть ли не каждый час в итоге получается что команды готовились к росту X2 А на практике Он должен был быть намного больше и не факт что даже x20 прежде чем попасть на сайт объявление проходит через цепочку из десятка различных сервисов у каждого из которых есть большое количество собственных зависимостей и автозагрузка здесь стоит лишь в начале пути если мы попробуем взять и построить Граф её зависимости хотя бы с глубиной два то у нас получится нечто подобное среди всех этих сервисов Мы точно не знаем какие используются в наших сценариях это просто сервисы от которых зависим мы и сервисы от которых зависят они и среди них нужно было найти тех кто не готов поддержать наш рост и пойти и рассказать Им о том что их ждёт Мы понимали что рас распутать этот клубок мы быстро не сможем поэтому сразу решили ограничиться зависимостями только первого уровня теми с кем взаимодействуем напрямую и в зависимости от каких-то крупных и критичных сервисов для каждого из них мы определили мы вручную собрали их список и для каждой определили сценарий в котором тот или иной сервис используется здесь может быть вопрос а Неужели у вас нету какой-то автоматизации Рейсинга автоматизация есть но чтобы узнать в каких продуктовых сценариях используется тот или иной сервис нужно залезть в код и посмотреть вот имен этим мы занимались у нас получился список из 37 сервисов и 110 методов А где для каждого из них мы определили в каких сценариях Он участвует От каких продуктовых метрик зависит на него нагрузка А ещё и мы собрали данные о текущей нагрузке на него в нескольких разрезах и на основе всех этих данных мы посчитали к чему нужно готовиться у нас получилась огромная таблица с которой мы начали ходить по командам расч был на то что мы этим запустим цепную реакцию и команды владельцы наших зависимостей пойдут общаться с владельцами уже своих зависимостей А мы таким образом соберём клок всех проблем и всего у нас было три варианта развития диалога команды знали свой запас прочности и были готовы поддержать ва наш рост и здесь каких-то проблем не возникало команды знали свой запас прочности и не были готовы поддержать наш рост тогда мы садились и вместе думали а что мы дальше вообще будем делать и Третий вариант когда мы Командо не знали свой запас прочности и тогда мы планировали проведение нагрузочного тестирования А по его итогам возвращались к одному из предыдущих вариантов и Даше мог бы быть контент для конференции уровне тко о том как нужно взаимодействовать С командами объяснять им важность и приоритет каких-то зада и пытаться впихнуть невпихуемое я его пожалуй опущу и скажу что мы по итогу всеми задачами справились Хотя работы растянулись у нас Почти на год но вся эта история с ростом вскрыла ряд очень интересных пром мы увидели что многие команды прекрасно разбираются со своих технических Метрика и часто даже знают тот предел нагрузки который они готовы переварить при этом не все из них знают Какие продуктовые метрики и как на них влияют пройдя через большую цепочку сервисов запросы раз один только поиск всех е зависимостей становится какой-то невероятной головной болью Нам очень хотелось как-то автоматизировать всю работу что мы проделали как минимум Потому что если наш продукт и дальше продолжат расти такими же темпами нам придётся рано или поздно всё это повторять тогда мы подумали А как же классно было бы иметь инструмент в который ты вводишь данных данные о каких-то на самом деле эта идея не так уж и далека от реальности Ведь мы вручную проделали почти тоже самое И первое что нужно сделать это научиться определять список сервисов которые участвуют в том или ином продуктовом сценарии Я как владелец сервиса 5 не понимаю Какую долю от всех запросов мой сервис занимает автозагрузку А какая какую например ручная подача если мы начнём пробрасывается чиной подачи не составит большого труда А я как владелец сервиса 5 буду понимать Какую долю от всей нагрузки мой сервис она занимает мы не можем масштабировать систему бесконечно потому что как правило есть какой-то какой-то ресурс в который мы Ура и может быть железо база или даже другие сервисы если для каждого из сервисов мы сможем определить набор таких ресурсов а для каждого ресурса оценить запас его Прости Томы сможем за это именно то чем мы занимались когда проводили нагрузочное тестирование и работали с нашими зависимостями ведь для нас сервис в которые мы ходим тоже выступает в роли таких же ресурсов при этом паттерн их использования может быть разный разные сценарии могут использовать разные ресурсы какие-то грузят базу какие-то продают запросы в другие сервисы нужно научиться сделаем то мы получим систему в которой для каждого продуктового сценария мы можем увидеть список сервисов которым в НМ участвуют понять как продуктовые метрики переводятся в технические а зная ещё и запас прочности каждого из сервисов узнать когда ибо что споткнётся наш продукт при росте эта идея нас ну никак не отпускала и мы решили реализовать mvp Прежде чем идти в какую-то большую сложную разработку хотелось удостовериться что наше решение вообще рабочее и может масштабироваться на всю компанию для его реализации Мы исходили из тех технических ограничений которые у нас тогда были в Авито есть трейсинг но он пока не умеет вы синхронно поэтому здесь мы решили работать только с Оха реализовать трейсинг продуктовых сценариев оказалось ну не так уж и дёшево поэтому мы решили ограничиться только зависимостями первого уровня список которых у нас уже был в качестве ресурса Мы решили использовать нагрузку которую готов выдержать вст продукто Трик только одну количество активных объявлений на которые управляются автозагрузкой проект мы называли ка дабор для него мы реализовали сервис который собирает данные о технических Метрика всех наших зависимостей и сохраняет их в базу чтобы наш инструмент умел предсказывать нагрузку которая будет расти с ростом продукта из за это отмечает его основная цель на основе исторических данных для каждой технической представить каждую техническую метрику как функцию от продуктовой и имея все эти данные и данные о росте продуктовых метрик мы можем попытаться предсказать Во сколько раз возрастёт нагрузка и обо что мы споткнётся Когда продукт будет расти реализовали проп и наумен вж можно выбрать сервис от которого мы хотим строить зависимости можно выбрать сервисы даже методы для которых мы хотим рассчитать нагрузку оранжевая линия на графике - это прогноз нагрузки который Он построен на основе прогноза роста продуктовых метрик а Чёрное - это запас прочности сервиса зная все эти данные мы можем попытаться предсказать когда сервис перестанет справляться решение у нас оказалось вцелом рабочее и мы но чтобы это делать нужно ответить на ряд открытых вопросов с которыми мы сейчас столкнулись у нас по-прежнему нет трейсинг продуктовых сценарий мы по-прежнему не умеем вы асинхрон чину это просто объёмная работа которую нужно взять и сделать держать отдельные модельки для расчёта зависимости технических метрик от продуктовых Слишком сложно и дорого мы Рем какие-то альтернативные варианты наме пропорции Но от идеи моделек для каждой из метрик Мы тоже не отказываемся а для того чтобы знать запрос прочности каждого из сервисов нам нужно внедрить практику регулярного перформанса и мы тоже работаем в этом направлении Ну и настало время подводить итоги Я думаю что никого не Удивлю если скажу что нам удалось адаптироваться к новому профилю нагрузки и сейчас у автозагрузке крутится 80 млн объявлений У нас есть запас прочности где-то на год-полтора но мы хотим большего большего поэтому мы вернулись к идее полномасштабного тестирования и будем проводить его в спокойном режиме оно поможет нам собрать клок проблем и оптимизации в которой мы будем вкладываться в ближайшие несколько лет помимо этого мы хотим понимать запас прочности Авито как сложной технологической системы поэтому мы будем развивать наш Капа дашборд Я надеюсь что на одном из следующих докладов я про него расскажу у ме всё пожалуйста голосуйте за мой доклад А я отвечу на Ваши вопросы Евгений Огромное спасибо за доклад Я думаю это всё будет от масштабируется Ребята в своих компаниях маленький президент от нашего партнёра по подаркам Газпром СБО нефти и у нас вопрос пока несут микрофон а вы сейчас на какую нагрузку вате мы планируем вырасти где-то до 110-120 млн объявлений именно в автозагрузке это вот как раз прогноз на ближайшие 2 года вот мы его готовы поддержать а сверху уже не готовы Сейчас 100 Милн секунду правильно понял 100 здесь очень хотелось опустить особенность работы нашего сервиса вот эти 80 млн которые через каждый час через нас проходят Они же не все редактируются Поэтому в среднем это реальной нагрузки 16 млн объявлений вот в час в среднем 20% Ну вот столько получается что 2530 нужно будет держать Это какой у вас rpc смотр где у нас Я не стал вставлять У нас есть компонент который читают из очередь со скоростью по-2 милна сообщений в секунду ой в минуту Извините в минуту в Минуту Минуту 60 в секунду 300000 поч 400 где-то так большие цифры и у нас вопрос большое три коротких вопросика первый - это откуда требования начинать по границам часа второй это как вы размечается пользователей это какой-то Центральный сервис или где-то в заглох передаёте понять тестово или нет И третье - это если ML обучает на исторических данных то она же ни разу не видела рост нагрузки x20 она как она может его предсказать да давайте порядку первый вопрос откуда требования запускаться в начале каждого часа а нашему продукту 10 лет и когда-то его сделали исходя из таких требований сейчас мы понимаем что вот этот пиковый профиль - это что-то ненормальное потому что сервисом многим приходится держать запасы железо рассчитанные на пики И это не ок а мы хотим менять это поведение мы уже проводили эксперименты насколько нам помогает спойлер очень сильно помогает то есть мы сможем можем пики взг там больше чем в 20 раз но чтобы поменять поведение нужно провести работу с пользователями у них уже есть какой-то опыт они уже рассчитывают на какие-то требования поэтому последний год мы занимаемся тем чтобы работать на над пересмотром вот этих требований там сейчас очень продукт активно вкладывается Я думаю что в следующем году хотя бы к концу года нам удастся всё-таки отказаться от этой штуки сделать получше но откуда она Да не знаю так исторически универсальный ответ Наследие Спасибо Напомните ВТО как понимать тестовый пользователь или нет как они размещены как это передаётся всё очень просто у каждого тестового пользователя у нас в базе признак что он тестовый юзер у нас много разных пользователей у него есть набор меток и у него есть метка юзер у нас прям в тох проверка и включен Ир то типа скипать то есть Центральный сервис с пользователями Да у нас есть сервис пользователями он на одном из там Ну я наверно сейчас не достаю на одном из первых слайдов как раз вот когда я показывал был с пользователями Да спасибо и тре презентации будут доступны для участников можете посмотреть и третий вопрос про Эль смка реально мы столкнулись с этой проблемой и я в конце сказал что это открытый вопрос потому что помимо того что не хватает исторических данных а этих моделек может могут может быть очень много их могут быть тысячи или даже десятки тысяч и всё это поддерживать очень сложно даже непонятно кто поэтому ответа У меня пока нет мы обучали на мы использовали линейную зависимость Да хотя она не очень подходит потому что если мы В тупую будем говорить что если там мы вырастим в два мы видим там мы на каждое объявление шлём два запроса и там будет четыре мы для ручного расчёта примерно Э так так пользовались но в реальности Там могут быть кэши какие-то ещё что-то поэтому такое идея не очень мы здесь смотрим в сторону расчёта через пропорции То есть если мы понимаем что там нагрузка в сервис не хотим а хотим от конкретных чисел уйти какие-то пропорции например мы автозагрузка грит там 30% каких-то геосервис запросов если от всех От всего трафика если там загрузка вырастет два раза значит там не 30 будет а 60 Там и 70 вот мы в эту сторону смотрим потому что с моделями тяжело я сам не особо аналитик но наши аналитики Вот как раз сейчас воюют с тем чтобы такие витрины либо витрины научиться собирать либо вот через пропорции будем считать спасибо ну по моему мнению это отличная тема на следующий если взлетит сю да нет Любой результат он как бы для сообщества очень важный и у нас следующий вопрос одну секунду вам сейчас при суд микрофон приветствую Спасибо за А кто первый-то говорите спасибо за доклад такой вопрос не раз прозвучала получается идея что приходилось тестировать грубо говоря на проде была идея вот механизм сгми очень круто получилось на самом деле А в ЧМ была проблема или какие-то несоответствия Может там тестовых получается стендов чтобы просто договориться Вот как раз со смежными командами которые со зависимые от вас и провести на тестовых стендах уже полномасштабное нагрузочное тестирование и сэкономить время на реализацию тогл функционала вот этого ну полномасштабное ты имеешь в виду детально каждый из компонентов изучать да Ну да то есть вот то что вы планируете сделать как раз изначально вам не хватало времени вы сделали функционал сгми чтобы был запас а сразу сделать минуй логику столами на тестовых стендах или какие проблемы вызывают это проблема была одна в том что это очень объёмная работа вот я показал план у нас ну прямо реально сотни компонентов для каждого из компонентов тебе нужно не просто подготовить тестовые данные но и детально изучать его под микроскопом масштабировать Да каждый раз искать вот эти точки отказа потом когда ты компоненты изучил собирать их в сценарии и так далее это то Чем мы сейчас будем заниматься Тогда просто не позволяло время Поэтому переобулись и пошли в гми и вот решили проводить тестирование вместе с ними на проде но ты прав так и собираемся делать есть контур какой-то и будем детально всё исследовать там под микроскопом А слушай вопрос А как вы Подойдите пер в контур свою большую нагрузку А нам е Или пропорци нам её не нужно подавать Потому что если мы смотрим на каждый из компонентов то мы Ну как бы заранее когда мы изучаем каждый из компонентов мы заранее готовим нагрузку нужную Да тестовые данные какие-то и можем в него Ну прямо под микроскопом изолированно изучать Когда мы будем двигаться на какие-то большие уровни там да там скорее всего мы вернёмся Опя к этому стенду с углами и не будем тестить на перфе проблема перф окружения что оно плохо эмулировать всю инфраструктуру Авито у нас огромное количество серверов огромное количество Ну типа свои какие-то дата-центры и чтобы повторить масштабы системы на перфе это просто надо X2 железа и у нас следующий вопрос показали на общей схеме там по-моему сем этапов публикации объявлений и из них по-моему только два параллели а рассматривали возможность параллели другие этапы скажем не полностью обрабатывать А вот какие-то там параллельные выгрузки и так далее чтобы этапы шли непосред друг за другом вот да на схеме она такая верхнеуровневое Да у нас внутри Там многие этапы параллели но здесь пока Ну короче ответ Пока нет а но мы думаем о функциональности сейчас в общем проблема Какая чтобы если клиент отредактировал цену нам всё равно приходится все этапы прогонять э и это боль потому что основные изменения допустим в цене а нужно прогнать там не знаю сравнить там фотки поменялись не поменялись мы здесь смотрим просто в сторону того чтобы дать возможность клиентам явно указывать что Они поменяли Ну то есть вот просто поведение продукта поменять само себ Мы обычно этап били на этот даже частично дублировали условно говоря загружаем Полный каталог и какую-то там его хэш функцию чтобы параллели пока Полный каталог грузится по хэш уже запараллелить коллеги Мне кажется это отличная тема для обсуждения рах поделим своим опытом и у меня традиционный вопрос от ведущего и ты даже знаешь какой какой Выбери лучший вопрос а и у нас будет два приза один от спикера другой от нашего о понравился вопрос по модельке Это от тебя Да Прошу выйти победителя на сцену И второй вопрос и второй а можно я пока вручу спасибо за вопрос Спасибо А про перф контур мне понравились тоже Да хороший вопрос прис Нашёл своего победителя а Благодарю за вопросы оставайтесь с нами"
}