{
  "video_id": "VZgwbZYesdI",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "а теперь под бурные Аплодисменты прямо из Иви Евгений росинский с разговором про йло Всем привет О у меня даже слайды появились Меня зовут Женя я технический директор Иви ещё я о балуюсь преподаванием в МГТУ имени Баумана и преподаю курс технологии командной разработки программного обеспечения что я вас тут всех сегодня собрал мы поговорим с вами про аномалии Что такое Аномалия Аномалия - это что-то что выбивается из привычного хода вещей anormal ненормальное мы будем говорить с вами про аномалии в двумерном пространстве про так на называемый Time Series или про временные ряды на самом деле если говорить про многомерное пространство математика там примерно такая же а Инженерная часть вообще Один в один пбх не работает пбх Не работает так во класс А как я сказал я технический директор а а доклад у меня будет про то как мне пришлось ручками залезть и чуть-чуть по кодить и почему это произошло что нужно почерпнуть из данного слайда пото что на самом деле у меня в моём департаменте 317 инженеров и почему-то так случилось что погодить пришлось мне зачем Ох Какой прекрасный слайд Но на самом деле Здесь должна была быть красивая анимация что-то пошло не так Короче с чего всё началось началось всё с того что года полтора назад мы прилег минуты на очень неприятно и когда мы делали постр прилег изза того что на один из сервисов прилетело очень большое количество запросов в секунду и если было можно было бы посмотреть 30 минут до аварии то там уже наглядно на всех графиках видно что нагрузка пришла время ответа выросло и можно было предпринять какие-то действия Мы конечно же собрались Такие блин Что будем делать Ну вот смотрите Давайте последуем Какие существуют детекторы аномалий ребята разошлись на недельку подумать вернулись говорит на само всё Ну то есть вот тут ложно положительное срабатывание Вот это работает только с прометеус это работает только с фано и в общем Ну Жень давай так мы добавим ещё дополнительных простых триггеров которые вот именно эту аварию будет совершенно спокойно детектировать я такой ну блин ну как-то не классно и все разошлись я такой встаю грустный думаю ну ладно в общем когда-то в институте У меня был предмет по цифровой обработке сигнала думаю ну ладно окей почитаю Вечерком может быть что-нибудь получится что я хотел Я хотел получить инструмент который бы либо за несколько минут или часов до аварии говорил бы будет скоро авария или что-то идёт не так либо же если авария уже произошла я хотел максимально быстро узнавать что она случилась Поэтому я взял и собрал свой собственный датасет технического директора Какие данные я туда добавил значит Ну во-первых это падение бизнес метрик Да например у вас резко падают просмотры или резко падают ээ платежи страшно ужасно либо же если время ответа какого-то сервиса значительно увеличивается либо что самое ценное и очень плохо детектива мое когда вот например третий график это реальный график когда на одном из наших кластеров на 4% просел отдаваемой трафик визуально незаметно э сравнение вчера к позавчера тоже ни фига не выявляет Но на самом деле падение стат значимо и там пять серверов вышло из строя и они оказали именно такой эффект поэтому я собрал датасет и сформулировал для себя А что собственно будет круто Мне иметь что я хочу от детектора аномалий во-первых Я хочу искать уметь искать аномалии этот поиск должен быть быстрый и максимально приближенный к реальному времени нужны градации нотификаций нужно уметь быстро добавлять тысячи и десятки тысяч метрик потому что серверов на каждом сервере куча разных метрик сервисов много надо по сервисам всё это бить вот Ну и конечно же вот я столкнулся с холодным отношением команды к вопросу детекции аномалий Конечно хочется чтобы этим инструментом пользовалась команда и все были счастливы и как следствие должно быть очень мало ложно положительных срабатываний Ну я человек ленивый я такой Окей Ну может быть я по пару вечеров троечку сидел крутил разные решения решений оказалось есть решения которые требуют денег есть решения которые денег не требуют сразу скажу они все более-менее адекватные и большей частью из них можно пользоваться Но почему Да в конце будет ссылочка на слайды можно будет прямо все названия себе ВМ сти в данных в некоторых готовых решениях нет подключения к нужному мне источнику У нас есть графана у нас есть прометеус у нас есть закс И мне очень хотелось ещё ко всему этому прикрутить кликхаус потому что в кликхаус у нас живут продуктовые метрики бизнес метрики и аварии - это не всегда аварии которые инженерные иногда аварии они в бизнес логики ты выгрузил какой-то код который проди тебе например конверсию в какой-то очень ценное действие Какие ещё проблемы проблема в том что надо данные отдавать куда-то а данные чувствительные если мы говорим про какие-то внешние облачные решения то для того чтобы передавать туда например пользовательские данные или персональные данные для этого должны быть специальные регламенты а мы два раза в год проходим аудит где нас мучают чтобы мы делали всё хорошо и не делали плохо почти везде требуется аналог Иля есть проблемы с доставкой данных некоторые решения вообще заточены только под бизнес метрики вот ну и нет возможности валидировать Умер ли источник данных Откуда ты вытаскиваешь данные для поиска аномалий или нет но не только в одних данных проблема некоторые инструменты которые мне очень понравились стоят как бюджет маленького островного государства потому что тарификация идёт за количество метрик вот Представьте что у вас несколько тысяч серверов на каждом там Low average там э соке память и прочее прочее прочее и вот ты вот только на простых Метрика уходишь куда-то в космос во-вторых если это Облачное решение надо всё-таки договариваться с сетевика с безопасника как наружу отправлять эти данные во многих нет возможности добавлять метрики тысячами и десятками тысяч где-то я сам не смог развернуть он преми с ремни хуже ко подели энтузиазма нет а это значит что реализация чего-то из-под палки супер неэффективна и поэтому я решил потратить либо своё свободное время либо максимум одного-двух людей привлечь Поэтому вот с решениями не всегда развернуть их просто и быстро некоторые работают просто до постыдного медленно в некоторых нет интеграции с нужным истан мессенджером вот Ну и не очень многие умеют работать сложно положительными срабатывания получается что я посидел думал что вот если всё равно надо готовить данные то А что В чём заключается система детекции аномалий Кроме того что в общем продуктовом решении надо дотащить до неё данные Я думаю блин ну неужели же надо так много времени потратить сел поис следовал эту тему и выяснил что Нет нифига на самом деле по моим оценкам когда я к этому проекту приступал Я думал что 70% менят интеграционные вопросы и 30% я буду ковыряться с алгоритмами детекции аномалий смотреть различные выбросы вот на деле же оказалось 90 против 10 То есть 10% - это сам алгоритм детекции аномалий всё остальное - это всё что связано с этим вокруг но никак не связано с математикой поэтому я расчехлил свой ноутбук и решил что несколько вечеров в неделю я могу потратить на то чтобы поис следовать эту тему За первые 2 месяца Я почитал статей поиз учал мата аппарат вот э и сделал Альфа версию ещё через 3 месяца такого же неспешно вечернего блуждания Я выпустил первый релиз только для себя после чего ко мне подключился мой дружбан Лёха который является архитектором Одного из наших энд направлений и дальше ещё 7 месяцев в очень вялом режиме то есть вот через 5 месяцев уже готов Готовое решение а через 7 месяцев перекидываю с МШ реквест там пару раз в недельку мы сделали из этого вообще просто красоту И конфетку что же внутри внутри Я выбрал не очень новую библиотечку от Твитера ныне это ха Вот которая на 90% совпала с моими ожиданиями относительно моего датасета работает супер Шустро это Open Source а умеет работать с факторами сезонности А у нас вопросов сезонности пятница у нас это отдельная история понедельник - Это другая история лето отличается от зимы сентябрь отличается от марта есть гендерные праздники все вот эти особенности очень хотелось бы чтобы как-то учитывалось из коробки Но что самое главное любой алгоритм должен быть супер прост в применении и у библиотечка которую сделали ребята из Твитера есть классное преимущество управляется всего двумя параметрами Первое - это стат значимость которую по-хорошему вы можете зафиксировать и никому из разработчиков об этом ничего не говорить вот а второе можно образно назвать как чувствительность хотите находить больше аномалий рычажок направо хотите находить меньше аномалий рычажок налево классно быстро и замечательно Какие ещё решения я рассматривал на самом деле это целый Волшебный мир детекции аномалий в конце будет тоже ссылочка на ТО на бенчмарки которые присутствуют в этом волшебном мире детекции аномалий и по одному из самых популярных бенчмарком находится где-то в середине В моей же собственной градации он находится чуть ли не на первом месте потому что работает Быстро классно и бронебойно но прелесть решения что вы можете абсолютно любой алгоритм заюзал горит либо вашего процесса л Петя Ермаков рассказывал про машинное обучение сейчас Это модно стильно молодёжно так вот если у нас внутри нашего детектора аномалий искусственный интеллект мы пробовали его туда внедрить результаты показывают примерно такие же по скорости хуже а иногда ещё надо сильно больше железа поэтому Как только появятся метрики которые мы не сможем обрабатывать обычными статистическими моделями можно будет из коробочки подключить ещ какой-нибудь детектор так вот конкретное решение что внутри берм библиотечку от Твитера она написана на языке R с ком Я был не знаком но как бы там на вход подал на выход получил этой библиотечка обернул это всё в питон Вот почему Потому что захотелось построить аминочка питон заворачиваем в Джанг Джан со вкусом EV у нас в компании есть довольно простая практика Как можно создать шаблонный проект со всеми настройками и прочими вещами ВС это в докер пор и погнали теперь как это всё работает с точки зрения архитектуры минуточку внимания схем очень простая значит что сначала нужно осознать осознать нужно то что у детектора аномалий нет своего хранилища где он хранит те самые Series или временные ряды это с одно щение с точки зрения аите ржать какие-то данные понимать Где консистентные где не консистентные у вас всегда данные во внешнем источнике это может быть либо опиш закса опиш графита опиш прометеус либо подключение к кликхаус про минусы поговорим чуть-чуть попозже так вот Как это работает в общем есть энное количество детекторов аномалий они из пас Гри выкачивают каждый свой список метрик которые хочется проанализировать дальше последовательно анализируют эти метрики берётся первая Метрика лезет в например э Метрика в заксе лезет опика в опиш закса достаётся оттуда Time Series ищется Аномалия если мы хотим об этой аномалии сообщить пользователю дёргаю опиш instant мессенджера и сохраняем в дис информацию о том что мы зафиксировали такую аномалию зачем здесь редис редис как раз для того чтобы помнить Какие аномалии мы уже находили раньше поскольку своего хранилища Time Series нет А во-вторых чтобы люди не раздражались очень классно уметь отличать АНО по господи Все начинают бегать воздух поднимаются вертон перекрывает станции метро от того когда Аномалия продолжается Ну вот мы только 5 минут назад сказали у нас авария и кричать каждый раз у нас авария бес смысле надо просто мы находимся в режиме аномалии Вот для этого как раз и используется редис теперь как это всё быстренько и просто разложить по контейнерам но ВМ Конте ль контейнеров вы поднимаете и есть ещ отдельный контейнер супероружие под названием поиск новых метрик это фабрика метрик как тысячами добавлять как раз метрики об этом будет отдельный кусок рассказа поэтому Как создаются метрики вы либо по одной задаёте в Джанкой Амино метрику либо с помощью как раз фабрики метрик будет косячит или не косячит но он работает с сухими данными которые по-хорошему это число Да там вот просто какой-то там не знаю поси Y какие-то значения отложены насколько и когда нужно нотификат человек могут положе положительным срабатывания бегать и очень сильно агриться Вот чтобы этого не допустить мы сформулировали несколько простых правил сейчас о каждом из этих правил мы подробно поговорим первый простой Супер лайфхак это игнорирование окрестности вокруг медианы Представьте себе что у вас Значит в каждый момент времени мы в зависимости от времени суток строим медианное значение и можем отступая от этого медианного значения глушить ложно положительное срабатывание причём для алгоритма эти срабатывания не ложно положитель они нормальные например ва ИТ срабатывание на 4 миску Но если у вас сервис как бы работает за 800 наверное не всем интересно людям которые занимаются поддержкой этого сервиса что нужно реагировать на 4 миллисекунды поэтому можно так вот немножко загру бить А у кого сервис отвечает там 8 миллисекунд там уже Извините можно и поработать 4-5 миллисекунд У нас например Это лбк переключение с одного дата-центра на другой То есть если ты переключаешь на другой D центр у тебя на 5 миллисекунд возрастает время это штатная ситуация как бы об этом зна поэтому можно вот так зарубить идм дальше следующий лайфхак тоже очень простой вот на данном на данной картиночки вы видите игнорирование значит точнее срабатывание на аномалии два из ТХ То есть три последовательно идущих точки Если в двух из них есть аномалии мы реагируем понятно что число n и может быть произвольным таким образом вот специальный график это реальный график Одного из наших сервисов очень нече в 5 утра Одиночный всплеск ненормального времени ответа можно вот так вот его срезать идём дальше максимальный возраст аномалии перед вами реальный график просмотра одного из турецких сериалов значит он многосерийный вот сейчас они очень популярны и вот каждый раз детектору аномали мы передам для анализа какой-то диапазон хося в правой границе этого диапазона и находясь в правой границе диапазона нам Конечно же очень интересно узнать что вот смотрите неожиданно у нас произошёл какой-то всплеск вверх и это действительно значимая Аномалия так вот выглядит на самом деле выход новой серии по-моему клюквенного щербета если я не ошибаюсь Живите с этим но если мы находимся в другой точке Да вот опять Мы перемещаемся в другую правую границу и в это запускаем детектор и у нас Аномалия получается далеко в прошлом потому что смотрите тренд нисходящий понятие нормы тоже становится всё меньше и меньше и меньше и в какой-то момент на границе диапазона появляется старая Аномалия То есть например день до этого она была не настолько стат значима А теперь она стала стат значима если раньше вы эту аномалию не нашли или вы добавили эту метрику только что Представьте вы добавили 10 метри которые вам тут же манут что у вас 2 недели назад была Аномалия та да спасибо что нам с этим делать нам бы в риал тайме справиться с большим количеством событий а так мы должны разбираться со старым окаменевший мамонтовский экскрементов суток или старше какого-то периода ещё одна штука которая связана как раз с целостностью данных не все источники данных одинаково полезны графит в свой пише может пару раз в сутки возвращать в последнем последней точке какое-то число которое не соответствует действительности он ещё не до собрал эти данные и вот у вас последняя точка выла и вы всё время видите Ой блин ПС упал бежите разбирайтесь отправляйте ещё один запрос а там всё хорошо или же если вы работаете с продуктовыми метриками берём тот же самый кликхаус и Например у нас история с конверсией у вас наме чи вы считаете конверсию в час то есть шаг сетки у вас час и вам надо дождаться окончания вот этого вот часа чтобы у вас и в числителе и в знаменателе были консистентные данные всё очень просто там математика восьмого класса Но если вот этого не сделать то иногда Вы можете получать просто тупые ложноположительные срабатывания ещё один пример из реальной жизни перед вами верхний график - это просмотры в минуту на старых Sony Opera телевизорах и у нас таких около 700 графиков по разным моделям устройств потому что может быть всё что угодно вендер может обновить прошивку и у вас там что-то упало код может обновиться и нам очень хочется понимать что происходит с пользователями так вот при этом эти данные тащатся из кликхаус Нижний график это отставание данных в источнике Что произошло А произошло следующее есть кавка которая собирает клиентские события и приближенные к реальному времени есть дата процесинг который эти данные перекладывает в кликхаус дата процессинг перестал справляться и у нас стали чудовищные Там сначала на 5 минут потом на 10 минут потом на 20 минут потом на час отставание в от Реал тайма к чему это приводит при детекции аномалий чёрт возьми у нас не хватает просмотров Почему Да потому что они ещё в кафке лежат что мы сделали мы сделали супер простой Хак для каждого источника данных мы придумали признак правила это может быть в том числе и Метрика благодаря которой источник данных просто отключается обновляется вы сейчас Victoria Matrix классно у вас автоматом отстрелить система мониторинга которую использует Виктория Matrix и вы не получите ложно положительное срабатывание смотрите все вот эти супер простые вещи совершенно спокойно выполняются студентам первого второго курса технического ВУЗа то и возможно школьниками Ну потому что это там Работа с простыми массив ничего больше где-то какие-то простые условия но возьмите любой практически любой алгоритм детекции аномалий навер на него вот эти вот Простые правила и вы увидите насколько всё качественной класс начинает работать что это приближается уже к продакшн решению и общая схема выглядит следующим образом мы сначала отбираем метрики в отборе метрик тоже есть фильтры дальше мы прогоняем их через детектор После этого мы прогоняем через фильтры ложно положительных срабатываний которые простые и эмпирические уведомление в instant Messenger и вы кайфует опытные люди которые давно в разработке сидят и ждут когда же они смогут задать вопрос А ты вообще не идиот ли потому что у тебя есть три системы мониторинга Ты как не в себя мучаешь их неистово запросами копи можешь их положить во-первых и остаться вообще без какого-то Нило монито этот вопрос Я задал себе тоже в самом начале когда решил отказаться от хранилища промежуточного и ответ Меня удивил оказывается что ребята которые делали фану прометеус и закс очень классные они умеют в кэширование они оптимизировали свои Шеки Так что однотипные запросы выполняются супер быстро десятки тысяч запросов в секунду иногда даже держат и этого более чем достаточно нашем размере инсталяции всех этих систем мониторинга Но есть один момент для того чтобы есть недостаточно провести просто нагрузочное тестирование сказать о мы пару раз постреляли из танков льну ачма всё хорошо поэтому мы сделали очень простые дашборди на которые тоже натравили детекции аномалий и вскрыли всего пока пока одну из довольно очевидных проблем э проблема классическая для системы массового обслуживания если у вас все воркеры выполняют однотипные задачи А некоторые задачи выполняются несколько дольше то э неизбежно есть вероятность что вы попадёте в систему ну не тупика а большого затуп представим у вас 10 воркеров и ээ те задачи с кликхаус ой задачи с прометеус за абексонечное запрос зависит Насколько быстро вы будете получать ответ и есть метрики в том числе продуктовые и бизнесов что все воркеры у вас в один момент времени получили задачу на выполнение запроса к кликхаус а это значит что они там например 2-3 5 минут заняты чем-то что не отвечает потребностью в регулярном запуске других метрик Это значит что вы опоздаете на 3-5 минут пока там где-то тайм-аут несётся поэтому сделали опять-таки классическую проу простую штуку Мы создали типы кластеров по скорости работы Сейчас пока выделили два типа и медленные запросы отправляются к неудачно кластеру а всё остальное работает в стандартном кластере количество кластеров не ограничено всё в админок добавляется красиво и просто плавно подходим кри Рик как я сказал Мне очень было интересно иметь тысячи метрик да то есть и десятки тысяч добавлять ручками по одной метрике это прямо Ужасно даже если ты напишешь скрипти который это делает нужен инструмент который позволяет любому человеку Кто примерно понимает что такое регулярное выражение добавлять большое количество метрик поэтому у нас появился отдельный контейнер с отдельным демоном в рамках этого Демона происходит регулярная актуализацию метрик приведу пример с заксом значит предположим это реальная Задачка У нас есть 40 Серков которые отдают картинки превьюшки для серий мне хочется построить для всех этих сока Серков метрику сколько трафика они отдают я беру простую регуляр в данном случае это вообще маска Хоста дёргается опика закса кото по данной маске возвращается список всех хостов и ээ по каждому хосту создаётся отдельная Метрика по исходящем трафику Я точно знаю что у меня таких штук не больше сотни вот поэтому раз в сутки достаточно чтобы подобное Ну по сути кронк работал и супер простое решение супер эффективное автоматически добавляются новые серваки или виртуалки уходят в эксплуатацию возвращаются Вот всё работает корректно и классно но настоящий оргазм я испытал вот сейчас когда сделал аналогичную штуку для кликхаус и для разных и бизнесов и продуктовых и где-то технических метрик У нас например of serv это метрики качества видео просмотра они живут в кликхаус сколько там длилась буферизация сколько происходило Старт видео сколько инициализации плее всякие такие штуки И как вы понимаете у нас там разные платформы десятки разных плееров куча разной информации хочется свести её воедино аналогия полная с тем что мы делали в заксе в заксе мы отправляем запрос и регуляр чтобы получить список кандидатов А здесь мы пишем специальный сэк на экране вы видите пример эника Не пример результат работы эника который вернул айдини контента в данном примере мы хотели построить для каждой Конте коих несколько десятков тысяч хотели построить графики по просмотрам берётся каждый дишни подставляется в шаблонный SQL получаете метрику которая точно также трека ется как и все остальные и универсальность этого решения очень простого заключается в том что вы можете количество колонок в первом аэ делать неограниченным А это открывает перед вами декартово произведение всех возможно наме в случае с конкретным примером Вы можете построить метрику вернуть ещ одну колонку страна вернуть ещ одну колонку тип платформы и построить метрику например Как смотрят сериал зимородок не знаю в курсе ли вы что это или нет но Живите теперь с этим один из самых популярных сериалов сейчас в России как его смотрят в Казахстане на вебе Или например как мультик Три кота смотрит сейчас в Ярославле на они получаются у вас из коробки Как раз за счёт того что вы умеете просто писать SQL Да это немножко более сложно Чем написать регулярное выражение Вот Но зато написав один SQ вы получаете тысячи метрик которые трека идём дальше собственно чтобы люди как-то это всё воспринимали Мы конечно это запихнули в instant Messenger не очень интересный слайд просто с тем мам который надо сделать это тоже всё супер быстро это надо уметь поддерживать десятки каналов для коммуникаций нужно уметь потоками с треми Вот как раз треды используются для того чтобы реализовать режим детекции режим пребывания в аномалии то есть открываешь инцидент и дальше мы всё ещё в аномалии всё ещё в аномалии ой Аномалия закончилась вот Ну и конечно ссылки на дашборд потому что инструмент должен быть удобным у тебя всплыл Арт ты кликнул типа на график в фане и ты уже там ты уже всё понимает доклада Я сказал что я на самом деле провалился как руководитель потому что я сказал типа ну Ребята давайте нам возможно нужна детекция аномалий давайте вы как-нибудь там на инициативе всё сделаете сами всё будет классно и как бы получил как бы полный игнор вот а теперь я вроде как из говна и палок сделал что-то своё и надо чтобы этим люди пользовались вот после первой неудачи уже бы нече хоро этот Я использовал самый древний инструмент для мотивации хороших разработчиков которые хотят делать хорошо ценят свою работу и не хотят делать плохо это стыд на 2 месяца я и мой дружбан Лёха в компании стали самыми информированным людьми относительно всех аварий и всех аномалий Мы создали чатик под названием звездец детектор первое слово умышленно изменено Это был закрытый чатик куда мы все дистр алерты добавили ручками их было там сначала около сотни А дальше мы стали приходить в команды просто в чатик команд пи ребят у вас пяти сотых много так а вот вы да у вас у вас там память течёт Так а вы у вас время ответа выросло народ охренел Потому что когда там самый большой твой начальник приходит тебе и День за днём говорит что ты идиот и делает твою работу лучше тебя тебе становится как-то неловко Через несколько дней в этот чатик потянули все мои замы руководители по эс 2 недели пришли Лиды и говорят блин А мы тут Новый сервис запускаем Давайте его на поддержку детектором аномалий Ой а можно на мне туда доступ с этого момента я сказал Аллилуйя Вот и выдал доступ и безопасника и сказал так всем в отдел б они вам раздадут доступы прочёл лекцию на 40 минут относительно того как этим всем пользоваться и наконец-то расслабился и стал кайфовать что мы получили а получили сейчас у нас обслуживается около 25000 метрик Вот это и rps сервисов и сетевой трафик и там блист куратора который нас защищает от ддоса и какие-то продуктовые события очень классно происходит работа с как раз конверсия особенно конверсами в оплату взаимодействие против фрода против подбора паролей куча всего то есть мы настолько много всего узнали я сейчас говорю капитанские вещи я это прекрасно понимаю но когда у тебя это есть ты кайфуешь когда у тебя нет Ты понимаешь это пря очень плохо и больно вот севский трафик вот тут тоже у меня поехала вёрстка вст всех микросервисов ну ничего вот и по-хорошему Я посчитал что за вот уже наверное как почти 7-8 месяцев продакшн эксплуатации мы во-первых сэкономили для компании около 450 мл руб потому что где-то мы увидели падение конверсии где-то мы увидели э зарождающиеся ошибки вот и осознанность наша по ведению нашего инженерного хозяйства стала намного и намного больше От чего Собственно как технический директор Я очень сильно кайфую А ну что же дальше А дальше Можно конечно поговорить про следующий этап - это детектор э корреляции да то есть когда у вас есть разные аномалии и вы прослеживается причинно-следственную связь а и особенно если у вас есть какая-нибудь там Open telemetry на текущем хайде будет довольно много рассказано про трассировку и вот должен вам сказать что написать детектор корреляции практически так же просто там тоже довольно простая математика как и за как и создание детектора аномалий Поэтому если вы захотите повторить пройти мой путь Я думаю что он будет для вас супербыстрый и супер классный вот мне было приятно тут вас развлекать Если вы проголосует мне будет ещё вдвойне приятней А теперь я готов ответить на ваши вопросы он мой дружбан уже идёт спасибо как всегда бодро и развлекательно а а у кого микрофон скажите пожалуйста Ага Так ладно прыгать со сцены не буду а то плохо закончится Ну давай грома Спасибо за доклад прям прям Здорово возник Вопрос такой У вас есть автоматика добавления новых метрик и так далее но у нас метрики бывает Надо не только добавить но ещё и убавить просто получается что у вас есть механизм классного добавления громадного количества метрик А как вы решаете проблему ренна для этих метрик когда они больше не нужны точно также шаблон или так Нет смотрите вот я специально привёл пример на котором Вы у вас два списка те метрики которые вы добавили и те которые вам сейчас вернул источник на одном из моих примеров там был закс у вас есть два списка вы просто как бы актуализируется одни относительно других если какой-то сервак ушёл из хостов Всё вы больше вы метрику удаляете и не жалеете о ней Вот поэтому как это актуализация Это не совсем добавление это добавление удаление вот более сложная история Когда вы хотите точечно потник сервачок То есть у вас есть массо редактирование есть какой-то очевидная персонификация отлично едем дальше прошу Добрый день спасибо Я тут я тут я тут Аче Чем занимаешься Добрый день Меня зовут Алексей компания вку автон тоже спасибо занимаемся и метриками в том числе Спасибо за доклад это классная ирия хуже и сложнее два Ну наверное вопрос какая команда ответственна за вот тепер создание этих метрик и наверное за их применение в работе то есть разработка поддержка кто это делает у вас Ну каждая команда отвечает за свою группу метрик у нас около 25 команд и каждая команда отвечает за какой-то свой сектор микросервисов где-то инфраструктуры поэтому у метрики есть хозяева там отдельные права доступа и всё точно так же как например и с ответственностью за код То есть ты отвечаешь за этот код и ты отвечаешь за то как этот код работает на проде то есть это разработка то есть метрики должна внедрить разработка в ито у вас да то есть смотрите где-то разработка где-то эксплуатация где-то вот Ну например часть метрик использует просто продуктовые аналитики которые у них есть доступ в детектор аномалий они пишут туда свои Да и тем более вот смотрите у вас где-то разработка где-то эксплуатация Как определяется эту грань плюс Метрика в рамках аналитики это может быть да у нас сегодня там повышенные просмотры там какого-то сериала соответственно А у нас а скажем так бизнес-аналитика совершенно другая и нам а надо что-то докупить закупить принять какие-то бизнес-решения и это как бы должно уйти вообще в аналитику но при этом аналитики могут сказать Да мы метриками как бы не занимаемся вообще что вы от нас хотите Кто тут что сломал Как у вас разделяется ответственность в этом Ну смотрите всё всё разделяется по задачам есть например отдел продуктовой аналитики которые трека продуктовые метрики они сами создают метрики за которыми им нужно следить и Они следят за тем чтобы они были актуальны правильно настроены и и они знают что с этим делать Вот а есть эксплуатация которую хотят следить за серверами друга Извините пожалуйста и они отвечают за Каждый элемент системы То есть за там не это сервис Ну то есть У тебя есть доступ в админку в этой админке Ты можешь создать метрики за которыми следишь Как решается проблему Когда аналитики Говорят это не наши метрик упали это упал сервис мы тут ни при чём они короче аналитиков не бьют поэтому сни мы вообще никого не бьём мы все смотрите Но это же это же что делает детектор он тебе просто зажигает ч лампочку что что-то идёт не так а дальше это уже задача как прострой процессы внутри компании таким образом чтобы на это на каждую аномалию была соответствующая ре это в том числе Моя работа как технического директора это работа директора по продукту это работа бизнесов топ-менеджеров то есть мы должны сделать так чтобы люди были неравнодушны к тому что им кричат типа ребята у вас проблема Спасибо большое Спасибо будьте добры вы добрый день Добрый день спасибо за доклад Михаил Вов Компани сие я руководитель группы мониторинга Поэтому вот эта тема была мне Осо близ и такой вопрос в архитектуру было заложено использование нескольких экземпляров детектора Как вы вообще синхронизируется их между собой То есть каждый детектор обрабатывает только какой-то источник данных либо Они между собой ещё распараллеливания используете твитеров скую либу всегда эта Метрика будет обрабатываться твиттеров ской любой А есть там какая-нибудь продуктовая Метрика и вы там запихивает с смм внутри и связь Метрика детектор один к одному Нет я имел в виду допустим у нас есть массив какой-то там 10.000 Мет и нам их надо распараллелить по кластерам соответственно каждая нота забирает свой кусок нет ли проблем как раз-таки с синхронизацией То есть когда у нас на работа выполняется там двумя узлами тремя узлами Как вы с этим боретесь ну классическая история что есть э брокер который раздаёт всем если очень грубо задачи Ну и собственно есть определённый производственный цикл за который должно пройти должны пройти все метрики собственно дальше брокер может выдать метрики там для медленного кластера может выдать для быстрого А если секрет что за брокер Ну ручками написали это наверное лабораторная работа четвёртого курса по системам массового обслуживания Спасибо это да это та ситуация когда не вопрошающий троллят спике это веди себя прилично там кстати в чатике спрашивают Можете ли за о Если честно я ждал этого вопроса но не жалко но очень Стыдно потому что ну как бы я тот ещё программист там мне коне мой Дружба помогал БН надо потратить смотрите тратите там 20% времени на то чтобы сделать код который работает внутри вашей компании и 80% времени чтобы он работал где-то ещё универсально и везде То есть я готов как бы отвечать на вопросы делиться если у меня будет время с удовольствием выложу Open Source Вот Но блин честно пока с одной стороны сейчас стыдно с другой стороны там надо убрать как раз вот нашу Джанго со вкусом EV докер со вкусом и потому что всё это собирается сейчас Тупо из наших шаблонных ээ конфигов Вот это надо просто переписать на универсальные вещи Ну что ж вам удачи ещ два вопроса вот раздва остальное в кулуарах Простите просто времени уже не хватит Да добрый день спасибо большое за классный доклад реально классный потому что очень простой и у меня есть вопрос Вот вы позволяете создавать тонны метрик буквально ть не одной кнопкой но при в том что можно сделать маску захватит Ну вот если маску там по бизнес Метрика там какого-нибудь турецкого сериала все турецкие сериалы популярны один не популярен по нему шумные данные и он постоянно начинает кого-то бесить Ну того кто следит за метрикой А вопрос в том насколько быстро Ну вот в рабочих днях Там тюни эта Метрика чтобы она Ну оставалась актуальной показывала какие-то аномалии но при этом Ну как можно меньше отвлекала на себя ну смотрите ответ такой на наш девиз слабоумие отвага вот поэтому всем можно всё Но действительно слежение за метриками особенно когда их очень много требует так или иначе механизма ревью который сейчас у нас на регламентам уровне сделал что-то зубо дробитель скинь коллеге по ревью Ну и я показывал мониторинг который показывает Ну короче мы в Киба логи посматривая есть мониторинг который показывает насколько хорошо сечас эксплуатирует в система то есть страшно да в худшем случае мы ослепни именно по детекции аномалий но это не единственный инструмент контроля в компании Потому что никуда различные правила команд которые есть в заксе в фане в проте они никуда не делись это есть всё просто в дополнении к этому есть ещё вот как бы кандидаты на страх поэтому раз за разом кейс за кейсом Разбираем эту историю пока ври ревю но я смотрю на дашборди регулярно Вот и если что-то идёт не так просто тушатся целый одной кнопочкой целый Пласт метрик которые начинают паразитировать но ошибки Конечно есть но как бы ничего страшного Если у вас в Трай блоке пробежало несколько метрик которые отработали там по неправильной маске Ну ничего Спасибо большое спасибо И вот финальной буд добр Евгений Величайшее спасибо очень интересная тема дмитри компаниях У меня вопрос Вы в своём докладе рассказывали что какие-то решения были медленными А ну медленно у каждого своё В вашем случае что это было Ну смотрите вот твиттеров библиотечка она если вы скармливать ей там С шагом в там я не знаю 5 секунд данные за 2 недели она справляется с этим ну чуть там не знаю миллисекунд за 800 А есть решение где ве обрабатываются Ну там минуту и это ну абсолютно неприемлемо Спасибо Спасибо большое Евгений кому отдадим приз за лучший вопрос мне понравился вопрос про распараллеливание вот там вот молодой человек сидел дадада очень красивый мужчина в пиджаке вот наверно директор я так далеко красивых мужчин не могу замечать я смотрю в душу это же генофонд Российской Федерации не обязательно видеть лицо так заканчиваем Пропаганду правильно молодец молодец молодец да Тебе тоже памятный приз от конференции Спасибо за выступление Спасибо и проголосуйте А уже следующий слайд Да вот Спасибо большое так Да друзья если даже вы встаёте чтобы выйти из зала досрочно вот дальше по конференции сначала оценивайте доклад потому что это помогает программному комитету потом тех кто облажался больше не выпускать на сцену Да и мне как члену программного комитета об этом очень очень интересно узнать насколько я вообще идиот Спасибо большое интересно спасибо большое Да спасибо Жень"
}