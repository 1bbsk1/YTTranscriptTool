{
  "video_id": "8W2SNEMhRr0",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Меня зовут Соколов Александр я м разработчик компании gpm Data в докладе расскажу о том как мы с помощью и с помощью чего мы находим нужный фрагменты видео в огромном количестве видосов для начала несколько слов о том Кто мы такие сейчас кликер проснётся О да компания п Data занимается обработкой данных и видео в интереса Газпром медиахолдинга в медиа холдинге более 40 телеканалов свыше 10 радиостанций и некоторые из этих телеканалов и радиостанций являются нашими клиентами а компания входит в э систему git газпро ID ой и один из продуктов разработанный компанией gpm Data - это программный комплекс tagging System это комплекс предназначенный для поиска по видео контенту Я хочу обратить внимание что имеется в виду видеоконтент заказчика то есть не все видосы интернета не YouTube а именно то что есть у заказчика сейчас в поисковой базе более 40.000 видео Это примерно 18000 часов контента и в векторных базах данных ну порядка 25 млн векторов то есть было сейчас уже наверно значительно больше пример того как работает поиск по по видео Упс здесь видно поиск по цвету по палитре преобладающей Также можно искать видео по объектам которые находятся в кадре а начало неплохой можно искать по тексту и по тем личностям которые этот текст произносит какой-то просто тарантас кулебяка кулебяка кулебяка Кубяка вот такую кулебяку находит сервис богиня Да ну сервис не богиня сервис называется V и собственно презентация не о продукте vts презентация о том что под капотом вся история началась с постановки задачи нашими заказчиками весь весь задуманный функционал это был не какой-то сферический в вакууме все функции которые бы Рева прино к пришли менеджеры из компании пятница и попросили сделать поиск в котором помимо фильтрации контента по каким-то логическим атрибутам там название шоу год выпуска серии ТД ИТП были бы уже функции которые без ML реализовать было невозможно и наверное самое интересно из этих функций - это поиск по произвольному описанию кадров здесь мы видим поиск по фразе вид высоты птичьего полта чуть получается немножко крупнее один из кадров результатов поискового запроса также нужно было искать по базе персон необходимо было реализовать спич текст то есть преобразование аудиодорожки в текст для задач субтитров поиску по тексту поиску по фразе а поиску по набору слов по словарям например нужен был поиск по набору матерных выражений для задачи модерации нужно было распознавать объекты которые находятся в кадре и искать по этим объектам то есть мы работаем с классами Коко такая же история с позами людей на в кадре например одному из каналов требовалось находить для модерации кадры людей которые курят нужно было распознавать в кадре текст и искать по этому тексту поиск по палитре Вы видели как работает на демо ролике точнее на фрагменте демо ролика необходимо в качестве атрибута было задавать также кинематографический план здесь на слайде видно так называемый средний план кинематографический план - это способ представления классификации того изображения которое ви на Эне есть бывает РУП ла средний пла панорама какая-то планами для многих приложений важно было знать границы сцен в частности для расстановки рекламы так называемая задача Shot separation то есть шт или сцена - это последовательность кадров снятая камерой от начала Ну до конца да то есть последовательность между двумя монтажными склейка количество объектов кадре собственно для того чтобы работала поисковая система нужно было из видео извлекать какие-то фичи сейчас мы извлекаем ну сейчас больше извлекаем распознан текст классы действий надписи распознан палитры кинематографические планы границы сцен динги с описания кадра и класс объектов с их количеством теперь немножко улм в технические детали упе расказать тоете моделях наверно самая интересная модель используется для поиска по произвольному описанию может быть даже не модель а решение ВС само в качестве ра была вы модель от сбера это модель Она имеет нативный русский язык обучена на датасете из 240 лно пар текст картинка для своих Иу из сах вариантов моде 52 чтобы поиск давал релевантные результаты необходимо из видео извлечь как можно больше информации как можно Более точную но тут мы Встаём перед дилеммой То есть если мы будем делать с каждого кадра то поисковые базы очень быстро распухнуть и работать с ней будет невозможно тоже самое если мы будем брать какой-то один из по из сцены вроде бы это может работать но но нет это тоже не работает Дело в том что внутри сцены события как-то развивается и никакой один кадр не может сцену характеризовать пример в начале сцены человек лежит на диване потом садится на диван потом встаёт одним кадром эту сцену не описать поэтому встала задача Как из видео вытащить наиболее полное описание и при этом уложиться в минимальное количество векторов на первый взгляд очевидное решение кластеризация не очевидны тонкости реализация этого решени в качестве методов была выбрана иерархическая кластеризация она даёт очень хорошую вычислительную сложность То есть к задача кластеризации это прям Ну наверно лучший результат и ещё плюс это этого метода то что мы можем заранее не задумываться о том количестве кластеров которые в которые должны собраться Инги также одно из хороших технических решений - это кластеризация скользящим окном вычислительная сложность у нас квадратичная поэтому выгоднее скользящим окном пройтись и собрать много раз мелкие группы кластеров чем делать кластеризация плюс который мы получаем При таком подходе это то что в кластер собираются те кадры те кадров коры если Мы собирали кластера в кластера кадры со всего видео тогда в одном кластере могли собраться кадры которые отстоят друг от друга на какое-то время в чём плюс если мы используем скользящее окно то малого размера мы можем получать границы смысловых сцен что это такое то есть у нас есть динг им с этого ка этого этого описывает то что происходит в кадре на слайде дендрограмма Ну так называе дерево иерархической кластеризации то есть видно что каждый раз группа кластеров делится на две по вертикали костная близость по горизонтали номера кадров их не видно но в принципе Понятно если провести горизонтальную линию на уровне где-то 03 то вот эти группы эти кадры мы можем разбить условно говоря на три кластера здесь они выделены оранжевый красный и зелёный а из нашего опыта что можем сказать в оранжевый кластер собрались кадры которые примерно соответствуют сцене то есть одному шотут собрались кластеры один кадр только чаще всего даже не чаще всего А это монтажная склейка то есть кадр который не нет никакой нужной информации и зелёный кластер это тоже какая графическая сцена но она не полная то есть она не вошла полностью в окно кластеризации и поэтому она как бы обрезанная поэтому что мы делаем кластера в которой находится только один кадр мы выкидываем потому что это мусорные кадры последнюю большую сцену Мы на этом этапе не обрабатываем мы оставляем е как бы для следующей риза используем остальные больши странное оже Как это работает а да то есть группировка у нас получается как бы в два этапа то есть Сначала мы собираем большие кластера аналоги сцены и потом уже эти кластера дробим на более маленькие смысловые сценки примеры кадров первого и последнего КАД с кластера то есть на примерах видно что в кластер собрались кадры из одной сцены достаточно хорошо а вот собственно кадры которые оказались в кластере единственными это монтажная склейка то есть то место где применялись какие-то спецэффекты там затухания размытие плавного перехода одной сцены в другую и так далее им бедин из таких кадров бесполезны несут никакой смысловой нагрузки то есть Выгода кластеризации скользящим окном состоят в получении малого количества векторов и извлечении более полную информацию из видео а также мы получаем границы смысловых сцен и убираем кадры монтажных склеек тонкость кластеризации здесь ещё нужно сделать ремарку относительно того как работает алгоритм на длинных сценах то есть сцена может не помещаться в одно окно кластеризации приме является сидит какой-то диванный аналитик и на вебкамеру монотон что-то рассказывает в течение многих минут в этом случае если мы затекли только одну большую сцену мы расширяем окно кластеризации проводим кластеризации так делаем до тех пор пока либо размер буфера не станет предельным в нашем случае это 1 минута либо не появится следующая большая сча боль с то что для НВ мы берм не все подряд кадры из видео А примерно каждый шестой кадр и из шести кадров Мы выбираем из ше подряд идущих кадров Мы выбираем кадр с наибольшей резкостью это снижает нагрузку на модель и ускоряет обработку модель под всем хоро можно подумать что по разделению на сцену но к сожалению нет Никаким подбором пороговых значений для кластеризации нельзя заменить разделение разделение видео на сцены пример далее мы видим две сцены два кадра Точнее они принадлежат разным сценам но по косному расстоянию им бедин с этих кадров они очень близки Да к сожалению это нерешаемая проблема то есть описание этих кадров оно очень близкое то есть два человека какая-то дорога поэтому мы используем отдельно извлечения из видео сцен ещё одна модель о которую я хотел бы рассказать более подробно это виспер модель известная популярная но тем не менее тонкостей много дьявол кроется в деталях Когда у нас только появился спите Мы изначально пытались пробовать банков скажем так были заявлены очень высокие качества но на поверку оказалось что качество нас не устраивало оно было довольно низким я это связываю с тем что решение от банков и ведущих с тек поставщиков оно работает хорошо несколько в другом доме скорее всего это хоро работает в контрах ЕС подать дорожу какого-то фильма Результаты будут так себе поэтому походив по рынку мы остановились на виспе точнее на его форке stable TS который работает в режиме visper Faster и использует веса А модели visper lach 2 вот Fork stable TS даже делали а комита модель to Хороша всем высокое качество транскрибация поддержка языков многих то есть модель Может на ходу перескакивать А на английский язык на испанский язык возвращаться на русский всё будет корректно прекрасно оставляет знаки припинания знаки там восклицательные вопросительные а начало предложений пишет с большой буквы имена собственно с большой буквы а вфр stable TS даёт правильный йп это очень важно если мы готовим субтитры всё классно один минус галлюцинация модель склонна к галлюцинация если випи из коробки подать аудиодорожку от какого-то фильма Скорее всего вы получите на выходе крайне нетель результат до какого-то момента модель будет распознавать аудиодорожку А потом перейдёт в режим циния собственно о борьбе с галлюцинациями я и хочу рассказать выде вици этои Лаки подписывайтесь на канал и так далее скорее всего это вызвано обучением виспера на открытом датасете эти фразы возникают в те моменты когда в аудио дорожке нет голоса и вероятнее всего в тех данных на которых модель училась в этот момент вставляли какую-то рекламу далее зациклен на одном звуке на одном протяжно звуке модель очень часто срывается в то что начинает повторять небольшую последова из дтх символов бесконечно И третье это бесконечное повторение фраз возникает оно в произвольные моменты и если оно начинается то оно как правило не заканчивается До завершения фрагмента аудио то есть продолжается бесконечно при этом естественно распознавание аудио завершается чтобы оценить Нако хором суб ци нациями и повышаем качество распознавания мы собрали собственный датасет из аудиодорожек фильмам а продолжительностью от 20 минут до 2 часов и к этим аудио дорожкам профессиональные редакторы подготовили субтитры в качестве метрики мы используем стандартный Word ER Rate но с некоторыми тонкостями то есть мы рассчитывали метрику как средняя из четырёх расчётов Word eror Rate первое это сравнение эталоны субтитров и то что выдал без обработки второе тоже самое но без знаков припинания третье тоже самое что в предыдущем Но приведённое к нижнему регистру и четвёртое - это приведённый текст к нижнему регистру без знаков припинания и без пробелов и о том что мы получили из короб нам 055 совершенно какое решение самое простое использовать Voice Activity det мы использовали Audio нарезали видео на нарезали аудио на фрагменты и скармливали фрагмента виспе качество сразу резко подскочило хотя бы за счёт того что при начале галлюцинаций эти галлюцинации они не выходили за пределы одного аудио сегмента то есть остальные сегменты оставались корректно распознан далее Это удаление фиксированных фраз фиксированных галлюцинаций Так мы их назвали стоп словами наверное наверное неудачное название презентации Вот они достаточно хорошо детект по словарю и сразу улучшили качество где-то на 1% третье - это детекция и определение заливай я уже говорил если начинаются то они не заканчиваются поэтому достаточно просто алгоритмически методами их определить здесь мы ещё на примерно 0,8 улучшили качество но и это было не всё как я говорил если ви начинает цини то он уже не завершает галлюцинации до конца Поэтому просто удаление зацикливания недостаточно мы делали переработку аудио тку аудио фрагмента с того момента когда были за детектирования из того что ему предлагали мы и там до этого и наши конкуренты нете моментов котом Я хотел бы рассказать Первое - это предобработка аудио Перед подачей аудио visper бы динамически выравнивать уровень громкости это немножко доки дыловодства фильт для подавления шума или для выделения голосовых частот практика показала что Да действительно на некоторых аудио дорожках это чуть-чуть доки качество Но в среднем на всём датасете качество только ухудшалось третий момент связан с тем что Voice Activity detection не всегда может распознать речь и очень часто он пропускает какие-то фрагменты говоря что здесь речи нет чаще всего это касается каких-то коротких фраз видимо аду требуется чуть больше чуть больше длительность и на тонкая настройка параметров к сожалению не позволила нам заставить работать Voice Activity detection корректно поэтому мы обрабатывали 100% всего видео вдом но а кажется да Зачем тогда делить видео на фрагменты А те фрагменты в которых гос не был за за detection они обрабатывались алгоритмами удаления галлюцинации с более жёсткими настройками и четвёртое наверное тоже довольно интересное - это манипуляция с протом то есть ви можно подать промт и вроде как Вис должен войти в контекст и этот промт должен улучшить качество распознавания на самом деле нет промт не доки дытячи цини в тех моментах когда он не может опознать голос чаще всего то чем он начинает гонить это является именно промт То есть он повторяет фразу из пром Поэтому если подать специальную после символов Ну в нашем случае набор там точка запятая то начинает люци то есть мы провоцирую его цини именно этой последовательностью которая очень хорошо определяется и очень хорошо модель простая я не нашл ничего подобного в репозитория Интернете Но тем не менее хочу о ней рассказать Она довольно изящная модель без модели все расчёты впа на слайде палитра в 64 цвета из неё пользователь при поиске набирает нужные ему цвета расставляет весовые коэффициенты и отправляет поисковую систему 64 цвета - это обрезая палитра обрезана Каким образом четырём градация то есть мы на каждую градацию цвета на каждый канал оставили четыре градации обычно а картинка кодируется вось битами на канал то есть 256 града на канал а то есть преобразование в предельно простое мы ставили эксперименты делали палитру менее обрезанная то есть палитру 125 216 Ну нетрудно догадаться да 64 125 216 - это кубы четвёрки пятёрки шестёрки то есть того количества градаций градаций канала которые мы оставляли практика показала что палитры из цветов вполне достаточно алгоритм следующий то есть картинка переводится в обрезанную палитру по каждому цвету мы набираем статистику Как часто он используется и дальше нормализует получившийся уже можно использовать для поиска например по костно близ поисковый запрос то есть здесь 24% красного 37 сиреневого и 39% это любой цвет Ну вот примерно такой результат можно получить это не единственная модель по прочим моделям нано можно пару слов сказать про моде определения пла на базе 50 для неё на толоке Мы собирали датасет меча его проводили обучение все остальные модели осные и взяты были без дополнительного обучения теперь о том как мы обрабатываем данные о пайплайф которая извлекает из видео какие-то изначально они были последовательные и один час одно часовое видео обрабатывались примерно за 18 часов а для mvp это было вполне приемлемо Но для прода это решение не годилось чуть крупнее пайплайн что мы сделали для ускорения Первое это нормализация видео то есть все видео мы приводили к формату 25 кадро в секунду и в дальнейшем стали также извлекать аудиодорожку и тоже её сохранить в pcm формате й который отвечает за поиск по описанию кадров был добавлен функционал генерации ю картинки то есть на каждый смысловой бенг на каждый Вектор мы генерирование этих картинок оно существенно упрощает пользователю получение поисковых результатов то есть пользователь из видео видит набор картинок к тем роликам которые он находит дальше для ускорения стали думать что можно сделать некоторые стейджи работали очень долго потому что им приходилось перелопатила было очень интересное мы стали картинки превью использовать в качестве входных данных то есть стейджи стали работать часть стейджи стала работать на картинках а не на всём видео эффект был такой что скорость увеличилась э уменьшилась с 15 минут сократилась до 40 секунд и фактически была ограничена скоростью скачивания этих картинок далее модели переводили в Tor RT это дало ещё ускорение в три в четыре раза На некоторых моделях ещё одна Техническая хитрость - это разделение этапов детекции и эмдин гов результаты детекции каких-то объектов в кадре можно использовать в других жах для оптимизации их работы например в случае с получением ли мы использовали разделение на сцены для того чтобы проще производить трекинг лиц и получать более качественные бедин Это не единственное применение и естественно Параллельная обработка итоговый Граф вычислений вы видите на слайде он уже не такой простой и время выполнения время обработки видео одного часового сократилось СМИ уже является прям хорошим приемлемым результатом и это при том что количество стей то есть тех функций которые извлекают чи увеличилось с 10 до 13 и пару слов о том как всё это разворачивается все приложения у нас развёрнуты в кубе каждый ж которы завлекает представляет собой микросервис и количество воркеров которое запускается зависит от того насколько этот микросервис загружен соответственно те а стейджи которые работают медленно получают большее количество воркеров версионирование Мы выполняем как в хмр тах так и А в самих стейдж То есть когда стейдж генерирует фичу Он сохраняет версию свою версию А как один из артефактов это очень важно поскольку видео часто приходится перерабатывать переть их приходится из-за изменения пап из-за внедрения новых фичей из-за улучшения каких-то фичей и если у стей входные данные не менялись а изменилась только версия та версия которая была предварительно обработана на предыдущей рации не сильно изменись то есть изменись допустим пач версия а мажорная минорная версия осталась той же самой то в этом случае с спает обработку и экономит нам ресурсы артефакты мы храним В3 а управляет ВС всем этим Да связка Да п се пару слов ещё нужно сказать про сери сел заточен на работу с очень маленькими заданиями и есть проблема с тем что задание требующие длительную обработку в сере иногда работают некорректно связано как by Design разработчики это не собираются фиксить но мы для себя для селера сделали небольшой фикс который снял потенциальную проблему зависания пода на глючные задачах или в рете Бага и кейс заказчиков Так я уже немножечко за полчаса выхожу Примерно в 20 раз мы сократили время на подбор материалов для канала пятницы в качестве примера некоторые производители допустим противо простудных средств требует показывать чтобы реклама их продуктов запускалась когда люди кашляют говорят о здоровье или сервис по продаже билета хотят чтобы реклама вставляла тогда когда люди говорят о путешествиях на фоне пляжей аэропортов подготовка рекламной кампании требует осмотра глазками для менеджеров десят часов контента и может занимать до 3 недель в нашем случае сюи системы достаточно быстро можно получить необходимые ролики один из реальных кейсов компании требовалось вставить рекламу клининговой техники И для этого искали сцены где моют полы такие сцены Нашлись закон предписывает 5% эфира покрывать субтитрами создание субтитров у профессионального редактора занимает примерно 8 часов на 1 час видео в случае с vts редактор может выгрузить субтитры готовые и таким образом сократить время работы где-то до полутора часов Спасибо за внимание голосуйте за доклад если было интересно если на чито вопросы Я не успею ответить У нас есть вопросов ответов то мои контакты в телеграме а Спасибо большое хорошо было мне кажется есть ли вопросы коллеги а прекрасно прекрасно Александр Выбирай Спасибо большое за классный доклад Я Александр компания Яндекс У меня три вопроса если Нате Можно два выбрать Давайте сначала вопрос потом ответ перво когда рассказывали про у вас оставалось е 18% ошибок теть айсберги или это просто тяжёлый хвост который вот бесконечно разгребать Ну виспер он не идеален во-первых во-вторых сама методика это данные Вер которые получаются на нашем датасете Это не то что публикует Open ai и какие-то там другие разработчики спич текстов То есть это именно наше и надо учитывать что Ошибка допустим в одном в одной букве в слове нераспознанный это уже будет Неправильно распознанных очень много слов которые виспер не может правильно произнести он иногда не понимает английские слова иногда ошибается в одной букве Ну вот так вот Окей Помогает ли Ну вот вы щее окно там для фичей для кластеризации кла рассказали архитектуру Помогает ли опять же пере разметка выс опять же для чтобы бороться с цива просто с разных мест перекрывать субтитры а не последовательно их дела Нуф Да фактически мы это и делаем то есть если мы детек галлюцинации зацикливание то мы определяем то место где оно начи как Понятно просто ти с ТХ разных мест ранить Нет мы это не делали и были уже какие-то ситуации когда поняли что вот нужно глобально пересчитать фичи вот сколько ну выписали вас огромная Да это база видео Сколько занимает пересчитать какой-то чтобы переиндексация по все обму видео она возникает для какого-то конкретно заказчика и для какого-то объёма видео производитель палана у нас там не топовая там не мегала всего там порядка видеокарт примерно за выходные пересчитывается в районе видео даже пере так у кого микрофон Александр Да повторяем вопро вопрос был такой 2000 видео Какой длины Я не знаю ае Спасибо зайо ня чи вы говорили что вы с помощью Вада сначала выделяли речевые фрагменты а потом випр распознавали это улучшило качество А вы не проверяли вариант когда мы вместо достаточно простого Вада P который Ну может ошибаться мы используем своего рода Вад на стероидах типа W более простая модель распознавание речи она не виспер она гораздо быстрее работает и при этом мы можем же мой опыт подсказывает что мы можем двух Зайцев убить Сначала мы более точно чем простой ват выделяем речевые фрагменты а потом при распознавании виспера мы можем выхо виспера сверять с тем первичным распознаванием которые сделал фто век например чисто лексически для того чтобы препятствовать люци ээ вы такой вариант проверяли Если нет то почему Если да то что пошло не так Спасибо хороший вопрос а такой вариант планировался к проверке А и именно планировался вот как бы завершить э распознавание алгоритмическое Да и перейти вот к чему-то подобному То есть к работе по двум моделям Тем более что это обещало дать хорошее Более точную привязку слов ко времени но практика показала что и так работает хорошо ресурсы команды ограничены Поэтому просто вот от того что бы не стали улучшать уже хороший результат Спасибо большое за доклад интересует такой вопрос Вы сказали что шумоподавление Вт нание ситуациями Когда у нас есть голос на фоне музыки на фоне там где-то кто-то летит на фоне песен и так далее это действительно проблема потому что если одновременно говорят несколько человек голос на фоне музыки действительно в этих моментах работает плохо в планах у нас попробовать восстановление голоса нервы моделями Но это в планах опять же ресурс команда ограничены Вот то получившееся качество есть Ну пока Нас устраивает для поисковых для поиска это отлично для работы тех редакторов которые подготавливают субтитры это тоже хорошо и субтитры они к сожалению Ну прямо не идеальны да то есть приходится руками что-то править Так ну вот в чёрном передайте микрофончик Здравствуйте спасибо большое за доклад У меня вопрос по поводу распознавания текста на кадрах вы сказали ну вроде бы вы упоминали что существует функция поиска по тексту в кадре Вот Но как решалась проблема с тем что текст не всегда целиком попадает в кадр зачастую он проезжает мимо кадров и надо как-то объединять его в смысловые куски можете поподробнее про Вот это рассказать смысловые куски мы текст не объединяли получается что при распознавании текста из кадров распознаются несколько кадров и с этих кадров получаются обрывки текста Вот какойто из обрывок попасть в результат поискового запроса Ну то есть это не семантический поиск где мы пытаемся смысл поиск по надписям это не семантический поиск и поиск вообще по тексту он пока ещё не семантический то есть это решение по семантическому поиску Оно ещё не на проде у нас поиск идёт пока по по словам Спасибо большое раз-раз большое спасибо за доклад очень интересно Александр си А подскажите пожалуйста пробовали ли сделать прямо генерацию чего наподобие сценариев или описаний видео из самих видео и э что получалось если не секрет то есть сумали видео Ну наподобие того что там сейчас показывают А вот такой текст всплывает А вот мужчина главный герой делает то-то да спасибо Хороший вопрос А значит мы ориентированы на запросы заказчика то есть от заказчика такой функционал не запрашивается Вот Но но тем не менее движение и разработка фичей в области понимания смысла именно того что происходит видео и мультимодального обработки оно идёт Пока не на проти тоже да Меня зовут Данил Качанов Я работаю в компании Магнит Скажите пожалуйста я правильно понимаю что Если ваше ну так скажем время обработки час и видео занимает 45 минут то вы можете с неким лагом но в реалтай Като поток и вы раскатали это решение только на канал Пятница или были ещ какие-то проекты клиенты так начну с конца Нет пятница Это не единственный Клиент не всех клиентов как бы можно упоминать у нас порядка шести клиентов насчёт Реал тайма нет Это принципиально нетай и для этой задачи никогда реалтайм не будет то есть зада ставится в очереди и когда очередь дойдёт до видео там это зависит от от загруженности палена Добрый день спасибо за доклад разметили много данных аудиодорожек не думали в Open Source выложить Хороший вопрос Спасибо Да как раз вот есть мысли какие-то из решений выложить в Open Source но не я принимаю решение Наверное это будет обсуждать и если от руководства будет разрешение на то чтобы выложить куски А это всё-таки куски рабочего кода в Open Source обязательно это сделаем Извините я не про код Я про данные про разметку и аудиодорожки вот это точно не может быть выложено в общий доступ потому что контент закрытый - это контент контент онлайн кинотеатров контент каких-то кинокомпаний он защищён как бы правами так вот девушка Здравствуйте Александр Меня зовут Анна компания криптонит Вот вы буквально в ответе на на один вопрос упомянули что сложные кейсы по типу шумов в аудио или двух каналов Скажите пожалуйста как вы поддерживаете вот высокое качество то есть Есть ли у вас какие-то приёмы Когда вы можете валидировать что у вас там например модель ошиблась мы можем проверить только то что модель снива А есть у Вас Вот в планах какая-то такая разработка Чтобы понимать когда модель жат Нега не галлюцинация я я понял а то есть на ходу оценить качество Да это не доведено было до финала то есть планировалось распознавание а двумя моделями то есть одна модель грубая который допустим в ловер кейсе всё произво переводит и далее виспера и по сравнению результатов а понимать насколько visper там люци ет или нет но опять же мы получили хорошее качество на тех решениях которые есть поэтому дальше мы не двинулись хорошо спасибо кажется у нас всё да коллеги Александр ну самое сложное как мы обговаривали да самый лучший доклад ой самый лучший доклад Да самый лучший вопрос выбрать нужно А ты помнишь вопрос я помню докладчика вот в зелёном докладчика вопрос К сожалению я забыл у меня вот СТК перепони прекрасно Иван Спасибо за вопрос а у нас Александр Разумеется есть подарок и для докладчика то есть для тебя Спасибо тебе большое за замечательный доклад коллеги появляется приз раз появляется приз два Давайте поддержим поддержим приз докладчика докладчика уже поддержали а в целом Ты же будешь ещё да на на стенде или где-то здесь ещё так что коллеги я уверен у вас ещё наверняка будут вопросы которые Может быть там нельзя сейчас задавать или лучше в кулуарах А спасибо большое Александр коллеги Спасибо"
}