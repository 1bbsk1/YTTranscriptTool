{
  "video_id": "_Is7pt4BC7g",
  "channel": "HighLoadChannel",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "друзья Всем привет подтверждая слова кате по поводу вечернего чата Мне Точнее по поводу чатов рабочих мне сегодня в 6 утра написал человек наш один из главных заказчиков по проекту про которому я вам буду рассказывать А почему у нас вечерний тель штормило В общем я доклад рассказываю а там штормит ну у нас команда клёвая короче будет решать без меня Давайте знакоми Крат Лянка хотел обойтись вот этой коротенько обби бочкой чем я занимаюсь но потом поностальгировать вспомнил Сколько всего интересного произошло с двенадцатого года пока я хранилищами занимаюсь то есть первое моё хранилище - это была команда из шести человек где я пришёл как разработчик мне говорят Ну начинай разработку Вот тебе пароль от Сиба и есть только прод А за лет пять эта команда выросло до 30 человек естественно появился и деф и прод идир и процессы гораздо интереснее стали релизы начали ставить их поддержка появилась потом занималась интеграцией в той же команде в той же компании где доставлял данные в хранилище и в другие системы в том числе операционные это было интересно потому что часть систем были особо критичные Когда в течение часа ты руководство не отчитывается А когда же ты всё поправишь начинается так съезжаем все в офис приезжаешь ты приезжает Твой руководитель приезжает руководитель руководителя приезжает директор всего что есть и начинает вместе думать что Тим м делать А внедрять в принципе хранилища с нуля То есть когда у тебя есть свои три контура на вендер и есть ещё три даже четыре кондуй соде в которое у тебя нет в принципе доступа То есть это поставок вот ставишь по инструкции и думаешь а взлетят не взлетят Ну чаще всего взлетали но были и проблемы и сейчас занимаюсь построением хранилища в X5 ril Group Ритейл он такой Ритейл А вот наши масштабы 700 серверов суммарный полезный объёма 12 пиб это хопчик а Чуть поменьше это у нас Green plam почти 50 серверов и 250 тбайт полезной нагрузки и кликхаус как движок - это 30 ТБ полезной нагрузки и 15 Северов Ну это один из Клик хаусов который у нас есть И один из Грин пмо там есть ещё другие бизнесов нпм это Центральный и наш utl Центральный тоже это 5.000 интеграций и примерно 60 ТБ ежедневного инкремента данных Ну как инкремента потоков данных не всё из этого ложится в инкремент что-то перезаписывает а проект Ну мне кажется нетипичный для текущих докладов пото что здесь любят рассказывать как распиливать монолиты А у нас чуть обратная ситуация мы взяли Монолит и начали натягивать на текущие бизнес-процессы Как сказать миграция из одного Монолита в другой Монолит то есть про это главная дилемма текущего доклада То есть у нас бизнес когда когда пришли проблемы бизнес лишился возможности продлевать лицензии и нам пришлось менять оркестратор к нему у нас были пробле были вопросы потому что он был монолитный был вендорный на него нельзя было Простите чуть волнуюсь на него нельзя было натянуть текущие современные процессы и мы давно хотели его поменять и тут случись э замечательная возможность а из специфических моментов которые у нас есть наше хранилище оно мм активно используется в операционных процессах То есть если э на хранилище произойдёт какой-то сбой то в течение нескольких дней будет ээ влияние на бизнес То есть это или на полка какие-то проблемы или прямые финансовые потери и из-за того что хранилище активно используется У нас не было возможности на проект вынести код Фриз то есть сам по себе проект о чём что у нас есть наш тель движок Он огромный он крутит 6.000 потоков и нам Пришлось его экстренно менять и мы начали рассматривать варианты которые есть вот если в цифрах посмотреть что у нас получается ежедневно считается 6500 потоков сам sdi у нас давно уже не в заводской конфигурации То есть он уже несколько лет нас как не устраивает мы отпилили от него ту часть которая отвечает за оркестрация чтобы упростить это стало там большим плюсом в текущем проекте само хранилище используется в и в Гри То есть это стопроцентная утилизация ночью стопроцентная утилизация днём то есть ночью считается е днём считается бизнес бизнес считает от хоки и соответственно Здесь мы получаем проблему что у нас в случае каких-то сбоев миграции могут быть будет минимальный запас на устранения проблем и само хранилище очень активно 910 релиза в день то есть днём считается ите всё дневное технологическое окно ставит релизы В прошлом году у нас поставили 1700 релизов в этом году думаю ещё больше будет соответственно чтобы начать проект мы обсудили границ с бизнесом зась перед ними что сохраним в при щие достижений которые у нас есть это высокая нагрузка высокая отказоустойчивость у нас 6500 потоков и это выливается примерно в 1.000 витрин которые покрыты слм эти 1.000 витрин ежедневно считается с слм примерно 96-98 про то есть почти стопроцентное попадание в требования бизнеса то есть важно было это сохранить и сохранить Time to maret то есть недопустимо было сильно повысить даже в процессе миграции трудозатраты разработки Ну 10% я в принципе считаю то что такая больше статистическая погрешность и по факту Мы закоментить что на время миграции бизнес не заметит то что происходит миграция Ну и для себя закамини Ну текущий проект имеет строгие дедлайны потому что лицензия заканчивается ровно в день когда закончится лицензия все потоки остановятся но это не будет бегством то есть мы выберем полноценное решение которое дальше будем развивать хоть и с мигрирует тех долгом и одно из тоже одна из целей которую мы для себя выбрали это развернуть достаточное количество контуров то что у нас был и было всего два контура про и тест Ну про и и здесь мы поставили цель развернуть нормальные процессы что понимали что безд мы не вывезем просто этот проект и в общем с такими договоренностями мы получили рассмотрели все открытые варианты посмотрели что достаточно зрело под наши масштабы и остались только два решения одни из требований были это сильная комьюнити гарантий того что текущее решение будет развиваться зрелость с точки зрения отказоустойчивости и масштабирования и вот dbt лучше всего нам подошли dbt мы использовали какви как оркестратор это максимально ложи нату СМУ У нас есть у на са используется как движок а самописный саду используется как оркестратор после того как выбрали движок мы начали перекладывать понятийный аппарат здесь мы столкнулись с первым сюрпризом в сале единица запуска - это дж это вот большой квадратик имеет какой-то набор трансформаций от до 12 рас шаг расч - это SQL запрос соответственно в дети это всё перекладывается в модельку и у нас наши 6 поя джав превратились в 30.000 моделей dbt в перспективе и на этом я вам скажу dbt просто сдох ну мы же инженеры мы и нашли выход Ну мы как инженеры подумали потом разберёмся Ну это одна из историй почему это вс-таки натягивание текущего софта на Монолит там будет достаточно в конце достаточно Интересная история как же мы всё это решали переписывая открытые пакеты Так ну и запустили R убедившись что наше решение хоть чуть адекватное и что то что мы выбрали устроит бизнес запустили сас в простейшем ой запустили dbt в простейшем варианте запустили мигрировали 60 джабо и в течение месяца крутили их в параллельных структурах данных то есть взяли про Тей дневной у нас максимально простой 6 жав структур и при помощи скрипта свели ежедневно расхождение не показало поэтому мы говорим всё хорошо и пошли уже в бизнес прорабатывать вариант миграции на вариантах миграции мы сделали три подхода самый первый подход это прыжок Веры он был максимально водом 100 наших 6500 джебов может из саса конвертировать в новый стек airf + dbt плюсом Здесь было то что сас - это Открытый формат все его трансформации они э хранятся в текстовом в текстовом виде их можно взять их можно как-то преобразовать зная зная документацию саса и получить какой-то результат Ну соответственно решили что можем написать такой конвертер а заморозить на какое-то время разработку и в одну прекрасную ночь случится магия мы перейм на новый софт Ну тут вспоминаем что наше хранилище активно используется в процессах и идеального сценария не случилось бы мы бы минимум неделю А то и месяц отважились отказаться потому что там слишком высокие риски следующим вариантом как раз был распил Монолита почему сейчас доклад не про распил Монолита А про натягивание нота на Монолит нас хранилище это потоков и 20 доменов каждый из доменов чётко очерчен на первый взгляд То есть это табличка витрин за которую отвечает отдельные команды разработчиков аналитиков Архитекторов данных и даже тестировщиков и соответственно если сверху глянуть то выглядит как набор изолированных доменов которые можно разделить каждый из них можно запустить в отдельном регламенте и получается по факту Даш когда каждый живёт изолировано и потом на границах этих доменов изолировано там совсем чучуть обмениваться данными пришли к бизнесу они говорят Да у нас доменная модель Но это неш домены не изолированные мы не поверили покрутили сами Граф увидели что в зависимости реально все со всеми и что-то изолировать не получится и отказались от этой идеи и последняя идея которую мы проработали которая лучше всего зашла Это идея параллельной работы оркестра В чём она заключается Ну она имеет максимальную гибкость что мы делаем мы берём текущий сас оркестратор а изучаем его где-то за документированной логику где-то Не задокументировано реверс ирим А кстати когда я говорю сас оркестратор Я имею в виду наш самописный сасо оркестратор соответственно и берём эту логику переносим на airf э учим АФ и на афо загружаем тот же самый граф Граф еля который есть учим airf ровно в том же самом порядке как сас обходить этот Граф и учим два оркестратор с другом взаимодействовать то есть что происходит оба оркестра в состоянии запускать один и тот же Граф как пустышку в том же самом порядке потом они учится как выполнять задания именно на расчёт или смотреть Как выполняется задание на расчёт в соседнем оркестра Таким образом мы получаем два разреженных графа каждый из которых или выполняет задание ждёт пока Это задание будет выполнено на другом оркестратор Ну получается распределённый оркестратор ещё и на разнородной стеке выглядит несколько авантюрного преимущество это что в случае проблем всегда можно откатиться то есть Первое это можно очень точно перебрасывать расчёты начиная с не критичных и в случае каких-то проблем эти расчёты откатывать обратно то есть мы этим регулярно пользовались когда есть какие-то проблемы с производительностью или вопросы Мы джебы и звезда нашего проекта - это конвертер У нас их было три штуки самый первый конвертер он был самый простой и самый надёжный и самый производительный он был на простых регулярка кусаем из са файла из открытого ищем регулярка где SQL скрипты и закидываем их в dbt модельки Потом смотрим где зависимости между этими SQL скриптами и закидываем их как са как он хорошо работал но работал только на простых случаях поэтому поэтому начали понимать что Ну примерно 50% джав этот конвертер покроет А все остальные жабы нужно мигрировать более сложным способом И начали разрабатывать новую версию конвертора первая верси вторая версия которая она была парси уже весь сас файл как текстовый файл Ира трансформировал его в и dbt код но к сожалению она не взлетела потому что там не хватало поддержки контекста А третья версия она как раз обладало такими возможностями то есть весь сас код который мы парсли он загонял се в объект ную модель это держалось как модель в ран тайме и можно было к ней обращаться то есть этот конвертер считывает файлы преобразует их в объекты и потом обратно записывает файлы в теории этот конвертер может не записывать файлы а выполнять сокод то есть стать средой выполнения В итоге достаточно большими трудозатратами мы получили конвертер который в состоянии покрывает Ну где-то 95% того что у нас есть И вот наша статистика по жабам про которую я говорил то есть мы чтобы ответить в принципе на вопрос а сколько у нас займёт миграция проанализировали джаб по 29 параметрам распределив их по большому сч на три группы самая первая самая многочисленная группа Слава нашим шаблонам и шаблонизатор вый конвертер мог скушать 20% - это то что пытались откусить вторым конвертером и в итоге Ну не получилось третий конвертер эти 20% кушает в большинстве случаев Потому что сам по себе он сложный И периодически баги бывают и последний 5% - это цикл вет ления то что к сожалению подвержено только ручной миграции и конвертер там слабо эффективен то есть проанализировав джаббы мы поняли Примерно сколько времени у нас займёт миграция и составили календарный план так а напомню что у нас целевой вариант - это работа афло в режиме работа двух оркестратор в параллельном режиме но первым шагом к этому плану У нас была э работа RF в режиме ли нетки В чём разница сас имеет достаточно сложную логику и повторение логики оркестрация заняло продолжительное время и как первый шаг мы взяли airflow научили выполнять просто без оркестрация то есть выполнять те самые джебы как есть и научились сас дёргать эти джебы То есть это было как это выглядело SAS считывает мету всю мету через WF определяет Какие присутствуют и какие совпадают в Сас и начинает их автоматически вызывать получается есть Давайте Попробую рассказать есть садур в котором 6500 джав мы берм какой-то конвертером гем паузы Делаем его активным SAS видит этот Джоб понимает что он живой что его можно запускать и начинает автоматически запускать этот Джоб WF вместо того чтобы запускать SAS Job э и так мы проверили что у нас работает на достаточно больших масштабах э выполнения dtl wif и перешли к режиму параллельной миграции параллельной работы как раз режим параллельной работы - это мы взяли два конвертера синхронизировались Да но ещё и добавили к этому что если конвертер Извините конвертер если оркестратор в принципе погасить то все джаббы сами приезжают в Сас и начинают там запускаться в режиме Марионетки из нюансов с которыми нам пришлось столкнуться в сас у нас те джаб которые были покрыты с они имели строгий порядок выполнения и их синхронизировать с двумя оркестратор была не проблема то есть мы берём просто э приоритеты выставляем всё работает а джебы которые не были покрыты слм они имели произвольный порядок выполнения и соответственно а невозможно два произвольных порядка выполнения синхронизировать чтобы они были совпадали и мы просто взяли эти джобы приоритизировать по принципу 1 2 3 4 5 в порядок выстроили уже ну с меньшим приоритетом и тогда у нас всё завелось Так ну и одна из задач которую мы ещё решали в процессе миграции я бы сказал даже одна из главных задач это валидация вообще корректности миграции Если бы у нас был идеальный конвертер то мы конвертирова запустили всё работает Ну если бы у нас был идеальный конвертер мы по первому плану пошли когда написали конвертер ВС скорти ВС разом запустило но он имеет Баги и поэтому чтобы у что он корректно работает э нужно как было как-то проверять самый простой и понятный вариант - это сверка данных то есть мы берём как в в нашем r& пилоте э конвертируем джоб плом на прод э делаем параллельную структуру запускаем один или несколько раз убеждаемся что всё работает и э потом это всё подменяя на проде уже на новый Джоб но такая такая методика она очень надёжная очень прозрачная но есть у неё нюансы самый главный нюанс - это дорого готовить данные дорого готовит структуры создаётся паразитная нагрузка пока параллельно работают потоки 6500 джав это достаточно много паразитной нагрузки хоть и растянутая во времени и этот механизм он на самом деле менее надёжен чем Альтернатива в ЧМ проблема что если просто запустить на боевых потоках потока то можно не столкнуться с какими-то крайними случаями это будет Типовая реализация и даже пройдя проверку Можно потом найти какой-то баг который не был обнаружен Ну и самое главное что если этот баг будет Надин потом непонятно почему его не нашли на тестовой функциональности потому что там данные нельзя положить в Гид и вариант который мы придумали это сверх SQL Мы приняли За аксиому что мы не будем Фактори потоки то есть задача миграции - это перенести текущий SQL Один в один Хотя очень хотелось где-то что-то поправить если придерживаться такого подхода то можно обеспечить э сходимость за счёт проверки SQL то есть задача миграция сводится к тому что мы берём текущий Джоб конвертируем его в новый СТК а и запускаем а собираем логи Джов на сас собираем логи джв на ф и начинаем их сверять построчно по батово проверяем как сам запускаемый сль так порядок выполнения так входящий исходящей зависимости И тем самым убеждаемся что миграция у нас один в один случилась Ну вот главная наверное проблема которая у нас была это повысить Доверие к такой Свер то есть бизнес понимает что такое сверка данных вот Данные есть льем данные сошлись вс хорошо а объяснить бизнес Что такое сверка SQL заняло некоторое время в итоге мы Убедили бизнес и пошли в эту историю ну одна из первых вещей которую нашла сверка SQL - Это она нашла сверку в жабах которые проходили сверку данных то есть там был момент когда у нас сверять в данных Только последняя таблица а перекладывание уже в рабочую табличку не сверять Ну чтобы не не поломать боевые данные вот так выглядит сверка SQL то есть html документ из списка всех SQL запросов которые выполняются строгим порядком которые котится в Гид и которые Потом если что можно поднять то есть вот есть первый пример это расхождение второй пример - Это где у нас там чуть-чуть чучуть ошиблись и рекордсмена у нас по прохождению такой сверки был Джоб со 124 запросами его сковали так что В общем решили мы проблему миграции ушли в сверку И тем самым тоже выиграли достаточно много времени как вычислительного так И нашего личного потому что такие сверки можно готовить и на стендах вообще где данных не самое главное собрать логи и сама вин нашей деятельности это то как мы боролись с текущим софтом и то Э с какими проблеме столкнулись у нас э первая проблема с которой мы столкнулись - это в принципе работа RF то есть а у нас детишки проект - это как говорил 30.000 моделей шедулер примерно раз в 5 минут обходит все и начинает их пересчитывать чтобы обновить текущее состояние тасо а для стыковки dbt моделе с АФ мы использовали пакет номе Космос ный пакет который берёт по запросу поисковому может из проекта выбрать энное количество моделек и запихнуть их в Дак и отразить и обеспечить их выполнение соответственно этот пакет чтобы распарсить проект де на 30.000 моделей он занимало Это минимум 2 минуты чтобы обойти эту проблему мы переписали пакет А в чём проблема заключалась проблема заключалась в том что он читал файл манифеста около 2 минут и потом этот манифест преобразовал словарик и уже достаточно эффективно с ним работал чтобы обойти эту проблему мы добавили в работу с астроном дис то есть Файлик который поднимался один раз он парся складывался в и уже за несколько секунд доста кша работал с ним снизили Ну где-то раз в 10 время парсинга вторая проблема с которой мы столкнулись - это в принципе долгий запуск джоба там всё та же самая проблема с манифестом чтобы запустить дбс чтобы запустить модельку нужно прочитать манифест в dbt также 2 минуты читается но здесь мы пошли другим пум мыса переписали пакет номер Космос Так что он чтобы запустить жабы берёт энное количество моделек жабы модельки я периодически путаю это одно и тоже то чтобы запустить модельку или энное количество моделек он берёт модельку выку свае из общего проекта складывает её рядышком в проект пустышку где лежат только там три или пять моделек компилирует их и запускает То есть это был тот способ которые мы нашли чтобы быстро запускать модели и тут тоже позволи нам с нескольких минут добиться производительности в секунды и третья проблема с которой мы столкнулись это динамическая работа с переменными В чём нюанс dbt у него есть возможность файл манифеста запихнуть определить переменные потом эти переменные использовать в dbt моделька Мы думали что эти переменные можно легко использовать в ранта То есть когда вызываешь консольную команду туда прям явно можно передать значение переменных Выяснилось что любая передача переменных Она приводит к полной пере компиляции проекта на маленьких проектах там сотни джав это происходит несколько секунд Здесь тоже это всё меряется минутами и мы отказались от работы с переменными в пользу просто статического кода и следу где мы лну с пробле это вильны инте 6.000 э узлов он не Не ну его в принципе невозможно глазами увидеть и отрисовать в интерфейсе тоже в стандартном невозможно А чтобы решить эту проблему мы написали свой интерфейс с тёмной Темой у него базовое табличное представление А и есть возможность провалиться в любой узел который есть и там потом отражается сам этот узел и все его входящие и все исходящие зависимости и дальше можно по по каждому узлу разворачивать зависимости исследуя граф его разворачивая знаете как раньше было в Героях Меча и Магии есть серая зона и эта серая зона потихонечку потихонечку расширяется достаточно комфортно чтобы можно было это всё смотреть чтобы не весь Граф А можно взять только те таски которые или сейчас бегут и посмотреть что от них зависит Или те таски которые упали и посмотреть что же от них зависит чтобы определить влияние Ну и с собственным тоже были проблемы пото что работа с графом занимала более 30 секунд То есть опрос рест интерфейса с запросом отдай нам Граф он занимал 5 5 Мб данных ие генерировать 5 минут мы поставили там тоже свой кэш и у нас всё взлетело то есть кэш обновляется сраз 30 секунд а точно если там нужно менять таск он обновляется в онлайне в общем решили мы все проблемы и получили работающую систему на выходе Мы в проекте получили отказ от графического интерфейса сас который никому не нравится когда ручками рисуешь стрелочки вот эти вот однообразные гораздо проще работает копа гораздо проще работает низация После отказа от са мы получили есть внедрили получили возможно квесты получили возможность делать код ревю прозрачный когда не просто са файлики которые имеют свой формат и их невозможно отре вють А когда это уже полноценный код добились сопоставимой с сам стоимость разработки во многом благодаря как раз отказа от графического рисования то есть аналитики готовили SQL потом этот SQL гораздо проще переписывается в Промышленный уровень то есть оптимизируется где-то дописывается и внедряется в прот а благодаря опенсорс открытости мы покрыли тестами ядро То есть у нас есть ядрово функционал в модуле который переиспользовать в в бизнес-подарки здесь 5 плюс у нас уже семь контуров э развёрнуто под все наши задачи то есть мы кайфуем от опен сорса Кайфуем от его лёгкости и гибкости А ещё из нюансов которые не рассказал вот здесь вот что мы выяснили то есть у нас ночное теле - это 6500 узлов в какой-то момент когда мы запустили мы увидели что на старте идёт огромный скачок потребления цпу выяснилось почему он идёт потому что стартовало в районе 500 сенсоров одновременно сенсоры которые ожидают готовности данных ини Выяснилось что каждый Дак когда он отправляется на воркер чтобы выполнить тас Он полностью парси и какая проблема получилась что у нас Дак 6500 узлов чтобы распарсить один сенсор нужно распарсить весь Дак чтобы выполнить один сенсор И это была наша плата за Монолит которую с которой мы ничего не сделали закидали просто ресурсами побольше проц накинули есть улуе при расширение текущего графа у нас будет квадратичный рост потребления ресурсов Ну плата за Монолит на этом конец доклада вопрос дискуссионный к которому я вас призываю Где по вашему границы между монолитом и бизнес спецификой то есть мы вот не смогли распилить что нам создало технические сложности если бы распилили думаю нам бы текущий софт Ой у меня тут не написан Если будут вопросы подходите дам свой В общем если бы смогли распилить текущий софт то не пришлось бы так оптимизировать И вот вопрос софт не предназначен потому что у нас такие масштабы или архитектура не соответствующая нужно пилить более усердно Монолит задавайте вопросы а да спасибо за Аплодисменты QR - этоко голосования за акт кому понравилось кому не пови голосуйте Антон Спасибо огромное Я полностью поддерживаю действительно надо проходить по QR коду и пока Воспоминания свежи писать Всё что думаете и хорошее и разное тоже потому что на самом деле это важно не только спикеру для того чтобы понимать насколько вообще хорошо всё было в реальности вот ну и программному комитету чтобы понимать то же самое но более пристально Вот но на самом деле конечно же я немножко шучу я прекрасно понимаю что быть спикером вобще на само деле волнительный вот эти вопросы ждать А я вижу поднятые руки пожалуйста просьба к хелпера приносить микрофон но сначала я зачитаю вопрос из чата контролируется ли статус потока в вашем шедуле Возможна ли ситуация при которой один и тот же поток запустится более одного раза Критична ли такая ситуация так статус конечно контролируем у нас есть Первая линия поддержки Вторая линия поддержки сервисны мониторинги всё это обрабатывает всё это контролирует по поводу запуска два раза нет таких проблем у нас нету потому что один шедулер главный второй шедулер ориентируется на него была обратная ситуация когда у нас из-за поломки этой интеграции наоборот Все потоки сползали в старый шедулер то есть ну это прям бы была большая проблема потому что часть потоков которые мы смиг они на конечной системе Ну на новом шедуле уже успели доработать и в одну прекрасную ночь мы просыпаемся и смотрим Что у нас часть потоков попадала с непонятными ошибками Выяснилось что интеграция поломалась потоки сползли и начал выполняться устаревший сос кот и чтобы этого избежать Мы просто сделали м доработку которая ржет изменения то есть новые потоки могут смиг на новый шедулер А старые уполз обратно Они могут только при ручном подтверждении то есть выходит интерфейс где жмёшь кнопочку обновить мету и там говорится о вот эти потоки добавились А вот эти потоки сейчас удаляются точно ли вы хотите их вернуть на старый Ду окей да напоминаю за лучший вопрос придётся дарить подарок самая большая проблема этот лучший вопрос запомнить обычно с этим сложности Итак использовали dbt тесты что делали с циклами тесты не использовали с циклами написали там есть два варианта реализации с циклами первый вариант реализации - это делать массив исок он Хорошо подходит когда задача параллели и второй вариант реализации - это реализовать циклы внутри пайтона а оба варианта у нас используются потому что в одном случае таски можно параллели а в другом случае важен порядок расчётов То есть если по дням считать какой-то набегающий итог или когда э при перезагрузке данных можно остановиться то есть мы берём циклом какой-то Горизонт считаем 30 дней и потом наступаем на момент когда эти данные уже пересчитаны и тогда останавливаемся О'кей так Давайте немножко Переключи на на вопросы Из зала я вижу руки много рук Пожалуйста передайте микрофон Угу добрый день спасибо за доклад Александр а так Антон Скажи пожалуйста а Сколько времени заняла вся эта миграция календарно это больше года больше года от этапа Когда вы решили ну перейти Ну то есть рассмотреть все гипотезы До До конечной реализации или до этапа Когда вы перевели первые потоки успешно проект сейчас на завершающем этапе поэтому Ну там осталось где-то пару месяцев до конца Но начиная от понимания что пора что-то делать и заканчивая вот текущим моментом вот ранее на где-то в середине доклада рассматривались различные гипотезы каким пум пойти а все эти гипоте оценивались чисто аналитически да Или проверялись на проде прямо напрямую или на каком-то отдельном окружении То есть как вы приходили к выводу что они не подходят Ну первая гипотеза Она просто по рискам не прошла потому что это там прямо классический классический водопад когда больше полугода идёт Разработка и потом в какой-то прекрасный момент проверяешь а нигде не ошибся никто не поверил что э гипоте жизне способна Спасибо огромное тогда давайте следущий вопрос из чата я буду немножко чередовать Я чувствую что на все вопросы у нас не получится ответить Но если что мы потом никуда Антона не отпустим и перейдём в дискуссионную зону и там продолжим а Итак вопрос из чата проводилась ли Оценка эффективности миграции какие оценки результатов использовались общая оценка по вложениям в проект и итоговый результат так я про вложение в проект не буду отвечать на вопрос по эффективности миграции у нас получилось сейчас мигрировало и на эти 4000 джав у нас было меньше де инцидентов именно миграции джебов то есть с оркестратор там были проблемы а вот джобы у нас получается меньше процента ошибок на с мигрирующий вопрос из зала пожалуйста Спасибо за доклад вот я услышал что у вас там где-то вредине появился собственный Интер кода не было идеи сделать из этого какой-то продукт потому что Наверняка вы не одни сидите на Сас и у вас даже наверняка не самое большое сасовское хранилище и если не сделали продукт то почему пока у нас Голова болит только о том чтобы завершить проект а делать продукт его оборачивать это существенный труд затраты Я очень рассчитываю что к тому времени когда мы закончим проект миграция саса у всех уже закончится пото что примерно в одно и то же время все с проблемами у нас было преимущество что у нас многолетняя лицензия была куплена поэтому мы без спешки идём в этом процессе А с людьми с которыми я общаюсь знаю что они были больше ограничены в сроках и более в экстренном варианте смиг то что есть благодарю Следующий вопрос пожалуйста микрофон так пока хелперы несут микрофон следующему а слушателю Каковы В итоге масштабы фу сколько и так далее сколько цпу и памяти выделено Так сейчас я пытаюсь понять на самом деле тут можно поступить следующим образом после выступления ответить также в чате хорошо так А это с чата вопрос Да Да это вопрос из чата нене не я ответить на него могу Я просто не знаю насколько это разглашает да какие у нас масштабы то здесь не сложно смотрите у нас три воркера каждый из воркеров сейчас 32 Яра и 32 гига оперативки то есть по сравнению с ресурсами которые SAS у нас потреблял это когда у нас оди Юнит с 512 ги байтами оперативки это вообще как бы детские какие-то масштабы учитывая ещё ту плату за Монолит которую мы из-за несовпадения архитектуры платим То есть у нас сейчас до расскажу раз спросили у нас примерно 10 или 15 ядер постоянно утилизируется Ну из всего кластера суммарно насибов парн дагов есть вотт процес который мы оптимизировали он у нас занимает столько же времени сколько выполнени самого сколько нагрузка при выполнении самой Окей супер Давайте два вопроса а потом дискуссионную зону прошу Спасибо за доклад очень познавательный интересный опыт А у меня вопрос Следующий Вот вы в параллели запускали Да несколько параллельных потоков Да это классический подход миграции а но я не совсем понял Для чего вы учили да несколько оркестратор Да взаимодействовать в разных пороках друг с другом Да И вот для чего это нужно было Да и что это дало Угу Так э Давай я Сейчас убежусь что правильно понял вопрос то есть у нас есть два параллельных оркестратор а один выполняет поток другой ждёт что этот поток будет выполнен про это вопрос да Про это да Я так понял что вы их в параллели запускали Да чтобы если новый сломался да то старый добежал как бы и Ну вы на проде не пострадали да то есть это нет это не для фловера было сделано то есть в чём ситуация у нас есть сенное количество джебов А мы их мигрировали постепенно и дорабатываем мигра Тор постепенно А И эти джобы Ну простой вариант миграции - это если бы мы взяли э Граф расчёта и начали его с листья обходить постепенно перенося листовые узлы в новый оркестратор Это был бы самый простой вариант Но не все листья э можно было смиг из-за Вот нюансов как раз мигра Тора и ээ два этих графа смотрят друг на друга чтобы можно было их разреженном то есть берём абсолютно любой узел хоть начале хоть в середине хоть в конце перекидываем его на новый мигра Тор и э за счёт отслеживания состояния графов друг у друга а мигра Тор оркестратор за счёт отслеживания состояния графов друг у друга Они понимают что э ну поддерживается та же одна и та же оркестрация То есть я правильно понимаю один и тот же граф К сожалению вопрос ЕС мы не говорим их не в микрофон не слышны он Я предлагаю на самом деле продолжить дискуссионной зоне ребят потому что вы здесь Давайте последний вопрос из зала пожалуйста я всё-таки отвечу Да один и тот же Граф мы проходили двумя оркестратор обеспечивая однократное выполнение узла на каком-то из оркестратор Спасибо огромное Да Привет Спасибо большое за доклад на самом деле чуть вернусь там чуть раньше был вопрос про инсталляцию вот в догонку стали ли выносить воркеров кубер Да нет И если нет Были ли сложности с этим Спасибо нет они у нас на то у нас три воркера не в кубе они на виртуалок Но это особенности нашей инфраструктуры в принципе рассматривается вариант Но нам сейчас более удобно на виртуалка их держать Ну что спасибо огромное Мы немножко выбиваем из тайминга поэтому предлагаю продолжить дискуссионной зоне А вот из тех вопросов которые были надо будет выбрать один либо онлайн либо олайн какой запал самое сердечко вот твой вопрос Понравился а супер Спасибо огромное так а дорогие хелперы Пожалуйста передайте"
}