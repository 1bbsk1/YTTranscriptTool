{
  "video_id": "LWUSFYU5JMQ",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет рады всех приветствовать на конференции девукс Меня зовут Олег Дениса зовут Денис мы с Газпромбанка я я удивил апер Денис он что-то делает что эксплуатирую сейчас Мы попытаемся рассказать то вообще чем мы занимаемся до описать для людей кому это интересно да на самом деле звучат несколько по-другому я руководитель разработки отдела инфраструктуры в департаменте машину обучения больших данных Газпромбанка Денис называется да Меня зовут Денис замков я управляющий директор Газпромбанка департаменте анализа данных моделирования в принципе часто работаем вместе с командой Олега Да я непосредственно занимаюсь разработкой модели анализирует направление занимаюсь поиском бизнес-эффектов тестированием гипотезов проведения пилотов и так далее чтобы это все работало Нам нужен какой-то эмаль ОПС процесс и он должен чем-то отличаться от стандартных процессов разработки какие-то особенности имеет про которые мы поговорим в этом докладе очень хотелось бы участников поактивнее вести себя в чатике Да и задавать нам вопросы Мы обязательно их все ответим В конце нашего доклада Ну и будет какое-то время на подискутировать про это все поэтому предлагаю начинать Олег да Ну что поехали Ну наверное пару слов стоит сказать про Газпромбанк Газпромбанк это реально очень большой банк с развитым АйТи У нас есть очень много разных интересных крутых it игрушек для взрослых мальчиков Вот и чары наши просили сказать Вот фразу Приходите к нам у нас есть печеньки доклад называется Что такое mlpoops и Но на самом деле последнее время появилась очень много слов оканчивающихся на опции это выглядит просто какой-то нездоровый хайп Но если начать разбираться внутри под каждый под каждым из этих слов лежит какая-то простая идея которую можно выразить предложение которое позволяет ее понять Итак mlps это когда мы инженеринки применяем принципы его для того чтобы унифицировать и ускорить процесс обучения и доставки моделей машинного обучения и прежде чем говорить как Давайте обсудим зачем Да Денис заниматься непосредственно искусственным интеллектом и он наверное знает больше всех про искусственный интеллект И сейчас я попрошу его объяснить Да можно пожалуйста следующий слайд на самом деле все просто да то что называется искусственный интеллект это можно выразить в такой простой формуле Да если в школе мы учили находить вот этот вот в этой формуле X нас учили сначала Да есть какая-то функция два плюс три равно и вот это Y мы находили равное 5 потом старших классах нас учили уже решать уравнение где там вида игры равно А X квадрат квадратичное уравнение вида или может простой Линейная Y равно X плюс B то искусственный интеллект можно назвать тем что мы сейчас ищем третью эту буковку в этой формуле по сути вся модель машины обучения представляет собой Вот то есть Наша задача просто найти функцию по каким-то переменным который мы называем X или фичами и результатами работы какого-то процесса игры и восстановить эту зависимость то есть найти следующий слайд а чтобы не путаться в понятиях искусственного интеллекта Давайте просто поймем что это такое вообще искусственный интеллект это что-то более философское такое и оно может быть относиться не только каким-то математическим формулам Да кто такие-то может правила назвать искусственным интеллектом основанные на бизнеса и продавать это в коробке современного хайпа Но вот мы знаем что есть такой большой философское понятие как искусственный интеллект в нем лежат именно что-то какой-то математический аппарат который мы называем машинным обучением то есть набор алгоритмов методов которые предсказывает там по существующим событиям предсказывать дальше что-то в дальнейшем или экстраполировать какие-то наши выводы Вот весь этот набор методов мы называем или машин Learning или машинное обучение и внутри него еще есть особая семейства горитмов так называемые нейронные сети это то что сейчас гпт и так далее вот это вот часть машинного обучения мы называем глубокое обучение так модели имеют очень большое число параметров очень большие веса собственно поэтому хотим поговорить как с этим всем работать Давайте дальше а ну вообще в классическом машином обучении и в том числе глубокому увеличению Мы в банке решаем две основных задачи это обучение с учителем без учителя с учителем это когда у нас известен игрок и нам нужно найти только вот эту буковку F А без учителя Это когда у нас и буковка Y неизвестный нам нужно как-то сделать какие-то сегменты на основе модели про которые как бы мы особо ничего не знаем Посмотрим на базе сегментируем Давайте подробнее задача с учителем бывает вида регрессия регрессия означает что мы предсказываем например доход клиента или возраст клиента то есть она может быть какое-то непрерывное число дискретная модель так называемый классификации это то когда мы предсказываем вероятность события модели без учителя правилах интересует кластеризация то есть побить группы клиентов какие-то группы и уже вести аналитику в рамках тут еще выделяется сделал так называемая обучение с подкреплением это то что за вас играет боты в Доте условно говоря когда модели обучается на себя но сейчас в банках это таких больших организациях не очень развита она очень эффектная б тесты но мы сейчас обойдем имя AB тестов Так нам надо 2 часть подчеркнуть Можно пожалуйста следующий слайд Давайте поговорим Какие задачи вообще в принципе да мы решаем как наверное банки самые первые организации которые применяют искусственный интеллект так как рисковые модели в банках Ну то есть склонность клиента дефолту или каком-то дефолт означает что клиент не погасит свой кредит какой-то срок уйдет просрочку и классические банки первые по законодательству должны применять модели простого порядка типа линейных предсказанию рисков И это норма CD и банки уже давно применяются интеллектом своих рисковых стратегиях и поэтому такая область банковская Кроме того искусственный интеллект помогает банкам в том числе нашему отток делать более персонализированные предложения например кошечку или собачку вам показать дальше модели применяются активно в маркетинге оптимизации performance это то есть всяких рекламных кабинетах Яндекса Гугла Мы тоже используем применяем модели это тоже отдельная тема вот но сейчас очень популярна тема тестирования и так далее Что каждую доработку нужно проверять через AB тесты и проект гипотез как раз такая мыльная часть большая статическая который тоже там модельные подходы активно применяются интересная область это борьба с мошенничеством поиск каких-то недоброжелательных людей транзакции и так далее Все знают и биометрия чтобы платить лицом тоже сейчас области а ну наверное по зачем зачем это делаем Я на вопросы ответил Вы можете задать там в чате еще но Давайте перейдем к самой сути доклада Олег те слова Да Денис спасибо ну как бы тебя Я хочу подчеркнуть что вот эти вот наши модели машинного обучения они Вполне себе бизнес критиков То есть например кредитный конверт моделька решает выдавать или не выдавать кредит Вот и если вдруг она встанет мы лишимся выдаче кредитов но Давайте окунемся до посмотрим что там под капотом и сперва обсудим жизненный цикл модели машинного обучения Итак у нас есть какой-то алгоритм модели машинного обучения который сделал дата-сантист который моделисты реализовал в ходе и положил и вот на этом классическая процедура разработки программное обеспечение закончилась только начинается мы должны подготовить обучающую выборку И прогнать это через алгоритм и получить на выходе так называемые веса то есть ну вот это вот нейросеть нейронные связи на основе которых алгоритмы будет принимать решение в дальнейшем и именно вот совокупность из алгоритмов модели машинного обучения и весов Вот именно ее мы должны рассматривать в совокупности как единое целое на самом деле алгоритмов 2 это алгоритма обучения алгоритм применения но сейчас наверное в контексте нашего рассказывать не важно потому что мы обычно направляем эти алгоритм как один целом и вот это вот все так вот моделька мы обучили получили веса Но мир не стоит на месте мы постоянно получаем новые и новые данные и что мы делаем мы обновляем обучающую выборку и делаем так называемая до обучения То есть фактически не меняя кода алгоритма мы можем получить новые веса и новые модели машинного обучения и вот совокупность из обучающей выборки алгоритма и Весов называется эксперимент и в общем случае Мы тоже хотели оперировать хотели бы оперировать им как единым целым для того чтобы понимать на основе каких данных какие результаты мы получаем так вот возвращаясь к мл ОПС что такое mlops и для чего мы применяем правила культуры devops культура эксперимента быструю обратную связь к машине леднике дата Инжиниринг чтобы получить ускорение потока создания ценности до чтобы быть лучше быстрее конкурентов Каким образом это делаем Мы сперва делаем вот эту петельку по подготовке данных для модели машинного обучения и обучение модели а далее У нас есть петелька которую все знают где вопс разработка диплоид эксплуатация и мы сливаем таким образом получая бесшовный процесс для ускорения унификации процесс подготовки данных обучения и вывода модели про то есть модельки в прозе в этом как бы суть devops Теперь давайте обсудим что вообще может пойти не так да и начнем с подготовки данных надо понимать что современные фильмы собирают очень много разнородных данных и просто пихать модели любую всякую всячину Да мы не можем мы должны Ну во-первых понять Наш кейс подобрать релевантные данные понять Какие данные из которых мы собираем Да они нам релевантные преобразовать их возможности несколько данных из нескольких источников и вот этот Челлендж он достаточно масштабный достаточно тонкий Я думаю у Дениса получится Лучше рассказать про тонкие моменты сейчас дальше пойдет Речь по сути сейчас всех на картинке показывает всего лишь первый этап который происходит и он наверное самый объемный дособрать со всех источников организации какие-то данные как-то их унифицировать карты сделать чтобы не переваривались моделью как-то не сделали чтобы не шумели это все мы проходим на первом этапе как правило у нас витринки данных так называемый который является финальным потребителем для модели чтобы это все произошло в том виде которые чтоб модель с этим работать Нам нужно пройти очистки сборки и так далее но после У нас есть витринка у нас есть еще ряд шагов которые имеют делаются в самой модели до мы Чистим на уровне сбора данных какие-то данные Да например по неправильно бизнес логике Но дальше проходит еще и очистка по какой-то статистическим до удаления выбросов и так далее вот второй этап я хотел подсказать что вот после нас так называемого дата опыта работы с данными Не прекращается дальше там остальные части делает Моделист чистка преобразования разбиение валидация и удаление выбросов нормализации эти все этапы по сути они уже работают над сагрегированными данными в каком-то виде я уже говорил и здесь я наверное подсвечу что этапы один и семь там занимает наверное 90 процентов 95 от всей трудоемкости на первом этапе когда там у нас делаются агрегаты нам чаще всего мешает такие кейс как резкое изменение бизнес логике то есть нам надо следить за тем чтобы продукция бизнес логика не менялась Ну и валидация как правило у нас наши модели еще его лидирует по закону ЦБ центр независимого лидации это люди которые там по регламенту должны быть Вот так просто прийти и подтвердить что наша модель может воспроизвести Да И вот эти вот два этапа оптимизируем в процессе это больше административные шаги Но из этого слайда вам должно быть понятно что как бы здесь это постоянная работа следить за бизнес логикой и так далее поэтому наверное в части молился Это один из самых самых тяжелых этапов подготовка этой обучающий выборки Если что мы потом на дискуссии это можем отдельно проговорить А пока я передаю слово дальше Да Слушай вообще если говорить выборка данных Да сколько она из процесса занимает усилий в процента Ну слушай у нас наверное процентов 60-70 до Вот то есть до выгодки впрок то есть подготовка прототипа выход и так далее Наверное это самое тяжелое область в части именно paypeline потому что как правило мы не владеем еще и бизнес логикой нам эту логику приходится регулярно обновлять подтверждать заказчиками и так далее это все там правильно воспроизвести например Ну вот такой Явный пример расскажу Да что мы считать откликом Какую карту А ну что клиент откликнулся на карту явно когда карта перевыпускается Она не должна учитываться Как как клиента какой-то там Триггер отклика явно Да когда она перевыпустилась потому что и вот эти вот всякие моменты тонкие надо учитывать постоянно звучит как большой Челлендж О'кей пойдем дальше обучение до обучения модели как бы стоит понимать что обучение модели это процесс достаточно сложный а достаточно несложный ресурсоемкий долгий то есть модели могут обучаться неделями Да и потреблять очень много вычислительных ресурсов далее версия они обучающих выборах и весов перед вами табличка на июнь 2023 года которая демонстрирует размер обучающих выборов называемый для длинных языковых моделей которые сейчас есть на рынке да Ну вот например gpt 4 - это 40 ТБ вы представляете просто Как хранить вот такой вот объём а-а Нужно ещё делать эксперимент версионировать на это определённый Челлендж что до статистики по размеру модели Газпромбанк да то потолок обучающих выборах мы еще не нащупали наши обучающие выборки начинается от 100 мегабайт веса от 2 до 6 гигабайт в среднем получается то есть 95 сетей размеры наших обучающих наших весов а лежит в этом диапазоне Да и докримиджа которым мы доставляем модели у нас занимают от двух с половиной до 35 гигов если считать библиотек которые нужны для работы модели Окей Идем дальше организация разработки когда мы говорим Маше лернинг мы подразумеваем Big Data большие объемы данных на которых мы обучаем наши модельки которые сама по себе работает большими данными это Челлендж работа с большими данными Кроме того для обучения моделей часто применяется дополнительное оборудование процессоры типы процессоры так называемые тензор процессор Юнит тензорные процессоры Я слышал многие пытаются обучать на асиках на платах то есть вот оборудование которое может много скалярных операций времени выполнять и вот это вот большие данные в совокупности с дополнительным оборудованием практически убивает возможность разработки на локальном месте разработчика а следующий Челлендж безопасность данных в классической разработке программного обеспечения У нас есть несколько стендов между которыми мы перемещаем артефакты в Machine Learning все усложняется наличием данных на которых мы должны обучать модель и часто эти данные сенситивные и подпадают под какое-то под какое-то законодательство и Челлендж по защите этих данных нужно решать постоянно Ну например разработка продуктовых его продакшены около Продакшен контуры Да они стоят без интернета изолированные защищенные всеми возможными способами по праву гордится тем что у нас не было серьезных проблем с серьезных утечек сначала работы и каким образом мы решаем Челлендж обучения моделей в контуре где доступен интернет нашему близко могут поиграться с какими-то библиотечками Да скачать посмотреть внедрить какой-то софт вот дальше после проверки безопасности он попадает в продуктивную продуктовые около продуктовые окружение Да все обучение моделей у нас делается в контуре который находится рядом с продакшеном Да и вместе изолирован мы можем передавать Ну какие-то обсудированные данные после нескольких проверок какие-то миниатюрные порции аффицированных данных тестовое окружение Да но это достаточно сложная процедура с многими проверками и само по себе это Челлендж и организация СИА сиди-процесса стоит понимать что вот этот процесс от подготовки данных дата инженерам через создание алгоритмов обучения моделей моделистами Да после которого разработчики наши встраивают модельки в код наших приложений для опции они диплоид этой эксплуатируют Да это очень длинный процесс который в котором задействовано последовательное усилия многих специалистов и который не влезает в рамках какой-то одной существующей системы просто слишком мало функций да в mlpoops достаточно много специализации специалистов усилия всех специалистов важны Да но у нас конференции посвященная и Давайте обсудим Какой вклад инженеры могут внести в машину собственно говоря вот узлы приложение и начнем мы их разбор источников данных как уже говорилось источников данных может быть достаточно много если в классический разработкой программного обеспечения у вас как правило базы данных но SQL базы данных то в Machine Learning у вас добавляется Ну как бы дополнительные сторожа дополнительные какие-то стороже для нужд посвященных мл лобс Big Data Да и вы имеете дело со всеми буквально со всеми источниками которые есть предприятии от баз данных до Я не знаю логов никаких серверах и главное здесь основной Челлендж это уменьшение расходов нужно понимать что подготовка данных для нужд машинного обучения это не основной как правило не основной не основная задача Рабочая на предприятиях поэтому мы должны во-первых как можно меньше мешать нормальной работе всех систем и окружении то есть положить основную рабочую данную основную рабочую базу данных каким-то запросиком для машин Learning это очень плохая ситуация мы должны помогать оптимизировать запросы мы должны помогать договариваться доступах подключении данных источникам данных и вот это вот все поэтому здесь все а что касается Газпромбанк Ну например у нас два петабайтных ходу попод нужды по крайней мере петабайтными они были весной сейчас они может быть уже перешагнули А это рубеж и под них есть отдельная команда ребята делают очень много интересных сложных вещей с ходу Идем дальше подготовка данных детей процессы Давайте посмотрим какие вообще подходы к организации источников данных У нас существует изначально это были дата вырихаус какие-то базы данных которых данные лежали структурированы далее подход расширился подходом до талой это ну хранилище где лежат данные Ну Возможно даже не структурированные сырые гибридный подход дата Лейк Хаус в котором могут быть и структурированные структурированные данные и в последнее время набирает популярность когда микросервисный подход мы применяем это lighthouse и получаем такое достаточно гибкое хранилище заточенное под множество разных интересов но если мы посмотрим на все вот эти вот хранилище данных мы увидим такую надпись etl Что такое это аббревиатура расшифровывается как экстракт трансформ лот то есть мы извлекаем нужные нам данные из нужных источников приводим их тому виду которая нам нужны и загружаем их в наши хранилище данных вообще Денис сказал слово дата когда говорил про подготовку данных до того что когда мы применяем правила джайл и методологию подготовки данных делом и непрерывной планирование до доставки на отдельный доклад поэтому мы не будем сейчас обсуждать мы просто пройдемся по идее туллингам что вообще мы можем применять для идти изначально Газпромбанк Это был сас сас это что типа SAP для etl сапог для детей дорогая Очень enterprisen система с крутой поддержки которая ушла из России сейчас мы его усиленно выпиливаем и первое На что мы решили съехать это Апач эрфу это с одной стороны который позволяет запускать процессы идти по расписанию с другой стороны это инфраструктурный фреймворк который позволяет строить Вот эти процессы pipeline называется так Direct сайт Граф направленный где его это действия по трансформации данных связи это условия при которых мы переходим от одного шага к другому эксплуатируем в губернато с можно как бы интегрировать с разными системами Да мы выбрали губернатор платформу для запуска airflow на каждый Дак на каждый у нас запускается Свой контейнер в котором делать какие-то действия Это позволяет нам унифицировать настройки библиотека настройку доставку библиотек поскольку это питон очень много питона наши моделисты хотят новые модные библиотечки Да и Челлендж debox это ну как раз пересобирать имиджи добавлять новые библиотеки когда что-то пошло не так невозможно чтобы помогать коллегам вхождением какие-то источников данных деловыми каких-то действий Да а патч найфай это следующие эти Турин который мы сейчас внедрили Да он очень похож на сас здесь можно графический накликать наш файплайн То есть это лоу код инструмент где вот при помощи визуальной интерфейса мы строим pipeline Мы точно также апачная используя эксплуатируемый губернатор Это позволяет нам опять же оптимизировать время на разворачивание инстансов на масштабирование на унификацию настроек мониторинга и здесь Челлендж опять же добавлять плагины для какие-то секреты для доступа к внешним данным и что-то пошло не так Окей Надеюсь процессами все понятно Давайте поговорим про разработку как уже говорилось это Big Data и специальная оборудование для разработки и ну как бы разработчики моделисты не могут работать чисто на своих машинах эту задачу по выделению ресурсов по выделению оборудования для для моделистов для дата-сантистов мы решаем при помощи джубайтер ноутбук jupider ноутбук это классическое поэтому ноутбук есть много аналогов Ну например Google collab ноутбук и мы точно также эксплуатируем Юпитер ноутбук Питер ноутбук это какая-то Ешка под которую запускается контейнер Да ты можешь описать код заходить проверять что там вообще сделалось по итогам выполнения твоего кода это опять же позволяет унифицировать доставку библиотек до среду разработки вот Ну что думают наши моделисты сантехни Юпитер ноутбук Я думаю мы можем спросить у Дениса любят ноутбук но все кто выкладывает код моделиста после Питер ноутбука ненавидят не Питер ноутбук не самого моделиста Почему ноутбук исключительно для экспериментов промышленный код писать не очень хорошо Я бы рекомендую всем ознакомиться попробовать поработать В этой едышке в чем суть в том что интерпретатор работает постоянно и я могу там в рабочей тетрадке условно на форме рабочий тетради где ты по ячейкам можешь выполнять кусочки кода и в онлайне прям подгрузить себе там в тетрадку конь график или табличку быстро сделать и собственно ее можно взять и выгрузить формате HTML и вот тебе готовая презентации по результатам твоего эксперимента очень интересно Но как правило подобные подходы написание кода Где вы там кусочками чеки пытаетесь очень ненавидят Когда вы хотите там по кусочкам собрали и так далее Поэтому да у нас есть Юпитер который очень хорошо подходит для исследователь исследований но все равно мы там впрот вводим когда собираем код вот этот код для применения самого Да все равно используем pagearm Visual Studio такие классические И доешки когда нам нужно повторить надо здесь Наверное добавить больше ничего разработки мы используем Юпитер самой модели до проверить берем эти веса идем студия код и пишем код под код обертки чтобы эти веса применялись нормально вроде вот собственно здесь такой и Питер это просто для исследований самый топ инструмент вот перед и слово дальше по моему Вам нужен линтер в pipeline достать модели чтобы не ревью ведь а или есть у меня есть работает Visual Studio я переношу вижу разработчик Код Да и ему такой у нас Samsung должен стоять но это мы уже внутри обсудим эксперимента и сохранение весов как уже говорилось очень большими изначально мы трекали наши веса детей можно включить поддержку но стоит понимать что больших объемов бинарных данных Кроме того например сканеры безопасников Да будет у нас начал тормозить сканеры безопасников при попытке просканировать Вот наши большие залежи бинарей Ну как вы делали так я упали и нас попросили так не делать поэтому следующим шагом которые мы сделали в плане трекинга эксперимента это внедрение dvc dvc это ну что-то вроде Гита для данных Да он сам может создавать репозитории в эти репозиторий он может сохранять и код и входные данные запускать эксперименты но у нас это как бы не пошло Ну и я не знаю прокомментируешь что не так смотрите Да у нас ходу классический где все таблички хранятся нестандартным бинарном виде формате паркет если мы меняем какие-то записи то нам есть паркет меня Вот это гитара с 9 у нас вообще никак не работает то есть мы не видим изменение там какие-то и то есть у нас есть бинарь поменялся инструмент хороший он нам нужен будет дальнейшем но пока как бы он свой функционал не выполняет То есть он просто словно мы можем просто таблички Также вы один В2 В3 называть это все там или делать что это первая версия вторая версия в самой таблице но чтобы сам функционал как бы Дивизии за того что паркеты в бинарях мы не используем по этой причине Ну то есть dvc мы не получили так желанного нами трекинга дифа на бинарные файлы поэтому мы решили на что пусть этим занимается хранилище которое заточено операции бинарными артефактами и мы выбрали Nexus мы сделали количество автоматизации и сейчас живем в Nexus это наша рабочие решение Окей тестирование и Доставка моделей вообще тестирование модели машинного обучения она достаточно сильно отличается от тестирования обычного программное обеспечение Я думаю тоже сможет пояснить чем Да но здесь такая есть Бейс проблема к Core проблема в тестировании модели нам нужно протестировать не только код как какая-то код будет работать на какой-то выборке в какой-то системе Ну то есть взять какой-то пул клиентов ограниченное и сделать так чтобы результат выхода модели был ожидаемый не только с точки зрения кода но Весов и самой среды знаю много кейсов когда там в одной библиотеке int64 и в другой библиотеке работали по разному напротив на тесте и так далее из-за версии из-за чего-то и основной Челлендж это нам какой-то тестовой среде отложить какой-то клиентов и на котором мы будем уверены что результат модели мы получим такой на котором мы обучались условно говоря чтобы все работало нормально то есть мы откладываем клиентов и Тестируем не только саму сам код но и результат самого кода который нам прогнать и чтобы получить ожидаемый результат Да отлично А еще можем делать нагрузочное тестирование моделек насчет доставки моделей Мы решили для себя использовать контейнеры докер и губернатор в качестве базовой среды для его запуска модели прекрасно ложатся На вот эту концепцию имидж модели они стоят лес они мутабельные и основная проблема заворачивания моделей в том что модели большие Да веса могут быть громадные часто имидже раздуваются до таких размеров которые их управление уже бывает сложно и Ну мы делаем как бы такие вещи как вы нас части библиотек из имиджа на ноду и Просто после монтирование то есть как бы везде нужна смекалка везде нужен подход и мониторинг моделей мониторинг моделей опять же отличается от мониторинга классической классического программного обеспечения прокомментируешь Денис Ну да здесь смотрите опять же по мониторингу мы я делю мониторинг наш который я должен делать для своих моделей на три таких больших блока в первую очередь я должен мониторить стандартный сделать эти мониторинг самого контейнера насколько он быстро работает не падает какие-то там логисти собрать и так далее Все надо все знают как там и так далее но у нас есть еще два направления мониторинга которые Мы обязаны делать для модели это машина мониторинг Я его так называю Это стандартные метрики точности моделей что модель не поехала что какие-то данные не корявые пришли не замулилось и все это мы можем наблюдать в таких-то пластических метрах метриках таких как рукавух отсчитать какой-то срез современно Ну актуальный срез собрать там целевые события И прогнать на нем модель и отдельные еще выделяю обязательно должен быть бизнес мониторинг модели которые оценивает что модели эффективно в процессе то есть мы например держим какую-то группу клиентов определенная рандомно ее модели не трогаем и постоянно сравниваем вот у нас группа без моделей живет бизнес который мы делаем коммуникацию по предложению какого-то продукта и отдельно есть группа которая там работает по модели и мы постоянно их сравниваем это вот один ключевых мониторингов и по-другому кроме как выделение там контро такой мониторинг не организовать и вам нужно там четко отгородить Этих клиентов которые контрольная группа чтобы к ним модель не применялась Но вот эти челленджи на самом деле в Enterprise организации они достаточно сложно поверьте как это все организовать правильно и так далее поэтому мы здесь отдельно подсветили что есть три направления я правильно понимаю что мониторинг У нас сделано и телепроцессах данный отель но по сути бизнес мониторинг он тоже не ты грузить куда-то Все мы можем быть Чего введение рассчитывать куда-то У нас есть модельки которые подглядывают за эмэль модельками чтобы они не шалили Да у нас есть модели качество данных непосредственно которые там как этап расчета всех моделей у нас используется то есть такое называется Модель которая ищет аномали в качестве данных и подсвечивает нам прежде чем запускать модели супер звучит так будто Нам нужен человек который бы жил в дата-центре и в случае Восстания искусственного интеллекта рубанул бы электричество что касается it-мониторинга то здесь ну как бы у нас есть модели который запускаются по расписанию получают когда что-то на вход и выдают анализ Здесь нам нужно просто смотреть потребление ресурсов Да и смотреть выхода моделей как запустился процесс вышел Да есть онлайн модели классические микросервисы которые слушают трафик здесь применяем 4 золотых сигнала до размер трафика время отклика количество ошибок Ну и сатурация да Окей Я думаю с этим понятно и напоследок я бы хотел поговорить наверное про организацию процесса CD да то есть вот этот процесс все дела достаточно длинный и он не убирается в рамки какой-то одной системы Да он покрывается определенным АйТи ландшафтом и это те ландшафт как бы достаточно сложно создать мы пытаемся смотреть было тесто эксплуатация системы это ну как бы такой компании комбайн который сводит воедино несколько проектов там все есть Юпитер ноутбуков до оргазм Да но после тестового использования Мы решили что недостаточно подходит под наши цели покрывает не все наши бизнес требования поэтому мы решили пойти другим путем этот путь называется Новая платформа данных платформа данных это нас на платформенного подхода мы делаем систему самообслуживания Где бы наши моделисты могли заказывать себе все для работы Тулы все ресурсы и таким образом как бы унифицировать и ускорять процесс разработки мы сейчас очень активно набираем инженеров от новую платформу данных и с чем мы столкнулись на рынке Готовых ml-специалистов нет поэтому мы как бы требованиях вот на эту вакансию Да знание мл-процессов не указываем мы нанимаем хороший голосов которые могут в докер губернатор системы мониторинг и специфику процессов вводим уже и вводим уже на месте Да в процессе работы над проектом вот большое спасибо что дослушали до этого момента Да с вами были Денис замков и Олег Вознесенский Если вдруг захотите присоединиться к нашим проекту новая платформа данных найдите нас в Telegram да давайте отдела обсудим Спасибо за внимание до коллеги Спасибо за внимание Я тоже посвящу что я сантисов нанимаю Но это видимо не та платформа где у кого-то нанять здесь Олег лучше наймет но давайте у нас будет еще время пообщаться дискуссии присоединяйтесь пожалуйста нам дискуссию после доклада будет ну и Напоминаю что Ждем ваших вопросиков даже после доклада Спасибо за внимание Всем пока Спасибо Пока"
}