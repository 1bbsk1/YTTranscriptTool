{
  "video_id": "0TE040zUK1U",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Я из компании гринатом начать хочется с опроса У кого в своей работе необходимо изолированные тестовые окружение в условиях ограниченных ресурсов так есть Народ а кто решал эту проблему с помощью темы нашего доклада то есть ревью стенды фи стенды кто вообще знает про это супер вам будет вдвойне сегодня интереснее слушать мы расскажем про эволюцию Костя расскажет поэтому поприветствуем докладчика Костя саму наш тех Всем привет е сегодня с ми поговорим внедряли у себя в компании какие проблемы у нас были как мы их смогли решить и в итоге каких результатов мы смогли добиться совсем небольшой слайд обо мне Я работаю в центре цифровых HR технологий компании м из технического стека люблю копаться с куром развивать обсер писать полезные псов ссе штучки на голанг и многое другое на слайде указан мой Telegram контакт кто захочет поговорить за то Добро пожаловать Ну и совсем небольшой слайд о нашей компании it интегратор госкорпорации рутом внутри Грина атома есть центр цифровых HR технологий в нём мы уже на протяжении четырёх лет разрабатываем продукты для HR теха в настоящий момент в портфеле компании 16 продуктов у этих продуктов довольно большой стек технологий Ну разработка тестирование эксплуатации держится на кубернетес кластерах но а в свою очередь кубернетес кластера держатся наос инженерах У нас есть стенд приходите пожалуйста у нас там довольно интересно немножко побуду Капитан Очевидность ни для кого не будет откровением что основ Одним из основных этапов при разработке программного продукта является его процесс тестирования Когда у нас только ожидается mvp то процессе тестирования его автоматизации в принципе мало Кто думает оно и понятно почему Потому что основная цель mvp - это минимально необходимый набор функций которые позволит решить пробле Но когда у нас mvp выстреливает и продукт становится на рельсы то собственно оказывается что данный продукт нужен был всем ещ вчера такая участь постигла и продукты нашего центра Многие из них разрабатывались с нуля их участь была неопределённой но когда выстрелила то начались некоторые проблемы Если всё это переложить на график то до сразу после инвестиции в обеспе больше чем но и собственно Когда mvp у нас зашло то количество фич которые ожидал увидеть заказчика оно резко увеличилось Ну мало того что фи ещё должно было увеличиться их качество Ну а собственно в связи с этим должна была вырасти и команда и Собственно как команде дальше жить вот с таким обеспечением Ну давайте представим ситуацию как у нас было у проши ветка в кою с собственно был развёрнуты стенд и разработчики тестировщики работали на одном стенде это выглядело Вот примерно как на картинке когда все пассажиры ехали в одном автобусе Ну и большинство вот из этих пассажиров Я думаю были тестировщика какие проблемы были вот при данном подходе ну самое очевидное что у нас в деф сливалось всё якобы готово нам негде было протестировать МР Ну давайте мы соль в деф Посмотрим как будет вести себя система после этого Дева после этого эмра и дальше решим Ну понятно что не все ры удачные и собственно стн частенько приходил негодность а другая Проблема была у тестировщиков тестировщик заводит данные для своего кейса они начинают ефекти другого тестировщика потому что данные довольно сильно интегрированы ну и соответственно этот кейс на деви не работает ни у того ни у другого что делать ну Давайте попробуем идти на локальное окружение будем разворачивать свои системы у себя на локали через doer compose или ещё каким-то способом и посмотрим что будет это жутко неудобно особенно когда у тебя довольно большая система и от этого к большому счастью удалось уйти Ну я думаю каждый из вас ещё сможет придумать пару-тройку проблем вот При таком подходе Собственно как мы можем решить вот данный набор проблем ну самое очевидное что приходит на ум - Это от стенда Def развернуть ещё например десяток статических стендов которые будут полной копии Дева и дальше с ними как-то работать ну пройдёт некоторое время вследствие дрифта версий дрифта данных эти стенды станут в принципе нерабочими это Ну можно сказать практический Закон и нам надо будет придумывать какое-то C обеспечение чтобы нам поддерживать эти стенды в рабоче способном состоянии или восстанавливать Ну и При всём при этом у нас ещё тестировщики и разработчики будут как-то конкурировать каким-то административным ресурсом распределяться на эти стенды Ну что как-то не очень удобно Ну лишние сложности противоположно решение чем динамический стенд Когда у нас появилась потребность мы развернули стенд потребность исчерпали стенд погасили Ну вроде звучит Здорово Да удобно и собственно если говорить про распространённую терминологию то вы можете найти что это можно назвать их ревью стендами фича стендами там кто-то называет мультитест у них есть масса названий но в рамках данного доклада мы будем придерживаться понятия RW Давайте немножко определимся Что такое СН мы возьмём вот в принципе определение которое написано прямо в лабе что rvw - это инструмент для совместной работы который предоставляет среду для демонстрации изменений в продукте Ну звучит как то что прямо нам надо А что у нас в принципе-то изменится если у нас будет Будут ревью стенды Вы помните картинку про автобусы Да где разработчики и тестировщики ехали все вместе Теперь у каждого из разработчика тестировщика будет свой собственный автобус где он сможет сделать с ними что угодно рулить ремонтировать Там и так далее другими словами индивидуально независимое окружение если вернуться к лабу как они из себя представляют ревю стенды то там немножко усечённой они представляют Это как review applications и собственно эта стандартная картинка из лаба Давайте её немножко про комментируем Обратите внимание у нас есть Topic branch Это в нашем в нашей терминологии это F branch то есть наша ветка с разработкой и после каждого комита в Topic brunch у нас билди RW ап И после этого билда оно куда-то деплоить вот этот процесс деплоя Вы можете настроить как угодно вплоть до того что статический стенд либо там написать большую портянко чтобы это поднимался динамический стенд и собственно дважды у разработчика неудачно прошёл ревью но третий раз всё нормально и у нас появился мерч почему появился мерч потому что у нас можно настроить пайплайн таким образом чтобы меж был возможен Когда в последнем пайплайн не очень подошёл что у нас просто applications мы решили что система мы будем делать полную копию от Дева и динамически опускать её и поднимать и когда мы С командами определились с командой разработки тестирования что Да действительно тот вариант нам подходит надо было выдвинуть требование к ревю стендам на берегу мы определили что по сути квинтесс этих стендов мы будем поднимать под ней что это короткоживущие стенды для оперативного тестирования изменений то есть стенд не должен жить там 2 недели неделю там несколько суток а протестировали стенд погасили и пошли работать дальше и какие требования у нас были определены на первом этапе к ревью стенда во-первых это была должна была быть полная эталонная копия среды разработки что она в себя включала Это копия базы данных То есть полная копия со все со всеми данными потому что тестировщики наводили туда кейсы есть какие-то понятные данные и собственно на них можно работать должен был быть такой же набор F пати решений типа база данных должна была быть та же брокер сообщения тот же что на деве Ну и так далее и состав версии микросервисов не должны были отличаться то есть ну другими словами как вы поняли это полная копия ветки Def что ещё предопределённость когда мы хотели бы развернуть стенд мы бы накрутили переменные какие-то накрутили на них логику И при разворачивания выбрали необходимый нам набор и собственно у нас ратил стенд той конфигурации который нам нужен Ну и скорость развёртывания будет странно если стен будет развёртывать дольше чем тестировщик тестирует какую-то фичу окей Какой у нас был стек с чем мы подошли вот к началу разработки р версия 123 Но тут надо обратить внимание что у нас cuber он са по сути раскатывается из нашей собственной роли мы не используем никакие облачные решения мы не раскатываем кус минимально необходимый нам в котором мы можем поменять Control Plan в качестве контейнер интерфейса мы использовали база данных пос в качестве брокера сообщений кавка в качестве транспорта и кэша всё это жило в лабе ой Прошу прощения в кубе Ну и в качестве CD системы Это был gitlab а теперь что касается качественных характеристик Нда на тот момент когда вот всё только после начиналось база уже в принципе была такая для деф стенда не маленькая примерно ну в районе 3 ГБ Ну и т пати решение кавка Реди PG баунсер для связки между базой и микросервисами ну и собственно стенд уже в тот момент разросся примерно до 20 подов и в нашем понимание это ну было что один под - это один микросервис я сознательно в этом докладе не буду вам приводить Как писать ревю стенды Да как там в тла разрабатывать этот C было довольно много хороших докладов эту те и в конце Я приведу ссылку на доклад Олега Вознесенского где там чётко ВС рассказывается какие результаты мы получили по итогу Вот это собственно наши предопределенные переменные мы когда Заходим в gitlab выбираем ветку у нас подтягивается набор переменных которые мы определили для веток подтягиваются с помощью вот этой конструкции Да и я думаю она вам знакома и выбираем набор как свободных перемен знаниями Ну и в зависимости от этого у нас будет Раскаты некоторая логика такой получился В итоге для раскатки если вот так вот вкратце пробежаться Да вот по этим штукам то первое на Первом стед у нас проводился деплой сторонних компонентов заливалась база данных заливалась она стандартным способом через это и через pql в другой Ну и версии микросервисов одели этоже параллели раскатка микросервисов из хельм чартов и Билд фича образа третье мы Раскаты фича образ стн и в конце уже ручная или автоматическая остановка в нашем случае мы определили что ну 24 часа если стенд после этого ещё сам разработчик или тестировщик не остановил мы покам его автоматически с помощью инструментов лаба ну супер Что добились время развёртывание вот всей нашей при всех наших данных было 7 минут Ну время вроде нормальное удов команду разработки так в принципе нас на этом мы немножко успокоились прошло некоторое время к нам приходит опять команда разработки говорит Ну ребята что-то у нас появляются проблемы Да у нас команда выросла количество данных выросло Ну и время раскатки выросло стало 15 минут Ну уже как-то мириться с этим было сложно данные тоже возросли до гиго собственно надо что-то делать Сделаю что в принципе вот во всём стенде Да основное время раскатки занимает эта переливка данных То есть если в процентном соотношении взять это 80% и 20% 80% переливка 20% - это собственно раскатка всего остального А что же как бы каким путём пойти нам будет сложно выжать что-то ещё такое серьёзное из нашего стандартного перелив данных и мы решили посмотреть на другие решения вспомнили что у нас есть CSI и может мы что-то сможем оттуда выдернуть это мы уже говорили что в качестве CSI у нас используется из его документации чёткое определение что это Блочная система хранения данных для кубе которая реплицируемый чтото хорошее сде вот что мы немножко пошли таким довольно странным путём на этом втором этапе и Давайте вернёмся к первому стейдж и вот немножко о логике вот прямо внутри этого стей чуть-чуть поглубже погрузимся собственно Что происходило мы Лои базу данных Лои и ждали пока у нас зальёт данные потом собирали статистику по базе данных Почему собирали статистику потому что после дам обязательно Ну необходимо собрать кугут запрос переди и как-то команды пришли к решению что Давайте попробуем в принципе вот взять как у нас есть namespace да Def наш и попробовать его полностью какими-то способами Ну вот клонировать буквально наш ревю снд Ну и на рынке и оказалось такое решение что можно было использовать велера в связке с другими компонентами собственно снапшоте который позволял нам снимать снапшоты научить р снимать снапшоты грубо говоря и где бы всё это хранилось ну немножко изменилась логика деплоить база данных F пати потом велера делала эп в S3 всех манифестов внутри name спейса наших pv сишек и потом же велера восстанавливал п Ну и дальше Всё по стандарту какие результаты по времени вот После всего этого были помните что там было у нас 15 минут что мы получили С таким подходом Ну примерно 15 минут Да плюс-минус там 10% от всего этого Как бы не так чтобы Вау не так чтобы круто мы получили При всём при этом неоправданное усложнение всего нашего пайплайн ребята уже смирились с тем что у нас 15 минут так и будет ну давайте типа мы со всем этим Поживём посмотрим что дальше будет окей 15 минут оставили вернули всё на ТО на старые рельсы как они были и проходит опять время некоторое 15 минут были прошло там буквально ю неско меся вается 30-40 минут А количество данных возросло до 20 ГБ немножко сделаю пометку Почему 20 ГБ но первое что никто не застрахован от ошибок и собственно разработчики Когда делали там некоторые манипуляции то в базу данных писалось довольно большое количество мусора вписались и логи базу данных пытались использовать как брокер сообщений мусорные данные при каких-то расчётах Ну и второе то что Вот пример в качестве примера на данном докладе выступает система по заработной плате по заработной плате довольно большое количество кейсов большое количество данных сами расчёты они также требуют много данных и собственно вот изза всех этих составляющих сложились 20 Гб а тоже необходимо пояснить что вот мусорные данные и прочие использование базы данных не по назначению нам удалось побороть и в принципе мы сейчас живём Вот примерно плюс-минус 20 ГБ со всеми полезными кейсами что дальше мириться с этим уже было совершенно нельзя и мы начали как-то пробовать подходы Ну начали вот с тех 20% Да которые не относились к базе и что-то там попытаться их ускорить самое очевидное это использовать на раннера кэши делаем кэши у нас не надо каждый раз билдить заново все библиотеки мы просто кэш подтягиваем распаковываем и поехали дальше Ну какое-то время выиграли другая очевидная штука у это что можно запускать сборки в параллель те микросервисы у которых необходимо было собрать несколько образов и оказалось что это можно делать непоследовательно собственно начали билди параллельно Ну какой-то никакой плюс мы получили Но блин что с базой то делать как нам пойти этим путём и собственно Мы решили переосмыслить текущую ситуацию Да посмотреть уже более глубоко имен на убера CS этапе научили ещё скажем так делать снапшоты Да у нас есть какие-то бэкапы и сторы Можем ли мы вот просто взять средствами кубера и шку из одного на спейса восстановить в другой най посмотрели что п снимается всё прекрасно Давайте попробуем pvc перенести в другой Space и нет это не удастся сделать потому что вот у нас на на манифесте ниже отсутствует в принципе спецификации поля какой-то Да если мете у нас есть где мы этот PC делаем то взять откуда-то этот pvc чтобы сделать текущем спейсе такого Ну вот в нашем кубе такого в принципе сделать было невозможно хорошо это не повод в принципе унывать Давайте кубе развивается мы посмотрим что в принципе возможно сделать Да проведём какой-то там res подъехала Вот такая крутая штука Cross Space Vol dat Source Ну если вот Прочитать то её може то она позволяла брать шку из друго спейса и клонировать её в свой необходимый Ну вроде как звучит Круто Ну забегая немножко вперёд версия 1.31 она до сих пор находится на стадии Альфа что Давайте попробуем в принципе что-то сделать с этим Ну первое Согласно документации мы включили менеджере эту фичу далее необходимо было включить её на CSI проне который шёл ставил нна но ношения мало имеет собственно он идёт скажем так прицепом всё супер далее необходимо Согласно документации было научить наш кубе новой дике это абстракция reference Grand и Обратите внимание Да что она так интересно как-то сделано что она относится в принципе к и в документации сказано что мы возможно переедем То есть она не будет относиться к gway IP а она переедет эта абстракция прямо в р но пока такого не произошло Если вкратце то она выдаёт разрешение что Да действительно эта операция разрешена и вы можете уть свою свою шку в другой на Супер далее накинешь в принципе уже склонить мы выдали разрешение на клонирование с помощью вот такого манифеста и клонируем видите что у нас появился уже такой параметр как dat Source manif и собственно Из какого делать всё отлично У нас клонировал давайте мы попробуем применить это вот в наш и посмотрим что из этого получится нам Профит из всего этого у нас ну забегая немножко вперёд что Профит у нас вышел Мы научились клонировать и немножко изменили видоизменились она изменилась в том плане что мы запускаем клонирование в ревю пока там клонирует всё это дело мы параллельно раскатываем наш приложение в RW Stand и уже запускаем деплой нашей базы данных с подключением существующей pvc которая Ну в тот момент даже если не склонилась то она ещё в принципе доедет и всё и переходим на следующий стейдж какие результаты мы получили помните Да было 30-40 минут и вот в принципе мы благодаря вот этой штуке которая появилась в кубе мы смогли уехать на примерно 4-5 минут то есть весь стенд с базой данных в 20 гигов там с гигантским количество микросервисов у нас стал разворачиваться за 4 минуты ну 4 минуты 4-5 минут это иде когда кластер находится уже под нагрузкой когда идт полноценный рабочий день и все проснулись то времяни превышает 7-8 минут при этом Ну вроде как всё супер да Но на этом можно успокоиться И праздновать победу но если говорить про развитие ревю стендов то опять приходит уже не сама команда уже больше руководство и говорит ребят бы руто количество возрос возросло но на последующих этапах мы стали наблюдать проблему Когда у нас стабильность продукта она стала ниже за счёт того что там какие-то кейсы самые простейшие они ну выпускались при тестировании на фи стендах там или были какие-то накладки давайте мы поработаем в этом направлении Ну чтобы у нас уже было как бы покруче с качеством и вот сейчас у нас идт по ревю стендам чей этап в компании мы пытаемся влить в ни тесты то есть Каков смысл вот всего этого пайплайн будет у нас когда развернётся полностью пайплайн Когда у нас фича образ заедет наш стенд У нас вот помните предопределённость какой-то набор тестов по предопределённость и собственно Вот а если брать Вот развитие ревю стендов да нашу эволюцию на отдалённые перспективу Если ещё куда нам поработать В этом плане Ну во-первых у нас уже поступали запросы что как бы круто что вы берёте с Дева да всё но есть ли какие-то варианты чтобы брать БД из других ту нантонг быть какие-то разные где-то более специфически например под интеграции где-то под ролевую систему то есть поработать с ними а Можем ли мы ещё также проработать вопрос чтобы более плотно упаковывать стенды Ну очевидно что тут можно как-то упаковка стендов чтобы побольше стендов влезло в наш кластер здесь уже можно будет поработать с реквест лимитами Да там определить те реквесты которые нам действительно нужны при старте с помощью специальных утилит и в зависимости от этого деплоить ну и там прямо уж совсем скажем так в кавычках утопическая идея что круто было бы если бы у нас для всех наши проектов был один кластер для ревю стендов То есть у нас исчезла бы потребность что не хватает стендов И как бы нам ещё развернуть А как-то у нас всё бы была такая саморегуляция скажем так и каких вопросов вот мы не коснулись в данном докладе собственно мы не поговорили как мы в принципе рассказываем раскатываем стенд какая у нас происходит логика там в первой д что мы там конкретно делаем Какие настройки настраиваем а внутренние проверки стендов также не рассмотрели то есть как мы проверяем что у нас стн соответствует версиям там чему-то ещё и Собственно как мы получаем в принципе версии микросервисов который нам необходимо раскатать ведь в принципе может быть такая проблема Да что у нас в стенде есть версия микросервиса например в лапа контейнер registry её уже нету как нам тогда быть чтобы в принципе стенд был максимально рабочий Вот но этих вопросов мы можем потом как-то обсудить например в дискуссионного вот с ревью стендами к разработке и тестированию Ну во-первых даже минимальная конфигурации ревью стенды позволят вывести уровень тестирования ваших продуктов Ну прямо на качественно высокий уровень Ну за счёт чего это будет достигаться за счёт того что у вас будет самое основное среда в принципе соответствовать среде в проде мы не говорим о данных в принципе говорим о среде в проде Ну следующий Вывод что отрицательный результат он в принципе даёт нам фундамент для будущих побед помните что у нас второй этап вышел Ну совсем фиговый по результатам но при этом мы на этом этапе затащили некоторые фичи у наш uber апробировать их и собственно дальше смогли ими манипулировать Ну и тоже такой вывод что когда вы будете обновлять CSI а corn он довольно активно развивается то всегда не забудьте выдавать вот эти вот права которые были там на четвёртом шаге чтобы потом не разбираться А почему же у меня всё перестало работать с ревью стендами ну обещанная ссылка на материалы собственно доклад Олега Вознесенского блог кубернетес где рассказывает вот об этой новой фиче и сама документация где вот прямо такие небольшие выжимки по фич которые мы применили так ребят У меня всё спасибо да ко Спасибо большое за доклад очень интересно Такой путь прошли А я пользуюсь случаем Хочу задать вопрос Собственно как сделать так чтобы Метрика Time to maret не взлетела куда-то в небеса вот при внедрении данного подхода Какие советы ты бы мог дать Ну слушай смотря что понимать то есть у нас по идее она взлетать небеса не должна Да она наоборот должна наве у Наста совсем минимальной Я думаю Ате Нам её вы выведут вот этот Time to Market вообще на минимальный уровень То есть когда у нас будут автотесты то Ну за счёт снижения ручного тестирование Да качест да спасибо А есть ли за вопросы Из зала Спасибо за доклад очень интересно было а у меня такой вопрос а у вас Всем разработчикам прямо надо чтобы была у них база данных прям актуально актуальная Я к тому что вы не рассматривали возможность просто в конце дня делать скеле скел в ноль всех кодов а потом утром их просто поднимать и всё без без того чтобы заново переливать всю базу данных заново создавать всё это заново всё деплоить Ну на тех этапах Да что-то такая мысль даже не приходило Но вот на текущих минутах Я думаю даже не стоит заморачиваться 4 минуты довольно быстро ресурсы вроде есть Ну как вы сами сказали у Вас могут быть проблемы с тем что у вас образ просто не спли в какой-то момент а тут немножко не так было то есть не слится он в тот момент если его не будет но мы в своей логике как раз вот это вот учили то есть Мы опрашиваем алаба спрашиваем У него есть ли у тебя вот этот образ на стенде если нету то какой последний г был берм этот г проверяем его собственно И как у вас доступ выдаётся к стенду разработчикам и как он контролирует чтобы они никуда не ушли Ну в каком плане не ушли Ну не знаю или как он у вас выдаётся Ну видимо имеется в виду на чужой стенд не зашли Да я правильно понимаю ну настолько у нас политика разделяется то есть снот влу не очень а ещё вопрос может быть да сразу хочу сказать спасибо за доклад вот актуальная кстати проблема Мы у себя решали схожую обсудим потом на переговорки буквально два КТА двад два квартала назад Да и у меня сразу сходу вопрос Вот это выделенное тестирование фичей на выделенных кружения Задумывались ли вы о подходе параллельного тестирования фичей или вы содержится грубо говоря в одном спринте либо в обм в одном объёме работ одну фичу её катите и потом по ней проводите регресс Как вы в общем и целом решали проблему параллельного тестирования нескольких тикетов которые могут после сформировать один релиз Да спасибо за вопрос Ну собственно смотрите то есть параллельное тестирование оно в рамках стендов тоже возможно то есть в целом мы можем проверить несколько историй то есть тестировщик развернул стенд они вместе пошли что-то тестировать Да О'кей закрыли вместе но тут как раз-таки ревью стендами мы решаем вопрос изоляции когда люди афект какие-то генерируют данные и могут Чисто гипотетически или реально на реальном примере нарушить работу других людей вот а грубо говоря регрессионное тестирование n2n тест мы в любом случае когда будем выпускать релиз мы это всё пройдём это всё будет сделано Ну как-то так Ну Женя как руководитель разработки в принципе авторитетно говорит об этом да я был вот заказчиком собственно этого всего дела Вам спасибо что слушали если что собираем"
}