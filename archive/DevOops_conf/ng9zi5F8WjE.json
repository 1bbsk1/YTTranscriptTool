{
  "video_id": "ng9zi5F8WjE",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "пока коллеги Добрый день Рад приветствовать вас на нашем демо по мониторингу по созданию процесс установки сервисов и продуктов на мониторинг встречи я вам расскажу проблематику данного направления Как быстро выбран номер архитектурное решение и Как быстро поставить свой сервис на мониторы в рамках нашей компании как мы это сделали какие инструменты доступны для нашей компании и Давай сначала поговорим Зачем вообще решили заняться этим направлением и поможем даже найти проблемы в нашем процессе самое первое самое главное многие команды проходят один и тот же однообразный длинный путь по постановке сервиса на мониторе когда задумываемся мониторинге когда у нас уже что-то упало это так нам прибегает Ребята с горящими глазами говорят ребята все плохо все пропало Почему мы не знаем где наш мониторинг где уведомления что за проблема также Так проходит в каждой команде И каждый продукции и все делают по сути одни и те же шаги и одному и тому же пути и наступает Что делают чтобы решить эту проблему обращается в Google для проблематики для решения потом пишут какие-то решения настройки парсеры метрики также без практики А теперь Представьте Нет вообще и количество итерации туда в нашем случае увеличивается соответственно время реализации ситуации Ну и как Мы все знаем Здесь и сейчас а лучше еще вчера так сервис упал решение нет И мы с командой решили что нам нужно универсальный подход который позволит не тратить ресурсы на рутинные задачи отдаст возможность продуктовому сконцентрироваться собственно развитие своего продукта наши сервисы И вообще требования к мониторингам мы смогли сформировать несколько тезисов для фреймворка первый самое главное что это нужны минимальные требования перед установкой каждый экспортер всем должен иметь свой репозиторий описанный как концы был роль Что позволит установить его пару кликов на подготовленный ход а также переиспользовать своих пайплайнах как Независимый инструмент также возможность командам использовать настройки наработки друг друга для минимизации на временных затрат в дальнейшем это позволит больше создать большой базу знаний по мониторингу различных сервисов все экспортеры по возможности возвращаться разворачиваются контейнеры Это для того чтобы во-первых для изоляции собственно сервисов мониторинга во-вторых для нивелирования рисков окружения на целевом сервере на выходе у нас вместе общий dashbox необходимым набором инструментов и собраны заранее информация по всем сервисам и продуктам В итоге собственно мы могли даже найти проблему также путь для решения единый подход постановки сервиса мониторе Далее вам расскажу Подробнее об инструментах сейчас доступных и как пользоваться доборными в нашей компании непосредственно Давай сначала посмотрим общую схему реализации данный момент реализованный эксперт для Flow Кафки Докера для сбора логов используется собирается все это в Прометей логи собираются власти дальше для визуализации настроена в графане и в кибани возможность строить также по Логан и бане имеется есть возможность получения уведомлений об авариях инцидентах на электронную почту Консул используется для Discover новых инсталляций также используется для установки раскатки технические требования для установки мониторинга логирования минимальные для кубера это сетевой доступ и токен расположенный волк для установки на чистую ноду в докере нужны собственно сетевой доступ будет установленный докер выше 19 версии бетон выше 27 докер для бетон и собственно доступ для технической учетной записи которая для раскатки все сети нас хранятся в общем репозитории реализованы с помощью с использованием шаблонов о которых завтра расскажет Мой коллега Виталий на своем директора расположены для установки в директорию мониторинг расположены собственно сами X портеры которые у нас сейчас реализованы все антигуроли у нас хранятся в отдельном репозитории Где в принципе хранятся все роли нашей компании Сейчас для установки любого экспортера нужны стандартные переменные такие спорта название продукта соответствующие внутренняя система в которой собственно весь список продуктов с ключами есть это мы сделали для того чтобы не было путаницы уже на дашборде потому что многие изначально заводили свои продукты по-разному называли и один тот же продукт фильтровался несколько раз и что вот этого мы избежать Мы сделали интеграцию с этим сервисом который собственно не дает установить Если такого продукта нет в нашем внутреннем сервисе собственно окружение в котором работает сервер так далее ну и собственно питон если используется отлично От юзер директория по итогам внутренних тестов на одном из наших продуктов для сбора логов был выбран fluenbit также рассматривались люди и файлбит но по уровню утилизации быстроты работы они не удовлетворили требованиям и поэтому мы решили использовать в данный момент реализована установка вклада cubernets и на чистую ноду в докере рассмотрим конфигурацию на примере кубера в директории конфликт расположены конфиги который разбиты по продуктам по дефолту собираются логи самого кубера и энгресса обычно это джинсы остальные сервисы каждый своем файле также есть также есть файл с красным партиями их можно определить Используйте любой конфигурация как парсициология форматы индексов и так далее теперь рассмотрим такие экспортеры уже реализованы какие методы можно получить и как установить намного своего продукта например слово спорта собирает метрики о состоянии дуллера веб-сервера и базы данных а также о состоянии запускаемых дагов спорта собирает метрики Кафки и может показать для каждого топика разница между записанными прочитанными сообщения можно за мониторить лагпов сетах или секундах для всего топика и для каждой партиции собирается по хостам такие как память диск также у нас есть и докер-экспортов который для сбора метрик именно контейнеров У нас реализованы два эскорта seadvisor и прометеос над докер exporter экспорт отслеживает состояние докер контейнеров и потребляемый ими ресурсов также есть еще плоскости данных собирает метрики А ее состояние также метрики по гостаты погасить Давайте поговорим о нашем дошкорды в таблице представлены все переменные которые мы используем для фильтрации построения метрик вытаскиваем их при установке каждого экспорта теперь теперь взглянем на общий dashboard на нем ниспадающим меню есть возможность выбора продукта слева вверху отображено количество авертов по всему продукта fireflow пока хостам и Кафки также предоставлена информация сколько хостов в продукте докер контейнеров instance firefall и posless и собственно видно основные параметры по хостам CPU память заполнить рутую файловой системы внизу отображается несколько вкладок по сервисам и далее мы на них подробнее остановимся цветовая схема плиток выбрана формате светофора зеленый цвет показывает что все в порядке желтый стоит обратить внимание красный нужно что-то срочно делать например при загрузке CPU на 50 процентов плитка будет зеленый при 85 желтый 90 красный обычно всех есть описание ее значение первые вкладке позволяет на одном экране увидеть основные параметры Ростов например Мы видим что загружена память на непонятно кому на сервере смотрим более детально и видно Где но мы хотим больше информации чтобы провести уже полный анализ для этого есть гиперссылка в углу панели и нажимая на нее попадаем другой зажгу с очень детализированной информации и возможность просмотреть исторических данных вся информация по хосту уровня железа операционной системы для этого также есть возможность не переходя во внешний наш борт посмотреть краткую информацию по нашим продукте выбираем в панели сверху так и смотрим открываем вкладки динамическими метками и информация по хосту на следующем а настоящем слайде мы видим основные метрики по Кафки такие как количество входящих сообщений секунду за последние пять минут по каждому входящий исходящие данные в килобайтах по топиком лаг сообщение между записью чтением и количество утилизированной памяти далее рассмотрим панели Flow здесь мы видим метрики по доступности базы данных на каждом Хосте где она развернута шедоулера количество запущенных процессов на всех инстанциях слов список дагов на всех новых их состояние выбрав в верхнем меню dashboard до нужной нам Дак и временной интервал мы можем посмотреть историю его работы графически показано когда так находился соответствующих статусов и цветовой раскраски на этой панели видно активный или остановленные если нам интересен только один статус то можно нажать фильтр выбрать который нам нужен конкретный момент времени с возможностью дальнейшей фильтрации непосредственно уже по хосту на вкладке по докеру мы можем посмотреть статистику по контейнерам запущенным на Хосте такое количество контейнеров на продукте или На выбранном Северного Сколько памяти и CPU используется и как утилизируется сетевые интерфейсы пользователи панель здесь мы показывает статистику по базе данных какой версии когда запущены размеры количество сессий транзакций Теперь давайте поговорим о сборе и парсингелогов рассмотрим инсталляцию тут есть несколько вариантов как можно развернуть сборщик логов собирать из файловой системы или забирать из систем далее рассмотрим конкретное приложение и конфигурационный файл для него в данном случае толпач флинк сервисом одно из наших команд вообще так себе собираем парсим фильтруем буферизируем отправляем посмотрим на секции но не будем подробно останавливаться на каждом параметре нас интересует только два откуда читать слоги в данном случае это содержится в ПАЗ и модуль партера который мы будем использовать это самописный find mult parser на входе мы имеем вот такой разрезанный Лог на несколько сообщений далее используется наш соматистый парсер говорим бит Как собирать настроечные сообщения в данном случае с помощью первого фильтра мы говорим что и надо у нас данными из кластера а также разобрать стандартное поле Лог нашим самописным и прибавить префикс и поиска затем с помощью фильтров мы удаляем логику уровня info и собственно добавляем новое Поле с типом окружения в данном случае это перемены заполнять значением тест его мы указали при установке флинбит и последний сектор отвечает за отправку логов здесь указывается куда и в какой индекс отправлять записи теперь посмотрим как это выглядит со стороны посуточно срок хранения 10 суток для просмотра на дашборде необходимо вручную создавать интересующийся индексом В итоге изначально не читаемого Лога мы на выходе получаем структурированные данные с возможностью полно текстового поиска и фильтрации здесь собрана информация по контейне по кластер куберы какой контейнер записал этот блок в каком поди он находился на какой он работал какой использовался при тепло и так далее само сообщение из приложения и его разобранная копия где мы в данном случае видим выдавшие сообщение уровень и текст ошибки время событий установка токере выглядит так же позволяет использовать парсер который написан до этого другими коллегами например мы с вами видим блок приложение используя самописный парсер javaluxe line мы собираем логи приложения с Хоста склеиваем многострочные записи затем мы встречаем данные по типу окружения и серверу и оттуда происходит сбор для дальнейшей фильтрации собственно получаем Лог удобного на формата Теперь давайте вкратце посмотрим эти Банк какие базовые возможности она предоставляет это собственно основной экран а для работы с индексами на нем видно выбранные нами индекс временной интервал а также в графическом виде количество сообщений с разбивкой по 30 минут есть возможность написать запрос на языке кебаны или отфильтровать по нужным нам полям можно сохранить свой запрос и поделиться ссылкой на него Для дальнейшего удобного использования внутри своей команды Например возьмем из один из сохраненных поисков здесь мы говорим что нам нужны записи с определенным текстом в поле лог а также через фильтр исключаем тестовую среду и отображаем данные за последние 24 часа выбираем нам Поля из доступных в индексе это произошло событие и само сообщение в итоге мы видим что был один из сообщений Ну и где когда они произошли также есть возможность графически отображать информацию из логов например тут вы видите дашборд продукта с картой источников запросов для формирования таких дашбордов доступно больше десятка различных визуализаций мы с вами рассмотрели основные элементы в рамках данной встречи полностью рассказать о каждом спорте нереально всего на данный момент их реализовано 15 штук которые готовы к эксплуатации Она вся из них уже написаны роли по установке добавлены метрики в общий дашборд То есть каждый новый продукт который приходит наша команда может сразу быстро настроить мониторинг на нужные сервисы на нужных серверах на вчерашний день Я посмотрел Сейчас пользуется более 40 продуктов нашей компании Big Data мы постоянно ведем работу по расширению и улучшение функционала запросам наших пользователей мы добавляем что-то новое развиваем дальше собственно на этом моя презентация подошла к концу Спасибо вам за внимание вопросы и предложения наверное в чате Да всем еще раз привет в чате есть вопросы Спасибо за доклад Павел спрашивает используется для мониторинга такие продукты как забиксы или Виктория метрикс У нас сейчас как раз собираюсь с помощью Виктория метрикс Это для уже Для более для рассылки и настройки алертов используется другими нашими командами денег администраторы например Мы в основном его не используем вначале были проблемы со связью немножко еще расскажу у нас выделенное подразделение Вот и у нас есть своя инфраструктура построенная для мониторинга то есть в общем большом тесте активно используется то мы себя исторически использовали Сейчас переходим из-за того что нам уже не хватает стандартного Прометея и Кто отвечает за настройку Но это каждый для своего продукта настраивает всех разные задачи Ну и также хочу сказать что это у нас настроено в гитлабе то есть каждое девопс продуктовый может зайти в gitlab сделать мёрзший квест и это автоматически после принятия квест попадает уже на продакшн еще один вопрос тоже отпала над экспортер собирает симметрики корректно если допустим в контейнере чтобы были некоторые проблемы их обошли уже то есть да собираются хорошо так в основном я тоже сейчас с вопросами Да алерты у нас сейчас в основном поимел настроено но как раз Виктория метрикса и прометеос у нас есть еще дополнительный инструмент по мониторинга который может рассылать СМСка У нас есть используется каким-то образом через собираете на моем продукте нет но вроде ребята делают подобное Окей так А Лер Ты по имейл только здесь уже Владислав ответил что есть звонки У нас есть которые тоже реагирует на нашу если не каждый раз дергается разработчиков Павла еще один Как происходит разграничение прав у графа на для конечного пользователя у нас разграничение прав с помощью адешных групп и в принципе если кому-то нужно там новом разработчику какие-то свои дашборды мы просто добавляем ему роль эдитора чтобы он мог спокойно свой даже борт Ну в принципе да у нас есть общий но никто не мешает сделать свой на основе нашего например переиспользовать наши запросы и настройки сразу ответил на второй вопрос для команды или только предустановленные заранее наборы Нет все можно использовать как вам удобно действительно у нас продуктов почти на каждом есть если что-то нужно расширить не оптимальным запроса выборки данных можно положить сервис источника данных ни разу такого У нас не было положить Наверно все можно на самом деле других командах были такие проблемы Вот это либо экспортера некорректно написано либо самостоятельно писал скажем без ревью данного решения что при каждом обращении даже борт идут запросы в сервис а сервисы тяжелые то соответственно можно его положить а если агрегирующий дашборд для первой линии без детализации для первой линии думаю вот общий dashboard Где в принципе общая информация предоставлена там дальше если детализировать то можно расширять бесконечности но это уже каждый продукт по-своему делает это и так принципе есть так коллеги приглашаю вас всех в дискуссионный зал время у нас уже закончилась будем рады там продолжить ответы на ваши вопросы"
}