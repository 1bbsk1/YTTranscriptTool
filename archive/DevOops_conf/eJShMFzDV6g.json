{
  "video_id": "eJShMFzDV6g",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "меня зовут олег и я работаю в компании одноклассники в команде платформ на что же еще есть в компании одноклассники в принципе очень много железа у нас 4 центр обработки данных в этих в центр стоит около 500 стоек в которой мы засунули более восьми тысяч серверов и кроме меня с этим железом работу следующие люди это инженеры который находится непосредственно в это центров и и работают с оборудованием это сетевики которая настраиваю сетевое обеспечение это админы и weser я которые работают больше на тему обеспечения отказоустойчивости инфраструктуры и это разработчики разработчики все поделенные на функциональные команды и они делают и выкатывают на продакшен софт который работает как то так запросы пользователей поступают на фронты или на фронт основного портала или на другие фронты например тут фронта пи музыкального сервиса для обработки бизнес-логики они вызывают applications сервер который в рамках обработки запроса вызывает необходимые сервисы микро сервисы каждый из которых является специализированным у каждого из такого из таких сервисов есть ответственные разработчики которые отвечают за функционирование своих модулей и их технологическое развитие эти все сервисы запускаются на железе и до недавнего времени было как то так на 17 выделялась на одном вся железном сервере запускалась ровно одна задача он был специализирован под нее чем это хорошо прежде всего это просто это просто в массовом управление то есть можно было написать какие-то скрипты которые единообразно работают с этим железным сервером какие-то версии библиотек можно было поставить специализированный на этой сервер версии чем все что угодно нужно чтобы этот эта задача была этот сервер будет специализирован под эту задачу это также просто в диагностике потому что глядя на допустим нагрузку центрального процессора вы понимаете что эту нагрузку могла сгинет только то задача которая работает на этом железном процессы в принципе поиски виноватого кончается очень быстро это также удобный в мониторинге если что-то не так происходит с сервером to monitor об этом сообщает а вы точно знаете кто виноват это вот этот сервис соответственно на сервисе сервис состоит из нескольких серверов сколько серверов кисти у сервиса столько он и может потребить соответственно это очень просто распределяется вычислительный ресурс под сервис просто не стоит точки зрения что это очень удобно с точки зрения что это тупо вы просто сколько если железо стаканы может потребить это также на позволяет сделать специализированные конфигурации под требования задачи который работает на этом серве допустим если эта задача которая в первую очередь хранить большие объемы данных то мы покупаем ти4 у сервер 38 дисков втыкаем его в стойку работает если это какая-то чисто вычислительная задача то мы можем купить один более дешевый сервер и поставить его туда и это эффективно с точки зрения ресурсов допустим именно вычислительных ресурсов в том числе и поэтому при сравнимой нагрузки у нас в 4 раза меньше железо чем допустим у контакт нагрузка при этом сопоставимо мы не только поэтому но в том числе и поэтому и мы исходили из и мы думали что будучи эффективным по вычислительным ресурсам мы будем и экономически эффективными мы исходили из посылки что самое дорогое это сервера которую нужно ставить и итога и время так и была самым дорогим была цена собственно железо и мы долго работали над тем чтобы снизить стоимость закупаемого железо с помощью реализации соответствующих алгоритмов чтобы мы могли понизить требования к надежности железа и таким образом закупать его как можно дешевле и сейчас мы дошли до той стадии когда цена сервера уже не являются определяющим сейчас у нас другая проблема на первый план вышла цена место в дата-центре то есть место в стойке который сервер занимает в принципе если не брать какой-то распоследние экзотики нам все равно что в эту стойку какую конфигурацию в эту стойку поставить с точки зрения экономики ну естественно раз мы поняли что сама теперь дорогое это у нас утилизация стоит мы решили посчитать эту самую утилизацию насколько эффективно мы используем эти стойки мы посчитали так взяли цену самый дорогой сервер которым самый мощный сервер из экономически оправданных сколько мы можем написать и в стойке и посчитать сколько же задач мы запускаем и как как они используются подсчитали прослезились оказалось что утилизация железного дата железных стойку нас около 11 процентов вывод в принципе очевидный да нам нужно повышать утилизацию нато центром давайте попробуем сделать это по простому то есть мы теперь будем на 17 и запускать сразу несколько задач и но тут становится сложности до начинаются сложности конфигурация у разные задачи требуют разную конфигурацию in часто она конфликтующие одни сиз циклы для дна озера нужно сделать другие друга диагностика тоже усложняется теперь глядя просто на загрузку цп вы не можете сказать себе какая из задач которую на этом сервере работает реально делает реально вызывает проблемы повышенном потреблении циpкa допустим или дисков вторая проблема это распределение ресурсов теперь если вот на этом сервере работает несколько задач от нескольких команд то какая то если команд может потребить все за все ресурсы этого серого этим самым повлиять на задаче других команд которые в общем то ни сном ни ухом и вообще не виноваты все из-за этого еще одна проблема то вот как раз то что нет изоляции если какая-то кто-то написал такую программу которая сожрало все ресурсы то это влияет на работающую рядом задачу вот как раз такая картинка когда работал себе работал сервис с короткой задержкой это его время ответа да и тут кто-то рядом на сервере просто запустил какую-то задачу которая что-то там посчитал да мы видим что время деградировала очень сильно давайте посмотрим что мы можем сделать для решения хотя бы части проблем часть проблем решает на самом деле докер он нам обещает изоляцию контейнеров друг от друга таким образом что они не будут влиять друг на друга и по памяти и по циpкa у него кроме того есть еще очень удобный и очень удобные образы файловых систем нее есть многослойность что улучшает кэширование нас кашель не одинаковых частей имиджей на на дисках на дисков машин есть таги которая в принципе готова готовая заготовка под versio нирования имиджей у нее есть registry который тоже готовый примитив для того чтобы доставлять код на продакшн кроме того мы бесплатно получаем унифицированные api для управления ими джами и задачами на машине и соответственно вас повышается автоматизированная но это только часть проблем а эти счет другая часть проблема которая докер в чистом виде не решает это собственно размещение контейнеров на сервера то есть понять какой контейнеры на какой конкретно сервер поставить на не такая простая задача как кажется на первый взгляд потому что нам нужно разместить контейнеры таким способом на сервера чтобы мы как можно более плотно упаковали контейнеры на машины с одной стороны а с другой стороны это не привело бы к деградации их скорости работы такое размещение может быть сложным с точки зрения требований к отказоустойчивости часто мы хотим размещать реплики одного и того же семеро из сервиса не в разных стойках или в разных залах дата центра для того чтобы при отказе стойки или зала мы бы не поднять теряли сразу все реплики сервиса ну и кроме того когда у вас с одной стороны есть восемь тысяч серверов с другой стороны есть 8 или там 16 тысяч контейнеров то вручную их и вот так распихать да это очень принципе сложная задача понятно что вручную мы не можем это сделать это не вариант для нас кроме того прекрасно при распределении ресурсов мы с одной стороны хотели сделать так чтобы разработчики получили больше самостоятельности то есть могли сами размещать свои сервисы на продакшне но с другой стороны мы хотели сохранить контроль то есть не допустить такого сущая как чтобы второстепенный сервис какой-то использовал все ресурсы наших датацентров очевидно что нужен управляющий слой который бы автоматически этим занимался ну то есть мы приходим простой понятной картинки которые все обожают архитекторы 3 квадратика да у нас есть отказоустойчивый кластер мастеров облака long old masters на нем реализована какая-то управляющая логика и он соответствии с этой управляющей логикой дает какие-то команды миньонам доминионе есть вот наш агент который получает эту команду он с одной стороны сообщает массе мастером о том что он жив с другой стороны в ответ на управляющей команды от мастера дает команды докер у который соответствии с полученными командами делает необходимые действия с линуксом kizashi мастерском фигуре все очень просто что может быть проще 3 квадратиков мы этой картинке еще вернемся ближе к концу презентации а теперь давайте сначала разберемся с задачей более сложного распределения ресурсов на множество миньонов для начала давайте поймем что же такое ресурс для нас не sux этого первую числительное мощность циpкa сколько потребляется циpкa данных задач во вторых этот объем памяти которую задача может потребить в третьих это трафик кстати вот эта часть очень часто опускается при из из рассмотрения но трафик это тоже конечные ресурсы вы не можете выбрать больше трафика чем машина в состоянии вам дать диски во-первых это место на дисках а во вторых это тоже очень часто опускается в различных системах управления надо центрами это тип этого диска что это такое хдд ssd и и опции то есть сколько задача может насколько она может этот диск нагрузить как она его нагружает потому что и овцы кроме место все мы знаем что и и опция это тоже ограниченные ресурсы у железки под названием диск ну с точки зрения программиста мы как-то так вот можем записать вот наборами саксов таким способом полторы тысячи con циpкa памяти полтора терабайта на сервис 32 гигабайта трафика туда сюда ой 20 хдд по 15 работ кашки ресурсы естественно конечно у нас всего восемь тысяч серверов и там определенное количество конечное количество ресурсов их нужно квартировать таким способом чтобы никто не мог потребить и все но на что поставить квоту куда ее привязать давайте вернемся к вот этой вот картинки нашей знакомый и ним на нас слишком к очень простая на давайте попробуем ее более понятно перерисовать и получается вот так тут уже первое что бросается в глаза что на самом деле веб front-end и музыка используют разные кластера одного и того же об летишь на одного и того же приложение applications второе что бросается в глаза это то что мы на самом деле можем выделить логические слои которым эти кластера относятся например вот это фронты вот это крыши а вот это слой хранения и управления данными но то ли ещё что-то выделить на этой схеме конечно видно что фронт он не однороден это разные функциональные системы вот это относится к общему его портала то есть это основной портал его вокруг а вот это тоже фронт но это api фронт для чистого музыкального сервиса каши тоже можно поделить по под системе данные которого они копируют давайте еще раз перерисуем эту картинку уберем из неё милые нашему сердцу квадратики вот у нас фронты вот у нас веб музыка все тоже самое ну единственно замечу на полях что веб достаточно большой кластер и для удобства управления и мы на самом деле его делим на 2 и на большое количество групп для ну для того чтоб просто проще было управлять что ж это такое напоминает иерархи ну правда и тогда для того чтобы распределять ресурсы мы могли бы более более крупным куском эти ресурсы распределит таким способом чтобы допустим на под систему назначить ответственного разработчика и к этой же к этому же уровню иерархии прилепите квоту и давайте еще совсем уберем отсюда картинки из хлопнем все это таким способом запишем в линию всю эту иерархию group 1 vip фронт api мезек фронт и user cash cash вот это вот часть вы решили назвать явно эта сущность какая-то да и мы ее называем эротической очередь у нее есть имя вот она групп веб фронт на нее вешается квота на ресурсы вот она на него так же мы вешаем и права пользователей да допустим на для человека больше на два пса у которого впереди дав да то есть разработчикам и вешаем право на отправку сервиса очередь он может отправлять и запускать что-то очереди админ может управлять этой очереди назначать туда каких-то людей давать право создавать и так далее и в эту очередь мы отправляем сервисы которые будут выполняться в пределах квоты то есть если вычислительной квоты очереди недостаточно то сервисы будут выполняться там последовательно имеют формируя таким образом очередь отсюда собственно она с одной стороны невротическое 1 тира очередь давайте посмотрим на сервис и более подробно о сервисе есть полное имя вот допустим одноклассники век групп один год фронт также работает apple пишем сервер одноклассники а папа труб 1 фетр у него есть манифест в котором указываются вся необходимая информация для того чтобы этот этот сервис разместить на конкретных машинах ресурсов потребляет эта задача к конфигурацию нужно сделать для этой задачи сколько реплик там должно быть кита профиль себе отказов для обработки отказывают отказов этого сервиса они все указываются там и когда сервис в конечном итоге размещается на машинах то появляются его экземпляры и они тоже именуются однозначно и мы видим какой экземпляр какого сервиса у нас есть ну а теперь давайте немножко ближе познакомимся собственно теми задачами и посмотрим что же какие задачи есть в одноклассниках все в принципе задачей в одноклассниках да наверное не только могут поделиться на следующий класс это задачи с малой задержкой которые мы называем прот здесь ваш для таких задач для таких сервисов очень важно время ответа то есть лет инси то есть как быстро каждый из запросов будет обработан системой другие задачи расчетные матч здесь уже как быстро каждый конкретный кусочек работы обрабатывается не так важно а можно за сколько общее количество времени потребуется для того чтобы завершить эту задачу примерами такое такого сервиса могут быть любые map редис тоски hadoop и машин learning статистика все чтобы третий тип задач это фоновый сюда входят различные тесты какие-то миграции пересчет и переживание данных из одного формата в другой да каким какие-то конвертации все что угодно для такие такие задачи с этой точки зрения они похожи на расчетные с одной стороны но с другой стороны на мне очень важно как быстро они завершатся то есть у завершили за неделю хорошо за неделю до 2 за 2 6 хорошо тоже нормально пойти разберемся задачами с короткой задержки если мы посмотрим на то как такие задачи потребляют центральный процессор то мы увидим какую-то вот такую картинку поступает запрос от пользователя на обработку быстренько задача начинает использовать все доступные ему ресурсы центрального процессора отрабатывает возвращает ответ стоит ждет следующий запрос поступил опять все выбрали все что было обсчитали ждем ждем следующего таким образом чтобы гарантировать минимальную задержку для такой задачи мы должны взять максимум того что эта задача потребляет и зарезервировать вот это количество core на непосредственном машинах которые и будут выполнять на миньон их то есть мы для нет для них напишем вот такой allocation мы хотим размещать эту задачу так чтобы количество core потребляли за resimleri для этой задачи 4-core и тогда если у нас есть машина в которой 16 коп ну мы очень просто размещаем эти задачи на такую машину первую задачу разместили она потребил а4 коры вторую туда же ну и остальными тоже все закончили четыре задачи на одну машину залезает замечательно просто понятно но здесь есть одна проблема это среднее потребление процессора у таких задач 5 часто очень низкая средняя утилизация процессора давайте перейдем к другому классу задач к расчетным мочу у них уже немного другой поттером потребление процессора на это чаще всего мы запускаем какой-то batch дальше он начинает работать он потребляется пау что-то там считает чуть больше чуть меньше и с этой точки зрения средняя утилизация у него достаточно высокая но для таких задач и сада с одной стороне ней средняя утилизация с другой стороны мы хотим сделать так чтобы эта задача заканчивалось в определенное количество времени поэтому мы хотим зарезервировать по днем минимальное количество процессоров которые ей ей дается определить меню и для неё по локация да будет выглядеть как то так размести пожалуйста на меню не где есть хотя бы один свободный свободная кора а дальше сколько сожрет столько сажи тут с утилизацией уже значительно лучше дать чем с заданной на задачах с короткой задержки но женщина значительно больший выигрыш можно получить если научиться распределять ресурсы машины на ходу так когда задача с короткой задержкой требует циpкa она его получает а когда задача с короткой задержкой циpкa мне нужен его будет потреблять расчетная задача но как это сделать давайте для начала разберемся спрос род хотим 4 кора зарезервировать в докере можем это сделать двумя способами мы можем объявить со paused то есть выделить задачи 4 определенных кора на машине или мы можем выделить их квотой то есть указать что мы хотим каждый каждый 100 миллисекунд чтобы задача потребляла не более 400 миллисекунд процессор на во времени таким образом эффективно это те же самые 4-core но какой из этих способов подойдёт с одной стороны paused выглядит довольно привлекательно да у нас 4 выделенных core есть у у задача крыши значит будут быстро работать память все хорошо но мы на самом деле давайте попробуем разместить на такую машину batch для batch задачи выделение pokora мне подходит потому что если у вас эти четыре коры завизирую ну и подзадачу то туда уже больше не эти дети коль и никто уже больше использовать не может а вот вариант сквоты подходят потому что вот они дает вам эксклюзивный использовать коры вы используете только процессор на и время а теперь давайте посмотрим как в докере сделать batch то есть резервацию по минимальному количеству core квота для батю задачу же неприменимо потому что ограничивать максимум нам не нужно на максимум у нас открыт нам нужно только гарантировать меню и тут хорошо подходят сибиу шерсть мы договорились дать так что если матч требует 1 кор и минимум ту мы используем себе уши рс1 к а если batch требует 2 куры минимум то мы резервируем это дизелем это так мы указываешь с 2к поскольку циклу шерсть только батч и отдал задачи используют то между собой они делят процессор когда он полностью используется то они между собой делят процессор в соответствующей пропорции задача с одним циpкa получает меньше задача с минимум два получает больше но даже при использовании к вот и шаг как сделать так чтобы задача с короткой задержкой получала приоритет перед batch задачей в докере строго говоря возможности приоритизации контейнеров нет и тут нам на помощь приходят различные политики планировщика центрального процессора минут давайте вспомним какие ни есть первый самый простой это shad азарт это политика которая по умолчанию получают все процессы обычные процессы пользовательские на linux машине другая политика это shad батч она специально предусмотрено для ресурсоемких процессов при размещении задачи на процессор linux scheduler вводят так называемый штраф за активацию то есть задача такая с меньшим приоритет с меньшей вероятностью получит cip унесли ее в данный момент использует про до используют и 3 3 политика это shad idol фоновый процесс не очень низким приоритетом даже ниже чем найс 19 мы используем ван него и поэтому таким способом можно поставить на пит понравившийся вам или нужный нужную политику schedule и рование процессора но даже если вы начала не программируете то то же самое можно на самом деле суть сделать с помощью команда черта данная команда точно также поставит idol на указанный и таким образом что мы получаем для того чтобы сделать нужные нам уровни изоляции мы делаем так для prado используем квоту пишет азарт ставим на выполняемую задачу для batch цепью шерсть и shad batch в качестве политики регулирования процессора для idol тоже супер шерсть и неджат idol соответственно вам может здесь понадобится capacities из нас если вы делаете что рты изнутри контейнера потому что по дефолту докер этот capacity отнимает когда запускает контейнер ну задача потребляют не только цепью на не только центральный процессор но и трафик который влияет на лэтэн сетевой задачи еще даже больше чем неправильное распределение центрального процессора поэтому мы естественно хотим получить точно такую же картинку и для трафика то есть когда вот задача отсылает какие-то пакеты сеть они должны получить приоритет перед batch задачами которые тоже хотят что-то отсылать сеть но они могут немножко подождать как это сделать docker ран кто знает это не делается в докера и здесь нам на помощь приходит linux traffic control это встроенная система приоритизации мы кто отменит тот знает чудную команду тисе китае для управления полетел сервис в линуксе попробовав всякие разные дисциплины этого traffic control а мы в итоге смогли добиться такого результата какой нам нужен с помощью вот этой дисциплины и рачек of our service куры и 4s с ее помощью мы выделяем два класса трафика 1 проц высоко приоритетной и другой матч idol канал да и они проходят чем по-разному приоритизирует a traffic control но есть одна сложность мы хотим приоритизировать как исходящий трафик так и входящий админы знают что тисе служит для приоритизации только исходящего трафика правильно а как входящие перетягивать для этого мы используем драйвер и vb который там внутри кинула где-то заворачивает входящий трафик в в исходящие внутри первого да и таким образом все дисциплины которые вы трафик контроля указали вы вешаете на интерфейс и в b0 и они работают точно так же как и для входящего трафика к сожалению вот прямо так прямо вот линуксом хороших результатов мы достичь не удалось потому что нам нужно для не приоритетного трафика устанавливать динамически полосу пропускания то есть сколько мы мегабит в этот не приоритеты трафика хотим давать в линуксе нет такой возможности по умолчанию поэтому пришлось делать специальный костыли который замеряет средние среднее потребление трафика пруд задачами отнимая и отнимает берёт остаток отдает в batch найду задачи таким образом у нас есть 3 класса задач просьба чай дал и эти задачи сильно влияют на характеристики как эти задачи исполняются и поэтому мы решили поместить этот признак очень хорошо его поместить наверх иерархии чтобы мы сразу глядя на имя иерархической очереди четко понимали с чем мы имеем дело с продам сба чем или сайт idol задачей таким образом весь наш продакшен фронты они идут под пруд в иерархии под batch идет допустим задача music каталог которая занимается периодическим составлением музыкального каталога из набора на загруженных файлов в одноклассники и подобным примером айдол задача может служить медик трансформер который занимается нормализации музыки dataset задача просто нормализовать уровень громкости ну естественно мы добавляем в имя эротические очереди эту характеристику и глядя на имя четко понимаем где у нас про делаешь расчетная задача агафонова и неважно все хорошо все замечательно но есть одна горькая правда полностью изолировать задачи работающие на одной машине невозможно чего нам удалось добиться если у нас матч потребляет супу интенсивно только циpкa то при этом планировщик очень встроенной проведу планировщик linux хочет хорошо справляется со своей задачей и влияния на продакшн контейнер практически нет никакого но если этот эта задача начинает еще работать с памятью то есть не только с процессором то возникает взаимное влияние 1 возникает из-за того что вымывается кэше 1 2 3 уровня у циpкa вымываются они собственно под задачи c пусть она работает для прок задачи медленнее в нашей практике где-то плюс 10 процентов к задержке вот такая batch задача может дать рот контейнер трафик еще сложнее изолировать потому что есть такая штука как внутренняя очень ли сетевой карты ну если пакет попал в хорватию очередь уже сетевой карты тасс вынуть его оттуда уже практически никак не возможно он попал знать что он и первым попадет в wine на в провод на этот ничего не никак не поделать 2 и 2 минус что таким способом можно приоритизировать только тисе пи трафик youtybe вообще никак не приоритизировать но и для тисе пи трафика если у вас есть какой-то бать задача которые очень много в итоге посылает данных посетили принимает то это тоже в нашей практике дает где-то около десяти процентов плюсом еще плюсом к задержке процесса дачи с изоляцией и мы закончили теперь давайте поговорим о отказоустойчивости давайте начнем с простого отказ контейнером например как какой может быть отказ ну например какой нибудь разработчик написал какой-нибудь код в прод контейнеры и у нас был такой случаем настолько сложная была логика что он сам там запутался и в итоге получилось так что она просто зацикли валось просто зациклилась да и все прут задачам зацикливается поскольку она более приоритетно начинает выжрать все больше и больше циpкa и здесь на хорошо спасает изоляция а точнее квота на ресурсы задача выделена квота она не смогла потребить больше чем ей выделено соответственно batch и другие прот задачи которые работали на той же машине ничего не заметили отлично вторая проблема которая может быть это просто крыш да естественно спасают ну понятно политики рестарта все их знают докер сам прекрасно справляется практически все под задачи имеют политику и startale life иногда мы используем moon sailor для матч задачей или отладки прот контейнеров но он практически никогда не используем ну а теперь давайте посмотрим посмотрим что забрались контейнер перейдём на более большой масштаб что мы можем сделать при недоступности миньона целиком что можно сделать кто знает перезагрузить миньону лама что вздох совсем разместить ее на другой машине на самом деле перенести то есть мы берем к ты не переносишь миллион это вы меня переносить можно двумя способами мы можем его перенести с замены api адреса по у него есть офис дом контейнера либо другое 5 взять либо сделать а пеппе в контейнер замена и опиаты совсем очень сложно потому что для этого нужен это это требует сервис discovery без него вообще никак часто даже сервис дисководы еще требуются и вариантами где айпи следует за контейнером тоже на это зависит от дина динамики выделения этих api days of discovery в принципе ну чего это удобно на удобно удобно на рынке много решений разной степени отказоустойчивости для этого дела часто в сервис discovery еще вставляется логика с балансировщик амга лессировки нагрузки и так далее но давайте подумаем нужен длина как одноклассников сервис discovery балансировку нас уже и так очень много всяких кратных и работают они отлично хорошо да вот сервис discovery это означает вот какой-то критически еще одной системы которые используются всем продакшеном и соответственно это какая то возможно . отказа нужно очень внимательно выбирать вот это самое решение не каждая подойдет то нужно выбирать то которое очень отказывал стоящего и третий минус большое это то что во всей нашей инфраструктуре для того чтобы старая инфраструктура работала снова инфраструктурой нам бы пришлось переписать абсолютно все эти задачи под то чтобы они использовали какую-то сервис дисковой системы это очень много работы а местами это даже невозможно потому что это какие-то очень низкоуровневые штуки которые работают на уровне 1 и прямо непосредственно с железом у нас часть балансировщик of работает прямо с железом поэтому очень сложно для нас это был не вариант и мы решили что мы будем не будем требовать сервис discovery как мы это сделали у нас вариант айпи следует за контейнером то есть у каждого экземпляра задачи есть свой собственный айпи адрес и он закрепляется за этим экземпляром в момент первой отправки сервиса в облака как только создается сервис ему сразу же выписываются адреса и выписывается столько адресов сколько максимальное количество реплик было у этого сервиса за всю историю его существования дальше эти адреса никак не изменяются они выписаны единожды и продолжают существовать все время жизни этого сервиса в продакшн и эти адреса айпи адреса следуют за контейнерами по сети то есть если контейнер переносится на троем миньон то и адрес перейдет за ним мы даже добились такого варианта что даже если один из миньонов потерял управление полностью на нем все еще работает это зарезервировано 5 5 100 перед папину и переносе этого и питается тот отключается и весь трафик направляется уже на новый вариант и тогда для того чтобы узнать вот такой mapping не между именем собственно сервиса и списком его айпи адресов давайте на него внимать он такой довольно статический получился он никогда не меняется практически очень редко менять поэтому его посмотрим на что похоже вот такое имя вот the dns правильно мы решили что это будет dns причем этот dns возвращает айпи адреса всех контейнеров неважно живые они мертвые много реплик сейчас иную допустим используется три реплики да у нас там 5 адресов зарезервировано все пять будут возвращаться дальше клиенты которые получают эту информацию они сами фильтруют этот жив этот мертв и тот жив этот мир им для этого да и нас и сервис discovery не нужно более того это открывает нам возможности в критических сервисах тех когда от которых зависит функционирует всего портала вообще не используя dns и просто забивать в конфигурацию и пи адреса с миньонами разобрались переходим нам нужно что-то покрупнее давайте теперь поговорим об авариях мелкие отказы все все системы управления это центрами отрабатывают приемы мы всегда были в контейнер этом норм практически везде давайте по расходам как мы отрабатываем аварию то есть отказ множество серверов сразу например при откате питания в одном или более залов дата центра что же значит авария для системы управления дата центра в первую очередь это массированный единовременный отказ множество машин и это означает что системе управления нужно мигрировать очень много контейнеров единовременно с одной стороны с другой стороны масштаб аварии может быть таким что до такой степени что задача не смогут быть перри размещены на других контейнеров потому что емкость дата-центра падает ниже 100 процентов номинальной нагрузке нет машинка способных запустить все задачи которые вы хотите часто аварии сопровождаются отказом и управляющего слоя так как из-за выхода из строя его это может быть как из-за выхода из строя его оборудование но чаще из-за того что аварии не тестируется и управляющий слой складывается от возросший на него нагрузки просто сам также это сопровождается количеством жутким количество молекул в мониторинге тормозами ваших мониторов баба солистов и так далее так далее что делает работа администратор еще сложнее обычно план по ликвидации аварии не очень эффективный нам давайте разберемся что мы можем сделать с этими проблемами массовые миграции означает что в инфраструктуре возникает большое количество действий миграций и размещение которые должны произойти каждая из миграции может занимать какое-то время например на доставку имиджей на запуск контейнеров и так далее поэтому нам хочется чтобы более важные задачи запускались бы быстрее чем менее важный давайте посмотрим на нашу иерархию какие задачи мы бы в первую очередь хотели бы разместить конечно быстрее мы хотим выпустить те процессы которые участвуют непосредственно в обработке запусков запросов пользователей то есть для проб для того для этого для того чтобы это выразить мы используем такую штуку как приоритет размещения это число которое может быть назначено очереди чем выше приоритет очереди тем первей отрабатывается размещение миграция этих сервисов этих этой очереди это решается просто вот так мы назначаем приоритеты на пруд повыше чтобы он шёл первым чуть пониже на оба чего миграция пойдет сразу после продано еще ниже на idol как видно эти приоритеты применяются иерархически у всех задач ниже по ираке будет соответствующий приоритет внутри же prada мы хотим чтобы крыши запускались перед фронтами и мы это можем сделать назначив вот такие приоритеты на кэш и на фронт под очереди среди же фронтов мы конечно хотим сначала запустить основной портал поэтому для фронтов музыки ставим совсем низкий приоритет следующая проблема это нехватка ресурсов и так у нас отказала большое количество оборудования тела из зала дата центра а мы по на запускали сервисов только столько что теперь на них на всех не хватает ресурсов то есть мы должны решить какими задачами можно пожертвовать для того чтобы работали основные критичные сервисы давайте посмотрим под этим углом на нашу и россию и лишим что должно работать а что нет в отличие от паритета размещения мы не можем огульно пожертвовать всеми базе задачами которые и диктор из них просто важны для функционирования портал поэтому мы выдели отдельно приоритет вычисления задачи при размещении задача с более высоким приоритетом может вытеснить то есть остановить задачу с более низким приоритетом если для нее нет свободного миньоны при этом задача от с низким приоритетом с большей долей вероятности так и останутся не размещенными то есть для нее больше не будет свободного миньона при этом задачи с низким приоритетом с большой долей вероятности для нашей раки очень просто указать трети от вытеснения такой чтобы рот задачи вытесняли или останавливали idol задачи но нет друг дружку также мы можем просто указать что функцией музыке мы можем пожертвовать остановить и если нам не хватает issues of для основного веб-портал с авариями разобрались давайте нам нужно больше переходим уговорить дата-центра целиком почему может отказать весь дата-центр в стихе был хороший пост от компании do the line на хабре на русском языке почитайте как ураган повлиял на работу дата-центра кроме того стихии можем можно считать еще и допустим бомжей которые спалили как-то раз в коллекторе оптику и дата-центра ваши устроен человеческий фактор конечно является причиной оператор может выбрать такую команду что весь дата-центр пойдет баги тоже все делают баги баги бывают большие и маленькие из-за больших падают дата центра и дата-центры падают это это это не редкость да они падают у нас на самом деле где-то раз в несколько месяцев давайте посмотрим что мы делаем для того чтобы никто вот такие то не в twitter не постил что же мы делаем в этом случае первая стратегия это конечно изоляция мы изолируем instance иван клала таким образом что максимально чем она может управлять это машинами кровно 1 дата-центра то есть потеря облака из-за багов чего угодно не про не команде оператора это потеря ровно 1 дата центра при этом наше предложение сейчас уже готовы к потере дата-центра у них есть определенно политика резервирование что из реплики приложение размещаются во всех дата-центров мы используем отказоустойчивой базы данных и мы периодически проводим тестирование отказов учения по поведению в авариях соответственно 64 до центра соответственно у нас четыре отдельных ничем независимых полностью изолированных экземпляра long love это такой способ помогает в первую очередь от физического отказа может помочь от ошибки оператора давайте подсос что еще можно сделать с ошибками оператора тут интересная концепция у нас есть проверка адекватности операторы до давая команду облаку допустим вот какую то такую оператор может внезапно получить вот такой вопрос и его попросят решить небольшую задачку чтобы проверить насколько хорошо он подумал на самом деле вот такая такой вопрос задается не всегда а только при потенциально опасных командах например это какой-то массовый останов многих реплик на или это может быть при каких-то странных командах например странная команда это уменьшение количества реплик обычно люди их увеличивают или смена имени образа которую нужно за деплоить обычно люди все-таки так меняют а образ нет тогда у него попросят такую штуку ушу проверить насколько он адекватен и так чему же мы пришли в итоге помните эту красивую радующую сердца архитектора картинку естественно так не получилось что получилось вместо трех квадратиков пришлось еще впилить туда три костыли к часть функциональности оказалось не поддерживается докером соответственно в любом случае надо выполнять некоторые операции команда ценились ядром напрямую плюс изменение в ад и докера часто бывают без обратной совместимости поэтому мы решили сделать то реализовать как можно больше функций без участия докера совсем и вызывать необходимой команды операционной системы сами соответственно для докером и в доке ли мы используем очень маленький набор команд вот это все что мы там используем у нас естественно есть свой registry все помнят чудное чудное мгновение когда докер view сложился да и половины интернета не могла деплоить свои классные контейнер и вся соответственно вот такие блокируем дефолтные регистре добавляю свой который просто 3 ст и и внутри компании в стоковом докере такого нет но это есть в centos варианте докером больше о боли можно почитать на русском языке вот был неплохой перевода переводной пост от сбер тех а по-моему и 2 вторая ссылка на английском языке от spotify я тоже достаточно интересно они очень много дочери используют вот суть своей болью они делятся и так это последний слайд презентации что мы узнали у нас есть иерархия сервисов которые однозначно позволяет очень быстро узнать что это за сервис чему он относится и как он работает мы используем свою технику совмещение про ты batch задач на миньонов для того чтобы повысить утилизацию машин мы используем мы не используется paused вместо этого мы используем квоты шер и и политики регулирования усилия полностью изолировать контейнеры так и не получилось у нас очень хорошо отрабатывают отказы да и с помощью графического а придя с помощью иерархического организации сервиса в ираке мы можем очень эффективно и быстро реагировать на аварий спасибо"
}