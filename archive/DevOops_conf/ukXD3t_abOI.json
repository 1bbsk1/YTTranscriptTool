{
  "video_id": "ukXD3t_abOI",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Привет друзья рад вас всех приветствовать этом зале Надеюсь все успели покушать пообедать А мы с вами будем продолжать сегодня программу докладом от Гриши Кошелева и перформанс вообще Гришу на Многие знают как большого и главного эксперта по Кафки сегодня нам рассказывает много непривычно него тему как ты выбрал такую тему для докладов Ну слушай на самом деле вот предложение нужно содержало ответ потому что Кафка кавка на эта штука которая почти все сразу делает хайлоудом и там идет слово перформанса например синоним слова Кафка Вот так оно получилось довольно нативное но этот вопрос о том как пришли к тому что Вода вот как там перформанс А вот почему вот Хороший вопрос как раз сегодня я попытаюсь ответить на главный пожалуй вопрос почему все-таки перформанс Я знаю у тебя очень много контента для нас поэтому не буду задерживать будем переходить к основной Единственное что напомню про qr-код для наших зрителей в онлайне его плане тоже где можно перейти в Telegram канал и задать вопрос в конце доклада всего лишь перед третье слово да спасибо большое спасибо Сергей перформанс или когда производительность имеет значение так вот как я уже говорил вот мы здание обсуждали о том что там многом занимались Кафка и капка у нас была не случайно Дело в том что я на протяжении нескольких лет делал на платформу для обработки данных телеметрии там кавка в основе все дела Вот сейчас там через эту систему уходит порядка там 10 миллионов событий в секунду это куча всякая разная телеметрии но сам факт о том что большая нагрузка высокая нагруженный сервисы и так или иначе ну условия заставляют себя думать про перформанс Ну вот если подумать А вообще когда среди инженеров вдруг будет важен ответить на этот вопрос то можно например вспомнить Вот такое выступление Алексей шепелёва в 2017 году на джипоньте который говорит следующее это вот критерий успеха проектов разработки и она вообще производительность где-то на пятом месте что-то такое незначительное Или даже вот написано а чаще всего производительность про performance И вообще даже в критериях успеха нет звучит как-то обидно наверное вот если Те кто не согласен с этим утверждением Да спасибо вам большое вот действительности Может быть так получится что может быть пользователи то и хотят этот самый перформансы производительность но и тогда конечно можно поговорить про село потому что вроде бы как раз там где-то что-то подобное может быть и там если мы обратимся к первоисточникам сырье сырье Book там четвертая глава она прям так и называется село и в целом там про это тоже что-то есть вот на самом деле про село завтра будет рассказывать как раздания которые сегодня сейчас выходил на сцену очень крутой доклад поэтому очень рекомендую посмотреть То есть я не буду вдаваться в детали слов это вот как раз на эти вопросы ответить Даня но в действительности судьи инженер еще важна работа с рисками когда вдруг что-то сломается и в принципе вы среди букв там целая глава посвященная принятию рисков Ну естественно работу с ними 3 это про емкость системы То есть если у нас тоже можно сослаться на среде Бог 21 глава она суть в чем что если вдруг у нас системе случится перегруз Ну как бы не хорошо то есть нужно уметь как-то вовремя момент понять Как это понять нужно вычислить кпсис системы и благодаря этому настроить троттлинг вот как бы такая идея в целом вот так выглядит Вот такой список ну плюс еще можно отнести каждый доступ потому что это тоже про какую-то ёмкость про троттлинг про правильные настройки когда нагрузка становится очень большой вот мне казалось бы да вот такой полный список Возможно есть какие-то еще вещи которые ну сюда попадают но мы наверное с Вами просто уже по ходу обращаясь к практике попробуем это понять так вот смотрите то есть вот вообще может быть там из-за нагрузки случаются какие-то факапы Но это решил задать вопрос в телеграме из-за чего вообще случается факапы попросил проголосовать за последний факап есть те кто голосовал в этом вопросе о много здесь Крутяк Вот вы помогли составить правильную статистику чем из этого получить Да кстати Обратите внимание что это было 13 сентября Это был День программиста и совершенно случайно оказалось что это был сорок второй пост и получается что главный вопрос Вселенной всего прочего это вот из-за чего как раз случаются факапы так вот если мы про суммируем установку обновления изменения настроек и прочие действия напротив то мы поймем что получается 58 процентов Акапов когда прочь шатают что-то с ним делают Нижний блок это все эти инфраструктурные сбои аппаратные сбои или когда мы не понимаем что происходит это какие-то такие внешние причины Ну или то что нам неизвестно Триггер неизвестен 33 процента и все остальное мы объединим нагрузку Почему Потому что шесть в повышении нагрузки 3 процентов это запросы смерти запрос смерти не все приводят к тому что это связано как-то с нагрузкой с повышением нагрузки но так или иначе большая часть из них все-таки попадает туда так вот почему проделать вопрос не было хотелось понять А вот та статистика которая у нас есть контуре насколько она коррелирует с вами с сообществом и оказалось вот так в контуре у нас 50 процентов факапов потому что кто-то шатает прод 40 процентов это что-то такое внешнее неизвестное и вот как раз вот довольно такой существенный большой кусок пиццы нашей это вот та самая нагрузкой и 10%. Это говорит о том что прям большой же кусок пиццы правда поэтому это то вообще о чём Стоит задуматься это вот по анализам по снортону в контуре за за несколько лет как мы начали эту практику вести так вот Давайте попробуем понять из-за чего вообще нагрузка может вдруг взять и начать расти во-первых естественный путь когда просто пользователь стала больше стало больше пользователей стало больше трафика больше нагрузка вроде все логично почему еще сами тоже их упоминали понятное дело вот эти самые запросы смерти то есть пришел запрос не знаю там неправильный запрос у нас в СУБД и начались фулл сканы повышение нагрузки или вот эластик вот у кого эластики дохлят повышенной нагрузки есть кто-нибудь такие примеры ничего сколько много Ну да короче это классика жанра и Да это к сожалению периодически случается если говорить немножко про разработку То могли просто усложнить сценарий Ну представьте себе напилили какой-нибудь mvp всё классно быстро летает а потом оказалось что нужно сделать одну валидацию вторую третью сходить еще куда-то за данными обогатить их и внезапно сервис становится в 10 медленнее беда баги в коде Ну допустим мы сделали ошибку которая делает не один запрос куда-то а Несколько или такой классический пример когда на фронтенде произошло Коин зацикливание и фронтенд начинает долбить быкан своими запросами тоже довольно частая история Ну или что-нибудь связанное там не знаю со стратегией отправки что вместо того чтобы отправлять там по очереди запросы они примерно там скопом параллельно отправляются в несколько реплик Когда например вовсе не нужно или где-нибудь ошибки в настройке правил retrike такие вещи могут быть тоже относится к багам а еще может быть Вот такая вот ожидаемая в кавычках деградация кода когда просто хорошо работающий код решили по рефакторить Ну и просто явно его сделали медленнее функционально ничего не поменялось Ну просто устал медленнее одну структуру данных на другую не проверили вот всё испортилось это кажется все таки теоретически рассуждения А давайте вернёмся к по с мортам и посмотрим что же там еще может произойти кроме вот этого и оказалось внезапно что очень много причин это всякие истории с миграцией данных выгрузкой данных когда сервис работал себе работал И вдруг пришла неожиданная нагрузка от аналитиков которым захотели построить там отчеты за год например и начали выгружать огромный объём данных система оказалась к этому не готова история с плохой балансировкой сейчас попробую продемонстрировать на небольшом примере Представьте что у вас есть три дата-центра и вы поднимаете там несколько реплик Почему 5 потому что оказалось что это вполне нормальное количество для того чтобы обслуживать всю нагрузку и даже небольшой запас иметь но смотрите Представьте что нагрузка в этих до центра приходит равномерно Ну то есть она поделилась пополам пополам там А все что было пришло сюда в итоге мы имеем то что здесь нагрузка в два раза больше чем на все другие реплики явно такой дисбаланс и может быть Возможно это будет проблемы Но можно сказать что ты нас не проведёшь и мы просто сделаем одинаковое количество реплик дата-центрах и всё будет хорошо Ну а кто он сказал что нагрузка распределяется по центру равномерно она может распорядиться как-то Так что в один два центра идёт 2/3 нагрузки А в два других по одной шестой Ну и получается что также у нас делится пополам А эти оказываются в четыре раза более перегруженные чем в других центрах и как бы тут можно заметить что у нас время какие-то проблемы в третьем центре и с этим надо что-то делать Но это плохая балансировка а может быть еще в таком виде вот Представьте что тут trustore рассказываю Представьте что у нас есть сервис У него три реплики и туда идет идеально равномерный трафик но трафик идет Не вот этими http запросами Представьте что это персистентные tcp соединение что теперь системные мысли установили один раз соединение весь трафик потом будем просто в этом соединении отправлять может быть даже кто-то узнает какое-то поведение из тех сервисов с которыми они работают Теперь мы такие приходим и говорим нам надо сделать Rolling Restart например обновить версию на новую мы значит пока еще не Обновили путем обновлять первую вот эти 33 процента они должны куда-то перейти но они равномерно распределяются на других вот по 50%, ну а мы делаем систему так чтобы там любую реплику выключить всё хорошо Значит мы рассчитали так что 50% плюс небольшой запас система должна выдерживать всё должно быть классная Ну в общем вот получается реплика одна или стартанулась потом идёт вторая нагрузка распределяется распределилась вот так Теперь смотрите на одну реплику у нас уже приходит 75% всей нагрузки скорее всего она даже к этому была не готова потому что 50% ещё ладно Ну блин в полтора раза больше от этого это уже сложно Ну и вот э-э так делаем то же самое с третьей нагрузка распределяется перезапустились и вот получилось вот такая вот картина то есть вроде бы ровненько рестарт сделали а получилось так что одна реплика примерно в два раза более нагруженная чем вторая плохо Спасибо нагрузочное тестирование на проде ну здесь на самом деле примерно история такая же И вообще как как такому люди приходят почему так происходит но скажем Можно например начать с того что на локальных тачках же нагрузочные тесты они не показатель И зачем вообще их делать правда ведь правда да давайте второй шаг смотрите если мы возьмем часы подним тестовый контур такой же как на проде дорого дорого Ну и давайте сделаем третий шаг есть же еще там культура учений так вот мы сейчас нагрузку поднимем на проде это же учение учение и общем так получается что нагруженное тестирование делает начинает напротив из-за этого конечно же идет нагрузка но пока еще пока не случается наверное еще может случиться такая штука назвал три горловины как-то смотрел фильм про топчик Как появляются лавины что это такое довольно страшная вещь И вот в данном случае три горловины такой одно какой-то маленькой-маленькое действие на которое лавинообразный рост нагрузки Какой пример может быть выглядит примерно как-то так Вот такая знаменитая гифка сразу вспоминается В каком случае может что такое произойти вот смотрите если вы вдруг Выключите кэш или перезагрузите его то все запросы например пойдут сразу в базу лавинообразный рост нагрузки или Представьте что у вас данные идут через веб-сокеты и ты на пользователь постепенно подключаются устанавливает эти высокие соединения и данные между ними ходят эти Представьте Вы по какой-то причине вас сбрасываются все высокие конвекции и соответственно что всем пользователям разово нужно их установить и вас там там 200 тысяч там два миллиона пользователей и они все внезапно пойдут устанавливать веб-сокет соединение то есть проходить авторизацию там всё прочее прочее прочее то есть там система будет нагружена нормально Ну таких примеров ещё на самом деле можно много привести вот все ли Нет не все есть еще вот такая история про трансвеститные массовый ритм тут лучше на примере показать вот Представьте что есть там тоже все же любят микросервисы почему-то монолиты людей перестали устраивать какой-то момент вот очень простой пример тут есть такая цепочка Вот давайте вот так изобразим то есть из первого сервиса мы идем во второй из 2 в 3 и так далее пока вот не идем самый конец и теперь Представьте что если вдруг вот этот последний сервис Ну вот он сломался то есть он вот не работает Давайте поймём вообще вот сколько тогда будет э-э ретраев в этой теме но у нас там настроен какое-то количество R вот у нас в последнее сервис надо будет несколько раз попробовать понятно что если там дальше по цепочке мы получаем ошибку значит ретрая у нас будут здесь и здесь ну Будем считать что везде значение ретрайв одинаковое Теперь давайте поймём А сколько Вот в такой системе будет вообще вот этих вот сетевых запросов то есть сколько вот этого трафика вот смотрите всего будет их э количество этих переходов если трафик у нас нет Ну то есть вот это самое N А теперь давайте поймем А сколько их будет если все-таки вот проблемные сервисы Вот это на самом конце случился То есть получается там из первого второй будет R из второго в третий - это R умножить на R и так далее То есть вот такая вот получается формула такая вот э прогрессия вот Я вот тут по пару дней назад когда вот был здесь гостиницы решил как-то упростить эту формулу посидел короче на салфетке порисовал вот получилось получилось вот такая формула и Давайте попробуем понять ну типа формула эта формула и Давайте поймём че- к чему это приводит Ну то есть вот если ретраев нету Там типа два перехода значит два запроса три перехода три запроса четыре перехода четыре запроса всё вроде Понятно Вот теперь давайте Нарисуем для двух-трех чем можно здесь заметить что очень как-то подозрительно быстро начинают расти эти чистилки это первое количество того какая у нас вложенность этих как у нас цепочка вот эта длинная и второй момент который здесь можно отметить насколько сильно меняется количество запросов от того если нет в данном случае мы одним движением взмахом увеличили нагрузку на свой сервис 30 раз потому что вот один из них сломался нагрузка стала в 30 раз больше звучит звучит на самом деле довольно страшно и мы получили highload в сервисе в котором ты его никогда не было Но все эти истории о том что нагрузка растет пока мы еще не пришли к факапам-то А почему факап-то случается Ну и самое очевидно это то что мы попали в бутылочное горлышко Представьте Давайте его вот так такой таким графиком То есть у нас нагрузка растет и соответственно сколько мы сможем удачно обработать запросов то есть есть некоторые пределы системы Да выше которого она прыгнуть не сможет естественно у нас обработка растет и в идеальном случае мы просто на этом лимите остановимся Ну как вы понимаете что в реальных системах там что-то начинает другое происходить и вот график он не остаётся таким горизонтальным вот всё что выше соответственно но уже не обрабатывается и вот здесь уже факап то есть мы хотели обрабатывать больше а не смогли могут быть заданы неверные параметры для троттлинга причём в обе стороны то есть мы могли завысить лимиты занизить Давайте поймём Что произойдёт если мы решим зависть лимиты Ну просто троттлинг перестанет работать то есть мы никогда до троттлинг не упрёмся мы будем упираться в какой-то Вот то самое бутылочное горлышко которое было на предыдущем в предыдущем пункте А что будет если мы занизим лимиты но мы получается начнём отбрасывать раньше чем по факту мы могли бы это делать то есть мы начинаем отвечать ошибками большему числу пользователей чем по факту это должны были сделать пока против пока но утечка ресурсов это классика понятно что чем больше нагрузка тем быстрее эта утечка тем быстрее приходится Вот про плохую изоляцию здесь Прикольная история Ну как прикольно она прикольно чтобы рассказать но наверное печальная по последствиям ведь смотрите вот у вас там если допустим вы запускаете не в контейнерах там А вот на железке несколько сервисов то Вполне себе так они вот начнут конкурировать За ресурсы и собственно говоря как раз контейнер Это был как раз один из способов от этой проблемы избавиться но Представьте что вы живёте в контейнерах запускаете приложение А ну допустим Не знаю там от пользователя получает файлы Ну поскольку файл получается не сразу там временно но складывает на диск Ну так нормально даже решение сложить А когда уже получили полностью Вот это уже можно куда-нибудь там персистентное хранение отправить Вот но Представьте что у вас на одну ноду попадает два сервиса вот один вот который так очень интенсивно работает с диском а в другой хочет тоже с ним поработать но ему не достанется ресурсов вот ну и внезапно вот в kubernet висит вот эта вот таская о том что давайте добавим лимиты на ёпты Ну там и на другие тоже есть э параметры которых вроде как до сих пор До сих пор нет В общем ты такие проблемы случаются Ну если группы с такая штука поскольку реализована то в целом это можно было сделать вот по-моему там какое-то время назад У Олега настасьева был доклад когда это они как раз сделали свою систему свою регистрацию Вот они как раз Вроде вот эти истории с ограничением на йосы ограничения на скорость записи скорочтения Они вроде как решили но вот выбирают вот на Стрим на таком инструменте вроде как это нет может случиться история с конкорент ошибками но почему Потому что как раз такие конкорнт вещи не как раз как правило появляются когда большая нагрузка когда очень много всего прилетело и вот здесь вот эта вот вероятность вот этих проблем возникает Ну это просто баги с которым нужно что-то делать Вопрос такой Как вы думаете а что общего вот с первыми четырьмя пунктами Вот давайте Попробуйте накидать вариант что вот прям общее вот такое прям общее общее между ними какие есть идеи Совершенно верно закончился какой-то ресурс Давайте эту мысль сейчас запомним и мы еще обязательно к ней вернёмся так вот сам факап его можно усугубить сделать еще хуже Каким образом но могут случиться вот такие метастабильные отказы кто-нибудь слышал про метастабильные отказы статьи клево есть такие ну Давайте тогда немножко расскажу если что у меня презентации очень много всяких ссылок которые идут на разные материалы доклады и прочее поэтому можно быть оттуда взять так вот есть очень кратенько в этой статье некоторые исследования которые говорит о том что система которая вот которая присутствует метастабильные отказы в ней может быть в этой системе три состояния стабильное уязвимое и метастабильная то есть когда система находится стабильной до тех пор пока не растет нагрузка выше какого-то порога дальше система продолжает работать но может случиться какой-то Триггер который придет система в такое состояние из которого ей очень будет тяжело выбраться в нормальное То есть она уже не сможет обрабатывать те запросы которые могла обрабатывать ранее будет лучше всего это видно вот на таком графике то есть зеленая начинает расти вверх система стабильно переходит некоторую эту границу и попадает Вот это уязвимое состояние и случается Триггер например какие-нибудь ошибки до возникли и ошибки повлекли за собой допустим ретро и как помните дам рассматривали вариант огромное количество становится много их надо обрабатывать они стоят в очередь получается те запросы которые могли обработаться они находятся долго в этой очереди скорее всего это приводит к тайм-аутам тайм-ауты приводят к еще ретрайм и вот дальше все мы попали зациклились единственная состояние как вот из этого выбраться либо перезапустить систему целиком либо снизить нагрузку до такой степени что вот это вот очередь которая огромная накопилась Ну как ты протолкнуть Да побыстрее то есть какая-то вот такая история должна произойти Ну вообще как бы очень рекомендую эту статью там довольно подробно про это описывается вторая проблема которая может усугубить ситуацию Когда у нас отсутствует система раннего реагирования Ну что значит раннего когда мы узнаем о проблеме не тогда когда уже всё прям всё взорвалось всё сгорело то есть всё-таки узнали об этом как можно как можно раньше вот чем раньше узнали тем лучше ну или там какие-то у нас есть сложности в диагностики в нашей системе Ну там например с инструментацией проблемы или ещё какая-нибудь Ну давайте Вот про среагирование начнём э Какое можно сделать реагирование Ну например вот алерты по ошибкам вот кто-нибудь по ошибкам делает много да Вот я даже рассказывал на дивупсе не знаю там года два-три назад то о том как мы внедряли центре и как много ошибок совершали как над ними работали Вот Но честно этого становится не будем над второй Я даже не буду спрашивать я почти уверен что алифтинг у вас всех есть правда же у всех есть Ну так вот про него история Какая но там есть четыре золотых сигнала как бы все все вроде Понятно Вот для того чтобы запомнить Тесла Как быстро запомнить о том вот эти четыре золотых сигнала трафикса трещинси Давайте попробуем ответить на такой вопрос а вот что скорее всего не подходит под ранее реагирования Вот кто Кто думает что Вот давайте какие варианты вот четыре варианта Кто думает что прямо уверен что вот эта штука не подходит для раннего реагирования ошибки не подходят Почему ошибки не подходят Ну да всю верность уже все сломалось как бы ну все это уже не ранее реагирование Вот уже и так понятно что всё сломано так ну смотрите Давайте помимо трафик подходит или нет но трафик в действительности вот убил трафик это не ранее реагирую Но типа у нас действительно допустим в системе там ночью мало Трафика днем много трафика ведь не надо же сразу бежать и реагировать на то что он в нём просто выше нагрузка Чем ночью правильно Поэтому надо скорее вспомогательный инструмент то есть мы можем как-то покоцанный признакам понять о том что Да вот тут могут быть какая-то проблема связанные с трафиком вот в целом у этой наверное да мог бы ответить на этот вопрос и наверное тут можно было ещё раз сказать про село потому что например вот эти метрики могут там оказаться Ну давайте примеру разберём вот Представьте что у нас вот э идёт время и вот этот типа потихонечку растёт и вот можем ввести Вот таких два порога э верхние и нижний то есть верхний это факап случился а Нижний что мы начинаем беспокоиться и таким образом смотрите от момента когда случилась э первая Ну первое первое превышение вот этого жёлтенького А у нас есть ещё какой-то запас времени чтобы добежать до э до компьютера и начать разбираться Да и Ну и починить эту проблему вот это вот уже близко к раннему реагированию Но есть же еще у нас сатурация то есть насыщение А теперь давайте смотрите мы запомнили о том что какой-то ресурс нас предыдущий Да закончился Ну и Давайте помимо какие у нас вообще ограниченные ресурсы могут быть Вот я выделяю здесь 5 таких базовых ресурсов которые Маст хэв для мониторинга CPU там соответственно предел чего может достигнуть там чистоты То есть просто не можем ядро мощности ядра нам закончились и больше не получить там Соответственно какой-то масштабирование по количеству ядер Это вроде тоже понятно про память там это в первую очередь объем памяти понятно что можно и опереться и скорость наверное работает памяти но я к сожалению таких сервисов так к сожалению таких сервисов не встречал Где упираясь бы именно скорость работы памяти обычно всё-таки объём дисковой То есть те самые как я уже говорил там скорость записи чтения опции и Внезапный объём диска диск тоже может закончиться И это тоже стоит мониторить четвертый ресурс - это сеть Ну и тут два важных параметры это пропускная способность и латентной сети могут закончиться и печники да спасибо так вот но смотрите это 4 таких системных ресурса базовых которые могут быть есть еще такое которое назвал условно runtime и туда соответственно все что касается нашего runtime нашего приложения Ну то есть там это блокировки какие-нибудь классические Гил в питоне это всякий тредпулы сборщик мусора Connection Pull это Например базе там да закончились коннекции базе Ну и всё приехали Ну утечки памяти тоже с вами сегодня смотрели и вот троттлинг запросов которые как один из механизмов Да работа с этим То есть тоже его естественно надо мониторить что если мы упираемся в троттлинг или вот уже близко-близко подходим к его границе вот нужно с этим что-то делать по поводу первых четырех системных ресурсов я тут Наверное сделаю отсылку бренду грегу потому что он лучше его наверное никто про это не расскажет про инструменты которые используются Ну и вообще как понять что вот те или иные метрики вообще означает поэтому очень рекомендую Именно его блок его доклады Ну и тут даже можно понять что очень-очень много всего есть на эту тему вот поэтому просто двинуть дальше и поговорил про диагностику наверное самый такой удачный способ диагностировать в распыленных системах это использование внезапно распределенных трассировок вот тоже у меня был доклад вот это как раз было благо указан год в прошлом году рассказал о том как мы еще могли бы использовать трассировки я не буду пересказывать есть доклад расскажу просто вот одну такую историю которая прямо ну яркая демонстрирует мощи распыленных трассировок вот Это пример такой трассировки там несколько сетевых запросов вот ну и если мы такие зададимся вопросом а что нужно бежать в первую очередь оптимизировать Ну видимо то самое длинная вот то что А ну ещё вот C Да тоже похоже на какой-то длинный возможно делать но тем не менее Вот есть такой метод метод критического пути - Это история пришла из теории управления проектами Ну если кратко то история такая что в него входят какие-то вот части так вот если вот какая-то исходящих туда частей изменится уменьшится увеличится вероятнее всего это повлечет на изменение времени выполнения всего проекта ну и соответственно то же самое переходя на трассировки если какую-то штуку поменяем скорее всего это отразится на времени выполнения всей трассировки вот ну таким образом можно сейчас понять сколько процентов каждый дает вклад Ну и Да тут первым сервисом там все было понятно он совсем был какой-то грустный по времени но внезапно оказалось что сервис B сервис они одинаковые вкладываются соответственно Когда вы принимаете решение куда идти оптимизировать Где искать проблему Ну в целом они в данном случае равносильно оказались Вот такая способ как куда идти и оптимизировать вот здесь я ещё бы сделал бы ссылку на статью ребят из Гугла Она вышла совсем недавно это прошлый год статья очень большая Там по-моему на 40 что ли страниц Вот они называют вот такой подход к анализу как критика ЛПС рейтинг вот поэтому очень рекомендую если вот интересно как вообще можно это использовать и соответственно диагностировать проблема в распределенных системах Давайте Так расплюнуть трассировки это хорошо но ведь распределенность рок может не быть Вот кто использует распределённые трассировки своих проектах Ну вот надо план Б короче иметь Давайте поймём что же в этой ситуации делать что нас спасёт что спасёт что спасти может если у нас трассировки нет логи логи могут Спасти ну логи да Но наверное сутки метрики потому что их много мы там вот Брендон Грег научил нас и хорошо делать Вот ну наверное Метрика от них недостаточно и нужно начать какие-то делать штуки типа не знаю там под перформанс тестирования вроде классная тема и Давайте попробуем про не немножко поговорить вот когда изучала паспортами то я увидел такую повторяющуюся картину то что довольно часто встречается по спортумах я не скажу что это случается в каждом втором ну это прямо то что бросилось глаза Первое это то что внезапно нагрузочно тестирование Но просто в проекте еще нет например Это какой-то Богом забытое Legacy когда еще культура нагруженном тестирования у нас в компании существовала либо это какие-то nvp ну типа Кто такой будет тратить время на нагруженном тестировании mvp это же mvp там руководитель же не даст потратить ресурсы поэтому такое происходит а второе внезапное когда нагрузочное тестирование было когда-то давно или статуре вот кто увидел в тем что делали нагрузочную тестирование статуре есть вот такие о май Бро так вот это действительно классическая проблема то есть вроде бы мы нагружен тестирование провели зачем его постоянно проводить И вообще Какие тут могут быть проблемы здесь я сделаю еще одну отсылку Я как Википедия ссылаюсь сам на себя вот как не был доклад на последнем баги это вот весной этого года было про то как не надо проводить нагрузочное тестирование опять же не буду весь пересказ от доклада делать Я лишь расскажу про виды грифонов тестирования Ну и про то когда один вид нужно использовать когда не стоит вообще какие проблемы здесь могут быть вот у нас есть есть у нас наша система на которой мы подаем какую-то нагрузку либо нагрузки нет либо она куда там бесконечность уходит где-то у нас здесь находится емкость системы мы пока ещё не знаем где съёмкость находится вот в действительности ведь емкость системы Это не какой-то такое число какое-то конкретное скорее всего это какой-то вот такой вот интервальчик вот кто может кстати объяснить почему этот интервал Почему нельзя говорить о том что это какая-то прямо конкретно чистилка там не знаю 100 rps Почему скорее всего это не стоит а какой-то интервал вот есть идеи Давайте я повторю для всех что допустим запросы у нас могут быть с разным пейлордом то есть размер поменьше размер побольше и получается что какой-то точное значение выработать сложно это хорошее тоже версия но смотрите ведь система в которой у нас запущена она не замкнутая А если система не замкнутая существует какие-то Внешние факторы которые могут быть маленькое влияние или большое влияние и получается что раз мы имеем систему с большим количеством случайных величин ты как соответственно в статистике мы оперируем не конкретными числами А мы оперируем доверительными интервалами вот поэтому мы вот и живем в таком доверительном интервале Ой что-то я перескочил резко вот так получается что у нас э-э некоторые доверительный интервал за этого так вот э-э поэтому первое тестирование которое нужно сделать и оно называется тестирование масштабированности Ну или сколотить китайский иностранной литературе это о том что вот как раз найти вот эту вот границу то есть мы начинаем с какого-то значения и начинаем потихонечку расти нагрузка у нас растёт растёт пока мы не видели что вот всё вот система насытилась вот мы упирались Какое значение но оно называется внезапно автомобилитицу какой-то масштабирование то есть мы Ну емкости дальше то что а история о том что А теперь мы берем и увеличиваем нашу систему вдвое поставили не одну реплику а две и посмотрим произойдет ли двукратный рост нагрузки то еще вот такую нагрузку дадим и посмотрим что будет дальше то есть благодаря этому мы сможем По экстраполировать А как система ведет себя примасштабировании Ну очевидно там ну прям увеличить в два раза ресурсы стала в два раза быстрее это фантастика такое не бывает вот поэтому там какой-то коэффициент и Вот его можно будет рассчитать и там не знаю по трём например точкам Да провести там экстраполировать и в принципе понимать как даже система себя будет вести ну самое главное задача вот этого осколобили тестирования о том что всё-таки понять вот эту ёмкость системы и как система себя будет дальше вести при дальнейшем масштабировании вот а теперь вот то самое нагрузочное тестирование которое часто путают со сколабилити тестирования другим тестированием она о том чтобы давать не максимально какую-то возможную нагрузку а какую-то такую разумную нагрузку ну скажем там 80%, да от ёмкости системы мы такую нагрузку даём в течение какого-то времени и смотрим о том что система не деградирует о том что запросы выполняются так как ожидается и здесь например можно сослаться на slo что поведение системы в рамках Ну типа тех требований которые мы к этой системе предъявляем стресс тестирования но тут понятно Что нужно чтобы система находилась каком-то таком плохом состоянии суть в чем что мы проверяем что система продолжает чувствовать себя нормально то есть не развалится под большой нагрузкой То есть у неё может быть какая-то небольшая деградация должна быть предсказуема должны понимать какая то есть мы даем какую-то большую нагрузку вот ее даем большую но не сразу прямо огромную А вот постепенно постепенно постепенно постепенно растет в плане Похоже как на сколобилити тестирование на сколобили тестирование но важно было найти просто вот эту ёмкость и остановиться А здесь мы продолжаем идти дальше в общем какой-то большой нагрузку Даем и смотрим как система себя ведет и может быть еще вот такая история что Ну про не перепутать это вот важный момент что вот про большую нагрузку ведь она может возникать спонтанно не то что она постепенно постепенно росла и сразу резко в системе стала огромная нагрузка как это будет выглядеть тестирование мы даем такой же нагрузочное тестирование как вот привычно нагрузочно и раз моментально даем какую-то нагрузку прям сильно превосходящую емкость системы Вот и соответственно проверяем что система возвращается в то состояние в котором она была до всплеска нагрузки то есть мы дали резко большую нагрузку потом вернулись обратно в нормальное состояние и смотрим Что метрики системы вернулись норму Вот Но это все-таки кратковременные тесты то есть мы нагрузили быстро далее вернулись обратно посмотреть что все хорошо вот есть еще такой вид тестирования тестирования на выносливость это когда мы вот эту нагрузку даем в течение долгого долгого долгого времени Вот как раз например на таких тестах можно увидеть утечки ресурсов но Чем дольше мы систему гоняем тем вероятность того что мы увидим она будет больше естественно там эндорас тесты могут длиться например там неделю и даже больше некоторые баги они например могут появляться спустя там э-э месячные например Вот кстати еще вот это вот тесты в литературе называются сок тесты или тесты вымачивания или замачиванием то есть вот так вот вымачиваете вымачиваете ну и смотрите Не развалится всё когда она долго замачивается вот эта система так вот история Понятно про различные батлэки которые проявляются не сразу Кстати какой Battle nake вот можно только с ходу сказать который Прямо хорошо таким тестом провериться вот кэш смотрите у нас потихоньку заполняется заполняется Что будет если прям конечно заполнится и скорее всего одномоментно кратковременной нагрузке мы его не заполним поэтому надо дать нагрузочку так вот подольше Вот как раз такой тоже классический пример Окей полем тесты или объемное тестирование смотрите Обычно когда мы делаем нагрузочное тестирование То есть у нас есть также Вот какая-то небольшая нагрузка как небольшая 80 процентов от емкости например там 70 но эти данные которые у нас системе живут небольшие тестовые данные вот маленький корпус данных Но в продакшне то нас данные этого такие как правило правда ведь и хорошо бы соответственно нам понимаете как система будет себя чувствовать когда мы отсюда перейдем туда и вот как раз вот эти вот узкие места связанные с базой то есть всевозможные индексы сложные запросы в базу Они как раз благодаря этому будут скрыты то есть мы на маленьком объёме процитировали на Большом и посмотрели А вообще будет деградация не будет система Вот и вот важный момент про который хотела сказать Вот когда я напряжение долгого времени наблюдал тот код который писали Ребята в команде я вот увидел что на кудривью очень много приходится Ну возвращать в доработки исходя из того что код прям стал хуже по перформансу А как я напомню там система в которой там миллионы событий ходили то есть надо прям скажем так деградация в одном месте она могла привести к тому что количество ресурсов требуемое для работы системы стало значительно вот и ну одна из решений одно из решений которая пришло в голову А давайте те дизайн доки которые мы пишем будем сразу пополнять истории про перформанс и как это было выглядит в дизайн док ты прям пишешь ответ на вопрос как на систему скажете твоё решение в плане производительности Если ты не уверен как оно будет работать Окей сделает концепт ну и соответственно Проверь на нём там нагрузочное тестирование проведи там микро-мар бенчмарки про бенчмарки Мы ещё немножко с вами поговорим вот поскольку основной стек у меня Java то немножко расскажу про инструменты очень кратенько Ну и понятно что если вы там какой-то другой стек там питон Go или какой-то другой В целом то инструмент у вас похожий но мне как-то даже можно будет переиспользовать вот на самом 1 такой это вот Джей тач от Андрея пангина который позволяет там сразу получать хип-дам по три дампы получается статистику классов вот грубо говоря это Суть в том что вот у нас продакшн система работает вот мы можем видеть что она нестабильном состоянии вот в этот момент мы можем сделать слепок системы и посмотреть что в каком он состоянии находится далее история про активная профилирование когда мы прям строим информацию о том как система работает вот допустим нагрузочным тестом То есть можно посмотреть где больше всего времени проводит наш CPU то есть на какие методы тратятся ресурсы вот профайлеры существуют великое множество вот для Java мы используем такой Там в других местах Это станет свои инструменты для тестирования каких-то отдельных участков кода используется Java микробенчмар харнес очень классная штука важно тоже не перепутать где ее использовать и Какие задачи при помощи не решать вот еще вот история я говорил про утечки ресурсов частотой утечки памяти вот здесь тоже классный инструмент мемориал лазерту ту или eclipsmad вот на нём здесь могу сослаться на доклад который был внезапно 2015 году Никита Сальников тарновский рассказывал про то где память где память Вот как раз и в том числе рассказывал про клипсы поэтому рекомендую если вот вы так или иначе Работаете С Джава стеком Ну поскольку многие поднимали руки когда речь была про эластик но видимо у многих он есть но javastec так или иначе в том или ином виде вот ну инструменты нагрузочного тестирования гетлинг джеметер Это вроде Понятно но инструментов много вопрос типа как начать использовать вот здесь хорошо бы тоже как поскольку мы все инженеры то давайте также Инженерный подход применять к таким задачам к оптимизациям Ну и к диагностике и поиску проблем вот здесь я ещё раз хочу сослаться на доклад Алексей шепелёва и перевести кривую его имени вот суть её в чём Что мы находимся зачастую с вами где-то здесь то есть у нас вот начались какой-то код скорее всего не самые классные написанные особенно когда после mvp то есть вот они сделали вряд ли мы заботились о красоте и чистоте кода так вот и идея вот этого вот этой кривой и соответственно здесь доклада Алексея что мы вот постепенно можем двигаться отсюда сюда и э улучшая наш код просто дело его качественнее растёт производительность не уменьшается сложность растет производительность вот мы доходим до вот этой точки Ну и дальше попадаем следующую зону в которой нам как раз уже нужны Более точные инструменты и более качественная работа и скажем так скрупулезная работа то есть там понадобится там хороший профайлер хороший инструмент для микро бенчмаркинга ну и соответственно эти инструменты Мы тоже должны правильно уметь использовать в этой ситуации вот кажется что вот даже вот такое движение уже большой плюс К тому как как сделать свой софт лучше Ну давайте посмотрим У нас есть какая-то архитектура А как начать использовать все вот эти наши инструменты у нас там есть штуки которые там не знаю хип-дампы профайлеры прочее вот смотрите инструменты для нагруженного тестирования типа Гатлинг джимметр они подходят в целом для тестирования всей системы целиком Вот и таким образом мы можем понять вообще там по метрикам дальнейшем или там те же трассировка вообще где какие-то узкие места у нас есть вот если нам стало интересно какой-то отдельный компонент мы можем также при помощи инструментов нагрузочное тестирование тестировать отдельно их на микросервисы там отдельно кунте очередь или базу в этом плане мы можем тоже получается какие-то отдельные компоненты проверить тем же самым инструментом вот если мы уже поняли что нам интересно вот это я например хотим не знаю там поработать с штукой по плане там поиска утечек памяти вот пожалуйста Там сняли хип-дамп получили получили получили дампы пошли его анализировать но смотрите вот игру сервисы Но предполагаем что не написано вот все дела Но в действительности если у вас какая-нибудь Кассандра находится то это тоже javastec И там ластик и ничего не мешает вам эти же инструменты начать использовать и решать при помощи них свои задачи но тоже самое с профилированием при этом профилированием также можете использовать для любого приложения написанного на javastek и Ну или какого-то другого стакана туда должна что при помощи профайлера Вы можете тестировать там целый компонент проверять профилировать целый компонент так и можете какой-то отдельный кусочек вашего сервиса вот там Если захотите использовать бенчмарки пожалуйста не делайте для всей системы целиком все-таки микро бенчмарк предполагает что вы тестируете какой-то маленький кусочек кода И для него пишите соответствующие тесты Ну вот говоря про культуру перформанс тестирования мы общались с коллегами внутри компании там вот с ребятами на конференции разговаривал И вообще удался понять Вообще Какое ожидание то как вот в идеале должна выглядеть то есть вот такое ожидание вообще вот перформанс тестирования как оно должно выглядеть Вот и на все отмечают большинство по крайней отмечают что вообще вот надо каждое изменение тестировать под нагрузкой Почему каждое Ну потому что ведь никогда не знаешь где что выстрелит правильно Поэтому в идеале всегда всё тестировать вот при этом не абы как А так чтобы ток чем мы Тестируем то есть какой нагрузкой Оно должно было быть Ну в соответствии с тем Какая напротив если напротив меняется профиль нагрузки то мы должны в тестах тоже уметь его быстро актуализировать и повторять Вот но профильные нагрузки это не всё тут правильно вот этот человек это задавал вопрос почему вот система Может там ёмкость у неё такая весьма не постоянная там был приведён примеру о том что все эти данные разные или говорит о том что и профиль по данным тоже должен быть актуальный то есть мы должны понимать как данные В каком виде туда отправляются Вот это такое ожидание вопрос такой вот реальность там такая или нет Ну и действительности по каждому пункту наверно много есть возражений но реальность такая что смотрите у нас там один тест нагрузочного тестирования занимает 15 минут это приводит тому что пайплайн увеличивается на 15 минут то есть фидбэк разработчику возрастает на 15 минут А если у нас таких нагрузочных тестов а там еще и смотреть там стресс тесты Да сколабилити тесты а там на одной на двух репликах ещё на сколько-то ещё сервисов полно и внезапно где 15 минут начинает расти расти и все начинают бунтовать мы не хотим так долго ждать результата справедливо Ну кажется да а-а Ну про то что нагрузочное тестирование делать так с тем же профилем нагрузки как напротив то оказывается что по цене это просто космос и их Да как бы деньги заканчиваются на этом и до этого никто не доходит там Мы помним Да Лёша Шепелёв говорил что там это Пятая пятый пункт критериях производительность на неё денег просто не осталось ну и наконец третья про про данные а там говорят о том что вообще-то говоря для того чтобы актуальный профиль данных поддерживать системе это по сути Как написать еще одну такую систему рядом то есть по затратам Это примерно сопоставимо что делать вот я над этим тоже размышлял и вот такое некоторые здоровый разумный компромисс Ну во-первых смотрите если мы не можем нагруженным тестирование делать прям сразу моменте Окей давайте сделаем его отложенным Ну например делать по ночам делать раз в неделю то есть главное чтобы получать некоторый регулярные фидбэк то есть не раз там в год да Когда мы планируем железо на следующий год А всё-таки почаще про про данные о господи про данный про инфраструктуру тестирования Ладно мы не можем всю систему протестировать Давайте тогда будем тестировать там реплику 2-3 и по ним соответственно проверять масштабируемость Ну то есть там проверили на одной реплике взяли две реплики взяли три реплики Ну по 3 репликам как себя вела система при масштабировании в принципе можем понять как В целом будет масштабироваться система у нас продакшене вот оно про данная история такая что давайте выделим критичный сценарий и всё таки Ну то что у нас там и слов личный сценарий это вот как раз Даня будет завтра рассказывать актуальный будем профиль поддерживать на них это уже не так дорого потому что мы с уменьшили количество этих но тем не менее так это будем делать Вот так вот Вот это все вот история она у нас развивается развивается Ну и как нужно понимать что среде тоже не стоит на месте то есть там в шестнадцатом году вышла Сергей бука Я до сих пор остаётся актуальной там потом вышла Workbook с большим количеством практики Через пару лет потом вышла ещё одна книжка про то как строить безопасный и надежные системы Вот кстати говоря в последней книжке там довольно много про Ну борьбу Как как противостоять до с атакам как с этим работать в действительности в какой-то момент меня стало открытием что это не все а Google регулярно выкладывает апдейты книги и они на том же сайте и там можно посмотреть каким конкретным главам они выпустили дополнительные апдей виде каких-то дополнительных статей и материалов вот поэтому очень рекомендую там можно многого еще увидеть по перформансу в том числе вот за сим я завершаюсь большое вам спасибо и Давайте пойдем к обсуждению Спасибо Спасибо те за шикарный доклад очень многие вещи лично меня откликнулись основном например про нагрузочное тестирование раз команде его нет мы очень его хотим Каждый раз когда приступаемся страхи убегаем просто реально очень дорого это очень сложно вот по времени у нас осталось немного к сожалению у нас зато есть дискуссионная зона когда мы всех вас приглашаем А может быть вопросы по поводу вопросов по доброй традиции контура у нас за лучший вопрос Мы дарим книжки от контура вот будет та самая классическая книжка среде вот поэтому Приходите в дискуссию и вот кому-то книжечка такая достанется она скорее всего у вас есть но если она вас окажется Вы можете всегда подарить какому-нибудь начинающему инженеру емся"
}