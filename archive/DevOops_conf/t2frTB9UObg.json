{
  "video_id": "t2frTB9UObg",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Меня зовут Тимур я работаю в компании колеса групп и сегодня я буду экспертом на следующем докладе от Глеба Соболева собственно Глеб у нас из компании Касперский и хочет сегодня рассказать нам про Танос также я хотел бы Напомнить зрителям что они могут задавать вопросы у нас есть Telegram канал посвященных непосредственно где мы будем проводить вопросы и вы также можете задавать там свои собственные вопросы самое интересное мы обсудим в самом конце Прежде чем начать доклад Я хотел бы спросить сподвигло тебя Я знаю что у вас много серверов и различных мастеров Расскажи нам пожалуйста как долго вы храните метрики и почему-то все-таки Да Тимур действительно У нас очень много данных у нас порядка 6 ТБ с сырых данных среди 12 катастрофу бернетиса огромная полу машин виртуальных из которых мы получаем данные Танос Нам нужен был для того чтобы все связать вот поэтому наверное хотелось бы немного рассказать о чем мы сегодня расскажем мы поговорим Что такое Танос Да мы поговорим о его архитектуре компонентах поговорим про оптимизацию и проведем большое сравнение с Викторией метрикс поскольку это наиболее популярные и наверное а кому может быть интересен этот доклад это первую очередь наверное Те у кого есть облачные ресурсы которые необходимы мониторить Те у кого есть какие-то гетерогенные среды включающие эти облачные ресурсы Возможно вы смотрите и прикидываете архитектуру каких-то решений включающих и либо в принципе погружаетесь мониторинг только может быть вы даже не в курсе что такое прометиус Да может быть вы знакомы с какими-то другими системами но так или иначе это обзорно будет полезно для всех немного о себе Я представляю лабораторию Касперского Я работаю на проекте Клауд Касперский ком он же kse Касперский ком который представляет saas и Pass решения в виде серверов которые мы варим и в удобном достаточно понятном виде предоставляем через интерфейсы Да и варим все вот инфраструктуру и поэтому у нас достаточно большое количество ресурсов включающих как раз виртуальные сервера Вот и некоторые виртуализации подразумевающие пришел я на проект С некоторым Legacy функционалом до который я последствии мигрировал Да и перекидывал губернатиз накручивал очень много инфраструктуры какое-то дело пай планы логированием занимался Да ну вот все все штуки Все дела плоские дела которые мы любим Вот и как-то среди этого про мониторинг в целом я не очень думал до глобально Вот и забылось и пришлось как бы искать решение потому что у нас было много появилось последствий много разрозненных вот этих вот которые как единичный инсталляции прометился не очень удобно было управлять поэтому я пришел к таносу и давайте рассмотрим что же такое-то нас это достаточно мощная система мониторинга надстройка прометилсом Да она разработана базе промичус но расширяет его возможности и достаточной степени облегчает жизнь до при управлении вот этими единичными основной принцип Танос предоставления надежного и масштабирования мониторинг для инфраструктур и окружений преимущественно в cubernetis Давайте ключевые характеристики перечислим Да это долгосрочное хранение данных в первую очередь масштабируемость этой системы высокая масштабирование агрегация данных и работа с облачными хранилищами касательно долгосрочного хранилища Танос позволяет сохранить метрики долгосрочной основе в облачных хранилищах Что делает его идеальным выбором для проектов с высокими требованиями к архивированию Метрика вероятно если у Вас например есть смотреть большой объем метрик это может быть вам интересно система спроектирована для горизонтального масштабирования Вы можете добавлять новые узлы для обработки этих данных причем вам не нужно будет глобально пересматривать Танос предоставляет возможность агрегировать эти метрики в некий некой общей точки Да и достаточно прозрачно смотреть их через вот весь этот Совет кластеров да как-то раскидывал возможно но это будет достаточно а один из ключевых аспектов Танос это интеграция с облачными хранилищами такими как Amazon S3 и в нашем случае это сколько наша вся инфраструктура находится для вот этого для поддержки вот этого долгосрочного хранения Что является очень удобной фичей Да она обеспечивает высокое отказоустойчивость и доступность метрик причем давайте рассмотрим компоненты базовые То есть у нас изначально есть которые мы используем в а наша инсталляции в этот сторож мы планируем собирать наши данные со всех сторон Поэтому в кластер Да рядом с прометился мы доставляем сайт Car производим настройку некоторую и начинаем синхронизировать данные то есть вот где-то На этом этапе уже мы получается уже охране нашей метрики Да и нам кроме какого-то небольшого контейнера рядом с прометеем особо ничего не нужно дальше мы расширяем это подключение к подключением сторон это некоторые сущность которая обрабатывает наши сырые данные до наши чанки наши индексы подгружает это все дело себя Вот и предоставляет и для взаимодействия вот с этими сырыми данными чтобы выдавать их У нас есть query которая позволяет опрашивать Store до наших хранилище которое мы вот эти архивированные данные получаем плюс оно опрашивает непосредственно наши кластера чтобы получить какие-то Ну более-менее актуальные данные Да потому что время синхронизации сырых данных Stories она регламентирована вот каким-то временем блока она может у каждого по своему определяться Да вот мы майним этот блок скажем где-то каждые два часа мы можем расширить функциональность некоторыми компонентами которые обслуживают сторож Да в частности компактных который позволяет нам эффективно наши метрики сжимать проводить при необходимости что нам эффективно повышает производительность работы с этими своими данными включаем к этому ко всему диалогу графа Ну да вот через одну точку входа и принципе Мы готовы вот этот вот наш набор кластеров достаточно прозрачный мониторить и это будет для нас вот как какой-то один сервер при необходимости для того чтобы оптимизировать производительность нашу мы подключаем кэш в данном случае мы используем кэш но принципе там есть еще некоторые что нам нужно для того чтобы сконфигурировать Да вот сбор наших данных то есть мы настраиваем наше хранилище Store сайт Карри и вот по нашим клиентам да каким-то или другим в разных облаках разные конфигурации по другим настройкам доступ к стору же мы начинаем синхронизировать эти данные собственно говоря через эти же настройки мы синхронизируем наши исключения от Store к стореджу и принципе также синхронизируемся остальные компоненты а что нам нужно чтобы развернуть Танос облачной среде да В первую очередь нам нужно выбрать облачную платформу Если вы этого еще не сделали и только рассматриваете какие-то верхнеуровневые архитектуры Ну непосредственно на это облачные платформе нужно создать кластер Танос преимущественно это делается инсталляцией В отдельной губернасе кластер Да потому что там я удобнее обслуживать удобнее скелей там никому не будет мешаться либо в какой-то изолированный application сконфигурировать компоненты Да нужный набор компонентов которые нам нужен протестировать Да и добавить свой мониторинг Да некоторые методы для мониторинга нашего чтобы мы всегда знали в каком состоянии нас эти компоненты возможно что на что-то где-то отключается что-то недоступно добавить чтобы мы имели высокую доступность Да и какой-то постоянный поток стабильных метрах ожидаемые ожидаемых выступлений а мы должны с интегрироваться с существующими инфраструктурой которая у нас есть но в виде кластеров Да и стораджи всего прочего Вот и при необходимости от масштабироваться посмотреть на вот эти вот метрики что-то где-то подкрутить добавить может быть not провести какие-то настройки кэша Ну и так далее Давайте посмотрим на схема работы станос Ной среде то есть нас есть схема отказоустойчивая которая подразумевает что у нас отдельный инсталляции будут находиться за неким балансировщиком и подключаться к какому-то общему сторожу и это позволит нам именно вот развести до наши компьютер мощности может быть по разным регионам может быть как-то их там заизолировать в разных средах но тем не менее всегда иметь доступ и получать актуальные данные То есть это дает нам конфигурацию высокодоступного кластера да как я уже говорил что можно размещать в нескольких регионах для отказа устойчивости и также это может дать нам гибкую настройку производительности случаи если мы например не всегда хотим вот так скажем чтобы у нас все данные вытягивались мы можем немножко потюнить отдельно взятые инсталляции также мы можем настроить некоторые шардинг да в режиме распределенного хранилища мы будем иметь N некоторых стражей Будем иметь N некоторых восторге твоих которые будут данные синхронизировать И вот так вот мы сможем отбалансировать эту систему чтобы мы не эксплуатировали Да все время какой-то одной точки а за счет этого также достаточно легко мигрировать эти данные Да потому что ну мы всегда можем Добавить новый узел и он все равно будет для нас как бы прозрачно тем же самым источником данных да то есть там по факту даже не придется мигрировать данные мы можем переместить дождаться там окончания цикла например жизни там сторича который у нас уже имеет либо его мигрировать последствия потихоньку в новый созданный вот и это значительной степени сокращает время обработки блоков поскольку мы имеем распределенную нагрузку к сторон И каждый все время работает с каким-то своим небольшим кусочком мы используем свои инсталляции сейчас высокодоступную Вот эту вот систему в которой У нас есть общий сторож и ну в какой-то момент у нас начались проблемы с тем чтобы оперативно доставать из него Данные в тот момент когда данных стало очень много и он нам пришлось начать тюнить и тут стоит поговорить про некоторые оптимизацию у нас есть возможности оптимизировать даже и проводя какой-то архивацию блоков проводя некоторые сэмплинг мы можем крутить разного уровня индексы то есть Можем кашировать индексы мы можем кэшировать ответы Вот и мы можем кэшировать взаимодействие между сторонами или между тором и какой-то базой Ну и проводить простому отрегулировать а что у нас тут было на старте да то есть у нас схема с общим хранилищем на 6 терабай данных 12 вот этих вот кластеров наших которые дают на метрики плюс сверху 400 серверов которые непосредственно через обработчики в кластерах cubernets тоже майнит какие-то метрики отдают их систему и вот пике у нас Танос потреблял там до 37 гигабайт памяти утилизировал там 8 то 10 ядер и как бы в целом для крупных систем мониторинга это нормально но у нас были потребности снизить вот эту историю до каких-то для нас более удобных пределов и мы провели вот этот набор оптимизации да то есть мы поднастроили компактно настроили вот этот провели некий за счет этих настроек то есть мы разделили там сырые данные которые собираются семь дней пятиминутные данные которые собираются 60 дней да и часовые данные которые у нас собирается отрезком до 180 Вот и соответственно настроили какой-то производительность это компактор который нас устраивала и в общем как бы с оптимизировали данные строения непосредственно сторож вот следующим шагом мы подключили каши некоторые Да и здесь мы настроили там каширование индексов для наших данных стражей которые по сути дела Все время должны быть у нас в актуальном состоянии до чтобы мы могли быстро оперативно добывать мы прикашировали с помощью групп кэша непосредственно наши чанки таком конфигурации что наши инстанции стора они сложились кластер и непосредственно обменивались данными еще друг Между другом не только Между другом чтобы лишний раз не выгружать до лишние данные а грубо говоря извлекать их из ближайшего своего соседа Вот и настроили кэш ответов на уровне куэрера который позволил нам наши данные собственно говоря лишний раз не перезапрашивать это очень эффективно увеличило производительность нашей системы то есть мы сократили утилизацию памяти Почти на треть и мы почти почти даже больше чем два раза увеличились сбор перевода метрик активный сбор то есть активных метрах которые у нас вот все время фигурирует системе и мы соответственно остались этим довольны хотелось бы также сравнить традиции система мониторинга с Виктории метрикс поскольку она по части функционала до сходятся стана сама это рассмотрим но она не совсем лежит Мне кажется в этом разрезе поэтому может быть правильно то есть Виктория метрикса если кто не знает это достаточно популярная система мониторинга данных которая позволяет собирать данные и хранить и анализировать у него есть там собственно говоря свой язык запросов и поэтому Давайте вот посравниваем немножечко их какие у нас есть сравнение положительное разрезе да то есть Танос тут явном виде выигрывает в долгосрочности хранения потому что ну мы буквально как в какие-то ведра до можем сливать эти данные в наши баки тогда наши сторожи которые мы можем в Облаке достаточно быстро оперативно варить и архивировать эти метрики большом объеме объеме без необходимости поднимать какой-то дополнительный компьютер и соответственно для этого нужен совершенно какой-то небольшой объем мощности в виде контейнера который соседятся рядом с Да мы можем легко интегрироваться с облачными хранилищами Да потому что настройка проводится там буквально одной строчке конфигурации и опять же мы включаем sextra Jum и к различным сторожам можно подключаться до различных облаках не только в одном вот тем самым мы можем это эти конфигурации Да заизолировать там между несколькими провайдерами вот Виктория метрикс также может интегрироваться с облачными хранилищами но тем не менее там нужно проводить некоторые Дополнительные настройки дополнительную интеграцию и Скорее это немножко не про это обе системы в принципе позволяет сложные запросы выполнять Да там сейчас тоже развивается в сторону каких-то своих своего языка до свои запросов пока что не эксплуатировали эти функции но тем не менее принципе функционала который есть сейчас вполне достаточно Ну как говорилось Да это обеспечивает все вместе совокупности все функции обеспечивают высокую доступность отказоустойчивость и в принципе мы можем разных конфигурациях достичь там различных необходимых нам уровне отказа устойчивости и в принципе Виктория метрик тоже это позволяет сделать но возможно таноса с моей точки зрения более мощные инструменты потому что архитектура изначально рассчитана именно вот на вот это горизонтальное сканирование в облаках из каких-то недостатков что некоторые настройка Да некоторые конфигурация таноса может показаться может быть сложной для новичков входящих в эту область и принципе для бывалых и с Виктории метрикс такой принципе может быть но наверное в целом какие-то базовые конфигурации выглядит гораздо проще а то нас требователем к ресурсам Да и отдельный отдельное внимание среду следовать уделять именно оптимизации но тем не менее базовый функционал архивирование хранения он подразумевает что мы как бы Если хотим можем завалить это деньгами до ресурсами как бы и очень быстро начать собирать но тем не менее история метрикс очень хорошо оптимизируется да Но тем не менее Вот Чем более долгосрочное хранение чем больше объем тем сложнее Мне кажется это оптимизировать Ну и с интеграции с другими мониторингами Танос наверное отсутствует слово совсем то есть там есть какие-то возможности с интегрироваться но тем не менее он больше рассчитан губернатиз на Облако на интеграцию со стореджими и вариться сам себе варится в этой своей системе время как Виктория метрикса позволяет нам собирать большое количество метрах различных и нам особо не нужно для этого приседаний что-то такое нас не очень интересует поэтому можно сделать некоторые выводы в виде того что Танос вам будет интересно использовать в определенных кейсах Да но они в этих кейсах наверное будет максимально полезны Да что вы преимущественно собираете метрики из кубернетис в облачные инфраструктуры у вас высокие требования к архивированию экране этих метрик то есть Может быть не всегда их использование но впоследствии как бы вы хотели бы чтобы эти метрики как-то ретроспективно использовались Да и в вашем продукте и у вас есть региональное распределение в облаках которые Ну как бы при котором не хотелось бы разворачивать каких-то лишних компьютерных мощностей чтобы обеспечивать каждый регион какой-то отказоустойчивость вот в принципе все поинты которые я хотел бы сказать наверное Хочу закончить свой доклад и наверное продолжить дальше Тимур спасибо за доклад Глеб было интересно у нас тут скопилось какое-то количество вопросов Давай Наверное начну озвучивать их Давай наверное начнем с такого не испытывали проблемы когда Microsoft ушел из России доступностью самого Жора Ну и вообще не боитесь потерять доступ Хороший вопрос мы ничего не боимся но мы опасаемся опасаемся мы готовим какие-то варианты чтобы это митигировать пока что у нас все это находится на уровне планирований еще достаточно долгосрочных и там много факторов Да подразумевающих что наша система Ну изначально очень сильно завязано на эжер не может скажем так взять и просто без каких-то потерь репутационных потерь возможно переехать оттуда вот поэтому нам приходится жить в тех реалиях которых мы попали Да но тем не менее У нас есть некоторые договоренности некоторые такие скажем ощущения того что у нас есть возможность все еще как-то это преодолеть Мы потихоньку готовимся что-то делаем планируем но прям конкретно бежать голову мы сейчас не планируем не рассматривали Нет к сожалению пока что это не рассматривал Вопрос хороший Я очень по верхам посмотрел и действительно очень много схожих черт возможно возможно как бы может быть там даже какая-то производительность может быть более высокая но наверное по двум факторам Я пока еще туда не ловлюсь Потому что насколько я знаю что по моему в мир мире все еще нет какой-то функциональности такой нативный с оптимизацией данных работы с время данными Да вот в рамках хранения архивирования А во-вторых ну пока что я только что добился Ну как бы попал в струю мачурности пришедшего мачурности таноса Вот и Ну просто из-за того что хочется посмотреть изменить систему мне пока что как-то не хотелось бы этим заниматься но тем не менее Ну да наверное интересно этому вопросу Какой объем ресурсов у вас сейчас используется чтобы эффективно а смотрите Но это совокупности Это что-то около 20 ГБ там оперативной памяти там с 4 до 8 ядер работает над обработкой данных ну стабильно в среднем где-то там 4 в Пике сейчас не поднимается выше 46 вот под этим всем где-то пол терабайт стороже для кэширования данных и сверху еще где-то там на всякий Клер и в районе нескольких гигабайт буквально используется оперативной памяти плюс периодически тот самый компактор про который я рассказывал запускается Вот и он может потреблять тоже какие-то мощности но мы скажем так перевели в плоскость того что он интерактивно работает да Как справиться Поэтому в принципе объем данного объема мощностей он очень небольшой Это достаточно небольшой кластер сейчас для того чтобы обрабатывать там порядка 6 гигабайт сырых данных Я считаю что это прям большой успех естественно мы не все из них прям постоянно предоставляем но мы все время обрабатываем Здесь есть такой интересный вопрос не используете ли вы друг и чтобы не отправлять все метрики в Танос соответственно лишний раз не используем ли мы что не используете ли вы дропы метрик чтобы не отправлять симметрики в Танос и не заполнять индексы ненужными лейблами мы пытаемся все-таки поддерживать метрики Наши в каком-то порядке чтобы нас не было прям большого объема ненужных метрик и нам собственно особо нечего да плюс у нас есть реальный Запрос к использованию перспективных методов поэтому мы используем стараемся использовать все оптимизировать и приезжать данные по возможности спрашивает я правильно понимаю что Храбрый метод сработает для внешних по отношению к кластеру потребители данных а внутри кластера метрики собирает по-прежнему один Прометей Да внутри кластера Ну то есть потребитель таноса по сути дела Это инсталляция Прометея в отдельно взятом классе соответственно метрики внутри класс страда собирает один и тот же Прометей наверное можно предвосхитить следующий вопрос что Прометея внутри нас есть тоже какая-то своя производительность тоже какие-то свои ресурсы расходуется Но я честно говоря не знаю в каких системах мы можем этого в чистом виде избежать такая ситуация допустим Один пасторов стал недоступен Вот и в него прометение может описать то Олег менеджер у нас с какой стороны будет отрабатывать смотрите я опустил этот момент в этом докладе поскольку про рулер да то есть систему алертинга в таносе там можно наверное было бы отдельно Достаточно долго рассказывать может быть когда-нибудь будущем я об этом расскажу подробнее но тем не менее Да есть когда есть рулер и по сути дела он работает с теми данными которые находятся в прометеях Вот то есть он сам парсит и передает данные в отдельно взятые менеджер да то есть у нас есть отдельная инсталляция менеджера мы его отдельно обслуживаем там есть отдельные свои правила настройки Да своим поинты и вот рулер со всех этих кластеров сам варят для него Как долго хранить эти метрики а ну наверное если говорить про самые долгие периоды того как мы стали оптимизировать мы хранили их два года вот мы хранили два года но у нас было на тот момент меньше потребителей и когда там резко привалило мы тут вот как раз немножечко присели и решили что нам это надо делать все с оптимизировать оптимизировать как раз такими средствами про которые рассказывал Да мы включали компактеры каши Мы даже какие-то данные там часть пришлось вычистить вручную да просто их обрезать о чем пострадали потому что у нас не сошлись там индексы и которые были сторожек с теми что у нас были сторах и потом приходилось перекошировать В общем все дропать и тоже был не очень хороший экспириенс но сейчас актуально мы держим где-то год будем потихоньку закругляться Я хочу напомнить что по окончанию трансляцию можете проголосовать за этот доклад а также перейти будет после отдельно дискуссия можете перейти Спасибо за внимание Спасибо"
}