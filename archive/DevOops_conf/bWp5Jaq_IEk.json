{
  "video_id": "bWp5Jaq_IEk",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Всем привет Меня зовут Старков Станислав и у меня есть вопрос С какой нагрузкой в продакшене вы сталкивались кто-то может быть 1000 rps у кого-то 5000 или может даже есть тот у кого 10 Что ж сталкивались с 50 тысяч РПС на продакшн серверах я хочу вам представить Леонида с утюгова он расскажет вам о том как он переосмыслил подход к нейм серверам и поделится своим опытом тебе Слава Спасибо Стас Всем привет Меня зовут Леонид стюгов об этом уже сказали и сегодня предлагаю поговорить вам ребята о том как мы используем наши нейм сервера но все их знают как часть дома name System раздаем имена получаемые айпишники спрашиваем за айпишник получаем имя Я думаю всем Это известно но можно делать не только так немножко о себе прям пару слов похвастаюсь Понятно Леонид стекол завод Уже все знают закончил Самарский государственный космический университет в далеком далеком прошлом занялся эти администрированием в 2005 году начал за это даже получать деньги можно сказать начал профессию начинал я прям с самого простого самый сложный прибор который у меня был этот принтер потому что к нему ходили по сети в основном бегали так потому что посетить он плохо работал потихоньку усложнялся дошел до инфраструктуры до вообще технологии Как понять технологии сейчас пытаюсь транслировать эти понятия технологии между разными командами между тем кто их используют и между тем кто их настраивает и в 2018 году я присоединился команде эксплуатации это часть большого такого холдинга My Games немножко она событии территории или it Мы уже 250 сотрудников у нас около десятка активных проектов а возможно кто-то слышал может кто-то прямо сейчас играет выключайте Rush Royal наш Флагман а Миллион активных пользователей аж ежедневно разные платформы Ну и как говорил входим мы большой холдинг Games там конечно не 250 уже намного больше а о чем поговорим сегодня значит когда я устроился сюда 2018 году присоединился команде ко мне приехала большая такая задача Нужно было все за инвентаризировать все за мониторить и описать и Первое что я начал делать я начал заносить сервисы по именам в DNS чтобы знать где чтобы знать что Вот и тут же пошел придумывать систему Brainstorm inventory все в кучу а потом уронил DNS и с ним наш инвентарь и с ним наверное зарплату тоже уронил Если бы я так больше не хочу И я хочу с вами поделиться правильно сначала нужно было это все сделать отказ устойчивым сделать масштабируемым поэтому пойдем аппаральному пути Сначала мы расскажем Что такое у нас на им сервера как DNS И почему они отказоустойчивы потом я поделюсь с вами нашими рецептами как мы используем наши name сервера для того чтобы получить еще инвентаре потому что по большому счету там уже есть все что нужно И если рассматривать это как базу данных то в базе данных нужно строить только поиск конечно же не обходится без Бизон Ну куда идти в безопасности это наше всё и они всегда приходят в нужный момент когда ты понимаешь что тебе пора совершенствоваться в этом направлении поэтому поговорим о том как мы еще и ограничиваем с помощью наших нем серверов походы в данном случае по ssh что мы используем как CL и почему мы это делаем И как мы это разделили Ну и конечно покажу как мы все это используем потому что использовать мы это очень любим Ну мы сами это сделали если это использовать не будем то для чего немножко хэштегов так вот начнем с DNS большая картинка для чего она здесь нужна хочу там вот вправо в углу если что есть в хайрезе можете посмотреть повтыкать кто любит большом разрешении хочу на этом слайде показать к чему примерно мы сейчас пришли не похвастаться а просто показать что когда ты приходишь к его лабирите когда ты приходишь к масштабируемости к геораспределению как у нас это тоже есть то ты приходишь к большому количеству хостов или к большому количеству инстансов на этом сервисе и это нормально и так должно быть потому что если оно сложное если оно отказоустойчивое если оно действительно балансируемое то оно не будет маленьким и оно не должно быть маленьким в правом верхнем углу там есть такой Standalone сервер один это Триггер мне каждый раз на схему Смотрю и понимаю что вот там тоже нужно доделать Ну Бесконечность не предел Мы работаем теперь что мы используем в DNS как в домен name System чтобы получать семена чтобы получать IP мы используем Power DNS это dns-сервер написано на C код достаточно простой исходники свободные огромные комьюнити можно все посмотреть в принципе ничего сложного нет даже если залезть в исходник и проанализировать потом покажу как мы анализировали у нас есть патчи на Power DNS несложные Непростые но действенные все это накладывается легко обновляется Потом пачатся проблем с этим нет Это первое Второе в какой-то момент мы задумались над тем что наша DNS должна быть разная она должна быть где-то геораспределенная где-то должна быть быстрая где-то должна быть инвентаризируемая то есть Нам нужны связи внутри DNS А это прямой путь к базе данных ну и вообще DNS эта база данных если почитать на rfc то это хорошо ложится на реликтивистскую модель у пауэрдессон есть куча бэкендов Я на момент поиска сейчас не знаю потому что это решение мы используем эксплуатируем на момент поиска я не нашел ничего чтобы использовал такое количество быканов плюс базы данных здесь можно при желании накрутить и пост Грис и какую-то стороннюю возле если очень хочется мы эксплуатируем майские также мы используем бинт Ну просто тупо потому что он очень быстрый здесь Бин лайк это То есть файл с бензин таксисом Я думаю очень многие используют DNS как бинд Файлик подкинул туда что-то написал потом наверное в Гид это все да все будем раскатал в общем схема простая Но для нас не очень полезное думаю пришли потому что скорость потому что мы пытались и выгрузить в память полностью базу и взять Мы пытались накидать каких-то там кучу кластеров быстрее А нам нужна была скорость в нескольких моментах всё будет видно потом ну и геораспределенный у нас есть сиены у нас есть решение которое хостятся по-разному в разных дата-центрах нам нужно уметь это гео распределять Мы решили сделать это на базе имен на базе DNS соответственно glip Он кстати здесь неплохой до файл но ямбрик спасибо я мог знать все вот и здесь проблем не возникло Нам очень понравилось и того куча бы кэндов не очень сложный носи код все с одним API и есть еще дополнительная плюшка это свой лот балансер Power DNS есть DNS dist это мощная штука она умеет вылезать и в kernel Space она умеет очень много луа и его регэкспо это тоже лавашная они тоже у него быстрые она умеет и балансировать она умеет и фильтровать она умеет масштабироваться с помощью нее много сделать можно чего при например обслуживания 24 на 7 в онлайне это было однозначно то плюшка которую мы себе хотели Ну и в итоге начиналась у нас все с майски ели Почему как в базу данных потому что нам во-первых не нравился товарность файле то есть удовольствие текстовым файликом крутить честно сказать и вычитывать потом это из гитару лично нам не понравилось а потом нам не понравилось это дело быка 5 разливать обратно опять таки из таймингом до минуты или до секунды и понимать где Какое изменение было Если я могу в майские или взять какой-то изменений посмотреть на него просто влогах бинарных то как бы файлики Ну так себе плюс не очень нам было ясно Каким образом можно масштабироваться и туда-сюда копироваться с файлами это нужно какая-то сторонняя технология это все множить и россинком или еще как перезагружать ну нет а в базе данных все уже давно решено Это все как бы из коробки там тебе репликация и отслеживании классный мониторинг и опять же велосипедов никаких не надо так что ушли мы полностью на базу данных воспринимаем это как базу данных и с ней как с базы данных Мы работаем теперь что по поводу самой инфраструктуры вот прям первый дос Ну может не первый но там 3 4 когда надоело начальнику а потом сразу Надоело мне после этого мы решили что инфраструктурой публичные нессы это разные вещи но мы знали об этом но как бы здесь мы причем очень плотно задумались и мы разнесли инфраструктуру и публичной части котлеты отдельно мухи отдельно теперь у нас профы внутри наших инфраструктурных вещей окружении никак не влияет на публичные нес и на отдаче что мы у себя делаем Это Наша кухня а паблика от этого не страдает А если нас доносят снаружи А мы еще и умеем защищаться от этого эффективно чуть позже вам это тоже покажу то опять-таки инфраструктура тоже Никаким образом не страдает и не задействовано в этом то что делает паблика как он обороняется его проблемы делают кстати очень неплох и в какой-то момент мы подумали А зачем инфраструктуру мы вообще завели на наши публичные имена также на правах общих пользователей то есть кто-то пришел снаружи спросить имя нашего проекта А если наш внутренний сервер либо продал и хочет узнать это имя он пойдет тоже в наш публичный возникает вопрос ребята смотрите вас у вас что-то не отвечает И ваша инфраструктура не знает о внешнем имени Да не знает Ну потому что снаружи мы все равно уже недоступны в данный момент если вдруг это случилось и нужно решать не следствие и обеспечивать инфраструктуре ответы а нужно решать причину для начала сделать так чтобы публичный нэсы отвечали всем тогда и продукт станет доступным Ну и вместе с ним инфраструктура тоже будет все Отвечать так что мы Все закашляли мы сделали ретрай внутри и мы просто оперативно решаем проблемы с пабликом если она есть а из инфраструктуры ходим прямо в публичные НС ну мы их Конечно же не отсекаем нашими оценками мы их не блочим инфраструктурные сервера мы не знаем но тем не менее они ходят на общих правах туда Давайте по инфре значит что нужно было сделать синфрой есть некоторые такие особенности связанные с высоко нагруженными в приложениями это то что запросов много соединений открывается и закрывается много она выгодно чтобы они достаточно быстро закрывались если они уже неэффективны вот и в связи с этим каждый открытый запрос как правило это один а то и два вопросов ДНС к имени потому что нужно обратиться и обратиться уже давным-давно не по IP мы этого давно не делаем значит мы должны его отрисовывать плюс ко всему к этому У нас есть cubernet у нас есть много воркеров того же инжинкс у нас есть огромное количество бэндов Они множатся и мы получаем нагрузку но наверное если все прямо вместе собрать около 5 к РПС на нашей инфраструктурный нас это абсолютно нормальная ситуация бы если представить даже обычный сервис в кубе ли за которым Ну хотя бы десяток кодов то это уже 10 как минимум вопросов секунду а если под ним на процессорный 20 30 50 и это только для одного продукт продукт не один Понятно студия их очень много как и бэндов как и фронтов и всего остального Поэтому нужно было как-то скелиться начали мы с того что мы поспелились по сети у нас горизонтальная развертка наших ns-серверов на базе баланса на сети сетевики предоставляют нам эту классную возможность мы можем анонсировать один IP и раскидывать запросы примерно 50 на 50 или 30 на 30 на 30 и так далее То есть равномерно на каждую железку но есть и свои ограничения в основном Это связано с тем что в пределах одного дата-центра трафик из такого балансера не уйдет другой дата центр и если какой-то сервер обратиться к VIP Мы помним эта инфраструктура Значит у нас внутренние сервера в том же дата-центре обращается к балансеру в том же дата-центре и всегда пойдут на одну и ту же ногу эту проблему надо было решать и здесь мы воспользовались как раз DNS dest Классная штука мы балансом еще и внутри за ним Поэтому в DNS 10 на каждой ноге мы заводим абсолютно все ресурсы и абсолютно все авторитативные сервера и размазываем запросы еще раз после того как мы их распределили на сетке что это дает помимо того что мы равномерно утилизируем сеть и Ну в данном случае железо в первую очередь и сеть тоже это дает нам возможность подкинуть железо не используя сетевой балансер нужно нам в данный момент увеличить нагрузку или провести профы или отключить один из авторитативных серверов все что угодно мы просто внутри DNS dest докидываем еще один говорим что теперь это бэкенд на авторитатив что он тоже умеет отвечать и нам не нужно думать о сетевого балансе мы просто в DNS 10 указали его еще раз и пускаем на него таким же образом размазанные запросы масштабировался стало очень просто причем это все происходит в онлайне причем Его можно подключить туда и не опускать запросы а потом пустить только часть или отфильтровать возможности огромное количество но инфраструктура все там все классно мы все забалансировали там защищаться от внешних угроз не надо от подломов Как защищаться поговорим чуть попозже теперь нам нужно разобраться с пабликом три картинки что как говорится интересует того кто держит DNS первое количество запросов Это был один из Досов здесь из-за агрегации не видно но на самом деле скачок был в районе 50к в секунду и надо сказать что путь любого досера как Путь самурая Цели нет есть только путь дос он будет продолжаться бесконечно И самое главное спасибо им за это это возможность развиваться защищаться что-то придумывать Ну и даст атака на DNS она очень дешевая снаружи для того кто ее устраивает достаточно дорогой может быть внутри для того кто на нее отвечает каждый несуществующее имя нужно прогнать по всей базе найти соответствие или то что его там нет и выдать на это ответ поэтому 50-60 карбс для нас вначале было проблемой сейчас нет как мы видим несколько секунд прошло порядка 2000 самураев попала у нас в динамическую блокировку И за все это время мы по диаграмме даже не вылезли вон за 10 миллисекунд ответ Это в худшем случае а по-хорошему здесь у нас в районе одной миллисекунды латнсе на каждый ответ Даже во время атаки Ну и надоело им там буквально через 15 минут Самура еще сколько-то посидели один блоки потом вылезли оттуда и картина как мы видим по количеству запросов устаканилось вернулась обратно где-то там пятиста шестиста которые были как мы это делаем Ну во-первых спорт рею спорт Почему не садр рисфорд потому что размазывать нагрузку на все процессы сидящие на этих портах равномерно кто обменивал джинсы очень плотно и между оркерами раскидывал нагрузку чтобы они утилизировались CPU знает здесь та же история регистратор По моему так не умеет мы не смогли это найти ривспорт дает такую возможность количество оркеров которые там используются летилизируется абсолютно равномерно Это первое Второе Но конечно мы начали с того что мы начали дотачивать бэнды Потому что много запросов надо дать много ответов Давайте докинем туда еще один сервер Да у нас есть DNS диск мы сейчас туда вот так вот их все накидаем и они там будут дружно 50 человек жить на 50 машинах и отвечать на любое количество запросов снаружи Нет не будет еще раз повторюсь до 20 Атак а снаружи очень дешевая внутри очень дорогая всегда можно закидать снаружи то железо которое ты накидал внутри ответить всем не получится поэтому на самом деле выход один нужно блокировать нужно блокировать по уму на время то есть хулиганишь мы тебя блокируем перестаешь Окей дружище возвращайся обратно спрашиваю то что нужно мы тебе ответить соответственно нам нужно Получить какой-то запрос обработать его внутри DNS понять какой наш авторитативный сервер дает ответ Это индекс домен это серфол или это что-то действенное у нас действительно такое имя есть ему вернем айпишник и на основании этого ответа от сервера вынести свой вердикт надо нам оно или не надо вот тут Мы возвращаемся к бинду Вот здесь мы начали тестировать Что быстрее всего работает и вот здесь мы пришли к бинду нам нужен вот этот Rocket Jump в самом начале когда 50к запросов мы должны все через себя пропустить обработать понять что из них правильно что нет кто из них больше всего спамит неправильными ответами Вернее неправильными запросами на базе наших ответов и потом уже булочки потом динамическая блокировка мы блокируем всех кто спрашивает Эни всех кто получает серфов Все кто получает несуществующий домен закидываем на но в районе 5 минут насколько я помню мы привязываемся в основном к ттлу который есть в зонах и исходя из ТТ выбираем время блокировки Самурай отсиживаются там А так оттуда прекращается DNS dist уже видит что с этого айпишника больше подобных запросов не сыпется адрес переходит автоматически обратно в разблокировку происходит все раз секунду за секунду статистика набирается за 5 секунд решения принимается таким же образом выкидывается обратно если все пошло хорошо и оказалось что это очень дорого в юзер спейсе вы знаете 50к запросов в секунду анализировать из userspace и все это через себя пропускать получать ответы а потом еще все это нужно каким-то образом запоминать и каждый раз проверять заново Ну жесть CPU просили очень хорошо Поэтому нужно уходить в кернеспейс и здесь мы пришли к обновлению ядер у нас везде ядра пять плюс Почему Потому что там есть к побились для БПФ мы используем ебэф X standed потому что он есть DS 10 раз и потому что есть некоторая особенности которые позволяют гибким образом это все фильтровать Но в основном DNS dest они сразу ушли на экстренных БПФ и на нем живут у кей не вопрос опять же почему ядро 5 Плюс потому что в четвертой ядрах тоже было БПФ но там оно было как побились System и к этому еще прислонялась на огромное количество настроек Нафига нам эта дырка в безопасности если есть пятое ядро и там есть к Повелитель на БПФ Давайте использовать его давайте давайте обновимся не вопрос сказать что это было не больно ну наверное стоит собрать да был где-то местами больно но перейти было возможно и от неких сложностей нет опять же мы переходили планы мы делали все это в онлайне убирали одну ноту обновляли взрывали обратно это возможность такая есть все паблик у нас защищен мы умеем отражать атаки мы умеем динамически блокировать всех ненужных нам самураев возвращать обратно когда они больше не Самураи Ну или может они одумались я не знаю что произошло с ними вот мы хорошо выдерживаем видос и собственно Ничего не страшно Но есть одно но в DNS 10 К сожалению все работало не так как мы хотели вот я говорил в начале что у Power DNS достаточно простой хищный код он действительно достаточно простой я собственно личным баг-репортов пару штук накидывал Но честно мы не дожидаемся пока они все это включают релиз мы пишем собственные патч и потом его просто накидываем наверх следующее следующее обновление все нам нужно Здесь и сейчас мы как и всем нужен прямо сразу вот возможно и свои как бы сделали у них не использовался и evp по умолчанию при дефолтных настройках даже если ключ нужно опцию Я нашел в коде Это довольно просто было где это используется Почему и поменял условия буквально там пару строк и полетели Так что здесь больше никаких проблем не было мы ни с чем больше при включении Ну и публичность это значит что не только ты придумываешь и держишь зоны А кто-то к тебе приходит и говорит вау да у вас там такой рок-н-лоадет вы ребята просто бомбите на всех и вас никогда никто снаружи не дадут Мы тоже хотим у вас свои зоны размещать Ну здорово Это классно и мы обязательно это сделаем вот взяли пошли делать А как мы пока еще не знали и что мы придумали нужно было во-первых быстро а во-вторых нужно было просто а в третьих нужно было масштабируем первое С чего мы начали это цел Ну людей которые придут и нам отдадут зоны много значит нужных как-то между собой разделять А еще мы на свои неск пускать не хотим Мало ли что мы настроили они донастроит смысла нет подняли отдельный инстанс там и свой IP там и свой токены секреты там хотите внешнюю целку если нужно на Power DNS можно надстройки накидывать опять же собственной IP это возможность ребятам разрабатывать под себя инструмент который нужен хотите на питоне хотите еще что-то он отвечать стандартам Джейсоном запихиваете во что угодно делаете как угодно Как Вам удобно Это ваш собственный инстанс вы там хозяева они что-то сделали они туда зону накидали они процесс выстроили нужно как-то забирать к себе как в ДНСе есть встроенная функция встроенный скажем так путь репликации данных между instaтами это xfr есть мастер сервер Он держит мастер зона он анонсирует периодические ID этой зоны это является командой для всех репликантов подсасывать к себе изменения протокол вернее путь этот называется xfr Почему бы не использовать у нас всегда есть как у репликанта копия всего что нам Отдали на делегацию чтобы у них не сломалось внутри на их собственном отдельном instance у нас репликация до сих пор есть но пока они конечно не серийник не принесли нам Где Зона стала пустой но мы еще на это не натыкались А если они что-то там у себя не доделали серийник не поменяли у них все сломалось мы живем дальше они все свои проблемы решили аккуратненько сиреничек поменяли на зоне у нас репликант это увидел засосал себе все изменения и мы отдали наружу все что они захотели схема Нам нравится мы на ней живем уже не одну зону так делегируем проблемы пока что не встречали Ну и наверное к самому интересному когда-то Я когда получил задачу работать с DNS я полез смотреть в сеть что и где ну без практиса никто не отменял Какая бы экспертиза не была послушать кого-то еще вы здесь Потому что вы хотите послушать кого-то еще я полез смотреть не знаю как вы я вот очень люблю рутков Я посмотрел доклад Николаева прямо руки DNS название горит само За себя и фраза оттуда определила все остальное DNS эта база данных и реально эта база данных когда мы начали смотреть на него только так мы смогли придумать вот что да я читал rfc оба даже на английском языке полностью реально очень полезная штука Всем советую во-первых они не сложно во-вторых rfc 1035 вообще регламентирует порядок работы с DNS И это прямо тот случай когда авторы рассказывают вам как лучше действовать с тем что они вам накопили супер И меня зацепило следующее там ребята есть упрощение жизни а именно ARP и домены это домены с обратными именами денисе есть прямые имена когда мы от имени идем мы получаем IP адрес взамен есть обратный когда мы имеем IP адрес хотим узнать Какие имена на этом IP адресе есть это обратный запрос это РП домен и они говорят прямо в России для определения местоположения всех шлюзов конкретной сети Почему шлюзов Почему в сети а сейчас разберемся Когда у нас стало огромное количество сервисов Они все в DNS описаны У нас есть имя там не знаю Джинкс 1 такой-то проект такой-то дата-центр Ну все что нам хочется напихать в этой мы захотели знать где эти сервисы располагаются нам нужна связь между тем что мы отдаем и тем где оно хостится если в пределах cubernates Это не так важно хотя там это тоже можно использовать в юзабилите поговорим то когда мы имеем парк железок на которых крутится сервисы у нас такие есть их довольно много на данный момент Хорошо ли плохо отдельный вопрос Вот то хочется знать где лезут привязаться Но это прям задача инвентаре она прямо прямая То есть то что мы делегируем и То на чем мы это круть Окей сервисы описаны есть об этом уже можно не париться нам нужно придумать как описать железки в ДНСе но они же получают айпишник Камон конечно получает нужно что-то уникальное значит про нашу сеть У нас есть базовые веланы в них мы регистрируем каждую железку и потом на уровне базового велана мы делаем репанонсы уже с сервисными публичными айпишниками у нас получается каждая машина это как бы шлюз на который есть в базовом Вавилоне свой адрес и он уже не меняется он уникальный и есть репоносы со всеми анонсируемыми адресами дальше это сервисные адреса публичные адреса и все остальное шлюз rfc немножко срастаться начинает уже каждая машина как шлюз для сервиса на RP и вот может что-то придумать и имя для каждого Хоста мы взяли из САПР Ну то есть если есть железка Значит на него потратили деньги значит она где-то в базе учитывается Но если не сап то что-то еще там есть айдишник он уникальный железку списали айдишник списали Никогда не повторится круто айпишник есть уникально есть имя есть и сойтишника уникального из сапоги тоже есть имя плюс IP это прямо запись в DNS вбиваем все железки как сапоги и хайбе адреса на базовом плане получаем каждый хост через который мы как шлюз рассказываем всем О сервисах тоже в ДНСе у нас там есть и сервисы у нас там есть железо осталось только придумать а как между ними осуществить поиск ведь наш DNS это база данных Мы помним как говорил сам Лев Николай эта база данных релятивистская база данных в нашем случае Ну давайте флажок какой-то туда прикинем и вот в этот момент airp флаги и все срослось каждая тачка как шлюз для сервиса у которой есть своя запись она есть прямая есть обратная то же самое сервиса это что-то что с Тачки как со шлюза анонсии в мир через риф у него есть прямая записи есть обратно давайте мы на каждый сервис который хостится на какой-то тачке на каком-то железном Хосте сделаем еще обратную запись от этого Хоста а на каждом Хосте который на себе несет сервисы сделаем обратную запись еще и от каждого сервиса если почитать в rfc никаких проблем Это не влияет никоим образом на работу DNS как name сервер зато мы получаем флаг по которому мы делаем выборку все инвенторе причем инвенторе дешево инвентаре на том что уже есть со всеми уже записями которые у нас были классным API хочешь ходи в маске хочешь делай запросы на базе DNS протокола все что угодно прямо вот просто из Клима ментально Но осталось только все это дело стандартизировать написать небольшой контенте оберточку Каким образом эти Хосты туда заносим сервисы заносим как мы обратки вместе это автоматизированно добавляем но здесь уже механика ничего сложного каждый прикидывает для себя каким образом он это напишет мы писали в основном на питоне Ну и получаем что сервисов вот у нас много хост может быть один проблемы нет но мы просто побольше обратно от каждого сервиса на хост накинем от Хоста на каждый сервис по одной обратке этого Хоста сервис уехал хост остался супер Отлично братка убрали до свидания был сервис нет сервис уехал на другой входную замечательно все это делается прямо там же использованием скриптиков и перевезли Ну и как я вас узнаю а я буду в правой руке со своим ПТР стоять рядом со своим хостом довольной все и с этой штукой мы и стали жить вот так это выглядит в базе данных вот пожалуйста У нас есть сервис один инфра СРВ у него есть какая-то прямая запись есть в airp и доменим обратная запись птрк для него же есть какой-то хост srv 00 ну там что-то где-то такое Edition Вот у него есть интерфейс на его базового угла на ip-адрес пожалуйста прямая для него запись пожалуйста обратная но этот сервис живет у этого Хоста поэтому к имени сервисы мы добавили обратную запись от Хоста к имени Хоста мы добавили обратную запись от сервиса теперь простым Джой нам Если мы скажем что имя искомый нам равно имени за братки то есть name контенту и Джой нам это все объединим то мы получим поиск либо в ту либо в другую сторону всегда можем сказать Какие сервисы на Хосте живут или на каком Хосте живет конкретный сервис что получили в итоге но связь код сервис Понятно Мы получили Ну как бы за что боролись на то напоролись это классно Теперь что можно еще все что вы описали в сервисе вот все что вы туда включили хотите количество лампочек на данном Хосте но Заведите отдельный сервис Назовите его лампочки один точка хост точка что-то там и будете фильтровать по количествам лампочек на этом Хосте или по имени Хоста вы всегда увидите этот сервис количество лампочек и будете знать что их там две три пять HD на нем крутится ssd-шки на нем кофе на нем когда кто-то пролил по этому блок питания не работает описали описали Да и в принципе мы можем завязать туда в эту обратную связь все что угодно Мы например еще используем записи публичные То есть у нас есть паблик ip-адреса которая носятся с железок Мы берем обратки для этих паблик адресов вбиваем в нашу базу DNS И теперь когда мы запрашиваем хост то в его обратках мы еще можем Вычитать какой публичный IP на нем сидит и анонсируется забивается это все автоматом и на всю жизнь пока ты это не изменил и это классно потому что в любой момент мы можем знать что у нас досят конкретно вот этот сервак потому что мы знаем по паблику которую попал в видос где этот сервер находится А еще мы знаем Какие сервисы на нем сидят потому что мы тоже Там писали но еще мы знаем что там кофе на нем пролили поэтому блок питания не работает он скоро помрет наверное и надо бы побыстрее это делать все поменять Так что все оказалось связано и самое главное очень быстро и просто теперь о граблях есть грабли Я бы очень хотел сказать что нет ребят грабли есть они есть всегда и без этих граблей вперед идти тоже не получается На что мы наткнулись прямо сразу мелкие огрехи не буду говорить кто-то забыл что-то написать где-то не договорились между командами это мелочи А вот это было интересно а первое что нам выстрелил в ногу дуплетом это сбор логов мы начали собирать влоги и когда например стандартный слог Арси слог слог NG все что угодно начинает писать влог имя машины Он берет ip-адрес которого прилетела и реализовывает его и берет первую обратку которая к нему приходит а у нас хотя бы обратно там может быть много теперь у нас ставите сервисы в обратках у нас там и имя Хоста в обратках и выдаются они повар Денисом в абсолютно разном порядке и завязать это все в единую картину оказалось очень сложным взглянули влоги а там 15 имен они ну вроде бы понимаем и интуитивно Если ты знаешь инфраструктуру но если не знаешь черт ногу сломит нужно чтобы порядок отдачи а браток был всегда один и тот же чтобы он сортировался опять же повторюсь достаточно просто было найти Вот я прям подсветил вам функцию которая за это отвечает в коде у Power DNS это Shuffle мы просто написали свою версию функции Shuffle там буквально 30 строк получилось и теперь она больше не выдает Рандом теперь она выдает список который упорядочен по алфавиту и мы всегда получаем один тот же ответ теперь Security Ну конечно всегда кому-то когда-то приходит без соли к нам он тоже пришел и он нам сказал ребята У вас есть сервисы А вы что к ним присаживаете ну то есть Джинкс И бах туда и Саша мы Нет конечно не ходим а сами закрываем консоли на джикс Саша потому что ходим нам нужны исправлять абсолютно правильно абсолютно верное решение требования мы стали исправлять что по факту нужно было нужно было ограничить доступ между хостами один хвост на другой Пассаж не ходит нам нужна определенная сеть с которым мы можем ходить Везде где хотим Но между нельзя и нужно при этом ходить на сервис по ssh а попадать на хост проблема нет У нас есть инвенторе который всегда можно Джой нам спросить И теперь мы можем обратиться к сервису а попасть на хост но напрямую наверное не получится нужно какая-нибудь обвязочка нужно что мы сделали мы выделили определенную сетку уходим теперь поезд со штока с неё ходим мы только на базовые IP во влани и больше никуда и используем прокси самый простое решение Почему Потому что любом конфиге Саша можно подкинуть прокси команду которая будет выполнять Чего угодно с тем что не пролетела а потом выдавать результат Что делает нас наш прокси команды но конкретно у нас бинарь она через свои 500 примерно так строк кода носи не моего К сожалению я буду стараться она берет сервисное имя которое вы отдали сервису превращает ее в ip-адрес потом у этого ip-адреса вычитывают все обратки среди них находит нужную имя Хоста а оно стандартизированно Мы помним это всегда сапоги его всегда легко найти гребнуть Ну как угодно и уже его еще раз реализовывает твои пешника отправляет твой Коннект туда Ходим на сервис попадаем на хост безопасно вообще огонь только из одной сети Классно А еще можно ограничить всех если ты девелопер из одной команды пришел на этот сервис А в сервисе где-нибудь на втором уровне имени было написано что проект не твой сорян друг тебе к поэму там доступ и там к нам то и файл даб публичные ключи бла-бла-бла и только потом сможешь Вот вам и как бы отстрел вместе со всем остальным Ну и немножко тегов он тут накидал что мы делаем со всем этим с точки зрения юзабилити Я не знаю Был ли Понятно нет но из всего моего доклада очень просвечивается что мы ребята любящий клип Мы прям ком онлайн интерфейс нам не хочется запариваться с вебкой есть чем-то еще мы хотим зайти на сервер и прямо оттуда прямо сейчас обычным запросом чем проще тем лучше получить все что нам надо поэтому мы сделали инвентаре сделали мы его на Агенту мы собрали свои репозиторий большой бинарный вообще мы на Агента живем и Марии ДБ Мы даже любим они майские или как многие и мы решили что нам нужен каким-то образом наши инвентари ходить прямо одной командочкой по большому счету из-за того что мы использовали стандартный Майский или у которого давным-давно все описано потому что мы использовали обычный Join который очень легко впихнуть в любой код мы сделали очень просто в лоб мы взяли engines как прокси мы взяли Апач как в сервер и запустили на нем простенький код на питоне который ходит в базу данных и делает тот самый большой и выдирает все что нам нужно Итого обычный URL из любой абсолютно консоли любого продакшн сервера ходит на этот сервис Ну конечно если он Firewall не закрыт из окружения и выдирает нужную нам информацию хотите по собственно имени сервиса получите имя Хоста Где он есть хотите по имени Хоста Получите его ipmi адрес получите сервисы которые на нем зиждется Ну соответственно просто быстро эффективно когда все горит реально глаз от консолей не оторвать в этой же самой консоли набрать одну простую команду сапоги Если ты знаешь айдишник или набрать простую команду с именем сервиса который ты сейчас чинишь ты его по-любому знаешь от этого никуда не деться это не сложно мониторинг обязательно не мониторишь ничего не знаешь ничего не знаешь не можешь оркестрировать мы мониторим Все мы используем у себя Прометей кстати в прометее Мы заводим каждый хост каждую железку как хост Да мы мониторим еще и cubernets и мониторим под это отдельный разговор но здесь мы говорим про инвенто и про железо Хосты в прометее Да как и в любой системе мониторинга должны быть Уникальны смысл опрашивать 5 сервисов на одном Хосте и получать одни и те же метрики нет нужно спускаться ниже на уникальность уникальность сапоги и айпишник в базовом валане Значит мониторить нужно там здорово круто а как вот интересно мы по моему инжинкс дефис один инфра СРВ узнать что происходит на железке меня там тупит а вдруг потому что Прометей о сервисах ничего не знает графа на сервисах ничего не знает а нет знает Потому что инвентарь Ну похвастаюсь Ну вот собственно ради этого и пилили что мы делаем мы в графане подключаем еще один бэкенд это майские база A DNS это база а там у нас инвенторе делаем простой Join про который я говорил где мы имя используем как контент из обратки и пожалуйста что мы делаем мы вводим ими сервиса который нас интересует Ну хост один инфра СРВ и первое мы получаем имя Хоста на которой она находится а второй хостовые метрики если нам надо теперь как мы мониторим сервисы сервисы монитором отдельно по сервисному IP Но это логично например тот же Джинкс он Ну так себе в Прометей метрике отдает туда мы накидываем ложку и вычитываем метрики уже в нужном нам прометеевском формате именно самого джинсы Так что для каждого сервиса его мониторинг на его же IP А вот для хостов через вот такой простенький Join на нашем классном оркестрация тоже надо надо напрашивается прямо само собой ну то есть мы пришли диплоить сервис А разливать код нужно на Хосты опять же не беря кубернец там вся сиди свой а если мы льем на железо Ну что-то у нас такой stateful там еще находится и Казалось бы блин перечислять всех асты вести вот это вот все но это все как раз решилась вопросом с инвентаре мы просто в баше побосятски из глины веточек накидываем тот же самый SQL Select с Join в базу данных и получаем динамический инвентарь для антибула А мы любимцы был в основном Академ Да у него есть свои недостатки но нам вообще все нравится экспертиза в нем огромная мы как бы понимаем как оно работает Нас устраивает так вот один раз написав вот такую простенькую конструкцию и скармливает туда например имя проекта мы получаем все машины по нужным проекту скормив туда еще дополнительно имя сервисов которые ты хочешь можно получить метаданные для antible и катить по принципу сервисов их по их принадлежности вы видите просто еще одну переменную туда и получаете в метре Не только hastwar но там еще что-то что вас интересует и нам это тоже зашло и нас это более чем устроило и регистрации вот в таком виде нас прямо очень порадовала по поводу cubernet есть отдельный интересный кейс Наверное мы к этому придем и попробовали нас вот что за бомбило значит представьте себе кластер кубера админ к etcd и вдруг все упало это CD нету все забыли о нем админка не работает ваш кьюб ctl похоронили можно не использовать но А собственно ноды это крутится сервисы крутятся поды крутятся слава Богу спасибо губерницу Вот он ради этого и живет что оно все как бы где-то там но только вот где теперь какой под На каком Хосте на какой ноде А как он приходит к конгрессу а что вообще с этим все делать мы попробовали и наверное будем в этом направлении дальше развиваться у нас самописные ПВС модуль для cubernate и в этом само описанном модуле мы накидываем имена в DNS для каждого пода сами соответственно мы регулируем их имя поэтому там нам не составляет труда Каждый раз при диплои на какую-то ноду еще и вбить обратку и когда легло все мы в любой момент можем сказать На какой конкретно крутится определенный под Ну курул вот это все новые поняли да там вот и по красоте значит что получили того мы получили отказываю устойчивую инфраструктуру DNS Но это мы обговорили нас доносят Мы живем бла бла и делегировать Мы научились тоже классно еще вам обслуживаем это все в Real Time И вообще прямо замечательно Теперь у нас есть еще и инвентарь с привязкой кв если нам нужно и очень просто масштабируемые самое главное просто используем и в один клик из консоли я все остальное Ну и мониторинг и acl и там же это все можно использовать также эффективно и красиво Так что спасибо вам большое у нас еще будет metab tbd приходить туда Может увидимся Ну и Welcome с вопросами Спасибо за доклад это было круто Лично мне очень понравилось и есть один вопрос Можешь ли ты назвать что было самое сложное при проектировании или внедрении вот все это большой обвязки DNS такого крупного сервиса Прям самой обвязки самой обвязки но на самом деле мне кажется сложнее всего было как-то переломить себя Потому что DNS это как DNS Ну то есть она уже сервис она что-то делает и представить то что он может делать что-то еще было сложно поэтому идей было не так много приходилось несколько раз собирать команду обсуждать каждый вопрос смотрите мы там хотим Вот это в DNS внутри Еще поковырять мы сейчас говорим она все рассыпется и Мы начинали каждый этап с того что обсуждали Если я сейчас вот это и она сломается что будет увольнение будет или там или мы живем Вот вот самое сложное было Вот здесь скоординироваться Мне кажется это большая тема для обсуждения Я хочу пригласить всех наш уютный уголок для дискуссий уголок номер два всем всех ждем Спасибо"
}