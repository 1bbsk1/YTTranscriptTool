{
  "video_id": "S3-qcogTeBk",
  "channel": "DevOops_conf",
  "title": "",
  "views": 0,
  "duration": 0,
  "published": "",
  "text": "Привет зал меня зовут Антон я из Купера И сегодня я буду вам составляйте помогать с тем как Дима проведёт свой доклад Дима Мой коллега Кто здесь в зале знает что такое кубернетес о а кто знает что такое оператор кубернетес тоже много а not про детектор есть пара человек трое хорошо Ну вам тогда стоит послушать Диму Дима Всем привет что происходит когда что видит клиент Когда происходит отказ одного узла то что приложени продолжает работать принимать заказы А когда 10 узлов выходит из строя что клиент видит всё тоже самое приложение работает и принимает заказы А когда целая зона доступности выпадает Неу жен видит с заметил и продолжал пользоваться нашим приложением и делать свои заказы Но со стороны инфраструктуры не всё так радужно возьмём например показатели S каки и видим что доступность брокеров начинает скакать в это начинает увеличиваться и приложение которое с ним работает также начинает проседать начинается небольшая деградация соно бюджет ошибок ви и приходит к инфраструктуре Можно ли уменьшить Дан окно деградации со стороны инфраструктуры Да можно как сегодня в моём докладе для начала немного компании компания пер была появилась в этом году чем появилась она не с пустого места был проз остались компании поэтому можно сказать что - это супер значение кубер для нашей компании Мы стремимся к архитектуре CL агностик и у нас существует правила kubernetes First оно говорит О чём о том что все приложения сервисы которые мы разрабатываем внутри компании а также те сервисы которые мы приносим из вне компании должны быть запущены в кострах кубер наша продавая инфраструктура запущена в кладах в одном регионе присутствует в одном регионе в пяти зонах доступности и на данный момент продакшн кластеров у нас более 15 в среднем чтобы было понимание что такое кластер соответственно в нём крутится более 10.000 подов развёрнутых на более 250 нот кроме й приложени у на есть приложение которое мы начинаем вать в этом году активно сервисы между собой имеют сообщения как между собой так и с другими кластерами при помощи ш сети чтобы говорить на одном языке я веду термин отказ узла Будем поднимать под отказом узла события приводящие к невозможности запускать новые поды либо использовать текущие поды что приносит отказ узла в нашей экосистеме да для этого мы позовём наш мем Даша привет А который поможет найти свою абстракцию Где же произошёл наш сбой современных клауда как мы и знаем а есть архитектура на базе бара метала на базе виртуализации на базе контейнеризации но когда мы используем а менеджмент сервисы такие как кубернетес у нас появляется полная микс всех технологий и попробуй здесь разберись а где же произошла на самом деле проблема для того чтобы разобраться и как-то упорядочить классифицировать Список проблем Мы собрались отделом всем отделам соответственно проанализировали свой опыт у нас есть прекрасный инцидент менеджмент процесс внедренный соответственно мы собрали все все инциденты за 2 года и уяли их на Первом мее частые проблемы которые у нас возникали - это отключение узла вызванные отказом либо сбоем оборудования и плановые работы прямо вот в топе которая постоянно находится на втором месте - это Фриз виртуальной машины Что такое Фриз когда виртуальная машина переносится с одной хост системы на другую происходит синхронизация состояния памяти И в этот момент происходит фриз а в этот момент NC всё выглядит как так как будто всё работает Нон у приложения начинает идти стремительно вверх на третьем месте проблемы с памятью вызваны как вызваны зачастую её нехватки соответственно следствием этого у нас есть состояние Ша и сист Killing Может случаться на четвёртом месте по частоте это сетевая недоступность а именно изоляция ноды Что такое изоляция ноды зачастую чаем с этим когда новая нода выезжает и попадает в некое состояние когда вроде бы у неё есть доступ к I серверам но теряется доступность со всеми остальными санеми и другими сервисами либо же при миграции виртуальной машины она попадает на железную ноду которая также заизолировать прочие проблемы вызванные нехваткой идентификаторов и Зомби процессами А собрав и классифицировал отказы мы поняли что 80% проблем связанны с недоступность у зла А все остальные проблемы - это проблемы на уровне узла зная это мы поняли на что стоит обратить внимание сконцентрировать свои усилия и решить соответственно методы выявления отказа узла возможности из коробки Так как кубес уже продуманная система что она собой позволяет сделать для начала за отказ узла у нас отвечает два компонента со стороны ноды у нас работает кубит отправляя сообщение о том что с Ной всё хорошо каждые 10 секунд нане работает 5ку сообщение от лета В случае их недоступности отсутствия вернее запускается следующий таймер описанный параметром и составляет он 40 секунд течени 40 секунд что происходит нода помечается как недоступная у неё меняется но здесь остатся активной соответственно трафик приходящий с наших лансе с других сервисов также перенаправляет на недоступный узел на недоступные поды Хорошо если у нас есть рекер и другие технологии позволяющие отлавливать эти проблемы и наш клиент не видит ошибки что что-то не так После истечения 4 секунд наступает сюй тай таймер в течение после которого наши поды на упавшем узле начинают вытеснять спустя 5 минут это происходит А как мы это видим видим Мы это следующим образом что а лоды начинают Термини и начинается процесс планирования на доступных узлах где есть для этого ресурсы но не всё так радужно для йф сетов поды зависают и ж ждут когда нода восстановится и пока мы не предпримем ручные действия она так и остаётся в этом состоянии как можно повлиять на этот процесс для это решение можно взять и поменять эти параметры Их всего три и достигнуть тем самым уменьшения времени с 5 минут 40 секунд до до 50 секунд на представленные а таймера но здесь есть нюанс Он подходит только для небольших кластеров потому что как вы сами понимаете увеличение частоты сообщений и частоты проверки ведёт к небольшому Ну всё же дедос IP серверов если у нас сервер большой это может вызвать серьёзные проблемы Что же делать существует достаточно простой недавно появился достаточно простой и рабочий способ Он подходит как для больших кластеров так и для менеджмент ксеров в значени toleration мы можем включить опцию toleration Seconds указать то количество секунд которое под должен оставаться на ноде при объявлении того или иного тента При этом если мы возм пример за основу то мы также сокращаем время с 5 мину секун до 1 минуты данный способ можно использовать не только для уменьшения времени но также для его увеличения Например у нас есть какие-нибудь кейсы для приложений когда мы хотим подождать возможно нода вернётся На сегодняшний момент существует сем тентов описываемых состояние нашей нашего узла нашей ноды которые мы можем использовать в данном примере для повседневного использова в шем кластере 126 версии курса появилось специальный который так и звучит Out Of при указании которого у нас происходит моментальное очищение всех плодов включая с нерабочего узла второй метод по частоте использова внут узла менять и также отдавать все свои параметры через проте метрики зачастую детек входит в состав менеджмент решений большинства облаков принцип его действия достаточно простой он парсит логи наших компонентов ядра системы опен Ири позволяет запуска скрипты и приложения изнутри себя которые мы ему зададим с той периодичностью как мы ему зададим на этом слайде представлен те модули которые мы используем и которые нам помогают в обслуживании наших ксеров зани ра Перов Это для нас является настоящей проблемой по той причине что зачастую мы о них узнаём после того как они совершили и соответственно уже как бы отказала восстановилась и мы только об этом узнали чтобы этого не происходило большинство крупных операторов внедрила модуль провер зани на самом деле достаточно простой операторы через Мета дату создают события о том что предстоит какие-то работы с этим узлом с этим узлом после чего конди меняется он от проб детектора и мы можем применять какие-то действия от оповещения команды до каких-то автоматических действий для существует моду соответственно мы можем его использовать отдельно либо собрать с его использованием у российских операторов Ну можно заметить что Яндекс в этом году выпустил тот же самый функционал через мето дату он публикует события которые предстоят с этой Ной но к сожалению пока дете Да функци неста с може сами включить в принципе получать все оповещения со стороны меда и изменения конди третьим методом являются операторы Мне очень хотелось бы рассказать о Проекте MX достаточно интересный проект у него совокупность около ше операторов но сегодня я расскажу о двух а тот кто пишет некий аналог самостоятельно советую приглядеться и взять за основу его алгоритмы Итак кратко по алгоритмам а snation при доступности IP сервера со стороны узла приходит в IP сервер и спрашивает жив ли я Откуда он получает эту информацию существует дополнительный сервис Check который проверяет все ноды чем-то его функционал схож с контроллер менеджером встроенный внутри кубернетес но тем не менее а при доступности IP узла соответственно Мы спрашиваем I IP сервер если у нас а есть какие-то сомнения мы а соответственно А с узла идёт обращение на соседние узлы и соседний узел узел B Также идёт в апе а спрашивает а доступен ли этот узел и при утвердительном ответе ничего не происходит если узел недоступен то узел перезапускается признаётся сбой если I сервер недоступен то происходит примерно всё тоже самое И происходит всё тоже самое И при недоступности а сервера и подтверждение это со стороны других но происходит перепуск также с других узла либо большего количества узлов которые задаётся специальным параметрам узел признаёт себя действующим и соответственно никаких событий не происходит Просто он ожидает то что AP сервер вернётся и всё заработает в цикле если узел заизолировать ни соседние ноды а-а то он как бы видит понимает что он заизолировать путём перезагрузки для узлов конп существует подобный механизм за исключением того что в случае а если большинство Work Note признаёт его недоступным а то он запускает процесс самоконтроля проверки целостности работы кубит и в случае непрохождения данных проверок он соответственно также себя пытается перезапустить в случае в случае если он не досту не получает доступ к соседним узлам ксер он признаёт себя также заизолировать процесс перем с ним все Зен который делает на самом деле две вещи следит за изменением статуса ноды и второе соответственно при помощи агентов пытается первое либо перезапустить ноду железную например к примеру исполь различные Виту е какие-нибудь системы и соответственно заизолировать и Восстановить всё это настраивается кроме данного оператора существует ещё один оператор который делает почти тоже самое но опирается уже на состояние со стороны кубернетес состояние доступности но и при помо приведено на этом слайде то что агенты Он поддерживает соответственно пытается также перезапустить либо удалить и заново создать наш узел в случае виртуализации Как видите он поддержит большое количество железного оборудования серверов систем виртуализации и с ними работает а е один оператор который наверно всем известен соответственно его основная функция - это следить за статусом за лами узла и в случае их нахождения происходит автоматический Кордон ноды для для отделов эксплуатации хотел бы предложить ещё на рассмотрение один оператор А благодаря ему можно декларативное о том что мы хотим сделать какие-то Main работы с нодом Main происходит тический её и после этого мы можем совершать запланированные действия четвёртый метод это метод на базе Рик раз у нас есть слово метрики Значит у нас есть где-то проте либо Victoria Matrix и Alert Man для примера я взял проект который написан ф Соответственно что он делает он смотрит события в алет менеджере и в случае нахождения их а соответственно навешивается not Condition А на ту ноду которая у нас пришла в алер и дальше при помощи райно соответственно эта нода может дрейнить Либо мы можем делать какие-то дополнительные с ней действия аэ мы обсудили Как уменьшить время определения свой узла соответственно Как быстрее выселять наши поды Но что же делать когда большое количество подов начинает запланировать и начинается расселяться По но по уже имеющимся узлам если у нас не кастом шедулер то на помощь к нам придут приорити классы Кто считает что приорити класса вы функционально Используйте и всё с ними хорошо у вас А почему я это спрашиваю потому что у нас ушло на это чуть больше года чтобы начать их использовать эффективно и они нам стали реально помогать Итак приорити классы зачем они нам нужны благодаря им у нас происходит приоритет при вытеснении подов соответственно приоритет при планировании подов и в случае нехватки ресурсов на уже имеющихся узлах благодаря приорити policy сервисы с меньшим классом вытесняются и на их место приходят сервисы с большим классом тем самым мы добиваемся управляемой деградации приложение Mission Critical Bus Critical всегда у нас продолжает работать в том количестве которое мы запланировали если сравнить подходы в то встроенные возможности хороши тем что они встроены присутствуют С каждом инсталляции ку Бернеса но плохи тем что Вуд решениях они не позволяют фиксировать оповещение операторов и неправильная их настройка параметров может привести деградацию нашего сервера детектор соответственно фиксирует проблемы внутри узла работает с к операторами достаточно модульный и можно его собрать под свои нужды Но работает пока узел у нас доступен и также из-за своих особенностей ребут повышенные привилегии безопасно оператора ши могут большинство задач взять на себя но здесь же и минус нету одного идеального оператора который может сделать всё за Вас решения на базе метрик хороши своей простотой но здесь же и минус то чтобы они работали нужна уже готовая система по сбору по сбору и работа с метриками а также должно быть что-то что генерирует эти метрики плюс к этому для какойто автоматизации потребуется оператор э я взял для сравнения нашу первую таблицу где мы оценивали все факторы выхода узла из строя перенёс на них соответственно наши методы и Как видим ни один метод не покрывает полностью все факторы и для того чтобы обеспечить эффективный контроль а узлов а нужно совокупность методов одного двух ТХ чех зависит от ваших кейсов но мы пользуемся как минимум тремя и присматриваем к четвёртому Ага для напоследок я составил чек-лист который по моему убеждению должны позволить уменьшить влияние инфраструктуры на ваш сервис если кто-то ими не пользуется пожалуйста прийдите на своё рабочее место послезавтра и проверьте Пользуйтесь ли вы ими Итак начнём а для того чтобы гарантировать что ваши виртуальные машины гарантированно планировались на разных стойках для у каждого оператора есть понятие Group соответственно благодаря ей ши виртуальные машины запланируй и запланированные работы оператора будут затрагивать не сразу все ваши виртуальные машины а как сле как правило по одной со стороны кластера для того чтобы обеспечить распределение ваших подом по зону доступности необходимо использовать который как раз таки этим существует У нас под affinity Да и для гарантии доступности определённого количества подов нашего сервиса У нас есть подди бюджет и как ранее говорил для ускорения запуска и выселение подов при ка любых авариях У нас существует приорити клас Спасибо за ваше внимание Спасибо Дима на самом деле я сделал большую ошибку я не объявил о том что у нас есть QR код где можно обсудить доклад поставить докладу оценочную сканируйте QR код Проходите в чатик Да делайте там всю эту активность А пока мы поговорим с залом после этого посмотрим что произошло онлайн так зал Ели у вас вопросы вижу руки кто мне поможет принесёт микрофон класс Я могу сам спуститься Давайте да здравствуйте Здравствуйте доклад прекрасен всё по теме отлично вопрос следующим и Кордон и ребут - это довольно-таки радикальные меры приводило ли это к шторму И как долго Как много времени у вас ушло на то чтобы балансировать такой подход Да это радикальный способ но зачастую он наиболее действенный соответственно чтобы привело это к шторму нужно как минимум вылить Ну зону доступности Да и При таком шторме мы защищаемся нашими приорити классами которые соответственно за счёт приоритетов что-то вытесняют то есть приводит к прогнозируемой деградации и те приложения с большим классам Дули планируется быстрее и соответственно продолжает работать обслуживая основные функции нашего приложения соответственно менее приоритетные сервисы вытесняются и ждут того момента когда появятся свободные ресурсы они спокойно запланируй Хорошо спасибо Вот вот молодой человек Здравствуйте спасибо за доклад очень познавательно много нового узнал вопрос примерно из той же оперы А как вы боретесь с бутлуп ять не может Достучаться до IP сервера не может Достучаться до другой ноды и опять уходит ребут и второй момент что как у вас реализован механизм ребут происходит он ребут или он софт ребут То есть если у вас превышает долго не переезжает не будет ли такой ситуации что вас просто не успеет переехать и его один из ваших операторов просто ребут ноду и ВС и чи деградация уже начну с конца отвечать наши операторы как минимум присутствуют пере переизбрание лидера Да которая может э перехватить на себя все процессы и начать Отвечать по поводу ребут Да если нода ребутнуть и также продолжает недоступно происходит ли Цикл А я привёл за пример а операторы проекта а забыл В общем за пример взял оператора который как раз-таки и может сам себя координировать запускает этот цикличный ребут или нет за счёт того что он проверяет доступность копи серверу к другим нодамэ I сервер начнёт отвечать Он сейчас за досин Да и сервисы которые продолжают в м работать также продолжают работать и обрабатывать трафик как-то Так ну по по баджет уточню Я имею в виду какая-то полезная нагрузка тот же например постгрес который Т сете сидит ему надо отключить ноду у вас там раз у вас КД это у вас скорее всего какой-то там ebs ч соответственно надо как-то грохнуть pvc переехать на другую ноду и там запуститься вот меня вот это интересует времени Я вас слышу с большим эхом просто и не все слова улав Если можно мы можем потом дискуссионное вопросы там более точно обсуждать более долго у нас дискуссионная зона есть а я пока задам вопрос из онлайна как мониторить работоспособность самого проблем детектора что он функционирует есть прекрасный механизм чеков просто обшить хол щеками хорошо И второй вопрос от того же автора Есть ли варианты починки кроме перезагрузки может выполнения какого-то скрипта какой-то рутины ещё раз кроме починки кроме перезагрузки собственно узла детектор любого Ну про оператора например вот для этого существуют как раз таки НН агенты которые могут не только тить но и управлять вашим оборудованием железным сервером коммутатором системой виртуализации железным хостом чем угодно то есть модули на любой вкус и цвет что говорится всё зависит от того какую логику вы в него ложите и можете использовать спасибо А ещё есть вопрос в первом ряду Здравствуйте Меня Сергей зовут мы на самом деле с Димой работаем вместе я бы хотел одну вещь прокомментировать и вопрос задать Вот прокомментировать про приорити класса что на самом деле штука действительно страшно по поводу внедрения и если вы не отслеживается опасные синхронные связи которые как бы каскада в отказ других систем то при класс могут усугубить ситуацию что вы как бы вообще не получите какое-то низко приоритетное приложение в ран тайме А из-за того что его не будет вы будете продолжать не работать и с этим надо будет бороться Поэтому с внедрением аккуратно Но это неважно потому что вопрос от уточки уточки вопрос Нужны ли какие-то страшные права для работы вот разных типов либо опера Смотри Нужны ли какие-то страшные права в кубернетес Да как бы какие-то политики дополнительные как для операторов так и для агентов которые в целом Ну вот были какие-то подводные камни со стороны по поводу их внедрения может быть они слишком высокие имеют привилегированный режим можешь ли про это рассказать подробнее конечно вопрос безопасности стоит на первом месте зачастую наш тот же детек работает в System для которого мы стараемся ограничить права доступа и максимально точечно их нарезать в этом нам помогает служба безопасности активно но как я отметил в плюсах и минусах что у операторов что у problem детектор есть такая проблема И соответственно её нужно грамотно подходить и решать именно точечно а не давать всё что запрошено по умолчанию Спасибо так кто-то ещё из зала может нука О да пожалуйста Да Дима Спасибо за доклад У меня вопрос по связке мониторинга и управлением Ну ат менеджером Да каким-либо а вос как контролируется что недоступен именно узел а не например мониторинг то есть Что будет если А менеджер Получи Ну от мониторинга что у нас нет метрик будет считать что узел недоступен при рабочей связке мониторинг плю амер но доступность узла будет для рабочей нагрузки мы получим перезагрузку тогда при рабочем музы проверки присутствуют я понял Понял Вопрос схож с другим автором вопроса смотрите здесь нужно разделять тектор смотрит состояние внутри узла Да соответственно пока узел работает он соответственно что-то делает мониторинг здесь не подключается не работает система мониторинга опираясь на метрики вашего проса либо витори кото здесь нужно разделять события внутри системы и внешняя недоступность узла соответственно у нас больше интересует внешняя недоступность узла По той простой причине что по той же теореме ка Да недоступность узла по сети либо его полностью отказ как бы он сгорел Для нас это Словно как бы его отсутствие недоступность В итоге уе компоненты кото по отношению ко всему кластеру есть операторы которые могут выборочно следить опираясь на различную логику доступности узла с разных компонентов нашего кластера и соответственно система четвёртый тип - это система на базе мониторинга Где наш наша система мониторинга может признать по какому-либо событию То есть вы заложите эту логику что данный узел нен и тогда благодаря автоматизации это этот узел будет исключён из эксплуатации и соответственно на нём произойдёт драйн дй - это не всегда прямо узел должен быть доступен и соответственно мы его вызываем Это чисто событие са сервера супер спасибо и появился ещё один вопрос из онлайна А спасибо за доклад тебе передаёт Максим сандалов и говорит актуально ли информация Это для Drop Up для кого ха Drop могу сказать не сталкивался с ний Ну мы не знаем да совместимо это решение или нет но скорее всего если там ванильный Куп никаких проблем с этим быть не должно ставьте операторы ставьте ПД настраивайте и пользуйтесь супер спасибо Мы Я выбрал абсолютно подходящие технология для каждого кубернетес будь со hosted либо менеджмент кубернетес в каком-либо клауде Большое спасибо Дима за доклад Спасибо аудитории"
}