{
  "video_id": "iTJpGa3W0xc",
  "channel": "HighLoadChannel",
  "title": "Chronicle Map — key value хранилище для трейдинга на Java / Роман Левентов (Chronicle Software)",
  "views": 1100,
  "duration": 2478,
  "published": "2017-04-08T14:07:34-07:00",
  "text": "коллеги добрый день у нас начинается следующая секция будет рассказано про несколько собственных наработок в области баз данных и про video streaming начинаем мы с с романа ли винтовок это нормально произнес на миллион который расскажет нам про собственную базу данных на джаве давайте послушаем сразу хочу спросить какая часть аудитории работает на джаве пишет enterprise система почти все это хорошо еще об ожиданиях доклад не маркетинговый доклад технический инженерный и он даже несколько про chronicle map сколько вообще про дизайн эффективной да это processing system и памяти в пределах одного сервера но в пределах анонсирование в смысле что система вообще должна ограничивать сервером а просто на уровень костяной к вопросов я не поднимаюсь только совсем чуть-чуть расскажу про совсем чуть-чуть расскажу про репликацию ну тоже в контексте работы на одном сервере доклад чем-то перекликается с вчерашними докладами кости осипова и александр крижановский он чуть менее хардкорный больше на таком концы концептуальном уровне идейном вот пару слов о себе я работаю в компании chronicles of твоя компания не российская компания британская мы помогаем писать высокопроизводительные системы на джаве основные клиенты из таких областей как финн тех тройник такие как инвестиционные банки брокерские конторы еще из областей вставочного бизнеса и туризма мы написали open source на key value хранилище в памяти хроникам up 2.0 hub у сразу первый вопрос который должен возникать когда кто-то сейчас говорит о каком-то новом теорию хранить и конечно же это зачем потому что уже есть десятки а сепеда выяснилось что для специфической домены области тренинга не подходит ни одно существующий опыт собственное решение класс source на вершине есть возможно что-то из областей про которые передо мной рассказывал алексей рагозин так вот какие специфические требования выдвигает область трейдинга ну первое это задержки те кто последними реагируют на какие-то рыночные события теряют деньги вы наверное слышали истории про то как трейдеры тратят какие-то абсолютно сумасшедшие деньги на то чтобы оптимизировать инфраструктуру на то чтобы по дну атлантики проложить новые новые оптоволокно которое там меньше километров в длину поэтому леденцы между нью-йорком и лондоном между основными биржами меньше поэтому обычный реляционный б д это вообще другая вселенной абсолютно то есть там в пенси совершенно другие ну в основном конечно потому что они ненадежны и durable но не только поэтому потому что там есть парсинг и сколь ну ладно парсинг искать там план запросов так далее не было на этом останавливаться out of просто скажи таких как радиус тоже не подходит об этом я буду позже говорить и что тут предлагает chronicle map медиальная задержка меньше 1 микросекунды естественно это задержка внутри одного сервера задержка между селами меньше одно микросекунда не бывает следующее требование домены области это такое явление что у нас есть много источников событий из разных процессов ну простой пример типичный кейс для брокерской конторы это агрегация данных из нескольких бирж то есть виды событий приходят на разные сетевые карты обрабатываться в параллельных процессах но я хочу поговорить о том зачем еще может быть нужно обработать за разных процессов даже не в области трейдинга то есть да какие сейчас есть тренды в железе да очень просто это у нас есть куча памяти и нагасаки этой машины поэтому есть такое явление как ну ма ну а ну миру уже на этой конференции не говорил только ленивый правда и ни у кого не было такой красивой картинки если в двух словах думаю это разделение памяти между сокетами и обращения к памяти чужого соки это на 30 процентов медленнее представьте себе вот такую вот архитектуру точнее архитектура железки да есть двинул аноды количество какое-то ядерное каждый нам аноде и работают какая-то здоровая при kumho на всю эту систему и обращение к памяти какие-то рандомные более-менее поэтому примерно половина обращение к памяти будет ко сну память будет к чужой нам аноде то есть красными стрелками обозначены дорогие обращение к памяти а если архитектура системы такого что приложение более-менее изолированы в рамках каждой numa но да то есть в рамках сокета то они в основном обращаются к памяти своего соки это если есть какой-то шарит стоит ну к нему может гораздо меньше обращений поэтому просто на такой топологии архитектуры которая совпадает с топологией железо можно выиграть до 15 процентов 30 процентов эта стоимость пинать еда для обращения к чужой numa ноги но уходя от таких абстрактных материи как просто процессы чуть ниже проживем зачем может понадобиться делить живем на несколько отдельных то есть васи была одна большая живем на сервер и вася зачем-то разделил ее на 2g м стала 2 маленький gm который через шарит стоит как-то общаться зачем это может понадобиться первое это сборка мусора очень просто чем меньше хип тем короче пауз сборщика мусора если есть один хит на 50 гигабайт будут одни паузы сборщик мусора из 5 типов на 10 гигабайт каждый там будет совершенно другие паузу сборщика мусора но пауза это вообще не про трейдинг поэтому да вот это пауза это не про трейдинг нас немножко другой случай бывают latency critical path системы которые вообще не генерирует мусор потому что они могут себе позволить уходить в какие-то пауза сборщика мусора если живем процесс один-то а какая-то другая подсистема она менее критично полотенце и она генерирует мусор джем не умеет устанавливать какие-то одни потоки и позволять продолжать работать другим живем остановит все потоки поэтому чтобы избежать пауз в леденцы critical по системе ее надо выделять в отдельную живем и бонусом к этому выделению ее в отдельных живем которая не генерирует мусор на этот живем можно сконфигурировать сборщик мусора который имеет более дешевый барьер на запись то есть сконфигурировать сборщик мусора который допустим не тратят время на карт marking при записи референсов потому что он вообще не не генерирует но своему это не просто не надо следующий момент такой на мой взгляд мой любимый в этом в этой презентации следующая причина зачем можно разделить живем на две части и больше это компресс tubes кому тут надо объяснять сколько компресс tubes кто не знает эту аббревиатуру хорошо компресс понятно с сжатые упс множественное число то есть опыту когда не объект на реке рынка hamel не а у ordinary обжиг пантеры то есть это просто ссылки сжатые ссылки в 6 ч 4 битном живем процессе ссылки ну пойди должна быть и 64-битные но если хип занимает меньше тридцати двух гигабайт их можно можно сжать до 4 4 по и 32-bit ну вообще четырьмя байтами можно адресовать 4 гигабайта памяти но за счет того что все объекты выровнены на границу 8 байт то можно адресовать 32 гигабайта hippo поэтому если да вот это такая возможность но если хип больше чем 32 гигабайта там нельзя применяйте зажаты ссылки там будут нормально 64 битной ссылки но мы можем разбить этот хит на две части и тогда каждая частей каждый учитель уже в свою очередь можно будет применить сжатые ссылки компресс tubes и выигрывается дополнительное пространство дополнительная память ну еще одна такая причина зачем можно зачем может потребоваться разбить живем это конфигурация на уровне ос в первую очередь это привязывание процессов к определенным я драм прием сокетом affinity и назначением приоритетов это то что позволяет избежать систем джиттер так называемый то есть когда а персона система случайно в какие-то моменты вытесняет этот процесс которую latency critical должен работать и возникают паузы это то прошло очень любят рассказывать питер лари мой коллега жил тени из азула и я тут ссылку не успел сайт прошла недавно конференция стран глупые там чувак из максик женщин тоже про это очень хорошо рассказал посмотрите найдите в интернете страниц глупо там макса костей про то как это конфигурируется них и как они уменьшили систем jitters этот очень хорошо сказал ну и еще с groups конфигурация можно настроить там с vapenation не знаем что угодно изнутри java процесс это достаточно сложно делать если вообще возможно не 3 такая специфическая особенность тренинга на которой хотел бы остановиться это час да не третье пока так что насчет источников событий из разных процессов не подходит из-за этого требования такие решения как сказал каст большинство других и номере деток рядов map тебе хотя они могут быть сопоставимы полотенце с кроме clamav но они поддерживают доступ только из одного процесса ну и соответственно хроникам а поддерживать доступ из разных процессов и хорошо масштабируется по записи на любое количество ядер системе но и на чтение тоже естественно и вот 3 3 специфическая особенность это очень большая через обновление базы то есть вебе в в комиксе в соц сетях типичное соотношение чтения-записи добывает там 90 на 10 80 на 20 бывают конечно в райт intenser враг ладу но это более редко большая редкость то есть что мы имеем и это в связи с вопросом репликации представьте что приходит 200000 каких-то событий на серым они сами события могут быть не очень большими но они затрагивают в его или хронической то развесистые стоит допустим на 3 килобайта этот достаточно приближенной к реальности цифры то есть это уже даёт и это надо реплицировать между нодами если в классе на конфигурации это уже дает трафик 5 гигабит если вам кажется что это можно реплицировать вспомните что это только в одну сторону нужно еще в обратную сторону то же самое пересылать потом вспомните что это репликация только на одну ноту когда индустриальный стандарт это как минимум реплика фактор 3 да и причем одна из нот должна быть не в том же дата-центре еще вспомните что это только репликация это без учета входящих запросов каких-то исходящих то есть но это вообще просто так не работает сеть просто не тянет такое количество обновлений поэтому нужно как это фильтрация обновление фильтрация информации которую надо реплицировать но фильтрация нет такой а что вот это мой реплицируется на этом и вообще забиваем надо поддерживать какой-то прогресс по всем там ключам key и value базу ну то есть хроникам об тоже адресует этот кейс его решает вот и на этом месте у вас должно возникнуть должны возникнуть вопросы потому что я вам толкаю вообще какую-то дичь потому что ну так не бывает все так классно чем подвох знаете такая старая еврейская мудрость что если вам кажется что у вас никто не обманывает то вы должны очень сильно напрячься потому что это значит что кто-то обманывает вас так что вы этого не понимаете то есть что то тут не так ну не так то что охранником об вообще ничего не гарантирует практически мультики запросах хоть они есть и они даже изолированы но они не от амарны база не дергал естественно ну your apple нельзя обеспечить с требованиями палит нещадно микросекунду это очевидно там flash и ты уже минимум там не знаю сколько 50 микросекунд записи на flash и только синхронной аппликации опять же синхронно репликация микросекунда не бывает даже на сервер находящийся на соседней стойке репликация занимает не знаю сколько десятки микросекунд если не сотен вот мы поговорили о том какие требования поставлены базе данных какие требования не поставлены это тоже важно знаете как в java enhancement proposals есть графа голос и non голос из целей это что не цели это всегда очень важно понимать что вы не хотите делать чтобы эффективную систему построить а теперь я расскажу как то есть какие приемы как это как добились вот хотя бы тех цели которые мы поставили 1 как организовать доступ из нескольких процессов в базе данных первый вариант стандартный это убег сокеты примерно так выглядит эта картинка то есть есть процесс базы данных он эксклюзивно обращается к памяти базе данных и обращаются клиенты общается с клиентскими процессами через сетевое не сетевой системы интерфейс то есть lubeck или соки да вот в чем минусы этого подхода 1 ну это системные вызовы до 1 системный вызов стоит сотни наносекунд там сто-двести это два прерывания в начале ведро из ядра 2 2 смена 2 смены дескриптора сегмента туда-обратно двадцать две смены стека туда обратно то есть это обеспечение изоляции тернова с прессой и визерса и держим в уме да что мы хотим добиться ладно себя 1 микросекунда то есть 1000 наносекунд мы уже 20 процентов десять-двадцать процента потратили если вам кажется еще что это можно терпеть то вспомните что на один запрос надо сделать четыре системных вызовов то есть системным язык чтоб положить допустим socket там запрос системный вызов чтобы на стороне базе данных забрать запросы соки то потом на стороне базе данных положить ответ забрать ответ 4 штуки если пытаться как-то это амортизировать то есть там не знаю 234 запроса укладывать в 17 вызов что это само по себе бьет полотенце потому что мы уже будем значит ждать выполнение всех этих запросов это еще еще больше ухудшает в этом все следующий минус это множество лишних копирование данных вместо того чтобы допустим напрямую общаться с памяти базы доставать напрямую работать со значением давки и вылью напрямую обновлять значением прямо в памяти базы мы копируем память в какую-то какие-то буфера внутри ядра и потом к первым из ядра ну даже тут наверно можно было написать 1 то есть минимальное количество лишних копирований одно если есть на какой-то из сторон zero копия aaa ну во-первых zero купе areva не работает как уже он тоже говорилось во вторых но это это серовно теория эта теория на практике если у вас есть там не знаю как у матери this instance и он общается с обычным с обычным драйвером на стране джавы то я могу смело сказать что он будет не знаю 5-6 лишних копирования данных абсолютно ненужных с места на место и есть самое главное есть просто какие-то задержки которые вот они есть этих интерфейсах добавлять полотенце там какое-то количество микросекунд 1 2 3 я не такой спец по этой области то есть я не могу жонглировать там терминами кира но space а что там происходит почему откуда берутся эти задержки тут есть куча специалистов на эту тему просто я видел на практике что даже на абсолютно тихой машине где ничего не крутится попытаться добиться минимальной задержки вот при общении через lubeck все равно есть какие-то иногда в этой цепи китам 10 микросекунд ну и так поэтому по этому принципу дал убег или соки это работает сладкая парочка вот и традиции win cash ну другой способ общения процессов от разделяемая память здесь два варианта либо разделяемая память реализация самой базы так доноси написано и ежа вы мы вызываем итачи реджиной либо напрямую на java с помощью интерфейса саннис конце iv то знает штука санги в конце хорошо ну те кто не знают это просто такое убогое подмножество сессии на стороне джавы то есть можно на самом на самом деле java это в каком-то смысле над множество си java не обязательно там общается нет и память и так далее как это выглядит схематически память базы данных является как бы им процесс для всех процессов которые обращаться база данных только случайная происходит общение через зная прослойку случае конце iv как бы без прослойки все это работает чтобы вы выбрали для реализации кто за джиной кто хочет реализовать на джиной все это никто не хочет кто танцев больше рук кого отменили не еще еще лет пять вообще не еще не будет колыхаться это точно ну конечно же on site если что-то называется солнцев разумеется его то мы и будем использовать в чем минусы джина и до сна есть равно джиной 50 на секунду это базовая цена то есть вот просто если вы с джиной 50 секунд вы бы потратили ну ладно это еще можно с этим смириться я согласен 2 лишь не к первой данных тоже происходят потому что джина и не позволяет напрямую пробрасывать память или себя из-за ограничений сборщика мусора и наносят самое важное это не возможность встроить какую-то логику на стороне базе данных ты такой простой пример в джаве эта операция мамутов epson вы хотите получить значение по ключу если она asus генерировать новое значение вернуть при этом положим его базу то есть если вот эту логику генерации нового значения реализовать как-то на яве то есть это конструктор просто объекта какой-то или это как это лямда то ссученная надо делать 2 денег запросы к базе данных потому что на стороне джина и там эта страна си входа есть надо реализовать эту логику этот колбы как-то носи то есть это уже не понятно как типа жить не понятно как это поддерживать непонятно как java программиста будут с этим работать ну конце его тоже есть минусы это геморрой с блокировками и солнцева ну то есть из этого поможет своей языка всей в я ведь нельзя нативно работать с системными системными блокировками you take some то есть нету нормального игнорирования то есть один поток будет другой поэтому нужно изворачиваться с просто каким-то засыпанием там потом просыпанием с быков а мы как-то так и еще одна проблема то что если поток который держит блокировку вот такую ношу на коле ночную и он умирает то есть приложение которое держит этот поток которым он прибежит она кажется то блокировка автоматически не освобождается то есть надо вручную чистить память ну такие минусы но ирония в том дак стать о блокировках сегодня в том что блокировки то просто не нужны ну даже если бы у нас в архиве была возможность использовать блокировки хорошо просто нативной операции мы мы мы бы все равно не использовали потому что блокировки это зло вот что будет если мы пришли в базу данных хотим заблочить какой-то ресурса его уже использует какой-то другой поток мы знаем да я в наслать на ti1 микросекунда хотим подождать пока тот процесс тот поток который держит блокировку закончить работу и потом самим начать ну мы заснем на на секунды на 1000 наносекунд поспим простимся уже бы все открыто как вы думаете сколько времени в среднем занимает этот вызов то есть он должен в среднем по контракту по идее он должен занимать тысячу на на секунд то есть мы спим тысячу наносекунд как вы думаете сколько он в среднем занимает какие версии от двух до пяти тысяч еще какие-нибудь есть версия 16000 в 16 раз больше ну вот тоже мой коллега дэниелса я буквально там пару дня назад как раз это мерил и там ссылка на блокпост меня в твиттере будет потом посмотрите 8000 среднем это занимает еще до меня в этой ситуации умиляет то что в документации к этом я тут написано что он может проснуться раньше ну да он проснется раньше конечно за одну наносекунду все выполнится эта цена просто 2 контекст свечей поэтому избегайте их ну что мы делаем мы просто спину бьемся жжем цепью так как мы уже за афинян и на какой-то ядро новую ладно секрете клапан системы то никто там даже не будет нас прерывать просто жен сетевые нормально следующую часть я хочу проинвестировать небольшим бенчмарком сравнивается chronicle мэп vanilla это система написанная андреем паниным из одноклассников она очень похожа по принципам на chronicle мэп только там другой алгоритм то есть ну на уровне алгоритмов там чуть по другому и сравнивается с кан каришма пам звездочки напротив хроник лампа его не оставит потому что на самом деле это не хроникам об иване о я там конкретно под этот мяч марк срезал уровень абстракции определенные сожалению chronicle мам сейчас чуть-чуть обросла уже знаете вот таким глуши там java вскинутом listener на стратегии и и фабрикой погоняет это чуть-чуть есть издавна добавляет какую-то стоимость я это все срезал чтобы цифры были красивые естественно вот и спасибо ещё андрею бородину тоже мой коллега за помощь в подготовке этого бенчмарка инвестируем ответы на заявки какую-то покупку продажа акций то есть заявка состоит из айди заявки айди инструмента то есть этих вот какие то акции до цены по которой хотим купить или продать и количество сколько мы хотим купить или продать то есть если количество положить назначь мы хотим это количество купить отрицательное продать его или хранилище мопед пару карт ожидая инструмент и цена на идиш ник последнего запросы которые не да не до удовлетворен то есть еще остатка ним что то сделать и остаток и всего запись занимает двадцать восемь байт то есть такой пример хотим кто-то пришел и хочет купить акции pla 10 акций по 600 долларов мы кладем значит в келью apple 600 долларов осталось купить 10 акций вот для 1 человека следующий запрос кто-то решил по этой же цене продать всем акции то есть мы simax и продаем и осталось еще первому купить три акции и потом пришел еще 3 человек и он хочет продать еще реакции первые уже уходит довольно и теперь осталось до продать две акции до 3 человека ну естественно в тесте фигурировать не только и полы 600 долларов инструменты разные цены разные да и вот данные подобраны достаточно реалистично 5000 инструментов ну допустим на nasdaq и насколько я знаю 3000 инструментов торгуются то есть что-то похожее на правду и распределение цифр эти столбики это объем торгов по какому-то инструменту то есть есть популярный инструмент и ну там не знаю допустим apple и есть длинный хвост но достаточно тяжелый хвост и цены распределит биномиальное то есть в случае там того же было возьмем 600 долларов сама популярны цена там папе ценился делаете что-то не кто-то пореже хочет провернуть сделку и так далее вот beach park включая 10 миллионов заявок 8 параллельных потоков и всего по статистике набирается 160 тысяч таких пар инструмент цена то есть количество ключей в и валюха не леща и на такой машине тестируется она двух сотен на и l3 20 мегабайт вот и результат такой хроникам об работать за сто семьдесят пять наносекунд среднем один запрос и прорваться за сто восемьдесят пять наносекунд ваню за двести девяносто шесть секунд и конкретно шмап за 367 и само по себе это мало чем говорит witch mark эти просто так ну не понятно о чем это говорит о чем это говорит о том что пока я не скажу о чем это говорит а вот распределение память занимаемая на этом же самом тесте самим к его key value хранилищем chronicle map в ванне и конкретный шмап 7 спален венге 10 и 1 мегабайта и 14 то есть интересно насколько хорошо эти графика коррелируют видите то есть их практически сложно так отличить все отсюда вывод такой что потребление памяти это вообще самое важная характеристика любой структуры данных то есть когда там рассказывают про какую-то новую невероятно заморочено структуру данных первое на что я смотрю это просто сколько память он занимает и неважно там какая асимптотика там это дерево или это хэш и это какой-то лог скилл хэш вот этот насолили это вторично первое это просто просто тупо объем потребляемой памяти и не могу упустить случая пнуть радиус еще раз если бы их можно было корректным сравните их корректно 40 нельзя во первых потому что редис однопоточный а во вторых потому что у ноутов процесса склоне компанию и company in process даже если бы их можно было сравнить редис бы занимал на том же самую рук лойди самки и вилью примерно 15 мегабайт если 32-битные со страницы и примерно 20 мегабайт если бы это был 6 4 генри instance раиса и красной чертой тут собственно отмечено объем реально полезных данных это 160 paroc ключ значения запись 28 будь то есть 400 мегабайт а то есть ну вот чего стоит так называемая эффективность сразиться с точки зрения его подхода то есть на самом деле вот самое нелепое что слышал когда объясняет зачем родить сделали однопоточный что из за того что она однопоточный можно реализовать какие-то эффективные структуры и поэтому все будет работать очень быстро в этом одном потоке то есть если вам не нужна многопоточность используйте редис то есть нас амели зависимости нет и тоже кстати вот часто заблуждение что-то пресловутая наша цель одна микросекунда какая полотенце какая часть от этой одной микросекунды это затраты на синхронизацию на обеспечению такой хороший парализации на запись ночей на самом деле цена почти ноль она очень маленькая и то цена 2 on on content id к saw которые там не знаю на стенде бриджи стоили не понял сколько 10-15 на на секунд то есть аки их надо две штуки захочется и разблокироваться то есть 30 наносекунд максимум на х свели к sat on content отказ твой ты на на секунду то есть вот из тысячи на носик у нашего лимитом им на синхронизацию реально тратим 6 наносекунд руки и не ноль процентов полпроцента на самом деле вот на что уходит вся эта микросекунда нашей цели половицы это все память это тупо обращение к памяти может быть какой то ты бегаешь мясик может обращение к основной памяти парочка троечка там так далее то есть почему тут получилось вот ну допустим у chronicle map получилось вы знаете гораздо ниже 1 микросекунды там 171 секунд потому что и такие были она очень маленькая она всего четыре с половиной мегабайта она влезает даже вольт 3 спокойно если в реальности key и value там на гигабайт и там будут сто процентов и т.п. мисо и будут и запросы к основной памяти то есть он он там до подскочит примерно то средняя литнике примерно до 1 микросекунды вот и кратенько еще расскажу про репликацию то есть ну как я сказал вначале сеть не тянет часто обновления в очереди репликации переполняются и поэтому надо как-то либо сжимать очереди там убирать какие-то редант записи уже которые не актуальны что очень сложно алгоритмически делать и пока мы делаем это сжатие надо ждать задержки ну во вторых это сжатия может даже может даже не быть возможности сделать то есть ну просто объем информации которые надо реплицировать просто слишком большое то есть леденцы уже начинает ограничиваться пропускной способностью сети поэтому хрониками как сделано репликация без лагов все очень просто нет никакого там за умного алгоритм опять же все просто как сказать просто как палка записи помещаются на репликацию в bitmap ах то есть записи помещаться как грязный и отдельный worker просто ходит по этим бит небом смотрит ага запись грязная кладет ее в буфер и в сетевой буфер да и отправляет на другую ноду реплицировать все очень просто потребление памяти константной мы при создании кивали хранить аллоцировать и bitmap и они там записываются как-то обновляется и все нет никаких лагов просто логов хранение диалогов как-то на диске всего этого нету но зовут ограничения то что естественно buy дизайна это только а синхронная репликация уменьшили consist in и если задуматься вот эта схема со всех урона репликации она ломает консистентной мультики запросов то есть если есть какой-то мультики запрос на вилле два ключа на одной ноте и они помечены как dirty и worker ходят по кругу пытается их за реплицировать он может один из этих ключей и реплицировать гораздо раньше чем 2 эти данные раньше придут на вторую ноду и потеряется консистентной если вам нужны консистентные мультики и запросы мультики обновления там тоже chronicle мы по или другой системой которая не дает синхронную репликацию это не будет работать ограничение такое сейчас кратенько за две минуты я обрисую все то что я сейчас рассказывал попытаюсь дать вот такой рецепт дизайна эффективной системы в памяти первое постарайтесь разбить систему но на какие-то под системы и распределить их по сути там то есть на 1 socket получить этом репликацию какой-то backup возможно и так далее там на 2 соки допустим ноутбука потом и знаю в и вскоре базу бибиси мусор сборщик мусора все там работает в отдельном живем процесс отлично на третью натрите socket положить вот в этом секрете кола систему которая принимает запросы разложите их по сути там сконфигурируйте их задайте критичным по системам хорошие приоритету максимальные на приоритет всеми прибейте гвоздями вот их сокетом чтобы они куда-то первых совсем их никуда не перем оплевал а чтобы не было систем джиттер забавляйтесь вот вот и сколов и джиной а вот эти границы в до этой процентик системе они приводят задержкам как выясняется то есть я упомянул ну джина и это контекст работаться разделяемой памятью и сколы то есть не не не используйте сколы то бишь не используйте соки тылу бак и так далее но следующий узел уровень это не использовать и сколы и для репликации то есть это то к чему уже сейчас тоже идут люди вчера был доклад александр крижановская про tempesta гибель то что они делают сейчас появился новый крутой проект с цилла тоже в этом на променаде лица то есть они используют жареную памяти чтобы реплицироваться и принимать получать запросы по сети без сколов забавляйтесь от кончик свечей то есть блокировки это прям почему-то в яви нету культуры спиннинга есть только культура заблокирована давайте сразу в блокировку пойдем как сказал глеб смирнов до спину бьемся по хардкору не такой ниже низшего я вещь вряд ли кто-то понял развитие общение процессов через shared memory и меньше памяти то есть память определяет в этом определяет производительность просто то есть позитивный итог такой не надо думать о каких-то сложных алгоритмов чтобы добиться лучше производились практически все о чем надо думать о том чтобы потреблять меньше памяти вот и ссылочки сайт нашей конторы смотрите какое модные домен верхнего уровня правда мне сообщают люди что сайт на некоторых провайдерах российских не открывается написано заблокированы я не знаю связано как-то с импортозамещением или нет если серьезно просто видимо там какой то какой то онлайн казино лежит на том же хостинге не знаю ссылка на мой блог там только хардкорные вещи подписывайтесь никакой воды нету ссылка на twitter и либо по старинке пишите письма спасибо если какие-то вопросы добрый день вопрос про то как вы управляете памятью в в хеппи и смежный вопрос собственно говоря что можно хранить вашим террориста же день потому что непонятно вы можете как-то развернуть вопрос как мы управляем памяти как именно выделяется память для нужд о ваших структур данных как правило для работы в любом приходится придумывать свой собственный менеджер и второй вопрос что туда можно положить можно положить байты массив можно туда положить жарский объект непонятно новый знак лада по поводу memory management a memory management очень простой реализован как марьяну состоящая из одинаковых блоков и когда нужно положить объект определенного размера и эти боги блоки пронумерованы и есть бесед который содержит информацию о том какие блоки заняты какие нет в бюджете ищется свободное место нужное количество блоков и туда кладется какой-то объект то есть это работает идеально если запись констант нам размера как в бенчмарке не зря такой beach park сейчас он показывает насколько быстро их уникумом если вы обратили внимание в этом вич марки записи она конца 1го размеру двадцать восемь байт то есть в этом случае при такой локации памяти будет просто заниматься то есть блок будет размером эти же самые 27 байт 0 внутренняя фрагментация views отличное все прекрасно если записи переменного размера но никогда не удаляются то тоже все достаточно неплохо и если записи переменного размера и удаляются добавляется то есть это такой кейс каких-то шесть expiration нами либо пытаться на коленке реализовать мульти map через хроника мог то есть когда добавляется то есть это мапо из ключа в коллекцию значений добавляется значение как бы увеличивается запись это работает все не очень хорошо из-за фрагментации то есть вот так по поводу того что можно хранить можно хранить все что можно стерилизовать в поток байт есть там реализация fly weight of для того чтобы на прямом вращаться в совке памятью спасибо и второй вопрос зачем вообще нужна репликаций учитываете ограничения в принципе репликация обычно используется там допустим для отказоустойчивости но из-за отсутствия от омар настей изменения такой реплицировали конечно очень сложно себе представить старт какой-то резервной копии поэтому не совсем понятно зачем она в принципе может это это резонный вопрос поэтому сейчас больше мы движемся в сторону того что какая-то какие-то гарантии по надежности обеспечиваются примерно также как вы алексей рассказывали передо мной то есть посылается запроса на две ноты сразу эти ноты между собой не реплицируются за счет того что мы ждем ответов от двух нот обеспечивается какая-то надежность это в этой сторону движется но кому-то нужно репликация да то есть кто-то там ну в общем есть такие случаи не могу сейчас сходу привести примеры где вот без такой репликация никак но такие случаи есть я думаю временно все спасибо"
}