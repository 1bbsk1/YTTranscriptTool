{
  "video_id": "lrWUcKTztmI",
  "channel": "HighLoadChannel",
  "title": "Что нового в nginx? / Максим Дунин (Nginx, Inc.)",
  "views": 6825,
  "duration": 3407,
  "published": "2017-04-22T14:48:18-07:00",
  "text": "Я представляю Вашему вниманию следующего докладчика Встречайте Максим дунин и он расскажет о том что же нового появилось такой технологии под названием eng Добрый день я Максим дунин Как вы наверное знаете я разработчик сегодня буду чить челок вслух и с выражением для начала Давайте определимся с какой с какого именно места мы будем читать челок посмотрим на статистику если верить в тех нулевой версии почти не осталось есть ещё отдельные товарищи которые держатся за 6 но нулевые версии кса вам стоит обновиться первая версия сейчас уже практически там 97% я искренне считаю что это хорошо потому что когда вот 3 года назад я делал аналогичный доклад всё было очень печально народ как-то очень усиленно сидел на старых версиях мы предприняли массу усилий чтобы как-то ситуацию изменить смотрим поподробнее на то что происходит в первой версии видим что 50% фактически пользователей уже там на текущем стебле 110 ещё 5% достаточно смелые чтобы использовать то что мы собственно используем и разрабатываем M 11 остальные выучили что чётные версии у нас стабильные Ну и как-то не спешат обновляться наверное просто потому что используют то что им предоставляют собственные дистрибутивы операционных систем и им не особо пользуются или просто не знают Чего нового появилось и Зачем им нужно обновляться Сегодня я расскажу Зачем нужно обновляться и что собственно Вы получили Если вы уже обновились там до 1.10 или 111 для начала то что появилось в Ветке 1.9 и соответственно доступно в версии 11.10 Мы научились наконец-то использовать порт клиента в различных местах отошли от модели что айпишник хватит для всем хватит всем и если вы много работаете с клиентами Занам что в общем Сейчас наверное у всех то в том числе Real IP модуль поддерживает порт и можно вытаскивать его из прокси протокола можно там передавать на backend руками через xrl IP Следующий вопрос идемпотентность кто знает что такое идемпотентность два человека в зале три человека в зале Круто Ну вот приблизительно это мне и говорил Игорь когда я произносил слово идемпотентность идемпотентность - это такое свойство объекта и операции при повторе давать тот же самый результат с точки зрения http там Get запрос им потенте потому что каждый раз вам возвращают один и тот же ресурс Если вы сделаете запрос не один раз а два раза то ничего не изменится Ну если вы сознательно не пытались нарушить протокол http и не повесили на гет запрос какую-нибудь там операцию Как в общем большинство счётчиков делает например любая статистика у вас в результате не идемпотентный дважды Get запрос засчитывает два хита но там с точки зрения стандарта Тентен В общем практически все методы http импотент кроме пост из основного стандарта и двух дополнительных методов L и пач почему это важно важно Это потому что когда ngx куда-то что-то ксит он имеет привычку запросы повторять вот для не идемпотентный запросов это может плохо кончиться Если ваше приложение ожидает полного соответствия стандарту Вы можете от этого защититься программировал некую защиту для пост запросов чтобы детектировать дубле ну в общем это наверное даже даже не можете а должны защищаться Потому что так или иначе у вас скорее всего дубли из браузеров будут прилетать Но поскольку мы стремимся быть стандартными мы сделали Так что теперь запросы нетент по умолчанию не повторяет и соответственно ведёт себя так как предполагает стандарт и так как некоторые люди программируют Если начал уже отправлять запрос Нант случилось ошибка Повторно он этот запрос не отправляет для пост запросов соответственно Get запросы замечательно отправляет потому что имеет право Попро не отправляет вернуть прежнее поведение это можно сделать легко с помощью конфигурации пишете про next upstream и добавляете параметр Следующий вопрос запись в кэш мы вообще в КСЕ записью особо долгие годы не занимались потому что с записью всё Обычно просто вы сказали операционной системе запиши мне Файлик данные операционная система сказала окей я записала на самом деле сохранила в буфера и когда-то потом запишет это не всегда так Если у вас очень много записи Вы можете наступить на то что буфера операционной системы закончились и соответственно ваша запись заблокируется вот чтобы этого не происходило теперь умеет писать через треды если у вас очень много записи в ш Вы можете с помощью директивы Включить запись через тре пока работает соответственно только через треды вероятно когда-нибудь в будущем сделаем и через опш следить и превентивно очищать зону разделяемой памяти от лишних записей если у него памяти там не хватает то есть теперь вы ошибок аллокации видеть не должны Если вдруг у вас зона маленькая просто будет хранить столько сколько в зоне помещается это по факту то есть когда он не мог Арова очередную запись в разделяемой памяти он говорил а давайте мы попробуем удалить Как самую старую запись удалял её и пытался аллоцировать снова обычно это получалось если у вас высокая нагрузка много рабочих процессов это могло не получиться просто потому что какой-то другой рабочий процесс успевал освобождён ную память уже занять ну и плюс К тому это на самом деле требует некоторое время потому что предполагает удаление файла соответственно cis уход в диск не хочется это делать в рамках обработки там запроса не хочется чтобы пользователь ждал теперь этим умеет заниматься кэш менеджер Ну и на программировали динамические модули наконец-то собственно то про что рассказывал предыдущий докладчик основные цели которые мы ставили это собственно упростить сборку пакетов в первую очередь потому что внешние зависимости у отдельных модулей сильно усложняют установку пакетов Либо вы делаете некого монстра который зависит вообще от всего в системе Либо вы не включаете какие-то модули которые имеют плохие внешние зависимости Либо вы собираете там много разных пакетов с такими модулями с такими модулями с точки зрения пакетирования статическая сборка Иса - это боль Ну и вторая цель которая ставилась у простить отладку потому что писать хорошие модули для кса мало кто умеет и зачастую когда к нам приходят с проблемами проблема оказывается в сторонних модулях поэтому уже долгие годы первое что мы просим когда к нам приходят со словами А у меня падает всё разваливается мы говорим Покажите пожалуйста мибо и рекомендуем перебраться берони модулей смотреть воспроизвели проблема скорее всего она не воспроизвели теперь можно достаточно легко собрать динамический модуль для стандартных модулей это включается с помощью суффикса Vis Dynamic с помощью Суфи dam в Если вы собираете какой-то свой или сторонний модуль вместо Add Mod вы используете Dynamic Ну и потом в конфиге загружаете сделать переделать свой модуль чтобы он умел загружаться динамически В общем достаточно тривиально мы предприняли массу усилий чтобы максимально упростить Всё это для авторов модулей иы это требовало фактически вам нужно поменять config файл если он у вас в старом виде написан чтобы использовался скрипт авто модуля Василий на предыдущем докладе показывал как собственно использовать Ну если у вас сложный модуль вам ещё нужно проделать пару изменений во внутренней логике ничего сложного вместо подсчёта модулей с помощью собственного цикла нужно звать иксов вскую функцию вместо глобальной переменной со списком модулей нужно использовать тот список который теперь появился в цикле config переделывается как-то так там были была прямая установка переменных со списками модулей стал вызов скрипта с поставленными параметрами для скрипта сам этот скрипт уже потом разберётся динамический ваш модуль собирают статический собирают и сделает всё нужное Следующий вопрос давно умеет собственно Рае процес Коре это конфигурации точнее как-то так когда у вас бинарную маску задаёте и соответствующий там для каждого рабочего процесса соответствующий рабочий процесс начинает работать на тех процессорах которые ему разрешены Это хорошо работало когда были двух процессорные машины Чех Маши сейчас когда машины бывают с Чех процессорные это уже немножко неудобно конфигурируется приняли их боль сделали простую ручку авто которая раскладывает рабочие процессы Просто вот по процессорам Один за одним если полной автоматики мало можно указать опять же маску из которой соответственно будет выбирать процессора Это позволяет ограничить эту раскладку спсм процессоров соответственно если в маске меньше бит чем имеется рабочих процессов Иса он просто пойдёт по кругу ещё одна проблема с которой периодически люди сталкиваются это кэширование больших файлов Ну в смысле совсем больших файлов Когда у вас там гигабайт имидж или там собат или там многобайт видео конечно умеет такие файлы кэшировать Но делает это не очень эффективно особенно когда речь идёт про запросы если вам присылают Range запрос там на что-то из второго гигабайта файлика пой скачивать фай ликом чтобы положить его вэш положит его ликом кэш и когда вот когда до второго гигабайта докачать начнёт возвращать ответ клиенту н Для клиента получается совершенно запредельная как-то с этим хочется бороться но опять же зачастую нужно только начало файла наоборот как если у вас какой-нибудь видео стриминг с длинным с длинным скучным фильмом большинство клиентов открывают скачивают первые несколько мегабайт этого потока и после чего соединение закрывают А а вы пошли и скачали все несколько гигабайт к себе в кэш положили и думаете что они нужные как с этим бороться Ну одно из возможных решений которое предполагает что у вас файлы на бэнде не меняются это качать по Каширова тоже по кускам У нас появился модуль сй который умеет собственно качать и Каширова по кускам он создаёт последовательно подзапросы заданного на заданные диапазоны диапазоны заданного размера и мы соответственно можем эти диапазоны отдельные кусочки небольшого размера зашивать с помощью стандартного кэша и потом при отдаче клиенту эти кусочки склеиваются всё работает и каширу ет очень эффективно но опять же повторюсь это всё можно использовать только в неких специфических условиях Когда у вас там файлы на бэнде не меняются если у вас файлы меняются то вполне возможна ситуация когда там клиенту отдалась половина файла потом файл поменялся и и что делать дальше ВТО второй половины у нас просто нет сейчас ngx пытается отслеживать подобные ситуации закрывать соединение ругаясь громко но вообще если у вас такое то этот модуль вам не нужен это стоит использовать именно когда у вас просто статика на бэнде и вы её пытаетесь раздавать и кэшировать э пока суть до дела Спиди умер вместо него появился http2 э отличия есть Но небольшие скажем так с точки зрения общей логики идея всё та же мы в рамках одного соединения lety как-то это работает что-то это даёт не могу сказать что это работает хорошо в том с той точки зрения что очень много всяких нюансов в реализациях протокол новый много кто делает неправильно в том числе сам Google делает в Хроме неправильно мы им периодически пишем тикеты про то что они вот эту часть протокола обрабатывают не так ту часть протокола обрабатывают не так встраиваем в раунды Для всего этого ну как-то оно работает Я лично небольшой фанат этого протокола Ну на самом деле в основном потому что протокол бинарный и это боль с точки зрения отладки и разработки Ну вот Теперь мы его тоже нормально умеем даже убрали некоторые ограничения которые были раньше в СПИДе с точки зрения реализации в никсе если хотите можете пробовать пользоваться ну собственно наверное многие уже пробовали и пользовались А тема популярная говорят про него много а научились несколько сафит делать за раз заодно сафит разогнали раньше Не умели Но это было плохо а теперь умеем И это хорошо с одной стороны с другой стороны если вы используете Саб фильтр наверное у вас опять же что-то не так в архитектуре для лода это конечно плохое решение разогнали слегка обработку новых соединений говоря сделали ручку которая их позволяет обрабатывать быстрее смотрим на график на графике тест количества обрабатываемых запросов в секунду в тысячах запросов От количества рабочих процессов видим что Ну вот совсем не скалится Почему так потому что у по умолчанию вклю у нас всегда работает один рабочий процесс Ну там 25.000 соединений в секунду Он как-то обрабатывает а дальше а дальше не может потому что всё сериализовать апмк смотрим где-то До двух рабочих процессов Ну может быть до трёх скалится 60.000 запросов в секунду выдаёт дальше всё становится только хуже с увеличением количества рабочих процессов Почему так процессор у нас не кончился но зато система начала лочи на сокете у нас один получаем ко Просто на этом сокете как решать добавлять простое рение сти по адресам ВС у вас будет хорошо если руками неудобно или невозможно IP адрес Например оди теперь это можно сделать с помощью специальной ручки RE SP эта ручка позволяет создавать для каждого рабочего процесса собственный с помою опции работает на линуксе не очень хорошо работает на dragonfly bsd хорошо но к сожалению мало популярная операционная система Если вы пытаетесь это делать на линуксе стоит иметь в виду что при изменении количества рабочих процессов у вас будут теряться соединения Если вы уменьшили количество рабочих процессов и1 из сокетов закроют Если вы ВС какие-то соединения в очереди вмте лежат они закроются Linux пока не умеет перераспределять эти соединения между другими сокетами с точки зрения производительности что получаем получаем вполне неплохое скалирование где-то До ми рабочих процессов дальше опять полка Почему полка полка Потому что клиент на той же машине и ез вдвое больше чем Ну соответственно Просто когда у нас процессоров заняты м остальные 16 заняты клиентом больше машина не может всё у неё процессор кончился если хочется больше надо клиентам куда-нибудь на другие машины выносить ещё одна большая вещь которую добавили это моду Он позволяет балансировать произвольные В общем и целом умеет почти тоже что htp Ну чуть попроще Чуть поменьше сейчас мы говорим про версию там 1.9 1110 сонно умеет балансировку произвольных соединений с теми же методами балансировки что и умеет принимать СС от клиентов умеет устанавливать опять же ssl эндом умеет ограничивать количество соединений умеет ограничивать скорость в этих соединениях на backend умеет про через прокси протокол отправлять адрес клиента даже умеет немножко udp Ну так чуть-чуть можно принять udp пакетик от клиента и отправить его на н а потом обратно принять один или несколько пакетиков от бэнда соответственно отправить его обратно клиенту если вам нужно Скажем балансировать ДНС то в принципе можно сделать это с помощью модуля если у вас что-то сложное udp то наверное сейчас вам счастья не будет но зато произвольные tcp соединение умеем в хвост и в гриву Как как хотите Ну и всякого разного по мелочи научили резольвер пользоваться не только udp но и tcp это позволяет работать нормально Если у вас больше 30 А записей ну и соответственно ДНС ответ не влезает в 512 бай udp пакета теперь можно резольвер может в этом случае увидеть что стоит bate и пойти по tcp получить полный список Если вы балансирует используете соответственно резольвер для того чтобы узнавать списки кэндо то вам это немножко поможет блоки upstream теперь могут быть в разделяемой памяти Это позволяет держать общий общий стейт между рабочими процессами соответственно если один рабочий процесс увидит что ваш энд умер то все остальные тоже об этом узнают если у вас балансировка хотите минимизировать количество соединений к эндам то опять же оно теперь не в рамках одного рабочего процесса работает и знает соединения только в конкретном рабочем процессе но и знает все соединения по всему КСУ разделяемая память теперь работает на версиях Windows aslr то есть Ино Если вы использовать под Windows вам это немножко поможет Но хочу заметить что не надо использовать ngx под Windows в продакшене пожалуйста Это может быть очень больно он серьёзно для этого никогда не точил ssl V3 мы по умолчанию выключили если очень надо можно включить но наверное не надо добавили переменную upst Connect Time которая сюрприз показывает время потраченное на установление соединения с эндом умеем печатать полный конфиг по ключи минут большое это как показала практика нашего собственного Ну ф когда полный конфиг зачастую люди прислать просто не могут не понимают где его брать Вот мы этот процесс автоматизировали и научились выводить версию в выводе минус большое Прим даже научились е выводить с кам С какой версие Open eng был собран И с какой сейчас будет пытаться работать то есть если вдруг у вас был собран с одной версии Open SS Вы сейчас работаете с другой версией Open он вам это покажет собственно более или менее всё про ветку 1.9 всё это доступно в стабильной версии 112 что у нас появилось нового в 111 это вот M версия которую мы сейчас разрабатываем в смысле ветка последняя версия 1115 что появилось в стриме появились переменные вообще Стрим усиленно развивается появились соответственно модули которые умеют работать с перемен Geo Geo IP Split clients Real IP появился Access Log Появилась возможность вернуть Там некий простой ответ из переменных или просто статическую строку можно теперь делать всякие странные конструкции с помощью МАПО и liit Con чтобы применять ограничения избирательно в общем практически тоже самое что мы умеем делать в http опять же в стриме Мы научились заглядывать в внутрь ssl соединение при этом не снимая ssl заглянуть зачем это может быть нужно вам может быть нужно там посмотреть на сервер который прислал клиент и отправить клиента либо на один н либо на другой НДС умеем соответственно вытаскивать из Client Hello Server name есть для этого переменная можно по этой переменной отбалансировать на один или другой кнд собственно на слайде пример как это сделать это нужно включать явно потому что по умолчанию Мы конечно ничего не ждём если мы хотим дождаться Client Hello то включаем директиву SS prit и nginx дождётся соответственно э будет переменная ssl prit Server name научились ограничивать количество соединений с бэнда конкретными то есть для каждого сервера Вы теперь можете прописать Max cons э и Engine X не будет открывать больше заданного числа соединений к данному Кэн аэ исходно это было сделано для Engine x+ сейчас мы померли в Open Source Ну просто для того чтобы сделать людям приятное с одной стороны и таскать поменьше кастомного кода с другой стороны а научились работать в режиме transparent Proxy обычно если вам нужно передать э адрес клиента на Кэн вы либо в http используете там заголовки с адресом клиента либо если речь идёт про произвольные соединения там в начале соединения передаёте заголовок прокси протокола там с адреса с адресом портом там А это не всегда к сожалению возможно использовать есть люди у которых Ничего из этого не работает есть опять же люди которые пытаются использовать не со своими бэнда а просто вот Внешний мир как-то проксирование с нужной опцией для того адреса который е передали соответственно Если вы передадите туда то есть адрес клиента она сделает ба на адрес клиента соответственно Если вы построили себе сеть так чтобы это всё работало то ран будет работать для этоже льно построенная сеть вообще если вы со своими бэнда работаете скорее всего вам лучше этого не пытаться делать могут быть может быть это полезно со всяким leg софтом который там ну в общем который обучить понимать X4 4 или xip нереально ещё одна вещь которой научились кто скажет сколько соединений можно установить к одному Кэн если у нас есть один IP адрес есть фнн с одним IP адресом сколько соединений можно установить 65535 по количеству портов потому что Destination пор у нас один а локальных портов ну максимум 65535 если у нас соответственно два бэнда 128.000 если у нас 10 кэндо больше полумиллиона соединений можно установить Это не проблема теперь пишем в config Proxy B и указываем какой-то IP адрес наши полмиллиона портов при дети бкх превращаются обратно в 65.000 почему так происходит происходит Это потому что системный вызов B делается до коннекта То есть он не знает куда именно мы будем коннектится и он должен выбрать локальный порт поскольку Куда именно мы будем коннектится он не знает он должен выбрать локальный порт так чтобы можно было потом законектить куда угодно а всего локальных портов у нас 65000 соответственно в 65000 мы начинаем упираться просто написав конфиг Proxy как с этим бороться бороться с этим можно Ну на свежих версиях линуса есть специальная опция IP Bind adress которая говорит баду что не надо ему выбирать локальный порт мы его использовать не будем мся что не будем и соответственно операционная система не будет его выбирать а сделает это как обычно в системном вызове Connect Когда уже будет знать куда именно Мы хотим при коннектится это опять возвращает нам наши многие тысячи соединений Даже если мы используем B Следующий вопрос АПК что вообще такое это такая ручка для борьбы с проблемой thundering Если у вас есть so и много процессов все процессы ждут событий на этом сокете Ну то есть ЖТ пока прит клиент вот Клинт приходит ждут ядро все процессы разбудило клиент один какой-то один процесс его забрал А все остальные проснулись просто так просто потратили процессор там погрею воздух ничего полезного не сделали традиционный метод борьбы - это сказать только одному процессу чтобы он слушал Ну ждал новых соединений А все остальные Пусть обрабатывают старые и не беспокоится есть проблемы с таким подходом Ну собственно во-первых у нас процессов не так много чтобы это было как-то актуально А во-вторых есть проблемы одну из проблем я собственно показывал чуть раньше если мы забываем выключить А в наших тестах на количество соединений в секун которая никак не зависит от количества рабочих процессов очень удивляемся ну то есть мы-то не удивляемся потому что мы знаем что это такое а пользователи кса зачастую удивляются пишут намм письма с вопросами иногда возмущенные иногда публикуют бенчмарки про то какой НКС плохой ну в общем нас это утомило очень долго объяснять и э и бессмысленно главное потому что процессов и так мало вполне можно э обойтись без всего этого Кроме того там Accept mutex э нельзя использовать на Windows потому что на Windows у нас не допрос работа с сокетами Если вдруг вы запустили несколько рабочих процессов и включили Accept mutex то на Windows у вас всё просто встанет колом Ну точнее сейчас не встанет потому что на Windows принудительно выключено игнорируется даже если вы попытаетесь включить он всё равно не включится при использовании liston RE SP опять же а MX не нужен потому что у каждого рабочего процесса свой L Socket ну и наконец на свежих версиях линуса опять же в ядре появился лаг который позволяет сказать ядру чтобы оно будило не все процессы а только один это не для всех программ допустимо потому что там у вас может случиться какая-то другая активность то есть процесс разбудит а он пойдёт чем-то другим заниматься в Исе это вполне работает Так что в общем мы тепер по умолчанию выключили а iol Exclusive теперь поддерживаем Так что если у Вас совсем свежий Linux то вы вообще ничего не потеряли у вас только сплошные плюсы Если у вас там не Linux или что-то Чуть более старое то Ну вы в общем тоже ничего не потеряли у вас сплошные плюсы Потому что если вы будете запускать какие-нибудь бенчмарки вы увидите реальное поведение системы а не поведение Акса с вопрос с и сертификаты С - это такая штука где большая часть времени тратится на хендшейк и собственно хендшейк сводится к тому чтобы проверить подлинность сертификата сертификаты бывают современные РСА и ецд то на эллиптических кривых это Но дорого а эллиптические кривые - это быстро Ну и в общем тоже хорошо но не везде работает в частности не работает на Windows XP как показывают всякие сервисы статистики Windows XP ВС е от 5 до 10 е вы просто переключитесь на ед сертификаты вам будет несчастье вы там 5% клиентов потеряете Наверное если вы большая компания то вы себе не можете этого позволить что делать Ну вот Циферки очень запускаем Speed видим что дкит Дат Ну вот 400 подписей на ядре мы можем сделать ад 5000 с лишним И это не предел на самом деле это просто Циферки от старой версии Open достаточно Конечно когда вы поставите перед этим ещё и Forward sec всё Немножко ухудшится там на реальных хендшейка см Циферки немножко не такие впечатляющие но ВС рано 300 шейков в секунду в случае р там 1000 шейков в секунду на ядре в случае рост в три раза то что хочется получить Теперь мы умеем делать так то есть вы можете сказать Вот тебе два сертификата работай с ними и их по мере необходимости будет предъявлять клиенту если клиент новый умеет ецд са будет использоваться ецдс всё будет быстро если клиент старый но для него будем использовать RS А кроме того в СС Э теперь можно задавать несколько кривых одновременно если у вас достаточно свежие Open ssl по умолчанию если раньше был м 256 V1 теперь загадочное слово авто авто зависит от того какая именно версия Open у вас используется совсем свежим сначала будет кривая Бернштейн 25519 потом тот же самый 2561 который был раньше по умолчанию Настоятельно рекомендую не трогать просто имеет смысл знать что вот такая ручка есть но трогать не надом параметры для дифи хелма обычного классического по умолчанию мы теперь не предоставляем если раньше внутри был были зашиты килобит параметры то тепер их ственно по умолчанию у вас шифры то есть for sec с использованием выключены и Ну в общем это на самом деле хорошо потому что они медленные по сравнению с эллиптическими кривыми и на них есть сейчас основания суст потому что они поддаются пред прочту в динамических модулях вот предыдущий оратор говорил про проблемы Проблемы там существуют в той реализации которая в стабильной версии сейчас проблема связана с тем что структуры в зависят от опции сборки если ему нужно структур убирает позволяет сделать структуры поменьше и побыстрее это приводит к тому что если вы собираете модуль то собирать его нужно с теми же самыми опциями сборки что и основной NG куда вы этот модуль собрались грузить в ситуации сборки пакетов это в общем работает нормально Когда вы там собираете основной и к нему множество пакетиков с разными модулями Вы можете контролировать опции сборки и собрать это всё одинаково это не всегда удобно когда вы хотите свой модуль для каких-то произвольных пакетов подсобное удобно Ну и опять же сборку Вам приходится делать свою сборку модуля Теперь у нас есть специальная опция когу которая включает режим совместимости с при динамической загрузке модулей и все соответствующие поля вне зависимости от опций сборки ственно модули и становятся Бинар совместимыми даже если вы там какие-то опции сборки поменяли Главное чтобы среди опций был Vis тогда вы можете собрать свой модуль и загрузить его в любой другой собранный тоже с опции Кроме того теперь можно так собирать модули и грузить их в если раньше изза той же самой проблемы собрать модули для п вы сами не могли то теперь Ну потому что там структуры другие были внутри теперь можете собрать сами свои модули и загрузить их в наш коммерческий Ну и вся всякое разное помело видим что ядро свежее это экономят силы при детектирования а не закрыл ли клиент соединения http2 улучшаем дополняем мап научился работать с произвольными комбинациями переменных и строк для злопамятный появись пере для идентификации конкретного запроса ВС это есть в 115 всё и собственно разработка продолжается свежий можно как обычно скачать у нас на сайте если вы используете fre bsd можно поставить из портов Если вы используете Linux то системные пакеты скорее всего у вас старые Хотя последнее время ситуация слегка улуе мы предоставляем собственную сборку можно взять у нас на сайте для модулей которые имеют внешние зависимости у нас теперь отдельные пакеты Ну соответственно с внешними зависимостями собственно Всё спасибо за внимание за внимание у ВМ зать Если они у вас есть Пожалуйста задавайте 1.12 появится как обычно в день космонавтике может быть чуть раньше может быть чуть позже в апреле ждите вот мне коллега подсказывает что у нас есть наклейки Если кто-то хочет Ижевских наклеек подходите У меня вопрос вы говорили про 64.000 коннекто Я здесь Да у нас века такая такая ситуации проблема Подскажите как её можно решить Ну кроме ки поева какого-то 64 коннекто Это просто ограничение к с точки зрения tcp Вы больше между одним ашнико другим ашнико и конкретным портом установить не можете чтобы установить м лидов добавлять либо ашнико либо портов либо сорс адресов добавлять Ну соответственно портов 65000 никуда от этого не деться если если вы добавили ещё айпишник то соответственно у вас будет больше соединений возможность установить соединения тему с Тайм вельми побороться с помощью лайва если этот ресурс исчерпан то единственный способ собственно добавлять айпишник либо на бэнды там айпишник или порты добавлять либо на фронтенд сорс адресов добавлять ругая на один кнд вешать несколько ашнико Ну или на один кнд просто на нескольких портах его поднимать я понял спасибо А будет ли возможность вешать листа на конкретные воркеры не думаю с точки зрения архитектуры воркеры они в общем все одинаковые и какой-то специальный биндинг отдельных ли сокетов конкретным конкретным рабом процессом планируем нужно и важно Подойдите ко мне в кулуарах Расскажите зачем вы это хотите использовать обсудим А вот интересно модуль сй и псевдо стриминг как они работают в смысле можно ли их включить в рамках одного одного локе Нет нельзя потому что стриминг который у на есть он собственно работает непосредственно с файлами умеет работать с проксирование в виду MP4 там достаточно много интенсивной работы с собственно самим файлом делать это на потоке Ну не очень удобно и может выйти боком особенно если у вас э метаданные в конце файла находятся Здравствуйте меня зовут Дим Спасибо вам за доклад Спасибо за поддержку и разработку Скажите пожалуйста как работать с ХТ ядрами и в разрезе опции Work affinity и process То есть если вы хотите повесить на конкретные ядра вы это можете сделать с помощью то есть в том числе в автоматическом режиме Вы можете задать маску там Если вы видели на слайде у меня было через один битки стояли это вот как раз для того чтобы Engine X работал на реальных процессорах и не пытался лезть на треды дополнительные Ну то есть просто в интернете бродят различные вот такие вариации вешать конкретный воркер на ядро и его поток отдельный То есть это правильно можно сделать так э так автоматически мы не умеем соответственно мы не умеем знать какие я Какие ядра настоящие А какие там дополнительные потоки э и как они там в общем как они соотносятся друг с другом Мы просто в автоматическом режиме мы умеем развесить э по по одному ядру Ну или по одному потоку там с точки зрения кса это одно и тоже если вы хотите э вручную Вы можете повесить Ну просто задать задать для рабочих процессов маски руками и тогда у вас Engine X будет работать на ядре и на дополнительном потоке этого же ядра я я честно не видел реальных кейсов Где бы cpo affinity сильно влияло На происходящее а на всяких бенчмарках это может быть важно для получения воспроизводимых результатов а так чтобы affinity сильно влияло на производительность икса я так вот таких кейсов не видел поэтому в общем на самом деле мне лично кажется что в интернетах когда пишут про Work affinity в основном пишут люди которые теоретики и с цифрами в руках они свои результаты подтвердить скорее всего не смогут Ясно Спасибо большое дорогие друзья к сожалению время не позволяет нам задать больше вопросов во время дискуссии Если возникнут какие-то вопросы Пожалуйста задавайте их уже в кулуарах"
}