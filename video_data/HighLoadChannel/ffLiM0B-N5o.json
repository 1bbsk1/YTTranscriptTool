{
  "video_id": "ffLiM0B-N5o",
  "channel": "HighLoadChannel",
  "title": "Opentelemetry и эволюция распределенного пайплайна трейсинга в Авито / Сергей Ларионенко (Авито)",
  "views": 2449,
  "duration": 2428,
  "published": "2024-09-12T00:59:53-07:00",
  "text": "Всем привет Я хочу сегодня с вами поговорить о Open telem о фреймворке Open telemetry и рассказать вам хочу об этом в контексте эволюции палана трейн Вита и предлагаю начать с небольшой вводной Я думаю что все это знаете но на всякий случай Давайте ещё раз повторим Open - Это фреймворк для генерации процессинга и экспорта таких сигналов телеметрии как и весь это фрево его можно разбить на несколько основных компонентов и нас будет интересовать на самом деле всего лишь два комне компонента это и это колектор на самом деле это просто jpc и описание проба схемы там ничего интересного нет а вот колектор это как раз тот компонент про который мы сегодня говорить как Гош прося это имплементация спецификации openet И на самом деле внутреннее представление этого бинари его можно представить в виде набора модулей которые связаны между собой в через паттен CH of responsibility то есть цепочку ответственности и Существует несколько основных типов модулей это ресиверы это процессоры Это экспортеры я думаю что из названия понятно за что они ответственны и для того чтобы вам воспользоваться Оль колектором Вам необходимо как-то его раздеть и Существует несколько схем деплой и Одна из основных - это схема которая называется агент колектор или Агент Gateway и Она состоит из двух основных сущностей первая сущность - Это непосредственно агенты То есть это бинари Оль коллектора которые вы раздеваетесь данные от клиентских библиотек как-то сделать какой-то лёгкий при процессинг и потом заэс портить эти данные дальше и вторая сущность в рамках этого деплоймент коллекторы непосредственно это уже не та сущность которая будет делать какой-то тяжёлый процессинг ваших данных и потом эти данные уже будет р врать куда-то дальше зачастую это просто уже будет экспорт в какой-то нный и если говорить об на то основная отличительная черта у нас это то что мы исторически используем еер библиотеке в качестве клиентских ли отличительная особенность биотека состоит в том что они все Спанки они посылают по через риф протокол соответственно что у нас трейсинг осуществляется на базе Open telemetry и мы процеси спа от более чем 3.000 микросервисов у нас достаточно высокий рейд спано Это около пиках Больше 15 млн спано в секунду у нас три процессинговый слоя и по факту этот каждый из этих слоёв мы его можем спокойно отселить как горизонтально так и вертикально соответственно мы получаем неограниченную пропускную способность а но само собой вот к такому развес ви архитек мы пришли не сразу это был процесс эволюционный итеративный и вот в ходе этого процесса мы натолкнулись на очень большое количество подводных камней которые тают в себе оме и как раз-таки об этих проблемах Я хотел бы сегодня поговорить и сделать Я это хотел бы на примере имплементации какой-то реальной фичи и в качестве такой функциональности я выбрал Итак ВТО в VP процессинга ТВ и он использовал сэмплирование на базе слинга то есть мы симпли всё делали в рамках получается клиентских библиотек то есть клиентской библиотеки у нас получали какой-то коэффициент симпли от агентов и потом при генерации первого сна для рейса мы подкидывание о том чтобы сэмплировать весь ой весь или не симпли Однако по истечении какого-то времени мы поняли что мы хотим изменить форму распределения сохраняемых рейсов то есть мы хотели сохранять больше рейсов с ошибками больше Долгих рейсов и соответственно HB сэмплинг нам для этого не подходил потому что нам нужно было иметь все СПА для каждого треса чтобы на основе их свойств уже принять решение о сэмплирования и мы начали задумываться о том как перейти на TB сэмплирование И на самом деле всё оказалось достаточно просто Как нам казалось опять-таки нам нужно было просто убрать сливание тем самым весь трафик снов перенаправить сначала на агенты а затем и на коллекторы и тут ключевой момент состоит в том что при балансировке данных на коллекторы нам нужно было использовать консистентной Почему так потому что зачастую сны в рамках одного треса они могут быть экспортировать раз нода и затем уже в качестве финальной какой-то части нам нужно было просто Вставить механику слинга на коллектора то есть мы должны были копить Спанки какое-то время для каждого рейса пробиться по этим потом скам и принимать решение сливания И на самом деле у есть два модуля которые позволяют вам организовать рование первый это достаточно простой модуль он делает всего лишь две вещи Он экспортирует СПА на указанные ты и делает это он как раз таки через cons по TR ID и второй модуль с помощью которого вы можете сделать Это непосредственно процесор это тоже достаточно простой модуль мы его размещаем на коллекторах и соответственно этот модуль просто с за какой-то промежуток времени и Поче этого промежутка времени по заданным правилам Итого у нас был какой-то план действий Как нам казалось достаточно простой и лёгкие то есть мы должны были вставить модуль рования на коллекторы мы должны были отключить сэмплирование и мы ещё заложили какое-то время на адаптацию всей этой истории и первые два пункта мы пробежали достаточно быстро вот мы отключили получается у фик пол на агенты затем на коллекторы и вро хоро увидели что у нас в системе появились трансмит Точнее не то что появились ретранс у нас в системе возрос пакет Рей И доля этих ретранс тов относительно пакет рейта она тоже значительно увеличилась то есть на самом деле это м достаточно большая проблема с которой нужно было разбираться мы тут же включили обратно ХБ млини и начали разбираться с пакет рейм и первое место куда мы обратили свой взор скажем так это конечно же модуль Load балансера э который мы вставили на агенты и когда мы открыли его Исходный код мы увидели примерно следующую картину То есть это то каким образом примерно этот модуль экспорте данные То есть у нас на вход прилетает пачка снов мы эти сны группирует и потом бежим по каждой из этой из этих групп и для каждой группы мы получаем Потом по шику получаем выбираем на ком экспорт Казалось бы ВС логично всё просто что же может пойти не так но Давайте представим как это выглядит на самом деле с какими-то реальными плюс-минус данными У нас есть пачка снов мы берём группирует ID эти сны потом для каждой группы Мы выбираем коллектор и делаем экспорт экспорт напомню у нас делается по протоколу это тоже вро выглядит Логично но Давайте посмотрим через призму реальных цифр есть у на тако снов он зачастую состоит из 20 снов при этом в лучшем случае в рамках этих снов у нас будет присутствовать всего лишь 5000 уникальных рейсов и соответственно мы сделаем 5000c вызовов экспорта на коллек прило кол заэс снов на 45 коллекторов нам приходится делать почему-то 5C вызовов на самом деле достаточно странно почему так ребята решили сделать всё можно сделать гораздо проще то есть у нас все те же исходные данные берём группируя эти данные не по а группируя сразу пом место 5pc вызовов мы получаем всего лишь 45 и соответственно для фикса для фикса пакет рейта мы форк стандартный модуль отеля И оптимизировали как я уже показал ранее jpc вызовы и также мы оптимизировали сжатие потому что у нас получается в рамках каждого такого боча который мы экспорте у нас получалось больше данных соответственно сжатие работало более эффективно и поскольку мы уже форли этот модуль Мы также добавили балансировку по кластерам с Панков а именно мы в первые несколько байт вшиваем Шик от получается имени кластера и потом стараемся трейс обрабатывать обрабатывать именно в тех кластерах в которых они были созданы это сделано для того чтобы минимизировать ossc трафик при обработке спано мыра вот На новы моду им ре всё стало хорошо мы уже начали Апти всю эту историю Но мы столкнулись со второй проблемой а именно с битыми рейсами то есть любой трейс на самом деле его можно представить в виде дерева снов Почему Потому что любой Спан он знает ID своего родителя соответственно приблизительно так может выглядеть ваше дерево спано в каком-то тресе Но что если мы возьмём какой-нибудь СН и потеряем его где-то при процессинг и вас получается не связаных между собой дерево снов и проблема здесь заключается в том что когда вы уже видите финальную картину таких деревьев не связанных между собой вы не можете точно сказать сколько снов вы потеряли может быть один может быть 100 Может быть там ещ сервис какой-то был который тоже прол этот запрос соответственно это достаточно большая проблема И с точки зрения пользователя это выглядело примерно следующим образом допустим и просто дропаем его и у нас вырождается в какую-то группу несвязанных между собой снов мы поняли что эту проблему Нужно решать и в первую очередь нам нужно было сделать мониторинг этой всей истории то есть мы должны были Понять насколько много у нас таких случаев в системе происходит само собой нам нужно было потом найти причину и пофиксить всё это дело мониторинг мониторинг Мы решили сде вра процессора Почему Потому что для того чтобы сделать осуществить проверку на целостность треса нам нужно иметь все Спанки этого треса а процессор он как раз таки как уже говорил он коррект пытается кортить все спа треса в памяти и соответственно после того как процессор принимает решение о сливании он вытесняет накопленные спа и именно в этот момент мы делаем нехитрую проверку Гра ивея что ит связано и также мы проверяем что наш трейс не заканчивается клиентскими походами то есть терминальных узлах у нас находятся серверные сны и соответственно уже потом Экспо результаты этой проверки в виде статистики реализовали такой мониторинг и оказалось что у нас в системе около 70% тросов являются битами это согласитесь достаточно большой процент мы начали искать причину а и достаточно быстро локализовали место где мы теряем спа и этим местом был ресивер это модуль который у нас стоит на агентах его основная задача как раз таки получать клиентские сны по udp и когда мы начали смотреть как же работает этот модуль всё казалось достаточно Просто этот модуль в основном использует просто ер библиотеку стандартную и в рамках что делает эта библиотека она непосредственно получает данные рованный канальчик и потом несколько тинок вычитывает данные из этого канала и вызывают пользовательские засе колбеки и конечно нас в первую очередь интересовал момент Каким образом Эта библиотека кладёт данные в это буферизированный канал когда мы открыли код это библиотеки мы увидели примерно следующую картину то есть данные пытаемся положить и в кано мы просто дропаем данные и ирем статистику но проблема была в том что этой статистики мы не видели то есть Колек не экспорте вот эти дропы статистику по этим дропа и мы тут же начали смотреть Каким образом отель инициализирует эту библиотеку и оказалось что при инициализации почему-то ребята из Оли решили инициализировать герев вскую статистику заглушкой то есть соответственно у вас получается история что если вы теряете данные то вы просто об этом не знаете это на самом деле ши проверенный подход но в тот момент он нас не устраивал мы поняли что нам нужно е исправить эту ситуацию с мониторингом входящих данных и соответственно тут тоже ВС достаточно просто мы форли ещ один стандартный модуль мы зали метрики и заэс портировали эти метрики и когда мы раскатились То есть это именно было именно то место где мы теряли данные и на самом деле э сейчас секунду Спасибо И на самом деле что это означало Для нас это означало что мы пытались запросить э больше данных чем могли то есть где-то в нашей системе Был ли ботл неки где-то Нам не хватало Фрута А мы начали искать в ЧМ же заключалась проблема И на самом деле достаточно быстро разобрались в этой проблеме Но перед тем как рассказать вам об этом Я хотел бы сделать шаг немножко в сторону и рассказать по поводу кон мо модели в Оль коллекторе как я уже говорил допустим у нас вот есть какой-то ресивер У нас есть каких-то два процессора которые как-то просят наши Спанки и как я уже говорил все модули в рамках колектора они выстроены в ч ответственности то есть условно говоря ресивер делает свой какой-то процессинг и вызывает модуль а модуль а модуль а процессе данные вызывает модуль B и уже только модуль B допустим он у нас асинхронно занимается синхронно процессинга и соответственно он кладёт эти данные куда-то к себе в буфер и вызывает ТН и только после этого мы можем продолжить обрабатывать входящие данные то есть Тем самым у нас на самом деле в системе появляется пре при том что эта сила обратного давления она будет характеризоваться тем насколько быстро в цепочке обработки мы дойдём до первого модуля который Затерянное сит данные или там насколько быстро мы доходим до записи там в наш буфер в модуле B а но что если допустим асинхронная работа модуля б реализована за счёт Гош канала и модуль B кладёт данные в этот канал через блокирующий вызов то тогда на самом деле мы у нас образуется ещё одна сила обратного давления и она нам будет афективна и соответственно она будет характеризоваться тем насколько быстро мы вычитывает отеля тут очень важно отметить что отель никак не формализуются свои модули с точки зрения concurrency э и с точки зрения того как модули обрабатывают данные синхронно или асинхронно соответственно получается Какая история что вы можете добавить какой-то Рандомный э модуль в вашу цепочку обработки И тем самым Не желая того Вы очень сильно можете за аффектив и frp э и кша который у вас образуется в пайплайн И на самом деле не непонятно почему ребята никак э не формализовать эту историю и возвращаясь к нашей проблеме напомню что мы остановились на том что мы искали Где же в нашем пайплайн в каких местах и вот примерный получается примерный пайплайн обработки данных в тот момент у нас соответственно мы получали данные в ресивере потом делали какой-то процессинг и первый модуль который асинхронно просил данные в на палане со стороны Агента Это был стандартный модуль для банга то есть этот модуль просто клал данные в Гош най канал и потом в рамках всего лишь одной рутины эти данные вычитывает соответственно у нас образовывалась сила обратного давления и начиналась она как раз-таки с момента получается записи данных в канал модуля банга Однако поскольку у нас там был Гош най канал э и данные мы клали в этот канал через блокирующий вызов А нам Мы ещё зависели от скорости чтения данных из этого канала и тут ситуация была немножко интересна более интересная Почему Потому что дело в том что когда мы делали экспорт как я уже говорил это был через llp протокол это синхронный jpc вызов привет вызов доходил до коллектора и коллекторов на коллекторах у нас потом была очень длинная цепочка процессинга она доходило аж до модуля л слинга То есть это был первый модуль который синхрони процеси данные в этой цепочке асинхронно и соответственно у нас образовывалась вторая сила обратного давления которая нам офек вычитка на агентах из канала получается для банга соответственно у нас в системе образовывалась некая такая композитная пша И на самом деле это именно та причина по которой Нам не хватало пута то есть величина этой силы была достаточно велика она не позволяла нам процеси столько данных сколько мы хотели и мы начали проверять тестировать эту гипотезу она оказалась верной и мы начали думать как же эту всю историю пофиксить на самом деле можно было пойти двумя путями первый путь это мы берм все модули которые у нас участвуют в цепочке обработки пытаемся их оптимизировать Но это путь мог быть достаточно длинным поэтому мы пошли немножко в ортогональную сторону скажем так что мы сделали как я уже говорил стандартный модуль бачин он почему-то вычитывает данные из своего канала всего лишь в рамка в рамках одной рутины мы просто форкнуть возможность обработки в несколько рутин при том что нюанс заключался в том что в любой момент времени у нас была всего лишь одна активная рутина и когда данные к нам приходили на на батчинг мы записывали эти данные в буфер именно активной рутины если этот буфер переполняло забит тогда мы делали активный другую рутину и уже клали данные в пустой канал но у нас как я уже говорил была ещё проблема после бачин состоявшая в длинной цепочки синхронных вызовов и её Мы решили достаточно просто мы взяли наш сфор модуль переделанный банга и вставили его сразу после приёма данных соответственно тем самым мы добились того что время jpc вызова Время jpc респонс оно у нас значительно сократилась И тем самым сила обратного давления в этом месте она стала гораздо меньше соответственно для того чтобы увеличить мы форк как я уже говорил ба процессор мы увеличили тем самым пропускную способность этого процессора то есть увеличили пропускную способность нашего батка и соответственно вставили ещё этот бач процессор на коллектор и когда мы эту всю историю раскатились а причиной остаточных скажем так битых ресов эта причина заключалась в том что мы заметили что у нас коллекторы падают Прим падали они с паника Почему это для ри уже говорил что мы колем данные в памяти и соответственно каждое падение коллектора оно приводило к тому что мы эти данные просто теряли Но поскольку там были паники мы легко нашли место и причину этих падений и дело заключалось в как раз таки модуле слинга и Давайте немножко покажу как там немножко всё устроено то есть дамти в рамках этого сначала приходит один спанк из треса и мы его кладём куда-то в память то есть какой-то условный слайс к нам в момент времени Т2 приходит второй Спан мы просто апендикс данным этот спанк и наступает момент времени Т3 и как раз-таки вот промежуток между Т1 и Т3 - Это как раз-таки так называемая decision Window То есть это окно принятия решения это то количество времени которое мы ждём чтобы рования и как раз таки в момент времени Т3 мы делаем так называемый проце это как раз таки Принятие решения сливания то есть мы в рамках этого процесса мы В отдельной рутине мы бежим по всем снам смотрим на их свойства и принимаем решение на основе правил то есть симпли эти данные или нет но Что произойдёт если в момент когда мы делаем evation к нам прилетает напом прот там наверно есть какие-то примитивы синхронизации но ребята из Оля решили не заморачиваться Вот и никаких примитиво синхронизации данных не было соответственно как бы помимо того что мы копировали не просто даже слайс с данными мы копировали указатель на слайс то есть и пытались по нему ировать в то время как в другой рутине мы делали ан само собой это могло приводить и приводило к падению и после того как мы добавили э примитивы синхронизации наши метрики пришли в тот вид в котором мы хотели их видеть то есть у нас были достаточно хорошие цифры по абилити и по Бим рейсам и Казалось бы всё на этом можно завершать доклад но у нас во-первых была ещё одна проблема небольшая то есть после того как мы добавили Лин мы начали потреблять на коллекторах примерно в два раза больше оперативной памяти Ну и Казалось бы как бы ой Колек данные памяти мы больше потребляем память но проблема заключалась во внутреннем скажем так представлении данных и в том что мы не могли с этим ничего сделать Дело в том что в рамках тематических соглашений отеля ещё на уровне OTP протокола свойства сна они представлены в виде тегов То есть это условно говоря какой-то там слайс с и проблема заключалась в том что мы использовали всего лишь там четы тега при процессинг хотя там в среднем у нас там может быть 50 60 7 тегов то есть мы хранили в памяти данные которые нам не требовались и мы с этим не могли ничего сделать потому что вот эти вот данные они ещё на уровне протокола были представлены в виде полей А что значит поля в профе Это значит что вы не можете применить никакую стандартную оптимизацию просю есть стилизацию тоже не сможете применить соответственно получается что вы платите за то что не используете то есть на самом деле тоже достаточно странное решение ребят из отеля но мы решили забить на эту проблему вот мы просто решили отке отлить горизонтально вертикально наши коллекторы и спать спокойно по итогу В начале мы думали что у нас получится что-то очень быстро сделать что-то простое элегантно и далее несла свои коррективы само собой это не вся история по поводу линга у нас были какие-то ещ планы на развитие этого всей истории и даже что-то мы уже сделали к сегодняшнему Дню а именно мы сделали статистику по сарым снам То есть это очень хороший инструмент при инцидент менеджменте также мы решили общую проблему практически любого сэмплирования а именно сэмплирование низкочастотных сигналов и решили мы её с помощью me скетча вероятностная структура данных и редиса для хранения стейта этого ну этой структуры данных как я уже говорил у нас достаточно большой развесистый пайплайн и то что я рассказал это лишь Малая Толька того с чем нам пришлось столкнуться работая с Open и для себя мы все наши проблемы с которыми столкнулись мы на самом деле спирова их по Руд козам и они легко группируются там в несколько основных а групп то есть первая группа проблем она обусловлена качеством имплементации то есть ээ низкое качество имплементации многих модулей недостаток обсер самого пайплайн а также performance - это в данный момент не про Open telemetry вторая группа проблем - Это архитектурные решения которые были заложены ещё на в каком-то начальном моменте развития проекта тут можно отметить как я уже говорил tlp протокол внутреннее представление данных непрозрачной concurrency модели про которую рассказывал и как следствие непрозрачный механизм кша А и также Несмотря на то что Open является по факту сейчас дефолтным фреймворков и проверка целостности данных Но на самом деле помимо минусов в Open темет есть свои очевидные плюсы то есть Open telemetry очень хорошо покрывает базовые сценарии обработки телеметрии а также это проект который динамичны и непрерывно развивается то есть допустим история с экспортом про который рассказывал ребята вроде как недавно её пофиксили плюс даже мы что-то там за контрибьютор какие-то Фиксы багов также когда вы берёте темет вы можете быть спокойным в плане поддержки различны протоколов идов и Open обладает достаточно широким тулим то есть там будет у вас и операторы Ича и так далее И какой вывод как бы мы для себя выводы все сделали в плане Какой вывод Вы можете сделать для себя Если у вас достаточно небольшой поток телеметрии который хотите процеси если сценарии процессинга у вас Бут достаточно стандартны то вы можете без зрения совести сно брать накидывать этих коробочек этих модулей и у вас всё заработает вы будете жить счастливо но если же допустим у вас достаточно а большая большой объём телеметрии у вас какие-то есть нестандартные сценарии Как вы хотите процеси эту телеметрию и вы решили взять он телеметр то как бы закладывается на то что какое-то достаточно большое время вы потратите на adoption этого фреймворка вот на самом деле у меня всё А если есть какие-то вопросы у вас то готов на них ответить Сергей спасибо большое за доклад я Напоминаю что можно сканировать QR код и по нему можно будет оставить фидбэк по докладу и проголосовать Если вы хотите для того чтобы задать вопрос Вы можете использовать чат зала или поднимайте руку мы к вам подойдём с микрофоном задавайте пожалуйста свой вопрос в микрофон микрофон держите у рта только так оно работает Ну а теперь вопросы из левой половины зала О спасибо большое за доклад А у меня вопрос такой вот эти оптимизации которые вы применяли для того чтобы вентиля тре справлялся с нагрузкой вы публиковали их куда-то или они только применимы у вас на локальной инфраструктуре А можете чуть-чуть погромче повторить асть Да а вот эти оптимизации которые вы применяли в он темет для того чтобы он больше справлялся с нагрузкой они только у вас в инфраструктуре применимы или вы их публиковали куда-то в о Source потом А мы на самом деле их не публиковали у нас есть уже давно висит в планах на самом деле у нас очень много м скажем так функциональности которые мы хотим законтрили а на самом деле времени хватает только там мы за контрибьютор условно говоря только несколько небольших бак фиксов То есть у нас в планах есть всё будет зависеть от Свободного времени То есть это применимо не только там нет нашей специфики это всё очень Общее решение по оптимизации скажем так супер спасибо с правой стороны зала вопрос я думаю надо дать слово свинке привет Дмитрий НТС У меня вопрос тоже по форка по вашим есть у вас какие-то сложности с поддержкой этих фоков в актуальном состоянии или вот вы их как форк и не трогаете то есть сколько вообще время занимает дорого недорого Ну на самом деле мы используем Если я сейчас не ошибаюсь версию 07 Это где-то она вышла где-то полтора года назад Вот Но у нас насколько я помню уже практически готово обновление на новую версию то есть да придётся потратить какое-то время но на самом деле это не то чтобы большое время вы на это потратите Почему Потому что максимум что может измениться это ребята могут там где-то вот поменять представление данных менять немножко какую-то корву опиш То есть это на самом деле не выглядит как что-то серьёзное то есть поддержка Тен этих фоков он достаточно простой супер спасибо очень много вопросов на первом ряду вот там слева вопрос да Привет Спасибо большое за доклад хотелось бы задать вопрос относительно поддержки нескольких кэндо трассировки на коллекторе Вот как это аффект производительность в целом профилировщик Если вы имеете в виду если мы для экспорта Ну экспортировать будем в разные бэнды одновременно это всё на самом деле опять-таки это немножко относится к этот вопрос относится к той теме про которой говорил то есть Open они почему-то никак не формализуются вообще модули и соответственно всё будет зависеть от конкретного модуля экспорта То есть как он процеси данные будете ли вы использовать там очереди в экспотех там есть очереди в которых скапливаются данных будет вы их использовать как быстро вы это будете делать то есть всё нужно смотреть это Минус один из минусов в о темет перед тем как использовать любой модуль Вы должны посмотреть код этого модуля Вот то есть но вообще как бы если делать всё быстро да то есть посмотреть что вы достаточно быстро экспорте то проблем не будет Мы сейчас экспортировали в большинстве случаев и у нас там как бы мы немножко переписали модуль у нас были проблемы мы его переписали проблемы ушли Спасибо Напоминаю что если вы не сможете задать вопрос здесь можно будет пройти в дискуссионную зону куда отправится докладчик и где можно будет с ним пообщаться лично Давайте дадим возможность первым рядам задать вопрос А Сергей спасибо за доклад Антон Яндекс А вот мне интересно та часть где вы форк и сделали пу воркеров чтобы очередь Вот примерно тот же вопрос насколько это влияет на производительность и не начинают ли они сами переполняло создаваться там да смотрите как бы в чём была история вот это вот я так понимаю что вы имеете в виду вот стандартный модуль банга да про который рассказывал а там Проблема была в том что не даже не в том что там Всё обрабатывала учитывалось в рамках одной рутины там не было возможности вообще задавать количество этих рутин То есть это дефолтное поведение и когда мы форкнуть как я уже говорил а мы не просто как бы там вот пул грунто каждая пытается вытянуть данные в каждый момент времени у нас активная только рутина Да и соответственно как бы да мы можем зафре На этом этапе если допустим у нас все Гру все буфера в каждой рутине точнее в каждой рутине есть свой буфер куда мы кладём данные да И если у каждой рутине эти буферы будут заполнены каналы то тогда да мы зафре но на практике как бы у нас такого не происходит параллельно они не параллельно отрабатывают я напомню что правильно будет это обсудить В дискуссионной зоне потому что это диалог который безусловно хочется провести но дискуссионная зона самая правильная для этого места А у нас есть время ещё примерно на два вопроса Давайте дадим возможность барышне в первом ряду задать и молодому человеку в конце Вт вопро первое Почему вы поставили Агента и через Агента закидывается сны а не не напрямую в коллектор и второе насчёт модуля балансера насколько я сейчас знаю там есть два варианта по-моему это кого из кого симес по-моему подтягивать Хосты и второй вариант статический Как вы вот делаете э эти настройки да Спасибо хороший практический вопрос на самом деле Отвечая на первый вопрос по поводу что он был Попроси Попроси А по поводу экспорта всё всё всё вспомнил по поводу экспорта Почему сразу не экспорте на коллекторы Дело в том что на Агента как я говорил мы делаем определённый легковесный процессинг а именно мы когда к нам данные приходят на Агент мы насыщая их информацие о ноде о релизе и так далее и чтобы как бы не делать это уже где-то в одной точке Да там в жирный на процесс ой на коллекторах мы это делаем быстро на агентах то есть это такой очень лёгкий при процессе начение данных не более чем и по поводу Лансера как я уже сказал мы форк и переписали и мы вообще ушли вот там Да есть самописный DNS резольвер вот это вот всё это мы сразу первым делом выкинули мы сделали вот статическую балансировку там по группам скажем так ну там тоже немножко хитро но основа это статическая балансировка потому что это нам показался уже какой-то который мы не можем контролировать Поэтому просто выкинули Отлично спасибо и последний вопрос в сессии Спасибо за доклад Я хотела спросить как вы выбираете что считать долгим Трей сом То есть это может же быть разное время для разных сервисов в зависимости от языка и других факторов и Ну то есть учитывает ли ваш л сэмплинг ээ специфику сервиса и как выбирается вот этот общий decision Window который Ну собственно сколько все трейс хранятся в памяти Спасибо тоже хороший вопрос на самом деле мы всё очень просто мы не делаем различия между сервисами Мы ещё в конфигах задаём что условно говоря там рейсы которые имеют там длительность больше там 500 миллисекунд всё их там должно быть там 30% от общей массы замлиння у нас на самом деле в планах есть сделать и адаптивное симпли самая главная возможность чтобы пользователи могли настраивать сами правила сливания сечас этого вот или нету этого не предвидится То есть это мы скоре всего будем делать сами и по поводу того как мы это считаем там тоже Всё достаточно просто это у вас есть панки и нам нужно просто получается пробежаться по всем с панкам получить Как выставить Вот это Window это тоже достаточно просто ну мы для себя рели это ние таким 99 они укладывались прилетали Спанки от них прилетали Вот в это окно То есть у нас на самом деле это около по-моему 12 секунд То есть да бывают рейсы которые могут длиться час но как бы ну извините ребят То есть как бы тут уже мы ничего не сделаем мы не можем час хранить все Спа Спасибо большое за вопросы Спасибо большое за ответы давай выберем вопрос который тебе понравился больше всего и подарим этому человеку матрёшку мне понравился вопрос по поводу Лансера и статический статического днса потому что это реально то место которое когда мы увидели мы тоже ужаснулись выбросили и забыли про это отлично Спасибо большое поднимите пожалуйста руку Спасибо вам за вопрос мы найдём вас и подарим вам матрёшку вас я тоже хотела бы поблагодарить Спасибо большое за доклад Это было очень круто нереальное количество людей очень очень полезный доклад Мы хотим Подарить вам подарок от конференции а ещё ещё хочется второй вопрос выбрать да ведь второй вопрос о вот девушка по поводу того по поводу н снов и decision Window потому что тоже для нас был такой щепетильный вопрос Мы это подбирали Да отлично поднимите тоже руку пожалуйста чтобы вас не потеряли Спасибо А ну а мы сейчас с вами прощаемся ненадолго L"
}