{
  "video_id": "KBEVw7B_zaA",
  "channel": "HighLoadChannel",
  "title": "Как воспитать себе помощника: применение локального ИИ для разработки / Алексей Цветков",
  "views": 3403,
  "duration": 2863,
  "published": "2025-01-17T02:35:22-08:00",
  "text": "Всем привет очень рад вас видеть здесь и я постараюсь чтобы сегодня для вас в этом докладе прозвучало что-то полезное Может быть вы этим даже сможете пользоваться вот в своей обычной жизни да и в работе я представлюсь Спасибо за представление первоначально Да вот я Алексей Цветков я Достаточно давно уже пишу программы получается что больше 10 лет как я пишу на го уже и теперь ещё так получилось что я Стараюсь помогать разработчикам сделать так чтобы их Рабочая жизнь да там выполнение задач было не только эффективным но ещё может быть приятным даже и вполне даже возможно что интересным И сегодня я попробую рассказать о том как у меня получилось использовать локальный искусственный интеллект который работает на моём ноутбуке в своих рабочих задачах и я начну прямо с того Вот как это можно запустить Что нужно для того чтобы это использовать А кроме раскрученный внешних сервисов искусственного интеллекта про который мы слышали Это gpt там кот ещ какие-то можем польва таким проектом который называется Lama cpp вы могли про него в принципе слышать и он нацелен на то чтобы позволить вам запустить модель искусственного интеллекта генеративную модель языковую сравнимую по мощности с gt4 там или gem Или другими такими моделями на самом обычном компьютере то есть обычный процессор МТИ оперативно Сколько нужно разработчику и даже не обязательно для этого иметь графический ускоритель если у Вас он встроен например в ноутбук Да там дискретная карта есть то вы сможете получать ответы от такой сети за секунды вместо того чтобы ждать несколько минут но всё равно даже без неё этот процесс выглядит как достаточно быстрый и удобный вот приме наото без графической карты на котором я тестировал те пром которые я буду показывать сегодня в презентации и я пользовался моделью китайской компании dips dips coder первая её версия вот у меня несколько вариантов было такого объёма здесь нужно заметить что вы можете эту штуку использовать даже на компьютере который не подключен к интернету Если у вас такие задачи там какие-то производственные есть но при этом нужно будет подумать как это в и затащить туда на этот компьютер Вот и есть ещ такое предположение обычно что у компьютера должно быть столько оперативной памяти чтобы вместить в себя всю модель чтобы она могла работать и с современными моделями на самом деле это уже не так я пользовался в своих примерах таким инструментом который называется Ома для того чтобы запускать модели и его можно скачать в виде Бинар для разных платформ запускать либо использовать докер образ который Они подготовили и в данном примере на слайде Я предлагаю скачать модель которая называется код stroll Она вышла всего месяц назад и она мощнее чем та модель которую Я использовал в своих экспериментах изначально а ещё можно сказать что у dipc кодера вышла буквально неделю назад новая версия которая ещё гораздо мощнее чем то что было у меня года тому назад но именно под омы Если попробовать её запустить Ну у меня по крайней мере так получилось что она стабильно падает в cump и есть там ию на гитхабе да о том чтобы это починить Я надеюсь что это разработчики скоро починят и можно будет пользоваться более мощной моделью dips coder версии 2 а второй инструмент который Мне необходим это плагин для инструмента разработки IDE vs или go в принципе любой дтб совский продукт позволяет этот плагин использовать он называется continue их вообще много всяких разных видов но я именно на этом сосредоточился этот плагин позволяет как обращаться к различным так называемым провайдерам вот этих вот генеративных моделей то есть ко внешним можно к Chat gpt или какому-то ещё там провайдеру а можно к локальному провайдеру обращаться А ещё там есть такая функция как построение векторного индекса или то что вы могли слышать и в предыдущих докладах даже да вот Workshop недавно прошёл про rag вот этот векторный индекс Да по кодовой базе которая у вас открыта в ID это расширение строит из коробки Ну там есть в нём ещё всякие функции типа там Tab completion Да автодополнение ещё какие-то вещи Вот и вы можете посмотреть на все эти функции на то как настроить и пользоваться ими в достаточно подробной документации на сайте этого расширения Теперь давайте уже к делу посмотрим Какие задачи Может этот искусственный интеллект решать и в первую очередь я попробовал самую такую простую Да задачку ему дать вопрос собеседования по го Мы же на го кон вс-таки Да значит я ему предложил написать функцию которая будет собирать че из нех каналов в один и я был достаточно удивлен когда спустя всего минуту мне моя локальная вот эта запущенная модель выдала ответ где используются и дженерики там произвольно количество каналов там есть группа чтобы синхронизировать эту работу закрытие этого канала выходного и ещё комментарий на русском языке написала да то выглядит достаточно прикольно но на самом деле уже в этот момент я стал понимать что здесь какая-то проблема кроется да И эта проблема на самом деле в том что в реальной рабочей задаче Я не знаю правильного ответа заранее и если на собеседовании я проверяю там этого соискатель да то здесь как бы если я никогда не видел Какое правильное решение для этой задачи то у меня сразу возникают сомнения Может быть там какие-то баги есть и действительно эта модель может закладывать свои ответы совсем не очевидные баги их нужно как-то искать А это всё Звучит достаточно печально потому что похоже Мы скорее усложнили наш процесс рабочий Теперь у нас есть куча кода который мы никогда не видели его надо ревью а это не самая приятная задача Но если немножко подумать мы можем попробовать эту проблему решить с помощью модели и можем ей задать такой запрос напиши нам Юнит тесты на эту функцию и тогда мы каждый этот Юнит тест можем уже рассматривать в отдельности и смотреть и на исходную постановку задачи и на то как она решена на всякие пограничные случаи и так далее да вообще насколько я понимаю этому искусственному интеллекту тесты нравится писать гораздо больше чем нам Обычно вот поэтому тоже достаточно прикольный результат как мне каже но ва вот мысль которую я хотел сегодня донести это что не только для небольших функций И не только для Юнит тестов А в принципе когда мы пытаемся использовать вот такую модель для какой-то задачи нам неплохо было бы этот трюк применить то есть попробовать её заставить проваливать тот ответ и те результаты Которые она нам дала Теперь давайте посмотрим на какие-то более сложные кейсы не всё же у нас задачки собеседований да аэ как в каком-то реальном проекте можно это применить и э я конечно не мог реальный рабочий проект притащить на слайды это было бы очень сложно объяснять Поэтому я решил создать проект с нуля но это проект такой очень очень простой прототип распределённой платёжной системы А о чём я имею в виду вот есть просто сервис на Java который получает платёжное поручение от человечка и дальше он выполняет транзакцию между двумя шарда на которых ведутся балансы там каких-то кошельков этих пользователей соответственно шарды представляют собой сервисы Наго это два экземпляра сервиса каждый из которых подключен к своей базе там на постс он там ведёт эти балансы И вот так вот будет выглядеть схема взаимодействия есть последовательно вст это успешный кейс только нарисован да то есть мы там отправили какой-то вызов grpc он разлетелся по двум шардам пошёл в базу Там и всё в итоге закончилось хорошо так вот эти схемы мне сгенерировал модель локальная когда я ей на вход подал Исходный код этих сервисов Навой Наго А самый Исходный код этих сервисов Я тоже сгенерировал с помощью модели сначала и я генерируют Исходный код что ещё мне удалось с помощью модели в этом проекте сгенерить в первую очередь это описание jpc AP потом ещё доке файл для того чтобы собрать всё это потом ещё конфиги для того чтобы в doer comp запустить потом Ну вот описание схемы и ещ тест-кейсы тест-кейсы выглядят примерно так на русском языке написана последовательность действий и там ещё даже есть примеры Как запустить утилиту консольную jpc клиент Какие нужно параметры включить там для того чтобы сделать перевод между двумя кошельками вот Я перевожу там 500 единиц и потом мне ещё модель предлагает проверить я должен запросить сколько там баланс да Какая история операции у этого кошелька и она предполагает какой придёт ответ так вот эти предположения строит не имея какой-то запущенной версии моего моей системы а просто по исходника которые я ей дал на вход То есть она понимает что это платёжная система и там такие-то функции должны выполняться и история должна появиться И так далее Вот это тоже выглядит достаточно прикольно но кто-то может сразу сказать что Ну а что у нас любой джун тестировщик напишет такие тест-кейсы как бы может что-то она может е более интересно делать Ну я тогда её спрашиваю а что ты более интересное можешь ещё нам предложить Она говорит ну можно сделать вот тестирование обработки ошибок параллелизма тестирование нагрузочное отказа устойчивости тестирования и так далее и по каждому из вот этих типов Вы можете сами дальше задавать более подробные вопросы и можете прийти к тому что она для вас создаст какой-то код или каркас хотя бы на основе которого вы можете запустить там нагрузочный те или тестирование отказа устойчивости Ну хорошо В итоге у меня получилась система из нескольких там сервисов компонентов который запускается и больше того в ней ещё отрабатывает функциональный тест который также автоматически срабатывает и он был написан с помощью этой генеративной языковой модели всего это 15 файлов вы можете посмотреть на гитхабе вот в моём репозитории все эти артефакты и собственно сессию тех вопросов и ответов которые я получал для того чтобы это разработать и вот на диаграмме Вы можете увидеть 15 файлов и оранжевым там помечено количество строк а которые модель сгенерить сама и их не пришлось менять а синим помечено количество строк которые всё-таки мне пришлось поменять то есть совсем без ручных изменений Не обошлось чтобы это всё могло подняться и заработать и тест успешно отработать Но вот видите размер этих синих прямоугольников показывает что похоже порядка 5% там изменений Да 5% строк мне пришлось вникать в них для того чтобы это всё вместе заработало А если мы это сгруппируй по видам артефактов то можем увидеть в первую очередь что запросы на русском языке которые я в начале давал чтобы она мне сне вот в их ответах вообще ничего менять практически не пришлось как я и сказал Сделай мне вот для переводов балансов между там кошельками вот так она собственно и сделала со всеми там типами данных и прочим Значит на го получилось чуть больше строк кода чем на Джаве но ручных изменений Пришлось сделать одинаково что на что на и я это могу попробовать что Java более многословный язык и в одной строке Там модель может больше ошибиться Да больше вероятность что она ошибится А ну хорошо На самом деле это не тот результат который я вам хотел показать Почему Потому что Вы наверняка многие из вас думают что эффективность нашей работы как программиста заключается не в количестве строк кода который мы делаем да вот а и я с вами соглашусь а больше всего я хотел показать Вот как можно создавать эти пром и какие вообще штуки этот инструмент может В нашей работе производить полезные и вот смотря на это количество строк кода я стал понимать что наверное наиболее сложное занятие В нашей работе задачах это читать и понимать код или постановку задач или логи или какие-то ещ результаты разбираться в них делать какие-то выводы я предположил что это сложно для нас потому что нужно во внимании держать сразу много объектов А ещё и связи между ними и тут я понял что кажется в этом этот искусственный интеллект как может быть нам полезен моей сессии увидеть такой запрос Значит у меня есть какое-то описание прото jpc Я хочу из него создать обёртки на го чтобы там реализацию потом написать но я не хочу вот это устанавливать там Проси плагины для него там знаете да вот эту всю тему а я хочу просто готовый докер образ взять который это всё умеет уже я не знаю такой где есть и как он называется и так далее И вообще мне было бы ну приятно это было обр например вфа чтобы я написал Make и у меня сразу обёртки сгенерить и моя вот эта модель локальная она в течение пары минут может мне дать готовый ответ например как это можно сделать если бы я пытался это сделать вручную то даже имея определённый опыт с этими всеми вещами Да мне бы потребовалось там минут 20 для того чтобы это всё собрать гуглить Там и так далее да а больше всего я хотел показать что она не просто может мне создать файл А что она может разные сложные объекты между собой как-то сопоставить и я её прошу вот Свяжи мне да с помощью кода эти вещи и она мне выдаёт код который их связывает Ну хорошо А теперь Более сложный пример в этом расширение коню есть такая фишка что мы можем в запросе через собачку фа указывать вот из нашего проекта из нашей кодовой базы какой-то файл который будет добавлен в запрос автоматически и здесь у меня такая ситуация у меня есть уже описание AP и я ещё спроектировал какую-то структуру там базы данных таблиц А вот писать круд который будет это связывать я его на такую структуру в базе и он достаточно хорошо понимает да что там нужно реализовать определённую в го структуру там методы такие всякие сделать и так далее вот он сделал мне какую-то реализацию вот я естественно стал её проверять И я там замечаю что он обращается пишет в таблицу балансов и в таблицу истории операций не использу транзакцию то есть в какой-то момент это может развалиться да рас синхронизироваться типа там по запись а баланс поменялся и я подумал а что если я попробую какими-то такими очень общими абстрактными намёками попросить её эту ситуацию исправить Я говорю а вот консистентной которое ты сделала Да в этом там в этой реализации А и она мне сразу отвечает что действительно надо поправить надо использовать транзакцию меня в принципе впечатлило тоже Ну хорошо А теперь ещё Более сложный инструмент про который я обещал рассказать это м rag или а retrieval augmented Generation то есть генерация расширенная за счёт получения А что мы хотим получать раз это получение А мы хотим так же как на предыдущем слайде мы использовали конкретные файлы из нашей кодовой базы Мы хотим к нашему запросу добавлять какие-то кусочки из всей кодовой базы и вот этот механизм R он в случае расширения кон работает так что вся наша кодовая база она разбивается на такие фрагменты даже с перекрытием и для каждого из этих фрагментов мы пропускаем его через модель и модель выдаёт нам какое-то численное представление смысла этого чка текста какой-то Вектор смысла или эмбеддинг ещё его называют и вот эти эмбеддинг Мы складываем в векторный индекс а следующим этапом Когда мы задаём уже какой-то промт запрос то этот запрос тоже пропускается через модель Из него получается мбенг и по этому им бенгу Мы в нашем индексе находим такие кусочки такие фрагменты кодовой базы которые соответствуют по смыслу этому запросу а как это выглядит Да я использую вот ключевое слово cbase в этом расширении контини Да оно позволяет как раз добавить в запрос такие кусочки из моей реализации которые соответствует смысл этого запроса Например я спрашиваю Какие сервисы вообще там реализованы в этой кодовой базе она получает на вход дополнительно Вот мои там какие-то части фрагменты и говорит что там есть вот сервисы они работают так-то так-то Вот я полный там листинг не стал здесь приводить но вот вы пожалуйста сейчас Подумайте и я вас прошу Поднимите руки у кого такая ситуация была вы получаете от какой-то другой команды или пришли на новое место работы получаете какую-то большую кодовую базу в которой нужно срочно разобраться была такая ситуация Поднимите руки у кого тако было отлично у многих такое было вот а что если у вас был бы такой помощник который может Вам подсказать вот в этой во всей кодовой базе где происходит например распределение моих аккаунтов по различным шардам Помните я картинку да про шарды показывал А и тут это этот инструмент справляется в принципе он находит место из своего индекса где там происходит это распределение и на русском языке он мне отвечает что вот берётся остаток отделения на два то есть чётные кошельки идут в один шарт нечётные в другой И вот так это как бы всё и работает хорошо а теперь чтобы у вас Осталось совсем сказочная впечатление от этого инструмента Я предлагаю немножко помечтать А что бы он ещё мог такого делать для нас и моя например Мечта это чтобы когда Я понимаю что нужно делать какой-то рефакторинг Да вот меня там что-то вот сильно беспокоит в этой кодовой базе А чтобы я мог попросить предоставить мне план что надо будет поменять для этого рефакторинга вообще легко это будет сделать или нет В какое количество файлов нужно внести изменений и так далее а совсем было бы круто если он сам Может это исполнить вот а не знаю может моя мечта Фантастическая Но я ещё вот несколько других вариантов придумал а Например я сделал какую-то задачу большую У меня есть МР там вроде посмотрели всё и мне хочется или перед тем как я его буду отдавать на ревью мне хочется понять а не нужно ли там ещё поправить документацию на какие-то э на какую-то логику которую я поменял а может быть ещё такой совсем фантастический сценарий вот мне аналитики написали постановку задачи большую я сделал МР да А теперь нужно понять вот оно вообще как-то бьётся между собой или нет Или может быть там что-то упущено Может быть там есть какая-то небольшая деталь которая сильно повлияет на то как я это реализовал А И на самом деле я думаю что каждый из нас в принципе хотел бы оказаться на месте вот этого парня в синем галстуке и теперь есть для этого шанс неплохой потому что вот этот локальный искусственный интеллект Он может быть гораздо внимательнее в моих рабочих задачах чем я сам и чем мои коллеги которые им не пользуются ещё вот поэтому Шанс есть заметить не только технические какие-то нестыковки Но даже может быть и бизнесом быть полезно на разных так скажем уровнях Да иметь разные эффекты Ну хорошо давайте посмотрим как это всё-таки можно реализовать реально есть такой проект опять же как и многие другие которые я упоминал сегодня орный проект называется и Он позволяет э как одна из фичей одна из из возможных кейсов один из кейсов а реализовать э детализацию запросов на самом деле это инструмент нужен для того чтобы автоматизировать каким-то образом По сценариям автоматизировать общение с этой генеративной моделью вот а здесь я могу например распознать что мой запрос увеличить количество шардов в этой кодовой базе имеет отношение к рефакторинга и аэ Ну в таком игрушечном проекте про который я рассказываю Похоже что там не очень всё готово к тому чтобы увеличить количество шардов и Практически везде нужно будет вносить изменения А мне нужно понять где конкретно Какие изменения и поэтому я такие запросы могу вопросы могу автоматически добавить в мой промт А ещё я хотел бы добавить такой запрос а вот как мне эти все изменения сделать так чтобы э сократить количество кода а не увеличить его потому что в рефакторинг Наверное я бы хотел как раз чего-то такого И когда я своему э этому ии задал такой промт то он мне вывел список из конкретных мест и конкретные предложения вот что можно поменять там добавить и так далее А это достаточно прикольно но Единственное во втором пункте он там всё равно считает что два шарда должно быть почему-то да вот поэтому это надо же проверять но о ЧМ Я хотел сказать это что Вот если бы у меня был такой помощник который когда я работаю над задачей мне перечислил ещё дополнительно все возможные изменения которые мне нужно внести да или там какие-то части которые могут быть затронуты в этом процессе то мне бы было гораздо счастливее жить И вот я всю эту сказочную картину вам представил дат хотелось бы сказать ещё что он не может может научится А может и не научится делать хорошо какие-то вещи а во-первых это конечно отладка сложных кейсов Когда в ран тайме у меня там какая-то ситуация специфическое возникла и вот погрузиться во всю Вот эту вот конструкцию Да и в то состояние в котором система сейчас пребывает просто так он не может То есть ему либо надо это всё долго как-то объяснять он может делать какие-то подсказки но это не тот инструмент с помощью которого вы можете отлаживать программы значит А следующий момент - это что у него ограниченный контекст А вот у той старой модели э полугодовой давности 16.000 токенов всего контекст у второй версии которая вот недавно вышла у неё на порядок больше уже контекст а контекст - это вот количество так скажем букв или частей слов там которые он может воспринять Да принять на вход и соответственно там сгенерить какой-то ответ но даже если этот контекст у него увеличится вот как сегодня рассказывали на воркшопе про ра во-первых засунуть сразу всю кодовую базу в один промт может быть технически возможно но это будет работать очень медленно пока что да А во-вторых у него есть ещё такое понятие как внимание То есть он когда генерить Ответ он как бы он сосредоточен имеет фокус на какой-то определённой идее Поэтому если сразу засунуть в него всё не уверен что он выдаст вам хорошие ответы какие-то хорошие результаты ну и связанны с этим вещи это что он не может одновременно редактировать несколько файлов сразу и не может выполнять вот по одному запросу выполнять много каких-то разнородных действий то есть для него всё равно нужно дробить на кусочки Да как-то разжёвывать что я от него хочу но как вы видели в предыдущих моих примерах он всё равно достаточно абстрактные вещи может понимать и Интересно этим пробовать пользоваться а-а в качестве заключения А я хотел бы такие три основные идеи рассказать А значит вот эти даже локальные Не говоря уже о внешних там каких-то да сторонних мощных и моделях даже локальные генеративные модели они уже достаточно хорошо понимают то чем мы занимаемся на работе на уровне разработчика в принципе а При этом когда они создают свои ответы выводы они могут допускать ошибки и к этому нужно Быть готовым но не просто так что типа вот ну там мы даже и не думали что он типа правильно ответит А Скорее это вполне в наших силах как-то процедурно Это от этого защититься Да какие-то придумать какие-то тесты да или что-то ещё что поможет нам избегать таких ошибок Вот ну и самый последний вывод э такой мотивирующий то что в принципе ну вот этот бум искусственного интеллекта он дошёл наконец Ну он и раньше пытался Да Зайти Теперь он уже гораздо сильнее пришёл на нашу улицу а действительно эти инструменты повышают скорость работы и качества результатов которые мы получаем А И если мы не будем этим пользоваться то наверняка этим будет пользоваться какой-то другой разработчик Который наш конкурент на рынке труда поэтому я вас призываю скорее обратить на все вот эти вот вещи Спасибо за внимание и пожалуйста Оцените доклад Спасибо Спасибо большое за доклад очень круто ещё и прикладная штука можно самому начать использовать Есть ли вопросы в зале Если у вас есть это было очень неожиданный эффектно если вопрос в зале подл ле ру Если у вас есть вопрос держите руку высоко к вам подойдут с микрофоном задавайте пожалуйста свой микрофон громко и чётко ой свой вопрос в микрофон громко и чётко Давайте прямо начнём вот с последних рядов Добрый день Андрей лохов немножечко холивар вопрос Вот ты показывал что тебе пришлось править Тебе пришлось вникать в контекст и вот Исходя из этого как ты оцениваешь применимость этих решений для использования их начинающими разработчиками Джуниора Потому что есть мнение полярные мнения от того что они повышают их продуктивность до альтернативы что нет ни в коем случае нельзя использовать они так ничему не научатся вот какое лично твоё мнение Спасибо Да хороший вопрос Спасибо действительно холивар Мне кажется они многому могут научиться у этого искусственного интеллекта Да если будут им пользоваться другое дело я бы со своей как бы колокольне Скорее это воспринял Так что не слишком ли сложная задача которую я поручаю вот этому джуниору Да чтобы он там что-то наге нери в gpt и не понимал как это работает то есть мне нужно как-то процесс всё-таки выстроить чтобы он сам это потестить бы ну такая практика же есть в компаниях Спасибо Спасибо ещё вопросы Из зала Давайте с правой половины зала а здравствуйте Спасибо за доклад А я бы хотела спросить такой вопрос допустим если а использовать эту модель использовать Несе для генерации кода А И если допустим в команде или в компании есть какой-то свой стиль есть уже какая-то кодовая база но а там код всё равно каждый человек ну пишет Не идеально то как бы вы представили себе подготовку кодовой базы для обучения модели чтобы она могла писать в стиле команды в стиле компании и так далее такой вопрос Спасибо тоже отличный вопрос Вообще но смотрите я затронул одну из методик вот так скажем настройки этой модели с помощью Рак да то есть мы ей пытаемся во время запроса подсовывать какие-то вещи например мы могли бы всегда ей давать на вход дополнительно Вот это соглашение о стили там или ещ что-то подобное я не исследователь не могу сказать это будет хорошо эффективно работать по сравнению с другими более сложными методиками про которые я слышал Да это Например какой-то Файн тюнинг за счёт того чтобы разрабатывать адаптеры для этих моделей я совсем коротко пытаюсь объяснить что это такое значит вот саму эту большую такую модель обучить с нуля Это очень дорого На самом деле очень дорого вот поэтому сейчас они придумали делать так скажем предварительный дополнительный слой на входе который позволяет как-то преобразовать запрос и возможно преобразовать ответ вот в эту сторону некоторые компании уже смотрят и активно пытаются на обучать такие вот адаптеры которые будут под их задачи уже немножко тюнить модель Спасибо Спасибо у нас есть вопрос с чата э я знаю что это кусочек его озвучивал в докладе но я тем не менее озвучу сравнивал ли ты вот эту штуку про которую ты рассказывал с github из Много ли преимуществ по сравнению с ними Спасибо хороший вопрос Нет я совсем не сравнивал потому что у меня изначально была задача такая чтобы можно было например Это использовать на компьютере без интернета и там ну это собственно то что ты озвучила оффлайн это можно использовать оффлайн ещё вопросы Из зала Давайте с левой половины Принесите ближайшему человеку микрофон День добрый Спасибо за доклад ба У меня вопрос Следующий Были ли какие-то измерения то есть допустим забеги Как это работает сравнительно Вот если бы вы это делали руками потому что то что я увидел вот эти графики то что там Ну примерно 10% кода приходилось исправлять То есть это нужно всё просмотреть найти исправить и то же самое протестировать сколько вот по времени сравнительно если бы это сделали Вы просто руками с нуля написали и ещё можно токенов 384 сколько это примерно по коду получается Сколько строк кода там умещается в эти 16000 токенов контекста Спасибо хороший вопрос по поводу токенов опять же я не специалист не могу здесь однозначно достоверно утверждать Я бы сравнил это с размером в байтах просто этого кода условно говоря 16Б у не вот окно котом она может оперировать а что касается времени я естественно не не успел это дело всё замерять Да это нужно был большую какую-то там методику Я не знаю да разрабатывать как правильно это время померить в сравнении но во-первых я не пробовал именно такой прототип специально отдельно самостоятельно вручную написать но честно сказать когда я начинал вот это вот формировать промто и так далее я ещё только учился и у меня реально очень много времени ушло на то что чтобы это заставить работать то есть вся разработка этого проекта у меня заняла Ну наверное недели две полного рабочего времени я думаю что я бы быстрее написал такой прототип сам но я не могу говорить за Джуна например которого такая задача была бы я не уверен что он бы Ну разные уровни бывают может быть он бы за месяц такой прототип мне написал на гой на Джаве и со всякими там тран спасибо спасибо Я думаю что этот вопрос можно обсуждать дальше Потому что действительно зависит от разных вещей у кого ещё есть есть вопрос поднимите пожалуйста руку Давайте подойдём на первый ряд и выдадим микрофон и пока Человек идёт сдесь на первый ряд Давайте там вот к Дальнему тоже подойдём поближе чтобы сразу же после можно было задать тоже вопрос а Алексей спасибо большое за доклад очень Мне было интересно я апрес Антонян из азом банка У меня вопрос такой больше бытовой тут говорилось про то что хорошо делает Что нехорошо делает мне интересно при подготовки вот этого доклада и всего проекта особенно вот на первых этапах было ли что-то что от чего вы ожидали больше и лучше что справится модель А вышло плохо или может быть на примере тех строк кода которые вам приходилось исправлять сформировалось впечатление о том что вот конкретно с этим справляется хуже модель Спасибо Да хороший вопрос здесь Я попробую да как-то сжато Ответить касательно каких-то вот технологий да Или ещ чего-то такого чтобы у не в каких-то темах были пробелы Например я такого не заметил я на это не смотрел специально я не думаю что это в принципе есть потому что у не очень большой корпус на котором она обучается первое что меня на самом деле сильно де мотивировало когда я начинал это то что там этот процесс генерации ответа он вероятностный то есть я могу задавать одни и те же запросы и получать совсем разный ответ по качеству да а это на самом деле исправляется тем чтобы повысить качество используемой модели то есть взять например не кванти зова ную версию или ту версию у которой больше э количество токенов так скажем Да там вот то есть запустить этнографической карте там для этого или ещё какие-то такие вещи делать то есть Чем более мощная модель тем она естественно лучше попадает в мои запросы спасибо спасибо вопросы из дальнего конца Спасибо за доклад вопрос тоже немного прикладной тире бытовой А вот это расширение для редактора кода оно отслеживает например э Граф зависимостей первый вопрос и второй тоже немного вытекает отслеживает ли например АСТ дерева самого кода проекта то есть Ну понятно что 16 КБ - Это довольно мало но используется ли хотя бы что-то из вот чтобы сохранять семантику потоков данных ну потока обработки спасибо спасибо насколько мне известно Ну вот само расширение оно не привязано Никакому языку конкретно и модель тоже не привязана обычно Никакому языку То есть если говорить про го там вот этого разбора синтаксического она никакого не делает она просто как текст подаёт и возвращает Вы можете в своём запросе просить сделать вот программу на Go или на JavaScript или с определённым стилем например да как до этого задавали Вопрос вот ну и последнее что хотел сказать Вот это новая версия этого пси кодера у неё заявлено там что она знает 338 что ли языков программирование Я честно даже не слышал про такое количество поэтому Ну и это вот одна модель которая умеет на всём этом писать Спасибо Спасибо большое Есть ли ещ вопросы в зале последнем ряду есть вопрос Спасибо за доклад Меня интересует Ты знаешь какие-нибудь случаи что при локальном развёртывании модели были какие-то угрозы безопасности или может быть сам опасаешься чего-то да Спасибо отличный вопрос мне немножко доводилось раньше работать с безопасностью и у меня когда я стал на всё это смотреть конечно возникла идея что в эту моде мо ложить какие-то закладки чтобы она что-то выдавала с ошибками Хотя бы да на определённые запросы Я не знаю про такие исследования и кейсов таких не слышал но я убеждён что они появятся Скорее всего в этом году или в следующем Спасибо Спасибо большое слева вопрос Добрый день Чернышов Андрей товарно сырьевая биржа подскажите пожалуйста предположим мы нанм использовать локальный итм какой-то наш домашний закрытый проект и далее возникает ситуация такая что мы ным количеством запросов к этому и ну по сути дела вводим его в этот контекст И как долго этот контекст будет храниться грубо говоря мы перезапустить образ он забудет всё или нет Можно ли его сохранить более того Можно ли затюнить этот контекст так чтобы в дальнейшем перезагрузке при перезагрузке образа он уже понимал что ну с чем он работает и пытаться его уже как-то как под тот или иной проект Ну и в принципе этих же можно наделать очень много разных инстан и затачивать его каждый под свой локальный проект Да спасибо большое Хороший вопрос Он очень обширный Я могу только указать вот направление про которое я уже говорил это либо раг да либо вот построение адаптеров этих может быть ещё что-то уже придумали Просто я не слыша об этом СБО СБО Привет Спасибо за доклад У меня вопрос один вопрос Это собственно насколько ты при использовании перегрин Ну собственно ответы нейронки Они же вероятностные в зависимости от того насколько тюни температуру вверх оно может те очень сильно раздавать собственно Сколько чепиков было из при использовании И второй вопрос Ну это доводилось ли сравнивать с другими моделями Возможно не заточенный под кодинг например взять Мистраль какой-нибудь 78 и сравнить заточенную под кодин моде особенно в области аргументации про архитектуру с заточенный под кодинг не заточенный под кодинг заточенный под кодинг Спасибо Спасибо большое отличный вопросы по поводу черенга значит вот здесь Кстати да прозвучало про температуру это вот один из параметров который можно использовать чтобы настраивать если температура в ноль то она не будет пытаться ничего придумывать а будет просто вот пытаться из того что она знает выдавать решение вот а значит поначалу мне приходилось очень много раз пробовать потом когда я стал немножко учиться писать эти промпто у меня уже получалось как-то построить это предложение там на русском языке или как-то упомянуть определённый фрагменты чтобы она мне выдавала уже больше похожее на то что я ожидаю от неё получить и ещё здесь был важный момент в какой-то чем дальше я разрабатывал да тем более вот эти абстрактные вопросы там какие-то появлялись более абстрактные артефакты я хотел получить типа вот схему архитектуры Там и так далее вот а тем А как бы тем тем скорее а я как бы уходил в слишком общие какие-то вопросы да или слишком общий а ввод подавал ей в запросе и она не могла ответить конкретно того что я ожидал от неё поэтому постепенно Я понял что мне нужно всё-таки вот разжёвывать и конкретизировать сужать сво свой э Запрос который я пытаюсь а задать а что касается мистрали то вот этот код сль построен про который я говорил он построен насколько я знаю этой же компании Да на основе её наработок вот я не пробовал всё это делать с моделями которые не заточены на код а потому что ну как бы некоторые запросы я им задавал они отвечают менее качественно или они отвечают что я не могу понять о чём это да вот а что касается архитектуры Я тоже не думаю что они будут сильны в этих ответах скорее вот обученные на кодовой базе модели Они же получают не только сам код но ещё и всякие redmi файлы какие-то и прочие вещи из которых она знает там про ПН uml и про то как это всё связать между собой и нарисовать Спасибо Надеюсь ответил Спасибо вопрос с первого ряда слева половина зала Спасибо за доклад Максим умин ВК подскажи пожалуйста а какие права доступа вообще у вот этого исполняемого файла который ты видимо запускаешь вот у себя на компе То есть он очевидно может читать файлы Видимо он может писать файлы тоже А может ли он например исполнять файлы может ли он собрать сам софт который написал удостовериться что там нет ошибок запустить тест и только после какой-то вот тайри выдавать результат собственно человеку и может ли он параллельно с этим сделать R - RF СШ Хороший вопрос провокационный Я в начале так подумал когда его слушал на самом деле он по делу вполне Как как мне кажется да Вот я немножко рассказывал про Long Chain про то что можно автоматизировать как-то там даже исполнение вот этих действий да Но насколько я видел это нужно делать с помощью специальных так скажем плагинов которые могут вот эти вещи там генерить файл или там что-то перемещать собирать Там и так далее а сама по себе эта модель она запускается там в докер контейнере у неё есть репи да такое же как у внешних провайдеров Ну и собственно она может на вход получать рест запрос и ответ выдавать с Ну как бы с с ответом ответ спасибо спасибо коллеги Большое спасибо вам за вопросы Извините у нас просто нет времени ответить на все вопросы которые есть в зале но я очень рада интересу можно будет встретиться с докладчиком дальше в дискуссионной зоне поймать его После закрытия конференции и поговорить уже лично на эти темы я уверена что ты не будешь против поговорить вообще Вот только за Вот давай выберем с тобой вопрос который тебе понравился Больше всего мне очень понравился вопрос девушки которая как бы в ответе которой пришлось сказать про адапторы пото Я думаю это будущее развитие вот этих всех тук Отлично Вы можете оставаться тамм вас на сцену но мы подарим вам обязательно подарок поэтому не убегайте Спасибо большое спасибо вас Мы тоже Хотим поблагодарить очень круто по количеству вопросов видно насколько это живая важная тема Спасибо большое Спасибо большое вам спасибо за внимание Очень приятно было с вами пообщаться друзья это был заключительный доклад конференции гон в рамках п+ 2024 Я очень рада была быть с вами эти 2 дня это было очень круто мы обязательно встретимся ещё я приглашаю Вас на закрытие конференции"
}