{
  "video_id": "oUzBF299iUo",
  "channel": "HighLoadChannel",
  "title": "Как VK вставляет данные в ClickHouse с десятков тысяч серверов / Юрий Насретдинов (ВКонтакте)",
  "views": 3127,
  "duration": 2904,
  "published": "2019-01-14T00:08:38-08:00",
  "text": "давай вот до класс вопрос а кто у или знает что ecли house ну на самом деле не все подняли руки поэтому я чуть-чуть скажу о том что это такое crack house это база данных от яндекса которая была звуком совершенно несколько лет назад там два года назад и которая используется для яндекс аналитики яндекс метрики в качестве основного движка хранения данных построения графиков и так далее вот я буду рассказывать о том как мы туда доставляем данные с нашего парка серверов ну в плане я расскажу потом зачем нам вообще понадобилось cliff house почему именно он приведу некоторые цифры сколько у нас получилось выжить если house на наших бенчмарках просто для справки и дальше расскажу про то как мы собственно вставляем данные с какими проблемами мы встретились когда начинали его эксплуатацию и про два наших инструмента которые будут выложены вулкан source get in house lighthouse а зачем нам вообще понадобился коли house у нас была такая задача храните смотреть дебаг логе структурированная дебаг логе от наших разных сервисов и желательно еще может быть какую-то статистику месяц убирать показывать но это не обязательно на самом деле в основном мы хотели научиться эффективно и быстро хранить логии и смотреть их и у нас большой парк серверов нам нужно где-то там с 20 30 тысяч машин это собирать начну с небольшого тизера почему вообще нам потребовалось что-то менять нас есть такой public называется backend vk я проверю что вы все подписались на него после доклада там есть такой такая запись за 10 ноября 2017 года где разговор двух сотрудников что такое лот лакс engine и ответ этот движок возвращающие пустые массивы то есть по идее это наши логе ну почему так я расскажу чуть позже чтобы сохранить интригу ну давайте посмотрим вообще как в индустрии принято хранить и обрабатывать логе ну первое что я обязан упомянуть от hadoop более приземленные варианты это например версия слова и сохранение файла или же вот например подушная разработка под названием лсд которые на замену скраба от фейсбука сделано ну это же хранение логов в итоге файлов и house или свой смешной вариант что мы хотим мы хотим чтобы ну желательно дам мы ничего такого серьезного не хотим хранить мы хотим хранить дебаг логе мы хотим простоту эксплуатации потому что большом парке машин это все будет эксплуатироваться настраивать нам все лень мы хотим все по-быстрому сделать потом естественно мы хотим собирать большой скоростью и читать потом оттуда тоже достаточно быстро при этом хранить эти лаги месяцы или даже годы чтобы можно было расследовать инциденты которые случились давно какого-то юзера и уже это случилось постфактум и к нам с саппортом дошло через месяц потом было бы плюсом сжатия данных потому что как рассказал как было на слайде нарисовано там сотни терабайт данных желательный чтобы система поддерживал прозрачное сжатие если возможно и мы иногда хотим странного мы хотим писать длинные строки больше чем 4 килобайта также если система поддерживает запись по египет а это будет большой плюс потому что ну с 30 тысяч постов не очень удобно tcp соединения устанавливать что из себя представляет logs engine это движок для хранения логов как можно догадаться из названия но у него во первых нет сжатия хотя это можно организовать самостоятельно и самая большая проблема что он умеет отдавать данные только из оперативной памяти то есть все данные которые в оперативную память уже не влезли отдавать этот движок не умеет соответственно есть проблема с долговременным и хранением несмотря на то что вконтакте большая компания можете позволить много серверов все равно мы ограничены объемом оперативной памяти это не очень удобно ходов ну как вы думаете кто из вас считают что hadoop хорошие решения для дебаг логов ну хорошо слава богу что никто потому что ну во первых это большая очень ын су структура которая только чтобы защита пить нужно большое количество времени и когда мы говорим о ходу пим и скорее всего даже раем какой нехаев или что-нибудь подобное и у него достаточно медленно чтение ну как очень медленное чтение на самом деле и также не решена проблема с тем как туда писать то есть нам все равно придется что-то придумывать своей практике писать для того чтобы писать по и т.п. ну да первый слог кто из вас слышал про вирусы сок или используется в продакшене честно говоря же даст весь зал поднимет руки ну ладно но рекомендую эту штуку на самом деле она это демон который позор который реализует syslog протокол и умеет большого количества машин вставлять данные ну вернее не вставлять данные доставлять логе структурированные тоже в принципе но у него есть несколько проблем ну во-первых поскольку мы пишем файл это читать мы оттуда можем только гриппом а это медленно сжатии данных из коробки не поддерживается тоже нужно самому пилить и самое главное его проблемы это то что он несмотря то что умеет по и т.п. он не умеет вообще в принципе писать мы не можем писать строки больше чем старика байта в него а если поедите работаем то и больше чем в один пакет то есть полтора килобайта мы не можем писать тем не менее мы использовали эту схему как запасную для долговременного хранения лсд в принципе у него похожие свойства то есть тоже нет сжатия данных тоже мы пишем файлы но хотя бы поддерживается запись длинный срок но зато не поддерживаете dp и соответственно у вас будет огромное количество tcp соединение установлен и наконец-то мы подходим к хаусу с ним все хорошо кроме того что он не подержите и т.п. я к сожалению не подготовился к докладу и не заметил пришел ли алексей надо кого-то или нет алексей сделайте пожалуйста и т.п. хотя бы в каком то виде что вы можете ожидать от клик хаоса в плане производительности но и просто чтобы заполнить чем-то время рассказ да классно сказал она не важно короче говоря если вам вдруг интересно какие какое железо мы используем мы используем далеко не самые топовые тачки это там 26 ядерно кассиана 200 гигабайт оперативной памяти и там порядка двадцати терабайт диск а вот на такой конфигурации мы можем составлять примерно 4 гигабит в секунду если речь идет про поиск то вы можете ожидать скорость фильтрации например 6 миллиарда строк в секунды если это фильтрация по какому-нибудь полю которая хорошо сжимается типа даты если вы хотите игре падь делать запросы с лайком на строковую поля ту конечно скорость быть не такая высокая но все равно это сотни миллионов строк в секунду итак вопрос да доклады как вставлять ну вы и нами все знаете что в контакте работает на печке в основном и соответственно мы будем вставлять очень простому возьмем со всех наших маркеров на каждый из 30 тысяч not установим по соединению и будем почти теперь вставлять в мир 4 обычный кто считают хорошей схема так можно делать ну хорошо никто не считает почему дело в том что во первых это очень много соединений то есть вы будете устанавливать по соединение не просто с машины с маркера и грубо говоря есть у нас простого киров на серверу 30 тысяч серверов ты получаются сколько 3 миллиона соединений многовато во вторых в мираж-3 можно вставлять не больше одного раза в секунду или лучше реже ну то есть вы в принципе то вы можете вставлять и чаще но работать будет плохо и к тому же мы хотим мы вернее не хотим иметь промежутке сервера потому что все таки мы хотим много кластеров при house и еще столько же машин для агрегации перед клик хаусом это ну как минимум дорого во вторых cliff house позволяет писать в него намного быстрее чем скорость записи на диск то есть в этих промежуточных машинах если мы захотим писать на диск то мы будем в нем упираться в первую очередь и это уже как-то странно будет кто знает почему в мираж-3 нельзя вставлять больше одного раза в секунду и как вообще -3 устроен ну смелее и смелее ну хотя примерно ладно к сожалению сегодня уроки ладно я расскажу у меня один слайд на это был подготовлен я думаю что все таки все знают h3 в ли хаусе работать следующим образом все данные во первых поделены на партиции обычно это данные за один месяц в партиях находятся файлы по одному файлу на колонку вернее даже по два и внутри партиции данные отсортированы в порядке возрастания первичного ключа при этом первичный ключ включался не гарантирует уникальность это просто название то есть на самом деле не первичный ключ это ключ для сортировки данных но когда вы вставку делаете в такую структуру понятно что вставка в середину отсортированного массива сделать нельзя даже если было можно это было бы очень дорого на диске делать поэтому кли house при вставке создает временную партицию с данными которые вы вставили в этом in certain сортирует там по первичному ключу и потом фоне меджид эти партиции в более крупные пока не задержит это в самую большую мы или в несколько самых больших партиций как можно догадаться из процесс достаточно дорогой и если вы будете вставлять там тысячи раз в секунду создавать тысячи партиций the cliff house умрет на мерсах потому что они еще все-таки на диск могут попадать если делается select то соответственно ну из сортировочного списка сделать select несложно даже по диапазону так какая схема более жизнеспособно на по крайне мере на нашем объеме мы для того чтобы уменьшить количество tcp соединений написали локальный прокси которые назвали kid in house и печки пишет туда кино хауз свою очередь агрегирует запись и делает ставку уже тоже почти тебе протоколу в кли house но перед коли хаусом стоит буферная таблицы что такое буферные таблицы это такие таблицы которые являются буфером в памяти поделена на несколько кусков количество кусков вы задаете при создании таблицы и они работают как независимые буферы эти таблицы позволяют туда вставлять весьма часто то есть действительно часто и как я сказал да эти куски раздельные и поэтому если вы например создадите буферную таблицу и время для сброса данных в основной таблицы вы стоите в две секунды и там будет набирать 16 кусков как предлагается в документации похоже на стройке то вы получите восемь калашей в секунду то есть 8 ставок номер 4 в секунду это говорил лучше не чаще 1 раза вставлять поэтому если вы используете буферные таблицы то имейте это в виду что-либо нужно кусков делать меньше либо если вы пишете очень много то делать флаш пореже эти таблицы поддерживать чтение то есть вы можете сделать select еще до того как они попали в основную таблица но есть огромное количество подводных камней с этим связанных например чтение блокировать запись в таблицу для буферных таблицей и соответственно это будет очень плохо сказываться на производительности если вы оттуда читайте в основном на наших тестах эта схема работает хорошо где-то до примерно 3000 вставок в секунду после если вы делаете больше то наверное все таки вам нужно что то еще и можно потерять данные то есть если например случайно вырубить питания то все что вы записали в буфер и что не попал еще минус 3 то оно запишется вдохнул с рипли фиксированными 3 таблицами шансов потерять данные в таком случае намного меньше хотя они тоже есть то есть в принципе вообще в кли house и нам не стоит хранить совсем супер критичные данные потому что немножко можно потерять где-нибудь также алексей вы тут нет zdravstvuite алексей а почему вы сделали буферные таблицы так что нужно делать alter два захода еще и с дропом таблицы очень неудобно мужем алексей оправдать с тем что буферный таблица вообще не надо было использовать и так понимаю но вот мы как-то не можем без них но в общем имейте в виду что если вы делаете alter таблицы то вся вставкой начинает идти в бездну чтобы она не шилов дивану вам нужно сначала удалить буферную таблицу проветрить таблицу исходную и потом создать буфер заново естественно пока я таблице нет данные тоже этот дивный ну хотя бы вы уже в курсе о том что так делать не надо просто altered это отдельный вопрос к алексею почему если недостаточно колонок в ну в смысле в буфере например там 10 колонка в родительской таблица 11 главный тоже не вставляется то есть если мы добавляем колонка всё сложно так что умеет наш прокси это прокси нога кто считает что гоку вас на язык а кто считает что вообще ни для чего не подходит ну ладно вам можно это прокси сделано для того чтобы поддерживать 1 tcp соединения на сервер также она умеет во флуд контроль то есть если вы пишете слишком много с одной машины то если вы не выбрали надежную доставку то данные которые выходят за рамки ну вот у нас это 16 мегабайт за 2 секунды если вы больше пишите то все данные остальные выбрасываются чтобы не положить cliff house основные но также есть надежная доставка которая гарантирует доставку от нуля до бесконечности 1 от 0 потому что это работает путем записи на локальный диск на машине и потом фоне попытке вставить cliff house если все-таки машина с которой вы вставляете умрет то данное вы потеряете но она намного более надежно чем вставкой просто из мэмри буфера и в первой версии мы поддерживать только формат в eleyus ну потому что у нас на самом деле уже был прототип он обычно из квн только поддерживал и я решил что попробуем итак может быть заработает ну и сбрасываемые буфер 1 2 секунды не соответственно вот такая вот задержку доставки логов мне кажется достаточно неплохая да вот эту схему мы использовали раскатали ее на где-то 1000 машин и начали смотреть как что будет все было хорошо мы используем надежную доставку то есть мы писали на диск все время и решили в какой-то момент провести работы на cliff house кластере потушили в этом на пару часов и потом через пару часов данные на начали доставляться со всех тысячи машин это график лота врач на сервере в этот момент вы когда-то видели такие цифры кто видел полторы тысячи до кажется что кажется что cly house использует по труду на соединение правда алексей вот ну да выясняли мы это конечно продакшене но мы еще тестировали только поэтому мы поставили что яндекс и ограничили количество параллельных соединений до 50 штук заодно чтобы вставка что быстрее сделали чтобы распределялась на 2 cliff house вставка это угадайте во сколько раз ускорило вставку в 2 да вот неожиданно хотя они в репликации то есть на самом деле мы вставляем в итоге в 2 раза больше в один и тот же кластер таким образом забавный факт ну эта схема уже достаточно неплохая оказалось она работала нас какое-то время месяц или два но были нюансы во-первых мы полагались на и дженкс что он делает hell стейки что он раскидывать нагрузку и если этот индекс выходит из строя то мы опять пишем давно это нехорошо соответственно нам нужно делать холсте к самой самим потом мы обнаружили интересные такой баг что вставка insert a mi в районе 200 56 килобайт иногда фэй лица с необъяснимыми ошибками причем еще не воспроизводится локально мы пошли в чатик телеграма спасибо что он есть спросили а чё это такое вообще почему так происходит и почему она ещё и не стабильно воспроизводится нам дали ссылку на и шли на гитхабе которым было на тот момент несколько дней буквально что оказывается в daytime колонки хоть и можно вставлять unix time но формате вэлью со в котором мы вставляли но его нужно обрамлять кавычки вот они вставлять как int при этом да спросите вы а почему все же работала то есть вроде бы и так же сойдет то есть можно только строкой вставлять у них ставим вот есть еще на гитхабе проект оказывается у клик хауса формате в и льюс естественно об этом написано в документации но в то же читает 22 парсера один полноценный а другой потоковый и мы всегда использовали полноценный постер то есть мы выжили там несколько гигабит в секунду на ставку на полноценном паркере это кстати говорит интересный аргумент в пользу того что может быть его стоит всегда использовать на самом деле не стоит потому что памяти многого он будет жать но все равно есть опция который можно задавать либо вычтите пи get параметрам либо на стороне сервера input format вылез интер expression страну 0 которая всегда говорит форсить потоковый parser и соответственно не будет таких проблем вопрос до вас навин возникну полноценный парсер используешь и что и при чем здесь файлы вставки как вы думаете какой размер буфера максимальные у этого партнера до 256 килобайт на границе этого буфера начинаются проблемы при этом сервера давал очень странной ошибки что кстати говоря отдельная боль алексей что ошибки иногда вызывает очень странные ощущения вот мы соответственно вот этот опыт учли написали вторую версию китон хауса заодно для того чтобы самки таунхаус было легче типа жить и чтобы следить за тем например какая версия на каких серверах с какими параметрами запущена мы начали писать логе самого kid in house of клик house ну как я сказал мы теперь умные и форсен потоковые skilled parker умеем балансировка нагрузки умеем делать проверки живости мы делаем select 42 и ожидаем что нам 42 вернуть если нет то это видимо просто engine x одни кли house нам отвечает и умеем разные таблицы на разные сервера раскидывать потому что мы уже в тот момент выросли из одного сервера и также есть еще такой интересный у space мы начали хотите собирать данные в кли house не только испечь приходом и например хотели собирать данные в cliff house is индекс модуля и яндекс модули нужно поддерживать наш кастомные del схемам протокол нам нужно пойти цепи работать это неудобно поэтому мы добавили поддержку и т.п. в китай house то есть он может принимать данные естественно не гарантируется доставкой в этом случае даже до самого китана хаоса но если вам нужно собирать какую-то стату и не страшно немножко потерять то как раз идеальный вариант вы можете слать египет а дальше она сама до ставится схема начала выглядеть вот так то есть у нас есть прикиды хаосу все еще на локальном сервере и уже балансировка делается на стороне китон хаоса то есть engine x имеет один appstore мы толку хосты единство для чего нужно это ограничивает количество соединений кто считает что тут тут уже нечего улучшать и это вообще самый лучший схема которую можно придумать почему-то никто не поднял руки потому что такого ты еще не закончился что не так мы в какой-то момент когда начали эксплуатировать много таблиц могут вставлять туда мы начали иногда замечать пологом которые собственно встроены в самки пентхаус что где-то полпроцента запросов и нас появилась небольшим небольшими разговорами с админами выяснилось что у engine.exe случался up stream таймаут на случался он потому что всего коннектор мы видели 50 штук и за 10 секунд они не успевали вставляться это было вызвано тем что у нас было много таблиц и тем что мы неправильно буферной таблицы использовали и мы использовали с кучей кусков и они флаш или очень часто и соответственно несмотря на то что мы писали не так уж и много у нас было много me joy параллельно кстати говоря то наверно хорошая метрика для мониторинга если у вас много мер джей то возможно выше параллельных что-то вы делаете не так вам нужно уменьшать дрова вставки верни увеличивает интервал вставки и так далее ну естественно я разбираться не стал да и зачем да почему эта схема плохо работает и про буферная таблицы тоже не стал смотреть я потом выяснил что можно было просто буферной таблицы нормальной пересоздать мы написали свой reverse proxy место индекса вот назвали его тот же кит marhaus потому что он имеет отношение к хаусу но он сработал флажком минус минус reverse что он умеет во-первых ну да он замеряет нужны кстати тоже общаясь по степи прокси рует все запросы докри хаоса но он понимает разница между select a me in стертыми например то есть и даже если вы забили insert a mi se весь пул соединений то вы все еще можете оттуда selected потом несмотря то что буферные таблицы частично решает проблему часты вставки в наш 3 но если вставлять совсем много то это плохо мы вставляем теперь в каждую таблицу в один поток но буфер при этом нас небольшой то есть 25 миллисекунд всего лишь или один мегабайт это вызвано тем что когда ставка идет большого количества хостов если там есть все-таки какие-то ошибки там например ином значении которое не входит войну мы пытаемся вставить или еще что-нибудь да это влияет на на всю пачку который мы на агрегирование то есть у нас не было такой проблемы пока мы использовали просто индекс теперь мы агрегирует вставку то есть у нас там типа 1 мегабайт может быть batch который мы вставляем и весь башни вставляется соответственно для того чтобы уменьшить вот эффект от таких проблем я делаю на короткое время агрегацию и соответственно не так много строчек задевает из-за неправильного bacci вставка синхронная то есть надежная доставка будет работать мы сразу скажем либо прошел insert либо не прошел и все рты соответственно его повторить и мы используем библиотеку косточки типе гошена которая спокойно выдерживает но у тебя будешь маркова у меня получилось забить гигабитный канал запросами вставкой по одной строке вот то есть это где-то сто шестьдесят тысяч запросов в секунду то есть принципе наш reverse proxy можно установить просто перекликался он вставлять по одной строке они использовать ну то есть буферной таблицы все она вставляет но по крайней мере больше ничего не нужно кто слышал вообще про fasttech и т.п. горный кстати говоря прилично людей то есть вы наверно тогда знаете в чем и недостатки которых мы говорим попозже ну то есть вот схема такая то есть к нам приходит 24 мы группируем по таблицам но это буферные таблицы все еще потому что мы не на секунду там агрегируется на короткий интервал времени и делаем по одному потока на ставку буферную таблицы это сразу уменьшило нам на потребление циpкa в два раза и позволило в общем-то больше не знать о 502 bad gateway потому что там нет нужны только тайм-аут и от китаны house прокси вот такая схема ну с ней на самом деле мы до сих пор в принципе живем практически исключением того что есть еще схемы вы 6 которая дорисовал буквально пару дней назад кто использовав остыть и типе в продакшене и обслуживают при этом post запросы они постом вставляются если никто а жаль хотя нет на самом правильно не надо делать дело в том что fast если тебе агрегирует всю ставку в память вернее так все post запросы которые приходят false . теперь mophie рисуется в памяти и только после этого вам отдается управление чтобы собственного эти данные тела по запросу обработали мы вставляем пачками по 16 мегабайт ну максимум 16 мегабайт если умножить 16 мегабайт и 20.000 машин то получится что нам нужно как-то очень много памяти но я рассматривал худший случай когда нас например cliff house уже тормозит и к нам приходит все больше размера пачки до 16 мегабайт и мы вставляем соответственно постом туда ну и у нас это выяснилось ну как обычно продакшене вот ну и там был тестовый кластер но это все на было в продакшене поэтому написал небольшое дополнение к и чтить и ты назвал протокол кетонал ну потому что на вконтакте заработаем да я сначала хотел назвать по другому но мне сказали ну чувак ну ты чё вот что она себя представляет это настройка надо степи то есть это отдельный метод под названием китам если вы отправляете такой метод то сервер должен вам ответить мя в ответ если он его понимает если не понимает то может ответить что угодно по идее должен закрыть свами соединения но фасту степени закрывает он просто отвечает 200 ok с нулевым ответом вообще супер вот что этот протокол позволяет сделать мы получаем первый запрос маленький без тела отвечаем на него почти теперь после этого работаем уже с сырым соединениям то есть фактически пятака и позволяет вы наверно спросите юрия чего websocket выпсуке тоже есть зачем вы изобрели свой протокол честно говоря мне просто было лень ну и хотелось сырым соки там работать потому что я точно знаю сколько туда будет уходить данных это бинарный протокол он отправляет формате длина таблиц имени таблицей таблица длина содержимого содержимое меньше данных отправлять сложно и собственно за счет чего он экономит память мы не читаем не больше чем из 50 клиентов за 1 то есть даже несмотря на то что к нам хотят присылать 20.000 машин мы их ограничиваем тем что мы оттуда не читаем это прикольные свойства те цепи что теперь дает но предоставляет обратную связь тому кто с той стороны находятся о том с какой скоростью мы читаем и если мы не читаем то данные дальше не шьются и клиенты ожидает пока мы начнем принимать данные потребление памяти уменьшилась примерно в 20 раз и нас это уже стала устраивать вот и к тому же еще случае если вы вставляете особенно по одной строке у вас будет существенно вверх от на то что вы шлете собственно и т.п. вас там и заголовки всякий контент likes там теперь собственно и так далее и это позволяет во первых не порвать на части типе во вторых экономит трафик а дальше это уже почти последние обещаю ну вы наверно подумали nokia юрий но а как вы читать то туда собрались свою логику никто же для логов cliff house не используют ну да вы правы не использует есть несколько глыб gui для cliff house а самые известные из них topics кто кстати говоря им пользуется вот а кто разработал topics не туда не имею ввиду смысле нет ли разработчиков это бегство здесь нет one в общем табекс немножко тормозит во первых во вторых она не умеет читать но мне очень удобный с его помощью читать сырые данные вот а нам нужно было только это нам не нужно было графики и прочую радость я написал небольшой интерфейс назвал lighthouse не удивляйтесь тому что у гугла есть такое название чистое совпадение они после нас назвали я уверен вот на такой интерфейс вы оба 20 не в полтора 0 нет в полтора просто который позволяет быстро смотреть содержимое таблицы фильтрацию сортировку делать для того чтобы заходить на каждую тачку и не пробрасывать к себе порты мы завели на engine.exe прокси для каждого hasta то есть нам не нужна psh конектится и он умеет еще всякие там структуры таблиц показывать количеству строк занимаемое место у всей таблице как выглядит возможно вы чем что-то похожее видели если видели то не удивляйтесь я вдохновлялся интерфейсом цикла pro для mac а если кто-то кстати говоря знает как выглядит стекла про очень мало кто маком пользуется те же самые люди подняли руки так что все правильно и спросил вот ну в общем там несколько вкладок там структура содержимое фильтрация по имени таблицы вот внизу слева и видно движок колись оценка количества строк размер можно делать просмотр фильтрацию если вы делаете фильтрации то вам показывают еще запрос который выполняется что вы могли потом пойти и вот в эту вкладочку забить скопипастить и забить свой запрос вместо этого вот ну быстро работает делать то что нужно написан буквально на коленке за три дня вот и как ни странно почти все пользуются именно им они the big сам у нас компании хотя его не особо рекламируем ну вот и все что хочешь сказать по итогу не бойтесь их поиск ли house для логов он прекрасно для этого подходит если вы конечно правильно все-таки все делаете не забывайте что если вы используете буферные таблицы то нужно учитывать что куски буфера работают независимо третий пункт я честно говоря написал не знаю почему многие типы соединений это хорошо потому что на этапе вы если не справляетесь со ставкой вы даже не можете затормозить того кто вам отправляет без того чтобы собственно городить еще свой протокол причем еще и довольно сложный тисе пи позволяет хотя бы такую задачу решить но надо аккуратно то есть как бы есть и плюсы и минусы теперь для cliff house on он в принципе нормально кино хауз lighthouse будет выложено в open source как я говорю подписывайтесь на наш паблик в кабак and я проверю что у нас сколько здесь человек 500 понятно смешная шутка в общем что на несколько сотен человек увеличилось количество подписчиков если нет то мы не выложим в open source ничего вот спасибо большое за доклад не за доклад а за то что пришли вот в каком случае y нас резинок это мое личное vk так что вам нужно заходить на в каком службы к backend и гид хоп у нас у нас их два на самом деле в каком и выкате райком вот но выложена будет вот по этому адресу большое спасибо я готов ответить на ваш вопрос 100 шакала is a paso поднимайте руки ослабил выкладывать не буду я так подумал и все равно вылазит раз почему не рассматривали elastic все человек стрижки бана и как ищите вот потом в том что сарж сказал что нужно писать не только читать быстро написать ну и там уже наши админы имели отдельный зуб на elastic я их прекрасно понимаю ну имели негативный опыт скажем так ну не не держит он запись автомобили в котором кли house держит спасибо за доклад вопрос она такого плана лекарства он предназначен больше для агрегируются вопросов во флоте склонялся к ним подстрочных запросов и выполняться для тормозит cliff house как известно не тормозит ну если серьезно то нас структурированной логия то есть они разбиты намного колонок и мы делаем фильтрацию обычно по этим колонкам плюс мы используем все таки возможности кли хаоса по названию первичный ключ и соответственно когда можем мы фильтруем по первичному ключу это очень быстро ну если все-таки нужно погребать именно именно грепп так ли хаусе это работает быстрее всего ещё у кого-нибудь есть вопросы ребятам задавать вопросы там когда музыка появиться там вы к бесплатно вас давайте а вот вот мужчина там на 1 эту добрый день а такой вопрос вы говорили что раскатывали новую схему что при этом было со старой схемой что наша с катарским маму вы имеете ввиду ну типо вот это вот тут мне раскатывали но я первая схема вы сказали тысячи машин по моему сказала ты же машин а до этого на них наверное была какая-то ну логирование то она продолжила работала родовая параллельно или параллельно оставили старую схему естественно нетронутой спасибо будете таки задавать вопрос да давайте андрей задавайте вопрос я вас помню микрофончик пожалуйста без микрофон нельзя ну-ну , не пойдет чудовищно мы должны попасть в запись конечно протокол судебного заседания сидела чё такой доклад скучно где кровь-кишки вот там сбой в продакшене который вложил весь vk ну когда будем рассказывать про что-нибудь что у нас используется для selecta в продакшене из-за чего может лечь в кале обязательно скажу переформулирую немного вопрос неужели доступную как бы по докладу ощущение чтобы внедрение прошло там относительно легко скажем так ну окей разные разравниваем его размеры вы сделать то есть что наоборот скажет о столько проблем было с хаусом там всего 130 тысяч машин не могут вставить нормально жалкого и количеству да конечно принц какие-то костыли by радиатор как каждый должен на 30 к хвостов там развернуться вообще из коробки ну это кстати говоря вот длина этого доклада иллюстрирует почему в к большой большинство вещей самописные но что эксплуатации их намного проще чем готовое решение которое для такого масштаба вообще не годятся обычно так и не только общее впечатление что относительно там спокойно раскатали скажем так понятное дело с нам с определенным количеством инцидентов вы хватом большого владимирович двумя проксиме и питерскими подряд это типа норм норм тут на один сервер на грани раз катаешься 5 а здорово больше количество проблем ну ты андрей просто уже работал в халат проектах я рассказываю про то как бывает вообще в принципе что берешь делаешь и она работает до тоже так можно я знаю у меня тоже была но об этом уже не доклад то не раскрыл у нас хорошо у нас например ломалась репликация когда мы драпали партиций в которой пишем ну наверно так не надо делать да я за чего про это рассказывать ага то есть подводные грабли все-таки еще дополнение будет просто от нас скрывание на самом деле именно продакшене мы такие вещи не делаем то есть мы в когда тестировали мы например пробовали дропать партийцы которые запись идет выход его нехорошо стало ну вроде тоже пофиксили то есть пойди так можно у нас еще была проблема то что в какой-то момент кто-то и своих хаоса создал таблица хотя это можно видеть да что здесь как бы select и предполагается делать и мы записывали в конец запросов но и дописываем сейчас такой ключевые слова формат json чтобы нам ответили в формат json оказалось что это идет в запрос для создания таблицы и причем что интересно что таблицы создается на потом или стартует сервер поскольку там есть лишняя вот эта строчка формат в структуре это лодка как-то не хочет и создавать над пофиксили тоже все все просто не пофиксили я рассказываю то что пофиксили и как такие мелочи как бы удалить строчку из файла . и скверну не знаю это не фатальные проблемы с фатальной проблемой рассказал что нет и дипе то есть нам пришлось вот этого все городить для того чтобы вставлять логе то есть по идее можно было бы сделать на стороне клих ауца чтобы он умел по этике принимать и вот похожую схему прострелю соусом ну - я на плюсах не пишу я не хочу это реализм никто не хочет писать как почему это one есть у кого-то еще вопросы может быть а вот так сначала вот наконец-то появились вопрос юрий спасибо за доклад пожалуйста скажите пожалуйста как вы делаете tracing запросов пользовательских то есть момент от входа до выхода ответы в страну пользователя если вы это делаете то каким образом формируете первичный ключ 3 запросов вопрос интересные я не знаю в общем механизма у нас по моего нет но мы вот по кроме для того что о геракле house и остальные места на клиенте то есть на стороне . мы пишем имя сервера на который пришел запрос и загадываем какой-то случайный идентификатор используемого как request айди и он фигурирует тогда блогах но мы на снег есть специальная система наговорят пробрасывать везде и так далее дальше у кого еще лучше конечно задать вопрос про cliff house спасибо за доклад а подскажите пожалуйста сколько у меня два вопроса с таких простых на мимо сколько у вас получается логов 24 часа в день все таки и что вы с этим select им потом делаете когда вы получаете select и уже хотите как-то анализировать или просто сели получить но понятно зависимости от под системы там логов разное количество йога вы сзади за день и вам не скажу я вам могу сказать за за час за полгода сколько накопилось вызова сырых данных чего-то порядка 100 с лишним терабайт вот один преодолевает на 11 прекрасно при этом это вот эта конфигурация ваши держит такая а то мы не крутая конгресс это обычно конфигурации cliff house и документации к самому cliff house и пишет но лучше не использует у вас 64 гигабайта памяти для 50 терабайт дисков то есть из чего делается вывод что наверно в яндексе все-таки побольше диск ставится например хотя у них тоже много серверов мягко говоря все это скажет что вот с такой конфигурации стоит начать диски не такие дорогие жесткие диски естественно там не и свойства ssd фильтрации ну по первичному ключу работает очень быстро если нужно все-таки отфильтровать в какой-то колонки это не требует сканирование всех там сотен терабайт это рыбы сканирования только маленькой колонки по которой вы делаете фильтрацию это быстрее чем практически с каким угодно какую визу я имею виду анализов такого типа визуализации каких то огромных а собственно намного собираются много данных собирается то приходится от selected в итоге да там до 10 строк но если если требуется все-таки что-то визуализировать но табекс никто не отменял то есть можно сделать туда запрос и он начертит вам красивый график и даже так делали иногда в основном это кино про текста в логе конечно у кого-нибудь ещё есть вопросы добрый день скажите какой процент потери данных у вас в продакшене а кто говорит а здравствуйте что вы подразумеваете под развал вы сказали есть потери данных возможны вы имеете ввиду того что из того что пишет of к хаосу да ну я бы сказал что меньше чем 1 миллиона я наверно вот так мониторинг ну все все все что потерялась пишется в отдельную табличку которую мы смотрим я как узнал что по процентам и теряем ну сейчас мы теряем не больше чем один на миллион ну там за за один день у нас было там 0 ошибок нет вообще ну с такой схемой ну с другой стороны мы пишем в локальный буфер то есть если требуется надежная доставка то мы теряем только когда выходит машины строя и когда они не за сложилось но об этом мы не можем нужно ну там обычно немного потому что раз в пару секунд она флаш не больше чем пару секунд записи на отдельном сервере давайте следующий юрий не пробовали френды посмотреть что френды как замена для доставки duckhouse а не проводишь ну я в принципе знаю что это но мне показалось что он не подходит давайте следующий все хорошо тогда давайте вопросы в зале закончим если у кого-нибудь еще появятся вопросы можно будет спросить на дискуссионной точки которые находятся напротив зала сейчас же хотим поблагодарить юрия за доклад"
}