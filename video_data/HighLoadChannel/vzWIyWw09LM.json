{
  "video_id": "vzWIyWw09LM",
  "channel": "HighLoadChannel",
  "title": "Высокопроизводительный инференс глубоких сетей на GPU с помощью TensorRT / Максим Милаков (NVidia)",
  "views": 961,
  "duration": 2190,
  "published": "2017-04-22T14:48:14-07:00",
  "text": "максим милаков я инженер по развитию технологий в компании nvidia я расскажу сегодня о том как вы сможете делать быстрый inference клубок сетей на джипе ю с помощью нашей новой библиотеки который называется там за рамки входим в ходе моего доклада я надеюсь что вы к его концу поймете вообще как если вы до этого не знали как джикию используется для различных видов задач связанных с глубоко неровными сетями почему вам вообще имеет смысл использовать джипе и для inference а если вы все и если вы это делаете то зачем вам использовать для тех кто азарте я предполагаю что у вас уже есть определенное понимание что такое глубокие сети что такое машинное обучение но даже если нет я думала все равно что-то почерпнете из моего доклада и я вообще не буду никаких примеров кода приводить здесь то есть если вас заинтересует библиотека там за врати вы всегда сможете ее скачать исследовать документацию примеры конкретных я вообще предлагаю на здесь не очень много если у вас будут вопросы вы поднимаете руки задавайте хорошо чтобы у нас такое интерактивное было обсуждение я думаю это будет более эффективно и более интересно в краз вообще компании nvidia вы наверняка знаете про нашу компанию потому что вы используете наши графические процессоры для игр мы с этого начинали ему до сих пор ну наверно больше половины нашей компании работает на именно эту часть на эту индустрию и где-то 10 лет назад мы начали продвигать наши графические процессоры для высокопроизводительных вычислений и достаточно популярна уже наши процессора наши профессиональные ускорителю скажу вы сами высокопроизводительных вычислений практически подавляющее большинство самых больших кластеров в мире используют наши графические процессоры для ускорения научных вычислений примерно пару лет назад мы начали инвестировать серьезно в искусственный интеллект я понимаю что это такое что называется базу мер дотащу слово которое как каждый под ним понимает под искусственным интеллектом что свое здесь я подразумеваю то что наша компания инвестирует не только в железо для ускорения задач связанных с машинным обучением вообще и глубоким обучения в частности но также мы инвестируем в какие-то прикладные задачи связанные с машинным обучением углу и глубоким обучением вопроса и вообще когда вы решаете когда перед вами стоит задача связана с машинным обучением обычно эта задача какая то это обычно это прикладная задача связана либо с компьютерным зрением либо с декодированием естественного и декодирования аудио либо обработка естественного языка для этого для решения этой задачи вы обычно используете фреймворке есть большое количество framework of самый популярный из них это ты за flow это кафе этот торт teana sentique mx на 1000 большое количество из них все они состоянии работать на наши графических процессорах и для этого они используют библиотеки которая разрабатывается в на видео это влиять и как у dnn библиотека для ускорения прежде всего для ускорения святочных слоев это бьете как у волос для ускорения матричных операций каспарс для ускорения матричных операции с для разреженных матриц библиотека никель для ускорения коллективных коллективных операций таких редукция reviews of между цепью на одном узле и его библиотека про которую я буду рассказывать тензор arte а для быстрого интересов до да мы поддерживаем все функции level 1 2 и 3 класса наверное лучше мне повторять вопрос вопрос был про что из себя представляет кубло sq глаз это реализация функции бласс стандарт де-факто операции с матрицами как выглядит типичный цикл разработки и внедрения решение связано с машину обучения вы если если вы даёте сантис если вы ученый по работе с данными либо вашей команде вашей компании есть дельта сантис команда либо конкретный человек он собирает данные обычно решается задача назовут так называемая задача обучения с учителем то есть вам для того чтобы обучить вашу модель вам необходимо какие-то размеченные данные например случай если мы говорим о задача классификации картинок то вам необходимо каковы какое-то множество уже различных картинок то есть картинка и что на этой картинке изображена вам откуда нужно получить этот так называемый ground трус то есть правду об этих картинках вы получаете это обучающее множество вы строите конструируйте модель то есть вы придумаете схемы вашей модели какие слои сколько в них фича map так называемых карт признаков как они связаны друг с другом и т.д. и т.п. и после этого вы с помощью фреймворка на ваш выбор вы обучаете эту модель процесс может быть сам по себе внутри итеративной то есть вы обучаете смотрите результат наваливаться на множестве вас может не удовлетворять вы меняете структуру сети меняете какие-то гибер параметры вы носите какие-то обогащаете ваше обучающие множество аугментаций есть много разных способов как можно повысить качество обучения модели в конце концов вы получаете какой-то более-менее приемлемый результат audi плойки эту модель и начинаете использовать во время использования вы можете выяснить что у вас на каких-то тестовых примеров она ведет себя хуже чем вы уже али и вы таким образом понимая это вы например добавляете это тестовые примеры с правильными метками ваше обучающие множество перри обучаете модели вы меняете схему это до этапа и цикл в принципе может несколько раз повторяться до тех пор пока вы не выбросьте свой продукт например либо не трансформируется чтобы другое вкратце расскажу об обучении то есть я буду рассказывать в основном об infinite сегодня но один слайд посвящу обучению что из себя представляет обучение практически все сейчас делают обучение модели с помощью вида обратно распространению ошибки то с помощью того или иного варианта нет да градиентного спуска в чем он заключается у вас есть обучающие множество например опять здесь же рассмотрим задачу классификации картины то есть у вас есть на входе какая картинка которая представляет из себя собаку в эту собаку подаете на вход вашей сети получаете какой-то ответ например вы получили ответ черепаха ну черепаха не собака да у вас есть явная ошибка на выходе неровности вы соответственно эту ошибку медном обратно распространение вы ее прогоняете по всей сети обратно и вы меняете веса этой вашей нейронной сети таким образом чтобы нейронную сеть предсказывала черепаха с чуть меньшей уверенностью а собаку то что вы хотите получить чуть больше и в эти картинки прогоняет этот цикл миллион раз через вашу сеть в конце концов постепенно меняя ее веса так чтобы она предсказывала то что вам нужно с большей вероятностью в конце концов вы получаете обученную модель и вы начинаете использовать подавая ей на вход новые картинки те которые эта модель не видела во время обучения вот и надеюсь что она сделает правильное предсказали и этот процесс когда вы используете обученную модель называется вентиляции не очень хорошие слова сожалению в русском языке нет какого-то устоявшегося хорошего перевода если если вы будете грудь и фриц во все поймут что то другое могут они хорошо для обучения нашей джипе используется повсеместно если мы возьмем например соревнований имидж нет это соревнование в котором каждому участнику выдается порядком миллиона размеченных картинок и цель этой соревнований цель каждого участника построить модель с тем чтобы эта модель предсказывала классы для отложенных сторону 50 тысяч картинок из теста во множество для которых участники правильную метку не знают да и в 2012 году арийской женской впервые применил глубокую сеть и использовали пью для решения задач естественным образом понизил ошибку и вы видите что что с каждым годом ошибка понижалась намного и 2015 году результат порядка пяти процентов 2016 уже где-то около трех процентов топ 5 ошибка на для этой задачи и с 2014 года уже практически все участники это соревнование использовали джикию для нашей компании для обучения свои модели и это пожалуй все что я хочу сказать об обучении deployment можно вопрос скиньтесь рассказу разбежался так да это были на облигационном на теста множество да это то что они загружают то что они не знали да конечно deployment есть два я явно выраженных типа дипломантом то есть типа внедрение в одном случае назовем его ой пирс кайл когда вы вашу модель деплоить и на какие то сервера и ваш inference работает на этих серверах в то время как задача по инфе пол классификации она изначально возникает на каких-то клиентских устройствах это может быть мобильное устройство это может быть просто десктопу кого-то где-то там в интернете далеко но по тем или иным причинам локально на тех устройствах вы in free сделать не хотите а вы хотите сделать централизовано на серверах и это задача во первых ей присущи высокий высокая пропускная способность то есть у вас большая большая загрузка на эти сервера идет и второе что у вас есть возможность пакетированных запросу то есть у вас такая большая загрузка идет что вас есть возможность объединять запросы какие-то пакеты и запускать и ты сразу для всех пакетов почему это важно потому что пакетные inference он обычно гораздо более эффективны ничего не фриц по одному примеру конечно разница зависит маску насколько большая разница зависит от модели которого используется на тем не менее то разница почти всегда будет просто папа сказал так и второй тип это интересно м б тут устройство здесь приведён пример когда вы выпускаете например перед вами стоит задача детекции автомобилей или to date акции разметки детекции дорожных знаков у вас просто нет возможности посылать каждый кадр на сервер дожидаться пока этот сервер ответит по многим причинам до вам нужно делать это этот интересно локального устройство причем с наименьшей задержкой задержка должна быть у десятки миллисекунд не больше и так так такого рода deployment он характеризуется прежде всего низкими задержками то есть требования по задержкам очень низкий фтор и это означает что у вас нет возможность формировать большие пакеты обычно вы получили картинку с камеры и вам необходимо сразу же запустить entry что понять вообще у нас появился там автомобиль новый какой-то да перед перед вашим автомобилем или не появилось вот соответственно иногда можно делать маленькие пакета когда у вас у вас например несколько камер of 4 камеры и для inference а вы используете что например камера вперед смотрит назад и по бокам да и в принципе вы хотите использовать одну и ту же модель для интереса вам вам ничто не мешает получив картинки с по одной картинки с каждый четырех камер объединить это в пакет и запустите фреза для всех четырех это будет конечно более эффективно но все равно пакет небольшой это интересное устройство и скорее всего вы захотите использовать и взрывать и почему потому что по сравнению с центральным процессором вы получите многократная более эффективно inference то есть эффективность в терминах картинок на секунду назад здесь я здесь идет приведён пример использования как хакерской латок mb даты плюс есть еще один пример на этот то есть драйв по x это у нас решение для автомобилей у нас есть еще отдельное решение джексон ты x1 это скорее для робототехники и каких-то других интересных разных устройствах гораздо более намного дешевле и доступнее в принципе можете с этим сами уже поиграться вот такой вот компьютер размером чуть больше кредитной карточки просто на нем вертит но на нем вертится убунта 1604 64 битная и там содержится 2 сэма максвелла ну то есть это g пью с поддержкой куда с поддержкой кузьменко у босса все весёлки там есть он порядка наверно раз в десять слабее чем самый мощный наши джипе в 10 15 раз но у него энергопотребление это где-то 1000 ватт 15 ватт сама вот это маленькое устройство оно стоит 300 долларов вместе с картой где есть всякие выводы типа юсби монитор это будет 600 долларов до 9 девки 600 долларов то есть вы на дискете разрабатываете а потом если у вас какой то есть готовый продукт вы можете начать этот джаз он использовать как покупать его за 300 такого я не продавец я могу где-то здесь ошибиться в цифрах но примерно знаю вопроса вы можете как бы смотрите как я перескочила центрального процессора джипе на котором мужика на котором уже крутится тензор arte то есть на самом деле промежуточный шаг когда вы начинаете использовать же пью но вы делаете infernus не с помощью т взорвать и а с помощью тех фреймворков которые вы использовали для обучения братства возчиков а у нас для этого тоже данные есть здесь мы запускаем на разных g пью inference используем как касается один из самых быстро фары work of на самом деле час на данный момент так и с использованием тензоры рти и для мы получаем ассистент на и ускорение использует азарте причем это ускорение тем больше чем меньше чем меньше размер пакета на котором вы за пределы те inference то есть на маленьких размеров пакетов назовите наиболее эффективны и танцевать и также эффективен когда у вас достаточно сложная сеть типа google он это где у вас так много разных блоков которые выполняются параллельно друг другу за счет чего ты возврате вообще получает показывать такое ускорение по сравнению с классическими проверками даже если эти и другие работают на тех же на тех же джипе и прежде всего самое главное это объединение слоев я об этом расскажу чуть попозже это дает наиболее наиболее значительный выигрыш в производительности получается за счет именно объединение слоев мы также не делаем какие-то операции которые являются лишними которых фреймворке вынуждены делать в тензор арте есть так называемая специалисты керну специализация что это такое в принципе в там забрать и есть большой например вам необходимо сделать свёртку да у вас все есть хотя сверху слой есть большое количество вариантов его реализации вы можете мы можем использовать наивный так называемый дорик can валюша прямой прямая свёртка можем использовать свёртка которая основана на перемножение матриц может мы можем использовать сверху которой основано на быстрое преобразование фурье можно сверху которое основано на алгоритме виноград все эти реализации есть внутри там за руки и зависимости от параметров в свертке зависимости от железа на котором это выполняется а одни могут быстрее а другие медленнее и мы используем самую быструю на данном железины для данной конфигурации свертки там закрытие первая версия нацелена в основном на решение задач когда у входа мы вас является двумерная картинка дальше мы будем расширять сферу применения это за верти ну пока первая версия она такая соответственно и выбор слоев в принципе у нас сейчас как таковой поддержки к основных слоев внутри азартен нет но если у вас например есть какой то один костюм и слой внутри вашей сетки то вы можете в принципе разбить вашу сетку на две части каждую запустить в темноте а ваш основной слой вы здесь реализуете по своему новому другой стороны можете подождать версии 20 у нас там будет более адекватная поддержка к 100 слоёв вопроса я не могу подать мне нечего сказать я не могу тензор арте смотрите тензор эти может может у нас есть отдельная библиотека такой wrapper который позволяет вам импортировать кафе сетку в тавде если вы обучили сетку в кафе и у вас есть протыкать и файл с описанием сетки и модель файл с весами обученными для кафе вы можете автоматически импортировать это в стандарте у нас в следующих версиях будет поддержка других фреймворков но в принципе даже сейчас у нас есть и плюс плюс 35 лет назад и который позволяет вам сконструировать сетку на лету программ программ абсолютно в принципе в интернете есть много обученных кафе моделей вы можете их загрузить из кормить там взорвать и до расскажу подробнее о объединение слоев есть условно можно разделить на два типа это вертикально и горизонтально о чем идет речь вот давайте рассмотрим это так называемый inception блок все сети google он и достаточно популярная сеть который используется вот например в том же для решения задачи классификации изображения для соревнований начнет выиграла в каких-то годах и вообще показывает хорошие результаты обладает высокой вычислительной эффективностью и в общем-то веса висит не очень много и это сеть google узнать состоит из большого количества таких блоков которые идут по следовали друг за другом вы можете обратить внимание что здесь есть под блоки то есть идет свёрточная сеть свёртка после этого добавляется боец после этого добавляется рекси файла нет вообще говоря свёртка эта задача вычислительно ага которой ограничена вычислительными ресурсами то есть ее производительность задача ограниченных мыслительных ресурсов и в то время как добавление байеса и добавление и применения активации виды реки файла ньяю нет это задача которая ограничена пропускной способностью памяти боятся очень простая операция но вам нужно во-первых почитать входные данные до добывать этот боясь и записать это чтение и запись она отнимает львиную долю времени у вас общее вычислительные ресурсы простаивают если вы будете применять боится отдельно очевидное решение это обвинить эти три слоя в один сделать свёртку и непосредственно перед тем как записывать результат мы просто добавляем байс и применяем практикой для нее и записываем это практически бесплатно да и свертки и блок inception блока упрощается таким образом в результате вертикального фьюжена существенным образом далее обратите внимание что у нас есть три свертки которые используют одни и те же входные данные это означает что мы можем эти три свертки заменить на самом деле на одну сверху которая просто шире в три раза и это будет более эффективно это будет более эффективно боли фиктивно будет заполнен g пью и будет выполняться быстрее плюс у нас есть отдельные явно выделенный слой конкатенации когда результаты 4 сверток объединяются в один тензор вообще говоря явно вам эта конкатенация не нужно все что нужно сделать это чтобы каждая свёртка писала в нужную область памяти сразу же и если это реализовать то конкатенация можно отбросить что у нас получается у нас был вот такой блок с action отель зайти внутрь и преобразовал вот в такой это гораздо быстрее используя терзайте состоит из двух фаз во время первой фазы вы скармливаете библиотеки тензора ти deploy файл так называемый файл с описанием вашей сети и модель файл это я говорю всё в терминах кафе это файл с обученными весами плюс вы говорите какие выходные слои вы хотите получать этой сетки потому что в принципе ваши сетки может быть разные слои и не все из них нужно запускать что получить тот выход который вы хотите да и тензор ракеты поймет и не будет их запускать не будет их выполнять если вы скажете это вз ortica как я какой выход вы от него хотите получать о той же сети и вы специфицировать и указываете также максимальный размер пакета после этого на конкретном устройстве то зарыть и строит план который вы реализуете например file system file и отдельное приложение которое уже будет осуществлять непосредственно inference она у вас этот план загружает из файловой системы начинают использовать и гонять конкретные примеры дело для них интерес вот такое двухфазовое использование that'sa рти вопроса да макс батчат сайт его надо зафиксировать или он от и да то есть можно менять если есть мало даем мало если много не больше чем значит если если ты укажешь макс batch сайт например 4 во время построить для то для того чтобы построить план это означает что ты тот план можешь использовать бочкам сайт борис 1234 ты не можешь давать пакет большего размера это этот робот batch сайта влияет на эффективность то есть если 2 h max 2 часа из 1 то могут быть выбраны одни конкретные алгоритмы свертки которые наиболее эффективны для именно этого почитается все только h4 может выбрать совсем другие алгоритмы свирске который эффективной для бориса за 4 то есть в принципе если у тебя очень разный может быть борьба что я вовремя интереса то ты можешь делать несколько и джиннов и несколько планов до 1 для бачатой за 1 2 для почесать за 4 3 для бачатой за 16 и использовать зависимостью от твоего текущий размер пакета наверно это будет самый быстро если размер пакета море минфин соединяет существенным образом мы недавно анонсировали новые продукты которые предназначены как раз именно лейфри со никто вам не мешает их использовать для обучения тоже но они оптимизированы как разлив это первый продукт это тесла по 4 достаточно маленькая джипе она очень маленького размера она одна салатовая и потребление энергии у него 50 поэтому этого папа этого продукта 50-75 во то есть оно не требует дополнительного питания и достаточно питания по пища экспо решения для этого продукта для для этой карты и вы можете поставить его практически в любой сервер который у вас есть где у вас есть свободный писяй экспресс лот это что касается по 4 ip40 это двухслотовая карта которая где-то в два с половиной раза мощнее чем p4 и она предназначена для максимальной пропускной способности вы ее будете использовать в серверах которые оптимизированы для джипе в котором есть достаточно большое количество свободных слотов для г.п. почему я говорю что эти продукты оптимизированные для inference а потому что они содержат себе новую инструкцию которая ускоряет операции с целыми числами точности всего на все восемь бит оказывается оказывается то есть обычно как вы обучаете ввп 32 до с числами плавающей точкой одинарной точности то есть каждое число это она занимает четыре байта в случае с inference он для подавлен для большого количества моделей 8 бит представление достаточно для того чтобы сохранить точность предсказания на приемлемом уровне и мы поэтому добавить инструкцию и фактически у нас получается количество так называемых те миллиардов операций в секунду до она выросла существенно врагу образом в разы как раз за счет добавления этой инструкции и вот инструкция высокая пропускная способность смотрите у нас на предыдущих продуктах м4 м42 киров ул 2 терра белль 2 миллиарда операции так и 7 миллиардов операции она p4 по 40 соответственно 2247 за счет чего за счет того что у нас появилась эта операция которая была большая пропускная способность и которую мы можем использовать для интереса вопросах дать те abs то есть сера значит abs это операций в секунду до тира это знать это означает у вас миллиард и одна операция это а 0 умножить на 20 это одна операция да а ну а 0 + 0 это другая операция такое сколько сколько операций в секунду эта карта может сделать это в ее просто мощность вычислительной до floating point operations секунду это floating point а здесь у нас четыре четыре раза выше пропускная способность как раз до 5 5 на 4 22 сошлось да а чтобы использовать вот эти вот n8 инструкции нужно специальным образом писать софт или где-то сейчас уже есть поддержка или может интересно катана где-то будет а куда тулкит 80 позволяет использовать entry секи ptx то есть вы можете как девелопер куда использовать эту операцию в своем коде если вы хотите но скорее всего будете использовать библиотеки типа кудина либо таза верти концерте это умеет условно из коробки начиная с версии 2 0 ну мы постараемся ее сделать готовый к тому моменту когда продукты по четыре по 40 окажутся на рынке черт не успеем мы стараемся мы работаем чтобы как можно быстрее сделать версию 2 да еще вопросов давайте следующий посмотрим по поводу точности специально здесь вот такой график идет от 0 чтобы вы не заметили эту разницу которая есть между этими двумя барами да она есть но она минимальна действительно при использовании int 8 арифметики у нас есть падение точности но но минимальные мы на самом деле до сих пор работаем над тем чтобы чтобы еще больше минимизировать эту разницу в точности нам нам приходится к мотивировать не только why so do i saw pad релизов p32 винт 8 но мои quanti зиру и матрица зарыть и активации тоже все это приводит может приводить к серьезному падение точности но не приводит если это все аккуратно делать и мы до сих пор чем мы пока работаем да обычно для глубокой сети увеличения количества трассы никогда не повредит то есть они особенно если это к этому добавить админ то цию мой обучающего множества сюда ну наверно наверно я думаю да но другое дело что понимаете увеличив количество операций вы получите точности в по 32 то есть все равно какой-то момент идеи придется идти на компромисс но мы всегда идем на компромиссы да это так и здесь приведены приведено сравнение производительности на карте по 40 темно зеленый график означает производительность зрительниц до производительность в картинках в секунду для в 32 и что происходит когда мы переходим на инт 8 до увидите что в принципе уже начиная с размера пакета 4 мы получаем существенно ускорения хочу заметить что 4 красную мы практически наверняка не получим никогда не смотря на четырехкратное увеличение пропускной способности по двум причинам первая причина у нас всегда есть какой-то константный фактор какой-то overhead который никуда не девается и вторая причина состоит в том что если вы используете числа с плавающей точкой пусть это будет в тридцать два лифта 16 у вас есть возможность использовать и всякие интересные алгоритмы для реализации свертки типа быстрого преобразования фурье или винограда у нас пока не получилось добиться прими приемлемого результата работы этих алгоритмов для id 8 и не факт что получится слишком мало бит может не хватить для того чтобы эти алгоритмы работали поэтому мы используем свертки наивной свертки то есть либо либо дорик к малюшин либо с помощью к смерти которые сводятся к перемножение матриц да нет здесь мерились то есть ввп 3210 виноград и эффективно быть да это это это реальное ускорение для как для конкретной сети в данном случае для гугла мета и в принципе даже на по 40 до вы получаете существенно ускорение для маленького размера пакета и я думаю на по 4 это ускорение будет больше то есть же пью меньше легче загрузить весь на сводная таблица слева я извиняюсь за большое количество здесь цифр но понять на самом деле просто слева у вас график покупку который показывает производительность до количество картинок в секунду и вы видите что по 40 это большая двухслотовая g пью который мы анонсировали которая скоро появится использовали восемь тридцать пять раз быстрее чем какой-то центральный процессор я не был конкретно здесь указан четырехъядерный центральный процессор на правом слайде на правом графике вы видите уже не не максимальную производительность и эффективность и производительность на ватт и здесь уже по 4 является самым выгодным устройством и он больше чем 60 раз превосходит центральный процессор именно для этого показателя по этому показателю эффективности с каким я не знаю то есть мы я я так скажу что есть мнение что в пиджей они для задач глубокого обучения нет как бы находится в неэффективном каком-то месте то есть если эффективно использовать либо джикию поскольку дает большую гибкость в применении новых алгоритмов людендорф быстро можно легко начать использовать много причин либо если у вас есть какое-то очень фиксированную алгоритму фиксированная модель и вы понимаете что вы ее будете использовать следующие несколько лет вы можете сделать и сик это либо эйсик либо джипе юнг j как то у меня такое понимание что она просто невыгодно но смотрите на этих слайдах сравнивается те решения которые вы можете получить да то есть вы взяли купили g пью запустили взяли купили центральный процессор либо запустили на существующем странам процессоре где вы возьмете ты в пиджей сколько у вас времени уйдет на разработку под него я не знаю но быстрый ответ нет здесь нет в пейджер и собственно все если у вас есть ещё вопросы"
}