{
  "video_id": "MGo5djFvXK4",
  "channel": "HighLoadChannel",
  "title": "Миграция БД больше 10Тб с DB2 на PostgreSQL без простоя БД / Дмитрий Погибенко (НИИ Восход)",
  "views": 1219,
  "duration": 2522,
  "published": "2018-01-16T13:36:59-08:00",
  "text": "я расскажу про то как мы мигрировали базу данных размером 10-15 ТБ с дебету для zos на пост SQL причём не останавливая работу с базой данных была поставлена задача щение перевести базу данных с дебету на постгрес причём постгрес на Эльбрусе То есть это первый цот на Эльбруса в России ну и в мире требования к процессу миграции на слайде Сейчас расскажу про каждый про каждое отдельно в процессе миграции необходимо было преобразовывать данные так как было принято решение вынести блобы из базы данных в цеф плюс К тому некоторые типы данных отличаются вту пост как я уже говорил процесс переноса должен был происходить без остановки баз данных так как база данных достаточно крупная и невозможно остановить работу с ней на время необходимое для Е полного переноса мто образом отслеживать и обрабатывать изменения в данных база в базе данных достаточно большое количество таблиц около 300 или чуть больше с достаточно сложными зависимостями и при переносе нужно было учесть эти зависимости потому что было решение переносить не сно что посчитали что провели замеры И посчитали что восстановление займёт по времени больше чем перенос с со всеми Кеми плюс К тому сохраняя мы гарантируем целостность баз данных если что-то пойдёт не так то мы это увидим сразу для перехода на постгрес были выделены достаточно сжатые сроки поскольку ограниченный бюджет плюс это политический вопрос и дополнительное требование - это возможность использовать систему миграции для миграции для потенциальных миграций других баз данных поскольку весьма вероятно что в госсекторе будет ещё много миграций бас как жить с зависимостями простенький Гра зависимости и тут достаточно очевидно как ВС это переносить то есть мы переносим вот в таком порядке и собственно мы так и попробовали сделать но натолкнулись на такой вот момент что натолкнулись на момент что считая диапазоны для переноса и перенося в таком порядке У нас в процессе миграции возникали конфликты было принято реа то есть условно говоря переносим мы начиная с независимых переносим сначала независи не зависящие ни от кого таблицы а диапазоны считаются в обратном порядке таким образом в процессе переноса конфликта не возникает Граф зависимости для нашей базы данных тут конечно не видно ничего но видно Тут специально не видно ничего потому что это в принципе информация можно сказать закрытая То есть даже если вы увеличите это вы ничего не увидите Там просто будет бедан но видно что граф зависимости достаточно сложный и руками это обработать нереально то есть выстроить Вот это в правильном порядке так чтобы не возникло никаких конфликтов это нереально плюс К тому ну здесь это конечно не видно но здесь есть циклические зависимости их тоже надо как-то разрешить поэтому необходимо автоматизировать анализ зависимостей И для этого мы взяли схема SP и немножечко его доработали чтобы можно было использовать и чтобы на выходе получать не картинки а собственно работать через Java это достаточно известный инструмент достаточно старый с открытым кодом с достаточно кривой архитектурой но тем не менее достаточно удобный в применении с помою него можно анализи зависимости он сам умеет искать циклические зависимости и умеет упорядочивать таблицы от независимых к зависимым Ну и наоборот соответственно если Развернуть как я говорю как я говорил мы его немножечко доработали сделали для него работ с большими массивами данных существует известный инструмент СН И что он даёт из коробки это управления транзакциями то есть вся головная боль по поводу транзакций уходит в и в общем мы ему вполне доверяем Но если хочется какой-то гибкости то можно в каких-то определённых местах указать как мы хотим работать с транзакциями а в основном Он отлично справляется с этим делом опять же он даёт возможность обрабатывать данные по частям то есть вычитывать таблицы маленькими кусочками обрабатывать их и вставлять в целевую базу данных очень важный момент это декларативная конфигурация то есть причём это xml соответственно эту конфигурацию мы можем генерить автоматом конфигурации важный момент это возможность остановки и перезапуска с места остановки то есть мы можем например мигрировать по ночам потом останавливаться днём когда высокая нагрузка мы не мигли уменьшаем количество потоков миграции ночью мигрирующие возможность гибко управлять обработкой ошибок то есть ошибочные строки можно пропускать можно попытаться обработать повторно там по по исчерпании лимита пропусков или повторов можно упасть и так далее Вот вот так выглядит маленькие кусочек конфигурации спринг бачей Ну собственно это обычный ничек М что тут вот объявляется а имя джоба ДБ - это собственно А так сказать верхнеуровневый М верхнеуровнево сущность в в терминологии Spring bch это собственно вот весь процесс А дальше СТП То есть это какой-то шаг этого процесса Ну в нашем случае то есть в нашем случае J - это сама миграция а п - это определённая таблица TAS это собственно само задание и вот дальше чанк я чуть позже расскажу что такое Чан ориентированная обработка в спринг Ну и дальше указывается процессор Writer А это обычные спринговый бины то есть Ях Я не стал м демонстрировать как они выглядят но собственно это Просто классики а чуть а да на следующем слайде я расскажу какой интерфейс и комит comit интервал - это размер транзакции то есть аа мы Коти каждые 100 строк в данной конфигурации это центральна интерфейс с собственно это вот как раз вотр процессор и это те интерфейсы которые должны имплементировать ла об вст и райте здесь Как говорится очевидно что ридер и процессор обрабатывают поштучно строки то есть построчно Ате обрабатывает целиком который объявлен как вот размер куска объявлен этот комит интервал А так едем дальше а разница между it ориентированной обработкой в Spring batch и Чан ориентированной обработкой в Spring batch а для айма ориентированной обработки а процесс такой э запись читается обрабатывается записывается для Чан ориентированный То есть это для нашего случая для случая конфигурации которая здесь указано А как я уже говорил запись происходит построчное чтение построчная обработка запись происходит для целой па есть это ба запись соответственно она значительно быстрее чем построчная можно в принципе можно свести Чан обработку к построчно если комит интервал поставить в единицу это опять-таки Чан ориентирована немножечко по-другому нарисова то есть читаем обрабатываем обва партиционирование То есть это одна из стратегий многопоточное вот этот этот это обычные шаги не партиционирование Master steep А как это организовано есть интерфейс Шенер А который нужно имплементировать и в нём собственно мы реализуем стратегию разбиения на диапазоны в нашем случае это а я чуть позже расскажу как именно это происходит в нашем случае это разбиение по диапазонам ID то есть мы заранее считаем диапазон ID по таблице выделяем каждому вот этому каждому суб так сказать шагу свой диапазон и они их спокойно обрабатывают не пересекаясь друг с другом в нужное количество потоков это общая схема миграции наверно здесь не видно но я постараюсь кратенько это всё озвучить это первичный анализ базы данных То есть это то для чего мы используем схема SP это чтение структуры базы данных её анализ построение Гра зависимости автоматическая генерация конфигурации СБА дальше ручной анализ базы данных это ну собственно проверка того что всё сгенерить правильно плюс разрешение циклических зависимостей Ну то есть мы получаем от схемы с список циклических зависимостей а Какою из контов в этом случае сносить это уже мы решаем из бизнес и вот так управление миграцией - это собственно то чем занимается СН бач это возможность приостановить возобновить отслеживать статус миграции м собственно перенос данных э и отслеживание изменений про отслеживание изменений я чуть позже расскажу как это всё организовано и плюс ещё такой момент у нас построчная верификация данных пос Была проведена построчная верификация данных после переноса то есть по сути мы повторно читаем всю исходную читаем целевую базу данных построчно и сравниваем что получилось на самом деле было проведено три миграции первая тестовая закончилась Ну она закончилась успешно условно успешно но там выявились проблемы в ядре шено что поскольку эти проблемы могли оказать влияние на данные то на всякий случай Мы будем перемиг потом было была во время Второй миграции как раз на построчной верификации было выявлено ошибка в а в самом процессе и и третья миграция была уже успешная и А да На самом деле я не сказал вся миграция была уже проведена и всё успешно запущено уже 2 недели стема работает на постгрес вчера коллеги мои рассказывали собственно о самом процессе перехода с фрейма на Эльбрус если кто не слушал вчерашний доклад это система гмир бывшая гспд НП То есть это система выдачи загран паспортов и виз видов на жительство кто и получает это ВС проходит через как раз таки вот этот вот цот который сейчас был переведён на Эльбрус То есть вы условно говоря получаете загранник через Эльбрус немножечко про отслеживание изменений отслеживани Дан самый очевидный способ отследить изменяющиеся данные в в базе данных это повесить на все таблицы триггеры и куда-то писать изменившиеся строки Ну в данном случае не целиком строки а только их идентификаторы то есть для каждой табли данных служебная таблица отслеживания изменений с дишни изменившейся строки Ну если это композитный ке то соответственно там будет несколько полей на P тайм смпом операции и собственно самой операции То есть это insert update либо delete А причём м Если по той же строке а были последующие изменения то эта запись перезаезд переноса данных периодически вычитывает из служебных таблиц ID изменившихся строк читает из основных таблиц собственно сами данные и переносит их в целевую базу данных сама Ну система переноса изменившихся данных устроена примерно также как система первичного пере данных Ну это такая деталь в во время основного переноса используются только инсерты То есть если если вдруг внезапно оказывается что мы пытаемся записать во время первичного переноса данные которые уже есть в целевой базе то мы на этом падаем Но это то есть это собственно ошибка Если мы пытаемся записать то что уже существует где-то что-то у нас пошло не так а во время переноса изменений это уже нормальная ситуация потому что это перенос изменившихся данных соответственно там используются АСР То есть inert он конфликт update - Это для постгрес либо для дебету Да система может работать в обе стороны там и не только для пары deg она там с небольшими изменениями может работать для любых других реляционных СУБД и даже не реляционных вот ну для дебету АСР реализован через храним так это упрощённая диаграмма работы системы Я думаю что её опять-таки не видно но здесь собственно Что интересного можно увидеть то что все операции записи происходят в транзакции причём При первичном переносе вот здесь нарисован собственно перенос основных данных транзакция происходит по одной базе данных то есть служебные таблиц отслеживания изменений служебной таблиц переноса сприн баче находятся на целевой базе данных и соответственно никакой распределённой транзакции не нужно и всё прекрасно соответственно здесь у нас изображено какое-то изменение в исходной базе опять-таки оно происходит в транзакции есть это обновление самих данных это даны в таблицах отслеживания изменений то есть вот Мы записали данные и записали их шники в служебные таблицы потом процесс А так это у нас следующий тут нарисован по времени процесс верификации построчной То есть он вычитал данные исходной вычитал из левой вериф и вот ВНО Ну тут нарисована ситуация что изменились данные которые же перенесли но но ещё не успели обработать с системой переноса изменившихся данных соответственно вот мы пишем а вот здесь нарисовано что эти данные нарисована обработка этих данных системой переноса изменений и вот здесь Такой тонкий момент изобра в вот этим вот красным кружочком тонкий момент тут вот в чём а сами данные пишутся в одну базу данных под одной СУБД а отметка о том что мы успешно перенесли изменившиеся данные должна быть в служебных таблицах на стране исходной базы данных то есть это по идее должна быть распределённая транзакция Но если посмотреть то в общем-то ничего страшного не будет если мы например эту транзакцию это если эта транзакция успешно прошла а это заферано не будет просто мы повторно те же самые данные попытаемся обновить успешно обновим поэтому распределенная транзакция здесь не нужна здесь мы обходимся просто двумя последовательными транзакциями по двум базам данных в двух суд опять-таки нарисована попытка верификации этих данных и на этот раз она закончилась дизо это то о ЧМ Я говорил как мы партиционирование данных на диапазоны по айдини кам как всё происходит читаем минимальный максимальный дишни из таблицы ой считаем размер партиции Каким образом разность максимального минимального ашнико на число партиции плюс о То есть получается плюс о здесь нужен для того чтобы гарантированно все данные перенести то есть последняя партия будет меньше чем все предыдущие не принципиальный момент Ну и собственно вот тут вот такой вот маленький кусочек кода как считается каждая партиции вот ну тут ничего такого интересного нет интересное вот здесь есть это а так вот этот простой вариант разбиения работает хорошо если айдини распределены равномерно тогда в каждую партию подает примерно равное количество строк равное количество айдини и всё хорошо они спокойно переносятся параллельно никаких проблем не возникает но в реальности не всегда такое бывает Бывает так что что-то как-то пошло опять-таки не так и образовался какой-то гигантский пропуск в в ашках Ну вот в нашем случае по нескольким таблицам Прим большим там на миллиарды Да там одна чуть меньше миллиарда 800 млн строк другая пол миллиарда там были большие пропуски и получалось так что на например на чех партиции 63 оказывались пустыми или почти пустыми и было был применён подход более сложного разбиения на диапазон здесь гарантировано равное число строк кроме последней партиции последняя будет как и в прошлом случае меньше остальных Но это работа этот подход работает очень медленно особенно на постгрес на дебету достаточно быстро обсчитывают диапазоны то есть на 7 млрд строк м расчёт занял что-то около 10 часов на постгрес это нереально а но к счастью для постгрес это нам и не нужно было нам надо было посчитать на дебету здесь Но но здесь кстати поз грессо вый запрос приведён поскольку он а проще дебету Наго А показывает собственно А показывает сам подход а-а правильно то есть мы опять-таки мы считаем количество строк в таблице опять-таки минимальный максимальный ID берём а но на этот раз размер партиции считается не от разницы между минимальным и максимальным ID а от собственно количество строк в таблице то есть здесь всё то есть здесь размер партиции будет действительно соответствовать числу строк В этой партиции А и дальше Просто берём и последовательно отсчитывая в табличке офсета берём офсет и то есть сдвигаем на нужное количество и получаем айди ничек последний в диапазоне Ну соответственно мы знаем первый мы получили последний и вот партиции посчитано и так для всей таблицы Это довольно долго но зато эффективно вот тут такая небольшая небольшое резюме данные отслеживаются с триггерами в зависимости анализируется схема спа и данные переносятся спринг батм и основной перенос данных и перенос изменений и верификация всё происходит всё производится спринг бам вот на самом деле Ну каждая миграция имеет своя особенности даже поку миграция работат в Да Сейчас расскажу как сейчас у нас организовано Мы перешли на постгрес но при этом у нас идёт асинхронная можно сказать репликация в дебету с небольшим лагом То есть у нас дебету всё поддерживается в актуальном состоянии чтобы если что-то у нас пойдёт не так мы могли быстро вернуться обратно вот часто спрашивают э ээ если снести индексы и восстановить после переноса будет быстрее Или нет вот В случае Эль брусов Нет в случае x86 и других процессоров А у которых каждое ядро имеет высокую тактовую частоту Скорее всего будет быстрее Но поскольку брусов ядра слабенькие а индексы считаются с большой нагрузкой на процессор то получается не быстрее и размер комита и количество потоков в каждом случае подбирается экспериментально то есть пробовали всякие варианты для основной миграции в нашем случае оказа это число ядер на серверах которые используются под базой данных и тысяча строк каждой транзакции не знаю почему именно 000 строк Но как-то вот так получилось что если меньше тысячи или больше то миграция ИТ медленнее ядер потоков то начинает быстро деградировать скорость миграции и небольшая такое небольшое отступление Какие базы данных легко мигрировать вчера на каком-то докладе спрашивали Хорошо ли по-моему иль Космодемьянского спрашивали как он относится к к бизнес логике в храним он ответил что в общем не видит в этом что если что какие-то трансформации данных лучше производить ближе к данны к данным и в общем ничего плохого в этом нет Если там нет какой-то математики Но для миграции Это не очень хорошо потому что нужно переписывать всю бизнес логику поскольку у нас никакой бизнес логики в храним ках нет у нас только какие-то какая-то логика работы с данными то есть ну те же самые uper update или что-то вроде того то ничего таго переписывать Нам не пришлось опять же во всех таблицах должен быть первичный ключ Желательно чтобы он был числовым Потому что со строковыми работа помедленнее Ну и проще когда он по одному полю а не композитный опять-таки добавляют много проблем и много проблем возникает если по базе данных идут апдейты и де интенсивно Почему Потому что это блокировки и скорость падает То есть когда мы пытаемся одновременно отслеживать изменения там писать в служебные таблицы при этом вычитывать и что-то обновлять удалять то там сплошные блокировки А debit по zos - это чистый блокировочные всё дедлок всё встаёт Ну на постгрес там обратная ситуация поскольку это версион то вот э вот история версии она разрастается там куча одновременных транзакций и тоже падает производительность Ну как-то вот так спасибо за внимание Если есть вопросы готов ответить в принципе Спасибо за доклад подскажите пожалуйста Каким образом фиксировали первоначальное состояние на момент инициации переноса Каким образом фиксировали на состояние на То есть как отслеживали изменения Это понятно но с чего-то надо начинать то есть пола у на реплика вот какой момент да Ну давайте вот в простом варианте считать чтобы Моро тем мы берм минимальный максимальный дишни для таблицы и собственно вот вот это состояние для таблицы а как я говорил диапазоны считаются в в порядке обратном переносу данных то есть сначала считаются диапазоны для самых зависимых таблиц и поже позже считаются диапазоны для независимых таблиц соответственно независимые могут убежать чуть-чуть вперёд Ну они спокойно перенесут а зависимые м зависимые в момент своего переноса будут в любом случае иметь уже все свои зависимости уже перенесённые вот так фиксируется собственно состояние Ну то есть я правильно понял да Что какой-то фиксации первоначальной не было То есть вы просто начали начали с метки времени А дальше отслеживали Лог который писался отри просто с этой временной отметки далее да то есть мы запустили эти триггеры они начали писать мы запустили расчёт диапазонов То есть у нас будет небольшое перекрытие а то есть часть данных которые часть часть данных которые изменились в момент расчёта диапазонов они Перенесу и в основной миграции и в миграции изменени переносе измене они перепишу просто да да то есть ничего страшного не случится как я и говорил там а на в в в системе переноса из низших все данных используется update or insert inserter update То есть если insert прошёл с ошибкой то это будет апдейт то есть если это данные уже есть то будет апдейт Ну понятно спасибо можете выходить на рынок с фреймворков для кроссплатформенный репликации бадан да на самом деле у нас нет задачи выйти на рынок у нас есть задача донести до рынка что миграция данных - это не так страшно и собственно Ну я боюсь что даже ну не боюсь а я уверен что нас поскольку мы основной государственный интегратор не Восход будут привлекать к миграция каких-то других государственных систем Так что без работы мы М вряд ли останемся с этим вот если Вопросов нет тогда Спасибо большое Благодарю за выступление Спасибо а"
}