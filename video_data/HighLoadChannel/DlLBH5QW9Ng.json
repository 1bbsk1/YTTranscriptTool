{
  "video_id": "DlLBH5QW9Ng",
  "channel": "HighLoadChannel",
  "title": "ElasticSearch и Heka: как мы учились просеивать слона через сито / Адель Сачков (Яндекс.Деньги)",
  "views": 18820,
  "duration": 3247,
  "published": "2017-12-11T01:19:32-08:00",
  "text": "всем спасибо что пришли я действительно зовут адель сачков я на самом деле работаю компании яндекс деньги мужчину все правильно объявил я в компании так уж получилось главный пологом когда год назад я пришел работать в компанию нас на тот момент не было системы сбора и что самое главное оперативного доступа к лагам нет логе конечно собирались они являются сейчас отправляюсь новак сервера но вот оперативно получить ним доступ было несколько сложновато и передо мной была поставлена задача эту систему собственно создать сегодня расскажу как я строил с чем пришлось столкнуться какие проблемы преодолеть на этапе строительства и почему были выбраны те или иные сервис и я очень надеюсь что вы рассказывают полезны только большим компаниям но и маленьким организациями поскольку вспоминая свой опыт работы небольшом стартапе несколько назад у нас была та же самая проблема и мы не смогли ее решить нам казался это очень сложно дорого и долго но нет на самом деле всё очень просто и построен очень простых сервисах и еще одно небольшое лирическое отступление в чате телик телеграм-канал а конференции я встретил фразу которая на мой взгляд достаточно хорошо характеризует со времен современное отношение к стыку sixer шлак стрижки бана попытаюсь процитировать звучал примерно так белка все три буквы отстой если киба на еще ничего то первые две буквы реально отстой а я надеюсь мне удастся это мнение сегодня преодолеть я расскажу как мы готовим ластик и почему отказались от lacoste с но это было лирическое отступление давайте перейдем в лирическое наступление когда я начал эту задачу год назад мне казалось нам что там о георге файлики растут соберем отправим но когда начал работать передо мной в полный рост немедленно стал целый ряд проблем первое наши сервисы написаны на множестве разных платформ и ты так сказать тяжелое наследие legacy решений это и специфика работы сервисов соответственно вас есть java и съест но джесс есть спички есть много чего еще данные сервисы работают совершенно разном окружении есть мощная тяжелая виктор занимают целые железные сервера есть сервисы которые живут в систему виртуализации есть сервисы маленьких тоже маленьких контейнерах а и все это нужно логировать хотелось бы еще в ту же систему сбора логов завести сторонние сервисы а эта муха как минимум и jynx maze gres жиру где идут где хранится вся информация о клиентах саппорта почта поскольку клиент попадаю на систему получают уникальные секаторы хотелось бы прослеживать весь его путь по системе поэтому индификатор по всем сервисам скачать который прошел если нужно будет найти где собственно затык следующая проблема истекает из специфики нашей работы мы все-таки финансовой организация работаем с деньгами клиентов и поэтому каждый шаг каждый чих должен быть записан наши сервисы генерируют огромное количество логов для примера могу привести недавно был микро сервис нас его сейчас команда рефакторинга слава богу распилила порезала но он стрелял по 250 тысяч записей минуту создан на одном только бы кенте таких быков и его было 20 25 ну и еще одна проблема это разные форматы логов никто никогда не думал и не заботился о том чтобы все логе делать в одном и том же формате или хотя бы более-менее приводить их такое понятие как культурологов у нас не существовало на тот момент соответственно рассмотрев все эти проблемы мы сформировали список требований к системе когда мы она должна удовлетворять первая система сбора логов должно быть не требовательна к окружению он даже должна работать везде везде где живет наш сервис должен и работать сборщик соответственно должна быть не требовательна к ресурсам поскольку очень многие сервисы живут маленьких контейнерах с весьма ограниченных по ресурсам но в том же время система должна уметь переваривает большой объем этих логов которые мы генерим и все это уметь делать в жиме реального времени поскольку основная задача которая была это в реальном времени видеть что происходит с системой с более чем сотни сотни микро сервисов размазанным по тысячам и тысячам разнообразного окружения следующая задача которая обязательно должна быть решена это не терять данные мы опять-таки финансовые организации мы не можем себе позволить данные потерять на каком-то следующих докладов пологом я слышал фразу а доставка логов не гарантируется вот мы этого себе позволить вы не можем никак и еще одна проблема еще одно требования которые обязательно должно было быть выполнена опять таки происходит из специфики нашей работы мы должны уметь весь этот большой объем данных логов фильтровать на лету что я имею в виду мы работаем с деньгами клиентов приватными данными и наши сервисы все научные маскируют приватные данные перед тем как положить их log но никто из нас не создан совершенным проблемы могут быть могут возникнуть и такие данные могут блок попасть соответственно мы должны уметь фильтровать их на лету не выпуская чувствительные данные за периметр сервисы где сервис работает что же мы в итоге выбрали ну сюрприза не получится громадный жирный спойлер у него в заголовке доклада присутствует до хера вот этот прекрасный мужчина без штанов это египетский бог магии heco я как от мужского рода для меня был сварен суп из а да и то что хека позволяет творить слугами на мой взгляд просто волшебство поскольку я к написано ногам она не требует никаких дополнительных сервисов для своей работы и в этот момент у нас как раз отпал из выбора лог стаж потому что написано j руби тяжелый требует яву а тащит я в машину кормить маленький контейнер где трудится несчастный backend но джесси ну категорически не правильные сильно расточительно соответственно из того что все это написано go вытекает скорость она очень и очень быстро и по соотношению перевариваемый объем производительность она превзошла всех конкурентов на этапе когда мы их рассматривать heco умеет в регулярное выражение это опять-таки критично когда вы имеете дело с огромным массивом развал разнородных логов сразу перевале переломить эту ситуацию многочисленных legacy решений которые пишут разные форматы не получается поэтому под каждый формат пишется своя собственная регулярно he claimed в плагины потом уже go или ничуть не немедленному а это на тот случай если нам вдруг захочется странно ну например что-нибудь человека из коробки не умеет недавно кстати нам странного захотелось таки мы обратились разработчики сказали что они хотят писать логин джи свою зачем я честно говоря не понял но мы можем это сделать и кстати кто вчера был на закладин джинкс знает или читает их через блок знает что индекс теперь наконец-то умеет писать логе в джейса и правильно я думаю мы это обязательно попробуем потому что для себя лично я вижу здесь плюс в чем мы сэкономим производительности одно дело нам прилетает длиннющая строка которую мы матчем в регулярке другое дело плита джейсон где все данные уже разобраны по полям мы сильно сэкономить ресурсы века и теми же плагинами мы фильтруем чувствительные данные то о чем я говорил не выпуская их за периметр серый где работает сервис плюс heco это обработчик и транспорт в одном лице вы когда пробовали другие системы нам приходилось ставить какой-нибудь транспорт мы пробовали кафку пробовали apache флю но потом мы подумали я решил чем меньше в зонтике сочленений тем меньше шанс что он сломается и поэтому мы выбросили все и оставили очень просто heco heco и приемник и отправили обработчик и транспорт данных хека покой данный про табов перед отправкой это очень компактно удобно поэтому мы пользуемся этим и плюс усики есть очень хорошие работа с буферами который позволяет нам не теряет данные хека накапливает данные перед отправкой в буфер и дисковые буферы и при потере связанности они там никуда не пропадают данные потом отправляются как только связь появилась чуть чуть и настройках тут самое основное за более подробными деталями я отсылаю вас к циклу моих статье нашем блоге на хабре там прямо есть примеры конфигов можно брать пользоваться но самое главное основной мы используем обычный лак стример то есть просто читаем изменение файла все сервисы пишут файлы мы читаем изменения раз в две с половиной секунды учитываем те к обращается каждому файлу проверяет что там с ним произошло нового собирает это данные и отправляет это вдвое быстрее чем дефолтные настройки это родилось все эстер экспериментальным путем если собирать чаще очень вырастает нагрузку на низкую систему если медли и мы теряем ключевое преимущество мультфильм real-time все это декодируется регулярка me a buffer и выходные буферы навешаны по гигабайт у на каждый сервис это опять-таки родилась экспериментальным путем и эти буферы позволяют сглаживать вот 5 от пики нагрузки которые прилетают либо переваривать переживая ситуацию когда связь прервалась политика работы с буферами это одна из специфики это бог что это значит как только буфер переполняется в смысле наполняется доходит до гигабайта хека может сделать три вещи она может упасть и то есть настройках просто выключится есть возможно начнет выбрасывать старые данные в эту себе не можем позволить и она может заблокировать отправку как останавливается и ждет пока связь не установится как только связь остановилась она начинает бешено про плевать этот буфер отправляя и мы можем получить вот такую capture это реальные данные zabbix а здесь вот видно что это за неделю и в один из дней утром что-то случилось то ли связь между со моргнул то ли еще какая-то причина выяснить не удалось кики встали как только здесь появился они начали бешено отправлять это минус данного подхода но он нам гарантирует что мы не теряем блоги и поэтому все приемные пулы куда уходят эти данные на приемном конце настроена таким образом что мы готовы к este кратным пиком нагрузки плюс еще этого в том что кто вчера был но докладе моего коллеги анатолия из-за нагрузок ников он рассказывал как они стреляют в сервис и вот о том что какие-то стрельбы были я узнаю не в тот момент когда ночью творит мониторинга говоря elastic упал а утром когда прихожу на работу и смотрю в записи что там была за ночь вижу такие вот горбы ого какие то стрельбы были замечательно хорошо данные мы собрали те к их разобрала регулярке упаковал в про табов отправила что на приемном конце ну опять-таки интриги не получится все было выдала все доклады мы используем ластик и честно говоря особого выбора что использовать нас не было потому что elastic это эта вся мощь библиотеки льются это полнотекстовый поиск причем поиск мульти индексный как я уже говорил пользователь нас получает уникальный идентификатор во всех сервисах и мы можем одним запросом поискать все вхождения идентификатора пологом всех сервисов сразу elastic это hibana поскольку логан и у нас пользуются не только технические специалисты но и менеджеры саппорт поддержка бизнеса мониторинг кто угодно еще но нужен был максимально простой и удобный инструмент типа на в данном случае просто идеально ее можно дать всем все будут ей пользоваться если кому-то не хватает того что киба она умеет нас пластике есть api куда открытый доступ разработчиками разработчики могут любой момент их туда пишут какие-то хитрые запросы агрегирует ризу получен результат и генерирует новые запросы я этого не касаюсь им доступ выдан они пользуются они довольны я довольно тоже дальше относительно небольшие объемы хранения лиц он достаточно компактный этом смысле ну и шарди ранее репликации это понятно с родированием мы позволяем размазать нагрузку по всему кластеру прилипли к цию тоже понятно поскольку данные позволить себе потерять мы не можем я публикацию чуть попозже так немножко про наш кластера ластика весь кластер весь кластер ластика живет на 4 xeon ах на которых стоит полтора байта памяти 316 травоядных рейда где все это хранится кластер состоит из трех мастернод 2 клиентских not они же являются in jest нотами они принимают запросы от ки баны туда же открыт доступ к api и разработчикам кэширует запросы опор и 8 data not а также на двух серверах расположенный по ул и хек которые принимают логе на психа прокси и все это собрано в иксе контейнерах вот тут вот один нюанс почему лекси galaxy не зря называет легка визором у него очень низкая верховную актуализацию и еще есть одно на мой взгляд uber фича который мы активно используем который обнаружил сюжета тестирование все знают что такое новую форму memory access доступ памяти на мультипроцессорных серверах когда каждый процессор у него есть ближайший путь к своему банку памяти и и лекси позволяет прибить контейнеры только к тем я драм которые находятся в пределах одного процессора и мне надо будет ходить в дальние банки памяти за собственной памятью на тяжелых java приложения которые кушают как elastic по 32 гигабайта мтс памяти по моим тестом отдает 11-14 процент производительность это очень много собственно схемы доставки логов выглядит вот так на каждый сервер в каждый контейнер в каждую виртуальную машину где стоят сервисы стоит прилетает один экземпляр хикки века обслуживают логе всех сервисов данного сервера собирает психики смотрят в один балансировщика нагрузки аппаратный а вот за ним стоят пулы приемные пулах патентами работают обычные лекси контейнеры которые стоят х прокси zoho прокси прячутся три экземпляра той же самой реки которые принимают данные разворачивают и спорта бафа декодировать и отправляют в ближайшую в ближайшую клиентскую но дуку автор elastic сейчас этих контейнеров у нас 4 когда я начинал строить было два учитывая что все это контейнер и клонируется это очень быстро при необходимости мы планируем пачками добавляем в систему чуть-чуть про настройки ластика logo одного приложения хранятся в одном яндексе каждую ночь создается каждый день каждый день создается новый индекс это позволяет нам очень просто и банально осуществлять чистку индексов поскольку хранить данные сильно долго не нужно мы храним данные 21 день за 21 день любой инцидент успевает протухнуть если инцидент подождал 21 день он подождет еще пару часов пока напишут запрос на доступ как сервер и получишь блоги для анализа соответственно каждый день это новый индекс индексы режутся пожар дам количество shard равно количеству дата но ты вот это вот тоже еще один тонкий момент власти которые хотелось бы рассказать ну на примере поначалу когда у нас было 4 да ты много ластиком и резали индексом 4 шарда потом добавились еще две дата ноды нагрузка выросла окажется shark я оставил 4 и обнаружилось что каждый день одна из data not начинало тормозить причем каждый день разное я начну разбираться почему выяснилось что тормозит модом на которой кончается память то есть и подбирался гигом приходил garbage collector обнаружу своему чистить нет ничего абсолютно автомобиль мир искал что по чести не находил уходил естественно а кластер работает со скорость самой медленной даты ноды это мы к этому пришли в результате опытов оказалось ночью когда elastic играет русскую рулетку раскидывая шарды по дата но там он не знает объем этих индексов в которых состоят шарды какие будут потяжелее какие полегче соответственно те моды которые мне повезло которую то надо которые пазла которые прилетали несколько шар дав какой-нибудь редкостно тяжёлого яндексе я вам покажу как она выглядит естественно выдала всю память поскольку индексную часть каждого шар дай ластик держит в памяти ему просто не хватало память соответственно у нас все с тех пор повелось так все даты ноды абсолютно одинаковые по объему диска и количество shard равно количеству дату not соответственно все шахты раскидывается равномерно по дата нодом и не происходит во первых нагрузку равномерно возможно во вторых вообще отсутствует какой-то ребаланс соответственно кластер не тратит время на ри балансировку два факта репликации 2 реплицирует все шарды держим их копию на но случай отказа как он железо момент про создание индексов и ставим столпа нас все работать phoenix тайме давите 7 но компания большая людей многом опять к ней совершенно есть ваши шансы что выглядит какой-нибудь новый сервис и конкурировать прилетит мск например аликанте экзотическое дата поэтому ластик научен не обращать внимание на даты приходящие блогах он создает индексы руководствуясь своим grammy и еще один момент это шар то локэйшн ava rose настройка который имеет смысл только когда ваш класс стр ластик живет разнообразно живет в контейнерах несколько нот находится на одном физическом сервере поясню на примере вот данная картина с точки зрения кластеры ластика никаких проблем не несет первичная и реплика каждого шарда расположены на разных дат анодах в случае отказа какой-нибудь дата но до ластик знает что поднимет реплику до статуса праймари соберется обратно в консистентные состояние будет работать но пластик не знает что он заперт в контейнерах и соответственно при отказе одного хоста мы теряем ни одну дату но duo 2 и в данном случае при отказе например 1 х 100 у нас вылетают 0 и первые шарды для этого есть нас троечка шартава конечного раз позволяющий повесить на каждую дату ноду атрибутики атрибут но в данном случае мы используем река иди йоту первой дотой 2 рынка иди одинаковые и пластику дана команда ни в коем случае не размещать первичную и реплику каждую шарда в пределах кинулся с одинаковым с одинаковым рака иди таким образом мы можем спокойно выключить любой из хвостов elastico остается в коэффициентом состоянием вот небольшой пример как у нас сейчас выглядит логин логе именуются по имени сервиса к ним добавляется дата и это очень облегчает задачу очистки логов не надо лазить внутри логов смотреть внутрь индексов смотреть что там хранится мы просто находим старые индексы и удаляем их системы вот кстати это топ индексов в нашей системе у которых больше ста миллионов записей хранится самый тяжелый как видите полмиллиарда и пока это все не тормозит но мы думаем что когда дойдем до миллиарда записей в одном яндексе мы начнем их резать либо на русская всего на часовые для простоты так к чему мы пришли в результате что у нас сейчас есть за сутки система переваривает 3 терабайта логов это где-то 2 и 7 десятых миллиарда записей наши пользователи которые внутри имеются вы пользователь системы и ряд по 40 тысяч запросов киба не и среднее время одного запроса получается где-то пример 250 миллисекунд на средне температуру по больнице эти тяжелые запросы длятся по четыре секунды есть очень быстро суммарно это выглядит мы храним то ли за 21 день как я уже сказал нет никакого абсолютно смысла хранить данные с мгновенным доступом к ним дольше чем 21 день любой инцидент с 20 дней стоит протух у вас есть лак сервера которые собирают логе тоже и учитывать специфику нашей работы там блоге лежат практически вечно известно это в быстром доступе на сейчас около 60 миллиардов записей суммарно 66 терабайт на дата но доха ластика мониторинг очень ключевой момент мало построить систему крайне желательно знать что с ней происходит и иметь какие-то возможности по прогнозирование того что с ней будет ближайшее время в качестве корпоративного стандарта по мониторингу нас при zabbix соответственно вот всю систему доставки логов от разнообразных як стоящих на серверах да и ластика мы идем на низких уровнях но самое простое невские туры и сервера это понятно это банально что я там с процом какой я в памятью какие есть ошибки в сети elastic крайне чувствительна к проблемам сетью оказался второй уровень повыше туры и приложения zabbix агент смотрит банально смотрит хек упала не упала ну вроде пока не падал и все дальше значит уровень сервиса пришлось написать небольшой плагин для zabbix а на питоне который ходит во первых контролирует объем дисковую буфер у всех на серверах если буфер и начинают подбираться к вершине это явно однозначно значит что что-то не то либо сетью проблемы либо объем вырос либо ластик тормозит не успевает все это переварить значит надо надо разбираться качество контактов на прокси естественно тоже мониторим нашу уровне java машина мы используем joe locke замечательный http джеймс гейт который очень легко интегрируется забег сам самое главное что мы мониторим это обязательно разъем объем памяти который ластик съел потому что как только он начинает подбираться к лимитом король коллектор начинает останавливать его пытаясь что-нибудь почистить если ничего не получается и весь класс торчать лихорадить соответственно тут же я только одно добавляет тут же наводите но да и резать индекса на более мелкие шарды соответственно мы опять-таки логе хикки пластикой и щеки банные заворачиваем в ту же систему в тот же ластик но для для анализа что собственно с немного происходит ну и естественно мониторим состоянии кластера через описан во власти к власти к огромное количество метрик который умеет отдавать просто огромная обо всех не расскажешь но ключевые 3 хотелось бы сказать которых по которым мониторинга приучен звонить мне в любое время дня и ночи это вот несколько это во-первых statuses кластера ну это понятно зеленый желтый красный если желтый означает что какие-то шарды потерял но ему хватает для consistent насти по красной значит все он не принимает логине отдает логином срочно чинить качество вела сыра и мокшан дав как я уже говорил при настройке когда у вас все даты ноды одного объема когда шар дав порезана по числу data not релокации не происходит вообще они изначально раскидываются по всем that анодом и лежат себе там спокойно не грузит сеть потом нужно не нужны или локации качестве nicevi зимы шар дав должно быть 0 если ну ночью когда создаются новые индексы может быть небольшой пикнуть сон длится дольше нескольких минут значит что-то не то с производительностью качестве не назначенных шар дав это сразу очень плохой признак до значится прилетели данные пластик не знает куда их деть держит их в usher и копится и системе все быстрей и быстрей соваться хуже соответственно как только не ной сразу alarm качество ожидающих task-ов по идее тоже должно быть 0 очень должна вы всегда пустая значит власти успевает в реальном времени перерабатывать все что происходит и туда же кстати максимальное ожидание в очереди задача тоже должно быть 0 это не ноль значит у нас пользователь ностью не то количество активных шар дав это метрика которая говорит что пластик видит все свои шарды знает что с ними происходит не волнуется их нужно всегда сто процентов если не 100 arm и мы еще смотрим в пулы трендов но там у нас интересует основном самое главное это количество rejected булок это значит что хека собрала данные приемную обработал их упаковала стрельнул его ластик а он не может их принять какой-то причине если это произошло все срочно alarm тревога знаете мне безопасность очень ключевой момент учитывая наши специфику нашей работы тут на одном да соответственно что нам нужно от безопасности что мы что мы подрезаем под безопасностью нам на главные требуя нам нужно чтобы кластера ластика икебана умели я в авторизацию пользователя удap поскольку все наши сервисы завязанные на удap мы должны иметь возможность дать раздельные доступы на индексы например поскольку разработчикам бэг-энда абсолютно не нужен доступ к лагам платежной системы завис на мы должны как-то уметь разграничивать доступ внутрь и ластика поскольку у нас api и ластика для разработчиков доступны мы должны уметь прикрыть api организовать авторизацию там и там же следить раздавать права на чтение и запись внутри индексов для приложения которые конектится к власти к папе опять-таки банально но в киба не изначально нет некой авторизации и все пользователи этой уровне пользователя и все пользователи могут например добраться до настроек keep on и зачем это не знаю но мы-то категорически не нравилось пришли от этого избавиться ну и крайне желательно иметь какой-то детектор аномалий который будет уметь ходить внутри индексов и смотри что там с ними происходит вот сегодня кажется одном из докладов я услышал похожие рассуждение прогиба ну и люди там решили проблему отсутствие различия доски пола очень просто они отказались атаки больны да но мы к сожалению себе это позволить не можем как я уже говорил нас киба на это основной сейчас инструмент им пользуются все и какое-то время выезжали на сознательности но потом когда начали добавлять блоге все много новых приложений жили что нужно с этим делать как мы решили эту проблему первым что вы сделали естественно обратитесь к производителю за лицензии на экспорт ну выяснилось выяснилось что знает связи очень сильно зависит от ряда факторов а ключевой момент там был количество индексируемых качестве индексируемых данных в секунду размер значит инсталляции объем и количество нот и прайс по результатам заполнение мной вот такой огромную анкеты оказался где-то самом дальнем правом углу от этой таблицы цен я значилось скромный слова кол звоните да по результатам анкету заполнили отправили позвонили по результатам сумма которая была озвучена я боюсь со сцены такие больших цифр произносить она казалась говоря ну очень неразумный там получилась цифра с пятью нулями долларов в год не сразу заплатили tea заплатить из год платье еще раз мы начали искать альтернативы поскольку это совершенно как-то несерьезно и мы придумали что собственно весь икс пак можно заменить тремя очень интересными вещами есть плагин от сторонних разработчиков называется readonly rest который очень бюджетный это кстати единственное платное решение во всём моём рассказе работает как плагин для выпускаются в двух вариантах да как плагин для кластера ластика и плагин для кабаны он умеет авторизацию голдап все пользователи попадая в кибанов получают сначала зеленое окно с авторизацией white логин пароль проверяются в доме не только потом и впускает дальше он умеет организовывать доступ на чтение записи и к индексам он к сожалению на данном этапе но мы общаемся с разработчиками не умеет скрывать индексу который по которому вас нет доступа но зайти в эти индексы посмотри что там вы не сможете если у вас не хватает доступ и этот плагин замечательно умеет делать уровни доступа в киба не то есть мы скрываем от большинства пользователей выключаем настройки и администрирования оставляем им только просмотрели лица вскрываем devtools пуском это не нужно и плюс с недавней версии он имеет выудить событий он ведет полный лог что собственно пользовались левкипп они наделали это очень удобно разбираться почему вдруг она затормозила и кто-то там выбрал поиск за весь период всех записей что это вдруг за длинный запросу нас там пролетел в очереди но опять-таки мы взяли икс пак в базовой лицензии бесплатный и используем его для мониторинга системы смотреть что с окна системы происходит он в этом отношении крайне удобен показывает в реальном времени естественно ничего не пишет не сохраняет просто в реальном времени позволяет смотреть а что собственно системой происходит nastya сейчас и последняя вещь это last alert это от независимых разработчиков спонсорстве есть на гитхабе мы им пользовались когда у нас был акебоно версии elastic был версии 2 2 но потом мы спешно переехали на пятерку они нет поддержку 5 ластика не допилили буквально вот вот недавно и сейчас мы снова к нему возвращаемся что умеет was the left the last lear ты умеешь ходить внутрь индексов анализировать то что он происходит и алор медь по очень большому количеству правил которые мы настроим то есть папиком каким-то по частоте повторение каких-то событий или я приехали ровная линия пошла там хотя ровную линию мы мониторим и так мониторим когда в интервью ластик смотрим количество поступающей индексов не просто всю систему а в конкретный индекс если вдруг каком-то что-то прекратилось это может означать только одно разработчики выкатили новую версию поменяли там формат логов а меня никто не предупредил и все логе пропали соответственно мы об этом тоже крайне хотелось бы узнавать до того как позвонил разработчика возмущенно спрашивает а что это мой логии степан исчезли ну такие случаи бывали раньше когда то сейчас слава богу все реже и реже но на есть поэтому используем last' alert именно для хождения в twinks более подробно его пока рассказать не могу мы его только-только снова начали внедрять ну думаю но х прибудет еще одна моя статья где я все это пишу ближайшее время и того что хотела бы сказать в итоге мы никоим образом не луддиты я никого не призываю пользуюсь и прикиньте технологиями просто хотелось показать что технологии которые вы выбираете должны решать фильме ваши задачи пользу выбирать что-то потому что это нового известная хорошо себя в мире зарекомендовала стильно модно молодежно это неправильно через все за этим кроется желание попробовать что-то новое за счет своей компании выгнать сервисы по принципу одна большая мировая корпорация начинающиеся на букву г пользуются этим или не менее крупная компания на букву я этим пользуется тоже неправильно сервис должны сжать ваше имя вашей задачи нашем случае идеальным совершенно идеальным решением оказалась deep реки этот продукт веко и мне абсолютно не стыдно свой выбор то что применила на потому что работает уже год есть большой запас по производительности говоря мы видим и я довольна своим выбором на этом у меня все спасибо вопросы пожелания угрозы может быть да у нас есть 10 минут на вопросы погнали да спасибо большое за доклад вот прям все рассказывали вот прям как будто один-в-один тогда вот выглядит у себя вот прям натыкались на те же самые грабли чуть чуть громче да хотела спросить а вот по поводу хранилище 16 терабайта у вас это какие-то дисковые массивы или нет на самом деле это обычная sata хорошие sata винт и это локальные диски локальные диски до пдд не это даже не sdd вот все это система она работает на обычной хороших скоротать на хороших sata дисков мы используем сато в данном случае данный обычных и еще такой момент я видел вас там четыре физические железки добыли до 4 физические железки в каждый живет мастернода 2 дата ноты клиентская но на первых дальше просто дата ну и соответственно если например там одна выходит из строя производительностью вас не просаживается нет как я уже говорил что происходит у нас три мастерноды кворум равный 2 собран поэтому при двух оставшихся мастернодах он будет прекрасно работать до thanon дата но да это я когда говорил про размещение шар дав внутри шарды размещаются по раздельным не дата но дома железным нодом соответствие мы в любой момент можем потерять люк железку можно выключить на обслуживание делать не что угодно мы не потеряем резистентность кластер передаст желтый статус и проложит работать я имею ввиду именно в части производительности индексации нет почему а elastic он поднимает все доступные ему шарды когда он в них смотрит соответственно никакой производительности никакой потери предательством случае происходит у нас были случаи мы вырубали как бы до женскую на обслуживали кластер положила работать себя спокойно данные в него поступает все нормально при подъеме этой железке обратно он обнаруживает что а две даты надо вернулись давайте мы перри индексируем ся и в баграм анти начинает 3 индексацию среднего индексация занимает 5 6 часов вот всего этого кластера если выключить 2 года и потому включить какое-то время до пасибо ещё один вопрос по поводу боретесь ли вы как-то со спайками в индексации но когда вот вы показывали на графике прилетает куча всего неожиданно это кучу всего прилетела именно потому что мы не хотим терять данные мы готовы к тому что и так вот этот пик будет но может быть там тибо кто-то включил нет он сейчас сейчас он десятикратный пики нагрузки переживает легко абсолютно не замечая то есть вот то железо что у вас есть 1 5 этаже десятикратно довести кроты я рассчитывал изначально когда встроен 10 пики нагрузки ну опять-таки отвалилась связь все эти буферы накопились но мы не можем себе позволить потерять ни строчки логов просто не можем немыслимо и накопилось потом выстрелом и год даже быть к этому готовы или даже когда оно не знаю разработчики выкатили табак версию куда-то которые в которой уже индексации уровень лагерная стоит ты бак и мы тоже должны быть к этому готовым 10-кратный уровень да мы готовы спасибо всего вот пожалуйста спасибо за доклад было очень интересно на самом деле мы ранее пробовали elastico у нас как-то не полетел есть несколько парочка вопросов технических и управленческих собственно в чеке лаяли уа jit жаль если бы куда я понял хека не умеет принимать налоги по сети только с диска то есть она поднимает диска или все-таки а можно как-то засовывать логе видимо не достаточно ясно об этом сказал да тяжело то отмотаю но как у вас да возможно ли по-другому она нет сейчас секунду секунду секунду до держите дойдем чтобы например хуже показывать вот здесь где мы видим приемные она принимает их как именно по сети там обычно тисе пи input слушают порты туда ст стреляют хикки с серверов упакованными данными мы даже одно время мониторили пока не поняли что-то не сильно интересно физически железки свечей который на к слову отправляли туда же и хек а также слушала в ту спин я что то как то развели логически видим у да я недостаточно просто я буквально но и второй вопрос был такой управленческие сколько человек у вас занимается вот обслуживанием этой системы круто великолепно пожалуйста на вопрос по поводу x пока вы сказали что используйте basic версию do a basic бесплатная лицензия она позволяет чисто мониторинг но она же не позволяет работать в кластере работы в кластере приказу работы в кластере до бесплатная позволяет работать кластере она не позволяет alert и не позволяет всего о том развитие доступов только мониторинг всего кластера картинку к сожалению не могу привести к соображений безопасности но она и видит все гиббоны говорит что у вас так два из казаки баны 8 data not for more и она работают и spax нормально икс икс икс пак именно до после просто его мониторинговой часть но когда подпадает под дезик лицензию первый ряд пожалуйста спасибо за доклад первый вопрос такой вы искали что вам блоге очень важны да вот но тем не менее там с диска 1 2 исполнитель секунду вы их учитывайте вы пытаетесь достать логе если скажем надо упало вот и не успела отправить эти соответственно ло геологии остались на если какая-то но до упала во первых ее поднимут админы где они видят здесь во вторых высокая не и поднимут хека во-первых выберет все что там она и осталась и плюс сработает обычные сборщик налогов которая творит логинова к сервера у нас ноги идут двумя путями налог сервера в я обычных файлов которые синхронизируются с постоянным с модами и соответственно в те q если она упала и и поднимут и посмотрит первым делом влоги что полезно собственно что с ней случилось даже если сервис был докер контейнеры все поднимут все ну естественно конечно спасибо и второй вопрос фильтрация критичных данных чувствительным она осуществляется ну под каждый сервис пишите какие-то риге экспы и или что-то вроде того да ну я могу титанов даваться запрос get yourself in forest серым да спасибо большое за очень интересный доклад я хотя спросите вы говорили что на мониторинге бывает иногда прямая линия ровная то есть лагов нет мира и всё-таки какие-то логе могут пропадать они не могут пропадать я упомянул что мы отслеживаем такие ситуации когда вдруг flatline пришел это может быть слава богу крайне редко то есть культурологов терме который я придумала который уже год пытаюсь вдолбить разработчиков конечно мой дало свои плоды и люди перестали менять формат и логов не посоветовавшись со мной но бывало и если они поменяли формат логов до века они перестали мочиться в регулярку соответственно перестали попадать естественно тут же alarm тут же начинаем разбираться что случилось и потом происходит очень следующие либо откат его им приложения либо если это штатный случай то есть там формате лагов поменялись меняется регулярка накатывается обновлено конфиг на все сервера с этим приложением я который запускается с удалением дискового кэша это заставляет ее причиной все локи сначала дня она находит то место где влоги и формат влогов поменялся и прокачивает их и дырки исчезают на кипами баттлоге старого формата вот нового вот пожалуйста спасибо пожалуйста у нас пять минут до стоящего доклада чтобы сговоримся добрый день и спасибо за так вот такой вопрос как между центрами у вас один кластер в одном dc ac остальных как собираемся да ну вот в отличие от я сегодня слушал того докладчика у которого который отказывается кабаны у них была проблема их были dc в азии очень плохой контакт между серверами а то центрами им пойду к что использовать кафку слава богу у нас такой проблемы нет у нас классно стоит в этом-то центре сервисы размазаны по нескольким и они все смотрят в 12 центов ну то есть теоретически возможна такая ситуация если там в одном дать этому суперкаров бульдозер приехал кабель оптический то но и там с ним не будет связи как в это время если с ним не будет связи тот для него и клиенты смогут достучаться ну в принципе далласа общественное логов тоже как таковых не будет спасибо большое продолжаем первый ряд пожалуйста спасибо за доклад очень интересно хотел спросить вот каким способом управлять конфигурации атала стали рта то есть как вы храните настройки фильтров вот как я уже говорил мы только начали снова опять внедрять поэтому детали об этом рассказать пока не могу следите за нашим блогом на хабре течение месяца это вот там будет моя заключительная статья из цикла как я устроился автор своей мечты и я там все это распишу подробно и детально спасибо пока не готовьте вот стану привет от человек который собственно вчера рассказывал от коллеги который тоже единственной ответственной залоге был азазиль это мы отказались не критично не доставить какой-то часть логов спускайся обнимитесь мы отдельно я думаю сейчас мы обнимаемся еще у меня вопрос то есть правильная опять же понял что по умолчанию вы пишете сначала файл потом его подбирает хек и отправляет до носа сервиса пишут сначала и стокера они попадают в этот файл каким образом в каждом контейнере ну докер на самом деле мы вроде не используем но те из других контейнер другие контейнеров там стоит хека внутри контейнера рядом с приложением всегда смотрит его файлы понимаете в отличие от вашего случая вот хотел планету плюнуть и слегка упустил у нас логе большие вот реально там же следующий вопрос сейчас стоит лимит 10 мегабайт на одну запись недавно мы наткнулись на то что пришлось его увеличивает поскольку логе медленных запросов вас gresso они не влезали в 10 мегабайт мне пришлось увеличить ну это сочувствует они нам а компании atlassian который пожирая их ноги и им давайте тоже посочувствует а им давайте тоже по сочувствуем давать и так ну то есть вы пишете файл они промо плен и как-то куда а до я к запущен непосредственно нам не только на живет внутри каждого контейнера каждого сервиса где есть сервис рядом сервис и в такой вопрос нет ли у вас полей внутри логов которые оказываются больше 32 килобайт где без пробелов это я на то что если вы ластик серж пролетает такой пакет но такое поле то он пугается его парсить и говорит ну там анализатор ругается что ну длиннее 32 килобайта и отбрасывает его страну знать не было таких случаев еще ни разу нашого ну знаете спасибо за я мы с вами вообще отдельно еще побеседовал на эту тему удовольствием я вернусь так сказать я проверить где то что полезно спасибо поэтому вопрос из транспортира пожалуйста упреждением неотвратим короткий вопрос какой размер к живым хип 3d на но до халатика так ну выделяемые сейчас по 30 giga дата но там имеется в виду сейчас примерно 25 26 плавать как только начнет подбираться к 30 я тут же навтыкаю новых data not добрый день я вот хотел узнать вы говорили вы не хотите ставить себе на апликэйшен и java машину на потому что тяжеловесно и все такое но ваш паттерну отписать файлы и потом транспортировать хека у elastico есть файл бит вы не пользовались мы пробовали но почему-то у нас не взлетел у него есть все то же самое regexp он легковесный он не на яве он по моему на сена песчаные фильтры он умеет мы по какой-то припомню моего пробовали по какой-то причине у нас не взлетел мы решили вернуться к этой проблеме когда нам хека насчет сжать в плечах когда перестает справляться мы решили что вернемся к проблемы выбора человек но ты то есть по вашему паттерну единственно что здесь вместо вот этих транспортеров у вас появляются файл бит но а там лак стек конечно на ресиверах возможно но я говорю пока эта система справляется и у нее есть запас на будущее когда начнет не хватать мы думаю для вернемся к этот вопрос вот смотрите тут уже я подарил подискутировать уже потом такой формой давайте здравствуйте у меня такой вопрос авторы хикки в свое время говорили что у них вот этот горный regex процессор достаточно медленные они все мы рекомендовали писать на убеги на вот именно я вспомнили и я читал эту дискуссию в хватает вот этого процесса да но данный момент совершенно прекрасно модель я тоже была удивлена я тоже читал этот трек эпичный но вы пока возразить нечего все работает работает прекрасно по результатам теста вам по сочетанию соотношение производительность объему которая успевать переваривать regex по работают идеально практически парсится они да да они кашицы на стороне леса на стране сервисов и улетают уже упакованы в потапов разделенные по полям хватает мощности хватает до хватает спасибо у меня еще вопрос момент первый ряд то да еще на такой вопрос говорит что вы не можете позволить себе потерять никакие данные но как вы живёте с осознанием того что эластик search это в первую очередь available system и джобсон тесты доказывают что она теряет данная при препарате шинах и в том числе там при когда класс top100 это приходит из рейдов когда ноды выпадают у них есть целая статья эластик search как там она завелась и все archery зеленцы что такое обычно сложные вопросы прилетают с конца и так не знала ты то вот первый дал но то есть обычно туда ничего не кладут полезно и важно и потому что не консистентной там нет никаких не показав не рафтов это что туда улетела но если там будет прям сильно я против шона пар тишины то просто потеряется 50 конечно нет все части потрать поправили минус 55 5 ну даже в 55 мы вам все равно остаются проблемы как вы с этим жить тогда вот эти вот этим прекрасный живем на данные проблем у нас не возникало еще ни разу соответственно да мы храним важные данные но надо понимать что мы храним так недолго мы хотим 21 день с 20 на 21 дня они оттуда удаляются они нам не нужны ну и налог серверах лежат соответственно на эту цель проблема не стоит лишний раз завод год эксплуатации так вот слева да здравствую спасибо за доклад тема интересна очень жизненно для многих уме только вопрос о можете объяснить подробнее в зачем вот насладить которого показывали нужен был балансиры и еще один инсталляции хикки почему каждая клиентская хека не может стримит напрямую в lasix plaster зачем-то промежуточная напрямую в кластер то есть джейсона me ну а там тоже такая же яркая стоит или нет да ну вот представьте мы взяли у нас куча сервисов куча хек каждая собирает лог пластик принимает джейсон по http соответственно мы все этими джейсона мы начинаем стрелять представьте какой получится объем а сейчас у нас организована как хихикаете разбирают логик пакует их пар табов бинарных крайне компактный стреляет про табов у брелок коллектор не нужны для схлопывания логов попрад above a и для точнее как раз хлопнул ее спорта бафов джейсон и складывания власти к если имеется этот конец который ближе галактику она сбалансирована он принимает про табов расшифровывает и поэтому вас объем иначе был просто дикий ну представьте twitter насколько я помню когда переходил сохранение на потапов они отрапортовали 110 крат и кисти кратное получилось уменьшение объема хрипом тоже переходили какое-то время назад чего-то там мостом у власти кипром хранятся в порто баффи нет власти они хранятся в собственную цинского формате бинарном тоже это же компактным я сравнивал он не уступает круто баф у по компактности так а как они то пишется в ластик ведь он же на вход принимает тот же самый тут то есть сама операция записи вас конечно же выставляет раз новый интерфейс по которому вы в него пишите нет не так хека собрала лаги упаковал их пар табов но мы еще с вами пачками сразу по 5000 пролетела это через балансиры пришло на приемную hi-q там стоит input который слушает и себе он принял этот пакет из порталов развернув джейсон стрельнула ластик ластик это взял проиндексировал изложил в лице навский бинарной формат к себе на диске то есть вы минимизируете таким образом сетевые расходы до котировках ну и так 3 терабайта в просто баффи летает и представьте мы будем в джонсонами слать звучит разумно спасибо пожалуйста спасибо адель это было здорово"
}