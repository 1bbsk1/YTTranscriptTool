{
  "video_id": "LaShwTfAFms",
  "channel": "HighLoadChannel",
  "title": "«Отложенные данные» — наш механизм обеспечения консистентности / Андрей Литуненко (2ГИС)",
  "views": 850,
  "duration": 2834,
  "published": "2019-05-15T04:02:49-07:00",
  "text": "я работу адис вот уже два с половиной да я бы kinder в проекте лишь ник нету 1 гб вы от я пишу на php уже 6 лет последний год пишу нога лэнге вот кем я стал того как начал писать на коленке о чём я сегодня расскажу я расскажу о том что такое личный кабинет в одессе для чего он нужен и для чего нам получать данные от наших внутренних систем также расскажу какие у нас возникли проблемы при импорте и поделюсь нашим решением поднимите пожалуйста руку кто знает что такое личный кабинет 2гис отлично здорово вот 2 дес это получается онлайн справочник и веб-карты есть мобильное приложение и также есть личный кабинет для владельцев компании предположим что мы с вами владельцы компании со сколкова мы заходим свой личный кабинет и можем смотреть контактную информацию по компании можем редактировать и смотреть другие разделы чтобы нарисовать такой дашборд нам пришлось за интегрироваться с десятком внутренних систем давайте по порядку посмотрим зачем интегрировались первая возможность в личном кабинете это редактирование контактной информации то есть можно перейти в специальный раздел и редактировать и email и телефон и адрес сайта эти данные через некоторое время попадают потом в конечные продукты инфекцию в одессой и в мобильную версию чтобы получать эти данные мы за интегрировались со внутренней системой который называется организации через личный кабинет можно управлять адресом то есть можно изменять адрес можно менять вход организации изменять внутренне ориентир это такая гентис по которому вы можете найти организацию в здании чтобы получать эти данные мы заинтриговали системы биография то есть мы себе выкачиваем все справочные улице и адресов из нашей системы и кроме того система организации публикуют привязку адреса конкретной фильме если посмотреть на несколько на sql запрос на получение этих данных то мы сначала джонни мся на адрес проедешь нику а потом получаем название адреса через личный кабинет также можно управлять дополнительными атрибутами то есть в зависимости от и рубрика у компании могут быть разные услуги то есть если рубрика ресторан это можно указать дополнительные что есть бизнес-ланч указать стоимость бизнес-ланча средний чек если например у компании брюки спортивные залы то можно указать какие в ней есть спортивные секции эти данные мы получаем и системы атрибуты и также мы выкачиваем всех все справочники и привязку атрибутов как к организации также это все получается вот этим запросам кроме того через личный кабинет можно управлять рекламными кампаниями то есть можно купить рекламу можно смотреть какие в заказе есть услуги смотреть по ним статистику эти данные мы получаем еще из одной системы который называется заказа также через личный кабинет можно управлять рекламными материалами можно загрузить логотип и загрузить кнопку действия это такое ул на который будет направляться пользователь и нажать и в справочнике это может быть либо группа вконтакте либо сайт эти данные мы получаем системы материалы то есть там идет привязка материала к заказу и так это работает также есть данные для наших внутренних бизнес-процессов и положим то есть он у нас есть наши сотрудники мы автоматически регистрируем и выдаем доступ на чтение кремом в личном кабинете и в этой всей схеме очень легко запутаться и какие у нас возникли проблемы и импорте данных во первых зоопарк импортируемых данных вот как это не нарисовал часть наших данных то есть это из разных систем данные связаны между разными системами разные типы связи есть один ко многим многие ко многим и нам это все пошло себе выгружать также системы с разной скоростью публикуют свои данные они публиковали так либо новые данные либо изменение уже существующих как это выглядит то есть как будет не день у нас приходится примерно миллион изменений наших данных то есть и не выходной день очередь меньше то есть это примерно 100000 изменения приходят если взять ведь если взять день 8 1-го я у нас приходит более двух трех миллионов данных то есть видимо в этот день все владельцы бизнеса выходят с с отдыха с отпуска и начинает активно вносить правки в свои фирмы также есть такой процесс как выгрузка всех данных от систем то есть если мы на примере начинаем интеграцию с какой-то новые системы панамы система отсылает все данные и это может быть там более 10 миллионов записей то есть если сравнивать с будним дням то это такой получается охотно ровном месте по сути и нам необходимо учитывать такие разные перепады количество данных также между зависимостями между системами есть зависимости и шагать вернемся к схеме с нашими командами внутренними то есть например заказа не может быть без фирмы материала не может быть без заказа атрибутов не может быть без организации и нам это нужно все учитывать при импорте также вот самый такой неприятный самый болезненный пункт мы готовим и сломали немало копьев это то что данные могут выглядеть а без некоторых зависимости как это выглядит то есть предположим завели новую фирму нашем справочнике и для нее добавили атрибут бизнес-ланчи и данные отправляются на по какой-то причине мы не можем себе сохранить фильму то есть это может быть ошибка на нашей стороне либо также по какой-то причине мы можем то есть фирма может до нас дожить не доехать это проблема на стороне системой которая публик вы данные и вот непонятно что делать в итоге с атрибутом он получается консистентной принципе мы вам можем вставить но у него нет у фирмы и поэтому вставлять его нельзя ситуация напоминает если вы заказали велосипед в интернет-магазине но она вам пришел без колеса то есть что делать с велосипедом он в принципе как бы не стал пользоваться и очень сложно и непонятно что с ним делать так же после изменений формата публикуемых данных определенной системой необходима поддержка двух форматов как это работает предположим и система публикуют данные в определенном формате мы формата себя поддерживаем ну наш справочник растет появляются какие-то новые данные и система начинает публиковать данные в новой схеме то есть мы у себя этот эту схему поддержали все все отлично но есть момент в том что еще может быть и хвост не вычитанных данных вставай схеме и таким образом нужно нам нужна обратная совместимость между новым форматом и ставим форматом поднимите пожалуйста руку для кого актуальны такие проблемы которые я озвучил отлично сейчас я поделюсь с нашим решением как эти проблемы можно решить мы сделали 1 решения она у нас работала на php ну так и для нас было просто сподручнее потому что наша написан на php и мы не стали так тогда особо заморачиваться с какими-то более интересными языками программирования мы за интегрировались с корпоративной системы обмена сообщениями через эту систему наши сервиса обмениваются данными то есть это было самописная система сделана еще до того как мы остались ни добиваться то есть как она работает то есть есть система организации например и она публикует в свой лик стенки изменения которые происходят в фильме то есть есть определенный формат то есть изменяться ловиться через топи здесь видно что изменяется фирма изменяется контакт в их чинче есть настройка кто эти данные получают данный дальше растекаются в очереди систем и мы со своей стороны данные себе забираем аналогичным образом работают другие системы таким образом у нас получилось интеграция с большим количеством очередей данные мы получали по крону то есть у нас были параллельны и задачи которые запускаются раз в пять минут ходят в очередь опрашивают есть если какие-то новые для меня данные если есть то одна дай мне их я их обработку и обработаю и вставлю в базу и утешение самый неприятный проблемы по которой я говорю это как раз чтобы обеспечить consistent ность мы придумали механику заглушек то есть вернемся к примеру с бизнес-ланчем то есть нам прилетает бизнес-ланч атрибут аферман от которых он зависит еще нету то есть что мы делаем так наличие фирмы мы предлагаем по привязанному и дисней-клубе значит то есть мы смотрим если в таблице фильмы фильм с со связанным идиш ником то есть я нету создаем заглушку заглушка это получается записи таблицы фирм с айтишником которого еще нету пустым названием и флагом пулевым что это типа из чтоб этими данными еще нельзя пользоваться и значение true вставляем заглушку в нашу базу и после этого мы уже можем вставить бизнес-ланч потому что фильма появилась с нужным нам айтишником через некоторое время там может быть через минуту может быть через 10 минут можно через до нас доедет уже консистентная фирма мы обновим ее параметры и заглушка станет консистентной сущностью выглядит это примерно так то есть у нас велосипеда мы поставляем треугольное колесо и начинаем ним как-то пользоваться что мы научились делать хорошего в первой версии нашего от импорта мы научились работать с двумя слoны данных то есть мы в случае изменения формата мы не ломаем обратной совместимости со старой схеме то есть мы удалим неиспользуемые колонки не делаем поля обязательными и удаляем таблице мы получается если нам нужно удалить неиспользуемые поле то мы это делаем потом отдельные задачи когда уже наверняка знаем что данный ставим поймать им не будут точно публиковаться но в остальном мы гребли кучу новых проблем таких как ошибка одновременной вставки заглушки и валютных данных то есть обработчик атрибутов смотрит что то есть бизнес-ланчи нету фильмы создает заглушку в базе при этом параллельный поток обработки фильм тоже этом мире нам помогать им нам прилетает на самой фильма который разом бизнес-ланчи он смотрит что еще момент обработки бизнес-ланча не было пытается ее вставить и получает ошибку что данные с таким мальчишник им уже есть то есть уже была создана заглушка и быть ошибки были на бою и чтобы их избежать мы сделали синхронный запуск всех наших команд по обработке данных и систем то есть сначала команда по обработке организации ходит в свою очередь забирает из нее сообщения и вставляют в базу дальше команда по обработке атрибутов идет в свою очередь и забирает из нее данные и уже потом команда по обработке географии поставляет данные свою таблицу своей очереди таким образом все команды запускаются синхронно и возникает такая проблема что если данных выгружается там более восьми миллионов это как я говорю там в случае если там идет какая-то выгрузка данных от системы всех то получается потоки который обрабатывают меньше всего данных они начинают тормозить и данные от них приезжают несправедливо долго то есть там нет там допустим им всего выгрузилась ты сейчас записи там и эти данные будут долго доезжать это несправедливо к таким потоком и выгрузки всех данных доставляли массу боли потому что наши шине в нашей системе обмена сообщениями не было механики выгрузить данные только определенным команде то есть все данные сразу попадали всем командам кто подписан на эти сообщения и это могло вызвать какие-то проблемы на стороне принимаешь то есть они могли быть просто не готовы к таким объемом данных и плюс ко всему на моей памяти были такие кого вы релизы что когда мы начинали интеграцию систем и географии то нам нужно было себе выглядеть примерно 20 30 миллионов данных то есть если мы это получает через нашу систему обмена сообщениями то у нас бы примерно две недели бы данные медленно обрабатывались и при этом ничего другого мы бы не могли обрабатывать то есть нам приходилось таком в полу ручном режиме запрашивать отключение нас от всех потоков нам скидывали csv файлы которые мы по силе и вставляли в нашу базу это все было очень грустно нам хотелось избавиться от ручная какой-то отличной работы при импорте и мы решили сделать новую версию нашего импорта решение 20 первые что мы переделали это работу заглушками то есть мы назвали механику отложенные данные как это работает то есть предположим нам опять же полетает бизнес-ланчем без фирмы мы не создаем заглушку на film.ua складываем бизнес-ланч специальную таблицу отложенных данных в этой таблицы указывается информация о том какой она предела сущность в данном случае это полетают атрибута указываются параметры которые мы получили от системы то есть тип значения и какой фильм nikon привязан дел отдельно указывается массив аллей подготовил не прошли зависимости в данном случае это фильма и также указывается дата создания записи возложенных данных после того как мы вставили данные и после получения данных от систем мы начинаем обработку от ложных данных то есть мы получаем все отложенные записи находим поехать неразрешенным зависимостям зависимости могут быть там фирмы заказы адреса и это у нас все хранится ну то есть все виды зависимости хранятся в коде и также правило как эти зависимости разрешить то есть предположим зависимость было фильма мы проверяем выгрузили фильмов с таким айтишником то есть появилась ли она в нашей таблице если она появилась там и удаляем записи из отложенных данных и вставляем ее в боевую таблицу атрибутов если если фирма не появилась там и отложенной записи удаляем и она будет снова потом проходить тест не все зависимости если зависимости и более 1 то необходимо чтобы данные появились по каждой из зависимости если хотя бы по одной зависимости данные не пришли то мы считаем что отложенная запись еще и консистентная ее нельзя вставлять и она будет потом еще проверяться также мы добавили модификации о залежавшихся сложенных данных то есть как это работает мы отдельным процессом который запускается раз в сутки смотрим сколько у нас всего записей похоже он их данных то есть итогам больше суток если их если такие записи есть то мы считаем что что-то пошло не так в нашей обработки данных и отсылаем письмо на командную почту такая казалось бы простая механика помогла нам найти проблемы как на нашей стороне так и на стороне и внешних систем на своей стороне мы нашли что мы импортировали себе не все данные и таким образом никогда не разрешились бы зависимости на стороне внешней командой мы нашли что нам система присылала не консистентные не валидные данные и ребята потом это поправили и проблема ушла и в качестве решения проблемы с игрушками чтобы сделать только для для своей системы мы за использовали апачи кафку у нас есть отдельно топике со всеми благами изменений то есть получается 1 не стали полностью отказываться от нашей старой очереди написали с помощью своего каком к коннектор соединение составе очереди и наше решение перекладывают сообщений из очереди миф кафку в соответствующем топике то есть в отдельно топика фирм отдельно в топик адресов то есть это все зависит от то есть система которые публикуют данные таких топиках хранятся все блоги изменений то есть топике состоят из партиции как известно вот и получается что здесь хранятся в силлогизме не то есть ли там создание новые фильмы изменения новой фирмы такие влоги у нас хранятся один год потому что они немного они тяжелый и ханнити бесконечно мы не можем также есть компакты топики с актуальным состоянием сущности у нас есть отдельный процесс который производит дедупликации у него топиков со всеми благами изменений и и складывает данные по идиш нику то есть как это выглядит у нас есть получается партиции в этих домиках и в них сохраняются только последнее состояние сущности в таких топиках нет то ограничения на хранение данных потому что они занимают значительно много значительно меньше места и плюс по таким топиком очень удобно делать полную перевыпуск данных то есть мы просто берем переключаем partition or set начала данных для своего консью мега и вычитываем данные самого начала то есть если нам приходит задача что нам нужно выгрузить новое поле которая публиковалась раньше и мы по какой-то причине себе его не сохраняли но мы просто при качаем на начало и вычитываем потопали только для своего потребителя и при этом никакие внешние сервисы не будут страдать от полные перри выгрузки данных также мы переписали наши импорт на гол янг и сделали его асинхронном то есть у нас разные обработчики данных от разных систем запускаются параллельно и никак между собой не зависят если всю схему нашего приложения то она выглядит вот таким вот образом то есть есть наша корпоративная система обмена сообщениями есть кафка в которой прикладываются из этой системы сообщения есть наше приложение это импорт который вставляет либо боевые данные либо отложенные записи и также есть модификатор который проходит по отложенным данным и в случае каких то проблем уведомляет нашу команду мы сделали это решение заметили что она мы приносили все мы приносили весь код по сути как есть и заметили то есть и делов его только на асинхронность новый язык и кафку издатель что у нас есть еще куда стремиться ускорение импорта мы сделали тюнинг то есть ставим пакта нас мог обрабатывать миллион сообщение в сутки новый импорта то есть мы принесли новый импорт также вставим импорте у нас данные вставлялись одиночными insert то есть нам пришла новая фирма мы вставляем фильму пришла счетного фильмов вставляем также ее отдельным инсектам вот и новые мы пригласили приносили с такой же механикой и у нас получилось что мы можем обрабатывать два миллиона записи но нам этого было мало потому что все равно большие перегрузки нас сильно бы конфликте ли и мы сначала сделали вставки данных через копия есть у нас база postgres она умеет вставлять массив данных моя команда копия если у вас какая-то другая база и там нету команда капитала в минске можно сделать можно воспользоваться командой балкан сердце такая оптимизация позволило нам увеличить количество сообщений в сутки до 4 миллионов но всего этого было еще мало пока и мы решили что мы удалим наших таблицах все внешние ключи да это было осознанное решение потому что наших данных обеспечивается только нашим приложением и других источников поступления данных нету скорость увеличилась до семи с половиной миллионов сообщений в сутки также мы провели оптимизацию кода то есть мы его версии нашего гулан голлинг импорта у нас было валидация exedy схем и как система показалось при обработке каждого сообщения мы сделали что оно подгружается лениво то есть если схемы в кэше нету там и и загружаем и потом при обработке новых сообщений я просто перри используем также мы когда начинали разработку мы использовали библиотеку либо вода кафка которая подключается к кафке это у нас была версия 010 вот и она в не были проблемы с утечкой памяти мы обновили и и до версии 011 4 в этой версии как раз были исправлены проблемы с печкой памяти и наше приложение перестало течь по памяти так же мы сначала использовали тему зима есть с кафкой полинг то есть мы там отправили отправлялись запросом к паковку если данных не было по нам тут же возвращались пустой массив мы переделали взаимодействием на long polling то есть мы отсылаем запросов клиент некоторое время ждет получении новых данных если по ней эстонии нам приходят и какие сми зации кода позволили а также еще в в кафки после прочтения сообщений необходимо отметить опцию нашем случае мы его тоните мы в закипит есть специальный топик с цветами и мы его изначально к метели в после прочтения каждого сообщения это было долго операции и мы решили что будем томить после прочтения какой-то пашки сообщения мы остановились на 500 сообщениях и организации с кодом нам помогли ускорить наш импорт до обработки восьми с половиной миллионов сообщений в сутки то есть выгрузки данных готовы там были 8 января мы их стали обрабатывать сутки это было отлично то есть наш велосипед теперь получил нормальное такое колесо чтобы я хотел сказать в качестве вывода то есть 1 если вы добьетесь с большим количеством внутренних систем то сначала нарисуйте зависимость из своих данных то есть это можно сделать просто от руки нарисовать либо состав можно сделать в поимке либо какой-либо специальной специальной программе например где это как раз первый шаг к тому чтобы реализовать механику отложенных данных используйте отложенные данные в том для того чтобы отделять мух от котлет то есть если у вас есть если для вас важно показывать пользователям консистентные данные он не консистентные данные то вы можете сделать разделение на полные и неполные данные кожаные записи при этом хранить отдельно если же для вас это не принципиальные и вы можете себе позволить показывать неполный данные своим клиентам то отложены данные вам здесь не подойдет нашей механика также реализуйте поддержку стога война форматов то есть моменты где лиза момент изменения формата общения между системами вас может быть какой-то хвост из не вычитает из не вычитанных старых сообщений и необходимо эти сообщения также обрабатывать как и новые сообщения и подумайте как делать при выгрузке данных без рисков положить все ваши внутренние системы в нашем случае нам помогла кафка то есть мы просто если нам какое-то поле нужно вычитать мы переключаем начала сначала все тов выключаем начала птицы и вычитываем данные только для своего консьюмер при этом внешние команды никак от этого не страдают и также запускаете обработчики данных асинхронной и независимо друг от друга мы здесь используем голлинг и у нас данные обрабатываются параллельно и независимо друг от друга спасибо за внимание ваши вопросы а микрофоны а можно голосом пожалуйста или я могу продублировать вот у меня такой вопрос а вы сказали что отказались от внешних ключей это осознанное решение было и как то вот у нас есть части похожая ситуация и психологически отказываться от внешних ключей некомфортно то есть первый вопрос возникло ли какая-то на практике ситуация когда вы например что-то не учли и все-таки в какой-то момент где так где-то что-то дало сбой то есть именно с консистентной данных и второй вопрос приводили в начале статистику о том что у вас примерно полтора миллиона записей в сутки вставляется и вот отказавшись от внешних ключей вы увеличили производительность четырех с половиной миллионов до 7 по моему то есть это просто запасом вы сделали то есть как бы вот папой тобу или я просто не так что-то понял то есть это 100 стоило ли от них отказываться если у вас 1 есть запас по количеству сообщений спасибо спасибо спасибо за вопросы то есть ответ на первый вопрос то есть у нас на практике не было таких ситуаций что у нас сломалось эти стены то есть мы приносили все просили получается аккуратный то есть и все как бы тысяч ли здесь у нас не было такого что у нас что то сломалось бы в итоге то есть здесь было все хорошо второй вопрос это по поводу того что да внешние ключи есть как я уже говорил у нас бывали большие при выгрузке данных и нам хотелось так чтобы такие выгрузки ну мы за сутки там максимум за двое обрабатывали то есть ситуации с смешными ключами то есть это бы у нас обработка заняло бы много времени и нам хотелось время время получается сделать быстрее и как раз мы решили что от них откажемся и тем самым ускорим время мне вопрос возникали ли у вас ситуации зацикливания что у вас есть сущность а сущность б сущность c вас приходит сырые данные до неполные сущности а ну верни так приходит вы начинаете праве она зависит осуществи б вы проверяете ее нет потом приходит сущность б вы проверяете у неё зависимости от сущности целью нет потом приходит сущность c который имеет зависимость настюша настя и таким образом круг замкнулся и вы не загрузите такие данные вот за счет того что вы отказались от треугольного колеса когда вы вставляете неполные данные спасибо за вопрос но такая ситуация то есть мы просто похожи на данные положим три разных сущности они будут там находиться получается до тех пор пока по всем не появится не будут разрешены зависимости и здесь я такой проблемы лежит испании могут там находиться какое-то время могут там часто много честных находиться но по ним все равно как бы рано или поздно придут зависимости но какой-то момент и потом мы просто найдем то есть все ли зависимости разрешились если да то вставим в базу если бы не будет более суток лежать то нам придет оповещение что что-то пошло не так в нашей обработки и но уже с этим случаем будем отдельно разбираться и и просматривать но я думаю что такой остался мы разрешим после того как нам придет модификация то есть потом что данных не хватает это то есть их много и мы уже будем с ней вы в индивидуальном порядке разбираться что там почему так так получилось до 1 раз спасибо за доклад мак тяги к посетив гарри оставишь по спасибо скажите если у вас подложенные данные пришли пришла цепочка зависимых сущностей и потом когда появилась эта сущность от которой они все зависели по сути то есть они друг за другом такая очередь и они оказались в отложенных данных и пришла уже допустим та же фирма сразу вся пачка этих зависимых сущностей попадет в мастер базу или только лишь одна из них а следующие на при следующей обработки отложенных цепочка вся то есть рекурсивно будет обработано когда и втором россии залежавшиеся данные какие-то лежат очень долго и получать что фирма не придет никогда потерялась навсегда вообще как как-то обрабатывается что происходит с отложенными данными да я там приводил что у вас есть модификации о том что данный более суток лежат то есть если так приходит такое сообщение там мы потом с этой фирмы уже в индивидуальном порядке разбираемся что с ней было не так почему какие-то зависимости по ней к нам не пришли может ли получиться так что данные есть отложенные но непонятно кому они принадлежат ее с кем связываться нет такого не может быть у нас мы знаем четко от кого мы получаем то есть там все типа у нас зафиксированные знаем какая команда эти данные пасе бликуют спасибо за доклад такой вопрос по сказали хранить год логе изменений да где это хранится то есть как-то пропущен ну так у нас и так хранится в кафе по тесту у нас в кафе кафки есть топите с этими блогами изменений они там хранятся то есть яд тонкости хранения не знают испытать дело как с нас отдельная инфраструктурная команда этим занималось тем как сделаете хранение данных листами есть там там есть целый класс этом то есть там путь язык есть пластик там в нем три ноты и там это все вектор храниться после коми до 500 сообщений они то есть остаются пк of да то есть у нас получается что изменение мы к митинг просто избегаем свой а все то есть сообщение почитали и при этом они из кафки эти данные не как после нашего почти не не удаляются очищается как кафка но через год честно даже на расскажи нам что на какой то есть отдельный процесс и сделали тоже ребята из запроса тонной команды чтобы понимать и данный как-то вычищают если вам интересно можете мне написать и я узнаю не ходи вам отвечу спасибо раз есть такой вопрос а одна из причин почему первая версия была неподходящая было то что локо эта проблема с конкурентным конкретной вставкой вот этих вот граф данных и настоящих данных можете пояснить момент потому что я не очень понял в чем проблема конкор нэнси потому что она выглядит как очень простое решение пришел какой-то одни пытаются ставить другие уже вижу что это есть мы кидаем контекс action ретро и мы все там разрулим уже на следующем этапе почему нельзя было дойти бы такой простой механики чем-то была проблема спасибо за вопрос то есть у нас так получалось то есть до в одном потоке прилетает там как я говорю без достаточно фильма нету мы в это время создаем заглушку а параллельно у нас получается вставляются валидные данные и вот весь код он был покрыт такими это те чьи имена то есть мы вставили к будем второй раз ставите то есть если прошло то все ок но это такой код было получается сложно поддерживать непонятно было там какой момент эта конкретность возникает и как с ним итоге бороться то есть ip и плюс нам хотелось сделать чтобы impact был настоящему асинхронным и многопоточном то есть чтобы данные а мы пытались независимо данные разных систем обрабатывались независимо друг от друга то есть что было что было многопоточность вот и она бы точно решение много получается медленным и долгим в работе и не устраивало нас по скорости гостя спасибо за доклад очень интересно хотел спросить и вот увожу микро сервисная архитектура то есть из предыдущих докладом не слышал вы рассказывали сейчас про внешние источники вот вы собираете данные и они там могут быть задержкой там час-два день для вас это нигде не очень а кто был не очень критично а допустим у вас наверное есть какие нить и агрегируются и микро сервисы грубо говоря которые собирают есть один микро сервис микро сервис отчетов или в нашем случае мы его называем микро сервис гриб который собирает информацию из разных микро сервисов вот и и и там должна быть информация не задержкой там в час два а максимум там пять секунд и даже лучше секунды вот с такими проблемами ну вы не сталкивались и вообще интересно как у вас если такие агрегируются микры серые вы допустим как вы выводите как он тесть grid информационной до которая содержит информацию не из одного микро сервиса там а из пяти десяти как вы решаете такие задачи вроде примерно по теме вопрос да спасибо за просмот по сути как раз наш личный тебя нет является таким вот агрегировать чем сервисом то есть мы себе получаем данные из наших сервисов внутренних и показываем там пользователю разные там разделы в личном кабинете вот других сервисов в которых бы как раз так информация была ну есть там отчеты по фирмам если мой отчет и там для менеджер по продажам ну у них там намного меньше зависимости то есть нет такого как у нас там что то есть у них там может быть и одна внешняя системы тагирова и то есть и все есть и такой проблемы что блага сервисов у них там нету ген на ваш способ ответил понятно хорошо спасибо за доклад такой вопрос а вы пробовали на лету запрашивать у сервисов то есть не импортировать данные например запрашивать напрямую на лету вот пробовать пробыли хотя такие вещи у нас то есть и вы имеете ввиду что данные себе в базу не сохранять запрашивать запросите сервис очень быстрый он быстро круто дает актуальные данные то есть прямо просто у него и запрашивать это было бы идеальное решение но фишка в том что у нас есть там выгрузки то есть мы там допустим джон там таблицы из одного сервиса потом же они на данный другого сервиса делаем это просто из келим ну нам так удобнее там это привычнее и у нас то есть все хроматид это делаю это slim запроса там то есть делают и аналитики и падут менеджеры и проджект-менеджеры то есть это так удобнее кришна для всех команде здравствуйте за доклад иван компонент форма у меня один может быть простой вы упоминали что вас есть кое-то централизованная система для обмена сообщениями в компании с которого интегрируясь первый раз просто стало интересно что за на докопаешься звучит как будто эта кафка потому сколь но мы добавили к эта система была написана нашими разработчиками это было нашим уже лет восемь назад там 10 то есть когда еще кафки не было в этом мире вот и нужно будет как-то построить взаимодействие между системами вот ребята сделали свою собственную сам описаны машину интеграции вот там она через я стапель работает там отсылается запрос потом также известны можно получить данные для своего для своей системы ясно спасибо еще подскажите вы упоминали что время от времени во дела теперь и выгрузку данных там сбрасываться в сытой на начало компактно этого топика а ну что еще вы делаете когда сделать перезагрузку там какие-то данные может удаляется или ну вообще вот ну любой какая то операция дополнительная ну мы получается переключаем up set начала да и в принципе кажется большим шенген ты наш барабанщик и запускает сын начинает данные все вычитывать и нам базу складывать из принципе тут никаких махинаций с нашей со стороны больше не требуется ясно спас больше здравствуйте спасибо за доклад вопрос такое как обрабатываются отложенные данные то есть у вас крону скрипт какой то есть или событию что-то происходит непонятно вот этот момент данные обрабатываются после того как мы получаем данные из внешней системы то есть мы сообщение от внешней системы обработали из excel уже после завершения обработки запускается обработка важных данных то есть получается сразу же то есть у нас там она не покрыта раз сейчас допустим это на газ минуту запускается as a сразу же после завершения чтения события a theater system там еще есть от мужчина вопрос 1 раз спасибо за доклад вопрос следующий я правильно понимаю что все ваши внешние серы откуда вы получаете данные то вашей сервисы они ходят в свои собственные базы данных да так и они бросили почему почему они ходят в raw собственной базы данных не проще ли все слить в единое целое и все ходит в одну базу данных но каждым таблицам и тогда ну соответственно вся ваша работа будет ну не нужно там уже все это будет слит а так не дешевле ли будет у нас получается у разных сервисов могут быть даже разные база данных то есть допустим погодного сервиса там база под газ там у другого сервиса и мы склеили вот и получается что в таком случае нужно будет как-то команды принуждать к тому что вы там все пользуются мозга самым местами раз келли но это как бы на 6 путь из ну то есть мы как бы за то чтобы разработчики делали на том чем приятно то есть ну и плюс ко всему в схеме с одной база данных это сложно будет поддерживать изменение формате то есть допустим если система какое-то новое поле добавляет топ она это делает хочется уже в тот же момент и всем нужно быть уже к этому моменту готовыми то есть что там новое поле появляется и его необходимо обрабатывать в случае с разными базами данных мы можем просто у себя схему валидации изменить то что там это поле будет приходить и никак с этим полем не работать то есть сразу же"
}