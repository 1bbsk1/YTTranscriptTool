{
  "video_id": "lsgLDsp1YhM",
  "channel": "HighLoadChannel",
  "title": "Отказоустойчивая архитектура фронтальной системы банка / Р.Шеховцов, А.Громатчиков",
  "views": 1339,
  "duration": 2814,
  "published": "2018-08-16T04:45:48-07:00",
  "text": "добрый день меня зовут роман шевцов моего коллегу алексей гра мальчиков мы работаем сбербанк технологии где отвечаем за архитектуру единой фронтальной системы и сегодня мы расскажем о том как обеспечивается отказоустойчивость систем банк прим службы 100 миллионов клиентов поднимите руку кто пользуется сервисом сбербанка о спасибо на самом деле пульс все даже те кто не подняли потому что есть случаи когда это происходит я потом расскажу как то получается собственно мы рассказываем например имеющихся нас решений в первую очередь сбербанк онлайн но на самом деле неважно сколько у вас клиентов и какая система если вы будете следовать трем основным принципом о которых мы расскажем то не только достигнете отказоустойчивостью но также сможете обслуживать своих клиентов даже тогда когда ваш сервис и не работает небольшая вводная как устроен банк в банке есть фронт-офис это система которая выполняет обслуживание клиентов в банке также есть middle office эта система принятия решений и оценки рисков скоринг принятие решения по кредитам анти мошенничества и так далее и есть буква с которым исполняется операций ведется бухгалтерией касается процента наша тема это фронт что же такое фронтальная система это высокое нагруженное приложение которое отвечает за предоставление сервисов балка в одном либо нескольких каналах обслуживание примера каналов обслуживания видите на слайде это мог бы быть интернет-банк мобильный банк сайт отделения всего около 20 каналов и в каких каналах непосредственными пользователей системы является клиенты банка а в каких-то его сотрудники здесь важно не путать до клиента сотрудники здесь важно не путать фронтальную систему с антентом фронтальной систем и у каждой есть свой front and back and свои базы данных но не все так просто типа выньте ландшафт крупного банка это сотни систем каждый из которых имеет свой уровень надежности доступности свой солей при этом все они связаны огромным количеством интеграций как же обеспечить обслуживание клиента в таких условиях также как подводной лодки у подводные лодки есть три важных свойства 1 у нее есть отсеки независимо если один отсек затопил остальные продолжает работать 2 в подводной лодке используя зиры некритичных компонентов двигателей баллонов с кислородом перископов тоже и третье свойство это автономность подводная лодка может уйти на глубину и работать независимости от того что происходит во внешнем мире давайте рассмотрим каждое из этих свойств подробно почему мы говорим о независимых отсеках почему не взять распределенную систему которая обладает внутренне отказоустойчивостью и не используйте ее был у нас такой случай 1 природе киш с тремя управляющими узлами и каким-то количеством зло с данными работал под нагрузкой факта репликации был тренд для данных и один из вас данным упал казалось бы дело житейское действительно контроль red обнаружили и мин серую процедуру ли балансировки данных с целью обеспечить за данный фактор аппликации пошла ри балансировка подскочила сетевая нагрузка начали теряться пакеты начали теряться узлы вот так и через несколько минут разделенный кеш упал целиком усугубляло ситуацию то что был совершенно неочевидно по симптомам что же происходит и довольно много времени админы потратили на выяснение причин к счастью все это происходило время на груше на тестирование никто не пострадал но осадочек остался а вот доктор хаус он нам говорит что падает все все ломается посмотрите в эти пойму полные боли глаза действительно так и есть были другие случаи когда падали целиком класс рисованые базы данных падали супер звериный внутри хайн сервера причины каждый раз были разные это мог быть баку управляющим по могла быть проблема в железе человеческий фактор и каждый раз проблема решалась и каждый раз осадочек оставался таким образом пришли к выводу что не падает целиком то что не является единым целым то есть не связан с зависимостями в первую очередь по управлению так появилась многомощно я архитектура в которой все железо intent начиная с веб-серверов и заканчивайте раме приложений и базами данных разделенными независимые блоки каждый блок обслуживать часть пользователей и любые проблем в одном из блоков никак не эффект от оставшиеся здесь возникает несколько вопросов первый как же мы распределяем пользователи между блоками 2 как мы обеспечим отказоустойчивость внутри блока и 3 что мы делаем если блок все-таки отказал об этом расскажет алексей добрый день всем присутствующим всем наблюдающим за нами по видеотрансляции ну и соответственно давайте рассмотрим какие же возможно отказов блоках как в любой системе отказы возможно конечно на любом уровне начиная от железы заканчивать человеческим фактором относительно блока можно рассмотреть такие уровни соответственно отказ не критичного компонента ну как видно на схеме отказ от такого компонента никак не влияет на доступности работа способность систему обслуживания клиентов возможно сбой в единой точки отказа что за собой учет естественно отказ блока возможен отказ также площадке то есть сода где размещается компонент системы возможно коллапс системы допустим на большом потоке данных как у нас даже зависание одного сервера ой очередей gms приводит к тому что пол и потоков на сервер положение уже через минуту будут все исчерпан весь пул и все потоки будут висеть в ожидании ответа из очереди джем с соответственно система также дальше не сможет продолжить обслуживание клиентов ну и конечно не исключаем человеческий фактор так называемый выстрел в ногу если прошло неудачно внедрение версии либо неудачно применили параметры сконфигурировали систему соответственно когда опять же приходят парни делают свой работы нам надо как-то продолжать обслуживать клиентов как же мы это делаем давайте изначально посмотрим на организацию системы организацию блоков у нас есть выделенный пилотный блог где мы проводим пилотирование новых версий плотно боке конечно в наши наши случае это находится в первую очередь сотрудники банка то есть лояльные клиенты банка ну и возможно присутствие добровольцев таких которых набирает банк с помощью опросов соцсетях кто желает первым получать изменения участвовать в тестировании систему в системе имеется три основных блока где живут основные клиенты банка гостевой блог где обслуживаются не клиенты банка то есть люди не имеющих да по продуктов на текущий момент и резервный блок на текущий момент он один по объему он равен примерно двум основным блоком и в штатном режиме работа не используется ждет своего времени в каждом блоке наш тем на текущий момент активных клиентов по 10 миллионов они с постоянной привязки также в каждом блоке изолированы все каналы обслуживания в данном случае в этой схеме the web мобильное приложение банкоматы для того чтобы они не влияли на работу друг друга и на текущий момент а три тысячи серверов расположенных в 300 таким образом давайте рассмотрим как же попадает клиент вообще в систему свой родной блок где он живет на постоянной основе есть выделен компанит мышцы это тоже некоторый блок системы этот блок выполняет функцию шарди рования на текущий момент функция шарди рования у нас табличная по ней определяется блог пользователя таким образом сначала клиент обращается клиент может в компонент маршрутизации и дальше переходит в свой блог с помощью redirect а если вдруг в блоке что-то пошло не так либо отказал серы приложения которому работал пользователь либо отказал весь блок ну какой-то сбой пользователя пойдем обратиться еще раз как об этом htc kombat марш наций также зарезервирован есть его холодный резерв то есть бог который не используется в обычном штатном режиме но может быть прозрачно подменил для клиента и клиент также получит свою марте режущую информацию если в блоке проблем было именно серым приложить либо как небольшая проблема клиент будет отправлен еще раз свой блог если же все таки проблемы с блоком более серьезно это будет определён резервный блок в резервном блоки клиент также сможет получить все услуги все сервисы банка для того чтобы это было возможно у нас пользуется архивная база в этой активной базе nnov накапливается все данные по всем операциям клиентов для того чтобы раз в резервном боке клиент мог увидеть все свои операции допустим провести повтор некоторых из них ну или какие-то ещё дополнить услуги получить эта база наполняется в постоянном режиме с помощью асинхронной репликации прикладной из всех блоков системы для того чтобы иметь консистентных данных в родных блоков с тем когда клиент вернется также реализована прикладная репликация из резервного блока по родным блоков блоком клиента прикладная репликация будет отставать конечно будет так а иногда возможно будет notification клиент с помощью там баннер еще что что на текущий момент вы видите неполной истории операции но мы не считаем это каким-то критическим моментом просто время некомпетентность данных это не ограничивает клиентов выполнение его операций на текущий момент и также переход в резервный блок у нас выполняется за 1 секунду всего и есть два режима принудительной и плановый в плановом режиме допустим крана надо выполнить какие-то технические работы в блоке мы можем оставить всех клиентов которые успели открыть сессию в блоке дорабатывать этом блоке на текущий момент в сбербанке онлайн средние время сессии жизни сессии то пять-десять минут соответствие мы можем подождать 5 10 минут естественным образом все клиенты сами будут из блока новые все эти уже будут открываться в резервном блоки что плавно переводит нагрузку с одного бока на другой при этом и есть принудительный режим соответственно когда нам надо все-таки моментально вывести всех пользователей сбоку и отправить в резервный мы можем разорвать просто все сессии клиентские тогда клиенты идут на компонент марш наций и опять же попадает в резервный блок то что касается отказа площадки для того чтобы иметь возможность отказа площадке обслужить этот уровень отказа корректно как и все остальные мы конечно гиа резервируем и компоненты блоков и базы данных и резервный блок и архивный базах соответственно все компоненты располагаются как минимум на двух площадках при этом надо располагать компоненты равномерно чтобы в случае отказа мы могли всех клиентов данного блока обслужить в рамках одной площадке оставшиеся то что касается базы данных до надо отметить что в данном случае это уже будет 4n резерв с учетом наличие резервного блока в нашей системе базы данных мы резервируем по схеме актив пассив то есть имеем холодный резерв для каждой базы данных копируется данные с помощью средствами схд с использованием high-end массивов с использованием оптоволоконных каналу связи между площадками достаточно дорогая схему конечно получается но за счет этого буквально за пару минут мы можем поднять вернуть работоспособность базе данных несколько терабайт бывает до двух десятков терабайт базы в нашей системе конечно надо сказать что отказ площадке допустим в этом случае может привести к тому что на какое-то время станет недоступна база данных таком случае перевод копии базы данных выполняется допустим где сказал в течение двух минут там до двух минут соответственно клиентов мы переведём на резервный блок на это время потом вернем и для того чтобы минимизировать влияние отказаться да на систему целиком мы располагаем активной и пассивной копии баз данных в шахматном порядке соответственно мы таким образом снижаем влиять на систему в целом при отказе им площадке также немаловажно имеет немало важность имеет план тиражирования новых версии нового функционала как я сказала у нас есть пилотный блок в этом пилотном блоки допустим ч недели отстаивать в новой версии для внедрения новой версии используется опять же перевод на резервный блок версия отстаивается через неделю если все хорошо знаешь мы продолжаем тиражирование если мы понимаем что эта версия лучше откатить то опять же используем перевод на резервный контур откатом версию останавливаемся предыдущем соответственно пилотируя на лояльных клиентов плюс при установке версии в блоке тогда все хорошо так же функционал становится не по умолчанию доступен всем он тиражируется по группам клиентов соответственно таким образом достигаем плавного увеличения нагрузки и так же плавно ввода функционала но обычно это случается с допустим совмещая интересы бизнеса то есть на каких группы клиентов мы это размещаем пилотируем и доступность первую очередь обеспечиваем и если все хорошо в последнюю очередь мы обновляем также резервный блок при этом весь функционал мы обеспечиваем рубильниками так называем то есть если опять же что-то пошло не так с конкретной функции то мы имеем возможность воздаем это возможно предоставляем администратору просто какое-то время отключить одну отдельно там бизнес функцию для того чтобы иметь возможность разобраться в дальнейшем и либо пофиксить какую-то причину либо либо просто опять дать возможность пользоваться пользователям дальнейшем соответственно таким образом мы с вами рассмотрели как обеспечиваем отказоустойчивость в рамках нашей системы но надо понимать что ландшафт банка он сложный опять же как роман показывал это большое количество интеграции всей системы живут соответственно в режиме взаимодействием с тем и как в этом случае обеспечивает отказоустойчивость сейчас подробно расскажет роман спасибо итак мы разобрались как обеспечить внутренний отказоустойчивость за счет разделения системы на части и деревья на всех уровнях но что делать когда для выполнения операции нужно пойти в другую систему которая не настолько надежно который может упасть целиком есть три механизм который позволяет этим справиться первый это буферизации отложены выполнение операций когда пользователь хочет совершить какую-то операцию например выполнить платеж мы сохраняем эту операцию себя в базе данных как черновик и дальше если внешняя система в которой она исполняется недоступна мы возвращаем пользователю статус операцию принтах исполнения и находится в обработке когда внешней системы все же поднимаются отдельно стоящие приложений докладчик вычитывает незавершённой операции с базы данных основываясь на маркерной таблицы и догоняет их пачками во внешнюю систему маркерные таблице это просто список 1 ников незавершенных операции она нужна для того чтобы не грузить основную таблицы с истории операции запросами с низкой селективностью то есть по ещё не завершён операциям их очень мало и до кад операций ведется пачками с паузами для того чтобы не уронить только что поднявшуюся внешнюю систему нашими сотнями тысяч отложенных операций здесь также используется два наверняка со для обеспечения целостности данных мы проверяем операцию при сохранении внешней системы проверяет при исполнении таким образом если что-то за прошедшее время поменялось операция будет отклонено по отклонены операции клиенты увидят либо уведомления либо увидит это в истории операций и сможет с этим что то предпринять второй механизм такеши рование рассмотрим кэширование профиле клиента когда пользователь входит систему запрашивается его профиль профиль состоят из данных самого клиента этого фильма паспортные данные и из информация его продуктов счетах картах кредитах это все запрашивается одним запросом который потом композитный сервис разбрасывает на несколько систем если этот запрос ответил за короткое время то мы показываем данные клиенту и также сохраняю в нашей базе данных в качестве пир системного кэша с определенным временем жизни если внешней системы за короткое время не успела ответить то мы показываем киши рваные данные и если внешней системы спустя какое-то время все же ответила то это также асинхронно обрабатывается мы обновляем кэш и опять показываем клиента данные вы могли это видеть изредка пользу сбербанк онлайн когда заходишь систему крутится несколько вот колесико потом показаться данная ваших счетах и остатках возможно не очень актуальны и через несколько секунд эти лена обновляется до актуальной также использовать кэширование с помощью репликации либо этель это нужно для справочников которые необходимы для ввода операции например для ввода платежа нам нужны справочник поставщиков услуг справочнике реквизитов платежей куча справочников если мы заранее к себе от реплицирует то можем позволить ввести клиенту данные сохранить операции этим самым предоставим сервис даже в тот момент когда система в которой эти данные ведутся не работает и третий механизм это технические перерывы если внешняя система упала либо если в ней ведутся какие-то плановой работы там у нее вставляется технический перерыв в этом режиме запрос от внешней системе не ходят используются описанный механизм кеширования буферизации также тем самым мы разгружаем наши сервера наши полу потоков от ожидания по таймауту и также в этом режиме для пещерных данных может использовать этот отель это увеличенный отель по сравнению с нормальным режимом тоже для того чтобы мы могли предоставлять сервис клиентов возможность чуть чуть менее актуальными данными и собственно технические перерывы выставляется вручную администратором либо автоматически автоматически не оставляют согласные статистике собираемый сервов приложений и правил мы в которых администратор настраивает пороги срабатывания это делается в разрезе каждого сервиса тем самым мы можем очень гибко адаптироваться под сценарий отказа для каждого конкретного взаимодействует а что разве система умирает по-разному у этих наконец есть ограничение например если вы придете в отделении чтобы снять наличные и система в которой ведется актуальный остаток недоступна то вы этого сделать не сможете ограничение касается основном отделений в интернет-банке с этим проще потому что любой операции мы можем трактовать как черновик и соответственно и и позже либо исполнить либо отклонить а тут клиент уже ушел с деньгами если этого не делать огромный простор для мошенничества итак мы рассказали как работают существующей системы теперь немного перспективной архитектура у нас стоит задача мигрировать существующие решения это несколько фронтальных систем найденный платформ на единую фронтальной систему с чем при этом мы столкнулись с тем что у нас как ни странно разные категории пользователей то есть существующая система каждая обслуживать основном одну категорию пользоватeли а здесь у нас и клиенты и сотрудники и партнеры у реки физике все это что же здесь не так первое у них разные данные профиль физлица и профиль юрлица они абсолютно непохожи второе у них разные сценарии работы в интернет-банке как сказал леша сессия длится несколько минут сотрудник который сидит в отделении работают системе несколько часов и 3 у них разная нагрузка интернет-банк + мобильное приложение создает нагрузку примерно в 10 раз больше чем система которая стоит в отделениях что интересно при этом количество операций которые через них проходит сопоставимым как вы думаете за счет чего такая нагрузка есть идея не смотрите когда у вас стоит мобильное приложение у него постоянно ходите чтобы посмотреть не капнули зарплата какой платеж по кредиту какие были списания по карте его за счет этих информационных нагрузка запросов основная часть нагрузки и получается то есть чем более удобными и доступными вы делаете свои сервисы тем чаще люди ими пользуются и тем больше на них нагрузка что мы сделаем мы вели сегменты каждый сегмент обслуживать определенную категорию пользователей это семян частных клиентов корпоративных клиентов сотрудников эквайринг эквайринг это когда вы в магазине оплачиваете покупке карты любого банка а там стоит вот такой термин нальчик сада типом сбербанка и это как раз тот случай когда вы пользуетесь сервисом сбербанк ты не будучи его клиентом и что интересно опять таки нагрузка по карточным операциям еще в 10 раз больше чем на интернет-банка а из карточных операций большая часть этой aqua ринг то есть от самой нагруженная часть банка и соответственно сегментах мы можем нивелировать различия между категориями пользователей в том числе там разное количество блоков стоит и есть 5 секретный сегмент о том что он делает и как мы улучшаем отказоустойчивости резервирования в новой схеме сейчас и душа расскажет связи с изменением до архитектуры такие же мы вели изменения в схемах резервирования на каждом уровне давайте посмотрим первое что можно отметить это компонент амортизации он теперь у нас резервируется в режиме active актив то есть он работает в каждой в каждом соде где размещен сегмент в котором установлен этого мы добились путем исключения единой точки отказа из компонента можете зации то есть наличие работающие база данных не является обязательным условием для работ компонент может ситуации второе блоки блоки теперь локализуются в рамках одной площадке что положительно сказывается на работу системы в целом так как запрос пользователя и клиентская сессия в целом она обрабатывает в рамках одной площадке тоже самый коллапс системы отрабатывается более корректно так как происходит сейчас есть определенные правила выработанные как тонко тюните пулы connect of pool и потоков отеля ожидания от внешних систем от отеля ожиданий от ателье работы потока то есть это все тоже тонкая работа такая на тюнинговая она конечно занимать большой объем мы не будем сейчас они подробно рассказывать то есть но корректно обрабатываем то есть теперь клиент может обратиться любой компонент можете зации также как и ранее он получит свой родной блок то есть по функции шарди рования а также средства табличный переходит редиректом свой блог если что-то пошло не так в блоке то его redirected сразу в другой блок прозрачно для пользователя в текущей теме допустим возможно кто-то из вас попадал ситуацию когда мобильный банк захочешь начинаешь что-то делать и попадаешь 5 на окно входа вот эта ситуация на случалось при отказе любого уровня что отказал сером приложение что блок вы всегда переходили сейчас же мы ведем механизм со singles вайнона и будет просто прозрачно перебрасывать его другой бок любой другой сервер приложений но единственно лишь некоторых случаях потеряется контекст обслуживания но как бы это не критично я думаю таким образом мы объединили в блоке в пары блоков так называемый кластер облака и условиям для объединения блоков кластер являются следующие 1 блоки должны располагаться на разных площадках таким образом мы достигаем гиа резервирования второе каждый блок должен иметь возможность обслужить все запросы пользователей обоих блоков то есть кластер блоков опять же если это нам надо в случае нештатной ситуации и третье это условие каждый блок должен обладать информацией о данных всех пользователей кластер а также архивных базы данных мы шар де равале внесли в блоке соответственно именно в этих базах и хранится вся информация по о клиентах обоих блоков таким образом мы также улучшили кейсы сопровождения так как меньшую базу подъемы и проще сопровождать второе мы снизили количество железа так как мы теперь с помощью 2n железо обеспечиваем идеал резервирование и случай отказ особый случай отказа блока то есть нам все на 2n железо и репликация выполняется с помощью прикладной репликации и из оперативных бас блоков в архивные между архивной базы также происходит синхронизация данных следующее мы изменили немного план тиражирования то есть теперь под сводом размещаются кластер облаков как я сказал парами но пилотирования также начинается конечно пилотного блока также версия отстаивается там ощущение неделю примерно дальше начинается первая волна обновлений она идет на волна соответственно подходом по кластером блоков и по разным ценам то есть в шарф на порядки для чего мы это делаем для того чтобы если вдруг версии окажется неудачным мы это поймем уже допустим через неделю когда мы раз катилина первой пары и могли откатиться переводом клиентов в резервные блоки которые теперь находится также в пластинах и равномерно иметь нагрузку распыленные под сводом соответственно если все окей запускаем вторую волну обновления на и обновляем систему целиком + мы делаем более тонкое управление фичами это нам надо для того чтобы fitch раскатывать по группам клиентов для того чтобы включать выключать для того чтоб откатываться на предыдущей версии реализации при этом как сказал роман мы при трансформации систем остальных legacy в нашу новую на нашу новую платформу fs всегда оставляем возможности вернуться к предыдущей версии реализации в legacy также через и что blink + новый секретный сегмент который сказал роман это сегмент общих данных сегмент общих данных шарди rowan уже по affinity функции что упрощает доступ к этим данным в сегменте общих данных мы храним каши каши в основу бэк систем то есть это профиль клиента продуктовый карточка его и также профиль в профиль входит история операции то есть данные по операциям плен которые выполнены были в бак системах и запрошены каким-либо из сегментов то есть в этой схеме каждый сегмент прогревает общее каши то есть мы имеем наиболее актуальный и полный кэш данных в системе целиком это допустим нам нужно потому что основная масса клиентов банк сейчас пользуется удаленными каналами обслуживаем таким же мобильный банк веб но придя в отделение банка и в случае задержек с ответами избах систем сотрудник увидеть наиболее актуальные данные по по вам и обратно ситуации если вы зашли в отделение банка выполнить операцию допустим открыли счет сотрудник вам подтвердил всего счет открылся sbk пришло подтверждение выйдя из отделения опять же попав мобильное приложение вы гарантированно увидите свой счет даже из любых систем и будет задерживать с ответом таким образом мы рассмотрели как мы улучшаем обработку всех уровней отказов в связи с новой архитектуры и сейчас слово роману роман то отлично итак что мы узнали мы узнали как работает подводная лодка у нее есть независимо отсеке у нее есть разорение критичных компонентов на всех уровнях и она может работать вне зависимости от внешнего мира делайте так в своих системах и вы получите открытую систему с доступностью на уровне четыре девятки выше очень много материала не вошло в доклад поэтому подписывайтесь на блог на хабре мы будем публиковать статьи по архитектуре по отказу в точности в том числе и детальную статью по итогам конференции потому что материал по многомощно sti особенно последним довольно сложный там будет детально можно прочитать и вкурить как это работает сейчас можно задать вопросы и мы будем благодарны за обратную связь по поводу перспективной архитектура потому что сейчас она реализуется и тем самым вас есть возможность на нее повлиять наши контакты спасибо добрый день спасибо за доклад подскажите пожалуйста в случае но если так произойдет что у вас выйдет и резервной и собственно основной канал ну вот эта вот часть там надо 0102 то я правильно понимаю что часть клиентов вы не сможете обслужить никогда даже если остальные ноты в общем-то будет работать говорят вечером он для да этот вариант он возможен при этом надо сказать что крайне мала вероятность такого исхода событий так как мы уже задел резервировали мы плавно обновляемся мы защищаемся от внутренних отказов то есть от коллапс системы различные настройками и уровень вот этот двойной отказ то есть это второй уровень отказа он крайне малы вы вероятно что он как также что совпадет именно в этом кластере блоков но то что на последнем слайде сказал роман уровень доступности системы фронтальный то есть целый который мы и бизнесу подтверждаем и подтверждаем клиентам 99,99 то есть это 52 минуты простое в год вот этот случай если так сложиться неудачно все то это попадет в те самые пися две минуты простое когда именно для части пользователей которые для части клиентов так сказать везунчиков которые окажутся в этой части системы потому что система имеет как минимум сейчас на текущий момент запланирован четыре основных кластер а соответственно эти миллионы клиентов распределяются по пластин то есть какая-то часть клиентов на небольшое время пока будет восстанавливаться базовых ну да не получат обслуживание но это всего лишь часть системы и это всего лишь там на очень короткое время и вероятность крайне мала да спасибо и 2 еще вопрос реплик сортирования клиентов скажем так вот вашей системе то есть если получается новый клиент система его автоматически относят к до шарнирами этот обычной функции причем она выражена то есть каждый клиент просто прописан лишним клиента и в каком блоке он живет новый клиент по регистрации попадает в новый блок при этом там есть одна фишка новый клиент может попадать в разные блоки зависимости от того через какой канал он регистрируется это нужно для того чтобы балансировать клиентов которые приходят через разные каналы потому что сначала народ веб-шоу потом народ пошел мобильное приложение чтобы их распределить равномерно вот облазила такая фишка и получается тогда что если вам нужно там нарастить capacity to вы просто вот мы ставим добавляете новые ноты и говорим что там всех новых клиентов туда просто это правило да это реализуется правилами регистрации новых клиентов для того чтобы уравнять балансировку нагрузки на всех блоках но также возможна функция балансировки отдельно когда можно перенести конечно клиента из одного блока в другой спасибо эта миграция до 20 раз только расти благодарю за доклад вопрос по базам данных точнее 3 вопрос 1 прикладная репликация это сам описано что-то или направить решение да я репликация которая идет в архивную базу это не самописные решение это метель репликация которая идет когда мы из резерва переключаемся обратно это прикладная репликация отлично второе решение по поводу отказоустойчивости баз данных вас там в схеме была указана актив пассив то есть самба репликации обычно правильно вы про текущую схему куча света просто на просто презентация был разговор поводу репликации на уровне всходы фактически поддержка холодного резерва который быстро поднимается сейчас вы получается отказались от нее но это достаточно дорогое решение то есть high-end массивы можно сказать там что это сотни долларов за гигабайт сейчас да мы снижаем требования по именно используем hand массива использованию оптоволокна то есть канал связи между сот но в общем доступность темы не должна уменьшаться так как именно доступность архивных данных то есть ваша история операции это не критично и условия для работы системы то есть вы попадете в систему вам будет допустим вы показан банях что ваша история пирата на текущем это не полная но при этом предоставит возможность выполнить это платеж либо другую операцию перевод денег то есть система работы да но время времени конфет из данных то есть ну ничего страшного третий вопрос запрещающий по текущей схеме были ли у вас при лове баз данных специальная база падает опережают но было такое но это принципе не так чтобы нештатной ситуации это просто перевод как раз клиентов на резервный блок это либо обслуживание базы обновления либо какой-то отказ допустим там проблемы перегрева шпинделей на дисках во время там каких-нибудь технических работ не то есть все что угодно может быть до базы может сказать спасибо за доклад два вопроса даже первые может просто уточнение правильно понял что когда вас съем был написан 2 балансировщика там все за двое на в разных дата-центрах один тот же блок тоже за двоен один мастер 2 слоев до интересный вопрос на самом деле там был не к лакомству потому что железный балансировщик это очень дорогая штука очень мощно и он действительно зарезервирован каждый дата-центра мейса балансировщик и они работают по схеме либо валькирий во что-то похожее там действительно актив пассив когда один умирает такого не было никогда но если он умрет то 2 подхватит его адреса и будет работать за него там нарисованы были скорее не сами высер о чеки озадачена балансировщик ах это как бы точки входа а блоки сами задать было программное обеспечение софт софт до серого право же нее все это зарезервировано но они не мастер мастер matter of life но она не просто разбором определены это тот же то же самое со стразером на всех серверах и каждая группа серверов обслуживать какую часть пользователей то есть они не masters of any каждые работают но здесь также просто допусти нарисована часть инфраструктурных сервисов таких как конечном хранилище сами там еще что то нас и точнее это все резервируется это все резервирует в основном конечно горячим резервом таки инфраструктурной сервис как балансировщик хранилище распределенные файловые еще что то то есть поддерживаться в основу горячих горячие резервирование холодным резервированием это отдельные стоящие блоки или еще что-то подобное базы данных ещё немножко вот я не знаю там правильным там вас нет больше про желез там призрак инфраструктуру доклад был интересно с такой точки зрения как вот фича toggling у вас реализованный ли вот выходка фум нового функционала на отдельном под множестве пользователей дает у вас все приложение новой версии на этом в конкретно этом под множестве или же новом приложении уже есть и ничего не работают только на тех пользователях смотрите да сейчас на текущий момент у нас монолитное приложение в новой схеме мы переходим к микро сервисом это 1 2 в монолитном приложение в любом случае также это не полный доступ к новой версии а в любом случае это доступ к сервисам соответственно также даже при обновлении монолита есть рубильники про кто рассказал именно на отдельные сервисы бизнес сервис и соответственно и доступ к ним реализуется через там права доступа клиентов то есть клиента объединяться по разным условиям в группу и соответственно каждый функция можно рассказывать популярным группам и также давать не давать доступ плюс объекты у вас есть допустим договор банковского обслуживания станционного это один уровень обслуживания если вы просто по карточке зарегистрировались по банковской за гробом кубань это будет другой уровень доступа это тоже некоторое распространение функционалом там еще есть условия с микро сервисами все уже более интересно становится но смысл такой что фичи просто может быть расположен на нескольких сервисах их можно также включать отключать или доступ конкретным сервисом и клиенту любом случае также объединяются в группы могут по половому признаку по географическому там по разным условиям объединяться в группы на которых это будет постепенно раскатываться и давать доступ это соответственно групп амортизируется там на другой хвост а другой порт там нет не так это так называемый профиль клиента то есть который в момент вашей аутентификации в блоке вам строится из вашей доступные функции и просто стен вам не будет авторизовываться ваш доступ к apple на функционал и на интерфейс предоставлять вам стресс на такие там кнопки или еще что то то есть получается новая версия приложения на будет обрабатывать как клиентов с выключенными фичами да да даже без пищи включаются и старые новое реализация в новую версию приложения спасибо добрый день спасибо за доклад вы не могли бы еще раз уточнить как от шляется репликация между основной базой данных и резервной и соответственно если то есть есть если бывает кита потери как осуществляется как вы их установка вентиляции но репликации осуществляется по таблично обычно соответственно плюс в одном блоке версии всегда схем данных совпадает соответственно убирается табличка который просто переливается то есть там это прикладная репликация грубая логическое по таблично интересная ситуация в рамках кластера когда у нас схема данных могут различаться вот здесь и теперь процесс который может модифицировать схему стресс на из одной версии там повышать или понижать версию данных но это уже отдельная реализация такой такого механизма то что касается перелив ки из оперативной базы в архивные то это просто выборка по табличкам соответственно табличка которую останавливаться ну и дальше это обычно делается либо средствами базы данных любой каких-то еще таких более низкого уровня их реализации то есть это не на уровне java это уровень базы данных все-таки если вот говорить об основной и резервный да то есть при переключении то есть не синхронный ждал любом случае репликации идет при переключении там могут какая-то часть данных остаться в основной базе дома да я об этом здесь наверно я об этом сказал что не консистентной временно не годитесь данных это не проблема для системы то есть максимум вам будет показан баннер что извините на текущий момент вы видите не полную историю операций с не все своего свои операции отображает во что горазд обращаются на в приложении но при этом все сервисы stem вы получите вы сможете провести платежи другие операции при этом отдельно надо понимать что во фронтальной stem есть история операции фронтальной системы то есть операцию клоны фронтально steam есть операцию планы в бэкки в банковском соответственно банк скиллом байки вы получаете обычно выписку вот функционал выписок тогда в таком случае вас тоже спасет получив выписку вы получите транзакции и в с допустим по карте и в магазинах и при этом даже не только в в наших pos-терминалов ну впускного других банков то есть это уже через бог спасибо здравствуйте вас доклад вопрос такой пока клиент не авторизован как он направляется на блог но этот авторизация аутентификация опять же это разные вещи свидетели различия это раз а два еще третья сторона это маршрутизация с тесно вы наверное мере виду как он идентифицируется то есть компания может ссылаться задача стоит идентифицировать клиента а дальше уже переправить соответственно по функции привязки шарди рования в нужный блок но идентификации может проходить разными способами по номеру телефона по логину и паролю сейчас будет скоро доступна биометрической идентификации возможно по паспорту если это касается допустим отделение банка но эти все привязки они ведутся в отдельной системе с теми аутентификации идентификации соответственно комбинации он также интегрирован с этой системой переправляет ваши криденс каналы и получают индификатор дальше по идентификатору же мартин марш these ru.tv блок а в блоке уже происходит процедуру авторизации авторизация может быть с учетом вашего профиля с учетом ваших этих договоров там отдельных ли еще чего то ли ваших настроек не совсем так пока я не вёл никаких данных и тебе просто от круг то есть вы прошлого не клиент банка нет на допустим вы видите окно аутентификации какое окно вы видите правильно окно вот индикация то есть окно входа в систему окно входа в систему это компонент маршрутизации то есть без разницы в данной схеме это раунд роббеном вас раскидает в любой в любую копию и в текущей схеме это один активный instance который вы придете один дисней получить свое окно входа в систему а дальше уже по результатам аутентификации вас перебросит в нужный блог добрый день и спасибо за доклад скажите а больные случае когда существующие эксплуатации блок была необходимость вывести целиком из эксплуатации и что происходило с пользователями который привязана к этому блоку такого не было была процедура миграция пользователей из одного блока в другой в общем для эксплуатации это была некая буря они не хотели бы и повторять там были просто искали скрипты которые переносили данные между базами и соответственно комп этим жить и зации переносили пользователей так чтобы целиком блока водить а зачем это понимал если вы работать вопрос такой какая гранулярный блоков ну то есть количество железа грубо говоря в каждом то есть о каких цифрах играть лишь сказал но я да я всерьез приложений и 4-3 основные блока сейчас в каждом 10 миллионов клиентов это касается сбербанк онлайн а просто мой это пример а нет это реально реально с промо текущие до текущее значение они таковой то есть при реализации новой схемы и микро сервисов конечно цифры скорее всего изменится мы надеемся в меньшую сторону но на текущем надо это примерно 3 тысяч серверов размещенные на все блоки счет вопрос затрагивали просто хочу уточнить по поводу регистре бьются я так понимаю вас просто не было песен когда и вы ответили когда много блоков добавляется если сразу не перераспределить и всех абонентов то они будут просто вид по сути не у вас такого нет мы так не делаем мы вводим по заполнению блока то есть мы изначально делаем некоторый сайзинг знаем какую какое количество клиентов этот блок сможет обслуживать и когда понимаем что мы приближаемся к границе наполнения этого блока максимальное количество клиентов мы вводим в ротацию новый блок и он также постепенно просто наполняется новыми клиентами приходит если же ситуация такая что бывает конечно старые клиенты отмирают то есть перестает ходить банк то просто на к это время включается ввод новых клиентов уже ну в существующие блоки так мы дополняем блоки активным клиент как искал 10 миллионов это именно активных так понятно спасибо здравствуйте скажите у вас тепло и происходит сейчас без дел таймов если да расскажите поподробнее президент таймов как раз за счет перевода в резервный блок то есть когда надо выкатить новую версию пользователи сначала пилотного блока переводите на резервный блок пилотный блок обновляются а не работает неверно потом они переключаются обратно какое-то время работать принимается решение что раскатываем дальше следующий блок переводится также обновляется переводится обратно опять какая-то пауза на проверке что под новый нагрузкой там что-то не падает например и так до конца и последним обновляйся резервный блок поэтому без 2 и плюс еще это когда происходит обновление системы также есть вывод из балансировки отдельных блок отдельных серверов приложений в блоке допустим для проведения опять же там каких-то технических работ именно с конкретным сферам приложение для этого на каждом сервере есть сервис холсте к и он выводится из группы балансировки же балансировщик am либо будет спрататься новой таким образом можно если какие-то локальные работ это просто вывести допустим стойку там или серверы с балансировки если по работе как часто у вас происходит обновление фитопатчи ставятся сейчас происходит раз несколько месяцев в новой архитектуре они будут частые потому что там не прощал и микро сервиса и там вот постоянно обновление там будет devops pipeline доведён до промо сейчас это вручную получается у вас доход много ручного труда сейчас дам его ручного труда и вот есть даже такие интересные вещи у нас не совсем же шарниры не да то есть мы у нас не так много этих шорт и мы делим не только в данные но и делим сервера приложений и на в каких случаях администратор даже говорят ребята не надо делать вот автоматизацию здесь вот у нас настройки ведутся в каждом блоке независимо у нас сидит там 40 человек и пусть они лучше каждой ведут свои блоги настройки чем вы будете даже это даже сделаю есть свеча распространению настройка между блоком и и не используем они лучше заведут их руками чем из-за того что она распространилась а где-то не там некорректно попадется система то есть у нас даже ограничивает в том чтобы что-то автоматизируется человеческий фактор чтобы отстрелили ногу того как бы одному минимум понятно ну что ж спасибо если кто стеснялся задавать вопросы можно просто час лично подойти на всем спасибо что пришли послушать"
}