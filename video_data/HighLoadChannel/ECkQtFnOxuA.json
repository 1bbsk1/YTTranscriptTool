{
  "video_id": "ECkQtFnOxuA",
  "channel": "HighLoadChannel",
  "title": "Масштабирование базы данных через шардирование и партиционирование / Денис Иванов (2ГИС)",
  "views": 31960,
  "duration": 2091,
  "published": "2017-07-29T12:57:50-07:00",
  "text": "всем привет меня зовут единиц фанов и я расскажу о масштабирование базы данных через родирование портирования после этого доклада у всех должно появиться желание что-то по парте целовать по шахте ровать вы поймете что это очень просто она никак жрать не просит работает и все замечательно так немного расскажу о себе я работаю в компании в папе в 2 gessi мы предоставляем api для организации у нас очень много разных данных у нас 8 стран в которых мы работаем 250 крупных городов 550 тысяч населенных пунктов ну в общем очень очень много разных данных и достаточно большая нагрузка у нас 25 миллионов активных пользователей месяц и в среднем нагрузка около 2000 рпс идет на пи все это располагается нас 3 дата центрах перейдём уже немного к проблеме которую мы сегодня с вами будем решать одна из проблем это большое количество данных какой-то момент когда вы разрабатываете тот или иной проект у вас в любой момент времени может учиться так что данных становится очень много если бизнес работает он приносит деньги соответственно данных больше денег больше с этими данными то что то нужно делать потому что эти запросы очень долго начинают выполняться и у нас просто сервер начинает не вывозить и одно из таких решений что с этими данными делать это масштабирование базы данных я в большей степени расскажу естественно про sharding он бывает вертикальным и горизонтальным сейчас расскажу более подробно о них и так же бывает такой способ масштабирование как репликация нотка с предыдущей у нас доклад про это ебу я эту тему практически не буду освещать перейдем немного подробнее к теме парте церовани я вертикальный shaking как это все выглядит у нас есть большая таблица например с пользователями у нас очень много пользователей и парте церовани и это такой принцип когда мы одну большую таблицу разделяем на много маленьких по какому-либо принципу с горизонтальным шаринган все примерно так же но при этом у нас вот эти таблички они лежат в разных базах на других инстанциях то есть единственное отличие горизонтального масштабирования вертикального в том что это горизонтальном масштабировании будет разносить данные по разным инстанциям ну про репликацию я не буду останавливаться тут все очень просто предыдущий доклад про это был вот перейдём собственно более глубже к этой теме я расскажу практически наверно все портирование на примере под газ и кто работает в способе сам не так много как хотелось бы но может захотите попробовать когда увидите что все хорошо ну давайте рассмотрим совсем простую табличку наверняка практически в каждом проекте 99 процентах такая табличка есть это новости у нас новость есть идентификатор есть категория в которой думалось расположены есть автор этой новости и рейтинг и за какой-то заголовок nude совершенно стандартная таблицы здесь ничего общем сложного нет как же эту таблицу разделить на несколько с чего нужно начать всего нужно сделать будет два действия над табличкой это поставить у нашего шарда допустим это будет news один то что это она будет наследоваться таблицы news news у нас будет базовой таблицы будет содержать всю нужно нам структуру и вот мы собственно создавая портится будем указывать что но наследуется от нашей базовой таблицы это наследования таблица будет иметь все колонки родители той базовой таблицы которые мы указали и так же она может иметь свои колонки которые мы дополнена туда добавим она можно сказать будет полноценной таблицей но унаследованные от родителя и там не будет ограничение индексов и триггеров от родителей это очень важно если вы на базовой таблицы на создаете индексы наследуете это в наследовании таблиц и индексов ограничение триггеров не будет второе действие которое нам нужно сделать это поставить к краске ограничения это будет проверка что в эту таблицу будут попадать данные только вот с таким признакам в данном случае это признак эта категория 1 равен 1 то есть только запись из категорий они равны 1 будут попадать в эту таблицу какие типы проверок бывают для порционных таблицы бывает строгое значение то есть у нас какое-то более четко равно какому-то полю бывает список значений это то есть какое-то вхождение в список что у нас может быть три автора новости вот именно в этой партиции и диапазон значений ну то есть все понятно здесь как бы от от и до какого значения будут храниться данные на этом месте нужно поподробнее остановиться потому что в проверка поддерживает оператор between но великого все его знаете и вот так просто сделать можно но нельзя можно сделать потому что нам разрешат такое сделать вас грейс келли поддерживает такое как вы видите что у нас первую партицию попадают данные между 100 и 200 а во вторую между 200 текста и я хочу задать такой вопрос в какую из этих партиций попадет запись с рейтингом 200 нет неизвестно как повезет и на самом деле поэтому так делать нельзя и нужно указывать строгое значения то есть строго в первую партицию значение больше ста и меньше либо равно 200 и во вторую соответственно тоже больше 200 что не 200 и меньше либо равно 3 ст и это как бы обязательно нужно запомнить и так не делать потому что ну вы действительно не узнаете просто в какую из партиции данные попадут нужно четко прописывать все условия проверки также не стоит создавать партиции по разным полям то есть что в первую партицию у нас будут попадать записи там с категории д1 кого вторую с рейтингом 100 опять же если у нас придет вдруг такая запись у которой категория де равен 1 и рейтинг 100 то неизвестно в какую из партиции попадет эта запись так что протестировать лучше по одному признаку по какому-то одному полю этот очень важно давайте рассмотрим собственно нашу партицию уже целиком это вот действительно так просто ваши портированная таблица будет выглядеть вот так вот у нас то есть этой таблице news один с признаком чтоб они будут падать два провода записи только с категория де равны 1 и эта таблица будет унаследовано от базовой таблицы news все очень просто мы на базовую таблицу при этом должны добавить некое правило чтобы когда мы будем работать с нашей основной таблицы news у нас приходит ставка на запись с категория де равный 1 мы хотим чтобы она попала именно в ту partition ним основную мы указываем простое правило как называем его как хотим говорим что когда данные будут вставляться в news с категория иди равный 1 мы вместо этого будем вставлять данные вниз один здесь тоже все очень просто паша гонщику она все отменяется и все будет замечательно работать это правило создается на базовый таблиц мы собственно таким образом заводим нужное количество нам партиций я для примера буду использовать две партиции чтобы было проще то есть у нас все одинаково кроме наименования этой таблице и условия по которому данные будут нападать мы также заводим соответствующие правила по шаблону на каждую из таблиц и давайте рассмотрим пример вставки данных данные будем вставлять как обычно как будто у нас обычная большая толстая таблицы то есть мы оставляем запись категория d1s категория эти два у нас можем вставить даже данные с категория эти три как вы думаете это будет работать а куда данные попадут да и так это правильно я потом дальше покажу как это работает вот мы выбираем данные у нас они все есть все которые мы вставляли но несмотря на то что как бы 3 партиции у нас самом деле нет но данные есть в этом может быть есть немного магии но на самом деле нет мы также можем сделать соответствующие запросы в определенные партиции указывая наше условие то есть категория 1 равен 1 или вхождение в число 23 все будет замечательно работать все данные будут выбираться опять же несмотря на то что партиции с категория эти три у нас просто нет мы можем выбирать данные напрямую с партиций это примерно будет то же самое что в предыдущем примере но мы четко указываем нужную нам партицию и ну для когда нам у нас что стоит в точно условия на то что нам именно из этой партиции можно выбрать данные мы можем напрямую указать эту партицию и не ходить в другие но как я уже сказала у нас нет 3 партиции а данные действительно как уже сказали в зале попадут в основную таблицу хоть у нас и применено парте церовани и к этой таблице основная таблица все равно существует она настоящая таблицы она может хранить данные и с помощью оператора он ли можно выбрать данные только из этой таблицы и вот мы можем найти что вот у нас это запись на самом деле здесь спряталась здесь можно как и как видно на слайде вставлять данные тоже напрямую в партицию ну может это пригодиться может нет можно вставлять с помощью правил в основную таблицы но можно и в саму партицию вставлять данным если мы будем вставлять данные в партицию с каким-то чужеродным условием например категория де равной 4 то мы получим некую ошибку что у нас как бы сюда нельзя такие данные вставлять и это тоже очень удобно мы просто будем класть данные только в те партиции в которой нам действительно нужно что если что-то пойдет не так мы на уровне базы это все отловим вот тут такой побольше пример можно балкон совет использовать вставлять несколько записей одновременно и они все распределяться с помощью правил нужные партиции сами то есть мы можем вообще не заморачиваться просто работать наши таблицы как мы раньше работали наше приложение продолжит работать но при этом данные будут попадать в партиции все это будет красиво разложено по полочкам без нашего участия вот собственно еще раз напомню что мы можем выбирать данные как из основной таблицы с указанием условия можем не указывает а условия выбирать данные из партиции как это выглядит со стороны explain а у нас будет sequence can по всей таблице целиком потому что туда данные могут все равно попадать и будет сканка партиции если мы соответственно будем указывать условия нескольких категорий то он будет сканировать только те таблицы на которые есть условия он не будет смотреть в остальные партиции это так работать оптимизаторам это правильно и так действительно быстрее вот мы можем посмотреть как будет выглядеть explain на самой партиции это будет обычная таблица просто секунд скан по ней ничего сверхестественного точно так же будут работать апдейты и дэвид и мы можем как апдейтить основную таблицу можем также отдайте свои напрямую в партиции также и дэвид и будут работать на них нужно также соответствующие правила создать как мы создавали сенсор там только вместо инсов написать апдейт или делить соответственно теперь перейдем к такой вещи как индексы как я в самом начале сказал индексы созданные на основной таблицы они не будут унаследованы в дочерней таблицы в нашей партиции это грустно но придется заводить одинаковые индексы на всех партиях с этим есть что поделать я немного дальше а потом расскажу нам придется заводить все индексы все ограничения все триггера дублировать на все таблицы это так собственно как мы с этой проблемой боролись у себя мы создали замечательно утилиту partition magic которая позволяет автоматически управлять партициями не заморачиваться совершенно с созданием от этих индексов триггеров с несуществующими партициями с какими то там беками которые могут происходить это утилита по ндс на этом в конце будет ссылочка я немного сейчас расскажу как это будет выглядеть то же самое проецирование только с используемыми этой утилиты мы эту утилиту виде хранимой процедуры просто добавляем их нам в базу она там спокойно лежит она не требует никаких дополнительных старшинов никаких расширений ничего пересобирать не нужно то есть мы берем просто пост grayscale обычную процедуру запихиваем в базу из них работаем вот в та же самая таблице которую мы рассматривали ничего нового все то же самое как же нам за парте целовать ее а вот просто вот так все мы вызываем процедуру указываем что таблица будет news и протестировать мы будем по категория иди и все дальше будет самой работой нам больше вообще ничего не нужно делать мы также вставляем данные здесь как вы можете заметить у нас три записи с категория д 1 две записи с категория иди 2 и 1 с категория де 3 после вставки данные автоматически попадут в нужные партиции мы можем сделать select и и все уже все партиции создались и данные разложились по полочкам все замечательно работает какие мы получаем за счет этого преимущества мы при вставке автоматически создаем партиции если ее еще нет мы поддерживаем актуальную структуру мы можем управлять просто базовой таблицы навешиваю на нее индексы проверки триггеры добавлять колонки и они автоматически будут попадать во все партиции после вызова этой процедуры еще раз мы получаем действительно большое преимущество в этом вот ссылочка можете сфотографировать и за переписать слайды потом думаю на сайте будут можно будет прямо оттуда кликнуть если что теперь с первой частью докладом и закончились мы с вами научились портировать данные напомню что парте церовани и применяется на одном инстансе это тот же самый instance базы где бы у вас лежала большая толстая таблица но мы ее раздробили на более мелкие части мы можем совершенно не менять наше приложение не как она точно так же будет работать с основной под таблицей нашей вставляем туда данные редактируем удаляем все так же работает но работает быстрее приблизительно в 3 4 раза в среднем это на быстрее работает действительно то есть тот же самый instance столько же оперативной памяти процессора столько же практически данные занимают на диске но вот пума получаем boost за счет того что данные размещены по партиции и перейдём ко второй части доклада это горизонтальный sharding я напомню что горизонтальный sharding вопросы после если можно горизонтальный sharing это когда мы данные разносим по нескольким серверам и все это делается тоже достаточно просто так же стоит один раз всего это настроить и она будет все работать замечательно я сейчас расскажу более подробно как это можно сделать рассматривать будем опять же такую же структуру с двумя шар даме тоже news 1 из 2 но это будут разные инстанции третьем инст он сам будет основная база с которой мы будем работать вот та же самая таблицы единой что-то нужно добавить их это constraint чек то что записи будут у подать только с категория de равна 1 так же как в предыдущем примере но это не унаследованная таблицы это будет наша таблица с шагом которую мы делаем на сервере именно который будет выступать шар дам с категория д 1 это нужно запомнить единственно что нужно сделать это вот добавить constraint также мы можем дополнительно создать яндекс по категория 1 я расскажу потом зачем это нужно сделать то есть несмотря на то что у нас стоит чек проверка под грейс келли все равно обращается в этот шар и sharp может очень надолго задуматься потому что данных может быть очень много случай с интересом он быстро ответит и screen как потому что в яндексе ничего нет по такому запросу поэтому его лучше добавить как настроить sharding на основном сервере мы подключаем extension extension идет в подгрести из коробки делается это командой create extinction называется он позарез вдв рф лица как фаренгейта wrapper дальше нам нужно завести наш удаленный сервер подключить его к основному мы называем его как нам хочется можем котик там персик как угодно можем news один сервер что было понятно что это сервер 1 шарда для новостей указываем что этот сервер будет использовать фаренгейта wrapper вот такой-то который мы указали точно таким же образом можно для шарда использовать mais quel oracle манга то есть сиськи white part iv аренда это wrapper а есть для очень многих вас данных то есть можно отдельные шарды в принципе хранить в разных даже совершенно базах в опции мы добавляем хост порт и имя база с которой будем работать здесь все просто вам нужно указать просто адрес вашего сервера порт скорее всего он будет стандартный и базу которую мы там завели далее мы создаем mapping для пользователя это собственно по этим данным наш основной сервер будет авторизироваться дочернему мы указываем что для вот этого news один сервер будет пользователей по сгр с паролем остров и на основную нашу базу данных он будет напиться как наш юзер по сгрыз я все со стандартными настройками показал тыс у вас могут быть какие то свои пользователей для проектов заведены для отдельных бас здесь нужно именно их будет указать чтобы все работало далее мы заводим табличку на основном сервере это будет табличка с такой же структурой но единственное что будет отличаться это префикс того что это будет форинт эйбл то есть она какая-то иностранная для нас удаленная и мы указываем с какого сервера она будет взята и в опциях указываем схему имя таблицы которую нам нужно взять схема по дефолту опять же public таблицу к которую мы завели мы назвали news точно так же мы подключаем вторую таблицу к основному серверу как я уже показал ранее добавляем сервер добавляем mapping создаем табличку все что осталось это завести нашу основную таблицу это здесь делается с помощью view через представления мы с помощью и не она просто склеиваем запросы из этих удаленных таблиц и получаем одну большую толстую таблицу news из удаленных серверов также мы можем добавить правило на эту таблицу при вставке удаление чтобы работать с основной таблицы вместо шар дав чтобы нам было удобнее вообще никаких переписывания ничего в приложении не делать мы заводим основное правило которое будет срабатывать если ни одна проверка не сработало чтобы не происходило ничего то есть мы тут это указывает уинстэд на финн и заводим такие же проверки как мы делали ранее но только с указанием нашего условия то есть категория е равен 1 и таблицу в которой данные вместо этого будут попадать единственное отличие которое мы будем делать это категория иди указывать имя таблицы также посмотрим на ставку данных я специально выделил несуществующей партиции так как эти данные как мы уже ранее создали условия не попадут на некуда то есть у нас указано что мы ничего не будем делать если не нашлось никакого условия потому что это у нас view это не настоящая таблица туда данные вставить нельзя в том условии мы можем написать что данные будут вставляться в какую то там третью таблицу то есть мы можем что-то вроде корзины или буфера зависти и и inside instead делать эту таблицу чтобы там копились данные если вдруг каких-то партиции у нас нет и данные стали приходить как для которых еще нет шагов выбираем данные хочу чтобы вы обратили внимание на сортировку идентификаторов у нас сначала выводятся все записи из первого шарда затем из 2 это происходит из-за того что он грыз собственно у нас же уходит по в ухе последовательно у нас указаны были selecta через юня но луи он именно так исполняет он посылает запросы на удаленной машины собирают эти данные склеивает и они будут отсортированы соответственно потому принципу по которому это юху создали и по которому нам тот сервер отдал данные также делаем запросы точно такие же как мы делали ранее из основной таблицы с указанием категории тогда по сгрыз даст данные только из 2 шарда либо напрямую обращаемся в шарф все точно так же как и в примерах ранее только у нас совершенно разные сервера разные инстанции и все точно также работает как и работала раньше посмотрим на explain у нас все просто же нас фокинском по news 1 и for and scan the news 2 точно так же как было с проектированием так место sequence канал нас for and scan это удаленный скан которые выполняются на другом сервере давайте подведем небольшие итоги так как мы в принципе разобрались уже спарте церовани и мы с родированием портирования это действительно просто стоит всего лишь несколько действий совершить все настроить и оно все будет замечательно работать не будет просить есть можно также работать с основной таблицы как мы работали ранее но при этом у нас все красиво лежит по полочкам и готовы к масштабированию готова к большому количеству данных все это работает на одном сервере и при этом мы получаем прирост производительности в три-четыре раза как я уже сказал ранее , что у нас объем данных в таблице сокращается за счет того что это разные таблицы в sharding это тоже просто но это немного сложнее парте церовани я только лишь тем что нужно настраивать каждый сервер по отдельности но это даёт некое преимущество в том что мы можем просто бесконечное количество практически серверов добавлять и все будет замечательно работать на этом у меня все спасибо за внимание может есть какие то вопросы потом человек еще в середине доклада поднял руку у него преимущество большое спасибо вопрос такой что наверное что касательно и и шарди рование парте церовани я приблизительно о каких числах мы говорим когда говорим когда таблица большая то есть ну если это 1000 строк наверное не имеет смысла делать да тут такой вопрос но тут не только количество строками и значение сцены не оставлял никаких цифр такой цифры наверно просто нет то есть она может и в 1000 записей быть плохо если у нас очень много колонок очень много данных то есть их все перебирать в одной таблице будет и дольше чем в разных таблицах но и при 50 миллионов записей все может замечательно работать по индексам то есть нужно смотреть когда все начинает быть плохо и только тогда применялись не стоит прямо сразу рваться и все таблицы партиции ты сами категории раз партиции ровать там все это то есть нужно смотреть по обстоятельствам смотреть на запросы которые приходят и ну заранее можно заложить найс таблицы которая предполагает рост на примере то нам какие-нибудь пользователи это заказы в интернет-магазине это новостью какой-нибудь проекте и ну их заранее можно спроецировать все будет готово заранее к масштабированию марки и второй вопрос это такой то есть тут же насколько я прямая имеет сильное значение по какому ключевому парте церу им и соответственно какие-то запросы как раз таки могут просесть по производительности или нет могут дать здесь вопрос тоже эффективности индекса можно сказать то есть вот это наше принцип сортирование он по такому же принципу как яндекс работает то есть не стоит пользователи разделять на партиции попова то есть просто чтобы у нас было два повод а мужчины и женщины отдельно стоит например использовать как range например по сто тысяч их разграничивать для заказов можно использовать даты например то есть раньше спокойно будет работать на даты то есть например с первого по 30-е число и на каждый месяц будет своя портится то есть тут нужно выбирать принципы именно того как мы будем партиции ровать это зависит от бизнес-логики я таких данных которые там лежат есть опять же от веток четкого нет как это делать это зависит от проекта акела спасибо раз нас а я очень хотел бы дополнить это к вашему вопросы можно применить такой принцип что мы сначала данные по разносим по разным серверам то сделаем шарди рование например наших новостей по категории и внутри мы уже можем и каждого сервера применить парте церовани и то есть данные еще более ветвистую структуру приобретут есть можно комбинировать даже эти вещи на самом деле можно еще раз уточнить вот чем одна большая таблица хуже чем много более мелких за счет чего получается просто производительность лучше раз проливания но зависит опять же от задачи то есть если мы просто хотим найти какую-то новость одну до еды у нас их нам 50 миллионов и нам нужно отобразить новость мы пойдем в котором новости можем определить партицию исходить только в нее там sequence скан будет меньше гораздо по миллиону записей чем по 50 миллионов том числе за счет уменьшения количества итераций которые системы сразу указываем партицию мы до можем сразу указать портится аутизм и не указываем партицию будут то прироста но на самом деле не будет будет нибудь даже у вверх это небольшой совсем потому что придется искать во всех partition но как бы мы практически всегда можем определить партицию это случай идентификатора мы можем использовать там 6-ти четырех битной адэшника и вот сделать композитным включать туда партицию просто мы так для себя например в проекте делаем спасибо есть вопрос по тому как собственно работает вот это посредством кыш родирование с фрэн таблицами вот когда мы делаем вьюшку делаем там вот этот замечательный union в каком порядке собираются данные и оптимизируется ли как то мы придется на определенных сервера и прежде таблиц отрабатывает запрос и они склеиваются и потом они отрезают как так как у нас будут индексы и проверки на всех сортах на всех партиях то мы просто-напросто получим ответ только из одного шарда и там это уже будет все профильтровано то есть можно на самом деле создавать view тоже с условиями то есть объединять запроса с какими-то условиями сразу же чтобы данные уже заранее подготавливались с нужным почему из этого шарда можно допустим war шарнир в ли юзеров а потом нам нужно постранично вывести всех этих user ну в таком случае не будет до прироста здесь прирост будет только в том в японии когда мы работаем с определенной партиций то есть здесь нужно по не понимать что ну естественно мы не получим прироста при выборке там всех этих youth пользователей на время ножниц данной таблице шатура ну-ка undead аккаунт тоже будет жестоко работать здесь уже немного другие вещи будут помогать и как водка тут уже говорили по распараллеливание этих запросов то есть подготовка где-то склеивания есть всякие сторонние утилиты которые вам позволят сделать но из коробки под грез позволяет нам вот так вот это все раз масштабировать и работать с более мелкими партициями вот к сожалению это так вообще возможно взять проект котором код не заточен под шарди раване изначально и вот таким вот средствами пожгли сами его расформировать рассовать в юшкой в принципе да в большинстве случаев так и будь без изменений кода это даст какой-то прирост да даст если кратко ответить ну то есть мы изначально у себя в проекте так и делали мы применили сначала проецирование она все заработало то есть запросы точно также отрабатывают как мы обращаемся в основную таблицу и все работает в принципе все спасибо спасибо за доклад такой вопрос мне несколько запутался вы сначала стали что для того чтобы был прирост нужно сразу из на ручками определить портится и запросить у нее вот на предыдущий вопрос на скале что все равно будет прирост из ничего не менять можно также запрашивать к основной таблицы и все равно будет перенос ты все-таки спарте церовани им прирост будет небольшой если мы будем и основном таблицу обращаться потому что все равно он пределах одного сервера это будет делать и ему придется все просканировать если мы не указываем портится если указываем условия это тоже будет быстрее потому что он пойдет в основную таблицу и в ту на которую указан constraint то есть по чеку если чек срабатывает если как вы вот ну то есть если в нашем условии можно понять что только по одной партиции то он пойдет только в нее правильно не будет никуда бегать до так и такой вопрос с джо джо юными протеин и можно забыть или как или с ними все хорошо ну да нет все в принципе работает ну хорошо паре портирования при шарди рование наверное нет там и там view и она работает точно также как и любая другая быть все сливать как вы сюда ну то есть все равно надо думать 0 до то тут нет никакой магии оно не вылечит ничего всех всегда нужно думать как перейти тогда она вот если обычная до структура наш армированную вот есть уже рабочий проект нагружен уже там дофига записи и как бы как перейти на шарди раваны ему такую ну я бы сказал что аккуратно но как бы мы это делали таким образом что создавали шарды в них просто как через фаренгейта wrapper у нас данные копировались постоянно через триггер и то есть мы навешивали триггеры которые при апдейте апдейте от данные приду летит и летит и так далее потом постепенно отключали основную таблицу и соответственно потом в итоге получили уже готовые то есть это прям такой ход режим кроме как с триггерами это практически никак не сделать чтобы прям на живую перенести данные в партиции если есть возможность остановить сервисов просто через копии инсаров потом они все разбредутся по нужным таблицу вы говорили что утилита есть для парти цианирования с вами созданным команду как ее применять то есть я правильно понимаю что первый раз при вызове она навешивает триггеры и что если категории встречается новым создает новую партицию а дальше если вы создавали какие-то дополнительные индексы ограничения нужно перри вызывать чтобы она их создавая дашь после этого нужно вызвать то есть мы это вставили в свой скрипт тепло и то есть когда у нас дельты накатываются какие-то altera колонок происходит или триггер нас вызывается эта процедура астана просто обновить всю структуру я в любой момент можно вызвать по поводу индексов начните пожалуйста то есть если вы говорите индексы они наш орды не расходятся никак то есть если у нас допустим есть таблица пользователей и мы создали в основной таблицы уникальный индекс на e-mail пытаемся вставить две записи с одинаковыми мы он получается уже shard он это даст сделать если честно я не смогу ответ на этот раз я такой кейс не проверялся уникальный с уникальностью именно индекса как бы даже не знаю что сказать если честно то есть как то он же должен если индексы не делает но ну я предполагаю что можно во всех родных запихать такого пользователя и он был только там будет уникальной в каждой шарди ты скорее всего этот кейс не обработается ладно спасибо но я не могу точно ответить поэтому ну предполагаю что так вроде все спасибо за внимание еще раз"
}