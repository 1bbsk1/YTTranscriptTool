{
  "video_id": "xbZgjMasSnc",
  "channel": "HighLoadChannel",
  "title": "Зеркалирование трафика в Рекламной Платформе / Алексей Лапаев (Тинькофф)",
  "views": 563,
  "duration": 2350,
  "published": "2019-12-05T12:48:28-08:00",
  "text": "вас сегодня и вчера были напряженные два дня вы получали много информации но и постараюсь что-то полезное еще положить вам голову своим завершающим выступлением послов и помни меня зовут алексей лапаев я работаю как уже сказали в компании тиньков работаю в рекламной платформы она является частью нашего направления привлечения клиентов банк а что же такое рекламной платформе расскажу чуть позже пару слов о том чем я именно занимаюсь на ней я тестировщик ведущий тестировщик меня есть небольшая команда которую я скажу пару слов тоже чуть позже и мы проверяем качественно качество нашего рекламную платформу те сервисы которые отвечают за ее работоспособность что обычно входит в рекламную платформу у нас есть какая-та инфраструктура с одной стороны у нас есть сеть поставщиков площадок на которых хотят они разместить какую-то рекламу таких ребят называют соплей сайт платформ ссп сокращено с другой стороны есть естественно ребяток у которых есть рекламы которые хотят ее где-то разместить таких ребят называют диман сайт платформ или дсп сокращенно для того чтобы конечному пользователю показать нужную рекламу в нужное время тогда когда он наверняка по ней кликнет и возьмет наш товар существует платформу дат data management platform которые оперируют данными по пользователям например какой то статистика их посещений возможно какими-то действиями пользователей за трек он их там пикселями и прочей информацией все эти три большие сущности составляют рекламную платформу деньков в то же время каждый из этих сущностей разбивается на пачку микро сервисов у нас все крутится в докер контейнерах очень похожи на ребят и за вида которые рассказывали докладом ранее о своей инфраструктуре а каждому сервису соответствует свой докер-контейнер все это соединено в одну какую-то сетку и между ними у нас бегает трафик по различным протоколам использующие и чтить и протокол про табов поверх тисе пи плюс еще некоторые бинарные свои самописные как это выглядит для пользователей естественно он не не смотрит на вот эти сущности спд спд м.п. они ему ни о чем не говорят он обычно видят различные наши баннеры всяких цветов и размеров предлагающих им наши услуги либо какие-то продукты есть еще вторая большая часть у нас есть мобильное приложение нашего банка и там пользователи заходя в него может увидеть не только ту сумму на счету денег которого у него лежит но и полезную штуку в виде мобильных историй это такие карточки которые находятся тоже прямо в мобильном приложении и рассказывают какую-то очередную полезную жизнь иную штуку которая может быть этому пользователю полезно естественно эти карточки нужно показывать релевантным пользователям для того чтобы эти истории были интересные они могли с ними например взаимодействовать как на примере видно есть желтая кнопка по которым можно кликнуть и например забронировать билеты на нашем сервисе заказа авиабилетов это 2 большие части рекламные креативы и мобильные истории для каждой из этих частей у нас поднят отдельный продакшен контур который состоит из идентичных микро сервисов но оба контура никак не связаны между собой кроме вот части части дмп в которой хранятся данные по пользователям потому что это полезно узнать как какие странички посещал пользователей на каких баннера смотрел и затем как-то эту информацию преподнести в мобильных историях трафик который ходит между нашими микро сервисами в итоге разбивается на две части это два продакшен контура на большом продуктовом контуре который отвечает за показ рекламных креативов у нас трав порядка двух миллионов запросов в минуту на меньше по своей по своим масштабам кластере у нас всего сто тысяч запросов в минуту но encounter отвечая за мобильные истории там поток пользователю нас до значительной меньше и на обработку одного запроса для показа рекламы либо отдачи мобильные истории наша система тратит порядка 10 миллисекунд это тратится на то чтобы из при летающего запроса о с информация пользователя сделать вывод какую рекламу баннер показать я отправить его назад в рекламную сеть на мобильных историях этот процесс занимает чуть меньше там это порядка 30 и 50 миллисекунд но это только за счет того что там нам надо отобрать ни один рекламный баннер а сразу 30 или 50 которые соответствуют к от единичной мобильные истории скажу пару слов о команде обеспечение качества которое таится над рекламной платформы всего у нас в тиньков порядка 350 тысяч щиков или q&a специалистов как мы сейчас называем на направление привлечения клиентов банк в которое входит не только рекламная платформа также не авторизованной озона и например наш тоже журнал над этим направлении работают порядка 120 тестировщиков и в рекламный платформе непосредственно трудятся 7 участников каждый из этих участников нам особенно ценен эту команду собирал личная и мы сейчас в команде пропагандируем подход что даже бывший тестировщик который просто нажимал кнопки был функциональ чекам не видел никогда бэг-энда не знает сетевой какой-то специфики у нас становится автомате зато рамный начинает вникает во все сущности также ходят где в общем а узнают про графики мониторинге и всю хардкор шину которая стоит за нашу на нашей рекламной платформой проблематика собственно того из-за чего мы ставили использовать закаливание трафика кроется в следующем представьте у нас есть какой-то сервис который крутится в докере и вот в один прекрасный день он заболел он упал что-то начинает происходить не так начинают ползти мониторинге как на примере здесь абстрагировано график открытых файлов дескриптор их соответствующих соки там соединений это вами края сервиса с различными другими контейнерами эти мониторинге у нас видны как devops он так и разработчиками естественно тестировщиков мы тоже туда опускаем для большего вовлечения в процесс разработки продукта то что происходит отклонение на графике все замечают и начинают интересоваться ребята тестировщики вы же обеспечиваете качество короче у нас вроде блага почему вы ее не отловили на тестах мы начинаем задумываться дайте святым чему мы не отловили на тесте начинаем копать функциональные тесты новым их еще раз воспроизвести на инфраструктуре которая очень похожа на плату нас ничего не получается проблема которую надо решить как с помощью функциональных тестов которых де-факто нельзя покрыть все существующие кейси вы поразите ситуация которая приводит к поломке на опрос я начал изучать эту тему и нашел интересную методику тестирования которые называются по-разному называется деколирование трафика называется еду и называется dark трафик testing смысл этой методики заключается в следующем смотрите ситуацию у нас есть внешний наш трафик есть наш сервис какой-то боевой на которые этот трафик бежит кажется все хорошо происходит нештатные ситуации у нас появляется идея ребята давайте попробуем завести какую-то штуку у себя на проекте которая сможет отцеплять или цель коллировать трафик по переходящий на плот на второй тестовый instance который полностью этот плод повторяет то есть нам нужна какая-то коробочка какое-то решение которое будет вставать на пути следования продуктового трафика при этом никак с ним не взаимодействовать не модифицировать его и это особенно важно и при этом делать дубль и этого трафика на тестовую систему тут я хочу заметить что дублирую трафик на тестовую систему мы никаким образом в рамках рекламной платформы не взаимодействуем с какими-то личными данными пользователя или какой-то чувствительной информации которую не хотелось бы показывать тем же тестировщиком да а в рамках рекламы позволим и мы оберегаем пользователем как некоторыми а безличными идентификаторами мы не знаем о них никакой личной информации кроме собранной статистике такой трафик мы можем позволить себе отзеркалить на нашу тестовую среду начали искать как это делать у себя в команде мы придерживаемся идея о том что не нужно писать велосипед если решения какое-то уже существует во внешне мы просто берем его притаскиваем начинаем использовать погуглил посмотрел что предлагает интернет он предложил и он и различных решений казалось бы все хорошо мы можем взять эти решение принести себя начинать пользоваться но это сделать не получилось потому что нам предложили в основном хардварные решение то есть принести какой-то свечу роутер поставили дата-центре переткнуть пару проводов и вот у вас зеркале вне готова на рекламный платформе мы к сожалению не можем так сделать она она скроется внешнего хостер у нас нет доступа к железу и в принципе затевать переписку по установке какого-то дополнительного оборудования нам совершенно не хотелось потому что это требовало ресурсов денег времени и трудозатрат на в плане перестройки поэтому начали искать дальше я начал смотреть а как же можно попробовать отзеркаливать трафик начал разбираться в устройстве сети как как вообще трафик бегает у нас по интернету и забегает к нам в сервисе нашел следующей точке где можно попробовать этот трафик выцепить и пудру продублировать пакеты на тестовый стенд первое это естественно сетевая карта куда наш трафик прибегает где мы можем попробовать взять пакет и следующий этап это так называемой дисциплины очередей где трафик можно классифицировать попробовать перестроить очередность пакетов а либо как-то еще с ним повзаимодействовать опять же вспомнил пару таблички в которых трафик можно перекусить и целовать как-то модифицировать его заголовки либо сделать роутинг на другие сервера на другие стенды и прочее ну и потом не остался незамеченным уровень самого приложения где опять же можно было что-то на программировать на писать какой-то код и а че пить трафик самим уже приложением либо какую-то проксю перед ним поставить то что у нас все сервисы кроются в доки в контейнерах накладывает определенную свою специфику если посмотреть на устройство сети внутри docker host а то она будет выглядеть так у нас есть docker host на нем существует допустим два контейнера в каждом из контейнеров виден сетевой интерфейс но на самом деле он не настоящий он виден только внутри этого конкретного контейнера на большом докер кассет то есть на той машинки где все это 1 армата видны виртуальные интерфейсы которые создаются докер машиной каждый из виртуальных интерфейсов соединен в сеть самый банальный пример которые по умолчанию это bridge 0 который заводится докер хвостом это сеть соединено сетевым интерфейсом уже физическим который располагается у вас на машинке и дальше трафика у нас бежит во внешнюю сетку в принципе эти ведь знания тоже можно использовать для того чтобы построить зеркалирование и как-то от дублировать наш трафик на тестовый стенд есть одна загвоздка в докер сети в докер-контейнер нельзя четко установить связь между конкретным сервисом и конкретным контейнерами тем виртуальным сетевым интерфейсом которым с которым он взаимодействует но получилось найти утилиту которую притащили на проекты который вот в таком табличном виде просто показывает вам такой то контейнер имеет такой то виртуальный интерфейс это утилита уже можно было отдать конечным пользователем опять же оговорюсь что разбираться вот в этой всей штуки взять взяли на себя эту ответственность тестировщики потому что мы хотим знать как хорошо работает наш сервис изнутри но у нас недостаточно знаний бывают в каких-то хардкорных областях поэтому мы искали простой инструмент для того чтобы решить нашу конкретную проблему поехали дальше первое решение которой мы нашли это утилита traffic control она входит в штатную поставку linux и позволяет вам а повзаимодействовать с трафиком на уровне дисциплина очередей напомните дисциплины служит для красивых классификаций и перри приоритизации различных потоков ваших данных ходящих по сетевым интерфейсом посмотрим как сделать это это такой утилит кай пишем что добавь пожалуйста новую дисциплину очередей в ту кучу который уже возможно существует к этой дисциплине очереди пожалуйста привет фильтр который будет слушать трафик на виртуальном интерфейсе соответствующим контейнеру источнику здесь оговорюсь и на дальше на слайдах дальше виртуальный интерфейс источников будет виден как 123 виртуальный интерфейс получателя будет виден как 987 просто для облегчения понимания в этом фильтре пожалуйста собирай трафик по всем существующим про таком до которых ты можешь дотянуться также примени пожалуйста к этому трафику фильтр с кодовым названием ue 32 на самом деле это просто служебной аббревиатура ничего за собой не несущие то кроме того что этот фильтр оперирует 32-битными масками пакетов по которым как раз таки и думают перенаправить пакет повзаимодействовать с ним либо пропустить его и фильтры какие-то дальше к этому фильтру пожалуйста принципе action который будет зеркалирование мин на трафик этот экшен опять же есть в утилите traffic control никакой дополнительной настройки тут не ну не нужно это что ты от зеркале ваш перенаправь на сетевой интерфейс вот с таким-то идентификатором получилась вот такая команда в принципе в ней шесть строчек у них достаточно легко можно разобраться если перечитать кучу документации и быть знаком вообще с темой сетевого взаимодействия но мы не могли взять этот способ потому что у нас ребята тестировщики которым предстояло заниматься разбирательством с вот этим зеркалирование это бывшие ручные тестировщик которые еще недавно нажимали кнопки в интерфейсе идут мы им говорим ребят у вас есть волшебные команды которая сделает вам красиво естественно они могли бы скопипастить ее вставить но ничего бы не произошло в дальнейшем когда бы им пришлось повторить этот кейс они бы не смогли разобраться в этой в этой штуковине соответственно несколько причин почему мы от этого способа нам пришлось отказаться несмотря на всю его гибкости возможности первое это банально сложно к 6 строчек команды кучу параметров которые нужно запомнить и в которых нужно разбираться если у них не разбираться то можно все сломать потому что команду предстояло запускать где-то на продакшене а на продакшен мы тестировщиков пускать к не очень хотим тем более с такими возможностями и техническая сторона то что такой способ позволяет от зеркалирование фиг только с какого-то сетевого интерфейса на сетевой интерфейс что не очень пора за что потому что мы хотели зеркальный трафик с адреса будь то хостеле я печник и указывает порт который соответствует нашему сервису этот инструмент нам не подошел я начал искать дальше где же еще можно это где же еще можно взять трафика его отзеркалить вспомнил по так называемый айпи тибблз эта штуковина который обычно используется для построения правила firewall у вас на серверах но у нее оказалось еще одна забавная возможность то что с помощью определенного плагина можно отзеркалить трафик работает она на уровне ти вот тех таблиц которые взаимодействуют с пакетами данных а и позволяют классифицирует допустим трафик либо перестроить какие-то служебные заголовки в пакетах посмотрим как выглядит зеркалирование в рамках этой утилиты мы ее запускаем передаем ей таблицу куда нам нужно добавить наши правила к этой таблице привязываем цепочку каждой таблицы в рамках в рамках такой утилиты соответствуют несколько цепочек в данном случае мы используем при роутинг она говорит о том что запущенное правило будет взаимодействовать со всеми приходящими пакетами еще до принятия решения о перенаправлении этого пакета либо в другой какой-то сервис либо для дальнейшей обработки здесь же мы указываем сетевой интерфейс опять kotova забирать нужно трафик и указываем логин в этой утилите который называется те и который умеет производить зеркалирование указываем естественно адрес назначение куда мы будем наш трафик отправлять получается команда намного проще чем в первом случае это всего три строчки и порой к опций но у неё есть те минусы которые не позволили нам отдать ребятам тестировщиком для того чтобы они начали ее использовать смотрите какие то минусы естественно можно все сломать мы пускаем тестировщика на плод даем ему в руки мощный инструмент айпи ты был с которым у умеет тупо блокировать пакеты и говорим чувак давай ка сделай нам зеркалирование это опасно сломать можно все очень быстро и уронить прот а даже ничего не отзеркалим следую штука что айпи тибблз дает возможность отзеркаливать только в той же сети где находится сам мы не могли за использовать от вариант из за того что у нас наши сервисы крутятся в различных сетях тем более тестовый контуру обычно вообще никак не связан а какими-то жесткими линками с продуктовым контуром начал искать дальше вспомнил что есть и happy дам это огромнейший комплекс утилит который позволяет взаимодействовать с трафиком как с пакетами и делать поистине грандиозные вещи работают он на самом нижнем уровне на уровне драйвер сетевой карты как можно им попробовать отзеркаливать трафик первый же способ костыль некоторый нашелся это сделать файлик pipe то есть кэш в которой тисе пи дам при запуске будет сетевого интерфейса источника записывать пакеты приходя и приходящий в этот сетевой интерфейс в дальнейшем мы должны предусмотреть что в нашем сервисе который заявил он в докер-контейнер мы должны забирать этот файлик извне то есть из где контейнера там его собрал тисе пи да и как-то нашим сервисом обрабатывать то есть парсить этот файл выцеплять пакеты применять на сервис для того чтобы он уже решил как ему работать а мы смогли увидеть хорошо систему у нас себя ведет или не очень способ костыль ней очень кривой но позволяет сделать именно то что нам хотелось естественно в таком виде отдать его тестировщиком мы опять же не могли причины все те же это сложно это непрозрачно потому что нам надо взять какой-то файл построить на его базе инфраструктуру да еще и попросить разработчиков перепрограммировать наши сервисы так чтобы они взаимодействовали с этим файликом ковшом ну и естественно это только локальный вариант файлик послать по почте или пересылать на другой какой-то сервис это далеко не real-time операция нам не хотелось мы хотели видеть все в реальном времени естественно пришлось искать дальше дальше копать интернет и что нашлось в пазов комплекте поставки тисе пи дампа нашлось утилита теперь и плай она работает все так же на уровне драйвера сетевой карты так как по сути внутри у них здесь педантом один и тот же движок и позволяет сделать зеркалирование следующим способом запускаем все тот же тисе пи дам собирают трафик файл говорим с какого интерфейса собрать запускаем еще одну утилиту название которого еще не звучало это тисе перерыть она позволяет собранном дампе пакетов переписать адреса источника и отправителя и запускаем наш ти4 плайк которому говорим возьми вот этот файлик и пожалуйста вот на тот сетевой интерфейс его отправив пару слов о том почему нам пришлось использовать теперь и right мы попробовали способ стесси переплыл на нашем проводе который у нас курицу внешнего хостера внешне хостер забанил над тупо машинку из за того что в пакетах которые на нее из нее начали ходить не соответствует адреса отправителя и получателя наверняка у них настроены какие-то мониторинге на это и они думали что мы их либо ломаем либо деда чем либо сами не понимаем что делаем очевидные минусы которые несет этот способ надо у коми править адресацию какой тестировщик пойдет руками отправить адресацию естественно никакой потому что это делать не хочется это не очевидный способ нам хотелось простого решения еще как выяснилось именно не смотря на название кисть и переплат эта штука не умеет зеркалить и happy протокол это очень странно но нам воспользоваться ей не позволил этот минус и и еще один очевидный из 1 из первой команды запуска тисе пи дамб и это опять же не real-time нам надо собрать файлик нам надо дать этот файлик распарсить опять воспроизвести в реальном времени это все сделать не получится начал копать дальше утилита нашлась похожим названием на предыдущую птицы пели и fly что она умеет она умеет наконец-таки в тисе пи трафик как и сделать зеркалирование достаточно просто запускаем говорим сетевой интерфейс на который отправляет подсовываем файлик говорим адрес назначение говорим ок адрес назначения и говорим о назначении этого трафика достаточно легкая команда всего пять опций очевидно любому даже тестировщику ручника почему нам не получилось ее за использовать тут есть минусы которые достаточно жесткие для нас надо эту утилиту прийти скачать исходники ее собрать соответственно любой точке ролик с этим справится просить помощи разработки devops of обменов и тех технических чуваков которые то естественно могут сделать мы не хотели потому что пробуем сначала все решить своими силами для того чтобы не напрягать остальную команду нас мало сервисов много продукт большой еще один минус что эта штука обновляет сетевые библиотеки при своей установки на продакшене нам не хотелось пользоваться этим способом опять же из-за того что мы боялись все сломать мы стараемся держать свою систему как можно более стабильной и если мы не уверены в каком-то решение то мы стараемся его не применять пришлось искать дальше что еще можно сделать посмотрели с админами на нашу инфраструктуру как она устроена заметили что у многих сервисов стоит им джинкс перед собственно обработчиками потоков трафика в яндекс нашлась интересная возможность это модуль зеркалирование трафика который позволяет его забрать отзеркалить на какой-то другой instance работа с ним достаточно легко вам нужно добавить локейшн на тот путь которого вы хотите забирать трафик подключить модуль и зеркалирование оставив при этом а паровоз трафика на боевой контур за напомню что в коробочке которые зеркале рует трафик это важный момент что бы она не ломал вам боевой поток трафика еще добавить 1 локейшн который будет принимать от зеркалирования трафик добавить ему опцию что он должен собирать ее только из внутренней сети для того чтобы внешние люди не могли нам туда зафигачить какую-нибудь пачку пакетов и сказать что это наше зеркалирование и естественно указать адрес назначения куда нужно это отправлять в принципе легко если бы этот способ нам не подошел тут забегая вперед скажу что это опять же нам не подошла пути это а это возможность можно было попросить body works of добавить вот эти все настройки в джинсы и пользоваться но повысить бы их пришлось каждый раз когда бы нам нужно было перенаправить наш трафик с очередного нового сервиса соответственно есть несколько минусов которые мне озвучены но когда вы опять же не позволили нам воспользоваться этим способом модуль зеркалирование оказался нештатным для того чтобы им воспользоваться нужно было не просто подойти где в общем и попроси добавить лакей шины нужно было попросить их пересобрать нам и джеймс и его перри установить это опять-таки несет определенные риски для продакшен контура еще один минус достаточно не очевидны почему-то при использовании этого модуля у нас в рамках тестовой среды немного проседал производительность погуглив я нашел похожую проблему и выяснилось что вот этот модуль при зеркалирование трафика дожидается ответа от тестовые системы куда он его отправляет и только после этого он взаимодействует с тем трафиком который ходит на бою вносить задержки в боевую систему нам не хотелось потому что мы не могли завести тестовый контур производительностью идентичны нашему production ну соответственно пришлось копать дальше мы перелили кучу различных ресурсов на находили еще каких-то утилит как пример и 4 она позволяет зеркалит трафика работает на уровне драйвера сетевой карты казалось бы идеальная ситуация запуск у нее вообще элементарный говоришь интерфейс которого забирать говоришь про то протоколу которые забирать и вот она все счастье но эти способы не один из таких из такой не одну из таких маленьких утилит нам не позволили за использовать некоторые моменты как пример эти утилиты могли только определенная плата то колы например ешь теперь рай умеет только из степи напомню что в рамках нашего продакшна у нас ходит трафик например попрад обувку соответственно надо зеркалить и себе трафик и это утилита нам бы не помогла и еще множество похожих решений давно устарели пример этой утилиты она не обновлялась пять лет мы не могли ее взять и начать поддерживать у хотя бы из-за того что она не поддерживаю нам протокол не хотелось вкладываться в давно умершей продукт мы готовы были опустить руки но нашлось решение под названием горе play она работает на уровне драйвера сетевой карты это круто потому что вы можете взаимодействовать с пакетами еще до того как они задействуют какие-то софтверные обработчики это утилита достаточно проста в использовании посмотрите на пример команды вы бы запускаете горе play говорите ей адрес откуда собирать трафик говорите адрес и порт куда этот трафик отправлять в принципе и все две опции одна команда с этой штукой справится любой тестировщик можно было отдать ее в руки им для того чтобы они уже запустили зеркалирование порешали все наши проблемы мало того эта штука умеет взаимодействие с пакетами это не просто слепое зеркалирования вы можете например как-то гибко а перестроить заголовок в пакете отправить его дальше либо расщепить трафик приходящий например отправить определенный процент только на ваш тестовый контур чтобы его не положить всем продуктовым объемом но этот способ не взлетел у нас и он не взлетел опять же вот по этим минусом тисе пи трафик как оказалось можно ездить коллировать только платно вкладывать деньги и оплачивать подписку мы не хотели потому что в рамках проекта мы пробуем решать все минимальными ресурсами минимальными усилиями при этом получать максимальный результат еще один минус а эта штука не умеет собирать одновременно с нескольких портов тут тут скажу момент что у нас один и тот же сервис может крутиться в виде нескольких инстансов соответственно нам нужно собирать трафик с нескольких портов одновременно для того чтобы воспроизвести полноценную ситуацию на тестовом окружении горе плай не умеет одновременно собирать нескольких портов у нас была идея за вернуть его несколько экземпляров в один контейнер и этот контейнер запустить для того чтобы он себя но опять же минус против себе не позволил развернуться этой идеи казалось бы все возможности интернета нами perrier и ты ни одно решение не подходит для решения нашей узко специализирован задача но тут нашлась библиотека под названием скапе это давно написанная библиотека на языке питон и на самом деле это целый большой комбайн она умеет все то же что решение traffic control которые мы рассматривали в начале моего доклада то есть она позволяет накладывать фильтры экшен и гибко перестраивать пакеты менять заголовки адреса все что угодно внутри пакетов а также даже данные внутренних все это она позволяет делать с помощью достаточно простого appy appy естественно в синтаксисе питона у нас многие тестировщики опишут авто тесты на этом языке и это решение кажется отлично заходит им при использовании также у этой утилиты есть еще один плюс она под обе версии питона 2 и 3 наши боевые сервера сейчас крутится в основном на третьем но в некоторых сервисах у нас все еще присутствует инсталляции второй версии и поэтому нам хотелось универсального решения которые покроют все ситуации но отдавать в руки тестировщиком библиотеку и просить их писать какие-то вызовы api жки этой библиотеке не хотелось потому что все она остается риск немного сделать не то api много api обширную этой библиотеке как раз таки за счет ее гибкости и многообразие ситуаций в которых ее можно за использовать поэтому мы пошли к нашим devops к нашей команде оптовой который следит за нашими сервисами и сказали ребят смотрите мы перерыли интернет нашли кучу разных способов как мы можем отзеркалить трафик но после анализа ни один из этих способов нам не подошел но ребят мы нашли библиотеку а у нее простой api можете помочь нам написать еще проще штуку для того чтобы мы ее отдали в руки тестировщиком им оставалось нажать буквально пару кнопок ребята сказали конечно мы можем мы же одна команда мы обеспечиваем качество написали нам утилиту которую мы скромно обозвали трафик реплей так как она использую аттикус copy the работает на уровне драйвера сетевой карты умели отёк из copic как раз таки есть бензин гепатита и поэтому наша утилита используют все возможности низкоуровневой работы с пакетами данных смотрите как ее можно использовать утилиту мы по традиции завернули в докер-контейнер поэтому вам нужно а запустить докер порабощать в утиль нету параметр в котором вы скажите адрес источника трафика адрес назначения трафика и передадите массив портов по которым вы хотите собирать трафик и отправлять это не излишнее усложнение а это оказалось филлер кичи нашей утилиты соответственно запускаем утилиту команда достаточно прозрачная для запуска любым человеком а теперь опилим фичах передавая массив портов вы можете сделать например следующие штуки допустим у вас есть порт источник и под на который вы хотите отправить от зеркальный трафик допустим у вас уинстона появляется у сервиса появляется еще один instance естественно это новый порт и новый порт получатель добавляем в массив еще один элемент наша утилита начинают закаливать трафик с двух портов на два порта тестовых еще одна ситуация который можно попробовать сделать это тот самый кейс который не нам не зашел в одном из предыдущих решений а как нам собрать трафик с нескольких продуктовых как портов и отправить его на один тестовый для того чтобы посмотреть полностью всю картинку и освоить все данные которые у нас ходят на параде указываем порт источник указываем второй порт источник и оба этих порта перенаправляем на один и тот же порт получатель круто следующее что можем сделать это ошибиться и указать два раза один и тот же порт источник перенаправив их на один из и тот же порт получатель на самом деле это не ошибка этой утилиты у нас получилось сделать такой квази нагрузочное тестирование потому что она дважды перенаправила одни и те же пакеты одновременно на наш тестовый узел и пока и мы могли посмотреть как же наша система вдруг поведет себя под удвоенной на гору кай мы остановились на своем решении но вот это утилитки трафик replay она показала нам показалось что она идеально покрывает наш тестовый кейсы позволяет решить проблему проблема говорят мы все таки решили мы нашли узкий кейс на продакшен трафике который не был покрыт функциональном авто тестирование соответственно чем можно отзеркалить трафик на рекламной платформе мы зеркальным своей утилитой трафик реплей тут скажу что мы собираемся и и выложить наш корпоративный getjar возможно у кого-то есть тоже сейчас узкие кейсы или появится потом мы хотим чтобы у вас было уже решение под такой случай не смотря на те восемь способов которые опять же вы можете за использовать каждый из них по-своему уникален каждый из них рассчитан на свой набор скиллов ресурсов конечного человека но каждый из них позволяет заточить затащить инструмент который полностью покроют ваш индивидуальный кейс соответственно зеркалит трафик можно практически десятью способами я показал вам как это сделать и предоставил даже еще одну индивидуальную возможность которой пока нет в открытом мире на этом спасибо за внимание я готов ответить на ваши вопросы так история творится сизо-2 за двое суток конференции первый барышни которые 1 подняли руку можно медальку пожалуйста пожалуйста меня зовут света есть 2гис спасибо большое тестовый instance насколько он по железу похож на боевой если очень сильно похож на как вы подняли на него бабла азим но три топора потому что болит смотри он по железом не похож на тот ни разу раз в два в три он слабее немного другая инфраструктура потому что он кажется все на виртуальных машинах вот но бабло нам на это хватило круто спасибо друзья еще принципе тиковый и не про деньги тоже вопрос можно задавать привет привет меня зовут максим спасибо за доклад такой вопрос примере запускается утилита docker контейнеры который находится своей сети не очень понятно как через него должен пройти трафик который будет реплицировать можно сказать какая утилита docker наша даже сама не знаю смотри это всё решено в рамках библиотеки вот этой скапе то есть она отвечает за взаимодействие именно с сетевыми конечного интерфейсами железками вот этой всей подноготной контейнер у нас связан с внешней сетью с помощью сети тм и пробрасываем хвостову учить то есть в сервисах при их запуске мы подбрасываем все эти hasta то есть у вас докер весь у тебя об этом вопрос и по оси вас докер диван запущен так что все контейнеры запускаются на h110 да потому что нам нужно пускать трафик из внешки нас рекламная вот этот контур да он у нас открыт наружу то есть это не ограничен каким-то firewall именно банка у нас две разных сети под банковскую инфраструктуру и личные данные там лежат и вот вот эту рекламу спасибо пожалуйста здравствуйте спасибо за доклад такой немного холивар ный вопрос меня немного смутило проходящие с практической сквозь весь доклад ну цель что вот там первое решение все круто но сложно тестировщику не дашь им все сломает второе решение круто решает все проблемы но тестировщику не дашь им все сломает а потом последнее решение которое вы даете в финально звучит как круто но все сложно тестировщику не дашь все сломает мы отдали это диво псам и они завернули его так чтоб тестировщик не мог все сломать есть фактически кажется можно было остановиться на шаге 1 или 2 прийти к devops вам сказать чуваки мы же одна команда давайте порешаем бизнеса вую проблему и сэкономить кучу времени и вот это вызывает у меня некоторые смущения и вопрос смотри первое решение они позволяют просто их завернуть в тот же контейнер предоставить какие-то простые ручки то есть это так как они под собой имеют достаточно сложно набор там команды опции да то дать простую оберточка опять же был был бы нетривиальной задачей даже nuit de в общем то есть они разбираются они крутые чуваки но завернуть библиотеку на питоне и завернуть тот же traffic control в один и тот же контейнер это две разные задачи по уровню сложности нам хотелось докопаться до наиболее простого и мы надеялись что мы его найдем но и найти не получилось ну в отношении первых вариантов кажется параметризовано и шел скрипт это было бы во он просто не дает протянуть туда лишнего прокидывает это там в условный 10 мир и так далее все мне кажется мы нашли еще одно решение этого вопроса но 9 попытки да вот это смущает немного но спасибо было любопытно какой клевый способ сказать ты молодец еще вопросы хорошо тогда памятные призы обнимашки спасибо спасибо"
}