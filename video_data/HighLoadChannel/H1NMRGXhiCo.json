{
  "video_id": "H1NMRGXhiCo",
  "channel": "HighLoadChannel",
  "title": "Построение современных lakehouse-архитектур с помощью Presto / Владимир Озеров (Querify Labs)",
  "views": 211,
  "duration": 2874,
  "published": "2023-10-06T07:22:22-07:00",
  "text": "раз раз коллеги Добрый день всем спасибо что пришли сегодня мы с вами поговорим про технологию просто про то как она устроено внутри и какое оно имеет отношение к такому понятию как лайфхаусы которая звучит довольно часто и продукты которые основаны на prest или похожих технологиях часто заявляют что они пытаются адресовать именно сценарий использования этих технологий в контексте лайфхаусов поэтому сегодня мы с вами фактически доклад будет разбит на две части мы с вами поговорим что общаясь представляет термин лайтхаусы что за ним скрывается и второе мы поговорим о том как технология просто встроена внутри чтобы понять как эти два понятия пересекаются друг с другом поэтому Сначала мы пройдемся по неким архитектурным вопросам после чего поговорим Пару слов про меня я руковожу компанию фаллапс мы занимаемся двумя двумя вещами первое мы с разработкой школьных движков в частности мы делаем оптимизаторы запросов движки запросов и с фокусом на обработку аналитических кейсов второе мы занимаемся разработкой продукции продукта для российского рынка цедру с дата это Это продукт основанный на технологии 3 на нутриной простят фактически продукты которые некогда появились из одной и той же технологии просто и представляется в распределенность движок Хорошо давайте давайте двигаться для начала чтобы понять откуда взялось понятие надо поговорить про типичные проблемы с которыми мы сталкиваемся при реализации аналитических сценариев обработки данных очень часто в организациях мы видим повторяющийся паттерны когда для того чтобы отрисовать все необходимые сценарии обработки данных организаций имеют с одной стороны дата Лейк То есть это некая файловая файловое хранилище в котором структурированная и неструктурированная информация с которой чаще всего вы общаетесь через парк или какие-то схожие системы с другой стороны в компаниях часто присутствуют одна или даже несколько хранилищ данных которые в России чаще всего представлены технологиями greenplam и clic House и они отрисованы для чаще для реализации реалтаем и отхолок а аналитики и проблема этого подхода заключается в том что вам приходится многократно дублировать одни и те же операционные данные в разных системах вам не очень Вам оказывается не очень просто объединять данные с разных систем например сделать Join между витриной кликаузе и какими-то данными в гринпами не всегда тривиально точно также Вам приходится организовывать довольно сложные и теле и в совокупности это все это все достаточно дорого в обслуживании эксплуатации с другой стороны у нас есть озера данных которые на которые можно было перенести значительную часть это нагрузки но в озера которых отсутствуют транзакции отсутствует как таковая проверка качества данных Поэтому с наскоку все перенести на них тоже не получается Поэтому отсюда и родилась концепция лейкхауза которая по сути представляет собой попытку совместить лучше двух миров от датархаусов и от дата лайков и фактически идея заключается в том чтобы хранить максимальное количество данных в озёрах но при этом добавить в озеро данных тот функционал которого в них изначально не хватало в частности SQL Если вы где-то не хватает это транзакции управление схемами ускорить их если вам вас где-то скорость не устраивает и прочее и здесь важно понимать что лайфхаус - это на самом деле собирательный термин который представляет собой большое количество технологий которые развивались уже много-много лет и просто постепенно пришли к тому что мы имеем давайте давайте проследим за этим Значит если говорить про эволюцию дата лайков то вы знаете что всё начиналось по большому счёту с того что мы просто сохра файлы в распределенном в распределенной файловой системе ходупа и каким-то образом проводим их анализ со временем произошло два интересных события первое очень высокую популярность получили получили облачные хранилище данных на основе S3 то есть Это непосредственно сам быстрее и куча системных сервисов Как облачных так он премис второй интересный момент заключается в том что появилась появилась появился ряд технологий которые попытались привнести транзакционность управления схемами в озеро данных наиболее такое известная технология на текущем этапе является патч Айсберг экономия системы есть пачехуде есть дельта-лейк это всё технологии которые пытаются Ну то есть если мы посмотрим на то как транзакции организована в классических И сколько системах да то мы привыкли что это какая-то ну что это какое-то какая-то подсистема запущенного процесса вашей СВД где происходит управление в Red Hot Logo какими-то другими сопоставления какие-то счетчиков и прочее но оказывается что Если у вас нету цели обрабатывать там колоссальнейшее количество транзакций в секунду как это характерно для LP систем вы хотите делать допустим периодические транзакционные выгрузки данных ваш даталей кто в этом случае сами транзакции можно описать как набор файлов непосредственно самом хранилище просто атомарные эти файлы сопать И тем самым показывать Где на текущем этапе находится актуальные данные актуальные схемы это же позволяет вам делать такую штуку как там Travel то есть смотреть на данные в прошлом и прочее то есть по большому счёту за последние годы появилась появился на технологии которые переносит управление транзакцией Ну по крайней мере их базовая функционал непосредственно в файловые системы Это если мы смотрим на озёра данных если посмотреть на дата вархауза то тут тоже происходит довольно интересный тренд исторически дата вархауза для аналитики представляли собой широты насыпь системы классическим примером является greenplant Да где у вас Где вы стартуете набор узлов эти узлы каким-то образом делят данные и каждый из узлов одновременно и обрабатывается скользные запросы И храни данные такому же принципу следует например Click House со временем к чему пришла индустрия потому что стало появляться все больше больше систем которые дезогредируют вычисления от storeg же такие системы часто называют шерсть storage или сервер Лиз не суть какой-то назовете Но идея заключается в том чтобы вывести хранения данных совершенно Независимый процесс одно из наиболее успешных известных продуктов которые это делают является безусловно Song like Но кроме него есть колоссальнейшее количество продуктов на рынке которые делают ровно то же самое и появляется всё больше и больше и вот этот тренд на отделение компьютер от 40 же мы видим и в OTP системах примеры примером является например э амазона Аврора Неон который берут и массивку Познер тоже отделяют отделяют от всего остального в аналитических системах яблочный сервис и типа Google bequery укликауза буквально недавно появился кликаус Клауд который тоже отделяет сторож от компьютера и это такой тренд который мы в общем видим очень очень активно преимущество главное преимущество этого изменения заключается в том что он позволяет вам масштабировать вычислительные узлы независимо от соржа А масштабирование в ширину архитектурах всегда исторически была очень болезненная проблемой потому что как только у вас появляется новый узел вам нужно каким-то образом перебалансировать данные туда как только у вас уходит узел потому что он упал там или автосерлинг какой-то произошёл вам нужно наоборот восстановить необходимое количество копий данных это все довольно сложный процесс вот если же мы выносим хранения данных вовне то это всё значительно упрощается еще один интересный тренд заключался заключается в том что вендоры могут хранить ваши данные у себя в своих притарных форматах вместе с тем есть Широкая широкий спектр для хранения аналитических данных открытых таких как паркет.org и соответственно можно попытаться эти данные соответственно вашего дата вархауза хранить не не в формате Data warhouse А в открытом формате и примером такой системы является как раз таки Press T3 на которых очень хорошо работает с такими форматами Это следующий шаг ну и наконец еще один интересный тренд что сюда же мы можем потенциально привнести управление транзакциями если вас воспользуемся воспользуемся все теми же технологиями а подчас беркуте и другими то фактически окажется что для того чтобы организовать дата вархаус возможно в самом именно дата вархаусе можно ставить только только под систему вычисления обработки запросов в таком случае конечно такую систему можно с натяжкой назвать дата вархаусом потому что она по сути только обрабатывает запросы но технологическая зрелость такова что на самом деле это становится реальностью потому что под систему хранения и под систему управления транзакциями схемами можно вынести в отдельно Облачное хранилище вот таким образом мы видим что и дата лейки и дата вархаус они примерно пришли к одной и то же постепенно приходят к одной и той же архитектуре когда данные у нас хранятся отдельно в hdface и воскрес совместимом storage Если вы эти данные храните в открытых форматах таких как парке торг то вы можете организовать одновременно работу с этими данными из разных систем Если вы хотите запускать какой-то сложный или ваш простенького туда подключаете Спарк Если вы хотите делать Real Time аналитику или отскок аналитику вы туда можете подключать такие как раз как простые трина И тем самым вы уменьшаете количество копии данных Вы можете организовать совместные изменения этих данных с помощью таких технологий прочих И тем самым вы значительно снижаете расходы на вашу инфраструктуру поэтому этот который довольно активно шагает уже много лет но очень важно понимать что само понятие Лейк Хауса но не оно не взялось из ниоткуда А Скорее это просто результат технологического развития многолетнего разных технологий которые со временем сошелся именно в таком видении Когда у вас есть дешевый сторож к которому вы подключаете разные системы под разные типы нагрузок соответственно Теперь мы переходим к тому что есть просто и какое оно имеет отношение пресс-3 на это два конкурирующих проекта которые на самом деле родились из одного проекта пресса который был опубликован Facebook в 2013 году и проект представляет собой фактически распределенный скольный движок То есть он только исполняется запросы них они данные поэтому его архитектура довольно простая трина это forkpress который появился примерно в 2019 году когда там произошел определенный конфликт и сейчас эти два проекта живут отдельно просто больше развивается вендорами типа Facebook убера и прочими для своих целей 3 на это больше такое народное что ли Народная реализация у которой есть очень активно комьюнити и часто в обычном бизнесе можно встретить именно 3 на идея заключается в следующем Что престотрина представляет собой Просто набор узлов которые исполняется запросы и которые могут работать с разными источниками данных основной из кейс который они пытаются рисовать эта работа с озёрами данных безусловно Но вместе с тем Вы можете подключаться и к ltp системам и коллапс системам и даже к новой Сколь системам довольно экзотическим типа там монго тебе или там даже Кафки можно подключить там к чему угодно если хотите можете сами свои плагины сделать а то есть она принимает данные через специальный интерфейсы коннекторов отдаёт данные через GPS что позволяет вам интегрировать эту систему себя и утилитами с любыми системами которые общаться через gdbc и прочим и прочим в основе всей этой идеи лежит понятие плагина то есть плагина это некий функционал это ряд интерфейсов которые вы как разработчик можете заимплементировать подложить в поставку просто литрина и они подхватятся и добавит какую-то функционал и основным компонентом плагинов является коннектор коннектор это как раз таки набор интерфейсов которые объясняют как работает с конкретным источником данных как нему подключиться как получить из него статистики для планирования запросов Как вытащить из него Данные Можно ли данные из этого источника как-то побить на независимой части чтобы обрабатывать параллельно на все эти вопросы отвечает коннекторы ну и наконец есть понятие каталог каталог это просто абстракция абстракция подключение коннектору конкретному инстанцию БД например Вы можете иметь коннектор для поиска из него сделать каталог который подключается к этому инстанцию поиска вместе с системой сделать каталог который подключается гренлан потому что они совместимы на уровне протоколов это основные понятия как просто устроен внутри Престо есть то есть просто предполагает что вы стартуете один или более процессор который формируют кластер в этом кластере существуют две основные роли узлов первая роль называется координатор задача координатора принять дисквалильный Запрос который вы отправили в просто его спланировать и запустить на всех имеющихся ресурсах кластера каким-то образом скоординировать его исполнение есть worker worker - Это непосредственно Рабочая лошадка пресса который исполняет запросы оркеры могут обмениваться данными друг с другом могут обмениваться данными с координаторами но в совокупность это формирует массивно параллельный движок который пытается исполнить Запрос который вы к ним отправили с помощью большого количества процессов и большого количества потоков условно соответственно всё исполнение запросов можно разбить на две фазы это планирование запросов и исполнение запросов планирование в Пресс организовано достаточно классическим образом То есть все все начинается с парсинга который преобразует из школьный Запрос который вы отправили синтаксическое дерево реализовано это с помощью партирогенератора антлера Ну по ссылке можете ознакомиться с грамматикой далее после того как мы получили синтаксическое дерево происходит шаг семантического анализа Это первый этап на который подключается коннекторы То есть когда вы отправляете запрос в этом запросе могут фигурировать разного рода объекты такие как таблицы колонки вьюшки схемы функции какие-то соответственно коннекторы позволяют просто узнать какие таблицы схемы доступны в текущем момент Кроме того через коннекторы Вы можете добавить даже кастомные функции в движок поэтому На данном этапе просто активно общается с коннекторами для того чтобы понять какие объекты доступны И вообще этот Запрос который вы отправили Можно ли вы в принципе исполнить или нет далее после того как мы провели семантическую валидацию в работу вступает оптимизаторы запросов первое что он делает это трансформирует синтаксическое дерево в дерево реализованных операторов это внутреннее это базовая внутреннее представление просто на основе которого происходит вся дальнейшая оптимизация запросов далее после того как мы получили реляционное дерево просто существует порядка 80 независимых фаз по последовательной оптимизации запросов то есть на каждой фазе происходит попытка постепенно улучшить план запроса то есть на каких-то шарах мы пытаемся допустим упростить выражение или вывести какие-то константы на других шагах мы пытаемся сделать фильтров на следующий шагах мы пытаемся сделать пуждал вычислении в коннекторы и прочее прочее таких шагов на самом деле насчитывается если не совру в последней версии порядка 86 что ли Вот это довольно сложный процесс работе тем не менее он именно он обеспечивает достаточно эффективное выполнение запросов здесь я остановлюсь на некоторых особенно важных шагах которые тут происходят первое важно понимать что просто Что оптимизаторы просто представляет собой так называемый рулбест оптимизатор Это значит что возможные оптимизации реализованы не большим монолитным куском кода А реализованы как маленькие независимые реализации определенного интерфейса руль который позволяет вам фактически сказать что если в дереве мы увидели Вот такой-то паттерн например проекция над оператором joina То можно применить такую-то оптимизацию Вот и этот подход обуславливает довольно быстро эволюцию и постоянное улучшение в оптимизаторы которые могут делать как разработчики просто так и даже вы как разработчики коннекторы и это разительно отличается от систем которые не используют реляционное представление с оптимизацию потому что в таких системах эволюция оптимизатора она как правило значительно затруднена А уж речь о том чтобы какие-то оптимизации могли делать Даже сторонние разработчики не идет Вовсе и здесь же это все довольно хорошо абстрагировано поэтому даже вы как разработчик мой имеете возможность вставить со стороны дополнительные правила оптимизации если посчитаете это необходимым далее очень важно оптимизация пресс является безусловно планирование джойнов то здесь на самом деле используется достаточно стандартный подход когда создается так называемая таблица таблицы динамического программирования которая для всех наборов для скажем так всех возможных которые пытаются перебрать все возможные порядки джойнов избегая какие-то заведомо не оптимальные такие как рост жены и пытается последовательно найти для каждого для каждого класса эквивалентности наиболее оптимальный порядок И тем самым мы снизу вверх формируем наиболее оптимальный порядок джойнов то есть это довольно классический подход который можно встретить в том или виде там в пострессе Мы сиквеле в других системах здесь интересно то что На этом этапе также очень активно используется интерфейсы коннекторов потому что они коннекторы позволяют просто получить информацию о статистиках тех или иных операторов Например если вы делаете сканирование таблицы в datalike то можно вытащить статистики из файлов паркета или орка который говорит о том сколько сколько партийшинов у вас есть какие есть какие есть Колонки можно посчитать индивидом и прочее то же самое некоторые статистики можно потянуть из из мастику и прочего поэтому здесь статистики являют имеют критические важные значения для нахождения оптимального порядка другая очень важная оптимизация присутствует prest это так мы динамические фильтры идея заключается в следующем очень часто мы делаем joina между таблицей фактов и таблицей измерения и у нас имеется очень высоко селективный фильтр на таблице измерения Ну например мы джоним таблицу продаж с таблицей времени Ну допустим вот Как это сделано в типе сидистом сети и говорим что ну или Давайте Так мы джоним таблицу продаж с магазинами допустим где проходили происходили эти продажи и мы добавляем условие что мы хотим получить все продажи по конкретному магазину В этом случае условия присутствуют на таблице измерений Но что мы можем сделать мы можем Сначала это условие применить таблицы измерений а потом собраться статистики по тем данным которые мы получили и используя Join используя кондишен эти статистики перевести на другую сторону таким образом сформировав фильтр который мы применим к таблице фактов в ранены если этот фильтр применим в рантами то есть шанс мы просканируем гораздо меньшее количество данных Например если в нашем примере таблица продаж партиционирована по магазинам и мы из таблицы dimensional узнали конкретные магазины которые Нас интересуют то мы можем отсканировать только те Partition только те партии в нашем батарейки которые содержат необходимые данные вот поэтому эта оптимизация имеет критическое значение Особенно для федеративных систем которые подтягивает данные данные из разных источников и в простона реализовано достаточно эффективно и наконец Еще одна очень важная оптимизация это так называемый коннектор по ждал вводе заключается в том что вы что мы можем попытаться запушить Как можно большее количество вычислений непосредственно в коннектор то есть Представьте что мы хотим просканировать таблицу в погреce и применить к ней какой-то фильтр мы можем вытянуть все данные из этой таблицы просто и только потом применить фильтры или же мы можем попытаться запушить этот фильтр непосредственно в возрасте соответственно есть набор интерфейсов которые позволяют на уровне коннектора реализовать такую такой пуш и это особенно активно применяется в тех коннекторах во-первых которые работают с озерами данных здесь наиболее часто применяемые оптимизация это Partition rooming То есть если вы фильтр запушили в Ваше озеро данных Вы можете отсканировать гораздо меньшее количество информации и это может и это применимо как допустим к таблицам которые хранятся в паркете здесь же просто он может использовать какой-то специфичную функционал конкретного сторожа Например если вы храните данные в амазоновском ис-3 то быстрее есть такое понятие как ис-3 Select это специальный сервис который Вам позволяет тоже фактически запушить вычисление в S3 и получить только части данных из него соответственно 3 на может пресс-3 могут использовать такую функцию в том числе и второй очень важный кейс это пуждал вычислений в коннекторы которые работают через gdbc Интерфейс это большая часть популярных коннекторов То есть это коннекторы по воскресу и прочими системами Это позволяет опять же значительно снизить количество данных которые поступают в пресс для обработки то есть суммарно вот это наверное три самая главная оптимизации которые присутствуют в PS3 на Но кроме них как и сказал Есть огромное количество других оптимизаций Эх хорошо Теперь давайте переходить к тому как просто выполняет запросы Как как мы уже проговорили просто это массивно параллельный движок для выполнения для выполнения запросов идея заключается в том что тот Запрос который вы предоставили изначально бьется на независимые фазы границами границами как правило являются операторы которые требуют пересылки данных кластере на примере Если вы делаете агрегацию для того чтобы посчитать агрегат распределенным кластере вам часто надо перераспределить данные Согласно ключевой агрегации точно также Если вы делаете джойн очень часто требуется перераспределить данную и прочее прочее поэтому в общем случае сложно аналитические запросы бьются на достаточно большое количество независимых фаз которые в просто называются Stage и в дальнейшем исполнение тексты Джей происходит Независимо друг от друга и соответственно эти стоит же обмениваются друг с другом данными через сеть то есть данные напрямую пушится из одной стыджи в другую Это довольно это по сути является таким ключевым принципиальным отличием мастера параллельно движков от движков которые основаны на парадигме мап redews или или движка Спарк Ну тут может быть на складе не всем корректно Спарк с натяжкой можно назвать мат редисом Но идея заключается в том что движки для обработки больших данных типа ходов из парка они работают очень схожим образом они тоже бьют запросы на отдельные фазы Будьте там придётся или какой-то или как в парке как Спарки направлены но они обмениваться данными как правило через диск Это обусловлено тем что обычно через парк мы запускаем задачи которые должны перемалывать очень большое количество данных которые часто в памяти не влезают и более того если у вас исполнение Spark jobe допустим которое должна работать много часов какой-то из узлов отвалился где-то в середине вы не хотите все это делать перезапускать с нуля Если же мы говорим про NP движке И в частности про Престо то они больше направлены на отхок аналитику и на real-time аналитику в которой запросы довольно тяжёлые но тем не менее они не бегут часами Да они как правило бегут там секунды минуты и в этом случае если какой-то из узлов отвалился в процессе исполнения то ничего страшного чаще всего мы можем перезапустить этот запрос точно так же э количество данных частота того что оно полностью влезает в память кластера Поэтому в случае с прессом диск мы диск для обмена данных между стадиями не используем Вот Но тем не менее Вы можете видеть что на самом-то деле э эти две парадигмы очень-очень схожие более того FPS это присутствует далее после того как мы получили независимые стадии исполнения запросов что мы делаем эти стадии распределяем по конкретным узлам и соответственно множество узлов просто могут одновременно выполнять тельные стадии обмениваться данными друг с другом именно этим самым и обеспечивается та самая массивно параллельное обработка данных далее Еще одна очень интересная концепция которая используется в Престо это понятие сплита Сплит это Независимый кусок информации из коннектора который может быть обработан отдельно от других кусков Например если мы работаем с озерами данных У вас есть какая-то таблица допустим в паркете которая протекционирована потому или иному атрибуту то каждый отдельная партиция может быть обработана Независимо друг от друга в таком случае нам удобно выставить такую порцию Как если это обратиться очень большая может быть мы хотим даже эту партицию поделить на отдельные сплиты такой же подход применимый под потенциальных другим и другим коннектором И тем самым разбивая изначальную изначальную таблицу на независимые куски мы можем обеспечить их параллельное исполнение на различных воркерах Независимо друг от друга и опять же это является ключевой это является ключевым функционалом пресса который обеспечивает именно параллельную обработку больших объемов данных Независимо друг от друга и что интересно что опять же реализация этого функционала вынесена в коннектор То есть если вы делаете собственный коннектор то вы можете управлять тем Каким образом данные которые из вашей системы поступают в Пресс это будут биться на части И тем самым фактически управлять уровнем косвенного управлять уровнем параллелизма исполнения но опять же главные кейс здесь это всё-таки работа с озерами данных здесь по полной используется все возможности файловых форматов паркет по разбиванию данных на партийцы и даже на разбиение чтения файла на отдельные куски далее внутри просто обмениваются данными между операторами в процессе исполнения с помощью объектов которые называются page внутри так как просто нацелена на обработку аналитических сценариев то она использует колоночные внутри она используют колоночный формат потому что он Хорошо подходит для выполнения например агрегации и поэтому что происходит что каждый обмен данных между операторами или между стрижами представляет собой обмен объектом Пейдж который представляет собой набор колонок то есть там и каждый колонка она абстрагирована интерфейсом блок из-за блока может скрываться допустим колонка может быть может скрываться колонка типа string может даже скрываться какая-то допустим колонка с данными типа string который применил дикшнаренкодинг то есть там может быть абсолютно что угодно это тоже довольно любимой части просто и здесь на самом деле внутренний формат вот этих блоков он если Вы посмотрите Очень напоминает например такую популярную систему как Апач эру то есть эру это Открытый формат обработки и хранения данных солнечного формате и внутри просто на него очень похож но непосредственно Он не реализует далее сами операторы просто реализуют так называют так называемую пуш модель выполнения Это означает что координатор сначала определяет набор сплитов которые конкретно стадия исполнения будет обрабатывать эти сплиты приходят на узлы воркеры после чего операторы исполняются снизу вверх на данном примере Мы сначала получились плиты из источника потом применили к ним какой-то фильтр потом применили проекцию потенциальные Join агрегаты и прочее прочее на каждой такой фазе операторы принимает один Пейдж и отдает другой как сказал просто набор колонок все это по умолчанию происходит в памяти вот поэтому здесь просто реализуют достаточно классическую так называемую push-модели выполнения если вам интересно более подробно почитать например описывает что не такая же модель и раскрывает ее преимущество но в целом большинство современных искоренных движков они работают ровно таким же образом и поэтому здесь но опять же ничего Сверхъестественного спроса нету Далее в Престо так как Просто приходится обрабатывать большие объемы информации то конечно очень важным вопросам является вопрос управления памятью и здесь идея заключается в том что на уровне всех воркеров и или на уровне конкретного запроса можно установить максимальный лимит памяти который будет будет потреблена если Запрос который вы исполняете превышает данный лимит то происходит отмена данного запроса потому что противном случае это может привести к нестабильной работе узлов или даже к их падению из возникновения аутов Memory и это как раз ровно то место про которое мы говорили ранее что так как мы по умолчанию с диском не буддистам то такие ситуации могут возникать Поэтому при использовании преста конечно необходимо грамотно оценивать Сколько памяти вам будет требоваться в Спарки такая проблема стоит менее острых она тоже есть безусловно Да ну так как Спарк заточена работа с диском то там то диски у нас чаще всего имеют значительно больший объем чем оперативная память вместе реализован так называемый функционал спиннинга на диск идея заключается в том что если вы исполняете запрос у которого есть какая-то квота на использование памяти и так вот оказалось превышенная то вы можете опционально сконфигурировать такое поведение что запрос будет и дальше аллоцировать все больше и больше памяти но если суммарно в системе память закончится то вот эти блоки которые были алоцированы сверх лимита система может принудительно выгрузить на диск и фактически здесь этот спиннинг это не какие-то умные алгоритмы Когда вы знаете не какие-то умные алгоритмы там exturnal сорта или там как каких-то хэш таблиц которые хранятся на диске нет в данном случае так как все вся информация которая необходима для исполнения запросов хранится в виде пейджей то это для всех данных которые в этих пиджах находятся реализованные функционал стерилизации здесь реализации поэтому что происходит что если в память в системе заканчивается то просто просто приходит в тот или иной оператор И говорит ему выгрузи все данные которые у тебя есть на диск и происходит соответственно выгрузка этих самых PJ впоследствии когда этому оператору потребуется продолжить исполнение может выгрузить других операторов загрузить обратно ну и прочее Понятное дело что для производительности это не очень хороший подход но если вам очень хочется обрабатывать если у вас возникают сценарий когда всё-таки надо обра такие запросы когда памяти не хватает Вы можете его использовать Но конечно производительность в этом случае будет значительно снижаться но тем не менее как я уже говорил в просто присутствует определенные зачатки такой более интеллектуальной работы с диском если нам не хватает памяти далее ну и Последний из интересного что из пресса это компиляция мы знаем что в ОТП системах очень частое исполнение запросов происходит Ну так называемом интерпретируемом режиме и проблема здесь заключается в том что когда вы как разработчик с OBD делаете оператора то вы не знаете Какие конкретно запросы будут к вам приходить Да поэтому вы делаете какие-то абстрактные реализации которые говорят допустим да мы будем делать агрегат в этом агрегате Может быть там сколько-то колонок типа данных мы там не знаем там и прочее поэтому Когда речь доходит до исполнения таких операторов это очень часто если посмотреть на то как движки устроены внутри то там возникает большое количество накладных расходов из-за того что разработчик момент разработки продукта не знают какие именно данные будут приходить в частности происходит разного рода проверки типов происходит виртуальные вызовы Потому что часто Мы стараемся скрыть разные типы данных из интерфейсами и прочее прочее и в для того чтобы эти накладные расходы убрать можно использовать так называемую justime компиляцию то есть эта компиляция прямо в процессе исполнения запроса когда мы зная Какие конкретные типы данных и колонок присутствуют в данном запросе мы можем создать узкоспециализированную реализацию того или иного оператора будет агрегат Джона или сортировка конкретно по данной запрос проблема заключается в том что компиляция Это довольно дорогостоящее удовольствие поэтому допустим таких продуктов как постгальцы она очень часто подключена по умолчанию в руководствах вам пишут что если вы включаете Будьте аккуратны потому что перформанс может упасть где-то Да если мы говорим про аналитические системы которые нацелены на обработки больших объемов информации то здесь чаще всего ситуация обратная мы сегодня с того что допустим у вас есть оператора который делает агрегацию ему нужно перемолоть много-много миллионов строк вот поэтому мы по умолчанию считаем что компиляция Будет нам полезна мы и поэтому для каждого запроса мы можем сделать такую узкой узкоспециализированную пигментацию которая минимизирует накладные расходы И тем самым значительно ускоряет допустим значительно ускоряет исполнение оператора Поэтому в аналитических движках компиляция часто по умолчанию включена велосипедная по умолчанию выключена в Пресс она по умолчанию включена и так сам просто написано на Джаве то она Ну эта компиляция фактически там реализована с помощью фреймворка который называется ST он фактически прямо в рантами формирует бойт-код который для конкретного оператора который скармливает машину и получают уже непосредственно исполняемый код для конкретного оператора вот опять же Это довольно такая тривиальная что ли для современных аналитических движков штука Вы можете встретить Практически везде но тем не менее просто есть имеет очень важное значение для производительности вот поэтому в принципе ну по таким основным по основным компонентам планирования исполнения мы прошлись в пресс туда и в заключении да хочется проговорить типичный сценариев которых просто используется наконец-таки возвращаясь к теме лайфхаусов значит в принципе я бы сказал что просто и трина на текущем этапе используют в трех характерных сценариях Первое Это непосредственно работа с озерами данных То есть вы берете просто у вас есть где-то запущенный метастор и у вас есть какое-то распределенное хранилище в которых хранятся таблица в сыром виде или в паркете Горки или других формате аура и прочем и соответственно Вы можете исполнять школьные запросы к этим таблицам если вам если вы видите что запросы работают не достаточно быстро Вы можете масштабировать кластер просто добавлять него больше узлов при этом совершенно не затрагивая под систему хранения это базовый сценарии которые вендоры которые используют пресс-литрина и мы в том числе которые счита основным для данной системы Именно поэтому мы именно поэтому просто очень часто витрина рассматривать именно в контексте лайк хаузов да то есть как некая некая технология которая дополняет весь Спектр решений которые относятся мощным исковальным движком второе второй сценарий который тоже довольно важный это так называемая виртуализация данных он заключается в том что вы подключаете Просто не только к этому источнику например к озеру данных но и другим Ну и другими системам например Вы можете объединить данные из вашего озера данных с какой-то витриной в кликхаузе Вы можете подтянуть из допустим какую-то таблицу измерений которая допустим которую вас отсутствует в Data like но которое время от времени изменяется И это тоже довольно распространенный случай который довольно часто используется на практике ну и наконец еще один интересный случай который мы здесь на слайде не понятен это то что мы видим тренд на то что так сейчас можно довольно легко получить доступ к мощным машинам в Облаке то часто сценарием является Такой сценарий Когда вы как аналитик своё распоряжения мощный сервер какой-то выгружайте какую-то часть информации из вашего корпоративного из вашего корпоративного хранилища и производите Независимо изолированные анализ этой информации как только вы закончили вы просто бросаете эту машину отдаете обратно в облако и все И про эти эксперименты забываете и на текущем этапе Интересно что появляется новые технологии которые которые стараются оптимизировать оптимизированы Именно под этот изолированный анализ рамках одной машины одно из такой интересных технологий является технология так тебе я к сожалению забыл указать на слайде но и просто тоже витрина является достаточно интересными кандидатами для этого когда вместо того чтобы стартовать какие-то сложные кластера делать распределённые вычисления вы просто берете одну мощную машину запускаете там движок который может утилизировать все CPU ресурсы а данные храните допустим локальные файловая система на время этих экспериментов поэтому все вот эти кейсы анализа данных но они их довольно хорошо поддерживаются престареи на и это обуславливает достаточно высокую популярность этих продуктов в реальной жизни вы можете увидеть использование PS3 на во многих Облачно у многих облачных вендоров если говорить про Ну например там озона Финна это Старпер Galaxy это все примеры продуктов которые поверх облаков позволяют стартовать просто автостелить их там стартовать просто или три наделать автосервинг узлов и прочее вот поэтому на этом в принципе все Ну время нас уже вышло Давайте заканчивать Да спасибо доклад очень интересный Мне прям было очень интересно послушать я люблю Тему дата лайков ваши вопросы вот пожалуйста надо время Спасибо действительно очень интересно даже микрофон да Вопрос такой если мы возьмем например Green Plan там есть известная вещь которая в принципе позволяет создавать Table и прочее какие-то особенности пресса можно там считать преимуществе по сравнению Это очень хороший вопрос потому что есть теперь XF И вообще вот функционал когда из одной системы можно подключиться к другим он еще там Ну ему Сто лет в обед правильно это там еще и возгласов рэпер это можно что угодно использовать вот идея заключается в том что именно знаете в по большому счёту специализации То есть когда вы много-много лет вкладываете усилия в один он начинает работать очень хорошо то есть Т3 на реализована огромное количество оптимизации по работе с вот этими форматами данных допустим в паркете появилась такое понятие как индексы Да с PS3 на появился функционал который может эти индекс использовать для более эффективной обработки данных и таких оптимизаций происходит очень-очень много То есть если Вы посмотрите на историю изменения коннекторов к допустим дата лейкам в трина то там идет просто колоссальнейший объем постоянных оптимизаций все время потому что для них это основной кейс Если же мы говорим про pxf Да тут XF это больше функционал который сделан ну скажем так в сторонке к основному функционалу Гримм Да и поэтому если вы и поэтому в него просто вкладывается меньшие и если вы вкладывать меньше усилий то выпасть то вы со временем отстаете по функционалу и производительности Поэтому если вы запустите план с одной стороны и запустите и просто конкретно для кейсы работы лэйками то и производительность у просто трина будет выше вот ну то есть поэтому здесь никаких никакой магии нету тут речь только про количество усилий которые вы в это вкладываете просто три на изначально под этот кейс оптимизирован поэтому они в нём работают Хорошо давайте дальше Давайте вот сюда я потом нужно будет выбрать лучший вопрос И спасибо за подарок вот вопрос такой часто аналитики работают не только там с данными которые поместится в память да И иногда бывает что там и тяжелый запрос надо запускать вот так такой вопрос Вот мне кажется если аналитик будет ну там работать пресс и у него там запросы будет быстро выполняться но часто будут падать он лучше выберет какой-нибудь там Спарк который будет помедленнее бежать но будет все выполнять вот как держать такой баланс и решил вы знаете Это тоже очень хорошо вопрос и тут Ну к сожалению универсального Ответа нет Если Вы посмотрите как действует индустрия то есть набор продуктов например есть продукт боль есть Alibaba Господи либо под двх не помню как точно называется который как раз таки пытаются совместить просто из парка Ровно той цели что иногда Спарк работает хорошо когда данных очень много надо такую батча обработку сделать Иногда просто работают хорошо когда данные влезают в память Вот и универсального решения к сожалению нету да поэтому часто эти продукты пытаются скомбинировать и с одной стороны иногда ответ это знаете часть ответ ну поэкспериментировать и сами решите где Это удобнее Ну чаще всего ответы на такое К сожалению да То есть вы сами вы сами определяете Какой продукт вам удобен для конкретного случая в Пресс есть одна очень интересная инициатива когда они пытаются делегировать исполнение запросов Спарк то есть и дело прямо сейчас вот буквально там месяц что ли был очередной релиз этого функционала Когда вы отправляете запрос в Пресс но бэкэндом является Спарк вот ну это ну звучит довольно конечно кривая кстати есть но тем не менее К сожалению простого ответа на ваши вопросы нету это надо экспериментировать для этого случая одно для другого другого поэтому здесь универсального Ответа нет но вместе с тем важно понимать что по крайней мере базовый функционал работы с диском есть в пресс туда Поэтому если вы допустим оказываете оказываетесь в ситуации что в целом воспресс устраивает но нет нет какой-то запрос отвалится то можно сконфигурировать систему таким образом что в этих случаях запросы не будут падать будут просто медленнее работать Давайте еще один вопрос успеем я думаю Давайте вот в этом крыле мы не спрашивали друзья Добрый день Меня зовут Николай Я хотел спросить а как вот просто и утрина обстоят дела с расширением написание своих каких-то функций или нет Это как Просто делать расскажите пожалуйста смотрите дела В принципе обстоят смотрите дела обстоят довольно неплохо потому что вы можете через есть понятие плагина чаще всего плагина чаще всего плагин считают синоним слова коннектор да то есть коннекторы там нечто что коннектится к другому источнику на самом деле плагин это гораздо более широкий интерфейс в котором вы можете предоставить собственные функции Вы можете даже там собственной таблицы какие-то системные предоставить если хотите там отображать допустим данные которые данные можете процедуры добавить там то есть на самом деле там довольно широкие функционал и более того в документации довольно неплохо описаны даже примеры есть даже прямо тестовые проекты которые сам пресс-3 на публикует который показывает как можно там тестовый коннекторы сделать тестовые функции какие-то сделать Поэтому в принципе это всё работает довольно неплохо вот по поводу фак знаете вот Я на практике просто сам не делал затрудняя сходу ответить рекомендовал в документации посмотреть по моему девки есть но не хочу собрать теперь проверить Да это надо писать на Java Совершенно верно лучший вопрос Какой знаете Давайте про prespark как самый каверзный и болезненный Здесь был Включите пожалуйста приз также Мы благодарим тебя и вручаем тебе памятные подарки от организаторов конференции Спасибо доклад был хороший Я вижу вопросов еще много Вы можете поймать Владимира прямо здесь на выходе и все их задать Спасибо Спасибо"
}