{
  "video_id": "osJcE2d4ymw",
  "channel": "HighLoadChannel",
  "title": "Достигаем субмиллисекундного времени отклика в торговой системе на Java под Linux / Алексей Рагозин",
  "views": 2771,
  "duration": 3114,
  "published": "2019-05-15T02:42:07-07:00",
  "text": "добрый день коля они рогозин и видеть название моего доклада но чем длинная оригинальное название была борьба за миллисекунды но если бы я его оставил тогда бы расписание богу совершенно непонятно чем я буду рассказывать поэтому решил сделать таким длинным рассказывать я буду микросекундах вот в каком контексте я долгое время работал финансовой индустрии в инвестиционном банке и когда вы слышите слова банк java вы на ум приходит энтерпрайз такой немножко скучноватой занудной так вот на самом деле я не знаю что вы можете понимать под словом java enterprise но как бы те решения которые применяются в области электронной торговли они во многих аспектах очень сильно отличаются от того энтерпрайза на котором вы могли слышать поэтому мне захотелось сделать такой так вот чтобы вот на примере задачи достижения но время отклика фото торговой системы проиллюстрировать некоторые паттерны некоторые трюки которые используются в этой области конкретно при реализации на платформе java для операционной системы linux и так низко и время отклика что я под этим подразумеваю ну первое что приходит на ум может быть это ультра улетаете high frequency трейдинг это не то про что я буду рассказывать когда мы говорим про high-frequency трейдинг там речь может идти на единицы десятки микросекунд и но надо понимать что как бы торговля это заключение сделок между контрагентами как бы контрагента это как правило разные сервера если это разные сервера ту у вас там есть на торг поэтому high-frequency трейдинг означает что сервера всех контрагентов стоят очень близко между ними специально сетевое оборудование заточенная под низкая время отклика и как бы это совсем другая история да в определенных видах торговли там в специально оборудованных дата-центрах там вокруг биржи по кругу стоят сервера чтобы обеспечить минимальное время отклика там да там действительно речь идет на единицы микросекунд и там немножко другие проблемы рилтайм еще один такой термин он как правило означает очень медленно но зато гарантированно тоже не про нас white in this сенситив систем этой системой критичных время облику это как раз сто про что я буду рассказывать откуда появляются такие требовали то есть принципе торговля какими-то финансовыми инструментами она начинается с того что появляется рынок появляется спрос первые сделки заключаются по телефону потом появляется электронная торговля потом в какой-то момент может появиться конкуренция может появиться действительно борьба кто первый быстро это нужную цену здесь как правило речь идет не не всегда у биржевой торговли и речь идет о том что контрагенты находятся в рамках одного города но не в рамках одного то этот центр не в рамках одного свеча там по определенным причинам то что не нет не такая ликвидная торговли и так далее и в такой системе у вас время транзакции она будет измеряться миль и секундами но надо понимать что вот эта транзакция она включает себя много компонентов между которыми тоже есть network если вы в каждом компоненте будете терять на своей стороне там 200 и 500 микросекунд то в итоге по общему счету вы завод все время выполнения этой транзакции на стороне вашей компании потеряете несколько миллисекунд и можете отстать от своих конкурентов поэтому как бы чтобы экономить миллисекунды в intent процессинге транзакции нам надо вытачивать все компоненты убирать с них лишний сотнями микросекунд чтобы как бы мы могли выжить все что можно при условии что мы работаем на обычном железе на обычном сетевом оборудовании на обычные операционной системе и наконец последний последние четверть этого квадратика низко и время отклика подразумевает под самым было логично что если у нас транзакции работают быстро можем ножем amx обработать много но это разные задачи то есть зачастую если у нас задача обработала обработать большой объем транзакций то оптимизация пропускной способности системы она как раз достигается в ущерб низкой задержки и система с низкую задержку очень часто могут быть не сильно нагружена как бы там может быть система какая то какой-то бизнес по которому у вас проходят сотни сделок в день но каждая из этих сделок она приносит вам такую прибыль что стоит побороться с конкурентами и выдать свое предложение на миллисекунду быстрее чем они ok это к вопросу откуда берутся такие требования что из себя представляет система электронная торговля но вот это торговля эта транзакция как бы это прежде всего бизнес-логика то есть нам надо обработать заявку применить какие-то правила нам надо обеспечить что все эти данные не потерялись обычно в такой системе есть особенно если мы говорим о бы чисто электронной торговли у нас есть критический путь который мы должны пройти чтобы заключить сделку чтобы зафиксировать плюс у нас еще есть достаточно большое количество интеграции которые находятся не на критическом пути или для которых время задержки не так важно то есть например если мы хотим считать финансовые риски в реальном времени то мы должны получать информацию оперативно прямо напрямую из торговой системы но сам по себе расчет финансово резко он занимает некоторое время он занимает миллисекунды потому что там сложно и вычислительной модели и так далее это здесь нам как бы не надо гнаться за прям минимальным временем отклика но тем не менее обеспечивает оперативную выдачу информации в такие второстепенные системы тоже и так значит когда мы хотим уменьшить наш бюджет по времени на точно вписаться в наш бюджет по времени на выполнение транзакции без потери надежности обеспечивая все гарантии потому что это финансы транзакции первое куда стоит посмотреть на архитектуру вот здесь такая иллюстрация классический java enterprise архитектура мы у нас есть какой-то брокер сообщение по которому которые используются для коммуникации с внешним миром мы получаем например заявку на покупку-продажу какого-то инструмента она обрабатывается в бизнес логики бизнес-логика соответствующие изменения делает в базе выдает в ответ какие то сообщения ты сообщение тоже через очередь сообщение гарантированно доставляются туда куда должна быть доставлена от соответственно нам надо чтобы если вдруг что-то случится в момент обработка нечто не данные не потерялись нас не получилось так что мы сообщения прочитали но не записали в базу или записали в базу что мы уже закончили обработку а сообщения не ушел классический подход это двухфазный кометы соответственно идея его в том что вот все операции подтверждение чтения сообщений за из очереди commit изменений в базу данных отправка сообщения в следующую очередь они выполняются в две фазы сначала мы собственно говоря выполняем от операцию а потом мы подтверждаем транзакцию и соответственно сначала у нас все ресурсы входящие в транзакцию выполняют операцию как бы проверяются с точки зрения функциональности что все сработало что нет никаких ошибок на стороне и и из криля и так далее а потом все они уже подтверждают правоту и специальный менеджер транзакцией следит за тем чтобы вот это вот действительно произошло атомарных это удобно тем что многие продукты поддерживают это из коробки то здесь вы можете комбинировать различные базы данных различные брокеры сообщений x и это стандартный протокол для поддержки двухфазного коммита но с точки зрения времени отклика мы добавляем целую фазу к обработке нашей транзакции на стороне системы прежде чем мы можем считать что она завершена за закончена гарантированно сохранена у нас получается вот эта фаза комета который включает себя сетевое взаимодействие со всеми ресурсами входящими в транзакцию соответственно это ключевой недостаток мы добавляем большой хоп сетевое причем который делается со многими ресурсами это нехорошо как можно сделать по другому на классический подход который давно уже применяется то есть я попал в индустрии электронной торговли в 2006 и это как бы тогда уже в те времена были стандартами де-факто может быть кто-нибудь знаком с термином when sorting вот как бы это один из ключевых аспектов архитектуры который был уже тогда в 2006 и как бы он бы там был не нов и так как нам обеспечить транзакционных без двухфазного комета идея следующем мы нумеруем все сообщения то есть у нас весь processing а ориентирован на события то есть у нас есть входные события у каждого события есть нумерация сообщений и соответственно у нас все ресурсы все компоненты входящие вот в эту цепочку обработки они могут перри проиграть сообщение с нужного номера и таким образом у нас схема обработки становятся проще если у нас упал компонент бизнес-логики там и на старте можем посмотреть какой номер сообщение был последний за комиссию в базу данных и просто перри проиграть все что было после этого номера то есть нам не надо источнику сообщений говорить что все мы закончили обрабатывать твою сообщением м это никогда не говорим он держит сообщение условно говоря вечно на практике как правило неделю-две вот вместо этого мы требуем от него чтобы он всегда был готов предоставить нам а все данные заново с любой точке во времени ровно вот в том же виде в котором мы их получили изначально и соответственно наш компонент последующем системам тоже предоставляет такую же гарантию и таким образом у нас вот эта вторая фаза исчезает мы за один проход получаем гарантированно возможность восстановления до для этого нам нужно обеспечить каким-то образом вот эту гарантию что мы можем с любой точки с любого порядка ванавара перри проиграть все сообщения обычно это достигается за счет использования специального брокера сообщения система строится так как таким ору мы например по тисе пи ай пи или там по протоколу fix если кто знаком с ним получаем сообщения сам по себе вот это ты себя и пена нет никаких гарантий не дает поэтому мы на входе это сообщение сразу схватываем в журнал ему присваивается в этом журнале порядковый номер и соответственно тот порядковый номер является как бы основным для дальнейшей работы в системе для последующего восстановления для этого используются весьма экзотические продукты для которых обычно люди вы вы далекие от этой индустрии никогда не слушали но идея такая что это очень сообщение в чем-то похожие на кафку только там как бы быстрее и немножко это самое по другому архитектурно устроено и о чем есть свои нюансы соответственно все входящие сообщения у нас проходят через входящий журнал получает порядковые номера и таким образом все даунсвинг компоненты они тоже получают этот порядковый номер и они на самом деле могут дальше следить за работой и нашей системы с различной скоростью то есть если это например модуль который пишет в бисквитную базу данных в пике торговой нагрузки может отставать на минуты на часы это не очень хорошо но как бы иногда так вот такое случается но при этом вот он пишет свой номер сообщения он как бы отстаёт от все остальные планеты но он догонит он все сообщения по порядку запишет рано или поздно после окончания торгового дня так далее как у него нету требований записать их в течение какого-то короткого временного окна вот ну на самом деле если у нас совсем такой вот медленный потребителю информации то обычно для него делается еще одна очередь чтобы как бы все-таки в в основном журнале ограничить время жизни промежуточных данных но тем ни менее идей остается такая же и таким образом мы можем в цепочку построить несколько компонентов и вот эта транзакция будет происходить без дополнительных фас без дополнительных к метов и даже какие-то простые преобразования если нам нужно например поменять формат сообщения там из xml приложить его в джейсон или photo booth то такой компонент может быть полностью стоит вас просто как бы его томским компонент если он встал потерял сообщение он попросит у него повтори мне сообщение с номером x этот медиатор пойдет к своему входному журнал дай-ка мне сообщение с номером каменного его транс кодирует передаст дальше это такая такая идея позволяет вот таким образом разбивать систему на под компоненты при этом не сильно терять на стоимости транзакционные обработки через всю цепочку компонентов так к просто соответственно достоинство такого подхода у нас больше нет распределенной транзакции мы получаем те же самые гарантии без явного кометы каждый бизнес-операций то есть у нас получается такой pipeline который рано или поздно выполнит все что начала выполняться системе и такая архитектура дает нам возможность вот этот компонент который отвечает за бизнес-логику дает нам возможность одержать теплую резервную копию то есть у нас есть основной компонент в котором работает бизнес логика и и она как бы там есть особенности связаны именно с бизнесом что все вся транзакции должны обрабатываться строго последовательно вот но мы можем поставить второй такой же компонент который будет обрабатывать все те же входящие запросы будет проигрывать сюда же бизнес-логику будет иметь все ты тоже самое состояние структур данных в памяти просто до тех пор пока он находится в режиме стендбай а все его выходные сообщения будут уходить в дивном но как только нам надо подключиться как только у нас например произойдет сбой основного компонента он может максимально быстро продолжать обработку транзакций ровно с того порядкового номера на котором остановилась основная реплика то есть нам не нужно его стартовать не нужно прогревать каши особенность таких систем то что все данные которые нам нужны для обработка бизнес-логики они должны быть в памяти как бы мы пытаемся избавиться от него взаимодействия на комете транзакций априори мы не можем на каждую транзакцию ходить в базу данных чтобы вычитывать данные мы уже должны заранее на старте все что нам нужно погрузить в память поэтому старт это достаточно дорогая операция окей с архитектуры разобрались мы получили у нас есть архитектура которая нам позволяет убрать все лишнее сетевые взаимодействия соответственно но у нас по-прежнему остается бизнес-логика которая как я уже сказала должна работать строго последовательно и нам надо как-то сделать наш прикладной кот тоже достаточно быстром убрать из него все лишнее но понятное дело что сейчас у нас сервера многоядерной и можно было бы да все все обработку делать на одном ведре но это не очень здорово классический подход это параллельная обработка запросов она не подходит по бизнес причинам мы не можем обрабатывать логику параллельно но даже если бы она подходила есть равно еще такая проблема которая возникает когда вы уходите нас от миллисекундный уровень вот здесь такая люстрация есть три запроса которые одновременно прилетают по сети эти три запроса будет три потока которые начинают их обрабатывать и дальше может произойти следующее вот какой-то 1 за один запрос начал обрабатываться первым попал на ядро процессора начал обрабатываться но в тот момент когда 3 запрос пришел операционная система решила что вот этот поток уже поработал достаточно его можно скинуть хитро память поместить на ядро другой поток который вы только что проснулся и таким образом мы получаем вот эту вот задержку посредине выполнении запроса связанную с тем что в операционной системе linux у нас абсолютно честный планировщик задач соответственно абсолютно честный планировщик задач абсолютно честно делит процессор между всеми запросами равномерно и как только у нас количество параллельных запросов превышает количество ядер которые у нас есть вот такие задержки начинают попадать во все запросы абсолютно честно непредвзято вот поэтому даже уже на этом уровне у нас есть проблема кроме того если бы мы делали опять же правильно обработку таким образом у нас достал задача что у нас есть к шее у нас есть какие-то структуры данных которым нам нужно обеспечить многопоточный доступ многопоточный доступа это дорогое удовольствие потому что нам нужен какой какая какой то есть какая-то за его действий колят синхронизация между потоками если мы рассмотрим абстрактную стоимость синхронизации между потоками то у нас тут возникает две ситуации 1 не первое достаточно нормально не проблемная как бы если у нас просто структуры данные правильно обложен блокировками но у нас не возникает конкурентного доступа то поток очень быстро получает блокировку это атомарная операция с памятью да это чуть дороже чем обычная операция с памятью но более-менее в контексте сотен микросекунд это быстро вот читает допустим какие-то данные из кэша освобождает блокировку это достаточно быстро проблемы начинаются тогда когда у нас блокировка именно срабатывает когда у нас два потока пытаются получить доступ к одному ресурсу и один вынужден подождать что значит подождать это значит что он должен сделать вызов операционной системы уйти с hidra и даже если ресурс освободится через на на секунду после того как он ушел с ядра он не продолжит выполнение он будет ждать когда планировщик операционной системы снова отправит его на ядро и соответственно мы даже если у нас время работы с этой блокировкой она мало получаем вот эти вот лишнее накладные расходы на то что планировщик задач должен поставить наш поток на выполнение хуже того вот это вот эта стоимость работы с ядром она двойная потому что тот ресурс который получил тот поток который получил этот ресурс владение когда он его отпускает он должен по смог пробежаться по списку всех потоков которые ждут от ресурс и и операционной системе игру сказать что вот эти вот ребята или там первый из этих ребят все может его будить он может выполняться то есть это все равно даже для того кто освобождает это дополнительный вызов ядро который тоже чего-то стоит еще один аспект стоимости в этом контексте и это переключение контекста когда выполняется наш код он пользуется очень то есть у нас есть каши которые специальная таблица которое кэширует адреса виртуальной памяти у нас есть cash code у нас есть кэш первого второго уровня и так далее соответственно когда у нас выполняется на ядре один кот все хорошо он все эти ресурс используют максимально эффективно когда у нас происходит переключение контекста мы часть этих к шее большую или маленькую можем потерять и соответственно какое то время после переключения у нас код будет работать медленнее чем нормально и соответственно если само по себе переключение контекста она не очень дорогое современные процессы операционной системы они оптимизированы они поставят стараются по минимуму вот эту информацию скажи выкидывать но если на вашем ядре поработал другой поток работал в другой памятью вытеснил всю вашу информацию скажу эту стоимость будет больше я нашел такое исследование этого вопроса она конечно уже немножечко устарело но на самом деле продолжает иллюстрировать идею здесь как бы это benchmark простого пин-понга там с нюансами и суть что что в какой-то момент вы пробиваете то рыжков вы теряете критическое количество вот это за кашированная информации и стоимость переключение между потоками по сравнению с выполнением тех же самых операций в один поток на одном ядре она возрастает на порядки в десятки раз чтоб просуммировать все эти идеи есть несколько как бы ценовых уровней на которые мы готовы пойти это требует от нас так сказать разного стиля написание кода бывают ситуации когда мы хотим чтобы взаимодействие между потоков у нас было супер быстрая то есть например если у нас два потока между которыми нам надо передавать 10 миллионов сообщений в секунду такое тоже может быть соответственно бюджетно вот каждую вот эту вот операцию то здесь даже не идет время речь не идет о блокировках о том что просто как бы один поток узнал что вот в другом потоке есть да на другой поток привел данные которые ему надо обработать вот здесь мы можем использовать стратегию с бог free as локти структурами данных то есть без блокировок без ожиданий это все возможные стратегии на циклах ожидания и так далее но в нем в принципе быстрой путин хронизации тоже он сам по себе не дорогой если мы можем гарантировать что у нас никогда не произойдет именно с настоящей блокировки между потоками и в этом случае как бы мы можем без очень постараемся действительно там 10 миллионов сообщений между потоками прогнать если у нас все таки цель поменьше если мы и хотим чтобы вот эта стоимость передачи данных между потоком по минимальной но но не микро секу там 10-20 микросекунд нас устроят то в принципе даже как бы те операции синхронизации они не страшно до тех пор пока мы гарантируем что наш код выполняется на одном и том же ядре и что на этом ведре никто ему не мешает выполняться даже если мы взаимодействуем с ядром будем этот поток переводим его в состояние ожидания до это накладные расходы но они измеряются десятками микросекунд а и в каких-то свиту но то есть вот в ситуации so white in sea sun city в системами это как правило допустим а вот если у нас потом наш код начинает прыгать между ядрами стоимость таких прыжков сразу резко возрастает если у нас кадров ядерно все потоки не хватает становится совсем печально то здесь мы у нас код уже может упасть стоять ждать ожидать пока придет ядро это может быть долго это может быть там как бы теоретически не неопределенно долго на практике это уже как правило начинается счет но сины миллисекундам на десятки миллисекунд уже за пределами от того бюджета по a weight in se которые в который мы хотим вписаться соответственно как нам обеспечить с одной стороны использовать несколько ядер для обработки нашей логике другой стороны не платить вот эту стоимость синхронизации не платить цену каждый раз когда мы там читаем данные из каша и так далее альтернативный подход к распараллеливание это распараллеливание не горизонтально и функционально то есть например у нас приходит сообщение нам его надо распарсить потом нам надо его права лидировать потом нам надо применить бизнес-логику которую там поменяет состояние баланса сделает что-то еще потом нам надо его снова превратить в генерировать какие-то ответное сообщение превратить их в бернар на и представление отправить в сеть соответственно вот эти фазы их можно делать параллельно при этом не нарушая строго последовательного строго последовательной обработки каждый бизнес транзакция но соответственно один поток будет отвечать за одессе реализацию один поток за обработку бизнес-логики один поток за реализацию в сеть плюс бонусом мы получаем то что поскольку у нас есть один поток который отвечает за бизнес-логику нам не нужно использовать многопоточной структуры данных для каширования информации и это очень здорово потому что как только мы начинаем использовать одно поточной структуры данных они сразу и с точки зрения производительности с точки зрения количества памяти которые они занимают они за существенно более эффективное и при этом у нас несколько ядя все равно делают что-то полезное они заняты работой вот здесь в простейшем примере как бы три узла канве на практике их как правило 6-10 зависимости от специфики от того business law который мы работаем кроме того как я уже говорил у нас приходит сообщение нам надо его положить журнал чтобы получить номер транзакция вот журнал нам должен подтвердить собственно говоря он должен нам дать этот номер транзакции но всю вот эту вот последовательность обработки мы можем сделать не дожидаясь номера то есть нам номер нужен только когда мы общаемся с внешним миром когда мы папа своем сообщении следующий в цепочке системы мы должны передать номер чем с гарантии что если она у нас попросят тот же самый результат по этому номеру в следущий раз мы его либо прочитаем из какого-то хранилища либо сможем повторить в точности все операции бизнес-логики то есть получить исходное сообщение повторить в точности всей операции бизнес-логики сгенерить ровно то же самое бинарное сообщение на выходе и предоставить системе который идет в дальше в цепочке соответственно мы вот эту дорогую операцию получения порядкового номера которая требует сетевого консенсуса чтобы обеспечить надежность мы можем это ожидание сделать параллельно работы бизнес-логика то есть пока мы исходили все эти получили номер входного сообщения она у нас уже обработано и уже в бинарной форме очереди стоят выходные сообщения соответственно такой контейнер позволяет нам в контексте каждого бен в каждого модуля обработки работать с нормальным 1 по точным кодом соответственно мы экономим на взаимодействие между потоков то есть взаимодействие у нас локализована в нескольких очередях но и очередь достаточно простая структура данных есть библиотеки в том числе и концертные которые эффективны это реализуют используя различные стратегии там тоже с различными пройду frame с точки зрения пенсии потребление циpкa вот кроме этого у нас есть набор функциональных компонентов и их фиксированное количество то есть я сказал от шести до десяти то есть мы можем просто разметить нашей атра чтобы на каждом недре запускался только определенным функциональный компонент соответственно на этом не требует запуск работать все время один и тот же код одна и та же логика с одними и теми же данными и у нас будет существенно меньше пересечения к шее между ядрами конфликты за работу спамят между с памятью между ядрами и так далее кроме того это дает нам возможность спекулятивного выполнения как я уже сказал мы еще не получили секундомер мы уже можем прогнать все бизнес-логику если что-то пойдет не так ну вот как бы произойдет такой глобальный restart какого-то другого секунд набора проблемы у нас есть естественное ограничение по распараллеливание у нас 10 стать конвейер максимум 10 я дермо можем загрузить все то есть все равно у нас вот есть бизнес логика который обрабатывает все транзакции в трубу последовательно когда мы начинаем выжимать максимальную пропускную способность это из этой системы мы очень быстром находим как будто у нег в каком-то из этих компонентов которые может быть исправлен только именно оптимизации кода оптимизации процессинга мы не можем просто так дать этого театра в систему и бизнес-логику надо делать аккуратно там не должно быть ни ничего что может приводить к блокировкам синхронная запись в лог файл еще всякие вещи которые далеко не очевидно на первый взгляд но на практике могут приводить к блокировкам и соответственно весь наш конвейер существенно тормозить кроме того логика должна быть чтобы обеспечить нам вот все возможности теплого резервирования откатов логика должна быть строго татар минирован и опять же какие-то такие совершенно очевидные вещи например jaws к реализация хэш-таблицы она вообще 40 говоря не совсем татар минирован с не бывают нюансы как бы очень немногие люди когда начинают работы писать код вот в такой парадигме наступают на них просто как бы каш таблица хэш таблица оно нам дано как данность оказывается есть вот еще такие не функциональные требования когда мы говорим про время отклика его также на ум приходит сборка мусора я про неё много говорить не буду сборка мусора есть оно неизбежно но у нас не система реального времени нас интересует 99 пирсинг вытащить поёт те the white in se которые нам надо добавлять сборщик мусора своими паузами за 99 писатель это несложно как бы это требует правильной настройке сборщик мусора это требует адекватного написания кода но это не сложно это как бы вот не далеко не самая большая головная боль и кроме того я видел множество пауз на ровном месте которые вообще были никак не связанное со сборкой мусора когда мы говорим про обычное железо про обычная операционная система у нас там очень много всяких причин она ровном месте затормозить на миллисекунду другую третью и сборка мусора далеко не самая основная из них возвращались к сборке мусора тут как бы можно привести две стратегии такие две вертикальные стратегия можно писать горбач приход там мы перри используем все структуры данных ничего не выделяем соответственно сборщик мусора у нас ничего не делает убираем проблемы с сборка мусора ну и так сказать из скорее мера функционального программирования где что у нас если мы используем все структуры данных и имеют able to у нас на соответственно тоже исчезают проблемы с синхронизацией и так далее вот с прагматической точки зрения истина где-то посередине надо комбинировать подхода где это действительно имеет смысл использовать имеют оба структура где то имеет смысл поэкономить помог на мусоре но как бы радикальные подходы они работают крайне радикализм он работает не очень хорошо окей последний последняя часть доклада как я уже говорил у нас потоки выполняются на ядрах это как они выполняются на ядрах это существенно важно когда у нас речь идет о с а миллисекундам времени отклика и соответственно проще всего проблемы связанные с этим аспектом решать на уровне операционной системы соответственно что надо сделать от операционной системы чтобы наш правильно за спроектированный правильно написанный код эффективно выполнялся пункт 1 по умолчанию все дистрибутивы идут с включенными опциями экономии электроэнергии зеленый linux все дела значит если вас интересует время строка согнали секундная выключаете все это по максимуму употребляете электроэнергию как бы время отклика и экономия электроэнергии две вещи несовместные в частности операционная система может понижать частоту ягер включает специальные режимы энергосбережения энергосберегающего ожидания der который приводит к тому что ядра просыпаются медленнее соответственно вы получаете дополнительные задержки при останове продолжение работы ваших потоков своп но достаточно очевидно если у нас вдруг операции памяти превращаются в операции с диском то как бывает инси будет уже не на микросекунд нам уровне далеко но тут как бы стратегии есть разные я придерживаюсь радикального подхода но как бы люди из отделов эксплуатации обычно со мной не соглашаются но тем не менее как бы надо обращайте на это внимание это базовые вещи теперь как бы более именно тюнинг на выдохе как я уже говорил у нас есть конвейерная обработка нас на сервер есть ядра и если мы размещая мы выделяем каждому из наших критических конвейеров отдельную игру мы получаем кучу выигрышем мы получаем кучу экономии и на переключение контекстов не на эффективности использования каша и так далее как это сделать поток в живом это обычно поток операционной системы у него есть айдишник доедешь них можно получить его можно получить например раз парсифаль под команда джей стапеле его можно получить расспросив аналогичный tritan по полученной другим способом и соответственно мы можем стандартной командой tasks от привязать этот поток к определенному ядру соответствии с нашей стратегии и этот поток будет выполняться только на этом е3 но это полдела потому что если мы привязали наш поток определенному ядро это не значит что на этом ведре не будет выполняться никто другой это не значит что с нас этого ядра не выкинуто поэтому чтобы гарантировать вторую часть нам надо исключить это ядро из планировщика задач операционной системы это уже требует готового доступа но точно так же делается в линуксе есть специальный параметр для этого то есть мы часть я der исключаем из-за планировщика на них выполняются только те потоки которые явным образом туда прибитый через tasks от когда мы все это делаем надо еще помнить что у нас но не uniform memory архитектор это значит что у каждого сокета свои банки памяти и опять же мы можем этим управлять на практике у как правило вот это такой процесс который выполняет обработку транзакций он требует там 16 я тянул все равно больше не способен взять поэтому моему целиком можем положить в одну ногу и соответственно использовать для него ядра из этой но нам надо для этого мы используем дома сидел чтобы на старте положить его сказать операционной системы что этот процесс должен выполняться на этой ноги соответственно он получает память только из банков памяти той но да ну и распределением я der мы уже занимаемся вручную но пример стратегии мы одну numa ноту на 16 ядер выделяем под критическое приложение соответственно 10-я der выделяются под стадии конвейера остальные ядра выделяются под все остальные потоки который у нас там не всякая синхронное багирова не и так далее далее у нас в любом java-приложение десятки и сотни потоков вот при этом потоке сборщика мусора сборщик мусора он тоже есть о но на поточной мы их вешаем на те же самые ядра на которых работают потоки бизнес-логики потому что когда работает сборщик мусора все остальные вся остальная вас стоит и здесь у нас конфликта нет вот соответственно получаем такой сетап когда одна носа за вся эта нуман надо полностью исключена из планировщика задач на не работают только наше java приложение за счет этого мы убираем вот этот вот шум который привносит нам дополнительный задержки который может привнести планировщик мусором ну и в заключении немножечко про такой пример когда мы проводили чистку одной системы то есть как я уже говорил сначала у вас появляется как бы рынок потом рынок становится электронном потом в какой-то момент он может стать в этом sensitiv может не стать согласно когда люди писали код они еще не знали что у них через год появятся требования к низким задержкам но при этом как бы по дефолту используется архитектура используется платформа которая к этому готово и все что остается включить правильные опции немножко почистить код вот здесь соответственно есть два столбика в каждом столбике есть медиана и 99 песен тилль и два режима испытания высокая загрузка нагрузка это где-то сотня сообщения сотня транзакций в секунду и низкой от ран за нагрузка это одна транзакция в секунду и соответственно что видно в принципе в исходной версии средний числу норману как бы не очень хорошие вот но выбросы особенно при низкой нагрузке они просто чудовищные 23 миллисекунда значит фаза 1 чистка кода на уровне я во включении всяких фишек на уровне я вот значит когда начинаете чистить код ну как правило это значит надо подать нагрузку включить профайлер не обязательно навороченный профайлер вижу в м позволяет вам как бы 99,9 всех типовых грабли найти фото типовые проблемы которые можно найти это лишнее логирования это публикация бизнес-логики когда мы как бы одну и ту же операцию делаем несколько раз хотя можно было бы сделать один там где-то как сохранить просто подписался так как было удобно водкой где там лишний reflection это же все-таки бизнес-логика куда штамп без reflection а вот это соответственно дает такой хороший выигрыш ну плюс ещё для очередей у нас использовалась библиотека я макс дистр автор если кто-то про нее слышал это концов библиотека там есть несколько режимов один из режимов включая это спинок когда у вас очередь соответственно использует не блокировки использует бесконечные циклы ожидания соответственно это тоже была включена ну и среднем где-то в два два с половиной раза время отклика системы удалось уменьшить но при этом выбросы папа ну во-первых цифры для высокой нагрузке в принципе уже были адекватными как я уже говорил нас интересует одна секундное время 700 микросекунд это уже достойно это уже не стыдно по сравнению с конкурентами но на несколько загрузки у нас все равно есть вот это вот аномалия когда во первых время отклика существенно выше а как я уже говорил зачастую нагрузка в реальной жизни бывает именно низкая то есть у нас реально могут быть в каком-то бизнес сотни сделок в течение торгового дня но мы за каждую из этих сделок хотим побороться мы за кают на каждую из этих сделок хотим предоставить свое клево же предложения в течение полмиллисекунды следующая фаза настройка linux фиксация частоты ядра включение разметки потоков по ядрам и соответственно для высокой нагрузке дома и получение небольшое улучшение у нас существенно улучшился 99 см то есть мы как бы именно разброс все меньше и меньше как только мы включаем вот эти опции у нас работа система становится существенно более детерминированной плюс мы решили проблему с низкой нагрузке она у нас стала приблизительно почтить большим близкую уже к высокой нагрузке и в целом уже попадает в тот бюджет по времени отклика который мы перед собой ставили вот что интересно в принципе вот как мы потом посмотрели спину ки после правильной настройки linux можно выключить они уже собственно говоря не помогают то есть их идея какая что вы на на уровне кода за счет того что постоянно держите ядро занятом мешайте сборщику мешаете планировщику linux сбросить с вас ядра как бы если вместо этого ему просто по-человечески сказать не надо это ядро для этого потока больше то он никуда не пускают а это оптимизация она уже не дает того эффекта который дает оставить не в не затененной системы вот на этом у меня все спасибо за внимание ночью есть времена вопроса так вот первая рука я видел здравствуйте спасибо за доклад очень интересно у меня собственно какой вопрос у нас прибита уже ядра linux у нас нету никакого многозадачности нет синхронизации и так далее что дает вот этот вот более долгое время обработки на низкой загрузке собственно по идее что высокая загрузка что низкая загрузка должна давать но плюс-минус примерно одинаковый примерно одинаковое время выполнения поскольку у нас как бы кыш-кыш и прогреты они не вытесняются это очень интересный вопрос я старался стараюсь на эту тему слишком глубоко не думать потому что как только это самая посмотришь как там на самом деле все это работает становится очень страшно но какие могут быть причины могут быть вытеснение данных из кашей за счет того что какие-то другие ядра с этими данными работаю то есть какие-то фоновые процессы обновляют статику это может влиять есть еще такой неприятный эффект который особенно у нас был когда были включены спину оки что джем иногда может и компилировать код то есть вот у нас включен спину который постоянно в цикле крутятся ждет когда сообщение в очереди появится есть бизнес логика которая работает а ноль один процент от общего времени выполнения в живом работает профайлер профайлер решает ага вот этот код который работает 99,9 процентов времени он важный а вот этот можно выкинуть из кэша это самое место освободить вот тоже еще один аспект который это самое в некоторых случаях замечали отключали эту функциональность вот современные сервер это очень сложная штука поэтому там очень много всего интересного можно найти как бы надо просто в какой-то момент остановить так вот рука простите разлились ли вы на живые moto зал systems нашли ли вы причину купить у них озон тетя лида некоторое время назад несколько лет назад по моему четыре или пять проводили тестирование отказались из того что она показывает худшее время связано еще раз все что вам дает озу это решает проблему со сборщиком мусора сборщик проблемы со сборщика мусора это не та проблема с которой мы боремся на выполнение кода он показывал худшие времена это было несколько лет назад то есть как бы наверное это самая система развивается возможно сейчас бы уже сравнение газового подруги результата второй вопрос что вы используете реагирование что что вы используете для лакирования но вот конкретно на вот этом кейсе там использовался по историческим причинам 1 wog fuji совсем к тендерам и в какой-то момент вот как как раз в рамках одного из таких упражнений по оптимизации в танце нам пришлось вот этим компьютер слегка переписать на самом деле не сильно там чуть-чуть синхронизацию поменяли и он стал вести себя нормально вот почему не более современный лагер потому что как бы система был платформа была написана уже была привязана я на это и то есть как бы тает вы это требовало миграция вообще как в планах букву g 2 был добрый день спасибо за доклад у меня два вопроса если позволите 1 вот это ваша картинка 1 из первых там каждый компонент это однако живым или несколько которыми же сообщается несколько так как вы решаете все-таки играх относить между ними он так небольшой но тоже есть значит если это вот эта картинка на 1 это 1 дживы оранжевым даже то что нарисованы между компонентами это очереди вновь в памяти следующий вопрос бы сказали что есть flow когда каждая сделка их немного да но каждый из них очень важно как вы решаете проблему если у вас клиент начал какое сообщение до с вами и вот посреди этого общения в очень из которой муки и вы не положили сообщение вот слой журналинг вот прошел обрыв приступала сеть там не знаю пути у -9 java на сервере вы понял кто то произошло у вас есть какие то не знаю резервирования на уровне там не знаю с петра фиков что-нить еще вот в этом духе или просто не получилось значит против против петровке она рассказать не смогу над понимать что это все закрытые сети что каждый раз когда устанавливается такое соединение это прокладывается отдельная линия связи там за к заключаются соответствующий контракт это не интернет вот про сетевую инфраструктуру много рассказать не могу но как бы между контрагентами там у как бы на обоих сторонах есть шлюзы они общаются по ком протоколу и этот протокол за май если он подразумевает тот или иной механизм восстановления при сбое соединения там обычно тоже идея связана с и квинси раване им то есть как только произошел обрыв шлюзы между собой производит координацию кто сколько сообщение отправил кто сколько почитал соответственно повторяют устам свои про такого восстановления после сбоя работают"
}