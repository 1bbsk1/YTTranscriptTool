{
  "video_id": "H2tqs1wvJi0",
  "channel": "HighLoadChannel",
  "title": "\"Сильный искусственный интеллект\" у вас в подвале / Иван Бондаренко (НГУ)",
  "views": 360,
  "duration": 3132,
  "published": "2025-01-17T02:28:14-08:00",
  "text": "Здравствуйте друзья Здравствуйте Я очень рад вас всех видеть здесь в этом зале на хайде Я Иван как меня уже представили и я люблю машинное обучение Я люблю машинное обучение с 2005 года когда оно проникло в моё сердце ещё когда я был студентом года Я работал в Академической сфере преподавал нейронные сети искус ши обучение своим студентам с триго года Я перешёл в it индустрию работал в разных компаниях занимаясь примерно Всё тем же машинным обучением и искусственным интеллектом и наконец в д втором году мне всё это надоело я решил обратно из it индустрии перейти в академическую Сферу И сейчас я работаю в Новосибирском государственном университете занимаюсь научными исследованиями учу студентов делаем всякие интересные штуки ну а в конце прошлого года я и мои ученики решили всё-таки не только фундаментальными исследованиями заниматься и наука должна приносить пользу людям и мы сделали маленький стартап под названием Сибирские нейросети есть Сибирское здоровье есть Сибирские нейросети теперь Э всё что я делал оно связано одним моей любовью к машинному обучению Мне это очень интересно было всегда но а помимо машинного обучения мне интересно участвовать в соревнованиях научные соревнования - Это не просто способ развлечься это способ оценить по гамбургскому счёту насколько твой алгоритм хорош объективно в сравнении с другими когда мы разрабатываем какую-то систему для заказчика мы ориентируемся на его данные эти данные закрыты как правило мы делаем какие-то какие-то кастомизации которые обеспечивают качество может даже чере пикинг иногда делаем Хотя это фу но тем не менее А когда мы предлагаем наше решение наш научный метод наш алгоритм на соревновании мы все в равных условиях и мы действительно можем оценить насколько хорошо то или иное решение себя показывает при этом самое главное что такие соревнования дают материалы в виде открытых датасета для дальнейшей воспроизводимости в виде открытого кода который опять-таки можно воспроизводить в науке проблема воспроизводимости стоит остро а подобные научные соревнования Я имею в виду не гл а что-то более интересное и более такое системное они позволяют действительно какое-то движение науки вперёд осуществлять и Вот наши коллеги из Бера уже много лет проводят такую чудесную конференцию как путешествие в мир искусственного интеллекта Ир И каждый год при этой конференции проводится одно или несколько соревнований и вот в прошлом году при конференции проводилось в том числе соревнование Strong intelligence сильный искусственный интеллект в ЧМ там была суть задача ставила следующ было разработать систему диалоговое которая могла бы отвечать на вопросы людей Ну например что-то в духе Что Где Когда или просто беседа человека и компьютера но человек мог задавать вопросы не чисто в текстовом виде А ещё картинки добавлять Вот посмотри что это такое звуки и так далее вот здесь как Пример например Здесь показано вот что это за существо на картинке система отвечает тин поняла вопрос текстом отвечает Крокодил Гена а вот посмотри пожалуйста послушай что он делает играет на музыкальном инструменте на гармошке Я играю на гармошке известная песня Вот подобного рода задача ставилась пред участниками но возникает вопрос А почему название соревнования такое амбициозное Strong intelligence сильный интеллект или сильный искусственный интеллект Почему мы говорим этот искусственный интеллект сильны что вобще за понятие если есть сильный Значит есть слабый действительно сам по себе искусственный интеллект - это известное направление которое Ну толком мало кто знает что такое искусственный интеллект у всех это на слуху все смотрели всякие там терминаторы со скайнета матрицы и тому подобные вещи у каждого своё представление об искусственном интеллекте поэтому Прежде чем говорить о силе слабости искуственного интеллекта нужно договориться о терминах вообще искусственный интеллект есть такая книжечка называется толковый словарь по искусственному интеллекту вот я предпочитаю опираться на неё и искусственный интеллект - это научное направление которая занимается исследованиями по автоматизации тех аспектов деятельности человека и не будем Антра постами животных которые традиционно считаются интеллектуальными конечно слово традиционно математики могут меня забросать этими помидорами за такое неформальное нечёткое понятие традиционно Но кажется здесь программисты математики э вот а Итак искуственный интеллект моделирует интеллектуальную деятельность человека но слабый искусственный интеллект делает это для какой-то отдельной узко специализированной задачи Вот мы обучили систему спич to текст она только спич текст и делает распознавание речи в шахматы она с вами не сыграет обучили систему обнаружения человеческих лиц она только лица в умном домофоне определяет свой или чужой она на вопросы о смысле жизни не ответит обучили систему определения токсичности в тексте она только токсичность в тексте на определённом языке распознаёт она номерные знаки автомобиля не распознает Это узкоспециализированные системы и их называют слабым искусственным интеллектом в то же время как сильный искусственный интеллект в противоположность слабому - это универсальная система которая может решает не одну какую-то задачу которую решению которой её обучили А в принципе любую задачу некоторые считают что сильный искусственный интеллект - это вот что-то что обладает сознанием что-то что как человек и так далее но сознание - Это само по себе сам по себе термин очень неопределённый мы тут в область какой-то метафизики или там какой-то религиозной мистики можем уходить если мы начнём разбираться что такое сознание поэтому я предпочитаю определение сильный искусственный интеллект - это универсальная система э как противоположность слабому искусственному инту специализированным системам Но что значит универсальная Эта система должна взаимодействовать с человеком соответственно мы уточняем что это не универсальная это универсальная коммуникативная система Дело в том что это определение не просто позволяет организовать взаимодействие человека и нашего искуственного интеллекта которого мы называем сильным в целом естественный интеллект который мы моделируем это прежде всего интеллект который в коммуникации Сколько в принципе порождается коммуникацией вот говорят что человека создал труд это стоит Уточнить что человека создал общественный труд в ходе которого Возникала потребность взаимодействовать Даже если мы посмотрим на животных то социальные животные которые непрерывно взаимодействуют обладают более развитым интеллектом чем животные индивидуалисты соответственно когда мы говорим о сильном искусственном интеллекте мы должны прежде всего ориентироваться на разговор искусственный интеллект при этом одно одна только модальность текстовая Это явно недостаточно чтобы искусственный интеллект был по-настоящему универсальным и сильным необходимо чтобы он мог за рамки текста выходить и понимать Окружающий мир через картинки звуки и другие модальности Таким образом мы пришли к выводу что сильный искусственный интеллект - это мультимодальный разговорный искусственный интеллект и таким образом название соревнования Рон осмысле и оправдано и мы начали разрабатывать сильный искусственный интеллект само соревнование было организовано очень интересно надо было сабти не ответы системы надо было собти само решение в виде контейнера а организаторы уже с ним взаимодействовали и получали ответы на вопросы это очень правильный формат соревнования Потому что когда мы самим ответы мы можем четыри мы можем там посадить массу там студентов которые будут имитировать искусственный интеллект и отвечать вместо настоящее системы и тому подобные вещи когда мы делаем систему в виде микросервиса с определённым интерфейсом то тут уже читерить никак нельзя тем более ей обрубленным соревновании и Зами наш докер и заняли четырнадцатое место из ца участников и это нас огорчило прям грустно нам стало мы хотели первое место занять заняли чее что мы сделали не так мы начали думать а что же мы сделали не так Ну мои ребята сказали Мы наверное за 5 дней до дедлайна начали участвовать в соревновании А все остальные за полтора месяца наверное Вот это мы сделали не так Я сказал Да не не может быть мы так всегда делаем наверно что-то ещ было помимо того что мы перест чтото ело с кото мы Зами было основано на лайне организаторов с небольшими модификациями А что же это за белайн этот безлайн был основан вот на такой вот роевой архитектуре У нас есть некоторая управляющая большая языковая модель чисто текстовая она на вход получает текст и в ответ генерирует текст и чтобы её познакомить с тем что в мире существует что-то ещ кроме текста к ней добавляются унимодальная энко Картино текстовые точнее тексто так знает катиноны звуковые и так далее и но модель работает с текстом соответственно информацию об изображениях о звуках и об иных модальностей у не модального энкодера какого-то как некий Вектор который определяет смысл и дальше строим проекционный слой который преобразовывает этот Вектор в некоторую цепочку токенов Ну попросту говоря слов или там слогов поскольку модель языковая работает с токенами э тоже в векторной форме то по сути дела Наши проекционные представления делают такие виртуальные токены ээ в виде векторов Только эта часть обучается только вот проекционные представления и спец начало картинки конец картинки начало звука конец звука там начало модальности конец модальности обучается большая языковая модель заморожена унимодальная энкодеры тоже заморожены мы считаем что они все хороши и в таком решении есть много плюсов прежде всего лёгкость до обучения сама мультимодальная система может насчитывать миллиарды и даже десятки миллиардов параметров Но самая тяжёлая здесь часть это большая языковая модель например какая-нибудь Мистраль 7b - это 7 млрд параметров унимодальная в которых мало параметров соответственно задача становится вычислительном даже для обычного компьютера там с не сильно крупной GP Но помимо плюсов такое решение имеет и ряд минусов прежде всего фиксируем количество виртуальных токенов в этой подводке в промтек которая описывает одну модальность другую третью и так далее и наши вот эти проекционные представления никак не обеспечивают связь между модальностей бейслайн и мы решили сделать лучше а как то есть нам хотелось бы сделать эффективное решение которое преодолевает вот эти вот недостатки мы понимаем что различные объекты в различных модальностей нагрузку бывает картинка очень простая там фон и просто какой-нибудь объект там собачка или котёнок на фоне А есть объект который очень сложный там куча вещей там котик сидит за столом на столе тарелка с едой и и тому подобные вещи соответственно фиксированное количество токенов для каждой модальности это не вариант ну и плюс хотелось бы иметь механизм который как-то обеспечил взаимодействие понимание знани о том что те или иные модальности - это отражение реального мира вокруг и мы задумались а что же такое знание как это знание отразить в мультимодальной системе Ну мы не одни такие кто думали о том что такое знание за 2500 лет до нас вот эта дяденька в Афинах тоже об этом думал его звали Сократ и он пролился тем что он бегал по афинам и к прохожим начинал задавать всякие каверзные вопросы по философии прохожие пытались отвечать и в конце концов понимали что они ничего не знают философии и вот эти вот диалоги получили название внезапно не сократовский а платоновских диалогов потому что у Сократа был ученик Платон он восторженно это всё записывал своим учителям и в итоге написал такой сборник диалоги и вот один из диалогов был посвящён природе знания они вдвоём встретили ещ одного несчастного Нона и они начали его про геометрии спрашивать сначала Мино ничего не знал по геометрии потом в процессе цепочки наводящих вопросов н Сократа он смог доказать теорему Пифагора внезапно и Платона который всё это слушал осенила оказывается знания Наверное они не внутри нас сидят Ведь этот менон ничего не знал до начала беседы с сократом они какие-то внешние и вот знания происходит через некое припоминание из какой-то внешней базы знаний там идеалистической Ну у Платона была ческая философия и вот эта идея нас вдохновила на построение эффективной системы в которой кросс модальные знания о мире выносятся в отдельную внешнюю сущность в целом это не новое решение знание через припоминание это подход который основан на векторизации наших объектов и быстром поиске по внешней базе знаний тут момент пос должен быть быстрым потому что внешняя База знаний должна быть достаточно большой Бор это не вариант чудовищно долго соответственно для такого быстрого поиска по векторной базе знаний обычно используют методы типа приближённых ближайших соседей когда мы рассматриваем э векторное пространство всех объектов строим какую-то разделяющую гипер плоскость в этом пространстве и дальше перебираем не по всем точкам не по всем объектам а только по тем которые по одну и ту же сторону от этой плоскости что наш входной объект Но это ещё не всё другую плоскость случайно построили третью четвёртую и таким образом мы выделяем подпространство котором мы ищем остальные подпространства не рассматриваем таким образом мы очень оптимизируем Процесс поиска в качестве фреймворка который это реализует мы взяли библиотеку Анной люди которые уже продвинутые в всяких рак системах могут сказать Ну что это такое аной нуи Давайте использовать или хотя бы nms lep но на самом деле аной достаточно хорошая а с одной стороны простая Но с другой стороны эффективная система векторного поиска и мы Останови и ней по соображениям простоты и эффективности реализации это система Spotify открытая эбер вторая часть этого коктейля знани через поминание Это хороший Эмбер и вот здесь был нюанс Обычно когда строя рак систему см предполагая что у нас МР тоже текстовый и мы ищем текст в текстовой базе А у нас мультимодальная система и нам нужен был льный иде мы взяли тоже открытую нероеву модель на 4 млрд параметров которая была настроена обучена нашими китайскими коллегами и называлась One Peace Ну One Peace один мир ээ Типа все модальности в одну картину мира объединяются сама модель обучалась на трёх модальностей ского языка хоть это китайская модель но тексты английского языка были и она предварительно обучалась двум задачам первая задача - это контрастивная обучение контрасти лн сопоставительное обучение между различными модальностей сближаться объекты в паре разных модальностей если они примерно про одно и тоже и максимально разносить объекты в паре разных модальностей Если они про разные То есть это Cross Model contrastive Learning и был iner Model contrastive Learning фактически это та же самая задача которой обучают бертом мы накладываем маски на объекты одной модальности и просим модель по контексту установить то что было замаскированы сочетание такой кросс кросс модального обучения и внутримозговое текст это милый пушистый котик картинка с котиком и звук мяу-мяу он построит вектора максимально близкие В косинусом смысле а если мы на вход даём ээ текст это милый пушистый котик картинку с собачкой и звук ква-ква то он для построит вектора которые максимально далеки друг от друга в косинус смысле и это то что нам нужно было Для нашего кросс модального знания через припоминание таким образом первый вариант нашего решения состоял из следующих компонентов это большая языковая модель управляющая мы взяли для начала Мистраль 7Б инструкционные это наш кросс модальный Эмбер One Peace и В качестве базы знаний мы взяли всю англоязычную Википедию распарсить статьи распарсить это вектори положили в одной индекс получилось более 70 мл параграфов естественно мы использовали не полноразмерные вектора генерирует вектора размером пому по мы сокращались на Википедии и получили вектора маленькие красивенькие компактнее мерные по которым уже легко и быстро искать и соответственно они не раздава индекс мы сделали рение искуственный интеллект наука Экспериментальная соответственно чтобы оценить качество решения необходимо собрать некую тестовую выборку тест-с на котором посмотреть что получится мы собрали буквально небольшой тест-с несколько десятков примеров это мультимодальный вход мультимодальный запрос и правильный ответ референс правильный с точки зрения человека и дальше как наш прокт менеджер шутит методом пристального взгляда оценивали насколько ответы системы совпадают с тем что Мы записали как эталонные ответы с точки зрения человека поскольку там буквально несколько десятков объектов было в тест сеете это в принципе получалось нормально Вот давайте посмотрим как это получается Например мы задаём вопрос что на изображении и модель начинает генерировать модель понимает чтото на изображении начинает говорить вот котик сидит котик сидит за столом на столе тарелка с едой Котику хорошо комфортно он там такой молодец Там и так далее В общем генерирует э ответ на вопрос что она увидела мы продолжаем диалог Мы задаём ещё один вопрос А вот э что ты слышишь система О да я слышу это с энтузиазмом отвеча система это же мяу-мяу это же котики так мяукают и давай рассказывать подробней про локализацию кошачьих там писать и так далее Вроде всё отлично система работает в принципе на других примерах она тоже такие разумные адекватные ответы давала но не всё так гладко против нас выступила армия Иисуса мы задаём на вход вот эту простую картинку три груши и яблока спрашиваем что это она нам начинает фигачит религиозную Пропаганду это там армия Иисуса это вот такая вот объединение религиозное за чистоту Веры там все дела Мы Дума что что это такое Почему начали экспериментировать смн Вот подводом это подводки по-русски называются мты соответственно э одна моя коллега пошутила подводом программирование начали экспериментировать с подводом программированием может быть мы неправильный подводку формируем для модельки может что-то ещё нужно вот начали всё равно начинает про какой-то округ Сан Хуан говорит что там ээ религиозная картина разнообразная Опять нам про религию втирает что ж такое Мы думали думали сражались сражались с этой армией Иисуса но мы в конце концов победили и наша система мы её назвали Нон в честь этого диалога сократического который Платон записал наш Нон в конце концов начал видеть что это не армия Иисуса что это груши яблоки и что это хорошие там фрукты спелые там вообще всё замечательно как же так получилось что мы сделали не так И что мы улучшили как я уже сказал Сначала мы грешили в рону инжиниринга Мы неправильно подводку формируем для модели но потом мы задумались решили посмотреть детально так называемый ablation study провести исследование по отдельным компонентам И выяснили что дело-то в нашем припоминая кросс модальном припоминание оно обеспечивает очень высокий рекол полноту но не очень высокую точность prion и соответственно когда мы ищем в топ выдачи не всегда самые релевантные ответы приходит в самой выдаче они есть но не на самых первых позициях и мы начали думать как это сделать лучше вот было раньше вот так только эти три компонента А мы потом к Припоминаю добавили то что мы поэтично назвали узнавания это конгломерат маленьких унимодальная выдачи полученное по Крос модально Припоминаю Это маленькие унимодальная во-первых блип это генератор подписей к картинкам очень коротких это классификатор аудиосигналов на базе Трансформера обучены на антологии аудио сеет там 1.000 классов акустических событий различных речевых И неречевых если это речевые события то мы подключали visp медиум в принципе лач для наших задач был избыточно там медиума хватало вполне и наконец э для сравнения того что вот эти маленькие унимодальная поис через ксмо дальное припоминание мы использовали ранжирование а для этого использовали векторизации модальный энкодер текстов предложений как это выглядит архитектурно сначала наш объекты иных модальностей кроме текстовых поступают на вход нашего Крос модального припоминая они вектори зу происходит сокращение размерности и дальше происходит поиск формируется выдача топ например N1 топ1 дальше в зависимости от того какие объекты каких модальностей присутствовали в вопросе мы подключаем либо blip либо аудио трансформер blip генерирует Caption подпись картинки аудио трансформер генерирует класс поскольку этих классов много то это тоже можно считать как подпись если это класс речевых событий мы включаем visper генерируем spe To Text и наконец вот эти вот коротенькие ответы у немодальных энкодера вектори зуем с помощью mnet Base и выдачу кото нам сгенерировал наше кросс модальное припоминание тоже вектори зуем И ранжиру насколько текстовые знания из Википедии про туну модальность соответствуют краткому описанию полученном унимодальная мы назвали механизм и длинный вариант от припоминая и такая система оказалась достаточно устойчивой она адекватно извлекая о разных модальностей уже давно закончилось когда мы начали усовершенствовать но мы решили чтобы люди могли пользоваться мы развернули это в виде телеграм Бота Можно попробовать с ним пообщаться преимущественно на английском потому что соревнования постановка задачи соревнования была связано с английским языком хоть это соревнование в России было но в принципе русский он тоже понимает он понимает вопросы на русском он может даже отвечать на русском но иногда сбивается на английский Если вы хотите максимальной точности Попробуйте с ним пообщаться на английском языке ээ Ну и собственно наверное интересный вопрос как вот именно происходит формирование подводки э общую архитектуру я рассказал как у нас конгломерат разных моделей взаимодействует друг с другом но наверное интересно разобрать пошагово как же мы именно формируем промт подводку в этом основной секрет Нашего припоминая Нашего механизма припоминая Давайте разберём по шагам начнём шаг первый пример диалога Я сдаю вот эту фоточку нону и спрашиваю что этот мужчина держит в руках те из вас кто занимался распознаванием речи или занимается наверняка Могут узнать это Кен хифи автор Одной из самых известных библиотек м для языкового моделирования много Н он разработал м и Кен держит в руках свою Барби собственно система наш Нон должен понять это он действительно понял и ответил как Нон дошёл до жизни такой значит начинаем с того что анализируется вопрос включается первый этап это рос модальное припоминание там топ 100 наиболее релевантных абзацев Википедии Как видите здесь кросс модальное припоминание акцентирует своё внимание на человеке не на кукле оно К сожалению Википедия не знает Кена филда мы-то с вами знаем кто Ар спич тек занимается А вот Википедия не совсем она пытается его сопоставить с тем актёром с другим актёром и где-то там в сороковой пятидесятой позиции начинаются тексты про Барби я здесь не показала у меня слайды ограничены но Поверьте мне на слово они там появляются но уже во второй половине выдачи поисковой соотве нам нужно краткое узнавание краткое узнавание это это и задачка пожалуйста оно сгенерировал очень краткое описание что вот Барби куклу Барби В руках Ора мы знаем что вот этот текст нужно сопоставить и перен большую выдачу перен Пожалуйста теперь в топе тексты про Барби всё отлично и наконец мы формируем общую подводку которая состоит из системной подводки я вот увидел вот эту картину Представь что ты тоже умная модель увидела эту картину и дальше краткое узнавание длинное припоминание из Википедии инъекция внешней базы И наконец пожалуйста увидь то же что и я и дальше уже идёт текст вопроса текстового который собственно приходит Таким образом мы формируем подобного рода подводку модель может отвечать адекватно понимает о ЧМ идёт речь Я здесь привёл пример на английском но Я уже уточнил модель может и на русском что-то говорить ээ к примеру такая модель может использоваться для генерации какого-то контента как умный копирайтер даём ей картинку задаём Вопрос вот этот чудесный трактор с куном Давай прорекламировать какой-то чудесный трактор как он хорошо там пашет сеет и тому подобные вещи То есть как копирайтер может работать может работать как например модератор когда мы задаём ей картинку или звук и спрашиваем есть ли там что-то нехорошее вот к примеру задаём модели вот есть ли там что-нибудь непристойное модель проанализировала и говорит к сожалению нет ничего непристойного вы что это же всё прекрасно ничего безобразного нету всё нормально и вообще-то мы за красоту Ну я думаю о круто хорошая модель Прям вся в папочку в общем нормально то есть видите она отвечает она работает она может использоваться на практике Но это то что Мы проверяли на наших данных бы маленькие и весьма специфически несколько десятков примеров и мы глазами оценивали качество ответов но мы хотим понять А насколько же наш сильный искусственный интеллект действительно сильный по сравнению во-первых с осми аналогами такими каква 7b Это около of решение осные насколько мы далеки от таких гигантов как например бар ба для этого маленький тестс на котором мы эксперименты проводили Для этого нам нужен какой-то известный публичный тесте на котором другие учёные проводят эксперименты и нам нужна Метрика нам нужна Метрика э которая бы рассчитывалась объективно независимо от того что мы как люди там глазами смотрим Итак начнём с тест Сета э тест сеет составляется следующим образом как я уже упоминал сейчас скажу чуть подробней это пара объектов входной запрос мультимодальный здесь я привёл пример текстового запроса Что такое конферен но он может быть мультимодальный там С картиной каком-нибудь постером про и так далее и правильный ответ с точки зрения человека это профессиональная конференция разработчиков нагруженных систем таких примеров может быть много Мы составляли наш тесте по этому принципу Но другие публичные бенчмарки в которых есть тесте на мультимодальной они в принципе похоже похожей концепции и тоже создаются там вроде Понятно с метрикой как сопоставлять ответ системы и правильный ответ человека методом пристального взгляда всё понятно мы видим ответ и мы прикидывается лексику Я люблю распознавание речи я периодически привожу пример из распознавание речи в распознавании речи для того чтобы сопоставить то что распознала система И то что она должна была распознать использует verter Rate на основе динамического программирования считают оптимальное число минимальное число вставок замены удаления необходимое для того чтобы там это слово хлеб превратить в слово пиво там или наоборот да слово хлеб - это пиво с написано четырьмя ошибками Вот соответственно вот такой таким способом мы оцениваем качество чем больше вот эта величина числителя тем больше ошибка verter raate или character raate если мы на уровне символов оперируем и тем хуже но так можно оценить слабый искусственный интеллект а сильный искусственный интеллект так не оценить приведу пример э тот же самый вопрос Что такое конференция лот вот то что мы хотели от системы получить - это профессиональная конференция разработчиков искусственно высоконагруженных систем а ответ Наш искуственного интеллекта может быть это конференция обо всём Что актуально для специалистов работающих или планирующих работать системами высоких нагрузок реального времени по смыслу та то же самое система Молодец но лексического сходства около 0% там только слово конференция встречается и в правильном ответе и в сгенерировано в ответе лексические меры сходства не не подходят для оценки качества нужно что-то другое и вот что-то другое было предложено так называемая Арена для искусственных интеллектов смысл в следующем мы Нам очень сложно оценить насколько хорошо отвечает наш искуственный интеллект или не наш искусственный интеллект но мы можем сравнивать два искусственных интеллекта вот как двух бойцов в боксе или двух шахматистов в партии и присуждать победу кому-то одному вот допустим лава отвечает получше чем допустим Лама 7Б с мультимодальный адаптером к примеру э это можно оценивать не по лексике А по семантике опять-таки тут два варианта либо Нам нужен человек судья но мы выяснили что с человеком судьёй сложно их таких людей нужно привлекать когда мы делаем новый сабмит нужно заново собирать коллектив людей остров судей А можно попробовать сделать по-другому Пусть нашим судьёй будет система искусственного интеллекта заведомо крутая там самая крутая на планете и это Например Chat gpt Ну сейчас это уже не так сейчас например Клод от anopic тоже может быть такой же крутой как Chat gpt 4 но тем не менее chg pt4 - это Эталон и вот мы вместо человека судьи используем CH gpt с помощью специальных вопросов просим chpt оценить насколько ответ той или иной системы совпадает с тем что разметили люди вот к примеру пара примеров из того бенчмарка Тай LM Benchmark часть мадалина которую мы использовали для оценки нашей системы по гамбургскому счёту объективно есть ответ Есть Ground Truth там да или там Круг и есть ответ который сгенерировал модель и есть gpt который говорит ответ модели правильный да или нет И ещё Она подробно рассказывает почему она такое решение приняла почему она оценила положительно э маленькую мку или там отрицательно Таким образом мы автоматизируем сравнение но при этом сохраняя достоинство семантики то то что мы по смыслу оцениваем ответы наших маленьких ллк а не чисто по лексике и вот мы решили потестить нашу систему на таком Вот бенчмарке и вот результаты там не было общего Over с Точнее он был но он не интересен а там оценивались все вопросы все задачи в бенчмарке были разделены по некоторым группам например Vis какой-то здравый смысл визуальный какой-то object gation насколько модель устойчива к галлюцинация какой-то Vis там и тому подобные штуки и вот здесь по вот этим всем аспек интеллекта мы построили диаграмму жирным линия это варианты нашего Нона пунктирным линиям Это не наша системы это наши аналоги такие как лава Лама с мультимодальный интерфейсом бар Гугловский и тому подобное и мы видим что первая версия нашей системы основана на мистрали в принципе себя показывала примерно на уровне Лавы мы модифицирования первой версии на местраль второй версии инструкционно стало лучше а мы подумали А насколько большую роль играет здесь размер самой модели Мистраль - это 7 млрд параметров может быть можно в качестве управляющей ЛМ использовать модель поменьше например Ф3 от майкрософта она меньше 4 млрд параметров Сказано сделано заменили большую модель на маленькую и получили результаты не просто сопоставимые А даже чуть лучше чем ответы большой модели потому что в такой системе когда мы говорим о по мультимодальной системе основанной на распознавании через припоминание на поиске на Крос модальном рак именно инъекция знаний из внешней базы в модель играет более важную роль чем способности самой модели даже маленькая модель может извлекать информацию из подводки и правильно отвечать величина здесь только помеха она будет медленнее инса И всё И если вы Обратите внимание по некоторым способностям наша модель наш мин например Visual Common Sense смог превзойти даже такого гиганта как Гугловский Барт в других способностях например Vis acquisition там где нужно было текст на картинках понимать подобные вещи мы хуже Но а допустим В визуальном здравом смысле мы оказываемся лучше благодаря вот этому механизму знаний через припоминание В общем результаты очень интересные оказались история наша на этом не закончилась мы сделали систему мы её Разместили Но во-первых э-э то что началось как такая история ради фана ради участия в соревнование продолжилось тем что университет поддержал нашу разработку грантом ээ мы сейчас пишем статью И самое главное мы сейчас делаем по заказу университета систему которая бы могла общаться с абитуриентами э и рассказывать им как какие-то философские ответы давать куда пойти учиться лучше всего на какой факультет так и конкретные вопросы какие документы Куда подавать Правильно ли всё заполнить и тому подобные вещи Вот то есть но какую пользу можно извлечь из этого для вас я подумал подумал и сделал такие заключения э прежде всего моя история Мне кажется будет полезна тем что систему сильного искусственного интеллекта можно сделать не через опиш какого-нибудь э ча gpt там или другим большим системам а её можно развернуть локально и у себя собрав из осор сны компонентов Это самый первый очевидный вывод и будет в принципе неплохо второй вывод ээ концепция компонентная концепция компонентная архитектура на основе распознавания через припоминание это в принципе гибкий и достаточно нетребовательный к железу способ управлять знаниями системы поскольку мы выносим мультимодальные знания из системы э нам нет необходимости очень большую лэм держать на иренс можно сократить размер лэм знание - это через Крос модальный Эмбер и через поиска реализуется соответственно такая компонентная система удобна Если вы не Google и не openi со 10000p и при этом в такой системе качество распознавания через припоминание играет наверное даже большую роль чем сама МКА и внимание нужно уделять именно механизмам векторизации и поиска и наконец Когда вы такую систему разрабатываете вы конечно должны ориентироваться на известные открытые бенчмарки но при этом если вы делаете специализированную систему там для врачей например для людей которые занимаются медициной старения или для Геологоразведчиков вам имеет смысл сделать собственный бенчмарк по таким принципам которых мы с вами говорили для того чтобы оценить именно на вашем домене на вашей задаче качество работы мультимодальной системы здесь можно использовать API для того чтобы какую-то большую наворовали Арена это но место где имеет смысл использовать какой-то Облачный API к большой мке таким образом вы получаете релевант ную оценку того насколько ваша система хорошо работает именно специфически вашем домене Ну и мой рассказ В принципе подходит к концу прихожу к самой наверное приятной части благодарностями сидит ээ поддерживает работу Нона чтобы он не упал аспиранты студенты это раз во-вторых наш подвал я говорил что мы собрали искусственный интеллект у себя в подвале поэтому наш подвал вот такой в институте теплофизики Спасибо нашему за Вла буу за то что пускал в наш подвал ээ там Некоторое количество пушек 20 NVIDIA Tesla A1 примерно 3.000 цпу AMD Epic в принципе подвал плохой некоторые считают что это лучший подвал по Восточную сторону Урала в России и мы там проводили все наши исследовательские эксперименты и соответственно там мы организуем иренс нашей Системы ну и наконец Спасибо вам дорогие слушатели за то что вы проявили интерес к искусствам интеллекту Надеюсь что мой доклад был для вас полезен что вы что-то новое почерпнули Если так то голосуйте если не так то тоже голосуйте Справедливая критика - это всегда лучше чем её отсутствие Спасибо за внимание друзья друзья у нас чуть меньше времени на вопросы чем обычно поэтому ловите лайфхак вы вступаете в чат зелёного зала и я чередую вопросы из чата и из зала оффлайн Давайте начнём с офлайна молодой человек на первом ряду Здравствуйте Роман Васин компания Арена Спасибо за очень интересны доклад Надеюсь презентацию можно тоже как-то скачать вот я хотел как бы задать вопрос по очень интересной теме которая никак не была как бы озвучена а именно контекст разговора Поддерживает ли ваша система контекст разговора по тесту Алана тьюринга если человек общается с машиной например 10 минут он может определить это машина вернее это или человек задаём 10 вопросов в вашей системе но очень сильно контекста связан и я думаю как бы можно определить то что Ну это как бы машина и как бы есть ли какие-то бенчмарки по поддержке контекст по проверке потому что получается система диалоговая диалоговая мультимодальная мультимодальная но контекст не поддержит и тест тьюринга не проходит Есть ли мировые бенчмарки где можно проверить свою систему на поддержку контекста Спасибо за вопрос Да действительно наша система поддерживает контекст мы тестировали на нашей тестовой выборки с учётом контекста то есть там могла быть серия вопросов само соревнование Ир тоже было с учётом контекста чтобы модель могла отвечать другое дело что к сожалению бенчмарком поддерживают такой контекст именно мультимодальных не так уж и много они есть но там ограниченное количество самые известные бенчмарки это именно вопросно ответные системы без учёта контекста но контекст наша система поддерживает вопрос длины контекста - Это вопрос не только семантически но и вычислительный я здесь кстати говоря о многом не рассказал Я вроде на конференции Хало выступаю Да но я ни слова не сказал о лоде А это важно в том смысле что если мы говорим о длинном контексте в таких моделях ЛМ используется механизм внимания он имеет квадратичную сложность теоретическую соответственно увеличи длина контекста сильно увеличиваются затраты памяти модель падает для оптимизации существуют варианты аппроксимации классического механизма внимания блочным вниманием там Flash Attention есть специальные фреймворки для имы использовали для работы Но на самом деле можно использовать и другие вещ о которых я не рассказал потому что за пределами доклада для организации оптимального по памяти по скорости инса это обеспечивает вычислительную возможность организовать контекст а такая теоретическая семантическая возможность у модели нашей Нона беседовать в контексте есть Безусловно вопросик в конференции было про подвал допустим у меня дома в подвале всего лишь 23060 и этого мало сейчас набирают популярность внешние акселераторы для всяких разных моделей которые мощнее И самое главное дешевле вопросик вы тестировали это дело и как оно вообще по итогу спасибо спасибо за вопрос мы не тестировали сейчас модель развернута даже не на А1 А на В1 и она занимает в ходе эксплуатации примерно от 20 до 24 Гб видеопамяти И это при этом как я уже отметил не сильно оптимизированная модель если мы используем механизм внимания типа Flash Attention то у нас почти Линейная сложность идёт соответственно ещё расходы на память снижаются там возникают вопросы связанные с обучением но речь идёт прежде всего об иренс То есть это действительно вещь которая может быть развернута в подвале на одной железяке как-то так Следующий вопрос из чата от Анатолия Разумовского Сколько времени было затрачено на обучение и сколько это стоило бы по рыночным ценам Спасибо за вопрос по сути дела обучение Здесь как такового в строгом смысле обучение машинное обучение - настройка параметров алгоритма на обучающей выборки обучение как такового не было была конфигурация самого мультимодального при поминания мы на тестовой выборке оценивали и вот оптимизировали само решение добавлять туда узнавание Единственное что было обучена это модуль анализа главных компонент для сокращения размерности признаков то есть была векторизация всех 70 млн параграфа Википедии поскольку там вектора размером 1500 мы их сокращались асванг анализ главных компонент то есть обучения как такового не было И это ещё одна сильная сторона Вот это компонентного подхода когда мы строим систему компонент мы не нуждаемся в обучении больших тяжёлых моделей вместо обучения на 10000 GP мы не openi мы не Google у нас нету столько GP мы должны непу работать а головой работать мы используем архитектурные трюки и специальный пайплайн для повышения интеллектуальности инъекции внешних знаний в модели то есть здесь обучения Как такового этой мки не было мы э с до чере адаптере ада это сильно большой эффективности не даёт это некое приг стиля ответов даёт но какую-то новую семантику не добавляет Следующий вопрос от артма Баталова насколько необходимо использование рак для работы мультимодальной системы не будет ли достаточно мй э с базовым вариантом она по знаниям оказалась хуже мы проводили эксперименты с Open Source нами альтернативами типа лава вот я об этом упоминал и на слайдах можно было видеть что в общем-то по всем аспектам знаний на бенчмарках такая модель проигрывает безусловно есть вариант строить прямо - to end систему с нуля Судя по всему gpt 4o Вот которую не так давно релизинг Скорее всего я могу только предполагать потому что Open по факту нужно меть в клоз они не говорят об особенностях своих решений но скорее всего там был ту подход реализован но он очень сильно требователен к железу на этапах обучения наш подход резко снижает требования к железу но при этом обеспечивает хорошее качество знаний и возможность черепин База знаний то есть гибкого управления актуализации без полного цикла до обучения модели знания модели ограничены обучающей выборкой если мы е обли вре году она ничего не знает про год в ситуации когда у насс модальное припоминание мы обновляем нашу базу знаний Всё теперь модель знает проче год Давайте молодой человек у колонны Здравствуйте меня зовут Алексей работаю в Озоне учусь хотел спросить просм это какая-то вещь действительно взрывающаяся текстовый запрос это работает круто но если я спрашиваю что-то с изображением то там много шума на фоне какая-то улица машины и размывается смысл того вектора вопрос В чём Есть ли какие-то открытые решения которые позволяют картинку разложить на какие-то ортогональные векторы чтобы потом с помощью а или чего-то ещё выделить Какая какой смысл изображени нужен СБО за вопро мы сейчас делаем чатбот для абитуриентов я об этом упоминал и там вопросы связанные с чтением визуальной карты с чтением визуальных отсканированных каких-то документов и тому подобные вещи то есть там Много мелких деталей это буквы это какие-то элементы карты и соответственно в нашем архитектуре это решается использованием дополнительных унимодальная это это решение для распознавания карты и каких-то гео построения гео таким именно благодаря какой-то такой компонент мы можем добавлять новые модальности и в наше Крос модальное припоминание пи архитектура гибкая расширяемая и для узнавания как отдельные Ути модальные ры и обеспечивать опять-таки без полного цикла до обучения большой языковой модели добавление новой модальности собственно мы сейчас как раз занимаемся вопросами связанными с с тем чтобы Нон умел карты понимать схемы смы корпусов и какие-то тексты потому что это важное для важное умение для наших абитуриентов друзья Мы не успеваем задать все вопросы оставшиеся будут вот здесь вот в дискуссионной зоне и у нас последний вопрос Со второго ряда Да погодите Да у меня уже микрофон Спасибо за доклад очень интересный хотелось уточнить Вот вы использовали для построения своей системы только Open Source модели или какие-то ещё свои доработки делали мы использовали только Open Source модели мы делали Ну доработка это собственно наш наш архи наш pipeline который был реализован ну и доработка до обучения там отдельных компонентов сжатия размерности саму саму всю систему мы планируем в ближайшее время выкладывать в Open Source мы могли бы это сделать и раньше просто нам стыдно зареч код пока что мы его сейчас Фактори и И через некоторое время Мы выложим это решение в Open Чтобы другие могли его использовать там расширять и так далее поскольку мы используем Open Source Для нас это важно И идеологически что мы какой-то вклад в Open Source делаем Ну это возможность развития продукта не только нами А и другими заинтересованными контрибьютор друзья Спасибо за вопросы теперь пришло время выбрать лучший вопрос и одарить вопрошающий выбор конечно вопросы были очень хорошие все но вот мне кажется вопрос про контекст про умение удерживать контекст в диалоге это был очень интересный вопрос Вот кто его задавал вот да вот собственно Вот этот мне кажется был вопрос Аплодисменты за лучший вопрос лучший среди хороших"
}