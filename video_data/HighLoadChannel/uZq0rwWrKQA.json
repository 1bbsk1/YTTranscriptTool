{
  "video_id": "uZq0rwWrKQA",
  "channel": "HighLoadChannel",
  "title": "РБК и неожиданный хайлоад / Анна Абрамова (РБК)",
  "views": 699,
  "duration": 1742,
  "published": "2023-01-19T07:01:38-08:00",
  "text": "когда я думала над названием этого доклада я ожидала что конечно же он его спровоцирует а с понятным персонажем мальчиком который выжил да и его противостояниями кому-либо и в целом то что с нами происходило наверное это действительно можно назвать как рбк который выжил и так рбк и неожиданных айклауд традиционная конечно начну с того что расскажу собственно кто я что из себя представляет рбк и первую очередь я конечно хочу это сделать для того чтобы вы прочувствовали что мы такая же компания как и вы у нас тоже есть все то же самое и если вы тоже подвергались высоким нагрузкам и при этом не являетесь гугла мама зонам фейсбуком и масштабирования он у вас происходит по щелчку пальцев то это боль которую мы ощутили вам будет знакомым и так меня зовут аня абрамова как уже меня представил я директор по разработке в рбк что касается наших продуктов это мобайл веб внутренние системы сама я умею react сочувствую фронтэнда и питон но моя любовь на всю жизнь java так что если вам хочется про это поговорить в колорита я готова раньше я работала в суровом банкинге как валенки сбербанка переломана вид на микро сервисы в розничную кредитном конвейере привет коллегам если вдруг вы здесь и немножко поработал за рубежом тоже над микро сервисами собственно а так и сфен тех а я перешла в media-tech это длинная история но рбк действительно можно назвать media-tech компании собственно что если барбато представляет в держи таня это более 20 сайтов это 5 мобильных приложений приложения под тв у нас даже есть свои озеро данных hadoop о да да да но есть а платформа персонализации автотесты нагрузочные тесты в целом у нас очень весело драйвово релизы каждую неделю совершенно не скучаем что касается основного сайта про которой скорее всего вы слышит да и который может быть даже когда-то своей жизни открывать наш сайт представляет собой немножечко микро сервисную архитектуру мы-то не конечно же стремимся что из себя он представляет с точки зрения своих компонентов это достаточно большое количество разных сервисов причем на совершенно различном стеки это сервис новостей это рекламные системы это финансовые данные видео данные эта интеграция с другими продуктами потому что мы тоже правой экосистема да да да эта статистика платежи данные пользователи рекомендации поиск и на самом деле еще много что но вот к этому слайду и к этой диаграмме я еще буду обращаться и подробно расскажу собственно где какая технологию на что сделала во время высоких нагрузок и такие выводом из этого сделали что касается нашими стайкой команд как я уже до этого сказала стык у нас широкий но дружный php и java ушка моя любимая питоны java script с react а мастера вания как я уже сказала не просто ручное но еще и с приводом для авто и нагрузочных тестов у нас есть мобильная разработка подается android озеро данных и даже до devops мы вполне себя в тренде я очень хорошо сейчас хвасталась да но вот такой вот мемчик я тут вставила эрнест хэмингуэй в какой-то момент поспорил что можно написать очень очень грустный рассказ и рассказ выглядел следующим образом а не спрашивайте почему мы не переходим на git так исторически сложилось я не хочу скрывать от вас это было бы нечестно у нас конечно же есть тех долг у нам есть над чем работать у нас есть вегасе что-то хорошо бы повысить до новой версии что это хорошо бы перевести на другие технологии и вот именно в такой ситуации нас застал неожиданный highload если представить как команды рбк выглядела полтора месяца назад наша этичная команда то наверное вот эта картинка очень хорошо все передает то есть мы были на вершине прекрасных американских горок с которых мы должны были неожиданно для себя спуститься мы успели подобно вид часть наших систем мы ожидали что мы будем сейчас проверять как они себя поведут продакшене но специфика нашей работы устроена каким образом а каждый раз когда в мире и в нашей стране в том числе до происходит что-то необычное то все идут к нам узнать что это вообще значит что вообще происходит и в этот момент происходит так называемый инфоповод инфоповод эта новость которая собирает особенно ощутимую нагрузку и привлекает внимание пользователей и это как правило больше 350 300р псы вот каким инфоповодом если мы были готовы дата к тому инфо поводу про который вы понимаете мы конечно мы такого не ожидали то есть мы обновили наши системы хотели посмотреть как это все будет выглядеть продакшене но нагрузочное тестировал дня и пришло к нам с тому скажем так что мы наблюдали до long story short мы наблюдали вать вал 500 киба ней и задавайте себе вопросы что вообще происходит что происходит с нашими системами как нам вообще с этим быть а вот что происходило нас накрыло два с половиной миллиона запроса в минуту на этой картинке вы видите так называемую волну убийцу просто для информации для нас не характерно такое количество запросов в минуту обычно такое количество пользователей к нам просто приходит течение дня но если спокойные выходные какие-то идут вдруг всем стало очень интересно почитать наш любимый главный сайт а история на самом деле достаточно драматично я постараюсь рассказать и и веселых тонах но огромная любовь моей команде огромное спасибо всем кто в этом участвовал ощущение у нас были достаточно тяжелые и достаточно тяжело тяжело мы это все переживали то есть это наверное хорошо передается вот такой был футболка хорошо бы передавалась да что там недосыпа до пяти утра не возможность отойти от компьютера поесть и вот этот все прекрасно но хорошо давайте закончим на этом драму и поговорим про то что собственно что мы делали когда это произошло с нами фактически то что я вам расскажу это выводы из нашей истории которые с нами произошла я поговорил про мониторинг про критично систем про масштабирования и как мы это делали про реестр отключение вообще отключение деградации систем и про доработки создания систем которые мы решили возобновить собственно давайте поговорим про мониторинг сразу говорю извините меня за любовь к диснеевским персонажам но они тут будут немножечко мониторинг наверное не самый характерный мониторинг который можно было бы ожидать мы делали в момент пиковых нагрузок это мониторинг сайта глазами дело в чем дело в том что никакие даже самые хорошие автотесты не ответят в момент когда не только вы подвергаетесь высоким нагрузкам а что вообще происходит то что происходит нормально или это ненормально котировки валют они нормальные линии нормальный то что они не приходят это нормально или ненормально соответственно мы установили дежурство в нашей команде были дневные и ночные дежурства и мы условно говоря проверяли огонечек горит не горит mvp в порядке не в порядке и старались быстро реагировать на то что им пеппи не в порядке естественно у нас был monitoring of the t ставим вы мне расскажите как вы так могли делать надо же было отключить полностью автотесты до высокая жена гру к но здесь речь идет скорее про эти авто тесты которые говорят нам про то что интеграции не оборвались что данный от наших поставщиков продолжают поступать да вот как я до этого сказала данные бирж что у нас продолжают нормально работать наши внутренние интеграции между системами у нас их достаточно большое количество как вы видите и это все наверное тут немножко по капитану удобно конечно же очень переводить в какой-нибудь часик чтобы там уже оперативно реагировать на эти или хорошее или не хорошие изменения это понятно что уже совсем внутрянкой систем и эта вещь которую нужно делать заранее понятно что уже если вы оказались в ситуации хай-лоу дата писать автотесты бесполезно но если они у вас есть то мой достаточно странный совет не отключаете все таки у вас будет хоть какое-то понимание того что пошло не так ну и конечно же я вас наверное не удивлю у нас есть и прекрасные икебаны игра фаны центре и именно там мы наблюдали в каком состоянии находится наша экосистема наш архитектурный ландшафт сгибание мы наблюдали 500 и которые росли как снежный ком и безумная волна в графа не мы смотрели все ли в порядке с нашими серверами и в центре наблюдать за за нашим а белом если вдруг у вас не подключены эти системы и вы хотите тоже почувствовать бали хай лоу то ну конечно же я вам советую подключить я уверена что на этой конференции есть множество докладов где можно узнать как это сделать корректно как ни странно конечно же очень важно наблюдать за тем что критично да то есть мониторить просто все подряд и времени не хватит людей не хватит не хватит никаких совершенно сил но и спасать все что есть а ну в большинстве случаев продукты я думаю что и которые вы разрабатываете с которыми вы работаете они достаточно сложные бесполезно пытаться спасти все надо спасать только то что критично что может быть критично ну во-первых может быть что-то критично для бизнеса мы на него работаем до и мы пытаемся спасти то что дорого сердце бизнеса в нашем случае это сервис новостей это рекламные технологии и это финансовые данные то есть это то что наши пользователи ожидают придя на сайт увидеть соответственно мы понимали что вот этот вот треугольничек условно говоря должен быть спасен сервис новостей у нас прекрасные php ребята спасибо вам что вы есть рекламу у нас на джесси и финансовые данные у нас на питоне то есть понятно что эти системы могут себя по-разному повезти под нагрузками и это очень весело что касается еще того что может быть критичный что наверное тоже стоит держать в уме и спасать если нужно это смежные системы потому что нагрузка которая придет на вашу систему может за эффект и другие системы то есть если вы тоже экосистемы и вы интегрируете например яндекс метрика и или с какими-нибудь другими каналами или с другими продуктами которые есть вашей компании то эти продукты увидят вот эту дополнительную нагрузку от вас у нас это было интеграция с продуктами которые не основные наши новостные но рбк право там и другие профессиональные продукты и конечно им досталась достаточно сильно дальше я расскажу что держа в уме что мы не должны положить наших друзей условно говоря нашей смертной системы мы делали и также естественно стоит выделить для себя а кто в принципе генерит высокие нагрузки вообще всегда потому что понятно что если у вас есть например событие на ориентированные системы до которые в каску кидают сообщение о том что вот пользователь сюда зашел пользователь зашел в другое место то у вас в целом это уже очень высоко нагруженная система и когда вы получаете дополнительный highload которому вы по честному особо не готовились то это то что стоит мониторить в первую очередь очевидно что это конечно видео данные ну для нас по крайней мере потому что у нас есть данные в разном разрешения их очень очень много и автозапуск видео у нас происходит автоматическом режиме если вы заходите в новости ну и это финансовые данные потому что мы получаем данные из h5 источников из московской и питерской бирже и других источников и они идут к нам практически в режиме реального времени соответственно если вдруг торговля происходит побыстрее с учетом каких-то изменений то мы тоже это чувствуем и тоже должны быть готовы к тому чтобы что-то с этим делать понятно что если очень сильно за paranoid то можно представить себе что критично вообще все и вот эти классные возможности там лайка дизлайкать материалы такие классные критичные и там push-уведомления это очень критичный вообще все очень критично весь наш сайт такой классный давайте попробуем спасти во весь но к сожалению тот вывод которому мы пришли это не вас невозможно сделать стоит спасать mvp который ожидает бизнеса естественно попытаться успеть согласовать с ним потом випе который мы спасаем это изоляция смежников потому что они не виноваты что мы часть этой системы и это сокращение событий в событийных системах где бы в системах которые генерят учим высокие нагрузки теперь давайте поговорим про масштабирование собственно что можно сделать в тот момент когда пошли очень высокие нагрузки и вы не amazon который по щелчку пальцев раз-раз-раз развернул себе много серверов что делали мы во-первых мы исходя из критичности систем задали себе вопрос что мы будем дополнительно спасать и что с точки зрения архитектуры нам позволяет вообще сделать масштабирование потому что как я вам уже говорил а у нас такая ситуация что ну не все можно масштабировать по честным и не все нужно масштабировать нигде всего это подходит такое решение мы стали масштабировать сервис новостей и сервис видеоданных какая у нас ситуация с тем как устроены наши сервера скажем так у нас свои сервера на свое железо оно стоит у нас и наверное это достаточно неплохая концепция если вы такие же пары медальные как мы не верите в облака вот никогда туда еще пока не ходили и вообще у вас это все пока что немножко пугает соответственно наверное схема для вас если вы помните как все начиналось с ним не необычная нас и зеркало и наверное ни одно у нас есть мастера у нас есть мастера бэкенд сервисов на зеркалах находится каширу ющий прокси и на мастерах и джинкс и и приложения непосредственно и конечно это приложение взаимодействие с каким-то дополнительным брендом соответственно что можно делать с период нагрузок можно либо масштабировать каширу ющие прокси на зеркалах не бы можно масштабировать мастера в целом мы пошли и потому и по другому сценарию сначала мы в виде встроить сервера нагрузочного тестирования и тем самым promise to be равале мастера затем мы попытались скакануть в облака но скачок получился достаточно сложный потому что а если у вас точно так же как у нас сложные маршрутизации прописанные на прокси это так легко это не произойдет мы пробовали индекс облака и с первого раза у нас и не взлетела то есть если вдруг вы тоже видите что у вас идет высокая нагрузка давайте масштабируемся срочно когда-нибудь то нужно держать в уме что не факт что все взлети с первого раза по крайней мере такой кейс был у нас и так собственно что я вам предложил ahi что мы делали мы бросали просто дополнительные мощности примерно как вот эту несчастную рыбку до облаке кода ужасную высокую нагрузку да к сожалению это помогало но до определенного момента и здесь я должна сделать видимо вот так потому что да у нас были отключения и деградации системы и в целом может быть это и не самая страшная вещь если вы хотите сохранить свою систему вы можете города продолжает сохранять весь функционал но до определенного момента что касается отключений что я здесь понимаю это одной стороны упрощение системы их деградация с другой стороны вообще полное отключение систем в предыдущих сериях до мы с вами поняли что есть система критичные есть системы которые ну и ладно что их нет и и соответственно мы естественно старались сохранить те системы которые критичные то новости это реклама и это финансовые данные у нас достаточно быстро выработался план о том в покой последовательность что мы будем отключать при какой нагрузке то есть мы прямо прописали его мы согласовали это с бизнесом естественно чтобы они не были удивлены и мы ее мы следовали да у нас был план моему придерживались что нам в итоге пришлось отключить мы практически сразу отключили сервис статистики сервис статистики у нас использовать технологию кафка и java java конечно крутая многопоточность и так далее но на такой высокой нагрузке мы увидели а деградацию кластера кафки мы носили его перенастраивать мы начали сокращать время жизни сообщение мы стали расширять кластер но она таких высоких нагрузках и это тоже не помогло ну и плюс конечно же мы на стадии наблюдается в нашем озере данных явно я уже его переполнения мы обвинили естественно мысленно себя в жадности и что наверное мы собираем слишком много сообщений и на будущее сделали для себя выводы тоже я принести с расскажу мы отключили наши рекомендации у нас есть рекомендательная платформы рекомендательная система и оно понятно что достаточно сложная на в режиме реального времени рекомендует пользователю какие-то видео какие-то статьи и понятно что под высокими нагрузками такой системе было нелегко потому что она не рассчитывала на это тоже на джаве тоже немножечко e-mail я возможно что когда-нибудь расскажу про это когда мы окончательно соединимся нашу платформу персонализации и мы решили отключить наш сервис поиска он дал без на работал с нами с 14 года он был классный плюсовые и на тот момент создания был скорее всего для своего времени неплохо но мы поняли что нет к сожалению на данный период времени на пиковую нагрузку мы с ним прощаемся мы немножко деградировали наш сервис новостей то есть если раньше у нас были постоянные обновления у нас там авто запускалась видео и была куча очень удобных примочек мы адские вещи которые дополнительно нагружали просто подгрузку отключили что касается финансовых данных здесь ситуация была очень похожи на сервис статистики то есть тоже к нам стало поступать огромное количество данных сервис был на питоне я тоже ему было очень больно и тяжело и мы сократили достаточно быстро количество данных которые мы получаем от бирж потому что торги на биржах ускорились мы понять и что мы жадные нам столько не нужно будем это все отключать и то же самое было с интеграциями с другими продуктами то есть тоже мы поняли что интеграция в режиме онлайн нам видимо сейчас не нужно видимо нам хочется сохранить эти другие продукты они тут не причем они не совсем про то ради чего к нам пришли и за каширование интеграции с ними на достаточно длительное время и перестали их ломать своей наведенной нагрузкой что я могу посоветовать если на вас пошла высокой нагрузкой вы дошли до периода когда начали отключать свои системы скорее всего вы точно так же как и мы в пять часов утра уже не помните что же вы вообще отключили зачем вы это отключили когда вы это отключили это было в рамках задачи или просто уже ну так так сложилась ситуация скажем так стоит вести реестр отключений включение то есть у вас должен быть disaster recovery план то есть после катастрофы что вы будете делать как вы будете включаться быть или вы включаться полностью а может быть вы вообще не будете включать пока что этот сервис и будете его оптимизировать дорабатывать после этого включится а может быть это вообще какой-нибудь store старый кэш вы его почистили до свидания этот конечно больше не нужен если ответственно а критичность включение систем тоже должна соответствовать до тому что вы выявили в самом начале мы сделали выводы из того что с нами произошло то есть мы пересмотрели свои в том числе продуктовые план и мы поняли что часть системы будем создавать заново часть системы будем достаточно сильно дорабатывать и это коснулось как вы видите на вот этому супер мега графики большей части наших систем то есть мы поняли что мы продолжим обновлять оптимизировать сервис подгрузки новостей мы будем переходить на более новые версии php мы будем переходить на более новую мангу мы будем думать про горизонтальное масштабирование практически поселку по щелчку пальцев в облака и пытаются превзойти преодолеть те проблемы которые мы наблюдали в тот момент когда шла очень высокая нагрузка мы буквально за несколько дней перешли на вообще другой из сервис рекламы и спасибо огромное за это команде потому что ну это тоже на самом деле немножко про наведенную нагрузку мы увидели что реклама стало тяжело вот мы поняли что в нашей платежной системе есть определенные нюансы тоже стоит оптимизировать и что несмотря на то что поттер api гей твой такой классный возможно что имплементация было не самое удачное мы отключили поиск и включим его после полной переработки после перехода на elastic search финансовые данные мы переводим на тарантул и я надеюсь что в какой-то момент уже летом сможем про это рассказать статистику мы тоже переработали поняли что мы жадные убрали часть событий и поверили в то что она выдержит теперь очень высокие нагрузки и сервис рекомендации тоже переработали также что касается полностью новых продуктов и новых приоритетов развития которые мы для себя сознание мы поняли что в общем-то высокие нагрузки и это вещь которая может произойти с компанией которые достаточно технологично но которое не ожидает изначально по своим продуктовом да не функциональным требованиям очень большое количество пользователей мы поняли что нужно ставить перед нашими системами балансировщик какой-то более крутой чем и джинкс без обид к индексу поняли что а мы будем оптимизировать нашей системы переводить их на совершенно другой стек в части продуктов и на самом деле из позитивных вещей мы поняли что мы можем это выдержать в части mvp мы можем это выдержать и что сейчас самое идеальное время для того чтобы договориться о новых бизнес приоритетах о том чтобы ликвидировать наш тех долг достаточно быстрыми темпами и для того чтобы передоговориться с бизнесом о том чем мы вообще будем заниматься дальше спасибо вам большое если у вас есть вопросы блага рада на них ответить of поднимайте руки вот будем подходить давайте микрофончик и может будет высказываться спасибо не и я тоже работал как-то похожим похоже компании тоже у нас были похожие проблемы так как 1 ряд и чеслав спасибо за доклад такой вопрос тоже сказала что пришло много нагрузки какую-нибудь систему защита да да сама на нее не было или просто она не выдержал этого у нас были и ни одна система которая балансировало нагрузки но у них тоже есть по изъяны соответственно мы пришли к выводу что мы будем строить свою систему которая по понятным правилам будет нагрузка балансировать понятно просто тот а тут до доз а тут настоящие пользователи пришли заблокировать можем все но в том-то и дело конечно то есть вот такие системы у них есть определенная проблема они могут подумать что ну ты как-то странно себя ведешь а это может быть связано что люди сидят в одной подсети да у одного провайдера и но да не заходит все на сайт не по минутам капча то же самое она помогает в таком роде как раз для людей разные системы по разному как раз интересовало какая используется не используется очень счастлив капча так давайте еще вопросики метку вопрос почему русалочка . главный персонаж выступление слайдов а ну дело в том что в далеком далеком детстве я хотела быть аниматорам диснея но максимум что со мной произошло я немножечко поработала выходите у них есть поэт она лежала между прочим да да да он мне кажется почти у всех есть python отжала и где-нибудь немного java скрипта так еще вопросы поднимайте руки может быть онлайн есть какие то вопросы так ладно вопросов не давай что вы стоим просто минут минуты две-три просто пообщаемся такой вопрос нагрузка во сколько раз увеличилось вас ну то есть у нас было два с половиной миллиона запросов в минуту при этом в течение дня обычно именно такое количество приходила если это допустим выходной и но люди так серфит немножечко сайтик но не особо активно то есть она возросла огромное количество раз понят расскажи немножко провод факап и что конкретно подала поскольку минут были простое самое наверное длительное падение у нас было ну буквально пару часов но в тот момент когда люди не смотрят новости к счастью особенно то есть это была ночь 4 утра мы не спали мы смотрели наши новости но успели перенастроиться попасть в recovery плану поди за астарот с вот да мы составили буквально на коленке сразу же свой дизайн the recovery план он включал это что мы отключаем это как мы это будем включать обратно куда мы будем масштабироваться если вдруг нагрузка пойдет дополнительная на нашей системы и тогда я как-то выгнал то есть вы все значит видели нагрузку и решили остаться поработать над так и работать посмотреть на нагружают из офиса или удаленно все сидели удаленная работа поэтому мы удаленно у нас какой-то момент мне кажется когда мы сидели очередной раз в думе обсуждали что нам делать уже время в зуме превысила 4-5 часов у вас платный зум это неплохо хорошо так он спасибо"
}