{
  "video_id": "9zagbmkdFDk",
  "channel": "HighLoadChannel",
  "title": "Миллион RPS в YDB: история одного переезда Метрики / Александр Прудаев (Яндекс)",
  "views": 935,
  "duration": 2073,
  "published": "2023-01-19T05:55:18-08:00",
  "text": "доброе утро меня зовут александр пруда я разрабатываю движок яндекс метрики сегодня расскажу про переезд нет личного сервиса сборки визитов на я тебе распределенную отказоустойчивый вас данных также мы переехали железова балка для начала что такое вообще яндекс метрика это один из ведущих сервисов веб-аналитики по данным на которые ссылаются в википедия мы 3 в мире то есть вот первый столбец это доля сайтов на которых установлена система веб-аналитики а третий столбец это как бы доля рынка имеется ввиду только среди тех сайтов где есть хотя бы одна система веб-аналитики понятно данных у нас довольно много как это вообще все работает значит владелец сайта ставит java-script код счетчика который отправляет информацию о событиях пользователя на бэг-энде яндекс метрики то есть информацию о переходах по страницам также дополнительную информацию о дополнительных событиях например что человек положил товар в корзину затем к этим информации добавляется еще переходы из поиска перехода из маркета клики по баннерам все это группируются по сайту по пользователю и выделяются пользовательские сессии визиты то есть группы событий близкие по времени объединяются визиты эти визиты могут потом как-то атрибутировать а например по источникам трафика что сюда перевел поиск из одной поисковой системы сюда из соц сетей и тому подобное затем владелец сайта заходит на яндекс метрику и видит различные аналитические отчеты по эффективность рекламных кампаний по источникам трафика и там подобно значит данных у нас очень много понятна система распределенная отказоустойчивые она спокойно переживает потерю машины стойки серверов даже потеря дата-центра это порядка 3 вычислительных мощностей также движок обеспечивать экзо clearance обработку данных как это все устроено это такой большой конвейер микро сервисов где данные движутся от начала то есть вот вот исходные данные и постепенно каждый микро сервис дополняет данными вот эти события группируют визиты и пишет все это в house house используют таблицы реплики этот меш 3 который уже в дальнейшем и отвечает на аналитические запросы пользователей рассмотрим вот движение данных по конвейеру на примере одного микро сервиса во первых для передачи данных между микро сервисами также используется cry house но это отдельная инсталляция тоже crosse bc инсталляция где данные пишутся изолирована в каждый сервер то есть не используется какая-то репликация между ними мы сами пишем эти данные в 3 разных сервера вот эта информация о расположении данных это такой некоторые джейсон есть айди этих данных и список серверов где они хранятся как правило это небольшой кусок данных скажем 100 200 тысяч сообщений и вот вот эта мета информация вот эти джейсон и они хранятся специальных узлах звуки пир которые представляют из себя очереди вот у нас есть micro сервис хиты и обработанные хиты это как бы входная и выходная очереди выходная очередь свою очередь является входной для какого-то другого микро сервиса вот микро сервис выбрал какие-то данные для обработки считал их из одного из доступных мест как-то обработал таким же образом записал три разных сервера и вот создал выходные джейсон и выходной в очереди вот этот момент удаления и создания выходных джейсон of выполняется 1 атомарной операции в за гипер это делается для отказоустойчивости синхронизации экзо клемансо обеспечения обеспечение экзо клево once сервис борки визит визитов это один из центральных серверов сервисов так как через него проходят все события кроме того ему нужно хранить информацию о предыстории действий пользователя потому что события не всегда приходят в хронологическом порядке некоторые данные могут отстать некоторые данные отстают по своей природе так называемый оффлайн событием могут прийти через несколько дней соответственно для хранения вот этого вот этих историй пользователей предыдущих их действий ранее использовалась своя база на ssd-диски теперь мы используем и деби для этой цели как это раньше было устроено во первых все данные были шокированы по счетчикам что это значит что один счетчик целиком обрабатывается в одном шарди то есть на одном сервере самом деле на паре серверов потому что мы используем лидер фолловер репликацию зеркалирования потоков на случай отказа оборудования отключения дата-центра у нас есть 2 реплика которая хранит тут же состояние то есть порядка 50 сортов этот 100 серверов ssd более подробно как устроено вот эта репликация и зачем нам мульти version ность хранилища данных вот здесь также есть входная очередь 2 входных очереди это хиты и клики выходная очередь с визитами версия что такое версия это просто порядковый номер итерации демон это нужно для того чтобы понимать какая из транзакция была последней успешный то есть демон работает итеративно и каждую итерацию он инкремент вот эту версию если вдруг он упал по питанию и затем очнулся он смотрит пир что там написано то есть завершилась ли последняя транзакция или нет и соответственно имея мульти version ную базу у себя на ssd он понимает какое состояние консистентная значит как выглядит одна итерация мы выбираем несколько больших данных хитов кликов как-то их обрабатываем генерируем соответствующие визит и соответственно подняв из хранилища истории соответствующих пользовались пользователей затем составляем такой jason jason of как батч и кладем его в очередь репликации соседней реплики для того чтобы она обработала те же данные и пришла в то же состояние привела хранилище истории в то же состояние так выглядит одна итерация наш проблемы эта система во первых это плохая масштабируемость из за того что у нас данные хранятся локально и на ssd чтобы как-то пересортировать нужно как-то переносить эти данные во вторых не очень удачный способ формирования например во время крупного соревнования например во время больше матч со сборной россии на конкретный сайт на конкретный счетчик нагрузка может увеличиваться просто колоссально в масштабах метрики это не так уж много скажем процент или два тем не менее sharp начинает отставать не справляться с нагрузкой также это своя система репликации которая требует поддержания дополнительных инвариантов для того чтобы данные обработаны и в разное время если какой-то сервис пропал тем не менее нужно какие то дополнительные инварианты соблюдать чтобы вот эта обработанная очередь аппликации чуть позже привела к тем же историям пользователей понимая минусы вот эта вещь наши существующей системы мы думали как бы вот или переделать что в ней не так чтобы было лучше помимо вот сухих фактов вот этих требований это еще очень личная история потому что я видел как заканчивается ssd диски очень сложно было переделать эту базу данных на сжатие z с т.д. я видел как ломаются диски из из отпуска приходилось как-то подымать в колену то упавшего базу всех этих недостатков мы хотели лишиться вот что для этого нужно во-первых отказаться от этой репликации сделать вычислительные ноды в облаке и соответственно доступная из любой вычислительной ноды хранилище истории также вот это хранилище историй должно легко масштабироваться у нас были продуктовые планы по наращиванию нагрузки как по объему хранимых данных так и по нагрузке на чтения запись под требования к базе этого первых высокая доступность как для любых сервисов яндекса высокая отказоустойчивость то есть нас не устраивают какие-то простое мы не можем остановить конвейер начать потому что на целый час потому что нам нужно произвести какое-то обслуживание базы также чтобы вот отказаться от своей репликации нам нужно чтобы комменты были строго консистентной нужно лидер лидер репликация синхрона вернемся назад этот объем данных вот такой рпс 400000 это на момент переезда мы хотели еще больше увеличить нагрузку едете на момент выбора базы это 2017 год хорошая хрена альтернатив я тебе на самом деле было не так уж много назовут плюсы и деби это от транзакции поддержка диалекта и спел синхронная лидер лидер репликация и высокая файл толеранс то есть очень высокая доступность при отказе из серверов стоек дата-центров если даже на тот момент базы не очень может быть чему-то удовлетворяла потому что еще находилась частично в разработке мы были уверенны что вот эти цели будут достигнуты потому что это как бы закладывалась в дизайн также очень высокая масштабируемость этой системы вы можете начать маленького сайта затем вырасти до объемов метрики и ну вас прогнозируемый увеличится latency но при этом масштабирование может быть сколь угодно большим как устроена портится и тебе ну точнее не портится извиняюсь таблица таблица выглядит как обычная реляционная таблица есть некоторый первичный ключ особенность этого первичного ключа что первый столбец должен быть целым без знаковым числом это ян 32 или 64 он используется для разбиения таблицы на партийцы на самом деле вот все данные можно себе представить отсортированы по первичному ключу цену целиком по первичному ключу дополнительно по диапазону значений первого столбца я у нас выделяются партийцы вы можете сразу задать исходное количество партиций для для обеспечения высокого высокой пропускной способности как на чтение так и на запись но количество портится она изменяется динамически зависимость от различных настроек по объему партийцы по нагрузке на партицию они могут как разделяться так и соединяться вместе также для обеспечения мульти version насти база нам требовалось добавить версию то есть это номер последний номер той итерации когда мы записали события вот объясняю на примере вот картинка у нас есть у нас допустим и трасса номер 100 мы получили три события записали их с версии 100 затем пришли еще какие-то события второе событие она обновилась мы его записываем с версии 101 но вы событие 100 письменность версии 101 вот здесь если у нас допустим сервер упадет по питанию или потеряет сетевую связанность где-то поднимется в другом месте instance он посмотрит в тупике перк какая из итерации была успешной если этот кто-то демон увидит в базе как бы три события если 101 то увидит 5 выйти еще раз обращаю внимание что второе событие на пире записалась первоначальный план был в том чтобы просто научиться работать с новой базой читать данные из обеих баз понять что они совпадают и отказаться от локальных в ssd который постоянно ломается и имеет свойство заканчиваться вот такой план не удался по нескольким причинам во первых данный нельзя сравнить просто паба этого дело в том что у нас есть специальный механизм забывания старых данных и он по разному устроен в разных системах и разные данные в разное время забываются какие-то забываются через день через 10 дней через три месяца и они в разное время забываются в разных базах поэтому на границах визитов может возникать различия что здесь мы уже успели забыть а там еще нет так же вопрос производительности дело в том что у вас разная пропускная способность вот этой этапы работы одной итерации демона читаем данный склиф house читаем из ssd собираем визиты пишем вновь пришедшие события в хранилище истории вот на этапе чтения мы упираемся в первую базу на этапе записи во вторую почему потому что начнутся api чтения мы упираемся в аду железку в ssd на количество одновременно возможных рандомных чтений ssd а запись в и деби дольше почему потому что нам нужно во-первых данные дважды стерилизовать сначала мы из про табу фасе реализуем данные от точнее сначала в порто пусть реализуем затем про табу стерилизуем в байты эти байты пишем gdb тысячи партиций и каждая из этих записи это отдельный crosse bc commit совсем не гарантиями поэтому пришлось перейти к плану б более сложному нам нужно сравнивать не входные данные и выходные визиты для этого нужно обеспечить одинаковые входные данные то есть план в том чтобы поднять параллельно новую систему сразу с облачными вычислительными нодами и сравнивать уже выход старой новой системы вот для того чтобы обеспечить обе системы одинаковыми входными данными мы решили 3 использовать существующий механизм репликации просто вовремя итерации железные реплики она пишет вот этот матч джейсон жетонов данных которой она обработала не в аду очередь репликацию а допустим в 11:01 для железной машины и 10 для наших облачных шар дав одно из железной машине соответствует 10 шагов потому что машина довольно мощное скажем 50 лидер а облачные ноты такие тяжелые держать не очень разумно поэтому вычислительные шардоне поменьше каждый shard обрабатывает какой-то диапазон как это подмножество юзеров которые в объединения дают тот же набор юзеров что обрабатывать железная реплика как разделить множество юзеров вот для шар дав мы решили использовать тот же хэш который используется в таблице для хранения истории пользователей для чего ну во-первых мы тем самым обеспечиваем то что с 1 партиции работает 1 шард ну максимум два если partition пришлась на границу шортов это избавляет нас отличная синхронизацию на стороне я тебе кроме того это позволяет лучше оптимизировать запросы мы можем за один физический запрос прочитать данные или записать данные сразу по нескольким ключам если у нас много партиций куда мы должны записать данные у нас будет лук хуже работать вот это вот оптимизация в чем состоял один подход копирования в том что мы запускаем настраиваем процесс который копирует постепенно в течение суток 2 копируют данные из старой базы в ногу затем когда процесс копирования завершён мы запускаем новую систему она догоняет своей очереди репликации ну и уже на этом этапе мы можем сравнивать выходные визиты что они совпадают конечно же они сразу не совпали вот этот процесс много раз повторялся мы понимаем что визит и как-то отличаются расследуем почему выясняем причины дальше какой-то bug fix разработка и повторение вот этого какие были основные проблемы почему гудит и рации повторялись ну значит во первых это сложный процесс мы работаем на живой системе это вот по сложности как операция на сердце причем сердце мы даже не можем остановить система работает и мы с этой железной реплики где данные постоянно меняются копируем данные в новую систему мы кстати здесь переиспользовать этот механизм с версиями те данные что лежат на диске мы вписались версии 1 div который генерирует постоянной операцию он питался с правильной версии с номером соответствующий итерации также были ошибки пир сортирования имеется ввиду изменение количества шар дав облачных этот механизм тоже должен хорошо работать на лету белль и без остановок система также были моменты производительности о некоторых оптимизациях рассказал так же самое смешное что вот все эти оптимизации придумали значительно уменьшили потребление циpкa на стороне я тебе у самой крутой оптимизации было то что мы избавились от бага мы выводили в лоб некоторое значение для вычисления этого значения пробегали по всему пишу событий в оперативной памяти соответственно с ростом размера кэша наши операции замедлялись и было очень нелегко найти эту ошибку когда мы ее исправили у нас просто в несколько раз увеличилась производительность одного облачного шарда после того как наконец вот этот процесс у нас сошелся мы избавились от всех богов визиты у нас совпадают хорошо и надежно нам нужно было избавиться от железных треплет железо вернуть чтоб использовалась в облаках для этого вот эта функциональность планирования итерации данных на одну итерацию мы вынесли и специальный облачный лидер этот облачный лидер также как и железной реплики мог захватывать лидер лоб и соответственно когда железный железный извиняясь облачный лидер когда захватывает лидер лак обе железные реплики работают в режиме ffa лаггера а облачные реплики помимо того что они визиты генерируют они их перемещают еще в выходную очередь визитов это обеспечил нам плавно и безостановочно переключение между старой системой в новую и обратно случай если в новой системе какие-то проблемы возникали они конечно тоже возникали через некоторое время процесс наконец-то сошелся мы убедились в надежности новой системы из закопали наши железные реплика одной из одной из продуктовых задач которого требовала увеличении нагрузки как по объему так и по производительности записи и чтения в базу была задача кросс девайс источников трафика о чем это есть у нас один и тот же человек и он логиниться с разных устройств мы понимаем что вот эти несколько юзер айди на самом деле один и тот же пользователь и владельцы сайтов хотят видеть статистику по источникам трафика с учетом вот этих вот сценариев кросс девайс дело в том что вот для таких сценариев нам нужно читать данные чужих шар дав это нарушает наши вот встроенную систему когда седален а и локально читаются нет каких-то блокировав на стороне я тебе и запросу у нас получаются большие сразу за многими ключами здесь по теории вероятности большинство вот этих кросс девайс запросов в других связанных пользователей они будут не в наши партийцы а в партиции принадлежащих чужим шердом и бываю так чаще всего так что мы в партицию делаем один запрос всего лишь за одним ключом соответственно рпс от этого увеличивается в разы ну вот как раз в этом моменте у нас было около миллиона рпс даже миллион двести затем это конечно оптимизировали мы вообще самый большой пользователь я тебе как по объему так и по нагрузке я между яндекс метрику и стерве сборки визитов также для решения этой задачи были заведены какие-то дополнительные таблицы с другими данными например вот про связи пользователей и вот одна из таблиц была сделана не очень удачно сортирование и была выбрана по визит айди это приводило к ситуации что каждый shard обращается в каждую партицию каждую порцию таблицы это много мелких запросов по partition мы всего лишь поменяли ключ сортирование на такой же как в базе вот то есть hash мы поменяли на такой же как используются шортами и пришли к такой же ситуации что каждый шар то используй только диапазон позиция это позволяет более эффективно группировать запросы и снизить физический рпс я тебе меньше накладных расходов меньше электричества жжём также хочу сказать что gdb вышла в open source вы теперь можете попробовать ее своих облаках решать этих клинические долг во время мы честно говоря с этим немного запоздали что пришлось вот такими большими усилиями переезжать на новую масштабируемую систему надеюсь вот мой доклад про такой большой тяжелый переезд поможет вам решить это быстрее на это и это будет чем раньше начнете тем быстрее закончить и и тем дешевле это будет спасибо за внимание саш спасибо тебе большое и пока готовятся разные вопросы можно будет поднимать руки у меня тебе вопрос ты ним не уходи со сцены я тебя попрошу ответить на некоторые вопросы у меня вот например есть такой вопросик ты говорил о системе когда вы перекачивая эти данные а потом делайте проверку и делали это пока не сошлось выписали отдельную систему для того чтобы сверять данные между шар домину которых из которых выселили данной или какими-то отдельными большой разливалась аналитиками потому что мы данные вот напрямую сравнить не можем рассказал куба этого никто книг не получится то есть так отдельной аналитическая работа была до так коллеги можно поднимать руки задавать вопросы и кстати может задавать вопросы в онлайне и мне подскажут что если есть вопросы то из онлайна там и соответственно эти вопросы зададим сюда в студию поэтому если вы слушаете нас смотрите в онлайне задавайте вопросы мы увидим вас на сцену и девушки пожалуйста отсюда вот молодому человеку микрофончик вот этот вот сюда и поднимаете руки вперед чтобы я видел вас и мы заранее поднесли микрофончик пожалуйста . спасибо за доклад у меня на вопрос не совсем по теме точнее даже два первый вопрос вы говорили про забывание данных вы что имели ввиду то есть какая-то агрегация что-то такое это как бы удаление данных по ттн но не просто по тенту life при удалении строятся некоторые агрегации этих данных так спасибо и второй вопрос сколько в итоге период занял по времени ну более года потому там были различные подготовительные работы нужно было код базы старой выдернуть из бизнес-логики они были переплетены затем нужно было все это распараллелить потому что пропускная способность you и т.п. больше чем узости где но общий латинский получается чуть поменьше чем ssd посему я бы я про я понимаю что вот в этот год еще включены доработки про которые ты говорю в конце что вы оптимизировали базу в конце по но для того чтобы уменьшить рпс конечно оптимизация тоже применялись во время этого процесса переезда хорошо спасибо большое так немножко сложно видно но есть еще у нас вопросы в зале вот пожалуйста девушки вот сюда вот микрофончик будьте добры спасибо большое за доклад у меня skip реклам с использовать ли что-то вроде орым а в управлении миграциями еще какими-то обвязками вокруг голой таковой типе которая упрощало бы жизнь разработчику ну вот при разработке таких систем даже не особо существовал в дальнейшем появился очень удобной backup и восстановление из еды где в быть еще одна внутренние системы в индексе google тейлз аналог то есть сейчас можно легко данные взять загрузить словно говоря в мапри deus исмо придется gdb тогда такого не было мне кажется это уже после нашего переезда доработанная функциональность спасибо так и давайте вот здесь вот на первом ряду ищу пожалуйста будьте добры вопросик и потом вот к вам ты поймешь я здесь ты упомянул что я тебе про час я считаю не столько золота но что там если трону поддерживается стратегия а почему не боясь то есть я так и понял что вам главное об теореме то есть вам главное варить любой убейте при этом как бы я это понял что вы остановились на и conti статьи портишь это аванс почему такой выбор был сделан нужно еще раз грабить вопрос задаете вопрос том то есть я теперь я так понял традиционность это все ну то есть это лежит футами тильда можно ослабить узел гибели имеется возможность ослабить гарантии на чтение увеличив adsense зачем нам такой струю вопрос в том что зачем нам такой строю строя уровень изоляции вам главная традиционность или доступность но есть эти транзакции да то есть как бы вот это был важно при выборе vdb или нет если ваш почему потому что иначе в случае каких-то отказов у нас бы не было строгой консистентной генерируемых визитов как я говорил нам важно асинхронная лидер лидер и аппликация нужно что если даже то в dc прилетает метеорит у нас данные были консистентных записаны здесь надо пояснить что есть несколько реплик в разных дата-центрах которые одновременно данные записываются и мы уверены что если они записали 100 не записались везде окей так хорошо я надеюсь что удалось ответить если нет то будут кулуары там можно будет дополнительно спросить давайте вот еще один вопросик вот здесь вот мол очаг встаньте пожалуйста чтобы немножечко видно было так сейчас решим этот вопрос всем привет вопрос такой не вы ничего не сказали правого отложен на реплику если такая возможность виде by еще раз какую липли q отложенная реплика ну то есть реплицировать данные задержкой допустим с основанием на 12 часов прикольно я не знаю про такую функциональность может быть и есть еще на стенд а вы знаете вот сейчас там есть стенд яндекса кто можно подойти и там есть яндекс клауд там будут специалисты по yandex зато bass эксперт в зоне и там можно прям спросить вот про вот эту техническую возможность человек есть в зале но пьет я думаю что мы булар и час переместимся и там можно будет спросить прям по техническим моментам был еще вопрос по накладным расходам на сколько вся эта история прожорлива допустим по сравнению с тем же клика усам или под весом насколько любит память насколько любит диск процессы и так далее по сравнению с остальными системами спасибо ну сколько у самые как бы сложно сравнивать потому что это разного назначения база данных я скажу что вот относительно нашего кастомного решения мы разменялись примерно то нато по железу потому что там была 2 реплики здесь у нас отдельные ресурсы в облаках для расчета то есть у нас не ведется расчет дважды обработка запросов в gdb это несколько сложнее чем просто рандомно и чтение ssd диска и поднять данные которые уже подготовлены в памяти лежат ну я правильно понимаю что до этого вы данные складывали таким образом что они уже были при подготовлены для вычислений и всегда из-за какой-нибудь как бы бинарный про то бог который просто куском в память поднял и у тебя там все структуры уже правильный лежат такой оптимизация было ранее да саш посетите большую за доклад коллеги давайте поблагодарим александра за доклад спасибо большое и"
}