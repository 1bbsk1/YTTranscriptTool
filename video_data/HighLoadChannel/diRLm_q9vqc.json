{
  "video_id": "diRLm_q9vqc",
  "channel": "HighLoadChannel",
  "title": "ETL на Kafka + Confluent, проблемы и их решение с помощью Go / Никита Степанченко, Юра Саргсян",
  "views": 147,
  "duration": 2053,
  "published": "2024-10-29T02:48:12-07:00",
  "text": "мы встречаем Никиту Аплодисменты пожалуйста Добрый день дорогие коллеги сегодня мы вам расскажем не столько глубоко технический доклад сколько историю о том как мы решали достаточно простую проблему при помощи готового решения как нам решение не подошло И как мы двигались с этим дальше здесь мы можем увидеть схему того что нам нужно было сделать У нас есть остатки и цены по товарам которые хранятся в складских системах и есть приложение агрегатор предоставляющее нам обычный синхронный ipi и в теории прямые доступы в свою базу данных также у нас есть Web отвечающий за наш сайт и мобильное приложение задача наша проста как никогда эти ценные остатки нам нужно тем или иным способом получить от приложения агрегатора и положить в наш веб при этом мы имеем прямой доступ к приложению агрегатора а сами склады находятся полностью за зоной нашего влияния начнём описание начнём с описания лиц задействованных в нашем рассказе первое действующее лицо рассказа - это компания Здрав этом платформа ГК Протек одного из крупнейших дистрибьюторов Фарма в Российской Федерации используя мощности Протек и аптечных сетей парв поте возможность удобно через вебсайт или мобильное приложение заказывать продукты для здоровья и красоты в ближайшую аптеку или курьером на дом следующее действующее лицо которых на самом деле так-то много Это команда разработки на момент этой истории Она состоит примерно из пяти де феро и двух тем Лядов которые все работают в одной дружной сер сервисной команде которая занимается переписываем Монолита на PHP на микросервисы Наго также команде помогает несколько специалистов по PHP которые занимаются поддержкой старой системы архитектора у нас в команде нет но на данный момент он в принципе не нужен с этим справляются два тимлида более того компания в рамках развития нашей новой системы даёт нам карб на любые архитектурные решения которые мы можем в рамках нашей команды реализовать так как в этой команде состою И я расскажу немножечко о себе в коммерческой разработке Я около 7 лет в моём опыте много стартапов почти каждый из них со сложными информационными системами в проектировании которых я принимал непосредственное участие как ожидаемо со стартапами многие из этих проектов либо не дожили до продакшена либо вышли на Продакшен не окупились отдельно стоит выделить что существует некая не названная игорная платформа за границей которая до сих пор пользуется моими архитектурными решениями и в принципе даже как будто бы оказалось успешным стартапом соответственно Я являюсь одним из двух Тим лидов Я на момент рассказа принимал Ключевое участие в архитектурных решениях и помогал развивать сервисную команду при этом всегда оставляя оставаясь играющим тренером также отдельно стоит заметить что в свободное от работы время я провожу ролевые игры и пишу свой сеттинг поэтому немножечко может доклад показаться драматичным но мы рассказываем его в формате истории Кстати о нас выступаю Я сегодня не один И в середине рассказа передам слово своему коллеге об этом позже Давайте немного подумаем о том какая же ситуация у нас складывается в теории у нас есть достаточно простая задача команда профессионалов и Карт Бланш на все архитектурные решения которые мы можем реализовать что же тут может пойти не так тут начинается первый акт нашего прекрасного рассказа в нём мы поделимся в том как не кавка единой мы справились с построением своего etl что у нас получилось в результате начать первый акт стоит с обозначения ключевых показателей вообще и предоставить некий контекст к задаче Как можно увидеть на слайде уникальных товаров у нас около 59.000 около 28.000 аптек соответственно туда входят аптеки протека здравсити и аптеки партнёры Эти товары и аптеки в обще общей сумме дают нам примерно 99.000 обновления остатков в секунду также стоит ответить на вопрос о том как вообще реализован этот процесс остатки цены по всем складам собираются из сладкого по в тот агрегатор о котором я говорил на Первом слайде до нас Они доходят в виде ивентов в базе данных счм автом это класически абсолютно Лок при этом цена остаток приходит к нам в одном ивенте в дальнейшем Мы даже Осо разделять их не будем в докладе так как мы не можем абсолютно на это повлиять стоит также подметить что на агрегатор мы можем повлиять очень лимитированной поддержки и имеет скелетную команду На склады мы повлиять абсолютно не можем они за зоной нашего влияния постараемся немного вспомнить как на начало этого рассказа было реализовано был реализован этот процесс до нас работала старая система она занималась синхронизации через полную репликацию Раз в час Она отправлялась в агрегатор и И синхронизировано почему же нам нужно это переработать чем это нам не нравится на самом деле простые две причины есть для этого в связи со стремительным ростом и переходом агрегатора в режим поддержки пиковые нагрузки Раз в час могут этот агрегатор на самом деле и положить так как там поддержка и скелетная команда это может выз оста то Наго ста в не актуальном состоянии что вызовет для конечного пользователя отмену заказа на этапе сборки Итак задачу нам нужно решить задача достаточно распространённая и использует сплош рядом однозначно мы сможем найти Готовое решение команда то у нас всё-таки маленькая собственно Мы изучаем рынок и находим готово решение от ро решение на всем нам известной Касли быть точнее её Connect API при этом маркетологи confl на тот момент обещают нам Готовое решение Production Ready распредели мое и что оно будет работать в формате собери настрой и Запусти с точки зрения использования решение действительно выглядит и работает достаточно просто при этом не требует написания никакого кода ни на одном традиционном языке программирования достаточно написать всего лишь парочку конфигов Кроме того са confl на момент этого рассказа могли бы нам продать и поддержку для этой системы а каку можно использовать как меж решени например в том же Яндексе если разбирать пошагово Как работает там всё тоже достаточно просто Шарак выполняет sce конектор это некий процесс запущенный на кавка Connect который подтягивает данные из нашей сорс базы кладёт их в кафку после чего запускается который можем реть примо kq ответственно язык который позволяет нам легко описывать преобразование данных и последний шаг Lo выполняется при помощи си коннектора который запишет наши данные в целевое хранилище решение нам понравилось оно выглядит очень простым из коробки мы его разворачиваем настраиваем направляем коннекторы sce конектор мы направляем на базу агрегатора S направляем на нашу базу данных Таким образом мы буквально за месяц если даже не меньше разработки получаем готовый рабочий затрачивая на это минимальный ресурс разработчиков и продолжаем попутно делать задачи по редизайн наш остальных частей нашей системы при этом задача поставленная перед нами решена наши остатки обновляются практически в ритам настолько насколько это возможно тут на графике можно увидеть в принципе как это работает а здесь у нас отображаются все сообщения которые проходят через кавка Connect это сообщения Source коннекторов Син коннекторов поэтому мы увидим здесь на наши 9000 обновлений 20 цифр потому что sce и соответственно работают попутно спойлеры Кроме того решение наше модульное и расширяемой на шаг несколько баз достаточно поднять несколько си коннекторов без каких-либо дополнительных работ нам достаточно написать один конфиг направить его на нужную базу и он будет писать для на это оче актуально прож всё ещё работают два сайта старый и редизайн у каждого своя база таким образом написав один конфиг мы можем ещё и старому сайту помочь с ритам обновлением остатков Так мы собственно поступаем настраиваем ещё на старый сайт смотрим на всё это решение пожимаю друг другу руки думаем о том как мы будем масштабировать эту систему дальше и считаем что всё у нас отлично но Подождите ну так же не бывает в нашей сфере Ну вот вы взяли решение Вы его реализовали и оно просто работает Ну когда мы такое видели вообще и действительно чутьё нас не подводит в один день к нам подходит бизнес и говорит о том что вот на сайте есть пример товара товар обновился 15 минут назад всё ещё считается не в наличии Как же так получилось на этой не очень радужной ноте начинается второй акт нашей истории здесь мы расскажем как мы столкнулись с первыми проблемами это готового решения как мы с с ними расправляю Итак Нам сообщили о том что есть товары которые не в наличии Несмотря на то что их только что Обновили Давайте зайдём на сайт убедимся в этом лично заходим и видим что товара в наличии действительно Нет давайте же вместе ответим на вопрос А где же он у нас затерялся начнём с того что мы локализуется все шаги нашего etl просматриваем результаты первого же шага экстракт и сразу же видим аномалию в топике в которой пишет наш sce конектор появляются пробелы ивента пытаемся оценить масштабы проблемы собираем метрики видим что пробелов таких по 100-200 случаев в день каждый случай по 5-10 записей потеряно что для нас является достаточно критичными потерями вот здесь можно увидеть конкретно как это выглядит в самой кафке наш сорс коннектор сюда записывает и мы видим что оффсеты у нас последовательно друг за другом че шестьдесят п но при этом колонка которая используется у нас как айдини Она имеет пробел в целых четыре записи эти записи мы безвозвратно потеряли для того чтобы разобраться в данной проблеме нужно подробно знать как работает вообще sce конектор к счастью для нас его механизм работает достаточно прост в зависимости от режима режима собственно два автоинкремент и таймстамп выбирается какое-то число или время задаётся изначально при первом записке это число наш прекрасный конектор в базу раз в какой-то промежуток времени вытягивает н записей обновляет своё число на то что он нашл последнее по дишни в этой базе и повторяет это до бесконечности как же вообще мы можем потерять данные в таком подходе здесь мы видим что в базе в принципе в нашей могут выполняться две транзакции параллельно друг с другом при этом транзакции в самом начале могут захватить адини нашем случае первая транзакция зах шник 42 вторая транзакция захватила дишни 43 при этом транзакция захватившая шник 43 завершается раньше и её айдини появляется в базе и становится видимым намного раньше наш коннектор будучи максимально простой сущностью заходит в базу читает айтишник 43 обновляет свой внутренний счётчик и ищет дальше Э При следующем заходе всё что больше 43 таким образом сорок второе наше обновление Мы полностью потеряли навсегда нам нужно какое-то временное решение так как проблема критичная мы немножечко собираемся соответственно с разработчиками и решаем Ну раз эти транзакции параллельно друг с другом выполняются мы можем подождать пока все параллельные транзакции закончатся и читать в прошлом на 15 минут добавляя искусственную задержку и таким образом исторические данные за 15 минут раньше они уже будут все в нужном порядке В принципе мы так и можем сделать мы так делаем и начинаем разбираться в проблеме дальше соответственно Ну я говорю вам что решение это временное Почему вы просто так не сделали и навсегда не оставили всё на самом деле очень просто а шанс поймать такой случай не равен нулю у нас нет информации о том сколько самая длинная транзакция в внешней системе агрегатора длится если она будет длиться дольше 15 минут мы такой случай можем поймать всё равно А кроме того у нас вроде как система realtime должна быть мы внесли дополнительную искусственную задержку В 15 минут Нам очень не хочется этого делать на этом моменте мы вспоминаем очень важную информацию о том что с нашим агрегатором можно было на самом деле договориться Несмотря на то что у него была скелетная команда сыграл этот фактор у нас мы договорились с нашим агрегатором с одним разработчиком который там находится ин ложил такое рение давайте это будем ить просто будем писать вам в каку у нас в бизнес логике видно Когда уже все шники в нужном порядке так мы собственно и сделали но мы хотели Готовое решение и мы берём из ко платформы просто выбрасываем один из компонентов заменяем его на самосе небольшой чекап происходит в этот момент смотрим Что у на обще систе ВС снова работает товары на месте пров това в правильных статусах сайты мобильное приложение работают стабильно опять обрадовались опять всё отлично но почему же у меня в докладе тогда ещё два акта и целый спикер ответ на это на этот вопрос достаточно прост через короткое время после того как всё это заработало нам приходит алёрт на то что нагрузка на базу выросла в четыре раза буквально за полчаса к чему это привело И как мы с этим справились расскажет Мой коллега Юрий нашкан разработчик Юра Выйди пожалуйста на сцену Всем привет Да ну что ж не опять основа начинаем с того кто я Меня зовут Юра последние 3 года Я занимаюсь коммерческой разработкой на языке го работаю в компании зра City также я автор и преподаватель курса по конкурентному программированию в Яндекс лицее и думаю по мне видно что я шашлычных дел мастер вот а продолжим столкнулись с тем что база начала в какой-то момент просто деградировать А на сайте посыпались пятисот надо что-то делать лезем в сло что мы видим а какой-то пользователь кавка пишет много данных а вспоминаем что под пользователем кавка у нас пишет только SY connector что-то пошло не так лак вырос всё плохо Син коннекторы не работают идм дальше что мы видим каждые полчаса происходит какой-то скачок нагрузки на базу с текущими ресурсами база это не выдерживает что нам столько пишут на оди SK приходит по 40-50 обновлений цены остатков нужно каким-то образом там убирать лишнее обновление Давайте искать решение к сожалению текущие средства ви позво этого сде кото существует у коннекторов который мы нашли мы не можем никак ограничить количество запросов в секунду конектор пишет очень быстро мы не можем никак размазать эти скачки нагрузки по времени чтобы как-то разгружать базу хочется посмотреть А что вообще пишет конектор как там работает бачин и так далее Давайте поднимем у себя небольшой контур и настроим там собственно указываем пароль им 100 штук Заходим в логи и смотрим Что как это работает у нас запускается транзакция вставляется куча куча куча мелких итов И вот так вот работает батчинг очень странно такой вариант с учётом специфики наших данных очень плохо работает обновлять одни и те же данные в куче мелких запросов транзакции крайне сложная задача для базы дарим Ну может там есть что-то по этому поводу и как-то это регулируется вот собственно весь список Он умел на одном слайде Нет мы здесь не находим ничего что нас могло бы поинтересоваться то есть здесь нет ни выбора режима банга не количество ограничение количества запросов но мы вставили пасхалки кто очень внимательно наш внизу слайда мы не нашли интересующего нас функционала среди других решений Какие ещё могут быть варианты Ну давайте подстраиваться под ситуацию хороший альтернатив выглядит возможность написать свои коню Из плюсов не нужны дополнительно компетенции у нас хорошая команда гошко мы умеем работать с какой и можем написать свои коню у нас будет полный доступ и полный контроль над всем что вообще происходит в системе мы там можем настроить спокойно мониторинги логирование самое главное у нас появится возможность размазывать нагрузку с приходящих сообщений ограничив количество запросов и даже сможем решить проблему с дублями данных Итак собираемся командой начинаем обдумывать как мы будем это делать остановились на библиотеке сама от IBM так Как коллеги уже использовали её есть некая экспертиза поговорили про возможные проблемы и всё готовы начинать чуть подробнее про проблемы что вообще происходит когда Новый коню присоединяется к группе что происходит когда существующий коню покидает группу и там изменяется количество партиции в топике собственно происходит ребалансировка нака на такую ситуацию и нужно не забывать что вот у Сара есть такая проблема И когда происходит ребалансировка нам нужно получать каждый раз новые данные о партиях Давайте напишем свою обр что мы хотим видеть удобный менеджер продюсеров удобную работу с обработками и хотим собственно решить Вот эту вот проблему с парми и ре балансировкой для удовлетворения наших потребностей Начинаем писать свою обёртку как и любой хорошей разработки ей нужно название подошли к этому немного интересно Сара - это индуистской божество вспомним про индуистского Бога трансформации Преображения разрушени зву ру так и называем нашу библиотечку А собственно Так выглядит структура коню группы У нас есть параметр enabled который с помощью которого мы можем включать или выключать consumer группу А есть параметры inal offset oldest собственно значение True говорит о том что используется offset oldest и мы читаем сначала топика соответственно при fse это значение становится равным offset newest и чтение начинается с конца а также существует тип process Fun он описывает формат функции обработчика сообщений А чтобы стартовать нашего коню мы запускаем бесконечный цикл в нём мы делаем сек и вычитывает свои ошибки и мы можем их отловить и залоги в дефолтной ситуации же мы запускаем блокирующий метод cons и что происходит Дальше коню присоединяются к группе Они получают свои какие-то доли партиции которые называются clim и для каждой части партиции вызывается метод cons Давайте посмотрим на него собственно Здесь также вызывается бесконечный цикл с селекто только сейчас мы ожидаем сообщение если мы получили это сообщение мы начинаем его обрабатывать Когда происходит какая-то ошибка мы её отдаём наверх И вот таким вот образом е логи и э итерацию цикла и начинается ВС заново что-то произошло Ну давайте обновим кою вот вернёмся обратно в метод и прочитаем небольшой комментарий если коротко говорить то когда в сессии что-то происходит Мы отдаём в канал контекст Да и возвращаемся происходит вообще замечаем что он был открыт в 2018 году собственно у человека была какая-то проблема с коню группами он не мог с ними нормально работать у него Возникала какой-то какая-то ошибка таймаута при использовании Давайте посмотрим что мы его ответили в комментариях находится человек у которого использование одного кон сюра Ну вроде всё окей ко при второто при понимает Зато комментатор выдал вполне рабочее решение которое помогает с этой проблемой оказывается в контекст прокиды Дан Ну вот просто если что-то происходит в сессии туда прокиды Дан вот проблему не нашли источник проблемы не нашли Костыль решение есть ию закрыть в 2012 году Казалось бы но в году 10 августа открывается е одно ссылкой на старое и собственно здесь человеку отвечает то же самое Запускай for с селекто и всё иди пиши свой код Ну мы люди простые видим решение проблемы мы её просто копируем а отсюда вот у нас в коде появился вот такой замечательный кусок который позволяет нашим консьюмер работать стабильно вот консьюмер написаны всё шикарно но мы всё ещё читаем и обрабатываем сообщения по одной штуке нужен какой-то батчер чтобы удалять дубли мы будем хранить все значения в баче в виде мапы Ну и нужно подумать В какой момент это всё будет обрабатываться Поэтому возникает Вот такая вот genic структура у неё есть vales собственно Это для хранения данных два канала канал на вход и на выход и S ttl ну и соответственно к с помощью T мы можем обозначить время сборки бача по которо мы принудительно просто отправим его в канал вот таким образом выглядит метод с помощью которого мы запускаем наш батчер и собственно он максимально прост У нас есть две рутины первая рутина она забирает все данные которые к нам приходят в канал in и добавляет в наши val вторая рути собственно все эти данные которые собрали либо По истечению времени заполнению нашего Бача запихивает в канал Супер ВС У нас есть возможность добавить нормальные Бачи работаем дальше как итог всех переработок и наших усилий нагрузка в пиках уменьшилась Примерно в четыре раза К сожалению хорошего доказательства этого мы не можем предоставить так как графики с того времени были исторически утеряны Итого имеем пики теперь не такие большие долгое время наблюдаем стабильную работу системы спокойно переживаем даже какие-то нештатные ситуации м всё хорошо Ну можно наверное ничего не делать дальше Да да всё хорошо но это не значит что можно расслабиться здравсити растёт очень Уверенно и быстро Поэтому нужно быть готовыми к любому ходу событий поскольку мы не хотим упасть в неудобный момент и мы усвоили уроки из нашего предыдущего опыта нужно подготовить систему к дальнейшему росту вспоминаем про Слабое звено в этой системе это то где мы храним данные вот а что там с базой нагрузка на базу ВС ещё большая и акцентировано на ставках изза специфики данных примерно треть приходящих сообщений всё ещё приходится на одни и те же SK почему всё ещё Мы же вроде там в Ба ну дублю убрали как бы да Но с другой стороны нет потому что размер Бача он Мирова не все сообщения подат в это у нас всё ещё остаются дубли вот большие Асер очень сильно грузят базу Ну в связи со спецификой наших данных в целом когда приходит много обновлений одних и тех же данных э внутри транзакции мы сильно начинаем её грузить и мы не можем себе позволить с нашими нагрузками долго жить в таком режиме нужно найти пути дальнейшего развития чтобы в будущем спокойно масштабироваться идём В Рес систему из возможных вариантов становится кликхаус в данной ситуации нас интересует движок Mer 3 это движок который умеет обрабатывать огромное количество данных он быстро записывает там приходящие данные по частям и в фоновом режиме их все объединяет именно нас интересует реализация replacing Mer 3 он наследуется напрямую и в отличие от просто merge 3 он удаляет данные и делает это в момент там неизвестный это выглядит как хороший вариант для дальнейшего роста нашей системы но не единственный мы можем пойти по пути наших коллег из магнита и затюнить наш постгрес чтобы он обрабатывал там до 150.000 rps на вставка Да и в целом очень много дальнейших путей развития мы активно продолжаем resch в этой области Вот и собственно к чему Мы пришли За всю нашу историю Мы пришли к тому что платформа имеет некие ограничения sce они работают лоб то есть они требуют чтобы данные приходили в чётком порядке и вот никак иначе Син коннекторы невозможно регулировать Вы можете поменять там какие-то параметры но там допустим скорость записи или там дубликаты вы никак не уберёте срама и с коробки никак не умеет обрабатывать ситуацию с ре балансировкой да А результат нашего рча 3 на данный момент выглядит как хороший вариант Когда надо почить дубли Никита да да А вот как-то так так А у нас сегодня впервые за день на ваши вопросы будет отвечать Аж два докладчика поэтому предлагаю начать так вижу руку сейчас у нас девушки добегу руку потяните пожалуйста ещё тяните тяните руку пока вам не принесли микрофон Спасибо большое за доклад вот я долгое время занимался разработкой и как-то вот Мне удивительно что вы взяли кафку в качестве et средства Там же есть более такие стандартные навороченные грубо говоря там где можно в виде объектов даже схему рисовать с агрегации там информатика например какая-нибудь или а там дата интегратор да мы в этот момент приняли решение использовать именно каку во-первых потому что мы в первую очередь просто наткнулись на ко ПТФ потому что у нас была медж кавка соответственно уже куплена на этот момент ну и соответственно это было для нас самым оптимальным решением в тех условиях которые у нас были Кроме того долгого времени на полноценный resch у нас толком не было да спасибо за доклад Да мне очень интересно было услышать что у вас conf и всё-таки интересно тогда А для чего она у вас используется или всё-таки Ну вы её только для этого пытались затащить А вопрос по существу на самом деле мне показалось вот эта история с кавка коннектом она чучуть сумбурно потому что А ну вас не удовлетворяет си коннектор Почему не написать свой то есть там достаточно большое разнообразие коннекторов которые можно устанавливать они есть также рсе а можно взять готовый можно затюнить свой а для Source коннекторов Ну это de безу cdc точно такие же коннекторы Source коннекторы а которые даже не нужно допили А и Да это проблема то что нужно инкрементальные Поля если база Это позволяет Да А ещё раз напомню что насчёт Source коннектора пойдём по порядку насчёт сорс коннектора проблему мы на стороне базы которая наш агрегатор решить не можем так как там очень лимитированные разработки когда мы обратились соответственно к ним Нам предложили вот писать соответственно через обычный продюсер нам не предложили что они решат проблема авто инкремента у себя или поставить таймстамп или что-то такое нам пришлось соответственно с этим жить насчёт того что нам не подходят Син коннекторы Почему не написать свои а команда разработки 5 10 разработчиков на этот момент занимается полный переписываем системы и экспертизы по Джаве просто Абсолютно нет в команде Ну вот и всё как можно написать свой конектор когда нет экспертизы на это так коллеги Может быть у нас ещё вопросы есть Спасибо за доклад я не очень уверен Это умный вопрос или нет но в ка вроде есть которы сохраняют только последний кей А остальные вроде бы не сохраняют и вот вы рассматривали это или это ну не подходит А мы рассматривали сразу Готовое решение полный etl соответственно как реализовано было а так и сделали ну там соответственно у нас на самом деле компакт используется но Наша задача именно была в том чтобы достать из одного источника положить это трансформировать и отправить другой источник вот мы в принципе закрыли ком платформу и потом сталкивались с такими проблемами так вопрос от наших онлайн слушателей не рассматривали возможность использовать вместо лиха он может быть Шом на чтении из него можно сикать в базу фоне Нет это очень хорошее предложение такой вариант мы не рассматривали возможно можно будет в будущем рассмотреть здравствуйте Спасибо огромное за доклад Меня зовут пожалуйста как вы боретесь вс-таки с дупликации от повторов тогда вам нужно какой-то State сервис который хранит весь проходящий трафик и в случае этого падения сервиса у вас собственно теряются информация о дубля Как вы решаете это вопро что с такой проблемой пока что не сталкивались возможно недостаточная нагрузка недостаточно часто падать сервисы может А спасибо за доклад Вопрос такой вот на этапе выбора confluent платформ не сталкивались или не смотрели в сторону а seel а ещё раз apch seel Нет не рассматривали Спасибо так коллеги ещё вопросы Ну что я тогда предлагаю спикера впервые за этот день опять же выбрать лучший вопрос так А вам придётся как-то к консенсусу прийти Хотя вас двое Это довольно сложно что ты предлагаешь мне это сделать Мне очень понравился вопрос про компакт один вопрос нужно выбрать да Да Вопрос по компакт понравился очень да так задавал Выходи к нам пожалуйста мы вручим тебе подарок"
}