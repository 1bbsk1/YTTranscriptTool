{
  "video_id": "ZvLw9PU--_w",
  "channel": "HighLoadChannel",
  "title": "Отказоустойчивый кластер PostgreSQL + Patroni. Реальный опыт внедрения / Виктор Еремченко (Miro)",
  "views": 17016,
  "duration": 2909,
  "published": "2019-12-05T08:48:46-08:00",
  "text": "ну давайте начнем меня зовут виктор и рябченко я lady waks инженеров компании мира нашей компании отвечаю за доступность нашего сервиса а также пишу различные микро сервисы для улучшения жизни команды и ускорения доставки вещей на пруд и сегодня я хочу рассказать как мы подошли к вопросу отказоустойчивости и что в итоге у нас получилось давайте начнем но немного пару слов о том что такое мира с точки зрения идея эта платформа это высокое нагруженный сервис у нас более двух с половиной миллионов пользователей по всему миру это большая онлайн доска то есть я покажу вам сейчас как выглядит доска потому что дальше в презентацию меня будет примеры как мы тестировали шейн как устойчивость как раз например доски пользователи работают режиме реального времени они видят все изменения и могут планировать идеи делиться результатом и делать кучу всего всего мы полностью находимся в амазоне мы расположены в одном регионе в ирландии и всегда в работе у нас более 100 серверов из них более 40 с базами данных сейчас их уже почти 50 а может даже уже больше 50 и если посмотреть наш бак and the это одно большое монолитное приложение на джаве которая держит постоянное высоких на и соединения с клиентом как раз для обеспечения онлайн коллаборации пользователя на доске и при этом чтобы пользователь в режиме реального времени видели все изменения мы постоянно сохраняем все в базу в качестве баз данных у нас пользуются редис ip-адрес и при этом мы пишем более десяти тысяч запросов в секунду и в пиковую нагрузку у нас редис бывают 80 100 тысяч запросов в секунду или сразу скажу редис используются никак кэш давайте вспомним о том с чего у нас все начиналось и почему вопрос отказоустойчивость стала членом важен раньше качество сна и базы данных у нас будут только редис редис это киева или хранилища которые хранит в памяти все значения и поэтому такие у него есть плюсы во первых это скорость потому что все хранится в памяти соответственно он очень быстро отвечает еще два плюс я хочу отметить это удобный backup & replication мне кажется здесь есть на люди-то скажут что это не очень удобно и там не все так просто но для нас это было удобно и хорошо какие есть минусы так как этакий вылью там нет настоящей транзакции там конечно есть мультик зик так называемый транзакции но они нам не подходят и мы имитировали транзакции на уровне нашего приложения иногда получалось писать очень сложный код который было тяжело поддерживать также так и все хранится в памяти то объем данных ограничены этим количеством памяти мы находимся в амазоне количество данных растет и чтобы переехать нам нужно сменить тип инстанса и чтобы это сделать мы должны остановить наше приложение потому что без downtime а к сожалению мы не могли переключиться между рельсами еще один минус нам необходимо низкого танцем так как мы пишем очень большое количество число запросов то оптимального танцы для нас примерно 17 20 миллисекунд и если она хотя бы в два раза увеличится то мы получим деградацию нашего сервиса такой например случилось сентябре прошлого года внезапно один из инстансов редиса стал отдавать watenshi в районе 30 миллисекунд и мы стали очень долго получать ответы на запросам получили деградацию сервиса и чтобы исправить эту ситуацию нам пришлось посреди рабочего дня остановить весь полностью наши сервисы и заменить этот instance редиса и вы наверное сейчас думаете почему вы пришли травы квад на отказоустойчивость под газ аа слушайте параллель из все просто мы поняли все эти минусы и решили с него переехать и мы переезжаем на пол веса мы уже переезжаем полтора года перенесли пока только небольшую часть нашего наших данных переезд будет длиться я думаю еще года полтора может быть и больше это связано с тем что нам приходится очень сильно переписывать наш код переписывать наше приложение а так как это монолитное средству приложение то это и надо было сделать очень непросто давайте посмотрим архитектуру которая была когда мы начали приезжать на подвес на шестеро приложение напрямую ходили к к мастеру по сброса за которым стоял slave и между ними было синхронная репликация и также они напрямую ходили к мастеру regisseur и у которого тоже был счастлив и это последний слайд вообще буду упоминать редис но здесь стоит отметить что сейчас у нас используется и под газ и редис и ну так для контекста чтобы не забывать об этом но так как во время переезда нам на было не только перенести данные но еще и выдержать нагрузку которая у нас все время увеличивалась у нас увеличилось количество данных увеличивать количество серверов и перед нами стал выбор менеджера соединений то есть connect и в подписи можно увеличить до определенного момента и в определенный момент вы можете получить так то есть на каждый connect возрасте создается отдельный процесс и потребляются дополнительные ресурсы и при большом к числе коннектов ваша база может работать не оптимально соответственно когда у вас очень много сервер входят по сбросу то лучше использовать мы уже соединений и мы выбирали между пиджи палм-бич балансиром и тут мы выбрали пить же bouncer потому что опять же по у не поддерживает радиационный режим работы который необходим нам и как получил как раз схема у нас получилось после этого при этом так как количество данных увеличивалась мы поняли что нам одного возраста недостаточно для хранения данных нам нужна очень высокая скорость работы чтобы пользователь не не получали никакого дискомфорта при работе с доской и мы приняли решение что необходимо сортировать и начали формировать на прикладном уровне то есть на уровне нашего приложения и наше приложение сама знает в каком из шагов под газ и лежат какие данные и тем самым он обращается к необходимому шарда как выглядит схема наши питера приложение обращаются к 5 же балансируем то есть это отдельный инстанции в амазоне на нем он имеет подключение к всем шар дам позже сам сейчас у нас в работе 12 различных шар дав и сюда приложение просто к нему ходит и он перенаправляются запрос на необходимый шарф все просто эта схема очень удобная потому что здесь очень легко добавить новый шарф достаточно развернуть кластер под газ мастер своих со синхронно репликации как у нас здесь и обновить конфликты джеба он сервис сервер приложений ту же смогут ходить в него но эта схема работала относительно небольшое время до определенного момента пока этот единственный узел не умер мы находимся в амазоне и в амазоне как у любого облачного провайдера и свое железо вчера коллеги замазано рассказывал как раз о том что у них используется это железо имеет свойство умирать и когда ваши инстанса живет на железе который убил он просто перегибается новое железо и снова запустится продолжить работать но как раз этот момент когда он будет впереди появятся он будет недоступен и amazon рекомендуют использовать избыточность на стороне костина то есть на нашей стороне чтобы избежать этих ситуаций так случилось и здесь inspire балансиры просто стал недоступен в амазоне и а так как это была единственная точка доступа к нашим все нашим под курсом то пользователи не смогли полностью полноценно пользоваться серверу сервисом нашим но мы используем там редис и полосы и поэтому там часть данных просто которой в возрасте была недоступна а часть данных которые являлись она отдавалась но тем самым мы получили мы считаем это полным downtime и он был в районе 25 минут наша команда там быстро среагировала все поправила и результатом этого инцидента как и каждого инцидента всегда становится ретроспектива который нацелен на то чтобы выработать экшены которые должен помочь не повторить эту ситуацию в будущем и здесь было 2 экшена как раз 1 action сделать отказоустойчивость балансира потому что он не может быть а у нас не должна быть одна точка входа к нашим базам а второй action направлен нацелена на будущее а как нам быть ведь то же самое может повториться с любым другим инстанциям тем же самым в pascal сам а после у нас есть репликация по идее мастер slave есть свои скрипты опекают это ну их надо запускать в ручном режиме и что делать если полет мысли мы же также получим недоступность нашего сервиса нам нужно как-то решить эту проблему проблема с отказоустойчивость приживался мы решили очень просто мы сделали следующую схему то есть мы поставили пиджи балансиры за метр балансировщик амазона и в итоге на шестеро приложения отправляют свои запросы в балансировщик а балансировщик перенаправить их на один из двух пиджи балансиров и за каждым пиджи балансиром стоят одинаково количество шагов возраста то есть это все шаги по сброса и эта схема очень удобная во первых у нас есть отказоустойчивость прижималась что мы можем в любой момент 11 ров убрать мы можем добавить 3 мы можем добавить 4 но здесь не надо переусердствовать потому что здесь надо понимать что вы ограничены коннектом количество коллег тома стороне под брассом и отказоустойчивость балансировщика нам гарантирует amazon чтобы решить вторую проблему с отказоустойчивостью под газ а мы решили рассмотреть какие есть вообще варианты и сначала у нас было 3 варианта для решения этой проблемы то есть это самописный power red менеджер и с rds потому что мы находимся в амазонии давайте рассмотрим их немножко поподробней самописный фолловеры то есть собственные скрипты которые выполняют переключение мастер своих . молотит реплику дома стирка при потере случае падения мастера это очень хороший вариант когда у вас один кластер позже со то есть вы просто то и понимание как это работает вы сами пишете скрипты вы всегда знаете как это сработает это мне надо ради каких-то дополнительных граблей там еще каких-то условий все очень просто но тут есть очень много минусов во-первых у вас обычный кластер состоящий из двух нот и при промо учили когда вы делаете про могут реплики до мастера у вас нет много реплики а если этот новый мастер тут же упадет то вы останетесь совсем без данных и нам будет остановиться коммуне бэкапы и чтобы там сделать схему гораздо сложнее соответственно его боль довольно-таки тяжело поддерживать и скрипту становятся не такими простыми 2 минус то что при падении мастерова может и не упасть возможно произошла сетевая задержка либо еще что то и и скрипты сработали за промоутеры реплику до мастера при этом мастер не упал на нем часть запросов выполнилась а новый запрос и пошли на мастер и вы получили два одинаковых мастера и вы не знаете такой в к мастеру вас последние актуальные данные какие данные верны тем самым получили так называемый сплит brain ну и вам необходим дополнительный мониторинг потому что где гарантия что эти скрипты сработают в нужный момент когда это будет работать когда это необходимо еще раз повторюсь что это отличное решение когда у вас один кластер под газ состоящим из двух нот но когда он так как у нас у нас 12 шагов от курса это решение то есть сложность решение очень сильно увеличивается и поэтому мы не стали на нем останавливаться реп менеджер ари менеджер он полностью управляют под весом и это его единственный плюс при этом он не имеет автоматического файла вера из коробки и чтобы его сделать необходимо также какие-то свои скрипты которые будут это делать за вас поэтому мы даже не стали рассматривать это решение и в с rds мы находимся в амазоне нам переехать в rds очень просто то есть какие есть плюсы rds во первых это автоматическое переключение при падении мастера то есть amazon берет это все на себя когда ваш мастер по датам промолчит реплику до мастера меняет данная запись как раз на и печник реплики и ваше приложение ходит на нового мастера при этом он еще дает of backup и из коробки а также возможность отказоустойчивости в различных зонах доступности какие есть минус и самый главный минус это цена у нас есть уже готовые инстанции c2 и чтобы переехать в amazon на тот же самый тип инстансов необходимо заплатить в один из 7 раза больше и это стало самой на главной причиной почему мы решили то не переезжать возможно мы еще вернемся к этому решению позже но сейчас мы решили на него не переезжать потому что составлен решающим фактором для нас при этом еще и задымился в там нет тонких настроек сервера с полюсом возрастом управляет amazon и у вас нет доступа на сам instance с этим под газом и вы не можете что-то там подтюнить допустим в нашем случае мы устанавливаем ограничение на типе connect и на каждом инстансе спас каса но это связано именно со спецификой на работа нашего приложения поэтому этот вариант нам тоже не подошел и после того как мы рассмотрели все три варианта мы подумали может быть есть что-то еще и действительно оказалась есть 4 вариант это патроне от компании zalando это окон source проект с исходным кодом на гитхабе какие у него есть плюс во первых это очень богатая документация там расписан каждый параметр конфигурации расписано как все это работает как это правильно настроить вообще много много всего и есть в документацию это просто пять с плюсом это лучшее что может быть потом автоматически фолловеры с коробки то есть патроне сам переключает это когда какая-то с его магия которую он сам это делает еще один плюс он полностью написан на питоне а так как мы очень много пишем на питание мы сможем легко наверное разобраться в его коде что-то пойдет не так а также наверное можем что-нибудь и до кантри beauty если нам будет необходимо но и как дополнительная плюшка это он полностью управляет под весом то есть это template для управления под прессом он берет все на себя и сама контролирует работу кластером из минусов здесь стоит отметить что в документации патроне нет ничего про работу с пиджи балансиром то есть мы работаем на 675 же баузером и как патроне должен правильно взаимодействовать с ним здесь нет ничего но это скорее всего не минуса просто то что который не отвечает за под глаз а то что у вас стоит перед возрастом это уже ваша задача и мы сами должны решить как это настроить и очень много примеров внедрения патроне но они все сделаны на чистых базах практически нет ни одного примера где люди раскатали патроне на готовой базе и при этом у них все хорошо получилось сообщение почти примеров на готовых базах но в итоге мы решаем становиться это внушение и попробовать его потому что по параметрам она лучше всего подходит для нас как говорится challenge accepted и чтобы подключить патроне в нашу конфигурацию то есть давайте вспомним нашу архитектуру у нас сиро приложение ходит за амазонский балансировщик на амазонский балансировщик за ним стоят 25 же баузера и каждый из них конектится каждому ко всем шагам позже сам и каждый шаг под газ и имеет конфигурацию masters wave с асинхронной репликации все просто и чтобы начать внедрять патроне сначала необходимо выбрать распределенная хранилище конфигурации и здесь патроне работает с несколькими вариантами то есть этой эти следы пир и консул и здесь получается такой момент когда мы осознаем что у нас оказывается на пороге есть консул он уже есть там где-то года полтора он используется только связке vault svald и больше никак не используется и это наверное будет очень хорошим поводом начать его использовать полноценно и нагрузить его учет просто простаивает и мы решаем что нам необходимо остановиться на конфигурации консул патроне и чтобы подключиться консул достаточно посмотреть а давайте как это работает консул кластер состоит из трех серверов между ними они постоянно обмениваются информацией они хранятся себя одинаково и состояние и кластер патроним состоит из двух нот как минимум при этом мастер это уже теперь лидер и здесь нет своего есть просто репликам тем самым мы переходим на у нас есть лидер есть реплики и каждые но каждый из нас в патроне он постоянно отправляет свое состояние в кластер концу тем самым в контуре всегда хранится последнее состояние кластеров и это очень удобно и чтобы подключиться к консулу достаточно на документацию т.е. документации нам говорит укажите по информатике теперь теперь зависимости от того как вы ходите к и вот коннектор консул защищенный или нет и схему но схема это опциональный параметры по идее можно не указывать ну ладно мы ходим по консул почти без у и мы указываем конфигурацию в таком виде и консул он тут же говорит то что он не хочет принимать connect потому что потро не пытается идти по нему page т.п. это не работает это первый камень с которым из-под и об который мы споткнулись и в попытке решить эту проблему если пойти в google и загуглить ошибку то google никуда подсказывает и возможно google даже прав и здесь стоит задуматься но нам очень сильно помогает исходный код патроним то есть мы полностью который не работает с консулом разобрали это модуль концу и оказалось все просто параметр хост вообще никак не парсится то есть ht ht ps вообще все равно что вы там укажите мы в итоге алану указывается вообще без почти пешки петься просто уроку да и нужно идти а потом протокол эти необходимо всегда указывайте в параметры схемы если вы не укажете вас сюда будет типаж теперь вне зависимости от того что вы указали в параметры хост в итоге вот такая конфигурация она работает следующая проблема который нам надо было решить как мы будем работать с пиджи балансиром и тут мы очень много искали решений в гугле еще где-то там смотрели различным документацию и прочее и одна статья которая нас натолкнуло на мысль там была просто одна одно приложение консул template нам очень помог в связке с пиджи bouncer мы патроне и все и после этого мы пошли без левый как это работает и до этого мы вообще не использовали con функции plate после этого мы используем концу тем будет не только здесь а практически везде где только можно здесь все просто как оказалось то есть на самом деле это не такая сложная схема так как у нас состоянии кластер хранится в консоли то консул template может а состояние квартиры просто мониторить и при каком то изменение он заранее подготовленный template просто куда-то тепло it и что-то еще делает и в этом случае то есть как у нас нас есть template в camp лет мы написали config пиджи баузера и когда какой-то shard пост заменяет лидера кластер а патроне консул тимплей обновляет это конфликтная самом пиджи балансиры и отпра пиджи баузеру команду на релат конфигом тем самым сбалансирует же переключит connect на нового лидера позже сам на нового лидера кластер а патроне это действительно какая-то магия магия консул tiempo это но она работает причем она работает очень стабильно как должна выглядеть наша архитектура теперь с этим решением у нас сервера также будет ходить на наших балансировщик за балансировщик am есть 25 же баузера и на каждом пиджи балансиры стоит консул template который постоянно мониторить состояние каждого кластера патроне из консула и направляет к g bouncer на нужного лидера на текущего лидера каждого кластера патроне при этом каждая нота в каждом классе и поток и всегда отправляет в консул свое состояние и чтобы провели то есть перед тем как вы хотите то на пород это необходимо протестировать и мы решаем проверить эту схему на небольшой тестовой среде мы все подняли а так как у нас основной инструмент для пользования то доска то отлично проверить как это будет выглядеть со стороны пользователям доске и самый простой элемент это стикер и мы решаем двигатель стикер во время того когда мы просто убиваем лидера кластер патроне и посмотри куда будет нас писаться данные все что будет происходить мы убиваем лидера двигаем стикер и стикер возвращается назад получается происходит откат транзакции и мы не можем записать новое состояние в базу и это происходит примерно 20 секунд как раз в тот момент на то время когда ее переключение квартира патроне затем мы можем двигать sticker из все сцене снова записывается тем самым мы получаем доску которую можно просматривать на ней можно что-то смотреть там рассказывает по ней еще что то но при этом ее нельзя изменять и это вполне очень хорошее решение потому что мы получаем на 20-30 секунд readonly режим который гораздо лучше чем там несколько минут me down time но теперь когда мы протестировали это у нас все равно остались вопросы мы тестировали на небольшой среде которая содержала там один сервис 1 доской а что будет когда мы выкатим это на противень напротив нас ни один серый ни одна доска у нас их много у нас 1000 и как нам проверить это под нагрузкой а во-вторых второй вопрос как это раскатать не на чистой базе куда мы с вами потом на генерировали данные она текущих данных и при этом эти данные должны сохраниться все должно корректно работать ничего не побиться и это должно еще пройти быстро и с минимальным downtime и тут нам помогает еще одна тестовая среда на которой мы проводим нагрузочные тесты это среда тоже помощью находится в амазонии в отдельном регионе она по конфигурации соответствует продакшен данные там находятся тест его не специально сгенерированы но по объема не соответствуют тоже production ну и на ней мы можем проверить газ работу от его отказоустойчивых кластеров во время теста а также это оказывается отличный способ проверить ваши скрипты скрипту тепло и раскатки этой конфигурации на этой тестовой среде потому что вам их надо будет выполнять на вроде что мы решаем делать этом поможет второй вопрос и теперь эти задачи уже не кажутся не такими сложными они довольно таки простыми и у вас появляется идея ведь у нас пост из 96 а тут 11 2 подъехал уже стабильная версия давайте мы еще обновился на 11 2 заодно сделал мне только отказоустойчивый кластер а еще и проапгрейдился и мы решаем это делать и давайте начнем с последнего вопроса как быстро обновить по и звезд на 11 2 чтобы быстро проводиться необходимо использовать параметры минус келли link по-другому он не будет копировать то есть при обряде подлость не будет копировать ваши данные из одного места на другое вам просто делают hard линки на диске тем самым апгрейт вашей базы будет происходить за несколько секунд у нас на базе допустим 500 гигабайт апгрейдить занял одну секунду что очень хороший результат но здесь стоит отметить то что перед сентябре там выполняйте чек это параметру этой же утилит который покажет вам возможность этого апгрейды можно ли у вас нет ли каких-то ошибок в базе которые потом приведут к поломке вашей базы а также но мы все это сделали с помощью сценария ansi был сам себя также подменял конфиге под газ а потому что одновременно запускать 961 с яком конфигами иногда очень накладную для работы инстанса и весь сценарий на одном полюсе выполнялся примерно 30 секунд это довольно таки очень хороший результат и мы решили что мы так и будем делать дальше чтобы решить вторую проблему достаточно поставить новую конфигурацию патроне это мысли раздел отвечающий за и не тебе он нужен для инициализации чистой базы когда вы запускаете патроне на чистом кластере а так у нас есть данные мы просто это раздел взяли и удалили потому что он полностью не нужен и когда мы начали раскатывать патроне уже на готовых инстансах с готовыми данными у нас было конфигурация мастер своих схроны репликации мы получили следующую проблему что оба эстонцы запускаются как лидер и потому что подруги ничего не знает о том кто у вас был раньше мастером кто у вас был словом он их оба запускает как лидер пиши сцене в консула там одинаковое имя кластера и они начинают конфликтовать между собой и не запускаются и здесь есть решение этой проблемы она есть в одном из ищут на гитхабе все просто удалите директорию с данными только у дарителя обязательно сливе ни в коем случае не выполнять это на мастере и не говорите что я вам это сказал и посоветовал это надо делать очень аккуратно это очень опасная команды и только очень крайних случаях а лучше вообще этого избежать и так вообще не делать еще одна проблема это как раз я уже я сказал когда патроне стартует он пишет имя кластеров в консул и наверное у всех многих и наверное все после работы с дефолтным именем кластер и наверно везде main потому что каждый отдельно работающих мастер не знает ничего о другом ему все равно какое имя потому что оно есть по дефолту мы на что ной будет main но когда вы начинаете писать состоянии кластеров в концу то этими они могут быть одинаковыми соответственно необходимо сменить имя и это все просто просто меня есть в конфиге рила удить конфиг директорию можно даже ним не переименовать потому что и так все работает еще одна проблема бывают ситуации когда патроне не запускается на готовом под гости где есть данные и боках патроне вообще ничего не написано и не сказано что произошло и почему он не запустился просто есть ошибка и все и тут тоже довольно таки все просто ответ тоже есть в одном из и существенно гитхабе патроне не может передать какое-то очень ошибку позже со своей логе соответственно не столько в полисе и авторы патроне рекомендуют запусти остановить патроне запустить по сгрыз посмотрите позже запустился или нет если нет то посмотреть чем проблема и решите и затем восстановить подлость и запустить патроне вот такой небольшой набор действий выглядит как небольшой костыль но это работает и такая ситуация повторяется когда вы перезапускаете ваш instance и хотите снова запустить патрон он тоже не стартует там уже немножко другая проблема в том что patronite для старта необходимо темпы в файл спидом позже сам но он его не может сам создать и как вариант если вы хотите запускать в патроне через систему чтобы он автоматически его запускался сюда перес после перезапуска инстанса то либо запилить и впрям вот такой костыль либо запили там создание того же файла который необходимо у нас сделано итак итак местами ну здесь к сожалению без костылей а вы никуда необходим не обойтись и после того как мы раскатали все это на тесты по шаг или нагрузочного тестирования мы решили снова протестировать наш тест мы нагнали нагрузку примерно там 15000 досок и решили убить лидера так как мы находимся в амазоне убить лидера очень просто достаточно просто посадят команду инстанцию наша down и посмотреть что будет и мы пытаемся двигаться тигр мы выдвигаем также он также перемещается назад и через 20 30 секунд он начинает нормально перемещаться то есть та же самая та же самая задержка на переключение на смену лидеров кластере патроне мы видим по нашим графиком что сериал насыпали немножко ошибками и после этого все продолжила работать дальше мы можем двигать это очень хороший результат который нас очень обрадовало очень вдохновил на дальнейшую работу с патроне и это было критерием принятия решение что это готова до продам но перед тем как вывести это на прот мы составили план то есть нам было сначала необходимо за тепло и консул template на опять же балансиры и запустить его потом нам необходимо обновить а после сна 11 2 сменить имя каждого кластер а у нас в 12 и запустить каждый класс типа троне и здесь эти действия можно делать не одновременно наша схема где у нас опять же балансиры выделены за вынесены в отдельный instance из-за нашего балансировщика me первый пункт можно выполнить на них поочередно и при этом не останавливаясь сервис что мы сделали мы просто сначала на одном потом во втором раскатали консул тимплей запустили его в работу и все заработало пункты 2 3 и 4 мы выполняли с помощью сценария on seba и весь сценарий у нас на тесте занимал примерно полутора двух минут там в зависимости от различных факторов и это принципе нормальное время то есть все зависит от того сколько вы готовы прожить без базы данных две минуты вы можете не остановлю приложение если вам это окей значит вы можете раскатать это но мы готовы откатывает транзакции пользователей 20-30 секунд возможно даже минуту но мы не готовы две минуты как раз на то чтобы наши пользователи не могли работать а пользователь то наша главная ценность и соответственно мы не могли пойти на такой шаг и тут нам помогает наш регламент каждые три месяца у нас есть окошко для планово maintenance а когда мы как раз полностью вставлен сервис делаем апдейты наших баз данных и как раз мы можем сделать это и при этом до этого кошку остается ровно неделя и почему бы не подождать и в это время еще не подстраховаться и мы решаем мы приняли решение так и сделать мы дополнили схему каждого кластера под колеса избыточностью с нашей стороны чтобы дополнительно страховаться мы добавили по одной дополнительной реплики на который всегда лежит будет лежать последнее состояние актуальное состояние данных которые не будут использоваться при этом она просто будет нас план б если мы не сможем запустить мастер патроне или если мы не сможем если мы как-то убьем наши данные и это просто план б она будет мы просто подстраховались так и мы создали еще один instance для каждого кластера он был полностью чистый итак 1 из нас для новой реплики как раз чтобы не выполнять команду удаление данных на основе потому что даже в автоматическом режиме очень легко ошибиться и даже перепутайте и печники когда а когда там 12 кластеров по сброса это вероятность ошибки еще больше и чтобы минимизировать риски мы просто сделали вот такую схему отказывал стоящие избыточности и в назначенные на ночное время мы выполнили наш сценарий запустились и все заработало то есть мы раскатали патроне на прот и тут же все заработало и пользователи снова начали пользоваться досками это было просто супер но мы получили тут же первую проблему о которых раньше даже и не знали а ум на тестовых средах мы и не получили наши конкурсе раз стали очень получать высокую нагрузку посетил причем оно было в разы больше и при этом нагрузки наши сервера с нашим приложением нагрузки не было и тут стал вопрос почему это произошло а здесь тоже все просто из как раз очень хорошо работает это пример очень хорошо иллюстрирует то почему надо следовать принципу не просто сша скотт когда вы следуете этому принципу то вы должны выкатывать свою инфраструктуру начиная с тестовых сред сначала на одной потом на остальных и постепенно доходя до породы где в конце у вас будет ваш продакшен и если бы это было так то эту проблему мы не получили мы пытаемся стремимся так делать но к сожалению мы не перевели еще весь пруд в код и конце у нас появился сначала она проводит и затем он был раскатом на все тестовые среды и на проводе версия была гораздо ниже чем на всех тестовых средах и в одном из релизов консула как раз было пофиг сильно проблема при утечке себе при работе с консул template и тут мы просто решаем обновить наш консул а так как этот коза устойчиво кластер это сделать просто достаточно по очереди каждую ноту делать консул лив обновлять ее снова добавлять и это так и работала на то момент пока мы не дошли до последней ноты и когда мы решили обновить последнем году мы получили проблему номер два все кластер а патроне просто взяли и перезапустили это произошло одновременно в один момент как раз в тот момент когда мы убрали третью ногу из кластер а патроны есть кластер консула когда первые две уже были спокойно обновлены и патроне спокойно переключался между консулами в патроне логе была ошибка в том что он не может получить состоянии кастера и он решает что надо дтп системы сша down но это хорошая подстраховка чтобы не получить какие там сплит brain of и еще чего то достаточно просто перезапустить весь кластер и посмотреть что будет дальше а если кластер будет не особенно наверно будет в циклическом в цикле перезапускать кластер из пока не появится информация от консула они пили запустились и снова заработали и это стало полной неожиданностью для нас то есть мы не подозревали что такое может быть и первым решением этой проблемы было пойти на гитхабе создать ищутся спросить разработчиков а вдруг там что-то сделали не так почему так происходит и нам посоветовали про обратить наш конфиг но как добавить консул sex там пустое значение мы долго думали что нужно там укротит на самом деле пустое значение и увеличить ретро это мало для работы с configuration распыленной выходящим конфигурация данную проблему мы смогли повторить им тестовой среде и протестировать это решение и к сожалению это решение не работают мы также получаем перезагрузку кастеров патроне когда мы удаляем ноду консула последнюю и это проблема она все еще остается у нас это единственная проблема с патроне которая возникла и которые мы еще не решили и какие нас варианты во-первых код патроне написан на питоне и мы нашли по коду где происходит ошибка там передается дефолтом тайм-аута и скорее всего который не перри определяется и возможно причина в нем и есть вариант попробовать потребитель в патроне поправить код и второй вариант использовать консул агенты на каждом каждой ноги с патроне тем самым патроне будет ходить только на консул агента консул агент возможно и не будет зависать во время как раз выхода последней моде из кластер и консула как раз в этот момент происходит небольшое зависание этого кластера из-за чего и происходит ошибка и мы планируем использовать как раз и попробовать оба варианта решения и попробовать их параллельно независима друг от друга чтобы наконец-то все-таки решить эту проблему сейчас мы просто пока не обновляем концу но после того как мы раскатали эту схему на пород мы решили немножко дополнить у нас было сначала по в каждом классе по две ноты то есть один лидер одна реплика и в случае падения лидера реплика вся становилась лидером что не совсем хорошо потому что необходим какой нибудь кворум для выбора лидера и здесь отличным вариантом стало добавление еще одной реплики они все работают в асинхронном режиме репликации и в итоге теперь при падении лидера а реплика реплики просто выберут нового лидера и эта схема ужас работала она нас уже выручила как минимум один раз мы помогло не опять получили проблемы с тем что один из лидеров кластер патроне просто умер в этот момент кластер который не выбрал между себя собой нового лидера отправил эту информацию в консул консул template на фиджи bouncer ах обновил конфиг и перенаправил и толкнул его и connect и пошли на нового лидера по нашим графиком то есть также в течение 30 секунд мы получали ошибки от серверов то что они могут подключиться к базе а затем все нормализовалось и стало нормально работать и это просто самый отличный результат что может быть когда решение отказоустойчивости которые вы выкладываете и она работает давайте ка от к еще я расскажу какие еще есть впечатление после работы с консулом сейчас у нас уже больше трех месяцев во первых это удобство обновления конфигурации позже сам патрон не берет это все на себя достаточно обновить конфигурацию одной ноги патроне ионное и за тепло этот автоматом на весь кластер при этом если вам необходимо перезагрузить принято пельмени конфигурации необходимо перезагрузить после стопа троне вам это подскажет и как раз для перезагрузки подвеса патроне тоже умеет перезагружать кластер с помощью одной команды но здесь нужно быть очень аккуратными если у вас большая база то перед тем как выполнить команду restart сделать и что нет чтобы перезагрузка прошла гораздо быстрее чем а то это может затянуться там на минуту или больше второй большой плюс то что файлами работает у нас он спас и это отличный результат и теперь мы можем обновлять под газ без downtime у нашего приложения что мы уже делаем мы сначала обновляемой реплики новую версию потом их обратно добавляем работу поочередно затем когда доходит очередь до мастером и просто с помощью патроне выполняем команду свечой и каналы переключаются на нового лидера и старый лидером и спокойно обновляем а потом добавляем снова в кластер и дальше переключаться обратно или нет это уже как бы дело каждого и при этом когда вы это делаете вы еще и проверяйте как работает ваш файл over как он правильно убирает нового лидера и как ваше приложение на это реагирует в общем так одни большие плюсы от всего если у вас остались вопросы или хотите как-то пообщаться пишите мне на фейсбуке статья поэтому докладывала сегодня в течение дня появится в нашем блоге на хабре там будет немножко больше информации если вам интересно читайте комментируйте задавайте вопросы спасибо у меня все спасибо большой виктор а я правильно понял что и последний про за что сейчас ты не хочешь отвечать на вопросы почему я отлично отвечу с удовольствием искал пишите мне но может просто кто-то стесняется задавались сначала пошли прочли статью да а потом задать если к вам бегут человек желтом поехали привет меня зовут максим спасибо за доклад и вообще много вопросов но я постараюсь уделить когда тестировали приключение с мастер на слив было было высказано что мы тихонечко стукнули мастер все переключилась а если убить его не нежно прямо как будто керном по ним случилось опробовали много мы так и делали то есть но здесь на стоит оговориться опять мастер slave в патроне нету мастер своих есть лидер есть реплики а то есть лидер мы просто убивали instance лидера то есть мы не ступали сервис мы просто в амазоне управляли команду инстанцию shutdown там или что-нибудь еще сигнал будет вот но в конце я говорю о том что нас это уже спасло то есть инстанс amazon а также умер без всякой причины и приключения также сработало и время было такое же то есть это есть финальная проверка и красно вроде как работает ваша половина прадед если выкатывать фолловер чего-то на пруд и не проверять это та не вопрос не в том что не проверять а в том что если например взять и просто запретить весь трафик с лидера как будто из нас просто пропал то ситуация немножко по-другому можете но нет там может я за я поняла ситуация в том что connect и могут зависнуть не получить обратно ответ они постараются висячим режиме вот и здесь я как раз рассказал о том что мы используем тонкую настройку как раз по тисе пи коннектом на каждых инстансах у нас и деканате всегда ограничено небольшим интервалом и поэтому они там ческого то проблем не просто закроются все равно то есть мужик мы получали такую ситуацию до мы уже подстраховались этого но остальные вопросы наверное коллегам здравствуйте меня зовут сергей спасибо за доклад я хотел спросить два вопроса первое вы говорили что вас раисе нагрузка порядка 90 тысяч рпс какую нагрузку выдерживает текучести у нас образом и второе это что если мастер под газ начинает тупить про запас и пожирает духе спасибо за вопросы по нагрузка это очень хорошо образца но папа сгасу мы не используем традиционный режим то есть у нас есть статистика по транзакциям и сейчас в пиковые нагрузки на каждый шар где-то примерно 500 600 транзакций в секунду то есть это очень хороший результат и на матах этого хорошо попова то что под газ может начать тупить мы его постоянно тю ним постоянно мониторим мы примерно знаем наши пределы потому что мы делаем для этого нагрузочный тест чтобы узнать наш лимит когда нам мы загнемся чтобы сделать так чтобы не загнуться дальше и мы ещё ни разу не достигали того чтобы там нагрузка на полюсах вырастала больше 20 процентов здравствуйте спасибо за ваш доклад очень интересно было почитать по обеспечение надежности по разогреву мне такой вопрос по сути дела вот патроне это релизов реализация которая перекладывает ответственность надежности на консул и вот я честно говоря с консулом просто не работал и ну я работала сеток от этом например столкнулся с такой проблемой что если вдруг реплик становится меньше трех то данные превращается в мусор это было очень неприятно и вот у меня такой вопрос по поводу надежности самого карсава вот вы на продакшене использовали консул как раз таки именно для обеспечения надежности вот можете как-то прокомментировать надежности консула но вот то что у нас время крутится это уже больше двух лет у нас не было ни одного случая когда это консул казался ненадежны то есть у него там если его начинают там много запросов идти у него просто вырастают цепи и тут надо как-то это просто мониторить и следить на это есть главное 100 тупо консулу это смотреть на нагрузку по ним то есть если нагрузка там то есть как бы у вас есть там внутри ноды в кластере если там нагрузка больше 50 процентов на каждую is not the при падении одной ноты у вас нагрузка на оставшиеся 2 соответственно станет больше ста из пресного скорее всего завалите кластер здесь надо краса подходить вопрос отказоустойчивости смотреть что где у вас есть предел по нагрузке и случае чего либо вертикальному что берется либо коли за и либо горизонтально спасибо 1 1 1 3 виктор спасибо за доклад меня зовут антон меня два вопроса один очень короткий да и не до 2 с подвохом 1 я правильно понимаю что этот реплика она асинхронная да да да вот вопрос ну коллеги если допустим соседа слева очень интересное потому что что вы будете делать если мастер умер от асинхронного сливаешь доехал они все ваши все будет не консистентная и развалится это хорошо вопроса новых версиях подвеса есть уже хорошая работа с синхронная репликация когда у вас есть там определенное количество корма когда если вы используете охранную аппликацию чтобы вы там для чтобы запрос не упал нас так долго и для перехода на синхронной приказ то есть как вариант перейти на синхронно репликацию чтобы и переключаться на ту реплику которая всегда синхронно репликации и второй вариант вам не страшно что эти данные потерялись то есть здесь остальные приложения то есть должно понимать что возможно какая то потеря данных и это не страшно то есть здесь надо выбирайте то есть либо переходить на синхронно репликации либо вы выбито есть либо вам не страшно в нашем случае у нас ну то есть это небольшие изменения мы откатываемся пользователи сразу увидят то есть так мы пишем постоянно изменения в базу у нас возможно что какая транзакция не выполнится и президенту и откат и нам это допустимо понятно спасибо второй вопрос а вы точно уверены что ргс дороже во несмотря на то что по прайсу он дороже там в один из селесты сказали но вы собрали столько всяких кораблей потратили столько времени и сейчас вот на поддержку решения абсолютно что вы говорите вы явно вот вопрос синхронную репликацию к этому все и партнеру в явно движетесь сторону rds и быть сразу просто был дешевле использовать 3d стс возможно дать но цена во первых на сначала нас остановила но наверное я немножко соврал сказав о том что это был решающим фактором здесь в одессе нельзя делать очень тонкие настройки которые необходимы нам допустим те же самые ограничения по тисе пи коннектом по времени типе коннектор о которой в одессе ты не просто не сделаешь принуждение доступная tanks на котором крутится базу а так как у нас своеобразная немножко приложения и нам это необходимо нам приходится так готовить самим но возможно в будущем когда-нибудь мы снова рассмотрим это с как пройдет ные варианты и переедем на него спасибо за доклад я тел бы спросить про тонкие настройки сколько у вас пол соединений по размеру там а где уважая такую монолитную вот сколько у приложение в соединении до базы но у нас есть каждый шард на каждый шаг у нас примерно 50 коннектов с одного сервера спасибо добрый день у меня вопрос про консул в чем причина почему он подвисал и я как я понял надо консул под по одной перизат перезагружались почему он впадал в ступор если последняя нота перезагрузилась но это последняя надо is so старая версия и когда-то ее то есть это был последний консул тоже есть там свой какой-то лидер кастера и когда ты хочешь последним надо убрать то какой то происходит зависание внутри консул она есть она незаметно обычным взглядом на патроне этого хватает чтобы упасть это прям особенность консула что он подвисает если последнюю если да я читал несколько как раз и часов на гитхабе это мапо концу и там как раз есть проблема и она пока еще не решена спасибо привет мне вопрос немножко образующие вот вы получили там интерлок в виде там i'll be или вы вы используете как патронник он стал все а не рассматривали это пример какую-нить бон куда когда переходить был редис бизнес транзакции до могли перейти на пример на мунку которая там кого веры все там есть как это или вы рассматривали или просто позарез к религиозным причину да я об этом здесь не рассказываю там у нас есть на хабре нашем блоге окрасы несколько статей потому как мы переезжаем на полюсе почему переезжаю на поезд моих коллег и там как раз есть то как мы выбирали решение и манга было в качестве основного решения помни даже там у моего коллеги на столе было книгам была книга как переехать на манга за 7 дней это просто отличная книга но она потом куда-то исчезла и мы в итоге остановились на полюсе друзья во первых поблагодарим виктора за доклад подарим у памятника язык"
}