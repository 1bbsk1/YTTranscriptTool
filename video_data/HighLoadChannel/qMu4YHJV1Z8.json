{
  "video_id": "qMu4YHJV1Z8",
  "channel": "HighLoadChannel",
  "title": "5 способов деплоя PHP-кода в условиях хайлоада / Юрий Насретдинов (Badoo)",
  "views": 11592,
  "duration": 3058,
  "published": "2017-04-22T14:48:25-07:00",
  "text": "А всем, всем привет. Меня зовут Юрий Насрединов, а и я буду рассказывать о том, как деплоить PHP код в условиях. А рассказывать я буду на примере BDU. А в BДУ, а довольно интересные требования. Вот они вполне попадают под Highot. Это 2.000 серверов с кодом, а, на PHP, которые нужно деплоить. И состоит этот код из 150.000 файлов объёмом 900 Мб. Про Баду, наверное, вы все слышали. Я не буду про него рассказывать больше. А про что я буду рассказывать в своём докладе? Во-первых, э, что такое деплой-коды вообще, в принципе, а про то, как в Баду деплоились до того, как, а, начали, а, рассматривать альтернативы, какие есть системы, которые, а, в основном люди используют и какую систему мы написали свою. Итак, что такое деплой? В английском языке этот термин означает приведение, а, войск в состояние боевой готовности. А иногда вот по-русски говорят залить код в бой. Это вот означает примерно то же самое. То есть вы берёте свой код в виде скомпилированным или же в виде исходных кодов, если это PHP, а загружаете его на сервера, которые обслуживает пользоческий трафик, и после этого а каким-то образом переключаете нагрузку с одного, с одной версии кода на другую. И всё это, э, входит в понятие деплоя кода. А обычно состоит этот процесс из нескольких этапов. Это непосредственно получение а кода из репозитория каким угодно способом. Его сборка в случае PHP фаза сборки может отсутствовать. В нашем случае это, как правило, автогенерация файлов. Это автогенерация файлов переводов, а заливка статических файлов на CD и некоторые другие вещи. И в процессе сборки у нас генерируется порядка 100.000 файлов. А, и после того, как всё, э, собрано, есть, соответственно, фаза непосредственно деплоя, то есть заливки этого на продакшн-сервера. И вот именно о последней фазе я буду рассказывать. А как а в Баду было устроено до этого? Я рассказывал о лупах, а, на конференциях Red и Highot до этого. Вот. Но расскажу ещё раз, если а у вас есть образ файла системы и он находится в файле, а то вопрос, как его смонтировать? Вот в Линуксе ответ, а что нужно создать промежуточное устройство, которое называется п устройство, привязать файл к этому блочному устройству и после этого уже это блочное устройство можно смонтировать. То есть, по сути, луп устройство - это костыль, который нужен в Линуксе для того, чтобы смонтировать образ файла системы. Есть операционная система, в которых эта костыль не требуется. А, но тем не менее, а-а, как происходит процесс деплоя с помощью файлов, которые мы тоже называем лупами для простоты. А у нас есть директория, в которой а находится исходный код и автогенерирован автогенерированное содержимое. А мы берём пустой образ файловой системы. А файлы системы раньше используется Razе FS, а потом с того используется XT2. А по очевидным причинам спи, значит, мы монтируем пустой образ файловой системы в какую-то временную директорию, копируем туда всё содержимое. Если нам не нужно, чтобы на продакшн что-то попадало, мы, соответственно, копируем не всё. А и после этого мы размонтируем этот файл, а, это устройство и получаем образ файла системы, в которой находятся все файлы. После этого мы его зипуем, а, заливаем на все сервера, там раззиповываем и монтируем. А какие есть альтернативы этой системе и почему вообще мы решили от этой системы отказаться? А давайте для начала поблагодарим вот этого товарища. А без него, без его лицензии не существовало бы большинства утилит, которые мы используем. А значит, о каких способах плоя PHP-кода, хотя это относится и в некоторой степени к другим в другим языкам, а, которые из исходных кодов распространяются. Какие есть подходы к деплое? Но я их разделил на условно четыре категории. Это на основе системы контроля версий, на основе утилита Airsy одним файлом, неважно какого типа. И а вот специальный способ, который вот подсказывает тот чувак с аккуратной бородкой в очках. А значит, какие есть, а нет, не какие есть, а, собственно, а способ первый с помощью SVNP. И СВН здесь не случайно, по моим наблюдениям, а так в таком виде оно существует именно в случае SN. СВН достаточно легковесная, позволяет легко сделать процесс деплоя. Вы просто запускаете SVNup и, в общем-то, готово. А, но а у этого способа есть один большой минус. Это то, что если вы э делаете SWNAP и в процессе того, как обновляются исходные коды из репозитория, к вам приходят новые запросы, то они будут видеть какое-то состояние файловой системы, которая не существовала в репозитории. То есть вы часть файлов новая будете иметь, часть старые. То есть это не атомарный способ флоя, он не подходит для а высокой нагрузки. Ну так считается, что не подходит. На самом деле я знаю проекты, которые всё равно так деплоятся и, в общем-то, вроде бы у них всё работает. А теперь давайте рассмотрим а решение на основе рсинка. А ну есть опять же два способа, как это можно сделать. А, например, сделать Sн от всей директории в новую директорию, которая не существует на сервере ещё. А, соответственно, поскольку вы сначала целиком заливаете весь код заново и только потом переключает на него трафик, это способ атомарный, то есть никто не видит промежуточного состояния. А, но очевидно то, что а в нашем случае создать 150.000 файлов и ещё удалить ээ самую старую директорию, в которой тоже 150.000 файлов, создаёт очень большую нагрузку на дисковую подсистему. И у нас используются жёсткие диски весьма активно. И сервер где-то в течение минуты не очень себя хорошо чувствует, когда вы так делаете. А, ну и понятно то, что поскольку на 1.000 серверов нужно залить, то нужно 1.000 раз залить 900 Мб, а вернее на 2.000. А как можно улучшить эту схему? То есть не заливать с одного сервера. можно сначала заливать на, а, какое-то количество промежуточных серверов, например, на 50, а, и, а, потом с этих 50 доливать на остальные. И тогда вы решаете проблему с, а, тем, то, что вас может сильно упираться в сеть эта система. Но проблема с тем, то что вы создаёте и удаляете огромное количество файлов, никуда не девается. Естественно, если вы использовали RSН, то вы знаете, что она умеет не только целиком фалько целиком директорию наливать, но и обновлять существующие. То есть это Air Sing, соответственно, поверх существующую директорию. У него есть огромный плюс, то что он умеет отправлять только изменения. А, но опять же, поскольку мы, а, в ту же самую директорию, которую мы обслуживаем боевой код, льём синком изменения, то там тоже будет существовать какое-то промежуточное состояние. А, и а что интересно, то, что этот способ, если вы когда-нибуд задумывались, как это работает, а, то есть отправка изменений как работает, а она работает следующим образом. Syв отправляющей стороне, то есть на стороне сервера, с которого, а, осуществляется деплой, и на принимающей стороне. И после этого э считает статт от всех файлов, а, и, а, отправляет весь этот список на принимающую сторону. И на сервере, с которого вы деплоите, потом дифы считается разница между этими значениями и, а, определяется, какие файлы нужно послать. И вот в наших условиях это примерно 3 Мб трафика и 1 секунда процессорного времени уходит на этот процесс. Вы, наверное, подумаете, что это немного, но если учесть, что серверов 1.000, в одном дата-центре у нас два, их, соответственно, 2.000. А если серверов 1.000, то это получается не меньше 1но минуты процессорного времени. И, соответственно, это нельзя сказать, что такой уж быстрый способ, но он однозначно намного лучше, чем а отправка целиком через Sing, но вам нужно как-то решить проблему с атомарностью. Ну дальше можно деплои с одним файлом, то есть а я сейчас буду рассказывать, какие есть варианты. В любом случае, какой бы вы один файл не заливали, его очень просто залить с помощью, например, битторента или же в случае, в нашем случае с помощью утилита UFTP. А, ну и понятно, что что может быть проще, чем распаковать один файл. А один файл можно атомарно заменить в Юниксе. Ну и понятно, что а тоже проверить то, что тот файл, который мы сгенерировали на билдсервере и который мы доставили на конечной машины, что он не отличается, можно тоже легко проверить, например, посчитав MD5 или1 сумма от файла. В случае синка вы на самом деле не знаете, что на конечных серверах. А опять же для жёстких дисков это будет большим плюсом, если вы делаете последовательную запись. То есть файл размером 900 Мб можно записать где-то за 10 секунд на незанятый винчестер, но вам всё равно нужно записывать эти самые 900 Мб и передавать их по сети. А небольшое лирическое отступление по поводу UFTP. Это а утилиты, которые тоже доступны в Open Source и изначально создавалось для того, чтобы передавать, а, файлы по сети с большими задержками, например, через сеть на основе спутниковой связи. А, но а эта утилита оказалась весьма хорошо пригодной и для того, чтобы заливать файлы на большое количество машин, потому что она работает по протоколу UDP, а, на основе мультика, а, на основе мультикаста, то есть, а, создаётся, э, один мультикаст-адрес, на который подписываются все машины, которые хотят получить файл, а, и, а, роутерами обеспечивается доставка копий пакетов на каждую машину, которая заинтересована в том, чтобы получить файл, который мы заливаем. И таким образом мы перекладываем нагрузку по тому, чтобы посылать данные на сеть. Если сеть ваша это выдержит, то этот способ, а у нас, по крайней мере, работает намного лучше, чем Bitorn. Ну и вы можете это попробовать у себя в на кластере, если хотите. Это Open Source улита. Она, несмотря на то, что работает по протоколу P, у неё есть механизм. Вот NA, который говорит, который заставляет перепосылать те, э, пакеты, которые были потеряны в процессе доставки. То есть это надёжный способ, а, деплоя. А, итак, какие есть варианты деплой одним файлом? Ну, вот есть ГЗ, но он сочетает в себе недостатки обоих подходов. То есть, а, вы мало того, что должны записать 900 Мб на диск последовательно, вы после этого должны ещё и случайным а чтением записью, а, записать те же 900 Мб и создать 150.000 файлов. То есть это способ ещё хуже, чем а по производительности. А PHP конкретно PHP поддерживает архивы в формате FAR, расшифровывается как PHP archive, а и умеет отдавать содержимое из этих архивов и инклюlлюди эти файлы и так далее. А, но аа не все проекты будут легко переводимы на то, чтобы их засунуть в один фархив. Поэтому я записал в конечно минус, что необходима адаптация кода. То есть код просто так не заработает из этого архива. А и в архиве нельзя поменять один файл, а можно только перезалить целиком архив. А и также несмотря на то, что фары архивы работает с обкод кэшом. Но при деплое его нужно сбрасывать, потому что аа в общем-то непонятно, как ещё. А иначе у вас будет оставаться мусор в код кше от старого фафайла. Если вам повезло или не повезло использовать HVM. Есть такие вообще в зале, кто использует HHVM? А, ну хорошо. А, а это а способ, который использует Facebook. А это что-то вроде фарархива, но аа в котором лежат не исходные коды, а скомпилируемый скомпилированный байт-код виртуальной машины хипхо VM, а, который является интерпретатором PHP от Фейсбука. А, и в этом файле запрещено менять что-либо. А, и за счёт того, что нельзя создавать новые классы и функции, и некоторые другие динамические возможности запрещены, виртуальная машина может использовать дополнительной оптимизации. И Facebook утверждает, что оно может принести до 30% к скорости исполнения этого кода. То есть, наверное, для них это хороший вариант, но а я здесь написал, что запрещено использовать евал и динамические наклюды. А это, наверное, не совсем правда. То есть евал использовать можно, но если он не создаёт э новые классы или функции. И инклюды нельзя делать из директорий, которые находятся вне этого архива. Но опять же, как я сказал, нельзя поменять один файл. Если вы хотите что-нибудь там одну строчку поменять, то вам нужно пере деплоить заново этот файл. А, ну и наш вариант, а, старой лупы, а, у него есть одно большое преимущество, вернее, даже два. А, это то, что он выглядит как обычная директория. То есть вы монтируете луп и в общем-то для кода всё равно он работает с файлами, как на deвеel окружении, так и на продакшн окружении. Илу можно смонтировать в режиме чтения записи и, соответственно, менять один файл, если вам нужно всё-таки что-то поменять срочно на продакшене. А, но у него есть очень большой минус- это то, что он странно работает с докером, то есть на момент по крайней мере доклада если вы создаёте, а, хотя нет, я расскажу это чуть-чуть попозже, он, короче, плохо работает с докером. А, и если вы используете SIMLink на последний в качестве document root, то у вас возник проблемы с обкод кэшом. Он не очень хорошо относится к наличию симлинков в пути и начинает путать, какие версии файлов нужно использовать, и его приходится сбрасывать при деплое. Ну и также это небольшая проблема, но всё равно стоит упомянуть то, что требуется привилегии на суперпользователя для того, чтобы монтировать файлы системы. И нужно не забывать их монтировать при старте и рестарте машины, потому что иначе у вас будет пустая директория вместо кода. Какие проблемы с докером? А-а, на момент, э-э, вот этого доклада у нас была такая проблема, то, что если вы создаёте докер контейнеer и про пробрасываете внутрь докер конконтейнеры папку, в которой смонтированы лупы, ну или другие облочные устройства, м то возникают сразу две проблемы. Первое - это то, что новые точки монтирования внутрь докерконтейнера не попадают. А второе - это то, что те лупы, которые находились на момент создания докерконтейнера, нельзя отмонтировать, потому что они заняты докерконтейнером. Ну, естественно, это вообще несовместимо с деплоем, а потому что количество луп устройств ограничено, и непонятно, как новый код должен в контейнер тогда попадать. А мы пробовали, например, сделать локальный NFS-сервер или же смонтировать директорию PSFS, но по тем или иным причинам у нас оно не заработало хорошо. Мы в результате в Кроне прописали Syн от последнего лупа в настоящую директорию. А и она раз в минуту это делала. Но а в на машинах, где есть докерконтейнеры, нам не нужно часто запускать PHP скрипты, поэтому то, что нетомарный, в нашем случае, а нас устраивало, но всё равно это способ очень плохой. Конечно, хотелось бы сделать какой-нибудь, а система деплоя, которая не имеет такого недостатка. А, ну и я, а, обещал рассказать про четвёртый способ, который предложил вот этот чувак. Вы знаете, кто это? Да, это автор PHP. А, и он это уже знает, наверное, как надо деплоить. А как сделать атомарный деплой? Причём в любом из способов, которые я, о которых я рассказывал. Вы берёте SIML, а, прописываете его в качестве document root и, а, в каждый момент времени симк указывает на одну из двух директорий. Вы делаете Syн в соседнюю директорию, то есть вы всегда делаете син в ту директорию, в которой код не указывает. А, но возникает проблема, то, что PHP код не знает, в какой из директории он был запущен. И вам нужно использовать, например, переменную, которую вы где-нибудь в начале в конфиге будете прописывать, а которая будет фиксировать, из какой же директории был код запущен и из какой нужно инклюдить новые файлы. Вот я е назвал rooter. А, и нужно эту нужно эту константу использовать при обращении ко всем файлам внутри а кода, которые вы используете на продакшене. А, и таким образом можно получить вот свойства атомарности, когда у вас запросы, которые приходят до того, как вы переключили SIMLink, продолжают инклюдить файлы из старой директории, в которой вы не меняли ничего. А новые запросы, которые уже после переключения симлинка, начинают работать из новой директории и обслуживаются новым кодом. Но это нужно прописывать в коде и не все проекты, опять же, к этому готовы. А это здесь я хотел рассказать, что я знаю, как сделать FPM relло руками, но на самом деле вы, наверное, тоже знаете, что нужно делать. А вот, значит, а что предлагает Расмус? Вместо того, чтобы руками модифицировать код, создавать такие константы, а можно немножко модифицировать апача или же использовать enginex. А вы в качестве document root, а указываете этот SIML. Но когда вы прописываете document root в настройках сервера или же в апа, вы вннексе пишете не документ подчёркиваниние root, а real подчёркивание root. И это Engenex поддержит из коробки. И в PHP придёт одна из двух директорий. То есть на момент создания запроса, на момент прихода запроса Engenex resolvт этот путь и document root будет указывать туда, куда нужно всегда. То есть ваш PHP-код вообще не будет задумываться о том, а куда приходят запрос. Это имеет э интересные плюсы. А если а мы делаем именно таким способом, то обкод кшу phpпишному приходит уже настоящие пути. Они не содержат всем линков, то есть даже самый первый файл, на который пришёл запрос, уже будет полноценным. И, соответственно, не будет никаких проблем с обкойке кшом. Мы можем его не сбрасывать при деплое, потому что когда вы сбрасываете upc, а-а, вы таким образом по сути очень сильно нагружаете а сервер по процессору, потому что он должен отпартьвать все файлы заново. И вот на в моём экспериментед к CAS примерно на полминуты а повышал потребление процессора в несколь несколько раз, ну там два-три раза, а и очень хорошо его бы переиспользовать. Вот этот способ позволяет это делать. И не требуется делать никакой FPM relло, чтобы сбросить акc, потому что, соответственно, его сбрасывать не надо. И, а, поскольку используете document root, то это работает с любым PHP проектом. Вам не нужно ничего адаптировать. Ну, единственный минус здесь то, что поскольку вы переиспользуете CASш и у вас две директории, то вам нужно хранить по копии, а файла, по копии файлов памяти, а, под каждую директорию. Ну, то есть в нашем случае две копии. А, и, ну, это странное ограничение, вам может показаться. нельзя плоса чаще, чем maxion time. То есть иначе вы будете иметь ту же самую проблему, то, что аа пока идёт Synн в одной из директорий, ещё могут обрабатываться запросы из неё. Ну и если вы используете апачи по какой-то причине, то нужен сторонний модуль, который тем не менее вот по этой ссылке Расмус написал и можете использовать. Я бы рекомендовал вам эту систему. Э, мне кажется, чтому говорит чётко. Очень хорошая система. А для, наверное, 99% проектов на этом стоит остановиться или даже с этого стоит начинать. Но, естественно, мы не такие. А мы решили написать новую систему. А почему? А, ну, в основном наши требования ничем не отличаются от требований для большинства веб-проектов. Но есть две вещи, которые а нам очень важны. Это возможность применять патчимарна. Патчи. Патчами мы называем изменения в одном или нескольких файлах, которые аа что-то правят на продакшене и хотим это делать быстро. И в принципе с этой задачей, с задачей патчей система, которую Расмас предлагает, справляется. Но а у нас также есть клискрипты, и они могут работать по несколько часов, и они всё равно должны работать с консентной версией кода. И вот в таком случае а эта система, к сожалению, нам либо не подходит, либо мы должны очень много директорий иметь. То есть вот я здесь отметил R син умножить на N, где n - это количество выкладок, которые происходят за несколько часов, а у нас это может быть десятки. А и соответственно это плохой способ, к сожалению. Поэтому мы придумали новую систему, а назвали её МДК, и это не её официальный логотип, это просто какая-то, а, картинка, которую я нашёл в интернете. А расшифровывается, а так, прошу прощения, а расшифровывается это как multiversion deployment kit, многоверсионный инструмент для деплоя. И мы его сделали, исходя из следующих предпосылок. Вот нам же нужно иметь консистентную консистентную версию кода, с которой работает скрипт. А, соответственно, по сути, нам нужны снапшоты. Снапшоты поддерживаютсям, но они реализованы там неэффективно, экспериментальными файловыми системами, вроде бы ТFS, а и GTO, например. Вот мы взяли, а систему мы взяли реализацию сNпшотов из гита. И, а, поскольку все файлы у нас хранятся просто на диске, то мы, а, если мы хотим хранить несколько версий одного и того же файла, мы должны добавить суффикс с версии этого файла. А, ну и поскольку я люблю GO, мы написали эту систему на Go. Ну вот и всё. Вот наша система. А как она работает? А значит, я говорил то, что мы взяли идею снапшотов у гита, и я её немножко упростил. А я буду рассказывать, как она реализована в МДК. В МДК есть два типа файлов. Это карты, которые здесь зелёным отмечены, они соответствуют директориям в репозитории. И непосредственно файлы, а которые, как я говорил, лежат там же, но с суффиксом, с версией. версия файла определяется на основании его содержимого, и карты тоже версионируются на основании их содержимого. То есть это просто MD5. И вот у нас, э, допустим, может быть такая иерархия файлов. И корневая карта ссылается на определённые версии файлов и других карт. И они, в свою очередь, ссылаются на другие файлы карт, а, и фиксируют определённые версии. Вот, допустим, мы хотим поменять какой-то файл. Возможно, вы видели такую картинку когда-нибудь. А до этого мы меняем файл на втором уровне вложенности и в соответствующей карте, то есть под названием MAP со звёздочкой обновляется версия файлов тоже со звёздочкой. И поэтому модифицируется её содержимое и у неё меняется версия. И поэтому в рутовой карте тоже меняется версия и мы получаем как бы новую рутую всегда, если мы что-то меняем, мы получаем новую рутовую карту. Но при этом все файлы, на которые мы не меняли, переиспользуются. То есть я постарался здесь как мог показать, что ссылки остаются на те же файлы, что и были. А, ну это основная идея, а создание по сути снапшотов на любым способом. Это и в ZFS тоже так реализовано. А как это, как это лежит на диске? На диске у нас есть а simлин на самую свежую корневую карту. А, соответственно, код, который будет обслуживаться из веба. А, есть несколько версий корневых карт, лежат файлы, а несколько файлов может присутствовать с разными версиями. И вот в вложенных директориях лежат карты соответствующих для соответствующих директорий. Но вы, наверное, посмотрите на это и всё скажете: \"Юрий, а как вот вот этим вот обрабатывать веб-запросы? Ведь куда будут приходить а на какие файлы будет приходить пользорский код? Ну да, я вас обманул. А на самом деле есть и файлы без версии, потому что если вам приходит запрос на index php и у вас нету index php в репозитории, то, естественно, сайт ваш работать не будет. А и у всех PHP файлов есть вот такие файлы, которые мы называем заглушками. Заглушками мы их называем, потому что по сути они содержат а две строчки. Это require от файла, в котором объявлена функция, которая умеет с этими картами работать. И, собственно, require от нужной версии файла. Сделано это именно таким образом, а не симлинками на последнюю версию. Потому что если вы из файла A PHP заинклюlлюдите BPHP без версии, то там, поскольку require ones написано, то а оно запомнит, с какой корневой карты оно начало, и будет использовать именно её и будет использовать и будет получать согласованную версию файлов для всех, а, для всего, что мы используем. А и ещё для остальных файлов у нас есть симлинки просто на последнюю версию. Действительно, а как с помощью этого протокола deploлоть? Ну, эта модель очень похожа на Gitpush, а, то есть мы посылаем содержимое корневой карты, на принимающей стороне смотрим, каких файлов не хватает. То есть, поскольку версия файла однозначно определяется содержимо, то если у нас есть такой файл, да, то нам его не нужно тоже скачивать, он точно тот, который надо. Запрашиваем недостающие файлы и так по кругу. А пример, вот, допустим, у нас есть файл с именем One на сервере, и мы присылаем к нему корневую карту. И вот в корневой карте, видите, точечками отмечены а ссылки на файлов, которых у нас нет. Мы их запрашиваем, мы знаем их имена, потому что они в карте находятся. И версии они тоже находятся в карте. Мы их запрашиваем у сервера, он нам их присылает. Оказывается, что один из файлов - это тоже карта. Смотрим, у нас вообще ни одного файла нет. Мы запрашиваем опять те файлы, которых не хватает. И вот больше карт не осталось, и процесс деплоя завершён. Можно легко догадаться, что будет, если, э, у нас 150.000 файлов, изменился один. То есть мы в корневой карте видим то, что не хватает буквально одной корневой карты. И вот так до нужного уровня вложенности. И потом сам файл получаем. Это почти, а, почти не отличается по сложно, вычислительной сложности от копирования файла напрямую, но при этом оно сохраняет консистентность и снапшоты кода. Итак, а, как видим, у МДК минусов нет. А он позволяет быстро деплоить а изменения, быстро и атомарно деплоить небольшие изменения. Позволяет работать скриптам сутками, потому что мы, в общем-то, можем оставлять все файлы, которые мы деплоили в течение суток, и оно будет занимать вполне адекватное количество места. Переспользуется CASШ. А ЦПУ почти не ест. Легко мониторить. Ну, тут я, на самом деле, наврал. Мониторить достаточно сложно, но можно, а потому что а все файлы версионируются по содержимому. И, соответственно, вы можете просто написать крон, который будет проходить по всем файлам, и сверять имя и содержимое. И также вы можете проверять, что корневая карта ссылается на все файлы, ну, что нету битых ссылок в корневой карте. То есть это можно проверить. И более того, при деплое проверяется целоосность. И можно легко откатить изменения, потому что у нас все старые карты на месте. Мы можем просто перекинуть карту, и там будет всё, всё, что нужно. А сразу и не нужно больше ничего делать. Ну и плюсом является то, что написано го, значит, она быстро работает. А, ну хорошо, на самом деле там второй слайд есть. А, как вы догадались, требуется существенная модификация кода, чтобы, э-э, проект с таким работал, но она проще, чем может показаться на первый взгляд. Ну и да, а система очень сложная. Я бы не рекомендовал вам, а, её реализовывать, если у вас нету таких требований, как у нас. Ну и понятно, что требуется garbage коллектора, потому что место всё равно кончается рано или поздно. Ну и мы написали специальные утилиты для того, чтобы редактировать файлы настоящие, а не заглушки. Ну вот, например, MDKвим. То есть вы указываете файл, и она находит нужную версию и её редактирует. А какие цифры у нас получились? А я говорил или не говорил, что у нас на стейнге 50 серверов. А, ну вот сейчас сказал 50 серверов. А и на них плой происходит за 3-5 секунд. То есть, а-а, по сравнению с со всем, кроме синка, это очень быстро. На продакш мы деплоимся порядка 2 минут. Небольшие патчилотся за 5-10 секунд. Если всё-таки вам нужно налить сервер, вернее, если вы по какой-то причине потеряли вообще всю папку с кодом на всех серверах, чего никогда не должно было случиться, а то процесс полной заливки занимает порядка 40 минут. Вот у нас случилось один раз, но правда ночью в минимум трафика, поэтому никто особо не пострадал. А второй фейл был на паре серверов. Я даже говорить об этом не буду. А вот эта система не в Open Source, но если вам интересно, то, в общем-то, мы можем её выложить. А если правда интересно, вот что хотел сказать в заключение, но слушайте Расмуса, он говорит вот прям самый лучший способ, на самом деле, у Расмуса, по моему мнению. А наша система тоже с лупами работала неплохо. А, но думайте головой. Используйте именно то, что, то есть, посмотрите, что нужно именно вашему проекту. Не пытайтесь космический корабль там, где он не нужен. А, но если всё-таки нужен и у вас похожие требования с нашими, то вот, пожалуйста, а система, похожая на МДК, будет работать. Мне интересно узнать, как вы деплоитесь. и заходите на наш техблок. У нас там много чего вносорсе, а, но не МДК. Спасибо. Говорил прош. А на Привет. Так, раз. Раз. А ты говорил проплой и говорил про симлинки, прокш и тем не менее на верхнеуровневый это на на дерево на первое на мапу у вас всё равно симлинка, да, но simлин при этом не инклюдится, то есть а инклюlлюдится файл, как вы, ну, не заметили, наверное. Нет, но этот файл INK - это файл. И вот эти все файлы заглушек тоже файлы, если представляет, не симлинки. Поэтому проблем с апкашом на само. А Curent Map - это файл, всё понятно. Окей. А Map нет. А map - это SIML на последний, но в PHP есть функция readlink, которая позволяет узнать, на что он указывает, и прочесть именно а этот файл не как simлин, а именно то есть и indeкс php где-то умеет читать вот этот через redit current map для того, чтобы его не инклюзить. Ну вот тут, собственно, это и происходит, то, что файлы содержат в себе require от mdk ink, в котором есть функция, которая умеет по мапам ходить. Она инклюдит файлы всегда без сим-линков. О'кей, всё, спасибо. Да, конечно. Возьмите микрофон только прямо что-нибудь не слышно. Привет, спасибо большое за доклад. А вопрос такой, э, ну, файлов вот здесь две версии, три версии, да? Ну, допустим, сервер в продакшене отжил полгода, файлов становится очень много. То есть вы написали, наверное, какой-то инструмент, который какой-то делает клинап или что-нибудь, да? И именно этот инструмент у нас по ошибке удалил весь код. А это вот это это вот этот эпиicфilй, который был и про который вы не рассказывали, да? Ну да, garbage коллектор. А ну его нужно, ну оказывается garbage коллектор написать сложно и можно ошибиться. Я понял. Спасибо. Так, ещё вопросы? Да, дайте там микрофончик человек. Почему бы вместо заглушек вот one PHP 2 PHP не использовать просто хардлинки в файловой системе? А потому что там, видите, имя написано ещё. И что? А хардлинки не содержит в себе информации об имени файла, к сожалению. Ну, то есть там можно, наверное, как-нибудь извратиться и узнать, да, на какое имя файл пришло, но именно из PHP. Но мне кажется, намного проще написать это. А для обкша это для работы обкэша, правильно? Я понимаю, не апкэш. Как отнесётся к Харлинкам, я даже не хочу думать. А, ну это просто проще. То есть, ну, я думал о том, чтобы харлинки сделать, но не стал, потому что с ними на самом деле геморрой. А, здравствуйте. Вы сказали, что ваша новая, ну, ваша клёвая система помогает деплоить приложение с минимальным простоем кли приложений, которые работают по несколько часов. Как она вообще помогает? Ну, мы можем их деплоить. Ну, понятно, нормально. Ну, грубо говоря, раньше, если, а, когда мы использовали лупы, если скрипт работает достаточно долго и лупы же меняются с новой выкладкой, новый лупт, а, и может так получиться то, что старого лупа уже не будет, а скрипт всё ещё работает, и он хочет, например, заинклюдить какой-нибудь файл из той директории, которую он запомнил. Его там нет. Его он, если там написано require, то он падает. Если написан клю, то он как бы в цикле ворнгами сыпет. Ну то есть не очень хорошо. Мы починили таким образом аэ скрипты, которые долго работают. И мы можем заодно атомарно деплоить подчи. Раньше мы, чтобы задеплоить подчи, которые состоят из нескольких файлов, мы должны были продумывать, в каком порядке их выкладывать, потому что в каждый момент времени скрипт может запуститься и запомнить вот то состояние, в котором он был. То есть нужно было думать о том, в каком порядке выкладывать патч, чтобы он работал, потому что мы клали его прямо в луп. Если бы мы выкладывали на каждый патч новый луп, то скрипты даже и несколько минут. Ну нет, хорошо, там и час, я думаю, не отработали бы. Угу. То есть не решает проблему, когда надо задеплоить патч именно на клирипt. То есть его всё равно придётся вам останавливать. И ну сам скрипт нужно останавливать, но а сам факт выкладки патча не ломает уже работающие скрипты. Угу, понятно. Спасибо. Да, добрый день. Спасибо за доклад. А я знаю, что у вас используется докер. И интересно, почему вы не деплоите код, допустим, внутри докера? Потому что это было бы альтернативным решением подобной проблемы. Например, то есть у вас, э, весь код упаковывается внутри докера, деплотся на сервер и, допустим, какой-нибудь там джинс просто показывает на новый апстрим там или что-то в этом роде. Ну, то есть почему такую схему не завязать? А, ну у нас докер есть только там, где это реально необходимо, а на PHP хостах в основном докера нет. И непонятно, он вообще достаточно серьёзный оверхед даёт в некоторых местах. Ну, а, например, не знаю, ну, непонятно, зачем его используеть, когда всё работает и до этого. Ну, потому что у вас версионирование будет на уровне контейнеров, и вы можете, э, вполне легко, допустим, тот же Garbage Коллектор вам не удалить, например, весь код. Вы будете этим видеть на уровне, допустим, версии имиджев. И, ну, всё равно нужно там будет сотню имиджей иметь одновременно работающих. Ну, то есть это как, а, сотни прямо, ну, допустим, ну, это вполне реально. Добрый день. Скажите, а какой оверхд имеет вот это решение в относительно вопроса до пйн ph в плане производительности вы имеете в виду? Да. А на самом деле overhead небольшой. А причина для этого очень простая. Если вы инклюдите mapфайл, то, во-первых, он намного меньше, чем PHP файл. Собственно, PHP файл с классом. Там обычно массив из десяти элементов. И более того, Upш в PHP, начиная с 56, умеет массивы складывать прямо в upкэш, то есть и он даже не создаёт новых массивов. А это первое. То есть на самом деле достаточно быстро. А второе - это то, что вы можете закшировать в локальном кше. То есть, например, я акселератор уже никто не использует, но вы поняли идею. А закашировать уже заизовленные пути для конкретной версии корневого мапа. И, соответственно, вот тот небольшой оверхд, который нужно на инклюды мапов, он будет существовать в очень короткое время, пока оно не обновилось в кыше. То есть по факту оно никакого влияния на производительность не оказывает. Добрый день. Спасибо за доклад. А подскажите, насколько сложно разрабатывать проект вот по такой системе? Ну то есть конечный разработчик, у его там в ПХПРМ, ну вся иерархия файлов или он конкретно разрабатывает нужные файлы и уже потом как бы это всё на деплой на сервере так выглядит. А также вопрос, как выглядит на сервере, на в девелоперском окружении с этим ужасом никто не работает. А они пишут файлики, как и раньше, но они должны иметь в виду, что есть некоторое ограничение, что вот оно будет в конечном итоге так выглядеть, но в большинстве случаев, в подавляющем большинстве случаев это не играет никакой роли. А что делать, когда баги сыпятся, баги и искать нужно его по стерейсу? Баги. А, ну там же есть имена файлов, там просто версия ещё дополнитель. Ну то есть это всё видно, да, в логе уже, в скресе, да, конечно. Спасибо. Добрый день. Меня Андрей зовут. А скажите, вы используете компор? Использую. А как с композером это сочетается? То есть вы переписали аutтодер? Ну, на самом деле также все файлы переписываются, включая то, что композером загенерировано. А это происходит в автоматическом режиме. Да, при деплое. Так вот, вот в такое превращается код только при деплое. Угу, всё понятно. Спасибо. Здравствуйте. Спасибо за доклад. И вопрос такой: мы остановились на способе Расмуса. Соответственно, мы не пошли дальше и не написали МДК. Э, у нас всё работает хорошо. У меня только вопрос по поводу Эрсинка. Мы используем пакетный менеджер систем. То есть какие минусы? пакетный менеджер. Ну, Ям. У нас версионирование из коробки, у нас возможность зеркалирования, у нас свой Nexus и так далее. Ну, это значит у вас используется способ деплой одним файлом. Вот. Вот это, ну, ну, со всеми плюсами и минусами. Как бы это зависит от того, как ваш пакетный менеджер, как он реализован. Если он таргз распаковывает, ну, и сочувствую вам. Если а-а умеет лупы, например, создавать, ну, здорово. Ну, то есть, чтобы RН использовать, по сути, вам не нужен пакетный менеджер. Угу. Спасибо. Понял. Здравствуйте. А можете рассказать, как вы обновляете базу данных и как происходит отказ? Это классический вопрос на всех докладах, мне кажется, Баду вообще все за всё время. А обновляют базу данных. Это это Давайте подходите на наш стенд, мы вам расскажем. А, здравствуйте. У меня А подождите, товарищ вот тот вот какой-то хочет ответить. А у нас будет завтра доклад от Николая Королёва. Может быть, он про это расскажет, вернее, он 100% про это расскажет. Не особо. Так, на самом деле я должен всё вопросы должен выдать. Работает. отвечает Михаил Крумаев на этот вопрос. А поводу обновления базы, а, ну, стандартная схема трёхфазная. То есть сначала мы готовим код так, чтобы он работал со старой схемой, с новой схемой. Потом мы выкатываем новый код. Ну, в смысле, этот код, потом обновляется база и потом убирается всё, что работало со старой схемой. Это, конечно, дольше, но зато безопасно. А чтобы Alter Table не блокировал всю таблицу, она разбита на куче мелких. Ну, у меня вопрос по технической реализации. Я вот сижу, думаю, как вы там сделали. Вы сейчас, может быть, подтвердите. Вот там, где инклуды у вас были. То есть у вас на момент А вот здесь, да, когда вы mk in аа requirity, вы получается считываете текущее состояние Carn Map, да, запоминаете его, да, и на основе него уже у вас переписаны все рекры MDK resolve puff должны быть переписа на самом деле не переписывается. То есть это заглушка, которая нужна, если человек забыл просто а использовать автолот, например. Вот. То есть по-хорошему это правка автолода только регули. Так, а как же у вас, если в коде стоит там file one include file one php? Ну, на самом деле, я переписал весь код, э, чтобы он MDK Resolve Path ну всё было объёнуто в MDK Resolve Path, но, э, грубо говоря, если новый код появится, который забудет это сделать, то вот это его спасёт. То есть он он надо сделать MDK resolve puff file one. Ну, сроко говоря, инклюlлюдить файлы, э, это где-то там 2005 год. Вообще вы не должны это делать. Вы должны использовать автолот. Спасибо. И автолот за вас выполнит MDK. Я должен выдать, на самом деле, футболку за лучший ответ. За лучший вопрос, вернее, за лучший ответ тоже могу выдать. А так а а ещё вопросы будут. Ну давайте. Ладно. А вы сказали, что не используете докер. А как вы поддерживаете состояние непосредственно на серверах? там переменное окружение, какие-то артефакты от старых выкладок между там prдакш prodдаction. Ну, строго говоря, артефактов от старых выкладок у нас нет, потому что это просто файлы мы раскладываем. А окружение как поддерживать, но есть вот папет, его админы используют и там всё хорошо. Всё, что я могу сказать. Но я этим не заведую. Я вам не могу рассказать. Опять же, подходите на наш стенд, если хотите об этом поговорить. У меня короткий вопрос. Здравствуйте. А у вас не возникает коллизий из-за короткой хэш-функции? Ну спасибо. Восьми символов хватит всем. Как как вы понимаете, на самом деле, а поскольку это не глобальный хэш, а он относится к файлу, то есть на самом деле каждый файл сначала префикс имеет с именем его оригинальным и плюс хэш, то вероятность коллизии падает драматически. Ну то есть я не видел, но возможно они были. А вообще не должны быть. Можно использовать длиннее, если вы боитесь. Спасибо большое за доклад. Скажите, а клиентские файлы всякие там, то, что идёт на фронтEND, также выкладываете или там меньше? Нет, нет, нет. Клиентские выкладывается отдельно на фазе сборки ещё даже. Вот они тоже версионируются по файлу, но не так. Я об этом пово тоже где-то рассказывал. А на Moskv JS, по-моему. А можете поискать, наверное, найдёте. Мо Moskv JS Юри на средину, скорее всего, немного докладов будет. А что, всё или ещё? А так, поскольку я должен выдать футболку, а кто спрашивал про кширование data current map в requirement de kind? Вроде вы похоже. Какой у вас размер футболки? Дедуш девушка выдаст. А так всё, спасибо, до свидания. Приходите на наш стенд."
}