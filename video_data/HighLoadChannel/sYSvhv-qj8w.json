{
  "video_id": "sYSvhv-qj8w",
  "channel": "HighLoadChannel",
  "title": "Прикладная математика высоких нагрузок / Алексей Рагозин (Дойче Банк)",
  "views": 2318,
  "duration": 2819,
  "published": "2019-01-14T00:11:53-08:00",
  "text": "добрый день коллеги мы здесь сегодня собрались на конференции посвященном интернет-технологиям мы обсуждаем микро сервиса кого удэ процессоры которые содержит для ardo транзисторов вот это новая современная технология однако на самом деле проблема систем массового обслуживания и вообще сложную система не изучаются уже довольно давно и как бы есть связанные с этим научные дисциплины несмотря на то что бы эти модели были придуманы и десятки лет назад тем не менее некоторые полезные выводы из этих моделей можно применять на практике и в современных высоконагруженных системах с которыми мы работаем соответственно вот этому посвящен мой доклад и начну я его с такого риторического вопроса вот у нас есть два примера времени отклика каких то систем вопрос какой из них лучше ответ и разумеется очень простой нам надо сделать какую-то оценку этой случайной выборки после этого мы можем сравнить простой да не простой тема оценок она достаточно часто всплывает на конференциях в этом году про нее уже говорили не раз про неё очень любят говорить люди которые занимаются к плантации мониторингом что важно для с точки зрения этой категории людей важно чтобы по оценке можно было сделать некоторый бинарный вывод работает не работает надо бить тревогу не надо и с их точки зрения это правильный поэтому они выбирают одни типа оценок но есть другая категория людей есть категория людей которые системы притирают которые системы оптимизируют здесь у нас встают немножечко другие задачи нам например нужно исходя из каких-то неполных данных аппроксимировать а как у нас будет себя вести система вдруг услыхали как будет себя вести система если мы вот этот вот компонент добавим или уберем кроме того когда мы занимаемся оптимизацией вот у нас есть какой-то код одна версия другая и не тот кот ни одна версия не другая она еще не достаточно быстро нам все равно надо понять как бы вот мы какие то изменения внесли мы движемся в положительном направлении или нет и соответственно здесь нам уже становится интересно немножко другие оценки с точки зрения оценок есть 2 таких распространенных класса есть средние протестам в простейшем случае это среднеарифметическое на самом деле средних много есть пирсинг или чем хороши пирсинг или 99 посетитель имеет очень четкую интерпретацию значит у нас один процент запросов находит один процент величин находится за пределами 99 процентиля очень здорово если вам нужно принять бинарные условия и вообще он не дает никаких идей что происходит в с теми 99 процентами которые находятся с другой страны это . отсечки далее вот я просто 9 а можно считать 95 можно считать три девятки это место параметр и его надо как-то выбирать выбирает нам с точки зрения мониторинга его выбирать прост у нас как правило есть какие-то осмысленные ограничения вот мы понимаем что если у нас время отклика будет больше пяти секунд у нас там пойдут тайм-аута и так далее поэтому мы выбираем какой то какой то процент ошибок с которым мы готовы жить соответственно выбираем этот центр вот это все эмпирические знания то есть мы уже рассматриваем и конкретную эксплуатацию понимая приблизительно в каких условиях она себя будет вести когда мы анализируем некоторые кубики из которых только потом эта система появится и будет как эксплуатировать даже вот банально выбор как какой persantine нам правильно использовать он уже не однозначен что можно сказать про среднее их много но он самое интересно на самом деле банальная средняя арифметическая которой он же является одним из центральных моментов случайной величины его очень удобно считать но его очень удобно использовать потому что как бы что такое среднее она нам говорит очень мало о случайной величине но нам не говорит ничего о разбросе атома какое максимальное значение она может понимать и так далее но у него есть ряд важных свойств фундаментальных собственно говоря которая благодаря которым дальше вся математика построен вокруг систем массового обслуживания и крутится что нам делать с разбросом ну есть такое roi вокруг сим кто слышал про это правило поднимите руку пожалуйста вот замечательно она нам говорит что если мы прибавим 3 сигма то мы получим там 99 что-то очень какой-то большой пир sentir и так далее можно прибавлять одну сигму 2 она построена из предположения что у нас нормальное распределение если мы говорим про измерение нагрузки ну и как правило про измерение время отклика у вас нормального распределения нет практически никогда в общем случае у вас есть нормальное распределение где-то в серединке может быть там в пределах 1 сигма хвосты у вас точно ненормальный притом глубоко не нормально поэтому это правило не работает тем не менее какое-то распределение у вас есть и в принципе для конкретной ситуации какую-то эмпирическую оценку исходя из среднеквадратичного отклонения или сигма все таки получить можно проблема возникает тогда когда у вас собственно говоря и распределение то меняется потому что очень часто у нас бывает ситуация когда в несколько разных существенно процесса вкладывают влияние в работу системы то есть у нас есть запросы которые попали в кэш которые не попали если это все более-менее если этих факторов много то да по центральные предельные теоремы это все-таки сходится к нормальному распределению но очень часто мы оказываемся в ситуациях когда у нас есть несколько важных факторов которые вот сильно разные есть еще варианты оценить разброс один из них это так называемый контур гармоническое средняя это одно из ряда средних там на равне с ним есть гармоническое додали чем она интересна форма у него достаточно простая это сумма квадратов деленная на сумму случайных величин его можно выразить через дисперсию и матожидания чем она интересна но интересно в ситуациях когда у вас выборка сильно аномальная то есть у вас случайно вели большая часть случайных величин распределена по какому-то разумному закону но есть совершенно аномальные выброса вот допустим вот так вот то есть у вас что-то там происходит в областях сотен миллисекунд и тут бах такие спайки эта картинка из кейса потоковой обработки и вот эти вот спайки они как бы связаны с особенностям архитектуры системы когда факторы не связанные с собственно говоря обработкой данных в блокирует систему подобные ситуации можно например наблюдать когда у вас в даже в системе начинаются какой-то пауза сборки мусора или ещё что-то такое и причем как бы вот видя такую картину можно сказать что все плохо на самом деле не обязательно все плохо у нас может быть дублирующая система то есть в принципе это может быть несмертельная ситуация но нам как то хочется ее оценить и что здесь интересного здесь у нас вот этот вот один несчастный супер аномальный спайк он даже в 99 персональный попал потому что у нас очень много хороших величин и вот одна несчастная такая плохая если мы нарисуем здесь контр гармонической средняя ну вот конечно не показывает нам всю амплитуду этих спайк of но движется вперед если спайку становится больше они по-прежнему за пределами 99 она растет выше соответственно это полезное свойство вот конкретно вот этого среднего и это позволяет его иногда эффективно использовать для вот таких вот величин когда у нас есть очень большие величины есть очень маленький но мы не можем вот так вот просто сказать а вот мы считаем что все что больше секунды это плохо что меньше секунды это хорошо потому что не знаем и наперед где будет проходить этот приход соответственно контр гармоническая средняя позволяет нам немножечко здесь эту проблему решить и получить такой результат хорошо другим другой важный аспект оценок как они взаимодействуют если у нас система состоит из нескольких компонентов вот такой простой пример у нас обработка какого-то запроса состоит из двух фаз а и б в чем мы знаем какие мы уже оценили сколько времени у нас проходит вас сколько времени проходит б вопрос как нам оценить аналитически время суммарная обработки если мы говорим про матожидания то форму очевидно мы просто складываем от ожидания времени о времени б получаем от ожидания сумма очень очевидно но это справедливо только для матожидания или среднего арифметического то есть другие средние величины например при сенти ли вы вот так вот складывать уже не сможете немножко интереснее ситуация состоится дисперсией оказывается дисперсию тоже можно практически также складывать у нас там еще появляется такой коэффициент корреляции такая интересная штука то есть если у нас время выполнения во время выполнения в бы независимые друг от друга случайной величины с точки зрения запроса то это коэффициент должен быть 0 а если зависимо это единичка например если а это у нас генерация какого-нибудь джейсон чека абэ вычисления как игра физического хэша поэтому же джей сонечку то очевидно что появляться будет практически единичка а если например а это времени в ожидании в очереди абэ собственно говоря генерация жетончик то теоретически корреляция должно быть 0 но на самом деле нам эти формулы нужны не настолько не столько для того чтобы именно оценивать сумму сумму мы на самом деле можем померить это провели эти формула нам важны для того чтобы перепроверить тоже что то что мы намерили действительно как бы верно вот мы меряем систему которая состоит из многих компонентов нам важно понимать сколько мы тратим в каждом компоненте и соответственно мы хотим быть уверенны что сумма то у нас ходится что мы действительно мере им правильно а не оказалось так что у нас один эксперимент в одних условиях другой в других вот случай дисперсии мы еще таким косвенным образом можем оценить тренирует ли у нас какие-то величины допустим в случае стоишь очередью мы мелем а когда оказывается что время ожидания в очереди все таки коррелирует удивительно возвращаясь к пирсинг или мы в принципе можем тоже взять как бы на пофиг песен деле попробовать их сложить что получится ну из определения персен деле можно понять что вот если у нас с вероятностью 099 1 величина больше чем а ведь больше чем одно значение другое тоже то-то точна и меньше то если мы перемножим вероятности мы получаем как раз вероятность того что суммарная величина будет меньше чем сумма вот этих вот двух представителей то есть из 9 петель мы получили 98 из медиана вы соответственно получится 25 проц intel который не очень полезен ну то есть такой математика далеко не уедешь поэтому для такой проверки посетили уже не годятся окей мы осознали что матожидание не такой быть не такой бесполезная величина и если уметь его правильно готовить и правильно оценивает разброс то в принципе можно с ним работать дальше какой математический аппарат мы будем использовать дальше сильно зависит от того какая у нас система если мы говорим про высокие нагрузки про интернет-то большинство система это у нас онлайн это обработка запросов которые отличаются тем что у нас независимые друг от друга поток запросов и нас интересует прежде всего время выполнения индивидуального запроса так что то у нас с краном неправильно да вот наравне с этим есть пакетная обработка данных когда нас уже не интересует время обработки отдельного запроса мы их обрабатываем пакетами и здесь у нас будут как бы другие правила есть еще нечто среднее потоковая или микро пакетная обработка которая тоже сейчас в мире финансов достаточно распространена была уже давно сейчас она начинает проникать и в более широкий спектр найти систем микро потоковая обработка она похожа на онлайн обработку но важным отличием является то что у нас поток за вопросов поток заявок на которых нам время обработки важно потому что мы хотим уменьшить задержку такой потоковой обработки он уже не независимы он уже об немножечко по другим законам работает говорим про онлайн запрос онлайн обработку она наиболее интересная и теории систем массового обслуживания дает нам такую простую модель для систем подобного класса эта система обработки случай один как ведет себя система обработки случаю на самом деле можно догадаться практически без какой-либо математики проведем такой упражнение допустим у нас есть какой-то сервис для которого мы хотим понять как он будет вести себя под нагрузкой начинаем с того что мы меряем а сколько этот сервис собственно говоря тратит на один запрос делом и это очень просто берем в цикле подаем на него не непрерывно запроса одним потоком и получаем пропускную способность чистую вот это вот нашего кода который что-то делает допустим она у нас получилось 100 соответственно на графике мы сразу можем отложить две такие условные не это пропускная способность 100 и время обработки одного запроса 10 миллисекунд у нас получилось как у нас будет вести себя кривая ну опять же исходя из общих соображений можно предположить что если у нас бесконечно малая нагрузка то мы получим время отклика те самые 10 миллисекунд а вот если у нас поток входящих запросов превышает пропускную способность системы то мы уйдем в бесконечность у нас получается такие вот две асимптоты можно между ними по строить гиперболу и мы получим закон времени отклика для вот такой вот простейшей системы массового обслуживания которые наталкивает нас на интересные но вода наиболее интересным в том что динамика времени отклика у нас не линейно у нас есть гипербола а это значит что у нас есть какой-то вот перелом до какого-то момента мы можем считать что у нас время растет линейно а потом нас система переходит в режим отказа и вот в такой простейшей модели если мы ее допустим на 80 процентов нагрузим мы уже будем в время ожидания в очереди уже будет приблизительно четыре раза больше чем собственно говоря время обработки запроса ok но это красивая картинка что нам делать в реальности с реальной системы мы в принципе можем построить такую картинку эмпирически и хорошие инженеры про нагрузочное тестирование так и делаем мы берем систему подаем на нее нагрузку подаем нагрузку если которая возрастает линейно по времени и в результате получаем вот такой график у него пасека отложено время но поскольку в этом синтетическом тесте у нас нагрузка пропорционально времени от начала эксперимента то соответственно это можно условно считать нагрузкой и картинка нам действительно подтверждает то что да вот у нас прорисовывается какая то гипербола что нам с этим делать но очень просто мы вот говорим что у нас есть условно линейный участок это хорошо потом у нас идет переломы и плохо отмечаем где у нас происходит этот перелом настраиваем исходя из этого мониторинг если этот перелом находится не там где надо с точки зрения нагрузка системы идем оптимизируем и так далее это хорошо если вы вот такое тестирование можете привести если оно у вас показывает вот такие вот красивые картинки можно получить те же самые картинки немножко другим способом вот это некоторое поведение реальная система в течение дня не он идет какая-то нагрузка на неравномерная у нас есть два пика когда у то надо же начинает вести себя уже не очень красиво что мы можем делать сделать с этими данными которые можно получить например с реальной системы в ходе эксплуатации мы можем разбить это все на какие-то временные интервалы для каждого временного интервала посчитать эмпирическую нагрузку которую был в этот интервал и соответственно вот эти вот все цифры перерисовать отложив эмпирическую нагрузку по оси x и тогда мы получаем вот такую зависимость от кого временем эта система от нагрузки по реальным данным они у нас уже отличаются от того чтобы его в эксперименте ну во первых как бы слава богу что у нас система практически не работает уже в красной зоне то есть у нас график более-менее а лежит в линейной части гипербола ну и немножечко он не такой красивый потому что вот с правой части где у нас высокая нагрузка там у нас просто меньше данных по которым производилась обработка потому что только вот те пиковые участке поэтому график немножко квадрате то за того что данных меньше и ширина уровня агрегация получилось ширин здорово но есть как бы проблема с тем что не всегда у вас получаются такие красивые графики потому что чтобы получить вот этот график я взял ноги системы я отфильтровал их по одному конкретному типу запроса для которого я знал что собственно говоря время выполнения самого запроса она более-менее невелико и не очень зависит от вот запроса то есть на в реальности у нас бы если система делает что-то полезное то как правило это действие оно зависит от того что у нас попросили сделать вдруг говорится мы отдаем файлы то чем больше файл тем больше времени уйдет его передача и так далее то есть чтобы увидеть вот эту вот характеристику именно поведение ожидания нам надо вырезать выборку данных в которой время обработки меньше ну или чем же время ожидания в очереди или более менее не имеет существенных выбросов в принципе этим можно пользоваться если вы понимаете какие запросы вашей системе обладают такими характеристиками то да вы можете смотреть только на них и как бы вы мне представлять что в принципе вот вот это поведение связано именно с тем что идет нагрузка но это не всегда работает так гладко как хотелось бы вернемся к этому графику под кривой у нас время о только системы она состоит из двух частей это собственно говоря время обработки и вот то что у нас надо пунктирной линией желтая зона это время ожидания в очереди в идеальном в мире время ожидания в очереди у нас не зависит от запроса удивительно она зависит от длины очереди и если мы немножечко посмотрим на проблему анализа нашей системы с другой стороны и будем мониторить длин очереди то в принципе мы можем получить более так сказать как качественную информацию о том как ведет себя система то есть даже если у нас время отклика сильно зашумлен а в силу того что как бы система делать что-то полезное и время отклика существенно зависит от запроса то по длине очень последним где не очень мы будем понимать а собственно говоря в какой в каком режиме мы находимся но тут опять же есть подводные камни почему очереди не слишком популярны с точки зрения мониторинга как бы их не не всегда включают в топовые метрики так далее потому что здесь нам нужно опять же эмпирическая оценка какая длина очереди какая средняя длина очереди будет для нашей системы нормально кроме того есть чисто техническая проблема что не всегда у нас вот это вот ли научить есть потому что потому что на самом деле очередей много то есть мы вот в нашей простейшей системе у нас есть какой-то код который отвечает за обработку запроса у нас есть какой-то код который принимает эти запросы извне допустим по сети и собственно говоря вот это вот очередь запросов которую мы приняли еще не обработали если мы начинаем смотреть как это работает на самом деле то оказывается что у нас еще есть очередь и себе запросов в операционной системе у нас есть очередь задач на для центрального процессора если у нас сервер перегружен то нас во время от времени для выполнения запроса будет еще добавляться время того что нам надо дождаться что операционная система планировщика выглядел нам какой-то только так далее все очередей на самом деле много и мониторить их не так просто на практике как вот в такой простейший картинки но тем не менее если вы если у вас есть возможность их мониторит то эта информация крайне полезно если вы делаете очередную систему то подумайте на перёд а может быть как бы вот у вас возникла какая то очередь запросов явно и неявно и добавить метку на эту через запросу причем если допустим я бы вам подложил мерить время выполнения вашего запроса в разных в разных частях вашей системы то это очень сложная задача вот так вот про трассировать запрос по различным компонентам системы это сложно трудоемко нам надо куда-то таймс темпа записывать считать текущую длину очереди очень просто вам нужно всего лишь один счетчик который вы инкрементируем на входе запроса уменьшаете на выходе и все вот у вас получилось текущее количество запросов находящихся в компоненте системы будто очень будто какая-то обработка и соответственно мониторинг вот этой простой величины он может вам дать более качественную информацию о том все ли хорошо в вашей системе где нет подводя итог а поведение очередей что можно сказать о первых поведение очереди нелинейно от нагрузки и например если ваша система загружена на то есть у вас есть какой-то сервис который вот обработал обрабатывает именно запросы в онлайн и вы видите что у него циpкa загружено на 50 процентов не значит что он что вот вы эти 50 процентов можете использовать знать что он уже на самом деле находится на границе зеленой зоной и скорее всего если вы отберете у него циpкa или добавить и какую дополнительную нагрузку или уменьшить количество реплик этого сервера то деградация производительности будет достаточно быстро соответственно система онлайн обработки запросов она никогда не может быть загружена на сто процентов другие системы могут быть если это пакетная обработка запросов то никаких проблем мы можем выжить из нее сто процентов по какому-то ресурсу там циpкa диск это и так далее для онлайн-системы это не работает длина очереди простой параметр который важно мониторить к только тут за которым важно следить причем очень часто он у вас есть просто вы на него не не смотрели потому что непонятно какие если мы смотрим на время понятно время там миллисекунды секунды прошу штукой длина очередь вот в линуксе есть параметр вот и вера и чита длина средняя длина очереди запросов процессор вот волод егорыч 5 это плохо или хорошо не понятно пока вы не изучите поведение своего сервера когда вы изучите вы будете знать вот для вашей конкретной системы а вот веры 5 это нормально или не очень и соответственно хорошо работающая система онлайн обработки эта система в зеленой зоне причем в зеленой зоне не обязательно должна быть вот как какие-то очереди которые вы овна видите не забывайте что помимо тех очередей которые вы видите которыми вы управляете есть еще скрытые то есть если вы написали система в которой нет очереди значит очереди где то есть на входе и на выходе у вас есть боковых сокетов так далее и тому подобное если у вас есть возможность протестировать прогрессивной нагрузкой то это самый простой и достаточно надежный способ понять где у вас находится реальная . осечки то есть вы реально нагружаете все явные и неявные очереди и получаете информацию как ведет ваша система это полезно сравнивать с тем как ваша система реально ведет себя в процессе эксплуатации потому что помимо очереди у нас же есть собственно говоря реальные запроса и при синтетическом тестирование далеко не всегда у вас есть возможность воспроизвести именно похожие на реальное распределение полезного полезной работы системе и соответственно характеристики такого синтетического тестирования реального переде не могут быть немного разные окей вот эта картинка про очередь она показывает стать поведение системы в стационарном режиме то есть в каждой точке этого графика в каждой точке на котором мы рисовали времен книгу нас есть какая-то фиксированная нагрузка но есть и другая сторона вопроса есть динамическое поведение системы и динамическое поведение системы в частности во многом отличая от определяется наличием обратных связей внутри этой системы ну вот начну с такого небольшого примера это опять график построены по реальному поведению системы который показывает нам зависимость времени отклика от нагрузки и тут мы видим очень интересную картину вот среднее время до но действительно соответствует нагрузке но вот сенти ли они внезапно уменьшаются вместо того чтобы расширяться то есть у нас получается парадокс чем больше мы грузим систему тем лучше она работает как так получается что что за магия данные перепроверили данная действительно как бы реальные с реальной системой все правильно в чем от к оказалось причина в том что в этой системе было ограничено и ограниченное количество потоков которые создавали запросы случае ограниченного количества потоков если у вас время отклика большое вы просто не сможете дать нагрузку которую хотите и таким образом в течение дня нагрузка прыгала то есть какие-то в пике действительно время отклика раствора сброс был больше но когда мы про агрегировать у нас получилось что только вот в те участки работы системы когда она вела себя очень хорошо ей удавалось выдавать большую нагрузку которую мы потом эмпирически замерили это эффект обратной связи и в данном случае это отрицательная обратная связь когда чем выше у нас было время отклика системы тем меньше было нагрузка за счет того что наша подсистема которую нагрузка генерировала она соответственно находилось времени ожидания ну как бы в данном случае это курьёзно смотрели посмеялись это может быть не столь курьёзно представьте себе теперь обратную картину мы для тестирования используем три тпу с ограниченным количеством потоков в реальности у нас система будет работать в ситуации когда количество конкурентов запросов ничем не ограничено и мы в результате в тестировании действительно можем получить то что у нас поведение тестируемой системы в каких-то крайних режимах на тестах будет существенно лучше чем она была бы в реальной жизни но отрицательная обратная связь это это не самая страшная самая страшная положительная обратная связь приведу такую историю которая в 2006 в 2012 году случилось с компанией skype при выкладке новой версии своего мессенджера у него прокралась ошибка которая вызывала то что если время отклика сервера была слишком большой ток клиент умирал то есть как бы неправильно обрабатывалась тайма происходило ошибка процесса врубался ну казалось бы ну не приятно вот но особенность skype заключается в том что это пир toupper система то есть клиенты сами являются серверами эта система некоторые и в результате получилась следующая ситуация выкатили новую версию у нас в соответственно просто в силу разброса времени отклика иногда случаются ошибки и соответственно новой версии иногда падают чем больше мы выкатили новых версий чем тем чаще они стали падать чем чаще они стали падать тем больше среди них подавать тех узлов которые также являлись серверами для сети таким образом чем меньше у нас сети узлов которые отвечают за груз на запросы тем выше у нас становится нагрузка на оставшиеся сервера и в результате сказать два дня лежал вот потом они там в это самое взяли выкатили дикие то сервера бы починили носка skype реально два раза два дня лежал я в этот момент находился в отпуске и активно им пользовался для того чтобы звонить а он взял и лег было очень неприятно это положительная обратная связь она обычно приводит к тому что система ложится как она возникает динамика работая системой без обратной связи у нас какая-то нагрузка время отклика нагрузка возросла время только тоже выросла еще возросла мы получили такой спайк время отклика нагрузка ушла вся система вернулась в нормальное рабочее состояние добавляем обратную связь но чтобы но просто обратной связи недостаточно обычно у нас вместе с обратной связью должна работать еще какая-то пороговая функция то что иначе у нас если у нас просто есть обратно и средств систем в принципе не старта ньютону сразу идет в режим пороговый функции очень часто в мире информационных систем является тайм-аут вот у нас появляется некоторые тайм-аут соответственно нагрузка идет доходит до тайм-аута дальше после того как мы преодолели тайм-аут у нас появляется дополнительная нагрузка которую выше пунктирные линии которое как раз вы его вызвано вот это обратной связью допустим переподключение миг системе и у нас время отклика уходит существенно выше чем была до этого и даже когда у нас правильная нагрузка уходит то есть пик нагрузки уходят все равно за счет того что мы накопили вот этот вот запас на который поднялась время отклика система оказывается в таком режиме работы за пределами нормального то есть она уже не может сама восстановиться что нужно чтобы получить вот такую ситуацию нам нужно что в наша система была положительно обратная связь например какие-то переподключения это наиболее частая вещь но помимо этого обратная связь зачастую возникает из-за того что у нас два компонента система использует один и тот же ресурс за счет того что один компонент активно использую этот ресурс другому достается меньше таким образом нагрузка на одном компоненте косвенно влияет на параметры другого компонента по обратная связь у нас есть практически всегда но для того чтобы она стрельна во нам нужно еще одно из двух условиях у нас должна быть либо какая-то пороговая функция то что обычно положительно обратная связь она чем-то компенсируется и чтобы система перешла вот в такой экстремальный режим нам нужно чтобы мы преодолели какой-то порог либо это может быть какое-то внешнее событие ошибка неправильно выложили конфигурацию запустили одновременно перезагрузили одновременно два сервера каша который пошли в базу данных и тут выяснилось что у нас база данных от этого просева на другие сервисы начали переписывать запросы и так далее так далее вот эти два фактора сами по себе безобидных могут при определенном сочетание обстоятельств привести вот какому эффекту положительные обратные связи поэтому каждый раз когда вы в систему явно не я добавляете что-то похожее на пороговую функцию стоит очень хорошо подумать как у какие последствия это пороговая функция там например тайм-аут переподключение может за собой повести еще один пример 10 а некоторые кластер это распределенный кэш у него есть фронт сервера bukkit сервера в нем хранятся данные для обработки финансовых рисков в реальном времени ну и все эти данные попадают в базу данных наблюдается такая картина где-то в середине торгового дня у нас умирает база данных перестает отвечать на запросы как то там все это работает работает а только после того как торговый день заканчивается а все возвращается в нормальное состояние оказалось что здесь проблема была ну помимо того что у нас были тайм ауты помимо там того что у нас 1 слово количество запросов к базе данных соединение сетевые внутри кластера и между квартирами базы данных они использовали один и тот же switch и в результате когда росла активность расчетов внутри кластера это давило пропускную способность в oracle он переставал обрабатывать запросы ну и соответственно дальше все пошло по кругу то есть обратная связь может возникнуть вот вот так вот случайно на ровном месте из за того что вы за тепло или два сервиса в один docker host и запустили два сервиса на одном свече то есть с точки зрения кода вещи могут быть не связаны но у нас еще есть инфраструктуру нас еще есть другие факторы соответственно все эти факторы могут стать источниками обратной связи также источниками обратной связи могут стать механизм отказоустойчивостью я уже упоминал тайм-аута переподключение балансировка нагрузки тоже на самом деле это у нас прямая обратная связь в чистом виде до в нормальной ситуации она отрицательная но как бы обратная связь это уже обратная связь если мы рассмотрим теорию сложных систем то в ней есть такие общие принципы борьбы с обратными связями задержки демпфирования противодействия и дальше если мы посмотрим на те best practice и которые у нас появились сейчас вот после того как в 2010 2012 году было достаточно много out уже в больших компаний связанных именно с тем что они переходили на микро сервисы и так далее то сейчас это все best practices экспонентов быков различные цикл брейкеры бак пришел но все вот эти вот новые механизмы они очень хорошо пересекаются с теми как бы фундаментальными способами борьбы с обратной связи которые придумаю же еще в электротехнике которые изучаются в экономических системах и так далее и несмотря на то что мы работаем с инновационными технологиями с последними достижениями человеческой мысли некоторые простые правила которые придумали десятки лет назад они по-прежнему могут быть полезны в нашей работе и так сказать понимание их делает использование современных лучших практик более осознанном более так сказать эффективным этом все спасибо да вот у нас есть вопрос 1 раз добрый день меня зовут алексей компонентов подскажите пожалуйста вот вы говорили о мониторинге очереди путем того что вы когда инкрементируем счетчик когда вы добавляете туда degree минти руки когда убираете но ведь мы таким образом же создаем ошибку когда у нас происходит какие-нибудь exception-ы там еще какие-то каким-то причинам при вычитывании-перевычитывании ровать счетчик мы опять же тайм-аут и до которые у нас возникают системе они у нас зачастую там не связанные с оборудованием а связаны например с тем что информация после там тайм-аута уже никому не нужна она ну все у нее есть срок жизни если ты не успела ее отдать там грубая сам за 10 секунд дальше оно не интересно если ты не успел отдать за 10 секунд и она никому интересно это уже потоковая обработка данных там немножко то на другие правила там у нас уже не совсем систему очереди у нас как бы другой класс система немножко другой подход хотя он близок с точки зрения инкремента инкремента ну как бы у нас всегда есть возможность обработать ошибки всегда есть возможность делать хорошо но как бы можно сделать из вопрос в том насколько ну то есть это уже технический вопрос важно то что если это сделать правильно то это дешево и полезно если этого не делать то это бесполезно если мы сделали это с ошибками это быстро обнаружим потому что у нас очень вот этот вот счетчик будет расти в бесконечность и до ошибки штука такая особенно в нагрузочном тестирование особенно в вот каких-то вещах когда мы тестируем оптимизируем производительность там очень много мест где можно давить или 200 допустить ошибки при измерении при расчетах и так далее это все надо к этому подходить серьезно и вдумчиво так нас время закончилось если у кого-то еще есть вопросы то я буду рад ответить в корах спасибо за внимание"
}