{
  "video_id": "GIslwdE2DWY",
  "channel": "HighLoadChannel",
  "title": "Микросервисная Архитектура: проблемы и решения / Сергей Орлов (Avito)",
  "views": 12167,
  "duration": 3763,
  "published": "2017-06-28T06:58:36-07:00",
  "text": "Давайте попробуем начать Меня зовут Орлов Сергей Я работаю в компании авит занимаюсь вопросами сервисной архитектуры сегодняшний доклад будет содержать следующие части вообще задача наша сейчас на сегодняшний доклад рассказать об общих подходах Зачем нужна микросервисная архитектура в рамках какого контекста она используется Какие проблемы решает и как и какие проблемы несёт сама микросервисная архитектура а соответственно начнём мы с короткого обзора Что из себя представляет кнд современного большого веб проекта а далее рассмотрим как микросервисная архитектура может помочь задачам которые в рамках ставится перед разработчиками каждый день рассмотрим основные паттерны которые используются при адаптации микросервисной архитектуры к задачам а рассмотрим подробно В чём даже не минусы А в чём требования которые предъявляет такая архитектура к разработчикам компании к задачам к уровню автоматизации и коротко расскажу про секцию РОЕ будет проходить здесь же сегодня начнётся чуть позже так Всё достаточно просто современный энд большого проекта - это огромное количество функциональности Даже если мы видим приложение из одной кнопки за ним стоят десятки приложений с терабайты данных целый зоопарк хранилищ баз аналитика события различные технологии языки есть таки такой вариант как приобретённые компании когда мы не можем сохранить один и тот же стек технологий в одном проекте просто потому что проектов на самом деле много и появляются новые проекты которые написаны на новых языках делаются отдельными командами часто распределённые командами далее много функциональности - это в любом случае много кода и много - это миллионы строк опять же разные языки если причём это как языки программирования так и языки запросов причём современные фреймворки помогают нам сделать код более лаконичным но качественно эта проблема не решается это ВС равно миллионы строк Прим высокоуровневый функционально соответственно это много людей много разработчиков много команд и при этом нам нужно как-то работать надо решать задачи соответственно нам нужно разрабатывать новую функциональность потому что законченный проект - это Мёртвый проект функциональность должна разрабатываться Как можно быстро как можно быстро доноситься до конечного пользователя наша цель чтобы тот самый Time to Market Да время до появления функциональности уже для конечного пользователя становился Как можно более низким и при этом мы должны сохранить достаточный уровень качества а сразу оговорюсь что говоря о качестве мы сразу должны понимать что есть некоторый нужный уровень которого мы хотим добиться и что Time to maret и уровень качества находятся по сути в обратной зависимости то есть мы можем делать всё очень быстро но с качеством будет беда Либо мы можем стараться избежать любой проблемы любой ошибки и при этом видить релизы примерно никогда соответственно две эти две основные метрики Да они вступают в противоборство с друг другом и тут Важно найти некоторый баланс здесь стоит упомянуть в этот момент такую вещь как закон конви тут есть прямая цитата и очень вольный перевод очень-очень вольный перевод который сделал Я то есть подход в том что архитектура программных систем соответствует структуре команд который мы имеем в случае энда большого проекта это утверждение е раз доказывает свою истинность потому что просто очень много групп разработки много проектов много продуктов относительно независимой функциональности которые разрабатывают разные группы людей которые решают на самом деле часто достаточно разные задачи причём как на осно как про функциональность так и про различные бизнес метрики и вот момент стоит начать говорить о микросервисной архитектуре о том какие решения она предлагает для того что с этим всем бороться а на мой взгляд микросервисная архитектура является по сути развитием некоторых принципов подходов паттернов которые описывались а Достаточно давно в литературе Ну тот же закон конве там шестьдесят седьмой год например соответственно то что предлагает микросервисная архитектура - это некоторые классические подходы которые перенесены на из уровня паттернов которые касаются разработки приложения на уровень архитектуры когда мы описываем системы из нескольких компонентов которые взаимодействуют друг с другом и основные принци следу первое микросервисная архитектура даёт возможность инкапсуляции причём инкапсуляция которую достаточно трудно нарушить в отличие от подхода с монолитом потому что в случае Монолита одна строчка написанная там по ошибке может нарушить инкапсуляция которая до этого выстраивал упорно специальным обм сред за вызвать там публичный метод не из того модуля который с которого он задумывался то есть языки программирования дают определённые гарантии отделения публичного интерфейса от приватного но этого недостаточно чтобы чётко поддерживать инкапсуляция ист качественным то есть исключать в принципе возможность допустить ошибку вот разработка в монолите даже с применением а паттернов проектирования не даёт возможности исключить ошибки инкапсуляции качественно в отличие от микросервиса микросервис в принципе которую мимо которой нельзя пройти то есть естественно теоретически мы можем найти Ту самую базу которую используют сервис начать делать него запросы напрямую такие вещи во-первых решаются административно во-вторых всё-таки Человек идёт по пути наименьшего сопротивления имея некоторые API он вряд ли захочет заменить его на что-то другое далее принцип единой ответственности тоже достаточно достаточно известный принцип что он значит здесь здесь о значит опять же две вещи опять же всё связано с законом кон то есть есть принцип единой ответственности кода некоторые системы которая делает Ровно одну коя от не ожидается и при е Мы видим что сервис начинает на самом деле выполнять различные функции есть целый набор функциональности которые не относятся к другой функциональности сервиса то мы можем вынести е в ещё один сервис и использовать его Независимо а второй второй Аспект принципа единой ответственности - это ответственность людей и команд То есть у каждого сервиса есть чётко черченный круг лиц который занимаются разработкой и поддержкой это может быть он человек для устойчиво чаще всего несколько человек минимум два Иногда люди болеют выходят в отпуск соответственно под ответственность здесь понимается в том числе ответственность за сам сервис в большом проекте это важно важно чтобы у любого куска кода У любой задаче был чёткий ответственный к которому можно обратиться и третий момент это скорость разработки при Дат возможность ускорить разработку не только за счёт того что приложения получаются Меньше меньше логики меньше логических связей в коде меньше вещей которые нужно поправить чтобы реализовать новую функциональность В чём основная проблема Монолита чтобы как правило новая фича упирается в несколько строчек Но эти несколько строчек находятся могут находиться в де модулях Монолита в разных частях затрагивать разный аспект и всё это нужно аккуратно поменять и протестировать то есть скорость разработки упирается даже не в скорость написание нового кода а зависит от чтения старого и зависит от тестирования потому что площадь затрагивая их изменений Просто больше Кроме этого на скорость существенно влияет такая возможность как возможность использовать технологии Которые наиболее точно подходят под задачи То есть как пример если вам нужно разработать сервис который использует подходы машинного обучения и ваш проект весь написан на PHP то у вас одна Ну у вас два варианта На самом деле на самом деле один Вы можете начать пробовать делать машинное обучение на PHP например своими силами И даже если вы умеете то на это удт очень много времени либо там какие-то сиш расширения писа можеть коу решить задачу это на самом деле даёт прирост к разработке также значительный помимо того что в микросервис про проще писать новый код а далее чуть больше конкретики как с этими сервисами всё-таки быть как их выделять за что они должны отвечать основываясь на вот предыдущих озвученных принципах а основные паттерны расскажу вкратце та сервис подход следует из названия Всё достаточно просто на словах при этом на деле это то что часто вызывает затруднения Почему Потому что как правило микросервисы особенно если мы говорим о большом проекте микросервисы - это не точка ноль это не код написанный с нуля который сразу построен по принципу микросервисной архитектуры чаще всего у нас уже есть монолит как правило он достаточно большой То есть это несколько десятков тысяч строчек Может быть там сотен может быть и за миллионы заходит у нас уже есть база которая Скорее всего тоже монолитная и скорее всего очень большая и и при этом нагружена и смиг её просто так затруднительно но при этом даже в такой ситуации Да когда мы идём не Из точки ноль в точку А из точки из Точку о а из Один в два в три хотим попасть куда-то в 10 где у нас прекрасная микросервисная архитектура и все сервисы независимые общаются друг с другам по понятно протоколам даже в таком случае можем применить несколько приёмов Чтобы достичь подобного уровня изоляции То есть первый подход который мы можем использовать ВС новое делается уже в виде сервисов получа ситуация ко Монолит обращается к сервисам к некоторому набору сервисов которые примерно на Ну примерно Независимо делают некоторые задачи некоторую полноценную логику которая вынесена из Монолита вернее ещё не внесена туда следующий подход собственно вынесения когда молится тот самый когда есть только вызовы сервисов и сбор данных от них расскажу наверно поподробнее про этот подход то есть представим что у нас уже разнес всё всё в отдельных базах отдельные сервисы работают с этими базами всё реализовано в виде при этом внутрених соблюдаем принцип когда один сервис на одну задачу при этом понятно что может быть несколько хендлеров и Максима о том что это одна функция она не всегда состоятельными но при этом у нас есть некоторые внешнего внешние которые сервисов причём часто ещё дополнительно как-то слитые вместе Плюс нам нужно где-то проверять авторизацию возможно делать троттлинг логирование там сбор событий многие подобные вещи здесь на сцену выходит Gateway подход заключается в том что мы делаем некоторый отдельный сервис который занимается исключительно тем что собирает данные с различных бвт при этом важно отметить что часто он может делать такие вещи в параллель опять же здесь выходит в плюс то что мы можем использовать различные технологии для различных сервисов То есть например где-то нам удобно делать крут банально там на Джанг условно каких-то синхронных фреймворка потому что просто больше поддержка библиотек больше разработчиков знают быстрее происходит разработка используют для их разработки асинхронные фреймворки Даже если мы используем один язык для всей компании то это могут быть разные фреймворки в случае питона там например асинхронное торнадо и синхронный Джанго соответственно Gateway удобнее делать синхронно потому что кода так там как правило немного и при этом мы можем собирать данные в параллель тем самым уменьшая время ответа нашего сервиса и несколько нивелиру проблему микросервисов что это вс-таки сист сетевые вызовы ин плюс борется с е ещ и тем что помимо сети которые есть внутри дата-центра Да локальной сети ещё есть сеть от клиента от фрон нашего Серви приложения сервиса соответственно как бы нам не нужно делать большой количество запросов с фронтенда мы делаем один запрос и получаем пачкой все данные при этом AP Gateway позволяет не перерез некоторую повторяющуюся логику в разных клиентах ну и соответственно сильно экономит время ответа и сильно упрощает клиент как по сни с подходом как если бы мы дёргали каждый Независимый простенький микросервис клиента и собирали это всё вместе Однако здесь возникает Ещё ещё один вариант Когда нам нужны разные API для разных клиентов Например у нас есть мобильные приложения есть десктопная версия сайта там с два скриптом фронт вот При таком подходе часто бывает полезно делать разные API для разных и такой подход называется frend когда Таких вот ГВ делается несколько по Ю на платформу плюс бывают варианты Когда удобно держать даже не одно мобильное IP А по мобильному I например на каждое мобильное приложение потому что здесь опять же вступает в силу Закон ко приложение ко команда разработки мобильного I там для iOS и отдельная для Android то логично сделать отдельный I Gateway иначе командам придётся толкаться в рамках одной кдо базы И большое количество времени сил идёт на коммуникацию что чревато задержкой сроков ошибок ошибками а далее когда мы переходим к сервисам здесь уже начинается переход в следующую часть про вопросы про проблемы которые ставит микросервисная архитектура в обмен на те улучшения возникает ряд целый класс задач Да которые тоже надо решать стаёт такая задача как Discovery грубо говоря находить где кто а так как сервисов много инстан сов ещё больше каждому из сервисов возникает задача найти инстансы там где запущено приложение и запросить такие данные тут вводится такое понятие как Service Reg - это некоторое централизованное хранилище которое хранит в себе весь список сервисов актуальную информацию где кто и ответственно за поддержание этой информации в актуальном состоянии при этом Discovery можно условно разделить на два варианта два подхода так называемая клиентская когда сервис клиент сам занимается тем что находит конечные эндпоинты и некоторая серверная когда он находит у него есть некоторые серверы и сервер уже занимается Discovery то есть Может быть некоторый прокси сервер тотже например там в случае облачных сист какме используем у него есть собственные средства собственные API он использует tcd для хранения Мета информации где кто Находится и отдельный демон эту информацию собирает и обновляет в API а прокси сервера которые стоят внутри кластера уже могут найти из этого API взять информацию где кто Находится ировать запрос уже на конечные при этом это прино чно сбоку и просто переписывает его конфиг так и далее собственно Чего нам стоит микросервисная архитектура надо понимать что это всё нужно для решения определённого класса задач в определённой проблематике проблематика была описано чуть ранее про много кода Много людей много функциональности вот если сейчас не так то наверное думать о подобных вещах может быть немножко рановато Почему Потому что налагаются некоторые определённые требования на все аспекты разработки в компании первый класс класс вопросов качество инфраструктуры То есть если у нас есть один Монолит мы можем научиться выкладывать его там за какое-то количество времени каким-нибудь скриптом который написали самостоятельно один раз он как-то работает и всех это устраивает особенно если у вас релиз всё-таки не один раз в день там раз в неделю например есть какой-нибудь один разработчик который имеет это волшебное знание и право доступа на то чтобы запустить какой-нибудь скрипти имеет его чинить есе Миро не прокатит Вам нужен некоторый чтобы автоматизировать деплоймент вам нужно собственно само средство деплой вам нужно сделать некоторые артефакты которые будут которые будут пло Да в нашем случае ну распространённый подход сейчас это Конте это може абстракции над теми технологиями на кото на которых вы разрабатываете потому что ну в нашем случае Например у нас 4 языка разработки но при этом должен быть Един как бы к этому стремимся помимо этого все эти процессы все эти сервисы даже если у вас всё это не нагружена но у вас уже 10ка Все эти 30 процессов надо как-то жить надо их запускать Прим запускать так как мы стремимся Да уменьшить как можно быстрее то ещё и перезапускать как-то выкатывать следить что они там всё-таки работают и тут возникает вопрос мониторинга Почём автоматического мониторинга который не просто должен присутствовать что автоматизации чтобы добавление каждого Нового узла проходило Как можно более автоматически и тут возникает вопрос Что опять же нужен софт который будет это делать плюс очевидно нужна поддержка с приложения нужны чеки то есть некоторые специальные которые для мониторинга том что серс жив что у него вс хорошо соответственно ВС это ВС это ложится на плечи отдела эксплуатации на девопс должна быть некоторая Вот такая инфраструктура хоть в каком Ну в достаточно качественном видении чтобы всё это тянуть Следуй лаб мо взд опять же ну по моему опыту налагает определенные дополнительные требования на каждого конкретного разработчика Почему Потому что на самом деле требования двух основных вещей первое разработчик должен стать немножко Почему Потому что если в случает конды он плот в условно бесконечный сервер когда-то давно была построена некоторая программная архитектура там были подняты какие-то железки настроены какие-то апликейшн сервера к этому прикручен какой-то скрипт который умеет катиться катить туда например PP приложения какие-нибудь там SCP или что-то вроде этого А и разработчик не думает о том сколько там железа какие там ресурсы что с нагрузкой и всё это всех устраивает пока что-то не станет слишком тяжёлым и не выт проблемы в случае запуска нового сервиса разработчику нужно сразу рассчитывать нагрузку сразу думать о ней сразу думать о том Какое количество железа потребуется на реализацию его новой фичи и в принципе это позитивный подход потому что все эти вопросы в случае Монолита не явно также присутствовали но Крос архитектура э требования эния разработки что важно е до написания кода и второй вопрос который возникает перед разработчиком который тоже желательно решать до написания кода это собственно проектирование API то есть в случае кода внутри Монолита проще Фактори кто-то недо передал какой-то параметр функцию не так что-то назвал не там размести есть катов надеж что если мы перемену функцию то ничего не сломается или по крайней мере мы это Увидим в случае микросервисов так уже не получится у нас есть это некоторый публичный контракт его нельзя менять максимум его можно дополнить то есть будет как-то мутировать Будут добавляться дополнительные поля но мы не можем просто что пере ша и именование переменных затрудняет переименовывать переменные при этом мы можем и нет волшебных там серебряных пуль в подходе к версионирование за е интересно это огромное количество коммуникаций огромное количество времени сил которое которы заплаче деньги там сотрудников Да сотрудникам просто чтобы переименовать какое-нибудь поле соответственно разработчик сразу становится немного архитектором в том смысле что он должен проектировать свои это дополнительная класс проблем А это документация на самом деле оно встаёт В любом проекте и микросервис там или нет но здесь оно опять же встаёт всё качественнее и на мой взгляд намного раньше то есть мы чтобы обратиться к какому-то сервису мы должны знать что он есть мы должны знать как выглядит его API мы должны знать где он находится тот самый сервис Discovery да Опять же проблема сонно нам нужны некоторые средства документирования может быть полуавтоматического документирования но тем не менее нам нужны некоторые каталоги сервисов нам нужно хранение Мета информации об этих сервисах про просто банально чтобы там те же средства нахождения к Кто отвечает за конкретный сервис например большой Компани просто невозможно знать всех нужны некоторые стандартные механизмы ронга запросов внутри команд вот эту эту проблему как бы чем надо решать как можно раньше то есть сразу внедряя микросервис архитектуру по крайней мере задуматься О том как бы как мы будем узнавать о новых сервисах как там интегрироваться по времени упирается в изучение API в отладку API если у нас нет полноценного стейджинг как Где мы можем сделать запрос к развёрнутого сервису то разработка каждой новой фичи сильно замедляется А в случае микросервисной архитектуры много и фичи и представляют из себя а интеграцию с ми так что тут нужна некоторая ответственность в принятии решений и в понимании Зачем всё это нужно Миш сколько у нас сталось времени Угу а далее У нас есть 10 минут расскажу коротко о секции а на самом деле мы начиная такую инициативу преследовали два основных две основных задачи да рассказать о своём опыте которым с которым мы реально столкнулись адаптируя сервисную архитектуру то есть мы занимаемся подобными вещами наверное уже более 2 лет как собственно разработкой софтвер най частью так и частью которая связана с devops с облаком с инфраструктурой и вторая задача послушать тяжёлый опыт потому что опыт вс-таки местами уникален и есть новые интересные приёмы которые нам могли не прийти в голову Но которые реально могут сэкономить время силы и при этом мы можем кому-то сэкономить время и силы это что касается затем секции то о ЧМ Я сказал предметная область на самом деле у многих она похожа ипро энда веб проектов больше сходства чем различий соответственно Я думаю что решения применимые для применимы в одной компании могут быть Ну по крайней мере частично явным образом не полностью применимы в рамках другой компании А где и когда за мной будет доклад Антона Иванова и Hunter про подробности э использования микросервисной архитектуры именно у них и далее Приглашаю всех на секцию микросервисы с часа и до упора зал Сан Пауло немножко расскажу в качестве тизеров О чём там будет будет доклад про мониторинг про мониторинг всегда полезно Мониторинг это то о чём вспоминают когда вроде уже обо всём вспомнили всё сделали и внезапно оказывается Что что-то сломалось понятно почему и как на самом деле Мониторинг - это огромная обширная Тема и там она может быть как очень скучно очень простой и так и бесконечным полем для применения знаний опыта таланта желание что-то делать будет доклад про так называемый истм процен то есть в случае микросервисной архитектуры У нас есть бы разные пате есть они могут быть асинхронными либо асинхронными то есть есть асинхронный вариант htp некоторые API там и rpc когда мы просто вызываем метод дожидаемся респонс и всё окей есть асинхронные варианты когда мы используем очереди используем некоторые события что ещё важно есть такой подход когда Ну мы изолируем по данным да в идеале и при этом нам нужно как-то синхронизировать состояние разных сервисов вот здесь на фоне на сцену выходят события и некоторые шины данных типа очередей когда мы информацию Можем прокинуть по очереди и по сути догнать стейт какого-то какого-то сервиса б до состояния сервиса А вот будет доклад моего коллеги о нашей системе Processing это так называемый СТМ то есть некоторый набор событий которые происходят на сайте там пользователь посмотрел объявление пользователь посмотрел рекламу куда-то нажал что-то посмотрел всё это превращается в событие и через специальную систему все эти потоки роут в различные внешние хранилища Для различных внешних сервисов соответственно там куча данных аналитика и так далее То есть это тот самый случай когда мы не можем ходить в один и тот же сервис в одну и ту же базу просто потому что база для аналитики и база самих данных Они разные Они заточены под разные паттерны использования под разную нагрузку и здесь нельзя просто так наплевать на принципы там разделения микросервисов а просто ходить в одну базу базы должны быть разные и вот здесь это классический пример Почему общение через события может быть полезным также будет ряд докладов про практику использования микросервисов причём в проектах которые отчасти уже монолиты не такие огромные как основной Авито но тоже не маленькие как люди новую функциональность разрабатывают уже в рамках микросервисов и какие вопросы встают и как они их решают Кроме этого будет доклад про от опять же моего коллеги Дима ходакова который занимается машинно обучением рекомендательные системами опять же даже вот В в таких областях где Казалось бы фокус смещён Ну в сторону от архитектуры Там веб-приложений и так далее тоже находит применение подход с микросервисами Когда у нас независимые маленькие сервисы каждый из которых отвечает за свою задачу Так кто у нас там ещ есть это то о ЧМ забывают даже когда не забывают О мониторинге мой пример это подтверждает опять же в контексте хранения в контексте Service Discovery там возникает ещё ряд вопросов связанный с Discovery конфигурации да то есть хранением конфигурации то есть ут на вообще здравый смыс ут на том что конгу при конфигурация должна ИК есть там принци опять же достаточно старый вот с таким подходом помимо инжекта конфигурации Да есть ещё инжек так называемых секретов то есть некоторый информации который нельзя просто так хранить в системе управления системе контрольно версии в те некоторые секретные данные пароли ключи от и много другая чувствительная информация вот от ребят из безопасности человека из безопасности который у нас занимается подобными вещами будет доклад про использование продукта от который называется служит как раз для хранения секретов то есть полноценный сервис опять же с который может который в шифровать внутри данные и из кого э данные молу Вива ге расскажет про конкретный опыт как мы это решение внедрили у себя как мы его с интегрирован кубе у которого из коробки есть свои секреты но они сильно проще и хуже и как это всё выглядит Ну вот такая секция час дня сан-пауло а сейчас за мной будет Антон Иванов наверное у меня пока всё так благодарим докладчика СБО у нас в этот раз осталось немножко больше времени на вопросы поэтому Давайте поживее задаём вопросы на должны какие-то призы но призы ещё у меня не дошли до рук Да за лучший вопрос будет книжка Ньюмана про микросервис очень хорошая здравствуйте Добрый день Здравствуйте меня зовут Виктор Благодарю вас за доклад вы упомянули в начале доклада о таком принципе вот вопро из это каждый сервис получится небольшая какая-то сво база а в общем в приложении Она будет очень фрагментированные сервис под базу данных а остальные сервисы интегрировать в эту базу которые будут к этому сервису обращаться Вот именно это и лучше просто не всегда мы начинаем с того что делаем новые сервисы поэтому есть вариант когда база уже есть она монолитная и так далее Тогда нужно постепенно выносить функциональность которая ни с чем не связана и действительно делать То есть просто накручивать на этот сервис новый функционал для работы с базой Ну вы имеете ввиду сделать один сервис вокруг всей базы Да вокруг остальные сервисы просто будут идти в этот сервис который будет уже с базой работать ну такой подход имеет ряд недостатков То есть во-первых у вас некоторая единая точка отказа во-вторых вы теряете принцип единственный обязанности дасть занимается все ВС одинаково хорошо часто это просто разные базы И под базой данных понимается не обязательно или и это может быть какой-нибудь кластер Кандры А может быть Тарантула может быть мо может быть что-то ещё в зависимости от задачи в нашем случае на практике так и есть плюс даже если это Например основная база там реляционная то профили нагрузки очень разны отлаживать то есть микросервисы тоже требуют некоторая инфраструктура для упрощения отладки но в случае базы вы Вам трудно понять из-за каких запросов всё тормозит потому что тормозят как правило то есть нарушают работу базы одни запросы а тормозят соседние Поэтому вот чем больше у вас некоторой функциональности внутри базы какой-то семантики запросов и так далее Чем вам труднее всё это отделить вам банально будет труднее администрировать единую базу плюс даже в случае монолитной базы у нас тоже не не всё в одном хранилище вот плюс тут как бы ещё большая нагрузка на эксплуатацию всё-таки лучше лучше по возможности разносить либо если вам нужно синхронизироваться между разными базами использовать события Благодарю вас Спасибо вам Здраствуйте бы была рука Да здравствуйте Спасибо доклад он такой архитектурный получился мне вот вопрос с этим если у нас разные сервисы используют какой-то общий Код да то естественно это общий код выносить в виде библиотек не обязательно какой правильный путь пере используемый код Может ли или Должен ли оформляться библиотеками которые потом естественно несут зависимость Да по коду по каким Я вас понял вопрос Да абсолютно правильный вопро утверждение оно мне очень понравилось если вам в этом что-то нужно Ну вот эту зависимость Да нескольких сервисов нужно что-то поменять синхронно да то скорее всего это не библиотека это некоторый ещё один сервис что-то вынести в библиотеку можно при условии что эта библиотека должна Ну может меняться Не синхронно по всем сервисам по всем инстам по всем приложениям потому что оно по определению распределено сервисов определению много Ну или несколько по крайней мере вы не можете синхронно поменять версию библиотеки во всех сервисах так чтобы это всё не сломалось Поэтому если зависимость требует некоторого вот единого деплоймент может существовать причём не в рамках там 30 секунд а в рамках долгого времени существовать в виде разных версий да то есть у нас есть например да Он может быть в одном сервисе версии оди в другом сервисе версии 2 и это в принципе ничего не ломает вот если так это может работать то это можно вынести в библиотеку если меняться должно синхронно в одном месте оно меняется часто и требует обязательного обновление клиентов то это сервис и даже в этом случае вам нужно будет если обновление несовместимое мигрировать Это всё через параллельный API и потом выключение вро пожалуйста Здравствуйте у меня такой вопрос а когда у нас результатом работы одного микросервиса является большой набор данных скажем гигабайт и он является входными данными для другого микросервиса а хорошо ли объединять эти два микросервис в рамках скажем одного сервера и передавать эти данные через память или через диск а не гонять всё это по сети там с точки зрения архитектуры смотрите гонять всё через диск если это именно вот диск физический Да тут могут возникнуть вопросы с масштабированием То есть пока оно как бы гоняется через диск может быть и ладно если вам нужно много процессов и вы можете как-то распараллелить обработка этих данных то здесь я бы скорее Попро этот гигабайт - это некоторый единый блок да то есть его нельзя разделить Нет ну даже в таком Ну то есть если задача ровно в этом и она в принципе не параллели то Ну я бы всё-таки оставил действительно там оставил бы всё это в виде файла на диске но при этом всё-таки подумал как бы это можно было распараллелить плюс не все инфраструктуры поддерживают в принципе оставить файл на диске да то есть если это кубе доке то там файловая система в принципе она эфемерна то есть тампу конне Оно просто стирается То есть тут нужно будет ВС равно какие-то другие подходы сетевые файловые системы как минимум Да если мы работаем с диском значит это всё равно сеть значит может быть этот гигабайт всё-таки стоит куда-нибудь положить в виде блоба в какой-нибудь Вот автон например советуют их блобы класть в рак Я не пробовал там ждать не могу но как вариант струк задавать та момен за ВС и так работает то почему бы и нет нет просто хочется параллели То есть каждый микросервис он делает свою работу и они не обязательно связаны вот эти два микросервиса друг с другом Есть и другие вещи которые с ними связаны и которые передают скажем не гигабайты а Тамба Ну понятно Если работа асинхронная и второй сервис просто ждёт то можно например отдельно положить файл куда-нибудь синхронизацию между сервисами сделать через очередь то есть второй сервис продает очереди прихода некоторого события некоторой задачи да то есть просто очередь задачи получает событие что файл готов Надо работать и и дальше обрабатывать Собственно сам файл на самом деле Вот я рассказывал про доклад Дима ходакова которая занимается там рекомендательные системами Вита в принципе у них насколько я могу судить их задачу у них похожие схемы Когда нужно обучать мат модельки и перекладывать большие файлы как раз там между этапами конвейера то есть подготовить данные потом скормить их модели потом из модели Ну Собственно уже получить артефакт в виде обученной модели с данными Да там в виде слр ского объекта и его уже потом там куда-то деплоить там оборачивать сервис и так далее вот в принципе я думаю что если е поймаете Можно поподробнее узнать как они это делают насколько я знаю У них как раз вот был рефакторинг в сторону конвейера с очередью с задачка но при этом где-то может быть ещё осталась файловая система Но это ВС равно если это всё хочется параллели масштабировать и так далее Потому что сегодня там обрабатывайте один бло например да а завтра м нужно обработать 10 блов и сам себе этот лоб не параллели А их стало больше то есть тут ВС равно нужно будет придумывать как его передать между узлами вычислительными спа пожалуйста Спасибо вам заклад вопро микросервис архитек что описывали сервис пер база да то есть сервис сервис становится такой независимой ячейкой и вот например чтобы пришла новая команда и нужно условно говоря сервис запустить для разработки то есть хотелось бы добиться вот лёгкого старта сервиса то есть там заходишь вми фай и пошл там чит скачать так репозиторий команда установки база команда там дистанцирование там зависимых библиотек и так далее Вот хотелось бы узнать конкретно решение Какое Вы применяете у себя вот Чтобы достичь Вот вот нам бы хотелось таких задач легко поднять значит продукт как восстанавливать группу микросервисов если что-то вот бэкап какие-то слетели и права то есть разные например версии базы данных например там какие-нибудь интимные данные что не сливать сторонним разработчикам где-то там далеко а сделать какую-нибудь лайто версию базы то есть и как вот это всё вот этим вот оркестри чтобы в проекте это было достаточно по тонкому реализованы не Баш скрипты там куча которые лазят там на ТП перекладывают что-то там бэкапы там прям тут же myq там вот как вы с этим справляетесь я нашл примерно четыре вопроса один вопрос то есть как кпить сервис и как его восстанавливать Но это жену как бы ограничения есть какие-то чтобы легко было права то есть Может быть разные версии то есть нельзя все версии посмотреть бэкапов и как востановить если Ну прям централизовано под кпом имеется вду какая-то Боевая база под нагрузкой или то есть Бова в которая много статистики заявок и например тестовые базы где всё это не надо чтобы каждый раз БК долго не поднимался чтобы вот легко Ну смотрите для нужд разработки мы используем подход Когда у нас есть отдельный оффлайновый процесс да который делает так называемый СМЛ то есть некоторый набор данных у него есть некоторая Конфи Ну в в э история самописный но Там ничего особо сложного просто пишете некоторую конфигурацию Какие данные вы хотите дёрнуть из реальной базы что у Вас могут быть некоторые внешние сущности грубо говоря какой-нибудь юзер на него там завязано куча всего вы Пите нее ко взять юзера там с ID условно или с определённым мем какой-то тестовый пользователь вытаскивайте по нему некоторую структуру дополнительную объектов фуете что важно Вот то о чём вы говорили про всякие приватные данные и так далее И вот на основе этих данных собирается уже докер образ и этот докер образ используется разработчиками для есть работат на не всех данных имм база разворачивается быстрее она занимает меньше места и так далее плюс эти данные аются соответственно мы не нарушаем личные данные пользователей какую-то приватную информацию там транзакции наверно вот такой подход а доке образ то есть база данных то есть условно говоря дам базы прямо хранится Бинар и когда он стартует он просто делает того с бинарными бинарными ну с записями в самой базе то есть это некоторый образ который содержит в себя внутри уже и базу тоже и всё это периодически на сие перестраивается то есть мы имеем каждый день Ну минимум каждый день Да некоторые новый слепок с обновленными данными с накатные миграция с пожалуйста а можно у меня просто есть какая-то конкретная реализация которая я придумал к вам подойти попозже и обсудить е насколько это велосипедном очевидно Не велосипедна не я име в виду свою то у меня есть идею я сейчас просто не буду до Долго рассказывать я понял да конечно я буду здесь Большое спасибо Пожалуйста Спасибо за доклад Здравствуйте спасибо за доклад Вот вы рассказали про микросервисы и там было упоминание что есть микросервисы которые обслуживаются микросервисами возникает некая иерархия зависимостей вот каким образом вы оформляете и если оформляете зависимость чтобы провести Импакт анализ Ну предположим какой-то из микросервисов мы планируем вывести из продакшена на что это повлияет с учётом развесистое дерева так ну в данный момент на самом деле готовой системы у нас подобной нету но мы над ней работаем есть этой СПО на самом деле всё могу рассказать как я планирую это делать Я это буду делать в ближайший месяц то есть всё начинается с на самом деле Почему Потому что для разработчика это некоторая единая точка входа в продакшн в кластер и так далее То есть нажимая кнопочку задеплоить сервис мы можем помимо собственно самого деплоя сборки там документации и так далее можем ещё и в том числе куда-то запушить Мета информацию о сервисе то есть мы вот на этом Эби не информацию в том числе описание связи но при этом описание связи скорее всего нужно будет делать руками Я видел аналогичные решения Но они требуют ку Бернеса и работают на уровне кластера и отслеживают трафик То есть это практически ксирон то есть на данный момент у вас нет форматов представите пока идея Да ну скажем так представление как это делать плюс там в чём ещё удобство что там часто такая звёздчатая система структура когда есть Монолит точ ну сервис и за сервисом который является по сути да ещё большая пачка сервисов то есть связи не все со всеми а всё-таки более централизованные это несколько упрощает подходы то есть понятно что есть связь там точка а точка б вот Команда А может Договориться с командой и команда уже в рамках своих че сервисов автоматически разбирается где Что то есть у вас ориентир на звёздочку структуру не на сетевую там типа мана когда он рассчитывает все при на самом деле когда всё совсем скорее всего что-то не так с логикой приложения потому что это уж данность Ну сложновато но я не отрицаю что у нас такого не будет но пока всё сводится к вот таким схемам скорее Спасибо пожалуйста можно сворачиваться Здравствуйте Спасибо за доклад вы сказали что дешевле сделать приблизительно так команде АО разрабатывает свою опиш свой микросервис команде допустим Android приложение разрабатывает с есть такой подход Окей бизнес логика - это отдельный получается микросервис или они обе команды дублируют ректы продук Ну вот есть варианты что они не дублируются и многие фичи часто не релиз одновременно на аое и Андроиде как минимум там есть смещение по срокам и смещение это не ну в случае мобильных приложений это не integration катим ри раза в день как написали это всё таки релизный цикл там раз в месяц хотя бы поэтому они не так уж ну далеко не всегда они делают одни и те же фичи плюс да Если у вас есть некоторая общая функциональность из серия там Дайте мне Ну вот notification цен хороший пример да то есть у вас может быть сервис почты сервис отправки ше сервис SM есть некоторый сервис который разруливает например все нотификации по разным каналам прокси на те на те остальные сервисы Вот это может быть вынести в отдельный сервис А например как этим сервисом будет пользоваться API Android или IOS это можно реализовать в каждом конкретном I отдельно То есть может теоретически получиться такая ситуация когда в Андроиде своя бизнес логика Вот если такая ситуация действительно очевидна ина вот этот подход с отдельным эндом для каждого Фронда он Дат как бы преимущество должен по крайне мере плюс меньше затрат на синхронизацию на коммуникацию и так далее ктото что-то добавил у кого-то что-то сломалось при этом это тестируют разные команды при этом непонятно почему она сломалась потому что поменяли разработчика другой команды есть практика показала что дешевле повторять два раза бизнес логику нежели иметь некую третью команду кото предоставляет дм команда но мобильно то есть практика показала но не наша окей Всё спасибо пожалуйста А здравствуйте Спасибо за доклад Ага Здравствуйте подскажите пожалуйста вы используете себя на проекте а тестирования и Если да то как вы распределяется запросы между разными версиями сервисов на уровне инфраструктуры кунет или всё-таки тестируйте внутри компонентов внутри сервиса Всё даже чать ще Все вки тестировани пока в монолите но уже инструменты Ну потому что сервис собственно что-то делают Монолит решает кого он вызовет когда и так далее И тут скорее движение в сторону того что из Монолита будет вытащен всё останется некото который как раз и будет заниматься тестированием тестирование это удобно дела вмте смм эс информацию Ну если вы будете использовать iway то вам нужно и между сервисами его ставить то есть они не напрямую могут соединяться запросы отправлять А всё-таки через I даже внутри может решать каким сервисом сделать запросы например как пример у нас есть там пачка рекомендательных сервисов Да перед ними есть О это как бы уже сечас так с лиен можете собрать запрос в таким образом чтобы указать Какие рекламные бэнды вы дте ну не рекламные рекомендаци То есть вы можете сделать некоторую там ну выборку да что вот каждый сотый запрос Мы запрашиваем ещё и Новый сервис рекомендации вместо старого там или ещё какой-то дополнительный то есть логикой рулит в нашем случае сейчас монолитно при этом с разбито или не делать Ну вот запрашивать или не запрашивать логика остаётся за вызывающей страны спасибо Так у нас последний вопрос После этого у нас будет книжка за лучший вопрос и следующий доклад раз Угу А спасибо за доклад У меня на самом деле два вопроса Ага А первый вопрос А как вы делаете транзакционные Виса то есть грубо говоря есть сервис который а там не знаю подтверждает счёт есть сервис который там совершает там покупку продукта Или там какую-то резервирование Если допустим счёт не подтвердился или что-то произошло то другой сервис там должен откатить операцию как вы это разруливает Это первый вопрос а второй вопрос А насколько должен быть маленьким или большим микросервис то есть Если не учитывать там принцип единой ответственности Ну что это как бы понятно а просто если так вот сложилось что у сервиса Ну там статистика например много данных много кода есть какие-то метрики которые позволяют там понять что вот всё как бы микросервис слишком большой пора делить там спасибо а Пожалуйста смотрите по поводу По поводу традиционности опять же распределённые системы опять же тут скорее даже задачи часто ставятся не обеспечить традиционность а иметь возможность восстановления после аварии то есть догнать состояние до какого-то актуального а в случае независимых баз в принципе это всё делается при помощи опять же событий и некоторого лого этих событий То есть у вас есть база состоянием А некоторая база б вы что-то комитете в локальную базу и отправляете ивент принимающий стороне чтобы догнать её состояние он его получает и догоняет То есть это как бы cons но EV cons как-то вот так если вам реально совсем-совсем нужны транзакции Что бывает на само не так уж и часто На мой взгляд то всё-таки Пусть это будет одна база но чаще всего вот такого догона состояния должно быть достаточно то есть грубо говоря у нас есть база для аналитики база вот для обработки онлайн транзакций Да и мы в принципе сделаем транзак будет Рава потом А по поводу границ микросервиса насколько по поводу границы есть некоторые Ну на самом деле если много логики скорее всего её можно разбить То есть как хороший пример вот сервис который занимается платежами это один сервис или нет На самом деле его можно разбить там можно сделать действительно много сервисов при этом там не будет проблем с станционно потому что транзакциями нет просто пояснил транзакциями будет заниматься сервис который будет заниматься собственно вот учётом Да но отдельно у нас в платежах есть ещё и шлюза до платёжных систем и тут цинности в любом случае уже как бы нет плюс плюс могут быть разные шлюзы отдельная функциональность для предоставления отчётности Да и она не обязана быть транзакционный с онлайновый базой то есть мы вот эту всю логику которая вроде как про одно и то же платежи можем побить уже на некоторую пачку совсем Ну достаточно самодостаточных компонентов Я думаю что в вашем случае Ну тоже можно хотя бы попробовать выяснится что не всё оно там про одно и то же а по размеру всё очень все варианты которые я слышал это что-то что можно относительно быстро переписать Ну мне кажется логику деления микросервисов на микросервисы и так далее можно уже обсудить В кулуарах А сейчас мы выбираем видимо самого лучшего вопросник Да вопрос на мой взгляд правильный это вот как раз про карту сервисов про да Для меня это очень неприятный вопрос потому что это то что я ещё не сделал и что что я делаю в данный момент Но я считаю что правильно Так поблагодарим Сергея был очень интересный доклад про микросервисы в Авито"
}