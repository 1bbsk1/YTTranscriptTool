{
  "video_id": "VSM7BAzlNsY",
  "channel": "HighLoadChannel",
  "title": "Мониторинг — разработчикам! Технологии — сообществу! Профит — всем! / Владимир Колобаев (Avito)",
  "views": 1741,
  "duration": 3121,
  "published": "2019-05-15T02:19:49-07:00",
  "text": "всем привет меня зовут владимир club f я работаю неа вид и занимаясь развитием системы мониторим наш компании мой доклад будет посвящен потому как мы варим мониторинг какие технологии мы используем какие новые технологии мы предлагаем open source вот и хотим чтобы как можно больше компаний людей и проектов использовали эти технологии потому что это окна source и от этого будет польза всем мой доклад разделен на три части на водную на техническую на заключении сделаны по следующим причинам ищет поймете почему в общем вводная часть мониторинг ориентированный на бизнес мы хотим приносить максимальную пользу нашему бизнесу мы считаем что сервера в стойках стоять не для того чтобы греть воздух проекты разрабатываются не для того чтобы ребята было чем заняться для того чтобы приносить бизнесу какой-то вылью и мы хотим как можно больше в со своей стороны предоставить возможностей для бизнеса этот вылью поднимать вот и значит мы несем мы под мы сели и подумали и решили как бы в чем мы в принципе им как отдел мониторинга можем приносить пользу по бизнесу и несем и значит пользу по нашему мнению в первую очередь выявление проблем в инфраструктуре большинство различных систем мониторинга которые есть сервисов там различных они предоставляют эту штуку прям все из коробки это как бы и так всем понятно выявление багов в коде при использовании нашего сервиса да мы можем каким-то образом разработчикам там или менеджером показывать что ребята вы выкатили какую-то штуку в этой штуке баги вот наши метрики присаживаются метрики ошибок растут пожалуйста вот вам alert этом вам вот аналитика как бы мы в этом плане помогаем ребята выявляют и увеличиваем скорость разработки в связи с тем что мы предоставляем метрики мы обучаем пользователей и все такое ребята начинают быстрее писать не так боясь допустить каких-то ошибок ну грубо говоря они допускают ошибку в коде они выкатывают свою штуку там вдв stay jing или даже в прод видит что метрики поехали на спад они на это реагируют и откатывают там грубо говоря это помогает им последующем не бояться допустить ошибку они пишут быстрее и от этого явно есть польза и мы можем предоставить как сервис мониторинга определенную аналитику эффективности бизнес-решений грубо говоря у нас есть например продукт-менеджер который решил в пилить 10 новых полей форму регистрации вот он короче принял такое решение мы спилили 10 новых полей формы регистрации и наша регистрацию упали в 10 раз условно в таком случае у нас инфраструктур на все работает багов нету как бы но у нас явные проседания как бы по пользователям у нас явные проблемы вот с помощью анализа эффективности какой то мы можем сказать что ребята тренды после выкопки определенные тренды которые мы строим для вас или которые вы можете строить самостоятельно по вашим метрикам нашей системе они падают падают или сильно растут эту аналитику мы предоставляем ребята на это смотрят как бы принимают решения и мы значит посидели подумали да мы можем предоставлять вот такие штуки в качестве чего этот для этого нам нужен какой-то сервис мониторинг надо рассматривать как сервис который мы будем предоставлять пользователям да ну для чего это у нас грубо говорят много всего у нас около наверно 400 серверов нет у нас около четырех сотрудников в разработке у нас около 700 серверов куча различных виртуала клык сишек всяких квн квн ок и прочего у нас есть монолит много различных баз данных грубо говоря у нас просто очень-очень много всего нам за этим всем надо следить за всем следить о надо мониторить и нам надо какая-то единая база куда бы мы могли скидывать метрики и предоставлять пользователям эти метрики при возникновении проблем приходится обращаться большому количеству компонентов у нас например где-то что-то от стрельнула раньше ребятам надо было сходить грубо говоря в киба ну для того чтобы посмотреть логе в какую-нибудь мунин там или другую систему мониторинга то что посмотреть как там метрики инфраструктуры поживают потом получить какой-нибудь аналитический отчет отверстие это очень долго это очень долго как бы и это демотивирует и мониторинг либо чего по тоску тоже очень негативный фактор грубо говоря к нам приходит к нам приходит купить пользователь наши программисты говорит вот мы вы выпустили бизнес фичу нам надо ее за мониторить или грубо сервис до или новую ручку написали говорит нам надо за мониторить как нам это сделать мы говорим о поставь task мы там у себя дави заведем триггеры заведем какие-то сущностей и начнем то на твою штуку мониторить во первых это очень долго потому что пока мы это сделаем пока он придет пока она пишет таск потом мы выступаем в качестве мы как системный администратор и да и люди об санджи не эры там или еще кто-либо выступаем промежуточным звеном который в данной системе как бы не надо и в конечном счете из-за вот этой продолжительности и сложно ты сложности из-за сложности в конечном счете ребята перестают приходить то есть он такой говорит да ну я лучше буду дальше свою кабан уходить как бы ее общее типа меня все устраивает поэтому мы решили сделать один единый мониторинг как сервис предоставлять его пользователю пользователю будет им пользоваться у них быть единая точка входа они будут радоваться что мы предоставляем для этого да вот единую точку входа для записей метрик для чтения то есть мы говорим вот сюда пишите вот отсюда читайте мы предоставляем пользовательские интерфейсы то есть мы говорим что вот вам пожалуйста различные граф анны различные мойры их web-интерфейс и вот вам пожалуйста на вход вы можете посылать либо какие-то посты в api этих проектов грубо говоря вот предоставляем интерфейса да и доступность и надежность мы следим за тем чтобы наш сервис работал стабильно и чтобы он переживал нагрузки грубо говоря у нас количество пользователей растет количество сервисов растет существует всего растет и мы как бы смотрим что вот но надо расширяться мы добавляем сервера это все делаем и за этим пользователю вообще не смотрят и об этом ничего как бы не знают им особые не надо и документацию то есть у нас есть confluence мы в конференции видим документацию постоянное и там как-то обновляем и пишем типа вот обновлено там 18 10 2018 ребята таки посмотрели у актуально здорово предоставляем различные обучающие материалы мы пишем для наших новеньких ребят различные видео ролики короткие которые ну грубо говоря по пять минут идут где мы говорим что вот ребята у нас и сервис мониторинга в него вы можете отправлять вот так вот так вот метрики вот так вот так вот пользоваться у нас есть там grafana пожалуйста типа посмотрите ролик по графа не 5-минутные вы поймете как с ней жить как нее заходить как не строить дашборде вот это все буквально за полчаса вы проходите fast курс по мониторингу и вы можете идти в бой грубо говоря зачем это разработчикам ну вот есть это все наши разработчики лучше начинают понимать что они вообще пишут то есть когда они там выкатывают какую-то штуку взаимодействие с каким-нибудь базой с редисом кашами или прочим они видят как на графиках как это влияет вообще на всю инфраструктуру на их код на проект ну а не таким образом начинают более ответственно подходить к факту разработки они перестают допускать они перестают бояться допустить ошибку так как они быстро об этом узнают и у них будет в любой момент возможность откатиться поэтому они как-бы перестаёт бояться ошибок и они быстрее пишут в связи с этим новые фичи так да и быстрее и лучше fixed старые фичи и вылавливают новые баги на этом вводная часть закончена сейчас немножко про техническую часть вся наша инфраструктура весь наш сервис крутится вокруг графита графита не как какого-то определенного стыка как соглашение как вот такого в граффити основным понятием является метрики возможно многие из вас что такое метрики а может быть кто-то не знает поэтому я решил всех выставить на одну плоскость и рассказать вам что такое метрика метрики в граффити это строка разделенные пробелами где первым полем является ими метрики вторым полем является его значение это может быть какой-то int или холода и timestamp уникса в граффити ну у нас есть какая то определенная схема чтобы вы лучше понимали как это все дело работают у вас есть какие-то приложения софт мы с этого софта софта снимаем показатели работы этого этих приложений с авто с помощью каких-то агентов у нас могут быть скрипт и у нас могут быть коллег д какие-то телеграф и или проще агенты с помощью которых мы мониторим состояние ваших определенных продуктов после чего мы собираем с них метрики в эти показатели собираем агрегированных метрики переводим и отправляем их графит графит используют для хранилища базу данных свою там series который в нашем случае это cliff house и для того чтобы из этого графита данные читать у вас есть графа на но более интересно для всех наших разработчиков это не то как устроен графита что такое стенды потому что мы очень активно используем ssd мы сами его развиваем и очень активным пользуемся в стаде есть такое понятие как событие события выглядят почти как метрика но она немножко отличается она состоит из имени значения и типа у события не тут они штампа у него есть какое-то значение флот какой либо какой-то числовой и есть тип для того чтобы понять вообще для чего это нужно давайте я вам расскажу такое типы типы в статье их там всего четыре мы используем три в основном первые годы это ваш сервис отправляет событие в наш создай агрегатор и указывать что тип события например гош вы их отправляете предположим 10 штук мы берем значения последнего события и только последнее событие записываем к нам хранилище это актуально например для различных для съема различных показателей там процессора до или каких-то таких штук есть каунтер но это обычный крем данный счетчик здесь очень просто мы суммируем за интервал агрегации все входящие значения и отправляем результат в хранилище и самое интересное то таймер и таймер и вы отправляете какие-то события мы эти события принимаем раскладываем вам результат на 11 метрик мы показываем вам количество пришедших событий последнее значение события максимальное значение события минимальная медиану среднее и пирсинг или это делаем все за вас вы просто отправляете какой-то один тип события грубо говоря вы какое-то событие отправляйте миллион раз сейчас мы на примере совсем разберемся схема этого следующее у вас есть какие-то события в сервисе вы эти события отправляете поедите в плен текстом к нам в стаде агрегатор в наш тогда сервер мы агрегирует его в течение какого-то определенного окна и отправляем в виде метрик в графит например у вас есть пользовательские запросы вот у вас использовать льда не отправляет вам запрос у вас есть какой-то тестовый сервис вы отвечаете вашим пользователям и в момент когда вы отвечаете вы отправляете событие что вот такой то пользователь пришел и его время время ответ этому пользователю составляла там столько этой секунды отправляйте в этом плане таймер мы принимаем данное событие агрегирует отправляем его в графит и отправляем по нему каунт и максимуму минимуму пирсинг или все про то что я говорил немножко цифрах да вот у вас предположим пришел миллион и 3 пользователя к вам на сайт миллион 3 пользователя в течение 60 секунд вот они пришли в конечном счете мы вам не миллион метрик пишем хранилище опишем всего 11 метрик в теле которых вы видите количество вы говорите что вот ко мне пришел миллион пользователей каунт мы знаем максимальное время за сколько мы ответили этим пользователям там 570 миллисекунд минимальное значение медианы persantine вы получаете вот это все из коробки этим этим пользуются наши разработчики как устроен сервис мониторинга у нас есть различные приложения которые необходимо мониторить как я раньше говорил различные апликэйшен и железки системы софт и у нас есть грубо говоря так исторически сложилось что у нас есть старая система мониторинга которую мы там по определенным причинам пока не выпилили ну и естественно как у всех у нас есть облака guberniatv значит все наши applique шины приложения все продуктовые пишет свои события к нам стали агрегатор мы в качестве стал и агрегаторы использовали разработку компании гид хоп который называется brubeck нас коней грубо говоря в течение полутора лет ребята просто забили на проект и мы решили у нас появилась берем целая пачка пожелание чего бы мы хотели иметь вот обратной связи не было форка тьмы не захотели мы решили написать свою штуку которую мы назвали bio и на так получилось такое название грубо говоря нам сгенерировала авто генерировал к названий вот да мы в общем сделали такую штуку написали ее нарасти она отказоустойчивая масштабируемая и она пор авто выбирает кто является лидером лидер агрегирует все метрики и отправляет их в графит то есть данная штука позволяет вам перезапускать сервис вот тогда агрегатор позволяет вам стать сдай агрегатор обновлять или например выключать какую-то ноду и вы не теряете метрики бизнеса вы мы в 2018 году пытались найти что-то похожее вот мы ничего не нашли поэтому написали сами что касается различных отварных системных софтовых метрик тут все очень просто у нас есть к или где в качестве агента который стоит на серверах собирает метрики и показания с hao staff is софта и отправляет их в графит что касается куба у нас есть хипстер так исторически сложилось и у нас есть про метался ну про метался так думаю никому без них и надо эти парни мониторит состояния кластеров и после того как они их от мониторили отправляют их к нам в карбон сериалы это такой просто роутер чтобы вам понятно было он отвечает за то что он делает определенную индексацию он проверяет а он проверяет вы во лидирует метрики на то чтобы они были корректными после чего отправляет их на бэг-энда в нашем случае первым брендом является класс стр графита который состоит из полностью переделана вас т.к. вся обвязка горная которая необходима для графита в качестве базы данных используется клик роуз вот соответственно все метрики уходят в нашу вот эту коробку в графит кластер и туда за этими метриками читать их ходит уже grafana и у нас есть сервис такой который считается слой по различным сервисам ну то есть мы говорим надо посчитать солей по сервису там продаж пошел посчитал помимо этого карбон сирил и отправляет эту пачку метрик в мой руль в детектор аномалий мой ru мы используем для лифтинга она сама себе грубо говоря графит и она не зависит от хранилище то есть если у нас падает хранилища метре кто мы не теряем а лифтинг это как бы очень здорово по разным причинам могут быть различные коллизии с нашим там графитом не знаю такое может быть на справа не случалось менее олег не всегда будет жив мойра имеет в себе свой собственный интерфейс для пользователей она хороша тем что она предоставляет любому пользователю возможность зайти в мой ру и создать себе самому подписки на какие то там триггеры да самому создать триггер самому на него подписаться самому на него получать альтинг таким образом наши ребята самостоятельно без без обращения к системным администратором могут отправлять метрики мы их получаем агрегирует складываем после чего они сами могут себе построить дашбордов графа не они могут себе настроить о лифтинге в море мы выступаем в качестве ребят которые просто поддерживают данную инфраструктуру там развивают ее все операции процедуру самостоятельно пользователи делают сами немножко про нагрузки not у нас есть такой стык он там как-то работает и чего же он там живет и ничего делает мы принимаем сейчас порядка мы живем в 30-секундных интервалах все метрики принимаем 1 30 секунд принимаем и порядка четырех миллионов метрик в 30 секунд в графит пишем да вот этот крик house как можете обратить внимание на первую ноту прилетает эти четыре миллиона а дальше они уже по реплики crack house и разлетаются на шарды и на реплики потому что таким образом намного меньше трафика и он как бы он намного намного меньше трафика мы гоняем по сети вот что касается нашего стада агрегатора в статье мы принимаем порядка 120 миллионов событий в 30 секунд это где-то наверно порядка четырех миллионов в секунду различных событий без носовых и отправляем эти бизнесовые метрики агрегирует ада и результаты агрегирования отправляем в графит на среднем верхнем графике который называется be a и на игр с как бы есть там циферки 3 миллиона его 4 миллиона которые полоса идет между ними это количество метре которые летят к нам от production ну и чтобы было видно да вот мы принимаем 4 там миллиона метрик из них почти 3 200 это бизнесовые метрики то есть инфраструктурных всяких штук у нас там сравнительно немного ну процентов 30 все остальное это бизнесовые штуки и чтобы было видно то есть мы видим на среднем графики посети что сетка нас утилизировано не очень сильно там до гигабита мы видим также полную статистику по метрикам различных приложений вот у нас различные мобилки и но и в топе то есть больше всего различных метрик летит именно с мобилок там сын воев и прочих штук подсыпку это выглядит вот так то есть мы в принципе расходуем на наших серверах процессор то в пределах 15 процентов но когда мы шли havasi говорим типа давайте мужчина нибудь там удалим то видно что процессор начинает разгоняться процентов и тогда 40 одесского утилизация на ssd рейдах начинает вылезать в потолок но это ничего как бы он хотя бы научился удалять это очень здорово считаем вот да а теперь немножко пока примером какие метрики лучше всего использовать чтобы понять что происходит с вашим сервисом вот у нас есть server-side девелопер василий его задача разработать микро сервис до какой-то условный сервис который будет показывать следующее он будет показывать количество показов объявлений пользователям вот нам надо считать сколько раз мы показали пользователям объявления вот этот сервис необходимо этому усилия разработать значит у нас есть условный сервис в него ходит к нам монолит и отправляет какие-то запросы до идиш некий от наших объявлений мы значит идем в редис в качестве каша запрашиваемой если там ну как бы за кашированные результат радист нам говорить что нету мы идем в пузырь с говорим дайконом данные возраст говорит набери мы отвечаем нашему монолиту и после чего записываем результат в каждом что нам из этого надо мониторить ну во первых нам надо мониторе сколько запросов и к нам приходит и как быстро мы на них отвечаем да количество тайминги нам надо знать как быстро сколько раз мы ходим в редиса как быстро нам отвечает радиус нам надо знать сколько раз мы ходим в позарез и как быстро нам отвечает позарез ну и собственно скажу вам то же самое а вот метрики различных радиусов пост грессов и различных других инфраструктурных систем вам должны предоставлять те люди которые в нашем случае до должны предоставлять те люди которые ответственны за эти системы если например запузыришь у вас встречают бананчики то значит ребята избе и вам помогут они вам подскажут вот смотрите метрики вашего сервиса на этом тоже barley у нас есть высокоуровневые метрики бизнесовые по которым мы в принципе оцениваем как живет наш бизнес как насколько нам хорошо или насколько нам плохо эта метрика называется стата вот выглядит она вот таким образом каждый заходящих на пользователь приходя сюда каждый приходящих нам пользователь отправляет одну единственную метрику который является response times то есть на каждое событие к нам прилетает response time относительно платформы у нас получается вот их несколько если смотреть на оранжевый график вот в нижней нижняя панель оранжевый график это total да сколько пользователей к нам приходит в принципе дальше идет разделение по разделение по платформам и соответственно синий график на нижней панели это график который показывает какой трафик был вчера а верхний график это response time причем 75 персонал мы предоставляем пользователям возможность показывать пирс antillas как быстро мы отвечаем нашим ребятам нашим клиентам как бы быстро отвечаем нашим клиентам по различным платформу и для того чтобы получить вот эти два высокоуровневых душ барда мы просим наших разработчиков отравлять всего лишь один одну единственную метрику вот и они отправляют нам ее миллион четыреста раз в минуту значит хорошо мы как бы говорим что вам возможно было бы неплохо смотреть на этот график если вдруг с вашим сервисом стоит что-то случилось грубо говоря о пришел alert что у вас упали купола количество обращений там до нуля посмотрите пожалуйста сюда наверх а уровень может быть эта проблема типа у нас там с монолитом вот у нас есть проектирующие прокси введение джинкс а который стоит между монолитом и нашими сервисами вам неплохо бы было мониторить его потому что все запросы которые к вам проходят они проходят здесь и бывает такое что у вас бэкон подстрелила и на яндексе грубо говоря есть ошибки и вот если у вас есть эта информация вы их увидите у нас да мы мониторим этот engine я название сервисов специально срезал по факту здесь статистика вот по этим поэтому миллиону сколько конкретных подключений было в какой сервис таким образом наш сервер сайт девелопер василий может мониторить свой сервис вот он пишет свои сервисы на гол инге а мы ему предоставляем различные штуки мы в бойлер флейтах сервисов вшиваем поддержку отправки метрик в виде библиотек нога лэнге питание php вот таким образом ему для того чтобы со своего сервиса начать отправлять метрики по его работе его состояние достаточно там ввести три строчки в есть такая штука но есть такое понимание что в принципе с весь стек этого графита он достаточно большой но и судя вот по той большой схеме синий как бы он такой достаточно большой его поднять одному достаточно сложно для этого для того чтобы сделать проще какое-то тестовое обучение тестовый вообще потрогать этот стейк что там с ним и как мы запилили маленький докер кампус скрипт в которой зашили поднятие всей этой инфраструктуры за там за три команды да то есть мы идем на git хоп клонируем себе репу заходим в директорию с нашим докер компасом и делаем докер кампус об и поднимаем весь стек включая cliff house is to sd граф анны и сборам метрика конкретно вашему хосту который вы мониторите таким образом в 3 команды можете поднять сами себе графит начать отправлять туда метрики из ваших каких-то кастомных сервисов грубо говоря вы можете там на своем локальном компьютере в среде или там мини-клубе тесте какой-то сервис и отправлять сами себе метрики в свою локальную маленькую графа но это типа очень здорово как бы вы сразу видите весь profit заключительная часть собирайтесь все типы метрик потому что это очень полезно собирайте их в и бизнесовые метрики и метрики различных систем собирайте все в одно место потом вам будет проще их найти вам после этого будет проще к ним апеллировать и инфраструктурные бизнесовые метрики чаще всего нужны все вместе для того чтобы понимать где у вас там чего отстрелил а и строить на морель тенге и аналитику предоставляйте пользователям возможность гибко использовать ваш мониторинг дело в том что если вы будете заставлять ваших пользователей создавать тоски на то чтобы что-то за мониторить и у них не будет возможности это делать самостоятельно то скорее всего они перестанут выходить вообще и стремитесь к увеличению эффективной команды эффективности всей вашей команды и вообще всего бизнеса в целом как бы от этого выигрывают все компоненты которые мы используем я вот привел на слайде можете сфоткать все компоненты являются open source нами вы можете вы можете их скачать и использовать как бы только какой-то конкретный отдельный компонент можете использовать весь стек можете там их менять как куски лего вот собственно мы пишем различные статьи на хабре про мониторинг про графит и просто т.д. и про проще вы можете до их прочитать на этом у меня все наверное успел даже быстрее чем хотя спасибо да пожалуйста спасибо большое за доклад очень интересно у вас на схеме был такой компонент карбон силь relay да-да-да можете чуть чуть подробнее что он делает особенно интересны вы кажется сказали слова проверяет или были дела он вы лидируют метрики входящие ну то есть смотрите вы отправляй к вам кто-то в вашу систему отправляет метрики вы заранее достоверно не знаете что там за метрики какие они внесут в себя там паттерна я и вы как бы по определенным шаблонам весь входящий поток проверяете ну то есть право эти метрики проходит валидацию что во-первых они корректны и во вторых там записанную предположим числа в виде значение в качестве значения записаны числа а не какой-нибудь там грубо говоря да они они что-то другую грубо говоря строка то вы вы лидируете эти метрики и после чего отправляйте их на бэг-энда вот то есть очень просто но это прокси с валидации спасибо за доклад пожалуйста очень понравилось я хочу такую же штуку себе вопрос такой сколько вы вообще по времени эти метрики храните или вы их дело в том что в хаосе в принципе ничего удалять было нельзя до определенного времени вот поэтому мы их особо и не удаляли вот в данный момент мы храним порядка двух лет ну и планер сейчас как бы так нет мы думаем что нам и мы на двух годах закончим просто будем партиций которая выходит за пределы двух лет отправлять в архив crack house позволяет портится которая он использует отключать в какой-то момент и их можно например отправить в архив если вдруг они понадобятся мы их оттуда заберем и подключим обратно в хаос то есть мы можем пользоваться этими данными там real-time в этом есть явный плюс спасибо спасибо за доклад такой вопрос вот вы говорите что все нужно агрегировать в одном месте это безусловно хорошо вопрос в том сколько времени после этого нужно вообще вот на настройку того чтобы отобразить это все кучу вот этих метрик до чтобы разные подразделения абсолютно могли правильно проанализировать ситуацию скажем тогда вот вообще ну то есть вот именно вот эта сложность дальнейшем настройки и поддержки этой ну потому что это же меняется со временем наверняка но сколько вот это вот сложно вообще ну вот смотрите тут основной основной посыл в том что команды которые разрабатывают какой-то продукт они самостоятельно за ним смотрят так поэтому если они там у себя что-то меняют они как бы себе и правят мы предположим для различных инфраструктурных штук самостоятельность пишем и alert и и например для состояния физических серверов раз для состояния там свечей и прочего поддерживаем конкретном и состояние бизнеса вых различных метрик которых большинство рассматривают сами ребята мы смотрим только на какие-то верха уровне вы штуки дано бизнесовые и у нас есть требование чтобы ребята их писали в определенном формате чтобы мы потом могли найти конце что типа вот эта метрика она относится к такому-то сервису да и вот это вот метрика она предположим имеет флаг критичности вот и относительно флага критичности этого структура этого сервиса мы как бы понимаем что вот это сервис там предположим а этот и он на данный момент ведет себя чувствовать себя хорошо вот поэтому особых сильных проблем у нас например не возникает мы собираем до метрик очень много но в этом определенный проблема нет так как мы не являемся конечными собственным потребителями этих же метрик каждая команда просто для себя лично все это надо ним и а мы уже более верха уровневые как бы срезы снимаем и можем говорить не о каком-то внутреннем поведение сервиса да а вот прям самым-самым верха уровне вам и по верха уровнем метрикам определяем все ли хорошо с этим сервисом и в конечном счете с монолитом с нашим потому что там можно еще просто быстренько вот вы сказали что вы там предоставляете шаблоны для разработчиков чтобы они могли эти метрики отправлять а есть у вас какие то ну может быть внутренние может быть и внешние ну скажем так наставление напутствие для разработчиков что вообще писать то есть ну вот пришел к разработчикам знаю джун или кто то да и вот ему говорят на пишет какую-то функцию какой-то код а еще надо по метрике думать и вот есть ли какой то вот здесь правила может быть какие то у вас может быть выработаны и практики что писать что не писать в каком количестве и так далее вообще каждый разработчик для себя решает сам что ему там писать что не писать мы со своей стороны говорим о том что необходимо замерять все взаимодействия внешние да надо обязательно смотреть на размеры ваших очередей буферов вот и в принципе на калинина на жизнедеятельность вашего сервиса мы количество запущенных процессов и пытался то есть по идее чем больше и структурирование чем у чем более детально метриками покрыт процесс проект тем ребятам после этого лучше вот пожалуйста спасибо за доклад на круто очень вопрос такой не была раскрыта та сторона которая вот о том когда наступает состояние и понимание того что что-то идет не по плану это вытекает в какой-то alert да потом эти состояния они где-то накапливаются где-то обрабатывается вот в какой системе каким способом вы это делаете компонентом которые отвечают у нас за лифтинг является майор в море есть различные триггеры эти триггеры так скажем сгруппированы в определенной группы и есть триггер и которые являются критически важными для всего проекта так когда приходит олег по данному триггеру мы скажем так отправляем сообщение в флаг в наш корпоративный messengers лак после чего в этом же мессенджере мы запускаем ну как бы мы запускаем команду для бота которая поднимает команду для бота запускаем которые грубо говоря отправляет запрос на проверку всех под систем там верха уровнях всех наших под систем в нашем в авито то есть это все эти базы различные на эскель штуки и там еще ряд определенных проверок после чего бог проверяет как себя чувствуют различные наши системы и говоришь ну например в такой-то системе обнаружена проблема ну например в сети и вот данную информацию он пишет он публикует в комментариях комментариях по татарскому то есть в с лаки есть возможность под сообщениями в сообщении писать комментарии вот мы всю вот эту информацию дополнительным напишем прям туда количество различных ошибок какие ошибки мы за дтп или имеется ввиду идут например 500 вот они 500 их целая гора мы идем в хранилище логов берем за последние 5 минут количество скажем так отфильтрованная и отсортировано и количество ошибок какие мы сейчас получаем и эти ошибки мы публикуем в комментариях к лету a500 их ну понятно то есть какой-то предварительной автоматизировано анализ да да да вот есть какой-то дашборд в котором есть какой-то отчет срез текущего состояния этих проблем чтобы кто-то с ним tab садился и разбирался и соответственно итоги этих разборов что они из этого даже гордо потом уходит но у нас по инцидентам заводит слср и вот и это наверное не в душ борьбе мы видим а в jiri скажем так да в жире создает своего сары в лср и публикуется информация о инциденте в том числе туда прикладываются графики время начала и время конца инцидента вот и собственно туда же прикладываются различные логе туда прикладываются метрики сервисов которые за эффекте ли но какого-то единого дизбанда в котором бы у нас написано было все окей у нас как бы нет у нас есть вот верха уровне уэста то вы по которому мы смотрим на с целостная как бы поведение общину вот нашего монолита это еще вы упомянули систему аномалий detection да у нас есть детектор аномалий но мы его не зовут ансар силе поэтому особого как бы про него я не вижу смысла рассказывать в час и вы захотите а мы не сможем его дать свой да это своя разработка и его суть в том что он принимает в себя поток метрик вот карбон сериалы от него отправляет полный поток метрик как в майру этот детектор аномалий держит у себя окно за сутки по каждой метрики которые него входят и после того как в него это метрика попадает он сравнивает входящие значение с окном с поведением данной метрики после чего он сравнивает его статистическими методами определенными и если все четыре метод или 5 говорят мы используем 5 кстати методов статистики для определения аномалий если 5 методов статистики одновременно говорят что здесь аномалия мы ставим точку аномальную и эту аномальную . мы также пишем графит вы для того чтобы вы могли понять что от вас по метрике там response time есть аномалия вот как бы смысл такой но мы его говорю пока не зовут ансар силе и этот детектор аномалий он актуален только для нашего стаканы место для графита до графита то есть вы его не сможете прикрутить там в другие системы мониторинга спасибо добрый день спасибо за доклад а на самом деле мой вопрос очень сильно связан с предыдущим мне интересно какие вещи вы научились детектировать к примеру понятно что если вы пишете метрики на каких-то событиях у вас бывают спайки это может быть вам не очень интересно а если какая-то метрика вдруг резко с производная 1 начала расти вверх и вышла на новое плато вам уже интересно это событие новым именно в этот момент не смотрели на металлику а ваш детектор он умеет ловить такие вещи имеют сообщать этого дайте настил на это да смотрите тут как бы такой момент что к нам летит 4 миллиона им вы по всем 4 миллиона мы ловим аномалии вот поэтому искать на какие-либо корреляции достаточно проблематичным просто там этих корреляций в единицу времени и сейчас и вообще но я думаю наверное тысяч под 5 каждый каждый интервал времени мы детектор аномалий прикрутили поставили он у нас работает и в основном мы его используем когда например есть например такие ситуации когда без него очень плохо но тип метрик тип метрик он везде одинаковый то есть у нас есть например какие-нибудь api запросы вот запросы в api методы api методов много запросы грубо говоря там тоже как бы достаточно сильно разбиты по чистоте вот и мы этим детектором аномалий покрываем там грубо говоря 5000 методов с помощью ну с помощью а лифтинга по конкретному типу этой метрики вот у нас есть тип метрики такой то мы подписали его на детектор аномалий детектор аномалий рассказывает аномалиях этих api методах конкретный чатик так чтобы мы смотрели аномалии на разрезе вот прям всего стыка наших метрик такого мы не используем это бесполезно хорошо правильно ли я поняла что когда вы по конкретным метрикам сообщаете в конкретный чатик у вас люди которые читают это чатик они не захлебываются от количество аномалий которые были за все верно потому что я говорю во первых для того чтобы сам факт аномалий был подтвержден мы ждем пока все наши методы статистики отработают и скажу что под действительно anomaly 2 способ уйти от ну как бы вот полна спама это количество то есть мы аль артем не первым при первой сработки а при условно 3 то есть если три раза в подряд вектор нормали говорит что на этой метрики аномалий только в этом случае мы отправляем аномальное alert об аномалии в чат я вас поняла а вот вполне возможно еще такая ситуация что у вас не одна и та же метрика но какая-то какое-то семейства очень близки тупо смысла метрик и с бизнес с точки зрения люди знают какие-то инвариантным по эти метрики что примеру они сумме должны сходиться пытались ли вы когда-нибудь детектировать онлайн такие вещи мы для таких вещей используем не детектор аномалий мы используем функции графита которых на самом деле очень много одна из этих функций называется бы и зла и набираешь на это функция которая строит вылезла инфа вашей метрике то есть у вас какой-то метрику не есть какое-то поведение историческое мы берем историческое поведение этой метрики за условно пять дней или семь дней до за какой-то продолжительный период после чего мы берем медиану от ее поведения ну грубо говоря у нас получается 5 метрик метрика за вчера метрика за позавчера метрикам за позапозавчера и вот у нас получается 5 метрик вот этой метрики но в истории мы берем между ними медиану получается усредненная такая метрика без провалов без пиков без вот этого всего и уже с этой метрикой бездной нам мы сравниваем входящие значения прям real-time вот это очень эффективно работает быстро и графит позволяет как бы накручивать эту функцию на огромное количество этих метрик поэтому для всяких бизнес новых штук мы в основном всегда используем именно данные данную функцию бы зла и набираешь она показывает отклонение твоих исторических данных от нынешних но она позволяет а реагировать значение 1 метр и нет а вот да вы так как эта функция графита она позволяет работать вам с любыми агрегатами любыми агрегатами любыми результирующем и функциями ну грубо говоря сумма вас например давайте так у вас миллион пользователей все отправили по метрике у вас миллион метрик вам неинтересно смотреть на аномалий в каждой метрики вот миллион метрик в каждый может быть какая-то аномалия грубо говорят вам может прийти там пять тысяч каждый раз оповещение то что у вас аномалии вам это неинтересно вас интересует одна результирующая которое будет являться суммой этих миллионов и которые в конечном счете должна быть ну похоже на одну единственную метрику результирующий и вас интересует аномалий конкретного результирующий вы берете этого результирующий метрику вешаете на нее бы зла и набираешь и у вас ну как бы есть она анализ всего вот этого потока событий на историческом промежутке хорошо спасибо а подскажите пожалуйста как быстро сама зарабатывает она маленький трактор и бывал ли такое что вот люди думают что все хорошо а но мы люди так то там задержался с ответом на час когда все уже ушли домой я не заметил что все упало они конкретно аномалия детектор мой вот в данном разрезе не используем вызваны используем breeze line реагируют реагирую достаточно быстро в нашем случае минуту отлично спасибо здравствуйте спасибо за доклад не интересует такой момент вот и переход от какой-то существующей например той же кабаны сбора статистики переход на вашу систему насколько это сложно может быть есть какой-то там гайд или что-то такое сбор именно метрик да есть гайд это вот запустить ту штуку которую я показывал в докер compose вот попробовать в нее что-нибудь подписать попробовать распилить ваши логе которые вы отправляете в киба ну на метрики и посмотреть что у вас получится собственно все достаточно просто но у вас использовал скиба нам дал им еду мы используем дальше как бы икебану ну просто ну используемые уже не так часто наши ребята некоторые любят новые технологии некоторые не любят мы к чему не заставляем и не принуждаем если вот они прям кайфуют от использование киба на мы как бы не бегаем за ним и не говорим нет нет никогда не в коем случае то есть у нас есть и логии у нас есть метрики более того мы логе сейчас впишем вообще в house для того чтобы их дольше хранить быстрее читать вот это все и еще такой вопрос ну а вот вы сказали чем больше метрика тем лучше на до какого как бы ну какой то предел то есть ну логировать вообще все в метрике ну например если я там дотошные разработчики написал там сервис я все метрики собираю насколько это как бы эффект всю систему и у вас первый не знаю на сколько это может эффект всю систему не знаю насколько большой ваш все естественно в рамках здравого смысла должно происходить если вам необходимо собирать эти метрики вы получаете от них какой-то профит они вы для вас полезны значит их надо собирать если они бесполезны они просто мусор то естественно как бы смыслу нет что почти большой также здравствуйте спасибо за так а вот я увидел вас что вы отправляете события поводу даты и так ну собственно понятно чем от связано но интересует вопрос вы какие-то замеры производительности проводили ну то есть либо это сразу такая созданный был выбор либо вы там сравнивали и 2 сразу же вопрос и дипе что вы делаете с потерянными пакетами они когда учитываться статистика верно эти не мерить но поподробнее мысли можно посмотреть юдифи был выбран не просто так мы не хотим тратить ресурсы от сервисов до от наших сервисов от монолита от паха пышного кода на то чтобы в тисе пи вы совать каждый prevent так поэтому был выбран youtube и и мы не хотим защитить наш пруд от того что у нас отвалился наши станции агент поэтому и т.п. для того чтобы понимать что данная статистика она валидная мы собираем метрики по количеству дрогнут их юдифи пакетов на хостах если на каком-то хвосте количество и типы пакетов там больше определенного лимита что мы говорим что вот конкретно с этого h100 во-первых на него надо обратить внимание во вторых скорее всего метрики которые он присылает будут неточными но по теории больших чисел когда вы собираете 4 миллиона в секунду различных событий если вы потеряете оттуда тысячу как бы мало чего изменится до если вдруг это скажем критичные событие ну там какие-то метрики response time там какое-то безумное для если если вы их теряете если это какой-то response time в 10 секунд если это супер критичные метрики отправлять их сразу в графит если это какие-то метрики которые вы отправляете в статье то как бы я говорю по теории больших чисел хотя бы одно событие с response time там выше 10 секунд она долетит и вы об этом узнаете вот новый большим опирайтесь на большие данные посуда мы опираемся на то что у нас данных многое нам как бы этого хватает и также мы опираемся на то что у нас не приходят alert и о том что youtube и дропается на хостах спасибо здравствуйте спасибо нет не часто здравствуйте спасибо за доклад вам мы проходим с вами очень похоже путь все очень похоже на наши но зачем я не услышал вас ничего просрётся поговорили вы отправляете и продуктовые метрики тоже до туда что сергей продуктовые метрики тоже отправляются и смотрятся через эту систему мониторинга такие как например регистрации да вот соответственно у бизнеса возникает вопрос а да кто входит войти регистрация мужчины женщины там возраст соответственно выбирает опишите тело метрики а это среза то так же само отправляется туда да конечно конечно да там предположим запросы регионы вы можете все у кого укладывать в имя ну это событие и отправлять его мы его агрегирует вы получаете среза спасибо за доклад небольшой вопрос по месту про метался вот в этой всей схеме товар mit uns получилось что он так в общем сторонке и метрики которые он производит в общем-то в графит потом преобразуется в его формат и в аллерс тенге он не участвует можете рассказать что давайте расскажу в два слова про parameters мы используем примет его столько для мониторинга облаков вот только инфраструктуры куба да потому что в к вернется из коробки предоставляется целый набор метрик который он отдает очень успешно применяются prometheus их успешно скрипит и собственно внутри себя хранит так как у нас есть как бы уже хранилище для метрик а у прометея с этим есть определенные проблемы мы как бы решили что мы будем из всех кластеров губернатор отправлять метрики в условный такой как бы ноту федерации так много федерации отправляем эти метрики после того определяем какие из них критичные и эти критичные уже отправляем в графит мойра умеет ходить за данными мойра сама себе графит но при этом она умеет ходить за данными в графит зад в другой сторож и когда ей надо предположим построить alert и по метрикам prometheus а которые там хранятся в грубо говоря в своем формате с учетом лейблов вот этого всего то мойра идет в приготовился говорит ноль в графе ты говорить дай-ка мне вот этот вот запрос метрики по такому-то запросу граффити и отдает она его сравнивает своими трудами и allure тит то есть с хранилищем графита у вас было намного меньше проблем чем с хранилищем prometheus а дело в том что у нас хранилище графита и графит уже есть давно а примите вас это скажем маленькая часть какой вот какой-то инфраструктуры которая вот ребята сказали что мы хотим его вот нам пожалуйста дайте мне пожалуйста далее точнее сами себе пожалуйста поставили но потом возникли у них различные вопросы на которые мы нашли вот такое решение которое устроило всех во-первых мы храним истории мы умеем allure think мы как бы отказоустойчивый вот в граффити долгосрочные метрики у вас хранятся ну да два года говорю два года хранятся метрики все верно они не агрегированные вот те кметы они естественно проходит определенные стадии рула по когда они схлопываются то есть мы храним 30-ти секундные интервалы в течение 35 дней для того чтобы строить бы и celine и корректно да потому что там 5 и 7 недель 5 5 недель и после этого мы данные с хлоп его им уже до пяти минут и храним вот 5 5 минутными агрегатов агрегатами но это даже так грубо говоря агрегатами 5 минут нами храним в течение двух лет схлопывается по времени а по инстанциям номер во что-то до нового вечно мы берем говоришь какой то среднее значение иногда берем сумму в зависимости от метрики в графит позволяет различные правил лапу применять к различным типам не track я понял спасибо пожалуйста"
}