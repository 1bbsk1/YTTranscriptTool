{
  "video_id": "JbV5PMoV0Hw",
  "channel": "HighLoadChannel",
  "title": "RePlay — библиотека построения рекомендательных систем / Алексей Васильев (Сбер)",
  "views": 541,
  "duration": 2334,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "совсем еще раз привет Спасибо что пришли Так давайте начнем немного о себе Я руководитель группы рекомендательных систем в лаборатории искусственного интеллекта Сбербанка преподаю в geekbrance еще Ну тут можно почитать какую-то информацию про меня чтобы было примерно понятно что делает лаборатория с Берта большой Да мы пишем статьи делаем некоторые инструменты для dsf вот помогаем другим командам так для тех кто не знаком вдруг с рекомендательными системами или слабо представляет Давайте такая маленькая водная то есть вокруг нас на самом деле много где встречаются рекомендации любой практически сайт их содержит YouTube на дает вам подборку видео магазин по заказу еды доставки или там какой-нибудь звук Сбер звук или Пикабу да то есть все это содержит рекомендации и предлагает вам на основе например вашей истории просмотров посмотреть какой-то новый контент или купить какие-то новые товары Давайте посмотрим Какие особенности есть у задачи рекомендации чем она отличается от задач например классификации или там регрессии как правило у нас все-таки много пользователей много это там тысячи миллионы может быть и больше там сотни миллионов иногда бывает товаров тоже достаточно много То есть это не 5 10 товаров а тысячи тоже миллионы и как правило взаимодействие значительно меньше чем Ну вообще всех возможных пар юзератов потому что пользователь не может посмотреть Все товары за раз мы не можем их показать просто также одна из особенностей этой задачи это мы должны показывать пользователю несколько объектов а не какой-то один Ну чаще всего все-таки это там 5 10 может больше еще в зависимости от задачи могут присутствовать только положительные например взаимодействия Да если у нас задача им плесит рекомендации То есть когда есть только какой-то отклик пользователя То есть у нас можно сказать только положительные нету отрицательного отклика например пользователь что-то купил или что-то посмотрел и нам непонятно то есть это отрицательный положительный То есть это у нас все считается положительным откликом Какие сложности Да будут при создании Ну давайте представим что вы DS и решили создать свою рекомендацию на самом деле многие доцентисты не занимались такой задачей и могут быть некоторые проблемы Ну первая проблема это понять что у вас задача рекомендации да то есть Когда вы ставите какой-то рейтинг явно фильму или не знаю может куплена еде вам нужно правильно рекомендовать на основе оценок им плесеть рекомендации Когда у вас есть отклик пользователя то есть его какие-то действия может быть это продолжение последовательности например Вы слушаете музыку да И хотите на основе там первых 10 композиций которые пользователь сегодня прослушал порекомендовать следующую также одна из проблем Это наличие множества библиотек алгоритмов То есть Вам как-то нужно выбрать с помощью чего вы будете рекомендовать библиотек правда много и в каждой может быть несколько алгоритмов Когда Вы начинаете их сравнивать у вас тоже могут быть проблемы Но первая проблема что каждая библиотека может возвращать данные в разном формате например одна Может возвращать формате numpi другая формате панда там кто-то Спарк и все надо преобразовывать разные названия столбцов типы это не так просто придется все это как-то оборачивать в обертку также у разных интерфейс с каждой библиотекой придется Ну просто познакомиться чтобы вообще уметь ей пользоваться Ну и значит вам нужно каждую библиотеку документацию в ней прочитать так следующие сложности предположим предположим вы в общем поборолись предыдущими да И теперь вы решили ну выбрали какой-то стек библиотек может быть поняли как их сравнивать между собой вот Теперь вам нужно понять Как делить данные и как их предработать да То есть вы можете ваши данные значит там как-то ограничить например да то есть если у вас оценки есть от одного до пяти Возможно вы хотите убрать маленькие оценки и оставить Только оценки хорошие чтобы фильмы например рекомендовали столько те у которых оценки больше четырех также важный вопрос Как разбить на трейн тест дальше через несколько слайдов мы посмотрим какие есть варианты разбиение но вариантов достаточно много То есть это может быть по времени случайно может быть по пользователям как-то следующий Да тоже сложный такой вопрос Из какого множества делать предсказания объектов Дело в том что если вы будете делать предсказания из множества всех объектов Возможно это займет очень большое время и бывает что берут например для валидации положительный объект И множество каких-то остальных объектов и пытаются понять положительный объект находится в топе или нет но это конечно будет работать быстрее но непонятно а правда ли будет правильная Метрика если вы сравниваете с полным сравнением с честным а следующий следующая проблема да То есть вы можете выбрать прекрасный метод Он наверное будет показывать классные метрики но будет совершенно не применим в проде Ну например у вас очень много данных и ваш метод просто работает Не знаю больше суток понятно что если Вы каждый день пытаетесь обновить вашу платформу например то будет не очень хорошо так и Последний пункт в этом списке это какие метрики собственно использовать для сравнения и как именно они считаются метрик в рекомендациях достаточно много И как ни странно считаться они могут тоже по-разному я имею ввиду одна и та же Метрика может иметь разные формулы На прошлой конференции rexis мы подавали статью приняли Да она как раз говорила о том то есть мы брали некоторые инструменты рекомендательные в которых есть естественно метрики вот список метрик верху каждой таблички указан и пытались сравнить а Правильно ли точнее неправильно насколько одинаково считаются эти метрики список библиотек которые мы сравнивали вот Ну например в нижние таблички слева и а видно что только две метрики есть присяжен рекол которые все понимают одинаково то есть считают по одной формуле остальные метрики могут отличаться на порядок Ну давайте пример какой-нибудь простой но вот хитрейт есть Метрика для рекомендации довольно простая Метрика хитрейт обычно считается для каждого пользователя это единичка если мы угадали хотя бы один объект который пользователь кликнул и Но если ни одного объекта не угадали но в некоторых библиотеках в данном случае в одной библиотеке Да это считается не как индикаторная функция попадания как количество попаданий и дальше усредняется по пользователям ну такие же проблемы могут быть с другими метриками видно что значение отличаются самая большая проблема с метрикой для рекомендации она вынесена в отдельную таблицу оказалось что Существует несколько рокоуков для рекомендаций как бы какие-то библиотеки называют рока окон немного разные вещи в принципе дело даже не только в коэффициентах формулах концептуальном обозначении рукавука где-то есть вот берут просто все рекомендации для всех пользователей в одну кучу считают рукаву как для классификации второй вариант для каждого пользователя посчитать рок-аук например и потом усреднить для всех ну то есть это концептуально разные вещи Ну тут в общем видно да что могут также на несколько там несколько раз отличаться значения и из названия метрики совершенно непонятно как она считается Вот это очень важно все определять Когда вы сравниваете библиотеки между собой крайне не рекомендуется использовать метрики разных библиотек для сравнения подсчет метрики Я имею ввиду на этой кстати конференции 21 года это в прошлом году это была единственная статья от России в этом году от нас тоже принята статья на конференцию 22 которая сейчас идет и статья новых вот из всего предыдущих из всех предыдущих проблем которые мы с вами обговорили Да можно предположить что наверное лучше сделать какое-то решение которое эти проблемы устраняет Ну например сделать какой-то единый фреймворк в чем плюс такого подхода у вас будет единый формат данных то есть не надо какие-то конвертеры делать для разных алгоритмов естественно из-за того что у вас единый Интерфейс это увеличенная скорость разработки согласованность тут измерений написано ладно согласованность изменений измерений тоже да то есть метрики у вас будут считаться одинаково для каждого алгоритма и еще Последний пункт такой бонус Вы можете более сложные сценарии использования делать не только там какой-то один алгоритм до проверять а какую-то связку алгоритмов какие были Ну и сейчас точнее Какие существуют фреймворки для рекомендаций здесь есть некий список и внизу год когда появился этот фреймворк ну в открытом доступе про наш фреймворк он сам внизу реплей Это скорее первый коммит когда он был просто для сравнения точнее для понимания что когда мы начали писать эту библиотеку Ну вот из того что здесь представлено был только МС рекомендорс и практически не было никакого фрейворка другого и были еще множество библиотек отдельных которые можно использовать и у которых были те проблемы которые я говорил раньше Как можно сравнить фреймворки между собой да то есть понять какой лучше хуже Ну как какой вам подходит то есть Возможно даже какой лучше хуже такая неправильная Метрика что ли Да это какой вам подходит наиболее правильно то есть Первое это количество различных моделей метрик для сравнения способов разбиения данных То есть другими словами количество каких-то вариаций которые вы можете проверить и использовать при построении рекомендации второй немаловажный фактор это простота использования опять же если у вас слишком сложный какой-то интерфейс наверное многие пользователи не смогут этим воспользоваться а третий пункт это может ли ваша библиотека работать с большими объемами данных То есть например если вы просто исследователи хотите написать какую-то статью Да и проверять она игрушечную дата сайтах возможно вам не нужно чтобы ваша библиотека прямо на больших объемах данных работала и достаточно каких-то открытых стандартных дата сетов для использования это важно работа в распределенной архитектуре но собственно насколько это связано с предыдущим пунктом насколько ваша библиотека может быть масштабируема если она у вас не работает в распределенной архитектуре Ну значит если данных много То вероятно будут проблемы какая-то придется решать Отдельно Ну также есть пункт необходимости GPU для использования алгоритмов начать алгоритмов это рекомендациях нейронки может ну естественно работают быстрее у всех есть У кого-то наоборот вот это все тоже может влиять на выбор соответствующего Да теперь расскажу про наш про нашу библиотеку реплей Какая Мотивация была для создания Ну первое Это для бизнеса да то есть делать какие-то быстрые прототипы решать реальные задачи на больших данных на распределенный архитектуре но То есть если вы начинаете строить рекомендации вам нужны какие-то для начала без Лайна например построить понять в принципе насколько у вас можно построить нормальную рекомендацию что от чего вообще отталкиваться ну либо сравнить существующий Например если у Вас уже есть какая-то Понять насколько она далека от безлайнов насколько она лучше или может быть хуже соответственно мы используем Spark в нашей библиотеке то есть Все вычисления проходят через него для исследователей это возможность сравнить и поэкспериментировать с какими-то новыми подходами Ну то есть вы можете свой алгоритм также встроить Ну или отдельно можно сначала его как-то реализовать на коленке но сравнить с помощью там наших метрик например Ну и для того чтобы было относительно просто пользоваться мы используем питон плюс простые интерфейсы и подробная документация Ну по план стандартный наверное для большинства задач эмэльных то есть сначала подготовка данных фильтрация Ну вот эти пункты в смысле они есть встроены в библиотеку там некоторые функции для подготовки данных фильтрации генерации признаков есть кодированные идентификаторов Ну то есть по факту там индексирования да то есть каких-то сложных идентификаторов в диапазон от 0 до какого-то числа дальше разбиение данных обучение модели оценка качества естественно и есть подбор гиперпараметров автоматизирован этот процесс и сравнение моделей и выбор Лучше давайте подробнее разберем что есть подготовка данных включает в себя преобразование естественно так все нас паркета переименование некоторые столбцов конвертация типов плюс можно если это необходимо профильтровать по дате релевантности возможно число взаимодействий например убрать холодных пользователей и построить для теплых пользователей да то есть вашу модель кодирование идентификатор пользователя объектов Но вот внизу как раз пример показан то есть какие-то допустим имена Иван Алексея до переводим просто в номера 12 также генерация статистических признаков по Логу Ну там популярность число оценок и так далее Какие есть варианты разбиения с вами обсуждали Да что могут быть разные есть вариант случайно подайте да то есть ну честно говоря самый правильный если у Вас все-таки от времени что-то зависит это конечно подать по фиксированной дате отрезаете пользователей Все что до обычно на этом обучайтесь все что после на этом валидируйтесь по истории пользователя вы также можете разбить как просто выбрать долю какую-то для каждого пользователя долю объектов которые вы откладываете в тест и это может быть опять же случайные объекты либо какие-то в конце его истории Также можно еще делать разбиение по пользователям в целом да то есть часть пользователей которых на которых вы обучаетесь остальных вы проверяете их в принципе ваша модель случайные на самом деле разбиение тоже Возможно если ваши данные они просто могут не зависеть от времени Ну либо это какой-то небольшой Горизонт событий где-то не так важно может быть Какие модели встроенные в нашу библиотеку Ну первое это не персонализированный алгоритмы например попрек Да довольно неплохой line который иногда довольно трудно побить Ну конечно у него есть проблемы в плане разнообразия но тем не менее с ним тоже стоит сравниться также есть да Рандомные модели разные есть классические коллаборативные модели Ну наверное многие знакомы с ils item knn есть также Slim ассоциативное правило но есть несколько нейросетевых моделей здесь их Ну не так много это не рекламиративная фильтрация моль твое вордвек но еще Вот реальная модель dpg это вот как раз сейчас тестовый такой вариант мы исследуем как она работает на некоторых задачах на самом деле Почему не растевых моделей допустим не так много если кто-то знаком опять же с конференцией то пару лет назад была такая веселая статья о том что не сильно то мы продвинулись рекомендациях за последнее время и там сравнивались нейросетевые модели с классическими оказалось что если правильно сравнивать то часто классические модели превосходят более-менее показал неплохие результаты многие сетевые модели оказались не супер Какие есть варианты предсказания предикта да то есть мы с вами до этого рассматривали скорее задачу рекомендации объектов пользователям да то есть это топка объектов также Вы можете просто оценивать пары юзеррайтом какие-то заданные заранее и у вас будет релевантность для них а также вы можете естественно решать задачу iten to item то есть показывать похожие например объекты на заданный Но это есть Да не у всех моделей но часть модели это может делать метрики давайте метрики рассмотрим какие есть метрики это значит первые метрики качество вот вверху Да это метрики такие простые скорее метрики точности то есть хитрейт присяжен рекол есть метрики ранжирования мрар dcg это важно естественно но также необходимо оценивать частые метрики разнообразия вот я приводил пример когда у него может быть отличные метрики качество то есть будет прямо высокое значение но разнообразие например Это покрытие доля короче объектов которые в принципе показываете пользователям Конечно будет близко к нулю другие метрики разнообразия Они показывают скорее насколько ваши рекомендации для пользователя Ну скажем так отличаются от например без Лайна насколько он их не ожидает увидеть насколько допустим они отличаются от попрека тоже важно да то есть пользователя хорошо бы удивлять Потому что если пользователь ходит например в магазин и покупает молоко вы ему опять рекомендуете молоко Наверное он вам спасибо не скажет Я и так знаю что можно купить молоко и хлеб Наверное если вы ему что-то интересное что ему понравится новая порекомендуете Он будет рад больше чем стандартным рекомендациям для подбора гиперпараметров Мы встроили optune у нас есть метод optimize есть заранее заданные границы параметров для оптимизации можно передать какие-то свои Если вы хотите в определенном диапазоне по подбирать там соответственно все параметры имеют разные скажем так тип подбора например там логарифмическая шкала или просто Линейная Вот все это тоже оптимизируется также у нас есть пара сценариев то есть сценарий это такой пайплайн из нескольких модулей Ну то есть несколько алгоритмов по факту используется первый простой сценарий это Full Back сценарий Когда вы дополняете просто предсказание основной модели какой-то базовой моделью Например если вы пользователю не можете холодным предсказать что-то можно дополнить допустим популярными рекомендациями или там случайными например Таким образом у вас будет предсказание для всех пользователей и в нужном количестве другой вариант это двухуровневый сценарий как раз картинка справа да то есть у вас есть какая-то модель первого уровня она достаточно простая которая отбирает кандидатов больше чем Вам необходимо показать модель второго уровня она переранжирует этих кандидатов и дает нужное количество рекомендаций на втором уровне мы используем градиентный бустинг для в частности сейчас вот мы работаем над тем чтобы в качестве второго уровня строить другую разработку нашей лаборатории это автоэмэль Light of tml может быть кто-то слышал про неё Она недавно тоже выпущена на Спарки Поэтому в общем-то должна гладко встраиваться так Давайте немножко Кода да То есть как это все работает значит Ну первое Так мы используем Спарк нам нужно сессия очевидно нас парке да это все может работать как на кластере так и на локальной машине первый вариант опять же потестить взять просто базовую сессию которая у нас зашита с какими-то стандартными настройками Вот первый блок как раз об этом второй вариант Чуть более кастомный вы можете несколько параметров настроить в этой сессии и тоже в общем-то ее вызвать Ну и третий вариант просто можете свою сессию объявить которая вам нужна там она может быть как кластера так локальная с каким-то своими настройками дополнительными и также передать ее в некий стоит где любой практически объект может эту сессию доставать и обращаться к ней пример предотвратки параметров то есть здесь вызывается некий класс даты препарата в котором в общем-то вы в данном случае происходит некая переименование столбцов и конвертация типов там случае временных временного типа также при доработке как я ранее говорил можно сделать фильтрацию данных Ну например можно оставить только релевантности допустим если в данном случае этому виленс Да мы хотим обучить модель какую-нибудь типа ils например или какой-нибудь такую для решения задач У нас есть экспрессии данные Давайте выкинем плохие оценки оставим только хорошие будут это будет потом единичками допустим четверки пятерки и дальше решаем задачу Для этого нам нужно отрезать данные пользователям с плохими оценками вот мы их собственно и отрезаем вот этой функцией фильтра от рейтинг следующий пример Да это мы можем также фильтровать по датам но очевидно что во многих задачах могут вкусы пользователей меняться Ну допустим вы смотрите фильмы есть какая-то информация не знаю о просмотре ваших фильмов допустим с детства Ну наверное в детстве вы смотрели мультики А сейчас смотрите боевики например ну наверное странно вам снова советовать мультики вот поэтому стоит как-то отрезать актуальный период да то есть вот здесь можно отрезать данные допустим старше какой-то даты про кодирование Да я тоже рассказывал то есть для того чтобы вообще ваш алгоритмы работали корректно вам придется Ну многие из алгоритмов большинство Наверное они используют вот такую сплошную нумерацию от нуля там до n вот вам естественно нужно конвертнуть ваши идентификаторы реальные вот такие идентификаторы числовые Ну потому что например там какой-нибудь LS до вас там есть Матрица которую вам нужно разложить Ну допустим какие-то имена пользователей не очень эту матрицу подойдут вам нужны все равно какие-то соответствия разбиение данных да то есть про них я тоже рассказывал да то есть получается у нас там есть много разбиение но здесь довольно много параметров есть то есть вы можете выкинуть холодных пользователей или холодный айтем если ваша модель в дальнейшем их не может как-то использовать также можете отложить определенное количество атомов тест для каждого пользователя как в данном примере и взять определенное количество пользователей на которых Вы хотите проверить чтобы на всех пользователей не проверять Это потому что это может занять довольно большое время Ну также Да тут есть некий шаффл случайно или подать вы отбираете данные здесь пример разбиения Ну давайте посмотрим как простая собственно рекомендация создается вот здесь просто айтом кнн практически все алгоритмы выглядят также я имею ввиду их использование то есть вначале вы создаете сам рекоммендер объект 3 комедора Да там у каждого рекомендара естественно свои параметры Но дальше когда вы вызываете Фит вы передаете туда какой-то Лог возможно печи юзера айтмов и вызывайте предикт Придите просто то количество объектов которые вы хотите показать Да это все пример задачи для рекомендаций топ объектов для пользователя Ну собственно передаете тех пользователей кому хотите показать и возможно если это необходимо фильтруйте уже просмотренные объекты каждому пользователем Прошу прощения оценка качества для оценки качества У нас есть тоже специальный класс здесь можно сравнивать как множество множество метрик модели так и в каждой метрике Вы можете выбирать разный к для сравнения Но вот в частности здесь 4 метрики используются и вот например по хитрейту У нас есть два значения к для сравнения в общем-то добавить какую-то модель для сравнения довольно просто просто вызов функцию внизу как раз показан результат выполнения да то есть у нас Вот как раз пять разных значений метрик оптимизация параметров вызывается Ну как я уже рассказывал optune просто вызываем оптимайз Передаем опять же основной критерий для сравнения в данном случае это Метрика ncg Количество попыток в параметре баджет И если это необходимо границы в которых мы ищем параметры если мы их не передали то будут использоваться базовые границы которые заданы в каждой модели Ну в конечном итоге вы получаете в результате Best params то есть при которых ваша модель показала наилучшее значение вот это вот метрики которую вы оптимизируете же в данном случае как я уже до рассказывал до этого в классе эксперимент Вы можете сравнить несколько моделей Ну и вот здесь вот сравнивается просто какое-то кнн с подбором Точнее с выбором 100 соседей и оптимизированный видно что метрики стали получше то есть после вызова вот отсюда мы получили лучший набор параметров и теперь собственно можем использовать его например для построения вашей рекомендации Как получить рекомендации Ну как и в стандартных функциях библиотеках и мыльных просто вызвав предикт вот здесь видно юзер мальди и релеванс то есть у вас отсортировав по релеванс вы получите для каждого пользователя необходимое количество объектов Ну опять же в данном случае указано 10 на экран выведено всего две Иначе просто бы не влезла так второй вариант как я также рассказывал до этого это решение задачи релевантность для пар юзера этом то есть если у вас есть изначально какие-то пары объектов и пользователей вы хотите просто понять как их оценить да то можно вызвать тогда функцию при диктарс и только для этих пар будет посчитаны релевантности кроме естественно вывода Когда Вы получили модель уже подобрали параметры естественно надо сохранить также Ну естественно у нас есть эта загрузка и сохранение в общем-то все довольно просто вызывается некая функция лот и естественно кроме модели вам придется сохранить и индексы который конвертит ваши ваши идентификаторы в числа вот Ну точно так же все работает ты в обратную сторону Так ну этот краткий такой экскурс В общем все скачать можно по ссылке через пип ставится пип-инстол есть значит на пайпе ссылка в github Ведется разработка документация тоже ссылка Если у вас есть доступ к приедет там это всё кликабельно в гитхабе Да это всё продукт Open Source в самом начале забыл про это сказать это очень важно и мы с вами рассматривали на самом деле Только опенсорсный фреймворки конечно есть много закрытых платных но про них трудно что-то сказать в плане внутреннего устройства также внизу слайда можно видеть другие разработки нашего центра это лайтов tmlood они также доступны в githubby В общем тоже предлагаю ими воспользоваться почитать про них вот ну и слайд для оценки докладов наверное все спасибо да Спасибо Лёша очень интересно Здорово принципе любой может прийти попробовать попробовать поучаствовать по контрибьете тоже Поэтому открываем квесты не забываем не только пишем гадости вышли Итак Если есть вопросы поднимайте руки Давайте запоминаешь лучше вопрос как обычно Спасибо за доклад Меня зовут Марк работа ру планируете или вообще продавать как сервис клауди например наподобие персонала предполагается что пользователями будут какие-то относительно небольшие компании например которые не могут себе позволить допустим сейчас и по метрикам неожиданности они также вызываются как и классические Да примерно так же в некоторых при инициализации нужно передавать дополнительные параметры Например если вы называете метрику нужно передать какой-то базовый рекомендации его результаты чтобы с ним сравнивать понял спасибо так был вопрос слева молодой человек Ага давайте по центру Алексей спасибо я зовут Сергей пара вопросов первое все алгоритм рекомендации которые вы демонстрировали там реализованы библиотеки вы реализовывали их с нуля либо брали какие-то библиотеки где они уже реализованы смотрите часть алгоритмов например есть в парке реализованный да то есть мы сделали Просто обертку над ним часть алгоритмов мы реализовывали сами как бы есть 50 на 50 OK пользовались остальное вы переписали с нуля Ну да тем что есть парки чтобы был похожий интерфейс сами алгоритмы на тему писали на носи или мы писали их используем парка просто питоновские как правило интерфейс Я имею Скоро у него работать не растевые модели написано на торце окей да это был еще один вопрос На чем вас не растет Ну вот век Он есть в парке Да он с парковкой реализации соответственно Окей и вопрос тогда по нерестим моделям если знакома с селфи в sequation это нейросеть на базе Трансформеров которая продолжает последовательность но не как бы самый лучший результат по сравнению с со всеми другими моделями в данной задачи планировали её включить вашу библиотеку или нет да смотрите например в том году по-моему была на конференции тоже Алексис доклад от NVIDIA там как раз Мерлин там рассказывался Мы с ними сравнивались да то есть пока ещё не включали Да это библиотеку вовнутрь но в зависимости короче От данных оказалось пока что наших тестах на некоторых сайтах что не все однозначно с ними тоже Там же есть общий бенчмарк по рекомендателям системам которые строится там на базе например moviance различного объема Ну и как это можно посмотреть что вот проблема в этом большинства моделей То есть почему то есть сравнивают на мой лэнс прекрасный дата сет но часто он отличается от того что есть в реальности Вот это может не работать то есть если вы ваш алгоритм хорошо работает на мой лэнс не знает что он будет хорошо работать у вас на ваших данных есть какие-то бенчмарки по вашей библиотеке ПО реализованному сравнение алгоритмов внутри библиотеки то есть такие какие результаты показывают ваши алгоритмы на ваши библиотеке на бенчмарках Ну какие бенчмарки имеется ввиду тогда есть датасеты точнее есть ноутбук внутри гитхаба где мувилонс то же самое Да сравнивается спасибо можно посмотреть пол request Welcome А так слева Алексей спасибо за доклад выглядит очень классно Вопрос такой смотрели Может быть я упустил смотрели в сторону алгоритмов таких более контент Base там как Lite FM Например подмешивает иногда Да смотрите FM Да смотрели сейчас в планах написать его нормально нас парке сейчас он скажем так встроен для сравнения просто как вот как есть Lite FM используют не очень быстро естественно работает да планируем написать на Спарки по нормальному Да очень круто и тогда последний такой часть пазла если говорить про Production То есть я так понимаю моделька там как-то упаковывается и работает на данных со спарка Как быть в случае пользователей из Cold стартом то есть для их надо как-то хендлить отдельно в продакшене или можно вот типа как-то это завернуть в рамках фреймворка Да смотрите там я рассказывал про двухуровневый сценарий в принципе там можно в эту часть строить Допустим их без коллаборативки условно предсказывать да ну либо отдельная модель строить Спасибо так было три вопроса он человек первый вопрос задавал по центру Так ну и принципе можем еще два три вопроса успеть так пожалуйста еще вопрос возник а у вас есть вторая модель бустингом Да планирует Да я вот рассказывал смотрите есть вот продукт лайтов tml про который вот я упомянул в конце можно слать прям переключить это тоже продукт нашей лаборатории То есть это в общем-то внутри которого основной алгоритм бустинг по факту и сейчас буквально Недавно вышел вышел его версия нас парке планируем его запихнуть туда а вот Скажите будет ли возможность калибровки результатов для того чтобы они были вероятностями или может быть еще модель калибровки сверху пока про это не думали если мы говорим о сервисе который Например если мы законтрибьютим как будет туда транслироваться в сервис Давайте сначала законтрите потом обсудим этот вопрос Спасибо пишите"
}