{
  "video_id": "w3FiubhinYw",
  "channel": "HighLoadChannel",
  "title": "Как мы построили платформу для рассылок перс. уведомлений / Руслан Гилемзянов (ex-AliExpress Россия)",
  "views": 357,
  "duration": 2349,
  "published": "2023-01-19T05:55:17-08:00",
  "text": "всем привет спасибо за представление спасибо что выбрали мой доклад действительно тема моего сегодняшнего доклада как мы строили платформу для рассылок персонализированных уведомлений пользователям aliexpress россия что у нас получилось и какие-то промежуточные этапы которые мы преодолевали на своем пути давайте начнем начнем с алиэкспресс россия во-первых это триста шесть миллиардов рублей джим виза 2021 финансовый год это 35 миллионов пользователей в месяц за 2021 финансовый год и двести одиннадцать миллионов продуктовых единиц товаров за 2021 финансовый год то есть понятно что аудитория огромные нагрузки также большие поэтому некоторые задачи приходится решать различными способами соответственно давайте поговорим что как мы решали задачу создание платформы для рассола кого и давлений давайте начнем во-первых с различных видов уведомлений на aliexpress возможно кто-то из вас пользуется имеет опыт первый тип уведомлений про который я расскажу это системное уведомление уведомление о статусе заказа начисление и списание баллов лояльности информация доставки товара и так далее что такое давление нет таргетинга нет персонализации нет какой-либо отправки по расписанию это по сути обработка данных режиме реального времени на базе паттерна events are young подробнее о нем я расскажу позже следующий тип уведомлений на алиэкспресс это также уведомление наверняка который вы не раз получали это промо уведомление уведомление распродажах и скидках на платформе как правило промо уведомления характеризуются возможностью таргетирования отправки по расписанию но нет возможности персонализации уведомлений и нет никакой потребности в обработке в обработке данных в режиме реального времени достаточно исторических данных и знаний х пользователей следующий тип уведомлений это триггер на и уведомление уведомление о персональных скидках на товары уведомления каких-то просмотренных ноги купленных товаров и так далее нет возможности не таргетирования не отправки по расписанию нет персонализации уведомления и как правило обработка данных происходит как в режиме реального времени допустим пользователь пользователь появилась скидка на товары вы сразу же отправили ему эту информацию так и офлайн до пользователь посещал карточки товаров но ничего не купила мы хотим ему об этом напомнить и следующий тип уведомлений это смарт-уведомления на представленном скриншоте телефона да видно тип уведомлений от как правило рекомендации товаров на основе действий пользователя на платформе есть возможность как таргетирование так и отправки по расписанию и что отличительно есть возможность персонализации уведомлений в этом случае необходима обработка данных как в режиме реального времени до допустим взаимодействие с товаром на платформе так исторически допустим мы хотим использовать информацию о статусе лояльности пользователя на платформе давайте рассмотрим каждый из типов уведомлений в деталях и начнем системных уведомлений во первых для системных уведомлений да допустим будем рассматривать пуше по заказам как уже было сказано мы используем even source на базе кафки events are seen это физик черный паттерн который позволяет вносить изменения в базу данных в том порядке в каком они происходили в системе допустим пользователь создал пользователь создалась корзина instance корзина мы записали в базу данных пользователь купил товар мы записали это событие в базу данных это удобно потому что это позволяет нам впоследствии впоследствии производить аудит системы до аудит информация пользователям какой у него статус данный момент что у него происходило прежде и так далее затем мы говорим о том что мы используем шарди равный по сгрыз чтобы поместить все данные о девайсах более 30 миллионов пользователей на потому что пользователи есть множество разных девайсов у пользователя есть активные неактивные девайсы всю эту информацию нам надо хранить следующий момент что мы пишем в мастер читаем с реплик да то есть используем паттерн команд вере responsibility сегрегация и помнила в особенностях этого подхода сейчас я вам чуть подробнее расскажу какие могут быть особенностям и говорим также что мы используем почеп работку читая выставки патчами и отправляем firebase также патчами давайте чуть подробнее поговорим об опасность особенностях чтения-записи мастер ощущение септик во первых тут надо сказать про такую команду как вакуум тонкий вы знаете что в подписи когда вы производите операцию апдейт или дэвид например строки которые подпадают под данное правило они не удаляются непосредственно сразу же из базы данных скорее помечаются как необходимые к удалению это нужно для корректной работы энди сиссе балдеж инкарнаций контроль затем в тот момент когда эти строки не используются ни одной из транзакций по сгрыз производит очистку вместо используя очистку место используемого данными строками и интересный момент что лог эксклюзив налог который захватывает снова контрам кейт он пишет брать на hotlog возраст узкие только лопну не unlock и это приводит к тому что на реплики лак держится до тех пор пока вакуум не закончится полностью при этом на мастере при конфликтах запросами лог отпускается соответственно для клиентов это downtime то есть инстанций который в этот момент читают из реплик подвеса они сто процентов будут засек чем это будет downtime для пользователей соответственно это не очень приятный действительно нежелательная особенность под колеса для нас да я привел скриншот на котором на форумах под гирс активно обсуждается данная проблема да например есть костыль виде настройки вакуум de fer клина аж до которая влечет за собой ряд других проблем то здесь нет стопроцентного решения вам нужно экспериментировать для того чтобы если вы действительно используете этот паттерн этот кейс понять что вам нужно делать в этом случае как для вас это будет работать лучшим способом следующая особенность чтение с реплика это микро оптимизации на индексах они работают за разные типы утаим на мастере сливе что также приводит тому что у вас вопросы могут на реплики исполняться дольше и хуже чем на мастере разницы можно стегать двух порядков опять же есть обсуждение на форумах если вам интересно есть вопросы по этому может быть судить чуть позже дискуссионном зале и давайте рассмотрим в итоге как это работает все вместе да то есть вот у нас even совсем создается ивенты которая записывается в некоторые evenstar из которого различные приложения ледовый корзины так далее читают эту информацию записывают это все notification топике так называемое и у нас есть два install сюда это pushing персис to persist r получает данные одевайся пользователи сохраняют это все в наш армированный позарез и мы богу что он пишет мастер опушкой при этом ходит пир сестер по ипдо то есть тут еще важно помнить что мы используем также дать тобой пир сервис соответственно пушер пирсе сообщается только по этой и пирсе star соответственно в этот момент считается реплик и затем пушер после того как получил информацию о девайсах и пользователей собрал бочче отправил это все firebase поговорили про системное уведомление давайте теперь рассмотрим как работает персонализация и какие здесь у нас особенности а вверх мы сказали что у нас есть это большая база данных о пользователях их девайсах но мы не ходим при отправке пуша на прямую неё так как это нам создает нежелательный различные побочные эффекты доведя той же самой нагрузки на базу данных и мы читаем информацию получаем информацию о девайсах и пользователей из ходу по и соответственно по чехоев для этого мы переливаем ежечасно наши позы из таблички до соответственно райта hotlog в с помощью флинн k-pop чихаем сейчас посмотрим как это будет выглядеть на схеме в какой то момент времени наши маркетологи создают специальные задания на отправку пашей пользователям наша система каждую минуту проверяет созданные задания и в какой-то нужный момент времени читает данные из коего по пользователям собирает их и в дальнейшем складывать в топике на отправку вот на скриншоте можно видеть пример нашей админ очки система поддерживающие sasa то есть у нас использовать или есть администратор и есть обычные пользователи различными правами у которых есть возможность создания изменения to suck на отправку удаления просмотра состояния to suck включения выключения и так далее кучей фильтров естественно чтобы точно найти нужную задачку соответственно если посмотрим как это работает на диаграмме дата вот у нас есть пользователи возрасте есть right ahead лоб который мы стримим где безе under наверно многие знают про этот фреймворк который позволяет стримить райта hotlog в данном случае и в кафку топики а затем еще один инструмент апачи fling про которые вчера был замечательный доклад считает кафка топики и складывает это все новыми партициями в табличке в apache и hyip уже созданные при то есть по сути каждое новое прочтение да тогда это новая портится в таблице vape чихает который содержит себе весь слепок таблицы в поскольку соответственно суммарно все вместе у нас есть некоторый air флаг эльф лодок который каждую минуту дергает нашу ручку нашей админке проверяет созданные задания на отправку наше приложение к читает hive таблицы с данными пользователями девайсов и складывать все это в очередь а мы помним что как только мы сложили в очередь у нас есть приложение которое читает этой очереди и бочками отправлять пушек мы обсудили возможность отправки пушей маркетологам да но это такие статические пуше то есть статический контент например прамада пошив который мы обсуждали и возникает резонный вопрос а где таргетинга как как у нас реализован таргетинг как отправить пуше необходимой группе пользователей да например мужчины в возрасте до пяти десяти лет увлекающиеся рыбалка а для этого у нас есть своя сидит и сидит эта каста мир do it do it a platform по-моему в прошлом году коллег и за зону был замечательный доклад по их сидит и построенный поверх лик хауса наши сидит и построена поверх также апачи hive и сегмент да мы здесь говорим что сидит и оперировать сегментами сидит эта связка юзера и сегмент айди которая сформирована по различным про вам страна город пользователь статус программе лояльности и так далее и важно понимать что каждый сегмент айди это также новая partition в соответствующей таблички в apache и hyip и какую-то сказано себе построен по мягкой соответственно если мы посмотрим с точки зрения как пользователи как это работает пользователь заходит на карточку товара нажимает добавить корзины корзину и вешали да с помощью той же кафки через различные системы сервис и это попадает в кафка топике откуда их забирает эту информацию fling и складывает в хай в таблице и тихой в таблице уже они они про сегменты да они про а не про то какому пользу какому сегменту пользователя относится и так далее соответственно у маркетологов в этот момент есть админка которая также позволяет делать эти сегменты в юань то есть какой-то набор правил и и так далее соответственно нашу в наш в нашу схему которую мы уже до этого обсуждали добавляется и всего лишь один шаг то есть у нас также вызывает проверяются созданные задания на отправку маркетологами но в какой то момент времени у нас происходит join таблицы с данными пользователей о пользователях с данными о сегментах то есть маркетолог не только указывает теперь информацию об уши да но также указывает сегмента иди а мы достаем нужную партицию из коего joy ним и собираем данные отправляем кафка топики хорошо теперь мы обсудили да у нас есть статические пуше да по расписанию с помощью построенный поверх х его у нас есть таргетинга который тоже построен поверх айва что по персонализации тут важно сказать что у нас есть различные модули персонализации да во первых это видно контент matching модуль затем скоринг модуль и frequency control module то есть это такой pipeline в котором на вход у нас поступает input да например в контент matching модули видно проходят input проходят различные шаги и например получение информации о пользоваться ли получение информации о действиях пользователя на платформе потом фильтрация контента полученного прикол да проверка полученной информации на полноту насколько 1 соответствует действительно тому что нам нужно и некоторые наполнение контента данном случае например если мы получаем пункта war of the наполнение контента это очевидно картинка товара ссылка на товар рейтинг и так далее цена опять затем нас происходит скоринг модуль у нас тут за тепло и на различные модели да вот тут можно видеть что есть разные очевидно модели которые по абэ соревнуются друг с другом за максимальную максимизацию своей метрики да например это может быть опыт райтман модель до которой направлены повышение у понравится модель направленное на повышение себя сити орда conversion rate и click to write и затем у нас pipeline заканчивается frequency control module им это модуль который проверяет так называемой усталость пользователя усталость пользователя да это такой некоторые термин который говорит о том насколько пользователь устал от наших ушей или не устал до то есть пользователь может как сам устать от всех ушей до или от ушей определенного типа так пользователь может устать от определенных товаров рекомендациях до очевидно что если мы например пользователю отправляем в течение долгого времени iphone и разных цветов наверное он бы не очень хотел этого получать да и мы можем попробуйте отправить что-то другое давайте чуть ближе рассмотрим каждый из модулей в отдельности и начнем с контент matching а тут перед нами ставит интересный вопрос пользователь добавил товар корзину как при отправке пуша на порекомендовать товар который наиболее часто покупается вместе с допустим с этой кофеваркой уверен тут действительно могут быть разные сценарии решения этой задачи позвольте мне рассказать как как мы подошли к этому вопросу во-первых рассмотрим бэкграундом скажем что по-крайней мере то как это у нас да у нас данные о товарах данные корзине данная покупка пользователя хранятся в различных базах данных и справедливо во первых как правило этими сервисами до которые так или иначе используют эти базы данных за них отвечают разные команды во вторых у данных бас разные сценарии использования разные требования no response time на куб с и так далее соответственно если мы будем мыслить в терминах что у нас есть несколько баз данных из несколько сервис отвечающих за эти базы вы скажем что для того чтобы нам получить товар на который наиболее часто допустим покупается вместе с кофеваркой нам придется сделать очень много запросов разные базы данных это сходить базу данных заказов найти совпадение покупок отсортировать по частоте по купания да да да обогатить информацию по товарам и так далее много запросов во первых во вторых нам придется взаимодействие с разными командами да если мы допустим положим сервис отвечающий за корзину просто потому что у нас появилось нагрузка на пуш и наверное это бы никто не хотел кажется интуитивно что задача и рекомендации товаров она тесно связан с сопоставлением вообще принципе связей между товарами и пользователями на нашей платформе и исходя из этого можно сделать вывод что под полученную задачу очень хорошо ложится графова язык описания запроса давайте рассмотрим например как эта задача может быть решена на языке апачи гремлин приборка который позволяет как раз описывать на таком оля ну не графики да будем говорить и гремлин гель необходимые нам запрос допустим у нас есть несколько пользователей да это алиса боб и джек которые купили продукт номер 5 но при этом мы знаем что бог и джек до этого покупали некоторые пул товаров и мы знаем общий пул товаров для боба джека до которые они оба покупали более того если мы знаем не только связи между богом и джеком а также между алисой бабы джеком да допустим они находятся на одном уровне лояльности в нашей платформе да мы также можем сказать еще больше да может быть мы можем найти еще какие-то товары и так далее соответственно этот запрос можно одним условно одним запросом это можно обязательно языке апачи кремль им довольны служит запрос причем довольно декларативно понятно что здесь происходит зачем мы это делаем и в принципе мы описываем практически то что мы сказали до этого на языке sql и ложится теперь резонный вопрос да мы знаем что нам подойдет обаче гремлин по наверное теперь данные нам нужно хранить каким-то образом чтобы эффективно с помощью apache и гремлина и доставать и на помощь нам приходит собственная инхаус решение графова я база данных ближайший аналог него fuji использующий апачи гремлин в качестве граф кель ну опять же это немножечко другой коробки льда понятно собственно house решение это часть alibaba клауд если он тоже интересно я расскажу чуть позже про нее вот но всю информацию так или иначе наверное можно найти в интернете для того чтобы у нас появились таблицы в этой графами базе данных данным необходимо экспортировать данные туда и мы экспортируем хай в таблице про которые мы уже говорили и наша база данных обладает возможностью извлечения данных режиме реального времени таким образом получается что рекомендации мы также получаем информацию по рекомендованным товаром до которые могут быть рекомендованы пользователи мы получаем режиме real time соответственно если представить так архитектурно дата мы берем наш апачи fling мы берем наши hive таблицы и переливаем их выиграв таблицы при этом мы можем очевидно делать ник только кастомизация да где то мы можем join каких-то графе hyip таблиц сделать и так далее соответственно мы переливаем это все выиграв где эти данные становятся доступными all times и позволяют нам с помощью apache и гремлин их доставать поговорили про контент матч он подал да и получается что у нас есть на вход input на out put есть какие-то какой-то пул товаров которые может быть рекомендована этому пользователю да но мы еще не знаем точно вы просто знаем что он может быть рекомендован и для этого нам нужен скоринг подал как я уже сказал нас есть различные модели машинного обучения за дипломе в этом вскоре в модуле который еще соревнуются между собой по по максимизации этого скоро победа то есть пользователь может попадать в разные баки ты в этих моделях машинного обучения и соответственно и могут быть разные рекомендации они соревнуются между собой мы выбираем лучший алгоритм выбирает лучшие так далее до этого используется собственно инхаус решение тоже часть alibaba клауд ртп можно в интернете почитать про него но я думаю так или иначе у большинства компаний крупных есть собственные собственные решения для машинного обучения и для рекомендации рекомендательных систем и последняя часть это free курсе control module опять же важно понимать что при отправке пуша мы получили то есть мы получили рекомендованные товары потом мы их за скурили и потом уже мы пытаемся понять хочет ли этот пользователь получать пуша или не хочет может быть он вообще устал от каких-то конкретных путей допустим проба может быть он в принципе от всех пушей устал а может быть он устал от ушей по конкретному товару да и надо отправить ему другой товар для этого наши хай в таблице которые мы уже так много использовали до при этом этому хай в таблице с различной информации про пользователя это клики на пуш и это визиты а по визиты сайта и так далее мы это все через встроенный инструмент хайма highways бал клод мы переливаем это все в и пейсы таким образом наш аул об информацию мы переливаем такой киева илью у лтп соответственно если посмотреть на общий схема персонализации дата если мы говорим про хранение данных после клика пользователя на платформе с помощью фрэнка мы сначала переливаем эти данные в разные hive таблицы где накапливаем информацию о нем затем с помощью того же самого фрэнка переливаем в графова и таблицы для рекомендательные системы также мы переливаем информацию о пользователе в хай в таблицах выйти из таблицы для дальнейшей фильтрации по усталости пользователя и соответственно пониманию тому будет ли ему отправлен пуш или нет или может быть им будет отправлен пусть не с этим товаром вас другим и так далее если рассмотреть теперь всю схему целиком то первым делом да мы помним наверное даже шагом 0 маркетолог создаст задания на отправку пуша пользователем aliexpress россии затем мы с помощью нашего air flow за триггере им джаббу на отправку да то есть каждую минуту проверяется задание наступила необходимо я минута вы нашли эту информацию готовы отправлять push как мы помним мы извлекаем данные skype таблиц по пользователям получаем данные по сидит и сегмента указанному в задаче на отправку push & joy ним это все вместе и затем полученную информацию мы прогоняем в графе с помощью а и графа мы получаем и арте ртп мы получаем рекомендации по пользователю то есть у нас уже есть много пользователей и для каждого пользователя есть рекомендованы для него товары со стороны и повод одному и по той или иной модели полученную полученные данные по пользователю по товарам и теперь проверяем на усталость да то есть у нас мы проверяем усталость пользователя конкретно всего да мы проверяем усталость пользователь по конкретному пушу мы проверяем устал из пользователей по конкретному товару снова производим фильтрацию получили какое-то количество информации до обогатили и все что вам нужно и отправляем полученные сообщения в нужной кафка топик в нужном кафка топике мы вычитываем сообщение на отправку пашей пользователя до нашим при жением persist пирсе stark pusher так как у нас уже есть данные о пользователях получены из коего мы уже даже можем не ходить пир сестер в каких-то конкретных случаях если нам нужно проверить какую-то информацию до может быть ставишь и так далее мы можем опять же сходить проверить затем мы до богача им информацию в хранилище шаблонов да если шаблон был указан очевидно что случае как пушей так и возможно тем более даже емейлов мы всю информацию шаблоне не тянем во всех этих кафка топиках а непосредственно перед отправкой уже до обогащаем кэширует и и все в принципе и затем мы получили этот матч обработали его обогатили сформировали и почём так же отправили в firebase почему бы чем мы столкнулись с тем что у фаерблейда нет никаких гарантий no response times то есть он может ответить за миллисекунды за секунды за десятки секунд поэтому нет смысла строить обработку до такой streaming обработку перса порт после каждого сообщения и отправку firebase это необходимо делать патчами вот соответственно примерно по такой схеме у нас все устроено да то есть начиная с обработки данных получения данных пользователь складывания hadoop затем с кедо лингу различных заданий на отправку созданных маркетологами обработку обогащение получение рекомендации складывания опять же в топике кафки и непосредственно отправку в какие-то нужны уже firebase те же самые сервиса на этом все спасибо вам большое за внимание если есть вопросы задавайте спасибо да спасибо еще раз хотелось бы тебе вот штуку вручить вася давайте перейдем к вопросам да вот по центру заря спасибо за доклад дженнер маков индекс такой вопрос насколько я тут даже против света насколько большая задержка между событиям и отправкой пуша был по интересным вот два последних слайдов и того по каждому шагу насколько этот каждый шаг вносит задержку да тут важно понимать какое событие да и какой push если зависит от зависит от да то есть если мы вернемся смотрите если вернемся вот на системные сейчас да вот допустим системное уведомление до произошло событие она сразу же залетел оффтопик мы сразу же его вы читали обогатили отправили то есть это принципе мгновенно в случае например каких-то рекомендаций да ну тут видно что мы получаем информацию сначала складывать какие то топике в хай вы обрабатываем портится неру и мы так далее по своему опыту я могу сказать что это еще очень сильно зависит от того как часто мы наливаем партиции в hive как правило у нас использовались часовые partition то есть тут можно сказать что информация не явно не будет то есть допустим если вы сделал действие на платформе до рекомендованный push вам новая информация по тому что вы делали в рекомендательных пушок она явно не придет раньше чем через час а тем более если мы говорим о сеги пигмент тогда важно сказать что так как aliexpress россии это все еще так или иначе тесто связано с головной компании alibaba да то есть alibaba один из акционеров и также сильно используется их решение в том числе поэтому например сидит и сидит и система про которую я рассказывал она в целом целиком на веселе экспресс по крайней мере пока что и соответственно там данные наливаются по-моему вообще раз в день раз в сутки и причем даже чуть задержка нам t + 1 получается вот поэтому в случае рекомендательных это не мгновенно точно случае системных этом главе ну с промо пушками примерно с провожаем получше потому что нет никаких сидите и так далее если это без таргетинга то тогда задержка примерно час спасибо и такой вопрос было про инструмент который от alibaba клауд почему не все инструменты али баба клава это отличный вопрос на самом деле во первых есть такое понятие как отделение так или иначе aliexpress россия в каком-то смысле он технологий али-бабы да потому что на российском рынке я думаю не так просто человек у которого есть экспертиза в alibaba клауд да и это и мягко говоря не просто во вторых опять же мы взаимодействуем с alibaba клауд как клиент да то есть вы также платим за эти решения и я не стоит отнюдь не дешево и соответственно так или иначе есть потребность в отсутствие вен thermo king да опять же как здесь уже много раз говорилось поэтому какие-то решения до сих пор используются да вот здесь например сказано крафтовая базы данных данном не так просто взять и поднять какой-то собственный солнца причем это же должен быть еще человек который которую явно есть экспертиза вы это поэтому также продолжаем использовать решения либо поклал каких-то случаях например пусть система доу али-бабы также есть своя у alibaba клауд есть своя путь система но мы сделали свою потому что мы во-первых этим не платьем до головной компании во вторых у нас появляется экспертизы и мы уже можем какие-то вещи делать более гибко это тоже одна из причин почему мы например многие компании и коммерс они используют для отправки пушей различные решения типа экспо не и так далее которые тоже стоит довольно большие деньги и это в том числе экономия средств после круто спасибо да вот на первом ряду привет я здесь на первом ряду вот девиз компании озон я спасибо за доклад спасибо я немного не понял вот по поводу схемы у вас сначала делается скоринговая модель ну вот шаг везде и только затем вы определяете можно ли да а можно ли пользователю отправить push может быть это должно быть наоборот потому что по идее проверить что можно пользовать отправить пуш или нет это дешевле чем вычислить применить модель да это хороший вопрос на самом деле тут важно сказать что многие модели они рассчитываются на основе fly данных пользователь к тому моменту как у fly данный вот только что отвечал на вопрос да у нас данные могут быть задержки 24 часа тому времени как модели начинает эти данные первых она может их рассчитывать на устаревших данных и к моменту как вы отправите уж пользователь уже получат там с десяток других ушей до которые уже так или дачи повлияет на так называемого усталость но это на самом деле важный важный пункт в том что мы в том числе сколько модули учитывая усталость пользователь от например получения тоже товаров каких-то определенных поэтому в целом это такая схема здесь в принципе можно сказать что часть frequency control module а также есть внутри скоро спасибо да да всем привет никита компания lamoda у меня три вопроса первый вопрос что почему мы сначала идем бабочкой а потом переводим граф и граф сначала я так понимаю идет разбивка на партиции не вот это какая-то но вот эта схема почему сначала мы формируем хай а потом идем в играх они формируем условно сразу два направления 1х и другой выйграв да это хороший вопрос на самом деле у нас так или иначе из коробки решения до которая позволяет переливать хай фай граф она работает непосредственно с оффлайн таблицами это опять же часть vendor локинга скажем так поэтому у нас в основном мы переливаем непосредственно готовые hive таблицы в warcraft а в целом действительно можно и используется переливать в целом поиграв я думаю можно вы просто так не делали мы делаем вот спасибо второй вопрос вот при отправке пуше у вас есть разные партийцы которые формируются на каких то там критериях но в момент отправки пуша менеджер может еще разбить группы пользователей по тайм зонам и по времени отправки там не знаю с трех до четырех и где будет учитываться именно time зона клиента и отправка непосредственно пуша она вначале будет другую партицию разбиваться или пузыри уже как-то будет рулится time zone а я это будет на уровне дало не портится то есть момент когда строится партиций мы когда переливаем данные пользователи когда я их девайса вы также переливаем сказано данная всех девайсах за пользоваться то есть в том числе time зона которой находится его девайс соответственно на момент построение партийцы там хорошего просто самом деле потом зонам для этого мы строим условно партиций которые отвечают за разное время наступления события то есть partition которая допустим будет прочитано там в 16 допустим в промежутке между 4 и 5 ю да она содержит пользователей которые так или иначе находятся в этой зоне то есть это будет на уровне долгов них айва ну довольно убит ходу по но вы гарантируете что момент отправки вот успеет условно отправить сервис на самом деле для таких кейсов может быть еще вторая проверка в реал тайме то есть мы можем проверить что действительно использовать находится той зоне что мы не ошиблись до или что пользователь не поменял информацию по своим девайса и в том что в этом случае может быть push уже не отправлю спасибо и такой маленький вопрос у вас все на патч сейчас такое время что есть риск а что простым не получится дальше продлять лицензия не боитесь как да тут очень важный момент что я уже сказал что у нас один из крупнейших акционеров это alibaba и по сути в данный момент да весь весь hadoop весь апачи которую мы используем это по сути их венгерское предоставление на то есть мы им платим деньги за то чтобы они нам предоставляли технологии пока такой угрозы нет насколько я знаю опять же я в данный момент уже не представляю компанию экспресс россия я возможно какие-то вещи могу сказать неверно вот но в тот момент когда я ещё работал были планы по тому чтобы создавать свое облако hadoop в свое хранилище hadoop да и полностью оперировать им что-то изменилось сейчас до в мире много изменилось и возможно планы уже поменялись возможно пока не будет переездов с windows кого решение alibaba клауд ну и так как она одним из крупнейших акционеров планов и расторжения каких-то договоров контрактов пока как я слышал нет спасибо по центру слил а привет спасибо за доклад максим система снова яндекс и снова про скорость немножко фоне the island таким движком hive таблице вы считываете потому что копы хайфон все-таки чем медный если данных много иска идет быстро запись быстро вычитка пробовали использовать парк импалу еще что-нибудь вопрос отличный вопрос у нас hive идет как как сказать по сути весь а либо вы по сути все alibaba решения допустим да вот распродажи на 1111 вот это известной китайской распродажа причем это же говорили про алиэкспресс про китайскую али-бабу где там условно миллиарда транзакций первые секунды весь processing построен на клинке вопросу pop chef линк или high five да хорошо тогда сейчас я должен немножко поменять свой ответ случае собачьих hive на самом деле мы используем платформу ядерную платформу макс компьют это по сути полностью клауд решение которое включает себя и хоть таблицы и вот апачи fling и так далее так далее соответственно мы на самом деле не пробовали использовать я честно скажу не пробовали использует другие решения потому что у нас так или иначе это идет как облачное облачно и предоставление данных да то есть у нас можно в юар создать табличку в хайме да и она будет работать и также в ей можно настроить синхронизацию из-под gresso в тот же самый хай буквально за счет нескольких кликов поэтому тут я наверное могу быть неве спасибо привет спасибо за доклад как раз пожалуйста вы как-то решаете вопрос неактуальных уведомлений то есть пока мы решали что-то покрепче рекомендовать человек уже это купил или там мы хотим напомнить про корзину а он уже и и там почистила или закончилась ней да это хороший вопрос а вот тут важный момент что во игра фидо что у нас на самом деле когда мы синхронист когда мы синхронизируем buy граф здесь я не указал здесь есть не только хаев есть еще другие движки которые позволяют синхронизировать алмаз 3 all-time данные в поиграв это первый момент который позволяет нам более real time ago приблизиться к тому что пользователь делает данный момент второй момент это то что достигли есть проблемы с этим да так как даже дело не только в том что купил человек да мы знаем что на алиэкспресс огромное количество продавцов и одни и те же товары можно найти в огромном количестве разных продавцов и вот к сожалению на тот момент когда я еще работал в компании мы не решили проблему того как нам например не рекомендовать различные там и скай уиллис поют поэтому я думаю что работа в этом направлении сейчас ведется но это требует не только нашего участия да как команда уведомления и так далее а в целом все платформы потому что там дизеля колоссальный объем работы необходимо совершить да спасибо давайте на этом вопрос и завершать кажется он ставил подходит концу давать еще раз поблагодарим руслана за прекрасный доклад спасибо"
}