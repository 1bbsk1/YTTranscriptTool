{
  "video_id": "neeRqwmAkgs",
  "channel": "HighLoadChannel",
  "title": "Платформа А/В-тестирования в Яндексе / Михаил Агеев  (Яндекс)",
  "views": 248,
  "duration": 2851,
  "published": "2025-01-17T02:28:08-08:00",
  "text": "Всем привет Меня зовут Михаил Агеев я Работая в Яндексе разрабатываю платформу а тестирования я начну свой рассказ с описания бизнес требований к платформе АТ расскажу про нашу зону ответственности Потом я расскажу про устройство платформы и основные компоненты потом мы погрузимся в самые сложные и интересные части системы базовая задача платформы сделать так чтобы любую гипотезу можно было легко и быстро проверить по АБ например проверить как новый дизайн карточки товара влияет на покупки или как новая формула ранжирование влияет на скорость решения задач в поиске Это простые требования но на практике оказывается что это далеко не ВС что нужно бизнесу от платформы на основе птит опыта развития АТ в Яндексе я расскажу какие на самом деле есть ещё требования к платформе И как мы их обрабатываем первая проблема в большой компании разные команды оптимизируют различные метрики и толкаются друг с другом легко разменять счастье пользователей на деньги изменением количества рекламы легко добавить новые функциональности проди скорость рабо нам нужно уметь с этим работать уметь с этим жить поэтому платформа тестирования должна предоставлять полную картину как эксперимент влияет на сервис показывать метрики всех команд и устраивать дискуссии если эксперимент улучшает одни метрики и ухудшает другие метрики и ти использования АТ Например можно накрутить ю множественным тестированием можно запустить 100 или сся экспериментов и выбрать те в которых Метрика значимо улучшается можно выкатить не то что тестировал можно выкатить дважды и дважды засчитать одно внедрение в мы должны выявлять плохие практики и пропагандировать хорошие тики И став инст хорошим практикам об тестирования одни и те же данные можно интерпретировать по-разному обычно автор эксперимента склонен переоценивать важность и полезность своего внедрения это нормально Поэтому нужно поддерживать научный подход автор пишет доклад научные исследования про свой эксперимент рецензент приходит исследует и челленджи автора либо подтверждает гипотез эксперимента либо авто и находит какие-то проблемы соответственно в платформе нужны инструменты для проверки и рецензирования результатов исследования Есть множество способов провести хорошее исследовани но не докатить его до продакшена Например можно протестировать флаги в одном регионе А раскатить на все регионы можно просто допустить при нужно чтобы платформа позволяла выкатить впт ровно те настройки с которыми авторы экспериментировали соответственно требования к платформе нужно чтобы настройки эксперимента соответствовали Продакшен и нужно чтобы результаты эксперимента соответствовали выходке последнее это очень слож лище Эри об этом нужно думать нужно предоставлять инструменты нужно проводить исследования чтобы показывать Как это работает не все эксперименты успешны большинство гипотез не подтверждается Это значит что большинство экспериментов скорее вредны если упростить порог входа на запуск эксперимента то обязательно найдутся очень плохие эксперименты которые даже на небольшом проценте потока будут давать существенный вред соответственно Наша задача обезопасить бизнес от плохих экспериментов выявлять плохие эксперименты и убивать их некоторые эксперименты можно проводить одновременно на пересекающихся потоках пользователей некоторые другие эксперименты не должны между собой пересекаться например эксперименты с дизайном шрифтов и с формулой ранжирования можно проводить на пересекающихся потоках две формулы ранжирования пересечь не получится поэтому мы должны С одной стороны максимизировать максимизировать скорость экспериментирования давать каждому эксперименту максимальный поток а с другой стороны запрещать выкатывать несовместимые Эксперименты на одном и том же потоке пользователей ещё проблема что у каждого сервиса своя специфика ВН разн свои подходы к архитектуре сервиса свои языки разработки свои особенности архитектуры и нам нужно обеспечить с одной стороны удобны АТ для каждого сервиса а с другой стороны не забывать про сквозные эксперименты где изучают влияние одного сервиса на другой обычно метрики АТ Форт ВХ продуктовых терминах нори не то что написано в её названии и Сегодня я расскажу про некоторые типовые проблемы метрик и как с этим работать ну и наконец к платформе АБТ предъявляются очень высокие требования по масштабируемости по скорости и по надёжности стабильность АБТ влияет на стабильность каждого из сервисов который пользуются экспериментами скажем падение АТ мы знаем что может привести к падению самых крупных сервисов Яндекса Давайте погрузимся в то как выглядит жизне цикл эксперимента пройдём по этапом проведения эксперимента любой сотрудник Яндекса разработчик менеджер дизайнер тестировщик руководитель может зайти в наш сервис в админку экспериментов и накликать себе эксперимент например как на слайде новый фильтр для факто ответа поиска нужно написать какую гипотезу проверя кае метрики Будем смотреть и указать на Какие сервисы должен раздаваться эксперимент затем задам выборки из которых состоит эксперимент задаём идентификатор разбиения и процент потока в данном случае эксперимент состоит из контрольный и двух тестовых выборок можно указать ограничение эксперимента например раздавать эксперимент только на пользователей из Московской обла кое в поис сфо выборки задаём флаги сервиса обычно флаги сервиса задаются в виде словаря ключ значения но в общем случае это произвольный J который интерпретирует код сервиса об шница позволяет задать произвольный н и дальше сервис его забирает и как-то интерпретирует после заведения эксперимента мы рекомендуем пользователю проверить вручную что его изменение работает так как задумано это сокращает количество ошибок дальше авто автор отправляет эксперимент на выходку и мы запускаем огромное количество тестов которые проверяют что эксперимент не сильно изменит поведение сервиса не сломает его упавшие тесты нужно проверить и согласовать с ответственными за тесты после этого эксперимент выкати на пользователей сразу после выкладки можно посмотреть на реалтай графики как эксперимент раскатывается на пользователей нет ли каких-либо аномалий для большинства экспериментов автору не требуется вручную следить за процессом Но для особо опасных экспериментов бывает нужен ручной контроль и возможно ранняя остановка эксперимента если что-то пошло не так типичный эксперимент длится от 4 до 30 дней по окончанию эксперимента автор смотрит на метрики и проверяет подтвердилась ли гипотеза и Стоит ли этот эксперимент катить мы раскрашиваем метрики вче цвета в зависимости зей цвет означает значимое улучшение красный цвет означает значимое ухудшение если мы не знаем как интерпретировать метрику всегда это увеличение метрики это хорошо или плохо и то значимо изменение красим жёлтый цвет вот ну и соотвественно серый цвет означает что Метрика изменилась не значимо дням проверить нет лиху подозрительных Скачков ВС ли ожидаемо если в эксперименте всё хорошо то автор пишет аналитический отчёт и аргументирует почему хочет выкатить в эксперимент в прот дальше в тикет приходит аналитик обычно это сотрудник не зависящий поста от экспериментатора профессионал по анализу метрит ибо Подтверждаю что эксперимент полез его можно экспериментатора задаёт разные неприятные вопросы находит в эксперименте проблемы если эксперимент хороший то аналитик согласовывает выходку эксперимента и эксперимент отправляется вы на выходку в продакшн а команда себе засчитывает в копилку полезный релиз выходка в продакшн тоже обычно делается через нашу инфраструктуру в полностью автоматическом режиме Каждый раз когда вы задаёте запрос в поиск вы попадаете примерно в 100 одновременно идущих экспериментов кто-то экспериментирует с дизайном кто-то экспериментирует с формулами ранжирования кто-то с новой функциональностью поиска все эти эксперименты можно пересекать и проводить одновременно за прошлый год через нашу инфраструктуру проведено более экспериментов и более 3000 из них Выка впро наш ранта сплитов сплитом запросов в секунду а для расчёта метрик мы обрабатываем более ПТА байта логов в день крупные сервисы рассчитывают по несколько тысяч метрик и всего мы перевариваем примерно 100.000 метрик рассчитываем ежедневно ра го к нам добавляются новые сервисы метрики и логи соответственно растёт нагрузка и количество релизов через АТ далее расскажу как это устроено технически сервис состоит из веб интерфейса админки ранта и ранта обрабатывающие запросы пользователей и ещё есть система расчёта метрик Давайте пройдёмся по этим системам в админке пользователи управляют экспериментами и смотрят метрики админка готовит конфиг экспериментов передаёт его в ранта и админка забирает из системы расчёта метрик рассчитанные метрики и красиво отображает их пользователю ранта отвечает за обработку запросов пользователей и тесно интегрирован с сервисами ранта решает для каждого запроса В какие эксперименты попал пользователь и какие флаги нужно применить три способа подключения сервиса Кб в каждом есть свои плюсы и минусы самый простой и самый ограниченный способ подключения через сервисный балансер можно в конфиге балансера указать несколько настроек типа подключить кбт Используй нарезку для сервиса и балансер Будет отдавать в http хадерах эксперименты и флаги которые нужно применить А дальше сервис просто Берт флаги из хоров и их интерпретирует ограничение этого подхода в том что балансер не может отдавать большое количество флагов А обычно когда серс подключается кбт то у него постепенно растёт количество экспериментов и размер флагов с которыми экспериментирует поэтому мы часто опираемся в ограничение размеров флагов если сервис подключен через сервисный балансер второй способ подключения это серс ходит HT вру говорит кото каким-то юзер агентом какие эксперименты ему нужно Нарезать и АТ отдаёт J в котором перечислены все эксперименты и флаги Этот способ имеет меньше ограничений на размер флагов можно передать хоть мегабайт флагов Вот но требует некоторой разработки в коде сервиса и наконец третий способ самый сложный и самый имеющий наименьшее количество ограничений тогда сервис встраивают библиотеку а нарезки пользователей и забирает регулярно забирает конфиги из АБТ а При таком способе нету а этот способ самый сложный потому что нужно следить за корректностью подключения и есть много разных нюансов в а таком способе подключения но зато снимаются все ограничения на размер конфига скажем самый крупный наш сервис реклама обрабатывает конфиги в которых 200 МБ данных и делает это достаточно эффективно за несколько десятков миллисекунд при разумной оптимизации и предобработки конфига это можно сделать очень эффективно сервис расчёта метрик берёт на вход логи сервисов считает метрики и считается значимость фов в экспериментах расчитанные метрики загружают в админку для отображения расчёт метрик делается в распределённой системе обработки данных в it которые реализует концепцию mapreduce и соответственно у нас есть фреймворк кофе который позволяет легко писать бизнес логику метрик не погружаясь в распараллеливание и не погружаясь в методы расчёта стат значимости А в результате расчёта метрик мы отгружаем ежедневный расчёт выжимок с метриками по всем экспериментам которые проводится в обт теперь когда мы изучили жизненный цикл эксперимента и устройства сервиса Я хотел бы погрузиться в отдельные проблемы архитектуры и рассказать уроки которые мы извлекли из нашего опыта первый урок про то как важен правильный дизайн конфига сервисом А хороший дизайн конфига позволяет уменьшить время на разработку экспериментов и проводить большое количество экспериментов разработки эксперимент - это просто патч к Конфи сервиса можно использовать произвольный но гораздо удобнее и гораздо меньше ошибок возникает если это схема например в виде проб схемы очень важное требование к дизайну конфига чтобы любой флаг можно было выкатить в прот а потом ответить и выкатить обратный эксперимент который удаляет этот флаг или заменяет на дефолтное значение поэтому Мы например очень не любим списки J списки в конфигах а стараемся делать так чтобы это был просто Каскад из словарей Сейчас я покажу пару примеров очень богатых конфигов и флагов например в конфиге поиска можно задать сложные условия и можно задать вычисляемые выражения над переменными доступными в ратай можно запрограммировать большие программировать на таком доно специфическом языке сложно но зато умельцы могут запустить очень нетривиальный эксперимент вообще не программирую в код сервиса и затрачивая совершенно минимум времени мы постоянно ведём дискуссию у нас внутри насколько хорошо такие большие и богатые конфиги потому что с одной стороны это риски для сер Что можно написать неправильный код и сделать что-то странное сго очень можно очень быстро запускать эксперименты очень быстро проверять гипотезы и двигаться быстрей ещё один сервис с богатым конфигом тут сервис разрешил себе доставлять прямо CSS и жава скрипты из конфига АТ прямо в продакшн выглядит конечно ужасно получается тако мего кода с которым могут справиться только умельцы но зато скорость доставки печей просто зашкаливает следующий урок про то как контролировать качество метрик Типовая проблема запустили эксперимент увидели прокрас который не объясняется гипотез эксперимента и оказывается что на изменение метрики может влиять не только продуктовые изменения но и технические особенности реализации технические особенности реализации метрики логов сервиса архитектуры сервиса а как устроена Метрика сразу возникает вопросы Как устроена Метрика Из каких логов получаем данные как эти логи Джони между собой часто кейс проблем в Метрика - это неправильная архитектура сплитов Нея и логирования хороший паттерн проектирования сначала определить попал ли пользователь в эксперимент потом посп това на контрольную и тестовую выборку потом применить флаги и реализовать функциональность эксперимента если сделать наоборот то есть сначала посп това пользователей на контрольную тестовую выборку а потом пофиксят если фильтры не симметричны и зависят от того в контроле в эксперимент попал пользователь то оказывается что в разных выборках контрольные тесты разное количество пользователей и разное количество событий метрики начинают врать а ещё мы встречали примеры лоскутного проектирования сервиса когда значит сервис по мере развития архитектуры всё время усложнять и получилась Полная каша что сначала применяются фильтры потом сплитом применяется ещё раз Потом делается е раз нарезка эксперимента в другой компоненте сервиса ещ раз применяются фильтры потом применяется функциональность эксперимента а потом пишутся клиентские логи и на основании этих клиентских логов считаются метрики поскольку клиентские логи имеют не гарантированную доставку это логи приложений и или логи которые пишет JavaScript из браузера логи имеют не гарантированную доставку соответственно эксперимент может влиять на процент потерянных записей логов и в результате метрики могут раз по причин раздеть такое бывает очень сложно поэтому проектируй сервис правильно заранее Думайте о том как вы будете понимать попал пользователь в эксперимент или нет лучше делать логи на самой ранней стадии как только вы сделали сптоваров пользователь в эксперимент или нет проблема с разъезд метрик сложно дебажить поэтому у нас есть сотни контрольных метрик это метрики которые нужны только для того чтобы проверить корректность логирования и быстро раздеть проблемы если они возникнут например количество пользователей попавших в эксперимент по разным срем и идентификатором мы всё это показываем в виде метрик и получается там неско мериль про контро корректности эксперимента разбиения пользователе на контрольную экспериментальную выборку сложные метрики нужно уметь объяснять если Метрика отношения то нужны Метрика числитель и Метрика знаменатель если Метрика формула то нужны метрики компоненты этой формулы а ещё нужны инструменты для нри То есть каждый раз когда в эксперименте возникают неожиданные протри Несе продуктовой гипоте разобраться почему это произошло Например можно разложить метрики по платформам по типам браузеров по типам страниц сервиса А Де багель метрики ускоряют аналитику и повышают Доверие к сервису в целом наконец метрики нужно не только реализовать но и проваливать мы очень любим запускать эксперименты с известным ведик ухудшающие эксперименты просто чтобы проверить что покажет Метрика на таком эксперименте и часто находим неожиданные инсайты когда by дизайн эксперимент ухудшающий а метрики почему-то показывает значимые улучшение А ещё можно запустить множество А экспериментов и посмотреть правда ли доля прокраса метрик в а экспериментах соответствует выбранному порогу P value Если вы запускаете 1.000 а экспериментов и используете порог P value 1% то примерно 10 из них должны иметь значимый прокс метрики следующая часть в данных часто бывают выбросы и некорректные данные Давайте посмотрим что с этим можно сделать первый и весьма противоречивый способ борьбы с выбросами это очистка данных от аномалий например антиромантик что они обычно основаны на евристика а эвристики не всегда правильные и поэтому если вы используете очистку данных Вы должны сделать большое количество метрик которое лидирует корректность очистки данных и в идеале на каждое правило на каждую иври которая очищает данные нужны контрольные метрики которые проверяют а не сломалась ли эта евристика в этом эксперименте второй подход это к очистке это использовать статистические тесты устойчивые к выбросам мы считаем самые популярные стат методы тест и Бакет мавит в основном используем Бакет мавит именно потому что он более устойчив к выбросам проведём небольшое моделирование возьмём два нормальных распределения с центром один и с центром в полтора возьмём 100 сэмплов из каждого распределения и добавим один выброс посмотрим насколько значимость различия этих семплов зависит от величины выброса при отсутствии теста при отсутствии выброса тест покажет большую чувствительность это естественно потому что тест основан на предположении нормальности распределения но большие выбросы ломают тест сильно увеличивают дисперсию вбо м хуже в тесте а тест устойчив таким выбросом его значение не зависит от размера выброса он всегда показывает что выборки значимо отличаются и пример из реальной жизни приходит ко мне экспериментатор И жалуется что он вырастил оборот по деньгам в эксперименте в два раза аш считают это изменение не значим цифры очень большие явно статистика статистики достаточно раскопки показали что рост в два раза вызван одним пользователем который оформил заказ на 24 супер телевизора по 9 млн руб каждый а потом заказ отменил Вот но соответственно мы посмотрели сказали что обни говорит правильно а изменения неста значимые потому что различие вызвано одним выбросом последний урок про который я хотел бы рассказать это Как защищаться от плохих экспериментов У нас есть множество слоёв безопасности экспериментов это до выходки эксперимента мы проводим оффлайн тестирование и В некоторых случаях согласовываем эксперимент с опытными аналитиками которые челленжа экспериментаторы и проверяют например что гипотеза хоро сформулирована есть ручная проверка экспериментов пере экспериментатор проверяет Правда ли что то изменение которое он закодировал оно видно в выборке есть во время эксперимента и во время анализа эксперимента Есть огромное количество метрик покрывающих все аспекты качества например в рекламе порядка 3.000 метрик в поиске больше 15000 метрик в Маркете больше 7000 метрик это нормально для крупного сервиса каждая команда которая заинтересована в своём развитии и в своей не поломке заинтересована в том чтобы написать метрики вбт которые чувствительны к изменениям в подсердцем реклама на 14% потока просто потому что не подумал что это может быть плохой эксперимент так такое бывает кто-то запустил вечный эксперимент для контроля некоторого показателя сделал дашборд с графиками потом перестал этими графиками пользоваться А эксперимент до сих пор бежит И каждый день там немножко портит сервис бывают Просто баги Когда например эксперимент роняет Кэн такое нужно очень быстро обнаруживать и такие эксперименты быстро убивать перед запуском эксперимента запускаем большое количество тестов если тесты упали то робот находит ответственных за теста и требует разобраться и окну падение ответственными могут быть либо разработчики тестов либо ответственные за стабильность сервиса в целом либо ответственные за сервис который который пострадают если тесты говорят правду а чтобы выкатить в эксперимент в прод нужно согласовать падение важных оффлайн метрик с ответственными за сервисы тут тоже возникает автоматическое согласование призываются ответственные ответственные нажимают кнопочку что да АК такое можно катить А у каждой команды которая хочет чтобы его ключевые метрики не просаживается над метриками просаживается важные проблемы Что просили метрики качество логирования в таком-то сервисе просили метрики денег пожалуйста согласуйте выгод с владельцами этих метрик вот и опять же мы умеем запускать такую окол которую призывают владельцев Рик и согласование происходит довольно быстро обычно в течение одного дня 10 лампочек можно согласовать если конечно это правда не очень хое изменение У нас есть основной контур расчёта Трик который каждый день Берт логи сервиса задень и считает метрики а для автоматического отключения очень плохих экспериментов нам понадобилось сделать новый реалтай контур расчёта метрик конр рассчитывает метрики С задержкой менее минуты потом поверх нфор акого отключения между скоростью просадки метрик и уверенностью в том что эксперимент действительно катастрофически плохой эта формула отключает большие баги с лагом несколько минут А если тайла ри спорный то ждёт накопление статистики И только после повышения уверенности убивает эксперимент а ещё кроме экспериментов с катастрофическим падени есть эксперименты которые прожит пон жен не процентный Диф насколько просили деньги в таком эксперименте А накопленный эффект сколько денег мы потеряли за время проведения эксперимента И сколько потеряем если его не отключить сегодня например вечный обратный эксперимент который каждый день немножко теряет денег или какой необязательно деньги молю метрику зав которая важна для сервиса для таких экспериментов мы сделали ещё один контур слежения который считают накопленный эффект для каждого эксперимента робот запускает дискуссию между автором эксперимента и аналитиком и аналитик челендже экспериментатора скажем Стоит ли эксперимент тех денег которые мы на него тратим есть ли шанс выкатить эксперимент в продакшн если мы уже видим вот такие метрики в эксперименте а эксперимент будет двигаться ещё неделю Можно ли уменьшить процент потока эксперимента Чтобы тратить меньше Но информацию которую собирает автор ВС ещ была доступна с нужной разрешающей способностью запустив такой процесс мы стали экономить там в масштабах Яндекса примерно 250 млн рублей в квартал просто на том что поща мусор из бесполезных экспериментов я рассказал про устройство внутренней аш Яндекса про бизнес-требования к ней и про сложные интересные части системы Если вы хотите узнать больше про АБТ и узнать про внешние АБТ которые предоставляет Яндекс Приходите ещё сегодня на доклад Данила валку он расскажет про куб который основан на тех же технологиях но сделан немножко для другой аудитории Спасибо Да огромное спасибо это было супер интересно немного сюрприз что в А можно учитывать столько всего и столько реально экономить это мега круто Я думаю что будут вопросы поднимайте руки мы дадим вам микрофон вот уже есть отлично о много супер Большое спасибо за доклад было очень интересно вы описали что у вас во время того как стартует атест есть метрики на которые люди могут смотреть ля что что-то не так а вы не думали это автоматизировать то есть есть ли какой-то аленг для того чтобы это делать автоматом и убрать труд вручную и были ли на это исследование спасибо спасибо вопрос Да конечно и Об этом я рассказывал в последней части мы на основе Реал тайх метрик убиваем плохие эксперименты если они критично плохие для сервиса но бывает такое что автор тестирует какую-то не супер критичну вещь типа как работает его энд его надо посмотреть на ретай графики просто посмотреть чтобы скажем не сломался ли его кнд если кнд не настолько критичен чтобы влиять на деньги всего Яндекса то мы этот эксперимент не убиваем это на усмотрение автора Ага А какой алгоритм вы используете в аленг с с дифм в средних или определя е смотрим на объём выборки и Нади средних на средних и прямо обём выборки чтобы примерно прикинуть значимость изменения сшу ещё очень быстро второй вопрос что вы описывали что вы используете критерий Но ведь в кейсе котором мы используем критери мы не можем сделать гипотезу о том насколько в меке отличается медиана или средние значения которые в ней есть Ну то есть типа мы определяем Было ли отличие в распределения А сам эффект между контролем и тестом вроде не можем измерить или вы измеряется его мы показываем в на панели Рик и Ди средних и тест мавит из-за этого могут быть некоторые неочевидности в показе то есть теоретически может быть такое что ди средний равен нулю а мавит не говорит что это статистическое распределение но такое бывает очень редко и в общем опытные Ну все аналитики знают про то что мы используем мавит и как это интерпретировать интересно спасибо большое Михаил Большое спасибо за выступление Александр хотел спросить вы используете только атест то есть CDI mab вы решили не использовать в своей системе Если да то Почему решили не использовать потому что Ну в целом классические а тесты показывают достаточно надёжный результат а при наших объёмах данных чувствительности хватает понял спасибо спасибо большое за доклад правда было очень интересно вот особенно сравнить с тем что есть у нас в том числе у меня наверное такой вопрос сначала по докладу я не очень понял вы сначала сказали что у вас есть MB которые берут петабайт в день и их рассчитывают вот я так понял что результаты готовы примерно на следующий день и в конце доклада вы сказали что у вас есть realtime метрики на которые можно смотреть Ну вот прямо сейчас это какие-то разные метрики или я просто чего-то не понял подмножество самых важных метрик считаем в реалтай сся метрик для каждого сервиса считаем то по дням то есть в целом анализ экспериментов сейчас вердикт делаются по дневным Метрика а метрики нужны для автоматического отключения либо для автоматической корректировки эксперимента что если автор понимает что скажем он страховал и запустил на маленький поток то можно э было у вас внутри запроса чтобы считать все вообще все метрики там ну не знаю через 15 минут Полчаса и так далее а запрос Конечно есть есть определённые технические сложности в том чтобы это реализовать есть сложности с архитектурой расчётов что просто Это очень дорого считать в в реал тайме есть сложности в том что ну скажем там заказы в Маркете это по сути очень продолжительная штука сча долго выбирает товар потом возможно на следующий день кдт в корзину потом через несколько дней мы их доставляем и поэтому во многих кейсах нам реально не нужен вот очень важен для ряжения за за Продакшен чтобы ловить какие-то проблемы очень быстро Михаил Добрый день спасибо за ня во сказал что у вас 1015 сервисов плюс-минус Наверняка есть сервисы С небольшой аудиторией как набираете для них аудиторию как получается это значимость Используйте cid что-нибудь такое сервис небольшой аудитории обычно проводит эксперимент 50 на 50 некоторые считают cid но по нашему по нашей практике cid даёт с одной стороны а часто очень не интерпретируемые результаты а с другой стороны не так уж сильно помогают ускорить эксперименты Спасибо И второй вопрос мы называем это лбк другие ребята по-другому называют условно когда мы берём выборку пользователе не катим на неё вообще ничего там квартал и потом сравниваем её с другой группой на которой все фичи выкатывать то есть такой оценка продуктового эффекта делаете ли вы такое мы называем это обратные эксперименты есть некоторые под Серви которые тако умеют Но это тче бо чтобы скажем целые полгода держать обратные флаги и воспроизвести Что что в сервисе было полгода назад Это очень дого дорого для разработки и поэтому обычно сервисы от этого отказываются в пользу того чтобы двигаться быстрей спасибо спасибо был классный доклад скажите пожалуйста вот когда вы говорили про тесты которые переводите автоматизированные тесты которые проводите перед прого об тестов это тесты фича флагов в веб приложении или первый вопрос вот а второй вопрос - Это тот это про ваш DSL который вы используете в АП тестах Правильно ли я понимаю что фактически протестировать такие штуки нельзя и они вот на бою как-то исполняются и тесты на них на самом деле никак не напишешь И это а этот DSL в свою очередь Он позволяет вам изменить разминку страницы чтобы произвести этот эксперимент а тесты обычно устроены очень просто что есть скажем поиск Яндекса можно обстрелять поиск Яндекса там 100.000 запросов с проми флагами и с экспериментальными и посмотреть насколько сильно изменится выдача если выдача меняется сильно то это опасный эксперимент Давайте на него пристально посмотрим тоже самое с там с рекламой с маркетом смотрим насколько сильно меняется выдача сервиса и ставим какие-то разумные пороги что типичный эксперимент он влияет только на очень маленькую часть сервиса и поэтому в типичном эксперименте тесты все зелёные Вот а если это очень если тесты красные значит это либо большое изменение которые должны запру Вить либо правда поломка так так не было задумано А вот эти автотесты - это те тесты которые написали разработчики Или те тесты которые как-то накатили и в проде исполняются что это за автотесты которые это разработчики пишут тесты они не раскатывают на пользователей пользователи не знаю это Просто внутренний обстрел беты сервиса обычно Понятно спасибо С сталкивались ли вы с оттоком из экспериментального сплита и Если да то по какому алгоритму вы считаете что Ну всё нужно завершать эксперимент При таком оттоке у нас обычно на первом месте почти в каждом сервисе есть Метрика кото если есть отток из экспериментального спта то она красится в красный а скорее на следующий день но да вообще изменить довольно сложно То есть если у вас катастрофическое изменение Да вы распух пользователей то у вас реалтай метрики тоже покажут что всё очень плохо там количество запросов количество пустых страниц количество денег зарабатываем все эти метрики реагируют гораздо более чутко чем Дао просто потому что возвращаемое пользователя - это такая долгая штука что по дау дау по сути это Метрика день ко дню Спасибо большое за доклад очень интересно у меня такой вопрос смотрите ли вы на целевые метрики экспериментов прямо в его ходе И что вы делаете с проблемой подглядывания в таком случае Спасибо целевые метрики эксперимента в коде Трик код метрик доступен всем поэтому все знают Ну если в метрике Баги то обычно это довольно быстро раскапывает ещё очень интересный вопрос на с проде может быть два эксперимента влияет на метрики второго умеете ли вы их определять автоматом и есть ли у вас какая-то пост аналитика для того чтобы вы являть проблема потому что они есть и выявление их Ну то есть такая таска очень интересно спасибо за вопрос мы знаем о проблеме автоматом мы такое не определяем это всё делается на уровне продуктового понимания как На что влияет эксперимент то есть авторы эксперимента и ну и Наши сотрудники которые понимают С какой функциональностью экспериментируют они разделяют А говорят что а эксперименты с картинками с разной функциональностью картинок не надо пересекать эксперименты с картинками и с видео можно пересекать хотя на самом деле картинки и видео конкурируют похожи и могут толкаться влиять друг на друга Спасибо за доклад вы сказали что у вас есть три способа подключения и 215 продуктов Какой из трёх используют чаще всего какой реже всего и какие Тен у каждого из способов подключения самый частый способ подключения - это просто через балансер Потому что потому что просто поэтому все новички сразу подключаются через балансер lcy по-моему там 20 миллисекунд на ответ обни а способ подключения порука какая там задержка порядка там 1020 миллисекунд а подключение библиотеке на энде Я так понимаю самый редкий ССО Это самый редкий способ СП ми Но дальше Всё зависит от того насколько эффективно вы предобработки вот и дальше начинаются разные тонкие оптимизации как зашивать результат применения конфига для каждого эксперимента Спасибо так да спасибо ещё вопрос на самом деле возник я вот не очень понял насчёт аналитиков которые проверяют эксперименты Вот то есть у нас есть человек который натыкал себе какой-нибудь ерунды хочет бесконечный эксперимент на миллион метрик есть аналитик который его проверяет чтобы их разделить Ну чтобы их вот отде чтобы один человек нения нагого должен быть либо аналитик условно говоря из там Маркета который проверяет какой-нибудь Яндекс Go Вот либо это должен быть вообще отдельно выделенный бизнес Юнит аналитиков которые вообще никому не подчиняются иначе у них может быть общий начальник который тоже может давить по какому-то эксперименту по которому он хочет И вот если это просто аналитика с другого бою получается так что все аналитики из условно говоря такси знают всё про маркет или как это работает не обычно аналитики просто не не из той же команды не из той же группы что и экспериментатор этого обычно достаточно если возникают споры то возникает эскалация без проблем там наименьшее общий руководитель обычно может принять достаточно хорошее решение Понятно спасибо и это был наш последний вопрос все остальные вопросы к докладчику можно будет задать поймав его здесь на площадке он будет здесь а а сейчас сложный вопрос чей вопрос понравился больше всего мы хотим подарить подарок мне очень понравился вопрос про конфликтующие эксперименты это то что А мы как как единственный вопрос который в котором мы чувствуем боль и у нас нет законченного решения Классно Спасибо а"
}