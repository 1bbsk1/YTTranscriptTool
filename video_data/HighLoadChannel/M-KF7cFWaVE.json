{
  "video_id": "M-KF7cFWaVE",
  "channel": "HighLoadChannel",
  "title": "Хранилище данных Avito: аналитика для микросервисной архитектуры / Артем Данилов (Avito)",
  "views": 7137,
  "duration": 3475,
  "published": "2017-12-11T00:47:50-08:00",
  "text": "всем привет меня зовут данил и портим я являюсь архитектором хранилища данных компании авито и сегодня я хотел бы вам рассказать о том как мы адаптировались внедрению микро сервисов нашей компании с точки зрения аналитики и хранилище данных сначала не расскажу немножко оба вид а потом немножко расскажу в хранилище данных расскажу о наших микро сервису почему мы начали переходить на них после этого расскажу о том какие у нас появились проблемы и о том как мы их решали что такое авито сейчас совета сейчас это сайт объявление номер 1 в россии мы входим в топ-10 рунета при этом мы третий сайт объявлений по величине в мире у нас около 35 миллионов уников месяц при этом примерно столько же активных объявлений общее количество объявления у нас примерно сейчас перевалило уже за миллиард 50 процентов трафика у нас идет при этом с мобильных приложений так как данных у нас очень много где-то в 2013 году мы решили начать внедрения хранилища данных компанию соответственно мы купили hp vertica сначала у нас было небольшое хранилище что первый год мы выросли до четырех серверов всего у нас было суммарно 11 терабайт данных и первую очередь мы начали загружать данные из наших внутренних исходных систем это собственно база сайта это экстрим и в итоге сейчас у нас кластеры из двадцати одного сервера всего у нас 100 1 терабайт данных на самом деле по более и при этом у нас сейчас ежедневно загружается данные примерно из 40 исходных систем если вы хотите подробнее узнать куда более подробную информацию хранилище данных и о том какая архитектура используется вы можете посмотреть наши предыдущие доклады которые были на холоде и мой коллега николай голов подробно рассказывал о том как у нас выглядит хранилище о том какие задачи мы решаем одним из основных источников данных нашем хранилище является extreme 2013 году году у нас всего было 300 миллионов событий в день сейчас у нас порядка полутора миллиардов это количество только растет и на самом деле quick stream является сердце нашего хранилища это основной источник данных он самый самый большой больше половины на и на все аналитики в компании делается на основе этого источника и например цифры которые я озвучивал на втором слайде они были получены собственно на основе этого источника то есть для нас это очень и очень важно для тех кто не в курсе расскажу о том что вообще такое клик стрим экстрим это поток событий которые происходят у вас в продукты либо продуктах если у вас их несколько для нас это это могут быть события как пользователя например это может быть просмотр какого-то объявления это может быть размещение нового объявления либо это может быть например контакт с другим пользователям например отправка сообщения мессенджеры при этом это также могут быть действия какие-то наших сотрудников например это может быть модератор который рассмотрел ваше объявление и принимает отклоняет его это может быть кто-то из отдела продаж и он может направлять сообщение каким-то частным пользователям и собственно произойти какие-то действия нам тоже интересно анализировать всю эту информацию поэтому соответственно все это собираем более того это могут быть какие-то робот это могут быть какие-то кроны которые совершают технические действия и отправляют все эти действия в 33 клик 3 может собираться с множества продуктов которые у вас есть компании для нас это собственно авито для нас это дома фонд это сайт о сайта библии не по продаже квартиры и аренде квартир и также эта статейка сайт который проверяет автомобили на их частоту все эти продукты лакируют свои действия в итоге этой сок попадает какие-то наши логе которых естественно много стоит заметить то что так у нас что такое все события события на самом деле представляет собой джейсон который говорит о том что произошло где произошло когда произошло и какого-то дополнительную и это событие есть какая то дополнительная обвязка какие-то дополнительные атрибуты которые могут быть вам интересны с точки зрения аналитики как как у нас с технической точки зрения выглядела генерация к экстрима где-то примерно еще год назад у нас был основной продукт авито который бэкон которого написано . он пошел множество событий пошлых вафлю и ндфл данном случае исключительно является агрегатором логов он роутер который перенаправлял эти события в mongo db в manga тебе все эти события попадали в гонке де беф cup в copied коллекции которые были настроены таким примерно образом чтобы хранить три дня данных зачем три дня на случай каких-то форс-мажоров если у нас происходит авария у нас все равно есть все события за какой-то за какое-то последнее время плюс для расследования всяких инцидентов затем все эти данные на batch основы попадает соответственно наши хранилища данных при этом мы стараемся делать так чтобы с момента с того момента как событие произошло где-то на сайте продакшене через два часа она уже была в хранилище данных и была доступна для наших аналитиков соответственно вот примерно такой pipeline при этом все события которые были написаны они были были написаны пекин где они были описаны как то по своему то есть каждый разработчик выделял какую-то свою логику которая собственно пушит вафлю int то есть общих общего какой-то формата не было так мы жили с 2013 года получается по где-то сентябрь 16 и в принципе нас знаем на все устраивало бы все так бы лаконично бы немножко хаотично бы развивалась этого доклада бы не было если бы не одно но у нас компании решили внедрять и переходить мы решили переходи на микро сервисную архитектуру распиливать наш монолит и соответственно у мешать связаны с его почему мы решили это сделать потому что кодовая база вид она достаточно большая и мы столкнулись с тем что внедрение новых изменений в продукт стала приводить к большому количеству ошибок при этом сложность этого внедрения привело к тому что мы стали очень долго доставлять какие-то изменения собственно в продукт наш танту market очень и очень сильно вырос и тогда мы поняли то что без и micro series окна собственно далеко не уедем для нас как для разработчиков хранилища данных мы сначала не понимали как на нас как на нас как на нас это повлияет но собственный брелок тому что все новые микро сервисы что все новые микро сервисы которые появлялись они тоже начали соответственно генерит новые события и все это привело к тому что у нас мышца резкий рост событий и мы столкнулись с проблемами ключевые проблемы ключевых проблем 2 первое это то что время которое разработчики и вообще сотрудники компании тратили на обвязку новых микро сервисов событиями очень-очень сильно выросла мы перестали в целом отвечает аналитическим потребностям у нас появлялись какие-то новые фичи но при этом мы не как не снились собирали по ним никакую аналитику мы не знаете как новый функционал влияет на наш пользователь хорошо им становится от этого или плохо при этом за за счет того что количество новых событий ощутимо возросло у нас начало началась деградация качества данных самых-самых событий сами события начали дублировать полип появились ошибки в том что кто-то забыл обязательное поле кто-то вперед что-то лишнее кто-то что-то старое сломал по сути начался такой хаотичный резкий рост и мы поняли что нам срочно нужно что-то предпринять для того чтобы разобраться вообще в ситуации мы решили посмотреть как у нас разные пользователи работают с нашим клик стрима как вообще этот весь процесс выглядит всего есть по сути у нас три стороны в компании это аналитики которые обычно инициирует создание новых событий и следят за всем этим процессом и дальше создают какие-то отчеты на основе этих событий у нас есть backend разработчики которые все эти события добавляют код сайта и есть также пвх разработчики которая все эти события загружают соответственно в хранилище данных представим что вы бэкенд разработчик и вам прилетела task на тему того чтобы добавить какое-то новое событие возможно изменить старые так как в бэг-энд разработчик вы не очень часто работаете с аналитика и вы не очень на самом деле представляете что такое quick stream и первый вопрос который остается что это вообще такое следующий вопрос который ведут вами стоит это какие поля необходимо выписать события а какие поля из этих а такие атрибуты являются обязательными какие атрибуты являются обязательными для десктопа а какие для может быть приложения на андроиде и все это у нас из мы как-то четко немало при этом за счет того что раньше у нас есть backend был абсолютно на php у нас не было никаких примеров у нас не было никакого опыта написания этих событий на других языках и соответственно нам сразу пали полетели вопросы о том как писать событий на примерно год как писать событий на питоне как писать за выйти на каком-то другом языке и помочь мы никак не могли нашим разработчикам и последний вопрос который у них часто возникал это куда вообще писать в какую коллекцию в манге это должно прилететь как и дальше вообще кто с этим событиями работая то есть это не то что было не понятно если это все немножко проанализировать становится понятно что ключевых проблем и тут 2 первое это то что у нас нет никакого общего формата по генерации этих событий и у нас нет никаких инструментов которые позволяли бы для новых языков как-то удобно генерировать и события все это привело к тому что каждый разработчик стал пилить свой велосипед этих велосипедов и появилось огромное количество следующая проблема в том что из за того что все эти велосипеды писались вручную постоянно допускались какие-то ошибки самое причем иногда эти ошибки были до нелепого достаточно глупы например иногда забывали добавить время события события и поэтому получалось что не знаю два дня льется поток событий и мы не знаем когда эти события происходило просто непонятно часто когда добавляли новые события могли сломать какие-то старые то есть например как-то например у нас как-то сломали события просмотра телефонов в объявлениях поэтому и чинили во 2 дня поэтому мы не могли посчитать за в эти два дня нет ни конверсию какой он какая у нас есть на сайте все тесты которые проходили на сайте в это время все можно было просто выбросить потому что это самая ключевая метрика она была сломана и все это вот началось именно в этот момент и при этом часто начинали писать какие-то дополнительные атрибуты которые никому не нужны и с которую непонятно что делать теперь представим что вы аналитик и перед вами стоит задача собрать много классных метрик сделать новую аналитику по вашему новому метро сервису и либо каком-то продукты первый вопрос который у вас возникли как как собственно и не добавить огромное количество новых событий как это сделать быстро и безболезненно при этом как посмотреть какие уже событий существуют чтобы возможных не за дублировать при этом если вы посмотрите что-то неправильно что-то неправильно велика вероятность что вы за дублируйте то что уже существует достаточно давно когда она липка даст очень много при этом каждый занимается какой-то своей областью и совершить ошибку очень очень просто все что вы хотите залакировать вам как-то нужно объяснить вашему backend разработчику донести эту информацию чтобы ему это было сделать просто и он это мог сделать быстро при этом и вас могут возникать вопросы какие-то старых событиях в старом событие происходит мистика там льются какие-то странные данные и вы хотите понять собственно рамках какого-то ска это делали события кто это дело кому нужно задать вопросы при этом к нам пришли коллеги из дома фонда я разработка находится на самом деле не в россии и они даже не говорят по-русски и у них стала задача тоже обязать есть продукт события и калек стрима чтобы могли делать сквозную аналитику из и среди пользователей вид и среди пользователь дома фонда и видеть как возможно пользователь ходят между этими продуктами и стал хороший вопрос а как это ценить нашим коллегам и завтраки также это сделать если если выделить ключевые проблемы которые были озвучены на предыдущем слайде то можно понять что у нас нет никакого общего языка общения между всеми ролями которую часто в данном процессе между backend разработчики медовуха разработчики постоянно возникают какие вопросы нужно кому-то идти что-то спрашивают что-то согласовывать в общем сложно при этом из-за того что у вас нет в удобном виде информация о том как какой какие вообще событие чувствует о том какой legacy есть вам очень сложно потом всем ориентироваться особенно сложно ориентироваться в истории изменений какого-то события чтобы возможно проследить какие-то баги в прошлом либо понять какие-то аномалии и вы при этом может легко за дублировать уже существующий функционал для для нас для 2-х разработчиков все это вылилось примерно в то что на нас полилась просто тонна вопросов мы перешли в режим работы или большие кидай дальше нам пришлось очень нам пришлось на все эти вопросы замечать все это пришлось разгребать при этом за счет того что качество событий стала падать постоянно кто совершал какие-то ошибки нам приходилось как-то обнаруживать расследовать коммуницировать общем начались проблемы при этом мы словили интересную проблему связанную с тем что и мы изменили очень старое событие и выпилили из него половину атрибутов при этом смотря поток событий который приходит на текущий момент мы увидели то что эти атрибуты они до сих пор приходят в это событие мы долгое время думали о том что это баг соответственно общались нашим разработчикам думали как это все убрать но ключевая причина крылась не в этом а ключевая причина причина крылась в том что обнаружилось какое-то старое приложение которое в большом количестве генерировала это событие и и мы не могли понять это легитимное поведение или это все-таки ошибка проблема здесь заключается в том что мы у нас нас не было никаких версий событий и мы не дали понять что новое событие с новым поведением может что старая событие которое было на сайте может на самом деле приходи течение долгого долгого времени может она еще где-то в legacy и тогда мы поняли что нам парад собственно что-то предпринимать если здесь посмотреть какие-то ключевые проблемы то для нас здесь ключевая проблема то что все эти вопросы упали на нас это что у нас нет какого-то versio нирования события у нас нет схемы событий и соответственно не обладая этой схемой мы не можем право лидировать наши события на тему того является какие-то аномалии в этих событий и легитимным поведением или это все-таки ошибка и тогда мы осознали что в условиях активной децентрализации всей нашими структуры и быстрого роста новых типов событий нам необходимо как-то для того чтобы собственно масштабироваться дальше нам необходимо наоборот централизации нам необходимо некая единая . знание о всех наших событиях и тогда мы поняли то что нам необходимо сделать некое центральное хранилище метаданных о наших событиях сделать нет единый справочник какие требования каким требованиям должен отвечать этот справочник он должен содержать некую базу информацию о том что вообще-то о том как событие называется о том какую нибудь индикатор какие у него есть атрибуты куда оно должно приходить то есть некая самая базовая информация литнике базовыми то даны об этом событии как дополнительным требованием поняли что нам необходимо научиться нам необходимо обличить максимально жизнь нашим backend разработчикам и научить наш новый справочник дилере для них код который не могли бы использовать для отправки этих событий причем так как языков много все это должно происходить на такая возможность нужно быть разных языков соответственно для этого мы внедрили языковые пакеты для наших backend разработчиков таким образом что разработчику больше не нужно думать и писать какой-то код руками он просто заходят указывает событие указывает язык справочнике делит ему нужны код и он просто его копирует продукт до его действие свелись минимум при этом так как мы этот код генерит мы самостоятельно и это у всего кода общая схема мы можем начать наконец-то лидировать наши события на наличие какие-то проблемы их на проверять что заполнена все нужные обязательные атрибуты что они забыли ничего что события нормальное хорошие чистое целое при этом если это происходит это на тестовой среде мы можем сразу поднимать ошибку если это происходит соответственно уже в продакшене мы можем просто кидать предупреждение о том что продакшена все-таки что-то доехал кривой соответственно так как у нас есть центральное описание всех наших событий мы наконец-то можем гарсиа не ровать все изменения в них и если события как-то меняется мы можем у него элементе его просто версию и присылать версию события сразу экземпляре событий таким образом мы можем сразу понимать всю лег более того у нас появляется возможность взять какие-то дополнительные метаданные которые могут быть полезны так как часто возникали вопрос о том кто делал события когда дело в рамках какого-то ска дело мы добавили такие атрибуты как собственно о нир события и тоски которые влияли на это событие таким образом любой человек может зайти справочник посмотреть всего историю изменений посмотреть в каких задач это делалось и так как у нас были какие-то старые уже гайды которые не отвечали нашему актуальном состоянии мы переписали все гайд и написали для разных ролей и стали активно посещать всех о том как вообще сейчас можно классно и удобно работать с новым нашим справочником немного про куда генерацию на слайде представлена представлена генерация события ногой питоне одного и того же события случае гул'дан импортируется некая схема события стандартная для события которое происходит доступен и при этом добавляется лишь одно какой то добавляется лишь один дополнительный атрибут который в данном случае называется стыд и и все вся проверка зашито в каких-то базовых классов и тот же самый код для бетона если посмотреть то выделен тот на слайде представлены общие части которые можно увидеть и в том и другом событий которые собственно можно скринить или другого языка то есть это вот общие элементы для данного события в этот же самый момент за счет того что он оставили появляться новые микро сервиса мы поняли то что наши микро сервис и геометрию за собой общаться событиями для экстрима раньше такой потребности не было сейчас к нам стали приходить backend разработчики и говорит о том что блин я пилю какой-то новый классный сервис и я хочу читать в реал тайме события которые происходят в продукте не хочу выходить в мозгу не хочу хранить в хранилища данных как мне вообще-то все сделать до этого все продукты которые которым нужно оперировать было экстримом они хотели напрямую реплику забирали оттуда события но так как vertica остается на два часа иногда бывает чуть больше это не очень удобно тогда мы поняли тоже то что нам необходимо некой единой шина данных для того чтобы ответить этим потребностям фриде не умел этого делать нет это просто достаточно простой агрегатор логов поэтому мы решили написать свою жену она написана и скилл на ее реализацию ушло где-то полгода на слайде представлена 4 микро сервиса это micro series регистрации нотификации поиска и объявлений которые как-то между собой взаимодействуют напрямую но при этом все они лоббируют событие a quick stream в шину данных если это все так же доезжает мангу но у нас появилась возможность каким-то нашим микро сервисом подписываться на события которые происходят одной из важных задач которая перед нами стояло это научиться поль научиться показывать нашим пользователям в режиме реального времени чистую статистику по просмотрам объявления по контактам очищенную от ботов так как ботов достаточно много нам было важно показывать им в реальную правду и у нас появилась и micro series сегментации который забрал несколько простых эвристик которые были у нас хранилище данных по поводу очистки от ботов и стал слушать события и собственно решать кто будто не вот этот миг россии раз написано лямда архитектуре он 1 день забирает данные сохранения данных очень детальные с огромным количеством разных эвристик и в режиме реального времени применяет простые эвристики соответственно решает кто плохой человек а то как-то собственно очень кто-кто человека кто вообще не человек и после этого у нас появился микро сервис статистики который точно также слушает событие extreme ходит ли pro series сегментации и понимает нужны ему для минске тический счетчики или не нужно и по факту мы смогли наконец то решать эту задачу если вы хотите узнать какую-то более подробную информацию о наши шине вы можете посмотреть доклад антона сухова которое было на предыдущем редкости он подробно рассказывает как это все работает как-то построена на ней скилл и вообще какие есть возможности и какие есть недостатки и почему и собственно выбрали энеску к чему это все привело сначала постов как у нас матрица резкий рост нам потребуется какое-то время собственно чтобы осознать то что что-то идет не так и что нам необходимо срочно что-то предпринимать после этого у нас ушло порядка четырех месяцев на то чтобы придать новый справочник а то чтобы рассказать им о том что это существуют и потихонечку начать его применять везде до этого момента пока писала с первой группе на брег нам при двух а разработчикам приходилось делать огромное количество лишней работой всех консультировать всем отвечать чтобы отвечать текущим требованиям по русски постав как у нас появилось имя пию для нас это проблема исчезла и соответственно затем мы сделали вторую версию нашего справочника события но об этом я расскажу чуть попозже как для нас стал стала выглядеть генерация событий quick stream у нас появились новые продукты которые пушат свои события флик стрим они в данном случае пушту же где есть вместо флинта есть и роботе все эти события нашими к сервисам плюс все также направлять с бытием мангу micro series и ходят слушают соответственно эту шину либо ходят иногда верьте q и делают какие-то действия и все свои результаты точно также управляет ей спи наверное на этом можно было в целом было бы закончить доклад сказать что все было супер мы молодцы мы решили проблему но на самом деле это не совсем так естественно мы столкнулись с какими-то трудностями и об этом расскажу как раз сейчас о чем и не подумали сразу о том что кроме единого справочника события нам также необходим единый справочник все наших атрибутов всех наших событий для нас это было не очевидно но стало достаточно быстро очевидно и нам пришлось делать новую версию нашего справочника о том с какими там собственным проблемами столкнулись то сейчас расскажу при этом мы поняли что мы забыли добавить много много полезных метаданных и нам пришлось их потом проходиться по всем событиям руками добавлять эти метаданные которые могут быть использованы для какой-то дальнейшего материализации все у этого процесса которые могут быть полезны для хранилища данных и в целом для аналитики и приводом при этом мы столкнулись такой задачей задачи перевода всего нашего legacy всех наших событий которые уже существовали в коде на новую схему мы думали что мы быстренько пройдем регуляр коми все заменим может быть это подъем руками она оказалась что это невозможно так просто сделать как вы думаете сколько существует способов чтобы назвать атрибут который вы будете передавать идентификатор вашего пользователя продукте мы насчитали шесть это вот все что писалось наших событиях 1 естественно самый логичный способ это просто писать юзера эти с нижним слышим то есть все все понятно в целом можно его убрать и писать просто через пробел тоже достаточно часто встречалось у нас можно и пробелы убрать и писать слитно а можно еще убрать вообще слово иди просто писать юзер но если вы знаете как манга хранит данные на диске то название собственно атрибутов на тоже хранит на диске она их конечно жмет но не всегда хорошо поэтому можно стараться оптимизировать это и делать название пали в манге максимально короткими соответственно у нас стали появляться такие поля как uid а в некоторых случаях просто у то есть это совсем гуру оптимизации и когда разработчик приходил ему нужно было создать новое событие ему приходилось выбирать сами все между всеми этими полями ему не было понятно чем они отличаются при этом и столкнулись с другой проблемой что в одно поле могут передаваться разные данные долгое время у нас поле мид передавался одесских метро но какой-то разработчик решил что в принципе вода поле можно еще передавать адэшника никого нашего внутреннего справочника и когда у нас появились эти данные мы с долго не могли понять что уже не так что у нас случилось с метро при этом ничего можно развлекаться с типами данных как вы думаете с помощью каких типов данных можно вообще времени описать у событий описать его время когда на произошло строка да это понятно естественно сначала мы начнем со временем то есть от самой самый логичный способ но можем передавать или стемп стемп это в таком случае это будет int если мы хотим еще блокировать микросекунды либо миллисекунды то это все превращается во флот но есть у вас что-то пошло не так вы это все можете обернуть с любой из трех типов ешь и соответственно приходить вам может все что угодно и тогда мы поняли что нам целом необходим единый справочник сделанный едины справочник наших атрибутов таким образом чтобы при создании нового события разработчик мог просто в формочки накидать не разработчик над никому просто формочки накидать нужным и поля если какое-то поле у не нашел он заходит это справочник и вот уже создает при этом у нас также было лидера валось типы полей и все также работала по этой же схеме следующий следующий пункт который мы стали доделывать это какие-то дополнительные метаданные ваши все события которые происходят у нас продуктах их можно классифицировать примерно следующим образом это либо просмотр страниц пойду например просмотр карточки объявления либо это контакт например отправка сообщения массаж для просмотра телефона и еще есть разные события которые мы считаем контактами если мы для них считаем конверсии нам их важно отделять это какие то прочие технические события при этом когда встает задача например для нового какого-то продукта например для дома фонда добавить обрезать его аналитикой нам это очень сильно помогло потому что новинки которые описывали такие события должны существовать на сайт они просто сразу разметили новые события этими атрибутами и и нам в дальнейшем не пришлось там узнавать какое событие что себе представляет при этом так как у нас при этом мы внедрили еще вторую классификацию то уровень логирования на мне очень интересно наши продуктовой аналитики учитывать какие-то технические события показ каких нет сниппетов of the sad жесты что не такое поэтому все это остается только в своих данных и никуда дальше идет все остальные события попадают в наши отчеты при этом у нас есть детальный отчет который клика циона где-то на счет по трафику который кольцо она очень и очень сложный чтобы он не деградирована со временем мы в него по сути передаем только очень рафинированный такой список событий очень ограниченный и и все внедрение двух этих дополнительных этих атрибутов позволило нам по сути целиком автоматизировать нашу учётность с точки зрения клик стрима если у вас появляется новое событие контакта она автоматически попадая этапа все отчеты и автоматически попадают в нужные нужны срезы по отчету и в так сейчас когда у нас появляется новые события мы сразу же начинаем и новые новые какие-то микро сервисы новые продукты нам больше не приходится как то вручную поддерживать других как-то поддерживать все это сразу автоматически у нас попадает в отчетность про legacy когда перед нами стала задача перевестись legacy наши новые языка вы и пакеты и мы столкнулись с тем что мы не можем просто пройти с регулярными как то это попросту мы сделать мы поняли что нам нужно как-то мотивировать всех наших бренд разработчиков перейти на новую схему поэтому мы естественно числе с просвещения стали рассказывать о том что ребят смотрите вы сделаете большое дело если перейдете на новую схему но при этом нам необходимо им было дать какие-то еще удобные инструменты чтобы них была мотивация переходить на новую схему поэтому мы дополнительно реализовали для них real-time monitoring событий таким образом не видят что в случае как случае какого-то тепла меняется сразу некоторые метрики некий поток событий некоторые продуктовые метрики при этом мы реализовать для них возможность тестировать наши события о том что раньше особо никто не тестировал и таким образом у них появилась первая прямая мотивация чтобы переходи на вы схему что мы планируем сделать дальше в планах у нас ближайшее время целиком автоматизировать всю нашу загрузку в хранилище данных и забыть о поддержкой sli стрима вот вообще сейчас у нас иногда происходит еще иногда еще требуется ручная работа 2-х разработчика чтобы покинуть это дополнительно новые атрибуты которых до сих пор не существовал в продукте либо мы по сути все большим и большим или какой работаем требуется соответстви мы планируем это целиком автоматизировать при этом мы хотим добавить в наш сервис который занимается сегментации наших пользователей как можно больше эвристик чтобы возможно отказаться от лямда архитектурой и увеличить частоту в сенате статистике которую мы показываем пользователю при этом за счет того что у нас появилась наша новая шина данных у нас появилась возможность наконец-то делаете некую стрим аналитику в режиме реального времени раньше у нас такой возможности не было но сейчас мы по сути планируем сфокусироваться на том чтобы переходи целиком на real-time аналитик при этом у нас как какая-то наша глобальная цель появилась возможность обвязать как какая-то глобальная цель мы хотим сделать так чтобы события в нашем продукте по большей части появлялись низ инциативы аналитика с инциативы разработчика чтобы эти события были полезны ему и чтобы при написании нового микро сервиса он мог сразу запилить может быть 80 процентов событий которые буду в конечном итоге микро сервисе без участия на лети к просто перес пользовал какие-то старые события таким образом скорость обвязкой аналитиков все нашими структуры будет гораздо выше чем сейчас таки можно из этого сделать выводы если вы сталкиваетесь с тем что у вас начинает происходить резко децентрализации все уши архитектуры вам не и вы хотите как-то эту децентрализацию контролировать вам необходимо задуматься над тем чтобы у вас был были некие единые метаданные собственно о том что вас детализован то есть в данном случае это клик stream поэтому у нас появился центральное хранилище метаданных и наших событиях которые обладают всякими дополнительными полезностями и облегчает работу всех при этом мы внедрили центральную мы принтере ледяную шину данных которые нам позволило делать уже сейчас много приятных вещей и в целом позволяет нам дальнейшем перейти на какую-то real-time аналитику при этом за счет того что у нас появилось множество метаданных которых раньше не было у нас появилась возможность автоматизации всего что связано с клик стримом таким образом наше время мы автоматизируем целиком загрузку тех событий духа и при этом уже сейчас мы перешли на целиком автоматическую отчетность и не поддерживаем это никак брюшную в целом у меня все спасибо за внимание из поз есть вопросы готов ответить сэлфи залам пока он почти полный до здрав вопросик можно да конечно вы в другую сторону смотрите люди суть все и я понял хорошо смотрите какой вопрос предположим у вас появляются обязательные поля каким образом вот вот этой генерации автоматизированного пакет это учитывать все же работает на старом составе обязательных полей происходит это примерно следующим образом у вас появляется новый дополнена новый атрибут который является обязательным для какого-то события вы до пол вы добавлять атрибут указывать его обязательным а версия событий три месяца на один соответствие раньше у вас была версия 1 теперь у вас версия 2 вам необходимо этот код новый добавить в нужные места в продукт заново зачем это необходимо зачем зачем это нужно затем что не везде мы это можем делать нельзя мы просто это можем делать предположим у вас есть старый android приложение и вы не можете и она уже установлено у пользователя вы не можете поменять ним как ним как-то кот соответственно данный обязательный атрибут появятся только в новых версиях приложений новых версиях уже после тепло и появится где-то там доставки либо мобильной версии продукта то есть сейчас это сделанными таким образом еще вопросы друзья руку добрый день отлично спасибо большое за доклад скажите пожалуйста какое программное обеспечение вы использовали для хранилище метаданных построение построения справочников метаданных и вообще всех сервисов которые были связаны с работы с метаданными по сути сейчас это выглядит лечим образом база postgres весь бэг-энда php и мы целом все appy appy тоже как-то с помощью пахи сделано то есть старались максимально использовать тех технологий в которых которых мы очень сильной поэтому сделаем это именно таким образом без какого-то космос здравствуйте каким образом я тут да каким образом происходит внедрение событий в новый сервис у которого их еще не было то есть мы выпускаем какой-то сервис и разработчик понимает что им нужно повесить событий на кита операции на какие конкретные и кто ему это говорит на данный момент принятием решением какие события должны существовать микро сервисе и инициация всего занимается в основном аналитики бакен разработчик просто внедряет код но в дальнейшем мы планируем что разработчикам будет понятно удобно и полезно самим внедрять эти события без участия аналитика пусть даже он совершит этом ошибку там что-то может быть за дублирует что-то сделает лишние но если он на 80 процентов без участия на лети к дабы обяжет микро сервис всем логированием это будет очень очень круто можете сэкономить огромное количество времени здравствуйте вы смотрите спасибо за доклад очень прикольную схема вопрос следующий кактус фронтенда собираете событию и как-то все ложится на эту схему как мы с front-end и собираем события ну по сути у нас есть специальные ручки через который мы можем прокинуть у нас есть у нас есть грубо говоря специальная пиксели картинки которые привет при отображении на фронте которых у нас генерации какие-то события вопи сейчас это сделано так плюс есть часть метки которые мы не губ не ешь комплекс экстрим а шлем напрямую например в графит хорошо спасибо раз раз раз спасибо за доклад у меня есть вопрос по поводу того как вы боретесь с дубликатами сообщений и как вы устроили инфраструктуру для 1 ссылки событий в случае если сервис приемы их не доступен как мы были с дубликатами по сути сейчас мы стараемся просто таким образом чтобы их вообще не допускать их количество очень сильного пола по 100 как мы пришли на новый справочник но те дубликаты которые уже существуют в legacy но по сути просто через какие-то тоски их выпиливаем как мы их обнаруживаем но это на самом деле не сложно сделать хотя бы по описанию целом по типу по описанию же события понятно на сколько она будет дублировать какое-то уже существующие то есть сейчас уже посмотрим выпили маме с того что есть нет я имел ввиду дубликата и не по описанию сабли а по факту их возникновение нас такого не возникает два у нас вообще не возникает дубликатов когда одно событие отсылается на дважды и где-то дублируется но представим ситуацию на бэкон пришло события он сгенерировал попытался отправить разрыв эти события ушло принято но при этом ответ его принятию не пришел на букинге алогично период править это событие или вы этого не делаете в данном случае мы этого не будем делать если у нас вдруг оказалась шина данных недоступна по какой-то причине это собственно ваш второй вопрос мы не будем это копить на по кэнди потому что событий много соответственно ну вообще это вся шина данных устроен таким образом что вы отправляете сначала этого сложиться в локальный буфер на на пи каком то соответственно дальше идет попытка отправить это сообщение в шину все это н с ю самореализовываться за этим следит соответственно если там происходят какие-то сетевые проблемы я так понимаю что протоколы устюг строил таким образом что не происходит просто при рование если не пришел и не случилось это было согласования что один отправила второй получил от этот отправки то события не пойдет дальше понял спасибо подскажите пожалуйста как вы организуете события в цепочке как мы организуем событие в цепочке как мы реализуем событию цепочки в целом сначала сначала мы берем на сессии сессии у нас есть внутренний определенно сессии которая что мы считаем сессии и и соответственно backend умеет правильно прокидывать индикатор сессии и это на самом деле такая самая одна из самых самых больших цепочек но если требуются какие-то реализуют более узкие цепочки у нас специально есть поле в которое на основе там cookies пользователя на основе собственно требуемых на основе того чего формируется эта цепочка на примерку к сессия нахождения на определенной странице еще что то мы просто пишем это по сути в атрибут индификатор цепочки вот как раз с спасибо за доклад и вопрос такой как вы избавляетесь от событий которые уже не используются то есть у вас есть новые версии вы добавляете параметры да старые перестают использовать в какой момент вы понимаете что они не нужны их можно удалить и второй вопрос как вы поступаете ситуации если у вас есть параметр в событий который добавляется и старые событий уже становится в принципе вам не нужно вообще то есть без этого параметра на в не интересно да я понял ответ на первый вопрос случае если этот столб или случае там или в случае если эта мобильная версия сайта переводим по сути силами backend разработчиков они могут произойти заменить код перед тепло и все и все будет ок случае если это какие-то мобильные приложения виде android ios еще чего-то у нас нет никакой возможности перегенерировать эти события и по сути мы избавляемся только тем что отказываетесь in целиком из какой-то версия приложения и сейчас мы стараемся сократить количество весе приложения которые нас находится поддержки потому что внедрение поддержка всего api и поддержка старых версий достаточно дорогая про второй вопрос ну собственно если мы убираем какой-то атрибут и пони если аналитик убирает какой-то атрибуты ему становится понятно что события нам не нужно он может снять галочку что она активно такая галочка есть при очень и после этого это событие перестанет учитываться где-либо то есть это некая с галочка которая поднимает вот прямо сейчас отключить эту статистику в дальнейшем если он хороший аналитик он поставит осно backend разработчиков на тему того чтобы код который генерирует о событии выключить ну удалить просто пожалуйста слева вот смотрите для разнообразия вижу да здрасте интересный доклад спасибо большое а вот по поводу в микро сервисов и баз данных хотел уточнить note с ним микро сервисами они же как независимый то есть как-то изолированной а все как бы вот они в одной базе данных использует одну базу или у каждого микро сервис свои а базы данных но просто я сею них один общий справочник то как это вот не по определению у них у каждую для сервиса своя база данных которую они используют для своей работы но именно для отправки лаков они используют кот заранее сгенерированные справочника который пушит это все в шину данных они не обращаются никакой дополнительной базе данных для того чтобы этот код скушать понятность просеивать тут еще да пожалуйста спасибо за доклад меня такие два вопроса значит вы versio нир уйти сами события и при этом данные которые вы собираете вы используете для аналитики я так понимаю в том числе исторической какой то это означает что когда приходят какие-то новые события или меняются их версии достоверность или вообще возможность корректно анализировать по всему объему исторически накопленной информации исчезает что вы с этим делаете это первый вопрос и второй вопрос что-то про тестирование скажите то есть где какие есть барьеры чтобы изменение которые вся команда делает не обрушили про мы не обрушили возможность видеть там хоть какие-то результаты анализа спасибо про первый вопрос вся наша отчетность целым устроен таким образом что она хранит агрегаты какие-то нас есть какие-то отчеты которые хранят максимально сырые данные и в случае если у нас вот при всех изменениях ну по сути если у нас меняется какие то события которые меняют и на бизнес-логику они никак не влияют на те агрегаты которые уже есть но и отчеты которые сделаны в максимально детализированного самом виде нам приходит соответственно этот бизнес-логику тоже поддерживает все это делается на основе просто коммуникации аналитиков и деваха разработчиков за счет того что мы скажем так по одну сторону баррикад мы очень тесно с утра мы работаем то есть то есть реально то на чем вы централизовано эта модель агрегатов вот это вот это то что неизменно даже в на линии ваша модель да понятно второй вопрос связанный с тем как мы что мы делаем для того чтобы из много изменений не обрушили старая сейчас по сути у нас все самые критично важные события проходит обязательное тестирование то есть просто есть определенные функциональные тесты и на мобильных приложениях и на кофе доступно когда запускается собственно сиси день происходят тесты они пробы залакировать событий если событие дошли до тестовых коллекциях манги то все ок это считается пройденным это дальше можем хотеть если не дошли мы соответственно не пускаем это все в продакшн то есть не проверяете что агрегаты вот эти корректно собрались донат они сами агрегаты но сырые события на понятно так пожалуйста здравствуйте сейчас такой вопрос как расследуете инциденты ну такого с микро сервисной архитектурой если к примеру проходит через несколько сервисов и где-то падает каким образом инциденты вас расследуется у нас события в любом случае первоначально когда один миг россии русские не вид события он управляет эту шину данных и и таким именно если речь про события клик stream если речь про цепочку общения не знаю по легким ешьте тебе как там полякам грудь что тебе кто-то кого-то мы не занимаемся расследованием у нас есть один на youtube архитектуры который поддерживает весь переход на микро сервисы на распил и у нас есть инструменты ну пока не мы сейчас хотим на реализуем которые будут показывать как у нас ходят как у нас микро сервис за другом общается потому что без этого достаточно сложно но и он с точки зрения событий телекс 3 мп все первоначальная падает в есть и и как минимум там мы отслеживаем все базовые метрики сколько событий что и как то есть правильно понимаю микро сервис вот именно инструменты для определения как проходит мы информационное событие вы свои используйте да да пожалуйста спасибо за доклад вопрос не по логике я по инструментам подскажите как себя ведет и на скан таких нагрузках и не пробовали ли клик house персики и носки сюда ведет нормально пока внедряли были там порой инцидентов но в целом полёт отличный флюид на самом деле работал гораздо более нестабильно чем минске почему мы не используем сейчас crack house даже мои вас пользу на самом деле внутри компании сейчас для как альтернативная графиту почему не используем конвертики потому что еще просто ну именно для целей единого хранилища данных продукт еще достаточно вселенной на ранней стадии то есть в него можно писать какие-то не изменяющийся данные виде каких-то временных рядов но если нужно писать огромное количество изменяющихся данных уметь делать обретает или ты позволять делать сложные join и писать вообще любые запросы в базу данных the tree house не подходит то есть сейчас мы позволяем нашим аналитикам прийти написать найду пиши запрос и с вероятностью не знаю процентов 80 база сможет его переварить и выдаст результат случае cry хауса нужно указывать очень много очень правильно писательский или запрос мы не можем такой позволить плюс за счет того что нет нормального еще до лета и нет учетом ряда вот тех базовых базовых требований которые нам нужны мы не можем перейти но если со временем они внедряться мы как бы перейдем без проблем спасибо просто прекрасно последний вопрос спасибо спасибо за доклад вы рассказывали про языковые пакеты для разработчиков а можете пояснить вот если происходит изменение справочника централизованного вы новые пакеты раздаете то есть в каждом микро сервисе нужно какой-то апгрейт делать или как-то прихода в каждом и красились необходимо будет сделать upgrade pack это сделано то соответственно так как одно событие зачастую бывает но максимум там в двух-трех микро сервисах но не везде прям мы пока не сталкиваемся с проблемой сложности этой операции соответственно если у нас если нам будет необходимо сделать прям целиком динамическое ходить справочник забирать метаданные понимаете как на сейчас правильность генерирует события то есть не вредить код сам-то здесь стают много там более сложных вопросов думаю со временем мы их решим но пока просто нет потребности вы при компилируете получается каждый все спасибо спасибо большое артем данилов авито"
}