{
  "video_id": "eke2h9fGtu0",
  "channel": "HighLoadChannel",
  "title": "Распознавание речи: как сделать Speech-to-Text своими руками / Иван Бондаренко (МФТИ)",
  "views": 30528,
  "duration": 3337,
  "published": "2019-01-14T00:09:17-08:00",
  "text": "всем привет меня зовут иван меня уже представили я хочу вам сегодня о способах и технологиях созда система распознавания устной речи для русского языка своими руками из open source ных компонент бесплатно и без sms вот но прежде чем об этом рассказать пару слов скажу о себе я работаю в московском физтехе по проекту а и павлов этот проект посвящен созданию открытой системой диалогового искусственного интеллекта также я работаю в компании да это монстр с который занимается внедрением результатов по диалогам и с интеллекту для практических задач и наконец я еще немного преподаю в новосибирском госуниверситете учу будущих разработчиков искусственного интеллекта чтобы они смогли подхватить за нами из наших ослабевших рук через некоторое время вот а еще я люблю театр новосибирск театральный город здесь много всяких интересных театров и один из самых интересных на мой взгляд театр старый дом вот вы видите вход в него действительно очень выглядит антуражно там ставит интересной пьесы в частности в конце сентября будет премьера спектакля пыль этот спектакль документальный посвящен исследованием в области искусственно интеллекта и машинного обучение в новосибирске поскольку спектакль документальный я кстати советую вам на него сходить будет интересно поскольку стык так документальной актеры имеют реальных прототипов и ребята михаил подклассов режиссер алина свирского драматург и другие ребята и в помощники они собирают интервью с множеством людей которые потом станут про образами героев спектакля они собирают интервью общаются записывают это все на диктофон людей много звука запись интервью очень много потом их брать и расшифровать вручную это просто адская задача бывает что и час беседуют и больше людей десятки соответственно возникла идея спектакль об искусственном интеллекте а может быть можно какие-то методы искусство интеллекта применить для того чтобы расшифровать эти записи не вручную а автоматически ok сказано-сделано мы поговорили с ребятами и у нас возникла интересная идея давайте мы сделаем систему распознавания речи которая автоматически бы перевела звукозаписи это текст пусть текст будет и с некоторыми ошибками тем не менее это гораздо лучше чем полность и править ошибки в тексте гораздо лучше чем полностью создавать текст 0 а как это сделать с помощью каких систему конечно есть пропили тарные системы распознавания речи всем известные речевые движке гугл с пищей пи ай движок от фирмы нюанс с американской насколько знаю он есть и в русской версии есть яndex есть центр живые технологии и так далее но наш проект идет во многом на общественных началах и соответственно мы решили а почему не применить open source на это для того чтобы создать систему распознавания речи автоматического стенографии рования интервью тем более есть опытные конструкторы которые позволяют создать систему что позволяет со своими руками мы попробовали это сделать таких у passwords систем тоже хватает среди них можно отметить сэму сфинкс ешьте кейдж такие вообще одна из самых первых систем подобного рода вот сейчас есть такая продвинутая система сыровато еще но может быть но она продвинута научно пони qoldi с нейронными сетями не так давно крупные гиганты эти индустрии типа байду или фейсбука начали выкладывать свои разработки танки погиб спич в eft лектор и так далее вот мы остановили свой выбор на своему сфинкс почему во первых c yмa сфинкс эта система с одной стороны имеющая под капотом мощную математику мы пару слов об этом скажем ну достаточно поверхностно не пугайтесь мощной математики здесь не будет в нашем докладе так вот она под капотом не достаточно мощную математику с другой стороны она очень легка в развертывании в настройки и она может работать буквально где угодно вплоть до встраиваемых устройств там есть вариант embedded поэтому ему сфинкс это наш выбор как же сделать с помощью этого конструктора распознавания речи на самом деле своему сфинкс как и другие опасные движки это некий фреймворк с помощью которого вы создаете собственную систему и нужно понимать какую архитектуру имеет эта система обобщенную схему классической архитектуры в которая реализована в своему сфинкс вот здесь на слайде представлена у нас есть некоторый звуковой сигнал который поступает на вход системой и система состоит из двух больших блоков акустика фонетический блок который анализирует сигналы выделяет из него признаки и на основе признаков распознаёт какие же фонемы в сигнале фонема минимальная единица устной речи по аналогии с тем как буква минимальное дениса письменного текста так и фонема считается минимальной единицей устной речи делает акустика фонетический блок это с помощью специальных моделей модели бывают разные мы об этом попозже поговорим наконец на выход выпуска фактически блок выдает цепочку фонем но цепочка фонем это еще сырое материалы из нее из этой цепочки нужно делать слова и вот этим занимается лингвистический блок он использует уже другие модели не акустика фонетические а языковые основанные на представлениях лингвистов и преобразуется почку фонем в слова связного текста семантические осмысленные все это можно сделать листами цэму сфинкс выглядит это может быть немножко пугающе тут у меня всякие схемы нарисованы этом нейронные сети марковские модели какие-то графы вероятностные но на самом деле давайте посмотрим не боги горшки обжигают как мы можем сделать такого рода систему давайте мы будем двигаться по очереди начнем с акустика фонетического блока итак что нам нужно для того чтобы приготовить пусть к фонетический блок ну во первых нам нужно нам нужен сэму сфинкс собственно движок open source ный он написан он состоит из нескольких компонентов сам движок распознавания пакет сфинкс описано чистом си и он легко протирается под разные платформы есть компоненты для обучения там сборная солянка из питона perla java используется вот есть другие компоненты и вспомогательные но алгоритм распознавания который резон сфинксе алгоритму деление признаков угадать им распознавания это только пол дела системе машинного обучения как минимум половину другую половину успеха а то и больше обеспечивает хороший корпус где взять корпус это одна из самых больших проблем разработчиков систем распознавания речи если специалисты по компьютерному зрению счастливые люди у них есть imagined начаты нас миллионов изображений с помощью которого они могут обучать свои не раз сеточки а потом уже их fine tune под конкретные задачи прикладные то разработчики с тем распознавание речи такого счастья лишены ну во-первых речь это не картинки картинки они и в африке картинки и в гренландии картинки одинаковые а вот речь она русская речь английское и французское они отличаются соответственно где брать корпус для русской речи с этим проблема один из немногих открытых проектов по созданию корпуса это проект фоксфорд такой мультиязычный проект в котором добровольцы заходят на сайт им предлагается что-то прочесть продиктовать они это диктуют оставляют свой образец голоса в базе и таким образом формируется корпуса например для английского языка на vaux fuji уже есть 70 часов звучащей речи нади кто ванны и разными пользователями сотнями пользователей для русского языка там которые часов поменьше только 20 но тем ни менее корпус весьма неплохой там больше сотни гектаров то есть учитываются особенности произношения разных дикторов разного пола разного возраста и можно считать что если мы обучим нашу систему на вот этом вот корпусе мы получим действительно диктор независимое распознавании фонем а это ключевой момент мы должны обучиться не под конкретного васю там или петю если мы подойдем к хорошему знакомому нашему просим внести вклад в искусственный интеллект на диктуй нам обучающим материалам и обучаемся то мы сделаем хорошую систему который будет распознавать нашего другого сию но уже не будет распознавать другого человека коты критическое требование корпусом для создания диктор независимых систем это вот мы нога диктор ность несколько сот как мы организуем процесс обучения на самом деле тут ничего сложного нету мы создаем папочку с проектом создаем в ней 2 подпапки et cetera и вов wave это у нас папка где будут лежать наши звукозаписи а не могу были рассортированы по диктором они могут просто кучей сигналов лежать а вот et cetera это папочки где папка где конфигурационные файлы для нашей системы лежат мы сейчас по очереди рассмотрим эти все файлы в целом здесь пока что на слайде не хватает главного файла файла который управляет сфинксом управляющий конфигурационный файл и как его получить очень простой командой ничего сложного космического нету как я уже говорил создайте папку с проектом заводите в ней 2 подпапки находясь в папке с проектом запускаете эту команду и вам kangaroos сонный файл по умолчанию которой сгенерируется в этой папке автоматически но теперь его нужно подтюнить для того чтобы получить систему во первых нам нужно вам нужно прописать собственные пути сам файл выглядит забегаю вперёд сам файл выглядит просто вам нужно прописать соответствующие пути и настроить параметры системы а что это за параметры там есть конечно вариант и параметров по умолчанию но не факт что у вас получится хорошая система если вы эти параметры по умолчанию ставите можно конечно относиться к этой системе как черному ящику что-то починить что-то подвигать авось получится но нет лучше всего эти параметры настраивать с пониманием того как она работает как я уже говорила пусть акустика фонетически модуль эта штука которая извлекает признаки распознают фонемы что за признак извлекается вот блок конфиг-файл а который отвечает за излечение признаков что это такое во первых что мы распознаем что за объект распознавания это звуковой сигнал звуковой сигнал математически это совокупность синусоид если говорить о технических аспектов его формирования мы записываем с определён наш сигнал 190 дискредитации также как картинку мы представляем в виде точек пикселей я приди и их яркости для монохромного изображения яркости до трех плоскостей света для цветного изображения то же самое для распознавания речи у нас есть точки амплитуды в каждый момент времени и вот сколько точек в секунду мы записываем такая частота дискретизации нашего сигнала здесь предложено по умолчанию 8000 герц то есть мы в секунду 8 точек пишем это качестве соответствующие телефонная речи может быть больше 16 тысяч герц может быть там 44 с хвостиком и так далее вот этот параметр отвечает за то какой сигнал мы ожидаем наконец что является определяющим особенностью сигнала то какие синусоиды в него вложен и а как определить синусоида если хочешь статой наибольший вклад дают сигнал провести спектральный анализ а можно ли провести спектрально ли у такого сигнала который показан на слайде вот вот это вот нет потому что он не периодически он нестационарный спектральный анализ например по методу быстро преобразование фурье провести нельзя но есть лайфхак на больших отрезках допустим секунда мы считаем сигнал нестационарным но если мы порежем сигнал на маленькие клеточки по 25 миллисекунд например вот как здесь показано вот видите как он на анализ вот крупно масштабное представление сигнала на участке 25 миллисекунд здесь уже что-то похожее на период наблюдается соответственно раз есть период то можно выделять частоты синусоид которые составляют от кусачек сигнала и проводить спектральный анализ берем окошко окошко скользит вдоль сигнала вырезаем этим окошком параметры и проводим спектральный анализ и вот здесь указаны параметры конфигурации файла которые определяют с какой по какую частоту спектр нам нужен обратите внимание если у нас частота дискретизации 8000 герц то если мы хотим получить допустим с трёхсот по 6 тысяч герц полосу спектр мы не получим у нас есть ограничения принципиальная теоретическая мы можем смотреть спектр до частоты в два раза меньше и частоты дискретизации есть к теорема котельникова либо за рубежом и называет теорем отчета и керимов найквиста вот так вот мы вышли энергетический спектр и вот как этот спектр меняется по времени является определяющей особенностью сигнала но есть вы посмотрите на слайд спектр очень шумный там куча всяких параметров которые связаны с акустическими условиями каким-то с индивидуальными особенностями говорящего и тому подобными вещами они просто захламляют процесс распознавания делает жизнь алгоритму сложнее надо как-то от них избавиться в это раз во вторых человек воспринимает речь достаточно нормально но у него есть некоторые нюансы связанные с тем что с ростом частоты раздражает разрешающая способность человеческого уха ухудшается человек вполне может отличить 200 герц и 300 герц но 3200 3300 герц уже ему отличить друг от друга сложнее то есть логарифмическое ухудшение идет ответственном и это все м это ухудшение моделируем с помощью мела шкалы запускаем умел шкале гребенка треугольных фильтров каждый feat с ростом частоты его основание расширяется ответственно большей больший кусок сигнала в частотной области он захватывает и количество фильтров мы определяем еще одним конфигом нашего конфигурационного файла можем задать 15 можно задать 20 может задать 40 разработчики своему сфинксы камин дуют по умолчанию убрать 15 для речи телефонного качество если мы распознаём речь более высококачественного более высокое чувство дискретизации возможно нам стоит повысить количество таких фильтров и в результате мы получаем красивый сглаженный спектр который уже для системы распознавания распознавать гораздо легче чем вот этот вот сырой спектр изрезаны всякими высокочастотными шумами окей значит признаки речи мы выделили мы научились их выделять научились управлять модулем вычисление признаков что дальше а дальше мы хотим на основе этих признаков распознать фонемы здесь представлена слайде блок конфигурационных параметров которые отвечает за распознавании фонем это три параметра это файл самими фонемами это файл с расширением dick with a dictionary это словарь транскрипции который знает система и наконец это словарь словарь филеров это называемых квази фонем давайте разберемся по очереди что такое начнем с в нем вот я уже говорил фонема это некий минимальный элемент устной речи по аналогии с тем как буква является минимальным элементом письменного текста так и фонема минимальный элемент устно речи но если с буквами все понятно сколько букву русском языке то с фонемами все гораздо сложнее ученые лингвисты до сих пор не могут прийти к единому выводу о том какая система фонем русском языке используются сколько их как их распознавать существует две больших таких научных школ и еще с советских времен они начали свое развитие ленинградское московская московская школа считает фонемы некими такими более-менее абстрактными единицами а вот ленинградская школа ее взгляды ближе к нам технарям программистом они считают фонем это то что непосредственно слышится в сигнале они какие-то более абстрактные единицы и вот мы в рамках ленинградской фонологической школы разработали систему фонем 54 фонема в русском языке для гласных почему так много букв то меньше а фонем больше дело в том что во первых для гласных фонем для гласных фонем есть ударный с безударной гласной это увеличивает количество ним во вторых там есть нюансы связанные с реализацией согласных некоторые вот так вот как будет выглядеть фонетическая запись фразы мама мыла раму да вот примерно вот так вот как показано на слайде видите у нас есть ударные и безударные гласные фонемы есть согласные соответственно нам нужно поделиться какой набор фонем будет использовать система распознавания речи речь воспринимается не как некий единый объект распознавания вот например картинка это единый объект распознавания речи эта структура из элементарных кусочков фонем стресс то нам нужно поделиться какими кусочками мы будем оперировать каким распознавание этих кусочков учить систему где взять эти фонемы для того чтобы сделать систему необходимо эти фонемы придумать тут есть два варианта во первых вы можете погрузиться в лингвистику и изучить что там ученые говорят например тоже не гродская фонологическая школа которой мне нравится больше придумаю система фонем а можно этого не делать можно собственно взять систему фонемы вот отсюда мы с моими ребятами из n buuren глистами предложили такую систему мои апробирована конференция в целом все норм ее можно взять система фонем именно отсюда хорошо с фонемами мы разобрались теперь словарь транскрипции savour the steps это словари всех слов которые знает наша система и для каждого слова написано транскрипция список фонем который вы образует последовательность фонем то есть помощью словаря трасс 30 мы начинаем постепенно переходить от уровня фонем уровню слов вот за этот собор strips отвечает приведенные параметры конфига как выглядит соваться strips это простой текстовый файл где каждая строка представляет собой пару слова его фонетическая транскрипция слова его фонетическая транскрипция вот фрагмент такого словаря здесь показан а как составить если мы допустим система фонем взяли us with hubby например а как составить правильно это scripts и опять-таки есть вариант следующий можно понять как человек говорит изучите закономерности устной речи и например у нас система общего назначения 800 тысяч слов мы носимся из слов сидим там выписан эти фонемы там месяц прошел выписываем 2 месть прошел золочевский запишем а можно опять таки не мучиться и взять уже готовые словарь с гитхаба здесь на базе национального корпуса русского языка составлен словарь наиболее частотных и актуальных слов и для каждого слова и слов проведена его фонетическая транскрипция более того для некоторых слов есть называемые альтернативные транскрипции дело в том как вы заметили в этом словаре отдельные слова определены есть например слова альплагеря я этим утром вышел из альплагеря на восхождение на кору например по алтаю раскинулись альплагеря это разные слова и они имеют разную транскрипцию соответственно для того чтобы учесть вот эта вот вариативность морфологическую вариативность необходимо по 2 а патрик раз клипсы на слово заводить плюс еще сами люди могут говорить не очень обычно они могут по разному например кит аббревиатуры там фсб там фсб разные варианты произношения но это же аббревиатуры собственном и когда разрабатывать этот словарь и мы позаботились о том чтобы учесть в эти вот вариативности и 800000 словоформ более менее нормально представлены в рамках нашей системы фонем это все три там до 105 можно пользоваться хорошо 800 тысяч слов там представлена а если вы хотите еще более крутую систему сделать на 800 тысяч слов а нам миллион где взять недостающие 200 тысяч слов неужели снова нужно вернуться к идее ручного выписывания нет к счастью во-первых кроме составления мы этот словарь тоже сами не вручную составляли мы сделали систему во первых на основе правил и словарей которые автоматически транскрибируются нашу наш текст это вот это вот пункте 1 представлена во вторых в ситуации когда допустим наших словарей например словарей ударений не хватает для того чтобы представить слова не известной системе мы сделали систему машинного обучения которое по по цепочке бутов может восстановить цепочку по ним с точностью выше 95 процентов соответственно допустим у вас появились новые слова которые вы хотите добавить систему сначала запускаете модуль на основе правил и словарей он более точный те слова которые удалось с его помощью транскрибировать добавляете словарь те слова которые с его помощью тоже сабирова не удалось скармливаете под системе машинного обучения она уже обычно там есть на гитхабе модели настроены и она уже по своему разумению генерируют транскрипции более-менее приближенные но адекватные с и css в действительности хорошо значит с фонемами составлен проспится разобрались фидер и квази фонемы что это такое во первых в любом звуковом сигнале кроме нашей речи есть пауза тишина и вот наиболее типичного квази фонема и the silence и вот мы задаем три таких квасе слова начальная пауза конечная паузы паузы в середине слова и все они транскрибируются одной и той же фонема и silence сил но в нашей речь в нашем звукозаписи могут быть не только тишина и речь какие еще могут быть филлеры квази фонемы ну например мы дома где-то у нас любимый котик мяукай он говорит мяу мяу мы где-то идем на станцию электрички там проезжает поезд он там туту автомобиль на как сон нажимает биби и тому подобные вещи эти вещи эти штуки они сильно мешает как распознавать речь система их начинает путать с фонемами соответственно на них тоже нужно отдельные модели построить и отделять их от обычных фонем и от пауза тишины вопрос как это сделать в корпусе в оксфорд есть только речи пауза там звуки относительно чистая а где взять вот эти вот неречевые события филлеры ну один вариант собрать самому на самом деле достаточно реалистичный вариант можно взять со смартфоном походить или диктофоном где-нибудь в общественном месте на улице дома заставить там кота за хвост подергать пункта мяукал вот и собрать таким образом корпус но есть вариант и другой можно скачать в интернете в интернете тоже достаточно много таких вот корпусов неречевых событий в отличие от речи людей неречевые события как я уже говорил они одинаковы во всем мире как изображения вот соответственно есть на как например соревнования там есть неплохой data set up a rose музыкальным каким-то звука записям под в к записям стук тарелки там щелчок мыши и тому подобные вещи вот их можно использовать для того чтобы сделать звукозапись филеров и завести в словаре филлеров отдельный класс допустим я у отдельный класс стук отдельный класс кашель и тому подобные вещи учет филлеров может повысить качество распознавания речи примерно на 10 15 процентов с признаками с фонемами с объектами распознавания со словарями трассы пса мы разобрались а с помощью чего мы распознаем сейчас у всех на слуху нейронные сети стильный модный молодежный способ распознавать что угодно но на самом деле нейронной сети не являются панацеей во всех ситуациях есть еще другие подходы в частности в распознавания речи используется классический подход который получил свою популярность конце 8 то годов с легкой руки lowrance arobin эра скрытые марковские модели собственно вот этот фрагмент конфига отвечать за скрытые марковские модели а что из-за название первых почему марковские во вторых что здесь что там в них скрытого что от нас скрывают давайте разберемся а двух подходах я уже сказал марковский процесс можно много математических определений приводить какие-то формулы но можно сказать проще марковские процессы такой процесс который развертывается во времени и при этом будущее процессы зависят только от настоящего то есть состояние которое процесс придет следующий метод времени зависит только от того где он сейчас находится от более предыдущих состояний он не зависит вот здесь просто я простой марковский процесс сменой погоды он конечно упрощенный во многом погода сложнее но тем не менее вот здесь есть состояние ясно светит солнышко есть облачно набежали тучки и есть осадки дождь или снег соответственно из состояния облачным можем перейти к в состоянии ясно так состоянии дождь или снег неважно в каком состоянии вы находитесь перед этим вот это вот марковский процесс и вот когда мы используем это получится вероятностный граф мы можем переходить и состоянии состояния сопряженной вероятностью также мы можем в текущем сцене тоже оставаться соплю на вероятностью когда мы строим такие вероятностные модели марковские они нам помогают отвечать на многие практические вопросы частности какова вероятность последовательности состояние погоды некоторый хайр вероятность того что солнышко будет светить там пять часов подряд сколь какова вероятность длительности наиболее такого наибольшей длительности дождливо периода и тому подобные вопросы которые актуальны хорошо а при чем же здесь распознавания речи вы спросите погода распознавания и где здесь а вот распознавание речи так просто не промоделировать для этого нужно скрытая марковская модель и представим предыдущую ситуацию прогноз погоды в предыдущей ситуации вы могли выйти на улицу и глянуть непосредственно на погоду ясно дождливо либо облачно а представьте что вы вот сидите без в последние два дня готовитесь докладывал конференции там вам на улицу выйти не когда вот ваша жена просто выходит на работу и вы видите взяла на зонтик или не взяла и вот поэтому наблюдению за своей супругой берет она зонтик или нет вы можете предположить а вот на улице сейчас светит солнышко или на улице сейчас дождливая погода сами-то вы безвылазно фигачить и в ноутбуке вот но какие-то догадки вы делать можете с предельной вероятностью то есть у на вы пытаетесь сделать предположение о скрытом процессе для нас смене погоды по наблюдаемому процессу потому как ведет себя жена берет она зонтик или нет и вот здесь добавляется еще одни элементы игреки как видите нас нас на y это алфавит событий наблюдаемых в данном случае алфавит простой два события берет же назвать не берет в случае распознавания речи там все сложнее у нас скрытый процесс эта цепочка фонем которую мы распознаем но мы наблюдаем и и не непосредственно мы ее воспринимаем через акустические колебания через спектр и вот то что я показывал как мы извлекаем признаки вот наши признаки это наблюдаемом мы наблюдаемое явление и вот по цепочке спектров мы пытаемся восстановить цепочку фонем в этом нам помогают скрытые марковские модели собственно параметры их фиксируется я сейчас не буду рассказывать про алгоритм там баума был слаб алгоритм прима обратного хода для настройки в тут у ариэль сфинкса об этом не плохо написана есть ссылки где почитать ну в общем так чтобы понимали как то это все под капотом устроены зачем нам нужны и спектральные признаки что это за модель и скрытые марковские там используются они будут работают так наконец значит с модулем акустика фанатически мы разобрались теперь давайте посмотрим а как же работает аналитический модуль как мы цепочку фонем преобразуем слова мы немножко об этом поговорили когда говорили о словаре транскрипций но слова в языке появляются не случайным образом они подчиняются плену закономерностям и вот учет эти закономерности тоже можно сделать при проектировании своей системы распознавания речи вот конфиг который определяет языковые модели языковые модели бывают двух видов во-первых до термин детерминированные когда мы говорим мы знаем какие слова идут за какими мы в этом уверенный и мы это моделируем другой подход для менее уверены в себе разработчиков это вероятностный подход мы не пытаемся предположить что вот слова мыло будет строго идти за словом мама арома в раму за словом мыло мы их делаем это предположение о том что скорее всего 105 вероятностью она blue таки но не точно на самом деле так тонированная модели тоже используются теоретически если говорить теоретически детерминированные модели лучше вероятностных они позволяют создать более or обосную более устойчивую систему и в маленьких приложения например кого-нибудь голосовой и vr меню или когда справочная система потом предварительное бронирование авиабилетов вы звоните кстати говоря такая система была разработана носит название система сирена 4 в аэрофлоте она есть моя студентка 1 даже я тестировала как можно с ней поговорить там на самом деле система сама ведет диалог активно она спрашивает у человека назовите город вылета ему ничего не остается кроме как назвать новосибирск шансов быть других нету назовите город прилета он там говорит город москва назовите дату вылета он говорит там 26 27 июня то есть лексика ограниченная способ постоения фраз ограничены и такой способ постреляв раз легко можно промоделировать это мир иной грамматикой существует ряд способов ее описания наиболее популярны в распознавании гсг в грамматика java спичек grammar формат он написан по ссылке но для более менее реальных практических приложений такой довольно сложно и практически приложение такой способ неприменим мы же хотим сделать систему автоматической расшифровки интервью а там люди могут беседовать на абсолютно произвольные темы и нам датомир на грамматике не помогут нам нужны вероятностные грамматики вероятностной модели как они выглядят как я уже говорил мы не пытаемся построить все возможные цепочки слов языке выразить их виде графа мы пытаемся взять выделить какие-то двойки-тройки слов например 3 грамма по двум словам о которых мы уже знаем мы пытаемся определить вероятность 3 слова вот есть у нас уже поступили на вход система мама мыла то она может мыть раму с большой вероятностью но можно также мыть синхрофазотрон теоретически может но вероятность этого очень маленькая одна десятая например таким образом мы формируем n-граммы для огромного количества текстов и этим грамм и они конечно поверхностно моделирует язык но тем ни менее неплохие достоверные результаты можно получать для того чтобы сфинкс понял наш инграма ему жить нужно подготовить специальном формате так называемый arpa формат он написан здесь по ссылке в документации ну а как их построить вы же не будете опять-таки вручную подсчитывать частоты всех слов в граммах что-то всех ingram опять-таки это может делать автоматически вам нужен инструмент и корпус инструментов много я вам рекомендую использовать слил это один из наиболее развитых инструментов для статистического моделирования зэка его использовать не только в распознавании речи но и в исследованиях по компьютерной мистики активно тоже и наконец здесь вам для того чтобы обучить инграм мы с помощью сри вам уже нужен не звуковой корпус не устно речь о корпус текстов большой-пребольшой корпус текстов чтобы ваш игра мы были статистически значимы чтобы они как можно большее число слов учли и вероятности для этих слов для связи этих слов были более менее адекватные что может быть примером такого текста таких текстов такого корпуса ну википедия с одной стороны но википедия тоже специфический корпус там энциклопедические тексты какие-то а мы же хотим сюда графе ровать интервью нам нужно что-то более менее разговорное на разные темы и вот нам здесь на помощь приходит национальный корпус русского языка января но к сожалению там есть лицензионные проблемы с доступом к игре нужно писать разработчикам ну пожалуйста дайте нам корпуса не может тут может не дадут но n-граммы на этом корпусе вплоть до 5 грамм они уже начитались сами и выложили в открытый доступ вот такая хитрость и сами сырые текст и получить сложно n-грамм пожалуйста открытом доступе лежат вот по этой ссылке можно скачать и можно взять использовать энграммы и использовать только утилиту из состава сил для того чтобы n-граммы из одного формата in кришна во привести в нужном формат arpa более того можно этого даже не делать мы это уже сделали за вас можете взять то что мы закончили нагиб хоп использовать и уже говорил там больше 800 тысяч словоформ и наиболее значимые вероятно частотные статически связи между ними слова формами у не граммы и граммы триграммы здесь в корпусе учтены уже варпа модели сжатый в бинарный формат но мы сейчас делаем систему распознавания интервью как я уже говорил там нужна система общего назначения а если вы хотите что то свое особенное сделать если у вас допустим специфические задачи голосовой чат бот например для выдачи кредита вы хотите для него рочева интерфейс делать для того чтобы для заказа пиццы соответственно вам вот этот мужик говорит мои вкусы очень специфичный ты не поймешь система поймет только ее нужно до обучить как у нас есть базовый лексикон системой и базовые модели языка вы берете подбираете тексты например на кулинарную тематику который описывает там пиццу маргарита чёрные бургеры тому подобные вещи либо если вы хотите сделать голосовой чат бот для банка вы берете кита текст на финансовые и строите особые вероятностные огромные модели на этих текстах а дальше берете базовые модели которые у вас уже есть которую например скачали с id хаба объединяя идти с вами с вашими особыми моделями и получаете предмет ориентированные языковые модели которые можно с успехом применять в торе ной узкой предметной области в целом мы разобрались как делать систему распознавания речи как видите не боги горшки обжигают в принципе ничего сложного нету с пользуемся ему сфинкс использованием 10х концертных компонентов который с на гитхабе с использованием с римма вы получите более менее нормальную работающие модели подождите нормально работающую модель аж такое нормально что такое хорошо применительно к распознаванию речи те из вас кто занимается машинным обучением знают классические метрики там accuracy of 1 мера сбалансированной от мэра престижный call тому подобные вещи но здесь такой подход не очень применим обычно наиболее популярный способ оценки качества распознавания речи it over the right to уровень ошибки слов у нас есть тестовый корпус вы допустим взяли ваш обучающие корпус от него чекнули маленький кусочек который в обучении не использовался ее разговорить это у нас тестовый корпус есть в тестовом корпусе есть парой звукозапись и и текста аннотация звукозаписи и текста в аннотации и вам нужно оценить насколько правильно тестовые за к записи ваша система распознает вы используете метрику 4 рейд сколько нужно сделать вставок взамен и удаление в распознанные цепочки слов чтобы привести ее к эталонной цепочки слов которые в тестовом корпусе лежит это считая если на основе расстояние левенштейн а с помощью динамического программирования наверняка у растения левенштейн а вы все знаете что это такое и получается мы считаем число вставок удаление и замен а в знаменателе это число слов эталонной фразе и получаем werther рейд хорошо мы научились оценивать качество а какое качество мы считаем хорошим какой вертолет мы хотим в зависимости от разных задач желаемый вертер рейд может быть разный так я прошу простить это мой конечно факап колоссальный я здесь хотела наоборот сделать поэтому мысленно пожалуйста сто процентов минус эти цифры сделайте либо представьте что это не вера же never to rate over the accuracy это сто процентов минус вектор a raid я приношу извинения вот если мы делаем систему голосового командного управления которы должна распознавать команды из одного слова либо из короткой фразы то здесь требования к качество распознавания очень высокий вертера рэй должен быть меньше пяти процентов стресс навер тт accuracy должно быть выше 95 процентов есть и мы говорим о какой-то системе голосового поиска либо вот диалоговой системе простой типа голосового и vr меню то здесь требования могут быть пониже но тем не менее тоже остаются достаточно высокими where the raid должен быть в районе 10 процентов не больше на чьи систем будет неудобной она будет постоянно переспрашивать у пользователей я тебя не поняла об авторе зачем такая тема нужно а вот когда мы решаем задачи в автоматическом стенографии рование звукозаписей задача более сложная потому что там структура фраз синтаксис может быть произвольной словари очень большой и требование качество снижаются дело в том для журналиста который обрабатывает интервью важно чтобы хоть какой-то подстрочник появился для звукозаписи он дальше вы вручную если надо пофиксит а самое главное смысл будет понятен и так чтобы он потом написал статью либо сделать сценарий для театрального представления поэтому требования к качеству остин графе рования it over the rain ну 20-30 процентов а какой же вертолет получилось у нас мы сейчас как раз делаем первую версию этой системы получили звукозаписи но прежде чем протестировать на реальное звукозапись а давайте пробу оценить на нашем обучающем корпусе а как оценить ни в коем случае вы не тестируете на тех звуковых данных на которых вы обучали это прям такой харам для специалист в области машинного обучения нельзя так делать обучаете на одних данных тестируйте на других я уже говорю способ вы берете кусочек отщипываем от обучающей выборке говорите что бы тесто выборка но вы получит только одно число и такой результат эксперимента будет не очень значимый как правило в мире машинного обучения для этого спалит кросса валидацию то есть берут делят наш dtc на 10 на кучу фолдов на кучу частей и вот проводят кучу экспериментов допустим к фолдов 10 ходов 10 экспериментов в каждом эксперименте 9 фунтов обучающе 1 fold тестовые данные и в итоге получают 10 10 оценок и уже это более-менее статистически достоверный результат оценки качества системы у нас получилось в принципе весьма неплохое качество на vaux фарш около 20 процентов мира и среднего отлично отклонения этой лишь мера уорд рейд и среднее квадратическое отклонение поверти это тоже в принципе в пределах разумного все окей все мы сделали хорошую систему были менее которую можно использовать для расшифровки интервью на этом я уже хотел бы закончить свой доклад но нет мы что-то забыли что мы забыли вроде бы мы все сделали опусти к фонетическим модуль языковой модуль протестировали по науке протестировать через просто валидацию все окей но а как в реальности происходит интервью как например со мной интервью они эти ребята брали приходим в коммуне кафешку например на студенческой есть там organic cafe неплохая кафе вкусным кофе вот там сидим беседуем по чашечке кофе там люди какие-то приходят заказы делают тихая музыка фоновая играет то есть есть акустические шумы а вот этим звукозаписи в оксфорд которые делались добровольцами в рамках проекта фоксфорд они записаны более-менее в тихих условиях то есть человек из домашнего ноутбука заходит микрофон фото говорит вокруг тишина как правило и звукозаписи хорошие там качеству часть хорошая когда мы запускаем на зашумленных звукозапись а качество трофической проседает мы забыли а шумоподавление как же сделать чему подавление ну во-первых частично подавление шумов реализуется в самой системе тему сфинкса вот этими филлерами о которых я вам рассказывал отдельные модели для неречевые событий импульсных шумов там наук но кто-то стукнул чашкой кто-то там еще что то произошло но есть у нас какие-то перманентные фоновые шумы да еще сложные музыка какой-то тихая фоновая речь так просто уже не обойтись такими простыми филлерами здесь нужно сделать что-то более сложное подавление шума при чем шум сложных я уже говорил нестационарный раньше когда-то восьмидесятые в 90-е годы для разных типов шумов стационарные фоновые шумы импульсный шум и там в речи подобных мы придумывали разные модель от простой венгерской фильтрации до каких-то сложных скрытых марковских моделей отдельно для распознавания шумов еще перед тем как мы распознаём с этими моделями фонемы мы отдельную модельку делаем для распознания шума в для подари для подавления эха реверберации там и так далее но сейчас наконец-то мы вспомнили о нейронных сетях любимых всеми то мы говорили скрытых марковских моделях а вот теперь на сцену выходит глубокие нейронной сети их как раз очень эффект эффектно можно использовать на данной задачи почему для них данных много если в обучении распознавании фонем данных у нас было немного мы ограничены были корпусом 20 часов то здесь как мы обучаем мы берем например 10 часов из этих 20 самые лучшие речи сама чистой и берем корпус шумов и дальше делаем аугментацию генерим множество звуковых сигналов где чистая речь зашумлен а вот этим вот шумами и используем эту глубокую нейросеть которую учим на вход мы подаем зашумлен у речь там одним способом другим третьем а на выходе она должна дать нам чистую речь то есть как-то научиться вот это вот сложные шум и подавлять одни из таких вариантов это вот предложенный в рамках в пятнадцатом году статья регрессионная нейронная сеть которая решает эту задачу не как задачи классификации задач регрессии то есть у нас есть последовательность спектров нашей спектрограмме внизу зашумленных спектры кусочек сигнала подается на вход глубокой глубокое нейронной сети он там распознается каким-то образом и на выходе получается чисто речь то есть на основе нескольких контекстных спектров получается один спектр чисто речи так такая не россия . скользит вдоль сигналы получает чистую речь очищен от шумов разного рода a data set для нее train set можно генерировать произвольного размера благодаря тому что у нас есть корпус шумов есть корпус есть то речи там два произведения там будь что огромный dtc ответственно глубокие сети можно использовать когда носить большой datasette когда рис overfit а переобучение их мал и он действительно мало вот вы можете почитать эту статью и реализовать такое шумоподавления но блин нужно читать статью нужно вникать в эту математику нужно писать своими руками не розеточку опять-таки зачем наш подход это собрать и за подсосных компонент распознавание речи и опять-таки нам на помощь пришло сообщество уже есть и т'хаб репозитории с такой сеточкой которая делает шоу подавление он написан на керосина тандер flow при этом нам нужно минимум усилий на нужно спланировать репозиторий нам нужно создать папку с чисто речью задать папку шумами прочитать ридми запустить эту штуку и она обучиться подавлять шумы сама тестовый варя где мы вариант на гитхабе ориентирован на корпус английской речи timid но сами авторы пишут что в таком же формате готовите звукозаписи ваши нам пока это научиться распознавать вашу речь опять таки никаких проблем нету ставите эту штуку впереди системы распознавания она шумовую речь очищает и дальше ваша система на основе сфинкса распознает и выдает более-менее приемлемый результат теперь уже можно заканчивать доклад теперь уже мы не забыли ничего теперь пора перейти к выводам какие выводы я хочу сделать своего рассказа первый вывод во-первых распознавание речи можно делать самому можно не обращаться компаниям гигантом не платить им сто пятьсот денег за покупку кого-то blackbox а еще тысячи пять тысяч денег за настроек этого был и бокса под вашу задачу нет можно взять и создать систему рст правиле своими руками для этого нет необходимости быть крутым математиком или крутым лингвистом вы все крутые программисты и этих скилов час достаточно за вас уже другие ребята продумали и окон сосны и компонент из которых вы можете создать систему соответственно open source это круто опыт собственные компоненты они позволяют людям которые решают свои задачи следователям специалистом по каким-то прикладным зачем делать свою систему мне повезло фирма где я расист работу помимо эмпатия работают это монстр за это монстр они очень положительно смотрят на contributing open source они-то подделал поддерживают но мой работодатель мвт у них вообще основной проект это проект и павлов продукты павла который выкладывается в опыт source вы можете взять склонировать его использовать для построения собственных ботов соответственно одна из задач и то что мы сейчас делаем это мы делаем для театра для прекрасного для искусства но эти же технологии можно использовать для создания пример голосового чат-бота частности у нас есть планы интегрировать де павлов текстовый чат бот который переписывается с пользователем с нашим распознаванием речи и получить уже голосовой чат бот который может не просто переписываться переговариваться вот и наконец я еще один хочу сделать вывод может быть более философский тем более преподаю выглядела более философский как видите я рассказал архитектуру системы распознавания речи в духе модульного подхода у нас есть компонент подавление шумов компонент акустика фанатического модуля компонента языкового модуля конечно мы все любим нейронные сети мы все любим любим не раз его нтн подход чтобы одна не раз сеточка для всего даешь водстрой сигнал а надо выходить текст не нужно с этими модулями возиться не нужна слава ретро scripts и придумывать но чтобы такая сеточка хорошо заработала ей нужен очень большой datasette наши не расти вы антон подходы эффективно работает когда у нас есть например 7 тысяч часов как это есть у компании байду которая предложила deep спич не растерять этот подход к наносить 20 часов когда он висит небольшой datasette необходимо во-первых делать систему модульный и настраивать каждому в отдельности во вторых очень эффективно является внесение априорной информации о предметной области в нашей модули здесь например информации это знание лингвистов а языке выраженные вот этих правилах транскрибирования правилах построения фонем в словаре транскрипции так далее и вот когда он и записать небольшое внесение априорных знаний о модели предметной области позволяет повысить устойчивость модели и обучить ее более менее нормально даже на небольших дата сетах этот вывод имеет место не только для распознания вообще для любых задач машине ангарских где у вас есть ограниченная предмета вас заданная и не очень большой datasette и нужно как-то выкручиваться вот безусловно мы хотим сделать нечто вроде deep спич и для русского языка но для этого нам нужно большой корпус мы еще с ребятами думаем о создании большого корпуса тысячи часов русской речи мы еще одним мы сейчас прорабатываем экономику проекта хотим воспользоваться такой для того чтобы собрать звукозаписи и наверное набор стартере запустим carrot фоне в в проект мы щас приблизительно самки делали например для того чтобы сделать тысяч часов речи нужно привлечь низко тысяч гектаров и на одних только дикторов то локеров 1700 рублей уйдет не говоря уже о том что нужно делать специфический frontend сама толока больше приспособлены для разметки текстовых данных там или изображений а интерфейс для ввода звукозаписи нужно делать вот и так далее мы через них то время выложим на был стартере будем очень благодарны вам если вы поучаствуете в создании открытого корпуса по тысяч часов и наконец я подвел итоги настало время перейти к благодарностям во первых я хочу выразить благодарность моим ребятам моим студентам из новосибирского государства университета который вместе со мной делали эту систему без них бы я бы не смог вам рассказать вот то что я рассказал сейчас и не смог бы для театра хоть прикольную штуку это оля лингвист данил математик студент мехмата и маша тоже лингвист видите у нас такая коллаборация программистов математиков лингвистов и наконец хочу поблагодарить вас за внимание за то что вы дослушай до конца и надеюсь вам было не слишком скучно если у вас возникли вопросы если возник интересный вопрос это я открыт для диалога открыт для вопросов задавайте буду рад ответить еще раз благодарю за внимание давайте мужчина начну здравствуйте иван огромнейшее спасибо за доклад вот такая популярная наука она вдохновляет еще раз огромное спасибо вопрос насчет корпуса а вы не задумывались о том чтобы взять например советские ну записи советские фильмы которые наверняка уже много раз субтитры к нему написаны там записи поэтов до которые читают стихотворение которое тоже ну уже текст готов там песни я не знаю вот все вот это спасибо за вопрос это хороший вопрос мы об этом задумывались мы задумывались и о том чтобы взять фильмы мы задумались о том чтобы взять аудиокниги например но есть одно большое но а первый фильм это штука длиной 2 часа например соответственно когда мы обучаем систему звукозапись на звукозапись алёной два часа пусть она даже анонсирована нормальная субтитрами проблема выравнивания проблема вот сопоставления вот эти фонемы вот этим кусочком речь соответствует очень острая а когда мы используем в оксфорд там всего 20 часов но там очень много звукозаписи на примерно 8000 звукозаписи каждой из них короткая примерно секунд десять мы не указываем границы фонем системе общего врага не станем нужны но она с помощью это рационом алгоритма постепенно сама правильно выравнивает когда кусочек звукозаписи короткие она это сделает хорошо когда звукозапись длинная два часа сделать плохо особенно с учетом того что там есть еще фоновая музыка и тому подобные вещи которые осложняют обучение кроме того есть еще одна проблема связанные с фильмами связанные с рукой записями набор актёров озвучки не очень большой набор дикторов которые создают аудиокниги не очень большой это десятки людей то есть мы можем сделать неплохую систему которая будет распознавать актёров озвучки либо дикторов наша цель же сделать систему диктора независимую и для нас гораздо лучше маленькие звукозаписи от сотен дикторов чем большие звукозаписи от десятков гектаров соответственно создание такого корпуса которыми над соответствует этим критериям она актуальна и важна в оксфорд этим критериям соответствует пусть они очень большой нет они 1000 часов а 20 но он этим бретелям соответствует на его основе можно сделать неплохую систему когда мы получим 1000 часов там вообще можно рокет сайенс сделать вот ну а вот аудиокниги они или там фильмы они этому критерию не соответствуют увы плюс еще есть еще один момент кодеки дело в том что здесь для нас критически важно чтобы звукозаписи были без всяких алгоритмов сжатия с потерями типа mp3 и так далее на слух это не чувствуется но не очень сильно искажают как сигнала мои товарищи из москвы они делали эксперименты в области генерации субтитров к телепередачам и они говорили что каждый канал использует собственный кодекс и система обучена нас вызов одного канала просто не пригодна для другого канала там спектральная картина другая и все и на качество к историческим падает соответственно нам нужно чтобы этом сырой во в pcm был они mp3 шкив и да я надеюсь в этом ваш вопрос давайте тогда следующий от кто-то здесь такой а как дела с пунктуацию и тому подобными вещами и сейчас никак почему не как мы эту задачу перед собой ни ставили здесь для распознавания интервью для генерации звукозапись интервью в текст мы ориентируемся на следующий признак когда у нас появляются длительные фонемы паузы ну там 300 миллисекунд 500 миллисекунд мы просто считаем что уже смысловой участок речи закончен и считаем это отдельно продолжением все грубо говоря мы ставим аналах точки во всех остальных случаях мы знаки пунктуации не генерируем есть и мы делаем эту систему например для для чатбота для голосового ему в принципе знаки пунктуации не важны чат-бот голосовой потом будет на основе этого текста распознанного он классификация пользоваться их намерений делать извлечение именованы сущности но подобные вещи там знаки препинания никакой роли не играют как признаки в тексте поэтому они тоже не важны для интервью возможно они понадобятся мы вот общаемся с нашими заказчиками и театральными они говорят что до было бы неплохо сделать такую штуку мы об этом думаем и у нас есть идеи все-таки попробовать отказаться от этой модели словарь трасс крипсы языковая модель оставить сфинкс только для распознавания фонем а сверху вместо инграм ных языковых моделей и слова рецепции прикрутить рекуррентный у сеточку который делается и христу sequence и и в принципе можно попробовать по цепочке фонем научить генерирует цепочку букв и знаков препинания там модель примерно та же как для нейронного языкового перевода параллельно корпус текстов только у нас неправильно корпус текстов на двух языках а параллельно корпус транскрипцией и вот текстов которые для этих транскрипции подобраны с вами транскрипции можно на генерировать искусственным образом с помощью наших инструментов насколько это быть получится не факт я специально о таком подходе не рассказал о своем докладе потому что наше предположение мы хотим так попробовать и знаки препинания сс познавать но это не является киллер фичей вы такого рода систем это как бы второстепенная фича поэтому мы наденем не акцентировали внимание дальше вопрос а вот вопрос такой как решена проблема неправильных транскрипций и двойственных транскрипций ну то есть вот если слайд синхрофазотрон нам вернуть там очень хорошо написана как раз синхрофазотрон неправильно написан да да мнения дальше дальше там где вот именно транскрипции будут дальше да да еще больше нет наоборот назад надо идти ну смысле в самое начало да да сейчас вот синхрофазотрон то есть я могу в речь сказать и синхрофазотрон а кто-то может произнести синхрофазотрон распознавание этого одинаково должно происходить в одно и то же словарное слово ну тут есть нюансы в беглой речи вы говорите сильного затрону ударение на последний слог идет на последнюю гласную букву здесь это показано видите цифры рядом с гласной обозначение гласных ним означать что это ударная гласная безударное о не бывает но действительно вы правильно заметили человек может этот говорить слово как-то по слогам синхрофазотрон то есть вот как выделить какой 2 case слова и тогда действительно ударная он может появиться такие вещи решаются как правило альтернативные метро скрип сами то есть у нас есть базовый вариант 1 клипсы и мы добавляем альтерантивный трасс крепится которые моделируют то или иное произношение есть даже теоретически и оценки что для создания эффективной системы распознавания необходимо примерно в среднем полторы транскрипцией на слово у нас сейчас в нашем словаре альтернативный то скрипт реализован только для того чтобы мы морфологически неоднозначность пофиксить от как я говорю про ольга гиря и об лагеря кроме того мы вручную для аббревиатуру делали вот эти вот неоднозначности как-то я говорил что можно там фсб сказать а можно фсб вот в общем случае мы таких вещей пока не делали эти транскрипции вы получали автоматически с помощью нашего транскриптов основана на правилах самара фильтру транскрипта предусмотрена возможность подключения новых модулей модуль например южного диалекта русской речи модуль там северного и тому подобные вещи мы планируем это сделать но пока что мы достигли приемлемого качества которые устраиваются таким вариантом вот так вот вообще вопрос хороший вы правильно заметили да давайте на этом закончим часть вопроса в зале если у кого-то еще есть вопрос них можно будет задать на дискуссионной зоне которая находится снаружи сейчас хотим поблагодарить его на за его доклад который для всех был очень интересен"
}