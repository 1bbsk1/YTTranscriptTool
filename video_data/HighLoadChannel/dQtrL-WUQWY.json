{
  "video_id": "dQtrL-WUQWY",
  "channel": "HighLoadChannel",
  "title": "Мониторинг облачной инфраструктуры / Михаил Прокопчук (Avito)",
  "views": 2638,
  "duration": 2028,
  "published": "2019-01-14T00:09:27-08:00",
  "text": "всем привет в компания эти занимаемся тему штуки для нашего облака совхоз так и и мониторинге этого облака и сегодня расскажу затем моего доклада мониторинг облачной инфраструктуры первый слайд стандартный то есть немножко правит если вдруг кто не знает что это сайт номер один объявлений в россии с 35 миллионов пользователей кучу сервировку чаю рпс бы kandu вот значит план моего доклада сначала расскажу из чего у нас общий построена облака во vita чтобы понимали ну то есть контекст этих программных компонентов состоит архитектурно как все устроено потом расскажу архитектуру систему мониторинга и самое важное расскажу как мы мониторим облака то есть будет про метрики то есть расскажу на что нужно смотреть все это и наконец расскажу про такие вещи как из ила и соло что это вообще такое и зачем это нужно вот надеюсь будет интересно так поехали облака во видом на текущий момент облака у нас представляет собой четыре кластера у нас есть два production кластер один дев и stating мастера примерно 50 нот в каждом из кластеров где-то 2000 кодов у нас есть вдв кластере и такой вот немножко круглая цифра буквально там за несколько дней до доклада решил посмотреть у нас примерно 100 релизов в день в наше облако в продакшен при этом разработчики хотят сами по технологиям чем у нас есть система регистрации разумеется у нас cabernet используем фильм сойтись сиди систему на steam сити и из ресурсов нас там свою registry докер registry свой фильм registry вот это вот все и сторожем и активно сейчас изучаем и внедряем сев то есть полновесной бы его нагрузки на него нет но что то пытаемся делать если интересно потом можете поспрашивать могу рассказать интересного туринга у нас есть собственный губернаторский линдер который мы используем при выкладке сервисов в продакшен который умеет проверять вещи там который губернатор ну там не может проверять там число реплик нужны аннотации чтобы было были выставлены тоже могу про это рассказать наконец у нас есть блок для создания сервисов то есть обычный такой ссылок бот для разработчик что-то хочет там новый сервис сделать он просто боту пишет bad ему там в дает ссылку на репозиторий ссылка на даже борды в графа не вот это вот все вот и собственно про разделение ответственности что у нас как устроена то сервера монолит у нас имею рулят наш доблестный unix-систем infrastructure облаком занимаемся мы юнит архитектура сервисы то есть диплом рубик это ну вот разработка соответсвено архитектура системы мониторинга у нас фактически используется от вас т.к. первый на основе прометею со второй на основе графита и клик хауса то есть про метаюсь это у нас инфраструктура облака прежде всего мониторится 100 кг на основе графита клик хауса это бизнес метрики сервисов то есть все что они хотят отсылать о своей работе не знают про продуктовые метрики вот эта всю инфраструктура монолит и доступность нот это все у нас в граффити и в клик роучем про память с мы не используем prometheus оператор у нас про металл запущен в каждом из наших четырех кластеров просто как обычный deployment и настроим кросс мониторинг между ними то есть поскольку про металл это прежде всего инструмент оперативного контроля мы используем оператор просто вот у нас их 4 parameters и получается как полна связный граф они все друг друга мониторит если какой-то из них становится недоступным об этом быстро очень узнаем помимо самого про метался мы еще используем prometheus экспортеры если кто не знает это просто такие gateway для отдачи метрик формате понятным прометею suisse экспортеров мы используем blackbox экспорта для высоко уровня каких-то там хотя т.п. там знаю иногда даже 7 pe проверок но для экспорта чтобы получать информацию о состоянии вот там нотку обернется simcity экспортер но поскольку мы используем тем сити поэтому мы используем всех экспорта и наконец власти ксир scholastic всё секс партнер нам нужен га мониторинга и ластиков которым у нас хранятся инфраструктурные логе самого q бернацкого hero то есть там события от q билетов от докер демона вот это вот все allure think облака у нас альтинг в облаке сейчас достаточно просто устроен то есть у нас просто в графа не настроен в пункт для отсылки уведомлений в slack бизнес метрики и монолит у нас алиса через систему уведомлений мойра которые мы тоже умеет отсылать флегмы что важно умеет использовать отсылать через sms мы не используем prometheus alert manager несмотря на то что это такая классная штука на самом деле я читал там смотрел документацию локально даже разворачивал очень классно можно настраивать к агрегации менты нас режим и все прочее но мы его не используем по одной простой причине что у нас вот есть уже два готовых стека и мы сейчас внедряем по интеграцию на самом деле мониторинга облака с текущим нашим стеком графит клик house и будет это выглядеть примерно следующим образом смотрите в левом верхнем углу это prometheus основной который мониторит cabernet кластер вот потом рядом с ним в этом же кластеры запущен так называемый prometheus federation он что делает он ходит на on point вот вот того самого примет промыты руссо данный in point федерация получает лишь подмножество метрик то есть через в правительстве direction настроена фильтрация метрик то есть собирает как бы не все метрики которые вот тот prometheus это только нужные нам не знаю которую мы хотим хранить для долгосрочной перспективы там не знаю для построения какой-то аналитики для чего-то и вот это подмножество метрик уже через ремонт в райт мы отсылаем в карбон клик хаоса и дальше уже непосредственно при krause потом собственно в правом верхнем углу то есть мойра она умеет ходить в карбон api она это совершенно недавно научилась делать мы сделали pull request он пока открыт у проекта мой разум и это уже используем есть мэра ходит в карбонат и дальше соответственно через тот же самый carbon treehouse идет crack house берет эти метрики и по ним уже можем строить альтинг и все прочие такая схема нам чем удобно да то есть во первых у нас есть возможность хранить метрики и дачное длительное количество времени потому что сам prometheus но как бы он не про долгосрочное до хранение данных инструмент оперативного контроля а с другой стороны мы интегрируем ся с нашей мудрость нашей уже готовы отстроенной системой вот уведомлений вот соответственно это вот было коротко потока у нас общая архитектура систем мониторинга устроена значит мониторим облака справедливость но разумеется это здорово все классным его там когда внедрили увидели там все круто но это не бесплатно не вообще не бывает бесплатных решений поэтому тут супу память сейчас будет все как всегда но интересно циpкa мы сначала за мониторили д в кластер потом думаю таким сделаем это правильный запрос и чтобы понять сколько у нас не знаю там например контейнеры используются путают это типичные запроса на языке пром перси запросы примет isu пишутся на языке профиль он достаточно простой тут можно прочитать на дело не в этом даже дело в том что этот запрос выполняется пять секунд просто на самом деле на большом кластере на двух тысячах кодов это именно циpкa time а если этот запрос использовать например в графа не да и потом там 100 разработчиков придут откроют этот график и эти все 100 запросов улетят в параметре стрессу станет ну очень грустно поэтому всегда пожалуйста используйте эрик орден груз то есть это такие pride компилирование запросы по которым prometheus но он их фоном просчитывает на основе них создает новую метрику и в итоге вот этот запрос он уже не будет выполняться каждый раз пусть про митаев соусом фоном прочитает создаст новую метрику и все разработчики когда придут откроет графа но они ее просто получат и в итоге про готовился будет хорошо в плане цыпа юзаешь так то пожалуйста делайте в корзинку год практически для всех запросов для всех графиков которые вы используете в grafana по поводу памяти то есть резидентной память у нас до в кластер примерно 70 ноты примерно 2000 кодов мы взяли и поставили там летающим 24 часа ну просто когда начали мониторить потом таки взяли посмотрели сколько штормит с потребляет память увели на самом деле очень грустную картину это как график употребление резидентной память он плохо по двум причинам первое это собственно 130 гигабайта 2 то есть мы видим что тренд идет на увеличение вот стали разбираться и обнаружилось что в про матирующий точнее кренник самом прометею еще там с интеграцией с клиентской библиотека кубер над которой он использует вот обнаружился memory leaks в той части функционала который отвечает именно за губернаторы discovery вот вот тут есть сразу четыре открыт патриаршую и один по request который это все исправляет и очень важно знать и понимать что вся эта история с вот с большим потреблением памяти было исправлено в версии 230 если кто-то использует prometheus ниже этой версии и мониторит свое блокаторами the wheels может утекать и очень серьезно утекать по памяти так что обратите внимание используйте вот версию 230 мы когда на нее переехали стала общем то все здорово резидентная память не растет и все очень и очень круто по поводу виртуальной памяти правительстве смотря на то что он там не про долгосрочное хранение данных теме тем не менее у него есть своя встроенная база тсд б она написана с нуля специально под профиль нагрузки prometheus является не там частью к до базы про метался в итоге и что важно знать понимать а нам объезд это база данных вот и поэтому для высокой производительности про метаются нужно смотреть чтобы на ноги где он запущен было достаточному свободных страниц под пачкаешь в идеале там есть хорошая статья от самого разработчика вот этой базы как писала все про чем говорит ну прям хорошо будет если почти весь dataset ляжет пачкаешь тогда все будет работать быстро и классно вот и напоследок то есть если говорить про правительства в div вроде развернуто метрики pdf кластер то число метрик примерно миллион двести при этом datasette всего 5 гигабайт predatory тельцами два часа мы не считаем нужным оставить ритм чем больше на самом деле потому что оперативный контроль нам только нужен параметра в долгосрочное хранение но я показывал как реализован союзов примерно 3 300 процентов то есть ну в общем у нас нас эти цифры вполне устраивают вот дальше собственно и как мы мониторим вот следим за инфраструктурой собственный учим в рамки достаточно простой на самом деле на самом деле язык по стране запросов но тем не менее каких-то деталях надо знать и так как мы мониторим кластер то есть четыре типа метрик но на мой взгляд четыре группы метрик то есть это кластер самаре то есть это метрики отражающие общее состояние кластера потом кластер infrastructure это метрики отражающие состояние работы именно уже каких-то под систем кластер не знаю там тоже кубе лето api сервера прочего то есть потом над специфик метрика наконец под специфик метрик то есть кластер самаре какие тут важны прежде всего метрика очень важно знать и понимать к вас емкость кластере насколько он на самом деле с утилизируем вот в целом то есть вот раз кластер там из станут вы хотите знать вас он наполовину заполнен или там не наполовину там какую-то величину значит смотрите на что здесь нужно обращать внимание то есть во первых надеюсь что не знаю кого кто у кого есть к бернацкого нет кубе лет это основной инфраструктурный процесс обернется исследовать его всегда запускать вот с такими ключиками систем резерва типу и систем резерве memory то есть это опция эти параметры определяют то сколько системе на самом деле хасту будет гарантированно выделяться ресурсов а скоро все остальные кубе лет может уже использовать под планирование подав но 1000 мегабайт и 1 idroid на самом деле маловато для хоста можно оставить не знаю 2 2 ядра например поставить и побольше памяти но самое главное понимать что вот общая емкость но до минус вот это и это будет ресурс для доступны для размещения кодов на вот этой worker ноги соответственно про метаются сразу есть две сам метрики которые позволяют эту величину получить то есть толоко это был цик укор села к это был мир омри бойцы с этим все здорово то есть мы можем посчитать сколько у нас вот доступно ресурсов теперь попробуем посчитать сколько у нас из этих ресурсов занимают утилизируют контейнеры да мы когда начали это все дело то есть вот есть такая метрика контейнер memory users байт и например мы ставим еще лейбл там хотим посчитать сколько у нас контейнер размещенные на ноги там кукла 53 до потребляют байтов вот такая вот метрика сумму баянист мы получаем 120 гигабайт потом заходим на эту моду и такие смотрим просто команду там free минус b до видим что всего на ноги на самом деле утилизировано 35 гигабайт даже включая пичкаешь на самом деле чет как-то не сходится и даже rss метрика не сходится если попробовать посчитать там контейнер memories с 22 giga на ноги 7 короче все очень интересно то есть и зачем я про это рассказывают и всегда когда я что-то за мониторить этом прометею сам и прочие посмотрите глазами пожалуйста обратите внимание на то что вы правильно агрегирует и и тому подобное устали смотреть из чего состоит метрикам memory с и внезапно увидели что по сути там есть еще информация о потребление памяти не знаю систем бешеных каких-то слайс of всего прочего поэтому история общем в чем то есть когда prometheus обращается к кубе лето чтобы получить мы всю необходимую информацию потребление ресурсов фактически обращается к такому программному компоненту как sio2 изар который скомпилирован в кубе лет asio драйвер уже знает там куда сходить получает все эти метрики так вот sio2 за в том числе собирает метрики вообще по всем группам включая систематически слайсы там где нет и это очень портит статистику и приводит ног вот так вот такой вот разница в потреблении поэтому если говорить как правильно строить запрос да то есть достаточно вот так просто сказать что и мышечные равно пустоте пример может быть тривиальным хотел показать что всегда смотрите действительно ли метрики которые вы агрегировать этом prometheus действительно ли они правильно агрегируются потому что могут быть куча на самом деле таких вот подводных штук которые ну как бы не очевидны а потом вы получите не неверные метрика это очень грустно тем более там в продакшене например еще помимо rss а можно считать то есть я говорю про емкость кластер из такое понятие как working сэт байт она представляет собой величину потребление памяти когда мы берем полное потребление памяти там включают пичкаешь и прочее и вычитаем из него и не активной странице . ш то есть это метрика ну на мой взгляд достаточно хорошо отражает то сколько фактически и памяти процесс таким образом мы получили там сделанную память поделили и на общее число доступных ресурсов мы можем считать метрику по working with байт также делить на полную емкость ноты получаем уже потом это все суммируем по нотам да и получаем величину которая показывает насколько у нас заполнен кластер я дальше покажу как это у нас выглядит то есть я приведу примеры там самаре дашбордов так что все это будет вот следующая важная метрика вот такая кластер вает не знают ресурсы доступны для размещения подав вчера еще раз перечитал статью от самих губернаторов то есть у них там есть статья который называется building клатч кластер стану построения больших кластеров и они сами прямо документации говорят что на ноги в целом не рекомендуем разворачивать больше 100 пудов потому что ну это на самом деле так если больше 100 пудов на ноги начинает работать то надо начинает странным образом деградировать про это я могу там секций вопросов-ответов рассказать в общем для продакшн и даже для дома мы вставляем лимит в 60 кодов на моду вот и очень важно знать и понимать не подбираемся ему случайно к этому лимиту тут еще какая история на самом деле может быть присмотрите ну метрику эту все мы можем посчитать то есть мы берем сколько у нас всего запущена кодов и смотрим сколько ее емкость уж мы можем понять насколько но до заполнена по потом и при этом еще очень важно отслеживать а вот число кодов которые работают на родине в ранен кстати то есть смотрите у вас например есть d в кластер у нас там предположим вообще там тривиальный случай там из двух но до состоит на каждой ноги и лимит в 60 кодов и разработчики берут туда вдв кластер что-нибудь котят у них это все выкатывается коряво то есть под и там в краж lubeck уходят еще что то то есть коды не в нормальном запущенном состоянии однако они потребляют вот эту емкость кодов и у нас были на самом деле историй когда разработчик мечом что-то выкатил в кластер может даже потом про это забыть заняться другой задачей но эти коды валяются в кластер поэтому очень важно всегда мониторить и allure тица на число кода в которой не в запущенном состоянии чтобы они не занимали впустую ресурс кластером вот такая вот история то есть по инфраструктуре кластер а какие метрики тут можно какие метрики можно обратить внимание во первых это сразу же метрики губернаторского api сервер ай-q и то есть это рпс на него и это его в танце на прошлом хайло де я рисовала картинку про то как устроен губернатор всякий случай еще раз ее покажу то есть api сервер это центральный компонент систему секу бернес все другие компоненты работают только через api сервер поэтому если сыпь и сервером что-то идет не так кластер может стать очень плохо то есть увеличивается там в этом все работа инфраструктурных компонент вот это вот все то есть метрики эти сразу же доступны если мы начинаем мониторить мышку вернуть кластер то есть там api сервер request каунт и можно еще разбивать по типу запросов на самом деле тоже очень полезная метрика вот то есть судьба over вот там смотреть сколько get почти там прочих этот и точных запросов из мы мониторить вообще-то тут факт что нет каких-то аномалий там врп сетапе сервер и вот это все это очень полезно но по нодам по потом я в принципе рассказал то есть мы метрики собираем там цепную заш memory юзаешь вот это вот все то есть там никого руки царь все достаточно просто вот и наконец blackbox проверки я говорю что мы используем blackbox экспорта стараемся за мониторить им вообще тоже работу всех компонентов из помимо того что мы получаем от них метрики мы еще ходим везде куда только можно пахать и т.п. да по тисе пи проверяем что все это работает что это очень важно знать и понимать и кроме этого blackbox экспорта еще предоставляет метрики то есть не просто что там с 200 не 200 например код или там latency предоставляет еще классно разбивку по перцентиль им то есть там по 90 95 можно смотреть общем это все здорово и мы еще внедряем на самом деле комплексной проверки всех ресурсов то есть там проверки вроде как ну то есть не просто сходим в ряде стрипах этот об этом проверим что резистор работает мы делаем еще всякие там докер пул вот это вот все вот и все эти метрики которых я вот так коротко час рассказа на самом деле там немножко больше мы вводим на самаре даже барда из них на так называемые связаны и даже борды в графа не очень классно этот функционал выглядит общем выглядит это примерно так цифры не отражают на самом деле реальность но я хотел продемонстрировать это наш самый дашборд на 1 там из наших кластеров вот смотрите на нем не все хорошо но это и здорово ты сразу видно куда обращать внимание да я сейчас прям если ли тут достаточно мелкая сейчас будут слайды покрупней то есть даже число нот в состоянии риге но до состояния реддита когда она не запущен кубе лет когда pi server действительно считают что кубе летом работает нормально и все здорово то есть 66 из 85 значит надо идти на те моды которые не ради смотреть разбираться ok рпс на pi server мы видим что он стабильный там за какой-то промежуток времени то есть вы приходите на работу и хотите просто понять да хорошо или плохо работает ваш кластер то есть мы не видим никаких пиков на api сервер то есть значит что в целом нагрузка на кластер но сохраняется на у стабильно не нет ничего не происходит все здорово вот те самые под и не в запущенном состоянии и подав эти распределения кодов по но нам то есть кодов не запущенном состоянии целые 91 но если посмотреть на вот график справа то есть под пернатых каждая вертикальная линия так обернется узкая но да вот и мы видим что в принципе до лимита им еще ну как бы у нас есть до резерв поэтому 91 91 не запущены под это конечно не весело но ресурсов пока хватает так что можно разбираться можно чуть-чуть отложить например задача несрочные но проблема есть здоровом и наконец время деплоя нашего эталонного сервиса про него я расскажу в последней части доклада то есть это нужно сделать обязательно и смотреть что сервис вообще эталоны у вас всегда выкатывается и он всегда доступен наконец график то есть там ошибок q билета при работе с докером в кубе летом на ноги работает он ходит в докере муж говорит тому чтобы он создавал контейнер мы видим что-то на какой-то ноги просто вообще превышение порога там порог в 6 ошибок в секунду но при этом график не несоленый да то есть мы видим там зеленая сердечко все это потому что там просто мы знаем что это надо там определенном смысле тестовый на не минут большое число ошибок может быть на всех остальных в общем-то ну все здорово вот то есть в итоге вот такой самаре дашборд позволяет ему достаточно быстро понять все ли у вас хорошо с кластер мы все плохо поэтому старайтесь делать такие даже борды чтобы сразу было понимание насколько у вас система всем работают вот и немножко еще хочу рассказать собственно про написании запросов кроме того как я уже говорил то есть и запрос пишутся на языке пранкер там есть ряд нюанс в которых я не знаю может быть вы знаете может быть нет но на мой взгляд на них стоит обратить внимание управился то есть любая метрика то есть не можно что то сделать про митоз предоставляет ряд supra mkiv язык представляет ряд функций для написании запросов наиболее часто встречающаяся ошибка что сначала мы считаем рейд а потом суммирую сначала считаем рейда потом суммируем и не наоборот то есть смотрите у нас предположим есть вот такой запрос который показывает нам число the request of мы их суммируем а потом по всем модом да а потом от этой суммы всей по всем надо мы берем и считаем рейд это не правильный запрос так почему он неправильный потому что предположим что в какой-то момент при рестарте там какой-то моды или выпадение и счетчик ну метрика конкретно по этой но диана сбрасывается в ноль соответственно у нас падает сумма вся у нас какую-то значительную величину соответственно у нас сильно падает рейд поэтому мы вот в таком в примере такого запроса если какая-то но до выпадет из кластер мы получим у серьезное падение увидим серьезно серьезно вообще спайк по этой величине начнем разбираться на самом деле ну могли просто но на самом деле штатно вывести из кластера но так вот в общем делать не нужно в итоге как правильно то есть мы сначала должны посчитать рейд по всем модом то есть взять по каждой ноги просчитать рэй потом уже рейд просуммировать и только тогда мы получим правильную величину обращайтесь когда на это внимание и запросы нужно делать правильному классика жанра избегаете абортов poweraid про метался есть две функции очень полезных то есть рейд и upgrade они различаются тем что рейд считает собственно рейд по временному окну которую вы ему говорите исходя из первого и последнего значений в этом временном окне то есть и в этом смысле рейтинг pride представляет на более сглаженную до метрику то есть которой она выглядит просто ну там трендовые все вот орыч считает рейд для временного окна по последнему и предпоследнему значению вот в этом временном окне тут если мы хотим посчитать например рейд ну там за минуту до по какой-то метрики тут случае рейтом и там предположим в начале минуту было 10 в конце минут стало 100 там 100 минус 10 деле мы все здорово и увидим ну какую-то среднюю айрой посчитает между двумя предпоследними и чем классно эта функция то есть она позволяет увидеть какие-то спайки т.е. если например у нас есть график рейта танцы пылью за например случаю рейтом и например видим что у нас принципе под потребляет му в половину от того сколько выставлены лимиты вроде бы все здорово мы вместе с тем приходит этом разработчики все проще гарри знаете у нас что там в этом все скачет в этом случае для разбора полетов aero это очень сильно пригодится потому что как только мы посмотрим на график айрейт а именно потребление цепную здесь мы увидим что возможно там какие-то пике которые примут добираются до лимитов данного конкретного поданные то что он опирается там или фц и пыли или в лимиты по памяти и соответственно смотрите всегда по какой величине вы действительно хотите строить альтинг то есть на основании чего самое главное избегать флопов разумеется вот и наконец я хотел рассказать про то что такое ссылается лол зачем это вообще надо и почему это нужно внедрять и использовать все наверное знают что такое sla то есть service level agreement на самом деле это скажем так такой контракт более бизнесовый вплоть до всяких не знаю юридических и прочих вещей есть еще такие понятия как силой и слов и вот на них прежде всего и нужно обращать внимание их высчитывать и строить метрики именно по ним то есть с аллой это service level индикатор то есть скажем так критерия и слов это как как конечно уже объектов пока вот и мы пока это все внедряем и как это выглядит то есть и сало это типичный такой критерий который может звучать так просто как утверждения что в этом все по 95 перцентиль у не превышает например 100 миллисекунд вот и слов она объектив это как раз частота выполнения вот этого критерия то есть и самое на самом деле девятки то есть когда у нас салай выполняется например 9999 раз тут самое сложное это правильно подобрать критерий по которым вы действительно хотите оценивать доступность вашего облака ну а дальше там мы слова уже просто выставляете нужное число девяток и начинаете промерять как это сделано у нас мы взяли написали то есть простейший сервис там лэнге с одной там грубо говоря ручкой с одним фингером вот назвали его там сервиса салоу вот он у нас выкатывается с заданным интервалом с определенным во все кластер а соответственно и мы что делаем мы проверяем процент успешных выкладок от максимально возможного да за период на этом сутки он например там там десять раз или 100 раз должен выкатиться носа тосно считаем процент успешных выкладок процент успешных проверок а мы этот сет доступность этого сервиса проверяем как внутри так и снаружи кластера считаем что эталоны да как будто и так как какой-нибудь ну любой уже продуктовый сервисы считаем процент наконец успешных проверок там еще ice response am который не живот миллисекунд то есть просто у нас вот на текущий момент ну примерно вот такие критерии мы на самом деле в процессе внедрения там еще всякие критерии вырабатываем и в итоге потом в графа ну подвозим примерно вот такие графики цифры опять-таки не отражают реальность но это очень полезно знать понимать то есть мы всегда видим что у нас за неделю там салон был там 98 81 там за месяц еще чуть пониже ну цифры не отражают реальность но важно иметь такой дашборд на котором вы будете видеть то насколько у вас доступно облака вот этот подход со ссылается соло да он позволяет формализовать и четко определить уже хорошо у вас все или плохо потому что вот просто у нас все плохо или у нас хорошо но такие слова которые ни о чем не говорят так что пожалуйста определяйте набор критериев то есть смотрите на основе чего вы хотите замерять доступность облака считайте это все водитель будет достаточно здорово кроме этого внедрения от этого подхода со слов позволяет определить так называемый бюджет да то есть если у нас солому говорим что у нас 99 процентов у нас есть 14 минут в день если у нас четыре девятки мы определяем их слоту всего 4 минуты в месяц классно это чем на самом деле что мы когда но эксплуатируем облака мы знаем что при заданному слову у нас есть определенное количество времени которым можем потратить на все что нам потребуется если это потребуется а соответственно если у нас возникают ошибки какие-то и мы не достигаем вот этого is a lot of фактически вас бюджет расходуется на наши пить нужно срочно брать бежать и чинить и всегда держать бюджет чтобы он был потому что очень полезно и очень важная вещь вот то есть и того не знаю там подводя итог то есть может достаточно обзор на все но тем не менее первое сущность prometheus муж иметь больше метрик ну ниже ритешем то есть про митоз инструмент оперативного контроля и лучше не фильтровать метрики из за того что у вас там не знаю дата сайт может быть будет большое или проще лучше собирать все ну ставить летающим там час или может даже меньше это будет здорово определяете вот ключевые высокоуровневые метрики стройте правильные запросы вот я коротко рассказал да то есть как правильно там сумм рейд или any rate сумм делать вот стройте самаре даже борды замираете салоу ну будет в общем в этом случае все здорово вот такой у меня получился короткий может быть доклад вот спасибо за внимание можете задавать любые совершенно вопросы про мониторинг про кластер постараюсь ответить стаж от первый вопрос раз спасибо за доклад скажите мне ничего не упомянули про дисковой подсистемы как ты и мониторить или это не проблема ваш в случае скверны в кластером у нас то есть у нас сервисы все в основном стоит ли свод все что касается хранилище прочие у нас в отдельном скажем так db кластерах вот и да мы мониторим разумеется нагрузку на дисковую подсистему то есть там и уэйд вот это все снимаем с рабочих ног но в целом она у нас практически всегда 0 потому что наш сервис и стоит лишь очень редко кто когда-то на диск ходит пищалка вопросе есть здравствуй спасибо за доклад хотел спросить и а когда врачи но выкатывает новый сервис и хочется сделать какой-то бизнес метрику то вы как-то в этом участвуете нет на самом деле мы в этом никак не участвуем смотрите у нас все бизнес метрики пишутся по протоколу графит они пишутся пою dp и у нас для этого есть там куча всяких не знаю уже даже есть подключены и лаггер и в бойлер флейтах то есть у нас есть шаблон и микро сервисов в общем если разработчик хочет отослать какую-то метрику он просто берет и в коде вставляет просто за данную строчку отсылки у нас есть там готовый and point ну все мы в этом не участвуем и проводим какие-то постоянные обучения разработчики сами зачастую знают что и как им куда отсылать вот плюс у нас еще вот я горю в бойлер play doh в шаблонах всех наших микро сервисов то есть у нас три основных языка там печка питон и год мы зашибло не zero вали микро сервис там есть уже проинициализирован эй лагерь там есть уже отсылка каких-то базовых метрик вот а дальше уже разработчик если хочет что-то сам добавляет здравствуй спасибо за доклад такой вопрос вы сказали что вы используете проверки black box да вот у кодов есть еще свою проверки в cabernet почему вы не стали использовать их вы говорите сейчас праведность солидность право про вот это да да да на самом деле нам то есть у нас смотрите у нас есть еще метрика они я вероятно не упомянул помимо того что мы мониторим под not in running state мы еще мониторим порт restart каунт вот как раз собственно когда у нас ли вниз или ревность пробы не проходят тут под начинает рестарта ваться проверка не прошла губернатора пытается перри поднять проверка опять не прошла но опять перед поднимает его для таких кодов у которых rate соответственно увеличивается мы на это лед получаем здравствуйте спасибо за доклад я здесь мне такой вопрос вы сказали что про минтая усну для оперативного мониторинга и рассказали про и корден роуз что ну собственно prometheus считает где-то там фоне и соответственно там разработчики не грузят там своими запросами эту штуку соответственно как как быть ну то есть он посчитает он сколько хранит вот эту информацию то есть все что юрий каннер recording rules и основные метрики они будут хранится столько сколько выставлен ретенция для data set of примет верующие то есть он задается там через аргумент командной строки у нас уставлена там на 2 часа все смысле потому что вот смотрите там циpкa поднялось до parameters у себя это сохранил вот разработчик поправил и хочешь посмотреть но исправило проблему или нет соответственно как он увидит смысле если он рикарду написал какая нет разработчики они их не пишут это мы создаем вот эти серые колдуны для вот такого набора метрик а дальше то есть там смотрите сейчас я вернусь к этому слайду я покажу акт акт акт акт акт акт акт акт акт акт акт так где же вот да то есть смотрите тут рикарду создается каким образом то есть мы считаем контейнер цыпа users ну то есть сколько он потребляет циpкa но мы суммируем по имени падает и namespace у таким образом там на самом деле но фактически несколько грубо говоря новых там там series создается на основе вот этого вот этой метрики а дальше разработчик просто выбирает свой namespace кубер найти где у него сервис выбирает имя кода и получает тут же всю информацию вот а сами рикарду ламы именно мы пишем да и стараемся их написать вот именно таким образом обобщенно чтобы потом можно было просто то есть разработчик не ничего не меняет конфигурации примет и русов не хотят спасибо за доклад было здорово а скажите почему в вашем случае вы выбрали для бизнес метрик клик хаоса не тот же самые параметры смотрите какая история то есть для бит в какое-то время у нас даже там не было кубер носил маску вернуть свои это примерно где-то полтора или года или около того скажем так ну в активном развитии до этого использовался график вообще для мониторинга всего на свете в том числе до продуктовых метрик потом ребята из юнитам мониторинг провели там research и сделали вывод что хранить метрики гораздо эффективнее не в граффити например там ну в клик хаусе вот соответственно бизнес метрики все уезжают crack house потом у нас появляется кубер нить мы пробовали cabernet мониторе через те же те же самые наборы скриптов до который там для инфраструктуру на это очень быстро выявила их неэффективность поэтому нужно решение но собственно про металл слот а поскольку мы сейчас хотим ряд метрик ходить долгосрочной перспективе то еще и вот вот на этой самой картинки где я показывал вот мы пытаемся сделать вот такую схему смотрите ну то есть если бы раньше у вас все-таки не было решения с ли хаусом вы бы сейчас рассматривали хранение бизнес метрик фармит и или нет или там есть какие-то объективные причины горячего нет не рассматривали бы потому что на самом деле на таких постерах то есть там размер досыта очень быстро увеличивается и там за сутки может быть не знаю там на десятки гигабайт идет потребление памяти и плюс у про метался у него есть короткий нет не было и скорее всего не будет никакой не отказоустойчивости там не репликация не шарден га хранить долгосрочной метрики в про метаюсь это неправильная идея вообще вот есть замечательная очки на гитхабе с номером 1500 на проекте про метался и можно почитать то есть она как раз вот про ту ну стоит ли не стоит хранить метрики долгое время в принтере оси ход ясно спасибо добрый день спасибо за доклад у меня такой практический вопрос насколько часто конкретно у вас в компании настроена скрейпинг я бланка но надо экспорта для все для всех job of для всего раз в 10-ку у кого-нибудь ещё есть вопросы ладно если у кого-то они еще появятся можно будет задать их на дискуссионной зоне а сейчас поблагодарим михаила за его доклад пасибо"
}