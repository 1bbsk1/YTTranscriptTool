{
  "video_id": "y1Jqm8ObcZ4",
  "channel": "HighLoadChannel",
  "title": "YTsaurus — это будущее DWH, и в Яндекс Маркете оно наступило / Филипп Козьмин (Яндекс Маркет)",
  "views": 3295,
  "duration": 2867,
  "published": "2023-09-01T03:13:01-07:00",
  "text": "и я так понимаю тьть и ДХ удачи коллеги Добрый день Меня зовут Филипп я вам буду сегодня рассказывать про то как мы в Маркете построили хранилище данных на технологии которая недавно вышла в Open Source Пару слов про хранилище хранилище - это такая система которая представляет из себя одну базу или несколько цель которых собрать все данные из вашего бизнеса и быть тем местом откуда аналитики Bi или эти данные потребляют для кого будет интересен данный расклад доклад Если вы любите всё что связано с бида вам будет интересно если на текущий момент вы задаетесь вопросом как же вы будете масштабировать своё хранилище вам тоже будет очень интересно это доклад во многом про это а если вы страдаете от того что ваша архитектура обработки данных очень модульная Вам приходится использовать много технологий этот доклад тоже даст вам рецепты Если вы уже что-то послушали про Иу или впервые проу слышите вам тоже понравится данный доклад стараюсь вам дать некие рецепты создания хранилища на этой технологии начнём с истории развития хранилища данных Яндекс Маркета оно прошло На самом деле достаточно стандартный путь в индустрии оно начиналось на очень маленькой базе данных Oracle потом под ростом данных мы мигрировали на ходу в годах 18 развился до взрослой фр было произведено сравнение их функциональных качеств и тогда мы поняли что как систему далека уже удобно использовать в it dat - это та система которая первично принимает данные и их структурирует но вы ещё не делаете ключевые кор слоя хранилища кор слоя хранилища В начале мы пытались сделать на верке но перешли на Open Source решение Пару слов про слой хранилища это так называ дельный слой он же ДС это то место куда вы складывает вот представьте себе У вас есть клиент объект он делает Ну просматривает все возможные Афера потом делает заказ заказ поступает на склады это связано со стоками стоки связаны с доставками это объекты которые связаны и наши хранилища очень сильно связаны Я думаю в банках телекомах связи то настолько же сильные как и у нас и вот мы приходим к 2022 году с архитектурой ИП для сборки вот этого ядра детального слоя А какие же параметры имеет наше хранилище к этому моменту ну во-первых оно уже дорослою планы роста более двух разг пони в 202 и вот Как видно на графике в дцать третьем году Да у нас получилось Мы доросли до таких масштабов при этом команда дата инженеров очень маленькая это 20 человек на тот момент было сейчас побольше 25 Вы должны понимать Это очень Малая команда вообще по меркам хранилищ данных И что же у нас есть в архитектуре к каким проблемам мы пришли Да вот на начало двадцать второго года проблема первая катет Грин Больше пба он не слится мы не взаем проблема вторая есть ограничени есть ролин на выгрузку из гпма непреодолимый проблема третья уже данных было столько что мы часть витрин продолжали строить на и тогда продолжали это делать как принято в даках мы использовали не SQL мы использовали императивные языки программирования и это является определённой проблемой Мы про это ещё поговорим нам приходилось развивать два разных один под M второй под по сути Red ИС это большие накладные расходы Ну Пятая проблема у нас был детальный слой как раз собранный в Грин ламе и мы посмотрим какие ещё были на самом деле варианты сборки этого детального слоя потому что мы поняли что от рип будем отказываться в первую очередь он не выдержит масштаб а идти путём добавления новых шардов мы не хотим это как бы неправильная концепция она всё равно заводит рано или поздно в тупик поэтому Как же вс-таки можно строить детальные слои на такой технологии как но у меня был ранее опыт построения хранилищ данных на дупе и у меня была определённая Фобия с этим связано я ожидал что будут четыре проблемы первое мне Будет не хватать онне нужен я поясню Почему будет мохите вду в рете ня было оние что я в ближайшие годы буду кататься на некой рули бо и вот будем смотреть как мы эти проблемы решали первое вообще почему нужен Да почему мы за него так Рату перво это всё-таки декларативный язык вы пишете Бине Вы конечно можете на императивно языке написать эффективный код даже победить Дато инженера который пишет на и но когда ваши хранилище масштабируется через год Я вас уверяю императивный код упадёт по памяти ещё по каким-то лимитам которые вы выставили И когда вы накопите тысячи тасо Вы пойдёте по кругу вы будете каждый день что-то в нём чинить у вас не будет никакой адаптивности поэтому Нам нужен был очень и нам в нужна реляция Это са на текущий момент компактный способ сзи данных а бы наше хранилище с большим количеством связей Ну и порог входа мы на самом деле за сч того что не имеет высокого порого входа работаем с аналитиками на одном языке и даже по-разному оптимизируем данный язык инженеры оптимизируют Время выполнения и ресурсы аналитики оптимизируют время которое они потратит на написание кода и размер этого кода самом деле что он предлагал на тот момент он предлагал три движка СР ий спа Они сильнее уреза по функционалу иляха по полнее ноха мадс у него нету дешёвой парадигмы спуститься на тот же самый Спарк и соответственно часто встречалось как модульность в хранилищах которые были организова на Ду есть когда приходилось использовать набор технологий чтобы почита так и в прин императивные языки часто побеждают в хранилищах построенных на ходу Вот я для себя выписал ключевые вещи которые на мой взгляд нужны в SQL нотации и есть такой язык который называется yql это основной SQ язык в платформе На мой взгляд функционально он сейчас превосходит вот эту тройку то есть выбрав его вы потратите Меньше времени на сглаживание мест которые как бы необходимо сгладить для того чтобы строить хранилище данных Особенно я бы обратил внимание Вот на три часто встречающих вещи во-первых это так называемые блокировки и эт в у заус когда вы будете работать с данными в хранилище Вы можете спокойно их одновременно писать них и читать Вы можете про это не задумываться это даст вам очень серьёзный бусте при пересчёта в хранилище - это очень часто встречающаяся операция Когда вы перестраивали процесс вам нужно читать при этом вам нужно ещ данные обновлять третий например Аспект это наличие шаблонов Где вы сможете встраивать свои агрегацией аналитические функции они есть они развиты ть зас в и это вам поможет То есть если например вы захотите в спарке в добавить собственную аналитическую функцию написать какое-то сложное окно вам придётся А ну либо использовать dataframe либо просто использовать на самом деле другую нотацию ни скель и соответственно количество вообще языков которые вам будут доступны для того чтобы достаточно активным образом расширять границы вашего ке языка А мы очень любим Python потому что Python - это язык который активно А в инженерии данных и вообще в обработке данных применяется и соответственно а нам доступна возможность в одном месте написать любую Python функцию и сразу же её в принципе вызвать в SQL конструкции это достаточно удобно для отладки это даёт вам большую гибкость по встраивания кода особенно когда идёт какой-то сложный парсинг у вас Он написан на питоне и переписывать на SQ вы не хотите это быстрый переход и это стоит абсолютно адекватно по ресурсам это не будет выглядеть для вас расч потребует процес потратите не более 20% процессора проблема вторая с SQ в дупе которой я боялся это вот как раз модульность как парадигма она как бы хорошо очень скели но она не отзывчивая представитель тут Хай как бы выбрав Хай вы не будете бояться масштабов данных но вы будете сталкиваться с тем что любо Даже самый мальский запрос будете ожидать очень дого в другие парадигмы например Memory streaming это Spark или не локальный MP это имла они будут очень быстрые на фоне Хава но у них существует предел масштабирования и рано или поздно вы в этот предел будете упираться и нету никакого фулка вы будете падать и пойти или идти оптимизировать код либо переходить на другие платформы расчёта и вот этот выбор как бы делать совершенно необязательно на самом деле Почему Потому что в yql в том же самом движке совмещены Сразу две парадигмы а есть движок под ним и есть distributed движок который умеет читать на стриминге Когда вы напишете и запрос планировщик самостоятельно решит Каким образом его можно отработать если данные ваши адекватного размера имеют определённую структуру он постарается это обработать очень быстро Нан если вы столкнетесь с огромным массивом данных в терабайты а то сот раба очевидно он выберет стратегию не удт обсе все нужные вам данные получаете очень удобную гибкость особенно когда у вас идут тесты Представьте вы написали какой-то запрос над таблицей 100 туров такие случаются и вот хотите ограничив количество строчек сотни посмотрите как он будет работать очевидно Если вы будете делать это насе вы получите все те самые как бы накладные расходы которые есть планирование операции материализация даже что запи десятки минут исполнения он же исполнится в Memory стриминг и вы получите за минуту понимание того как этот запрос устроен поговорим про следующую как бы проблему и чего я боялся Надёжность А вот фактическая Надёжность Изаура Такова Он последний раз падал в декабре 2022 года я тогда не заметил этого падения в хранилище на то есть причина У нас два боевых кластера и наши процессы на втором боевом кластере успешно рассчитались А вот Надёжность инфраструктуры как бы я предлагаю ваше оценить вам А вам же я расскажу какую стратегию расчёта мы на самом деле используем мы не считаемся в параллель мы считаемся чуть хитрее мы используем идею расчёта ма сй а по сути мы запускаем два etl процесса на двух кластерах когда запускается таска А на кластере о она создаёт и блокирует семафор таска 2 на кластере таска о на кластере 2 видит семафор и на самом деле ожидает она не считается когда же таска 1 закончит свой расчёт она скопируют данные на второй кластер отпустит семафор таска 2 увидит окончание семафора увидит что е принесли данные и просто Скит расчёт А почему мы преследуем такую стратегию на это есть три причины во-первых Вы потратите вычислительные ресурс один раз во-вторых Ну копирование на самом деле бесплатно во-вторых вы будете иметь абсолютно идентичные данные на двух боевых кластерах а третий момент ваши данные будут по времени появляться одновременно для пользователя практически без разницы на какой бы кластер он не пришёл он видит одинаковое состояние на двух как бы боевых кластерах Поэтому в принципе такая парадигма плюс Надёжность вю ни в про достижение надёжности переходим к самому интересному в хранилище как будем строить Вот этот страшный связанный детальный слой а будет четыре вопроса три которые касаются его логики построения и четвёртый как бы непосредственно техническому алгоритму вопрос первый А сд2 ну это на самом деле форма организации связи данных Вертикаль Давайте просто поймём вот если есть заказ он проходит некие стадии жизненного цикла Окей у него меняются атрибуты и вот базова система источник вам отдаёт его в форме таблицы а его можно привести немножечко в другое состояние перевести в состояние когда есть дополнительные атрибуты времени которые покажут вам следующее во-первых вы всегда будете знать в определённый момент записи в каком состоянии находился заказ очень полезное бывает свойство во-вторых вы всегда очень простым способом можеть актуально состояние всех заказов которые эти дополнительны Дат построить их не так легко потому что это получается нужно вертикально связать со строчки но строим Мы один раз а читаем много поэтому мы предпочитаем в детальных слоях использовать эту модель вопрос Следующий как мы хотим построить этот детальный слой когда мы достаём новые данные мы можем идти стратегии апдейта можем как бы делать полный ребилд больших блоков табли кото назват можно и так и так рассуждение следующее апдейт - это по сути в какой-то мере произвольный доступ к блокам данным А и поскольку было решено что хранилище этого масштаба должно строиться преимущественно на хдд Аде работает очень плохо с произвольным доступом то есть хдд диски реально по скорости модификации сильно деградирует поэтому это первый технический Аспект Почему мы всё-таки предпочитаем строить партию целиком просто потому что эффективность дисков на порядок выше аргумент второй перестроение партиции полностью нам открывает очень два полезных свойства идемпотентность - это свойство которое говорит о том что сколько бы раз я вот запрос не повторил я получаю один и тот же результат А как я говорил ранее очень частая стратегия в хранилище это пересчитывать вот обычно Я считаюсь как бы с дневным инкремента А тут пришёл бизнес заказчик говорит А вот этот атрибут или вообще вот целую таблицу желательно пересчитать но алгоритме за 3 года индент вам позволит а ещ с ум наличия абсолютно спокойно не беспокой запускать эти процессы рядышком они будут работать и они друг друга не будут никак мешать и будут давать вам один и тот же результат на выходе и ещё одно свойство которое даёт перестроение - это иммутабельность иммутабельность - это по сути неизменность неких блоков данных которые Вы только что построили А это путь к холодному хранилищу Ну то есть если вы даже Посмотрите практически все базы как бы могут вам позволить только одно из двух стратегии Либо вы уйдёте в колоночной хранилище И тогда апдейты вам недоступны совсем а Ну либо вы пытаетесь как бы играть в апдейты но не получаете эту структуру а структура супер ценна колоночная организация хранения во-первых откидывает всегда ненужные атрибуты из боков Когда вам не нужны они в запросе Вы очень сильно экономите чтение А во-вторых вы безумно нажимаете данные данные в одной колонке друг на друга похожи поэтому они потрясающе сжимаются соответственно мы идём стратегию пол перест последнее время провокационный вопрос нормализация денормализация или просто строить Как можно простые объекты вот смотрите во-первых нашим бизнес пользователям всегда проще работать когда таблица - это бизнес объект заказ - это таблица Афера - это конкретная таблица и так далее То есть им не нужно думать как вообще собрать какой-то бизнесов объект из разных частей Казалось бы это парится тем что можно сверху насадить какие-то абстракции Но на самом деле в большинстве случаев планировщики ни в одной базе не справятся с тем чтобы сделать сквозь то есть грубо говоря когда вы попросите один атрибут сквозь прокинуть вы получите сразу всю таблицу потому что планировщик не в состоянии чески определить какие куски вот этих вот джоно вам нужно откинуть и вы потеряете свойства своего колоночной нормализация - Это хороший размен дисков на цпу Ну то есть как бы понятно что разделяя данные они меньше умножаются внутри таблички но при этом когда вы начнёте их как бы вытаскивать вам понадобится цпу чтобы их заново собрать вот сверху Вот можете на картинке посмотреть обычная нормализованная модель снизу нормализованная где один объект разбит на множество физических табличек а они будут компактнее Но каждый раз обращаясь к ним будете вот если у вас хранилище а Аля в it Ну или на самом деле Аля ходу у вас такой экономии особо нет она вам не нужна Поэтому в принципе в нашей парадигме это не имело никакого смысла как бы экономить Диски за счёт на самом деле даже более дорогого цпу поэтому это ещё был аргумент в пользу классической простой модели если Вам кто-то скажет что нормали Зро модель яче модифицировать он будет прав отча отчасти Если вы хотите добавить атрибут или часть атрибутов да это просто не надо пересчитывать захотите поменять хотя бы одну строчку кода в Джой или фильтрации весь объект выкидывайте и перестраивается заново потому что вертикальный состав полей меняется а перестроить такой объект м будет намного сложнее чем обычную цельную табличка поэтому это тоже очень спорный такой аргумент Ну и как бы как я ранее говорил колоночной хранение уже очень хорошо для нас решило задача оптимизации дискового пространства оно уже На физическом уровне организовало то что мы сейчас видим на логическом оно разбило данные вот на эти по сути маленькие области и там производит сжатие То есть получается нормали модель становится не особо нужно и мы идм в классическую модель как же будем строить всё определились со всеми вопросами строим Ну вообще когда мы вот строим сейчас таблиц детального слоя засе в случае если она 500 гигов Ну меньше или там около това особо заморачиваться не надо берм пару ней из предыдущего слоя обновляем и она за 15 минут у вас перестроится вообще без каких-то сложных алгоритмов когда таблицы будут уже терабайт здесь как бы есть на чем подумать в алгоритме построения детальных слоёв как я вам говорил данные связаны вертикально всегда есть редс то есть Вот эта упорядоченность Это обязательные редьюс операции логически и соответственно главное что мы знаем про редьюс операции нужно стараться их производить на меньшем объёме данных Чем меньше объём данных будет тем как бы она работает эффективно надо отдать должное что эффективность даже приросте данных хороши мы сечас Это посмотрим но это будет оптималь соотвественно как мы действуем мы берм пару партий которые только что пришли из источников редм готовим практически готовый слепок детального слоя и м накаты на оставшуюся часть ДД вот к такому алгоритму мы сечас стремимся для крупных на самом деле средних потому что я сейчас буду показывать детальный объект среднего уров вот предположим ласси история партиции и на 90 дней в глубину их Обновили это получилось как бы совокупный объём изме данных 139 ГБ 30 минут заняло Почему 90 на самом деле вот этого порога нам хватает для того чтобы 99% записи обновить можно больше мы попробуем сейчас сделать больше например сделаем се входных дней и 366 проти Дневни в глубину это ПТ точность обновления ДД и в том жи когда мым пересчитывать это за 2 года мы возм год данных и ещ год хвоста ДД и всё это вместе попробуем обновить получаем вот Такие показатели то есть 500 ГБ у нас просчиталась за 70 минут 1000 гиб Ну по сути терабайт за 126 минут если мы как бы базовый инкремент возьмём как бы за единичку 13 гигабайт то Наш график выглядит примерно вот таким образом реакция подаваемого на вход объёма данных СРО что это означает на самом деле означает следующее мы не боимся перев от слова совсем есть переход от инкремента к расчёту за огромные глубины для нас не является проблемой он как бы происходит логарифмической сложностью А это очень классно это решает одну из самых Вот как раз нудле задач как это хранилище развернуть за несколько лет и получить актуальные данные вот Наста Ну есть те вещи которые были очевидны как Плюс То есть я не сомневался что ИВС мне их даст и как бы сейчас я просто его пох за то что и так должно было быть в нём очевидно хорошо Это его масштабируемость ещё Раньше он выбрался по этому критерию можно классно в нём организовать среду тестирования И вообще стоимость всего этого масштабируемость Ну вот если Вы посмотрите на цифры размера нашего хранилища которая обрабатывает сечас там и хранит 30 данных ис ста каждый месяц то все параметры текущего кластера можно расширить в 100 раз я совершенно не беспокоюсь про то что мне непонятно как На горизонте ближайших 10 лет оно будет масштабироваться это вопрос для этого хранилища снят полностью Я не знаю кластеров ходу такого масштаба Я слышал что парочка есть но во всяком случае я их лично не видел среды тестирование Тестируем на классная среда изоляции по расчётам и по квотам хранения То есть вы можете спокойно сказать расчёту что ты прочитаешь в отдельном пуле ядер в отдельном пуле памяти и В отдельной квоте хранения данных Он положит вам всё Это рядышком и вы вообще никак не повлияет на прод процесс в какой бы момент времени вы это не запустили это всё будет полностью изолировано Если вы соответственно выполните два условия то есть во-первых в таком случае хранилище Желательно чтобы не было персональных данных очевидно соответственно второе у вас должно быть два кластера боевых потому что вы никогда от логической ошибки не застрахованы Вам может на какой-то момент времени показаться что сделали хорошую поставку вы сначала на одном кластере задеплоить и у вас будет момент времени откатиться мы этим Ино пользуемся Поэтому если есть боевых кластера ненах данных вам не нужно поддерживать ничего кроме боевого кластера его настроек Как запускать процессы тестирования и данные копировать с кластера на кластер не надо для этих расчётов стоимость Ну есть три аргумента в пользу классной стоимости во-первых хранилище ориентировано на хдд соответственно нету требований однородности серверов и коллеги как раз недавно про это рассказывали у них много действительно серверов разного типа участвует в кларе А значит вам не нужно гнаться за каким-то железом определённого типа ну и вопрос опыта Чем больше тем дешевле вот что у меня получилось Я взял собрал абсолютно идентичный по железу квоты на в так идентичный тому железу которое было для плама Я получил разницу в цене в три раза в пользу из Арса то есть в три раза будет дешевле Если вы соберёте одинаковые показатели а на самом деле когда я просто сравнил фактическое своё хранилище с грим Плам И сколько вообще стоит цена хранение на одном и на другом как бы стеке у меня получилась разница в 23 раза то есть 1 гиб информации мне в 23 раза дешевле стоит хранить чем на грип разница большая Окей Вот Мы перешли действительно на всеми слоями получили упрощённую архитектуру а движок основной который используется в инженерии развиваем один ельник классические четыре слоя в котором очень простой ль слой А давайте поговорим ещё пару слов про общую архитектуру Я здесь пробегу сейчас Галопом Если вы будете делать хранилище насе вы получите ещё очень хорошую интеграцию с B а помимо движка yql есть так называемый движок cck по сути это вы сможете развернуть очень дешёвым образом кликхаус внутри вашего кластера и сразу подключить его к данным а затем соответственно это произойдёт я уверен в ближайшее время вы сможете воспользоваться дансом для того чтобы начать разработку ваших дашбордов графиков и прочего это тоже очень хорошее преимущество на этом я детальнее более по архитектуре всего хранилища не пойду у нас не хватит время я сегодня рассказал только про ядро часть Ну давайте подводи ито этого эксперимента я начал работать в сфере хранилищ данных в 2011 году впервые их я увидел Тогда эта сфера была она выглядела достаточно классно во-первых мы разрабатывали на нале и нам не требовалось тогда каких-то других более сложных как бы языков императивных джавы скалы для того чтобы писать поставки данных не было в 2011 году каких-то сложных моделей просто потому что никаких вопросов Как же оно будет масштабироваться не стояло А я в 2 одиннадцатом году когда увидел первый гнп Я думал не хватит в мире данных чтобы он наполнился вот это было такое примерно ощущение сейчас это уже не так и четвёртое я заново разрабатываю на прод Ну не совсем прям на прод но во всяком случае на продуктивном кластере ведёт вполне Разумная разработка которая как бы безопасна то есть безопасно во всех смыслах потому что у нас там нет персональных данных есть закрытие доступов и всё изолировано вот и что же я хочу прямо совсем в завершении сказать иус мои личные ожидания превзошёл и поменял вообще моё понимание того как хранилище данных можно строить второй момент я уверен что На горизонте года двух внешне инсталляции в каких-то компаниях и это даже уже видно что есть определенный набор Энтузиастов которые находятся в тиках зау которые сейчас пытаются развернуть его инстансы Ну пока предположу что в основе для экспериментов но возможно рано или поздно появятся первые как бы попытки уже внедрения под боевые задачи третье как бы э технологию точно однозначно надо рассмотреть э чтобы вот не заниматься порождением определённого беспорядка когда побеждает концепция Пусть кто Каждый делает как Он хочет лишь бы были какие-то правила о то что инфраструктура Просто становится супер гидроген най это Решим потом то есть потом просто из этого уже выбраться будет тяжело Лучше попробовать развернуть это сейчас на вот этом Едином однородном кластере на сегодня Это всё что я вам хотел рассказать надеюсь вам понравилось голосуйте за доклад Спасибо большое Фили ребятушки пожалуйста подняли свои телефончики навели на QR код и Оставьте пожалуйста отзыв Ну пожалуйста Ну ребята ну это важно спикеру нам конференции Мы же Для вас стараемся чтобы было интересно А друзья мои у нас с Филиппом даже сегодня Два подарка за лучшие вопросы один от организаторов от Филиппа поэтому призываю всех задавать вопросы у нас есть чат кто стесняется задавать Пишите в чат То можно через анонимного чат-бота кто с нами онлайн Под трансляцией есть там кнопочка с чатом пишите туда и поднимайте руки Давайте вот сюда сначала Добрый день спасибо за доклад Вопрос такой насколько я вижу Независимо температуры данных все они хранятся ввх у вас используете Като стратегии разделения данных на горячие холодные Если да то какие и не думали ли на тему того чтобы охлаждать данные В3 например или ещё куда-то ну на текущий момент именно опять-таки хдш хранилище в принципе стоит сейчас адекватно я не могу прямо конкретную цифру сказать сколько стоит о гигабайт данных Но немного и поэтому просто не стоит сейчас такой задаче Как слить данные а а если вопрос бы делаем лимы какието ра нище ске Ну то есть например более оперативно У нас есть примеры как и часовых расчётов так и можно сказать пти минуток То есть это просто будет немножечко в другой архитектуре там появятся динамические таблицы НТ но оно может работать и в такой парадигме то есть я правильно понимаю что можно использовать разные движки таблиц для разные движки таблиц Они как раз хорошо подходят под разный стиль расчёта То есть если вы считаете на дневном масштабе это статика это об десятки ров А если вы считаете как раз на мам скеле вам динамические таблицы очень подходят интервал обновление для них адекватные 5 минут они будут с этим вполне нормально справляться до 10.000 записей на транзакцию до 100000 записей на транзакцию Спасибо вот там вот вопрос пожалуйста Да Привет Спасибо большое за доклад ты на одном слайде показал что Вы практически все обновления закрываете глубиной 90 дней а что Ну есть вообще понимание Что делать если пойдут какие-то очень большие ретроспективные обновления на год на два назад О'кей вопрос я понял вот я как раз показывал на графике Это скорее всего было может быть не видно или голосом не продублировать точки - это три стиля расчёта на Первом я взял 90 дней на втором я взял год а на втором на третьем я взял 2 года и как раз ты можешь посмотреть что время расчёта от 90 дней до до 2 лет изменилось незначительно То есть он очень хорошо реагирует если ты на нему подбрасывает каждый день таблицу это как бы приемлемо для вас Если вы хотите обновлять таблицу за глубину 2 года каждый день да это 2 часа вопрос как бы Зачем если можно делать инкрементальные поставки и вот мы как бы совмещаем одно с другим если нам надо мы пересчитывает 2 часа а так обычно мы считаем 30 минут за 90 дней Спасибо Спасибо вот там вот вопрос Привет Спасибо за доклад два вопроса Первый сравнивал гпку срум по стоимости места а по производительности сравнивали или нет производительность ты имеешь в виду если бы мы взяли например одну таблицу там и там и попробовали применить он обработки там исть снива с дум в принципе это сравнение можно было бы произвести А так с другими системами Не понимаю зачем Поня сни из разного класса то есть Это наверно бессмысленно их ставить друг напротив друга просто интересно по скорости регламента грубо говоря ушли вниз вверх или он бесконечно ядра ушли как бы стали быстрее собирать после переезда медленнее или вы весь день крутите сборку А я понял о чём ты говоришь вот самое забавное на самом деле скорость построения общая витрины она растёт и как раз во многом из-за самых болевых точек когда ты пытаешься вот эти огромные объёмы данных выгрузить обратно на пресную систему то есть выгрузка из Грима она очень сильно трот И эта точка она в принципе может пошить вс полу быструю на обновление какими-нибудь апдейта внутри пма понял спасибо если можно второй вопрос Ты показывал что вы тестирует на проде вот на выделенных железка они выделяются динамически или это какой-то заранее подготовленный для тестов это прям настраивается конкретно мной и лидерами команд инженеров лы рас представляют собой дерево вы просто заводите нотку существу квот нро и вообще их нет Есть наме те могут работать в квотах без гарантии То есть им достанется только тот ресурс который не нужен боевым процессам и отдельно у тебя существует настройка как раз так называемых аккаунтов это то место куда таблицы приземляются тоже заводишь отдель прием туда понял спасибо что надежность дупа вызывает какое-то сомнение Однако вчера в докладе про я услышал что все те же проблемы присущие и которые могут возникать с ходу просто должны быть люди должны быть инструменты которые помогают их решать и админы в Яндексе достаточно круты чтобы их решать так вот нет ли ощущения что ну просто по вашему прошлому опыту админы дупа были не такие крутые как админы вкп сходит размером это достаточно стабильно Ну почему Есть такое ощущение что хадуп какой-то нестабильный м Можешь ли ты пояснить вот вопрос Ты имеешь в виду что у тебя есть кластер дупа сопоставимый по масштабу то есть ну у нас есть кластера ходу которые Ну несколько кластеров каждый из которых в два раза больше чем у вас и они работают хорошо много эк зоба кластера и многомиллионные по ядрам и наш tole сейчас 250 пиб ну не как у Яндекса но неплохие размеры Я просто не понял ты говоришь превосходит а тут а кластер о котором вы говорите это 35 пиб Да нет кластер - это кбайт кластер Яндекса большой эба это ваш кластер выделенный меньше Это единый кластер это просто логического экта в который Существую он единый просто ребята рассказывают что вы их Ну и нарезается более мелкими для отдельных это это логическое разделение на самом деле вот эти два сверх крупных кластера которые существуют в Яндексе покрывают потребности всего Яндекса и в том числе хранилище Маркета поэтому я говорю что я вот просто пока ни Ну кластеров на которых мы работаем подобного масштаба не видел Ну понятно просто должны быть уникальные обстоятельства уникальные компании например майкрософте Фейсбуке убере есть такие кластера да Ну к сожалению мне пока не удавалось их посмотреть действительно они представляют единое физическое пространство или это теоретически какие-то под кластера а Возможно они есть и Ну аурусе тоже это теоретически шардирование можно изолировать мастера за отдельные как бы области это действительно кстати порой бывает полезно Очень даже а просто Отвечая на твой вопрос У меня был ли опыт и проектов Сха я не могу тебе честно сказать это действительно инженеры Яндекса вытащили вот эту Надёжность или это всё-таки его архитектура Мне кажется архитектур очень хоро Да в этом вопрос архитектура хорошая Однако она очень похожа на то что в дупе им возможности по дивани на и всякое такое То есть это почти один в один и Ну нет ощущения что я возьму себе в it если у меня нет команды инженеров Яндекса я смогу его сделать таким же надёжным как у вас Почему у вас есть такое ощущение вот вчера был хороший очень доклад как раз с точки зрения нижнего уровня Иса когда рассказывали про то какие есть конные прикладные плюсы при его администрировании вот здесь очень интересно бы с администратором который сказал да Вот это может пря повлиять на то что я буду делать его стабильным или нет но по факту как ты видишь это фактический параметр он очень стабильный то есть инфраструктура нас не подводит большая часть вот какая сейчас есть проблема у хранилища что его подводит Данные есть данные которые очень часто меняются это единственное что добавляет нам нестабильность иф Нас устраивает абсолю но пока мы не получим е Несколько или кесов наш диалог как бы прохо более теоретической плоскости нежели в практической Давайте дальше Вот там Мне кажется у нас был вопрос Василий компания ДНС вопрос Следующий вы упомянули что конфигурации гпма не хватает для обработки ваших данных хотелось бы узнать какой обм данных на мо принятия рения пере на нову попытки перен Гримма либо какой-то внутренней оптимизации хранения вот смотри когда уже стало всё понятно На тот момент если я не ошибаюсь где-то половинку от максимального касита 500 ГБ занимал Грин план А мы уже Понимали Вот наши данные которые нужно в детальный слой грузить и всё там оно не влезал ником образом уже расширен к Макси бо часть оттуда ушли А какой вторая часть вопроса была были ли какие-то попытки переконливо из попыток реконфигурации логической когда ты берёшь и делаешь сильно нормали Зро ную модель данных для того чтобы сэкономить существенный объём мест который занимает детальный слой если ты говоришь про ресурсную историю Ну то есть про аппаратную часть как его реконфигурации заводить вакуум блокировать таблицу А что у вас я понял вопрос звучит так Каким образом мастер достигает вот того самого эда о котором я говорил Я боюсь тебя сейчас обмануть потому что последний раз я смотрел об этом как бы статью месяца три-четыре назад если я не ошибаюсь мастер Когда видит попытку модификации данных он Берт некие блокировки берёт это как будто отводит отдельное дерево кипариса Я боюсь тебе с алгоритма соврать в принципе это в документации описано я точно видел что эта статья детально разобрана Как он это делает Спасибо я думаю что если это очень важно и интересно ты можешь потом по Контакту написать спикеру и тебе помогут с детальной информацией Привет Спасибо за доклад А у меня вопрос такой учитывая что с 2011 года уже в работе все Мы помним хадуп появление импа появление Хай потом в хаву сделали на шлюпку лапа и все говорили что вот теперь-то дуп станет быстрым потому что мы встроили этот ЮС вот в этот движок им и в общем-то архитектурно Я смотрю что в принципе всё было очень похоже и услышал от тебя оговорочка о том что при определённых размерах всё работает здорово Вот и просто вспоминаю какой Вау внедрении был тогда то есть Вот то самое появление трёхногая халупа в банках А как ты думаешь э АйТи заус На каких объёмах примерно стоит думать о внедрении Нижняя планка не Верхняя там всё понятно Нижняя планка О'кей Аа есть у меня определённое мнение Ну давай предположим хранилище развивается прям А с нуля Ну то есть э вот мы пойдём по неким вехам если мы строим терабайт хранилище которое вы можете прикинуть что на 10 лет не раст до оного пита байта Ну возможно в таком случае вы можете сейчас даже пойти в mpp системы достаточно классические хоть тоже быт для вас они позв попроще ивас долж вполне удовлетворять в случае вот этого петата На горизонте 2-т лет надо как бы уже вс принимать однозначное решение Вы пойдёте всё-таки строить либо своё хранилище на дупе либо на в принципе вас сечас другой альтернативы особо хорошей нет Спасибо сная отсечка Давайте один вопрос ещё и вот будем выбирать лучший Добрый день спасибо за доклад вопрос по поводу выбора модели данных пробовали ли посмотреть в сторону якорной модели то есть вообще Были ли такие попытки вот и ну второй вопрос уже относительно выбора нормализованная де нормализованная модель Но это видимо после первого ответа Ну на самом деле мы оценивали вообще насколько ну был набор аргументов которые ранее озвучил Почему мы в принципе не выбрали даже движение сто нормализации А так глобально когда я задавался вопросом сколько по ресурсам будет стоить обслуживание якорной моделе в Ис это Космос те же самые механизмы блокировок Вот это эды которые будут блокировать одни партиции чтобы Вы могли как бы работать с ними писать читать у вас на порядок скорость вопросов деградирует просто потому что сложность для мастера работы увеличится также на порядок даже поряд Да понятно просто одной из заявленной фишек вот насколько я помню это был как раз сор Mer Jo который умеет там за один собирать данные поэтому казалось что вот Якорная модель такое может подойти Угу Ну это значит у вас должны Как бы быть отсортированные данные мы далеко не всегда как бы их сортируем у сортировки должна быть определённая цель во-вторых вообще самый быстрый вид джоина - это как бы масай джоны поэтому мы как раз к ним и стремимся то есть по возможности если мы можем предложить какую-то архитектуру которая будет на мап Сайда мы будем делать масай по сути это шй который происходит в мпе быстрее его нет ничего поняла спасибо спасибо Ну что настало выбрать лучшие вопросы у нас Два подарка кому будем дарить я из как это из принципа подарю от себя Ой это был мой телефон подарок в виде кепки тому человеку который защищал хадуп Да потому что как это мне нравится когда есть какая будешь теперь защищать ходов в кепке Яндекса и второй подарок девушки Угу готовы вручать Я бы хотел вручить за вопрос связанный с изоляции расчётов я вот вот вот там вот вот туда вот Встань пожалуйста чтобы тебя видели наши помощники Всё спасибо тебе большое от организаторов от программного комитета тебе тоже маленький такой Презент носи как спикеру соответственно нашей конференции Мы тебя ждём с дальнейшими докладами по развитию тя на наших конференциях И последнее что я хотел сказать если кто-то на самом де сечас хочет потре визуально Мы сейчас с моим коллегой останемся здесь и можем показать вам это хранилище вживую с точки зрения его реальных го интерфейсов тогда поэтому не стесняйтесь подходите крия снаружи от зала ребята ловите докладчика Спасибо большое Филип"
}