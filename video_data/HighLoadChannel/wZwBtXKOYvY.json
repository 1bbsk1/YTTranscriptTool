{
  "video_id": "wZwBtXKOYvY",
  "channel": "HighLoadChannel",
  "title": "Как писать сервис, поддержка которого не превращается в ад / А.Резников, И.Мунькин (Mail.Ru Group)",
  "views": 2671,
  "duration": 2571,
  "published": "2017-12-11T01:45:41-08:00",
  "text": "сегодня расскажем вам о нашем опыте написание логов ну что поехали так господа второй микрофон не работает а давай мы с ним поиграем вот этот твой вот этой сейчас мы конечно тут часто я просто лишь ты не туда повесил а ну-ка так поговори а так да так он дару спасибо ну вот теперь намного лучшую спасибо продолжаем да ну собственно что стоит ожидать от нашего доклада в нем не будет ни код не примеров кода не примеров конфигурационных файлов не каких-то отсылок к теоретическим знанием мы с антоном просто поделимся опытом которые прибыли за время работы в этом проекте да и все наши выводы мы постараемся сформулировать на таком символическом монеты сейчас он немножечко маловат но мы будем развивать его зато очень лаконичен да собственно зачем мы пишем логин в первую очередь это расследование инцидентов и отладка так же вроде полезны для мониторинга и сбора статистики конечно же писать статистику лучше использовать используя специализированное средства как-то графит но если статистика вам нужно за вчера описать вы ее начать только сегодня воде могут быть очень полезным и так как выглядели воде чуть больше десяти лет назад и как выглядел в принципе хайло вот это экс коксе за ним апликэйшен сервер за ним база данных если требуется возможно вам крыш воде были лаконичные и 1 срочную хоть и содержали и от полезной информации как-то опиаты с клиента username дату к ттп метод с которым к вам пришли и путь а также сад с ответа и его размер но с тех пор прошел много времени аудитории интернета и гон это в том числе сильно увеличилась ноутбук есть даже у моей бабушки и что же мы имеем сейчас конечно же на примере нашего проекта первая часть не изменилось все также есть фокси теперь это уже точно engine x не какой-нибудь squid дальше application server а дальше куча пишет хотя до но перед тем как взаимодействие с многими нашими api сервер в первую очередь верифицировать пользователя и с помощью api аутентификации которая настроена над кластерам сессии кластером профилей также непосредственно само приложение ходит за профилями через соответствующий api и оставлять желать лучшего далее мы забираем информацию об опыте пользователя через соответствующий api которая лежит на то соответствующим кластером тарантулов после чего забегаем требуемую часть дерева пользователя забегаем публичные сути пользователя собираем информацию об объектов деве пользователя но завершаем все это походом наш биллинг я даю всю полученную информацию в шаблонизатор да это слегка упрощенная схема одного из запасов в нашем проекте урока могу он же этим box ну и пойдем дальше все воде в нашем проекте для команды разработки собирается на 2 довольно толстых сигарах и для их обработки мы используем гну utils clicker не поддается клитер хочет использовать исключительно греппа алексей как же так а вот пошли следующий наутилус но в общем кому это знакомо тот использует эти утилиты но все эти страшные слова варды заменить самым страшным словом самым нет самым страшным словом который было зеленым и все увидели да ну а теперь перейдем к первому кейсу итак нам обращается пользователь пользователь жалуется на то что его любимый файл который недавно редактировал прокатился в году ненужных байт к сожалению обращении в службу пользователей у нас зачастую эмоциональные да но и насколько же не информативны насколько эмоционально поэтому проблему приходится решать пологом богом мы видим три последних изменений пожалей пришедших в одну секунду и по моему все достаточно очевидно вот же испортим файл антонов селе достаточно очевидно давай попробуем добавить миллисекунды давай попробуем добавить миллисекунды до того в очень отлично сделали почти добавились миллисекунды но и видно что джорджу подставил мультяшек и самый спорту файл на самом деле учитывая по времени акции это было непреднамеренно и действие а скажем работа антивируса тем не менее наша задача выполнена найдена причина паучьи файла файл будет восстановлен мы придаем маленький но очень важный промежуточный итог да а итогом будет то что время нужно писать правильно если вы до сих пор не пишите миллисекунды вам стоит об этом позаботиться практически сразу же после конференции следующий кейс к нам обращается команда мобильной разработки которые жалуются на то что часть запросов от свежих пользователей завершается 5 соткой под запросами по думе это подразумевает создание пользователя в нашей базе данных и до 2 одинаковых запроса из которых 1 500 и другой нет что мы увидим водах игры но пока что видим два неудачных запроса давай еще по гриппу но грег долгий он выполняется выполняется отлично вот у нас нагрелось то что это банально повторное создание пользователь мы не можем вставить в уникальный индекс еще одну запись таким же ключом отдав что интересно мы сначала не смогли вставить а потом вставили если не ошибаюсь погибшим на quake addiction был добавлен версии тарантул которую мы еще не выскочили мне кажется она вообще еще в планах хорошо ну что же давай добавим тайминги выполнения запроса патч почти раскачал отлично вот мы теперь влогах видим время за которое эти запросы выполнялись ну и в принципе если представить их на таймлайне то видно что успешный запрос пришел сильно раньше выполнялся немного дольше и соответственно картина в принципе ясно да ну и гай у нас не бывает звук запросов в секунду на большом ps как ты будешь искать соответствующая вопрос запросы и с чем они конкурировали с бумажкой пожали деревья хорошо но тогда давай запишем отдельно срочку когда запрос пришел и когда запрос завершился опять-таки патч у нас команде обычно быстро и но не в этот раз собственно если мы это рассмотрим налогах то мы видим ситуацию гонки ну я бы не сказал что все так очевидно особенно с этим критикам ну да теперь мы новых видим ситуацию гонки ситуацию грунте я разговаривал с андреем он говорит что он 15 легкой воде и котировки писать имеет никакой грунте быть не может врачу такая же обратная да давай тогда попробуем более подробно залакировать ok и что из этого ясно до в общем и целом как то ничего ну да не понятно что к чему относится поэтому давай как-то попробуем разделить один запрос от другого да ну номинация будет не самой лучшей идеей потому что срывов у нас больше чем один и на нем накажем если вы его в по несколько болтиков и могут добавляться могут убираться из нагрузки сквозная нумерация это не та не тот вариант который будет легко реализовать что еще но может быть случайной величины да главное у гандам они нет критик сегодня просто замечателен и так добавив диффе катар запроса мы можем в достаточно объемных луках найти тот те самые сучки которые нас интересует относящуюся к определенному запросу от пользователя имея столь подобные лакирование мы легко можем позволить процесс на таймлайне но видно что запрос номер успешный запрос приходит пришел прошел аутентификацию дальше сходил выбрал что-то из каша по select all из базы теперь выполнять второй запрос и вот теперь мы видим в первом запросе блокировку вставку сущности и снятие блокировки после этого не успешный запрос выставляют блокировку и пытается повторно вставить тот же самый объём ну да блокировки в принципе работали над не очень как к сожалению про ту ну что же проблема в этом ясно мы дополним наши майдум тем что воде желательно писать более подробно с рейтингом и квеста от пользователя или другого события понятное дело не все события у нас происходит вот пользователь это могут быть очереди это могут быть нити регулярные работы и маленький следующий кейс да ну в холоде и своей теории относительности вот у нас представлен успешный запрос который отработал за 850 миллисекунд антон это много или мало ну всех тайниках я не помню поэтому обычно использую графит ну да из графика мы видим что наш запрос под а мега по средним таймингом сильно выбивается из общего фонда запрос в этого метода api да ну обычном пишу не только средняя и другие статистические показатели как-то минимум максимум и процентили и конечно же старательно добавляем это в графит чтобы понимать как то выполнение того или иного запроса соотносится с общей картиной до в нашем проекте мы часто сталкиваемся с задача передачи данных на примерах сербов и данный могут транслироваться как от нас к пользователю так и от пользователя к нам данном кейсе пользователь хотел забрать довольно увесистых в течение в течение нескольких миллисекунд было произведено в дефекации началась передача данных после чего мы видим огромную дугу фай в боках потом запас завершается успешно впрочем 200 статус ответа это не всегда успешный закон что но к тому же непонятно что вообще происходило с этим когда к нам чуть более часа давай добавим более виртуозные логе а именно каждый несколько секунд будем писать время относительно начала запроса статус отдачи контента заполненность буфера и скорость отдачи контента ну и дамы не зря увеличивая размер лугов осмотрим посыпками пользователь обращается службу поддержки жалобой на то что у него не скачивается файл по богом мы видим что данное передавались достаточно быстро в начале обработки запроса но потом скорость упала и в конце концов соединение было цели на по таймауту что же случилось в этом ответить нам поможет заполнены искать буфера когда данное передавались быстро пользовать пользуйтесь и клиент быстро вычитывал их и взять бушинги был заполнен при падении скорости во тьму фик был заполнен соответственно мы со своей стороны данные подготовили но они не были вычтены наиболее вероятно это проблема со стороны клиента ему посоветовал использовать либо другой клиент либо поверить его на другой операционной системе игры сбил следующий stels ну давай попробуем так на графике скорость отдачи контента мы видим сильно низкую скорость тому же из логов мы видим что врач мусора практически все время соединения был практически пустой . я стабильно вычитывал данные однако данные сохранились шли не так хорошо как мы это вы бы хотели скорее всего это проблема с хранилищем и мы отдадим эту проблему на растерзание нашей команде эксплуатации которая должна наладить нашу инфраструктуру следующем тесте скорость передачи сильно скакала все также по и высокая скорость стирает буфер фактически пуст по ее падение был заполнен а о чём это нам говорит нам это говорит о том что клиент в какой там они не мог вычислить данные судя по картине со скачками скорости передачи данных это скорее всего потери на канале которая приводит к падению размера типикой окна что свою очередь приводит падение скорости передачи данных мы можем порекомендовать клиенту попробовать воспользоваться сервисом другое время суток чтобы подтвердить теорию и возможность сменить провайдера ну что же подведем итоги этого инцидента для того чтобы статистику отображать ее нужно сначала собрать поэтому гарнируйте какие-то статистические важные данные до чтобы забрать несколько следующих кейсов нам придется писать примерную схему работы видео в облаке ну а схема работы примерно следующее пользователи отправляйся своего устройства запрос наши приложения приложения непосредственно взаимодействует с тарантулом который является не только базой данных но и очередью по постановке задач на конвертацию отдельных кусков видео эти задачи выполняет отдельный worker который также загружает сконвертированный части на соответствующие но до кыша по сути клиент всегда получает ответ и скажу но иногда он притворяется конвертация видео иногда просто идет из кэша и так в один не очень прекрасный день мы замечаем рост количества ошибок на отдачи видео хуже того они подтверждены соответствующими запасами от пользователей в службу поддержки ну что игры какие идеи вы можете извлечь из этого графика ну да есть вал ошибок давай посмотрим время конвертация ну скорее тайминги и так ну в момент пика мы очень быстро конвертировали видео до или не очень правильно писали о де давай разделим ответы получены прямо из кэша от ответов которые по 2 java конвертации и так ну теперь да теперь видно что примерно две трети запросов отдавались с каша да а вот файлы у нас только на запросов с канализацией и на фоне именно этих запросов файлы не выглядит файлов не выглядит столь уж незначительно посмотрим на тайминге ну а тайминги отдачи контента из кэша они ведут себя стабильно но при всем при этом возрастает тайминги на конвертацию видео да и так придем за священному слайду с версии того что же происходит у нас сервисом ну версия несколько мог деградировать сторож могут происходить проблемы с конвертация какого-то определенного но в то же время популярного видео могут наблюдаться проблемы сетью или банально отвалилась одна из надо кашей да и давай выкупаем один из проблемных запросов ну да тот какая-то статистика средняя собранная по больница да мы видим время консультации мы видим время загрузки и о чудо мы видим размер файла но на каждую bios нам понадобится маленький 1 срочник маленький 1 строчки маленький она сочник в 45 строк и достаточно много времени чтобы подтвердить или опровергнуть сетевое ну либо мы можем пойти другим путем да а давай залакируем какую-нибудь интересную для нас статистику например для процесса конвертации мы будем планировать следующий показатель время конвертации качество конвертации номер части видео которые вы конвертировали а для apple о да мы будем блокировать то же время размер файла и на самом деле одни немаловажные показатели это но до кыша инвариантная к нему время загрузки на этот кэш ну чтож как же так а дальше графит от лагал и мы теперь видим графики антон мне кажется даже твой сын сможет понять в чем проблема да очевидно но да ты и основной где ты их пошло что-то не так уточни пожалуйста у админов что там с ней после доклада и выводы да ну и собственно мало логировать какие-то характеристики важны и грамотно разделять чтобы по ним можно строить грамотные среза по статистике интересующий вас да тут не совсем подходит фазы разделяя вас и но тем не менее если ваша статистика собрана в одну кучу вы из нее не сможете знает ничего кроме красивого графика для маркетинга и снова видео до снова вернёмся к видео приходит очередная жалоба от пользователя что он не может посмотреть свои любимые видео с котиками дамы и к ней толерантны к видео с котиками но да ну как в этом случае не видимо лугах никаких различий запросы на это видео как успешные так и не успешно и не отличается ничем к нашему стыду мы вынуждены спрашивать у пользователя скриншот браузера с открытой консолью ну да на котором мы собственно видим причину того что у него не играется видео банальная сервер не отдал соответствующий заголовок ну да а почему он мог не отдать решение об отдаче заголовка отсосала у control engine или как то так принимается на основании запроса от клиента именно на основании преданного заголовка и джен ну так давай залакируем этого логов да теперь проблема кажется более очевидной до клиент банально сам сам не отдал нам этот заголовок соответственно сам же не смог проиграть это видео ну надо сказать что клиент это наш уже в приложении поэтому запрос будет отдано более компетентным ребятам а именно frontend они либо найдут в аккаунт либо попустит нас за чините состояние сервера от он ну исходя из этого случая может быть звони ruim вообще все заголовки которые нам отсылают хост реферер экстрималы api контент лэнс cookies коллег за доводку ти это замечательная идея премия безопасникам гарантированно извини но с этой информации можно компенсировать пользователя если мы надеваем пути то мы их либо каширу им фишеру им дабы по найденным по найденному woah значения нельзя было определить что там было либо него одеваем вообще и в принципе мы руководствуемся связывающим следующим принципам опять же есть интересующие нас данные которые могут быть полезно при расследовании есть данные которые не компроментирует пользователя и есть данная которая достаточно мало чтобы быть помещены wog они достаточно малы сейчас пойдет достаточно маленький пакет который такие долетит до приемника да и лишь удовлетворяющие этим требованиям данное должно быть заводи гаванная ну что ж если вы захотите разблокировать что-то важное для вас вы должны во первых проверить его размер а во-вторых всячески сохранить приватность пользователя что что мы движемся дальше у а это моя любимая да и на самом деле наверно любимая ошибка всех программистов а именно запрос смерти по времени легко заметить что было это субботним вечером я сидел ужином как тут на телефон приходит великолепные с на котором написано что worker нашего приложения закончил работу по сигналу сига word и вслед за этим прилетает любезное письмо в котором содержится исключительно ссылку по которой я могу забрать картам с которым процесс завершил свою работу но что же происходило на самом деле у нас на минуточку 12 машин под это под этого демона каждый демон представлены 10 маркерами и каждый из них в данную секунду обрабатывал порядка 10 запросов и тоже 1200 подозреваемых запросов антон ну и что ну давай попробуем как-то сократить их они смогли вечер так clicker да ну сократить это можно следующим способом например если вы заблокируете имя хоста на которого у вас крутятся это демон вы сократить радиус воинскую примерно в 12 раз в нашем случае точно 12 раз а если еще постарайтесь заблокировать номер маркера и его процесса де то вы вообще сократите количество подозреваемых запросов до 10 я это можно посмотреть глазами примерно за 20 минут до и я тоже полезную информацию можно отправить в том самом любезном сообщение ссылки ского скорой to do собственно предлагаю также логировать всякую системную информацию которая может характеризовать работу вашего сервиса а также работу клиентов и следующий кейс ну пожалуйста ну вот мара сейчас с итак мы разобрали небольшую проблему с видео массового характера теперь представьте обращается конкретно пользователь жалуются на конкретное видео и вам нужно понять что же происходило именно с этими с этим запросам именно от этого пользователя на всех каскадах обработки но да у нас есть эквестрии на каждом сервисе но к сожалению но к сожалению он у нас на каждом сервисе свой и мы и на будет очень сложно от трекать запрос внутри всего нашего сервиса да это либо опять магия для связки либо можем передавать и квест один от одного сервиса к другому ну на самом деле внимательный слушатель может спросить парня че вы не используете первый квест во всех компонентах данной схеме это можно было бы сделать хотя в общем случае в рамках одного запроса можем сходить в одну и ту же api 2 ты более газ и отличать запросы внутри того самого api куда мы ходили нам тоже нужно поэтому икс икос 1 генерируется накажем каскаде свой и наследуется но есть ещё один интересный момент да мы рассматриваем с вами не сферический запрос в вакууме а рассмотрим реальный запрос где нейронный пользователь а запросы от пользователя они могут подразумевать под собой несколько отдельных обращений к нашему api соответственно такую существа клиента и тоже неплохо бы залакировать ведь приложение начинается не с нашего engine.exe ольга с станица запущенной у пользователя ну что же подведем итоги нашего доклада если вкратце то вашего логе должны быть настолько подробно насколько вы можете себе это позволить но в тоже время и всей этой груды текста вы должны уметь вычленять только то что вам необходимо в данный момент пишите время правильно также учитывайте особенности системной особенности работать демонов и системной особенность работы клиентов всю необходимую для вас информацию нужно для начала проверять достаточный размер а также пытаться как-то зафиксировать чтобы не скомпрометировать пользователя ну и логе это конечно здорово но построены на основе их статистика еще лучше ну или если подвести дик доклада в двух словах мы пишем воде для себя но пишем их так чтобы любую проблему выходные или ночью можно было решить без нас ну пожалуйста да как часто вы говорите своему проекты вы пожалуйста да пишите воде так чтобы иметь возможность проводить время с семьей и спать по ночам засим спасибо и мы можем перейти к вопросам и на вопросы у нас с вами 25 минут и друзья не стеснять кто выходит выходит выходить и аккуратненько и тихонечко вот смотрите прям здравствуйте спасибо большое за доклад скажете откуда вы все это делала герои просто файлы или какие-то специализированные решение использовать данный момент мы еще не внедрили никакого специализированное решение х ним файлах целом возможно это кажется как вау ну как же так ну надо же использовать wax тыж но на наших объемах не так просто ввести любое решение чтобы она вдруг начала работать это тюнинг и доводка пока файл они достаточно надежны спасибо пожалуйста спасибо за доклад такой защищающий вопрос продолжение 1 а на какое решение вы переходите если не секрет и вам лично я медаль за то что вы можете с помощью крепа все это понять и найти ну кроме гриппа у нас есть еще утилита который умеет быстро искать у порядочных полов по времени вогом это позволяет значительно сократить область поиска плюс файлу своего именно вы отираются чтобы не прерывать 10 гигабайт логов прихожан гриппе совершением и на данный момент не определились чтобы назвать его потом сверху пожалуйста спасибо за доклад продолжая тему курсов и ошибок pronto вы не думали или может быть уже блокируйте ошибки фронта если да то как вы это делаете соответствующим запросом на наш backend есть до определенного диване и ошибок фан то есть я думаю идеальным решением для этого был бы были бы websocket и но к сожалению на них агриться много быть огурчиков реклама поэтому да мы ладим им дам владимиром отдельными хотят вы запросами спасибо добрый вечер спасибо за доклад ребят я не совсем не до конца понял по поводу request a lady in a каждом шаге нельзя ли было просто самого начала получить request айди а влоги добавлять сервис которого мы сейчас работаете смотрите да в дан на представленной схеме так можно было сделать потому что у нас всего три каскада и в каждый каскад запрос попадает один раз но например с api работы во первых работ из деревни можем сходить несколько раз за один запрос поэтому до 2 запроса у нас отрабатывают корректно 3 лица если мы не дефицит им конкретный свалившейся запрос мы можем его пути перемешать его с остальными и же время такой время честь ну у нас сервис асинхронный простите на всю голову поэтому без проблем 34 запаса параллельно хороши по ним пасибо здравствуйте вы сказали о том что никакого специального решения для лакирования времени применяйте лагер уйти файл и соответственно еще раз вы говорили о том что у вас допустим 12 машин то есть вы по всем двенадцати машину курите игре бугре пойти в каждой из них или каким образом вы придете куда пошел запрос это первый вопрос а второй вопрос о том насколько детально вы пишете логе кто вообще определяет что должно попасть в лоб для того чтобы вы смогли исследовать какую-то проблему то есть если это делать разработчик то откуда ему знать что нужно вам а если он делает это не советуясь с вами то как вы понимаете все что он туда пишет и что это все значит да воде для команды разработки сводятся на парочку довольно жирных сервисов и хранятся там серверов простите хранятся в виде файлов для команды эксплуатации есть другие сервера где они могут работать с лагами и до алексей вел небольшую путаницу я являюсь разработчиком они сотрудникам службы поддержки хоть и довольно часто со службы поддержки работают потому что есть стандартные кейсы которые службу поддержки может решить в любом нестандартном кейси проблема пропитывается дальше чтобы ее мог решить компетентный человек ну и от тебя тоже дополнен что на основе вообще всей истории в докладе легко заметить что многие фичи водятся после каких-то проблем особенно после каких-то мучительно решаемых проблем поэтому возможно это не приходит голову сразу что что-то нужно залакировать но после таких инцидентов это становится уже очевидно до разбор их проблему он очень хорошо прочищает мозг и повышает желание писать качественные ludi добрый день вы сказали что вот такую фразу блокируйте все что вы можете себе позволить а как вы определяете что вы можете позволить то есть вот инфраструктуру вам не скажут что а здесь у вас слишком много логов либо здесь у вас деградации производительности либо вы заняли мощностей в 10 раз больше чем планировали то есть вот где та грань что можно лакировать а что нет и как вы это для себя определяете ну вообще пустоту иногда говорит что мы слишком много ладим и мы сокращаем объемы то есть да это такой процесс взаимных уступок парни нам нужно больше писать чтобы было подробнее нет парня вот у нас есть там скажем 10 дисков и если вы их своими ногами забьете то больше нам вашего не писать никуда а если касательно производительность то есть если итог произведенных повлияет то есть многих странах а типа синхронно все равно вас будет занимать к это время ну пока если честно не замечал особых проблем с производительности на записи логов наверное мы пишемся уже не настолько много либо производительности смог кончается раньше кстати но к такой методике не разрабатываем для себя да то есть что вот это можно это нельзя все экспериментально но вначале доклады мы осветили что на самом деле никакой теории бы под это не подкладываем только наш личный опыт спасибо спасибо за доклад как то ты начинаешь писать чуть больше логов а уж тем более все что себе можешь позволить быстро заканчиваются места соответственно как вы бронируете логе это первый вопрос и второй вопрос не вы не всегда можете на уровне приложения узнать сенситив данные вы пишете или нет как вы с этим боретесь ну место у нас пока об счастье не заканчивается пишем ага тигры мы примерно 1 сутки соответственно у нас есть утилита для репа с учетом времени которое позволяет вычленить кусок по за нужный промежуток это сильно увеличивает скорость разбор инцидентов что касается сенситив данных ну на самом деле мы не столь versace значительнее как сказал игры и не не пишем прямо все подряд например заголовки мы знаем те данные на основе которых у нас идет ветвление на основе которых мы понимаем те или иные решения в коде и их стараемся владимира либо сразу либо через гуте опыт одра стены спасибо часть доклад а вот хочется узнать примерно сколько у вас объем файлов в тот день хранится ну-ка какой примерно результат объем файлов в игре пойти при необходимости гигабайт 100 гигабайт в день вот сейчас проблема нука сейчас сегодня достаточно хорошо разбиты по различным компонентам сервиса поэтому в целом в случае какой-то массовые проблемы едва ли речь пойдет более чем оба нескольких дико байтах логов именно тех которые имеют значение не тех которых мы записали пишем мы довольно много у нас на хранилище более терабайта суммарного место и то второй вопрос у вас есть два сервер логов дано которые перевариваются логия из продакшена на сервера логов а как часто они перевариваются с каким датой мам loc dog не повышает ну по-моему 5 секунд до езда логов мы используем по такому skype и соответствующее решение несмотря на определенные недостатки в целом мы довольны то есть у вас не хватает вас сетями все хорошо у вас то что у вас гигабайт логов а летит как бы постоянно гигабайтами не идут на два сервера у вас проблем не возникает производительности ну нет спасибо еще вопрос такой вы только скалишься используйте cледует для грэба с в рамках конкретного промежутка времени это open source решения посетите да еще раз еще раз вопросы вы только что говорит летом с используйте специальную утилиту которой глеб аид в рамках определенного дам жидко вы можете назвать это ваша личная разработка или был сразу же это внутренняя разработка я надеюсь мои как-нибудь вложим предварительно правда переписав с плюсов на первом как или искать в интернете как она будет называться я не помню она называлась его гриб возможно за бочек он сейчас работает другом проекте и и выкладывал спасибо большое спасибо за доклад для ивентов на аналитике через пользуйте тоже файла пишите ливанская другая система для аналитики на за большой придут времени ну за всякий ну аналитикой занимается у нас отдельная команда когда мы передаем данные обычно это skype протокол они их соответственно разбирают и на достаточно большом количестве машин обсчитывают вы исключаю доставай определенные связи между данными например мы в приложении не можем связать несколько объектов какой-то файл который пользователь давно загрузил и скажем изменение его бог а но аналитики mia данная за большой период времени могут различное положение различные события связать и сделать из них вывод а также мы еще пишем некоторые технические данные непосредственно графит то есть я вот не понял аналитики они логе парсов или вы просто want его внешние стенки пошлете свои ну скорее the event его внешнюю систему спасибо спасибо тут у стажеры вашего вот вопрос собственно дополнить хотел ответ про объема логов совокупный объем лагов по всему облака в сутки составляет 6 терабайт храним мы их на записи с компрессией то есть нам на одной машине получается вместить за счет компрессии логов приблизительно в шесть раз больше то есть можно считать что в сутки пишется терабайт суровы сырых данных и про аналитику там используется hadoop ну это не нашу команду я имею дух аду поди тебя еще вопросы друзья принципе можно стажеров дальше вопросы задавай здравствуйте спасибо за доклад от собственного вопрос следующие какое у вас отношение как бы вот это вот полезных хранимых данных к тем объемом логов есть получается что у вас допустим там шесть терабайт логов за день работы при общем объеме база там до суда достаточно небольшое получается правильно ну предположим то есть получается что суммарно и хранение вот этой информации лаггеру ющий она становится достаточно дорогим и соответственно опять же мы упираемся вот вопрос с инфраструктурой стоит ли это хранить как это делала обрабатывать до это сжимается еще там еще в 60 раз но при этом это дело саппорт опять же залазит запакованные логе по нему ищет то есть вот это вот время вы знаете подходить к этому вопросу можно по-разному можно сказать но проблема случилась мы там через недельку вас катим приложение версия положения с 1-ого не именно под эту проблему a8 шум спела газа если не решим сказала добавим в одевании числе ли еще с искать им мы предпочитаем иметь воде под руку из чтобы решать реальные проблема пользователи более оперативно и любой разработчик принципе может взять решение работы решение проблемы на себя и пологом иногда сожалению с привлечением кода понять что происходило возможно смоделировать проблему и пофиксите и судя по выражению лица это немного не тот ответ которую вы ждали можете уточнить вопрос папа перед формулируйте у вас 10 секунд люк просто подойдите потом как бы на попозже волком друзья надо чтобы татьна бросил нас есть 5 минут до если не знаете куда подходить у нас вот есть там стендик mail.ru на него на нем можно найти нас до мужчины спасибо большое мы достаточно вас помучали уже друзья помните о том что кулуарно всегда можно задать вообще любой вопрос"
}