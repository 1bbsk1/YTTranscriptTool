{
  "video_id": "P__hN6u9yCw",
  "channel": "HighLoadChannel",
  "title": "10 способов достижения HighLoad'а и BigData на ровном месте/Илья Космодемьянский",
  "views": 11023,
  "duration": 2943,
  "published": "2017-04-22T14:47:53-07:00",
  "text": "коллеги в нашем следующем докладе Илья космодемьянский расскажет про 10 таких типичных грабель на которые наступают обычные разработчики когда пытаются вот свой проект из такого низко нагруженного переделать под поприветствуем Спасибо собственно говоря да ровно об этом доклад и будет я бы не сказал честно говоря что прямо низко нагруженный переделать на высоко нагруженный скажем так иногда получается из низко нагруженного внезапно сделать высоко нагруженный и далеко не всегда в том виде в котором как бы хочется а есть типичные ошибки работы с хранилищем и эти ошибки они как бы вот не то чтобы я их там выдумываю специально да поскольку мы много работаем с удалённой поддержкой баз данных мы их просто коллекционирую зачастую одни теже от клиентов и Составляем некий своеобразный рейтинг того что на коллекционировать вещах я и буду сегодня рассказывать какие-то вещи будут абсолютно общие для всех хранилищ ну пару специфических вещей для постгрес я естественно упомяну поскольку как бы работаем осном с постгрес Ну и постгрес много применяется в радин традиционно в качестве такого бы даже с эпиграфа можно привести следующую вещь то есть подобно как в электронике бывает проблемы двух типов либо где-то Есть ли есть контакт который лишний либо соответственно нет контакта там где нужно с базой данных та же самая история то есть какого тока люди не хранят в базе Да там от картинок до каких-то там совершенно удивительных вещей которые Может быть там бы хранить и не стоило вот а может быть наоборот не хранят в базе те вещи которые стоило бы хранить потому что не знаю для каких-то вещей применяется один для других вещей применяется другой кэш для третьего какой-то Там новое Сколь хранилище и так далее А может быть оно лучше чтобы было бы где-нибудь в базе и ценнее Ну давайте собственно говоря по этим вещам кратенько проедем они не то чтобы как-то упорядочены в порядке каких-то либо жёсткости этих проблем но Сейчас разберёмся А как бы в качестве дисклеймера будет некоторый троллинг возможно возможно я где-то не удержусь Да потому что ну как бы когда рассказываешь скучно о том что Вот ребята не делайте вот так вот естественно все говорят Угу и делают Да а как бы Когда появляются какие-то эмоции Но человек смотрит думает Блин какие дураки так пишут открывает гид Да там кто же это написал вчера на тогда запоминается лучше значит смотрите во-первых одна из первейший проблем и первей она в том числе потому что я её не наблюдаю только она очень редких случаях Да вот наверное 40м из db2 вот э проблема редко случается потому что там каждая от масштабированных денег да это всё-таки ограничивает полёт фантазии но как бы и в вебе особо не применяется А с Open Source нами с бесплатными вещами только в путь и притом совершенно необязательно там с прогрессом с ма сэлем это ещё больше характерно и с новы сэлем тем более люди любят масштабироваться потому что масштабирование - это хорошо об этом писали в книжках просто потому что хорошо почему хорошо мало кто может объяснить да И тут возникает много довольно разных проблем особо характерно что вот на протяжении там не знаю последних 10 лет я постоянно слышу что всё должно быть с и ни в коем случае не должно быть SK Да потому что SK - это очень плохо за прошедшее время с тех пор как это было вообще Придумано компьютеры стали несколько мощнее задачи тоже выросли Да но задачи выросли всё-таки не до такой степени насколько мощные компьютеры да То есть в принципе есть люди которые по объективным причинам имеют дело с Биг датой это физики Да которые там из Андронова коллайдера что-то достают это физики которые там звёзды изучают это там биологи которые Гены исследуют это люди которые пишут компьютерные игры и плохо разрабатывают игровые сценарии у них там зачастую может быть элементов больше чем атомов во вселенной и они считают что это должно работать да но вот объективных задач где действительно нужно много данных и в одну машину никогда они не вмест их довольно мало да может быть там какой-то Сток Exchange и тому подобные вещи а поэтому Возможно что в принципе масштабироваться с самого начала особенно не так уж и хорошо собственно говоря типичный случай чтобы как бы стало ближе и понятнее о том как бывает а Мы решили что у нас нашим веб-сайтом будет пользоваться очень много народу там не знаю обычно когда маркетинг с кем-нибудь из учредителей строит планы на то сколько у нас будет нагрузка нормальный программист Может это делить на 100 сразу Да потому что вряд ли оно так будет но если оно будет то вы должны быть готовы что-то с этим сделать и естественно Люди задумываются сразу же о масштабировании и Я бы даже сказал О так называемом преждевременном масштабировании ну типичная история Давайте раз у нас будет миллион активных пользователей на сайте Мы по дате создания этого пользователя их расшарить А почему по дате создания пользователя Ну вот потому что вот нам так показалось нужным на самом деле там таких случаев может быть много разных но это вот один из них в результате чего Через некоторое время А мы получаем кучу проблем потому что пользователи у нас не вполне независимые Да и например чтобы собрать какую-то такую банальную задачу для реляционной базы если она на одной машине Как флен нам нужны какие-то Като специальные сервисы и так далее и фактически на любое между Узер взаимодействие будь то чат или что-то ещё у нас получается так что неизбежно юзеры живут на разных машинах и мы приехали да у нам сразу резко усложняется вся логика сразу резко усложняется поддержка и так далее ещё в довольно давние времена мне доводилось в одном проекте считать что вот если мы поставим 10 машин с пасом тогда ещё как бы не очень быстрым поря вещей то э машины должны быть такой мощности чтобы выдержать там нагрузку запланированную такой стоимости сравнили посмотрели Ну купить Oracle энтерпрайз най лицензии поставить его на дисковый массив со шкафом большим просто получилось тупо дешевле по деньгам да такой случай в принципе он как бы Вполне может быть а сейчас как бы ещё на эту тему на самом деле проще потому что база данных стали работать лучше все притом и Oracle и mysql и pog за последние там 10 лет сделали очень большой Прогресс Но дальше возникает ещё большая проблема внезапно выясняется что у нас из этих 100 машин на которым мы это всё дело распилили активны только несколько потому что пользователи там свеже зарегистрированные в силу того паттерна как они у нас живут на сайте они активны неравномерно да То есть те пользователи которые зарегистрировались давно и на каких-то там машинах осели они соответственно ничего не делают и машина стоит наут ещ одна проблема если машина стоит у неё не не прогрет кэш база данных быстрее работает когда она отдаёт данные с кэша а не с диска и соответственно если туда Раз в час приходит запрос достать данные о каком-то пользователе то в какой-то далеко не прекрасный момент выясняется что для того чтобы это сделать запрос работает в несколько раз медленнее потому что не прогретый кэш и всё плохо работает на лицо проблема что мы поставили 100 машин сделали соответствующие изменения в инфраструктуре и получили не работоспособное которую нам немедленно надо переделать И вообще этот случай как бы гораздо шире сначала распилили по одному ключу на шарды потом поняли что на самом деле нужно было сделать совсем по-другому стали соответственно переделывать переделали выяснили что надо ещё раз по-другому потому что web - это Moving tget и собственно говоря условия меняются быстрее чем мы на проектировали поэтому мой здесь такой типичный совет - Это сначала вырасти до ресур одно Маши на нормальной реляционной базе посмотреть просто докуда мы взаем такими темпами потом посчитать сколько стоит проайти эту машину и сколько мы ещё можем соответственно на модном более железе более хорошем более быстром жить и после того как мы это посчитаем только после этого принимать решение о масштабировании и вот этот подход он на самом деле спас не один проект потому что преждевременно оно отнимает кучу ресурсов команды кучу денег и в конечном итоге получается только дороже и хуже второй момент который тоже у меня в рейтинге достаточно высоко Это всё-таки кейз Биг даты на пустом месте я бы сказал бизнес хочет иметь данные за всё время Ну типичная история мы считаем какую-то статистику собираем там не знаю активность пользователей какой-то В общем И на самом деле нам нужны от не в основном только агрегаты потому что свежих данных Ну последний день последняя неделя последний час всё остальное - Это предрассветный пример плохой Биг даты и объяснять бизнесу задачу эту это как бы задача программиста потому что боязнь бизнеса потерять какие-то данные не посчитать аналитику она совершенно очевидна да то есть как бы данные - это деньги Да всё как бы просто но при этом вместо того чтобы держать там 4 ТБ Вы можете сделать много разных интересных вещей Вы можете данные правильно архивировать А даже даже данные сырые хранить где-то на архивной машине чтобы если понадобится пересчитать по ним агрегаты которые вы используете для какой-то там статистики или для чего-то ещё если вам вдруг понадобится новый агрегат но в результате те горячие данные которые к вам только что приехали они будут вместо 4 ГБ 4 ТБ они у вас будут занимать там не знаю 100 Гб И с этим работать будет на порядке проще более того в многих базах данных например там опять же в том же постгрес есть много автоматических средств которые позволяют это делать например PL Proxy позволяет на удалённую машину унести архивированные данные и при необходимости подтянуть данные оттуда и оттуда чтобы как бы какую-то выборку там выдать методик как это сделать весьма много и э то или иное партиционирование на архив и горячие данные оно сильно помогает в такой ситуации потому что эксплуатировать базу данных отличающиеся там по размерам в 1.000 раз в большую сторону когда реально большая часть этих данных там 90% вам не нужна это всегда боль и делать так не надо а очень любят использовать универсальные подходы да то есть entity attribute value - это вобще как бы такой бич для дба потому что программисту так проектировать интересно да Потому что вот у нас же всё универсально нам не нужно менять структуру таблиц Когда у нас что-то новое надо добавить А мы можем просто там Добавить новый тип соответственно атрибута прописать новый атрибут и ему новый UE туда засунуть хорошо удобно прекрасно но у вас в результате это всё разрастается до ТХ или четырёх Если у вас есть тип таблиц огромного размера и все ваши данные живут в них и вы их всегда Джой то есть при этом как-то Со оптимизировать эти джоны на самом деле очень сложно потому что данные у вас скорее всего будут лежать там в каком-нибудь типе текст в такой ситуации потому что вам сложно будет положить их в другой Тип и например эффективность индексирования Таких данных будет на порядке меньше чем если вы будете их держать в отдельных таблицах реляционных ну и плюс опять же представляете какого объёма документацию нужно держать чтобы разобраться какой атрибут Что значит и так далее всё-таки реляционная схема Она до некоторой степени сама себя документи ет особенно если к ней есть какое-то Разумное описание в яве вы не разберётесь просто так без хорошей документации вообще ни при каких условиях в результате Обычно вот то что представляет собой яа ВОМ обычно называется ядром да то есть как бы а когда оно достигает такого состояния Когда становится полностью не работоспособное оно переименовывается в гордое наименование ядро и это всё начинает обвешивают где по сути хранятся денормализация не достигаем той цели которая у нас там была заявлена тоже самое с умом Да я вот как бы тут не хочу вдаваться в дол в долгий лир хорошо или плохо иметь урм да но как дба я в общем всё-таки Ур Категорически не люблю вот и в принципе я понимаю как бы стремление что-то быстро за прототипирование на рме но по факту дальше начинается какое-то странное явление да то есть мы понимаем чтом существенно тормозит базу данных мы начинаем некоторые запросы переделывать на PL SQL ещё лучше на самом деле пытаться переписать их пытаться выдре сирова РМ писать хорошие запросы Вот это вообще страшное дело я как-то наблюдал человека который мужественно боролся с запросом генен им ремом Зная как его написать правильно у него был уже Запрос который он написал правильно И он пытался выдре сирова урм чтобы тот сгенерировал запрос такого же чтобы он нормально заработал Ну как бы бессмысленность этого становится совершенно да очевидной более того в принципе можно прочитать например отдельный доклад на тему того А давайте мы угадаем по логам SQ запросов каким из какого Урма к ним ходили Да ну вот вот это вот из какого Ну вообще как бы многие этим грешат но добавлю что вот этот вот и он может быть там какого-нибудь огромного размера Я думаю что скорее всего всё-таки Джан будет это они будут покороче вот ну в общем как бы факт тот что по многим признакам можно м угадать А вот эта вот вещь Она вообще как бы очень плохая Да почему потому что этот список может быть каким угодно оптимизатор вообще не знает что с ним сделать если это заменить на какой-то это будет работать ещ куда не шло скорее всего это можно как-то оптимизировать с этим ином не сделаешь ничего Без очень грязных хаков и вот в реме так всё То есть все запросы до такой-то степени делаются именно такими то есть да пожалуйста прототипи ите на любимом рме но надо понимать Да что в каком в каком-то в какой-то момент это рано или позно станет всё равно неудобно и плохо и с точки зрения производительности главное плохо А вот такая чисто постгрес сова вещь на тему Биг даты в постгрес есть такая штука автовакуум да постгрес когда он делает он делает и А когда делает он делает п Del при этом Del Это тоже не Del просто убирание из области видимости тала и получается что у нас получается очень фрагментированные значений 100.000 а она может весить какие-то Адские там гигабайты просто потому что в ней там ещё несколько мил неактуальны ездят и превращают нашу базу данных в типичный пример bata естественно как бы если там ничего не настроено если работает всё плохо первый же первая же реакция у людей кто это эксплуатирует А давайте выключим автовакуум потому что он что как бы самый долгой работающий процесс всему мешает соответственно мы не можем там индекс добавить вообще выполнить если автовакуум по таблице идт и так далее Давайте его выключим это очень плохо ну и соответственно тут можно много об этом рассказывать вот здесь ссылочка если что с рекомендациями Как бороться с автовакуум и что делать главное что Никаким образом не надо отключать потому что результаты получаются совершенно чудовищным у вас Big Data получается ещё более на ровном месте чем с Time Series данными которые вам на самом деле не нужны и просто занимают место в базе Jo - это зло вот эта вещь как бы у меня даже есть такие наблюдения Откуда это у людей в голове получается Например люди которые давно работают ССМ где-нибудь какой-нибудь третье версии вот у них часто бывает идея что дй - это зло А ну что я тут могу сказать А джойн - это добро потому что реляционная модель Она почему настолько успешна Ну как бы кто из вас хоть раз слышал что Революционная модель - это такая отсталая вещь которая вот как не зна что вот не знаю Я думаю все слышали Да тако такое мнение что вот сейчас вот придёт схема лесного SQL и всех победит не происходит Почему Потому что у нас данные удобно хранить одним способом в виде блоков на диске а доставать их удобно другим способом каким-нибудь желательно более высокоуровневым и соответственно если у нас данные достаются высокоуровневым способом из раз табли и так далее реляционная модель очень удобна для того чтобы делать оптимизацию если у нас мы используем революционную модель то надо использовать её на всю мощь потому что Что является альтернативой тому что мы сделаем Join очень всё просто мы берём вытягиваем в наш любимый язык программирования на наш там сервер приложений end куда угодно данные из двух-трёх табличек То есть фактически они у нас как бы живут уже в приложении занимают место и так далее и тому подобное при этом эти таблички могут быть большие запросто то есть нам надо на самом деле получить в итоге 10 строчек а так мы вытягиваем огромные простынью А и дальше мы занимаемся Джой нам вручную таким закатом солнца вручную Вот то есть мы там не знаю сначала начинаем ходить циклом потом понимаем что это медленно начинаем какой-нибудь там алгоритм хеширования туда придумать по факту мы начинаем изобретать базу данных такую как модель паровоза действующая в натуральную величину да и всё равно она как бы будет несколько плоха Да потому что оптимизатор собирает информацию о куче всяких параметров для того чтобы выбрать алгоритм дна Да там N ш Или там merge или ещё какой-нибудь где они есть в нашем языке программирования мы это всё будем писать заново сами Ну и зачем как бы это делать тем не менее опять же вот кто ни разу не видел чтобы кто-то делал вот так вот прям чтоб ни разу То есть все остальные хотя бы раз такое где-то встречают то есть Это говорит о том что на самом деле вот в народе Эта мысль популярна почему-то поэтому Используйте ту мощь реляционной алгебры которая вам Дана SQL - Это высокоуровневый хороший язык если вам нужно достать 10 строчек для предварительно пройдя по очень большим таблицам Jo вам серьёзно хорошо поможет в отличии от делания этого вручную и не предназначенными для этого средствами А ещё одна больная совершенно тема - Это изобретение многочисленных вариантов репликации Ну почему слони Потому что в постгрес есть такая А как бы не очень любимая многими и я бы сказал заслуженно не очень любимая многими система репликации слони которая очень старая ещё до того как появилась встроенная репликация Но это такая тгр bas репликация которая как бы хлопотно в обслуживании весьма тем не менее Несмотря на то что она есть Она есть много лет она не очень плохо работает Если её выдре сирова Ну просто потому что очень старый продукт да то есть как бы у него кучу багов всяких вытащили Люди регулярно пытаются изобрести что-нибудь своё то есть там в постгрес Есть как минимум три широко распространённых метода репликации это Ship ПГ которые там имеют свои плюсы свои минусы Я бы честно говоря вообще в 99% случаев не советовал использовать ничего кроме встроенного шинго логов но тем не менее народ пытается изобрести что-то своё с какими-то своими целями всегда когда я видел такие изобретённые штуки они всегда работали как-то не так потому что вы не учтём которые у вас возникнут репликация - это обработка распределённых транзакций обработка определённых транзакций это всегда тяжело там никакого волшебства нету и соответственно если по каким-то причинам встроенная репликация не предоставляет вам такого-то функционала например там мультимастер да это означает что-то почему-то это так не работает и если вы будете пытаться это изобрести самостоятельно с большой вероятностью будете ходить по граблям и многие так в общем-то делают Поэтому в первую очередь я бы всё-таки советовал если есть какая-то технология в базе данных то подумать почему она как бы так используется и использовать её что касается репликации так тут ещё один момент немаловажный заключается в том что встроенная репликация она не работает на высоком уровне на уровне SQ да То есть вы Когда пишете какую-то свою репликацию наверное всё-таки обычно общаетесь с уровнем таблиц там триггеров хранимых процедур и медленно как правило чревато конфликтами залезть куда-то глубже это уже гораздо сложнее то есть перепилить там базу данных чтобы у неё была там другая репликация Это задача уже очень серьёзная Скорее всего вы должны понимать что делаете Если вы можете залезть так глубоко вот а а встроенная репликация - это репликация трансакционным логом да то есть пишутся пишется информация об изменениях но не в виде там SQL стейта А в виде того что Какая информация нам нужна чтобы вернуть страничку килобайт предыдущее состояние или наоборот сделать ряду до нового состояния и вот этот Лок едет соответственно на с и там применяется и вот это будет на порядке эффективнее и на порядке надёжнее чем любой другой метод репликации и он уже сделан да то есть он как бы встроен и можно брать и пользоваться программиста админу который говорит о том что процессы взаимодействия эксплуатации и разработки в конторе фундаментально поломаны все знают что нужно использовать далеко не все используют но все знают что надо использовать то есть надо посмотреть оптимально ли работает запрос не забыли ли мы там у себя в разработкой среде и Выяснилось что ну самый простой вариант что на продакшене будет просто в 100.000 раз больше данных и будет выбран другой план и соответствующим образом будет происходить работа и уже будет соответственно медленно там не знаю понадобится индекс понадобится другой индекс понадобится что-то ещё и так далее То есть тут могут возникнуть куча проблем более того база данных - это очень сложная система есть там зависит ку разных странных параметров Да например у вас проект шарит базу с другим проектом да то есть они работают там вместе А у вас на девелоперской среде есть только ваш проект Да от того проекта порождается какая-то нагрузка потому что не знаю там все сотрудники всех офисов России утром за чашечки кофе заходят на ваш сайт например да с которым работает тот проект А у вас проект который с этим никак совершенно не связан но вы испытываете какието удивительные тормоза потому что вот база резко более сильно тормозит Вот в эти утренние часы то есть здесь очень важно на самом деле разработчикам иметь какой-то доступ на продакшн либо соответственно отлаженные процедуры работы с дба да то есть один из самых худших моментов - это когда админы просто стараются не пускать бестолковых программистов никуда Там закрыли Ну как знаете Советская уборщица которая там как бы тся что тут ходят топчут вообще всякие вот школу бы закрыли только чтобы они туда-сюда не ходили Вот это неправильно да то есть разработчики должны Ну возможно там какой-то более привилегированный доступ в базу должны иметь у сильно проверенные там ведущие разработчики которые там знают проект и точно не навредят Да но либо доступ на чтение либо какую-то информацию из мониторинга должны иметь все То есть если у вас стоит мониторинг который показывает Там вст по й Какие запросы занимают сколько ресурсов вот эту картинку должен иметь каждый программист и после каждой выгод посмотреть на свой запрос Как он себя ведёт что там происходит и должен уметь это дело интерпретировать Если админ туда не пускает разработчиков Никаким образом рано или поздно закончится Вот такими вот вещами что у меня всё в тесте работает потому что как бы ответственность за свой код за свой проект как бы в такой ситуации разработчик не несёт а он должен уметь посмотре это ВС происходит потому что разница может быть там весьма и весьма существенной такая ну ни в коем случае не хочу обидеть Ja программистов самые разные программисты это такая уж роль потому что как бы программисты люди любознательные и как бы им интересно попробовать чтобу новое что-нибудь интересное исполь подходами вот есть у нас JAVA да в Джаве есть потоки А и известно что вот эти jav ские нити с ними можно сделать так чтобы всё работало быстрее чем без них но у нас есть дальше база данных Мы в базу данных хотим загрузить много данных кладём их туда в несколько там соответственно потоков нам кажется что медленно Мы распараллеливание всё побольше Ну и при этом как бы разработчиков в данной ситуации не волнует что на самом деле происходит а происходит следующее что в базе данных у нас там 10 воркеров Потому что у нас такое количество ядер там на машине что с учётом служебных воркеров нам только на 10 их остаётся Вот и в эти 10 воркеров приходят вот эти вот все потоки что дальше происходит ено эти потоки начинают просто тупо драться между собой и в данной ситуации как бы это не самая хорошая идея поэтому программисту нужно став весь стек в больших и лучших деталях да Потому что если такие вещи делать получается очень странно вот второй пункт - это как бы случай Вполне себе из жизни Да мы обычно делаем следующее У нас есть мониторинг медленных запросов да то есть как бы топ медленных запросов Почему они медленно работают смотрим в отчёте запрос в топе Что такое Почему обычно как дба дежурный проверяет что такая проблема есть он запрос и в транзакции Ну потому что запрос может изменять какие-то данные у поса ВС транзакционные что ребята решили попробовать рути и соответственно из скрипта это депу рутины они дерутся там промеж себя и в результате запрос работает медленно притом Не потому что запрос плохой а потому что он просто как бы на стороне питона дерётся и там данные с него медленно отправляются и данные в него медленно приходят там всё Ждёт Ну и таких вещей Может быть дофига Поэтому в эти вещи надо как бы внимательно смотреть и не пытаться применять свою технологию на всю катушку не зная достоверно что технология с которой вы взаимодействует а именно база данных в данной ситуации А это дело вообще как бы поддерживает не поддерживает и нормально работает но вот что касается десятого пункта то это на самом деле не один единственный пункт А это сразу много пунктов и как бы это вот такие вещи которые тоже постоянно всем всегда объясняешь А у нас есть запрос он возвращает сколько-то строк много строк Там миллион да мы вебсайт например то есть мы работаем с веб мордой вот как вы думаете часто на веб морду приходится выводить миллион строк в каком-то виде на самом деле выводят и часто в какую-нибудь поисковую листал такую какую-нибудь вещь и так далее Как вы думаете Сколько людей прочитал этот миллион строк не один очевидно да то есть если вы разбираетесь или как-то ещё что запрос возвращает такое количество строк и это не ет не выгрузка чего-то куда-то ночью в аналитику и так далее вот Задумайтесь вообще А это кто-то может прочитать это верный признак того что у вас явная ошибка да то есть это как бы такой запрос на который надо посмотреть и понять что может быть там просто кто-то либо там данных стало больше а когда-то было мало либо кто-то его просто с ошибкой написал То есть это сразу большая проблема И само что Для такой запрос совершенно бесполезен это ошибка е надо просто убирать та же самая история со счётчиками который я наверное рассказываю на каждой конференции где я что-то говорю о том как правильно работать из Веба с базами данных и в очень многих случаях я вижу это дело в отчётах о медленных запросах очень лют пользователям показывать сч при этом у нагруженный веб и на морде этого сайта эти счётчики тикают быстро да в конкурентной среде да то есть если они тикают не быстро то их можно показывать очень просто да там у постгрес есть там данные от анализатора статистики планировщика И можно написать процедуру которая будет возвращать эти данные которые будут обновляться раз в какое-то время и они будут достаточны потому что они приблизительные как бы и хорошо Но люди делают следующее они реальный вот этот счётчик выводят Ну вот у вас будет информация о том что сегодня зарегистрировалось 261.cc в постгрес Да потому что проверяется версия каждой странички каунт не бывает лёгким не в одной базе данных по этой причине соответственно вы сделали 20 счётчиков на главной странице и эта вещь будет отдаваться несколько секунд если у вас под этим делом лежат большие таблицы и что что здесь делать как это ускорить никак убрать такие счётчики Потому что если у вас страница тормозит Да и то более-менее отвыкает в новейшие времена да а Web для пользователя должен работать мгновенно Потому что если он загружает страничку долго пользователь пошёл на другой сайт и не знаю сделал заказ на нём или там Что что ещё он там сделал вот а поэтому эти вещи нужно всегда Выка Ну и традиционный главный совет в такой в таком докладе про базы данных Data Вы должны знать как работают ваши данные да как-то у Тома кайта это такой НТ orac по консалтингу который очень умный дядька и очень много знает про то как Oracle работает про SQL запросы и так далее То есть он может провести панельную дискуссию с оптимизацией запросов которые ему предлагают оптимизировать прямо сейчас да то есть как бы высочайший класс Его спросили А какими вы инструментами пользуетесь для того чтобы так хорошо оптимизировать SQL запросы он сказал Да тут как бы всё очень просто я закрываю глаза и пытаюсь представить как это работает Вот то есть грубо говоря э полезно вообще знать какие у вас данные какие у вас запросы и немножко думать когда соответственно вы с ними работаете это основной Вообще классный секрет э успеха работы с базами данных вообще там с прогрессом в частности да и с Любой в принципе с технологией с которой вы имеете дело вот а на этом У меня собственно говоря всё И у нас остаётся Вполне себе Разумное количество времени под вопросы И спасибо и я вам с удовольствием на них отвечу Спасибо за доклад такой вопрос а был было сказано что автовакуум как бы не стоит отключать А если базан Only как бы имеет смысл В таком случае Тогда как бы ну отключить и не использовать не имеет не имеет надо всё равно держать там по по ссылке это написано но несколько есть моментов во-первых помимо автовакуум автовакуум как такового Этот демон занимается аналайзер нужно это знать чтобы выбирать оптимальные планы во-вторых у вас есть ПГ каталог который обновляется внутренние всякие таблички если по нему отключить автовакуум результат может быть очень удивительным да у вас какой-нибудь табличка класс станет несколько гигабайт и работать это всё будет очень печально то есть этого Просто не надо делать хотя бы уже даже поэтому то есть лучше не трогать лучше да настроить разумно и работать ну в ряде случаев если есть какие-то таблички которые обновляются не очень часто можно делать по ним индивидуально указывать чтобы автовакуум работал не так интенсивно ноп же ти я бы так делать не советовал Потому что если табличка вырастет до Больших значений у неё там на 90% адев стоит автовакуум то этот автовакуум будет работать долго и будет серьёзно мешать перфоманс системы Несмотря на то что он будет срабатывать редко То есть это как бы нехорошая практика и ещё Тогда спасибо такой вопрос по поводу больших выборок то есть там если есть такой запрос там же лимит можно поставить проли это лимит Да можно поставить но возвращается миллион то лимит э не поставлен но с лимитом нужно понимать следующее что чтобы получить те данные которые вы хотите вам надо понять как они у вас отсортированы и какую вы часть их получаете Ну хотя бы просто пейджинг сделать да какой-то да то есть как бы тут надо уже как бы конкретной реализацией заниматься нам Спасибо Спасибо за доклад меня зт Тимур такой вопрос Вы сказали сначала что бизнес там Хочет хранить любые данные всегда и за весь промежуток времени у нас тоже примерно такие ситуации и вот как в таком случае лучше подходить к проблеме архивирования данных ну скажем какой-то большой таблице огромных логов которые не воздам му счёту А вот этот большой хвост который остаётся его надо куда-то деть заархивировать каким-то образом Да но при этом сохранить чтобы можно было с ним работать Вы немножко про P Проси сказали вот интересно было бы что за инструмент подходит ли он для этого или какие-то другие есть инструменты есть достаточно много методов Ну во-первых простой способ держать какую-то машину может быть попроще просто с большим объёмом Да которой не нужно особую производительность просто там места должно быть много и можно туда выносить вот этот хвост холодный собственно говоря А дальше уже вопрос о том Какими методами выносить собственно говоря простейший способ - это просто дампить эту табличку и этот Дамп выносить на тот хост и соответственно его там разворачивать на таком архивном Хосте конси особой не будет Поэтому Пожалуйста пусть она там будет это можно оттуда достать в любой момент пойти посмотреть поработать если например нужен более оперативный доступ то можно написать хранимую процедуру на языке попси один из методов Может быть там не самый лучший не для всего подходящий но тем не менее как бы он работающий что это за технология У вас есть две хранимых процедуры одна на вашем хасте на котором у вас активные данные живут и э процедура на языке PL Проси которая занимается только тем что вызывает на удалённой машине с архивом хранимую процедуру на языке plpgsql который который обладает такой же точной сигнатура это реу бы по удаленному вызову довольно быстро работает в принципе хорошая технология Скайпом в сво время разработана ещ когда они были не под майкрософта там либо то есть как бы она действительно там хорошо работает вот и в такой ситуации вы можете например повесить в с юнионом на запрос из вот этой таблички которая у вас с горячими данными на активном сервере с результатом выданным из Рани Вот и дальше соответственно Если вы обращаетесь к этой ВХ И вам нужны только горячие данные по услови вы обращаетесь как бы только к ней Вы только эти данные поднимаете архивные данные там как бы разбирается что куда надо сходить смотрит что там нулевой результат и как бы в он приезжает нулевой результат да То есть в принципе это одна из методик как вот это можно сде за зовут Владимир хотел ещё уточнить вот вернуться в самое начало вы говорили что нужно не торопиться масштабироваться а если всё-таки нужно как-то предусмотреть масштабирование и об этом подумать всё-таки заранее то есть какие подходы стоит учесть что может посоветовать и подсказать спасибо ну как бы первый на самом деле совет - Это как не удивительно не масштабироваться заранее а просто банально готовясь к старту понимать сколько данных будет да то есть Понятное дело что нагрузочные тестирования не гарантирует воспроизведение ситуации как оно пойдёт в бою но в любом случае первое что нужно иметь это нужно иметь хороший мониторинг да То есть вы должны в идеале иметь там график прироста ваших данных и реакции базы данных на это да То есть вы имеете графики и смотрите тренд Да если вы видите что у вас там маркетинг начал активно продавать какие-то там услуги и у вас пошёл рост Вот вы заметите это на графике и тогда примете решение достаточно оно что вам проще и дешевле купить несколько новых эсэс дшв быстрых и там доставить оперативной памяти либо это слишком дорого и нужно поставить там пару дешёвых машин чтобы разгрузить на какие-то определённые задачи да то есть я бы сказал что всё-таки там нулевая задача - это просто понять нужно надо вам масштабироваться или нет Ну а дальше уже как бы Исходя из этого как бы думать то есть на разумно щем условно говоря 30.000 долларов да стоит то есть для баз данного сервера это как бы Разумная цена там по нынешним временам вот он может выдерживать не замечая очень большую нагрузку и далеко не во всех проектах такая нагрузка возникает да то есть тут как бы дело такое Я бы скорее сказал что имеет смысл масштабировать возможно какие-то вещи по клоу да то есть например если у вас есть на НМ много ТП запросов Вот они идут на мастер если ну какую-то аналитику прогнать да то тут скорее всего будет не очень хорошо потому что на базах данных особенно версион нах не очень хорошо живут одновременно длинные и короткие запросы по там массе причин того как устроены транзакции в этой ситуации вам как бы лучше от масштабироваться просто тупо реплику поставив и запросы на чтение туда отправив да то есть как бы разделять так вот масштабироваться не по размазывания Да а просто исходя из задачи если у вас запросы там длиной больше нескольких там миллисекунд намер они идут на реплику если они там соответственно запросы короткие пригодные для утп они там соответственно живут на Мастере вот скорее в эту сторону я советовал думать скажите вот на предыдущего вопроса вы налогов кроме Проси ещё же вроде можно использовать for вы не пользовались можно использовать но там больше вещей на свой стра к то есть ppy не до конца умеет транзакции в том смысле что он умеет только автокот там нельзя управлять транзакциями Но это транзакционный вызов rpc притом он может быть вызван там очень далеко например да вот а dater - это вещь во-первых совершенно непредсказуемое для оптимайз во-вторых не всегда хорошо работающая с транзакциями потому что бог его знает кто его там написал for dater к постгрес вообще довольно странная вещь да потому что как бы там получается что на одной стороне исполняется запрос вообще с одним планом Наго с другом с другим планом и это может быть предельно не оптимально Вот То есть в принципе как бы можно да использовать для этой цели но я бы рекомендовал сильно более простые решения и использовал бы только если очень хочется получится Но с ним по опыту проблем меньше бывает на эту тему Понятно спасибо Вот ещё на первом ряду а вам встречались решения типа вынести архивную табличку на отдельный диск положить диск этот в какой-нибудь там shared storage с какой-нибудь ocfs2 и просто с этим вот два отдельный сервер там на ron работает В смысле отдельный tace так положить и соответственно сейчас а в смысле на другой По какому фсу грубо говоря ходить и Ну можно ени чуть более оптималь Ну грубо говоря да Ну это не самая лучшая идея Потому что если вдруг кто-нибудь дёрт этот по каким-то Прим этот это всё добро начинает лезть в шарен ие буфера А я имею в виду с другого сервера в смысле Table Space на этом сервере дёргать с другого сервера Да там этого делать ни в коем случае не надо даже на ron в общем-то потому что там вся Мета информация в йб спейсах в пейджа Она вся относится к этому серверу и как бы это не будет работать ну Oracle как-то так же делает Нет у оракла есть рак и это и это большая разница О'кей А что всё-таки делать с омом То есть вы вообще отказываетесь от орма как только начинаете писать проект или вы перед выпуском продаж всё переписываетесь Какая у вас политика относительно него скажем так я ничего не пишу я только последствия ликвидируют делает по-разному есть люди которые как бы умом пользуются и как бы и живут с ним и у них как бы есть бизнес-процессы которые отвечают за оптимизацию Урма и они считают что так хорошо это как бы совершенно нормально я как бы призываю только к тому что умом Ну как бы с моей персональной точки зрения польз что это ве удобная Да описание там на Джаве конструирования запросов оно как-то выглядит На мой взгляд немножко Дикова Да но на вкус и цвет все фломастера разные есть куча людей которые это любят наоборот делать Вот не знаю В принципе опять же опыт подсказывает следующее что проектов которые начинаются целиком Наре очень много проектов которые успешно эксплуатируются многие годы и при этом целиком Наре я не встречал ни одного да то есть обычно народ начинает с того что какие-то критичные запросы начинает выдёргивать из орма и писать их руками вот и наверное 90% проектов начавшихся с умом живут именно по такой схеме при этом проекты которые я видел что их просто сма взяли и переписали я тоже видел сильно меньше потому что обычно это большие затраты и во всех случаях ситуация с производительностью них изменилось просто на порядке да то есть это это серьёзно приносит много плюсов Но единственное да вам нужно нанимать программистов которые знают SQL умеет его писать и соответственно тратить время на какие-то более медленные вещи в разработке поначалу да то есть во многом возник вообще как идея от такой венской разработки Да когда люди разрабатывают какую-то систему ставят её заказчику и и деле нужно очень сильно сократить время до подписания акта да то есть вот поставили а дальше то что его будет сложно поддерживать Это лько бонус Да за эту поддержку деньги платят А когда мы в вебе живём Это совершенно другая история нам нужно делать по-другому потому что у нас нету точки подписания акта как правило мы сами потом будем тратить время на вот эти вот все вещи поэтому вот как-то так ещё вопросы Илья Спасибо вам большое за доклад да"
}