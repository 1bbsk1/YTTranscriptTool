{
  "video_id": "O0iIADHgBVc",
  "channel": "HighLoadChannel",
  "title": "Реверс-инжиниринг архитектуры Amazon S3 / Владимир Перепелица (Mail.ru)",
  "views": 4074,
  "duration": 3457,
  "published": "2018-01-16T13:10:48-08:00",
  "text": "значит я расскажу про то как лично я повторял у нас сервис amazon из 3 значит что такое реверс инжиниринг реверс инжиниринг это процесс извлечения знаний и какой-то информации о сервисе о котором мы не можем что-то узнать это может быть сервис это может быть продукт это может быть библиотека реверс инжиниринг паня полезен может быть не только в случае конкретного какого-то сервиса как это происходило когда-то давно около полугода назад пришли менеджеры и стали бы говорить вот у нас есть облака но она не очень растет на него не очень большой спрос и вообще бизнес-пользователей чего-то хотят есть amazon в котором понятно есть деньги он хорошо растет вот нужно нам что-то такое ну мой первый вопрос я вообще никогда не пользовался из 3 до этого мой первый вопрос что вообще такое этот ис-3 что с ним делать ну как оказалось с 3 расшифровывается очень просто simple старик сервис nook simple уже навевает на мысли что будет просто хотя на самом деле это не так ну в общем нужно разбираться собственно для того чтобы повторить какой-то сервис для того чтобы что то сделать что нужно предпринять нам нужно было сделать так чтобы уже существующие клиенты библиотеки готовые приложения так как они работают сама зонам точно также стали работать с какими-то нашими сервисами для того чтобы наши кости мир и могли спокойно просто переключиться на нас для того чтобы понять что вообще нужно делать нам нужно изучить понятное дело предметную область собственно об этом изучение и от механизме и сборе информации пойдет сегодняшний доклад идем на самую первую страницу описания начинаем собирать информацию первое что мы узнаем про amazon s3 это то что это rest api уже неплохо второе как мы уже знаем это storage service после того как мы продвигаемся несколько минут по информации мы понимаем что там есть нечто под названием bucket и мы не знаем пока что это и нечто под названием объекты которые видимо лежат в этих пакетах вот есть сам сервис сами запросы разделяются на запросы к сервису запросы кабаки там запросы к объектам и так сервис мы открываем самую первую вкладку из d в документации видим что туда приходит обычный get запрос на некий ход который называется ис-3 там чего-то там amazon в заголовках обязательно передавать дату в заголовках есть какая-то хоть эта пышная авторизация мы тут же узнаем что формат обмена с amazon am i to xml это что наш сервис возвращает некоторые набор пакетов в общем дальше нужно узнать что же такое багет багет это некая сущность идентифицируем а я именем имя прописывается горле так или иначе то есть несколько форм записи и содержимое пакета это вот те самые объекты над бакетами есть набор листовых операций и the head гей от пут делит и так далее если кто-то знаком с ростом кстати кто знает что такое рост вот какие правила реста собственно хорошо часть аудитории знает значит там все довольно таки хорошо согласуется то есть если пульт мы создаем этот самый bucket если там head мы проверяем то есть есть она есть ли у нас право его можно удалить собственно когда мы начинаем с чем-то работать нам нужно начинать задумываться при изучении над лимитами наша цель повторить сервис для этого нам нужно узнать как он работает внутри поэтому мы будем обращать внимание на то какие лимиты ограничения и свойства есть описанный вопи либо будем их доставать ну и собственно get на баке для возвращает нам объекты значит объект для того чтобы узнать что такое объект лучше всего пойти посмотреть как он создается создается он точно так же при помощи простого пута у объекта есть имя причем это имя это ресурс в орле тут сразу же если вы видите url если увидеть идентификацию чего-то орлом нужно подумать о нормализации кто знает что такое нормализация для тех кто не знает одни и те же символы в url могут представляться разным в разной форме и в зависимости от реализации сервиса вас они могут означать одно и тоже или ни одно и то же ну и собственно с пути передается блок то есть некоторые данные которые ассоциированы с этим объектом это объектно и хранилище собственно нужно подумать какого максимального размера может быть этот самый объект это тоже нам что-то скажет про хранилище значит над объектами точно так же можно делать все эти рисковые операции их можно получить дети проверять существование удалять либо есть альтернативная форма записи это пост немножко проверил как устроен url на объект в хранилище amazon и street как я уже говорил префиксом является тот самый baked причем зависимости от версии либо необходимости использования вы можете использовать как host name часть так и часть пути то общая часть которая вот здесь написано как с треском называется host bass это уход без можно поменять другие сервисы которые реализуют с 3 подобное api находится на другом хост бей же все остальное мы должны сохранить у объекта есть имя ну или ключ так в разных местах он называется по-разному на эту сучку что вот это имя объекта не включает ведущий слэш в объекте могут быть какие-то разделители по умолчанию разделитель слэш и еще существует терминология префикс когда мы берем берем какую-то часть этого имени до разделителя значит что мы можем с этими объектами делать собственно если мы уже нагрузили какое-то количество объектов у нас есть листинг листинг в амазоне довольно интересная вещь поскольку при реализации это было наверное единственная вещь в которой по документации я довольно сильно ошибся то есть кажется то есть что просто реализуешь повторяешь начинаешь тестировать оказывается сложно значит в листинге есть объекты объекты отсортированы лексикографические и когда мы получаем листинг но получаемому строго в таком порядке если мы хотим сместиться как-то по списку у нас есть способы то есть мы можем сказать что начинаем после такого-то ключа можем сказать максимум столько-то ключей мы можем работать в рамках какого-то префикса если мы останавливаемся то есть мы получили максимум вот те самые 4 записи нам может захотеться позднее продолжить с этого места нам возвращается специальная сущность которая называется контингента кинг которая позволит нам листать эту описку дальше соответственно нам нужно сделать какое-то хранилище которое будет позволять вот это если посмотреть бегло может показаться что под с 3 api подойдет сущность которая реализует файловую систему у нас облака и в облаке у нас есть своя база данных реализующая файловую систему но здесь есть определенная особенность здесь отсутствует понятие директории здесь есть только ключи и никаких директорий при этом я могу иметь сразу ключ с большим количеством разделителей более того я могу разделить или менять значит директории виртуально создаются на лету когда мы запрашиваем листинг указывая некий разделитель по умолчанию разделитель везде слэш но в этом случае поведение меняется если файле то есть в этом объекте содержится расти тот разделитель от у него откидывается все после разделителя и это превращается в префикс когда мы выполняем листинг нам возвращается либо сам объект если в нем нет разделителя либо возвращается этот префикс и все записи с этим префиксом пропускаются и возвращаются как 1 запись то есть если мы запрашиваем 4 записей из этого списка мы получим первую запись 2 префикса запись три икса и кантины и шин токен установлен установится на следующую запись значит на обычной файловой системе то есть или ее абстракции это реализуется очень плохо поэтому вы можете сделать с 3 api подобное к файловой системе но вы не можете сделать полное с 3 api на базе файловой системы ну что мы узнали достаточно для того чтобы в общем попытаться собрать какой-то прототип значит выполнять мы это будем приблизительно по такому цикл у нас есть идея мы хотим сделать стрипе нам нужно выдвинуть некие гипотезы относительно того как она устроена то есть мы собственно и сейчас уже смотрели предполагали далее проверить эти гипотеза тем или иным способом на основании этих гипотез и того что у нас получилось собрать прототип и проверить этот прототип заработает или нет по результатам проверки у нас может быть три результата нас не устроит то что получилось гипотезы были неверные мы где-то ошиблись в общем возвращаемся в начало можем найти небольшие недостатки исправить их и остаться там же и когда нас все устроит мы можем перейти к формализации этого прототипов продукт значит что мы должны сделать при выдвижении гипотез как я уже говорил нам нужно определить те самые пределы значит на что обращать внимание основной вопрос который вам нужно задавать когда вы изучаете какую-либо внешнюю систему про которую вы чего-то не знаете или ничего не знаете по сути сколько вот вы смотрите у вас есть сущности задаете себе вопрос сколько есть bucket и сколько может быть bucket of всего какие ограничения на там их имя там например максимальная длина набор символов объекты все то же самое значит когда вы записываете эти самые пределы вам нужно обращать внимание какой это лимит лимиты бывают мягкие значит что такое мягкий лимит это лимит который выставлен но при этом его можно превысить например у дропбокса существует лимит на количество файлов это мягкий лимит он говорит до такого-то количества все будет работать хорошо после превышения такого-то количества объектов производительность деградирует но продолжит работать это мягкий элемент это не значит что вам нужно поддержать максимум столько объектов другой мягкий лимит это когда вы можете делать бесплатно столько вот с такого то мы вас начинаем сильнее белить но продолжаем обслуживать это значит что предел там не установлен это просто какое-то логическое ограничение hard лимиты это лимиты которая превзойти нельзя это то на что вы можете гарантированно опираться если вы пытаетесь что-то повторить то вам нужно знать где вы можете остановиться где вам останавливаться нельзя это может быть какой-нибудь асимптотический предел либо это может быть явно установленное ограничение еще мы забыли про такую вещь как авторизация то есть мы посмотрели да вот есть api и списке объекта и так далее но у нас приходит нормальные пользователи и приходят злоумышленники которые могут пытаться что-то у нас взламывать нам нужно как-то узнать как авторизовываться пользователей ну в общем все просто у нас есть документация к счастью гораздо сложнее реверсе без документации мы узнаем что у нас данные request a формируют некую строку для подписи у нас есть ключ для подписи который делается из двух новых сущностей про которые мы узнаем это access кейсик редкий от них делается хэммок архимаг atx и matx маккой так несколько раз в общем кто-то кто разрабатывал этот ключ очень любит химок sha-256 так или иначе в результате мы получаем строку которую мы используем заголовки of the relation именно эта строка и дает нам возможность авторизовываться стри клиентов теперь посмотрим что мы собрали значит у нас есть некие пользователи с этими самыми access ключами у этих пользователей есть bucket и на баке ты выставлен софт лимит в 100 штук это soft лимит его можно превысить при определенных условиях но тем не менее для нашего прототипа мы можем воспользоваться этим лимитом имея в виду что мы позднее можем его превысить у баки то есть имя на имя есть ограничения у баки то есть еще некие а цели атрибуты то есть что-то к нему нужно будет сохранить у bucket of есть объекты объектов может быть произвольное количество в общем на какие-либо лимиты закладываться не стоит на имя есть жесткое ограничение 1024 байта это полезная информация то есть мы можем своем хранилище иметь это как верхний предел у объекта также есть а цели атрибуты какие-то дополнительные и у каждого объекта есть тот самый блок данные которые нам нужно хранить зависимости от метода мы можем сохранять либо объекты до 5 гигабайт но в целом существует метод собирать объект из нескольких и максимальный размер объекта в с 35 терабайт это тоже максимальная цифра на которую нам нужно рассчитывать когда мы решаем какое хранилище нам выбрать нам нужно собственно разобраться как мы будем хранить эти данные значит существует простое хранилище это блок сторож когда мы получаем какое-то блок данных вот того самого размера там до 5 гигабайт или 5 терабайт сохраняем его просто на несколько дисков на разных серверах это простое хранилище это хранилище у нас есть но существует другой вид хранилища это блочное хранилище когда любой входящий блок который нам нужно сохранить мы разбиваем на блоке равна величины или около того и дальше уже эти самые блоке мы сохраняем на этих самых разных серверах здесь нужно было решить подходит ли нам блок хранилище или объектное хранилище как его называет amazon или нам нужно реализовывать свое блочное хранилище блочное хранилище более гибкая но при этом у него как вы видите вот можно даже из картинки понять намного больше метаданных сохраняется под каждый объект его не так удобно поддерживать значит нам нужно верифицировать api на предмет существуют ли какие-либо операции которые требуют блочного хранения что требует блочного хранения то есть какую операцию вы не можете сделать нормально одна из операций тут есть у вас файл допустим вы тот самый файл на 5 гигабайт вы хотите его изменить вот он у вас лежит вы говорите вот измени ему вот небольшое количество это реализуется например в вдове операции патч вы просто выкидываете какой-то небольшой блок перри записываете этот небольшой блок весь файл у вас остается собран из тех самых кусочков это быстро перезаписать 5 гигабайт быстро вы не сможете перезаписать пять терабайт тем более другая операция которая требует блочного хранения it up and когда у вас есть файл и вы говорите а я в этот файл дописываю еще какой-то кусочек он остается там же лежит там же но в нем появляются новые данные для того чтобы выяснить это все нам придется пройтись последовательно по всем методом объектов и попытаться найти признаки либо патча либо пендаль ибо чего-то похожего у нас всего три способа создать объект это путь пост и ничто на под названием мультипарк в пути мы встречаем довольно такие строгие утверждения там говорится что put никогда не добавляет объект частично если у нас есть конкурентные путы они всегда перезаписывают последней операцией то есть в принципе путь такой либо он кладет все либо ничего то есть здесь есть как бы ожидании что в общем блочное хранение здесь не нужно пост на самом деле это тот же путь только работающих форм датой то есть он точно так же все все объекты перезаписывает никакой до записи нет единственное опасение вызывает метод мульти парта плод но если начать с ним разбираться то есть у смотреть как он устроен можно встретить утверждение что мультипарк собирает объект из кусочков причем в методе комплит мульти парта плод написано что обработка request a может занять до нескольких минут и сама api за дизайне на так что она поддерживает возможность длительной работы этого самого мультипарк completo то есть мы можем на основании изучения api сделать вывод что хранение мы можем использовать объектная то есть хранить blob целиком я не могу утверждать достоверно какое хранение использует amazon но по косвенным признакам я могу утверждать что скорее всего это именно объектное хранение тем более amazon сам называет свое хранилище объектным значит для хранения метаданных вот тех самых пользователей ключи bucket of и объектов нам нужно что-то выбрать какая-то база данных прикинем объемы мы определили с менеджментом некий наш прототип которого нам хватит для проверки наших гипотез и запуска pin первых клиентов нам нужно было поддержать 10000 пользователей этих пользователей должно быть сумме около 100 тысяч пакетов и в этих байки так должно быть не менее это точнее не более 100 миллионов объектов этого достаточно для проверки пользователь умещается спокойно вот записи пользователя в 100 байт запись а боккетти тоже ограничение на его имя мы знаем объекты имеют ключи под линию мы оценим их приблизительно как 256 байт в основном мало кто добивает ключ до его максимальной длины в 1000 байт и суммарный размер вот этого всего то есть у нас самое значимое это объекты мы видим что под хранение этого нужно двадцать четыре гигабайта и очевидно что поскольку мы mail.ru и мы mail.ru очень любим тарантул под это дело и мы тут же возьмем тарантул тем более что она все прекрасно влезает в рамках одной машины теперь пришло время нарисовать как это все у нас будет устроена с чего мы будем начинать и как мы это будем развивать ну очевидно на фронте у нас будет стоять индекс собственно самый распространенный инструмент для терминации с или termination их и т.п. трафика за engine никсон мы поставим некий сервис который будет выполнять вот роль с 3 сервиса на скажем так границы он будет выполнять различную валидацию request of принимать все входящие данные проводить авторизацию взаимодействовать с метаданными входящий трафик он будет заливать в блок сторож исходящий трафик из block story джон будет забирать и отдавать пользователю поскольку он будет через себя гонять трафик предполагается выносить эти ноты на скажем так пограничье то есть если мы будем строить сидел нам нужно будет лететь но ты утащить далеко поэтому мы предусмотрим возможность установки крыша либо дискового либо в памяти можно и так и так собственно метаданные у нас будут отвечать за bucket и объекты и временно мы туда положим авторизацию поскольку это прототип значит ну теперь все нам нужно собрать mvp кто-то кто знает что такое mvp почти все для тех кто не знает mvp минимум воевал продукт это минимальный жизнеспособный продукт у нас были каста мир и которые уже пользовались из 3 когда наши продавцы предлагали использовать выдав которые собственно в облаке есть они мягко говоря плевались говорили выдав это это не rest это вообще ну доказать человеку который считает что вы вдохни rest что это rest очень сложно гораздо проще сделать из 3 и продать ему из 3 значит нам нужно было сделать так чтобы те клиенты которые у них используются заработали с нашей системой то есть нам нужно было сделать какое-то такое облако куда пользователь может сложить свои данные чтобы это было удобно с удобными ручками сэмплами и прочим для того чтобы сделать минимальную жизнеспособную версию нам как нам показалось достаточно 5 методов посмотреть тот самый список пакетов которые доступны положить в него объект посмотреть что там лежит получить объект обратно и удалить собственно для всего остального у нас есть универсальный ответ амазона 501 not implemented дальше осталось просто это за прыгать полгода назад в ноябре то есть где-то в начале ноября я сел это все собирать имея все вот эти данные в общем прошло довольно немного на то чтобы собрать этот самый прототип у меня ушел всего месяц спустя месяц у нас был готов прототип ну на самом деле это был прототип потому что он обладал очень малой функциональностью но мы назвали его бета собственно вы наверняка многие знаете эту фразу потому что это было намного лучше чем то что у нас было до этого конечно же после начального тестирования мы обнаружили там различные баги особенности и прочее вот здесь был вариант либо это исправляется и мы идем дальше либо мы ошиблись все неправильно надо начинать заново счастью мы не ошиблись все было выбрано правильно но надо было просто исправить баги оказалось что амазона существует не одна версия подписей а изначально их видимо было 4 то есть они развивались чела первая вторая и так далее на данный момент живы 2 и различными клиентами поддерживаются 4 и amazon рекомендует 4 это вот та самая хэммок от хомяка архимаг а есть еще так называемая в два или rest аутентификация и добрая половина клиентов и и поддерживает поэтому нам нужно было добавить авторизацию и так же добрая половина клиентов используют запрос head для того чтобы проверить а можно вообще тут хватает ли у него прав доступа например есть ли объект также наши клиенты практически сразу попросили public рида цель это когда вы заливаете объект авторизована а скачивать его можно без какой-либо авторизации но в общем amazon s3 под это в большей части и предназначен дальше нам осталось просто пофиксить баги значит мы исправили авторизацию мы добавили public вида цель добавили кеды нашли небольшое количество ошибок и пофиксили их и поскольку этой системы уже кто-то начал пользоваться но и начали делать тесты таки более обширные и продвинутую систему контроля доступа access control полисе поскольку на нее тоже были запросы в этот момент обнаружился некоторый недостаток в скажем дизайне приложения а именно мы использовали какие-то библиотеки при этом мы одни и те же библиотеки использовали и в самой системе ее реализации и поскольку они у нас были там генерация подписи все удобно мы их же включили в тест в итоге когда при очередном каком-то обновлении мы в этой библиотеке допустили ошибку ошибка была одинаковой и в тесте и в тестируемой системе то есть мы успешно выкатили сломанную авторизацию суд на когда мы это нашли нам пришлось починить авторизацию еще раз после этого нужно было сделать следующее собственно никогда не используете одно и то же библиотеку если это ваша библиотека и в тестируемой системе и в тесте значит вообще по итогам этого мы перешли к следующей модели тестирования никогда не стоит один раз написать тест на какую-то вашу систему и считать что этот тест фиксированный стабильный ничего не меняется мы пишем тест в качестве референса у нас выступает amazon если вы будете реверсе что-то другое вас реверсом может быть либо тот самый сервис либо библиотека либо еще что то в тесте у вас есть копия библиотеки которая что-то реализует и после того как у вас написан тесты вы проверяете его на референсной системе вы тестируете свою систему которую вы делаете если вы что-то меняете если вы например дорабатываете тест проверяете еще раз на референсной системе теперь вопрос такой вот у нас есть прототип мы его собрали протестировали все хорошо клиенты довольны у них все работает нам нужно растить до продакшена кто может сказать что нужно вот здесь чтобы перейти от прототипа к production ну нам нужно подумать о масштабировании конечно написать с нуля это хороший вариант но зачастую при написании с нуля мы используем какой-то опыт какие-то наработки которые у нас уже были но основное о чем стоит задуматься у прототипа есть предел в прототипе прощаются различные вещи то есть мы допускаем ну вот здесь у нас будет столько и не больше нам достаточно чтобы проверить для того чтобы поддержать все что нам нужно нам нужно научиться масштабироваться значит при масштабировании бывает два подхода собственно на что нужно обращать внимание бывает хорошее масштабирование и плохое вот здесь изображена два плохих масштабирования значит одно из них имеет асимптотической у линию то есть вы наращиваете объемы вам это скажем стоит чем дальше тем дороже и дороже дороже хороший пример это вертикальная масштабе 1 выберите базу данных вы в нее чего-то наливаете вас кончается вместо того чтобы сделать например sharding вы решаете а мы сейчас возьмем и поставим сервер помощнее и поставим туда максимальные камни и прочее у этой системы все равно есть предел физически одна машина ограничивает если вы не умеете шар лица у вас есть вот эта самая вертикальная линия вас просто машина становится дороже дороже дороже но вы не можете нормально скейлится другой вариант это когда для вас рост имеет ну какую-нибудь далекой от линейной форму квадратичную не дай бог экспоненциальную в этом случае у вас на начальных этапах бизнес может выглядеть красиво в общем так все хорошо мы запускаем разрабатываем потом вы начинаете масштабироваться и понимаете что у вас бюджет и не сходятся то есть вы начинаете продавать больше и вам это начинает стоить больше чем вы на этом зарабатываете значит про масштабирование нужно думать сразу еще на начальных этапах и собственно посмотреть хорошие примеры это линейная вот самое простое масштабирование это линейная просто вы выросли в два раза у вас выросли касты в два раза она может быть суп линейным это когда при больших масштабах вам что-то достается дешевле например вы где-то закупаете хранение или там вы закупаете диски оптом либо у вас может быть немного более чем линейная то есть например с ростом количества метода данных у вас растет количество метаданных она в общем близко к линейному немного это тоже нормально значит еще один момент это компоненте зиру и масть вот здесь как бы относительно того что переписать нормальная система разбита на компоненты причем каждая компонента реализует либо внешние api либо внутренняя либо компоненты между собой тоже соединяются через api компоненты не пытаются делать одновременно несколько разных задач если какая-то из компоненты предоставляет несколько api то она предоставляет однотипные api собственно это схема нормального человека а вот это скажем так то как она может выглядеть после некоторого прототипирования то есть когда вот по-быстрому внешне вот по контурам выглядит вроде бы точно также но здесь в разных местах по быстрому воткнуты разнотипные методы где-то вот кнута пару костылей что-то прилеплена вообще изолентой но самое страшное даже не это снаружи может быть более менее ничего важнее что внутри если вы что-то пытаетесь внутри такого менять то вас могут например те самые костыли отваливаться потому что они там вот связаны с тем методом и вот такую систему нужно именно что взять и переписать сразу разбить на компоненты вы что-то проверили посмотрели и так далее вот если у вас такое ни в коем случае с таким не идите в продакшн обычно менеджеры очень любят вот получив второй результат сказать о класс у вас все почти готово давайте продавать нет это продавать нельзя нужно взять и сделать первое значит для того чтобы как-то скейлится и понимать сколько вам нужно ресурсов нужно научиться их измерять вообще а синтетическое тестирование то есть бенчмаркинг эта штука довольно таки ненадежны судно кто считает что синтетика и невозможно измерить нормальную нагрузку хорошо есть такие значит тем не менее синтетика может быть полезно ну допустим рассмотрим некую гипотетическую систему у нас есть некий сервис который принимает запросы и во время исполнения запроса этот сервис совершает два запроса к базе данных запросы разные мы можем используя синтетику довольно точно спрогнозировать пропускную способность данной системы значит мы возьмем стандартная рпс точнее даже не сам рпс а рпс на одно ядро обычно заканчивается в первую очередь циpкa они сейчас тем более не такие горячие как раньше 3 2 гигагерца уже редкость и они как раз дорогие поэтому мы возьмем какой-нибудь средненькое не большое ядро на нашей тестовой системе и посчитаем сколько у нас может наша система пропустить каких-либо запросов то есть возьмем наш сервер который принимает запросы возьмем отдельные его компоненты например хоть и т.п. сервер который терменируют запрос внутри приложение просто простых хеллоу ворлд оф может сделать 10000 цифра с потолка и например у нас есть библиотека которая ходит в эту самую базу данных и это же просто так про бенчмарка им вот пустые запросы там например 150000 в общем их очень сложно между собой сопоставлять но тем не менее мы пойдем еще в базу возьмем вот эти два запроса пусть один бенчмарка это быстро дает 75000 рпс и другой запрос который потяжелее дает 20000 при бенчмаркинга важно что тот ресурс который мы бенчмарком должен уходить в полку если вы воткнулись в какой-то предел раньше значит вас проблема в бенчмарке итак мы знаем что мы можем прогреть запросами там а запросами б нашу систему как узнать когда она все в сборе да очень просто поскольку если перевернуть рпс то у нас получится потребление этих самых циpкa секунд или еще каких-либо секунд на один запрос мы можем их спокойно просуммировать дальше еще раз перевернуть таким образом мы получаем что вот для такого сценария у нас наш вот тот сервер пропустить через себя 88 крп с а база данных на вот такой нагрузки половина одних запросов половина других пропустит 15000 при планировании то есть когда у вас есть база есть какие-то запросы вы можете очень легко и очень просто очень быстро оценивать некоторые пределы если вы чем-то пользуетесь вот например для нашей базы данных тарантул основные показатели например сколько стоит select сколько стоит апдейт сколько стоит там local туда-обратно мы знаем сколько там стоит взять и таратар пройтись например по миллиону записей например это занимает одну секунду циpкa то есть я могу прекрасно понимать что если мне нужно выбрать тысячу то есть у меня будет уходить на это одна тысячная секунды дальше исходя из этого я могу довольно легко и просто видео запрос зная какие запросы приходят прогнозировать сколько эта база выдержит это очень хорошо помогает заранее спрогнозировать рост вы можете понять что вот этих запросов вы столько выдержки вот этих нет ну и как бы подтверждать какие-то свои гипотезы графиками если вы запустили систему у вас была оценка вы видите на графиках перекос с большей вероятностью у вас где-то ошибка в системе чем вы ошиблись в таких расчетах если вы сами бенчмарки были проведены правильных при этом синтетику очень просто тестить берете вижу что-то зацикливаетесь это повторяете замеряете на общем синтетику умеют практически все делать теперь посмотрим вот у нас есть наша эта система там engine.exe рода метаданные историк engine x c годами масштабируются линейно вообще без проблем здесь я думаю ни у кого не будет возражений поскольку это ноты без состояния они принимают запрос передают дальше их можно спокойно вводить выводить здесь проблем нет база данных поскольку для прототипа мы взяли одну базу данных у нее есть тот самый вертикальный предел про который я говорил для того чтобы его обойти для того чтобы выйти в продакшен нам нужно применить как я уже говорил sharding даже как бы супер быстрый тарантул имеет вполне реальный предел поэтому мы делаем шар функцию у нас основной ресурс это объекты нам нужно шар функция по объектам значит после этого если мы умеем объекты раскидывать в разные тарантулы мы можем масштабироваться линейно и сторож это то место куда мы складываем данные я про него вообще ничего не говорил на самом деле сторож устроен вот практически также как я вам рассказывал только еще раз там есть ноты которые принимают трафик там есть шар функция там есть базы с метаданными то есть где лежит какой кэш объекта то есть объект идентифицируется hашем размером там еще дополнительными флагами и собственно большое количество дисков в моем случае если бы я стартовал совсем с нуля и у меня рядом не было бы 100 раджа часть из этих метаданных я бы взял к себе но поскольку я стартовал на базе у облака у нас уже есть готовые написаны работающий сторож он проверен проверено его масштабируемость в общем 55 из пользовательских данных хорошая цифра чтобы убедиться в масштабируемости поэтому просторах я тоже могу утверждать что он масштабируется линейно и так в общем выяснили как масштабироваться линейно дальше как развивать этот самый продукт значит иногда в документации все написано понятно то есть открываешь смотришь повторяешь все работает но зачастую в документации есть не все поэтому разработку мы вели вот можно было бы сказать т.д. но если здесь есть хоть кто-нибудь кто знает что такое tdd он может начать со мной спорить поэтому я изменю формулировку на тест черт мы сначала тестируем amazon во время тестирования мы исследуем этот самый вот предмет который мы тестируем его поведение его свойства его возвраты то есть все то чего нет в документации после того как у нас готов тест по результатам у нас есть детали детали реализации ограничения какие-то свойства тайминги еще что-то и мы пишем для себя по сути техническую спецификацию то как мы будем реализовывать свой сервис уже внутри после этого мы его реализуем по той самой спеки это specs это то чего нет в документации чего нет нигде и даже если бы система была без документации закрыта в результате этого все равно появлялась bespeco он после этого мы тестируем уже наш собственный облачный сервис во время тестирования мы для себя выработали некоторый набор правил и эти правила знаете как правила дорожного движения каждое правило написано по результатам какой-то аварии так же и здесь каждая из правил которые мы вводили к нашим тестом было результатом того что где-то что-то было пропущено значит всегда стоит стартовать с чистого листа то есть если у вас есть какие то данные в том же амазоне до их может быть жалко удалять но тем не менее если не убить старые данные у вас тесты могут начать проходить тогда когда им проходить бы не стоило если вы выписываете тест сложной системы прописывайте остановку везде если тест идет не по правильному пути точно также например функции там очистки или подготовки данных не выполнена проверка данные не заливаются но при этом тест продолжает работать сами функции тестирования работают при этом что-то сломалось следующий момент особенно полезен при исследовании внешних систем на которые вы не можете повлиять это запись детализированных логов вы можете их писать на короткое время но почему это важно например тот же amazon может в каких-то случаях вот вы запускаете tr 20 раз все работает на 21 он сломается он даст вам выдаст что-то очень странное дальше он продолжит работать и вы никогда больше не увидите эту ошибку если вы не сохранили если у вас не будет достаточно данных для ее воспроизведения для ее анализа вы это потеряли а поскольку ошибка была вы с этим можете столкнуться повторно значит если у вас есть какие-то параметры ограничения или еще что-то загоните в тестовые данные все краевые значения если ключ может содержать любой произвольный байт загоните эти байты если у вас ключ может быть там минимальной длины 1 максимальной 1024 возьмите и 1002 4025 посмотрите как ведет себя система на предельных данных ну и собственно когда тестируете всегда докапывайтесь до дна если что-то произошло если вы услышали какой-то подземный сток раскопайте значит один из интересных таких стуков произошел у нас мы проводили нагрузочное тестирование нашу собрано системы то есть определенное количество нот бас всего определение пределы мы запускаем тест система не дотягивает до него причем когда мы смотрим то есть мы открываем графики очевидно что то воткнула в предел на графиках у нас основной ресурс это цикл 1 смотрим и так ни одна из нот ни одна из компонент не воткнула в сто процентов но при этом мы четко видим полку то есть все растет растет растет растет потом начинает на каком-то уровне колбасится причем если добавлять количество параллельных соединений еще а чего это рпс не растет просто растет время ответа полка явно видно значит смотрим сеть нет сети там выше крыши и на хранилищах и на еду на водах то есть везде по сети все нормально еще вариант диск может быть тот сторож куда мы пишем нет все нормальные на 100 родах dist даже там и близко не загружен в общем все нормально все графики всех компонент вытащены нигде на графиках ничего не видно во чтобы она уперлась но если вы видите график такой формы или например у вас есть стандартная такая синуса подобная волна которая вдруг в верху срезается и вот около верха колбасится горизонтально у вас полка по какому-либо ресурсов по какому-либо из ресурсов и вот здесь важно найти этот самый ресурс то есть никогда не оставляйте палку просто так после того как мы пошли просто глазами смотреть на машины что где происходит мы нашли оказалось мы пишем много лагов при этом раньше для справки у нас c6 c7 centos 6 санта семь центов 6 мы пользовались нормальным число ганга в которой влезает очень много логов вообще к нему нареканий практически никаких нет когда мы перешли на centos 7 мы стали писать в journal de a journal de неумеет целиться по ядрам в результате он воткнулся сотку перестал обрабатывать наши логе логирование у нас было сделано синхронным потому что нам нужно важной были эти логе для отладки но и в итоге как бы все блоги не пишутся сервис начинает просто подтормаживать просто под уровень этого самого journal de в общем решилась очень просто но вот интересно можно было бы подумать если бы не графики не анализ что вот это предел нашей системой нет это не предел нашей системы предел был обусловлен исключительно криво настроенным логированием поэтому всегда докапывайтесь до причины того что произошло собственно когда мы убрали journal de поставили syslog нормально то есть мы пробили до цикл как и ожидалось чего мы и хотели добиться значит теперь те кто поднимали руку про то что знаю что такое mvp могут порадоваться значит с бизнесе утверждается что это не mvp если вы это не продали если вы делаете би ту би продукт вы не можете называть его mvp если вы его не можете продать а для того чтобы продать вот то что мы сделали нам нужно научиться это считать то есть мы хорошо его запустили у нас был спрос клиенты довольно не все работает но нам нужно с них у научиться брать деньги значит если здесь есть кто-то кто писал пилинги а есть кто-нибудь писал биллинге поддерживал биллинге я попрошу особо не смеяться да это конечно на фоне других биллингов может выглядеть смешно но биллинг эта штука которая считает и которая выставляет считаю умеет процессе деньги значит пойдем в amazon изучим как тарифицируется и что считает con и сделаем также поскольку мы собираемся поддерживать клиента сама зона нам нужно обеспечить им то же самое что и amazon им дает значит что считает amazon amazon считает все request и то есть у вас проходит какой-то запрос этот запрос стоит очень мало но стоит amazon не считает входящий трафик то есть заливаете пожалуйста собственно можно понять почему потому что весь залитый трафик оседает в виде данных а за данные то есть за их сумму он берет какую-то стоимость за единицу времени хранения зато если заливать в него можно спокойно он берет дополнительную стоимость за отдаваемый трафик то есть вы залили залили бесплатно она лежит вы это оплачиваете когда вы этот трафик начинаете раздавать в этот трафик оплачиваете значит здесь стоит обратить внимание на следующий момент у амазона очень хорошо и очень грамотно продумана политика оплаты если вы будете например делать какую-то свою систему посмотрите как сделано у них у них нельзя найти какого-либо способа сделать что нибудь чтобы вогнать их в минус например вы можете создать огромный bucket с миллиардами объектов но при этом вы не можете сделать к ним такой запрос который будет стоить им много а вам мало потому что у них например выставлены ограничение на получение количество записей то есть они говорят что в одном листинге мы вернем вам максимум 1000 записей ведь если у вас миллиард вам понадобится собственно делать очень много запросов на то чтобы получить список объектов это позволяет им нормально масштабироваться это позволяет и нам собственно поскольку мы позаимствовали модель нормально масштабироваться не беспокоиться о том что происходит много запросов собственно каждый входящий запрос оплачивается если у вас есть хранение то есть это хранение оплачивается в общем бизнес-модель и вообще самообеспечение всех ограничений защитой пусть малыми но деньгами это очень полезное вещь если вы даете какой-то запрос который вам чего-то стоит о пользователях может делать бесплатно вы потенциально загоняете себя в условия когда кто-то может эти запросы делать вгонять вас в минус здесь очень хороший пример системы где это все закрыто значит по результатам биллинга нам понадобилось делать первый солидный апгрейт значит что мы пропустили мы пропустили то что может быть несколько ключей с доступом нам понадобилось ввести сущность организация компания на которую мы будем выставлять эти счета поэтому нам пришлось вот тех пользователей которых мы в начале в схеме убить вместо них ввести такие безликие аккаунты с ключами причем там у одного аккаунта может быть несколько ключей ну а всю структуру bucket of объектов и прочего мы перетащили как есть значит поскольку нам при пришлось сильно переколпаковать базу данных нам уже налили около 300 миллионов объектов нам нужно было их как-то обновить мы воспользовались следующей схемой апгрейда значит как обновиться на лету вот у нас есть сервис у вас есть база с некоторые версии кода номер один мы пишем некую версию кода 2 который продолжает работать с версии базы один при этом мы его можем спокойно выкатить посмотреть что все работает если что-то не работает откатить это безболезненно это позволяет нам как выкатиться так проверить такой откатиться обратно дальше особенность этого кода версии 2 в том что он умеет поддерживать базу версии 2 после этого мы выкатываем базу код демонов мы не трогаем если база выкатилась нормально все хорошо если мне нормально откат его им если все хорошо мы конвертируем данные внутри версия 2 года умеет работать с данными формата версии один из данными формата версии 2 после того как мы все от конвертировали у нас все хорошо мы можем вычистить код вычищаем все отверстие и 1 то есть не называем это версии 3 сначала по той же схемы выкатываем демоны проверяем что все хорошо после этого выкатываем новую версию базу и так мы на лету обновились на каждом шаге при каждом обновлении мы могли в случае проблем откатиться обратно и все исправить и мы это сделали на лету значит дальше поскольку мы говорили что потом можно залить 5 гигабайт максимальный размер пять терабайт нам понадобилось сделать мульти парта плод значит мульти парта плод устроен в общем просто инициация заливка нескольких частей завершения или отмена и также листинг в нашу здесь мы по той же методологию извлекли и свойства мультикарта построили схему то есть он прекрасно стал в нашу существующую схему один момент поскольку у нас есть завершение мульти партой сборка объектов мы его немного с оптимизировали те порты которые залиты они уже лежат на сторонах нам для отдачи объекта все есть поэтому мы ввели еще небольшую такую часть мы позволили существовать объектом состоящим из нескольких частей и унесли сборку фон тем самым мы ускорили один из запросов в общем мы пришли где-то к завершению то есть у нас есть проекты и у нас есть побитая на компоненты система которая постепенно повторяет структуру амазона у нас выделился отдельно айдентики access management анала на аналог амазонов ских у нас есть отдельный биллинг у нас есть отдельный и стрим из окна планируем дальше расширяться в эту же инфраструктуру в завершении как устроены наши сервера три основных сервера edge надо пограничная но да там engine x внутрь engine икса у нас но собственно edge daeman который крутится у него есть каши причем каши есть как в памяти так на ssd и на хдд дайте даймон написаны на perl мета но до метаданных это набор тарантулов для максимальной утилизации всего причем часть тарантулы часть тарантулов отвечают за хранение данных один тарантул приблизительно вмещает в себя до миллиарда объектов и сортирующие балансер который проектирует запросы в эти самые ноты метаданных из особенностей там много памяти на одной ноте 512 или 1024 гигабайта сторож простор edge да практически ничего сказать это такая большая полка с кучей дисков диски от 4 до 8 терабайт где-то возможно десятки скоро будут из интересного мы меняем порядка шести до 6 дисков в неделю на всем облачном хранилище теперь что стоит делать когда вы разрабатываете большую многокомпонентную систему первое это снабжайте весь во все ваши request и неким псевдо уникальным то есть не обязательно гарантировать полную уникальность произвольным request айди как только к вам попадает какой-то request сгенерируйте для него рандомную фигню а дальше это постоянно передавайте со всеми запросами когда вы пишете лог в любой из компонент записываете этот request айди в лоб собственно у амазона в формате ответов формате возврата присутствует параметр позволяющий вернуть request айди то есть наверняка у них используется эта же система request найди позволяет вам от 37 весь запрос весь его путь по падения его в разные компоненты и собственно узнать судьбу той или иной причиной про конкретные проблемы если есть какая-то проблема второе это сдерживающие логирование то есть мы либо блоги само приложение их пишет то есть она их имитирует но лагер у нас в рамках одного request to die баттлоге накапливает поэтому в обычном режиме да у нас нет никакого дебага мы логов не пишем то есть когда у нас нет ошибок если происходит ошибка в рамках одного request a он забирает все де бо блоге все в армии нге error собственно и продолжает все писать в стадо out таким образом мы сэкономили количество лагов в 10 раз нас логов стало намного меньше они стали быстрее писаться journal стало полегче но при этом случае ошибок у нас есть полный виртуозные lager ну и мониторинг про мониторинг можно как бы особо много не говорить значит у нас это продакшен мониторинг это не то что железо каждая компонента пишет либо результат своей работы либо и то и другое то есть смысле то и другое и результат своей работы и какие запросы она совершает с таймингами и со статусами ответах под каждую метрику под каждую компоненту строятся сразу графики на этих графиках нужно обязательно определить для себя два предела первый это когда что-то пошло не так вы должны на это обращать внимание второе это когда системе придет конец вы должны знать предел конкретной системы и смотреть чтобы до него не доходило эти пределы можно использовать для прогнозирования емкости вашей системе то есть если это что-то растущие ну собственно у меня все всем спасибо за внимание если есть какие то вопросы можно обсудить их видимо за пределами если я правильно понял что мне говорят"
}