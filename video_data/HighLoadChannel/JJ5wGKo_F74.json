{
  "video_id": "JJ5wGKo_F74",
  "channel": "HighLoadChannel",
  "title": "Архитектура высокопроизводительных распределенных SQL-движков/Владимир О., Алексей Г. (Querify Labs)",
  "views": 1078,
  "duration": 2156,
  "published": "2023-01-19T06:56:45-08:00",
  "text": "всем привет меня зовут гончарук алексей я работаю в компании корифей labs сразу скажу что этот доклад мы должны были читать вместе с владимиром но к сожалению владимир не смог приехать поэтому я буду отдуваться 1 давайте я немножко расскажу о нас мы разрабатываем компоненты зубы до компоненты баз данных такие как оптимизаторы runtime который исполняет запросы сторож системы и распределенные протоколы до этого многие из нас работали над распределенными системами такими как apache и игнайт козелка ства и т.п. и crack house и опять же многие из нас являются камерами в проектная подсекал сайт и апачей играет немного о мотивации данного доклада рамках нашей работы мы много смотрели на то как устроены различные распределенные склеишь движки и увидели некоторые паттерны которые повторяются от системы к системе в тоже время мы видим что в последнее время наблюдается большой всплеск интереса к такого рода системы и даже такие системы как мдг или даже стриминговый системой типа кафки который изначально искали интерфейс они имели они пытаются этот интерфейс добавить и это в целом понятно потому что цель знаком многим этот это удобный интерфейс и если у вас есть такая возможность то наличие сквере позволяет открыть дверь и интеграции с большом с большим количеством различных utility при этом если вы добавляете и сквирт движок свою систему то сделать так чтобы он работал быстро является достаточно сложной задачей поэтому структурно этот доклад мы поделили на две части в первой части мы посмотрим на то как работает внутри именно оптимизатор запросов то есть что он делает для того чтобы составить оптимальный план и во второй части мы посмотрим на execution на то что делает runtime для того чтобы опять же ваши запросы были быстрыми ну и возможно мы обратим внимание на некоторое количество ручек которые в той или иной системе можно покрутить чтобы это работало лучше собственно начинаем с планирование почему вообще оптимизации это сложно и почему столько времени скажем вот появлении первой базы мы начали заниматься оптимизации запросов и до сих пор появляются какие-то новые техники и новые скажем так открытие дело в том что и сквере то декларативный язык и он описывает то каким должен быть результат при этом он не специфицирует именно ту программу которую мы должны исполнить для того чтобы этот результат по учитель и как правило существует достаточно большое количество планов большое количество способов выполнить тот или иной запрос при этом если смотреть на какие-то специфические под задачи планирования например планирование порядка join a таблицы или выбор той или иной матери зова най вьюшки то каждый из этих под проблем является сложной и поэтому оптимизатору для того чтобы сделать планирование достаточно быстрым потому что мы конечно не хотим чтобы планирование занимала дольше чем исполняется сам запрос оптимизатору приходится идти на какие-то эвристики из разных систем и эти very sticky являются разными теперь когда мы добавляем к оптимизатору вернее помещаем оптимизатор в распределенную среду у него появляется дополнительная задача которой состоит в том что мы должны минимизировать количество данных которые передается по сети давайте посмотрим на примере почему вообще данные нужно передавать и в каких случаях их можно минимизировать начнем с простого случая когда у нас есть распределенный join двух таблиц и мы заранее не знаем распределение данных в этих таблицах для того чтобы распределенной среде я такой join исполнить нам необходимо перераспределить данные таким образом чтобы на одном узле были сосредоточены данные которые совпадают по ключу join и соответственно за такую операцию а плеча отвечает оператор который называют либо их чинишь типа shuffle и он по сути пересылает данные по сети в вашем кластере соответственно если у нас именно такой случай когда распределение случайной а то мы будем пересылать данные из двух таблиц при этом есть альтернативный случай в котором мы можем исполнить это join локально на каждом из узлов который хранит данные для того чтобы это сделать необходимо чтобы данные были заранее шарди раваны таким образом чтобы ключ сортирование совпадал по крайней мере совпадал с ключом join двух таблиц в этом случае никаких данных пересылать не надо и мы можем исполнить джон локально такой joy называют кола кейт от эрика shorted однако есть в некотором смысле и промежуточный вариант при котором например если у нас один из входов нашего join достаточно маленькие там и вместо того чтобы перераспределять обе таблицы мы можем просто растиражировать маленькую таблицу на все узлы нашего кластера в этом случае мы избегаем пересылки большого числа данных до второй таблице и опять же наш запрос выполняется быстрее в этом случае на самом деле отдельным вопросом стоит что такое достаточно маленькая таблица и разные системы определяют какие-то свои три желтых для того чтобы включать или выключать этот сценарий исполнения опять же в зависимости от характера вашей нагрузки вы можете этот прошел подкрутить например вот этой профиль те которые определено папа чаплинка окей мы поняли что в зависимости от того какого у нас распределение данных в кластере мы можем получать различные планы исполнения каким же образом оптимизатор может с этой информацией работать на практике это происходит следующим образом каждому оператору в плане исполнения назначается некоторые свойства которое описывает распределение данных специфичное для этого конкретного оператора при этом каждый оператор может ну если грубо то потребовать от нижележащих input а или input of распределения если эти распределения не совпадают то оптимизатор составляет вот эти самые excel-g или решаффлы которые моделируют пересылку данных по сети как мы видели из примера в общем случае у нас могут быть несколько сценариев выполнения запроса то есть оптимизатор может сгенерировать несколько планов и в общем случае мы должны выбирать оптимальный в некотором смысле плана при этом опять же мера оптимальности оно может быть совершенно разной в зависимости от ваших задач как правило меры оптимальности выбирают лет инси запроса то есть ну как как как правило лайкните выражают через семью время которое потратит по оценке ваш запрос но при этом вы вполне можете построить оптимизатор который будет например минимизировать затраты денежные на ресурсы которые потратит опять же вас запрос дальше давайте посмотрим на то можно ли вот это распределение выбирать локально каждым оператором оказывается что нет и это видно на следующем примере здесь у нас есть hash join у которого есть два input а и правы input на картинке он простой то есть этот обласкан а влево бы in quite у нас есть скан поверх которого стоит какой-то агрегатор и соответственно join происходит по колонке а два агрегат делает агрегацию по двум колонкам а1 а2 если мы попытаемся потребовать распределение оптимального для каждого из операторов независимо то мы получим план в котором у нас будет два решафла но можно заметить что если мы потребуем распределения для левого им будто только лишь по колонке а 2 the aggregate все равно сможет может быть выполнен корректно и все данные могут быть вычислены все агрегации может быть вычислено локально но при этом мы избавляемся от вышележащего их очень что приводит к тому что мы пересылаем опять же меньше данных по сети из этого можно сделать вывод что локально локальное решение с точки зрения операторов мы принимать не можем и нам нужен оптимизатор в идеальном случае который позволяет искать у такого рода кросс зависимости между операторами и искать оптимальные в глобальном смысле план исполнения теперь давайте посмотрим на то как планировщики устроены внутри и такой первые дихотомии первое разделение можно сделать исходя из того как планировщик представляет внутри себя план исполнения одним из таких прямолинейных вариантов это одним из прямолинейных вариантов является из использование абстрактных синтетических деревьев или асти и рио истин работать такому планировщику достаточно сложно потому что по факту вы работаете со строками и делать какие-то сложные выводы о том каким образом данные проходит через ваш запрос достаточно сложно поэтому как правило такие планировщики ограничены в средствах которые они могут использовать для трансформации и нужно быть готовым к тому что если ваш запрос сложный то вполне возможно вам придется чуть-чуть его руками до работы для того чтобы привести к оптимальной производительности в то же время есть альтернативный класс оптимизаторов которые трансформируют абстрактное синтаксическое дерево в дерево реляционных операторов и в этом случае работать гораздо проще потому что каждый оператор имеет строгую вычислительную семантику и существует достаточно большое количество правил которые описывают трансформации этого реляционного дерева при этом эти трансформации являются независимыми и такой оптимизатор является достаточно расширяемым то есть вы например при примером такого оптимизатора является spark или тремя такие оптимизаторы сидят с парке или dreamin' где вы можете например написать свой плагин который предоставляет дополнительные правила которые может быть будет делать какие-то дополнительные оптимизации важные для вас при этом то как работать с деревом тоже и до того как работа с деревом есть несколько вариантов самый простой вариант это итеративной или эвристическое планирование суть его состоит в том что у нас есть некоторый набор правил и мы эти правила скажем так независимо и абсолютно прямолинейно последовательно применяем к этому дереву при этом мы считаем что каждое такое правило она безусловно улучшает характеристики нашего плана ну и классическим вариантом такого правила является фильтр бужда он потому что мы считаем что чем ближе фильтр к источнику данных тем меньше строк нужно обработать последующем оператором несмотря на простоту опять же достаточно большое количество production системы используют такой подход для планирования альтернативой такому подходу является планирование с использованием так называемом мимо эта структура которая позволяет закодировать множество альтернативных планов в компактном виде в этом случае оптимизатор идентифицируют операторы которые производят одинаковый результат такие оператора называются эквивалентными и они объединяются в группы в группы эквивалентности и соответственно оптимизатор в нем и заменяет input и операторов на правильные группы эквивалентности такой граф впоследствии используются после того как мы перечислили все возможные планы оптимизатор обходит такой граф и выбирает опять же оптимальной с точки зрения коз модели план проблема таких оптимизаторов заключается в том что он может сгенерировать опять же достаточно большое число планов и время перечисления тип планов тоже может быть большим поэтому на практике production оптимизаторы разделяют планирование на фазы при этом каждая фаза может быть как реалистической так и cost buy stop и в результате в конце каждой фазы мы получаем некоторые оптимальный локальный план и этот план передаем в начало следующей фазы для того чтобы получить такую цепочку планирование при этом опять же строго говоря в результате такой многофазной результате такого многофазного планирования мы получаем в общем случае не оптимальный план но как правило вот эта цепочка на tune за таким образом чтобы наша система работала достаточно хорошо на практике итак давайте поди тут подытожим то что можно вынести из первой части про планировщик с точки зрения распределения данных в распределенной системе правильный выбор схемы сортирования очень важен потому что он позволит оптимизатору выбрать наиболее подходящий плана в частности если у вас есть большое количество распряженных joiner то выбор правильного ключа сортирования позволит использовать к шарды join и важно посмотреть на архитектуру оптимизатора и быть готовым к ручным активизации ям случае 100 и планирования и конечно можно изучить hand и который предоставляет оптимизатор потому что в тех случаях когда в силу ряда причин оптимизатор не может полноценно исследовать пространство поиска существует hand и которые позволят вам опять же вручную улучшить и помочь оптимизатора давайте теперь перейдем к on time мы закончили планирование получили план который был транслированы в некоторую физическую программу но это на самом деле не означает что на этом все наши возможности по ускорению закончена фронтами мы можем использовать различные трюки которые могут менять структуру плана а менять на структуру плана можем потому что даже если бы оптимизатор использовал исследовал полностью все пространство решений то те решения которые он принимает по факту он принимает на неполных данных например статистике которые используют оптимизатор могут быть а вот этот и при вычислении кардинально стей джайнов например может накапливаться большая ошибка при этом при исполнении мы можем собирать эти статистике индивидуальных операторов и при возможности мы можем бери стартовать планирования с той точки в которой мы сейчас находимся но при этом имеет уже какие-то конкретные значения статистика и других характеристик нашего плана поэтому давайте посмотрим на три категории которые мы выделили и который является с нашей точки зрения наиболее важные в runtime 1 оптимизация работает очень часто и практически везде это пронин и и идея заключается в том что мы просто не должны выполнять ту работу которую заведомо можно отбросить браунинг можно условно поделить на несколько подвидов которые необязательно взаимоисключают друг друга и могут быть использованы одновременно parties and running используется в том случае если оптимизатор сумел проанализировать запрос и запушить достаточное количество подходящих предикатов к источнику данных в этом случае например если мы смогли вывести что скажем значение ключа шарди рования имеет какое-то одно конкретное значение или находится в диапазоне значений то мы можем вывести эти шарды которые нам не подходят и не исполнять запрос на соответствующих узлах или собственно шарда каламбур не так активно используется в каланча tedx и аналитических базах и здесь здесь абсолютно такая же оптимизатор транслирует запрос и мы понимаем какие колонки будут использоваться в источнике в этом случае мы просто не читаем лишние колонки с диска что может в общем случае сэкономить нам колоссальное количество дискового и о и наверное наиболее интересным по крайней мере с моей точки зрения является блок pruney нг его идея состоит в следующем весь dataset разбивается на небольшие блоки и для каждого блока мы в момент построения данных момент заливки данных мы агрегирует некоторые статистике например мин-макс и далее когда мы исполняем запрос опять же если у нас есть некоторый предикат то мы берем этот притекать и анализируем можно ли отбросить блок заведомо исходя из статистики которые в нем записаны это очень интересная техника потому что она позволяет на практике пропускать большое количество блоков даже без индекса при этом здесь стоит понимать что для того чтобы эти техники pruney нга использовать нужно чтобы ваши предикаты были сорго бу то есть они очень любят вот эти техники различные больше меньше сравнение quality like по префиксу и их объединение через и или с точки зрения имплементации эти тихие техники сводится к тому что мы максимально спускаем фильтры к источникам данных и объединяем скан вместе с предикатами ну вот здесь приведён собственно пример такого партий шампунь инга по запросу дальше развитием этого этой идеи является динамическая фильтрация в join операторе и на практике это оптимизация очень часто используется и очень важно в различных федеративных системах идеи и состоит в том что если у нас есть joint в котором придвигаться и только с одной стороны то если мы будем исполнять такой план ну скажем так в лоб то с другой стороны мы будем обязаны сделать фуу скан что в общем случае не очень хорошо вместо того чтобы инициировать сразу этот fusco мы можем подождать про в сторону пока у нас построиться хэш-таблица и проанализировать те строки то есть опять же либо собрать индивидуальные значения либо собрать какие-то статистике построить рейндже тех значений которые попали в итоговую хэш-таблицу и перенести эти значения в правую часть что позволит в последствии сократить количество данных которые будут проведены через join оператор соответственно как я уже упомянул это очень важно в федеративных системах и поэтому практически все системы которые представляют ядре едет клэрис эту оптимизацию реализуют при этом понятно что если наша таблица будет достаточно большой то накладные расходы на поддержание такой таблицы могут быть достаточно большими и наш оптимизация может даже привести вред поэтому для того чтобы контролировать поведение этой оптимизации существуют опять же некоторые параметры которые по превышения некоторые прошел до могут эту оптимизацию отключать здесь например приведены такие параметры для пресс то или три на интересную штуку делает snowflake вообще если у нас есть вот такого рода план агрегат поверх join а то мы в ряде случаев агрегат можем разделить на 2 части и вторую часть поместить под джейн идея здесь заключается в том что после того как мы получить за пушем агрегат по join the он сократит количество строк которые будут приходить вы собственно сам оператор join при этом это решение можно принимать исходя из оценок кардинально стена опять же оценки кардинально sti могут быть неправильными здесь можно заметить что отключение вот этого второго агрегата который был помещен to join она никак не повлияет на корректность результат а потому что просто если в произвольный момент времени моего заменим на пастру оператор то есть оператор который будет просто пропускать через себя строки неизменными то мы получим тот же самый корректный результат поэтому на кровь на практике оптимизатор может сделать оценку кардинально sti для результата этой агрегации и мы можем ее спустить runtime при этом если в ран тайме мы понимаем что количество строк которые мы уже загримировали в этом операторе она превышает нашу оценку мы просто можем этот оператор отключить и никаких накладных расходов он больше не будет привносить что позволяет собственно балансировать и хорошо избавляться от ошибок в эстимейт их кардинально sti дальше опять же проблема с оценкой cardinal настей и процент про проблема с оценки размера результата она очень остро стоит стоит в любых системах в том числе и в распределенных и когда планировщик в распределенной системе принимает решение о том насколько шар дав разбить поток он использует количество ресурсов то есть это степень параллелизма который мы можем себе позволить и собственно оценочный размер резался это при этом может оказаться что-то количество шар дав которые мы предсказали она оказалась чрезмерно большим что приводит к тому что у нас появляется большое количество маленьких шар дав дальнейшая обработка маленьких шар дав носит опять же некоторые накладные расходы что не очень хорошо поэтому многие системы умеют подменять план после некоторых точек в которых это можно сделать так например дело это патчей spore потому что его исполнение его запроса разделена на стадии и промежуточные результаты между этими стадиями они материализуются соответственно вы можете по сути передать управление обратно планировщику и он может поменять в ран тайме план исполнения собственно эта штука включается вот этой property и вот в этом случае если у нас появилось большое количество маленьких шар dave the spark может их просто склеить что опять же сократит накладные расходы если мы вспомним про алгоритмы джайна про которые мы говорили и про распределение данных при выборе алгоритма join а то у нас был вот тот самый брат костры школ после которого мы отказываемся от бородка с джой на и переходим к меры joy ну так вот опять же в при исполнении запроса может оказаться что-то количество данных которые мы предсказали она оказалась больше чем промежуточный результат который мы получили в действительности то есть в этом случае разумно было бы откатиться обратно к братка join а потому что наш input оказалась в маленьким что собственно с парке и делает и это оптимизация на опять же контролируется той же самой и тем же самым свойствам sparkasse ель адаптив enable теперь наверное наименее видная для конечного пользователя но тем не менее очень важный на имени видный но очень важный аспект это собственно эффективное исполнение самих операторов здесь пожалуй наибольшее значение этот аспект имеет для olap запросов которые в отличие от yld и затрагивают малое количество колонок но сканирует большое количество данных в том числе сделать фу scan для лапа это окей в этом случае для хорошего перфоманса критически важно эффективная утилизация ресурсов процессор и вообще всех серверов и уже достаточно широко известное по моему уже на этой конференции много про это говорили является вектор на исполнение операторов опять же суть суть векторами исполнения достаточно просто вместо того чтобы обрабатывать данные по строчкам мы их обрабатываем пакетами причем внутри этого пакета данные организованный по столбцам то есть на самом деле векторная обработка операторов не требует каланча той организации структуры хранилище и например распределенный база как кровь за кровь baby они используют строковые хранилища но при этом много операторов у них используют именно векторное исполнении соответственно как только оператор когда оператор получает вот такой векторный пакет операции происходит по колонкам это позволяет избежать накладных расходов виртуальных вызовов каких-то дополнительных свечей и что позволяет компилятору сгенерировать очень оптимальный код и обрабатывать данные с оптимальной утилизации процессора опять же большинство аналитических систем уже давно используют этот подход и пожалуй более продвинутая техника которая еще дальше развивает векторной обработку данных в операторах это jit компиляция запросов суть ее состоит в том что у нас есть некоторый набор операторов и если у нас нет jetta то эти операторы должны быть в некотором смысле дженерик то есть должны обрабатывать данные от любой схемы в любой комбинации как только у нас появился какой-то конкретный запрос и конкретная схема данных мы можем на самом деле произвести специализацию этого кода вот вот этот конкретный запрос и эту конкретную схему данных соответственно такой трюк позволяет опять же убрать больше накладных расходов которые все еще присутствуют при интерпретируемым исполнение и еще больше улучшить характеристики runtime и конечно такой подход имеет и некоторые скажем так опасной стороны потому что компиляция это не бесплатный процесс и нужно следить за тем чтобы опять же время компиляции не превышала время самого запроса но это можно адресовать например смешанным исполнением то есть например стартовать запрос в интерпретируем варианте и запускать в компиляцию в фоне и по мере того как император и будут компилироваться мы будем просто заменять реализацию этих операторов на более оптимизированные вот и на самом деле если вы не ходили вчера на доклад ребят если хауса то вот советую посмотреть этот доклад в записи потому что вот они как раз говорили про джип давайте подытожим вторую часть опять же несмотря на то что мы уже перешли в runtime даже в ран тайме распределение данных имеет большое значение потому что при правильном использовании ключа и сортирования и правильном распределении вы можете эффективно использовать браунинг данных адаптивное исполнении ну тут по большому счету вы на него повлиять не можете на по крайней мере можно проверить что эти оптимизации включены execution тоже он не особо tune ца но при этом с точки зрения разработчиков систем оптимизации постоянно добавляются и выпускается новую верьте в версии поэтому здесь наверное таким советам можно было бы дать именно иметь некоторое расписание для обновления новых версий потому что это справедливо как и для самих баз данных так например для g детей которые постоянно вносят новые возможности для например того же для той же авто векторизации и наверное такой более экстремальный вариант для более авантюрных людей это можно попробовать новые движки исполнения для уже существующих систем например в спарке можно использовать газель или в просто можно использовать велокс который разрабатывает facebook и наверное напоследок хотел бы поделиться таким ну скажем так ощущениям которое кажется есть у многих ребят в нашей команде это то что на первый взгляд все оптимизации про которые я говорил они кажутся сложными для имплементации но при этом на практике уже существует достаточно большое количество библиотек и инструментария который заставляет кирпичики при помощи которых можно строить специализированные системы которые будут заточены под какие-то конкретные нужды и уже имея этот инструментарий на руках вы можете сосредоточиться на каких-то конкретных оптимизациях которые важны для вас при этом в офисе все то что уже известно она достаточно легко интегрируется поэтому по по нашим ощущениям вот за последние несколько лет порог вхождения скажем так вот в область разработки именно баз данных за счет вот этих доступных строй инструментов он был существенно снижен и поэтому мы видим вы такое обилие новых баз к которой наверное все слышали на этом у меня все есть спасибо я думаю что можно переходить к вопросам по всем большая тебе памятный приз от конференции до того как то отвечу на вопрос друзья давайте помочь им спикера у нас 10 минут ну можно 8 вот смотрите на последнем ряду галёрка так скит не спит давай как спикер спикеру спасибо за доклад очень было интересно а можно отмотать на слайд про а с т и реляционные планировщики вот и там упоминается что в apache spark как раз используется реляционный планировщик и он типа эффективный потому что есть широкий набор оптимизации быстро эволюционируют но в следующем слайде как раз же опять упоминается apache spork-и второй пункт говорит что быстрый простой планировщик но не может гарантировать оптимальность то есть получается что он вроде как и хороший но у него есть недостатки ввиду точности здесь имеется ввиду следующее apache спарка ими работает с реляционным планировщиком то есть он представляет запрос в виде дерева реляционных операторов но при этом цикл планирования у него на каждом этапе рассматривает один единственный вариант плана то есть мы применяем правило трансформации безусловно когда мы говорим про более advanced выполнение данный пример такой вот как apache и френки в одной стадии здесь имеется ввиду то что в рамках этой стадии мы можем использовать cost баэс планирование и рассматривать множество планов одновременно поэтому если бы мы объединили эти стадии в одну большую cost bst фазу то тогда мы могли бы действительно найти глобально оптимальный план но на практике это редко работает потому что поиск вот такого глобально оптимального плана будет занимать очень много времени я ответил вопрос да друзья сдаю зададим еще вопросы поднимите руки пожалуйста если пользователи интернета хотят поучаствовать друзья не стесняйтесь нажимайте соответствующий кнопочки вот будет собрать спасибо большое за доклад а подскажите есть ли может быть open source на имплементации распределенных движков куски ели вот как например кальцит да это но можно и сквер прекратить своему хранилищу вот но это можно сделать не для распределенной системы вот для распределенных систем если имплементации какие-то но вот именно наверное реализацию планировщика если вы горите про планировщик то вот система который бы из коробки поддерживала именно работу с распределенными катку от которой моделировал бы распределенные данные нам но мне пока ремень и rich нас не приходит в голову но тем не менее с abs используя подсекал сайт вы можете достаточно в достаточно ограниченное время этот оптимизатор построить вот что чем собственно мы и занимаемся вот это говорит если про планирование если говорить про runtime то достаточно большое количество примитивов для создания уже именно эскель runtime а есть в apache эру вот и за последний год было добавлено на самом деле очень много потому что изначально у них было только можно было сделать только интерпретацию выражением сейчас у них есть даже уже там некоторые готовые операторы что опять же существенно сокращает количество работы которые нужно сделать спасибо еще вопрос друзья отлично тогда подарим себе пять минут тишины алексей посев большая красота"
}