{
  "video_id": "yDSS5MABMi0",
  "channel": "HighLoadChannel",
  "title": "Как мы разместили 200+ дата-сайентистов в кластере K8S / Алексей Кузнецов, Михаил Лепешкин",
  "views": 501,
  "duration": 2317,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "Здравствуйте мы сегодня хотим вам рассказать как при помощи небольших и несложных изменений нам получилось разместить большое количество аналитиков и дата инженерам нашим кластерика 8S но Давайте Сначала мы представимся Меня зовут Кузнецов Алексей Я работаю системным инженером в компании X5 тех и занимаюсь внедрением таких решений как Big Data Ну и сопровождение Здравствуйте коллеги Спасибо что пришли Меня зовут лепешкин Михаил я также являюсь системным инженером на текущий момент работаю в компании НЛМК Но сегодня хотелось бы поделиться опытом который мы приобрели совместно с Алексеем в компании X5 на своем текущем рабочем месте крутим cubernetics выстраиваем коммуникации Ну и все сопутствующая обвязку начнем Алексей да Давай начнем Ну и начнем мы с того как у нас все началось Когда у нас появилось направление в компании Big Data появился кластер хадуп Мы встали перед проблемой А где же размещать нагрузки наших аналитиков и самым простым и первым решением это было использование просто обычных железных серверов с доступом Саша вот все этого решения у нас получалось отсутствовала простая точка входа мониторинг контроль используя ресурс ресурсов масштабировать централизованное управление первой попыткой как-то вмешаться в этот процесс это было попытка прикрутить игру мы для каждого пользователя создавали отдельный слайс и таким образом когда он подключался по ssh его все процессы запускались там слайсы который был как-то ограничен по памяти в целом это помогло потому что уже аналитики не могли алоцировать скажем так всю память на сервере но как-то с другими проблемами это никак не помогало Мы решили поставить Юпитер хаб на тех же самых железных серверах и у нас получилось таким образом простая точка входа и предыдущий групп там также работали потому что мы использовали по модификацию но это не было не масштабируемое и отказа стоящего потому что опять все эти сервера были отдельно друг от друга никак не были связаны друг другом почему же мы все-таки выбрали Питер хаб первая причина и самая Основная это потому что наша аналитики уже использовали Юпитер своих расчетов вторая это то что у нас был положительный опыт развертывания и когда мы развернули на железных серверах нашей в целом аналитики Наши были довольны также это обширная документация И огромное количество плагинов Но к этому решению вы уже сформировали определенные требования Ну и Вот первые четыре требования они довольно таки стандартные это масштабировались отказывать то есть централизованное управление простая точка входа А другие это более такие нужные нам а именно это запуск по испарк в режиме мастер рианда Planet клиент для того чтобы был интерактив такой с работой с кластером а также персональное окружение для коллапсов чтобы не было никакой там помойки контроль за использование ресурсов возможности гарантировать и мониторинг который должен был быть не только со стороны нашего окружения в котором они работают ну и что бы это было со стороны нашего кластера ходу Сначала мы думали все это разместить на нашем докерством но должно образом этот это решение не рассматривали потому что уже у нас компания был кубернете с разными интересными плюшками действительно в нашей компании был развернут уже cubernets и когда коллеги пришли к нам со своими мыслями какими-то изысканиями Мы очень быстро натолкнулись в Гугле на комьюнити очень интересная это комьюнити богато документацией которая позволяет Развернуть как сам kubernets в различных окружениях так и установить внутрь само решение Юпитер хаб тут же очень много административной документации документации по кастомизации решения в общем очень много всего интересного советую если будете разворачивать ознакомиться Ну ознакомившись с эти документацией мы естественно остановились на этом решении мы выбрали его так как у нас уже было подготовлено окружение как сказал Алексей мы разворачивали губернатис кластеры по окружениям у нас были прот дев стейджинг теста в общем все окружение Какие можно было придумать рядом с кластерами мы разворачивали цеф кластеры для предоставления сторожа у нас был настроен на логирование уже на этот момент Мы собирали метрики Ну и самое главное у нас были настроены различные интеграции с внешними системами с которыми работали как раз таки дата инженеры и наши аналитики примечателен был тот факт что развертывании данного решения в кубернете сейчас требования к нам прилетало из коробки какие это требования но естественно это масштабируемость во Вселенной губернатиз от масштабироваться достаточно просто приобретаются сервера проходят какие-то пусконаладочные работы добавляется в кластер мы расширяем лимиты на спейса все привет от масштабировались отказа устойчивость в кубернете смерть части нот она не Влечет деградации полный сервиса там или какого-то влияния не оказывает при смерти части нот нагрузки просто перезапускается в живой части кластера ну и соответственно не оказывает влияние на остальные расчеты естественно здесь присутствует даунтайм на момент перезапуска данных нагрузок но этот для нас был приемлемой при развертывании в cubernetics и публикации на ингрессе мы приобретали единую точку входа то есть наши аналитики получали какое-то and Point URL на который Они заходили могли работать от них уже была закрыта кухня подготовки этих окружений им не нужно было бегать по всей компании искать сервера который закреплены за командой получать доступ в информационной безопасности Ну и какие-то окружения под себя уже настраивать не нужно было люди заходили и начинали максимально работать также к нам прилежал естественно централизованное управление Но со стороны губернации это любой любимый UI которых очень много можно было через консоль управлять теми же по доме со стороны Юпитер хабок нам прилетала админка в которой мы также могли управлять жизненным циклом самого хаба Ну и также Юпитер тетрадок мы могли стартить рестартить топать в каких-то случаях могли в шоу-пода проваливаться и смотреть что происходит непосредственно там далее мы рассмотрели варианты как бы могли развернуть все это дело естественно Первый вариант это ну неестественно первый вариант который мы рассмотрели это выделенные узлы мы заюзали механизм губернатиса тент или рейшн мы маркировали определенные узлы тентами прописывали к ним толераншен на нагрузках Юпитер хаба Ну и тем самым наши нагрузки запускались на выделенных нодах Мы также могли тем же способом прибить ингарск нужно нодам и пускать трафик уже через нужные нам надо следующий вариант который мы рассматривали это выделенный кластер мы могли развертывать губернации по щелчку и соответственно мы могли Развернуть кластер как на железе так и на виртуальных машинах за диплоить туда Юпитер хаб настроить DNS Ну и отдать уже непосредственно заказчику третий вариант это общий кластер привет общага здесь мы приземляем Юпитер хаб как очередной веб-сервис в наш кластер но и с этого момента весь кластер становится доступным на этом варианте Кстати мы и остановились То есть у Питер хаб наших окружениях живет рядом с основными другими нагрузками хотелось бы высокого уровня осветить архитектуру Юпитер хаба Юпитер хаб по своей сути состоит из трех основных частей это обратный прокси который является куском Юпитер хаба он содержит различную он содержит таблицу маршрутизации запросов которая дает ему Юпитер хаб сам Юпитер хаб Ну и конечно же Юпитер хатти тратки То есть под наших аналитиков если мы разворачиваем Юпитер хаб где-то с губернатисе нам нужны еще два компонента это какой-то Клауд провайдер который будет предоставлять нам диски для наших аналитиков и Image registry это то место где мы будем складывать наши образы самого хаба прокси Ну и базовые образы которые подготавливают наши пользователи на этой схеме не отражен один компонент который присутствует в кубернете под названием Image Puller его основной задачей является пул образов которые подготовили пользователи на все ноды кластера Ну и нужно Это для того чтобы сократить время загрузки для наших инженеров решение поставляется в виде простого хельм пакета установка из разряда Next nexdone подключаем просто hermer репозитории с этого момента в кластере у нас плюс-минус Рабочая окружение готово мы посмотрели на это все дело посмотрели на их шаблонизацию от рендер или шаблоны положили статические в наш gitlab посмотрели как собираются их образы в общем начали от них отпачкаться но уже подготавливать подготавливать сами Ну и складывать свое registry прикрутили простейшую сиайку Ну и с этого момента Мы вписались в поддержку так сказать своего какого-то кастомного решения Ну и у нашей кастомизации как раз пойдет речь дальше да Мы помним наши требования и одно из самых главных это было запуск поспайка в режиме мастер янды поймёт клиент иначе нашим аналитикам это решение было бы не интересно здесь такая схема сетевого взаимодействия самого Спарк драйвера с ресурсом менеджером по ней видно что помимо того что Спарк драйвер открывает соединение с ресурсом менеджером и менеджер также и сам ресурс менеджер пытается соединиться с портами соединяется с портами Когда мы это запустили внутри губернете получилось что партии Спарк стали для ресурс-менеджеров недоступны Мы решили использовать кубернатис-сервис и для того чтобы выдавать порты нашим аналитикам Но нам нужно было сделать это как-то автоматически они каждому создавать сервис поэтому мы решили использовать функцию преспон хук самых спавнере для этого мы написали простой функцию которая будет вызывать у нас сервис отпай который находится в образе самого хаба эта функция передали на пресс-паук в целом он работает Просто а перед тем как запустить пользовательский под он выполнит нам сервис от Пай также мы для каждого пода стали создавать уникальный лейбл чтоб как-то он был связан с будущим сервисом на основе имени пользователя все данные изменения происходят главном конфигурационном файте файле Юпитер хаба а именно Юпитер хаб конфликт Пай давайте рассмотрим как у нас работает сервис отпаи работает очень просто мы находим все сервисы которые у нас есть делаем условия проверяем есть ли у нас такой же сервис для пользователя или нет И если его нет то мы его создаем из шаблона находя свободные порты и прописываем уникальный лейбл вначале мы использовали сервис тип Лол баланса после того как аналитик уже получил эти порты он их мог найти в переменных окружениях своего пола Ему надо было их как-то использовать для этого мы или использовали стандартный параметры самого спарка а именно блок менеджмент порт Driver Port ueport и Spark Driver Host где мы отдали ему адрес балансера он нужен для того чтобы ресурс-менеджер знал как соединиться с парк драйвером Также хотелось бы отметить другие параметры необходимые для работы Спарк драйвера если у вас не ванильный ходу по например сборка Words ему необходимо было также передать саму версию ХП то есть для драйвера и для ярмаркечной мастера Также хотелось обратить внимание что мы отдельно прописываем класс файловер провайдера потому что по умолчанию класс который используется fortners не поддерживается ванильный сваркам здесь мы используем обычный который обратился к первому если он активно с ним работает Если он и активно подключается ко второму который будет активный Ну использовать эти параметры наши аналитик смог поднять сессию Спарк с кластером ходу с ярным и уже заниматься аналитикой еще одним нашим требованиям это и хотелка это было были персональные окружения на нашу команду Мы хотели чтобы у них были разные разные окружения самом Юпитер Хабиб по умолчанию используется один общий профайл лист для всех пользователей что нам не нравилось потому что у разных команд есть разные потребности ресурсах и когда мы стали собирать свой базовый образ на основе него наша аналитики создавали свои образы и не все хотели этими образами делиться с другими командами вот так вот выглядят профайл лист Мы видим что вот мы специально передали его переменную это кому profa общем эта переменная которая передается список сложенным словарем где мы видим название того образа который можно запустить какой-то description и лимиты откуда собственно нам выкачать этот образ дальше эту переменную можно просто передать мы снова добавили новых правок Юпитер Hub config а именно Мы создали простую функцию смысл я такой Мы создали словарь Где ключ это группа в актив директоре значение Это уже как раз переменная потом мы находим группы в которых состоит наш пользователь и возвращаем профайл есть зависимости от группы в которой состоит пользователь и нашего словаря Ну и передали эту функцию на профайл лист и во что у нас получилось как мы видим у разных команд появился разные набор образов которым он может пользоваться получилось Действительно красиво пользователи после того как проходили аутентификацию получали разные наборы образов Но к сожалению это не Решало нашего еще одного требования а именно контроль за использованием ресурсов и возможность их гарантировать дело в том что В текущей конфигурации все нагрузки всех команд запускались в одном шаринном спейсе Ну то есть такая общага у нас была там же запускались еще нагрузки самого Юпитер хаба Естественно для нас требованием было раскидать команды по своим каким-то персональным спейсом это нам позволяла гарантировать ресурсы а именно команды расширялись они приобретали серверы они приносили в нашей кластера свои сервера и ждали что эти инвестиции вернуться к ним в виде каких-то гарантированных ресурсов старая конфигурации мы не могли но раскидавнем спейсом мы могли управлять уже ресурсами самого также нам это давало больше изоляцию для команд могли задействовать какие-то Network policy cubernatis Ну и там просто крутить какую-то логику мы могли управлять ресурсами уже уровнем выше мы могли контролировать помимо стандартного процессора памяти могли контролировать количество сервисов количество дисков и в принципе любые сущности которыми оперируют губернатиз Ну и мы могли разделить в таком случае служебные нагрузки самого Юпитер хаба от пользовательских нагрузок как этого добиться мы открыли документацию естественно нашли переключатель который включает данный функционал он его включает но здесь следует сделать оговорку каждый пот рождается действительно в своем спейсе и это name Space уникален Это значит что будет у нас там 100 пользователей это 100 уникальных но нам это естественно не понравилось мы полезли дальше в документацию нашли шаблон по которому генерируется этот Space Ну мы посмотрели что по умолчанию он генерируется из имени на спейса в котором запущен хаб и имени пользователя также мы посмотрели Какие доступны переменные которые можно скормить этому шаблону ну и соответственно вооружившись этим знанием пошли изменять наш первым делом мы накинули ему прав чтобы он создавать на экспрессии в наших кластерах мы прокинули адрес хаба для остальных нагрузок это нужно для служебной для обмена служебной информацией между компонентами хаба Ну и уже так как начали складировать все наши кастомизации Останавливаться не собирались полезли в исходники самого куб спавнера а именно в спавнер пай файл мы нашли место где генерируется сам name Space Ну и с этого момента начали встраивать свою логику мы переиспользовали функцию которую написали профайл листе Мы также генерируем словарь где ставим соответствие AD группе нужный нам Space дальше мы отлавливаем пользователя который проходит аутентификацию смотрим В каких группах он состоит Ну и на основе этих групп возвращаем Space которым нужно запуститься если пользователь не состоит ни в каком нам спейсе возвращается дефолтным Space эту возможность мы оставили Ну там Для различных демонстраций нашего Юпитер хаба вот таким образом это выглядит в губернасе верхней части слайда это выхлоп самой консоли здесь мы видим что участники команды а запускаются в спейсе предназначена для этой команды участники команды б в другом ну и соответственно пользователи CE в данном случае запускается в дефолтном спейсе Ну и ниже возможные визуализация той же самой истории это было бы все не интересно естественно если бы мы не столкнулись с проблемами но и первой проблемой поделится Алексей до с удовольствием и первая проблема с которой столкнулись наши аналитики это проблемы со вскрытием с парка из интерфейса через ссылку в ярле Давай переходили по этой ссылке видели вот такую ошибку Мы решили запустить там внутри нашего кода подцепившись к Порту дизель интерфейса с парком и что вы увидели мы видим что так как у нас продавец запущен в губернатите запрос нам приходит уже от имени какой-то нашей ноды из губернатиз и ему отвечает тем что отдает его 302 редирект снова на ресурс менеджер запрос приходит на ресурс менеджер ресурс менеджер отправляет его Спарк драйверу и 8 таким образом нас просто появилась петля наше решение может скажется неказистом но оно работает работает долго мы решили использовать etc Host внутри самого пользовательского кода Каким образом мы прописали первое значение это фактически ip-адреса ресурс менеджера А дальше мы перечислили все адреса куб спаунера дав его имя одного из наших ресурсов менеджеров для этого мы используем еще одну функцию чтобы этот сельхоз был всегда одинаковый на всех образов и на базовом и на пользу Ну что у нас от этого Получилось мы еще раз запустили СПИДом и видим что теперь запрос приходит от ресурс менеджера и Спарк драйверу и отдает честный редирект на свой парк визуально вот он открылся то есть было 500 теперь вот естественно это было еще момент Да у нас это проблема просто еще раз вернулась Вот и совсем недавно мы подняли второй кластер компании более свежим и получается в новом кластере Да была такая же проблема Мы решили теперь пойти другим путем мы просто добавили еще одну строчку конфигурации в Ян сайта xml внутри самого пользовательского кода чтобы он считал что тот Запрос который ему придет от имени ресурс менеджера от старого кластера был валидным и таким образом мы добавив эту строчку нас снова работает и если добавлять 5 6 там 7 кластер мы просто добавим вот такую строчку в базовый образ естественно эти сетевые Приключения были не единственными След через какое-то время А именно когда количество наших пользователей перевалило за сотню к нам начали сыпаться странные обращения а именно это непредсказуемо падающие расчеты странные разрывы соединений Но и вся вот эта магия которая указывала в принципе носить как-то намекала мы стали разматывать эту ситуацию мы вспомнили что для простоты мы стали использовать губернати сервис балансер открыли схему и что мы увидели во-первых функционал балансера нам предоставляет решение металл б Это куберовый балансировщик в нашем окружении он работает два режиме суть его работы она схожа с работой типа лифт то есть по сути в кластеры выбирается нода Лидер ей присваивается виртуальной и весь трафик идет через это виртуал что мы увидели мы увидели что на ноги может присутствовать не один Virtual IP потому что как я говорил раньше мы Разместили в общаге Юпитер хаб мы предоставляли уже сервисы и какие-то и уже у нас был набор виртуальных IP в этом кластере следующий момент virtualip при различных условиях мог блуждать по кластеру то есть компонент Metal b если там где-то запнулся или упал адрес переехал соединение разорвалось Ну и Неприятный момент который мы также увидели что трафик до пода может идти по оверлейной сети кластера Это значит что он может идти совершенно в другую часть кластера не в той ноги где Виртуал совершенно в противоположном конце это добавляет новые какие-то моменты дебага это новые задержки в конечном итоге для нас самих стало страшно неприятно Мы решили выкинуть эту абстракцию и затащили новую но попроще мы стали использовать тип нот порт этот тип сервиса открывает порт на ноде и позволяет Достучаться до подачи через айпишник непосредственно ноды на которые он запущен тем самым мы избавляемся от задержек хопа где багов ненужных нам добираемся до подача по кратчайшему пути Ну и Казалось бы этот должно быть должно решить нашу проблему как мы решили ее Мы переписали полностью свой сервис отпай мы выкинули все куски которые были связаны с использованием каких-то тимплейтов бинарей Coop ctl Ну и прочего не интересного мусора мы стали работать с губернате Софии напрямую подсмотрели кстати в исходниках Юпитер хаба наш сервис Новый сервис стал состоять из трех кусков на Первом этапов на первом этапе мы создаем сервис болванку прописываем необходимый тип мы прописываем необходимый селектор то есть чтобы этот сервис у нас смачился с нужным нам кодом Ну и задаем определенное количество портов нот портов Это необходимо для того чтобы кубернация динамическим образом выдал эти порты на следующем шаге Мы стучимся в созданный сервис Ну и получаем выгребаем оттуда полученные нот порты и используем их на третьем шаге Мы побочно в сервисе приравниваем все значения к полученным от портам но там поблочно это позволяет нам правильно пробрасывать переменное окружение подано и строить уже с парк сессии Ну и для того чтобы Достучаться до входа через айпишник ноды мы стали пробрасывать айпишник этой ноды также в переменное окружение спарка мы стали использовать modify под hook спаунера Ну и выгребали информацию о айпишнике и скубер найти сапи Мы из метаданных запускаемого подобрали айпишник пробрасывали в пот Ну и с этого момента уже можно было полноценно строить спарксессию еще одно интересной проблемой для нас было перенос пользовательских каких-то данных между нами спейсами то есть мы сделали красиво мы раскидали всех по нам спейсам вроде бы все классно но к этому моменту у нас уже где-то за 150 наверное перевалило пользователи у них уже были какие-то наработки это все лежало под ногами упада то есть на дисках которые мы предоставляли но и не все хотели естественно расставаться со своими наработками в целом Мы всегда рекомендуем наработки хранить в гите чтобы это всегда можно было достать Ну и всегда сами считаем точку правда чтобы решить эту возникшую проблему мы написали еще одну функцию которая работает также с губернати сапи на вход получает она имя пользователя и новый namespace дальше выгребает информацию о старом диске в старом спейсе выставляет определенную политику для диска в данном случае ретейн это необходимо для того чтобы в середине процесса если что-то пойдет не так наш диск не удалился ну и соответственно мы удаляем старый заявку в старом Space на основе полученной на предыдущих шагах метаинформации мы создаем в новом спейсе новую заявку на диск зачищаем метаинформацию самом диске Но и вишенкой на торте старом нам спейсе мы удаляем сервис который уже не нужен вся картина была бы неинтересна если был не реализован мониторинг со стороны губернации это было реализовать достаточно просто как я говорил у нас уже был развернут стек мониторинга мы использовали прометеос у нас уже была развернута графа на Таким образом мы просто набросали простейшие панельки где можно было посмотреть память процессор какой-то сетевую нагрузку Ну а также естественно диск то есть статус самого диска но его загруженность на основе этих данных можно выстраивать алертинг о мониторинге со стороны запросы и как они влияют на нашу платформу сам мы используем встроенный функционал спарка а именно возможность его отправлять метрики на какой-то сборщик тут мы переиспользуемся другую функцию чтобы metrics Property которым у нас будет прописан этот сборщик был абсолютно на всех образах Независимости наш базовый или какой-то пользовательский здесь давайте как источник можно использовать Прометей несколько таких интересных графиков а именно сколько пользователь аналитик закамметил памяти и сколько фактически он используется суммируется Это все из всех экзекуторов которые у него запущены в его задача и рядом график аналогичный только непосредственно для спагрегора Таким образом мы можем составлять списки таких пользователей которые просто сжигают наши ресурсы и не хватает другим Это очень полезно Ну и другие метрики есть парка геометрикс мы можем смотреть какую-то нагрузку на хдф с этого данного приложения сколько записал сколько он прочитал Также хотелось бы отметить что когда мы данное решение внедряли то мы сделали простой чатик в котором наша аналитики подключились и мы как-то помогали перейти на это решение сейчас это потом чатике больше 200 участников и они уже помогают друг другу что нас очень радует потому что они не отнимают наше время также это помогает нам выстраивать коммуникации и они стали предлагать также свои решения например те два графика по поводу памяти это как раз к нам помогли наши аналитики за что мобильное Спасибо а что хотелось бы сказать заключение мы видим четыре требования верхних они такие стандартные это то что мы получили просто из коробки использовали решение Юпитер хабзира и ниже 4 требования которые мы показали как мы реализовали свое видение Вот и Мы надеемся что это интересно И как-то вам поможет создавать свое рабочее окружение у себя в компаниях вопросы Спасибо большое поднимайте руки те кто смотрит онлайн трансляцию Пишите в чат тут вопрос тоже читаем Так давайте первый вопрос Здравствуйте А спасибо за доклад большой был реально очень интересно вопрос очень простой когда планировали архитектуру системы рассматривали ли ноутбук вообще как какую-то альтернативу Если да то почему не подошло мы как альтернатив почти ничего не рассматривали у нас был еще запилен который идет в стандартной коробке ХП которым некоторые аналитики у нас постарались попытались пользоваться им это не зашло и всё и мы альтернатив главным образом не рассматривали Потому что когда они работали на отдельно выделенных серверах они пользовались Юпитером им это было удобно все к нам приходили в принципе с Юпитером уже спасибо спасибо выбор был в принципе как бы достаточно убирать будет подарочек потом за него скажете так еще какие-то вопросы есть Давайте вот второй ряд человек Красная кофте У меня просто по поводу чата вот с пользователями это откуда идея пришла создать чат чтобы люди сами общались друг с другом Это же супер экономит время саппорте получается вы хотели разрекламировать наше решение просто в первую очередь чтобы он стал большим и они все-таки стали пользоваться а переехали с этих опнот и мы хотели забрать эти сервера себе Спасибо за доклад вопрос У каждого скорее всего разные версии зависимости которые не используют они постоянно прыгают туда-сюда Они каждый раз вынуждены собирать Новый образ а смотрите во-первых можно выкладывать зависимости внутри hdfs видите пархива которую можно пользоваться второе Да они могут собирать свой образ но также они могут на время А делать это в своем внутри Роберт и делать пипы стал тиролюзер где будет нужный модуль сохраняться в хомяк грубо говоря себе насчет по факту там Юпитер хаб запущен под капотом тут тоже это ряд сейчас по бабкам Ну в этом направлении Мы работаем модели вообще какая у нас так как раздается по командам то в принципе на Ну как на ресурсы команды у нас весь кластер в принципе можно разрезать на ноты команд То есть фактически они запускает там в своем спейсе который они билет просто как ресурсы кубера правильно Да Прикольно спасибо три вопроса насчет зависимости хотел еще добавить Ну мы собираем образы сами то есть на начальном этапе мы какие-то куски конфиги сам баре там все что связано с бигдатой туда складываем Ну то есть чтобы было полностью и дальше они отчковываются этих образов Ну и в принципе что хотите Почему не в конфигером конфликт Map имеется ввиду конфиги амбаре засунуть в куберовский конфиг моб или у вас не часто меняется список вот сколько я работал он по моему один Так и остается Нет они меняются Просто каждый раз когда менять список нот вам надо будет триггерить пересборку всех образов всех пользователей происходит работает так он всегда выкачивает последнюю версию Да а кастомным образом нас идут фролом от нашего базового Ну так вам средерить надо все сборки Да и нам надо стригили все сборки Это хороший вопрос Ну вот замечательный вопрос Вы мы об этом просто не думали честно зато мы сам Юпитер хаб конфиг пай вытащили в конфиг мап чтобы не пересыграть образ хаба постоянно Да кстати хорошая можно сделать шестой ряд если касательно самого Юпитер хаба И решение то у него есть класс настройка которая позволяет по истечении тайм-аута выставленного там администратором он принудительном порядке гасит плоды Юпитер тетрадок Но вот мы используем у нас она 8 часов у нас работает на некоторые аналитики просто запустили сессию и ушли но тут мы тоже У нас не бывает Sport сессии из кластером ходу который старше скажем так был в ней мы так и сяк придем вот тоже другая история и всё уходят поэтому мы их Чистим у нас также есть система чисток кодов и сервисов мы ходим в API Юпитер хаба проверяем последних активность и если их активность была скажем больше 3 месяцев И всех вместе Спасибо а потом он возвращается говорит Где мои Поппи и у него будет просто он сделал она запустится просто там будет вкусненько Так ладно Еще вопросы есть Окей в целом можно этом заканчивать"
}