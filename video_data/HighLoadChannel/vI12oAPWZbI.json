{
  "video_id": "vI12oAPWZbI",
  "channel": "HighLoadChannel",
  "title": "Высокие нагрузки в индустриальном интернете вещей / Евгений Потапов (ITSumma)",
  "views": 478,
  "duration": 2112,
  "published": "2019-05-14T14:32:41-07:00",
  "text": "мы существуем 10 лет мы занимали раньше разработки поддержкой сыгранных сайтов затем мы занимались 7 поддержкой отказоустойчивостью потом мы стали заниматься devops а мои разработки всяких сложных структур а потом к нам не пришли клиенты говорят ребята вот вы знаете мы снимаем информацию с датчиков множеству датчиков и хотели бы сделать так чтобы система не падала потому что разным большая нагрузка а нам нужно построить так что она не подавала но нужно построить так чтобы на масштабировались и нам нужно это очень критику потому что данные которые идут они идут со станков и нам важно понимать что данные приходят и важно понимать сломался вот для тех кто связан с лотом disclaimer вещи будут очень базовые и больше про обработку данных тем про железо вот потому что на самом деле вообще что такое интернет вещей которые все слышали ну там концепция сети объединение устройств которые прицепные к интернету почему это highload потому что эти устройства там вот мне буквально вчера товарищ рассказывал как взял некий умный чайник котором можно включать с телефонной который тоже чат пингует в интернет но на самом деле если посмотреть есть там все общеизвестные применения которых слышали там умной розетки лампочки включаются все это то что на слуху колонки так далее это на самом деле очень малая часть рынка интернета вещей на встрече рынок интернета вещей это интернет вещей в промышленности фактически существует огромное количество сфер около промышленных где существует не знаю датчики на станках датчики в полях которые измеряют влажность полив рост рост растений и так далее существует там классический пример для промышленной метро-то вещей это ветряные мельницы в которые расставлены где-то по большому полю у них стоит датчик этот куча датчиков которые смотрят здоровья там ротора 9 на мельнице всегда точатся военную систему там мониторится и и дальше путем там умело и я и предсказывается аномальное поведение ну и так далее и так далее и так далее и вот здесь порядка там 80 процентов рынка интернета вещей на самом деле существует и это действительно полезное применение лампочку включили выключили для нас забыли а эта штука по сути по сути позволяет видоизменить бизнес целом вообще откуда это пошло от существует некий термин 4 in сталина революции индустрии 40 звучит всегда там очень пафосно непонятно но суть проста в том что фактически путем внедрения цифровых технологий сокращается этом сокращается простоев в dota aware оборудование получается мониторинг производства получается там мониторинг здоровья wohl сквере получается мониторинг перебоев электроэнергии там и каких-то еще штук она системная цель всего этого обеспечить оптимизации бизнеса путем изменения цифра цифрового видоизменить производства значит сесть страшные слова а про цифровой трансформации вот я не знаю слышал наверное про программа про экономика круто звучит на самом деле в том ну то есть для меня это пьер 1 штука которая а кто здесь суровые техники и она сама территория техник но я могу говорить про пра-пра-пра бизнес уровне могу не говорить ну давайте я быстро расскажу так чтоб не надеетесь как бы потом потом все на бету пишем вот короче смысл в чем есть программа цифра экономика программа цифра экономика говорит о том что сейчас фактически там не знаю раньше эти был неким придатком любого большого бизнеса любого вашего производства и решал чисто этичные цели сейчас задача идти в том чтобы изменить оффлайновые проблему которой раньше было непонятно как решить ну условно говоря там есть цепочка производства и раньше бочку производства планировали несколько людей аналитиков которые в плане говорят мы предполагаем что в марте мы произведем столько продукции исходя из того что предлагает что в марте нужно правительство к той продукции нужно закупить только то продукции нужно чтобы эта продукция значит на заводе там цепочка из танков была обработана с каким то определенным количеством и так далее с рук выясняется что марте потребовалось два раза больше продукции то и во первых надо где-то понять где закупать снова потом надо взять короче и вывернуть станки эти до изнанки чтобы они все это выпустили а потом надеяться что она выпуститься без брака и нормально соответственно теперь идея в том что выбил вместо этого получаем некую полную цепочку контролю производства мы знаем там потребление за последние два года исходя из потребление за два года мы четко можем предсказать когда и сколько будет потребленной продукции нужном словно мы знаем что там по статистическим данным исходя из все что было в прошлом мать потребили столько в позапрошлом marty party убили столько значит будущем марте по трибет мир настолько же исходя из этого мы знаем что там нам нужно купить вот столько продукции мы знаем смоделировал всю цепочку что нам нужно выкрутить станки именно вот на такое количество чтобы это сделать если продукция кажется хуже всего и стану teaser он там за за мониторится ну и так далее и в целом вместо того чтобы где-то была ручной контроль мы теперь путем оцифровки всех всех этапов это производство мы можем понять ну как нам дальше жить но но как это все будет выглядеть внутри как бы то есть смысл в чем существует вообще по сути два типа систем связанных с индустриальным при этом вещей один который вот мы часто видим около около человеческий это связан с непосредственным управлением системами там старые скале систему и так далее друг и и и системы которая занимается непосредственно доставки информации с датчиков но сложно там с классический пример это там много где сейчас будет это счетчики которые отправляют жкх информации сами текущих показаниях ну то есть вот есть не кидайте не книг и показания датчика она там просто какое-то время снимается все хорошо от не сильно много данных существует совсем другие вещи где этих датчиков там сотни на каждом станке и станков может быть десятки сотни тоже я не шлют в каждую секунду эти данные откуда идут и соответственно пизано датчиков получить эти данные надо собрать эти данные на таким-то образом агрегировать эти данные надо проанализировать дальше принят на основании в какие-то решения я хочу пройтись по каждому этапу о том как это происходит в о системах связанных с производствами там где эти данные используются для анализа и принятия решений первый вопрос собственно в том что там мы взяли какие-то данные короче с разных мест мы как-то их перемешали и куда-то его их сложили потери некую аналитику и как мы как у них возьмем у нас есть информация значит с разных станков носить информация с разных вязать связанный с scada-системы так далее и мы это должны как-то сгруппировать и с этим как-то жить какая специфика чаще всего у нас эти данные находится где-то на производстве и там уже подвал это может быть какой-то отдаленный регион там очень хреновый интернета очень много данных и данный тег потери при этом не хочется поэтому и придумали что она там они о конечных точках собирается неких об этот хаб это фактически там это интересная штука мы есть ну фактах об это фактически там некий маленький котеночек который собирает данные о существует множество крутых компании которые производят шлюзы которые эти данные собирают ну и дальше потом присылают что интересно мы потом последнее время видели низко раз применение разбили пи и там более промышленном более промышленного бибигона для сборки данных цехах чтоб пойти дальше то есть фактически у нас есть некие типа компьютер который собирает данные и дальше должен передавать идет поток cms телеметрии с непосредственно с датчиков идет поток телеметрии с данных со склада системы с агрегировать сократ придется придется в 1-ой . ануш тут пусть мы это сложим дальше продукты например например ходу это надо как-то собрать и обработать как это типично обрабатывается существует ну в нашем случае котором мы использовали существует такая прикольная штука называется apache некий apache не fi это продукт очень интересная вещь это если посмотреть на него значит со стороны то это некий голый продукт в помощью которого можно нарисовав свернув кубики значит и составит стрелочки пустить некие потоки данных пугаю при этом звучит довольно странно то есть мы берем там условно некий сервер очередей который стоит на нашем хобби в нашем производстве из него берем поток данных этот поток данных значит берем обрабатываем куда дальше все это происходит в графиках все это происходит красиво идут циферки звучит странно но фишка в том что не fable разработана агентством национальной безопасности использовался где-то у них америке использовался где-то у них значит там в закрытом виде потом почему-то они решили его open source но потом его купил карту дворцы и передал там поражается право сопровождать в концерте есть 2 2 2 2 части как бы apache не fi есть apache minifee и который собственно ставится куда-нибудь надеть и apache мифе который уже собирает данные скейтов в единую систему то есть это все мы говорим отчасти которая собственно со сборкой данных по как не обработкой то есть у нас на наш хавчик ставится minifee которые маленькие быстренько приложения которое может собрать данные у тебя внутри есть некий там региональные серверы легче общих об который собирает данные со всех мифе и придает куда дальше там в кто связан с big data и поднимите руки пожалуйста окей круто ну то есть потом складывается куда-то в ряд хранилище там в хранилище данных должны постоянно хранится хранилище где там какая-то там series где собирается свежие данные чтобы смотреть на то что происходит с датчиками ну и так далее другие системы анализа после того как мы данные собрались разных кусочков фишка них и в чем фишка не в том что там условно хамона служить много разных источников данных у нас может быть много и разных а нам надо как то эти данные собирать если мы будем писать софт каждого из каждой из этих штук мы запаримся потому что но разные протоколы разные форматы так далее в мифе существует огромное количество при подготовленных форматов ввода данных которые можно быстро прототипировать и при этом опустить дальше работать при этом мифе это такая штука которая ну работает под очень высокими нагрузками сохраняя работу в боях может мониторить сама себя может легко масштабироваться ну и поскольку там есть вопрос из обеспечения безопасности за час . не то насколько это просто но security там тоже довольно неплохой поскольку кругу nb и дальше hutton works данные мы собрали в мифе с разных местом включает у нас есть знакомые которые среди прочего собирают у них помимо информации чисто с датчиков у них есть информация с в excel koch которая объединяется с информацией из датчиков идет дальше мы объединили в мифе нам надо когда целует что дальше мы могли с этим работать фактически сейчас индустриальным стандартом стала пачка вко которая фактически на себя берет роль там шины данных и и система очередей для сбора информации там для тех кто почему-то не знает кафка этом это фактически система не очередей система никого коммент logo который собирает информацию которая мне записанной может там у повторно проиграть на распределенная на profits ированный отказоустойчивого не есть аппликация она очень крутая у них высокая пропускная способность она сохраняет стабильную производительность для больших объемов данных ну и так далее то есть дальше на схеме нас как идет у нас есть некие некий железки из которых мы собрали данные в них и onefit опасалась значит в кафку для того чтобы туда уже наше приложение которые будут заниматься обработкой смогли это все обработать и куда переложить где мы будем уже дальше это анализировать теперь мы приходим к самому интересному и одновременно не знает самому нудному для конечных исполнителей как я узнал смотрите у нас есть некий поток данных поток данных перед тем как сложить в куда-то в хранилище но не в слабо здесь подходит в некое хранилище мы должны каким-то образом выработать обработать нам нужно с помощью чего то есть ну для тех кто в передать это понятно известный термин для тех кто не в передать и зачем существует прямо набор практик обработки приходящих данных у вас есть некий поток данных вам нужны сгруппировать вам нужно каким-то образом обработать вам нужно отсеять лишнее и дальше положить это все куда нужно там в концепции теле вы это значит сначала трансформируете в нужном вид и складываете в концепции ялте его это сначала этель и и экстракт runs формула то есть но выгрузили обработали загрузили а елси типа экстракт latrons форму то есть вы теперь ты взяли в каком ты виде сначала сложили а потом уже обработали нас их чем когда мы говорим о какой-то простой но относительно задачи обработки потока данных ну там у нас на сплетают какие-то информации в очередь от пользователей это все довольно простая задача если мы говорим о том что нас проходит порядка например 10 терабайт в уже какой-то короткий промежуток времени которыми должны обрабатывать тут возникает какой вопрос как мы будем значит таки 10 работ обрабатывается нормально то есть во первых если у нас будет скриптик у нас будут вопросы связанные с тем что там скрипте купол как он возьмет и оживет и той же точки где он обрабатывал если данных любит много как этому скриптик у нужно масштабироваться если там сервер на котором скриптик упадет как мы заработаем на другом сервере как мы установится в той же точке на и так далее всего для этого сейчас появилась раз систем которая ну помогает этим жить если говорить ну как бы если смотреть по ст идеологически наработаете систем здесь конкретно картинкой за патч с парк этот смысл какие то что у вас есть некий кластер экзекуторов задач которые на которой раскидывается собственно задача трансформации потока данных если говорить о том что сейчас есть но вот на что мы смотрим используем то есть почти spark streaming и я почти нг spark streaming то есть перед тем как нужен поглядят об обработке смотрите есть есть поток данных от поток данных должен каким-то образом прийти собственно ваших рабочих он идет либо там потоком стримом то есть вот данные идут и идут либо его можно принимать неким бочками короткими патчами которые там получается некий псевдо streaming то есть у вас пришел патч данных о его обработали отдали шел базе данных и обработали отдали короче spark эта система spark streaming система которая работает на микро ботинки позволяет работать и в набат a fling это чисто streaming у него есть свои преимущества связанная с этим и в целом frank гораздо круче но мы его еще пока не использовали фишка spark всем fling это чистая система для ну для для в этих задач от информации спарк на самом деле такая обложка поверх ходов было ну как обложка system power ходу по и других источников данных который позволяет эффективно быстро произвести кайт анализ спарку прикрутили spark streaming систему которая позволяет анализировать входящий поток информации сам по себе спарка это некий как сказать ну и для тех кто 5 же не знает некая система которая просто поверить данных и там позволяет анализировать эти данные из pdf с в ходу без хранилищем данных вы можете с помощью sparky проанализировать есть у вас там не знаю cs вышка вы можете и проанализировать ну так далее так далее так далее насколько вы обычно этих штуках но задача там данных кто нужно анализировать десятки там сотни терабайт а вот люди придумали что можно эти задачи раскидывать на кластер задача соответственно там исполнять соответственно тут же пришла в голову идея что если нас идет поток данных там и поток данных также можем раскидывать на набор кластеров и там раскидывается только набор кластеров а вот исполнять соответственно если у нас там упадет какой-то элемент с кластером и продолжим ввод другом месте если у нас будет там повышенная нагрузка мы добавим докинем и червячков и не будем думать о том как нам на штат скриптик если мы не писали скрипке этого все балансировать ну и так далее в это всего есть свой отдельный геморрой которое заключается в том что например там не знаем ни сейчас новая шутка что главная проблема передачи в том что она большая короче потому что если у вас есть 10 терабайт неправильно обработаны hotel im данных которые как потом выяснилось что вы сложили как я и потом выяснилось например там они обрабатывались неправильно про скидан они не столь с тем временем преобразовывались неверные так далее то у вас идет какое-то защитное время на то чтобы понять что эти данные не актуальны если они тоже ночи карте мониторить на актуальность нам на правильность а во вторых если вы решите их заново перезалить то вам заново нужно перезаливать 10 работ данных снова их обрабатывать я так просто но чисто вы действительно это большая долгая задачи поэтому она с одной стороны круто и интересно другой стороны как бы вот надо быть готовым к вещам что я вы как бы вот запустили и ждет теперь следующий неделю что она вам поможет каким-то образом оказалось что скриптик там который должен был обработать опять работал неправильно ну блин как бы заново запустили и ждем поэтому кстати я буквально недавно узнал что люди которые работают big дате занимается телеме очень многие не любят свою работу потому что ну вот книг знаком прикрыл человек которого спросили чем-то занимаешься а он говорит я вот звук в передать ее хочу уволиться м вот почему потому что я последние два месяца занимаюсь ним что прикладывать джонсона место другое вот поэтому этот авто все авто по то что задача немножко нужно то есть вы пишете этот теле вы его запускаете ждете а вас еще кстати при этом данные с то цена станков системой вы должны с этими данными как-то быстро обращаться вот специфики много и как бы хотелось бы сказать как с этим всем жить но жить с этим сложно то есть какое-то универсальное решение нет нужно быть готовым к этому то есть условно очень интересный вопрос буквально на днях был хорошо вот у нас есть пром кластер который мы придумали там вот используя все эти штуки там давайте пошлём из них iv кафку мы шлём из сказки в spark streaming потом и это складываем какие-то базы где мы это как-то используем но как бы а вот все дела переделать как сделать поэтому с этим будет работать и это отдельный вопрос потому что он удивил поможет прогнать каком-то небольшом ему во первых нужно взять этот вести так себе у нас был вопрос по то что там собрали некое окружении вопрос кластере цифра же никогда не видев пластика пути разработчики которые я раньше этим не были связаны только того же завода и сказали что ребята мы хотим локально поднять как на локальном и понятие можем сделать вот и пришлось но там есть долгий долгий процесс взаимодействия с разрабами чтобы висит что мало того что ребята с локальным будут проблемы помощью нужно привыкнуть потому что там случае каких-то ошибок вам придется либо смириться с часть того что данные будут потеряны как-то или не из-за коробки но если вам critical иметь данные свежие ну условно там датчик температуры может в каток однако на которой надо среагировать именно с точки зрения того что там прибежать это поправить если вам будет температуру за вчера это уже короче но никак не не крут они никому не нужны если нужно собрать информацию нам как год температура была это окей но если у вас есть специальный человек который если в холодильнике температуры повышается до плюс пяти и тогда там корочка которая лежит охлажденной в этом холодильнике значит с ними открыто опасность быть надо прийти приближать если вам пришла информация про то что вас вчера был у холодильнике плюс 5 то значит на ситуация уже такая горочка соединить он не поможешь вот соответственно процесс нудный процесс связан с большим набором ошибок процесс связан с тем что как бы часто приходится ждать смотрите же получится вот а переходя к они не данных есть некая штука которая называется линда архитектура такая теория о том что поскольку у нас данных там прет много с разных источников и очень сильно нам надо каким-то образом сделать так чтобы с одной стороны мы видели свежие данные и собирали эти данные люди могли видеть эти данные зубы страны нам нужно хранить данные за все время соответственно там вели довольно очевидны для ребят которые работают в обе термин для архитектуры но там в часто-часто пеппа не услышать можно не понять фактически у нас есть некий поток данных мы разбиваем на batch уровень где данные хранятся долго и обрабатывается там сложно и некий скоростной уровень условно уровень там каширование где данные хранятся быстро для доступа гитлера фактически с того что мы видели там какой-то например часто систему на радио сейчас системы tarantul и почему ты радиста почему тарантул потому что из того что мы сейчас работали это большие около год свои предприятия большой около глаз собой предприятие то скорее всего требования к избеганию рисков в сам ценности и соответственно желание использовать вот это кстати очень крутая тема серьезно то есть с программой там цифра экономика пошла значит работать всех этих больших компаний на условно снег а поскольку buy мы живем 2018 году и у нас есть санкции у нас как бы есть риск зарубежного winder лака все эти большие компании они говорят мы больше не хотим использовать большие старые enterprise 2 кромочные продукты мы хотим взять и забрать и запад source и поэтому использование panzar со но фактически очень сильно увеличивается и блин был доклад буквально месяц назад на devops конфи я там показывал огромный огромный огромный стек технологий связанных с датой и все это около там защитные чести них это около по царской штуки которые можно взять и использовать это круто потому что ну раньше там условно стрелка дни коробка от оракула к чего-то еще и вот живите с ней теперь с одной стороны это конечно стало больше маленьких кубиков которые нужно использовать другой стороны эти маленькие кубики открытое их можно представлять на них можно ну условно говоря вот я весь этот стек но начинают омс не fi перепиши чего в кафку пишущего в спарке пишущего в например pdf с оливку не гриппом можно собрать у себя на компьютере ну то есть мы для себя там где шутки спаивали датчики которые на которые ставили ставили на orange pi вы доставили minifee у нас есть это на хабре сходите в том потому рассказать с мини фильме отослали в мифе и с ними мы отослали как раз в кафку потом стали spark ну и так далее и это все можно собрать и себя они покупают и не беря неких триалов не покупать никаких тайну сложных продуктов посмотреть как это работает и в принципе с этими жителями знаешь хотите за мониторе до можете за мониторить дома таким образом оной да кстати почему мы вошли в штуку riot и почему рассказывай мне про управление непосредственно датчиками а про мониторинг потому что вы с нами и тренируемся это время занимались ну то есть раньше в интернете очки от ferre мониторим железо ну пытаемся мониторить вот соответственно есть петли есть башло верно вот куда-то надо складывать для тех кто не в биг дотянут есть несколько важных моментов есть в принципе в концепции там беда ты мы можем подцепить мэром понимать условные даже просто по сгрыз ее там какие-то еще привычные раз пт-шки потому что с точки зрения большого охранения мы хотим хранить всю информацию за кучу времени мы хотим например там есть есть концепции до долей как где мы по сути должны хранить всю информацию которая к нам поступает просто как есть что потом когда-нибудь достать этот баттл их должен быть бесконечным безгранично инете куча времени во времени но и так далее поэтому там speedlight любая система где к данным можно обратиться быстро и деньги их немного оба чего r24 мы рассматриваем что на заданный скорее всего будет много их будет и будут они расти и растения будут но постоянно при этом скорее всего старые мы выкинуть не захотим а это означает что нам нужны базы которые могут стелется горизонтально причем могут стелется горизонтально скорее всего так чтобы это было не привязана вложения auditing раз начинаем говорить о базах связанных со лапам в мы мы видели решение на кассандре мы здесь и нет я написала патчем по лампочка iv но это фактически имею в виду дфс куда складываются в определенных форматах файлики с данными и соответственно эти фрески лиц и горизонтальных остановки или горизонтально и учился много людей был офигенный доклад ребята снимка соседнем зале про использование green to move тинькове это том прикольную крутая база построенная на пост грехи которая позволяет как раз стелется горизонтально то есть у вас есть несколько серваков вам нужно больше данных вы можете еще данных добить вот соответственно какая здесь есть специфика если вы складываете какие-то базы типа того же там green mama или вкладывать и five вас есть вот вот серьезные вопросы там например способности девочки транзакции по этим базам там что-то лапани лтп и с этим приходится жить с этим приходится как-то думать соответственно если мы говорим но мы мы взяли данные в мифе мы загнали их кафку мы загнали их после этого в spark после этого мы разложили их по базам кишки при среднем делать нам нужны разработчики которые будут писать приложение фактически приложении есть трех видов и прикольный слайд у нас есть приложение которые связаны с трансформацией и обработкой данных которые пришли нута которые располагаются в условном спарки у нас есть приложение которое связанный с работой с анализом данных ну то есть нам нужно посмотреть на данные по за последние два месяца по каким-то метрикам и решить что будет дальше или например решить что будет в насколько аномальное текущее поведение есть приложение которое уже вводят непосредственно ли аналитику информацию система принятия системы поддержки принятия решений для конечных людей где будет понятно как это будет дальше работать ну то есть это могут быть либо типа привычная нам систему мониторинга какие-то где вместо тех же серверов идут данные с датчиков либо это могут быть системы которые больше информируют о состоянии например здоровье текущего вот + отдельная тема которой мы не касались это система с обратной связью ну там есть офигенная тема про scada-системы в иране когда был стакснет там была некая система где данные с турбин на иранских а с neo из собирались в некую scada систем универсальную декорированный сад рубин и эта система была обратная связь соответственно mb американская сумела с помощью там какого-то коррупции коррумпирована сотрудника с флешкой поставить поставить некий вирус который работал как практики для этой скат и соответственно они в течение двух месяцев на самом деле увеличивали оборота турбин данные при этом году передавались в том что оборот такие же какие были если вы не там разом это врубили все было слышали шум подумали что происходит какая-то беда а так вот они и значит потихонечку подкручивали подключил подключили пока турбинного иски не достигли критических значений все поломалась потом пришел касперский я нашел так сенатского смог его выключить и потом случилось с касперским в америке вот но смысл того чтобы эта байка про то что что может быть с системами управления но по сути там есть есть есть приложение связанные с управлением обратной связи с которыми мы пока еще не работаем вот , что мы там говорим где идеи инфраструктурный располагается если это и телятам в том что мы строили если это этель то это spark of link которые работают у нас например чаще всего подчиненности ну потому что надо их потому что берется им починить ближе к почти q чем тот же самый кубик если это приложение связанные с анализом данных то это чаще всего какие-то ссоры сбитые сервисы которые закидывается кабинетик в кубик и оттуда работают но и приложение политики но все складывается либо standalone если они standalone либо в тот же купить тот приложением аналитиками виду некий системы поддержки принятия решений в чем специфика разработке предложений приложений подсеть штуки ну я то что я сказал уже форме создания девелоперской среды вам нужен большой поток данных о нужно как-то с этим жить соответственно вам ну никакого локально больше не будет и даже здесь средой сложно потому что где взять никита 100 поток данных для дев среды здесь вы можете либо это слать там параллельный поток вас вторую систему либо придумать как генерить этот поток ну и так далее очень сложно откатиться потому что вы выкатили код который трансформирует дан или который вкладывает и откатиться назад уже становится непонятно как сложно сложно тестировать потому что вы не знаете как правильно скорее всего но особенно на первых этапах то есть вы преобразовали данные это очень похожи на системы бизнес-аналитики у нас работали с клиентом одним которые строили похоже систему и фишка была в том что предыдущих система аналитики которая собирала данные с приложение процесс и складывала как выяснилось в течение года сказал совершенно не те данные но поскольку из этих данных food объединяются даже бортики тоо когда человек смотрит на нас же борт и которые более-менее что вменяемая пишут наверно думает что это ну это полезно и важной информации в течение года люди руководствуясь системы аналитики в которые были неправильные даже борды не жили здесь примерно та же самая ситуация мы не на нем не можем гарантированно выставить assert на то что данные пошли нити вот с этим приходится жить с этим приходится мучиться думать о том как организовать качество данных но и так далее вот собственно про сами системы аналитики мы разделяем но это уже ближе к не только к лоту это ближе щук система мона лиза но в обычных данных если мы хотим что-то быстро проанализировать мы связали apache запилена и я патчи питер зависимости от потребности привычек клиенты это такие штуки где вы в питании можете написать некий набор скептиков которые непосредственно с генерят даже в итоге дашборд на кране есть вместо того чтобы там где не лететь и даже борды как в сложных серьезных там долгое количество времени вы можете написать быстрый кричать проанализирует и дальше сделает либо в для сложного серьезного боевые зале пинтах а и были одни клиент проверяем а ну либо это уже серьезно и кастомное приложение которое на непосредственно под конкретного конкретные потребности делают вот собственно проблемы проблемы и прошелся большие данные большие и с этим приходится жить данные привязанные ко времени и ну как бы данные температуре в холодильнике магазина не нужны через день потому что ну а не нужны для истории но они не нужны для оперативных петель и синий и главная проблема которая там фундаментальный вопрос это как удостовериться то что данный запоминать качественные как понять что особенно когда вас поток данных что там данные стали тени те данные стали преобразовываться не так данные куда-то потерялись и так далее когда ну у вас данных от большой объем вот очень надеялся что доклад мы будет перед вадима пока там оказался после надеюсь чтобы был хоть как-то полезен с радостью отвечу на любые вопросы спасибо добрый день а насколько старые данные приходился устанавливать насколько старые данные на практике оказались полезными а я читер мы с этим работаем получается реальности реальные данные мы начали писать с декабря прошлого года поэтому я когда-то это случится но пока нет привет у меня вопрос такой наверное концептуальный первый вопрос потребления вот ваши клиенты они потребляют у вас за сервис по большей части или они требуют чтобы вы делали им коробочное решение которое они оставят эксплуатирую дальше сами а нам нельзя рекламироваться на докладе я могу потом прийти рассказать но в целом мы как бы считаетесь у нас сотрудниками клиенты карате кори после это да да здравствуйте вы упомянули про использование не fit для использования ну различных протоколов ких тогда получение данных вот дальнейшее там обработки анализ хранения а есть может быть опыт использования fit для взаимодействия с устройствами именно то есть я нежели защитник но из того что я видел мы чаще всего это скидывали там где мы были близко к железкам и чаще всего это скидывали данные каким-то образом датчиков тут вам пике is empty уже хочется в мифе вот и соответственно не непосредственно до железок железки . это кастом а уже пикирует сам без пикировки набранные данные пошли дальше"
}