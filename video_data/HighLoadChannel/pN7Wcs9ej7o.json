{
  "video_id": "pN7Wcs9ej7o",
  "channel": "HighLoadChannel",
  "title": "Эффективная ML-обработка видео в web-браузере для видеоконференций SberJazz / Дмитрий Балиев",
  "views": 106,
  "duration": 2841,
  "published": "2025-01-17T02:23:27-08:00",
  "text": "Всем привет В общем да меня зовут Дима сегодня расскажу вам про то как мы делаем обработку алгоритмами видео в браузерах для нашего сервиса конференции СЗ и начать Я хочу с такого небольшого тизера Почему вообще это всё круто и интересно мы вот что сделали взяли одну из нейросетей которые мы используем это нейросеть которая отвечает за сегментацию человека которы используется в таком эе замена фона и запустили её в двух вариантах вот в первом мы её запустили на актуальной версии ранма в вебе и причём используя один из самых таких передовых кэндо который ещё поддерживается мало где вот в Хроме и то не на всех платформах и также замерили время Ирен в нашем движке который мы написали про который сегодня Вам расскажу и вот у нас наша сеточка работает в четы раза быстрее Ну вот сегодня расскажу некоторые детали как у нас получилось достичь таких результатов а о чём я вообще буду рассказывать вначале немножко пройдёмся по контексту чтобы было понятно что мы вообще делаем для какого продукта какие у нас есть ограничения Потом я расскажу про сам движок и про вот некоторые особенности его реализации как мы работаем с графами вычислений как мы инфе сеточки как это всё собираем и оптимизируем дальше я Пройдусь по нескольким нюансам тестирования таких систем Ну и дам в конце несколько полезных Советов о том как вообще можно делать Несе более удобными для встраивания Давайте начнём с продукта и вот для чего мы всё это делаем это сервис видеоконференции с у нас больше миллиона активных ежедневных пользователей больше 300000 пользователей каждую неделю пользуются создают конференции общаются в нём и в этом продукте мы предоставляем довольно широкий спектр крутых алгоритмов таких например шумо подавления обработка видео про которое сегодня поговорю транскрибация ре и даже есть XR режим в котором можно проводить виртуальных пространствах встречи на каких платформах мы всё это запускаем ну понятно у нас есть десктоп в котором сейчас у нас приложение написанно на фреймворке Электрон То есть это по сути обёрнутый браузер с некоторыми расширенными возможностями И это всё должно запускаться на вот основных платформах то есть Windows macos Linux понятно что есть мобильные платформы iOS Android и там у нас сейчас нет акцента именно на обработке видео но нам нужно в любой момент возможность туда тоже какие-то фичи раскатать и есть Web иб для нас очень важная платформа потому что вот когда мы работаем с сервисом видеоконференций очень часто может возникнуть ситуация в которой вот вам прислали ссылку на встречу а у вас никакого приложения не стоит Но при этом мы всё равно хотим дать полноценный экспириенс дать все фичи которые есть у нас на платформе чтобы вы могли пользоваться там той же заменой фона улучшением картинки и так далее И вот для нас такая важная базовая платформа и при этом она самая ограни не меньше всего возможное Поэтому вот мы от не отталкивались если там сможем сделать то везде и на десктопе на мобилках Мы тоже сможем сделать хорошо за какую часть вообще джаза мы отвечаем вообще в любой платформе видеоконференции происходит на самом деле очень много разных вещей там Обработка медийки кодеки собственно там сеть UI который нужно рисовать кот за койт после сме вот получили Стрим получили кадры мы делаем некую свою магию обрабатываем эти кадры и после этого отдаём результат он уже кодируется кодеками отправляется на сервер маршрути зру ется попадает другим пользователям И это всё работает Какие задачи мы решаем в нашем модуле Ну вот Давайте пару примеров рассмотрим например бьютификация какие здесь задачи нужно найти на кадре лицо человека на этом ли определить некоторый реги Интере одели Где у человека кожа находится вот в бонди боксе лица и дальше мы э накладываем размытие ну вот и э получается более приятная картинка второй пример - это размытие фона это частный случай замены фона самый сложный в котором намм нужно сначала найти пиксель относящийся к человеку то есть решить задачу сегментации и после того как мы получили такую сегментацию маску нам нужно Ну её обработать обработать фон соответственно размытием сделать композицию Ну вот такие примерно задачи мы решаем в нашем модуле и Вот какие у нас хотелки Какие ограничения как я уже сказал для нас браузер - это базовая платформа и мы хотим хорошо работать в браузере при этом мы хотим осуществлять поддержку нашего продукта малой командой И на самом деле это требовани превращаются в то что мы хотим максимально универсальный код писать и не поддерживать целый зоопарк разных решений на разных платформах нам нужно минимизировать нагрузку на устройство пользователя это с одной стороны сделает наш продукт более быстрым более приятным для использования а с другой стороны также поскольку мы например работаем там наши пользователи работают в основном на ноутбуках скажем то это ещё и вопрос жизни ноутбука на батарейке Там и так далее То есть Нам очень важно это делать Мы хотим работать тти кадрах в секунду это вот стандартная скорость с которой работают камеры но важно отметить что мы хотим не просто наши эффекты чтобы работа в 30 кадрах в секунду но чтобы вообще как бы вся система при этом работала быстро То есть если мы возьмём весь этот вычислительный бюджет только на себя то у нас будет тормозить медийка у нас будут тормозить кодеки у нас будет тормозить UI это будет неприятно вот надо это учитывать Ну и мы хотим работать на относительно слабом железе вот некоторый такой внутренний референс Для нас это илов ские процессоры со встроенной графикой i3 i5 2018 года выпуска Ну вот примерно ориентир там железа на котором мы хотим чтобы всё хорошо работало а при разработке вот практически в самом начале мы для себя вывели одно важное правило что вот чего мы не хотим в нашей системе делать это делать лишних больших копирования данных и особенно мы не хотим делать лишних больших копирования данных между центральным процессором и графикой потому что этот процесс медленный сам по себе Мы работаем с большими кусками данных То есть у нас большие кадры там разрешением 720p 1080p иногда 4K бывают камеры и дополнительно к этому проблему создаёт то что вот графические ipi они обычно асинхронные если мы пытаемся передать кадр собственно с центрального процессора на графику мы ещё будем сталкиваться вот с барьерами которые есть в асинхронной работе это тоже дополнительно нам будет ставить палки в колёса Ну и вот получается что в идеальном мире мы получаем наш кадр с камеры Мы его как-то процеси на нашем графическом процессоре получаем результат вот он уходит в кодеки и мы нигде не переходим в память центрального процес Ой у нас теперь есть некоторое представление о том что мы хотим сделать в каких ограничениях Какие компоненты нам вообще будут нужны ну для начала Нам нужен некоторый движок для построения пайплайн собирать конечный эффект то есть из разных кусочков дальше нам нужно определиться как мы будем делать самую сложную часть из этих кубиков это ну и в конро собрать ОБЖ это делать нанм с движка для построения палав А конкретно поговорим зачем мы остановились на графом движке и какие это плюсы нам даёт почему это важно Вот давайте посмотрим на пример того как реализуется один из наших пайплайн виде это пайплайн который улучшает картинку и вот что мы делаем Мы сначала уменьшаем избрания того нерока с поме сеть Исеть соответственно находит На этой картинке лица и мы вот получаем местоположение лиц на изображении дальше по вот этим частям картинки мы считаем некоторый набор коэффициентов и когда мы посчитали этот набор коэффициентов мы уже применяем обработку конечную кадру Ну вроде всё просто довольно легко такой пайплайн построить в коде Что будет если мы теперь хотим не один такой пайплайн запускать сразу несколько параллельно Ну вот например мы к нашему улучшению картинки хотим ещё бьютификация у нас ВС ещ остаются все операции которые мы хотели делать для улучшения картинки Но к ним добавляются ещ операции которые нужны для фикации что мы делаем мы берм картинку уменьшаем её размер для обработки нейросетью снова ищем на этом картинке лица на этих лицах мы находим регион интереса и к это региону интереса мы применяем сглаживание вот Какая здесь проб Ну наверное довольно очевидно что у нас в этих палана операции повторяются а мы так делать не хотим часть из этих операций тяжёлые в частности запуск нейросетей А мы хотим минимизировать нагрузку на устройство пользователя то есть нам в идеале Хочется вот так сделать что да и запуск не россет поиска лиц у нас происходит один раз а дальше мы вот по одной ветке считаем коэффициенты для улучшения картинки по другой фикации Окей в принципе такую систему тоже не очень сложно построить но какие здесь Е есть подводные камни А что если мы хотим только один из этих эффектов использ нужно улучшать картин цию Тим оставить вот если мы сделаем это таким грубым подходом то у нас Бут лишние вычисления вот так делать тоже не хотим и мы для того чтобы всё вот это решить пришли к такой архитектуре которую я называю пул архитектурой что мы делаем У нас есть некоторый результат вот мы хотим получить картинку которой примена фикация Отчего будет зависеть вот очевидно будет зави выхо подго э Ну вот мы соответственно эту зависимость прописываем нам нужно получить данные из вот последней ячейки для того чтобы её посчитать в свою очередь нужны данные о том как мы посчитали регионы интереса Ну вот мы просчитывать и так мы устройство пользователя лишними вычислениями которые на данный момент нам не нужны Если же мы хотим оба эффекта использовать то здесь у нас уже получается что мы считаем также результат зависимым от ветки улучшения картинки нам придётся тогда посчитать эти ноды тоже ну и здесь мы сделаем каширование результатов нахождения лиц для того чтобы не считать два раза эту тяжёлую часть и тоже нагрузку делать маленькой некоторые детали реализации которые хочется упомянуть Ну во-первых мы сразу держим все пайплайн инициализирован И это нам позволяет очень быстро включать и выключать эффекты То есть как только у нас поменялся Граф зависимости мы просто понимаем что теперь на этом кадре нам нужно ещё посчитать дополнительную ноду и соответственно у нас сразу всё работает при этом мы всё ещё считаем только необходимый подграф И тем самым минимизируем нагрузку сами операции мы делаем как обычные функции и вот оборачиваем их аккуратно Ну и вот ещё маленький момент мы вообще не стали В этой системе делать какие-то там внешние конфиги у нас сами пайплайн собираются в коде это удобно это даёт вот подстраховка в виде строгой типизации языка программирования который помогает поменьше ошибок допустить вот э в общем делаем вот так О'кей Теперь мы можем собирать из наших кубиков пайплайн у нас Э теперь нужно решить как мы будем делать кубики которые относятся к иренс Нера сетей вот если посмотреть на то как делать это оптимально то на большинстве таких платформ на которых можем считать Нера сетки есть уже какой-то инструмент который позволяет это делать с наилучшей производительностью Например у nid есть TT там у Apple есть cml и так далее но при этом мы не хотим поддерживать здесь большой зоопарк разных решений Ну и не для всех платформ на самом деле эти решения есть а ещё нам кроме неск нужно обработку писать и скорее всего прид тогда ещ дополнительный реворк для обработки брать и вот Мы так не хотели подходить и мы посмотрели в сторону другой категории решений которые не заточены на именно inference Нера сетей Но которые тем не менее дают нам полноценный доступ к нашей графической карте чтобы мы могли эти вычисления там реализовать и вот мы остановились на семействе алгоритмов точнее API opl вот opl полноценный для ну для компьютеров для ноутбуков Да есть Open который работает на мобильных платформах и есть самы интересно Для нас это webgl который позволяет с графической картой работать в браузере и какое здесь большое преимущество если мы напишем наш код Так что он будет совместим со самым слабым API из этой тройки то он будет работать везде он будет работать на мобилках он будет работать на десктопе он будет работать в вебе при этом мы также можем писать нашу обработку вокруг вот обработку изображения там да пост процессинг поскольку это API общего назначения то их тоже можно на НМ делать Ну вот остановились Давайте теперь посмотрим как мы реализуем inf на вотже и подобных языках Какая вообще базовая концепция вот когда мы работаем с графикой У нас есть рные программы которые собственно выполняют некоторые математические операции Они читают данные из входной текстуры и записывают результаты в выходную текстуру а сами такие программы могут работать с потоков вот здесь будет зависеть от того какая конкрет у вас графика Сколь у не ядер таких программ мы получаем вот нужный нам эффект соответственно цепочка разных вычислений получаем посчитаю не росет здесь важно отметить что мы хотим количество таких шейр программ минимизировать Почему Потому что на самом деле При работе вот с такой архитектурой у нас именно операции с памятью в основном самые медленные и вот мы не хотим чтобы на этих операций теров из записи тензоров текстуры было много Чем меньше их тем лучше Поэтому стараемся сделать этих программ поменьше Давайте подумаем как это сделать Значит первое что хочется обсудить какие вообще операции Мы хотим в этих шейр программах запускать Ну вот у нас есть стандартная операция для наших нер сетей это свёртки это пулин это апскейл И вот все эти операции они характеризуются такой особенностью У них одно выходное значение оно зависит сразу от нескольких значений на входе и вот В общем случае мы такие операции не можем собрать в одну дурную программу их придётся разделять есть второй класс операций это полетные операции вот в нерв сетях самый яркий представитель - это функция активации и такие операции Они как раз вот одно значение на выходе у них соответствует одному значению на входе и их мы можем комбинировать Ну потенциально в бесконечное количество И это хорошо делать соответственно базовая архитектурная идея получается такая вот од програ мы берм одну толстую операцию поверх неё ставим от нуля до тонких пока не встретим следующую толстую операцию и вот таким образом Соединяем часть шейр программ вместе вторая идея которая также дала большие плоды Вот как я сказал мы толстые операции объединить не можем в общем случае но мы можем делать это в частных случаях если мы напис специализированный код и вот для некоторых мест в архитектура такой код написат из где мы это сделали это такие места в структуре декодера вот архитектуры для сегментации в которых у нас происходит Ай после которого сразу идёт свёртка Ну вот здесь вот схематично нарисовано помимо прочего поскольку размер входной текстуры вот такого слоя в четыре раза меньше чем соответственно выходной здесь дополнительно мы вот получаем плюс от того что мы будем соединять эти операции Ну и вот это то что мы сделали вот сделали операцию которая совмещает сначала потом конволюция что нам всё это дало Нам всё это дало довольно существенный прирост производительности по сравнению с вот таким решением в лоб совмещение операции дало 10% прироста Причём здесь проценты Это не просто там процент от и какого-то слоя или процент от и нети это 10% от всего палана влом есть реальны 10% производительности в продукте кото вы увидите раз совмещение и свки в одну операцию Ну и вот с таким решением мы сделали Наш первый релиз как вообще всё это собиралось у нас было некоторое описание палана там есть путь к модели какие-то параметры конфига которые нам нужны ну и модель которая в стандартном формате по сути такие шаблоны на языке c+ в которых у нас уже лежат заготовки кода на glsl который язык шейных программ вот дальше всё это попадает в компилятор стандартный в нашем случае мы всё это делаем под веб поэтому основной основной вариант сборки Для нас это We assem Но помимо этого можем собирать и например под десктопные платформы Да там под maos под Linux под Windows Ну и вот на выходе мы всё это встраиваем продукт и неминуемо получаем счасть пользователя вот так вот поехали в первый релиз в принципе всё хорошо работало но у некоторых пользователей эффекты всё-таки подтормаживает ную оптимизацию которая дала нам самый большой прирост производительности и про которую на самом деле Ну довольно сложно что-то прочитать в м вообще базовая проблема как вот инструментом для ици Нера сетей Дело в том что в этом стандарте нет поддержки типа шейр программ которые называется compute shaders специально предназначенные для Вот как раз вычисления математики для матричных операций и так далее его разрабатывали но в какой-то момент полностью заморозили всю разработку стандарта webgl переключились на следующий Стандарт webgpu он вот через какое-то время у нас у всех появится и мы будем счастливы с ним жить но вот пока и мы получаем ситуацию где вот на десктопа у нас всё есть на мобильных устройствах У нас тоже всё есть а в вебе компютеров нету Как из этого выпутываться нам подсказал блогпост который выпустил Google в 2022 году что там утверждалось ну вот они тоже встретились с проблемой что в ну пох по их замерам без компьют шейдеров производительное ш 25% от производительности при этом часть этой потерянной производительности Можно отыграть если использовать подход который называется что это за подход мы берём одной шейной программой пишем не одну выходную текстуру а сразу в несколько параллельно и вот за счёт этого можем что-то оптимизировать почему это нам может помочь Дело в том что свёртка - это операция То есть у нас операции с памятью чтени например они занимают большую сть времени чени если мы сможем как-то оптимизировать вот операции с памятью наша свка будет работать быстрее Вот соответственно они попробовали это применить и получили что вот у них с такой оптимизацией производительность достигла 90% от производительности Open вот изначальной Окей очень круто звучит очень интересно Проблема в том что никаких деталей нету никаких реализаций нету В общем с этим работаем Ну давайте вообще смотреть проб тут я сейчас расскажу вам Почему вобще эта базовая идея работает для этого надо вспомнить как свто операция работает Давайте посмотрим на Супер простой пример вот у нас есть маленький тензор и мы его сворачиваем вот с простым ядром 3 на3 для получения результата то есть что мы делаем Мы сначала берём окошко соответственно делаем полимет перемножение получаем наш результат Вот и так двигаемся по нашей матрице смеем окошко получаем следующее число Ну и вот четыре раза повторяем получаем полностью результат свёртки давайте это запомним Теперь будем считать операции с памятью которые нам нужны для того чтобы это сделать Вот первый вариант мы не используем multiple render targets оптимизацию и просто считаем одно значение на выходе Для этого нам нужно считать из памяти девять значений нашей свёртки 3х 3 и соответственно девять значений из нашего окошка тоже 3 на3 Итого у нас 18 операций чтения Если же мы переходим к оптимизации то есть что нам теперь нужно Мы хотим четыре значения сразу почитать на выходе одновременно и записать их в четыре разные текстуры Вот для этого что нам нужно сделать вот нам нужно считать данные нужные для всех вот этих четырёх операций которые сейчас в анимации показываются то есть Нам нужно ВС ещё считать де значений нашего ядро свёртки поскольку она общее для всех соответственно элементов нашего тензора нам тедо считать область 4 на4 из входно операций чтения Ну и вот сумме мы получаем 25 поскольку это ВС операция чтения на четыре выходных пикселя то вот если пересчитать их на один то мы получим чуть больше ше операций на оди пиксель то есть порядка 35% от вот изначальных 18 операций которые нам нужны были на один пиксель Ну и вот у нас получается такой ожидаемый теоретический прирост производительности от использования этой оптимизации ври ра здесь стоит Е отдельно упомянуть Почему именно выхо вобще стандартом гарантировано но мы здесь решили остановиться на четыр потому что здесь при написании такой оптимизации очень сильно код усложняется вот во можно было бы использовать но там уже прирост производительности не такой сильный и мы решили что он того не стоит Давайте теперь тестировать это всё на реальных кейсах на вот реальных слоях мы взяли некоторые слои которые вот самые тяжёлые были в наших архитектура и для них посмотрели Что будет если мы будем паковать вот тензоры в одну текстуру на входе одну на выходе будем паковать в четыре и вот разные комбинации посчитали Ну и действительно если мы будем паковать в четыре текстуры то у нас получается существенный прирост производительности вот на реальных слоях мы получаем в два-три раза прирост при этом тут стоит отметить что иногда иногда у нас бывают всё же и не очень приятные э комбинации в которых наоборот происходит замедление и вот когда происходит замедление Мы конечно так не хотим делать И если такие комбинации нужны в вашей архитектуре за этим надо следить и нужно делать репаков тензоров Она быстрее чем то замедление которое вы здесь получите вот ну и Давайте посмотрим теперь на результаты которые получаются ЕС уже посмотреть на всё ту end и вот ту end На замене фона мы получаем 36% реального прироста производительности То есть это вот всё вместе и Нера сетка и все обработки которые вокруг То есть это тот прирост который увидит конечный пользователь Ну в принципе это очень круто то есть это самая вот эффективная оптимизация из всех которые мы пробовали Окей давайте теперь посмотрим на некоторые нюансы тестирования таких систем что мы вообще хотим тестировать мы с вами хотим тестировать что во-первых нее работают правильно то есть сделать некоторый сачек потом мы хотим тестировать что код работает правильно соответственно иметь возможность гонять тест Ну и хотим тестировать производительность Давайте нам но здесь на самом деле всё просто Вот у нас есть наш некоторый inference мы э берём некоторые эталонный набор изображений прогоняем через этот inference параллельно к нему делаем ещё некоторую эталонную реализацию на каком-то проверенном движке например берём X Run Да там э стандарт довольно известный и проверенный получаем два результата эти результаты между собой сравниваем если у нас всё хорошо то вот сачек прошли и соответственно наша сетка работает нормально грубых ошибок в ней нет Окей сетки проверили дальше Нам нужно запускать тесты и вот тут у нас появляется проблема Дело в том что для того чтобы мы могли тестить приложения которые использует внутри себя Open нам нужно во-первых иметь некоторую доступную реализацию API opl а во-вторых нам нужно иметь некоторое устройство дисплея на котором мы можем создать контекст при этом мы хотим эти тесты запускать в какое-то окружение Да там для всех квестов например А это окружение Но вот в нашем случае это там CL в котором У нас есть виртуалок в них нету ни дисплея ни графической карты соответственно Ничего из этого запустить не можем как выпутываться ну вот для драйвера есть Ну такой драйвер ме на линуксе который как раз даёт реализацию API Open и вот у него есть конкретный подвид этого драйвера который называется смес и он как раз даёт нам реализацию на центральном процессоре она не очень быстрая Но вот для Юнит тестов она вполне подходит а для дисплея нам на самом деле нужен не сам экран нам на самом деле нужен лишь э собственно буфер этого экрана в который мы можем э записать нужные нам вот кусочки для создания контекста но сам дисплей в общем-то нас мало интересует и здесь вот есть такой пакет Вот в линуксе это X Virtual Frame буфер который как раз на даёт буфер экрана не треу наличия физического экрана мы там создам наш контекст пишем в эту память с ней работаем вс хорошо окей Теперь мы можем нормально тестировать наше приложение На тестах но мы ещё хотим тестировать производительность и здесь я хочу вот остановиться на парочке нюансов с которыми можно встретиться и там может быть неприятно первый нюанс это то что стоит помнить что этон если вы будете запу функци Вы скорее всего намерите странные цифры вот на самом деле вам надо замерять останавливать замер тот момент когда вы уже получили данные эти данные почита вот здесь всё просто второй момент - это то что часто вот помимо скорости выполнения нашего алгоритма можем например хотеть нагрузку мерить да насколько он грузит наше устройство здесь есть тоже такой нюанс вот у нас одна из основных платформ с которой мы работаем это ноутбуки а в ноутбуках обычно как это реализуется у нас есть Центральный процессор есть графика есть некоторый общий бюджет мощности при этом мы не можем на 100% его отдать центральному процессору графики одновременно и вот может такая ситуация случиться например у нас есть два алгоритма и тот и другой по нагрузке нам показывает 90% нагрузки на графику Окей но при этом в первом случае у нас вся мощность доступная уходит на графику Центральный процессор сидит на частотах у нас система подтормаживает это неприятный User exp во втором случае у нас графика сидит на своей минимальной мощности процессор спокойно может разгонять ядро всё быстро работает экспириенс классный а нагрузка и там и там 90% то есть нужно следить за тем как у вас распределяется мощность как минимум следить за тем как у вас себя ведут частоты например на центральном процессоре во время запуски на графике иначе здесь можно опять же намери не те цифры которые есть в реальности Окей последняя такая часть которую я хотел рассказать это немножко про сами модели как их делать чуть-чуть более приятными для вот внедрения в inference и здесь с чего хочется начать вот есть два таких немножко разных подхода к работе с моделями вот мы можем условно быть исследователем и Наша задача сделать модель которая будет выбивать метрики что мы делаем мы берём статьи смотрим Какие сейчас есть крутые архитектуры эти архитектуры обычно борются между собой за какие-то последние доли процентов В какой-то метрике и там часто есть странные решения в архитектуре они могут быть Вот как раз обусловлены там конкретным бенчмарком которые пытаются оптимизировать они могут быть условленное но с точки зрения там организации графа вычислений она очень странная и не имеет смысла вот а при разработке продукта нас зачастую интересуют некоторые другие вещи мы вот метрику можем оптимизировать гораздо сильнее путём работы с данными путём работы с какими-то другими частями пайплайн сумен тация и при этом нам гораздо интереснее вот поменьше использовать без надобности какие-то нестандартные решения побольше использовать какие-то проверенные архитектуры которые вот часто лучше скеля Вот при работе с данными лучше скеля при их опти и я хочу здесь разобрать просто вот один простой понятный пример с которым мы конкретно сталкивались вот проблем которые могут возникнуть при вот исследованиях и попытки их внедрить продукт история такая вот у нас была модель которая хорошо работала Она уже была в продакшене была оптимизирована всё Окей но вот хочется её ускорить вотже говорим промен опцию моде один из стандартных подходов к оптимизации это Нин вот Ну хороший метод вот может быть получим модель поменьше которая при этом будет хорошими метриками Ну вот подрезаем модель делаем цикл Файн тюнинга что ожидаем Ну вот ожидаем что она будет быстрее работать при этом вот по метрике не просят Тестируем и получаем снижение скорости Ирен очень странно как так вот но перестало быть кратным четырём то есть мы вот порезали каналы как Мы считали нужным по метрике и вот у нас странная архитектура получилась А у нас часть оптимизация была как раз завязана на том что каналы идут кратными четырём и у нас на этом паковка тензоров собственно завязана И вот она перестало быть кратном четырём и всё стало медленно работать ну решение этой проблемы довольно простое то есть нинг надо добавить правило что вот каналы просто так нельзя выкидывать нужно чтобы это правило соблюдалось но вот тем не менее вот яркий пример как не думая о том как эта архитектура выг для вот конечного исполнения мы можем просто на простом месте потерять фор Окей давайте наверно теперь подводить итоги О чём сегодня поговорили поговорили сегодня о том как мы обрабатываем видео в браузере с помощью Эля Да вот про важность того что мы хотим всё держать в памяти графического процессора поговорили про то как мы работаем с графами вычислений Почему вообще именно вот графо движок Он важен если мы хотим обеспечить оптимальный и рассказали про то делаем наш Конный иренс на и Про некоторые особенности оптимизации которые дали вот нам очень хорошие бусты по производительности также мы с вами обсудили как всё это тестировать некоторые вот нюансы которые возникают при тестировании приложений использую и вот пару Советов о том как делать росет более удобными Вот на этом У меня всё здесь у нас есть пара Куров можно проголосовать за доклад также у нас есть нашего Канам а также мы сейчас вем трансляцию того как выглядит глазами спикера вот заходите смотрите если вам интересно А я готов ответить на ваши вопросы Спасибо Дима очень много QR кодов на слайде но я думаю что с помощью приближения вы сможете разобраться какой использовать Напоминаю что зрители онла трансляции также могут задавать вопросы за лучши вопросы Мы Дамм из зала первый вопрос Давайте молодой человек на втором ряду Спасибо за доклад во-первых У меня вопрос наверное такой Ну получается МРТ даёт возможность свести Web jel к тому что показывает Open Я же правильно понимаю что в принципе ничто нам не мешает такою же методику на opl применить И она тоже там ускорится раза в три Ну условно это вот первая часть вопроса А вторая а вот в новой пишки не знаю изучал ты или нет Там есть возможность вот этот батчинг условно Ну прям в опи заложить то есть потому что кажется идея очень крутая И зачем заставлять всех писать это с нуля каждый раз да спасибо за вопрос на самом деле очень наверное правильный хороший Смотри у нас на самом деле так вообще и сделано то есть у нас поскольку общая кодовая база у нас всё написано под стандарт и вот в Open он работает точно так же и работат с такой же производительностью вот в чём загвоздка дело в том что вот компьют шейдеры Они они написаны так чтобы как раз Хорошо выполнять те операции которые нам нужны вот при компью То есть когда мы вычисляем вот матричные перемножения сеточки наши строим и там уже конвейеры которые работают с данными они написаны соответствующим образом вот в самом стандарте шейдеров мы по сути вот этой оптимизации пытаемся решить проблему того что у нас нет нужных нам конвейеров для работы с данными вот в стандарте в котором их вот нет соответственно для Open эта оптимизация уже такого Смысла не имеет потому что там есть эти конвейеры которые работают хорошо И вот webgpu например вот сейчас его можно там в Хроме пощупать на некоторых платформах Я думаю что дальше он будет потихоньку раскатывать на другие браузеры там уже есть поддержка вот компьютер шейдеров наверное там будет лучше с этим Спасибо за вопрос есть ли у нас ещё вопросы а давайте в дальний в дальний угол зала молодой человек на пятом ряду Да спасибо за доклад Григорий Соколов компания Баум ваш вот доклад он был посвящён по сути инфе на стороне клиента например с ноутбука Да а проводили ли вы какие-то исследования либо сравнения и думали ли вы о том чтобы перевести эти вычисления на сервер сайт Спасибо за вопрос смотрите А как раз наоборот у нас основная цель была именно оптимизировать иренс на клиенте то есть какая ситуация а вот очень дорого для нас такие эффекты масштабировать сервер сайт вот при этом Ну вот ценность Для клиента условно она от этого сильно не повысится то есть мы можем достаточно качественно эти нейросети запускать на клиенте и вот как раз для того чтобы вот не грузить лишнюю серверную архитектуру не попадать на проблемы слинга там что нам не знаю Мы продали допустим продукт ещё одной крупной компании нам нужно X10 серверов теперь для того чтобы всё это обрабатывать вот мы как раз наоборот смотрим в сторону того чтобы выносить такие обработки Как раз на сторону клиента и делать там это хорошо и быстро вот да спасибо И второй вопрос У меня был в начале был слайд о том что у вас идёт распределение на несколько потоков соответственно вашего видеопотока И вот вопрос связан с тем Как у вас архитектурно заложено допустим у вас идёт видеокадры 640 например на 480 либо 4К как-то у вас это архитектурно заложенное количество потоков которым обрабатывается видео а Ну смотри у нас ну как видео оно по сути обрабатывается в одном потоке то есть мы просто строи Ну условно у нас этот Граф просто превращается в последованность операций следующий из которых зависит от результатов предыдущих но с точки зрения графического API параллелизм он идт на уровне шейр программ То есть у нас шейр программа исполняется параллельно Но вот конкретно операция которую мы в ней делаем они последовательные на уровне вот графа из которой из БЧ состоит то есть по сути у вас видеопоток выстраивается в очередь Да и каждый кадр обрабатывается последовательно Спасибо Давайте молодой человек на седьмом ряду Кстати я до сих пор не вижу ни одного вопроса из трансляции там в плеере есть кнопка можно по ней перейти в чат и задать вопрос и также оценить доклад Спасибо за очень крутой доклад пал Богомолов я вот такой хотел вопрос задать прой про код генерацию это вы сами это пишите или есть какая-то осор реализация и если сами то второй вопрос как ни экспериментировать в смысле того что вот мы попробуем но какую-то архитектуру а потом её 3 месяца Надо будет там писать шник под Нега Ну да смотри Значит у нас ну генерация у нас своя кастомная то есть ну она кстати на пайта не написана не на плюсах потому что писать куда генератор на плюсах было бы слишком насколько она ограничивает ну смотри у нас действительно вот В чём минус того подхода который мы используем он конечно в том что мы поддерживаем довольно ограниченное количество нейросетей то есть мы взяли Там те эффекты которые мы хотим собственно реализовать в нашем продукте мы посмотрели что для них нужно и мы для вот этих конкретных операций написали реализации и вот там Если вы возьмёте просто рандомную не росет её так запустить не получится это ну довольно большой минус но для нашего продукта это вот было ровно то что мы хотим то есть ровно те операции которые мы хотим в него заложить с точки зрения ограничений Ну да наверное в какой-то степени это нас ограничивает то есть мы не отказываемся от такого экспериментирования то есть если у нас есть какие-то интересные идеи че Мы хотим попробовать но мы это пробуем мы даём фидбек разработчикам ро сетей что в них можно поменять чтобы это было проще встроить и как правило получается поменять архитектуру Так что метрики у неё не падают а она становится гораздо проще её легче встраивать Вот но с точки зрения такой общей да Безусловно это ограничивающий фактор который вот в каких-то проектах может будет неприятным да А если интересны кстати подробности вот мы после доклада у нас будет тут курная дискуссия у нас с нами Сергей сегодня который может прямо подробно рассказать про эту часть Вот можете с ним пообщаться Давайте молодой человек на первом ряду Спасибо за доклад поднималась тема по поводу B операций большинство операций они есть соответственно вопрос у большинства современных фреймворков Open Есть такая опция даже не опция это обязательна операция компиляции нейросети перед подачей на вычисление компиляция подразумевает перекладывание весов в том порядке чтобы как можно меньш проди тоже сами реализовывали и есть ли она у вас Смотри вообще Если я правильно понял то что ты имеешь в виду ты наверное имеешь в виду что все современные фреймворки Ирен они так или иначе делают Ну по сути векторизации путём определённой умной упаковки данных в те объекты памяти которые им доступны Да смотри я в презентации про это не упоминал потому что это типа рассказ на отдельный доклад Но действительно эта векторизация у нас есть просто ну векторизация есть действительно во все фреймворка То есть поэто можно почитать можно почитать исходные Кодыма там это есть вот это очень важная часть без неё у вас конечно хорошо Ничего работать не будет то есть надо именно грамотно паковать данные в текстуры для того чтобы они подавались эффективно в программы это ну важная часть палай Окей и второй вопросик по поводу склейки операций Вы упомянули только про склейку Я может пропустил была ли упомянута склейка convolution операции с последующими активация потому что по факту перегонка этих данных она тоже может сильно замедлить Да смотри Ну вот склейка как раз конволюция с последующими активация она у нас вообще идёт автоматом то есть мы это не рука вот склейку а скейла со свёртка мы прямо писали руками отдельный код программы которая может делать Вот такую комбинацию а а там это соответственно из-за того что активация - это функция которая зависит только от одного входного значения Она у нас по с автоматом сразу дописывается в ту шейр программу которая делает предыдущую сврт Угу Да понял Спасибо Илья можете передать микрофон своей девушки по соседству Привет практически коллеги Меня зовут набережная Мария Я из Бер инфра и вот хочу задать такой интересный вопрос вы Задумывались о том легче ли картинку Ну видеозвонка на стороне каждого из собеседников или просто передавать Ну вот изменённый поток уже как бы вот ну да на самом деле такие вещи в том числе в разных контекстах У нас обсуждались тут какой нюанс Есть дело в том что когда видео уходит Роны клиента другим клиентам оно паку кодеками Прим оно паку кока вариантах например там полное разрешение разрешение поменьше потому что у всех разные каналы связи и с этим на самом деле вот видеоконференция самая сложная часть - это вот э вот работа с медийка работа со слабыми каналами и так далее И вот если вам приходят видео 360p и вы будете пытаться его потом обрабатывать нейросетями когда оно пожа тое кодеками вот с такими квадратами на нём то боюсь результаты получатся не те которые хотелось бы и вот поэтому здесь в большинстве случаев вариантов нету нужно обработать на том клиенте кто отсылает данные Отлично спасибо Есть ли ещё вопросы в зале Давайте ещё молодой человек На предпоследнем ряду Спасибо Дим за доклад У меня вопрос всё-таки про пайплайн и про их параллели зации скажем так Если я правильно понял слайд то по Су операции накладываю разные эффекты но они при этом работают изначально с входным кадром фреймом и тогда если так то как потом ржится результат который получился или по факту они вс-таки последовательно выполняются по факту они всё-таки последовательно выполняются то есть мы просто построим Граф и определяем по этому графу последованность которой мы будем дёргать соответствующие куски кода но дело в том что то есть поскольку мы всё это исполняем собственно там ну вот так запаралелить Ну то есть как бы можно но это Нест такого особого преимущества и соответственно у нас это исполнение само оно идёт последовательно Ну то есть если там условно там у нас в конце идёт эффект там вроде там тоже бьютификация то к нему на вход уже подаётся не сырой изначальный кадр А который был уже обработан предыдущим эффектом каким-то А в этом смысле ту тут зависит Ну вот смотрите вот последовательность эффектов она а она на самом деле зависит от того как Ну она зависит от того что вы хотите получить на выходе то есть Это скорее вопрос не перформанс Это вопрос того как эти эффекты скомбинировать чтобы картинка была правильной они неправильной То есть например там операции по например обработке кадра с точки зрени его освещённости надо делать до замены фона не после потому что после у вас будет фон влиять на ваши статистики А вы не это хотите править и с этой точки зрения это вот определяется продуктовыми требованиями Но дальше в зависимость от них то есть получается что например если у вас пайплайн требуют там одной и той же росет обработки то сначала почитается росет дальше посчитают куски пайплайн если она требует например полностью уже иметь улучшенную картинку скажем по освещённости то да Сначала посчитает всё что нужно для этого потом то что идёт дальше но мы стараемся максимально здесь оптимизировать чтобы вот не было случаев когда у нас один эффект зависит полностью от результатов предыдущего и как правило у нас большая часть вычисления Она идёт Ну условно параллельно В смысле Граф параллельный он вот посно исполняется и в конце у нас уже последние операции которые нужно нной последованности сделать мы делаем понял спасибо коллеги Спасибо за вопросы Давайте следующий из них уже унесём в кулуары Дима рядом с залом в дискуссионной зоне ответит на них после доклада А сейчас Дима надо выбрать Два лучших вопроса и наградить их Давай сначала награждаем призом от с Devices ох так Наверное наверное наверное вот вопрос который со второго ряда был на самом деле подсветить расписанная вручную у меня несколько кандидатов кто наверное всё-таки вот вопрос от Ильи с перво с первого ряда был самом Да раскрывающим тему поэтому Давайте Но это ещё не всё у нас есть ещё есть подарок для тебя Спасибо что выступил у нас на конференции и тебе так также достаётся матрёшка Давайте поал Спасибо"
}