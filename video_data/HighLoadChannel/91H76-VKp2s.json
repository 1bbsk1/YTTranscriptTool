{
  "video_id": "91H76-VKp2s",
  "channel": "HighLoadChannel",
  "title": "Миграция витрины данных с СУБД Teradata в СУБД Greenplum / Станислав Свириденко (Axenix)",
  "views": 160,
  "duration": 2170,
  "published": "2024-10-29T03:06:59-07:00",
  "text": "Всем привет давайте ознакомиться Меня зовут Стас снко Я работаю ввх разработчиком сразу хочу сказать что я немножко приболел Так что Не обессудьте если буду там подкашливать или там заикаться что-нибудь такое Давайте нам это моя история о том как мы мигрировали витри данных с ВНП в первую очередь стоит сказать что миграция витрины данных с одной технологии на другую это сам по себе достаточно сложный процесс который связан не только с конвертацией кода Т здесь есть свои неочевидные нюансы В своём докладе Я хочу рассказать о опыте миграции наша витрина данных была достаточно объёмной она составляла 44Б и и состояла из 2.800 таблиц и более чем 1.000 процедур а далее хочу рассказать об этапах миграции А В первую очередь это конвертация кода далее подготовка сред гмп Что включало в себя создание схем а настройки ролевой политики ресурсных групп и создания объектов БД после чего Аа перешли к загрузке промышленных данных и сверке кода на них а параллельно с этим а происходила настройка оркестратор настройка devops процесса и настройка загрузки выгрузки данных с источников после чего Мы перешли к наверное самому важному этапу это итоговой сверки данных а параллельному запуску расчётов нагрузочному тестированию и оптимизации работы витрины И последнее О чём хотел бы рассказать но не последнее по значению - это настройка систем мониторинга что ж начнём с конвертации кода для конвертации процедур и ddl объектов мы написали свои конвертеры кода на Python но при этом многие сложные моменты такие как вложенные курсоры рекурсивные запросы различные агрегатные функции использовани qualify их приходилось уже обрабатывать отдельно и переписывать вручную при этом также часть функций в роте и в гнп работают по-разному например сортировка в terata ставит N в начало списка А нпм в конец Это довольно легко решить достаточно в Грин ПМЕ отдельно указать после наименования атрибута конструкцию First либо которая позволяет явно задать расположение отсутствующих значений также наверное самая классная фича тиро даты по моему мнению - это то что она умеет переиспользовать алиасы внутри одного запроса тем самым код получается более компактным и его больше более легко читать потому что результат одного расчёта может использоваться в других расчётах в джоина и так далее в гн ПМЕ К сожалению так делать было нельзя поэтому приходилось А разбивать это всё на множество А вложенных запросов а также при сравнении аэ двух атрибутов рота умеет неявно приводить типы данных А например если у нас одно и то же значение 123 А находится в текстовом атрибуте И в интом то терадата при сравнении автоматически э-э проведёт нужные операции и выдаст True в гн ПМЕ же необходимо такие для такого сравнения приводить кастами к одному типу данных иначе соединение Не сработает также очень важный момент в терадата используется банковское округление А в НП математическое А собственно Что обозначает банковское округление оно приводит э числа до ближайшего чётного числа например полтора и 2 с поно при банковском округлении будут давать двойку это необходимо учитывать при расчётах довольно важный момент а также при сравнении текстовых атрибутов терадата умеет игнорировать конечные пробелы чего не может нпм по умолчанию и соответственно тоже при джоне по таким текстовым атрибутам приходилось добавлять тримы чтобы соединения правильно отрабатывали а помимо этого также teradata умеет прямо в ddl таблиц указывать признак для атрибутов Cas and Sensitive м когда мы обнаружили этот момент в начале мы начали добавлять в код процедур обёртку из лоров при сравнении двух текстовых атрибутов Но это довольно долго неприятно мучительно А поэтому по итогу Мы перешли к тому что переконвертировать ddl объектов на основе объектов ты и для всех таких атрибутов с признаком Sensi использовали тип данных ситек который позволяет автоматически при сравнении таких атрибутов всё приводить к нижнему регистру Вот и последний момент о котором я хотел бы сказать насчёт конвертации это то что версии использу нету процедур есть только функции которые представляют из себя единую транзакцию и в них нельзя использовать com rollback для отдельных операций Это приводило к тому что если у нас функция не отрабатывал успешно и выдавала ошибку то откатывать всё целиком включая записи в журналы отладки из-за этого нам пришлось переделать процедуры таким образом добавив туда эксп и отслеживая ошибки по ним и выводу в Out далее перейдём к организации схм проблема которую необходимо было решить это настроить ресурс ролевые группы таким образом чтобы ДД объекты ВНП требуют чтобы операции над ними мог выполнять только их владелец из-за этого Мы создали отдельно роли для бизнес пользователей и для технических пользователей из-под которых уже осуществляются различные etl процессы запуски расчётов и devop операции также мы настроили роли для запуска функций настроили выделение ресурсов по времени суток и Дню недели и отдельно организовали уровне витрину данных в плане наименований атрибутов наименований объектов схем и параметров в переменных в переменных в функциях далее хотел бы рассказать про сдание объектов ещ на самых ранних этапах мы отдельно определили для каждых таблиц способы хранения данных ключи распределения по сегментам в большей части они соответствовали тем что были в teradata но частично отличались например для всех справочников мы использовали distributed replicated для того чтобы сократить лишние моушены при джоина с этими справочниками а также определили способы партиционирование данных ориентацию данных колон либо срочную и типы силы сжатия а данных в партиях с учётом их температуры говоря про промышленную загрузку данных мы использовали последовательную перелив вначале брали данные и при помощи qud заливали их в hdfs после чего через pxf Лили данные в отдельную схему п в которой они использовались уже как эталонные Дан пос также копировались в различные схемы Green plam для проведения тестовых расчётов при сверке кода на данных мы пользовались Python а при помощи двух jdbc коннекторов Мы подгружать в Python ра дату и Green после чего брали исходный и инвертированный код помещали их в результат исходного из конвертирова кода помещали в два пансо датафрейма и начинали сравнивать в начале сравнение происходило по агрегатам атрибутов А после чего сравнение было по атрибутный с учётом заданного ключа Здесь сложностями было то что порой было нетривиально найти уникальный ключ для сопоставления и также были порой проблемы с при сверке таких типов данных как FL либо при по настройке оркестратор и дес процессов для оркестратор необходимости к hdfs через специальные учётные записи с использованием kbos сами сценарии хранились в специальных технических таблицах н и представляли из себя последовательный либо параллельный запуск функций либо также выполнение команд в параллельно с этим также настраивали devops процесс он был необходим для раскатки ресурсно ролевой модели артефактов Green запуска сценариев технологический стек для процесса мы использовали jenkins bbet C и Nexus для разработки нашей витрины данных также требовалось разработать новые etl процессы для загрузки данных с источников это осложнилось тем что параллельно с миграцией нашей витрины данных также происходила миграция источников и получателей таким образом чтобы всё обработка и хранение данных у них мысленно осуществлялось на hdfs серверах А поэтому мы проработали взаимодействие А с источниками при помощи pxf серверов через External table На этом этапе в целом была только одна проблема через Хай загрузка происходит весьма быстро только если мы не говорим о загрузке через вьюшки порой не получалось избавиться от выгрузки из вьюк и в таком случае данные переливались достаточно медленно также требовалось достаточно аккуратно относиться к фильтрации данных к описанию фильт чтобы фильтрация происходила на стороне источника и лишние данные не гонялись по сети вот а когда Мы перешли уже к выгрузке в А dfs тут возникли сложности в первую очередь сама выгрузка через pxf могла производиться только при помощи профиля hdfs паркет что накладывала ограничение потому что через этот профиль данные о партиции таблиц доступны только на уровне файловой системы и чтобы например записать из гн плама данные в какую-то определённую партиции дупа необходимо было в внешней таблице прямо в самом ddl прописывать полный а Location включая каталоги партиции что Ну на практике очень сложно и мало применимо поэтому мы э решили воспользоваться альтернативным вариантом когда из гпма данные переливались в не протекционистских таблиц уже в партиционирование Что позволило избавиться от этой проблемы ещё момент о котором хотелось бы упомянуть в плане выгрузки данных при выгрузки через формировалось очень много маленьких файлов Ну негативно влияет на работу hdfs поэтому приходилось после переливом к нагрузочному тестированию и здесь выявил ряд технических проблем например когда мы стали запускать параллельно Ната и нап процедур и сравнивать Результаты работы Выяснилось что порой сконвертируйте код teradata в п мог либо падать в ошибку либо работать гораздо медленнее это могло быть связано и с не оптимальность некоторых тер датов ских запросов для оптимизатора gren plam но также и с настройками самого кластера поэтому мы обратились к нашим dba для того чтобы они помогли оптимизировать настройки кластера с ум специфики работы нашей витрины и также были сложности при при обработке м процедур с большим количеством джоно внутри них например Когда джоно было там порядка п штук различных таблиц начинал очень медленно обрабатывать такие процедуры И тоже по в ошибки типа Out of memory либо recovery mode на сегментах с этой проблемой нам получилось разобраться поменяв логику работы процедур и логически разбив таблиц участвующие в джоина на части После чего чтобы у нас итоговый Селект состоял не из п таблиц А например одной основной и пяти промежуточных это позволило достаточно сильно ускорить работу подобных процедур в гнп вот также так как п является mvcc системой при изменении данных таблицы постоянно увеличиваются в размерах а команда Del не й очистке данных поэтому мы постарались где это возможно Del например без условий заменять на и также настроили запуск вакуума раз в неделю ещё отдельно хотел бы отметить по оптимизации гпма очень важно производить сбор статистик для изменяемых таблиц СБО позво Ура нельзя пренебрегать а последнее о чём я хотел сказать это настройки система мониторинга и По началу мы не смогли найти хорошую систему мониторинга для ванильного Грин плама поэтому мы пользовались логами работы нашего оркестратор записью в логи из критических мест процедур а также системными таблицами гпма такими как PG каталог вот а для мониторинга общей производительности кластера мы использовали фану А в заключение хотел бы сказать что опыт Ну что сам процесс миграции он занял нашей команды больше года и отдельно по гпму хочу сказать что в процессе работы стало понятно что это весьма а хорошая функциональная система Да со своими проблемами недостатками которые я описал уже в докладе но при этом с ней можно работать вот а для нашей команды этот опыт миграции дал э дал рост наших скилов в многих технологических стека и в принципе дал неоценимый опыт а Всем спасибо за внимание Большое спасибо за доклад А теперь вопросы Спасибо большое за доклад А у меня два вопроса Первый сколько у вас сегмент хостов сегментов и второй вы упомянули что вы обратились км чтобы они что-то там пот можете подробнее пожалуйста рассказать А так получается по сегментам У нас сейчас точно скажу А у нас а 40 узлов было из которых два мастера 38 рабочих и на каждом узле было по 10 сегментов Green plam и по 10 их зеркал вот а в части тюнинга с db тут я к сожалению не могу вам точно сказать подробности этим занимался не я Я знаю что эти работы производились но подробности Ну сказать не могу Привет Спасибо большое за доклад ри cloud.ru А подскажи пожалуйста Я немного не уловил тему Зачем вы зачем переезжали из рада в генплан судд вкладу как бы минусов больше пришлось Ну как бы пришлось больше исправлять чем было в таро дате Да и второй Аспект поменялись ли какие-то утилизационные метрики допустим там стало меньше потребление CPU рама или что-то ещё А ну получается сам проект начался м ну по большому счёту после того как внедрились после того как начали накладываться санкции и предполагалось что Обслуживание рата Может в ближайшее время сильно усложни Вот поэтому начался проект по миграции на Open Source и Вот выбрали ванильный НП для этого в плане Трик Ну могу сказать что в принципе сократилось например количество места под витрину если в teradata это было м полный объём витрины составлял Вот как я сказал 44 ТБ то в НП после переезда а объём витрины стал составлять около 30 ТБ за счёт вот работы с партиции со сжатием партиции и так далее Спасибо за доклад я Рябов Евгений из Сбербанка мы прошли такой же путь Я занимаюсь управленческой отчётностью и это одно из миллионов направлении и у нас тоже была миграция СТ на Грин Плам местами даже ещё не законченная И у меня много есть мы можем с вами вообще хоть ве день проговорить У меня есть как бы такой подковырин сильно похоже на что и мы наступа чтото даже я увидел что мы не обнаружили даже было классно полезно как бы большая основная выводя боль тире решение то чего много потом плясала у нас связано оказалось повлияло на разработку это обслуживание Вот вы упомянули что вакуум еженедельный стал это прекрасно Понятно У нас получилось чтом Ира Аминов обслуживани к тому что это даже стало влиять на то как мы разрабатываем код как мы ведём миграцию что можно что нельзя например там количество партиции способы обновления витрин сбор статистики командами который раньше на не делался и был централизованный процесс не было индивидуального и там это лучше работало чем например на мпла вот у вас вот это взаимодействие с админами с процессами обслуживания кластера какое-то влияние оказывал помимо того что они пот что-то даже как чный ящик почти не знали Ну это я понимаю но у нас вот это как бы пошло даже в сторону к разработке они пришли и сказали так делайте так вот так рекомендации такие Иначе мы вас просто выключим и всё Угу А ну да у нас тоже в принципе бывало подобное А например когда вот э на слайде где я говорил про нагрузочное тестирование аэ там у нас выявилось что большинство проблем Ну множество проблем было связано с А партиции когда у нас э запрос работает с большим количеством партий порой там бывало что доходило там до 100 или 150 партиции то с этим возникали проблемы Вот НП падал в ошибки не мог работать такие процедуры и вот помимо работы с db я также забыл тогда сразу сказать Мы также частично в тех таблицах с которыми были такие проблемы мы переработали сам механизм партиционирование чтобы уменьшить количество и чтобы оно меньше аффектив Здравствуйте спасибо за доклад меня такие больше чайников ские вопросы я делал миграцию тоже на гнп И у меня там валились там все планы потому что в Грин ПМЕ даже если делаешь подзапрос почему-то он не берёт там не подключает индекс от вот запроса когда динамически делаешь А ну ну да то есть как бы и соответственно там были там сложности и вторые как бы там сложности были Ну это вопрос номер один То есть сталкивались ли с этим как это как от этого уходили Вот и второй вопрос - Это то что у ме не такая большая там база как у вас но в любом случае столкнулись по количеству пользователей и как бы ограничения мастера вот с этими сложность сталкивались и вот такие стандартные вещи а и как как это решали Так ну вот По второму вопросу Нет не сталкивались А насчёт индексов Ну получается у нас э ветрина данных она для расчётов бизнес метрик предназначена и для того чтобы вот эти вот все алап запросы м работали максимально быстро Мы в принципе ещё Ну вот на этапе проработки архитектуры решили что от индексов мы отказываемся они у нас не будут использоваться только ключи для Ну ключи распределений а именно индексов В витрине Ну по-моему вообще нету Добрый день классный доклад чувствуется что проделали работу подскажите у меня нет такого большого опыта работы Да вообще нету с нпм вот есть Oracle есть exata да это от нас уходит и когда мы смотрим на пос и на Green plam Есть ли какие-то дополнительные плюшки или возможность оптимизации Если сравнивать пос и нпм И в какую сторону смотреть Ну если сравнивать пос и нпм тут есть свои плюсы и минусы для обоих вариантов у поса са главный наверное плюс - это то что это mpp система из коробки которая позволяет э-э а позволяет работать с масштабными витринами с большим количеством сегментов э но при этом а Green plam он использует довольно старую версию постгрес то есть ну это девятая версия она по-моему была м в 2016 году или что-то вроде того Да и многих современных функций которые есть в последней версии постгрес там нету А вот например основное вот с чем мы столкнулись это то что процедур нету И нужно было отдельно перерабатывать механизм Ну логику кода процедур таким образом чтобы можно было отслеживать ошибки потому что поначалу у нас просто пытаемся запустить не отработала А в чём дело абсолютно непонятно потому что происходит лбк И откатывается вообще всё также ещё было множество каких-то мелких э моментов которые можно было бы по-другому сделать если бы у нас э использовался под капотом более новая версия постгрес но сейчас сложно будет вспомнить точно что именно но основном вот разница именно в том что нпм просто сильно отстаёт э от постгрес именно по вот набору по функционалу который там есть Станислав Спасибо за доклад у меня простой вопрос Сколько времени у вас ушло на миграцию сколько планировали Сколько потратили и отдельная команда это делала или теми же ресурсами которые поддерживали старое решение это была отдельная команда при этом пока мы мигрировали витрину на гнп та команда которая поддерживала тиро дату она продолжала её поддерживать и приходилось То есть например какие-то были доработки по функциям переработки по модулям добавление каких-то новых атрибутов и это необходимо было отслеживать и также вносить когда подобные подобные доработки появлялись а по времени это заняло полтора года то есть началось э началось в прошлом году в апреле а вот сейчас оно э заканчивается и вот с начала года уже должна а витрина данных запуститься в прот должны с ней начать работать потребители Ну в целом у нас команда была достаточно маленькая То есть это где-то 5-7 человек в различное время Здравствуйте а скажите пожалуйста сейчас получается вы из точки А в точку б практически конечно приехали то есть с начала года уже у Вас планируется отключение полностью тра даты и сейчас вы наблю даете то что ваша витрина абсолютно корректно работает или какие-то есть ещё проблемы с которыми вы будете работать вот до конца года дорабатывать и если есть такие проблемы то расскажите пожалуйста про них с чем ещё столкнулись А ну получается да в ближайшее время терадата должна отключиться закончить свою работу А в данный момент мы до сверяя ещё последние расчёты на корректность и Ну в целом сейчас больше в последнее время больше были те проблемы о которых я в последнюю очередь рассказал в своём докладе это вот то что были технические ошибки которые исправляли вот настройками кластера и переработкой процедур в целом сейчас с этим уже разобрались и осталось вот один Челове сказа что 90% работы сделано и осталось ещё 90% Да сверить всё что недо Свер прогнать какие-то технические моменты и уже наконец-то выпустится в принципе вот так Спасибо за доклад у меня вот какой вопрос а другие альтернативы Грин пму типа шардирование а вот тут я точно не могу ответить потому что я в проект пришёл Когда уже был нпм выбран целевым вариантом и то есть наверное э такие варианты рассматривались архитекторами на самых ранних этапах но я не могу сказать точно причины почему был по итогу выбран именно НП Спасибо доклад такой маленький вопрос на одном слайде было указано указано что алиасы они ну нельзя использовать дальше алиас и решением было представлено что внутренние подзапросы формируются не проще ли разворачивать просто лясы до колонок и под запросы не делать А ну получается в там использовалось такие вот асы использовались часто Когда у нас в селекте происходил какой-то либо расчёт далее он обзывался алиа сом и использовался уже в другом расчёте и так могло происходить несколько раз подряд Поэтому в принципе можно было Вот как вы сказали использовать Ну просто повторять расчёт целиком просто запивая его в вместо Алиса уже в гнп но мы решили что тогда будет ну плохо читаемо то есть Ну я вот Мне тоже кажется что это просто мы не это Да перем в Спасибо за доклад я вот хотел спросить были какие-то трудности при миграции связанные с управлением нагрузкой на кластер вот в рода выделение ресурсов Для различных групп польва телится Были ли здесь какие-то трудности А ну вот к сожалению да На это вопрос я тоже не смогу ответить Я всё-таки я всё-таки больше разработчик А это скорее относится к dba по вот нагрузке поэтому я просто ну не касался этого момента и Ну не знаю и м второй вопрос разрешили задать а рота и гн plam ну довольно-таки похожи друг на друга системы Вот сама целесообразность миграции Вот таких довольно похожих друг на друга систем не проще ли было там выбрать скорость кликхаус или Ну какую-то другую систему не получилась ли эта работа ради работы скажем так А ну получается у нас ветрина данных она в принципе её смысл был в том чтобы рассчитывать бизнес метрики и дальше уже передавать их в другие системы для соображения а по кликхаус ну насколько мне известно кликхаус всё же не предназначен для таких масштабных э витрин и он лучше а работает с чем-то Ну более а мелким Так ну что друзья Спасибо за вопросы чувствуется доклад вызвал такой горячий отклик Тема болезненная и предлагаю докладчику Выбрать самые лучшие вопросы Из зала А так ну вопросов было очень много я уже не все точно помню А так Ну вот э Ну вот наверное ваш вопрос было интересно второй подряд Ну что спасибо за доклад"
}