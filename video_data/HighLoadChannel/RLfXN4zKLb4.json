{
  "video_id": "RLfXN4zKLb4",
  "channel": "HighLoadChannel",
  "title": "Снятие отпечатков сетевого трафика собственными силами / Николай Белобородов (Variti)",
  "views": 568,
  "duration": 3025,
  "published": "2020-04-14T11:15:17-07:00",
  "text": "всем добрый вечер меня зовут николай белобородов я работаю в компании варите занимаюсь разработкой высоконагруженных сетевых положений на си плюс плюс на пустые зил вот пока вы знакомитесь тема доклада я хотел бы быстренько спросить у присутствующих в зале кто знает что-нибудь о учили типов а utility нм и поднимите руки немного но хорошо что кто-то знает надеюсь что кто-то узнает и всех оставшихся давайте расскажу немного о том чем мы занимаемся компания варить им разрабатываем собственную систему фильтрации трафика с помощью этого продукта защищаем бизнес от adidas так вот парсинга от ботов делаем много чего еще интересного в основе всего этого лежит такой процесс как проксирование трафика или даже скажем фильтрация трафика в данном случае вот это изображено на картинке да мы пропускаем через себя достаточно большие объемы трафика разбираем его в реальном времени и принимаем решение о том пропускать пользовательский запрос а дальше либо блокировать вот в этом сером кубики границу наша логика до который в принципе говорить распространяться я не могу но мы решили открыть определенный модуль эта система которую мы используем и модуль этот называется пав до используется он для того чтобы сопоставить трафику который пришел с удаленной машины операционную систему на то есть определить реально эта операционная система либо не реально случае реальными трафик пускаем дальше в случае если операционную систему вызывает у нас какие-то подозрения мы отправляем этот трафик на дополнительную проверку есть готовое решение этого по собственное решение называется она pov да и запускается на отдельным процессом мы общаемся с ним с помощью меж процессного взаимодействия какого-то давайте просто подумаем точнее обсудим какие способы определения операционной системы бывают в контексте данной задачи а бывает так два типа это активный и представлена нам утилиты in map и например утилита экспроф да которые наверное многие не знают но есть такая почему активный эти утилиты активно сканировать сеть они рассылают дополнительные пакеты чтобы понять что же находится на том краю сети какая операционная система стоит на удаленной машине этим способом мы не пользуемся потому что как я обозначил ранее мы работаем с большими объемами трафика если мы будем на каждый пакет который к нам приходят рассылать еще дополнительные пакеты the traffic мы увеличим в разы мы пользователь пользуемся решением которые пассивно само по себе называется она это утилита называется пав не какие пакеты по сети пав не рассылает он анализирует то трафик который получает и пытается сопоставить трафику некий сетевой отпечаток по-английски это называется fingerprint да и утилиты пав есть своя база таких отпечатков где по отпечатку можно понять что же за операционную систему с пользу используется на удаленной машине помимо основной задачи это определение меня операционной системы пав умеет делать еще кое-что да в частности оценивать примерно дистанцию до удаленной машины может за детектив если между удаленной машиной и нами firewall и может тоже примерно достаточно оценить аптайм удаленной машины то есть то время которое она работает без перезапуска вывод этого телета показан на экране показан на слайде да здесь вы можете увидеть что пришел тисе пи пакет это sin пакет он пришел из интента с api адреса 7730 7031 парта 15 4 на другой on point 72 14 981 здесь должен быть слышь опечаточка дано порт 443 то есть эта цель соединения какое-то который отель этапов посмотрела на уровне тисе пи эс т.к. здесь наверное надо обратить внимание в первую очередь на последнюю строчку до которое называется сик это сильно чью-либо fingerprint это собственно и есть само отпечаток трафика здесь говорится что клиенту который находится на удаленной машине сопоставляется ну вот такая вот запись до первое поле это версия айпи протокола в данном случае это протокол api версии 4 второе поле равно 102 120 этот отель время жизни пакета дальше 8 это дистанция нолик это количество опционов в пакете версия пиво 4 заголовки дальше идет максимум сегмент сайт 1452 размер окна 65000 windows кейл и наверное в первую очередь надо обратить внимание на именно те цепи общины и квирки что такое мы сейчас обсуждать наверное не будем посмотрим на других слайдах будут примеры станет понятно да просто перечислим что здесь внутри тисе пи пакета общины содержит 4 записи это мсс но кришна операций носок квирки представлены как df и иди плюс дальше вот пример дальше будет понятно наверное и стала примера который был на предыдущем слайде всем ясно что работает утилита по в первую очередь с протоколами версии 3 и версия уровней 34 сетевой модели уэс ай да это айпи протокол иди себе протокол она porsche и заголовки этих протоколов собственно ищет fingerprint следующие три саид слайда как раз о том что такое протокола ipv4 от 60 до что просто напомню что есть вот такие вот заголовки в них есть вот такие вот поля и слева перечислена на каждом слайде какие поля утиль этапов используют для анализа случай пиво 4 это версия type of service этьен де флаги время жизни и общем случае пиво 4 это снова же версия этого 6 эта версия 6 этапов service & sean & flow и до заголовка tcp анализируются флаги размера на argent pointer и опция если кто-то будет смотреть презентацию после дата внизу справа более данной ссылочки на википедию там принципе есть исчерпывающую информацию о том как выглядит заголовки этих протоколов да можно вспомнить мы на этом останавливаться не будем мы ограниченного времени прошу вас обратить внимание когда показывал пример вывода теле этапов до больше количество информации там занимали именно те цепи общины и квирки если deception а понятно что такое тако верке непонятное вот есть пример того какие квирки используются утилиты пав и на примере давайте посмотрим вот например что такое ддв fingerprint и указывается в том случае если в флагах протокола ipv4 присутствует флаг не фрагментировать в общем то пакет донат фрагмент айди плюс говорит о том что идентификатор в протокол в заголовке протокола ipv4 не 0 1 минус говорит о том что он 0 допустим 0 плюс если не изменяет память в снова уже протоколе ipv4 есть флаг который называется мозги zero то есть он должен быть всегда ноль в данном случае он не 0 может быть такой сгенерированный трафик да и к такому трафику мы должны относиться достаточно серьезно поэтому вот это выделена отдельно отдельно полем отдельным клерком таких аверков много перечислены они здесь далеко не все но так как утиль этапов это открытый проект всегда можно посмотреть в ходе всегда можно посмотреть общее количество этих клерков когда говорил фильтрации сказал что мы начали использовать эти ли топов для того чтобы принимать дополнительное решение о том пропускать трафик дали или нет и так случилось что с ростом клиентов мы столкнулись с проблемой производительности of a что случилось он уперся в планку когда его максимально пропускная способность это сто кило ппс кто не знает fps это пакетов в секунду до то есть 100 тысяч пакетов в секунду пав может обработать это достаточно маленькое значение потому что если мы будем говорить например осин флот атаках которые происходят на сервиса клиентов то они могут составлять несколько десятков гигабит вот например в конце октября на графиках я нашел атаку которая была размером 72 гигабита в секунду до это были сплошные сен пакеты сен пакет его размер листа мне не изменяет память порядка шестидесяти двух байт если мы берем 16 машин то на каждую машину прилетает порядка четырех с половиной мега ппс да и на фоне этого всего стоит сто кило ппс это детский трафик нужно обрабатывать намного больше и собственно нам нужно было это сделать обычно когда белла готовое решение до чем оно хорошо тем что она готова и в нем есть реализован алгоритм и они отточены работает хорошо до но когда вы отправитесь в определенные ограничения вы что думаете либо развивать от решения дальше либо писать что то свое и в первую очередь конечно же мы решили не писать что-то свою развить то что уже было и мы прогнозируем анализировали те недостатки которые были утилиты пав в первую очередь эта утилита не масштабируемая то есть там используется один поток там используется библиотека пикап для чтения пакетов из сетевого стека linux все это обрабатывается в селе qte в одном потоке можно было бы смасштабировать добавить многопоточность но кот патель этапов написан на си он в принципе достаточно устаревший и вариться в рамках этого кода ну достаточно проблематично подчеркнул что можно было развивать дальше можно было добавить многопоточность вторая основная проблема была это то что плохо работает сети через библиотеку пикап я уже сказал о том что это linux новый стек да и он в принципе достаточно медленный то есть нам известны другие решения которые сильно производительные данном случае но все равно выделяем это в отдельный пункт то есть здесь что то можно сделать третья проблема утиль этапов это отдельный процесс мы взаимодействуем с ним через меж процессное взаимодействия соответственно у него утиль этапов есть некая фишечка так вот этого-то пишешь к она тоже оказалась медленной мы пытались ее как-то улучшить например драпировать сообщения которым отсылаем в эту пакеты фишечку и получать драпированные сообщение назад и наверное самой главной проблемой да если что-то можно было улучшать что-то можно было переписывать то проблему того что база отпечатков сетевого трафика которая была быть или типов она была на не развивалось все это время если посмотреть вообще когда последний коммент делал совпав это было в 2016 году если мне не изменяет память это были минорные кометы и в базу отпечатков там попал всего несколько строчек это несмотря на то что разработчики сама утилиты настаивали пререлизах на том чтобы сообщества и не только сообществом и всевозможные коммерческие проекты пытались развивать пополнять эту базу как я сказал мы какое-то время пытались улучшать да не внося каких-то кардинальных изменений но в итоге пришли к тому чтобы написать свой аналог на самом деле есть и другие аналоги например если аналоги написанной на питоне по определенным причинам они нам не подошли и за производительность в первую очередь есть аналог который является вообще модулем ядра linux он нам тоже не подошел потому что взаимодействовать с модулем нам не хотелось нам хотелось работать хизир спейси продолжать в общем мы приняли путь написать свой пол и назвали его по фиджи много сервисов которые используются у нас внутри компании написано на си плюс плюс в принципе у нас достаточно богатый опыт разработки на си плюс плюс именно высокопроизводительных систем поэтому вопрос в том какой язык программирования использовать еще для одного модуля на он не вставал достаточно остро все + + быстрая беремся prosper используем то что можно стрельнуть в ногу ну да можно но опыт подсказывает что стреляем мы не так часто плюс если продукт начинают развиваться там в конце нулевых дата последнее десятилетие говорит нам о том что си плюс плюс мы можем что использовать и как язык программирования которое идет в ногу со временем до 3 новых стандарта которые появились на носу следующий есть очень хорошо набор библиотек под названием boost на основе которого построен весь проект наш есть много позорных библиотек и free software написано как на си плюс плюс таканаси в общем берем используем так мы и поступили написали мы fng перед тем как его написать мы выделили определенное количество модулей здесь опять да и несмотря на то что утилита достаточно специализированная и вообще тема больше относятся именно к фильтрации трафика до возможно не все присутствующие в зале с этим знакомы но в целом это высоконагруженные сетевое приложение и практики которые здесь будут перечислены они наверное могут понадобиться многим я по крайней мере надеюсь на это первый модуль который мы выделили это модуль по работе сетью я говорил о том что вот этапов работать сети через пикап да это достаточно медленно можно быстрее о том что там внутри я расскажу чуточку попозже второй модуль это модуль каширование с каждым потоком данных которые проходят через нас и через утиль этапов мы ассоциируем какие-то свои объекты временные объекты ну например поток данных да он пришел с какого-то одного inpa это с одной море молот машины и шоу на какой-то другой inpointer говорим о от машины для этого нужно сделать запись нужно анализировать состояние потока если говорить о протоколе тисе пи то соответственно там есть какая-то стоит машину внутри когда мы получили сен на сильными в ответ получили sinok на sin ок ок и так далее если происходят какие-то нарушения дата этот объект удаляется из кашей если он соответствует данному конечного автомата он там оседает на какое-то время показывает что соединение между этими двумя машинами валидны конечно же нам понадобился модуль логирование да куда без лагов нужно детектив ошибки нужно их анализировать исправлять будущем понадобился нам модуль для сбора метрик да потому что объема трафика большие они достаточно частотные хотелось бы это все наблюдать на мониторинге быстро реагировать на происходящее и мы подумали о том что нам нужен более быстрый интерфейс взаимодействия более быстрая . потому что наш по фиджи замена пав это тоже отдельный процесс с которым мы общаемся через низ процессное взаимодействие давайте перейдем к модулю при работе сети сетью и я говорил о том что пикап медленный стек ядра сетевой стойке троллинг тоже медленно и как это проявляется проявляется это на гигабитных сетях из это примерно после шести гигабит после 7 с помощью пикапа вы теряете до 30 процентов пакетов да и мы говорим о 10 гигабитных интерфейса в первую очередь нас от не устраивает но не везде можем отказаться от этого стека и допустим перейти где 5 кей где-то мы используем например виртуальная машина дядя петя кеннету где-то мы используем определенных ароматное ограничение например у нас не заведен отдельный сетевой интерфейс куда мы дублируем трафик который анализируем потом поэтому пикап мы оставляем как обратную совместимость и как возможность работы virtual koch в первую очередь но в 99 процентах случаев на наших новых мы используем dippy детей это int лавский сетевой стек который позволяет работать сетевой карты напрямую мину и системные вызовы и в общем сокращая время работы при печи пакета на 10 гигабит ах там потерь пакетов порядка наверное одной десятой процента до 30 процентов и одна десятая процента разница большая после того как мы получаем пакет мы его обрабатываем модуль каширования заносят объекты связаны с этим пакетом в хэш-таблице да и таких хэш-таблиц на самом деле у нас три после того как мы получили пакет мы регистрируем объект под названием flow это информация о том откуда этот пакет пришел и куда он шел но есть отдельно хэш-таблицу где мы можем вставить запись удалить запись изменить запись и поискать запись после того как flow был зарегистрирован до возможна другая операция после того как нам пришел следующий пакет соответствует конкретному потока данных то есть из того же самого in point of тоже самое на другой ремонт машины мы можем увидеть что например на сян сян а к не пришло пришел ок да странно в этом случае из хэш-таблицах flows мы удаляем такую запись после того как мы зарегистрировали потоки данных мы хотим посмотреть какая же все-таки операционная система используется на удаленной машине откуда пришел этот пакет в это кружочек матч матч fingerprints вот строим хэш пакета обращаемся в таблицу в которой находится fingerprint и по сути это наша база аналог база которая была в pov да и если произошел matching the в таблице с хостами это 3 таблицу да мы регистрируем данный хост данный and point с которого пришел пакет и сопоставляем ему fingerprint до вот таких вот подход потоков данных у нас много в том плане что мы хотели масштабироваться до и слипов был один поток то в наш utility по фиджи количество потоков мы наращиваем чтобы не знаем пытаться увеличить нашу производительность как-то пропорционально количество потоков да то есть из тех 100 кило ппс которые у нас были в pov получить например с ростом потоков до 4 до 8 соответственно четыреста кило ппс там или 800 тела по пояс обрабатывать больше количество пакетов и при написании модуля каширования у нас возникли следующие проблема как только вы добавить туда многопоточность первое это то что те таблицы которых я говорил да это является неким общим ресурсам для всех потоков и изначально они висят на одном и том же объекте синхронизации соответственно все потоков все потоки попираются при записи при чтения в таблице в один объект синхронизация это узкое горлышко до оказалось помимо всего этого что скорость вычислениях и шей пакета тоже может влиять на ситуацию в целом может влиять на производительность потому что то хэш функция которая например используется стандартной библиотеки си плюс плюс да это мур махеш она достаточно медленно также по мере наполнения таблиц хэш-таблиц мы столкнулись с тем что они разбухают они пристраиваются внутри и если перестроение в случае например вектора когда вы достигаете его кпк пасти происходит на прозрачного увеличивать размер 2 копировать и память то случается хэш-таблицы это еще более дорогостоящую операцию и мы столкнулись фрагментации памяти и вот сейчас по всем этим вопросам на следующих слайдах будут ответа как мы все это дело решали добавили на копа точность столкнулись с проблемами первая проблема это скорость работы хэш-функций да я сказал что мой more cash которая используется в стандартной библиотеке он медленный мы нашли проект под названием с сэм фишер есть он на гитхабе внутреннего собрано очень много хэш-функций все это оформлено в тест кейсов с ю это да и есть определенные данные результатов этих тестов и результатам работы этого проекта является то что определен конкретный список хэш-функции которая является достаточно быстрыми точнее максимально быстро me при этом они не теряют в качестве это вот те шесть функция которые здесь указаны на слайде помимо этих функций есть на самом деле еще несколько но они платформа зависимые мы остановились на функция который называется ти иваныч ай да и ананас принципе после синтетических тестов удовлетворила ну стали использовать проблема синхронизации дом доступа хэш-таблицы изначально как только мы добавили много потоков да у нас было все еще одна хэш таблица с потоками данных с хвостами и один объект синхронизация чтобы не висеть в этом объекте синхронизация постоянно мы взяли использовали шарди рование на разбили то множество ключей которые изначально у нас была в таблице flows и в таблицах ос на подмножества каждому подмножество выделили свой объект синхронизации каждый подмножество оформили в отдельная таблицу сразу скажу что количество шагов конечно же должно быть достаточно большим но при этом подобрать его конечно же нужно определенным образом заранее чтобы не упереться во всевозможные проблемы связанные с памятью точно такая же таблица для hao staff и точно такой же способ это сортиром я говорил о том что потоки данным данных большие таблицы вот эти которые я приводил на предыдущих примерах разрастаются до рано или поздно они перестраиваются проблемы перестроения решить наверное эффективно достаточно сложно мы от нее отказались в принципе мы резервировали сразу заранее при запуске утилиты по фэн г определенное количество объектов внутри каждой таблицы и пытались его никоим образом не превышать по достижении максимума запускали чистку удаляли наиболее старые объекты с таблице мы не перестраиваем на это не тратим ресурса цикл проблема фрагментация памяти до так как объекта у нас очень часто создается и очень часто удаляется то есть на каждый пакет возможно мы регистрируем новый объект в таблице потоков данных таблицы хостов возможно на каждой мы удаляем то при частом вызове функции оператор new оператор делить у нас возникает как мин тация памяти со временем оператор него оператор делить работают все дольше и дольше чтобы не заниматься такими вещами постоянно объекты так как у нас хэш-таблица предопределенных размеров до мы выделяем в полу объектов берем объект память подобъект и спала когда нам необходимо возвращаем назад когда мы закончили использование операция взять вернуть сильно быстрее чем использовать оператор не выделит тем более когда память стала фрагментированного времени для пула объектов мы используем boost bus пол и там есть локатор под названием boost пол локатор все это очень хорошо строева надо ритмов прозрачно просто нечего здесь особенного делать не нужно модуль логирование ничего интересного здесь особо нет потому что мы решили не логировать частотные данные решили логировать только всевозможные ошибки предупреждения фатальной ошибки до для 3 сообщений дебаг сообщений создать отдельный флаг которая при передаче ватель этапов начинает использоваться при написании в лоб вот в данном случае это используется для отладки да никогда это на проводе никогда в релизе не запускается поэтому услуг является неким лак не является каким то неким узким горлышком используем его как есть но конечно же нам нужно постоянно куда-то говоря говорить сообщать информацию о том смогли лим раз парся трафик какие пакеты к нам пришли сины сенаки какие тому подобное делаем это с помощью метрик лагерным только самый необходимый минимум модуль по сбору метрика ну если те проблемы которые говорил для бус logo явления актуально потому что вы просто не стали тот описать данные то для модуля подбора метрика проблема частого обращения из разных потоков достаточно актуальна используем а графит для него мы написали свою оговорку на си плюс плюс который является полностью lock free оберткой мы аккумулируем данные у себя в лоб три переменных на протяжении 1 минуты собираем статистику по какой то конкретной метрики 1 минуту эту метрику отправляем пдп графит power графита у нас накручено grafana с красивыми графиками есть такой маленький нюанс до графит у нас использует все подсистемы и каждую минуту они отправляют эти данные на сервер и здесь возникает проблема когда все одновременно они пытаются туда что-то отправиться с нами какие пакеты могут потеряться сервер может например нагрузиться мы используем как которая делает смещение отправляем и пакеты не каждую минуту неровно каждую минуту до календарной минуту делаем маленькое смещение например там минуту + 5 секунд а минут вопрос 15 секунд и так далее то есть разводим наши модули между собой и с графитом они пытаются общаться как то более равномерно метрики мы собираем они используются как нами на делом аналитики интеграторами системными администраторами для детектор проблем принять какого-то решения о том как эта проблема устранять также используется эти метрики и клиентам в личном кабинете у каждого клиента которые работают с нашим наша система фильтрации есть графики по уровням р3 и р4 кому-то они нужны кому-то они не нужны все зависит от того какие системные администраторы есть у этого клиента то есть если они хотят более детально понимать что же за трафик приходит крем пожалуйста у них есть такая возможность дальше будет два слайда с собственно теме метриками которая есть внутри нашей системы внутри paw in g это метрики касательно протокола ipv4 и ipv6 смогли мы распарсить не смогли расспросить заголовки и метрики которые относятся к протоколу tcp здесь их сильно больше ну не знаю можно наверное обратить внимание на то что есть группа метод связано с тем прошел matching пакета или нет да причем матча как мог пройти один в один например fingerprint fingerprint соответствующие этому пакету текущему пакета максимальному подходят да и мы точно можем сказать что там на том конце например используется операционную систему под названием windows xp мог пройти мачин с более слабыми условиями это generic мальчик и еще более слабыми условия метафазе matching вот так же можно посмотреть на то в принципе просто проанализировать протокол tcp что приходит какой трафик приходит нам например можно выявить syn flood на можно увидеть что нам определённый момент начинают приходить сильно больше сынов до в ответ отправляются syn-ake акков при этом нет выглядит это примерно вот так это так и который которой я вам говорил 72 мега ппс здесь на самом деле 5 мега ппс указывается на самом деле просто графику среднем до в минуту здесь видно что произошел скачок сынов графиком мониторинг звенит система аллигатора обращает это внимание смотрят что делать дальше ну и давайте перейдем наверно к последнему модулю модулю это называется интерфейс взаимодействия да я говорил что интеграция с утилитой пав изначально за тр1 а потому что-то пишешь к которая там была она медленная там использовался тисе пи socket и была вторая возможность использовать у них socket да и если мы говорим о сто кило ппс который ватель этапов пропускала изначально то здесь с нами способности отписки примерно на тех же значениях до в случае тисе пи ссориться со чи сок это это чуточку быстрее мы решили взять наверное максимально быстро и известный нам и трофей взаимодействия называется он им kill это очереди линуксовые да они позволяют пропускать больше двух миллионов ппс в секунду и если сделала дополнительных ок и например группировать сообщения это то что мы пытались сделать изначально суть или type of да когда пытались использовать описывать это unix socket то здесь можно выжить больше например на два порядка то есть это не является узким горлышком на равне с выбором нашего сетевого интерфейса на 6 ласты когда dippy детей и api это не узкое горлышко узкое горлышко это все-таки обработка данных в многопоточном масштабируемость среде и работа с таблицами в итоге мы получили такой результат до 1 мы провели два теста в 1 колоночки у нас оригинального тилль этапов которая выдавала порядка ста кило ппс об этом не говорил далее в каждой колоночки утилита по фэн в скобочках указано количество потоков и на одном потоке только на одном потоке телефон наши утилита по фэн г смогла получить показать трех кратный прирост производительности до если изначально время было сто кило ппс не время количество обработанных пакетов то получили мы двести восемьдесят пять кило ппс в худшем случае худшем тесте да это две целых восемьдесят пять раз производительность увеличилась дальше собственно у нас появилась возможность масштабировать использовать многопоточность мы посмотрели как это работает на 2 4 8 потоках и случае 8 потоков производительность у нас выросло более чем в 14 раз и составило она почти полтора мега ппс да я вам говорил об атаке в семьдесят два мига ps там народу на 16 нот прилетает четыре с половиной мега ппс здесь пав умеет обрабатывать все лишь полтора на 8 в потоках соответственно что мы можем сделать чтобы атаку обработать собрать по ней статистику отобразить граффити в графа не показать пользователю и самим и проанализировать мы можем нарастить количество нот например 16 до 32 мы можем добавить потоков на наших серверах используется семьдесят два потока да то есть из этих 72 допустим взять 16 и увеличить производительность еще представляется возможным более чем возможно в итоге наверно можно подвести итог и сказать о том что тот прирост производительности которые мы изначально хотели получить и мы его получили до наше приложение масштабируется мы можем его подогнать под пользовательские данные под количество трафика это хорошо за счет чего мы сделали за счет многопоточности в первую очередь далее мы сделали шарды для каши и до наших хэш-таблица уменьшили время синхронизации то есть какие-то дополнительные оптимизации до которые понадобились нам при переходе на многопоточность стали обрабатывать больше трафика стали больше обращаться в утиль этапов энджи для этого взяли заведомо быстрый и заведомо более чем производительный интерфейс взаимодействия названием им киев ну и собственно для чего все это задумывалось для того чтобы начать с самим работать с отпечатками трафика на пополнять свою базу данных с этими отпечатками возможные в будущем отдавать сообществу коммитить впав в общем результат был достигнут там на протяжении слайдов внизу справа были ссылочки да там на полное мы по нато как выглядит протокола пиво 46 цепи в общем все эти ссылочки перечислены здесь если кто-то будет смотреть презентацию позже я думаю что можно по ним пройти очень быстро и воспользоваться освежить знания собственно на этом все больше вопросу до как мы будем звать вопрос вопросов будет возможным лагоса нет я даю микрофон вы встаете и и за эти вопрос без микрофона просьба не говорить иначе на камеру не слышно здравствуйте спасибо за доклад слайд с модулем метрик там был такой 10 что вы пишете в графит 1 минуту до то есть вопрос почему так а именно интервал и как это связано с нагрузкой на карбон и если это тестировалась то какие-то величины были давайте по порядку параметр того как писать как часто писать 1 минуту там две минуты так далее он задается в качестве аргументов командной строки пишем 1 минуту исторически наверное это связано в первую очередь с тем что все остальные модули тоже пишут 1 минуту и смотреть статистику 1 минуту но как-то все к этому привыкли чем чаще тем лучше чаще чем минута плохо раз в десять минут не такое быстрое реагирование на происходящую ситуацию в карбон на карбон мы используем графону с карбоном есть такие проблемы то есть если разработка хочет посмотреть на метрики и обычно делает это в обход дашбордов grafana через как раз напрямую графит и карбона подтормаживает да но там и динамика не нужно ты просто смотришь на ситуацию в целом за отведённый отрезок там последние допустим несколько часов этого достаточно спасибо спасибо николай спасибо за доклад на вопрос такое железу который используется на серверах операционной системы вот можете сказать большой большую боль что по персонаж системам нет аппарат надо это зиона ясно и вот еще значило просто такой вот ну понятно что приобрел пакет в 9-ке используя причем то далее пустые живот упомянули об этом не очень понятно но стэйшн в данном проекте пустые же не используется действительно используется малая часть связана с пашин например and point of понят только это и вот еще следующее что вы говорили там про хэш-таблицы про проблему функции расчет стандартно стандартную хэшей там в принципе библиотеки физики она же активно развивается то есть там много все из коробки если хэш-таблицы и функции просчетах по расчету хорошо то есть они анализировали то есть вообще как там вот если взять вот стандартный 9 если взять и используете вы уверены что хоть сумочек сумма наверно там есть hash значит с этим знаком хорошо они отлично папа хенге принтов я так понимаю вы свою базу собираетесь с учетом того что вы знаете какую адам оборудование у клиентов какие машины до нее вы можете сопоставить да там словно какой-то fingerprint и то есть вы должны обладать знанием какая операционка есть иначе они не сможете подобрать так мы не знаем какой операционной системы используется клиентами точнее конечного подмножество нет может использоваться любая конечно же мы знаем что там на том конце и то как мы это определяем я вам не расскажу из индии нет но захотелось узнать вы как-то это определяете делайте догадки или все-таки условно ну как обычно там сначала обучается система да потом уже на произвольных данных работой то есть это понимаем с обучении используется или просто без обучения у нас есть ли обучение обучение в общем мы сопоставляем много критериев если как бы в энтом по трём из них да там или по 5 то можно делать из 10 ok по 5 и 7 это можно сделать предположение что это именно то операционная система котором говорим есть есть определенные мышь лёнинг накопления статистики аналитик все это есть и вот еще постоянно просто хорошо сказали что не может это там разглашать по поводу к операционной системы будет то есть было ли такое что приходилось обновлять операционную систему на серверах и как-то влияло на работу приложения ну это же не один сервер это целый кластер и ни один кластер соответственно происходит на миловидным образом по порядку балансер отвечают за то чтобы a person систем обновляется на конкретной ноги на нее балансер не отправляет трафик да я просто закончилось обновление я просто из низ вопрос то есть вот моему опыту же у нас в проекте тебе дикие активно используются и у нас проблем было что после обновлений операционной системы с red hat 6 in 1 по 7 то есть был просадку производительности где-то порядка десяти процент нади в приложении целиком то есть там все подсистемы бикини то есть и вот пока вот решение правления нашли только увеличение частоты у нас было такое обновление до и мы не заметили просадок спасибо за вопрос в общем подумай над этим на самом деле сам до хочу напомнить что у нас сейчас этот вопрос и они дискуссии если вы хотите сдать о какой-то более широкий вопрос у вас будет возможность перейти в дискуссионную зону спасибо спасибо артем гречанка куратор labs слушайте но все-таки среды хата 6 на центр 7 это не обновление эта миграция да ведь давайте так там очень много чем могло поменяться можно насладиться результатами пожалуйста на таблицу да это ожидаемый вопрос ну как бы 72 мега пакета хорошо вот я сейчас заглянул нашу графа ну увидел 220 а так вообще было до 450 если вы из одного сервера снимайте полтора мега пакета означает что для отбытия такой атаки вам нужно 300 физических серверов а это скилл на котором нам интереснее ну аудитории холодна верно было бы интереснее слушать как вы управляете таким флотом чем как почти утилиту я просто к чему есть понимание как эту цифру спилить дальше ну хотя бы там в двадцать тридцать сорок пятьдесят раз потому что полтора мега пакета сервера это смешно я понимаю что вы можете добавить потока в ней сервер как бы тоже еще чем то занимается помимо обработки плохо так что ну это реально странные цифры вот то есть если по нему я перефразирую вопрос если понимание как вот эту цифру растить дальше понимание такого нет поэтому на определенной стадии мы просто считаем трафик то есть внутри нашего флага к связано с тем что она смотрит деда сад эрниди доз да и в пределенный момент трафик режет мы теряем в статистике соответственно в граффити начинает отображаться далеко не та картина которая есть на самом деле ну дополнительными метриками мы указываем на то что эта ситуация не стандартам да мы не можем обработать такой объем трафика правильно или понимаю что ввиду этого путин флудом вы перестаете уметь отличать windows будто длину забот если syn flood идет потому что позже не работает что вы его отключили windows бота длину работа но если у вас detect операционной системы ну или между операционными системами если под всем флотом of у вас выключается поскольку у вас нет достаточного не отключается пав режет только тот трафик который относится к сен флоту ну хорошо я понял спасибо хорошо в общем это работает не так как многие хотели бы чтобы то здесь работала есть нюансы действительно такой трафик мы не можем обработать поэтому моё теряю добрый вечер меня зовут андрей штамм волк большое спасибо за доклад несколько коротких вопросов первый вопрос вот вы упоминали именно класс там на и построение системы вы между нодами в кластере а именно данные по словам синхронизируйте или каждый надо помнить только свой набор что касательно по фиджи я не уверен что могу ответить на этот вопрос с точки зрения день мы можем поговорить после там есть человечек менеджер он подключится следующий вопрос вас вообще имеет ли упав работать его симметричном режиме у нас входящий трафик ходит допустим через ноды с пуфом исходящий патентов другим путем абстрактного другим апстримом упав а три режима в режиме сен то есть когда мы пытаемся с кем-то соединиться все на когда пытаются соединиться с нами собственных соединение установлено до pov если вы выбрасывать какую-то часть он остается в одном режима из трех лича умеет но не на все сто процентов есть какие-то плоды они регистрируются им сопоставляются операционная система fingerprint еда заработает но как бы будет ли это идеальная картина мира не факт на этом наши вопросы к сожалению заканчиваются потому что время этой венге извините дал ай да сжигать нельзя и по традиции наш конференции спикер выбирает самый лучший вопрос из тех которых был чтобы вопрошающего немножко наградить вот этот человек задал самый каверзный вопрос помойку тогда этот человек получает небольшой презент в виде игрушки от нашего партнера wargaming и книжки но и соответственно ваши награды то что вы пришли на нашу конференцию и выступили со своим докладом пусть вы с пустыми руками не уйдете тоже спасибо уважаемые слушатели уважаемая трансляция на этом сегодняшний день транс сегодняшний день лекции заканчивается прошу всех в 18:30 перейти в конгресс холл где будет вручение премии и после чего обещают турнир по игре counter-strike go и надо все спасибо большое и если он нужен будет спикер дискуссионная зона ждет вас"
}