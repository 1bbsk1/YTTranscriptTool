{
  "video_id": "6e0wzxnUGuE",
  "channel": "HighLoadChannel",
  "title": "Open sourse - трибуна",
  "views": 372,
  "duration": 3663,
  "published": "2023-01-19T05:55:16-08:00",
  "text": "у меня слайды будут формате истории потому что формат не позволяет дать много технических деталей но думаю будет интересно сначала немножко контекста моя работа в команде тарантула тарантул это президент на марио хранилище и в тоже время это серой приложение мало то что это терапия ларина лу это важно на самом деле для вот этого доклада в какой то момент мы добавили поддержку синхронной репликации и висите и у нас стал вопрос как софт на с функциональность тестировать вот мы рассмотрели тестовой фреймворке изучали вопросы как это делают для других баз данных и мы на самом деле обед мне кажется было естественно остановились на фреймворке джексон для которые используют для хаос тестирования доказал свою эффективность вот мы сделали несколько тестов и добавили их неправильно интеграцию для тарантул а еще немножко контекста если кто не знает джексон это популярный тесты from work который заработал кайла кингсбери и он же тестируют разные распределенные системы и базы данных и публикует отчеты о том насколько модель консистентной sti для этих баз данных и их уровни изоляции соответствует тому что написано в документации эффективность от этого фреймворка доказано отчетами которые call публикует и проблемами которые он с помощью тестеров реворка находит но на самом деле у джексона есть один существенный минус это то что библиотека написана на языке кожа кожа это один из вариантов лист на подобный язык для java машины это не самый популярный язык программирования вообще в индустрии и тем более не самый популярный язык для разработки тестов у нас не было экспертизы по этому языку в нашей команде поэтому я эти тесты написал и скорее всего бы я бы эти тесты и дальше поддерживал потому что у команды не было ресурсов чтобы еще изучать новый язык для того чтобы поддерживать и разрабатывать новые тесты и еще один момент то что не было хорошего качества на коннектора для тарантула коннекторы это возможности использовать функционале сторона подключаться к нему из другого языка то есть эти коннекторы были но они были не совсем полноценные и их нужно было еще дорабатывать и по поводу минусов джексона в том что написано на языке кожи высказывается и другие инженеры которые пытались писать тесты для джексона если декомпозировать джексон на несколько частей то он состоит на самом деле из двух основных частей это первый это тестовый фреймворк непосредственно который позволяет описать тесты в него включаются смага теле функции для установки базы данных так так скажем подготовительная часть это генератор операции функциональном стиле для того чтобы генерировать операции который будет отправляться распределенную систему или в базу данных и код для реализации сбоев так называемых не месяцев в терминах джексон и 2 наиболее важная часть это checker и то есть 1 часть библиотека для тестов она непосредственно реализует тест который после выполнения оставляет историю операций которые отправили в базу данных и результат выполнения всех этих операций а вот вторая часть checker и для проверки к соответствие выбранной модели константой костенко sti они вот эту историю операций который полить и получили после теста они проверяют на соответствие выбранной модели консистентной sti и для этого есть две другие библиотеки тоже написаны написанные кайлом это рык нос с вот они тоже написаны на коже и соответственно во время разработки теста вы используете jepsen для самого теста и используйте примитивы модели описанные валик насоса для того чтобы проверить полученную историю операций если так разделить джексон вот на две части то можно попробовать приписать и ту и другую части тем чтобы можно было их использовать для друга в других языках я переписал джепсен нала и что мы получили тот же самый язык который используется в тарантул то есть у нас все тесты и так написано лова и библиотека джексон лайк тоже написанного используется генератор функциональном стиле на базе модели мулов on минимум зависимостей и вместо вытесняющей многозадачности использовать кооперативная задач насти с помощью файтеров реализованы в тарантул со второй частью было немножко интересней так как у кайла есть и две библиотеки для реализации ч киров они написаны на коже и эти checker и нельзя используйте извне я то есть например с помощью других языков я написал утилиту которая использует эти две библиотеки но представляет интерфейса командной строки принимает историю формате json проверяет ее и выдает вердикт потом соответствует совет соответствует ли истории операций выбранной модели костенко sti и на выходе получил так называемый джобсон с человеческим лицом который можно использовать человеку без знания кожи спасибо вопросы ну если и вопросы есть поднимать руки не стесняйтесь моя только геном на вопрос на сколько вашему бизнесу в итоге помог голова это решение на самом деле сейчас есть я тесты которые написал для иску light для того чтобы просто проверить ну то что чтобы продемонстрировать что вы билетик работает у отеля тарантул еще в процессе разработки тесты потому что у нас часть тестов также написано кожи ну изначально kb написал вот я пытаюсь сейчас их переписать для тарантула вот и потом в перспективе как бы заменить джексон тесты которые мы написали 1 до сегодня я буду рассказывать про light of time или то наша библиотека для автоматического машинного обучения и на самом деле скажу что сегодня представляют две новые функциональности которые light of time или появились за последнее время и ещё нигде не были презентованы так что вы сегодня будете первыми слушателями информацию об этих возможностях собственно по содержанию наверное не будем останавливаться до но вкратце расскажу о том что такое light ft mr зачем им нужен бизнесу и собственно расскажу про 2 новые возможности это собственно работа с цепью и с парком и так что такое light html это непосредственно кроссплатформенный модульный фреймворк который позволяет строить автоматическим образом модели машинного обучения поскольку я к сожалению могу показывать на слайде кликером соответственно в левой части картинки увидеть входные данные и путем сложные или несложной черной магией миля вы получаете на выходе предсказания и чуть ниже представлен блок который отвечает непосредственно за выполнение этой самой модели но все это скрыто от вас внутри некоторой интересной черной коробке которая собственно и называется light html и мы уже подготовили заранее пресеты для решения различных задач на текущий момент существует много различных бенчмарков в сфере html и вот на одном из них вот adsl такая достаточно широкой в россии сети дантистов мы занимаем первое место по качеству и скорости но помимо этого мы обладаем достаточно возможной достаточно глубокой кастомизацией соответственно у вас есть уникальная возможность записывать свои модули блайт автоэмаль на основе вашего опыта ну и конечно целевой аудитории для нас являются как ds и так и разработчики которые хотят собственно решать задачи м.л. ну и в самом низу есть ссылка на наш гид х где собственно можно посмотреть икоты примеры они все полностью доступны поскольку это все-таки open source решение итак чем вообще light автоэмаль полезен для бизнеса во-первых он кратко аккуратно сокращает время от идеи до реального production решения во вторых за счет кастомизации у нас есть возможность внедрять различные соты решения во внутрь html без изменения реальной интерфейсу да с которым взаимодействует сам пользователь во-вторых мы в третьих мы действительно можем повышать качество тех моделей которые строятся на разных бенчмарков на разных пепел соревнованиях нам удается добиваться результатов порядка топ 10 процентов и выше помимо этого автоэмаль открывает уникальные возможности для работы с так называемым длинным правом хвостом то есть позволяет решать много экономически экономически невыгодных и мыльных задач до которые складываются в единую бизнеса вую задачу которая уже стоит достаточно много денег ну и конечно за счет того что это автоматизированное решение вы можете достаточно быстро тестировать свои гипотезы до проверять новые dtc ты смотреть насколько все работает и внедрять иль не внедрить в продакшн ну и за счет того что это опять же автоматическое решение мы можем попрощаться с так называемой моделью на века которая сейчас очень актуальна в различных компаниях до поскольку dots on this не может каждый день обновлять свою модель соответственно это можно делать автоматически для тех кто хочет существенно глубоко погрузиться внутрь light of time или здесь представлены ссылки на три части нашего курса вот собственно можно в них погрузиться и посмотреть как автоэмаль работает с различными задачами а для тех кто не любит смотреть вебинары и решать практические задачи но любит читать статьи снизу есть ссылка на нашу архивов скую статью по собственно light of time или и его внутренностям ну и собственно перейдем к самому вкусному первая из них это light of time на джипе you что вообще стоит внутри то есть слева на слайде видны те библиотеки которые мы использовали для того чтобы реализовать полностью джикию pipeline то есть фактически все что есть засовывается на джипе юху и соответственно там работает но если наверное самого интересного хочется выделить это гибридный при processing данных как мы видим здесь mondas овский dataframe превращается в соответственно купив на или доску df ный dataframe за счет того что разваливается на разные джипе юхи какой-то кусочек может остаться и на цепью и там обработается вот и соответственно превратиться в итоге в полностью джипе южный dataframe с которым автоэмаль дальше будет работать ну и конечно параллельное обучение моделей да то есть у нас есть возможность параллели ца как о джипе ухом так попал дам так и по данным в данном случае на слайде видно как как она параллель отсюда по конкретным соответственно джи пи юфу mafalda вот и собственно внизу слайда опять же приведена ссылка на репозиторий в котором на текущий момент да уже есть доступная версия light of time или на джипе you но конечно в теории это все хорошо да но всегда интересно посмотреть как это работает на практике и мы просто взяли несколько конкретных дат ассетов один из них приведем здесь на слайде это fashion вниз достаточно известный dts точки зрения бенчмарков это картинки разных предметов одежды развернутые в семьсот восемьдесят пять столбцов да то есть 784 это картинки 28 на 28 развернуты в столбцы и соответственно последняя колонка это торги вот ну и 70 тысяч таких объектов нам надо каким-то образом по классифицировать если мы все это делаем насыпью то получается вот такая вот синяя стрелочка да там подписано в секундах сколько что считается то есть видно что она достаточно длинная да и работает это не супер быстро но опять же отрабатывают в автоматическом режиме однако если мы переходим на джипе you и собственно работаем дальше на ну со всеми этими данными исключительно на джипе you то есть в данном случае на те слева 100 то она нагружается полностью или фактически полностью и мы получаем ускорение в шесть с половиной раз вот если мы за юзаем 2g пью поскольку наши вот это решение да умеет работать multijet ее режиме соответственно мы можем получить ускорение в девять и три раза и это в принципе достаточно хорошие цифры как для ускорения обычного мыльного pipeline а на джипе ю ну и собственно переходя к 2 вкусной части да это собственно лама нас парке или slo-mo как мы ее обозвали это распределенная версия ламы которая сейчас работает под с парком версии 32 и выше в ней пока что реализован так называемый тбр присед это наш основной присед который как раз используется для решения мыльных задач она написана вся эта библиотека написано на по из парке и частично для максимального ускорения на скале вот и собственно в правой части слайда видно как выглядит весь pipeline который в итоге превращается в конкретное решение применимо и на новых входных данных ну опять же в низу слайда видно ссылка на сам репозитории который может вам помочь да если вы хотите применяться на спарке кратко пройдусь по основным особенностям которые здесь есть их на самом деле достаточно много и все они конечно по очевидным причинам на слайд не поместились но по основным моментам мы все так же старались максимально ускорить весь этот pipeline поэтому очень не часто использовали чекпоинты старались максимально все кэшировать старались уходить от так называемых джонов и брат костов которые все нам портят написали кастомизированные стринги string yandex.ru на скале для того чтобы все единовременно запихивать в этот индекс р и соответственно при добра батэ вать признаки ну и собственно получить итоговый автоэмаль трансформер до который поддерживает как сохранение так и загрузку с диска ну и соответственно дальнейшую применимость на реальных данных ну и собственно если вы уже умеете пользоваться ломай или научитесь после прохождения этого курса который я показывал до или почитайте статью посмотрите туториалы то как видно здесь слева расположена запуск обычной ламы а справа соответственно запуск slam и то есть как видно по кускам отдельным эти запуске фактически полностью совпадают то есть переписать запуск одного в другой фактически не представляет не представляет каких-либо трудностей но опять же интересный вопрос что это дает реально на практике здесь мы начинаем говорить о том что теперь машинное обучение начинают уметь работать с миллионами с миллиардами строк и так далее на левой картинке мы видим что в самом начале красному отображено обычная лама которая работала на dt сети в сто миллионов строк вот и мы в данном случае взяли ее за некоторую единицу да и она вот отрабатывал за 11 часов соответственно если мы начинаем использовать кластер и начинаем использовать собственно славу то конечно чем больше у нас есть экзекуторов да тем больше получается ускорение ну и вот в данном случае да в самом максимальном режиме когда у нас 16 компьютеров у нас получается ускорить обычную ламу на этих 100 миллионов строк да ну примерно в девять и три раза и собственно справа есть такая же история по размерам data set of и по ускорению как мы видим чем больше у нас данных тем боле тем более скажем так наклонной становится эта кривая да она перестает выходить на плато и собственно становится очевидным до что чем больше у нас данных тем ускорение становится все больше да и фактически вырастают вплоть до линейного ну и собственно подводя итоги во-первых до light of time and open source инструмент для dc in this тов для разработчиков и для аналитиков вообще говоря мы его разрабатывали с той целью чтобы у любого д с а была возможность построить типовую модель машинного обучения на обычном ноутбуки минут за десять с качеством достаточно неплохим на текущий момент дамы топ-1 по качеству в сфере html и теперь это еще и фреймворк из коробки для построения джипиэс парк pipeline of которые позволяют нам получить кратное ускорение работы при решении различных и мыльных задач ну и собственно на предпоследнем слайде я привел большинство ссылок которые вам скорее всего понадобятся если вы захотите более подробно разобраться в теме это как ссылки на репозицию репозитории так и на доке на канал с нашими новостями собственно из которого можно будет много еще куда попасть ну и на этом у меня все буду рад ответить на ваши вопросы если вдруг они есть ну как минимум ни один есть задам тонн постараюсь 10 минут на разработку сколько времени нужно будет потратить чтобы обучиться всему этому с нуля на самом деле с учетом того какое количество кёрбалов сейчас есть на гитхабе на кабеле и еще много где в принципе я думаю что часа наверное хватит на то чтобы разобраться в том как запускать базовой pipeline и какие у него есть особенности какие возможности по кастомизации у него есть и соответственно как их можно подтюнить под конкретную задачу если вдруг не устраивает качество решения прям вот из коробки совсем вот поэтому я думаю что вот ну как бы просто научиться им пользоваться можно наверное за час времени а то и быстрее вот если хочется погрузиться скажем так в большие глубины то здесь уже можно обратиться к тому самому нашему курсу и там на самом деле в подробностях разобраны и различные возможности которые у light автоэмаль есть включая и на пышные северные задача да то есть это задача на текстах и задачи на картинках эта задача of the uplift это возможность в строения интерпретируемых моделей и собственно наверное что самое интересное для таких как бы людей специалистов в своих областях это возможность собственно кастомизации решения фактически мало кто сейчас вообще в принт в принципе такую возможность предоставляет но у нас такая возможность есть и собственно человек может на основе какого-то своего опыта дописать дополнительные модули которые позволят его конкретные задачи решать лучше ну и конечно мы очень ждём контрибьютором в нашу библиотеку которая собственно допишу да какие то свои модули и будут готовы поделиться ими с остальным комьюнити это уже для новичков видимо да получается от тех у кого есть опыт но опять же всегда в и майли существует достаточно большое количество классов задач и эти задачи решаются немножко по-разному все-таки в каждой конкретной области и большинство людей решающих эти задачи на постоянку они хорошо знают постоянные их у себя применяют но когда ты решаешь непосредственно ну когда ты пишешь наверное автоэмаль да тебе всегда нужно бороться с тем что ты заранее не знаешь какие данные тебе придут на вход и ты должен максимально хорошо работать вне зависимости от этой информации собственно мы с командой поскольку у нас достаточно большой опыт на кабеля что я что мой коллега являемся гранд-мастера миг аглаи еще один человек тоже как бы фактически грандмастер карла поэтому в себе весь тот опыт который у нас был накоплен с когда мы смогли внедрить в это решение для того чтобы она с одной стороны работала быстро с другой стороны позволял получить реально хороший результат я поведу рассказ действительно снова про машинное обучение и более того снова про автоматическое машинное обучение и это будет тоже free work свете предыдущего доклада начну с того в чем же отличие от того open-source фреймворк а про которые я рассказываю здесь мы как команда лаборатории моделирования природных систем университета итмо делаем ставку больше на исследовательские задачи или же некоторые нестандартные бизнесовые задачи в которых возникает необходимость использования pipeline of машинного обучения с практически произвольной структурой то есть фактически такие pipeline могут быть описаны большим разветвленным графом и мы хотим попробовать средства и решить задачу поиска оптимальной структуры такого графа отношения между котором позволяют описывать прикладным 2 различных типов данных для различных задач более того даже общаться на различные типы моделей не все из которых вообще имеют отношение к машинного обучения но при этом быть и модульном расширяемым на разные инструменты задачи и главное позволяет пользователю легко и удобно и и пользоваться потому что действительно автоматическом машину обучение важно что под комод под капотом ну точно также важно что по этого был интерфейс который он пользуется ли может обучиться но действительно хотелось бы чтоб не больше чем за час каковы основные возможности ну во первых это построение в этих самых нелинейных pipeline of то есть если для задачи подходит простая модель оба иного обучения из одного блока отлично именно такую модель федот найдет если же нужна большая большая разветвленная структура то здесь уже будет искаться именно она также для этого pipeline а будут настраиваться гипер параметры причем весь pipeline рассматриваетесь как черный ящик и тебе параметры настраиваются одновременно в одном pipeline не могу бить блоки которые решают различные задачи например сначала решается задача классификации а потом ее результаты и решений учитывается при решении задач и регрессе если у нас есть и гетерогенные данные то можно с ними работать такого духе также может решаться задача мультимодального обучения кран у нас и одновременно и текст и картинки и табличные признаки и например временной ряд и соответственно если мы все модальности о чём-то качество нашей торговой модели будет выше и структура такой модели тоже хотим искать автоматически также мы хотим понимать как каждый блок pipeline а влияет на результат хотим уметь его экспортировать для того чтобы все наши эксперименты были полностью воспроизводимы точно так же как мы хотим знать как именно был получен pipeline что же собственно внутри внутри достаточно сложная логика основанная на эволюционном алгоритм схема которая показываю довольно запутанная запутанная на почему потому что мы стремимся обобщить задачу поиска структуры граф твой модели шире чем только на машинное обучение поэтому мы работаем с некоторыми абстрактными графами прокидывая снаружи внешние знания о семантике узлов и отношения между ними если это pipeline машинного обучения оптимизатор будет искать такой pipeline ну точно так же это может быть и практически любая другая игра в модель как работает сам процесс поиска он основан на генетическом алгоритме который проводит аналогию с биологической эволюции той что происходит есть некоторая случайная начальная популяция далее каждый элемент в этой популяции то есть к pipeline машинного обучения или мутируют или скрещивается с другим оценивается его пригодность выживают те которые приспособлены сильнее всего и так далее и так далее и iterative постепенно происходит сходимость находится те варианты структуры pipeline а фантазирования которое наиболее эффективны для конкретных данных и постановка такой задачи может быть также много крита реальной например если мы хотим получить модель у которой очень маленькое время inference но при этом у нее максимальное качество мы можем задать оба критерия запустить оптимизацию и получить некоторый набор компромиссов между эффективностью модели и ее учителями затратами на то чтобы ее применить и здесь могут быть совершенно произвольные целевые функции переданного фреймворк и использовали как и сказал pipeline буду бить простые для одной задачей простых табличных данных могут быть сложными в таком случае в них есть некоторые под графы которые работают с данными одной модальности например свёрточная сеть для картинок и также есть модель случайного леса для табличных данных и весь поиск всей этой структуры происходит автоматически потому что это такой же граф и оптимизатору достаточно просто знать немного дополнительных фактов чтобы все это в правильном порядке выставить если какой-то модельность лишнего просто и и выбросит точно также описанный подход годится и для временных рядов мы хотим спрогнозировать значения временного ряда на несколько шагов вперед что мы можем сделать можем выполнить преобразование временного ряда в траекторию матрицу заданным окном и дальше решать это как задачу регрессии естественно можем объединять несколько таких моделей в ансамбль можем брать разные размеры исторического окна разные заблаговременности прогноза и здесь отличный потенциал для того чтобы сложные нога масштабные процессы моделируя с помощью сложных разветвлённых моделей и вот фреймворк федот как раз позволяют такие модели автоматически искать безусловно здесь очень важные аспекты связанные с инфраструктурой потому что задача очень почтительно сложное в ходе эволюционной оптимизации у нас есть популяция оно для того чтобы узнать пригодность каждого индивида в ней мы заново заново обучаем большой сложный pipeline и поэтому здесь конечно очень хочется делать это быстрее что мы пробовали чтобы этого добиться ну во-первых мы применяли систему каширования которое основано на том что если мы изменили структуру pipeline а и хотим мы заново его обучить нам не нужно делать все целиком мы можем в прошлых pipeline их поискать такие кусочки которые уже были обучены и соответственно нам понадобится только несколько измененных узлов заново обучить и вычислить функцию пригодности ну естественно это отлично раз параллель его это потому что все индивиды в популяции эволюционного алгоритма не независим между собой поэтому учитывая что популяция обычно большая есть минимум места несколько десятков pipeline ав параллельна существует они могут и обучены параллельно здесь действительно очень хорошо помогают джипу ускорение очень сильная и вот эта песчаная графа я структура действительно позволяет часть узлов обучать на бьют часть на цикл потому что по факту оптимизатор не знает ничего о семантике модели и не знает вам как они реализованы ему без разницы что под капотом у конкретных узлов pipeline а поэтому можно этом на ходу буквально подменять зависимости от того какая инфраструктура доступно и как крайний случай мы реализовали возможность обучения вообще на удаленной инфраструктуре когда структура модели и указание на тон на каких данных нужно производить обучение передается в виде запроса крест интерфейса у нас есть какой-то вычислительный сервера вообще отдельно на нем слушаются запросы и соответственно этот сервер все счета все что нужно считает получают целиком популяцию то есть некоторые бача запросов которые нужно badge вычислительных задач которые нужно обработать и в таком случае автомате вообще абстрагируется от выполнения таких сложных вычислений выдавались это специализированному ресурсу так как пользователю достаточно интересна не только какая модель получилась но и как оно получилось и почему мы сделали некоторые упор на механизме визуализации от того что показать где какой на каждом этапе эволюции доля определенного вида моделей где там где больше линейных моделей потом можно увидеть что нелинейных моделей становится больше что эволюция находит варианты из другой области пространства поиска это может полезно для некоторые объясни масти того что происходит и точно также можно весь всю структуру эволюцию тоже нарисовать в виде графа проследить генеалогию то есть есть у нас вот модель есть 10 поколений ее предков и можно смотреть кто с кем скрещиваться как модели мутировали почему все-таки получилось именно то что получилось то есть сделайте автоэмаль некого рода прозрачным ящиком ну и бегло пробегусь по ты примером вот например мы для временных рядов промышленных процессов применили html и и федот обыграл специализированное решение для временных рядов например of tts или фейсбук овский профит который вообще не очень хорош при том что само-реализация занимает буквально несколько строчек кода закидываем данные запускаемых tml ждем можно применять и гибридные моделирование как я сказал вообще не обязательно чтобы у нас все модели относились к области машинного обучения и если у нас есть гидродинамический симулятор и мы знаем что процесс которыми мы моделируем может быть объяснены вас президент этим симулятором мы добавляем его в как источник данных pipeline и дальше оптимизатор смотрит а нужен вообще этот источник или нет ну да задача прогнозирования уровня моря прогнозирования добычи нефти это очень хорошо работает еще один кейс прогнозировании наводнений на реке лена вот коллеги участвовали в катании с фреймворком федот взяли данные дистанционного зондирования земли со спутников исторически измерения прошлых наводнений и так далее так далее закинули в автоэмаль сделали прогноз на 7 10 дней вперед и получили результат лучше чем у всех дантистов которые участвовали в соревновании то есть фактически достаточно эффективно получается и при этом без лишних затрат человеческого времени на рутину так как мы говорим не только о pipeline их машинного обучения то и дров реворка федот может быть использована как вариант для поиска архитектуры нейронных сетей для поиска структуры байесовских сетей как вероятностный граф их моделей и даже для поиска структура уравнений например дифференциальных все что можно описать графом и задать некоторую целевую функцию может быть найдена с используем такого автоэмали это естественно режим для продвинутых пользователей тут все не просто ну и напоследок скажу что у нас в лаборатории множество open source разработок не только федот есть и другие и многие из них оптимизатор фреймворка федот используют в качестве ядра то есть можно сказать что это я идея максимально универсального граф в оптимизатора она оправдалось хотя бы потому что нам позволило наши исследовательские задачи решать не переизобретать велосипед каждый раз смотря спасибо за внимание у нас есть помимо гитхаба fscanf открытия репозитория еще чат hal диском сайт научные группы где большое количество научных статей по фреймворка перечислено и также на ю тубе поясняющие видео запись особенно raw и так далее если кто то кто то захочет воспользоваться то окажем всю возможную поддержку спасибо время вопросов на этот раз есть кто кроме меня ну давай тоже такой же вопрос задам тебе сколько времени мне нужно чтобы с нуля вот понять вникнуть вообще в этот инструмент и что-нибудь на нем сделать честный ответ зависит от сложности задачи которую вы решаете если это типовая задача классификации и регрессии то общем то в них тут можно за 5 минут из которых 4 будет из купе устанавливаться потому что она буквально три сто три строчки указать целевую переменную указать задачу нажать запустить естественно если задача реальны из бизнеса всегда влезает множество нюансов что данные не такие как рассчитывали разработчики авто имели то есть мы и так далее и так далее и здесь уже можно наверно измерять в часах потому что к сожалению наверное никакой html не умеет автоматизировать интеллектуальную работу человека он больше автоматизирует рутину и в реале знать очень много рутины но все-таки очень много вещей которые человек делают лучше правильно понимаю что вот со сломай есть какие-то очень общие вещи смотрели ли вы на инструмент тот же самому почему с ним не сравнюсь например там были сравнения видел там других продуктов вот такой вопрос безусловно смотрели под собственный продукт очень удобно что можно заглядывать в код и подчеркивать какие-то идеи ну концептуальная разницу что мы не позиционируем себя как light from work все-таки а скорее как такая вещь которой можно как из кубиков пересобрать посмотреть ну вот интересную задачу сравниться признаюсь откровенно не успели все собираемся поучаствовать вот в о д с бенчмарки для автоэмалей затея еще очень-очень хорошая очень хорошая но с этим еще не успели поэтому сравнялись как бы с текущим стоит азартом of the glenn теплоты h2o и так далее тоже не буду врать что всегда выигрываем могу сказать что нашим локальным эксперимента получается что при этом времени оптимизации кругу рядом час получается что мы там в 3 случаях выигрываем встречи наравне ну в трети случаев всегда под любую задачу лучше взять все инструменты попробуйте посмотреть какая конкретно в этом месте будет лучше работать зависит от постановки задачи если у вас всего есть часто бессмысленно перебирать все инструменты лучше взять тот который он кажется более все подходящим и применить его потому что к сожалению во многих задачах объективно разрыв между of time элеми не столь велик и вот на первое место на мой взгляд часто выезжают некоторые не функциональные требования вроде того что мы хотим там другие стрельбы и функций налагаем требования на структуры модели у бизнеса есть вообще какое-то свое представление должно выглядеть модели он там хочет его использовать их начальное приближение например то есть вот обычно все упирается скорее в такие нюансы чем фтор что прокоук вырос на 1 процент обычно это менее интересует идей которые непосредственно использует результаты моделирования для зарабатывания денег понятно так вопросов больше о появился целый вопрос можно вот микрофон спасибо за подвиги на почве автоэмали а подскажите пожалуйста под более подробно про фичи selection и фича генеральша что там внутри себя мы заложили такую логику у нас в каждом узле вот этого графа может стоять или блог моделирование или блок при доработке данных и вот предобработки данных может быть любой то есть мы взяли и стандарты в библиотек множество видов фичерят шин методы снижения размерности методы там-то порождения новых фич информация существующим и так далее и так далее и полностью отдали на тест на откуп эволюция что если так получится что будет в животе варианты pipeline of где fitch selection и вообще не нужен то его в итоговом варианте не будет если нужен то постепенно он за счет эволюционного давления от берет именно в том варианте который наиболее пригоден для конкретных данных естественно есть некоторая обязательная часть то предобработки например там вон хоть encoding ляп категориальных данных ну вот недавно мы на хабрахабр писали статью которая посвящена исключительно реализации предобработки в нашем авто и мэри page там много интересных нюансов действительно как заставить все это с одной стороны работать стабильно с другой искать эффективные варианты всем привет меня зовут никита я инженер в компании проектов и я вам сегодня расскажу о нашем внутреннем open source продукте проекту суток компания общее с огромным опытом консалтингом до 3 лет областях там дата инженеринг куда-то сами самолеты у так далее мы помогаем выстраивать и улучшать процессы компанией тем самым помогая им развивать свои продукты и зарабатывать больше денег по сути и в процессе нашей работы мы увидели определенные паторны и определенные проблемы которые присуще большинству даты команд с которыми мы работали мы провели ряд интервью по задавали вопросы получили ответы и объединили эти проблемы в такое в одну всеобъемлющую проблемы to the discovery и обзор mobility то есть проблема в поиска данных оценки данных и доверия к этим данным вот около 90 процентов команд которых мы интервьюировали которых мы просто спрашивали имеют эти проблемы и эти проблемы занимают у них шпилить в проблем занимают у них до 50 процентов рабочего времени дата специалист это очень много и параллельно с этим мир не стоит на месте pipeline и развиваются какие-то графы зависимости pipeline и простуда сами продукты развиваются и в за счет развития и таких проблем рождаются новые требования к мониторингу своего дома продукта это покрытие data quality тестами поддержка м эльмира до талии на это длилось что граф вашего pipeline или путь ваших данных от начала до конца то есть грубо говоря что пишет в табличку что с таблички читает и куда дальше пишем вот такой вот путь и так как мы консалтинговая компания мы особо не хотели свои велосипеда писать мы пошли на рынок смотреть какие-то готовое решение так называемая от каталоге и такую сюда в каталоге на рынке мы нашли много прекрасных отличных продуктов как он собственных так и комплементарных но у них у всех были и до сих пор у некоторых есть какие-то блокеры нас кто-то не поддерживает m-elle сущности хотя этот тот же самый кусок инфраструктур дата продуктов и непонятно почему они забывают про никто не поддерживает reposado заколете test data профайлинг у большинства проприетарных не понятно как они собирают данные метаданные да а вы же хотите знать если у вас какие-то закрытые данные от complain сам которые нельзя ни с кем шарить не каком виде и вот мы на все это посмотрели и решили все-таки запереть вы велосипед и назвали его up into the discovery и разделили его сложно так на две части первая часть это specs спецификация она призвана унифицировать our метаданных из источников она описана с поддержкой m-elle веро с поддержкой data quality да таллин эйджи профайлинга всех всего того что хотелось бы видеть современном продукте дату discovery физически specs это обычный опытный 5 он лежит нас на гитхабе описывает ешьте pinpoint и и модельки через которые общаются агенты и вот мы работаем над тем чтобы экрана или просто сделать его таким универсальным стандартом для сбора метаданных или хотя бы часть универсального стандарта тоже уже будет очень классно ну и потом успеху естественно просто specs лежит что с ней делать мы написали ряд коллекторов таких небольших агентов которые подключаются к вашим танцор сам собирает это данные о табличках поджогах да например когда джо бы запустилась если вы табличка на прочитала что какие колонки в этой табличке какая статистика и статистику можно достать по колонке например какой то из этой таблички и отправляют дальше в когда-то каталог что важно понимать мы не лезем в данные абсолютно то есть если публичные 5 datasource а отдает нам информацию допустимо статистике супер мы забираем например как делать hive или glue местный если нет то нет никакие select и напротив реальных данных мы не запускаем мы конфигурируется эти коллекторы на самом деле простыми я бликами это можно описать кучу-кучу data source of и таким образом всю инфраструктуру покрыть там двумя-тремя коллекторами а вторая часть это сам до каталога туда кластер как назвали этот каталог эт успеху поддерживается что она не базируется умеет им жестить метаданные из тех request of которые кушать коллекторы эти метаданные как-то хранить агрегировать и показывать пользователю в удобном виде со всеми фишками которые нужны поиск фильтрация далее наш путь связи между компонентами так далее каталог coupe собственный был если будет все что чем будут рассказывать о концертная и мы сделали на самом деле большой приставку не то что очень просто интегрировать вашу инфраструктуру из все что вам нужно из внешних зависимостей только после со и вот это вот на самом деле вообще интересная тема на наш взгляд это один из самых главных блокеров всех тех да так налогов которые мы рассмотрели на рынке огромное количество внешних зависимостей большинство дата каталогов open source ных от вас потребуют половина vs развернуть то есть им нужно и нужен подлесков к им нужен airflow манга зачем-то ластик сердца для поисковых викторов данного фаджр до долины где можно граф хранить просто для того чтобы запустится показать по стойкам мы считаем что после 100 достаточно он может заменить допустим поисковые виктора и власти ксир чьи своими тесты к раме до долины он может заменить рекурсивными стрижка каре ключевыми запросами в базу и правильную просто построением моделей базы дан если бы те клиенты те компании которые нас уже используют пока проблему не имеют если будут какие-то проблемы вот именно вот с этим подходом да то что мы все в пазл складываем мы обязательно запилим какую-то опциональную поддержку ластик серфинга fuji можно будет переключаться в конфиге там удобно как также мы адепты контракт все раз подхода на тут мы сначала пишем об анапе стеку генерируем заказ 5 и ферментацию и уже вот сюда имитации как работаем и так как платформы написано джамиа коллектор на питания мы написали все это еще используя реактивную пробегу для java буквально неделю назад релиза availability at артур бесси specs и возрасте драйвер у нас показывает себя отлично никаких проблем нет запросы в базовым и кидаем жуком прекрасные туза которая позволяет вам писать свои запросы через десять java вский потому что мы хотим контролировать общение с базой не полагаясь на магию будут под магию под капотом там сервис предмета и так далее с жуком россии кстати возникли проблемы небольшие кантон транзакции не поддерживал реактивный то он точно не закрывал но мы это со преодолели если кому то интересно как белкам в репозитории или можем списаться созвониться все расскажем ну и в любом случае мы сделаем хоть техническую статью по этому поводу вот интеграций понятное дело что классных полок написали коллектор написали стэкнуть как используйте где видишь т.к. а интеграции мы подержим на данный момент около 25 источников как хранилищ данных хоккее тильды штоф самые кондиционные самые популярные мы постарались по 1000 в самом начале продукта проекта всякие этапа сгрыз и массив алых rehau своих блоков ки-викс самый популярный и за счет наш из пике и тех бетон тех питон библиотек которые мы написали вокруг этой спеть и написать интеграцию к новому datasource или какому-то проприетарным у закрытому in-house который используется только вас компании очень просто это еще один плюсик к интеграции в свои в створ и еще мы умеем также получать метаданные из ряда микро сервисов суп с помощью об интеллект реагентов представьте если у вас написано когда микро сервис которые читают из кафки пишет нас три с помощью небольших телодвижений туда можно подключить об интересе агент который будет в каталог пушить данные о том откуда вы читаете прямо буквально сhaos топик искать и откуда и куда и таким образом это как будто бы джова которая начинает подпишет true этель самой песне вот не вот в целом это наша цель попить spring про структуру стандартного дата продукта дата проекта своим одесского решили предоставить такой себе мониторинг в игру всего in varmint и компании момента продукта и дать возможность просматривать текущее состояние проекта они завязываться на консоль instance страничках которые никто все равно все равно никто как правило не обновляем по ценностям и мы в команде видим она так ценность есть ли любого участника разработки или поддержки инженеры менеджеры аналитики для всех использовать например sticking лом намного проще проходить процессор boarding а когда нужно получить эту картину общую картину мира посмотреть там с какими-то тусовками работает компания как как у них pipeline и выглядит откуда куда данные льются и так далее символом намного проще находить данные для своей первой задачи оценить их сразу же выйти на контакт с ордером либо какие-то дополнительные вопросы сносить либо попросить попросить 2 судак ним и благодаря обзор уберите функционалу который у нас есть там сети alert и можно на раннем этапе отловить проблемы в pipeline их представьте что вы знаете ст вы делаете свою модельку вы и отдалив подачи все классно все работает через неделю прибегать бизнес говорит не работает в моделька там как бы оно не падает на данные общине ти не те цифры и показывает вы сначала здесь разбираться свою модель вы все нормально работало раньше почему не работает сейчас а потом оказывается что ты где-то там далеко в обстреле тех данных которого используйте какой-то да ты инженер взял и удалил колонку никого об этом не предупредил о вас на этом все завязано и вот такие вот такие вот изменения ломающие можно на раннем этапе отлавливать с нашим discovery вот наш род макс выглядит вот так то есть начале мы по-взрослому мы написали растишку пошарь или трусишь с нашими партнерами и клиентами тот перфидо к доработали выложили в паблик то есть параллель с комьюнити начали параллельно делать мдп добавляясь в каждом низменных релизов добавляя там какие-то фичино вы сейчас мы немножко перестраиваем подходы будем делать минорные релизы каждый месяц примерно там три недели чтобы быстрее delivery быстрее собрать себя к их целостно развиваться вот если вам эта область интересно если вы захотите там попробовать поиграться провод потыкаться или попробовать поставить локальные все это тоже самое сделать заходите к нам на лендинг у нас там есть вся информация о том как мы это делаем для кого мы это делаем зачем мы это делаем более подробно мы сейчас в процессе запуска сын бокса что можно было просто по своим google при этом зайти и а ты сам погиб поставить в сущности заходите нагиб хоп ставьте звездочки contribute мы будем рады любому кантри буш от вас и шью вопросы просто обычные звездочки и так далее на все ответим всем поможем также у нас есть флаг где мы пытаемся строить такой все взрослые комьюнити мы привлекаем разных специалистов из разных компаний больших сейчас активно работаем с аналитиком чтобы она нам помогла правильно построить построить в коллекторе так что это было удобно потом просматривать в платформе и так далее и мы с недавнего времени завели блог где мы постим как марку как маркетинговые такие бизнесовые и еще технические статьи и с теми компаниями с которыми мы работаем мы готовим объединенный такие кейс-стади и об этом тоже можно будет булочки почитать вот всем спасибо за внимание я думаю что можно вопрос переходить да никита спасибо тебе вопросы из зала не стесняйтесь руку поднимайте это просто ну давай я тебе задам один вопрос ты написал что других продуктов нет поддержки м или а у вас я так понял все таки есть да смотри когда когда мы это делали примерно полтора года в год назад мы начали действительно у многих продуктов не было таких понятиях как sticker star и как они имели модели как там сети switch maker пошло pipeline и не так далее после этого просто сегодня был и поэтому когда они говорят школу and and lynch это немножечко лукавство из хорошо у вас есть старта для выданное забираете но где она кончаются они не попали там где по факту вы показываете исключить или дальше ваша панель моделях ваши интеллигенция тогда сейчас теплота немножко поправилась люди активно как репутации да да каталоге затаскивает а моей сущности мы очень радует увидеть но у некоторых не который до сих пор скажи мне кажется это мой сегодня любимый вопрос сколько мне нужно времени чтобы ну ладно не совсем любимый поскорее если мы уже готовая система много микро сервисов 2 заданных шины события и так далее вот сколько мне нужно будет ресурсов потратить меня одного человека вот то чтобы внедрить все это в свои процессы на слушай если все описать все три вершины базы данных все твои идеи и кого я думаю что на самом деле не посидишь ехал конфликт везде напишешь про тестируешь поднимешься довольно супер быстро я думал прям месяц придется колупаться с этим ну что ж спасибо надеюсь кто-нибудь в итоге попробует те кто слушали отсюда и им это супер понравится я лично сам обязательно посмотрю всем привет ну что очередь дошла и до меня рассказать вам про замечательный open source инструмент date and enter сразу оговорюсь инструмент простой доклад тоже простой поэтому можно выдохнуть и расслабиться пару слов о себе меня зовут михаил я backend разработчик и open source активисты а еще я автор и основной контрибьютором проекта тут and filter что такое dtm клинкер из название я думаю и так понятно что это линдер для date and файлов но прежде чем рассказать о его возможностях мне бы хотелось первую очередь рассказать о том что такое date and файлы и так патент файлы это обычные текстовые файлы в которых хранятся переменные окружения формате ключ-значение и их довольно удобно использовать в процессе разработки и тестирования например не нужно указывать огромное количество переменных окружения при запуске приложения все хранится в одном файле удобным для работы в дотан файлами есть довольно большое количество библиотек под все современные языки программирования все что они делают это загружает перемен окружению из этих файлов при запуске приложения так вот основная задача date and linder это поиск проблем date and файлах у него есть целых двенадцать проверка например он может находить дубликаты больших but in файлах или например переменное окружение с не правильными именами еще он может автоматически исправлять все найденные проблемы для этого достаточно его запустить с отдельной команды fix чтобы не беспокоиться о том что он что-то там удалил случайно патент фильтр по умолчанию создает файл с резервной копии также он автор он может сравнивать date and файлы между собой и находить расхождение между ними это бывает удобно когда в проекте например есть некий файл шаблона патент . экземпляр который хранится в git репозиторий и содержит все переменные окружения необходимы для запуска приложения но без конкретных значений этот файл шаблона используется разработчиками для создания своих локальных файлов часто возникает ситуация разработчики добавляют новые переменные окружения в проект добавляет их свои локальные файлы но забывают добавить шаблон шаблон устаревает приходит в проект новые разработчики и не могут развернуть проект чтобы не было подобных ситуаций вот патент линдер тоже может помочь dota на принтер можно использовать на любом проекте вне зависимости от языка программирования он написано 1 можно скачать бинарный файл и запускать его локально либо установить с помощью пакетного менеджера например homebrew или запускать как докер-образ кому как удобно еще есть вариант использовать dig up action который будет проверять pull request и в атлетике от локального запуска когда проверяется только весь файл целиком и каппа action проверяет конкретный мнение в квесте если ему что то не понравится он оставит комментарий к определенному файлу конкретной строчки с указанием причины нет капюшон можно настроить чтобы вместо комментариях он сразу предлагал конкретные изменения файла чтобы потом их можно было применить с помощью одной кнопочки на гибком тот and winter также включен состав популярного суперленд ира от компании гид хоп это тоже get up action состав которых включены все популярные литры которые запускается при наличии соответствующих расширений в вашем проекте отдельно мне бы хотелось рассказать что date and linder изначально создавался как дружелюбный open source проект цель которого помочь всем желающим разработчикам в изучении раз на примере простого но в то же время полезного инструмента а заодно и привить им любовь к open source и помочь с первыми шагами в этом направлении немного статистики проект уже два с половиной года и за это время было выпущено целых 13 версии проект изначально разрабатывался силами open source сообщество и за все время над проектом успел поработать 810 контрибьютором что не так уж и мало для такого простого проекта и удод инвентору больше тысячи звездных гид hop на этом у меня все всем спасибо за внимание вопросы ну напоминаю поднимаем руку вам дают микрофон никто не хочет хорошо спрошу я подняли о пропустил самый вдаль смотрела да сейчас принесут у меня на самом деле вопрос не совсем технического характера вот вы сказали про сообщества множество звезд а как вы это сообщество создавали то есть вы достаточно много обзоров продуктов пытаемся запускать и всегда создать сообщество с нуля задача чуть ли не сложнее чем создать сам продукт спасибо за вопрос изначально проект создавался в рамках компании то есть в компании мы развивали open source направления и в рамках него создали проект чтобы научить наших разработчиков компании правильно работы с open source когда научили наших разработчиков правильно работать с open source решили поучаствовать в роли метров для разработчиков не из компании как-то так ты сказал что этот проект в том числе используется для как раз некоторого такого обучения расту правильно я услышал да как это выглядит как это происходит в эту козу уже готовый да про продукт готовый но я рассказал про то что изначально проект создавался то есть мы в команде сделали некий скелет приложения и расписали мы создали много еще раз писали очень подробно как это все делал все что нужно сделать как это все запустить протестировать и просто дальше распиарили проект с помощью ну через различные каналы там twitter ну всякие рассылки и так далее пришли разработчики кому интересно было поизучать раз брали задачи делали вот получился продукт супер интересный подход мне понравился еще образ при использовании самого инструмента как его настраивать как ему сказать какие файлы и проверять или он их сам находит делает он это только в кодовой базе или я могу где-то этого рандами вон отравить чтобы он смотрел на те файлы которые у меня появляются например каким-нибудь генерирующими инструментами это сила инструмента он ну запускается через терминал консоль и он по шаблон просто находит файлы в которых встречается название там . м но его можно настроить то есть какие-то файлы исключать из проверки какие-то включать дополнительно то есть все можно настроить да и какие то свои проверки можно туда создавать чтобы они появлялись к скины нет жаль хорошие вот вам и шью создайте кастомизация"
}