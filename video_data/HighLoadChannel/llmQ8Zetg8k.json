{
  "video_id": "llmQ8Zetg8k",
  "channel": "HighLoadChannel",
  "title": "Чистые метки для ML / Анастасия Беззубцева (Яндекс)",
  "views": 145,
  "duration": 2543,
  "published": "2024-10-29T03:07:39-07:00",
  "text": "мы продолжаем тему Эля И в этот раз в этом докладе нам Настя расскажет о том а про частоту данных Как отличить хорошие данные от плохих и что делать с плохими данными Насть Пожалуйста выходи Ура Всем привет ой как громко очень рад вас видеть А зовут Меня Настя да как уже сказали работаю в компании Яндекс буду рассказывать про качество данных для машинного обучение Как можно улучшить вашу модель через данные Ура работает а так вот работаю последние 10 лет в компании Яндекс успела позаниматься там всякими разными задачами сансом машин обучением статьи пописала ресечер ские аналитику поделаю это в разных местах Яндекса в антифрод в Анти спаме в ранжировании в поиске в Алисе и последние 2 года я руковожу командой аналитики NLP в который мы включаем аналитику распознавания голоса синтеза голоса и больших языковых моделей А почему именно про чистые данные хочется вам рассказать потому что по моему опыту и по многим 8% времени которое человек который озабочен машинным обучением он тратит именно на данные на агрегацию данных на очистку данных на разметку данных на аугментация прикольные задачи типа подбора параметров каких-то алгоритмов новых внедрения и так далее Вот мой опыт показывает примерно тоже самое И что громадная до в упе это именно данные про что расскажу про то Какие данные собственно бывают насколько они бывают грязные про то когда э проблема когда не очень про то что делать если это проблема как их очищать и расскажу пять историй из жизни моей в Яндексе про то как я очистила мы очистили данные и всё стало хорошо А какие метки бывают метки бывают не очень чистые например Наверняка вы знаете про на НМ начинающие ры учатся распознавать числа в картинках если пристально вглядеться в Да окажется что там метки не совсем соответствуют тому что на картинке изображено какие ещё бывают дасе и там картинки всего остального не чисел вот как вы думаете что изображено на этой картинке вот есть подсказки как вы думаете это мбат или вид нру вала каже что Бори пото что е бывает бывают датасеты на парные из интернета например из базы RW там если у кино какой-то хороший отзыв с оценкой там по десятибалльной шкале хороший то мы считаем этот отзыв в целом хорошим и наоборот так вот они опираются на оказывается что контент Эх отзывов не соответству выстав IMDb - Это хороший отзыв на самом деле там не очень хороший текст честно говоря и наоборот но скажете вы что ну это какие-то искусственные дасе мы их не очень используем в реальной жизни вообще в продакшене у нас что-то другое например клики А что же пишут про клики а клики Зачем можно использовать как предиктор релевантности документа или там элемента на который кликают А если пристально рассмотреть клики то оказывается что от 50 до 80% кликнув на самом деле релевантны то есть данные шумные как минимум на 20% Ну есть прям сайты и вообще проекты которые посвящены исключительно шумным меткам и там много таких подобных черепитчатый достигаете решать вашу задачу говорят что dearing - это более Уй алгоритм который более склонен переобуться под плохие данные а бустинг более устойчивы очевидно зависит от того сколько у вас шума и сколько у вас грязи и от того как эта грязь распределена То есть она может быть юниформ най равномерной есть такой грязь в вакууме синтетическая равномерно распределённое А может быть смещение какое-то также зависит от того каким способом вы лидие ваш алгоритм машинного обучения конечно типа насколько датасет на котором вы измеря его ф насколько он чистый Если у вас есть какой-то отдельный чистый а учитесь вы там на чём-то другом то может быть и не страшно А если такого нет то на самом деле у вас нет прибора по которому вы точно видите что качество Вот именно такое как же связан уровень загрязнения с качеством модели вот прекрасный график например рассмотрим нижнюю линию где среднее качество данных Орле в ML оно-то типа 0,5 скармливать по количество наблюдений скармливания в ML лучше не остановится там а алгоритма по-прежнему 0,5 А если же мы начинаем с качества данных например 08 или 0,9 розовая линия то уже начиная там со 100 наблюдений качество всего алгоритма лучше чем качество меток которые на входе это бустинг другой алгоритм и другая проблема распределение грязи есть синтетический шум Ну прямо совсем синтетический нормальное распределение независимое по всем классам просто взяли и зашуми и есть естественный шум который обычно в дикой природе и присутствует это шум от разметчик это люди которые смотрят на данные пытаются метки проставить и немножко могут ошибаться и видим что алгоритм очень хорошо отличает некорректные метки в естественном шуме и очень плохо отличает некорректные метки в в естественном шуме и хорошо отличает в синтетическом шуме это графики распределения лосо и вот супер хорошо видно что ему просто понять что синтетика - это синтетика И что там шум наверно просто с этим бороться Да действительно просто с этим бороться модель переобуться скорее под естественный шум А к синтетике более устойчива это задача классификации картинок надо отти фар 10 заумный задаче где уже бар У нас чего-то классифицирует на то есть это уже N задача совершенно другая ситуация здесь мы чаем Под синтетический шум растёт количество эпох и видно что кривулька справа сильно больше сгибается чем кривулька слева там естественный Шум Какой вывод всё очень зависит от вашей задачи от того какой шум Какие алгоритмы но в целом везде шум никогда пользы не добавляет то есть видно Где синяя линия - это всё прекрасно у вас супер чистые данные и вот Чем ниже тем ниже там на 10-15 процентных пунктов какое-то загрязнение Может у Вас украсть в качестве Вот про валидацию качества отдельно Наверно стоит заметить что самое главное иметь супер классный чистейший досе конечный и вот если у вас нет такого то это проблема а если у вас есть какие-то косвенные признаки там ретеншн количество пользователей в вашем сервисе В вашем меле то может быть это не такая проблема небольшой тест грязные ли у вас данные Давайте проверим да у вас грязные данные к сожалению не видела чистых данных достаточно чистых чтобы тест сказал другое что-то Как понять насколько они у вас грязные Ну валидировать взять кусочек выборки разметить посмотреть оценить процент можно ещ косвенно понять если очень не хочется разме вы пробуете разные Вы долива железо ничего не работает всё плохое возможно ваши метка и ваш Таргет не очень Что же делать с этим ну во-первых уже Ещё раз напомню У вас должны быть супер точные приборы по которым вы замеряется обучени который называется Learning Lab можно позаниматься этим но доклад сегодня не про него если супер коротко то там не супер большой Профит дают эти алгоритмы они делятся на несколько классов из них самый мейнстрим это калибруем лосы и делаем лосы более устойчивые а второе давайте выберем наиболее чистые данные какими-то эвристика в нашем Дат сеете и обучим на них и итеративный все остальные данные нашим алгоритмам и доливать их в алгоритм А говорят что тоже помогают такие методы не совсем шумом скорее синтетическим Так ну и наконец про что доклад про то как повышать точность тройна Какие есть способы что делать а во-первых можно найти подозрительные метки и выкинуть их во-вторых можно найти классные метки оставить их и в-третьих можно ничего не выкидывать и работать с тем что есть и улучшать те метки которые есть найти плохие метки разметить более хорошие метки первое выкидываем грязное как выкидывать Ну тоже понятно берём трейн смотрим какие там кусочки пытаемся разметить где Чего грязное где хорошее делаем эвристики может быть какой-то вспомогательный обучаем который нам говорит где хорошие данные где плохие и что-нибудь выкидываем А из плюсов это легко реализовать Из минусов мы портим распределение трейна и мы портим пление датасета И поэтому это не подходит если мы обо перс конечным валион дам потому что в НМ должно быть хорошее распределение репрезентативные не знаю хорды какие-то В общем всё что вам нужно но там должны быть все эти примеры нельзя выкидывать Ну и Из минусов возможно вам придётся немножко данных помечать Вот пример как в какой-то статье выбирают Рандомный кусок данных выкидывают и выбирают не Рандомный грязный кусок данных выкидывают Ну конечно же лучше выкидывать грязный кусок данных история номе жиз быст в Алисе этой для распознавания для Алисы в НМ есть разные кусочки например там есть разметка экспертами Яндекса или там есть какие-то публичные дасе или есть кусочек псевдо меток это вердикт старых моделей на живых данных пользователей вот что-то там когда-то пользователь сказал в Алису что-то распознали и это записали в й как псевдо метку Как выглядит общение пользователя с Алисой он говорит Алиса Включи ану она что-то не расслышала и говорит горит включаю Ван Что делает пользователь говорит Алиса хватит и при этом что происходит Вован едет в трейн К сожалению вот грязная метка оказывается в трейне А ну что Мы заметили что возможно у нас возможная гипотеза появляется Как вычистить такие псевдо плохие псевдо метки из трейна если произошёл быстрый стоп после запроса то это потенциально плохая метка Давайте сначала проверим эту гипотезу сравнивая до верных аннотаций в разных подмножества тройна вот в таком и во всём остальном и правда срез быстрых стопов действительно грязный и хорошо бы его убрать убираем его из обучения улучшаем распознавание классно вторая история про Яндекс гпт она супер наверное Капитан Очевидность Ну в Яндекс гпт тоже есть прит там куча документов они на Майны из интернета документы могут быть хорошие плохие могут быть хорошо распа плохо распа наверно учиться на плохо распа некачественных документах не очень хорошо для большой языковой модели Наверное это не полезные данные Давайте разметить документы из интернета обучим классификатор качества документа и оставим в трейне для большой языковой модели только качественные документы ну собственно делаем улучшаем Яндекс гпт Классно теперь посложнее что можно делать чтобы улучшить грязные данные два основных способа А экстенсивный и интенсивный экстенсивные - это типа Давайте закинем бабла в машинку и она нам выдаст каких-то получше данных это перекрытие агрегация Давайте данные показывать большему количеству разметчики и из большего количества информации от разметчик Давайте попытаемся выливать максимально хорошую метку согревать её в что-то лучшее чем отдельные эти метки а интенсивный способ - Это Давайте работать с исполнителями то есть Давайте сделаем так чтобы каждый конкретный исполнитель Лучше нам размечается плюсов мы можем получить метки для почти любых данных То есть вы можете idate харды всё что угодно максимально любые ваши таблички на размечается есть задача идентификации говорящего в Алисе Вот вы общаетесь с голосовым ассистентом и там вы живёте с кем-то и говорите Алиса Включи музыку и она вам предположительно включает ваши персоналий рекомендаци вот нужна разметка для такой задачи оказывается что люди которые не знают людей которые говорят очень плохо чуть лучше рандома справляются с такой задачей то есть мы не можем прямо взять Вот эту серебряную пулю разметку и размечается получить данные для такой задачи то в конце рассказа обязательно Расскажите Вот пам-пам чего перекрытие как перекрытие Как из прикрытия можно вытащить побольше качества Ну видно опять вот где P ра 05 это среднее качество разметчик равно 0,5 увеличиваем перекрытие делаем там 1 3 5 сколько угодно разметчик X интегральное качество по перекрытию по агрегации перекрытия не улучшается здесь использован базовый метод агрегации который подходит почти для всех задач называется majority это мнение большинства про вашу задачу Вот Но если же индивидуальное качество разметчик уже выше чем 0,5 то при увелечении перекрытия majority voe ещё лучше чем интегральное качество разметчик и чем лучше оно изначально тем быстрее эта кривулька насыщается то есть тем быстрее качество становится практически стопроцентным Но это всё ээ стоит это всё стоит либо времени Ну и времени разметки и денег которые вы тратите на разметку а majority W не единственный метод агрегации и часто В задачах нужно использовать свой кастомный метод агрегации А например для задач классификации а популярны Skin White Hill может быть кто-то слышал они дают ещё несколько процентных пунктов профита поверх majority V задачи бывают разные например есть задача сгенерировать текст там написать аннотацию для аудио и эта задача она не подвластна вот этим популярным David Skin и White Hill потому что там Не фиксированы там бесконечные вариант бесконечное количество вариантов ответа на каждый объект и там возможно нужно придумывать какие-то свои кастомные методы здесь пока литература недалеко ушла в общем и это может принести тоже большую пользу история третья хитроумная агрегация у нас по-прежнему распознавание Алисы теперь нас интересует другой кусочек трейна разметка на толоке талака наверняка слышали сервис где можно за денежку получить разметку данных какого-то качества А у нас локер Что делает он слышит аудио Он должен написать к этому аудио текст который он там слышит транскрибировать версия каждого локера это гипотеза локера и мы размечаем в динамическом перекрытии от Т до пти динамическая Это значит что мы можем сначала набрать перекрытие три если у нас есть уже такой вариант который набрал много голосов Ну два например то мы говорим что всё хорошо сошлось больше не размечаем если нет такого варианта то набираем перекрытие дальше какая проблема есть часть разметки которая не сходится то есть мы набираем даже п голосов и такого одного варианта который набрал там два или три из пяти А вот например песня Open style как её написать Да по-разному в целом так Нормально и так нормально Вот это очень важные запросы для Алисы это музыкальные запросы это наш основной поток и Мы очень хотим их правильно распознавать и хорошо отвечать пользователю но не можем потому что такого даже в тройне Нет Как же сделать чтобы было А идея давайте считать между каждой парой гипотез попарное расстояние а текстовое какое-то давайте считать Ну 10 расстояний левенштейна например Это количество замен вставок замен удалений чтобы превратить один текст в другой давайте считать фонем нае расстояние левенштейна то есть между фонемный порог то кластеризованный гипотезу которая набрала наибольшее количество голосов плюс там какие-то хитроумные листики как ещ можно выбрать гипотезу внутри кластера что же получается у нас получается не только до разметить дойти до свести ещё какое-то количество данных а у нас Это причём половина из того что у нас не сводилось удалось свести таким способом нам удалось также улучшить аннотацию на тех данных которые уже были сведены то есть там была какая-то аннотация а стала классная Ну конечно же мы улучшили распознавание на Таких данных так история четвёртая называется капча от слова RE капча напомню Что такое капча изначально это два текста которые показываются предположительно роботу и про один из этих текстов а тот кто показывает знает правильную аннотацию тут уже другая задача OCR мы распознаёт изначально ре капча была такой А зачем мы знаем аннотацию вообще мы хотим разметить те данные про которые мы не знаем аннотацию а и использовать те данные про которые знаем аннотацию как маркер того что размечают хорошо или плохо сейчас рекап выглядит как картинки но не суть в Яндексе тоже есть рекап которая выглядит Вот например Так там какие-то два слова про одно из них мы что-то знаем про второй не знаем А что важно что качество меток которые мы так собираем для нашего OC довольно невысокая 70% Почему так потому что на самом деле капто мы показываем предположительно роботам и роботы умеют на самом деле парсить эту кап некоторые Они видят эту картинку собственный OCR И отдают нам какой-то ответ на эту картинку и ну по счастливой случайности на правильную картинку они могут дать правильный ответ А на ту про которую мы ничего не знаем они могут дать какой-то дурацкий не очень хорошую метку А вот посмотрим на распределение ответов полученных вот таким алгоритмом видим что если использовать majority vote то правильная Вот бадом она выделена правильная гипотеза не в топе она не побеждает поэтому метка оказывается Вот такой не очень Вот Что делать будем давайте сделаем динамическое перекрытие с машин обученным скором остановки А давайте на каждой новой гипотезе а считать confidence а кат бустом какой-то там обученный на фича который говорит что эта гипотеза классна и что нужно остановиться фичи какие были в этом КАД бусте Это всё что угодно время ввода этой гипотезы статистика по накопленным голосам конфиденс нашего OCR текущего какие-то расстояния левенштейна между нашему и тем что нам прислали наличие там латиницы кириллицы Чего угодно введённом ответе и тут даже не суть ка какие были показатели качества Вот этого ML вспомогательного важно что а Итого используя вот этот алгоритм мы увеличили качество меток полученных А в таком перекрытии с 70 до 90% и немаловажно сильно убыстрить разметку то есть мы сильно снизили среднее перекрытие стали быстрее размечают быстрее в пять раз потом провели эксперимент и заменили часть трейна OC на новый трейн и Естественно улучшили качество о на пару процентных пунктов Ну и самое неприятное Наверное это работа с исполнителями напомню Что такое далин И что там за исполните далин это прям целая индустрия можно взять задачу и кому-нибудь принести компании которая занимается дагом попросить залить можно у себя в компании иметь экспертов которые чат важно про эту инст ини зная степень навыка и Рая степень добросовестности поэтому их нужно обучать и контролировать качество исполнения Как так сделать чтобы всё сразу было нормально ну изначально построить хороший проект в котором все аспекты эти есть есть и обучение контроль качества во-первых нужно обучить исполнителя делать вашу задачу и довольно сложно обучить исполнителя делать сложную зада какую-то слону есть лож задачу в удобном интерфейс шаблон чтобы там максимально всё было прозрачно потом нужно написать полную Но короткую инструкцию про то что нужно собственно делать Почему Потому что и так её особо не любят читать люди а если вы ещё и плохую Напишите Ну точно никто не прочитает и качество разметки будет страдать ну и наконец нужно в этой инструкции обязательно показать примеры на все случаи жизни Например у вас классификация является ли картинка котиком в инструкции нужно описать что вот если у нас игрушка котика или если тигр - это котик или морской котик меча ли его как котик или не меча Вот но лишнего тоже наверно не нужно Если у вас не предполагается игрушек котиков в разметке то можно наверно не писать или Рыжий кот От Серого наверное и так понятно контроль качества первое что самое наверно универсальное и полезное в контроле качества это примеры про которые мы знаем правильный ответ вспоминаем там в половине мы знаем правильный ответ эти примеры можно по-разному использовать можно на них сдела экзамен и тестировать исполнителя фильтровать тех кто не справился с экзаменом можно их подсовывать незаметны потов он такой выполняет задание а на часть мы знаем ответы и мы считаем какой-то скор по Хани потом и также это иногда называется Годен сетами второе Что можно делать можно делать пост приёмку А мы только тогда платим Деньги исполнителю когда он справился с заданием и Нас устраивает его качество ну и наконец перекрытие тоже можно использовать как контроль качества например человек не очень хорошо попадает в maity Все говорят одно а он говорит всё время другое возможно он что-то не то говорит но тоже не факт Ну наконец Пятая история аннотирования вспомним У нас есть аннотирование оно не только на толоке есть но и разметка экспертами Яндекса каких-то важных нам запросов а разные слова но такое аудио что непонятно и это мешает на самом деле улучшать дальше Ар вот он как раз на таких запросах он он-то и сам не справляется что мы поняли что на самом деле для части запросов если посмотреть больше информации про то что происходило вокруг становится понятно что же там за запрос Например я помню Очень хорошо случай когда девочка говорит непонятные какие-то мля Чам тюм тям какие-то даже не слова не понимаю что Что она говорит Но если посмотреть что там было вокруг оказывается что это начало песни в сериале игры в кальмары чего-то на корейском она набивает мотив и потом родитель её говорит Включи вот там песню из игров кальмаров вот я потом послушала эту песню и реально Похоже на то что девочка говорит вот ну в общем да научили мы наших асессоров опираться на контекст естественно повысили качество разметки Ну и конечно же улучшили распознавание чего Если вдруг вы хотите за один слайд понять что я хочу сказать во-первых нужно убедиться что у вас есть точные приборы качества а во-вторых почти всегда Вы можете улучшить качество вашей модели уборкой и чистыми метками Но это сложно хорошие метки - это трудо затратная задача можно пытаться сделать это простым каким-то способом влить туда денег и получить чего-то качеству меток прирост можно научиться работать с исполнителями Но это тяжёлая работа их нужно тщательно контролировать Ну и возможно если вдруг этого ещё не делаете возможно вам придется меть дан это весело всех призываю посмотреть на данные на которых вы учитесь Вот Всё Всем спасибо во-первых вопросы жду во-вторых идеи про то что можно в идентификации голоса на чём можно как размечается и то тоже очень интересно послушать будет Давайте Спасибо большое переходим к сессии вопросов и ответов запоминаем всех кто задавал вопрос выбираем лучший А давайте начнём вот с левой стороны здесь ближе к проходу Спасибо большое за доклад Меня зовут Марк team.ru я как раз поделиться Одним из методов Вот вы просили Да поэтому А значит мы используем мки сейчас есть такой подход называется Contract bas с LM когда ты описываешь контракт и потом спрашиваешь соответствует этот текст или нет И мы себе так почистили некоторые самари то есть мы делали самари зации размечаем разными методами и потом автоматически почистили то есть говорим Да сари должно быть контракт и потом Да нет метка ответь один или Ноль всё автоматом все почистили классно вот у вас есть Яндекс gpt Я думаю вы тоже так можете да По идее Да скорее не вопрос А очень услышать любой фидбек и вопрос и не вопрос очень Да интересно спасибо большое А тогда вот здесь я тоже видел вопросы были по вот на первом ряду А спасибо за доклад Саша ВКонтакте хотел спросить вот самые такие алгоритмы которые приносят больше всего денег они обучаются как правило на каких-то неявных действиях типа кликов вот есть какие-то хорошие практики того как чистить клики лайки и прочее отличный вопрос а я достигала сама успеха когда навешивается ты у тебя есть идея берёшь размечается алгоритм который на этом обучен катишь продакшн смотришь на свои другие приборы и становится ли от этого лучше а как-то так спасибо Вот здесь на первом ряду можно тоже вопросик Привет Спасибо за доклад э у меня такой вопрос э он окончательно оформился в момент когда ты сказала про контекст для исполнителей вот как вы решаете вопрос приватности то что не показав исполнителю ты не узнаешь что там есть что-то приватное но просто Божественный вопрос очень беспокоимся о приватности во-первых у нас есть сценарии про которые мы знаем что они приватные сценарии лиси Например если кто-то заказывает чего-то в лавке то он наверняка там карту свою привязал и мы такие сценарии не размечаем просто не размечаем совсем вот их слава Богу не так много но мы их не антирутина Ну юридически мы можем а анони Зро эти данные оторвать все возможные связи там этого запроса с не знаю геолокацией чем-то таким А и всё-таки показывать экспертам внутри Яндекса вот во вне не можем внутри Яндекса можем Спасибо Здесь вопрос у Иры Привет Спасибо большое за доклад у меня пара вопросов если можно первое как раз продолжение комментария а используете ли вы Яндекс gpt или другие там внутренние мки для разметки и второй вопрос также ты говорила про использование модели чтобы разделять на хорошие плохие документы вот Насколько часто такой способ вообще помогает чтобы действительно чистить свои данные начну со второго довольно часто помогает именно использовать чтобы чистить данные хороший рабочий способ дешёвый довольно да Мне кажется это то что наибольший Профит приносит А про первый вопрос используем ли мы Яндекс гпт чтобы размечается говорила касается стоимости разметки потому что и мы не хотим смотреть Потому что вроде как бы работа такая и И сколько платить как-то ты можешь э ты наверное работаешь с этим рынком а как-то сориентировать там было что-то про 200 там на 10к токенов это что-то мне не очень понятно может быть есть там в месяц человеку просто мы тоже занимаемся у нас своя внутренняя команда и как раз недавно прол вопрос что похоже наверное надо поднять потому что уже год они они хорошие А и Наверное если мы возьмём надо будет обучать и непонятное качество То есть наверное вот как бы что ты думаешь платить может быть просто хорошо платить и они такие прямо будут стараться и смотреть действительно есть Есть информация что чем больше платишь тем лучше размечают это действительно мотивирует людей лучше размечают если ты за сложенное задание платишь копейки Ну там наверное родер придут которые просто проклинает Правда Ну тут всё время какой-то баланс того сколько ты можешь потратить на разметку И сколько какие у тебя ограничения со стороны бизнеса А я знаю что некоторые ориентируются на минимальный размер оплат труда в стране labeling comp companies зарубежные выставляют вот такой порог что не меньше чем столько-то А вот не знаю опять же Это зависит от того где Мы набрали работников если это внутри компании то наверное нужно ориентироваться на зарплату других членов компании если это внешний та локер например внешний сервис то там нет таких ограничений и там можно платить Ну правда небольшие деньги это лока там то что цифра которая была там что-то типа 200 долларов за 10.000 элементов разметки Ну то есть это Это довольно мало на самом деле это недорого Вот но и качество может быть не совсем хорошее то есть баланс в целом чем больше заплатишь тем лучше качество очень зависит от задачи задачи очень разные бывают Ну вот 200 долларов чтобы получить 10.000 элементов для тройна например так на толоке Спасибо за вопрос вернёмся в эту часть зала вот первый ряд уже давно тоже руку поднимает А привет Спасибо за доклад Меня зовут Серёжа и у меня такой вопрос Вот ты говорила про работу с исполнителями и про перекрытие А можно ли смешивать эти два варианта объясню мысль А у нас есть работа с исполнителями мы им даём какие-то оценки мы их как-то оцениваем хорошие они или плохие и например для если у нас мы делаем какой-то трейдов если у нас э три плохих оценщика то там кворум достигается через три оценки А если оценивает хороший Исполнитель то она достаточно двух оценок то есть комбинируются ли эти варианты если у людей которые оценивают какая это репутация и в зависимости от этой репутации разное количество кворума нам требуется вот такое Да да да конечно в теории нужно использовать и то и то если вам ваша задача - это максимум выжить из всего вам нужно и работать с исполнителями и использовать перекрытие агрегацию а зависит от платформы типа в лаке например есть такое такой инструмент как ты какой-то скор работнику присваивает и потом если он ниже скор он просто например не попадает в твоё задание или ты можешь просто скор присваивать и потом выгружать результаты разметки и ну сам в процессе агрегации уже там дисконтировать этого человека и учитывать с большим весом что-то другое или в динамическом перекрытии это использовать Да совершенно верно спасибо Так Следующий вопрос Давайте того угла издалека Спасибо ещё раз за доклад Меня зовут Артём хотел с можно микрофон пожалуйста чуть поближе слышно слышно отлично а пробовали в целом такой подход брать Как языковую модель Да обогащать ей данные то есть брать там несколько похожих там текстов одинакового лейбла су маризи перефразировать и таким образом доки себе данные в дасе или это плохо работает и Ну в целом не очень подход А с изначально данными что делать их тоже оставлять или только самори зации поливать Ну нет просто доме условно домет Есть такие идеи я не могу сказать насколько хорошо они работают но идеи такие точно есть да там проблема что прогнать через самари зации там же огромное количество текстов терабайты И прогнать их через самари зации это довольно дорого и типа может быть есть более дешёвые способы на майнить себе данных Ну да в этой половине зала есть вопросы нет тогда пойдём Дальше можно вот на первый ряд и сюда потом Да спасибо за доклад Я занимаюсь компанией разметкой медицинских данных это своя специфика Вот и у нас заходит иногда подход что мы в обучение прокиды айдини врача который размещал нам данные то есть используем информацию кто Ну что это некоторая унифицированная исто вот используете ли вы такой подход и дат ли Если да Дат ли он прирост которыми я занималась Нет мы такое не используем явно Но идея отличная Да единственное сколько у вас если у вас конечное количество там не тысячи а там десяток врачей Наверное это будет лучше работать чем если у вас тысячи разных исполнителей которые меняются всё время да наверное можете унифицировать разметчики между собой кто-то наверное похожим образом размечается это нуже какой-то классификатор который такой приходит Да да да ну то есть пока не используете Нет ну идея отличная Да спасибо да из центра Следующий вопрос А привет Спасибо за доклад Меня зовут Айгуль и вопрос Ну поразмышлять наверное в Яндексе очень часто во многих разных проектах использовать ку ну для разметки для того чтобы были вейб и всё такое проверять там что не знаю Алиса какую-то пургу нею сказала вот э но при этом как бы э сейчас все э совпадения случайны и так далее Ну вот я работала в компании в которой Э не занимались разметкой Ну то есть как бы брали какие-то клики не знаю там покупки и всё такое и обучались на это Но при этом как бы э неплохо было бы размечается ну ощущение у людей точнее скептик в сторону Локи что вот там сидят какие-то школьники какую-то фигню размечают и вот Ну как в такой ситуации человеку который как бы считает что вот ну знает как что вообще-то этим инструментом можно иметь пользоваться можно там настроить не знаю разметку контроль качества и так далее Как ему помочь какими доводами помочь убедить коллег что вообще-то к - это ну тоже инструмент которым можно пользова А какую задачу мы решаем чтобы Зачем нам чтобы Ну хочется чтобы какие-то алгоритмы были более качественными наверное Ну вот Ну что если мы делаем там в смысле данных не хватает или нет уверенности в их точности Мы хотим повысить данные рные данные грязные Мы хотим почистить данные хотим хотим контролировать хотим контролировать например там условно релевантность поиске и знать что ну она действительно вот такого порядка регулярно иметь какие-то дашборды и так далее сложный вопрос зависит конечно от человека как увидить человека что нужно использовать лаку а есть ещё один порог входа не только тот факт что дамы скепсис Да там школьники там в целом не знают лаку там какой-то чужой интерфейс Ну как бы вот изнутри Яндекса понятно там у нас есть ошка внутренний инструмент все привязаны а снаружи Я слышала отзывы что очень тяжело понять Вообще что куда как там Создать и так далее А я думала что это в основном проблема а вот всё остальное оно решаемо вот это просто Че через это перебороть сложнее а всё остальное Ну типа нужно сделать контроль ка нужно сделать фильтры экзамены в общем ВС по Если идти по методичке то можно гарантировать себе хорошее качество Это точно решаемая проблема просто нужно в это вложить не знаю там пару месяцев ресурс человека который поднимает Этот проект убедить людей в том чтобы вложить эти ресурсы не знаю Ну тут можно такие аргументы что вот смотрите Яндекс большая компания Они же используют наверно Неплохая идея может мы тоже будем ива мотивация универсальный ответ Спасибо так Следующий вопрос тоже рядом Ну у меня здесь на самом деле не вопрос А вот комментарий к предыдущей дискуссии Я ведь насколько я знаю Если не ошибаюсь на Яндек толоке Теперь ещё и там нужно как самозанятому оформляться Вот то есть как такое дополнительное препятствие которое может с количество разведчиков вот мы это уже ощутили в девайсах частично тоже используем на некоторых проектах уходит из России там вот такие фокус Теперь нужно делать но в любом случае можно не толокой пользоваться А другими сервисами есть можно самим человеков нанять можно не знаю Если он чем-то вдруг больше нравится чем Яндекс задание может быть слышали Нет спасибо за комментарий пожалуйста вот Следующий вопрос Да у меня е не вопрос е одна интересная история по дали Один мой друг не буду говорить кто вы его всё равно все не знаете когда-то работал аналитиком в скоринг в коллекторских агентствах и собственно Когда уже клиент которого коллекторы не могли выбить деньги Ну выходил на связь но уже было понятно по скоринговый модели что всё он уже внизу где-то его от него денег не получить ему предлагали размечается ему списывали за это долг получали По сути как бы такую бесплатную себе разметку Вот это коварство Ну да коллекторы они такие куда деваться хотя бы что-то выбить Да полезное Спасибо друзья Есть ещё вопросы пожалуйста а просто по разгонять Можно ли автоматизировать написание и дополнение инструкций для метчиков исходя из данных а ну как смотря что называть автоматизацией я думаю что гпт не самый хороший вариант не настолько он хорош пока Ну автоматизация с точки зрения искать проблемные точки то есть допустим какой-то если у нас классификация какой-то класс мы знаем что мы на нём ложа и мы как-нибудь пытаемся авай методами понять какие там есть сложные кейсы и дополнить инструкцию Там просто очень много всяких мелочей типа уже есть даже не авай методы А есть уже какие-то листики которые тебе говорят что что-то не так с разметкой вот где-то здесь не так примерно надо идти разбираться тут проблема скорее что их много и что нужно идти и разбираться в каждой из них там например ты пост поставил очень высокие пороги на экзамен и люди медленно размечают и или ты поставил какие-то ещё хорошие низкие пороги и у тебя сегодня с таким качеством размечают завтра с таким Например у тебя есть мониторинг качества по примерам которые ты там по ним не бани Голден сеты Вот и сегодня так а потом так и тут как бы приборы то в целом есть автоматизированные что куда-то надо копать А вот копать Спасибо всё закончили Насть все вопросы помнишь ой ой очень много вопросов Спасибо большое Мне все мне понравилось три на самом деле нужно выбрать один только один да Ну про приватность вот нас приватность очень всех беспокоит очень хороший вопрос и за вопрос да о приватности получает подарок от нашего партнёра Газпромнефть Насть ну ты тоже не убегай У нас для тебя тоже есть подарок большое тебе спасибо что поделилась своим опытом А дала какие-то советы тоже и приходи к нам ещё рассказывай Спасибо большое спасибо"
}