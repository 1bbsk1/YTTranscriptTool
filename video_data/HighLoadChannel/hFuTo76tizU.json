{
  "video_id": "hFuTo76tizU",
  "channel": "HighLoadChannel",
  "title": "Оптимизация производительности запросов в ClickHouse / Максим Кита (ClickHouse)",
  "views": 6840,
  "duration": 2527,
  "published": "2023-04-28T06:10:46-07:00",
  "text": "Всем привет Меня зовут Максим я разработчик кликаус и в кликхаусе я отвечаю за словари за джит компиляцию за анализ и планирования запросов Но больше всего в последнее время я занимаюсь оптимизациями производительности И сегодня я поговорю из чего вообще состоит производительность кликауса я мой доклад будет разбит на такие следующие секции они как бы практически независимы друг с другом и вывод на своем проекте Можете потихоньку пробовать разные советы и практики для разогрева давайте начнем с высокоуровневой архитектуры Клик Хауса собственно все наверняка знают что Клик хаус это лап система колоночная база данных и данные мы храним по колоно что нам это дает во время выполнения запроса только необходимые колонки читаются и за счет того что похоже данные лежат рядом обеспечивается улучшенная компрессия данных лучше нажатие данных Кроме того что мы храним данные по колоночным и обрабатываем их по колоночка мы обрабатываем данными блоками по дефолту размер блока 65000 505 и блок Это всего лишь массив колонок колонка это некоторый массив примитивного типа и такой вот подход в движке выполнения работа с массивами позволяет нам во-первых улучшить утилизацию кишечник пью но также позволяет компилятору генерить кот с использованием синд-инструкции или В некоторых случаях мы можем это делать сами чуть-чуть подробнее рассмотрим Из чего состоит колонка колонка все колонки в самом низу состоят из массивов и массив откликался Это не студвектор это под A чем подари отличается от студвектора Ну во-первых по Дары используют наш локатор наша локатор поддерживает метод reallock это работает намного лучше чем стандартный Ну локатор так как мы например используем специализации и в случае realoco используем функцию для больших массивов также мы не делаем мы не делаем когда на массив нужно отрицать довольно часто возникает практика когда пишет человек-код И у тебя есть несколько массивов входных и там выходной массив нужно чего-то записать и довольно часто это все делается в цикле и перед циклом нужно сделать resis чтобы сразу писать по индексу в таком случае компилятор сможет реактеризовать и как раз таки используется resis и стандартный Вектор он как бы дополнительно сделает и была такая приятная особенность мы делаем паддинг 15 байт на конце эти 15 байт позволяют нам не обрабатывать хвосты во время функции мемкопи то есть еще некоторые дополнительные производительность и более сложные колонки они состоят из более простых колонок Ну например колонка это некоторая колонка с данными и колонка которая содержит питовую маску элемент Ну или нет например колонка массив это колонка с данными плюс колонка с абсетами и также есть такая интересная колонка константная колонка Но это просто одно значение и Если кто-то захочет разобраться как это устроено в коде за все это отвечает класс это некоторые такой полиморфный класс Мы его таскаем среди через интерфейсы реализуем например интерфейсы функций входные параметры будут вот эти вот и что он делает объявлены методы которые в принципе нужны чтобы выполнять различные реляционные операторы на слайде видно что тут есть например фильтрация получение перестановки для ордер бая ставка данных в большинстве функций вот этот вот тип просто приводим к какому-то конкретному типу и работаем с ним уже без использования виртуальных функций просто с использованием специализацией и такой некоторые еще прям супер высокий уровень что вообще происходит когда запрос попадает в кликхаус Мы сначала парсим его вести зачем Затем мы делаем некоторые HT оптимизации там некоторые довольно даже сложные Мы хотим это все перенести на логические физический уровень затем мы из этого исте строим логический план затем оптимизируем логический план затем строим физический план оптимизируем его и в принципе дальше Просто выполняем это физический план вот мы немного поговорили про архитектуру на высоком уровне теперь стоит поговорить про очень важную вещь Хаусе за счет чего в принципе мы можем двигаться так быстро это стоит у нас из следующих компонентов это функциональная интеграционные тесты все тесты мы гоняем под всеми возможными санитазерами Это Сан У нас есть дополни браузеры фазеры типов данных фазеры compression кодеков У нас есть специальный ICT piser который может генерировать разные странные запросы и все вот эти файзеры тоже работают естественно под санитайзерами мы гоняем стресс-тесты У нас есть например специальный стресс-тест с анитазером который оверяет методы Например у Condition variabloutex чтобы создавать больший контеншн рассылает сигналы остальным потоком и у нас есть например специальные тесты где мы вообще рандомизируем все настройки кликаусе это все тоже гоняется под санитазерами и самое интересное про что мы сегодня поговорим это Форма с тестом Что такое перформанс тесты запускаются на каждый коммит в каждом полудра квесте и на каждый коммент мастер Из чего состоит перфоманс тест это просто некоторый такой xml-ный Файлик напайтоне тут есть некоторые вот подстановки чтобы код лишь не дублировать и стоит обратить внимание на такую секцию query это запрос там вот есть какие-то подстановки с какими-то данными он работает и вот это собственно говоря Запрос который будет перформа и использоваться Как выглядит формат тестов но у нас есть Старый коммит У нас есть новый commit У нас есть время старого запроса время нового запроса Насколько изменилась производительность какие это были запросы Вот и также во время запуска пифама с тестов Мы собираемся возможные статистики для чего мы это делаем Ну чтобы потом если что-то пошло не так или что пошло хорошо понять мы действительно повлияли на изменения там провести некоторую отладку мы собираем кучу всяких статистик я про них поговорю еще поподробнее Ну например интересно мы собираем статистику перфа циклы например по ним по этим всем статистикам мы можем строить графики вот так вот например выглядит график после тестов мы прогнали тесты Мы можем взять и посмотреть цикла себе и Тут видно что старый запрос там фиолетовый получается Треугольники а новый запрос это зеленые треугольники Вот и то же самое например для софт То есть это очень полезно например Представьте вы решили что-то оптимизировать нашли какой-то лишний и убрали его смотрите запросы ускорились можете посмотреть например brunch Miss и увидите что их стало меньше Окей но PE formance тесты это не только про регрессии Многие думают что это только для нахождения регрессии Это не совсем так тесты это так скажем инструмент который помогает нам реально ускорять производительность во многих сценариях Ну например мы можем пробовать разные локаторы и смотреть как ликхаус отреагирует на другой локатор Какие запросы ускорились чтобы потом эти запросы могли уже лично руками пойти посмотреть мы можем пробовать разные библиотеки это тоже очень интересно Ну там например какую-то новую библиотеку для парсинга например джессона мы можем пробовать разные опции компилятора например лупан роллинг мы включаем там ролик на максимум смотрим Что ускорилось потом идем эти запросы и локально в тех циклах делаем этот ролик мы можем пробовать разные компиляторы пробовать там играться с GTC с клиентом и очень интересная штука про которую я еще потом поговорю мы можем включать avx2x512 и смотреть какие запросы ускорились затем мы для этих запросов просто идем и руками делаем динамик диспач Я просто говорю и как вообще писать перформа вот эти вот запросы к пифама с тестах Ну во-первых запрос не должен быть слишком коротким потому что в таком случае он ничего не меряет запрос не должен быть очень длинным потому что в таком случае он подвержен различным внешним факторам например диски сеть баги в ядре там например перегретый CPU все это может повлиять на ваш перформанс тест и чтобы грамотно написать тест запрос в идеале должен тестировать какую-то фичу какую-то функцию какой-то маленькую вещь именно в изоляции то есть как-то так и очень важный момент который на который натыкаются все начинающие разработчики которые пытаются оптимизировать производительности они начинают тестировать свои там например таблицы и все такое на Нереальных данных всегда тестируйте на реальных данных реальные данные например для почти любых нагрузок Вы можете взять сайта Клик Хауса мы используем фольцированное данные Яндекс метрики Окей и немножко расскажу поподробнее про пифам с теста мы запускаем два сервера одновременно два сервера кликауса на одном сервере одновременно Мы гоняем пифама с тесты как бы то с одним сервером то с другим сервером затем мы считаем медианы разницы вот тестов и также мы используем разные статистические методы считаем максимальную разницу в этих максимальную разницу в медианах которые мы могли бы получить если ничего не поменялось мы назовем эту статистику т и затем вот мы посчитали разницу в медианах используя статистику и вот используя статистику то мы в принципе можем понять у нас вообще были изменения существенные или несущественные и это как бы все понятно все довольно просто но вот есть интересный момент что если у нас вот это вот статистика например как условно говоря статистика если изменилось на 10 процентов то есть статистика что у вас изменилось производительность когда ничего не поменялось Что же нам делать в этом случае Понятное дело что для таких запросов мы вообще никак не можем про производительность говорить то есть производительность для таких запросов просто скачет мы их называем нестабильные запросы нестабильные запросы Они вообще говоря довольно большая проблема для тестирования производительности потому что нужно разбираться почему же все там пляшет Ну например из моей практики Вот это самые основные проблемы это во-первых лишняя локации очень большие копирования сам запрос может быть плохо написан и у Вас могут быть разные Внешние факторы например проблемы с дисками проблемы сетью background активности и мы должны удалять или переписывать тесты только если у нас запрос плохо написан во всех остальных случаях мы должны разбираться глубоко что же там все-таки произошло я покажу некоторые такой простенький примерчик вот у нас был перформанс тест это написано функционал НЛП получается некоторые такие новые функции которые могут определить язык или Определи э определить характер сет и в эти вот тесты они в производительности довольно часто прыгали было непонятно что они прыгают Ну и Пришлось мне взять и разобраться собственно говоря я зашел в эту функцию зашел в цикл и опытный разработчик на c++ сразу увидит проблему мы аллоцируем Хеш таблицу внутри цикла это все очень плохо и также немножко прокомментирую Что происходит в цикле Вы только что таблицу мы записываем энграммы и затем эти вот он граммы мы сравниваем с уже какими-то заготовленными словами и смотрим С какими словарев у нас самый близкий матч принципе все довольно просто и вот таблицу мы так потестировали посмотрели и просто поменяли на хэш таблицу с которой будет аллоцирована на стеке У нас есть свой Framework для таблиц мы вот так вот поменяли И что же вы думаете произошло конечно же произошло увеличение производительности примерно до 4 раз буквально на ровном месте Окей Теперь давайте поговорим немного про интроспекцию собственно говоря в кликхаусе я могу с уверенностью сказать что мы собираем все что только можно собирать userspacy Мы например собираем метрики используя системный вызов гетеросорс usage различные метрики например софт-печ Falls hordpress fals Мы также собираем структуру Task stats из process Мы также поддерживаем netlink интерфейс этой структуре и мы можем например посмотреть как работает шедоллер Сколько байт Мы записали это мы делаем И это еще даже не все мы можем для каждого конкретного запроса включать профилировщик внутри хаоса то есть внутри кликался Что может быть лучше мы используем для этого системный вызов и это даже еще не все у нас есть куча метрик которые считаются прямо внутри Клик Хауса сейчас их у нас больше 300 это Например сколько файлов было открыто во время запроса сколько мы потратили на чтение с дисков на пересылку каких-то там например данных по сети статистика закипера статистика джейма лока и все эти метрики можно экспортировать например в графит про митис И как это все работает Ну например Представьте вы пришли сделали какой-то запрос и хотите разобраться что же все-таки происходит внутри запроса вы делаете запрос System query Lock указываете ID запроса и смотрите вот эти вот Ну например конкретно на данном слайде указано Как посмотреть статистику perf рентов можно посмотреть так например сколько на каждый запрос у вас было например затрачено там цикла все пью Сколько было брать весов всё хорошо работает но это еще не самая крутая фича которая есть Хаусе Мы периодически собираемся со всех потоков как мы это делаем мы отправляем всем потокам периодически сигналы и в обработчики сигналов собираем все интерфейсы для этого ваш бинарник должен быть скомпилирован со специальной опцией f-синхронной онлайн tables и в таком случае все будет работать но нужна какая-то специальная библиотека мы используем патчину версию библиотеке которая умеет раскручивать стек Но кроме Зачем вообще патчили Ну во-первых например если у вас компиляторе бак он может секцию которая отвечает за вот эти вот информацию о стыковых фреймов она называется hram Может там допустить какой-то Баг и Вас например все по интернеты поедут и кликался упадет это недопустимо это первая проблема мы по фиксале и вторая проблема то что по дефолту это библиотека была не сигнал Save мы это тоже выписали и как это может работать Ну представьте вы зашли на сервер вам кто-то говорит что у вас сервис задолчился Он такое не происходит и вы можете просто сделать запрос из Systems и посмотреть что же сейчас происходит вот на данном слайде видно что тут есть какой-то трэт он ждёт на кон рибля скорее всего к пока там начнется запрос или вообще какого-то сигнала Окей но когда мы получаем возможность собирать Так Трейси мы можем делать еще более крутые штуки Ну например мы можем сгенерировать сгенерировать Flame Граф прямо не выходя из кликауса Что такое Fly Граф нужно почитать по ссылочке но штука довольно таки полезная можно посмотреть какие у вас так трейсы реально были горячие Где больше всего вы проводили времени И что самое интересное самая большая проблема у таких вот начинающих разработчиков это как вообще мерить производительность распределенной системе ведь Ну если вы будете мерить на одном шарде все понятно и включался на этот случай Мы можем обращаться к этим всем таблицам используя кластер табличную функцию То есть у вас произошел запрос вы пошли со всех участников запроса с кластера собрали все эти статистики по агрегировали и можете строить и Flame графы и все графики выводить очень удобно Теперь давайте Немного поговорим про абстракции и алгоритмы опустимся так скажем на уровень ниже что у нас есть на уровне ниже Ну во-первых про это уже довольно много говорил например Лёша миловидов можно посмотреть его китайский Его доклад с конференцией btc 2019 году тут я добавлю еще несколько вещей от себя Ну во-первых высокопроизводительная система интерфейса высокопроизводительных систем должны быть определены алгоритмами топ дал на прочь не работает Если вы будете сначала пытаться дизайн какие-то крутые интерфейсы а потом будете пытаться писать низкоуровневые структуры у вас это все работать не будет так как интерфейс должен определяться структурой то есть каждая структура она может условно говоря дать вам оптимальный интерфейс чтобы там не было лишних копирований условно говоря интерфейсом вы раскроете какую-то структуру данных также важный вопрос Это то что высокопроизводительная система поначалу должна работать Хорошо хоть на одном конкретном сценарии кликаунте - это сценарий это фильтрация агрегация данных которая помещается в оперативную память и важный момент дизайнить вашу систему нужно исходя из возможности вашего оборудования как это можно делать Давайте предположим У вас есть таблица Как можно смотреть Нормально ли у вас работает таблица если у Вас например все данные помещаются в каши то все понятно Если у вас все данные не помещаются в каши то нужно посчитать доступ к manory например это будет 100 на секунд потом это все можно посчитать посмотреть сколько у вас принципе должно быть локопов в секунду на одно ядро и проверить ваших таблицы тормозит или нет И также что стоит отметить что нет никакой Серебряной пули нет никакого лучшего алгоритма для конкретно вашей какой-то задачи Вы должны для своей задачи пробовать просто разные алгоритмы пробовать разные подходы смотреть Что работает А что не работает И обязательно все это делайте на реальных данных все алгоритмы подвержены распределению данных и например алгоритмы фильтрации алгоритмы джойнов алгоритмы сортировки зависит от количества уникальных значений например все это нужно учитывать и вот несколько советов от меня например у вас есть какая-то сложная задача вы пытаетесь представить себе как несколько каких-то простых задач и для каждой простых задач Вот разбирайте её в отдельности а потом когда вы разобрались уже в отдельности какие-то взяли структуры данных какие-то выбрали алгоритмы Вы можете Начинать тюнить все всякими низкоуровневыми трюками про которые сегодня поговорю и вот эти вот низкоуровневые трюки там например могут быть различные специализации 7 инструкция И я покажу пример как это можно рассуждать чтобы Вы могли также рассуждать про свои системы Ну вот у нас Самое интересное это конечно же агрегация агрегация она изначально планировала сделать не только на одном сервере А на множестве серверов в таком случае что получается получается так что архитектура масштабируемая хотим например быстрее обрабатывать на одном узле докидываем туда например оперативки покупаем получше оперативку получше сети хотим например масштабироваться горизонтально тогда добавляем шардов внутренний компонент самый низкоуровневый компонент который у нас очень серьезно написан Это фреймвор для таблиц и в нем же находится множество специализаций Например у нас есть специальная таблица для строк маленькие большие таблицы всякие лукап таблицы все это у нас есть и затем после того как у вас есть вот скажем короб вещь можно начинать добавлять специализации Ну например для нула был колонок для Лок кардиналети колонок для спар с колонок мы тянили множество lol вещей например уменьшали количество локаций улучшали размер структур в памяти батчили множество операций вместе чтобы избегать количество виртуальных вызовов затем мы добавляли Jet компиляцию в грубой и вот недавно мы добавляли кэш- предсказание размера и оптимизировать производительность Это обычно пытаться много всяких разных подходов делать но почти всегда без каких-либо результатов и еще такой полезный пример Как можно рассуждать проблему с разных степеней свободы Ну то есть у каждой проблемы есть много разных степеней свободы Вот например Давайте разберемся сортировкой сортировка может быть стабильной или нестабильная она может быть во внешней памяти или полностью помещаться в оперативку она может быть с лимитом или безлимита у вас может быть данные уже отсортированы или почти отсортированы или совсем не отсортированы Какой у вас распределение данных Какое количество уникальных значений ведь алгоритм должен хорошо работать Даже если вы сортируете просто массив с одним значением Можем ли мы использовать их авторизованный алгоритм сортировки А можем ли мы отслеживать дополнительную память и Когда Вы начинаете отвечать на все эти вопросы ваш как бы поиск алгоритма существенно снижается виднее существенно ускоряется и еще такой дополнительный совет от меня вот как я это вижу почти всегда хороший дизайн выглядит примерно так У вас есть некоторые низкоуровневая вещь которая прям всё оптимизировано написано в таком можно сказать хакерском стиле не важно и вокруг неё вы делаете высокоуровневые абстракции например какие-то красивые там c++ интерфейсы и все такое И у нас это работает и причем во многих местах Ну например я уже сказал пример агрегация агрегация по сути обёртка над крутой хэште таблицей Хаусе У нас есть компоненты поменьше например раньше словарь это обертка над статическим интервальным деревом которое находится в оперативной памяти и у нас есть сортировка и вставка в Мерс 3 недавно в марте начали улучшать фреймворк наш для сортировки мы добавляли кучу специализаций И вот я даже сейчас несколько примеров покажу например вставка Почему вставка для вставки вообще нужна сортировка Ну потому что когда вы вставляете данный сначала нужно посортировать по первичному ключу и затем записать на диск И вот в это вот месте сортировку Мы немножко упирались и все это дело переделали теперь ставка 3 в 2 в три раза быстрее в клип хаос то есть это доступно уже с марта и очень интересная штука которую я с которой я довольно долго боролся это Как оптимизировать сортировку кликхаусе сортировка в кликауте не то чтобы наш самый крутой юскейс но хотелось бы чтобы она работала действительно быстро потому что многие системы говорят что у них самая быстрая сортировка на западе в общем ускоряли мы вот эту вот сортировку и удалось ее ускорить примерно в 10 раз за счет использования кучи разных специализаций различных пробовали разные структуры данных для мира и собственно говоря выглядит Это примерно так у нас есть несколько уровней вокруг которого у нас есть какие-то хайла обвязки Окей и Давайте Немного поговорим про такой Перекур поговорим немножко про библиотеки собственно говоря что сказать про библиотеки в плехаусе если кто-то говорит что в интернете есть самая крутая библиотека самый крутой Solution мы находим такие библиотеки тащим и к себе пытаемся их как-то протестировать И иногда они действительно в тайском их продакшн иногда не таскаем например сейчас у нас 97 внешних зависимостей что у нас есть во внешних зависимостях но у нас есть разные алгоритмы для парсингасонов например для парсинга флотов У нас есть куча разных интеграций например сажур с 3 У нас есть различные хранилище встроенное Например roxdb у нас есть эливен целый левее Мы таскаем в Клик Хаусе для Jet компиляции и у нас есть даже стандартная библиотека c++ для чего для того чтобы Билл был герметичный и почти во всех системах наша вся система про которую я говорил находит баги мы эти баги фиксаем мы их в формате мейнтейнером мы стараемся все это влить мать Ну обратно в Мастер но у нас есть также множество библиотек множество своих форков с кучей прям вот наших чейнджей которые мы поддерживаем постоянно это полка например и это либо про который я уже говорил и мы не боимся добавлять лишний как бы лишний внешнюю зависимость потому что наша вся система она сделает свою работу мы не уверены мы уверены что она найдет магов если они там есть и теперь давайте перейдем к Ниндзя техникам вот представим что все что я до этого рассказал никак не помогает вам у вас это все уже сделано в продакшене И вам реально нужно ускорять не ускоряемое что же тогда делать я расскажу два подхода первый подход этот жидкомпиляция Jet компиляция позволяет трансформировать какую-то динамическую конфигурацию в статическую конфигурацию и не все функции легко скомпилировать не все алгоритмы легко скомпилировать Но если это все сделать у Вас могут быть значительные улучшения производительности также нужно понимать что этот компиляция это не серебряная пуля у нее свои Касты например вам нужно где-то в памяти хранить код который Вы скомпилировали у вас на компелейшем тайм у Вас ухудшится например каких-то там разогревающих запросов и вам также нужен человек который разбирается компиляции всего этого И покажу несколько примеров что мы вообще компилируем кликался мы компилируем вообще всё что только можно вот например и у нас есть выражение а плюс B умножить на с плюс 5 мы его компилируем У нас есть специальные случаи грубая например selectum of Count мы вот эти вот три агрегата скомпилируем в одну такую функцию И кстати говоря многие скажут Ну зачем такое делать у одного знакомого так скажем человека было около по-моему тысячи сум в одном запросе Ну просто Селект и тысячи сумм по разным колонкам в таком случае это довольно серьезно все это дело ускоряет и Мы также можем оптимизировать компилировать компаратор worderbaya например колонкам это будут лишние виртуальные вызовы Мы хотим как бы сделать такую функцию сравнение и во всех этих случаях мы Превращаем динамическую конфигурацию статистическую конфигурацию вот Давайте возьмем к примеру компиляция выражений для компиляции выражений У нас есть условно говоря Как выполняется выражение В базах данных для вот этих вот выражений а плюс B умножить на C плюс 5 строится дерево выражений затем это дерево выражение Оно обычно состоит там например колонки функции константы и мы снизу вверх как бы его обходим где-то нам нужно хранить промежуточное значение у нас происходит какие-то лишние виртуальные вызовы и такую конфигурацию я называю динамическая конфигурация и хотелось бы все это скомпировать как бы в одну мощную красивую функцию я делал презентацию на c++ Russian в прошлом году про Джет кликаусе те кто хочет познакомиться поподробнее с ней вот есть ссылочка на сайте и давайте как раз таки посмотрим этот пример потому что он такой самый красивый вот у нас есть такие выражения а плюс B умножить на с плюс 5 как это выглядит компиляция Вот это выглядит псевдокодом на c++ Тут есть функция Она такая одна чтобы ну было понимание что вот это все как бы в одну такую функцию сворачивается и у нас есть результирующая колонка У нас есть какие-то входные колонки у нас есть Константа и вот такой цикл такой цикл любой серьезный разработчик на c++, скажет это очень хороший цикл он бектеризовал викторизуется и производительность будет очень серьезная и вот это настоящая Сэндлер который я взял склик Хауса в принципе понимать что тут написано не надо нужно видеть что тут есть какие-то серьезные инструкции что оно все викторизовано я даже пометил что вот Константа Пятерочка вот это вот она была тоже за инлайнена в этот ассемблер то есть Насколько быстро это будет работать Вы можете прикинуть Но это еще не все это такая первая техника но вторая техника она такая еще более хакерская собственно говоря крихаус мы распространяем как такой универсальный бинарь этот универсальный бинарь по дефолту поддерживает старый instruction Set 4.2 Ну как известно есть новая instructions это Например avx2x512 и различные оптимизации делаем мы различные оптимизации нам приносит компании например Intel conten Square и хочется оптимизации использовать но как бы не хочется жертвовать по стабильностью бинаря в таком случае можно использовать технику которая называется динамик диспач собственно говоря весь наш курс компилированности 42 но конкретно выборочная функция мы компилируем вот этими вот инструкциями и фронтальными мы используем инструкцию на Андроиде у процессора Смотрим как бы спрашиваем процессор ты поддерживаешь VX ты поддерживаешь vx2 ты поддерживаешь vx512 если он это делает мы используем эти вот специализации и тут Важно держать в уме то что компиляторы сейчас они могут даже довольно сложные циклы викторизовать вам в принципе не всегда даже руками нужно прям что-то такое самому пикторизовать И как я уже сказал основная идея Мы компилируем весь наш процесс 4.2 а часть кода компилируется в x20x512 и фронтальная Используйте смотрим Какие инструкции поддерживаются и запускаем специализированную функцию тут сейчас пойдут некоторые макросы но не пугайтесь все тут будет довольно просто собственно говоря например для кланга функции нужно пометить таким вот специальным макросом атрибут там какие-то еще атрибуты там можно указать С какими инструкциями тебе эту функцию нужно скомпилировать мы говорим это клангу И вот вокруг вот этих вот макросов у нас уже как бы более высокий уровень макросов мы можем определить Вот примерно так на слайде то есть определяем код с дефолтным экстракшн сетом с avxvx512 и затем мы используем снизу на слайде диспач функцию вот там есть арч из арчиса портит мы проверяем вот avx2 поддерживается если поддерживается давай-ка мы позовем функцию с avx2 но Standalone функции нас не интересует И вот я задался таким такой проблемой Как же сделать чтобы это работало для мембер функций потому что довольно часто у вас следующая ситуация у вас есть какой-то класс Вы знаете что вы убираетесь функцию в этом классе но сделать выносить ее как Standalone функцию совершенно не хочется для этого можно конкретная функция помечать именно функцию помечать прям атрибутом они секцию с кодом тоже с использованием естественным макросов и чтобы мы хотели сделать в общем идея примерно такая вот у нас есть функция и мы хотим как бы перед именем функции вставить вот атрибут а функции имя поменять как бы добавить туда префикс например avx2x512 то есть мы хотим сгенерировать код когда человек на себе слышит про генерацию кода он сразу думает про темплейты и про макросы в данном случае мне пришлось написать такое вот макрос выглядит этот макрос не очень красиво но как я покажу дальше работает он очень эффективно собственно говоря мы разбиваем функцию на какой-то ее заголовок то есть там с типами с возвращаемым значением с темплейтами разбиваем на имя функции перед именем функции мы как раз таки вставим вот этот вот наш атрибут который мы хотим ставить и после имени функции мы добавим суффикс и затем У нас есть тело функции собственно говоря примерно так оно макросы заворачивается и все вот у нас готова эта инфраструктура куда же сейчас нам сунуть этот макрос чтобы всё работало быстро собственно говоря Как находить такие места мы берем и собираем наш код с avx512 и смотрим Какие же функции ускорились мы посмотрели Опа функция ускорилась надо посмотреть наверняка там где-то цикл мы находим этот цикл и его заворачиваем в макросы И сейчас я покажу несколько примеров чтобы убедились как просто это работает у нас есть такие функции агрегатные например сумм everage который работает с множеством значений и у нас есть дополнительная специализация что когда ключи в грубое Нет просто условно говоря селекцию из таблицы то мы просто значение сразу перечитываем и видно что тут есть цикл я его пометил и вот как раз таки мы убедились что с vx2x512 это все работает намного быстрее OK Теперь нужно все это завернуть наш крутой макрос мы заворачиваем это все в наш крутой макрос делаем там десять функцию она немного не поместилась на слайде Я думаю Понятно А вот он как раз таки на следующем слайде вот мы такую вот делаем 10 функцию и после того как мы сделали здесь функцию тут видно что мы как бы условно говоря довольно сложный кейс тут например есть template но все равно вся инфраструктура нашей работает мы вставляем макрос стоит ли нам все вот эти специализации использовать по дефолт это все включено И Например если vx2 поддерживается мы вызываем специализацию в X2 если специализация sse 42 поддерживается мы вызываем ее как-то так и собственно говоря Насколько это все ускорилось все ускорилось довольно серьезно для сумм для Ever Edge почти все функции ускорились полтора в два раза если говорить про там например некоторые функции еще дополнительно еще больше потому что в некоторых случаях бывает такой паттерн что компилятор понимает что условно говоря он может викторизовать не просто цикл В тупую а какую-то более умную оптимизацию применить И вот я расскажу про свой самый любимый квест в этом году как мы оптимизировали цикл лунарных функций цикл лунарных функциях выглядит примерно так у нас есть входной массив функцию и выходной массив куда мы хотим результатной функции записать он уже провоцирован он уже нужного размера мы идём циклом по вот этому Вот по первому массиву и применяем такой лук об аплай Опа Play это о конкретного оператора такой темплейный какой-то метод который делает функционал этого оператора унарного Окей мы применяем этот лупа Play и мы просто заворачиваем все это дело в нашем макросы вот в данном примере Все выглядит намного даже чище говоря мы это все завернули и смотрим для функции rounduration все ускорилось в 7 раз вот это как раз таки тот пример про который я рассказывал что вот эта функция внутри нее есть какой-то паттерн который можно не просто по тупому викторизовать а применить какие-то более сложные инструкции и для avx2 для vx512 я вот довольно часто говорю пройти оптимизации и почти всегда говорю X2 и почти никогда не говорил x512 Почему Потому что например для X2 мы используем такие оптимизации Ну почти везде где-то возможно для avx 512 мы пока что не везде используем такие оптимизации Почему Потому что 512 у некоторых инструкций есть сайт эффекты за счет которых у CPU частота Может понижаться это может пофигтить как Click House так и какой-нибудь соседнее приложение которое с ним работает И что же в этом случае делать для последних Intel процессоров таких как Rocket Lake и islake эту проблему уже пофиксили Мы можем бронтами задетектить у тебя процессор этой модели или нет Если ты все же использовать оптимизации и у нас есть билды avx512 которые мы постоянно гоняем все можно посмотреть например насколько там какие-то вещи быстрее какие-то медленнее очень интересно и немножко в заключение собственно говоря что сказать заключение внутри всего как бы производительности у нас лежит вся сиди payline это все не случайно потому что например когда люди там оптимизируют какие-то вещи там почти всегда появляются какие-то баги какие-то кейсы которые это все нужно аккуратно уметь тестировать перформанс тесты ядро ciscd инфраструктуры и без глубокой интроспекции без глубокой интроспекции в системе вообще как бы никакую производительность оптимизировать нельзя почему Ну в хорошем случае когда у вас все всегда работает все всегда оптимизируется она в принципе не нужна но в случаях когда что-то начинает работать плохо Нужно пытаться понимать вообще там например что происходит внутри системы и даже если например вы улучшили какую-то производительность тоже очень интересно посмотреть А реально ли там например какие-то метрики поменялись то есть ваш код ваши изменения реально какие-то метрики для высокопроизводительных систем интерфейсы должны определяться алгоритмами после того как основные какие-то алгоритмы составили основные интерфейсы составили можно переходить к обработке специальных случаев Ну там например ну был кардинально как мы обрабатываем и затем После всего этого Пора начинать тяните вашу производительность на прям вот на низком уровне то есть менять добавлять компиляцию добавлять динамик здесь патч как-то так аплодисменты больше футболок Богу футболок поэтому за вопросы о том Почему кликхаус не тормозит второй спикер тоже будет выдавать футболки и Давайте поиграем в эту игру ваши вопросы прошу Спасибо за доклад вы упомянули что вы затягиваетесь к себе все Все самые крутые я так полагаю себе все контейнеры в частности хаши не ведете ли вы какую-то статистику по тем контейнерам которых к себе затянули с локатором я скажу так обычно прям низкоуровневые компоненты которые критически у нас написаны все свои Мы обычно тащим только библиотеки которые прям нужны Но они уже хорошо тестированы например все таблицы у нас свои функции по моему тоже довольно много написано всяких своих каких-то куча своих специализаций Мы прям вот такого почета не ведем Но больше всего Ну прям я скажу 50 процентов плюс этой интеграции например библиотечка для grpc библиотечка для ажур для стрима Что такое больше всего так Смотрим еще вопросы левая сторона зала фронтенд прошу Максим Огромное спасибо за доклад И чудовищное спасибо за кликаю за вашу работу это прям что фантастическое сорян У меня вопрос не по теме вашего доклада но вначале упомянули о том что словари это ваша Вотчина и хотелось бы уточнить Какие вы видите лимиты на использование словари кроме оперативной памяти то есть какой момент происходит какая-то деградация собственно для того чтобы использовать словарь на удаленную шорде со словарем принципе Все упирается только в оперативку Какая у вас оперативка больше так скажем него что не упирается То есть если например Какие реально задачи могут решать словарик которые вроде как по-другому пока тяжело решать Это оптимизация джойнов это иерархические какие-то данные словари позволяют работать с иерархическими данными это специализированные словари например словари для полигонов и словари для раньше то есть например Когда у вас есть какие-то интервалы вам нужно по интервалу какие-то данные находить вот такие прям специализи в данном случае это прям идет кисть для словарей зовут Денис Спасибо за доклад на одном из слайдов была функция определения языка и те тесты которые я вижу Ну вот на вашем сайте Да они с как раз текстами функциями Ну то есть там немного этого Скажите насколько кликаус идет в эту сторону то есть вот это был какой-то пример Хорошо я так скажу для текстовых функций мы идем в эту сторону мы добавляем много различного функционала Например у нас появится инверторные индексы скоро Ну прям вот в этом месяце Я думаю у нас появляются функции для работы НЛП Вот например некоторые которые я показывал то есть мы эту сторону движемся с анализом текста будет больше всяких вещей Спасибо Да добрый день спасибо за доклад я по поводу перформанс тестов хотел спросить Может вы посоветуете бывают такие ситуации Да когда у нас нетворкинг задействован да и у нас там допустим я сейчас утрирую может быть Агент этим Сити находятся там Соединенных Штатах Да мы объект тестирования располагаем на серверах selectella до санкт-петербурге и наблюдаем деградацию перформанса и в этом случае мы не можем Ну как сказать исключить действительно то есть проблема может быть нетворкинге да Каким образом вот провести такое томарное тестирование чтобы нетворкинг это довольно сложно на самом деле тема для начала Ну конкретно вашем сценарии Я бы попробовал поближе посмотреть Можете ли вы потемнить условно говоря tcp-stake поковырять там эти вот всякие настройки по моему опыту в этих настройках бывает там X5 производительности может лежать То есть вам стоит это попробовать для начала сделать еще вопросы Ну мы как знаем пакет да он По тебе описток он ищет кратчайший путь Да и Ну вот если достаточно большой путь пакета да то есть И вдруг кратчайший канал там занят он вдруг начинает идти более длинным путём да то есть детей у него будет меньше дата интулив пакета и в этом случае Ну как сказать в любом случае будет деградация performance за счёт нетворкинга Да как этого избежать то есть э-э мы не всегда можем мерить с того же самого сервера Да чтобы это понятно Ну в принципе каких-то хороших решений тут понятное дело нет то есть пытаться как-то так всё делать чтобы данные были локализованы на одном сервере Например если у вас там речь идёт про Джона условно говоря распределённая джойн то понятное дело сделать распределённый Join В общем случае невозможно и тебе нужно как-то данное пошафтлить чтобы ты мог нормально поднять чтобы не было каких-то очень жёсткой пересылки по сети левая часть зала мидовая Здравствуйте спасибо за доклад в этом говорили Это же про нагрузочные тесты скорее Интересно что у вас сиану из вот эти все тесты запускаются на МР и на каждый камень мастер вот ну и вы показали что вас там достаточно большой такой набор то есть куча всяких параметров все они как бы параллельно сколько это занимает по времени как Ну насколько реально вот эти результаты разбирать потом честно сказать тут это все тяжелая работа понятное дело если например нужно оптимизировать какую-то конкретную подсистему какой-то конкретный алгоритм это может занимать Ну там две недели плюс месяц плюс два месяца плюс Это нормально если говорить про то сколько это времени занимает в плане вот прогона всех этих формах тестов на данный момент у нас все ну то есть весь наш тестов он пошартирован на четыре части четыре части запускаются на отдельных воркерах и в сумме вот вообще весь этот прогон занимает кажется часа четыре то есть и мы го эти тесты сейчас уже не только под x86 64 и еще и под ARM то есть подарок может даже быть там дольше например Это все тоже нужно смотреть часто бывает такая ситуация что например вы что-то вроде как ускорили да например там на одной там платформе потом смотрите там на другой почему-то появилась какая-то деградация Или например Вы ускорили в одном месте оно в другом месте как бы поехало Ну то есть тут как бы просто долго Спасибо так наверное я еще скажу что По всем вопросам По клик хаусу можно еще подходить ко мне я вот тут буду находиться вот мы с Артуром будем отвечать на всякие там по эксплуатации потом словарям по Джой нам по новым фичам всем Можно спрашивать"
}