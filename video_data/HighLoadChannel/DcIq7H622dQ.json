{
  "video_id": "DcIq7H622dQ",
  "channel": "HighLoadChannel",
  "title": "Надежные и быстрые бэкапы PostgreSQL / Даниил Захлыстов (Яндекс)",
  "views": 10159,
  "duration": 1998,
  "published": "2021-10-04T02:17:58-07:00",
  "text": "всем привет так слайда видно меня зовут данил зав и став я хочу сегодня рассказать о том как мы в команде индекс облака делаем бэкап и погреться немного более надежными и быстрыми на самом деле пытался часть того что этот доклад бюджет далеко не первый это у нас целая серия докладов которые мы докладываем про нашу утилиту для резервного копирования который называется вол'джин и поэтому в этом докладе я не буду останавливаться на каких-то базовых вещах а я буду рассказывать о сном про новые фичи поэтому те кто хочет деталях ознакомиться можете посмотреть предыдущие доклады сейчас все сделаю небольшое введение для тех кто возможно ещё не совсем в теме резервного копирования если вам нужно просто перенести данные с одного кластеру подвес на другой вы можете использовать консольную утилиту который без коробки с подвесом называется пиджи дамп она сделает логическую копию данных какие у него есть преимущество она не зависит от версии позарез вы можете перемещать данные между разными версиями без проблем вы можете брать только те данные которые вам нужны тоже большой плюс но если у вас все серьезно и вам нужно восстановление на точку во времени вам уже нужно не логическая и физическая копия и web агрессии нам повезло есть тоже функционал готовый api которое заводиться пиджи start backup что он делает он создает check point контрольную точку это нужно для того чтобы привести данные на диске в актуальное состояние также на время создания backup а мы включаем full пожрать это нам нужно для того чтобы если страница была изменена во вратах от лап сразу пошла полная версия измененной странице это такая небольшая защита от кэша файловой системы если у нас какие-то данные не актуализировали все время чекпоинта также мы записываем его сын начала быка по он нам понадобится в дальнейшем ну конечно я думаю многие из вас знают что просто вызвать петерстар бэкап и скопировать файлы недостаточно для того чтобы восстановиться . во времени нам нужна физическая копия файлов плюс посоветовать волос сегментов начиная с н начало быка по и заканчивая . и времени на которую мы хотим восстановиться и чтобы не делать все это делал руками не вызывать пиджи start backup не копировать файлы не находить вал сегменты у нас в прогрессе опять же есть хорошая консольная команда в коробке который называется пиджи баэс backup по сути она использует тот же сам пишет рбк папе и с помощью нее вы можете очень просто создать резервную копию физическую но нам конечно всегда хочется немножечко большего мы хотим сжимать наши бэкапы чтобы не занимали меньше места мы хотим параллелизма чтобы ускорить снятие и восстановление из бэкапов мы хотим и шифрование чтобы в наши бэкап и никто не заглядывал посторонние никто не мы хотим троттлинга ресурсов чтобы снять ее backup а нет ни мало слишком много процессор иных ресурсов может быть дисковых может быть сетевых ресурсов sh100 с которого мы снимаем backup также мы хотим удобный инструмент для митинга для управления пикапами например мы хотим хранить только бэкапы за последние 7 дней и хорошие новости внезапно у нас есть круто и вакансия бы каталка которая называется вал g написано на гол и она по сути большую часть всех этих вещей умеет делать по сути был такой небольшой introduction сейчас я расскажу что вообще во лжи нового 1 фича про который я хочу поговорить называется верификация конкретности истории white hat logo она называется сложены но по сути своей очень полезные простая если мы посмотрим на пример топологии кластер высокой доступности с архивом мы можем увидеть здесь то что мы в данном сценарии снимаем backup из реплик и архивируем волс мастера и нас в контексте данной фичи будет интересовать именно пункт с архивации вал поднимите пожалуйста руки кто уже пользуется во лжи возможно посыл этого доклада у вас станет больше вот кто уже пользовался вот же я думаю настраивали архив mod archive команд и по сути что делает вал g он при выполнении archive команда загружает вал сегменты в облачный архив и вас сегменты просто лежат там таким же набором файликов по сути в название каждого вас сегмента она состоит из двух частей первая первая часть содержит номер той майна а вторая часть содержит lsn для тех кто скажите кто вообще знакомы с понятием поймай на подвесе так хорошо тогда я не зря сделал следующий слайд зачем вообще нужны в прогрессе тайны предположим вот вы у вас все было хорошо вы там делали бэкапы вам внезапно понадобилось восстановиться на 2 дня назад и для того чтобы вы не перезаписывали историю после восстановления из бэкапа описали новую фазу весь есть понятие timeline of и когда вы восстановитесь bacopa у вас time in the месяц на единицу то есть на картинке у нас вот было допустим было восстановить бэкап и могло быть что угодно например свеча вера или failover и у нас начался новый timeline и соответственно в архивов сегментов у нас появились вал сегменты с тайманим 2 ну конечно вот этих двух вещей не достаточно чтобы погреться потом проиграть непрерывную историю вас сегмента в подъезд нужно еще знать какой конкретный момент произошло переключение то есть lsn приключения для этого есть специальный файлик с метаданными которые называются time on his three файл соответственно в нашем случае был записан файлик у которого timeline 2 . history можно посмотреть что в этом файлики вообще внутри содержится для этого даже в облака далеко ходить не надо можно зайти просто в папку переживал посмотреть если у нас to make the history файлики если вы уже с уже было приключение таймлайна наверняка они там есть вот и а также данном примере у нас есть h 3 history файлика давайте посмотрим что в четвертом в четвертом у нас видим три строчки до в каждой строчке у нас содержится некоторая информация а именно у нас сначала индификатор таймлайна с которого произошло переключение lsn на котором произошло переключение и комментариев произвольной форме соответственно мы видим что на этом примере у нас до 4 таймлайна есть история с тремя переключениями первое приключение было вот с первого на второй в первой строчке во второй строчке со 2 на 3 из 3 строчки 3 4 так ну и какие вообще с этим всем делом могут быть проблемы первая проблема которая часто бывают в кластерах высокой доступности если у нас какие-то появляются проблемы с тела связанностью еще на это накладывается неправильно настроен сервис координации вроде за кипера у нас может быть ситуация называется сплит brain по сути что может произойти в результате это то что у нас в облачном хранилище попадет новый time line 6 хотя у нас актуальный демоян остался 5 и несмотря на то что автоматика должна быстро погасить 2 мастер в облаке у нас останется лишь не поймали которые дальнейшем может вызвать проблемы который нам не нужно соответственно мы можем делать простую проверку на неизвестные timeline и как она будет работать мы просто просканируем все загруженные timeline и и посмотрим вот у нас допустим есть timeline с индексом меньше чем текущий пойман кластера мы его оставим текущей монтаже в принципе не вызывает никаких сомнений то что он у нас валидный а вот какой нибудь timeline у которого индификатор выше тем текущей может означать что у нас произошла кайт нештатная ситуация это что требуется участие оператора человека чтобы он посмотрел точно ли там все в порядке у нас с кластером следующая проблема которая может быть это недоступность в остальным . во времени как почему это может случиться у нас может быть утерян либо один вал сегмент либо файлик с метаданными history файл и обе этих причины могут вызывайте недоступность расстоянии . времени потому что мы не сможем проиграть последовал сегментов у нас будет дырка и как мы это можем проверить что у нас нет этой проблемы мы можем просто узнать текущий туман текущей lassen и пройти по вал сегментом назад во времени используя этой магистре файлы переключаться patarimai нам и так дойти до самого раннего bacopa если в ходе этого обхода мы не нашли никаких лишь не нашли никаких отсутствующих вал сегментов это значит то что у нас есть возможность выполнить party time recovery начиная от самого раннего bacopa и заканчивая текущем и лосином знаешь все хорошо как собственно использовать эти проверки для этого мы сделали команду новый вал джек которая называется волдыри фай она краски призвана выполнять проверки состояния архива вал в облаке для того чтобы провериться на неизвестные той мой не нужно использовать проверку который называется твои main все просто на казанской на примере видно то что мы запускаем проверку timeline у нас текущей time and просто это 4 максимально который мы нашли в этом облачном хранилище тоже 4 поэтому все хорошо статусу кей для того чтобы проверить доступность point in time recovery мы запуск которая называется интеграция тут видно как работает она сначала находит самый ранний backup который находится в тораджи и потом сканирует по цветности волос сегментов на предмет берг и видим то что на скрине тоже все хорошо она нашла 3 майна и среди них не нашла ни одной дырки то есть нас 2 3 4 timeline статус в них окей так ну и используя эти правила проверки можно начать спать немножечко спокойнее чтобы спать ещё немножечко спокойнее можно использовать следующую фичу которая называется верификация checksum страниц вообще зачем вам нужна кейс проблемы ну заправляем не далеко ходить не надо проблема это коррупции если вы из внезапно зашли и увидели у вас в воде под gresso вот какие-то такие похожие ошибки это может быть признаком того что у вас в кластере произошли коррупции данных и причин для коррупции на самом деле быть может быть множество это могут быть проблемы с дисками проблемы с ошибки в микро программах проблемы с файловой системой баги и ошибки в паз гресь и такие тоже могут быть внезапно ошибки в процессе репликации баги в со все которые вы делаете backup в общем причин просто множество и на самом деле в паслись начиная с версии 9.3 уже все обо всем позаботились там появились checksum и и в трагичных файлах в заголовке каждой странице есть специальное поле которая называется обидеть иксом и там хранится чип сумма страница с помощью которой можно убедиться что страница не была повреждена ну казалось бы все хорошо но какие с этим могут быть проблемы проблема заключается в том-то даже если в кластере у нас включены checksum и то мы можем узнать о коррупции данных только момент обращения к данным и либо если мы специально запустим проверку щека сумму по всему кластеру таким образом мы можем иметь поврежденные данные но мы можем у них не знать довольно-таки долгое время пока не попробуем к ним обратиться и может даже найти того что эти данные попадут вконец backup поэтому важно проверять checksum и при снятии bacopa собственно теперь можно это сделать и в во лжи нужно просто добавить флаг verify к команде backup уж ну либо в конфиге указать соответствующий параметр тру это позволит определить потенциально проблемный backup как можно раньше случае если при создании бэкапов во лжи заметил что в каких-то из страничный файл и cove у нас не совпали checksum и он запишет эту информацию метаданные bacopa чтобы потом мы могли этим воспользоваться ну и теперь можем спать немножечко ещё спокойнее потому что у нас есть еще и проверка чиксу вот после того как мы убедились что наши backup устали немножечко более надежными мы можем сделать их немножечко более быстрыми а именно использовав обратную распаковку дельта бэкапов вообще сначала расскажу в принципе что такое у нас во лжи дельта бэкапы мы используем называемые вас and bass дельты как они работают предположим у нас есть какой-то базовый бэкап и мы хотим сделать бэкап мы начинаем процесс быка по и идем по файлам постраничный файлом идем по первому файлу и смотрим по каждой странице lsn страницы и если у нас сын страница больше чем сэм конца прошлого bacopa это значит устраниться поменялось это что нам нужно включить ее в кольцо проходимся так во всем файликом и у нас составляется такая карта измененных страниц после этого для каждого файла по этой карте мы составляем дельта файлы который у нас и пойдут в backup без затем после того кунас есть какая-то цепочка из дельты бэкапов чтобы восстановиться из последнего быка по нам нужно совершить следующие действия сначала распаковать полный backup затем распаковать дельта бэкапы и так далее по цепочке пока мы не дойдем до последнего дельта backup а такие вот могут будут проблемы я думаю тут видно то что мы некоторые страницы перезаписываем и тем самым мы делаем лишнюю нагрузку на диск а это что делает это замедляет время восстановление из бекапа как мы можем это оптимизировать мы можем избавиться от лишних при записей мы можем сначала распаковывать последний дельта backup дальше предыдущий и так записывай страница только те которые которые у нас еще нет итак доходить до полного бака по и в конце у нас получится тоже самого стандарты backup насколько все это сделало быстрее работает ну можно посмотреть benchmark я выдержку сделал с таким небольшим графиком по оси y у нас нагрузка на диск по оси x время и слева можно видеть распаковку дельта backup а в обратную распаковку а справа стандартной распаковку да и табака по и можно весь что обратная распаковка справляется в разы быстрее как все это дело включить ну довольно таки просто нужно просто добавить флаг живет антек команде бэк-офис либо в конфиге дописать во лжи и us reversing равно true ну и тут приходит сразу же небольшой такой бонус на самом деле используя обратную распаковку страниц некоторые архивы промежуточные из промежутке умельцы могут содержать страницы могут стать полностью страниц который нам уже не нужны а это значит что мы эти архивы можем упускать их загрузку и для того чтобы включить режим нужно у волшебников печь добавить еще 1 факт skip редан and tires но чтобы эта фича работала эффективно при создании backup а нужно также использовать рейтинг composer чтобы он мог предсказывать какие страницы меняются часто и стараться и группировать в отдельные tar архивы чтобы повышать вероятность что мы при восстановлении с обратно распаковкой их пропустим так ну и как нам все это дело попробовать у себя как я уже говорил достаточно просто зайти в нашей базе торе и на гитхабе не забудь поставить звездочку и скачать последний привели потому что покажите еще релиза со всеми перечисленными фичами полного не было а вообще у нас еще есть много идей поэтому если хотите поучаствовать в разработке крутого проекта приходите к нам мы всегда будем рады новым потребителям и всегда будем рады по reviews ваши pull request и вот спасибо теперь это понимаю часть с вопросами спасибо за доклад вот несколько раз упомянули о том что мы будем спать спокойно связи с этим такой вопрос вот из слайда я понял что эта информация о том что произошло с бэкапом она в какой-то джейсон выгружается до мониторинг есть какой-то встроенный то есть метрики под груз или are my tiles или еще чего нет у нас есть во лжи метаданные bacopa которые хранятся рядом с бэкапом это просто такой же сам файлик и сверху мы ничего еще не прикручивали к нему вы можете себе прикрутить существует свою обвязку чтобы посмотреть на это в общем нужно вставить что-то придумать чтобы реально за спокойно всем спасибо вот там человек руку по нему спасибо за доклад а у меня такой вопрос по поводу можно ли например вместо того чтобы прогонять изменение самого конца эти дельты бэкапы как-то объединять до на самом деле в других богатых например в пиджи про бэкап есть специальный функционал который позволяет объединять последовать табака pv1 и на самом деле мы тоже у нас есть планах когда найдутся свободное время лев может быть найдется какой-нибудь талантливый человек который захочет это сделать мы будем рады такому парик месяца который бы позволил объединить несколько ценных дыбу капов у нас есть кстати мы участвуем google summer of code и поэтому если среди аудитории есть студенты которые планируются хорошо провести лето и получить стипендию от гугла и поучаствовать в прикольном проекте приходите к нам на google самар в код у нас есть много прикольных идей и вы можете хорошо провести лето спасибо да здравствует спасибо за так вот хотелось бы узнать о обратной бэкапы мы не получим в конечном итоге не консистентные данные когда накатим бэкап и но не учтем предыдущие изменения спасибо ну смотрите тут такая схема то что мы когда распаковываем 20 вернусь на словить назад когда мы распаковываем back to backup в обратном порядке у нас такая схема в том то что у нас последним дтп copy самая новая версия страниц и по сути версии этой же самой странице более старые они уже устаревшие нам они в принципе уже не нужны то есть пропуская загрузку мы ничего не теряем потому что у нас уже есть более на аверсе и по сути мы не пропустим любом случае никакой никаких данных там просто человек хотел что добавить в одну ну и ним дельта бэкапе хранятся изменения от полного бекапа о нет нет нет у нас есть целая цепочка и последнем этапе хранится изменят последние дельта ну мы ж не знаем после линдельта когда накатываем самый последний backup почему нет когда мы закатываем сомнений backup у нас краски с текущей схеме сам-то не backup это строну среднем вот эта дельта backup мы его знаем мы знаем всю цепочку от последнего data backup а до полного бака по мы ее знаем изначально поэтому можем пони пробежаться так все я понял пасибо большое спасибо за доклад я правильно понимаю что вот же это так называемая теплая бэкапы то есть у нас есть какой-то базу и бэкап и за счет быка погонщиков мы как бы ну делаем какой то бэкап и потом должны накатить на базовой backup эти мальчики это первый вопрос второй вопрос какие стороны поддерживают ваш волги ну допустим ну я правильно понимаю что для создания дельта backup а он должен видеть все бэкапы которые создавал то есть если у нас из 3 хранилища да куда мы выкупим на можем ли мы вот использовать его нативно спасибо да конечно так начиная с первого вопроса да совершенно верно нужно сначала накатить ну вообще для того чтобы снесли data backup а нужно иметь все бэкапы начиная с полного и вот по цепочке до этой дельты это нужно знать вот ада по сторожем получается у нас во лжи одна из кибер фич это то что у нас есть поддержка различных облаков например с 3 совместимы и же google cloud storage вот николай самохвалов давно делал прикольный доклад называется над пропастью во лжи где он рассказывал как они прикольно заводили чинили вал джигу cloud storage вот поэтому у нас это одна из киллер фичей то что мы очень хорошо качеством облака вот да спасибо и еще вопросик у вас получается бинарная бэкапы правильно то есть для того чтобы восстановить ваш backup нужен postgresql той же самой версии с которой снят и бэкапы ну для того чтобы снять наш backup вообще получать сюда нужно его у нас выставляется просто впустую директорию и потом конечно же нужен тот же такая же версия мажорная погреться которая была при создании мира и я и так слышу трансляции возможно люди не услышит так давайте пролистаю назад на 1 ладик краста кипра информацию которую мы получаем поврежденным страницам мы смотрим на поврежденные блоки вот у нас если посмотрите например нас есть в душном файлики для каждого страничного файла такой вот словарик с поврежденными блоками там показываются сам корабль blogs и просто их номера по сути используя эту информацию можно найти конкретно какие данные подвесе были повреждены вот но говорю у нас еще не к автоматике нет это скорее так просто как комета информация которая уже нужно для того чтобы в ручном режиме потому что все таки коррупции слава богу ну не так уж и ежесекундно встречающееся явление как то попытаться что-то починить вот то есть сейчас покажу вот если посмотреть здесь на ошибку как раз таки написанными валит ph блок и of relations bass и директорию ну и путь к страничного фабрику на диске вот и мы вал jit также записываем и тот же самый путь и просто говорим еще какие блоки по этому пути были повреждены нет странице считается поврежденной когда у нас у нас специальное поле в погреться встреч на файлы каждой страницы в заголовке есть специальное поле чек суммой и получается мы до проверяем тип сумму мы считаем чип сумму всей страницы ну за исключением полищука суммой чтобы как бы не было никаких проблем вот и сравниваем со значением которых не сучек сумме вот если у нас это повредилась у нас что сумма не совпадёт и мы скажем что страницы повреждена ну слушайте возможно есть но я вот сегодня рассказывала про этот других методов насколько насколько мне известно я не знаю других ментов ну получается сумма для сущее у нас будет расхождение чип суммы и и посчитаны checksum и даже если мы удалим чук сумму тоже не совпадёт естественном и если пропадают страница полностью вместе с чьих знать со значением чек суммой skip to the как вы узнаете какую аварию теряется полностью страница вопрос понятен так понятия но смотри а смотря что значит потеряется потому что достаточно сиськи это байта на диске которые мы пытаемся прочитать по адресу то есть она в целом потеряться никуда не может и мы просто нас будет ошибка чтения этой страницы сразу же моментально странично файле но даже не может просто уйти куда-то словно говоря мы всегда знаем конкретно где она должна находиться средства когда мы пробуем почитать мы просто получим то что нас не сопрет checksum а вот и все там вроде еще в заголовке есть специальные magic биты который позволяет убедить в том что страница вообще что-то мне совсем полная каша написано спасибо за доклад я правильно понимаю что вот эти вот дельты дельта wolof она дает какую-то эффективность только для will keep и где переписываются данные для data warehouse а не тот не для data warehouse а где данные только добавляются правильно да где седаны только добавляю это будет не так эффективна чем при перезаписи с доски спасибо за доклад у меня такой вопрос вы приводили график сравнения производительности можно прямой вернуться до сравнивали вы производительность вашего решения с другими конкурентными решениями ну и высадили думал сделать водопад какую-то такую секцию со сравнением но как-то решил что все растут мериться не стали сравнивать с другими вот если интересно можно как-нибудь попробовать забыть маркете пока что директ не находил бенчмарков таких сравнительных это просто надо тестировать и сравнивать до вас timeline вашего решения есть было бы круто увидеть timeline конкурентов сравни с вашим да было бы круто мы тоже думали спасибо еще вопросы спасибо за доклад доклад подскажи а при потом при таком подходе если необходимость делать периодически полный бэкап и да как правило мы сделаем полный бэкап и через семь лет то есть у нас чтобы эта цепочка не раздавалось до больших размеров мы делаем каждому полный backup каждые семь лет я дополню свой вопрос про производительность я здесь если вы делаете бэкапы каждые семь лет то вот здесь это подозреваю время восстановления за какой-то не очень большой период если у вас вот скажем 6 половиной лет сколько времени будет восстанавливаться mockup из такой цепочки нет ну смотрите у нас как правило дкб как делать ежедневно то есть нас максимум будет вот там недели разницы то есть таких длинных цепочек 6 половиной лет правильно ну вы сказали что полный backup нужно делать 1 7 лет бетонным я снимаюсь вопрос спасибо отличная практика раз земля делать бэкапы вообще не нужны 1 7 лет существенно это так это интересно здравствуйте и спасибо за доклад интересно узнать стала как вы получили это число именно 7 дельты то с чем связано да просто чтобы раз в неделю у нас был полный backup окей пасибо я думаю все данил спасибо за доклад вам спасибо за вопросы"
}