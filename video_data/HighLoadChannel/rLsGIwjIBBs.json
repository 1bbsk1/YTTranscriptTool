{
  "video_id": "rLsGIwjIBBs",
  "channel": "HighLoadChannel",
  "title": "Распознавание речи для субтитров в VK Видео / Виталий Шутов (ВКонтакте)",
  "views": 992,
  "duration": 2535,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "так Всем привет Меня зовут Виталий Шутов И сегодня я вам расскажу как мы делали распознавание речи для субтитров в видео текущий момент я занимаю должность руководителя разработки речевых технологий Ну и начнем же без задержек сразу о чем мы не будем говорить то есть мы не будем греть никаких готовых фреймворках библиотеках как можно построить какие-то sr-модели или с RP плайны мы не будем говорить о том какие есть дата сеты для того чтобы это все можно было обучать fantunity улучшать тестировать и так далее и также мы не будем говорить как такие модели едут в рот об этом завтра на этом же месте расскажет Филипп маликовский как-то всю машину о чем будет сегодня мы затаскивали в рот Так о чем же мы поговорим Какие вообще бывают подходы к построению SR Pay плайна И что он из себя представляет поэтапно С какими проблемами сталкиваются обычно разработчики при выборе там тех или иных топологий тех или иных подходов Как можно по оптимизировать качество скорость в каких местах покрутить какую ручку Ну и Разумеется А что выбрали по итогу мы начнем наверное обычно с постановки задачи Что такое СССР обычно tsr модель требует одного свойства очень простого на вход у нас есть некая Ауди дорожка А на выход Мы хотим получить текстовый расшифровку там запятыми с точками с этим всем всем Вот например как выступление Саши на весеннем хелоде и внизу у нас Рендеры на автосап то о чем он говорит Вот мы хотим добиться такого же эффекта а начнем про акустические признаки конкретно про волну то есть мы работаем со звуком нам приходит такой сигнал например 16 килогерц то есть одной секунде 16 тысяч отчетов смотря на эту картинку мы как люди можем в принципе понять то что нам ничего не понятно то есть никаких выводов общество делать не можем и даже Казалось бы такое относительно простой задачу Как разделить речь чего не речевой сигнал даже по этой картинке мы не можем сделать То есть можно сделать какие-то обманчивые предположения например о том то что вот у нас в начале амплитуда низкая Ну раз на низкая значит там чувак ничего не говорит на самом деле это не так то есть вас просто мог приложение автогей не сработать но там всё ещё есть речевой сигнал было послушайте всё будет О'кей то есть такое представление во временной области очень не компактная и сложная для анализа решение простое Давайте перейдем в частотную тут у нас уже зависимость чистоты от времени и уже намного проще какие-то выводы то есть тут мы уже можем очень просто разделять такие задачи Как отличить неречевой сигнал от речевого мы видим то что у нас На некоторых участках нашей спектрограммы есть области более ярко красные есть более тусклые и в принципе мы можем сделать некое предположение о том то что люди говорят не во всем частотном диапазоне А вот именно в конкретные его полосе такое предположение в принципе верное то есть в результате эволюция у нас речевой аппарат внутри них они подруга подстроились и в принципе слышим люди примерно как и говорим в районе 3 килогерц шире на самом деле Но примерно три килогерца плюс минус пару и вот это пишет нам почти всю речевую область это такая самая простая распространенная модификация любой спектрограммы это MFC мелкие пострадальный коэффициенты название сложно идея простая раз у нас область низких частот более нам интересно давайте мы просто сделаем так что там будет значение больше банально цифры будут выше чем в области высоких частот достигается это такое несложная матишей которая называется сверка с треугольными фильтрами они позволяют нам на область низких частот выделить более высокие значения А на область высоких частот более низкие то есть Таким образом мы уже сделали неплохой признак с которым нам удобно работать Так что же за srpline вот на вход у нас есть какая-то волна мы из нее извлекаем какой-то акустический признак в нашем случае будем греть про msc-шку потом подается оттуда сейчас в магический 2 блока а МЛМ и мы уже получаем на выходе текст поговорим про первый блок про этот ам начнем издалека Какие вообще бывают акустические модели в принципе любым или можно так хорошо поделить на какой-то старой на статистике это всякие там GM методы линейные модели и модные Молодежный нейростевые потом мы вернемся короче к этому будет такой форсада Зачем вообще в этих моделях знать конкретно отжимаем расшифровывается хамела скрытый Марковские модели что это из себя представляет жмем от алгоритм кластеризации когда мы хотим на какой-то набор точек обучить сколько-то голос стоит и вот эти голосаиды будут отражать какие-то там полезные фонетические признаки Например можно найти группу голосойд который отвечает за фонем а или с помощью этих голосов можно спокойно решать такие задачи Как отделить голос одного спикера от другого Мы даже можем сделать моно канале разделение с миксованной дорожки на каждый канал там будет отдельный человек отделять мужчину от женщин и в принципе любую задачу которая нам приснится потому что факту мы просто более мощный признак А поскольку мы решаем СССР У нас есть такое свойство в принципе очевидное то что между признаками есть какая-то временная зависимость То есть если я говорил России Скорее всего я скажу Потом я Россия и Вот именно вот эти зависимости временные позволяет нам моделировать hmm то есть Какова вероятность перейти с одного состояния к нам в другое обучается все это алгоритм со сложными названиями какой-то алгоритм Баума велша ем лайк подобного алгоритмы и так далее Но идея на они работают в принципе одинаково даже разберем по шагам вот нас есть какое-то некий набор точек на слайде каждая точка тут будет представлять наш акустический Вектор то есть 20 миллисекунд и фичи в которые уже компактно жата какая-то инфа которая скорее всего говорит нам о каких-то фонемах которые юзера произносил и есть Мы хотим их защитить Что происходит на первом этапе мы каждую точку оцениваем вероятность принадлежности к голосуйде и соответственно мы их так кластерилизовали ход Прошёл первый этап Потом мы все эти голосоеды подвинули чтобы средний дисперсия совпадали с множеством защищенных точек И так мы делаем много-много раз показ наш не сошел и вот он сходится и как итог каждого стоит записан какое-то множество точек то есть как я и говорил голосоеды отвечает за какие-то признаки То есть их можно уметь выделять можно уметь их брать но не всеми линейными стат моделями жить есть нейросетки и прежде чем говорить каких-то современных модных очень хочется упомянуть о более таких старых топологиях это конкретно топология основаны на лстм слоях такие как спич второй конкретно расшифровывается это как там делал Нетворк название сложное очень непонятное многим людям которые не из области спича но в принципе тдн слой это та же 1Д свертка то есть отличник никаких просто такое название придумали в чем идея заключались такие топологии это в том что нас есть некий беленький квадратики это вот наш фик который мы подаем мы прогоняем их через точных слоев пока нам не надоест вот на какой-то момент мы решаем то что все хватит признак уже у нас очень мощный и потом мы настаиваем сверху лстм и радуемся жизни то есть слои сверки из лихийно мощный признак А между ними временную зависимость нам еще помогла ловить лстенко и мы можем делать предсказание на какой-то таким нам интересный все работало замечательно с одним Но это работало довольно-таки медленно То есть это обучалось не совсем быстро там были всякие начала градиенты придуманные прочее прочее и в принципе понятно что жить так нельзя было вечно Ну и пришли современные свёрточные модели то есть и посмотрели поняли что зачем нам эти лстемы посмотрели на соседние области это НЛП это CV взяли оттуда всё современное модное что есть выкинем батч норм поменяем нормы добавим везде селфишный и современные способы обучения там косинусные дуллеры всё всё вот прям собрались миру по нитке и в принципе стали крафтить разные технологии плюс-минус они все имеют какую-то схожие идею у нас будет какая-то 1Д сверка потом какой-то батч норм плеер норм активация и так много-много раз подряд и потом мы получаем какое-то предсказание какого-то нашего токена из таких топологии то есть интересных модных которых можно поговорить Это кварц-нет и конформлеры как контекстнеты и как в отдельную Касту можно отнести в Автовек и во флэм потому что как раз вот эти модели они работают обычно это все обстоятельства называется работа необычно чистым сигнале если построить некий такой график качества конкретного тут libridge тестовая часть чистая можно видеть что идут годы и качество растет но в последнее время что-то перестало расти И несмотря опять же график то есть вот у вас какая-то идея в голове Я хочу скрафтить свое сердце модели хочу выбрать сетку Ну типа очевидно красную наш лучше всего работает но если мы посмотрим такое так называемый импровизационный график 200 это просто зависимость от числа параметров то видно что эти красненькие кружочки находятся намного ниже то есть они такие модели работают сильно-сильно медленнее чем более назовем так простые модификации в виде кварцнета в комформеров и так далее и может дать такую рекомендацию некую Если у вас есть какое-то вот Infinite железо вы вам очень-очень важно добивать проценты доли качества то наверное вам корректно идти Вот именно в эти в авто веке во флэм То есть вы готовы много проинвестировать в обучении этих моделей потому что код очень сложный кода нужно много написать какого-то нормально готова реализации Вы скорее всего не сможете найти А если вы люди попроще скажем так например как мы то можно пойти в всякий комфортеры то есть на складе любом случае указана модификация которая самая большая число параметров можно порезать и в принципе очень хорошо корректно сваренной конформеров не особо уступая этим в качестве плюс есть формеры трансформер вот это все модификации модификации над ними чтобы это либо качество нас получить получишь либо он нам добавилось какое-то свойство модели интересно но об этом чуть дальше как такие модели учатся тут никаких секретов Нет все как обычно все учат обычно на ctc позволяет нам обучать сетку без точной разметки иметь текст все записи то есть что это значит вот например Мы хотим обучить и у нас одна секунда аудиохи мы из нее извлекаем фичи по 20 миллисекунд получаем 800 темпов на одну секунду и нам вот нужно чтобы наши разметки каждому соответствовала какой-то лейбл обучать моделька СССР и нужен там на 5 тысяч 10-20 тысяч часов аудио то есть такую разметку получить вообще нереально поэтому все уличности отлично работает уже очень много кто объяснял что такое ctc и в принципе есть короче замечательный сайт Можете посмотреть там можно визуально попробовать использовать но как такая Ремарка работает Это довольно таки просто нам сеткой выдает некую последовательность для каждого таймс темпа А чтобы посчитать лосс мы просто возьмем все буквы которые одинаковые и свернем их в одну То есть если сетка нам зациклила ррр свернем в одну букву Р и уже будем считать лосс Именно по этому одному такену и тоже опять же интересная Ремарка и от начали говорил что задача решается в двух вариантах это стриминговая распознавание и оффлайн распознавание а решаются они очень по-разному и можно тоже так привести параллель вот мы ушли от лстема мы пришли чисто к свёрточным топологиям на теннишных все дела модельки перестали улавливать зависимость между различными темпами у нас ничего не работает если раньше мы могли наши спокойно переводить на любой сценарий продуктовый то сейчас это уже делать нельзя просто так Разумеется выход есть это модели позволяет нам наши сверточные топологии обычные превращать стриминговые и плюс еще качество добивают лучше чем ctc и тоже один супер важный Профит который мы получаем это что у нас нашей закрываем моделька lmc прям уже вшита сюда была как бы чуть позже но этот момент очень важно запомнить Ethernet какие у нас есть проблемы эта штука очень сложно обучать очень сложный год писать сейчас если поищите в интернете найдете там 5-6 различных реализаций реализации на Куди все имеют какие-то свои профиты где-то очень страшная сложная математика и Это сложный код для инференции нужно писать особенно в стриме И это не совсем тривиальная задача как вообще работает РНТ и довольно таки простая У нас есть некая сетка например там комформер и он нам генерит какие-то входные фичи вот это хочу назовем там X от аудиокодер это просто некий набор там слоев лстенных чтобы могли захватить норм информацию между различными темпами и мы получаем некую фичу ft которая же находится в пространстве нашего rnt потом у нас есть некий текст предиктор это вот есть наши капсуляция языковой модельки текст предиктор тоже обычно состоит это какие-то стакан лстм слои Ничего особенного на вход он принимает себя предыдущие предсказания модели соответственно когда мы начинаем предсказывать мы инициализируемся с бланка с пустого символа и начал Стрим плодят нам некие выходы GQ потом Просто берем соответственно выходцы один кодеров текст предиктора конкатенируем и подаем в сетку вот этот процесс очень вычислительно сложный там образуются большие тензора и вот именно это то из-за чего они любят процесс сложный это объединение и соответственно дальнейшей прогон через матричные умножения нет ничего сложного с точки зрения объяснения но опять же повторюсь очень сложно реализовать все корректно а вот такой был экскурс нашей эмки То есть если подытожить есть некие старые модели gmm Хмм которые имеют очень узкую применимость наше время если вы хотите делать какие-то свои модели смотрите на современность свёрточные топологии Если вы хотите добиться стримингового сценария то Вам нужно будет накручивать обязательно РНТ Но если Вы только начинаете разрабатывать какую-то такую свою систему то лучше сильно не запариваться лучше начать сети отводить обучение на сети и только потом переходить к таким же сложным трюкам модификациям потому что очень сильно любит расходиться что немаловажно языковая модель что тут поскольку говорим мы не так как пишем например Все мы говорим Россия через букву а описать правильно нужно через букву о и когда мы отрендерим юзер в России через а он будет очень недоволен языковая моделька позволяет нам такие косяки исправлять Я уже много говорил то что наша Эмка предсказывает некие такены такие метакены А что вообще бывают такие на которые можно предсказывать это соответственно Word Base подход когда мы все наши слова в словаре помещаем какое-то уникальное чиселкой И вот я будем предсказывать с точки зрения эмок и так далее это общение особо-то приветствуется скажем так как минимум таких работ найти сложно это что-то очень эзотерическое подход на Чарах То есть просто каждая буква нашего Фит это отдельно таким который мы предсказываем замечательный подход он очень просто работает и он работает очень качественно Несмотря на все его наивность но Разумеется можно и лучше это бpring то есть мы уже обучаемся не на полных словах А конкретно на особо вардах то есть мы берем наш словарь обучаем некий бпин кодер который играет все эти слова находят там суффиксы префиксы общие части и позволяет нам переводить ВТБ и пространство и обратно из него соответственно получать обычный человек читаемый текст вот Эмка выдает нам вероятности То есть это какой-то таким от нашего темпа 20 миллисекундного типа текста нет мы хотим текст рендерить какие у нас есть варианты чем можно самое простое что в принципе приходит в голову это гриль то есть от каждого темпа мы будем просто брать максимально отклик нашей сетки Ну и так получим нужный текст который уже можно трендерить юзеру и там посчитать качество и радоваться это работает очень быстро Как ни странно это работает очень просто но не так хорошо как хотелось бы то есть мы хотим более высокого качества может работать в ряде случаев Плохо что это Beam Search bin Search работает хорошо любим Search работает медленно соответственно в чем идеям searcher если при гризе Мы берем только одну максимальную гипотезу соответственно максимальное предсказание всегда то при бенсердж Мы берем каких-то N максимально вероятных гипотез то есть на каждом этапе от одного стенда к другому мы считаем общий совместную вероятность и просто пути которые менее вероятны мы отсекаем соответственно под конец мы получаем например 100 возможных путей дикотинга и чтобы нажмем нормально использовалась нам нужно что-то что эти гипотеза позволит нам поспорить это в принципе делает наша млмк Что из себя представляет лэмка То есть это термин не который каким-то АСР проблемам или вообще с плечом Это все из НЛП по факту может нам имея некий контекст слов сказать какое будет слово дальше как на примере то есть Москва это столица скорее всего дальше будет Россия бэнка позволяет нам сказать Типа насколько это вообще предложение адекватно насколько оно Похоже на то на чем обучалась на корпусе вашего языкового текста Какие лмки бывают есть два тоже такие основных подхода Первое это грамм не модели они просто работают они очень легко обучаются и вот хоть начале сказал то что не будет нас не про любые не про феймворки ничего в паре мест будет Вот одно из них само писать реализацию огромной модели прям очень корректную там с суффиксными деревьями с этим всем это очень сложная задача но есть замечательная библиотеки хочется упомянуть конкретно Кен ЛМ отлично решает эту проблему запускаете нрав текст и получаете ваше дерево поиска есть пара но первое но это число грамм нам нужно выбирать второе такая модель занимает очень много места на диске то есть не удивляйтесь Если ваши Ланка будет весить 10-20 гигов и так далее Это норма энграмма это способ как мы для нашего построения по словарю будем кодировать конкретный текст unigram модель То есть это 1 грамм каждое слово это отдельная таким Big Gram то есть 2 грамма это по два слова и с таким плавающим окном 3 грамм по 3 соответственно 4 и так далее То есть мы строим такие N грамм такенность нашего исходного текста и потом на них обучаем киноленную модельку например но опять же как и смками не одни местами методами Мы едины есть Трансформеры есть модные сетки они работают чуть лучше прям чуть То есть если с точки зрения ам переход от GM модели К какому это прям был жесткий прорыв качество дикой бустанулось то тут это не так это обычно если вас правильно хорошее попадание в домен прям совсем чуть-чуть доли процентов Ну может там 5-7 процентов относительного качества вы это жмете а это будет весело на диске Но это будет считаться чудо вечно долго То есть вам если Кен лэм у нас спокойно считалось на CPU то есть нам не нужно было там память видяхи забивать ее флопсы свободно и так далее то тут это все надо это намного дороже то есть если сделать такой небольшой итог то если вы не гонитесь за какой-то доли качества вот этой призрачной Вы готовы проинвестировать много времени сил для того чтобы выбрать нужную там сетку для нашей элмки обучить её все дела тогда вот пожалуйста Если вы опять же как мы попроще То идите в энграмные модели они работают замечательно они очень просто обучаются а вот так значит и мы дошли очень быстренько уже до форреста лаймонта В чем это в чем еще заключается проблема что это значит еще будет такой сложный слайд для понимания все попытаемся объяснить конкретно мы то есть возможность Различные подходы к решению сдачи но мы текст после лмки рассматривали вообще вне какого-либо вероятностного контекста у нас был текст после ln у которого потерялись темпы потому что лэмка добавила какое-то слово еще что-то произошло мы рендерим автосап а видос долгий 2 часа то есть Нам нужно понимать когда юзер видео какое-то действие произошло у нас нет как это можно сделать мы пошли таким классическим даже дедовским подходом этот что нельзя представляют То есть как я уже упоминал Джеймс моделирует некое акустическое пространство а хммка говорит нам вероятности переходов из одного состояния фонемного в другое имея некий лексикон обучающий выборку Мы наш мелкую можем расширить то есть этот Граф который нам строился только по фонам мы уже можем расширить до слов То есть на этом частоту произнесения слова в нашем словаре и так далее мы можем построить такой граф который работает по словам естественно получаем такой композитную хммку Соответственно что происходит у нас есть текст У нас есть аудиаха мы посчитали по ней все фичи gmm-ки и потом пошли делать дикодинг соответственно получаем такой Граф и по нему просто ищем самый-самый вероятный путь дикотик по такому графу дело на самом деле не совсем простое то есть понятно что это можно очень просто объяснить он там типа Граф стрелочки все дела но опять же в реализации самому без это вообще стучат это прям нереально сложная Инженерная работа мы это делали конкретно через калди через их фастор-декодер То есть он под капотом реализуется алгоритм deaterb если я не ошибаюсь и там работает все довольно таки просто хорошо Вот соответственно то как работает наш sr5 То есть у нас есть некая волна мы с нее считаем MFC потом засовываем это сверточную модель на ctc и делаем реформинг обычный эмгранный лмкой поскольку у нас уже был опыт интеграция сэра в наш сервисы Если конкретно это мессенджер расшифровка коротких сообщений то с видосами подходить Мы уже имели какую-то набитую руку но проблемы все равно были у нас были плохие слова расшифровки То есть лмка она моделирует некий словарь на котором она обучается а в аудиосообщение любят маты говорить шутки шутить И вообще всякие неформальные словечки и для видео нам это вообще не подходит Я как раз таки мы смогли вообще это очень просто победить мы просто взяли нашу лэмку из со стены переобучили на comman Travel и типа обрадовались А если у нас например были какие-то сложные Трансформеры этот переезд был бы очень больно потому что просто так все обучающий выборку обычно поменять не получается расшифровки были некачественные то есть вот как расчётноскренне видно как только запустили там был промо-ролик Red Dead Redemption и в начале была тишина такое играет и сэр расшифровывает Стас мы такие покекали ну надо фиксить в чем проблема СССР не уверен в расшифровке то есть серная моделька обучается на каком-то тексте и она не привыкла что ей дадут там 8 секунд тишины и потом какой-то кусочек речевой не она привыкла что всегда будет речь соответственно всегда старается вероятностями что-то до вытаскивать нам нужно это фиксить довольно таки тоже прозаичен У нас в аэмке была матричка Темп на вероятность токена мы просто смотрим если все таки плюс-минус имеют одинаковое распределение вероятностей это расшифровка некачественная СССР моделька не может дать каких-то минимальных гарантий то что все будет норм лайнер У нас не было вообще в мессенджере он появился только для видео и с ним была проблем больше всего лайнер работал очень медленно поскольку вот эти различные лаймонты могут себя представлять сложности такого рода как ассрная моделька может слово пропустить наши конкретно работает не мультиязычно это только русский язык и можно видео услышать какую-нибудь фразу два слова русских одно английское два русских соответственно английское слово расшифровано не будет а лайнер как бы у него есть текст и он знает то что сначала ABC видит английском как бы там какие-то вероятности нашел и спотыкается конник не может успешно завершиться Всё у нас падает а также иногда юзер может говорить очень тихо там какое-то быть шепот шумы на фоне и так далее и соответственно гипотезу корректную на поиск нам нужно искать намного шире этот Граф который у нас был если лайман простой то можем пройтись там чуть ли не по Арк Максу А если сложно нам нужно много-много-много по нему делать проходов в поиске наиболее вероятной гипотезы что мы сделали первое поскольку это была все реализовано калди к аудио очень хорошо дружит это такой бэкент для линала просы у нас Intel Ну и типа про сингл есть лучше чем глаз как минимум было наших бенчмарках и мы смогли выжить историю алтаймов на одном ведре с нашего лайнера То есть за 1 секунду реального времени мы можем залаим 100 секунд и также поскольку пространство поиска нужно увеличивать я уже говорил если лайман простой мы можем чуть ли пройтись не арт-максом то есть брать максимальную гипотезу она успешно задекодеться а мы таки сделали то есть мы теперь экспоненциально с ретраями увеличиваем наш Бим чтобы это было сказать более оптимальное с точки зрения ресурсов вычислительных лайнер работал не точно То есть он у нас косячил он первое слово стоять неправильности Вот именно на первое и еще как я уже говорил Нужно выкидывать фраза которая с сыром были не распознаны решение прозаичное Граф поиска есть вероятности сэмки У нас есть Давайте пути кодинга который имеет низкие вероятности мы будем очень жесткость Да это у нас Ну что поделать качество важнее потому что когда опять же пример со Стасом у нас рендерится в неправильном куске это вообще не Рабочая тема в принципе основные шишки которые Мы собирали с лайнером с нашим асером обновленным и что по метрикам Мы считали веер в принципе как и все соответственно сумма встава к удалению замен в словах на общее число слов не сложно догадаться то что эта ошибка вылетает за сто процентов без проблем потому что у нас количество вставок может быть очень высокая и вот недавно я померил специально на comman Voice надев части нашу эмку и Эмка выдала нам 8 процентов Вера что в принципе Норм а лайнер тоже по статье 98 процентов всех слов Алания с погрешностью менее 100 миллисекунд что в принципе нас так нормально устроило Это вся Машина будет доступна через API То есть можно зайти получить таким и потрогать руками Все доступно Если не ошибаюсь моделька как нейтральная так и для жаргонов и сленгов а и под завершение Подводя итоги у нас фильтр банки если что Ремарка фильтр банки мы все это одно и то же в принципе концептуально у нас сверточная ctc модель у нас Кен ЛМ моделька энграммная мы используем старые gmm-ки для лаймонто и везде мы вынесли все в куче ручек порогов чтобы это все нормально крутилась и работало Не забудьте оценить по Киану выше доклад и какие-то вопросы можете задавать сейчас или потом Найти меня здесь или уже в личке вот внизу QR на телегу вот в принципе и все коллеги прежде чем мы перейдем к вопросам 20 секунд потрачу вашего времени и напомню что завтра в этом же зале в это же время в 11:10 будет доклад Филиппа мальковского который посвящен той же самой теме но не с алгоритмической а с инфраструктурной стороны То есть если вам интересно не просто Как это сделано Как это сделано с точки зрения инфраструктуры то Приходите или если у вас есть друзья дата инженеры которым был не интересен то Вот можете передать им хорошо Теперь давайте задавать вопросы так я свой микрофон тоже еще отдам для оптимизации Доброе утро Спасибо за доклад очень интересно хотелось бы спросить примерно какое время заняло разработка первичных моделей и выработка алгоритмики для того чтобы достигнуть нужный результат помимо Стаса Это первый вопрос и второй вопрос в целом как долго вы шли к результату который сейчас получили спасибо за вопросы по поводу того как мы долго разрабатывали конкретно у нас прямо внутри там разными людьми это все начиналось несколько лет назад в 2020 году на первый раз поехали в трос какими-то моделями и вот с тех пор какие-то радостные происходили по улучшению конкретно когда мы ехали к видео лайнера Он точно занял но в принципе довольно-таки быстро мы справились заняло у нас Может быть там несколько недель сделать лайнер Ну вот именно алгоритмические модели какой-то c++ напе Но вот сколько ты заняла прям полностью Чтобы в прот там пресс-релиз Я уже не помню давно не было дело вот Надеюсь полностью ответил Доброе утро Спасибо большое за доклад очень понравилось не могу проголосовать меня что-то не включили в список людей кто может голосовать Вот скажи пожалуйста а вот двухчасовое видео сколько уйдет времени на то чтобы нормально а если я не ошибаюсь то сетка Эмка на гпушке на какой-нибудь Т4 отрабатывает где-то 63 алтаймов и в принципе такое самое тяжелое процесс Ну короче примерно вся система Я думаю работает раз 50 быстрее чем реальное время Ну и там можно посчитать плюс видос двухчасовой он на самом деле это скажем так маловероятно имеет непрерывную речь А у нас есть для этого нарезка то есть мы не расшифровываем все подряд мы Режем на сегментики для Вада потом группируем по размеру чтобы это уже всё оптимально она видяшки посчиталась Ну в последнее время точно нет тот момент то что у нас есть некий домен определенный это конкретно вот эти сленге жаргоны и так далее и обычно какие-то готовые вендоры не особо вообще хорошо с этим работают от слова вообще не работает то есть пойти в какой-то там публичное надеяться что эти всякие шутки могут Все будет расшифровываться Это скорее всего нет вот с Яндексом последнее время точно не сравнивались но нужно опять смотреть на данные на чём модели обучались Потому что так коробочные решения сравнивать тоже не совсем простая задача чтобы корректно себя обеспечить эксперименты Спасибо Здравствуйте спасибо за доклад А подскажите пожалуйста как ваша модель работает когда несколько спикеров сразу одновременно говорят плохо плохо Какие вы новости хотите добавить в будущем конкретно это очень сильно паримся над тем чтобы это все у нас хорошо завелось более современными топологиями то есть конкретно мы так очень сильно пинаем заставляем хорошо работать нашего такой кастомную немного подпиленную модификацию из формера это больно но это даст профиты в будущем то есть моделька будет работать намного качественней намного быстрее и плюс мы опять же сейчас переделываем STC на rnt это то что определенный ряд более несет Ну короче так из подробностей считать Если у вас есть ампер на fp32 вообще дело неблагодарное Он видит процессоров Давайте использовать и вот на ФП 16 это все вообще дико больно то есть модели постоянно расходятся вот интерспич сейчас прошел и там есть очень интересная прикольная статья я не помню от кого конкретно они короче показывали как они учат свой комфортер и у них там вообще восемь этапов разных То есть как Learning Great где поправить где-то поставить 0002 личный там константу главное чтобы это всё обучилось и не разошлось короче очень тяжело стать эксперименты именно вы еще говорили про оффлайн модели они смартфоны или про оффлайн модели та которая требуется полная запись для расшифровки соответственно то есть мы не можем не кидать по кусочку там 100 миллисекунд 200 и ждать ответа по буковке Нет мы можем получить только сразу весь ответ она все равно считается на ваших машинах клиентских моделей у нас никаких нет насколько я знаю А можно ли Как вы считаете это можно Google Pixel у них модель на клиенте все отлично работает у них тоже мощность процессоров стоит в айфонах и у них тоже серия какие-то модели Айфонов имеют оффлайне отвечать тоже распознавать Но тот момент такой про качество то есть сделать на девайсе с большим словарем это Нереальная история Мне кажется в текущих алгоритмических реалиях а небольшие команды как помощники это вообще Изи и последний вопрос Как только мне надо слово тримик я не очень понял о чем его имею ввиду что значит слайд какой-то надо Нет вот просто сказали что там три нити или А да а вот 3 м То есть каждый сегмент для расшифровки Мы просто прогоняем его дом Вот это такая штука которая выдаёт на 20 МС в сегментик Ну или линеечку если речь но лезть не речь и соответственно мы удаляем из сегмента для онлайн вот эти первые последовательность нулей и в конце тоже нули естественно в начале в конце уходит тишина и вот это первая проблема у нас ушла с таким костылем а вы расшифровываете фоновые звуки допустим Аплодисменты что-то еще если Аплодисменты Нет это делается обычно отдельным алгосом который детектирует акустические события то есть сссрная моделька поверх неё еще работает акустические детектор акустических событий как например Это можно посмотреть у Ютуба у YouTube иногда он может написать вам музыка или там прям в скобочках таких квадратных у нас пока этого нет хорошо спасибо так Спасибо за доклад подскажите пожалуйста у вас есть API и Планируется ли добавить какой-нибудь флажок фичу чтобы конвертировать эмоции в Emoji То есть ты что-то говоришь соответственно зависимости от тона у тебя в конце вставляется нужный эмоджи Ну сейчас нет вот интересно Планируется ли Ну потом когда-нибудь это будет конкретно сказать нельзя Но когда-то я думаю точно будет идея потому что прикольно да вставлять короче эти юникодовские всякие эмоджики это прикольно да но пока это сделано это на самом деле еще можно сделать не только на звуковой фиче но можно сделать в принципе на тексте то есть текст есть какая-то эмоциональная окраска и скорее всего там какой-то НЛП Адепт сможет извлечь нужную фичу и сделать классификатор Ну да вот интересно сравнить результаты точности этих двух подходов Пока нет пока не делали Здравствуйте спасибо за доклад Вопрос такой вот если мы сейчас ваш доклад попробуем прогнать через вашу модельку Мне кажется примерно половина ваших вот этих терминов типа РН оно не распознает Как какой-то слово термин она пытается распадать какой-то русское слово потому что очень часто сталкиваюсь с таким субтитры включить вот можно ли это как-то пофиксить не знаю краску какую-то передать научную Да короче ну типа у меня речь на очень домен на специфично это все термин это идти это все сложно делать эмкам но вообще у нас был короче на ВК все это зимой Похоже на это что-то выступление и мы прогоняли в конечном автосабом И даже это было адекватно в какой-то мере расшифровывалась разумеется если он прям хотим чтобы моделька как это умеет Google делать например два русских слова одно английское дальше русский и чтобы это английское было прям английскими буквами это уже мультилендж подход это прям намного сложнее больнее А если хочется расшифровывать такие очень узкие доменные области например как найти конференции там лекции по матанализу А это пока никто не умеет хорошо делать понял спасибо доклад мне продолжение предыдущего вопроса Возможно ли как-то уточнить вот расшифровку речи может быть на этапе там акустике на этапе именно по тематике это делает лмк моделирует нам языковой контекст соответственно чем то он будет пытаться вытягивать исправлять текст"
}