{
  "video_id": "k64dTGJtFBE",
  "channel": "HighLoadChannel",
  "title": "Поиск наоборот: материализуем результаты поиска / Николай Сивко (okmeter.io)",
  "views": 313,
  "duration": 1982,
  "published": "2018-01-16T13:12:31-08:00",
  "text": "я работаю ваку метр это сервис мониторинга я расскажу изначально в тезисах называлась поиск наоборот у меня коллеги сказали что поиск наоборот и такой отчет прячешь поэтому поиск наизнанку переименовался соответственно расскажу сначала про задачу которую мы решаем вообще делаем сервис мониторинга мы собираем очень большую кучу метрик серверов клиентов там стоит наш агент и он посылает нам метрики в наше облако и метрик достаточно много так как мы решаем задачу давать ответы на вопрос что происходит они просто показывать какие-то там потребление ресурсов метрика очень много соответственно при в интерфейсе когда клиент работают с метриками на график для того чтобы рисовать допустим топ-5 каких-нибудь запросов может real-time подниматься 1000 метров и так же у нас есть большое количество преданно встроенных триггеров когда клиент ничего не настраивают а мы знаем что если вот эта штука произойдет то это плохо и клиент над сообщить эти преднастроенные триггеры их реально много и они постоянно работают для всех всех клиентов даже если ничего не настраивали и соответственно отсюда растет наша задача которые хотел поговорить но прежде мне нужно рассказать вам немножко какими термином оперируем во первых такой метрика метрика это некая ну так скажем time series это значение каких-то замеров соответственно метрику мы идентифицируем словарем ключ-значение называемого лейбл set но конечно это не сет это словарь но вот у нас так называется решил чтобы самому не путаться оставлю как есть ну вот на данном примере мы показываем количество запросов которые мы на porsche или из блога thomaxs слог на машине фронт 3 со статусом 403 и вот значение в каждый момент времени этой штуки мы называем метрикой то есть там в 1200 на нём была там 13 значение через минуту там другое и так далее естественно эта метрика визуализируются линии на графике для того чтобы понимать опять же про этот самый поиск наоборот расскажу вообще какую как вы это храним и соответственно потому что мы хранилища на сам описаны мы не используем особо каких-то распространенных time series баз данных мы берем во первых все этот лейбл сет и делаем из него ключ это обычная там строка максимально короткое но в то же время чтобы исключить коллизии мы там достаточное количество всего соответственно на вход некое хэш-функции подается весь этот лейбл сет и возвращаются с ринга с так называемым ключевым метрики и соответственно хранения метрики все разделяется у нас на две части и то метр информации о метриках и соответственно сам само хранилище хранилище у нас лежат ключ-значение соответственно по ключу метрики мы имеем возможность получить временной ряд таймс темп значение там значение а мета информация состоит из двух частей первая мы по ключу храним исходный лейбл set мы храним время когда метрика создана когда оно обновлялось а ещё у нас есть поисковый индекс соответственно основное хранилище кассандра поисковый индекс мы используем ластик ластик решает задачу по запросу пользователя показать список от этих самых ключей метрик для того чтобы потом их подняли из кассандры а потом еще из по метрик ключу но по ключу метрики пошли в наше основное хранилище и достали оттуда даны запись метрик происходит следующим образом мы нам прилетает метрика она пролетает виде лейбл settings нам значение мы делаем из нее хэш соответственно ключ идем смотрим есть ли такая метрика у нас знаем и или оно новое только что создано если он только что создано нужно ее зарегистрировать кассандре проиндексировать в ластик и соответственно у нее начинает мы записываем creation times и апдейт мы станем текущем числом соответственно если мы понимаем что метрика у нас есть но давно не обновлялось мы 1 12 часов обновляем значение в метод дайте про то что это метрика все еще приходит 1 12 часов это вызвано тем что если мы будем словно метрика приходят каждую минуту и мы будем каждый раз все периоды xi жить в ластики пластику не очень хорошо то-то будет соответственно тут есть некая оптимизация и дальше мы по ключу просто записываем в основное хранилище условно блок со значениями чтение метрик у нас два источника чтение метрика первое это соответственно когда пользователь приходит открывает дашборд график и смотрит на него второй триггер точно так же по какому-то выражению приходят каждую минуту вычитывают метрики сравнивать пороговым значением или там еще как-то хитрее и соответственно там заводит инцидент и отправляют уведомление еще как-то ну и соответственно я тут показал пример запроса как это все делается то есть мы выбираем конкретную метрику у нее есть селектор это наш поисковый условно запрос а дальше есть какие-то функции группировки есть функции агрегации а там не знают об показать неважно и общем то вот этот вот expression выполняется как графиками так и триггерами и соответственно этот запрос всегда выполняется в интервале времени у нас все запросы ограниченные интервалом времени если пользователь хочет график за читы часа значит 4:03 геры понимают сколько им нужно данных если нужно там последняя сколько . не запрашивает там меньше часа ник они запрашивают но чем они забрасывают эти данные тоже за интервал времени начиная там с x таймс лампада y и что происходит физически при чтении физически мы отправляем запрос в ластиком этот селектор метрик разворачиваем в некой elastic узкий запрос и говорим elastic ну-ка дай нам метрики дживс request right у которого есть поле префикс весел и был сет разворачиваются в фил и elastico то есть наш документ словарик люди значения дай нам по такому-то критерию и критерий идет по дате по временному окну и соответственно так как мы оптимизировали 12 часов у нас есть еще погрешность мы как был запрос включаем то есть у нас погрешность если метрика там 12 часов не приходило но мы можем ее выбрать как бы но на 13 сейчас она уже не выберется и соответственно часто elastic возвращает нам тысячи метрик на наш запрос и потом мы берем эту тысячу айдишник of 1000 ключей идем с ней в кассандра чтобы получить рыбу с это исходное потому что они нам нужны при обработке нашего выражения потому что мы там группируем по полям и так далее и соответственно на этом этап metadata закончен мы идем непосредственно в сторож получаем оттуда все данные и потом вычету вычисляем наше выражение уже там на память и немножко про нагрузку всего этого запись записывается у нас сейчас вот прямо сейчас где-то 110-120 точек в секунду тысяч метрик запросов в секунду от всех источников нас где-то триста пятьдесят каждый запрос в ластики у нас власти индексы по шарден и по месяцам то есть зависимости от интервала запрос поисковый запрос дергает либо 1 либо 3 индекса в худшем случае соответственно в каждом яндексе где-то около 100 миллионов документов ну где то это 30 гигов власти кипа компактный индекс но есть определённый кайф в том что большинство запросов все-таки делают не люди а триггеры их там около 90 процентов и мы стали ну и вот еще это график потребление процессора elastic все о чем то есть данном случае по оси x у нас количество ядер и на нашей такой достаточно слабенькой нагрузки в пике elastic у нас живет 55 процессоров процессор ных ядер это вот как бы не то что сколько мы машинам далее а сколько он реально потребляет и это что-то кошмар какой то вот мы поняли что надо крутить и ластик моего крутили вообще-то мы ожидали от него что так как запросы одинаковые и данные изменяются редко это должно все попасть в него в некий каире кэш и он нам должен как из пушки ответы на наши повторяющие запросы выдавать но нифига все наши упражнения с ним давали где-то плюс минус может быть там пару процентов производительности мы пробовали гонять наши запросы на вообще неизменяемым яндексе и тоже ничего не дала в общем либо мы его так не осилили либо он это вообще не осилил но так как это ластика отказаться мы не можем потому что все таки есть этот хак запрос от пользователей и мы не можем все заранее при дочитать мы решили что мы сделаем кэш который соответственно основную нагрузку эти вот 90 процентов снимет с него и вот сформулируем такие требования кашу метрики которые перестали приходить должны вытесняться потому что у нас очень много есть метре который достаточно динамичные они там пришли две точки не знаю там 500 кипур лам-ка комната второстепенному потом их нету потом они может быть опять пришли и такие метрики которые пропадают они должны с каша вымываться иначе там очень много накопится данных и будем много всего лишнего поднимать и соответственно по его a consistent насти актуальности метрики которые пришли вот новая пришла она должна искаться но в течение минуты максимум и такие требования не позволяют нам сделать просто за каширу это результаты одного какого-то поиска плюс ко всему мы ищем все время по по интервалу времени этот поиск будет инвалиде равана постоянно ну как бы кэш и мы соответственно никакого профита от этого не получим и мы решили что надо обновлять кеш при записи можно попробовать и все свелось к тому что мы решаем задачу так называемого обратного поиска его еще называют перкаля перкаля тарам потому что ну там дальше я попытаюсь объяснить что такое то есть если у нас обычный поиск это какой-то статичный набор документов которых у нас уже есть мы по нему построили inverted индекс то есть мы знаем какие ключевые слова или там термы ну в общем случае там слова мы знаем в каких документах они есть и к нам приходит поисковый запрос дай мне там условно документы в которых есть котика он ищет adige ники документов которых при индексации он видел слова котик и отдает нам этот список 1 ников обратный поиск устроен наоборот нас нету документов не от индекса по документам мы знаем только сохраненные запросы которые нам заранее с configure ли и когда к нам приходит некий документ наша задача ответить что на какие запросы он мочиться соответственно мы делаем совершенно противоположную операцию часто перкаля цию использует но вот я такие основные из кейсы выписал очень часто делают пред преданны кассационную логику которую у нас есть документ мы составили несколько экспертно составленных запросов и мы проверяем на какие из этих запросов мочиться документ что потом мы поставить теги условно мы знаем запрос по которым мочиться порно или там матерные слова мы ищем если запрос мочиться на этот запрос значит он такой значит мы ему поставляем так или мы там куда то система антиспама отрубает и так далее также можно на этом делать какую-то разве ческую логику что если там не знаю у нас приходит резюме если есть там но доджерс там реак и прочее то это там метка хипстер ну в общем там потом покажи мне там похожих хипстеров там я хочу найти sechelt тирану вот поэтому так вы потом ищите соответственно другой из кейс распространенный если у вас на каком-нибудь магазине есть каталог товаров это на самом деле поиски 1 коты креатив телевизор и он ищет все товары которые телевизор а потом он телевизору не знаю там samsung ищут и это как бы обычно натуральные поиски то есть у вас есть просто индекс документами которых есть некие филби и по каком-то пред ограниченную множеству значение этих field of вы ищете тем самым у вас появляется каталог и часто этот каталог материализует то есть вы говорите если у вас телевизор новый на склад поступает вы проверяете они телевизор ли ты они samsung и зависимости от того что он вернет калькулятор вы его сразу засовываете в нужные каши или в там нужно хранилище прямо материализуете как есть и тоже самое также обычно работают news feed когда вы подписывайтесь на новости по каким-то ключевым словам я хочу получать все новости про бмв или я хочу там условно знать что происходит там в кейптауне вы подписывайтесь точно также у перкаля то есть ваши сохраненные запросы и он знает что если он новость новый документ который пришел за мочиться на запрос который вы сконфигурировали то вам надо его послать по почте или куда-то для вас сложить в аналитической системах even базе точно также подписка на события проходят я хочу знать все покупки в категории там кухонная утварь что же есть на рынке вообще есть технологии для перкаля ции ластик search есть перк olight к вере это прямо то что нужно и то есть вы создаете некий специальный индекс этом потом дальше партнеру хожу в ссоре сфинксе в ссоре есть ticket мне не сделаны которые они считают что им нужна пара баб завестись при котором какую ластик search но там движения нету там есть какой-то обсуждение но решение нету сексе и ничего нету в google open джон я помню шок до его активно смотрел там был проспекте все почему проспектов вообще откуда термин берется считается что поиск перкаля ци это перспективный поиск когда мы не знаем какой документ пришел обычный поиск называется ретроспективным когда у нас уже есть документы и мы как бы назад ищем так вот об инженер функционал свернули он там вот так и залив и не вышел ну соответственно только elastic прям готовое решение есть какие-то на базе люсин и отдельно стоящие штуки которые делают перкаль атор но я так глубоко не вникал ее фишка в том что если поиск вас не полна текста какой-то упрощенный то вы можете где-то подписаться на поток событий делать его руками в ластики я мельком посмотрел как там сделан поиск перкаля цар дождь и честно говоря не собирался в использовании там значит происходит следующее когда вы создаете индекс специальный вот этот перкаля тарный он пытается ваш запрос который вы ему дали разобрать на термо и куда-то все сохранить он их сохраняют сохраняет сохраняет и тут ему приходит запрос на поиск то есть давай ищи нам по документу он в этом случае делает следующее он из всех запросов что они есть допустим вот 100 или 1000 запросов него залили он откидывает те которые не мочиться по полям допустим можешь запрос хочет искать по полю там не знаю там диагональ телевизора а вот документы поиска ну как бы нету такого фил да он их выкидывает остается так называемые запросы кандидаты так вот чтобы их прогнать он делает индекс пром а яндекс состоящие из одного документа в памяти и по очереди забросы в него фигачат и смотрят какие смочив на самом деле процедур индексации по ресурсам вообще-то дорогая ну и как бы а вот я тут не перелистнул соответственно процедура дорогая и как бы мой там микро bench это подтвердил то есть там получается достаточно дорого это можно либо применять когда вас поток записи небольшой либо там еще каких-то случаях когда томас либо запросов мало либо еще что то ну и соответственно мои моя и как бы наши аллергенный ластик она дала себе знать и мы не рассматривали его вообще соответственно но наш поиск не пома текст вы нам не нужно разбирать ничего на термы у нас с документ это словари ключ-значение искать мы разрешаем либо по точному совпадению какого-то сюда либо по префиксом совпадению какого-то филда соответственно мы подумали что надо начать общественной реализации это когда вы берете каждую метрику повернёте на каждый сохранённый запрос единственное что конечно это все в контексте нашего там клиента иди никого происходит то есть у клиента 1 своей запросу другого другие соответственно получается что у нас есть 100 тысяч метрик секунду запись и где-то 100 запросов каждую метрику нам нужно прогнать соответственно мы сделали некий код который просто повторяют логику поиска ну моча моча метрики на запрос соответственно померили биньям он там худшем случае дал тристана на секунд на один человек соответственно так как это вычисление мы никуда не ходим мы просто берем и тупо суммируем это время получилось что на нашем 10 миллионах проверок секунду мы потеряем 3 ядра соответственно 3 секунды в секунду мы будем это делать три дрова на 100 займет в общем то звучит не страшно надо выкопать бой чтобы выкатить это в бой нужно понять логику соответственно я пытался изобразить соответственно приходит запрос на поиск метрики и каждый запрос и знает этот хак он или он регулярные повторяющийся и он говорит пожалуйста использую кэш соответственно сикоша нет запрос просто идет в ластик и все по-старому если есть кэш по этому запросу может быть так что это был первый запрос и раньше мы его не видели значит нужно создать запрос а так как кэш нашу пустой мы опять идем в ластик и соответственно валиден для наш кэш то есть если там данные для нашего запроса по времени если да мы отдаем все из кэша если нет идем в ластик логика предельно простая естественно мы свой cash is elastic они наполняем вообще соответственно при записи метрик приходит следующее мы приходит метрика куча-куча метрик обычно за один запрос приходит там несколько тысяч метрика от клиентского агента как только они приходят мы для этого клиента мы понимаем метрики какого клиента пришли поднимаем все известные нам запросы которые мы хотим кэшировать и каждую метрику проверяем на каждый запрос в случае совпадения мы пишем ее в кассандру то есть эту информацию в кэш который у нас хранится кассандре я дальше подробно расскажу как он устроен и соответственно одну и ту же метрику мы не паримся писали мы в кэше не писали нам кассандра это все разрулит и дубликаты уберет бронницы лиза цию кыш кыш наш вот у него есть дата создания но начинает он быть валиден только она то есть есть чтобы обеспечить консистентной так как с мы не планируем онго лидировать вообще мы хотим чтобы он был к системе мы делаем запас на то что мы запрос создали а в этот момент происходит какие-то запросы которые не увидят ну приходит запись каких-то метре которые не увидят еще то что это конечно чувствует поэтому у нас есть тайм-аут нас на вообще сколько может максимально длится запрос на запись метрик и ровно этот тайм аут и является как бы этим окном которые мы пропускаем соответственно у нас появляется время с которого кэш валиден и как это все мочиться на то что у нас запроса по времени соответственно если наше окно запроса где-нибудь здесь a cash валиден там-то мы считаем что конечно не валиден идем искать в ластик если соответственно так то тоже кашне валиден только вот такой запрос попадает в кэш ну как бы результаты такого запроса берутся из кэша и мы считаем что они целостны и отражают реальность потому что все изменения после 3 нет обязательно в кэше присутствует если нам в ходе записи метрик не удалось что-то записать кэш значит мои агенты возвращаем пятисотку и значит он будет делать 3 трой и тогда мы точно запишем метрики кэш у нас хранится в кассандре соответственно результаты ну сам кэш побитно 24-часовые куски для того чтобы решить задачу вытеснения и соответственно ключ хэша это некий хэш от кори ну там все там еще ко всему этому приделан модификатор клиента потому что у клиентов все равно и соответственно time stamp суток то есть это текущий тандем штампа нормированный на 24 часа и соответственно в кэше у нас лежит на показ андровская это ключ метрики и лейбл секс реализованных jison и фишка в том что если мы из каша берем то это всю задачу метод вычисления метаданных метрик мы решаем сразу нам не нужно идти в кассандру для того чтобы получает метрики по ключам то есть нам нужно сходить в кассандру для того что получить значение метрик и соответственно то как мы в этих вытесняем метрик в чине суток метрики все копятся в своих чайках соответственно сутки перед щелкнули метрика впадает в д2 в d3 и так далее к вере берет вытаскивает все дни которые вы и границы попадали и просто на память и убираются дубликаты вот собственно то как мы это выкатили это целуюсь лучше ластиков он там с 55 ягер упал куда-то вниз и в общем на там и зафиксировался при этом кассандра не на чтение на запись ничего у нас не почувствовала backend вот мы как ровно посчитали 3 ядра так он примерно 3 ядра и занял hit rate у нас 98 процентов где-то то есть с 90 процентов там что-то напутали 98 по факту мы отдаем из кэша происходит когда новый запрос которого мы не знаем конечно него лизин час эластики чуть нагрузка повышена на потом все спадает и это как бы навсегда фиксируется в кассандре ну и соответственно полотенце из кэша достать примерно неужели понтам меньше 100 миллисекунд соответственно сходить власти корчевка сандру это где-то в 5 раз дороже собственно все что я хотел рассказать потому что паттерн достаточно пустяковые я просто хотел рассказать про то как мы это применили соответственно задача может быть растет из наших кривой круг я не утверждаю что власти невозможно заставить так работать соответственно наш кэш нам перспективен в том плане что мы имеем некую шенон который мы подписаны изменения по какому-то запросу и дальше мы наворачиваем на неё логику у нас есть планы мы будем там там же на потоке все считать ну и соответственно все если есть образцы я готов ответить кори спасибо за доклад было круто вопросов 2 первый вопрос следующий 1 следующий а собственно во первых как вы реализовали выбывание с каша собственно вот про про чанки суточные труда но есть нам сказки тачанки как как вымываете то есть у вас счетчик это памяти вот что не подожди смотри вот у нас приходила метрика она приходила ни один в дне 2 внyтри уже нет и когда мы будем искать за день 3 она как бы не будет попадаться в результаты а в кассандре но она пусть лежит хрень снятом отрезаете воскрешать бесконечному доски но просто право не понятно тебе понятно и я имел ввиду про то чтобы в результатах не замешивал метрика которая уже нет это на я не правильно сформулировал да это него но не понятно и второй вопрос новый бизнес пакет прямая что like что на уровне лайки на сайте потому что фактически про запишемся даже города сейчас нет сейчас даже борды не за кашированные потому что я не помню почему сейчас мы решили задачу для 98 процентов запросов это триггер и делают так это и есть наш борта то есть люди смотрят на то спорта и больше не автозвука несколько наград и роботы считают триггеры они же учитывают все то же самое а то есть три изучать для тренеров это тоже используете вот 98 процентов на чтение делают триггеры людей мало но при этом а задержка три минуты a trigger должна сработать в ней средствами на траке три минуты нет три минуты этот когда мы провязали zero вали кэш вот эти три минуты пока он не валиден мы насилуем ластик но мы все данные видим вот через три минуты кэш начну начинает отдавать нам полностью консистентные данные если у тебя range помещается у него попасть и в этом большая часть триггеров они обычно поводу того что происходило последнюю минуту ну нет ну да и нет у нас очень много тренеров от нормированы на предыдущий период а то есть то есть то что мы сейчас вы берете и жалости к ну а последним то что далёко вы берете искоса ну вот когда мы первый раз встречаем запрос покажи мне все метрики по процессу питон и хотим там сравнить его с процентами вот этот запрос создается создается кэш и пока вот этот хэш мы даем три минуты на то чтобы запросы дошли и и следующий запрос на запись знали что такое существует с этого момента проходит условно час и сто процентов запросов по этому закону по этому запросу возвращаются из кассандра а до этого возвращаясь из кассандра или нет то к кришне валиден не возвращаются но через условно через час все запросы по часовому ренджи будут валидный консистентные спеша но хоть раз спасибо за доклад не только вопросик вот двери там есть диапазоны и значения диапазон ную только подати кроме даты нет ничего нету там либо точное совпадение термо либо префикс даже после кс у меня вопрос такой небольшой хочется уточнить по алгоритму когда вы говорите у вас есть какой-то свет документов но при в качестве примера один документ и пытаетесь понять какие то поисковые запросы к нему могут быть заданы его что по очереди просто перебираете какие-то то поисковые запросы к этому документу откуда в эти запросы берете это ручные какие-то этой вот первый раз когда к нам пришел наш потребитель либо график нарисовал дашборде либо триггер учитывался и понимаем что этот запрос будет повторяться каждую минуту словно триггер он сохраняется и даст с момента к сохранили каждый раз на него строится крыш какое количество примерно этих запросов может быть для среднего проекта у нас по моему штук что запрос я просто смотрел возможен тут может быть еще такой подход триггера такое техническое решение а можно попробовать точки зрения там анализа данных опять же пастеризовать документы и посмотреть какие запросы потенциально были заданы к похожему документу не а у нас нет проблем с при предиктивный составлением запросов потому что у нас хороший хитрить на выходе 98 процентов нам вот лучше не на даче у нас всю нагрузку то есть изначально задача была снять нагрузку с elastico ну и как косвенная задача снизить в этом свет этого этапа но снизить время задержку мои сделали вот 98 процентов удается из кассандра elastic по циклу не потребляет в танце меньше 100 миллисекунд на эту стадию вместо 500 и улучшать это можно было бы дать сделать predict и предсказывать какие запросы гипотетически нам понадобятся их причислить но по сути нет такой проблемы не только задач но я согласен проблема не очень актуально особенно когда еще всего что запросов это не очень большое количество можно просто перебрать возможна ли ситуация когда вы будете расти и не 100 запросов утомили он и будет документ не маленький какой-нибудь две странички а миллион страниц может быть так это не документ это словари ключ-значение маленький настанет документов документа и на виду сущность поисковые машины то есть тогда картина другая ну плюс условно на клиента нас устраивает вот это вот сцена вот этого вычисления тристана на секунд на одну проверку нас устраивает ну плюс там есть на сандвичи покрутить чтобы завести ключ-значение там конечно структуре на данный получается очень быстро перебрались раз я думаю документ текстовый там почти нет это очень доки конечно да ну то есть вот я и про то и говорю что задача сводится к очень примитивной реализации но она как бы получается от elastico добиться чтобы он нашу примитивную задачу решал примитивно но быстро мы не можем поэтому мы накостыляли свое мы вообще хотели иметь сервис поиска в которые мы отправляем запрос нам возвращают за адекватное потребление ресурсов так как нам существующие решения да не дали но мы вот сделали такую штуку можно маленький прям совсем вопрос такой во говорит что 1 12 часов перрин фиксируется метрики это у вас прям константа потом крону было 12 часов запускаете монеткам нет метрика на самом деле когда приходит метрикам и из некого каша поднимаем как какое у неё текущее значение апдейт компаса не раз апдейтов именно она и соответственно если процесс этого момента прошло 12 часов и более мы и отдайте мой проблем на индексацию момент записи это сделано для того что мы не можем по крону нечего делать иначе но тэсс у нас происходит 100000 метрик секунду это значит минуту мы обновляем где-то сколько 6 миллионов до 60 я веду просто к тому что вас ведь неравномерные такая нагрузка была на мерно ночью днем вообще равномерно мы же собираем данные сенсоров условно на агент на машине это сенсор он управляет метрики каждую минуту не зависимости от нагрузки если у него там где-то нагрузка то у него значение метрики там увеличиваются до носом количество метрику на суд реально рыб с вот такой ну там пришел новый клиент вот ушел клиент такого не происходит как-то рано компания не почему это же это же данные это вот куда-то администраторы установили условно на сейчас обслуживаются там около под 2000-х став наверное вот и на каждом стоит агент он генерирует константное количество метрик они там чуть-чуть плавают но вообще незначительно но это же это же не людские посещения поэтому дорогу хорошо и снят образца спасибо за внимание"
}