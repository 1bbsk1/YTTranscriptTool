{
  "video_id": "Wq7wQ9oyvSw",
  "channel": "HighLoadChannel",
  "title": "Odyssey - масштабируемый пулер соединений для PostgreSQL / Д. Симоненко и Д. Сарафанников (Яндекс)",
  "views": 5188,
  "duration": 2732,
  "published": "2019-01-14T00:12:59-08:00",
  "text": "как вы уже поняли с докладом одни представим вам одиссей это новый масштабируемый puller соединение для прогресса я расскажу немного о том как мы к этому шли что нас привело к такому решению и потом дима вам расскажет более подробно про сам одиссей начнем сначала с вопросом вообще почему стоит экономить соединения позарез у почему есть такая необходимость но собственно позарез использует процесс ную модель это значит что на каждого клиента он фыркает отдельный процесс который обслуживает запросы этого клиента вот и внутри этого бэг-энда непосредственно есть свой кэш локальный он кэширует много всего например в системный каталог там вся информация о таблицах правах и так далее там лежат скомпилированные пыль пока рискует функции и также там кэшируются планы запросов разобраны также если копнуть поглубже в плоскости есть такая структура данных про к-рый она называется это такой массив который содержит по элементу на каждый backend ну и там собственно содержится вся информация про все бренды чем они сейчас занимаются там и так далее вот массив этот лежит жареной памяти соответственно он защищен про кары лаком к нему обеспечивается конкурентный доступ вот значит как известно вывести snaps у тебя есть в подписи список активных брендов но да и соответственно точнее список активных транзакций чтобы его получить нужно непосредственно пройтись по этому брокеры локу поэтому при каждом создании вестись и snapshot а но фактически это при каждом запросе were't комитет уровни изоляции происходит взятие блокировки в жареном режиме такие блокировки между собой как бы не конкурирует но однако при каждом создании нового бэг-энда новой сессии или при завершении транзакции блокировка или берет что в эксклюзивном режиме она уже конфликтует со всеми шарик блокировками того что получается так как backend кэширует много все внутрь это очевидно что повторное исполнение запросов в нем же будет работать быстрее чем создание нового и потом наполнения этого кэша но отсюда вытекает следующее свойство что чем больше бэкон дав тем больше памяти употребляйте памяти как бы памяти навсегда конечно я вот ну и справа рыло к как бы так вытекает что чем больше у вас запущен бэг-энда всем получается все медленнее работают так посмотрим где можно вообще экономить соединения как их можно экономить можно ну вы экономите дней не можно создавая как бы полу и перри используя их вот где можно создавать эти полы можно создавать приложение базе данных как бы на стороне база данных и где-то посредине между ними но и всячески их комбинации пул соединений в приложение будет полезен в любом случае так как вы хотя бы сэкономить там факт установления соединений и аутентификации однако это будет не очень хорошо работать если у вас например много серверов приложений каждый из них будет держать какой-то пул необходимы ему для работы вот соответственно будет запущена много брендов ну и так же если у вас много серверов баз данных например леська это база данных она там разрезано на 100 ярдов получается что каждому из этих сортов нужно держать свой пул соответственно на это у каждого бэкон смысле у каждого сервера приложений получается очень много памяти там будет тоже расходоваться большие пулы пол синий на стороне будет бдм ну в подгрести нету пул соединений поэтому фактически это второй вариант это пул соединений остается между базой и между вашими брендами в об стриме есть два самых популярных решений этапе джип ил-2 и пока bouncer пиджи pool 2 умеет много всяких интересных штучек вот однако он умеет только сашин pulling up bouncer и такая штука которая но умеет мало всего но зато умеет делать это хорошо самая главная фича это производительность но естественно мы выбрали пока bouncer собственно все хорошо однако мы испытали некоторые проблемы первое с чем мы столкнулись но естественно это логично по сложилось любая диагностика соответственно так как капусту теперь непосредственно ходит пока bouncer пастбищ думает что к нему все клиенты выходят слуг аллаха 100 от немножко усложняется любую диагностику если у вас имеются какие-то сетевые проблемы или если у вас есть какие-то клиенты которые используют там всякие необычные хипстерские там драйвера которые как правило могут себе чаще других везти не очень адекватно вот та диагностика осложняется для этого в пагуба он себе придумали такую фичу сделали такую настройка называется приклеенный макхост когда вы ее включаете у вас пока bouncer вопреки шинным дописывает айпишник и порт клиента который к нему пришел таким образом во вью типажи стадо activity вы можете увидеть реальный и пешни клиента и собственно диагностика у вас обратно облегчается но здесь есть обратная сторона медали по сути получается что на каждую транзакцию по губам сыр теперь перед запросом посылает в после запрос это плетей шинным такой-то вот здесь приведён график синеньким зеленым он здесь даже видно неплохо с зеленым цветом здесь отображена сколько рпс по сути влетает в позарез а вот эти вот коричневым цветом сколько рпс летает bouncer но тут можно заметить что разница примерно в два раза вот как раз со включенной настройкой application name a ghost дальше пока bouncer иметь такую настройку макс клиенткам это настройка ограничивает количество клиентов которые могут подключиться балансиру извне вот здесь на примере она выставлена 20000 однако нет настройки которые ограничат количество клиентов на один пол мы сталкивались ситуациями когда один из клиентов базы данных использовал там какой-то но джесс драйвер в нем текли соединения в итоге он съедал все двадцать тысяч соединений с базой больше никто работать не мог но собственно это очень плохая ситуация вот и как бы решить и стандартными средствами не представлялось возможным но мы ничего лучше не придумали как запотели bouncer и сделали там такую настройку вот например выставили в 4000 они съедят из своего пола 4000 соединений сами перестанут работать остальным мешать не будут вот дальше следующая проблема в погба он сам средствами пока bouncer нельзя ограничить для одной базы данных выставить разные размеры пула разным юзерам то есть вы хотите для одного лидера там 200 соединений для другого 10 но зато в подгрести у юзера есть такое свойство каком connection лимит там можно его ограничить количество брендов максимальной запущены из под этого юзера и вы можете средствами внутри под gresso ограничить как бы одному юзеру 200 поставить другому 10 казалось бы все хорошо вы на самом низком уровне ограничили количество брендов запущенных из-под юзера но здесь есть один нюанс это как бы работает но the bouncer скажите пожалуйста а кто видел когда-нибудь ошибки по губам сыр cannot connect to server есть такие в зале значит что происходит при этом пока bouncer пытаясь подключиться получает ошибку от прогресса что у него закончились connect и выйдем элемент коннектор для юзера такого-то вот а наружу отдает ошибку пока bouncer cannot connect to server вот собственно это особенно больно всяким администратором приложений которых нет доступа к лагам пока bouncer и которые просто не могут понять что происходит они получают ошибки пагуба мастер cannot connect to server не без объяснения причин ничего непонятно в общем информативность этой ошибки стремится к нулю вот здесь приведён пример как из psyko пока 2 также мы получаем эту ошибку и даже вот по сути не получаем никакого внятного кода ошибки и даже если вы будете писать какую-то логику retrieve the как бы сделать то что то нормальное крайне трудно потому что нет никакой системы возврата этих ошибок по сути до установления сессии вот эта ошибка возвращается на все на любые ошибки дальше вот здесь приведен скриншот даже барда графиков одного из наших сервисов вот тут можно заметить как в один момент сервис начал 500 вот 500 он начал из-за базы данных вот из-за того что время выполнения запросов базе данных подскочила до небес вот когда мы полезли разбираться то не ушли никак не нашли никакого криминала ничего подозрительного кроме вот такого факта что погибал surf съел одно ядро сто процентов одного ядра и все как бы вот здесь приведен скриншот из топа видно вот он есть 97 процентов как бы погибал сыр как известно однопоточный по сути он съел столько ресурсов сколько вообще он мог съесть и масштабировать его как бы больше не представляется возможным но что значит нужно сделать нужно запускать больше по губам серов но начали мы пробовать собственно первая наша схема которую мы попробовали это было запускали несколько пока балансиров на одном порту точнее на разных портах ставили перед ними х прокси и балансировали нагрузку клиент ходил в х прокси вот какие собственно плюс и вот и схемы все прозрачно для клиентов все хорошо клиент продолжает ходить в один порт для него ничего не меняются какие минусы но диагностика осложнилась еще сильнее теперь и погибал сир думаешь что к нему ходит слуг аллаха 100 поэтому все по сути и печники становится локалхост вот появляется еще одна движущаяся часть перед пока баузером за который надо как-то следить там управлять и так далее ну и также х прокси ничего не знает про протокол погреться поэтому когда собственно направляет запросы в пику bouncer если там база недоступна по губам всему возвращает ошибку что он не может под конектится х прокси думает что это как бы нормальная ситуация и продолжая лить туда нагрузку в общем в итоге у вас заканчиваются соки ты и все и ничего не работает ну тут это можно обойти написав нормальные чеки там для х прокси и так далее вот но мы подумали что проще будет за патчить bouncer конечно вот начиная в линуксе начиная с версии ядра кажется там 39 появилась такая опция историю спорт это она позволяет вам запустить несколько процессов на одном порту ну чтобы они слушали один порт вот вот такой маленький патч позволяет bouncer у запустить несколько балансиров на одном порту вот так выглядит эта схема вот мы тут в данном случае запускаем триполи bouncer на одном порту клиент ходит в этот порт и ядро само балансирует там распределяет коллекцию между пока балансирами вот вроде все хорошо с этой схемой фанов также прозрачно для клиентов клиенты ходят в один порт никаких дополнительных движущихся частей нет однако тут есть минус что у вас увеличивается количество запущенных брендов позарез а потому что каждый bouncer держит свой пул пул и не между собой не шарят по этому запустите 3 балансира будет у вас трепала соединений запустите больше будет больше собственно все было хорошо запустили вот например 3 п г bouncer а но было хорошо все до тех пор пока он не пришли безопасники пришли безопасники и сказали включите tls вон там мы включили увидели вот следующую картину вот здесь скриншоты стоп а где ты ти3 пока bouncy раз ели 3 ядра процессора и все опять опять мы уперлись по сути в процессор i5 масштабироваться тяжело но мы подумали но ладно давайте запустим там 1016 там пагуба он серов на одном порту school запустим столько сколько нужно правильно вот он собственно постреляли если пострелять погибель чём то мы видим что на самом деле просадка производительности если переустанавливать соединение ну вот здесь данном примере порядка 20 раз вот если посмотреть в перв то в топе мы увидим там всякие open и социальные функции вот по сути весь процессор тратится на тсн шейки вот но и тут может случиться такая ситуация которую называем взрыв тсн шейков когда вы открываете базу для нагрузки вот только только вы открываете все клиенты видят что она стала доступна и хотят все разом у нее притти-вот они начинают все разом устанавливать соединение происходит вот так называемый взрыв ты ласкал шейков пока bouncer только и занимается тем что устанавливает делать хен шейки вот но если вы так хорошо подгрузить и процессор то может случиться так что у вас они будут как бы происходить медленно а у некоторых клиентов может быть выставлен очень маленький connect тайм-аут они собственно не будут дожидаться пока уст произойдет как они будут вырвать соединение и ретро и но в итоге можно как бы они просто запросто могут заддосить вашу базу и все и как бы база просто не сможет встать с колен вот здесь приведен скриншот где запуск здесь видно плохо но там запущена 16 пагуба он серов и все они как бы вы или 16-е der вот это как раз ситуация взрыватели скан шейков такого но это мы просто до экспериментировали и как бы в общем то ни стало понятно что чтобы перезвон переживать такие взрывы нам нужно держать запущенными много балансиров однако если мы будем держать 16 балансиров мы получим количество сессий там 16 кратное увеличение он собственно это нам не очень нравится поэтому мы придумали вот такую схему она выглядит смешно вот в общем мы стали запускать баузер в два слоя на первом слое в который ходит клиент запущены 16 пока балансиров на втором слое запущена уже там два или четыре сколько хотите вот собственно только эти внутренние полосы держит путь подвесу вот таким образом на внешнем слое может запустить сколько хотите чтобы пережить этот взрыв кончиков вот ну и собственно что получается в итоге по этой схеме также она остается прозрачных для клиентов собственного управляя количеством балансиром на внешних слоев мы способны по сути сделать но сдержать там любой наплыв клиентов вот ограничен только количество ядер на железке количеством балансиров на внутреннем слое мы как бы по сути дела регулируем количество игл и сиси по сгрыз а вот ну так же тут появляется такая фича который можно как же пользоваться можно плавно их по одному рестарте практически незаметно для клиентов вот но тут большой есть очень большой минус все это дело очень сложно обслуживать схема очень сложно появляется всякие процессы типа супервизор которые следят за всеми ими управляют и так далее вот но в общем-то это схема выглядит немножко монструозно вот напрашивается такой логичный вопрос почему все это не неё да ну выпил source там где то не выложено а вот но вам покажу на примере здесь пагуба он все еще одна проблема в общем если пришел клиент по губам сер отправил запрос он запрос долетел до погреться подогрев его выполняет но выполняет его почему-то долго у клиента произошел тайм-аут вот ну то есть там клиент написан так что есть настройка клиента и мало то смысле ну какой-нибудь таймаут на выполнение запроса у него он истёк он должен по сути перетравить выполнения этого запроса вот у него два варианта либо он пошлет там есть специальный в ли pq механизм отмены запроса вот он должен либо послать какую consell отменить как бы выполнение этого запроса и при травить но однако клиенты если клиент асинхронный тут есть один нюанс что вызов пику конце флип икон синхронный поэтому тут в общем нужно либо если у вас там какой то клиент поверх ли pq либо нужно реализовывать самому асинхронный i can sell либо нужно там городить какой-нибудь дэдпул сбоку и так далее в общем в итоге получается что клиенту проще всего просто оборвать соединения установить новый прекратить запрос вот когда клиент обрывает соединение в общем все это до погреться не долетает по взгляд продолжает его выполнять выполнять выполнять как только он его выполнит попытается отправить клиенту ответ только тогда он поймет что его ответ на запрос уже никому не нужен и вообще можно было его не выполнять вот таким образом то то же самое можно как бы как бы уложить базу на самом деле такими ретро яме то есть просто задать стиль краями вот на это собственно какой здесь вариант решения здесь можно возложить эту обязанность на bouncer а когда клиент рвется единение с ним он может послать на самом деле отмена выполнение этого запроса и вернуть в соединении в пул вот собственно был там сделан ребятами из pull request на эту тему но в общем честно говоря очень он неохотно как бы рассматривался вот и честно говоря пока bouncer уже не выглядит как живым проектом вот поэтому скорость там межевания туда каких-то изменений она практически нулевая вот поэтому собственно говоря на мне очень хотелось с этим связываться вот ну давайте подведем итог чего хочется нам от кулера соединений первая основная как бы первое основное требование этого масштабирование по ядрам чтобы не приходилось городить вот такие монструозные какие-то сложные обслуживании схем и чтобы он масштабировал ся по ядрам сам дальше хочется более гибкой настройки то есть я вам там приводил примеры какие-то вот так же хочется чтобы можно было наглядно проследить вообще любой запрос там от конкретного клиента до того там как он выполняется в базе возможно хочется чтобы puller был немножко умный чтобы он например мог там сам выбирает тип полинга ну то есть если например вы послали там запрос на создание временной таблицы то он понял что у вас надо прибить гвоздями к этому бренду и как бы все ваши запросы выполнять на нем ну и естественно хочется проброса коды ошибок что вы клиенты понимали чтобы прозрачно было все чтобы понимали какие проблемы сейчас базой что нужно ретро не что нужно не или травить и так далее вот но самая большая проблема это масштабирование по ядрам то есть посмотрев на погба он сам поняли что там но это как бы по сути это архитектурные проблемы и там нужно в по сути дела все переписывать чтобы решить эту архитектурную проблему вот и таким образом мы пришли к тому что проще написать свой на самом деле пули оставляя учесть все эти минусы пока bouncer а вот так родился одиссей про который сейчас расскажет мой коллега дима вот всем привет я расскажу про детей который мы опубликовали буквально в прошлом месяце так что это наш первый доклад о нем одессе сейчас выложен в репозитории яндекса яндекс одиссей сам он написан на языке си для сборки вам понадобится любой из компиляторов семейка ли си лонг и он сделан с минимальным количеством зависимости сейчас там только у панаса цель для запуска одиссея нужен файл конфигурации в этом очень похож на pg bouncer если сравнивать одиссей спг балансиром в принципе они очень похожие друг на друга только odyssey написан с нуля и он сам по себе многопоточный если посмотреть на список поддерживаемых операции и типы пулен горит транзакций pulling и сашин pulling the вот этот вот табличка с поддержкой фичей и для детей она будет такая же как погибал тире основное отличие конечно десерт погибал сердца то что многопоточный но также мы реализовали несколько других очень полезных фич пример автоматически rollback console и я об этом расскажу немножко дальше подробнее также мы сделали возможность передачи ошибок и более удобную отладку помимо этого в одиссей совместим с консолью погибал сэра это может быть удобно если у вас на погибал сир уже завязан какой-то мониторинг вы скорее всего сможете бесшовно его интегрировать туда и если какие-то может быть команды не поддерживаются то они скорее всего либо скоро появится либо мы вам поможем и добавить так значит многопоточная обработка в одессе я поскольку мы решили написать свой connection puller то мы решили сделать это основательно для одиссей мы написали свой многопоточный движок крутим на котором одиссея весе построен по сути дела machinarium каждый поток работает в своем отдельном потоке своим реализует свою task manager и привязан к какому-то и пол контексту также машина рим обеспечивает очень эффективную поддержку сетевых операций например если мы делаем какой то буфере zero ванна и чтение или запись то курите на будут ездить контекст светится на другие и дожидаться выполнения также там есть поддержка time out of cancer action of крутин и и так далее помимо этого есть несколько очень полезных оптимизацией в одессе например это пай planning запросов которые вы насколько я помню не было пока bouncer и то есть например когда клиенту приходит какой-то запрос то есть в подгрести вообще запрос он состоит из нескольких пакетов обычно то есть итак вере потом происходит рис пункцию от сервера которую состоят из нескольких пакетах вот и если пакет и маленький то одессе умеет их совмещать в один большой буфер и отправлять пачкой клиенту или серверу будет помимо этого эти pipeline буфера не внутри одиссея кэшируются это для того чтобы избежать тяжелых рио локов многопоточном приложение и как то лучше работать с локаторами стандартными так значит как одиссей устроен в одиссей сам по себе он основан на machinarium а также там реализовано внутри библиотека для работы с протоколом под gresso внутри одессе есть несколько под систем которые работают своих картинках например эта система маршрутизации который отвечает за обращение клиентов на выдачу и ассоциацию с отдельными пулами и выдачу серверов ожидания новых серверов и так даря потом к подсистема для работы с консолью которые тоже связано с маршрутизацией и имеет информацию доступных маршрутах также крон который отвечает за то чтобы обеспечить устаревание каких-то серверов под этой или и так далее и слушающие входящих клиентов нас вот кажется заработал когда происходит соединение от клиента когда происходит соединение от клиента об этом поступает событий на один из слушающих серверов и это событие передается в один из из worker of которые находятся в пуле worker of то есть каждый worker работает войдем в своем отдельном треке который тоже привязан с apple контекстом тоже и в крути не слушается входящее сообщение vento новых клиенток когда клиент приходится для него создается новые крути на и внутри которые уже в синхронном представление происходит работа уже с этим клиентом почему синхронным потому что вот это вот все затея с картинами это было для того чтобы обеспечить для разработчиков более простую работу с синхронными приложениями потому что весь код он выглядит очень просто как будто он написанная синхронным дальше после аутентификации клиента происходит ассоциация с маршрутом и дальше уже происходит постоянно запросы к маршрутизатору на выдачу и ассоциацию к серверу то есть 10 transaction pulling нам пришел запрос мы получаем должны получить сервер поработать с ним потом отдать соединение дальше вот поскольку очень часто бывает случай когда нам нужно запускать puller соединения в 1 поточном режиме или возможно вам просто не нужным множество потоков вы хотите но возможно новые фичи просто одессе я тогда в одессе есть очень интересная оптимизация для работы в 1 поточном режиме которые вместо того чтобы создавать разные потоки для в worker of он начинает так запускать в одном едином тренде и также понимает что вся работа работа с сообщениями и и созданием клиентов и так далее оно должно происходить минимум и сколов и каких-то коммуникаций за счет этого он работает очень быстро этот весь многопоточная вверх и там в принципе уходит также мы реализовали множество улучшений которые нам понадобились прежде всего одиссей старается сохранить connect с сервером в отличие от погибал сыра который пытается его закрыть при любой возможности как-то от него избавиться реализовали автоматический rollback он работает например если клиент отсоединяется то есть он находится в середине транзакции и соединяется просто одессе это видит понимает что была открытой транзакцией выдает рубик серверный connect и уже потом возвращает этот connect обратно в пол также если клиент уходит во время выполнения запроса которые еще не вернулся результат-то одессе умеет устанавливать отдельно и соединение в котором для этого же соединения выдает концу и дожидается пока вас крест вернет управление назад также здесь и умеет понимать что запросы могли быть в по и планинги может выдать несколько концов если там была какая-то очередь вот и еще есть интересная оптимизация это на установку клиентских настроек то есть если карен делает сет одиссей это все помнит также сэм скорее всего будет автоматически выставляется на какие-то операции вроде а приписанные мы и так далее то есть для каждой конкретной сессию клиента она запоминается и эти операции должны повторяться на новый к серверный connect каждый раз приезд с отцы сервером вот одессит запоминает что у этого клиента и скорее всего если этот сервер ему принадлежал паши расту этого делать не нужно не нужно заново перри социализировать сервер новыми параметрами достаточно просто его заново использовать также мы наконец решили эту проблему с передачи ошибок клиенту при соединении с позарез сервером теперь одиссей может правильно передать то что возвращает под gres например если при обращении к базе то купаться не существует то он скорее всего не вернет field connect у сервер как делает пока bouncer но также эту опцию можно например отключить если вы каким-то образом перри определяете внутри базу впо сга рисовую которые вы ходите хотите ее скрыть от клиентов то это тоже можно сделать для этого есть опции настройках также мы сделали удобно логирование отладку в одиссее каждое у каждого клиента есть свой уникальный айди по которому можно отследить что делал клиент по его логу посмотреть просто погребать или как тасс агрегировать куда то можно включить режим отладки также посмотреть очень подробно какие пакеты приходили и так далее помимо это и можно настроить формат логирования который может быть очень удобный если у вас есть какой-то собственно парсинг или вы агрегировать и логин какое-то свое хранилище то можно туда написать что-то в своем формате вот здесь вот на примере сообщение об ошибке при если клиент возвращается ошибка ему также возвращается вот этот вот уникальный одесских клиента по которому можно и вас ассоциировать вот это очень удобно вся настройка маршрутов в одессе осуществляется файле конфигурации там добавляется несколько сессий секций например для настройки сервера указание сервера и секции старый-то мост устанавливается хост порт и тип этого хранилища здесь ты прямо у tribal около около это на данный момент настройка для консоли пока там локальной базы нету также можно для каждого сервера отдельно указать свой режим работы с tsm вы ставите свой отдельный сертификат для отдельных серверов по моему в пока bouncer этого не умел ассоциация с полами осуществляется на основе правил мы определяем базу и пользователей которые к ней относятся если приходит пользователь тест базовый тест то для него ищется вот это вот правило все эти настройки пула если вам к ним по совпадает тогда он с ним ассоциируется если же например пришел какой-то другой пользователь базу тсд и есть дефолтное правила для которого попадает все другие пользователи здесь вот например ставит анти-гей анти fiction блок который такого клиента просто заблокирует в данном случае можно выставлять лимиты соединений для отдельных пользователей потом также включать или отключать концу rollback настраивать типу лингой the transaction рисепшен также есть дефекация на ней есть разные есть например по сертификату мы да и недавно добавили come on i им поддержки то есть можно ассоциировать по сертификату пользователей и сравнивать его с командным сертификате либо какие-то переопределять свое также можно например сходить в какой-то соседней пол для анти фикации то есть у карен пришел и мы должны проверить его пароль мы можем сходить другой пул сделать поверив другую базу и как-то сравнить ее результат и также по аналогии с диффузными базами есть дефолтный пользы по аналогии с дефолтным и пользователями и дефолтной базы которые точно также могут включаться если пришел какой-то клиент в неизвестную базу по моему в балансе это по аналогии с автоматическими пулами что-то похожее есть если же говорить про перформанс в принципе это была наша не основная задача потому что мы прежде всего хотели получить единая то есть мы хотели чтобы у нас многопоточный puller мог шарик между собой серверное соединение но также нам удалось достаточно хорошо и вас оптимизировать эти участь смотря на то что пока bouncer сам по себе достаточно хорошо написан в плане несите в одном по точным приложением мы добились хорошего результата это в основном получилось достичь за счет пай планинга вот и также при включении дополнительных тредов мы получаем достаточно хороший прирост очень похожи на линейный вот здесь на графике изображена сравнение производительности с той конфигурации которые 16 балансирами так далее которые у нас было это по перформанса собственно вот но здесь нужно иметь ввиду что здесь основная задача это именно от sharing pool of серверных соединения между собой значит если говорить про то как одессе тестируется отдельно machinarium по открыто своими юнит тестами и в основном для тестирования мы используем разгаре совы и тесты то есть мы запускаем тест и под греции там указываем место сервера подгорица детей и пропускаем через одессе все тесты и там уже смотрим что сломалось насколько она актуальна очень интересно то что мы сравнивали под bouncer с одиссеем в такой конфигурации у нас получился 0 div помимо этого мы в такой же манере тестировали через за популярные клиентские драйверы точно также переопределили место сервера под греться указывали туда одиссей и пропускали всем весь трафик через него если же говорить про и road map и ближайшее время то что мы хотим сделать это сейчас мы занимаюсь поддержкой добавлением скрама анти фикации который появился в паз gres 10 вот так же поскольку мы за ложились в одессе скорее всего там появятся какие-то очень интересные фичи ближайшего времени например одно из наших хотелок это научить одиссей ходить в реплике для редон и запросов вот возможно появится что-то еще интересное вот мы достаточно открыты к новым пожеланием разработкам или есть ли у вас есть какие-то проблемы вы спокойно можете нам добавлять тикет писать делать пузыри квест и мы с радостью вам поможем если у вас есть какие-то проблемы этого значит что мы имеем odyssey многопоточный puller приложений который может масштабироваться если вам это нужно ну помимо этого он также работает хорошо в одну поточном режиме сравнение спг балансиром и реализует ряд новых фич которые могут быть очень полезны помимо этого проект активно очень развивается мы всячески вкладываемся в разработку и готовы принимать по горе квесты и он точно не не заржавеет ближайшее время спасибо вопросы вот человек 2 даже спасибо за доклад с меня два вопроса будет подскажите как обстоят дела с онлайн рестарта my например нужно обновить версию пока балансира по 1 версию одессе в по губам себе можно было вызвать онлайн restart он без потери венских соединений мог подменить бинарник передать сокеты и все для приложения работала прозрачно до такого сейчас нету покопался действительно документ а вы этим прямо пользуетесь и конечно есть еще другая фича как обстоят дела с постановкой клиентов на паузу когда клиенты висят на паузе это выглядит со стороны приложения как будто база тормозит но мы в это время базу перезапустили база поднялась мы делаем команду резюме клиенты снимаются сползать продолжают работать в приложении до такого нет bouncer действительно и то есть и скорее всего одессе это тоже появится да супер и последний вопрос как называется служебная база ну то есть в baciuzzi она назвалась пока балансира мы заходили в нее делали шел bull собрали статистику смотрели и как в одиссее как вы ее назовете то есть вы просто назову называете какую-то базу ассоциируете is a story джим астор говорите что он local все я понял просила выше спасибо за доклад вот там в самом начале доклада было сказано про клиентский пул и приложении много ну плохо а причем тут как бы клиентский пул и как это относится именно тому что будет пол на стороне не пешки на стороне приложения то есть почему это именно вот здесь сказано как в этом поможет ну или общего принципе полна не на стороне приложения но смотрите пол не на стороне приложения как вам поможет в этом вопрос если у вас много приложений серверов каждый будет держать свой пол в итоге вы очень много connect в базе откройте напрямую если вы перед базой не поставите пул то в итоге вы там просто сотни будете брендов запускать если поставить режим перед базой чисел камин чисел кое-что количество коннектов понял со ну я вам вначале рассказывал что это все не бесплатно увеличивайте чисел q начинает все медленнее и медленнее постепенно работать в конечном итоге вы получаете ситуацию когда у вас все тормозит вы не понимаете почему а потом позже стад activity видите что все там на про кары локи висит у вас и все но как бы рано или поздно к этой ситуации вы придете при увеличении нагрузки вот там вопрос спасибо за оба доклада этот вопрос по автоматическому концу можно ли вообще отключить эту фичу или сделать так чтобы концы лист только select и и не таблиц там и сектором дейт до отключить можно можно для каждого для ввода пользователя это делать база пользователей можно ему сказать чтобы концу не работал или например работал только рубик но только для selecta в такого нету это интересная идея в принципе можем мы об этом подумаем спасибо большое спасибо за доклад очень интересно подскажите а как широко одиссей сейчас используется в инфраструктуре индекса но он в общем пока он не раскатано весь продакшн но уже в некоторых местах продакшне он используется то есть мы его обкатываем на себе на самом деле внедряемся в продакшене дай мне я не буду вам конкретных сервисов называть скажу что где-то использовать я забыл сказать одессе сейчас быть и позиционируем как бы это но она активно готова к тестированию и то есть она ведет себя достаточно стабильно уже после не не знаю больше полгода чьи вопросы ваш доклад у бага по он вчера есть настройка разрешенных параметров от клиента то есть параметр который клиент может это при условии соединение с помощью все это установить у вас также сделана она там ограничивается чтобы можно было потом сделать нормальный из карт нет там этой настройки нет odyssey более permission и в этом смысле он возвращает больше клиентов потому что мы тестировали на большом количестве клиентских драйверов и которые у нас используются в том числе бетонной или горный может быть какие-то вещи вот и они часто выставляют свои какие-то настройки которые просто у нас тест они проходили поэтому мы добавляли в одессе чтобы это все работало с по губам всем было сложнее вот одессе просто сейчас старается запоминать его еще в отличие от пока bouncer одессе всегда делает дискард то есть он на каждый например transaction по ринге при получении соединений к северу он всегда скажет дискард конце и там это все оптимизирована чтобы это сделать побыстрее а этот помощью this card все эти настройки можно надежно сбросить до еще вопроса кажется все"
}