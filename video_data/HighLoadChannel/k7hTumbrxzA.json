{
  "video_id": "k7hTumbrxzA",
  "channel": "HighLoadChannel",
  "title": "Пайплайн для расшифровки речи в миллионах видео в сутки / Филипп Мальковский",
  "views": 684,
  "duration": 2675,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "Да всем еще раз привет как говорил доклад об инфраструктуре автоматической генерации субтитров и сразу обращу внимание что это не доклад не про нейросетевые компоненты если там были какие-то вопросы про устройство моделей что-то больше про инференции так далее был вчера доклад коллеги Виталия Шутова Можно либо посмотреть в записи более подробно либо подойти на стенд мы ответим на вопросы более подробно это же доклад про Back and про инфраструктурную часть про встраивание этих моделей Ну и о чем же именно я расскажу и расскажу чего мы изначально хотели такие решения рассматривали что у нас В итоге получилось а также с какими проблемами мы столкнулись по ходу и дальнейшие Наши планы по развитию технологий а Итак исходная задача заключалась в том чтобы предоставить пользователю удобные качественные субтитры в ситуациях когда сложно или невозможно посмотреть видео со звуком транспорт лекции митинги Ну и как обычно мы хотели начать с популярного контента чтобы сразу же замерить эффект и в перспективе перейти ко всему загружаемому Ну и дальше как обычно использовать новые технологии для того чтобы обогатить рекомендации поиск ну и так далее И что у нас уже на тот момент было мы какое-то время до этого запустили расшифровку голосовых сообщений пользователи были в основном счастливы были довольны тем что их не надо больше слушать и мы искали новые точки приложения этой технологии Ну и у нас также была платформа видеоконтента на которой которая является лидером в рунете по количеству ежедневных уникальных пользователей это также означает не только количество просмотров высокое но и то что контента разнообразного тоже много а именно релевантного для домена распознавания речи То есть у нас много лекций интервью и блогеры разные контент выкладывают Ну и поскольку видео у нас много просмотров много все это не могло существовать без уже развитой инфраструктуры для транспортирования видео для раздачи Ну и в общем казалось что строить будет все довольно просто и интуитивно а да ну и чтобы не запутаться вообще в наших сервисах что где находится При рассмотрении решений кратко пишу как очень схематично как у нас устроен архитектура VK значит запросы пользователей идут через фронтенд фронт сервера У нас есть кирпич пи Монолит в котором окулирует аннулирована бизнес логика которая связывает все разделы сайта и миллионы строк кода огромный бинарь и дальше уже запрос перенаправляется на узкоспециализированные движки и микросервисы то есть в данном случае когда мы говорим расшифровке голосовых сообщений он находится вот здесь это микросервис набора соответственно когда там бизнес логика по отправке сообщений их загрузки обработана монолите на других сервисах уже дается запрос на расшифровку в конкретный микросервис расшифровка получается и дальше уже отправляет пользователю так вот видео А ну больше более подробно про именно про архитектуру данного сервиса по расшифровке голосовых можно посмотреть в докладе Сергея ларионенко Мы же двигаемся к фото видео это тоже на самом деле не сервис а набор сервисов огромная платформа и тоже она находится у нас отдельно от кирпич Монолита тоже мы идем сюда в данном случае через gpc вот нужно нам как-то связать подружить их вместе Ну и первое что мы хотели это просто добавить нужные шаги для генерации субтитров уже существующий но тут же мы столкнулись следующими сомнениями то что во-первых на схеме было то что они находятся не в одном месте они также еще и физически в разных местах то есть микросервис на Гоа распознавание голосов сообщений и Монолит они работают они находятся в Питере а видео Ну так исторически сложилось что у нас видео хранится в Москве и нужно будет слать аудио по сети канала в принципе не является узким местом здесь но в целом для такой задачи задач подобных просто много и каждый раз слать какой-то контент видео аудио по сети мы стараемся избежать помимо этого сомнением добавилось также то что новые шаги точно Нужно будет внедрить сюда чтобы как минимум связать текст с дорожкой чтобы понять когда слово начинает заканчивается но это бы замедлила в целом latency для отдачи расшифровок голосовых сообщений пользователя это Ключевая Метрика этого сервиса вот поэтому все равно пришлось бы делать новый кластер отдельный кластер Для субтитров Ну раз уж делать отдельный кластер Мы подумали А давайте мы сделаем его в Москве его развернем в инфраструктуре VK видео но тоже на самом деле задача не на день потому что помимо того что нужно принести с собой всю инфраструктуру разные дипломы у сервисов разные мониторинг и технологии даже разные то есть здесь такой плюс был у нас видео в основном написано Java а так еще и отсеть от сети мы не полностью ушли Потому что система визуализации метрик в данном случае все еще Она остается в Питере и некоторые другие зависимые компоненты то есть полностью от сети мы не уйдем вот помимо того что сложности с инфраструктурой развертыванием сам домен здесь другой то есть нашем случае мы разработчики предоставили нам другую модель поскольку Голосовые сообщения это немного другой домен у них там много постоянные лексики много разговорной речи видео же могут быть очень разнообразными может быть специфическая речь профессиональная и с точки зрения моделей там разные словари и возможно разные подходы к обучению и даже принцип организации pipeline и параллель параллелизма может быть разной потому что объем данных другой если голосовые сообщения мы по максимуму В общем берем много сразу голосовых сообщений потому что они короткие отправляем в пайплайн видео нам не всегда нужно сразу много видео потому что они могут длиться много много часов Поэтому в целом pipeline В итоге организовали по-другому Ну и нужно добавить новые компоненты Это я уже говорил но в итоге мы решили посмотрели да у нас значит те компоненты пайпла и на то есть в основном это модели это по сути библиотеки на си плюс плюс мы решили В итоге не брать не брать готовый сервис который вот сообщение не переиспользовать не стараться его натянуть на новую задачу Но поскольку вот он использует уже набор готовых библиотек которые нам предоставляют там Или разработчики мы решили переиспользовать этот API Ну и здесь мы подготовили образ для нашей инфраструктуры Ну и написали вокруг этого свою обертвуем который более соответствовал нашим задачам видео да И теперь мы Чтобы понять Где у нас находится sr4 видео Перед тем как мы будем рассматривать я расскажу про то как устроена организация очереди и как раз вот как набираются эти миллионы видео в сутки значит когда пользователь загружает нам файл мы его помещаем во временное хранилище его оригинал и затем ставим задачу в очередь на трансформацию что там происходит у нас есть группа серверов которые мы называем трансформами они приходят в очередь трансформации берут следующую задачу и задачи на самом деле много разных в основном это транслирование в разные качества и форматы в зависимости от качества сети или там уровня заряда батареи мы можем отправлять разные форматы на устройства Ну и довольно часто с этим экспериментирую помимо загруженных видео в очередь трансформации попадает популярный контент потому что ну это может быть например какой-то старый контент который стал популярным мы его перенарежем в более эффективный формат или это могут быть какие-то новые фичи как в данном случае ну чтобы чтобы больше захватить эффект потому что нет смысла просто идти запускаю новые фичу итарироваться по старым видео поскольку мы так не очень скоро доберемся до эффекта до пользователя Да и в этой группе серверов которые занимаются транспортированием видео Здесь также есть отдельный кластер на каждом сервере соответственно видеопарк видеокарта там на самом деле много разных то есть не какой-то унифицированный кластер Ну и на этих серверах выполняется например Недавно мы представили улучшение изображения с помощью нейросетей Ну и вот в данном случае голосовые сообщения вернее расшифровка субтитров она тоже находится у нас в этом кластере также мы ее строили Мы конечно сначала пошли писать там интерфейсы но в итоге мы подумали что будет лучше совсем полностью изолировать этот процесс и общаться именно с нативным процессом через вот вывод чтобы максимально изолировать айсар который требует больших моделей что-то там может пойти не так А на этом сервере у нас обрабатывается десятки разных задач то есть Это не именно выделенный кластер для для расшифровки речи видео это кластер на котором выполняются разные задачи например какие-то тяжелые видео мы отправляем нарезать не на себе пластырь а на GPU кластер Ну и вот параллельно другие задачи связанные с машинным обучением и также мы он не выделенный потому что мы как раз масштабируемся в данном случае не выделением тут видеокарта или ресурсов дополнительных кластеру А мы просто назначаем на конкретные сервера конкретные таски и в данном случае например на запуске мы запустили SR на всем кластере А когда мы как раз таки нарезали вот эти миллионы видео в сутки мы уже поняли что у нас дневная интенсивность не такая высокая по расшифровке речи и сократили соответственно количество серверов которые обрабатывают видео которые расшифровывает речь видео чтобы отдать это другим чтобы отдать место другим задачам Да ну и мы переиспользуемся здесь механизм очередей трансформацию и задач которые у нас тоже есть подруги видео значит переходим pyline распознавание речи сначала у нас соответственно обработка что же происходит на преподобработке Мы скачиваем видео затем FM бегам мы транслируем его то есть сервисы ample и параллельно микшеремона там в 16 тысяч сэмплрейт 16 тысяч битрейт это формат который у нас соответственно принимает модели машинного обучения Ну и в общем отдаем дальше нашему нативному процессу путь до файла который транслировали Ну и дальше мы будем рассматривать paypline распознавание речи здесь пока на общем плане два момента обращаю внимание то что Да мы все еще естественно обрабатываем не полностью дорожку разбиваем ее на чанке чтобы лучше утилизировать видеокарту Ну и много у нас получается Здесь параллельно Ну ладно два параллельных пути которые тоже можно параллелить и выиграть ресурсы значит первый этап это разбитие дорожки на чанке потому что во-первых модели плохо работает аудио с длинными аудио То есть если начинать отправлять видео отправлять дорожку от минуты там уже скорость распознавания очень сильно падает а ну и если мы добавим pading к нашим чанкам даже если не разного размеров в целом будет лучше утилизация видеокарты дорожки мы Режем не В тупую по 20 секунд мы с помощью Voice Activity detection смотрим если пауза еще 3 секунды Мы ждем паузы если нет уже обрубаем жестко Ну потому что иначе мы можем если резать ровно слово посередине разделить и ничего не распознаем затем эти чанки Мы прогоняем через наш шумодав про который который используется у нас уже в звонках про него была статья на хабре и уже очищенный сигнал от шумов мы Передаем в акустическую модель Да кстати про шумодав Здесь тоже вот мы его добавили по сравнению с голосом и сообщениями потому что в голосовые сообщения мы его пока не добавляем потому что он сильно увеличивает Время всего пайплайна и как раз таки по тем slo которые мы предъявили к скорости доставки расшифровки голосом сообщением пока не позволяет нам внедрить шумодав туда вот но этот очищенный сигнал здесь мы Передаем в акустическую модель на выходе из акустической модели мы получаем матрицу распределения вероятности символов Я чуть Ну именно проговаривает потому что нам пригодится чуть позже когда будем рассматривать проблемы с которыми столкнулись на запуске в данном случае это для каждого шага времени мы получаем распределение вероятностей для символов то есть модель нам говорит с Какой вероятностью символ в конкретный момент времени какой появится ну и затем мы отдаем эту матрицу в лингвистическую модель получаем расшифровку потенциальная модель расставляет знаки препинания А параллельно с ней у нас Onliner сопоставляет речь с текстом и на выходе мы получаем пары временных меток начала и конца слова и самого слова ну и получив эти пары таймс темпов и слов и соответственно знаки пунктуации мы совмещаем все это дело и формируем файл который так что-то залипла который дальше мы Передаем уже в постобработку Итак получив текстовый файл мы генерируем уже субтитры но почему мы не сразу генерим субтитры потому что мы хотим этот текстовый файл Там положить несколько разных мест для целей рекомендации чтобы именно использовать чтобы потом обратно не парсить субтитры а использовать вот эти сырые данные для других задач рекомендации и так далее вот а параллельно именно для целей видео уже дальше на пост обработки мы генерируем файл субтитров и сохраняем их метадату к видео для формат субтитров у нас внутри продуктовой команды на запуске были очень жаркие споры потому что они до сих пор не заканчиваются потому что кто-то считает что нужно в обычном формате их выводить построчно кто-то считает что нужно в других популярных платформах делать по словное появление Ну вот мы решили попробовать сделать послабное появление текста использовали для этого подмножество стандартов webt которая позволяет установить задержку для каждого слова для каждого для каждого фрагмента субтитров А почему мы решили использовать этот стандарт потому что в целом Ну можно было просто свой Паркер какой-то написать потому что у нас по моему Хроме изначально работала как-то уже из коробки в остальных разработчики поддерживали это с нуля Вот это исключительно из-за того что на какой-то платформе уже проще было это встроить Вот если бы этого не было мы бы наверное какой-нибудь попроще формат сделали так Ну и как это в итоге выглядит Ну да то есть послабное появление мы реализовали Ну и немного слов про дипломмент здесь мы не до конца решили наши проблемы получается модели очень тяжелые там весь компонент который мы собираем ZIP архив мы кладем его в некоторые хранилище артефактов Ну и если раскатывать там сотни наших серверов мы Ну вот это узкое место моего В общем придут админы с инцидентом и заберут права продакшн мы такого не хотим поэтому выкладываем там по н-серверов и Ну это может растянуться поскольку Это довольно редкий случай модели обучаются не каждый день мы не каждый день обновляем этот pipline в принципе ну там раз в месяц можно потерпеть Вот но думаем вообще в целом это не для единственного какая-то проблема мы думаем эту систему переделать на то чтобы серверы они раздавали соседям не только шли в хранилище артефактов вот мы переходим к запуску мы запустили наш pipeline Ну и в итоге мы получили какие-то нас на старте приемлемая скорость работы то есть на одном в одном процессе там за секунду работы у нас 50 секунд аудио Мы расшифровываем целились в 100 там Но вот для запуска тестового в принципе мы решили что нормально Вот и на видео тестовых сообществ которые мы выбрали под домен распознавания речи все было отлично Ну и мы решили дальше запустить AB Но оказалось что тестовые сообщества как мы не старались В итоге Мы оказались выбирали их сами и выбирали соответственно такие что где заведомо уже качество распознавания было бы хорошим опять же лекции в случае произвольных видео оказалось что там принципе может быть речи танцы под музыку и так далее а ну и здесь на примере в верхнем на Верхнем слайде там английская речь А на Нижнем там ну ничего просто вот музыка в начале перед рекламой какой-то игры вот ну это еще это еще цензурные примеры вот значит почему Мы же взяли те же голосовые те же модели что были более нейтральные более сдержанные Но на самом деле по качеству примерно такие же как в голосовых сообщениях Почему мы вдруг здесь решили что это плохо потому что голосовое сообщение человек люди отправляют друг друга остается между двумя людьми и расшифровки Но если Ну если что-то не устроило Да можно переслушать в принципе ну никто не побежит типа бегают Ладно но в общем не так не придет человек и прямо удаляете мое сообщение расшифровку потому что вы распознали что-то не то видео если это какой-то бренд если это какой-то публичный ролик и вы туда повесили нецензурную расшифровку это может быть больно и неприятно а вот Ну и что мы с этим сделали Да мы присмотрелись к выходу акустической модели где у нас Матрица распределения вероятности символов на каждом шаге она показывает в каком символе она больше всего уверена ну и если там у нас например на символе а 09 Ну значит скорее всего символ А если там везде по 0 0 1 Ну значит модель не сильно уверена мы решили ну и мы посчитали среднее по этим таймс темпом и получили некоторую метрику уверенности в результате путем отсмотра видео и смотрев на эту метрику мы определили некоторые порог ниже которого мы субтитры пользователи не показываем Ну и бонусом мы померили и поняли что таких дорожек довольно много то есть большая часть видео Это что это какие-то опять же танцы под музыку это может быть там видео с регистраторов Ну и в общем много дорожек которые нам не обязательно распознавать Полностью мы сделали второй порог поскольку Ну вот этот порог мы возможно будем на б тестах там менять Возможно мы еще лучше осмотрим там повысим или понизим но есть еще некоторые порог ниже которого вот сто процентов все плохо и мы решили просто делать ранний выход после акустической модели из пайплайна Ну и таким образом экономим 50 Времени 50 процентов времени на таких плохих дорожках и поскольку таких дороже много мы существенно экономили ресурсы на перенарезке вот вторая проблема с которой мы столкнулись во время тестов это то что у нас выросли одни из ключевых метрик когда пользователь хочет посмотреть видео мы во-первых ему сначала выписываем ссылку потом он посылки идет его проигрывать Ну вот выросла как время получения этой ссылки так и время получения первого кадра после того как клиент захотел его проигрывать вот чтобы понять почему рассмотрим как это происходит клиент опять же идет а в kphp дальше у нас Ну и дальше ссылку запрашивает видеосервис то есть Мы помним он находится в Москве у нас там раунд Trip 12 миллисекунд и но естественно мы сделали какой-то кэш в данном Ну и большинство популярных видео в этот же попадают кэш естественно не для всех общий он там для класса юзеров там по юзера Агенту по не знаю версии приложения и так далее да ну и затем когда он получил ссылку он идет играть видео но он идет не в Москву У нас по всей стране не только на самом деле есть еще в ней России идет ближайшему сидень узлу на котором кэшируется популярное видео вот ну и то же самое либо если оно есть у нас на сиденье играем Сиде налить бы идем в Москву за этим видео Ну и почему же у нас не работает но почему же у нас выросло время оказалось что для обычных видео с субтит видео вернее видео с субтитрами у нас в принципе не было поддержано кэширование субтитров на сиденах и кэширование ссылок на субтитры То есть у нас всегда был здесь раунд трип именно за ссылками на субтитры потому что ссылки на само видео поддерживались вот и ну и здесь у нас всегда был раунд трип чтобы запросить субтитры то есть видео мы все еще пришли на сиденье но там из Красноярска Мы каждый раз ходили в Москву чтобы достать достать субтитры к счастью мы запускали AB не включили это на всех Вот Но почему же вообще так получилось то есть Это же очень сильно мы не досмотрели Почему Потому что во-первых таких видео субтитрами крайне мало Это скорее всего какие-то фильмы которые загружают субтитры специально и там их процент менее 100 процентов точно В общем очень мало этих видео в принципе это не было заметно и как бы но никто даже до этого не знал что это не поддержано но а не было это поддержано сразу потому что для видео получается мы кэшируем и ссылки и ширируем контент именно на Ну когда у нас пользователь гроби грузят копии видео мы используем для дупликацию Мы храним один экземпляр видео ну и соответственно кэшируем Этот один экземпляр и ссылки генерируем на конкретно единую копию ко всем обращениям А субтитры у нас каждому каждое из этих копии они могут быть разными соответственно мы не можем прийти к какому-то одному контенту и оттуда запросить субтитры вот ну и поддержали эту динамическую генерацию ссылок на субтитры то есть конкретно ему экземпляру видео поддержали их кэширование как в кэша ссылок так и на сети на избавились от этих раунд трипов ну и соответственно дальше Поехали хотите B вот текущие цифры у нас примерно такие они меняются в зависимости там от но когда мы запускаем например другие фичи мы немного например можем прикрыть расшифровку расшифровку субтитров Когда у нас ресурсы более свободно мы там до нарезаем старый контент Потому что его бесконечно много ну и сейчас у нас примерно 10 процентов всего контента доступны с автоматическими субтитрами больше на самом деле сильно не прыгнешь потому что опять же большая часть видео не Это не тот домен для распознавания речи то есть там скорее всего не такое качество речи на русском языке чтобы вообще мы могли его распознать то есть опять же танцы под музыку и так далее ну и всего у нас 17 процентов просмотров видео из ленты видео оно автоматическими субтитрами и это на самом деле у нас еще небольшой процент пользователей еще находится в обе без них Вот но я думаю что мы их докрутим вот что у нас дальше мы расширение количество видео наверное здесь скорее улучшение бесконечное качество моделей Перри нарезка этих видео добавление каких-то новых компонентов если они появятся Ну и эксперименты с новыми форматами и также улучшать поиск рекомендации как обычно Вот но и Один из таких новых форматов экспериментов мы запустили Вчера мы открыли Наш наши технологии по распознаванию речи для всех пользователей То есть можно попробовать наши модели интегрировать в свой сервис пока лимиты вот здесь на слайде соответственно можно пользоваться этим моделями мы будем добавлять дальше новые возможности Так ну и выводы во-первых внимательно изучить домен и желательно делегировать это каким-то другим людям не самим когда это отсылка к тому как мы запускали на выбранной категории сообществ тестировались то есть лучше чтобы это было более объективно и отобрано кем-то не предвзятым вот предусмотреть возможность отката в данном случае у нас это были AB тесты и все там под ручками соответственно когда увидели что там время Ну естественно мы когда увидели что растет время ссылок мы там не жили Неделю вроде с этим мы отключили все пофиксили и включили дальше Вот и дальше что решайте проблемы оперативной такой общий подход Потому что если первую наверно по качеству субтитров можно было Заранее предсказать особенно когда мы начали 22 выстрелила проблемы неожиданно Ну и тут как бы нужно опять же наверное сослаться на второй пункт предусматривать возможность отката Вот у меня все спасибо так поднимаем руки можно будет сейчас подискутировать создавать вопросы второй ряд молодой человек поехали есть вопросы с чата Кто смотрит нас трансляции Пишите в чат Да можно сидя на нас немного вроде Спасибо за доклад было очень интересно послушать у меня такой вопрос вывод отбрасываете часть какого-то контента по аудиомодели на лингвистической модели вы не рассматривали которая потом идёт возможность сброса потому что там тоже мусор скорее всего может появляться Там прям по ней мусор сложно отсеять потому что там ну уже словарь то есть там все слова которые в принципе только те которые ожидаются десятки или сотни тысяч каких-то то есть там нет такого как набор бессмысленных букв там осознанные слова по поводу того Как связывать предложение вот это все Ну скорее всего это уже в самой лингвистическом нет мы именно не отсекаем единственное что там происходит после лайне то что там опустил это то что мы там фильтруем если там какой-то для под множество видео если например это какие-то брендовые ролики Ну скорее всего ну или лицензионный контент скорее всего они без мата вот мы нецензурную рексику если здесь выскакивает мы ее фильтруем вот вот в таком ключе Окей спасибо Филипп запоминай лучше вопрос тебе нужно будет потом выбирать так в конце на восьмом ряду в темноте рука так Давайте следующий вопрос будет из чата Да Филипп Здравствуй очень интересный доклад у меня несколько коротких вопросов первый это что вы делаете с мультиязычными видео то есть когда у вас идет русский русский а потом идет фраза на английском например Да у нас здесь несколько подходов Ну мы английскую речь сейчас не распознаем соответственно она распознает там как Speak From My Hard Ну а что мы делаем по конфиденсу мы как раз сейчас в процессе того чтобы перейти от считания это подсчета среднего вот этого конфиденса на большие участки видео то чтобы только чанки учитывать тогда это нам вот позволит эти фрагменты отбрасывать не отбрасывая все дорожки Ага хорошо второй вопрос он связан с версионированием моделей то есть вот у вас есть несколько моделей понятно что на этапе обучения есть какой-то тестирование какие-то там коробка кривые строится еще что-то какие-то метрики оснований которых дата сайт команда принимает решение выкатывать или не выкатывать Но это все делается в рамках тестируемый выборки какого-то теста когда оно выходит на продакшн там уже совсем другие результаты Как вы смотрите вот на метрике Да как вы их учитываете и откатываете ли вы модели были такой случай что вы откатили новую модель да Но именно по поводу качества именно по поводу отката такого пока не было потому что модель в целом не так быстро появляются новые обучать их долго и в целом добиваться хорошего результата тоже сложно по поводу версионирования и того как мы это уже в продакшене смотрим ну здесь на самом деле основное тогда то что происходит до метрики по ДТП вот Единственное пока что было потому что мы Единственный способ это пока то что у нас есть сообщество ВК тестерс много людей которые первыми получать вот на запуске э-э люди просто приносили баки вот так пока такого чтобы когда мы Обновили модель и сравниваем точечно как она на что-то повлияла такого механизма Сейчас нет но какой-то момент когда мы обновляли пунктуацию у нас сильно сильно просело качество но оно было видимым и это в общем-то тоже на тестировании заметили сейчас Да это вопрос тоже пока такой полуоткрытый вопрос для реальных пользователей которые бы давали бы вам фидбэк на основании того что пока не думали мы думаем над возможностями в общем думаем в сторону возможностей кастомизации и участие в пользователей в самом контенте хорошо спасибо Так давайте прочитаю просто с чата Кирилл каулин спрашивает на чем реализован pipeline Air Flow или что-то самописное может подсказать Ну pipline на самом деле у нас это просто сервис там на c++ несколько там файликов которые вокруг вот этих библиотек построены то есть какого-то здесь такого инструмента для того чтобы это пролете нет В общем здесь не стояла задача по максимуму утилизировать все ресурсы сервера потому что у нас здесь десятки задач основная задача это не навредить другим то есть на самом деле а ну если пользователь загрузил большое видео он расстроится сильнее если мы его будем транслировать два дня чем если к нему мы субтитры два дня не навесим самописный пайплайн так И второй вопрос от него Как передаются чанки кавка подобная система или пушить реквестами или какой-то еще решение Ну чанке в смысле в середине патлайна передается Да но у нас что мы скачали видео транспортировали его файловой системе она где-то есть мы его считали в память Ну дальше уже с помощью войск активизиты Action от выбор тисе мы нарезали на чанке Ну и также в памяти мы Передаем моделям никуда не шлем Окей то есть они крутятся в памяти и какого размера примерно чанки ну по 20 секунд они там в размерах смысле в объеме А я деток не скажу сейчас так еще какие-то вопросы зала руки так девушка слева Добрый день спасибо за доклад два небольших вопроса оба касаются интеграции СССР сервиса с кодом видео Вот вы сказали что первый вопрос Вы сказали что решили изолировать полностью SR вот основного кода потому что могут быть какие-то проблемы которые могут положить процесс вот вопрос что это за проблемы и второй вопрос Это правильно Я понимаю что у вас как демон вертится Так ну второй вопрос да да то есть у нас есть ну как бы это не первый такой процесс У нас есть какие-то там обертки траволы которые колбаки вешаешь и общает общаешься с этим процессом Так что Да он там постоянно крутится Ну соответственно если там да по поводу падений но здесь сейчас уже нет какой-то несколько месяцев последних в начале были всякие фолты внутри моделей там приходилось тюнить у нас большой зоопарк там видеокарт голосовые сообщения расшифровываются там на они все одинаковые там все затено под размер например мы часто не пролезали по тому что у нас в внутри моделей временно там аллоцируется память и там падала с каким-нибудь лоямом вот тоже тюнин или параметры здесь какие-то фиксели баги которые нашли здесь Потому что там видео потому что объем данных может быть домен другой Ну в общем несколько месяцев мы постоянно какие-то баги появлялись сикфолты в основном всякие в лесах вот мы их там Дева жили отлавливали Ну и фиксили так слева девушка у меня такой общий вопрос мне просто интересно насколько отличается процесс расшифровки для видео которые Ну являются клипом к песне например да там все-таки речь немного другая особенно если там читать их так скажем вот интересно как это отличается Да это зависит от зависит от В общем от клипа и музыки и жанра действительно если там какой-то вокал и песня Но сложно его распознать Не всегда в общем я то сам могу понять что происходит но с точки зрения например рэп индустрии там 50 на 50 если это ну мы как тогда выбирали тесты сообщества там тоже была музыка какие-то клипы мы то что загрузили здесь у нас плюсы в том что шумодав у нас в работу моделям тем что он эту музыку как-то уменьшает Вот но здесь могу привести пример видео Джигана на Чили распознали практически идеально моргенштерна распознали два слова Ага и ну вот так Так ладно и вопросы с чата какой был критерий успешности об тестирования вот говорил про ошибку чем была Ошибка выбора группы значит про успешность об тестирование то чтобы не проследить метрики метрики сначала до просили пофиксили потом а б у нас там несколько месяцев наверно месяц на небольшой аудитории было дальше увидели что у нас автоматически про красном метрик и мы видим если там что-то ушло в Красное и все плохо вот такого не было какие-то там сильно приросты тоже ключевых тоже не было Вот а фича полезная поэтому дальше уже попотели на больше аудиторию ссылки как ссылка критериев там десятки Ну это одни из ключевых которые выросли То есть это могут быть падение просмотров в Ленте падение взаимодействия окей ладно так наверное еще один вопрос Мы успеем молодой человек третий ряд слева и Филипп Выбирай лучший вопрос вспоминай что задавали да спасибо за доклад Меня зовут Марк хотел спросить вот вы говорили про раскатку 10 Гб модели А что вы рассматриваете вот раскатку модели То есть это все вместе в ад спичечный текст там языковая модель левый раскатываете по очереди и если по очереди то как проверять не мы собираем единый компонент то есть весь пайп line в один бинарь здесь на самом деле не было смысла делить это прям отдельно потому что там 70% всего пайплайн на это акустическая модель Вот то есть остальные там как бы ну Ради них в общем не было смысла делить поэтому если вот что-то около семи гигабайт весит акустическая модель вот поэтому все единым компонентом Ну и Да здесь у нас пока такой незакрытый вопрос вместе да ну у нас опять же нет такого что каждую неделю выкатывается новой модели сейчас вот например у нас из потенциально обновлений пунктуационный модель новая ну такого чтобы вот прям Весь pipeline нужно было обновлять такой очень один вот раз было на запуске потом через какое-то время когда мы там все фиксили вот"
}