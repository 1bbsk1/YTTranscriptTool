{
  "video_id": "9Ud52PbYeeQ",
  "channel": "HighLoadChannel",
  "title": "Построение крупных кластеров Tarantool из 100+ узлов / Ярослав Дынников (Tarantool)",
  "views": 1074,
  "duration": 2423,
  "published": "2020-04-14T11:24:32-07:00",
  "text": "меня зовут ярослав я из mail.ru представляю команду тарантул сегодня хочу поделиться с вами историей развития одну из одного из аспектов нашего продукта про то как мы учили тарантул собираться в кастера как тренировались его artistry ровать для начала поднимите руку кому нужно объяснить что такое тарантул я удивлен всего пара рук тарантул это applications сервера база данных в одном флаконе это значит что вы в одном процессе можете аль вас один процесс и транзакции обслуживает и вы можете бизнес-логику свое какой-то дополнительный писать это применяется в самых разных сценариях иногда как быстрая база как быстро кэш пары храним ок иногда наоборот чисто как плетей шин сервер почти не используя возможности базы у меня например дома telegram.bot на таран то ли написан там базы нет только при кишил сервер у нас команда не перед не перестает расти сейчас нас чуть меньше восьмидесяти человек большая часть из которых это программисты и условно всех можно разделить на два больших лагеря это ребята которые пишут развивают тарантул как продукт пишут ядро и команда решение которое разрабатывает коммерческие проекты на основе вот этого окна снова решения мы тесно взаимодействуем и стараемся чтобы в нашем продукте было поменьше багов а еще нам очень важно чтобы разработка на tarantul явилась максимально быстро потому что так мы можем быстрее реализовывать проекты давайте посмотрим на набор инструментов которые у нас есть наличие ну и самый основной из них понятное дело это тарантул у него много fitch количество их постоянно увеличивается туда уже и эскивель завезли и функциональными индексами в последней версии можно пользоваться и мы как команда решение на его основе строим замки в облаках но каким был быстрым и классным тарантул не был нам все равно одного железного сервера никогда не бывает достаточно поэтому постоянно встает вопрос а масштабирования но мы можем также запустить два сервера но тогда непонятно а что между ними и как организовать связь чтобы они работали сообща для этого в tarantul и уже достаточно давно существует у подсосный модуль в шорт который позволяет сделать базу данных распределен это не первая попытка реализовать sharding до этого по-моему было еще две не очень удачный нот в шорт получился то что надо он работает по принципу виртуальных макетов то есть все данные сгруппированы по виртуальным ведерком разложены по серверам ибо киты могут переезжать атомарная за счет чего достигается отказоустойчивость ну и относительная простота эксплуатации по сравнению с ришар деньгам когда вам все данные надо везде перевозить и тем не менее в шорт не всемогущ у него есть ряд особенностей его первых дело вода в удобстве вы shard как и все у нас стороны ли управляется при помощи ло при помощи ложных таблиц конфигурации и давайте я покажу пример простой как это может работать вот с таким конфигом мы можем заставить ваш арт разложить нам данные на два сервера рядышком поднять роутер роутер будет знать какие данные где лежат и сможет правильно направлять запросы ведерок вот этих пакетов их достаточно много их в сотни раз должно быть больше чем серверов которых у вас когда-либо будет поэтому они получаются относительно маленькие в них мало данных они их можно быстро перевести каждый ведерко можно быстро перевести с одного сервера на другой и вот представьте себе ситуацию что данные нас лежали лежали и в какой-то момент нам стало тесно нам понадобился 3 сервер чтобы это осуществить нам нужно отредактировать ту конфигурацию которую я показывал добавить у нее еще один пункт pad 3 рипли кассет запустить этот новый сервер но на этом этапе не роутер не предыдущие 2 стороны еще не знают о его появлении поэтому ничего интересного не происходит он просто есть а данных на нем нету чтобы данные на нем появились и запросы стали работать как положено мы берем ту же самую конфигурацию и применяем по очереди к старым стражам и к раутеру и вот тогда задумка осуществлена роутер раздает рыба lancer отправляет часть данных на 3 сервер у нас опять достаточно простора роутер тоже уже по трем сервером запросы разруливает мы все хорошо но я рассказываю эту историю неспроста с ней со мной в прошлом году произошла забавная ситуация я делал здесь же на хэллоу диме то показывал прототип нашей системы и достаточно быстро все рассказала меня коллега коллега сказал типа что ты не знаешь чем время занять покажи как это делается руками в итоге пока я проделывал вот эти все три простые операции у меня нашло на это полчаса я допустил около сотни ошибок раз десять в ранил условный прост и все оказалось но не очень хорошо поэтому понятно что вручную такие вещи делать не стоит так что так что мы пробовали разные варианты как вы шар дом управлять и ну относительно стандартный the man sibl и в принципе все хорошо с основной задачей управления конфигурации эти инструменты справляются но у нас есть ряд хотелок дополнительных которые вносят накладные расходы во первых мы не хотим простое поэтому конфигурацию нам надо применять на лету так что никакой речи не идет о том чтобы погасить контейнер и поднять с новой конфигурации так делать нельзя у нас будет простой во-вторых в шорт ничего не говорит как скином следить за бизнес логикой в шорт это только про хранилища как нам распределить код разных наших маленьких сервисов по кластеру непонятно ну и в конце концов разработка нового проекта никогда не начинается с диплом первых этапах нам более важно какую логику проект будет реализовывать какая там бизнес логика и вот проект с которого все это зарождалась упрощенно можно описать следующим образом у нас должен был быть а петли твой который проводит первичную обработку данных из разных источников как ты их там ну обрабатывает складывает сторож а рядышком стоит еще один компонент scheduler который раз в сутки условно говоря ходят в базу и строит по ним какой-то агрегированный отчет когда мы начали это проектировать первое значит что здесь стоит дорисовать это то что не битвой не scheduler напрямую в базу не ходят у нас есть ваш art is the раджей самом деле не один а много поэтому битвы будет общаться напрямую столько с роутером наша dollar тоже во вторых на этой схеме не со не хватает понимание как это все в действительности ляжет на тарантул поэтому мы берем и дорисовываем небольшие группы мы ведь не хотим чтобы у нас были лишние сетевые походы и и гей твою в роутер по сети хотите ходить не нужны они должны быть запущены в одном процессе это именно то ради чего роутер создан это роутер должен в сторож писать и ходить поэтому получается вот примерно три разных компонента так относительно разных которые реализуют по крайней мере раздую бизнес-логику и дальше мы думаем а как же все это запустить потестить что с этим делать мы могли бы упаковать это в 3 разных контейнера на весь спектр кампус и в принципе по минимуму этого хватило бы но тут встаёт ещё один вопрос а как все это дело тестировать мы очень щепетильно к тестам относимся все соседи поэтому если мы при собачьим тесты поверх такой системы получится что мы не можем тестироваться без докер комп оуза нам нужен докер в docker и это просто лишние сложности если мы предел запускаем эти сервисы самостоятельно средствами тестового фреймворка то во-первых мы остаемся без тестирования разных топологии непонятно как топологий все равно остается сложной но дипломы уже не тестируем как бы лишние потери а может там что то пойдет не так хотелось бы видеть ситуацию немного по-другому в шорт он в принципе нас не заставляет запускать много разных роутер и сторож отдельно их можно запустить локально внутри одного процесса и они тоже будут работать и по крайней мере для тестов нам этого хватит роли тоже как отдельные влажные модули можно все упаковать вместе и вот хотелось бы иметь одну большую кнопку сделать все хорошо которая запустит на тарантул в необходимой нам конфигурации топологии мы прогоним тесты локально это будет как эта маленькая инсталляция когда речь пойдет о deploy на пруд мы уже разнесем все сервисы в зависимости от а по от них возможности поднимем столько сторожей сколько нам нужно и будем пользоваться масштабирование системой мы начали делать прототип у нас получилась такая еще одна конфигурация которая должна быть одинаковая на всех сторонах ради того чтобы избавиться вот от этой мороки с раскладывании конфига по всем ишгардом и мы решили что тарантул сам будет следить за топологий за конфигурацией и сам будет применять ее везде чтобы она не разъехалась не потерялась мы решили пользоваться двухфазным коми там в принципе все инструменты у нас есть applications сервер мы можем быстренько написать двухфазный commit и все будет хорошо но не тут то было первое с чем мы столкнулись эта известная проблема что было раньше потому что у нас есть втором туре бинарный протокол и мы собирались ну что им воспользоваться зайти на сервер там по вызывать какие-то функции и тем самым применить конфигурацию но проблема в том что бинарный протокол является частью базы и транзакций репликации через него работают и до того как мы сервер сконфигурировали пользоваться им фактически нельзя встает вопрос как зайти на сервер чтобы его сконфигурировать который еще не сконфигурирован стандартный способ решить эту проблему разорвать порочный круг и этим механизмом стал протокол внутреннего мониторинга swim про который лад расскажет в этой же аудитории через час подробно я лишь общую концепцию расскажу swim это один из протоколов семейства go типов которые распространяют слухи он работает по идее от базы ничего не требуют поэтому мы можем его спокойно инициализировать до бокс f и g и пользоваться им для своих нужд принцип работы у него основан на том что когда в сети появляется какое-то событие то на восклицательным знаком отмечено больше протоколы рассылают его не сразу всем чтобы снизить нагрузку каждый момент времени отсылают одному каком-нибудь случайном у коллеги так что в первый момент времени он управляет одному потом два рассказывают 4 и осведомленность возрастает эпидемический в общем все узнают об этом событии в среднем за логарифм от количество узлов сети ну и сеть этот протокол грузит не слишком сильно а у каждого инстанса вообще нагрузка константной ему 1 секунду нужно принять один пакет от рандомного коллеги и отправить один пакет событиями в этой истории являются как информация о том жив instance мертв кто стал недоступен за счет чего мы можем внутренний мониторинг реализовать и помимо и прочего у инстансов есть полезная нагрузка которой который они могут распространять так что изменения мы можем хранить там любую информацию небольшом количестве и membership сан распространяет ее гарантированном что со временем эту информацию знают все члены кластера и вот со спец с использованием этого внутреннего мониторинга получилось следующая схема мы решили проблему курицы и яйца решить за счет полинга и схема такая у нас есть кластер но тут 3 ниточки нарисована условно trining солнце и мы хотим подключить сюда 4 вот 3 уже сконфигурированы от 4 пока только мебельщик принято лидировал они как бы поведи пит друг о друге уже знают но на новый приконнектиться пока нельзя это новый начинает узнает о существовании уже готового работающего кластера и начинает болеть с него конфиг в надежде что рано или поздно его добавит в конфигурацию и он сможет узнать с кем ему реплицироваться какой вид у него должен быть другие настройки узнать кластером наш тем позволяет пользователю выбрать но зайти на любой из инстансов управлять можно через любой они все одинаковые и один из них выбирается главным и двухфазными входным кометам накатывает конфигурацию в которую включает этого нового коллегу сначала делается как обычно в двухфазном кормите pp-r все проверяют что конфигурация валидная что тот instance которым мы собираемся добавить действительно живой что это не ошибка никакая но когда все получилось хорошо конфигурация к месяца и при следующем поле нге новый instance видит что его добавили он это понимает в углу и может уже вызвать боксов а г а вместе с ним и поднять тисе пи порт ну и после этого настраивается репликация дальше втором туре все становится относительно просто структура кластер а ну как я уже сказал состоит из отдельных инстансов которые объединены в репликации он ее группы аппликационная группы это механизму чисто тарантулов ский это репликация которая держит все данные внутри рипли кассеты одинаковыми и помимо топологии в конфигурации кластера мы используем такой важный параметр как лидер который но обычно это тот instance на которой происходит запись но на самом деле это может быть не так у нас могут быть последнее время появилось много ситуаций когда с мастер мастер репликации мы можем писать схема данных нам позволяет писать на любой мы не боимся в конфликтов репликации конфликтов данных но некоторые операции все равно необходимо делать только на одном инстансе например создавать space и для этого флажок и существует а еще благодаря membership он благодаря своим протоколу и внутреннему мониторингу мы можем относительно легко организовать failover если вдруг 1 инстанции выходит из строя протокол семьям об этом сообщает и мы можем и тот instance который был запасным может принять решение и забрать корону на себя тем самым спасая нагрузку на запись изначально в том проекте о котором я говорил все вот эти маленькие кусочки бизнес-логике и все модули были жестко зашиты и мы не пользовались ну как как встроенными но в какой то момент мы поняли что эти ложные модули могут стать хорошей точки расширения и в последующих версиях выделили отдельная api для написания сторонних ролей вопию нота на здесь выписано есть функция и нет которая вызывается первый раз либо при старте инстанса либо при включении этой роли если раньше этой роли воинственности не было запущено а также мы решили что двухфазный комет и общая конфигурация могут быть полезны и для хранения каких-то маленьких бизнес конфигов поэтому также позволили ролям использовать этот распределенный конфиг чтобы это реализовать роли реализуют калби кивали дейтон feed.ly play конфиг который вызывается на стадии при п р и к мид и тем самым могут отслеживать изменения и свою бизнес-логику завязывать дополнительно вот на этот конфиг который гарантированно везде одинаковый эта вещь по которой я рассказываю мы выложили в сентябре в open source под кодовым названием тарантул картридж это фреймворк который позволяет проще строить распределенной сервисы не особо задумываясь о инфраструктурных вопросах и больше внимания уделять бизнес-логики нежели решать проблемы с конфигурацией ваш орда мы с вами им активно пользуемся и со временем у нас понятное дело начали возникать проблемы мы первое с чем мы столкнулись это мы попробовали строить достаточно большие кластером и внезапно оказалось что это не так то просто проблема здесь следующее вот упрощённая схема того что уже было двухфазный commit добавляет нам в кластер еще один сервер сервер делает бокс ф а г инициализируется мы можем добавить следующий потом еще один так по одному это мысли у нас кластер маленький из 10 узлов то все относительно хорошо но когда мы пытаемся собрать кластер на 100 узлов чтобы добавить 100 нам нужно сделать 99 пример коммитов 99 стадии при п р убедиться что все согласны принять конфигурацию 99 раз закомитить потом дождаться пока новый винс эту конфигурацию спалит и дождаться пока все не поедет и не спеша со логарифм н друг друга про пингует пока все узнают что этот новый instance конфигурацию накатил такой алгоритм оказался сильно ограничена в масштабировании поэтому мы стали искать варианты решения 1 1 часть проблемы которую было решить проще касается полинга нет наоборот 2 pro pulling a 1 про предже него не и по одному в этом если посудить нет никакого смысла и ничего казалось бы не мешает нам одним двухфазным кометам при j нить все новые 99 серверов и пусть они спорят этот конфликт инициализируется дальше но тут проблема возникает немножечко другая двухфазный коммент мы накатили а дальше они пытаются сделать бокс ff параллельно когда мы говорим про разные сервера независимые все нормально но если пара электронки серверов принадлежат к 0 к одному рипли кассету то им необходимо они начинают конфликтовать пытаются определить кто же из них должен быть мастером кто из них должен первым поднять tcp порт и так далее проблему в целом становится похожей на ту которая была про курицу яйцо но только уже более локально вот самый яркий пример можно проиллюстрировать вот таким простым примером мы накатываем конфигурацию указываем что у нас в реплика сети будут два инстанция 33 0102 и тарантулы должны общаться используя username и пароль но сам юзер и гранты для того чтобы это было возможно даются уже после поэтому возникает конфликт рейс спасло нас то что все эти нюансы были аккуратно обработаны в коре тарантула и в принципе тарантул позволяет такое проворачивать сам разумно делает ретро и когда необходимо но богов пришлось пофиксить немало с от 99 двухфазных комментов мы избавились и сборка кластера стало достаточно быстрой с уже этим алгоритмом у нас получилось собрать сначала 100 инстансов кластер потом 500 в принципе 1-фазный комет проходит достаточно быстро мы потом membership тоже некоторое время паппинга вал друг друга информацию распространил из-за полминутки все узнали что кластер живой это все получилось но остается вторая проблема про неэффективный полинг он мало того что неэффективен он влечёт за собой ещё одну более фундаментальную проблему потому что мы не можем правильно обрабатывать ошибки если вдруг на этапе присоединение новой инстанция этапе конфигурации что-то пойдет не так как оказалось эта ситуация достаточно частая чаще всего вызванная пользовательскими ошибками и в такие моменты обычно хочется видеть достаточно явное сообщение что и где и почему не так там где-то памяти слишком много выделили пару терабайт у нас на серваке столько нету в это другие опечатки leport оказался занят и вот такие проблемы с полингом из мембершипы никак не отследить чтобы ну и проблему приходится решать как-то по-другому мы еще когда делали этот парень задумывались об альтернативах например нам в принципе ничто не мешало поднять еще какой-нибудь теперь сервер рядышком или даже х ттп и для инициализации пользоваться им но эти варианты тоже не оказались удобными потому что нам приходится следить за еще одним себе пор там как-то прокидывать информацию какой именно tcp порт используется для конфигурации какой для базы если мы их пытаемся скрещивать то у нас получается что в разные моменты времени на одном порту слушают два разных протокола и все это неудобно решение оказалось достаточно нестандартным мы просто взяли и реализовали бинарный протокол тарантула без с ограничениями без возможности пользоваться базой протокол точно такой же там есть внутри две части одна связана с базы другая связанная с вызовом лова функций и в принципе ничего не мешает вызывать ложные функции до того как база инициализирована то есть select и мы делать все еще не можем но нам и не нужно зато можем на том же порту поднять тот же самый пример на сервер который ходит тот же самый таран пыльный клиент и до поры до времени ну и этого достаточно чтобы накатить конфигурацию на практике это выглядит примерно так что мы поднимаем вот этот вот урезанную версию протокола на том же самом порту а с другого сервера делаем и вал который останавливает этот сервер и выполняет бокс сафага и еще одна интересная особенность здесь в том что мы можем остановить и себе сервер который леся нет но при этом старые соединения которые у нас уже была подключена остается все еще доступным мы можем по нему общаться и смотреть насколько успешным был a top box тпг который должен был собой заменить урезанную версию протокола этот кусочек алгоритма тоже скоро появится в мастере картриджа и он обещает быть намного проще с точки зрения отслеживания ошибок отслеживания статуса и состояния кластера и на этом мы также надеемся стабильность улучшить ну а на этом я вот хочу еще делиться ссылками на сам framework и на эту презентацию и если у вас есть вопросы буду рад на них ответить здравствуйте спасибо за доклад было интересно послушать мне вот интересный вопрос а вы не пробовали применять какие-то уже существующие методы регистрации например чистку bernie this взять какой-то купер нить из оператор или делать это через свой через тоже какой-то koston по сути дела это все выглядит как кастомно стройка над тарантулом которая встроена в сам же тарантул как бы мы делаем вещи которые обеспечивает надежность тарантула но базируемся на основе надежности тарантула что спасибо за вопрос мы пробовали несомненно у нас есть каберне this оператор про не у вас вчера рассказывал у нас есть шансы был роль которая работает с картриджем и мотивация здесь никак и стечение обстоятельств в том что без вот этой лишний прослойки управлять тарантулом напрямую было достаточно сложно потому что слишком много логики приходится пихать в кубе оператор ему необходимо знать о деталях реализации ваш ардан о том как применить конфигурацию к раутеру и это из кубера делать не очень хорошо получалось на тот момент это был не кубера это были звуки пир и docker и тем не менее а вот с возможностью управления в шар дом заизолировать в лишним слоя все получилось достаточно хорошо и кубер операторы ansi был роль сейчас нормально регистрирует уже картриджем то есть часть ответственности на себя берет картридж а часть действительно мы продолжаем пользоваться имеющимися инструментами и ну вторая часть вопроса поводу надежности как бы вся вот эта вот магия делается для того чтобы обеспечить надежность гигантского кластера горели простоту эксплуатации сохранив надежность но как сохранить надежность если хотя бы даже с точки зрения надежности теории надежности вы инструмент обеспечение надежности вставляете в саму вещь и надежность который вы меняетесь обеспечить мы защищаемся в первую очередь от пользовательских ошибок здесь которые достаточно часто поэтому упрощаю эксплуатацию мы обеспечиваем надежность вот в этом месте от падения серверов и так далее мы продолжаем пользоваться теми инструментами которые встроены в тарантулы здесь картридж почти ничего нового не привносит он просто упрощает ручные операции которую до этого надо было делать полчаса на этапе понял спасибо ярослав спасибо за доклад в целом за картридж вопрос такой вы рассказали что можно на одном таран дулин senso крутить несколько ролей неизвестно там потоков немного всего три как происходит переключение между этими ролями и какое best practice чтобы какие роли лучше совмещать какие лучше растаскивать переключения происходят стандартными to randomly механизмами это кооперативная задач ность это нами всеми любимые файбер и которые работают по очереди значит пока один работает остальные ждут когда этот сердился отдал управление либо на какую то системную блокировку захотел сходить в сеть начинают работать остальные что касается рекомендаций и best practices то тут все очень зависит от того что именно а та или иная роль делает если представить себе простейший случай с роутером стер из торы джим то обычно вешают несколько сторожей по необходимости под хранилище значит по тот размер оперативы которую вас есть роутера навешивают масштабирует о необходимости в зависимости от того какая у вас нагрузка на запись на select и здравствуйте спасибо за доклад на подскажите пожалуйста какой то вы сейчас упомянули про фейдеры а с точки зрения вот потоков операционной системы какое-то время назад тарантул был однопоточный для того чтобы утилизировать не знаю средний цепова и сервер там 48 яйца нужно приличное количество этих тарантулов этот сервер посадить а если взять большой класс ну не знаю там 10 минут десять серверов то как этим управлять тарантул едет куда то куда едут его конкуренты с точки зрения автоматической автоматической балансировки автоматических чтобы она стала дешевле и легче это два разных вопроса на про файбер и ваш вопрос действительно ли он все еще однопоточный условно условно говоря да ну там есть три труда и разделение на сеть wow транзакционный но грубо говоря да действительно он до сих пор ложный код выполняется в одном потоке масштабироваться и занимать разные ядра может быть нужно в зависимости от того какой у вас профили нагрузки и что у вас является battle ником если у вас ботаник в диске то там масштабируйте не масштабируется подсыпку несколько тарантулов ситуацию не спасут но если проблема в циpкa в условно говоря в роутерах то там да это все еще эффективно вешать несколько роутеров грубо говоря там десяток роутеров на 3 сторож я больше имел ввиду тарантул как базу данных они как applications сервер и если взять среднюю типичный сервер там за 10 15 тысяч долларов там с большим количеством ядер с большим количеством дисков вот не знаю то что сейчас называют камолетти харви то с точки зрения пирей шанс жизнь превращается в ад ну не вода но эксплуатировать тарантул достаточно сложно потому что этот сервер нужно несколько инстансов тарантулы посадить нужно сделать так чтобы каким-то образом вот этих лишь ардов до при выходе сервера из строя реплики находились все таки на разных серверах они на одном и вот что с этим делать и мы картридж появился не случайно мы тоже ходили по этим граблям испытывали эту боль тоже реализовывали достаточно большие проекты поэтому мы делаем все что можем чтобы это упростить и тестируем на своей шкуре вот картридж оказался достаточно удачным с точки зрения упрощения эксплуатации есть ли еще у кого то вопросы если вопросов нет выберите который вам понравился больше всех пожалуй это будет андрей с его провокационным вопросом зачем действительно вопрос хороший спасибо за ваш вопрос и также он давайте поблагодарим спикера за его прекрасный доклад"
}