{
  "video_id": "OxSycvSoy1I",
  "channel": "HighLoadChannel",
  "title": "MPP СУБД на примере Vertica: архитектура и способы достижения производительности / А. Скоробогатов",
  "views": 1523,
  "duration": 2785,
  "published": "2022-03-21T12:55:00-07:00",
  "text": "давайте попробуем поговорить проверьте q что это такое и какие за последние годы были сделаны улучшения и усовершенствования которые позволили улучшить производительность в двух словах если кто-то не сталкивался что такое vertica это огромные и экстремальное быстро и хранилище с sql доступом мы поддерживаем полностью ansys коваль 99 стандарт доступ и джитибиси воде бесси драйвера все хорошо и мы стопроцентно колон ночная база данных почему архитектуры база данных vertica это массивно параллельная архитектура и в принципе шарят нас шарик на значит каждый узел обслуживает свой набор данных и все они действует как единый кластер кроме этого внутри базы данных реализовано большое количество аналитических функций сейчас это больше 150-ти функций этой машины обучение и работа с временными рядами огромное количество математики которые мы принесли к данным то есть нет необходимости перегонять данные туда-сюда теперь данные остаются в базе и все математику весь анализ мы принесли на кластер база данных что в принципе даёт нам практически неограниченные возможности мы знаем душ нас есть заказчики с 12 петабайт ими данных в продукте we с онлайн ответами 12000 терабайт по моему прекрасно и vertica это там полностью программное обеспечение разворачивается практически на любых инфраструктурах начиная от то он прям и там обычных x 8 штук серверов с внутренними дисками до модных ныне кубер нетесов облаков и виртуальных сред с маркетингом закончили давайте теперь немножко все-таки в технику в то что будет интересно и понятно я думаю инженером это-то зачем вы сюда пришли во первых как я уже говорил исторические верьте как развивалась как массивно параллельная архитектура соответственно множество вычислительных узлов на каждом есть свой набор данных и верьте к позволяет обрабатывать эти данные распределена потом собирать результаты получать клиенту полностью результат анализа этот режим у нас называется интерфейс мод он до сих пор в ходу множество инсталляций который до сих пор это эксплуатирует и действительно даже в в этом режиме мы видим много терабайтный инсталляции а в россии у нас есть уже и петабайт на инсталляция в таком варианте что сделано с точки зрения доступности и надежности хранения каждый узел сети хранит на себе свою часть информации и плюс информацию которая зарезервированного для друга это прямо так называется body набор данных который позволяет случае выхода из строя узла продолжить исполнение запросов исполнения транзакций без остановки без ошибок то есть мы понятно то что какому-то узлу придется сделать двойную работу за себя из-за того за своего друга но тем не менее это встроенный механизм который позволяет продолжать работу даже в случае отказа от одного из узлов а иногда даже и большего количества узлов и восстановление в этом случае это принесли ноду обратно включили вставили в кластер и она из существующих реплик собрала свой набор данных мы сделали копию для соседа которую как которого она будет дублировать случае если все пошло не так и тем самым мы обеспечиваем фоне восстановления кластер и продолжения работы как только данные закачались на восстановленную ноду она включается в работу и это может происходить даже когда не полный набор данных восстановился данной какой-то таблицы полностью восстановились на этом на этом узле и уже можно работать восстанавливать все это прекрасно все так здорово работает но глядя на то как в облаках реализована и надежное хранилище мы видим то что в том же амазоне который был для нас первым облаком в которой мы принесли нашу базу данных есть amazon s3 хранилище объектные с уровнем надежности то ли 12 ребята кто ли 15 девяток но об этом можно только мечтать это значит то что мы можем разделить уровень надежного хранения и вычисления в таком случае каждый узел подписывается на шар данных и непосредственно занимается вычислением надо над этим шар дом данных но надежное хранение делегировано объектном у хранилищу что происходит ну естественно там каждый узел подписан на свой шарф данных и плюс он подписан на shorts своего соседа если тот погибнет в общем чуть чудес не бывает если один вдох нет сосед его также из общего хранилища подтягивает разогревает кэш для этого сорта и продолжает исполнение запросов то же самое логика работы не меняется даже запросы не прерываются они продолжают работать это все работает быстро но восстановление дан узла в этом случае это всего лишь заменили узел включили в кластер он сделал подписку с на свой шорт выкатил разогрел свой кэш и или depo storage и опять поехал в работу вот shard который находится в кэше + подписка на вторичный шар для своего друга если кто-то выйдет из строя мы называем depot хранилище общее хранилище разделяемые мы называем коммунальным хранилищем дословная калька но есть общее хранилище и тогда скорость исполнения кэш на узлах нацелен на поддержку именно скорость исполнения о надежности хранения и обеспечения нерушимости набора база данных делегируется внешнему хранилищу там в часто с протоколом s3 но также мы поддерживаем эти хранилища и он принес уже есть инсталляции который позволяет там использовать там тоже менее или этом пью старую не проблема это все работает не только в облаках но и на площадках заказчика если мы говорим про то как же такой кластер расширять понятно то что рано или поздно мы приходим к ситуации когда данные растут данные растут сейчас просто катастрофически то есть это даже не линейный рост данных и так специальный розданных и ценность анализа заключается в том чем больше данных вы сможете использовать в анализы в едином тем более ценное знание вы получите и это круто и если мы говорим про классические наш фонарь и развертывание то здесь масштабирование это необходимо по новый порезать те сегменты данных которые находятся на узлах после чего сделать три балансировку да это работает это работает в бэкграунде но это немножко нагружает сеть тем не менее это действительно рабочий вариант можно делать там из нфл это не является каким-то грань чаями это что здесь сделано там из 36 это про просто показано можно сделать из 3 4 из 35 и стрип 10-15 все что будет если мы говорим про второй сценарий и который и он называется вот здесь масштабирование но просто элементарные добавили новые узлы новые узлы перри подписались на новый шарды узлы которые перестают обрабатывать шарды они просто и от них отписываются соответственно новые узлы разогревают свой кэш и это начинает работать если мы говорим про растущую нагрузку мы можем просто докинуть в кластер узлов и несколько узлов будут подписаны на одни и те же шарды верте к сможет договорить эти узлы которые подписаны на одни и те же шахты и сделать аналитику над разными сегментами внутри шортов тогда нагрузку полностью определиться но что более ценно что чаще бывает нагрузки бывают разные и разные нагрузки часто конкурируют за кэш и начинается процесс вымывания каша здесь персики был реализован механизм формирование суп кластеров су кластера входит в общий кластер работают надо единым коммунальным хранилищем но нагрузка от разных клиентов идут именно в разные в разные кластера не таким образом нагрузка одного типа не вымывает кэш который необходим для обработки нагрузки 2 типа это прикольно это работает и что самое приятное можно внутри еще этих суток мастеров делать ресурс направление которое позволит разделить транзакции по ресурсным полом и тем самым еще более гарна лярна более точно сделать управление нагрузкой все это все это работает это опять же позволяет ускорять ускорять за счет чего вымывание каша убираем это значит то что печатные узлы всегда работают над тем набором данных который есть у них в в ближнем в быстром хранилище и тем самым нет необходимости держать очень большие каши для того чтобы и то и другое в одном каши совмещать более того суд кластером могут быть совершенно разные с точки зрения объемов ресурсов то есть если например там 1 со пластик будет огромный на физических машинах по 2 с у ps3 slim это какая-то частная задача которой рассчитывается раз в полгода и и можно все сделать динамическим подняли он разогрел своих ешь и посчитал сделал этом помнить мы с шумом и сложную отчетность через две недели через три недели его похоронили при этом оба кластер всегда работают над одним набором данных то есть если в один кластер вливаются данные это второй знает о том что эти данные там работают и здесь здесь есть несколько проблем с которыми мы сталкиваемся и которые нам необходимо решать для того чтобы это действительно было эффективно быстро и здорово во-первых необходимо обеспечить быстрый запуск суп бластера для того чтобы мы могли делать реально динамические инфраструктуры динамические в смысле там запуска суп мастеров по расписанию подтягивать их фризить или кибернетики на диске для того чтобы все это было быстро я отвечала вызовом бизнеса второе должна быть обеспечена консистентной с внутри кластера между с у кастерами потому что plaster это не просто какой-то отдельный кластер который работает над каким-то snapshot of он всегда работает над единым набором данных которые есть у базы данных здесь поддерживается и должна поддерживаться традиционная целостность потому что иначе это не база данных иначе нет смысла в такой базе данных если все это начинает рассыпаться и естественно то что все узлы должны понимать с какой с какой базы данных что находится в базе данных для того чтобы работа над одним отбор набором данных и в этом смысле нам необходимо постоянно обновлять эту информацию о сторож контейнерах между узлами с уползти раме внутри кластера это информация должна быть консистентной всегда это позволит обрабатывать данные но при этом когда мы говорим про консистентной да мы не забываем то что нам необходимо обеспечить в том числе и высокую степень изоляции между суп мастерами это и изменение топологии кластера это и изоляция нагрузок и про то что я говорил включая там тонкую нагрузку тонкую тюнинг нагрузки внутри суп пластина для того чтобы управлять разными суп бластерами разным способом потому что разные нагрузки приходят на них ну и если мы говорим про управляемость то нам нужно поддерживать хорошую предсказуемую подписку узлов на данные для того чтобы администратор понимал что у него происходит в базе данных это также позволит упростить работу фонового процесса тупо мура который занимается объединением контейнеров между собой верьте к всегда пишет файл с данными только один раз и в этом смысле мы достаточно интересный мне кажется уникальная база данных который позволяет работать с данными их объединять она интерпретирует все контейнеры в виде единой базы данных но при этом мы никогда не делаем апдейт уже записанного блока данных у нас нету этот геморрой с очищением контейнеров это этого просто нет едем дальше поговорим про запуск суд plaster и есть две части каталога который необходимо синхронизировать и перераспределить внутри кластера при изменении топологии есть первое это глобальная не разделяемая часть каталога который мы вынуждены полностью расшарить и держать синхронном состояние на всех узлах кластеров для того чтобы они понимали какие узлы есть в кластер и какие данные с какими данными работы и вторая часть она там зависимости от структуры баз данных может быть больше может быть меньше это разделяемая сортированная часть каталога которые связано уже непосредственно с подпиской на шарды данных из коммунального хранилище и одна из задач которая стояла стояла перед нами за последний год это увеличить скорость включение суп кластеров в plaster так как включение ясу постеров это задача требующий глобальной блокировки глобальная блокировка на кластере она блокирует не только изменен топологии но на блокирует и комет она блокирует процесс тупому игра на это достаточно болезненная блокировка и в качестве примера например надо в кластер скинуть 100 дополнительных узлов 20 из них поднялись очень быстро и 80 отстают возникает вопрос что делать впитываем сразу 20 который уже готовый а потом дотягиваем оставшиеся восемь и вот решая эту задачу мы поняли то что лучше сделать все разово решить эту задачу разово это будет единое распределение копий данных если дождаться полностью готовности всех узлов это будет подписка за одну транзакцию и это будет минимальный набор глобальных блокировок то есть это на самом деле выгодно и это эффективно то есть изменение топологии более важно делать согласовано нежели визуальной скорость там какие-то частных серверов виртуальных машин под чего угодно на самом деле это проблема который с который так часто можно столкнуться в виртуальных инфраструктурах и в области хэм структурах когда машинки проверить правильность и с разной скоростью вот и тогда логика работы получается дождаться чтобы все узлы были готовы передать каталог баз данных дожидаемся конца стен дасти и делаем подписку всех узлов новых узлов на своей данные это реально сокращает количество блокировок и более эффективно использует транспорт данных да зачем нужно поддерживать у кластеру синхронизованы во первых это нужно для того чтобы нам поддерживать традиционную целостность с одной стороны с другой стороны если мы поддерживаем кластера синхронными мы это делаем тоже традиционно и самого чтобы это было эффективно как сделать на самом деле глобальной блокировки возникает как на операциях изменен топологии так и на операциях изменения схема так и на операциях тот того же камень падает увидит упал мудр это значит то что нам нужно сократить и минимизировать время владения или время вы поддержание блокировки глобальной блокировки ну и улучшить время доставки данных внутри кластеров как это было сделано исторически как это работает сейчас и куда мы движемся есть такая прекрасная технология который называется спрэд фактически это система гарантированного гарантированно доставка управляющих сообщений мы рецензированию встроили в состав персики она базирована на и vdp и формируют кольцо управляющих узлов talkin' ходит по кругу каждый узел гарантированно иметь доступ к доступу и тем самым мы управляем передачи управляющих сообщений но в том числе и и ясен хрен синхронизацию каталога беда в том что когда узел становится там больше 50 100 узлов узел кластер и становится огромным когда количество узлов растет то кольцо вытягивается чем чем длиннее кольцо тем дольше так он ходит по кругу но чудес не бывает и в этом смысле мы придумали используют двухуровневый способ передачи данных когда у нас есть только управляющие узлы для суб кластеров они торчат в общем кольце данные мы дальше передаем на второй уровень с этих управляющих узлов работает эффективно быстро позволяет сократить на порядок количество управляющих узлов это здорово это это замечательно но есть в том числе и свои недостатки из плюсов такой архитектуры то что управляющий узел позволяет не выносить на общее кольцо тот трафик который специфичен для исполнения там тех или иных запросов внутри суп кластер там это пример 1 например там простейший запрос там агрегации выборка она позволяет взаимодействие только внутри суп бластера это хорошо мы никуда наружу не вытаскиваем никакие данные если мы говорим про другой пример например commit который требует кроме исполнения операции внутри этого со plaster перед передачу данных для синхронизации другими stampa мастерами вот тогда через эти дистанционный вызова dist колы они будут через общее кольцо переданы в остальные суп кластеров для того чтобы зафиксировать изменений в остальных кластерах но в этом же крика строит в этом же есть и проблема с которой нам пришлось бороться бороться каком смысле то что во-первых спред это виде be best part акул он все брака барт кастит узлы которые не участвуют в информационном обмене которые которые не предназначены эти пакеты они вынуждены дропать эти пакеты и при больших интенсивных внутренних обменов данными спред начинает забивать разбиваться перри насыщается трафиком ему становится плохо и плюс ну смысле там еще одна как это копеечка в копилку это не она сама вот и еще один большой минус спрэды он однопоточный это значит то что если поток сообщений большой он просто упрется производительность единого потока и ему станет плохо отсюда появится задержки в передаче данных появятся новые блокировки ничего хорошего из этого не выходит и начиная с прошлого года в составе версии мы сделали новый продукт новый сервис для передачи данных и назвали его transfer service удивительно правда вот этот проект уже уже идёт он уже используется в текущей версии и начиная с версии выбранным пам пам пам пам пам весенний эльдар февральской он уже идет в продукте vi он основан на тисе пи . . протокол он гарантирует последовать передачи данных и что самое приятное нет подкастов нет токенах нет брат костов и прямое взаимодействие между участниками взаимодействия лучше утилизируется сеть но при этом можно реализовать программный multicast то есть сделать группу дистрибьюции управляющего трафика и как начиная как я уже сказал февральской версии мы используем этот сервис для передачи кота блога внутри базы данных для синхронизации каталога внутри база данных и в этом смысле мы максимально загрузили сетевое взаимодействие на этапе в том числе старты и синхронизации каталога как это работало со спредом и диск сми фактически внутри сопла стерилизатор собирал результаты со всех участников исполнения запроса после чего через пред транслировало их объединенный пакет на все узлы все узлы приемники принимали полный пакет и дальше принимать применяли только ту часть этого пакета которые предназначены и если почитать пример то есть например каждый из исполнителей генерит кусок гигабайт 2 гигабайта приходит на in сатар он добавляет свой гигабайт и отправляет это 6 этим сам 6 потребителем то есть 6 на 3 18 + 2 + 2 получается 20 20 гигабайт трафика сгенерирован для того чтобы поддерживать поддержать консистентной как работает новый сервис транспортировки данных он просто берет и каждый исполнитель транслирует изменение в подписчиков того же шар да чё то есть каждый станет гигабайта и отсылает дом подписчикам то есть и итоговый трафик получается 6 веков 6 год 20 гигов получается реально быстрее и этим летом проводили тесты красненьким это старый способ доставки изменения каталога ну естественно это там на достаточно большом кластере сделано зелененьким это результат работы transfer service то есть 5-6 раз только на схеме изменения трансляции каталога внутри кластера мы выигрываем это в том числе и время удержания блокировок то есть это реально это сервисной операция которая позволяет работать быстрее казалось бы тяжелая тема про глобальные блокировку каталога сколько раз а сегодня про это уже говорил давайте поговорим еще пищу что такое global catalog уловка эксклюзив по большому счету это тип блокировки который останавливает исполнение всех запросов изменяющих данные он не блокирует аналитику select и и тому подобное он блокирует все изменяющие операции это и определение схемы и это дыма и лики которые там ставки удаления все что угодно это и внутренние процессы тут уговора блокирует все все эти операции и это значит то что если таких блокировок много и они долго удерживаются это будет влиять на производительность кластер а там простейший способ нам необходимо выполнить транзакцию т3 для этого нужно получить глобальную блокировку каталога есть единая глобальная очередь блокировок которые не даёт сделать блок инициатор всегда ждет когда все узлы подтвердят то что да мы готовы обслуживать эту блокировку то есть эта транзакция будет висеть все это хорошо в теории но на практике бывает всякое первый узел сказал то что да я готов едем 2 из-за там внутренних проблем и будь то диске или там какие-то проблемы в операционной системе не можем перейти к выполнением 30 транзакций выдать подтверждения то что готов исполняет блокировку а третий узел отрапортовал но данные потерялись из самой проблемной сети или они просто еще не пришли к узлу in сатурн и вот тут начинаются проблемы если усложнить то бывает ещё хуже да когда эти блокировки начинают накапливаться в качестве снежного кома когда одна еще не выполнилось блокировку нам нужно уже следующий раз тут очереди блокировка время на получение этих блокировок и с этим нужно что-то делать и наши инженеры подумали и решили то что клёво давайте будем оптимистичной если в верте ки как у я уже говорил там мы пишем данные один раз и дальше только их читаем то по большому счету рубик или там откат да это вопрос для нас бесплатный то просто удалить новый файл который мы только что создали давайте будем ходить оптимистичны мы делаем работу потом делаем запрос блокировки только на время финальных проверок этих финальных проверок для того чтобы подтвердить то что до эту работу можно закомитить прошли проверки к мите мне прошли бесплатные рубок круто если мы делаем там большую ставку делаем commit все тоже самое делаем ставку фиксируем все это файлах дальше просим блокировку и на основе этой внутри этой блокировки делаем только при чеки у нас все сходится мы просто подтверждаем если у нас не совсем сходится то мы делаем аборт аборт равно rollback это бесплатной операции для нас то есть принципе для нас это проще но временно которое мы удерживаем глобальном будто на блокировку она сокращается на время при чеков дополнительных чеков это очень быстро по сравнению со временем исполнением непосредственно исполнение запросов из хорошего что мы видели до там с чем мы боролись у заказчиков возникали длинные очереди на получение таких глобальных каталогов и иногда даже возникали тайм-аут и естественно с таким жить в праге тяжело это напрямую влияет на производительность производительность всего решения в целом да и на бизнес естественно влияет начали взбираться что могло быть причиной это и там могли быть проблемы носите которые приводили к задержкам передачи данных большое количество мельчайших мерчанта пиратов операции которые возникали при большим количеством малых ставок вот и мы видели то что бывает такое что при больших изменений при больших загрузках при насыщается сеть и это тоже приводило к росту очередей сделали эксперимент девяносто шесть узлов и в таком супер кластере стали грузить в огромном количестве данные увидели действительно то что максимум ожидания глобальной блокировки в таком тесте составил 30 минут 30 минут таймаут на ожидание этой блокировки среднее средние ожидании такой покровке в этом тесте составил 6 минут беда решили попробовать все то же самое но с оптимистичным подходом к работе с блокировками то что я рассказывал там сначала делаем работу потом запрашиваем блокировку работаем в рамках этой блокировки только финальные чеки после чего если все хорошо к видимся подтверждаем ся если плохо то рубик который у нас бесплатный и чем у нас получилось получилась интересная штука то что максимальное время ожидания блокировки на этом тесте при таком оптимистичном подходе сократилась 30 минут с отваривании по таймауту в некоторых случаях до 50 секунд практически на порядок если мы говорим про среднее время ожидания блокировки упала 6 минут до 5 секунд тем самым мы увеличили пропускную способность загрузки данных с 500 до 6000 операций по моему это очень неплохо сделали много но вопрос который наверное в глазах у каждого кто сидит в этом зале вот с этим если есть crack house 10 в этом еще время до буквально немножко пробегусь на самом деле house обалденная система это без сарказма она нишевой она предназначена для работы с конкретной задачи с одной большой таблицы и все все все что в ней построена она построена на максимальную производительность нацелены на работу с этой большой таблицы фактов естественно есть проблемы с это не проблемы это это та стратегии которые используют treehouse для работы с джой нами с таблицами один лишний вот это ходжой то есть для вторичной таблицы делается хэш и дальше по правой таблицы пробегается по умолчанию размер этой хэш-таблицы не ограничен если попытаться сделать joins большой таблицы и есть шансы получить огромные кэш этой таблице и а ведь может закончиться удивительно но все join и в кли хаусе делаются в оперативной памяти в этом смысле один большой join может похоронить всю систему вот и после чего еще и отвалится есть у память потом еще отвалится в этом смысле там персики реализовано бюджетное управление ресурсами когда на каждый из запросов выделяется бюджет операционной памяти и если его не хватает то запрос может стелиться приятно то что слайдах им штриха пирует не это не сарказм это это нормально потому что это вопрос который меня всегда задают сколько я работаю версии с всегда там клевую вас система почему не дальше сортирование crack house это фактически множество баз данных которые между собой сортируются на чуть более высоком уровне и делалась из трибьют от таблица которая по сути и за ним и знает ту логику которая позволяет разделить данные между узлами есть там стратегия который говорит то что мы всегда читаем случайную логику и всех и читаем подрал подробную роботу round robin у по кругу не начинаем до ближайшей которые окажется доступной вот не всегда это случайная реплика будет ближний всяко бывает вот ну и там чтение определения доступности осуществляется в процессе чтения то есть vertica в этом смысле там сортирует она понимает где какие шарды есть всегда выбирает локальный и всегда понимает какие из шаров доступны в этом смысле нам хорошо беда с которой приходится мириться когда работаем с клик хорусом это отсутствие транзакционных ти и со временем реплики могут содержать немного разные данные это цитата их из документации то есть в принципе действительно если мы работаем с экстримом и нам нужно сделать очень быстро примерную аналитику это хорошо даже если там будет небольшие расхождения ничего страшного но если потребуется решить задачу связанную с деньгами не один бухгалтер с этим не согласиться вот в этом смысле конечно vertica весит complaint база данных и с этим мы все хорошо ну и с обновлением в плит хаусе все не очень хорошо есть alter апдейт и alter дэвид который именно сделано через altro для того чтобы показать то что это достаточно тяжелой операции вот и они сделаны не очень хорошо там нет точно-точно удаления то есть там все равно даже этот alter он будет сначала делать поиск потом удалять операция достаточно тяжелый именно поэтому мы и говорим то что в отсутствии транзакций и сложности с об до этой дэвид грин хауз он направлен на такой большой поток одинаково структурированных данных и работать с этим потоком аналитика в этом смысле в нем не такая полноценная как той же версии когда у нас там 150 аналитических функций вот теперь один слайдик как узнать как попробовать вертик у то есть нас есть там и бесплатной версии которые можно попробовать есть документации доступные в онлайне и на самом деле в начале октября будет русский вебинар на русском языке по новый фильм where we're текке я приглашаю вот евгения в принципе закончил хочется спасибо как как минимум поблагодарить за внимание и хочет услышать вопросы спасибо большое саше друзья для наших онлайн и зритили я напоминаю что не забывайте пользоваться возможностью задавать вопросы у нас по традиции сасш вам сейчас по придется проявить силу воли выбрать лучшие вопросы зала и подарить книгу за лучший вопрос коллеги у кого вопросы зале книга лучший подарок середине зовут александр спасибо за доклад у меня вопрос очень простой мне кажется и он практически вы сравнили с крик хаоса но я все ждал в конце какого-то подведения итогов все-таки есть еще другие базы дар от шифтом snowflake пиквери все вот эти ускорения на единицы затраченных средств бизнесом они где ставят вашу базу то есть приказ по-прежнему эффективнее и быстрее или там раньше вот в этом сравнении на это единицы затраченных 1 доллар до как смотрите если мы говорим с тем же клик хаусом там и очень неплохо так же как и там с ходу пойми всякими инсталляции мы очень неплохо живем вместе это значит что мы получаем синергию от того что кто то делает там первичным буферизацию подготовку данных для нас а дальше всю наличку делает верочка это это здорово это прекрасно так же как и hadoop может быть использован там холодным хранилищем вот но исторически там если мы говорим про рэп шит по big вере это не очень актуально для россии это эти самые 152 и тому подобные сразу начинается и трансграничные передачи и обработки данных вот для небольшие стартапов это это неплохо вот для россии облака но это такая история скорее на попробовать на по моделировать а дальше все равно к себе в норку и поехали но то есть вы не сравнивали нему сразу сравним конечно и мы там в штатах и в европе и очень часто мы конкурируем с этими вещами с биг верим и сравнивались у нас получается то что на сравним их на сравнимым железе мы даем большую производительность вот сосновых лайком есть беда snowflake перепродаёт через себя ресурсы облачного провайдера вот он моментально надувает с ресурсами если мы нужно выполнить какой-то тяжелый запрос и это не прогнозируемые с точки зрения заказчика потребителя клиента вот заказчик просто можно через некотрое время просто очень удивится получив итоговый счет вот в этом смысле там например есть vertica есть в том же амазоне google claude и она более предсказуемо с точки зрения исполнения времени исполнения и затраченных денег на инфраструктуру которую она использует а так как этом если мы говорим про vertica из-за сервис там с платформы то что называется берти как zerator который полностью счас из амазона буквально сентябре мы начинаем это делать то мы действуем по принципу что мы не не являемся перед продавцом виртуальных ресурсов облака мы мы работаем внутри выделенного сегмента клиентского в писе слушай sage вот из онлайна там похожий вопрос нам поступает в чат а чем vertica отличается в твоих глазах а тапочек на интеле грибе и отличается тем что мы хотим получить в результате если мы хотим заниматься у нас есть шаловливые ручки которым просто интересно сделать это до на продуктах apache можно сделать например на ту же функциональность но это займёт время и это потом потребует очень высокой квалификации специалист которые это будет поддерживать если мы говорим про верочку поставили как обычный промышленные продукты она сразу работают сразу приносит деньги спасибо еще вопросы вот на первом ряду потом туда здравствуйте алексей cooking компании нас пока большое спасибо будет очень стройный доклад все вопросы которые на самом деле возникали уже были отвечены поэтому такой короткий вопрос человека поворотами а в контейнер зация умеете купер да буквально с августа этого года у нас есть пудреница оператор для верте ки которые тепло и отвертку skylab скилл down поддерживает в чем он может тебя в сосать вашу существующую версию все это поддерживается и более того этот оператор доступен на гитхабе он open source его можно скачивать смотреть как он работает и дальше дополнять спасибо предлагаю вечером после всех докладов устроить primator холивар тех кто затаскивает базы данных куберы тех кто не затаскивает базу данных прошу следующий вопрос александр спасибо за доклад можете привести реальной эскизы с примерами использования вертите да легко возможно вы слышали такой небольшой компании авито наш петабайт ный заказчик в россии самом деле это крупнейшее крупнейший инсталляции верте кино российском рынке и восточную европу то есть россия и снг восточная европа вот кроме этого там практически если вы пользуетесь новым бизнесами практически все они классические являются наши нашими клиентами uber facebook одно время подкладывал контекстную рекламу пока они пристани сделали через вертик у вот и очень часто на самом деле игровые игровые компании которые зарабатывают егрп и хотят поддерживать интерес клиентов к своей игре тоже самое все это делается в онлайне почему там на петабайтах данных о какой сетки идеальные из кейс тогда с вашей точки зрения против конкурентов когда мы выбираем вертик у они что я если нужно аналитика реального времени или там предикативной аналитика на больших объемов это наверное идеальной you space ну и ну и естественно это модернизация существующего хранилище к данному там вырастает самом деле верить кучу но куда подходит и там сказать то что там только сюда нет мы видим то что заказчики делают огромный успех спектр систем и это user 360 это сама потом управление фруктом управление праве действием фродо множество класс систем который реализуется но это уже там бизнес реализация которые используют наш инструмент спасибо коллеги последний вопрос наверное зала я prime понимаешь что если у нас надо больше копий то у нас будет больше приятелей на каждом узлов еще раз для хранилища для того чтобы переживать выпадение сразу двух узлов можно больше копиями правильно прекрасно да был удивительный звонок буквально этой весной когда мне позвонил заказчику знаете александр у нас тут слегла виртуальная инфраструктура и из 9 узлов в арктике скончались 4 а почему она дальше продолжим жить я не буду показывать пальцем на ком это были мы это не я назвал на самом деле внутри вертите гарантированно отказ одного узла но кроме этого можно настроить вот эти вот группировку друзей body таким образом чтобы они попали в разные fall домены вот и тем самым можно сделать действительно так что там потери целой стойки из пластика не будет останавливающим фактором при этом даже запросам при всем при этом нет вольфович то есть один узел много друзей может быть 123 они съесть конфигурации когда у одного узла будет один друг едва больше двух нет смысла вот но архитектурный есть возможность собрать full домена который позволит там переживать большее количество отказов но тут уже"
}