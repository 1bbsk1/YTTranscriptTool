{
  "video_id": "5g6NAKzTKTs",
  "channel": "HighLoadChannel",
  "title": "Prometheus как time series database / Тимур Нурутдинов (Lamoda)",
  "views": 10059,
  "duration": 2770,
  "published": "2018-08-16T04:36:03-07:00",
  "text": "пожалуйста давайте поприветствуем поаплодируем окей коллеги добрый день меня зовут тимур я работаю в компании ламода немножко расскажу о том чем компания занимается чем я там занимаюсь но для начала не вопрос скажите кто уже использовать прометей вообще хоть каком-то виде в продакшене знает что это курагой все знают хорошо тогда я работал в компании ламода немножко пройти в ла моде и вообще право моду судака ламода это один из самых крупных и конвертов в россии или в снг некоторых странах с точки зрения идти у нас очень много систем написано 60 на самом деле уже наверное больше очень много людей большой эти став и в общем примет ее мы тоже используем используем для мониторинга в классическом виде наши микро сервисы сервисы счастливая кучу кучу данных вот и собственно мы там смотри по ним графике но сегодня мы поговорим еще об одной маленькой дочке который мы решили попробовать решить с помощью примет ее что у нас получилось окей начать немножко про то кто я и чем занимаюсь в лом 1 у нас есть такая одна из продуктовых команд который занимается мобильными приложениями на всех платформах телефоны таблеточки этом часы это и проходите пожалуйста это значит и iphone и android и соответственно 40 коп продуктовой команды есть full stack начинает бэг-энда фронтенда заканчивай fontaine дамку a product owner и аналитиками и так далее вот я тимлид команды бэкенда для мобильных приложений мобильного скажем так мобильных платформ окей значит как понятно у нас надеюсь понятные схемы что у нас бизнес находится составе нашей команды и мой бизнес активно коммуницируем и бизнес часто приходят и говорят хочу вот такую штучку давайте быстренько сделаем что-нибудь ключевое слово быстренько мы делаем проверим что она работает а дальше будем это либо развивать люди закопаем в один из таких приходов бизнес пришел и сказал что вот хочу такую вот маленькую бляшку с циферкой на нашей странице нашего продукта крупнее чуть-чуть да что это за циферка такая надпись хакер описано на даче на бляшке описано что купили этот товар там 8 человек на этой неделе окей таких вариантов различных цифрах бизнес придут предложил много не только купили посмотрели что-то еще сделали возможные комбинация вот и соответственно сказал как давайте быстренько проверим этот каком такие себя дальше будем развивать хорошо давайте проверим давайте какие-то минимальные требования к эта задача сформируем ну мы сформировали их вот так что мы хотим как хранить какие-то исторические данные там до месяца о фактах события например произошедшего события например товара посмотрели купили добавили в корзину что-то еще сделали ну это то что мы хотим в момент в каком-то времени посчитать агрегатные функции например сумму за прошедший период за 7 дней окей теперь следующее развитие этой темы мы решили надо бы визуализировать что было более понятно и наглядно для нас самих уже с точки зрения там больше данных или инжиниринга визуализировали как-то так это пойму line вниз время сверху события средства вот есть две точки ты 1 t2 в каждой из них мы хотим получить сумму ивентов по какому-то типу за предыдущий предыдущие семьи или один день или вообще любые произвольные товаров которые нам захочет бизнес стоит отметить что здесь есть два важных элемента это время и это факт события ну или чисел k это очень похоже на то что называется time series совсем необязательно думаю что это все вьетнам мы посчитали что это там селиться нам нам грамм кажется это выглядит очень натурально для этой задачи вообще вот для такого разложения окей там service time series давайте положим это в базу данных time series все будет должно быть все хорошо сходим в интернет и посмотрим какие у нас есть общий вариант идем в интернет и там оказывается большой большой ворох всего что называется time series первую очередь на глаза попадаются нам попались сразу 3 варианта горилла influx и примет примите мы сразу вспомнили ага у нас есть примет их продакшене отлично наверное это поможет например быстренько заставьте запустится проверить теорию и сказать что все хорошо все работает или ничего не работать со плохо но начали все-таки пришли посмотреть на некоторые из этих вариантов в том числе на гориллу сейчас объясню почему и новинку в тоже объясню почему в двух словах почему на гориллу посмотрели ну во первых потому что надо сразу понравится и и пейпер про вообще time series кому интересно посмотреть очень хардкор на нам этот интерес написано что можно делать так как вообще хранить time series и как их много много собирать упаковывать и потом с этим работать но там есть много нюансов в том что во первых горилла использует некоторые говорить на сжатие при этом предоставляет в пользователю заставляет пользователю распаковывать мы должны знать как данные упакованы то что потом их распаковать от не очень удобно + h bass который использует как хранилище долгих данных это тоже не очень удобно для нас потому что это новая технология которую нужно изучать и потратить чуть больше времени чем нам хотелось бы поэтому мы вариантов ставили себе на заметку как концептуальные но пошли дальше дальше influx сын все просто у нас компании был опыт работы с инфу сам негативный к сожалению мне не удалось расковырять каких-то более подробность больше подробностей от моих коллег узнать об их коллег что же было не так но общий смысл такой что инструкции начинал при нашли нагрузки не справлялся на запись его очередь записи вставала и соответственно он перестал принимать данные возможность была старая версия influx а не знаю плюс кластеризация у него еще какая цель и масштабируемость него платная что тоже очень хорошо но и тренер сам не пошел посмотрел на его внутреннее устройство интересно там есть ссылочка очень интересно но достаточно сложно требует времени для изучения для понимания того как это крутить-вертеть unity так далее поэтому influx мы тоже отмели ну и третий вариант понятно дело проветрить почему потому что есть нас production уже запущен уже работает уже собирает миллион метрик в 1с нас там с каждые 15 секунд все огонь все кажется что все хорошо это был достаточно очевидный выбор потому что опять таки повторюсь скорость запуска надо сложно хорошо давайте на этом наш такой предварительный минимальный анализ хоть какое-то был закончен и мы решили погрузиться в дальше в мир time series вообще-то как устроен прометей почему сейчас будем про это говорить во-первых давайте с точки зрения вспомнишь такой time серию с точки зрения данных так маленькое отступление это 2 чисел ки time spent плюс целью которые образуют так называемый сэмпл вырезом . измерения неважно of time series дата это вот такой набор таких сэм бликов во времени в котором например время монотонно возрастает окей теперь давайте про параметре какие же вопросы встают в пример какие вопросы перед нами встали когда мы начали работать памяти и мы засовывать наши данные туда во первых вопросов про то какие у нас данные и товар знание того какие у вас данные сложно оперировать базы данных вообще понимать что будет происходить ну немножко про наши данные буквально два слова мы посчитали у нас есть аналитической системы в которой работает долго-долго шуршит и потом в дает нам некоторую информацию от наших данных вот вы посчитали что количество событий которые нам нужно сложить нашу базу данных это 50 в 500 миллионов в месяц примерно с потенциалом роста ответственно как мы наши данные представляем для себя это некоторый продукта и de plus eventtype это соответственно ключ по которым будут храниться наш time series большая длинная ok next а как теперь наши данные смоделировать в терминах прометея для этого нужно немножко понять что в параметре себя представляет метрика и как примет с этим работает давайте немножко потом поговорим метрика в прометея это такая простая штука у него весь метрик нем есть лейбл вылью и лейблы внимание был в илью с этим скажем так с этой строкой будем так говорить ассоциирован некоторые таймс темп и некоторые вылью это может быть интернетом уровень флотом что угодно естественно как мы себе видим ну точно также наши данные так вот ложатся это продукт айди плюс в качестве лейбл мимо используется type в качестве лейбл целью используется некоторые винт ну и дальше там таймс темп целью ну например на нужно 500 тысяч таких ключей по нашим подсчетам исходя из того объем ивентов которые мы получили окей тут исключения так страшно это похоже на продаж на нагрузку давайте дальше про метрику на самом деле в прометею дальнейшем чуть поподробнее про метрику метрика переписывается вот в таком виде то есть на самом деле все там есть лейбл и просто вот такой вот набор у лейблов ассоциирован ставим с темпом из вылью ничего сложного окей тут мы вроде разобрались следующий вопрос уже интереснее когда мы приходим к нашим замечательным демопсы говорим ребята мы тут решили поставить базу вообще нужны какие-то ресурсы мы не задают нам некоторые каверзные вопросы которые не очень приятны вот этому на которые нужно ответить иначе вам скажет мнение ну без этого мы не можем вам дать ничего ответить на пожалуйста вот на такие вопросы тут уже сложнее потому что это уже приводит тому что нужно разбираться как прометея работает внутри и мы начали это делать чтобы ответить на эти вопросы ну в первую очередь про диск для того чтоб понять какой диск нам нужно добавить как прометей структурирует у себя эти данные как он и записывать на диск как он с ним работает давайте немножко про это поговорим значит про структурирование у прометея вот такая вот метрика такая строчка про который я говорю или пары лейбл вылью лейбл name себя представляют собственно саму метрику они каким-то образом сортируют от не берется хэш кажется фнб дальше относительно этого хранится вот такой вот в ближайшем приближение простой массив вот этих вот сэмплов таймс темп плюс валюта м ст м плюс белье каждые метрика пишется в отдельный файл если вас миллион метрику вас миллион файлов на диске ну кажется это должно приводить в ужас потому что миллион файлов метрики нужно собирать часто такие пары писать часто и кажется что в этом случае какой-нибудь винительный диск у нас очень быстро на гнется во все мы-то помним про скорость позиционирование его там про 20 миллисекунд всё такое и мы не успеем писать такие пары быстро но ребята из памяти из картин собственный такой рамеш чувак я рубинштейн который сказал что вы конечно можете поставить ssd но он сломается мы проверяли поверьте нам вот эти ребята действительно могли проверить поэтому они сделали следующие они стали организовывать группировать такие пары в чанки даже вытянешь кипень мишка нет чем ты мишек что из себя представляет значит сэмплы time steam + вылью чанг это некоторый набор таких вот сэмплов при этом чанг имеет фиксированный размер нас в один килобайт соответственно в файл мы пишем не каждую пару а вот такими танками по 1 и по одному килобайт ну и только если прикинуть 16 байт на 1 кило быть там в общем очень много очень много пар влезает в этот чарам к соответственно писать нужно вроде как не очень часто отсюда мы сделали такой вывод что нам в общем без разницы какой диск там ставить ssd или шпиндельный потому что мы вроде как работаем уже у нас есть уже инстанса которые работают с таким объемом данных на шпиндельных диск все хорошо поэтому мы обмену честно сказали кстати к выходить ok следующий вопрос следующий вопрос который встает это сколько ж нам нужно диска для этого нам нужно понять как наши данные хранятся на диске вообще состав чан когда помимо вот этих пар вот кажется что это всего можно просто умножить количество event-ов на 16 байт и мы получим примерный объем данных которые нам нужно сохранить ну мы так сделали там примерно почитали 8 гигабайт вроде все хорошо но решили по уточнять у прометея нет ли у него вверх и да а может быть можно и меньше начали изучать состав чанка и общака промытый работает с данными но оказалось что савченко очень простой 5 байт оверхеды на чанг это заголовок а дальше хранятся выстоим был чуть позже станет понятно что это такое и просто time вылетаем в alltime вылетаем были вроде бы все пока просто но кроме то есть такая штука как encoding это уже становится интересно потому что и мы помним мы в своей команде помним о том что мы читали про компрессию time сервисы web и перед фейсбук и нам стало уже интересно может быть прометея занимает наши данный буду занимать меньше места на диске мы стали изучать encoding ну вот поскольку есть очевидно что такое encoding в терминах прометея помочь видно какой класс значит давайте об этом немножко поговорим значит предположим что во первых мы хотим сначала поговорить про то как сжимать таймс темпы это самый простой вариант потому что не всегда монотонно возрастают правда в памяти и есть эванс что они смели секундной точностью но ok давайте посмотрим на пример чеку берем три таймс темпа который монотонно возрастает интервал сбору статистики или метрики у нас 15 секунд но в силу возможных там различные функции он может варьировать от 14 до 16 там плюс-минус 1 вариант который предлагает прометея просто дельта что делает сохраняется первое значение миллион соответственно дальше сохраняются разницы текущие минус b из текущей минус bass и сохраняется только эта дельта в чем плюс в том что мы можем сохранить это в более например в двух байте когда они там не в 8 или в 4 бантиках плюс он сохраняется возможность случайного позиционирования внутри чанка то есть мы можем как-то случайно попасть на турчанка в любую точку в чанки там будет дельта мы знаем bass целью все посчитала все хорошо но ребята заметили давно уже заметили только эти ребята что на самом деле можно сделать еще лучше можно сохранять базовое значение можно сохранять первую дельту а дальше можно сохранить давал дельты что это значит вот смотрите там есть 29 и 1529 минус 15 14 14 минус 15 минус 1 ну вот мы сохраняем некоторые такие девицы и как бы добыл дельте и на самом деле мы все может уместиться в один бантик и это работает по умолчанию прометея эта кодировка компрессии можно назвать версия 1 так называемые теперь про значение ну значение на самом деле поехала значение точно также комплексы кодируется давай такое слово то берем как таймс темп но есть нюанс если у вас константное значение то есть если у вас есть некоторые величина который не меняется во времени всегда единичка всегда там пятерка то сохраняется только первое значение а дальше ничего дальше ребята говорят что достаточно только таймс темпа и это похоже на правду к сожалению на начальном показал все это наш случай потому что у нас всегда будут единички почти всегда будут единички в качестве значений и мы сильно обрадовались сейчас чуть позже расскажу как и случился файл ну собственно вот эти вернуться к схеме чанка это получается так бысто mbs вылью дельта time дельта вылью дальше дабл дельта да будет сначала про то как мы проверяли эту теорию что она работает ну и до 3 3 байта для сэмпла это в среднем тату компрессию которую обещают ребята из квартир они направляли на своих серверах мы проверили на своих серверах это правда работает 500.000 монеток один вашингтон сам в 500 тысяч метрик каждые 15 секунд до 50 дней ну так если прикинуть вроде бы там 2 терабайта но у нас это 490 гигабайт ну и собственно очень похоже на те самые три три байта на один сэмпл 34 но в чем случился файл нашей текущей задаче мы не учли тот факт что у нас данные нерегулярные то есть нас может быть эвен случится сейчас и через два часа в параметре есть такая штука как и да они если чанг не получает данные в течение часа него просто закрывают сохраняют ups и это мы выяснили уже к сожалению после того как нам дали тачку под прометеем и начать заливать до данные но к счастью все подумали три раза мы посчитали на русском показалось у нас будет 8 гигабайт мы умножили на 2 сказали админ 220 они подумали что инженерного рот умножили на 20 на 2 и долина и у них кучу с 50 а потом пойдем еще раз умножить на два и получил столь в итоге нам дали 100 гигабайт дисков все счастливы но на практике к сейчас наши данные где-то 25 26 гигабайт и это хорошо вопрос как нам это оптимизирует того что в реальности мы там должны лежать в 10 вот такая история окей это pro v1 дальше есть еще компрессия в 2 супер интересно но мы ее не используем в продакшн я все же вам про нее расскажу она мне очень нравится компрессии v2 для таймс темпа это те же самые дабл дельты только теперь они кодируются в переменное количество бит если у вас дабл дельта влезает например вот в интервал - 3231 то там два первых бить и к префикс дальше 6 быть значения ну почему так много на самом деле то что милисекундные точности там в общем чуть больше надо чем при секундной точность ну и фенечка если ваши давал дельта 0 то в принципе вам ничего не надо кроме 7 бит для счетчика повторений но это прямо идеальные данные которые наверняка встречаются в особенности на секунду точность и еще про илью тут все очень интересно а давайте прям по по пунктикам пробежимся быстренько самый первый ноль байт для постоянных значений но это тоже самое констант в илью если значение не меняется со временем сохраняется к первое значение дальше она не записывается дальше если дабл дельта это целые тут очень корректная написано но в принципе если это целое число то есть если параметры понимает что в качестве в ли у вас целая они флот он это сохраняет в некоторые такие же чанки переменной длины девчонки отрезать и там несколько бит всем 613 сколько там что-то сейчас не помню следующий пункт это если это не целое а это если это флот то прометей пытается сделать к ссор с большим шансом если у вас величина даже float но при этом разница между соседнюю величинами маленькая после ссор у вас получится какая-то маленькая там маленькая величина или вы можете записать как последовательность бит как маленькую вещь ну и прометей пытается записать ее именно такой маленький но если после скоро опять получили все 64 бита то записываем как есть когда это нужно в два давайте про то немножко что это дает это дает по уверениям ребят из картин 128 байт в среднем на каждую сэмпл что в общем на самом деле очень хорошо вот ну пока мы это не проверяли в продакшене но верим ребятам опять таки из картины саундклауде которые проверяют на своих серверах когда я вам это будет полезно если у вас ну прям очень много данных а читайте в их предка вам не жалко циpкa надо кодирования например вы легко можете поставить в 2 получить очень хороший компрессию и получить малом маленький объем на диске как-то так соответственно в про посылочки можно почитать на самом деле когда лучше использовать отвар бетон кодинг ну собственно про диск мы поговорили поняли что это нам в общем неважно какой диск как договор как уже было сказано договорились до 100 гигабайт все хватает чего хватает всем теперь проповедь но с памятью в первую очередь мы хотели что все наши данные вылезали впарить исходя из нашего первичной оценки 8 гигабайт мы опять-таки умножили на 2 и сказали но давайте 15 вот ну да там с математикой какой округленный математик соответственно но при этом мы все таки решили посмотреть как прометея работает с танками дальше то есть как он их держит в памяти как он их скидывать на диск потому что очевидно to my heart кэширование что-то еще не спать скоро будет финал да вот теперь немножко про чанки но тут все очень просто да у нас есть series хэш у нас есть то самых и shot наши нашего ключа относительно него ассоциирован массив чанков он какой-то отличительная особенность в том что они все кроме одного и мутабельные их нельзя модифицировать модифицирует столько 1 чанг которые записываются новые данные дальше они каким-то образом пока каким-то образом синхронизируется с диском что важно понимать важно понимать что у примете есть такая опция как в пробку и льда всем и кто использует знает этот язык запросов как он работает вот с точки зрения диск память когда пробку el'pride вопросов приходят и он понимает что каких-то чанков ему не хватает они лежат на диске в памяти их нет он начинает высасывать из дисков память соответственно если у вас большой запрос который поднимает много чанков очень легко можете забить вот этими танками поднятыми с диска всю свою память чему это приведет ну приведет к комнате он наверное чему-нибудь еще такому нехорошему мы это видели это неприятно как с этим бороться добавлять памяти не использовать такие запросы других вариантов особого рвения с точки зрения такой подход с точки зрения изучения вывоза работы диск память наверное здесь ничего особенно больше сказать нельзя за исключением того чтобы немножко раскрыть тему как прометей конфигурирует с точки зрения памяти диска про конфигурирование пару параметров это не в прометея счастью или к сожалению есть количество параметров сильно уменьшилось с новыми версиями который можно крутить теперь у него есть точки зрения памяти ровно одна ручка таргет хип сайт о чем это говорит о том что мы говорим прометею чувак вот тебе память делайте ничего хочешь раньше можно было настраивать количество максимальное количество чанков памяти максимальное количество чанков которые ожидают записи на диск сейчас это всё на травить нельзя были почти все нельзя но зато появился ровно одна ручка она уже была на остальные старики при кейна тагильских сайт я не стал приводить здесь формулу формулы что примет и делает с этим торгах веб-сайт потому что на там такая многокомпонентная во всем он пытается понять влезает ли его текущее состояние в ту память которую ему дали если не влезает он начинает входить в состояние а давайте я быстренько быстренько все запишу на дисковод все подождете вероятность конечно продолжает собирать метрики но на диск начинают очень быстро очень интенсивно и тут включается вторая ручка эта серия sings 3g это собственно то как данные которые примет и записал в как ему кажется записана на диск должны быть синхронизированы физически с диском что это значит это значит что когда примет ее я сделал в райт вызвать искал какое-то не сам прометея runtime ok данные попали в париж операционной системы в этот момент прометей такой говорит а давайте-ка мы эти данные и на диск физически запишем и говорит операционной системе фсин к вот и эта ручка собственно отвечает за то когда мы будем вызывать в sing есть прям вариантом и варианты значений для этой ручки адептов что стоит по умолчанию это значит что прометею по какой-то своей логике считаю что сейчас он не очень сильно нагружает диск и может синкай данный на диск а потом например у него в группу понимает что у него потребление памяти сильно выросла он начинает писать на диск интенсивнее и как вы думает о теперь я не буду делать и в senki потому что я начал писать а диск интенсивнее и так сойдёт второй вариант него есть и делать никогда и третий вариант алви сделать всегда не рекомендую ставить адрес наверное мы никогда не пробовали честно но я думаю что это не очень не очень нужна история по крайней мере когда у вас данный там не синкретические они в данном случае не всегда некритически адепты самое оно вообще можно поставить него если вам не очень нужно синхронизировать не они очень 2 гарантии что данные будут записаны на диск физически вот это наверное про работу с памятью диском и внутреннее устройство 100 раджаф все но есть чем маленький нюанс который я хочу тоже озвучить никто не устал все хорошо окей тогда самая тяжелая часть закончилась маленькие капельки в параметре есть такая штука как индексы они лежат в ловил baby служит разным целям вот есть три четыре варианта канкан фигуру конфигурационных параметров они отвечают за размер кэша для л д б опять к там ссылочку все наверное и кто в приметаем работал читали простор edge там про это более-менее подробно написано про что там не написано там написано например про то что у вас могут проблему случай вот такого запрос что это запрос это когда мы хотим получить для продукта до стрелочка поехала соре мы хотим учили его продукты за несколько циферок относительно например разных ивентов это регулярное выражение примет трактует как регулярные выражения значит что он делает он берет для лейбла tight вытаскивает все имеющиеся у него метрики в нашем случае это там 500 тысяч например или там сколько 600000 может быть миллион то что и был тайфуна сквозной вот и начинает к ним применять регулярное выражение означает искать эти метрики которые ему нужны ну в общем это приводило к тому что при этом 10 запросов у нас возросла до 100 процентов и прометей сильно-сильно медленно начал отвечать нам на запрос собственно про индексы наверное пока больше сказать нечего это не сам интересной часть вот что же дальше на самом деле дальше немножко про результаты чего вы добились зачем мы все это делали все за ересь такая а добились мы очень простых вещей мы значит удовлетворили бизнес который пришел к нам задачей мы и быстро решили запустились проверили что концепция работает все хорошо но столкнулись с проблемой что на видно при рид нагрузки на примете он не очень хорошо себя ведет по разным причинам здесь я их уже не буду рассказывать но наши там циферки такие это 200 запрос в секунду в среднем временем 150 миллисекунд тут все важно сколько у нас винтиков лежит относительно каждого запроса каждый time series но в пике это было самое пиковое значение 16000 event of a scoop я помню за 7 дней но в целом очень большой циферки просуммировать цифру кажется даже быть быстро но почему-то за быстро никто не получается так как мы делали как бы в концепцию нашего бизнес-кейсы делали это быстро на эту нас на изучение этого просто времени не осталось но мы написали маленький кэш как революционный как все это делать и все заработало но зато нас примет ее есть данные которые позволяют нам смотреть разные графики ну там например графинчик некоторые бизнес метрики даже спойлеров что это проезжую мы видим что пойду продукта хороший хороший хороший бас спадает какой-то точке ну вот автомобиль в этой точке мы практически автоматическом режиме можем реагировать на то что у продукты упал поэзию и что-то делать например какие-то маркетинговые акции в теории можно делать мы над этим сейчас размышляем вот но в целом мы можем просто мониторить изменение наших бизнес метрик там в том числе сидни продукт таким образом вот еще или результатов что нам же как инженером понравилось это то что мы очень хорошо закопались sdb нам очень понравилась история с гориллой то как она была как это у них построена мы посмотрели как можно компенсировать на компрессировать или сжимать наши данные вообще насколько можно нашим данным так повертеть чтобы они занимали минимум места у нас есть насчет никакой план мы хотим сделать такой же маленький кэш для некоторых нашей задачи положить все вы распайка ну по нашим оценкам и должны работать очень быстро и очень хорошо может быть я расскажу вам про это следующий раз вот какие еще кейсы для прометея но наверное все знаете ну просто я с ними лично сталкивался да это просто ручной анализ временных рядов когда ребята загружали туда кучу данных исторических и глюками что-то анализировали телеметрия для j я тоже видел это автоматический анализ он реально автоматически то есть там реально собирается телеметрия датчиков котом приборчика в так далее анализируется и дальше прогнозируется стёпа вот у вас например вероятность такой то вот тут сломается через там два дня ну естественно бизнес метрикой автоматически я лифтинг это вот то что мы с на что мы смотрим это когда у нас есть три бизнес метрика мы даем для нее целевые показатели если вдруг что-то с ним происходит мы делаем какой то что там с этим делом только автоматическом режиме через а лифтинг спасибо за внимание на это наверно все этот ваш вопрос я вас слышу тогда громче так он здравствуйте меня зовут юра а хотел бы вас спросить если вы знаете как у вас устроена как то вас устроен отказоустойчивость над этим работали в и меч и листочки хранению с точки зрения не данных прометея с точки хранения с точки зрения вообще что в если там промытые вообще смотрите в праймериз короткий там нет инструментов для вообще отказоустойчивость вся идея в том что вас один instance который стоит на тачке работает как бы и масштабирование как будто на такое его нет поэтому с точки зрения нет нас прометея один если он выйдет из строя то мы вероятность сервис который вот это вот имитировать и перестанет но это данные которые не критические мы можем их не потерять нет у тебя плохо мы можем некоторое время пожить без них прометея с точки зрения восстановления например есть механизм у него есть механизм поединка то есть когда он через некоторый интервал времени лечить поставок о нём рос какое-то количество грязных данных в памяти берет в один просто файл сбрасывает все свои метрики последовательно и дальше когда происходит падение прометея при восстановлении он может на это посмотреть какие-то данные восстановить но если у вас данные просто физически побились на диске то тут уже вам очень поможет если не секрет падал ли он у вас нет не падал хорошо спасибо от меня зовут максим как долго ты послушно как долго вы храните приметаю месяц строением дольше хорошо мы каким-то квартал за год во всех мануал по первым пунктом ведь это уже очень много да это правда мы на самом деле мы вообще хранили за 7 дней вот как инженеры данном это вообще огонь потому что маленький совсем мало данных все хорошо но бизнес call давайте хотя бы месяц ok давайте месяц что касается большего срока ну можно делать визуализацию да можно какие-то две более старый давно проданы агрегировать и хранить там агрегированном виде соседнем прометея мы на этот счет пока не думаем потому что месяц нам хватает день добрый спасибо за доклад здесь я хотел задать вам вопрос такое нее думали ли вы о том чтобы мер жить данные справился в treehouse и потом в ваших проектах использовать данные уже если хаоса в каком направлении мер то есть откуда куда данный был из из parameters of crack house заливать метрики то есть про металась в этом случае выступает качестве агрегатора метрик он общается со своим понял нет мы пока не думали у нас просто объем данных которые мы храним в проеме три наверное чуть чуть меньше чем подожд у нас очень легко уж не знаю но в целом мы смотрим на разные инструменты как как хороший инженер мы смотрим на много разных инструментов и при house один из них если вдруг нам понадобится мы попробовать еще делать на пока нет скажите пожалуйста индексы все время находится в памяти или они подключаются индексы работают так как работает ловил тебе там сейчас я боюсь вам соврать там безусловно есть какая-то часть янамари вот интересует если корреляция между количеством метрик и объемом памяти использования конечно ну какая конкретно корреляции я вам не скажу то есть прям в числах но она есть то есть если вас количество меток возрастает то объем памяти вам также нужно жалеть что что даже не использоваться да-да-да ну потому что во первых есть яндекс который хранится некоторые архивировано метрики которые сохрани которые еще есть примите но range in time у них не вышел да и они хранятся в отдельном яндексе который по-моему самый большой потому что им кажется что то потому что хранят штамм ranger вот сюда корреляции есть и прометей очень прожорлив до памяти и второй вопрос можно ли изменять значения метрик назначении метрик мы исторически в этом фишка то есть ну вот фишка или не фишка это факт что прометея не дает возможности добавлять историю изменять историю только пинт все время такой вопрос я здесь у вас изначально задача была показывать счетчики или крайне истории какой-то изначально задача от бизнеса было показывать счетчики но потом она немножко модифицировал серож это понятно то есть у меня такой немножечко кощунственный вопрос пойдет начали задачи а зачем для этого вообще про метался если можно было там для ваших 500 тысяч наименований поставить там из 4 гигами памяти просто хранить данные в одессе или там не знаю а selected из моих целей кэшировать а не знаю в том же видите так можно рейде сможем тарантул можно потом можно что угодно разница в этих всех решений в том что а вы все равно поверх их структур данных в этих баз данных будете делать некоторые свое там решение то например вы будете удалять старые данные вам нужен какой-то кроме job который будет ridge на тайм поддерживает вам нужно эмулировать вот этот вот мой массив с сэмплами да потому что понятно что можно какую-то предо грига цию и делать на самом деле там я сказал в конце про кэш мы в нем такую prada грига цию сделали там в точность до получаса и так далее но исходные данные мы хотим чтобы они были вот в частном видим натуральным да то есть таймс темпы when time stamp event ну например у вас в том же самом и склеили они наверняка лежат можно же дергать и смазка или и складок просто в конечно какое-то время и от этого компонента пробовали там 500 миллионов ивентов за месяц наверное это немного нам не хочется 500 million табличку на 500 миллионов строк например медь они и лежат в банке они эти винты и лежат в некоторые аналитической базе данных которых но скорость ее работы не та которая нам нужна и даже с учетом того что мы будем делать в нее запросы на пересчет и потом кладет класть это в кэш скоростью работать все равно не та которая нам нужна спасибо пожалуйста меня зовут алексей и вот самом начале вы упомянули что под каждый метр купишь свой файл то есть на 500 . 500 тысяч файлов sharding это прямая турника у меня его нет были кении грабли сталине проциона система 500 тысяч открытых нова дескрипторов отряд много были грабли у разработчиков ядра когда они действительно сделал открыли файлики не закрывали их теперь они просто закрывают то есть открывается пишется закрывается и второй вопрос насколько тема выкапывая такого количества файлов для вас вообще актуально делали пробовали нужно не нужно если дело летучим вот тут я вам скажу потому что все таки де велде cooperation немножко не моя тема но я знаю чтобы копы делаются но как и чем не скажу честно понятно спасибо вопросы такой у вас наград в докладе был график который там сервисы визуализирует вы каким-то инструментом пользуетесь чтобы его ну просто я знаю про митоз и есть тигров она можно имеете ввиду может быть вот этот график красненький да ну да это grove on это кстати тоже один из плюсов grafana есть приметы есть визуализация работает удобно из коробки понятно и второй вопрос продолжение тут вот говорили и действительно зачем писать если можно например ну в принципе я вот как все вижу можно за день за два написать сервис который с порядок рига ции в памяти нажмите и держите такие данные ну и там разве 20 минут скидывает их на диск но притом держатель агрегат подниму например последние там восьмой день удалять нам надо к нему будет обращение держать последние семь дней под ним ну пишется за день за два есть ряд тонкостей всегда первое это во-первых мы хотим иметь все таки набор натуральных данных так как они были в некотором месте где мы будем можем можем экспериментировать делать разные запросы раз второй нюанс да вы можете написать сервис пошли в памяти хост машина переехала сервис опустился здесь поднялся там данный потерялись в 3 в нюанс про диск это уже не один два дня на самом деле если вы ну как бы да просто дети записать в тупую как бы на диск океана 5 машину переехал данные потерялись сервис ваш переехал двух машин так у нас не секрет докеры там еще в дополнительная опция с тем что нужно он быть некоторая часть файлы системы в контейнер там да и так далее то есть это все накладывает на нас затрат по времени на самом деле ни один два один два дня это точно не будет написан и запущенным просто вот это за цикл разработки за согласование с админами тогда дали есть много нюансов которые не позволяют делать это быстро а ранга скорость запуска было важно поэтому для нас вариант с прометеем показался скажем так самым быстрым с точки зрения запуск понятно спасибо у нас последние два вопроса подскажите вот сейчас как раз про доки заикались до соответственно а вообще пробовали ну то есть имеете ли вы опыт запуска этого параметра в контейнере и выдержит ли контейнер 500 тысяч файлов открыто нет мы не запускали в контейнере только для кого для тестов для таких вещей а вот на тесте утекать павел ну вот просто что-то из контейнера себя да нет там не было какого-то нагрузочное тестирование контент по просто тестовая среда точно просто когда отлаживали там разрабатывали систему запустили его в контейнер и там он работал нормально не ничего себе происходило соответственно и линковать наружу из контейнера не провален нет нет а если допустим запускать не линка и а потом как раз просто вот агрегированные данные тут вынимать не думали об этом можно на тогда опять таки если контейнер опуститься или машина с контейнером переедет что произойдет с нашими данными и всего куда-то надо складывать какие то да вот и я говорю о том что вопрос сказали что он там с периодичностью раз в какое-то время скидывает данные в один файл и соответственно вы вот этот вот один файл ленку и тебя уже например их там не один их там or check point имя и нынче paint.net так об этом не думали но интересный вариант не знаю надо подумать ну потому что стоит позволит вам линковать один файл и вы при этом вы собственно говоря имеете возможность как раз перекинуть памяти и на любую машинку куда захотите но я понял идею мы так мне пробовали делать спасибо или еще вопрос быстрый вопрос скажем метрики заливается через пушки твой или попал модели о это хороший вопрос сов хочешь дать футболках эта боль боль и страдания потому что да у полиции нет нормального копушей пий но есть при филлеры то есть есть некоторые мы сами написали свой при филлеры некоторые утилитка которые используют базу код база данных прометея мы ее подключили как бы создаете себя виртуальную базу данных не виртуальной физической свою утилитки наливайте туда данных вот и все потом подсовываете в параметре гитхабе не публикует хобби и есть опубликованные не нами такой при филлер с которого мы скопировали того чтобы просто depot свою задачу немножко доделать поэтому его можно спокойно взять и поищите потом в угли promises при филлер такое спасибо всем спасибо всем большой давайте поаплодируем спасибо всем"
}