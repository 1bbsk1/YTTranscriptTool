{
  "video_id": "RSTHex_rKBU",
  "channel": "HighLoadChannel",
  "title": "Подход к Continuous Deployment в микросервисной архитектуре / Алексей Баитов (2ГИС)",
  "views": 2731,
  "duration": 3577,
  "published": "2019-01-14T00:10:20-08:00",
  "text": "так привет меня зовут байтов алексей яром пони 2гис таким каким клад про подход как континиус диплом ментов микро сервисной архитектуре я скажу что у меня есть небольшой трибуне больших подарка за лучший вопрос который я ожидаю в конце моего доклада приступаем я работаю в компании 2гис и немножко про нее расскажу кстати кто знает про 2гис молодцы хорошо тогда я просто на видео расскажем пока расслабьтесь 2гис это международная технологическая компания входит в десятку forbes самых дорогих компаний он это ее главным продуктом является городской информационный городской информационный сервис и 2гис который объединяет карты справочник навигатор он охватывает 300 городов в 9 странах мира им пользуется 36 половина миллион человек такие условия накладывают определенные требования на качество ответственность и на учета рисков выпускаемые нами нами продуктами команд в компании много я работы в компании более трех лет и уже работаю не в первой команде моя текущая команда разрабатывает хранилищ рекламных материалов как раз для этого городского информационного сервиса она состоит из 10 10 человек семь человек у нас разработчики 3 искал и один из них это я 2 сишарп едва java разработчика один клан инженер и один аналитик давай аналитика один из которых является менеджером проекта у нас нет выделенной должности 2 вс поэтому вы здесь ее не видите зато у нас есть роль devops какое которой распределено между всеми разработчиками и куа инженером под микро сервисной архитектуры я понимаю архитектурный стиль который объединяет который структурирует приложение как набора слабо связанных микро сервисов осознанных с определенными бизнес логикой микро сервисной архитектура обычно загораживается от внешнего мира какой то изоляцией у нее есть публичная api а то что находится внутри может спокойно изменяться в данном случае у нас два публичных api ну вот здесь на этой схеме из внешние потребителя вращаю общаются с микро сервисной архитектуры только через эти два сервиса изменения их нужно хорошо контролировать контракты версии а то что происходит внутри от пред я сейчас расскажу когда мы разрабатывали микро сервисной архитектура мы столкнулись с определенной проблемой которые присущи всем микро сервисным архитектура водными для нее являются следующие параметрами что если вы разрабатываете микро сервиса при этом разработку вас ведется сразу вашей команде сразу нескольких микро сервисов и при этом они у вас объединены в рамках какой-то микро сервисной архитектуры взаимодействует друг с другом имеет какой-то контракт то есть они у вас связан и более того может быть вы уже настроили и continuous integration и continuous delivery каждого микро сервиса отдельным вроде бы все хорошо вроде у вас микро сервисы где плавится поразить все замечательно как по концепцию microsd сервисов но приходят проблемы согласованность версии или отсутствие и или сложность сложной согласованность версии появляется на из-за того что микро сервисы постоянно дорабатываются меняется внутренней какой-то контракт у них или например меняется структура rfid микро сервисной архитектуры то есть например добавляется какой-то микро сервис какой-то удаляется ну потому что это микро сервисной структура и она нам говорит что мы можем спокойно отказаться от какого-то микро сервиса из-за того что он может быть не устраивает нас по своей производительности можем полностью заменить язык разработки в общем переключиться на какой-то другой стек но внешне это будет не видно со стороны публичного api в общем все происходит внутри и хочется например какой-то момент случае возникновения к это проблемы реплицировать и ну или составить точно такой же список версии microsd вируса в которой находился на продакшне например 2-3 дня назад всех микро сервисов собрать в себя точно такое же тестовое окружение и его про ты протестировать соответственно мы и доставлять их должны с соответствующим образом а именно как к коллекцию микро сервисов бывает очень сложно построить continuous delivery именно коллекция микро сервисов а может быть я просто нет что хочется ну например у нас есть micro сервисной архитектура у которой есть фронт-энд 1 2 и 2 бэг-энда 3 4 это совершенно разные сервисы тесты не они не масштабированы например один тоже backend это два разных бэг-энда предположим у нас произошел какой-то первые релиз и и повелители из каждой в версии какой-то 10 после этого они начали свое развитие нашими красивая архитектура при этом нам очень важен порядок мы хотим его контролировать мы хотим знать что при внедрении чего-то нового мы внедряем его означали на самые низкие уровни например на backend 4 зам ниже находится потом мы уровне выше и у нас есть бы коэн трети и потом уже frontend по дипломам самый последний момент то есть например нас появилось какое-то новое свойство и мы хотим его подержать на всех уровнях предположим у нас есть какая-то задачка и мы изменяем только бэкон 4 хочется вот так делать хочется иметь какой-то срез в этот момент времени говорить что для того чтобы воспроизвести например ситуацию на бою нам нужно собрать архитектура из вот таких сервисов из сервисов о таких вот версий предложим делали еще какую-то задачку поменяли уже бэкон трети а потом мы взяли и сделали фичу который затрагивает одновременно несколько микро сервисов мы поменяли frontend 1 в коэн 3 к 4 и потеплели снизу вверх в определенном порядке а может быть им нам показалось что какой-то на данном случае backend 4 плохо справляется со своей задачей мы хотим полностью заменить на backend 5 ну вот пожалуйста мы добавили в конфеты пока наша сеть архитектура никак на него не смотрит все остальные сервисы а потом мы его добавили в наш стек frontend уже работает именно с ним после этого мы выпили либо к n 4 как видите у нас есть разные моменты времени которое мы хотели бы переключиться на пример мы посчитали что но это было наверное ошибочным решением выпиливать наш backend и но бэкон 4 мы бы хотели откатиться на момент вот например четвертый по счету когда у нас backend и был согласован с front and am первым например это то что мы хотим сделать такая концепция содержание моего доклада включает во-первых я расскажу про у микро сервисной архитектуру которую мы написали но более конкретнее потом расскажу про continuous delivery вообще микро сервисов компании 2гис это как мы изменили этот подход применили изменили революцию контрактов в общем как как мы сами доставляем наши микросферы с нашей команде микро сервисной архитектура у нас имеется с разные слои на фронте у нас несколько микро сервисов они общаются с внешним миром есть высокого уровня уровень высокого уровня api порез там они общаются с фронт эндом есть какие-то демоны и эти темные то есть фоновые процессы а синхронизируется с высоким уровнем api через базу данных либо через какие-то хранилище при этом оставить им ставится задача у нас в данном случае на брокерах брокер это кафка есть внутрикорпоративный брокер и мы также держим очередь задач на отгрызть микро сервисной архитектуры позволяет нам писать микро сервиса на разных языках здесь видно как мы распределились то есть не так что например скала только на высоко уровнем апиа сишарп на на фоновых процессов мы распределились по закону конвейер когда структура компании диктует структура приложения приложение данном случае это коллекция micro sim micro сервисов то есть micro сервисной архитектура как вообще можно развертывать микро сервиса тут небольшое условное обозначение для следующего слайда кружочек это сервис остаётся свой исходный код кубик это экземпляр сервиса микро сервис то что работает фронтами существует а следующие шаблоны вы можете их найти на сайте microsoft с его можно все микро сервисе запустить на одной машине но необходимо следить чтобы им хватало ресурсов может быть тесной они начнут друг друга вытеснять и кто-то из них будет зависать падать не хватать к машинного времени можно быть альтернативным путем и микро сервисе распределить каждый на своем хвосте тогда ресурсы используется нерационально можно запаковать экземпляр сервиса в виртуальную машину и отправить ее какой-нибудь amazon.com пьют клауд но данном случае подготовка такое виртуальная машина занимает большое время хотя мы этим не занимались можно также запаковать свой экземпляр сервиса в образ вы здесь видите картинку доки расскажите кто пользуется докером в отлично а кто пользуется rgt я тоже не пользуюсь хотел вас кинуть пообщаться но нет среда кастрации кубер нет у кого это вас своя среда да нет не своя google cloud наверное да отлично кто тоже есть со своей средой и не так много вообще людей в зале моисея кого то есть никого - нет ладно а если дальше есть другой вариант можно не оперировать экземплярами сервисами переливать микро сервисами а можно оперировать просто кодом вы можете запаковать свою функцию в какой-то архив и отправить на сервер на данном случае это аренда amazon линда да можно не отправить и просто пока кого в какой то момент времени обращаться к этой функции это просто будет какой-то метод в api функция будет выполняться в давайте какой-то полезный выхлоп и в дальнейшем никаких ресурсов не потреблять есть также вариант довольно знаменитый это платформа для развертывания сервисов я здесь изобразил heroku кто пользуется heroku так очень мало людей я не пользуюсь я руку просто так поднял вот наш компания используя это использовал адрес это open source проект подобен к уроку еда из 2 но мы в конечном итоге от него отказались значит так да у нас а бывало много экземпляров сервисов на хвосте мы использовали dance как платформу развертывания и остановились трендом нашей компании является docker и среда артист рации это купер ниц как проходит continues деревья кокаин с инструментарий код мы хотим храним гид лобби seo и процессы и сидим мы построили на git lapsi образом блогер образ у нас является артефактом для дистрибуции с регистрации как я сказала и так обернется на собственное среда фильтрации собственная команда которая ее поднимала и которая ее поддерживает постоянно и который обновляет ее и в качестве инструмента развертывание у нас 2гис инструмент собственный для развертывания повернуть это инструмент писался во время ну это было несколько лет назад когда еще не было достаточно не был достаточно развит развит хэлом был на уровне хилым классика и кто тот момент он нам не подходила не поддерживал разные окружения поэтому было режим принято решение написать что-то свое ну так вот мы переживем что и что на себя представляет этот инструмент это питон который работает ска вернется через оберните опять так гораздо удобнее чем через консоль и через скобки t el хотя бы ранее он работал через кубка t el он содержит множество окружения и они записываются в яму спецификации ресурсов убирается у нас записывается в джинджер и получается этот инструмент пропуская через себя яму спецификацию шобла не зиру ит-ресурсы губерний тс на выходе мы получаем уже готовые ресурсы будь то диплом it serves конфет map ну и так далее также у него написан плагин внутри для больших 4 кодирован декодирование для того чтобы можно конфигурировать секреты в cabernet он может работать в синхронном синхронном режиме дожидаться либо нет диплом и он может деплоить сразу несколько микро сервисов сейчас вам покажу как выглядит у нас процесс скользили озеро независимых и микро сервисов вначале на одном а потом на нескольких параллельно надеюсь виднее стал на слайде да значит здесь у нас имеется pipeline это я специально снял скриншот гид лобо чтобы кто-то узнал что это гид лап кто пользуется йоги туапсе почти половина зала кто пользуется дженкинсом 7 то уже почти половина за ваката чтобы остальные хорошо может быть m-city тоже почти половина зала до во всем где-то распределились равномерно чита меньше конечно небольшое количество зала пользоваться тем сити в общем pipeline а вы можете построить на чем угодно даже на беззватетной plain я не говорю что надо делать именно так я говорю как сделано у нас мы строим их на git lapsi поймаем это совокупность последовательно идущих этапов с 3g при этом на каждом этапе можно параллельно запускать джо бы какие-то работы первым этапом у нас является тест ну так вы назвали на самом деле здесь мы собираем наш продукт делаем сборку запакованные выбросу в докер-образ и параллельно проводим unit тестирование то есть мы тестируем какие-то методы в коде или ну либо небольшие классы при этом мы делаем день термостатической анализа ция кода после этого после того как сборка прошла успешно успешно она улетела в наш собственный docker hub уколов компании есть собственный docker hub ну отлично это чуть больше чем дальше чуть меньше чем половину ладно в общем у нас собственный таких об мы там храним наши артефакты мы собираемся на каждой ветке у нас там много образов просто потом потихонечку их за собой чистим образ используется на этапе функционального тестирования что это такое мы тестируем именно сборку готовы для того чтобы ее внешним развернуть где-нибудь и на тестом окружении нас тренинги либо на продакшн и тестирование проходит следующим образом мы в ноге тла про не решил экзекуторы запускаем через докер кампус какую-то сеть dagger сеть изолированы там работает наш образ приложение параллельно запускается контейнере с каким-то belkin сервисами например это база данных кафка или что-то еще и есть работает контейнер с функциональными тестами в нем встроенные моки в конфигурируем и то есть то есть перед каждым сценарием в тестах мы очищаем полностью базу и очищаем make потом пред конфигурируем мою нужной информации запускаем тест и так вот вы на каждом сценарию то есть каждый тест у нас проходит чистый-чистый тасс получается что дальше после того как мы прошли это функциональное тестирование наше приложение проверено как сбор которых например если это сервер с rest api то мы уверены что он запускается два первых он запустится и во-вторых его методы будут работать после этого мы занимаемся как раз развертыванием кубер ниц я думаю просто ли здесь рассказать давайте дальше немножко тогда вы здесь это мы используем как раз и нашу инструмент внутренние 2гис для того чтобы развернуть скоб микросферы saw что здесь здесь представлена continuous delivery параллельно разрабатываемых микро сервисов а это необязательно они даже вот все одновременно все пройти все может быть синхронно я просто упростил схему и показал что в дальнейшем у нас будет кружочками бо значатся этапы в наших pipeline ах на выход у нас получится экземпляр сервиса ну или микро сервис проблема из-за того что мы постоянно доставляем микро сервисы независимо макрос приходим к проблеме согласованности версия которые я ранее рассказал но я рассказал только на примере какой-то версии 1110 но работа с контрактом бывает вообще-то разные эволюция контрактов как мы эволюционируем во первых можно конечно же использовать рафинирование она бывает двух типов это гетерогенное то есть например у нас имеется какой-то заказчик клиент мы с ним договорились что у нас будет определенный контракт для выдачи какого-то ресурса к нам приходит новый клиент и говорит я хочу тот же самый ресурс но немножечко по-другому ну например я хочу информация о пользователе но при этом чтобы там у него был никнейм какой-нибудь или может быть дата рождения и добавляется новый контракт и и получается нас есть два контракта для одного клиента и для другого клиента и так потихонечку они плодятся есть другой вариант это гомогенное versio не рование то есть когда вы добавляете версию в контракт приходит новый клиент говорит я хочу что-то новое про этого пользователя вы понимаете что вы контракт можете расширить versio не рвите выставляете версию для предыдущего контракта 10 например она была такая для для нового клиента вы расширяете этот контракт ставите у него версию 11 и первый клиент какой-то момент удобно для него может потихонечку перейти на новую версию контракта вот такой вот такие verso не ну не обычно все пользуются можно вообще уйти от этого и можно использовать разъединения контракта то есть снизить какой-то сервис который который как раз будет разгар all разговаривать с клиентами и в дальнейшем будет обращаться к нашим внутренним сервисом что он делает он не только один в один прокси рует информацию с например бэкон серверов он может ее трансформировать что-то добавлять объединять например нужен кому-то в силу а у нас все по отдельности он может с хлопнуть информацию бывает так что мы что-то изменяем внутри своих сервисах и вырезаем какую-то информацию но при этом ее можно собрать из разных ресурсов нашего api вот как раз отдельная микросферы занимается тем что он вы искать эти ресурсы объединяет их в один контракт и все точно также дает клиента для клиента ничего не поменялось если у вас все часто меняется тогда в первом случае вы будете платить очень много версию себя неважно что это будет какие-то новые контракты либо будете настаивать версии внутри какого-то контракта определенного но это будет много версия если посмотреть как это идет в разработке то у вас будет много тестов написано на каждую версию на каждую разновидность контракта у вас будет много legacy кода вы вынуждены будете потом отслеживать кто перешел на новую версию и только после этого после того как все пришли на версию будете выпиливать старую версию во втором случае вы будете постоянно плодить новые сервисы это это не нужно в внутри микро сервисной архитектуры если все это ваша семейка сервиса вы можете их слаженно переходить на реализацию и не добавлять версии весят мы пришли к нашим подходом мы поняли что часть сервисов часто меняющихся представляет из себя единое приложение это та же самая картинка к я приводил только сейчас будет пояснению backend высокого уровня api и демоны некоторые у нас имеют концепциям он репозитории что это это когда в одном репозитории вы разрабатываете несколько сервисов и при этом на выход у вас вас является либо сборка один докер-образ и вы можете запустить его с разными переменными окружениями в губернии то есть они будут работать например как rest и как коими фоновые процессы но на самом деле это очень удобно потому что вы в на этапе разработки локально работаете можете все переменные окружения ему за сети тем будет работать у вас и к крест и как демон для разработчиков это удобно для нас либо второй вариант вы можете создавать в качестве артефактов несколько образов один для backend api другой для демонов это тоже варианты это тоже у нас есть команде далее мы поняли что сервис и фиксируется версии при сборке то есть тем коми там гита где мы собрали сборку это может быть либо так это может быть либо какой-то шишками там и дальнейшем мы и то и другое используем при этом он репозитории тонируется только одним ночью таких их hашем либо тегом то есть на выход на выхлопе у нас несколько образов но не имеет какую-то одну единую версию их удобно контролировать как о совокупности в рамках одной версия более того мы поняли что можно в какой то момент времени зафиксировать все эти версии и в этом месте они представлены вот таким слепком я дальше так и буду оперировать этим понятием слепок версии вы здесь видите что слева у нас версия 8 верными и ты патч версию слепки версию вместо патч у нас звездочка все потому что мы не хотим обременять процесс тестирования кула например какими-то проверки патч версии это что-то незначительное то может проверить сам разработчик зачем зачем зачем нам контролировать все мелкие изменения более того весь этот слепок можно как-то версия тоже versio не ровать то есть у нас может быть в каждый момент времени какая-то версия данном случае этот слепок имеет версию 46 что мы поняли мы поняли что нужен отдельный сервер тепло и он был выполнял роль менеджера пакетов и ему нужен собственной репозитории и собственный pipeline вот как это было вот каков мы независимо доставляли наши микро сервисы вот чему пришли мы все точно также независимо проводим ее не тестирование с не делаем собираем сборку она улетает docker hub на же тестируется на функциональных тестах а потом используется отдельный play services & diplo и интриги рица я дальше расскажу про это подробнее там мы поднимаем какое-то отец твое окружение проходит acceptance test in the end с то какие то после этого мы готовы уже к непосредственному выкатки в губерн и сейчас на примере тестова поднятия теста напряжения для какой-то задачки положим у нас фича сейчас состоит из одной задаче номер задачи и тоска 777 и она изменяет какой-то один бэкон сервис ну одна задача на какой-то сервис обычный можем frontend изменять ему неважно данном случае бакан сервис у нас имеется изменения мы его запушили и таким образом создали ветку и инициировали profiline в данном случае ветка 777 уже прошла тестирование сборка сборка улетела docker hub протонировали образ бросай но доктор образов этот ток называется простояли мы версию номер задачи и какое-то сокращенную 1 6 символа из фишками это никита отправили протестировали на этот эту сборку и дальше наш pipeline скажем так подошел к ожиданию он ждет разработчик в зависимости нужно ему это или нет поднимается тесто в окружении он триггерит api guide лобана определенные ветки на мастере и передает в качестве переменные окружения номер нашего образа все это встроено у нас в планах разработчику только нужно у себя сервисе например если он band нажать на джоби там меню action' то есть запустить его вызывается сервис тепло и инициируется pipeline у него есть информация слепок там хранится виде ямала он себе подставляет вместо backend 3 который мы изменяем версию образом и отправляется docker hub ищет какие последний патч версии там есть для этих контейнеров находит и их отправляет уже как раз наш инструмент диплом в компании которые используются и поднимаем это тесто в окружении при этом тестовое окружении ещё не готова его нужно наполнить данными с there is deeply этим занимается в у нас например он берет с при подготовлены данные с продакшена и ими наполняет тесто в окружении через api pipeline сервис абакан сервиса ждет это просто с какой периодичностью он в своей джоби который разворачивает инициирует разворачивание окружения запрашивает pipeline сервиса деплоя все ли готовы там и когда там все готово я оба pipeline а завершается разработчику себя в pipeline не понимает что у него есть тесто в окружения у него должна мне ссылка он может отдать его например в ucla инженеру на или аналитиком на какие-то приемочные тесты мы поднимаем не только сами при микро сервиса но и все необходимые для них backing сервисы то есть там база данных какие-то хранилище кита очереди таким образом наше тесто и окружения полностью изолирована вот у нас слева задачка 777 изолирована параллельно кто-то работает на задаче 88 и кто-то работает над неудачные сети 66 она явно и потом потребует от кота continues deployment именно production окружении но проходят следующим образом все построено на аптеках мы-то герой бэкон сервис выливаем наша задача 777 в мастер то героем инициируем pipeline на то чтобы было собрано сборка протестирована и после этого в автоматическом режиме автоматическом режиме происходит вызов в pipeline и на ветке мастер сервис и диплом там поднимается костей джинка окружении но она есть просто обновляется данном случае и при этом мы изменили какой-то патч версию никакое воздействие сервис деплоя не требуется ничего не нужно тогда коммитить никакой так там ставить сейчас данный момент не нужно все пресс разведет обновления автоматически все команды которые с нами интегрируется дорогие есть в нашем стайлингом получает последнюю версию прогоняются какие-то гриве агрессивные тесты и мы приходим к тегирование сервисы диплом предположим у нас поменялся не патч версия минор или мы предложим минор бы поменялся что делаем мы обновляем слепок версии который хранится там репозитория ну предположим 412 стало так же ставим звездочку вручную комиссиям это делаем марше квест может быть добавляем какие-то дополнительные информации про то как изменился deployment давай рис переменное окружение либо какая-то связка этих сердцев поменялось друг с другом то есть мы уже подготовили тепло и для продакшена всей на всего нашего слепка протонировали сервис диплом на данном случае с 46 менялся на 47 мы меняем минорные версия здесь у нас нет патч версия только тогда когда меняется сам сервис диплом какие-то внутренние логике у него поэтому мы данном случае поменяли происходит автоматически вызов pipeline а при просто постановки тега в начале мы диплом as they jing убирается понимает что изменился только б контрить и поэтому остальные копики пунктиром он не обновляет он говорит deployment не поменялся и ничего нет не буду таким образом мы достигаем независимого тепло и только например 1 микро сервиса в рамках слепком прогонять и регрессионной тесты мы готовы и проходит диплом production точно так же там поменяется только backend 3 какие преимущества у нас есть хороший аудит слепка версии он находится в git лобби мы можем всегда посмотреть по pipeline нам когда какая версия выкатывалась и какой там был слепок мы унифицировали диплом окружение не важно это stay джим продакшен и или тест в окружении все у нас одинаково это позволяет новому человека в команде быстро влиться в процесса континиус диплом n-dubz он может попрактиковаться на тестовых окружениях и потом мы говорим все ты можешь заниматься любыми продакшен даем ему доступ к berlitz production чтобы он мониторил что там происходит в момент релиза если уж очень нужен например и все у нас в человек уже 2 выполняет роль давался все очень быстро у него требуется ну где-то недели на это чтобы войти весь процесс что нас еще есть у нас есть единая подследственность тепло из сервисов это как раз обеспечивается нашим инструментов компании нова гис и как я уже сказал у нас есть изоляция тесто в окружении после того как review закрывается автоматически срабатывает a job guide лобби на то чтобы удалить это тестовое окружением и руками ничего не чистим ну только если что-то пошло не так в дровах это бывает очень редко недостатки сложный плоской структуру структуры beetle обсе так как все работает на триггерах то нам приходится вставим добавлять условию v jopu если это триггер вызвали то есть меня вызвал какой-то сторонний сервис тогда я например не буду и тепло и nostalgic например да или например если это стретчинг тогда я не буду его наполнять данными как-то выглядит не очень более того триггеры не могут создавать ветки и триггеры не знают про другие приложения оно про другие сервисы о чем это говорит триггер можно вызвать только на мастере ли вы на ветке которые мы зашили у себя в жопе в каком-то сервисе при этом очень бы хотелось поднимать в рамках фичи единое какое-то окружение и потихонечку обновлять его разными сервисами чтобы заказчик принимал смотрел на лайках все происходит и после этого сказал да все нормально и можно было бы все это выкатывать куда-то в общем неудобно работать на триггерах вы подумали что нужен некрасиво тепло и для диплома микросферы со мной архитектуры или craster этого дятла нет микро сервис уже на что-то начинает быть похожими я ожидаю вопрос создали после доклада так как теперь происходит у нас поднятие тесто окружения я все сразу же вам показал здесь изменить простое у нас триггере тся при поднятии тестов окружения микро сервис точно также вызывается какой-то мида топи у него у него есть какие преимущества он может уже работать с нашим репозиторием он может создавать ветки можно создать несколько веток то есть он может создать ветку для тестов окружения и ветку для нагрузочных тестов конфигурации подобны просто они у нас на разных купер nights модах находится для того чтобы нагрузкам никому не мешала более того мы все так же можем ожидать когда наш pipeline закончится но только через наш микро серость диплом и он может менять он может коммитить мы наделили робота возможности изменять имена то все наши репозитории что может сделать он может дополнить слепок он может ему точно сказать что в яму нотация там есть возможности наследования потом якоря и ссылки соответственно может снизу написать и сказать что вот бы контрите будет вот именно такой и мы соответственно можем зайти и еще что-то поправить в этом диплом ну deployment сервисах и так далее ресурсы кумир ниц для нас это очень удобно что получилось мы упростили гид lapsi и создание ли ветки для разных тестов для теста окружения несколько веток можем создавать теперь задачи если в fitch несколько задач что они могут иметь единое окружению как то происходит нужно где-то хранить связку что задача совокупной задача ответ на это какой-то какой-то фиче мы заводим фичу интеграционную заводим задачи и в git лак сниппете храним такое соотношение задача фича задача все то же самое fitch еще кое-то дальше все тоже самое фичу и когда сервис диплом принимает решение создать ему какую-то ветку он обращается туда и говорит хорошо я буду ее создавать в рамках какой-то фиче и придает и номер 1000 там тоска не знаю фича 6 или не знает и может быть семь семь семь или восемь восемь более того он может сказать ну посмотреть и сказать что но вообще-то редко уже есть значит я буду обновлять этот слепок версии и обновляет он ну барсе этого и добавляет только то что нужно то есть у может ким разу не сказать и добавить в один слепок у нас появляется средства и окружение автоматическое для конкретной фичу это очень удобно результаты к tennis and aggression автоматизировали сборку в докер-образ автоматизировали тестирование юнит функциональный тест прогоняем надо кирком паузе у нас есть до нагрузочную емкостные отказоустойчивость тесты используем для этого гатлинг но для такого за устойчивое самой просто на гатлинга нагружаем нашим какое-то окружение а потом какой-то периодичностью устраиваем холсман типа грохнем его пода вот мы и другие там приемочные тесты и так далее continuous delivery он базируется поверх снега tennis интеграция и позволяет нам при подготовить развертывание уже в продакшен за счет чего за счет слепка версии за счет того что есть у нас порядок развертывания и там из-за использовали в корпоративный инструменте диплом и откат на предыдущий слепок за счет гид lapsi хотя news deployment позволяет нам автоматизировать процесс деплоя уже в продакшен и дело так чтобы документация поспевала за изменением что это ну мы изолировали изменения микро service of a candy deployment он все так же говорит что мы обязаны следовать но желательно следовать уже puffy чем так мы делаем мы принесли все интеграцию команды внутрь кода последовательность и так далее все уже есть мы не тратим время на то чтобы спрашивать так ты там сделать свою задачку там когда можно и выкатывать все проходят автоматически и последовательно не меняется унифицировали диплом все как я сказал тестовый to stay jing и продакшен одинаково почти и автоматизировали его за счет того что мы делаем все на кометах на кометах в нашем бэкон сервисы на кометах в сервис диплом всего спасибо за внимание так вначале подождите я бы хотел воспользоваться случаем и передать привет своей дочке ей точно будет приятно сыну он еще маленький чтобы понять жене родителям и всем своим родственникам спасибо вопросу что ж давайте начнем вопросы вот вижу рука спасибо за доклад в своем докладе вы не раз упоминали о том что корпоративный инструмент диплом мира его зовут у нас ведь не планируете я разговаривал с человеком который вы разрабатывает то у нас есть отдельная команда infrastructure and operations он сказал что над этим активно работает но это очень сложный процесс потому что каждое мы затачивается под версию купюрница которую мы в данный момент ну хостинга соответственно он потихонечку нас и изменяется инструмент диплом в points forth нужно уходить выходите для каждой но для разных версий а каждая версия имеет свои какие то не знаю на шероховатости приходится варка раунда прорабатывать в общем длительный сложный процесс вообще планируем может он только выигрывает от перехода фокус возможно дальше надо еще поддерживать принимать марше квеста людей ну в общем это довольно сложный процесс конечно вы играете спасибо дальше вот чуть сзади мужчин спасибо за доклад слушая как работает тогда трал блпк версии сервиса если при переходе от младшей версии к старшей допустим тебя было миграция схемы базы данных все просто мы не делаем обратно обратно изменения без обратной совместимости то есть мы добавляем начали какое-то опциональное поле база данных и потом уже через какой-то момент уже делаем его обязательно то есть стараемся все аккуратно делать мы не делаем так что срез извиним участвовали ли более и все давайте вот вам спасибо за интересный доклад можно вернуть на слайд где был bass все четыре я там может не правильно услышал вот начало используйте b4 алёшка бы секреты губерний подставлять в джинджер шаблоны то есть они не понимают мы обычно котировка надо выше тетя ногу то есть в их никак не я думал прячете этим образом но мы прячем да ну это так себя на тоже боишься 4 можете кодировать я думаю можем наш лимит ага но у меня вопрос был так так вы говорили что у вас номере мы на репозиторий вопрос почему именно он почему именно так сделали скалы разработчики сделали свой репозиторию сша разработчики свой репозитории и разрабатывали у нас как бы разделил и замена я модель но в рамках каждого репозитория домены модель какая-то сая общее но в рамках сервисов которые там порождаются то есть именно принцип то что а почему обычном он репозиторий возникает чтобы одни и те же классы не распространяйте не поддерживать сразу в нескольких репозиториях очень удобно в одном находиться в общем модель иная модель да понял спасибо спасибо за доклад вы как-то помянули во время свои выступления про то что когда собираете докер-образ потом и функционально тестирование с использованием мог of отец бы несколько подробнее узнать как где вы эти муки храните как а их поддерживаете с помощью инфраструктуры вы для данного сервиса котова тестируйте до кэроба с развертывать экзотики это можно платить там настроечки да там у окружении так моя находится памяти они конфигурируемые конфигурируются самими же тестами когда стартует ну мы запускаем все в декабре наша ретро мире нашел эксикаторе так бывает докер экзекутор шизик vitara нашего shell экзекутор то есть мы можем там поднять докер инфраструктуру какое-то через докер кампус у нас в отдельном контейнере приложение уже готовая сборка мы ему говорим изначально что ты будешь смотреть на такие то на такой the road и определенные мог of вот в рамках какой-то подсети носите в докере но в данном случае у нас там тасс кв антенна назовем его так этот контейнер вот и докер компас в dns встроенный он все понимает вот мы говорим тест ланджоу порт такой-то слэш там у тебя будет там не знаю юзер обе я слышу тебя будет рекламный материал или что то еще вот поднимаемся бейкер backing сервисы и когда поднимается контейнер с тестами он вначале поднимает отдельно отдельном третье сервер с этими муками и в другом он уже занимается тем что запускает тесты тесты это фича и декорирована на сценария получается перед каждым сценарием и полностью очищаем базы baking сервиса то есть тест имеет доступ к базе и дальше очищают моки eprint пред конфигурирует его то есть каждом тесте мы описываем в этом море должно быть тот а вот кладем и после этого делаем запрос на наше приложение в наш контейнер с приложением и он уже обращается к мукам можно дальше дождя еще вопрос допустим вас потребуется обновить существующие моки для сердца дом из минска поведения до соответственно вас в муке они как-то где-то под контролем есть находится как вот у вас происходит например от необходимость того обновить существующие муки для того чтобы сохранить актуальность тестирования то есть если вдруг в продакшене поменялось контракт как мы меняем оки так как у нас имеется слепок версия мы знаем что мы по диплом ся например с таким-то следующем контрактом на другого микро сервиса вот соответственно эта версия уже будет адаптирована к версии контракта будущего сара него микро сервиса мы меняем внутри контракт и тесте переписываем все работает спасибо следующий вопрос спасибо за доклад сколько у вас длится полный цикл continues дипломата от сборки до рода у нас очень длительный процесс и функциональных тестов 15 минут а на скале происходит я вообще думаю делать о как и параллельном единственно он сильно подтормаживает то есть суммарно где-то минут 20 25 получает то есть у вас от момента начала сборки до порода на вот всю пачку сервисов из тех кто готова тепло всего 25 минут ну да откатиться мы просто на сервисе deployed котором 100 секундное дело просто зашел выбрал новый новый ну pipeline просто инициировала его и откатился на предыдущую версию у меня был вопрос могут ли цикл и deployment a ver la пица то есть пока одно одно поколение тестируется может ли следующая собирается и и так далее чтобы на каждой стадии была постоянная работа на неверно уже на таком коротком промежутке типа 30 минут есть ли профит от этого все что угодно может произойти мы нацелен на нет ну да оправдали проиграли ность да то есть ну конкурентность должна за ресурсы не не одно поколение тестируется следующего собирается потом соответственно про цитировались выкладываемся в прод предыдущие отправилась в testing уже собранная на такая модель есть да конечно и поэтому я там написал что мы прогоняем нас тычинки каждый раз регрессионные тесты то есть мы можем выкатиться потом правильно кто-то ведет разработку вот и он вроде бы с какой-то версией еще не не проверился скажем так снова версии кого-то бэг-энда до следующего мы уже что-то подготовим подготовлены много и прогрессивной теста должна это выявить в общем я параллельно если есть над лет мы тогда можем потом поговорить хорошо следующий вопрос только во был давайте алексей скажите пожалуйста а вот вывод упоминали на второму и третьему слою приводили пример что вас есть а когда различные сервисы стали high level ok и еще по моему какие-то демоны паскаль просто это где все же вот это все живет где на каких-то был сервис или вы где-то в claude по что все больше и больше команд переходят навыки вернитесь в том числе нашей стране и вот интересно с точки зрения нагрузок это все-таки ваша собственная инфраструктура на вашем железе либо все таки многие то в claude и примерно вот таких нагрузках идет речь ну сколько запросов в секунду на бред так да это наша инфраструктура наш купер нет наша команда которая поддерживает ну не моя конечно наша и им про страшит operations нагрузки там бывают разные с продакшена чисто на наши сервисы мы занимаемся хранилищем рекламных материалов если 2гис вы зайдете на карточку этой компании то там есть логотип чеки везде это наше готовься на за графическая и текстовая и видео информация и эти вот видео которое это тоже мы хотим у себя но занимаемся этим всем вот в общем есть внутренняя админка админка нагрузка 10 рпс то не о чем есть красс эти логотипы и графическая информация там мы хорошенько закрылись от внешнего вида клауд мира это клауд флаер у нас есть потом есть собственный dns cdn кеша но они уже находятся cabernet а вот я уже дальше мы рендере на лето все размеры картинок вот то есть мы нигде не храним привет рендер не на размеры там нагрузка когда один раз нас прошибла то есть где-то кэш полетел на кластере я был где-то 50 60 то есть мы не ощутили вот и с видео у нас порядка 100 р пояс ну то есть тоже не так много версиях к берлинцев побольше никакая 18 или 19 сейчас уже 19 до у нас постоянно обновляется на самом деле уже где-то последний 110 но нас где-то сейчас 19 потому что изменение с одной версии на другой влечет за собой изменения и докера на всей нашей инфраструктуре вы вину выявлено было то что собранный образ желательно на чтобы по версии он совпадал докера он совпадал с версий докера в губерн с таким образом для того чтобы перейти на новую версию cabernet необходим посмотреть обновить начали на докера мерах на всех на гид la праймерах все версии докер а потом обновить его уже еще в кубер нити и только потом уже в качестве о вероятных сетей во что используется wife нет или что у вас сегодня вот коллега 1 делал доклад и зуд авито в качестве чего power реальных сетей ну для того что все это связывает ну там вы не то что то еще я не отвечу я могу вам получить ответ от нас а вы можете короткий вопрос буквально две секунды а вот вы вначале говорили что использую в качестве seo гид lapsi на при этом в конце упомянули что этот это и вот недостаток потому что плоская структура необходим для дипломата а почему почему диплопии же там три вися есть есть и дженкинс здесь хочет уже все около себя в конце концов я понимаю что не стоит кого денег вы хотели но мой загид лап не платим на самом деле вот почему выбрали той как это обсе это ну вообще желательно ну нам удобно что все находится в одном месте и код и себя и с ним связаны б да это на самом деле очень удобно минимизировать stack технологий следующий вопрос вот зато класса значит вопрос из сотен говоря по теме есть реализован или какой-то пол thorens сценарий вот в эту инфраструктуру она все-таки кажется достаточно разозленный и грубо говоря если что-то идет не так совсем говоря какие механизмы здесь задействуется и вопрос на приз считается считает ли такой клевый специалист дубльгис мега крутой компании что не считается лепестки специалист что считает ли такой мега клёвый специалист дубльгис мега крутой компании она спасибо выбери меня началом франсиско вопрос значит так фунтов он отказывался точного нас работ с ошибками скажем до full tower and если что-то идет не так во первых у нас есть команда infrastructure creations который постоянно мониторит губернии цена 500 и и всевозможные ошибки она выявляет кто является инициатором этих 500 ах и дальнейшем звонит или как-то сообщает дежурным о командам в данном случае у нас роль домов за распределена и это своего рода дежурство но только в рабочее время каждую неделю мы выбираем тот того кто будет отвечать на такие возникающие инциденты он если что-то возникает пытается решить проблему сам если нет тогда прибегает к помощи разработчика чей сервис например 500 вот либо например он понимает что это не у нас но случае я понял что не у нас и я стал звонить дальше по инфраструктуре там другим людям там это было что ночью даже такой один раз случилось всего за два года у нас вот разбудили мы там приподняли вот да я считаю компанию крутой на вот еще один вопрос спасибо большое за доклад вопрос в следующем я так понимаю что тот что сейчас описывалось создавалась вашей команды и для вашей команды верно ну в первую очередь и соответственно собираетесь ли вы или пробовали ли вы использовать и внедрять вот данную систему в рамках все ваши организации и на каких масштабах вы пробовали ее использовать создавалась мной он нашей команде поначалу то есть ну полгода где-то я это создавал параллельно занимался разработкой потом подключил тестировщик какой инженера и мы с ним распределили нагрузку это было еще где-то несколько месяцев и после этого нагрузка распределялась между 7 и по боксу уже на готовом решении это 1 два ко мне приходят из-за разных команд и спрашивают наш опыт я пришел мнение что это полезно и решил рассказать людям приходила уже из двух или трех команд единственное я не могу им отдать свое решение но как поделиться потому что она слишком заточена процессе подготовки я стал углубляться в хилл и к сожалению не слышал это вопрос а вот сейчас холма очень хорошо развит у него есть чарты есть пункт allure называется серых который занимается непосредственно диплом я увидел сложность в том что тайлер то есть я людям стал советовать hell и потому что я говорю ну зачем ну заново пилить велосипед вот если можно использовать готовое решение единственно мы тогда потеряем поддержку нашей команды внутри но infrastructure решиться на наш инфраструктуре мы будем сами саппортить все это не очень удобный вариант вот более того это тайлер в холме он на для скачивания чартов просит доступ к репозиториям предположим они закрытым 3 то есть определенные сложности и я на самом деле ушел дальше когда я различал home я ушел дальше я написал уже я уже ушел от яму программирование ну холмы таяма программирования ты вкладываешь одно в другое очень удобно все приложение но java programmer у меня убило просто здесь у нас яму спецификация но я уже руками и не готовлю я придумал систему это абстрактная фабрика она порождает на питание тоже написал потому что с инструмент в дипломе на питоне вот тракт моя фабрика который порождает семейства микро сервисов а потом они процессе порождения не можем могут быть вложены один в другой вот и на выход там по компоновщик у то есть я запрашиваю грот есть секция там а теста окружения я говорю с компа создание для ямал для вот это вот инструменты тепло и и он уже пора ходит по каждому из микрофибры с их вложенных они запрашивают вложенные в них микро сервис спрашивать на к матрице ты находишься и формируется такое таяму но опять же яму в одну я уже руками его не делаю вот поэтому я с одной стороны как бы людям и советую и даже придумал как тариф разместить в дела проныре где-нибудь внутри на джоби там бывает сервис еще вот чтобы в отдельные во всем нам спейси не держать и он бы не завалился когда вы несколько приложений где плелись он же один вот соответственно как бы я советую на с другой стороны я понял что похоже нужно уходить в сторону как от своего программирования деплоя благо решение такие есть есть на питоне есть ногой есть на скале это гораздо удобнее вы можете проваливаться в код по ссылкам и формируем формировать свое окружение уже именно в коде что спасибо большой алексея за его доклад"
}