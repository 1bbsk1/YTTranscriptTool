{
  "video_id": "eEHZN1TWF-A",
  "channel": "HighLoadChannel",
  "title": "Explaining the Postgres Query Optimizer / Bruce Momjian (EnterpriseDB)",
  "views": 461,
  "duration": 2381,
  "published": "2017-04-28T04:21:05-07:00",
  "text": "бреус не нуждается в представлении с 91 года он входит в core team разработчиков postgresql и делает одни из лучших в мире технических докладов об этой судьбе мало какой доклад сразу даст столько же представления об архитектуре и устройство postgres как этот брус сейчас системе называется postgres оптимизатор очереди gres это не то что написано у вас в расписании сейчас вот тот доклад который указан у вас в расписании где-то начнется часа в три вот мы поменялись с этим доклад будет закончена в 2:30 который должен был быть сейчас кто и слышали предыдущую гораздо проще интересное но не настолько сложное как предыдущие поэтому здесь проблем особенных не будет вот за 35 минут я думаю мы уложимся завод плюс монтян я забыл работаю в компании дар проезд baby эта презентация вместе с остальными тридцатью моими презентациями находится на этом сайте домой сайт если вы в google и прогуглите меня молча то найдете этот сайт легко так если какие-то вопросы до начала презентации нет хорошо итак это презентация предыдущая презентация а программе сиси как обеспечить одновременную работу пользователь а теперь я расскажу о том как мы оптимизируем очереди оптимизируем запросы sql как посада дает вам помощь определение того как эффективно получать даром не знаю кто из вас работал до эры school потому что до того было сложно таттва вы должны были понимать когда ты распределяют когда на и распределяются какие там индексы и так далее и всю эту информацию нужно было встраивать ваше приложение когда появились и реляционные базы данных у вас появилась возможность направлять запросы на базу данных а база данных уже сама решает каким образом исполнять этот запрос на примере имеется пользовательский терминал работает это все времена ли приложение приложение делает запрос библиотеки библиотека отправлялись по сети запрос на сервер базы данных и сервер отвечает приложению все просто вот просто несколько более подробно самые внутри базы данных имеется множество этапов которые выполняют этот запрос 1 парсер рерайт но самое интересное вот здесь мы об этом поговорим это optimizer и вот именно здесь работает та часть системой которая является самой интеллектуальной самой умной которая решает как вам отправить данные быстрее всего вот я увеличиваю эту часть вот у нас есть optimizer который определяет как вам отправить данные по быстрее и вырабатывает соответствующий рецепт для это что у вас есть обнимайся в базе данных это означает что вам не нужно оптимизировать свое приложение то есть ваше приложение должно знать индексацию не должно знать что находится в той или иной колонки она просто делает запрос основное выполняет мозазавра вот это интеллектуальная часть нашей системы ну сейчас мы и поговорим мозг такое решение должен принимать optimizer screen сканирование подобно joy я поговорю об этом давайте поговорим о методах каким образом получать данные вот есть три варианта первый вариант очень простой это последовательный скан это означает что я сканирую все данные выбираю те величины которые отвечают требованиям сначала мы ну я создаю тут небольшую табличку временную табличку символ и яндекс этой таблице как и в предыдущих презентация вы можете запустить sql который я здесь показываю в последней строчке на вашем компьютере и получить все что здесь выдается играл еще мы создаем одну функцию помните я говорил что у нас есть 3 способа доступа как система выбирать как система выбирает способ таким образом давайте посмотрим я беру временную таблицу которые первая колонка и и какие-то данные случайной выборки посмотрим на эту таблицу 199 строк в этой таблице с буквой 9 с буквой с 8 строк украсит и вне ну а у меня только есть только один ряд с буквой а и и один ряд с буквой один одна строка с буквой могу даже посмотреть процентное соотношение годов с другой соседей вот 78 процентов моих строк есть с буквой пи 3 процента с буквой s3 siii так далее так далее сверху донизу и такая дистрибуция для нас очень важно вот для optimizer а давайте посмотрим практический пример используем команду explain чтобы посмотреть если я рассмотрю выдам команды с ну поиск всех строк укрепи какой метод выбрать тогда я буду сканировать индекс а если идти которые где то по середине таблицы тогда тоже сканирование индекса а если букву кей которая в самом низу тогда тоже я будет ну и что скажете мы ничего не делая у меня очень разные величины для поиска результат получается один и тот же кан индекса а почему потому что оптимизатор не имеет статистике которая могла бы ему сказать что это очень частотные буква ok это очень редкая буква поэтому я выполняю команду и эта команда дает статистику по таблицам помните я говорил о функции auto ваку of the vacuum не только выполняет функцию вакуум ну и она выполняет функцию и долорес автоматически хотите выполнять она лайс пожалуйста можно и без ну если вы модифицируете ваши данные в таблицах вот от факел будет анализировать снова и снова и обновлять вашу статистику автоматически итак когда я получаю статистику с помощью команды канала из теперь если я выбираю пик да у меня получается последовательный сканер sequences к можем он смотрит данные подряд вот считывает все строки почему потому что индекс здесь не поможет если я через яндекс буду смотреть я просто двойную работу буду проводить сначала индекс потом опять что-то посмотреть все строки все страницы поскольку и 78 процентов строк и так имеет букву пи зачем мне еще смотреть индекс рассмотреть следует сразу и оптимизаторы то знает когда у нас есть последова и тайском вы последовательно рассматриваете таблицу система распознаёт это и автоматически заранее считывает таблица и последовательной скан в базах данных работает очень быстро нужно ли логе проверять в этом случае вы были на моей предыдущей презентации мы не проверяем луки пола что каждая строка имеет достаточной информации по оси у мы понимаем этот ряд на это строка видимо-невидимо в других базах данных без сервисе есть команда думы или онду у нас этого нет все данные старые и новые находятся в одной и той же таблицы когда вы и последовательное сканирование делать вы их видите но хорошо да хороший вопрос потому что иногда люди спрашивают как же а старые новые данные хранятся рядом не последовательно scania это все рассматривается подряд и когда производительность может понизиться потому что все это идет статистика забирается у нас во время исполнение команды как-то наиболее частотных величин и создаем 100 граммов 100 как бы областей италии мы не через последовательный скат делаем а через случайную выборку вам не нужно в общем то все считать для того чтобы выбрать 100 наиболее частых объектов чтобы оптимизировать самом деле если посмотрим мы этот запрос он знает что есть 199 строк 199 если мы вернёмся назад это мы выйдем до 199 последовательный я очень понятно блин а случайной выборки будут выбирать и поэтому он не точно будут такие величины совпадать но не будут очень близкими ну хорошо пойдем буква п очень частотную его а если женя другую букву д три процента по малых было что-то в этом роде три с половиной если я проведу поиску длится поскольку у меня и статистикой аналог система выбирает уже другой скан beep beep beep что он делает этот скан он идет в яндекс и создает bitmap всех страниц которые имеют соответствующий параметр у этого нам не нужен а значит вы повторно рассматривать страницы если на странице есть но может быть есть несколько раз попадает это самая величина но если мы видим его хотя бы один раз все мы уже предоставляет туда доступ а если кей очень редкая буква в общем то она один раз всего встречается в этой таблице это мы проводим сканирование индекса одна строка всего лишь есть такая вот таким образом как видите вот таким образом postgres использует статистику для оптимизации поиск вот я эту информацию все хочу ввести сюда вот у нас запрос который просматривает мою таблицу и вызывает функцию которая ранее объяснил для каждой буквы выбирается тот или иной принцип первая строка вот слайд который может быть вам полезен здесь мы видим что всех величин и сыр и да пей вот сколько у меня раз встречают зовите в величина и далее какие варианты сканирования выбирает обнимайся вы видите вот выбирается последовательной скан вы видите здесь совпадений отведаю имеются bitmap скм и а и туки здесь есть одна ошибка потому что и встречается два раза а здесь показана только один отлить уже вам несовпадение здесь вы увидите уже некоторые расхождения не вполне понял если что наш вопрос есть ли вы принимаете решение о том что использовать какой метод использовать кто это решает postgres имеет некоторые заранее определенные переменные конфигурации которые сравнивают стоимость последователь маска она случайно вас к на и зависимости от аппаратных средств можете это тоже варьировать мясо sti допустим имеет разные стоимость и стал то 6 используя там мы 4 разница счастью вы меняете вместо четырех выставляете там 1 и 2 десятых кроме того на некоторых устройствах кристи работает так на других по-другому и вы можете указывать что вот здесь допустим вы присваиваете 1 и 2 она этом магнитом диски и 4 или выше то есть вы можете контролировать эту границы postgres не оценивает скорость потому что она бывает разной еще какие-нибудь есть ваших вопросы были итак еще раз скажу видите по мере снижения частоты меняется и метод поиска теперь что еще здесь интересно стоимость вот стоимость вот этих операций начинается с 8 из 11 12 наконец 13 а если мы optimizer отключу если мы настроим систему чтобы оптимизаторам только индексы сканировал и все и больше ничего что произойдёт в этом случае если мы снова запустим операцию то мы увидим виде индекс к везде то стоимость начинается от 8 как и раньше но поднимается вверх гораздо быстрее 12-15 19 еда заканчивается на 39 это оценки примерно а не может быть никто не точно соответствуют реалиям вот если вы включите интеллектуальные средства если вы говорите optimizer у и принимайте решение тогда вы видите стоимость некоторых операций будет высокой и у вас замедлится быстродействия вот видите 39 или 13 разница есть я думаю что это ярко показывает вам почему optimizer помогает вам что именно год оптимизирует почему это полезное средство некоторые используют дикторы использует ману optimizer просто облегчает работу программиста роза зная вот эти вот вещи ускоряет и если у вас меняется распределением так если мне нужно повысить допустим количество часов езды увеличивается то автоматически у вас меняется и все остальное сейчас тут нас меняется да и для буквы д допустим билет для других величин автоматически меняется и метод поиска автоматическим и так это не все у нас есть еще разные методы joy методы слияния это традиционно для реляционных баз данных показывал вам что это все поддерживается горло все корпоративных базы данных есть четыре типа слияние join есть настя 2 которая использует либо последовательно искали паскаль индексов есть ешьте он мечтает я сейчас поговорю обо всех этих методах для начала создадим временную таблицу который называется сму-1 такими параметрами 6 строго потом вторая таблица simple 2 261 таблица большое другая поменьше вот индексов нет статистики нет ничего нет все пусто вот все и далее если я сделаю запрос если я скажу проведите слияние этих таблиц через насти глуп все понятно выглядит вот так когда я сравниваю каждый странах со всеми другими строками статистики нет статистика не знает что там записывал написанными что-нибудь это конечно работает медленно если таблицы маленький нормально но система не знает насколько большой это все восемь шесть строк 52 она не знает статистики и система выбирает ность глуп вот как это все выглядит если я говорю более 33 тогда возникает почти хочу и выглядит вот так хэшируется одну сторону и виду поиск с другой стороны и вот в как выглядит псевдокод что если я на меняют две таблицы не имея информации о условия сейчас она будет готова черта идет вот и так и обвиняли таблице не без ограничений в данном случае этим сортировку двух сторон осуществляется на подбор обеих сторон хорошо есть таблицы при этом большие мы проводить сортировку двух сторон что соответствует чему это соответствует тому то это соответствует этому нет можно сделать сюда начинает смотреть отсюда соответствия соответствия нет соответствия вот здесь мест соответствия таким образом осуществляется вот такая параллельная подборка вот это псевдокод для такого объединения слияния что если мы поставим разит 1 до вопроса 2 что имеется нет помните вот здесь образец 2 бы верху образец один был внизу неважно в порядке здесь безразлично все делается наиболее оптимальным путем вне зависимости от того каким образом насущная запись теперь посмотрим да статистику вы удивитесь насколько система становится умнее когда не работает таким образом вот это у нас имеется дружины теперь это хожу система знает 200 с лишним строк здесь 260 строк здесь и в результате запроса получается гораздо быстрее если я сделаю авто я поближе покажу это новая функция в об адресе 91 способность делать offer join и если делать cross join я не знаю о таком ли вы с этим крошку это означает объединение всех строк тут получается месте отлуп а фактически потому что невозможно провести хеширование чего-либо если мы создаем индексом 1 были индекса у нас была статистика яндекса если добавляем алексей то опять заменяется здесь у нас мистер духу а при этом мы может также проводить и дык сканер помните есть два типа мест и глупо последовательный и фиксированные теперь мы проводим с индексированным сканом гораздо быстрее здесь я провожу сравнение по индексу а не по последовательности это псевдокод для индексного поиска что если можно посмотрим за год на эту колонку jiang если я попрошу сделать join чтобы там были одни только на букву а система вроде как не знает что-то по статистике нету таких где т.к. она попробует положит что там есть одна такая строка если мы а при вставлении с иксами в данном случае мы имеем афишу теперь мы знаем мы знаем что там немного а букв они там мы сделаем тут вот так же мы проведем соответствующую трудно такие вещи о которых разработчик часто не думы такие элементы поведения которые зависит от того как происходит работа заключение я хочу сказать вот что есть еще одна вещь которую пытаются управление это заброс который обычно делают ходжой если мы добавляем здесь ограничить ли лимит босс опустим мы хотим чтобы только из-за рака из этого запрос была завеса вместо ходжой на мы теперь делаем мест и блок насколько вы попросили прыгает ну строку если бы был было десять строк тут все равно был бы лес если было бы 100 строк то в этом случае скай хорошо сделаю хорошо и брать как system gold но вот вы дошли до точки как дань с ibm будет работать слишком долго и мы лучше сделаем хэш jouet создавал я на уникальный и такого в этом случае по моему нет давайте вернемся и посмотрим нет нет я не создавал уникального итак вопрос почему она считает что будет только то соответствие органов к другому такая уж эвристики по которой работает с gres я думаю что здесь делается предположение о том а когда как бы это лучше сказать ну собственно здесь этом конкретном случае мы здесь имеем образец 1 и при детство это цифры это центр который ведь у них очень и колонку вас град знаю что есть олю с грейси колонки к называется дисперсией колодок оказывается насколько велико мой ник разброс значений я думаю что если бы до было допустим два значения всего таблицы то в этом случае было бы понятно что там ожидается определенной поведение но а здесь на дисперсии является уникальной мы создаем некой индекса весь этот значение дисперсии колонки она дает на этой команды это не идеально это нету было ценный и полноты это не идеальный вариант но я вроде как достаточно и это лучше чем можно дать других разработках можно успешно статистикой плесени абсолютно точный но в конечном итоге важно то что большинстве случаев optimizer у не нужны идеальные цифры одевай заработка знать где идет отсечка от этого направлению к другому допустим если побеждают последовательные с карты то это самое главное не важно там по баллам нас болью идет превыше не только граница между диска на обед рабским и другими типами это на по сути дела единственно что результат так что когда вы отправляете 1000 на сервер есть и те которые не будут идти по оптимальному варианту но тем не менее их количество не будет достаточно большим для того чтобы кто-то заметил обычно если это значение похоже это любой вариант даст нам быстрый ответ проблемы возникать там где вообще нет или вы статистике систем работать вслепую и тогда как раз все замедляется мосгаз optimizer когда я только начал работать люк был далек от сегодняшнего состояния сегодня он является отличным примером того что можно сделать в плане оптимизации и все это удалось получить благодаря внесение изменений и улучшений тестированию и сегодня системы в общем весьма хороша но не идеально конечно никогда она не будет идеальной это собственно природа оптимизации которая таким образом определяет курс движения есть талон и колонка дисперсии в которой происходит агрегация общая я показывал вам что он определить значение если использовать предельные значения вы помогаете apтиcты зару пример какие-то prograf приложение открывают курсор берут 1 одну строку дали закрывает курсор если этого можно избежать он хорошо так сказать что вам нужна только одна строка тогда optimizer smart на эти листы клуб которому не нужно проводить сортировки и хэшировать а не тот вариант и где есть несколько строк то есть здесь как раз условие ограничение позволяют нам оптимизировать позволяет нам давать optimizer у храма цветом сколько на нужный рядов и это повлиять на то как быстро мы получаем результат вот собственно я и пошел концов своего доклада у меня остается время на один вопрос я уже несколько вопросов принял из аудитории не знаю остались ли еще вопросы ко мне очистка в сформирует ли трафик блогах но только мыши особых условиях почему давайте так подумаем если мы что-то перемещаем в процессе что генерит трафик то сколько можно отметить извините за есть дикторы операции который будут отражаться блогах особенно если у вас какое-то приложение с потоковой передачи но в большинстве случаев этого не будет поскольку вы что-то меняете на странице тока и неважно будет ли повторно из презрения или нет может при сдаче ска позже если вы из коры и приложения обычно этого не происходит это один из примеров того очистка помощи реплицируется вопрос акциях нет это связано со сложностью системы вот то что я показала в игры сисенто все это плотно сделан в оси логе мы рассматривали такую возможность но это настолько усложняя система что мы не нашли оптимального способа делать в общем время меня кончилась большое спасибо за внимание а еще есть один вопрос да еще есть вопрос повторить пожалуйста я не услышал если возьмите подготовили трансакция что получается 1 просто вопрос о том какую работая с подготовлен транзакциями а когда вы подготавливаете запрос мы по сути дела осуществить его разделения переписать оптимизируем неоптимизированный план мы сохраняем в относятся готовы осуждать выполнения мы не повторяем оптимизацию мы не повторяйте его повторное а разделение его передает существует новые возможности pro-версии на 92 этого круто вается о состоянии реке стандартных при правке и при подготовке там определяется что исполнитель обнаружил что константами другую чистота и в этом случае нацию константин отличается от новый"
}