{
  "video_id": "Ac2C2G2g8Cg",
  "channel": "HighLoadChannel",
  "title": "Эффективное использование ClickHouse / Алексей Миловидов (Яндекс)",
  "views": 32694,
  "duration": 3511,
  "published": "2017-12-11T03:36:19-08:00",
  "text": "привет меня зовут алексей я делаю crack house посколькy рам о работает отлично во первых сразу спешу вас обрадовать я не буду сегодня рассказывать вам что такое crack house я сейчас на мне надоело вот каждый раз рассказываю и наверняка все уже знают ведь правда же все знают отлично вместо этого я буду рассказывать какие есть возможные грабли как можно не правильно использовать crack house на самом деле боятся не стоит потому что мы разрабатываем краков как такую систему которую простая удобная работает из коробки поставил все никаких проблем но все-таки надо учитывать что система это специализированная и можно легко натолкнуться на какой-нибудь необычный сценарий использования который так сказать вы видят эту систему из зоны комфорта и так какие есть всякие грабли ну и в основном я буду говорить про очевидные вещи что все всем все очевидно всем все понимают и могут порадоваться что они такие умные но кто не понимает тем хотя бы узнают что-то новое значит первый самый простой пример и к сожалению достаточно часто встречается это большое количество insert of с маленькими бочками то есть большое количество маленьких концертов вот если рассматривать как приказ выполняет insert то вы в принципе можете за один запрос отправить хоть поток данных там на терабайт это не проблема и давайте посмотрим какая типично будет производительность на обряд таблица у нас с данными яндекс метрики хит и стал опять каких-то столбцов 700 байт в несжатом виде и будем вставлять по хорошему так правильно большой по 1 по одному миллиона строк значит вставляем соблюсти поменяв 4 получается пол миллиона строк секунду отлично в реплицирует a blues чуть поменьше примерно 400 тысяч строк секунду и ясно включить коронную ставку кстати интересно кто его слышал что в кли хауса есть кого ровная ставка поднимите руки хотя бы ну несколько человек есть это замечательно потому что это на самом деле даже недокументированная возможность так что те кто знают те молодцы получается чуть меньше но все равно приличную производительность 250 тысяч строк секунду а что у нас будет ясно делать плохо значит вставляем по одной строке в таблице r4 и получается 59 строп секунду этого сколько в десять тысяч раз медленно и кажется в реплика taters 3 6 строк секунду а если еще корм включится получается две строки в секунду по моему это какой-то кромешной отстой как можно так тормозить вот у меня на футболке должна написано что treehouse он не должен тормозить тем не менее вот бывает иногда а собственно почему так происходит на самом деле это наш недостаток мы могли бы вполне сделать что все работало нормально но не сделали и мы это не сделано потому что для нашего сценария это не требовалось у нас и так были бочче просто к нам на вход выступали bacci и никаких проблем вставляем и все нормально работает но конечно возможно всякие сценарию например когда у вас куча серверов на которых данный генерируются и они вставляют данный не так часто но с вами получается частые вставки и нужно этого как-то избежать с технической точки зрения суть в том что когда вы делаете insert в cliff house то данные не попадают ни в какой там менты был у нас даже не настоящий лак стара как мир 4 а просто мир 4 потому что нет ни logo нимим тайбл мы просто сразу записываем данную файловую систему уже разложенные по столбцам и скажем если у вас 100 столбцов то будет больше двухсот файлов надо записать в отдельную директорию все это весьма громоздко и возникает вопрос как же все-таки делать правильно ясно такая ситуация что то нужно все-таки ссылки нужно же как-то записывать данные в crack house первый способ самый простой это использовать какую нибудь распределённую очередь например кафку просто вынимаете данные сказки скажем патчами 1 секунду и все будет нормально и вы записываете все нормально работает но недостатки то что кафка это еще одна громоздкая распределенная система я еще понимаю если у вас в компании уже есть кафка это хорошо это удобно но если ее нет то стоит трижды подумать перед тем как тащить еще одну распределенную систему себя в проект и поэтому стоит рассмотреть альтернативы вот такая олдскульная можно сказать альтернатива и при этом очень простая есть у вас какой-то сервер который генерирует ваши логин и он просто записывает блоге файл и 1 секунду например этот файл переименовываем открываем новый и отдельный скрипт либо по крону либо как в этот демон берёт самый старый файл и записывает в crack house я сортируют логе 1 секунду все будет прекрасно но недостаток этого способа то что если вас сервер на котором генерируется логику да ты сейчас-то и данные тоже исчезнут есть еще один интересный способ вообще без временных файлов скажем есть у вас какая быть рекламная крутилка или еще какое-то интересное там демона который генерирует данные и вы можете накапливать пачку данных прямо в оперативке в буфере и когда прошло достаточное количество времени вы этот буфер откладывается в сторонку создаете новый на в отдельном потоке просто то что уже накопилось вставляете в kohl's и в принципе тоже нормально с другой стороны данные тоже прикинул -9 исчезают скажем я свои просто ваш серу падет то вы эти данные потеряете еще проблема то что если вы не смогли записать в базу то вас данные будут накапливаться в оперативки или бы закончиться оперативка либо просто потеряется данные еще один интересный способ такой значит есть у вас какой-то серный процесс и он может отправлять данные в house сразу но делается в одном соединение скажем отправил эстетики запрос останки трансфер encoding сенсор тон и gear минут чанки не слишком можно уже не слишком редко можно и каждую строчку отправлять хотя будет ever had no флеминг этих данных тем не менее в этом случае данные будут отправлены в 3-х у сразу ecли хаусом будет их буфере завывать но тоже возникают проблемы что теперь вы потеряете данные в том числе и когда ваш процессу гнется и если процесс к хаусу бьется потому что это будет не завершенный insert a в хаусе insert и атомарные да некоторые указанного порога в размере строк в принципе интересный способ тоже можно использовать вот еще один интересный способ это какой-то разработанной комьюнити сервер для бочонка данных я на него сам не смотрел поэтому ничего гарантировать не могу впрочем и до совок ли хаоса гарантий никаких не предоставляется тоже open source но с другой стороны вы могли привыкнуть конектор вас стандарту качества который вы стараемся обеспечивать а вот до этой штуки ну я незнаю зайдите на git хоп посмотрите код может быть нормально что-то написали еще один способ это использование буфер таблиц достоинства то что это очень просто очень просто начать использовать создаете буфер таблицу и вставляется в нее а недостаток то что проблема решается не полностью если при вставке в таблице типами арчер и вы должны группировать данные скажем по 1 патча в секунду то приставки в буфер таблицы вам нужно группировать хотя бы до нескольких тысяч секунду если будет больше 10000 секунду то все равно будет плохо а ясно ставят патчами вы видели там получается сотня тысяч строк секунда по крайней мере и это уже на достаточно тяжелых данных ну это же буфер таблице не имеют logo и если с вашим серому что-то не так данные будут потеряны и в качестве бонуса недавно у нас клих а у себя появилась возможность собирать данные из кафки непостредственно существует движок таблиц кафка вы просто создаете и на него можно навесить материализованные представления в этом случае вам будет сам вынимать данные сказки и вставлять в нужные вам таблицы и особенно радует в этой возможности то что я делал и ним и это комьюнити фича и когда я говорю комьюнити фича я говорю без всякого без всякого презрения код мы читали review делали должна работать нормально еще сто неудобного или неожиданного просто приставки данных скажем если вы делаете запрос insert волос и value спешите какие-нибудь выражения вычисляемые выражение ну например на у скобочка открывается скобочка закрывается это тоже вы часто и мое выражение и в этом случае cliff house вынужден на каждую строчку запускать интерпретатор этих выражений и производительность просядет на порядки лучше этого избегать другой пример когда тоже мог быть некоторые проблемой это скажем если у вас в одном бача данные относится сразу куча партиций по умолчанию в хаусе портится по месяцам если вы вставляете бочку с каждым из миллиона строк а там данные за несколько лет то у вас там будет несколько десятков партиций и это пример наклонял потому что будет бочче в несколько десятков раз меньшего размера потому что внутри они всегда сначала разбивается по partition теперь рассмотрим второй вид проблемы этот типизация данных типизация данных бывает строгая а бывают строковое стоковое это когда вы просто взяли объявили что вас все поля типа string это отстой так делать не надо ну давайте разберемся как делать правильно в тех случаях когда вот хочется сказать что какое-то какое-то поле у нас строка и пусть там кликов сам разберется а я там париться не буду но все таки стал апертуре от некоторые усилия но сначала рассмотрим от чего это стоит вот например есть у нас api адрес в одном случае мы его сохранили как строка то есть там например 192 . 168 11 другой случае это будет просто число типа и in 32 32 бита достаточно для ipv4 адреса во первых как ни странно данные сожмутся примерно одинаковые там будет разниц конечно не такая большая так что по диску по дискам ввода-вывода особых проблем нет но есть серьёзная разница по процессор во времени и раздать а по времени выполнение запроса скажем посчитаем количество уникальных api адресов ясно микро цветы чисел получается 137 миллионов строк в секунду если тот самый виде строк то 37 миллионов строк секунду я не знаю почему такое совпадение получилось я сам выполнял эти запросы но тем ни менее примерно в 4 раза медленней а аяз ты посчитать разницу вместе на диске то получается все таки разница тоже есть и где-то на одну четверть потому что все таки уникальных api адресов достаточно много а если бы здесь были какие-то строчки с маленьким количеством разных значений то они по спокойно жались по словарю примерно в одинаковый объем так вот четырехкратное равенство времени на дороге не валяется может быть вам конечно и пофиг но я когда вижу такую разницу меня как-то грустно становится вот а как правильно делать но рассматривал разные случаи один случай когда у вас разных уникальных значений немного в этом случае используем простую практику которую вы наверно знаете и можете использовать для любых слободами это все имеет смысл не только для кори хауса просто записываете в базу числа числа вы идентификаторы конвертировать строки обратно может вас уже на стороне вашего приложения вот например есть у вас регион и скажем вы его хотите пытаетесь сохранить виде строки и там написано будет москва и московская область и вот когда я вижу что-то написано москва это еще ничего а когда и московская область как-то совсем грустно становится это за сколько байт вместо этого мы просто записываем число типа и in 32 и там 250 ну у нас 250 в яндексе у вас может быть по другому на всякий случай скажу что вкх все встроенная возможность работы с гиа базой вы просто записываете справочник с регионами в том числе иерархически то есть там будет и москва и московской области все что вам надо и можно конвертировать com на уровне запроса второй вариант примерно тоже самое но уже с поддержкой внутри клик хауса это тип данных и нам вы просто внутри нам и прописывается все нужные вам значения например тип устройства и там desktop мобильный планшет телевизор всего четыре варианта но недостаток то что надо периодически артрит добавили всего лишь один вариант делаем alter table на самом деле alter table включался бесплатен особенно бесплатен для таких in a move потому что данные реального на диске не меняются но тем ни менее alter захватывает блокировку на таблицу и должен подождать пока выполняется все select и а когда и только posted вольтер выполняться то есть все таки некоторые неудобства присутствует еще один вариант достаточно уникальный докри хауса это подключение внешних условий вы можете писать клика us числа справочнике ваша держать в любой удобной вам системе москва москва ль пожалуйста манга пожалуйста по сгрыз можно даже micro sim 1 свой запилить который будет поищите 5 давать эти данные и на уровне cliff house вы просто пишете функцию которая будет эти данные преобразовывать из чисел в строчке это по сути такой специализированный но очень эффективный способ выполнить join join с внешней таблицей причем есть 2 вариант в одном врать эти данные вот просто за каширу она полностью присутствовать в оперативке обновляться по с нектар периодичности в другом варианте если эти данную оперативку не помещаются можно их частично кэшировать вот пример я стендах с директ и там есть рекламные кампании и баннеры рекламных кампаний порядка наверно десятки миллионов и примерно помещается в оперативку банеров миллиарды и не помещаются и мы используем каширу имый словарь из mais quel источника единственная проблема то что все таки к шару мой словарь он у вас будет работать нормально если head right близок к ста процентам ясно поменьше то при обработке запроса на каждую пачку данных надо будет реально брать недостающий ключи и ходить забирать данные весьма искали профиль house я еще могу заручиться что да не тормозит про другие системы говорить не буду вот а в качестве бонуса словари это очень простой способ обновлять данные в хаусе задним числом то есть был у вас от четкую рекламным кампаниям пользователь просто поменял рекламную кампанию и во всех старых данных во всех отчетах эти данные тоже поменялись е100 писать строки непосредственно в таблицу то обновлять их будет невозможно ещё один способ том случае когда вы не знаете откуда вам взять идентификаторы для ваших строк можно просто за хэшировать причем самый простой вариант отобрать части четырех битных ешь единственная проблема то что ест и хэш 6 4 бедный то коллизии у вас обязательно будут ну почти наверняка потому что я создам строчка миллиард то вероятность уже становится ощутимой существенно больше 0 и скажем не очень хорошо было бы так вот хэшировать имена рекламных кампаний потому что ясно рекламные кампании у разных клиентов перепутаются будет что-то непонятно но я не буду говорить что чтобы не компрометировать и есть простой трюк правда для серьезных данных тоже не очень подходит но ясно что нибудь не очень серьезно это просто добавьте в ключе словаря еще и идентификатор клиента и тогда коллизию вас будут но только в пределах одного клиента и такой способ например у нас использоваться для карты ссылок в яндекс метрике есть у нас там url и мы храним хэши и мы знаем то что коллизии конечно есть не знаю правда где она точно знаю что есть но когда отображается страница то вероятность того что вот именно на одной странице одного пользователя какие-то url и слиплись и а то еще заметят этим можно пренебречь но в качестве бонуса многие операции тип аккаунт distinct достаточно считать просто искушай и с вами строки можно нигде не хранить другой пример из строки коротенькие скажем домены сайтов можно хранить как есть или вот скажем язык браузера ru два байта я конечно я красного очень жалко байтики но не беспокойтесь два байта не жалко пожалуйста храните как есть не партесь другой случай когда наоборот строк очень много и в них при этом еще очень много уникальных да еще и множество потенциально не ограничено типичный пример это поисковая фраза или url и поисковые фразы в том числе из-за опечаток скажем посмотрим сколько уникальных поисковых фраз за сутки и получится что их чуть ли не половина от всех событий и в этом случае вы могли бы подумать что давайте будем данное нормализовать читательницы в кадр и складывать в отдельную таблицу но делал так не надо просто хранить эти строки как есть лучше ничего не придумаете потому что ясно отдельно хранить то потребуется дело join а это джон это в лучшем случае случайно доступ в памяти я слышал в память поместится если не поместится то вообще будут проблемы а я 100 данных рации in place to они просто вычитывают в нужном порядке из файловой системы и все нормально далее скажем если у вас есть url и или еще какая быть сложная длинная строка стоит задуматься о том что можно считать еще какой-то выжимку заранее и записать в отдельный столбец до углов например можно отдельно хранить домен и если вам на самом деле нужен именно домен то просто используйте от столбец ауры будут лежать и вы к ним даже прикасаться не будет давайте посмотрим какая получается разница значит в клика уся есть специализированная функция которая вычисляет домен она очень быстро мы ее оптимизировали и честно скажу она даже не соответствует rfc тем не менее считают все то что нам надо вот и в одном случае мы будем просто доставать url и и вычитать домен получается сто шестьдесят шесть миллисекунд ой оставлять готовеньким дамян то получается всего лишь 67 миллисекунд то есть почти в 3 раза быстрее при чем быстрее не за того что нам нужно делать какие-то вычисления а из за того что мы читаем меньше данных вот скажем вот почему-то у одного запроса который медленно и получается больше скорость гигабайтах в секундах ну просто потому что он читает ваша гигабайт просто это совершенно лишние данные запрос как бы работает быстрее но выполняется за дольшее время айос и посмотреть объем данных на диске то получается что значит url 126 мегабайт а damen всего лишь 5 мегабайт получается в 25 раз меньше тем не менее запрос выполняется всего лишь в четыре раза быстрее ну это потому что данные горячая а если вы было бы на холодную наверняка был бы как раз двадцать пять раз быстрее из-за одесского вот вывода кстати вот ясно оценить насколько домен наша чем url получается как раз где-то раза в четыре почему-то на диске данные занимают 25 раз меньше кто знает почему да совершенно верно и зажатия конечно и орал сжимается и доме он сжимается начальство урал содержит кучу как он мусора в бф4 какой-нибудь случайное число и тому подобное вот ну и конечно стоит использовать правильные типы данных которые предназначены специально для нужных значений ну или которые сразу видно что под скажем если у вас айпи адрес я стою 1 4 хранитель 32-я сапего 6 to fix из трех 16 потому что опершись на др со 128 бит в то есть корейца прямо в бинарном формате вот что делать с а например у вас иногда ipv4 адреса иногда я пила 6 кто знает да можно просто хранить оба один столбец 1 4 другой допер 6 ну конечно есть вариант просто ipv4 отображаться пиво 6 тоже будет работать но если вам запросах часто нужен именно а пиво 4 адрес то неплохо бы засунуть в отдельный столбец еще заметит что лучше данная правда обрабатывать то есть поступает вам какие-то логе ссоры и может быть стоит их не сразу засовывать house hotel очень заманчиво ничего не делать и все будет работать но все-таки стоит провести те вычисления которые можно скажем версия браузера вот в некотором соседи vandeven на который я не хочется показывать пальцем может быть люди из этого отдела сидят в зале сейчас тем не менее там вот версия браузер хранится так вот как строка то есть 12 . 3 а потому что сделать отчет они берут эту строку делает на массив а потом 1 ринат массива естественно всё тормозит но я спрашивала почему так делать и они мне говорят мы не любим преждевременную оптимизацию вот а я не люблю преждевременную пикселизация так что в этом случае правильно разделить на четыре столбца тут не бойтесь потому что и так ли хауз каре хаоса тасс торцовой базы данных и чем больше аккуратных маленьких станциях тем лучше будет пять вариантов версия делаете пять столбцов это нормально теперь рассмотрим что делать с ты вас много действительно очень длинных строк каких на вид очень длинных массивов их не нужно хранить в хаусе вообще вместо этого вы можете сохранить греха вася так как катар эти длинные строки ну засуньте их куда-нибудь в какую другую систему например в одном из наших аналитических сервисов есть некоторые параметры событий и если на событие приходит больше очень много параметров мы просто сохраняем первые попавшиеся 512 потому что 512 не жалко вот ясно вы все-таки не можете определиться с вашими типами данных вы можете тоже записать данные в treehouse но во временную таблицу типа лог специально для временных данных после этого вы можете просто проанализировать какие у вас какое у вас там распределение значение что вообще есть и составить правильный тип и теперь рассмотрим ещё один интересный случай вот иногда у людей все как-то странно работает а я захожу и вижу такое и сразу представляется что это делал какой-то очень опытной умный админ у которого большой опыт настройки например майского версии 323 то есть здесь мы видим тысячу таблиц в каждой из которых записано остатка деревья чего-то не баяна чего на 1000 в принципе я уважаю чужой опыт в том числе понимаю какие страдания на этот опыт может быть наработан и в принципе причину боевыми понятны это старые стереотипы которые могли накопиться при работе с другими системами скажем в моей сам таблицах нету кластерного первичного ключа и такой способ разделения данных может быть отчаянной попыткой получить ту же функциональность другая причина это скажем то что всякий маунтенс операция типа альтеры набат над большими таблицами делать трудно все будет блокироваться хотя в современных версиях маска или уже проблема не такая серьезная или например micros формирование но об этом чуть позже вот в хаусе так делать не надо потому что во первых первичный ключ кластерной данные упорядочена по первичному ключу и иногда меня спрашивают скажем как меняется производительность диапазонных запросов в хаусе от размера таблицы и я говорю точно никак не меняется да никак не меняется то того что скажем было у вас таблиц на миллиард строка и вы читаете диапазон 1 миллион строк все нормально я со таблицы триллион строк и вы читаете 1 миллион строк будет то же самое почти то же самое вот автор их всякие штуки типа ручных портится не требуется потому что если вы зайдете посмотрите что там на файловой системой файловой системе вы увидите что на самом деле таблица достаточно такая серьёзная вещь и там внутри уже есть что-то типа партиций то есть ли house все делает за вас и вам не нужно страдать значит отрывка хаосе бесплатно я стоял или дроп колонн и маленький таблицы делать не стоит потому что если у вас скажем в таблице 10 строк или десять тысяч строк это совершенно не важно для house это в основном система который активизирует вот они latency так что 10 строк обрабатывать не имеет смысла правильно просто использовать одну большую таблицу избавьтесь от старых стереотипов все будет хорошо а в качестве бонуса у нас последние версии появилась возможность делать произвольный ключ парте цианирования для того чтобы выполнять всякие maintenance операции над отдельными партициями и наконец ясно вам действительно нужно много маленьких таблиц скажем реально бывает потребность для обработки каких-то промежуточных данных вам поступают какие тачанки и вам нужно выполнять преобразования над ними перед записью финальную таблицу до этого случая есть замечательный движок таблиц stripe log это примерно как тайне лог только даже лучше я снова про это не знали значит узнали сейчас теперь еще один анти паттерна который иногда встречается это же люди научены своим опытом это микро шарды суть в том что данное например вам нужно сортировать и у вас есть там пять серверов а завтра будет 6 серверов и вы думаете о как эти данные перри балансировать и вне а стартовых разбивайте на не на 5 шортов она 1000 например сортов и дальше отображаете каждый из этих микрофонов на отдельный сервер и у вас получится на одном сервере например 200 клик house of отдельно единство со найденных портах или отдельные базы данных но в хаусе то не очень хорошо так скажем аккуратно во-первых потому что один даже если насколько уса старается использовать все доступные ресурсы сервера для обработки одного запроса то есть есть ваш сервер какой-нибудь там например 56 процессор на фидер вы выполняется запрос который там одну секунду выполняться и он будет реально использовать 56 театр а если вы разместили там 200 гр и house of на одном сервере то получается что запустятся 1000 потоков я правильно посчитал не а 10000 потоков в общем все будет очень плохо другая причина это то что распределение работы поэтому детства сам будет неравномерное какой-то закончить раньше какой-то позже я снова всё это происходило в одном местности только house бы сам разобрался как распределить правильно данные по потокам и еще одна причина это то что будет у вас с процессом и взаимодействия по тисе пи данное придется сериале заводись и реализовывать и это огромное количество микрофонов просто неэффективно будет работать еще один антипатию хотя это трудно назвать антипа терном это большое количество предо грига ции вообще придвигаться это хорошо скажем был was the only app строковые вас агрегировать и стала 1000 строк и теперь запрос выполняется мгновенно все замечательно так можно делать и для этого даже в хаосе есть специальный тип таблицы агрегат он мертв 3 который делает она криминальную агрегацию по мере вставки данных но бывают случаи когда вы думаете мы будем вот так агрегирует данная щеток агрегирует данные и вот некотором соседнем отдельно тоже не хочется говорить в каком использовать таблицы типа сон orchestre для суммирования по первичному ключу а в качестве первичного ключа используют вот штук 20 каких-то столбцов я на всякий случай изменил имена некоторых столбцов для конспирации но в принципе примерно так и есть вот и возникают такие проблемы во первых объем данных у вас уменьшается не слишком сильно ну в три раза уменьшается например дело в том что три раза это была бы хорошая цена чтобы позволить себе неограниченные возможности по аналитике которые возникают я стану вас не агрегированные я содана агрегированные вы вместо аналитики получается всего лишь жалкую статистику какую-то вот то что особенно достается тут о столице люди из соседнего отдела ходят и просят иногда добавить еще один столбец первичный ключ то есть мы вот так вот игра герои ли данный а теперь хотим чуть больше но в хаусе нету altera первичного ключа поэтому приходится писать какие-то скрипты на си плюс плюс а я не люблю скрыв ты даже астане на си плюс плюс и ясно посмотреть для чего создавался crack house тони агрегированные данные это прямо тот сценарий для которого он рожден ясно вы используете кликов для меня агрегированных данных вы все делаете правильно я снова агрегируется ну это иногда простительно еще эти такой интересный случай это запрос из бесконечном цикле вот я иногда есть такое развлечение случайного его творение захожу на какой-нибудь products and service смотрю там чтобы процесс лист и каждый раз обнаруживаю что происходит что-то ужасное новгород такое но тут сразу ясно что можно было бы все выполнить в одном запросим просто пишите там you are all in и список и вот почему в принципе много таких запросов бесконечном цикле плохо но ясно яндекс не использоваться то у вас просто будет много проходов по одним и тем же данным но ясно индекс используется скажем есть у вас первичный ключ пару и вы пишете where you are all равно чему-то там вы думаете что от будет точечно читаться из таблица 1 орал все нормально но на самом деле нет потому что crack house все делает по пачкам когда ему нужно прочитать какой диапазон данных он считает чуть больше потому что индекс quickcal все разряженной этот индекс не позволяет найти в таблице одну индивидуальную строчку только диапазон какой-то и больно того данные еще и сжимаются блоками то что прочитать в какую-то одну строчку нужно взять целый блок и рожать его и получится если вы выполняете кучу вопросов у вас будет много пересечений таких и куча работы выполняться будет выполняться снова и снова и в качестве бонуса можно заметить то что в как хаусе не стоит бояться передавать даже мегабайта или 100 мегабайт секцию in вот я помню из нашей практики я снова москва ль там тогда уж кучу всяких значения акцию но сначала надо увеличить макс пакет сосед нормально а потом скажем передаем туда 100 мегабайт каких-то чисел москва ль съедает 10 гигабайт памяти и больше с этим ничего не происходит все работает плохо а второе это то что в хаусе если у вас запрос использовать яндекс это всегда не медля ни о чем full screen то есть даже если прочитать нужно почти всю таблицу он будет идти и последовательно читать всю таблицу короче сам разберется тем не менее есть некоторые сложности например то что in с под запросам яндекс не использует но это наша проблема и нам надо это исправлять ничего фундаментального тут нет будем чинить а еще интересная вещь это то что если у вас очень длинный запрос и распределённой распределенная обработка запроса идет то этот очень длинный запрос будет отправлен на каждый сервер держать а скажем 100 мегабайт запрос и 500 серверов и соответственно у вас будет посетить передано сколько там 50 гигабайт ну будет передано потом все успешно выполняться и довольно частый случай ясно запросы приходят из этой вот скажем сделаны в какой-нибудь сервис свой и если ваш сервис конечно кому-то нужен вы открыли опять и уже буквально через два дня смотрите и происходит что-то непонятно все перегружена и какие-то ужасные запросы приходят которые никогда не должны быть хорошо я тут одно ясно и вы открыли опять вам его придется резать обязательно вводить квоты какие-нибудь других нормальных вариантов нет и начал просто сразу напишу скрипты будут проблемой и в крик aussi есть специальные возможности то подсчет квад причем можно передать свой ключ кого ты это например внутренней идентификатор пользователя и квоты будет считаться независимом для каждого из них теперь еще одна интересная вещь это репликация на ручном приводе в принципе я знаю много случаев когда несмотря на тост африка все есть встроенная поддержка репликации люди реплицируют кли house вручную вот пожалуйста поднимите руку кто так делает ясно что осуждать не буду ну нормально не так много значит принцип такой что у вас есть какой-то план обработки данных и он работает независимо например разных дата-центрах вы одинаковые данные одинаковым образом записывается в к house как бы правда практика показывает что данный все равно будут расходиться из-за каких-то особенностей вашем коде надеешься в вашем вот и периодически вам все равно придется их вручную синхронизировать ну например раз являясь отмены делают пирсинг пожалуйста но на самом деле гораздо проще использовать встроенную в какао с репликацию но тут может быть некоторые противопоказания потому что для этого нужно использовать звуки пер я ничего плохого круза кипер говорит на всякий случай не буду в принципе систему рабочая но бывает например то что люди не использовать звуки пер из-за java фобии ну что cliff house такая хорошая система написан на си плюс плюс все можно пользоваться все отлично будет а звуки пива но на я я как-то даже не хочется смотреть ну тогда пожалуйста мастер аппликации на ручном приводе использовать и что можно заметить это то что такое хаус это практичная система она учитывает ваши нужды если у вас даже репликация на ручном приводе вы можете создать distributed таблицу которая смотрит на ваши ручные реплики сама делает между ними failover и есть даже специальные опции которые позволяют избежать флопов даже если ваши реплики систематически расходятся далее могут быть проблемы если вы используете всякие примитивный ты был angels cry house это как такой конструктор и там есть куча разных движков таблиц для всех серьезных случаев как написана документация используется таблица 7 место north 3 а все остальные это так для отдельных случаев или там для тестов и что стоит заметить то что в таблице r4 даже вас вовсе не обязательно что у вас было была какая-то дата и время все равно можете использовать я занят даты и времени пишите что дефолтом 2000 год это будет работать и ресурсов не будет требовать и кстати в новой версии сервера можно даже указать чтобы вас было костанае парте цианирование без вообще какого-то ключа партиции это будет то же самое с другой стороны можно использовать примитивные движки таблиц например залить данный один раз посмотреть покрутите удалить можете использовать лак или скажем хранение маленьких объемов для промежуточной обработки то stripe лак или тайне лог memory можно использовать если маленький объем данных и просто покрутить ученые оперативки далее клика ус не очень любят перрин нормализованные данные вот типичный пример это огромное количество ров каких-то и вы их засунули в соседнюю таблицу а потом решили с ними дел join но это работать не будет как правило потому что калле house поддерживает только хаш join то есть join с хэш-таблицы в оперативке я сам оперативки не хватает для подмножества данных с которыми надо соединять to join выполнить не получится значит я содана и большой кардинально sti не партесь хранить их в dio нормализованном виде урну и прямо in a place в основной таблицы еще парочка примеров но я уже сомневаюсь антипа терна это или нет скажем в хаосе есть один такой чуть ли не самый известный недостаток он не умеет апдейты в некотором смысле это даже хорошо есть у вас какие-то важные данные там я не знаю бухгалтера и некоторых в отправить не сможет потому что а в дуэтов нет но есть некоторые особенные способы которые позволяют делать апдейта как в фоне например таблица типа реплейсер 4 они делают отдать во время фоновых мир джей вы можете это форсировать с помощью артмастер но не делать это слишком часто потому что это будет полная перезапись партиций вот распределенные join и включался тоже плохо планируется или скажем я бы не рекомендовал использовать house для громоздких вычислений но я-то не совсем так потому что мы уже отходим от этой рекомендации и у нас недавно добавилась возможность право применять модели машинного обучения в хаосе котбус и это меня беспокоит потому что я думал какой ужас это ж сколько тактов на байт получается в каком из обычного состояния то там ну короче мне очень жалко такта на байт вот но не бойтесь вставьте крюк house все будет хорошо ясно что у нас есть сообщество кстати сам часто это вы и я снова с какие-то проблемы вы можете хотя бы зайти у нас чатик и надеюсь что вам помогут алексей спасибо судя по времени окончания выступления понимать что на вопрос он не хочет отвечать я хочу от вас один вопрос один вопрос да наша вы не из индекса пожалуйста да спасибо за доклад у такой вопрос а куда пожаловаться на падение клик хаоса можно жаловаться мне листа прямо сейчас да у меня и я недавно начал использовать клик house сразу уронил интерфейс вам повезло чуть позже я уронил сервер селектор маленьким у вас талант я открыла бак на гитхабе но его проигнорировали посмотрим смотрите на конференции highload танцуя люди и смеясь выходят из зала запомните этот момент 2017 год сложные вопросы есть да все с одну секундочку вот возьмите микрофон и не стесняйтесь не очень не отказывать алексей для обманом заманил в нем доклад обещав рассказать как вода на и внутри жмете давай за три минуты очень просто это я еще вчера понял vaper больше конкретики но там нет никаких хитростей ужасных как в твоём сфинкса удалял кодирования нет хорошо хотя по блокам по умолчанию используется за 4 можно включить 200d блоки вот 64 килобайта одного мегабайта зависимости от блоков просто сырые данные да ну не совсем сыр это мотивчики которые скажем я сова столбец там числовой там вот просто числа подраться ложные массивчик а мы все понятно вычеркнул бы я тебя из твоего из своего доклада ног нечестие уже доложил тропа 1 раз алексей вот пример который был с unique как там над айтишниками ну что что и никак сект по строкам дольше считается чем по числам и так далее а если мы применим финт ушами и будем кастить момент вычитки ну то есть вы вроде как бы сказали что на диске она у нас не сильно различается вот если будем читать диск строки кастить и и тогда быстрее у нас агрегаты будут или нет или мы все-таки не значит и здесь выиграем что вы тестировали это но почему-то не указали в я думаю что она будет даже медленнее чем без карт а потому что в одном случае a5 rs на три строки распарсить у нас конечно включался парсинг айпи адресов тоже оптимизирован мы очень постарались но все-таки там же у вас прямо числа записано в десятичной форме очень неудобно с другой стороны функция веник экз акт будет настроках работать мятными не только потому что это строки но ещё и потому что выбирается другая специализация алгоритма строки просто обрабатываются по-другому а если взять и но более примитивный тип данных типа там записали юзера иди который у нас in the записали в строчке потом скостили будет веселье нет я сомневаюсь я думаю особую должны грустнее потому что все таки парсит числа это серьезное управлял вот не окажется вот у этого коллеги был даже доклад на тему того как сложно партия числа в десятичной форме avast и нет спасибо алексей большое спасибо за доклад и еще большое спасибо за клик хаусом у меня такой вопрос насчет планов есть планы какой-нибудь фичи для апдейта словарей не полностью то есть частичная перезагрузка отдохнуть и по возможности задать стамбуле в мае съел то есть аппетит after и вот чтобы загружались только эти данные слова такой очень большой очень интересная фича и вы окажется какой-то человек предлагал ее в нашем чате после должна это было вы были вы не думаю что я но вот отлично теперь 2 получается запроса и можно неспешно начинать делать но сразу вас предупрежу что эта фича довольно простая для реализации то есть по идее нужно просто в таблице написать номер версии и даже делать воротам версия меньше такой-то а это значит то что скорее всего мы делать ее не будете ну не совсем то есть может быть будем может быть мы предложим энтузиастом вот скажите вы энтузиаст да но к сожалению не все плюс плюс коллеги ваших на си плюс составляют писать найдем какой-нибудь барбарис уговорить спасибо здравствуй спасибо за доклад здесь вы упоминали что playhouse очень хорошо потребляет все ресурсы доступны ему и вот докладчик соседней с люкс авто рассказываю про свое решение для почты россии рассказал что им очень понравился клик house но они не использовали его в место своего основного конкурента именно потому что он сжирал без процессор и они вот не смогли его воткнуть там в свою архитектуру в свой звук и пирс докера мечта там такое соответственно есть ли возможность все-таки как-то ограничить клика в том чтобы он не потреблял все все все что ему становится доступным да можно и очень легко если хотите чтоб наш лидер потреблял просто писать с от mac стресс равно скажем единица и все будет в одно ядро выполняет запрос причем можно разным пользователям указать разную эту настройку так что никаких проблем и коллегами из двух софта передайте что нехорошего что они не нашли это настройка в документации пальцы здравствуйте хотел поинтересоваться с таким вопросом уже не первый раз слышу что многие начинают использовать playhouse как хранилище для логов от на докладе погорели что не делайте так не храните длинные строки как врата то есть можно но сложно предсказать короткой во-первых логе это как правило не длинные строки бывают конечно исключения то например какой нибудь все раз там написано на яве китая так сапсана лакируется и так бесконечном цикле заканчивается места на жестком диске но вы понимаете вот в этом случае очень легко я со строки действительно длинное ряжских решение там недавно была клик клак house храним логику из cabernet типа то есть принципе норм да нормально ну что значит длинная скажем на десятки киловатт это плохо а килобайт ну нормально так вот я хотел бы поинтересоваться я уже в чатике спрашивал но не помню получили ответ планируется ли как-то расширять секцию из ну на манер сети пока нет то есть county black спросилась пока не думали секция виз она у нас несколько несерьезно а как такая маленькая фича по не понял спасибо и на первом ряду последний вопрос и 7 билета спасибо за доклад очень интересно такой глобальный вопрос планируется ли делать ну может быть в виде каких-то заглушек из целей все таки минификации удаление данных обязательно это наша первая задача у нас в очереди мы сейчас активно продумали как все делать правильно и стоит начинать нажимать на клавиатуру и вопрос повредит коктейльная производительность системы либо нет мы вставка будет так же такая же быстрая как и сейчас мы планируем так то что возможно что сами деле ты some old и будут очень тяжелыми но зато это никак не повлияет на производительность и реактор и производительность insert of такой трейдов и еще вот маленький вопрос на презентации вы говорили то что primary key поднес вопрос по primary key успешно нас есть подстричь зонирование которое по молчанию месячная правильно и когда мы сдаем диапазон дат которые укладывают сумеют что у нас считывать столько этап ратиться верно и такой вопрос если мы не можем выделить какой то прям реке это правильно его делать по именно по полю дате для того чтобы меньше было фоновом режиме перестройка вот этих вот данных чтобы они ложились уже у порядочно ясно у вас нету диапазон их запросов и вы даже не можете выбрать никакой первичный ключ стали все-таки засова с первичный ключ дату для совершенно верно смысл мозгу может быть положите первичный ключ такое поле по которому данные будут лучше сжиматься если они будут отсортированы по этому полю например идентификаторы юзера например ходят там один близкими от времени на один и тот же сайт в этом случае кладете юзер идеи и время и вас данные будут лучше сжиматься расчет даты если у вас действительно нет и никогда не бывает диапазон их запросов по датам то можно не класть на тоф первичный ключ хорошо спасибо большое спасибо алексей да кстати если у вас остались вопросы и вы хотите еще поговорить покры house а то прямо сейчас через две минуты в четыре часа мы готовы ответить на вопрос это состоится около зала москва там поднимайтесь на второй этаж и рядышком мы будем отвечать спасибо большое"
}