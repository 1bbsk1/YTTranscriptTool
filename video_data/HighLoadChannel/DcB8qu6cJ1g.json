{
  "video_id": "DcB8qu6cJ1g",
  "channel": "HighLoadChannel",
  "title": "Принципы автоматического масштабирования приложения в AWS / Антон Регеда (Juno)",
  "views": 573,
  "duration": 2351,
  "published": "2017-04-22T14:47:52-07:00",
  "text": "и наш первый доклад будет о том как правильно постелить ваши сервис если вы используете amazon и vs так чтобы не платить лишних денег так чтобы у вас не было простоев и других проблем с amazon поприветствуем антон риги до всем привет собственно маленькая водная все кто знает что такое ws amazon web services отлично кто туда что-то диплом круто да и кто знает что такое авто скиллинг отлично может быть что-то будет для вас но вы собственно принципы автоматического масштабирования ws немножечко себе я около пяти лет занимался архитектурой в lingualeo таком онлайн сервисе популярна в россии сейчас я занимаюсь инжиниринга в компании джуна это такой молодой стартап с израильской американскими корнями в общем бьемся супером лифтом и подобными ребятам окей что такое масштабируемость масштабируемость это способность системы да правильно обрабатывать производительность пропорционально своим ресурсов ну предположим вот этот стул масштабируем или вот эта комната она масштабируема до важно понимать что такое масштабируемость масштабируемость это когда у нас есть а производительность бы ресурсы да круто когда она вот по этой линии идет до мы добавляем больше ресурсов нашей системы становится более производительно плохо когда у нас работало два сервера мы добавили 3 производительность остается на том же месте это говорит о том что что то у вас идет не так да скорее всего производительность опять же этот два параметра можно мерить это ну что там латынь сюда и рпс на количество request так вот если мы добавляем ресурсов то мы говорим что мы можем больше делать рпс производительность при этом должна оставаться константной ну либо становиться куча да там меньше латынь все возникает в общем проблема в том что в мире дайв вот программирование deployment а там не знаю важно думать не только о производительности но и ресурсах которые в вашу систему будет утилизировать немножечко теория даже чуть skill up skill up это вертикальное масштабирование до у нас есть applications там blimp что-то там работает у нас возникает проблема с тормозами мы добавили еще один там сервер в ренне сервера процессор до в рамках одной физической машины и у нас стало все круто но нужно понимать опять же ресурсы ограничены представьте google который работает на одном сервере но это по моему фантастика более того это проблема отказоустойчивости google который работает на одном сервере в один миг этот сервер падает просто было больше нет с нами увы и опять же это дорого каждый ресурс и несмотря на то что с каждым годом там вроде дешевеет памятью кокаину иметь большой компьютер это дорого не да дорого не только его иметь но и там обслуживать все такое скейл out это горизонтальное масштабирование когда мы имеем несколько серверов да то есть у нас был observer с двумя sign up observer четырьмя si peu теперь 2 серия по 20 для чего для того чтобы те самые ресурсы в которых мы ограничены сделать их безграничными да то есть мы говорим что теперь ресурсы для нас чуваки не проблема все мы короче можем там тысячи серверов но в этом есть проблема эти сервера они как-то взаимодействуют между собой да они взаимодействуют с другими системами они в первую очередь взаимодействуют по сети да но проблема сети в том что это первую очередь тайм-аут и не нужно считать что он мы сервера подключили по сети все таймаутов не все круто нет это в первую очередь тайм-аут более того проблема неравномерной нагрузке у нас тысячи тысячи серверов и так или иначе они работают неравномерно конечно там были доклады вот предыдущем не там праха прокси и все такое но это не супер проблема но эта задача делать систему с равномерной нагрузкой более того drops неизбежен если у вас тысячи серверов 1000 серверов должны одинаково сконфигурирована за диплоидный все такое да то есть здесь в ауте нужно научиться управлять производительностью до ресурсами мы не ограничены производительность у нас отличная но чтобы она была нужна этим управлять автомасштабирования автомасштабирование это способность системы самостоятельно решать сколько и нужны ресурсов да не мы там сидим мы говорим ну давайте мы там 50 серверов выделим нет мы горим что система сама должна зачем затем чтобы наша производительность согласно ресурсом была пропорционально до чтобы не было каких то проблем с плохой утилизацией немножко ремарочка что нагружается вашей системе вы должны для себя в первую очередь решить что загружается загружается себе нагружается network нагружается очередь да то есть растет безгранично может быть у вас нагружается диск вас там файловый стараясь который вы оплатите картинки диск не безграничен ресурсы не безграничны вам нужно больше дисков выделенные ресурсы в 60 процентов случаях на системах ресурсы выделяются по принципу есть пиковая нагрузка какая-то да и мы знаем чтобы эту пиковую нагрузку выделить нам нужно 100 себя отлично но проблема-то в том что трафик неравномерный к вечеру он больше ночью вы просто его и да и при этом мы понимаем что ресурсы утилизируется очень плохо есть всякие хакида там запускать что-то ночью на этом сервере не знаю там девелоперские какие-то процессы но это на самом деле бывший продакшен должен быть продакшеном у сервера должна быть конкретная роль которую он выполняет в общем тратите ресурсы впустую по сути деньги у нас еще была такая проблема новый год все как бы кайфуют отдыхают но новый год для маркетинга это самое лакомое время потому что они могут там configure какие-то настройки с продажами скидки делают пользователи как бы хавают и начинают больше генерит трафик данном но разработчики они под запустили пять серверов и отдыхают система упала трафика больше пять серверов не выдержала прибежала эти суммы маленькой рекламы и сказала давайте чуваки еще один сервер подымет но повалялись подняли downtime схватили мы начали думать что делать это был с авто скиллинг эта способность системы самостоятельно выделять ресурсы по ту нагрузку которую вы имеете да то есть правильно выстраивать пропорцию между ресурсами и производительностью по сути как бы нагрузки и ресурсы они вот тут нога в ногу методологии авто скиллинга первое когда трафик заранее известен все очень просто балансер два сервера двадцать восемь часов вечера не за 25 декабря об сервер поднялся отлично когда нагрузка не известно у нас слов bouncer два сервера по 60 процентов нагружены по 80 процентов нагруженный об 3 сервер до перри балансировали со временем нагрузка спала сервер убрался предсказывающие нагрузку ну на самом деле это был сшит потому что мы понимаем что если что-то делать понятно предсказывание нагрузки это наверное для более крупных компаний какими-то магическими способами выясняю щий что у них там через 50 минут будет трафик плюс 30 процентов bbs миф номер 1 автомасштабирование защитит от diedas никогда автомасштабирование защитит adidas представьте эту конференцию да вот для нас там выделили комнаты обед шатер и вместо нас прибегают суда тысяч овец однотипные овцы заполняют комнаты мы не можем через них протиснуться ok организатор решают нам нужна еще одна комната еще один шатер еще тысяч овец сюда прибежала и это не спасает поэтому запомните adidas нужно считаться другими способами это вопрос отдельно как бы отдельное тело это был с авто скиллинг магии нет доп тизере было написано как стать магом магии нет как бы представьте молоток молоток простая вещь которую берете забиваете газе но представим в мире где люди никогда не слышали о молотки для них это безусловно будет магия до для нашего маркетинга of the spelling это магия для нас это молоток все очень просто неплохая диаграмма которая описывает ну поверхностно что такое wsf тоске линда архитектура базовым его представление it all out bouncer вот он у нас да это и ситу инстанции в of the skill группы это amazon cloud watch по сути это сборщик и визуализатор метрик и это скейл правило skill of skill да ну основные понятия эта группа группа она по сути configure скука минимальный максимально серверов вас может быть launch configurations это говорит о том какого типа essence и можно запускать какой диск у них может быть короче вот такие настройки при этом нужно помнить группа может запущена быть только на одном ломать configuration вы их можете убить несколько переключать но по сути может быть только одна ну и по факту это скиллинг plans скиллинг place вообще отдельная тема скин place говорит о том когда нам увеличивает ресурс и когда нам уменьшать ресурс важное правило скейлится вверх то есть увеличивать ресурсы нужно можно как можно раньше то есть не ждать пиковой нагрузки а стараться это делать раньше например если у нас загружается степи у мы смотрим что секу в среднем уже три минуты держатся на 70 процентов давайте увеличивать ресурсы иначе нам плохо будет а вот донские лице нужно наоборот позже потому что непонятно что проезжает но об этом чуть попозже неплохой пример 30 удержим 20 минут вода течение 20 минут 30 вроде все ок давайте убирать из ну и помнить нужно что скиллинг планы даст стратегии для разных applications могут быть разные не нужно там приходить другу говорит да у нас 70 вверх 50 вниз он говорит да я тоже так сделаю нет это все мониторится подгоняется в общем тонкая работа и так немного практики вчера был такой трафик сегодня вот так что произошло думаем да как бы смотрим по графику si peu у нас прыгала вот так какой-то момент она резко упала в какой-то момент резко возросло в этот момент мы собственно и валялись что происходило у нас был запущен такое количество инстансов 112 поднялось потом опять 1222 что происходит смотрим на скиллинг план 70 это наш верхний потолок когда мы считаем что нагрузка уже становится предельно и 50 когда вроде нам хорошо 50 это реально из опыта вот этот сценарий потому что 50 это некий такой выиграла жадность да мы не хотели много платить им озону или считали что если 50 меньше 50 нагрузка то давайте убирать сервера чему за них платить будет но это нам сыграла шутку плохой ну amazon авто skellington работает все просто это такой топор который говорит что как только мы заходим за не gytrash фолды происходит alert типа чуваки давайте увеличиваете ресурсы или давайте уменьшаете для него как бы пофигу что это за приложение бездушная система но представим что наши сервера это некие умные хорошие ребята которые беспокоятся о нашей нагрузки когда происходит alert ниже доске линга один из них говорит ребята зачем вы это делаете вчера по паторну нагрузка продолжает расти а сейчас вы говорите о том что нужно убирать рано нагрузка растет мы убрали слишком рано сервер следуйте вследствие этого один из них силе говорит ну все я один не справлюсь потому что нагрузка она продолжает расти сервер 1 убрали происходит по сути downtime система alert говорит надо еще один сервер один сервер подымается но проблема остается либо лансинг да то есть все быстро не происходит в одну секунду пока одному плохо 2 продолжает как бы выгребать следующий трафик это очень популярным при для печки который не любит php-fpm когда все worker взбиваются то очень плохо нужно стараться чтобы система жила задыхалась потом как 50 минут им эту боль или менее балансируется и все становится на круги своя маленькая и марочка вот здесь в 30-минутные как бы точки мы еще и потеряли денег потому что и ws мы платим за час до каждого запущенного остаться если мы из нас убрали и там через секунду его опять поднимаем мы за предыдущие заплатили как за час секунду мы ничего не делали решение понижаем до то есть говорим о том что будем да он стелется намного позже плавнее в итоге наш график выравнивается и идет по нормальному пути опять же с точки зрения экономии денег неплохо иметь резерв instances мы этого не делали но неплохо иметь потому что у вас всегда будет запущена какое-то константное количество серверов которые так или иначе будут 12 или любое другое число поэтому резерв они дешевле можно платить за нее за год за три года в общем сэкономит вам денег все очень просто приложение в условиях авто скиллинга это не просто настроить of the spelling и сказать всем мое приложение работает вот лежит на стоге сена я счастлив или она счастлива в общем нет приложение нужно тоже подготовить первую очередь диплом диплом должен быть асинхронный и он будет всегда синхронным вас много серверов много пользователей нужно думать не только о том что мы переключаемся в любое время на каждом серию то что еще сам пользователь может попасть в разную версию v и w с в elastic балансире есть так называемый степени station с которой говорят что ну минут 20 пользователь на конкретном сервере будет жить будь спокоен но это вам накладывает определенные условия задачу deploy должен быть быстро и вы не должны как бы тепло и цапа час иначе пользователи начнут гулять из версии версии будет что-то плохое естественно стараться вот эти версии когда разрабатываете чтобы они были обратно совместимы и да не ломать хотя бы предыдущие функции да вы добавите новую в новую версию пользователь придет и выполняет какую-то задачу случайно переключиться на старую но такое должно быть происходить очень редко тепло и тесь как можно быстрее ну один из простых хаков запускайте искусственное создание дороже но они как бы дороже не настолько чтобы всю систему ломать где пойти в сеть все дела и обязательно прогревайте каждую приходу трафика у нас были такие на мониторинге бы пике когда вот вроде идет нормально потом пор выпекал прошел и дальше пошло вот этот пик он абсолютно коррелирует с диплом потому что пользователь пришел на холодную систему все очень плохо система как бы про осталось успела быстро обработать но бы успела быстро обработать потому что там принципе ssd все дела это спасает но прогреваться нужно до прихода трафика и есть неплохой такой хак у них называется холсте gs грейс-период это говорит о том что помимо того как система запустила instance у вас еще есть время до которого она начнет туда пускать трафик его можно configure хоббит хоббит простая штука говорящий о том что ваша система работает хоббит говорит о том что этот инцидент либо нужно выкидывать потому что он умер либо этот инцидент должен жить в итоге правильно нужно выбрать хоббит хоббит это 200 ищите пилки и например это значит мы живы пятихатка это значит мы умерли так вот вопрос масику отвалился или мы за тепло или какую-то версию конфигурации да это все это как бы накладывает некие проблемы которые будут генерить 500 для ходьбе то это говорит о том что система умерла но основное правилах отбита вы должны выбрать такую конфигурацию как бы такое условие при котором вы резко не будете терять количество уже выделенных ресурсов пример когда мы думали чужие у нас будет хоббит ему как бы нормально поведение допустим на сиквел умер да не знаю там диск закончился или там memcache конечно торис вроде 500 koch отбит система не работает но это неизбежно приведет тому что когда вы например за тепло или какую-то версию у которой ну какая-то плохая конфигурация или админ не успел перри configure мускул то система начнет идти инстанции выкидывать вы как бы в порыве быстро пофиксите конфигурацию или там пофиксить ему school но система войдет в нормально положите но трафик то останется большой да а система по выкидывала много ресурсов в итоге вы придете к тому же графику где был downtime ресурсов нету хоббит мы выбрали фиговый и система короче ждет пока все запустится в норму нужно выбирать правильные условие правильные условия говорят о том что applications configure он правильно на нём хорошая версия мы прогрелись до этого достаточно не нужно включать туда проверку мускулом мкш и все такое это неизбежно приведет к падению ресурсов толерантность падению важно помнить что любой instance который запущен в облаке не только в авторские линги он может быть убит в любой момент любым человеком любой системой космическим роботом в любым потоп никогда на нем не держите никаких там файлов а плодов если ну очень любят разработчики php залили оплот файл потом тут же начинают либо там чудо конверте вся фигня потеряли файл нет как только файл залит старайтесь его куда-то в третье место там где с ним разберутся а потом поставьте задачу на его обработку блоги блоги бывают разные да там биологии влоги которые мы просто оцениваем все ли у нас окей тут тоже важно куда то их дальше справлять в кибанов грейлок в с3 дам пить это уже как бы отдельная проблема но вы должны просто обеспечить что все логин на нашем сервере отсутствует грейс пул shadow grey сил shadow конечно копеечки это меньше всего относится так как там как бы процент менеджер но это неплохо для долго играющих процессов для голлинга для си для тех же пички каких-то worker of когда instance выключается нормально да то есть авторский link принял решение что это dance нас не нужен он говорит там софт чудо он систему linux говорит сов shadow она отправляет процессом сигнал этот сигнал можно отловить можно что-то доделать но вас на это 30 20 секунд не успеете получите kill такое что как бы никому ничего ждать не придется есть ваш цикл хёке которые как бы а ноют наружу да так так сказать через внешнюю очередь которую вы этот анной как бы этот alert можете перехватить и делать что хотите час ну это например интересно будет если вы там делаете какую-то конверте лку сжимал q и mpeg файлов не знаю да ну час наверное хватит ну потом опять будет жесткий kill используйте транзакции в базе данных это важно конечно не нужно оборачивать транзакцию один запрос потому что это бессмысленно транзакцию нужно оборачивать до несколько запросов ну надеюсь все понимают почему транзакции хорошо маленькая ремарочка которая не относится конкретно к вто скиллинга но очень хорошо иллюстрирует как должна работать сессия пользователь в горизонтальном масштабировании до сессии пальцы простая вещь когда мы говорим о том что пользователь там авторизован да есть два подхода совершенства и сань cookies 1 stations top у нас есть какой-то третье место редис его практически большинство используют для сессий не знаю не знаю при этом почему это так надо делать но все простая схема user отправил какой-то хэш applications просил какой иди мы сказали о кей юзов ты наш юзера становится больше мы увеличиваем количество и paradise пока еще выдерживает потом когда не выдержит мы еще один родись поддер ну подними простая схема для чего так нужно делать ну я для себя в принципе только одно условия использую если бизнесу и пользователям важно управлять аудирование сессии своей ну например у вас там на страничке в api есть пункт хочу разлогиниться из всех устройств на которые залогинился да тогда это неплохо у вас есть какое-то третье место откуда вы можете все сессию дропнуть и как бы выполнить бизнес-задач sein cookies some cookies говорит о том что мы нигде не храним у себя некую карту мы говорим о том что есть пользовательский им то едишь ником с каким-то хэш он по которому мы будем проверять омыли вы дали этому пользователю этот айдишник доверяем ли мы этой этому как бы айдишник у есть какая-то функция хеширования которое просто год он сравнивает наше какое-то секретное знание этот хэш который выдал пользователь становится больше об а просто масштабируется радистом не нужен в этом случае понятное дело работает не даст не для всех и не работает тогда когда вам нужен аудит сессий мы в lingualeo кстати именно так использовали надеюсь так и используйте сейчас потому что ну не всегда это нужно аудирование мониторинг мониторинг важная вещь которая дает как бы в течение всей презентации говорю мы там видели на мониторинге видели на мониторинге если вы не позаботитесь заранее об этой фигне а фигне под названием в тоске link думать не стоит потому что вы ничего не поймете что у вас там происходит в этом космическом корабле под названием молоток важно мониторит количество инстансов это делается просто можно из клауд watch через и 5 забирать это количество и смотреть как меняется это важно мониторить какой скил кондишен да то есть если вы скалитесь по себе смотрите сколько у вас средняя si peu сколько секу на каждом инстансе это даст вам картину все ли идет нормально правильный ли у вас скиллинг план выбран или нужно что то менять это обязательно нужно мониторить low трафик лоу трафик это какая-то внешняя система который как раз таки говорит сколько вам ресурсов надо потом мы понимаем если у нас падение то ли у нас сибиу перегружен то ли у нас трафик вырос я всегда когда прибегали что-то падали я создал вопрос у нас трафик вырос мы как бы счастливы что мы падаем или все плохо и важно мониторить отбиты шаги то есть хоббит шаги это когда мы тепло или бывает такое что становится все плохо от того что мы за тепло или какое-то кот очень популярное слово на этой конференции мы когда выкладываем какой-то applications что она становится не так давайте откатывать откатили смотрим все вернулось на назад давайте чинить важный момент масштабируемость не значит производительность если вы пишете медленный код если ваш код может обслужить только одного пользователя на одном сервере масштабируемость конечно спасет донатом на сотню пользователи сделает 100 серверов и как бы вы будете я of the spelling используя всё как бы хорошо нет если ваш код тормозит думайте о его производительность и масштабируемость это способность выделять ресурсы под ту производительность которая идет снаружи да то есть на то как вы сможете выдержать любой объем трафика в общем всем спасибо на маленькой момент джуна харит голлинг android разработчики ios разработчики если что подходить и спрашивайте спасибо за информацию действительно интересно можете еще поделиться из практики каких инструментов вам не хватает вы высечем пришлось подход что пришлось доделывать самим либо то что есть она как бы работала это как вам надо и что вам пришлось опять же так как то переделывать взаимодействие вы при этом напрямую с amazon им что пойдем как чем-то помогали и so dark' ситуациях спасибо одной из вещей которую мы наверное сделали в первую очередь это научили все инстанции в кластере of the skill и понимать друг от дружки что-то да то есть это некий классе в котором все сервера находятся в неком таком взаимодействии да они могут обмениваться сообщениями и это один из способов deep ловятся да когда в эту шину бросается к это событие происходит deployment то есть в первую очередь мы решали проблему deployment а у amazon только позже появился по-моему называется код диплом система которая позволяет тепло и цена с помощью то есть первая проблема это дипломы саппортом по этому вопросу никак не общаюсь на них просто не было на тот момент инструмента но вот наверное первую очередь это тепло то есть нам этого не хватало делали сами это не только наверное deploy applications ну это вообще способ как бы создание вот этих образов инстансов которые должны of the skill группу добавляться а сколько у вас уходит времени вот на подъем еще одного иисуса и как выводе плоти на подъем - и по моему там уходит не так много времени до пяти минут сколько ну это уже наверное меньше минуты собственно как деплоить и диплом следующего характера собирается некий build файл который отправляется в облака до с3 такое распределенные файлохранилища и в этот как бы кластер отправляется события ребята новая версия diplo на каждом инстансе есть скрипт который знает что по этому номеру можно сконфигурировать url этот узел скачивается да и to build потом наступает шаги когда этот билд нужно распаковать куда-то разложить есть engine.exe на котором нужно переключить конфиг все это автоматизировано в итоге как бы получается такой вот баян да мы сзади плавились даст можно такой вопрос здесь вот смотрите у нас приложение тоже крутятся в амазоне скребётся автоматически но с помощью клауд watch и мы не можем следить когда закончилась у него какая-то операция и вот ваш способ который вы показали что мы кидаем ходе события очередь поднимаем его то мы и сейчас можем обрабатывать нам не подходит потому что пример обработки заранее известно в этом случае что то можете порекомендовать но если только предмет не и расскажите что это за проблема потому что если говорить о некой такой абстрактной проблеме почему вам это не хватает ну не знаю если вам нужно понять почему это выключилась или почему это заканчивается обрабатываться ну не знаю то есть только если конкретно расскажите что за проблема то его может что-то и по совету посмотрите мы занимаемся консультированием презентаций нас такой сервис есть вот и соответственно презентация может быть разных размеров и мы не сможем спрогнозировать сколько будем может конвертировать ориентируемся в основном нам размер очереди то есть если у нас размер очереди конвертирования вырастает там и инсов поднимаем если при этом размер очереди уменьшается мы должны instance выливать вот но мы не знаем можем ли мы этот intent убить потому что возможно ним еще запущен процесс как можно следить по сути скорее всего вот этих хуки которые да то есть вот этот термин аид хук он вам и поможет не знаю почему он вам не помогает вы когда запускаете то есть берете из очереди джогу чтобы начать над ней работать до то или там н задач которые обрабатывают n количество презентаций то вы должны так иначе для себя через q это мониторинг определять все таки какое среднее количество дней сколько времени до вам ну сколько времени тратите на то чтобы это количество обработать до если все инстанции все там баркер и работают больше часа то скорее всего вам нужно поменять объем сервера да и стараться вогнать эту нагрузку так чтобы вам часы хватал потому что вы ограни china теме лимитами которые дает это был и с вы не можете делать это дольше максимум час поэтому с configure ти сервера так чтобы этого часа хватило либо там делайте более то есть меньше очередь да пусть очередь накапливается но не так чтобы вы там воткнулись и все умирал делайте мечты меньше инстансы спасибо пробуем можно сказать пожалуйста в ваших проектах учитывалось ли откуда приходит трафик допустимо сервис глобальные я хочу чтобы навестить мой сервис приложение было поближе конкретным клиента будь то штатах латинской америки в японии собственно использованию это как amazon дает нам для этого нормальные инструменты ну и может быть 2 в рамках вот вопрос я понимаю что там письме сервису слегка раскидать как угодно нас масштабировать что делать с базами которые если сервис 1-м глоба не просто 2 номер один да про глобальную как бы там глобальное масштабирование ws позволяет вам делать лаут balancing снаружи да то есть вы можете сказать что там лаут balancing в такую зону всякую зону в такой дата-центров так в другой дата-центр в каждом дата центре есть по три зоны каждая зона обслуживается ну по словам амазонок отдельными физическими там серверами вины кластерами и в итоге ну глобальные масштабирование так или иначе возможно если что-то конкретный лучше это уже напрягать solution архитекторов именно и ws про базу данных конечно это совершенно другие подходы как бы то как вы масштабируете web applications которая была не обладает состоянием это как вы будете масштабировать базу данных которые есть состояние совершенно другой другой доклад совершенно как бы другая песня да не уверен что of the spelling в этом вам поможет это какая-то can кастомной инициализация инсталляция ну вот полны вчера вечером про такое примерной рассказываю ребята и завита здравствуйте вы говорили про deploy просто вот вопроса elastic band также есть amazon хорошо хорошо elastic бенз толк это по сути некая автоматизация авто скиллинга да то есть это подход который неплохо работает для базовой инсталляции я его не упоминал хорошо что сказали и ластик бенз толк неплохо если вы берете какой-то базовый тамаля лэмб и хотите его масштабировать это вам отлично подойдет но помните что как бы внутрях это именно то о чем я рассказывал это авто с кейлин группы it all out балансе просто для конечного пользователя это выглядит проще и да там можно тепло и ц'ада там есть некий diplo менту но lingualeo уже добра стал каким-то мясом таким что вогнать его власти cabins толк невозможно потому что там нужно определенное иметь конфигурацию самого инстанса там другие как бы демоны работают которые как бы взаимодействуют по своим причем мы не использовали apache использовали engine x там власти ганс толки это все завязано на патч не знаю как они сейчас это все подрубились индексом но там свои как бы грабли есть до которые именно под тюнинный под elastic бен стал при этом на облаке на тех же ресурсов все это работает у нас было более кастомной а инсталляция ну со своими блохами и ими самыми а владимир компания флант такой вопрос вы говорили о хранении сессий в одессе и меня вот такой вопрос а как определять крана поднять еще один instance редиса еще раз как понять что нужно поднимать еще один из на зарядиться какие условия для его поднятия как у нас это никак не работает я рассказал один из подходов фрёйдис может быть заменен любым другим моментам не знаю насколько это относится к этой теме но если вы понимаете что с radisson все плохо не знаю там в память например начинает упираться слишком много сессий на нем уже храните то это один из признаков не ждать когда один instance лопнет давайте еще один и скачет а второй вопрос а что вы еще и спросите место редиса ну на самом деле я сейчас уже давно отошёл от так сказать два пса и все такое системы поэтому я сейчас не использую ничего для хранения сайта спасибо а на каких российских площадках я могу такую систему построить то есть вот если именно мазан нельзя использовать это скорее всего вопрос гуглу и yandex кроме амазона вы это кусте мы исправили как бы до amazon был одним из первых с кем удалось работать крупно сима антон спасибо вам за доклад большое"
}