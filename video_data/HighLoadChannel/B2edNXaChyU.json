{
  "video_id": "B2edNXaChyU",
  "channel": "HighLoadChannel",
  "title": "Как решить проблемы оркестрации сотен задач по обработке данных с помощью Apache Airflow? / В. Баев",
  "views": 7856,
  "duration": 2809,
  "published": "2021-10-04T02:02:08-07:00",
  "text": "лица сегодня мы поговорим про регистрацию и почерпнул в частности и я бы хотел начать первую очередь с проблематике соответственно самая большая проблема в нашем когда это мире заключается в том что данных действительно много а и становится ещё больше есть множество систем для хранения данных для процессинга становится все больше приложений которые как известно некоторым не всегда тривиальным образом связаны друг с другом и здесь нам определенно нужно оркестрация ответственно что это такое это способ взаимосвязи различных компонент приложения с целью предоставить соответствующую запуск по расписанию и правильно взаимодействия этих компонентов в качестве примера можно рассмотреть череду строковых джо бак которые спускаются пусть у последовательно и параллельно каждая следующая жопка принимает на вход вот пусть предыдущий и соответственно об этом мы сегодня поговорим пару слов обо мне я работаю в компании grid dynamics сейчас я управляю несколькими проектами для одного из наших клиентов из этих сфер и соответственно по стыку в этой области у нас довольно много как классического этель batch processing а так и довольно плотном работы с does in this to me надо эмаль по рекламе и еще раз повторюсь наш план начнем и в целом цирке страции далее у нас будет небольшой in тропу up a cheerful после этого мы рассмотрим уже более какие-то интересные production news кейсы проблемы и места на который стоит обратить внимание и буквально пару слов про наш проект отмечу что это конкретный опыт одного проекта одной команды естественно мы работаем в этих сфере мы анализируем рекламу собираем информацию о показов и просмотров рекламы далее анализируем это собираем некоторые метрики применяем моей модельки на выходе генерируем репорты для клиентов которые соответственно должны улучшить показатели качества нашей рекламной кампании если говорить про объемы данных это десятки терабайт в сутки при этом на разные сервисы у нас различные слой накладывается от нескольких минут до нескольких часов и повторюсь это основном она сейчас batch processing с таким сильным упором фокусом на m l соответственно в таких ограничениях задача регистрации несколько решается тривиальное общем много всего интересного можно встретить я постараюсь сегодня в большей части этого покрыть окей начнем с регистрации к регистраторам мы предъявляем традиционно требования они должны поддерживать различные источники данных и input источники наших регистратор должен быть отказа устойчивым распределенным должен удобно масштабироваться и вы собственно просто удобен в поддержке в эксплуатации при этом сейчас на рынке представлено довольно большое количество различных решений иду к скажем так нашему кейсу почему решили посмотреть в сторону air flow изначально у нас было несколько десятков приложений распределенных по разным проектам вертикальным командам при этом возраст как базы у нас тоже варьировался сильно в костер пестрота raw нас был такой микс из узи луиджи где-то мы использовали самописный in-house регистратор при этом эти приложения были распределены по нескольким различным кластером что опять же усложняло как поддержку так и разработку естественно в тот момент вы поняли что необходимо как-то унифицировать регистрацию в нашем проекте и начали исследовать рынок решили посмотреть сторону apacer flow и сейчас я расскажу что собственно из этого вышло опять же давайте начнем с основ в предложении так скажем анализа аудитории интересно об аниме и поднимите руки кто вообще хоть когда-нибудь слышал про airflow может даже там не используйте у себя но чуть побольше окей тогда да надеюсь что что-то новое для себя сегодня вынести в целом airflow это регистратор который позволяет описывать ваши workflow в виде геля на айфоне и я бы хотел ввести несколько базовых терминов которые нам помогут при дальнейшем рассмотрении airflow соответственно если мы представим нашу большую бизнес задачу как некоторые такой дак он же а цикличный направлены графон же pipeline эту задачу можем разделить на более такие элементарные составляющие которые в контексте эльфов называются досками и тоски vr flow делятся на две большие категории это операторы и сенсоры операторы в основном выполняют некоторую работу а сенсоры ждут некоторого внешнего воздействия или ивентов также пару слов про архитектуру ноги вверх владельца на мастер варки ноды я чуть дальше к этому еще вернусь рассмотрим подробнее и один момент который хотелось бы отметить по поводу дизайна изначально airflow придумывался как такой battery in that регистратор а это значит что если вы условно говоря хотите запускать pipeline и раз в секунду или делать какой то делать а не просто sing to аирфлоу наверное это не совсем подходящий инструмент но тем ни менее также на слайде представлены пример , у нас есть некоторые так с различными досками и можем наблюдать их взаимосвязь и в продолжение разговора о лайки также у нас есть список всех дагов с статусами их запуска с параметрами их schedule инга а также для конкретного дага очень удобно можно посмотреть в treeview потрогать историю запусков посмотреть статус это сачек и для каждой конкретной тоски мы также можем ее перезапустить можем забираете и статус или посмотреть логи ok далее хотелось бы поговорить о базовых концепциях которые есть firefall как я уже упомянул нас есть операторы и сенсоры при этом операторов довольно большое количество разнообразных разнообразных в том числе потому что они монтэйн со со стороны и open source комьюнити и с помощью операторов мы не только описываем работу которую хотим сделать но и операторы позволяют нам задайте структуру дага то есть мы можем делать branching мы можем 391 так из другого также если вам необходимо задать некоторые при приоритезация над досками можно использовать механизм плов и очередей если у вас есть интеграция с какими-то внешними системами например базы данных в excel для этого есть механизмах look'ов connection of также может сохранить некоторые конфигурационные переменные и передавать информацию между разными досками издали я хотел бы показать такой минимальный пример работающего договор фло утверждается что нам требуется буквально рампы 20 строчек кода для минимального примерчик а естественно мы описываем наш так объявляем задаем ему имя дискрипшн далее задаем следу интервала в данном случае у нас будет акрон expression запускаем наш pipeline раз пять минут и в по японии нас присутствуют две тачки первое это ваш оператор который исполняет команду дейт и вторая тоска python оператор который запускает функцию print help естественно в пайке наш pipeline выглядит следующим образом и также мы можем в treeview потрогать историю запусков видно что pipeline запускали два раза он отработал вот эти запуск у нас сейчас в процессе 1 то сачка справилась на scheduling в очередь естественно мы можем также посмотреть логи для запуска конкретной the ski out put и таким образом мы покрыли такой минимальный базовый функционал но понятно что для надежного использования рухлов продакшна системе этого я достаточно соответственно давайте рассмотрим чуть более глубже что нам потребуется в первую очередь мы должны определиться с бизнес логикой естественно давайте рассмотрим пример мощный летних pipe light of допустим 1 pipeline у нас обучает модельку изначально мы должны загрузить туда новые данные допустим какой-то ты to set размеченные теми же аналитиками после этого мы выполняем некоторые при processing далее запускаем тренировку самой модели и на выходе мы получаем артефакт модели которые можем за диплом в какой-нибудь отжиг сторож например сохранив также мина информацию и на далее на этапе скоринга то есть prediction pipeline а давайте рассмотрим пример матч процессинга естественно мы ждем поступления но бача далее опять же может потребоваться некоторое предобработки данных подготовка после этого мы применяем соответствующую модельку здесь тоже можно добавить логику вы можете выбирать модель исходя из метриками качества или брать самую свежую и на выходе вы получаете построенный батч который можете отдать в downstream системы окей мы определились бизнес-логика и давайте посмотрим на инфраструктуру что он для этого понадобится я предлагаю рассмотреть пример альфа сетапа на целый рюкзак шутеров естественно как видно из съемки у нас есть мастернода есть несколько маркеров на мастерноде у нас хостится airflow scheduler и веб-сервер естественно на горке родах у нас находится worked процессы которые слушают соответствующую очередь забирают тоску на исполнение выполняют и возвращает результат уже на мастер естественно для этого общения нам необходим какой-то message broker в данном случае рабби темпе и также у нас сбоку еще есть база данных airflow которые скажем так хранит стоит всей системы текущее состояние и пару слов о конкретном сэтапе которые мы использовали своей команде у нас было три отдельных эльфа кластера получается под каждый янов есть дев есть эйджинг есть продакшен на каждом мастере мы крутим порядка 200 до дав и это все с помощью 20р flavor киров ну это же такой момент все преподнес разделены по разным проектам вертикальном то есть они скажем так тоже могут другая фиксить и отдельно хотелось бы отметить так как мы все-таки живем в python мире то и процессы на мастере наварки raja не стартует под своим каким-то python виртуален вам естественно если вам в pipeline не потребуется какой-то какие-то зависимости питания чей пакет это следует учитывать обновлять ваш вашу среду или же если вам хочется больше гибкости кастомизации вы можете просто на уровне pipeline а имеет те же зависимости или допустим даже создавайте virtual and динамические в ран тайме под запуск конкретной тоски как раз опасен виртуальных оператор для этого был создан окей то ли я хотел бы поделиться несколькими такими челленджа мир с точки зрения структуры из которой вы сталкивались 1 эта миграция между версиями архол наверное около двух лет назад мы к 1 мигрировали с восьмой версии на десятую при этом потребовались мнение как со стороны разработки там минорные апдейты в фильме виду со стороны дагов плюс по инфраструктурной части тоже приходилось мигрировать схему базы данных но в целом как бы этот процесс пошел более менее безболезненно the grid опять же у относительно это зрелости mature насти продукта erfolg от с этим можно жить и можно работать и вторая такая большая миграция у нас было это переезд со второго питона 3 здесь тоже такой момент мы были несколько ограничены в ресурсах то есть мы не могли взять нашу среду и просто ее грубо говоря за дублировать и потихоньку перетаскивать pipeline и там со старой со старого январе менты на новый а потому что мы постились новое племя это были всяческие тачки мы пытались как-то переиспользовать допустим подворки одновременно гоняли и для второй для 3 версии питона вот но естественно миграция более-менее тоже прошла без каких-то серьезных сюрпризов и что нам еще предстоит это миграция с 1 сверху на вторую естественно тоже потребуется как облейте со стороны дать инжиниринга так и со стороны инфраструктуры вот я не ожидаются понятно больше чем там при переездах в минорных всех и отдельно важный момент по поводу каких-то интеграции vr float значит airflow поддерживает несколько типов разных экзекуторов какие-то из них больше подходят для локального тестирования дебага другие же например целый ряд гитары купить скутер вполне себе можно использовать в живых production системах и также отмечу что airflow довольно неплохо за интегрирован с основными и клауд провайдерами то есть и жорой wccp вы можете из коробки найти операторы кита сенсор для работы с соответствующими кодами плюс по интерфейсам кроме традиционно видео и у нас есть сила у нас есть rest и отдельным моментам хотелось бы подчеркнуть существование - инстилляции or fall to steer флова за сервис пример из компания астра номер что ребята делают они берут соответственно релиз airflow под себя кастомизируют его добавляют больший функционал а плюс берут на себя оверхеды по тепло и манту по менеджменту инфраструктуры предоставляет свою поддержку и собственно продают это уже как какое-то коробочное решение со своей поддержкой плюс хороший амин в том что они перечислить эти свои фичи тоже бока портят обратно в мастер ветку эльхолл естественно это в целом хорошо помогает росту и развитию продукта open source продуктов и отдельный момент по поводу менеджер flow это и джерси peavey ws недавно появились верховой за сервис джесси привет называется кукловод composer amazon буквально этой весной тоже за релизимся то есть но я скажу мы пробовали немножко играть если вам хочется так по щелчку пять пальцев развивать инфраструктуру это работает можно так делать но безусловно клауд провайдеры накладывать какие-то свои ограничения то есть у вас не будет той максимальной гибкости вы не сможете там все property верху и из конфига как то забирает по себе настроить но зато вы не заморачивайтесь об инфраструктуре окей мы придумали бизнес логика у нас есть инфраструктура давайте теперь поговорим про всю ту мощь пальцем дизеля и в целом airflow для разработки первое что хотелось бы упомянуть это возможность хранения каких-то конфигурационных переменных верху из коробки есть отдельная юшка которая хранит в riddles видит key value старриджа в базе по сути то есть возвращаясь к нашему примеру из имели можно какие-то три школы для моделек просто хранить вот этих переменных и иметь быстрый доступ возможность это на лету подправить тут опять же is down side of war flow нету какого-то аудита там треккинга истории апдейтов вот этой табличке поэтому стесняясь и sky the production a critical параметр что все таки наверное имеет смысл и его куда-то засунуть в гид по системы контроля версий что отметь понимание кто когда что за тепло и и и почему все поломал вот но для более киты легковесных параметров вполне себе можно использовать следующий интересный момент это возможность динамически генерить структуру дага то есть у нас напомню мы описываем дак на пальце не у нас нету какой-то бесконечного дублирования тех же xml конфигов как в том же узи мы буквально взрыв две строчки кода можем видеть какие-то сложные структуры при этом этот подход можно понятно обобщить стас окна также динамически генерить много дано много дагов из одного атома исходника файл с планом как это можно использовать вот в нашем примере у нас есть при план который анализирует рекламной кампании стресс новой рекламной кампании есть едешь ник и там в зависимости от рекламной кампании мы хотим запускать припаяны несколько разной конфигурацией при этом на разных рекламных кампаниях разный трафик естественно просто идем в тут же сиквел баску вычитываем все эти одесский динамический генерим отдельный pipeline под каждого клиента и у нас получается кучка pipe айнов которые независимо работаю там случае падения они не эффекте от соседней pipeline и собственно это упрощает нам существенно жизни у нас появляется прозрачная история это запуска в по конкретной рекламной кампании такие следующим пунктом перед тем как сзади плавится на продакшен и упасть хочется хоть что-то протестировать первым моментом отмечу что эльфов довольно неплохо заточен под локальную разработку то есть вы можете поставить себе тот же , чей пакетик с air flow поставить сиквел базу и собственно такой минимум вы уже можете разрабатывать у себя локально но если это кажется слишком чем-то таким сложным то давайте просто возьмем официальные докеры матч и вот вы уже можете разрабатывать локально при этом можно потрогать более кита интересные варианты дикторов то есть тот же целую такие то есть локально можно разрабатывать далее опять же перед диплом хочется на уровне тех же yummy тестов какие-то базовые проблемы отловить что можем сделать мы можем протесте что у нас так за им портился без ошибок то не знаю все dependency у вас есть на среде можете проверить это действительно существует что у него есть нужное число to suck что они связаны между собой так как вы действительно этого ожидаете плюс как здесь у меня показано в 14 строчки вы можете даже запускать некоторые операторы смотреть на утку то что они работают так как от них этого ожидает к следующий шаг для более таких серьезных тестов я имею ввиду там регрессия смолки на шухере например используются ристопии то есть они через rs-триггера они смотрят за их стаи там смотрят за лагами to suck их вычитываю требуется там бьют кита значения из логов естественного далее мы это просто центрируем в нашей сиди лук и вот пожалуйста у нас то мисько это регрессия которая для тех же и моделек мы можем на допустим голдинг эта сеть и запускаться смотреть что у нас там метрики не падают допустим модели все еще жива после обновлений и отдельный подход тоже кто-то пишет прям отдельные которые тестируют другие итоге это тоже работает окей движемся дальше дальше мы готовы перейти к дипломату какие здесь нас могут ждать сюрпризы прежде всего это versio не рование какие здесь есть опции первый подход вы можете хранить грубо говоря версию pipeline а просто вымени да да и при каждом обновлении менять имя и релизе новый pipeline чем это может быть удобно у вас сохраняется вся история запуска вы ничего не теряете если вас есть какая-то необходимости в аудитов не хотите ничего терять то вполне себе рабочий вариант понятно что с другой стороны если у вас есть внешние системы того же мониторинга которые смотрят на этот pipeline и ожидают определенное имя дага то надо как-то чем эти версии синхронизировать вот но понятно это уже вполне себе обрабатывается если же мы не хотим хранить версию вымени дага а просто обновлять существующей pipeline здесь тоже верху есть одна особенность как у меня представлены на скриншоте мы за тепло или новую версию добавили то сучку принты на верх low препарат работал в нии зеленый state ведущий запуска хотя тоски не было поэтому там следующие потратите без статусов как бы окей но что будет если мы наоборот хотим тоску удалить или как-то более серьезно обновить структуру да да ответственно нас из истории просто пропадут все предыдущие запуски мы не сможем понять что за той таская происходило месяц назад если сегодня мы ее просто убили то во всех предыдущих выпусках на должны пропадет ну это в целом такая проблема на здесь наверно общий подход если вы меняете бизнес-логику конкретной тоски то окей это можно делать в рамках текущего дага если же вы кардинально меняете структуру да готова наверное все таки имеет смысл вам просто за деплоить отдельный pipeline при этом во второй версии нам обещали что-то сделать для versio нирования но пока этого нет окей и отдельный момент по поводу дипломанта уже существующих дагов накатывания обновлений в случае с теми же целые культуры между надо нам надо просто раскидать по некоторым хастам питание очки файлики артефакты при этом понятно мы их можем разложить как-то некой ассистент на но это наверное больше проблем инфраструктуры нам как когда-то инженером хочется чтобы с не было там тех же падения pipeline на месте у нас дак запущенность на эту тяжелую задачу при этом имеет какие-то зависимость этого не знаю смотрит на файлике локальной файловой системе при этом мы время запуска перед тепло или новую версию файлик может пропасть снасточка упадет и этого хочется по максимуму избегать что мы пробовали для этого делать мы грубо говоря просто идем в базу данных airflow перед выходкой останавливаем scheduling при плагинов дожидаемся пока не успешно отработают после этого века ценного версию и дальше уже можно возобновлять scheduling естественно это нам позволило уменьшить число падения именно среди таких запущенных дагов окей мы написали наш pipeline за тепло или он даже как это работает но понятно что начиная с какого-то момента нам хочется каких-то тонких оптимизации тюнинга что здесь предоставляет air flow в первую очередь мы можем гибко настраивать число параллельно запущенных то сачек в рамках определенного worker а можно также это делать для целого дага чтобы она словно говоря там так не мог на генерить там 100 to suck сразу всех запустите забить все с ватой в очереди плюс мы можем настраивать число параллельно запущенных инстансов именно 1 дага если вы допустим динамических акта выберите большого числа гадов плюс если там хочется тонко настроить очередь что целые опять же предоставляет для этого возможности и отдельный момент он именно по нашему проекту что хотелось бы посвятить это airflow игнор такой механизм по аналогии с git игнора когда мы хотим спрятать от процесса который на стране scheduler критические сканирует вашу папку с датами и пытается выбросить оттуда pipeline и чтобы средства с ними работать вы можете указать некоторые локейшн и вашей файловой системе которые scheduler должен скипать в нашем случае именно вот сканирования этих папочке с дагами занимала допустим там около 10 секунд при этом в некоторых pipeline of мы использовали , чьи пакеты в качестве зависимости они лежали рядом у кого-то это были тиц жаркие соответственно пустой как мы грамотно настроили рф игнор у нас время именно сканирование папки с дагами но там уменьшилась 10 секунд где-то до секунды был очень тоже такой приятный boost for performance окей ну и последняя вещь которую хочется рассмотреть именно в рамках такой production system это мониторинг что он представляет из коробки случае каких-то падений to suck a full имеет систему notification то есть может допустим присылайте mail и также для от тоски или для дага вы можете задать какой-то тайм-аут после которого ваша тоска упадет и а3 портится об этом также для тоски можно гибко настроить политики паре троим там перезапускать сколько раз каким делаем и отдельная концепция это целый верховья реки перми специальные view а где куда упали все целые мисс и естественно они портятся но даг при этом не прекращали свою работу ну естественно что с ним можно сделать можно и на своей миссии на какие-то падения просто на через call бейки навесить какую то кастомную нотификацию всем надо не знаю слать сообщения снег или звонить людям в приюте вот но скажем так из коробки представляется довольно гибкий механизм для мониторинга окей но кажется что всегда нам этого мало хочется как-то расширять и улучшать что мы можем сделать еще сверх этого это безусловно кит extensions в airflow есть специальный механизм называется плагины для этого ответственно если у вас есть набор кастомных каких-то операторов и не снова хуков или даже вы хотите за кастомизировать ваш ей добавить новые вьюшки какие-то кнопки это можно просто удобно сложить в нужный локейшн обернуть это в так называемый плагин и автоматом airflow же это будет подхватывать у вас все эти ваши классы операторы будут доступны другим pipeline am то здесь не требуется с вашей стороны каких-то там активностей по deployment в общем все из коробки удобный работает ok следующий пункт по поводу конфигурации здесь ну скажем так это тоже наш конкретный опыт как мы под себя кастомизировать традиционно приема конфигурации на хотели как-то вынести хардкот разделить имплементацию и конфигурацию уменьшить дублицирование кода естественно мы просто взяли ямал конфиге по ямам их парсим из и с этим работаем уже на стороне pipeline плюс к этому мы в партер я был файликов добавили наши кастомные теги то есть для процессинга для парсинга например даты для пары каких-то airflow специфичных вещей таких как переменные также допустим удобно парсить execution из дагов прокидывать их в какие-то например пути которые связаны с датами работа с их скобами также вы носите нужен конфигов можно переиспользовать и тоже отдельным по энтом так как у нас было три живых январе мента дев стрижек production такая традиционная ситуация конфиге в них дублируется на 90 процентов при этом хочется как-то этого избежать мы просто вынесли общей функционал в везет яму файлик при этом какие-то инвариант специфик конфиги и в них уже хранились там какие-то имена баз данных специфичный там для дьяволе для провода кита руд в окей шины путей уаз тест на мы в для конкретного элемента делаем отдельный конфиг ходим туда базу и просто через забирает и переопределяем конкретный танки вылью из коробки я был не особо это за . но в общем пришлось обойтись именно парсер ok следующая такая наша головная боль это документация поясню у нас соответственно условно пять или шесть вертикальных команд где есть даты инженеры которые производят pipeline и а поддержка всего этого добра ложится на плечи получается одного инженера в каждом от времени то есть человек который дежурит он отвечает за все падения должен какую-то совершить 1 активности по перезапуску pipeline of a безусловно у нас есть документации есть какие-то разборки но понятно она устраивает она всегда какой-то разнородная нет общего стандарта естественно что мы с этим сделали мы решили взять всем известный сфинкс и расширить необходимый нам функционал и сэр пол и генерить документации автоматически стресс на что мы делаем мы уже готовый pipeline doc парсим вычитываем оттуда требованием требуемые нам параметры такие как имя дага то как он счету лица какую-то структуру то сачек их взаимодействия плюс если у вас есть какой-то кастомный код то хочется да все эти операторы тоже видеть с традиционными 2 стрингами описанием того что происходит и ссылками на исходники с тестом и просто парсим готовый pipeline его конфиге генерим из этого сфинксом это милку импортируем это дело наконец на витим после этого очень инженер в случае падения может легко зайти посмотреть в стандартном формате и как-то восстановить работу pipeline ну здесь как бы очевидный плюс мы не забываем обновлять документацию потому что она живет рядом с кодом если вы обновили какой-то там конфигурационный параметр 3 школ для модельки у вас просто на этапе все и сиди на этапе билда перри собирается документация то есть до какой-то параметр обновился мы перри собрали и соответственно документация актуально собственно это нам помогло избежать проблем при каких-то production инцидентов окей и тоже такой отдельный момент который связан именно с мониторингом то есть как я упомянул ранее верху из коробки есть вполне себе неплохие возможности но скажем так что будет если сам air flow кластер не очень хорошо себя чувствует и очевидно нам нужны какие-то инструменты для мониторинга снаружи что мы для этого попытались сделать первые мы темпе влоги и сэр flow шулера мы тампе многие to suck которые исполняются данным это сидел ластик search естественно мы можем уже сверху какую-то аналитику над этим делом наворачивать анализировать плюс отдельные мы смотрим в саму базу данных airflow оттуда можно понять сколько 100 сачек или дагов запущена какие у нас есть падение естественно это мы тоже можем рисовать на даже прудах в той же графа не добавлять туда какие-то альтинг и вот и получать средстве надо дефекации но тут наверно такой самый часто кейс это когда у нас тоска могла запустится на потом почему-то залипнуть вот при этом airflow дома и что все в порядке это не знаю оказалось какой-то worker отпал ее общем информации из баз данных и фол помогает это как-то патрик и обработать окей в качестве такого самаре завершения на нашем проекте и рф но вполне себе успешно показал как такой серьезный регистратор который можно использовать в продакшене то есть живем мы с ним уже давно есть позитивные фидбэки как со стороны команды инфраструктуры которые то саппорте так и со стороны разработки даты инжиниринга плюс удобно что у проекты довольно большое комьюнити он активно развивается и растет вот мы тоже по мере возможности стараемся бэкон трибетить какие там потенциально следующие есть места куда мы смотрим который нам интересны а сейчас мы почти закончили миграцию с нашего железного он прям кластера v и w с я имею ввиду миграцию не только erfolg мастеров но и всей нашей это создает инжиниринг инфраструктуры то есть все та же ходу вас парк у нас тоже уехал в amazon way more и при этом airflow сейчас у нас хостится в амазоне на и титушках потому что были определенные constraint и по времени но нам интересно посмотреть в сторону каберне this опять же чтобы более оптимального утилизировать ресурсы чтобы сэкономить на костях плюс дайте командам гибкость скелетик мастера более удобно там опять же в ответе на динамичную нагрузку которая у них есть в приложениях плюс связи с переездом в amazon именно вот по этим the air-flow оператором для амазона мы скажем так взяли ту базу которая есть но безусловно там всегда кастомизации не хватает поэтому мы ее расширили под себя но это прежде всего касается менеджмента допустим геморно кластеров потому что мы его строим создаем эфемерные бластера их надо поднять на дату раза согните job кинутых погасить плюс еще могут быть это нужны это активности со стороны блюдо это каталога кислых антоновских сервисов там сводить войска с вот здесь у нас сейчас тоже такая довольно большая обвязка сверх стандартных грузовых императоров появилась в этом этаже мантеньи мы просто имею виде отдельного пакета который нас лежит на вариантах и все припаяны могут этим пользоваться плюс наша инфраструктурная команда сейчас активно работает над тем чтобы дать разработчикам гибкость в поднять январе ментов кластеров пдр флота сейчас мы ушли от подхода вот как я изначально говорил там глобально три два элемента и все команды живут в одном кластере если там кому-то одному потребовались новые пакеты все остальные тоже заблочен и надо иммигрировать там всем в одно время стесняйтесь и dependency добавляют сложности и сейчас мы пытаемся грубо говоря каждой команде там давайте свой кластер on demand или даже там под отдельное приложение и хочется иметь возможность виде такого сервиса наш топ команды могли и сами себе эти кластер оправе женить как тоски делить зависимости от нагрузки естественно мы к этому идем и отдельный момент да по поводу миграции в airflow 20 здесь скажем так интересно было зрелищно много полезных вещей там ребята хорошо поработали над scheduler am потому что изначально это был таким ботаником сейчас он готов к тому чтобы его деплоить в лыбидь режиме естественно вы можете скейлится что вы больше нет узкое место плюс для разработки для dat инжиниринга появились более интересные пиаре которые позволяют упростить разработку pipeline of но скажу честно как бы мы это планируем на пока не особо торопимся туда переезжать потому что очень хочется послушать больше фидбеков узнаете в индустрии кто этим пользуется насколько оно уже готово вот то есть по ощущениям как бы все слышали всем интересно но немного кто-то туда ехал какие-то знаете такие основные зоны которые нам интересно джай ши и время и заключение здесь у меня есть парочка интересных ресурсов есть ссылка на официально вики страничку atari flows команд pitfalls есть workspaces лайки международный и плюс vr flow есть российская telegram комьюнити qr-код присоединяйтесь нас уже больше 1000 естественно задавайте вопросы можно делиться опытом и помогать в развитии продукта ok на этом у меня все спасибо всем большое за внимание и не большое спасибо владимир за доклад у нас есть время на несколько вопросов я считаю что это был очень классный годный контент лично я для себя мне очень запала в сердце термин job к вот я думаю и вовсе непременно буду использовать своей работе от вас несколько желать не очень длинных вопросов затем владимир будет доступен в зоне цифровых кулуарах где вы можете более предметно и вдумчиво попытать его алон слышали на вячеслав добрый день спасибо за доклад очень интересно подскажите пожалуйста можно сначала немного водно не совсем теме данной больше новичок можно так сказать возможно просто будет простые можно ли workflow строить некую событийную модель то есть если у меня есть 1 pipeline есть там еще один пай план они работают с данными я не хочу или допустим хочу запустить второй pipeline когда первое от работает успешно или когда первый от работы там пять раз успешно или не запускать этот pipeline когда какие не соседние там 10 pipeline он сейчас находится в работе и следующий вопрос ну чтобы не повторяться можно ли передавать переменные между несколькими pipeline ami там-то гамида в этой терминологии и можно ли поднять значения переменные в самих задачах которые непосредственно работают с данными ну например задач процессе данные на этот момент времени она поняла что значению переменной должно быть такое с помощью кого-то там раз сервиса или библиотечки подняла это в дак и дальше уже остальные задачи могут на основании там это переменные типа свои действия предпринимать спасибо да можете повторить пожалуйста вот начало потому что я уже под конец начала забывать о событийная модель вместе я хочу запускать один когда не запускается пять других ну какая сложная логика не обман тивно и сложно или когда там пять других уже успешно отработали окей ну смотрите то есть что вверху есть из коровки чтобы именно там как-то взаимодействовать между ногами вот эти вот в эндре вину строить сами первые мы можем из одного дага триггерит другой то есть если там вы прямо сейчас готова это сделать то можно 3 вернуться 2 так у вас будет параллельно запущен после этого допустим вы хотите там подождать пока он завершится для этого есть тоже такие там аналог сенсоров именно для до дав то есть вы ждете пока у вас от работает это у вас отдельная то сачка и после этого там можете ваш optima это не продолжать какие-то там более сложные взаимодействия между ногами я боюсь что вам нужно будет что-то вот там отдельно сверху какой-то такой сервис делать который будет этом все условия собирать как-то там агрегировать и просто определить нужные pipeline и то есть так они по дефолту что мы можем мы можем по крону запускаться или явно просто тигрица там не знаю через рис или из одного pipeline определить другой продолжение вы спрашивали тоже про механизмы общения между разными tantos коми дагами верху есть механизм xcom of a ну по сути скажем так это все та же табличка в базе данных то есть оно не за дизайне на на то чтобы там могли какие-то большие бинарники передавать но тем ни менее например в этом в одной точке это какие-то данные положили там их условно в xcom в табличку и дальше из рук из следующей тоски можете их забрать но при этом там типа для наивных кейсов вы можете это просто без какого-то вверх и допустим есть из базы делать вы просто можете там грубо говоря вот для python операторов вот это вот функций она может возвращать как раз этот значение по сути то xcom и следующая доска может его автоматом подтягивать вот но это можно использовать также там для взаимодействия между разными дарами если нужны какие то большие объемы да понятно он ограничен то наверное имеет смысл там где-то хранится в ком-то отжиг старриджа и передавать просто какие-то ссылки путина вот эту информацию при этом во второй версии там тоже насколько я помню обещали что-то сделать для вот автоматической поддержки больших объемов но честно я не помню резного сито или нет так это про взаимодействие с досками и последний был ещё какой-то вопрос я опять забыл по одной тоже можно ли переменной между ногами разными передавать можно подрочить алла а можно ли переменной между разными дарами передавать мы по факту вы ответили давайте еще один вопрос и можно и продолжить вот про кларк владимир спасибо за доклад у меня вот вопрос возникшие по ходу это вопрос того как вы синхронизируете сами тепло и релизы новых багов то есть если допустим выполняется там часы то как мы можем 10 раз за deep ловится за день ну на самом деле у нас наверное нет таких кейсов где прям действительно там конец я мерная жопка этом исполняется сутки зарелизить в определенный момент я скажу так что для базовых кейсов мы на самом деле просто не особо заморачиваемся и просто диплом вот но есть несколько таких критиков приложений и в которых как раз вот как я сказал мы там ловили падение при тепло и на запущенных дагов то есть там мы действительно просто ходили в базу как-то стопа ли там опять же такой момент получает средствами паузе между link но хотим вроде как дождаться пока тапочки завершатся то как они будут работать привод этом остановленном schedule инге поэтому мы несколько разделяли наш pipeline обличать и грубо говоря один просто циклически триггерит downstream pipeline вот естественно мы вот верхний pipeline просто паузе ли дожидались пока да он steam который сохраняет работу завершается просто ходили в пазу как-то трека ли после этого да к нам понимаешь что случае мне запущенном и тепло и мся и возвращаемся возвращаем спасибо и еще вопрос по поводу средств то есть у вас есть продакшен среда есть стрижем к среда понятно откуда данные появляются на продакшене а если мы говорим flow это все же отель процессы которые на новых данных как появляются новые данные на ost играх ну скажем так когда мы жили на он примет нас stay джек был не настоящий это по сути это будет всё тот же кластер но там грубо говоря другие юзер нэйм ее как-то мы на этом уровне старались ограничиваться то есть нам но было не так сложно в этом плане то есть иногда мы нас тренинги просто забирайте же production данные обрабатывали иногда мы какие-то отдельные pipeline и собирали которые там грубо говоря сэмплер уют про данные и на стыке можем этим пользоваться а сейчас мы уехали в amazon вам озоне у нас просто энвайроменталисты длины как отдельные аккаунты в амазоне вот и там тоже как бы есть do the lake по сути это тоже отдельный мазановский аккаунты к нему несколько аккаунтов имеют доступ и там мы тоже сразу центрируем данные чтобы можно было в том же стражники просто не на полных объемов запускаться на меньших то есть это просто какое-то перетекание сп рода анонимизирован а его стричь ну да если нам дан прям честные данные так дело и места нет то какие-то синтетические данные просто генерим на них запускаемся на встрече спасибо"
}