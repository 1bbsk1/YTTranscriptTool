{
  "video_id": "qW2ErP9o7mo",
  "channel": "HighLoadChannel",
  "title": "Нестандартные способы использования ClickHouse / Александр Зайцев (LifeStreet, Altinityt)",
  "views": 4218,
  "duration": 2645,
  "published": "2019-05-15T04:55:46-07:00",
  "text": "всем за а это мы 5 доклад про кликал на этом где отрадно что интерес до сих пор остался что не устали вот я расскажу такой несколько меня с будет специфический доклад про то как мы забиваем клик хаосом гвозди вот обычно говорят что микроскопом гвозди забивают ног кали-кала с он как бы штука все-таки которая смотрит вдаль и работает с большими объемами поэтому микро к нему не подходит вот я назвал это телескопом почему вы сейчас я надеюсь поймёте вот кто я такой я выпускник московского государства университета и работы в компании livestreet уже больше десяти лет занимаюсь там аналитической инфраструктурой вот мы одними из первых за тепло и люси oklick house после после яндекса и это нам так понравилось сейчас носи мне так понравилось что я вместе с коллегами друзья мясо основал компании активности который пытается клифф tools продвигать по всему миру вместе с яндексом вот и о чем мы поговорим то есть все вы знаете что кликал с очень быстро и очень удобные все об этом всегда раз рассказывают что он замечательно подходит для разного рода аналитики но вот не совсем понятно для чего он вообще еще подходит вот про это еще и я и поговорю то есть доклад будет про то как использовать ли cows не для аналитики вот значит что такое не для аналитики традиционные примеры использованных ли house они обычно укладываются в какие-то такие вещи то есть это анализ какое приложение это то с чего начала яндекс и там большое количество компаний они идут в ту же сторону да это различные от тех компании которые занимаются рекламной оптимизации у них немножко другой сценарий у них другой трафик у них другие задачи больше может быть какие-то машинах алгоритмов меньше запросов пользователей кроме того это очень много похожих сценариев когда анализируются логия ты мог быть логе операционные ты быть могут быть логе безопасности это может быть какие то то что делают клауд в dns http-запрос они не совсем блоги но они у них там идут с каких-то каких-то устройств это различные системы мониторинга хотя кликал с не не идеально подходит для мониторинга но тем не менее лучше чем многое другое там даже для мониторинга производственных процессов это использует используют recalls значит что общего у этих всех сценариев то что в них всегда включал и загружается очень много данных либо пакетами обычно пакетами разного размера это может быть там пакетная загрузка либо через кафку бы смысл один а потом гоняют olap запросы что такое о лап обычно это какая-то у нас есть скан по таблице какая-то агрегация вот и там комбинация этих вот запросов иногда может быть объединение запросов она составляет собой девяносто девять и девять может процентов того что сколько у сам делаю там клиенты алгоритма и так далее и считается что анти паттернами 2 сек николас использовать не надо это транзакционные система на понятно что увлекалась все транзакции просто нету это севилью и хранилище они еще документов вот и что здесь общее у этих антипа тарнов то что они все предполагают point quieres то есть запросы которые получают одну или небольшое количество количество записей и это как бы понятно что включалась антипатр но он предназначен для того чтобы сразу много всего читать и много всего делать вот накликала с очень гибкие да вообще когда рисовал вот этот слайд я так подумал что его можно интерпретировать немножко двояко то есть можно подумать что cly house гибкая можно подумать что он стоит на месте а вокруг него нужно изогнуться узлом вот чтобы чтобы что то сделать обе точки зрения имеют на самом деле право на существование то есть легковых действительно очень гибкий ведь еще дополнительно вокруг него там завязаться узлом то можно получить совершенно потрясающие результаты вот и подходя собственно еще ближе к теме то на самом деле поговорка про забивать гвозди она пошла людей уже там сто лет почти до гиперболоид инженера гарина то есть crack house такая замечательная штука и мы собираемся ей в общем забивать гвозди например делать point вырез там хорошая это задача или нет это одна задача которой я расскажу а другая задача будет совсем другая вот но тоже как бы с виду для кликал со совершенно не подходящая и тем не менее накликал себе можно достаточно эффективно решить значит какая у нас задача самый задача очень обычная и простая это как раз то с чего начался началось использовали клика us alive street и я рассказывал подробно на холоде и два года назад вот что есть много много серверов которые пишут логин вот и на самом дел ноги очень большие наверное когда два года назад рассказывая может быть говорил 2 килобайта записи налог на на одну запись 2 килобайта где-то в начале этого года запись была 4 5 килобайт вот сейчас вот когда я готовился к этому выступление посмотрел что 15 20 килобайт это одна запись в логе они конечно упакованные но тем не менее это достаточно большие записи их достаточно много почему так сейчас только сидите ровно я вам покажу запись запись в логе вот это одна запись в логе почему она так выросла но как бы можно пытаться прочитать что там написано можно не пытаться весь на самом деле когда идет r себе различные там какая система пытается что-то на ртп выигрывать она делает очень много решения очень принимать много решений когда что на какой трафик надо бегать вот и вот эти вот все решения на самом деле когда она их приняла они все эти решения на самом деле пишутся в лог чтобы можно было потом там проанализировать и во время отладки так далее налог совершенно непотребные вот естественно этот лог мы там пропускаем через этель можно пропустить загрузить в data warehouse который клик house естественно вот после этого получить какой-то отчет и это то что делает в общем все и livestreet это тоже прекрасно делает это это паттерн а дальше какие-то люди там бизнес-аналитики или пользователя смотрят в эти данные и иногда им чего-то не нравится то есть они видят что какие-то неправильные там цифры кида и они задают вопрос может быть те кто работали с бизнес пользователями знают они часто задают вопрос вообще откуда взялись эти цифры что это такое я не понимаю и вы начинаете разбираться в системе пытаться понять а в общем то где то есть вот здесь вроде все правильно и тел вроде правильно написан в схеме лишь тростью правильно там отчет гинером правильно где же ошибка чтобы найти если она есть чтобы найти ее надо вернуться обратно в лог то есть нужно найти транзакцию вот в этом вот огромным логе s500 серверов да причем это может быть транзакцию снизу сегодня она может быть за вчера ли там за несколько дней назад но больше сильно-сильно прошлое редко то есть это надо все логе сохранить во первых где-то и во-вторых сделать способ достаточно быстро в этих влогах эту транзакцию найти то есть такой хороший анти партиям для crack house а вот поэтому обычно и собственно мы тоже вначале еще до клика вас а пробовали разные подходы то есть вы либо делаете распределенный глеб до каким-то образом что здесь немножко помогает то что мы обычно знаем в каком файле надо искать то есть поскольку это наш reporting то мы в принципе можем знать до этого хаоса посмотреть с какого это файла пришло и так тогда можно в принципе да попытаться найти этот файл среди миллионов файлов там найти там распаковать и окрепнуть это все можно но это не очень быстро работает можно используя какой не spark на он по идее для таких задач хорошо приспособлена он ускоряет вон там не делает лишнего и так далее или какой он тела stick search но мы решили попросит лекарств сначала был у нас какое-то решение на гриппе с парке они были не очень хорошие решили попробовать а почему бы и нет действительно почему бы нет вот какая здесь может быть структуры данных вот структура записи которая описывает лог вот она может быть примерно такой то есть есть есть дата файла какие-то там стоим стоим сервер с которого это пришло собственно название файла и вот это очень странная штука которая называется tx да это как раз ольги транзакции и с дефолтом визит парам экстракты что это такое это может быть одна из тут самых интересных вещей подсвечена profits и они ruim и подати и делаем яндекс по имени файла и по транзакции то есть принципе можно было бы наверное сделать яндекс и по транзакции есть это нам нужен был искать только транзакции но иногда хочется найти целиком все что находится файле например если ваши тел процесс загружая epilogue вот он иногда ругается и падает что не могу обработать файл вот у меня тут что-то не так вот и вам нужно найти этот файл а он может быть уже там куда-то ушел и удалился но и проще как бы в одно место и тьяни искать где этот файл находится сейчас можно тогда найти и попытаться посмотреть прямо на этом там блок блок сервер rockstar это и последнее здесь написано индекс гранате и специально выделено об этом мы поговорим подробнее то есть это уже не дефолт дефолт 892 в кликал все мы уже поменяли а что это за чем мы применяли и надо ли менять дальше это мы сейчас и увидим вот что такое вот этот вот дефолт видит para max акценты то есть crack house он позволяет вам делать вычисления в момент сердца и selecta на колонках как делается вычисление во время inserto то есть я могу делать insert в таблицу и не указывать это поле тэкс им не посчитает клик house на самом деле как выражение на другой колонка и в данном случае я взял из роу который мне джейсон вытащил параметр айди то есть ли calls может парсить джейсон не очень хорошо но как бы так вот очень очень быстро но не очень правильно но для наших целей это подходит вытащили а иди и положили его в транзакцию сразу а когда говорю что это может работать во время select of ими и вот что то есть мы можем эту схему взять и дальше расширять то есть я решил сначала что не нужно транзакция а потом решил что на самом деле в этой транзакции есть ещё много полезных вещей вот который хорошо бы иметь было бы сразу на записи на и и что я могу сделать я могу сделать alter ты был и добавить колонку с дефолтом причем клик house он естественно не будет этой сети считать сразу потому что это было бы очень неразумно с точки зрения алексей миловидова вот он и в по начнем с точки зрения разумного человека поэтому alter у нас работает мгновенно у нас колонка добавится вот она будет пустой вы сделаете select окликал начнет делать на самом деле вот это сложно и регулярное выражение это будет медленно но и это еще не все когда клика вас начнет мер жить вот он это вы все-таки вычислит запишет в базу и через некоторое время даже если вы добавили колонку у вас в принципе уже в базе данных будет правильное значение которое быстро можно вычислить то есть не нужно уже разбирать регулярно выражением оно уже там есть вот так и когда мы это сделали что у нас получается у нас получилось вот какая то такая таблица в которой на самом деле мы вставляем только две колонки это имя файла и саму строчку logo а все остальное вычисляется так сколько он сделает там две трети работы за нас и он это делает очень эффективно тоже мы знаем что клика вас написан на си плюс плюс все общем функции оптимизированы хорошо и сделать лучше и быстрее там на джаве или на каком мишель и совершенно точно точно нельзя так теперь посмотрим как это все работает или может работать сначала какой объем локов вот это объем логов из этой статистики которых там загружает это не тот что лежит реально сервера что мы думаем лежит сервер услуги за 10 дней с почти s500 серверов это тома де 1,3 миллионов файлов в которых шестьдесят четыре миллиарда записей и всего это занимало вот на диске упакованная в брод ли шестьдесят один терабайт когда это загрузилась клик house сожалению открыть счет старую версию слайдов но но неважно вот то у нас получилось здесь получилось почти петабайт сырых данных распакованных то есть я их не мог посчитать во время загрузки и на их можно посчитать кликал или почти петабайт данных они выражались восемьдесят четыре терабайта то есть упакованные в брод либо лишь сотни терабайт откликалась и 8 4 терабайта немножко хуже но но тоже это тоже неплохо вот можно спросить какой-то сервер от на самом деле пять серверов вот пять серверов достаточно средненьких у них просто достаточно большой raid-массив у каждого сервера по моему там 60 терабайт диск а в raid 10 в рейтинг то есть примерно на данные у нас есть чуть меньше тридцати терабайт соответственно на каждом сервере сейчас здесь 17 примерно терабайт данных а если в сырых чистовых посчитать то примерно 200 терабайт на сервер очень консервативная система опять же почему потому что в принципе сходить в логе надо редко прежде чем я покажу как это может работать быстро или медленно маленькое замечание что если вы хотите что-то там измерять в плитка оси вот алексей рассказывал про php что клика вас пытается кэшировать но вот слугами обычно это не получится то есть можно предположить что если у вас огромные там терабайт и логов то они и спрашивают произвольной транзакции то скорее всего в кэш не попадете почти никогда тем более что у нас сервер от нее очень большие диски гораздо больше и если вы хотите перед тем как все это тепло из чтобы пролезть как это работает да то нужно всегда сбрасывать каши файловой системы прежде чем выполнять какой-нибудь запрос иначе они будут выполняться очень быстро вот идеальные случаи когда мы используем полный индекс то есть ищем там лоб лоб запись какую-то я здесь обрезал чтобы не забивать экран четко по имени файла и по транзакции работает полторы секунды достаточно достаточно неплохо вот хуже случае когда у нас есть только частично индекс то есть мы не знаем на самом деле какая транзакция вот и только предполагаем в каком типе файлов она находится тогда это работает уже 17 секунд и уже немножко немножко не нравится что это немножко кажется долгим для того чтобы найти транзакцию и наставили почему так долго это интересная тема для дискуссии я постараюсь чуть-чуть ее коснуться во первых вот эта колонка у нас записью она очень тяжелая она занимает там 15 20 килобайт вот так ли calls пытается читать сразу по помногу и в частности он считают пытается читать по многу потому что и он индексирует не каждую запись только каждую ценную запись и когда мы делаем запрос даже который должен вернуть одну запись кликал все равно приходится прочитать много приходится прочитать много это распаковать что тоже много это достаточно большие накладные расходы случае частичного индекса она как бы не так очевидно случае в случае полного индексов учитесь и снова индекс oklick все приходится в любом случае считать что-то лишнее вот это лишь не она накапливается накапливается накапливается соблюдать мы прочитали этот миллион с лишним строчек и из разных мест может быть вот что такое индекс игра норовите которые мы уже уменьшили на 1024 вот и может быть надо его у мешать еще то есть кликал хранить данные отсортированы и на диске и хранит яндекс и на диске в памяти которые индексирует каждую n-ную запись по дефолту n8 192 мы уже немножко уменьшили сейчас попробуем уменьшить еще что это значит это значит что есть файле засечка то есть когда мы хотим найти что-то по индексу кликала сможет найти только примерно там то есть неточно эта запись эту запись плюс там сколько это записи ну или там вот это окно она немножко сдвинуто в одну или другую сторону то есть он прочитает записи в любом случае больше плюс дополнительно к этому еще сами данные мог быть разбиты на другие блоки другим образом в файлов данных то есть он может еще чуть чуть больше прочитать вот хотелось бы наверное сделать яндекс и журнале типа меньше индексировать может быть почти каждая запись но тогда нам потребуется существенно больше памяти я просто не хватит то есть если здесь сейчас яндекс может занимать где-то гигабайт памяти это если мы увеличим скажем там восемь раз это уже 8 гигабайт памяти она на сервер если еще восемь раз уменьшим игра 0 ведь еще восемь раз больше памяти то есть время будет все больше и больше это не очень хорошо здесь нужен некоторый разумный баланс но и проверим то есть вот мы сейчас попробуем уменьшить немножко индекс уменьшить гранулярный будет ли какой-то эффект вот на на полной записи то есть первый случай когда мы используем две колонки индекса эффект почти в три раза и видно что количество строк она уменьшилась ровно ровно 8 раз посчитать конечно строку меньше ровно 8 раз количество данных которые откликалась обработал и прочитал она уменьшилась не в 8 раз она уменьшилась всего а там в два с половиной раза если про что вот то есть как бы эффект есть но конечно не восемь раз а по частичному индексу эффект еще меньше то есть у нас было 17 секунд мы уменьшили 12 секунд ну все-таки crack house для поинт qrs предназначены не идеально но тем не менее это уже хороший результат я считаю что если нужно иногда там 1 или несколько раз в день найти транзакцию просто так вот то мы можем это использовать и 12 секунд совсем-совсем немного это идея можно развивать то есть как это такая некоторая инфраструктура с которой можно что-то начинать и что можно здесь начинать например можно искать все транзакции пользователя или же искать последнюю транзакцию пользователя и об этом я чуть чуть попозже рск поподробнее расскажу предположим что вы занимаетесь какой-то там а3 бьются в рекламной сети и вам нужно привязать там некоторые вент к последней транзакции пользователя для этого ее как бы нужная транзакцию найти последние я вам рассказывал это на backend конференции но вряд ли здесь многие многие там бы там были то есть идея в том что конечно можно использовать какой-то иным restore этом хранить все все все транзакции когда приходит и квест туда сходить в этой транзакции там найти вы че все транзакции пользователя найти последнюю которые подходят под это атрибуцию там связать и записать обратно но это хорошо пока данных не очень много так получается что если использовать атрибуции по impressions по показу и имеет достаточно большое окно в рекламе особенно в брендовый считается что все что человек вот видел аж 30 дней назад может быть по конкретным продуктом у него это где-то там откладывается и когда он что-то купил то надо все это дело проанализирует посчитать и может быть даже заплатить тому кто он там 330 дней назад видел какую-то рекламу через кого-то вот конкретно этого продукта и получается очень огромный объем данных которые держать в памяти поэтому можно использовать не память cliff house вот и включалась и выстроить вот такую хитрую структуру ну во-первых мы начинаем с того что опять же вытаскиваем user айди как отдельную колонку а после этого строим адыгея наш 33 гете наш 3 этот очень классная штука включался которая позволяет строить частичная агрегация для тех вещей которые обычно не агрегируются например unity то есть вы можете построить агрегацию для unique в хотя и ники складывать вроде как считается что нельзя или вот что я здесь использую это агрегацию для ork макс то есть вам понять что максимум можно агрегировать легко то есть максимум от максима всегда будет максимум а вот арт максимум уже не получится то есть нужно хранить что дополнительно вот для этого используется агрегате он мертв клика оси которая хранит стоит агрегация то есть какую дополнительную формацию чтобы можно было потом это все объединить и вот такой вот конструкцией то есть используя все наши те данные которые мы собрали пологом вот прям на них мы можем выстроить так называемый snapshot он будет хранить последнюю транзакцию для для пользователя или последнее состояние транзакции попользоваться вот в этом примере последнее состояние и если вы хотите что то там получить из этого сна что-то просто выполнять такой запрос и работает это достаточно хорошо потому почему потому что мы usa ради поставили на первое место здесь в яндексе здесь у нас четко за заточенный под бизнес задачу случай кроме того мы можем сразу выполнять этот запрос для многих юзайте а не для одного и если так делать то получается достаточно эффективная по цене решения не требующее большого кажется железо вместо того чтобы разворачивать огромные in-memory систему можно в общем обойтись маленьким классом кли хауса вот подводя тут некоторый промежуточный под итог я хочу отметить что клика us неплохо работает сырым джейсоном и это иногда очень сильно упрощает жизнь если у вас какие-то данные с джейн джейсоне и point херес если очень хочется то можно то есть это до неэффективно в клика уся особенно если это делать часто но тем не менее вот для таких вот редких случаев когда надо достать что-то достаточно редко это работает вполне неплохо обратить внимание что в принципе это все было еще антипатра в том смысле что мы не использовали колон ночную структуру практически по нотам и мы и без того чтобы наделать много много колонок которые хорошо оптимизированы под там разные наши структур данных у нас все лежит в одном зависанием и если хочется поискать поэтому джейсону что-то уже вот всякими там все теми же функциями работы с джейсоном или регулярными выражениями то это будет конечно очень медленно запрос вернется но он-то может проработать несколько десятков минут все таки про лопатить 80 терабайт данных а предупредить придется калька усов но если мы в один день смотрим то это меньше им придется это все загрузить распаковать там выполнить там это поисковую операцию и как и продолжить дальше то физику не обманешь это все будет очень долго поэтому нужно если хочется делать по young ladies надо очень внимательно подходить к тому как именно вы ищете вещи и если обычно говорят что для клика уса не так важно какой у вас индекс в принципе на чтобы он был не самый просто плохой то для пленка вырез без хорошего индекса ничего не получится ну и последнее вот здесь а другие сидеть с марсело ветвью видите наш 3 мая властью она позволяет получить последнее состояние что тоже как очень удобная и полезная технология которая далеко не все используют теперь совершенно другая задача вот совершенно с другой области совершенно по-другому используется кликал то есть предположим что у вас есть некоторые данные по времени ну как какие-то финансовые или нефинансовые есть эти данные они приходят в нерегулярные моменты времени то есть вы точно как бы не знаете есть какая-то фиксированная временная сетка и у вас стоит задача аппроксимировать ваши существующие данные на эту сетку вот либо же их сдвинуть сдвинуть на эту сетку то есть вот какая то такой там график непонятный есть здесь в качестве времени использования даты какие-то там случайные числа и видно что временные промежутки разные вот а для многих видов там анализа каком и финансово или так далее вам нужно чтобы вас данные были про нормированы одинаковым образом с точки зрения вот этих вот временных промежутках и вы хотите их аппроксимировать выхотите вот некоторые люди захотели там это аппроксимировать либо вы хотя бы до этой сетки фиксированные сдвинуть то есть оставить то же количество да это points но уже как бы привязана привязан к сетке и как это сделать накликал оси можно если вообще сделать или нет ну начнем со структурой данных всегда то есть вот у нас структуры данных очень простая у нас есть таблица т где есть номер серии то есть какие-то у нас там много серии жить в таблице есть да то есть значение вот и есть таблица сеткой там другие даты какие то другим образом построены вот и я специально писал что это энджин memory предполагается что сетка мы можем использовать разное это вообще временная структура нам она нужна только только иногда и какой алгоритм примерно можно предположить то есть вот у нас темном выделены точки которые обходятся кассу к исходным данным гибкий plos one вот и мы не считаем линейную интерполяцию просто соединяем там линиями вот либо вот в левой части 2 2 под задача мы сдвигаем до 2 сетки ну вот так вот захотелось как вообще это можно в принципе сделать на накликал ся кто может то есть чтобы чтобы взять и на кликовых посчитать хоть и хотя бы какую технологии использовать нет здесь ничего не надо корригирует надо просто взять и преобразовать данные никто не знает очень хорошо значит я вам сейчас расскажу надо использовать массивы есть обычно массива используется включалась не для этого ну или не только для этого то есть масел это очень классная штука например чтобы хранить хэштеги вот и можно очень быстро найти все хэштеги хэллоуин примерно или это очень классная штука чтобы охранить какие-нибудь с собой dice то есть они мвд пирс там вы храните два массива и можно понять по ним легко и легко искать вот такие такие случаи позволяют существенно упростить там схему сравнении с каким-нибудь с другой базы данных вот казалось бы причем мотивы какая массива относится к к наша задача а вот так вот относится сейчас еще попробую сделать один тест один раз я делал в эту аудиторию он прошел наполовину сейчас проверим ваша аудитория кто знает что вот это такое написано на экране не алексей машук опустить ctos кто-нибудь хоть кто-нибудь может предположить что это написано и да правильно есть греческие буквы так так хорошо подсказка эта программа прошел тест прошел в принципе в том что и что уже все забыли эта программа на языке на языке который называется и programming ленгвич просто назвается и пел язык 1960 года очень интересные необычные в частности тем что для того чтобы на нем программировать не выпускалось специальная клавиатура вот что с этими всеми буковками вот а кто может догадаться что делать это коко эта программа здесь есть подсказка в принципе ну так нет не совсем не совсем давайте посмотрим еще одну программу тогда это у нас и пил вот еще одна программа а вот это кто знает на каком языке написано не смотрите усилий уже ушли все греческие ушли все греческие буквы да думаю что вот этот вот 0 черточка это о игра жизни это правильно до этого угадали что что что предыдущая да это эквивалентная программа но создатели вот этом языка они на самом деле это такая а попсово на я версия perl а который называется язык джей вот создатель этого языка они считали что у них слишком короткая жизнь чтобы писать длинные программы вот и они вот придумали этот язык j на котором периодически выигрывают всякие там эти конкурсы программирования где там программирует какие-то нетривиальные вещи за карта короткая короткого это язык достаточно старый он по моему там середина конце 70-х годов и до сих пор на нем разрабатывать например вы может быть слышали про база данных кейди беда и деби топки деби класс вот она слышала нет используется в банках там она супер супер быстрая in memory а там баз данных вот она написана на следующем развитие языка джей который называется языке и по вот так что или эти эти идеи идеи живы так а вот следующего пасовать что вот это такое а вот это уже клик хаос нет но это уже не программа это уже не играет negro жизнь converse к это уже на самом деле программу которая нам нужно написать я специально здесь написал самым непонятным образом хотя оставил несколько лишних пробелов чтобы конечно на в принципе вот такой хуан лайнер получается ну может быть больше похожей правда на лист причем на j ноте но тем не менее вот прям вот есть а скопировать вот этот код с ес в crack house вот его скопировал выполнил он как-то отформатировал и чуть по другому и выполнился ну конечно в таком виде никто к врагам и не пишет я его и его специально как бы портил до что чтобы чтобы сделать по непонятнее да то есть программа она на самом деле была написана вот так вот это накликал оси где где уже все более понятно выглядит сады во-первых и во-вторых как бы глядя она имеет дополнительную информацию который просто удобно отлаживайте сначала мы берем из сетки создаем массив то есть вот этот выезд 1 это такой аль азим глоба инга глобальный включался способ делать такие оля за то есть мы создаем массив и сетки потом заворачиваем в массивы все наши и и время и время и и данные причем там группировка по иди да то есть это мы все для каждой для каждой серии делаем отдельно вот после этого идет шаг 1 вот для каждого элемента в c то есть мы попируем c в некоторое множество индексов кей до получаем множество индексов вот после этого мы делаем ленин интерполяция то есть переводим вот пару то есть опять же вот и рэй map может работать не только с одним оси у нас нескольким массивами передаем ему два массива отсеки и и переводим пару уже в уже в интерполированное значение потом как будет вторая часть задача уже попируем с в другое такое множество индексов и округляем это да сетки вот такая вот получается программы накликал ася здесь посмотреть что она выводит то тот сначала у нас идет отладочная информация то есть вот эти вот наша сетка то можно увидеть что каждые два дня то есть seo на через каждые два дня идет из и это наши исходные данные которые как бы там совершенно произвольные временные промежутки вот потом веет а вот наше значение которые были дальше делать множество индексов то есть который мы находим куда в общем надо там это сдвигать интерполяция и второй наш the index of и сдвиг на из них по сетке так вот такая вот штука просто на массивах одним из сквозь запросам мы сделали для всего большого дата эта фраза для всех серий его можно выполнить положить в другую таблицу или там ку-куда это нам нужно ли какие-то система анализа и это будет работать быстро потому что такое хаус нет не замерял то есть это был как бы такой бой больше прототип чем реальная система но она показала что такие вещи можно сделать здесь и чуть-чуть комп и размышлять что вообще нужно для сложных вычислений вплеталась а то это в первую очередь вот массивы и функции работы над массивами вот во 2 а может быть это на самом деле в первые немножко воображение той чтобы вот придумать вот то что там написано до в общем ну либо иметь какой-то опыт функциональном программировании и понять что его можно здесь применять либо просто чуть-чуть попытаться воображать и в принципе еще было бы неплохо расширять то есть наверное можно было многие здесь вот эти вот операции их сделать более эффективно если если бы они были написаны на си плюс плюс и вот но поскольку кликал он расширяется не не самым тривиальным образом то мы их написали отличался тем не менее откликалась можно расширять и вот реальный пример который был показан там несколько некоторое время назад была задача у одного человека из из bloksi что ему нужно было считать roi de france по массиву вот и он делал вот так вот то есть можно действительно с помощью функции работы с массивами это не единственный способ там несколькими способами можно посчитать roi de france вот тут для упрощения здесь написано а еще одно выводится на самом деле это ради france по массиву 1 а вот показалось это неудобно и он захотел сделать лучше он взял и написал свою функцию включался р difference сделал пул request лишь миловидов посмотрел в мир жил и теперь увлекалась с функцией де фрaнс а также еще много других новых функций работы с массивами все гораздо удобнее и эффективнее резюме то есть калле krause это не только olap система то есть не надо думать что накликала сета только аналитика только там эти многомерные кубы и так далее crack house очень гибкая и часто ее называют система баз данных для программистов потому что написано программистами для программистов на самом деле написано программистам для всех но программисты могут не получить гораздо больше удовольствия использования чем может быть те кто пытаются написать сложные сложные join и они не могут он не работает вот и начинает ругаться что кликал с join мне не до конца поддерживает и так далее все эти вещи которые я рассказал они есть конечно в документации то есть и она просто внимательно читать и там есть достаточно много примеров и но читая документацию конечно же недостаточно нужно экспериментировать то есть клика us такая система которая любит чтобы с не экспериментировали чтобы смотрели как там все выполняется как работает схема и так далее алексей прекрасно рассказал два часа назад как можно профилировать различные вещи выполнение запросов и понимать какие структуры работают эффективно какие нет где вы теряете где вы приобретаете и так далее и спрашивать спрашивайте в телеграме спрашивайте здесь у нас через 20 минут будет митап во владивостоке то можно вообще задать любые вопросы и потрогать пучками вот такой вот набор юного слесаря если хауса я вам сегодня попытался продемонстрировать спасибо вопросы здравствуйте скажите а там вот примере которые с массивами там же из фото максимальное ограничение на количество элементов в массиве папой там или по количеству элементов то есть не получится там если временной ряд сильно длинный в данном случае как бы были даты вот и поэтому дат не очень много проблем такой не стояло если временной ряд очень длинный надо начать бить на куске то есть это понятно то есть массивы они она они конечно не панацея если нужно там миллиона обработать но я другого способа включался без массивов это сделать не знаю если был какой-нибудь там oracle или поздно сможет был написать процедуру и она скорее всего работал бы медленнее чем вот таким образом написаны написанный запрос расчет по поводу а макс state то здесь полчаса требуется происходит только если один ивент у одного пользователя надо за а трибетить последний тампон загсы но что если их там за акции было несколько пользователей и получается что если бы например вчера будет он за кто сегодня тонн за акция вчерашнего лента должна уйти вчерашние транзакция сегодняшние сегодня есть как бы с паутинкой танк range как там он называется потому только с точности та та та еда подерживать она range пишет справочник или словарь он не подходит если у вас там этих несколько сотен миллионов транзакций на самом деле лежит в поиске то есть он не поможет это раз во вторых то есть предполагается что требуется она происходит это в общем-то не задним числом а у нас сейчас вот есть какой-то набор ивентов например сегодня или на самом деле там пакетами тоже по пять минут который нужно сделать атрибуцию и по или для каждого event-а находится там за человека последняя транзакция или на самом деле последние несколько потому что иногда есть логика какая из этих последних транзакций она на самом деле должна быть использована и эта логика она не выражается на уровне сиквел она лежит там в другом месте александр спасибо за отличный доклад скажите пожалуйста водки с лагами зачем и альтернативы какие будут что чего-то но добились на самом деле логе хранить от конечно не большого ума не надо можно их просто выкинуть наглеешь ах да они там будет решать проблемы с тем что нужно искать то есть вот найти транзакцию в сколько там я считал петабайт данных да ну хоть они там упакованы 80 терабайт этот и сделать это быстро очень низких секунд задача на мой взгляд далеко не тривиальная особенно с учетом того что на ее не хочется тратить очень много серверов то есть это то что требуется сделать там может быть несколько раз в день конечно можно например поставить там с ферму из там стояла стиков и они будут это очень быстро делать но это будет очень дорого банально а тут стоит пять серверов они стоят там места там около 1000 долларов в месяц в хостинге почему нет спасибо потому же вопрос по поводу логов я правильно понимаю что вот эти 12 17 секунд которые мы там вытаскивали запись плодишь нику туда не включалась время как раз расчетом и же выставляли что этот бар сердце джейсон ну это уже данные которые лежат уже включалась они уже подготовлены но это cold storage то есть я специально указал что мы для того чтобы проверить как это работает мы всегда дропаем ся каши то есть это фидере аль на сколько времени кликал за потребовалось чтобы с учетом того что мы используем не лучший yandex потому что файлов много в принципе и с пирсингом женщины нет ли jason jason польстятся наверное in certain перекликалось будет по парте jays a-jays тонн сердца и заполнять дефолт то есть если с паркингом это этапа потому я услышал что принц смерти или парсится не всегда есть некий там умный подход до что только при том когда мы трогаем эти да нет это это если сделать alter ты был тогда он не будет их считать сразу это для альта для альтера а вот если эта таблица уже есть то любой insert где у нас вот это вот либо inserto он уже приведет к тому что все же здесь показано по считается вот вы рассказывали про функцию arb макс state она убирает соответственно максимальный по критерию подати например если у меня транзакции принесла за одну секунду он пример изменился статус дважды то как вот здесь выбирать ну понять вопрос или не дискретность так как daytime хранится на с точностью до секунды одинаковой транзакций сразу здесь здесь tts это на самом деле не не daytime а там это правильно сказали что с точностью до секунды может быть неоднозначность поэтому там т с надо хранить либо как строку до либо дополнительно миллисекунды чтобы ну и дойди до либо на сам ездить как unix time она хранится то есть выбора нет ну в daytime там секунда до то есть или либо хранить отдельно миллисекунда отдельным полем либо хранить что-то какое-то другое время как как big and просто с точностью до миллисекунд отдельный колонка"
}