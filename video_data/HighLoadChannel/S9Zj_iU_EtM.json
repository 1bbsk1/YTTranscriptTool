{
  "video_id": "S9Zj_iU_EtM",
  "channel": "HighLoadChannel",
  "title": "Гибридная архитектура: разделяемый на микросервисы монолит / Станислав Сидристый (ЦРТ)",
  "views": 8236,
  "duration": 2667,
  "published": "2023-04-28T06:21:30-07:00",
  "text": "а меня зовут Станислав сергейстый Я работаю архитектором в центре речевых технологий и в основном мой стек упирается это все Sharp Вот это прям супер основной Вот иногда ухожу в CC плюс пореже вот и когда ностальгирую ухожу в такой странный язык силой это смесь c++ и dot.net вещей пишу иногда книгу вот сейчас не очень пишу Вот ну муза не прет Как говорится но в целом в целом стараюсь и если что со мной можно связаться либо по телеге седристый либо по почте это странный который когда-то в детстве завелась с тех пор от неё не избавиться значит давайте Попробую вас ввести в некий обыденный мир да ведь ну в основном думаем что есть два типа архитектуры Да основных это Монолит когда все в одном Вот и когда микросервис надо когда все по отдельности работает вот выполняю какие-то задачи Вот Но иногда очень редко может возникнуть ситуация когда может понадобиться И то и другое Давайте посмотрим что может быть дано с точки зрения Ну проектирования Да система может делаться под некоторое понятное будущее Вот это например да может быть какая-то будущем высокая нагрузка которая с чем-то вызвана может быть вызваны какие-то внутренними а процессами Да какие-то не знаю там составление отчетов переработка данных там еще что-то да то есть какие-то внутренние процессы которые создают эту нагрузку но который не является результатом действия пользователя так например какие-то внешние причинами Да работа тех же пользователь либо например затягивание каких-то задач через сервис интеграции с какими-то внешними системами это может быть какая-то динамическая нагрузка на разные участки системы например да днем может быть одно вечером совершенно другое ночью совершенно полное отсутствие нагрузки Вот и мы можем как результат перераспределять нагрузку Да унося некоторые задачи на вечер на ночь вот а и соответственно возникает идея что было бы хорошо вот чтобы система автоматически расширялась и сужала количество задач которые количество сервисов до рабочих единиц которые бы эту нагрузку на себя принимали но да сейчас-то нагрузки нету то есть это все будущее вот а потому нужна какая-то изначально простая конфигурация наоборот может быть Да сейчас мы делаем огромную систему Вот потому что например пришел какой-то большой большой клиент вот ему нужно много чего делать Да вот у нас например человек технологий что мы делаем мы делаем соус для распознавания голоса переводов текст для перевода текстов голос но вот ну когда надо какую-то например озвучить статью Да в интернете Вот и многие многие манипуляции с голосом то есть это звучит как большая математическая нагрузка на CPU Вот либо на видеокарты Вот и Вот наши клиенты которые этим пользуются вот есть большие Да вот которым нужно много-много большое количество текстов озвучить Либо наоборот большое количество аудиофайлов перевести в текст чтобы дальнейшем проанализировать Вот Но есть Клиенты всегда они такие появляются им сложно отказывать Да когда хотят по-простому То есть у них нет таких больших мощностей у них нет таких на вход да у них какие-то небольшие объемы файликов либо какой-то другой информации вот и мне нужно строить огромный дата-центр ставить большое количество серверов Вот это ДТП им достаточно там не знаю одного сервака чтобы на нем все работало Вот и соответственно вот когда проект на старте Да очень часто непонятно куда идти что делать например разберем ситуацию такую Монолита вот мы написали Монолит растет нагрузка возникает службы какие-то фоновые задачи с какой-то неравномерной нагрузкой да и с каким-то собственным состоянием Ну естественно после года 2 такой эксплуатации вот возникает желание выделить это все в отдельные подсистемы и куда-то там отдельно например через кубер горизонтально отмасштабировать вот Ну вот у нас такая ситуация вот часть не догружена часть средненькая и какая-то вот прям как красная зона Да вот если эту красную зону попробовать вытащить Вот то соответственно все будет равномерно распределено и все будут спокойны что ничего никогда не отвалится и не упадет например это все заворачиваем через рынки Вот и Вот соответственно вот мы получили микросервисную архитектуру где часть может быть работает все еще как монолит хорошо вот но в той системе Да вот в этом решении мы делаем количество работы большое дополнительное Да на то чтобы это все растащить вот далеко не всегда изначально конфигурация предполагалось что это вообще будет когда-то сделано Да некоторые куски просто переписываются зачастую все переписываются то есть что-то переписали дифайнами закрыли проверили удалили да Или еще как-то соответственно вроде как был хороший Старт Да вот мы изначально не затратились на Over engineering Да когда мы соответственно очень много чего сделали чего изначально не понадобится но потом может быть понадобится может быть и нет да то есть мы не стали сразу же вкладываться микросервисную архитектуру не стали сразу вкладываться в соответственно найм devops инженеров и т.д и т.п там что-то тестирование это все так и сяк тестировала то есть вот этого всего изначально не было Вот но этот весь все эти проблемы перенеслись в будущее хорошо второй вариант мы там изначально знаем что у нас какой-то супер заказчик Да там просто заказ пришел от какого-то супер заказчика например там не знаю от озона Да изначально понятно что зона большая компания вот У них все будет хорошо вот поэтому мы изначально закладываемся на то что будет определенная стиль нагрузки Вот и изначально понимаем что скорее всего микросервисное все порешает хорошо тогда все замечательно Вот Но если у нас нет такой уверенности Да что будет такой заказчик и вот мы делаем какую-то систему которая будет классно работать но не понятно пока что для кого да то есть пока что заказчики небольшие А может быть будут большие непонятно Но изначально выбрали микросервисную тогда мы ожидаем некоторую большую неравномерную нагрузку в будущем Да вот изначально мы делаем большое количество затрат на диплои в кубер поддержку кластеров чтобы все правильно кластеризовалось чтобы не было такого что из кластера нода выпало и все развалилось потому что все было неправильно настроено поддержку там radisso rebita каких-то других мессенджеров Может быть там mongodboxgress чтобы все там красиво репликацией там там протекционирование там еще прочее прочее прочее короче вот изначально заложились все сервисы написали правильно часть теста часть stateful вот настроились CD наняли de voxer of которые это все поддерживают обучили тестировщиков что вот надо вот Будьте добры пожалуйста тестировать и так и так Вот потому что ну если мы не будем изначально тестировать в горизонтально распределенной системе да то мы никогда не поднимем потому что когда-нибудь мы уйдем от этого вот и соответственно Когда у нас изначально написано якобы горизонтально распределенный мы так никогда не запускали А в будущем будем обязательно да И это не тестировать то оно не запустится так там обязательно будет сто пятьсот багов вот в том числе каких-то циклических зависимостей может быть появится Вот и просто не запустится то есть это надо все вкладываться Однако Да вот мы все Это вложились изначально сделали круто и т.д и т.п Да запустили и на каждом из сервисов на каждом серверов мы имеем такой бреющую нагрузку Да потому что ну как бы написали Круто Вот сейчас оно не нужно но понадобится потом вот ну ресурсов съели очень много Вот соответственно а все это за депоили очень хорошо нам Да чтобы все правильно работало Вот но и сервиса тоже разложили Вот но в итоге в итоге все это может быть работает вот так вот на таком минивриате Вот потому что пока что такого классного заказчика нет вот такой была такая ситуация что вот так вот здорово сделали вот но пока что такого заказчика нет и поэтому все работает на одном серваке есть такие варианты Отлично вот Ну вот такой случай Да может быть Однако да При этом при всем если заказчики появится сохраняется возможность правильного диппоя на неограниченное количество серверов в кубе ли возможность горизонтально масштабирования ДТП но Да чтобы не столкнуться с неработающим комплексом в будущем как я и сказал вот важно иметь диплой все-таки намного серверов как тестовой зоне так и для разработчиков Вот потому что ну как бы мозгом Конечно можно как бы практически все покрыто Вот но всего не покрыть Вот если бы все покрывали не было бы тестировщиков вот правильно да то есть поэтому надо и тестировать тоже соответствующие это соответствующие Касты на покупку оборудования или аренду Вот и так далее хорошо проблема общих ресурсов Ну давайте вот можно конечно еще вот когда у нас вот в таком все маленьком формате работает да там каких-то 150 сервисов там еще сколько-то вот можно начать играться ресурсами Вот например часть работы переносить на там после шести да или после семи То есть когда здоровая половина человечества уходит домой Вот и соответственно отдыхать начинает вот вторая часть не половина может процентов 10 вот остается на работе дорабатывает Вот мы их расчет брать не будем Потому что их Малое количество и соответственно количество нагрузки на сервера Ну такая теория на каком-то например месте диплоя Вот и что в итоге в итоге мы часть работы переносим на вечер да то есть мы говорим что вот вы сами так захотели работать на маленьком количестве серверов Ну денег например мало компании чтобы много себе арендовать значит часть работы переносится на вечер какие-нибудь отчеты например будет составляться по ночам вот хорошо да ограничение можно ввести Да чтобы ресурсы как-то сэкономить например да Все мы знаем что в докере можно как-то ограничить там по ядрам по памяти вот там выставить там в пол ядра в одно ядро вот память выставить максимальную которую сервис получит вот Ну например вот если продукт говорить Да ты в принципе про любую другую систему Ну например на дунете горбаче коллектор там или другие менеджеры памяти Они же как зачастую Да они работают только скажем так предполагая что только они на этом серваке работают То есть он видит какое-то количество памяти Да И вот он ее как бы полностью использует вот также поступает Примерно трек-пул вот если например он работает с точки с тем знанием что он типа один на сервере то есть на сервере серверная система серверная программа обеспечения должно быть одно чтобы друг другу не мешает да Если два серверных программ освещения это разные сервера вот в принципе на Джаве если там даже если не про общий а про разные говорить то в результате То есть когда у вас много сервисов запущено на одной системе они все равно будут друг друга мешать Потому что почему камешек он не резиновый да то есть как бы сколько там ядер столько ядер Вот и как бы ну тут как бы ничего не делай он если он 32 ядра то все там вот он не растянется однако Да вот как я уже сказал Пусть будет например 150 вот на 32 ядра вы все равно у каждого Да У каждого сервиса то есть вот он работает на каком-то количестве потоков Вот и все равно работает рамках операционной системы Да операционка выдает потоки Вот она их менеджер то есть выдает кванты Вот и соответственно они все равно начнут друг другу мешать Вот то есть это не то что например 150 сервисов запустили на системе и они все равно клёво такие работают значит они просто медленнее будут работать каждый из них вот и получается что при неудачном стечении обстоятельств Да когда пришла нагрузка вот возникнет потребность по ядрам больше чем их физических есть вот что приведет к очень нехорошим последствиям То есть например плов это letones увеличивается Да ну как бы они же через себя делегата пропускают методы функции то На каких языках пишет Вот и соответственно время между закладкой и выработкой этой функции оно начинает увеличиваться начинает увеличиваться таймауты между закладкой и выработкой вот возникает тайм-аут у сервисов Да что типа к нему обратился а он Извините запрос обработал очень даже не скоро и т.д и т.п начинается к чему это ведет вот если мы например тот же в тот пул начинаем заваливать делегатов много вот но при этом сервисов очень много на одной машине растет очередь задач увеличивается уровень терроризма потому что трэдпул такой типа ну он же не знаешь что помимо него еще их 149 он такой типа ну чтобы быстрее работать надо увеличить количество потоков А количество потоков меньше чем количество ядер значит можно увеличить он начинает их увеличивать падает опять общая производительность потому что ну как бы квантомическими Если распределять да то сервис если увеличить количество потоков то скажем так следующий квант будет получен все позже позже вот отсюда опять растет очередь задача и мы тестовой зоне схватили ситуацию Однажды вот искусственно что система ничего не делает и умерла вот просто потому что например в фоновом режиме собирались метрики вот эти метрики это были редкие задачи раз в секунду зарегистрировать какое-то число в промете Да вот раз в секунду это 150 получается раз да на самом деле потому что сервисов много вот на какой-то сервис пришла нагрузка вот остальные сервисы ихний интернет Тулы посчитали что типа опеньки производительность упала дай-ка накидаю потоков Вот Они каждый накидали потоков все тротуары посчитали опеньки опять производительность они опять накидали потоков вот в итоге было примерно по 75 потоков на каждом из сервисов которые ничего не делали но пытались разгрести его через задача вот это вот касательно если взять микросервисную архитектуру и поскольку у нас еще нет клиентов которым это надо запустили это все на пары сервачков да Вот такая вот не очень хорошая ситуация Ну да возникает тайм-аут и все падает Как достичь безопасности Да сумма всех требований количество ядер не должна быть сильно больше их реального количества Но это звучит максимально логично да то есть если мы даем нагрузку больше чем машина может вытянуть вот да не будет иначе существуют риск внезапной смерти всей системы во внезапное время например ночью например в субботу вот выход выход пришел такой очень неоднозначно рискованный это взять и объединить сервисы в один слопнуть их в Монолит Вот почему Потому что при слабовании в Монолит А все трат пулы превращаются в один все менеджеры памяти превращаются в один вот ресурсов становится резко меньше потребляться Вот и система начинает на том же железе вывозить отсюда возникла идея модульной архитектуры вот философское понятие на самом деле что такое модуль Да вот особенно в программировании вот программирования Я очень любил из детства И сейчас вот за то что этот мир абстракции вот можно взять написать программу Да программ будет работать в рамках операционной системы операционная система в рамках виртуализирующей фигни которая запущена в другой операционной системе и т.д.п вот на самом деле это просто ну линейный кусок памяти Да который процессором делится на Виртуальные части вот по правам выдается всем и в общем максимальный максимальная Как сказать виртуализация всего каждого понятия вот а потому если взглянуть например на это дело под другим углом то есть сервис Да вот он Привыкли что сервис это прям такое уже готовая программное обеспечение да то есть это неделимая вещь То есть он как бы сервис А что если сервис это как грубо говоря функция как модуль Вот и с этой точки рассуждать То есть это модуль у которого просто есть точка входа а если соответственно взять и написать Код да Ну вот как вот не знаю как Джаве это делается но в дуднете это есть проект который делает одну Dell Q вот а или so файл неважно но а есть Solution Да Solution под собой объединяет кучу этих долейлек и одна из них выступает экзешником Да вот что если взять и просто создать Solution в которой объединить вот эти вот Project файлы вообще всех сервисов вот сгенерить автоматически исходник который в рамках себя запустит каждый интрипоинт который присутствует в разных сервисах Вот и очень грамотно обернет Вот и получится одна программа но которая в себе будет объединять вообще все да все все фишки всю работу с рынки утром но вообще все То есть он просто будет как Монолит по сути то Ну возникла идея взвесили прикинули вроде прикольно Вроде должно завестись Давайте попробуем соответственно код сервиса модуль сам сервис это его оболочка Да меняем терминологию вот тогда что получается можно взять и скажем так место того чтобы иметь планшеру для каждого модуля мы можем сделать один лаунчер который эти три модули запускает да и тогда можно настроить себя таким образом что вот если тебе нужен Монолит ты галочку ставишь Монолит хочу Окей вот оно компилит это все как Монолит и на выходе у нас Монолит Вот а если галочку не ставишь у тебя Монолит нужен оно компили то все по отдельности получается куча сервисов каждый из которых упакована свой докер вот что-то даст из кучи нескольких Да станут одним большим общем-то полом Ну тут найти он Статик вот упомянуть нельзя можно свой написать Вот Но с ним будет работать не очень удобно то есть не так красиво как с общим вот там в джави их много я знаю вот тоже можно соответствующий фишки сделать через фабрики там чтобы ну например тоже привести логику к тому чтобы на определенных этапах при монолитной сборке разным подсистемам выдавался один и тот же Дэдпул вот А например в сборке когда микросервисная то соответственно у них у каждого будет естественно свой тропу Ну через какую-нибудь фабрику там еще что-нибудь Вот соответственно память станет единой памятью для всех да то есть меньше будет всяких различных кучи выделена То есть тут найти это куча маленьких больших и при пьяных объектов в жаре там свои кучи вот где-то там еще свои кучи но в целом имеется ввиду что вместо N умножить на количество кучи Да будет просто количество кучи то есть вместо трех вернее вместо 60 станет три например да вот а куча Как устроены если немножко так сказать отойти от темы куча на чем она когда операционная система вернее когда runtime запускается Да вот и внутри него работает программа и запрашивает выделение объектов там же не ходит каждый раз к операционной системе Да за каждым объектом он у нее большой кусок выделил начинает размечать потихоньку там до конца дошел еще кусок выделил потому что в операционную систему ходить долго Да это системный вызов это проход между тамринг три ринг 0 Вот скопированием стеков соответственно это много вот и если у нас Взять все эти микросервисы превратить в один Вот то получится что и вызовов вот этих вот станет сильно меньше в операционку во-первых во-вторых получится меньше вот этих вот выделенных кусков на всякий случай да то есть он выделяет много начинает авоцировать Но мы же не так что там типа в бесконечном угаре аллоцируем мы там сколько-то спровоцировали в каких-то сервисах Да и стоим дальше Вот далеко не все сервисы работают на полную катушку вот этот большой оставшийся кусок он просто висит в памяти если их объединить то 150 этих кусков станет одним Вот соответственно памяти будет потреблять меньше какие результаты мы получили здесь естественно без настоящих имен вот любые совпадения так сказать Случайность Вот вот Но вот мы запустили не на 150 до 11 сервисов Вот И посчитали что простое каждый сервис Ну в среднем потребляет где-то 250 мегабайт оперативной памяти вместе они потребляют два и восемь гигабайта а процессор они практически не используют но в сумме это дает 19 процентов вот тоже интересно открытие было система вся стоит Да а там например 4 ядра нагружена вот ровно потому что микросервисные да запущенное в несвойственном их среде на паре серверов Вот соответственно когда все в Монолит в монолите скомпилировали получили что памяти сильно меньше расходуется Да примерно 7 раз в Максиме Вот и примерно в два раза расходуется меньше цепи вот просто потому что нет вот этих вот огромного количества фоновых холостых задач вот на подборе метрик там еще почему-то до которые просто фоном нагружает процессор но при этом Если вы просто посмотрите что она делает Ну кажется что он ничего не делать то не должно потому что даже запросов нету под некоторые нагрузкой не очень большой вот тоже интересно результаты то есть примерно 3,6 ГБ Вот примерно там три с половиной ведра нагрузили вот Ну опять же да примерно примерно те же результаты получились если запустить в качестве Монолита то есть по памяти оно тоже примерно в 5 раз меньше занимает Вот и по процессору опять же примерно в два раза меньше занимает Вот это не значит что любую систему Запусти вот так вот она будет два раза меньше занимает да то есть это вопрос не в этом Ну вот вопрос в том что опять же меньше фоновых фоновых ненужных накладных расходов хорошо что же дальше делать Ну давайте локальные вызовы вот нужно что осталось вот есть куча сервисов Да они же не просто там ну как-то работали да не работали друг с другом правильно вот значит остались вызовы между сервисами вот и что не очень-то хорошо они очень-то хорошо что получается что вызовы остались через http и messaging да то есть как бы они типа вместе но почему-то чтобы вызвать соседнюю функцию он должен сходить через КТП сам к себе Вот это создает накладные расходы на сеть расходы на себе Вот и на память вот а Наша задача то что то есть у нас была классная большая система для большого заказчика у которого много много работы вот к нам пришел другой заказчик их много пришло но они все мало работы нужно и много не надо их много да то есть как бы тоже деньги что отказываться Вот Но вот систему которая была изначально написано для большого заказчика если загнать в узкие рамки то мы все увидели к чему это может привести Да это может привести просто потому что это Случайный момент что-то произойдет система сама с собой войдет в резонанс да Ну я вот мне это нравится так называть Потому что когда тропу начинают так вот расти Вот но фактически он сам с собой в резонанс входит вот система входит в резонанс ее разносят и все короче ну просто она падает к черту и непонятно что с ней происходит потому что смотришь влоги она ничего не делает Просто Ноль вот а все ресурсы выживает значит почему почему вот это вот сюда плохо да потому что ну как бы чтобы вызвать какой-то метод что нам нужно сейчас вот на собеседованиях это перестали спрашивать вот когда я был джином вопросы были позаборосте значит что происходит когда происходит вызов по ищете пида но сначала понятное дело данные надо стерилизовать потом сформировать ищите пи запросы на каком-то буфере Да в каком-то массиве дальше нужно отправить что для этого нужно сделать нужно зайти в себе пи стек Да который Что делает который Ну там с гарантией доставки до отправляет пакеты ацк вот это вот все на той стороне приходит запрос по цепи мы получаем пакет вычитываем через Socket Разбираем ищите по запрос здесь реализуем делаем Что надо Да Ну что нас попросили то делаем стерилизуем ответ формируем ctp ответ в буфере отправляем в обратную сторону опять же через scp/ip там опять это все уйдет через там туда-сюда вот изначальная сторона принимает пакет разбирает тебе ответ здесь реализует его полностью да А там что там было какой там ответ был например там был ответ Ну как мы сейчас тут любим Да Джейсон документ с статусом все нормально Да вот типа все хорошо но и по сути то все что нужно было это вот это вот делаем Что надо а все остальное не надо было вот и оно все Еще присутствует если мы все собрали в Монолит доводим до финального решения Ну например у нас есть запросто ответ вот а соответственно когда мы все И вот они друг другу так вот взаимодействуют и чтобы это все получить как надо чтобы получить Так что они друг друга вызывают нужно что сделать нужно сделать чтобы например двумя путями можно поступить вот например можно взять вынести в Интерфейс Да скажем так Ну есть клиентская библиотека до который работает со своим сервисом Вот Но клиентская в плане она выступает фасадом Да вот мы вызываем она уже к сервису идет вот и сделать Интерфейс Да вот и в зависимости от того какой Билд собран этот интерфейс его реализация будет ходить либо просто в класс который тут же находится либо по хттп Да уже уходить на ту сторону вот и через Di мы либо одну версию либо вторую версию подкладываем то есть Di интерфейс и две реализации одна реализация ходит по http вторая вот прям вот вместе да компилируется Вот все вот и то же самое можно через ну к мессенджменту сделать да то есть мы просто для Messenger сделали такую библиотеку которая реализует контроллеры методы у контроллеров Да И вот нам в этом плане проще взять в Интерфейс это все обернуть и вынести Вот Но если у вас не так то можно вот точно так же написать клиентской библиотечки которые отправляют сообщения в шину Вот и получает соответственно слушают сообщения в ответ Вот и соответственно тоже через Di подкладывать либо реализацию которую локально находит либо на сервак хорошо а я тоже самое сказал да какие можно сделать выводы из сказанного выводы простые да то есть ну у меня этот сайт на самом деле уже не знаю докладе вот я один раз случайно оставил старые выводы встает такой на сцене смотрю выводы короче прикольно вывод они те Вот и понял что все выводы которые Ну для этого доклада они очень универсальные Вот они очень хорошо подходят вот если замечать проблемы как решать То есть если заметить проблему что грубо говоря есть Ну вот у нас была проблема один раз что стандартный пул не выводит вот мы написали свой да то есть мы его боялись и просто свой написали кто эту проблему решает здесь например Мы заметили проблему Да что Несмотря на то что ну там же нужно то есть Вопрос не в том что можем ли Да запустить систему микросервисную на малом количестве железа задача стоит нужно запустить систему на малом количестве железа Вот соответственно проблема Это у нас память Вот и работы сетью которая не нужна потому что все микросервисы запущены в одном экземпляре вот как решать слить Да ну как бы надо чтобы всю работу как мы налить тогда все проблемы решена Как сделать просто взять условную компиляцию вот можно менять какие-то привычные стандартные механизмы да то есть если думать немножко Out Of Да out of box вернее даже вот то приходят такие нестандартные решения это очень здорово Вот потому что если бы например Это идея не пришла Мы бы шли стандартными путями да типа вот есть микросервисная есть Монолит вот туда-сюда можно либо распилить либо склеить Вот то соответственно Мы в итоге бы наверное отказались от каких-то там заказов Вот потому что с инженером точки зрения Мы живем в рамках бинарной логики вот еще прочитали в Учебники то и знаем вот а дальше не идем вот фантазия Да просто взяли стандартный механизм поменяли получили реально офигенное решение и может это решение должно получиться лучше чем у против каких-нибудь там rentinek да то есть например антайм runtime не предоставляют таких возможностей Да что мы можем и так и так Запустить вот и это решение лучше потому что решает конкретные кейсы то есть опять же когда мы писали свой tradpool вот решение получилось быстрее чем стандартный пул дуднета то есть оно работало быстрее и на малых делегатах очень коротких и на длинных делегатах и на Малой на высокой нагрузке вот мы просто очень так плотно подумали переписали сделали свое бояться не надо вот если не попробуешь Никогда не узнаешь вот такие вот славные выводы вопросы Спасибо за доклад ваши вопросы Спасибо за доклад я не знаю может быть надо Нет таких инструментов но конкретно Java есть авторы jdk которые приспособили jdk для работы в докерах и на Вот как раз кластерах там насколько я помню есть возможность как раз сказать что ты работаешь на ограниченном железе меньше одного ядра меньше памяти чем вся система и Java видит это то есть видится что можно было бы сделать старыми подходами микросервисами просто сохранялись дополнительные Касты На там кубер или что-то еще развернуть но она все равно на одной машине максимум на двух но вот я как раз это затрагивал там в начале вот что если Ну количество микросервисов Достаточно уже большое Да вот а ядерного по-прежнему 32 Вот то всегда ситуация когда-нибудь что требования к железу выше чем само железо Вот и даже если вы выставите в пол ядра тоже можно то есть там вопрос не взяли пол ядра выставить выставить и Малое количество памяти вот все равно может магнититься ситуация когда пришел Внезапный пик Вот она выжрала вообще всё вот и развалилась Вот потому что везде пошли тайм-ауты методы перестали хорошую скорость проходя через этот пулы вот и т.д это просто реальность вот произошло вот Так что это не решит вот в данном случае это не решит Станислав Спасибо за доклад собственно говоря немножко похож вопрос на предыдущий но с другого ракурса то есть описанная вами история она больше прям вот про оптимизацию до последней ниточки когда мы там все накладные расходы снижаем в ноль но при этом имеем достаточно высокую стоимость разработки за счет того что надо там все файплайны написать все конфигурации подменить И поддерживать актуальным работающим состоянии для обоих случаев есть например же в кубе механизм Когда мы можем запускать коды с каким-то ограниченным числом ресурсов как минимальное число для его работоспособности и масштабировать его до необходимого в случае повышения нагрузки то есть кажется что вот эти вот все накладные расходы они всё равно Ну там поставить ещё там одну такую же машину рядом и на них можно забить А по стоимости разработки ещё одна машина будет гораздо дешевле чем только конфигурации поддерживать Ну не везде то есть машина хорошая стоит дорого Вот и заказчик который Ну ну не готов но не готов то есть есть такие заказчиков очень много да там например там и там 250-350 вот становится дешевле вот написать такую приладу вот и все это продать ну то есть именно вопрос получается в том что если там три заказчика это хотят выгоднее раскошелиться новый сервер если это там 100 заказчики приходят везде есть если есть Ну грубо говоря законодательная гарантия что оно будет много Где установлено Вот то или там еще какая-то гарантия Вот то закладываем все делаем оно везде всем приносит пользу и удовольствие а если нет то сделать кто-то другой Понятно спасибо здравствуйте Да спасибо за доклад у меня такой вопрос учили ли Вы Работать вашу монолитную архитектуру работать с разными подами в разных дата-центрах у одного и того же планируете ли вы это делать Нет потому что система поставляется она коробочное решение поставляется в сервер который находится в комнате в которой есть доступ только у некоторых людей Понятно спасибо за ответ Здравствуйте спасибо за доклад Очень актуальная тема Я дивов в тинькове и нас очень просят утилизацию значит наших проектов чтобы она все больше и больше была вот и вопрос в том что Насколько нужно выше квалификацию программистов джуниру там идолы чтобы реализовывать такие подходы но смотрите чтобы вот так вот сделать Да вот если брать тот же тут нет вот у них у нас у них Как семья уже вот есть ну как бы стандартный запуск сервиса Да вот то есть ну там так называемый хостел сервис то есть некий Билдер туда с помощью грубо говоря метода добавляется контроллеры которые будут обрабатывать http запросы вот туда же добавляется Di Вот и вот он аккуратненько может быть очень компактно написан Вот и если вообще все сервисы привести к единому стандарту да то есть этот проблема единого стандарта как вот все сервисы написаны вот если к единому стандарту привести то соответственно можно написать автоматизированный ту который их всех запустит в рамках одного процесса просто потому что они все одинаково у них всех одинаковый старт Вот то есть это не будет вообще никакой проблемой вот если они написаны все вообще кто как то конечно уже такой автоматизацию уже не сделать да то есть это нужно будет руками Все проводить вот поэтому в нашем случае это вообще ну как бы вот есть команда так называемая rnd они написали библиотеку написали соответственно код старта Монолита из нескольких микросервисов вот а остальные этого даже не заметили то есть на остальных разработчиков это вообще никак не повлияло от слова совсем Вот оно Просто где-то стартует как Монолит и все Ну то есть Оно даже логи пишет в разные файлики внутри егеря это видится как разные сервисы Да в консульт регистрация как разные сервисы То есть все системы видит это как микросервис архитектура но по факту это монолит последний вопрос Станислав А как происходит переключение на уровне идеала между двумя версиями запуска сервисов это переменная среды или что и условно компиляция как для работает фактически Да Как у вас то устроено Ну я он работает фактически скопом то есть в том смысле что у каждого микросервиков Монолита свой набор Они между собой не шарятся Вот это отличие Ну вот Да но откуда Блин хотел еще сказать но забыл что хотел все"
}