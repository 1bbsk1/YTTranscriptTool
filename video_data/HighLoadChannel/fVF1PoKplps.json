{
  "video_id": "fVF1PoKplps",
  "channel": "HighLoadChannel",
  "title": "Дорогой DELETE / Николай Самохвалов (Postgres.ai)",
  "views": 2628,
  "duration": 2948,
  "published": "2020-04-14T11:06:01-07:00",
  "text": "привет спасибо что пришли я николай будем с вами говорить про один десны запрос делиться что-то там ну немножко себе если кто не знает я пока он комитете хайло да с первого года 2007 и с подвесом я 2000 наверное 4 5 использовал его очень у многих проектах практически каждый день писк велят и там ти макс виайпи скелет вот там где мне очень нравится находиться ну и только и собственно группа руб мозга со счетом это же 2007 совпадения с холодом мы вот на митапе например доросли до 2100 участников второе место в мире после нью-йорка и обогнали сан-франциско уже давно в общем вот так вот так и у меня опыт сейчас последние сколько лет я живу в калифорнии в общем-то занимаюсь больше американскими компаниями в том числе крупными в некоторые из них здесь некоторые из них unicorn и то есть единороги знаешь больше миллиарда оценка и они активные пользователи под газ и там возникают всякие интересные штуки вот но в целом подгоняемая компания мы занимаемся тем что мы автоматизируем задачи такие которые устраняют замедление разработки то есть если вы что-то делаете иногда вокруг пояса возникает какие-то затыки допустим вам нужно там подождать пока админ поднимет вам тестовый стенд либо вам нужно подождать пока тебе его в на вас отреагирует и общем мы находим такие узкие места в процессе разработки и тестирования и администрирования и стараемся их устранить с помощью всякой автоматизации и новых подходов в общем я был недавно навел де беф в лос-анджелесе и это самая большая конференция по базам данных 45 по моему раз проводилось и там была был один из больших докладов про то что будущем базы данных будут sbd будут не только хранить они должны будут еще удалять данные и автоматически это такая новая тема почему потому что данных все больше экспонента в мире да вот есть за тобой ты это миллион миллион петабайты сейчас вот оценим оценивается что у нас там где-то 100 там и так далее уже за тобой в мире данных хранится и все больше больше больше и собственно понятно что что с этим делать нужно удалять вот эта ссылка на на этот доклад интересный но сегодня мы говорим что о том что пока что это свобода реализовано поэтому мы должны это делать но как должны обычно те кто умеет считать деньги они хотят двух вещей и они хотят чтобы мы удаляли поэтому мы должны как технически мы должны уметь делать то что дальше буду рассказывать это некоторое абстрактная ситуация которая включает себя кучу реальных ситуаций никто компиляция того что происходило на самом деле со мной и с окружающими базами данных много раз много лет и в общем-то грабли везде на них усилимся наступают значит допустим у нас есть база или несколько и аннан они у нас растут и некоторые записи очевидно мусор например вы там пользователь что-то там начала не закончила и понятно что через какое-то время там через месяц мы знаем что уже не закончит можно это уже не хранить какие-то еще мусорные вещи мы хотели бы почистить естественно желание это почистить экономить место лучше будет производительность и так далее в общем за ставится задача автоматизировать удаление конкретных вещей конкретных строчек of какой-то таблицу например и вот очевидно у нас есть такое запросу которую мы будем сегодня говорить удаление там где какой то признак что это мусор абстрактный до попросили какого-то опытного разработчика это сделать он сделал взял этот запрос проявила себя все работает потестировал на station все хорошо выкатили все работает собственный раз в сутки мы запускаем это все все хорошо что случается дальше dd растет растет растет растет и делит немножко медленнее работать начинает вот этот ежесуточно еда ежедневный потом мы вдруг понимаем что вот у нас 1 маркетинговая кампания трафик будет несколько больше поэтому давайте камелота личные вещи пока на паузу поставим и забываем вернуть и дальше через несколько месяцев вспомнили этот разработчик например уволился и ли он там другими занят поручили другому вернуть он провел надев провел нас ты джек все окей естественно нужно еще почистить то что накопилось он проверил все работает что случается дальше дальше у нас все роняется роняется так что у нас появляется какой-то момент когда просто все ложится и все такие в шоке что случилось там alert и никто не знает что происходит и потом выясняется что дело в этом делите было что пошло не так вот здесь причислены список из нас до дан список того что что принципе могло пойти не так да вот подумайте что из этого самое важное и я буду рассказывать а в конце мы сверим часы посмотрим как мы думаем у меня есть свое мнение у вас может быть свое мнение посмотрим интересно что кто что думает да например разработчик не не было review не не он не установлен этот review да то есть baby expert не посмотрел он был опытным взглядом сразу бы нашел проблему потому что у из доступ prada он видит там накопилось несколько миллионов строчек надо кое что что то короче надо аккуратнее с этим проверяли может быть не так как тогда мы может быть на жилье за ужас устарела и нужно нужен upgrade для для этой базы или что-то самой базы не так и нам с мозгом сына носик нужно переехать или может быть эти операции что-то не так или может быть ещё что-то там организационное нужно уволиться нанять лучших людей поехали значит первая ошибка не было проверки детей ну принципе вот значит если детей было бы да он был видел вот эти несколько миллионов строчек и опытным взглядом даже без всяких эксперементов он бы сказал слушать и так не делают вот допустим если бы этот код был бы допустим в в git label гитхабе там где угодно без боккетти и было процесс кадре view и не было было такого что без утверждения babay это это операция пройдет на прот очевидно теперь бы сказала у вас тут короче нельзя так делать он бы даже наверно с телефончиком вот так описать как я иногда делаю то есть можно даже ничего не гонять нигде сразу пишем комментарии не пойдет ни не буду оправить и собственно понятно что он сказал слушать у вас там с диска и опыт проблемы и соответственно там все все процессы с бесятся и общем плохо и вообще локи могут быть и еще вы заблокируете of the vacuum на кучу минут от нехорошо понятная проблема давайте вот окунемся что здесь вот тебе и увидел а да извините 2 вторая ошибка да проверяли не там то есть мы вот постфактум увидели что мусорных данных накопилось напротив много она разработчика там не было в этой базе накопленных данных дэна стерженьки там особо никто не создавал соответственно там был там 1000 строчек естественно не быстро отработали то есть понимаем что наши тесты они слабые то есть этот процесс ум который выстроен он не нах не ловят проблемы не проводили адекватные дтп из экспериментов соответственно желательно чтобы он был на таком же оборудование и очень важно ну то есть такое же оборудование всегда получается но очень важно чтобы это было полноразмерная копия базы данных это то что я проповедую уже несколько лет и вот в принципе год назад и об этом и говорил можете в youtube это все посмотреть дальше ну может быть у нас оборудование плохое ну да если посмотрим там вот lafense подскочила мы увидели что ютились утилизация сто процентов конечно если бы это был envy me диски современные наверное нам было бы намного легче и может быть мы бы не легли от этого может быть если у вас облака это бред может быть легко делаться да там подняли новые реплики на новом железе failover switch over и все хорошо довольно легко если же вас вам пример может быть сложнее дороже и дольше открытиями виду но вот такой вопрос а можно ли как-то иначе все таки диски поменьше трогать и вот тут как раз с помощью теперь мы ныряем в некоторую тему который называется чекпоинт тюнинг выясняется что у нас не было проведено чекпоинт тюнинг кто знаешь такое чекпоинт вообще поднимите руку пожалуйста кто знает что такое чекпоинт хорошо половину ну значит коротко объясню это когда у вас в любой sabado есть когда у вас данные в памяти меняются они не сразу записываются на диск это не нужно сдана и сначала информации о том что данные изменились записываться в опережающей журнал в райдер это hotlog и потом какой-то момент особо до решает что пора бы уже вот реальные страницы их на диск скинуть чтобы если у нас будет сбой поменьше делать ряду это как в игрушки мы если у нас будет сбоем из из нас убьют до мыса мы будем начинать игру уже стала место вот с последнего чекпоинта вот собственно все зубы до не это реализуют соответственно по умолчанию check point настроен так что он по сути вообще плоскости настройки они отстают и они рассчитаны на там на 10 или 5 15-летней давности объемы данных и операции и так далее и тэ ик моет не исключение вот если мы посмотрим если никто ничего не делает а вот эта информация из нашего отчета с пастбища капов доставать этическая проверка здоровья и вот какая то база там несколько терабайт на и видно хорошо что принудительные чекпоинты вот больше 80 почти 90 процентов случаев это значит что там есть для настройки чик может по таймауту наступить там действует например или он может наступить когда наполнилась уже в довольно много и по умолчанию вот это maxval says он один гигабайт по факту так устроен пользуюсь реально случается уже даже через там 300 400 мегабайт то есть вот вы поменяли столько данных и у вас чапман случается и если это никто не tune a service вырос и компания зарабатывает кучу денег у него много транзакций это очень легко и часто можно увидеть что check point выступаю там 1 минуту иногда уже 1 30 секунды на это даже накладываются друг на друга лишь не чекпоинтам друг на друга это вообще уже совсем плохо и соответственно нам нужно сделать так чтобы это просто он наступал пореже по сути да то есть мы можем просто поднять вам maxval сайт и он будет наступать реже но нам и мы разработали у себя целую методологию как это сделать более правильно принимать решение о выборе настроек четко опираясь на конкретные данные соответственно мы делаем 2 2 видок 2 серии экспериментов над базами данных 1 серия мы меняем макфол says и проводим массовую операцию то есть вот сначала делаем ее над дефолтные настройки один гигабайт и делаем вот этот массовый делить многих миллионов строчек нам тяжело видно видно как там тяжело смотрим что здесь койотом очень плохо и смотрим сколько валом и сгенерирует очень важно смотрим сколько раз чекпоинт случился вот и видим что ну не хорошо дальше мы увеличиваем макс полз раз повторяем увеличиваем повторяем и так много раз принципе там 10 точек это хорошо там 12 там 4 8 гигабайт смотрим поведение конкретные системы понятно что здесь оборудование должно быть как напротив то есть вас должны быть те же диски столько же всего там столько же памяти и так далее память тоже важно настройки поиска 100 такие же и таким образом мы обмеряем нашу систему и знаем как будет вести себя в плохом при плохом вот этом делите массовым как бы свести суде как она будет вот чек по энтица да то есть контрольной точки кран оступаться check point по-русски it can контрольной точки и у нас вот примерчик при дефолтный ну это некоторая база да и при дефолт на при дефолтные настройки один гигабайт для mac стол says очень хорошо видно что у нас диски на запись идут в полку вот такая картинка это типичный симптом больного очень больного пациента то есть ему реально было тяжело плохо и все такое то есть такой пускать прот вот такую операцию да тут вы была одна из на проц а тут был один делита как раз нескольких миллионов строчек вот есть такое пустить под как раз мы ляжем потому что у видно что даже один делить вы убивает нас в полку вот дальше мы увеличиваем от 16 гигабайт и уже видно да зубчики пошли зубчики это уже лучше то есть мы стучимся потолок но уже не так плохо то есть мы начали какая-то там свобода появилась чуть чуть вот справа это запись до в группах и количество операций второй график и как раз видно что мы уже немножко для себя полегче задышали до 16 гигабайт его 64 видно что совсем лучше стало да то есть уже такие зубчики ярко выраженные появляются больше возможности выжить других другим операций мы все-таки что-то сделать с диском еще раз вот было дефолт получше и совсем хорошо 64 и возникает вопрос а давайте вообще терабайт подставим да и или вообще там его сделаем 1 сутки будет чекпоинты и не париться чем это плохо да почему так вот это на самом деле я буду немножко окунаться в подробности но это была эта тема она как проводить чекпоинт тюнинг это целый доклад может быть поэтому я не буду сильно грузить но немножко обозначу какие там сложности есть значит если check point часто случается и мы идем удаляем ли там обновляем наши строчки непоследовательно там сначала только первую страничку потом вторую страничку мы их их находим по индексу что хорошо потому что мы же не всю таблицу удаляем мы можем может учиться так что сначала мы первую страничку потрогали под том какую там тысяч ну и потом вернулись опять первую и у нас если между этими заходами в первую страничку чекпоинт уже ее на диск сохранил значит он ее будет еще раз сохранять потому что мы во второй раз папочка ли до называется папочка тети бафов и соответственно мы будем заставлять чекпоинты и много раз сохранять понятно да то есть она как бы избыточные операции для него возникают но это еще не все в подписи страничке 8 килобайт а у linux 4 килобайта соответственно есть настройка full приезжает был поджигается write alright она у нас по умолчанию включена это правильно потому что если мы и выключим есть опасность что при сбое только половинка страничке сохранится и но это требует поведение запись вот это хоть logo приезжающего журнала такую что когда у нас check point случился и мы страничку первый раз меняем в в журнал при женщина попадает вся страница целиком вся 8 килобайт хотя мы меняли там какую-то строчку который совсем маленькая 100 байт и вот оно ну вы нужны сначала всю страницу целиком и и записать все последующие изменения будут уже только конкретный кортеж но первый раз всю и соответственно если какое-то еще раз случился мы опять к мы должны с нуля начинать опять же страничку запихивать понятно то что количество данных в журнал в такой ситуации в час частой чекпоинты и мы гуляем по тем страничка мы возвращаемся к ним при убежать равно он будет будет у нас очевидным образом больше чем могло бы быть то есть мы больше вала генерим это все отправляется на реплики больше и это все в архив отправляется больше ну и опять же это запись на диск вот соответственно 2 избыточности у нас возникают да и если мы увеличиваем maxval слайс у нас получается что мы как бы облегчаем работу и чекпоинта и вал райтера который пишет вал райта hotlog и это классно ну давайте трогает поставим и будем с этим жить чего плохого плохого то что если в случае сбоя мы будем подниматься может быть даже часы потому что нам нужно будет ряду сделать чек пойнт был давно уже очень много изменилось на все это надо ряду сделать и поэтому мы делаем вторую серию экспериментов мы смотрим мы вот тоже делаем операцию и смотрим когда чекпоинты уже близок к тому чтобы завершится и мы делаем кило -9 полюсу специально и после этого его стартуем заново и смотрим как долго будет подниматься на этом оборудовании сколько он будет делать ряду в этом в этой плохой ситуации отмечу что ситуация плохая дважды во первых мы упали прямо перед завершением чекпоинта соответственно нам проигрывать очень много надо во вторых у нас была массивная операция и если бы чекпоинт и были по таймауту sky все меньшего лобо сгнили лась с момента последнего чекпоинта то есть это дважды неудачник и мы смотрим сколько времени да и и опять же замеряем так такую ситуацию для разного размера ну maxval сайт и понимаем что если макса 64 гигабайта в 2 и в двойной худшей ситуации мы будем подниматься например там 10 минут и думаем нас устраивает или нет это бизнес вопросу то есть мы должны говорить разговаривать ну показать картину тем кто отвечает за бизнес-решение спросить у нас какой вот соло дата то есть сервер словил объекте в какой у нас сколько мы можем пролежать максимум и в случае этом проблемы совсем ничего что мы три минуты парижем или там пять минут в худшей ситуации и соответственно принимается решение но тут интересный интересный момент вот у нас в конференции есть пара докладов про патроне да и возможно вы его используете это of the flower of the fall over для мозга со vitlab рассказывал и и достигают рассказывали да и если у вас есть автопилотов который наступит через 30 секунд может быть черт с ним мы 10 минут можем пролежать мы уже вот к этому времени переключился на реплику и все хорошо принципе это вопрос спорный и я не знаю хороший такого от четкого ответа я только ощущаю что в принципе не только вокруг flower а это система этапов вокруг восстановление после сбоя если у нас долгое восстановление после сбоя нам будет неудобно многих других ситуациях например в тех эксперементах когда мы там делаем и вы же не надо ждать по 10 минут и намнут разработку устанавливает то есть я бы все-таки не ходил слишком далеко даже если у нас есть of the flower как правило вот такие значения х 64 там может быть 100 гигабайт это хорошее значение иногда бывает меньше стоит выбрать в общем это такая тонкая наука получается вот немножко про то вот вы в оба чтобы вот итерации делать вот макс плз с 1 там 8 там и так далее вы разные хотите пора проверить вам нужно повторять маслу операцию но много раз вот вы ее сделали его на той же базе хотите еще раз это сделать ну вы же все удалили все делать вот я попозже расскажу про наше решение что мы делаем для того чтобы оперировать в таких ситуациях и это как бы самый правильный подход я считаю но в данном случае нам повезло если мы делить будем вот как здесь написано бегин делить фрау бек то мы можем его повторять то есть если мы его отменили сами мы можем повторять и физически вот здесь показана почему физически данные у вас будут там же лежать вот даже благо то никакого не образуется вы можете тренировать на таких дели так экспериментировать такой делить высрал беком он идеальные для чекпоинт тюнинга оказывается даже если у вас нет нормально развернуто до to buy слеп и вот видно да это это это мы сделали табличку с одной колонкой ой упал высокий служебные колонки они невидимы и если их специально не попросите тианде x-men xmax и видно вот сити одета физический адрес 0 страница 1 все то есть 1 1 кортеж веб-страница видно что после его troll беком и еще мы dahlback и после рбк вот дизель и там да мы страницу кортеж остался на том же месте то есть мы можем еще раз попробовать его ну все она будет себя вести так же это главное и есть xmax это время смерти кортежа он проставился но после знают что эта транзакция было откачано поэтому что 0 что мертвые одну от качества я транзакция не важно то есть это все говорит нам о том что делит можно по нему утрировать и проверять массовые операции поведение системы идеальной для database либо для бедных вот так можно сделать четвертая ошибка и это уже про программистов ну про детей тоже они как бы за это всегда программистов ругают зачем вы делаете такие долгие тяжёлые операции может быть кстати кто из присутствующих именно это ожидали от меня услышать им исчез об этом будем говорить совершенно другая перпендикулярная тема сейчас было там администрирование сейчас будет разработка очевидно мы не разбили на часть это понятно ну нельзя такой делить кучи миллионов строк не разбивать на части он будет делаться 20 минут и все будет лежать всем понятно постфактум ну к сожалению ошибки совершает даже опытные разработчики даже очень крупных компаниях почему важно разбивать это очень простое 2 ответа мы сможем контролировать скорость т.е. если мы видим что диску тяжело давайте замедлим и если у нас разбито мы можем паузы добавить до можем быть says уменьшить можем замедлится это называется троттлинг по-английски и мы других не будем блокировать надолго то есть мы не будем на 20 минут в некоторых случаях это неважно и в если вы удаляете реально мусор наказ котором никто не работает скорее всего никого не заблокируете но если вы ну кроме там работы of the vacuum потому что будет ждать пока транзакции завершится но если вы удаляете то что вдруг кто-то может еще запросить вот они будут блокировать возможно там пойдет уже какая цепная реакция целом надо сбегать в lte пиф в сайтах и и мобильные приложения нужно избегать долгих транзакций вот такие два простых ответа значит как именно разбивать вот это интересно я часто встречаю что разработчики doom спрашивают а вот какую размер пачки выбрать ну наверное мне кажется я протестировал 10000 нормально здесь тысяч строчек ну там ли вот 50000 этого мы там сто тыщ понятно что чем больше размер пачки тем меньше транзакцию вверх и то есть дополнительные накладные расходы от транзакций но при этом время увеличивается в этой транзакции у меня есть очень простое правило сделал возьмите как можно больше но не превышаете выполнив выполнения в секунду почему секунду объяснение очень простое понятная всем даже не техническим людям мы ну глаз мы видим сколько там 50 миллисекунд не помню то есть реакцию мы видим а если что-то изменилось мы можем глаз наш среагирует и мы поймем что что-то изменилось там меньше уже сложнее если что-то отвечает через 100 миллисекунд вот в этом наружка нажали она через сто миль секут ответила вы уже чувствуете вот эту небольшую задержечку секунду уже воспринимается как тормоза соответственно если мы нашли вот массовые операции разобьем на 10-секундные пачки у нас есть риск что мы кого-то там забыл о чем и он будет работать несколько секунд это люди уже заметить поэтому я предпочитаю больше секунды не делать но в тоже время и совсем мелко не разбивать потом a transaction оверхед он будет заметен базе будет тяжелее немножко и там разные другие то могут возникнуть проблемы значит мы поэтому подбираем размер пачки в каждом случае можем по-разному можно автоматизировать и убеждаемся в эффективности работы обработки одной пачки то есть мы его делаем telit одной пачки или там апдейт да кстати все что рассказывают не только при зиле так вы уже догадались это любые операции массе массовые операции над данными и мы смотрим в план отличный видно там индекс скан еще лучше индекс английском и у нас небольшое количество данных задействовано все меньше секунд отрабатывать супер и мы должны убедиться что деградации нет на самом деле то есть вас бывает 1 пачке быстро отрабатывает а потом все хуже и хуже и хуже и хуже то есть процесс на самом деле такой надо много тестировать для этого как раз нужно добытого из лап и мы еще должны подготовить что то чтобы нам позволило production уже за этим как правильно следить например мы можем в логе писать время мы можем писать где мы сейчас кого мы сейчас удалили это нам позволит потом понимать что происходит и в случае что пошло не так быстро найти эту проблему вот случае если нам нужно проверить эффективность запросов и нам нужно изолировать много раз как раз есть такая штука у нас как раз 11 тут товарищ под он уже готов он используется десятками разработчиков и ежедневно и он умеет вам огромную это много trabant ную базу дать по запросу за 30 секунд вашу собственную копию и вы можете там что-то удалить и сказать reset еще раз удалить и можете с ним экспериментировать вот таким образом об этом будет доклад я попозже скажу когда и мы будем еще и практическое занятие проводить завтра в конце я скажу когда 8 итак 1 штука которая вот я я вижу что здесь это будущее и мы уже это это уже делаем вот какие стратегии разбиения я вижу три разных стратегии смене которые используют разработчики вот на пачке до 1 очень простая но у нас есть сидишь ник числовой например давайте мы разобьем на равные интервалы и будем работать с этим минус понятен в первом отрезке нас реального мусор может попасть запустим 100 строчку втором там пять строчек потом по общине попасть а потом все 1000 строчек окажутся наши мусором то есть очень неравномерная работа зато разбивать легко взяли максимальная идеи разбили это такой наивный подход сбалансированный подход потом гид лобби используется поиграл на грешен сможете почитать у ниже все открыто взял я просканирую таблицу и обнаружили границы пачек а идей наши да так чтобы каждая пачка было ровно там полностью по 10 тысяч записей и засунули куда ты такую-то очередь и дальше обрабатываем можно в несколько потоков 1 кстати тоже можно иска потоков это несложно но есть более такой я считаю классные оптимальные подходы когда это возможно лучше его выбирать мы на основе специального яндекса вот в данном случае цска и все будет яндекс по нашему условию мусора да и айди мы включим эти чтобы это был индекс он резко чтобы когда мы select айди чтобы но филипп не ходили желательно это если кто не знает яндекс диска подсчитайте в документации подвеса это быстрее чем индекс как правило вот и мы очень быстро находим нашу наши айтишники которые мы с которыми хотим удалить и еще мы их выбираем ну так и чесались понятно мы подбираем заранее да и мы их не только получаем мы получаем специальным образом их тут же лучшим но так лучшим что если они уже заочно мы их не лучше мы едем едем дальше берем следующее это вот for оптический блок это на позволяет несколько потоков работу очень важно да это супер фичи подвеса позволяет работать в кучу потоков потому что диски принципе обычно кучу потоков могут нормально но если мы хотим можно в один поток и вот такой сети да это один из самых запрос и у нас во втором по второму это же этого city in происходит реальное удаление stryder ник звездочка можно ли черненькой динуша звездочка принципе если у вас данных там немного в каждой строчке это нам зачем нужна для того чтобы отчитаться мы сейчас удалили столько строчки по факту и у нас так границы там по айди или покоряет это это или почему то еще вот такие там aminomax можно сделать еще какие-нибудь можно сделать тут нужен общего запихать это все красота что я упоминал для мониторинга очень удобно вот понятно да такое все вот здесь насчет индекса ещё одно замечание если мы решили что нам именно для этой задачи нужен специальный индекс то нужно убедиться что он не испортит hot hot отдайте keep on youtube отдайте то есть в поясе есть такая статистика это можно посмотреть перестать юзер tables для вашей таблице вы можете посмотреть используется легко the blades или нет если они уже используются бывают ситуации когда ваш новый индекс может их просто обрубить и у вас все другие апдейты ну все апдейты которые работают они замедлятся вот то есть не просто потому что индекс появился каждый индекс замедляет апдейта до на чуть-чуть а тут он еще испортит и вот эту специальную оптимизацию просто для этой таблицы сделать невозможным так и такое иногда бывает я вот статью написал там в общем слайды скачаете ссылку нажмете если интересно то есть это такая тонкость которую мало кто помнит и очень легко на эти грабли тоже наступить иногда бывает нужно какой-то подход с другой стороны найти и все-таки обойтись без этого нового индекса либо сделать другой индекс либо ты еще как нибудь ну или в использовать метод 2 например можно ну вот это вот самая такая продвинутая ситуация как разбивать на патчей и в общем одним запросом стрелять по пачкам удалять по чуть-чуть и так далее вот ну и ошибка номер пять она такая большая вот николаеве сантиметр как раз рассказывал про мониторе казгаса идеального мониторинга полюса не существует к сожалению кто-то ближе кто-то дальше аки метр достаточно близко к тому что вы будете хорошим идеальном но есть много чего не хватает и нужно добавлять это к этому нужно быть готовым ну например дать упал своих лучше мониторить если у вас много мертвечины в таблице отчет не так нужно лучше реагировать сейчас а то там может быть деградацией можем лечь бывает такое если большое его понятно что не хорошо на надо лед такой иметь долгий транзакции тоже одном типе долгий транзакции не стоит допускать и вот здесь ссылка на сниппет которая позволяет так сказать взять этот сниппеты уже сделать некоторую некоторые некоторые слежения за долги метро за акциями почему долги транзакции плохо потому что все локи от пусть столько конце и мыло чем всех плюс мы блокируем работу of the vacuum для всех таблиц это нехорошо в общем даже если на реплики если если у вас сходство этих дак включен это общем то плохо то есть это мы очень нигде лучше не запускать долгих транзакций значит если у вас много таблиц него куница тоже нужно ли ртами возможна такая ситуация как раз косвенно можем влиять на работу of the vacuum еще один сниппет я взял сниппет от авито и выложу немножко покрутил улучшал и общем получился интересный инструмент чтобы смотреть что у нас в час авто вакуум ждут ли какие-то таблицы свою очередь никак не дождутся например тоже засунуть мониторинг и alert иметь и блоки низших лес деревья блокировок я вот я люблю какого-нибудь взять и чего-нибудь улучшить здесь одна это игритт взял взяла очень классные рекурсивные сети который показывает лес вот этих деревьев блокировок хорошая штука для диагностики и на основе него тоже можно соорудить мониторинг но аккуратно делать нужно самому себе стоит над amount маленькие сделать и лак тамия желательно значит резюме какие ошибки мы здесь увидели детей не проверил проверяли не там check point тюнинг не сделали не разбили на части мониторингового слабый иногда это встречается в сумме на мой взгляд самая главная ошибка здесь это организационная хотя она организационно потому что техника не тянется это номер два проверяли не там то есть мы проверяли там потому что у нас не было клона продакшна на который легко править особенно разработчику не вообще доступа может produce что нет и мы проверяли не там соответственно мы не могли мы бы увидели все это нубаса разработчик в пизде и без детей бы это увидел если бы он проверял это на в хорошем окружении где данных столько же желательно вообще идентичное расположение и обувь деградацию это увиделось сам бы такое никому бы ему бы стыдно было просто ну еще вот там право of the vacuum про то что после того как мы лишь 40 мы сделали массивную зачистку нескольких миллионов строчек еще нужно репак сделать особенно для индексов отважно им будет плохо по 100 км и там кучу всего почистили и если если вы хотите опять же вернуть вот эту ежедневную работу по зачистке я должна всё делать это часто но мельче то можно там 1 минуту или даже еще чаще по чуть-чуть и наладить и мониторинг двух вещей что ошибок нет у этой штучки и что она не отстаёт обрабатывает там вчерашний день и там месяц назад и не они 2 месяца назад довольно вот этот трюк которая показывала как раз позволит это решить так и вот немножко там на правах рекламы то что мы делаем инструменты у нас вот базовые вещи у нас open source ноге плоды выложены и вот как раз мы делаем так чтобы люди могли проверять и даже без babay то есть мы делаем дтп слаб мы так называем компоненту такую базу базовую на который сейчас уже работает же она включена в него да и вы можете взять просто копию продакшена и ну сейчас есть ре зация джорда slug а вы можете там сказать explain такой-то запрос и тут же получить результат для вашей копии базы и вы можете даже там делить сделать никто этого не заметит то есть на одной копии базы то есть мы берем вот властям 4 терабайта или там 10 терабайт мы делаем дтп слеп тоже 10 байт и можно одновременно 1010 виртуальных действительно байтов бас с ним можно одновременно работать 10 разработчикам каждый может делать что хочет удалять дропать и так далее перезарядить обратно за несколько секунд вот такая фантастика об этом мы завтра будем говорить то есть это называется фильм про режиме то есть такой тонкий проверен и признан как по-русски в общем это такая некоторой фантастика которая сильно убирает вот эти задержки в разработке в тестирования и делает мир лучше в этом плане то есть как раз позволяет вам избегать вот этих проблем с массовым операциями и вот пример там пять терабайт менее 30 секунд до самом деле от размера даже не зависеть и не важно сколько торбой там анонсы завтра в два часа вот в зале москва на втором этаже в сезоне как раз анатолий расскажет наша команда расскажет про вот этого бота джо да это приходите и мы в 3:00 сделаем дыма и такой метод проведем его мы перенесли в зал побольше потому что явно интерес выше чем вот эти маленькие комнаты в зале рио будет зеленой зоне это рядом с маленькими комнатами несложно найти обязательно приходите на практическое занятие тоже мы там сможем всякие вот эти вот тонкости показать потрогать там и так далее ну и сегодня вы уже можете зайти на позиция и и покопаться в наших инструментов зарегистрироваться посмотри там есть по поставить себе этого бота он он бесплатно его концертной пишите в общем спасибо тебе спасибо вопросы друзья предложения коли варны и споры приглашение на работу что там вот под здесь двое есть и ты сказал приглашаю на работу оговорился извини пожалуйста нам нужны гаишники гош ники гаишники вам нужны не просто гаишники вам нужно их ага грешники да пожалуйста включить меня слышно прямо в микрофон и громко меня слышно очень часто в реальных ситуациях получается так что данные которые должны остаться в таблице гораздо меньше чем нужно удалить то есть такой ситуации часто проще осуществить такой подход что просто создать новый объект скопировать туда только нужные данные и за tranquility старую таблицу ну понятно что здесь нужно как бы некий программный подход на этот момент пока вас будет происходить переключение как такой подход это очень хороший вопрос очень хорош задача спасибо оно очень похоже на то что делает пиджи репак она очень похожа на то что вам приходится делать когда вы идиш ники сделали 4 байт нами многие фромборке это делали когда-то там несколько назад и краз таблички подросли и их нужно конверсий на 8 байт и в общем-то это такая задача она довольно трудная под нагрузкой и большие базы это прямо-таки мы это делали и и общему вам нужно быть очень аккуратными там локи и так далее но это сделается то есть стандартный подход похожий на пире репак вы объявляете такую же табличку и прежде чем там сне начать в нее начать заливать данные с на потом вы еще объявлять еще одну табличку которую все изменений отслеживаются на самом этом хитрость есть такая бы некоторые измене можете даже не отслеживать можем об этом к раз поговорить там тонкости и потом бы приключается сен накопив изменения там есть очень маленькое время паузы будет к мы всех залочим но в целом это делается у меня была еще идея если вы пережили пакт на гитхабе посмотрите там есть вот каждой задачи конвертнуть 1 nix сын 4 на and 8 как раз была идея смог сам пережили пока использовать это тоже возможно но это немножко такой хакими то так короче но он для вот этого тоже подойдет то есть вы можете вмешаться в триггер который использует пиджи репак и там сказать она вот эти данные не нужны и то есть мы переливаем только тоже нам нужно и потом он просто приключиться и все то есть туда при таком подходе мы на самом деле еще получаем вторую копию таблица в которой уже даны индексированный уложен очень ровно блатует это хороший подход да но я знаю там есть попытки разработать автоматизацию для этого универсальное решение я могу вас цвести там с этой автоматизацией на 5 написано хорошая тоже интересная штука вот собственно да да это так интересно что из мира mais que al как бы пришел послушать ну вот мы пользуемся таким подход окей спасибо следующий вопрос но он только когда когда нас допустим 90 процент 8 нас там пять процентов ну капни лучник применять спасибо за доклад у меня я не измеряю sql у меня вопрос попроще а что если нет ресурсов сделать полную копию prada данных если какая-то там алгоритму ли формула именно просчитать нагрузку или размер ну можно попробовать как-то хороший вопрос я чист вело транспорт немножко покажет of но у нас получается там на катара патины и базы в сутки найти где-то там пусть железный совсем такое же будет поменьше памяти polnyj процессоров и диске может не совсем такие же но все-таки мы делаем это если совсем не где надо подумать давайте вот каскада завтра подумаю приходите мы пообщаемся на тему хорошо раз вопрос вот пожалуйста потом питер спасибо вопрос такой мы вначале начали про то что есть крутой подгрести вот у него такие ограничения но он развивается и вот это все это такой к стеллинг по большому счету и ну не будет лет не идет ли все это в противоречие с развитием самого под gresso в котором там какой-нибудь делить дифферин deferred появится или что-нибудь еще что должно поддерживать на низком уровне то что мы пытаемся здесь обмазать вот какими-то своими средствами странными ну я вот немножко не очень понимаю то есть если мы хотим удалить если мы спускались сказали удалить или тома подарить правда итить много записей по одной транзакции как там под газ может распределить он сына будет это делать но физически ограниченное 1 операция да ну что будем делать долго и мы будем учить в это время и так далее с индексами же сделали нет вообще вот есть допустим я могу предположить что допустим тоже чекпоинт у них можно автоматизировать было бы до когда-нибудь это возможно будет ну место просто не очень понимаю дает хороший вопрос просто нет ли такого вектора развития который идет вот там вот здесь параллельно идет ваш там пока про это не думаю я рассказал про какие-то принципы до который можно используя сейчас мы также на самом деле у нас есть разработка вот вот есть другой бог немцы называется год назад рассказывал с помощью этого можно сделать автоматизируем tunic будет ли это когда-то пол и сину открыто не знаю то есть это пока даже не обсуждается мне кажется пока что мы пока далек далековато от этого но есть ученые которые делают новые системы и они нас на с вами пихают вот это индексы автоматически там параметр автоматически подобрать есть разработки вот например отортен можете посмотреть он подбирает параметры автоматически но она до сих пор пока не сделает то есть он там подберет для при von uns то там шерпа пирс и так далее а вот для чип-тюнинга вот можно применить можно сейчас уже автоматизировано сделать такую штуку что она будет если у вас допустим 100 тысяч разных кластеров вы можете и не разные железки до разные виртуальной машины в claude вы можете вот с помощью нэнси нашего бота можете автоматизацию сделать и будет подбираться максвелл сайт по вашим стилевым установкам автоматически но пока этого в ядре вообще даже близко нет к сожалению так и хорошие вопросы а может ли под колеса отправить такой запрос который сам не сможет обработать петербург друзья я приглашаю вас в пите да с вами снова питер и у нас есть опять вопрос от наших участника прошу прошу прошу добрый день не вопрос такой вы говорили о вреде на долгих транзакция пожалуйста более подробно то есть первой степени вы верили в нашем сценарии о том что блокируется автово кунда в случае удаления чем еще нам-то вредит ну потому что of the vacuum и больше мы говорим о высвобождении место для как бы и возможность да ну хороший вопрос и еще мы теряем я бы сказал это wacom даже может быть не самая большая проблема здесь а вот то что долго транзакция может залучить другие транзакции вот это можно вот она более опасна она может может стоит а может не стоит сильно встретилась болин вам очень плохо может быть то есть вообще of the vacuum тоже проблему то есть везде и проблемы в долгий транзакция в лтп локи и auto lo que и если у вас сходством баффет как включен на реплики то вам еще блокировка of the vacuum прилетит на месте на прилетит оттуда с реплики вот ну пока и на это блоков не будет а вот здесь могут быть локи если у вас ну мы же к ним об изменениях данных поэтому локи тут очень важный момент и если у вас это все долго-долго-долго ну все больше больше транзакций лучится они могут площадь другие и появляются вот эти деревья локов этом сниппет приводил ссылку и это общем проблема на еще более да она она быстрее становится заметной чем проблема с of the vacuum который может накапливаться только спасет секундочку давайте раз а потом кого дождитесь микрофону пожалуйста вам ответить следующий освободишься микрофон да питер спасибо поехали москва сего зато класс скажу вам спасибо скажете вот вы начали свой доклад что там неправильно тестировали нигде не правильно тестировали продолжили свою идею что нужно взять оборудование одинаковая базу взять точно также хорошо допустим мы даже дали разработчику и базу и он выполнил запрос и у него все вроде хорошо окей но он же не проверяет на лайве а на лайве например у нас нагрузка на 60 70 процентов и даже если мы используем вот этот тюнинг получается ну я иметь в команде экспертов и пользоваться эксперта миде бегут которые могут погнул сделать что будет про про реальные фоновой нагрузки это важно тоже есть еще подход когда мы просто чистым чистый-чистый наше изменение прогнали мы видим картину но более продвинут про подход на самом деле ловила fda когда мы еще раз то же самое сделали но еще симулированные или реплей продакшена нагрузки это как бы совсем классно к этому надо считать это надо расти которых бог да это прям вообще по-взрослому то есть мы и чисто посмотреть же есть и еще посмотрим смотрели что будет хватает ли нам ресурсов если при этом реально там обычно этом крейсерская нагрузка такая идет и мы тут со своим деле там были там апдейтом пришли это это хороший вопрос правильно абсолютно разумно хорошо еще тогда когда мы уже делаем горбач select ну у нас есть там deleted к примеру флаг и мы хотим все что делает это было ударил что of the vacuum делать классический пастбищ а он как бы есть garbage collector of the vacuum и то есть два garbage collector а ну все тогда спасибо передайте пожалуйста коллеги вот за спиной а вот вот микрофон отличный супер типа хотел прямо в микрофон то есть ли вариант сразу проектировать базу данных спарте церовани им таким чтобы весь мусор он как бы отпочковывается от основной таблицы куда-нибудь в сторону и конечно ведь ведет можно ли тогда обезопасить себя если мы заложили партицию которая по идее не должна использоваться но ничего страшного там как то конечно здесь но это вопросы пока курица и лицо если мы все знаем что будет в будущем ну конечно мы сделаем классно но бизнес меняется и там появляются кит новой колонки новые запросы и потом опа мы хотим это удалить то есть из это идеальная ситуация в жизни она встречается встречается но не всегда но в целом это хорошее идея конечно просто tranque и ты все да да да но может быть мы потом еще по другому признаку хоть и мал это уже позиционирование потом по этому признаку вы приехали ну это вполне себе разумно да еще на один вопрос есть время вот здесь кто-то махнул это типа уходите или вопрос был хорошо тогда вопрос к себе кому подарим вот и чашку малыш так футболки мини-чат вот был вопрос про то что что делать если железок нету я до завтра это буду думать хорошо но ему сейчас их дадут железную чашку не зашла шутка да хорошо для тебя тоже есть есть память памятные призы можешь поклониться супер пасибо большое мы"
}