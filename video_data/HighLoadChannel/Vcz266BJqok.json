{
  "video_id": "Vcz266BJqok",
  "channel": "HighLoadChannel",
  "title": "AB-тестирование: на что следует обратить внимание / Артур Маликов (Яндекс)",
  "views": 704,
  "duration": 2561,
  "published": "2017-04-22T14:47:46-07:00",
  "text": "зимой о том что такое бы тестирование оба в экспериментах и на что следует обратить внимание при проведении об и тестирования то есть мы я попробую вам рассказать как избежать типичных ошибок которые могут у вас возникнуть при проведении б тестов многие компании думают о том как оценить влияние своих внедрений некоторые из них делают это анализируя показатели в динамике давайте посмотрим на конкретный пример здесь изображен изображена диаграмма продаж устройства amazon kindle синеньким цветом у нас те моменты те даты когда сайт имел один дизайн и вот начиная с 27 октября на сайте поменяли дизайн ну казалось бы да вот поменяли дизайн и продажи у нас резко выросли некоторые там товарищи могли даже надеяться на то что у них тут премию будет очень замечательная вот но к сожалению не все так просто дело в том что 28 октября известная известная популярная американская телеведущая опра уинфри в своем шоу сказала что amazon kindle это ее новый любимый гаджет который полностью изменил все ее представление о мире то есть что мы здесь с вами наблюдая то что на ваши изменения оказывает влияние как бы точнее на вашу продукцию оказывают изменение не только те изменения которые вы сами в носите но и внешние факторы ведь мир как известно очень изменчив меняется погода происходят какие-то события в конце концов конкуренты выпускают какие-то новые продукты которые могут на вас повлиять кстати говоря вот у нас в яндексе один инженер так баловался дело он следующие есть такая метрика доля не кликнут ах такая достаточно известный метрика это доля запросов в которых не было ни одного клика по по запросу вот и строил такой график температуру это было весной март-апрель значение температуры и значения доли не кликнут их ну и получился такой забавный график что с увеличением температуры пользователи начинают больше кликать есть если бы мы смотрели на этот график можно было бы сделать такой вывод вот поэтому эти все примеры показывают нам о том что показывает нам необходимость об и тестированию вот точнее необходимость того что мы должны принимать все решения исходя из фактов исходя из статистики как показывает практика решения эксперт а вот я считаю что мой продукт лучше не всегда плохо предсказывает результаты поэтому что мы могли уже понять и из этих примеров во-первых контрольная группа экспериментальная группа они идут одновременно при этом особенность в последующие очевидно что пользователь не знает что находится в эксперименте и вообще говоря у нас нет непосредственного контакта с пользователем вот пример у нас есть две поисковые стрелки и надо сравнить какая из них лучше но сразу оговорюсь если есть внимательный читатель такого эксперимента конечно же не было потому что это версии стрелки разных годов но просто пример наглядно демонстрируют то что можно проводить вот пример такого такого эксперимента так выглядит классическая схема об эта не у нас есть множество пользователей мы делим их на две группы в простейшем случае это 50 на 50 одной группе мы показываем изменения точнее не показываем таких изменений это продакшен контроль bass line а эксперимент и соответственно другой группе он показывает а изменение влияние которого хотим оценить получаем логе обрабатываемых считаем показатели получаем результат принимаем решение вот я выделяю вообще в схеме проведения экспериментов два крупных этапа которые надо обязательно проделать первое это разбиение на группы вот сюда входит еще следующая во первых на предыдущем слайде был простейший пример когда мы проводим эксперимент по 50 на 50 вообще говоря если вы проводите эксперименты часто вы будете понимать что экспериментов у вас единовременно достаточно много даже далее на слайде я покажу сколько одновременно экспериментов идут в яндексе но тем ни менее вам нужно иметь конфигурацию экспериментов и соответственно выкладывать ее и обязательно логировать факт попадания в эксперимент ну то есть что данный запрос данный клип попал эксперимент казалось бы да вот стоит парень вам рассказывают очевидные вещи но практика показывает вот все равно люди натыкаются на такие грабли ну и соответственно вторая часть то есть в первой части что мы имели на входе мы имели пользователи имели умеем показывать экспериментальные изменения и лаггер у им эксперименты во второй части мы на вход получаем логе в которых события размечены этот это событие в такой-то эксперимент попало и так далее а на выходе получаем показатели на основе которых мы сможем принять решение что данное изменение лучше или хуже продакшена давайте чуть подробнее поговорим про каждый из этап во-первых разбиение который вы делаете должно быть случайно вот здесь и далее мы будем говорить что мы эксперименты проводим по пользователя по пользователям я имею ввиду идентификатор пользователя куклу которую вы выставляете на своем сайте вообще говоря имеет смысл в некоторых случаях проводить эксперименты по запросам например если у вас заведомо плохое эксперемент если вам нужно собрать какую-то статистику это имеет смысл но далее мы говорим только про разбиения пользователя при этом смотрите у нас есть все пространство наших пользователей и мы хотим побить их на какие-то группки вот в минимальной единицы деления будем называть ее слот вопрос сколько нам нужно вот этих отделений сделать ну какие могут быть варианты там 10100 1000 и так далее ну как его фантазия вот разыграется но такие варианты если мы делаем мало например 10 какой минус то что одновременно если у нас простая схема тестирования продакшн и только 10 экспериментов вот если мы делаем многое например 10 тысяч то мы приходим к тому что выборка вот минимальное которую получаем будет не репрезентативная если вы там проводите эксперименты 1 десятичная на одну десятитысячную результаты могут отличаться вовсе движение потому что вас изменения есть просто потому что выборки не равноценно вас пользователя разные вот ещё очень важный момент это перемешивание пользователя о чем я говорю смотрите еще раз напоминаю есть пространство пользователем и его как-то разбили и говорим вот этот сотик показан этот эксперимент эта контрольная группа аха здорово провели эксперимент приняли решение а потом на этаже сотик на котором был предыдущий эксперимент ставим другой и вот могут быть очень занимательный эффект и когда предыдущий эксперимент влияет на текущие вот об этом подробнее расскажет следующий докладчик роман сергеевич вот я здесь подчеркнул что вообще говоря лучше предусмотреть такую схему когда по окончании эксперимента пользу у вас есть возможность перемешать всех пользователей вот так же в некоторых случаях имеет смысл перемешивать каждые n часов теперь поговорим про второй этап мы эти эксперименты проводим не просто так что нам захотелось посчитать какие-то чисел ки вообще говоря мы проводим эксперимент чтобы принять решение понять что экспериментируя экспериментальная функциональность лучше вот поэтому у нас есть такие метрики есть приемочные по которым мы принимаем решение есть информационные метрики например мы считаем сетях какого-нибудь блока но очевидно что если это не значимый блок и эксперимент заключается не в нем-то принимать решения об изменении о выходке ценности в продакшен по изменению блока маленького city or a смысла конечно нету обязательно у вас должны быть такие показатели мы в яндексе говорим метрики для контроля или метрики лампочки то есть если у вас есть значимые изменения такой метрики то это говорит о том что эксперимент некорректной нельзя верить результатам естественно так как мы же бизнес надо уметь считать деньги в эксперименте ну давайте чтобы не быть голословным проговорим в день примеры например метрики число запросов число кликов вот это пример метрики лампочки если у вас вы проводите эксперименты на равных объемах а у вас число пользователей число кликов значимую прямо отличается и даже на несколько процентов то это сигнал к тому что надо разобраться время до первого клика вполне себе тоже имеет место для таких экспериментов может быть даже и приемочные метрикой вот метрика про которую литературе много говорят доля запросов без кликов или более известна как веб и банда мент доли не кликнут их то есть что это такое это доля запросов по которым не было ни одного клика вот и все все метрики про которым мы до этого говорили это временные запрос ные кликовые метрики но чем плохи например кликовые метрики они очевидно накручиваются поэтому надо смотреть и на сессионные метрики тоже вот базовая метрика число сосина пользователя к примеру она на самом деле по практике недостаточно чувствительное смысле очень тяжело на этой метрики поймать изменения но если мы его ловим то это прямо вот огонь далее надо помнить что у каждой метрики есть своя граница применимости но например из того что мы говорили это доля не кликнут их доля запросов по которым не было ни одного клика если мы меняем на сайте ранжирования сортинг некоторые называют термин применяет такая метрика вполне имеет смысл мы можем по этой метрики принимать решение о том что новое ранжирование лучше или хуже старое но допустим мы экспериментируем с аннотациями вот уже в примерах очень много пример рассказов про поисковую выдачу ну извините тут вот такая профессиональная деформация представим поисковую выдачу у нас есть там сколько-то результатов есть титул и у каждого результата есть некоторая нотация вот аннотацию многие знает называется стене 5d вот эта аннотация допустим мы наш эксперимент заключается в том что мы меняем с не питер прямо в длину или вообще как бы подбор этих сми битов и если мы начинаем давать больше ответов в сниппете например запрос год рождения льва толстого мы прямо даем сразу ответ в результатах очевидно что такое метрики вдоль запросов без кликов стоит в этом эксперименте относиться иначе вот пойдемте дальше немножечко да я вижу что вы вовсе не скучаете поэтому этот слайд я не скрывая или про него тоже расскажу вот что с точки зрения математики у нас есть два эксперимента ну собственно об этой стерве не поэтому так и называется а контроль там бы эксперимент к примеру и мы в каждом в каждой выборки в каждом эксперемент контроль в эксперименте считаем какую-то случайную величину на самом деле метрика те кто то же самое число запрос это случайная величина вообще говоря о суть-то экспериментах как раз и заключается в том чтобы понять вот эта случайная величина она значима отличается в эксперименте от контроля или нет поэтому как бы случайная величина вот этого дельта на что характеризует некоторый шум плюс вот как раз вот этот самый эффект вот и для измерения как раз эффекта мы используем статистические тесты ведь давайте посмотрим если мы запустим два контроля то есть сравнивать продакшен против продакшена и посчитаем метрики вот точно метрики у вас будут отличаться в одном в одной выборки будет не на два миллиона триста запроса в другом 2 миллиона 200 с копейками вот вопрос просто в том эта разница значимо или нет вот посмотрим например это скриншот 1 из наших юзеров внутренних что здесь показана здесь есть некоторые метрика сетях блока какого-то какого именно история умалчивает и видно что эксперимента в течение двух недель вторая третья колонка это показатели метрики и соответственно дальше это дельта абсолютные и относительные что здесь мы видим вот показатели идут и идут идут и зачем-то подкрашена два результата у итогам эксперимента и за какой-то день у нас был выброс наш veyron подкрашивают результаты если есть как раз значимые изменения вообще у нас принято ну и собственно все мной рекомендуется разрабатывать свой инструмент очень удобно если метрика показывает зачем улучшение красивыми ну статистически значимое улучшение красивые зеленые если мы знаем если это ухудшение красим в красно здесь мы красим вот желтый свет потому что нет река у нас не приемочная но вообще говоря мы не знаем рост данного показателя это хорошо или плохо но давайте чтобы здесь закончить проговорим следующее мы при или метрики мы что-то вообще говоря измеряем принимаем решение но давайте не забывать о том что метрики надо бы лидировать то есть если у вас есть метрика вы считаете ее значение в контрольной группе экспериментальный если она день ото дня показывает разные результаты статистически значимые в один день мы говорим блин здорово надо принимать решение другой день нет это значимое ухудшения это значит что то идет не так либо проблема с вашей метрикой либо проблема с постановка эксперимента ну и вообще говоря у вас должен быть регламент приемки вы говорите до запуска экспериментах по каким правилам вы принимаете данное изменение вот но коллекционная скучная часть закончилась поговорим вот теперь о важных моментах которые могут у вас возникнуть вот что надо делать до запуска эксперименты первое это обязательно эксперимент надо тестировать казалось бы тоже очевидная вещь но если вы этого не делаете это в лучшем случае в эксперименте вы увидите продакшн и просто потеряете как бы несколько дней потому что будете думать что вы измеряете эффектов эксперимента в пользователи будут видеть продакшен важные моменты длительность эксперимента задается заранее нельзя выходить эксперимент в продакшен увидеть что например на третий день ваша метрика значимо прокрасил все здорово хотя в продакшн нет ребята так не работает деятельность эксперименты сдается заранее и всегда выдерживается но всегда это конечно вру если вас ей значимые ухудшении его надо включать как можно скорее вот и такая рекомендация обязательно до запуска вы пишете свои ожидания и критерий выходки это вам самим в дальнейшем поможет принимать решение процедура будет более прозрачно немножко поговорим про контрольную группу как и выбирать первый вопрос контрольно вот есть у нас контроль а есть эксперимент вообще говоря каждому ли эксперименту нужен свой контроль или можно использовать один и тот же если у вас есть серия экспериментов ну что такое серия например вы экспериментируете с цветом кнопки из вас есть разные оттенки конечно же для такой серии экспериментов должен быть один контроль мочевина вы экономите часто в этом месте если у вас вообще говоря вот здесь конфигурации экспериментов и вы постоянно круче разные эксперименты здесь вы экспериментируете с ранжированию здесь вот с интерфейсом то рекомендация каждому эксперименту делать свой контроль во первых это более гибкая схема потому что вы можете запускать эксперимент на разные объему во вторых вас эксперименты еще говоря идет поток такой да сначала какой-то эксперимент выкатился другой выключился и так далее то есть они его времени находятся бы не постоянно у нас знаете была такая идея у тебя здорово что такого эксперимента собираем конфиг вот полностью до говорим планируем вот все заранее например следующие две недели мы проводим н каких-то экспериментов вот и все никакие другие эксперименты зайдите две недели не выкатываются у казалось бы да вот провели серию всех разнородных экспериментов вот потом отключили и новую серию вот на практике так не работает всегда есть какая-то команда которая надо срочно выходить эксперимент срочно посмотреть на его результаты потому что это деньги или потому что это такая клевая идея вот у нас такой постоянный поток идет экспериментов еще моя такая рекомендация постоянно если вы делаете эксперименты чтобы контроль эксперимент были равных объемов те из вас кто этой темы интересуются наверное слышали одна из последних таких модных тем если у нас есть там контрольный эксперимент разных объемов то чувствительность метрик повышается значительно вот но как бы новомодные всякие вещи лучше делать базу проверено например какой вот яндекс выкатывает свои изменения ведь на несколько стран присутствия я напомню это россия казахстан украина беларусь турция был вот у нас один такой случай значит контрольный был нас постоянные на все стороны присутствия на 2 процента а эксперимент мы выходили на все страны кроме турции все метрики относительно относительной метрики кстати можно смотреть на их изменения если эксперимента разного объемов например тоже долю не кликнут их под всеми торги поехали блин как бы что такое поехали в плохую сторону из хорош вы хотели бы наверное вот стали разбираться вот а потом увидели вот да как бы но этот старый случай сейчас у нету вот уведи вот а если бы у нас были контроля x период равных объемов мы сразу увидели что у нас число пользователь за чем отличается потому что на объемов там миллионы до турция вы сами понимаете она вклад никому не вносит мы смотрели то тут я не знаю 4 миллиона запросов с копейками 8 миллионов с копейками примерно в два раза а значит мы не значима и бы если была равна непонятно поговорим теперь немножко про особенности интерфейсных экспериментов вообще говоря если вы выкатывать интерфейс на изменение то пользователь должен к нему привыкнуть вот свежих примеров когда instagram поменял иконку я если честно даже не первые дни просто не запускал это приложение хоть несколько раз на дню запускают вот это есть пользователи он должен привыкнуть к интерфейсу моя рекомендация следующее если у вас такое сложное изменение вы выкладываете его в продакшен ждёте некоторое время например неделю и только со следующей недели начинаете замерять показатель для принятия решения смысле вы их замерять можете сразу естественно чтобы не видеть тут например там по контрольным метрикам видишь что нет сильных ухудшения вообще решение о принятии лучше там принимать по истечении недели накликал еще такая рекомендация вот с интерфейсными экспериментами думаю ни для вас все-таки актуально все просто да у вас изменение работает на всем потоки если у вас что-то более сложное ну например ранжирование и вы изменяете ранжирование не на всех запросах например на просто на запросах какой-то определенной категории товаров вот что можно делать можно считать метрики по всему потоку да потому что вы когда разбиваете пользователю вас же вы не можете заставить пользователя сдавать за давая мне запрос это к категории он задает любые запросы а вы потом просто считаете показатели как бы одной группы против другой и можете выделить срез именно вот этих вот запросов которые вас интересуют и уже в на этом срезе вы можете увидеть значимые изменения собственно поэтому то вы это изменение делали вот ещё такая тема будьте очень аккуратны при внедрении интерфейсных изменений старайтесь чтобы в эксперименте был только было только интерфейс на изменение потому что вообще говоря при интерфейсных изменениях ломаются поведенческие привычки пользователи вот у нас такая тема была очень сложный эксперимент менять интерфейс логирование еще и привычки поменяли если вот вы пользуетесь яндексом вы знаете да что сейчас мне на следующем слайде а вот здорово меня эксперт пример поисковой выдаче вы смотрите в левой колонке можно переходить на сервис картинки видеокарты и так далее в контроле собственных продакшена сейчас если мы переходим на другой сервис вы получаете выдачу в новом to be a в эксперименте сделали чтобы выдачи открывалась прям там же вот такое изменение она на самом деле из-за него мы потеряли 04 процентов запросов вот и на самом деле не осознали потому что эксперимент вот такой сложный аналитику будет делали долго поэтому еще раз и того стараемся интерфейс на изменение выкатывать очень аккуратно смотрим на то как ломается поведение пользователя вот давайте посмотрим на поисковую выдачу как она выглядит смотрите у нас есть блок вот с ответом сразу да есть результаты ранжирования есть правый блок и так далее это говорит о том что вообще говоря мы можем делать эксперименты то есть пользователь может падать сразу вниз к экспериментов вот я уже назвал блоки со всеми ними можно экспериментировать то есть пользователь может видеть несколько экспериментов одновременно вообще зачем это нужно если у вас сервис такой что позволяет набирать статистику достаточно быстро и поток экспериментов не очень большой не надо ничего выдумывать одномерная схема принимаем решение запустили перемешали все здорово это работает как только у вас начинается большой поток экспериментов у вас начинается скапливаться очередь и эксперименты уже становится не инструментом того чтобы понять быстренько запустить в онлайне проверить фичу и принять решение вы например там запилили какое-нибудь новое решение и вынуждены там я не знаю месяц стоять в очереди чтобы эксперимент выехал в продакшен конечно не годится возникает необходимость в многомерной схеме вот давайте я попробую объяснить мой сложный рисунок вот вот это все это все наше пространство пользователи зеленый блок это у нас одномерная схема у нас прямо сейчас то никаких экспериментов нету вот и второй прямоугольничек на его поделили двумя способ вертикально и горизонтально вот и что мы сравниваем давайте для простоты первое измерение это у нас ранжирование то есть у нас контроль один это базовое ранжирование против экспериментального а горизонтально это у нас новый интерфейс и production интерфейс вот пользователь желтые рожица у нас попадает в эксперимент интерфейса и видят production ранжирование а пользователь синькой рожицы но не повезло ему видит в эксперименты одновременно вот и решение смотрите это вполне работает себе к себе кстати решение важно как считает да смотрите мы сравниваем полную группу 1 контроля против полной группа 2 то есть вот серенький квадратик против серенького полностью да они вот эти маленькие блоки ну и соответственно горизонтальные блоки также поговорим о том какие полезности нам могут быть не говорим полезность их просто вот а если вы запускаете эксперимент вообще говоря эксперимент чтобы улучшить до но если поток большой можно где-то не протестировать да ради скорости поэтому обязательно нужен мониторинг ваших экспериментов и чем быстрее вы получаете данные down чем быстрее вы умеете обсчитывать там через четыре часа после запуска уже было бы здорово иметь результаты лучше кэш через час через полчаса через 4 часа уже нормально если вы видите значимые изменения то вы должны предусмотреть инструмент если она не вяжется с нашим пониманием чтобы быстро отключить эксперимент и чтобы пользователи вашими страдали так над момента можно проговорили вот клёвая тема когда вы только начинаете проводить эксперименты вытащить здорово почему вы придумали такую фичу давно уже надо было сделать да вот и сразу видите изменения на ваших метриках то есть очень легко выходить вот так прям растете в начале потом приходите к кому-то пределу все таки да уже вот и улучшали интерфейс на улучшали ранжирование что делать дальше то есть приходим к тому что в какой-то момент на ваших показателях вот вы делаете изменения они значимых изменений блин потратили там не знаю месяц на подбор формула она показателях не значит улучшение какое рекомендация здесь берем принимаемся например запуская в эксперимент совсем ненадолго и смотрим что показатели у нас не поехали промышляет поломки а там решение о качестве принимаем по оффлайн метрики ну например сайд бай сайды там показываем экспертом эта часть лучше чем это собираем такие оценки и так далее потом берем аккумулируя все изменения которые мы таким образом выкатили и запускаем обратный эксперимент который содержит все те изменения которые вы набрали за ваш период на пусть это будет три месяца вот если вы все делаете правильно на обратном эксперименте вы увидите улучшение но потому что у вас в сумме сделали пользователям хорошо если вы увидели на обратном эксперименте ухудшении значит вы что-то делаете не так ну и такая рекомендация лучше включать 7-дневные промежутке вот bing например рассказывает про то что у них они проводили кучу замеров они еще больше помочь им и делают экспериментов и что одни выходные праздники никак не влияют там ссылочка будет меня потом на статьи белковые мы все-таки делаем рекомендацию лучше делать 7-дневные промежутке почему например ну потому что на денежных показатели все-таки в абсолютно значение есть разница пользователи тратят все таки деньги свои там в будние и выходные неравномерно особенно в москве поговорим о том какие инструменты вам могут потребоваться при работе с абэ с ними но как я уже говорил обязательно сопоставляйте планы факт это вам будет правда очень полезно иначе можно уже принять любое решение на кто читал там в молодости или в молодости книжки это физики шутят а была такая шуточка аспирант приходит к профессору мертво смотрите вся график такой читая непонятно почему он так себя ведет и профессор начиная так с умным видом объясняет да вот всего логично изменение так и должно быть стран блин а я то это самое оси перепутал перевернуть надо он не растет он падает профессор нифига не смутился и продолжает объяснять да блин такое тоже возможно поэтому еще раз написали план свои ожидания смотрим уже по факту что получилось ним и не объясняют задним числом вот еще такой один момент если вы вдруг получили значимое улучшение которые не ожидали данного ждали интерфейс делаем метрика там вырастет на скупка десятки сотые процента а у вас тут бац и на несколько процентов блин все равно надо разбираться ребят серьезно как бы потому что возможно где-то ошибках вот возможности недостаточно лампочек вот этих лампочек контрольных метрик да вот поэтому разбираться надо вот смотрим на метрики для контроля над краски про это проговорил проговорил пам-пам-пам а это вот у нас такая процедура да вот мы the bad bad bad запускаем и эксперименты но вообще говоря очень здорово хранить историю проведения экспериментов таким образом вы набираете сет вот был нас такой эксперимент такой такой такое и рекомендуется все-таки по возможности хранить и логе ну потому что мы обсчитывать например эксперименты на выжимка точно сна вход сырые логи дальше выжимки и по этим выжжем кому же посчитаем вот если у вас похожая процедура the vogue тоже надо хранить вот поэтому если у вас есть такой сет вы направили например за последние полгода до 50 экспериментов вам на этом сети экспериментов очень удобно будет подбирать новую метрику то есть не надо будет заново проводить эксперименты смотреть о блин как бы эта метрика повела себя на эксперименте у вас уже есть вот вам может потребоваться инструменты как viewers сессии пользователя чтобы смотреть как вообще говоря поле ведет себе на отдельно запросах вот и очень такая замечательная тема если вы считаете ваши показатели по срезам мы какую терминологии применяя вот у нас есть еще раз есть контроль есть эксперимент вот и мы можем считать измене и показатели по всему потоку мы говорим это интегральное наблюдение да вот а можем считать по потоку где происходит изменения ну например на коммерческих запросов на это у нас целевое наблюдение мы его так называем вот вообще говоря средством ну может быть много да можно побить по города можно побить по браузером кстати для интерфейсных экспериментов вот срез браузеров прям вообще обязательно всегда смотрите на показатели в браузерах потому что можно найти ошибку вот заранее набираем такие срезы которые нам могут понадобиться запускаем наш эксперимент посчитали подготовили выжимка потом быстренько переключаемся между ними принимаем решение про браузер и мы поговорили вот немножко статистике за 2014 год здесь именно про поиск яндекса то есть веб выдача the market и так далее все здесь не считается вот у нас было примерно 1000 экспериментов и пользователь видел примерно сто экспериментов единовременно но пугаться о пользователь видел 100 что же в ней поправляете как-то пользу видел стоп в продакшне крутилась то экспериментов одновременно вот но здесь учитываются также контрольные эксперименты формы просто для мониторинга делали вот и всего лишь двадцать один процент из всех экспериментов которые мы проводим выкатывается в продакшн так статистика во бинга обещанная ссылочка где вы можете все это почитать пользу видел примерно 15 экспериментов одновременно если мне память не изменяет по моему у них в 13-м году было 250 экспериментов одновременно в продакшен крутилась вот на этом у меня все если у вас есть вопросы я с удовольствием на них отвечу здравствуйте скажите пожалуйста вот вы когда упомянули инструмент вы сказали что необходимо хранить логе экспериментов да для того чтобы в будущем эти какие-то тесты проводить не нужно было что если у нас модель поведения пользователей поменялось и он может вести себя в этой ситуации совершенно иначе чем он вел себя например там я не за полгода назад спасибо да такое вполне возможно поведение пользователя конечно меняется но у нас именно ведь обед и статусе вас и в контроле и в эксперименте поведение поменялось ну то есть то есть вот ко второму пункту когда вы говорили о том что необходимо анализировать поведение отдельного до пользователя какого-то то есть все может быть все может поменяться абсолютно цена хоккей понял смотрите действительно может быть так вы на сайте подбираете метрику да и вам кажется новая метрика на ты бы лучше продакшна который использовалась и далее если вы будете проводить там подобные эксперименты у вас там может быть и абсолютный показатель точно будет разным 5 времени меняется и про краска будет может может может нибудь про краски чем я говорю когда я говорю про кратко я имею ввиду если статистически значимое отличие или нет то есть вы можете видеть на сайте что до метрика здесь улучшилась там проводите такой же эксперимент уже в новых реалиях и не видеть значимого изменения ну да к сожалению ну такое возможно но с это чем он хорош вы же и старую метрику то тоже принимали на старых экспериментах в этом тему такие изменения могут быть нет конечно не скрою мог быть и такие моменты вы подбирали метрику вот на свете и увидели она показывает значимым ухудшение потом проводится такой эксперимент она показывает зачем улучшение но это значит что то вот был баг в структуре мы например такое находили с одним экспериментом татьяна с был баг не в инфраструктуре а именно вот самом этом эксперименте которые у нас есть один контрольный и мы просто поняли что да вот в этом сете когда мы проводили принимали решение мы делали неправильно то есть это вам тоже позволит открыть ошибки спасибо спасибо за доклад в два вопроса один маленький небольшой маленький мне кажется что совмещение б тестов это плохо в том плане что они друг на друга могут влиять то есть мы совместили 2b теста и один тест сработал плохо из-за другого варианта абэ теста это когда мы одновременно показывает да да да несколько образцов смотрите во первых вы должны когда вы водите многомерную схему вы должны очень аккуратно как бы к этому подходить мы когда ее в воде ли мы проводили следующее исследование там более полугода мы это делали мы брали и дублировали эксперименты у нас есть один эксперимент например ранжирование мы его запускаем в многомерной схеме пересекаем с интерфейсами и у нас есть еще одно пространство пользователи где только пользу и может быть один эксперимент и запускали дублер эксперты там это вот и смотрели на показатели точно было достаточно дорого потому что учитывая что у нас все говоря борьба за пользователи чтобы эксперимент production запустить вот тем не менее мы в течение полугода делали и различие в разные стороны когда не 3 поздно чем улучшалась поменялось ту или иную сторону мы не видели до чувствительность по разному да ну то есть в 1 мерной схеме у нас чувствительность было даже ниже чем многомерной схеме эксперименты прокрашивать какие-то нет такого вопрос действительно хороший надо смотреть это первый пункт второй пункт рекомендация такая вот ваша многомерная схема там несколько измерений каждом измерении сделайте 2 контроля мониторинге следите за показателем в этих контроля если они вас там начинают как-то разъезжаться то уже сигнал потому что да что то идет не так да и второй вопрос я сам из мира earth тебе и это реклама и прочее и там суть такая там почти никогда не мере то есть все разочаровались метриках которые им про шины клики ну то есть просмотр клики это уже никто не верит в основном все стараются изучать конверсии то есть когда юзер сделал набор определенных действий то есть мы меряем не то что user там из-за того что главной странице он кликнул на кнопку а мы верим что из-за того что главная страница он поискал что-то надо ли стал до какой-то страницей им кликнул благодаря тому что у нас кнопка такого такой формы то есть мы не читаем клик непосредственно мы считаем набор действий то есть вот набор клипа versions и метрики да блин да то есть вот вот это именно вы все правильно делаете отличный метод я просто не стал вопрос об этом базовой раз правильные подходы versions и метрики вы все правильно делаете артур привет вопрос про инструментарий но что вы используете свой инструмент какой-то для мониторинга и запуска что что про инструментарий больше про методологию рассказывала меня вопрос про инструментария используете собственный инструмент для запуска экспериментов есть ли какие-то рекомендации по уже готовым инструментом который можно использовать или который можно кастомизировать если такое ожидал этот вопрос я к сожалению погружён в узкий специалист свои инструменты делая рекомендации тут не могу дать вот я знаю в нет яндекс метрики уже должны были ввести некоторые сегменты вот мы сейчас рассматриваем такой проект чтобы сделать возможность в яндекс метрике но как бы просто на этапе согласования возможно если она все получится с командой яндекс метрики такой будет но это так никаких обещаний ничего просто договариваемся вот есть по моему optima языком для интерфейсных посмотрите может если у нас силы будут сделаю внешней инструмент мы подумаем об этом спасибо простите спасибо за доклад вот изменение которое интерфейсные влияет на поведение пользователя вы говорили что нужно привыкание сколько вы закладываете на такие бы тесты времени и как понять вот происходит ли это привыкание потеки есть надежда что пользователя привыкнуть допустим выкатили сразу метрики упали и как понимать пользователь привыкают к этому если надежда что потом это пойдет в плюс сколько времени вы обычно на такие интерфейсе там неделю две три обычно неделю если сложно изменение две недели вот как понять но у вас показатели можете считать сразу собственно вы их начинаете считать сразу вот у вас есть график который должен не сильно колебаться например там даже дольник но люблю эту метрика по идее она не сильно должна изменяться ну вы увидите прямо в затухание на графике что они начинают более менее сходиться и начиная с этого момента делать измерения серебряной пули нету базовые рекомендации вот такие есть еще вопрос у меня здесь я за стеклом так скажем в тестировании она имеет много всяких факторов и мне было интересно вот как когда вы упомянули что например ты не просто цвет меняешь например кнопки а именно экспериментируешь с оттенками в данной ситуации каким образом можно проследить проконтролировать тот фактор что например сегодня было больше кликов несмотря на то что то мне не знаю оттенок по факту хуже но был вторник вторник там более по посещаемости я не знаю как как бы день недели повлияет на метрику больше чем изменение оттенка как это контролировать как это ну посмотрите вообще базовая рекомендация все-таки в течение недели ждать вот но когда у вас вариаций очень много и не знаю там вы экспериментируете с оттенками с размером шрифта с отступами то есть там комбинаторный взрыв на самом деле получается да ах а решение хочется принять как можно скорее здесь рекомендация следующие первых проводите сайд бай сайд да то есть если у вас есть возможность показывайте экспертом вот одно изменение второе изменение эксперт делает оффлайн оценку таким образом вы уже уменьшаете в число кандидатов которые вы запустите в эксперимент это первая рекомендация вторая рекомендация это действительно тут начинается у нас множественной проверка гипотез потому что там много метрик много экспериментов и какая-нибудь все таки может случайно про краситься вот как вы говорите там вторник мог повлиять да если у вас нет возможности там очень недели экспериментов крутить выбираете победителей которые у вас по результатам вот из всей этой серии вот которые показали значим улучшение на метрик а потом их еще раз прокручиваете ну то есть чтобы повторный эксперимент уже среди победителей вот и если не прокрашивается то уже дает повод задуматься о том что предыдущая прокраска вова случайны более того при повторном запуске она точно должна прокрасить потому что вы же уже отмели кандидатов вас объемы еще больше становится вот мы о чем больше событий тем меньше у дает ему можем поймать спасибо благодарю за ответ и благодарю вас за ваш доклад"
}