{
  "video_id": "TSFVV0zGSBI",
  "channel": "HighLoadChannel",
  "title": "Поиск по образцу на последовательностях строк в БД / Евгений Зверев (Яндекс)",
  "views": 175,
  "duration": 2680,
  "published": "2024-10-29T03:07:37-07:00",
  "text": "Евгений Зверев из Яндекса же Привет как дела вс хорошо ты занимаешься разработкой Яндекс db Я так понимаю Да да Я работаю в команде разработки платформы Ага А как давно ты работаешь несколько месяцев Ага Понятно У тебя уже таково неплохой контент с всё класс А друзья будет доклад запоминаю лучшие вопросы задаём у нас есть призы вот пожалуйста Жень начинай да Алексей спасибо всем Добрый день я начну с того что расскажу чуть-чуть подробнее о себе чем я занимаюсь я работаю в it Уже довольно давно больше 20 лет А причём работал как и разработчиком тиб дом так и руководителем различных команд и подразделений разного размера продуктовой сервисной разработки в депс команда и так получилось что Во время моей карьеры у меня чередовались периоды Когда я работал разработчиком и когда работал руководителям разных подразделений Таким образом получается совмещать И поддерживать некоторый баланс между развитием руководящих скилов и поддерживать на уровне высоком Experience необходимый для непосредственной разработки последнее несколько месяцев как я уже сказал Я работаю в команде платформы разработчиком и сегодня хотел бы рассказать об одной интересной задаче которой мне привелось заниматься в этот период а именно речь пойдёт о выражении ма recognize в SQL стандарте Это новая ф Ну относительно новая функция языка а она малоизвестная Поэтому в своём рассказе я сначала Расскажу какие возможности представляет выражение ма recognise разберу несколько примеров а потом перейду к тем сложностям которые приходилось решать во время разработки Какие дизайн решения Мы приняли в итоге и что из этого Получилось И какие дальнейшие планы у нас на развитие функционала Match recognize добавился в s standart в 2016 году То есть уже довольно давно и многие производители баз данных уже поддержали его в своих продуктах А теперь и мы в idb платформе тоже занимаемся поддержкой этого функционала для того чтобы расширить возможности и как бы обеспечить полноту выполнения стандартных функций если коротко рассказать о том что это такое то проще всего провести аналогию с регулярными выражениями Когда нам нужно найти какую-то последовательность символах в строке мы пишем регулярное выражение ну наподобии того что сейчас представлено на слайде я не буду его разбирать думаю что все знакомы с синтаксисом регулярных выражений и примерно понятно что он делает аналогичным выражением над таблицами будет паттерн который Здесь представлен на слайде он структурно соответствует регулярному выражению но имеет одно существенное отличие вместо символов он состоит из переменных которые описываются бинарными предикатами то есть каждая переменная может принимать True или в зависимости от того каким данным Ну каким строчкам таблицы она применяется и в результате работы будет найдена последовательность удовлетворяющая такому паттерну а разберём несколько примеров которые позволят понять мощь выражения much recognize и то на каких задачах его целесообразно применять синтаксис выражения ма recognizes довольно сложный Там есть много вариаций и я потихонечку буду вводить новые элементы конструкции по мере своих своего рассказа по мере показа дополнительных примеров на этом сла представлен пример использования для обнаружения попытки взлома аккаунта например системе анро что мы здесь понимаем под взломом аккаунтом аккаунт это последовательность событий состоящий из следующих шагов сначала несколько раз неудачная попытка ввода Пина потом удачный ввод Пина пин-кода причём важно чтобы эта последовательность событий произошла в относительно небольшой период времени слева у нас представлены исходные данные это таблица или поток событий в которых для простоты указано лишь несколько параметров временная метка тип события результат события и пользователь с которым ассоциировано событие выделена на этой табличке последовательность событий которая приводит к интересующему у нас проблемной ситуации то есть кто-то пытался подобрать пароль к аккаунту И после этого сменил пин-код в этом случае операцию нужно Ну либо блокировать либо как минимум пометить как подозрительную для того чтобы потом провести дополнительное расследование теперь посмотрим как выглядит запрос recn написанный для детекта этой ситуации начинается он стандарта зв - это имя таблички дальше идт ключевое слово и первой стро после ИТ который говорит что перед тем как начать дальнейшую обработку мы разбиваем все наши входные данные по пользователю по полю по колонке User и потом обрабатываем независима далее следует секция паттен которая очень похожа на ту что мы видели на предыдущем слайде и дальше секция кото как раз и одет те Дика которые Перемен использу в паттерне синтаксис Здесь вроде бы довольно понятен я остановлюсь только на основных моментах нуги мы Принимая значение когда строчка таблицы имеет значение типа логин значение статуса suc Аналогично следующий предикат это дикат который все принимает знание Илю объявления не писать и они не явно будут принимать значение все переменные которые не объявлены явно и последняя переменная Она имеет несколько особенностей во-первых она ссылается на ранее описанную переменную а во-вторых в ней используется функция это так называемая навигационная функция которая позволяет заменю дача другие навигационные функции Last Next PR но о них я не буду разговаривать останавливаться подробнее следующим так в процессе работы выполняется матчинг этих переменных на соответствующей строчки таблички Ну и в данном случае видно что мы нашли в таблице интересующий наш результат и нужно сформировать Ар о том как формируется результат работы recn по переменным я расскажу в следующем примере следующим примером Я хотел бы рассмотреть пример из другой области это поиск специфического шаблона изменения цен на акций допустим у нас есть исторические данные которые представляют собой цены изменения цен акций на разные инструменты соответ У нас есть символ опять же временная метка и цена и мы хотим в этом наборе данных те акции которые имели так называемый vap в графике изменения цен когда цена сначала падает до какого а потом поднимается Ну в каких-то диапазонах соответственно для этого мы тоже используем recn первое что мы делаем Это партиционирование по символу это по типу инструмента В данном случае акции после этого новая конструкция это Order by мы говорим что нам Мы хотим рассматривать события в таблице по в порядке увеличения времени то есть в хронологическом порядке далее секцию я пока пропущу секция паттерн Аналогично описывает последовательность Упс я прошу прощения Спасибо большое Тогда ещё раз коротко слева это таблица с изменением цен справа это графики соответствую в этой табли в середине и мы ищем паттерн цены соответствующей буковки в Латинской когда цена сначала уменьшается потом увеличивается сначала смотрим на ма партиционирование паттер дальше объявлены в секции она в значительной степени повторяет структурно тоже что было на прошлом слайде используются как ссылки на ранее определённые переменные так и навигационные функции но я хочу заострить внимание на последней объявление переменной D там помимо навигационных функций используется ещё и агрегация функции которая позволяет почить в данном случае среднее значение всех н с матче на переменную б Ну в процессе работы точно также происходит матчинг переменных на строчке таблицы и после того как этот матч найден нужно сформировать и выдать результат работы ма recognize и тут вступает в действие секция measures она описывает Какие данные нужно выдать в качестве результирующих столбцов таблицы то есть результат здесь Также можно использ можно использовать навигационные и Арен функции в результате работы данного выражения будет выдано Вот такая строчка состоящая из одной строки и пяти столбцов описанных в секции теперь посмотрим на то после этих двух примеров в целом на алгоритм работы алгоритм здесь Вт в кавы помм реу он описывает то каким должен быть результат поэтому здесь будет алгоритм в том смысле что это некоторые логические последовательность действий которая приведёт к желаемому результату в первую очередь при работе макона происходит партиционирование этап партиционирование входных данных на предыдущих примерах были простые варианты партиционирование по столбцу но в принципе здесь можно указать произвольное количество произвольных выражений которые данных выделять ключе и по этим ключам данные будут разделены на несколько независимых партиции дальнейшая обработка будет выполняться по каждой партиции Независимо а далее эта партиции сортируется А что происходит э опять же в зависимости от э тех выражений которые были указаны в запросе э в примерах было партиционирование по времени здесь могут опять же быть произвольные выражения далее начинает работать секция пате и Def в результате которой строчки входных данных матчи на переменные в соответствии с паттерном после того как соответствие найдено работают секции me и новое выражение которое определяет количество строк которое нужно выдать Когда у нас найдено соответстви это опция которую мы рассмотрели на примерах говорит о том что на весь найденный паттерн нужно выдать одну результирующую строчку со столбцами описанными в All говорит о том что нужно выдать все строчки на которые сма переменные паттерны там тоже можно управлять количеством чтобы не выводить лишнее но я сейчас на этом не буду заострять внимание после того как мы выдали первый найденный результат алгоритм переходит к поиску следующего и здесь есть несколько опций откуда продолжить ээ поиск можно продолжить Либо со следующей строчки после первой ээ которая смачило на образец это вариант After Match to Next Row можно продолжить после последней строчки таким образом будут найдены только а образцы которые не пересекаются не имеют пересечения друг с другом можно сослаться на Любую переменную которая смачило в процессе поиска и продолжить выполнение с этой строчки здесь есть один интересный эффект можно в качестве автома СПТУ указать первую переменную которая смачило на начало паттерна и таким образом алгоритм продолжит выполнение с той же самой строчки это позволит найти все паттерны начинающиеся на одной строке данный сценарий полезен например опять же в сценариях антифрод Когда у нас может быть несколько подозрительных цепочек событий начинающихся с общего логина первое событие логин потом что-то что-то что-то разные события и несколько подозрительных активностей так рассказал немного про мач в целом теперь перехожу к тому как мы реализовывали поддержку май Какие вопросы решали и какие были сложности Ну в первую очередь перед нами встал вопрос того где мы хотим поддержать конечно описывает это только в применении к таблицам но у нас в платформе wdb также есть потоки и мы хотели поддержать функциональность одинаково как на таблицах в аналитических запросах так и на потоках также в этом был заинтересован один из внутренних заказчиков поэтому мы не могли выбрать только что-то одно для этого сравним немного функционал которым можно при выполнении запросов на таблицах и на потоках ну на таблицах ВС довольно просто относительно по сравнению с потоками мы можем использовать сортировку которая имеется уже в базах данных основанная на индексах мы можем в ходе выполнения поиска сопоставления по образцу использовать неограниченные итерации по данным за счёт этого можем использовать как алгоритм с трекингом это основа классических алгоритмов для Рекса так и алгоритмы основанные на конечных автоматах их они используются в современных библиотеках опять же для Рекса и тут мы в праве выбирать какой класс алгоритмов использовать И тем самым можем искать баланс между тем С какой скоростью мы ищем или сколько стейта мы Тим хранить или накапливать в ходе работы алгоритма также мы можем применять стандартные методы оптимизации которые уже хорошо отработаны в базах данных ждана предикатов Джов и прочего потоковая же обработка имеет существенную особенность но первоя очевидное мы не можем сортировать бесконечный поток данных это в принципе невозможно он никогда не кончится также у нас есть ограничение на доступ к данным из прошлого А поскольку поток условно говоря бесконечный цепочка сопоставление может быть очень длинное мы не можем хранить Всё мы должны удерживать только то что нам нужно для продолжения поиска принятия решения поэтому мы ограничены в нашем выборе алгоритмом только какими-то вариациями на основе конечных автоматов и при этом по-прежнему сохраняется актуальная проблема с растущим стей количество накапливает стейт растёт характеристики работы алгоритмов ухудшаются о том какие это имеет эффекты я расскажу чуть подробнее попозже Но к слову сказать что выбирая между двумя вариантами обработки через стриминг и таблицы нужно сказать что эти варианты в принципе Вырази один через другой если у нас есть реализация какого-то алгоритма на потоках то Естественно что мы можем её применить для таблиц просто последовательно подавая на вход этого алгоритма строчки таблицы просто пусть не самым оптимальным образом Если же у нас есть реализация таблиц на таблицах и нам нужно реализовать на стриминге то это в принципе тоже возможно Ну путём нарезания нашего потока на окна окна нужно подбирать такой длины чтобы в него в это окно поместилось цепочка максимальной длины которую мы отлавливает это скать понятно что тут есть проблема с цепочками которые попадают на границу окна в данном случае они не будут найдены Понятно тоже как е решить это накладываю окна они порождают другую проблему то что у нас происходит Ну во-первых задержка на выдачу результата во-вторых у нас появляется дублирование результатов когда какая-то цепочка попадает целиком в одно окно задержку можно уменьшать увеличивая кратность перекрытия при этом усугубляется проблема дублирующих результатов в общем реши обработку через табличную можно но это имеет вот эти очень неприятные эффекты поэтому мы решили что мы в первую очередь ориентируемся на потоковую обработку делаем её в соответствии с принципами принятыми для потоковой обработки решая те сложности которые с ней сопряжены и применяем эту потоковую обработку для обработки таблиц Какие из этого следуют выводы Ну первое мы заменили сортировку на переу порядочное событий на скользящем временном окне переменной ширины ширину окна определяемую в Рика и поэтому когда всё идёт хорошо оно небольшое и не вносит существенной задержки для табличек слову сказать мы по-прежнему используем сортировку поэтому получаем выгоды которые есть от обработки таблиц алгоритмы используем на вариации на основе конечных автоматов Несмотря на то что мы выбрали в первую очередь потоковую обработку событий которая э сфокусировано на обработке временных потоков потоков упорядоченных во времени мы тем не менее не стали вводить в синтаксис языка расширение для указания окна обработки как это часто встречается в потоковых системах и остановились на том что указание окна обработки задаётся регулярным образом через предикаты над полем AMP в исходных данных Это позволяет реализовывать алгоритмы оптимизации не зная о том что у нас какое-то одно поле имеет выделенное значение времени и применять его эти алгоритмы оптимизации к другим наборам данных Ну и как следствие того что мы выбрали алгоритмы потоковой обработки а не относительно простой алгоритм на основе трекинга У нас сейчас относительно небольшое подмножество возможности и Стандарта реализованы в данный момент Ну как наиболее существенное ограничение у нас не поддержаны агрегация функции далее но мы при разработке ориентировались на то что у нас будут большие объёмы данных как в таблица так и потоках поэтому общая архитектура сразу была выбрана таким образом чтобы мы могли масштабироваться при увеличении объёма входных данных и при увеличении сложности запросов которые запускают пользователи общий пайплайн выглядит следующим образом слева у нас входные данные это может быть табличка или поток Даше блок выполняй чтение и фильтрацию диванных данных ли по количеству шардов далее после этого Мы выполняем партиционирование и после партиционирование уже данные по какому-то подмножество ключей партиционирование переходят на обработку тут на слайде не очень хорошо видно но между блоком шал и блоком Order по сути стрелочки каждый к каждым поскольку у нас ключи партиционирование обычно не совпадает с ключами шаровая так после завершени обработки идёт блок записи результатов тут у нас тоже есть параллелизм Но обычно в при использовании марей количество выходных данных существенно меньше чем входной поток поэтому здесь ну просто показана Параллельная запись два шарда основная идея этого слайда то что в зависимости от того какой у нас входной поток и насколько сложные запросы задал пользователь мы можем Независимо масштабировать разные части этого увеличивая либо количество шардов и количество читателей либо количество computation node которое выполняют обработку далее э расскажу немножко про то как у нас реализован алгоритм на основе конечного автомата а конечный автомат состоит из э двух основных частей это статический Граф переходов который строится на основе запроса пользователей и по сути является Ну в некотором смысле программой которую выполняет конечный автомат при обработке входных данных и Run State - это то состояние которое накапливается при получении входных данных расскажу о том что из себя представляют обе эти части конеч автомат строится на графе переходов и на этом слайде представлены основные наверное заготовки из которых строится Граф переходов сложного паттерна Здесь представлен паттерн соответствующий просто одной переменной переменной с квантификация двух переменных А и альтернатива а или б на графе переходов вершины пронумерованы просто для удобства а рёбра представляют собой условия при которых выполняется переход из одного состояния в другое основной тип Наверное это рёбра соответствующие переменным тут помечены как А и и переход по этим переменным осуществляется в том случае если соответствующий предикат предикат соответствующий этим переменным ра истина а другой тип переходов - это н переходы переходы по ним осуществляются вне зависимости от входных данных иде оди для просто но по сути они имеют разного ти они имеют чу-чуть разный Тип и описывают разные действия которые нужно выполнять при выполнении этого перехода Так что Грас переход вместе с переход и э переходами и переходами по переменных и представляет собой Ту самую программу которую выполняет конечный автомат Далее для примера представлен Граф переходов который соответствуют сложно по сути это ну некоторая комбинация не комбинация а композиция элементарных графов переходу с предыдущего слайда разбирать мы его не будем Не пугайтесь наверно основная тут мысль что он хоть и выглядит довольно большим и сложным он не имеет громадного размера Ну и соответствует паттерну который тоже е нужно писать Это скорее нетипичный пример но тем не менее чтобы вы имели представление Каким образом Какого размера могут появляться графы Как происходит обработка этого графа Ну Здесь представлен Граф переходов соответствующий паттерну а звёздочка всё это в скобочках звёздочка C паттерн Здесь представлен и здесь есть небольшая анимация на примере которой мы сейчас разберём Как происходит выполнение программы Ну при начале обработки каждой строки у нас помечается активным стартовое состояние и дальше алгоритм в целом следующий сначала выполняются все сисилон переходы А здесь я хочу обратить внимание что при выполнении сисилон переходов количество активных состояний может увеличиваться То есть их может стать не один там атри больше сколько угодно и в этом проявляется свойство недетерминированный строчка ни на что не смачило поэтому не после завершения выполнения первой строчки не осталось активных состояний дальше переходим ко второй строчке Аналогично выполняются Син переходы Ну и тут будет видно что у нас смачило переменная А и дальше после неё также выполняются переходы пока есть возможность и у нас Граф и весь конечный автомат находится в состоянии ожидания двух потенциальных событий B или C Ну если мы перейдём на последующую строчку то опять же начинается с выполнения сисилон переходов и Тут видно ещё одна характерная особенность то что граф конечный автомат может не только может иметь несколько переходов несколько активных состояний эти нескольких состояний могут быть в каждой вершине графа то есть по сути Это не просто точка где-то на графе переходов а каждой каждый из этих кружочков обозначает всю историю перехода прохода состояний по графу перехода в процессе обработки то есть две точки например в вершине значит ча что мы сюда пришли двумя разными способами пом двум разным траекториям и это запом запоминается в состоянии конечного автомата Ну и далее У нас смал со C и Мы перешли в конечное состояние и эта ситуация соответствует тому что мы нашли образец который искали у нас смачило в данный момент сразу два матча у нас мачала вторая и третья строчка и отдельно у нас Мась третья строчка то есть последо а и ну и оба эти результата будут выданы автоматом как результат работы запроса если указано указан режим искать все матчи начинающиеся с одной строки что здесь можно ещё сказать что у нас количество вот этих вот матчей количество состояний автомата очень сильно зависит от того как данные соответствуют нашим предиката и образцу и если у нас например одна строчка соответствует нескольким предиката то количество состояний будет ещё больше а это не очень хорошо и Об этом я сейчас расскажу так да на этом слайде представлено А что из себя представляет э накопленный стейт нашего конечного автомата как я уже говорил каждая точка обозначает траекторию прохождения ээ обработки по графу переходов и эта траектория описана в виде рендже на которое сматчить переменные соответственно каждая точка каждый кружочек соответствует какому-то кортежу рендже ренджи ссылаются на строчки входной таблицы это нам нужно для того чтобы ну продолжать выполнение матчинг переменных и нужно для того чтобы выдать Конечный результат который может ссылаться на переменные и соответственно на входные данные для того чтобы не хранить все данные мы здесь используем SP L счётчиком ссылок соответственно пока на строчку кто-то ссылается она удерживается в памяти как только соответствующее состояние удаляется Ну потому что либо у нас оборвалась цепочка мачин либо Мы дошли до конца и выдали результат удаляется состояние удаляется ренджи которые с ним ассоциированы ренджи освобождают ссылки на входные строчки входные строчки также удаляются и освобождают память Таким образом мы удерживаем количество необходимой памяти только в том объёме который необходим для продолжения работы алгоритма и выдачи результата какие есть сложности у данной реализации основную проблему представляют такая комбинированная характеристика как частично смачивается цепочки их количество определяется вход как бы комбинации входных данных и заданных пользователем в запросе образцом и предикатов когда количество этих частичных матчей небольшое текущая реализация работает хорошо когда количество начинает расти Имеются два неприятных эффекта Ну первый эффект понятно что когда у нас растёт количество количество частичных матчей у нас растёт общий накапливает и здесь на графике он условно нарисован линейно и одновременно с этим обратно пропорционально Опять же условно снижается скорость обработки входного потока Почему так Потому что по каждому частичному матчу на каждой строчки нам нужно принять решение то ли его продолжать накапливать то ли отбросить уже как не состоявшийся это не единственная возможная реализация но сейчас у нас именно так и по сути вот текущий слайд он соответствует той точке в процессе разработки этого функционала Где мы сейчас находимся Поэтому в качестве завершения Я бы хотел рассказать о том А чем мы планируем заниматься но на самом деле уже занимаемся в первую очередь это будет оптимизация обработки частичных матчей то есть повышение эффективности работы алгоритма Когда у нас большое количество частично смах следующим по приоритетам пунктом является расширение функционала для того чтобы догнать функционал который у нас реализован до продуктов до возможности реализованных в других продуктах также хочется отказаться от требования упорядочивания потока и убрать вот ту фазу рр которая была на пайплайн обработки она требует довольно много ресурсов и кажется от неё можно отказаться механизм с помощью которого мы можем решить наверно первую третью проблему кажется что это так называемая ленивая конечные автоматы в сторону которых мы сейчас смотрим они позволяют при получении событий буферизированный части образца не реализовано это то что мы смотрим и Надеюсь в ближайшее время сделаем на это у меня всё спасибо спасибо большое поднимайте руки у кого есть вопросы в чат тоже можно написать кто смотрит нас онлайн Пишите в чат возле плеера из зала можно задавать вопросы в чат зала так вот рука у кого-то есть микрофон Да уже вс Давайте сечас идт микрофон и задам вопросы Я наконец-то Поня зачем я университете потому что иначе бы было тяжело так вопрос У меня наверно простой вообще вот то что внедрили вы уже используете в каких-то продуктах Яндекса или пока это только на этапе тестирования Нет это пока не используется это на этапе тестирования оно доступно в ранке idb на гитхабе Так что можно попробовать но мы это ещё пока не рели А через Яндекс облако это пока ещё недоступно Да тестирование я точно не могу сказать надо уточнить То есть это возможно включить но оно будет в уреза функционале вот в том что я сказал и под праг мой если есть заинтересованность то это можно обсудить Да спасибо доклад был очень интересный спасибо Ну да То есть можно подойти в кулуар или на стенд наверное да И эту подробную историю узнать а уже хочется попробовать да Понятно ладно уже уже есть Ага давайте Здравствуйте спасибо Я тоже хотел Вас поблагодарить за доклад Ну потому что реально вроде столько ковырял и тут это опять такой вынос мозга в хорошем смысле вопрос а-а там представим У меня есть небольшой проект Но он у меня реально есть я туда пишу в базу некие события там снятые с камеры То есть я увидел там человека а человек пропал Я так понял что там мач recognition Мне бы как раз подошёл очень просто описать ситуацию когда грубо говоря я встретил человека а в течение дня встретил его снова если по событиям я его распознал Вот и я как помню правильно если из вашего доклада одно из ограничений входных вроде как данные уже должны быть упорядочены а ещё какие-то есть ограничения то есть вот вы привели пример с партиционирование по пользователю Partition by User там случайно не требуется как-то ещё и партиционирование вы готовите данные Угу а тут было кажется два вопроса Первый тре всё нормально Требуется ли упорядоченное во времени требуется для работы nfa но оно в принципе не требуется для на пользовательском уровне для выражения ма recognise потому что первой строчке второй можно написать Order by и нужный параметр и соответственно движок движок SQL сам упорядочить те события которые у вас есть в источнике вот второй вопрос Нужно ли партиционирование это определяется логикой то есть логикой работы запросов ние в данном случае это не шардирование и не оптимизация Если вы хотите чтобы данные двух пользователей обрабатывались Независимо вы их должны партиционирование Да кроме СН готовить нужно всё что требуется для выполнения запросов можно указать в теле запроса Ага это может влиять на эффективность конечно ну то есть если у нас потребуется сортировка по столбцу на котором нет индекса она будет долгой понятно То есть делаем запрос потом передаём это всё дальше в и он дальше уже сам считает Да наверное про нужно знать только если интересоваться как реализовано внутри на уровне писания запросов знать Угу О'кей так ага пожалуйста так Нет ну в общем слышно просто на на записи наверное будет плохо да Ну ладно Задавай я повторю У тебя короткий А наверное короткий короткий Я так понимаю это аналог всем систем типа слан или куме А И у нас используется позиционирование и например кейсе кото У нас есть антифрод э у нас может ну мы накапливать какие-то данные то есть там допустим логины на картой партиции Что будет если количество данных которые мы накопили Ну у нас очень много может быть не знаю неправильных логином Да что буде количество данных привы количество места которое находится на партиции Как отследить этот кейс происходит Что что будет для трансляции что будет количество данных превысит количество данных которые находятся на партиции как количество памяти превысит количество памяти на партиции да превысит то есть не уберёмся по памяти Да эта проблема как раз соответствует той сложности про которую я рассказывал в самом конце частичными матчами мы пока эффективно не умеем бороться мы над этим работаем Э да проблема Когда у нас начальное событие цепочки приходит очень часто а конечно придёт там через день и только на один из нескольких тысяч начальных А да в Да пока у нас э такие ситуации обрабатываются не очень хорошо Ну с деградацией производительности про вытеснение из памяти с этим мы ещ Не сталкивались ну тут тоже понятно что делать в этом случае нужно сбрасывать эти данные на диск то есть реть какую-то стратегию слинга но опять же пока этого нет добавить больше памяти это не всегда возможно ладно Так ладно ещ вопросы Дайте вот третий ряд А вот микрофон тебя Зак задал коллега то есть предполагается ли какой-то тюнинг на уровне там настройки edb чтобы можно было конфигурировать объём памяти который может быть использован для стейта Ну то есть для запросов которые захватывают очень большие цепочки либо специально ограничить объём вот для накапливает для очень коротких Ну первая часть простая сейчас этого нет вторая Я наверно отвечу ун мы об этом подумаем Спасибо Да проблема действительно относится к тому что говорил предыдущий звучал в предыдущем вопросе Пока нет решения Да вот вот вот Т ещё Давайте третий ряд Да Жень ты лучший вопрос думай кто тебе больше нравится подарим подарок Евгений Спасибо за доклад Интересно насколько это вообще инструмент готов к применению в про есть да вы е какието какие-то планы у вас ещё есть но вот по производительности что может мерили на чём мерили какие результаты мы мерили мы мерили на синтетике там по были сотни кило событий в секунду на потоках вас это устраивает Или хочется Нет не устраивает Мы хотим гигабайт нае потоки то есть таргетный цель таргетное состояние - это единицы десятки гигабайт Спасибо А с кем С кем-то соревнуется Нет мы не соревнуемся Это скорее из потребно нашего заказчика внутреннего А мы перейдём к фазе сравнение по производительности с конкурентами Но тогда когда будет более или менее реализована пока сравнивать не совсем честно то есть какой-то конкурент который сейчас используется и это по сути замена Нет ну как есть для примера с кем сравниться есть так-то вопрос бутва СБО частичные чи да вот у вас проблемы вызывают когда там данные потом доезжают А что если Вот именно вот первые которые точки приезжают позже ну то есть запаздывают данные как-то например вот поток идёт Да И вот первые мчи когда вот сам стейт ещё не будет готов Вот как вот с этим бороться Да ну если речь про таблиц то на таблицах полагаемся на сортировку такая ситуация невозможна е же говорить про потоки то да это возможно у нас источники могут выдавать данные неравномерно для этого мы пока раз поставили фазу шаг Time reorder который восстанавливает хронологи событий в каких-то пределах Ну то есть мы говорим В каком окне Мы это можем восстановить хронологию если события выпадают за это окно в данном случае цепочка не будет найдена и здесь можно просто выдать Арт что у нас случилось нарушени хронологию И если в этот момент было что-то подозрительное Ну или есть основание считать что это целесообразно её можно прогнать отдельно уже чуть позже скажем так принцип такой на потоке максимально обрабатывается ИРР в потоке выбросы должны обрабатываться отдельно а при при алер падает заброс да получается он не находит просто а а ну пустой ответ ну там выпадет Вот это событие которое пришло вне окна пере упорядочены конечный автомат его просто не увидит оно до него не дойдёт ой всё вот продолжаю отвечать на этот вопрос тут ситуация изменится если мы откажемся то есть найдём способ эффективно отказаться от этой фазы переу порядок независимо от порядка в котором события пришли понятно То есть у вас такая научная работа Илья ну она вряд ли научная тут скорее поиск Среди наиболее подходящего относительно известных вариантов Угу всё понятно Так ещё какие-то вопросы есть да давай первый вариант я хотел спросить а были какие-то вообще инновационные вот вообще вещи которые прямо вот изобрели или всё всё это какие-то уже известные алгоритмы а Наверное это скорее Инженерная работа по составлению сложной системы из из из известных кирпичиков кусочков понял Да добрый день спасибо за доклад и я вот хотел спросить э про сложность этого алгоритма который рассказали и это больше э ранта история про то что прямо в ран тайме можно ожидать каких-то быстрых результатов или Это скорее аналитические запросы которые будут выполняться там в течение в потоковой обработке это прямо ранта там выход это единиц секунд Угу Так окей Всё Давайте а стоп Давайте полонием жене Да Аплодисменты Жень Выбирай лучший вопрос Какой тебе больше всего понравился наверно мне понравился вот практический вопрос с тем как с камеры события обрабатывать и полу результа Да поднимите руку кто задавал Да вот получаешь приз у нас от партнёра Жень тебе тоже приз от онтика А всё спасибо большой ловить"
}