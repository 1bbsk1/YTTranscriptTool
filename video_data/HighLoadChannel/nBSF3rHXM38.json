{
  "video_id": "nBSF3rHXM38",
  "channel": "HighLoadChannel",
  "title": "Deep dive into PostgreSQL internal statistics / Алексей Лесовский (PostgreSQL Consulting LLC)",
  "views": 1357,
  "duration": 2352,
  "published": "2017-04-08T14:10:11-07:00",
  "text": "дорогие друзья сейчас ровно по расписанию в 45 минут мы начнем следующий доклад последний из вот этого утреннего блока таких технических докладов папа сгрыз у рассказывать будет мой коллега алексей лисовский про то где у пожгли со смотреть какой performance то есть когда что-то происходит плохо нужно как бы поглядеть какие средства диагностики но не просто еще их поглядеть правильно интерпретировать и смотреть в некой системе если кто считает что я много понимаю в мониторинге последствия как он устроен внутри так вот вы ошибаетесь мой коллега алексей знает это намного лучше и в общем наверное он один из немногих людей кто это знает может быть лучше всех уж по крайней мере на русском языке так точно может об этом рассказать лучше всех поэтому что называется сейчас у нас еще остается полторы минуты вы свои смартфоны доставайте чтобы сразу фотографировать у нас конечно в блоге будут выложены слайды обязательном порядке но тем не менее как бы хочется все свое побыстрее иметь берите блокноты и записывайте что нужно делать вот но предоставляю слово алексею он дальше сам все лучше расскажет добрый день меня зовут алексей как у жилья сказал я буду рассказывать про статистику пост грессов начнем о чем будет доклад статистика активности под криса upon криса есть две статистике статистикой активности про которую будет речь и статистика планировщика распределение данных так вот я буду рассказывать именно о статистике активности мозга со которая позволяет нам судить о производительности и как ты ее уже улучшать расскажу как эффективно использовать статистику для решения самых разных проблем которые у вас возникают у или могут возникнуть чего не будет в закладе в докладе не будет статистике планировщика да то есть это очень большой такой пласт на отдельный доклад о том как данные хранятся в базе как там идет распределение этих данных этого в докладе не будет и не будет обзоров инструментов то есть я не буду сравнивать один продукт другим ничего такого никакой рекламы вот а бросим это итоговая цель доклада такая я хочу вам показать что использовать статистику это полезно это нужно использовать и не страшно нам понадобится всего лишь обычный иску или с базовые знания риску или и какую статистику выбирать для решения проблем и так если мы посмотрим на пост grease до операционной системе запустим команду для просмотра процессор мы увидим черный ящик мы видим какие то процессы которые что-то делают и мы по названию можем примерно представить что они там делают чем занимаются но по сути это черный ящик внутрь мы заглянуть не можем мы можем посмотреть нагрузку на процессор в том же топе можем посмотреть утилизацию памяти какими-то системными утилитами но заглянуть внутрь под колеса мы не сможем для этого нам нужны другие уже инструменты и продолжая дальше я расскажу куда тратится время если мы представим босс gris вот видя такой схемы да можно будет ответить куда тратится время это две вещи это обработка клиентских запросов от приложений и фоновые задачи которые выполняют пузырь стран для поддержания своей работоспособности если мы начнем рассматривать сверх него с правого угла то мы можем проследить как обрабатываются клиентские запросы запрос приходит от приложения к нему открывается сессия запросов передается в планировщик планировщик строят план запроса отправляет его дальше на выполнение происходит какой-то вот вывод данных таблиц и индексов все это поднимается в шарик байерс результаты запроса если это но апдейты какие-то билеты результаты фиксируются в журнале транзакции в рай то hotlog потом значение значит какие то вы путаются в лагерь либо попадают и статистику и результат запроса уже отдается клиенту обратно вверх по стэком что у нас с фоновыми задачами и фоновыми процессами у нас есть несколько процессов которые обеспечивают работоспособность и поддерживают базу данных в нормальном рабочем режиме пройти процесс и я буду говорить это of the vacuum чекпоинт процессы связанные с репликацией и вот бэкграунд райт рычаг winter процесс я буду их я затрагивать по мере доклада какие проблемы есть со статистикой информации много от 94 предоставляет 109 примерно 100 метрикам для просмотра всяких разных данных однако если в базе данных хранятся много таблиц много схем много баз все эти метрики придется умножить на соответствующее количество таблиц баз информация становится еще больше и утонуть гораздо ну очень легко следующая проблема это то что статистика представлена онлайн счетчиками если мы посмотрим эту статистику мы увидим постоянно увеличивающиеся счетчики и если с момента сброса статистике прошло очень много времени мы увидим просто там миллионы миллиардные значения и они нам собственно ничего не говорят нет истории если у вас произошел какой-то пока что-то там у вас упала уронила 15 минут назад 30 минут назад вы не сможете воспользоваться статистикой и посмотреть что происходило 15-30 минут час назад эта проблема отсутствие нативного инструмента та же проблема под gres quelle разработчики ядро они не предоставляют неё к и утилиты у них нет ничего такого они просто дают вам статистику вот в базе пользуйтесь сделайте к ней запрос что хотите то и делайте нативном инструмента нет и это является следствием другой проблемой множество сторонних инструментов каждая компания у которой есть более-менее прямые руки они пытаются написать свою программу и в итоге у нас на ну не на рынке на комьюнити очень много инструментов которыми можно пользоваться для работы со статистикой и в одних инструментах есть одни возможности в других инструментах нет возможно нет других возможностей либо есть какие-то новые возможности и возникает ситуация что нужно использовать два три инструмента 4 которые друг друга перекрывают и обладают какими-то разными функциями это проблема вот этот зоопарк это очень неприятно и что из этого следует важно уметь брать статистику напрямую чтобы не зависеть от программ либо как-то самому можно было улучшить эти программы добавить какие-то новые функции чтобы получить свою выгоду и нужны базовые знания sql то есть чтобы получить какие-то данные статистики нужно составить запросы sql то есть вам нужно знать там как составляются select и join и вот всякие такие вещи идем дальше статистика предлагает нам несколько вещей первое это их можно разделить на категории первая категория до события происходящие в базе когда в базе происходит какое-то событие там запрос обращение к таблице автово камстри делился commit иди блоки это все событие соответствующие счетчики инкремента ца и мы можем отследить эти события свойства объектов таких как таблице базы у них есть свойство это размер таблиц да мы можем отследить рост таблиц рост индексов изменения в динамике и третья категория это время затраченное на событие запрос это событие у него есть своя конкретно мира длительности здесь запустился тут закончился можем это отследить либо время чтения блока с диска или записи блока такие вещи тоже отслеживаются источники статистике представлены следующим образом в шаре тной памяти до блок памяти который отдан под гришу для размещения там данных там есть счетчики которые постоянно им кременец а когда происходят те или иные события или какие-то от возникают момент вот в работе базы все эти счетчики они не доступны пользователю недоступны администратору это низкого уровня и такие вещи чтобы к ним как-то обратиться в тот лес не доставляет функции мы можем выбрать там selecta функция и получить какую-то метрику однако использовать эти функции не всегда удобно поэтому функции представлены в виде представлений это такие виртуальные таблицы которые предоставляют статистику по какому-то конкретному какой-то конкретной по системе и упал кому-то там набору событий в базе данных и есть встроенное представление да вы установили под гриль запустили вы можете сразу ими пользоваться смотреть брать и туда информацию и есть кантри бы contigo и есть официальные да то есть вы как пакеты вы установили подгрузили его в конфигурации указали для него параметры перезапустили под grease можете пользоваться есть неофициальные кантри бы они не поставляются в стандартной поставке под gresso их нужно там либо скомпилировать либо там подсунуть библиотеку то есть там варианты могут быть самые разные и зависят того что придумал разработчик этого неофициального кантри во источники статистике вот я вам показываю сети view heroes и но части функции которые доступны как мы видим их очень много и ну довольно легко запутаться если вы столкнулись с этим в первый раз однако если мы возьмем предыдущую картинку до где время как тратится время на поскрести совместимого с этим вот списком то получим вот такую статистику каждую вьюгу либо каждую функцию мы можем использовать в тех или иных целях для получения соответствующей статистике когда у нас работает под grease и получить уже эту информацию о работе подсистемы картинка это потом еще появится дальше поэтому вы можете ее не фотографировать первое что мы рассмотрим это пиджи стадо the bass да как мы видим это вот вьеха в ней очень много информации то есть самая разнообразная информация и она даёт очень такое полезное знание что у нас происходит в базе данных что мы можем полезное оттуда взять начнем самых простых вещей в начале презентации там была короткая ссылка вы по сути можете открыть эту с руку там презентация и можете с этой презентации копировать запросы и вставлять там и смотреть что у вас там в базе происходит итак первое что мы можем посмотреть это процент попадания в кэш процент попадания в кэш это такая полезная метрика она позволяет оценить насколько у нас данные берутся из кэша из оперативной памяти либо они берутся с диска понятно что чем больше у нас попадание в качестве лучше мы оцениваем вот эту метрику как процент и соответственно если у нас процентное отношение от этих попаданий в кэш больше 90 процентов это хорошо если она уже опускается ниже 90 процентов значит нас памяти недостаточно для удержания от горячей головы и от данных в памяти и чтобы эти данные как-то подтянуть розыгрыш вынужден обращаться к риску и это замедляет работу и соответственно нужно уже думать над увеличением памяти либо как-то там шарик с увеличивать либо наращивать железную памяти идем дальше что можно еще взять из этой вьюки можно посмотреть там аномалии происходящие в базе что здесь показана здесь есть commit и rollback и создание временных файлах их объем ты блоки и конфликты мы можем воспользоваться этим запросам это scoin такое довольно простой и можем посмотреть вот эти вот данные у себя и вот сразу пороговое значение если у нас мы смотрим соотношении к метафоре бкк мид это успешное подтверждение транзакции rollback это откат то есть транзакция делала какую-то работу напрягало базу что там считала произошёл сбой и и результаты транзакции отбрасываются количество румбиков постоянно увеличивающаяся это плохо и следует как-то избегать их и править код чтобы такого не происходило конфликты они связаны с репликации и их тоже следует избегать если у вас есть какие-то запросы которые выполняются на реплики и возникают конфликты нужно эти конфликты разбирать смотри что происходит это обычно делается в логах и устранять конфликтные ситуации чтобы ошибок приложению не возвращалась get lucky тоже плохая ситуация там когда запросы борятся за ресурсы один запрос обратился 2 запросу обратился к одному ресурсу и они друг друга заблокировали это тоже проблемная ситуация их нужно решать на уровне переписывания приложений и если вы видите что вас за блоки там увеличиваются постоянно да то есть нужно разбирать эти кейсы и смотреть в чем проблема темпа вы и файлы временные это тоже плохо когда вас грязцова мука никто не хватает памяти для оперативных временных данных он создает диск на диске файл и начинает все там операции выполнять уже на диске это медленно это замедляет работу разрисовывать коннектор и клиент подключившись к по адресу он просто получит более дольше ответ если эти все операции будут выполняться в памяти он ответ получить гораздо быстрее и клиенту на будет меньше ждать идем дальше от бега вы райтера это представление описывает работу двух фоновых подсистем под гриль so check point р и фоновые писатели что мы можем здесь взять для начала разберем чекпоинты что такое чекпоинт check point это грубо говоря сброс и грязных страниц жареной памяти на диск для чего это нужно если вы под крис все время обращался виску и брала туда данные записывал туда данные при каждом обращении это было бы медленно поэтому под криса есть большой объем памяти ну зависит от вызванных параметров конфигурации он эти данные о он это область использует для помещения туда данных до потом как-то их там меняет и мы получаем две версии данных 1 нас в памяти и 1 у нас на диске и периодически нам нужно эти данные синхронизировать нам нужно то что изменено в памяти синхронизировать на диск для этого нужны чекпоинты чекпоинт просто проходит по шариату фирс помечает грязные странице что они нужны для чекпоинта потом запускает второй проход по шарит майерс и страницы которые помечены для чекпоинта олег уже синхронизирует таким образом выполняется синхронизация данных уже с диском и чекпоинта есть 21 chic white выполняется по таймауту это полезный чик воин тут чекпоинт тайма то есть чекпоинт по так скажем принуждению recovered чекпоинт это когда у нас идет большая очень большая запись данных мы записали очень много журналов транзакций и под grease считает что ему нужно уже все это как можно быстрее синхронизировать сделать контрольную точку и жить дальше и если вы посмотрели статистику быкова райтера и увидели что was recovered чек-поинтов гораздо больше чем тайма там то это плохо почему плохо это значит что поверх находится в постоянной и такой стрессовой ситуации когда ему нужно записывать данные chic white по тайм аута он растянуто по времени и упал gresso есть возможность сделать паузу в работе и не напрягать дисковую подсистему это для подкаста полезно и запросы которые выполняются во время чекпоинта не будут испытывать стресс а от того что дисковая подсистема занята и вот для регулировки чек-поинтов есть три параметра чекпоинт сегменты чекпоинт ремоут река птичий таргет они позволяют как бы регулировать работу чекпоинта не буду на них задержатся их влияние как бы уже это другая такая тема кому интересно могут подойти на наш стенд и поинтересоваться следующая по системы the background в райтер что не делает он работает постоянно в бесконечном цикле scanid шарит мою память и страничке которая нашел грязная он их сбрасывает на диск то есть он помогает чекпоинт делать меньше работы и для чего он еще нужен он обеспечивает backend клиентские подключения чистыми страницами когда клинское выключение запросила новые данные у него есть чистая страницы ему не надо не надо самому ничего чистить он берет эти страницы и пользуются если вы видите что у вас параметр макс фрай think when большой это значит бэкграунд в raider не справляется со своей работой и нужно увеличивать параметры макс пейджер чтобы он мог за один цикл работы сделать еще работы больше очистить страничек и другой очень приятный такой показатель это пор за backend осинка бренды они не делают в senki потому что это медленно они передают их senki выше просто кучек по интеру типа интера есть своя очередь он периодически этих senki обрабатывает из и файлы синхронизируют если очередь и простая о большая чекпоинты roi заполнено the back and вынужден сам делать sing и это замедляет работу бэг-энда то есть клиент получит ответ позже чем мог бы если вы видите что as the значение больше нуля это уже плохо и нужно следить за оптимизировать но оптимизировать дисковую подсистему идем дальше репликация тут тоже нас много параметров но понадобится нам всего лишь пункты связанные с логичным если мы видим что все значения равны это идеальный вариант значит у нас реплика не отстаёт от мастера это прекрасно а вот это вот позиция 16-ричной а эта позиция в журнале транзакций а постоянно увеличивается если выбрать здесь какая-то активность insert и delete и так далее если эти вещи отличаются значит есть какой-то лак лак это отставание мастер от реплики то есть данные отличаются между серверами лак есть три причины отставания это дисковая подсистема не справляется с записью синхронизации файлов это сеть ошибки возможны и сети либо перегрузка сети когда данные не успевают доезжать до реплики и он не может их воспроизвести и процессором процессор это очень редкий случай и я видела своей памяти всего два или три раза но такое тоже может быть и вот три запросы которые нам позволяют использовать статистику мы можем оценить сколько записано у нас журнала транзакций есть такая функция как слог allocation div и можем оценить лак репликации в байтах и секундах тоже мы используем значения из этой view him слогам репликации есть один в секундах который лака с ним есть один момент если на мастере не происходит никакой активности да транзакция была где-то там 15 минут назад и активности никакой нет если мы на реплики посмотрим этот лак то мы увидим лак 15 секунд об этом стоит помнить и это может вводить в стопор там когда вы посмотрели этот лак идем дальше ппс tattletail это тоже такая полезная вьеха она показывает статистику по таблицам когда у нас в базе есть таблицы с ними есть какая-то активность какие-то действия мы можем эту информацию получить вот из этой вики первое что мы можем посмотреть это последовательные проходы последование сканирование по таблице само число последовать их проходов еще не обязательно плохо и не показатель того что нам уже нужно что-то там делать однако есть 2 метрика секта притон количество строк возвращённых в результате последовательного сканирования если среднее число усредненная до превышает уже тысячу 10000 там 50100 тысяч до это уже такой показатель что возможно вам нужно где-то построить индекс чтобы обращение были по индексу либо оптимизировать запросы чтобы такого не было но простой пример допустим а вслед за большим там количеством да и лимиты то есть мы берем там сканируем 100 тысяч строк в таблице и после этого берем там 50 строк это как бы тоже плохой такой кейс и такие запросы нужно оптимизировать и вот здесь вот простой такое школьный запрос которым можно это посмотреть и оценить примерные цифры идем дальше размеры таблиц также можно получить с помощью этой таблицы и с помощью дополнительных функций вот total relations айс relations сайт есть мета команды dt который можно выпуск выпустить в sql в происходит и посмотреть размеры однако использование функции помогает нам посмотреть еще размеры таблиц с учетом индексом либо без учета на индексов и уже делать какие то оценки на основе роста базы данных до как она у нас растет с какой интенсивностью и делать уже какие-то мысли об оптимизации размера в райт activity активность на запись что такое запись запись это вот я написал апдейт это операция обновления в баню в таблице на либо этот велит по сути апдейт это две операции эта вставка новой версии строки и пометка старой версии строки как неиспользуемая впоследствии придет of the vacuum и вот эти вот неиспользуемые строки он вычистит память это место как доступна для повторного использования кроме того апдейт это не только обновление таблицы это еще обновление индексов если у вас на таблица много индексов да то приобретите все индексы которые в которых участок поля обновляемые в запросе эти все индексы тоже нужно будет перестроить в этих индексах также просто мертвые строки которые нужно будет почистить и апдейты этот тяжеловес на такие операции но их можно облегчить есть так называемая ход апдейты они появились возрасте версии 83 и что такое это легковесный объект который не вызывает перестроение индексов то есть мы обновили запись но при этом обновилась только запись в страничке а индексы по-прежнему указывают на то же самую записи на странице там немного такая интересная логика работой когда приходит вакуум он просто эти цепочки ход перестраивает и все продолжает работать так без обновления индексов и очень легковесно то есть мы обновлены делаем такие легковесное обновление и когда у вас вот and обход об большое это очень хорошо это значит у легковесные апдейты апдейты проходит гораздо легче для таблиц и все прекрасно как увеличить этот ход рейд да как увеличить объем от этих от обновляемых таблиц мы можем использовать так называемый фактора он определяет размер заполнении страницы в таблице когда в таблицу этот insert и они полностью заполняют страничку да не оставляет мне пустого места потом выделяется новая страничка снова данные за меняются и это поведение по умолчанию you фактор сто сто процентов мы можем сделать фактор например 70 до то есть при концертах выделилась новая страничка но заполнилась всего 70 процентов до 70 процентов странички и 30 процентов осталось у нас на резерв когда нужно будет сделать апдейт апдейт с высокой долей вероятности произойдет в той же самой странички и новая версия строки поместиться в ту же страничку и будет сделан ход апдейт таким образом облегчается запись на таблицах вот внизу приведена to alter ты был как вот можно задать и фактор идем дальше очередь авто вакуума of the vacuum это вообще такая подсистема по которой статистики в прорезь и очень мало мы можем в таблицах только в стад activity увидеть сколько у нас там авакумов длится сейчас на данный момент однако понять сколько таблиц в очереди у него так вот сходу очень сложно мы можем использовать вот такой упрощённый запрос и посмотреть когда таблицы над ним над ними должен быть сделан вакуум как три годится лаком подойдет мертвые строки о которых я говорил раньше до обитает произошел новая версия строки вставилась появилась мертвая строка таблицы пгс that user тейлз есть такой параметр ended up он показывает нас количество этих самых и мертвых строк и как только количество мёртвых строк стало больше чем определенный порог таблица клей придет вакуум и как рассчитывается этот порог то есть это процентное отношение от общего числа строк в таблице есть параметр of the vacuum vacuum скилл факторов вот он определяет нас процентное отношение допустим 10 процентов плюс там есть базовый порог 50 строк и что получается когда у нас мертвых строк стало больше десяти процентов от таблицы да и он превышает этот раз hold the мы с aim of the vacuum таблицу на авто лаком однако тут есть один такой момент вот эти параметры базовый порог ps3 с hold и скилл фактор они могут на таблицу назначаться индивидуально и соответственно порог будет не овощ ip-адреса вайда такой не глобальный а индивидуальной для таблицы и поэтому чтобы рассчитать там нужно использовать некоторые такие ощущения уловки и если вам интересно вы можете посмотреть на опыт наших коллег и за это они написали для манин для мунина плагин который учитывает эти вещи там такая портянка на два листа вот но считает он корректно и довольно эффективно позволяет оценить где у нас вакуума много требуется для таблиц где мало что можем с этим сделать если у нас очень большая в два помидора является мы можем поднять количества маркеров вакуума либо просто сделать вакуум агрессивнее чтобы он 3 делился раньше обрабатывал таблицу маленькими кусочками и тем самым просто уменьшал очередь будет уменьшаться идем дальше приказ total индекса это статистика по индексам она небольшая и мы можем по ней получить информацию по индексам сканированием и определить какие индекс у нас лишние как я уже говорил апдейты это не только обновление таблицы это еще и обновления индексов соответственно если у нас на таблица много индексов их нужно обновить если у нас есть неиспользуемые индексы да по которым нет яндекс их сканирований они у нас висят балластом и и от них нужно избавляться для этого нам нужно поле индекс как мы просто смотрим количество индексах сканирований если у нас там за промежуток времени большой ноль то это плохие индексы нам нужно от них избавиться и две ссылки есть это значит примеры запросов для того как искать неиспользуемые индексы вторая ссылка это довольно таки такой интересный запрос там очень такая крутая логика заложено от рекомендую его для ознакомления и так что у нас еще стоит это тоже медленный не используем индексы это плохо занимают места замедляют операции обновления и лишняя работа для вакуума если мы их спилим то мы сделаем базе только лучше следующая view х это pg startactivity это аналог ps а только в воскресе если ps сам вы смотрите процессы в операционной системе то при красота кейти вам покажет backend и внутри прогресса что мы можем оттуда полезного взять мы можем посмотреть общую активность что происходит в базе сделали новый диплом у нас там все взорвалось connect и новые не принимаются ошибки сыпятся в приложении мы можем выполнить вот такой запрос посмотреть общий процент подключения и посмотреть кто у нас занимает больше всего коннектов вот в данном приведенном случае мы видим что юзер кроме роли открыл 508 коннектов что-то видимость им там произошло нужно с этим разбираться и смотреть и вполне возможно что это какое-то аномальное число подключений долгие запросы это если у нас нагрузка в лтп до запросу должны выполняться быстро очень быстро и должно быть все хорошо однако если возникают долгие запросы в краткосрочной перспективе ничего страшного нету но в долгосрочной перспективе они вредят базе они увеличивают плод таблиц так называемый когда у нас фрагментация таблица увеличивается и от него нужно избавляться от этого болота и от самих таких вредных запросов вот обратите внимание вот таким запросам мы можем определять долгие транзакции мы используем функцию клок time stamp для определения времени работы и запросы которые мы нашли мы можем их заполнить запомнить выполнить explain посмотреть планы как-то оптимизировать а текущие запросто долгие мы их отстреливаем и как бы дальше живем плохие транзакции это транзакции в состоянии и дылым transaction и idle introduction aborted что это значит транзакции они имеют несколько состояний и одно из этих состояний могут принимать в любой момент времени для определения состояния есть cola более state да в этой вики и мы используем его для определения состояния и вот как я уже сказал выше эти два состояния это плохо что это такое это когда кот открыл транзакцию сделал какие то действия и ушёл по своим делам транзакция осталось открытая она висит она ничего не делает она занимает connect и потенциально еще увеличивает blot то других таблиц потому что там есть накладные расходы на транзакционному движке и такие транзакции тоже следуют отстреливать потому что они вредны и в долгосрочной перспективе если вы видите у вас в базе больше там 5 10 20 то нужно уже беспокоиться и начинать с ними что-то сделать здесь мы также для времени вычисления используем блок timestamp транзакции отстреливаем приложение оптимизируем блокировки как я уже говорил выше блокировки это когда три и больше транзакций борется за один ресурс ну или за группу ресурсов для этого у нас есть поле вейпинг с болевым значением true false true значит что процесс находится в ожидании нужно что то делать когда процесс находится в ожидании значит клиент который инициировал этот процесс он тоже ждет клиент в браузере сидит он тоже ждет и негодует что делать если вы видите true значит нужно как-то от них избавляться мы просто такие транзакции отстреливаем разработчикам пишем что вот у вас нужно как-то оптимизировать чтобы не было этой гонке за ресурсов и дальше разработчики уже оптимизирует приложения чтобы такого не возникало и крайний случай это возникновение для блоков 2 транзакции обновили 2 ресурса потом обращается к ним снова уже противоположным ресурсам да вот здесь в этом случае просто берет сам отстреливает транзакцию бы другая могла продолжить работу это тупиковая ситуация и она как бы сама ни разу не разбирается поэтому пузырь из вынужден принимать крайние меры и вот два запроса которые позволяют отслеживать блокировки мы используем youtube epilox которая позволяет отслеживать идет тяжеловесные локи про которых говорил или носа и первая ссылка это сам текст запроса он довольно таки длины и вторая ссылка это вообще статья по лаком и и полезно почитать она очень интересная и так что мы видим мы видим два запроса alter ты был до это блокирующий дискурс он как раз у нас пошел из транзакции и где-то занимается своими делами и второй запрос апдейт он значит ждет когда закончится alter ты был чтобы продолжить свою работу так вот мы можем выяснить кто кого там залочим держит и разбираться с этим дальше следующий модуль это пгс the statements как я уже сказал это модуль чтобы им воспользоваться нужно погрузить его в конфигурацию или запросить ip-адрес и дальше уже у нас появится в ухо для использования что можем оттуда взять если говорить о простых вещах мы можем взять средние время выполнения запроса да это как средний температура по больнице время растет значит у нас процесс отвечает медленно нужно что то делать можем посмотреть самое активное пишущие транзакции в базе данных до который меняет данные в атмосферах посмотреть что у нас там об этих билетик вот и просто посмотреть статистику по этим запросам мы же погас the statements используем для построения отчетов мы каждый раз в сутки сбрасываем статистику накапливаемые и перед сбросом статистике сколько сейчас следующий раз считаем отчет строим о чем что мы делаем мы вот ссылка на отчеты от приведена вы можете посмотреть там даже такая портянка на 3 игра что мы делаем мы используем мы агрегирует до сунул свой и подсчитываем общую статистику и затем для каждого запроса мы считаем этот индивидуальный вклад и что мы можем посмотреть мы можем посмотреть общее время выполнения этого запроса на фоне общей статистике посмотреть использование ресурсов процессора и ввода-вывода относительно тоже общей картины и уже оптимизировать эти запросы мы просто строим топ запросов по этому отчету и уже получаем пищу для разрешения что оптимизировать что у нас осталось за кадром осталось несколько вьеха которые вот я не стала рассматривать потому что время уже ограничено есть bg 100 табл это тоже контрит он позволяет оценить blood таблиц до фрагментацию таблицы и если фрагментация большая нужно значит фрагментацию выбирать использовать разные инструменты и функция красота была на работает долго и чем больше таблица тем больше она будет работать следующий кантри это pgpr кэш он позволяет проводить инспекцию шарит буферов какие вчера у нас используются какие нет и просто позволяет заглянуть шарик байерс и оценить происходящее там следующий модуль это fincord он позволяет проводить низкоуровневая операции с таблицами через системный вызов линкоры то есть он позволяет загрузить таблицам жареные буфера либо ее выгрузить и позволяет помимо прочего проводить инспекцию страничного кэша операционной системы то насколько у нас таблица висит в прыжке she в аридных буферах и просто позволяет оценить загруженность таблицы следующий модуль остатка кэш он также используя системный вызов и вешает его перед выполнением заброса и после выполнения запроса и смотрит полученные метрики сколько у нас запрос затратил на выполнение на свое дискового ввода-вывода там операции с файловой системой и использование процессора однако модуль молодой и для своей работы он требует после 94 и пгс that statement о котором я говорил ранее и уже конец доклада вот резюме умение пользоваться статистикой полезно вам не нужны всякие программы вы можете сами заглянуть посмотреть что-то сделать выполнить после со статистикой не сложно это обычная ce que el вы собрали запрос там составили отправили посмотрели и статистика помогает ответить на вопросы у вас возникают вопросы вы обращаетесь статистике смотрите делайте выводы анализируйте результаты отлично и экспериментируйте запросов много данных много всегда можно оптимизировать какой-то уже существующей запрос сделать свою версию запроса которая подходит вам больше чем оригинал использовать его годные ссылки которые встречались статьи по материалам которые были в докладе и от два блока 1 на английском один на русском если вам что-то хочется прочитать из моего творчества вот добро пожаловать и на этом все спасибо можете задавать вопросы так сейчас я думаю что в году обеда"
}