{
  "video_id": "wbIpn44Z2_8",
  "channel": "HighLoadChannel",
  "title": "Опыт создания резервного и кластеризованного Zabbix-сервиса / Михаил Макуров (Интерсвязь)",
  "views": 2291,
  "duration": 2574,
  "published": "2019-12-05T12:56:07-08:00",
  "text": "я работаю в компании провайдере провайдер называется интерсвязь работает в городе челябинск у нас примерно полтора миллиона человек и для того чтоб правой доработал есть огромное количество инфраструктуры у нас это примерно 70 тысяч единиц оборудования это коммутаторы и вот устройство много всего того что нужно мониторить то есть мы но конкретно этот рассказ и доклад сегодня про использование zabbix а про построения кластера на основе zabbix а для инфраструктурного мониторинга примерно еще немножко про себя я 12 лет работаю в провайдере на самом деле сейчас я не совсем техническими вещами занимаюсь больше управлением людьми вот это все сегодня это на самом деле моё хобби я там немножко тему разовью и мне я считаю повезло примерно полтора года назад я оказался в проекте который звучал так нужно решить некоторые проблемы с нашим мониторингом я получил в наследство так можно сказать зону ответственности мониторинга которая состояла из кучи серверов конкретно из двадцати одного сервера на 4 был и мощных сервера и 15 прокси это все было аппаратная и ну к этому мониторингу были некоторые претензии первое претензии было того что это было много нас ни один другой сервису провайдеры не занимал столько места но это деньги электричество это на самом деле не большая проблема большая проблема была в том что мониторинг не успевал затем сколько мы от него хотели на вот кто активно за лексом не пользовался значит скажу это дашборд который показывает опоздание по проверкам да у нас большинство проверок сидела в красной зоне то есть они выполнялись больше чем на 10 минут медленнее чем мы хотели то все позволено 10 минут это было не очень приятно жить еще будет более-менее было можно самая большая проблема была вот это это была система мониторинга за делать это была система мониторинга исправно работающий сети когда делались плановые работы отваливался сегмент отлично опять допустим коммутаторов вместе с этими коммутаторами в небытии уходил мониторинг когда все восстанавливалась чесать эти двое мониторинг восстанавливался это было больно неприятно и вот эта фраза которая должна быть каждом lac la dee da тогда что-то с этим проектом нужно было делать и здесь я для историю расскажу мы тогда попробовали пути пойти одновременно двумя путями у нас есть такая группа интеграции они избрали путь построения модульной системы вот был очень классный доклад если я помню а то вид она highload в ноябре в москве в ноябре прошлого года они примерно про это рассказывали то есть ребята из маленьких кусочков стали строить систему вот а я там с несколькими энтузиастами мы продолжили заниматься забег сам были на то причины значит какие причины во первых есть классные пиаре и когда у тебя есть 60 70 тысяч элементов мониторинга понятно что это все работает только автоматически то есть в руками столько не добавить без ошибок второе это кадры то есть есть дежурные смены мониторинга который сидят 247 это не а хищники это ради жены и люди их переучивать то есть мы показывали допустим графа ну какие-то другие системы им тяжело вот есть админы которые привыкли к разнообразию удобству мониторинга в самом за биг си то есть шаблоны автообнаружения это все клево но и чуть позже расскажу общем-то zabbix может быть эффективным ну поехали первая причина была очевидно мы тогда работали на майский эли и мы упирались примерно в шесть семь тысяч это река секунду видели постоянные задержки на дисках ну вот сегодня это звучало уже сто раз очень ответ один клик house да то есть структуре запросов основную часть запросов составляют наш наши там профайлинг за несколько часов запись метрик писать метрики вы спеть базу крайне дорого ну time scale деби появился наверное если бы вот я думаю если бы доклад андрея был вот год назад ничего этого бы не было да вот тогда у нас в эксплуатации был treehouse примерно год по другие задачи мы там занимаемся back to the big big диеты у нас большое приложение там общем провайдер это такой щас целый эти бизнес и посмотрел всякие красивые графики из интернета что клика us сотни раз быстрее что ему надо очень мало места имея текущий опыт мы просто написали свой history сторож модуль для язык для zabbix а чтобы он мог сохранять данные в house напрямую то есть не из экспорта файлов прямо на лету и более того мы написали тоже модуль для фронта то есть вот эти все красивые графики прям админке за писанины сколько усы могут строиться ну понятно что это это же работает эффект примерно такой sql-сервера как отдельные сущности не стало совсем то есть загрузка упала в ноль что самая примечательная у нас был уже выделенный cliff house кластер когда мы туда подали всю нашу нагрузку она там 6000 метров до 10000 увеличилась ребята кто занимается администрированием сказали мы что-то вообще не видим что пришло вот ну нету я скажу даже дальше для тестов мы пробовали подавать нагрузки это примерно до 140 150000 метрика секунду больше мы не смогли zabbix а выжить и тоже расскажу почему и этой нагрузки тоже кликала не видит то есть это очень комфортная классная нагрузка в общем вот есть такой модуль кроме того мы его немножко расширили в этой версии в нашей версии можно выключить на секунды вы наверняка знаете zabbix пишет и пишет секунды нам на секунду двумя полями при хаусе поля в которых вариативность очень большая занимают много места вот кстати про место одна метрика в клика выси вот сейчас у нас примерно 700 миллиардов метрик записано занимает 2,9 байта по документации запись со одна метрика в sql базах занимает от 40 до 100 байт вот выключение наносекунд дает экономии еще 40 процентов то есть примерно полтора байта на метрику то есть клика ас очень эффективен с точки зрения место по просьбе наших ребят которые занимаются машинным обучением мы сделали опцию чтобы можно было писать хост и имя метрики так как вариативность данных большая долгими тестами правда не проверили еще это занимает немного места дополнительного несмотря на то что текстовые данные могут быть значительные плюс сделали два дополнения так как мы develop или забег всего часто приходилось дергать значит очень прикольно и добавление выполнения на старте так и house позволяет очень быстро читать миллионы записей мы можем заполнить кэш истории да то есть мы на старте задерживаемся на лишние 30 40 секунд зато получаем сразу запущенный сервер с прогретым кэшем нам случаях когда допустим проще с инфраструктурой качество брать есть еще такое опция тоже написали чтобы запретить чтение из кэша на какое то время то есть лучше пять минут быстро проработать не считая триггеры да а потом конечно полнится есть просто этого не делать начинается стагнация history singer of в общем есть модуль crack house а сегодня кто-то спрашивал вот он есть его можно использовать дальше несмотря на то что мы решили тогда проблемы с базой тормоза и проблема с 15 практике все равно осталось связано было с чем это основной pipeline обработки данных за биг си то есть этап сбора данных есть три processing значит и есть чем триггер history синкер и которые делают общем-то всю работу это общее триггеров лет кинг сохранения в хистори самое узкое место оказалось кэш конфигурации по расследованию почему тормозит полинга потому что треды которые делают запросы они за единичными метриками ходят в очередь в кэш конфигурации его блочат вот есть другие места но они не такие узкие например есть сам при processing есть history кэш на нашем скайлер значит вот у меня цифры другие вот все сегодня андрей рассказывал там него были цифры большие мы получили вот такие примерно ограничения возможно по связано с тем что в нашем случае мы база наша составляет примерно 5 миллионов метрик которые мы снимаем в со всеми оптимизация my которые мы делали мы смогли получить 70000 метрик в самом узком месте да и то на конфигурация каши но только в случае когда мы их обрабатывали массово начал такую массу обработка полер идет в configuration кэш и берет задание не на одном метре куда она 4 на 8 тысяч и при этом он получает еще одну замечательную возможность он может делать теперь полинка синхронно давно потому что он получил 4 тысячи метрик человек одна за другой делать можно сразу все спросить для основных типов которые используются провайдер это snmp agent мы переписали полинг на асинхронный режим и агрегативной это дало примерно прирост скорости от 100 до 200 раз то есть вот у нас было 15 прокси мы разделили на на 150 и в общем них не осталось совсем ну и в итоге вот это все превратилась вот в две банки только которые для резерва нужны причем загрузка банки 1 процессор на там один xeon 1280 street загружен это отдел тайн иначе это загружено примерно на 60 60 процентов процессора свободно а вот этот звон от 60 до 40 это запускаем ее периодически скрипты на самой машине то есть external script но там их можно по оптимизировать общем пока проблема не создают скейл примерно вот такой то есть это 62 1000 хостов около пяти миллионов метрик текущая наша потребность примерно 20 тысяч метров секунду начал вроде все то есть проблемы с производительностью решили history рашили полинг у нас классный проблема решена но не совсем да все было бы слишком просто я немножко слукавил на предыдущем графике его не весь показал есть 2 проблемы вот вы ческой дураки и дороги до есть человеческий фактор есть оборудование значит 1 серверов все-таки мало за примерно год эксплуатации было два случая у нас с аппаратными проблемами это ssd диск и я не помню что и больше всего составляет проблем человеческий фактор когда люди делают какие-то проверки у нас в компании zabbix используется как сервис то и все подразделения могут нам что-то свое писать хотелось бы расширение да то есть хотелось бы не зависеть от одной банки хотелось бы чтобы ну нагрyзки лица еще сильнее и причем хотелось бы чтобы можно было стелется по принципу скилл out то есть тут даже обсуждать нечего то есть расти повышая мощность одной банки это сейчас ну 10 лет уже как некоторые 20 лет как не актуально вот ну то есть просился кластер где-то в декабре появилась первая версия атомарная единица кластер а то есть то что обрабатывается на отдельном посте был выбран хост дело в том что за биг си есть достаточно сильные связи между этим ими которые могут быть на одном посте то есть могут быть связаны и триггер и они могут быть в при процессинге вместе обрабатываться а вот между кастами связанность уже не очень большая поэтому это норм для того чтобы эту связанности делать использовать между нодами их мастера много трафика там не будет вот то есть основная задача кластер это договориться между собой кто какими хостами занимается хотелось обойти наш этот максимально ли миф 60 70 тысяч метрик потому что аппетит приходит во время еды и нас сразу ребята которые занимаются к и а какое то quality of experience дать то есть анализ того как интернет работают в абонентов на основе транзитных метрик дат оставляете все тыс и предмет реки полутора миллиона человек ведь мониторинг то есть там много данных вот на и хотелось надежности да то есть хотелось чтобы если что-то случилось там позвонил дежурный смена сказал что у нас проблемы сервер омска это выключи ты его утром разберемся первый кластер первая версия была реализована на становитесь иди иди себе это распределенная key value хранилища используется в многих прогрессивных проектов насколько я понимаю в кабинет усе все было классно работает на 4 сити дает очень интересные инструменты например возможности решает проблему такую как выборы основного сервера но такая проблемка вот у нас была классическая троценко zabbix ада то есть либо база ну сам сервер а мы добавили дальше клик хауса теперь мы еще и 10 добавили и ну админы что так стали писать заголовки ну что-то многовато до зависимости наверно это будет ненадежно вот ну и в процессе развития на самом деле выяснилось еще одна вещь оказывается но не оказывается она там всегда было общим записи в самом есть уже встроенный способ вместе раваной коммуникации просто он используется между сервером и прокси это так называемый процесс прокси полер вот но он вполне классно подходят для мести рваной коммуникации с минимальными изменениями это позволило эти сиди не использовать по крайней мере временно очень сильно упростить код самое главное работать на коде который выверен уже то мне кажется ему лет пять или семь этом году потому что прокси это все там давно старую как сервера координируется в кластере во первых вот я там написал координация сделана по принципу ну что-то типа джипе протокола то есть для того чтобы сервера могли иметь приоритет я скажу зачем это надо и для того чтобы можно было избавиться от конфликтов в гель базе при записи так называемых логов каждому серверу присваивается индекс пока вручную индификатор прошу прощения это число от 0 до 63 нож театре это просто константа может быть больше сервер с максимальным идентификатором становится мастером и когда у кого ни будь появится распределенные кластера на потому что когда мы у себя запустили первый тест кластер во первых что сказали наши админы wow а давайте мы их на разных площадках постоянно здорово к этому еще вернемся можно будет управлять тем как будет перераспределяться топология куда будет уходить роль мастера случае падения основного zabbix сервера на то есть в данном случае вот так ну и плюс t пинг до записи исконно то есть это сделано в оригинальном за биг си так генерацией автоинкремент ных индексов занимается сам сервер чтобы много инстансов друг другу не наступали на пятки да то есть там не создавали logis 1алексей одинаковыми индексами используется степпинг ну я думаю понятно что такое то есть zabbix с идентификатором один будет генерировать кратные там условно примитивно говоря единицы то есть один 1121 с идентификатором 77 1727 там с нюансами нефиг татарами проехали как взаимодействуют между собой но это наследия и джипе да то есть есть привет пакеты каждые пять секунд так сильвера знаю что в них есть соседи так мастер знает что есть соседи рядом и на основе этого мастер решает кому каким севером сейчас можно раздать каких аст и соответственно есть конфигурация какой-то старой памяти и называют апология топология это по сути список серверов и холстов которым относятся протокол в простой это джейсон это тоже наследие коммуникации zabbix прокси и забег сервера ну в общем нет смысла использовать что-то другое единственное что ты че за пицца там есть четыре байта там zabbix что-то не суть важно follow пакете передаются идентификатор сервера то есть когда сервер посылает пакет он говорит свой идентификатор свой версии топология ну таким образом фермера очень быстро узнают что есть новая версия топологии и очень быстро обновляются пни ну и собственно сама топологии это просто дерево список серверов и для каждого сервера список ростов которые он поддерживает а дальше возникает интересная проблема ответом на эту проблему и вот есть такая магическая фраза доменный мониторингов значит в чем суть в классическом за пикси у нас все было просто было однозначное отношение этот хвост мониторится этим прокси этот прокси дает данные серверу либо если прокси не был установлен ну или там если прокси не нужны то эти сервер мониторил все хосты а когда у нас много серверов чего делать тем более может быть проблема с тем что нас географически распределенные сервера и ну скажем так сервер в каком-нибудь медленно работающим офисе в кемерово начнет попыток питаться там мониторе всю инфраструктуру новосибирском этого не хотим да то есть мы хотим иметь некий механизм чтобы не все сервера а выбранные нами возможно по географическому признаку могли мониторить какой-то конкретный хост но при этом мы хотим управлять этим да и мы хотим чтобы это была просто вот для этого была придумана идея доменов мониторинга по сути это простые группы просто записи уже есть группы и когда вот я это делал и мы с ребятами с эксплуатации разговаривали они сказали не группы нас путают очень сильно мы всегда начинаем думать про нормальной группы поэтому вот такое название домена мониторинг она хасты однозначно относятся один хвост один домен а в один домен может ходить любое количество серверов сервера могут ходить любое количество доменов это весьма гибкая штука ну и плюс чтобы гибкость можно было расширить но и совсем сломать мозг еще домен по умолчанию сервера который входят элемент дефолт мониторят все хасты у которых ну либо не осталось живых серверов либо которым не присвоен домен мониторинга и так раз позволяют топологически ну во первых в нормальном режиме привязывать холсты каким-то сервером и управлять тем как распределяться хасты в случае если сервер у нас один упадет следующая проблема с которой мы столкнулись но не проблема это больше уже осознание и если вы будете думать кластер на мониторинге вообще любой классные службы но конкретно в этом случае когда у нас появляется много серверов есть появляются новые возможности по построению кластера по построению топологию вот такая классика да когда у нас есть какой-то центральной сайты есть удаленные или допустим есть прокси куда делегирована нагрузка может случае класть иного zabbix а реализовываться двояко да можно пойти классическим путем просто удвоить инфраструктуру в центре у нас два сервера которые образуют кластер и которые могут перераспределять хасты либо брать нагрузку на себя если сосед упал вот соответственно можно поднять дополнительные прокси можем на тех же серверах получим двойной резерв вот ну либо можно воспользоваться новыми фичами сделать так данным главное опять же не прийтись к ситуации когда географический удаленный сервер мониторе тонкую то большую инфраструктуру в другом месте это больше вопрос администрирования я их называют бизнесовые да потому что ну это вопрос настройки с кластером пришла еще одна интересная ситуация мы не столкнулись значит сплит бренда и point of view то есть . съема они немножко пересекаются спреды он понятно что такое то есть у вас есть два сервера отвечают за полинка одной и той же инфраструктуры когда у нас развалилась связь случилась какая-то авария как они себя будут вести ну в общем понятно что они себя будет вести так как вы настроите и про это тоже нужно заранее подумать то есть допустим подумать и не знаю сценарий разные проблема point of view она примерно такая что проверки которые зависят от топологической удалённости серверов могут давать разные результаты для одного и того же hasta потому что они далеко ну допустим это касается проверок связанных со время со скоростью доступа dap им если вы ртт меряете но разные может быть с точки зрения техники очень сделали вот такие макросы они работают на уровне элементов данных на ульт на уровне триггеров они позволяют идентифицировать откуда быть были эти данные или какой из телеграф являлся инициатором триггера ну а как интерпретировать данные что делать опять же это решаете сами то есть но когда вы знаете какой сервер допустим зафиксировал падение доступности до хоста вы знаете что делать вот теперь тема который я бы хотел рассказать больше что делать эскель базой то есть очевидно если мы разнесли кучу серверов то мы бы хотели чтобы у каждого была рядом своя база да ну то есть неправильно было бы завязывать на 1 вообще и к сожалению сейчас сказать что какое-то вот у меня есть прям готовое решение сделайте так или мы протестировали вот меня пока такого опыта нет конечно же скажу почему то есть во первых вот пока я предполагаю что если кто-то начнет тестировать и пользоваться кластером можно использовать стандартные решения допустим галеру для маски есть куча решения по асинхронной репликации для полчаса в случае забег сам это работает норм я уже сказал что индексы пересекаться не будет от того что данные немножко опоздают логе запишется чуть позже это не проблем ну да crack house понятно что он может быть класс there'sa вам при арина значит почему нет готового решения хотелось бы сначала завершить такую работу то есть у меня работа продолжается слайд уже было из общей структуры запросов есть только очень маленькая часть которая не касается истории вот из этой маленькой части подавляющее большинство запросов сейчас у нас это лаги лаги в основном формируют 3 таблицы это логирование каких то вещей которые случились с инфраструктурой то есть это таблица проблем с таблица events и по-моему эванс recovery то есть это там server service упал серьез остановился на то есть когда срабатывает тригер a few это пишется процентов 15 составляет состояние что такое состояние сектор изменение элементов инфраструктуры сервер упал или хост упал до триггер сработал zabbix записывает базу то есть он по сути хранить свое состояние в базе с одной стороны это здорово с другой стороны вот тут у меня есть что сказать на эту тему и вот совсем чуть-чуть запросов касаются загрузки и изменение конфигурации так вот хотелось бы сделать что вот значит классический zabbix данные в него добавили кликал вынесли его вынесли метрики из sql базы во первых хотелось бы за состоянием ходить в сервер это правильно потому что сейчас если вы уроните сервер пойдете через два часа откроете об админку он нам покажет какое-то состояние мониторинга это будет неправдой да это будет то что было два часа назад правильно было показать я не знаю какое состояние сети вот но если кто-то конкретно интересует можно посмотреть по истории допустим проблем элементов что там реально было второе логе просятся вынести в более дешевую систему хранения которое занимает сильно меньше диска и меньше 5 ресурсов а вот потом можно подумать что делать потому что ну то ли общем от эскель базы то хочется на самом деле избавиться ну посмотрим то есть сначала бы хотелось вот вынести состоянии логе в низких базы то ли она будет легко реплицируется потому что изменения очень очень мало останется то ли ее можно будет перетащите house если вдруг он допустим начнёт поддерживать и полноценное изменение и удаление данных посмотрим на этом по кластер теорию такую воду и рассказал конкретика если вы решили попробовать поставить кластеру себя чем отделать нужно поставить 2 zabbix сервер то есть именно сильный демон для кластер и появляются два новых параметра и про них рассказал это идентификатор сервера число от 0 до 63 сервисов высшим индикатором становится мастером и имя хоста имя хоста нужно для для сама идентификации сервера когда он загрузить список серверов из базы для каждого сервера нужно указать сервер айпи их в порт это нужно для того чтобы сервера могли находить друг друга эти трафик между этими серверами сервисе между этими ip-адресами портами он должен работать до каких-то дополнительных портов не требуется так как у нас работает все через стандартный прокси полер то есть стандартный trapper ловит хлор запросы ну прокси полер не цитирует трафик дальше небольшие изменения там где раньше у нас было управление про xiaomi теперь появилась панелька называются управления кластером там появилось некоторое количество новых объектов значит самое главное нужно туда зайти создать домен дефолт это я говорю про минимальную конфигурацию для теста второе завести оба сервера записать туда те самые айпи адреса порты и имена хостов которые вы задали в конфигурации они должны совпадать и значит у сервера есть там новое поле называется на домен выбрать этот дефолт в общем-то все запустить один сервер посмотреть в логах что он пишет по поводу кластер а он пишет он напишет что я тут один в поле воин теперь самый главный начнет заниматься мониторингом подождать какое-то время запустить второй сервер а не значит сначала друг друга увидят потом пройдет там некий full-time они скажут мы можем работать вместе поделят хасты между собой ну в общем наслаждаться работой ну я думаю что стоит поранят сервера смотреть как это работает в принципе на наших тестах время задержки перехода время отсутствия мониторинга случае падения одного из серверов составляют например 30 40 секунд это можно уменьшить но тогда страдает надежность коммуникация между серверами особенно если там сеть допустим ненадежны начинаются небольших зон все теперь немножко не техническая часть это все родилась и где планировалось это там как виде патчи пропихнуть вас иную ветку но по разным причинам не пошло и с апреля этого года вот ну кто-то из комьюнити подсказал а давайте мы это сделаем оркам отдельным проектом и пошло поехало и тут интересная вещь появилось какое-то количество энтузиастов которые что-то делают пилят которые настраивают диплопия сиди и которые приносят классные идеи в допустим на секунды это с комьюнити пришло в общем пока она живет как отдельный проект она обновляется пока практически автоматически до актуальной версии сейчас на 49 находится по моему четыре двойку пока не брали есть некий ровно то есть сейчас уже можно это скачивать видео debian пакетов по моему есть сборки для ubuntu я не знаю если лпм и сеть скоро будет полноценная поддержка прокси там есть некоторые заминки и touring для текущего просмотра состояния кластеров zabbix панели потому что по нашим опыту админом важно знать на каком сервере обрабатывается какой host ну чтобы начинать искать проблему потому что система новое чисто психологический факт мы поставили кластер что-то работать не так кто виноват кластер ну поэтому нужен touring нужно понимать вот но и до конца лета хотелось бы максимально вытащить все информационные потоки из sql базы которые общем а там не нужны не обязаны быть history сторож ссылки и значит вот у меня есть 40 минут поэтому еще есть пять минут я вот еще хотел запасные там свои темы обсудить во первых все что я рассказывал классно ложится в идеологию я вернусь к ссылкам потом в идеологию активного мониторинга то есть когда сервер ходит за проверками куда то что если у вас пассивный мониторинг вот у нас достаточно много такого есть проверки который допустим долго считать или когда какие-то специфичные скрипты но что-то куда-то ходят готовят данные и потом их нужно отправить на сервер и понятно что такие скрипты они не могут знать всей структуры кластера делегировать им всю базу никто не будет вот для этого сделан в класть или такой механизм чтобы переживать такие вещи вот есть сервера до к ним прибитые ну то есть мастер сервер решил какие хвосты на каком сервере обрабатываются тот случай если хост шлет принудительно данные не на свой сервер то этот сервер данные принимает обрабатывает там в стандартном за биг си есть проверка то есть они убеждаются что эти от эти метрики действительно присутствует конфигурация кэша общем делает нам некую работу проверяют их тип если все окей он эти данные уже подготовленном виде пересылают на тот сервер куда они должны быть получены так как все сервера имеют полную информацию о том где каких ест и обрабатываются это делается напрямую и на сервере финальном адресате это обрабатывается быстро уже без дополнительных проверок но тем не менее с распределением с распределением того куда какие проверки приходят нужно я думаю все но с умом к этому относиться потому что если пытаться лить 200 тысяч метров в секунду на один сервер но он просто не справится он в блокировках погибнет и маленькое изменение про прокси классический прокси до в своем значит ну ремарка пассивные прокси не поддерживаются пока и просто убрал код это связано с тем что тяжело для людей под сделать еще один механизм кто из серверов теперь будет за этот прокси отвечать активные прокси активный прокси они сами ходят на сервера и для этого есть опция сервер до стандартные прокси так вот в измененной прокси есть опции сервер и что делает такой измененный сервер он держит keepalive соединение со всеми серверами которые для него указаны спрашивает конфигурацию шлет данные на 1 на первые доступные сервер из списка вот это позволяет решить проблему допустим если у вас прокси настроенный на zabbix сервер этот забег сервер упал в класс terrace другой да ну что мне оставаться и без прокси тогда прокси просто к другому перед сыпется вот теперь точно все я возвращаюсь к ссылкам возвращать михаил ссылку спасибо огромное да для меня наслаждением было случае такого спасибо от чистого сердца практика и вручить грамоту почетные отвар примите это программного кабинета комитета и подарок проведенную работу по подготовке доклада всего большая да предстоит ответить на вопросы выбор лучше не да я запомнил иметь руку первый ряд как всегда вы побеждает иметь и кто еще вы спасибо за доклад хотел бы уточнить как обстоит дело между связями связями между сервером по какому протоколу общается если какая-то защищенность потому что вот в интернет выводить вот коммуникации между серверами не особо secure на гранта дело происходит я думаю это вот претенденту же больше вопросом и потому что в точку как это первое то что мне пошагового потому что очевидно на самом деле вот когда мы перешли к стандартной коммуникации сервера для своими раваны коммуникации унаследовали все эти фишки протокола коммуникации которые есть между сервером и прокси я уточню то есть там есть шифрование там есть сжатия данных то есть пожалуйста также через веб и все настраивается как это стандартно настраивается для элементов там для серверов и прокси все будет работать спасибо еще вопрос и кто будет следующим трензелем спасибо за доклад очень круто все и скажите и может прослушал housekeeper случае с привкусом как у вас работает значит есть ну стандартном за пикси нет интерфейса из housekeeper а в хистори интерфейс то есть сестры интерфейс не поддерживает ротацию данных настила ластик допустим не поддерживает ну может в 42 на самом деле этого есть я не смотрел но пока на 409 да ей сделать легко в новом клик хаусе есть парте цианирование хочется сделать путем оцепления устаревших партиций да понятно что на уровне отдельных айтемов ротации не будет но за биг си есть там фишка можно указать глобальные значения то есть допустим всю историю хранить не больше 90 дней вот и вот по этим глобальным значением чести все эти мы всю историю можно и это будет сделано этом есть и на гитлер будут если посмотрите есть и сюда на эту тему там хочется просто архитектурно правильно сделать то ли history интерфейс расширить чтобы это в принципе было да ну в общем не хочется оставлять технического долго но сделано будет потому что это надо надо тем более кликал стал поддерживать спасибо еще вопросы зените руку хорошо мы вручим есть еще вопрос андрей это просто а есть немного не не по поводу изменений никакого со стороны бизнеса к этому относится получается не провайдер скую работу довольно огромное проворачиваете я наверно не очень вы выразился это хобби мой брат то я на самом деле не технические специалисты а менеджер тон и вот я в свободное время занимаюсь я думал это основной деятельностью бизнес дает мне классную площадку для тестов покрасили симбиоз да да да да но это это на самом деле я очень рекомендую то есть за ним очень прикольно разгружает мозг да ну и где нибудь наконец менеджерской бы вот штуки рассказал про это прям ну когда можно переключиться от людских проблем открыть им они так классно решаются это технические проблемы тэсс программировал она работает но как тэсс программировал людей жалко так не зайдешь нужно такие продавать элиту туры для менеджеров да-да-да книг программирование софтсофт тур ещё вопросы у нас книжка классно хорошо и выбери пожалуйста лучше вот еще вопрос а если крышка нужно может быть спасибо за доклад в клик house вы через какую-то проксю пишите или in primo напрямки напрямую на самом деле унаследован тоже ну это видоизмененная history интерфейс который используется для elastix а используется карл то есть или зашли типе интерфейс zabbix лед откликалась вот там секундочку уточню я кажется говорил на самом деле вот что классно zabbix агрегирует когда большой поток история идет он агрегирует значение по тысяче метрик в одну пачку это очень классно ложится накликал ясен позвольте самбо чем у него пишет да он 11 искать запрос которые выполняются карлом типично в себе содержит 1000 метров и админы кликал со просто счастливы кого я еще не вижу просто скажите я хочу задать вопрос отлично и тогда пожалуйста вот мне кажется уже не первая книжка вот молодой человек синим человек синюю разгар по себя еще раз зовут меня юрий собственно почему задался таким вопросом когда мы что-то разносим локальных машин и это начинает как-то общаться по интернету соответственно возникает вопрос безопасности вот только и всего спасибо за вопрос пожалуйста давайте поздравим человека с этим прием и на этом программа в этом зале закончена есть вечерняя программа причем есть та часть которая организована и есть то что может сделать только вы я предлагаю в то время как вы будете общаться друг с другом подумать о том а что же интересного может и раз когда в разгар рассказывать друг другу про свои случае это скорее всего то просто вы можете сделать доклад и друг другу обсуждаю вы можете как раз найти какую-то канву программный комитет примет вашу заявку рассмотрят и поможет сделать из этого хорошего упакованный рассказ может говорить какие-то отзывы о работе с огромным пометил ну на самом деле футболка много дается то есть вот мне так повезло человек из программного комитета живет мим челябинске и highload единственная конференция которая так плотно работает с докладчиками на самом деле они мне больше такого это очень в пользу идет на самом деле и разные этапы ребята осматривают видео от но с чем я сталкивался возможно там что-то еще есть я думаю я не мог то но все папа есть они посмотрят и говорят комментарии по по слайдам очень в тему бывают то есть ну орфография пески так далее очень здорово я рекомендую попробуйте себя там типа тебя есть одна опечатка очень в тему кстати я вот это намекает на тоже сегодня будет пивная вечеринка как дата тогда мы отмотаем интересно на фронт там один из первых сайт мне кажется да заметили да хорошо и еще из вечерних активности будет игра quiz плиз чтобы на нее попасть нужно подойти к точке выдачи визиток и записаться на нее а на сегодня всё завтра жду вас в этом зале 10 утра а насколько я помню приходите берегите себя вечером завтра будет много интересного спасибо за возможность спасибо нам"
}