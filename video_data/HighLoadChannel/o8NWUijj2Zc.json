{
  "video_id": "o8NWUijj2Zc",
  "channel": "HighLoadChannel",
  "title": "Такой MySQL мне нужен самому, или Как мы докатились до multisource / Константин Рекунов (Эльдорадо)",
  "views": 1312,
  "duration": 2663,
  "published": "2021-10-04T02:01:09-07:00",
  "text": "всем привет спасибо что пришли на мой доклад несмотря на его такое странное название меня зовут константин регунов я руководитель группы эксплуатации интернет-магазина эльдорадо и сегодня я вам хочу рассказать немножко про внутренности нашего mais quel заглянуть под капот но сильно глубоко заглядывать мы не будем мы посмотрим сверху на то что там происходит поэтому не бойтесь глубоко технических терминов не будет но начнем с предыстории я к вам немного даже случайно попал мне в марте позвонили девушки с незнакомого номера я подумал что это оказались девушки и зонтика которые пригласили меня на конференцию ну начнем последние несколько лет мы распиливаем наш монолит на базе битрикса ни для кого это не секрет платформа достаточно старая и тяжелая сразу сделаю пометку такую со звездочкой когда я говорю битрикс я имею ввиду очень-очень старую версию битрикс и к современному битрикс у она может не иметь никакого отношения потому что у нас версия которой последний раз обновлялась примерно в 2012 или 13 м году где-то в этом районе это совсем не тот битрикс который сейчас и есть огромная часть которая сейчас пилится на новом стеки и так uber куча сервисов на ноде кошки и других языках но мы будем смотреть сегодня про mais quel который находится под основным монолитом на него нагрузка не падает несмотря на то что мы распиливаем потому что трафик растет спасибо пандемии в последнем году у нас там чуть ли не 100 процентный рост по онлайн продажам и перед тем как погружаться дальше поднимите пожалуйста руки те кто использует москве в продакшен отлично много людей значит точно что-то полезное для себя вынести сразу скажу что битрикс это в нашем варианте такая тяжелая система которая на одной странице без кэша может генерить сотни тысячи запросов в зависимости от того какая там сложная логика завязано это все выливается в огромный рпс на весь кластер это примерно в районе 50 fps если говорить про текущий момент времени в высокий сезон это может быть еще в два раза больше легко поэтому этот кластер мы должны очень хорошо оптимизировать поддерживать и есть еще такой нюанс у битрикса он может генерить нагрузку на чтение с мастеров потому что после любого модифицирующие во запроса он переключает поток select запросов тоже на мастер как вообще обычно масштабируется такая система когда растет нагрузка естественно добавляют слоев добавляют другой мастер активный например об чаще всего конечно это пассивный стендбай или слоев на который потом переключается мастер и остальные слои вы вот но в нашем составе был именно активный мастер мастер на каждой зоне был свой мастер и как-то у нас добавился 2 сот поскольку система высоконагруженные и постоянно должна быть доступна онлайн по 2 сот прилепили к этому мастер мастер кластеру из чего получился такой франкенштейн такой сетап в котором кольцо из четырех мастеров первый мастер пишет во второй второй мастер пишет в 3 3 мастер пишет в 4 и 4 пишет в 1 вот такой вот франкенштейн вроде бы на четырех ногах стоит но если мы любую ногу это франкенштейна подпилим то наверно он все таки упадет упадет сильно много ли это нам добавляет вообще стабильности скорее создает проблемы и вот с этими проблемами с этими болями мы жили очень долго жили даже не если не преувеличивать то лет 7 наверное жили вот в таком сетапе какие же проблемы во первых если у нас любой мастер отказывает то начинаются пляски с бубном у нас поток репликации перестает писаться и соответственно весь кластер становится не консистентными на одних словах есть данные которые писались в 4 мастер например она других словах нет этих данных просто потому что связь между этими мастерами разорвана мастер вы вышел из строя это естественно не единственная проблема а если придут прилетел тяжелой отдай да точно также репликация начинает лагать начинает тормозить транзакции выполняется долго она не попадает в бинарный лог очень долго даже если попало то потом нужно подождать еще кучу времени чтобы она попала на следующий мастер потом еще во время чтобы на следующий потом еще во время что попало нас life но самой отдаленной зоне то есть как минимум четыре шага это должно пройти это должно записаться и в табличке на типичные в этот сторож и в репутационный логе если посчитаете сколько их щенков должна выполниться чтобы это все прошло по такому сетапу то можно схватиться за голову на все это еще нужно наложить то что у нас достаточно много товаров но если не сравнивать marketplace сами там конечно побольше и у каждого товара в каждом регионе может быть своя цена их нужно обновлять это обновление помимо того что вызывает обновлению самой цены еще вызывают обновление кучу связанных сущностей поэтому поток записи в этот кластеров в это кольцо он тоже достаточно большой кроме цены еще есть и остатки и логистические цепочки когда один остаток может перемножаться еще на 100 складов и обновлять автоматом доступность по сотне точек и чтобы подлить еще масла в огонь и стала совсем больно у нас была версия 55 на мастерах и как вы понимаете в таком сетапе когда мастера работают в кольце обновить тоже не так просто и вдобавок еще и белок роу имидж full когда пишется все поля которые были до все поля которые были после в бинарный лак и соответственно объем бинарных логов тоже из этого у нас был достаточно большой буквально перед конференцией я специально посмотрел сколько же у нас в момент когда идет интенсивная запись fps на обновление всех этих сущностей это вывод греппа эсэмэску альбин logo поминутный соответственно цены здесь далеко не в топе дании в топ-5 входят но намного больше апдейтов проходит по другим таблицам и to buy блок элемент проб с 31 если кто-то с битрикс им работала кстати поднимите руки кто сбит рексана работал вот вам должны быть знакомы эти таблички естественно у нас 31 инфоблок в которой тоже пишется много чего это там хранятся детальное описание товаров если просуммировать то что то в районе двух тысяч модифицирующих рпс у нас прилетает в этот кластер в отдельные минут и естественно может быть и больше может быть и меньше я специально не искал а просто выбрал перед конференцией произвольный момент долго думали что же с этим делать как поступить рассматривали разные варианты думали насчет галеры думали насчет экстра тебе кластер а может быть на них переехать вроде как есть совместимость и все должно быть замечательно хорошо но у нас были свои нюансы использования кластер а про которые вам расскажу сейчас обязательно может быть они вам пригодятся энди бьют мы сразу отмели то совсем было не в ту степь а когда изучали описание галеры то в ней было важное ограничение что она работает с точки зрения репликации бинарных логов только с движком и на тебе к сожалению или к счастью мы используем не только и на тебе используем активно еще и black hole и так как гарантий что там это все будет работать нормально не в галлерею не в экстра тебе кластере тоже нет поэтому в чем основные плюсы этих систем то что они позволяют осуществлять синхронную репликацию и гарантировать консистентной состояния во всем кластере но при этом такая запись тогда будет очень долгой и придется дожидаться от всех мастеров слоев подтверждения транзакций поэтому современном мире а синхронная репликация остается преобладающей для того чтобы масштабировать скорости доступность теперь чуть подробнее про black hole за что мы его так любим поднимите пожалуйста руки кто все знает что такое зачем это нужно применять отлично все теперь узнают это специальный движок в москве ли он встроен по умолчанию обычно даже включен не надо ничего делать он работает сразу из коробки в этом движке он реально представляет из себя черную дыру ты в него пишешь а он ничего никуда не пишет в таблицах на диске будут лежать пустота в чем же его фишка и особенность он не пишет ничего в таблице но пишет в репликации он эй log за счет этого мы можем на одном из своего в кластере например или на нескольких за артрите джонс и на тебе и тогда эти данные появятся в этой таблице на отдельном сервере при этом они будут не содержаться на всем кластере это очень полезно если вы например пишите какие нибудь архивные данные которые не нужно просто хранить к ним очень редко идут обращения и в этом случае это может пригодиться но конечно же есть нюансы например если у вас есть праймари ключи обычные сорта инкрементом в этой таблице то все инсульт и всегда будут с этим одинаковым праймари ключом поэтому это может для вас не работает для вашего кейса нужно адаптировать приложение чтобы оно могло использовать эту фишку у нас она используется очень активно и когда мы планировали обновление тоже был ряд ограничений конечно админы у нас не хотят что-то делать лишний раз руками они любят надежны и устойчивы и решения которые не падают и фишки репликации нам нужны обязательно это одно из главных ограничений и с точки зрения эксплуатации мы хотим сохранить совместимость со всеми нашими инструментами которыми осуществляется мониторинг и диагностика проблем и так далее ну и конечно обновление должно пройти без downtime официальная документация мускуле говорит что для того чтобы обновить мастер в репликации нужно чтобы все слои вы были 57 поэтому злобный тролль над нами посмеялся взглянул на наше кольцо мы почесали голову подумали а как же его обновить думали очень долго придумывали разные варианты даже пошли сначала на рынок поискали подрядчиков которые могут помочь нам в этом но к сожалению таких подрядчиков не нашлось кто бы придумал надежный гарантированный способ позволяющий выполнить такое обновление ну а для обновления что нам требовалось если с клиентом все понятно клиенты совместимы между версиями то несовместимая частью это как раз бинарные логе которые пишутся в разных форматах есть несколько опций в бинарном логе который позволяют плюс-минус организовать идентичность форматов между версиями их можно покрутить включить и получить в 57 практически такие же реплика ционные логин как и в 55 мы это естественно не могли просто вкрутите и пустить на продакшен мы это очень активно тестировали для тестов нам понадобилось кольцо там мы это кольцо развернули на одной из виртуала чик примерно вот конечно вряд ли вам видно слишком мелкий шрифт но с помощью например москве льда мульти можно прямо на одном посте сделать несколько разных дата директорий для insan сам sql и поднять на разных портах эти инстанции после этого взять и подменить версию отдельным пинар ником конкретного инстанса и попробовать как же это будет работать мы сделали очень простой тест мы взяли развернули такое кольцо подменили версию и попробовали залить dunk нашей же базы в один из мастеров в этом кольце это базовый самый простейший случай когда хотя бы мы пройдем по всем нашим данным по всем типам колонок что они точно запишутся точно от реплицируется проверим на всех этих инстансах что конкретно произойдет не будет ли падение не будет ли несовместимости и конечно мы такой несовместимость нашли она в принципе есть в официальную документацию мишель но чтобы ее найти нужно ни один час посидеть в этой документации а это несовместимость полейте падает time есть еще несколько кроме daytime а идиte в том числе и time у нас таких полей оказалось всего 240 и любой ддл запрос которые модифицируют эти поля он автоматом падал и клоуном репликацию почему потому что начиная с 5 6 эти поля имеют другую версию у них другой идентификатор у них другая суть почему потому что добавились микросекунды в эти поля все что создано ранее в целом работают и если ддл а нет то можно попробовать и полететь на такой схеме но только в случае если вы гарантируете отсутствие дудел чтобы никто не модифицировал эти колонки эти поля тогда это в целом вроде бы даже работает и по нашим тестом могло бы так поехать но рисковать мы не хотели брать на себя ответственность и если вдруг репликации развалятся потому что починить ее это не один час в таком варианте мульти source для нас показался волшебной пилюли которая решит сразу огромный пласт проблем который в этом сетапе в кольце есть обычно люди делают нормальные кластеров кавычках до делают один мастер делает пачку слоев но если решение нормально нам это не подходит неинтересно надо что-то оригинальное придумать мы решили сделать всё наоборот и мы съели такую конструкцию поддерживает можно писать в 4 разных мастера и все эти изменения сливать напрямую в конкретный slave более того не нужно даже переучиваться почему все команды которые работают с репликации те же самые абсолютно этот cinch мастер единственное изменение мы добавляем в этот cinch мастер вотчину это именованные каналы которые можно назвать как угодно и с ними работать таких каналов тоже может быть сколько угодно у каждого канала отдельный поток репликации отдельный бин лак отдельная позиция таким образом получилось вот такая вот красивая схема она может быть кажется немного запутанной на самом деле у каждого мастера появилась условно 15 слоев при этом это все мастера активные мы в любой можем написать и изменения сразу же напрямую миную бинарные логе через logs for days которые прокачиваются попадают напрямую slave важный нюанс у нас есть специальные технические славы внизу они выделены это слои вы на которой не попадает боевая нагрузка пользователей который заходит на сайт и используются они для разных целей либо для бэкапов либо для того чтобы делать аналитические выборки тяжелые и не блокировать базу для остальных пользователей также есть специальный отстающий slave который содержит все состояние кластера но на несколько часов назад схема мне показалось очень хороший может быть вы меня в вопросах потом разубедить и и расскажите а и и минусах начали думать как же мигрировать на такую схему и решили что один из технических flyleaf как раз станет мастером для нового кластера единственный минус что нам понадобилось примерно столько же железо сколько уже было затрачено на этот кластер чтобы развернуть на этом железе новый мы подняли новый multimaster временно на нем включили logs life of bytes для того чтобы через его бинарные логе питать весь кластер который будет уже по multimaster схеме построен так у нас добавились все остальные мастера здесь это было уже многопоточная репликация у каждого мастера свой канал мы их для простоты назвали канал мастер один канал мастер 2 канал мастер 3 канал мастер 4 и естественно вся обвязка из слоев тоже ну для того чтобы схему не усложнять я ее не показываю на слайде вроде бы все хорошо кластер получился в состоянии prado в реальном времени обновляемый целиком и мы в любой момент времени можем на него переключиться единственный минус у нас нет пути обратно поэтому это нужно было тщательно протестировать и в первый раз когда мы это развернули мы тестировали очень долго и проводили нагрузочные тесты проверяли что все работает дать у него или конфигурацию в том числе по выполнению запросов в параллельном режиме но есть нюанс и конечно же во первых нужно подумать про балансировка нагрузки как эта нагрузка идет и какой ее характер у нас честный round robin пользователь приземляется на абсолютно любой мастер и его поток записью раскидывается и на мастера in если вы даже если следующий запрос пришел на другой мастер то это не имеет никакого значения принципиального подчеркнув нормальном состоянии кластер а когда нет отставания отставание может быть всегда потому что никто не отменял тяжелые запросы и нужно учитывать возможный лак репликации если вы разрабатываете системы которая работает смысле в кластере то очень полезная опция которую я советую вам применять это поставить на d в стендах slave который будет отставать хотя бы на одну секунду вы возможно найдете сразу очень большое количество фантомных багов которые всплывают на продуктивен о которой вы не можете воспроизвести в тесте и конечно нужно учитывать что инкрементные полях закончится быстрее о чем речь каждый мастер чтобы он был активный имеет свое значение auto increment of сэто и у них у всех авто инкремент инкремента 4 то есть они все про мире ключи увеличивают не на единицу как обычно она 4 но каждый со своим смещением поэтому про мире ключи которые записаны на разных мастерах друг с другом не пересекаются про эти во все то надо не забывать особенно обратите внимание на нагрузку на сеть на мастерах почему потому что эти 15 каналов репликации они могут упереться все это легко особенно если вы что-то большое пишите поэтому перед тем как такое делать обязательно прочитайте хватает ли вас канала позволяет ли сеть если у вас ресурсы для того чтобы например 100 мегабит записи умножить на 15 и конечно еще большой очень пласт вопросов наверняка будет про онлайн миграции онлайн миграции будут затронуты на следующем слайде и чтобы эту нагрузку на сеть минимизировать нужно еще выставить параметр для того чтобы бинарной логе тоже занимали минимум места белок рау имидж minimal в этом случае мы в бинарный ловко распишем не весь набор полей да и весь набор полей после а только одно конкретное измененное поле автоматом уменьшая в десятки раз размер бен логов который почти бегают теперь к онлайн миграция на рынке есть много инструментов которыми пользуются большая часть пользуются пир конов skype лозой pt онлайн ский матч кто-нибудь в зале пользуется перуанской тузами это был за на самом деле очень похоже на то что мы используем мы используем гост это тоже широко распространенное известное решение но у них есть некоторое отличие из лепреконов скатал за работает на триггерах то есть на таблице вешаются триггеры на апдейт триггеры наделит и создается отдельная таблица которая сохраняет чулок и этот чин влог формируется по этим триггером то гост этот утилита которую сделали в гитхабе в этой утилите нету триггеров за счет чего это достигается один из слоев тоже начинает писать бинарные логе включается logs for dates он и все события модификации таблице они нативным способом без каких-либо дополнительных телодвижений приходят в бинарном логе либо дэвид либо апдейты и соответственно не нужны никакие промежуточные таблицы которые будут хранить измененное состояние по записям в этой таблице рядом формируется как и везде во всех этих утилитах а рядом формируется таблица в новой структуре и в нее потихонечку копируются данные если вдруг в по бинарному логу для этой же таблице пришли какие-то изменения то выкачиваются нужные ряды и эти изменения тоже применяются и к гост таблицы которая рядом всегда готова до за лица важный нюанс который нам пригодился очень сильные которого нам не хватало в перк one of sky тулга это контроль отставания репликации по другим словом то есть мы можем задать список слов которые мы хотим проверять и в случае если эти слои вы начинают отставать на примерно 300 миллисекунд или на секунду мы можем задать этот порог и можем сказать что если хоть на каком-либо из этих слоев есть такой отставанию ты пожалуйста вот эту миграцию и копирование данных в гост таблицу прекрати приостановить подождите пока это отставание уйдет и только потом продолжай за счет этого онлайн миграции можно делать в любое время их можно делать днем их можно делать в час и высокой нагрузки можно делать ночью и откладывать switch этих таблиц на любой момент времени вперед например сделать миграцию ночью и отложить на рабочие часы можно проконтролировать что в этой новой таблицы все корректно с данными все корректно с кодировками ничего не пропало есть драй раны и так далее в общем мы очень много пользуемся этой утилитой она доказала свою работоспособность и она по сути единственная которая может применяться в multimaster схеме потому что триггеры повешены на одном активном мастере ничего не дают изменение пишутся и на другие в том числе поэтому возможно вам это тоже будет полезно ну конечно без ложки дегтя не обошлось есть и минусы конечно это сложнее настраивать сложнее поддерживать сложнее мониторить но надо сказать что не сильно сложнее ну да у вас четыре теперь потока репликации они один вы мониторите в четыре раза больше но для любой нормальный системы мониторинга это непринципиально сколько там метрик важный минус который мы поймали и которым я хотел бы поделиться это то что берлоге проигрываются с разной скоростью если вы вывели один из слоев обслуживания захотели что то на нём сделать оффлайн и потом через час включили то поскольку у каждого из бинарных логов есть свой worker свой процесс который этот бинарный лог применяет он процесс синхронизации между применением разных бинарных логов не производит он применяет свой белок с той скоростью с которой может его произвести из-за чего набор данных при таком вот выключение и включение может резко отличаться у вас нарушается транзакционных и порядок выполнения транзакций у вас может прилететь апдейт для которого еще не прилетело insert соответственно этот апдейт не применится и все это приводит к не консистентной sti но если у вас кластер работают нормально вы мониторите отставания вы оперативно принимаете меры то таких проблем быть не должно не сколько еще опции которые полезно было бы вкрутить для того чтобы немножко быстрее репликация работала это использовать параллельные worker и больше 5 наверное в целом никому не нужно там обычно они не загружены можно в performance схеме посмотреть насколько они сильны используются главные плюсы для нас это то что такая схема позволяет любой мастер в целом выключить в любой момент если вдруг что-то с ним не дай бог произойдет упадет сгорит железо все остальные мастера при этом продолжают работать в них работают прекрасно запись кластер тоже сохраняют работоспособность все слои вы получают все обновления и даже переключать свои вы из них на другие мастера не надо поэтому с точки зрения эксплуатации даже упрощается поддержка такого кластера меньший размер бен логов про это я уже говорил и главное что у нас всегда теперь только одно плечо для репликации используются и поэтому изменения попадают быстрее ну и наверное важный фактор 25 процентов записи которые в этот момент теряются когда падает мастер точно также можно спроецировать на то что когда лагает этот мастер он точно также влиять только на 25 процентов потока записи и 75 при этом процентов пользователей прекрасно себя чувствуют и даже не замечают что то идет не так доклад не был бы интересным если при мне рассказал про fa cup of a cup у нас был и ни один самый интересный и самый жесткий который привел в этом году к часовому дому тайна даже несколько часовому это были плановые работы по переключению линии питания и эти линии питания переключались под из хадаш к как вы понимаете отказала подул и без хода школе globe полностью на этой скале жки крутилки весь кластер а кроме этого кластера крутилась еще много всего включая и гид лабы и много других сервисов но нам понадобилось несколько часов чтобы все все все поднять считаю в таком варианте это не самый плохой результат если у вас есть вопросы готов по хули варить пообсуждать и и волкам а можно у меня появился меня слышно сила спасибо за доклад вопрос про данная консистентной после сбоев данное расходились ли и как вы с этим боролись конечно расходились конечно они расходятся регулярно и без сбоев на самом деле если постараться все проанализировать есть несколько вариантов вообще как с этим бороться во-первых можно максимально изолировать пользователя и привязать его к конкретному мастера то есть весь поток данных который он пишет он пишет только на один мастер другой пользователь пишет на другой мастер и в таком случае расхождение данных практически не будет происходить но для этого нужно адаптировать приложение почему не будет происходить потому что все транзакции которые этот пользователей производила не и выполнится вот в том же порядке в котором он их накидывал если нельзя сортировать что что если сортировать нельзя пользователя по если сортировать нельзя но тут остается только надеяться и ждать до optimistic стратегия как говорится меня вопрос еще вопрос и вопрос два вопроса какой вас трафик что вам нужно 15 слоев и второй вопрос это все в одном надо в центре на текущий момент это стало в одном раньше это было в нескольких и скоро это тоже будет в нескольких снова насколько будет мастер друг от друга что касается вообще количество серверов таких и общей нагрузки трафик относительно небольшой но это трафик тяжелый почему потому что это битрикс у которого в среднем на одну табличку приходится еще 10-15 джонов из других таблиц это запросы как правило двух страничные с кучей условие с кучей выборок и так далее естественно мы можем ехать на меньшем количестве но нам нужен небольшой запас еще поцелуи по всем остальным параметрам чтобы мы были гарантированы уверены в том что кластеров не упрется в capacity а когда будет два дата-центра насколько будет удален и мест мастера друг от друга я предполагаю что это будет в пределах москвы спасибо поэтому там минимальный лот нас должен быть скажите пожалуйста три раза три допустим такая ситуация у нас есть продукт сойди с ником 1 и ценой 100 и у вас приходят два апдейта одновременно на 1 и 3 мастера в одном обновляется цена на 200 в другом на 300 мастера примет этот апдейт тут на самом деле это типичный риск кондишен и гарантировать результат тут нельзя именно поэтому сам процесс применения цен у нас всегда идет на конкретный один мастер но я допустим и процент я вообще про любые апдейты просто по моему опыту когда мастер с ней slave принимает запись берлоге в нем говорится с какого на какое значение поменялось поле если предыдущее значение не совпадает она будет из память если кто-то конечно транзакцию отклониться да тут вопросов нет все будет запускать придется пропускать да и потом восстанавливать консистентной с этим конкретным данным на самом деле мы это практически не делаем мы скорее адаптируем приложения что в таких ситуаций не возникало окей спасибо так вот давайте сразу рядом большое спасибо за доклад андрей прокофьев раз севастополь вы сказали что вот на уровне приложения вы заранее идентифицируете пользователи привязываете его сразу со потому что он писал свой свои действия на щите там в определенный мастер но поскольку сказали что это битриксе вас интернет магазин ту боли бома там еще есть где-то учетные системы остатки обмен и как вот это вот все вместе живет живет прекрасно на самом деле все фоновые процессы у нас всегда работают с одним мастером и вся интеграция соответственно тоже завязано один мастер и тут такая адаптация для такой системы не получится что там какой-то вот 3 пользователь до него еще не дойдет вот этот дельта там товара количество не будет ну на самом деле у нас есть онлайн подтверждения из другой внешней системы по остаткам поэтому на финальном шаге корзины то в любом случае проверится и другой вопрос как часто то система обновляет эти остатки и вот здесь есть проблемы спасибо я вот хочу немножко продолжить историю про файл с репликацией вы явно указали что до может быть ситуация у нас пришел insert потом был апдейт и до какого-то мастера который на самом деле слои в данной ситуации апдейт пришел после inserto это стоп репликации или она автоматически не запустится раскрыть это круто что вы заранее готова к такой ситуации вот расскажите как автоматизирует если автоматизируйте или как вы не сходите с ума если руками как вы справляетесь ситуация на самом деле мы просто и банально выключаем игнорируем ошибки прямо на уровне в конфигурации мускуле и отслеживаем логин который мускул пишет про ошибки применения таких транзакций то есть вас булочки binary руются эти ошибки и репутации идет дальше а вы качестве деле routan смотрите за тем что происходило до чего такого вопроса да спасибо за доклад вот есть такой вопрос большое количество серверов то есть между ними настроена логическая тип ли catia каким образом осуществляется контроль идентичности данных на этих серверах собственно наблюдая за logo мимо и сквера можно понять какие данные начинают расходиться если вы посмотрите в гирлок там будет конкретная транзакция который не применилась и эту транзакцию можно побил логом потом отследить что конкретно в этой транзакции не обновилась посмотреть поэтому идентификатору что конкретно содержится в базе на одном сервере на другом на всем кластере по этой записи сравнить и принять решение то есть тут арбитром выступаете вы их сами вы можете это фиксить руками можете использовать тузы и типа перков skype заезд для синхронизации но в нашем сетапе пока это не применимо спасибо спасибо за доклад уточните пожалуйста вы начали с предыстории чтобы использовать один принципе я с ним я с ним постоянная работа я знаю что он пишет огромное количество данных о 6 использовать миллионов простите я услышал чтобы говорить о что использовать 1с битрикс тем более старая версия а и за ним работаете вы с ним семь лет вопрос за все это время у вас не возникло желание заменить битрикс на что то другое но если он действительно такой сложный и тяжелый но если вы обратили внимание на один из первых слайдов то желание конечно возникла и сейчас ну не меньше чем половина сайта это уже не битрикс совсем другой микро сервисный стек который и на кубе работает и сервисы на гошке но на самом деле мы пока в начале пути у нас нет десятков тысяч сервисов как в авито или еще где-нибудь и это пока еще всего лишь в районе сотни может быть две сотни сервисов не больше спасибо за доклад дмитрий зайцев м3 два небольших вопросов 1 вы сказали что в некоторых ситуациях привязываете запросы конкретному мастеру вы это вручную делаете следите за нагрузка этих мастеров и так далее что делаете если он там перегружен то есть как масштабируете да и второй вопрос не думали ли уже об обновлении на восьмёрку и если вдруг думали то это будет такая же схема значит начну с обновление обновляться на восьмёрку мы конечно уже думали но пока ещё не решились и для того чтобы это движение началось нам нужно какой-то очень весомый аргумент почему нам стоит вложить ресурсы и начать двигаться туда end of life хороший критерий да но пока еще 57 не windows live а первый вопрос повторить пожалуйста по распределению нагрузки есть хитрости есть данные которые для нас критичные это данные заказы все что связано с заказом пользовать в этом случае для получения такой информации мы всегда знаем номер заказа а по номеру заказа мы можем всегда получить офсет и узнать по офз эту на каком же мастере он изначально зайонц остался то есть мы можем был просто по номеру заказа всегда знать что а вот этот сперва мастер пришел а вот этот со второго и приложение может сама подключиться к конкретному мастеру и данные по этому заказу вытащить себя игнорируя вообще весь остальной кластер таким образом у нас по крайней мере по тем данным которые мы считаем для себя критичные мы всегда получаем точно именно тот набор данных который нам нужен так я вижу еще вопросы есть один опрос здравствуйте спасибо не нарбут самый холивар на такой вопрос там был вопрос из зала по поводу на замену битрикса у меня будут вопрос насчет замена сумма д сторону под gresso простите если можно чуть чуть погромче холивар ный вопрос насчет смены sbd сторону под gres конкретно в сторону пас греции или в сторону какой-либо другой базы данных мы пока такой процесс в принципе не рассматриваем да у нас есть позоря которая под сервисами крутится в кубе есть еще несколько других баз там и in memory все подряд но для того чтобы мигрировать просто так битрикс на по сгорю ресурсы того не стоят на самом деле да это можно сделать но зачем у нас битрикс там условно через какое то время уже не будет поэтому сейчас нецелесообразно здрасте спасибо за доклад я вот хотел спросить вопрос у вас было там перка надо вы рассматривали там несколько вариантов вот почему то я не увидел мой успели есть там групповая репликация и вообще мы свое как бы стандартное решение именно тебе кластер вот смотрели ли вы в эту сторону как бы и почему не выбрали если смотрели энтеббе смотрели но даже на слайде было где-то она не в ту степь немножко это больше про то как размазать данные на несколько серверов они-то как сделать независимый сервер который был бы полностью идентичен другому что им сказано да да это групповая репликация мне кажется момент а другой нет но по крайней мере мы пока они не увидели для себя зачем просто там много фишек как бы стандартной комплектации уже там всякие мои скилле роутера используются это в общем все это как-то само решается из вот этих не кажется всяких разных схем наверное мы рассмотрели и стоит посмотреть всем спасибо так если вопросы еще где то что вижу подойду и это будет ужинаем а последний вопрос спасибо за доклад у меня такой момент о технике репликации вот 55 когда вы использовали там понятно традиционная было пять 7056 уже жить indiglo был транзакций найди по ее переключались на нее или так на традиционное остались на джетте один не переключались тут есть несколько субъективных причин нам просто не понравилось когда мы видим эти j10 а если в них есть еще skip и то шел sleeve top превращается в такую простыню из этих типов и пока это наверное более субъективная вещь да он полезен да он хорош но не захотели так константин спасибо большое за ваш доклад"
}