{
  "video_id": "AGtJjKQ7Ius",
  "channel": "HighLoadChannel",
  "title": "Распределенный blockchain процессинг / Алексей Трошичев (QiWi, Rakuten)",
  "views": 1209,
  "duration": 2446,
  "published": "2017-04-10T02:11:39-07:00",
  "text": "добрый день меня зовут тросов алексей и я работаю сейчас в компании руку-то ну и сегодня я хочу рассказать про специальную систему которая позволит много иначе взглянуть на processing коммерческих транзакций и начну я свой рассказ про то в общем что такое processing что такое блокчейн и что значит дистрибьютер чтобы стало понятно какая конкретно задача решается есть мнение что processing это такая система привода в денежных когда один человек берет например вот там маша берет 10 долларов и переводят их вася и через какое то время эти 10 долларов вася получать на свой счет внутри этой системы звучит очень качественную и понятные просто на самом деле processing это хороший бизнес и основным клиентом там является не вася и не маша основным клиентом которые приносить реальные деньги является и коннорсу то есть какой-нибудь онлайн магазин и его покупатели соответственно то есть покупатели приходят в процессе они получают переадресацию от магазинов processing суммой покупкой они покупают что-то магазин получает подтверждение и начинается доставка какого-то благо это может все что угодно может быть доставка каких-то материальных благ типа провайдера может быть достав каких-то реальных благ типа какого нибудь там amazon и руку тайна и тут сразу возникает несколько проблем во первых пользователей не любят ждать или и поэтому если в первом случае какой intimacy мог выпить чашечку кофе перед тем как нему придут деньги которые отправляли машей то пользователь не будет смотреть на крутилку вот на своем любимом магазине или своему процессинге он хочет как можно быстрее чтобы транзакция прошла для этого у нас есть требования к скорости 2 2 требование соответственно к стабильности и кстати если возвращаться опять требую скорости то нужно понимать что чем больше транзакций можем обработать как processing это значит тем больше комиссии мы получим единицу времени то есть скорость транзакция это критичная для бизнеса величина и вот допустим и такой processing и вот мы растем растем 1 тел вот какой-то момент получается что вот это вот база данных которую так любят схематически изображать она больше не работает нормально и нам нужно ее как-то менять ее архитектуру сделать ее распределенный когда мы говорим слова распределенный мы фактически за этим словом произносим огромное количество проблем которые это та не тянет за собой есть понимание что распределена это такая отказоустойчивая система которая обладает хорошей консистентной можно работать с любым узлом с одной ну в общем с не теряю каких-то важных функций например скорости там доступность и прочего там марте шинта лоренс вот и одна из принципиально важных вещей о которых нужно иметь ввиду если мы говорим о финансовом процессинге это состояние гонки race кондишен это 100 некоторая которая есть очень много где вы не поверите каком количестве она есть системах и когда оно происходит когда у нас есть два несогласованных процесса которые работают с одним ресурсам или когда у нас два или еще хуже один процесс который работает с распределенной инфраструктуры с большим количеством реплика и при репликации есть задержка и есть вероятность того что данные будут в какой-то момент не согласованы а чтоб понять насколько высок может быть ущерб такой ошибки можно спросить жителей северо-востока сша потому что это конечно не процессинга качается 1003 году там был огромный блокаут который произошел из-за того что в систему мониторинга линий напряжения не систем мониторинга была ошибка безопасную работа с данными из-за этого когда одновременно из-за жары и 14 августа случилось несколько отказов системы при обработке нескольких alert of одновременно ушла в глубь мертвый цикл бесконечный и данные об авариях перестали обновляться и операторы перестали адекватно реагировать то есть они из такое вполне себе повседневной аварии сделали катастрофу неадекватностью своих действий и самое замечательное что там был конечно backup но поскольку в бэкапе был тот же софт когда они переключились на backup он пришел ровно такое же состояние через 15 минут вот поэтому два дня они вручную чинили свет очень красивый фотографии нью-йорка без света нужно интернете найти вот если мы говорим о двух процессах который делит один ресурс очевидное решение которое приходит в голову это делать локи то есть когда один процесс блокируют ресурсы с которыми он работает а другой процесс ждет это замечательные простое решение такой которая последствиями сравнила что называется с костылем потому что когда у нас начинается сложный процесс и которые могут работать одновременно с несколькими ресурсами еще говорить для некоторых наверное очевидные вещи то используя локи мы можем попасть ситуацию когда при разной последовательности используя ресурсов оба процесса блокируют ресурсы и брызгать они просто ждут то есть они могут так до бесконечности ждать и на практике это выливается в то что например у вас есть онлайн магазин который ну процессе сколько там тысячи транзакций в день а потом пример новый год когда вы строите большие планы на прибыль троллить количество транзакций на полторы тысячи возрастает до полутора тысяч при этом вдруг 90 процентов ваших транзакций представиться обрабатываться потому что система просто находится большую часть времени состоянии до блок вот хорошим способом конвертировать ожидание в ошибки по выгодному курсу вот это решение с сохранением состояния внутри самого процесса когда у нас какой то процесс берет данные из базы данных работает с ними а потом вносит соответствующие этим данным изменения только в том случае если данные не поменяли своего состояния за время когда он с ними работал ну вот и в этом случае это получаете много ошибок в плане обработки транзакций но у вас не уходит время на ожидание вот а потом например вы решили свою систему сумму считать то есть использовать не один процесс ни один немного процессов и одну базу а например большую распределенную базу данных которые между собой стрип лиц и равана и вот когда у вас происходит например 2 райта которые постепенно расползаются по репликам то в какой-то момент может быть ситуация когда вы вдруг обнаружите что рейд и они имеют разную ну раз разный логический смысл вот для того чтобы этого избежать используется такая методика в результате система не знает какой из них правильной той с какого какой из них записать базу вот используется подход и вершил консистенции кости по консистентной в конце концов ему и исходим из того что мы каждому мы берем и каждые события которые падают в систему как-то нумеруем то есть мы можем четко выстроить последовательность и пока системой сходятся мы выбираем и единственным состоянием из тех противоречивых только то которое пришло последним вот есть такая система используется непосредственно в кассандре когда у нас есть несколько right of вот который могут конфликтовать мы берем именно тот который вот пишем базу именно тот и считаем его правильном который произошел позже всего вот сейчас еще один момент пример из жизни про то почему это критично для процессинга именно состоянии неопределенности когда у нас в одной распределенной системе может быть несколько противоречивых состояний хороший пример из starbucks то есть человек просто обнаружил что если имея starbucks есть свой внутренний processing это баланс на карточках и они сделали такую глупость чтобы они особо не подумав как это сделать правильно позволили между карточками эти деньги гонять заседали для этого интерфейса но система была написана так вот я не знаю как она была написана как и нужно было написать что если параллельно слать много запросов на перевод с одной карточки на треть вот на вторую карточку то можно было добиться такой ситуации что перевод происходил дважды то есть когда мы отправляли параллельно много запросов на перевод 5 долларов при человеку пап-1 карточку попадали 10 долларов что это значит да процессе com финансового это значит одну очень важную вещь что если мы можем себе допустим принять несколько ошибок которые вызывают райс кондишен то есть мы провели исследование поняли что мы несколько раз вместе на случается рынка кондишен вот мы вновь видим какие-то проблемы в данных которые приходится вручную разрулить вручную разруливать там какие-то деньги у людей ну блокируются или пропадают они звонят и саппортом и это разруливал мне это в принципе дешево гораздо дешевле чем писю инфраструктуру перепиливать такой подход ошибочен потому что если кто-нибудь снаружи поймет что таким образом можно воровать деньги из вашей системы то как-нибудь в понедельник утром придя на работу вы можете обнаружить что кто-то используя ваш processing уже стал миллионером это не вы вот это коротко про race conditions и почему это очень важная проблема в процессинга сейчас немного про букчин опять же процессингу большинстве своем случаев если выкинуть много-много маленьких деталей и нюансов то весь processing можно представить как две большие таблицы одну маленькую таблицу другую очень большую в одной маленькой таблице написанная актуальный балансы счетов который в этом процессинге а другой таблицы просто блок транзакций который в результате которой хоть и баланса менялись в первой таблице к чему это приводит это приводит к тому что я наверно не знаю ни одного человека который бы мог реально серьезно поручится за то что если мы проиграем все транзакции которые есть в истории мы получим балансы которые актуальны в данный момент который находится таблицы балансов потому что связь она то есть если кто то получил доступ к базе данных и там что то поменял даже по ошибке то эти изменения очень трудно потом отследить и чтобы этого не происходило было на самом деле все технологии для блокчейна они были придуманы помощи в годах восьмидесятых то есть это не какой-то там вот новые гениальное изобретение это просто делается следующий берется какой-то информация транзакции от нее вычисляется хэш и пишется следующая транзакцию и тогда мы можем просто проверяя хэши всех последовательных транзакций понять что первое что мы можем удостоверить последовательность этих транзакций проверяй об их и шам и второе мы можем просто посчитать их ешь и понять было ли что-то изменено в этой цепочке транзакции то есть задним числом менялись эти транзакции или нет и соответственно мы можем актуальный баланс единственная проблема почему раньше блокчейна нормально не работали большие потому что технологически это действительно сложно и тяжело потому что нужно по большой базе вычислительной точки зрения дорого ходить и постоянно не брать баланс как значения из базы а постоянно делает огромный select по транзакциям и баланс считать вот этими сперва проверь эту свою алгоритм использования такой мы сперва берем цепочку транзакции проверяемые а потом считаем актуальный баланс и еще важная вещь эти транзакции можно аутентифицировать то есть это значит что если пользователи эти транзакции подписывают на своей стороне то есть как это доказывает свою подлинность то мы можем однозначно понимать когда имело место какое-то локальные изменения этих транзакций внутри нашей базы данных или когда это какая-то активность со стороны пользователя то есть фрод связанный с тем что пользователя увели секретный ключ если мы говорим о подписи вот а есть следующие очень классная технология которая позволяет очень интересным ключом использовать свойства транзакции блокчейн и именно свойства контроля последовательности то есть если их называть то есть механизм который нам поможет это дистрибьютер хаштай бал что к дистрибьютор штейн болот самом простом виде это мы берем множество значений какой функции вот внешний контур вот там и деле множество значений этой функции между узлами которые находятся в сети то есть зеленая это фактически множество значениях ишаем до 5 вот жёлтое это просто объема машина какие-то узлы в сети которые объединены в аварийную сеть ну типа как вот самый популярный наверное их относить это к земле которая используется в торрент ну не в торрентах ну ну да в торрентах используется то есть ей пользовался этому каждый но никто не признается вот и соответственно мы можем каждому узлу а привязать диапазон значений от 5 до 5 функции что это нам дает это нам дает очень интересные свойства что если у нас есть транзакции поступающие в сеть которые мы обрабатываем в большую сеть несогласованную то мы можем в каждый момент времени получив новую транзакцию посчитать от неё хэш и знать одну и только один и только один узел каждый узел может знать на каком будет следующим узлу это транзакция выполнено то есть мы например получаем транзакцию на на обработку на узле n1 и видим что у нас там есть уже транзакция обработанная на зелёным цветом обозначены на схеме и чтоб понять на каком узле будет обработано транзакция следующее нам нужно вычислить хэш от уже обработаны и транзакции и таким образом мы можем все последующие для конкретного счета транзакции раскладывать по всем узлам то есть что было понятно по шагам вот например есть некоторый узел nx который может быть как это называется если говорить про мир кассандры координатор или как то так то есть в который входят все транзакции и он их не обрабатывать тонов просто маршрутизировать и у него есть вот и последних транзакции он берет сперва идет на узел n1 получает сообщение о том что транзакция обработано тут индекс 0 на пусть допустим и потом получив эту информацию он сохраняет их ешь от последней успешной транзакции и получив этот хэш следующий он уже знает что ему нужно обратиться на узел n2 который контролирует диапазон до хаты диапазон в котором будет транзакция следующая выполнена ну да потому что в этот диапазон входит хэши транзакции один вот и сразу возникает вопрос 5 как эта система нам может помочь с консистентной стью потому что система то распределенная и если мы например запустим в сеть а нормальное состояние распределенные системы она некой время распределенной системы это полное отсутствие консистентной sti то есть когда там постоянно крутится транзакции там постоянно идет репликация и мы не можем гарантировать что у нас будет какая-то одна версия данных системе поэтому мы просто по шагам сейчас рассмотрим все возможные служу случае в такую в описанной архитектуре не консистентной sti то есть например нам тут есть их всего 3 в 1 случай если система на который приходит первая транзакция ну первый узел на нем находится версия более актуальной цепочки то когда мы отправляем эту транзакцию на следующий узел то есть мы шутили ruim который должен эту транзакцию выполните и вставить в цепочку то нам нужно про и сделать простую операцию нам нужно сравнить хэш последним успешной транзакции в но узле nx и на узле н y и таким образом если мы видим что эти хэши не совпадают то эта система не consist то есть мы системно хостинг ассистентом состояний поэтому транзакция выполнено не будет вот разумеется может запустить как бы suction который закрутит там процесс обновления цепочки это займет нам миллисекунды как показывает опыт но вся держится в том что мы не сможем создать две противоречит выполнить две противоречивые транзакции и мы никогда не сможем если у нас логика обработки транзакций это контролировать чтобы баланс человека не уходил в ноль то мы никогда человека в ноль не сможем загнать потому что только ждать потому что каждой транзакции имеет только один и только один узел на котором она будет выполнено во второй вариант если мы видим что первый узел nx находится не консистентной состоянии вот и он получает какую-то входящую транзакцию отправляют ее на узел который находится в более актуальным состоянием там просто вот сейчас объясню вот эти вот справа то яндекс 21 x1 это количество транзакций в копи в локальной копии цепочки на каждом узле то опять же из-за такой проверки ой чёрт там они а да все верно без опечатки то есть мы видим что эти hash-сумму не совпадают и поэтому транзакция не будет выполнено и возникает вопрос следующие а что если обе оба этих узла находятся в не актуальном состоянии то есть так вот получилось что у нас есть данные другой сесть на других узлах танки транзакции были обработаны и тут мы видим что у нас попадает систему транзакция номер четыре где-то там обработано транзакция номер три она этих двух узлах вот транзакция номер два есть только в их локальных копьях и хэши совпадают и вот самое интересное заключается в том что где тогда транзакция номер три существовало потому что если мы машите зиру им на транзакцию на систему используя хэш at&t nx2 то значит мы эту систему автоматического эту транзакцию автоматически отправляем на узел где будет уже транзакция 3 выполнено то есть это есть такое состояние описано на этой картинке она возможна только в том случае если на локальной копии н y и зла транзакцию 3 кто-то уже выкинул вручную потому что она нам ни на каком другом узле просто выполнена быть не может и вот поэтому такая ситуация описанная она просто невозможно если руками данные не править вот какие замечательные свойства мы приобретаем используя эту архитектуру если мы используем криптографическую хэш-функцию которая дает нам равномерное распределение там и тогда получаем что все транзакции которые входят в систему они распределяются по всем узлам равномерно то есть вся нагрузка от входящих транзакций он распыляется равномерно просто и можно доставая узлы в систему эту нагрузку выдерживать а второе время выполнения транзакции она слабо зависит от времени время количество узлов в сети то есть единственное что тормозит эту систему сейчас я расскажу чуть попозже почему это то что это поиск по таблице маршрутизации в дтп то есть чем больше узлов тем больше таблица маршрутизации и узлу который принимает амортизирует транзакции нужно просто побольше то большего размера таблицы искать вот ну и разумеется чтобы уже быть не погрешить против истины мы можем упереться в то что в какой-то момент у нас просто перестанет нормально работать сеть если вы много узлов поставим и будем там гонять огромное количество транзакций то у нас просто сеть станет то есть я имею ввиду именно такие софтверные логические ограничения физически никто не отменял вот можно транзакции отправляемые на списание средств со счета можно обрабатывать в реальном времени ну вот как по описанной схеме сейчас картинку ещё покажу и самая важная вещь что имея такой блокчейн таким образом сшитый такую последовательность любой кто может взять его и проверить подлинность данных и корректно всех транзакций локально то есть мы просто можно делать такую структуру данных и публиковать и и каждый участник процесса которые используются таким процессингом он может эти данные братья проверять что все транзакции в корректном виде прошли то есть и что там никто не задним числом ним на мухлевал то есть старайтесь такая страшная ситуация например когда деньги тут снялись а товар не куплен то есть как бы от транзакций обломилось а потом ты звонишь processing и они говорят что у нас ничего такого не было у вас там изначально было столько денег нужна такая конечно очень гипотетическая ситуация пугающе но она в этом смысле почти полностью исключено вот по поводу real-time процессинга тоже очень замечательный момент что если мы получаем входящую транзакцию на н1 и отправляем ее для обработки на н4 то в процессе ее обработки на узел и медленно 4 процессе обработки мы возвращаем данные хэши это успешной транзакции на н1 синхронную и потом поскольку у нас есть все данные чтобы знать как на каком узле будет выполнено следующая транзакция мы можем тут же отправить эти данные синхронно на узел на котором будет выполнено следующая транзакция для этой цепочке вот это позволяет система там работать со скоростью ну где-то в количестве трех четырех тузов несколько сотен транзакций в секунду причем умею уже в базе в районе миллиона вот конечно требует особого особую программисту подхода в плане реализации потому что тоже понятно что нужна специальная база и вот хороший доклад сегодня в первую половину дня про и номер один процесс и то есть про работу бас который находится полностью памяти как это грамотно организовать вот нужно решение уже с такой области и вот следующий таком последний слайд то есть куда дальше нужно двигаться в этой системе первое это как наверное заметили тут есть такая вещь что мы можем проверить подлинность цепочки может до проверить ее последовательность но мы не можем проверить ее актуальность если кто-то публикует например одну версию цепочки где есть там 30 писаний а другую кто-то публикуются в версии цепочки где последнего нету списания например средств их там все 29 то есть нужен какой-то таймер который подтверждает фиксирует версию цепочки таким образом что ее нельзя будет как-то публиковать контент конфликтную версию который будет просто меньше в качестве этого таймера можно использовать текущую систему bitcoin у них есть место в протоколе с помощью коты где можно публиковать хэш и если мы в нашем процессинге публикуем данные о транзакциях то мы можем производить эту публикацию с публикации хеша данных который мы публикуем и из-за этого как-то создать конфликтующие версии но это нужно будет хэш сломать то есть это очень очень тяжелая и задача очень дорогая то есть она гораздо я решение и гораздо дороже чем весь этот processing это первое второе это разработка протокола отказоустойчивости потому что сейчас заметно я думаю многие заметили что если у нас все транзакции исполняются на всех узлах то если у нас просто вылетит один узел то мы можем то есть весь processing может встать и поэтому поскольку сейчас очень сильно развитой системой на clown диплом и то есть смысл делать в этом как бы два параллельных облака которые будут находиться в репликации в этом вход стан боюсь их можно будет снова на другой переключатель ну и третье это конечно если мы хотим а быстро публиковать или данные о том какие то какие транзакции сколько мы процессом для всех участников процесса которые хотят этому доверять то нам достаточно разработать просто быть систему и в каком-то tracker их выкидывать и скачивать на низко независимых узлов прелесть в этом заключается в том что даже если кто-то придет в processing который создает такие транзакции вот и просто там сожет все сервера я всех твоих отменит ну или ещё что не страшный ученицу все участники этого процесса они могут продолжить использовать эту расчетную систему на основе данных которые находятся в торрентах вот то есть единственная проблема заключается только вот в этом наверное чтобы собрать все это вместе нужно будет найти нового оператора который реализует описанную инфраструктуру и сможет продолжить начатое в общем я специально побольше времени на вопросы оставил очень интересный класс спасибо такой вопрос а как решает вопрос с ветвлением или за счет того что это один и тот же оператор он ветвлений там быть не может с чем вопрос решать sweet лени и цепочки ну у нас есть однако эта транзакция кто-то от нее одну цепочку построила туда другую а потом кто из них есть еще раз цепочка строится внутри оператора то есть как бы вот это вот идея когда какая цепочка придет первое верняка какая версия цепочки будет актуальна и и не возникает потому что for к цепочке не возникает мы просто получаем цепочки время пав этого запроса на транзакцию внутри себя их маршруте зиру и мы выполняем и они приходят выполняются строго последовательно понятно я могу на самом деле это я понимаю сути вопросы я могу вот в кулуарах потом просто объяснить более подробно здравствуйте я правильно понимаю что эта система такая же проблема как у биткойнов с откатом транзакции то есть откатить транзакцию по сути нельзя а что такое откат транзакция ну ну позвонил клиент сказал вы знаете короче от меня украли карточку и это в общем транзакция не моя сделайте что-нибудь что мне вернули эти дни я и вообще считаю это как сказать вопрос такой дискуссионные мне кажется что само понятие откат транзакции она больше процедурная то есть если у нас есть какой-то счет по которому мы переводим клиент который мы переводим деньги клиенту и пишем комментариях а это откат транзакция создаем еще одну транзакцию которая делает там даус обратно единственным да да да а так математически это обратно никак нет к нему можно но только это будет стоить столько что ну вот буду подарок на 60 летия добрый день до всего за доклад зовут илья tutu.ru подскажите как вы добавляете новые узлы что как вы добавляете новые узлы переключаемся на горячий с их этот ход и на горячую замену вот этого кольца и после этого на предыдущем перри распределяем диапазоны есть мы добавляем новые узлы с новыми конфигами сейчас я поясню там было два возможных варианта это добавлять новые диапазоны которые будут как питер нити например новый узел появился и у него там система по протоколу специальному согласовала себя не просто поделились с ним каждый с кусочком своего диапазона или один отвалился или соседи его диапазон забрали но как показывает опыт в системе с большой нагрузкой и если у нас есть некоторые не определенной сети ту это такие алгоритмы крайне сложны и опасны потому что мы можем получить for к цепочке то есть такое состояние когда у нас например два узла держит один и тот же диапазон и тогда у нас может быть выполнится 2 транзакции выполнив на двух разных узлах с разным логическим смыслом то есть поэтому такое решение тупое простое типа перекидывание ногой нагрузки с одного контура на другой она была выбрана то есть и для соответственно перенастройки контуру нужно перекидывать на старый то есть во время добавления у вас происходит остановка всего процессе нет еще раз есть контур основной есть контур запасной то есть представьте вас есть до 2 дата центра и оба дата центры могут обрабатывать транзакции в каждой нато центре написать запущена такая система которая в реальном времени между собой данные гоняет и вы можете просто изменить трафик из одного дата-центр в другой или кто-нибудь вам поможет с помощью бульдозера его извинить вот и тогда просто ленты ничего не заметят потому что все это будет подхвачена заработает сразу же я могу подробнее описать если есть вопрос чуть позже вопрос если система такая будет там 10 лет работать соответственно большой объем транзакции то с какого момента мы будем начинать анализ баланс надо узнать у как конкретного клиента это хороший вопрос на самом деле он такой инженерное больше зависит от того как дизайн блокчейна то есть он наверное вдохновил к этому вопросу пример биткоина вот у которого нету промежуточной фиксации баланса но если мы например будем промежуточное фиксировать в каждой транзакции баланс то с одной стороны мы сможем использовать несколько баз то есть мы можем старый подтвержденный транзакт ну старые транзакцию проведенный просто отсекать от основной цепочки вот и хранить их отдельно то есть низ не ходить понимал данное балансах брать из последних транзакций и но при этом мы можем их использовать для того чтобы если мы хотим что-то асинхронно долга и перепроверить то есть нужно понимать что эта система она хоть и производит такой букчин который может все проверить она все-таки заточена под то что поработать в доверенным окружении алексеем раз спасибо за доклад за карете цепочка на 1 или их много 1 . для каждого счета своя а конечно перевести со счета на счет инфекционно да очень просто хорошо я поясню что такое цепочкой как она вот в данном случае физически выглядят то есть у нас есть грубо говоря как таблица заданном как большая заданным количеством колонок каждой колонке есть да ну как минимум данные кто кому и сколько их ешь предыдущий такой транзакции и а вот эти записи транзакции они для каждого счета свои но они существуют все в рамках одной таблице то есть фактически у каждого клиента своя цепочка но поскольку они все в одной таблице мы можем со всеми эти данными работать одновременно ответил вопрос и тогда если вопрос есть я там буду у меня вопрос наше время есть и немножко не понял сутки на счет или таблицы вы говорили про систему распределенную на тросике много узлов если ударите пройден у таблицу начнет получать от вас таки есть одна в центре базы данных это всё идёт я имею ввиду штат копия одной и той же таблицы распределено между всеми участниками сети вот и в данном случае когда он проводим транзакцию на списание используя данные из этой таблице мы можем определить только один узел на котором такая транзакция будет выполнено ну то есть если правильно предыдущего доклада требуемой суммы вопрос тоже они в том как в такую систему отправить запрос вида спеши у васи 20 долларов если они у него есть переведи их напели чтобы это прошло там арно вот вот как это будет в рамках хотя бы одной системы уж не говорим про росбанк ну хорошо по шагам мы берем создаем какой-то город запрос о том чтобы вася привел петь и деньги пишем сумму каким образом ну если мы говорим про здесь про подпись то мы подписываем этот запрос и отправляем в сети через api например на какой-то узлов узел смотрит свою локальную копию цепочки берет последнюю успешную транзакцию той цепочки которая является привязана к моему счету от 8 до 20 смотрит в счет васи говорит так вот последних ешь последний транзакции от васи такой-то вот и соответствии с этим huge он он выбирает узел вот и вдыхать эти на котором эта транзакция будет обработано и отправляет на этот узел так а почему у него достоверную информацию о последнем шоу вася никто не гарантирует что достоверно и рассказывал про к частям так раз не сойдется она недавно deapool я описывал алгоритмы как проверять так что она может не сойтись вот но если мы например через один через через один и тот же узел запускаем транзакции сеть то она будет достоверно потому что она обновилась от предыдущие транзакции которую вася в эту сеть записал я понял об одном это patooties но уже то что плюс баланс ушел петь и это уже не так страшно важно вот как раз идеи о том что поступающие средства они как раз и дочери завершил могут идти через завершил консистенции то есть они просто так пишется а потом уже через этот асинхронно расползается по всему кластеру в каком месте атомарный может royal то что у вас все еще есть деньги что но нужно же ваши чтобы вовсе не было минус 5 долларов ну да так идея заключается в том что когда транзакция а начинает выполняться на том узле на котором он амортизируется как раз логика обработки транзакций это мы сами то можно проверить да там ну все данные в таблице той берутся потому что мы уже проверили что эти то данные актуальны сравнив каши и просто эту транзакцию обрабатываем или не обрабатываем еще другой стороны короче вопрос такой вот дня сомнение вызывает момент переключением на вторую инфраструктуру то есть предположим у нас нарушалась связность внутри системы и мы должны переключиться на вторую инфраструктуру для этого мы должны всем узлам сказать перестаньте принимать транзакции но связанность уже нарушилась начну можем кому-то не сказать перестанет принимать раздать или время транзакцию да хороший вопрос но я несколько по-другому поскольку я немножко балансировка занимался к этому подхожу что если мы ведь то есть как я показывал схеме узел через который транзакции попадают в сеть и он видит получают информацию о том что как эти транзакции обрабатываются то есть мы можем просто этот узел отключить как минимум потому что туда через него не проходит а и а также мы можем ориентироваться на счетчике ошибок то есть если мы видим например что начались ошибки на этом узле то он сразу же уходит в офлайн ты самый просто веселый способ это например сделать два успев маршрута которая вот будет анонсировать в каждой системе вот такой узел если один будет скатываться в одну какие то проблемы будут обнаружены то мы просто берем будем отключать его испив анонсы весь трафик будет автоматически тут же уходить другую систему просто мне казалось что номер узла определяется как раз hашем на котором должна быть выполнен транзакция еще раз то мне казалось что исходя из вот этой конструкции нарисованные до исходя из кэша транзакции определяется на какому взгляну должна быть выполнена одного узла через который входит транзакции как сейчас я поясню что на в другой инфраструктуре запасной на котором мы переключаемся там настройки абсолютно те же системе то есть это фактически зеркальная копия текущей инфраструктуры вообще на самом деле а когда я занимался вопросом именно отказоустойчивость это очень сильно завязана на размер этого кластера вот там есть вообще разработка от когда искать решения по отказоустойчивости она очень сильно завязан на то с какого размера система у нас есть и поэтому это не не просто так этот пункт был как сказать упомянут в будущих работах и в данном случае вот то что я сейчас говорил это для небольших систем где-то наверное до сотни узлов можно сделать вот но если еще какие-то вопросы есть оставил я вижу по глазам то я вот буду здесь добрый добрый день спасибо за доклад очень интересный есть небольшой вопрос небольшой а как вы боретесь с убитыми цепочками с какими сбитыми ну вот у вас был один из слайдов на котором была изображена что на одном здании втором узле были только номер 2 цепочки да то есть последние 2 cache и а 3 не было вот таких случаях это же ведь счет клиента сейчас я поясню там основной нюанс заключается в том что то есть вы имейте ввиду что если данные были целенаправленно удалены до все верну то есть по какой-то причине вот не находится там транзакции номер три да то есть каким то образом нужно восстановить то есть как вы это делаете проходитесь по всем народом ну по всем узлам либо технол сару из если мы не можем гарантировать целостности базы данных вообще никак то есть то есть мы допускаем то что кто-то мог туда зайти вот и данные какие-то удалить то это контролируется ну такая задача довольно тривиально то есть мы видим такую проблему что транзакция прошла потом следов в системе нет то значит нам нужно эту транзакцию откуда по не на полу пологом поднять говорю что вот этот промежуток данных между публикования my когда мы генерим эту цепочку это как раз он происходит в доверенным окружении то есть как раз сейди и потому заключается из мы говорим даже опять же о том потом могу сказать"
}