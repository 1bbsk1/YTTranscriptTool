{
  "video_id": "g_NVpx35IHE",
  "channel": "HighLoadChannel",
  "title": "Какие архитектурные решения в Яндекс Go позволяют запускать десятки продукт.экспериментов/О.Ермаков",
  "views": 2155,
  "duration": 2534,
  "published": "2023-04-28T06:19:53-07:00",
  "text": "а смотрите перед тем как я перейду к смысловой части доклада Я бы хотел задать небольшой контекст О чем я буду говорить начну Со следующего Я работаю в Яндекс голос 2018 года вот я работал над большим количеством разных продуктовых проектов связанных как с тарифами как суперапом так немножко успел поработать над самокатами большое количество разных областей а весь мой рассказ будет крутиться в контексте вот этих двух приложений это Яндекс го приложение для пассажиров для тех кто хочет заказать еду лавку и Яндекс про приложение для водителей и курьеров и тут несколько важных фактов это то что у нас несколько сотен заказов в секунду приложение запущено в большом количестве разных стран и то что мы используем микросервисы активно используем микросервисную архитектуру в зоне ответственности каждой из команд десятки микросервисов Я из продуктовой разработки и есть очень важная особенность продуктовой разработки а именно то что все проекты которые мы запускаем это гипотеза мы не уверены в том что они Должны развиваться именно в таком виде и порядка 80 процентов гипотез не развиваются по результатам экспериментов это такой субъективное число которое я там в своей голове держу но вы можете поискать в интернете информацию о других сервисов например booking говорит что у них порядка 90 процентов гипотез не развивается дальше и из этого вытекает такая сложность продуктовой разработки то что продукт это противостояние того что нужно делать быстро потому что мы ничего не знаем все гипотезы нам нужно понять В каком направлении мы будем развивать архитектуру и нужно с другой стороны делать качественно Ведь все что мы делаем видят пользователи нам нужно предусматривать многоступенчатые фолбэки нам нужно не замедлять приложения нам нужно делать что-то что мы можем переиспользовать в дальнейшем и вот как раз в рамках текущего рассказа Я наверное сконцентрируюсь именно на правой части то есть Нам нужно делать качественно Какие платформенные решения мы реализовали да И тут еще такой контекст в целом команда разработки делится на команду которая развивает продукт и команда инфраструктуры вот тут может быть покажется немного парадоксальным то что я из команды продукта рассказываю про инфраструктурные решения но мы являемся заказчиками и наиболее активными пользователями этих инфраструктурных решений поэтому я бы хотел подсветить некоторые особенности того как приятно использовать те или иные полученные решения и как следствие цель презентации это поделиться вот этими платформенными решениями как реализованными идеями так и мотивации к их созданию и вот как раз в рамках встречи я планирую пройтись по трем пунктам первое рассказать немножечко про микросервисы прям буквально на пару минут блок про то до какого состояния использования микросервисной архитектуры Мы дошли второе я расскажу про паттернатигиэтвей как мы его используем как мы его реализовали и в конце остановлюсь на платформе экспериментов поехали начнем как раз с микросервисов Я на слайд вывел паттерны Криса ричардсона который он показывает на своем на своем портале на ssio что здесь хочется прокомментировать есть достаточно большое количество материалов информации о том как использовать те или иные паттерны в чем боль даже вот предыдущий доклад отлично покрыл всю информацию о том как использовать микросервисы и хочется отметить что путь Яндекс в этом плане не уникален И основная ценность которую я вижу вот Ну в блоке про микросервисы в Яндекс это рассказать о том как эволюционировала система как мы использовали когда мы внедряли те или иные паттерны то есть вот на примере паттерна Монолит или микросервиса когда ты читаешь эту информацию достаточно тяжело сразу же понять ну а в какой момент я должен применить тот или иной паттерн поэтому кажется основная ценность это рассказать про то что мы уже сделали и в какой момент просто путь который прошли и как раз Я вывел Ну такой своего рода таймлайн слева 2018 год когда я пришел в компанию и 2022 год это тот момент когда мы уже до какого состояния дошли посередине блоки приблизительно распределяются по годам Я не стал специально концентрировать на конкретные года и вот желтым выделено количество микросервисов в зоне ответственности там команд то есть в начале в 2018 у нас было совсем немного микросервисов мы все еще активно писали в Монолит мы имели отличную инфраструктуру для того чтобы создавать новые микро сервисы и изолировано смотреть на них были прогоны тестов мы могли спокойно релизить эти микросервисы у нас в одну кнопку заводились базовые мониторинки сервиса мы видели количество успешных ответов количество неуспешных ответов сервиса а дальше мы пришли к такому состоянию что внутри Яндекс го появился фреймворкью сервер который недавно совсем коллеги из платформы за Open Source или мы столкнулись Естественно с проблемами межсервисного взаимодействия начали активно внедрять serkat Breaker мы все еще активно трогаем Монолит но начинаем его потихонечку распиливать причем сразу отмечу что мы распиливали только критичные кусочки которые на которые зависят цикл заказа и при этом мы сразу такой спойлер Монолит у нас до сих пор живет то есть мы не распиливаем его в ноль мы по сути вынесли только критичные вещи и в это же время у нас появляется Framework для экспериментов который мы активно используем в всех наших продуктовых задачах дальше у нас появляется аппетит вейфрендворк я про него буду рассказывать как раз чуть позже появляются первые сайты Car реализации асинхронных очередей экспериментов и мы активно внедряем В традиционную прокси в во все клиентские поинты и наконец вот такое настоящее в настоящем мы активно концентрируемся на надежности сервисов мы внедряем хаос engineering Control У нас есть фреймворк для асинхронного процессинга событий и улучшаем диагностику Вот про Монолит Я как раз немножко заострил внимание здесь опять же вот из паттернов Криса ричардсона он описывает Как нужно распиливать Монолит и важная часть распила это опегитвей которая позволяет вам по сути изолировать от внешнего клиента логику куда мы именно идем в Монолит или в наш Новый сервис детали тут рассказывать не буду заострил внимание Просто на том почему появился у нас там тот или иной момент вы и вот состояние на 2022 год здесь не все по сути решения Ну вот важно наверно понимать что наша клиентское приложение идет в традиционную про Ксю следом идет в API Gateway API Gateway может распараллели запросы пойти в тот или иной сервис в сервисах У нас есть толстые клиенты или сайдкары которые реализуют логику экспериментов конфигов логов мониторингов на самом деле много еще чего вот помимо этого есть инфраструктурные сервисы как раз для асинхронного асинхронной работы над событиями это вот проказ есть статистика и многое другое но вот опять же концентрироваться я буду в текущем докладе на двух паттернах это Вэй на данный момент он нас держит порядка 30 тысяч FPS Вот это 200 инстансов по 4 ядра и 8 ГБ оперативной памяти эти ресурсы с учетом возможностей держать нагрузку X2 То есть если у нас падает какой-то дата-центр мы все равно живем на оставшихся ресурсах и остановлюсь подробно на экспериментах которые позволяют сейчас нам запускать несколько сотен параллельно запущенных продуктовых фичей и начнем как раз с эпигитвея опять возвращаюсь к моему любимому ресурсу Крис Ричардсон и гейтвей классическое определение У нас есть какой-то единый единая точка входа для разных клиентов мы закрываем от Этих клиентов то с каким протоколом и в Какие сервисы Мы идем и по сути объединяем так или иначе ответ наших микросервисов изолируем их от клиентов и рассматривать наше решение мы будем на таком простом примере наши клиентское приложение идет Point 4.0 Stories хочет получить какие-то какую-то и над маркетинговую коммуникацию Раньше у нас эта информация была в монолите мы написали Наш новый энт Point выложили его в наш новый микросервис и мы хотим плавно переключаться по эксперименту по фича тогу в как раз Наш Новый сервис как мы подошли к решению этой проблемы для этого была реализована такая инфраструктура мы описываем походы в наши внешние сервисы в таком декларативном Ямал конфиге здесь есть два важных блока это sources источники куда мы сходим в Какие сервисы мы пойдем и response это как раз то как мы сформируем наш итоговый ответ в этих источниках мы как раз с вами указываем два наших важных источника первый это Монолит сверху такси сторис 40 Stories пост и снизу Наш новый ресурс Наш новый микросервис в который мы хотим идти по эксперименту это как раз вот вторая строчка кода сами ресурсы источники Мы заполняем в нашей такой отдельной админке что нам дает эта админка мы можем сразу же зафиксировать и о прозрачить то какие тайм-ауты ретраю этого источника мы можем сразу же там описать какую-то логику работы sirccot Breaker мы сразу же описываем там РПС лимитер и в том числе какие-то административные права то есть кто ответственная команда куда мы можем пойти если этот источник вдруг начал работать хуже и в итоге мы сходили в наши два источника у нас есть response и как раз по вот этому эксперименту по включенности источником Мы выбираем откуда взять тот или иной ответ пока в целом звучит Ну достаточно легко это как раз наверное одна из самых первых итераций как мы начали использовать такой паттерн теперь Чуть более сложные примеры я специально Взял старую старый дизайн шторы суперапа в этой шторе есть плиточки шорткаты это элемент шторы с оператора которые мы должны получить из разных источников У нас есть лавка еда есть Маркет Drive большое количество сервисов которые интегрируются в суперап мы для реализации вот энд пойнта которая дает эту штору с оператора как раз использовали этот паттерн апегитвей высокоуровневая источники выглядят таким образом то есть прям есть отдельные источники у них есть какой-то единообразный ответ который мы в итоге мерзжем чтобы отдать пользователю на этом примере как раз Ну пройдемся по каким-то усложнениям например стандартная история наш какой-то наш сервис за 500 все плохо нам нужно понять как отреагировать на эту проблему Вот так мы усложнили дальше паттерн появился появились блоки которые описывают логику фулбэка в случае если наш сервис лежит то есть вот наш ресурс купон шорткат мы описываем явно в этом блоке Fail полисе что мы будем делать если сервис не отвечает И декларативно описываем что Full Back в случае не ответа этого сервиса просто пустой массив шорткатов естественно мы можем описывать какие-то другие логики фолбека в том числе в том числе мы можем сразу же заложить в этот файл полисе логику брекера То есть если у нас сервис уже достаточно долго лежит Давайте может вообще не будем ходить в него сразу на такой ответ следующее что мы сделали это в том числе Ну упростили логику работы с кэшированием ответов то есть довольно частая история Когда у нас есть сервис есть and Point который по лица или слишком часто вызывается при этом мы хотим подмёрзнуть в ответ что-то что не требует частого обновления и мы просто добавили по сути новый оператор responscash который позволяет по разным ключам которые мы сами зададим это может быть Вот на данном примере юзер ради его сессия кэширует ответ на некоторое количество времени все это выглядит таким образом довольно простая схема есть сервис apegateway Он внутри умеет ну парсить такие декларативные конфиги сам этот сервис написан как раз на Ю сервере это его логотипчик он все сохраняет в какой-то кэш если нужно это для этого мы используем радиус и умеет ходить в разные источники естественный вопрос может быть что делать с этим сервисом он выглядит Как единая точка отказа в таком случае мы поднимаем просто разные кластеры разные сервиса который в себе содержит только ту логику которая допустим кричит для цикла заказа Или наоборот не критично и такие же кластеры мы поднимаем для других каких-то сервисов типа лавки еды и так далее и наверное последний паттерн использования pgateway Это бэконфоротент что это значит у нас такси может использоваться не только в основном приложении оно может интегрироваться в какие-то иные сервисы например вот слева это Яндекс карты и мы туда внедрили такси там показывается цена когда приедет водитель вот Или например веб-версия в таком случае опигии твои позволяет довольно быстро поднять новый Point который будет может быть немного переформатировать ответ но при этом брать данные из тех же микросервисов которые ходили мы перед этим и как итог такого блока про пегитвой основные паттерны использования рефакторинг Монолита в микросервисы расширяемые клиентские поинты и бэконфоротент и вот здесь как раз Профит который мы получили по сути мы смогли капсулировать и сделать таким единообразным межсервисное взаимодействие на Верхнем уровне это как раз уровень где мы взаимодействуем с клиентами мы упростили доставку улучшений То есть все ресурсы все пойнты которые используют такой аппетит вы Они могли итеративно эволюционно получать новые фичи которые мы добавляли в аппетит вы это допустим кэш это какие-то новые мониторинги Это фалбеки например сейчас мы планируем добавить логику работы такая единая точка которую можно активно улучшать и скорость настройки таких сервисов вот а обратная сторона медали о которой я ну вкратце расскажу это ну естественно и желание продуктового разработчика усложнить немножечко такую систему написать на ней что-то более сложное и в итоге мы получили некоторые вот такие конфиги работающие с паттерном аппегитфой сильно переусложненными то есть некоторые продуктовые разработчики некоторые команды начали писать там чуть ли не продуктовую логику вот мы здесь как скорее решали эту проблему выстраиванием процессов стали определять какие-то рамки того что Ну те или иные задачи не подходят под этот паттерн про платформу экспериментов здесь вернемся к изначальной постановке задачи что у нас есть одна сторона медали нам нужно делать быстро есть другая нам нужно делать качественно и вот чтобы делать быстро нам на самом деле нужно проверять это на разных пользователях получать какую-то обратную связь мы можем запускать на команде в тестовом окружении мы можем на команде запускать в прод окружение мы можем запускать на сотрудниках всей фирмы или использовать паттерн frienden Family приглашать знакомых друзей ну и конечно же нам нужно проверять на каком-то проценте пользователей но для этого мы используем такую платформу экспериментов это ее первая версия вот пройдемся просто по таким основным полям что нам нужно использовать по сути Вот это первая версия полностью транслирует то что я описал на предыдущем слайде есть какое-то название эксперимента мы это название эксперимента получим в коде если пользователь попал в него Здесь можно включить эксперимент выключить можно на пользователей задать задать процент пользователей задать команды Яндекс Яндекс такси можно по каким-то отдельным номерам очень простая реализация это простая реализация вполне ее даже как будто бы не нужно подробно описывать рассказывать вот ее можно реализовать простой библиотеке на уровне кода но при этом мы пришли к эволюции то есть вот предыдущий слайд еще раз на самом деле этого недостаточно когда сервис начинает стремительно расширяться у нас достаточно большое количество зон достаточно большое количество стран и не все фичи включаются просто по проценту пользователей нам Иногда нужно включить для какого-то конкретного региона или может быть для каких-то отдельных вообще полигонов города и мы начали усложнять систему Ну первое С чего начали это добавили возможность включать по каким-то версиям Но дальше Ну пришли Вот к такой модели работы с такими экспериментами есть какой-то какое-то место использования библиотеки в этом месте использования есть контекст который мы можем передать в систему например в данном контексте мы передавали какой-то фон ID мы передавали класс поездки передавали класс водителя зоны страны и как раз библиотека экспериментов позволяет сложными операторами логическими операторами или выдать любое сложное условие с помощью того контекста который мы передали Ну как это выглядит сейчас с точки зрения реализации у нас есть вот этот толстый клиент экспериментов который подгружает ту логику которую мы видели на предыдущем слайде То есть он кэширует у себя локально информацию о том какие у нас условия Почему этот толстый клиент потому что он в месте использования начинает эти условия проверять проверяет первую строку допустим не попали в эту выборку переходим к следующему условию и Допустим мы в это условие попали в эти 50 процентов и в этих 50 процентах в этой выборке мы вместе использования кода получаем свободного формата json то есть мы можем этот свободного формата json использовать как угодно Мы можем по сути разного сложности конфигурации задавать с помощью вот такой модели работать с ферментами и в коде это выглядит приблизительно так У нас есть консьюмер консьюмер это по сути строчка которая говорит о том в каком месте используем мы эксперимент То есть просто текстовая строка которая говорит о месте использования и по сути на основе вот этого консьермера мы фиксируем количество кварков типа кварков которые могут в этом месте появляться сами кварги это вот как раз те параметры которые мы можем передать в это место использования то есть на одном из предыдущих слайдов Я показывал фон айди тариф класс Ну вот конкретно в этом месте использования в этом коде Мы в кварге добавляем User ID добавляем Phone ID это какая-то в традиционная информация мы можем ее активно использовать в экспериментах и дальше мы как раз в этом месте использования из кэш-менеджера подгружаем все эксперименты которые есть в консюмере и получаем итоговое значение это по сути ключ название эксперимента вылью Джейсон свободной формы который мы можем использовать эксперименты в том виде который я описал до текущего слайда позволяют нам конфигурировать но достаточно важная часть системы Это еще подсчет результатов эксперимента для этого толстый клиент экспериментов все логирует эти логи мы выгружаем вть такое распределенное хранилище данных за один день использования экспериментов в сервисах мы получаем порядка 100 терабайт данных со всех сервисов мы сохраняем там информацию о том какие кварки были в этом месте использования например в данном случае Application Android application Brent и так далее и мы сохраняем эксперименты в которые попал пользователь то есть буквально ревизия эксперимента и какое-то значение выборки в которое мы попали в данном случае всё этих данных на самом деле достаточно аналитикам чтобы рассчитать те или иные метрики которые изменились в случае попадания пользователя то есть помимо этого мы естественно собираем информацию о том не знаю Какая активность была У пользователя сделали он заказ и сопоставив метрики и попадания в те или иные клозы мы можем получить какой-то результат аналитический вот здесь небольшое такое усложнение которое мы уже сделали из-за того что фичей стало достаточно много что эти фичи начали активно запускаться большим количеством разных команд и это переусложнение выглядит приблизительно таким образом таблица с наблюдениями это вот как раз логи которые я показал на предыдущем слайде Мы каждый день преобразуем в так называемые при компьютере я здесь не буду углубляться подробно что это То есть это такая промежуточное состояние данных где мы получили разные срезы метрик по пользователям сам процесс преобразования этих данных из таблицы с наблюдениями в при компьютере настраивает наш аналитик дальше есть Клик Хаус кликхаус Овер ить То есть это такой доступ к нашим при компьютер с помощью которого мы можем нашим сервисе abt получать просмотр тех или иных метрик промежуточных результатов эксперимента вот выглядит это приблизительно таким образом сверху есть две группы экспериментов которые вот ну по сути задаются на в тех же примерах которые показал на предыдущем слайде то есть какая-то контроль группа порядка там 40 процентов есть какая-то вторая группа тестовая и мы с помощью как раз сервиса отслеживаем наши критичные метрики то есть например количество уникальных пользователей в день количество заказов количество поездок и вот здесь хочется важно отметить что мы используем это не только для каких-то продметрик бизнесовых мы это используем в том числе и для технических метрик То есть например насколько долго отрисовывается селектор тарифов Как быстро загружается главный экран приложения поэтому основной Профит здесь приблизительно следующий мы с помощью такой системы начали запускать сотни параллельных экспериментов эти эксперименты запускаем не только для каких-то бизнесовых фичей и вот здесь Наверное такой самый важный момент что за счет оптимизации за счет упрощения таких запусков мы дали возможность дали инструмент разработчикам запускать эксперименты без предварительной помощи аналитиков то есть большое количество технических улучшений разработчики могут запускать самостоятельно и зачастую даже интерпретировать результаты вот ну в каких-то возможно сложных кейсах все равно приходится подключать аналитиков и данный инструмент мы стали активно использовать не только еще бизнесовых фичах проверках гипотез Ну и для например раскатки коммуникаций маркетинговых кампаний на этом все здесь готов обсудить с вами тему ответить на любые вопросы и пожалуйста Оцените доклад Спасибо большое Олег А покажи подарок за лучший вопрос хорошо Toyota Camry друзья Комфорт Плюс да да быстро пожалуйста Да спасибо за доклад вопрос Следующий когда рассказывали про API getway и рассказывали про то что на нем надо мерзнуть ответы от сервисов Да вот как это достигается потому что там же Или надо стандарт рисовать ответы от сервисов и тогда непонятно Как вносить изменения в эти респонденты Ну либо какую-то бизнес логику на сторону опегит вы помещать и он будет уже заниматься маппингом в зависимости от сервиса который отвечает Спасибо за вопрос Мы правда в начале сделали скорее такие простые операторы которые позволяют некоторые блоки ответов как раз стандартизированных как вот в первом варианте решения вы описали вот дальше стали появляться Чуть более сложные операторы которые позволяли выгрузить допустим конкретный ключ Ну по пути следования Джейсона и его уже использовать в том или ином ответе в respontia вот поэтому Да мы вынесли на уровень Вот таких декларативных конфигов ещё и логику работы с рессорными и позволили компоновать ответ вот но я про него не стал глубоко углубляться потому что как раз в конце упомянул что зачастую После этого мы получали такие достаточно большие конфиги и здесь вот такой очень тонкий лёд то есть точно ли это нужно именно в конфиге описывать или нужно перенести на уровень кода спасибо спасибо Вот Будьте добры Спасибо за доклад вот вчера был тоже доклад на тему оба теста фотозона и они рассказывали о том как уходили от как раз таки этого я к распределению логики и нагрузок Я так понял оба тестов именно на сторону самих сервисов А почему было принято решение именно вот такого горизонтального масштабирования геттвы и не Планируется ли как-то от него уходить дальше Спасибо за вопрос и здесь здесь кажется мне кажется два было разных блока то есть один про эксперименты в данном случае про эксперименты мы распределяем по сути нагрузку и ответственность заработать экспериментами по каждому из микро сервисов и в данном случае мы получаем достаточно хорошую масштабируемость с такой точки зрения То есть у нас нет единой Ну прям точки отказа которые переваривает все эксперименты у нас есть вот такие толстые клиенты распределенные по каждому из сервисов которые внутри переваривают эту логику сервис по сути только отдает информацию о том какие эксперименты допустимо в том или ином вот аппетит вы мне кажется все таки Ну не столько про сами сервисы сколько про возможность вот получать межсервисное взаимодействие и компоновать ответы под разные клиенты и в данном случае по сути масштабировались Вот описываем как я показывал на одном из слайдов просто поднимаем разные кластеры под под разные проблемы то есть допустим цикл заказа Мы для него подняли отдельный кластер в котором все живет изолировано и Работает спасибо спасибо Вот здесь на первом ряду двое сейчас Спасибо за доклад вчера был такой рассказывали что если вы хотите какую-то идею попробовать вы пишете на чем Вам удобно Если вы понимаете что идея выстреливает вы это все сносите пишите уже заново как бы ну с перспективой на будущее вы говорили что у вас баланс между сделать быстро сделать качественно вот как вы такой же идеи придерживайтесь или вас все-таки баланс в этом спасибо за вопрос Да быстро на коленках склепать чтобы курьерой мучились да да на самом деле очень индивидуально То есть у нас буквально каждый проект каждая фича Мы рассматриваем отдельно то есть вот прямо сейчас в моменте есть проект который мы там оценили по первоначальной оценке его делают Там почти полгода и естественно мы его не можем начать и делать правильно просто потому что у нас нету достаточного количества информации мы не уверены что он вообще нужен в таком виде пользователям и мы как Ну условно на коленках сделали то что ну прям выкинется но мы их сделали прототип который там через три недели донесем до пользователей и проверим вот при этом есть какие-то Ну иные кейсы Когда у нас уже есть небольшое количество информации и мы здесь соблюдаем баланс мы там не знаю закладываем в архитектуру какие-то идеи которые мы в которых мы уверены Вот наверное как-то так Спасибо за клад вот такой вопрос хорошо Вот вы запускаете сотни экспериментов никогда так не получается что эксперимент эксперимент он начинает мешать как вы отслеживаете что нет конфликтов Да спасибо за вопрос Это правда одна из проблем здесь мы на уровне самой админки экспериментов сделали какие-то предварительные такие проверки что у нас где-то соль сильно пересекается то есть проценты пользователей которые могут показываться пользователям и в целом есть еще все-таки предварительная работа аналитиков в случае если нам нужно допустим запустить какой-то крупный эксперимент Вот они могут заранее там подсказать что в том или ином регионе допустим Ну есть такой условно свободный слот куда можно запуститься или что нет достаточно большого количества пересечений не ответила технически это никак по сути не реализовано организационными мерами технически на уровне самой админки экспериментов Мы очень базовые проверки делаем то есть их недостаточно для того чтобы полностью принять решение быстро Скажите получается на входе пакетов которые мы еще не знаем по какому как будет обрабатываться этот пакет по какому маршруту он пойдет я так понимаю что там возможно альтернативные варианты Как у вас транспорт в этом случае реализован так понимаю тут какой-то тип динамической маршрутизации здесь идея приблизительно следующее что у нас на уровне как раз момента обработки запроса мы как раз определяем по тем или иным источникам В какой источник мы дальше направим запрос сам протокол взаимодействия с источником на самом деле может быть относительно любой вот главное потом после того как мы сходили в этот источник получить ответ его как-то интерпретировать я должен вам оставить время на выставку поэтому два вопроса вот Раз два и потом подарим Camry и можно будет спикеров дискуссионную зону отвести там до спросить пожалуйста Спасибо за доклад мне вопрос такой При таком количестве экспериментов Как вы вообще понимаете когда приходит соответственно какие-то тикеты от пользователей Да какой есть нормальное поведение приложения а где есть ошибка То есть получается что из-за такого количества экспериментов Да поведение приложения может быть непредсказуемым да это правда хороший вопрос и потом как вы их потом удаляете то есть отключить как бы можно отключить в интерфейсе Да а потом нужно за этим вручную следить как вычистить код от этого старого уже не нужно кода отвечай на первый вопрос мы если вот именно диагностируем проблему которая возникла у пользователей за счет того что у нас есть как раз исторические данные попадания пользователя в ту или иной выборку Да как раз здесь вот за счет этого мы можем диагностировать Что именно произошло то есть какие именно эксперименты он попадал в тот диапазон времени Когда возникла ошибка и что произошло при этом именно кейсов чтобы включение двух экспериментов параллельно создавала какую-то не знаю коллизию и состояние когда приложение абсолютно не работает у нас почти не возникало то есть таких проблем нету вот а второй вопрос был про а Про удаление до конфигов в данном случае сейчас мы Скорее это в ручном режиме делаем то есть ну условно есть какие-то процессные вещи то есть мы после продуктового проекта закладываем время на такой тех долг Спасибо за ваш доклад у меня стригирился на параде что разработчик Может выкатить свой эксперимент без участия аналитика и у меня появился вопрос первый кто генерит эти все эксперименты Так кому это интересно и второй как это обосновано для бизнеса там это наверное какой-то Ренди или как вы договорились И сколько времени на это закладывается также Спасибо здесь Наверное я не очень Как точно отметил тот факт что разработчик может скорее запустить технический эксперимент который допустим влияет на оптимизацию того или иного инвента на скорость загрузки каких-то экранов вот подобного рода эксперименты разработчик действительно может Ну относительно без лишнего количества запустить но если говорить именно про продуктовые фичи про связанные с бизнесом то Но в данном случае у нас есть достаточно большой отдел продуктовых менеджеров продуктовых аналитиков которые как раз Ну могут сформулировать то в каком направлении нужно развивать тот или иной Стрим в приложении То есть генерирует как раз гипотезы и вместе с разработчиками это все обсуждают и по сути всей команды идут в данном управлении Спасибо А вот вопрос по поводу как раз технических экспериментов там есть какое-то время то что разработчику видел я хочу попробовать Вот это техническое там лучший там сделать там более насыщенные логики и так далее так далее там какой-то лимит выставляется или просто даем свободу и потом снимаем метрики Сколько времени он потратил на технический эксперимент И сколько сам продукт это достаточно глубокий вопрос потому что в принципе вот баланс между продуктовыми фичами И техническими это ну сложная отдельная тема связанная наверное больше с процессами Мы в данном случае экспериментировали с таким вариантом процесса когда у продуктовых команд есть 10 процентов такой техно-квоты в которые они могут работать над проектами дальше есть довольно сложная задача перед разработчиком оценить В каком именно направлении ему нужно двигаться как ему максимально эффективно эти 10 процентов реализовать Вот и в данном случае также как из продуктовыми проектами есть ряд механик который позволяет быстрее проверить ту или иную гипотезу То есть например вот опять же с теми же оптимизациями чтобы понять какой именно этот Point важно оптимизировать мы можем запустить ухудшающий эксперимент который на очень маленьком проценте пользователей замедлит буквально там с липом работаю того или иного это требует как раз опробов то есть такие эксперименты разработчик не может по щелчку запустить на 50 процентов пользователей Вот Но это опять же вот такая работа гипотеза ничего не знаю нужно быстро проверить Олег кому подарим машину мне понравился вот вопрос Отлично Спасибо большое благодарим спикера друзья"
}