{
  "video_id": "uWWcCm5qWWU",
  "channel": "HighLoadChannel",
  "title": "Как переписать фасетный поиск с Solr на Elastic / Денис Сотников (Lamoda)",
  "views": 5515,
  "duration": 2906,
  "published": "2020-04-27T13:28:38-07:00",
  "text": "итак всем привет меня зовут denis я работаю в компании ламода и сегодняшний мой доклад в сегодняшнем докладе я буду рассказывать о том как мы переписывали последный поиск стал ареной ластик и зачем вообще мы это делали какую боль мы при этом испытали вот иди чего добились не так пожалуй начнем прежде всего нужно рассказать вообще что такое faced на поезд до для тех что они знают и проще всего объяснить это например вот так выглядит наш каталог когда вы заходите на сайт la моды и вот здесь я пометил красным это те фильтры которые выбирает пользователь или их можно еще назвать фасеты и зелененьким вот у нас обозначены эти самые продукты которые у нас получается в результате и фильтрации и выдачи то есть passed и и продукты то есть passed можно по другому назвать это как некий атрибут продукта с его множеством значений по сеты и продукты все что нам нужно для того чтобы рисовать эту страницу ok юзер зашел на страницу накликал какие-то фильтры как нам все это объединить и скомбинировать в каждом посетив есть группа значений которые он выбирает все они объединяются по или и между собой все эти кассеты склеиваются по и и комбинируется с результатом полнотекстового поиска и из и у этого собственно получается наш поиск и так какой у нас api для отдачи данных у нас есть наш сервис каталог он развернут в кубе ну как и все остальные наши сервисы написанного и у него есть эта пышная пия вот и две основные ручки которые нас сегодня интересует это фильтр лист и product list фильтр лишь возвращает нам фасеты те которые вы видели product list возвращает нам продукты кто взаимодействует с этим сервисом давайте посмотрим вот наш сервис каталог в него high 2 бэг-энда это backend сайта который у нас тоже написано go на дженги на самом деле тоже есть но основное сейчас написано go есть backend мобильное приложение они ходят плохо это тпф каталог каталог соответственно входит соло или в паз г с заданными ну еще на самом деле вариации русов но здесь мы не будем об этом рассказывать как вообще реализует passed на пояс как он ну вы наверное видели везде почти у всех онлайн-магазинов он есть и чаще всего технологии выбирают 2 либо сolor либо elastic обе они основаны на apache или семь это java open source библиотечка для поиска для фильтрации и для агрегации вообще откуда у нас появляются данные в нашем поздно подгрести xari нас есть ряд сервисов которые нам уж от данные это контент в которой даны попадают из фотостудии куда приходят товары их там фотографируют вот и после этого не загружается в контент у нас есть склад которая пушит данные о том что товар на изменился ну то есть товар привезли на склад и его количество позиций изменилось либо человек сделал возврат это же соответственно там количество позиций увеличилась и у нас есть наш сервис заказов это боб протас менеджмент вот который тоже умеет пушить данные ну резерв по товарам когда человек сделал заказ и все эти данные не попадают в наш апекс беговые это api guide вей то есть это такой большой толстый сервис как про который все знают который много чего умеет вот и который сам знает много прочего частности он знает про нашу библиотеку про нашу базу позарез сайта вую куда он пушит там порядка 17 миллионов уникальных товаров это что касается россии вот эти данные после под gresso высасывается solar мастером с помощью datakam пика там написан используется дата импортер для прогресса эти данные высасывается каждый час там настроен crontab и примерно там 45 50 минут он индексируется это реплицирует на слои вы вот со своего фати данные уже читаются каталогам и раздаются в кансай то и backend мобильных приложений и так зачем нам вообще нужен рефакторинг вроде предыдущая схема она как бы простая понятная чего не так в первую очередь мы хотим сделать машин ленин для персонализации каталога что это такое когда юзер попадает на каталог сейчас у нас используется некая сортировка ранжирование то есть мы хотим юзеру предложить те товары которые он который ему больше всего нужны которые ему больше всего актуальны часто тоже делается некой моделью которая там обсчитывается в ходу пи вот и мы хотим сделать машин ленин который будет работать прямо в угол тайме то есть пользователь приходит на каждый запрос мы будем там строить модель и считать в по ней скоро и соответственно какие-то товары там ну поднимать на папа выше выдачи вот соответственно там ну методы машины он никогда не там разные бывают способы вот эти расчета то есть там может быть одна форма может быть там целые деревья выбора вот и для всего для этого нам нужно скажем так иметь некую возможность чтобы это все спилить второй момент это у нас есть лак между созданием данных в какой-то в каком-то сервисе например там условно в том же контенте и отображением их на сайте то есть минимум это 50 минут потому что 50 минут сейчас у нас работает яндекс ну индексируется наша база просовывая solara ну вообще на самом деле то есть 50 минут это прям совсем минимум на самом деле обычно бывает больше вот потому что у контента там у них тоже есть какая-то своя кухня там своей очереди раббит им килтом пока все это про сосется в общем проходит очень много времени вот ну и третий пункт он конечно такое холивар ный но ограничить сильную зависимость между сервисами то есть избавиться такого сервиса год серво из пар который все знает который все много чего умеет вот такие вот примерно у нас были поинты и так и факторингом разобрались почему почему нам нужен нужно его разбить на две части вот первая часть это была заключена в том чтобы нам можно было построить какое-то масштабируемое решение для нашего машин ли они нга и для того чтобы выдержать предстоящий black friday то есть black friday все знаете это время когда проходит распродажи куча скидок акции и все пользователи там условно целый год копится корзину в 100 товаров потом приходит и за 5 минут нажимаю там применить выкупить общем и нагрузку порой бывает непредсказуема и то есть например в этом году верни в прошлом году у нас была такая довольно ровненькая довольно ровненький такой график то есть ну-ка там два с половиной а от дневного бывают случаи когда у нас например там полтора полторак а вот фпс и например под вечер то может быть резкий скачок the mix 4 например и вторая часть и факторинга нам нужно развязать зависимости между сервисами то о чем я говорил и стараться уменьшить время между тем когда там продукт или какую-то акцию завели где-то у себя в системе и когда она уже отображается на сайте это очень важно для бизнеса вот бизнес очень негодует когда он злой товары и условно не только отображается каталоге там через три-четыре часа почему мы выбрали ластик search ну в первую очередь потому что он легко скейлится из коробки то есть поддерживает шарды и реплики можно добавлять к вере ноды и все вот это вот второй момент это экспертизы у наших дата аналитиков которые нам считают все эти модели в частности сделали нам тоже новый поиск на elastic search вот третий момент это гибкая api которая позволяет менять настройки то есть я условно могу с помощью этих настроек пушите решает допустим насколько шар дав у меня будет залит энди индекс в этом время обновления у меня будет то есть какие то вот такие вот вещи решать там например какая там файловая система у меня будет использована на ластики и вот это вот все еще один момент это поддержка runtime скриптов то есть мы 1 request можем делать там все что угодно блогун там сортировать выдачу там подменять какие-то поля и вот это вот все и последний бонус это экспертизы в эксплуатации поскольку у нас уже есть elastic у нас есть логина ним то есть у нас используется ела галок стаж вот и было бы неразумным держать там и сола рэй ластик поэтому решили ну почему бы и нет давайте переедем на одну технологию так как мы меняем архитектуру вот картинка предыдущие архитектуры здесь все понятно об этом я уже рассказывал то есть есть а фиговые которые пушат все впг в салон мастер и на слои вы и вот это вот все в чем делаем первую очередь мы избавляемся от api г.в. он нам не нужен добавляемся да и when was even бас это брокера сообщений ну тыс шина данных которую мы реализовали на кафки вот и куда скажем так можно кушать различные ивенты в различные топике вот после него концу миром для этого этой шины данных выступает наш каталог контент который получает все эти обновления о том что у меня там поменялся продукта меня поменялся резерв там что-то и может быть бренда сменилось что-то такое он консью нет все эти данные и заливают их в базу далее мы убираем наш салон так ага при этом из каталог контента после того как он обновляет нам базу мы пушем этот айдишник товара freddy's тардис у нас здесь выступает качестве очереди можно на самом деле люблю другую очередь взять так он пушит айдишник товара очередь из этой очереди читает наш worker артикул товара высасывают эти данные и спас gresso и заливает elastic и соответственно салатика уже учитывает каталог и раздает всем нуждающимся вот какая-то вот такая вот у нас схема получилась и так и собственно вот то что я обвёл зелененьким это предмет нашего сегодняшнего обсуждения наш первый этап в первую очередь что читали когда мы решили приехать на elastic мы решили погуглить вообще ну если какие-то кейсы как лучше всего сделать и нашли вот такой вот статью частности она рассказывает о построении кассетного поиска в и cameras с помощью ластика и например и как раз таки online shop а с молотками насколько я помню вот мы ее почитали и основная идея у него была какая по поводу схемы данных то есть чаще всего традиционно схема данных вот этот ну так джейсон который есть в нем заводит прямо напрямую вот эти поля свойствами то есть например то что вот и видно выше то есть изготовитель там for this the hammer ну то есть вес молотка там допустим два килограмма в противоречие ну в противовес этому в этой статье предлагалось что а давайте-ка мы все вот эти свойства которые нам нужны для там фильтрации агрегации мы их разделим по отдельным структурам по сетов с каждым каждый со своим типом и будем туда пустит эти значения вот например string faced и мы сюда заливе летом manufacture и там без собственно изделия и вот например наш пример схемы какой ну этот маленький кусочек какой у нас получился то есть наш этот string faced у него есть type nested nested я здесь даже выделил дело в том что поскольку elastico соло ранено основаны на базе apache или 7 и они не поддерживают вложенные документы в массивов тыс он поддерживает только плоскую схему власти кита как отдельная фича сделан место документы и нам специально вот это ключевое слово указывается на указывается и в схеме и в самих запросах вот и году у нас получилось вот такие вот свойства которые мы туда залили то есть это айдишник какой-то тип интеджер name и какое-то саму значения и вот наш пример схемы который мы на на этом сделали то есть залили часть такая небольшая залили туда brand name с названием adidas значением и вот в номер faced например у нас получается высота каблука там условно 7 сантиметров так здесь вот не отображаются иконки ну ладно в общем окей схему мы сделали индекс заливать как-то научились как организовать апдейты доставку данных в первую очередь мы решили что в первое на первом нашем этапе мы сделаем такую же схему примерно как было в солоде то есть каждый час мы будем высасывать этот индекс заливать его и вот это вот все получилось примерно так власти есть такая фича как алиасы раз это условно ссылка либо псевдоним на какой-то индекс то есть чем в чем суть мы на самом деле не знаем конкретно на какой алиас допустим сейчас указывает на какой индекс сейчас указывает алиас вот но мы обращаемся к этому лесу для того чтобы записать данные вот и он внутри указывает уже на тот который нужен то есть мы условно каждый час заливаем индекс он в своем названии имеет таймс темп вот 12 и 13 30 и плюс каждые 15 минут потом подкручивается и обновляет данные касаемые позиции на складе вот когда приходит очередное очередное время индексации то есть вот 1430 мы начинаем это все заливать из нашего в рокера с помощью балка заливаем заливаем записи в какой-то момент понимаем что все данных не осталось вот и переключаем просто least этот новый индекс и таким образом у нас получается что мы словно downtime а получаем новые данные балок как я уже говорил заливаем и все эти данные с помощью балка что это вообще такое балка это по сути заливка бачей крестилась позволяет сразу несколько там сотен или тысяч и там записей за один запрос заливать и эту заливку на стороне приложения вы можете сделать синхронный то есть сделать условную с и в терминах там говорить годы или какого-то другого языка ты сделать какую-то очередь там в одну заливать какие то едишь ники за другой стороны вычитывать ее там pool water of будет заливать это власти все данные так но здесь нужно сказать отдельный момент то есть если мы с помощью вот этого механизма можем регулировать вообще поток данных которые у нас будет туда отправляться если его сделать слишком большим то мы увидим в продакшене примерно следующую картину то есть каждый час когда мы начинаем это заливать у нас начинает увеличиваться response time вот и по 95 по 99 перцентиль у соответственно поэтому здесь нужно найти такой некий баланс между тем между временем этой индексации которую вы хотите занят ну готовы отдать и response time который вы готовы пожертвовать вот это на самом деле не удачный пример этой эту порядка восьми вампиров заливал потом мы поменяли на 2 так дальнейший план нам нужно было реализовать наше получение продуктов протестировать нагрузкой затем реализовать получение фильтров через фильтр лист и протестировать оба методов соотношении 50 на 50 потому что для отображения страницы нам нужно и продукты и фильтр и соответственно так работа с легаси одну тут такое небольшое введение в общем сервис на сервис наш был написан нога там было порядка 40 тысяч строк как вообще работали ну то есть когда я пришел на этот проект в эту команду опыта с этим сервис у меня не было и команде было очень много много новеньких соответственно мы не знали ни предыдущий бизнес-логику нет вообще текущими ссора вниз ластиком вообще по сути никто не работал еще делали предварительный research то есть прям заводили себе этом тоски условно там на неделю по и серчайте выписать там все декомпозировать на делается датчик соответственно по результаты этого делали ты сделали итеративный подход начала запилили сам метод который словно был пустышка добавили там допустим ну папа парочку полей которые мы можем уже как-то выбирать оттуда зарелизили там писали функциональные тесты покрывали чтобы нас ничего не ломалось и вот таким вот подходом потихоньку добрались реализации что мы хотим видеть с точки зрения нагрузки таки нам нужно поставить верхнюю планку которую мы хотим достичь x4 а дневные нагрузки иная нагрузка наша было примерно 900 ну там в 850 в пике 900р ps я округлил примерно 2000 ii x4 это у нас получилось ну примерно 4 крп с вот и мы хотим уложиться в девяносто пятом перцентиле 150 миллисекунд вот такие у нас были требования так пошел первый обстрел кластер мы собрали так чисто эмпирически поставили туда 6 data not поставили ты шарда факторы облигации 1 и начали стрелять и вот чего мы добились наш результат был примерно 1000 с причем от по графикам внизу это вот процентили видно что после 1000 gps у нас начинались уже такие тайм-аут и еде нас делать нам где нас пятом перцентиле которые там долетали до 2 до 4 секунд и очевидно что это было для нас неприемлемо чё делать нужно спилить кластер но прежде чем стерлядь классе и можно вообще понять какие типы not бывают в кластере ластика есть три роли которую вы можете навешать на каждую из нот можете навешать там даже при на самом деле роли первая роль это роль мастера этого он отвечает за управление по за поддержку кластеров работоспособном состоянии и также если произошел какой-то networks плит или но да вообще ушла в небытие то есть он состоит голосование за выбор нового мастера далее у нас роль идет дата это хранение данных и собственно агрегации фильтрации 3 роль это и джесс это при processing индексации то есть когда вы заливаете балкам все эти запросы они попадают на и джесс ноду вот как-то там трансформируется при процессе и после этого уже собственно заливается надо то ноду и 4 роль это такая условная роль это отсутствие вообще всех ролей то есть когда мы не ставим не какую роль у нас получается по сути лот был интер который рауте запросы и агрегирует данные так сколько брать чертов опять же когда мы начали всю эту историю с келли вот были разные мнения что давайте там сделаем я говорю давайте сделаем два шага нам хватит за глаза abs и говорили давайте мы сделаем там десять шагов или 20 ну в общем понятно дело что споры ни к чему бы не привели поэтому наши ребята потратили там пару дней и пособирали разные конфигурации и выявили примерно следующую взаимосвязь то есть здесь у нас внизу подпись и тех запросов которые мы отправляли но это на самом деле не столь важно поскольку здесь почти везде видна одна и та же закономерность то есть когда мы на условно одном и том же мощностях увеличивали количество she родов у нас снижался response ставим но здесь вот какой момент то есть если мы допустим добавляем одну ноту там 2 до 3 то у нас падения response time она такой довольно ощутимая чем добавление каждый следующий но да но уже становится менее эффективный вот и здесь видно что сама эффективно это было десять шагов вот ну из-за эффективности мы решили что ну давайте возьмем нечто среднее и взяли 6 шагов и так взяли 6 шарда фуке и договорились кластеру нас получился мы добавили 18 data not 6 рядов факторы облигации один добавили 5к were not и еще abs и попросили добавить 3 к прокси для того чтобы проще было конфигурировать кластеру проще было добавлять новые ноты из скрывать за ними адреса и так мы все это сделали начали стрелять и о чудо мы вышли на цифру в 5000 rp с причем мы вложились по всем параметрам вот и кажется это был успех почти мы уже практически расслабились и так похудела собственно сделано мы реализовали получение продуктов протестировали нагрузкой и теперь нужно реализовать получение фильтров и протестировать это все как реализовать фильтр лист то есть фильтра лист это получение faced of ключ к пониманию того как строится эти пакеты это ггц навигация это нахождение всех возможных значений и их счетчиков для всех тех фильтров которые мы хотим видеть самом верху для всех значений которые нас интересуют в этой фильтрации вот например вот пример здесь у нас есть верху вот размер цвет когда пользователь нажимает на каждый из них он получает множество вот этих значений и счетчики по ним сколько этих товаров есть допустим заданным размерам или заданным цветом так как мы это делали на эластики первоначально наша реализация нас есть некий запрос который мы туда отправляем в общей к вере мы засовываем фильтры которых условно который пользователь памяти у которой он хочет видеть например здесь это он выбрал два размера то есть 3741 и поставил цвет белый и в верху соответственно самих облигациях мы это все оперируем по двум полям вот такое была наивна или отцы после того как мы это запустили и начали постить на сайте оказалось следующая вещь что все те фильтры которые были помечены пользователям они давали правильную информацию по своим счетчиком а все не выделены они оставались по нулям почему так происходило происходит это по следующим соображениям когда мы делаем такой запросто мы фильтруем по всем тем параметрам и которые пользователи нам поставил и в результате выдачи у нас получается только те товары с выбранными атрибутами то есть с размером с цветом и когда мы по не могу героем мы получаем только именно те товары с тем размерам и тем цветом который выбрал пользователь вот очевидно что нужно было поступать по-другому поэтому мы поделили агрегации на разные группы власти кассир очень мы можем делать множество агрегации и в каждой из них кричать свой фильтр то есть по сути в каждом выбранному по сети нам не нужно фильтрация по самому себе то есть если у нас есть passed с размером нам не нужен в нем фильтр по самому этому размеру естественный для цвета также для цвета нам нужны фильтры все кроме этого цвета ну и остается еще одна группа агрегации это не вообще не выделенный passed и то есть для них для всех включаются все фильтры вообще и так и вот примерно как-то выглядит то есть вот у нас две группы агрегации здесь мы говорим что мы хотим реагировать по цвету например вот слева и фильтровать по размеру по всем выделенным и тоже самое по размеру мы хотим и кодировать по размеру а фильтр мы проставляем только для цвета и в таком случае у нас получается все ок с выбранными вот этими товар это счетчики у них считаются и так каким-то образом мы там все это уже за это медь или сделали этот фильтр лист настало время для тестирования та же самая конфигурация мы начали обстреливать вот и каков был наш результат 250р ps после напомню 5000 вот это была маленькая неожиданно мы были демотивированы я уже начал думать что давайте-ка за им применим пакетный поиск сами напишем там на гол в чё там в принципе месяцев работы ну отогнали эту мысль прочь и решили все-таки поковыряться части можно сделать очевидно было что такая посадка была собственно из-за нашего второго метода начали думать начали изучать запрос и увидели следующее в каждой группе агрегации у нас было были повторяющийся фильтра то есть когда мы получаем эту выдачу мы хотим всегда видеть те товары у которых есть позиция на складе больше либо равна единице и мы хотим видеть те товары которые мы условно вообще сейчас готовы продавать вот эти фильтры из села был throw и quantity у нас больше либо равен единице все эти повторяющиеся фильтры мы вынесли из агрегации и засунули в карьере всего запросов вообще вторая история мульти feel the gay гей шин то есть когда мы получаем эти фильтр и нам на самом деле нужно не только значения но и айдишник этого фосетта а газировать напоминаю мы можем только по одному полю как вытащить два поля сразу допустим у нас есть а иди и name ну первый вариант это можно сделать 2 вложенные агрегации то есть сначала мы оперируем поедишь нику и следом вложены двигаться у нас будет по вылью второй способ как это можно сделать это top hits что такое top hits то есть когда мы выгребаем ну то есть когда мы кодируем запросе все наши документы top hits позволяет то есть он содержит список этих агрегированных документов и позволяет выбрать там 1 этом н из них по скоро вот соответственно нам нужен поскольку у нас там связка и гибли сны им она по факту уникальная поэтому мы можем условно применить этот по птиц вытащить один документ самый топовый из него вытащить этот name но когда мы начали локально все это тестировать и пожарьте казалось что это все очень медленно сейчас этим делать ну мы придумали такую штуку поскольку у нас эти блесны им уникальные мы решили сделать одно дополнительное поле в которой будет входить конкатенация нужных нам полей то есть это айди некий сепаратор и вылью мы будем агрегировать по этому полю и разделять это уже все на уровне приложения вот мы поменяли примерно 30 процентов схемы чтобы понять вообще в том ли мы направлений движемся или нет ее запустили наш обстрел и о чудо это помогло после обстрела мы выяснили что мы можем выдержать уже вполне себе тысячу ps они 250 как было раньше и это я напомню мы еще поменяли только 30 процентов схемы 1000р ps это конечно хорошо ну вот но нам нужно двигаться куда-то дальше я напомню нам нужно выдержать границу 4k что делать ну очевидно abs и начали говорить что давайте еще постелем них появился такая скажем так они зарядились всем этим проектом и такие лет ну давайте добавим еще больше железа ok давайте добавим добавили получилось у нас 6 шар дав фактор репликации 4 мы поставили уже 10 not вместо семьи и добавили data not сделали их равным 30 ну после этого мы выяснили что 2500 мы можем выдержать вот и по 95 перцентиле мы опять же не пролезали а также в этой конфигурации мы нашли очень интересную штуку если вы посмотрите на график вы увидите что в какие-то моменты у нас начались проседания fps и внизу также синхронно нас начинали увеличиваться тайм-аут и чистим делать у меня опять в мыслях появилась выдавать все таки напишем свой поиск closed на чё там ерунда вопрос вот ну нам не дали этого сделать вот нам пришлось ковырять почему такое может происходить смотрели смотрели графики и в итоге раскопали вот что refresh interval казалось бы причем диск refresh interval ну давайте разберемся общее что это такое refresh interval в каждом яндексе есть такое понятие как и фарш интервал и она по сути влияет надо на этот интервал между тем когда мы залили данные в яндекс и тем когда они уже появились поисковой выдачи по умолчанию этот параметр равен был одну секунду мы его тогда они стали настраивать поскольку еще не понимали чековый как вот и в чем здесь может быть причина с этим собственно refresh interval почему он дает такие просадки вот здесь пример ответ весь в называемых recent сегментах что это вообще такое то есть ли син сегмент это естественно корни его из папа chili sin библиотеки вот когда вы индексирует и какие-то данные у вас получаются неполный индекс а такие вот мини индексы которые он делает эти мини индексы потом сливаются когда их становится слишком много что произошло в нашем случае refresh interval у нас был поставлен по дефолту на одну секунду то есть и напоминаю в продакшене мы мы тестировали вернее все это в продакшене то есть во время того когда у нас делалось обновление индекса когда у нас держал или все то теперь ты индексы к нам и поддерживали инка ментально все те товары у которых изменился резерв на складе вот и каждую секунду когда elastic как бы управлял эти данные в поиск у нас рождалось очень много вот этих песен сегментов какой-то момент эти сегменты начинали объединяться начинался миша мер и вообще это довольно таки дорогостоящая операция вот что мы собственно и увидели наши графиках то есть у нас были просадки у нас был тайм-аут и вот я там не стал показывать на самом деле были всплески тоже по циклу так мы поняли в чем дело вот ну и мы поставили пять минут refresh interval то есть ну это такой некий компромисс с которым вам нужно согласиться то есть можно поставить побольше но тогда когда вы будете обновлять данные вы будете дольше ждать чтобы увидеть их в своем поиске так еще один момент по поводу оптимизации когда мы все смотрели к нам прибежал в один из отцов которые у которого очень хорошая экспертиза власти к посмотрел на нашу схему готовят у вас тестов документа я тут где то читал что они не очень хорошие мы такие ну да ладно вот и он накидал пример там с несколькими полями с несколькими запросами посмотрели но у него там разница конечно было такие довольно ощутимую то есть ну вот и раза наверное в этом и такие решили ну конечно мы не хотели избавляться от этих местах документов потому что все-таки это прикольная фича когда они нужно менять схему когда ты условно залил какие-то общие там ты и группы и в них просто добавляешь нужные документы вот но мы решили попробовать почему вы не давайте поменяем давайте развернём это все в плоскую схему ну и вот пример здесь то есть допустим на свойства страна производитель swahili сша мы развернули это в плоскую такую схему вот уголь это же опять мир на 35 процентов запустили на тест и вот что у нас получилось те же самые 2500 fps и у нас существенно почти на 100 миллисекунд уменьшилась время ответа наша испанцами мы подарим это неплохая история надо двигаться дальше ну то есть мы нащупали уже какие-то эти все вещи поняли что наверное это она после этого мы уже начали приступили к финальной стадии оптимизации начали оптимизировать остальные 70 процентов схема на вообще конечно была довольно большая поэтому поэтому мы собственно и двигались так по шагам ты сначала сделали там тэсс процентов по кости они посмотрели что да мы движемся в верном направлении вот теперь да оптимизировали остальное убрали в сортировке тоже наши насчет поля это очень тоже сказалось на нашем перфомансе и получили в итоге вот 3800 fps и по 95 перцентиле у 130 50 секунд вот такая вот история какая у нас была дальнейшая работа после всего этого ну нужно собственно сделать второй этап и факторинга то есть перейти на асинхронный обмен сообщениями избавиться от зависимости между сервисами вот и сделать инкрементальный индекс то есть избавиться от этих часовых когда мы по крону настраиваем часовых вот этих индексацией и поддерживать сил в процессе в процессе поступления данных вот ну и как я уже говорил все это тоже порождает lucent сегменты вот поэтому возможен нам для этого придется использовать for смерш пока еще не знаем посмотрим как это будет вот ну и какие выводы такие картинки можно сделать ну шар был у нас в нашей схеме уменьшили response times то есть чем больше тем меньше но тут опять такое тоже момент если слон на одной и той же конфигурации невозможно их там увеличивать бесконечно и получает там всегда какой-то выигрыш то есть ну закон сохранение энергии на все равно есть вот поэтому какое то нужно найти оптимальный вариант добавление реплик позволяет повысить количество fps которым мы можем выдержать много лисе лисин сегментов эта проблема их вершит и еще хуже следующий момент это не стоит поля не так уж хороши как мы про них думали вот ну и в целом нагрузочные тесты которые мы проводили практически каждую ночь продакшене очень здорово нам помогли и помогли понять нам вообще в какую сторону стоит двигаться и что вообще стоит оптимизировать вот такая вот история вот ну и собственно настало время для ваших вопросов здесь вам понравилось спасибо за лекцию очень интересно хотел спросить а вы пробовали смотреть стороны сфинкс сравнивать нет не пробовали у нас была идея с сола клаудом вот то есть ну мы посмотрели что он есть вот но как я опять же говорю у нас очень такая большая кстати за власть таких других отделов поэтому нет даже не стали смотреть вот real-time индексация вы еще не пробовали да в каком то виде она сейчас ну то есть мы начали ее делать вот то есть мы сейчас вычитываем эти винты из shinee вот но обновляем базу но обновление индекс пока еще не делали то есть это еще предстоит нам они пробовали использовать например mongo db и там есть тоже вместо поля можно использовать индекса на них наверное да да я знаю тоже рассказывали про это но у нас манги вообще нигде в компании нет а то мы стараемся сократить скажем так разнообразность нашего зоопарка технологий вот поэтому нет ну и плюс там есть некоторые геологи у нас компании которая не любит мангу вот поэтому это было бы проблематично поверхность пасе выше большое спасибо за доклад вопрос следующий у вас все атрибуты находятся в вы ластики или ну то есть passed и можно построить во всем чем угодно или ваш бизнес говорит вот мы хотим уметь строить по таким-то атрибутом и вы только эти атрибуты запихиваете и не раздувается ли ластик и если нужно больше и как вообще за ним следить и ну смотрите на самом деле дал бизнеса есть такие требования что он не хочет видеть все атрибуты то есть у нас есть список определенных атрибутов более того я могу сказать что этот список атрибутов он разница от категории категории то есть у нас есть так называемое сейчас забыл как мы их называем кастом фильтры то есть когда то есть в одной категории мы допустим хотим видеть какие-то фильтры например сейчас даже придумать не могу на природ там есть большая разница между товарами косметики например и обувью вот поэтому у нас там до маленькой не просто вот то есть мы какие-то атрибуты скажем так засовы власти какие-то нет по поводу вопрос был связан раздувается или нет да сама собой раздувается мы стараемся этому противится но бизнес есть бизнес у него есть какие-то определенные требования которые он хочет реализовать вот ну какой тут вариант ну на доске или канада дальше все этаж радировать вот выход только один спасибо за доклад у меня 2 вопрос на самом деле finger death на правильно ответили ли во второй . короче вопрос 1 nested атрибуты когда вы рассматривать ту схему типа с обычно ровная схема и nest я немножко пропустил в чем как вот плюс н с т а в чем плюсы да то есть в этой статье он рассказывал на самом деле несколько плюсов один из которых что вот условно когда у нас есть плоская схема и у нас есть например вот одни и те же скажем так значения да ну их надо использовать по разному то есть одно какое-то значение мы хотим использовать там для агрегации например еще какой-то поле мы хотим использовать например там для поиска вот и поэтому он собственно выделял вот эти вот скажем так различные структуры то есть отдельно структурка там с валетами отдельных структур к там с какими-то поиском куда-то же эти значения входили вот и еще один из его поинтов был в том что когда мы заливаем такую схему да то есть мы хотим допустим условно настраивать да и это есть где-то определять что это мы хотим индексировать это не хотим то есть нам нужно вот это полностью описание схемы вот и случай если мы добавляем новые поля эту схему приходится менять и перезаливать то есть в нашем случае например когда мы каждый час там перри заливаем этот индекс нам как бы это не страшно потому что мы заливаем фактически новые схемы у нее заталкиваем новые данные вот этого но потом это довольно проблематично менять эту схему поэтому он предложил давайте мы сделаем такие общие структуру и в них просто будем данные добавлять и все смотрите у меня поправьте если что-то не понимаю вроде как власти кисть такая штука как темплейты которых можно стараешься папа такой-то маски такие тополя буду давить то типа файла все что как бы надо может сделать пост и нечего переживать не надо ну может быть когда мы вообще выбирали всю эту историю то есть с ластиком и не очень были знакомы мы там скажем купились на эту статью до то есть который рассказывал все это почитали и в принципе нам показалось что это og ну посмотрите вот стану 2-х второй вопрос почему не сразу real time почему вот вот эти вот с окнами кадры вытяжной совы и да почему не кого-то им дело в том что вот когда мы добавили давайте может быть пролистаю чтоб было понятнее на саму схему так долго ли стать вот когда вот здесь мы убрали а первые поставили вен бас у нас для того чтобы нам получить все эти данные нам нужно очень много ивентов то есть нам для этого эти винты они должны спускаться из собственно вот этого контента вот есть там ивентов на самом деле ну очень много то есть обновление бренда обновление продукта категории лэйбл af акций и очень много всего эта работа такая не быстро поесть и тому моменту когда мы это все разработали эту пилотную схему у нас со стороны контента еще не было ничего готова ты соответственно мы могли бы это сделать на данные нам не прилетали бы вот но они по-прежнему на самом деле еще не до конца все прилетают и сейчас там уже ведут финальные работы то есть там фактически осталась там пару винтов которые нам нужно поймать вот ну и мы со своей стороны начали уже в каталог контенте тоже это все делает есть у нас уже делается там обновление резерва обновление брендов категории еще чего-то но общем какая-то работа стала сет все не быстро это вот в течение там наверное года это все делалось пока мы пилили у фи сет на пояс то есть на тот момент не было готово то есть оправе понимаю что dio проблема во первых то что лэнс басс как бы был не до конца имплементировать и во-вторых то что у вас прям очень много изменений да окей спасибо здравствуйте спасибо за доклад и я бы хотел спросить вот именно по этой схеме я так понимаю вашу проблем можно было решить просто заменив а лорной ластика зачем здесь менять ременной архитектуру вашего great white api говори да да то есть даже вот сейчас вы ответили что совсем была проблема что нет каких-то данных может быть ну конкретно я хочу слышь какой плюс от того что вы за днем поменяли важной двойная до ответ такой то есть у нас ну вообще вся эта история как я уже говорил на такая холивар на я вот но смотрите когда у нас допустим есть одна почка да допустим тот же самые пиковые в которой мы работаем и примеру у нас есть этот световая база с множеством продуктов и на самом деле эти продукты их хотят читать ну много кто то есть например на шерегеш ники которые составляют по этим продуктом рекомендации там наш маркетинг который делает выгрузку всех этих продуктов на рекламные площадки то есть ну очень много кто хотят потреблять эти данные вот и здесь вариант то есть ну вот в этой схеме до предыдущей то здесь вариант 1 что-либо пеговой будет писать им во все эти базы вот либо они все будут ходить например в наш каталог и ну на мой взгляд это не очень хорошая история вот потому что к нам приходили например ребята даже и там и склады и говорят а давайте мы к вам походим в каталог вот ну то есть мы такие ну а зачем меня больше конкретный вопрос я так поняла можно было бы решить проблему перевода сорной власти без рефакторинга ну вообще да не пролить их не было ну вообще на самом деле да еще вопрос работа ранжирование она применяли ранжировать и если бы вы использовали nester поля как бы вы применяли ранжирование ранжирование но сортировка у нас применяется вот и до этого у нас скажем так ну у нас есть определенные группы как это правильно сказать скажем так группы выборок что ли вот есть когда к нам приходит пользователь мы понимаем какой группе он относится и у нас есть для каждой группы посчитаны скоро для каждого товара вот и когда мы ранжируем вот у нас как раз таки вот эти 40 факторы как они называются они были в этих местах документах вот ну и как там делается сорт и указывается там не стыд и указывается поле по которому нужно отсортировать раз по сортировке до получаса мною да да да но но сейчас да сейчас мы также тоже как раз такие вот делаем машин лёнинг вот начали уже к этой истории приступать его залили там примерно какую-то модель там формулу готовую тоже сейчас с этим экспериментируем спасибо разве спасибо за доклад на нем интересно там каталог у вас достаточно разобщенное на сайте не пробовали вы использовать различные индексы для различных разделов каталога что значит разобщенный но имеется виду что в epam случае заходишь какое-то раздел и там в общем то находится на заходишь другой раздел там находишься даже если вот поиском воспользуешься все равно там ну мне кажется возможно было бы быстрее поискать по каждому из индексов уже и человека направить в определенный раздел а вы может было получается что как бы не растет база из того что все товары с определенными набором фильтров они находятся в одном яндексе соответственный войск возможно будет быстрее работе меньше да хороший хороший вопрос да на самом деле мы думали про вот ну про историю она была тоже в ключе в таком что как вообще делать she родирование да то есть у нас словно мышь ордеру им там и не форм до распределение там поедишь ника документа был в том числе типа а давайте мы привяжем там документ к одному шараду или давайте мы там сделаем отдельный индекс там с какими-то категориями отдельными мы будем ходить только в него получать все данные с парнями мы поговорили и пришли к выводу такому что у нас эти категории количество размеров количество товаров каждой категории вообще истории такая сезонная то есть например зимой у нас там может быть очень много зимней обуви соответственно очень много запросов там на поиск вот а допустим летом на там футболки на кроссовки вот из-за этого возникает может возникнуть неравномерное какое-то распределение запросов то есть мы условным на какой-то шар можем пустить там очень много нагрузки на какой то наоборот недодать то есть история хорошая да но как ее реализовать нут с тем чтобы не было проблем вот мы пока еще не придумали но тоже думаем в этом направлении спасибо за доклад подскажите пожалуйста конфигурацию железа под дата нодами сейчас и экспериментировали ли вы с этой конфигурации чтобы посмотреть как и как она влияет на результаты отдельные интересны были в этих экспериментов разные диски там ssd и классические ну на самом деле по поводу конфигурации но да я вам особо не подскажу мы все это отдали на откуп откуп об сам единственное что я знаю что на тех уже на том железе на котором все это разворачивалось это был ssd то есть это были довольно таки мощные тачки но конфигурацию каждой датой но ты не могу подсказать к цифровому самого процесса ластика хотя бы сколько ядер и памяти ему нравится их я не помню я помню точно по памяти там было ну у нас по моему имеется потолок на каждой ноги по 8 гигов из этих 8 гигов мы там условно там шесть с половиной где-то используем вот а по поводу я der не помню честно спасибо я так понимаю это был последний вопрос а давайте поблагодарим дениса за его интересный доклад"
}