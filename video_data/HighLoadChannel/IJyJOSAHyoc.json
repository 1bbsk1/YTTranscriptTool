{
  "video_id": "IJyJOSAHyoc",
  "channel": "HighLoadChannel",
  "title": "Потоки данных, графы, стейт-машина — строим бизнес-логику в Go-микросервисах / Апрес Антонян",
  "views": 222,
  "duration": 2203,
  "published": "2024-10-29T02:48:12-07:00",
  "text": "Всем привет коллеги Меня зовут Арес Антонян Работаю я в компании самокат тех собственно у самокат тех много разных направлений бизнеса и одно из этих направлений - это Mar матп МегаМаркет Я думаю многие из вас сталкивались с маркетплейсами в своей повседневной жизни как минимум там в качестве покупателей что-нибудь заказывали но только отмечу что одно из ключевых особенностей маркетплейсов от интернет-магазинов для простого пользователя то что на маркетплейсе для каждого из товаров представлено большое количество может быть представлено большое количество продавцов и соответственно цены могут быть конкурентными так как рынок маркетплейсов в нашей стране он хорошо развит и чтобы занять свою нишу на этом рынке необходи приносить что-то новое ист которые уже есть которыми пользуются другие при этом быстро расти необходимо привлекать новых пользователей на матп собственно Какие пользователи на маркетплейсе есть есть покупатели есть продавцы но сам Я работаю в команде которая занимается развитием опыта именно продавцов и поэтому об этом будет мой сегодняшний доклад есть различные способы привлечения продавцов на сгруппировать там по определённым признакам вот здесь я Как пример группируют проект над которым я работал был призван закрыть Некоторые из этих способов так Как матп растёт быстро некоторые инструменты которые использовались При появлении вообще на свет мегамаркета они требуют серьёзных модернизации Как пример при добавлении новых товаров на сайт от продавцов раньше использовались исторически большие Excel файлы и попер ими пользоваться было достаточно удобно они простые они понятные всем но с ростом количества продавцов с ростом количества товара это стало делать неудобно и соответственно перед нами стояла Задача в построении системы доведения предложений сырых от продавцов до состояния карточки товара на витрине маркетплейса такую систему сделать её надёжной качественной нужно сразу предусмотреть множество факторов различных обеспечить безопасность работы с этой системой и прочее но я очень надеюсь что вот про всё это вы уже слышали в последние 2 дня потому что я вам про это рассказывать не буду я расскажу немного о другом я расскажу о том какие костыли мы использовали Какие изобретали свои велосипеды на какие грабли наступали и так далее если корот про то что мы написали свой сервис хранилища как обёртку над базой данных немного расскажу про то как мы устроили жизненный цикл наших основных сущностей в приложении поговорим про построение стойт машины на графах и коротко коснётся версионирование сущностей версионирование структур данных в системе А так как проект писался с нуля первая основная задача была гиб на протяжении всего времени чтобы иметь возможность быстро реагировать на запросы бизнеса иметь возможность быстро реагировать на запросы пользователей и одним из способов оставаться гибкими Это был низкий мат Вот чтобы понизить Mar ещ на этапе начала разработки Мы приняли сразу несколько решений во-первых мы использовали элементы вмм виде в бан доску некоторую у нас был безусловно клок но мы не работали с принтами мы выбирали приоритетные задачи двигали их по доске и соответственно При появлении какой-то задачи от бизнеса которая имела более высокий приоритет мы её могли брать прямо в моменте Кроме этого мы использовали старались использовать в большей части инструменты которые позволяют осуществлять гибкую разработку Как пример и дальше я об этом подробнее расскажу мы использовали местами Джейсон в вместо строго описанных таблиц в базе данных для тех структур которые мы подразумевали могут изменяться в будущем Ну и При всём при этом мы сразу выбрали микросервис ную архитектуру как минимум это нам дало возможность распалить работу над большими частями системы и избежать там большого количества конфликтов и плюс ко всему это нам дало возможность раз частях сист сечас наш проект выглядит примерно следующим образом Т видны некоторые микросервисы тут я вас читать не заставляю всё это просто схема где указаны базы указаны ка топики есть внешние сервис есть внутренний но когда проект только начинался он начинался с двух основных микросервисов и логи другими Серви сервисами обвязки но сервис обвязки они в основном типичны там есть некоторые интересные инженерные решения но не так много логики и поэтому я в сегодняшнем докладе сконцентрируйтесь непосредственно доступ базе имеет только вот этот единственный сервис А все другие сервисы при необходимости получения доступа к данным ходят в этот микросервис и первый вопрос который может возникнуть и вопрос резонный зачем вообще писать сервис обёртку над баз данных причём мы до сих пор иногда его се задаём Когда сталкиваемся со сложностями Но и на тот момент мы взвесили за и против те преимущества которые наст такой подход и сегодня что сделаем Иначе мы бы лучше жили и легче разрабатывали В общем какие мы какие мы аргументы принимали во внимание когда начинали разрабатывать сервис хранилище во-первых нам удалось выделить единый сервис по хранению всех ключевых структур данных нашего проекта безусловно у на есть некоторые сервисы своей небольшой базой но так всего данных в в проекте достаточно много и более того они очень широкие в разных частях системы необходимо обращение и оперирования разными наборами этих данных где-то там полный пакет данных нужен где-то частично И если бы мы делали на каждой микросервис свою базу данных нам пришлось не только дублировать там какие-то наборы данных но ещё и о забочусь тем чтобы эти данные были синхронизированы при изменений Кроме этого безусловно хочется там разрабатывать и писать всегда чисто всегда идеально но зачастую так не получается И когда приходится в идти на какие-то компромиссы очень хочется чтобы эти компромиссы затрагивали как можно меньше участков кода собственно выделяя сервис хранилище нам удалось добиться того что многие сомнительные можно так сказать решения они оставались только в этом сервисе хранилища те которые касаются структур хранения данных и зачастую даже в одном единственном там слое репозиториев нашего сервисах плюс когда мы разрабатывали этот сервис хранилище мы его проектировали таким образом чтобы максимально очистить его от всей возможной логики он должен только работать с данными непосредственно Он должен иметь их доставать сохранять и всё такое но при этом зачастую Он даже не знает какими данными оперирует если у него есть какие-то ты на общие данные сохранения или изменения он даже нела этих данных это опять же касается тех данных которые можно хранить в джейсоне Ну и как бонус мы получили возможность не обременять другие сервисы необходимостью предоставления API для доступа к данным большинство сервисов наших других кроме сервис хранилищ имеют только ручки для реализации непосредственно своего функционала каких-то бизнесов методов естественно у нас были уже тогда аргументы против которые И сейчас иногда стают камнем при разработке Но в основном они все связаны с транзакционных консистентность Дело в том что из-за того подхода который мы применили нам зачастую не удаётся использовать транзакции уровня базы данных Потому что часто операции которые необходимо выполнять атомарний посредством вызова разных API ручек и соответственно могут быть разделены во времени Ну вот мы с этим боремся есть есть ещё куда расти там в конце немного об этом ещё дополнительно скажу а так как я уже говорил большая работа производилась на Excel таблицах которые та работа которую мы на мы были призваны заменить А в Excel очень удобно сортировать по любой колонке фильтровать по любой колонке и примерно те же требования выдвигались и к нам соответственно в большинстве запросов сервисах У нас есть какая-то стабильная часть где описывается там набор данных которые мы должны достать собственно Откуда мы эти данные должны достать и и некоторая динамическая часть которая содержит в себе фильтры для выбора сортировки параметры по Гена и подобные параметры и собственно перед нами сразу встал вопрос что использовать использовать ли сырые тоже для долгих рассуждений мы сразу отменили вариант с ормко потому что решили что это недостаточно гибко зачастую может быть медленно и не стали использовать SQL на самом деле у нас есть некоторые Часть системы где используются сырые SQL строки Но для формирования динамической части запроса это не всегда удобно мы выбрали qu Builder и ещё одним плюсом из этого получили возможность пере использования некоторого кода в запросах вот здесь на примере некий псевдокод как мы формируем запросы в базу данных Мы формируем сначала общую часть запроса и потом вызываем некоторые не экспортируемые методы которые выполняют сортировку применяют сортировку к запросу либо фильтрацию и вот здесь небольшой пример как мы собственно делаем сортировку Мы сначала определяем по входному параметру от клиента по какой колонке необходимо проводить сортировку если по такой колонке соб в это меде можем воем ошибку явно фолт колонку для сортировки использовать но так как потребители этого сервиса не только пользователи но и другие сервисы мы бы хотели сразу видеть Какая ошибка произошла Что делается что-то не так и соответственно выдаём ошибку но если никакой параметр не был задан мы используем дефолт сортировку и в конце просто применяем полученную сортировку к запросу на первых порах это в работало хо когда е было mvp или запустили первых пользователей но когда данных становилось больше мы собственно начали переводить часть пользователей уже на использование этой системы данные стали расти пользователи начали пользоваться различными запросами и мы столкнулись с проблемой производительности мы вот практически там со старта выходки в прот начали проводить оптимизации мы всё ещё в процессе нам есть куда расти Но мы уже приняли некоторые меры по ускорению работы с базой вре индексов Прим в большинстве случаев это были составные индексы в части случаев это были покрывающие индексы это нам сильно помогло но в те моменты когда пошла большая нагрузка на запись наши индексы стали соответственно перестраиваться и запросы стали деградировать чтобы побороть эту проблему Мы пришли к необходимости патинирования погони мы позировали не по привычным ключам типа дата создания Дато обновления А по достаточно специфичным специфичной колонки Это тип сущности нашей Дело в том что у нас большинство запросов выбирается именно по конкретным типам сущности без фильтрации по дате создания или обновления сущности этой соответственно если бы мы провались по какой-либо из этих Дат то мы Скорее бы получили деградацию а Приорова именно мы Ну неплохо так в моменте подняли производительность Ну и естественно Естественно нам пришлось в какой-то момент нормализоваться потому что были сложные запросы в которых из-за схемы нашей схемы наших данных мы не могли всё уместить в одну таблицу мы соответственно могли фильтровать по колонкам из одной таблицы сортировать по колонкам из другой таблицы когда данных много идёт Пугина там на какие-то большие значения Мы начинали деградировать нам пришлось переместить некоторые данные между таблицами но при этом естественно старались не смешивать совсем несвязанные данные так как сервис хранилище он его потребителями являются не только пользователи но и другие сервисы встал вопрос о выборе способо взаимодействия но в силу специфики хранилища вс-таки это работа непосредственно с данными с базой большинство взаимодействие с этим сервисом происходит синхронно по htp но при этом есть и некоторая часть асинхронного взаимодействия которую мы смогли вынести достаточно безболезненно к примеру при обновлении каких-то ключевых сущностей Мы в в брокер сообщений размещаем сообщение о том что конкретная сущность была изменена Какие изменения были произведены и плюс добавляем некоторую Мета информацию к сообщению вот источник этой информации - это именно Тот клиент или пользователь который спровоцировал обновление сущности То есть он присылает кроме данных для изменения сущности ещё и информацию Мета информацию а сервис хранилище просто ксит эту Мета информацию в брокер сообщении и вот одним из источников этой Мета информации этих обновлений является сервис логики собственно понятно что это сервис котором заключена основная логика приложения коротко о том что за логика У нас есть некоторые предложения сгруппированные от продавцов они группируются по товарам и их надо докатить какой-то дополнительной информацие чтобы разместить на витрине маркетплейса уже готовую карточку и вот весь этот процесс обогащения карточки товара ещё немы раздели на зада на каждый блок карточки и проводим над этой задачей определённую определённую работу при этом мы не двигаем сами карточки Ну сами задачи по статусам у нас процесс выглядит примерно следующим образом мы создаём сначала некую задачу для описания конкретного блока карточки причём на определённом там этапе потом над этой задачей производится определённая работа а иногда это автоматическая работа другими сервисами иногда Это работа которая требует вмешательство пользователя описания добавление какой-то информации После этого мы поча данную задачу Как неактивную как выполненную сохранением всего её состояния и просто на следующем этапе создаём уже новую новую задачу которая содержит только ту информацию которая ей необходима выглядить выглядит схема примерно следующим образом часть задач Могут могут двигать двигать процесс только впер часть задач могут двигать процесс и в обратном направлении неспешно и вот такой подход нам позволил иметь доступ к состоянию процесса на любом из этапов в любой момент времени то есть потому что мы задачи не двигаем и не изменяем мы их сохраняем в том виде в котором они были на момент выполнения мы можем проанализировать процесс описания допустим одной карточки и на этом на этом процессе мы построили анализ и автома автома исправление То есть если возникла какая-то проблема при переводе задачи из статус в статус причём если это Можно повторить выполнение этой операции мы пробуем несколько раз повторить если проблема повторяется мы анализируем состояние этой задачи если в не ошибок не найдено мы можем пройти по цепочке к родителю этой задачи и проанализировать состояние той задачи потому что возможно где-то не тот пользователь был записан не с той ролью возможно где-то статусы были путанные или что-то в этом роде и поэтому текущая задача может не проходить контроль собственно из того что я рассказал Я думаю многим понятно что нам необходимо было использовать стейт машину так как много движений происходит по статусам и перед нами встал вопрос Какую стейт машину использовать использовать какую-то готовую стейт машину писать свою стейт машину но мы выбрали что-то среднее что-то между и мы взяли библиотеку для построения графов в го и на основе этой библиотеки написали СД машину мы написали некоторую обёртку которая обеспечивал необходимый нам функционал и получили стоит машину собственно Благодаря этой обёртке мы могли строить Вот такие графы тут такой Монстр нарисован Но если рассмотреть например какую-нибудь ветку этого графа поближе тут вчиться тоже необязательно Но по крайней мере становится фид что есть некоторые узлы это собственно этапы продвижения процесса и для йт машине они являются статусами есть грани либо переходы и это просто варианты завершения конкретной задачи успешное неуспешные выполнение Ну и благодаря тому что мы использовали графы и использовали библиотеку это было удобно не только в разработке это было удобно ещё и в поддержании всего этого к примеру Мы в какой-то момент столкнулись с нехваткой функционала конкретной библиотеки и достаточно безболезненно просто заменили её на другую потому что API у большинства библиотек работа с графами примерно схож сам процесс создания новых статусов новых веток он достаточно удобный мы просто описываем новый статус описываем а те связи с другими узлами которые у него есть в случае успеха К какому статусу он должен приводить и в случае неуспеха и соответственно описываем э переход непосредственно в этот статус от других узлов дерева причём удаление добавление веток оно происходит всё аналогичным образом мы либо просто удаляем какую-то ветку и сводим два два статуса которые остались без связей между собой либо добавляем в разрез каких-то двух статусов новую ветку тут описан пример того как мы строим диаграмму в в этих библиотеках которые работают с графами все узлы они хранятся плоским списком это достаточно удобно не нужно постоянно идти по всему графу Чтобы построить схему мы просто циклом проходим по всем узлам этого графа и потом внутри циклом пробегая по всем возможным переходам и добавляем это ну в нашем случае в mermade диаграмму но можно я думаю использовать любую и получается Вот такая вот диаграмма Это я повторяюсь э эту диаграмму удобно давать тем кто собственно в ней заинтересован это могут быть qa аналитики кто заинтересован в знании того как вот движутся задачи по нашим статусам Кроме того если допущена была какая-нибудь ошибка в проектировании самих переходов и статусов Это тоже может быть видно на диаграмме вот к примеру здесь красным обведено висящая веточка из двух узлов которые связаны между собой но никак не связаны с основным деревом диаграммы они просто близко расположены на самом деле никак не связаны и это может говорить о том что допущена какая-то ошибка саму ветку тоже надо связать с основным деревом так как этот сервис логики соответственно в нём происходит манипуляции с основными структурами данных нашего проекта и в связи с этим собственно мы описание структур этих данных размещали в этом сервисе Но со временем необходимость работы с этими структурами возникла и в других сервисах и чтобы не дублировать там код не беспокоиться за схожее состояние между структурами в разных сервисах мы вынесли описание этих структур в же директорию А в смежных сервисах просто импортировались изменять структуры данных набор полей в ключевых сущностях и опять же чтобы не иметь проблем с обращением каким-то конкретным свойствам эти сущностей в других сервисах мы здесь же в package директории описали э методы для Ан маршалинг этих структур и причём методы которые преобразовывает J в структуры всегда должны были возвращать только свежую версию структуры они могут получать версии любых данных потому что в базе может быть сохранена старая версия но возвращать всегда готовую структуру новой версии Примерно это выглядит следующим образом есть некая структура которая содержит свойство version и она встраивается во все структуры которые должны версионирование это к Если э версия какая-то старая мы собственно получаем структуру этой версии потом делаем какие-то преобразования и возвращаем уже новую версию структуры если эта версия уже Новая Мы просто возвращаем её как есть тут нам никаких дополнительных манипуляций проводить не нужно Ну если версия какая-то Неизвестная мы собственно возвращаем ошибку просто не знаем как с этим работать иву очере должны появляться именно в сервисе логики собственно на сегодняшний день у нас есть достаточно гибкая система для работы с предложениями от продавцов по доведению этих собственно предложений до витрины маркетплейса мы вынесли логику работы с данными в отдельный микросервис благодаря этому получили какие-то плюшки у нас есть и проблемные зоны и ещё о них два слова скажу мы построили работу с жизнен с жизненным циклом сущности таким образом чтобы иметь возможность в любой момент времени посмотреть состояние на каждом из этапов этих сущностей но и есть некоторые моменты над которыми Мы работаем это собственно наш клок и техдок одновременно который мы постоянно пытаемся улучшить во-первых Это работа с с отсутствием транзакций в сервисе хранилища тут есть вариант который мы сейчас планируем использовать это версионирование сущности При ответе от сервиса хранилища собственно у нас идея возвращать При ответе на гет ручки не только саму сущность но и какой-нибудь либо хэш ключ либо тайм СМП чтобы потом при попытке обновить эту сущность клиент присылал ещё и этот ключ мы сравнивали это состояние с тем которые у нас хранится в базе и производили обновление только в том случае если если ключи совпадают если ключи не совпадают Мы просто будем просить клиента перезаезд я думаю тут у нас есть большое поле для для работы Как смена непосредственно хранилища больше каширования данных ну и собственно остальные способы которые которые есть описаны в интернете на этом У меня всё Да есть такое Спасибо большое за доклад так я помечают вопросов два Как вы боретесь в целом с некон систентки Что вы делаете если у вас скажем вот стоит машина Она просто в середине процесса Бах упала а как вы восстанавливает весь этот процесс workflow да первый вопрос по поводу борьбы с не консистентность Вот я как я в конце уже озвучил у нас есть идея по улучшению этого этой борьбы и наших методов есть уже меры которые приняты нами во-первых проверок мы добавляем как можно больше на сервисе логики Ну или на других сервисах которые обращаются в микросервис храни мы контролируем больше больше разных кейсов когда может быть вызвано там обновление данных из двух разных мест мы стараемся при вызове ручки на обновление каких-то данных блокировать эту запись проделать работу а потом уже вызвать само обновление в сервис хранилище благодаря этому У нас есть некоторые лак во времени собственно таким образом ВОМ больше операций именно на чтение на запись на обновление их не так много потому что пользователи в основном работают со списками и поэтому может быть каких-то там критичных проблем Мы ещё не словили собственно пока мы их не словили мы и хотим вот улучшить этот процесс по поводу вопроса про про проблема состоит машиной если в какой-то момент она обломилась и упала есть естественно систе когда она пытается перев когда сам сервис логи пытается перев какие-то операции которые провалились есть несколько попыток у него на это Но кроме того У нас есть отдельный сервис инспектор который ходит по тем задачам которые не выполнились и даже повторное их выполнение не привело к успеху и соответственно проводит тот анализ который был на одном из слайдов он ходит сначала анализирует конкретную задачу ищет причины у него есть набор стандартных кейсов по которых по которым могли происходить ошибки Он смотрит укладывается ли Задача В какой-то из этих кейсов если нет он идт к родительской задаче и так идёт вплоть до самой первой если решение найти не удалось такая задача повисает и мы потом ручками Разбираем если можно выделить какой-то кейс для этого же таск инспектора мы его описываем и добавляем Чтобы в следующий раз это автоматически выполнялось коллеги Не забывайте ручку держать чтобы я понимал кто кому следующему давать микрофон Да конечно да Привет меня зовут Катя У меня вопрос с учётом того что у вас один сервис который работает с базой данных Как вы обеспечиваете доступность всех всей вашей системе если этот сервис упал Ну получается это же такое узкое голыш это так и есть И на самом деле если сервис упадёт мы действительно э в большинстве своей работы просто встанем у нас всё завязано на данных но есть Часть системы которые могут продолжить работать которые будут продолжать ставить задачи Просто они будут копиться в брокере сообщений либо Ну собственно других вариантов нет они будут вставать в очередь но есть ещё часть микросервиса который взаимодействует асинхронно собственно есть тот же процесс по постановке задач на другие сервисы и на выполнения их вот часть работы будет продолжаться Но к примеру пользователю полностью будут заблокированы с этим не боремся Мы очень Мы очень сильно заботимся о том чтобы база не падала коллеги ещё вопросы тогда у меня будет Вопрос там Вижу вижу отлично Здравствуйте спасибо за доклад а такой ещё вопрос каширу ете Вы на какой стороне То есть тут как будто бы выглядит это что и там и там нужно и как будто X2 получится нет да а кэширование во-первых Ну у нас сейчас сейчас у нас кэширование только на стороне сервера Мы очень хотим внедрить каширование на стороне клиента потому что я об этом не сказал у нас очень много операций ба чами идёт именно от клиента с фронта в том числе и когда вот эти большие данные уходят на сервер и их надо обновить собственно фронт всё ещё может отображать старые данные когда операции ещё выполняются вот чтобы это побороть мы планируем вводить каширование на стране фронта в том числе но пока это только на сервере возможно А можно ещё поясню возможно тут вопрос говорил о том что смежные данные каширу в разных местах если об этом Ну я скорее имел в виду что вот у вас есть этот сервис хранилища к нему ходит каждый из сервисов и вот каширование между этими инстанциями да каширование В основном на сервиса конкретно логики происходит Привет Спасибо за Извините а можно тогда ещё продолжу Но есть же сущности которые нужны нескольким сервисам соответственно на роне хранили ним сходит У нас у нас прям вот прям идентичных запросов нету от разных сервисов Кроме того даже если структуры данных нужны одни они в большинстве случаев запрашивают списками с разными условиями поэтому мы тут повязаны по рукам ногам Давайте Дубль 2 Привет Спасибо за доклад такой вопрос возник ты упомянул что структура данных нуж в нескольких сервисах вы их храните в те в другом сервисе да то есть у вас другой сервис прям напрямую зависит от сервиса это бизнес логики получается да Ну он зависит на самом деле получается от одного пакета этого сервиса именно от того что в ж расположено но по сути да мы могли бы просто вынести этот пакет в отдельный репозиторий был была такая возможность ну и собственно есть такая возможность но из-за того что изначально эти структуры описывались в этом сервисе В какой-то момент дешевле было Просто их унести в другой пакет и оставлять всё ещ в этом сервисе но я вот не знаю концептуально есть есть если есть какая-то опасность Я бы хоте не знаю У нас просто похожая ситуация мы просто держим в каждом сервисе свой вариант этой структуры А даже так вот да ну то есть Есть мысль вынести из какую-то библиотеку вот возможно но просто такой способ Мне кажется слишком жёсткая связанность между сервисами он может быть нам не больный потому что именно этот сервис логики он в любом случае работает со всеми данными данны все остальные сервисы используют частично либо одну структуру либо другую Но если происходят какие-то изменения значит сервис логики точно будет его Это точно будет касаться так коллеги я кого-то видел желающего задать вопрос в первом ряду но потерял во во во Мы хотим у себя тоже использовать подобный подход Вы можете нас отговорить от подобных ошибок на самом деле про про что Про хранилище дамы хотим у себя создать единое нище Ну мы с командой не видим перспектив и как бы очень сильно Спорим с техдом от этого подхода и хотим просто вот Ну вот два главных Да да я понял два главных вопроса которые стоит себе задать это именно сохранение консистентность из-за того что вы не можете транзакциями пользоваться из-за того что операции могут быть разорваны во времени если делать их последовательно Селект и обновление И второй вопрос - Это именно нагрузка если у вас будет один сервис хранилищ соотвественно вся нагрузка на чтение будет к нему и собственно даже более того КК одной базе данных вот этот вопрос который больше всего нас волнует с которым мы боремся но мы до сих пор не имеем хорошего плана сделать иначе и чтобы это было удобнее поэтому мы миримся С тем что есть коллеги ещё вопросы так повторно Ну так уж и быть и мы потеряли одну из наших пока бегут с микрофоном Я всё-таки до задам свой вопрос он достаточно простой и связан с Гошей частью Почему именно squel не dbr не другие фреймворки для построения запросов а именно вот сл Да ответ тоже будет простой просто потому что экспертизы в команде было больше пол собственно его взяли Причём я хочу заметить для тех кто возможно будет исполь выбирать какую-нибудь библиотеку для построения qu для использования в насколько я знаю до сих пор нету работать с с тешка то есть блок описывать но есть РК в котором это есть Поэтому возможно лучше использовать ФРК возможно как минимум там стоит скопировать код из форка к себе я не советовал это делать но такая возможность есть потому что с те что-то придётся решать так ещё раз у меня може немножко дурацкий вопрос Если у вас несколько команд и какая-то вопрос какая команда пожи работает с базой данных как я понимаю КОНБ туда все поддерживать должна одна команда У нас у нас мини-версия того что вы озвучили потому что у нас команда на самом деле одна но по разным сервисам есть ответственные ответствен ответственно за сервис хранили перед вами Ну собственно говоря прожить рашить про ВН мот в рах Бира лучши вопрос Да мне понравился вообще все вопросы мне понравились даже более того чем я себе мог представить про вопрос Но вот мне понравился вопрос молодого человека Да да Так выходи к нам мы дадим тебе подарок Давайте похлопаем так Ну а теперь вручение непосредственно подарка тебе за такой хороший доклад Спасибо Спасибо большое"
}