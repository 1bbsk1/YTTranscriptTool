{
  "video_id": "d3GdZTOWGLk",
  "channel": "HighLoadChannel",
  "title": "Учим Kibana работать с Clickhouse / Ярослав Саган, Николай Нестеренко",
  "views": 1747,
  "duration": 2904,
  "published": "2020-04-14T11:21:21-07:00",
  "text": "всем привет меня зовут ярослав саган со мной сегодня мой коллега николай нестеренко всем привет и мы расскажем о том как сделай архитектуру для компактного хранения логов или хаусе как прикручивали к этому киба ну для просмотра логов фильтрации для аналитики для чего вообще это делали с какими трудностями столкнулись и и что у нас получилось в итоге сначала несколько слов о компании мы работаем войти подразделение компании камней это международный платежный провайдер и прямая твой компаний обеспечивает прием платежей и проведения выплат как при помощи банковских карт так и с помощью многих других платежных методов у нас работает более 700 человек а в семи странах мира и это на самом деле очень ответственная сферы потому что мы работаем с деньгами причем преимущественно с чужими деньгами поэтому нам необходимо постоянно следить за работой наших сервисов с одной стороны для того чтобы уметь оперативно реагировать на различные возникающие проблемы с другой для того чтобы уже пост постфактум иметь возможность посмотреть когда и какие операции мы совершали ну вот в качестве затравки для последнего рассказа этим ежедневно у нас проходит более 1000000 транзакций и по всем необходимо сохранять данные за последние несколько месяцев данные хранятся в горячем хранилище для оперативного доступа мелко ацтеки белка ацтеки затем старый индексы отстреливается покоится все-таки лежать в холодной хранилищ вот мы сегодня расскажем об эксперименте который у нас мы поставили в аренде отделе для хранения анализа логов ли housing либо все началось с того что что наша инфраструктура основанная на ластики перестала справляться с теми объемами данных которые начали ей поступать и ежедневно на миллионы транзакции у нас пишутся десятки миллионов логов и сейчас занимает до нескольких терабайтов в ластики в день и в итоге наших хранящий для оперативного доступа выросли где-то до 80 терабайтов и к сожалению это негативно сказалось на скорость их работы у нас начали тормозить за запрос его ластик стай стали жаловаться пользователи ну и в итоге мы решили попробовать научиться хранить логе более компактно и более эффективно с ними работать но она при этом не потеряв его функциональности что для нас очень важно и вместо ластика мы решили взять клик house ну во-первых из-за его очень высокой скорости работы наверное это самая быстро из доступных сободы во вторых из эффективного сжатия данных и в-третьих из большого числа агрегатных функций которые могли бы в дальнейшем нам пригодится для анализа им им и мониторинга логов ну и кроме этого он у нас уже был схожий опыт по замене ластика над легка us мы сделали свою версию джаггера это раз распределенной трейсер на базе uk and racing с хранилищем данных в хаосе и результат нас устроил и по скорости работы и по объему базы все было общим хорошо и что-то подобное мы хотели бы иметь и для логов ну о кукле хауса есть и ограничения некоторые в процесс работы нам не всего мешало русской схема данных то есть на нам нужно будет думать о структуре хранимых logo хуй типах данных и все все все такое во вторых всего один индекс на таблицу и в-третьих то что house плохо справляется с частыми вставками в него ну и есть еще один момент по которому кли-кли house не может выступать полноценный с замены для ластика и нам это нужно учесть о чем идет речь как вы думаете да да поиск но его мы еще коснемся немножко дальше прежде чем кидаться на амбразуру и реализовывать это все внедрять treehouse для хранилище логов нужно понять о чем для нас полезно кабана и какие сценарии использование вообще есть у нас в компании но первый чириканье это просмотр логов мы хотим логе видеть смотреть на них читать их это очевидно логина спешиться структурированной формате json помимо текста сообщения там могут быть и дополнительные атрибуты ну например информация о том где когда была сделана запись и на fastapic процесса это может пригодиться например системным администратором для выборки всех логов с какого то сервера по его имени фильтрация будет разные фильтрации тоже нужно поиск и особенно пола текстовый поиск нужен у нас в первую очередь с аппаратуру к ним чаще всего обращаются для выяснения деталей по той или иной транзакции если там зависла или платеж был отклонён а из отклонён то по какой причине или платежная система затупила такое тоже бывает и вот прям приходит с этим вопросом основных кейс для тех показать их поддержки получается в поднятии всех логов по определенной транзакции по ее имени причем номер по номеру номер транзакции может быть в одном из несколько текстовых полей позиция этой информации как бы четкой недетерминированные к тому же поиск может быть не только по этим полям может быть поиск по имени клиента нашего по по платежной системе вариантов масса поиск нужен помимо поиска нам также важно следить за состоянием нашей системы и интегрированных снизить внешне платежных систем это уже задача такая на стыке технический бизнес сфер ну например нам важно знать сколько за единицу времени у нас инициируется на в транзакций и все это в срезе по клиенту по по платежной системе или сколько транзакции доходит до финальных статусов и какие-то станции вообще такого рода информации оно само по себе уже как полезно двойной просит у ты используя есть если видеть все в динамике то есть скажем если количество транзакций у нас инициированных падает либо количество успешных уменьшается количество decline of при этом растет ну это все сигнализирует о том что где-то есть проблема либо нашей стране либо с таней платежной системы и ее нужно отдельно по исследовать не обратит на нее внимание вот получается что акебоно как бы всем хорошо кроме того что она не умеет работать клик хаусом и нужно понять если какие-то альтернативой общее способные работать три хаусом но обладающие хотя бы частично той же функциональностью что икебана мы можем взять интер фанов или приспособить что-то более узкоспециализированное тепло house например но к сожалению ни одна из рассмотренных нами альтернатив а их очень мало на самом деле нам нет не подходит по функциональности где-то в области поиск где-то в области мониторинга нам чего-то не хватает а с другой стороны реки баны у нас уже давно работают и и или саппорты и тестировщики аналитики она всех всем устраивает и по в возможности нас просили ее оставить ну и в итоге мы решили что что так было бы удобнее всего и нам нужно научить киба ну а работать скри хаусом так то для этого мы рассмотрели два возможных пути можно либо сделать свой форк как с джаггером мы делали но это очень не просто на самом деле деньги это то что в первых самой киба она очень большая а вторых она совершенно не приспособлена для добавления в нее новых данных новых источников данных там все все за и связано на и ластик и вам во многих местах так что было рисковали стива это и обратно уже потом не вылезти никогда в вторых если в будущем мы захотим продать свою кабану то все эти изменения нужно будет продублировать и там тоже но это очень удобно и поэтому мы решили идти по другому пути и сделать независимый адаптер и вы не вынести в него весь новый функционал такое решение легче будет и разработать и сопровождать и переход на новые версии ge больна для нас будет не таким болезненным но однако есть и минус у нас будут в ривен и потери в адаптере при конвертации данных между разными форматами но в принципе можно этим и пренебречь так как запроса идут не слишком часто логов много так что на фоне вот так хауса этот выход у нас затеряется просто вот такая схема у нас сейчас есть чтобы разбить эту связку нам достаточно в конфигурационном файле акебоно заменить его один параметр указывает какой адрес нам слать запросы в ластик такую схему мы хотели бы иметь у нас есть и внешний адаптер мы решили назвать его киба us он будет брать данные иски бан и разбирать их и строить на их основе один или несколько раскрыли запросов и тетис не if my house брать данные и отдавать киба ну ответов понятное для нее форме это ластик в этом случае нам уже в принципе не нужен но и что можно импортировать из него настройки для кабаны они хранят стал в отдельном яндексе то то есть это же полный графиков дашбордов индексы и вот все это но даже в этом случае связь со ластиком нам нужно будет только один раз при первом запуске а затем мы его выключаем ну и чтобы научить киба но работает ли хаусом чтобы вообще как-то подойти к этому снаряду нам необходимо реализовать следующие во-первых научиться доставлять в лагере house а затем запустить икебану таким образом чтобы она заданными ходила или клаус в том числе и на стройке сварить иного оттуда же ну и наконец реализовать никто часть функциональности ластика начнем с доставки логов блоге у нас пишутся файлы и дальше идут долог старше logs наших можно трактовать как некий такой prefilter в которую можно сделать предварительной обработки по логу такими дополнительно трибута если нужно но и вообще здесь нужно будет подготовить данные до ставки для вставки house но следует учесть некоторые особенности особенности нового хранилища во первых это строгой схемы хранения данных строгой типизацией отвлекалась логе лучше писать и хранить структурировано и у себя мы например разбираем вложенный джейсон и сразу раскладываем по колонкам будущее таблички таблички на пони дополнительно генерируем здесь уникальная идеи и уточняем timestamp все это пригодится потом затем для киба ней при запросах нее другая особенность вытекает из того что основной и наиболее функциональный вид движков для работы с данными в хаосе это семейство merge ты знаком кто-нибудь с этим или хауса смерш 3 отлично когда есть нам особенность много ставку в проставке правильно дело в том что при не сердцах данный там не пишутся в какой-нибудь менты бык было к записи тоже не ведется данный пишется сразу на диск по колонкам афоне уже происходит слияние сортированных кусков из этого следует что оптимальный будет вам бы только бочками не чаще чем раз в секунду просто противном случае постоянной вставки и и слияние они будут насиловать диск и это все придет потому что в определенном этапе система станет налоги у нас пишут постоянно и при этом них даны содержащие информацию о финансовых транзакций то есть лет никогда ничего не хотим ничего не можем поэтому мы выбрали способ гарантировать доставки через кафку с некоторых пор по моему стараниями клауд в пары механизм выполнения кликал устных таблиц табличек через кафку встроен в ядро приказ как-то работает лог стаж при помощи нативного плагина пишет данные ставку на стороне клих алсо одноименный движок капка учитывает эти данные ну движок кафка это то это не совсем табличка даже это скорее просто консилер консилер группе данных он себе не хранит мы можем там обратиться к нему как таблички сделать select всех заполненных данных выбрать их но такой операция не будет видно патентной и последующей select уже данных не вернет просто потому что все за наметился ушел дочку портишь но именно поэтому здесь на схеме дальше присутствует матери зоны и view его основная задача это получить данный из engine кафка и положить уже в конечном мер 3 табличку чем еще нравится такая схема это тем что можно достаточно просто увеличить проходимость по доставке логов мы можем сделать ни одну ноту как бык ли хауса сделать из нее кластер добавить туда при добавлении дополнительные ноги в этот кластер получится что новые ноты будет также полете своего пар тишина в кадке данный как бы это все от легко дома собирается еще один плюс такой что мы можем относительно безболезненно терять эти ноты в кластере если мы этому если она упала по какой-то причине лета мы сами захотели выключить то ничего страшного не произойдет произойдет просто ребаланс на стороне кафки и те пар тишины как которые обслуживали сразу с упавшей лодой за садится на другую и для консилера этих логов для потребителя внешне ничего не изменится в общем мы записали данные в табличку кстати не знаю по таймингу успеем и или нет мы тут есть тоже свои особенности в этом механизме если что к ним вернемся в конце еще записали мы в между и табличку данные там индексируются по timestamp у вас потому что нам не нужны все логе всегда да мы хотим как бы как правило сидит за какой-то интервал за период времени мы к счастью киба на такой траволта же присылать на указанный запрос это клубе мы храним теперь можно запускать саму киба ну а для этого ей надо эмулировать связь с ластиком дело в том что и секунд на она шлёт у нее несколько запросов ну а словно это всё разные halls чеки их у нас ну где-то штук 10 или 15 разных но не сами эти запросы и ответы на них со временем мнениями не меняются то есть мы можем это все все у себя сохранить просто и по мере надобности отдавать икебану уже сразу готовый ответ так же для удобства настройки тоже лучше импортировать и за ластиков cliff house для этого мы нож так и к осени операции вид и апдейт то чтобы смысла с настройками что там можно было в реальном времени времени делать например облететь их из графического интерфейса икебана мы используем специальный жег он называется коллапсе mesh 3 и и он умеет удалять одинаковой строки отличающийся одним специальным атрибутом обычный он называют sein и он может иметь два значения 1 или минус 1 и и пример же две одинаковые страха keysight у нас схлопываются а selecta мы делаем включим слой войну чтобы иметь уже сразу обработанные данные не дожидаясь очередного мер же ну так делать не рекомендуют из этого того что файл плохо влияет нас на скорость выборки но для нас это не не критично так как в настройках мало данных обычно а во-вторых сами запросы идут не слишком часто так что мы можем себе это позволить у нас зато это самый удобный способ для работы с движками такого типа вот мы запустили киба ну направили запросы в наш адаптер который прикинулся и ластиком и теперь нужно перейти к реализации необходимой функциональности новостями в частности нужно как-то уметь изображать на вкладке диска выравнивания флаги там мы показываем логе закрыть перевод либо по условию либо без него ну например мы хотим здесь изобразить влоги отфильтрованные по имени хоста ну и делается это несложно прям в принципе у себя в адаптере мэр забираем джейсон формате и ластика и строим на его основе один сквер запрос по индексу определяем целевую таблицу буквари условия выборки по сорт порядок сортировки опасаясь число записей и идем с этим в crack house ну еще в пластике можно было бы брать данные сразу из нескольких и пекин индексов по шаблону в хаосе это тоже можно сделать в принципе с для этого мы берем шок мерз он умеет выбирать данные сразу и из нескольких таблиц с именами удовлетворяющими регулярному выражению ну правда в отличие от а ластиков структура у этих таблиц она должна быть у всех а одинаковая но есть несколько таких проблемах первое то что у нас не получится нормально полноценно использовать яндекс отвлекалась дело в том что на одну табличку то можно есть только один индекс у нас уже есть и он уже потом штампом получается что при фильтрации скажем потому же имени хоста нам придется вычислить все все логе за интервал и к бы пройтись по ним ну не намокли холста сделать но или суммы за действия и вторая особенность то что увлекался нет я думаю не предвидится план текста поиска все-таки инструменты несколько для другого но такая социалистам нужно нужно с этим что-то делать ну и и мы решаем убейте проблема своей и индексации и полнотекстовым поиском на базе обратного индекса обратный или инвертированный индекс это такая сестру структура данных которые можно по слову эти все все записи в которых это слово содержится вот например слева на у нас есть логе чтобы сформировать по ним обратный индекс нам надо разобрать их все на слова и записать эти слова по одному в новую табличку слова и и идентификатор logo ну и так далее и индексируется это все по словам и теперь если мы захотим что-то найти в основных лугах ну например все все записи в которых есть два слова об то в начале мы идем в обратный яндекс и выбираем из него все идентификатор логов для которых у нас выполняется два условия во первых на каждый идентификатор у нас таблица должно быть два разных слова у них марта эти это то же самое что и колонн distinct part 1 обычно москве во-вторых эти два два слова могут быть только либо либо b и таким образом мы находим все село гифка в которых есть эти два слова и неважно в каком месте и в каком порядке главное что чтобы они просто там были ну искать можно и по одному слову в этом случае это будет что-то типа аналог а для встроены в собой индексов для ускорения поиска просто мы это все в теории а на практике нам еще нужно индексировать все входящие логе вот такая схема у нас сейчас есть для ставьте мы добавляем в нее есть еще один процесс он называется и yandex.ru его задача вычитывать логе из кафки р-р разбирать их на слова а затем в новый топик для инвертированного индекса он запишет слова идентификатор logo timestamp logo и колонку в которой это слово нам встретилось она из сказки уже в по той же схеме что и логе данные запишутся вк лекал чтобы эффективно использовать такой обратно индекс надо как-то научиться быстро искать влогах записи по их имени котором так мы говорили что яндекс уже действие он пытаем штампу для того чтобы сделать новый индекс по идее как вариант можно использовать вторую табличку она будет содержать тир самый данный но другой яндекс и я здесь специально я говорю табличку они мотивированы и view просто потому что отвлеклась и нет поддержки каскадных моторизованных видео то есть нельзя сделать матвею на табличку которая уже сама запылилась и смотрю первый матери зоны представления нас уже есть по схеме доставки логов ну не суть вот у нас есть две таблички 1 апреля дефицита на идентифицирован проиндексирована повод м штампу 2 проиндексирована по айди чем такой вариант плох как вы думаете да получается дублирование ну прямо через чур избыточно другой вариант это использовать составной индекс потом штампу и идентификатору его можно представить виде такого списка отсортированы сначала по первому атрибуту а затем внутри сегменты с одинаковым тем штампам отсортированные плоды получается чтобы при поиске подать в которую этот индекс был задействован нам нужно явно указать timestamp однако на момент такого поиска информации еще нет выход сохранять опять же лог два раза первый раз с нормальным временем второй раз синтетическим нулевым и тогда при поиске по идентификатору нужно будет просто условий указать и timestamp равен нулю и мы как бы проскочим эту первую часть 1 атрибуты задействованы и вторую часть индекса ну такой вариант может быть чем-то лучше немного чем полное дублирование от табличек да но он тоже весьма затратен по памяти особенно если учитывать сопли класс по разному сжимает данные зависимости от индекса так нас опытным путем установили что данные про индексированные площади занимают named места на диске раза в два или три по моим больше чем данные индексированные потом штампу и конечном счете получится что на 1 гигабайт логов нам пришлось бы хранить до 10 мегабайт с морозильных данных ну такое себе нужно как-то улучшать ну мы стали это все оптимизировать и в начале хотелось бы избавиться от дубликатов для этого мы решили пойти на компромисс такой и отказаться от в выборке из обратного индекса идентификаторов логов вообще то есть я стоит вас записи мы идентифицируем по их timestamp у это будет работать если timestamp сделайте максимально точно да микро лучше дано на секунд мы это волк старше делаем стати и в этом случае вероятность того что два logo окажутся на одном временном интервале очень мало но если это иприт и и произойдет . не мы хотим на более позднем этапе уже перед отправкой за ответа но зато в первых мы избавляемся от дубликатов во вторых можем не хранить в обратном яндексе атрибут сойди ну это не все наши оптимизации еще можно не индексировать самые часто встречающиеся слова в нашем случае это я к вендор сердце печки вот все в этом духе мы ищем мы считаем что они есть во всех записях и исключаем из обратного индекса и но в принципе и и скай исключать можно и ни слова исключать можно и целые атрибуты и в итоге оставить только те из них в которых у нас реально что-то ищут ну особенно с пользованием полнотекстового поиска и вот все это вместе дало нам определённый результат на 1 мегабайт логов мы их мы храним не 10 а 2 мегабайта вспомогательных данных но это все все еще конечно не очень но уже лучше чем вы ластика на самом деле выходило по памяти и по месту вот такая у нас схема индекса здесь еще можно увидеть что слова мы храним не в строках а используем интер это еще одна такая микро оптимизация для уменьшения объема базы известно что числа зажимаются лучше чем строки и поэтому все слова перед записью маршируем используя для этого встроенный в клика us сети х64 ну кроме поэт поиска нам еще и мониторинг нужен для того что чтобы следить за состоянием нашего сервиса и в внешних платежных систем ноги для этого у нас есть графики на вкладке visualive вот один из них здесь у нас изображена число сетевых ошибок на их единицу времени возникающих между ядром процессинга и адаптером в внешних платежных систем у нас он называется плюс ошибки мы определяем порно и чулках специальных слов маркеров здесь это response from плюс и cod4 то есть если эти слова в лугах есть то значит у нас где-то была ошибка но его вот здесь в одном месте видно что у нас был сбой в сети из-за этого резко выросло число ошибок но затем все снова вернулось в норму и и вот таких вот green графиков у нас очень много но в целом они все эти полы это временные ряды с с числом записей удовлетворяющих определенным условиям на интервалах времени и его ластики это делают с помощью агрегации детских 100 грамм в хаусе мы для этого используем функций аккаунты аккаунты и говорит о том что считаем только логе от удовлетворяющие определенным условиям это нам нужно для фильтров условия может выступать и под запрос вот например для этого графика мы используем результаты в выборке из из обратного и и индекса вот по этим словам маркером the response from + код 4 целом наши запросы выглядит вот так вначале мы определяем так каким фильтром удовлетворяет на наша запись а затем а какой временной интервал она приходится для этого мы и мы делим ее timestamp она фиксированную длину и интервала на графике затем мы группируем по этому значению что чтобы высчитать статистику по всем богом на вот этом временном интервале результате у нас вот такая выборка образуется по числу спас правом игру пировали из если помощью можно восстановить граница интервала а слева у нас статистика по фильтрам первому второму ну и так далее и в конце общее число записей общие нужно для киба на что про строила на мнение непрерывной графике то есть в ластики всегда при агрегирование есть и и общее число и по баки там в фильтрах нам это нужно эмулировать ну и в принципе по функциональности это все что нам было нужно и поэтому вот на этом мы пока что становились давайте подведем те действия которые мы совершили для реализации и золотым попробуем это на то как основная задача которой мы ставили перед собой изначально организовать доставку логов мы сделали это через кафку мы получилось гарантированно надежно нам нравится эмулировать связь с власти кассир чем здесь мы изгибание мы провели конфигурационный url направили его на наш адаптер который прикинулся велась костер чего на самом деле входит в playhouse и настройки своих хранить там же по функциональности ластиком и сделали поиск на основе обратного индекса обратный индекс у нас не простой а свой мы там используем не идентификаторы a timestamp в качестве идентифицирующие и фиксирующее сущности затем мы индексируем не все колонки которые там есть то только те которые нам реально нужны и индексируем не все слова часто употребляющие все слова мы не индексируем считаем что они есть просто во всех логах код адаптером и записать или выложили его на give up namespace компании можете посмотреть по итогам что можно сказать на основе сделанного прототипа мы пришли к выводу что идея использовать crack house в качестве хранилища для логов это в принципе имеет право на существование технически это реализуемо и у этого есть свои плюсы в первую очередь конечно по занимаемому месту у нас получается что логе в плехова снимать где-то в 23 раза меньше места чем те же самые логии васька search что касается скорости работы то есть то есть здесь однозначно выигрышем получить не удалось почему потому что когда у нас много записей это все работает медленно и оптим оптимальный кейс для поиска в таком увлекался это по уникальным ключам например по номеру транзакции в таком случае нас найдется не более низких десятков записей данных будет обработано немного и практически все еще отец на начальном этапе при обращении к обратному индексу в этом случае скорость в 4 5 до 10 раз лучше чем власик search но если условия для поиска такое более общие и данных найдется много ну например у нас по фразе киви саксэс может найтись несколько десятков тысяч логов в таком случае утки bows работает медленнее ластика где-то 1 5 наверное к плюсам ластик search еще можно отнести то что он прекрасно работает из коробки вот такая система она требует дополнительной настройки и определенные дисциплины работы с этим дальше нужно заранее определить схему логов решить что именно будем индексировать и в дальнейшем этом исследовать как бы следить за типами не искать пони индексированным колонкам не искать по всем колонкам случае если у нас какие-то не индексирован и такие есть ограничения свете нужно будет как-то жить в общем можно сказать что решение это но не для всех очень многое зависит от того какие сценарии работы у вас с поиском число гамме есть и от объема данных которые вы подлоге себе определили если в вашем случае снижение объема данных в два-три раза приведет прямо к существенному увеличению уменьшению костов на содержание такой инфраструктуры то возможно тварин для вас если вы еще ищите пользуйтесь поиском ищите некоторые небольшие группы записи и а еще лучше даже отдельные записи то еще получите большой выигрыш по скорости в других условиях результат может отличаться поэтому думайте решайте взвешивайте все за и против и тогда уже определять спасибо спасибо привет света при этом спасибо за доклад актуальна тема столько самое главное не рассказали как выписан выкладываете объектную структуру джона столбцы как вы укладываете 2 будет про то что что делать когда данные меня структур тип до пину у нас блоге в обычном виде они имеют вложенный структуру джейсон естественному как у всех могут но так как мы не хотим использовать остатки привыкли к выси мы просто их у себя прямо темно конечные колонки то есть если объект имеет название там а о под объекта б имя у нас будет просто отдельный колонка которую называться а там подчеркни б то есть мы в plain вид для клика last распределяем в случае для что делать если меняется схема логов да вот власти это было просто здесь придется делать alter других вариантов каких-то нет альтерна табличку то есть если винтам шоу при а потом оба встреча прошла в этом же поле вы будете альпертом делать да поэтому это неудобно да согласен о каких-то других более крутых штук а где то и три золота какой момент дтп то есть прям пришло первое поле там другого типа вы сразу альта запускаете или рублей мы заранее определяемся когда нас начинают вести логи определенного типа сменяет типа не или нет стопа рим это все alt и рим и тогда но я имею ввиду что другая там команда которая пишет логе она же не обязательно вам об этом скажет что они поменяют тип просто неожиданно какой-то момент придет типа да ну вот еще может быть сразу отвечу немножко дальше это система которым мы сделали она у нас в прототипе какого-то productions кейс у такого большого нет поэтому таких деталей как бы и нет как как с этим дальше работать по поводу структуры 1 после если вы учились велась из-за кликала со все данные вы их потом в эту структуру просто из названия столбцов как бы собираете назад чтобы кивано отдать спасибо да у нас ее в коде есть мама pink там чем через теги но это писали и вот там у нас структуру нас и вся теги и мягко усе имя в киба не но и все-все получил от это удалить из гор работали там можно представить коли красную табличку виде обычной структуры а то как она выглядит будет выглядеть в покое в кепке бани и как она должна сохраняться в клик хаус это все делается через свое теги в этой структуре спасибо за спасибо за доклад вопрос очень много было и ещё я там сказали что нельзя сделать смотрю посмотрел это можно дать можно где мы сразу ответить мы можем сделать матери зоны view но она не будет наполняться данными то есть физически она его сделать никто не запретит она при первом при первом нет матвею нам от на табличку которая сама запалить илси смотрю ну не работал это раньше есть стишок на это нет хобби а не писать писали об этом что когда-нибудь может быть сделать не знаю может вы сделали конечно обновляться там она не будет но то есть все все да где то что то там были они в три будут а если создания новая эра пойдет что вы используете если у вас там реплейсер h3 туда от не будет работать это был следующий вопрос что вы используете вот там после кафки вас идет идет обычный мерз 30 и принятых мер 3 хорошо и еще такой вопрос и сказали что там stampa лучше хранить там на на секунду даже данного все хранится максимум до секунд что вы делаете с этим the time используем у нас просто меньше 4 длинные просто все спасибо спасибо за доклад я услышал что ваш саппорт ходит скиба ну ищет там потом казакша найди мне кажется это эскиз для бэк-офиса у вас есть бэк-офис у нас есть быка офис нас запрос пролетают саппорт с разных мест и садике на самом деле может пользоваться не только саппорта аналитики поэтому предсказать предугадать и кейс кто туда зайдет и будет этим пользоваться как бы нельзя саппорт это такой собирательный образ возможность бы кофе спасибо за доклад хотел бы узнать насколько ресурсоемкая вся система и насколько стабильно по употреблению ресурсов не случается ли вы же ранее свете не весь он не случается в лирании диска какие-то неожиданные пике да нет не будут не случается такого он опять же если у вас нету скажем кафка кафки в вашем контуры да то вам определенно нужно быть вы поднять и это дополнительные ресурсы у нас она была мы ее просто задействовали поэтому каких-то по памяти по диску опять же получится эффективнее чем хранится власти ксир чьи поэтому не сильнее этим было бы там ну вот пожалуй все ничего такого непредсказуемого кстати по доставке логов по доставке логов если вам вдруг не хочется использовать кафку и хочется поразбираться можно ли будет сделать это надежно есть и другие варианты можно использовать эти нити я знаю сделали плагин для ног старше который пишет непосредственно в кафку но мы его и не пробовали потому что не показалась нам это надежно там есть какие-то сценарий работы случай если не получилось записать какие-то ретро и очереди можно попробовать мы в эту сторону особо не копали потому что сразу при делились тем как хотя нет настали до туда логе ластик все чаще это вас полностью устраивал но не устраивал производительность и из-за этого это вы стали делать это я сейчас тоже занимаюсь тестированием производительности и как бы вот у меня там 72 метра ну там есть 8 гбайт памяти и в принципе я стабильно 100000 строчек логов в секунду я индексируют ну то есть там у меня тоже несколько терабайта пять терабайт логову я и я их индексируются ну скажем 12 16 часов на одном сервере вот хочется узнать у вас какие мощности были и какие скорости там вот пиковые а вот именно ну чтобы прям на грузился по максимуму и работали три часа ну вот что по индексу занимают дневному вот коля говорил у нас получилось до 80 терабайт сколько это будет в секунду получалось влогах сейчас на нем есть не скажу ну и вообще как как мы пришли к этой светлой мысли использовать как легко узнать для ломов изначально когда возникла проблема с и ластиком с съемка стеком у нас ее начали решать по двум как бы фронтом проблема одну не оставили жить по себе админы и решали по-своему пытались как то мы попробовали в эту сторону сделать прототип когда мы его сделали он наши администраторы поставили шестую версию ластика 6 киба ну и как-то ну поехали чьи новые железки и получилось что с этим можно более-менее жить поэтому вот эта вся история которой сейчас прописана у нас таком в резервном канале и замерла под в резервном варианте для доставки логов потому что мы более менее научились жить с и ластиком который стал быстрее да и как может быть по железу не что ты приехала дополнительно поэтому 72 медитировал но я еще смотрю что у вас есть лог-файл бит лак stage in file pid здесь тоже все люди по монетным отдельная такая же которая живет но одну треть точно если вот я 3g руби и там какая-то такой адский ад вот соответственно если его не использовать файл бит как ты научение ну я просто вынес это вынесла усечь лог стаж на самих аст и вот он там отбирает память но вроде они живы и сам elastic достаточно шустро и вот возможно такое решение и помогло в том числе нашим админу потому что я знаю точно что стоял лог страшно мастерноде который можно было следить за всеми в пластиковом кластере раньше когда в но в новой версии с приходом на новый ластика и с новыми железками это вынесли плохо смысле оттуда как бы вот это это же россия облегчило жизнь просто сильно облегчить жизнь здравствуйте спасибо за доклад как и понял в логе раскладывайте по колонкам правильно treehouse есть функции для работы с бессонными как охладилась джейсон их можно было бы их сразу в одной колонке храните потом выбирать оттуда не думали об этом мы знаем о таком варианте но нет мы и так не делали потому что фильтрация пока кот по какой-то колонки она баксан они быстрее чем это сделал бы clear house не медленнее точнее а в кликал смог сделать медленнее tac toy и только 8 можно искать по лайку да ну это такой поиск ну просто тогда бы ушли по строгой схемы данных можно лить ну может быть может быть некоторые колонки которые имеют в себе еще вложенные структуры можно было бы вынести в для такой схемы не пробовали просто необходимости может не возникнуть понятно спасибо остались еще вопросы тогда нам нужно выбрать лучше душу вот человеку и человеку про его steep можно эти подарки пожалуйста к нам на сцену представьтесь и расскажите о себе войти сфере на я дмитрий перфильев я работаю в им всем solutions и агрегатор сообщения то есть все эсэмэски которые от банков идут паролем с 1 одноразовые коды вот мы этим занимаемся ну вот у нас очень много лагов и соответственно нам потребовалось система которая бы позволила человеческие работы с ними логов очень много и есть люди которые за клик house есть который завелась а вот мы решили сделать какую-то там тест производительности и вышли на вот максимум не было 130 тысяч индексации logo в секунду на одной воде к ластиков да меня зовут артемий работая валит и мы тоже страдаем сила стингом поэтому у нас есть несколько усаму то что снимаем эту сторону есть идея а что если sings попробовать запихать потому что у нас андрей оксана как бы мы с ним обсуждаем как вы на тему того как бы этот синг се жирует и полна тексты поиск сразу поддержать нормально вот поэтому игру тонн доклад был интересный вопрос кстати услышьте спасибо спасибо"
}