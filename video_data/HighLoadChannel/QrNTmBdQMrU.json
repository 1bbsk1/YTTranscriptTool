{
  "video_id": "QrNTmBdQMrU",
  "channel": "HighLoadChannel",
  "title": "Внутреннее устройство, тюнинг и мониторинг Tarantool/Vinyl /Константин Осипов(Tarantool)",
  "views": 3260,
  "duration": 4004,
  "published": "2018-07-19T13:22:50-07:00",
  "text": "вот винил дисковый движок который появился версия 17 мы продолжаем его развивать версия 19 было много обновлений и версии 10 мы тоже хотим целый ряд fitch для этого движка я про него уже довольно давно рассказываю года три как потому что для нас очень большое тело моего давно делаем поэтому меня вопрос к вам чтобы кто читал мою статью на хабре из присутствующих здесь раз так наука подождите так на в общем-то да то есть многое из того что я буду той с ним просто многое вся первая часть которой относится именно к устройству то есть у меня меня очень сложная задача сейчас да с одной стороны люди которые читали а кто понял понял а гораздо меньше вот чем дело то есть моя меня сложная задача с одной стороны людям которые в общем то не сталкивались с этим материалом что-то рассказать причем за 45 минут с другой стороны людям которые уже знакомы с темой да что то новое вот поэтому давайте мы попробуем начать с каких-то базовых вещей и вы помогаете мне же называется скролить вперед для того чтобы помогайте вопросами помогайте так сказать прерывайте меня если я говорю какие-то очевидные вещи чтобы мы дошли до каких-то до какого-то нового материала который добавил к этой к этому событию и мы поговорили волю больше про какие-то детали и так какой боксита план план того что собираюсь сегодня рассказывать ну наверное на сегодня уже особо рассказывать о том зачем это сделали мы уже это сделали ну не стоит для этого были причины мы их наверное сейчас опустим я начну с рассказа о том как устроен самуила сэм дерево потому что все таки все кто понимает кто не даже так те кто читал мои статью они должны хотя бы были но как-то разобраться с устройством мало самом деле давайте так кому нужна информация в устройстве об алгоритме лоси то есть немного то есть многие знают что такое ласам дерево так что ли получается нет не будет ну то есть вот эта часть мы можем просто про скипать даты домашняя работа хорошо значит дальше мы проведем какое-то сравнение между lsm и классической технологии вся вся проблема тюнинга оптимизация она возникает из недостатков амина должны сначала те недостатки как бы обсудить дальше мы посмотрим на самом деле на нем ножку другом порядке учитываю нашу аудиторию над тюнингом мониторинг на что смотреть как как пользоваться и посмотрим если хватит времени на расширенные возможности давайте начнем с устройства волос м а вот тот для того чтобы рассказывать правило сэм нужен какой-то reference point нужно нужно начать с понимание того как устроена стандартная база данных что как она хранит информацию там вэба деревьев кому нужно опять же в аудитории эта информация что такое б дерево отлично ничего себе вы про ширина я аудитория мы так так сказать si дает плоды до усилия но скажу просто формально давно дереве данные упорядоченное условно говоря слева направо и до крайнем левом узле у нас самое маленькое значение в крайне правом допустим самое большое значение в отличие от там какого-то бинарного дерева она гораздо более менее развесистая и любая операция но она классической она очень похожа на любой поиск в любой школьный ну условно институтской структуре да надо мы находим нужный узел модифицируем не им значения записываем его на диск если мы читаем опять же находим нужный узел читаем blocks диска и поверх этого большинство свободы они накручивают такие штуки как кэширования как всякие сложные истории с тем что и в каком блоке хранится управления версиями данных и так далее да вот для того чтобы осознать что такое ла-7 все-таки мы как бы эту историю про говорим нужно представить себе ни одно дерево да не одну порядочную структуру данных а целый каскад упорядоченную структуру данных и если мы будем говорить про винил то помимо каскада то есть там винил устроен как фракталы алиса в стране чудес то есть 1 1 мы об этом поговорим чуть позже да то есть одно lsm дерево это просто компонент из которого строится сам яндекс а яндекс это компонент из которого строится вся таблица и так далее вот но давайте просто поговорим про базовые вещи в элосе не как как как эта вся штука работает в отличие от классического дерево которое хранит имена значение lsm хранит операция это ключевой момент за счет хранения операций мы можем фактически трансформировать эту структуру данных и сохранения данных хранение истории и вся работа lsm алгоритмы это какой-то у порядке ли упорядочивания истории работы с данными какие-то операции классические операции to replace и дэвид их всего 2 в случае тарантулы есть еще absurd мы про него поговорим отдельно сейчас нужно просто осознать что есть реплей сабель или соответственно сама сама запись в дереве оно устроено вот примерно так как здесь как здесь написано да то есть ключ по которому собственно нас делается порядочность это первичный ключ и либо вторичный это сынок sequence number то есть номер операции глобальный номер операции вообще можно сказать номер транзакции это вот этот код один из риплейс либо до лета да и собственно некое значение строка документ не важно что то есть это отображение ключа назначение да вот если посмотреть на там сам какой совсем простой пример то мы получаем вот пример например вот такую вот табличку обратите внимание на то что она упорядочена по ключу эта табличка то есть у нас есть некая упорядоченная структура данных она может быть здесь она у меня представлено именно таблицей и в принципе это может быть какое-то дерево это может просто отсортированный список неважно что главное что вот есть вот эти вот значение они таким образом порядочен и обратите внимание что есть вторичная упорядоченность в пределах одного и того же ключа есть упорядоченность в обратном порядке павел с н то есть наверху условно говоря меньшим считается более новое значение то есть мы беремся вести наш журнал изменений до который то есть все что происходит с базы данных мы записываем в такой журнал но если классический журнал он имеет порядочность строго по времени то есть российском журнале первой строкой будет вот это потом вот это потом вот этот 53 сон и так далее да то здесь у нас пир сначала порядочнее подключу только потом появился и этот журнал изначально lsm дерево хранит в оперативной памяти вот она хранит это в оперативной памяти до тех пор пока журнал не передок а пока объем оперативной памяти под хранение переполнится что это дает хранение в оперативной памяти нас любая операция любая запись волосам дерево она не пишет на диск вообще она просто до подала добавляет а запись ну понятно что есть журналирование классическое журналирование менеджера транзакций которые мы сейчас не рассматриваем а но всегда есть она находится сбоку и есть еще журнал с вот такой соответственно у тарантула есть для этого прямо ручка называется винил memory который определяет размер этой оперативной памяти понятное дело что мы чаще мы его имеем дело с десятками как я уже говорил вот сам деревьев например у нас много разных таблиц много индексах в одной и той же таблицы на концептуально вот эта ручка она определяет размер этой таблице дальше происходит переполнение да логично предположить что рано или поздно все этот приз переполнится что нас доступны в оперативной памяти и в этом случае берется вся все фильтр весь уровень и записывается на диск целиком и старые уровня по совершается вот на этой картинке мы соответственно уже избавились от лак sequins на барах и в нам баров то есть от номеров операций просто храним показываем ключи да опять же ключи могут быть любые они могут быть строковые могут быть числа вы это не важно здесь числа вы просто для того чтобы проиллюстрировать но обратите внимание что на диске вот этот уровень памяти уровень диска в памяти у нас всего один такой буфер а на диске у нас рано или поздно ну естественно образом накопится большое количество дампов да значит и вся остальная история lsm она направлена на то чтобы каким-то образом управлять этими домами на диске потому что ну естественно если мы просто берем и дампе вот эти вот все операции на диск постоянно то нам очень сложно читать нам для того чтобы прочитать найти информацию нужно поискать в каждом файле да вот соответственно основной процесс который уже работает в бэкграунде волосам структуре данных процесс называется compaq шин он берет несколько файлов и из них делает один файл опять же упорядоченные по ключу но уже в котором мы можем как-то более удобно искать ну я думаю что это должно быть очевидно да то есть это такое введение всем все заявляли что знают что такое lsm поэтому ну пока что все четко да да значит ну поехали дальше проговорю пару слов про опять же чисто формальным надеюсь что вы все понимаете про то как работает в этой системе удаления концептуально у нас каждый вот такой дамп после того как он записан на диск он нему топилин то есть то что мы можем сделать это взять два файла отсортировать их и получить новый файл отсортированы уже по всему каким образом данные в такой истории удалять удаление волосам дереву представлены как операции да то есть это отдельная операция возвращаясь вот сюда и она точно также записывается вот обратите внимание в журнал такой порядочный в memory уровень просто как операция конечном итоге во время слияния этих файлов мы что делаем мы сначала дам пим удаление на диск вот она оказывается на диске она сливается она сливается с этим уровнем дальше происходит некое слияние происходит файлов и в конечном итоге вот смотрите мы возьмем предыдущий слайд вот у нас есть ключ 2610 лишь 26 в самом нижнем уровне до конечном итоге когда эти два друга встретятся они друг друга взаимо уничтожить и в результате одного из слияний у нас видите лишь 26 и сейчас конечно из из-за результирующий структуры данных то есть удаление проходят через все файлы насквозь процессе слияний пока не вынесут называется из дерева своего своего свою записи как происходит чтение собственно вот если вернуться к этому слайду и все-таки проговорю значит при поиске мы ищем информацию в этих журналах журналов есть очень интересно таких вот у memory уровне дампов журнала буду разному произносить одно и то же слово у них что что у них есть одно свойство что новые данные они всегда находятся как бы выше концептуально вот по вот этой иерархии то есть мы дам пим этот уровень и он всегда содержит более новые данные более свежие были старые находится где-то там дальше в списке этих файлов дампов соответственно при поиске мы просто должны перебрать все наши дампы да и и результат если я ником компактно той вот эти файлы иной если мы нашли искомую информацию то все замечательно мы можем остановить поиска вернуть значение пользователь потому что гарантированно самое свежее значение если мы нашли далит то есть ключ на 10 значит код для этого ключа дали тут в этого ключа нету то же самое свежее значение но в худшем случае нам приходится пройти по всем файлам если допустим значение не найдено то мы об этом узнаем только тогда когда про шерстим все вот здесь это собственно проиллюстрирована мы делаем поиск если 16 сначала ищем на этом уровне потом спускаемся на уровень ниже на уровень ниже и вот в конце концов какой-то момент мы найдем значение 16 что происходит если поиск делается по диапазону то есть нам нужно найти ни одно значение в базы данных это частый сценарий мы открываем курсор или искали использует там select between там и указывает два значения диапазона в этом случае просто вот такой оптимистичный до по порту низкий сценарий когда мы можем завершить поиск сразу после того как прошли нашли первое значение он не работает нам нужно прошерстить к сожалению все все наши уровня и осуществить влияние того что нашли получить уже исходящий диапазон обратите внимание что на этой иллюстрации у меня уже есть какие-то новые новые концепции где-то концепции уже именно винильная мы их более подробно рассмотрим как только начнем говорить в недостатках этого подхода но вот здесь если вернуться к терминологии эль 0 лидера это это память наши оперативная assorted ран это какие-то файлы на диске то есть мы берем все все что находится в текущей оперативной памяти берем все файлы осуществляем слияние получаем результат ну вот такое краткое введение я честно сказать уже наверно не один десяток раз рассказывал про то что такое lsm и так быстро мне не удавалось это сделать никогда значит что называется сам понял профессор скажите пожалуйста если поэтому вопрос или мы можем двинуться дальше нет замечательно значит что с в у этой структуры данных как бы какие у нее преимущество да какие преимущества и недостатки проблемы вообще чем она такая замечательная почему мы ее стали использовать чему не использовали классические б деревья значит вот для того чтобы как бы рассуждать те же преимуществах и недостатках нужен некий контекст нужна некая модель сравнения классическая модель сравнения которая используется в литературе в компьютер сайнс это так называемая вычислительная сложность алгоритмов мы там все про это знаем в общем один алгоритм делают логарифм того операции другой алгоритм делает н п квадрат операции и так далее вообще вся история с такими структурами данными данных это называется конечно oblivious структура она родилась как некие ответ на то что вычислительная сложность больше не работает когда мы сталкиваемся современным оборудованием речь идет о целый иерархии устройств и невозможно сказать собственно с каким устройством алгоритм работает то есть допустим он может хорошо эффективного использовать кэш то может неэффективно может он линейно читать с диска а может не линейно и когда мы сравниваем 2 2 структуры данных им вот здесь это таблице приведено сравнение по вычислительной сложности именно мы сравниваем в некой их в контексте никого идеального вычислителя у которого есть словно диск и память да и у диска есть некие операции прочитаь не я там блок и запиши блок в реальности это не так есть диски с оперативной памяти есть кэш процессора разного уровня и так далее давайте сначала разберемся с тем как эти вот классическая структура вела сэм сравнивается в стандартном контексте а потом приведем какой-то другой фреймов reference с помощью которого мы можем показать преимущества его сэма то есть с точки зрения алгоритмической сложности смотрите в б дереве для того чтобы расширить поиск мы берем начинаем с рут блока спускаемся влево вправо влево вправо пока не ну и по посылкам пока не дошли до листового узла это логарифм от числа значений шагов логарифм а по основанию b в b это размер это количество элементов в одном блоке бы дерево для того чтобы растить поиск в lsm мы берем вот это вот все да и еще умножаем на некое число k которая на самом деле является функцией форма дерева да это каретка какое количество файлов нам нужно поискать но очевидно что мы каждый файл тоже можем представить в виде бы дерево поэтому здесь у меня указан бинарный поиск но на самом деле это может быть не бинарный поиск это может быть поиск падения но у нас хотя бы нужно поискать в каждом файле соответственно нас к файлов то есть это в k раз хуже ну чему равно k мы для того что много равно к должны оценить размер вот этой вот структуры я готов это сейчас так сказать готов этому посвятить время на сначала давайте просто базовый рассмотрим что у нас есть какое-то количество файлов каким-то образом они сливаются в каком-то алгоритм и в любом случае мы все время сливать не можем кстати понятно почему мы не можем при каждом дампе инициировать компактным нет непонятные не очевидно да смотрите если мы при каждом дампе require отвалился на давайте я про это чуть скажу сразу вот смотрите вот у нас здесь есть некая каноническая картинка если у нас при каждом дампе инициируется compaq шин то есть вот у нас есть объем оперативной памяти допустим 100 мегабайт и общий размер базы данных на диске допустим 10 гигабайт да там и каждый для того чтобы записать каждый 100 мегабайт на диск мы фактически пишем 10 гигабайт то есть понятно что ну эта структура будет в разы и менее эффективно чем даже бы дерево потому что случае бы дерево но мы сейчас все это можем посчитать случае бы дерево для того чтобы записать там 100 мегабайт данных мы ну запишем на самом деле на диск где-то 4 гигабайта а здесь для того чтобы записать 100 мегабайт мегабайт данных мы бы вы написать 10 гигабайт вот вот примерно такая арифметика то есть это невыгодно реально все файлы на диске они упорядочиваются в некое в некую пирамиду и compaq шин происходит тех файлов которые более-менее похожи по размеру то есть вот наш произошел дамп мы нашли предыдущий дамп обратите внимание здесь есть как бы такие маленькие файлики мы видим что этих файликов становится слишком многому берем их сливаем обратите внимание что при слиянии у нас еще происходит удаление то есть мы еще чистим мусор и у нас получается один файл чуть большего размера можем он может быть в 3 раза больше если montreal три файла заливаем но обычно он будет не менее чем в 3 раза больше потому что есть удаление есть дубликат и 1 это одно и то же значение обновляется несколько раз дальше рано или поздно нас постоянно журнала новые появляются у нас несколько таких файлов появятся уже в результате слияние непрямые дампа файлы получены результате слияния мы образуем что этих файлов много берем их сливаем тоже и получаем вот такой большой файл то есть файл и таким образом они структурируются в некую пирамиду и и как раз вот этот фактор showa роста размера файлов волосам дерево определяют ну давайте это просто можем посчитать представим себе что каждый следующих что мы сливаем файлы да и для слияния находим только файлы шаг слияние у нас равен двум то есть мы вот у нас есть концептуальный level 0 то память значит здесь мысли сливаем файлы когда их больше двух да и мы сливаем только те файлы которые размеру одинаковые и шаг размера он равен двум да то есть вот здесь образовалось два файла мы их слили получили еще один файл в два раза больше вы толкнули его на следующий уровень здесь у нас пусто и соответственно пока на следующем уровне не 1 уровне появится двух файлов в два раза большим размером мы не будем отчислят слияния таким образом у нас все файлы они как бы все все данные они образуют такую пирамидку каждый следующий слой он будет в два раза больше предыдущего вот смотрите я проиллюстрирую это а я не могу это проиллюстрировать у нас нет флипчарт у нас не отличат в общем у нас получается ряд из серии единица плюс 1 2 то есть на самом нижнем уровне нас лежит единиц а потом на верхнем уровне 1 2 потом чуть выше уровня 1 4 1 8 вот такая пирамидка этот ряд в сумме дают двойку то есть одна единица плюс 1 2 + 1 4 плюс 1 8 и так далее дает двойку и вот просто при таком подходе к выбору размеров этих уровней мы говорим о том что у нас общий размер вот этой базы данных он будет не более чем в два раза превышать количество данных которые там естественным образом есть ну смотрите гарантированно в самом нижнем уровне у нас есть все данные если бы они где то есть они есть самом нижнем уровне все уровни от нижнего до верхнего все остальные уровня занимают еще единицу соответственно вот у нас получается такой вот overhead на мусор в реальности если мы опять же посмотрим на тарантул то соотношение размеров уровня уровня выбирается больше чем 2 убирается в тарантул это 7 в кассандры это 10 то есть в реальности overhead еще ниже но все таки мы не осуществляем слияние при каждом дамбе мы расширяем слияние только похожих файлов давайте вернемся к таблице сравнения clicker значит здесь у нас в итоге появляется к вот этих уровней количеству к опять же если мы знаем форму дерева можно посчитать случай если вот обратите внимание если нас уровень растет в два раза каждый следующий уровень тока это логарифм от n на п п то мы считаем что размеру evil zero уровня в память случае если у нас размер у меня растут по другому как будет еще меньше ну то есть но в любом случае это много то есть как бы как бы как представить число много вот представьте себе вэба дерево вы у вас бы дерево из скажем 100 миллионов элементов в одном блоке у вас там 20 миллионов миллионов момент я сейчас не могу произвести там без калькулятора все математику но это означает чтобы дерево вас будет 45 уровней может быть 6 уровней здесь у вас будет все то же самое но только еще будет 45 уровней файлов еще в каждом файле вам нужно искать как будто это бы дерево то есть вы в там в пять-шесть раз увеличились стоим и стоимость поиска стоимость записи или вставки у вас напротив гораздо ниже потому что чаще всего вы вставляете в оперативную память и вот вся остальная часть собственно доклада она про то как эта структура работают как она балансирует стоим и записи стоимостью поиска чтобы стоимость поиском плане слишком высокой потому что стоимость поисков в дерево как я уже говорил в несколько раз или выше чем стоимость поисков воде и значит прежде чем мы об этом поговорим в принципе давайте с некий самаре того какие проблемы от этой структуры возникают главная проблема этого так называемые ридом префикса вторая проблема это то что если мы вот давайте я вам дам фреймов reference немножко другой вот смотрите когда мы пишем одно значение b деревом и на диск пишем блок целиком блок бы дерево то есть одно значение приводит тому что вы записали блок блоки допустим 20 значений в двадцать раз больше запись одного значения волосам дерева и говорит о том что вы просто записали самойло сын вот этот дом целиком то есть саму стоимость этого значения вы записали вот общий термин которая обозначает сколько лишний записи вы сделали он называется в райт амплификация и в в дереве в рай там плиссе конечно возникает за счет того что вы лечите пишите блоки целиком волосинки rewrite амплификация возникает за того что вы делаете compact мусор мусора в дерево может больше чем собственно размер последнего она в нем присутствует потому что мы храним журналы это проблем называется space амплификация и последняя собственно то с чего мы на самом деле начнем сейчас это то что по своей за своей каскадной природы у нас нелинейная стоимость за стоимость дампа снижение стоимость записи в дерево то есть когда мы пишем от значения которые не приводят к дампу у нас это очень дешево когда он пишем значение которые приводят дампу это это запись она несет себе всю цену записи всех предыдущих значений давайте этот пропустим давайте давайте посмотрим на то собственно каким образом мы мы это решаем я начну с того что того как мы решаем проблему с сказка с качками la pensee в вот смотрите если мы будем как я говорил писать тот момент когда у нас переполнился memory уровень этот memory уровень на диск все те транзакции которые пришли в этот момент они окажутся несчастными они будут ждать они будут страдать подход очень простой мы берем и предсказываем предугадываем тот момент когда у нас память кончится и начинаем писать на диск ранее за заранее вот смотрите я сейчас покажу статистику а у меня уехал слайд каким-то образом невероятно вот эту штуку нельзя никак поднять она просто проецирует ниже чем то есть слайды и кончаются чуть ниже мониторе то же самое она тогда это папа на офисы против powerpoint а ну давайте давайте давайте вернёмся без статистике вот есть просто 100 была статистика мониторинг который хотел привести вы смотрите представьте себе что у нас скажем 100 мегабайт доступной оперативной памяти скорость записи скорость вот накопления журнала она допустим равна 5 мегабайт в секунду скорость торт скорость записи журнала на диск она равна допустим 10 мегабайт в секунду соответственно для того чтобы записать журнал у нас есть 100 мегабайт оперативной памяти наших записать эти 100 мегабайт оперативной памяти нам нужно 10 секунд соответственно мы должны начать дам за десять секунд до того как у нас память закончится правильно для того чтобы начать дам за 10 секунды того как память закончится нам нужно начать его когда мы накопили 50 мегабайт из ста то есть имея там 100 мегабайт доступных для записи эффективными и для мы оставляем 50 и просто другая половина пишем пока мы пишем половину буферы на диск мы накапливаем данный во второй половине постоянно ротировать эту историю соответственно если возникает какое-то уже ну ничто не может никто не может запретить пользователю писать больше чем влезает вообще в диска то есть он может писать у нас 100 мегабайт в секунду пытаться в этом случае уже срабатывает механизм квартира вания то есть как только у нас заканчивается кого-то транзакции которые ждут вот этот винил memory вот она этот винил на море все транзакции которые не поместились они уже ждут того что память освободиться все так это работает так мы боремся с скачками way пенсию значит дальше стоимость чтений вот обратите внимание что когда я рассказывал как про то как происходит чтение мы я упомянул еще вот эти вот две истории еще два каких-то концептуальных уровней из которых мы делаем стене в виниле есть полноценная поддержка транзакции соответственно все незаконченные данные они не присутствуют в дерри они присутствуют в отдельном структуры который называется менеджером транзакций и естественно для того чтобы базы данных могла читать свои собственные то есть вот транзакция могла читать свои собственные изменения да все остальные транзакции хочу видеть не могут мы должны подключить этот уровень второй уровень который мы используем это так этот это уровень каширования то есть тоже классический способ для того чтобы скорость чтения с диском и каширу имаиси чтение если они уже до этого дана использовались мы используем повторно что интересно про винил значит переменная которая определяет размер этой структуры данных называется винил кэш удивительным образом но в отличие от там каких-то других решений можем в этом более подробно говорить просто не в контексте 45-минутного докладываешь виниле он не кэширует данные на диске он устроен совершенно своим образом он кэширует значение который уже прочитанных диск только те значения которые были нужны то есть классический cachito пачкая шон кэширует страницы или кэш просто файловый он будет кэшировать блоки в блоке на диске у нас cacib отличается следующие ускорение которое мы используем для того чтобы снизить стоимость теней тут просто того чтобы по ним поговорить нужно разобраться с феноменом который так называется скрытые чтения вот смотрите вот классической базе данных вы когда даже не меняйте меняете просто делаете insert у вас появляется скрытые чтение вам нужно для того чтобы сделать вставку базы данных вам нужно проверить наличие базе данных дубликатов чаще всего когда пользователь делят insert он делает вставку ну еще не существующего объекта но на более частой сценарий зачем ему получать ошибки но случае с bright оптимальность алгоритмами мы знать заране не можем поэтому в для того чтобы ускорить вот именно такие чтения не существующих записей используется вероятность на и структуры данных это называется блин фильтр кто знаком с этой историей вот она у нас тоже реализовано то есть если секунду я все время путаю с тем что он licker нужно направлять на ноутбук и нужно слать а найти конечно не могу то есть если мы посмотрим вот на это чтение которое вынуждено пройтись по всем уровням то каждому уровню у нас с ним с каждом уровне с каждым файликом со стаци и равана небольшая битовая маска с помощью которой мы можем определить надо искать в этом уровне или нет это битве маска называется блин фильтра есть у нас будет чуть больше времени я готов и про это рассказать как это все работает но в общем то можно посмотреть википедии опцион виды большой не будет дальше для того чтобы вот если вернуться к оценке то смотрите вот здесь есть это беда с со стоимостью поиска которая говорит о том что нам нужно искать в каждом уровне каким-то потому в каждом этом файлик им по бинарным поиском естественно мы используем индексацию каждого уровня для того чтобы в каждом уровне гарантированы находить данные за 1 сиг то есть мы храним оперативной памяти яндекс по уровню это на так называемый позже индекс который позволяет поискать сначала в позже яндексе найти нужную страницу поэта можно найти в самом уровне ну и наконец мы используем компрессию для того чтобы lsm деревья позволяет очень хорошо сжимать данные и за счет компрессии мы также снижаем собственным тот объем который нам нужно поднимать диска когда машина им пользу вы смотрите вот я вот про все это рассказывая собственно зачем да то есть вот есть такая структура данных у нее есть такие сложности с чтениями зачем-то мы это сделали и зачем-то как бы вот вам все это надо значит история тарантула она права простоту использования да то есть вот от ключевое отличие memory движка заключается в том что это очень стабильная структура дано то есть если память есть он отдает делаются ставки удаления чтения за предсказуемо и время тебе ничего не надо особо максимум там слабо локатор как-то подкручивать это все здесь получить появляется довольно сложная по своему внутреннему устройству структуры которую для того чтобы ее глушенок готовить в ней надо разбираться зачем это сделать основное предназначение по нашему представлению этой структуре данных этого энджи надо то есть вы можете указывать это для каждого space отдельно это хранение так называемых холодных данных то есть это данные который в основном в основном не читаются пишется то есть если у вас данные горячий там 50 процентов все не 50 процентов записи но сейчас оперативная память наверное не так дорогая do i was working set вы можете разрешить разместить наши memory движке холодные данные вот для этого мы сделали вот такой движок какие особенности как его просто так взять и приготовить не получится то есть вот из-за этих особенностей устройства алгоритмом очень большой оптимизации которая направлена на ускорение записи и сложности чтения то есть вы не можете просто взять заменить нам тег с винилом соответственно что что нужно знать для того чтобы более-менее его готовить конфигуратор фигура ция вся эта история она довольно развесистая нужно настроить в первую очередь уровень размер оперативной памяти размер кэша по умолчанию размер оперативной памяти подменил стоять там 100 мегабайт размер кэша равен 100 мегабайт там но это соответственно ни о чем рассчитывать нужно из сад с нас понимания своего working сеты то есть первое что нужно о чем нужно подумать того чтобы приготовить эту историю это рассчитать размер базы данных до соответственно исходя из того что я говорю выше space амплификация о количестве мусора которые может генерироваться прикинуть и умножить на 2 потому что есть еще мусор то есть счетчик еще чекпоинта которой мы хранились все журналы то есть начинаем мы тепло и винил из того что мы понимаем что а он нам нужен б у нас есть достаточно под него дисков и c у нас есть достаточно и мы можем посчитать количество iops of до который нам хватит опция для того чтобы протянуть нашу нагрузка почти не запись значит после того как мы посмотрели размер нашего диском им нужно задуматься о том сколько оперативной памяти под это все делаю отвести правило большого пальца заключается в том что если у вас отношении 1 10 то у вас все будет хорошо к сожалению то есть это диск память к сожалению наши пользователи они хотят один links to некоторые монеты хотят один к тысяче то есть на 1 гигабайт оперативной памяти они хотят хранить 1 терабайт данных да он представьте себе значит что при этом соответственно в этой структуре данных происходит происходит ничего сансом для особенного не происходит если она используется именно под назначение если в основном в эту таблицу идут записи они чтения но к сожалению для того чтобы понимать как это все готовить нужно понимать когда возникают скрытые чтения в базе данных это не относится к винилу это относится к любому к любой как семантики базы данных то есть скрытые чтение возникают при нем сердцах естественным образом тоже нам нужно ограничение первичного ключа верить при апдейтах потому что нам нужно старое значение прочитать с диска иногда они возникают при вылетах потому что нам нужно удалить это из вторичных ключей если есть вторичный уникальный допустим вторичной ключей то они возникают мы сейчас работаем над патчем которые тут убирают но но главное если есть апдейты и insert и то преимущество структуры она уже чтобы сводится на нет да и тогда уже вступают в игру вот все остальные условно параметры то есть например мы insert и можем ускорить если определим bleu фильтры на ключи по которой на первичный ключ до в этом случае чаще всего bluefilters позволит избежать чтение с диска для того чтобы сделать insert апдейтом и ускорить ну никак не можем кроме как ты шел до ответственном нужно задумываться о том как максимально эффективно сделать сделать так чтобы апдейтом минимум читали данных с дисками вступает в игру такие параметры как размер страницы то есть один апдейт как и в классическом там бы дереве в случае винила читает с диска страницу целиком размер форма дерево которое в нашем случае определяется двумя переменными ранка он перевел и ранса израиля помните я вам говорил что ранса из расчета соотношение уровня между собой да насколько следующий уровень больше предыдущего в три с половиной раза ну там на самом деле в 7 потому что три с половиной надо дать файл следующего уровня в три с половиной раза больше чем файл предыдущего уровня на каждом уровне хранится ран hound per level от ран этот ранам в терминологии винила называется один файл sort it ran отсюда название ран вот ранка он перевел по умолчанию равен двум то есть каждый раз в семь раз больше предыдущего вот эти параметры чаще всего а скажем так вас будут удовлетворять тоже на что стоит смотреть первую очередь это печь сайт который по умолчанию равен 8 килобайт am если у вас данная если вас извините значение равно 8 килобайт то это уже во мне очень интересно потому что одна старая одно значение на страницу это неинтересно рассчитываетесь того что боишься из до 1 одна страничка должна сохранять на хотя бы сто-двести значений ну и в общем-то памяти кэш это главные параметры при оценке размера диска стоит еще учитывать что есть глобальные глобальные параметры которые влияют на потребляемую потребляемый диск например количество чек-поинтов который хранит тарантул и с каким интервалом делается check point то есть если у вас база данных опять же очень интенсивно меняется то вы просто журналов можете на генерировать за один час такое количество что они займут все места на диске и нужно эти параметры крутить дальше объем дампа и compaq шина может влиять на скорость чтений то есть вот смотрите у вас есть скрытые чтение у вас есть явные чтения и у вас есть еще использование полосы диска который используется слиянием файлов вот для того чтобы ограничить нагрузку на диск с ли они чаще всего имеет пиковую природы то есть появился задача на слияние она максимально интенсивно выполняется потом курим появилось еще больше файлов максимально интенсивно выполнены слияния курим соответственно для того чтобы избежать такого с таких спайках есть ручка под названием и а рейд лимит для слияний которые по умолчанию нас неограниченно потому что обычно полосы хватает но все-таки ее можно ограничить по той допустим 10 мегабайт секунда 20 мегабайт секунд таким образом ограничить я не слияние на скорость чтения и последнее о чем стоит иногда помнить что винил в целом сделан по принципу up and only базы данных то есть мы никогда не менее не модифицируем старые данные и по принципу разделение данных и индексов соответственно в случае если какие-то дан данные либо индексы за карабкались вся эта система умеет себя чинить force recovery достаточно поставить при старте в true и мы восстановим данным потерянные данные потеряны и диск потерянные индексы автоматом то есть мы произведем перри сортировку при recovery как это все выглядит на практике вы создаете space engine винил ставите для этого вот смотрите после этого создаете обычным образом yandex вот в этого индекса появляется дополнительная опция все что я вам говорил можно крутить для каждого конкретного индекса причем крути динамически то есть вы можете поменять эти опции а некоторые из них не будет сразу действия допустим почесать вы поменяли у вас уже кучу файлов со старым почесать вам не бросимся при билде телефон просто новый файл будем генерировать сна вам почитай сам значит ну я сожалею что такая история с наверно не видно да на черта короче мораль заключается в том что у винилин их индексов появляются новые опции на все это можно посмотреть после того как вы это начали эксплуатировать через статистику то есть есть новые и новые вывод статистики направлен на то как как качественный утилизируется кэш здесь статистика по интерактивным транзакциям проектом нужно отдельно наверное более интенсивно говорить в частности ну здесь как минимум показывается текущее число открытых транзакций какое количество запросов в открытых транзакциях то есть транзак молча стоит митрич молча стоит man транзакции вот здесь внизу у меня уехала использование дампы и компактным как используется кого-то плюс есть статистика у каждого индекса который также можно пользоваться то есть мы аккумулируем пирсинг или почти по по чтению из индекса какое количество данных в нем хранится количество байтов количество строк сколько ran over оч вова напомним что такое рано вич вова ран и врач количество файлов в яндексе да но и врач меня смущает и количество файлов в яндексе количество файлов в одном в одном яндексе да значит количество нет тут что-то но в раннего вечера аккаунт это одно и то же на самом деле случилось на 1 ренджа значит про рейндже я пока говорить не буду чаще всего вы видите вот это если у вас большая бан база то вы видите что-то другое и тогда все числа они их нужно делить discount дальше статистика по индексам сколько занимают фильтры сколько занимает страницы и и так далее ну и наконец как конкретная статистика по дампу и компактно для этого индекса то есть механизм тюнинга получается следующее вы создаете базу даете нагрузку смотрите на параметры дампа компактно и использование кэша и использования блин фильтров и крутите ручки связанные с настройками да то есть увеличиваете селективность для фильтров за счет этого переменной блюмов pr увеличиваете объем памяти увеличивать размер кэша пока не достигаете оптимальных параметров до для кс при эксплуатации но для того что все это закрутить начала нужно разобраться где у вас есть скрытые и явные чтения в вашем предложении вы можете давайте мы сейчас перейдем к вопросам прямо сейчас зададите да вот что называется провинился 45 минут я skip ну то детали проработаю transaction менеджера про специфические данные по все рты читайте мою статью там гораздо больше интернет информации нет информации правда про тюнинг мониторинг мы про это мы выпустим отдельную статью ну и сейчас уже тогда действительно время для вопросов спасибо да поднимаете но не страшно но ладно смотри у меня концептуальный вопрос он начинается как зачем вопрос шикарные часы потому что я вот только раскрою вот у нас сегодня был доклад brannan volatile рамы зачем мы делаем gold star ну вот нас очень просили мы сделали но это просто можно да я раскрою смотрю у нас есть штука которая ну явно плохо на selecta да у нас есть штука которая вроде как должна бы быть не плохая на запись но если у меня есть хоть один yandex но у меня возникают селекции и она также плохо соответственно очевидно хороша эта штука только для данных которые вообще не проиндексированы не просто валяться валяться в анальном проиндексирована пример по первичному ключу это или очень молода яндекс по первичным ключом мы говорим о том что оптимальные начиная опять же со 110 оптимальные будут не уникальны и вторичные ключи то есть они так плохо то есть они в нем не уникальна и вторичные включения будет не будут приводить к закрытым чтением но если у вас большой интенсивный поток апдейтов просто смотрите есть очень много приложений где но собственно лишь ты знаешь это приложение называется лента апдейтов даже insert вызывает черты и зелья за счет прямо за счет блюма на самом деле reflective хорошо да это была вторая часть вопроса единственно что мне здесь помогают это блюм даже остальное в общем-то вызывают вопрос зачем на самом деле мораль доклада заключается в том что в отличие от ментик со дисковые структуры данных причем любые вот по деревьям этим хороши ты поставил postgres он дает гарантированный 300 рпс но вот эта вся ужасная структуру данных она тоже даст гарантированный 300р ps на самом деле то есть даже на чтение даже со скрытыми чтениями совсем но если вы хотите десяточку то подходите к ней с умом вот мораль доклада такая просто пока нет ощущения что я могу получить больше фпс по 50 рекламе арочку если все правильно спроектирована на ней получить она потом расскажешь но не помню за счет чего но и про это и был мой вопрос что вы говорили что смотритель на свое приложение ну а толку смотреть он уже не может меньшей инвертор делать или апдейтов смотрите давайте еще раз разберемся и у нас на калькуляторе q смотреть на самом деле нужно то есть для того чтобы первую очередь на количество я бы начал анализ со следующего сколько вот какой процент ваших транзакций делает select и зачем давайте начнем с явных чтений давайте забудем про скрытый давайте начнем съемные часто винил начинают использовать для того чтобы просто берут комплекс приложение говорят о а сейчас у меня будет тарантул такой же быстрый но я буду в 10 раз меньше за это платить из использовать для этого винил и конечно мы видим крики в чате да почему она не работает и как это тюнить и так далее то есть это первый пункт второй пункт если вы видите что у вас явно чтение действительно мало вас в основном идут допустим insert и то то что стоит посмотреть это если у вас вторичные ключи и нас другой это уникальные к вторичной ключи либо их можно сделать не уникальными работает ли у вас bleu фильтры для них и так далее вот можете ли вы заменить например insert она replace и да если вы можете заменить enter the на риплейс и вас не уникальны и вторичных ключей тут опять же для вас это тоже подходит вы получите преимущество в райт optima из структуры данных то есть вот такой ответ заходит например у нас есть специфический оператор absurd который объединяет апдейты insert и он работает на виниле и работает быстро то есть десятки тысяч обзор то в секунду тоже получить реальное просто про это тоже не рассказываю что же специфический кейс не ответил или поздно планшет у мужчин до нужно подумать до интригами кондрат так вот у меня вообще вопрос такую надеюсь ваншотом я правильно понял основную идею всех этих структур чтобы они были адаптивны как под железо так поданы и так и под приложению ох это прямо за двиг на novol литра вот реально действительно понимаете действительно если посмотреть на lsm его ключевую такую такую вот разницу с деревом в том что она сама структура она в принципе адаптивно под нагрузку под time series она адаптивно под потому что time series например от кейс да у вас компакта на самом деле случае time series дата будет возникать гораздо меньше потому что вы один раз какой-то диапазон вас естественным образом брать надо отдельно говорить да под time серия с под вы высокую интенсивность беликов вот короче для того чтобы приготовить эту структуру нужно ее понимать вот действительно была правда спасибо большое за доклад меня на самом деле то и вопроса но не маленький 1 я правильно понимаю что бум фильтр и yandex они всегда в памяти хранятся да верно хорошо и это важный момент размер вы можете посмотреть в мониторинге и этот размеру он как бы его нужно вычислять это некий этникой касты которые идут помимо винил кэша винил нами до второй вопрос блок причесать получается 8 давос дефолт можете поставить вопрос такой дефолт появился вы как-то benchmark или просто у нас вроде по нашим бенчмарком основном в основном и создает и 4 64 килобайта достаточно всем известной more это что чем у нас появилась такой дефолт дефолт зависит от размера страницы понимаете август лет размер одной записи если у вас крупные записи вам нужен больше дефолт но исходя из того что у вас там 100 200 байт на закон и хорошо и последний вопрос касаемо того как происходит compact я могу сделать так чтобы compaq нить на другом диске ну допустим чтобы делить и обсе и писать не компактен и добавите рейд на двадцать первый век используйте рейд у вас все будет и abs и поделится там он вопрос у нас мало времени тоже нас начинается сессия крайней последний вопрос почему не получилось или не захотелось использовать какой-нибудь существующей engine базирующуюся на схожих принцип например rocks я на этот вопрос подробно отвечаю в статье у нас очень много специфики сингл трейды transaction менеджера который позволяет на самом деле сделать при правильном приготовлении эту структуру быстрее рокса то есть опять же вы берете вот эту структуру она на одном инстансе вам дает там нужно перформанса вы на дно машины можете загнать там десяток-другой инстансов то есть эта штука потенциально очень хорошо масштабируется будем фильтры на диск не дам поются дам поются они и дребин фильтры и p&g индекс дампа и цена диск креститься просто мы вовремя recovery их читаем массово в память с к ним а не в отдельных файлах хранятся им эти файлы со своим память если памяти не хватает если памяти вы не хватает вы берете покупаете больше памяти можно два вопроса вы меня 1 я до конца и мэр немножко не понял я занимаюсь не хватить и ни зэкам по винил memory можно достаточно безопасно увеличитель памяти много короче можно бить достаточно безопасно увеличивать размер и не беспокоиться за то что в один прекрасный момент вот он фильтрует когда там до половины дойдет до он начнет сливать там допустим там 30 40 гигов от половины от 80 выделенных одномоментно или смысле там не было не стал грехом который берёт это раньше вопрос офигенный значит памяти много туда влезла смотрите исходите из того что все таки садитесь следующих правил большого пальца во первых а нет смысла делать винил на море особенно крупным то есть если вот если вы lsm все-таки работает да то есть в этом префиксе шин если у вас все правильно вы снизить и по сравнению с бы деревом даже на соотношении 1 6 1 star все сразу станет уже хорошо то есть грубо говоря нет смысла если у вас хотя бы 50 процентов уже памяти есть то нет смысла 50 процентов памяти отводить подменил memory винила да если вас 10 процентов но он то есть как как какого рода машинка это сотни гигабайт буду там будет 9690 6 гигов правильнее всего побить следующим образом где-то 10 гигов подменил memory и оставшиеся 90 гигов подменил кэш то есть 80 гигов подменил кэш потому что основная основная нагрузка все равно пойдет на чтение выпад второй вопрос как раз прочтения вот допустим записи много они аппендицит конец в основном пенится практически никогда не удаляются вот илью солью сольются можно ли мне не беспокоиться если я читаю их только в конце у меня есть личный индекс потом темпу и у меня есть там допустим отсечка там 100 последних записей то есть я как я пойду индекс то есть я читаю только по следу смысле прохожусь чаще всего наверное можно не беспокоиться может переживать что он там пойдет до самого конца будет проживать все спасибо но раньше запрос он в любом случае будет читать изо всего на у вас просто там делаю сижку талант он за байден держу все течет до вас всё будет хорошо привет спасибо я здесь у меня наивный вопрос lsm действительно вот спрашивали уже и рок спрашивали про benchmark спросил всн реализации много есть ли какие-то понятные вам случае когда вы считаете что это лучше чем всякий rocks кассандра и сцилла у нас есть два понятных случая 1 случае the absurd и вот если можно использовать наши absurd это там нам просто конкурентов такого нет то есть там скрыт ощущение не возникает и мы за счет этого с оси цены было сравнению со стелы стороне ней не было значит и понимаю куда клонишь то есть возьми если те нужный лаз м возьми сциллы потому что это правильно кассандра ну типа того но я этого не говорю и не подразумеваю не подразумевал я просто хотел узнать все равно смотри сравнение не было сравнения будут мы пока на наших сценариях мы видим удовлетворительную производительность говорящую нас это десятки тысяч рпс значит как как это все понимаешь что это стратегический вопрос вот для нас это была комплиментарно и решение к номера технология то есть мы нас нет задача вынести mongo db если манга тебе завтра на 7 тебе уже сегодня за адаптив wild tiger как мне написали в комментариях ребята из game кстати мне написали в комментариях на хабре сказать что смотри могут бесов док силвари tiger ii уже vr тагир переключил режим бы дерево потому что они не осилили доведения до конца то есть вот вот все недостатки которых я говорил предостаточно кропотливой работы на самом деле устраняется скрываются от пользователя автотюнинга значит фичами определенными la sima да они скрываются то есть в будущем из этой штуки можно сделать и приготовить убийцу бы деревьев условно но сейчас каждому надо готовить но сейчас дойду до магаза работает это это немного работы это и это в первую очередь понимание структуры данных и ну какие то в дальнейшем это понимание структур данных на всех этапах немного работам подкрутить не нужно несколько ручек но если она как бы не зайдет вообще-то и пробовать не стоит то есть возвращаясь к сравнению со стелы и кассандры я думаю что они в плане доступности этой структуры наверное где-то впереди нас то есть два не а наличие интернетов которые позволяют это но потом если честно приходили вот люди которые используют кассандру говорят вот у нас вот такие вот скачки лейкен севка sun java нет игры выяснилось выяснилось опять же что дело было не в джаве что скачки light in se заключается в том причиной скачков латексе при использовании кассандры заключается не в том что они в одну и ту же базы данных простите меня фигачат из одной трубы по 100 килобайт of записи а с другой трубы посту байтов и у них периодически так накладывается что 100 килобайт ный поток у него происходит скачок и он душит 100 байт ный поток это вообще на любой базе данных как бы понимаете на иной мере вы этого просто не видите потому что номере быстрый вот она диски это уже все становится как бы вуду практиками которые собственно консультанты на этом хорошо зарабатывают у нас закончилась времени предлагаю про винил продолжить чуть позже а сейчас сейчас не расходитесь и вот единственное в каком залито все происходит по программе следующем зале у нас будет серия вопросов и ответов произвольных про в первую очередь о чем я хотел бы пообщаться почему вот мы решили сделать такую штуку это пообщаться про будущее то есть вот вы сюда пришли его на нас посмотрели скажите нам что самое главное вы хотели бы видеть нашем продукте вот всем кому это интересно прошу проследовать в зал и там будет круглый стол с программным комитетом"
}