{
  "video_id": "SjS2sLhZAOA",
  "channel": "HighLoadChannel",
  "title": "DBA-бот Joe / Анатолий Станслер (Postgres.ai)",
  "views": 631,
  "duration": 2643,
  "published": "2020-04-14T11:19:34-07:00",
  "text": "всем привет меня зовут анатолий станций я работаю в компании по сгрыз и ой мы занимаемся тем что ускоряем процесс разработки убирают задержки связанные с работой sports у разработчиков тебе и клей у нас классные клиенты и сегодня часть доклада будет посвящено кейсом которые мы встречали в работе с ними и о том как мы помогли им решить достаточно серьезные проблемы когда мы ведем разработку мы делаем какие-то сложные нагруженные миграции мы задаем себя вопросы взлетит ли эта миграция вообще и зачастую мы прибегаем к тому что ну мы пользуемся review мы пользуемся каким-то знаниями более опытных коллег и тебе экспертов и они могут нам сказать полетит она или не полетит но возможно было бы лучше если бы мы могли сами протестировать это на полноразмерных копиях и сегодня мы как раз поговорим про то как такой как сейчас какие есть подходы к тестированию и как это можно было бы лучше делать с помощью каких инструментов и какие плюсы и минусы если таких подходах и что мы можем здесь исправить поднимите руку кто когда-нибудь прям на проводе делал индексы или какие-то изменения вносил окей на довольно много а у кого это приводило к тому что данные терялись или простой были ну да в общем он знакомая это вольт начал слава богу бы капризен ну то есть вот первый подход он про то что ok давайте пойдем впрочем потестим а или разработчик просто сидит с локальной машины у него тестовые данные какая-то ограниченная выборка и мы катим на прот и получаем такую ситуацию это больно это дорого наверное так лучше не делать а как можно сделать давайте возьмем стейджинг и возьмем туда от центрируем какую-то часть prada или в лучшем случае возьмем прям настоящий провод все данные и будем дополнительно проверять после того как локально разработки дополнительно проверять еще и настей тенге окей это нам позволит какую-то часть ошибок убрать не допустить на провод но какие есть проблемы проблема в том что этот стейджинг мы делим с коллегами и очень часто так бывает что ты делаешь какое-то изменение бам все никаких данных нету работа насмарку стейджинг много терабайтный был ну в общем долго ждать пока он снова поднимется наверное я доработаю ты завтра все у нас разработка встала ну и конечно у нас работает много там коллег много команд мы все делим и нужно согласовывать как то вручную опять-таки не удобно здесь стоит еще раз сказать что у нас есть только один одна попытка только один выстрел если мы хотим какие-то изменения внести в базу данных потрогать потрогать данные поменять структуру навесе какой-то индекс если что-то пошло не так и слив миграция была ошибка мы быстро уже не откатимся это лучше чем предыдущий подход но все равно у нас есть большая вероятность того что какая-то ошибка уйдет на про дальше так что она мешает взять и дать каждому разработчику вот держи тестовый стенд полноразмерная копия я думаю понятно что у кого база данных больше чем терабайт больше чем у половины за и понятно что держать машины для каждого разработчика когда такой большой продакшна это очень дорого и к тому же еще и долго представьте у нас есть клиенты которые поняли что очень важно все изменения тестировать на полноразмерных копиях но у них база меньше тра байта но ресурсов чтобы для каждого держатель стенд нет поэтому им приходится скачивать дам по себе локально на машину и тестировать таким образом это занимает кучу времени представьте даже если вы делаете внутри инфраструктуры скачать 1 терабайт данных в час это уже очень хорошо но они используют логические дамб и они скачивают локально с клауда для них скорость порядка двухсот гигабайт в час то есть и еще нужно время чтобы из логического дампы развернуться накатить индексы и так далее но они этот подход используют потому что это позволяет им держать под надежным то есть что мы здесь можем сделать ok давайте просто сделаем так чтобы тестовые стенды были дешевые и будем использовать будем каждому разработчику выдавать свой собственный тестовый стенд и и такое возможно и на самом деле в этом подходе когда мы делаем center лежнин когда она мы можем делать тонкие клоны для каждого разработчика мы можем пошире титана одной машине например если у вас есть 4 терабайта я база вы хотите дать ее 10 разработчикам вам не нужно иметь 10 x 4 терабайт на базовом достаточно одной машины и вы можете делать тонкие копии из-за изолированы для каждого разработчика использую одну машину как это работает чуть позже расскажу вот реальный пример то что база четыре с половиной терабайта мы можем получать независимой копии за 30 секунд то есть представьте вам не нужно ждать тестовый стенд вне зависимости от того какого он размера вы можете получить его за секунды это будет полностью изолированные среду на которые делят данные между собой круто то есть здесь мы говорим про какую-то такую магию и про параллельной вселенной это работает с помощью ну в нашем случае с помощью системы о пинцетов с это копия играет файловая система которая сама из коробки поддерживая snapshot и и клоуны она надежно масштабируемый и очень просто управляет там буквально в 2 команды можно ее развернуть есть другие варианты lbm и схд да и т.п. исла про который я рассказываю он модульный можно реализовать будет использование таких вариантов но пока мы сосредоточились на указав с потому что конкретно smm были проблемы как это работает вместо того чтобы при изменении данных нам приходилось мисс того что переписывать данные каждый раз когда мы их меняем мы их сохраняем просто помечают что вот эти новые данные относятся к тому моменту времени к ному snapshot у и в дальнейшем когда мы хотим откатиться или мы хотим сделать новый клон с какой-то более старой версии мы просто говорим о кей дайте нам вот эти блоки данных которые так ты помечены и вот этот пользователь будет работать таким набором данных он их будет постепенно изменять делать свои снапшоты и получается что у нас будет ветвление у каждого разработчика в нашем случае будет возможность иметь свой собственный клан который он редактирует а те данные которые общее они будут шириться между всеми чтобы развернуть у себя такую систему нужно решить две проблемы одно это источник данных от куда вы будете их брать можно настроить непосредственно репликацию с продакшна можно использовать уже бэкапы которой у вас настроены я надеюсь валы в лодже или бармен и также если вы используете какой-то клауд решение rds или или клауд с кем-то вы можете использовать логические дампы но мы все-таки вам советуем использовать bkb потому что при таком подходе у вас сохранится еще и физическая структура файлов что хорошо что позволит еще более точно быть еще более ближе быть к тем метрикам который бы вы увидели на продакшен и и отлавливать там те проблемы которые есть и также нужно понять где конкретно вы хотите по хостить дтп из лап это может быть также клауд это может быть он примет и здесь возок важно сказать что ctfs поддерживает сжатие данных и достаточно хорошо это делает поэтому ну представим что у каждого у каждого такого клона в зависимости от тех операций которые мы с базы делаем у него будет нарастать какой-то div вот и для этого дефо тоже нужно будет место да но за счет того что мы взяли четыре с половиной литра байта базу ctfs ее сожмёт до трех с половиной тра байт и например в зависимости от настроек это можно варьировать и у нас еще для дефов останется места такую систему можно использовать для разных кейсов например это разработчик и гибель для проверки запросов для оптимизации это можно использовать в тестировании для проверки конкретно миграции перед тем как мы будем выкатывать этот род но и также мы можем поднимать специальные специальные январем это для peavey с реальными данными где они могут по тестировать новый функционал опять-таки это будет занимать секунды а вместо того чтобы им приходилось ждать часа часы и может быть даже сутки в каких-то других случаях где у нас центробежные не используются ну и отдельный такой кейс если еще в компании не настроена специальная система для аналитики мы можем выделить тонкий клон продуктовой базы и отдать ее вот под какие-то другие запросы или под специальные индексы которые аналитики могут использовать итак с таким подходом у нас реально есть низкая вероятность ошибок напротив потому что мы все изменения уже протестировали на полноразмерных данных у нас появляется культура тестирования поскольку теперь не нужно часами ждать свой собственный стенд и реально нету вот этой преграды и нет вот этого ожидания между тестирование это реально можешь пойти проверить где так будет лучше поскольку мы ускорим разработку будет меньше рефакторинга у нас меньше багов попадет в пруд мы меньше ехать и фактором потом и получается уникальная возможность то что мы можем обращать необратимые изменения и то чего вообще раскис и стандартных подходов нет это выгодно потому что мы делим ресурсы и тестовых стендов но уже хорошо как что еще можно было бы ускорить благодаря такой системе мы можем сильно снизить порог вхождения в такое тестирование сейчас есть замкнутый круг когда разработчик чтобы получить доступ к реальным полноразмерным данным он должен уже стать экспертом его должны как-то принятие да и доверить ему такой доступ ну а как расти если его нет что если тебе доступны только какой-то очень маленький набор тестовых данных тогда получить реальный опыт не получится как выйти из этого круга в качестве первого интерфейса такого удобного для разработчиков любого уровня мы выиграли свобод но на самом деле это может быть любой другой интерфейс что он позволяет делать можно взять запрос какой-то конкретный на следующих слайдах будет получше видно можно взять запрос и отправить его специальный канал для базы данных мы автоматически за секунды развернем тонкий клон прогоним этот запрос соберем метрики рекомендации покажем визуализацию и дальше этот клон останется для того чтобы этот запрос можно было как тасс оптимизировать добавить индексы ну и так далее и так же слаг и нам дает возможность коллаборации из коробки поскольку это просто канал можно прямо там же в трети для такого запроса начать этот запрос обсуждать пинговать каких-то своих коллег и бей которые есть внутри компании но есть конечно же проблемы поскольку это все-таки реальный мир и мы используем сервер на котором хотим сразу много клонов нам приходится сжимать количество памяти и количество но процессами мощности которые клоном доступны но чтобы эти тесты были правдоподобными нужно нужно как-то это решить проблему понятно что важным является одинаковой данные но это у нас уже есть и нам хочется добиться одинаковой конфигурации и мы можем такую одинаковую конфигурацию дать но практически круто было бы иметь прям такое же железы на как на продакшене но она на самом деле может отличаться давайте вспомним как работает как после сработает с памятью у нас есть два кэша один от файловой системы и один собственной по сгрыз и шельби фыркаешь важно отметить то что шайба фыркаешь он лоцируется при старте по сбросу в зависимости от того какой параметр ну какого размера вы зададите в конфигурации 2 cache он использует все доступное пространство и когда мы делаем несколько клонов на одной машине получается что мы постепенно память заполнена и по хорошему 6 баффер кэш обычно это 25 процентов от всего объема памяти которые на машине доступен и получается что если мы не будем этот параметр менять то мы сможем на одной машине запускать всего 4 инстанса всего таких тонких клона и это конечно же плохо потому что нам хочется и их имеет гораздо больше но с другой стороны казалось бы баффер кэш он используется для для выполнения запросов для для index of plant ну в общем план зависит от того какого какого размера у нас каши и если мы просто так возьмем этот параметр и уменьшим то у нас планы могут сильно поменяться например если на прозе у нас кэш большой то у нас после зовут почитать использовать яндекс а если нет то тогда будет six can и ну и какой бы был смысл если у нас эти планы не совпадали но здесь мы приходим к тому к такому решению что на самом деле планов под грехи не зависит от конкретного размера от конкретного заданного шарит баффер размеров плане он зависит от эффекте в кэш says то есть это предполагаемое предполагаемый объем кэша который нам доступен в сумме баффер кэш и и кэш файловой системы это задается конфигом и это память не а лоцируется и за счет этого параметра мы можем как бы обмануть подогрет сказать что нам на самом деле доступно много данных даже если этих данных он с нет и таким образом планы будут полностью совпадать с продакшеном но безусловно это может повлиять на тайминг и мы запросы оптимизируем конкретную по таймингу но важно что томит может зависит от многих факторов он зависит от той нагрузки которые сейчас есть на проводе он зависит от характеристик машины самой и поэтому и так и это косвенный параметр но на самом деле мы можем оптимизировать именно по количеству данных которые этот запрос прочитать чтобы получить результат и если хочется чтобы тайминг был приближен к потому что мы увидим в прозе то нам нужно взять максимально похожие железа и возможно даже больше чтобы все кланы поместились но это компромисс то есть вы можете вы получите такие же планы вы увидите сколько данных прочитает конкретный запрос и и сможете сделать вывод этот запрос с хорошей или миграция или плохое его нужно еще оптимизировать давайте разберем как конкретно джон проходит оптимизация как возьмем такой запрос с реальной системы в данном случае базы данных это один терабайт мы хотим выбрать все посчитать количество постов свежих у которых было больше 10 лайков если мы просто прогоним этот запрос то есть мы пишем сообщение в канал развернулась развернулся для нас для нас клон мы увидим то что такое запросу нас отработает за две с половиной минуты и это первое что мы заметим и второе джо покажет автоматически и рекомендации основаны на плане и метриках мы увидим что запрос обрабатывать слишком много данных что получить относительно небольшое количество строк и нужен какой-то специализированный индекс поскольку мы заметили что запросе слишком много отфильтрованных строк ну давайте посмотрим подробнее что произошло да действительно мы видим что мы прочитали почти по полтора гигабайта данных с файлового каша или даже с диска и это нехорошо поскольку мы достали всего 142 строки и казалось бы у нас здесь вообще индекс can и должно было быстро отработать но поскольку мы отфильтровали слишком много строк нам пришлось их сочетать то запрос медленно от работа и это произошло как мы тоже можем увидеть в плане из-за того что индекс построен из-за того что частично не совпадают условия в запросе и условия в яндексе ну так давайте попробуем сделать яндекс по точнее и посмотрим как изменится запрос волнений запроса после этого создание индекса за него достаточно много времени но теперь мы проверяем запрос и мы видим что время вместо двух с половиной минут стало всего сто пятьдесят шесть миллисекунд что достаточно хорошо и мы читаем всего 6 мегабайт данных и теперь у нас используется индекс английском другое другое важное другой важной история в том что нам хочется план представить каким-то более понятным способом мы у себя внедрили визуализацию с помощью flame граф это другой запрос более насыщенный и flyme граф мы строим по двум параметрам это количество данных которые конкретная но до в плане считала и тайминг который занял на на выполнение но время которое прошло на выполнение этой ноты конкретно здесь мы можем сравнивать конкретно ноды между собой и будет понятно какая из них больше меньше занимает что обычно бывает сложно делать в других способов элизы визуализации ну конечно же все знают спмд пешком здесь хорошим хороший свечой это визуализация является то что мы сохраняем текстовый план и также выносим какие-то основные параметры ну в таблицу для того чтобы можно было тоже как-то по сортировать и в целом когда разработчики которые еще не углубляюсь эту тему они это же пользу эспланаде пешком потому что как раз им проще разобраться в какие метрики важны а какие нет есть новый подход к визуализации to explain дали бокам они делают делать такое древовидная древовидную визуализацию но здесь очень тяжело сравнить нам надо между собой хорошо понять структуру правда если большой запрос будет нужно будет скролить туда-сюда но тоже вариант ну и как я уже сказал в слайк нам дает возможность коллаборации например если мы встретили какой это очень сложный запрос который непонятно как оптимизировать мы можем в тренде с лаки это этот вопрос уточнить со своими коллегами в общем нам кажется что важно тестировать на полноразмерных данных для этого мы сделали инструмент от этого и слеп который доступен в open source и вы можете и в том числе и budget тоже вы можете брать его прямо сейчас и внедрять у себя все все гады там доступны важно также отметить то что само по себе решение не является каким то революционным потому что например есть 2 fix но это проприетарное это enterprise решение она полностью закрыта стоит очень дорого мы именно специализируемся на подгрести это все продукты open source ные можно присоединяйтесь к нам дальше будет д м а конкретно можно будет посмотреть наш бот и дебилов в действие и обсудить какие-то моменты вот ну на этом я заканчиваю спасибо zdravstvuite спасибо за доклад очень интересная особенно мне потому что я такую же задачу примерно решал некое время назад и поэтому мне целый ряд вопросов надеюсь я хотя бы часть задам смотрите интересно как вы рассчитываете место под эту тестовую среду потому что технология подразумевает что при определенных обстоятельствах ваши и клоны могут вырасти до максимального размера эту игру gres вас там 10 терабайтный база и 10 клонов то при определенных писать мы легко смоделировать такую ситуацию когда в каждый клон будет весь по 10р уникальных данных как вы рассчитываете вот это место good туда или то которой мы говорили в которой будут жить вот эти вот вы его клоны да хорошо опрос на самом деле здесь важно следить за конкретными клонами и если они начинают превышать если какое-то слишком большое изменение у клона он начинает расти то мы можем сначала вы дать предупреждение пользователю про это либо сразу этот клон остановить чтобы у нас не произошла к это феллер ситуацию вложенный вопрос собственно как вы обеспечиваете жизненный цикл этих модов потому что у нас это прям проблемы и скажем так ну целая история отдельной как это вообще происходит но есть какой-то те тел у каждого клона который зависит от ну то есть в принципе у нас фиксирован эти тел но если этот клон используется та же один час это еду то есть и дал один час если он не используется моего грохот но здесь никакого удивления нет поскольку мы можем клон поднимать за секунды и если он опять понадобится пожалуйста можно еще по поводу выбора технологии тоже интересно потому что вот мы например параллельно используем несколько способов ну там по тем или иным причинам интересно почему допустим это именно за tfs почему не использовали в ambit рфс вы упомянули что вы были проблем интересно каких стать потом уже там но на мой взгляд уже и вот но на мой взгляд например наиболее оптимальным является вариант схд потому что с точки зрения производительности и главные проблемы даже в чем что ты должен все запускать на одну кастету все инстанции бутса жить на одной вернул в рамках одной операционки а случается с ходы ты можешь подключать плату там разного оборудования и у тебя узким местом является только грубо греки блоки которые на исходы он сам а вот этот вопрос интересен выбрать налогов чем не умеем btrfs ну тогда конкретно проявляем сможем обсудить на митапе более подробно кейс происходи скажу что но эта процедура то есть вот эту систему zts мы можем внедрить где угодно вы можете ее у себя на машине развернуть можете просто скачать репозитории и развернуть ее ctfs станут изотов и остается практически везде но это если мы про linux говорить вот то есть мы получаем очень гибкое решение и сам z fs сам по себе он из коробки очень много дает то есть можно загружать туда сколько угодно данных подключать большое количество дисков есть ну шо ты как я уже говорил его просто администрировать то есть он кажется очень приятна в общении он проверен ему много лет его делали в сани сначала но потом он пришел ворокова сейчас поддерживается этим там очень большое комьюнити она растет то есть ситов с очень надежное решение правильное еще прокомментировал имя николай золото вместе полем ну я согласен что схд классно и у некоторых end of у нас есть там плюс дороже так далее анатолий правильно отметил что мы нацелены на модульность и в будущем можно будет реализовать достать и на сделали snapshot сделай клон уничтожу все легко вот и сходи это классно если он есть весь исходя из будем мы используем исходы супер более того там можно там детали можно обсудить можно он несколько машин но зато фаза доступно всем и наша задача сделать вот эту технологию уже хватит там dfx у них 300 клиентов из них творчество 50 клиентов да то есть они нацелены там наса и так далее по роду стрий получить эту технологию вообще всем и поэтому осокин сорска у нас да там есть часть интерфейс на которой они опыта существа это платформа мы там сейчас покажем но мы хотим чтобы это было доступно каждому мы хотим сделать революцию чтобы все разработки разработчики тестировщики перестали гадать на ноутбуках да и при сделали просто на больших данных пусть они там но это уже детали там измененные данные или прям реальные данные если есть возможность не париться про приватные данные да если не может не появиться классно паримся значит паримся в этом случае мы должны вписать select и сразу видит что он медленный хватит уже там ждать когда тебе об этом расскажет вот это главная цель я думаю что мы к этому придем все и вот эта штука мы ее делаем чтобы она как раз была у всех вот поэтому z fs вот ответ на вопрос потому что он будет доступен вообще везде спасибо там комьюнити решению этих проблем это что там upon собственный source лицензии и так далее вот приветствую спасибо за доклад максим зовут но решили такие же проблемы вот то есть порешали мне интересно такого вопроса как вы разделяете ресурсы между такими клонами ведь каждый клон может в каждый момент времени заниматься своим 1 1 тестирует другое другое у кого-то индекс троицы кто-то джабба работает тяжелое по ее нагрузку но если по оси пью по памяти вы как-то еще разделить по и вот вопрос как вы делите тарас вот а второй вопрос про не похоже стендов вот у меня предположим здесь за tfs я все классно работу с ней а у клиента на про дениза tfs а x4 как скажи где будет что делать там сейчас это ещё дамы это мы тоже покажем вопросы на самом деле очень хорошие я немного упомянул эту проблему с тем что мы делим ресурсы и решение здесь она заключается в том что ну представьте вы нас таджики тестируйте да вас же тоже может быть одновременно такая ситуация что кто-то нагрузку одну дает другую и в итоге вы вы видите какие-то метрики ну не непонятные даже такая же проблема может быть с продам когда вы хотите проверить какой то запрос вы видите что с ним какая-то проблема он медленно отрабатывает а на самом деле проблема то не в запросе была в том что нагрузка есть какая-то параллельно и поэтому здесь важно сосредоточиться на том какое у нас будет план по каким шагом мы в плане пойдем и сколько данных мы для этого поднимем то что допустим у нас диски будут нагружена чем-то она повлияет конкретно на тайминг и но мы можем по количеству данных оценить насколько этот запрос нагруженный то есть это на самом деле не так важно то что одновременно с ним еще будет какое-то выполнение если потом они стали сдавать вот ну да ты смотришь смотришь на данные вот у меня два вопроса очень крутая штука были ли кейсы когда данные на продакшене критически кент номера кредитных карт что такое и вот ну их обфусцированный то есть если кто то уже готова для этого или это просто отдельная задача и второй вопрос если что-то такое для mais quel и таки по поводу данных есть да мы будем делать of us и рование пока мы не делаем но если вы разворачивается именно джо если вы не даете доступ разработчикам то они доступа к данным нет почему потому что джон не показывать данные он показывает только метрики планы и все это спину специально было так сделано поскольку одно из требований нашего клиента они хотели иметь возможность оптимизировать но при этом не давать всем подряд доступ второй вопрос а майский до в общем эту систему можно использовать для чего угодно на самом деле что хранит стоит на диске и поскольку мы занимаемся под пирсом мы сейчас в первую очередь делаем полностью всю автоматизацию для подвеса мы хотим автоматизировать получение данных из бекапа мы в правильно конфигурируем по сгрыз знаем как сделать так чтобы планы совпадали и так далее но на самом деле поскольку система она расширяемая ее можно будет быть также использовать и для майский например и такие примеры кстати есть похожая штука есть у яндекса но они йони но не публикуют не где они используют внутри в яндекс метрике и там как раз право майские истории но как бы технологии те же самые z fs спасибо за доклад меня тоже пару вопросов первые вы упомянули что клонирование можно использовать для аналитики строить там какие то дополнительные индексы можете немножко подробнее осветить как это работает мой вопрос давайте нам сразу тоже за там насчет одинаковости стендов одинаковости планов план зависит том числе от статистики собранный позже сам как в эту проблему решаете какие по аналитике конкретных кейсов нет то что мы так еще не использовали но такая возможность есть и если мы говорим про индексы но представьте что гоняется запрос по таблице с сотни миллионов записей и по колонке которые там обычно в прозе не проиндексированы мы какие-то там хотим посчитать данные если этот запрос прогнать на вроде есть возможность того что на проводе будет простой потому что запрос там будет минут отрабатывать но ok давайте сделаем тонкий клон который не страшно на несколько минут ну остановить скажем так и для того что было комфортнее считать аналитику добавим индексы по на те колонки в которых в которых нас данным интересует а какие плане можно да можно сделать так что мы данные потрогаем как-то изменением сделаем снапшоты потом с этого snapshot а будем восстанавливаться и и но уже гонять новый запрос кит то есть еда и можно сделать можно сделать так чтобы у нас получится поднимать новые клоны с уже проставленными индексами спасибо за доклад спал а еще еще был вопрос видно а что конкретно но так вот если мы делаем если мы становимся из бекапа если мы делаем репликацию тона статистика будет точно такая же потому что у нас полностью вся физическая структура данных прям как а как данные есть со всеми метриками статистиками мы их привезем тоже тут другая проблема что если у вас клауд решение используется то там только логические дампы доступны потому что но google и amazon не дают просто взять физическую копию там такая проблема будет не получится часть да спасибо за доклад здесь прозвучало два хороших вопроса про майской и про sharing ресурсов но по сути получается что вода сказали что оракул тоже использует все сводится к тому что эта тема не конкретный баз данных до субд с кожа в целом файловой системы и соответственно вопросы вести по шарику ресурсов тоже должны решаться оттуда до той с ней в конце там что это по сброса в принципе файловой системе ну серию в сервере в целом да например вы знаете мой вопрос чуть о другом более приближенному к как раз вот этой многослойно базе данных там несколько слоев вопрос от мы например настроили обновление вот этого 10 трой обаятельного образа скажем у нас привлекаться идет да вот мы конкретно используем это решение для баз данных идет репликация происходит обновление данных тут параллельно работает 100 сотрудников которые запускают постоянно эти разные снимки что же делать как сделать так чтобы не было конфликта что они запустили одно а потом файла с тем поменять подменила и эти снимки все поехали они поедут они вы не поедут потому что так за зад офис работает мы можем удержать отдельно в одной в одном потоке изменения файловой системы которая благодаря репликации приходят и на старых версиях данных держать клоны которые разработчики используют и это у нас уже как бы работает например то есть получится что обновление будет происходить как дополнительный слой все новые снимки будут идти уже исходя из этого слоя но из предыдущих до слоев которые были но с предыдущих аппликации на предыдущий ему эти слои они отвалятся получается когда но они будут ссылаться на старый слой новые машины и новые образы они будут снова последним слой который был полученного дженни тогда получается как следствие у нас будет слоев и потом на будь со временем их даже мэрами все правильно ну есть какое-то окно да мы хотим сказать что там мы сохраняем там недельные снапшоты ну это просто зависит от того какой у вас есть ресурс если у вас есть возможность хранить много данных можно за долгое время хранить снапшоты они сами не удаляться то есть никакого там да это кара пшена ничего такого не будет если снапшоты устарели как нам кажется да это зависит от политики в компании мы можем просто их ударить место освободится здравствуйте и спасибо за доклад по поводу джо и вы сказали что заказчик не хотел доступ давать всем подряд к данным но строго говоря если у человека есть результат explain унылой зато он может в принципе данные подсматривать хотел дополнить не знаю все так безусловно есть да например мы можем написать select from в email равно тому тогда и увидим в роста что один да то есть мы не увидим сами данные но какие-то косвенные признаки да мы можем посмотреть это нужно понимать с другой стороны у нас есть это все видно у нас есть аудит логе у нас есть контроль других коллег которые тоже видят чем занимаются разработчики и если кто-то попробует так сделать но к ним службы безопасности придет и поработает над этим вопрос да и вы же доверяйте как бы сотрудникам своей компании добрый день спасибо за доклад такой короткий вопрос не очень понял что если вот в компании slug не используется как какая-то к нему привязка сейчас есть или можно допустим для разрабов развернуть инстанции чтобы подключить приложение по средству базу непосредственно приложения теста вы сейчас смотрите сейчас есть привязка к сне куда то есть нету никакого другого мастера да но очень хочется сделать поддержку других мастеров тоже но вы можете что сделать вы можете развернуть и себя просто дебила без джо например ходить с помощью rest api или с помощью нашей платформы создавать клоны и подключаться уже просто песка или например туда но это опять таки если вы уже готовы дать доступ своим разработчикам к данным потому что тогда вы тут уже никакой никакого экрана не будет ну вот этому вопросу меня про прослойка этот принцип не нужно нужно только вот вас на такое можно сделать среду спасибо все я так понимаю вопросы закончились вы выбрали лучший вопрос было довольно много был один из тех вопросов где ширинка а я вот по моему от этого участника мы вручаем его приз за самый лучший вопрос можно поаплодировать также мы приносим свою благодарность за ваши труды и в кот басик меньше"
}