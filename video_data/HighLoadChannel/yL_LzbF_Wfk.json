{
  "video_id": "yL_LzbF_Wfk",
  "channel": "HighLoadChannel",
  "title": "Переосмысление рекомендаций в Дзене и внедрение item-to-item-схемы / Дмитрий Шишов (Дзен, VK)",
  "views": 574,
  "duration": 2461,
  "published": "2024-04-17T01:10:29-07:00",
  "text": "мир платформ это технологический бренд национальной системы платежных карт нспк мир платформ создает и развивает платежные сервисы которыми пользуются по всей России а сейчас доклад переосмысление рекомендаций в дзене и внедрения item to item схемы расскажет нам Дмитрий Шишов из дзена поприветствуем товарищи Всем привет мой доклад посвящен тому как мы в зоне упростили наши рекомендатор а именно про внедрение айтом тайм-схемы поехали Меня зовут Дима кликер не работает я пытаюсь его починить О все включить нужно было да артза не отвечаю за качество рекомендации задач им рекомендациями занимаюсь несколько лет до этого работал в поиске по видео Яндекса дел там процент Дзен это контентная платформа soffleur не работает но я буду поворачиваться Видимо это контентная платформа в которой авторы приходят выкладывают длинные видео короткие вертикальные посты пишут статьи или делятся мыслями фотографиями в коротких постах Наша задача состоит в том чтобы для 30 миллионов ежедневной аудитории сформировать ленту таким образом чтобы пользователи нашли интересные публика ции авторы достучались до своей аудитории и Давайте посмотрим на цены изнутри Вот спасибо месячная аудитория составляет 70 миллионов человек у нас среднем пользователи проводят 35 минут в день для того чтобы делать качественный сервис для такого объема пользователей мы должны быть хайлоут сервисом держать хорошую нагрузку мы держим 10 тысяч rps на рекомендор и отвечает должны за пол секунды пользователи за сутки генерируют порядка 10 миллиардов событий в день все эти события мы должны быстро уметь переваривать чтобы делать наши рекомендации еще лучше о чем мы сегодня с вами поговорим я расскажу про метрики которые есть в зоне про найденные проблемы мотивирует переход на айт им схему рекомендации покажу немного Как выглядит рекомендор и расскажу про внедрение рекомендации и про результаты про метрики в дзене три верхнеуровневые ключевые метрики это да ежедневная аудитория timespad количество времени сколько пользователей проводят зени и nps нет по Motors удовлетворенность пользователя о платформе конечно же все эти три метрики Мы хотим растить дал мы растим с помощью маркетинговых компаний запускаем рекламу поднимаем узнаваемость узнаваемость бренда записываем эксклюзивный контент с блогерами и Прокачиваем SEO для того чтобы помочь пользователям найти интересный им контент у нас на платформе для роста таймспента мы увеличиваем контентную базу рекомендации повышаем качество предсказания наших моделей для этого лучше интерпретируем сигнал пробуем различные новые сложные модели отличие nps от предыдущих двух метрик в том что прошлые две можно посчитать пологом несложным скриптом понять сколько у нас времени сколько у нас аудитории соответственно это не так Для этого нужно залезть голову пользователю чтобы его оценить Мы конечно запустили опросы интересуемся У пользователя сколько насколько насколько у нас оценивает вид ли он какие-то проблемы если отвечает негативно то мы даем ему возможность дать развернутый ответ спрашиваем Что именно не так с вашей лентой за мной не видно но там форма обратной связи а мы провели такое исследование и касательно рекомендации обнаружили две точки роста пользователи были недовольны частью ленты говорят иногда им что-то показывается не похоже на то что они смотрят в дзене вообще не понимают Почему а также сообщают о том что не все интересы пользователя представлены в Ленте если не будет слышно Вы как-то скажите потому что я же себя не слышу пользователи говорят что не все их интересы представлены они иногда с чем-то может прореагировать А рекомендор по тем или иным причинам не подсовывает это в рекомендации и nps конечно зависит не только от рекомендаций зависит от большого числа факторов как внутренних так и внешних и для того чтобы выделить рекомендационную составляющую мы запустили опросы это опросы Боже шторм какой-то Это вопрос насколько недовольны своим публикациями и для того чтобы подрастить НПС Мы решили это делать через сайт подрастить положительные ответы на такие вопросы Однако не только пользователи нам жалуются о некачественных рекомендациях иногда мы видим это сами иногда коллеги приносят и первое что приходит в голову в случае негативной рекомендации Да пойти вообще попробовать по дебажи Давайте поймем как это можно сделать Сначала посмотрим на схему устройства рекомендации которая была в зоне такая схема была ну она интересно по крайней мере такая схема используется не только где можно встретить о чем она есть какой-то контур сбора и хранения пользовательской истории эту историю мы собираем и отправляем в процессинг модели их обрабатывают генерируют представление пользователя в вектором пространстве которое мы называем имбидинг этими бедингами мы идем в Canon Index Canon индексе мы находим близкие по мнению модели публикации пользователю отправляем это на этап скоринга после этого на этап пост процессинга Где работает всякие механики про разнообразие бизнес логики и фильтры из этого уже формируется Лента и вот в Ленте мы увидели то что не хотели бы там видеть Давайте попытаемся как мы будем понимать что произошло пойдём назад идем на это блендинга он достаточно простой его можно там не знаю пройти с дебаггером понять легально или нелегальный документ прошел наши правила Окей это не сложно идем на скоринг здесь мы используем КАД буст Это довольно сложная для интерпретации модель сложно Конечно есть какие-то методы для того чтобы понять почему один Документ получил спор больше чем другие Но они такие они не очень уверены не очень экшена был не всегда нужно понять что именно нужно сделать модели чтобы на такое не рекомендовала В общем объяснимость но Давайте вообще посмотрим А почему мы Этот документ эту публикацию приняли к рассмотрению посмотрим Из какого источника кандидатов она пришла это не сложно для этого достаточно залогировать воронку рекомендации понять Из какого селектора мы ее достали вот а так как селектор у нас кнн связан однозначно с моделью мы можем выйти и на модель которая эту публикацию поставила близко к пользователю Но на самом деле мы хотим понять какие взаимодействия в истории пользователя повлияли на то что модель эту публикацию подвинула близко пользователю смотрим какие у нас модели здесь используются А на этом этапе уже достаточно сложных интерпретаций модели это могут быть матричные факторизации тяжелые рекомендационные модели и на самом деле есть тоже для части из них способы про интерпретировать их понять что там произошло на во-первых для каждой модели Этот способ нужно делать разный во-вторых с интерпретацией там проблемы еще больше чем boostone поэтому мы для себя поставили цель сделать наш рекомендор простым и понятным Ну а сейчас мы поговорили о каком-то частном случае конкретном кейсе дебага Давайте попытаемся понять Как можно вовсе Взглянуть на ситуацию вот у нас есть пользователь есть история для него Мы все храним знаем какие-то публикации он быстро скипнул не посмотрел с какими-то позитивно про взаимодействовал я буду это называть позитивами это могут быть лайки длинные просмотры до читки В общем какой-то глубокое взаимодействие выразил интерес есть у нас история возьмем позитив и посмотрим на то что мы сейчас показываем пользователю Давайте сравним то что мы показываем с его историей а именно посмотрим на похожесть каждому его позитиву из истории если они не похожи поставим не на один Позитив это публикации не похоже его истории поставим нолик если похож хотя бы на один то поставим единичку остается вопрос А что такое похоже в данном случае Ну первое что приходит в голову это посмотреть глазами сравнить А вообще про одно и то же или нет но так как для пользователей много сэмплы нужны большие и парк таких может быть много то от них глаз не хватит но можно воспользоваться глазами крауда сделать инструкцию мы это делаем Яндекс сталке для оценки похожести двух публи каций говорим что они похожи если там идет речь про одно и то же событие про один и тот же объект Либо они в одной тематике или в жанре и не похоже Если между ними нет совсем ничего общего а таким образом можно оценить всю релевантность ленты пользователя посмотреть на долю релевантных пары и это назвать метрикой релевантности ленты то есть похожая стена историю пользователя мы провели такое исследование в дзене и обнаружили что для достаточно горячих пользователей у нас была низкая похожесть приблизительно 50 процентов ленты была так или иначе связана с его историей поэтому мы поставили для себя цели вырастить похожесть ленты на историю его взаимодействий И третье проблема про который говорили пользователи не все интересы представлены в Ленте Давайте поймем Почему так Может происходить а именно посмотрим на одну из наших веток когда-то генерации вот у нас есть пользователи есть модель которая процессит его историю им бетин генерирует для него этими беттингом мы идем в индекс достаем кандидаты и вот и случилось какое-то новое взаимодействие мы заново модели обработаем историю сгенерируем какой-то новый имбидинг и в целом ожидаем что на этапе кандидата генерации после неё вернее Будут еще и публикации Похоже на это новое взаимодействие Но на самом деле ни одна модель это явным образом не гарантирует наверное в среднем это так и происходит но мы захотели сделать наши комменты таким чтобы мы каждому интересу пользователя гарантирован находили документы а потом вскорели вот такие требования и мы поняли что нам подходит схема рекомендаций Давайте на нее посмотрим как она выглядит мы каждая публикации можем построить список похожих ключом будет какая-то публикация я буду называть Якорь похоже публикации справа буду называть документами можно построить такие списки похожести и когда приходит пользователь на платформу мы смотрим на историю его позитивные взаимодействий каждому из них находим список похожих публикаций объявляем их кандидатами идем на этап скоринга вскоре мете документы применяем разнообразие формируем ленту в итоге наш рекомендор превращается в то что представлено схеме Давайте поймем почему она нам подходит первое сделать этап кандидата генерации простым и понятным действительно видно что не сложно если какой-то документ встретился в Ленте пользователя не сложно найти то взаимодействие с которого мы его ему порекомендовали и в случае если с рекомендацией проблемы можем посмотреть на позитив в истории пользователя на рекомендации понять какой дополнительный сигнал нам нужно дать модели что и рассказать про Вселенную для того чтобы она узнала что это не нужно рекомендовать к этому позитиву второе это схема позволяет обеспечить похожесть ленты на историю пользователя действительно если мы сделаем так что это мы справа в 90 процентов случаев будут похожи на этом и слева то и вся Лента будет похожа на историю позитивов то есть на истории пользователя и третье мы можем себе гарантировать на этапе кандидата генерации то что если пользователи случится какое-то новое взаимодействие мы для него так же как и для остальных пойдем в список похожих отправим это на скоринг Да после скоринга конечно же не факт что документ получит высокий predition и пройдёт в Ленту но у нас ещё есть этап постпроцессинка где применяются логики разнообразия они уже работают с документами с какими-то с корами и сильно больше шансов показать пользователю в Ленте все его интересы осталось понять как построить такие списки которые на 90 процентов похожи на публикации слева то есть на якоре если они должны быть похожи давайте что попробуем сделать классификатор релевантности то есть похожести двух айтомов на что его учить Но на самом деле ответ уже есть мы делали такую разметку для того чтобы построить метрику сделали процесс который собирает такие данные можно взять их и обучить классификатор на разметку краудом в качестве фичей взять как раз всю эту информацию о похожести двух публикаций которые у нас уже есть в рекомендоре и при построении списка для коньков это конкретного якоря взять всю контентную нашу базу и поспорить ее к нему Окей мы построили списки Но на самом деле этого недостаточно потому что списки могут получиться достаточно большими а нам нужно у ться в пол секунды и все мы поспорить точно не сможем Поэтому нужно выбрать самое лучшее для того чтобы выбрать самое лучшее эти списки нужно как-то отранжировать а давайте поймем как это сделать наш первый подход был следующим мы транжировали их по условному стеару что это такое вот у нас есть какой-то Якорь А мы хотим понять вот две публикации B и C Какая для них лучше Давайте возьмем аудиторию ту которая с якорем а позитивно про взаимодействовала и посчитаем ctr элементов BC не на всем здание А конкретно на аудитории этого якоря и сравним и впервые Мы выкатили в Production это именно в таком виде и это даже работает Однако такого подхода есть ряд минусов Таких данных достаточно мало они разреженные не всегда мы условностиры знаем достаточно точно и этот подход плохо работает на непрогретый хайтамов поэтому Нам нужен был другой Надеюсь схему слева будет видно потому что рассказывать я буду её Давайте сюда отойду мы на самом деле знаем Из какого позитива пользователя мы сделали рекомендации Давайте эту информацию залогируем и все показы из позитива сравним между собой и на основании этого сравнения сделаем прервайс дата сет в котором победителем будет тот Items которым пользователь лучше взаимодействовал в качестве веса возьмем разницу во времени обучим на таком Data setty Cat Boost и опять же в качестве фичей будем использовать всю ту информацию из моделей которая у нас уже есть в рекомендационной системе В итоге у нас получилось такая схема построения списков Мы берем Все айтем считаем айтем айтем признаки схема конкретного списка даже не всех мы считаем к каждому якорю со всей базой этой признаки пропускаем через фильтр релевантности которые гарантирует нам похожесть публикации справа на этот Якорь и ранжируем их формулы интерактивности мы называем получаем финальный список конечно же вскоре все публикации достаточно трудозатратно много процессорного времени на это нужно убить поэтому можно добавить этап кандидата генерации При построении списка и набирать там документы которые хотя бы как-то похожи на этот Якорь из-за этого мы проиграем в полноте Но может не всем видно но в общем мы потратили всего лишь 20 процентов публикаций мы таким образом потеряли то есть полнота у нас 80 процентов В эти списках что на самом деле достаточно неплохо и финальные списки получились такими мы строим для 40 миллионов потенциальных позитивов в истории пользователя строим над базой с 5 миллионов документов на этот процесс занимает порядка двух часов и финальные списки получается размером 200 Гб осталось понять Как это внедрить в Дзен опять немного в сторону отойду рекомендуем рекомендации зрения выглядит приблизительно следующим образом у нас есть не Real Time контур обработки пользовательских логов здесь мы процессим историю пользователей формируемых профили они попадают в userstorage когда пользователь приходит мы идем в Stories за его профилем отправляем на четыре наших рекомендара каждый под свой формат он генерирует уже рекомендации для своего формата и в блендере Мы это замешиваем в Единый Фит пользователю что А про рекомендор у нас он был достаточно простым это одна шардовый при этом максимальная память там составляет 40 гигабайт ограничения облаков которым мы живем и первое что приходит в голову Когда нужно сделать доставить фронтально эти списки давайте сделаем Перед каждым рекомендателем kevely storage в котором мы эти списки будем хранить похожие публикации на истории позитивов доставать отправлять на рекомендор вскоре и так далее при этом сервис должен достаточно быстро отвечать 20 миллисекунд поэтому списки мы держим в памяти Конечно Нам нужно чуть больше шардов чем один все на одну машинку не влезет и значит списке нам нужно шортировать когда мы имеем дело скивали сторожем самый очевидный способ сортировать это по ключу будет ну сделать так что каждый шарт отвечает за свой диапазон ключей и возвращает это сервис Однако в этом случае мы получим сервис который достаточно загружен по памяти и процессор которого простаивает потому что все что он делает он берет списки и отправляет их и достает из памяти отправляет их дальше по сети и возникнуло желание загрузить этот сервис работой Давайте поймём как это можно сделать на самом деле можно шортировать по значению потому что значение У нас их не одно Их много и сделать так что каждый шарт у нас будет отвечать за свой диапазон публикаций в этом случае еще и на каждый в этом случае можно шортировать и все те данные которые у нас есть для того чтобы поспорить публикации и нашей превратить в шортированный рекомендор который будет отвечать уже на нем будет работать Cat Boost он будет отвечать поскоренными айтами старые рекомендор превратится метрикаметр который это все агрегирует и делает там сложные тоже вычислительно сложные механики разнообразия теперь про результаты мы так опять не туда Простите Мы за счет похожести списков сделали ленту похожую на историю пользователей вырастили из 50 до 90 процентов при этом несмотря на такие как бы ограничения в то того чего мы можем рекомендовать на достаточно коротком горизонте мы смогли вырастить и Темп на 10 процентов но все это мы затевали для того чтобы пользователи чаще нам отвечали все свои вопросы Что им понравились рекомендации и мы увидели здесь положительную динамику пользователи когда видели похоже контент на историк взаимодействий стали чаще нам отвечать Что Да им это нравится помимо этого есть ещё ряд выводов э которые мы для себя сделали первое мы сделали рекомендор проще понятней нам стало приятнее с ним работать Мы научились его дебажить сделали больше телеметрии так как мы стали больше понимать что там внутри происходит Мы например смогли сделать метрику реактивности а именно понимать как свежее позитивное взаимодействие пользователя Как быстро Мы из него что-то порекомендовали да то есть не осталось оно у нас там лежать и через 3 дня моего вспомнили А ты протестовал и сразу тебе что-то классное подсунули на эту тему Мы научились легко не только себе но и пользователям объяснять рекомендации там этим схема это достаточно удобно позволяет мы делаем подпись такой для пользователей в котором говорим на основе какого его взаимодействия Мы решили порекомендовать эту публикацию мы для себя закрыли вопрос о недоиспользовании интересов пользователя на этапе кандидата генерации мы каждого ему интересу гарантированно достаём публикации скорим их больше про это не думаем и схема на самом деле легко масштабируется Мы это шортировали сейчас увеличиваем контентную базу и это достаточно не сложно получается на этом все спасибо за доклад переходите по qr-коду А у меня уже сегодня была такая ошибка Да ну хорошо В общем Спасибо за внимание заговорился поаплодирую у меня тут qr-клада 2 но наверное голосуем за спикера обязательно это важно во-вторых Вот есть чатик можно там вопрос задавать не только из зала Я на правах ведущего первый вопрос задам каково это выступать когда гневаются небеса Но это интересно на самом деле Да приходится изобретать Да это в интернете Спасибо за классный доклад У меня вопрос смотри помнишь ту схему рекомендации которая самом начале показывал где мы брали брали вот мы все эти беленькие на самом деле в том числе для фичей для того чтобы достать кандидатов чтобы не спорить всю базу эффективнее это сделать так так раз дальше Еще Еще наверное еще так это моя там здесь начался до этого ты имеешь ввиду сама моделька которая по которой вы похожесть вычисляете первоначальным которого кандидатов для вот этого списка отбираете а смотри я понял давай ты говоришь вот у нас тут сейчас будет финальная схема ранжирования Да вот это вот смотри мы тут используем все то по сути все те КНР которые использовали в обычной схеме рекомендации Мы в основном используем СВД матричные факторизации еще делаем матричные факторизации есть контентный нерести вы тоже есть да Конечно есть контент на своих логах их строим Добрый день Спасибо большое за доклад Меня зовут Роман вопрос у меня следующий вот как часто обновляется модель рекомендаций и учитывает ли она обратную связь от пользователя то есть допустим вот пользователю в Ленте появился какой-то материал пользователь не захотел допустим его смотреть там через день через два я часто замечал По своему опыту что мне снова этот материал попадается я не хочу его смотреть вот учитывается ли как-то такая обратная связь от пользователей такой вопрос Ну смотри вот мы Конечно я только что отвечал на вопрос говорил что мы используем матричные факторизации конечно же отсутствие взаимодействия в них это как правило нолик положительно здесь единичка и мы эту информацию учитываем через TM бединги которые генерируются матричными факторизациями у нас для этого да Мы конечно же учитываем Давайте дальше туда девушка Спасибо большое за доклад А вы просто такое что насчет exporation Неужели людям нравится читать все то что это хороший вопрос конечно же задача рекомендации сильно шире на самом деле в рекомендациях есть две большие задачи Первое Это explatation рекомендации на основе уже известных системе интересов пользователей я рассказывал конечно же про неё есть еще вторая важная часть системы Это exploration когда мы прощупываем историю пользователя прощупываем его интересы подкидываем разные контент Смотрим как на него реагируют О классно про взаимодействовал Значит будем такое дальше рекомендовать весь айтом айтом он основан на то что мы рекомендуем к уже известным интересам поэтому это про эту часть exploration притом на самом деле алгоритм exploration выглядит совершенно по-другому супер другая механика мы должны как-то неизвестно при этом Это должно поспорить и а это моя там нам еще позволил точно понять какая часть нашей ленты сформирована точно на основе интересах пользователя и мы когда знаем долю такой ленты мы можем как-то балансировать между эксплором эксплойтом конечно да это item этом другой задачи решает но спасибо Вопрос хороший exploration Это важно Давайте с этой стороны кто-нибудь вот молодой человек Давай я оглядывайтесь Здравствуйте спасибо за доклад Вопрос такой насколько точный получается разметка на которой обучается вот модель подходит достаточно ли уровень согласованности у модерации для того чтобы обучить такую сложную модель первый комментарий на самом деле согласованность можно победить объемом разметки и мы это делали мы собрали достаточно много а второе мы как бы учитываем это согласованность нашей модели соответственно как бы там где более уверенные наши предсказания более уверены где согласованность пониже мы как бы ну веса при обучении меньше добавляем но Вопрос хороший да конечно за разметкой важно следить если сделать разметку плохой то ничего не получится здесь спасибо спасибо Еще вопросы еще кто-нибудь хорошо Тогда у меня есть вопрос который мне в личку прислали это даже не столько вопросов такое Крик души это пользователь пишет ваш рекомендуется все время одно и то же по ключевым из моих запросов по ключевым со страниц где была подписчикам на кого я подписана плюс мусор и стопа и рекламы Ничего необычного но все время одно и то же очень больно что-нибудь сделайте с этим но реклама мы не рекомендуем нет другие товарищи рекомендуют Но на самом деле тут ответ такой что рекомендации никогда не бывают хорошими они всегда как бы плохие они бывают только лучше или хуже рекомендации Здравствуйте меня зовут Сергей вопрос Следующий А можно ли предотвратить формирование информационного пузыря когда мне рекомендуют то что мне как бы понравилось а я начинаю читать то что мне рекомендуют и я никогда не выхожу за пределы этого Круга и Остаюсь в рамках какого-то набора рекомендаций Каким образом он может случайно расширить я могу не сейчас не знать о том что мне очень может быть даже понравится или нравится Как разорвать порочный Круг рекомендации да да Ну вот я на самом деле частично уже ответил на этот вопрос для того чтобы выйти из пузыря есть механики exploration в рекомендательных системах когда мы реально показываем то что не похоже на твою историю при этом хотим чтобы все равно как бы не совсем как бы антиисторию твою Да но что-то ортогональное что будет ты с этим всё-таки при взаимодействовал прощупал много интересы конечно это очень важная часть рекомендационной системы Да нужно прощу пывать иначе Лента станет скучно Ну что давай А ещё вопрос Давайте Время ещё есть Алексей по поводу последнего вопроса А как вы замешиваете вот какой процент контента пользуюсь исследуйте что вы рекомендуете айтом туайтом то есть какие примерно порядки ага но смотри там конечно же сильно зависит от прогретости пользователя от объема истории про которые мы о нем знаем это как-то варьируется от того что варьируется да да от того насколько богатые его история Конечно если пользователь приходит Новый у него Ну никакого айтом в принципе не может быть если мы знаем там несколько его тем несколько взаимодействий то тоже как бы вселенту из этого строит наверное не прикольно да и это варьируется Но если говорить про какой-то процент то для горящих пользователей на это порядка десяти и там как-то в зависимости от какую школу прогретости используешь эту это доля она меняется порядка десяти процентов на эксплуара вот тут ещё Сразу две руки было вот да вот прям передайте Здравствуйте спасибо большое за доклад и я хотел отреагировать вот на ваши такие искренние слова что рекомендации никогда не бывает хорошие они могут быть только лучше или хуже и это вызвало во мне некоторое противоречие Потому что много моих там Друзей знакомых в какой-то момент стали очень страшно Кайфовать от Spotify именно от рекомендации что ты включил песню и потом вот только то что надо идет и даже этого не знала и всё ништяк И вот именно самоценность этих рекомендаций она людей Вот вовлекала и заставляла ещё Навязывать мне например этот Spotify типа Да нет ты вот попробуй будет классно Вот и тут вот вы говорите ну такую вот оценку да я хотел чтобы немножко эту тему раскрыли Если можно да Ну конечно же сейчас я думаю просто как лучше ответь конечно же как бы не все так однозначно да как бы на любой платформе хорош или плохой нет людей вернее есть люди которые очень довольны рекомендациями есть люди которые очень недовольны вопрос как бы в этом соотношении кому-то платформа нравится и она хорошо работает с рекомендациями конкретно там на одни темы там вот Spotify может быть сроком Яндекс.Музыка с попсой там на что угодно как бы вопрос как бы в доле довольно конечно же хорошая рекомендации это важно просто идеальными они не бывают возможно надо было сказать идеальными они всегда Как бы где-то хуже где-то лучше но нужно всё равно их растить повышать качество Спасибо Евгений россинскому Он тянет руку на самом деле хочу сказать спасибо за доклад и ответить на предыдущий вопрос который который отвечает на этот вопрос такой Баттл затевается уже на самом деле в рекомендациях основная проблема это как раз маркетинговое воздействие вот отвечу почему Spotify хорошая рекомендации они вот просто ребята сумели продать что это классный продукт и вот если ребята из Дена запихнут они запихивают свой продукт объяснение того что их рекомендации классные большой процент пользователей сайта мы вот на качественных исследованиях будет говорить что они классные если Рекламу по телеку пустят будет ещё бомба хотя бы все считаете что телек никто не смотрит развесит билборды короче вот восприятие рекомендации - это настолько субъективная штука Дмитрий попытался рассказать про какие-то Человека понятные метрики они про ощущения ощущения это маркетинг был чит и вот маркетинг был чит это маркетинговые инструменты А так доклад шикарный Спасибо Спасибо да на самом деле Вы тоже хотите ответить на предыдущие Большое спасибо очень насущно интересная тема и вот мне как раз стало интересно Как оценивается похожесть истории тому чтобы указать в Ленту Дело в том что человек может рассматривать несколько тематик разнообразных вот оценивается она в совокупности Эта история или по именно тематикам если эти тематики учитываются отдельно то э в каком объёме их выдавать какую-то больше какую-то меньше То есть если в разных годах интересуется Может быть какая-то у них там тема которую много читает и иногда интересуется ещё чем-то то есть это вместе оценивается или или вот Ага как бы то метрику которым мы растили которые в целом про как бы качество ленты говорит она а про то чтобы оценить это вместе разбивка уже нужна скорее когда мы хотим понять какую-то конкретную аналитику например насколько мы Хороши ли слабы в той или иной теме это уже скорее про точки роста Но вообще Лента оценивается вместе обеспечивает как бы разнообразие в самой ленте те механики которые у нас есть на этапе постпроцессинка Когда мы уже с коры формулы там берем смотрим на них смотрим на то насколько это мы который мы формируем ленту похожи и как-то пытаемся разнообразно сделать То есть финальный ответ такой смотрим мы я говорил про метрику в совокупности разнообразие обеспечивается механиками в рекомендоре а для как бы оценки качества в тех или иных темах Это скорее инструмент для аналитики Спасибо Дима отличное выступления надо выбрать Два лучших вопроса и кому мы что подарим был хороший вопрос про exploration потому что это важная часть рекомендаций один подарок точно уезжает туда кто у нас это просто девушки Какой подарок ваш или я предлагаю выбрать есть подарок а второй а второй на самом деле тоже хороший подарок я уверен ребята классный хорошо делают хайлаут разметка про согласованность это действительно важно да это как бы это молодой человек книжка замечательная Спасибо тебе А тебе тоже подарки да Спасибо"
}