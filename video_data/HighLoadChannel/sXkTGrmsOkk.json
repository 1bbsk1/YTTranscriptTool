{
  "video_id": "sXkTGrmsOkk",
  "channel": "HighLoadChannel",
  "title": "Как строить Low Latency-рекомендательный трансформер на миллион RPS / Всеволод Светлов (Яндекс)",
  "views": 701,
  "duration": 2268,
  "published": "2023-01-19T06:59:52-08:00",
  "text": "меня зовут все влад сегодня вам расскажу про то как мы строили рекомендательные трансформеры с какими проблемами столкнулись по дороге и как мы все таки в конце концов сумели внедрить эту модель значит начнем с постановки формальный задач рекомендательных моделей у нас есть некоторое множество пользователей который приходит нам на сервис и у нас есть некоторые множество объектов которые мы можем этим пользователям предложить и собственно задачей рекомендательной моделей это выбрать из всего множества наших объектов какой то небольшое количество которые были бы для конкретного пользователя наиболее интересными мы в яндексе достаточно давно занимаемся персонализации рекомендации наши самые большие сервисы это поиска реклама они внутри имеют достаточно сложную многоуровневую рекомендательную систему кроме того у нас есть какие-то другие сервисы поменьше типа музыки маркета или кино поиска которые также основаны на рекомендательных репер sneezy ровных моделях но в тот момент когда мы начинали этот проект два года назад в нашим рекомендациям стойки почти что во всех частях индекса мы использовали в основном либо относительно легкие либо относительно простые модели которые в основном были заточены на решение проблем в конкретных сервисов мы захотели сделать следующее поколение рекомендательных моделей которые бы были возможно обобщены на все сервисы внутри яндекса не обладали бы некоторыми следующими свойствами первых мы хотели конечно же получить какую-то сильную выразительную модель эта модель по нашей задумке должна была бы быть основано на анализе сырой истории взаимодействия пользователей с нашими сервисами и основывалась бы на моделях глубокого обучения и обучалась в intent глядя на успехи в области анализа естественно языка в то времени в то время мы поняли что возможно мы сможем обобщить подходы к анализу текстовых последовательностей на анализ последовательностей пользовательских действий ну и собственно таким образом у нас родился проект по построению рекомендательного трансформера давайте я напомню что такое трансформер все-таки highload наверное это нефть до конца prime иль поэтому здесь люди могут быть которые не сталкивались с этими моделями трансформер появился уже наверное лет 5 назад и достаточно быстро он стал основной моделью для анализа текстовых последовательностей в силу ряда своих плюсов он выбивал стоит у фарт и выбивает стриту part результаты почти что на всех науки задачах и надпись специфичных задачах как мы подаем внутреннего текст мы разбиваем наш текст на какое-то количество частей каждый такую часть мы будем дальше называть токи нам каждый такой частью мы в соответствии с некоторым на период заданным словарем сопоставим некоторые имбилдинг которые мы в дальнейшем будем обучать вместе с нашей глубокой моделью ну и собственно говоря из таких им биллингов мы формируем последовательность которую мы и подаём в наш трансформер основной фишкой трансформер является так называемый механизм внимание механизм внимания позволяет токи нам в разных частях последовательности более хорошо смотреть более хорошо понимать общей зависимости путем того то что они смотрят на все остальные токины в последовательности и таким образом имеют больше контекста и больше понимания того какие зависимости мы можем в этой последовательности извлечь другой отличительной особенностью transform является параллельная обработка токенов в отличие от предыдущих поколений в отличие от рекуррентных моделей в отличие от модели основанных на свертках мы можем параллельно обрабатывать все токены в нашей последовательности что обычно ведет к хорошему обучению более стабильному обучению и к более быстрому inference am ну соответственно мы решили эту модель обобщить на анализ пользовались последовательностей это выглядит достаточно просто вместо последовательности им дизенгоф слов мы будем подавать в нашу модель имбирь инки наших событий каждый из которых каким-то образом мы получили из каких-то других энкодеров у них я расскажу чуть позже используя такую модель мы достаточно быстро сумели побить прошлые bass line и и неплохо улучшить качество рекомендации в наших сервисах мы верим то что в основном это произошло из-за некоторых особенностей которые есть во первых это из за того что мы начали совместно анализировать различные типы событий чего до этого мы не делали и таким образом модели появилось больше контекста больше знаний о каких-то типовых поведения пользователя больше возможностей извлечь из этого какую-то полезную информацию во вторых мы начали учитывать контент события каждое событие взаимодействия представляла собой некоторый набор атрибутов например это могут быть некоторые тексты например это могут быть некоторые категориальной фичи поверх этого мы придумали некоторые энкодеры которые мы могли обучать совместно с нашим большим рекомендательным трансформером и такое совместное обучение она опять таки вело к тому что мы увеличивали качество нашим моделям ну и учет временных зависимостей всего того то что как я сказал трансформеры имеют механизм с of attention мы более точно смогли анализировать зависимости в нашей последовательности причем не только краткосрочные как мы это делали в случае сверток и в случае рекуррентных сетей но также и глобальные интересы пользователя мы смогли учесть в такой модели но к сожалению ничего не бывает бесплатно модели очень тяжелое интерес ли таких моделей нужно делать тот же пункт и собственно весь свой остальное доклад я расскажу про то с какими сложностями мы сталкивались при внедрении этой модели давайте поговорим начали про скорость значит полгода назад мы решили закатывать нашу модель в рекламную сеть яндекса рекламная сеть яндекса это один из самых высоконагруженных сервисов внутри яндекса среднем нагрузка это сотни тысяч рпс у нас было достаточно сильное ограничение с точки зрения в этом си которые мы могли потратить на один запрос это было порядка 30 миллисекунд если мы за эти лимит вываливаем ся то соответственно пользователь перестает быстро видеть рекламу реклама nike недовольны пользователь не довольно поэтому этот лимит достаточно жесткий на один запрос по счастью нам нужно было просчитывать достаточно небольшое количество документов это связанно с тем то что рекламной сети яндекса это уже достаточно сложившейся сервис он имеет многоуровневую систему ранжирования и мы можем как тяжелая модель можем работать на достаточно высоких уровнях ранжирования в тот момент когда у нас уже не так много кандидатов которые мы бы хотели порекомендовать пользователю под модели у нас были worker s80 цеху ядрами и 8-ью видеокартами nvidia бостон ну и тут немаловажный момент то что пользовательские данные они были не в каком-то предпочитал видео то есть мы прямо на наши маркеры тащили тяжелую историю пользователя прямо на месте и каким-то образом при процессе ли на циpкa и только после этого мы уже отправляли ее на расчет модель давайте немножко поговорим про ту архитектуру которую я описал начали и почему может быть плохо хотеть закатывать такую архитектуру в продакшн для этого давайте я напомню что мы подаем на вход этой модели мы подаем некоторую историю пользователя который пришел к нам за про и мы подаем некоторые целевой ой там как для которого собственно говоря мы хотим получить оценку интересности в контексте данного пользователя модели очень простая модель очень похожа на ванильный трансформер и поэтому ее достаточно просто обучать ну и помимо этого оно обладает таким хорошим свойством как раннее связывание раннее связывание означает то что вы вашу целевой ой там и историю связываете самом начале вашей нейронной сети и используйте всю емкость ваши нейронной сети для того чтобы превратить какой-то совместный анализ обычно это ведет к улучшению качества хорошие свойства но к сожалению есть очень очень очень большой минус к сожалению как я сказал у нас сотни запросов сотни документов которые мы должны почитать на один запрос и всю вот эту схему весит тяжелый трансформер даже несмотря на то что у него практически одна и та же исторически история у пользователя в этой точке мы вынуждены просчитывать и и сил все это всю эту сотню раз на это нужно какое-то гигантское количество живут сбу потому что если вы почитаете то вы получите то что вас сервис с нагрузкой в сотни тысяч рпс еще сотни документов на каждый запрос в результате вы приходите к цифрам десятки миллионов просчета трансформеров в секунду что какое-то гигантское количество видеокарт требует мы пошли дальше придумали архитектуры под названием live ужин трансформер мы воспользовались тем простым фактом то что история в рамках одного запроса она действительно постоянно и мы можем посчитать ее ровно один раз и дальше передать некоторые митинги за исторического transformer pad transformer 2 уровня который уже будет совместно анализировать некоторые выход из исторической части и наш целевой ой там таким образом мы получаем некоторую оптимизацию наших вычислений потому что теперь тяжелую историческую часть в которой обычно длинной истории порядка сотен мы можем просчитывать только один раз и получаем некоторые 2 трансформер в котором уже длинной истории меньше десяти мы можем его достать чтобы быстро гонять и при этом у нас сохраняется некоторые связывание пускай и не в самом начале нашей сети а где-то ближе к конечным стаям но тем не менее мы все равно анализируем историю и наш целевой этом совместном к сожалению такая схема она достаточно неплохо усложняет нам обучение но с этим мы справились но у нас все еще остается 2 трансформер который к сожалению мы также вынуждены гонять на жопу это тоже также достаточно большая и тяжелая штука и для этого нужно нужно большое количество видеокарт в сервисах поменьше типа поиска мы сумели внедрить такую модель но в рекламной сети яндекса нагрузки оказались слишком высоки и нам пришлось пойти дальше и и тег модели без связывания соответственно здесь очень простая идея если нам не нравится верхней transform если мы хотим тратить на него джипу не хотим дать мне лучше подавать мы попробуем от него отказаться такая схема с точки зрения архитектуры с точки зрения внедрения обладает очень большим количеством свойств мы получаем явный дик uplink между пользователем и нашим целевым артемом и соответственно мы можем все просчитать отдельности то есть мы можем отдельно на запрос просчитать историческую часть мы можем просчитать все наши целевые а этом и сложить их куда-то в базу и потом когда пользователь приходит запросам не пересчитывать их на месте а поднять их из базы и единстве что нам останется сделать это просто посчитать какой-то очень очень легкий dot продукт который можно делать даже на циpкa и который фактически бесплатен с точки зрения наших ресурсов таким образом мы во-первых упрощаем себе модель потому что у нас появляется явный дик uplink на историческую часть и и атомную часть и при этом мы упрощаем себе внедрение потому что там теперь не нужно думать на тему того а где нам хостить 2 трансформер должно ли быть это отдельный сервис должен ли быть он совместно с первым трансформером как туда балансировать нагрузку и так далее но у этого подхода есть огромный минус он заключается в том то что если мы такую модель и обучаемость коробки то она теряет примерно половину качества от своего life фьюжен аналога половина качество никому не нравится поэтому нам пришлось придумывать очень большое количество трюков для того чтобы завести эту модель чтобы она теряла как можно меньше качества по сравнению со своими фьюжен аналогами ну и в итоге у нас удалось очень сильно снизить просадку сильно усложнил себе обучение но тем не менее мы остановились на этом варианте теперь давайте поговорим про результаты ну про early фьюжен трансформер наверное говорить не очень интересно потому что как вы видите судя по 1 трением временам на потраченным на один запрос мы улетаем куда-то в космос и никакая никакой нормальный сервис нас с такими таймингами себе не примет в live фьюжен модели все становится чуть чуть получше не чуть чуть получше в реальности что полтора порядка но тем не менее остается проблема с тем то что у нас есть 2 трансформера то что мы должны его достаточно сильно оптимизировать и все равно он потребует каких-то джипу ресурсов для от своего расчета ну и но фьюжен модель на которые мы остановились работает еще на полтора порядка быстрее чем на пол порядка быстрее чем life ужин модель немножко просаживает качество но сильно-сильно все упрощает и для рекламной сети яндекса мы решили остановиться собственно говоря именно на этом варианте мы выкатили наш нужен модель на наши тестовые стенды и увидели то что у нас сильно сильно не до загруженный джипу обычно когда у вас сильно не до загружены джипу вы можете утяжелять ваше вычисления двумя способами во первых вы можете увеличивать размер модели потому что ну как бы одна из причин не до утилизации вашей джипу это то что вы в нее schedule и тени достаточное количество вычислений это может быть как раз таки напрямую связано с размером той модели которую вы хотите внедрить и таким образом если вы увеличите размер модели вы нарастите качество но качественно 100 тот момент устраивала мы хотели пойти по другому пути увеличивается число запросов которая карта может одновременно обрабатывать и таким образом вырастить пропускную способность и тратить на наш наше внедрение чуть меньше дорогих видео как вырастить пропускную способность можно также двумя способами в реальности первый способ это параллельные запросы карте когда вы не дожидаетесь того что у вас выполнился тот вопрос который мы задали раньше и в этот же момент начинаете накидывать в карту все новые и новые запросы карта умеет с таким справляться но к сожалению здесь появляется какое-то большое количество недостатков во-первых мы начинаем терять время на запуск cuda-ядер потому что в драйвер прилетает все больше и больше просит запусти куда и дроу драйвер в этот момент к сожалению начинает подтапливать и заканчивая тем то что весь про лизу в этом случае он остается на стороне драйвера пользователей никак не может контролировать то какие операции будут выполнить выполняться параллельно драйвер выбирает выбирает запускать или ему два куда ядра параллельно или нет зависимости от размера этих cuda-ядер и в зависимости от размера входных данных сожалению когда вы работаете с достаточно сложными тяжелыми моделями такие как трансформер в которых очень много разнообразных операций достаточно сложно научить драйвер нормально балансировать эту нагрузку и делать так чтобы он действительно плотно утилизирован карту есть на данный момент некоторые расширения куды под названием куда graphite но к сожалению даже с использованием него у нас не удалось добиться какого-то значимого результата в этой точке поэтому мы пошли по другому пути который выглядит и звучит намного более просто это так называемое бы чего не когда вы группируйте некоторое количество пользователей которые приходят вам на сервис и просите у модели вместо того чтобы прочитать каждого пользователей по отдельности вы просите просчитать их сразу какое-то количество таким образом мы собственно утяжеляем вычисления и более плотно утилизируем нашу карту по счастью большая часть операций в пуде она из коробки умеет работать с такой размерностью которая описывает количество примеров в бочке поэтому с точки зрения модификации модели их почти что не требуется и если даже требуется то они скорее носят некоторые косметические характера ну и в этом 100 пивом очень легко утилизировать джипу потому что вы фактически можете контролировать утилизацию просто уменьшая или увеличивая количество примеров вашим большое количество пользователей вашим бачок который переменной карты должна рассчитать но к сожалению здесь есть очевидный минус то что мы за счет такой группировки начинаем растительности и можем здесь выйти за лимиты по счастью в нашем случае мы достаточно высоко нагрузкам сервисе пользователь приходит очень часто поэтому время от 1 пользователь до последнего пользователя целом это единица миллисекунд низкий единицы миллисекунд и нас удалось достаточно неплохо написать код который делает эту группировку фактически мы не видим задержки от такой группировки на наших графиках результаты мы выкрутили это дело на стенд и увидели что вместо того что все стало хорошо все стало плохо мы начали копать пытаться понять в чем же дело посмотрели на графике циpкa и увидели то что у нас оказался загружен в полку начали думать что вообще у нас происходит кто у нас является основным потребителем циpкa вспомни то что у нас есть целый при processing который у нас очень много цифр сжирает попробовали его отключить попробовали про гнаться на синтетике и увидели то что все действительно стало хорошо то что бы чего не работает то что мы утилизируем карту мы очень сильно ускоряемся с точки зрения пропускной способности все было бы ничего но теперь у нас есть проблема что нам делать с этим чертовым циpкa сожалению дальше мы начали копать начали смотреть что мы можем с этим сделать увидели то что у нас есть на flame граф их то что у нас есть два основных потребителей во первых это 10 лизации тяжелых контейнеров которые как я то помню с тяжелый сырой истории который мы прямо в явном виде таскали на наши варки к сожалению в рамках текущей инфраструктуры мы с этим мало что могли сделать и второй момент это 2 такой жирный кусок на план-график занимала подготовка события конкретно таки низации текстов в этой точке мы потратили какое-то время из умели достаточно неплохо разогнать эту таки не за цию но в какой то момент мы поняли то что даже несмотря на то что мы эту оптимизацию проделали это какой-то тупиковый путь потому что в дальнейшем привыкать к следующей модели мы захотим увеличивать размер истории которые мы анализируем мы захотим усложнять какую то обработку событий добавлять какие-то новые события и в целом мы никак не сможем простые лица процедуру в этой точке ну и ещё один важный момент это то что в какой-то момент нам придется переезжать на следующее поколение видеокарт обычно видеокарты от поколения к поколению ускоряются где-то примерно в два раза сцепу к сожалению таких ускорений мы давно не видели поэтому проблема в этом случае будет становиться все хуже и хуже мы придумали решение что нам достаточно очевидны и опять таки то что нам нужно разделить просчет нашей модели на два сервиса на циpкa сервис который отвечаю отвечает только за при processing in a джипу сервис который отвечает уже только за просчет нашей тяжелой модели ну собственно мы так сделали увидеть то что все более-менее становится получше в этом этапе мы можем фактически просто закидывать доливать циpкa сервера для того чтобы балансировать нагрузку случай если мы захотим увеличить наши циклы участь утяжелить при processing или увеличить длину обрабатываем истории и фактически не бояться на тему того то что наш дорогой ресурсы то есть жопу будет простаивать в этом сетапе важно еще отметить то что обычно цпу сервера стоит порядка там 10 раз меньше по сравнению с пусть серверами поэтому в этом плане очень сильно нужна упираться в то то что джипу это ваш самый дорогой ресурс и вы должны делать все чтобы его утилизировать на сто процентов ну соответственно по результатам мы достаточно сильно замедлились относительно нашего байфлай на 1 сэмпла варианта это произошло опять таки как я сказал из-за нескольких причин во-первых из-за того то что мы начали терять что-то в районе быть чего не а во-вторых из-за того что мы придумали вот это размещение на циклы жопу сервис у нас привел некоторые общение по сети между двумя этими сервисами и в целом но это занимает какое-то время требует каких-то накладных расходов но тем не менее по пропускной способности мы фактически добились результатов которые уже очень близки к синтетике то есть к идеальному варианту и очень сильно начали утилизировать наши джипу в целом на этом мы решили наверно остановиться и начали выкатывать эту модель уже в эксперимент в продакшн теперь поговорим про то с какими проблемами в качестве мы столкнулись значит во первых и проблема которая связана с кем системностью данных в обучении и в применении мы использовали немного разные данные это было связано с тем то что обучались мы на исторических данных которые были собраны за очень и очень долгий период времени а в продакшене мы применялись на данных из быстрых контуров которые обладали немножко другим набором событий там были немного другие фильтрации там были немного другие тексты там были немного другие атрибуты у событий например время которое пользователь провел на сайте и в силу этого в силу и таких небольших различий наши модели начала работать не то чтобы сильно не корректно но она теряла некоторое качество после того как мы обнаружили эту проблему мы потратили достаточно большое количество времени на то чтобы свести эти источники данных единому знаменателю и у нас принципе это даже удалось но в какой то момент мы опять-таки поле то что это фактически путь в никуда потому что если в наших данных для обучения мы захотим добавить какие-то новые события если мы хотим затем добавить какие-то новые поля какие-то новые вещи то нам придется проделать всю эту процедуру введения данных заново с новыми событиями процедура достаточно неприятная довольно дорогостоящие с точки зрения ресурсов компании поэтому от нее было решено отказаться в пользу какого-то надежного решения который бы работал вне зависимости от того что мы там нового сунули в наши данные и это решение это до обучения на данных использовались до обучения на данных из продакшена соответственно мы взяли некоторый небольшой сэмпл данных из продакшна прямо перед наши выходкой буквально там обучались мы условно на данных за период год до обучались мы за на данных за период там в неделю или в несколько недель то есть это сильно меньше объема по сравнению с нашим остальным остальным обучением но тем не менее за счет такого до обучения мы сумели большую часть просто который мы потеряли отыграть обратно и наша модель подстроилась под эти новые данные которые она видит продакшне следующие проблемы с которой мы столкнулись это затухание качество мы начали после выкопки мониторить качество нашей модели и поняли то что модель начинается временем терять качество причем терять достаточно сильно за полтора месяца она потеряла больше половины своего профита мы начали пытаться разбираться в чем дело чекнули проблемы с данными основываясь на предыдущем кейси чекнули проблему с какие-то проблемы которые возможно возникли на стороне инфраструктуры посмотрели что у нас происходит надев машинках получаем ему такие же predict и как мы получаем runtime а оказалось что получаем оказалось что все работает так как оно и должно работать и в этой точке возникла гипотеза то что возможно у нас в некотором виде изменилось поведение пользователей в таком случае наша модель на вход начала бы получать какие-то другие распределения входные с точки зрения данных по сравнению с тем на чем она обучалась в тот момент когда мы учили блоге большие глубокие нейронные сетки они очень не любят когда на вход им вы подаете что то что отличается от того на чем они обучались они начинают работать некорректно они начинают терять качество в итоге вы приходите в точку где ваша модель перестает работать ну и соответственно здесь как-то не забавно мы пришли ровно к тому же решению которое у нас было в предыдущем шаге только с приставкой регулярная мы построили регулярное обучение нашей модели на новых данных ну и собственно увидели то что графики нормализовались то что действительно мы отыгрываем почти что весь тот просит который мы от этого затухания потеряли выводы они же правила которые вы можете забрать с собой с этого доклада они достаточно тривиальна и но как и любые там тривиальные очевидные вещи в погоне за качеством вашей модели и со скоростью вашей модели их достаточно легко потерять во первых оптимизируйте архитектуру ваших моделей порой вы очень легко можете отказаться от какого-то небольшого количества качество вашей модели сделав модель поменьше сделать какую-нибудь дистилляцию сделать какие-то другие оптимизации вы потеряете чуть-чуть в качестве но вы разменяете это на большое количество ресурсов которое вполне возможно позволит вам выкатить вашу модель в продакшн и во вторых почему то все нули не знаю должно было быть 12345 на лад 0 так 0 значит все очень важны профилируйте в условиях которые идентичны вашему production ну потому что если вы профилируйте ну это достаточно простой кейс если вы профилируйте на машинках которые немного отличаются с точки зрения ресурсов от того с точки зрения ресурсов с точки зрения нагрузки от того что вы имеете в продакшене вы можете начать заниматься оптимизацией ами совсем не нужных и не настоящих ботаников совсем не того чем вы будете в реальности сталкиваться в продакшене в третьих старайтесь мониторить все ресурсы которые вы используете потому что какие-то ваши априорные предположения относительно того какой ресурс может быть критичным для вашей модели для вашего сервиса он может быть абсолютно неверным вот как у нас случилось то что мы изначально предполагали что джипу это абсолютно важный ресурс и все будет же полу bound но в итоге мы в какой-то момент пришли к тому что мы оптимизируем секунд так бывает поэтому лучше вы настроите мониторинг и узнаете об этом сразу обучайтесь и при меняйтесь на одних и тех же данных и очень важный момент на моей практике очень раз было много ситуаций когда распределение данных немножко менялась в применении и от этого вашу модель можно было ну если не выбрасывать то она давала сильно сильно меньше профита по сравнению с тем что от нее ожидалось это может быть что-то очень простой например ваш инфраструктура изменила кодирование изображений которые вы подаете ваши василенко с папина джипег ваша модель обучалась только нова пик и вот вы уже находитесь в том сетапе когда ваша синенко не работает это может быть сетап как у нас старайтесь обучаться на них и тех же данных это важно ну и последнее это настройте мониторинг качества модель а это очень важная штука потому что опять таки измениться может примерно все начиная от кодека кончая каким-то положением звезд и ваши модели в этот момент начнёт работать некорректно лучше вы узнаете об этом раньше чем вам об этом расскажут вашу пользователя спасибо за внимание я надеюсь мой доклад был полезен буду рад ответить на ваши вопросы если что мой telegram если у вас будут какие-то вопросы лично я буду рад на них ответить давайте поблагодарим села да и пока вот поднимаются руки уже позже подняты руки давайте вот сюда вот микрофончик а потом вот туда чуть чуть дальше во второй ряд все вот спасибо большое за отличный доклад самом начале накладывать сказали о том что при переходе от фьюжен моделек новую жену вы сильно потеряли в качестве и сказали что применили несколько трюков для того чтобы попытаться коктейлях качество вернуть можете пара способов это тема если часто на отдельный доклад в основном это трюки которые связаны с при допущении модели с тем что мы тратим при допустим наш исторический трансформер на какой-то другой таргет по большей части то сначала когда мы начали этим заниматься это было похоже на если в курсе на москвич модал таргет из виртов но в дальнейшем от этого отказались перешли к более сложные или более простой нанкине даже не знаю как это правильно сказать с теми при допущении через так называемый индекс and lose наверное я готов ответить на этот вопрос более подробно с какими-то формулами но уже в кулуар так спасибо большое и давайте вот почему удочек спасибо спасибо большое за доклад хотелось бы задать вопрос по такой животрепещущей теме валидации регулярно еду обучения вы сказали что регулярно то обучали до обучали всю сеть либо 1 прос нарушили всю сеть либо и этого человечка просто это первый да да это очень хороший вопрос смотреть у нас модель в реальности тут легко заметить тоже состоит из двух частей и они выкатываются в разные контура которые не могут быть атомарного обновлены в одной точке мы провели некоторые исследования относительно того если мы будем до обучать модель и у нас условно говоря мы будем какое-то время использовать например ай темную часть от старой модели не до обученный насколько много мы в этой точке потеряем качеством и нам в этой точке в реальности повезло потому что оказалось то что мы теряем не очень много качества и фактически время перекатывания а это мой части после того как у нас перекатилась историческая часть она занимает некоторый шум часы мы можем себе это позволить и поэтому мы решили остановиться на этом сетапе но ваша проблема описанная проблема она конечно здесь имеет место быть и в реальности нам просто повезло то есть если бы ситуация была такая что нам нужно было бы а там арно делать обновление модели нам бы пришлось делать две вещи либо нам пришлось бы фиксировать баннерную часть атомную часть еда обучать только историческую часть потому что фактически только она содержится по информацию о меняющемся поведение пользователя но в этом случае мы это тоже проверили мы начинаем терять качество сильно больше чем от такого перри использования предыдущей модели либо нам бы здесь пришлось каким-то образом фиксировать с точки зрения модели что распределение старых выходов она не сильно уехала от распределения новых торги то есть какой то не знаю loves классно это накладывать либо нам пришлось бы решать эту проблему инфраструктурная и пытаться обновлять от омар на обе части нашей модели что наверное самый жесткий вариант нашей инфраструктуре но как-то нам повезло поэтому мы остались на самом простом варианте спасибо большое и второй вопрос в продолжение то есть вы получается да обучаете не атомарном тем не менее регулярно проверяю при этом какие-то метрики мобильными дальности мы их вот смотрите мы до обучаем обе части то есть мы условно к нам приходят там условно говоря приходит время которые мы должны переобучать нашу до обучать нашу модель мы берём данные за там последнюю неделю словно говоря берем предыдущий слепок модели и просто до обучаем его на этих же данных обе части и атомную и историческую и потом в какой-то момент мы выкладываем историческую часть в этот же момент просим наши базы пересчитать атомную часть этот пересчета пересчет он происходит с небольшой задержкой там несколько часов поэтому нас вот есть несколько часов когда наши модели немножко раз согласованы историческая часть уже новая баннерная часть еще старые но в самом как искал мы в этой точке не теряем начну качества поэтому мы могли себе позволить вот если вдруг на этом этапе у вас качество давайте последний вопрос за последний год качество потеряется да как вот вы давайте обсудим этот кулуарах спасибо большое хорошо и вот давайте здесь последние вопросик большое за доклад очень классно очень классный тайминг 32 минуты почти идеально было упоминание про то что перри обучаемся может появиться какой новый фактор до новое хочу засунуть модель если мы говорим что мы просто изменили там распределение все классно архитектура не меняется там до обучения вообще в лед а если по добавился новый фактор как мы его , смотрите это правильный вопрос мы в любом случае поправили какую-то работу по добавлению этого нового факторов быстрый контур юст и что нам бы не потребовалось делать какую-то метрику которая бы следил а затем то что наши данные в исторических и в быстрых контурах консистентной между собой то есть в целом мы наши модели допускают такое различие всё там как я сказал различных причин которые могут быть связаны там с тем чтобы быстро контурах данные не за антиспама из других вещей они могут немного отличаться от того что у нас есть исторических контурах и такая подстройка до обучения она в особенности если она регулярная она случае даже если у вас какой-то момент фактор поломался и вы начали писать в вашу модель ваши данные что-то совсем левая на вашу модель будет работать какое-то время плохо потому что вы еще не успели ее да да обучить на новых данных но потом она это подхватит и уже станет работать нормально оно будет меньше поработать полагаться на это качество возможно она потеряет немножко качество но это лучше чем если бы она работал с некорректными входными данными и потеряла бы качеству совсем но это если у нас те же самые через новое через две денги просто через подготовку ранит норовите посмотреть новую фичу мы не добавляем таким образом что как это будет все таки перикарда bridge у модель спасибо"
}