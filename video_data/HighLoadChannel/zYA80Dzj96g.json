{
  "video_id": "zYA80Dzj96g",
  "channel": "HighLoadChannel",
  "title": "Как мы попали в истории. Stories в сервисе объявлений / Александр Инякин (Юла)",
  "views": 550,
  "duration": 2306,
  "published": "2021-10-04T02:03:00-07:00",
  "text": "всем привет я александр аникин я тимлид 1 сбн команд и вы которые занимаются продуктов разработкой и сегодня я хочу вам рассказать о том как мы запускали сервис историю или о чем будет доклад по началу я расскажу о историях велел и что это такое расскажу про их особенностям дальше я верхнего уровня у пройдусь по архитектуре и инструментом который мы использовали для разработки этого сервиса затем я подробно пройдусь по теме родиться так как он является основной ключевой частью нашей системы и расскажу о проблемах с которыми мы столкнулись а как мы их решали в конце концов конечно же при делюсь результатами кому будет интересен этот доклад для всех тех кто не пользуется редисом или пользуется винтовка кэшем а также для всех тех кто может быть не планирует делать истории в своих сервисах но надеюсь что какие-то решения будут вам интересны прежде чем продолжить хочу рассказать о том что такое юла юла это классе fight the service объявлений крупнейший сервис объявлений которые позволяют продавцам и покупателям найти друг друга дело заботиться о безопасности пользователей решает проблемы с доставкой дела помогает пользователям общаться друг с другом или есть встроенные питу позвонки прямо внутри приложения и недавно него интегрировался к запустив к объявления в общем юла делает много инструментов которые позволяют пользователям покупателям продавцам как-то улучшать свой опыт и одним из таких инструментов как раз были истории в юлия скорее всего вы заметили что формат историей довольно популярен везде используются практически везде и в чем же отличие наших историй от других и для чего вообще мы сделали в первую очередь мы хотели дать инструмент продавцам профессиональным продавцам рассказать о себе на еще больше аудиторию именно поэтому мы разместили истории на самом верху главного экрана нашего приложения также мы хотели дать возможность рассказать продавцом о своих объявлениях и услугах новом формате поэтому мы добавили в нашу историю с не только фото но и видео и все это в конечном итоге должно должно помогает повышать доверие к себе и к своим объявлениям или услугам и отсюда особенности истории на ели первым делом истории создают сами пользователи то есть весь контент все истории которые мы видим или это история созданы самими пользователями как следствие это ведет к тому что этого контента очень много и это первым делом тоже влияет на качество контента соответственно второе что нам нужно для наших историй это модерация как же особенность наших историй вели является то что ленты историей которая отображается на главном экране оно персонализировано она рассчитывается для каждого пользователя персонально и зависит от таких по от гиа от подписок пользователя интересов и так же для того чтобы нам от рисовать эту ленту нам необходимо учитывать просмотры то есть все просмотры всех историй какие истории пользователь видел какие нет для того чтобы отобразить эту ленту так как это так как истории находится на главном экране требования к нашему сервису довольно высоки то есть наши три наш сервис должен быстро отвечать и быть довольно отказывай устойчиво ну и под конец так как это продукт это нужно было сделать ещё вчера немного расскажу про использую терминологию как это вообще выглядит история история это фото или видео которое пользователь загрузил в углу к истории пользователь может прикрепить ссылку либо на свой профиль либо на свое объявление группа истории группы историк сложно догадаться это несколько историй сгруппированы в одну группу для упрощения это история одного пользователя preview preview это некая обложка группы в превью по сути это кружочек в котором отображается первое не просмотр на я история в этой группе для текущего пользователя для пользователя формируется список групп для каждой из этих групп мы формируем превью и вот именно этот список preview он как раз и отображается на главном экране теперь хочу рассказать как это все работает начнем с публикации историю первым делом клиент делает запрос вопи и создает пустую историю так называемый черновик для чего нам нужен черновик дело в том что на клиенте несколько историй могут загружаться параллельно сделан для оптимизации и таким образом вторая история может загрузиться чем первая вторая история может пройти модерацию быстрее чем первое и таким образом черновики помогают нам сохранить список истории именно в том хронологическом порядке в котором пользователь их создавал после того как клиент сделал запрос на за черновиком идет загрузка фото и видео после фото и видео после загрузки клиента сохраняет уже с генерирует сгенерированную историю после этого история попадает на модерацию если необходимо идет обработка видео после этого история публикуются и это история становится доступна для всех как это выглядит под капотом приходит запрос вопия схема немного упрощена просто чтобы понять как это примерно работает после того как пришел запрос мы сохраняем данные в базу самую историю после того как история сохранена начинается процесс загрузки медиа ожидаем ответа от меди сервиса после того как ответ успешно получены мы отправляем историю на модерацию уже после того как модерация прошла история публикуется в этот момент история становится доступна для всех для всех пользователей улай так как нашей истории еще и базируется на подписках пользователя то следующим шагом мы получаем все подписки текущего пользователя и уже обновляем верно все ленты всех его подписчиков об этом я расскажу немножко позже что касаемо просмотром теперь да про просмотр на главном экране юлы мы видим некую ленту истории которая персонализировано как я уже говорил и генерируется из массы параметров это лента учитывает она отсортировано по новизне то есть более новые истории пользователь видит начали более старые в конце также учитывается просмотр то есть если ради этой истории были уже просмотрены пользователям эти истории убираются в конец списка перейдя в любую из групп в этой ленте пользователь может ли стать истории влево-вправо переходить из одной группы в другую что путь анимацию в общем этот полный аналог инстаграма по сути как это происходит на стороне бэг-энда тоже схематично для начала мы получаем список групп который мы должны отобразить пользователю то бишь ленту затем мы получаем весь контент каждой группы для того чтобы просчитать какую историю мы должны показать после этого мы получаем все просмотра текущего пользователя и после этого формируется лента и уже конечно лента уходит на клиент и так верхнего уровня мы прошлись примерно по архитектуре и хочется рассказать прежде чем искать о деталях хочет рассказать о технологии которые мы используем в или мы используем php его как основные языки программирования мон гар и дисков к тарантул в принципе стандартный набор изначально когда мы проектировали этот сервис мы планировали использовать мозгу как основную базу данных и использовать редис просто как кэш однако в процессе разработки мы пересмотрели наш подход мы оставили мангу только для как резервную базу данных и стали использовать редис как полноценную базу данных и дневник и группы ленты просмотры в общем все данные практически которые у нас есть мы храним именно в одессе кафка у нас осталось для общения между сервисами для модерации для обработки видео и тарантул мы используем для очередей так как раз по сути является центральной частью нашего сервиса я хочу рассказать подробнее о том как устроим редис у нас как мы с ним работаем и какие данные мы в нем храним исторически редис или прошел несколько стадий развития начинали естественно мы как и все с обычные символы ноды пробка кэш пишем данные получаем данные все работает все замечательно однако в какой-то момент мы задумались о масштабирования отказоустойчивости с отказоустойчивостью нам помог ради центе но тут тоже никакого рокет сайенс а все довольно легко настраивается помогает нам с этим однако в такой схеме для сортирования нам пришлось механизм ордера нам пришлось реализовывать на стороне клиента мы использовали количественных и shine ring он позволил нам избежать проблем с добавлением или наоборот удалением но тэсс кластера но остались про тем что данные мигрировать все равно приходилось руками и мы какое-то время жили с этой схемой и в какой то момент мы пришли все-таки крадись кластеру родис кластер в принципе решает все эти проблемы под капотом миграции данных между нодами отказоустойчивость шарди рования очень много кто из вас пользуется ради с кластером в продакшене учащийся я думал меньше окей значит будет интересно в или у нас много родис кластеров на самом деле и каждый кластер на используется для каких-то определенных типов данных все эти кластеры настроены под эти данные но принципиально родис кластеров или выглядит следующим образом это 3 дата центра три независимых дата-центра мастера кластера распределяются по этим дата-центром равномерно как мы видим на этой схеме и для каждого мастера в этом кластер и мы 2 2 дополнительные ноды которые лежат соседних дата-центрах такой подход нам позволяет спокойно пережить падение одного дата центра и продолжать отдавать она и жить с этим спокойно также мы не делаем большие ноды то есть все наши мастера за редким исключением обычно не превышают больше двух гигабайт это обусловлено тем что в таком случае эти ноты во-первых быстрее добраться быстрее поднимаются и требует меньше цикл чем например если бы мы использовали одну ноту но больше объема например нам 4 гигабайта так как для нас родис кластер должен отвечать быстро мы больше оптимизируем подсыпку нежели по памяти потому что память для нас дешевле в принципе примерно так выглядит кластер но есть небольшая проблема то что управлять таким кластером довольно сложно если not десятки там может быть там не знаю еще больше это несколько дата-центров это несколько физических серверов в случае падения каких-то not надо понять что за реплицировать куда перевести из какого дата-центра в общем это боль и это надо сделать на основе вывода по сути ради склей вот вообще не вариант к счастью мы сделали в юле такую штуку как ради скала старту который может использоваться для мониторинга таких проблем и для автоматического каких проблем по сути он решает следующие проблемы если мастер и реплика находится в одном дата центре следующий проблема которого может решить это несколько реплик находится в до в одном дата-центре еще одна проблема которую автоматически решает это то что у нашего мастера нет реплик либо их недостаточное количество обычному реплицирует используем по двери блики на мастер и также экспериментальным путём мы выяснили что для нас падения в кластере больше 12 мастеров приводит к тому что время восстановления такого кластер растет практически экспоненциально то есть именно больше 12 поэтому мы стараемся не делать больше 12 мастеров в рамках одного кластера на одном сервере если нам нужно больше соответственно 30 мастеров мы используем уже не 3 сервера a6 серверов которые точно также в разных dc и последняя в принципе очевидно то что вытекает из всех пунктов выше редис однопоточный поэтому мы можем разместить на физическом сервере столько нот редиса сколько я der мы имеем для нашей стандартной машины это пятьдесят шесть ядер мы вывели что мы не можем мы не размещаем больше тридцати семи мастеров почему при падении одного физического сервера все ноты которые там есть все мастера которые есть на этом сервере должны равномерно распределиться по двум другим серверам соответственно если мы используем тридцать семь мастеров то 37 пополам это примерно 19 по 19 мастеров переедут на два других серверах 56 -19 это как раз и будет та цифра в 37 таким образом мы всегда держим некий запас для того чтобы упавшие мастера чтобы им было куда переехать и так поставок мы примерно пробежались смотрели как выглядит кластер вели я хочу рассказать о том с какими проблемами мы столкнулись и собстна говоря как мы их решали первая проблема как ни странно это конечно был пользовательский контент тут на самом деле это не было проблемой у нас отлично работает модерация и ни один пользователь на самом ли морально не пострадал я серьезно то основной задачей самое сложно задачей было для нас решить то как мы будем хранить данные в одессе нам необходимо хранить персональные ленты всех пользователей уметь ею сортировать по новизне нам необходимо хранить все просмотры всех пользователей всех историй то есть довольно большой bim данных и также нам надо уметь сортировать истории в рамках одной группы чтобы сохранить и хронологический порядок как не раз уже говорилось родис это в принципе не только кэш но и целый набор встроенных типов данных которых нем есть эти типы данных помогают решать различные задачи принципе если этих типов данных не хватает даже можно использовать la можно использовать сторонние модули мы ввели в принципе активно используем практически все эти типы данных в нашем сервисе я хочу остановиться на сорта цветах и строках потому что они используются активнее больше всего как сорта ct что из себя представляет сорта цвет в одессе это некий список элементов где каждый элемент имеет еще собственный score с помощью стандартных средств редиса мы можем добавлять элементы в этот список убирать менять элементом score и одна из особенностей интересных фич этого сорта цитата что мы можем получать этот список отсортированный в том или ином направлении более того мы можем получать часть этого списка где скоро удовлетворяют каким-то нашим потребностям например там score больше там 10 или меньше 12 и так как мы используем сорта цвет сорта центах мы храним группу историей по сути как элемент мы храним идентификатор истории как скоро мы храним дату создания истории теперь при добавлении истории мы делаем зад в эту группу и соответственно конец списка попадает новый элемент с новой истории такой подход позволяет нам хранить группу историей сохранять его хронологический порядок сортировать и показывает всегда в правильном порядке вне зависимости от того как клиентах запросил также сорта цвет мы используем для персональных лент в отличие от групп мы храним в элементе уже идентификатор не самой история группы историей и также мы храним как спор не дату создания а дату обновления группы таким образом когда какая-то группа историей обновляется по сути мы делаем ту же самую операцию это за и обновляется score по факту обновляется score у того элемента который мы обновили такой подход еще позволяет нам решить еще одну проблему дело в том что когда мы делаем за от мы по факту не знаем если такой это элементов в списке или нет и сорта ces сорта сет из коробки решает эту проблему потому что он следит за уникальностью элементов с этим теперь перейдем к строкам в строках мы храним сами объекты истории объекты истории мы храним сервированном виде в виде строки почему не в кэше дело в том что в кэше несмотря на то что мы выиграем по памяти мы потеряем по сложности то есть по сути подсыпку поэтому для нас лучше сделать реализацию на клиенте и положить уже строку в редис для одессы меньше нагрузка подсыпал для того чтобы обеспечить больше рпс это важнее также в строках мы храним счетчики просмотров тут в принципе все понятно и интересно для нас стала задача как хранить все просмотры пользователей то есть нам нужно понимать какие истории он уже видел а какие нет для этого мы тоже используем стройке выглядят примерно следующим образом допустим у нас есть группы историей после того как пользователь посмотрел первую историю мы сохраняем этот индификатор в ключ изначально мы вообще планировали хранить все айдишники всех историй которые пользователь посмотрел но если прикинуть в самом плохом кейси это будет по сути перемножения всех активных историй всех активных пользователей это большой объем данных и мы решили как-то это упростить соответственно мы придумали такой механизм после того как пользователь просмотрит вторую историю мы не создаем новый ключ мы в тот же ключ записываем айдишник второй истории и так как нашей истории расположены в хронологическом порядке это нам всегда позволяет понять какая история будет следующее то есть пользователь не может посмотреть вторую историю не увидев первый из по сути мы храним некий курсор но что делать если историю на которую мы ссылаемся как просмотр пользователь удалил дело в том что мы используем бонгу в проекте и соответственно все идентификаторы которые мы используем в наших объектах это манга иди вон гайде легко переводится в time stamp и в принципе их можно сравнивать друг с другом поэтому даже если такого объекта в сети нет то мы легко можем найти следующий элемент у которого дата создания выше предыдущей но вы выше текущей решение такой задачи приводит нас к тому что для того чтобы получить рассчитать просмотре ность всей ленте на главный нам нужно сделать м запросов в редис где n это количество групп вот этих кружочков и для каждого этого кружочка нам нужно для каждой группы получить смотрел ли пользователь не смотрел где он там остановилась и так далее и в сингла но дед в принципе не проблема мы делаем ульте get мы получаем десяток ключей условно и десятых значений и дальше там с ними что-то делаем но с ради раваном кластере такой подход не работает шарнирном кластере в мульте get может отрабатывать только на одном шарди то есть мы не можем использовать этот подход но счастью в родис кластеры в одессе подумали об этом eurodisc кластере есть такая простая штука как хэштег по сути это фигурной скобки которые указывают радиусу ту часть ключа от которой будет браться хэш и соответственно высчитываться хэш слот то есть таким образом с помощью хэштегов мы можем четко понимать какие данные у нас будут храниться гарантирован на одном шарди благодаря этому мы можем сделать уже мульти get в шарди раваном кластеры и получить эти данные за один запрос с проблемой в принципе решено очень частая проблема при работе с кластером это медленные ответы радиуса при практически любой нагрузке и причем эти ответы они тем медленнее чем больше кластер проблема в принципе уже изученные решена и про нее уже много кто говорил есть прекрасный доклад от 18 года на ради sconfig где подробно рассказывается про эту проблему я прибегу лишь по верхам просто расскажу в чем проблема допустим мы видим что время ответы ради со довольно большой лезем свой лоб и получаем примерно следующую картину и видим некие кластер слов что это общее такое в том что в одессе используется механизмах слот то есть по сути сватов есть 16384 и все они равномерно размазаны по всем мастерам кластера то есть каждый мастер знает за какие слоты он отвечает соответственно перед тем как сделать запрос в редис мы получить актуальную слот мапу где мы будем знать в какой слот в какую ноту идти рассчитать из нашего ключа текущей свод и после этого сделать уже в конкретный вопрос заключён соответственно таким образом на каждый запрос в редис на каждый поход в ряде см и делаем два запроса получения slut map и и получение данных решается просто надо кэшировать свод папы на клиенте либо использовать библиотеки которые уже реализовали каширование на своей стороне после применения такого подхода обычно картина выглядит примерно следующим образом следующих проблемы с которым мы столкнулись который для нас была очень актуально это оптимизация хранения списков дело в том что наш сервис очень активно используют списке и мы заметили что потребление циpкa при использовании таких списков довольно большое но для нас было большим дело в том что в одессе списке хранятся в двух внутренних типах данных это zip лист и dictionary dict по умолчанию все speedkick отца в zip листе zip лист оптимизирован по памяти но тяжелее попрошу в то время как dictionary на бартон не оптимален папа требует больше памяти для хранения списков но сложность получения списка и из этого из словаря проще таким образом есть настройка которая позволяет указать жестко количество элементов в списке после которого он перестанет хранится в zip листе будет храниться в dictionary таким образом мы принудительно храним списке все не пустые списке в таком формате это позволило нам решить еще одну проблему дело в том что когда списке имеют размер очень близкий к тому что в настройках то очень большая вероятность того что список будет постоянно переходить из одного типа данных в другой тип данных и радиусу для того чтобы перестроить эти списки нужно постоянно постоянно перестраивать эти списки это тоже очень сильно грузит радиус по типу собственного после того как мы стали хранить списке сразу в dictionary мы получили следующую картину и теперь теперь собственно говоря у нас примерно по 4 процента эту нагрузку в среднем аноду то есть мы вы получили выигрыш порядка 15 процентов пунктов для нас это было очень критично и наверное самая интересная и самая такая не тривиальная проблема с которой мы столкнулись в итоге при разработке stories of это была проблема бибера почему именно бибера вообще бибер это тот человек с которым собственно говоря в instagram у первого случились проблемы с лайками дело в том что у всех сервисов которые так или иначе работают подписками механизмы для обработки подписок и для как-то и для работы с ними они оптимизированы и когда появляется человек у которого подписок сотни тысяч десятки миллионов там неважно зависит лишь от масштабов сервиса эти механизмы перестают работать и это заставляет больших проблем расскажу на примере как это вообще работает допустим у нас есть пользователь у него есть несколько подписчиков так как наша нашей истории основаны на подписках для того чтобы пользователю отобразить его ленту мы должны сходить в сервис подписок учить всех тех на кого он подписан получить их контент и отобразить пользователю звучит не очень поэтому мы используем немножко другой механизм от обратного при добавлении контента пользователям на которого подписан и другие люди мы также добавляем в их персональные ленты тот контент который добавил сам пользователь соответственно добавляется еще контент обновляем лента добавляется контент обновляем ленту и все замечательно теперь когда пользователь заходит на главную ли он просто получает персональную ленту отображает ее и не нужно лишний раз использовать подписки чтобы получается когда происходит проблема с бибером когда появляется бибер нам приходится на каждое обновление контента такого бибера делать там десятки там сотни миллионы каких-то телодвижений которые по сути нагружают нашу систему и мы решили это таким образом мы помещаем таких пользователей у которых очень много подписок как бибер и и для них отключаем механизм обновления лент подписчиков соответственно после того как бибер добавляет себе какой-то контент свою ленту мы не обновляем подписки не обновляем все ленты подписчиков но при этом когда пользователь заходит ему мы получаем его ленту получаем всех дибиров на которых он подписан и моржам эту ленту таким образом это некий баланс между двумя подходами по работе с подписками и это очень легко настраивать для нагрузки своего серого сервиса можно выставить любое значение так результаты в итоге сервис запущен сервис запущен быстро сроки кластеров которые обслуживают только истории получают нагрузку порядка в 30 30 fps это средняя нагрузка пике бывают данных до 40 до 50 к среднее потребление подсыпал на ноду кластера порядка четырех процентов то есть запас прочности очень большой и время ответа нашего сервиса в среднем 70 миллисекунд благодаря этому благодаря радиусу вообще нам удалось решить эту проблему очень быстро на самом деле редис очень гибок в настройках и нам очень легко было настроить редис он в принципе быстрый но если чуть-чуть его подтюнить можно получить очень очень хорошую производительность и более того редис настраивается itunes очень легко благодаря радису и вообще встроенные функциональности которые есть а ты типа данных и кластерное решение мы можем решать подобные задачи очень быстро потому что редис практически решил основную часть инфраструктурных задач и позволил нам сфокусироваться чисто на продуктовых решениях на этом у меня все спасибо спасибо александр хороший доклад нас есть здесь как на вопросы спасибо было интересно скажите пожалуйста к и кейс вот вы используете кластеры де сада в низких дата центрах и в одном то центре у вас там расположена допустим 20 мастеров сколько вы сказали цифра не помню и что происходит вот упал дата-центр мастера переехали механизм обратного переключения как у вас реализовано через редиску который вы написали или как или вручную это все происходит скажите допов равномерное распределение нодом мастеров да и сейчас это вопрос а давайте я щас на это отвечу по факту до после падения по факту машины все мастера которые там были они до ноды соответственно реплики в других пусть в других дата-центр в других машинах они становятся мастерами после того как мы поднимаем начни еще должен даже до того как мы поднимаем этот сервис родис кластер tool который вот мы сделали он позволяет следить за тем чтобы количество мастеров было равномерно распределено потому что после того как много упала радист начинает голосовать кто из реплик станет мастером и есть такая вероятность того что например 10 реплик упала в 10 мастеров и полу и все десять поднялись на одном сервере родис кластер tool позволяет пром условным мы можем прям сказать точно что вот ты будешь мастером таким образом перед получается ручной обратно извращение но обратно и распределение наверное то есть пускал как поднялся до нужно сказать ему что эти всем а как теперь живут мастера та-да-да-да-да так примерно происходит в окей хорошо и спасибо второй вопрос понятно что из репликация все-таки данные вы сохраняете там узнаю там же журнал какое-то ведет своего быка пить или нет или вот говорить что у вас есть свои вы и мы не пишем там называется правильно я либо другой метод либо комбинированные ну конкретно в этом кластер и мы на что так что да persistent ность для нас здесь была менее принципиально чем скорость но тем не менее с персен то есть нам помогает манга то есть условно те данные которые приходят от клиента мы кладем в мангу кладем в редис и используем же редис просто какая то есть кроме просмотров в принципе все данные теоретически можно прогреть конкретно в этом кейсе в этом кластере у нас up and done для отключим но при этом есть только snapshot gdb который раз в какое-то время делает дам not за счет того что но да в принципе маленькие это не занимают очень большого меня опрос стал сейчас не очень понимаю вопроса смысле а на самом деле это я примерно понял в чем проблема у нас roi des кластер он спрятан за к прокси на то есть там на уровнях a proxy все это решается спасибо за доклад здесь на мой вопрос вы уже этих частично ответили предыдущим ответом мой вопрос про вытеснение ключей так как у вас основная информация ну редис использовать как основная основной источник оно дано вот вы сказали что как минимум для просмотров вы храните только в одессе данные вот сталкивались с проблемой вытеснение ключа вот и может быть тюнингу как-то это меняли алгоритм вытеснения ключей в одессе в данном случае мы не упирались такую проблему то есть в принципе но у нас довольно большой кластер вот то есть нас все туда влезает и чисто теоретически даже просмотры по аналитическим данным можно как-то будет поднять но в продуктовой точки зрения потеря просмотра какой-то группы она не критично поэтому мы изначально не задумывались на кем-то механизмом чтобы мы железно могли их потом восстановить до проблемы именно вытеснения ключей мы не доходили но в рамках этой задачей в рамках этого кластера еще вопросы господа и дамы добрый день александр коллега и тоже александр компания из нас хотел бы сказать я посчитал вот результаты и 4 процента на ядро классно это посчитал получилось сто тридцать восемь процентов из 56 ядро сервера используется не кажется ли вам что каким-то этики power оверхендом таким что такая хорошая железка занимается ничем ну вот так я на самом деле для этого сервиса есть как минимум три таких железки по факту есть еще так как у нас у нас на каждой из машин на самом деле может находиться больше одного кластера но до в данном случае у нас где-то порядка порядка тридцати-сорока not мастеров редиса ну пока можем себе позволить понятно ещё такой вопрос на самом деле я уезжал на корфу и у меня разработчика спрашивает почему 6 гигабайт среди снова это плохо игры давай чуть по другому сделанную инсталляцию там другой редис там на самом деле сингл используем ну неважно то будет кластер там еще что то вот вы если вдруг вам разработчик подойдет и спросит почему александр больше двух гигабайт вы не рекомендуете скажите свое слово спасибо окей на самом деле pro 2 гигабайта да есть на самом деле тут все просто 2 гигабайта по сути этот тот небольшой объем которые позволят нам во первых быстро дам кнуду сущего быстро ее поднять после рестарта редиса то есть в принципе это такой ну как сказать у нее талон но такое среднее значение которое можно использовать опять же при использовании двух гигов при 56 и ядрах это как раз будет примерно там половина или целая память стандартной тачки опять же это зависит еще от кластер а потому что при а в данном случае для нас не критично какие-то данные поэтому мы например хранимых только президент не percent если мы используем только дампир db то есть мы не используем а панда апнул но при этом если мы будем использовать для каких-то других данных например долгоживущие кашу или данные которые очень важны и там занимают очень большой объем данных то в принципе почему бы не использовать больше чем меньше но до чем проще с ней работать а постоянно установится и последнее это вопрос просто когда 6 гигабайт и и стандартный конфиг заливаете у вас ноду rgb будет зовут при достаточном обновление ключей я не знаю каждые пять минут скидывать собственно эту базу для rgb если вы посмотрите на график и то он будет занимать но достаточно серьезно и долгое время вот ну и собственно это а поскольку все таки это все в одном треке решается то это фактически может очистить ваш основной основные задачи видится как обработка ключей вот поэтому наверное здесь как раз вот этот 2 гигабайтный ключом к будет более-менее такой оптимальная производительность и это хотя можно настроить наверное богатеев ну как вы правильно можно сделать любое количество просто так проще да спасибо еще раз спасибо александр"
}