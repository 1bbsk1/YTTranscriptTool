{
  "video_id": "xXDzkHr-Alo",
  "channel": "HighLoadChannel",
  "title": "Алиса, не тормози! / Арслан Урташев (Яндекс)",
  "views": 334,
  "duration": 3178,
  "published": "2024-04-17T01:10:19-07:00",
  "text": "Давай Зажигай да Про Город на Неве это воистину конечно столица мировой архитектуры Я прошел вчера 20 тысяч шагов вот Меня зовут Арслан я расскажу историю про то как Алиса работала очень медленно Как нам это не нравилось что мы с этим вообще делали вообще я в Яндексе уже 10 лет я пришел на самый стартовые на самую стартовую роль разработчика писал код сначала в рекламе потом в поиске В поиске стал руководить людьми так далее так далее И вот сейчас я сетевого Алисы моей команде 190 технических специалистов но в душе я еще разработчик в прошлом сентябре Я даже заметил код который починил одну не прикольную бумагу в прозе моя история она длится команды я присутствовал не самого начала скорость в Алисе занимались все время с разной степенью интенсивности мой рассказ В первую очередь про архитектуру Но также я вплетаю функциональные изменения потому что они влияют на архитектуры вообще на все наверное из моего доклада можно будет какие-то подходы не замедлению и ускорению выцепить Итак эпизод 1 скрытая история Вот в этой части как раз меня не было Я знаю про то что там происходило по рассказам разговорам и другим разным артефактом которые остались я украл слайд в 2018 году Яндекс публично рассказывал про то как Алиса устроена Вот это первый слайд который был публичный я Его спер сначала Когда вы обращаетесь колонки запускается распознавание речи по распознанной речи создается текст по тексту определяется intent intent это то что вы хотите вот системы например будильник поставить узнать что-то про какие-то события или как в этом примере узнать погоду погода на завтра вот помимо того что intent берется из текста также берется набор слотов это какие-то значения на которые нужно логику завязать затем запускается бизнес логика так это назовем диалоговый менеджер в нем есть походы в стороне ифы разные обработка ответов сторонних и прочее диалоговый менеджер генерирует текст синтезируется в голос Алисы и уже начинает проигрываться на устройстве с которого был задан запрос когда я рассуждаю про скорость Мне кажется удобным говорить в терминах временных колбасок вот запрос начинается слева идет направо и Вот пример как раз того как выглядит временная колбаска для предыдущего запроса начало запроса идет распознавание сколько-то много затем запускается диалоговый движок диалоговый движок заканчивает работу затем синтез и Вуаля ответ тут сразу надо добавить пару важных дополнительных точек когда идет распознавание когда вы обращаетесь к колонке вы нигде явно запрос не заканчивается нет такого что вы жмете на кнопку Все я закончил давай ответ вот ваш конец запроса он существует только в реальном мире физическом и не существует поэтому есть отдельные точки EOS это and Speech паршего с частично распознавание когда вы обращаетесь к Алисе которая живет в каком-нибудь устройстве у которого есть экран то вы хотите наверное как-то видеть что она не залипла что-то происходит поэтому было сделано такое важное X решение отображение того что уже сейчас распозналась в процессе того как вы обращаетесь к Алисе вот в качестве примера Я задал запрос приложение Яндекс Как подготовить доклад на конференцию холод и вот постепенно появлялись ответы как подготовить Как подготовить доклад на конференцию Hello и в конечном итоге Как подготовить доклад на конференцию холод дальше закрутилось эта штучка и начал ответ генерится и вот какая очень значимая идея была придумана давайте мы будем запускать диалоговый движок на каждом таком парше на каждом результате частичного распознавания потому что заметили что очень часто на экране появляется текст запроса гораздо раньше чем срабатывает классификатор конца запроса и вот в точности как работает начинается запрос он идет идет идет сервис распознавания выдает первый паршивал Пусть ключи здесь в примере Включи свет Эту певицу запускается диалоговом менеджер асинхронно работает распознавание дальше новый паршу Включи свет распознавание асинхронное вот где-то тут сработал Точнее не сработал где-то тут вы закончили запрос то есть момент времени дальше уже идет распознавание все еще по-прежнему идет так как классификатор индуфата не сработал вот третий запрос асинхронный Включи свету певицу дальше система дожидается пока доработает последний запрос в диалоговый движок запускает синтез речи синтез речи генерирует первый Чанг Чанг отдается и дальше ответ до стримливается в устройство вода озвучивает а сюрприз я люблю про это размышлять Так что разработчик первый раз когда закончил закончил эту логику задал этот запрос и у него одновременно свет включился и музыка запустилась потому что диалога движок получил вот два запроса которые делают разные как я упомянул диалоговый движок ходит во внешней API случай если это Умный дом то внешние API может быть про включение лампочки поэтому мы разделили работы делового движка на разные стадии есть отдельная стадия в конце про применение сайт эффектов она запускается только после того как уже сработал классификатор конца запроса теперь про функциональные изменения довольно важные изначально диалоговый движок был построен так как я показал на украденном слайде классифицировался intent по intent запускался сценарий внутри делала движка Вот пример сначала как обычно как у всех классификации ответа но заметили что не всегда только по запросу можно понять какой ответ будет для пользователя самым лучшим например абсолютно непонятно что хотел пользователь когда задал запрос на запуск какого-то контента который может быть или музыкой или видео можно узнать какой ответ наиболее релевантный только запустив и то и то и потом сравнив результаты какой больше всего подошел соответственно началась масштабная миграции переделка полностью диалогового движка так чтобы могли запускать много-много сценариев одновременно и дальше уже ранжировать их ответы и выбирать тот который больше всего подойдет второй эпизод как я уже сказал интенсивность ускорения Алисы было разные скоростью занимались плюс-минус всегда но вот этот эпизод про изменения был конец 19 года и решили что нужно браться очень-очень сильно за скорость и существенно повышается ускорение Помимо того чтобы непосредственно ускорить систему надо научиться следить за скоростью чтобы она не замедлялась потому что чтобы не сделали Если вы не следите за тем что система не замедляется она через несколько месяцев в лучшем случае лет становятся станет снова тормозить Ну и да было важно найти какие-то ключевые места где нужно систему по оптимизировать что-то поменять для того чтобы все стало круче Как мы начали следить за скоростью симулятор устройства как я уже сказал когда вы задаете запрос у вас нет нигде физического действия которое означает конец запроса поэтому мы не можем просто взять и по потоку логов с продакшена построить какие-то хорошие графики потому что не так важно сколько вообще вся система работала важно сколько она работала после конца запроса поэтому мы взяли набор запросов для которых мы знали конец запросы и вот моими регулярно наш Production обстреливаем и таким образом знаем скорость системы когда мы первый раз запустили и замерили мы ужаснулись Конечно Потому что в 95 процентов или почти три секунды медиане 1,41 секунды и даже даже q25 Алиса работала дольше секунды 1,21 помимо того что строили метрики мы начали крепость запросы внимательно чтобы понять что вообще в системе происходит вот эту копипасту я прям нашел в чате когда готовился к докладу и скопировал ее здесь запрос про установку громкости времена от начала запрос и момент времени когда что происходит Итак что же мы поняли что детектор конца запроса работает плохо что очень важно им заняться потому что между концом запроса и тем когда мы поняли что произошел конец запроса проходит очень много времени следующая вещь Это мысль которая собственно базируется на том что квесты запроса не очень мысль заключается в том что мы в принципе можем постараться гораздо раньше получать финальный запрос систему и делать так чтобы работа делового движка была еще более синхронная еще одна Подстава быстрый сценарий против медленного сценария как я уже рассказал раньше мы запускали только один сценарий А начали запускать сразу много сценариев если раньше запускался медленный сценарий то он был медленный вот если запускался быстрый то он отрабатывал очень быстро и система работала быстро но после нашего изменения функционального мы стали ждать самый медленный сценарий всегда И это прям заметно все замедленно как научились получать запрос раньше ну уже К тому моменту сделали некоторую переделку так чтобы в конечном итоге в конце запроса запускалась наиболее тяжелая модель распознавания предыдущие запуски модели распознавания для частичных результатов чтобы они были полегче чтобы в целом меньше железо потребляете чтобы система была не такая дорогая и вот сделали классификатор близкого конца запроса то есть стали финальную модель запускать не только в самом конце но и когда вероятность того что скоро конец становится достаточно высокой одна из ключевых вещей которую сделали начали обучать модель распознавания частичных результатов распознавания на том же распределении собственно данных которые есть продакшене изначально брали просто Ту же самую модель и ее же запускали каждый раз Ну в тот момент поняли что модель видит не весь звук как ее обучают нужно отрезать конец и на этом обучать модель распознавания которую запускаем на середине и очень интересная штука которая сработает два тоже много профита детектор конца запроса стал получать как раз вот эти результаты частичного распознавания потому что запрос длится разное время в зависимости от того какую команду вы дали если это Стоп то всего чем быстро очень коротко если это запуск какого-то контента то запрос может быть очень-очень длинным и это влияет теперь про диалоговый менеджер и запуск сразу большого количества сценариев вот здесь как раз в терминах временных колбасок Я продемонстрировал как длится запрос как мы ждем самый самый медленный и только потом выбираем победителя и система тормозит что сделали с этим заметили что на самом деле не для каждого сценария имеет смысл полностью всю логику проворачивает для того чтобы определить что этот сценарий победит потом Например если это запуск музыкального трека то достаточно поискать его в поиске взять какой-то минимальный необходимый набор данных и дальше использовать их уже в ранжировании вот остальную часть генерации ссылок там хождением по дополнительным базам данных и прочим можно доделывать как-нибудь потом вот взяли самый медленный сценарий их как раз разделили на части и ускорили таким образом систему стали дожидаться вторую часть только для того сценария который победил что еще делали всегда когда хочется оптимизировать скорость имеет смысл посидеть профайлером но не очень много потому что архитектурные изменения в системе всегда я везде в течение своего опыта вижу что дают гораздо больше чем просто оптимизации кода и вот в данном случае тоже так получилось оптимизация кода с профайлером дала 10-20 процентов и все предсказатель запроса была также идея А давайте мы не просто будем запускать результаты не просто будем частично распознавание делать но еще будем пытаться где-то как можно ближе к началу тем или иным способом генерировать А какой запрос будет в самом конце какой финальный вот и это дало Профит это внедрили Но не Но на небольшом срезе вот ну там запуск треков всяких довольно неплохо работает Например если вы запускаете какой-то трек и в конце добавляете туда исполнитель исполнителя потом какой-то трек то часто можно понять достаточно рано Что вы там в конце договорите вообще также сделали асинхронный кэш синтеза ТТС это текст to Speech В чем заключается идея идея заключается в продолжении многократного запуска диалогового менеджера но только запускать нужно не только диалоговый менеджер но и потом по его ответу запускать много раз синтез речь Почему мы от этого отказались потому что на самом деле ответы Алисы Очень неплохо ложатся в кэш хит может достигать 90 процентов Если Вы прям посидели посидели и очень круто пописали кода в кэш оптимизировав его таким образом до нескольких миллисекунд то вам уже там разворачиваться смысла никакого не имеет В общем это сделали Мега схема теперь с архитектурой большой вот у вас есть какое-то устройство это может быть станция может быть телевизор может быть что-то еще неважно это устройство все время держит Connection с нашим бэндом для того чтобы не тратить время на установку Connection Ну Входная точка в бэкенд естественно это балансер балансер конечно нужно чтобы балансировать сюрприз и балансер держит Connection еще из нашей уже веб-сокет прокси который знает как внутри поток байт устроен дата в для того чтобы этот поток байт нарезать на отдельные запросы и уже задавать в систему как отдельные запросы вначале на запрос происходит какая-то инициализация диалогового контекста из базы достаются предыдущие реплики еще что-то неважно запускается распознавание на стриме звука распознавание выдает Стрим частичных результатов в запускалку диалогового движка диалоговый движок по этим текстам выбирает набор intent of для этих контентов запускается сценарии которые могут их обработать запускает стадии continue для тех сценариев для которых это необходимо дожидается continy от сценария победителя и дальше применяется дефекты после того как уже сервис распознавания сказал что пришел конец в случае если необходимы затем синтез закошированный начинает или генерится или достается из США и отдается дальше устройство обратно ну и конечно перед этим сохраняется диалоговое состояние обратно в базу чтобы на следующий запрос оттуда взяться а теперь про то как никак не замедлять Ну валиси практически все внедрения делаются через abe эксперименты разработчиков очень много продукт развивается очень быстро много много всего катится постоянно следить за скоростью сложно но из-за того что у нас обо экспериментирование она может сказать повезло Мы сами кузнецы своего счастья и мы естественно наделали метрик и внедрили в систему Теперь каждый разработчик когда запускает что-то ВБ видит что он что-то замедлил если это произошло и в поиске И сейчас вались и я вижу что скорость системы очень-очень стабильно себя ведет можно ориентироваться вообще на самые высокоуровневые метрики просто длительность всего запроса и она будет практически идеально одинаковая в группе б если скорость не поменялась поменялась то очень быстро можно буквально за час увидеть что ваши изменения замедляет систему конечно нужно делать дополнительную детализацию для того чтобы проще было все подыбакать чтобы сразу понять на каких этапах все стало хуже интересный вопрос Ну а сколько надо Собственно как бы ускоряли ускоряли а вдруг слишком много ускоряли на самом деле непонятно Но этим вопросом мы задались только в прошлом году потому что до этого нам и сами Было очевидно что Нет так не пойдет это слишком медленно надо чтобы быстрее и что ж ты что же мы делали мы провели UX исследование звали людей в комнаты давали им там запросы ответы про кликаем проклеены через какую-то Дельту и просили оценить как бы Ок и мне Ок как вообще Это ощущается и что же получилось получилось так что от 700 до 1 секунды когда голосовой ассистент отвечает пользователь мог есть детали которые связаны с тем что не на все запросы от системы ожидается ответ в виде речи там если это команда там стоп дальше громкость 5 не знаю много их то конечно же пользователи не хотят и 700 миллисекунд ждать они хотят чтобы мгновенно произошло что они попросили интересный сюрприз Что быстрее 700 миллисекунд оказывается что не просто не нужно они комфортно кажется что Алиса перебивает не дослушивает вообще грубой себя ведет И это не классно Ну и естественно медленнее одну секунды воспринимается Так что она тормозит и тупит чего 700 миллисекунд Я когда увидел это результат Я сказал Не ну это точно не может быть правдой не может быть как бы вы там ошиблись неправильно замерили Неправильно там организовали их исследования 7 секунд но можно улететь за это время надо переделывать все мне сказали да Нет давай приходи к нам мы тебя с вами проверим вот я пошел следуемого тоже прошел через это исследование что у нас в конечном итоге получилось после того что мы после тех вещей которые мы наделали мы сделали вот действительно большое ускорение в q95 это полторы секунды с 295 до 1 19 медиане на одну секунду с одной 41 до 0,39 и в 25 процентили тоже на одну секунду с одной двадцати одной до 0,22 Казалось бы всего но у меня есть еще третий эпизод те оптимизация которую мы сделали нам отомстили в некоторых смысле продолжаем все еще у них есть обратная сторона силы надо добавить да Судя по тому как я делаю собственно В чем заключается месть месть номер один сложность голосовой инфраструктуры там где запрос представлен в виде голоса это Стрим Стрим данных каких-то Я немножко слукавил и сказав что там есть только распознавание на самом деле там есть не только распознавание там есть например онлайн валидация запроса то есть иногда бы такие случаи что колонка активируется сама по себе хотя вы не обращались к ней вот и нужно применить на бэкенде более сложные модели машинного обучения которые скажут что на самом деле устройство ошиблось и активации не было или например отмена мультиактивации если у вас много много колонок и вы обращаетесь и вы говорите Алиса они все вас слышат они все активируются и начинают лететь запросы в бэкенд и нам нужно в бэкенде понять какой Вы на самом деле обраща лись и остальные все погасить В общем и там много есть еще вещей стриминговых это на самом деле не очень важно это привело к тому что запускалка диалогов движка такая большая сложная стоит машина которая много-много всего умеет как-то переключается и новым разработчикам сложно понимать как это вообще все работает следующая проблема гораздо более очевидна это то что мы на каждый голосовой запрос в диалоговый движок сдаем гораздо больше запросов чем требуется вот в среднем в два с половиной раза больше И конечно мы из-за этого тратим больше железа чем могли бы из-за того что много вот этих ненастоящих запросов в диалоговом движке мы ходим во внешние сервисы то в этих внешних сервисах влогах оседают такие ненастоящие запросы и дальше этим внешним сервисом Приходится их внешним сервисом по отношению к Алисе говорю про другие сервисы Яндекс музыка погода неважно много их и вот им приходится потом вычищать из логов эти запросы и какое решение вообще в целом прикольно что если у вас сервис построен на машинном обучении там уже много-много людей потратили много времени и сил для того чтобы придумать какие-то фичи для формул Вот и классно потом в инфраструктуре переиспользуйтесь эти фичи Просто берешь их вообще не разбираешься что там лежит из чего они состоят Почему они так посчитаны а пробуешь на свой Таргет обучить какой-то классификатор и как правило сразу получаешь сходу результаты вот мы увидели что 15 процентов ненастоящих пар Шилов можно срезать сразу же без какого-либо замедления вообще есть такой день в году 31 декабря когда нагрузка на нашу систему не специфично все собираются вместе для того чтобы Отпраздновать Новый год вся семья там не знаю люди общаются я не общаются не только друг с другом но и с Алисой гораздо больше чем в обычный день и вот для того чтобы остальные 365 дней в году не держать огромный запас по железу Мы перед Новым годом чуть-чуть подкручиваем классификатор и он срезает чуть больше иногда даже сильно больше но при этом замедляет систему не очень сильно Вот так мы избегаем большого верха по железу следующая проблема некоторым смысле похоже на предыдущую это бесполезные континьо для многих сценариев запускаем много континента но нужен нам в итоге только один решение такое же надо тоже сделать классификатор потому что все уже есть есть куча фичей надо использовать но мы пока еще этого не сделали Ну конечно же обязательно сделаем потому что рост нагрузки у нас кратные каждый год этот слайд я вставил близко к концу подготовки потому что вот я вам все это рассказал вы можете мне сказать отчет нам это все рассказал чат gpt large Language Models вот это все вам все надо переделывать твои архитектура не актуальны Давай иди отсюда гуляй Вот но на самом деле мы уже сделали несколько релизов с вставленными большими моделями в нашу архитектуру И на самом деле Нам не пришлось что-то существенно переделывать но большие языковые модели приводят к тому что в голосовой со структуре становится еще больше стриминга она становится еще сложнее не знаю что-то нам придется придумать в будущем про это Небольшая предыстория про этот сайт тут раньше было написано приходите к стенду но потом стенды не оказалось я Заменил на приглашение в свой телеграм-канал потому что тут есть вот три темы про которые я договорился с пиаром что я про них публично расскажу его чтобы эти договоренности просто не потерялись Я про них напишу у себя в Telegram канале устройство очень много продано вообще в целом колонок Многие из них стоят недалеко телевизоров если это какой-то популярный телеканал иногда иногда бывает так что героя там зовут Алиса и сразу очень много устройств у нас активируется Вот это выглядит как огромный всплеск нагрузки там многократный в течение нескольких Ну естественно мы это побороли еще следующая особенность про которую я даже не думал пока тоже не начали срабатывать аллерты почему-то люди не знаю почему я сам такое кстати любят вставать вот ровно в какое-то время 7:00 8:00 9:00 Ну почему мы делаем Я не знаю Вот Но это привык к тому что нагрузка тоже растет если эти пользователи попросили установить на будильник нестандартную мелодию а просто музыку какую-то произвольную нужно там рекомендации запустить выбрать самый лучший треки и начать проигрывать вот еще я повесил там где-то в середине Чеховское ружье про то что колонки и устройство все время держат соединения с нашим бэкэндом до центров Яндекса несколько мы там в трех из них развернуты иногда бывает такое что эти дата-центры по сети пропадают вот и получается так что миллионы колонок должны в этот момент переподключиться к другим дата центрам не всегда это конечно происходит из-за экскаватора если честно вот сетевые инженеры у нас любят такие учения проводить периодически Как так спасибо Спасибо большое Арслан ребята Напоминаю что можно писать вопросы в чат зала пока у нас люди формулируют чат зала давайте начнем из зала вопросы задавать Давай здравствуйте Спасибо за отличный доклад вы сказали что есть попадают неправильные логи которые как бы вроде не нужны А насколько это действительно проблема для внешних сервисов актуальна и почему и как эти сервисы узнают что вообще именно вот эти лаги надо удалить вот эти не удалить а для внешних сервисов это проблема если они ориентируются на эти логи если они оттуда достают таргеты для своих формул например вот получается что в каких-то случаях там по ответу не кликнули или трек долго не послушали не из-за того что он плохой А из-за того что просто вы не отдали и не показали вот так второй части А как они понимают что вот эти-то логики на самом деле нерелевантные Ну не те ну механика для разных внешних относительно нас сервисов немножко разные бывают разные кейсы там поиск просто их выфильтровывает там в рекламе У нас есть отдельные передёргивания там специальные ссылки которые подтверждает что это реклама отдана вот ну немножко по-разному но в целом нужно просто ко написать который не будет эти логики использовать по той или на логике Короче всё сложно и все по-разному Да и можно маленький еще один маленьких детей вообще очень сложно понять Кому угодно но Алиса как-то их понимает какие-то специальные модели отдельные языковые Именно под маленьких детей делают Или как это происходит А я не помню но да сервис распознавания речи дотачивали чтобы запросы детей он распознавал лучше специально была эта работа сделана Спасибо большое спасибо я на всякий случай Руслан тебя запоминать вопросы потому что за лучший вопрос тебе надо будет выбрать кому дадим подарок вот там вот микрофончик Спасибо за доклад хотел отдельный респект выразить потому что интегрировались с различными умными домами сам поставил себе штук 30 умных устройств Вот и вообще сижу кайфую Но вот вопрос такой А почему иногда когда я вот говорю Алисе типа закрой шторы иногда она закрывает их а иногда Она такая типа Ладно И всё И ты такой мне повторить или что почему нельзя сделать такой Типа если она ничего не делает она вроде поняла это но она что-то отвечает типа не Повторите пожалуйста запрос я там не понимаю она такая ладно О'кей Ладно сложно про конкретно твой кейс сказать Вот А ну нужно посмотреть подымать что там происходит Ну ты вообще возможно что она не распознала или же Она распознала но как-то не так скорее всего Она распознала и в Клауд ту Клауд решение умного дома по дороге очень много всего может просыпаться если у тебя какой-нибудь там а китайское устройство для управления шторами вот живёшь ты в каком-то городе в Москве Ну там не знаю Вот пример Я живу в Москве и когда я говорю какую-то команду в каком-то городе после Питера в Москве сначала летит там 10.000 км до Китая поэтому там 10.000 км обратно Вот и естественно там он может по дороге много где потеряться именно чтобы вот ну просто такая типа не понял поэтому есть это локально Умный дом зигби устройство Вот который эту проблему обходят мы ее действительно видим видели и работаем над тем чтобы такого было меньше Окей спасибо И еще вопрос такой как вот мне просто интересно как вы отличаете в момент запроса когда человек делает запрос Именно его голос и ну параллельно идёт какой-то разговор какие-то люди другие тоже вмешиваются какие-то слова вылетают но вы прямо чётко фиксируете именно э запрос того человека который начал его делать валисе Вот вообще Вот это была для вас проблема или как-то это всё легко решилось Ну я не могу сказать что легко такие проблемы они есть как ты сказал Вот но в целом модель распознавания речи делается так чтобы она распознавала именно запрос человека который сказал слово Алис вот не всегда это удается конечно там что-то подмешивается но постепенно модели улучшаются улучшаются улучшается и наверное конечно было что она достаточно хорошо это делает и возможно у вас там целый не знаю исследование на эту тему было что вот как отличать одного человека от другого так чтобы запросы не вмешивались очень круто да спасибо Кстати говоря по поводу умного дома Вот я знаю что ребята недавно выпустили версию с домашним хабом для умного дома колонки и вот у нас по-моему вчера э-э был мастер-класс Вы получите все записи потом можете посмотреть там один из вариантов разворачивания умного дома как раз вот на базе инфраструктуры Алиса всё как это быстро и есть коробочки и даже почти не больно вот там был микрофончик а потом вот здесь на первом ряду Здравствуйте спасибо большое за доклад Вопрос такой Зачем вообще нужно запускать несколько сценариев параллельно когда мы ещё не закончили не определили полностью что от нас хотят то есть кажется вот даже был пример со светом ключи что там свету певицу было то есть первая часть ключи Света Она явно неправильная включить Эту певицу Это какое-то уже другое совсем действие Почему бы не дождаться до конца и не выполнить вот Казалось бы правильный конечный запрос Так давайте сразу договорились что вы будете говорить Ты мне смотри Для чего много раз запускать диалоговый движок потому что классификатор конца запроса он в любом случае не идеален и там в любом случае есть какая-то дельта по времени между настоящим концом запроса и тем момента времени когда действительно Ну классификатор сработал и поэтому если можно поделать какую-то работу асинхронно параллельно Ну почему не поделать это ускориться а если какие-то замеры насколько вообще большой верха от этого вот там был какой-то слайд про то что железо там используется по-моему в два с половиной раза больше железа из-за этого или что-то два с половиной раза больше запрос Да железо не помню точно Во сколько раз больше Ну да есть это действительно оправданного ускорение мы считаем что мы должны делать качественный продукт вот на все деньги и скорость это очень важно составляющая составляющая любого продукта и поэтому мы стремимся делать так чтобы как можно быстрее У нас система работала понял спасибо очень интересно вот какой вопрос услышать ответ подстройка Алисы под конкретные отдельно взятые профили Потому что люди с одной стороны разные с другой стороны разные люди могут быть друг на друга похожи и вот этот вопрос он вообще существует или нет это интересно или нет это реализовано или нет это возможно или нет Как вы с этим обстоят дела подучиваются ли она вот под конкретный какой-то профиль Спасибо компонент системе много Некоторые подкручиваются некоторые нет Вот например музыкальная рекомендации они очень сильно зависит конечно же вот человека который просит Запустить музыку вот там персонализация очень круто если честно прокачена вот если же говорить про классификацию запроса то там персонализация мало роляет потому что как правило по запросу и какой-то части запросов по ответу нескольких сценариев можно понять что человек Хотел вот не прибе Гая к тому чтобы знать про Человека что-то еще дополнительное Окей спасибо росла очень интересный вопрос нас поступил из чата Мы все знаем что в приложении для вызова Колонки можно выбрать два позывных Алиса и Яндекс вот Татьяна спрашивает Мою собаку зовут Мелисса А еще я часто говорю про индексы Будут ли еще какие-нибудь позывные колонки а то она часто срабатывает вхолостую вопрос задан про какой-то конкретный продуктовый план вот мне такой план неизвестен может быть надо пользоваться в целом если говорить про имя то Алиса это же не просто исполнитель команд это персонаж который еще дополнительные эмоции вызывает вот с каким со своим характером Так что Конечно нам бы хотелось чтобы ее только Алиса называли но некоторых пользователей кого-то в семье зовут Алиса и они будут страдать тогда совсем поэтому есть Альтернатива в виде слова Яндекс не хватает вот сзади там Привет спасибо Я хотел спросить а вот когда Алиса научится отвечать вот конкретно на твой вопрос Без отсылки на какие-нибудь ресурсы допустим там спросишь там когда был последний раз год собаки она начинает говорить что там на ресурсе каком-то Я нашла такой-то ответ и сразу же дагонку вопрос Вот сейчас же вы научили Алису с gpt моделью работать но она типа триггерится только когда ты там типа определенную скажешь фразу что типа Давай придумаем типа рассказ вот когда в принципе Алиса вообще сможет сама отвечать И вот обучаться а Давай придумаем он несколько отдельно сделан конечно но мы эту технологию интегрируем и валится тоже Для чего Алиса произносит источник Потому что когда ты у нее что-то спрашиваешь хочешь получить информацию то на самом деле Ее ответ дополнительно Ну ты бы хотел проверить там Это насколько вообще правда потому что иногда бывают конечно ошибки вот и когда Алиса тебе говорит источник с которого она взяла Ты Можешь прикинуть Насколько этот источник вообще авторитетный ты насколько доверяешь ответу вот в интернете ну чего только не пишут Спасибо вообще вот можно я сейчас немножко адресую вопрос зала много вот в зале сейчас из вас игрались Вот такими LM типа gpt и так далее Поднимите руки практически все наверняка же все сталкивались с тем что это мыло ему задаёшь вопрос он дает ответ неправильный Вот мне кажется вот Краеугольный Камень пока вот эти ЛМ и не будут настолько хороши чтобы самостоятельно оценивать качество ответа может быть проблемы Вот здесь у нас был вопрос да спасибо за доклад про gpt Я тоже про него спрошу как раз таки про синтез речи ты сказал что в обычной жизни там кэш Хит в районе 80-90 какие-то цифры были но в случае генерации речи для Чад GT Как это работает Простите для GPS так А ты как вообще заметить эту проблему Я заметил отправляем Мы с женой очень долго ковырялись с тем что она на одинаковые запросы всегда примерно одинаково один из Сета одинаковых ответов отдает и мы такие думаем Ну при генерация кэш и вот рассуждали таким образом А здесь мы начали с ней разговаривать и там совершенно Ну генерация как ты очень точно заметил эту проблему вот 2023 году мир поменялся конечно же и лмки ответы генерируют разные и продуктовые мы считаем что это лучше чем более-менее как-то одинаковые фразы для ответа вот а ну проблему мы естественно будем решать для начала путём там доливки железа в синтез речи э-э Ну постепенно придумаем что-то ещё скорее я про то что ситуация сгенерилкой а нет Ну он есть просто там кишки 0 почти А Все я понял спасибо О как кэш но кэш хит 0 Вот мы сейчас вскрыли прям вот здесь вот вопрос на Привет Спасибо за доклад тут тоже вопрос частично про генерацию речи я вот пользуюсь Алисой достаточно часто и довольно Больно когда ты просишь там Поставь лайк и когда ты делаешь Это несколько раз в день ты Слышишь Постоянно одни и те же фразы это прям реально бесит И когда ты приходишь поддержку говоришь А можно как-то настроить профиль того что мне не надо вот вот эту чудную фразу чудную речь а просто сказала о'кей и всё Когда будут настройки профили того В каком формате Алиса отвечает Ну опять же про конкретные сроки Я тебе не могу сказать Ну планируется это вот без учёта там человек а именно вот продукт постоянно улучшается та проблема про которую ты говоришь она там в вопросах пользователей светится так или иначе вот не помню уж точно в каком объеме Но вот к примеру в умном доме когда ты говорил команды умного дома она раньше отвечала тоже голосом сделала Например или еще что-то но потом заменили это на проигрывание коротенького звука для того чтобы пользователь понял что вообще на что-то сделала они просто погасло но при этом чтобы ответ был не голосовой Не длинный а супер короткий В общем ответ такой когда-то Твоя боль обязательно решится Давайте еще два вопроса один вот там Руслан такой вопрос Мы все время обсуждали сейчас Алису работу с ней как со стороны от Алиса идет реквест Алисе приходит я правильно понимаю взаимодействие правильно или это квест Можете ли вы без запроса от пользователей к Алисе что-то посылать очень ограничено И это всегда какие-то специальные продуктовые фичи Вот например сообщение о том что Курьер из лавки подошел мы без запроса пользователя умеем посылать нотификацию так чтобы Алиса сказала про это или есть вот функциональность музыкального пульта в приложении яндекс.музыке там конечно тоже нет обращения к Алисе есть обращение к кнопкам на телефоне и дальше через наши сервера Мы команда шлем для уже проигрывания треков переключения и так далее с курьером это получается как бы через Как ваш сервис опять же получается да есть связь с устройствами или связь с хостом допустим человеком либо телефон получается и поскольку это устройство связано вы получается с одного бакенда отправляете просто на Алису уведомления фактически в целом Да мы просто интегрированы сервисом Яндекс они знают что надо к нам сходить отправить информацию о том что курьер подошел теоретически вы не можете там отправить уведомление начале войны или подобным массовой такой рассылку или можете одно новое сообщение в госуслугах этого инкома не знаю что-то сложно ответить Как вы тут Ты задаешь вопрос вида А может ли вы что-то сделать прямо сейчас или Можете ли вы что-то запрограммировать Вот мне кажется знаешь что здесь Вопрос немножко примерно следующее У тебя же Алиса вернее У нас у всех да Ну ты это делаешь своей командой Алиса Она же э-э как бы лук бэком получается сообщение То есть она сама обращается к серверу а не сервер имеет постоянное Соединение со всеми алисами во всём мире э-э я надеюсь Ну нет о том что Connection постоянно Да мы постоянно держим Connection со всеми устройствами Да это испугало для того чтобы это быстрее работало а все я кажется Понял Вопрос смотри Connection это просто сущность вот сетевого стека Если ты не обращаешься колонки то там ничего не ходит Вот уж тем более никакой звук не ходит Вот Но при этом через Connection в обратную сторону мы можем послать команду для ряда продуктовых свечей Спасибо вот там вот вопрос Спасибо большое за доклад очень было интересно послушать у меня такой вопрос Вы вот в команде наверное не так давно запустили фичу что можно звонить с одной колонки на другую в рамках одного аккаунта У вас есть как-то идеи делать чтобы можно было звонить с Алисы на другую Алису на другой Яндекс аккаунт через мессенджер И второй вопрос тоже такой просто интересно как это работает когда говоришь Алисе положить трубку она тебя прекрасно понимает и собеседник Почему слышит что ты просишь Алису положить трубку как типа не слышит Не слышит но у меня стран должен слышать Я думаю что слышит просто как вы делаете Так что она вроде не глушит они делают тише себя чтобы услышать положить трубку но одновременно с этим прекрасно все распознаёт Вот спасибо на первую часть про то что мы планируем А чего не планируем Вообще процесс планирования у нас выглядит как очень-очень большое количество фичей которые хочется сделать Вот Но сил есть на то чтобы их сделать несколько лет наперёд Вот и эти фичи они берутся из разных источников это там продуктом менеджеры что-то придумали они появились запросов пользователей или пользователей жаловались поддержку вот или кто-то из команды что-то придумал Вот и Ну да ты говоришь конечно же она есть в списке вот ну когда на появится в продаже я не могу сориентировать Ну и получается как типа Алиса Ну то есть у вас же есть проблема что сама себе Алиса мешает когда что-то говорит взял микро своими микрофон шумит А можешь поближе не услышал да так лучше когда получается ты говоришь собеседником Алиса постоянно что-то тебе вещает То есть она получается другой колонки какой-то типа там саунд и его воспроизводит и вот когда ты сам говоришь Алисе Алиса она делает себя потише она делает тише музыку и прочее но во время разговора с собеседником она не делает себя тише вроде но типа всё очень хорошо себя распознаёт А ты должна делать не знаю Нет по идее всё работает замечательно конечно понижение громкости проигрываемого контента Ну написано кодом с работы запрос сделать потише музыку значит для звонка не написали такой код круто круто что сделали что-то типа во время звонка в общем Спасибо за фичу Спасибо ничего не трогайте все работает а так сейчас Надо всех вспомнить вон там были вопросы с такой подковыркой молодому человеку в розовой рубашке вот туда пожалуйста книжку ой книжка то какая у нас сегодня ничего себе это что ninbow Спасибо большое Руслан как бы мы очень тебе говорим Спасибо за очень-очень-очень крутую абсолютно дискуссию это от нас небольшой презентик Приходи к нам снова рассказывай про нововведение про Алису это это очень круто Спасибо тебе большое спасибо большое за крутую конференцию Да Обязательно надо прийти чтобы было написано приходите к стенду"
}