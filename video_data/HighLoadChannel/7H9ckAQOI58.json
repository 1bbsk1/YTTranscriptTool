{
  "video_id": "7H9ckAQOI58",
  "channel": "HighLoadChannel",
  "title": "Zabbix: рецепты высокопроизводительного мониторинга / Алексей Владышев (Zabbix)",
  "views": 6934,
  "duration": 3501,
  "published": "2018-08-16T03:57:10-07:00",
  "text": "да добрый день я тема моего сегодняшнего доклада zabbix а рецепта высокопроизводительного мониторинга фактически это некий отчет о той работе которую мы сейчас проводим связанную с тем чтобы как бы понять какие узкие места существуют за биг си в плане производительности на что способен zabbix на данный момент и может быть каким-то образом очертить план действий чтобы с этим бороться в будущем но о чем я буду сегодня говорить это архитектура внутреннее устройство zabbix а не смотря на то что доклад на чит называется рецепт высокопроизводительного мониторинга все равно он будет вокруг забег суда то есть я может быть иногда буду говорить о каких-то других других продуктах но все таки какой то не может быть небольшое знание записи концепции zabbix а она она все-таки приветствуется тесты производительности проведем ну и посмотрим что можно с этим сделать дальше архитектура zabbix а кто из вас использует zabbix кто не использует zabbix да есть есть люди в наших селениях так хорошо архитектура zabbix но если посмотреть высоты птичьего полета это zabbix сервер центральная часть zabbix а которая фактически занимается всем да и сбором данных и анализом данных и alert стингом эскалация my фактически вся логика zabbix а встроена в zabbix сервер есть также такие процессы как агенты агенты которым устанавливаем клиента вспомни из и с агентами можно общаться там по тисе пи соединению используя разные модели там пущали пул модель и также есть zabbix прокси который используется чаще всего для мониторинга каких-то удаленных локаций да то есть если у нас есть предположим какой там раньше нашей компании мы устанавливаем zabbix прокси в этом удаленном branch он мониторит локальную инфраструктуру и все данные отпра вляет на zabbix сервер для анализа и данные те которые собирают эти вот меня 3 киев и в том числе конфигурационные вся конфигурация забег сохранится хранится в базе данных а есть еще frontend до frontend тоже оказывает какую-то определенную нагрузку на на базу данных в первую очередь ну и опосредованно на на zabbix сервер вот давайте поговорим о таких самых простейших рецепт вообще что быстрее но безусловно если мы сравниваем model пуш или пул пул это модель когда мы опрашиваем агентов то есть скажем система мониторинга подключается к агенту спрашивает дай мне пожалуйста список метрик либо одну какую-то метрика это работает медленнее чем если бы агент пушил данные на сторону забег сервера до поэтому если смотреть с точки зрения производительности отвечать на вопрос что быстрее пущали пол безусловно push быстрее мы просто ничего не делаем ожидаем данные с наших агентов агенты могут быть любые да там zabbix агент и может быть что-то другое дальше если записи существует прокси об этом я уже говорил основное основное предназначение прокси мониторинг удаленных каких-то локаций с другой стороны zabbix прокси можно использовать для того чтобы разгрузить zabbix сервер от всей логике работы с агентами то мог бы самой пьем агент snmp agent и тропы все что угодно да и поэтому мы строим посередине zabbix прокси zabbix прокси осуществляет всю эту логику работы с агентами собирает данные и потом в очень и очень эффективно отправляет все эти данные на сторону zabbix сервер и опять же с использованием пуша zabbix сервер но скажем и вот если мы посмотрим на другие системы мониторинга ну допустим там про металл с да про метался он в какой-то степени настаивает на такой пул модели да когда мы там через http отдаем метрики про металась подключается к к нашему агенту агенту приложения и одним из 4 запросам получает получает список метров zabbix есть свобода и мы не настаиваем ни на одном подходе не на другом можно получать метрики с помощью push модели либо с помощью полу модели дальше пакетная обработка данных но опять же очевидно я здесь даже не буду объяснять как то углубляться в подробности очевидно что обрабатывать метрики таким скопом дешевле с точки зрения производительности дано мне нужно скажем каждую метрику отправлять не использовать одно с эти цепи соединения на метрику мы собираем метрики там скажем а десятки сотни или тысячи значений и одним тисе пи соединением отправляем эти метрики на zabbix сервер именно таким образом и работает прокси да что еще но если мы заботимся скажем не заботимся о безопасности заботимся о производительности то на самом деле можем обратить внимание что тело соединения в записи существует два вида шифрования да это песке и прищепки когда мы шифр он над симметричное шифрование с одним ключом до нас на одной стороне на другой стороне то может быть прокси zabbix сервер либо там прокси агент либо агент агент сервер и такое шифрование симметрично она очень дешево да то есть процессор они мощные сейчас и и и в общем то на сетевом уровне симметричное шифрование она не привносит никакого охеда там и не нагружаем сетевой уровень в случае тел с мы сетевой уровень немножечко нагружаем потому что потому что фактически нам но есть есть процесс хан шейкин года то есть перед тем скажем образуется соединение есть хан шейпинг обмен ключами и в зависимости от late in se это может добавить такую достаточно весомую задержку которая будет видно с точки с точки зрения производительности всей системы а дальше если мы говорим о за биг си о чем важно помнить но несколько моментов один из моментов то что zabbix является мульти процесс ным приложением dante процесс ным что это означает это означает что вот предположим мы запускаем забег сервер мы видим что запускается масса процессу все эти процессы играют разную роль то месте полер и есть трапперы из какие-то процессы со странными названиями там тебе синкер и alert эры но примерно можно предположить чем чем эти процессы занимаются здесь есть и плюсы и минусы на плюсы очевидны и заключаются в том что но это такое одно приложение мы запускаем и получаем всю логику здесь мы сравним скажем с микро сервисной архитектурой либо мульти 3 давай скорее смутит ряда войда и плюсы такие что мы четко видим есть некое распределение ответственность есть нас какие-то определенные процессы мы их четко видим с точки зрения операционной системой понимаем кто чем занимаются конечно если бы забить болт был мульти преданным я так думаю что он был более эффективен в каких то моментах почему потому что операционной системе нужно было бы тратить время на переключение контекста да тогда могли бы запускать скажем количество тредов по количеству ядер и zabbix мог бы работать более эффективно запись является полновесной системой мониторинга да поэтому когда иногда люди сравнивает а давайте сравним zabbix потом сын фукс д.б. да это не совсем корректное сравнение потому что индекс д.б. это просто ну скажем некий такой сторож да то есть мы туда складываем данные забег все-таки является полновесной системы мониторинга и хранение данных это лишь одна часть кусок функциональности zabbix а есть и многие другие такие как анализ данных такие как обработка обработка этих данных и ryoko реакция на на проблемы но и zabbix также об этом необходимо помнить предоставляет различные гарантии целостности ну например мы используем всегда тисе пи да то есть вот такая гарантия доставка на уровне сети мы используем транзакционных то есть какая-то more ность операции на стороне забег сервера то есть операция не проект происходит как бы независимо мы используем транзакционный что тоже влияет на производительность и так же мы используем различные ну скажем constraint и либо проверки целостности данных на уровне базы данных поэтому как бы конфигурацию зафиксировали достаточно сложно сломать какими-то может быть неправильным операциями но вот так я не знаю видно или невидно так примерно zabbix выглядит из консоли мы запускаем zabbix сервер запуск после этого команды ps там либо топ мы получаем получаем в общем-то всю информацию что такое за биг си с каких компонентов состоит и чем процессы в чем процессы занимаются но предположим мы видим тамале ртр и мы увидим history синкер и полер и трапперы и абсолютно понятно какое состояние этих процессов на данный момент и это очень полезно для такого trouble суть инга если у нас есть системы production вдруг мы видим что какой-то из компонент начинает тормозить по каким-то не определенным причинам что мы можем сделать мы буквально в реал тайме например можем поменять уровень дебага до установить его на какой-то максимально возможный через пять секунд подключить для этого нам не нужно перезапускать зафиксируем это можем сделать для группа процессов либо для одного процесса но потом анализируя вот этот вот и бокал посмотреть в чем же в чем же была проблема либо может быть консультироваться с инженерами и из-за бикса но опять же когда мы запускаем zabbix до zabbix сервер либо другие процессы есть какие-то параметры по умолчанию случае zabbix сервера это допустим старт те параметры которые начинаются с префикса старт трапперы star baby синкер и старт полер и ну и и и и достаточное количество таких параметров zabbix внутри внутри себя используют различные буферы различные каши да то есть я не поговорю немножко подробнее и в конфигурации zabbix сервер а также присутствует там касаясь history касаясь в люкс сайт пока это звучит абсолютно непонятно но это постараюсь расшифровать как-то влияет на производительность что это такое да то есть у нас есть какие-то определенные размеры буферов и об этом необходимо знать для того чтобы выжить и за биг си максимальная производительность но давайте на сегодня наверное бы поставил две задачи это достичь максимального уровня производительности на каком-то эталонном железе чтобы мы могли сказать вот у нас есть определённое железо на этом железе забег способен достичь какого-то уровня производительности да и вторая задача найти узкие места забег сервера да где же эти узкие места почему мы может быть достигаем какого-то потолка и дальше не можем масштабироваться ну давайте мы выбираем для тестов как раз как раз взгляд для тестов мы приобрели два сервера на сервер от такого скажем так среднего уровня это 2 processor ные hp девятого поколения 24 ядерные 128 мегабайт памяти и 4 диска 4 ssd диска до стоимость такого решения порядка 5-7 тысяч если у вас хорошие отношения с чёрной можно купить дешевле да ну вот мы купили примерно там за 7000 евро на в облаке такой облачный аналог я я посмотрел быстро на и дабл ю си не знаю не тестировал но мне кажется что это примерно там ой 38 x large до который примерно сопоставим этот дикий этот сервер который примерно сопоставим вот с этой спецификации стоимость облачного аналогом и порядка там тысячи тонн 1300 евро в месяц до то будет столько стоить как операционную систему мы использовали red hat enterprise linux до последней версии 75 файловой системы xfs но и такое тестовое окружения 2000 2 миллиона метрик то есть миллион триггеров и все это мы поделили по хостам до 20 тысяч постов получилось на один хост 100 метрик и 50 триггеров дальше метрики да ну вообще в записи появилась такая возможность мы называем предобработки метрик либо какая то такая трансформация метрик да то есть приходит метрика она немножко неудобоваримая то есть допустим приходит какой-то текстом из этого текста все-таки нужно выбрать какую-то полезную информацию паре гэг спал до либо приходит метрика в 16-ричной системе нам нужно преобразовать десятеричную систему либо использовать какой-то множитель там бита преобразовать в байты либо байты в биты и так далее в записи все это сейчас можно делать появилась как функционально который чуть чуть чуть чуть чуть расскажу более подробно это предобработки то есть мы можем строить некий конвейер предобработки метрик да и вот из и сел двух миллионов метрик 25 процентов nitrix предобработки и 40 процентов всех метрик это числовые значения то есть восемь процентов числовые из них половина целочисленные половину с плавающей запятой 10 процентов строчки string до пяти то текст это более такой более длинный текст несколько килобайт и 5 это мониторинг лог-файлов да то есть я думаю что это достаточно такое реалистичное окружение когда у нас есть метрики метрики различных типов некоторые имеют предобработки есть и тексты есть лог-файл мониторинг есть мониторинг просто обычных обычных училась целочисленных значений да и что такое предварительная обработка это та функциональность которая появилась в 34 мы и подробно разбирали вчера вчера на митапе по сути это возможность получать полезную информацию из данных любых типов да то есть на zabbix можно отправлять джейсон xml если любой текст zabbix а может с помощью жестов выбирать какие-то данные да и и дальше сам забег сервер делает две вещи появилась возможность вот этот большой блок данных делить по метрикам да то есть то есть есть у нас скажем джейсон мы по ключам распределяем информацию по различным метрикам да это это одна часть этой функциональности вторая часть функциональности это то о чем я рассказал когда приходят данные с ними не удобно работать и что мы делаем их преобразуем в тот вид чтобы было с ними удобно работать да ну простейший пример 16 шестнадцатеричную систему преобразуем десятеричную систему другой пример это когда мы пори горячку что-то выбираем или компан компонует до из двух кусков рига экспо дальше ну как мы будем тестировать вообще если говорить о тестах у обоих марках zabbix а то здесь скажем на входе очень много переменных особенно если бы мы использовали агентов мы использовали использовали бы прокси то есть тут сразу же нужно было бы понимать как на этих как мы этих агентов загружу какой ли и танцы между агентами прокси и забег сервером до переменных так много что я решил все это упростить и мои коллеги решили все это упростить в итоге мы не будем мы как бы отбросим ту часть которая занимается сбором данных да то есть мы не будем скажем измерять как быстро zabbix может собирать данные и это достаточно легко масштабировать мы запускаем дополнительные прокси и дополнительные про ксенон могут мониторе там сотни тысяч постов до в этом нет проблемы проблема едите эту проблему которую мы хотим обнаружить скорее всего она существует забег сервере потому что зафиксирует центральная точка в которую сливаются все данные соответственно тестовое окружение будет выглядеть следующим образом мы будем использовать от 1 до 8 прокси почему 8-я и почему вот мы ограничились 8 пока я потом объясню мы заранее готовим данные в базах данных этих прокси то есть мы считаем что в proxy есть уже данные которые накопленные данные там прокси одна база данных 2 миллиона измерения если два если два прокси мы используем то это будет четыре миллиона 8 прокси 16 миллионов дальше мы все эти данные отправляем на zabbix сервер zabbix сервер обрабатывает фактически мы измеряем время за за какое время забег сервис способен обработать эти данные там 2 миллиона там четыре миллиона ну ну и и так далее и и в итоге мы должны получить цифры количество скажем метрик в секунду который способен обработать забег сервер мы посмотрим что у нас получилось на физическом уровне из чего со все это состоит два идентичных сервера практически идентичных это zabbix сервер и спецификацию я уже назвал есть другой сервер тут практически такой же самое и с на котором мы запускаем zabbix прокси и посередине гигабит на switch да все это так работает ли апельсину на самом деле минимально но если смотреть на zabbix сервер опять же на то чем занимается забег сервер фактически вот этот вот вся вся обработка данных она сводится к обработке метрик вначале то есть мы эти метрики получаем как-то их при добра бат его им готовим дальше у нас есть анализ анализ это тот момент когда включаются триггеры да то есть есть непрерывный поток данных с помощью триггеров мы пытаемся понять есть у нас проблемы или не то такая достаточно тяжеловесная операцию и следующая операция это запись базу данных и что мы будем делать мы сначала мы попробуем отключить анализ данных считаем что у нас триггеров нет и мы отключаем базу данных то есть мы не пишем в базу данных и попробуем определить производительность под системы которая отвечает за обработку метрики дальше мы будем подключать анализ данных мы будем подключать базу данных и смотреть насколько это будет влиять на производительность это это нам такое деление нам позволит более точно определить ну во-первых производительность каждой из под систем и насколько под системы влияют на общую на общую производительность и и определить вот эти вот battle ники определить узкие места более четко давайте расскажу немножко во внутренностях zabbix а что касается обработки метрик есть такие процессы трапперы которые слушают входящие соединения эти соединения могут прийти со стороны zabbix агентов активных zabbix агентов либо со стороны zabbix прокси этот краста push модель когда мы данные отправляем на zabbix сервер у нас есть трапперы дальше что происходит дальше у нас также есть configuration кэш внутри самого забег сервера кусок памяти которому называем configuration кэш и это по сути копия той конфигурации которая хранится в базе данных то есть список всех метрик айтемов список всех триггеров макросов состав но еще дополнительная информация время от времени забег синхронизирует то что есть у нас базе данных с кэшем чтобы держать его в таком а в постоянных в таком в правильном в правильном состоянии то есть если мы через фронт добавляем хост zabbix не начинает мониторить этот ход сразу же в тот же самый момент проходит какое-то время по умолчанию это одна минута 1 минуту про происходит от синхронизация приходит приходит значение на trapper traper используя configuration кэш получает информацию о байтами это скажем типа этом а это его статус может быть нам уже не нужно обрабатывать метрики поэтому уайту данные по по этому атому и так далее дальше это идет все в так называемый при процент при processing менеджер да этот процесс который появился в версии 3-4 при processing менеджер он работает по такому достаточно стандартному шаблоны проектирования до когда мы получаем некие задачи на вход и распределяем эти задачи по маркерам да это те процессы которые выполняют реальную реальную работу и дальше вот предположим пришло пришел какой-то кусок лог-файла мы обратились configuration кэш нам стало все понятно что да этот лог файл нужно обработать таким-то образом скажем с помощью регулярного выражения оттуда вытащить респаун скотт да если это мониторинг веб скажем веб-сервера да и и как раз вот эти вот worker и что они делают они смотрят да вот у меня есть значение на входе есть некие правила предобработки все эти правила выполняются и потом результат уже такая чистая метрика там 200 ли там 401 400 записывается history кэш да вот это первый этап обработка метрик пусть мы мы сделали некую предобработки посмотрим какие какие цифры мы здесь получили но во первых да еще расскажу немножко о конфигурационных параметров которые влияют на производительность что касается количества трапперов это параметр старт rappers да все все достаточно просто и очевидно что количество трапперов должно соответствовать ну в но в данном случае как минимум количество прокси чтобы вот наши там 4 proxy ли 8 прокси одновременно смогли подключиться к zabbix сервер у и одновременно отправлять информацию дальше у нас есть кэш сайт нож configuration кэш сайт фактически размер его зависит от того как много метрик как новой томов и триггеров у нас есть базе данных чем чем больше нас конфигурация тем больше мы должны выделить память configuration кашу есть также configuration sinker и вот этот вот кэш апдейт frequency 60 секунд как часто мы как бы подкачиваем последние изменения в конфигурации из из базы данных и есть у нас еще старт при processors такой параметр как количества маркеров для при процессинга и history каша из history кэш сайт это некий буфер между забег сервером и базой данных то есть перед тем как записать значение в базу данных мы сначала держим в памяти вот в этом буфере на самом деле в за биг си все можно очень четко мониторить с помощью внутреннего мониторинга можно четко ответить на вопрос скажем заняты trapper или нет на сколько процентов до можно ответить на вопрос насколько процент занят configuration кэш либо насколько заняты препроцессоры либо при processing менеджер да то есть мы используя там стандартный шаблон zabbix а мы заходим в дашборд в экраны и видим очень четко хватает нам трапперов или нет хватает ли нам размера configuration cacilie скоро может не хватить поэтому лучше заранее и увеличить ну да из консоли это выглядит примерно так что касается обработки метрика то есть у нас configuration синкер есть у нас трапперы при processing менеджер при processing при примерно если система не работает то тут то вид вид вид примерно такой дальше ну я не знаю здесь видно наверно цифра не видно но без триггеров и базы данных но мы запустили с одним прокси получили такие там 65000 в секунду с двумя прокси в два раза больше с четырьмя прокси где-то может быть в три с половиной раньше раза больше из 8 pro прокси получили такие же данные как и четырьмя прокси да то есть почему то по какой-то причине причине 4 pro 8 прокси не смогли загрузить zabbix больше того уровня чем при использовании 4 proxy ну вообще первые выводы но 168 тысяч проверок в секунду это действительно как-то не очень много при работе zabbix сервер утилизация цепью было в районе 8 проц процентов да то есть вот у нас два четыре ядра с hyperthreading а мы-то будет 48 но примерно в на 8 процентов мы смогли загрузить циpкa и мы обнаружили что уперли сейда один из интерфейсов был сконфигурированные на гигабит на 100 мегабит ну и понятное дело что просто вот эти вот а мегабит в секунду там 11 но это в данном случае мы уперлись сеть и тут нас возникла опять же идея почему бы не использовать компрессию этой функциональности пока нет записи но там быстро за один день мы мы сделали прототип и на самом деле опять же протестировали из компрессии мы получили лучшие цифры да то есть с одним прокси там 81000 с 8 прокси порядка двухсот тысяч значений метры в секунду которые которую мы можем обрабатывать до при увеличении количества прокси мы мы не смогли увеличить производительность zabbix у да к сожалению вот опять же достало все быстрее на 20 процентов за счет того что мы во-первых добавили мы мы перешли на canon айна мы протестировали сначала на 100 мегабитах это и это привело к увеличению производительности на 20 процентов в на gigabyte мы получили примерно такие же примерно такие же цифры ну какие какие выводы вот в плане анализа и предварительной обработки данных на этом железе zabbix может обрабатывать 200 тысяч метров в секунду то есть 203 200000 значений в секунду может обрабатывать различных типов компрессия помогла я думаю она действительно поможет в таких реальных реальных условиях когда когда бы особенно большой лейкен силе или или с или слабые слабые соединения между между зафиксированные и прокси ну и мы уперлись в узкое место при processing менеджер в при processing менеджер мы исправили такую одну проблему мы заметили что в таком в цикле при процессе к менеджерам мы делаем несколько лишних системных вызовов увеличили производительность еще порядка нагнать на десять процентов но все равно оказалось что при processing менеджер это это узкое место да вот то что есть у нас один процесс и скорость этого процесса на данный момент определяется скоростью одного ядра процессора до у нас там скажем 2 и 2 гигагерца серверные серверные процессоры на самом деле если запустить все это на на десктопе допустим там наносит но сильно 7 мин то ли там 3 33 гигагерца мы получим больше производительность просто за счет того что ядро работает ядро работает быстрее и действительно с этим надо будет что-то делать мы мы мы над этим будем работать до видно что здесь есть такое узкое место которое можно распараллелить парализация она может быть не настолько простая как как кажется потому что zabbix опять же предоставляет гарантии по порядку тех метре который мы получаем то есть предположим если для одной метрики мы получаем значение сначала 0 потом один мы его должны через весь стек пробросить вот так вот сначала 0 потом один есть мы начнем параллели и потом в какой-то момент нас порядок поменяется и к чему хорошему на уровне обработки триггеров это не приведет дальше подключаем анализ данных подключаем триггеры фактически мы используем похожие триггеры которые мы используем в наших стандартных шаблонов в шаблонах это анализ несколько последних значений трейдеров это анализ последнего значения триггера это анализ триггера за какой-то промежуток времени очень большой порядка там 5-15 минут давайте посмотрим насколько это отразилось на производительности но сначала я покажу из чего состоит history синкер это следующий процесс которые участвуют в обработке данных то есть начало traper он складывает все history кэш и дальше есть процессы которые я надеюсь что видно history синкер и которые по сути выгребают те метрики которые у нас находится в хистори кэш и дальше и дальше что происходит опять же используя configuration кэш идет вычисление триггеров здесь мы используем как бы такую прослойку между базой данных и забег сам для того чтобы не лазить в базу данных очень часто за исторической информации которая называется в люкс то есть это по сути кэширование исторической информации да для того чтобы просто не делать часто выборку из из базы дальше идет event processing когда мы генерируем проблемы дальше идет processing действие до отправка нотификации то и так далее тут тут мы работаем напрямую уже с базой данных пока мы не пишем не history не тренда это в самый последний этап здесь есть несколько параметров это количество singer of которые можем запустить размеры буфера в кэш сайт и и виллы кэш да wip кэш сосет все дефолтные значения 8 мегабайт history к 6 8 мегабайт для больших систем рекомендуется конечно же увеличить для того чтобы иметь как бы больше запас надежности между базой данных и зафиксируем случае если запись если база данных начинает тормозить по каким-то причинам да не предоставлять нам хорошего уровня производительности у нас будет некий запас в виде буфера который запись будет постепенно заполнять как только база данных возвращаются в приду состояние это это все скис быстро скитаются базу данных ну с триггерами до триггеры опять же там 1248 прокси упал в максимум и мы получили порядка -60 минус 60 процентов производительности то что обработка триггера все-таки это такая очень очень тяжелая тяжелая операция да сейчас мы находимся порядка уровень 90 тысяч в каких-то случаях в каких-то случаях больше чем больше чем 90 тысяч ну какие выводы здесь можно сделать но понятное дело что обработка триггеров снижает производительность до теперь мы видим что где-то 30 до 60 процентов мы уперлись где-то в производительность порядка 90 90 тысяч секунду и опять же это узкое место вот этой спорт системы которая понятное дело что здесь все зависит от того как мы определяем триггеры насколько эффективно мы работаем с историей если у нас триггеры prostate будет работать быстрее если триггера на сложные в данном случае у нас комбинации простых и более сложных триггеров то мы можем увидеть и уменьшение производительности там до дождь есть процент по может быть больше да все зависит все зависит от того как много у нас триггеров насколько сложные триггерные выражения а пробуем подключить историю до историю то есть мы добавляем вот history синкер когда он получает данные с историки он тут же записывает и of history и в тренды то есть сразу же тут же пишем of history в трендами пишем 1 час то есть им нужно записать то to the thumb thumb то мы пишем в том числе и в тренды мы выбираем базу до тестировалась то что есть на red hat enterprise и это 55 достаточно старой версии конечно же и моя скала это мария де беда и под газ а версия 92 но в том числе мы взяли самую последнюю самую последнюю версию infox дебин до 135 пас посмотрим на что они все были способны но мария де без начала просто провел синтетические тесты по сути в одну таблицу несколькими отрядами в историческую таблицу в хистори не с и мид рядами подписал с максимальной производительностью метрики но видно что деградация происходит достаточно быстро если у нас не затюнена базу то это в этом мгновенно происходит буквально через через две минуты производительность снижается до 10 до 10000 порядка может быть 15 тысяч в секунду несмотря на то что если посмотреть на дисковую подсистему это ssd-диски до 10 райт плюс еще посередине кеш гигабитные ноги гигабайт до 1 гигабайт кэша все равно это ну это это работает очень плохо да поэтому после определенного тюнинга пришли вот такой картинки производительность все начинается где-то с 200 тысяч и падает до да ну может быть ну 110 тысяч 100 тысяч через час ну можно с этим бороться до можно использовать партийцы позиционирования то есть мы делим партизану скажем мы готовим часовые партийцы соответственно это нам позволяет вернуться в какой-то степени к тому уровню производительности который был до до этого до однопартийца через час-другой a partition индексы как бы индекс на и пространства у них разное соответственно это это работает достаточно хорошо и быстро но но все равно да вот у нас максимум что мы можем выжить хотя я опять же тут должен сказать что мы использовали не самую последнюю версию мария д.б. мы не tune ли общаюсь как бы стек железа и файлы систему dxf дефолтные настройки можно было бы там установить какие-то параметры логирования более правильные там новой а ну отойди и все такое да мне чего-то не ничего подобного не делали тут просто в данном случае для нас было важно получить просто некий некий уровень дальше посмотрели на пол игры snoopy сгрыз на самом деле я думаю что картинка будет одинаковая но я думаю что тот тут видимо разница как бы в уровне тюнинга да насколько мы правильно смогли настроить пол игры суммы марию убей но паскаль показал лучшее значение папа performance у да вот это по сгрыз сверху и снизу мария тебе до плоскости если мы начинаем с 240 тысяч и падаем где-то порядка до 180 тысяч мария тибета деградация происходит происходит быстрее и дальше infox baby да с индексом конечно все хорошо то есть начинается я я не знаю чем это связано поначалу может быть чуть чуть все медленно работает медленнее скажем так немедленно медленнее работает в итоге мы достигаем уровня там миллион 300 тысяч миллион триста пятьдесят тысяч метрик метры в секунду и дальше но по крайней мере в течение там нескольких часов день производительность сохраняется на том же уровне да это это на самом деле очень здорово если мы посмотрим там на мария де be in a position to что снизу вот это те картинка которую мы получили на этом железе очень приятно видеть то что нету деградации конечно это условие абсолютно тепличные да мы только пишем нету потребителей этой информации не понятно что произойдет если мы подключим допустим frontend если мы начнем запускать какую-то аналитику там через infox деби насколько это повлияет на производительность как бы вопрос открыт и но если мы просто сравним чистую скажем чистую скорость записи скам скажем но искал и искал то видно что сын фукс д.б. суть картинка картинка намного лучше ну и результат до мария тебе 160000 в секунду где то в среднем возможно но это даже может больше к пику дополз города 200000 опять же повторюсь что мы писали в одну таблицу в zabbix есть несколько исторических таблиц если если писать несколько я думаю что картинка чуть-чуть бы изменилась но принципиальной разницы мы бы не увидели но и infox д.б. infox тебе миллион миллион 300 тысяч секунду где-то до миллиона 400 тысяч секундах каких-то в каких-то пиках ну фактически отсюда можно понять да если мы доу если до этого у нас было производительность где-то порядка devin 100 тысяч то сейчас подключив базу данных базы данных не является battle найком как видно да то есть даже используя the moscow post грез и подключив индекс baby мы получили незаметны незаметную потерю в производительности буквально буквально пять процентов до на данный момент где-то порядка порядка 85 90 тысяч метрик или значений метрик в секунду но можно попытаться расшифровать что значит 90 тысяч метров в секунду но это достаточно для мониторинга на самом деле тут можно в кассах это измерять на лучше измерять наверное в метриках это достаточно для мониторинга 5 миллионов 400 тысяч метрик каждую минуту да то есть можно прошивать 55 миллионов четыреста метров в минуту если это будет каждые 10 секунд то ну тут по-разному опять же можно считать либо это будет 540000 метрик нет если там если нет все это надо делить на 6 немножко сложнее ладно тогда обещал объяснить здесь 10 тысяч постов 90 метрик на хвост каждые 10 секунд либо 1 секунду 1000 хостов 90 метрик на хвост то то есть в принципе показатели производить достаточно хорош но и на самом деле я абсолютно этим не удовлетворен ну какие выводы подключили историю в нашем случае история не стала узким местом соответственно не сильно повлияло на производительность хранение истории уменьшило скорость общую скорость обработки данных на 5 процентов существенно не повлияло на производительность данном случае и вообще что можно улучшить по вообще по результатам по результатам этого тестирования но безусловно может добавить компрессе она поможет в любом случае обязательно нужно думать о том как распараллелить внутреннюю обработку zabbix of внутреннюю обработку тех значений которой мы получаем внутри забег сервера фактически это и было целью вот вот этой работы которые мы сделали до определить его узкие места и что еще понятное дело что если мы выйдем на достаточно высокий уровень производительности самого забег сервера то следующим узким местом станет база данных да ну и очевидно что скажи мне внимай скилл не мария де беннет не плоскость наверное не могут тягаться с теми решениями которые на скажем так заточены под хранение time series дата да такие как infox ну там можно еще привести различные примеры но я не знаю положим там тут же up in this baby можно посмотреть там на графит и на подобные системы но но вот это как бы скорость и в том числе и например в случае нфл к тебе просто то развертывания на конечно же подкупает это это то на что мы уже обратили внимание проводим тестирование с различными сторонами их 40 это это это это функциональность появится абсолютно однозначно а что еще но биток да и ток очень простой то есть мы получили производительность на железе 90 тысяч метров в секунду при этом мы используем лишь 10 процентов процессор на во времени процессоров до те которые существуют на системе 2 4 ядра мы загружаем с трудом 3 ядра при такой производительности до что на самом деле позволяет нам надеяться при исправлении узких мест на пятикратная может быть на но не знаю десятикратное получится или нет на пятикратное десятикратное увеличение производительности самого забег сервера до если мы все сделаем правильно с архитектурной точки зрения ну и мы получили 20-процентный прирост производительность по ходу тестов добавив компрессии в какой-то момент да и в том числе и но это на 100 мегабит на 100 мегабит най сетки до и избавившись от некоторых каких-то лишних вызовов лишних системных вызовов в при processing менеджере ну задачи на 40 опять же немножко повторюсь это поддержка быстро хранилищ данных вот обязательно да то чем мы занимаемся и почему почему этого еще пока нет забег сином конечно хотелось бы выбрать то решение которое максимально надежно в продакшене с одной стороны с другой стороны которые действительно работает но так как как как , что то есть так как так как говорит вендор потому что очень часто бывает но мы заходим ну предположим на страницу на странице про металл сюда пытаемся понять пытаемся получить какие-то достоверные цифры по по производительностью к сожалению таких цифр нет поэтому приходится есть есть цифры скажем вот у нас там 800 тысяч восемьсот и секунду мы обрабатываем но не спецификации железа никаким образом было не то какие какой была тестового окружения вся эта информация отсутствует поэтому приходится нам самим смотреть на различные решения и пытаться выбрать то решение которое но с одной стороны нам нужно чтобы это решение было открытым и чтобы она была надежным дай чтобы она была быстро да вот вот это та работа которую мы сейчас занимаемся но также задачи на будущем я думаю что будет изучение влияния интерфейса опять же мы все протестировать достаточно тепличных условиях мы просто пишем ничего не читаем за исключением триггерных выражений конечно когда мы подключим интерфейсе когда интерфейсы zabbix api будет влиять на систему хранения данных на цифры цифры могут быть другими абсолютно другими ну и третья задача это конечно избавиться от узких мест те узкие места которые мы нашли и и найдем в рамках этой работы спасибо большое спасибо за внимание спасибо алексей вопрос пожалуйста и я может быть добавлю приходить пожалуйста через час на наш стенд мы разыгрываем поездку на zabbix конференцию в следующем году вопрос здравствуйте и спасибо за доклад вопрос по поводу вот при процессе кастинга метрик для насколько кастомизируют этот 100 визируется этот вариант можно ли туда свои какие то при процесса встраивать на самом деле сейчас есть определенный набор такой тех действий которые можем выполнять это работает следующим образом что мы ну мы готовим некий конвейер обработки первое действие второе третье четвертое на выходе мы получаем результат в планах есть использование каких-то языков так и более высокого уровня например но когда мы на ло можем есть если не хватает то функциональности которой забег синалоа могли бы дописывать свои способы обработки данных вот вопрос развод алексей спасибо за доклад савченко евгений такой вопрос influx baby будет только для данных или для фронта и всего остального тоже будет две базы использовать мире нету нет будет использоваться однозначным две базы однако конфигурационной абаза вторая история infox delay будет использовать для истории использоваться в том числе и фронтэнда мм конечно же бы понял это как замена история которая хранит свои скорее сейчас следующих хорошо добрый день спасибо за такой вопрос вы упомянули про предварительную обработку метрик а вот интересует плане раз функционал или может быть уже есть определение взаимосвязи имена между акимами и потом предварительная обработка на основании допустим значения каких-то айтемов я а то без него про здесь мы допустим получаем там пачку айтемов snmp балкан запросам и нам надо определить что допустим вот этот вот параметр мы хотим простовата дропнуть но дропнуть отбросить на основании значения там предыдущего тема котором получили поэтому разобраться я думаю что функциональность по игнорированию каких-то значение атомов она появится что касается какой-то такой более сложной логики возможно в будущем но важно знать конкретный us кейсу насколько действительно необходимо можно для нас вот это очень критичный а потому что приходится это потом как исторические данные приводить мир на временной шкале и как бы уже и логику дальнейшая обработан можем может быть можем подробней поговорить на стенде до чтобы узнать какая функциональность конкретном было бы здорово посева хорошо пожалуйста спасибо вам за доклад очень честный получился доклад первую очередь я к сожалению учили немножко опоздал на метод у меня вот немножко обратный вопрос по при processing данных в принципе мне показал что это немножко накладно тащить с трендовый данные на сервер чтобы капотом обрабатывать ведь намного проще работать с короткими данными с быстрыми с числами почему не делать это на стороне агента это первый вопрос и второй вопрос если уж вы позволяете разгребать логе то есть мы возьмем x услуг он хранит связанные данные например линию времени и какие-то данные почему не выгребать тогда целый кейс данных связанных по времени либо к какому-то другому параметру это было бы очень здорово ну на второй вопрос мне может быть сложно ответить нужно подумать действительно как лучше это реализовать что касается первый вопрос почему мы не делать при processing на стороне агента фактически до запись час это не поддерживает я думаю что но очевидно ответ заключается в том что в этом случае вся логика при процессинга должна поддерживаться в том числе и агентами да то есть если у нас есть что-то сложное опять же мы делаем допустим xml тут появляется зависимость от допустим там xml либо xml автом jason jason если мы добавим скриптовые языки поддержку ска там предположим лота то вот весь этот интерпретатор он должен выйти на стороне агентов не хотелось бы чтобы агенты превратились в монстру хотя и абсолютно согласен что во многих случаях это сделать эффективнее на стороне агентов скорее вообще-то это нужно вот вот эта вот вся логика при процессинга нужно тогда когда у нас есть много данных они имеют определенную структуру это джейсон xml и и и мы хотим избавиться от накладных расходов отправки 1 1 метрики за другой да то есть это такой самый распространённый из кейс но некоторые функциональность по pride предварительной обработки мне так уже существует на стороне zabbix агента то что касается лог-файлов когда мы порядок spice лог-файлов можем выбирать какие-то определенные куски но тот же сон вы и так используйте для передачи данных там повтори scary например это понятно а вот когда выгребать из сырых грязных данных cobie куча всего как бы никто нас не заставляет отправлять все эти сырые грязные данные то есть ну я незнаю у нас есть сырые грязные данные можем отправить какой то маленький кусочек этих данных уже нас но я тот нужно говорить о каких-то конкретных примерах я думаю хорошо виден добры представлю себе туфли компании mail.ru мы активно используем zabbix в ряде проектов и столкнулись с проблемами и у меня соответственно вопрос вопрос первый это то как работает запись с дисками и соответственно мы вскоре здесь время к сожалению мы не везде можно поставить raid10 ssd-дисков но при этом понимаем что нас там нет 90000 вы либо персик там на порядки меньше две-три тысячи и при этом у нас все опирается в диске соответственно чтобы вы порекомендовали сделать здесь парте цианирование однозначно хорошо чуть пространстве и вопрос номер два это нас интересует непрерывный мониторинг то есть он должен никогда не прерываться тем не менее машины так или иначе нужно обслуживать уводить в минтон обновить ядро что-то еще при этом мы теряем мониторинг весь чтобы вы порекомедовать в данном случае в случае каких-то hour дурных проблем да насколько понимаю дат из машины гасится этом rebooted сам является что пляжами и в этом случае обычно делалось от хавел билотти кластер с файловым на ну скажем на соседнюю на соседнюю ноду нет но тут есть разные моменты да если мы используем в мвр то это вообще как бы элементарно делается да если мы не используем веем во рту можно с помощью linux свечей стыка да а создать файл кластер и основная здесь проблема даже не хавел бьете самого за объективе а хавел был эти базы данных потому что базу данных это некий такой single point а файлов да все эти данные нужно хранить в двух местах если одна машина завелась то мы переключаемся на другой но в этом случае до либо либо некий такой fila верно валить на уровне dns а либо мы используем статический айпи адрес и переключаемся с одной ноги на другую и они уже решают по по каким-то hour by там какая из этих нот живая как как какая неживое но это стандартный подход zabbix какой-то мастер власть решения планируется сделать эту запись мы думаем думаем об этом да опять же с мастер мастер проблема мастер мастер хотелось бы сделать может быть больше на уровне про xiv в том числе еще чтобы zabbix агент случае недоступности прокси мог спокойно отправлять на другой прокси и и как гарантированно эти данные доставляют на zabbix сервер есть определенные технические сложности может быть я не буду вдаваться сейчас подробности но маг могли бы это обсудить они связаны и опять же с теми гарантиями которые предоставляют zabbix нам важно вот вот этот порядок обработки очень важен нам конечно сложно если вдруг предположим нас есть два прокси который мы не тот ну в случае redundancy мониторит одного и того же агента и в какой-то момент один из прокси недоступен становится доступен начинает отправлять старые данные вопрос что делать со старыми данных забросишь потом делать том что запись он еще монетаризм себе данном случае выхода из строя мы об этом просто не чего не знаю потому что олег тов нет тоже он и сам умер тоже вынужден стоять еще один запись чтобы мари творит 1 запись мнение от но уже для того чтобы мониторить zabbix наверное не стоит ставить 2 записи это слишком тяжеловесные решали бы пострадали поступить но можно поставить что-то более легковесная ну самый простейший вариант это какой-нибудь потом crontab для которые снаружи стоит они над не на том же сервере по низу низ на том же конечно да ну либо более простые system monitoring acme не туда которая опять же где-то отдельно стоит и проверяет работает ли зафиксирую или нет но это плохая идея проверять не зафиксировали суммы не садисты zabbix сервер как уходят остро и мы об этом не знаем и это проблема вероятны вы об этом подумаете да но мы ее не можем решить это не решаемая проблема в рамках одного зафиксирую ира поэтому и предложение мастер мастер и вот все станет понятно хорошо спасибо спасибо стоишь на меня спасибо за доклад вопрос такой очевидно уже что база данных это достаточно узкое место получается вот об эту мало часть доклада но и опыт показывает что именно his 3d того из этот медленно иногда очень медленно планируется ли какое-то решение на любимых многими здесь подключаемых решениях типа cliff house или тарантул а еще лучше чтобы можно было хранить ближний горизонт истории настраиваем и естественно выстроить базе данных возможно даже in memory дальний горизонт отбрасывать более медленной мог бы даже другой стороны другой engine есть какие-то такие мысли ну да что касается ближнего я не знаю сколько у меня время есть есть во время или нет так 3 минуту до что касается ближнего горизонта но внутри zabbix этим ближним горизонт является вот эти вот наши буфере которой в памятью то есть скажем триггеры работают с этим им неважно что снаружи практически до я пока не могу прокомментировать тарантул и клик house я слышал много всего хорошего увлекался слышал много всего хорошего tarantul и здесь нужно экспериментировать я думаю как только у нас появится первое первые 100 речь которая работает просто уварович дтп да ну как допустим случае сын фукс д.б. когда достаточно просто записывать там там через через резцы без помощи поста и получать данные то при прикрутить другие стороны жены которые работают по тому же принципу будет делом 10 mins спасибо но пожалуйста хорошо спасибо большое спасибо большое алексей мага интересный доклад"
}