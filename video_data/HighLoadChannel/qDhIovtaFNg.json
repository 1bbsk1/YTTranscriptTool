{
  "video_id": "qDhIovtaFNg",
  "channel": "HighLoadChannel",
  "title": "Percona XtraBackup экспертные возможности / Алексей Копытов (Percona)",
  "views": 1025,
  "duration": 3228,
  "published": "2017-04-25T08:02:58-07:00",
  "text": "знаете ли вы что такое компания персона не знаете вон из профессии персона это самые большие специалисты по мая скрыл который доросли до того что выпускают собственный форма и скрыл на сцене алексей копытов ведущий разработчик участвующий в разработке персона сервер и экстра backup встречайте сегодня тонкой подстройки бы каналов или сложных нестандартных сценариях резервного копирования а у меня был следует даны пока готовят слайды я бы хотел провести быстрый запрос мне очень интересно кто из присутствующих уже что-то знаете 3d cad если уже работали пожалуйста поднимите руку довольно много да ну в общем полезным наверное будет напомнить какие-то базовые вещи от этих очень не знаю так сказать про базовые вещи про архитектуру что такое x3 backup это свободная бесплатная утилита для резервного копирования горячего резервного копирования свободой сбил горячего значит без установки сервера и под мой скил здесь я понимаю три наиболее популярные ветки есть некие правдиво технологии я предпочитаю термин клетки то это не форки во-первых собственно со мной успел обычный называть который разрабатывается в oracle purple на сервер который назад и запер конная и морить который разрабатывается будете программ для каждой ветке мы поддерживаем в общем-то все актуальные версии которые поддерживаются соответствующими вендорами ямайский план сервер мы также поддерживаем все версии с 50 до 55 включительно и 1 есть 2 версии теперь устроенные тебе и тебе плагин смотрите без все несколько сложнее значит во первых моей тебе есть несколько нестандартными пешком данных достоин джинс там ария был тексте и скоро он будет кассандра и честно говоря не думаю что тут кто-то тестировал их строка с этим нестандартными крышками пока неизвестный автор этого тестирования я думаю что там была проблема и есть еще мелкие такой борьбы к версии 5253 и предстоящих 0 не потеряются корректно что очень то конечно не так трудно исправить просто до этого не доходит руки я думаю что на этой неделе только до этого доберусь и по крайней проблему с определения версии исправлен выкопает резервная копия данных и чем собственно блок но там cpr swing почему нельзя взять скопировать данные причина в том что база данных работают с файлами несколько сложнее чем большинство других программ напомню значит основные принципы работы на тебе по мере того как пользователи выполняют запросы и обновляют данные одной страницы и страницы тела обновляются в памяти они не записываются сразу на диск да это нужно для того чтобы если мы много раз обновляем одну и ту же страница чтобы каждый разу не нужно было записывать и по мере того как мы обновляем странице памяти мы делаем запись в специальном журнале который называется традиционный лук о фильме и фиксированные размеры и кольцевую структуру то есть по достижении конца этого файла начиная писать сначала иначе никак записывать записи вначале это в общем основной принцип работы в сердце b2 специфичны для ютюбе книжный материал и данное не записываются мгновенно на диска понравится в памяти соображений производительности но зачем нам нужен инфекционный лук традиционный лук на мужчин на тот случай когда в результате там программного или аппаратного сбоя потеряем все данные все страницы памяти и нам нужно будет восстановиться после этого сбоя что делали на debian а ночная читать записей трансакционного logo и применять их страницам памяти и отсюда очень понятно во первых почему нельзя просто взять скопировать файлы и файлы данных на диске находится не все данные часть от них памяти часть а никто индукционном логе которые перезаписывается и за культурным понятно в общем идеи для организации горячего backup от ада и на типе данных по мере того как мы копируем данные мы дублируем все записи в инфекционном воде в отдельный файл называется которые к-поп мы начинаем с последнего чекпоинта то есть с того момента до которого все страницы помяв памяти были заплачены на диск и померил эта модель копируем файлы дублируем все записи в отдельном файле понятно что потом на сказал нас есть копии файлов данных и копия записей в традиционном логе нам нужно их объединить да и фактически на этом этапе актар пока пчела и то же самое что делает и на тебе и на стадии восстановления после сбора абсолютно аналогично мы применяем записи дистанционного logo к страницу на английски это называется подготовка и backup а его можно делать в любой момент после создания выкопав мы настоятельно рекомендуем это делать сразу же после создания backup собой страны вы сэкономите время которое необходимо драгоценное время который хотим при установлении на этой страны ситуация и нужно скорее-скорее это время в другой стороны вы убережете себя от возможных сюрпризов что-то может пойти не так при восстановлении пока не будете знать что процедура подготовки в кабул вас уже прошла если вы делаете то сразу после создания на кого-то пока поддерживает инкрементальные backup когда копируются не все данные только измененные с некоторым момента времени а словно это на понятие сандра по мере того как мы записываем апдейт это инфекционный лоб в каждой странице память есть уже 1 поле которое соответствует позиции и смещению соответствующей записью традиционно блоги и elsen это монотонно возрастающая величина то есть когда вы доходите до конца файла и начинаем писать сначала lsn продолжает раздать фактически лосины время последнего обновления страницы не понятно что до того чтобы сделать игри ментальный backup нам нужно скопировать все страницы че его сын больше некоторого там заданного значения правилами и лосин прошлого пока то плюсы игры ментальными кого очевидно это малый размер данных на диске минус качает о том что для того чтоб найти обновлённой странице нам нужно просканировать весь набор данных я довольно серьезное ограничение в некоторых случаях некоторых инсталляциях мы работаем для решение над решением проблемы я буду говорить об этом до сих пор мы говорили о и no te pido пусть не транзакционных данных точнее традиционных данных но в сервисе чего не транзакционные данные такие как frm файлы файла где хранятся описание структуры таблиц где дел операции в москве не транзакционные то в общем того известное кричи архитектурной ограничение в москве а кроме того есть нет инфекционные тэшки данных таких как нас есть ярко и другие и даже если вы сами или ваше приложение не использует моей сам вас все равно есть такие таблицы потому что системная база москве а где хранится там информации о пользователях там права доступа и прочее она по умолчанию в моем и информация о мастерстве и в рипли кации тоже хранится в эти простые файлов и традиционных до них нет журнала правда 6 собираюсь исправить то можно будет задать сконфигурировать так что это информация хранится в таблицах в общем с нетрадиционными данных довольно много проблем с точки зрения рбк по есть одна большая проблема эти данные древние блокировки для того чтобы экспортировать то есть экран вынужден делает флажке был святой долг это эта команда блокирует сервер на запись на время копирование недр амбициозных данных мы поговорим об этом подробней о том в общем экстра пока состоит из двух исполнять основных исполняемых файлов это собственно утилита x3 backup который выполняет всю работу связаны с этими файлами копирование файлов на проверки контрольных контрольных сумм страницах и на этапе подготовки backup она выполняет применение логов candida файлам и есть обертка вокруг этой утилиты это скрип написанный на peerless тараски названием in экотекс который делает всю остальную работу запускает эффект рыбака для копирования файла в копировании логов и копируют все нетрадиционные данные для этого он выполняет масштабу цветок основные команды просто чтобы были понятны примеры дальнейшем создать резервную копию нужно вызвать иногда cortex обертка вокруг экстра бэкап и передайте директорию куда мы хотим положить backup для того чтобы подготовить backup нужно передать ключи к плану и восстановить бэкап опускает файлы в их первоначальное место нужно передать ключик к be back pack поддерживает поток вырежем то есть когда данные не сохраняются локальном диске а и реализуются в поток поток по умолчанию информатор несколько простых примеров чтобы показать зачем это нужно во первых мы можем компрессировать пока подам здесь я передаю по блоку тех друзей и сохраняю беде единого сейчас компрессировал его образа такая по на диске пока то можно собрать здесь использовал для того чтобы зашифровать потока опять и сохранить его в локальном шифрованный файл и образе естественно батуте можно передавать на другой хост с помощью из личный пример и вот в этом примере я еще на другом гостей динамический распаковывают поток в другую директорию на удаленном костях и естественно все это можно комбинировать разные методы вот эта команда она создает компенсированный шифрованный поток направляет его на такой пост этом сохранять эти образы на этом с базовыми функциями мы закончили переходим к более интересным вещам начнем с производительности точнее минимизации удар хеда часто довольно проблема с софтом для создания резервных копий заключается в том что он может эти программы могут иметь негативный эффект на другие программы которые работают на той же машине и экстриме копыта в общем то наиболее легковесное решение для создания бекапов москве тем менее 1 эту утилиту тоже потреблять ресурсы цикла процессора естественно дисковым пропускной способности того чтобы скопировать файлы если вы убиваете к сети ту и ту самую способности и для того чтобы как-то решить проблемы минимизировать ее тпк предлагает несколько опций одна из них имеет трудно переводимый название альфред и ну может привести как ограничение скорости копирования по сути это мой есть x 3 bk копирует данные блогами холодильника байт фактически аргумент опций отработал это сколько блоков . гигабайтов секунду вы хотите чтоб экстра backup копировал ну например значение 1 значит работа будет копировать там один блок секунду и потом за следующие секунды чтобы продолжить у этой опции есть одно серьезное ограничение конечно сценария не очень серьезная она реализована в x-tribe как то есть она имеет эффект только для и на типе данных а если у вас есть большие там не транзакционные данные большие мая сын таблицы хотя есть то можно использовать 4 можно создать поток да и использовать утилиту baby одну из ее функций является то что можно ограничить прохождение данными через paypal да заодно значение например если используя ключик минус 1 м до границы прохождение данных через paypal от скорости владения брать секунду и потом можно отправить этот поток либо опять же другой холст либо распаковать на камеру можно локальный пока вы тоже принялась другая проблема том для создании бэкапов заключается в том что копируя данные мы можем скрывать дисковый кэш да то есть операционной системы по умолчанию кэшировать все данные и соответственно разбили горящие данные в каше долго начала копирование то они вытесняются данные некоторыми которые копируют процессе backup а возможно эти же данные не могут не дают вам записываться обратно там уже ядро linux ведет себя не всегда корректно в тех случаях когда памяти малые нужно решить кого отправить слово просто мало данных иногда о том что для нас важно java может шестопал нас есть такой там толстый процесс матильде который съел всю память давайте-ка его пронесло потому что у нас тут благодарна копируется нужно силы кешировать да для того чтобы решить эту проблему x-tribe кант на linux используют средства представляем ядром linux мы можем не кнут о том что вот вот эти данные которые мы только что прочитали не записали их и нужно кешировать нам они больше не понадобятся и то данные в итоге не кешируется что классно воды функции то что это специально включает нет опции это просто работают автоматически сольёмся другая опция связанная с производительностью это параллельные копирование файлов довольно просто если вы указываете там как рука затекает количество потоков опции pearl после этого конечно парадокс начинает копировать файлы один файл в каждом потоки это обычно приводит к более эффективному использованию диска и выше всего начнут заметным на ssd для которого параллельна ботвы вот это не проблема но однако это может привести к более эффективным и сколько же обычных жестких дисков даже самых простых систем там нет никакой обычная диска поскольку у нас здесь больше параллельных забросов то планировщик ввода-вывода в linux может производить и не там оптимизации до переставлять эти запросы объединять смежных забросов и минимизировать количество операций при при зонирования головок на на жестком диске но лучше это потестировать какое именно значение сколько потоков лучше всего ваши году случай потому что зависит от многих параметров это пример работы abs и pearl ex 3 bk печатает рядом с каждой операции номер потока в котором производится операции на тот случай если что-то вдруг пойдет не так то было проще определить где и на один важный момент насчет doge для того чтобы как бы заметить эффекта даты опции нужно что-то было много файлов потому что если у вас например на день большой там обида the one to be может своих море потоков но работать будете копировать файл будет только один поток поэтому имени смысл создавать и надели таблицы с опции включенной опцией тебе файл protein всегда рекомендую турцию включает потому что очень негативные какие-то эффекты под включенной опции мы мы не знаем раньше были там какие-то проблемы с файловыми системами которые не могли эффективно обрабатывать огромное количество файлов под огромным не понимают десятки сотни тысяч а насколько я знаю все эти проблемы в современных lilac системах или решены и по крайней мере минимизированы функции берлин было такое ограничение в прошлой версии треков 16 там и работала в потоковом режиме и мы исправили то есть 20 я буду говорить об этом позже подробнее теперь давайте подробнее поговорим про блокировки сервера напомню для того чтобы скопировать не транзакционные данные экстра пока вынужден временно заблокировать сервер на запись с помощью команды flash требуется grid но и также внутри блокировкам задействует позицию в кино в блоге что именно делает waste your weblog а переустановили глобальную блокировку на запись после этого все операторы обновляющее данные или модифицирующих структуру таблиц блокируются потом он закрывает все открытые таблицы и того чтобы это сделать html стрелок вынужден подождать показывает шанса все текущие запроса и он блокировать все пока не томи проблема гули раз с этим о том что значит мы должны подождать завершении всех текущих запросов это значит вот если у вас есть какой-то там select на миллион строчек счастливы это большие таблицы он может заблокировать их trocal будет подождать что с этим делать не так на самом деле много вариантов можно выбивать длинные забросы то начала копирования или если ложно запускается какая-нибудь аналитика по расписанию то запускать пока потом уже самого списанию не самая хорошая идея уже развести и половине против номер два это опять же большие нетрадиционные donna если у вас есть большие магазин таблицы и что вообще не должно быть но есть например там осталась какая-то систему наследства или вы создали это временно мой сын таблицу положению налог на слой гигабайтов изобрели про него тем не менее у поедет пока не заблокирует сервер на на запись на на время копирование что с этим можно делать во первых есть опция пирсинг в этом случае яндекс использует утилиту версий при копировании нетрадиционных данных и происходит в два этапа сначала мы копируем основную часть до блокировки и внутри блокировки мы только копируем дельту если она вообще есть там лошадь 0 если данные и традиционные данные не модифицировались в процессе backup от отеля путина любой совместно блокировкой пойдет практически мгновенной то здесь мы используем той свойства verseq что он имеет эффективно вычислять дельта и передавать только только разницу до но очевидно эта опция не работает потоковом режиме потому что после того как мы отправили данные в поток достать оттуда невозможно версию ничем не нести вычислять пример работал в версии здесь я об этом сообщает что он сначала выполнять подготовительную корки с помощью arsenka до блокировки потом он выполняет блокировку даст приду подготовительной копья в моем примере значит составила 11 секунд потом он абонент блокировку и сама блокировка была на грани этом меньше секунды потому что у меня не было модификаций нет индукционных данных процессе показа второе решение этой проблемы решение проблемы с блокировками это не производить блокировки вообще да то есть если вы передаете ключик налог то яндекс не выполняет не выполнять команду flashtools и 30 это возможно при некоторых условиях а именно вам нужно убедиться что во время создания backup они выполняются модификации структуры таблиц не только ты был и не выполняются обновление нетрадиционных дана прямая к таблице то есть текст рыбы как делать блокировку для того чтобы гарантировать гарантировать целостность нетрадиционных данных но вы можете эту ответственность за себя сказать что нет обновлений поэтому не нужно делать не к блокировке и 6 ловится прекрасно еще одна функция косвенно связана с производительностью виктор backup это сбор статистики идея следующий раз у нас есть оффлайн копия данных почему бы не использовать ее для того чтобы прокормить эти данные проанализировать не волнуюсь о том что эти то этот анализ по решается там запросом на боевом сервере возвращаясь энергии внутри стены ингибировать все данные хранятся в индексной страницы который имеет размер 16 килобайт а вот по умолчанию и когда у нас данные вставляются последовательно то есть входной поток данных упорядочен то странице заполняются равномерно да и рядили поддерживает коэффициент заполнения на уровне примерно 15 16 . 94 процента на тот случай если вдруг мы решим обновить какую-то запись на странице и немного увеличить ее размеры чтобы это можно было сделать без перевозки страница но если ставку на случайные входной поток данных не упорядочим мы получаем days плиты вставляем запись на уже заполненную страницу получали 2 страницы томска это ценам заполнения 916 их или примерно 56 процентов результате вместо равномерного заполнения страниц мы получаем что-то вроде этого то есть много страниц которые заполнены не полностью эта проблема известна как дефрагментация хотя опять же она не специфично для и надели в той или иной мере она применимы к любым базам данных это фундаментальное свойство индексный структуру данных что с этим делать одну во первых это собственно вывод опции стас которая показывает статистику в данном случае можно видеть что приставку слова первичного ключа там где хранятся данные средний коэффициент заполнения стараемся вопроса что довольно мало чтобы оптимизировать фрагментированные индексы их нужно перестроить а если фрагментирован первичный ключ что нужно пристроить всю таблицу потому что данные хранятся в первичного ключа если примете раваны вторичные индексы то их можно перестроить гораздо быстрее просто где-то с помощью / индекс try it индекс в этом случае они будут рисоваться с помощью fast иных kreation то есть мертвым они вставкой что гораздо быстрее теперь поговорим про частичное копирование и восстановление таблиц иногда нужно из полного бекапа восстановить какие-то отдельные таблицы они не все данные поставить самодельный мая сент облетит очень просто можно просто скопировать файлы сам из-под ритуале полный backup victory данный сервер и на этом все с объективными теперь все гораздо сложнее нужно использовать опцию экспорт в excel p-cad и научного импортировать сервер нужно использовать функцию им пруд импорт в purple на сервер в обычном я сказал ситуации нет и опять же для того чтобы установить отдельный тег таблицы они должны лежать в отдельных файлах потому что невозможно если они лежат большом систему спейси их невозможно оттуда вытащить поэтому опять же не сбив употребил должна быть разрешена почему просто не скопировать файлы обиде это почему нельзя скопировать отдельный файл импортировать их причина заключается в метаданных как вы знаете и на тебе поддерживать свой собственный словарь данных который содержит там видите секатор и таблиц и индексов показательные корневые структуры индексной страницы и так далее храниться до этого в основном системном преуспеете то есть в обиде этого сами файлы данных также содержит уже служебные записи заголовком страницы опять же спереди там lsn индикатор транзакции индекс от и прочее и если индия нарушились что идентификатор и словаря данных и в самом по или данных не соответствует она правомерно жалуются на покореженные данные и завершается марину с ошибкой поэтому опция экспорта x3 backup экспортирует метаданные из файлов данных бэкапе потом purple на сервер использует эти метаданные для того чтобы привести в соответствие словарь данных и файлы данных это пример работы значит я использовал ключик export firm этом сообщает что экспортируют это данные в файле файлик с суффиксом next собственно сами метаданные которую экспортирую этот идентификатор индексов и указатель на корневые индексной страницы это той информации которая необходима так он server data correct импортирует этот файл далее значит функция ты был импульс только можно восстанавливать либо на том же самом хвосте либо на другой на такой машине а если вы снова этим другой машине сначала создать таблицу с таким такой же структурой как оригинальная если вы устанавливаете в том же посте то сначала нужно выключить внешняя проверка внешних ключей если есть внешние ключи которые лаются на эту таблицу а после этого нужно выполнить операцию диска то есть общительный тебе что мы собираемся заменить эту таблицу на другую после этого вы можете скопировать или файл включить ум функцию ты импорт в purple на сервер овцы называется едем партии был франек tracker и после этого выполнить итерацию не просто таблицы с помощью не portrait of space потом уже включить обратно проверку внешних ключей что делает в обычном моей спел в котором этой функции нет обычно моя спел можно восстановить таблицу только на том же самом кастетов не на той же с на том же самом intense москве то есть там где все идентификаторы точно такие же как и в оригинальной таблицы более того не допускается после команды просмотра восстановления и выпускаются любые операции которые изменяют идентификаторы там индексов или таблицы и так далее случаю процедурного непростая и даже не нужно использовать экспорт можно сделать сказка первой леди и сделать импорт но это очень конечно случае частичное копирование до этого значит мы говорили про от раньше когда я исполнила backup а нужно вытащить отдельной таблице 1 иногда даже скопировать в как хочется не не все данные только какие-то выбранные таблицы опять же нет отрубей был процедуру восстановления точно такая же как и в случае восстановления отдельных таблицах полного бака по те же ограничения майский л я опять же если включена опция и protein bar от пансионата этих ограничений нет как выбрать какие таблицы должны попасть в частичные тыкал можно использовать функцию и передать есть список баз данных и опционально после каждого имени бастан после каждой базы можно после . казатине таблицы например ему из пробился идут он тот он будет скопирует все таблицы в базе на поиски только танцы ордер освободился если таблиц много то можно положить всех файл в формате имя базы . имя таблицы и передать путь к этому файлу опцию тейлз файл и наконец можно использовать опцию и тут которая позволяет выбирать таблицы на основе регулярных выражений не природу в изображении скопирует все таблицы и которые именно которые начинают с report из баз данных перебрать вам и дикостью подготовка частично только получим ничем не отличается точки зрения пользователя можно использовать опцию экспорт из мы собираемся импортировать эти данные на другом кости в этом случае здесь на разница в выводе карабеков здесь сообщает что некоторые таблице не были найдены напомню что мы их просто не скопировали поэтому он удаляет их из словаря данных до восстановление системы backup опять же с нее на теперь таблице мы все просто можно просто скопировать файлы в случае обычного москве ларина теперь со всеми ограничения при которые уже говорил можно сделать discounts for tables baxter дебит ускакал на сервере можно использовать экспорт и тогда уже импортировать без всяких ограничений интересный частные случаи частичных бэкапов заключается в копировании даже не отдельных таблиц и отдельных партиций сегментируем их таблицах к нам клиент пришел с таким вопросом на что не было таблицы там сегментированное по дате и старый видит партиции со старыми данными хотелось удалять перед удалением сделать резервные копии на тот случай если они потом понадобятся и и восстановиться и вопрос от клиента был можно ли использовать 2 карты того чтобы скопировать отдельные партициями мере до можно дело в том что с точки зрения сторож женщина партийцы они общее реализован спел на уровень выше скорость поэтому с точки зрения стороны на позиции это просто особые таблицы со смешными именами вот например имя соответствующие одной из партии за из предыдущего слайда имеет имя файла это reports решетка и решил 3-полосная партиции то есть нам нужно запомнить этой ими того чтобы потом скопировать разъехалась скопировать эту партицию мы выполняем функцию частичного da capo только в качестве имени таблицы передаем не именно настоящее имя таблицы в специально ровно или партиции опция экспорт ничем не отличается значит экстра пикап создает файл метаданных и восстановление деле partition она несколько более хитрая потому что мать пела не позволяет взять существующую таблицу и восстановить ее как партицию еще одну портится кожа сегментированной таблица это таблицу можно стоит только как отдельную таблицу значит нужно создать сначала таблицу такой структурой как оригинальная сегментированная таблица и после этого выполни стандартов скоро импорта мы копируем файлы соответствующе партиции только уже под новыми именами который соответствует имени отдельные таблицы которые мы создали включаем опцию им траволтой блин город и импортируем ну в общем может быть членом но стоит вернуть что-то разговора подходит для майсен таблиц только без все еще проще да без диска от импорта space потенциально горы еще одна туда приводимая функция понятно да иногда нужно восстановиться то определенного момента во времени скажем если у нас есть ежедневные бэкапы то мы можем остановиться только на какое-то состояние соответствующее тому моменту когда был сделан до гола а если у нас там какой-то плохой запрос удалил все данные там час назад мы не можем возвратиться на класса на час на два часа напомню что кулинарный блог мой спел значит это не журнал который сохраняет все обновление данных там данные могут быть праздным формате просить простейшем случае то есть пигмент формат это когда и на ноги просто сохраняется текста sql запросы которые модифицировал даны то есть маскел серы в этом случае ну фактически ведёт двойную бухгалтерию все-все обновлениями на типе таблицах записываться в транзакционный лоб и все обновления для всех storage engine и только для не деби записываются бинарный log in or магии есть координаты которой состоит состоит из двух значений и другими файлами много и смещение соответствует той причем здесь актер пикап при том что он печатает координаты в бинарном логе соответствующие моменту создании бэкапов при завершении бэкапы он печатает координаты последнего апдейта вина на блоге который попал бы к информация также сохраняется в файле с именем их тропе camping info в самом территории пикапа вот так она выглядит тут она мы понятно мы можем использовать мы можем должно установиться до определенного момента времени мы можем восстановить сначала из последнего быкова которое предшествует этом a memory этому моменту времени после чего использовать думаешь глубин блог для того чтобы нагадить ялты из берлога до нужного момента времени все события примерно блоге имеют темп поэтому майкл белок переслать когда становиться клонирование узлов в репликации значит если у вас есть репликация вы можете использовать свои при создании бэкапов для того чтобы разгрузить мастер пар сбор в этом случае абсолютно аналогично и с одной маленькой деталью если вы делаете backup слева вы можете придать опцию слои лимпа которая записывает позицию чтения бинарного logo на мастере для текущего слоя его который мы покажем и страница файле карадага been looking to виде опечаткой хронограф с lightning на самом деле виде готовы команд очень внимательно выполните команду на том стриме мы получим абсолютно идентичны если картинка которая иллюстрирует один из моих любимых примеров начнет of three простая команда мы получаем по своей вода используем поток будут от того чтобы передать данным на другой хост подготавливаем выпуск другом костей и выполняем через мастер этого файла очень простые команды очень и критовать или на аналогичный механизм используется только на этой вилле plaster при добавлении нового слова поэта то есть мы используем используется к рыбакам потоком режиме того чтобы передать все данные служат информацию набор почему вы получаете поводу теперь прогулок функции producer погонь эту версию вы будете полгода назад новой функции болотные ментальные богаты встроенными параллельной компрессии новый формат потоков extremely утилита для управления этими потоками одноименная и копирование установления invisible пол в чем проблема с элементалями buy потоками бэкон инвестор backup 16 индекс использовал внешне утилиту для генерации для от потоков с другой страны в энгри ментальном режиме нам нужно использовать утилиту restore backup на сканирование файлов данных и надели и вычисления дай инкрементальные деле поэтому сила режимы были несовместимы вести только 20 учили так строка сама умеет генерировать потоки формате лютор или в новом формате и cry 3 и теперь можно делать инкрементальные потоковые бэкапы встроенной компрессе с дисковым местом часто проблемы даже ваших самых больших клиентов там что-то мне все время растут и тяжело масштабировать железо на соответствие с этим ростом поэтому люди часто ищут там нет возможности для минимизации места которые выкопаны это диски и компрессии этого что-то первое что приходит на ум нам до этого как можно компенсировать внешнего утилитами как я уже показывал в примере но этот метод имеет ряд ограничений в чем проблема во первых большинство утилит декомпрессии популярных утилит для bento они однопоточный то что они используют максимум одно ядро семью что общем довольно странно в наше время этот мобильный телефон и даже многоядерные процессоры есть на кого точно интернате вы или тогда точно приятный жизнь она делает параллельно компрессию декомпрессии все равно однопоточный и самый главный недостаток это то что если у нас есть так jeezy да мы должны установить одну таблицу если мы хотим вас не только таблицу нам нужно распаковать весь пока что в общем неприемлемо для в некоторых случаях для того чтобы решить эту проблему мы сделаем строй реализовали встроенную компрессию stb card теперь включи компресс и алгоритм который используется при компрессии так велел-де почему именно ум потому что эта политика была создана для специально для обработки больших объемов данных они нам на сайте у них есть некая beach park они горят что-то не на одном достигают на одометре достигает 300 8 гигабайт в секунду и кроме того библиотека сочетая скорость неплохим сжатием возможного им болеет более популярные алгоритмы и друзей или два позже и главное что каждый файл фонд при использовании стройной компрессии сжимаете свой отдельный архив не нужно контролировать весь того чтобы оставить только одну таблицу далее кроме того встроенный компрессия на никогда точная как компрессия также рекомпрессия можно использовать месяц параллелен копирования причем этих аукционе абсолютно независимы можно независимо назначать сколько потоков мы хотим назначить на чтение файлов и сколько потоков соответственно сколько ядерными максимум и готовы выделить для декомпрессии но примерно в этой команде дается 4 потока для чтения файлов и компенсироваться они будут 8 потоках тебе обратил рассказать про новый формат и из быстрее но прежде всего зачем вообще мы изобретать велосипед и способствуем формат в чем что не так стороны пролива старым заключается в том что он на самом деле не предназначен для передачи потоковых данных это архиватор все файлы там хранятся целиком и приказом год ребят перед каждым файлом этот заголовок указываются атрибуты файлов среди прочего размер файла что означает перед тем как мы продолжим перед тем как отправить файл поток мы должны знать заранее размер файла что в случае с динамически компрессии с криминальными богатом невозможно мы не знаем заранее единстве вариантов и случаев сохранить файл сначала локально а потом уже проходил поток что в общем теряет всякий смысл до этого мы реализовали свой формат быстрее им все данные все файлы взяли сохранить файл целиком можно сохранить его по кусочкам поэтому указан размер только для соответсвующего очень кусочка можно управлять поток динамические данные и кроме того можно чередовать кусочки от разных поэтому можно направить поток много файлов параллельно естественно нужно извлекать данные из потоков extreme поэтому есть утилита она имеет там подобный интерфейс то есть того чтобы извлечь данные со стандартным хватом и придает минус x если нам нужно еще к за территория отличного текущие то вы -7 большой также авторе но этот пример нам здесь стою параллели сжатый backup несколько потоков и все это передаем динамически на другой пост с помощью extreme старого то всё было бы невозможно последняя новая функция x 320 восстановление на пол и на типе управляет баффер полном виде белого списка странице более того на приведение этого списка прикладные состоянии требуется очень много времени адекватные нагрузки поэтому после сбоя или просто восстановления из бэкапа иногда требуется многие часы иногда ритме для того чтобы баттер пришел горячие состоянии функции строку на сервере которые есть это сохранение состояния батраков и причем скорее не сама же пулами естественно именно состояние идентификатор страниц и этого достаточно для того чтобы прочитать на странице из файлов данных при при старте при старте ну и маленькие на полезные функции котла волю мы автоматически копируем этот план состоянии поэтому после восстановления из бэкапа баттер получается горячего строение течение там минут они часов и дней убедитесь что вы включили соответствующую опцию purple на серверы и напоследок функция которая настоящий момент разрабатываются этих можно ожидать в будущих релизах вектор b к а на верх это быстро инкрементальные мы копы напомню проблемы с их летальными пикапами это то что мы должны просканировать все весь набор данных даже только на того чтобы скопировать одну страницу если была изменена только на страницах вообще ничего не было изменено по сканированным сразу нужно обнаружить не проблема настолько серьезное что мы работаем сразу за двумя решениями параллельно первое но оба решения до требует некие кооперации со стороны zero а первое это отслеживать модификацию страницы на стороне сервера второе это архивировать и транзакционные логина сели они в процессе быков как это делается сейчас в чем заключается следование модификации если эта функция включена перво на сервер тут появилась появляется еще один еще один поток который отслеживает все займись транзакционные всегда тилль традиционный вот и записывает бедно при измененных страниц поддельные лог-файлы после этого или backup для того чтобы сделать инкрементальный backup просто читает эти этикет map и дамиса сканирование все всего набора данных может принять папой противники страницы были изменены с некоторого момента времени архивирование логов нутуз довольно просто поскольку традиционный лук имеет кольцевую структуру и перезаписывает можно можно дублировать эти записи в отдельном файле соответственно мы получим тот огромный и лог-файл которая пока потому сможет просто применить то зала момента времени можно и криминальный богата вот так организовывать и наконец компактные бекапы людей в том что не все страницы в файлы данных тебе одинаково полезны там например есть вторичные индексы которые могут занимать много места если у вас много таких индексов и точки зрения пользователя с точки зрения данных они не имеют никакой ценности потому что их можно там перестроить вторичный индекс работы счет первичного ключа кроме того из неиспользованной странице если у вас была благодарных а потом их удаления и на тебе замечательно видеть как неиспользованные но они остаются она не возвращает эти страницы файловую систему и естественно идеи звучит в том что должно водитель компактный backup мы можем некоторые страницы данных пропускать при копировании но мы так сложно сохранять 10 кадров всех рабочих страниц в отдельном поли чтобы а то можно было корректно восстановиться ну плюсы компонентов опять же что они занимают меньше места на диске иногда гораздо меньше если у вас много неиспользованных страниц или много вторичных индексов минус очевиден да нам нужно произвести гораздо больше работы на этапе при подготовке бэкап и поэтому и play along занимает больше времени и последнее новые функции которым мы сейчас работаем это встроенные шифрования причины для реализации встроенного шифрования такие же как для реализации строй декомпрессии но блага поточная и для того чтобы восстановить одну таблицу можно нужно расшифровывать весь пока вы тоже мы поговорили про архитектуры extreme игра про базовые возможности такие как полные временные криминальные бэкапы потока вырежем поговорили про связан с производительностью life ровной оптимизация кэша параллельное копирование данных обсудили блокировки проблемы с ней связаны и методы решения этих проблем опрыскав статистику и часто чистишь некоторыми восстановления points америка вами планирование узлов репликации и новые функции достигать 20 и те который находится в настоящий момент в разработке полезные ссылки мы имеем неплохую коммент акцию по эксперт аккаунт который живет на нашем сайте скачать кинари для обратных по for можно соответсвующем разделе на сайте бекон и нужно обсудить любые программы драконы в списке рассылки на google groups у нас также версий канал например зайцы преклонном многие сотрудники про клоны там сидят я тоже поэтому можно заходить и там может над вопросами код можно получить на . и там же можно зарепортить бани спасибо за внимание здравствуй 100 возник вопрос по поводу значит использовать о компрессии новой версии костра пока либо мы теперь можем узнавать раньше мы передавали архиватор у нac сооружали передавали будешь там да и он распаковывал даже как мы поступать в этом случае удачного таро я просто пони так не помню если функция которые распаковывает солнце не такое у него нет нужно использовать внешние утилиту для распаковки мой информатор утилита китайской распаковывать файлы сканированные я стал мощная еще парочку быстрых вопросов подскажите по поводу значит и реализации того чтоб не использовался файловой системы я x конкретно есть ли что-нибудь такое для операционном семейства я не знаю представляет литре бензина и если он присутствует карта то мы будем использовать еще момент я сейчас организации плане перевести таком на бошке устройства то есть когда мы хранили не в папках на системе устройства делать как робокоп работает . устройство насколько похожи на хороший вопрос я думаю что он не будет работать с большим устройствами как они продолжал это не просил ясной и подскажите маленький такой еще момент вот к примеру у меня есть некоторые патчи для горком и я в принципе быть и против и мне поделиться вот куда вам можно отправлять патчи том числе пишут для по зато польше нет то можно их отправлять вами делиться опытом их рассмотрению могли включить в принципе поставку драконы такая проблема и вот кстати патч который решает я думаю что после этого держали видео найдет понять спасибо большое все вопрос 8 рассказывать про репликации там впоследствии чинить мастер традиционный подход к на момент я занимаюсь переводом база данных словей на экстренное классно и вот там река ция карьера не стоит несколько но до нескольких словах вам интересно и входили класс тут лучше используйте стандартную мать кого импликацию для организации х и выберите и вы страдаете от проблем огромные формате мастер реализован синхронная репликация автоматическое до 8 у вас тоже есть спорте пока нет вы еще не достигли это раком на дальше вниз компенсирования с я до него должно протестировать на и наверняка придется 4 поправить район 56 и своей реализации сохранение состояния потапова которые отлично реализация идей 1-дан было резался другая поэтому можно будет поправить чем просто выдан программы не начинали"
}