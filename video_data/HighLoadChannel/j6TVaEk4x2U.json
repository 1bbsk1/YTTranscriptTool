{
  "video_id": "j6TVaEk4x2U",
  "channel": "HighLoadChannel",
  "title": "Руководство по выживанию с MongoDB / Сергей Загурский (Joom)",
  "views": 15231,
  "duration": 2857,
  "published": "2019-05-15T05:25:52-07:00",
  "text": "всем привет прежде чем буду рассказывать манга диме расскажу о себе в трех словах меня зовут сергей загурский я работаю в компании джун занимаюсь инфраструктурой вообще и манга деве в частности профессиональный набивать иль шишек собственный дом граблями все все как полагается прежде чем мы перейдем к материалу докладом я немножко поясню форму в которую я материал структурировал будем использовать метафору стартапа все стартапы все хорошие стартапы занимаются чем тем чтобы либо быстро умереть либо жить хорошо и потом от масштабироваться вот мы будем сейчас моделировать такой стартап который сначала про фичи а потом pro performance стартап который в качестве стратегии управления техническим долгом использовать стратегию под названием накопления будем двигаться по мере ну плюс минус по мере того как эти проблемы будут возникать в хронологическом порядке хотя конечно экспириенс может быть различным итак наш старт-ап запускается фичи и тут внезапно пользователи к нам приходят и на наш маленький маленький манга тебе сервачок внезапно сваливается нагрузка о которых мы даже не мечтали ну мышь в облаке мышь стартап мы естественно немножко там в самые простые вещи которые можно сделать где-то там посмотрели запросы а я тут у нас вся коллекция вычитывается для каждого пользователя а тут значит тут мы можем индексы построить там можем немножко железо добавить ну где-то чуть запиши ровать все живем дальше в тот момент когда мы можем решать вопросы вот такими вот средствами это прекрасно надо их такими средствами решать по сути у дальнейший путь успешного старта по это медленно и мучительно и оттягивание момента когда нужно горизонтально от масштабироваться и я попытаюсь достичь советы как пережить в этот период когда добраться до масштабирования и на какие грабли ним не наступить при собственно масштабирование одна из проблем с которой можно столкнуться это проблема с медленной записью и например вот вы столкнулись об совету с предыдущего слайда уже не помогают что же нам делать режим гарантии durability в мозгу тебе по умолчанию это подтверждение большинством всем ли понятно что это такое 3 в 3 словах мы пришли на праймари реплику сказали пиши праймари реплика записала после этого с неё прочитали secondary реплики и сказали праймари мы записали и в этот момент и в тот момент когда большинство secondary реплик это сделали запрос считается выполненным и управление возвращается в driver ну соответственно в приложении такие гарантии позволяют быть уверенными что когда управление вернулся приложением данные дюрер был никуда не денутся даже если манга деби ляжет ну кроме совсем уж там страшных катастроф первым к счастью манга деби это такая база данных который позволяет гарантии your abilities уменьшать на каждый запрос отдельный то есть мы можем для каких-то важных запросов оставить гарантий durability который на который максимально дефолтной гарантии для некоторых запросов я сейчас поясню как о каком классе запросов речи можем гарантии уменьшить и о чем о каких гарантиях речь первый слой гарантий который мы можем снять мы можем отключить подтверждение записи большинством реплик это нам сэкономит latency но никак не добавит трупу то но иногда платности это то что нужно особенно если у нас там наш кластер уже немножечко перегружен и сок одной реплики работают не настолько быстро насколько хотелось бы если мы записи пишем с такими гарантиями то в момент когда мы получили в управление в приложении мы уже не знаем будет ли эта запись жива после какой-то после какой-то аварии но в целом обычно оно все таки будет жива дальше следующее гарантии которые уже не про латынские ну и право танцы тоже но в основном про трубу это отключение подтверждение записи в журнал а я тут поясним запись урн all конечно же делается в любом случае журнал есть журнал это 1 один из основополагающих механизмов если мы отключаем подтверждение записи в журнал то мы просто не делаем две вещи первое это не делаем и в sing на журнале ну и соответственно не ждем к этому закончиться вот тем самым мы можем довольно некисло сэкономить ресурсов дисковой системы и получить кратный прирост трубу то просто вот поменяв durability гарантии ну и совсем совсем в самую пору самые упоротые гарантии durability это отключение любых подтверждений мы получим только подтверждение о том что наш запрос дошел до праймари это нам сэкономить latency естественно никак не сэкономит трупу плюс мы получим разные штуки вроде на самом деле может быть запись то и не прошла потому что был конфликт с каким-нибудь уникальным ключом ну в общем это уже так для полноты картины каким операций вообще-то применим а вот при длительно к нашему сетапу в компании joom у нас помимо того что есть нагрузка которую от пользователей там конечно никаких послабление durability есть нагрузка которая который можно описать как фоновая batch нагрузка когда очень там обновляем тени будьте знаю рейтинге пересчитываем или собираем данные для аналитики и вот эти операции фоновые они могут занимать часами они за дизайне на таким образом что если где-то они оступились где-то на там backend крошился еще что-то произошло что они не потеряют много свои работы то есть они возобновятся с какой-то точки в недавнем прошлом и вот для них в принципе такие durability гарантии могут очень неплохо помочь тем более что фсин журнал ну как и в принципе любые операции они в конечном итоге будут аффекте latency и на чтение тоже следующий момент с которым мы можем столкнуться это недостаточность недостаточно пропускная способность по чтению и тут мы можем вспомнить про то что у нас на самом деле не только про его реплики в кластере есть еще есть secondary а из них оказывается считать можно давайте из них читать можно из них читать но есть нюансы во-первых из-за конторе реплик будут приходить немножечко немножечко протухшей данные ну сам пол секунды секунда может быть это og в большом количестве случаев это но есть еще второй момент дело в том что secondary реплика она немножко поведение отличается от про мире реплики на secondary реплики есть процесс применения плохо который которого нет на праймари и вот этот процесс он не то чтобы прямо за дизайн под какую-то низкую latency разработчики манга деби не очень на этом заморачивались и при некоторых условиях процесс применения об логос праймари на secondary может давать спайки там до 10 секунд мы наблюдали что уже user experience шел в мусорное ведро вот на не сортированных кластеров это обычно не сильно заметно скажем так меньше заметна споить все равно есть почему сортированные страдают потому что особенно сильно влияет на применение блога удаления а удаление это часть работы балансировщика и балансировщик смачно со вкусом удаляет документы десятками тысяч за короткий промежуток времени еще один момент о котором надо задуматься в какой то момент времени это ограничение по количеству соединений на instance of manga по умолчанию никаких ограничений нет можно делать можно подключаться до тех пор пока разрешает операционную систему однако есть нюансы нюансы заключается в том что чем больше параллельных запросов конкурентных тем медленнее они выполняются эффект этот естественный нелинейный поэтому дабы не допустить в возможности ухудшение качества обслуживания ну если к нам прилетел какой-то своих запросов лучше мы обслужим там 80 процентов нормально чем не обслуживаем сто процентов поэтому количество соединений надо ограничить непосредственно манга тебе но есть баги которые из-за которых могут быть неприятности из-за этого в частности этот connection pool который на стороне mongo db он общей как для пользовательских подключений так и для служебных подключений внутри кластерных если приложение съела все соединения из этого пула то кластер может в кластере может нарушиться целостность с этим ну я думаю излишне пояснять как мы об этом узнали буквально там очень была очень интересная история буквально было следующее мы собирались перестроить яндекс так как нам нужно было снять индекса уникальность то эта процедура делалось в несколько этапов но в мозгу тебе нельзя построить рядом с индексом такой же но без уникальности поэтому мы строили похоже индекс без уникальности потом хотели удалить индекс уникальностью потом построить индекс без уникальности вместо удаленного и удалить временный так вот когда мы строили временный индекс начали удалять этот индекс еще достраивался на стек андре начали удалять яндекс уникальный индекс и в этот момент secondary манга тебе сказала что нет у меня все тут блокировка тут какие-то метаданные зал учились короче ну вот моя что становился становились в мажоре ти записи все остановились остановились как естественно не висели все в connection пули и ждали пока им подтвердят что запись прошла все чтения на secondary остановились потому что был захвачен глобальный мог ну и кластер в таком интересном состоянии еще и потерял связанность потерял связанность но связанность параде чески было поэтому иногда когда две реплики друг с другом у соединялись я не такие ой а у нас же тут праймари то нету давайте-ка выборы проведем давайте и пытались провести в своем состоянии выборы которые естественно провести не смогли потому что ли глобальная блокировка захвачен вот лирическое отступление в общем с соединением за количеством соединений надо следить есть такая достаточно широко известная особенность mongo db но настолько часто на нее наступают что я решил все таки panic коротенечко пройтись это если если в manga деби отправить запрос который пойдет по индексу то запрос можете все документы которые удовлетворяют условию причем ну совершенно неожиданных случаев связано это с тем что при запросе по индексу когда мы идем по началу индекса тот документ который в конце перемещается в начало уже так сказать за те документы которые мы прошли вот и это связано исключительно с mouth обильностью индекса если применять нему табельный индекс ну то есть яндекс по нему табельным полям таких сложностей не будет но есть еще один нюанс манга тебе имеет свои виды на на то какие индексы я использовать поэтому с помощью hand можно посоветовать настойчиво посоветовать mongo db использовать конкретный яндекс и счастью hands именно в обязательном порядке заставляет использовать яндекс который там указан наш старт-ап развивается данных становится много что-то не хочется дисков добавлять уже добавляли три раза за последний месяц давайте посмотрим чего у нас там в данных хранится смотрим на коллекции как нам понять где у нас где мы можем что-то отжать по бантиком можем смотреть на две вещи можно смотреть на размер конкретных документов для того чтобы там поиграться с его длиной или можем посмотреть на средний размер документа в коллекции как мы можем размер документа повлиять есть не специфичные для данных советы во-первых не знаю все новерна знают что в каждом документе копируются все названия полей поэтому если документах используются длинное название поля то это название поле прибавлять прибавьте размер этого название к размеру каждого документа если у вас коллекция с огромным количеством маленьких документов ну там на несколько полей то постараемся назвать эти поля каким-нибудь коротенечко им названием типа а или б у две буквы максимум на диске это можно компенсировать сжатия на в памяти в каше конечно же никаким затем это не компенсируется все хранится как есть иногда это уже дата специфик штука иногда можно вынести некоторые поля за пределы коллекции в название коллекции например таким полем может быть язык если мы храним например здесь у нас есть коллекция с переводами у нас есть переводы на русский английский французский и у нас соответственно есть поле что что за язык хранится в документе можем на самом деле это поле вывести значение толпой вынести у нас в название коллекции и там сэкономим и на индексах и на документах в общем сплошная экономия к сожалению не всегда такое можно провернуть потому что иногда есть индексы внутри документа которые не будут работать если коллекцию разнести по разным коллекциям и последний совет по размеру документов если вы не используете поле идея то подумайте как можно его использовать если у ваших данных есть какая-то есть какой-то естественный уникальный ключ ты можно прям в поле аиде положить даже если ключ составное можно использовать составной айди он отлично индексируется есть только одна небольшая корабля в том что если у вас маршаль который будет марша ведь это поле иногда меняет порядок полей то едишь ник с одинаковыми значениями полей но с разным порядком это разная идиш ник с точки зрения уникального индекса в манго тебе ну покрайней мере в некоторых случаев в год такое может случиться не знаю наверно питания не может не знаем отлично и немножечко по размеру индекса пройдусь размер индекса он состоит в первую очередь из тех данных которые проиндексированы если мы пытаемся проиндексировать большие поля то готовьтесь к тому что индекс у вас будет большим и второй момент который очень сильно раздувает индексы если вы индексируется поля массивы то эти поля масел и будут multiply целовать другие поля и из документа в этом яндексе так что с большими массивами в документах будьте осторожны либо не индексируется что-то еще к массиву либо поиграйтесь с порядком в каком порядке в яндексе перечислить эти поля до порядок полей вид значения если поля отличаются по кардинале те если в одном поле количество возможных значений сильно отличается от количества возможных значений у другом поле то имеет смысл их выстраивать по увеличению кардинале ти если мы говорим о размере индекс конечно также я уже говорил что с порядком полей если одно из полей индекса массив можно прям смело и грацию чтобы посмотреть как повлияет на размер ну я видел цифры 50 процентов но я думаю что это не предел я думаю что перед ставка полей с разными кардинально все реально может дать и более значимый уменьшение размера иногда когда поле содержит большое значение нам на самом деле не нужно сравнивать это значение больше меньше достаточно только сравнение по четкому равенству и тогда мы можем заменить яндекс по полю с тяжелым содержимым на яндекс по пишу от этого поля ну соответственно индекс будет в яндексе будут храниться копьях и шеи они копии этих полей так я уже как-то упоминал что вроде бы что удаление документов это гнусная такая операция и поэтому тоже хотел бы пройтись то что грабли закопаны во первых когда будете дизайне схему данных постарайтесь по максимуму сделать так чтобы удалять документы было не нужно либо удалять их можно было целыми коллекциями потому что удаление коллекции это дешевая операция удаление отдельного документа это ну не естественно ни одного если вам там тысячи десятки тысяч документов надо удалять то это тяжелая операция если у вас все таки получилось так что вам нужно дофига документов удалять обязательно нужно делать тротлинг иначе массовое удаление документов не неизбежно скажется на latency чтений в первую очередь это будет прям совсем неприятно и и особенно это плохо влияет на лад once in a secondary ну что ж и совета что можно что стоит сделать какой то ручку чтобы можно было крутить тротлинг потому что сразу очень тяжело подобрать нужный уровень троттлинга мы просто настолько много раз через это проходили что тротлинг угадывается с 3 4 раза лучше сразу сделать ручку про тротлинг и если вам нужно удалять большую часть коллекции ну естественно если коллекции очень борту само по себе очень большая то лучше живые документы перелить в соседнюю коллекцию коллекцию старую целиком удалить тут понятно есть нюансы потому что со старой на новую коллекцию над как-то переключить нагрузку и так далее но если такое возможно то это прям так и стоит делать 2 еще один способ удаления документов все знают да ты что такой to the ellen dix вкратце отель индекс это такой индекс в котором индексируются поле в котором лежит манга the instep и этот манго таймс темп содержит дату смерти документа в когда приходит это время манга тебе автоматически документ удалит это прекрасно очень удобно однако есть нюансы дело в том что mongo db никак не заботятся о том чтобы эти удаления затрат лить если вы возьмете и попытаетесь в один момент времени удалить все удалить или например миллион документов ну ждите что у вас будет на несколько минут не работоспособный кластер который занимается только удалением и больше ничем чтобы такого не происходило надо особенно если у вас есть какие-то естественные причины в бизнес логики которые концентрируют удаление в один момент времени нужно просто добавить к это рандом я не знаю размазать так чтобы ну настолько насколько это позволяет опять же ваше бизнес-логика и спецэффекты на latency вот мы пытались пытались значит отсрочить всячески это этот момент но настал нам таки приходится масштабироваться горизонтально если мы говорим горизонтальном масштабировании применительно к манга тебе-то то конечно же шарди рование а ну для начала такой disclaimer если вот вы не уверены что вам шарди рование очень нужно лучше не надо сортировать шарди рование усложняет жизнь разработчика и devops а многим количеством разных способов например это вот у нас в компании называется налог на сортирование когда мы сортируем коллекцию то удельная производительность коллекции снижается почему снижается потому что нам требуется в manga деби поддерживать отдельный индекс для сортирования нам требуется передавать дополнительные параметры чтобы запрос чтобы этот запрос мог более эффективно исполняться некоторые штуки просто с родированием плохо работают например если вы используете запросы саске ну это вообще не очень хорошая идея особенно если у вас очень много документов потому что манга тебе реально физически вот вы говорите skip 100 тысяч документов омон в тебе говорит так 1 2 3 - он стотысячный ну и пошли дальше значит вот это вот это мы будем возвращать пользователь если в несортированный коллекции где-то внутри себя сделает а в шарди раваной коллекции все вот эти вот 100 тысяч документов которые она будет скипать реально прочитает и передаст сортирующие прокси в мангас который уже на своей стороне как-то отфильтрует отбросит первые 100000 супер гнусная особенность надо об этом обязательно помнить обязательно будет усложняться код потому что в во многие места придется протащить ключ родирование ну сами понимаете не всегда это бывает удобно просто и вообще возможно некоторые запросы пойдут либо бродкаст он либо multicast он что тоже не добавляет масштабируемости в принципе нужно нужно как-то так аккуратно прямо подходить к выбору ключа по которому будет шар диване и еще из таких удивительных моментов шарди равных коллекциях ломается операций аккаунт она начинает возвращать больше число чем есть в реальности может врать там в два раза может собрать в пределе и связано это с тем что в процессе балансировки когда документ переливаются 1 шарда на другой вот когда они уже перевелись на соседний shard она исходном шарди еще не удалились каунта все равно посчитает это такой даже не знаю разработчики манга дебин звони называют это богам эта вот такой но мышью не знаю будут они это чинить или нет хорошо ну и ещё один момент про шарди рование это но шарнирный кластер гораздо тяжелее в администрировании devops и вам спасибо не скажет потому что процедура снятия backup остановятся радикально сложнее и также начинает гораздо сильнее подгорать необходимость автоматизации инфраструктура то без чего можно было бы обойтись становится уже необходимо ну и даже как вообще шарди рование в manga деби устроены здесь у нас коллекция мы и хотим как-то раскидать по шар дам этого манга тебе ее делит начинки чанки она как поделить на чанки она выводы выбирает с помощью шахт ключа пытаясь поделить так сказать под в пространстве шахт ключа например на равномерные кусочки ну а дальше включается балансировщик который начинают эти чанки старательно раскладывать по всем шердом причем балансировщик у все равно сколько и чанки весят сколько в них документов балансировка идет только в штуках чанков когда вот такие дошли до шарди рования все короче надо сортировать надо подумать как выбрать ключ формированию первый вопрос ну вот все эти пункты которые перечислены важно в первую очередь в первую очередь такой естественный выбор ключа шарди рование это первичный ключ поле аиде если вам подходит для сортирования поля идея то лучше прямо понимаешь ордер уйти отлично отличный выбор у него и картина лети хороший он ему табл но а насколько хорошо ложится в частые запросы это ваша бизнес специфика нужно исходить из конкретных ваших с конфетой вашей ситуации если мы говорим о неудачных ключах сортирования могу привести такой пример если у тебя уже упоминал коллекцию переводов translations у нас там есть поле ленгвич ленгвич который хранит язык наша коллекция например поддерживает не знаю 100 языков и мы берем и шар деру им по языку почему это плохо потому что во первых кардинале ти ну количество возможных значений довольно низкое всего 100 штук но это не самое плохое может быть для этих целей cardinal найти достаточно но как только мы пожар де равале по языку мы тут же узнали о том что мы тут же узнаем о том что у нас оказывается пользователей англоязычных в три раза больше чем всех остальных пользователей и на тот несчастный шард на котором находится английский язык приходит в 3 раза больше запросов чем на все остальное вместе взятые по этому тоже надо учитывать что может быть иногда sharp ключ он естественным образом тяготеет к тому чтобы нагрузка распределялась неравномерно тут надо быть аккуратным и еще один немаловажный момент дело в том что когда мы подходим к шарди рование вероятно у нас уже прям вот очень надо сортирование прям очень-очень хочется потому что наш кластер манга тебе уже поскрипывает похрустывает своими дисками процессором и всем что там можно похрустывать но куда деваться уже деваться-то некуда сортировать надо мы берем и героически шар деру им каких-нибудь не знаю там поток коллекции шар деру я все это значит запускаем и внезапно узнаем что шарди рование это оказывается точнее сама формирования процесс балансировки он оказывается нифига не бесплатный балансировкой чтобы было понятно она проходит несколько стадий балансировщик выбирает чанки вероятны откуда и куда будет переносить и дальнейшей работы в две фазы сначала документы копируются с источника в цель и потом те документы которые были скопированы они удаляются и если первая часть этой операции она довольно лайтовые для того шар да откуда мы копируем а он у нас перегружен потому что на нем все коллекции лежали когда мы начали когда мы пришли к тому что нам нужен сортировать то вот вторая фаза про удаление она прям совсем грустно и потому что она положен на лопатки и без того страдающий под нагрузкой sharp и проблема это немножечко еще ну как немножечко сильно усугубляется тем что если мы например берем и балансируем большое количество чанков ну скажем 1000 chunk of the с дефолтным и настройками все эти чанки сначала копируются а потом приходит удалятор и начинает все это скопом удалять и в этот момент на эту процедуру особо повлиять уже никак нельзя и приходится только грустно наблюдать за происходящим поэтому если вы подходите к тому чтобы сортировать перегруженный кластер вам нужно планировать планировать вам нужно время желательно конечно выполняешь родирование не в прайм-тайм если у вас это применимо то есть в периоды низкой нагрузке и балансировщик вообще говоря запчасть отключаемой то есть можно подойти к первичные балансировки в ручном режиме включая и отключая балансировщик отключая на периоды прайм-тайма и включая когда прайм-тайм уже прошел можно немножечко себе позволить большего и если возможности облако все еще позволяют как то от масштабироваться вертикально то лучше shard источник заранее как-то папский лить по железу чтобы вот эти вот все спецэффекты немножечко уменьшить в общем нужно всячески готовится так у меня по материалу все если у вас есть какие то вопросы я на у них с удовольствием отвечу раз спасибо за доклад у меня вопрос тому манги есть фича что ты можешь более по яндекс по полю построить дом поле не обязательно должна существовать в этот момент а как sharding с этим дружок ну то есть если неожиданно по этому полю еще и сша родирование было сделано sharding требует наличие поля то есть это constraint фактически и второй вопрос о пробовали ли вы переливать ну вот вас там собраны в мастер слайды а потом взять там 2 или 3 слова его налить а потом итоге мигрируя сюда и то это не будет ли проще чем схема с переездом временным и балансировщика не уверен что я понял о чем речь схема с временным приездом ну то есть у вас есть там мастер и три слова 3 слова берем переключаем ну наливаем его отсоединяем от текущей машины потом берем отдельный инсталляцию за шарнира ванную чистую и с ней переливаем да я понял а так можно сделать если возможен downtime ну на время пока шар будет перри наливаться вернее на время переключения будет естественным downtime ну окей просто над по идее должен быть незначительным и сейчас как раз планируем переезд с большой большой там мастер своих вот на такую схему вот хотел знать ваши мне ну ладно но в целом в целом такое возможно мы похожие схемы применяем при перелив key данных из одного кластера в другой там те же самые ровно проблемы связанные с переключением база куда нам нужно ходить взлет молния работает вполне возможно еще один быстрый вопрос с шарды лучше живут с этим сама принес им присуща это был модель да то есть есть прирост производительности то земли на мимо придется но наверняка есть но зависит от листья с нашей по запросам и мало используем a greedy шин фреймворк для обслуживания запросов клиентов запросу пользователь поэтому кто у меня нет большого опыта использования годичном фигурка но я думаю вот так навскидку чтобы каких запроса должны безусловно ускоряться просто вот на мастер славе нет ладно спасибо пожалуйста хотел спросить как из одного шербет классифицировать другой вы переливаете данные у нас есть когда у нас есть набор наших внутренних инструментов если вкратце процесс состоит процесс примерно выглядит следующим образом мы запускаем утилиту копирование которые сначала наливает все данные которые там есть а потом читая об лоб поддерживает их в синхронизированным состоянии там описаны самописная да есть второй инструмент который координирует переключения между базами откуда читать откуда писать там естественно замороченная несколько фазная схема что мы должны как синхронизироваться мы должны остановить все записи встать на паузу потом подождать пока нам скажет но теперь вы можете писать туда а если кто-то там что-то нет не успел ответить под подвис или еще что-то там какие-то в рекавери механизма есть в общем ну в целом такая штука у нас есть можем наверное даже зоб unsourced если большой можно на спасибо за доклад вопрос такой если мы еще пока стартап для но уже запускаемся на манге и предполагаем что возможно нам ближайшей перспективе может понадобиться сортирование вот имеет вообще хоть какой-то смысл с точки зрения балансировщика и работа шарден га сразу создавать кластер пускай этот шарф будет считаете из одного узла до чтобы потом возможно проще было sharding поднимать или это оч никакого смысла не имеет можно начинать с обычной с обычной конфигурации а потом поднимать шарлин когда поймем что нам это будет нужна в целом смысла большого нет если вы не собираетесь сортироваться заранее то есть если вы создадите шарди рваный кластер то в нем коллекции будут все равно не шарди рваными если вы по шарнир уйти коллекции то это значит что вы уже делаете шарди рование даже если у вас всего 1 шард это знает что вам уже нужно принять какие-то решения по поводу в шорт ключей и возможно они будут ошибочными потому что вы сразу не увидите каких-то отрицательных спецэффектов просто потому что у вас всего один шорт лучше но не знаю самообманом не заниматься и по шарнира ваться тогда когда время придет и если все-таки это 1 шард будет создана накладных расходов на балансировку здесь значимых не будет или все таки нет на балансировку никаких расходов не будет добрый день спасибо за доклад меня короткий наверное вопрос было сказано что обломки очень грустно с удалением документов хочется узнать как у нее с изменением документов но имеется ввиду что первичные сортирующие ключевые документы не меняются но тем не менее документ изменяется существенно на нашей практике апдейт документа сильно дешевле удаление и это именно в терминах влияния на latency чтения то есть если мы оба этим много документов если мы удаляем много документов то если вот это много это одинаковое количество то latin стена чтение прыгает гораздо меньше в случае апдейтов да в целом нормальной практикой будет помечать на удалении и потихоньку вычищать с хорошим труд лингам который опять же повторюсь нужно иметь возможность подбирать спасибо тем кто же задать вопрос а парики реализацию еще речь была час что простите не реализацию манги какая у нас обычно реализация mongo db версии у нас сейчас 3 6 версия мы в процессе миграции на 4 пробовали другие смотреть вообще как касается других реализаций в продакшене да и не в продакшене на самом деле не пробовали так смотрели и еще один вопрос может я просто просушить там недопонял еще раз хотел что у нас есть и sharding и удаление по этой коллекции собственно идет то есть это 1 печаль умножается на другую совсем плохо на то как бы нас стараться мешать коллекции который часто удаляюсь но это но я бы не стал давать вот именно такую рекомендацию не сортировать коллекции в которых часто удаления дело в том что в норме если мы например создаем коллекцию с нуля и и шар деру им то удаление при балансировке это довольно таки редкий кейс потому что при хорошем подборе ключа шарди рования у нас перед первые чанки как-то вот плюс-минус равномерно разъедутся по шар дам и после этого балансировка практически требоваться не будет ну за исключением разве что случаев когда мы добавляем новые шорты или убирая но тут нужно либо резервировать дополнительное железо если это облако то соответственно там поднять на одну ступеньку хардвар ную конфигурацию благодарю за доклад у меня вопрос следующий допустим такую ситуацию если мы все-таки разбили сделали ключ хординги по по регионам или например там по языкам да в какой то момент мы поняли что нам нужно его расширить и подробить на более мелкие кусочки вот насколько вообще трудоемкий процесс и возможно ли это сделать средствами манги средства и манги встроенными такого сделать нельзя если вы ошиблись short ключом то единственный ваш вариант это перри наливка коллекции то есть вы создаете сбоку еще одну коллекцию в которой которую уже шарнир уйти другим более подходящим шарф ключом переливаете данные старую коллекции удаляете со всеми сложностями которые сопутствуют этому процессу если мы хотим без downtime и это сделать у меня два вопроса первый похож на предыдущий только не прореагировали аппарат индексы если хочется поменять индексы допустим удалить там добавить новые стоите переливать или можно сделать на текущей коллекции без проблем с производительностью можно сделать прямо на текущей коллекции стоп большой разницы нет у меня к сожалению не в хронометраж него не вошли не вошел материал по индексам вот индексы в принципе достаточно неплохо ну не аффекта производительность строятся в фоновом режиме вот но если прям совсем по феншую как рекомендует мануале делать то индексы можно строить в фуре ground режиме в в реплике в стенду лом то есть мы берем реплику вытаскиваем ее из кластера перезагружаем и и установлен режиме без связи с кластером строим на ней индекс в блокирующим режиме там возвращаем в кластер потом то же самое повторяем со всеми остальными репликами спасибо и второй вопрос такой по поводу количества документов насколько хорошо манга переварит большие коллекции ну например 1 миллион документов это нормально если есть уже индекса хорошо настроены там ну и не общем жирные документы а 10 миллионов но ткань порядок я не видел проблемы связанные с количеством документов у нас есть коллекции в которых сотни миллионов документов не знаю миллиарды и миллиарды тоже есть"
}