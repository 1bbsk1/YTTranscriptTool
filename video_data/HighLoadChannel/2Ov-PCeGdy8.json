{
  "video_id": "2Ov-PCeGdy8",
  "channel": "HighLoadChannel",
  "title": "Как снизить накладные расходы на добавление +1 микросервиса / Руслан Сафин",
  "views": 810,
  "duration": 3011,
  "published": "2022-03-21T13:13:02-07:00",
  "text": "всем привет очень место в вы видите да то есть после года наверно полутора онлайн а когда ты просто говоришь черный ящик не понимаешь на тебя смотрят люди вообще тебя слушают не слушают вот в общем круто что собрались в оффлайне так давайте сначала расскажу немножко пару слов про себя я работаю в компании bundy софт уже пять лет я являюсь техническим директором отвечаю прежде всего за культуру техническая культура в компании и также участвую в наших проектах в проектах аутсорс разработки в качестве эти архитектора будут рассказывать про наш опыт наверное стоит сказать для кого мы это все делаем для таких наверное не маленьких компаний как leroy merlin 585 золото ozon.ru и других так вот вообще о чем сегодня хочется поговорить если мы выбрали микро сервисную архитектуру то прежде всего мы выбрали стратегию да давайте и придерживаться то есть мы должны нам стоит проектировать архитектуру чисто то есть не без оглядки на количество микро сервисов дают не боясь этого количества микро сервисов это вот первая важная цель первый важный point и с другой стороны мы можем вообще не бояться количество микро сервисов мы сможем клепать налево и направо как попало копипаст вам и так далее понятно что наша система очень быстро в таком при таком подходе превратиться в какую-то тыкву то есть она будет не масштабируемый ее невозможно будет поддерживать как-то улучшать и так далее то есть вторая цель это не накапливать тех долг извините не накапливать их долг когда он а система растет развивается как и микро сервиса становится все больше и больше но вот здесь сразу случай из жизни да то есть на одном из сазонов по проектирование архитектуры будущих систем была такая фраза что вы что шутите для такой мелкой штуки целый микро сервис так вот хочется своим докладом сегодня развеять вот эти вот страхи во-первых а во-вторых дать вам некий чек-лист да то есть я буду говорить о семи факторах которые позволят убрать страх и проектировать чисто для того чтобы понять как снизить расходы на добавлением микро сервиса давать попробуем разобраться вообще в чем эти расходы состоят из чего эта стоимость складывается то есть или какие есть издержки условно я разделил издержки на растущие то есть это наверное самый критичный когда вы добавляем 3 микросферы с моста задержка 1 добавляем 4 5 издержка все растет растет и растет то есть на мой взгляд на наш взгляд нашей компании такая издержка главная она связана с увеличивающейся сложностью да то есть сложность она есть сразу на всех этапах и при проектировании нового микро сервиса вообще какой-то новые фичи и при ее разработке и при тестировании и при эксплуатации то есть на каждом этом этапе а если у вас система 10 20 40 50 микро сервисов сложность обычно растет попробуем как раз вот поработать с этой сложностью следующая издержка такая тоже динамичная которая может к сожалению расти это отказы систем то есть у нас больше точек деплоя больше точек отказа и естественно повышается шанс что этот отказ произойдет рано или поздно ну и плюс если у нас много ручных действий на каждый микро сервис а мы помним да что у каждого микро сервиса может быть своя база данных твоя очередь в мисочку куча куча всего то есть оливер think of monitoring про это все поговорим то есть на каждом этапе есть шанс человеческой ошибки шанс того что кто-то ручное действие сделать неправильно либо забудет и так далее да то есть чем больше точек диплом тем больше соответственный риск человеческого фактора это наверное основные издержки про которые поговорим но есть еще и постоянные издержки относительно постоянные то есть под постоянными издержками я понимаю те временные затраты да там затраты разработчиков по и других которые нужно постоянно делать при каждом новом микро сервис то есть вы хотите добавить еще один вы возможно делать какие-то одни и те же действия один и тот же код одну и ту же инфраструктуру одни и те же настройки на самом деле да почему относительно постоянные то есть ростом количества микро сервисов скорее всего и это издержка будет расти ну и плюс еще одна относительно постоянная задержка это технический долг если им не заниматься в процессе проектирования процессе разработки каждого микро сервиса то рано или поздно придется его отдавать и хорошо если это какое-то займет постоянное время примеру 2 ты итерации мы активно фигачим фичи добавляем и потом тратим половину нет рации или целую операцию на рефакторинг на технические долго это может быть оптимизация по скорость работа над стабильностью это может быть до рефакторинг как самого кода так и инфраструктуры и архитектуры как же с этим всем бороться до мы можно сказать агрегировать и разные подходы разных компаний разных проектов на которых мы работаем и я наверно вот эти вот много много практик которые мы сложили в рамках разных команд попробовал упорядочить вот в такие семь факторов и про каждый из этих факторов мы сегодня поговорим первый фактор это шаблоны репозиториев тут такая глобальная цель будет у каждого фактора такой идеальный мир да то есть в идеале все разработчики хотят должны это эффективно разрабатывать только бизнес-логику то есть не надо тратить время на какие-то не функциональные требования логирования там не знаю общения с мониторингом какие-то еще действия которые не относится напрямую к бизнесу мы стараемся закрыть этот фактор шаблонами стараемся закрыть эту цель шаблонами репозиториев что мы обычно включаем шаблон так наверное на секунду остановлюсь чуть расскажу вообще шаблон репозиторию что он себя представляет то есть мы и сами раньше так делали признаюсь и признаюсь и в других компаниях часто видим что делает разработчик devops когда нужно добавить плюс один микро сервис он берёт старый copy-paste создает новый да все лишнее убирает всего всего того чего не хватало добавляет естественно при таком подходе можно кучу раз ошибиться что-то лишнее убрать или что-то забыть добавить так вот шаблоны репозиториев призваны убрать вот этот начальный копипаст при создании нового рип на микро сервиса ну он же с множество зданий репозитория то есть мы именуем репозитории и выбираем из шаблона шаблон сразу к нам уже добавляет какие-то mpm или могет в зависимости от платформы пакеты для лакирования трассировка и так далее то есть все что вам нужно это могут быть разные шаблоны отдельно для api сервиса отдельно для крон джо бы и так далее services базы данных без базы данных и так далее мы обычно примерно вот этот список включая в наш шаблон в итоге шаблоны репозиториев на наш взгляд снижают таки издержки как издержки на инфраструктурный код и настройку то есть у нас сразу же в новом репозитории в новом сервисе все это есть нам не нужно вручную это либо копипастить либо самим это делать мы естественно снижается также человеческие ошибки то есть убирается вот этот ручной труд в этом году наши шаблоны и другие какие-то готовые кубики инфраструктуру мы начали выкладывать волкон source то есть есть для разных абсолютно для того стыка который мы поддерживаем в компании вокал pension с выложены шаблоны которые включают тут все что было на предыдущем слайде можно посмотреть также мы выкладываем и другие кубики которые частично затрагивает и другие следующие факторы можно будет глянуть ok это что касается шаблонов репозитория давайте пойдем дальше второй фактор это визуализация архитектуры то есть тут тоже абсолютно по-разному мы приходим на проект сталкиваемся с тем что либо архитектуры нету вообще либо она наоборот супер подробные то есть есть enterprise архитектура с кучей систем давайте возьмем допустим 10 систем в каждой из систем по 20 микро сервисов в каждой micro series по несколько in point of и ну для меня было удивительно пытается все это разместить на одной архитектуре то есть огромное количество связей каждый in point каждый лист вызов каждая очередь в мисочку она вся на какой-то одной огромной схеме естественно эта схема она не читаемы и естественно эта схема она но становится неактуальной практически сразу же с пока мы и готовим она уже устаревает когда мы и актуализирует это быстро не сделать она тоже тут же устареет так вот то есть мы сталкиваемся с разным вообще когда приходим на проекты что мы хотим мы хотим чтобы как сказать да не накапливать тех долг и проектировать лучшее решение вам нужно развить архитектуру на несколько уровней то есть должен быть какой-то верхний уровень до потом чуть подробнее подробнее подробнее уже без детализации то есть если мы смотрим архитектура конкретного салюта на решение либо к конкретной системы нам неважно уже знать всю в целом enterprise enterprise периметр нашей компании так вот то есть мы есть абсолютно разным не совсем разные есть просто до разные модели которые позволяют разделить архитектуру на уровне si4 модели либо четыре плюс один модели также есть разный enterprise фреймворке тут мы говорим о том что команда или даже набор команд который работает в одном домене или в1 в1 в одном предприятии должны договориться и придерживаться какой-то одной модели архитектуры то есть не стоит смешивать допустим enterprise технический уровень и так далее ну в зависимости от той модели которую вы выберете таким образом мы воздействием на растущую сложность то есть мы либо верхние уровни его смотрим такое bird view по нашей системе и примерно понимаем как она работает и понимаем что нам нужно разобраться конкретно вот в этой системе или в этом микро сервисе и можем перейти на другой уровень архитектуры и посмотреть актуальную версию того как работает вот вашей конкретной там нужная деталь до факторы я постарался разбить по ну как сказать то есть первый фактор самый важный потом менее важные сразу оговорюсь это очень сложно то есть для каких-то проектов седьмой фактор будет самым важным для каких-то проектов 5 ну очень условно субъективно это так давайте пойдем дальше после архитектуры третий фактор я назвал автообнаружения что это такое вообще цель у нас следующее чтобы не было ручных действий при добавлении микросферы сада конкретно в этот фактор отвечают на вопрос как как все системы вся инфраструктура подхватит наш новый микро сервис то есть зала моей практике было как ты программируешь некра сервис его пишешь потом идешь devops у говоришь надо теперь его билде там прогонять тесты деплоить идешь baby а говоришь ему надо нужна база данных в том говоришь а еще не забудьте его бы копить а потом говоришь эксплуатации что вообще-то его нужно мониторить и allure сеть и так далее так вот никаких ручных действий не быть не должно то есть новый метро сервис должен сам автоматически подхватит и каждая система знала как его мониторить как его собирать что с ним сделать и так далее как мы это делаем то есть есть некий шаблон по именованию репозитория например системным project name сервисные и возможности restime то есть сервис тайги мы указываем и 5 значит это какой-то restful сервис либо мы говорим что это кран jobo соответственно нужно его мониторить allure tidy площадь как кром joblo то же самое иногда делают иногда делают с помощью тегов создают репозитории и тегами в нем на клики вают что это такое и соответственно по этим тегам либо по имени уже выдаются право на репозитории как командам такие системы то есть я и сиди подхватывает знает как его билде куда его деплоить то есть после первого билда и тепло и все другие системы как кубер нет так далее узнают про него и будут правильно его хоть соответственно мониторинга лифтинг базовый тоже сразу подхватит то есть сразу должно появиться мониторинг циpкa то есть каких-то физических показателей если мы для разных тегов мониторим разными то соответственно это тоже подхватит естественно это снижает затраты на человеческие ошибки не нужно уже ходить в 10 мест просить чтобы что-то сделали либо делать это самому ну и нет никакого то инфраструктурного кода в каждом новом микро сервисе да еще раз оговорюсь то есть это заранее в инфраструктуру заложена и она постояла вот это of the discovery проводит да как радар и находит новые сервисы да это все по третьему фактору дальше на мой взгляд связанный фактор это то как мы вообще работаем с кодом после того как мы его разработали ну и сиди pipeline цель этого фактора в том же опять же уже на следующем этапе также не было никаких ручных действий для всего того что можно автоматизировать что мы сюда включаем понятно да то есть билд с диплом но это далеко не все что должно быть включено в pipeline и в на наш взгляд то есть все что можно проверить автоматически какое-то качество кода покрытия кода тестами уязвимости должно быть автоматизировано то есть также прогон интеграционных возможно нагрузочных если это актуальная тестов то есть ваш pull request который вы создаете и он автоматом попадает в pipeline и если допустим сон арку на сон арене пройдет проверка допустим по коды с мелсон то этот pull request даже некому превью на review не попадет ну то есть что толку тратит человеческие ресурсы на code review если мы автоматика определились что тут качество кода низкая то есть только после вот этих вот всех автоматических проверок на code style и так далее pull request доступен для человеческого review то есть таким образом да мы экономим людское время и освобождаем людей от лишних от лишней работы то есть таким образом если мы автоматом проверяем качество естественно у нас сложность она не так сильно растет да то есть технический долг это как раз какие-то проблемы в качестве то есть те же коды smells тоже покрытие кода тестами то здесь мы этими автоматическими проверка метраж холдеме отсекаем не качественный код и таким образом пытаемся бороться со сложностью ну и плюс да то есть также уходит человеческие ошибки и какой-то инфраструктурный код который мы могли это внутри сервиса делать вместо того чтобы делать на pipeline и оговорюсь что вот этот pipeline он как я сказал общей то есть не не должно быть такого что в каждом micro series вы делаете какой-то уникальный pipeline то есть максимум разные pipeline и на там три четыре пять типов и репозиториев так это что касается pipeline а давайте пойдем дальше пятый фактор это окружение по требованию в чем здесь суть если у нас количество микро сервисов уже приближается к нескольким десяткам перевалило за приближается к сотне точнее переводил сложно становится их разрабатывать да то есть нужно вообще разобраться как как разработчику отладить очередной микро сервис как к протестировать микро сервис как не помешать другому к и так далее то есть обычно там наверное у всех есть тестовое окружении production окружении иногда выделяют еще встречи или пре-продакшн окружении но вот в такой системе с большой командой с большим количеством сервисов этих окружения уже недостаточно я разрабатываю фичу хочу передать его from тендеру как фрукт in der с ней про интегрироваться займет тест а тест уже занят другим девелоперам он там отлаживают а еще в очереди 2 кого которые хотят развернуть там какую-то свои свои ветки чтобы проверить так вот цель чтобы вот этих окружению у нас было неограниченное количество то есть сколько нам необходимо сколько необходимо для команды или для каких-то автоматических проверок и допустим нагрузочное тестирование антуан тестированию чтобы все они у нас легко поднимались мы в этот фактор включаем ну во первых для каждой ветке автоматом создается такое окружение которые повторяют тестовые то есть базами данных и так далее иногда на некоторых проектах поднимается неполноценное окружении только часть то есть только нужные точки тепло и а к примеру база данных используется общее на тест окружении в таком случае это настраивается то есть мы при нажатии на кнопку по которых хотим развернуть новое окружение мы указываем что нам нужно вот это вот этот вот этот набор сервисов этот набор там к примеру шины данных и все мы обязательно на наш взгляд практика это автоматическая ошибка auto автоматическая очистка да то есть если такие окружения плодить тем более если они автоматом вообще создаются для новой ветки то рано или поздно любые ресурсы закончатся то есть в команде мы договариваемся либо по какому-то таймауту окружении чистятся либо там на выходных все чистится либо что она не используется течение какого то времени то есть на разных проектах по разному у нас сделано на что этот фактор влияет точно так же то есть у нас становится проще разрабатывать отлаживать большое количество сервисов их проверять тестировать до то есть нету какой-то какой-то гонке за окружению какой-то как конкуренции да ну и это снижает человеческие ошибки если вам не нужна на локальной машине условно 10 докеров поднимать наверное это удобнее наверное будет быстрее разработка наверное у вас будет меньше багов ok шестой фактор смотрите до этого мы рассматривали такие наверно больше инфраструктурные технические факторы но не стоит забывать вообще про то как мы создаём программное обеспечение то есть все мы люди и все мы работаем в командах все мы принимаем решения как-то коммуницируя между собой и так далее как раз шестой фактор суть его в том чтобы стандартизировать и как-то привести в единообразие процесс нашей разработки нашего тестирования нашей поддержке да то есть общие любых решений любых действий иначе иначе если мы сервисы будем в разнобой называть в разнобой как-то подходить к именование воинов тов таблиц баз данных и так далее будет очень сложно во-первых переключаться между такими между разработкой таких сервисов во вторых хочет сложно борзеть новых людей да ну и плюс если мы части сервисов допустим используем какой-то один potter пример уже трой до при ошибках в другой части сервисов используем circuit breaker то тоже будет непонятно будет сложно и начнется какой-то зоопарк как раз шестой фактор про это то есть перед началом проекта обычно в рамках 0 итерации или еще как то мы садимся командой там зовем архитектора зовем project-менеджера и договариваемся что мы выбираем вот такую примеру методологию разработки да то есть если это привычный вид флауи legit капсул то как правило у нас вся раза вся работа ведется в рамках этой методологии то есть не только работа с кодом работа программистов но и работа аналитиков в рамках тех же pull request of работа тестировщика и так далее да то есть наш как я уже говорил pipeline полностью зависит на гидрофлоу или на git flow то есть выбранное методология она нитью проходит через все этапы жизни разработке далее процесс и мы описываем ну то есть хотя бы кратко то есть как вообще добавить микро срежет что при этом нужно сделать кого оповестить какие мы используем паттерны и какие используем гайд linea допустим для именования and point of и так далее то есть главная задача не уйти в разнобой это также прежде всего влияет на наш взгляд на растущую сложность да то есть у нас все единообразно и мы примерно понимаем как что работает даже в новом сервисе который мы до этого ни разу не видели снижает человеческие ошибки то есть мы знаем как нужно проектировать паттерн и используйте мы подходим к обработке ошибок и так далее но и это также немножко задевает оптимизацию то есть нам при каких пункта разбор инцидентов ускорение сервисов не приходится городить смотреть что здесь один паттерн тут другой изменять грозить пиши и так далее у нас сразу все стандартизованы и описано вот это что касается процессов и наконец седьмой фактор это прервали летим или наблюдаемость тут наверное стандартно мы должны видеть состояние системы получать активные alert и и вот с чем мы не сталкиваемся как правило это с проактивными alert ими то есть это alert и который не говорят когда уже все плохо о который заранее говорят что скорее всего скоро будет плохо сейчас чуть объясню это вообще вот помимо стандартных технических метрик которые надеюсь и отслеживают в этот фактор мы включаем визуализацию и alert и по бизнес метрикам да то есть система может работать о конверсия у нас упала никто об этом не знает то есть наверное это еще более критический alert нужно разбираться что сделать обязательно мы помогаем заказчиком вы ставите сумму и обязательно мы его отслеживаем то есть мы его визуализируем в любой момент времени мы должны понять мы выдерживаем и соло на текущий момент либо уже не выдержим до иначе зачем мы его выставляем и вот пример про активных alert of italy рт о быстром сгорания бюджета ошибок то есть если у нас слог примеру девяносто девять и девять это значит что сколько одну десятую процента мы можем там себе позволить вообще упасть либо оба от работать дольше дольше положенного так вот если мы имеют меряем допустим результаты slope месяцу и мы видим что за первую неделю месяца мы от этого от этой одной десятой процента уже сожрали половину то наверное в месяц мы не уложимся так вот это и есть бюджет быстрая сгорания бюджета ошибок о котором наша система нам должна лететь и ещё один важный момент тоже на нем отдельно остановлюсь это отслеживание частоты использования сценариев как правило все мы знаем какой рпс на том или ином от pointy но мы не всегда знаем какой рпс на том или ином and point с учетом каких-то входных параметров ну то есть условного наших нашим point постоянно используется с входным параметром true с входным параметром фолз уже перестала использоваться у по бизнесу этот сценарий от мира мы о нем не знаем мы тратим время на поддержку этого кода на рефакторинг этого кода еще не дай бог там высокие требования по нагрузке до и мы еще и постоянно отлаживаем эту ветку кода который на самом деле не используется также к примеру с флагом фолз у нас контент может использоваться но гораздо реже то есть вас нагруженный and point и мы должны там сотни рпс выдерживать и мы стараемся выдерживать для любых комбинаций входных параметров но на самом деле львиная часть запросов на and point приходит с флагом труб с высокой нагрузкой а с флагом phones там вообще нагрузки нету и мы можем условно сэкономить на рефакторинг и на оптимизации этих сценариев и вообще выстоять разные и соло для разных сценариев в рамках одного из пэнд и так вот немного вернусь то есть вот это тоже очень советую визуализировать то есть какие сценарий как часто у нас используются все это влияет на но вот как раз наверное мой пример про этих долг и оптимизации плюс если мы не выдержим и слова или мы проседаем по оптимизации мы это увидим заранее нас the edge окружении при нагрузочных тестов и и максимально убережем production от этого ну и плюс когда мы видим наше состояние системы как что куда ходит где какие сценарии использования используются это тоже нам позволяет бороться с растущей сложностью так вот если применять все описанные семь факторов на наш взгляд да то есть в вообще во всем цикле разработки микро сервисом из давайте еще раз быстренько мы создаем rip микро сервис через шаблон репозитория и сразу его добавляем на архитектуру тем самым сразу же из репозитория у нас микро сервис подхватывается все нашей инфраструктурные системы через автообнаружения у нас появляется настроенный pipeline который готов его биндить на этапе тестирования у вас будут окружения по требованию и на этапе также тестирование и потом поддержки в продакшене у нас будет об сервами лети но практически из коробки ну и плюс у нас есть описанные процессы как его разрабатывать допустим крон джо бы мы разрабатываем вот так с базой работаем так и как его тестировать так в итоге сколько же стоит добавить микро сервис то есть по таким примерным подсчетам да то есть да чтоб добавится микро сервис у нас командах обычно два основных идей основных действий это его от рисовать на архитектуре и обсудить с командой ну то есть представить что вот здесь у нас теперь новый блок о будет работать делать то то то то ну в зависимости от размера команды это можно сделать и за час и создать репозитории то есть задать имя по шаблону либо набрать нужные теги и вы выбрать шаблон все по сути за один час 5 минут у нас появится новый микро сервис готовы к выкладке в прод ну естественно в нем еще не будет какой-то бизнес фичи то есть можно быть дальше просто ее разрабатывать не тратя время не трать там ресурсы накид и издержки в итоге мы получаем стабильную скорость независимо от количества микро сервисов тут наверное известный график дауны против долг и про хорошую архитектуру если я не ошибаюсь график фаулера да то есть на каких-то этапах предложенный подход будет проигрывать из-за своей ну да там тоже какой-то инфраструктурной сложности подходу без этих семи факторов но если вы строите не мгп если вы строить какую систему который был достаточно долго развиваться то с учетом 7 факторов вы достигнете стабильной скорости которая достаточно быстро обгонит подход без данных факторов спасибо за внимание готов ответить на вопросы руслан сафин спасибо тебе огромный я вижу уже две руки сходу надеюсь на онлайн на этом докладе давайте принесем микрофон и вот в центр 1 2 и потом я вижу за колонны еще рука да мы туда пойдём у кого из микрофон начинаете говорить привет спасибо за совет у меня такой вопрос внутри мы все увидели что это дешево очень новый сервис эксплуатацию но как обстоит дело с тем чтобы обновлять уже существующие microserver скажем изменив pipeline и новая версия понапе это все нужно поддерживать старых как происходит отличный вопрос смотрим то есть тут два я услышал первое если мы хотим обновить микро сервис то есть примеру вышла вышел наш новый допустим пакет логирования мы хотим обновить то есть первых версиях шаблоном у нас прям был какой-то инфраструктурный код шаблона то что такое мы создали сервис из шаблона и все мы не сможем потом шаблон нарастить то есть текущие шаблоны у нас максимально легкие они просто подключаются разные кубики то есть мы хотим обновить логирование и мы обновляем версию логирования шаблоне 105 и по всем сервисам естественно там автоматически не вручную теперь вопрос про pipeline то есть если мы просто хотим обновить стиль микро сервис production минут то есть тут каких-то обновлений pipeline у наверное не потребуется то есть мы просто добавлю фичу и обновляем если мы хотим вообще с там наш pipeline нарастить либо инфраструктуру нарастить но тут тоже каких-то проблем не вижу то есть примеру в pipeline но я не знаю мы добавили еще одну проверку эстетического анализа sommer ну просто все микро сервисы при следующем билде они будут проходить плюс одну проверку ну там можете попросту не понял да и у меня еще 2 вопроса где есть про управление зависимости первым отвечай на первый вопрос обновили версии логирования но скажем бывают там проектов проблемы что используются разные там коннекторы для баз данных липкий для работы с кашами то тут все в это тоже как-то рулите на уровне инфраструктуры или каждый команда выбирает свое но то есть если у нас сервисы зависит от версии пакета то есть для них это критично то естественно вот этой tool за который по всем сервисам пройдет она будет это учитывать то есть это естественно от проектов и от самих сервисов зависит мы на этом натыкались то есть у нас был какой-то список исключений допустим там пакет для подвеса вы не обновляем только вручную везде потому что там брики мчс ну естественно вот это вот у за она учитывается стратегию то есть если там обновилась минорная версия то наверное можно раскатывать если мажорное там есть ну наверняка есть брики очень чувства только вручную просто пакет для поздра статам версия у нас была нарушена видимо там минорное обновление были брекин женщин поэтому мы словили такую проблему понятно спасибо супер сейчас вот вот у нас две руки по центру и дальше множество руку в той стороне привет спасибо за доклад на самом деле первый вопрос у меня забрали вот такой важно я думал вопрос для всех кто начинают рано или поздно много сервисов разворачивать как поддерживать и и второй вопрос это просто подхватываю то есть у вас есть какой-то шабане zero ванный набор допустим конфигов кубер нет асада и достаточно указать разработчику в сервисе подходящий тип вам подхватит или же все-таки командой разработчики пока иначе разбираются с ним и пишут дипломе cooper конфиге у себя внутри сервисов равно подхватывается так первый вопрос про поддержку на него уже ответили про типы ну то есть да есть он заранее подготовленные там и pipeline ее какие-то конфиге в зависимости от типа сервисов да то есть там концу меры по одному диплом ци какие-то медиаторы которые накатывает миграции на базу данных по другому рис сервисы по 3 вот так а почему 8 собственно вопрос пишет или сами разработчики сервиса в deployment конфиге или просто выбери рода в каждом репозитории есть просто но во первых до либо по имени либо по тегам мы понимаем что это за тип плюс каждой репозитории есть какой-то сейчас боюсь наврать но по-моему там докер-образ и плюс какой-то кастомный дженкинс дженкинс файл если нам нужно прям супер кастом на что-то сделать мы не вообще весь pipeline переопределяем а мы просто вставляем вот там две три строчки кастомный список для этого сервиса и это дженкинс файла он вставляется в нужное место большого jenkins файла спасибо супер следующий вопрос онлайн вы вы если не решаетесь вот как это сказать выйти в эфир вы напишете в чатике я надеюсь что все у нас работает я смогу задать вопрос хотя бы так очень хочется увидеть что мы все вместе да у меня тоже 2 вопроса с помощью спасибо за доклад первый вопрос насколько большой зоопарк стеков и языков можно поддерживать при таком шобла низе раваном видим насколько можно сложно сказать могу только из своего опыта сказать то есть как правило в рамках проекта у нас максимум 2 ст и к примеру там но dsg что еще бывает ну то есть либо 11 клипа два стика то есть два стака нормально тянет больше мы не пробовали нокий и второй вопрос по touring то есть марони уже что дженкинс а что еще так ну тут тоже немножко варьируется в проектов поэтому каких-то конкретных я не давал там не ссылок и так далее ну то есть это кубер нить из у нас дженкинс как правило но в джанкен здания на всех проектах то есть где то и другие соседи инструменты плюс у нас есть много собственных инфраструктурных кубиков вот которые мы постепенно выкладываем вулкан source еще не все но надеюсь к концу года мы их подготовимся и выложил cursors вот ну то есть как правило это какие-то открыты инструменты то есть либо стороннего open source либо нашего пан source то есть каких-то платных там супер дорогих но просто платных инструментов я так стар скидка не вспомнил про нет единства гид хоп платные enterprise вот там где то еще за колонны и я видел во 2 кажется ряда поднимали человека пересел же привет меня зовут алексей кукин компания национальностям пути нужна карта я смог вами более инфраструктур щека будет такой вопрос понятно что скорее всего не китаем некоторые модели мониторинга вы задаете с помощью тегов омон ответственно у вас есть несколько ри набор шаблонов некоторым набором тегов их много вопрос автоматизации видимо выбора из множества сопло новых нужный тогда у вас получается очень много шаблонов на все случаи жизни еще такой вопрос сразу что в каждом шаблоне скорее всего для каждого сервиса прописан некоторые лимиты лимиты и ресурсов но когда мы де планку в кабир соответственно там есть некоторый запрос ресурсов под это диалог как вы определяете необходимость в этих ресурсов то есть я понимаю что разработчикам проще заказать больше ресурсов и как это потом отслеживается они заказали слишком много ресурсов чтобы просесть по производительности так первый вопрос про там количество шаблонов да то есть тоже хороший вопрос то есть их может быть вообще огромное количество да то есть шаблон спазган somersby там только с гор сам и так далее то есть сейчас у последней версии шаблонов насколько я знаю там есть патче то есть какой-то базовый шаблон и если нам нужен допустим по сгрыз либо манго мы просто патчем ставим в этот шаблон ещё и нужную базу и из него уже стартуем репозиторий сначала мы как раз шли до вот по такому пересечении действительно получилось много шаблонов сейчас по моему есть только вот базовый шаблон и + patch то есть примеру на если взять majestic но джесс шаблон typescript шаблоны для нас гсм фреймворк у нас появился шаблон вот они включают ну там наверно логирование везде нужна а допустим какой нибудь по сгрызть по чем либо ставится либо не ставится то есть мы так боремся вот количество шаблонов вот второй вопрос про ресурсы то есть как запрашивают ну это инструкции для инфраструктур щека больная тема просто потому что запрашивается да много происходя дискуссионный вопрос то есть мне кажется какой-то серебряной пули нет то есть тут как команда договориться как команда вообще ну то есть все люди адекватные как мы делали то есть есть какой-то дефолтный набор ресурсов которые определяют devops и и когда с которыми стартует все сервисы если тебе по каким то причинам нужно больше там за гигабайт оперативной памяти ты говоришь devops у но с ним без какого-то формализма дополнительно просто обговариваем что вот поэтому поэтому он говорит о'кей типа прислал pull request на там увеличение до 4 гигабайт эти об рублю ну то есть вот тут у нас лично такой подход персонале за какого-то там активного нет у devops of возможно есть ну я сейчас то есть вы можете мне написать на почту я спрашиваю devops of как они следят вот автоочистка это прям но их тема слежения то есть возможно они следят спасибо большое у нас еще один или два вопроса с правой из правой секции зал а потом в центре один вопрос потом там в общем на сколько успеем ребят добрый день вот этот вот слайде где бирочки пересекаются и любопытно вот на каком количестве сервисов по опыту вот эта . тоже хороший вопрос но наверно тут какое-то субъективное тоже только может быть ответ я так отвечу что у нас сейчас команда из шести семи человек это примерно 50 сервисов но 50 до 100 сервисов там по-разному вот этот вот эта вот . да пересечении перегиб чисто субъективно где-то 5-6 сервисов уже случается такой перегиб ну то есть всего пять шесть и мы приходим к на какой-то проект то есть там нелепости там не монолит говорят все хорошо у нас пикар сервис и смотрим один micro series он отвечает за там три четыре разных бизнес-функций смотрим второй микро сервис а он шлет запрос в 3 потом в 4 потом еще раз в третий и так далее то есть пять менее монолитов я понял наверное 56 это из за того что вы натягиваете свой фреймворк а я имел ввиду если вот есть чистая компания у нее нет каких-то уже готовых врагов cove и что нам допустим проще поднять вот такую же всю инфраструктуру когда вот с этими шаблонизатора my с этим всем самом или не запариваться ну скажем до 100 сервиса тут смотрите но опять же субъективный ответ мне кажется зависит от подхода к разработке если к примеру ваш за сервис отвечает один человек ну или даже одна команда за один сервис ну то есть такая крупная нарезка сервису то это будет 1 одно количество если как у нас то есть команда отвечает за количество сервисов 10 раз больше чем человек внутри команды то эта точка будет явно левее то есть если то есть 5-6 по этому подходу и но для маленьких команд для больших команд она будет немножко побольше но сложно сказать то есть мнение нет такой выборки наверное нет такого опыта потому что вы разворачиваете и еще один момент я сейчас про воспользуюсь своим правом человек с микрофоном давайте у нас осталось пять минут на вопросы по одному вопросу в одни руки пожалуйста я вижу вот на втором ряду давно человек тянет руку сейчас моему предоставим слово и дальше вот в левой части зала в конце там была рука привет спасибо за доклад такой вопрос хотел уточнить кто определяет периодизацию с точки зрения вот работа инфраструктурных команд которые отвечают за новый функционал шаблонов то есть клиента это другие команды разработки которые безусловно делают это понятно но как каждого командам нужно что-то разное то там новых фич хочет шаблон чтобы с базами работать кто-то по доработке системе continent играешь нам вот как вот этот вопрос решается есть такая практика inner source постараюсь кратко рассказать то есть это попытка внести open source в рамках каких-то enterprise системы и так далее то есть у нас в каждой команде обязательно даже быть devops который работает на нужды этой команды и то есть если конкретной команде что-то нужно она берет и inner sourced в инфраструктурные с помощью devops а либо с помощью бы киндера который просто хочется в это погружаться ну и знает и потом корт команды она правит либо там какие-то пожелания и дает попал request и ну как-то так это работает это понятно что если какой-то команде нужен она может прийти сама закон трибетить но есть команда которая же все равно это основном поддерживает как ее кукла приватизируется ну там наверное все то же самое как в любой продуктовой разработки то есть должен быть продут турниру такой инфраструктурной команды который каким-то образом ходит в поля то есть по разным командам строить гипотезы и работать с блогом то есть у него же не так все просто него нет продуктов то у них такое получается внутренний продукт инфраструктуру оставляя много внутренней как называется каждым мне кажется какие-то такие дискуссионные вещи где а вот хочется поговорить можно перенести ее в кулуары кажется мне что мы на два вопроса еще успеем ответить за пару минут 1 и вот на третьем ряду в центре да ребята всех кто сейчас не успеют вы приходите в кулуар вы там с русланом продолжите добрый день руслан спасибо большое за доклад собственно у нас тут бы вопрос от инфраструктуры теперь маленький вопросов безопасности был поминали что у вас там блокируют этого поймана есть сканирование кода сканирования образов я полагаю как вы защищаетесь от так называемых ступайте intex то есть когда у вас как гарантировать того что у нас код неизменно прошел всю цепочку доставки как гарантировать то что все проверки были выполнены и никакая проверка либо пропущены так если честно не стал вас слышал про как как мы проверяем на уязвимости нет нет не не как вы видите вот проверка на уязвимости это часть где все кокса есть еще такая проблема что злоумышленник может попытаться обойти эти проверки на уязвимости и соответственно нам необходимо каким-то образом гарантировать что во первых все проверки были пройдены а установить так как обычно сканеры но или там какие-то средства devops имеют большие привилегии они могли изменить целостность кода целостность приложений и туда что-то внедрить какой-то мало вот соответственно как вы являетесь но естественно автоматическая проверка на уязвимости это только базовая до проверка безопасности то есть там смотрим что нету каких-то версии пакетов которые уже консорциум признанные уязвимыми что там нет сканирования кода на наличие секретов паролей в коде вот на code review у нас одним из пунктов тоже есть какая-то базовая проверка ну то есть условно что нельзя эдичку просто в параметре передать из-за другого пользователя чтобы сделать то есть это уже какая-то ручная проверка все это автоматика наверно не закрыть ну и плюс целом если мы у нас система она такая критичная для безопасности то есть вообще отдельные команды которые занимаются pen тестом проверкой безопасности это как правило даже отдельная компания от компании разработаны это уже отдельная тема на самом деле я имею в виду что вот и дискуссию ребята вы продолжите войну арахна из честно плохо слышно поэтому давайте я обещал еще человеку задать вопрос на что ты успеешь вы задать чтобы руслан выбирал лучшие вопросы и твой вопрос попал ответит он уже в кулуарах дальше переключение слове переходить туда да здравствуйте большое спасибо за доклад я для себя что-то почерпнул из него такой вопрос есть вас шаблоны до из которых вы делать проекты вы могли бы крупными мазками сказать что там находится тоже там не только под похоже там еще что то какие то кусочки и вот связано метрики в бизнес метрики ля ля ля это там описывается и потом как-то по и планом вытягивается в графа ну куда то еще супер вывод в кулуарах будет жара в ответ на этот вопрос руслом спасибо тебе огромное за доклад за подробный рассказ"
}