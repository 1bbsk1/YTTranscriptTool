{
  "video_id": "qcKwkmzwM_E",
  "channel": "HighLoadChannel",
  "title": "Zero cost-абстракции на примере хэш-таблиц в ClickHouse / Максим Кита (Яндекс)",
  "views": 1868,
  "duration": 1966,
  "published": "2021-10-04T02:45:36-07:00",
  "text": "меня зовут максим я разработчик клик хаос и сегодня мы поговорим про хэш-таблицы в хаосе мой доклад будет состоять из следующих частей это будет введением хэш-таблицы вопросы разных моментов дизайна хэш-таблицы то есть какие вы можете сделать трейдов и с алгоритмической точки зрения потом мы посмотрим как такие хэш-таблицы нужно бенчмарка ведь и посмотрим на дизайн си плюс плюс таблицы в клик хаусе зачем вообще нужны хэш-таблицы в хаусе все наверняка в курсе что клика us это аналитическая база данных и самая важная в крик aussi это ответ отвечайте вы правы это грубой и как сделать быстрый грубой это положить все в каждом лицу вообще некоторые люди даже говорят что клик house это тонкая обертка над грубая так теперь немного про хэш-таблицу все наверное в курсе и из университета что хэш-таблица это такая структура данных которая предоставляет методы за константу lookup insert рейс ну в случае агрегации данных рейс на мне очень нужен так посмотрим на картинку то есть как вставляется или делается lookup хэш-таблица обычно хэш-таблица это какой-то массив например каких-то ячеек мы пытаемся вставить значение высчитываем хэш-код находим слот это будет hash hash плюс остаток хэш и модуль от размера массива и мы нашли слот это так работает вставка и также работает lookup в идеальном случае это очень быстро так хэш-таблицы это королевы структур данных они состоят из многих разных частей и каждая часть очень важно давайте вот посмотрим есть кэш функция это очень важно и очень важное свойство потом можно выбрать способ разрешения коллизии так как они обязательно будут потом можно смотреть на политике ресайза их тоже есть большое количество и самое интересное в вопросе дизайна хэш-таблицы это как она будет лежать памяти вот тут вот и начинается самое интересное но мы начнем с выбора хэш-функций есть несколько правил таких как бы законов хэш-таблиц и хэш-функций во первых не надо использовать identity функцию для чего с цист целочисленных типов так вот сделано например в стандартной библиотеке это плохо у вас будет много коллизий не стоит использовать хэш-функций для строк для целочисленных типов например какой нибудь сети хэш для целочисленных типов это будет тормозить там много кода в общем не стоит также не стоит использовать криптографические хэш-функции так как их вычисление ресурсоемкая на слайде видно что сидишь может считаться около гигабайта в секунду а вот например сети h10 гигабайт в секунду а из вчерашнего доклада мы уже знаем что мем копии то 12 гигабайт в секунду не использовать сип hash это не очень хорошо и также не стоит использовать устаревшие хэш-функции например я позавчера смотрел и вот это вот хэш функция используется в библиотеке джесси так теперь про выбор хэш-функции какие хэш-функции используются в клика уся мы используем плохие хэш-функции во первых у них плохое распределение они не пройдут тест сэм фишер это такой тест хэш-функции на гитхабе и в общем то у них есть плохие свойства но они хорошо работают на практике для целочисленных типов мы используем сердце 32 си это одна инструкция на самом деле 2 и latency этой инструкции три такта вычисляться будет очень быстро для строк мы используем свою хэш-функцию построенную на сердце 32 se но если вы не хотите такие эксперименты то можно использовать просто что-нибудь стандартная например сити hush теперь разрешение коллизий по парадоксу дня рождения у вас хэш-таблицы по-любому будут коллизии один и тот же ключ захочет стать в один и тот же слот как видно на слайде мы посчитали хэш от второго ключа и видно что он хочет залезть в слот 1 ключа что тут можно делать есть такие два основных способа 2 и рабочие лошадки это метод разрешения цепочек и метод открытой адресации есть и другие методы они хорошие в теории но плохие на практике плохие они зачастую так как происходит дополнительные фичи из памяти все начинает тормозить или код написать становится очень сложно мы не любим сложный код в клик хаусе вот давайте возьмем для примера через хэш тайбл как устроена такая хеш-таблица берется 2 хэш-функции берется два массива мы вставляем в одну хэш-таблицу и для каждой из этих вот двух хэш-таблиц мы смотрим количество коллизий и из и мы вставляем в ту хэш-таблицу у которой сейчас меньше коллизий в целом почему это тормозит мы считаем 2 хэш-функции на горячем пути два фича память не работает давайте теперь от плохого перейдем к хорошему ну или не очень хорошим метод разрешения цепочек а два одинаковых ключа например попадают в один слот что можно делать самое первое что приходит голову давайте в sla те сделаем какую-нибудь структуру данных например список или вектор вот так это выглядит на слайде такой метод используется в std она артрит map и в целом в этом методе есть несколько плюсов во-первых вы получаете стабильности указателей на ключ и значение для каждого ключа то есть для каждой ячейки хэш-таблицы в которой будет храниться ключ и значение выделяется память отдельно алла котором то есть вы можете указать или найти ключи где-нибудь дополнительно хранить они не будут инвалиде рваться при ресайза то есть это очень удобно вы также можете хранить большие объекты и не перемещаем ее объекта это скорее больше про такие какие-то вещи и связаны си плюс плюс а также такой метод хорошо работает с плохим лот фактором с плохой хэш-функций в целом он может пройти такие тяжелые условия но этот метод очень сильно тормозит когда это хэш таблица перестает помещаться в кэше пракаш локальность мы тоже уже вчера послушали и сегодня тоже будет к сожалению немножко про это вот еще из-за чего это сильно тормозит хотя многие на это не обращают внимание это из за того что это очень сильно нагружает а локатор вот представьте вы пытаетесь ставить очень много ключей в хэш-таблицу на каждой из этих ключей делается a location так теперь про метод который использует все серьезные разработчики это метод открытой адресации а два ключа попадает в один и тот же слот что мы делаем мы просто ложим в какой-то из в какой-то из следующих ячеек как мы можем выбирать в какую следующий хищник мы можем положить тут выбор очень большой мы можем двигаться с шагом например один что мы тогда получим это будет идеальная кэш локальность то есть за один поход в одну кэш ленью вы можете уложиться и собственно говоря разрешить вашу коллизию можно использовать квадратик probing квадрате нг probing это шаг будет являться степенью двойки в таком случае в начале у вас будет такая же хорошая кэш локальность но затем вы будете немножко прыгать и можно использовать еще различные шаги но при этом я не буду рассказать так минусы такой хэш-таблицы во-первых нельзя хранить большие объекты если вы будете хранить большие объекты то все плюсы такой хэш-таблицы так скажем уходят так как за один поход в carlion вы ничего принципе сделать и не сможете и нужно очень аккуратно выбирать хэш-функцию так как если будет хэш функция выбрана неаккуратно у вас вот эти вот кластера цепочки коллизий могут начать склеиваться и вы будете проверять ключи у которых даже не тоже хэш-функция так теперь про ресайз когда ключей становится много ваш константный lookup то есть константа в этом look at и становится слишком большой это может начинать тормозить и нужно делать ресайз тут важно во-первых определиться так во сколько раз мы будем делать ресайз мы можем делать ресайз по степени двойки это хороший выбор почему остаток отделением можно посчитать вот так как указано на слайде по сути это бесплатно но можно как раз вот из теоретической такой из теоретических докладов похож таблицам пробовать выбирать простое число близкое к степени двойки к сожалению в таком случае вам нужно как то придумать как делать быстрое деление компилятор если видит константу может заменить ее на умножение и сдвиг и это будет работать хорошо но для этих констант у вас будет большой switch либо можно использовать библиотеки например лебде white она будет работать медленнее чем деление которое я показал но принципе лучше чем cost and switch теперь про выбор лот фактор лот фактор это когда мы начинаем рисовать хэш-таблицу то есть насколько хэш-таблицы должна быть заполнена стандартный хороший выбор для хэш таблиц с открытой адресация это половина хэш-таблицы клик хаоса и google tanks хэш мам которая была популярна почти все время используют этот метод но можно использовать и побольше лот факта например новая гуглово я хэш таблица из библиотеки опция используется что-то около девяти десяток так теперь про самое интересное это способ размещения в памяти тут нужно учесть такой момент каждый человек который когда-нибудь писал такие хэш-таблицы сталкивается с решением он пытается вставить ключ и нужно понять какие ячейки пустые какие ищейки удаленное где хранить эту информацию так давайте начнём с самого простого метода который был известен очень давно мы попросим клиента выбрать два ключа ключ которого который будет считаться как за пустое значение и ключ который будет считаться за удаленное значение таких ключей клиент использовать не будет ну в чем тут сразу проблема проблема в том что во первых с точки зрения юзабилити мы заставляем клиенты думать этого делать никто не хочет поэтому вот такой метод используют google dns хэш move старая и принципе довольно часто вы можете действительно придумать какие-то ключи которых у вас не будет но все равно это не очень удобно и вот например когда мы будем вставлять в такую хэш-таблицу мы просто сравниваем значение в ячейке пустой она или нет так теперь поговорим про то как сделано у нас фрика усе мы отдельно обрабатываем пустое значение про удаление расскажу чуть попозже с отдельно обрабатываем пустым значением перед вставкой или поиском хэш-таблицы мы проверяем этот ключ пустой или нет то считается этот ключ пустым или нет и ячейку для такого ключа мы храним отдельно в чем плюсы во первых мы не нагружаем клиента то есть не нужно выбирать какие-то ключи которых никогда не будет хэш таблица из минусов то что возникает какой-то branch на каждый локо по или там insert но этот branch хорошо при диктуется и в принципе на него ресурсы не тратятся по нашим бенчмарком так теперь про сжатая хранением метаданных и данных это такой один из новых методов которые например используется в хэш-таблице в новой библиотеки от гугла swiss хэш-таблицы вот давайте подумаем если бы мы захотели где-то держать информацию о том пустая ячейка или нет удалена она или нет ну наверно можно использовать два бита только нужно придумать куда их засунуть вот например если мы засунем их ячейку то это будет не очень хорошо так как из-за alignment а все немножко поедет это будет кэш локально но мы можем поместить его например в какие-то группы давайте сделаем такие группы мы будем хранить 8 ячеек с метаданными по одному байту и например 8 ячеек с ключом и значением по сути мы разбили нашу хэш-таблицу на такие группы по 8 что это дает это дает то что мы можем теперь в принципе понимать какие ячейки удалены какие пустые мы можем построить бытовую маску и сделать это но получается что в каждом байте мы используем всего лишь два бита это не оптимально давайте подумаем что мы ещё можем туда запихать мы можем запихать туда нижняя семь бит хэш-функций мы записываем эти нижние 7 бит хэш-функции в каждый из этих вот ячеек мета-данные остальные биты будем использовать для адресации в эти группы что это нам дает представьте мы можем теперь создать группы по 16 и затем использовать синды инструкции и проверить какие ячейки на вообще собственно говоря стоит смотреть этот способ очень хорошо работает если у нас есть он sux с woola копы то есть если у вас ящики в хэш-таблице вообще нет все будет работать очень быстро теперь немного про бенчмарки такое чувство в интернете каждый написал свою самую быструю хэш-таблицу и вот если посмотреть на бенчмарки глаза немного разбегаются что выбирать в каждом из бенчмарков их хэш-таблица автора которую написал вчера самая быстрая это очень сложно если проанализировать все эти бенчмарки можно находить некоторые недостатки как не стоит делать бенчмарки во-первых не стоит тестировать это напросто числа в каких-то случайных числа так как распределение в реальных данных не многое другое также нужно тестировать хэш-таблицы с учетом того сколько памяти они будут занимать какие какое там используется лот фактор и самое важное вы должны публиковать код бенчмарка чтобы мы могли посмотреть что это правда так как надо тестировать мы тестируем наши хэш-таблицы на реальных данных яндекс метрики они выложены в паблик доступ и любой может скачать и посмотреть вот давайте немного сделаем бич марков попробуем взять таблицу в ней возьмем колонку watch айди там около 20 миллионов уникальных значений всего в памяти это будет 600 мегабайт на моей машине которой я тестировал такая же какого алексея миловидова это не помещается в аллель каши так как это не помещается в олег кашин значит мы будем ходить в оперативку и можно посмотреть на слайдов что std on orders темп куда-то далеко ушел почему так вообще происходит так как std an ordered map хранит каждую ячейку в отдельной локации это очень много каши миссов плюс можно еще заметить что деструктор шмапы должен освободить всю эту память то есть будет происходить много просто даже вызовы функций это некое шлака льна остальные хэш-таблицы в принципе ведут себя достойно кстати то что хэш-таблица стандартная тормозит можно сказать что так продиктовано стандартам то есть оно должно поддерживать интерфейсы из-за которых в принципе быстрее написать вы не можете например там есть вы можете получить итератор для багета кто-нибудь этим пользовался вот видите никто не пользовался так теперь давайте посмотрим кэш мисс и есть такая утилита на линуксе перст от мы запускаем ее и запускаем наш биг мак чтобы проверить что наша теория верна мы видим что у an ordered хэш очень много кэш весов до наша теория верно теперь почему так происходит давайте посмотрим на такой заезженный слайд latency numbers можно заметить что вход в main сторож это 100 наносекунд это очень дорого и такое будет происходить у вас на каждый космизм так возьмем теперь реджио найди тут меньше уникальных ключей все прекрасно помещается валеев каши и мы видим что она одарит map всего лишь два раза медленнее ну все равно два раза можно сказать вы устроили себе хай лот на ровном месте так теперь поговорим немного про дизайн си плюс плюс хэш-таблицы вот мы поговорили про алгоритмическую часть но для хорошего такого алгоритма серьезного нужно сделать си плюс плюс оснастку и главное zero cost какие основные так скажем интерфейсе у нас есть мы в принципе уже обсудили давайте попробуем предположить что это может быть в коде во первых это нужно нам нужна какая-то хэш-функция также нам нужен а локатор выделять память также нам нужна политика ресайза ячейка ну и собственно говоря хэш-таблиц интерфейс каша у нас такой же как std хэш си плюс плюс 11 ничего нового мы тут решили не придумать а положиться на стандарт но сало котором мы не смогли положиться на стандарт пришлось немножко переделать интерфейсы чтобы дать возможность делать realloc для чего мы делаем realloc мы для больших кусков используем м map area лог мы делаем через м римом это очень быстро и для больших кусков памяти это не тормозит также у нас например есть локатор выделяющий память на стыке если вам нужно посчитать там небольшую хэш-таблицу в каком-нибудь локальном алгоритмы все будет работать очень быстро без походов хип теперь про ячейку это самая крутая часть нашего дизайна хэш-таблицы ячейка у нас это полноценный объект она отвечает не только за ключ и значение но она также может сказать пустая на или нет и вернуть свой хэш но что самое интересное у нее есть интерфейс которым она может специализировать хэш-таблицу в которой она лежит то есть наша ячейка умная она понимает что она лежит хэш-таблицы и может поменять ее поведение это прикидывается через параметр состоянии хэш-таблицы третий параметр template так теперь немножко про интерфейс ресайза тут принципе все просто то что мы с вами обсудили нам нужно выбирать место в хэш-таблице двигаться с какими-то шагами при понимать когда рис оазиса так теперь про хэш-таблицу хэш-таблица у нас это такая такой клей который склеивает все эти компоненты и предоставляет клиенту простые интерфейсы look up and insert так тут можно заметить такой трюк который использует все профессиональные разработчики на си плюс плюс zero bass of optimizations мы наследуем ся от сша а локатора состоянии ячейки и так же мы делаем такой хитрый трюк zero байлю starish вот допустим ячейка говорит нам мне не нужен zero пылью сторож в таком случае этот вот класс зеро волю старых будет такой данный класс ним ничего не будет мне мне будет состояние это будет настоящий zero cost теперь возможность создавать кастомные гравер и прокидывать его во первых мы можем прокинуть политику интерфейса ресайза без политики интерфейса ресайза и в таком случае мы получим lookup таблицу там не будет разрешение коллизий и это можно сказать будет такой вот просто кэш мы можем покинуть им политику движение по хэш-таблицы с шагом больше чем один например использовать шаг 2 или какие то другие шаги просто проверить наши бенчмарки теперь что мы можем делать с состоянием ячейки в хэш-таблице вот например у нас мы храним хэш-таблицы большие строки и пересчитывать хэши для этих больших строк это не очень хорошо например в стандартных хэш-таблицы для каждого объекта который вы бы там хранили вы бы должны были обернуть его в такую структуру в которой лежал бы этот хэш и сохранять его туда не очень удобно у нас то сделано автоматически когда хэш прилетит в ячейку она его сохранить и затем будет отдавать хэш-таблицы при повторных обращениях так вот теперь пойдут секретные трюки это быстро очищаемая хеш-таблица представьте юз кейс у вас все не помещается в аллель каши у вас такая хэш-таблица пусть будет гигабайт и вы хотите ее переиспользовать если вы будете пытаться удалить все эти чеки вам нужно будет пройти по всей этой памяти это будет много пейдж болтов некое шлака льна очень плохо как мы можем сделать это так то есть удалить все элементы в хэш-таблице не удаляя их мы храним версию версию в ячейке версию в хэш-таблице и когда нам нужно удалить все ячейки из хэш-таблицы мы просто поднимаем ей версию а ячейка когда я буду спрашивать пустая я или нет будет сравнивать эти версии очень круто так теперь поговорим немножко про where you кэш мы можем в ячейке хранить их даже указатели мы храним ищейки то есть мы хотим реализовать политику каширование р.ю. и сделать трюк хэш-таблицу как она обычно делается мы используем два контейнера список и хэш таблица хэш таблица указывает своим значением на элемент списка когда происходит обращение ключу элемент списка двигается в конец когда кэш переполняется элемент удаляется и сначала но это ни к шлака льна поэтому мы решили сделать список прямо поверх хэш-таблицы для этого мы использовали библиотеку boost к сожалению весь код не прошел цензуру поэтому я оставил только самый маленький кусочек который собственно делает уже такую финальную подготовку мы вокруг нашей ячейки так как мы задекларировали next и previews pointer и bus сделал нам адаптер и поверх этого адаптера мы использовали интрузивные контейнеры из густо эти вот интрузивные контейнер и собственно говоря предоставляют тебе интерфейсы например списка но они не отвечают за выделение памяти то есть вы не контролируете память контролируете где располагаются элементы а получаете от библиотеки только алгоритмы так теперь немного про специализированная хэш-таблицы первая специализированная хеш-таблица это не хэш-таблица это массив который предоставляет интерфейс хэш-таблицы он маленький помещается в один кэш иногда все-таки мы его используем теперь немножко про хэш-таблицу для строк как вообще мы храним строки хэш-таблица мысе реализуемых в арену и в хэш-таблице лежит только указатель на эту арену но человек пришел один из наших основных контрибьютором из китая и сделал нам улучшение в этом месте он использует четыре хэш-таблицы для строк разной длины для строк маленькой длины используются одни хэш-функций а для строк большей длины другие хэш-функции и такая можно сказать завершающая часть из наших специализированных хэш-таблиц этот уловил хеш-таблица она состоит из 256 хэш-таблицы зачем такой вообще может понадобиться только если вы не фанат хэш-таблиц про из вот например мы хотим с агрегировать наши данные во много потоков мы создаем четыре таких тулы в хэш-таблице для наших для каждого из наших потоков мы в них пишем потом как это всем я жить мы могли бы придумать какие-нибудь системы смею так с нами сложные которое бы тормозили но мы держим это все бакетами то есть у нас получается такая матрица где каждая ячейка это хэш таблица и в этой вот матрицы мы можем по столбцам в заключение хотелось бы сказать что мы написали настоящий фреймворк для хэш-таблиц который подходит под многие из наших уст кейсов очень легко адаптируются бенчмарки есть на и есть у нас в ходе тут хотелось бы сказать что вот я признаюсь честно очень люблю хэш-таблицы но алексей сказал что любит их еще больше по этому человеку который сможет улучшить нашу хэш-таблицу и улучшить наши бенчмарки мы подарим ходе которых нет даже у нас они еще в разработке спасибо спасибо максим у нас есть время на вопрос можем минут десять подискутировать тебе от нас сувениры от организаторов highload все пожалуйста может поставить чтобы руках не мешались мой мир баритон все задавайте разговоре он включен сейчас выведут так нет нет сейчас замена микрофона даже тип это стекает вынесено нормальный микрофон еще раз здравствуйте спасибо за доклад меня также зовут максим у меня вопрос про конкурентность как вы обеспечиваете конкурентный доступ на чтение и запись у нас мы не используем lock free у нас нет лапы и хэш-таблиц мы не используем шарнира ванием you take some единственное что мы используем во много потоков этот уловил хэш-таблицы про которая сказал в конце мы вставляем во много потоков в отдельной хэш-таблицы имиджем их тоже во много потоков но по столбцам спасибо так следующий вопрос у кого микрофон типа сдавать поднимайте руки напоминает что у нас есть приз за лучший вопрос те кто смотрит нас онлайн можете нажимать кнопочку задать вопрос даже подключаться выведем вас на экран вы спросите итак третий ряд да спасибо за доклад каким образом происходит выбор между стеком аллокации на и в хеппи ну изначально у нас во локатора лоцируют в хеппи но вот я показывал специализированный локатор в нем например есть там 300 байт сначала они ассоциируются на стыке если ты выходишь за это количество дальше мы идем хит еще такой вопросик начальный размер сначала она решается больше чем в 2 раза вначале у нее вроде бы размер 32 и она ресайза в четыре раза потом начинает 3 садится в два раза спасибо так интересный алгоритмы на первом ряду были вопросы или вы задали расспросили так всего два вопроса у меня такой вопрос вот еще можно наверное 30 лет так за подтянут запоминать и выбирать лучшие будет потом от нас оффтоп какая машина лексин это секрет так и вот еще тогда вопрос вне основы вопрос про конкурентность используется для в бенчмарках тесты конкурентный доступ то есть например tale пешка из нескольких потоков в один и тот же ключ то скорее всего лишь и делал такие тесты я такие тесты не псом да держи микрофон это вообще очень интересный вопрос и супер интересные тесты у меня даже есть на ютюбе доклад под названием параллельный и распределённый группой но на всякий случай скажу осторожно этот доклад 2 часа если я правильно помню так что смотреть его не надо но там рассмотрена куча способов и основной вывод который сделан это то что чтобы сделать в параллельный грубой гораздо лучше когда у вас не какая-то одна хэш-таблица который может быть вот при хэш таблица или еще какая-то поддерживающая конкурентный доступ а лучше когда у вас сначала потоки используют каждый свою хэш-таблицу а потом идти своих хэш-таблицы можно параллельно мер жить а чтобы их правильно держать можно использовать 2 url его каждого в лицо 256 этих самых ячеек и каждый поток может выбрать какой-нибудь из них имя ржать и по секрету скажу что мы еще один способ придумали который еще будем разрабатывать чтобы еще больше всего ускорить секретный способ разработки потому что вот мы с максимом очень любим цементировать хэш-таблицы еще небольшого просит если можно вы сказали вас есть операции insert a варфейсе а есть какой-нибудь insert который сразу resizer ну чтобы быстрее круг берем все загрузить в таблицу вот если интересный вопрос у нас мы пробовали делать такие вещи а вы имеете ввиду insert они lookup именно insert нет на интернет но мы лука пробовали делать во много ну то есть с прежде чем у нас чтобы не подмена не попасть на каскад на решаясь да мы у нас в некоторых местах мы провоцируем все что мы сейчас будем закидывать и делаем так и у нас в разработке есть еще такая фича круто для грубая попытаться вычислить размер хеш-таблицы который будет чтобы не было ресайза до такой у нас планируется или есть сила"
}