{
  "video_id": "YuPJO90FUuw",
  "channel": "HighLoadChannel",
  "title": "7 петабайт логов в Elastic. Как мы это сделали? / Роман Николаев (Тинькофф)",
  "views": 2836,
  "duration": 3259,
  "published": "2024-04-17T01:10:23-07:00",
  "text": "Роман Тиньков погнали так зал еще наполняется давайте начнем материал будет много Всем привет Меня зовут Роман Сейчас я вам расскажу вкратце как мы в Тинькофф запихнулись семь петабайт логов и ластик кто-нибудь из вас использует ластик Поднимите руки Ничего себе Все так любят и ластик Ладно сейчас вам расскажу Окей Сейчас я вам все расскажу и рассказ будет вам очень интересный и даже если вы прилав не очень хорошо знаете будет небольшой ликбез получился такой трехлетний опыта сырья команды за 30 минут поехали вкратце немножко о себе Я уже войти Больше 15 лет начинал как системный администратор сейчас Сергей инженер успел поработать В РЖД промс банки И сейчас уже больше семи лет работаю в Тинькофф Что сегодня будет чтобы сказать про Ивасик нельзя не сказать про Sage потому что в нашем случае эластик это часть фиджа который находится у него под капотом И если мы хотим власти запихнуть много логов придется узнать как он устроен держитесь далее я поделюсь некоторыми архитектурными принципами для нашего большого хранилища когда мы его создавали Какие принципы и как мы ими руководствовались на больших объемах замена стандартных компонент стека у нас произошла я расскажу почему нас перестали устраивать стандартные компоненты в заключение советы и планы на будущее Окей как я уже говорил в начале в нашем случае ластик это база данных для хранения логов в она находится у него под капотом Давайте вначале быстро как же появился который типа это прокачивает и надо сказать что четыре года назад 2019 году еще у нас весь бизнес мониторинг все бизнес-показатели мониторились Планк спанг для тех кто не знает это такой эластик на стероидах заточенный подлоги и у него очень крутой язык запросов очень богатый что же у нас там было у нас там вы очень много логов и там сотен там десятков всяких систем использовалась естественно много даже бортов налогах Ну и естественно были аллерты Как вы догадались тоже налогах и тут такой план резко уходит из России в девятнадцатом году да уходит причем совсем лицензию нельзя продлить поддержку нельзя ничего нельзя Ну мы такие что делать посмотрели мы на рынок но я думаю что все бы примерно так же поступили хочешь поискать замену посмотрели мы на рынок в тот момент и не нашли ничего подходящего чтобы могло эту систему заменить поэтому мы решили сделать свою систему диалогов с авертами и всякими штуками примерно так стоишь и появился надо сказать что изначально задумывался для логов но в итоге вмещает себя и метрики со всех сервисов он уже решает такие задачи как собственно сборы метрик и логов и забросы к ним запросы мы делаем на собственном языке запросов потому что мы хотели как раз таки повторить тот самый богатый язык планка встроенный велосик этого не позволял у нас есть визуализация у системы есть свой в котором можно визуализировать данные по запросам и мы написали плагин для графан и также у нас есть alerting как без алертинга и богатые возможности для интеграции потому что тот самый поиск который мы сделали свой язык запросов Это поисковая фишка Она готова к любой интеграции не хочу это архитектурная схемка сиджа просто для понимания Где находится ластик все же успели найти он Вот про этот квадратик Сегодня поговорим опыт опыт эксплуатации наши показывает что да Нельзя просто взять и запихнуть очень много ластик не понимая как он устроен в рассказе будет много понятий за ластика поэтому сейчас быстро пробежимся и узнаем как он работает но вначале стандартный вопрос который системы был о чем мы собственно взяли васик они что-то другое прежде чем строить нашу систему для логов которые мы поняли что будем строить с нуля мы составили список требований к этой системе мы же умные ребята получился примерно такой мы хотели от этого на текстовый поиск потому что она текстовый поиск у нас был в планке на основе этого было настроено всего того много налогов что уже Мы хотели перенести будущую систему К тому же плана текстовый поиск это такая достаточно большая Свобода можно искать что угодно они только то что размеченная и так далее Это должен быть ресурс потому что мы бы хотели это в дальнейшем дорабатывать сами у нас всегда так хотим заканчивается как бы мы не хотели всегда допиливаем под себя думаю тоже так делаете мы бы хотели чтобы это могло быть установлено он премис Ну тут все просто мы хотим хранить свои логии у себя и регуляция Ну и кажется так будет проще эта штука Ну точно должна уметь горизонтально масштабироваться потому что я думаю вы тоже знаете что логи это такая штука которая становится этой штуки Все больше больше систем они плодят больше логов и в планке мы это тоже видели что становится только больше к сожалению меньше не становится Ну и в итоге Это должно стать заменой с планка Вот такие у нас были критерии посмотрели мы на рынок в девятнадцатом году и не нашли ничего лучше власти в тот момент К тому же в одной из наших команд уже была экспертиза по эластику причем они уже сделали это в кластерном режиме и казалось что мы делаем правильный выбор Итак Почему собственно мой ластик выбрали мы уже вроде поняли в качестве а Собственно как эта штука работает все любят этот мем Я тоже очень люблю но для васика по моно идеально подходит сейчас поймете основная единица власти это индекс Если вдруг то из революционных начал вспоминать что там за индексы бывают то тут не это другое в индексе есть данные Они разделяются на кусочки на шарды один Второй двадцать второй может быть много внутри каждого шарда находится Люси на индекс Ну и вкратце можно сказать что ластик это такая большая надстройка надо люсин внутри Люси на индекса тоже лежат уже собственно данные и они тоже разбиты на кусочки которые называются сегменты внутри сегментов уже лежат документы они в свою очередь уже содержат последовательность полей это как раз те самые документы которые мы туда в итоге пишем как-то Так примерно но устроено А дальше У нас есть несколько нот у нас же кластер должен быть власти устойчивой индексы в отличие от традиционных в отличие от всего выластики индекса это такая абстрактная сущность которая просто размазывается между нодами и об этом просто есть запись в состоянии кластера и там указано что shard просто лежит на одной ноге а другой шар на другой И это типа индекс все записали вот так устроен индекс это просто абстракция над шардами шарды Как видно бывает праймери и реплика реплик может быть несколько все зависит от вашего replication фактора Ну пусть нашем случае будет просто один правильно один реплика отличие на самом деле минимальное такое что сначала аллоцируется Праймари а потом реплика за ним и праймери не может находиться на одной ноге с репликой Ну тут шутка про бидон Вот и вот так вот это происходит они лоцируются потом туда реплицируются данные и вот так появляется индекс они размазываются по нодам Ну ноты их может быть много они объединяются уже в кластер Всё теперь вы все знаете про эластик стоишь Сейчас обрабатывает в Тиньков суммарный поток с нескольких дата-центров примерно три с половиной гигабайта в секунду и когда поток логов Уже становится большой могут быть проблемы вплоть до того что этим трафиком может захлебываться сеть поэтому нужна распределенная архитектура которая позволит с одной стороны сделать отказоустойчивость а с другой стороны если происходит какой-то отказ по системе будет какая-то понятная и минимальная деградация архитектурный принципы наши распределенной системы которые мы руководствовались примерно такие дата-центр Это значит что у нас минимум взаимодействия между содами то есть мы не переливаем логия из одного до центра в другой получается что где логи родились Там они остаются Там они живут вплоть до самой смерти Аминь кровь центровый поиск тут я думаю тоже догадываетесь Это значит что между дата центрами все-таки трафик какой-то есть но мы делаем так что он только поисковый то есть только поисковый запросы ответ мы делаем небольшие кластера и ластик Я часто вижу на докладах что есть какой-нибудь один дата центр или локация второй и в каждой локации или дата-центры делают один большой кластеры ластика и все загружает туда Мы со временем пришли к тому что мы делаем не один большой кластер а несколько маленьких дальше расскажу подробнее как мы к этому пришли сейчас пробежимся по этим архитектурным принципам начнем с первого дата передата центр заодно увидим на съемках Как устроен собственно процесс заливки данных есть много всяких сборщиков вектор и вот эти все клевые штуки собиралки Бывает такое что тревожка имеет сама напрямую писать влаги дальше этиология мы записываем в кафку у нас один кластер плавки на дата центр вот таким образом Кафка это Входная точка для системы как туда записать это решает наш клиент поставить или напрямую опять же из трешки или еще как-то дальше мы вычитываем эти логики нашей замены США про замену США Я тоже Расскажу чуть позже это как раз один из тех компонентов которые мы заменили вы читали мои этилоги обработали Да процессили и записываем собственно в эластике как-то так это в простом варианте работает Ну если это второй дата-центр там все то же самое понятно что дата-центров может быть много история легко тиражируется записью вроде все понятно да Окей молчание знак согласия тогда давайте посмотрим как в этом во всем делать поиск если у нас опять же дата центр данные уже лежат квасаревастика много кластеров там надо в них поискать мы как я думаю многие из вас Кто использует эластик мы используем эластик прокси кластеры это просто особым образом как правило небольшой кластеры ластика настроенный которого задач только одна в нем Нет данных он только проксирует запросы где Данные есть и объединяет результаты если они лежат в нескольких кластерах мержет и отдает обратно Окей Сверху над этим у нас находится наш поисковый движок который как раз с богатым языком запросов и все такое И он просто идет уже прокси-кластер и прокси-кластер за него делает пожалуй основную работу окей Все просто и Понятно До тех пор пока не появляется второй дата-центр и представим что у нас есть в квстрии ластика 1 dc1 и в таком же костере только в dc2 хочется поискать и там и там ну и данные получить не просто вот эти две пачки данных а чтобы они логически объединились мы тут сделали Так что просто прописываем в прокси-кластеры 1 Вот это центра хвосте рай ластика другого Тем самым у нас каждый прокси кластер смотрит во все кластер эластика пожалуй на данный момент это лучшее решение есть мысли что мы может быть когда-нибудь логику перенесем к себе в поисковый движок Ну вот пока вот так я думаю многие из вас Кто сталкивались похоже задачей сделали примерно так же Ну а дальше у нас есть кластер балансировщика он просто обеспечивает единую входную точку для нашего пользователя который эти запросы поисковой делает про небольшие кластера у нас когда-то был один большой костер ластик он как-то вот так выглядел тяжело ехал мы разделили один большой кластер на несколько маленьких и у этого есть плюсы у нескольких мастеров ластика маленьких противовес одного большого меньше Вектор поражения если у нас какой-нибудь деградация или проблемы в каком-то кластере у нас страдают только клиенты наша система мониторинга только те которые находятся в этом кластере и не задевает остальных если у нас один большой кластер эластика не дай бог он будет падать у маленького кластера логично что меньше то самое кластер стоит состояние которое хранит записи обо всех шортах маппингах и всем прочим все то что находится в кластере этим кластер стоит Там постоянно обмениваются все ноды в кластере соответственно от этого влияет то на это влияет что если этот кластер стоит какая-то нода не примет не обработает это надо скорее всего вылетит из кластера тем самым кластер работает менее стабильно чем больше у него кластер стоит в определенный момент ощущение было что он стал очень большой очень много индексов много клиентов это важно эта штука по итогу быстрее стабильнее работает когда Много мелких это наша было ощущение у этого подхода есть минусы к сожалению у Много мелких мастеров для них надо больше накладных расходов каждому кластеру кроме но с данными нужны мастерноды мы пришли опять же к тому что мастернода мы вынесли эту роль на отдельные Хосты иначе кластера плохо себя вели разваливались поэтому мастернод придется делать подскажет такой Мелкий кластер если чего-то больше надо сопровождать то это сопровождать как правило сложнее логичный вывод могут быть клиенты которые не влезают в такой кластер не влезают это Смысл в том что у наших клиентов внутренних мы их поделили на группы и у каждой группы мы выделили квоту то максимум сколько наш клиент может заливать логов Ну он бы хотел столько заливать и мы выдаем у кого-то если у нас есть такая возможность в один момент было такое что клиент попросил кого-то которая по размеру по нашему кпсисе не влезет ни в один кластер мы решили с клиентом это так и в дальнейшем так решаем что мы не выдаем квоту которая больше вместимости кластера Мы предлагаем разбить эту группу на две поменьше И тем самым обойти это и разнесем внутри в разные кластеры Давайте посмотрим как устроен примерно Из чего состоит наш такой стандартный кластер и ластика у нас есть три мастерноды отдельные узлы можно сказать что власти должно быть правило 50 плюс 1 должно быть минимум три мастерноды активный мастер который делалось работу следить за кластером и распространяет этот самый кластер стоит это пожалуй его основная работа он всегда один Несмотря на то что мастеров надо всегда как минимум три или больше все остальные мастера называются Мастер и лига был нот которые могут в случае если первый мастер потерялся или упал переизбраться и стать активными мастерами они такие запасные У нас есть ноды которые мы называем ход моды Я думаю Многие так тоже делают это такие быстрые SSD диски там побольше памяти и на них в первую очередь попадают данные там же они в первую очередь обычно же сразу же их надо поискать У нас их 10 можно сказать что от этого числа 10 мы делаем многие процессы например Мы распределяем те самые кусочки данных шарды максимально равномерно надо учитывать поэтому количество нот чтобы оно было делителем для количества шардов Ну и есть у нас ворм ноды туда данные переезжают остывать обычно это нужно когда данных Очень много они должны еще полежать возможно в них будут поиски может какие-нибудь интеграция сделать какие-нибудь отчеты на больших объемах и там уже диски медленные HD на шпинделях но тем не менее все работает но будет медленнее второй кластер или 22 будет выглядеть примерно так же мы также историю сделали такой тиражируемый Ну а сверху у нас находится прокси кластер как был ранее показано стандартные кластер для прокси это тренода опять же напомню в нем Нет данных он просто нужен для того чтобы проксировать запросы и объединять данные отдавать результат OK пробежались по эластику по стандартному кластеру практически сразу мы поняли что многопользовательская система в которой ресурс может закончиться он исчерпаемый для таких систем нужна квота какой-то лимит ограничения иначе такая система недолго проживет Потому что клиент любой может залить логами если у него нет ограничения сколько бы вы запас ресурсов туда не отложили любой может написать какой-нибудь клевый скрипт огромным количеством полей генерации логов и будет не очень смешно также без квотирования не получится планировать какие-то ресурсы системы кпсити planning так называемый непонятно сколько когда закупать сколько там дров подносить и сложно будет настраивать какие-либо подсистемы потому что обычно это является основой Какие шарды сколько их ретеншен Сколько хранить Где хранить когда переливать есть одна плохая новость власти конец встроенного механизма клотирования Действительно зачем какие варианты я много статей пересмотрел Но кажется что в основном все делают подобные вещи либо своими средствами в начале ставит какое-то ограничитель либо используют кафку на Кафки есть такая штука как вот и мы используем как Лотос для того чтобы ограничивать потому что Как Мы помним на съемке процесс заливки данных выглядит так что клиенту вначале Надо данные привести в кафку там же мы сделали некое ограничение по группам у каждой группы есть своя квота есть свои нюансы например в кафку к вам могут заливать влоги в сжатом и не сжатом виде Когда вы разожмете данные которые пришли в сжатом виде их может быть там X5 X7 там в несколько раз больше и надо будет придумывать как Этих клиентов наверное уравнять потому что на входе то они одинаково заливали и так это видят а потом данный разжимаются и для вас все меняется потому что Вам уже надо X5 залить власти вот да мы сделали накавки про замены Сейчас я вам расскажу в начале как Мы перешли sockstage на самописное решение опять же самый первый вопрос что него те кто использует стек И ластика это одна из тех букв которые сокращении у кого это такой комбайн который помогает при обработать данных что-то с ними сделать обогатить и записать власти часто он очень используется как раз для pipeline заливки но в итоге мы от него отказались у нас Он тоже был в пользу своего решения и у нас было на это ряд причин какие у нас были причины Он не умел в кластер А нам очень хотелось масштабировать горизонтально опять же Наш кейс наверное такой сложный нестандартный у нас много клиентов которые заливают влоги мы Этих клиентов поделили на группы и у каждой группы есть свой топик и мы хотели распределять Это между instaнцами нашей переливалки Стеша так не получалось и учитывать эту группу хотелось нам еще умную работу с эластиком Я думаю те кто использует ластик знает что он иногда может затупить если в этот момент когда эластик тупит его еще больше нагружать скорее всего ничем хорошим это не закончится ему его надо не перегружать мы хотели сделать такую обработку чтобы когда эластику плохо Мы его не перегружали мы хотели делать сложную валидацию полей потому что не только содержимое полей хотелось проверять но и количество еще мы хотели это делать в разрезе наших групп пользователей Ну и всякие такие штуки которых мы его к сожалению нашли и посмотрели Как это там реализовать показалось что проще написать свое Ну и в итоге Пятая причина это боль потому что она работала нестабильна четвертая причина да мы постоянно какие-то проблемы получали то Vox Stage перестает читать то перестаю записывать на разные ошибки ластика Он может реагировать не очень адекватно и любая валидация которую мы пытались туда сделать очень затратно получалось по ресурсам нам казалось что это просто не оптимальное решение как его оптимизировать мы не придумали показалось проще сделать свою опять же Итак что умеет наша замена она умеет Умно обрабатывать ошибки от эластик например она делает retrike когда есть не критичные ошибки как раз когда эластик затупил мы его можем притравить если все хорошо получилось то отлично Ну а если какие-то ошибки которые мы не можем в моменте обработать мы сделали специальный топики в Кафки я видел что многие так тоже делают и некоторые ошибки мы складываем в эти топики Это позволяет сразу перейти к следующей пачке логов и продолжать ее процессе все остальные лаги сложив в отдельное место до обработать потом тем самым Мы не там заткнулись они остановились на какой-то паре ошибочных логов У нас есть циркетбрейкер Когда эластику точно плохо прям совсем плохо эта штука закрывая заслонку и смотрит что ивасику стал лучше И постепенно не сразу все что было а постепенно увеличивать нагрузку и доливает то что осталось У нас есть встроенная защита от дублей кажется совершенно тоже есть Ну у нас тоже есть мы с кафкой работаем чуть по-особенному У нас консьюмер вот каждый топик Это позволяет делать быструю ребалансировку и в целом наши заменил США успешно работать кластеры потому что как показала практика если так не делать работает намного медленнее и переподключение балансировка скавкой занимает много времени еще наша штука имеет Я считаю Киллер фичу она фиксит работа с типами полей Что значит проблема с типами полей да такой наверное вопрос Если кто работает с ластиком он наверняка с этим столкнулся это достаточно частая проблема происходит она вот из-за чего когда мы создали индекс и записали туда какой-нибудь Лог и в нем есть какой-нибудь поле допустим в это поле попало им тот же какой-нибудь цифровое значение и следующий момент если прилетает Лог и в этом логике есть такое же поле с таким же именем и там например внезапно объект и ластик на это дело скажет Exception не совпадение типа полей и не будет это записывать это так работает динамический момент первое улетела Такой тип поля у нас и будет Что делает наша штука что делает обычно вручную как это обойти как думаете что с этим делать правильно что можно сделать надо от троллить индекс то есть закончить писать текущий индекс отложить его Окей что-то записалось создаем новый индекс и записываем туда первым логом тот самый Лог в котором те Поля с новым типом в нашем случае объект И тем самым эластик считаю что теперь все норму вот в индексе первое создалось по динамическому Пингу у этого типа Поле теперь объект можно писать все дальше с типом объект Но это да естественно работает Если у нас вот так вот не скачет также через один логи если у нас просто поменялся тип поле раз и навсегда можно это вот так решить собственно на что делает это в автоматическом режиме Она видит что типа поля поменялся видит эту ошибку она откладывает этот Лог ролик индекс создаёт новый пытается записать проблемный Лог который был с ошибкой типа поля заново в новый индекс все хорошо и оно всё едет дальше вмешательство не требуется наша штука легко масштабируется потому что мы изначально ее делали Как кластер можно просто ввести ноду она перестреляет между собой топики индексы сама с этим разбирается никаких там перенастройка особых не надо тем самым можно спокойно релизить по одной ноге выводить обновлять и так далее ну и добавлять много очень легко добавили Ну да Ну там само всё разберётся важный штука которая тут у нас есть это Грейс уж отдал важное вещь она важна тем что если резко бросить записывать данные на каком-то там части большая логи остановить и в кафке со все там забить ничего с ними делать то следующий раз когда мы запустим нашу замену Ок США она пойдет подбирать влаги она увидит логи которые еще не до записались она попробует записать их заново те части из батча которая уже есть она увидит что там есть дубли получит ошибки от эластика и это намного хуже работает закончить записывать то что мы уже схватили отпустить топики в Кафки аккуратно и При следующем запуске будет намного меньше проблем ошибок и запись реальная запись ластик пойдёт быстрее Ну в общем мы все это сделали наша Тула именно так работает Нам очень понравилось что мы не жалеем что мы это сделали Ну вот как-то так это работает вот мы записываем логин там мы откладываем в топике Примерно вот так это работает теперь про следующую часть которую мы переписали и заменили своим это сейчас расскажу заодно что это за буковки и расшифровывается как индекс менеджмент Он занимается тем что жизненным циклом индексов наш опыт показывает что в нашей системе мониторинга слогами большинство запросов по этим логам делается на интервале за последние часы ну максимум за сутки и через какое-то время логи можно переместить на более медленные ноды где более медленные диски но затем вообще Удалить Ну потому что я думаю что у всех логи хранятся не вечно обычно это не нужно примерно этим и занимается индекс стекол менеджмент власти он как раз проносит все данные через эти стадии и вы можно настроить на жизненный цикл какой-нибудь у нас он достаточно простой и коррелирует с тем как у нас живут данные Мы сначала записываем шарды на горячую ноду и данные потом через примерно 2-3 дня потому что мы еще там кое-что делаем эластики на быстрых нодах через два-три дня примерно данные переезжают на теплые ноды остывают нормы там как раз медленные диски HD на шпинделях и по умолчанию где-то через 14 дней это можно поменять для каждой группы отдельно данные переходят к удалению и все удаляются вроде все просто Почему И вам стандартный который может это делать почему мы его не используем чего же нам там не хватало не хватало нам например то что мы называем сезонность мы поняли что наш профиль нагрузки таков что у нас очень большая нагрузка на запись и соответственно поиски на чтение днем и она достаточно сильно спадает в несколько раз ночью это видимо связано с тем что логин плодят наши различные системы и в эти системы которые можем систему у нас пишут вообще любые балансировщиков до приложений Чего угодно кажется что сам профиль работает этих систем он больше дневной поэтому они платят днем и ночью у нас получается что на система менее нагружена и мы хотели побольше логов затолкать и решили делать разные процессы которые днем занимали ресурсы и мешали бы процессингологов мы решили их переместить на ночь поэтому нашем случае сезонность это день или ночь в самом простом варианте такая Мы например хотели мир жить ночью сегменты и перевозить тоже шарды потому что как оказалось межсегментов сегмент это слово из устройства эластика сегменты создаются изначально с не очень оптимальной структурой и когда данный уже записано если скомпоновать смерть они занимают намного меньше места на диске на диске Это не так важно Но самое важное что они занимают меньше месяца в памяти это значит когда мы заберемся по ним поискать нам будет намного легче опять вопрос про высокую утилизацию и мы хотели эти все тяжелые вещи делать ночью мы не придумали не нашли Как сделать в этой л.м в котором надо сказать настроек буквально несколько отрежь там закончить писать по размеру перевези или по времени примерно такое основной набор настроек нас есть нам хотелось чтобы у нас было и у нас В итоге это есть разные политики в зависимости от потока я периодически говорю что у нас много клиентов мы их побили на группы и эти клиенты эти группы бывают разного потока разного размера у них могут быть квоты от 100 килобайт до 100 мегабайт встроенный вы не умеет особенно не Как работать с потоком для него есть просто шарды индексы он их знает количество время когда создали вот есть там 10 штук таких я их перевезу сюда а то что эти 10 штук могут быть 100 килобайтным потоком забиты там чуть-чуть данных или 100 мегабайтным и там вообще огромный размер может схватить все по 100 мегабайт огромные объекты иногда мы хотели менять политику уже созданного индекса задним числом что-то внепланово перевести какие-то шарды когда может быть как антиградация или проблема была или просто там безопасники пришли сказали что надо что-то срочно перевести нам нужна была логика на основе содержимого индекса потому что ELM очень простой парень Он видит индекс когда его создали там тогда-то создали он отчитывает этот момент дату которую вы там указали там 14 дней От этого момента читал и перевезет А мы хотели смотреть внутрь и видеть когда там например последний раз был записан документы когда туда реально перестали писать потому что клиент может перестать туда писать И эта штука валяется не до конца забита и нам бы хотелось такое тоже учитывать и перевозить еще мы хотели распределить индексов опять же с учетом наших групп группы разные а мы хотели их потом класть на те же вармы в соответствии с группами чтобы не получилось так что у нас на одной ноте вармовой мы перевезли все данные какой-нибудь одной маленькой группы а на другую надо свалили все данные огромный большой группы и когда не дай Бог поиск пойдет на данный по большой группе они окажутся на одной ноте вся поисковая нагрузка туда Пойдет Ноги будет не очень хорошо но будет сильно жаловаться мы хотели это размазывать равномерно относительно клиента относительно группы в итоге мы сделали свою реализацию как я уже говорил с учетом разного потока клиентов и она от этого умеет отталкиваться и делать такие клёвые штуки что у нас разное количество шаров учитывается на индексах разные политики ротации мы что-то можно сказать мы реже ротируем и перевозим мелкие индексы и большие индексы почаще потому что любая операция чего-то стоит а мы хотели Как можно оптимальнее тратить ресурсы У нас есть свой алгоритм распределения индексов клиентов по кластерам что это такое у нас есть вместимость кластера мы эмпирически высчитали сколько туда может влезть влогов и у нас есть наши клиенты которых там сейчас около полутора тысяч по моему если не стала только что больше и мы бы хотели Этих клиентов равномерно распределить потому что как показывает опыт поместить два огромных клиента на один кластер и свалить тучи мелких на другой не очень оптимально надо помещать несколько буквально несколько больших клиентов и постепенно их размазывать более мелким клиентами вместе с большими мы поэтому наша Туле написали этот алгоритм он сам смотрит вместимость кластера смотрит какие есть группы и какие квоты выданы и равномерно это распределяет между кластерами если появилась опять же новая группа происходит перераспределение и он заново Может по-другому начать перекладывать данные и размазывать опять же более оптимально с учетом новой группы перераспределяет он еще шорты по Хот ворм нодом потому что стройные в м он там тупо раскидывает шорты по количеству или по времени и про поток опять же не знает и равномерную нагрузку делать не умеет мы умеем кто-нибудь пишет на Java Окей я чуть-чуть прям пишу вас Прям вообще столечко ну подводка такая и ластик написано Java Казалось бы мы тут привеласе к они про джала но при больших нагрузках даже это важно на чем написан ваш компонент сейчас будет еще немножко вопросов да вот есть у нас такие еще указатели сжато не сжатые они это очень внезапно сжатые указатели 64-битном варианте занимают два раза больше места И я И еще есть моменты сжатые указатели это расходы на операцию сжатия-разжатия Ну я думаю многие инженеры когда свыше своего сжатия они чувствуют подвох потому что что кто-то должен сжать потратить ресурсы кто-то потом рожать тут тоже самое Каждый раз когда мы Обращаемся к указателю мы тратим ресурс нажатия-разжайте Зато указатели это уже нами проверено требует больше ресурсов То есть зависит все конечно цифры от того как написан Java код Насколько часто используются указатели в каких случаях как мы часто к ним Обращаемся Но то что это влияет на производительность при наших объемах это такие большие цифры получаются это уже точно установлено процентов 5-7 может быть даже 8-10 зависеть от нагрузки Что будем делать У нас есть сжатые указатели мы тратим нажатие ресурса Что будем делать кого какие идеи правильно не использовать жертвы указатели все не Используйте же это указатели делаете 32 гига хит маленький кластер немного памяти меньше Но побольше мы не придумали ничего лучше мне кажется неплохо а что там на документация напишет надо использовать сжатые указатели когда падение производительности Происходит что там написано Ну возможно мы сделали неправильно мы могу сказать не всегда идем по документации потому что по документациям один раз четко прошли и что-то не Все сходится у нас почему-то документацией на наших объемах Вот это Наш кейс я не агитирую ну нам показалось что так будет хорошо нам точно стало лучше производительность выросла в конце давайте подытожим у меня есть несколько советов по итогу надо сделать квотирование если у вас многопользовательская система вам тоже надо много заливать логов надо сделать квотирование иначе кто-нибудь вас зальет не делайте большие кластера Я думаю что кто-нибудь сейчас тоже скажет А у нас там и в документации написано Вполне возможно что это не ваш кейс но нам показалось что маленькие костера много маленьких работает стабильнее и лучше большой это где-то 50 нот уже начинается Ну да количество нот там как получается вариативность кластер стоит в нем написано на какой ноте какой шарф с каким апингом если у нас множитель любое увеличивается много индексов или много нот это циферка большая становится вот такой кластер стоит и много процессов этих связанных надо много данных переместить и наверняка будет еще сложнее если у вас не просто ход War А еще там несколько стадий будет еще много ресурсов тратиться Да по-моему у нас где-то такой как раз был большой кластер живом хит меньше 32 гигов вычеркиваю на всякий случай как будто этого не говорил лучше почитаем документации может действительно это неправильно но у нас это сделано так следующий этап Советов мы вынесли мастерноды на отдельные Хосты вначале у нас опять же для оптимизации чтобы не выделять отдельные Хосты мы в начале мастера ноды поместили на вармы у нас там не очень большая нагрузка туда только на данный отвести они там полежат есть ряд запросов которые там выполняются но сопоставимо с хотами намного меньше нагрузки и нам казалось что у нас есть запас мы можем эту роль там сделать мы там тоже сделали там выделили из 6 7 8 ходов нет три штуки и сделали их мастернодами как показала практика даже набор может прийти какой-нибудь запрос или что-то случится или какой-нибудь шаг долго едет забивает ресурсы и случайно там оказывается активный Мастер и кластер разваливается вот мы решили вынести по документации опять же написано что лучше выносить и в какой-то момент мы поняли что да Мы точно уже готовы выносить и мы вынесли отдельные мастера сделали надо равномерно раскладывать шорты по нодам тут я уже рассказывал если свалить все шарды не оптимально туда придет как они поисковая нагрузка или запись и это надо будет отдаваться за весь кластер мы не придумали ничего лучше как ри стартовать и ластик ноды когда они залипают кто Чем может тут может я на самом деле полностью открыт всему новому кто что делает если у него залипла нода видно по показателям клеводы на SR E точняк 70 Несмотря на то что мы кажется много всяких штук сделали У нас есть планы на будущее Мы хотим сделать более жесткую схему данных Для чего нам кажется что это позволит точнее прогнозировать нагрузку например когда может случиться Так что кто-то пришел наши клиенты написал очень большое количество полей влогах количество полей там тоже документация написано сильно влияет на индексацию и за этим тоже надо следить там по умолчанию есть ограничитель все его обычно поднимают потому что кто-то сразу него уперся мы не всегда на это Идем в какой-то момент мы решили остановиться и на больших клиентах кажется что это принесет профиты и какое-то ожидание мы может быть даже перенастроим под них мастера по другому Когда увидим что мы не индексируем все не нужно более жестко когда будет схема еще мы хотим отключить индексацию всех полей по умолчанию это на самом деле внезапно Но может даже логично и ластик по умолчанию индексирует все зависит опять же от настроек Ну как правило самым простом варианте в дефолте он все поля индексирует Мы со временем не сразу поняли что пользователям не нужны все поля часто бывает такое что логия есть несколько полей которые несут какое-то полезное суть ошибку текст ошибки по нему можно поискать что-то найти Может быть аллер ты даже настроить хотя мы стараемся чтобы весь мониторингертинг строился больше на метриках но есть какая-то полезная часть мне действительно есть смысл искать ее значит можно индексировать остальная часть какой-нибудь Еще какой-нибудь там текст там Play новый записался он нужен как контекст дополнение то есть мы нашли по основному полю инфу открыли ок и глазами уже прочитали что-то с нами даже наши многие клиенты согласны Мы думаем над этим очень сильно Это точно разгрузит индексацию прям гадалки не ходи У нас есть несколько идей мы пока только идеи только пока думаем нам хочется автоматически блокировать проблемные запросы проблемные запросы не вошли в доклад К сожалению я боялся что не успею в тайминг проблемные запросы для нас было тоже поначалу открытия можно взять и сделать поисковый запрос власти которого настолько сильно загрузит что он может начать себя очень плохо чувствовать и перестать даже писать логи идея такая что какой-нибудь поисковый запрос который у нас появляется мы его выполняем один раз видим что проблема фиксируем эту проблему проблемы наверное эмпирически выясним какой метрикой вычислим потом это происходит второй раз третий наверное на каком-нибудь окне и система это может обнаружить и автоматически занести такой запрос карантин будет автоматическая блокировка таких запросов можно по этому вертеть дежурному оповещать находить клиента его вертеть и все такое еще у нас есть идея что в случае когда вдруг на эластике случаются проблемы деградации Не дай Бог сбой Мы хотим научиться переключаться на запись свежих логов потому что по умолчанию Я думаю многих система построено что у нас есть на кавке логе мы их читаем сдвигаем у нас происходит проблема например там какой-то там пару часов есть у нас недоступности а логика продолжают заливаться должок Копится и это надо все потом Вычитать система заработала она начинает это дальше перебирать записывать логи но как показывает наш опыт и наше видение кажется что клиентам хочется Даже если была проблема И они там что-то хотят влогов посмотреть понимаю что у нас там был сбой они дожидаются когда все заработало им хочется прямо сейчас видеть свежий логе понятно что мы там где-то логично в капке лежат их надо записать у нас там есть должок Но как правило многим хочется видеть свежие логи в этом есть идея что мы например там этот офсет там куда не записываем вот отсюда должок считаем как только система заработала мы заберем самые свежие логики по времени можно посмотреть записываем их наши пользователи ищут многие у них внезапно на последнем каком-нибудь интервале в час полчаса сразу логики свежие появляются они довольны А мы потом постепенно фоне это дописываем весь должок такая вот идея Мы кажется выжили из эластика все что можно неплохо с ним порой страдали и кажется что мы не знаем уже что с ним можно поделать Может быть там вот с хитом 32 гига чего не сделаем переделаем и мы пришли к тому что мы хотим перейти на собственную базу данных для хранения логов потому что эластик он изначально же не задумывался для логов это просто кто-то давок кажется записал один прекрасный момент увидел что по нему можно еще поискать его клёво и все начали использовать эластик для логов но в нем очень много фичей которые для логов не нужны там например можно изменять документ но я думаю никто не будет менять его записанного Кому это надо это даже как-то логически неправильно такие факты их нельзя менять и много всяких вещей там есть которые как правило не особо можно отключить но они работают тратят ресурсы И тем самым получается что этот инструмент не самый идеальный для логов А мы хотим уже сделать что-то максимально идеальное потому что нагрузка растет а мы хотим на те же ресурсах обрабатывать еще больше логов причем кратное на эластике мы не придумали как это сделать Мы решили писать свою базу данных на замену есть некоторое количество ссылок мне не показались интересными важными книжка с красным ветром и сжатые указатели все такой пластика есть хороший Бог там про шарды все написано очень здорово я не смог это запихнуть доклад Мне кажется уже выше стаминга Я не знаю пока что с этим делать Наверное я сделаю может быть какую-нибудь статью где там будет там фу вершин включусь да то что уже было и добавлю то чего я не успел У нас есть свой формат логов что мы там требуем И как мы валидируем там тоже много интересного как этого лидировать особенности динамического маппинга Как он может вас немножко иногда обманывать вы кстати за сенсив данными смотрите вам влоги наверняка прямо сейчас кто-то заливают всякие токи на пароли что-то никто руку не поднимает есть молчит Вот да мы смотрим за ценности в данными на потоке автоматически и наши безопасники это сразу обнаруживают и всех в безопасности ломающие запросы очень интересная тема мне кажется можно там отдельные 20 минут про это тоже посвятить как мы с этим боремся как мы обнаруживаем и как они могут интересно ломать какой-нибудь там f-сессию можно устроить мы используем мы то есть Таким образом мы не пытаемся дублировать данные за счет рейда тоже могу потом будет как-нибудь рассказать Я очень люблю мониторинг я сам инженер по мониторингу У меня написано Но вот мониторинг пришлось вырезать не хватало времени у нас есть стандартные метрики и есть кастомные Тулы есть кастомные метрики все кастомное там тоже очень интересно как мы следим за переездом шардов как мы ловим проблемы какие мы видим засечки интересные тоже обязательно про это как-нибудь напишу расскажу так вот вы знаете что делать Всем спасибо Спасибо большое это был мастер класс Как сделать 3 доклада за время одного К сожалению время друзья закончилось поэтому те кто Двое крикнули в середине доклада Подойдите пожалуйста замерчом одному футболка второму чашка и сейчас берете спикера идете в кулуары и там за лучший вопрос получите книжку все что не успеете Напишите пожалуйста в чатик зала Тинькова проконтролирует чтобы Рома на все ответил увидимся на тех токи через пять минут спикеру подарки от конференции погнали дальше"
}