{
  "video_id": "on2yVvKejwc",
  "channel": "HighLoadChannel",
  "title": "Отладка и устранение проблем в PostgreSQL Streaming Replication / Алексей Лесовский (DataEgret)",
  "views": 4150,
  "duration": 2952,
  "published": "2018-07-19T04:59:23-07:00",
  "text": "меня зовут алексей лисовский я администратор баз данных компании дата и град и ближайшие 40 минут я буду рассказывать вам про отладку и устранение проблем в пожгли сколь стремена рипли гейши как я уже сказала я рисовые дыба и одной из любимых тему в подписи мне нравится именно потоковый репликация и работа со статистикой поэтому я буду рассказывать именно о статистике как с помощью статистики искать проблемы и буду рассказывать вам в этом как выглядит наш план сначала будет немного теории поднимите руку кто знаком с вас grease овой репликации кто использует ее кто не первый раз отлично супер много рук отлично дальше расскажу о средствах которые есть в паз грехи какие предлагают сообщества тоже немного задержусь о том что предлагает нам позарез и какие инструменты можно использовать и основной третий раздел это как раз trouble судим кейс с какие бывают проблемы какие у них симптомы как решать эти проблемы и какие меры нужно принимать чтобы этих проблем не возникало ну и последнее это итоге вопросы и ответы и зачем все это нужно этот доклад о нужен для того чтобы вы смогли лучше разбираться в потоковой репликации чтобы вы знали как она устроена как искать проблемы как быстро на них реагировать чтобы сократить время реакции на эти проблемы на инциденты и если вам понадобится эти слайды вы можете перейти по этой ссылке и у себя на устройствах там на телефонах и планшетах их просмотреть итак поехали немного теории ли как работает под грязцова я репликация в подписи есть такая сущность как врать-то hotlog или его еще называют их слог это журнал транзакций все изменения почти все изменения которые происходят с данными внутри базе внутри базы данных они записываются в этом журнале транзакции все изменения данных сердце изменения метаданных все выпадает журнал транзакций и так обеспечивается надежность если вдруг произошла какая-то авария пузыри запускается он читает журнал транзакций и эти изменения восстанавливает на данных так работает надежность это очень крутая штука в подписи журнал транзакций пишется двумя способами по умолчанию все бренды когда делают какие-то изменения в базе insert и апдейт убили ты все изменения фиксируется в этом журнале транзакции синхронно клиент отправил команду commit на подтверждение данных данные пошли фиксироваться в журнале транзакций как только фиксация произошла управление дается бэг-энда backend может дальше принимать какие-то команды от клиента второй вариант это а синхронная запись журнала транзакций когда отдельный выделенный процесс вал райтер он с определенным интервалом времени пишет изменения журнал транзакций и за счет этого достигается некоторое увеличение производительности бэкон дав им не нужно ждать когда завершится команда commit и самое важное это то что потоковая репликация как раз таки основана на этом журнале транзакций у нас есть несколько участников потоковой репликации это мастер где происходит все изменения и несколько реплик которые принимают журнал транзакций от мастера и воспроизводят все эти изменения уже на своих локальных данных это в общем то потоковой репликация и тут стоит еще помнить что все журнал транзакции все сегменты 16 мегабайт нее файлы они хранятся в каталоге пгк слог и в десятой версии разработчики перевале этот каталог покрывал потому что побег слог иногда путают слугами и удаляют его потому что он вместо много занимает и становится все плохо продолжаем дальше если мы посмотрим на с точки зрения операционной системы на процессы которые запущены под гриссом в подписи есть несколько процессов со стороны мастера это будет вал сендер это процесс который отправляет журналы транзакций репликам на каждую реплику будет свой вал сендер который будет отправлять журнал транзакций на реплики свою очередь запущен вал ресивер который по сетевому соединению отвал сендера принимает эти самые журнал транзакций передает их старта процесса стартап процесс читает их и воспроизводит на каталоги с данными все эти изменения которые прилетели по журнал транзакций схематично это выглядит примерно так есть вал буфера где прессы fix записываются изменения которые потом вот записаны в журнал транзакций они находятся у нас на хранилище у нас есть вал sender который читается хранилища журнал транзакций передает их по сети вал ресиверах принимает сохраняют у себя она стороны и потом стартап процесс уже их читает все что там принято и воспроизводит все довольно просто схема простая и только верификация работает довольно таки надежное много лет уже эксплуатируется очень прекрасно следующий пункт это какие средства какие утилиты предлагают сообщества либо воскрес для того чтобы как-то расследовать проблемы возникающие с потоковой репликации и я начинаю со сторонних инструментов это утилиты довольно универсального плана ими можно пользоваться не только при расследовании инцидентов связанных с потоковой репликации это вообще утилиты любого системного администратора ли мак слово это топ из пакета процесс в качестве топ в виде замены ток можно использовать любые утилиты типа a top и чтобы подобные они предлагают похожие функционал дальше и as that is packed assist от и и о топ это утилиты показывают утилизацию дисковых устройств и какое о создается процессами в операционной системе next от это аналог и остаться только для сетевых интерфейсов можно смотреть утилизацию интерфейсов пока центр это утилита для работы только с под грифом она показывает показывает статистику подрисовываю в таком в топ подобном интерфейсе и можно смотреть также статистику связанную с потоковой репликации в этой утилите и перф это утилита для более такого глубокого расследования чьих-то причин подземных стуков когда какие-то непонятные проблемы на уровне кода под gresso происходит в эксплуатации и немного поподробнее топ что мы ищем топом это утилизация процессоров средняя нагрузка и использование памяти и slope что мы ищем с помощью частота это утилизация хранилища сколько вепсов нас данный момент какая пропускная способность трупу то какой сейчас да на устройствах какая утилизация какой light in se то есть там довольно-таки подробная информация берется из прог файловой системы и пользователь уже предоставляется в таком в наглядном виде next от аналогичная ситуация мы видим утилизацию интерфейсов какие-то ошибки которые возникают на интерфейсах пропускную способность тоже очень полезная утилита пока центр там статистика по репликации можно ставить лах репликации как-то оценивать его и еда на дальнейшие работы мы первые то подземные штуки то есть там нужны дебаг символы для подвеса и можно уже смотреть прямо стык функций которые там в процессах и какие функции занимают больше всего процессор на во времени все эти утилиты они нужны чтобы когда мы ведь рабу шутим что-то у нас появляются гиды гипотезы где что тормозит где что нужно проверить и утилиты они помогают нам проверить наши гипотезы и удостовериться на правильном ли мы пути дальше есть встроенное средство что предлагает нам сам адрес вообще средств для работы с под крестом довольно много и каждая компания которая предоставляет поддержку либо vendor пожгли со они предлагают разные свои средства но как правило все эти средства они основаны на внутренней статистике под gresso и в этом плане пост представляет системные представления так называемые view куда мы можем делать различные select и и получать оттуда информацию то есть нужен обычный клиент как правило это ps quelle и мы с помощью него можно делать запросы смотреть что происходит на статистике также исполнительные функции мы можем с помощью этих функций брать данные из статистических у этих системных представлений и в более удобном виде как-то их для себя представлять уже и есть также утилита провал дам до версии 10 0 она называлась побег слог дамп вообще в десятой версии все системные представления все утилиты которые включали вся слова ics lock были переименованы вал то есть побег с лордом стал побивал дампом и также с функциями и с верхами то же самое произошло порвал дам нужен когда нам нужно заглянуть в сегменты журнала транзакций когда у нас есть просто какой-то сегмент мы хотим посмотреть какие ресурсные записи куда попали и и что после суда записал то есть для более такого же deep inspection системные представления и есть их довольно много и для того чтобы как то работать с потоковой рипли кации сливать проблемы нам нужны лишь просто трип ликей шин по гост отвал ресивер просто дтп за своего стада базис конфликт и вспомогательные юхи и погас атаки типа гастер кавер то есть их немного этого набора нам в общем-то достаточно чтобы посмотреть все ли хорошо либо проверить нет ли каких-либо проблем вспомогательная функция их тоже всего несколько штук буквально 45 и самое нужное это пгк rental lsn и старый и аналог пока корр yandex logo локейшн что это это функция позволяет посмотреть текущую позицию в журнале транзакций то есть журнал транзакций это непрерывная последовательность каких-то данных и с помощью этой функции можем посмотреть вот последнюю точку получить позицию где сейчас у нас журнал транзакций остановился last вал рисе well as in last x100 красив locations это аналогичная функция вот вышеупомянутые только для реплик то есть реплика получает журнал транзакций и мы можем посмотреть позицию журнала транзакций у последнюю полученную то есть ну примерно то же самое что и пгк жертва уилсон только для реплика другая полезная функция тап и goval elsen div мы передаем ей две позиции журнала транзакций она показывает нам div она показывает нам дистанцию между этими двумя точками и она показывает это расстояние дистанцию на показывать нам в байтах то есть эта функция всегда полезным для определения лога между мастером и репликами в байтах полный список функций можно получить вот такой мета командой можно в по иску илью набрать и показать все функции которые содержат себе валик слагалась in locations да то есть там функции будет может быть где-то около 20 и 30 и они тоже представляют различную информацию по журнал транзакций рекомендую ознакомиться по городам для чего он собственно утилита просто декодирует содержимое их слог сегментов в человека понятном формате мы можем посмотреть какие ресурсные записи так называемый ресурсные записи попадают в процессе работы после со попадает журналы сегмента какие индексы были изменены какие хип файлы были изменены какая информация предназначена для стендбай туда попало есть очень много информации там попадают и можно вот значит смотреть эту информацию с помощью покрывал дампа но есть такая оговорка она написана в официальной документации типа голдом может показывать чуть-чуть неверные данные при работающем подписи все это связано не знаю ну не сталкивался и вот такой командой можно воспользоваться вот я ее записал это аналог команды tail минус f то есть она показывает хвост журнала транзакций которые вот прямо сейчас происходит то есть можно запустить эту команду она выполнит значит найдет подавал file name последний сегмент той записи и журнал транзакций которые вот сейчас прямо самое последнее подключиться к нему и начнет прямо с него показывать вам содержимое журнал транзакций такая немного хитро команда но тем не менее на работает я часто пользуюсь дальше основе часть нашел доклада trouble h1 кейс с проблемой симптомы и диагностика здесь я буду рассматривать самые частые проблемы которые возникают в практике вот нас consult rafet на у нас консалтинговой компании кики часто проблемы возникают это прежде всего лагере приказ и это вот наиболее самая частая проблема даже я не поленюсь у нас буквально час назад с докладчиком о с заказчиком была переписка у нас сломалось рипли catia мастер slave между двумя серверами смотрю окей так обнаружил лак два часа запущен по годам то есть там нас сотрудник посмотрел определил да п годам ок понятно какой у нас допустимый лак 16 часов в maxthon buy стриминговый не знаю почему именно такой а что случится ли этот лак будет превышен свой сирена нет крепится транзакции и накатка валов возобновится то есть это вот последнее сообщение 1006 это было ну час пятнадцать назад то есть проблемы с лагом репликации нас бывает постоянно и чуть ли не каждую неделю мы решаем там эти проблемы другая проблема возникает реже это распухание каталога где хранятся сегменты журнал транзакций побивал либо побег слог старых версиях тоже часто довольно таки проблема и с ней часто бывают нужны какие-то немедленные действия делать чтобы проблема там не превратилась в аварийную круто ситуацию когда реплики отваливаются следующая проблема это связано с долгими запросами которые выполняются на реплики и которые привод конфликтам и восстановление то есть ситуация когда мы на реплику пускаем какую-то нагрузку на репликах можно выполнять читающие запросы и в этот момент эти запросы мешает воспроизведению журнал транзакций возникает конфликт ip адресу нужно решить ждать завершения запроса либо завершить этот запрос и продолжить воспроизведение журнал транзакций это конфликт конфликт арии приказ или конфликт восстановления тоже такое байт и последний кейс это когда процесс восстановления журнал транзакций на ребенка занимает 100 процентов процессор на во времени это тоже такая редкая проблема но от нее бывает много проблем и очень сложно их расследовать и первый пункт это лаги репликации что такое лак репликации и тогда у вас один и тот же запрос выполненный на мастере на реплики возвращает дать разные данные это значит что данные как бы не консистентные между мастером и репликам репликой и есть какое-то отставание то есть реплики нужно часть журналов транзакций воспроизвести чтобы догнать мастера ну основной симптом выглядит именно так то есть есть запросы они возвращают разные результаты как искать такие проблемы есть основная йух apps to the replication она есть на мастере она есть на репликах она показывает информацию по вал с интером то есть по процессам которая занимается отправкой журнал транзакций для каждой реплики будет отдельная строчка которая показывает статистику по именно по этой реплики и положительная функция поигрывал сэнди она пока позволяет сравнивать нам разные позиции в журнале транзакций и вычислять тот самый лак то есть мы можем уже получать какие-то конкретные цифры и определять где у нас большой лагерь и маленький и уже как-то реагировать на проблему серьезная проблема или несерьезная также есть функция появилась зигзаг реплей time stamp эта функция работает только на реплики и она позволяет посмотреть время когда была выполнена последняя проигранная транзакция то есть есть всем известная функционал которая показывает текущее время мы из функции на у вычитаем время которое нам показывает этой функцией получаем такой лак во времени но в десятой версии получил пфп goes to trip летишь на появились дополнительные поля которые показывают временной лаг уже на мастере поэтому этот способ через старую функций такой уже устаревший но тем не менее его можно использовать и есть небольшой такой подводный камень если у нас мастер неактивен какое-то долгое время да он не генерирует журналов транзакций то вот эта функция 2 она будет показывать увеличивающейся лак то есть на самом деле система просто простаивает на нее нет никакой ценности но в мониторинге например мы можем видеть что лак растет этот такой подводный камень про неё стоит помнить юг это выглядит следующим образом она содержит информацию по вал sindrom и содержит несколько важных для нас более это в первую очередь плантатор это адрес сетевой адрес подключены реплики это как правило ip-адрес какой-то и набор полей lsn старых версиях он называется locations мы разберём их там чуть дальше я при не буду рассказывать и в десятой версии появились поля лак это отставание выраженная во времени то есть такое более человека понятный формат flac может выражаться либо в байтах либо во времени то есть тут вы уже выбирайте что вам больше нравится и как правило я пользуюсь вот таким вот запросам это не самый сложный запрос который выводит пгс то треплите шин в более таком удобном понятном формате что здесь в первых я использую функции волос n div чтобы считать div и но между тем я считаю div и у нас есть несколько полей такие как сын тела сын в atlassian плашил сынри place in то есть высчитывая div между текущими предыдущем полем мы можем точно понять где у нас произошло залипание где у нас конкретно лак происходит и мы используем функцию corinth волосин она показывает текущее положение журнал транзакций то есть мы смотрим положение между текущим журналам и отправленным это сколько журналов транзакций сгенерировано но не отправлено дальше у нас send lsn в рай тсн это сколько отправлено реплики но не записано то есть это где-то на в сети там находится сейчас либо оно получено реплика и где-то в сетевые буферах может быть но еще не записано на дисковое хранилище в рай tsm и флаш или сын это записано но не было выпущено команды в sing то есть она как бы записано но она может быть находиться где-нибудь в оперативной памяти в . операционной системы как только мы делаем их sing данное синхронизируется с диском данные попадают на percent нагрели щ и вроде бы все надежно и последнее это реплей lassen и flash и лосин то есть данное сброшены за сянган и но не воспроизведенной репликой и последний самое последнее это общего между corinth волосины репеллента есть какая-то такая некая суммарная суммарный лак в который включает в себя все вот эти вот все зодиак позиции и не много примеров от которые здесь изображены реплика 668 у нее pending лак то есть она на генерировала какие-то журнал транзакций но они все еще не отправлены они лежат на мастере вероятнее всего здесь какая то у нас проблема сетевой производительностью может быть там затык сети мы будем это проверять с помощью утилиты next от мы запустим никс от посмотрим утилизацию интерфейсов нет ли там проблем нет ли там ошибок них сорта все показывает и мы можем эту гипотезу проверить правда это или не правда следующий лак это в right на самом деле этот флаг очень довольна таки редкий я практически не вижу чтобы врать лак был когда-то большими большими цифрами он как правило всегда небольшой здесь проблема может быть либо с дисками и мы используем утилиту росстат и либо а я топ мы смотрим утилизацию дисковых хранилищ мы смотрим какое его создается процессами и дальше уже смотрим почему flash и реплеи это наиболее частые наиболее частые кандидаты лога чаще всего лак бывает именно там когда дисковое устройство на реплики они не успевают просто проиграть все те изменения которые прилетают с мастера и также мы смотрим утилитами areas that a о том что происходит у нас диска утилизации и почему тормоза и последнее это то thalac это такая полезная метрика для систем мониторинга то есть мы мониторим запихиваем to the lock если у нас там порог превышен на мы поднимаем флажок и начинаем расследовать что же там у нас происходит то есть вот таким запросам можно смотреть что происходит и как мы дальше исследуем то есть я уже сказал если это сетевой лаг мы смотрим все ли у нас в порядке сеть в первую очередь это ошибки потому что сейчас у нас практически все хвост или предоставляет 1 гигабит 10 гигабит это уже тоже реальность поэтому полоса , полоса пропускания это самый маловероятный сценарий как правило нужно смотреть на ошибки next от содержит информацию по ошибкам и интерфейсах можно это все смотреть и уже разбираться что у нас там проблемы с драйверами может быть какие-то либо проблемы с сетевой картой самой либо с кабелями там какие-то проблемы проблема в хранилище мы исследуем с помощью аист от и а это аист от нужен для просмотра общей картины связанные с дисковыми хранилищами утилизация устройств пропускная способность устройств light in se а этот уже для более таких точных исследований когда нам нужно выбить какой из процессов грузии дисковую подсистему если какой-то сторонний процесс мы можем просто его обнаружить завершите возможно проблема исчезнет то есть вот эти две утилиты они используют для проверки гипотез связанных с дисковой производительностью задержки восстановления и конфликты репликации мы прежде всего смотрим через топлива по гост от activity мы смотрим какие процессы у нас запущенные какие запросу нас сейчас работают время их выполнения как долго не работают если это кино долги запросы мы смотрим почему они долго работают отстреливаем их разбираемся с ними оптимизируем ну исследуем уже сами запросы если какой-то большой объем журналов транзакций которые генерируются мастером мы можем это обнаружить кпг startactivity может быть там какие-то backup иные процессы запущены там bk бьется копии он затормозил вакуум у нас какие-то запущенные они генерируют лал либо это чекпоинты может какой-то выполняться тоже может быть в этом проблема то есть если у нас генерируется большой объем журналов транзакций и реплика просто не успевает его обработать в какой-то момент она может просто отвалится и это будет уже проблема для нас ну и конечно покрывалась indev для определения лога и определение где у нас конкретно лак находится в сети на дисках либо на процессорах какие могут быть варианты решения тут довольно таки все просто и с точки зрения конфигурации это как правило не решается можно подкрутить некоторые гайки но в целом либо мы проверяем workload какие у нас запросы может быть это какие то миграции сейчас запущены которые генерируют много журналов транзакций либо может быть это какой-то перенос данных удаления данных или вставка данных то есть любой процесс который генерирует журнала транзакций он может приводить к лаку транзакции то есть все данные они на мастере генерятся как можно быстрее то есть мы asap сделали изменение данных отправили на реплику исправиться реплика или не справиться это уже как бы мастера не волнует и здесь может появиться лак нужно с ним делать либо самый тупой вариант возможно что мы уперлись производительность железо и нужно его просто менять этому какие-то старые диски и либо некачественная sd-карта мирские ну то есть тут и бомбит азаттык в производитель стирает контроллера то здесь мы уже исследуем уже не саму базу проверяем производительность наших железок задержки восстановления если у нас конфликты какие-то репликации возникли мы первым делом отстреливаем долгие запросы которые у нас работают на реплики потому что они задерживают у нас воспроизведение журналов транзакций если и такие-то долгие запросы связанные с не оптимальности самого искали запроса к там кривые планы мы видим до нужно просто подходить по другому к этому запросу переписывать его либо есть вариант настройки отдельные реплики для отчётных запросов если мы это отчеты делаем которые долго работают их нужно вносить на отдельную реплику или вариант просто ждать если у нас какой-то лак на уровне нескольких килобайт десятков мегабайт и мы считаем что приемлемому просто подождать когда запрос выполнится и лак само рассосется это тоже варианты часто бывает что он помогает если мы генерируем большой объем журнала транзакций нужно уменьшить этот самый объем генерируемого журнал транзакций в единицу времени до что есть нужно сделать так чтобы реплики нужно было меньше журнал транзакций прожевывать как правило это делается либо с помощью конфигурации есть такой параметр full поезжу rights но это частично и такое решение что делает этот параметр он включает запись полных образов страниц изменяющихся в журнал транзакций то есть когда у нас произошла такая служебную операция как чекпоинт контрольная . последующее изменение какого-то блока данных в жареной памяти в журнал транзакций ует полный образ этой странице они только вот самоизменения все последующие изменения этой странице журнал транзакций будет попадать только дельта то есть после чекпоинта мы записываем полный образ странице это сказывается на объеме зэки самого журнал транзакций если чек-поинтов единицу времени довольно много допустим у нас сейчас делается 4 чекпоинта и полных образов страницу нас будет записываться тоже очень много это будет проблемой то есть можно отключить запись полных образов и это скажется на объеме вал мы уменьшим объем генерируемых объемов но опять же то такая полумера другая полумер это увеличить интервал между чекпоинтами по умолчанию чекпоинт делается каждые пять минут и это настройки она очень маленькая как правило этот интервал увеличивают до 30 минут 40 50 час то есть это вполне приемлемое время для чек-поинтов но основной вариант решения это конечно же посмотреть наш workload какие там сейчас операции тяжелые тут связаны с изменением данных и возможно постараться эти операции по изменению сделать делать пачками допустим у нас есть таблица мы хотим из не удалить несколько миллионов записей допустим там 10-20 и оптимальным вариантом будет не удалять эти миллионы разом одным одним запросом развить это на какие-то пачки там по 100 по 200 тысяч чтобы валы генерировались не так не так много и чтобы вакуум успевал проходить по удаленным данным как ты че се это все дело и чтобы лак не был таким критичным не был большим следующий пункт это распускания каталога pg ics lock старых версиях побывал в десятой версии каждый раз нужно об этом помнить и говорить что как можно обнаружить что у нас распух tg x лог побивал по идее ip-адрес всегда поддерживает его в таком в оптимальном для себя состояние на уровне определенных файлов конфигурации и как правило он не должен расти выше там определенных приемов есть параметр max vol says он определяет максимальное значение плюс есть параметр валки psy гнется то есть дополнительное количество сегментов которые мастер хранит для реплики если вдруг там мастера реплика отвалилась и посчитав вот это значение maxval сайта свалки все dance мы можем примерно оценить сколько места будет занимать этот каталог по их флаг и если он растет гораздо больше если он занимает гораздо больше места чем ты тут наши рассчитанный вот в голове цифра здесь к эта проблема и нужно что этим суток что-то делать и как обнаружить такие проблемы ну конечно же в операционно стиме linux есть команда дуться саш мы можем просто мониторинг взаимной цифру и смотреть сколько у нас там журналов транзакций держать там предпочитают эту отметку сколько он должен и сколько он по факту занимает да и уже по факту мониторинга уже как-то реагировать на измене цифр другое место где мы смотрим это pg реплики шанс тот прогресса top cover наиболее частыми причинами почему у нас прыгать слуг занимает много места это либо забыты слоты репликации либо это сломанной архивация других причин на моей практике бывают очень редко ну и конечно же подрисовываю логе там всегда можно найти какие-то ошибки связаны именно с архивной командой с другими причинами которые связаны с переполнением место в играх слоги там к сожалению не будет то есть мы можем там только открыть ошибки репликации ошибки архивации какие могут быть варианты проблем опять же это тяжелое операции обновления данных тяжелые insert эдди ли ты или апдейты связанная с изменением там нескольких миллионов строк если он лесу нужно сделать эту операцию понятно что будет генерироваться большой объем журнала транзакций он будет храниться в их слог это придет к увеличению место то есть опять же как я уже сказал раньше нужно такие операции хорошей практикой является просто развивать их на пачке и не все массивом делать обновление а там по 100 тысяч по двести-триста другой проблемой частый бывает это забыты или неиспользуемой слот репликации люди часто используют логическую репликацию для каких-то своих там задач настраивают шины которые отправляют данные в кафку отправляют данные в какую-то стороннее приложение которое делает decoding логической репликацию логической репликации в какие-то более предпочитаемые для того приложения формат и как ты их обрабатывать и логическая репликация как правило всегда работает через флоты и бывает так что мы настроили этот слот репликации поигрались приложением поняли что нам это приложение не подходит выключили приложение удалили осмотре публикации продолжает жить и когда слот репликации живет в подписи настроен под grease для этого слота репликации держит сегменты журнала транзакций на случай если удаленное приложение или реплика снова подключиться к этому слоту и мастер сможет и мойте журнал транзакций отдать но идет время к слоту никто не подключается журнал транзакций копятся и в какой-то момент место занимает там 90 процентов и нужно выяснять что же там такое почему место так много занимается и как правило этот слот забытый неиспользуемого крепятся нужно просто удалить и проблема будет решена но об этом чуть дальше другим вариантом может быть слова на архивная команда когда у нас есть какое-то внешнее хранилище журналов транзакций которые мы держим там для задач аварийного восстановления как правило настраивается архивная команда реже настраиваться прогрессивных слог команда но тем ни менее archive команда это капрала какой то скрипт который берет сегменты журнал транзакций из пгк слога и копируют в архивном хранилище и бывает так что провели какой-то апгрейт системных пакетов архивная команда сломалась там допустим там мэр sing версия поменялось там флаги обновились какие-то или изменились либо там какая-то другая команда который использовался в архивной команде тоже том что нити формат поменялся правила и бывает такое и архивная команда ломается и архивы тоже перестают копироваться если их архивная команда отработала с выходом не ноль то в лоб запишется сообщение об этом сегмент останется в к в каталоге pbx лук и пока мы не обнаружим что у нас архивная команда сломалась сегменты будут копиться и место также в какой-то момент просто все закончится что делать во первых есть некоторые наборы экстренных мер во первых нужно отстрелить все долги и запросы которые выполняются у нас на данный момент на мастере это могут быть какие-то копи запросы выполняющиеся backup это могут быть какие то долгие апдейты которые там у нас выполняют сейчас обновляют наш миллион строк это может быть концерт и деле ты первым делом нам нужны отстрелить и запросы чтобы предотвратить дальнейший рост каталога pg их слог чтобы там сегменты не генерировались новая следующая мера это уменьшить так называемое резервируем а и место для файлов пользователя root это относится к файловым системам семейства x и по умолчанию файл smx создаются с резервным местом пять процентов представьте себе что вас файловая система там на несколько сотен гигабайт и пять процентов это довольно таки значительная цифра поэтому когда мы видим что у нас там один процент свободного места встал сам и быстро делаем команду и 2 октан там называется и указываем там минус m 1 и у нас резервное место сразу становится доступным пользователю postgres и появляется какое-то у нас такое место время для того чтобы исследовать проблему дальше то есть мы откладываем стопроцентный лимит заполненности на дальше время если мы используем lvm либо zfs мы можем но если администратор имеет свободное место в пуле м либо зевс он может просто из этого резервного пула выделить свободное место дополнительная на том где лежит база и опять же с помощью в команды и файловой системы растянуть это место и файла система станет больше то есть вот таким вот с медом можно как-то экстренно отреагировать на то что вместо заканчивается и самое главное никогда ничего не удалять руками из каталога побег слог побивал об этом говорят все подгрести ст и на всех конференциях на всех докладах но люди все равно удаляют удаляют и базу них ломаются и там самое разное последствии бывает никогда ничего туда удалять нельзя после сам оттуда периодически удаляет файлы когда посчитают нужным у него есть свои функции свои алгоритмы он определяет когда это нужно сделать и вот кстати пгк слог переименовывать впаривал именно по той причине потому что фраза лог оно сбивает с толку администраторов и они думают что ну наверно там каталоге не нужны удалим их что делать дальше когда мы отложили вот этот наступление стопроцентного использованного место что делать дальше нужно проверить во вклад нужно проверить миграции что у нас там что у нас команда разработки запустила на этот раз может быть они там хотели что-то 1 какие-то данные какой-то сделать загрузку данных или еще что-то и от этого уже принимать решение может быть это ну добавление к the disco дополнительного там выделения нового ты был space а перенос данных между ты был с пейсами то есть уже какое такое архитектурное более решение там связанная с апгрейдом железа и добавлением нового места нужно дальше проверить состояние репликации если у нас сгенерировать много журналов транзакций вполне вероятно что мог образоваться лак и если образовался лак то вполне возможно что реплика просто не успела все проживать журнал транзакций могла попросту отвалится нужно проверить реплики все ли с ними в порядке дальше мы проверяем наши настройки чекпоинт сегмент maxval со свалки psy гниц и вполне возможно что они тогда безначально системы configure лась какие-то были выбраны и большие значения там 10 тысяч двадцать тысяч для валки пигмент либо там десятки гигабайт для мо сайт может быть есть смысл пересмотреть и настройки и уменьшить их да и тогда под grease просто необходимо и сегменты просто удалит и каталог побег слог станет меньше нужно проверить slade и репликации через вижу которую там было pg реплики шин слот нет ли там неактивных слотов если они есть то нужно проверить подписчика который подписано должен быть подписан этот слот все ли с ним в порядке если подписчика нет он был давно удален нужно слот просто удалить тогда проблема легко решается если ошибки связанные с архивированием валов мы можем посмотреть эти ошибки в логе либо посмотреть счетчик ошибок впг с татаркой where там все это есть ну и конечно же нужно починить архивную команду разобраться почему она не работает и архив архивация не происходит и конечно же после всех мер желательно вызывать команду чекпоинт это именно эта команда в ней зашита функция определения какие журналы транзакций нам уже не нужны мы можем их спокойно удалить ip-адрес сам высчитывает эти определяют вот идет сегменты и самых удаляет то есть ничего не удаляем руками только через команду чекпоинт дальше долги запросы конфликты репликации как я уже говорил конфликты и при восстановлении конфликты репликации это когда выполняющийся запрос на реплики он выполняется долго он запросил какие-то данные и в этот момент мастера прилетает какой-то за прилетает изменения этих данных и репликация входит в конфликт запросам и вроде бы запрос нужно продолжить но и эти измененные данные тоже нужно изменить и это является уже конфликтном при восстановлении какие бывают ошибки и какие вообще бывают причины для конфликта вас конфликтов восстановления первые две причины это наиболее частые причины это когда вот именно запрос запросил те данные которые должны быть обновлены по репликации и происходит следующий сценарий есть так называемый параметр который определяет задержку которая будет отсчитываться при обнаружении конфликта как только эта задержка отщелкнуть по умолчанию 30 секунд то пузыри завершает запрос и репликация продолжает дальше восстанавливать данные все супер следующая проблема возникает реже и как правило она связана с тем что репликация с мастера она придает некоторую информацию о блокировках на мастере в реплику и если запросы которые выполнялись они как-то конфликтуют с этими блокировками то запрос также через тайм-аут отстреливается и возникает ошибка такое бывает на миграции когда мы делаем какие-то альтеры добавляем кита индексы на таблицах такая ошибка может возникать следующие проблемы следующие ошибки возникают уже гораздо реже и они как правило связанные если был какой-то ты был спейси либо за удалена на мастере и запрос который обращался в этот и был space или базу был запущен и работал с данными с этой базы ну это возникает редко и это как правило удаления базы это ну все знают когда кто-то удаляет базу ну мне так кажется как обнаружить для обнаружения у нас есть места дтп из спб стать дтп с конфликт в этой в этих you have у нас есть информация о конфликтах какие конфликты произошли и эти вещи нужно мониторить если у нас есть конфликт и мы уже начинают дальше разбираться когда это действительно становится для нас проблемой это становится проблемой если запрос и отстреливаются по конфликту репликации очень часто мы считаем что эти запросы важны нашим пользователям пользователь начинает страдать и это уже проблема да либо когда возникает большой лак рипли кации вследствие того что запрос держит нас репликацию у нас растет лак и это тоже проблема что делать есть несколько вариантов и они все такой выбор наименьшего из зол первый вариант это увеличить maxthon 2 из 3 мин delay это именно та самая задержка которая будет отчитываться при обнаружении конфликта репликации тем самым мы увеличиваем диск логарифме кации то есть тайм-аут будет держаться гораздо длиннее лак будет потенциально расти другой вариант это включить hot stone 2 финн бег это вариант когда вакууму нужно почистить какие-то строки но эти строки пользуются транзакций на реплики в этом случае есть риск блата таблиц и индексов это тоже одну из зол которые с которым нужно либо принять его либо понять нужно включать has the nba фидбэк или нет другой вариант самый такой простой для дыба и непростой для разработчика это переписать долгие запросы то есть нужно все запросы которые нас выполняются на реплики по review может быть они написаны не оптимально как-то их переписать пересмотреть и последний вариант который как правило устраивает и разработчиков и 2 это настроить выделенную реплику для долгих запросов для четных запросов например в таком случае maxthon 2 из 3 менделе задирается максимально на несколько часов то есть такая реплика может выполнять долгие четные запросы которые работают там часами но при этом она может там накапливать лак но то что это реплика она создает как бы всех устраивает то есть это такой компромиссный для всех вариант и отчётные запросы работают и лак никому не мешает последний recovery process сто процентов бывает так что процесс который накатывает журнал транзакций занимает 100 процентов утилизации одного ядра он однопоточный он сидит только на одном ядре процессора и он не может перепрыгнуть вот эту планку в 100 процентов и как правило если мы посмотрим в погоста треплите шину можно увидеть там большой lock up like replay то есть очень много данных нужно воспроизвести и реплика не успевает ну и конечно же в топ можно увидеть сто процентов утилизации этим процессом обнаруживаем это через топ то есть это очень быстро легко проверяется и через просто трипле клишин то есть мониторинг если мониторинг настроен мы впали 103 british надо все быстро увидим как искать это одна из самых нетривиальных проблем и алгоритмов как такового поиска не сформировано как правило люди мы прибегаем к использованию утилиты 1 db и реже подавал дан нужно посмотреть какой стык функций и где функции тратят больше всего времени типичным примером может быть workload связанные с созданием удалением временных либо обычных таблиц на мастере такой workload бывает и чтобы удалить таблицу по адресу нужно все шарит буфера там просканировать и ссылки на эту таблицу удалить ну в общем простом случае и это операция на довольно-таки трудоемкая при воспроизведении журнала транзакций и бывает что на этом на таком в окладе возникает такая проблема как решать такие проблемы тоже не всегда очевидна и зависит результатов расследования где-то можно поменять workload что-то поправить где-то нужно писать патч разработчиками писать что у вас вот функция здесь занимает долго времени я поковырялся в исходном коде обнаружил что вот там что-то не оптимально это списках рассылки postgres hackers postgres бакс можно это все писать по сети ждать там когда они отреагируют частью это все быстро происходит но еще раз повторюсь каких-то гарантированных решений здесь сожалению нет ну и мне уже показывает что пять минут заканчивается поэтому если у кого-то есть вопросы задавайте подождите секунду и небольшие итоги я подведу да то есть на нашу такая заключительная . проблема потоковой репутации всегда распределены между хостами что это значит у нас всегда есть мастер всегда есть несколько реплик когда мы ищем причины проблем нужно определить на нескольких узлах искать это да и быть готовым к тому что это распределенная проблема и не на одном узле находится источниками проблем часто бывает нагрузка пользовательская то есть все запросы которые генерятся приложениям это как правило все проблемы оттуда и реже проблемы с оборудованием ну и конечно же нужно использовать мониторинг без мониторинга никуда нужно добавить нужные счетчики и которые я упоминал в мониторинг и тогда время реагирования будет гораздо быстрее ну и встроенные средства про который рассказывал их желательно знать ее желательно использовать и тогда проблема будет гораздо меньше время которое вы тратите на поиск проблем будет гораздо меньше ссылки полезные это списки рассылки наш блог и документации официальная документация по статистике ну и все спасибо за внимание теперь можно вопрос назвать упоминали такую настройку как folge rights to чтобы выключить да для того чтобы уменьшить размер валок если негативные стороны стоит ли включать по умолчанию негативные стороны вот вы спасибо что до упомянули негативные стороны есть есть некоторый риск повреждения данных случае не повреждения данных а не корректного восстановления данных случае аварийного за решения по сгрыз если вы работаете с деньгами считаете баланс и лучше эта настройка не включать не отключать то есть содержатели включает умолчать что никто не был так далеко или произошел чекпоинт настройка выключена и при первом изменение странице записался неполный миша только дельта и бывают какие такие граничные случаи когда повредилась страница на файловой системе и postgres воспроизводит журнал транзакций и вот эти вот изменения накатывается на поврежденную страницу но они накатываются неполным имиджа на только частичным и гарантирован восстановление стопроцентно не гарантировано в данном случае и при последующем обращении к этой странице после сможет там контрольная сумма может не совпасть либо может данный не прочитать либо еще какой то будет будет ошибка чтения данных может быть такая проблема но на каких-то проектах мы отключаем эту настройку потому что там например люди не работают с деньгами да там какая такая простая система и есть какой-то определенный определенное окно для восстановления данных из избы к по условно говоря да то есть отработанные процедуры то есть там можно играться с функцией из бука позже тоже взять будут пример применяться в логе в которых опять же таки не полный формат это уже другая задача проверки backup а тоже должна быть от многие ей кстати пренебрегают к сожалению нет и даже в хакерских по моему таких вопросов я не видел ну то есть люди как бы пока все еще считают что воспроизведение логов как бы упирается в диске и типа iec но сейчас уже с ценовыми и дисками бывает так что чтение с диска гораздо быстрее чем работа процессора да да быстро нагнать это проблематично к сожалению нет журнал транзакций такой последовательный поток данных то есть как бы представить себе параллельно в этот поток загнать 10 писателей нет ну не очевидна и пока эта проблема никак не решена друзья у нас к сожалению время уже вышло все остальные вопросы можно задать вне зала нашим у нас есть стенд дата игры вы можете подойти туда понимать меня там либо других наших специалистов и задать вопросы всем спасибо"
}