{
  "video_id": "Ji7vOYsvPcY",
  "channel": "HighLoadChannel",
  "title": "YTsaurus и аналитические витрины с актуальностью в 15 минут / Филипп Козьмин (Яндекс Маркет)",
  "views": 254,
  "duration": 2731,
  "published": "2025-01-17T02:22:09-08:00",
  "text": "Коллеги доброе утро Добрый день Меня зовут Филипп Я являюсь руководителем хранилища данных Яндекс Маркета Сегодня я буду вам рассказывать про то как на платформе иус мы начали строить витрины с актуальностью данных в 15 минут актуальность 15 минут - это значит что с момента когда события происходят в системе источники у вас уже через 15 минут Всё это видно в конечной витрине В вашем бие Ну давайте поговорим вообще о в каких витринах такое нужно а в целом если посмотреть на аналитические оффлайн витрины можно их разбить на два класса классические из которых состоят наши хранилища Ну это обязательно регуляторная отчётность это управлен которая у нас везде под B это различные клиентские сегментации это очень крупные витрины это могут быть несколько тысяч атрибутов которые мы варим каждую ночь и поэтому мы как правило видим эти данные на прошлый день отсюда появился вот этот термин т ми1 в среднем в нашем хранилище мы создаём такие витрины за 4 часа о том как мы С такой скоростью их делаем рассказывал год назад но время идёт и у нас появился второй класс витрин это операционные витрины вота час работает ваш бизнес-процесс они сильно более узкие Это несколько сотен атрибутов но они витрины высокой актуальности вы хотите понимать как это происходит сейчас как ваш процесс в настоящее время себя чувствует И поэтому их нужно варить с регламентом в минуты соответственно Давайте я вам расскажу про кейс который породил у нас эту Потребность у нас порядка ми миллиарда товаров которыми мы торгуем и одновременно запускаем по этому миллиарду товаров 2.000 различных промоакций которые создают промо давление то есть снижают цену при этом ещё промоакции могут заводить наши мерчи наши поставщики и получается что в какой-то момент времени мы можем продавать товар слишком дёшево ниже закупочной цены и вот случился такой случай с квадрокоптерами и они буквально за один день все улетели со складов Ну естественно это приносит нам убытки и Вот такая вот история побудила нас начать работать в этом направлении давайте я попробую сейчас сформулировать эту задачу чуть-чуть упрощённом видо первое нужно построить витрину которая бы отвечала на вопрос Как качественно работают наши промоакции очевидно что надо сделать это с актуальностью в минуты иначе как бы будет слишком поздно если отвечать на этот вопрос на т-1 Можно ли это сделать и Нужно ли это делать с регламентом секунды нет нужны минуты потому что только человек на текущий момент времени в состоянии понять Нормально работают такие сценарии или нет слишком сложная логика вообще оценки адекватности продаж поскольку Ну продажа с целью роста - это по сути контролируемое как бы падение что у нас имеется по данным да для запуска такого сценария у нас будут потоки То есть это уже непрерывно поступающая и Первое - это поток заказов нам нужно анализировать заказы нам нужно анализировать все промоакции которые применяются К данным заказам нам надо анализировать комиссии которые мы зарабатываем потому что заработок комиссии в том числе должен быть учи тан для оценки сильно много мы тратим деньги или нет А ну и надо понимать что вот на эти потоки нужно будет накидывать ещё достаточно большой объём статической справочной информации которую мы варим ночью это порядка 150 гигов для того чтобы просто понимать Ну с какими товарами мы имеем дело Давайте посмотрим какая Вот будет Техническая развилка с левой стороны у нас потоковая обработка Я думаю многие из вас знают что есть такие решения есть знаменитый флинк Это можно сказать сейчас Эталон в индустрии Как можно решать такие задачи это разработка наве Если вы делаете потоковую обработку м достаточно тяжело запустить сценарий нужно какое-то время чтобы он приобрел данные его достаточно тяжело пересчитывать чтобы компенсировать какие-то дырки И вообще сложно сравнивать с вашим оффлайновый стороны у нас есть ить на ите мы варим витрины уже Достаточно давно огромных объёмов там есть ль который очень дёшево при разработке витрин данных никаких сложностей с пересчёта Нет мы хорошо научились это делать ну сверять с оффлайновый но соответственно есть только одна проблема а мы варим витрины за часы Мы решили попробовать на вот этом стеке технологии зас сделать это быстро и в дальнейшем рассказ будет про то как мы потихонечку шли к тому чтобы На том же самом стейке на котором мы варим классическое хранилище начать варить витрины с актуальностью в 15 минут А давайте углубился сейчас в технологии которые я беру конкретно из которых я буду Вот выстраивать это решение я беру ИС в нём я выделяю четыре основных технологии которые мне нужны мне нужен Киль А это мой основной язык для обработки данных он прекрасен он очень функционален Я ем полностью удовлетворён я беру статические динамические таблицы про них я чучу сей Сейчас расскажу и я использую Python в различных местах Я использую питон для планировщика я использую питон для взаимодействия с динамическими таблицами Ну базовые технологии которые мне нужны вте как бы это они на этом как бы вте всё мне нужен будет лиха хау Мне нужен будет для быстрой агрегации данных потому что я буду строить B деки с большим количеством фильтров и прочих возможностей пользователю отсекать данные Поэтому мне нужен инструмент быстрой выдачи данных на потребителя это Клик ну и соответственно би инструмент dat Lens - это наш индексов инструмент Я выбрал его в первую очередь поэтому а немножко про таблицы которые я взял динамические и статические статическая таблица в ите это вот Таблица которую мы привыкли видеть больше всего те кто из вас работал с хопом знает есть такой apach org это вот по сути Ближе всего к ним некая колоночная структура иммутабельность чаще всего для того чтобы работать с объектами динамическая таблица чуть Более сложный объект вте Это если проводить аналогии то как устроен движок merge 3 в кликхаус или как работает внутри себя Касандра То есть это на самом деле некий движок встроенный таблицу который позволяет вам выполнять ltp операции в том числе то есть производить быстрые модификации данных и вычитывать какой-то инкремент данных при этом это колоночная организованная структура которая очень эффективна на чтение и на компактность данных Вот такая замечательная структура и про неё Мы ещё в будущем как раз поговорим потому что во многом она помогла достичь этого результата теперь начинаем из этих компонент проектировать решение сейчас я буду как кубики его выстраивать поехали Ну начинается всё с чере сообщений в них поступает из источников информации дальше мы прог задача на выполнить первичную обработку то есть мы должны все потоки данных сюда приземлить привести их в какое-то человеческое обрабатываемое состояние соединить обогатить вот этой оффлайновый справочной информации дальше опять очередь сообщений для надёжности для троттлинга которая передаст данные в кликхаус в кликхаус уже будет конечная агрегация для наших потребителей дальше на Верхнем уровне Вроде должно быть понятно углубляемся берм берём наши три потока каждый из потоков мы начнём персистирование данных и вот оно происходит про это мы поговорим чуть в будущем Как же оно происходит после того как у нас существует инкремент соединённого потока остатся обогатить это справочной информацией О'кей передаём это дальше в кликхаус в Клик Хаусе нужно выполнить дупликации данных а дедупликация данных нам нужна для того чтобы отсечь повторяющиеся конечные состояние Ну данные приходят одно и то же состояние меняется устаревает и соответственно на пользователя всегда надо выдавать только самое актуальное конечное состояние здесь есть два метода которым вы можете пойти метод первый Вы можете Просто сразу применять э либо функцию Final либо ако и функцию RAM для того чтобы выбирать конечное состояние Но это вот по нашим наблюдениям заняло у нас 15 секунд То есть каждый раз когда вы обращаетесь через Bi к такому источнику вы заставляете пользователя подождать 15 секунд и мы пришли Просто к тому что на самом деле намного дешевле для пользователя и приятнее Да запускать это всё на кроне то есть раз в пару минут материализовать эту таблицу с устранением дублей и уже пользователя опускать ну без вот этих повторяющихся записей строить нужный агрегат а задержка в таком случае снижается до 2 секунд и вот сейчас у нас такой целевой вариант простое на самом деле победила всё с кли хаусом больше особо ничего нет единственная операция - это дедупликация выполняет он функцию только агрегации данных и конечных метрик для потребителя посмотрим на схн целиком всё понятно кроме вот этого вопросика Как соединить потоки из этих инкреторная скажем так 150 ГБ оффлайн данных которые мы варили я буду соединять обычную операции Джоном это на самом деле вполне реализуемо за пару минут но вот как соединять потоки неясно от слова совсем ну и Давайте я вам расскажу как мы двигались да для решения этой задачи Первая Попытка была лобовая мы просто берём вот эти вот таблички вот эти маленькие инкремент и пытаемся с помощью скеля написать обычные SQL который позволил бы нам получить соединение как бы данных без пробелов так получилось что данные нормально соединялись В нашем кейсе только на глубине двух недель То есть они достаточно сильно связаны если мы не берём тысячи этих инкремент составляют 2 недели глубины данных они не соединяются у вас где-то постоянно пробелы и состыковки получилось что на каждом потоке это по раба 3 сварить быстро Ну не вариант вообще никак не получалось на это может уйти Если Вы хорошо можете затюнить Y 30 минут в час нам это не подходило а соответственно Мы на этом этапе отвергли вообще идею что вот в лоб ала подходом это можно как-то решить пошли дальше а начали придумывать А вот где здесь можно найти какие-то тонкие оптимизации мы по-прежнему находимся в келе мы по-прежнему строим это классическим лаб Джоном массивом но мы пытаемся подра подобрать последовательность этих соединений пытаемся везде вырезать данные пытаемся поиграться с регламентом где-то что-то ускорить где-то что-то замедлить И вот так вот доигрались до какой-то безумно сложной архитектуры с большим количеством пересечений данных то есть вот сейчас я даже не хочу тратить ваше время объясняя какую муть мы там наварили за месяц и вот потратили мы на всё месяц что мы получили Да мы конечно получили что-то работающее быстро но Глядя на наши конечные графики FBI мы видим мы теряем данные то есть реально в какой-то момент времени Вот в этой всей сложной архитектуры потоки друг на друга наезжают и происходят вот такие ситуации когда один поток перетёртое другого очень обидно данные нам терять нельзя То есть если мы не можем управлять точностью то мы не можем просто отличить факт бизнес проблемы от наших ошибок то есть решение которое мы строим Обязательно должно работать заранее заложенной точностью Какая при той ошибкой было мы на самом деле нале оперируя с одной таблицами разных потоков Да периодически запуская два процесс работающие с одной таблице вот приводили к такой ситуации Если же их делать сериализовать д процессом там работать с одной таблице мы не достигали скорости Ну и пришли получается к к выводу что как бы мы не старались классический ала подход не достигнет здесь результата а вторая как бы мысль Ну если не работает у laab надо приходить к ltp подходам к супер маленькому обновлению данных из тех вот таблиц инкремента над какой-то сущностью так как мы привыкли работать в наших таблицах источниках брать какую-то запись накатывать её на табличку брать несколько потоков и накатывать их соответственно на какую-то табличку то есть схема бы выглядела Так у нас есть какая-то ltp табличка способная принимать модификации данных и мы из трёх потоков на неё Нака вот эти вот изменения чтобы получить длинный Вектор который из себя представляет проно событие и которым мы сможем оперировать но у этой парадигмы Если вы попробуете сделать в постгрес в гримме во многих других оракле транзакционных базах данных вы столкнётся Локи Что такое Dead - это как раз когда одновременно бегущие транзакции А в нашем случае одновременно опускающиеся потоки начинают захватывать большой сет данных и так получается что захватывают они асинхронно и например первый поток успел захватить первую запись и нуждается во второй он идёт за ней а второй поток успел Уже захватить вторую запись и нуждается в первой они заходят вот в такое пересечение и ожидают друг друга пока не придёт кий процесс планировщик и соответственно не разрулит эту ситуацию в результате обычные архитектуры которые пробовали строить таким образом заходили в тупик Потому что есть Если вы налетает на Deadlock Вы слишком долго ждёте опять не успеваете реализовать э свою как бы идею свою витрину за эти 15 минут но тут вспоминаем что есть динамические таблицы что могут дать динамические таблицы для решения этой проблемы в них есть э функционал позволяющий определять как сущность блокировки не просто строку а строку и набор колонок это определяется прямо на момент объявления ДД это таблички И тем самым что вы можете сделать Вы можете сказать что пусть у каждого потока есть его уникальный набор атрибутов значит соответственно вы выделите в таблице приёмнике независимые изолированные атрибуты которые будут как раз принимать атрибуты из соответствующего потока И тем самым вы развед вот эту проблему блокировок более того как я говорил динамические таблицы - это как раз таблицы позволяющие выполнять транзакционные операции То есть можно непрерывно в них что-то вставлять выполнять апдейт Ну и также Потом можно будет из них довольно-таки оперативно и быстро что-то вычитывать получается эта табличка работает в ltp режиме обладает нужным режимом нам блокировок и от неё мы сейчас начнём отстраивать эту архитектуру мы берём Наф три потока мы размечаем а динамическую таблицу на три части сохраняем только некий ключ по которому идёт на Join сущности это единственный их общий атрибут среди всех этих потоков остальные атрибутивные части пишутся соответственно в свой сегмент и это происходит непрерывно они могут писаться таким образом асинхронно А ну на текущий момент я вот м показывал что это потоки мощностью где-то по терабайт за несколько недель а при этом мы видим Сами наблюдаем как происходят стрельбы эти потоки могут выдержать нагрузку в десятки раз больше то есть если бы это были потоки в петабайт они также могли спокойно накатывать на эту табличку То есть петабайт за 2 не это мы вот точно сейчас досконально знаем а Но есть один маленький нюанс с которым вы столкнётся у этой таблицы получается есть только один ключ это идентификатор и Как из неё читать а Да нету никакого поля например нету поля даты которое бы вам позволило вообще определять А какие записи только что были модифицированы чтобы дальнейший процесс обработки можно было ввести эффективно Почему нет на то есть две причины но первой нет вторичных индексов То есть пока просто в динамических таблицах не существует но они наверное скоро появятся а вторая вы не можете завести общее поле кроме идентификатора вы нарушите предыдущее правила про дедлокед динамической таблицы можно решить с помощью двух динамических таблиц соответственно надо сделать вторую динамическую таблицу и туда записать ключи и технические даты модификации этих ключей в первой таблице Вот это вторая таблица которая у вас есть она как раз вспомогательная она будет у вас использоваться для того чтобы вы потом вытаскивали идентификатору из вот этой сегментировано таблицы записи которые у вас были только что модифицированы вытаскивать вы будете на неком крон процессе раз в пару минут как вы сочтёте себе нужен ну и соответственно следующий шаг - это действительно Вот такая Такой способ забора данных вы получаете набор ключей который был модифицирован за последние 2 минуты вторгается вектору выполняете все нужные вам арифметические математические преобразования получаете уже красивый прямо конечный финальный объект добавляете справочную информацию Всё дальше вы загружаете это всё в кликхаус где пользователь начинает а применять свои агрегации для построения финальных метрик снизу я показал э тайминги которые существуют вот основной тайминг он нарисован сверху то есть Сколько нужно времени чтобы сохранить вот эти таблички инкремента минута Или даже меньше дальше порядка 1Д минут происходит вставка вот этих табличек инкремента сегментирован ную динамическую таблицу менее минуты вам нужно чтобы вытащить накопившийся объём изменённых записей в нашем случае это объём записи накопившийся за 5 минут 10 минут занимает вот это вот массивная операция мы справочники наджва на маленький поток данных то есть самая долгая техниче это вот просто добавить справочники здесь это 2/3 а перегрузка в очередь практически не занимает Ничего как её дальнейший проброс уже в кликхаус Ну и где-то менее минуты нужно для того чтобы материализовать табличку с загруженными данными из потоков и дедупликация то есть Представьте что на этих этапах Вам нужен крон процесс который ждёт 5 минуток Вы можете его безусловно сокращать когда ваши тайминги находятся в пределах минуты Вы можете хоть раз д минуты запускать но мы для простоты картины запускаем Раз в 5 минуток в целом задача с построением таких витрин решается таким образом что можно сказать по качеству данных мы наблюдаем уже порядка года как работают такие витрины Нет они теряют данные они в этом плане идеально консистентные А как раз здесь я вам показываю наложение двух графиков то есть старая реализация осталась мы её сейчас используем для мониторингов а сверху как раз золотистый график - Это новая реализация которую мы построили и Как видно по полноте Она всегда доминирует То есть она не теряет данные А что ещё хочется сказать Я не сказал про vq для чего мы его использовали И вообще чем он был здесь прекрасен в используется на двух этапах он производит первичную обработку вот этих маленьких табличек инкремента превращает их во что-то удоб вори и делает как раз вот Jo справочной информацие на получившийся маленький инкремент хорошего собранного потока данных а его плюс то что может работать как быстро быстрый его режим это про него рассказывал год назад так и в режиме То есть он может обрабатывать очень большие данные и получается так что если вам нужно например эту витрин по какой-то причине пересчитать Ну вы пропустили какой-то поце данных или поняли что у вас существует где-то неточность в расчёте Вы можете прогнать вот сначала эти инкремента через wql То есть например их за месяц за счёт мадса он это сделает достаточно быстро и также потом произвести достаточно быстрое соединение справочной информации Темп пересчёта такой витрины примерно за день Вы сможете пересчитать месяц полтора данных это достаточно хорошо Если вы Сравните это с показателями инструментов потоковой обработки За сколько Насколько быстро они корректируют свои ошибки это быстрее примерно на порядок То есть если бы вы делали сценарий на Финке вы бы за день обработали Ну вам повезёт если неделю А все ли витрины мы теперь делаем так Ну на самом деле Конечно нет не все на это есть очень понятные объективные причины Ну первое Вот я сказал что мы пересчитывает примерно на полтора месяца и это сильно меньше чем мы пересчитывает для классических витрин которые мы строим как правило Мы можем за сутки пересчитать 2-3 года и это часто нужно многие метрики которые мы строим это метрики E to которые показывает нам как Наш бизнес Из года в года с учётом сезонности развивается и раст да и данные соответственно витрин не про такое они всё-таки про порционные про то что есть сейчас и классические витрины свою роль по-прежнему продолжают исполнять второй важный Аспект в той архитектуре которую показал не было никакой красоты с точки зрения пере используемой моделий Если Вы посмотрите на то как собираются классические витрины там стараются выделить слои у которых есть определённые назначения пере используемое всегда были одинаковые в разных областях хранилища эта архитектура она про скорость она не про то чтобы удобно было переиспользовать эти объекты объективно такая обработка информации дороже а так или иначе вы будете одни и те же данные обрабатывать чаще чем в классических витринах и поэтому в несколько раз вырастет расход ресурсов в преимущественно цпу на содержание таких витрин Ну и в целом витрину с такой оперативной доступностью нужно более как это внимательно и более оперативно пожи что естественно дополнительная нагрузка на дежурных и просто так без необходимости такую витрину создавать не стоит что же можно подытожить про весь этот эксперимент и про который мы использовали Ну первое действительно мы для себя надеюсь И после этого для вас доказали что это платформа которая не только про обработку супер дан стояние кластеров в Гбайт данных но и про то что вы можете используя его базовые технологии обрабатывать данные очень быстро а такой тайминг Вы не достигнете скорее всего ни на одной и другой текущей технологии ни в дупе ни в Грин пламени в гресе вы будете упираться в разных частях их функциональности в том что вам Будет не хватать э функционала для реализации этой витрины а третий важный как бы Аспект - это платформа орная она доступна всем везде более того она очень высокоуровневые то есть грубо говоря те из вас возможно кто уже попробовали смогут подтвердить мои слова что это не просто какая-то а платформа Где вы из коробки получаете что-то работающее с командной строкой это уже развитая платформа с хорошими продвинутыми интерфейсами которые быстро позволяет вам в неё залететь и по сути вы получаете решение практически рка которым мы пользуемся в Яндексе А в Яндексе большинство из нас искренне верит что э платформа лучшее что существует сейчас на рынке для обработки данных на этом я доклад сегодня закончу и Давайте перейдём к вашим вопросам это собственно говоря то за чем мы сегодня собрались обязательно голосуйте даза голосу Ново новость для спикера вас сегодня ждёт три подарка за лучшие вопросы супрематическая матрёшка подарок от спикера и от компании спикера Поэтому вот тебе ручка а бумажка и вот тебе бумажка я не верю нижнее нижнее нижнее это мой план по которому я всё рассказываю вот поэтому записывай вопросы поча и тебе нужно будет Прямо сказать Кому ко Машку Кому ты подаришь подарок от своей компании а кому От себя лично и мы приступаем первый вопрос Спасибо за доклад очень интересно вопрос простой на том слайде где вы показывали промежуточная таблица в которую мы по факту укладываем все данные чем динамическая таблица в я лучше по производительности чем в кха То есть если например вместо явкой динамической Ну подложить кликхаус таблицу и в ней уже делается решает вопрос идеологически это на самом деле одно и тоже и наверное можно было бы построить архитектуру где я попробовал бы пропустить вот такую петлю но здесь нужно отметить что вте больше фичей Именно под обработку данных система которую всё-таки разрабатывали для того чтобы данные предоставлять и некоторых операндов у вас может не быть некоторый функционал динамических таблиц я сейчас просто даже опустил их очень интересно будет посмотреть в документации например там существуют встроенные агрегацией НК которые будут например применяться после каждой вставки каждой записи То есть вы можете например строить на такой динамической таблице на литу агрегаты А вы можете более вот на Большом кластере удобным образом им управлять то есть грубо говоря Вы сможете создать на кластере и тысячи таких таблиц для разных задач то есть значительно больше чем вы скорее всего себе сможете позволить таблиц на вашем кластере кликхаус в целом Это связано с тем что и - это платформа для обработки данных и соответственно отсюда появляются дополнительные фичи детали обсудим на в рах следующий вопрос Добрый день Меня зовут Андрей компания МТС а у меня вопрос немножко наверное схожей сферы потому что там тоже это большой п данных это Кибер бец потому что у нас постоянно какие-то сработки допустим тех же самых фов и прочего и допустим ваши коллеги недавно на конференции по Cloud Security А я как раз тоже вопрос поднимал по поводу обработки именно такого вот быстрого потока данных а просто то что вы сейчас показали оно прямо идеально накладывается этот пайплайн как бы всех этих вот вещей потому что за счёт агрегации прочих Ну просто смотрите А вот то что вы показали именно в тиус и там же он получается Бут модульный да то есть там можно будет его расширить топ модули допустим для колясок дополнительных и прочих там допустим для Ti там рексов и прочего или это структура не модульные получается Он фиксированный А модулями мы имеем в виду написание какого-то своего кода который мы хотим имплементировать для выполнения каких-то операции обно говоря да какие-то доп модули там допустим по М же самым по а допустим по выгрузке Да в целом да то есть в Исе вообще большое количество а для того как с ним взаимодействовать а для разных структур и даже Более того я про эту фичу рассказывал около года назад на прошлом хайлоу Вы можете сильно скрещивать SQL Итон Ну то есть то что вам не хватает в штатном функционале SQ Вы можете просто взять инъекций впрямую затолкать питоне почему это работает классно - это Плюсовая платформа она дружит с питоном В отличие как раз от дупа Где вы не можете себе такой роскоши позволить Там просто работает на порядок менее эффективно российского сообщества Python разработчиков я глубоко одобряю Следующий вопрос из чата и Обратите внимание что онлайн слушатели тоже могут получить супрематический вопрос мы их найдём и отправим Где бы они не были поэтому обязательно записывай вопросы из чата тоже и вопрос от Павла как в Яндексе ить запускается в кубе или на голом железе Ну железки Следующий вопрос левая часть зала либо большой за доклад Вопрос такой насколько я знаю в аврус есть как раз таки модуль для Хауса Почему вы не используете его почему вы выносите это в отдельный Инста сейчас поясню Да Действительно вчить это по сути встроеный движок который может быть т его мощностях на его тачках он в целом выполняет свою задачу он действительно достаточно неплохо подготавливает и предоставляет данные для инструментов но есть маленький нюанс он всё равно менее эффективен по скорости выдачи данных нежели физически построенный клика На СД именно для того чтобы сделать вот это очень важный для И вообще длях Поль вообще снизить максимально задержку мы применяли физический кликхаус при этом у меня в хранилище порядка наверное 80% дев отражается именно через щить и только самые Топлайн самые важные как раз используются физические кликхаус Следующий вопрос тоже с левой части зала прошу Филипп Спасибо за доклад очень классно у меня вопрос насколько я знаю может работать in Как быстро он может выдавать данные можно его ВТА процессы и насколько его можно рассматривать как замену или альтернативу таким базам как там апай Тарантул и прочее Спасибо А я наверное не смогу в полной мере ответить на этот вопрос только расскажу про свой эксперимент Мы пытались конкретную табличку Вот динамическую про которую рассказал запустить как раз над память у не Действительно существует такой режим нам это нужно было не для какой-то цели А мы хотели поиграться и надо сказать что как раз первые попытки у нас не удались то есть запустить стабильно работающую динамическую таблицу на памяти за день мы не смогли понимая что для продвижения нашей как бы ну достижения нашей цели это не нужно мы остановились на текущей реализации но да в принципе эта функциональность существует и Ну я думаю если для вас прямо важно ускорение там с минут уже до диапазона каких-то секунд это это вполне работающее решение ты записываешь вопросы делаешь пометки Тебе нужно будет выбрать три и это будет сложно Follow Up вопрос из чата Вот ты сказал что вы запускаете на железе а гайд как разворачивать ыть на железе У вас есть а Честно говоря я счастливый человек да Я работаю в хранилище и вот поддержание вот этого огромного кластера - Это команда и для меня то как он разворачивается ни разу в жизни мне не приходилось с этим сталкиваться Я думаю на этой конференции будут ребята которые представляют как раз непосредственно платформу и вот этот вопрос правильно задать им следующий вопрос центр зала Привет Спасибо большое за доклад у меня такой вопрос чем обусловлена необходимость пересчитывать недельные инкремент каждые 15 минут я поясню мы постоянно совершаем какие-то на самом деле ошибки которые даже а они существуют даже в текущем расчёте я уверен их просто находят Спустя время к нам приходит бизнес потребитель говорит смотрите ребят Вот пример каких-то конкретных заказов Вот пример применения к ним промоакции Говорит и здесь неправда и мы как бы бежим быстро это исправлять то есть Нам нужно как можно быстрее привести данные в консистентной состояние Но это надо привести не только с текущего момента времени как мы обнаружили ошибку но и просчитать ближайшие данные которые были до до этого потому что все потребители всегда смотрят данные сейчас вчера позавчера за неделю Они не смотрят только цифру в моменте они их постоянно сравнивают с тем что было в ближайшем прошлом только так они ориентируются что всё похоже на правду Следующий вопрос снова центр зала Привет Спасибо классный был доклад Скажи пожалуйста между итм и кхао Сом стоит очередь мне интересно на какой технологии эта очередь реализована и коннектор между итм который кладёт в очередь это cdc какое-то или это какая-то бочо Ja очереди которая используется в Яндексе это Лог брокер это на самом деле полный аналог Кафки в какой-то мере я бы сказал поэтому Давайте будем считать что это кавка так будет понятно а cdc используется Действительно это один из нужных и перспективных скажем так форматов зацепки данных из Ну у нас преимущество по использу в 99% случаев из порса к нам в систему мы используем как бы стандартные де бези умные реализации Да это как бы популярная у нас тема Пользуясь случаем стенд постгрес расположен на Центральной площади рядом с шатром вопрос с правой части зала ещё один маленький вопрос а ять не поддерживается основной первичный ключ для чего нужна вторая таблица в которую записывать А вот я попробую пояснить этот тонкий момент во-первых вторичных ключей просто нет то есть Пока нельзя задать второе какое-то поле которое было бы эффективно на чтение из этой таблицы То есть он всегда эффективен только по первичному ключу поскольку там модификатор ну просто по модификатору не умею какой-то вспомогательной информации читать не получится Вот поэтому вторая таблица появилась она окрашивает идентификаторы через время какие из них свеженькие и мы уже по конкретному перечню начинаем вытаскивать данные вот а а вторая проблема даже когда ребята создадут эти вторичные индексы нельзя нарушать правило что потоки работают с одним полем если мы попробуем создать единую бизнес дату для всех потоков куда бы они скидывали своё актуальное самое состояние Ну типа последняя бизнес дата вот оно бы попало бы в блокировки Следуй вопрос вывести в отдельную табличку из правой задней части зала и на футбол у них разная схема там вставка а там обновление детали можно будет обсудить В ларах на футболке следующего гостя написано кликхаус не тормозит это как бы намекает А на что это намекает мы сейчас узнаем Да Филипп Я здесь Да спасибо за доклад Меня зовут Василий а честный знак три вопроса два короткий один пожалуйста один короткий Прям просто Да нет Давай да первый всё-таки всех заинтересовала табличка вторичного индекса на чём она построена Угу Вот это та же самая динамическая таблица то есть та же самая технология которая просто используется в режиме вставки Мы туда только вставляем О'кей э гранулярность удаления Как вы делаете удаление при пересчёте и А вопрос понятен да и ну основной вопрос то что вот смотрите Практически везде присутствует идея о том то что У нас есть инкрементальная заливка данных нам хочется это дело обновлять Да там в том же самом клике то что agreed да Engine Ну в ите тоже самое классические тели были построены вот есть какая-то задумка видение или вот ну как бы понимание что будет в будущем с такими таблицами потому что по факту вы сделали Вот то же самое что все пытаются сделать на коленках на руках или вот как ну то есть вопрос в целом понятен У меня есть наверно да то есть ожидается что это будет какое-то такое ну коробочное решение Простите это есть колоночные решение динамические таблицы они колоночные а скажем так Ответ на второй вопрос это как раз Решение не на коленках это по сути базовый функционал ИТ то есть вот оно темы прекрасно то есть любой инженер садится и начинает работать и делать А вот первый вопрос я честно говоря даже забыл Обсудим в ларах записывай ставь пометки Следующий вопрос из онлайна А Сергей говорит что динамическая таблица решает проблему потоков А И вот она эту проблему решает для потоков которые работающие которые работают с разными колонками и есть ли какая-то проблема Если два потока будут работать с одной колонкой а Сможет ли в такое динамическая таблица а ну так делать не стоит потому что я как раз рассказывал про блокировки То есть если так сделать Вы действительно рано или поздно поймаете транзакции которые друг друга Взаимно заблокировали То есть если вы позволяете на уровне etl процессов или других планировщиков которые такую архитектуру строите нескольким потокам одновременно делать вставку или обновление данных ну именно конкретно обновление данных динамической таблиц здесь надо строго развести атрибуты чтобы с одним атрибутом не работало два потока Так у нас осталось времени по три вопроса да человек прямо напротив в конце всё время тянул ру д и оди из зала начинай Филип Привет меня зовут Глеб очень классная архитектура классное решение И вот вопрос такой а оно с точки зрения бизнеса оправдало то есть насколько метрики буста это решение не про бури это решение Мониторинг это поставка стала Второй по популярности то есть мы-то думали что самые наши популярные дешки это будет управлен но на самом деле вот эти истории очень интересны пользователям им очень интересно наблюдать как Маркет вообще работает в моменте А вот такая витрина она достаточно хорошо отвечает На многие вопросы мы делали её исключительно под промо но она стала полезной и в других местах Следующий вопрос правая часть зала Да всем привет Спасибо за доклад вот у меня такой вопрос скорее как предложение может быть Вот архитектура была с потоками Да потоки - это сейчас как приложение да пишущие получается в один таблицу Вот они пишут разные колонки вот ну там всё-таки создаются какие-то Локи Да чтобы они там как бы ну не конфликтовать Да друг с другом как предложение такое А что если потоки организовать как ордеры таблицы динамические вот записывать в них как бы эти данные вот вести некоторый офсет который будет там двумя неделями ранее допустим да смещать его каждый раз вот и запускать процесс агрегации который будет по этим Дин таблицам ордере собирать вот этот агрегат и класть уже его туда дальше в поток то есть не нужно будет как-то писать в одну Дин таблицу вот не нужно будет держать отдель смотрите а архитектуру голосом вот так вот в зале мы сейчас просто не потянем Давай в кулуарах обсудим там будет просто больше вре по доклада выйду и как раз я предлагаю обсудить альтернативу потому что это кстати были сортированный динамические таблицы ты говоришь сейчас про порядочные это по сути очереди это будет архитектура уже другая над ней надо будет сейчас прямо подумать сходу на такой вопрос вообще тяжело в любом случае ответить Я вспомнил вопрос про удаление у на самом деле очень классный что человек обратил на это внимание да в этой архитектуре завершающий вопрос из чата Вот ты сказал что прилагаемая предполагаемая предлагаемая архитектура быстра требует вычислительные ресурсы в большем объёме Алексей интересуется что вот на этом объёме условно классические решения не будут ли сопоставимы по скорости если игнорировать удобство и гибкость мм Ну на классических решениях вообще это не сделаете то есть я не понимаю как э вот имея свой опыт работы с грин Плам в много лет с постгрес базами я вижу определённые функциональные ограничения в которые вы упрётся достаточно серьёзно допили ээ саму платформенную часть Ну например по колоночной блокировку придётся писать то есть вы отказываетесь от встроенных механизмов блокировок и уходите в блокировку в режиме приклада то есть насколько это сложно сделать Да это будет сложно сделать а возможно намного дороже чем сами витрины А по касаемо ресурсов Ну вот конкретно э реализация это нужно где-то 400 ядер для того чтобы она работала Ну что ж вот у нас просто классическая талонная сессия 25 минут доклад 26 минут вопрос Вот давайте раунд алоди спи несите мне подарки прямо вот все подарки сюда несите сейчас у нас будет огромная церемония награждение и мы начнём с твоего личного подарка За какой вопрос ты готов свой личный подарок подарить чный подарок я дам за вопрос про удаления на который я не ответил А это связано с тем что вопрос сам по себе классный удаление задал вопрос про удаление Приходите человек сам задал вопрос про удаление пока он идёт например чтобы я ему вручил подарок я отвечу удалить данные нельзя поэтому выстраивается статусная модель есть отдельный атрибут который отвечают за статусы в этих колонках у меня для тебя будет личный подарок в Питере меня всегда встречает дожд уже есть такая традиция Аплодисменты нашему гостю поэтому от меня тебе зонтик Оставайся с нами на сцене сейчас а следующий подарок от компании Кому мы вручим А следующий подарок - это от коллег из ити они тоже находятся здесь и этот подарок Я хочу вручить за два вопроса вот я даже не знаю какой мне Понадобился больше это брелок А я не помню как называется этот зверь Вот Но это символ тя Аплодисменты и наконец супрематическая матрёшка кому же кому доста вопрос про чить вопрос про чить который был э вот с этой стороны Аплодисменты И матрёшка а матрёшка мне не дали матрёшку вот гото СБО ну и наконец спасибо тебе от нас организаторов при спикеру в студию Спасибо L"
}