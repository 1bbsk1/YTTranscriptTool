{
  "video_id": "6A7ZfMsHJRM",
  "channel": "HighLoadChannel",
  "title": "Реализовать OLAP: как мы делали колоночное хранение в YDB / Софья Новожилова (Яндекс)",
  "views": 342,
  "duration": 3138,
  "published": "2024-10-29T02:57:22-07:00",
  "text": "Приветствуем Софью так всё можно начинать Да Всем привет меня зовут Софья также как написано на слайде Я работаю в Яндексе в команде idb занимаюсь разработкой направления компонента отвечающего за аналитическую обработку данных за колоночные таблицы забыла взять Итак а Для начала я пару слов для тех кто не знает что такое vdb скажу что это такое vdb - Это распределённая база данных которая появилась в Яндексе несколько лет назад активно в нём разрабатывается и используется большим количеством сервисов А это транзакционная база данных она используется например такими сервисами как яндексмаркет для хранения там данных о корзинах а она используется платёжными сервисами Яндекса Если вы сегодня утром слышали доклад про про платёжную систему Они как раз рассказывали Как используют vdb и в целом используется для хранения логов в Яндекс клауде в целом достаточно мало сервисов в Яндексе которые так или иначе в idb Не используют А так как наши клиенты как бы клиенты в idb внутри Яндекса довольно крупные Поэтому собственно масштабируемость она для нас важна из коробки как бы это распределённой и масштабируемость это такие основные три вещи ради которых в idb разрабатывалось Ну конечно же кто-нибудь сказал бы что сделал базу данных она не производительная все такие Да Хотим её использовать Итак что умеет vbb умеет работать изначально с классическими транзакционные количество запи в транзакциях в единицу времени раскладывается в табличке Ну нагрузка как бы типичная Работа как вы работаете с пом точно также можно работать с только она е распределённая второй способ использовать vb - это стриминг данных стриминг данных мы здесь подразумеваем под стримингового о почка вке про него сегодня тоже утром были доклады и ещё завтра будет Мой коллега рассказывать на треке Open Source по-моему если вам интересно про это узнать побольше я сегодня буду говорить про аналитический компонент про аналитическую обработку данных про колоночные таблицы и самый первый вопрос как бы который меня спрашивают типа А зачем вы это сделали и самый простой первый ответ да потому что мы можем это сделать как бы нам система позволяет потому что база данных есть она достаточно платформенного сделать довольно локальный набор доработок И мы сможем поддержать колоночной хранение а второй Поинт Почему Потому что это ну нужно и полезно вот Как развивается сервис как бы сначала вот предыдущий был доклад сначала люди заливают данные в какую-то базу данных и думают Да нам не нужна аналитика мы как бы зальём будем их использовать потом через некоторое время аналитика становится необходимой и возникает вопрос как и куда эти данные переложить как бы как настроить какую систему развернуть вот было бы классно же как бы вот у тебя есть wdb ты заливал в неё свои обычные там заказы тебе для аналитиков нужны строить какие-то дашборды или какую-то аналитическую информацию использовать ты чуть расширил кластер развернул там рядом ещё колоночные таблицы переложил эти данные средствами базы там каки cdc потоки настроил и ну используешь всё классно как бы не надо ничего нового учить как бы как поднимал так и работает Главное чтобы система умела перераспределять ресурсы потому что всё-таки поведение разное Итак о чём я расскажу Сегодня я расскажу о том как мы делали собственно проектировали эти колоночные таблицы и какую модель мы придумали какие там базовые у нас структуры как мы их используем дальше расскажу собственно чем нам это встало потому что как бы имет последствия какие трудности у нас в результате возникли и как мы их решали Итак чтобы было как бы проще понять почему нам Я сказала изначально было сделать Это довольно легко Почему Потому что изначально проектировалась как платформа да то есть она это база данных которую можно чётко разделить на слои есть слой процессинга данных это компонент отдельный который привязан к том как там лежат таблицы внутри компонент который умеет распарсить входящий Сколь запрос построить по нему какое-то вычислительное дерево и дальше понять В какие шарды запросить данные отправить эти данные собрать отдать наружу в целом ему всё равно какие там шарды внутри он изначально так спроектирован поэтому как бы подменяя один тип шардов на другой Ну и Там сверху практически всё заработает а вторая часть которую мы можем также просто как как есть использовать от имеющейся системы это подсистема работы с транзакциями в idb поддерживается распределённые транзакции там значит тикает время общее значит всё это упоряд как бы строгий уровень се сериала был обеспечивается и всё это как бы мы тоже можем переиспользовать своей системе А в новом компоненте э третья вещь которая закроет нам кучу головни - это подсистема хранение данных это та подсистема которая собственно отвечает за масштабирование распределённой как бы Надёжность хранения данных это некоторый Data storage в который мы просто отправляем блок данных какой-то бинарный блоп получаем от него идентификатор если мы его получили всё прекрасно он там лежит в 3 4 5 ДЦ Сколько нам нужно чек суммы нужные считаются просто как бы пихай куски данных сохраняй дишни И знай куда их приложить Потом и всё прекрасно работает вот эти три основные подсистемы То есть как бы такие технические задачи которые нужно решить перед тем как ты будешь реализовывать какой-то там новый вид э метаданные новый вид таблиц они у нас решены сразу то есть Нам нужно сосредоточиться только на каком-то промежуточном слое метаданных Как нам данные собственно Да спроектировать как на эти блобы разбить как к ним построить индекс одного шарда и дальше уже с этим работать Собственно как бы мы ожидали что всё так просто и будет Мы у нас в целом компоненты забыла сказать про это в целом вот эти компоненты отвечающие за шарды данных мы их называем ещё таблетками можно на них смотреть как на как бы физически как на некоторый шарт данных просто кусок таблиц Ну в случае кортов это прямо кусок таблицы а с другой стороны это как бы некоторый там программный код куча интерфейсов Да которые говорят ну которые каким-то протоколами общаются с внешними системами снм с То есть это некоторый набор программного кода который этот шарт и обслуживает то есть Наша задача в целом сводится к тому чтобы по максимуму сделать там и чуть-чуть потютьков Дописать что табличка там снаружи вот у нас компоненты шар что табличка колоночная а не строковая и наверное балансировщика нашим сказать что как бы вот есть новый тип таблиц и ты в целом их балансирующий не так как ты это делаешь с другими таблицами потому что там во-первых они одни друг друга могут и убивать вот а во-вторых Ну в целом разный профиль нагрузки нужно пон системам про это рассказать Итого что мы для себя как бы решили что мы хотим сделать Мы хотим сделать переиспользовать во-первых все преимущество масштабирования которое нам даёт vdb Мы хотим сделать систему ну все все Наверно так хотят но хочется чтобы пользователь не страдал Ну то есть чтобы он взял данные развернул создал ночную таблицу правил туда данные и не думает больше ни о чём а мы уж внутри посмотрим на какие там блоки мы их Разобьём как мы их разложим если что шарды подвигам просто есть ограничение кластера не знаю там у нас там восемь да машин железных мы задаём там 64 шарда таблички они ездят между этими машинами наши наш балансировщик их перекидывает хотим больше там ресурсов использовать машины добавляем и он дальше переносит эти таблетки сами Ну то есть и ты не думаешь что как данные переразложение сама вот и собственно всякие там внутренние параметры опти майзер что где сколько потоков Ну как бы чтобы по минимуму приходилось с этим мучиться вот глобально нам Конечно хочется сделать Ну платформу А если кто был да на предыдущем докладе там довольно яркий пример там хотят люди начинает с начинают с ЛТП хотят построить аналитику ещё там им нужна очередь сообщени эти данные нужно как-то между собой синхронизировать Классно же как бы во если бы они могли развернуть один кластер и всё в нём настроить и им хорошо и нам приятно вот ну и в целом хотим чтобы это всё как-то жизнеспособности на Рассказываю что мы что мы делаем чтобы в целом представить картинку как бы сверху что происходит Аа сначала как бы как данные попадают в эти колоночные таблицы изначально У нас есть некоторые РПЦ куда м приходит данные Ну так как мы ожидаем аналитические данные представим что как бы ну типа Это скорее всего какие-то Бачи куски большие данные это какие-нибудь паркеты CSV в целом можно и построчно вставлять но мы сейчас пока делаем именно Ну типа в первой версии вставляем блоками пакетами либо через балка Асер приходят эти данные попадают в некоторый распределитель по шардам данные мы шарди сейчас по праймери ключу мы по нему их и шарди и сортируем э поэтому как бы если вы там какие-нибудь стмп как правило включается в часть праймери ключа то есть соединяется У нас сейчас а данные попадают в рва йте он значит их пилит по кусочкам раскидывает в Ну в нужный шарт ээ данные улетают в эти таблетки А дальше собственно Что происходит в самой таблетке вот уже в самом колом шарден у нас вся основная логика про которую я буду сегодня рассказывать в основном а данные приходят туда в формате Arrow мы активно переиспользование данных для представления то есть мы берём вот эти вот э рекорд Бачи которые там можно построить их у себя сжимаем сохраняем кусками используем активно вычислительные ядра Ну вот на старте в первой версии мы использовали именно вычислительные ядра из чтобы собственно всякие агрегации вот эти фильтрации все проводить простые вот значит данные попадают в таблетку Дальше они у нас оседают в так меня сбилось ой сбилась Где какая картинка Дальше они попадают в некоторый промежуточный буфер Зачем он нужен влом Яри хотим чтобы пользователь запарился на тему того как эти данные разбить Ты просто закладывает где-то в буфере дальше уже бьёт на кусочки и помещает в основной индекс этот буфер - это как бы такой промежуточный накопитель который помогает нам адаптироваться под разные поведение либо в целом они там лежат данные недолго если это был большой Ну как бы большой какой-то бач он Примерно там сразу начнёт разбиваться попадёт в индекс А если их данных было много они сначала подкоп потом попадут в основной буфер он персин как бы по нему да поиска идёт чуть менее эффективно чем по индексу но позволяет нам чуть более аккуратно заработать данные попадают в буфер дальше запускается некоторый регулярный процесс который эти данные собственно бьёт на кусочки порции и эти кусочки оседают в индекс А собственно сейчас-то Ключевое понятие в нашей архитектуре Это порция я довольно долго на погонах пыталась объяснить что такое время не понимают поэтому както сказать следите за руками порция - это кусок таблички а в базе данных То есть у нас есть таблица она отсортировано по праймери ключу мы берём эту табличку и так вот горизонтально нарезаем и как бы вот эти вот кусочки - это порции отсортированные по праймери ключкин таблицы вот у нас в буфере накопились данные там сформировалась вот эта таблица мы порезали побили на порции это как бы вот минимальная единица с которой мы работаем дальше везде аа это как бы в целом аналог вот я там написала на слайде это аналог sorting strict T который используется в кассандре в целом там примерно такая же идея А это кусок Что значит какие у неё есть свойства В итоге получается Там есть все эти данные отсортированы по праймери ключу Мы всегда добавляем дополнительную колонку а со с версиям данных Типа снапшота время по таймеру когда получается эти данные Зами Почему мы в кодах обеспечиваем как бы по умолчанию склеивание данных по первичному ключу то есть мы не выдаём дублей мы не делаем не склеиваем дубли на на заливке потому что ну это дорого их искать мы склеиваем дубли на поиске И потом ещё делаем дополнительные оптимизации чтобы этих дублей было поменьше поэтому как бы с каждой строкой данных мы храним некоторую версию чтобы понять Какую выбрать из сохранных данные оставляются целиком то есть мы сохраняем строки целиком не обновляя кусочки на текущий момент Итак а порции содержат вот эти снапшоты и порции могут на самом деле пересекаться Почему объясняю вот в идеальном мире как бы если бы пользователи писали всё время растущую табличку растущую по праймери ключу с растущим временем данные бы как бы постепенно укладывались друг за другом и индекс выглядел бы примерно вот так ну как бы здесь у нас primary КЧ растёт там у нас растёт время Ну как бы новая ступенька постоянно но данные приходят хаотично поэтому как бы мы каждый раз нарезаем этот вуфер на куски и закидываем их в индекс в итоге индекс выглядит примерно вот так там есть порции разного размера разного времени то есть в маленьких ключах есть свежие данных в свежих данных есть там как бы старые ключи и индекс выглядит примерно Вот вот такой вот Катавасия а и с этим надо как-то работать поэтому я сначала чуть-чуть упро картинку чтобы потом было как бы визуально понятно что я объясняю На этой картинке я заменила Ну вот эти порции на на отрезки да то есть у нас primary CL - это минимальные максимальный primary ключ по порции есть И минимальный максимальный снапшоте то есть в проекцию на каждую ось мы как бы понимаем что видно где в каких местах порции могут пересекаться потенциально При этом надо понимать что эти стрелки они на самом деле Ну это не целые отрезки они могут быть Вот так вот располагаться то есть по факту там может и не быть пересечений потому что сначала мы одни включи потом другие вставляем Но когда резали они ну потенциально пересеклись А собственно индекс в итоге выглядит вот такой вот штукой А как по этой штуке искать на самом деле довольно просто такой классический алгоритм который рассказывают всем в университете и где только не рассказывают это слияние сортированный списков мы идём фронтом от начала по росту праймери ключа Я всё думала что т у меня будет с другой стороны и я рукой не так махаю будет по росту праймери ключа идти вот этот фронт если у нас пор попадает туда как бы целиком ну смотрим на пересечение она там одна попадает целиком мы её засовывая в ответ Если есть какое-то пересечение собственно мы начинаем распаковывать и смотреть по а брать данные того ключа который по постарше по снапшота это как бы базовые понятия вообще базовые операции с которыми Мы работаем в в колом рде в Цем вокруг всего вот этого мы и пляшем то есть надо положить вот эти порции как-то их так расположить чтобы вот такой вот Поиск выборка по интервалу по ключу по которой потом мы будем делать агрегацию сработала эффективно Итак суммируем картинку дальше перейду уже к всяким деталям А у нас есть данные они значит в каких-то пакетах в в формате попадают к нам в рй раскидываю по шардам там основных с которыми мы столкнулись пока всё это делали первое как бы возникло практически сразу это как эти данные в эту порцию упаковать А как бы у нас колоночной хранение такая нативная идея Ну как бы сейчас колонки повернём в лабы положим и отправим их в наш хранилище А всё бы прекрасно но как бы данные они неравномерные у нас наше хранилище Тоже имеет определённые ограничение сверху какой размер обло можно положить маленький какой как бы насколько минимальный и если взять данные например логи там да там есть Джейсон Колонки есть СТМ колонки как бы разница огромная и как правило Джейсон колонка одна а мелких то там ле ещё что-нибудь их там до кучи Вот и как бы первая наша нативная версия была а давайте мы как бы ну самые пытаемся эти колонки максимальные блобы положить отрежем по жирное колонке А и мелкие такие кучу маленьких кусочков нам составят а так мы узнали что наша система плохо работает с мелкими бабами Вот она как бы отлично вычитывает большую колонку но с мелкой там она Т значит пу в полку и работает всё это плохо и мы поняли что это не вариант тогда мы начали поняли что колонки нужно резать на куски то есть надо взять отсечь именно порцию по может быть фиксированному числу строк Ну типа сейчас мы остановились Там на 10.000 строк так прикинули по объёму нормальное количество порций Ну это можно поправить но сейчас возьмём 10.000 вроде неплохо выходит А мы значит отрезаем эти порции смотрим жирные колонки бьём на куски чанки А и дальше их как бы Чан он должен быть просто в запакованный формате в сжатом Когда мы будем сохранять в dat storage быть не больше вот этого максимума А и собственно мелкие колонки все скидываем в один блоп и запихивает что-то как бы ну примерно такая история Да на данной картинке там C1 колонка которая ну она меньше чем допустимый размер бба у меня масштаб тут не сохранён я художник так вижу я только потом тут не масштаб тут цвет цвет - это значит отдельный бинарный блоп вот синенький значит там у нас влезла жирная колонка C1 и ещё две мелких влезли C2 и C3 а колонка C4 она типа очень большая Она её пришлось порезать типа основная часть пошла в отдельный блоп она там одна а её остаток уже пошёл в следующий колонка может и на пять там Лобов разбиться Вот но в целом как бы по мы стараемся сделать у нас сес жадный Довольно простой как бы мы взяли колонки отсортировано если мы там не можем положить колонку не реже в какой-то момент да типа не докладывать к мелким а положить целиком стараемся этого не делать потому что потом перепаковка сборки они нам на поиске могут Ну не очень удачно вылезти вот ну мы этот алгоритм конечно же как-то так это за интерфейсом изолировали если мы решим что он плохой нам больше не нравится Мы хотим сделать что-то более умное и красивое Ну мы там локальне ВС будет дальше работать как мы не будет слайм как мы оценивали этот алгоритм мы его как бы глазами оценивали мы наделали кучу графиков сколько у нас чанков сколько у нас порций как часто мы данные Режем или переупаковка мы считаем что типа алгоритм работает вот наш текущий алгоритм он как бы нравится нам на картинках на вот этих вот графиком его пока сохраняем дальше более интересные вещи про чтение вернёмся к нашей картинке пока вы фокусируется можно гладно собственно чтение У нас вот есть этот алгоритм сканирования классический сорванных спи вот один Мой коллега говорит что это самый востребованный алгоритм он на собеседованиях его даже только его и спрашивает типа говорит я в своей практике столько этих мёрз написал Вот всё остальное не нужно вот но всегда здесь есть нюансы В этих в этих мрх всегда Новые грани открываются Итак в целом если у нас слишком много мелких порций они скорее всего вот эти не будут пересекаться но как бы по ним метаданные надо хранить И это ну беда это память если порц сильно большие они будут более вероятно пересекаться поэтому тоже их придётся мёрт тоже не очень хорошо Ну и вычитывать эти получается Мы хотим чуть-чуть данных получить А вытаскиваем вот эти большие блобы которые у нас будут получаться вот при их пересечении нам нужно их мёрт а немножко промёрз порций собственно если порция у нас одна на интервале пока мы идём Это хорошо как бы мы Её положили целиком если нам не нужно ни каких-то операций дополнительно делать мы её можем прям практически не распаковывать там ничего не заглядывая внут мы е выдаём наверх на в процессор чтобы там что-то с ней дальше сделал посчитал А вот если порции пересекаются У нас есть как бы жёлтые порции Да жёлтые куски это нам нужно найти точку пересечения это у нас логарифм Бинар найти в этом сортированного наверх Но самое неприятное это когда данные У нас вот мыли сечение имы Нам нужно только перебрать Ну то есть нам надо взять все элементы проверить там может даже не быть этого пересечения но проверить мы должны вот чтобы сделать эту склейку по максимальному снапшоты и взять только верхнюю стрелку А вот и Собственно как с этим ну как бы как с этим делать тут можно двумя способами решать проблему первую - это просто придумать какие-то оптимизации в плохой ситуации то есть мы уже знаем что вот они пересекаются можно как-то попытаться себе облегчить жизнь Като порции например не распаковывать к нам как правило запрос всё-таки не Селект звёздочка аналитика - Это не просто всё посмотреть там не обозримое количество это какие-то фильтры сначала применяются данных Да по интервалу ещё по каким-нибудь признакам и фильтры эти спускаются у нас в шарт и применяются тоже на эти данные во время сканирования и собственно тут можно как бы на этом сыграть как Например если к нам приходит какой-то вот у нас есть две вот эти порции приходит какой-то фильтр и мы сначала к порции собственно распаковали её применяем фильтр это более уже Блочная операция Да это быстрее чем мы всё переберёмся нам не нужно мёрт потому что если эти данные и раньше нам были не нужны ну как бы ну в новой версии только может что-то появиться А это определённая оптимизация тоже в целом на большом количестве пересечений даёт неплохой Профит всё это сам вот этот вот как бы МЖ спис звучит очень просто и красиво но как бы в распределённой мель когда у тебя куча данных этот слайд не чтобы читать а чтобы впечатлить как мы код умеем писать а почувствовать вроде бы простой алгоритм Да который на пальцах очень легко объясняется склеить списки но мы знаем что у нас много данных у нас ограничена память мы иногда эти пор порции целиком в память влезают а там три штуки уже могут и не влезть мы как бы сжатые данные мало Места занимают сжатых данных размеры распакованные как бы в метаданных порс сохраняем И их нужно при чтении при мержи все учитывать и как бы смотреть там нужно прочитать мы приходим там как бы к определённой порции нужно её асинхронно куда-то отправить распаковать отправить одновременно распаковывать не больше нужного числа порций Чтобы они не конфликтовать то есть это система ресурс брокеров котором мы говорим сейчас будет как бы таска на такой-то объём на такой-то цпу и дальше ВС система конвейеров которые как держит Гард на эту память и понимает что сейчас у нас вот уже какой-то большой кусок данных обрабатывается и ну как бы идёт щение Что следующий там вперёд зачитывать нельзя и то есть вроде бы простой алгоритм Но на самом деле он тратит там под собой типа надо изрядно подготовить инфраструктуру чтобы чтобы делать потом это просто чтобы всякие оптимизации по фильтрам потом туда легко встраивать это про поиски оптимизации на поисках на вот этих снах вторая часть что мы можем делать Ну как бы Зачем проблемой бороться Когда уже наступила Давайте заранее данные пытаться как-то в порядок уложить получше поудобнее и мы делаем некоторые регулярные оптимизации индекса то есть вот у нас было плохое состояние Мы хотим как бы чтобы было состояние получше здесь в качестве примера я беру и дальше на оптимизации буду говорить про сценарий э для использования колоночной хранения для хранения логов просто потому что у меня есть хороший пример на нём мне кажется довольно легко Ну как бы понять и на нём удобно показывать то есть в хорошем состоянии если у нас этото логи там отсортированные по тайм стмпу старые данные уже не меняются а в голове постоянно происходит какая-то каша там ретра из кучей источников данные учитываются они перемешиваются в целом если мы в хвосте будем поддерживать порядок а в голове Ну он будет ограниченное время то нас это вполне устроит а в целом задача чтобы решить эту задачу как бы нам нужно два компонента собственно один по компонент - это тот который нам говорит типа оптимизатор который говорит какие Вот бери вот эти порции Они тут больно пересекаются собери их в новые он выбирает порции А и второй компонент их перепаковать значит оптимайз как это устроено под система это некоторый Ну некоторый компонент который постоянно он он он подписан на изменение как метаданных в шардена появление новых порций он на них подписан он смотрит там сколько добавилось сколько ушло какие-то считает метрики и потом эти метрики позволяют ему в моменте регулярному процессу сказать всё вот к нему приходит говорит какие порции А вот эти бери А вот эти Бери чтобы он долго не считал то есть чтобы процесс Шёл как бы нон-стопом поэтому он в фоне пос Ну досе этого потому что ну вычислить тоже не супер быстро кого выбрать вот выдаёт задачи для упаковщика и в целом его задача выдать порции так чтобы нам ещ бы и переливать был поменьше упаковывать Потому что если мы будем всё весь как бы пул данных имеющих у нас переливать как-то блобы перестраивать да которые в бло стороже лежат это значит и надо достать не просто не всегда можно просто метаданные перестроить их надо будет распаковать склеить найти дубли он как бы за всем этим делом тоже следит выдаёт задачу с этим списком порций всякие там до неё дополнительные ограничения и как бы дальше эту задачу уже берёт упаковщик там работают алгоритмы похожие собственно работает как такой Минин он по этим порциям делает Примерно вот эту же историю с конвейерами как их Вычитать и собрать в новые порции Мы в первой версии так не делали и в какой-то момент мы кажется из нескольких порций собрали новую и там получилась такая колонка что она просто не вылазила в память на МР постоянно падало всё вот поэтому как бы вот этот контроль он нужен вообще на каждых этапах вот эта система конвейеров которую мы разрабатывали изначально для поиска она как бы вот прям сквозная вот инструмент подготовить себе важно прежде чем ты нач умничать следующее собственно упаковщик отработал он вернул результат это порции которые уже не пересекаются это как бы важное свойство алгоритма у оптимайз и упаковщика на выходе лучше выдавать уже хорошие результаты некоторые потом ещё можно улучшить вот Итого мы значит ключевой здесь это именно вот этот вот оптимайз придумать оптимайз довольно сложно поэтому первое что мы сделали мы его изолировали ну можно было не получится сделать другой как бы не надо было Потом значит что мы придумали весь код завязали на эту логику оптимайз потом поняли что она плохая и ещё значит полгода его переписываем поэтому Значит первое из чего как бы наша политика что-то очень сложное изолируйся с этим главное сначала чтобы было рабочее на этом сделано а потом уже что-то а потом это нужно улучшать у нас В итоге там три версии оптимайз на самом деле есть от простой к сложной на которой мы остановились Я Расскажу чуть позже значит он должен быть изолированным это самое главное Дальше он конечно же мы бы хотели чтобы он адаптировался под профиль нагрузки да то что я говорила в начале а мы в целом не не хотим чтобы пользователь парился на тему того вот как как вот я лью данные вот сейчас мне так надо потом у меня система растёт профиль меняется да или там по выходным по-другому А чтобы система под это адаптировалась в целом понятно что под разную картинку разные оптимайз нужны то что мы там можем их переключать делая разные реализации мы можем в какой-то момент можем придумать прям супе адактилидиум углом смотрим на те же данные вот а но сейчас мы выбираем один пока больше вот лого ориентированные данные А у оптимайз что важно ему всегда должно хватать ресурсов это регулярный процесс который должен допускаться всегда если он остановится то мы как бы на поиске грем вот ну и самое главное что он должен делать это собственно целевые функции То есть он должен оптимизировать Ну то есть индекс должен становиться лучше а один из примеров оптимайз который мы вот используем прямо сейчас для там лого в части внутренних сервисов мы его называем батм оптимайз потому что мы вот Бакета назвали структуры ключевые в нём идея в том что мы собственно смотрим на наш индекс делим его на такие кусочки Като бакеты в баке есть основная порция которую мы считаем Вот ну типа она самая большая Она хорошая и в неё вы в идеале всё подмерз Вот И там могут быть типа много маленьких которые пересекаются с ней либо пересекаются с соседними а то есть вот выделяем мы вот этот Бакет А эти бакеты они строятся каждый раз на лету типа ну то есть точнее не так неправильно я сказала оптимайз же постоянно накапливает своё состояние поэтому он типа на старте их построил они данные не размеченный он загрузился их построил а потом держится это состояние помимо метрик Он держит эти бакеты и по ним там выбирает тас дальше собственно А в каки Ну Бакет должен то есть быть Вот какая-нибудь старая хорошая Такая проверенная порция Вот которую мы подклеивать маленькие кусочки всякие маленькие порции или очень-очень свежие мы пытаемся как бы они не могут стать образующими потому что Это скорее всего голова и там вот это какая-то каша ме сня происходит Мы лучше подождём пока эти данные уедут чуть в прошлое и там уже как бы Когда замес прекратится мы уже как-то всё уложим чтобы меньше собственно перепаковать и меньше мучиться а дальше мы берём эти бакеты оптимайз на них смотрит а и выбирает в каждый момент времени какой-то один самый с которому Как сказать самый классный и наоборот не самый Ну который он считает что сейчас вот пришла Его пора его час а он выбирает лучший кандидат на на перепаковка нам может испортить собственно есть некоторая функция которая набор какой-то некоторый палиндром с пока мы там подбирали коэффициенты кото зависит от количества порций Да если их много она должна расти если там много пересекающих порций эта функция должна расти и как бы падать при А если очень много данных придётся перепаковать может быть лучше это не делать если там не так много пересечений но надо Ну типа очень жирные порции Вот то возможно нам дешевле вот этими логарифмами пересечения найти выбрать под куски и лучше мёрт их на поиске А вот я не стала приводить что как бы там с этими коэффициентами функции я кинула ссылку на код как это самые детали всегда можно почитать немножко в этом смысле двигалась в целом мы что сделали Сейчас мы под текущую задачу как-то подобрали Вот в тот момент когда нам понадобится лучше мы ну подумаем об этом ещё как я говорю подход к тому чтобы локализовать самый ад он в этом плане Нам очень помогает а и что у нас получилось а сейчас будет пример как бы рабочего кластера этот на котором я хочу показать типа мы вот какой-то жизнеспособные взяли кластер который может поднять каждый Вот и взять реальную продакшн нагрузку и показать что с ним можно работать то есть мы взяли кластер на восемь восемь хостов подняли на нём на каждом хасте по две вычислительные ноды в idb То есть это как бы отдельные процессы они работают Независимо это как бы дополнительная наш способ параллелизма Вот и на на каждую ноду у нас было типа по 16 ядер То есть всего у нас кластер на 256 литних ядер в которые мы пускаем поток логов сначала как бы Когда Вы начинаете ну сервис Он где-то там копил свои логи Когда вы их включаете первое что случается - это бум потому что он там 3 дня хочет эти логи хранить какой-нибудь там где люди обычно налоги хранят в кафке от нас в кафке Вот они у вас копились и вы такие а дайте-ка я их сечас в аналитику положу и значит Сначала мы получаем там X5 нагрузки потому что всё за все эти 3 дня сейчас Ну бахнем Вот то есть в целом Стартовая заливка - Это 4,5 там до 5 Гб в секунду логи пока просто накапливаются мы разгребаем голову Мы сначала как бы подождали пока мы ну не не делали считаем что люди в этот момент они ещё не не нагоняют пользователей в свою систему логов и не говорят Мы теперь Ищите в них потому что там ещё старые данные когда мы разгреби голову постоянный поток логов у нас был примерно 2 Гб в секунду а Даже на самом деле 2 и п я тут немножко цифр которые дальше приводила были больше на 2,5 2,5 Гб в секунды данные заливаются Теперь мы хотим собственно сделать какой-то эксперимент сравнить с жизнеспособной системой к нам пришли коллеги сказали У нас есть кластер на кликхаус у нас там вот столько же ядер Ну с развёрнутой конфигурацией на таком же железе Как у вас Мы хотим вот если мы сейчас заменим на вас будет работать или нет И они дали нам некоторые цифры на которые нам надо было равняться как мы эти как они мы эти цифры получали данные реальные это логи то есть надо как-то нельзя взять их их цифры которые они вчера посчитали потому что сегодня всё по-другому Особенно если они считали там в субботу а у них много логов в другой день а поэтому они мы подобрали интервал тайм темпов свежих логов в который попадает там 70 млн записей и дальше уже выбрали этот интервал зафиксировали его ну то есть перед экспериментом нашли его и дальше уже на нём пытаемся прогнать запросы а первое что хочу показать до того как покажу результаты вот эта вот картинка где я говорю как поиск идёт мы её визуализировать Сколько у тебя каких порций там было Какого типа и собственно можно посмотреть вообще как алгоритм сработал на самом деле потому что ну на больших этих объёмах уже сложно как бы что-то глазами наблюдать только графиками только кардиограмма жива или мёртвая показывающий данную картинку там сейчас вот не вспомню Ну то есть там это какой-то был ну запрос фильтрации по интервалу там какой-нибудь L level Было ли а данные в джейсоне и мы в целом получаем что у нас оптимайз сработавших да то есть данные лились работал постоянно оптимайз и у нас получалось э тут порядка там ди один к ТМ Да соотношение между прямо супер классными порциями которые там попадали в хвосте и сильно пересекающимися которые были в голове вот в целом удобно было наблюдать вообще как алгоритм работает Что происходит то что мы ожидаем Какие запросы мы смотрели мы брали как бы нам дали типовые запросы которые делают логом мы брали в этих интервала я их упростила потому что они бы не влезли это как бы самая суть простой Ну типа Господи как слово забыла агрегация да там каунт звёздочку мин Максу это типа нулевой запрос а давал агрегации и сортировки ой сортировки и фильтрации в целом мы на старте больше фокусировать на фильтрация вот эти вот всякие оптимизации дополнительные на поиски Чтобы меньше пересечений было и чтобы там не дотаскоп хаосе вот на группировках Ну есть ещё над чем поработать а но что как бы Зачем этот слайд показать что как бы мы видим что система в целом жизнеспособны получилось тайминги здесь не сказала это как бы секунды то есть там запросы до до 2 секунд получались в целом если говорить для прологи где сидит человек там и ищет смотрит что там получилось 2 секунды Ну ту тут разница как бы такая не сильно заметная глазом вот а выглядит как то с чем можно работать а и собственно дальше мы Тоже планируем с этим работать и делать лучше а в целом я заканчиваю Какие хочу сделать выводы Я здесь выводы больше про разработку Да в целом когда ты начинаешь разрабатывать новый компонент даже если у тебя кажется базова простая очень логичная и красивая идея модель Ну что там вот как бы порции и мёрз ь эти порции особо больше ничего не происходит а но внутри много всяких нюансов И пер и большой Айсберг того что нужно где потютьков означает супер простую реализацию и в целом наверное в распределённых базах данных трудно придумать простую реализацию поэтому наверное классно когда мы не придумываем сложные идеи вот если идея сложная ция сложная то потом вот такой вот график как бы не построишь и в жизни не разберёшь что происходит проще может заново начать вот поэтому как бы в плане выводов мой Такой типа локальный мой призыв у Прощайте по крайней мере верхний уровня сложности вам ещё хватит вот а и сложные штуки их очень круто и полезно изолировать Потому что когда они вас достанут вы можете сделать простое решение и позаниматься чем-то другим а потом вернуться к ним и ещё доделать и ещё копнуть глубже вот плюс дела простые решения можно делать Ой уже что-то работоспособное вот и ещё такой важный вывод мне мои коллеги некоторые сказали что он валиден только для вас вот у вас большая система и большая платформа поэтому вы можете сказать как круто работать в большой платформе типа у тебя есть всё готовое Но на самом деле а мне тут хочется сделать более широкий посыл Мне кажется когда вы что-то разрабатываете пытайтесь смотреть на это как на штуку которую можно потом переиспользовать Ну то может какая-то локальная платформа Но если вы можете переиспользовать свои решения в рамках там любого сервиса там базы данных я какое-то время работала в платёжных сервисах Если вы можете взять какой-то кусок И использовать как бы для расширения для другого компонента это очень круто и на этом ну к этому я считаю надо стремиться это прям приятно потому что даёт вам возможность потом в будущем сфокусироваться на чём-то действительно сложном что вы изолируется вот на этом У меня в целом всё спасибо вам что вы меня послушали Надеюсь было понятно Буду рада вашим запросам Спасибо я Напоминаю что за лучшие вопросы у нас есть призы Так что давайте задавать хитрые вопросики даже не знаю откуда начать столько рук Да я думала сейчас хочешь я тебе ещё тему для спринта на не хочешь ещё систему сменить у меня вот какой вопрос Ну начиная с темы вообще и на протяжении всего выступления он меня мучает хаос и вопрос ожидаемый да то есть тут алап там алап из того что я видел заливка и туда Бача и сюда паркета цсв ками Ну то есть это не те же самые данные которые и рождаются в этом ддб то есть их надо ещё заливать большим потоком и отсюда возникает резонный вопрос а Какие конкретно плюсы и бенефиты и выигрыши именно ебш Наго хранения по сравнению с кликхаус нам то есть а ради чего вся эта игра потому что ну если вы и так сделали инструмент который для Апа это немножко странно когда мы делаем ещё одного ребёнка чтобы немножко насолить другому Это хороший вопрос но это немножко не про то я надеюсь что я думала что посвети в начале но повторю во-первых мы говорим что ну типа вот Это пример что я привела что Да он как бы стартовый такой в целевой картинке Мы хотим чтобы система была цельной Ты разворачивает какие там cdc потоки из своих транзакционных обычных таблиц Аля Как в постгрес ты положил их в idb А как ты с ними работаешь потом настраиваешь внутри cdc поток рядом создаёшь колоночные ничего дополнительного не разворачивая и у тебя поток идёт не внешних данных каких-то бачей а сама vdb теб то есть там готовит Эти пакеты внутри эти Бачи переливает в колоночные может быть Там классно было бы сделать там подержи транзакционные Какие делать там типа ты данные записал ре какие-то аналитические сразу преданные почитались В соседнюю табличку положили а сбоку дашборды и агрегации поэтому считаются Ты их используешь как бы это всё сделано как промежуточный шаг такой более системной картинки Можно я тоже Соф попробую Ответь на это вопро свойстве перепрятать база данных - Это нерешённый вопрос мы не можем построить одну базу данных и сказать что всё всё Вот теперь правильно Так вы так и делаете новую серебряную пулю чтобы туда можно было и не первая база данных в Яндексе их было десятки до этого и это технический поиск он может здесь может это как бы всё правильное решение А может будет что-то ещё Ну да ещ плюс как например мы мы берём какие-то вещи которые вот мы делали в ADB у нас в ADB Хорошо хорошо шарди ется там хорошо работает авто шардирование и в целом Вот это та фича которую мы хотим переиспользовать то есть мы хотим чтобы дальше расширение колоночной базы тоже было прозрачно добавил хостов у тебя вычислительных ресурсов Stage там прозрачно для тебя данные е если нужно переложила е нужно даже не перекладывать потому что как бы объёмы метаданные же на нужном на нужно Наде только подгрузить нужно и всё нужно нужно нужно Ну кликхаус решал одну простую задачу заменить вертикуттер ли вопрос задать уже Да да Давайте ещё вопросики Так где не вижу а всё вижу Да Дада Здравствуйте спасибо большое за доклад на самом деле очень интересно и вы и так очень подробно сконцентрировались на вот как бы логике хранения да на механизмах и смотрите вот такой вопрос У меня Я же правильно понимаю как бы я в примерах не увидел но предполагаю что операции соединения Да они же тоже поддерживаются Ну Join операции как в классических собственно движках вот а вы ещё сказали что Ну вот делали упор на слово merge я же правильно понимаю это вот физическая операция которую оптимизатор выбирает Да при как вот соединяет наборы данных слева справа и выбирает физическую операцию merge и Просто у неё Ну действительно пререквизиты такие что набор данных должны быть отсортированы предварительно и вот у меня вопрос А что делать если в каких-то определённых случаях не всегда ч подходит есть же там ну Nest Loops Да есть ещё там ш Match когда там данные уже сортируются либо на литу либо прогоняю через какую-то функцию Да сложную которую вот в реальном времени выполняется и вот этот реквизит про сортировку не может быть соблюдён но с другой стороны про сортировка у нас обеспечена физическим хранением что мы на уровне шардов по праймери ключу храним всегда сортированный набо Ну то есть как бы насколько вариан движок под разные кейсы Вот это первый вопрос а второй вопрос смотрите про слово оп Вы тоже упомянули И я вот изначально когда Шёл на Ну как бы к вам на сессию я предположил что вы расскажете что-то типа про кубы Да но я так понимаю под слово алап вы имеете в виду что база она для аналитической нагрузки да для быстрых вот каких-то там ну обработок вот просто что вы не делаете какой-то семантический слой в котором там звёзды снежинки да Ну вот эти классические олав штуки вот да А давайте Ага С первого вопроса да мира измерения Да вот коллега подсказывает А с первого вопроса Мы в целом пытаемся я говорила несколько раз то есть мы пытаемся добавить как бы побольше вариативности чтобы себя не ограничивать но сейчас мы действительно А вот как бы у нас все эти сортировки Да по праймер ключу потому что нам вот эти поиски дубли склейки они для нас важны А и мы как бы больше на ну на вот этот сценарий затачиваем но в целом Я думаю Э ну то есть я не скажу что мы прямо сечас сейчас сейчас уже как бы в других разрезах много подумали а но ну хотелось бы сделать вот эту гибкость в плане того что сосно нам не нужно вот эта вот уникальность не нужно вот эту сортировку праймери ключу делать какие-то дополнительные где-то структуры оптимизации Мы в целом уже для оптимизации различных фильтров и выборок делаем Ну то есть в метаданных порции там по по возможным данным там всякие мин Максы какие-то разреженные фильтры пытаемся хранить это про первая часть про то что это не общая а не общая пролаб систему Да мы хотим э Возможно это построить но нужно с чего-то начать Для начала нужно данные сохранить чтобы Дальше можно было с этим как-то работать поэтому сейчас мы готовим вот этот Базис А вот дальше надо исходить уже из задач которые э стоят как бы перед сервисами которые к нам приходят и и говорят хотим vdb вот э как бы чем больше появляется запросов тем а я уточню что речи о модели данных MDX не шло её реализовывать никто не собирался снежинку Вы можете сделать из таблицы это нормально похо Понятно Ну то есть сами уже да делаем как бы свой кастом А тогда можно последний вопрос вот к тому что вы сказали что Вы сейчас хотите сделать некий Базис а потом развивать Я же правильно понимаю что ну какие-то доступные род мапы есть да вот можно посмотреть на продукт и как бы в Горизонте там ну там год три-пять лет Да как бы и смотреть что вендер предполагает Ново е запихнуть туда каких-то фич штук Ну бы то есть это открытая информация можно смотреть в интернете или на сайте Мы очень открыты и код У нас очень открытый лежит в Open sce по поводу ропа У нас есть на стенде Open Source нашим индексом можно посмотреть на ближайшие пару лет по поводу того если он где-то у нас там на сайте я туда не смотрю мне в трекере на работе показывают Возможно там он тоже есть можно не просто посмотреть вот там вот стоит Олег можно к нему прийти и попробовать на roadmap повлиять сказать что мы хотим MDX Мы хотим измерение меры агрегацию А в Росреестр вы не заходили да ведь вот тут бы Олегу дать микрофон Он наси вопрос нашли вы зелёные отлично Спасибо Давайте ещё какой-нибудь вопрос Добрый день спасибо за доклад я ээ э пересекается с предыдущими вопросами э первый вопрос немножко троллинговый Почему вы парты из Клик Хауса назвали порциями а а мы мы художники мы так и видим так получилось Лёша миловидов тоже колонки называл столбцами просто потому что ему это слово больше нравится русский язык язык Пушкина богат на разнообразную классную лексику надо кто-то кто-то естественно назвал и оно прижилось да Угу а второй вопрос собственно у вас жёсткое шардирование Придумано по сути по первичному ключу и потом по тайм стмпу я правильно понимаю у нас шардирование по первичному ключу сейчас чтобы сортировку собственно по по тайм стмпу задать Ну он по праймер ключу и сортируется поэтому как бы включаем его типа как первой поле в праймери ключа ну это прямо В текущей версии Мы хотим как бы шарт именно привязан именно к к Туда входит сейчас туда входит Ну получается тогда что мы не можем например добиться локальность данных если Делаем джоны из разных таблиц Ну чтобы они на рде на одном были и там проходила агрегация не гоняя данные по сети на у нас нет у нас в целом шарди идёт по таблицам Поэтому если давать информацию более верхний уро компоненту конно эти шарды двигает а они двигаются легко Да потому что как бы ж отдельный система метаданных отдельная Поэтому если в целом видя что у нас склеиваются данные таблицы определённые шарды задействуются мы можем шарды разных таблиц положить рядом И тем самым обеспечить локальность То есть это автоматически вот этот вот оптимизатор сделает или как Да то есть мы сейчас на самом деле мы сейчас на ним как раз ну его собираем его пишем этот оптимизатор и идея именно такая так как у нас по шардирование таблиц чтобы он просто их перевозил коллеги у нас тайминг к сожалению не позволяет дальше продолжить но Софья будет недалеко где-то ещё можно вот Алексею или Олегу задавать много вопросов про А сейчас Софья нам надо решить какой вопрос был самым лучшим Если честно мне очень понравился последний вопрос про меня это ещ никто не спрашивал про да давайте подарим подарок от партпро по от конференции Большое спасибо за доклад было замечательно Да спасибо вам и ставьте плюсик Так где-то где мой QR код Где мой приз личес их симпатий просто Верните он там был за твой доклад обязательно проголосует Не забывайте голосовать за доклад Софии и сказать что он был классным"
}