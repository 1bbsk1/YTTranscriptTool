{
  "video_id": "5KQsNmRTQmg",
  "channel": "HighLoadChannel",
  "title": "Разгоняем обработку событий до 1.6М/сек. Опыт Badoo / Александр Крашенинников (Badoo)",
  "views": 7274,
  "duration": 2817,
  "published": "2018-11-19T02:51:40-08:00",
  "text": "привет друзья спасибо большое чтобы доклад я извиняюсь за накладки со звуком это неловко ситуации когда хочется чтобы был голос как у луча хотя он себя как у михаила боярского и так кто из вас пришел послушать про то как обрабатывать полтора миллиона со быть в секунду пожалуйста поднимите руки отлично я надеюсь что будет вам приятен тот факт поговорим ел прячешь на самом деле мы говорим о чуть больше цифр и а именно 18 миллионов секунду вы за время пути собачка могла подрасти и так о чем мы с вами поговорим во первых это я и александров и работаю в бега занимаюсь руковожу командами которые занимаются инфраструктурными штуками связаны с обработкой данных вот я уверен что классный распределенных систем можно готовить из окон source и и не платить вендору поэтому я люблю кли house hadoop и и spark о чем мы с вами сегодня поговорим мы поговорим о том зачем вообще нам собирать статистику в проекте какие у нас есть для этого средства и чем с этими данными вообще потом будем делать я извиняюсь технически накладка если будет возможность вывести мне на монитор слайды я буду очень благодарен спасибо итак начнем со сбора зачем мы можем собирать статистику в первую очередь эта мониторинг жизнь способность вашего проекта если в вас нет данных вы слепы вы ничего не можете сделать со своим проектом эта труба далее нам нужно давать ответ на вопросы бизнеса потому что техническими то их техническими но бизнес тоже заинтересован каких-то показателях их seo надо считать и наконец штук который мне больше всего нравится я ее держу для себя девизом что хоть что-то улучшить из измере это а мы как инженеры мы должны стремиться к тому чтобы улучшать наши продукты но в первую очередь конечно это бизнес это его его ответы на вопросы бизнеса жизнь цикла статистике я определю четырьмя пунктами это define коллектор процессы презента и про каждый из них мы сейчас будем отдельно разговаривать начнем с фазы define что общем мы собираем в приложении это бизнес метрики на то есть ли у вас водочный сервис наверно будет интересно сколько у вас фотографий в день занимаются от час так далее и так далее и тому подобное есть такие полу технические метрики например насколько ваше мобильное приложение для ваш сайт отзывчивый то есть как ваша api работает насколько быстро пользователи взаимодействуют с вашим сайтом какой него unix и так далее наконец это самая классная штука trackid поведение ну то есть если мы говорим про системы типа google analytics яндекс метрика и так далее вот у нас тоже и то есть она свое классная и мы очень сильно инвестируем в это тут интересная штука что в процессе работы статистика очень много пользователей это разработчики это бизнес это аналитики так далее и важно чтобы все взгляд на одном языке поэтому а договариваться договариваться можно устно но гораздо круче когда это происходит в какой-то формальной форме а именно в четкой структуре событий то есть мы говорим о том что когда василий говорит сколько у нас регистраций аналитик понимает что разработчики предоставляем информацию о том сколько нас регистрации не только в общем но и в тальные стране какая нас разбивку по полу и так далее и тому подобное и все эта информация на формализованном и вот например у себя храним эту информацию в протокол батерс формате то есть у нас есть событие регистрации там есть пользователь у него есть пол из какое-то время конца быть случилось есть страна в который зарегистрируется пользователи то есть эту информация доступна аналитиком дальнейшей бизнес понимает что вообще собираем и что интересно эта штука красной нитью потом пронизывается еще в описании бизнес лайки то есть например у нас есть внутри система описание бизнес-процессов и вот у нас есть скрин и потому что на свет новая фича им в правда крикун документе есть секции о том что когда пользователь взаимодействий положение таким образом мы должны еще до кучи отправить event-ы из точно такими параметрами и в последствии мы сможем во лидировать насколько наши фичи хорошо работают и очень крутая штука что наличие такого формальное описание позволяет нам в дальнейшем иметь представление о том как эти данные сохранить в той или иной базе данных не важно пока это новый сквер леску или так далее в принципе у нас есть схема данных и это очень круто в принципе если у вас не очень много событий да там например я слышал в некоторых аналитических систем которые представляются как сервис в подноготной то есть хранилищ непосредственно там около 15 например со быть у нас это число щас доросло до более чем 1000 и собирается останавливаться и соответственно без caught единого реестра жить не возможно дать подведем итог нашей первой фазы то есть мы решили да ребят мы понимаем что статистика это важно и мы описали некую предметную область и это уже прям некий вин с этим можно жить дальше ехать давайте рассмотрим фазу коллег то есть сбор данных мы в принципе для себя решили строить систему таким образом только нас происходит бизнес события то есть регистрация отправка сообщения лайк и так далее то одновременно с тем что мы гул от сохраняем эту информацию мы еще отдельно кидаем кидаем будем использовать термин некое статистическое событие и она обрабатывается совершенно независимо от хранилищ данных которых работы приложения то есть например еще раз когда как в коде это выглядит значит нас есть описание событий регистрация и автоматически его сгенерируется и пиаре доступны пользователям разработчикам из кода которые в четыре строчки позволяют отправить статистику это внешняя наша система почему мы так делаем потому что у нас есть например какие-то невероятный сервис которые предоставляют нам api для работы с данными фотографиях еще чем то и они все хранят данные вот я например взял какие-то две классные новомодные базы и распайка короче где они хранят данные там биой когда захочет построить reporting какой то ему не надо будет ходить и побираться у ребят а сколько вас тут этого сколько у вас это у нас все данные от отдельным flow то есть мы должны снять это приложения отвязать все эти данные и отправить куда-то дальше в отделе pipeline то есть когда мы говорим про фазу коллег значит мы вас есть наши applications сервера у нас это например php у кого например кстати еще папа есть вниз по настройке нас малварь телегах вот мы с вами сейчас рассмотрим фазу как из нашего плетения сервера в какой-то blac box наша статистика дальше поедет мы будем называть эту штуку транспортом меры к многи из вас уже догадываются о чем будет речь дальше идти значит суть в том что транспорт это некая система которая нам позволит вот это то что вы выдернули из контекста приложения отправить в другой pipeline выбирается исключительно из ваших требований какая у вас ситуация в проекте есть такие характеристики как гарантия доставки то есть на руках все слышали от лист vans excerpt vans и прочее значит это характеристик транспортом выбирается под ваши задачи статистики насколько вам эти данные важны то есть очевидно что какие-то биллинговой данные недопустимо чтобы вас транзакции в статистике отображались больше чем их есть ну потому что это это тупо деньги нельзя никак опять же транспортом над как взаимодействие соответственно надо выбрать под язык на котором написан проект и раз мы говорим про какие-то миллионы в секунду то хорошо будет лежать где-то в уме о том факт того что мы будем это масштабировать дальнейшем вариантов овердохрена база данных которых приложения хранит свои данные какие-нибудь цифры флинн диета кафка про которую разумеется уже не первый год рассказывает но поскольку мы абсолютно у ворот и мы используем лсд это наш путь особый и звуки лсд это не имеет ничего общего с ким запрещено веществами это просто живой стриминговый демон который очень быстро и который не представляет какого-то агента для того чтобы него записать мы его умеем тюните так далее до кучи у нас существует интеграции с какими-то другими системами такими как fs кафка и так далее то есть мы можем отправленные данные перри стрим ливать куда-то и прочее прочее и самое классное что это упал сразу компаний баду соответственно нет повода не доверять этому программу обеспечения разумеется если бы это был такой идеальный демон то вместо кафки могу на каждой конференции обсуждали лсд у нас есть свои constraint с которым мы живем который под наши нужды настраивают в частности лсд нет поддержки репликации и гарантия доставками в это листва то есть опять же если мы говорим про деньги то наверно это будет не сам подходящий транспортного в принципе как на ходе конференции говорили что с деньгами-то обращаться исключительно стрельца через милиционной базы данных через кислотный весит итак подведем итог фаза collect мы основании результатов из предыдущей серии учили формальное описание наших данных мыс не сгенерировали отличный и удобный для разработчиков и наконец мы придумали как эти данные транспортировать из контекста приложения в какой-то отдельный pipeline в принципе уже неплохо и сейчас мы будем подходить к фазе которы называется процесс мы четко собирали да все знают о том что существует регистрации а плоды фоток голосовалки и прочее прочее что этим добром всем делать чем хотим за и тогда на получить но мы хотим построить графики потому что графика такая штука который все понимают смотрят понятно у меня быть разработчиком доход компании растет на графике это видно все счастливы и разумеется для каких-то более сложных случаев наши аналитики захотят выполнять аналитический запросы на этих данных то есть и этот этот функционал нам нужен графики бывают такие такими-то разбивка my графики бывают с большой истории годами то есть у нас например есть данный график у которого история там более десяти лет надо понимать что это длинная и интересная история графики бывает даже вот такие это результат какого-то б теста и он удивительно похож на здании chrysler а также будем рисовать график ну тут у нас есть два стула два способа есть вариант каждый раз когда мы рисуем график за паши какие то сырые данные есть вариант рисовать графики из такого time series тораджа этот тот подход обладать недостатками которые достоинствами который мы сейчас не будем останавливаться подробно то есть но я скажу что поскольку я понял что нам нужно это это то есть будем использовать гибридный подход когда мы будем какой-то кусок данных держать оперативно для оперативного reporting и для долговечности у нас будет time series стоит заметить вот я говорю у нас там 18 миллионов в секунду до но это довольно долгая история это рпс не случился в один день и подает компания с более чем 10 лет истории и этот путь мы прошли это не был какой-то скачок и так далее как это все эволюционировала нас было ничего учет начали собирать нас получилось например 5000 на быть в секунду принципе кожа руку на сердце с этой задачей стараюсь справится любая реляционной субд и с ней будет комфортно вас бы транзакционных вас будет там класть эти данные потом по ним запросы все классно все довольно неплохо потом мы также или какое-то время разумеется в какой-то момент случился функциональный шарден когда данные на регистрациях сюда фотках сюда так мы дожили до пример 200 тысяч за быть в секунду мы начали применять всякие комбинированные подходы о том что мы не начинать или уже храните сырые данные агрегированные но пока еще в пределах реляционной базы данных ну и когда мы говорим о том что мы храним счетчики то судьба инсталляционных база данных такая что на этих фото невозможно будет выполнить destin запрос потому что алгебраическая модель счетчиков такого что здесь никто там не посчитаешь нас в буду есть девиз unstoppable force и в этом случае мы его тоже придерживались и мы не собирались останавливаться мы росли дальше в этот момент как раз когда перешагнули порог 200000 события секунду мы приняли решение вот эта формального описания которую я говорил раньше потому что раньше был хаос некий терем получили структурированы реестр событий так далее мы начали скелет нашу систему мы подключили hadoop все данные легли на свой некий хай в таблице кто понимает что такое ходу пухаев они ведь пожалуйста руку в общем это hadoop огромный программный комплекс файловой системы и так далее для распределенных вычислений есть штука которая говорит вы положите мне данные я вам позволь выполняет все политические запросы на них так мы и сделали мы написали регулярный и расчет все графиков классно но графика такие же такая штука они имеют ценность когда они достаточно оперативно обновляются то есть если мы раз в день смотрим какое то обновление графика это не так весело и если мы разложили code of the fatal не дай бог на продакшен ту мы хотели бы увидеть сразу падение графика не через день поэтому разумеется вся эта штука с кого то время начала деградировать но в принципе мы вкусили уже эту тему с я вам миром и так дали потому что упаду как бы это php агностик компании они java для нас java было в новинку нам понравилось мы поняли что можно чего-то как-то по-другому сделать мы заменили hadoop в чистом виде и hive как исполнитель аналитически запросов на приблуду под названием spark дико у порывались и и ещё три года назад рассказывал про то как мы это сделали и тогда нам казалось что эта штука будет жить вечно никто никогда не умрёт но жизнь распорядилась по-другому и мы стали упираться в некие ограничения в принципе ходу по в нашем случае то есть возможно если бы у нас были некие другие условия то мы бы продолжали жить так с ходу гумно cooper есть то что помимо вычислений графиков на ходу пи аналитики гоняют свои неимоверные четырехэтажные сколь запросы графике у нас обновляются не быстро мы уперлись в то что там довольно такая хитрая работа с тем чтобы оперативно процессе данным то есть быстро real time ago круто чисто наша тема о том что у нас есть обслуживаться двумя ты-то центрами эти 20 центр расположены по двум странам классического океана то есть в европе и в северной америке и для того чтобы построить единой какие тори портягино до данные из америки прислать его ровно та же в европе назад центр польши там больше вычислительных мощностей весь отчет статически ведется там к слову round trip между дата центрами порядка 200 миллисекунд что говорит о том что сети она такая довольно нежная то есть это не то же самое что ходить сходить в соседнюю стойку и опять же когда мы начали делать эту классную формализацию ивентов и разработчики продукты втянулись всем это все понравилось у нас значит просто взрывной рост ивентов и мы понимали что надо покупать железо вкус plaster мы этого не особо хотим делать вот мы прошли этот пик 800 событий в секунду мы узнали что я назову посольство такой офигенный продукт как плит house мы решили попробовать мы набили вагон шишек на нем пока что-то пытались сделать и в результате когда все завелось мы начали пить шампанское примерно вот так это наш первый миллион то есть мы небольшой фуршете как по поводу 1 миллиона устроили ну наверное на этом можно было бы и заканчивать доклад просто возьмите клей house и живите с ним но это не столь интересно напоминаем и все-таки разговариваем по прежнему по processing данных рисом и вдруг приключились контекста хаус я думаю не стоит рассказывать это hyip последние два года на как hail audi в этом году тоже порядка пяти докладов семинары вебинары и прочее то есть суть в том что эту инструмент предназначен для решения таких задачах которые вы перед собой поставили там есть real-time апдейты там есть те фишки которые мы получили свое время от ходу по такие как репликация данных шаг и так далее и не было повода не попробуй инструмент потому что мы понимали что с реализацией на ходу пи мы уже пробили дно до инструмент классный документации ваще огонь я сам туда писал прям очень нравится все здорово но нам надо решить ряд вопросов а именно как же мы все-таки наши весь поток событий переложим в клик house как бы мир жить данные из двух дата-центров потому что от того что мы пришли к админам сказать ребята войти с этапе намокли house они сказали о давайте ребята смотрели ходу по крюкову смутили вам все эти два раза толще сделаем и элитность это раза меньше нет сети нас по-прежнему такая же тоненькая маленькая как первая зарплата и нам надо как-то понять вот у нас был на ходу пи что там и как это понимали как и зато рисовать графики как москве house этого волшебного будем рисовать графики это говорит лектор в институте просмотрим три схемы данных стратегическую физическую и логическую про что речь на 2 до центра чё делать мы узнали что при house умеет в общем-то ничего не знать про дата центры и мы просто сетапе левада-центр кластер в другом они данные не переезжают через кулак автоматический кабель то есть все данные которые произошли то центре хранятся локально в своем кластере а когда нам надо произвести запрос над объединенными данными то есть мы хотим узнать как у нас регистрации случилось и в этом и в этом дата-центре николс нам дает так возможность это просто это это шаровар это отлично физической схема хранения как наши данные лягут в реляционную модель клика уса что нам надо сделать чтобы не потерять репликацию sharding и прочее прочее но на самом деле в документ проблевался это довольно обширно написано то есть просто если у вас больше чем один сервер вы разумеется наткнетесь на эту статью поэтому мы не будем сильно углубляться потому что все есть репликация sharding и запросы ко всем этим данным пожар дам все это есть и это есть мануале логическая схема это самое интересное мы говорим о том что мы в одном pipeline обрабатываем гетерогенные вены что это означает что у нас есть регистрации у нас есть голоса у нас есть заливки фотографий у нас есть технические метрики у нас есть tracking поведение пользователей все эти события обладают совершенно разными атрибутами т.е. посмотрел у какой-то экран на мобилки мне нужен айтишник экрана я за кого-то проголосовал не надо понимать голос был въезд но у и так далее все эти события продают разными атрибутами их совершенно разные графики по ним рисуются но все это обрабатывать один пай плане как это за суд модель crack house первый подход который мы экстраполировали с того кто у нас был с mais quel им этом мы создавали под каждый и веток ли хаусе табличку звучит довольно логично ивента таблица пока все пока норм но мы тут натолкнулись на ряд сложностей в частности у события нас нет ограничений на то что событие у нас изменит свою структуру когда вы несёшь дибил я тут можно сделать любой разработчик под чьим то есть у нас схема вообще во все стороны ну табельное так далее то есть нас эрик wild поля единственное то типа timestream событие ну и что за событие было все остальное не меняется на лету и соответственно эти таблички на сбыт альтере чтобы туда засунуть включаемся даже есть возможность выполнять альтерна кластере но по факту эта процедура довольно нежная и ее довольно сложно автоматизировать чтобы оно работало безотказно поэтому это минус дальше этот паттерн когда мы говорили о том что у нас более 1000 различных клиентов дает нам высокий интер трейд одну машину то есть нам надо все данные поставить постоянно запихивать в тысячу таблиц и это дать это по факту это анти паттернами house of нужно любит как девиз колы или пепси и жили большими глотками при house девиз свой большим патчами если этого не делать то у нас захлебываются репликация у нас оказался отказывается принимать новые вставки и в общем это довольно поганая схема сибирские мужики попробовали подсунуть бензопиле рельсу и применить другую модель данных мы делаем огромную таблицу с тысячи колонн и где у каждого event-а зарезервировано какие-то колонки под его данные у нас получается glu огромная-огромная таблицы и к счастью это не вышло дальше разработчики среды потому что она уже с первых снова показалось что она абсолютно поганое и мы конечно же так делать не будем но все таки хочется такой классный инструмент но блин вот вот ну чуть чуть чуть чуть еще вот чуть-чуть чё ты допилить и будет она до 3 подход это у нас есть одна огромная таблица в которой мы храним данные в массивах потому что crack house поддерживает не скалярные типы данных то есть мы заводим колонку который у нас был хранится название атрибутов и у нас будут отдельно колонка с массивом в котором хранятся значения атрибутов классно на вставку рвет вусмерть то есть house здесь здесь свою задачу выполняет более чем то есть есть мы если нам нужно только вставлять мы бы наверное еще раз в десять на текущие столицы и выжили однако ложка дегтя в том что это тоже антипатр для treehouse а не надо хранить массивы строк это плохо то что не хуже жмутся чем простые колонки они сложнее в обработке но для нашей задачи мы этим всем поступаемся и нам от это довольно хорошо как мы будем select из такой таблицы значит у нас задача посчитать регистрации сгруппированы по полу нам надо сначала в одном массиве найти какое какая позиция соответствует колонки gender потом в другую колонку залезть с этим индексом его достать данные чем дальше мы ведет какую рисовать графики с этих данных поскольку нас ивенты все которых сказал описанную них есть другой структуру и так далее мы каждому типу события формируем такой четырехэтажная сколь запрос выполняем его и результат сохрани в какую другую табличку это работало прям классно всем его до шампанское успели попить когда миллион взяли но до определенного момента исключительно из-за дизайна таблице какие у нас здесь есть проблема проблема в том что для того чтобы рисовать эти точки на графике нам надо отсканировать всю таблицу то есть например мы смотрим регистрации за сутки до это событие вот вверх и самой строке до предпоследней отлично просканировали один раз потом через 5 лет мы хотим рисовать новую точку на графике мы опять сканируем диапазон данных который пересекается и так делается для каждого event-а и так далее и вылет как будто это не очень здорово ну же звучит логично но не здорово и плюс ко всему когда мы берем какие строки нам надо еще считать под агрегации то есть у нас есть факт о том что раб божий зарегистрировался в скандинавии был мужчиной и нам надо с водой статистику посчитать сколько у нас всего было регистрации сколько мужчин сколько людей из норвегии это называется в термах туристических баз данных о лапы юпс игру пинцет то есть нам надо одну строчку превратить в более чем одну частью какого существует инструмент для решения этой проблемы а именно мы можем использовать реализованы состоянии агрегатных функций что это означает это означает что мы можем какой-то кусочек данных просканировать один раз только и сохранить эти результаты и это прям киллер фичей и очень круто что когда мы 3 год назад сделали точно такой же нас на спарке и ходу пи что как бы параллельно с нами лучшим и яндекс и делали откликалась такую фичу вот нас есть медный запрос посчитать уникальных юзеров за сегодня и вчера так выражается в физическом плане мы можем высветить состояние за вчерашний день получите бинарное представление кудато сохраните для сегодняшнего дня у нас просто меняется условии что это будет туда и ну и таймс назовем xxx их y и y потом мы из таблицы с этими бинарными данными селекции и получаем в итоге циферку о том сколько у вас было людей вчера и сегодня за два дня извините то есть тактика такого мы quantum время на какие-то минуты мы над данными за минуту выполняем этот запрос получаем результаты агрегатных функций в сервированном виде и потом их мерным соответственно за сутки мы не сканируем все винты за сутки одержим там какое-то количество часовых и минутных промежуточных результатов эта техника позволила нам снизить время обработки в разы точных цифр не скажу но оно помогло нам выжить потому что когда мы сказали что ребята мы теперь классно treehouse все считаем люди сказали вот фильма можно еще и винтиков налить ну давайте сейчас посмотрим на вас как будем хранить эти результаты опять же как мы помним если у вас будет 1000 таблиц это не очень хорошо поэтому результаты агрегации тоже над сливать в одну таблицу мы в ней будем хранить имена агрегатных функций и значениях то есть тоже опять два массива преимуществом этой таблице помимо всего прочего является то что принципе к ней можно написать sql запрос который позволит аналитиком над этими результатами поколдовать поезда классно они могут любые запросы выполнить над исходными данными нового с результат агрегации тоже это очень полезная информация но и мы не забываем о том что нам как-то нарисовать time series как мы это реализуем реализуем это посредством функционалу материализованный представлений то есть что это означает как только мы вставляем в нашу таблицу у нас срабатывает тригер который в другую таблицу предназначены чисто для time series делаю вставку табличка ли там series тупорылое до невозможности потому что time series только так и делаются колонка с датой колонка с именем метрики колонка с точным time с темпом и колонка со значением собственно какая точка на графике будет сделано то есть когда мы вставляем результат выполнения агрегации над каким-то конкретным моментом на срабатывает тригер который выглядит следующим образом нам надо получить имя метрики этой табличке которые показывал с массивами взять от него hash это очень важный момент очень важный момент о том что в отличие от большинства баз данных мы не храним здесь текст и представление метрики мы берем от него hash hash это круто х занимает меньше места да у него возможные коллизии но в 3-х россии существуют хэш функция дает очень крутое распределение и мы их радостно используя ты не влезай в математику какая-то вероятность коллизий на поставившему работает и работает круто когда нам надо получить данные опять же мы на клиенте не знаем реально значение этого хэша мы тоже вадима на откуп ли хаусу то есть мы говорим вот тебе как с точки зрения нас кажется эта метрика выглядит а есть регистрация мужчин от и пожалуйста там поколдуй и сделал из него фишек эта штука дает нам выборку time series за две недели с точки за две недели для порядка 20 метрик за 20-80 миллисекунд это очень крутой результат и такая схема хранения на прихоти функционал графин мираж-3 который позволяет нам хранить time series на этот подход он еще круче он еще более производительный какие у нас параметры системы процессинга у нас есть 8 серверов из которых 6 вот это центре в европе 2 в америке то есть нас реплик личный фактор 2 нас в одном что в дед два сервера нам этого достаточно в пекине процессе мадина 8 миллионов событий в секунду и выходная мощность системы до 500000 оставлять облетает 18 миллионов ему drammasi его усиливать и выдавать 500 тысяч метров в секунду и всего наша система знает про порядка 1 миллиард метрик какие у нас были последствия переходы с ходу по исключительно позитивные у нас суетности снизилась в два раза то есть мы стали точки на графиках рисовать в два раза чаще мы сэкономили три раза по памяти 4 раза по циpкa по-моему это очень внушительный результат и прям кипятком плакали когда все и случилось итоге наши фазы а процесс то есть обработки данных мы научились поэтапно выбирать технологии под нашу задачу это не значит что вы выйти с доклада и тут же прибежите к себе начнете писать 3000 событий в секунду возьмите cliff house да возможно но возможно это будет а вертелом под вас мы научились выбирать узнали как мы проходили этот путь мы выбрали cliff house и пока что пока что мы нащупали его пределов то есть я уверен что наша модель который мы сейчас используем позволит нам скейлится и дальше ну то есть по по моим оценкам эти 8 серверов позволит нам пережить пик в порядка 3-4 миллиона событий без таким не железа ну дальше понятно железо можно решать проблемы презент что мы будем делать со всем этим добром да с этими данными произойдет дальше кто с ним будет работать и так далее ну разумеется мы говорили про time series мы нарисуем time series у нас будет даже бортики где разные люди из компании будут что-то смотреть описать другого вопросы а почему здесь так почему здесь так у нас будет штуку под названием / detection суть в том что нехитрым искали запросом к таблицы с результатами которые мы посчитали по ивентом мы можем выявить самые интересные и самые необычные поведения метрика это пока никакой нету муриды так что это просто сравнение нескольких точек на график то есть у вас есть инструмент который нам рассказывает о том что вот голоса за профили просели там на 2 процентов в таком разрезе а в таком процессе разрезе выросли на 40 и среди всех метрик которые там случились по этому ивенту их может быть там десятки сотни тысяч это наиболее значимые измерения изменения это все прикольно да мониторинг можно построить можно задать тот школы и так далее но хочется чего-то большего лучшего теплого и поэтому приходит anna malle detection она multi action это система которая берет эти time series данные у нас есть как мы уже говорю о том что они русские эротические то есть из регистрация регистрации здесь регистрации мужчин в скандинавии так далее для каждой из метрик то есть докажет там через точки мы на каждом series графика мы учитываем предсказания и трешхолд и в случае если актуально поведение метрики выходит завтра школ тьмой производим а лифтинг то есть мы еще рану ранжируем тоже примерно как делает дробный так что то есть наиболее интересные аномалии наиболее значимые то мы производим а лифтинг мы примерно вот так выглядит наш ей тоже опять же их аномалия отсортированы по весу вот есть какой-то outline который вылез за ширину доверительно интервала серика области и это очень круто этим пользуются и продукты и разработчики то есть от системы которые тоже компании white то есть это не что-то которые придумали чужие для хищников эти пользуются все в итоге чему научились фазе презент на основании охренительных технологий которые применили в прошлом шаге у нас появилась возможность рисовать графики у нас появилась возможность отдела мониторинга настроить allure цинк на основании жестких правил которые задают разработчики то есть если это метрика падает ниже 1000 алярм если этот метрика отличный от нуля алярм все это есть это позволяет сторож мы прикрутили наша думали дтп и кстати да еще одна штука которую забыл упомянуть у нас раньше он умер detection у него отдельные к этому своей структуру данных таблички с колоночка медали раньше она у нас жила в аналитик системах засов теперь его данные также хранятся в клика усе то есть мы еще и побочную задачу решили и этот переход позволил нам также ускорить процесс она вальдо точно в два раза то есть просто сменив базу и наконец заключительной фазы марлезонского балета мы с вами узнали зачем нужно собирать статистику в проекте мы рассмотрели техники сбора которым можем применить для этого и мы рассмотрели как поэтапно изменять свой стек технологий как мы его прошли вы узнали какие инструменты можно построить на базе этих данных то есть что даже с этим данными делать пожалуй все спасибо большое за ваше внимание к готов ответить на ваши вопросы и у тебя прямо полчаса на вопросы и ответы ну друзья как это говорят ружья не уходите давайте поговорим ручки в небо это все кому пописать в частном наверху впервые сегодня галёрка задает вопрос здравствуйте спасибо за доклад скажите пожалуйста вы съели ли клик house или вы изначально вот запустили эту конфигурацию которую вас сейчас выстрелили из я скажу с 4 до 8 ног мыске weleda тогда насущный вопрос в интернете пока еще мало рассказывает об успешных скиллах как вы ришар делись мы решались так что у нас логика вставки в cliff house она нам подконтрольно у нас прописаны жестко пока что хасты который нам доступно то есть нет никого автоматической регистрации сервис discovery и прочего и мы просто добавляли весу шар ду что вот шар над больше данных лиц и когда данное равномерно столика когда спустя какое-то время просто выровняли вес хорошо спасибо и второй вопрос у вас на слайде с шампанским было пять бутылок и всего один бокал это пять бутылок и всего один график бокала один сегодня всего один бокал атака это самый мама это же только для фото ну то есть понятно что там одним шопа ласки дело не ограничилось одним бокалом спасибо прямо из горла клик хаоса будь добр и здравствуйте вопрос такой как вы структурируете события для того чтобы дальше их использовать как мы структурируем как я показывал пример что у нас описание забыть страницы в прато баффи и здесь как две ветви у нас есть одна ветвь это разработчики прямо в коде в репозитории описывать про the file is генерится а фишка и так далее другой путь это наша система трекинга пользовательских событий там есть отдельный отдел аналитиков потому что информация очень нежная и она доносится до клиентов то есть надо прийти к соглашению между всеми мобильными платформами то есть у нас их 4 о том как отправлять данные какой контекст доступен и так далее вот и поэтому там увлекаются специальные аналитики в них уай в котором они записывают события то есть изначально команда какая-то анализируя так как события будут структурированный того как как я уже говорила жало когда приходит от продуктового отдела требования на разработку на ухичу там обязательным пунктом является tracking и вот ну поскольку фичи как правило affected через его и вызывать ест и польза детали то там понятно что когда пользу я посмотрел такой экран должно отправиться события с таким-то контекстом и вот этот контекст который должен должна будет за и приметить мобильные разработчики отписывать отдельной команду до 8 тиков вот еще выше смотрите здравствуйте а хотел задать такой вопрос каким образом у вас реализован на чтение данных из лсд сборка батчат для crack house и это прям это прям отличный вопрос значит лсд кванту it весь поток данных на файлике то есть в конечном итоге у нас в дикой территории получается файлик там 1 2 3 и так далее какого-либо фиксированного размера либо алиала грата это то есть вот у нас есть приложу к наживе которая читает эти файлики и по протоколу любой мере записывает данные в клик house откликаюсь и у нас в табличке с фактами то есть советами для каждого event-а хранится имя файла откуда он был прочтен и раньше мы хранили прям позицию из файла то есть строчка номер такая-то каждую лента соответственно у нас treehouse гарантирует нам атомарной вставки вплоть до какой-то ну тогда привет миллион ивентов файлики нас был может быть больше чем миллиона видов поэтому мы вставляем по зерну в event и вставляем еще позицию последний вставленную мы поняли что это довольно поганый подход и на самом деле нам не нужно для каждого вето слать и мы знаем что cly house на пряном гарантирует ставку вплоть до миллиона поэтому мы для всех ивентов пишем пуганули а для одного единственного суррогатного ивента пишем позицию из файла который мы прочитали таким образом мы там снизили типа на порядка 15 процентов хранения то есть event файл из которого был вставлен и позиция файле она то есть этого словно какая-то софтина разработанная ваша компания который работает на севере лсд читает приложу х для inserto да это чисто своя голосам деле если бы я делал это на кафки то я бы сделал абсолютно точно так же я бы писал туда в свет из коробки и ну партицию например ну то есть здесь она не сильно лсд band спасибо спасибо здравствуйте вопрос по поводу хранения истории какой объем вы храните где вы его храните и ну там то есть катера байтах в миллиардах но вот диск его емкость cliff house а у нас исчисляется терабайтами то есть в день нам помогала бы соврать вам около терабайта сырых данных приезжает и она не раскладывать вот в таблицу с результатами в time series так далее нового для time series например мы храним две недели а вот этих вот сырых данных а дальше у нас эти данные уезжают в некий свои самопальные демпси ресторан шинок ли хаусе где выполняются свертки уже то есть когда мы сворачиваем данный меньше количества . это происходит несколько усекли хаусе это вот для оперативного репорты чтобы графики быстро отдавались из когда мы значимых отдавались локтём time series тораджа когда переделан окне house у нас теперь не стали нас опять быстрее загружаться с нашей новой схемы мы храним тоже обычно люди продукты заходят дашборде какой-то чем я там за два дня за три дня за неделю а когда за пашешь за год ну можно подождать лишнюю секунду слазить в долговременны сторож понял спасибо большое спасибо за доклад добрый день вопрос секундочку спасибо за доклад вопрос такой вы упомянули что ко всей этой кухне прикручен еще allure thing это что-то самописная какой-то open source и алена тесно то не планируете ли вы посмотрите на самом деле а лифтинг до безобразия простой у нас есть табличка в которой лежат результаты агрегации разработчик приходит в отдел мониторинга говорит я хочу чтобы просмотры профиля и внезапном топ 10 стран не падали больше чем на 10 процентов там за последние там за три за 30 минут в общем всего из этого рождается sql запрос который отдел мониторинга регулярно посылает cliff house и получает куда циферку ну то есть тут тут нету как раз магии вас прикол в том что используя такой инструмент как лихо вас нам позволяет закрывать и потребности мониторинга к этим штукам тоже есть пример раньше подобной задачи нас решались когда он ещё был жив забыл вашим к к к к к к я то просто штука которая принимала на вход time series и говорила у вас тут отклонения и так далее но она ничего не знала про бизнес вылью этого события на то есть ну метрика ну пошла вверх вниз от чего с ней не ешь меня на тут sql и разметка этих данных позволяет нам всю информацию их вытягивать select из таблички с результатами сейчас я найду нас вот-вот нас есть табличка с результаты когда у нас есть die menschen эта есть возраст и пол например у нас есть значение mail 20 лет у нас есть метрику что таких событий на случилось там сто пятьсот отдел который говорит мы хотим чтобы высветить отсюда данные у которых предыдущая точка была там не сто пятьсот а качество ради грядущий точку с текущей то есть но это делается банальном маску и запросам и это происходит быстро ну что кликал сам себе быстрый и классный вторая попытка говорят что у клик house есть некий проблемы с производители что joiner я правильно понимаю что ваши метрики jointly 1 отличный вопрос да мы проектируем ивенты таким образом что у нас отсутствует необходимость соединения данных то есть нас каждый ссы в контент и и весь его контекст достаточно для того чтобы производить агрегации найдем то есть вас нет необходимости joy within the между собой когда мы это делаем мы это делаем в аналитическом хранилище но в различных хранилищ помимо потока ивентов у нас там на кучу другого контекста хранится оля полный профиль полной информация профили пользователей из всяких других совершенно разных систем или а пилинг и прочее то есть соединение освободиться в экзо соли до этической год я вы ответили на второй вопрос аналитической хронических засол лет до этого в лесу и третий вопрос если позволите я правильно понял что вы в принципе игнорируете возможной потери событий для вас это некритично у нас зрение со быть да у нас разумеется про это есть кросс чеки то есть у нас есть источники данных которые нам носить источник на который нам постоянно посылает разбиты значит и у нас есть некоторые другие системы через которые мы производим ну то есть event улетает в систем процессе konakli хаусе иветт улетает в систему процессинга mais quel и которую я описывал ранее то есть мы никуда не выкинули все у вас есть некий футзал которых обрабатывается через mais quel и и у нас есть информация о том что в принципе вот отправка отработал скрипт который отправляет их орбиты мы сравним между собой эти три показателя и в общем то большую часть времени она в линию то есть мы но мы не видим мы не детектив потери на свитере независимым источником их сравнивать между собой и да если позволить последний самый вопрос аналитическое хранилище treehouse вы в аналитическое хранилище льете отдельным потоком и ливийских house неким почем туда заливать а вот здесь немножко бэкстэйдж осталось следующая штука как мы говорили что у нас вы ведь есть некий паевого то есть пойму нагрузка по которой мы рисуем графики uniq user айди перцентиле какие-то и так далее вот но помимо этого у event еще есть куча другой требухи которые не всегда нужно ну то есть например мы оперируем когда мы говорим о том что у нас event содержит юзерам и не каждый раз говорим она юзера это юзера иди юзеры the country и так далее нас есть описание что у нас есть структуру user и каждый раз когда разработчик отправляет event содержащий узор там автоматически заклеивается возраст страна еще что то еще что то есть но этот это эти данные не нужны прям как может нарисовать график но они нужны потом был двери парсинга это отдельный стрим данных который едет не в клик housewife hadoop и из ходу по у нас есть возможность импорта этих ивентов в аналитическое хранилища все все во все устроено клик house в ходу по туда-сюда везде в общем данные умеет гоняться между экзо соломкой хаусом и ходу кликнул сосуда до хотел уточнить про агрегат про кого мизинец агрегированные то олехаус а они как они используются только для для графиков и аналитики и можно ли их и пересчитывать до пересчитать можно мы нас есть возможно ли бы можем удалять партицию какую-то либо мы можем заюзать дома моды функционала alt и был дэвид который появился в хаосе не столь давно то есть можно пересчитать эти данные да в самом приложении они как-то используются или этот вот только графики и какая-то аналитик но смотрите у нас есть графики до купил свой time series внутри cry хауса и у нас есть 1 моль этот экшн на этих данных экономика раньше нужны размеченные метрики о том что метрика это состоит на самом деле из голосов мужчин и женщин и и мы мы мы мы их ранжировать дальнейшем то есть мы смотрим вес метрики относительно всего объема то есть нас иерархический там series ну вот так используется да ну или мониторинг как я говорил что мы селекции данные по какому-то критерию есть нагнулся и найди my time series с такими-то метками то есть это не какое-то вечную хранилищ есть если говорить о раума если говорить о том что лазер для туда прямо на ли отдел аналитиков нет потому что как и сказал у них у них отдельный сторож который может излечить эти данные типы данных которые доступны в момент отправки события ну то есть когда ли когда-либо платил пользователь или нет применялись климатом и закинуть санкций антиспама какая у него история биллинга и так далее из контекста приложения информация доступна поэтому она хорошо будет слов сложные research будут хорошо работать только в аналитическом хранилище самый момент сейчас поклониться в принципе уже можно друзья спасибо что пришли на глаз отлично спасибо большое скажи кому мы книжку подарим за вопрос молочай когда спрашивал про вставку где он потом молча когда спросу как вставлять вот книжка уже побежал наверх вот эти памятные призы тебе спасибо спасибо большое но и отличный штаны"
}