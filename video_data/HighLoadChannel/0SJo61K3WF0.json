{
  "video_id": "0SJo61K3WF0",
  "channel": "HighLoadChannel",
  "title": "Кластер Elasticsearch на 200 Тб+ / Петр Зайцев (Одноклассники)",
  "views": 11207,
  "duration": 3010,
  "published": "2020-04-14T11:30:14-07:00",
  "text": "давайте знакомиться я другой зайцев пётр сильно чуть менее известный и занимаюсь сильно другими вещами я на текущий момент работаю системным администратором в одноклассниках а до этого я тоже был админом работал сфинкс мантикор сердце ластик search возможность появиться какой нибудь еще один search буду работать с ним вот и также принимая участие в ряде в конкурсных проектов на добровольной основе собственно когда я пришёл в одноклассники я сдуру сказала собеседование что я умею лстк search соответственно после того как я там освоился поделка реки это простенькие тоски ко мне пришли подарили мне большую задачу по реформированию системы менеджмента который там на данный момент было требование к этой системе были сформулированы следующим образом во первых это в качестве фронтэнда для всего этого хозяйства должность пользоваться грейлок почему ну во первых потому что в компании уже был опыт использования этого продукта программисты и тестировщики которые этим пользовались этот парк и продукт знали он им был довольно таки удобен и было принято решение что мы будем использовать его по поводу объема данных которые необходимо было пропихивать вы всю эту систему можно было сказать следующее что это среднем там 50 ом 60 иногда 80 тысяч сообщений в секунду но когда cry где-то что-то ломается у нас трафик получается совершенно не ограничит то есть это там 2 миллиона строк в секунду 3 миллиона строк в секунду то есть любая вещь достаточно большая величина в принципе для этого подошла бы этот трафик и также вот проспавшего программистов о том собственно говоря с какой скоростью они бы хотели что вы отвечал подобный сервис на их поисковые запросы пришли к тому что в среднем potter использование подобной системы это то что обычно люди ищут за последние два дня логе своего приложения и не хотят ждать больше секунды для того чтобы получить какой-то результат на сформулированный запрос а от админов была очень большая большая просьба что они не хотели и не хотят очень глубоко вникать в то как это все устроено они хотят чтобы она легко просто масштабировались при необходимости и чтобы единственной штуковина которой с этими системами приходилось периодически делать это меня где-то как как какое-то железо как такой вот и испарение масла которое периодически происходит и в общем то все и кроме того в одноклассниках есть одна прекрасная техническая традиция что любой сервис который мы запускаем он должен переживать отказ нато центра потом внезапный не незапланированный и вы абсолютно любое время это практика далась вот в реализации конкретно этого проекта наиболее большой кровью о чем я подробнее расскажу чуть чуть больше и так собственно говоря запускаемся мы на 4 этот дата центрах при том что дата но до нас могут из полагаться только в трех ну там по ряду бизнес и экономических причин этих четырех дата-центрах у нас находится гретна я 18 тысяч различных инстансов в том числе всякие железки контейнеры виртуальной машины в общем все все все вот это вот вот и все это хозяйство пишет вот эти самые логе которые мы хотим агрегировать и как-то использовать а и ещё одна важная особенность прежде чем делать начну рассказывать как мы все это строили это то что мы это дело запускали не на физических машинах мы это запускали она собственно об облачной продукте который родился в эпоху док оберните со называется one клауд и фактически получается что у нас эластик search запускается в контейнерах бутоны докер вот ну и все это хозяйство разумеется дописана практически полностью поджарен общем продюсеры все эти требования понял что мы будем строить примерно вот это общий вид решение мне изначально виделся следующим образом что у нас есть определенный data flow который у нас льётся через com балансиры попадает на батарею игры логов который преобразовывает различный формат это персия слова где тагил это там еще что-нибудь после чего это хозяйство у нас влетает в следующую батареи elastic чёрч координаторов которые соответственно дальше уже fargo лет этот запрос в релевантный data model вообщем и была не то чтобы особенно сложный и для того возможно это знает поэтому ты хотел остановиться чуть чуть на терминологии что в ластики есть определенное количество типов ноту в частности это мастер и координаторы и дата ну то есть есть ещё два других они используются там для разных преобразований логов там связи разных кластер между собой но мы их не использовали поэтому я остановлюсь только на вот этих собственно говоря мастер занимается тем что он пингует всеприсутствующим кластере ноты и рассказывают собственно говоря координатором о том куда им фар вардить запросы на запись в релевантный индексы и жары и кроме того там есть еще такая штуковина которая занимается какими-то задачами по русски pingu в кластере как например processing кластерной карты и вот вот это вот все соответственно координатор он выполняет одну-единственную задачу принимает запрос от некого клиента на поиск вина чтением записи на и чтение в случае если это записи то он скорее всего спросят мастера о том собственно в какой шар релевантного индекса это христа положить и соответственно перенаправит запрос дальше да то надо но она очень простая она хранит данные выполняет поисковые запросы которые в нее откуда-то прилетают его соответственно выдает информацию тому кто ее о чем-то спросил брелок может не все знает что это это некие из плавки ibanez logs то что он там под капотом работает кафка там под капотом работает и перрон мест из-за этого кэшировать логе в случае какой-то недоступности elastico ii умеет орет уровень запросы на чтение и запись и кроме того там ее стройные и сервис discovery который позволяет на основе 1 до доступный пластика соответственно вытащить всю карту кластера отфильтровать и и по определенному тегу для того чтобы направить соответственно наши поисковые запросы запроса на индексацию на те машины который мы изначально хотели чтобы вот именно они занимались и теми или иными задачи собственно говоря на визуально это выглядит примерно вот так вот это вот скриншот с конкретного инстанса здесь не по поисковому слову выстраивают гистограмм q там какие-то травмы выводим релевантные строки и собственно говоря вот так вот он выглядит как рабочая поверхность собственно возвращаемся к топологии и того как это все было построено я бы хотела сейчас более детально остановиться на то как мы строили модель индексов для того чтобы все это работало правильно то есть вот это вот картинки это самый нижний уровень как все очень дата но да собственно индекс пластик search а в общем виде выглядит следующим образом есть вот большая виртуальной сущность в который которая состоит из вас так church сортов которые сами по себе являются ни чем иным как лице низкими индексами эти лица минске индексы состоят из сегментов 1 и более когда мы это проектировали мы прикидывали что для того чтобы обеспечить требование по скорости чтения на большом объёме данных нам необходимо раз быть предельно размазать эти данные по данным дата но да это вылилось в то что количество сортов у нас на яндекс с репликами должно быть строго равно количеству дата но для того чтобы во первых обеспечить рипли кришну фактор да во что мы можем потерять половину кластер а во-вторых для того чтобы запросы на почтение процессить как минимум на половине кластера время хранения об одесском мы определили как 30 дней возможно мы в дальнейшем это изменим в большую сторону и соответственно получается что вот у нас эта информация размазано по трем дат дата-центром где то получается там 120 not of каждым и получается что там любой поисковый запрос вазов отрабатывает грубо говоря в полутора до то в центрах говорят распределение шортов это графический выглядит следующим образом тонна стал большим квадратиком представлен индекс в нем есть еще два разных call от квадратиках левый красный это соответственно праймер шаг 1 яндексе 2 квадратика голубенький эту нас реплика short они находятся в разных так и дата-центра когда мы добавляем еще нас тут должен был быть желтый черт возьми этот шорт она соответственно должен садиться в 3 дата центр и в конце концов мы получаем вот такой вот структуру что грубо говоря каждый каждый реплика shard относительно праймари шарда должен располагаться в каком-то другом месте собственно говоря как уже до этого я говорил у нас любой поисковый запрос отрабатывается полина кластеров ротация индексов мы сделали равны 48 часов по паторну использование этого самого яндекса потому что именно по 48 часам чаще всего ищет и собственно мы это еще сделали по той причине что когда у нас в какую-то конкретную дата ну да прилетает запрос то пластик черт спавнит априорное количество тредов для того чтобы его выполнить вспомнит он их на 1 шард и по количество доступных hyperthreading овых core который мы прописали в конфиге эластик таким образом получается что если мы будем складывать гарантировать не индекс чаще то у вас получится что один поисковый запрос по тому же временному интервала будет генерировать вдвое больше крест отрядов из-за чего он поезд будет подтормаживать потому что процессор не то чтобы сильно это резиновый и это все будет работать значительно дольше для того чтобы получить заявленные скорости по поиску мы стали строиться не на хдд ssd и машины на которых стали размещать эти контейнеры должны были обладать их хотя бы 5 6 кадрами для того чтобы просить запросы достаточно быстро вот в итоге у нас получилось что в среднем шарф у нас равен где-то по весу 20 гигабайтам и на один индекс у нас приходится 360 шар долл соответственно если мы гарантируем 1 48 часов у нас их 15 штук вот при этом давайте разберемся в том как записываются данные в все это большущая хозяйству допустим у нас из горелова прилетает в координатор какой-то запрос допустим вы там хотим по индексировать скажем две-три тысячи строк это хозяйство предстоит координатор когда-то спрашивает собственно говоря вот в запросе на индексацию нас бог конкретно указано индекс но которые шар это описать это там не указано соответственно мастер отвечая что допустим запиши вот эту вот информацию в шар номер 7 ст1 а после чего данное хозяйство направляя что уже в непосредственно релевантную дата ноуту где находится промилле шар номер 71 после чего под могут транзакции это синхронизируется на реплика short который уже находится в другом дата-центре вот почтение из всего этого хозяйства происходит став что у нас из того же игры логов координата прилетает поисковый запрос координатор forwarded его по индексу массы при том что ластик распределяет в данном случае запросы по round robin у между праймериз шар дом и реплика шар дом моды в количестве 180 штук отвечают не равномерно и пока идет этот самый от ответ координатор копит информацию о которой в него уже выплюнули даты но до и после этого отдает как запрос либо от тайма учился либо вся информация пришла уже непосредственно клиент вся вот эта вот штуковина по последним 48 часам нас в среднем отрабатывает именно на пояс там где-то миллисекунд за 300 за 400 скучая запросы которые начинается sliding wild card потому что в таком случае у нас идет очень большие выгрузка данных мы просто не успеваем грубо говоря уложиться в наше село собственно для того чтобы у нас это все вот так вот заработала мы очень-очень долго отлаживали различные вещи в этом кластере для того чтобы все работало в соответствии с тем как мы это изначально хотели первая часть проблем которые мы нашли это была проблема с тем как изначально путь по дефолту в классе все очень расстраивает уже настроено java а собственно говоря проблема первое мы откладывали очень большое количество ошибок о том что у нас на уровне + n когда у нас идут по горам джо бы меньше сегментов происходит неуспешным при том в блогах бы было видно что это он ошибка по типу мы смотрели что в принципе рама еще предостаточно не было понятно почему собственно говоря это операция падает выяснилось что оказывается мертв установках индексов они происходят не в и happy мнение о контейнеры были довольно жестко зажаты по употребляемым ресурсам и получается что в эти ресурсы или зал только hippo как какие-то таскать архип операции довольно большие уже не вылезали текст был довольно тривиальным увеличили рам в два раза доступна для контейнера после чего забыли о том что еще такие проблемы с были где-то спустя 45 после пуска кластера мы заметили что периодическое назад дата мода начинают вы из кластеров вываливается и заходить в него там буквально там секунд через 10-15-20 когда полезли разбираться выяснилось что вам а вот это самая of key память в elastic search и не контролируется практически никак то есть когда мы контейнер отдали вдвое больше памяти мы получили возможность наполнять подарок буфер пус различной информации и она очищалась только после того как запускался xposed джесси со стороны ластика при этом эта операция происходило довольно таки долго и за это время физически бывало так что кластер успевал помечать эту самую ну да как же выжег это проблема хорошо описано вот этот ссылки тот который я привел с графиками обоснованиями всем остальным fix был следующего видом и зарезали возможность использовать джаве большую часть памяти вне хе-хе попутать эти операции мы лимитирование и души 16 гигабайт с таким образом получили картину что экс месяц джесси у нас вызывался значительно чаще отрабатывала значительно быстрее если вы думаете что на этом у нас проблемы с тем что у нас вот вы самый непредвиденный момент покидали кластер кончились вышиваешь когда мы прописывали работу с индексами мы использовали попутный вес для того чтобы сократить время поиска по конкретным джордан это было довольно таки грубой ошибкой по причине того что когда мы используем map f с у нас файл напиться в оперативную память соответственно дальше мы работаем уже с метод файлом после чего получается что когда у нас скорбишь коллектор пытается остановить 3d в приложении мы очень долго идем до с of point ум и в по дороге к этому самому своих point у нас приложение уже перестает отвечать на запросы мастера о том что он уже мастер соответственно помещает что ну да у нас больше в костре не присутствует после этого там спустя там секунд пять десять у нас все-таки отрабатывает гарбич collect анода оживает смогла заходит в кластер начинает инициализация шар дав в общем все это было не очень хорошо для того чтобы избавиться от поведения подобного вида мы сперва перешли на стандартный милфс ну а после когда уже это сопят их версии elastico удерживались на 6 по пару были гибрид fs этом данные проблемы не встретили голод потом было еще очень занимательная проблема которую мы лечили рекорд надолго где там и там ловили около двух или трех месяцев по причине того что был абсолютно непонятен я потру и тогда у нас координаторы уходили в 6 где то в среднем вот так вот после обеда вот и оттуда уже не возвращались при этом при лакировании задержка кирпич коллектора это выглядит так что она сведет все хорошо хорошо хорошо хорошо хорошо а потом резко плохо сперва мы думали о том что у нас есть какой-то злой тестировщик или злой программист который запускает какой-то такой запрос который нам выбивает координатор из рабочего режима очень долго лагере были запросы пытались найти собственно говоря что там происходит в итоге выяснилось что в тот момент как когда какой-нибудь программист запускает большущий большущий запрос и он попадает на как какой-то конкретный координатор elastic search in the он и которые надо отвечает выше чем остальные и в то время пока коррелятор ждет ответа всех вот получается что он копит в себе информацию которая собственно говоря должна как которая составляет часть это ответа на этот самый поисковый запрос для коробочка лекторы это означает что у нас очень быстро меняется паттерн использование типа и 1 6 которым использовали с этим задачей не справлялся единственный fix которые мы нашли для того чтобы изменить поведение кластеров такой ситуации этом и от мигрировали на 13 же т.к. и начали использовать это закрыло вопросы карнотавр господа перестали собственно на этом проблемы которые были с java закончились и начались проблемы непосредственно пропускной способностью то есть мы пришли к тому что а сквозь работает стабильно но в некоторых местах по против романса еще не совсем так как нам бы хотелось симптом 1 которые мы встретили это то что нам так каких-то взрывах на продакшене когда у нас резко генерируется очень большое количество лагов в логия начинает большом количестве 5 ошибки индексации это происходило из-за того что он ред пузырьки в пластике он может на 1 доп аноде до момента как elastic сумеет обработать запрос на индексацию и закинуть информацию уже в шорт на диск он умеет кешировать только 200 запросов по дефолту и документация власти ксир чьи об этом параметре говорит что вы его лучше не трогать и потому что он там выверен быстро дан и больше об этом и говорит ничего разумеется мы пошли крутить это самое место и выяснили следующую штуковина что вот конкретно нашим сетапе довольно хорошо так кэшируется до 300 запросов и больше значения чревато тем что мы снова улетаем fuck гости у нас уже дата надо становится абсолютно неоперабельный кроме того поскольку это бочки сообщения которые прилетают в рамках одного запроса то надо было еще подкрутить крыло для того чтобы он писал не часто и мелкими boccia большущими патчами и как как можно реже в таком случае получается что у нас информация которая мы в ластик пишем становится доступной там не через две секунды а через пять что в общем-то для пользователя нашего является вполне себе адекватной ситуации но у нас уменьшается качество ретро яд которой приходится делать для того чтобы пропихнуть большую пачку информации это особенно так сказать важна в тех момента когда она что-то начинает по какой-то причине в другом месте разваливаться чтобы и получать все полностью заспавнены и и ластики и соответственно через какое-то время из-за забившись акаши неработоспособны игры логе кроме того в те моменты когда у нас происходили вот эти самые взрывы на продакшн и к которые генерируют и гигантское количество трафика в эластик search у нас приходили жалобы от программистов и тестировщиков чтобы именно в тот момент когда им очень нужно вот эти вот логе они выдаются им очень медленно стали разбираться с одной стороны было понятно что и поисковые запросы и запроса на индексацию они отрабатывают по сути на одних и тех же физических машинах и так иначе априорные посадки будут это можно было чуть-чуть обойти за счет того что в 6 холостяках появился алгоритм который позволяет распределять запросы между конкретными релевантными дата нодами не по случайному принципу по round robin в то время как машина которая занимается индексацией которая держит праймари шаг может быть очень занятая там просто не будет возможности ответить достаточно быстро направить этот запрос например на менее загруженный реплика short который ответит значительно быстрее то есть возвращаясь к вот это сами вот картинки получается что мы выключили вот этот алгоритм и включили адаптивную селекцию реплик что позволило изрядно улучшить кьюри time в те моменты когда у нас и большие данные запись и основная беда у нас было с тем чтобы вывести дата-центров собственно говоря чего мы ожидали когда у нас он начинает отваливаться мы ожидали что если у нас в отвалившийся дата центре находится текущей мастер что он будет перри выбран и переедет как король в другое место мы ожидали что мастер быстренько помечен пометят все потерянные но да и скажет что вот их вот большой нет мы работаем только с тем что осталось соответственно основании того что осталось он вычтем что ага вот тут потерявших взять дата центре у нас были такие то праймари шарды быстро за про могут реплика шарды в оставшихся местах и у нас продолжится индексация данных и получается что вот мы думали что результате этого у нас будет пить потихонечку плавно деградировать пропускная способность но в целом все будет работать хоть и медленно одно также как выяснилось хотели мы чего-то вот такого а получили что-то вот такое собственно как так получилось в момент выбора дата-центра у нас узким местом стал мастер почему так получилось дело в том что в мастере есть такая штуковина который называется то значит это процесс или даже наверно вернее класс который отвечает за то чтобы распространять в кластере определенной задачи определенные даты и там любой выход ноды любой промоушен шарда из реплики в прайме этом любая задача на создание где-то какого-то журнале что-нибудь вот вот такой вот вот она попадает сперва в этот-то сметчик где процессе c соответственно последовательно и в один трек когда у нас ложился какой-то дата-центр пусть даже тестовый получалось так что все дата ну да которые нас оставались в выживших дата-центрах они считали своим долгом сообщить мастеру о том что у нас потеряюсь какие-то такие то таки это шорты и какие-то такие the data но до при этом они всю эту информацию в текущей мастер-класс аллен пытались даже дождаться подтверждения о том что он эту информацию принял этого не дожидались потому что они говорили ему об этом все вместе после чего таскать разумеется поталь эти а 333 эту самую эту операцию а мастер в это время пытался от центра и какая же собственно говоря из прилетевших ему задача является наиболее приоритетной но и исполнение в терминальном виде получалось что таким образом дата ну да за спам него ли мастер до того что угодил в juice после этого у нас роли мастер и приезжала на как какую-то следующую ночь не происходило абсолютно тоже самое и в конце у нас кластер разваливался в принципе мы делали измерения и вот был версия 640 это было наконец fiction а нам хватало вывести одновременно всего лишь 10 data not exceed 360 для того чтобы просто положить кластер собственно говоря выглядело это примерно вот так вот пускай версии 640 где они наконец-то починили эту стремную могу дата но ты у нас перестали убивать мастеру но умнее он от этого не стал а именно как когда мы допустим вы выводим dom2 310 там любой отлично эта единица количество data not мастер получает какое-то первое сообщение которое говорит о том что у того плода а вышло и пытается рассказать об этом вышедший но только что с следом дать ноги б но и ноги цены д д н а текущий момент с этим можно бороться только тем способом чтобы установить таймаут на попытки кому-то о чем-то рассказать равна или где-то там 20 30 секундам и таким образом управлять скоростью вывода дата-центра из кластера в принципе это укладывается в те требования которые изначально были предъявлены к конечному продукту но само по себе это довольно такие стрёмные штуковина и выловишь сегодня занимаемся тем что вот до сих пор с этим явлением боремся вот как когда все уже от гремела и на тайм-ауте лезть в этом самом тасс бачили все запросы которые не могли быть запас вершины чисто физически у нас вот эти самые у нас а до чуть-чуть забегая назад забыл сказать что вот когда у нас выходит некая да то надо то у нас получается что инфа распространить информацию о том что вышло data not a а это значительно важнее чем рассказать всему кластеру что на этой дата ноги а находились вот такие-то таки это про мире шарды чтобы грубо говоря за промыть и какие-то реплика шарды в другом дата-центр это праймари чтобы в них можно было писать информацию ответственно получается вынужден ждать когда таскать у нас под тайм-ауте за все пинге до у выживших дата но только после этого босс кластер начинает рассказывать о том что вот там-то там-то и там-то на надо продолжить запись информации в конечном итоге операция вывода дата-центра у нас на сегодняшний день заменить нимает около пяти минут час пик и в общем-то для настолько большой неповоротливые махины это довольно таки хороший параметр как я считаю собственно говоря в итоге мы пришли к следующему этапе решению что у нас есть 360 data not с дисками на 700 мегабайт каждый это 60 координаторов для рутин га трафика по этим самым дат анодом и 40 master of которые у нас еще остались как некое наследие с времен версий до 640 потому что чтобы там пережить вывода то центра мы морально были готовы потерять несколько машин для того чтобы через какое-то время там получить операбельной оставшуюся часть вот и любые попытки с совмещения вот этих вот ролей на какой-то одной машине у нас тоже заканчивались крахом собственный бот да и ну и разумеется во всем этом костерин используется хип says равное 30 одному гигабайт а потому что все остальные контак попытки уменьшить этот размер приводили к тому что на тяжелых поисковых запросах у нас где-то что-то переполняло особенно на координатор и в общем весело падал вот и кроме того для того чтобы обеспечить перформанс по поискам мы старались держать количество объектов в кластере минимальным тупо для того чтобы как можно меньше событий обрабатывать в самом узком месте которые у нас получилось в мастере вот для того чтобы все это хозяйство у нас работала так как задумывалось мы мониторим следующий штуковины во-первых каждая дата надо либо репортят в наше облако о том что вот оно есть и что на ней находится такие-то такие-то шарды как как как когда мы где-то что-то тушим у нас кластер где-то через две три секунды понимает что грубо говоря вот в дата-центре а мы потушили ноду 2 3 и 4 это означает что в других до дата центрах мы ни в коем случае не можем тушить те надо на которых остались шарды в единственной копии вот кроме того мы и знаем характер и поведение мастера очень внимательно смотрим на количество подзадач потому что да даже одна завершит задачу если она вовремя не от прямо учатся она теоретически в какой-то там экстренной шутки не способна стать той причиной по которой у нас не отработают допустим промоушен реплика шагов в праймериз и чего встанет индексации мы очень и пристально смотрим на задержки и garbage collector а потому что у нас с этим были очень большие сложности в оптимизации и настройке но из стандартной метрики такие какие парам и его в общем что хочется сказать относительно всего этого в конце ну во первых у нас все получилось то есть грубо говоря мы сумели дать нашим программистам разработчикам инструмент который практически любой ситуации способен им быстро и достоверно предоставить информацию о том что происходит их приложение да это получилось довольно таки сложно но тем не менее наши хотелки все-таки удалось уложить в вы существующие продукты которые при этом не пришлось почти переписывать под у себя собственно говоря большое спасибо за внимание вот буду рад вопрос об человек которого я вижу с микрофоном поймаешь давайте сначала вы а потом вы вот вам микрофон спасибо за доклад скажите вы говорили о том что перешли на тринадцатую java здесь и выбрали в качестве конце шенандоа делали вы какие то помимо дефолтных настроек что-то почуяли тому залазили таланте а вот область ну на самом деле все изменения которые мы вот делали именно в настройках джавы я здесь на слайдах привел и привел я окончательные варианты мы довольно долго пытались работать с м с который является стандартом для вас тикси очень начинали мы с ржавым номер восемь потом у нас были довольно долгие попытки и под потуги различного тюнинга использования же 1pc ну и когда мы поняли что все это не работает пришли уже на по сути то что было вот наиболее свежим на текущий момент это вот это 13 жанра экшен а ты перешли мы однако это от безысходности и получили неожиданно полное решение вот тех проблем которые у нас было еще если это на ваш вопрос у себя да у меня вопрос петр спасибо большое за доклад и меня вопрос такой немножко философский но все-таки он для меня очень актуален оправдан ли поисковый движок движок поисковый для именно логов вообще для хранения логов для поиска пологом не слишком ли дорого 360 нот и 60 координаторов скажем так если есть команда людей которые готовы писатель x вот все вот эти вот web интерфейса для пользователей прочего разного стоило бы может быть взять какую-нибудь другую технологию например вот клик house является в этом плане наверное более производительно но когда таких возможностей нет говорил бисми черчилль демократия это не очень хороший устроен он единственный меняем и который у нас есть то также is elastic все очень попытки построить подобную штуку при вот заданных параметрах на чем-то что я встречал были скорее не получилось то есть да это оправданно вот там просто надо чуть-чуть изменить философию того что власти xi очень хорошо работает тогда когда есть допустим не три четыре пять больших толстых а когда как когда он у нас их максимально много и они сами по себе очень маленький как тогда это получается решить вопрос про пониже вопросы небольшие про deploy ты кажется начали сколько помнил про контейнеры у вас в контейнер и все так да да да да она на какой платформе это севку верните нет дело в том что в одноклассниках вопрос того как строить облака начались до того как начался hyip вокруг каберне tissot и там используется самописный падут который называется он клал да он оперирует докером имеет определенные свои плюшки но теоретически тут я вот говорил за исключением вот там пам пам учиться с мониторингом в это полностью переносим ее на кубе последние два дня говорим все про операторы губернаторские для баз данных если что-то на рынке для elastico честно говоря здесь не подскажу скорее всего есть довольно популярный продукт скорее всего кто-то уже написал но вот из гугла не отвечу еще в первый ряд пожалуйста а потом 8 я не угадал привет идет о пациенте мы вас будем лучшими спасибо большое а или неладны вставайте норман привет пётр спасибо за доклад я так понял у вас один кластер возможны на несколько дата-центр соответственно вопрос возник следующий пытались ли вы использовать несколько кластеров искать через кросс кластер search если нет то почему у меня было очень много мыслей о том что да ну его к черту с вот этими большими мастерами потому что вот большая часть проблем которые я озвучивал в кластере буквально вы двое меньшего размера не встречается в принципе вот и добыли идея для того чтобы построить соответственно будете кластер соединить их вот этим самым четвертым типом not о которых я сегодня не рассказывал и заметь компания свое счастье но к сожалению frontend в качестве брелока не умеет с этим работать то есть на уровне вот это вот продукта брелок мы к сожалению были просто прибито гвоздями к потому что это должен быть один кластер а переписывать это проведение совершенно не хотелось было грубо говоря значительно проще построить вот этот большой махину отладить не проблема чем городить огород с вот этими самыми нет небольшими кластерами как тот я зашел на крыло графский дед хоп увидел там собственно и шью на тему того что мы хотим будет мультик кластер посмотрю что ему в этом два года то ли три года и понял что ну форсировать эту задачу своими как-то не хочется вот так давайте так 1 1 ряд 1 2 потом второй просто помашем петербургу с новосибирском у них там нет вопросов но идет networking а потом возьмем галёрку ура впервые за два дня поехали пожалуйста я продолжу вопрос про контейнеры вы говорили что запускать надо где больше 50 6 ядер машинах вот как у вас получается контейнер на одной из железной физической машине один контейнер и спускается или вот как и там 700 мегабайт диск да да да мы стараемся вернет искать там в политиках размещения контейнеров в облаке мы прописываем что во первых то место где мы размещаем контейнер должно обладать более чем пятьдесят шесть укором это во-первых и второе что там не должно быть никакого контейнера которая содержит в себе да я даже намек на название ластик search потому что если они начинают делить между собой процессах то мы получаем большую деградацию папе форме привет спасибо за доклад мою просто уже на самом деле быть процессе иммиграцию вчера был очень близки в этом смысле доклад от коллеги из амазона который рассказывал как они приезжали с 8 джавы на 13 и среди прочего он упомянул что даже когда они приехали тринадцатую джаву они не старыми garbage collector они остались на g-1 я спросил его почему ведь там есть за джесси там еще надо и он сказал что они не стали этого делать потому что эти garbage collector и плохо справляются с высоким отличным рейтом они не основаны на поколениях и так далее с точки зрения на зону да они сменили джеддака но при этом на джесси остались на старом вот хотел спросить не было ли вот у вас такой проблемы может быть у вас таких слышно ритм все хорошо я воспользуюсь попку помощью за вы буквально вызовами главный инженер который ответит на данный вопрос значительно круче чем дайте пожалуйста микрофон олега настасью я думаю что мы в дискуссионную зону и ему что-то вопрос про giovanni elastix еще большую часть ok красота стрелки забиты галёрка пожалуйста приветствую меня зовут григорий аструс компании бренд alytics ты не похож на интроверта почему ты не сидишь так высоко потому что отсюда хорошо видна вы запросто на самом деле мы сейчас сидели ностальгирую ли потому что мы прошли практически весь такой же путь нас на текущий момент кластер приближается там кстати об этом и у меня вопрос немножко уточняющий просто интереса ради у вас вы не уточнили сколько у вас данных в количестве то есть средний объект средний вес объекта насколько сложный маппинг и как вы производили обновление с версии на версию учитывая что индексы они конечно обратно совместимы и до определенного уровня мы вопрос на самом деле очень большой тут стоит сказать что я когда составлял вот эту презентацию и готовилась к докладу я вот все думаю что же у него впихнуть а что нет потому что по-хорошему там и кластер большой в нем доклада на 3 говоря о миграции и о паппинге собственно по-хорошему мы взяли вот и именно то что изначально поставляет брелок что мы там чью не ли мы занимались тем что и сейчас занимаюсь этим что выставляем различные приоритеты на выставление индексов это индекс priority recovery ли как то вот так вот называется параметр вот когда и собственно чтобы там еще делаем да в общем то все по сути используем и полный мэппинг который нам предоставляет грейлок то есть это индексация всех полей и кроме массаж потому что он слишком большой в таком случае у нас получится просто непомерных размеров вот и относительно вот вопрос говоря об объекте речь о джорди об индексе или а людском сегменте я имел ввиду один объект 1 запись а в этом смысле а то я не совсем понимаю вопрос можно перефразировать или может быть переместитель дискуссионную зону сами смотрите вы говорите у вас 200 терабайт кластера 200 терабайт это суммарные вместе с репликации совсем и соответственно интересен вес одного объекта то есть чистый полезные полезные нагрузка хранения а вес одной строки но блин на самом деле довольно сложно сказать наверное у нас будет очень сложно вывести как какую-то норму потому что с одной стороны как когда у нас прилетает одной строкой какой-нибудь гигантский stack trace это грубо говоря один объем когда у нас пролетает какое то среднее сообщение допустим о том что не знаю там info что-то там это совершенно другая блин принципе я встречал строки которые там размером килобайта 23 бывает это вот в предельном размере вот сколько там среднем честно говоря не скажу потому что не было необходимости производить такой анализ друзья еще посмотреть еще раз и два насчет апгрейда был вопрос еще не до ответили да так еще что то можете напомнить что прав гриб а все понял вопрос по самом деле когда мы обе эти есть там с 56 что-то там на 6 там что то там вот как то так получилось что вы проблем не встретили совершенно никаких мы пошли по инструкции которые собственно говоря предоставляет компания elastic search учете модифицируем что там сперва мы выложились там на одном координат или где нету никаких данных чтобы посмотреть как она в офисе приведет после чего это распространение на координаторы потом взяли мастер и потом нет несколько дат дата но ты вот так вот это за две недели потихонечку постепенно переползли со мной версию от другую вот каких-то приколов и спецэффектов от пользователей и влогах вот это спасибо за доклад если правильно понял архитектуру как у вас правой стороны а подождите где вы смотрите а вот на вот если правильно понять архитектуру у вас реплика фактор 2 это значит что праймари shard как и его реплики могут попасть в один dc поэтому вопрос как вы рулите локацией что кажется потери dc может привести к нам от вас индекс покрасьте а дело в том что мы the girl i'm not и по их типу то есть соответственно это дата это координатор это мастер и навешиваем еще дополнительный тыкву имени дата-центра дальше у нас просто власти все очень работает политика что бараках получается одной зоны нельзя размещать оба вот этих вот праймеры и реплика объекта это гарантирует то что нет пони будут аллоцирование вообще либо будут аллоцирование в разных листа отлично и финале зиру ющий павел безруков большое спасибо за доклад смотрите решаю задачу есть большое индекс тампе а 10 15 миллионов вот хочется увеличить производительность одного запроса есть кластер elastico ii и слышу несколько рекомендаций 1 рекомендация подбираются количество шар дав на количество нот вторая рекомендация подбирать количество шар дафна количество ядер что посоветуете я посоветую во-первых бренд анализировать за какой интервал времени нам требуется вот чего устранить чудной чем встретим луч евгений мнения о том что грубо говоря индексу нас во время не простирается допустим на день и на час или на неделю до какой вот провал данных нам это интересно мы гарантируем этой мелодии это продуктовый индекс као лак а хорошо в таком случае я бы сказал что дано больше держать 1 шард на одной ноте а дальше грубо говоря ориентироваться по тому какой у нас сторож что грубо говоря если допустим у нас с бетоном имеет смысл повышать концентрацию carnage арт потому что грубо говоря мы упремся из-за этого в дисковое его если у нас это как учащийся один тут надо поэкспериментировать и вы чинить какую-то оптимальную концентрацию carnage арт привод текущем дисковом хранилище а разве elastic не ищет по yandex проверить он координатор отправлять запрос на каждый из нот если будет partition поменьше то вроде как должно работать быстрее плюс если у нас есть несколько ядер а то они могут этого параллельно я объясню в чем дело дело в том что когда его stick search запускает вот это самый поисковый запрос допустим на одной ноги и поисковый запрос у нас stuffed допустим 2 шарда то получается что для того чтобы из этих сортов прочесть он спавнится допустим нас там 50 ядерных процессов спавнит первые 50 трейдов для чтения из одного шара и одновременно с этим еще 53 дафна второй шар то есть у нас получается что у нас на 50 ядерный процессор получается стол трендов в наш эксперимент и выяснилось что значительно быстрее мы получаем ответ в том случае если у нас не происходит такого перри использования процессора спасибо супер спасибо большая скажи кому мы дарим поощрительный приз за лучший вопрос кто там был с сложным вопросом по поводу вот просьбу вот там вот сверху спрашивали про миграции и про маппинг сверху приз уезжает на галёрку для тебя у нас тоже есть супер памятный приз спасибо огромное красавиц"
}