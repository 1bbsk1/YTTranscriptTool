{
  "video_id": "obQunWMJ8qc",
  "channel": "HighLoadChannel",
  "title": "Базы данных на GPU / Денис Тишков (Технологический Центр - Deutsche Bank)",
  "views": 2657,
  "duration": 2560,
  "published": "2020-04-14T10:50:24-07:00",
  "text": "спасибо всем привет да меня зовут дани стежков я работаю в компании дойче банк и в докладе в своем я расскажу про базы данных на gpu и в принципе поговорим о том как такие казалось бы на первый взгляд несовместимые вещи как видеокарта может быть связано с базы данных и где она может помочь поговорим про база данных и поговорим о гopoдa в целом чем хорош чем плохо где он может помочь в каких-то вычислительных аналитических задачах и так немного обо мне около десяти лет занимаясь коммерческой разработкой программного обеспечение из них 7 лет писал на си плюс плюс последние четыре года пишу на джаве работаю в даче банки и сейчас работаю в проекте о валентности приложения вот в докладе и немного расскажу о нашем проекте чем мы занимаемся какие проблемы возникают откуда вообще идея возникла gpu посмотреть использовать коротко пробежимся по базам данных стелах чем отличается ул теперь от лап систем потому что это принципиально для gpu чем готова нам поможет помочь поговорим про gpu про его архитектура и какие о том какие задачи в принципе может помочь нам решить погоняем бенчмарки гopoдa базы данных против аналитической и и базы данных поговорим коротко о программировании под gpu посмотрим как классические алгоритмы работают на видеокарты и насыпью где когда они быстрее вот по ходу доклада я буду делать выводы обращать внимание где хорошо где плохо где есть смысл использовать где нет из доклада вы также узнаете где как попробовать чего не будет не будет цифра с продакшена к сожалению да продакшена еще решение не довели вот но активно исследуем и думаем как это все таки в продакшен вывести кстати в продакшене уже готова кто-нибудь использует может поднять руки никого да да есть а машина обучение кто-нибудь использует да вот уже больше но в целом казалось бы вот gpu и машины обучения это более такие вещи на слуху и особенно нейронные сети очень сильно ускоряет нейронные сети ну мы немного другом сегодня итак предметная область что у нас за проектом наш проекта написаны работает для электронного fx трейдинга для рынка обмена валют электронного ну все знают что такое обменный пункт валют захотели поменять рубли на доллары перед отпуском пришли в обменный пункт отдали наши рубли забрали доллара из отпуска вернулись назад поменяли вот удобно но для корпорации особенно международных корпораций для которых постоянный поток финансов в разных валютах в будущем имеет смысл форвардные сделки то есть что это такое коротко это заключение контракта на обмен валюты в будущем но курс фиксируется сегодня вот это удобно для крупных компаний например российская компания знают что будут поступления в долларах через год и компания фиксирует текущую ставку курс обмена валюты и может по это планировать свои расходы в будущем независимо от того как изменится курс ухудшили лучшую сторону так вот понятное дело что на такие сделки возникают риски и сам очевидны резко это того что какая-то компания заключила такой форвардный контракт изначально она за него ничего не платят но в будущем когда курс валюты изменятся понятно что либо банк останется должен денег компания либо компания банку так вот есть резко что эта компания обанкротится да и когда банк предлагает курс обмена валют его для такой форвардной сделки банк закладывает вот этот риск в спред между покупкой и продажей валюты вот и от того насколько надежная компания или не очень надежная будет зависеть вот эта ширина спреда и определяется такой метрика как себе и кредит в илью adjustment есть также много других метрик например пифе это та нас если курс очень сильно изменится в будущем а компания заключила очень большую тяжелую сделку то есть риск что курс очень сильно валюты уйдет и компания будет должна очень много денег и опять же может оказаться неплатежеспособны так вот мы можем посчитать такую метрику спрогнозировать что с какой-то вероятностью такой риск наступит и заблокировать такую сделку не не пропустите и есть еще метрика peavey это уже риск того что сам банк обанкротится вот метрики разные по сути по смыслу но считаются они вот как для технического специалиста похожим образом вот поэтому мы считаем в одном проекте вот все это о том что будет в будущем то есть обанкротится не обанкротится клиент уйдет курс не уйдет вот понятное дело никто не знает что будет завтра и мы можем только моделировать ситуацию как вот изменится положение дел вот можем смоделировать это полагаясь на исторические данные курсах валют в прошлом используя определенные математические методы например метод монте-карло и теория случайных процессов в общем очень много математики но в целом мы можем спрогнозировать более менее вероятные пути развития курса валют вот на графике вы видите как мы моделируем я не помню что за валюты а здесь наверное доллар доллар евро но теоретический курс как может измениться курс валюты на из определенной вероятностью мы можем сказать на какую-то дату например 27 ноября девятнадцатого года что скорее всего курс валюты не выйдет за таки за такой коридор вот дальше мы можем также спрогнозировать сколько клиент на будет должен если вот он много денег сделать на заключал в зависимости от того куда курсу идет изменится это сколько клиентам должен вот это финансовые термины вот сейчас потихоньку спустимся более к таким техническим вещам на какие задачи возникают для нас как инженеров это все выглядит как матрицы мы берем сетку дат из 60 дат и тысячи симуляции вот то что вы видели на графике много ли не вот мы 1000 таких симуляции делаем вот и на 60 дат в будущее считаем есть одна матрица заголовки можно не читать но суть в том что есть входные матрицы здесь 4 у нас в принципе в проекте когда мы многое что за кашира вали что-то там заранее посчитали где-то на вход в алгоритмы поддаются 5 матрицы и с матрицами выполняются простые действия умножить вычисти причем это не сложно и линейная алгебра а поэлементно берем строчку 1 колонку один за одной матрицы 2 3 4 5 и складываем вычитаем умножаем и вот так для матриц 60 на тысячу то есть в общем виде можно представить это как набор матриц 60 на тысячу выполняем математику все это сводим к одной матрицы 60 на тысячу дальше там еще до ножа им на какие-то коэффициенты агрегирует по колонкам остается вектор из 60 дат и дальше все это суммируем и получаем 1 число то есть как выглядит у нас работа приходит один request от пользователя с несколькими параметрами из к шее мы достаем вот такие матрицы большие считаем там преобразуем и на выход отдаем там до 1 метрики но два числа подсчитано разных матрицах так вот делаем все это мы на джаве в проект на джаве написан тем не менее он был от нас три миллисекунды request response вот сам расчет вот с этими матрицами который я показал если в один поток то где-то 900 микросекунд занимает держим 25 или просто в секунду вот эти матрицы у нас за кашированного в памяти где-то 16 гигабайт занимает сейчас мы считаем 6 метрик на выходе можем где-то около 15 чистил отдать и в основном что важно это вычисление вот с матрицами по элементные вычисления водки проблем у нас возникают вот этих метрик я вам показал только три метрик но и их все больше и больше разные методологии расчета вот соответственно новая метрика притягивает новые static данные новой матрицы вот раз в полгода наверно мы добавляем по 1 метрики объем данных растет количество request of растет больше клиентов которые хотят считать вот эти все метрики чего хочется хочется оставаться с той же elite 3 миллисекунды она всех устраивает всем комфортно в смысле клиентам для нас понятно что железо не безграничное количество потоков которые мы можем запустить не безгранично но что можно с этим сделать но самый простой вариант купить помощнее железа помощнее процессор но как бы тоже бесконечно это не будешь делать можно разнести вычисления на несколько серверов можно разные метрики вы на разных машинах считать но уже другого рода технические сложности возникают что ещё можно сделать можно использовать синди инструкции процессора я думаю многие знают что такое 7 это вычисления но чтобы говорить об одном и том же я коротко все-таки скажу обычное скалярные вычисления сян сян construction multiple да это обычное скалярные вычисления есть вектор а с элементом 1234 вектор b и хотим посчитать по элемент на сумму этих значений у виктор ах да если мы просто в коде например на джаве будем писать но это будет цикл от нуля до четырех складываем 1 плюс b 1 записываем c1 что здесь особенного тип данных и а и b вектор разве mind of a и b они одного типа данных и на выходе тоже получается вектор 1 типа то есть данные разные типы одинаковые и операции везде плюс то есть одна и та же синглом страшно на самом деле не то что здесь только один плюс здесь будем может быть плюс минус там разделить но один и тот же набор действий для разного набора данных так вот в процессор и добавили оптимизацию которая позволяет процессору буквально за несколько тактов выполнять такие сингл instruction multiple дейта над векторами можем взять вектор загрузить его в 1 регистр можем взять вектор b загрузить во второй регистр и сказать процессу процессору считаю сложить вот эти два вектора поэлементно и он в регистре нам выдаст подсчитанный вектор c то есть не надо вот этих циклов от 0 до 4 1 1 загрузили сказали посчитать посчитали вот сингл construction multiple да это так вот что можно сделать кстати missing вычислениями ну соответственно можно задействовать эти инструкции процессора проблема в том что мы пишем на джаве напрямую к этим сент инструкциям не подступиться вот можно надеяться только на jit компилятор который за нас там сделает оптимизации за использовать эти регистры но на данный момент вот у наших задачах это не очень хорошо работает вот что с ним что без эффекта мы не увидели вот такую что можно сделать эти вычисления можно переложить на gpu почему gpu и вообще почему речь о нем заходят потому что вот этот график желтая линия это рост производительности в бега плохо псах цепью голубая линия это рост производительности gpu и то есть видно что с каждым годом рост производительности такой впечатляющий и наконец 2018 года разница была где-то восемь раз вот конечно график интересный и хотелось бы вот эту мощь как так ней подступиться и использовать такой что можно сделать можно взять какой-нибудь из детей от конкретного производителя от конкретной видеокарты разобраться написать код для этой видеокарты и получать вот эти блага такую дикую производительность эффективно но долго порог входа очень высокий девайс сложные все-таки комьюнити меньше чем для классических языков и программирования фреймворков вот но самый эффективный способ то есть максимальную отдачу можно получить что можно еще сделать можно использовать готовые решения по верху как раз вот базы данных акт о которых мы будем говорить чем привлекательна как бы суп поддерживает стандарт на искье устанавливается там быстро администрирования более менее понятно и всем знакомые если да то есть уже реализация скрывает под собой и тонкости того как взаимодействия закупку как там память выделять передавать как там использовать вот эти все ядра самые наверно быстрый простой способ подступиться и попробовать отдачу и можно использовать промежуточные варианты фреймворке которые скрывают какие-то тонкости в этих самых группу и при этом позволяют таки на классических языках программирования более-менее понятный код писать так вот что мы для себя решили ну во-первых попробовать суп на gpu 1 почему ну потому что самый простой способ как я говорю подступиться 2 в эти матрицы про которые мы говорили операции то математические на самом деле все этому эти матрицы можно представить как таблицы с колонками и строчками а вот те операции элементарные их можно привести к аналитическим запросам то есть по сути это можно написать и сквер который вот сделает вот эту всю математику на карте и можно быстро посмотреть насколько это эффективно второй нюанс в принципе суп на gpu так как я работаю в банке у нас баз данных очень много большой зоопарку oracle клика уж много всего для разных задач своей базы и в целом ну все хотят чтобы запросы тяжелой запрос аналитические выполнялись как можно быстрее вот то есть смежных проектах если вы увидим boost когда performance действительно вот таких баз их можно вот в каких в конкретных проектах использовать смежных ну и в целом интересно вот и второй вариант для себя мы смотрели это написать код руками для gpu разобраться с этими из детей и вот взять наши ти матричные вычисления написать и и вот скормить видеокарту посмотри что будет вот давайте коротко базах данных поговорим транзакционные аналитические базы я понимаю что конференция техническая секция про базы данных все знают знают чем отличается от ран сексуальная от аналитическая база вот но это принципиально почему мы вообще об этом говорим поэтому давайте коротко пробежимся транзакционные работаем с одной строчкой атомарная запись чтение много где используется аналитическое мы уже работаем из низ одной записью с большим массивом колонок то есть выбираем из базы уже много значений и выполняем какую-то аналитику там агрегацию еще что то вот почему важно вот это различие потому что вот эта классификация она влияет на реле на реализацию таких баз есть классическая таблица имя фамилия надо всем знакомо если мы говорим а транзакционный системе то удобно во-первых вот эти строчки хранить на диске последовательно вот эти имя фамилия на диске записали там по порядку перешли к следующей строке записали на диск d вторую строчку третье это у нас будет срочно и хранение данных вот и удобно пользователь пришел говорит хочу там отредактировать имя фамилию там записи сойди один заблокировала вот эту запись и работая с ним другим таким же запросом не мешает но если придется аналитический запрос например посчитать среднюю зарплату выведет что запись cd 1 заблокирована будет ждать вот возникают конфликты то есть как бы пересекаются интересы блокировки и как бы запросы по характеру разные и тем не менее мешают друг другу так вот чтобы ускорить такие запросы придуманы колодочные хранения на диске для аналитических bass то есть мы в один файл записываем последовательно одну колонку один например в отдельных файлах имя фамилия последовательно идут все имена в следующем файле последовательно фамилии потом возраст зарплата чем удобно приходит энергетический запрос обычно таком запросы не нужны все колонки из таблицы например хотим посчитать среднюю зарплату зашли в один файл зарплаты считали весь файл в оперативную память и пошли либо циклом по всем этим элементом либо этому те же сент инструкции используем в как бы и удобно и быстро причем здесь видеокарта давайте разберемся ну все знают что такое видеокарта отдельный девайс обычно есть собственная память и собственный я до ядра вычислительные и может выполнять какую-то математику на себя изначально предназначалось как отображение картинки на экране позже появилась 3d графика уже назначение было таково что в карту загружаем набор вершин и к этим вершинам мы хотим от рендерить изображения добавить какие-то эффекты тень свет еще что-то для этого пишут шейдера то есть маленькие программки которые можно вместе с изображением отправить на карту и этот shader пробежится там либо папик сильно либо по вершинам и каждый пиксель преобразует так как мы скажем то есть такие маленькие программки который может на карту отправлять его для преобразования таких изображений что интересно шейдеры они по сути очень могут выполняться параллельно то есть изображение большое пикселей много вычисления в принципе не зависят друг от друга можем отправить один shader на видеокарту и запустить множестве потоков вот эти самые преобразования вот соответственно производители видеокарт для того чтобы ускорять вот эти вычисления добавляют все больше больше ядя на эти видеокарты и современные карты уже содержит около 4 тысяч этих самых я der что интересно вот эти самые ядра они уже могут не только выполнять какие-то графические преобразования они могут выполнять вычисления общего назначения плюс минус умножить вот и здесь уже интересно то что мы можем вот такие вычислительные задачи с процессором переместить на видеокарту и вместо одного ядра использовать вот эти тысячи и вот такие вот вычисления уже общего назначения подходят для аналитических вычислений аналитически например тоже агрегация это но на самом деле не совсем синди операции там будут какие-то условия добуду цикла но все равно можно привести аналитические операции касим операцию просто их будет несколько вот здесь уже интересно вот это вот возможность этих аналитических вычислений как раз для баз данных вот как я сказал лидер может быть тысячи 4000 череда но интересно чем все-таки отличаются вот это и иду на видеокарте от ядра насыпью доказала почему в процессор нельзя запихнуть вот эти самые четыре тысячи едят так вот ядро процессора она изначально заточена на выполнение витиеватой логике много условий и фас циклы да и каждое едва она выполняет операции независимо другого евро то есть чем больше я der тем больше независимых задач мы можем выполнять и соответственно связи с этим на на ядре процессора очень много всяких логических блоков которые оптимизируют эти самые вычисления например branch предикторы out of memory контрола джек и много всего еще вот чем же отличается ядра gpu с одной стороны оно проще с другой немного сложнее прочь в том плане что убраны в это те такими зонта оптимизации branch предикторы memory префетчер а вот то есть это как можно сделано как можно проще вот более того как вы видите на картинке вот эти арифметические и логические устройства их уже много но соответственно вот вот это и говорят количество ядер вот сколько этих устройств которые могут непосредственно математику выполнять что здесь интересно вот эти ядра уже делят между собой общий регистр очень общего фиджи декодер инструкции то есть здесь важно то что вот эти ядра они уже как бы используют общие какие-то логические элементы на карте вот то есть в чем здесь идея вот этот свет жди кадр он загребает из памяти несколько инструкций до в регистры раскладываются данные и вот эти арифметические логические устройства они начинают выполнять одну и ту же инструкцию но с разными данными вот в регистрах то есть будут разные данные вот то есть вот это и есть тот самый сент и топот что эти видеокарты закон за кожина и почему вот когда говорят о видеокартах этого и вот именно связано сент инструкциями так такая архитектура на самом деле накладывает еще ограничение на то как данные могут располагаться в памяти то есть здесь важно то что вот эти каждый ведро не может работать с каким-то произвольным типом данных мы можем загрузить вот один большой вектор как я показывал на картинке либо большую матрицу из элементов одного и того же типа работы каждое ядро будет работать с каким-то элементам из этого большого вектора или матрица так вот поговорив огпу наверное вы заметили что в принципе здесь уже находятся точки пересечения аналитической базы и вот видеокарт где можно совместить интересы то есть мы говорили около начном хранение это массивы однотипных данных вот эти данные можно блоком загрузить оперативной памяти отправить на видеокарту аналитически запросы можем преобразовать к симбе инструкциям и вот на карте выполнять так вот умные ребята смекнули посмотрели на это догадались и сделали несколько реализации независимых этих самых баз данных на gpu одна из них это генетика интересно то что разрабатывалась военными вот может выполнять операции как на себе так и на gpu если носить пью выполняется быстро теперь выполняется быстрее то данное отдается степью если нога побыстрее эту результаты дается с gpu гаусс дебит недавно анонсировал huawei интересно то что работают с данными больше десяти петабайт bright light это на базе пост грессов сделанная база из к теориям тоже как бы позиционироваться что с большим объемом данных может работать так и он мне все про неё мы будем более подробно говорить вот а кто-нибудь слышал хотя бы одну что-нибудь об одной из этих баз данных до есть отлично вот там нельзя будем говорить про неё смотреть на нее почему потому что бесплатно есть бесплатная версия ядро опасная есть как энтерпрайз версия такова облака если понравилась бесплатная версия можно заказать коммерческую поддержку можно их облака взять можно очень быстро поднять instance в амазоне и быстро проверить насколько хорошо плохо поддерживает работу в кластере и можно как выполнять вычисления так и на себе он то есть как бы им и моря и очень много рекламы ятен видео и от гугла принцип интересно попробовать вот так вот дальше посмотрим как выполняются запросы на этой базе данных будем сравнивать у меня себя на gpu клик хаусом вот клик house потому что ну реально быстро все довольны вот и наверное самый такой удачный пример аналитической базы которая действительно быстро выполняет самые аналитической запросы вот кликал с у нас будет зацепил у меня себя из-за готовы будем сравнивать инстанции на амазоне в amazon узком облаке единственно какой нюанс как бы мы сравниваем видеокарту и степенью как бы совершенно разные девайсы и там адекватных параметров чтобы выбрать как-то покорить каким-то критериям нет ну так то же самое что сравнивать клавиатуру и мышку девайс как бы разные но можно сделать одно и то же в общем я взял самый простой instance на амазоне это 4 литра 60 гигабайт оперативной памяти и 1 серверами к видеокарта тесла к 80 и кликал с 2 инстанция 1 на 4 ядрах 16 гигабайт памяти и на 32 и драк 128 гигабайт памяти открыты datasette и 70 миллионов строк 30 гигабайт в файлах вот и набор запросов часть запросов я взял и сайтах ли хаоса там в принципе уже гоняется benchmark вот на этом же дата сети с этими запросами и показываются результаты выполнения и часть своих запросов и так же как я говорил вот наши вычисления преобразовал иск вели операциям и померил насколько быстро наши вычисления выполняются на карте так вот методология версия это версия мне 748 один клик с 1915 3 и там и там локальный клиент то есть нет сетевого вверх и до файл с sql-запросами и время берем и из блога клиента так на что сразу хочу обратить внимание красно это первый request ком есть голубая голубой столбик это второй request видно что первый request он на самом деле очень плохо то есть сразу первый вывод почему это возникает когда мы говорили про фильтр там видно что у нас есть еще выход на то чтобы переложить данные с диска и в оперативную память и еще в самую видеокарту перекачать то есть это узкое место на самом деле у видеокарты так вот первый запрос на самом деле он очень хуже чем клик хаусу хауса такой проблемы нет что первое что второй запрос примерно за одинаковое время выполняется так вот будем смотреть на второй запрос камни себя и на второй запрос клик хауса так вот первый сет запросов это поиск задаем условиях где и какие то простенькой условия по вертикали и талэ пенсиями в миллисекундах по горизонтали номера запутался в три четыре пять и вот справа собственно сами запросы которые мы выполняем первый столбик этого мне 7 2 1 столбик это клик house на 32 ядрах и третий столбик и так ли house на 4-х ядрах здесь видно что у меня есть хуже всех интересно то что клик хаос на 32 я вот эти поисковые запросы выполняет хуже чем прекрасно 4 ядрах я не знаю с чем это связано но вот такой вот результат получился ну суть запросов надеюсь ясно простенькое условия где так давайте сделаем запросы на сортировку и трансформацию пример запросу упорядочены по какой-то колонки и здесь вы тоже видите что он есть ну прям совсем плох и как бы никто не всегда на самом деле результат был не не ожидаем потому что поиск это как раз таки вот такая 7d инструкция которая не требует каких-то сложных преобразований просто кучу данных отдали на карту от 1 параллель или должна быстро выполняться но вот такой результат получился и запросы простенькие преобразования по колонкам и упорядочивания вот дальше агрегация то есть суммируем считаем среднее по колонкам и делаем все эти три действия в одном запросе то есть вот здесь уже видно что ум неся и в принципе вот уже чуть чуть лучше кликал сын тридцати двух ядрах да ну и значительно лучше cliff house и на 4 ядра то есть вот агрегационную запросы уже как бы более-менее чуть усложним запросы добавим join и вложены запрос преобразования по колонкам вот уже такое более менее похоже на реальный запрос тяжеленький и вот здесь уже видно что но на самом деле я специально не подбирал запроса я вот эти по моему сайта crack house а вот здесь уже видно что он не ось и сияет показывает такие хорошие результаты например 57 59 запросу же раза в два быстрее и просто разные смешанные запросы join и select это же кот запросов я не привожу но можно будет потом посмотреть вот уже видно что на сложных запросах во многих кейсах амнистия показывают себя неплохо и в принципе вот можно найти кейс где да он действительно хороший стоит использовать и вот конкретно наш кейс как я говорил вот те матричные вычисления преобразовали в москве то есть это join 1 таблицах 4 другим таблицам в эти таблицы собственные то матрицы 60 на тысячу в 7 колонн строчки выполняем эту математику которая показывала в начале на слайдах и считаем которая агрегацию делаем по этим колонкам да какой результат получился вот конкретно для нашего кейса первый запрос 5 секунд то есть ну вообще никак второй запрос 350 миллисекунд я вначале говорил тоже что у нас light эти три миллисекунды request a response и посчитать ну то есть вот для нас конкретно тоже 350 миллисекунд ну не подходят вот как думаете crack house быстрее медленнее он быстрее вот конкретно на таком запросе он быстрее существенно быстрее вот это все интересно сколько один запрос считается интересно как под нагрузкой ведет запустим много потоков под нагрузкой уже видно синяя линия это тоже он не сеем тоже похоже уже чем клик house то есть специфика gpu что давно все четыре ядра но запускаем два потока у нас вот эти четыре тысячи тому же на делятся по 2002 и вот видно что но уже тоже не так хорошо это какие наблюдения можно сделать если данных памяти нет то он есть медленно работа действительно медленно и вот сложно придумать кейс где может быть это хорошо сортировкой трансформация тоже работает не очень вот сложные запросы join агрегация вот такие тяжелые аналитические запросы уже работают существенно лучше и под нагрузкой в танце тоже уже не очень где можно вот такое поведение использовать ну во первых если вы можете данные заранее в карту загрузить это хорошо будет проблемы могут быть если данные в карту не влезут я честно говоря не мерил но должны быть оптимизации на самом деле в карту можно в несколько потоков данные писать и теоретически должно быть быстро принципе если данный в карту не влазят вот где-то вот эту умница и можно использовать хорошо подойдет если вы строите какие-то даже бороды графики когда запрос один может быть большой длинный запрос но он один могут меняться только параметры этого запроса да как это мониторинг еще что-то и при этом количество request of небольшое то есть но если небольшая группа администратора в том что то мониторит или вообще один дашборд на всех в принципе уже быстро или если несколько аналитиков работает тоже уже неплохо и конечно нужно проверять на своих кейсах заранее сказать что вот этот кейс будет быстро этот медленнее но к сожалению нельзя так и для у меня есть я быстро расскажу времени у нас на самом деле не много осталось для у а мне семь может результат запроса оставлять на gpu и вот до тех кто использует машинное обучение у себя уже в компания интересно то что вот вы сделали select по данным данные оставили в карте вы можете натравить библиотечки например игры boost передать указатели вот на этот кусок памяти и данный не гоняй назад в оперативную память выполнять алгоритма машинного обучения кому интересно запросы все что я мерил код открыт на гитхабе посмотрите по ссылкам если интересно и где он не все попробовать теперь к корню коротко пробежимся о том ну про базу данных поговорили мы поговорили про конкретную имплементацию да но все таки интересен потенциал я список большой приводил этих баз данных конечно все там нереально попробовать но вот интересен потенциал что можно выжать из этой видеокарта и вот решили ну так сказать руками закончить и наши алгоритмы и классический алгоритмы померить сколько у нас осталось время да я к сожалению растяну немного давайте к результатам перейду если детали интересным и после докладов можем детально поговорить что на чем и как алгоритмы существенно преобразуется когда мы делаем такой на многих потоках выполняем вот эти сент инструкции например агрегация очень показательно если в обычных алгоритмах мы циклом проходим по элементам то здесь уже нужно исхитрятся то есть есть вектор 1 8 элементов мы запускаем четыре потока по два элемента складываем и в несколько этапов сортировка совсем уже усложняется те кто интересуется алгоритмами имплементации очень интересные алгоритмы сложный но такие трюки используются для которых сам не догадаешься но в арсенале имеется желательно примера можно посмотреть по ссылке бенчмарки на си плюс плюс написано где-то компилятором видео где-то gcs оптимизации трансформация насыпей уга по гоняем w60 четырех битной 8 мегабайт 80 мегабайт 800 мегабайт трансформация плохо работает то есть выход на перекачку данных из оперативной памяти видеокарту он сказывается перфоманса нет математики на карте мало агрегация вот агрегации уже на 8 мегабайтах виден результат в два раза на 8 10 мегабайт уже в четыре раза на 800 мегабайт тоже четыре раза то есть агрегация суммируем среднего что такое посчитать передали на карту много данных забрали одно число performance есть вот агрегация сортировка чем больше данных тем разница просто колосальная да на 800 мегабайт разница уже в 25 раз как я говорил вот когда мы на базу данных смотрели что сортировка плохо выполняется вот это удивляет что как бы на таком имплементации в лоб такой хороший performance да а вот в базе ну не не очень возможно где то это используется лучше кому интересно вот в хэды на перекачку данных из оперативной памяти в gpu вычислений и передача то тех же данных назад на большом объёме данных вот эта перекачка она примерно одинаковая занимает время и кто если захочет конкретно для себя в этом не посчитает вот можно примерно ориентироваться по графику на какое в этом все можно рассчитывать наши вычисления насыпью как я говорил 900 микросекунд gpu уже 260 микросекунд уже лучше уже то что хотелось бы но опять же вопрос про нагрузку на нашей матрицы gpu под нагрузкой пошло вверх коли krause цепью горизонтален к там на самом деле есть наклоне большой но незначительного видно что вверх уходит но интересно что если увеличим размер матриц в 10 раз но это не наш кейс но интересно было посмотреть вот этот кейс где же губкой получше красная линия 32 ядра видим что вот скачок есть дано 32-я такой еще хуже становится на 4 ядра ход после четырех я такое улетает вверх график то есть вот есть кейс принципе где а нагрузку держит готова на самом деле gpu может быть быстро данный лучше предзагрузить в карту один сервер с gpt flops а мы видели что может заменить в принципе несколько серверов в один сервер можно поставить до 9 карт и вы может быть больше уже можно заменить кластер из серверов при соответствующей нагрузки и нагрузка тоже зависит от характера нагрузки ссылке вот эти все бенчмарки можно повторить я на github все выложил заключение рекомендации проговорил графики даже борды если виктора матрица видите 72 числе не я у себя можно это попробовать если уже машинное обучение используйте так игровые обращать внимание есть игровые серверные отличаются понятно что одна можно держать нагрузку другая нет больше меньше потоков так заканчивать тем графикам с которого начал gpu производительность растёт хочется она это использовать желательно это обращать внимание пропустим мимо себя вот такой вот рост есть вероятность что наши конкуренты нас обгонят у меня все спасибо"
}