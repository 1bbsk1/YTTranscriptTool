{
  "video_id": "3yRt9jSwrlg",
  "channel": "HighLoadChannel",
  "title": "Zabbix, 100kNVPS на одном сервере / Михаил Макуров, Максим Чернецов (Интерсвязь)",
  "views": 2121,
  "duration": 2042,
  "published": "2019-05-15T02:20:41-07:00",
  "text": "всем привет добрый день вот разреш maxima макс талантливый инженер лучший сетевик которого я знаю максим занимается сетями и сервисами их развития и эксплуатации я хотел бы рассказать о михаиле михаил разработчик носи он написал несколько высоконагруженных решений для нашей компании по обработке трафика мы живем и работаем на урале в городе здоровых мужиков челябинске компании интерсвязь наша компания это поставщик услуг интернет и кабельного телевидения для одного миллиона человек в 16 городах стоит сказать что интерсвязь это гораздо больше чем просто провайдер это эти компании большинство наших решений сделаны силами собственного эти отдела ит от серверов обрабатывающих traffic to call центра мобильного приложения войти отделе сейчас около 80 человек с очень разнообразными компетенциями а теперь я попробую поставить личный рекорд и за 1 минуту и рассказать что же такое zabbix запись позиционирует себя как система мониторинга из коробки уровня предприятия в нем есть много упрощающих же их функций развитой правило эскалации и пиа и для интеграции группировка хостов и метрик автообнаружения х 100 х метрик в сексе есть так называемое средством от сабирова нее прокси zabbix эта система с открытым исходным кодом коротко об архитектуре можно сказать что он состоит из трех компонентов 1 сервер написан на си достаточно сложный обработкой передачи информации между потоками вся обработка происходит в нем от получения до сохранения в базу все данные хранятся в базе mais quel поддерживаю zabbix поддерживает mais quel под газ и oracle веб-интерфейс написан на php в большинстве систем поставляется с сервером apache но более эффективно работает связки engine с + php-fpm все три секунды есть сегодня мы хотели бы рассказать одну историю из жизни нашей компании связанной zabbix миша привет рад что успел тебя поймать и есть разговор у нас снова были проблемы с мониторингом во время крупной аварии аварии все the mozilla и не было никакой информация состояние сети к сожалению это повторяется уже не первый раз мне нужна твоя помощь давай сделаем так чтобы наш мониторинг снова работал при любых обстоятельствах давай ну давай сначала синхронизируете я не смотрел то должен пару лет насколько помню мы отказались от nagios и перешли на zabbix лет восемь назад и сейчас у нас кажется 6 мощных серверов и около десятка прокси я ничего не путаю ну почти 15 вовсе тизеров часть из которых виртуальной машины но самое главное что все это нас не спасает в тот момент когда нужно больше всего как авария так сервера тормозят и ничего не видно мы пробовали оптимизировать конфигурацию вот но оптим окно прироста производительности оптимального это не дает понятно что то смотрели уже что-то накопали диагностики до первое с чем приходится иметь дело это как раз база данных mais quel и так достаточно высоко нагружен постоянно сохраняя новые метрики а когда zabbix начинает генерировать кучу новых событий база уходит себя буквально на несколько часов про оптимизацию конфигурации я тебе уже рассказал а вот то что мы буквально в этом году уже обновляли железо и на серверах стоит больше сотни гигов памяти и дисковые массивы на ssd рейдах и линейное вырастить дальше нет смысла вот что-то будем делать понятно ну вообще мой скелетон типе базу и видимо она больше не подходит для хранения архива метрика нашего размера давай разбираться давай через некоторое время мы получили интересные данные большая часть место в нашей базе была занята архивом метрик и менее 1 проц и это использовалось под конфигурацию шаблонные настройки этому моменту мы уже больше года эксплуатировали решение bigdata на базе crack house направление движения для нас было очевидным на нашем весенним хакатоне миша написал интеграцию zabbix с клик house in для сервера и фронтэнда на тот момент в за биг си уже было поддержкой ластик search и мы решили сравнить их для сравнения мы генерировали нагрузку такую же какую делает zabbix сервер и смотрели как будут вести себя система мы писали данные пачками по 1000 строк использовали куру мы заранее предполагали что plexus будет более эффективен для того профиля нагрузки который делает за pics но результаты даже превзошли наши ожидания в одинаковых условиях на тестах олехаус писал в 3 раза больше данных причем при этом обе системы очень эффективно потребляя малое количество ресурсов могли читать данные но elastix у при записи требовалось большое количество процессора суммарно клика us значительно превосходил elastix по потреблению процессора и по скорости при этом за счет сжатия данных клик house использует в 11 раз меньше места на жестком диске и делает примерно в 30 раз меньше дисковых операций то работа с дисковой подсистемой apple house реализована очень эффективно под базы можно использовать огромные сад одесские получать скорости записи в сотни тысяч строк секунду система из коробки поддерживает sharding репликацию весьма проста в настройке мы более чем довольна и эксплуатации в течение года для оптимизации ресурсов можно установить клик house рядом с существующей основной базой и тем самым сохранить кучу процессор на во времени и дисковых операций мы вынесли архив метрик на уже имеющийся cliff house кластера и настолько разгрузили основную морскую базу что смогли объединить ее на одной машине вместе забег сервером и отказаться от выделенного сервера под москвой ну что про проблемы с базой можно забыть это точно другая задача которая нам нужно решить это медленный сбор данных теперь все наши 15 прокси-серверов перегружены процессами snmp и полинга iq нет никаких альтернатив к сожалению кроме как ставить новые новые сервера отлично но расскажи сначала как устроен полем за ну если коротко существует примерно 20 типов метрик и с десяток способов их получения zabbix может собирать данные либо в режиме запрос ответ либо ожидать новые данные через так называемый интерфейс траппера стоит сказать что в оригинальном zabbix это самый быстрый способ существует прокси сервера для распределения нагрузки прокси могут выполнять те же функции сбора что я zabbix сервер получая с него задание и отсылая собранные метрики как раз через trapper интерфейс это официальный рекомендованный способ распределения нагрузки также прокси полезны для мониторинга удаленной инфраструктуры работающий через над или за через медленный канал понятно с архитектура все понятно надо смотреть исходники слушай кажется что-то накопал рассказывай я обнаружил что при проверках доступности zabbix делает проверку максимум до 128 хвостов одновременно я попробовал увеличить эту цифру до 500 и убрал меж пакетный интервалы в пинге это увеличило производительность раза в два но хотелось бы больших цифр в своей практике мне иногда приходится проверять доступность тысяч постов и ну ничего быстрее и nmap я для этого не встречал я уверен что это самый быстрый способ давай его попробуем и нужно значительно увеличить количество постов заодно итерации проверять больше 500 до 600 нет но как минимум пару тысяч хоккей самое главное что я хотел сказать я нашел что большинство полингом за биг си сделано синхронно но обязательно должна его переделать на асинхронный режим тогда мы сможем кардинально увеличить количество метрик собираемых колерами особенно если мы увеличим количество метрик за за одну итерацию здорово и когда как обычно вчера ну вот мы сравнили обе версии of pink и in map и на большом количестве хостов map ожидаемо был до 20 раз эффективнее так как эмма проверяет только факт доступности и время отклика подсчет потерь мы перенесли в триггеры и значительно сократили интервал и проверка доступности оптимальным количеством холстов для map мы нашли в районе четырех тысяч за одну итерацию эмма позволил нам в три раза снизить затраты цепи на проверки доступности и сократить интервал со 120 секунд до 10 затем мы занялись поле раме в основном нас интересовал съем и snmp и агенты за пикси полинг сделан синхронно и приняты специальные меры для того чтобы увеличивать эффективной системы в синхронном режиме недоступность состав значительно вызывает значительную деградацию полинга существует целая система состояний существуют специальные процессы так называемые андрича был полер и которые работают только с недоступными хвостами это пример комментарий который демонстрирует матрицу состоянии всю сложность системы переходов которые требуются для того что в системе оставаться эффективной кроме того сам синхронный полинг достаточно медленный именно поэтому тысячи потоков полиров на десятках прокси не могли собрать для нас нужного количества данных асинхронный реализация решила не только проблемы с количеством потоков но и значительно упростило система состояний недоступных ростов потому что при любом количестве холстов применяют проверяемых в одной итерации полинга максимальное время ожидания составляло один тайм аут дополнительно мы модифицировали доработали систему полинга для snmp запросов дело в том что большинство хостов не могут отвечать на snmp на несколько snmp запросов одновременно поэтому мы сделали так называемый гибридный режим когда по снг полинг одного и того же hasta делается синхронно но при этом это делается для всей пачки хвостов и такой режим в итоге не и медленнее чем полностью асинхронный так как опрос ну скажем полутора сотен истинных значений все равно гораздо быстрее чем один тайм аут наши эксперименты показали что оптимальное количество запросов в 1 из 1 1 интеграции примерно 8000 приезд олимпе по линги и суммарно переход на синхронный режим позволил узко ускорить производительность полинга в 200 раз несколько сотен раз например полученные оптимизации полинга показали что мы не только сможем избавиться от всех прокси но и сократить интервалы по многим проверкам прокси станут не нужны как способ разделения нагрузки ну что макс пара продуктов ok мне нужен мощный сервер и хороший инженер хорошо запланируем давно пора сдвинуться с мертвой точки в 5000 метрика секунд а миша мы обновились ног утру откатились обратно отгадай какой скорости удалось достичь ну тысяч 20 максимум 25 только без двадцати к сожалению мы там же с чего начали отчетах диагностику давать знали какую да конечно вот например интересный топ давай посмотрим я вижу что мы пробовали огромное количество потоков полинга но при этом не смогли даже утилизировать систему наполовину общая производительность достаточно маленькая около 4000 метров секунду я что-нибудь еще до estrace 1 и спойлеров здесь четко видно что процесс болеро полинга ждет семафоров это блокировки понятно непонятно внутри это похоже на ситуацию когда куча потоков пытаются работать с ресурсным с которой можно работать одновременно только одному тогда все что они могут делать работать разделять этот ресурс по времени и суммарная производительность работы с таким ресурсам ограничиваются скоростью одного ядра лежит такую проблему можно двумя способами либо апгрейда железо машины и переходя на более быстрые ядра либо меняю архитектуру и параллели нагрузку кстати говоря на тестовой машине пусть и меньшее количество ядер чем на болевой но зато они раза в полтора быстрее по частоте на ядро ясно надо смотреть код сервера чтобы разобраться мы стали анализировать как данные передаются внутри zabbix сервера классно картинка правда давайте пройдемся по ней шаг за шагом чтобы были менее прояснить есть потоки и сервисы ответственный за сбор данных собранные метрики они передают через socket препроцессор менеджер где сохраняются в очередь данные препроцессор менеджер передает своим маркером которые выполняют так называемые инструкции предобработки и возвращают их обратно через тот же socket после этого препроцессор менеджер сохраняет их в кэше истории откуда их забирают history синкер и выполняющий достаточно много функций например вычисление триггеров заполнение кэша значений и самое главное сохранение метрик в хранилище истории в общем процесс весьма сложной и запутанной первое что мы увидели это то что большинство потоков конкурируют за так называемый конфигурационный кэш это область памяти где хранятся все конфигурации сервера и особенно много блокировок делают потоки ответственные за съем данных так как конфигурация хранятся не только метрики с их параметрами но и так называемые очереди из которых полер и берут информацию о том что им делать дальше когда полиров много едим блокирует конфигурацию остальные ждут запросов поэтому первое что мы сделали мы разделили очередь на 4 части и разрешили безопасных условиях полирам блокировать эти очереди одновременно эти части одновременно это убрала конкурентность за конфигурационный кэш и скорость работы полиров значительно выросла но затем мы столкнулись тем что препроцессор менеджеры начал копить очередь задание это происходило в случаях когда ему не хватало производительности и тогда все что он мог делать это копить запросы от процессов сбора данных складывать их буфер до тех пор пока он не считал всю память и не падал для того чтобы решить эту проблему мы добавили 2 socket который был выделен специально для worker of таким образом препроцессор менеджер получил возможность приоритизировать свою работу и в случае разрастания буфера задач тормозить съем и давать паркером возможность этот буфер разобрать затем мы обнаружили что одной из причин торможения были сами worker и поскольку они конкурировали за скажем совершенно не важны для их работы ресурс эту проблему мы оформили bug fixes мы в новых версиях zabbix она уже решено дальше сам препроцессор менеджер стал узким звеном поскольку это один поток он упирался скорость ядра давая максимальная скорость примерно в 70000 метрика секунду поэтому мы сделали 4 с четырьмя наборами сокетов маркеров и это позволило увеличить скорость примерно до 130 тысяч метров нелинейность роста объясняется тем что появилось конкурентность за кэш истории за него конкурировали 4 при процесс менеджера и history синкер и к этому моменту мы получали на тестовой машине примерно 130 тысяч метрика секунду утилизируя ее примерно на 95 процентов по процессору макс да мне нужна новая тестовая машина в текущую вы большим полазим вот как а что я сейчас сейчас 130 пищу в псы процессор в полку ух ты круто но погоди у меня 2 вопроса по моим подсчетам наша потребность примерно в районе 15 20 тысяч метров в секунду метрика секунду зачем нам больше ну хочется доделать дело до конца и хочется посмотреть сколько мы сможем выжить из этой системы но но для бизнеса бесполезных военных и второй вопрос а даже то что есть сейчас мы сможем поддерживать самостоятельно без помощи разработчиков я не думаю изменения работы с конфигурационным кашам эта проблема она касается изменений в большинстве потоков и достаточно сложно в поддержке скорее всего поддерживать ее будет очень тяжело но тогда надо какую-то альтернативу есть такой вариант мы можем перейти на быстрый ядра при этом отказаться от новой системы блокировки мы все равно получим производительность 60 70 тысяч метрик при этом мы сможем оставить весь остальной code crack house асинхронный полинг будут работать и это будет легко поддерживать тщательно предлагаю на этом остановиться нокий после оптимизации северной части мы наконец-то смогли запустить новый класс продуктов мы отказались от части изменений в пользу перехода на машину с быстрыми ядрами и минимизации количество изменений в коде мы также упростили конфигурацию и по возможности отказались от макросов в элементах данных так как они являются источником дополнительных блокировок например отказ от часто встречающегося в документации и примерах макросы сыном и комьюнити в нашем случае позволил дополнительно ускорить полен примерно полтора раза миша мы два дня пользуемся новой системой и все работает круто но только тогда когда все работает у нас были плановые работы с переносом достаточно большого сегмента сети и мы опять руками проверяли что поднялось что нет ну не может быть мы десять раз все проверили сервер обрабатывает даже полную недоступна сети мгновенно да я все понимаю сервер базы то просто отлогих все быстро но мы смотрим в интерфейс а там вот это и процессы в полку на сервере понятно давай смотреть году мы обнаружили что в ситуациях когда было большое количество активных инцидентов большинство оперативных виджетов начинали работать очень медленно причиной этому было генерация всплывающих окон с историей инцидентов которые генерируются для каждого элемента в списке поэтому мы отказались от генерации этих окон закомментировали пять строчек в коде и это решило наши проблемы время загрузки виджетов даже при полной недоступности снизилась с нескольких минут до допустимых нам 10 15 секунд а историю по-прежнему можно посмотреть щелчком на времени миша уходишь есть разговор не собирался опять это zabbix он до нее расслабся я просто хотел сказать все работает спасибо с меня пиво подведем итог zabbix достаточно универсальны и богатая системой функции его вполне можно использовать для небольших инсталляций из коробки но с ростом потребностей его приходится оптимизировать для хранения большого архива метрик используйте подходящие хранилища можно воспользоваться встроенными средствами виде интеграции с elastic search или выгрузкой истории в текстовые файлы доступность четвертой версии либо нашим опытом и интеграции сколько us для кардинального увеличения скорости сбора метрик собирайте хоть и скромными методами и передавайте через trapper интерфейс zabbix сервер либо можно воспользоваться патчем для асинхронности полиров самого за алекса zabbix написан на си и достаточно эффективен решение же нескольких архитектурных узких мест позволяет дополнительно увеличить его производительность и по нашему опыту получать больше ста тысяч метрик на 1 процессор на машине я хочу добавить пару моментов все весь сегодня текущей доклад все тесты цифры приведены вот для этой конфигурации которая используется у нас с нее мы сейчас снимаем примерно 20 тысяч метров в секунду то есть если вы пытаетесь понять будет ли заработать у вас вот можете сравнить и то что о чем рассказали выложены на git хоп виде патча бухты но это это трудностью надо решить как любом случае потому что ссылки там организаторы что понравилось значит выложена виде патча патч включает себя полную интеграцию с клик хаусом как zabbix сервера так и фонтен до решения проблемы с препроцессор менеджером конечно асинхронный полинг почти совместим со всей веткой версии 4 в том числе сэл тесной скорее всего с минимальными изменениями он будет работать на версии 3.4 спасибо спасибо вопросы и спокойно взаимодействия добрый день посмотрите пожалуйста если у вас какие-то планы интенсивного взаимодействия с командой zabbix и ли у них с вами чтобы это был уже не page а это было нормальным поведением до бикса да значит часть изменений мы обязательно за камедь им что-то будет что-то останется в патче спасибо большое за отличный доклад подскажите пожалуйста после применения патча поддержка со стороны zabbix останется и как дальше обновляться на бог выше версия будет ли возможность обновить после вашего apache zabbix до 4250 нет про поддержку я не могу сказать если бы я был техподдержка , бы видимо сказал нет ну потому что это код из но чужой кода что касается кодовой базы 42 ну я не видел я думаю наши сейчас позиция такая что мы будем идти со временем и сами будем обновляться на следующей версии поэтому патч мы будем выкладывать какое-то время на обновленной версии вот еще раз я сказал докладе или количество изменений с версиями пока не достаточно небольшое и я думаю что вот переход с 3 на 4 на четверку названием кажется мне 15 то есть там что-то поменялось но не сильно важно ну вот то есть вы планируете поддерживать свой патч и можно смело его стоять на продакшн и в дальнейшем получать обновление каким-то образом ну мы категорически рекомендуем нам это делается решают очень много проблем ну и еще раз хотелось бы заострить внимание что там изменение которые не касаются архитектуры и не касаются блокировок и очередей они модульные а не в отдельных модулях и даже самостоятельно при незначительных изменениях и будет поддерживать достаточно просто да то есть и если интересно для полета есть кликал использую так называемый библиотеку история на связано это копия поддержки elastix а то есть она конфигурационный изменяем полинг меняя только именно болеро то есть ну то есть мы считаем что это будет работать на долгую понятно спасибо большое подскажите пожалуйста есть ли какая-то документация внесенных изменений документации это патч но о том как с ним работать потому что очевидно с введением клик хауса с видением новых типов полиров возникают новые конфигурационные опции вот ссылка на наконец то обидно достала там ну есть коротенькое описание как этим пользоваться по себе большая на спасибо ребята отличный доклад вопрос про замену f пинга мамам как вы в итоге это реализовали ну прям можете на конкретных примерах это у вас трапперы и внешне скрипт или что что в итоге проверяет так быстро такое огромное количество хвостов как вы добываете получается этих остыть то есть в итоге надо им об их как-то скормить то есть получить от куда-то положить что-то запустить в общем вот это неинтересно круто очень правильный вопрос такой а значит мы модифицировали библиотеку библиотека называется симки bing это составная часть zabbix а для оси импе проверок в которых количество пакетов указана единица код пытается использовать н то есть это внутренняя работа zabbix а то есть это стало внутренней частью pinger а соответственно никакой синхронизации использование болеро не требуется извиняюсь траппера да то есть это было сделано сознательно чтобы максимально чтобы оставить систему целостной и и не заниматься синхронизация о двух систем баз что проверять заливать через спойлер а не сломалось ли у нас заливка это гораздо проще ну вот ответ да но я маленькую ремарку но мы не проверяли но кот полинга и в записи сервере он единый должно работать просто еще раз акцентирую производительной системы такая что ну нам прокси не нужен правильный ответ на вопрос а зачем вам ты такой системе прокси мы только за наука если из-за на то вы ели мониторить или через медленный канал как это да можно еще один вопрос спасибо за доклад а вы используете zabbix как alert если я правильно понял или вот графики который архивный слой до использует него заехали в куда-то в другую систему типа граф она и так далее или вы не использовать эти функционал я еще раз подчеркну ночь мы сделали полную интеграцию и мы выливаем history в клик house но при этом мы изменили и php часть то есть печка font and то есть печки frontend ходит crack house и весь graphing делает оттуда вот при этом ну если честно у нас есть часть которая строит из того же brick house из тех же данных за бикса данные в других системах графического отображения частности в графа не в том в том числе вопросов больше нет поделитесь пожалуйста немножко внутренней кухней как принималось решение о том что надо выделить ресурсы на серьезную переработку продукты это в общем то определенные риски и скажите пожалуйста вот в истории того что сейчас происходит вы собираете поддерживает новой версии а пятки как было принято оправданность этого решения чисто с точки зрения управления ну видимо драму истории мы не очень хорошо рассказали мы отказались оказались ситуации когда что-то надо было делать и мы пошли по сути двумя параллельными командами 1 занималась запуском системы мониторинга на новых методах то есть это мониторинг как сервис то что о чем рассказывал предыдущий докладчик стандартный набор у концертных решений которые мы комбинируем и потом мы пытаемся изменить бизнес процесс для того чтобы работать с новой системой мониторинга вот и параллельно у нас был энтузиаст программист который этим занимался иначе ну и вот так получилось что он победил и какой размер команды она перед человека всегда нужен пассионарий не знаешь такой профессиональный данном случае видимо вы спасибо большое вы крутые спасибо спасибо еще небольшой такой вопрос для системы все-таки который использует прокси например каких-то распределенных системах возможны ли ваше решение адаптировать и пропатчить например полер и прокси и частично препроцессор самого алекса и взаимодействия то есть возможно ли существующие наработки вот вас на вид хоть как-то оптимизировать под систему с несколькими прокси еще раз смотрите вот я знаю что прокси что zabbix сервер собирается собирается прокатим то есть компилируется и получается какой-то код ныне не проверяли это в продукте we я скажу честно я не уверена в этом по моему препроцессор менеджер не используется в proxy то есть задача прокси это взять набор метрик из-за бикса с полить их но там он записывает конфигурацию локальную базу и отдать обратно забег серверу паре processing потом будет делать сервер sun то есть когда получит интерес про прокси понятен мы проверим на я думают интересна тема 10 состоит идея была такая что если нужно по чуть полер их можно почти прокси и почти взаимодествие серверов иски от препроцессор имена только на сервере по адаптировать под эти цели я думаю все даже проще вы берете код его там накладывайте патч потому конфигурируете так как вам надо то есть там собираете прокси-сервера там саде би си и соединим ой и значит выплаченный код видимо разносите по тем системам и найти этих системах то где-то надо где надо вы собираете прокси где надо сервер то есть дополнительный как точить передачу именно прокси-серверу не придется карниз она стандартная стандартная понял почему на самом деле вот не звучала одна из идей мы всегда старались соблюсти баланс между вот этим взрывом идеи да и количеством изменений нашу легкостью поддержки вопросы закончились тогда всем большое спасибо за вы красиво большой коробов"
}