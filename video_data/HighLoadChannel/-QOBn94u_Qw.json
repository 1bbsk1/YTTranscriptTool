{
  "video_id": "-QOBn94u_Qw",
  "channel": "HighLoadChannel",
  "title": "Zero-cost I/O и fault tolerance в распределенном глубоком обучении / Алексей Морозов (Яндекс)",
  "views": 68,
  "duration": 2606,
  "published": "2024-10-29T03:00:50-07:00",
  "text": "Алексей расскажет нам про то как обеспечить отказоустойчивость в обучении нейросетей Алексей тебе слово Давай всем привет Я руководитель группы модернизации нейросетей в отделе качества рекламы в Яндексе у нас самая наверное крупная рекомендательная система и одна из самых нагруженных в компании Да и вообще в России и сегодня я вам расскажу как мы решали проблему того проблему улучшения утилизации GPU в обучения потому что обучение рекомендательных систем обычно изл обучение рекомендательных систем обычно очень сильно завязан на input-output там гигантские датасеты там нужно много писать в сторо Это должно дела эффективно потому что у нас не так чтобы и много Итак О чём доклад во-первых мы сконцентрируйтесь в принципе ложаться на эту парадигму но так Обычно мало кто делает потому что юшки на репликацию каких-то расчётов дорогие и обычно дешевле запустить модель и иметь возможность очень дёшево её рестарта нуть в случае выпадения какого-либо Хоста а также я вам расскажу о том какие оптимизации могут возникнуть из того какую свободу действий вы даёте пользователю и какие интерфейсы вы для него делаете Значит у нас будет два Zero cost а в двух смыслах первый zer cost - это с точки зрения влияния на производительность то есть работа со сторедж в вашем обучении не должна сказываться на том насколько быстро ваша модель обрабатывает данные данные должны быть всегда готовы и не сказывается на производительности А сохранение состояния максимально дешёвой и второе - это зеро Кост по когнитивной нагрузке потому что обычно по опыту люди у людей которые пишут фреймворки под рекомендательный системы Да и вообще под какие-то большие обучения очень много когнитивных усилий уходит именно на работу со storage значит небольшой дисклеймер Как работает распределённое глубокое обучение У вас есть какой-то скрипт на питоне и если вы хотите распределённое обучение Вы один и тот же скрипт запускаете на несколько GPU и связываете их барьерным синхронизация барьерные синхронизации могут быть разные на разных фреймворка но глобально вот когда пользователь думает о том что пайтор чу учится распределён он представляет себе в уме эти четыре строчки Посчитай Model Forward Посчитай loss Out то backward и на Out то backward у нас происходит усреднение градиентов вот уединение градиентов это барьерная синхронизация О чём должен думать пользователь пользователь должен думать как раз вот ровно об этих четырёх строчках какие у него Данные на вход модели какая у него модель какой метод оптимизации а помимо этого он должен писать какие-то артефакты модели в свой сто стриминг прогнозов Сохранение снапшота и так далее и ему нужно с него нужно максимально снять когнитивную нагрузку например по сохранению но сохранить состояние должна быть одна вообще на всю программу То есть пользователь просто нажимает в какой-то момент кнопку сохранить состояние и думает больше ни о ЧМ мы должны за него подумать о производительности о том чтобы у нас была передача владения объектов из питона в на запись чтобы нело жил и так далее давайте рассмотрим пример что это вообще такое хороший пример библиотеки для работы с и это когда пользователь Пользуясь вашим фреймворков за него всегда решает фреймворк любые оптимизации производительности настройки потребления ресурсов всё это должно делаться под капотом с хорошими дефолтным параметрами пример I htp Наверное всем вам знаком Вот в этих двух строчках пользователь говорит Я хочу переложить три батика из точки А из моей программки в точки Б какой-то Сервис который я се поднял на локалхост за него там под капотом на самом деле делается огромное количество действий которых он не видит люди написали на чистом но он этого не знает что он пользуется интерфейсом там мультиплексе в настраиваются и так далее вот мы будем целиться примерно в такие же свойства чтобы мы все вот эти оптимизации Ну не вот эти а те которые я скажу делали за пользователя начнём мы с рассмотрения sle process пурини виде самом деле видна уже в том как мы работаем в однопроцентное барьер синхронизация так вот большая часть оптимизации видны уже когда мы работаем с одним процессом а там нам просто потребуется правильно расставить барьеры и сказать как не доло поэтому большую часть мы проведём в sle process для нача мы построим пример кода на котором мы будем работать сст м че кгые скобки ЕС мы делаем ЕС Нет мы можем делать и я ту к сожалению не успел Уже довид конечно тоже по делаем мы ИТ что мы хотим дальше делать вот мы например в ре какую-то таблицу чтобы потом проанализировать и с кем-то поджо нам это нужно потому что у нас в рекомендательных системах везде идёт онлайн обучение Когда у вас каждый час логов новая модель и так просто удобнее обучаться Когда вы прямо в обучении можете текущий модель на текущих весах записать все прогнозы загрузить потом добу опять заст прогнозы и так далее Окей вот здесь это кстати пример уже хорошего интерфейса то есть мы говорим что у нас есть некоторый йте мы говорим что мы хотим записать и всё больше ни о чём не думаем мы позже поговорим о том что вот эта операция сама действие должна быть производительной то есть не должно быть Никаких блокировок никаких ожиданий мкх и так далее но об этом после Ну оберн это всё функцию я просто потом буду использовать эти обозначения Но вот эти пять строчек у нас об такую функцию значит дальше чего Нам нужен собственно итератор по этим самым Чам и здесь когда вы работаете с какими-то кастомными ридерами из вашего сторе как правило это какие-то Клиенты у которых куча разных настроек и Чем более нагруженные у вас сценарии а рекомендательные системы очень требовательны к пото что это табличные данные и там как правило очень толстые датасеты они довольно требовательны к тому как вы настроите себе чтение данных чтобы у вас всегда когда модель хочет обработать следующий бач Он уже был готов нужно будет настраивать кучу параметров смыс которых он не всегда понимает тут может быть какой-то размер внутреннего буфера Хорошо если он в гигабайтах или там вообще в байтах а не в штуках Например если там Говори размер оче едино чтения у тебя там 10 единиц А эти единицы могут от модели к Модели варьироваться там от мегабайта до гигабайта настраивать такие вещи не самая приятная не самая приятная самый прит количество тдо какой-нибудь е проко дажи неко способов общения с вашим Режем и из них эффективно работае только один и так далее мы должны избавить пользователя от всего вот этого А я это уже поговорил дальше мы говорили про prediction в который мы засовываю прогнозы мы его тоже должны как-то создать и у него опять же если он должен эффективно работать не тормозить вам обучение у него тоже будет наверняка какой-то внутренний буфер в который вы будете складывать данные на отгрузку Вам нужно будет настраивать лимиты на память лимиты на количество соединений лимиты на параллелизм в которых он обрабатывает данные в которых он отсылает сто и так далее люди этого как правило делать не умеют это умеют делать там единицы а нужно чтобы пользователь который работает с распределённой обучалка и мог легко создать какой-то свой примитив записи записать какой-нибудь Файлик и у него из коробки всегда всё эффективно работал значит Ну вот здесь я привёл пример того Во что может функция Если мы просто распи эти аргументы в её сигнатуру Понятное дело что Т можно распи по структурам но глобально это ничего не изменит всё равно параметры в этих же структурах точно также надо будет больно настраивать Вот и третья проблема которую мы сейчас посмотрим как я вам сказал у нас может быть про ива могут чередом одних таблиц или файлов на запись других И если мы создаём по каждому клиенту на запись каждой единицы он как правило лоцируется свои ресурсы То есть как стандартно люди пишут код мы создаём объекти входим в контекстный менеджер он внутри себя ше абстракции А вы допустим написали сначала for Train Table там процесс только TR Да как Какие бы вы классные интерфейсы с точки зрения программы не сделали но когда вы создаёте новый Райтер он может нало столько ресурсов что вы вылете за лимита по памяти или за лимита по CPU И вам придётся вручную перебан сирова то что вы до этого уже настраивали это очень плохо это как раз нарушение абстракции в том смысле что у вас каждый созданный клиент на запись чего-то влияет на все остальные это нехорошо А и первая мысль до которой мы дошли чтобы нам удобно было работать с записью Чего угодно в ч это это я уже поговорил это чтобы у нас были везде единые пулы ресурсов и у нас была везде единая фабрика с понятными единицами измерения а пользователь в начале своего скрипта создаёт у такую фабрику И в этой фабрике должны быть параметры в понятных ему единицах если он запустил свой скрипт обучения на какой-то виртуалке или где-то в Облаке он как правило Ну если не знает то легко может посмотреть сколько ресурсов у него на хасте и каких сколько у него памяти на GPU сколько CPU памяти сколько у него CP ядер и так далее Вот в этих же единицах он должен один раз подумать в начале своей программы сколько он готов выделить на вашу библиотеку вообще суммарно а дальше А вот видите здесь Мы создали один dat о prediction дальше мы создаём второй dat loer второй prediction Writer и они работают под общими лимитами на CPU и на память они за них не выбиваются и поэтому мы можем сколько угодно их на создавать как угодно друг с другом комбинировать Мы никогда не встретимся с проблемой переа кация ресурсов Что у нас там Out of memory и так далее Окей А ресурс извиняюсь понят опять я это проговорил дальше пойдём про собственно процесс сохранения состояния мы с вами сейчас говорили о том что мы когда-то куда-то что-то пишем Но как правило нам ещё нужна в какой-то момент кнопочка сохранить Я записал всё что я хочу до определённого момента времени всё отщёлкивается и У пользователя Это должно быть очень простым действием он должен думать только о том что вот я записал переложил все байты которые я хотел Куда нужно нажал кнопочку больше ничего как вообще выглядит Вот такая кнопочка сохранения данных Обычно люди пишут какой-то код ин капсулит в какие-то объекты эти объекты умеют там не знаю имеют какие методы мы их долж где-то запомнить и в конечном итоге сохранить здесь на самом деле уже возникает несколько проблем первая проблема связана с тем что пользователю нужно будет помнить про все эти объекты раз пользователю нужно будет очень аккуратно делать код завершения обработки ошибок и в случае если у вас нет атомарность про атомарность мы потом говорим она должна быть но ему ещё нужно будет следить за обработкой ошибок в процессе сохранения того или иного примитива и мы постараемся с него вот всю вот эту нагрузку снять чтобы он об этом не думал Ну первое что мы скажем это про то что пользователю нужно помнить про все объекты поскольку мы уже сделали фабрику эта проблема на самом деле в каком-то степени уже решена как правило если вы как правило у вас на старте обучения есть какие-то объекты которые живут постоянно вы их Вы опять же один раз про них подумали в начале работы программы засунули в вашу фабрику Она всегда про них помнит А если вы в процессе работы создаёте дополнительные примитивы записи то опять же за счёт того что у вас есть единая точка входа которая помнит по все примитивы Она Вам их сразу запомнит И эту когнитивную нагрузку мы с пользователя снимаем пользователю не нужно больше когда он создат вручную там записать его в какой-то там словарь Ну ладно это довольно простые идеи дальше уже следует менее очевидная идея которая связана вообще со спецификой того как люди работают со стом в обучении А когда пользователь что-то пишет в своей обучалки нейросетей он как правило хочет потом это прочитать только в конце обучения когда он записал обработав весь датасет а в середине обучения ему это читать не нужно Ну понятное дело ему это нужно иногда читать в начале обучения если он упал посередине хочет восстановиться из снапшота Но вот посередине когда он в процессе обработки модели ему этого делать не нужно отсюда на самом деле следует не очевидная оптимизация что во-первых интерфейсные изменение что пользователю не нужна ручная кнопка завершения записи на запись каждого там конкретного файла таблицы и так далее код написанный в таком стиле что мы сначала из модели что-то пишем в Stage сохраняем потом тут же в этой же обучалки что-то читаем он как правило довольно странный пользователь они либо хранят какие-то статистики агрегированные in Memory либо Просто если это небольшие данные сохраняют их у себя в памяти и анализируют они не засыпку завершения записи конкретного файла или таблицы Аа что из этого следует из этого следует на самом деле что а вот тот код с тред пулом на эффективное распараллеливание завершение записи каждого файла или таблицы Мы можем взять на себя фреймворк сам эффективно всё всегда распараллелить Какие бы писатели или читатели не создал пользователь это очень удобное свойство Это позволяет ему опять же не думать о том что он там на создавал слишком много объектов как мне их потом распараллелить сохранение как если они там ещё фреймворк может взять на вас заботу о том что если два примитива допустим пишут в одну и ту же папку Чтобы у них не было конфликта при создании этой папки но это уже правда специфика того как у нас устроена работа с нашей распределённой файловой системой но тем не менее эффективное расправа обработка ошибок и возможных конфликтов на запись между этими Прити ВС это можно просто отобрав У пользователя кнопку ш которая ему не нужна давайте поедем дальше Вот мы здесь создали кнопочку necessary то есть мы пришли к тому интерфейсу который я вам обещал что пользователь говорит хочу закоммитить состояние всей системы и все примитивы которые мы создавали этой фабрикой Create что-то там Мы здесь завершили но сейчас это действие блокирующее пользователь написал там сколько-то данных во время мы е там можем Вот в эти объекты которые мы раньше запоминали Допустим мы хотим сохранить модель в этот момент мы реализуем модель ждём пока она отгрузить ждём пока нам приедет респонс от нашего замечательного сто что всё классно Мы молодцы Мы записали ваши данные А нужно ли нам это ждать если мы как пользователь внутри своей программы не собираемся эти данные сразу читать ответ на самом дем на самом деле вообще комит всей системы можно делать почти полностью асинхронно с минимумом простой GPU Давайте посмотрим вот на такой пример Мы хотим сохранить тою модель вот здесь пять строчек кода Значит мы создам какой-то буфер делаем точ про рие интерфейсы Я поговорю отдельно пока что вот мы делаем полную копию данных я потом скажу почему конкретно в этом случае так лучше Вот делаем он нам сразу сохранил полную копию данных в буфере сериализовать Writer то Write от нашего буфера и котек comit а внутри мы Блокирую ещё ждём финиш а пользователя на самом деле не волнует Когда закончится этот финиш пользователя Единственное что волнует что чтобы у него не было гонок между кодом который делает tch Save это его объект пользовательский модель и кодом которым он обрабатывает Бачи то есть на самом деле А код который бы повлиял на обучение если бы мы пытались сохранять модель параллельно с обучением это единственная строчка tch ВС остальное мы должны уметь делать асинхронно и время сохранения в таком случае запись в у нас будет всегда в потоках параллельно обучению и время сохранения снапшота будет равно времени блокирующей работы с пользовательскими объектами то есть времени вызова tch А это время как правило на порядке меньше чем время передачи данных по сети и тем более ожи записи на диск конкретных на диск тех данных которых вы записали диски вообще очень медленны и сразу Давайте скажу про стриминг обычно принято чтобы не потреблять много памяти какие-то жирные объекты сохранять римо мы создаём какой-то итератор и руся по ием в какую-то оче вот похо поле вот чтобы реализовать эту идею вам стрий интерфейс как раз не нужен он ей противоречит потому что пока у вас живёт итератор который потихонечку сохраняет ваш объект вы блокируется этот объект и вы не можете продолжать обучение обычно на хостах с GPU достаточно много оперативной памяти и как правило можно себе позволить делать Вот такие полные копии всех ваших объектов сериализовать сразу в байты а потом асинхронно уже куда-то отсылать и не думать время сохранения состояния системы время сериализации польских обк бай это я уже поговорил чит про Тома Ну тут думаю наверно не надо сильно углубляться что если пользователю надо будет самому реть Диф от того что у него там какой файл записался какой не записался вся магия сломается как бы это очень плохо и поэтому кнопка должна быть атомарной все файлы табли которые вы созда долж быть сох сохран никто без этого свойства ничего не заработает последнее чего мы коснётся это производительности передачи данных на запись вам недостаточно уметь эффективно в бэкграунд там потоках особенно плюсовых которые не блочат жил грузить ваши данные вам ещё важно уметь из питона эффективно их передавать Потому что если вы их переда Прямо во время обработки баче неэффективно написать Вас могут быть копирования изн объектов в плюсовые объекты Почему Потому что н объекты создаются локатором они должны быть уничтожены питона локатором они должны быть уничтожены Когда вы держите л из-за этого как правило если вы хотите передать данные допустим в плюсовую библиотеку делаются копирование вот этих копировании лучше избегать вообще вообще Т конечно же напутал порядок рассказа Ладно неважно короче есть три способа решения этой проблемы Первое это грузить вот когда вы делаете Table вы передаёте данные в какую-то очередь и вы можете их грузить тремя способами через н многопоточность через н вам нужно же данные из этой байтовой строки засунуть в сот Вот это всё делается под жил если у вас нагруженная запись у вас опять-таки это всё будет перенимать на себя блокировку питона той же самой проблемой страдает Python multiprocessing Если вы допустим хотите грузить в подпроцесс у вас ваши байтовые строки всё равно должны как-то в этом подпроцесс оказаться там их можно передать по сокету в подпроцесс чтобы он дальше стримил в Stage но эта проблема эта проблема на самом деле не решает количество данных кото вам нужно передать будет такое же можно пробовать писать в буф сразу но во-первых это неудобно то есть ваша у вас должна быть не Батова строка у вас должен быть какой-то Объект который уже записан в этот буфер во-вторых у вас на самом деле получается уже такая локальная распределённая система потому что у вас буфер порен между процессами вам нужно как-то оркестри общую с ним работу Это достаточно неприятный процесс щая Иво кото ль времена бы данных было написано shed Memory Я честно скажу этот код сложнее чем написать его на плюсах с хорошими бинга вот реально он реально сложнее его сложнее дебажить тестировать И поддерживать Если вы пишете код на плюсах единственный момент который Вам нужно решить - Это передача владения из питона объектов Плюсы это можно сделать я сейчас не буду на этом останавливаться пото что если честно мне времени не хватит на технический рассказ если кому интересно я могу можете подойти Я могу вам показать код там библиотечка буквально на 200 код на плюсах и сот на питоне как вот это можно аккуратно сделать чтобы там ничего не селло и передавалось владение Окей значит промежуточный итог у нас Какой Вот мы собрали воедино всё что мы делали и мы сохранили свойства для пользователя что он в каждый момент времени думает только о том что он хочет сделать не думает о том как он хочет это дела в нача своего скрипта где-то там совсем начале подумал о ресурсах больше о них не вспоминает тогда же он запомнил какие-то объекти которые он хочет сохранять и больше о них не вспоминает всегда про них помнит А когда он создаёт любые примитивы на Table Right или dat он может создавать их сколько ему влезет они не должны вылезать за те ресурсы которые он создал А и когда он хочет сохранить состояние он нажимает Одну кнопку и больше ни о чём не думает и эта кнопка очень быстрая и дешёвая потому что время её работы равно времени сериализации пользовательских объектов в байтовые строки и мы её можем дёргать очень часто таким образом а эффективно защищаясь от каких-то вытеснении или рестартов То есть если вас вытеснили Вы можете А вы можете сохранять снапшота в час или в 2 часа а раз допустим в 10 минут и если у вас проблема с нагруженность на кластере Когда у вас там часто приходят и уходят задачи вы будете терять меньше работы и ваш GPU будет тоже в некотором смысле эффективнее утилизировать Окей давайте теперь поговорим про распределённый сценарий в определённом сценарии на самом деле тут будет не так много потому что основные идеи по оптимизации Я уже проговорил А в определённом сценарии Нам нужно будет просто эффективно это связать барьерами первое про что я хочу сказать это про лимиты ресурсов значит как правило распределённое обучение строится Так у вас запускается по скрипту на каждую юшку но этики сидят на одном хасте и этот же Кост имеет одну общую на все эти воркеры память цпу и так далее но когда вы запускаете вот пишите код у себя в программки вы создаёте ресурсы как если бы вы эксклюзивно ими владели То есть у вас каждый скрипт говорит Я хочу себе Свои Свои лимиты на 200 Гб памяти свои 20 потоков Если у вас на Хосте 8 GPU это получится уже 1 ТБ оператива и 150 потоков это не то чего хотел пользователь А поэтому здесь важно сделать Поша лимиты а то есть чтобы у вас был какой-то небольшой сервис который оркестри ет все эти очереди когда пользователь хочет что-то передать на запись Он не внутри дёргает какой-то мюк типа есть у тебя данные локально в процессе или нет а он стреляет запросом в какой-то сервис который поднят на локал Хосте и который знает про каждый из воркеров и он уже видит общее потребление памяти каждым кером И говорит ему Арова или нет ещ это очень важно потому что как правило нагрузка на запись между ними не сбалансировано Например если вы если у вас модель Ой простите если у вас модель не порро и храниться по каждой копии на каждом ворке вы обычно хотите просто на одном ворке сохранить эту модель и не париться с тем чтобы её как-нибудь там нарезать на чанке каждый чанк писать с каждого воркера и из этого следует что у вас на gpu0 допустим будет использоваться 50 ГБ оперативы допустим на запись этой модели А на остальных GPU не будет использоваться Вот пошарить вот этот вот сервис на Local Хосте с общими лимитами памяти он ещё и служит для того чтобы пользователь не думал о ручной балансировке нагрузки между воркера на записи это тоже важное свойство так дальше поговорим про барьеры значит я пробовал пользоваться тоже distrib барьерами И это всё классно до тех пор пока у вас не появляются какие-нибудь замечательные ивки которые не консистентной в одном кере и Condition в другом fse в одном вы войдёте в барьер под ифом в другом войдёте вне его функция Con в gpu0 не обязательно упадёт там бывают разные ситуации То есть никто не гарантирует что этот код сразу же грох неся на gpu0 и мы сразу узнаем об ошибке а barer последний Он вообще задело Ну или не залочить за таймаут но тем не менее мы просто в какой-то момент Увидим что у нас где-то произошёл рассинхрон Где на самом деле непонятно потому что он может реально реальный дедлок может произойти вообще не там где была причина проблемы как раз вот из-за того что необязательно код который под этими Ифа не консистентность упадёт он может просто насчитать фигню но отработать Вот и поэтому мы себе сделали такую вещь как ключи в барьерах значит когда Вы заходите в барьер вы пишете строчку эта строчка грубо говоря идентифицирует Ну номер строки в программе но номер строки в программе мы побоялись автоматику делать потому что там надо мараться с инспектором с определением строки непонятно быстро будет работать и так далее В принципе человек запишет в меняю строчку и можно будет точно также найти в вашем репозитории просто поиска по вашему Ну просто по гре ваш репозитории на эту строчку И точно также найти где у вас упало если у вас барьеры входят с разными ключами то у вас всё тут же отваливается ровно в тот момент когда у вас произошёл асинхрон и он пишет какой воркер на какой строчке с Каким ключом отвалился это вам помогает сразу обнаруживать ошибки которые шли ровно в тот момент когда они произошли не когда-нибудь там потом Когда ваша программа таки соизволил где-то упасть а именно вот в этот момент и в целом эта штука нам значительно упростила отладку то есть прям тестировать дебажить значительно Проще сразу видишь где Что падает и сразу понимаешь где-то Там какой ивчик или какой цикл некон систентки длины сделал последнее про что мы поговорим это про сохранение состояния значит а глобально сохранение состояния распределённой системы Тут есть тут много вещей есть короче во-первых сохранение состояния должно быть барьером потому что у вас Каждый воркер должен финализировать то что он записал у себя локально и сказать Всё мы всю систему отлк она дошла до какой-то общей точки Поехали дальше второй момент что у вас должен быть одинаковый порядок обхода тех примитивов Конте зас Потому что если вы ВХ моде аго оптимизатор онива попытаются снта по барьером или что-то ещ сделать это будет тоже нехорошо У пользователя должна быть гарантия что фво ему все примитивы которые создаёт он будет обходить в одинаковом порядке он не должен об этом заботиться он должен заботиться только о том что мы момент это ЛВ конфликтов на запись Между керами но с резом конфликтов мы на самом деле уже разбирались когда мы говорили sle process сценарием когда мы параллельно сохраняем какие-то объекты допустим разные таблицы которые лежат в одной и той же папки мы занимаемся тем же самым резом конфликтов поэтому на самом деле здесь этот код как правило Ничем не отличается просто вместо того чтобы локально у себя в программе фреймворк посмотрел чтобы у вас не было конфликтов на запись Он соберёт со всех по барьерам со всех воркеров кто кто куда что пишет И там сделает правильные блокировки то есть в этом смысле сложность написания сложность масштабирования вот этого Factory котек с одного процесса на распределён ную систему а не такая большая как проделывания шагов для Single process вот всех этих оптимизаций с А синхрони первые шаги Они самые сложные Ну наверное всё теку Дава с договаривай текущим итогом Ну текущим итогом стало то что пользователь может сохранять свою распределенную систему когда хочет это будет очень дешёвое действие которое он может часто вызывать не блокирующая которая не держит Лок на его GPU и в случае когда у вас мало ресурсов задачи часто вытесняются вы можете себе позволить терять меньше наработанных вычислений ние задачи становится гораздо более дешёвой операцией Ну и из этого неявно следует что и перезапуск задачи должен быть дешёвой операцие но это как правило уже ответственность облака а не пользователя Спасибо большое Лёш очень интересный доклад переходите пожалуйста вот по QR коду для его оценки в желательно в моменте чтобы потом всё сразу не навалилось А сейчас мы наверное готовы перейти к вопросам ответам да поехали вот пожалуйста Алло так Лёш Привет Спасибо за доклад очень насыщенный э Дима и звук если что вопрос вопроса два на самом деле первый вот по-моему он даже был отвечено если так то прошу прощения по-моему даже на двадцать первом слайде вот мы создаём instance Factory Contex Если вдруг мы случайно Или специально второй создаём как они Они же знают прави второй раз ресурс не лоцируются то есть как они вообще друг о друге узнают Это первый вопрос Ну на самом деле тут можно по-разному сделать можно сделать так чтобы они шалили ресурсы можно сделать так чтобы у них были свои ресурсы там бывают разные кейсы у меня был кейс когда пользователю нужно было ДК Я если честно даже не помню зачем но второй ему нужен был с каким-то ат минисо кижа в том-то вот вопрос что если их будет Допустим два или больше если первый сожрал все ресурсы то втором просто некуда будет уже негде развернуться Не ну он должен знать о том что есть первые Вот как это происходит проходит можно сделать э там не знаю создание каких-то объектов которые держат ресурсы и просто передать их в Конструктор каждого Фактори контекста они тогда будут их шарить в этом особой проблемы нет проблема тут скорее в том что если создаёшь несколько Фактори контекстов независимых исчезает свойство того что ты нажимаешь Одну кнопку на сохранение всей системы потому что они независимы Не ну допустим каждый контекст создан Под свою какую-то систему и то есть в рамках этой системы это всё работает по одной кнопке но они под разные туда предназначены Ну ладно В целом я концепцию понял Спасибо И второй вопрос я правильно понимаю что вся эта красота сейчас работает только внутри Яндекса и Если да то планируется когда-нибудь опенсорс или нет её можно было бы за опенсорс потому что она зависит По факту только от Иса То есть у нас в Яндексе - это общая инфраструктурная система И на самом деле когда мы пишем обучалки мы пришли к тому что мы должны максимально работать вот ровно с ней и внутри обучения не трогать ничего больше потому что там есть общие транзакции вот эти файловые системы там эффективное чтение запись этот код можно было бы за осор Сить но все реализации завязаны на OS то есть в реализациях как раз то самое мясо про оптимизацию скорости передачи данных и так далее интерфейсы которые я здесь Рассказывал Ну можно за осор Сить Но типа всю реализацию под новый сторедж нужно будет писать заново то есть не знаю насколько полезное действие будет Вроде же Open Open что по идее про просто Open Source это большие трудозатраты и не очень понятно насколько эта штука будет сейчас нужна вот нам она очень нужна в рекламе в ещё нескольких командах на которые мы распространяем сейчас постепенно А вот за пределами Яндекса Пока непонятно Стоит ли тратить сейчас усилия на такое действи вот в центре за вопрос пожалуйста ещё я пытаюсь как-то осознать с точки зрения применимости вот можно чуть-чуть подробнее пояснить это вытеснение параллельной работы между людьми с пушек или же это в рамках одного запуска или Какая задача решается А как работает запуск у нас задач нашем 30 команд каждый из них хочет использовать общий кластер ГПУ они все хотят решать проблема быстрого избежание при Лем запуске там пробле ре конфликта всю классику ipc Да что решается решается Когда вы запускаете задачу в Облаке вас в любой вы ну вы во-первых можете как я сказал писать в сто должно быть эффективно Об этом я уже сказал Вас могут в любой момент вытеснить вытеснить это значит прибить вашу задачу прибить вашу задачу могут по самым разным причинам не обязательно это какие-то проблемы с хостом проблемы с хостом на самом деле бывают Сам вытеснение часто бывает когда приходит какой-нибудь Яндекс gpt и говорит мне нужно запустить задачи на вот таком шмоте облако чтобы у него все Хосты были рядом д другом расположены у него были эффективные синхронизации поэтому все задачи которые здесь работали они идут нафиг и запускаются где-то там на других тачках и воо вче нужно ча сохранять состояние и делать это не раз там в 3 часа потому что три потерянных GPU часа или даже умножить на 8 потому что на Хосте шек а вытесняется сразу во штук не одна аво Вот это довольно дорого вот решается задача того чтобы пользователь мог чтобы мы а эффективнее утилизировали GPU в Яндексе в частности для себя в рекламе и могли удобно разрабатывать Вот тако код чтобы у нас всегда когда мы пишем какие-то дополнительные наши штучки для которые работают с файлами или с таблицами у нас не просаживается утилизация GPU чтобы это мог сделать Любой человек который не умеет писать код на плюсах который не даже может особо не знать как там все вот эти нюансы работы с многопоточность в питоне работают чтобы любой ресечер который знает только про модель и про данные на которых он обучается мог делать эффективные инфраструктурные действия Вот такая задача реша Окей спасибо второй вопрос тогда бекова реализация То есть все этой синхронизации насколько она интегрирована рчо и собственно говоря вот тот самый сиш код магический Да который там решает вопросы так сказать айпи сишка внизу а как бы в двух словах если можно что это Потому что так в лоб нун ребята я возьму редис напишу там ну хорошо не 100 300 строк сделаю внешнюю сию через него да И при этом я сохраню все возможности работы как как бы по дефолту в рамках торча нуно хорошо а барьеры мы написали свою небольшую библиотечку типа там не сильно много работы свою библиотечку мы написали просто чтобы иметь возможность удобно интегрироваться в любые обучалки потому что обучалки бывают на самом деле не только торчок она используется и в некоторых нзф обучалка у нас компании и она Framework агностик интеграция с фреймворка глубокого обучения там делается через библиотеку Dail Pack Dail Pack - это такая Либа написа на чистом си то есть там китайцы пришли договорились с каждым держателем крупного фреймворка давайте вы себе вте Вот такие методы и мы вам дадим сошку чтобы Вы могли из любого фреймворка из любого нзра одного фреймворка переть данные в другой вот таким образом у нас делается интеграция счм То есть она делается не конкретно счм а именно ском А по транзитивности со всеми осталь ВТО вопро так далее тут тут можно сделать по-разному Вот именно вот этот вот механизм как в бэкграунд грузить данные мы пошли тем путём что у нас просто нес это по синхрон как раз как бы про интеграцию Понятно транзитом через кого-то делаете про передачу владения из питона да то есть как бы вот глобальная там идея такая когда люди пишут какие-то питом библиотеки Особенно если это какие-то там не знаю парчи они пишут плюсовые биндинг они рассчитывают на то что объект арованы в питоне уничтожит тоже в питоне это первая проблема вторая проблема что когда вы хотите передать владение питон объектам допустим вот у вас есть питон поток Да вы засовывается из этой байтовой строки по бидин читать в плюсом потоке Да вот если вы хотите в этом c+ потоке удалить объект Вам нужно будет взять Вот вти ПМ потоке в некоторых версиях вообще а в некоторых оно падает в 37 оно по-моему потому что на самом деле не просто Это куда более сложная штука поэтому мы пошли таким путём У нас есть один единый Т запущенный в питоне там крутится функция в которой есть какой-то Вектор объекта и мы Если хотим передать данные владением из любого обп деструктор передаём его вместе с этим объектом с этим хенд в примитив которым мы пишем и когда Мы закончили писать деструктор этого объекта возвращает его в питон обратно чтобы он уничтожил тоже в питон потоке и тогда как бы люди не писали код они сохранится Вот это свойство того что то что мы создали в питоне уничтожит тоже в питоне и объекты любой библиотеки мы можем так вот передать владение на Псой код и он корректно ужи будут там были интересные приколы с тем что происходит на завершении интерпретатора Вот то есть там весело живёте честно скажу весело что не Ну я так понимаю что это не от хорошей жизни Видимо да это не от хорошей жизни У нас уже была предыдущая реализация нашего фреймворка для обучения не росе ток в рекламе но мы упёрлись в его возможности масштабирования Вот Ну вообще интересно было посмотреть на код если было выложено куда-нибудь а Но я могу показать часть его потому что там ничего сильно проприетарное с питоном я могу показать там ти неско па соте бук скорее вло конструкцию коллеги я вас рву Извините а то Это уже превращается больше в Диалог да у нас есть ещё вопросы в зале мы тогда можем как раз передвинуть в дискуссионную зону но перед этим вопрос и вручить подарок от нашего партнёра Газпромнефть Давайте про владение с питоном потому что я долго с этим долбан Это очень важный вопрос чтобы GPU нормально утилизировали и он непростой Лёш ну для тебя у нас тоже есть подарок спасибо тебе большое за твой доклад приходи ещё развивайте свои продукты Успехов тебе"
}