{
  "video_id": "KAH4_9PVggU",
  "channel": "HighLoadChannel",
  "title": "Как мы готовим MySQL / Николай Королёв (Badoo)",
  "views": 3210,
  "duration": 3087,
  "published": "2017-04-22T14:48:24-07:00",
  "text": "я работаю над компанией буду лишнего непонятном с кэлен а точнее о том как мы его используем пару слов о том что такое баду году итак крупнейшая социальная сеть знакомств в данный момент насчитывает более 320 миллионов зарегистрированных пользователей ежедневно мы обслуживаем более 12 миллионов и ежемесячно более 32 для того чтобы эти пользователей чувствовали себя в тепле и комфорте у нас есть пкф тысяч серверов чуть подробнее нашей инфраструктуре как видно из этого слайда достаточно большой процент инсталляций занимает у нас москве если говорить абсолютных числах это пекка 600 65 машин и поэтому я хотел бы сегодня рассказать в следующих моментах я расскажу о том как мы храним пользовательские данные как мы выбирали стратегию масштабирования и детали реализации затем я расскажу вам как мы делали свою репликацию и моменты которые вас при этом получились потом перейдем к изменение структуры схему данных и распределение нагрузки по себе в конце я расскажу как он все это дело богатов сегодня было сказать вам только в одном кластере пользовательских данных вот несколько цифра кластер насчет их порядка 300 10 серверов на которых хранится 370 терабайт данных которые свою очередь распределены почти 4 миллиона таблиц пиковый кпс на северах на классике достигает в пике трафика порядка 1000 миллиона 900000 и так что требуется от его в компании баров в первую очередь а что вы были базовые стабильно работали чтобы время запросам всех устраивал и чтобы данные пользователи были сохранных доступно и так пользователь еще лучше активный пользователь а еще лучше активный пользователь с платными подписками серьезно а пользователю займу дабл она выглядит примерно так это набор таблиц зрелых с пользовательскими данными чтобы получаем начале проекта проект растет количество пользователь увеличивается в какой-то момент ресурсы сервера на котором живут эти пользователи кончается встает вопрос что делать масштабе нужно как-то масштабировать варианты масштабирования посмотрим первый вариант марте церовани и или секционирование это масштабирование в пределах одного сервера второй момент и тарификация позволяет масштабировать хорошо чтение но не позволяет масштабировать записи и третий вариант этаж армирование шарнир хорошо позволяет может и берем 4 записи по факту представляет собой разбиение таблиц на части шарды которые физически хранятся на различных серверах совместно вы выбрали эту схему потому что как он и более гибкое воинству настраивал формирование мы делаем по ключу easy ради вот так примерно выглядит армирование вот так таблица рвётся на части каждый в частей является шар дам а вот так выглядит spot под ваши внутренние базовое понятие которое объединяет понятие шар ты понятия пользователя тоже говори раньше из определение the spot a spade это набор шарниров таблицы связанных с пользовательскими данными оставить запомнится понятие поможет маслом я буду оперировать дальнейшем им и так мы придумали схему шар де равале распределили шарды спад и поселян расположили там пользователей код знает юзера иди как ему узнать в каком спорте живет пользователь нужен какой-то сервис классическая схема что можно использовать этот сервис weather data bass или и деби что такое у нас этакий very стоишь в котором хранится юзеры из-под они соответственно у нас он построен так же на войск гель плагинов шашлык который позволяет нам использовать достаточно высокий фпс получать высокий фпс порядка 50 тысяч пики и при этом уметь чувствовать на низкий низкое время ответа порядка пяти миллисекунд и так вот приходит в базовых и тебе запрашивает по визе райден получает ответ спутаете отлично мы узнали где живет пользователь к вам спать и что делать дальше нужна какая-то карта который у нас располагается в коде в котором есть соответствии с по тайге сервера иди индекс базы индекс таблица оригинал этой карты хранится в базе в коде хранится его копия в коде на хранится по простой причине потому что читать из файла гораздо дешевле чем ходить каждая с базу и так что у нас получилось мы реализовали схема формирования данных создали доставить в решении кластер названный дпс сделали сервис и видели и карту спотов отлично проект начал расти 2006 году году располагался в дата-центре в европе и счастливо жил рост rolls через какое-то время разрыв пользователь появились всего мира и 2008 году достаточно большой процент пользователей составляли пользователей с америки северной и южной америки так как эти континенты достаточно удалены от европы пользователь на на этих континентах в принципе испытывали проблемы с временем ответа нашего приложения чтобы решить эту проблему мы решили поднять но это центр в америке в сша и снега пользователей по принципе гео-локации которые жили эти континентах пользователь стало все хорошо но у нас появилась другая проблема запроса между площадками внутренние как я рассказала время запросов от этой между площадками между континент мыслишь небольшой составлять порядка 100 200 миллисекунд сейчас и время когда как базе занимает порядка 6 милисекунд 60 секунд это достаточно большое время для коннекта и ответа и поэтому у нас возникли проблемы когда вы резника лес запроса между площадками проблема эти можно разбить на две части внешне это когда кто-то пользователь например или поисковый под запрос информации с удаленной площадке если это пользователи он запрашивает профиль удаленного пользователя у пользователя с такой площадки ждет какое-то время не дожидается ответа загрузки профиля закрывает приложение уходит страдает use экспириенс и псы это поисковый бог то опять таки же какое-то время отваливается по таймауту индексация прекращается это внешняя часть проблемы внутренняя часть проблемы это скрипты которые работают с пользовательскими данными так как они работать со всеми пользователями то очевидно после разноса пользователи по двум площадкам время обхода всех пользователей стал составлять непривычно большое время чтобы решить эту проблему возникла идея создать копию данных много на площадке так как все описанные кейсы касаются только сущее чтение данных отлично идея возникла решились 1 для нее требования то есть как реализовать ее требования для этого решения это только что нужно только до чтения в тот момент когда это решение было принималось нам нужны были только часть данных из под они все данные и учитывая это а также то что количество запросов на чтение на удаленном площадке будет гораздо меньше чем оригинальный другой подразумевался другой профиль нагрузки а именно больше записи меньше чтениях учитывает а мы захотели рисовать схему репликации много коды wpgh-1 решили посмотреть на существующие готовые решения напоминаю это что в 2008 год москве только выкатил версию 51 так что предлагал нам москве открыт в тот момент работала только в один поток и позволяла схему резва схему только репликации один к одному очевидно что это решение у вас не устраивало и мы решили делать своем и так пелин велосипед своя репликация на печке а логически наша схема репликации можно разбить на три части первая часть это логирование запросов вторая часть это доставка запросов на удаленном площадку и третья часть это проигрывание полученных запросов и так поподробнее про каждому пункту логирование как она выглядит мы пишем у вас есть код который пишет выполняется дыма или запросы в этой же транзакция он выполняет запись выполненного запроса в служебную таблицу записывай туда тема запроса спорта и gif который запрос был выполнен и время в которой запас бы вы по ним таймс темп доставка 1 несколько секунд на севере запускается скрипт который выгребает записи заказ уже на таблицу разбивает их по сервер назначение потеряем назначения и раскладывает их на диск виде слез криль тамбов после этого также другой скрипт сжимает полученные дамбы и отправляет их по ftp на удаленную площадку на сервера репу проигрывание на на себя хлебу запускаются скрипты которые распаковок получил ее дамбы и проигрывают проверяет целевую цену куда они должны идти и проигрывает их через обычный москве клиент стоит сказать зачем мы используем промышленный себя репу очевидно что ресурсы баз данных стоит экономить чтобы ресурсы оставались только базе данных поэтому очевидной используя привычный севера регулы которых проигрывать ребекка ция мы экономим следуй ресурсы и abs и это который тратится в первую очередь на запись и удаление файлов темпов и память файл записался попал файл в кэш это первой части вторая часть это очевидно запись запуск скриптов которые собственно проигрывает эту репликацию и так как выглядит в общем наша схема репликация примерного тогда кластер дпс прессуется в кластер аппликационные кластер названный дпп так из теории закончили давайте перейдем к эксплуатационным части в процессе разработки нашей аппликации у нас появились инструменты для работы с ней 1 струмент который нас появился он позволяет перезалить полностью одно отношение отношение это связь между в которой входит несколько спотов изначально этот инструмент появился для того чтобы запустить нашу репликацию дополнить данными данные надо бы в дальнейшем мы его использовали для того чтобы восстановить данные случае какого-то сбоя результате которого данные надо bbs сталине консистенции второй инструмент который у нас появился это писарев к одной таблицы или нескольких таблиц в отношениях как я уже говорил с подло состоит из пользовательских таблиц изначально мы решили не реплицировать все таблицы для того чтобы в дальнейшем мы могли изменить добавить таблицы в репликацию мы и появился этот инструмент третий момент который в эксплуатации это мониторинг как мы мониторим наши репликацию элементарно мы это делаем проверяя реплика сонный лак у нас есть время выполнения запросов на оригинальном у вас есть время выполнения на его repack славный парень вы читаете два значения мы получаем собственно значение репетиционного алого мониторим мы этот лак записям эксплуатации закончили давайте перейдем к плюсам и минусам итак сначала плохие новости минусы вашего решения это в первую очередь операционный лак который может быть достаточно большим достигать от 10 секунд до минуты 2 минус нашего решения это достаточно сложность его то есть чтобы исправить или выяснить где проблема человек должен хорошо знать как эта система работает то есть мы не можем взять инженер со стороны и завтра же отправить и очень требуется время на подготовку теперь хорошая новость наша схема репликации подразумевает схему много к много изначально говорю это было наших условиях и это позволяет достаточно гибко распределять нагрузку между свои вами и мастерами 2 + который логично вытекает из первого это проигрывание в нескольких поток в несколько потоков что позволяет достаточно быстро примет применять запросы проигрывай на мастерах и 3 плюс это наличие инструментов которые позволяют восстанавливать данные на репетиционный paris ну что 6 при кация закончили перейдем к изменение структуры данных как мы меняем структуру данных в нашем кластер а главные запросы главный del который но в этом случае нужны это crate тайбл alter дай бог или drom.ru но прежде чем я расскажу вам как мы это делаем я хочу рассказать зачем зачем мы в принципе делаем в дверь очевидно что проект растет развивается появляются какие-то новые фичи в процессе реализации которых разработчиков возникают потребности по изменению структуры данных там добавить новое поле изменить тип поля или добавить новую таблицу например очевидно что в спать никаких изменений нет и нужно нужно сюда как-то доставить есть несколько способов например достаточно модно сейчас способ это миграция база данных занимает изменение структуры базы вместе с выкладкой кода так как объем данных достаточно большой нам такой инструмент не подходит потому что миграция будет завершена большое количество времени и сильно нагружать следом второй вариант это например иметь припека сонную пару для каждого сервера в кластере и изменять структуру сначала там после того как структура там быть отменена и своих до гонится код переключается на использование этих серверов она использования этих баз очевидный минус такого решения нам нужно резко увеличить кластер в два раза поэтому мы тоже в не используем соответственно нам нужно изменить структуру таблиц до релиза задача которая позванивает изменение структуры хочу сказать что мы не делаем изменения структура данных которые подразумевают необратимые несовместимость с предыдущей версии то есть новая структура данных должна работать на старом коде и так как выглядит вполне на т.д. разработчик ставит ticket на изменение структуры в котором он пишет тело запроса который должен выполняться ты была проверяет этот запрос на валидность на то что он вырезает нашим требованиям пап собрат по обратной совместимости и после этого труд моя из во всем кластер после чего разработчик может выкатывать which of production из всех этих пунктов и десны технически является как и мы вы поменять рассмотрим поподробнее как именно мы делаем для дрели мы делаем его обычным блокирующий мотор спасибо мой скрипт 56 в котором этот alter стал менее блокирующий почему мы делаем его обычным блокирующего виктором и не использование какую магию тип об этой онлайн с кем очень чили других утилит который позволяет блокировать таблица это маленький размер спад а то есть вот у нас достаточно небольшой размер таблицы в спать и максимально составляет 100 мегабайт среднем не превышает 40 и учитывая все это мы время выполняется по всему класть им занимается среднем 40 минут как именно выполнить сайта у нас в в пик трафика на площадке запускается скрипт который подключается к каждой базе на площадке и выполняет alter согласно картин спотов в это же время на противоположной площадке такой скрипт выполняется альтеры для их репутационной пары так как я уже говорил что у нас из нее структура не позволяет подразумевает обратную совместимость то мы не идем и строгого соответствия что схема должно быть правильно вре мен нас под и на 1-м дпс и на тобаго то есть у вас может быть расхождение в какой то момент времени что не вызывает проблем по результатам выполнения этого скрипта он отправляет письмо завершение в котором он пишет статус успешно не успешно если не успешно то почему и где после чего либо проверяя что alter успешно выполнился и закрываете кит разработчиками и что ticket закрыт и может родить свою задачу хочу сказать что разработчик по факту может решить задачу свою раньше и это их чуть договоренность следующий момент трипле кации проект растет количество растет количество запросов на репликацию растет что делать легкие дтп добавление нового значения в вину мы можем как-то объединить услуги с остальными очевидно нужна какая-то очередь очень надо del выстраиваться у нас вручную съем это было строится по принципу free fan fest in first out порядок ученики может быть нарушен например если какой-то разработчик считает что его задача наиболее приедет он приходит где было мило к разработчику которой стоит на очереди выполнение запросов 1 ребята между собой разбираются те же задачи важнее примерно так и после этого порядок очереди меняется или нет кто сильней а вот так и живем с изменением структуры закончили перейдем к распределению нагрузки пару слов о нашем кластер и количество машин на каждой площадке составляет порядка 100 дпс на самом деле 1-му щеки 120 на другой то железо в кластере не гомогенная потому что север по купаясь в разное время и все до сих пор работают так же количество пользователей активных неактивных на разных сериалах тоже разное а основную нагрузку греют именно активные пользователи что происходит плюс наткнулся мы покупаем север устанавливаем его запускаем английской заполняем его спортом и пустыми открываем регистрацию начинаю появляться пользователю вопрос как как насколько хватит сервером чтобы ответить на этот вопрос мы ввели такое понятие как температура спорта температура спад а это формула которое подразумевает некоторую нагрузку которую создается под на север вычисляется на следующим образом у нас это количество месячных активных пользователей умноженное на коэффициент сервера коэффициент сервера это коэффициент его производительности который колебается от нуля до единицы 0 это бесконечно производительный север то есть там миллионы abs имеет миллиард гигабайт памяти то есть бесконечно ресурса единица это характеристика северов и самые первые поставки на нашем кластере коэффициент зачисляется с помощью бенчмарков прав при первичной закупки серверов купили programme which make узнали в их его к и всем правитель настя как выглядит жизненный цикл по 100 км его поставили спорта начинается дополняться новыми пользователями в какой-то момент температура спорта достигает критического значения после которого стоит его закрыть регистрация на север закрывается spot начинает остывать количество активных пользователей падает через какое-то время количество активных пользователей падает достаточно страшно сильно остыл регистрации открывается заново и так собственно до тех пор пока у нас не кончится место проблема которая возникла через какое-то время помимо того что нас кончается место это расхождение актуальные нагрузки на сервер и нашей расчетной температуры это возникла потому что они активные пользователи хоть и нет не потребляют активно эти ресурсы которые потребляют активы но все же потребляет нам пришлось изменить форму добавив туда всех пользователях спать и и поделив их на 100 то есть 100 неактивных пользователей создает такую же нагрузку и как один активность еще один момент как я уже сказал раньше активный пользователь потребляет появляется своим потребителям ресурсов то есть он потребляет процессорное время память и и обсе дисковую подсистему не активный пользователь потребляет в основном дисковое пространство пришла идея что стоит разделить эту профили этих профиль нагрузки стоит разделить потому что очевидно они друг другу не подходит так возникла идея проекта кого пища что такое кладбище у нас это нет нет кристоф нет под кластер серверов который отличается в основном больше иди skype системой по объему приглашаем туда сменилась на большое количество активных пользователей в данный момент миграций осуществляется в фоновом режиме 2 этом участия не принимают счастье можно еще не делать введение этого кластера позволит вам сэкономить порядка 25 ресурсов основного кастера это у вас под ног лист это пока как мы делаем backup несколько цифр о том что мы делаем что мы имеем на данный момент количество спотов составляет порядка трехсот шестидесяти тысяч на обеих площадках количество таблиц в каждом споте более 80 общий объем данных которые нужно выкопать это 190 таро байт как эту этот объем данных бэкапить хочу сказать что зачем еще бэкапить уже есть реплика может возникнет вопрос напоминаю что реплика это не backup если вы удаляете данные на оригинальном себе этот запрос точно так же уйдет по реплики на своих и данные будут потеряны навсегда поэтому нужно иметь backup условий успешного backup а у нас следующая в первую очередь нам важно консистентной данных в пределах одного спорта то есть чтобы данный были актуально только приехала способ все таблицы в спорте у нас вы на db свойства можем использовать раза акцию для сохранения консистентной и как я уже говорил несколько раз размер спорта маленький общий размер спорта в среднем составляет 500 мегабайт также ддл которые могут помешать нам бы капица они происходят строго по расписанию мы можем это учитывать при нашем бэкапе учитывая все это мы решили использовать такой инструмент как mais quel там просто эффективно как выглядит схема нашего пикапах у нас есть под кластер себе фбк на которых запускается скрипт и которые в несколько потоков подключаются случайном порядке согласно карте дпс и в одной транзакции до мкад споты результаты этого backup а мы получаем порядка 25 терабайт так данных время полного бэкапа составляет менее 24 часов что там он достаточно отличная цифра для такого объема и последний кофе мы храним накласть рисковать backup остальные копия уезжают на ленту что хочу сказать заключение имеет пользуясь принципам keep it simple уступит имея достаточно высокий уровень инженерной культуры и активно контактируя с разработчиками выясняя их требования к системе можно создать надёжные главное отлично масштабирую систему не используя огромный stack технологий не стоит использовать модный инструмент если ваш текущий набор набор инструментов позволяет вам решить ваши задачи эффективно с ним спасибо вопросам добрый день спасибо большое за доклад скажите время развертывания из бука по пример верху не backup а проигрываем если эта история да конечно нам приходилось несколько раз остановится зато backup а достаточно быстро потому что мы также в снова несколько потоков зависит на самом деле мы же него сами весь кластер нам нужно с ником отдельный дпс зависит от его объема но в среднем меньше суток несколько часов что в этом если идет восстановление что это момент видит пользователь 500 вышивку извините мы работаем на восславим нужно спасибо за доклад я хотел спросить если у вас 6 минут какие-то глобальные отчеты которые необходимо генерировать на основе всех спадов например выбрать мужчин которые с голубыми глазами и сколько они нам принесли денег вчера да конечно гибель и как вы ну то есть как вы объединяете данные со всех спорта вот их 30000 есть специальный отдел называется биой они периодически выбирают данные из наших потом сквозь лёд на свои сервера эти давно анализирует то есть по сути вручную это только делает вручную нету например там какой-то you a интерфейса для аналитиков которые могут нажать кнопочку и посмотреть убей аналитиков есть целый отдел который занимается сохранением сырых данных и которые хранят у себя их системе и обрабатывают то есть наша наша спорта не позволяют обработка этих данных там просто хранятся данные биой выбирайте даны хранятся и у кластеру которых свой кластер свои базы которые отдельно пошла кластер не как независимое обрабатывают их здрасте можно вопрос очень понравилась идея с температурой спад а вот интересно стало а сам коэффициент к для старых серверов он пересчитывается когда появляется новый сервер не пересчитывание посмотреть может возникнуть такая ситуация когда у старого ну вот установили сервер у него допустим коэффициент 01 через год появился новый benchmark новые сервера карнавы сервера тоже оценивает как 01 нагрузка на них получится дед равномерно хотя они один и тот же объем них ну и в силе обработать если они ответили мощнее такой в центре такую же не получится то есть как всем не привязан к десятой доли то есть может быть 005 то есть быть быть маркс до одинаково никогда не меняется и обновляется и выдает более менее стараемся держать а пока до хватает то есть он в сторону уменьшения ведется до то конечно спасибо здравствуйте здесь спрашивали про отчет про мужчин с голубыми глазами сколько денег принесли вчера вот если мы говорим о реально вчера до 7 ноября то какого числа биой получит этот отчет насколько это real time вот насколько я знаю они получают их агрегирует данные самый свежих самый горячий тогда который нужно не агрегирует постоянно то есть у них выбираются они в ванной режиме то есть постоянно основной объем целях данного гриба этого в пик по площадке они прибегают на рипли к ционные пару mtb и выглядит он оттуда нижнего вот если это отчет скажем так но вы его раньше не было никто не собирал данные и я захотел его сегодня то когда я посматривайте цифры вам может быть вы просьбе я к сожалению не могу это вопрос хорошо спасибо здравствуйте спасибо за доклад и его это здание скажи пожалуйста а как организован поиск по параметрам я так понимаю он тоже должен затрагивать много споров но и сам хочу найти там всех пользователей в своем городе возможны многомиллионным выше ростом там 180 сантиметров кто и там и желательно девушка или бит-бокс как мне пробежать все эти спад и в реальном времени для этого у нас есть отдельная команда хищник с лишних разработчиков которые пишут свои демоны которые позволяют собственная квартира фку делать то есть ли ты подробности можете рассказать как это реализуем вам навернусь расскажет именно разработчики все может пойти к нашему страна к нашему стенду и спросить у них здравствуйте и спасибо за доклад я здесь до хотелось спросить скажите я так понимаю вы сделали просто свою репликацию в москва или да скажите вы стандартно это все-таки собираетесь использовать или в принципе нет смысла и не менее не хочу и не буду почему потому что да почему потому что как бы у меня впечатление такие что на самом деле даже в 57 если репликация затрагивает верни так если вы собираетесь что-то делает с до d или мда то на чем репликация далеко не лучший долг у это же все решения упираются то что как-то нужно это делать самому то есть вы не так мило не собираетесь на стандартной репликацию возвращаться в этом кластер и не дам вообще максима используем репликацию войска и конечно же то есть на других кастеров спасибо за доклад у меня сразу три но короткий вопрос 1 а вот вы сказали толпа железа стоит и что из себя представляет средний для юзер спотов сервер под маской то есть какие какая конфигурация второй вопрос чупа метрикам считаете какие именно что вы с такими нагрузками и больше как бы обращайте внимание на и третий вопрос вот я так понял что с 5 6 должно у нас стоит номер планируете ли вы на 5 и 7 и как вы видите ли что то для себя как бы какой-то перформанс 57 ответ на первый вопрос в данными мы ставим севера дел объем памяти 6 гигабайт дисковая система raid10 на 8 дисках объем данных порядка получается 4 терабайта процессор для который точно скажу 26 дек 2012 я дирку метрики а метрики мы посылаем этой как для базы данных это на самом деле дисковой подсистемы то есть про язвительность памяти произвести процессор не так важно поэтому в первую очередь мы берем именно близкой по система это количество и abs и и эти семь мы планируем у нас данный момент на самом деле идет тестирование кода совместимости 57 справляется ошибки нет хандлер socket у нас используется только на избив данный момент основам и он остается на версии 5556 и на самом деле работает ни вашим образом поэтому этот кот серый будет на версии 55 пока нас вполне устраивает здравствуйте спасибо за доклад подскажите пожалуйста какими инструментами вы пользуетесь для выходки изменений в базе данных то есть вы немножечко рассказали о борьбе между программистами за право коми то какими инструментами именно вы пользуетесь как вы все-таки соблюдайте от очередности отслеживайте изменений как ты рассказал выстраивается очередь руками 2 очередь выстроится из пикетов в нашей этики системе совместно эти киты назначаются на определенную дату их если выполнение которое вставляется таких системе в пик это запускается скрипт он идет в базу выбирает оттуда alter на сегодняшний на этот день и выполняет их я 3 на вопрос здравствуйте инструменты да это скрипт приветствую здесь а периодичность бэкапов спорта у вас вот получается 3 машинки которые занимаются бэкапом и вот в сутки получается 3 итерации но смысле с каждого спорта три бака по или как нет машин на самом деле там их порядка шести на каждой площадке и на каждом из этих серверов одновременно выпускается скрипт который в случайном порядке согласно карте к распределяется по этим сервером бы капитан и все сразу же у нас в backup идет по всему кластеру то есть не по частям и словесному каждые сутки мы имеет свежий пока смысле вы не делаете несколько сутки добрый день тут слева ну спасибо за доклад я так понимаю кроме с потоцких данных есть еще какие то общие типа там переводы или еще какие то как они хранятся очень по-разному как я уже говорил общее количество жиров для мастеров 600 665 квартир описано сегодня занимаю 300 есть средства иностранных занимаются всеми другими задачами переводы нанимает на самом деле небольшой процент порядка 400 сколько напомню спасибо пожалуйста добрый день можно здесь хайбуллина компаний автограф у меня четыре коротких вопроса первый сколько бы по процентам соотношения примерно сколько запросов идет на запись сколько на чтение из 151 на запись 5 на чтение так следующий вопрос вот я часто зал прослужил доклад от сотрудник facebook от разработчика они там применяют нее надо бы а рокс db там и у них получается так что если брать по записям то примерно при определим fly в 20 раз быстрее скорость записи происходит вы как-то рассматривать и переход на просто b на самом деле насколько я помню это горе они не используют и рокс добавьте эту кровь частью да но пока нет пока потому что мы еще кто-то даже не 15 и потому что там нет ни большого смысла 3 просмотреть вот вы используете hunter соки но я уже услышал там получается на версии 55 до майской там мастер на 5-7 включать вас нестабильно работает на 57 hangar стойки в принципе сабетта поддержки хорош на кота закончилась на версии 5 5c от разработчиков на 56 он был мигрировал съемным перк он и и наших разработчиков но в дальнейшем миграции под вопросом да и на самом деле смысла большого нет то есть соответственно если вам все же придется купить люстра интернете что вы примените если например там через два года выйдет уже 7 8 и какой инструмент вы планируете применить в местах андерс от возможной господин которого уже весь версии 80 выглядит вполне себе аппетитно как никакой инструмент уже встроенный плагин москве который позволяет обращаться тэмин тем же у зомби на весовой оптимизатора и гарри потера здорово примерно сколько запросов там секунду способен там вы держите инструмент к сожалению данном фильме год ведь потому что мы не тестировали его еще последнюю версию но по бенчмаркам от 40 ватт слышно высоки выше чем хозяйка в тестах но поживем увидим примером цифры наверно 500000 2 секунды на среднем возможно так и последний вопрос вот смотрите для аналитики вы я был используйте свои инструмента да то есть вы рассматривать там hadoop какой-то для выборки facebook там google и прочее не скажу за призвук точно скажу они используют ходов для аналитики для статистики и прочее вы чем пользуетесь у нас есть кластер hadoop но как я уже говорил этим занимаются у нас отдельно 915 и вот человек из чтобы может помочь хорошо спасибо пожалуйста такой вопрос а как происходит заливка если миграция на дроп каких-то потом заливка наиграться какая на удалении полей alter извини структуры случай если делается удаление полипа сначала ticket конечно же выезжают продаж им после этого мы его это поле удаляем как я рассказал обратно не совместим их или нет но если мы удаляем какое-то поле то процесс обратно то есть сначала поле удаляется после этого если вы не используется мы его гробом как вдруг таблиц на него тоже можно в системе как-то тически что если миграции смотреть если у нас происходит изменение которое подразумевает удаление полей то есть имея который по факту нельзя откатить то сначала выезжает код который уже не используйте эти поля но балакшин то есть обратная процедура сначала выезжают код потом мы делаем изменяя структуру так то конечно то что два проверяет состояние альтера то есть если он прошел не успешно как я говорил скрипт при свои письмо что в таких the spot a hunter не прошел и собственно же после этого 2 что-то да конечно спасибо за доклад как обнаженка баня живо сайта то вы рассказывали про то что не активный пользователь у вас переезжают на кладбище но вот тут например меня осенило я стал гиперактивным как это будет происходить я на кладбище на нагрузку создаем как я буду передать обратно спасибо также про своего собственного считается когда количество активных пользователей на кладбище увеличивается в какой-то момент праге происходит обратная миграция этими полюсами когда он когда они переезжают и грубо говоря на кладбище то есть вот этот процесс он единообразно из кладбищ и уезжают и на кладбище переживают да спасибо у меня еще один вопрос вот опять с вашим опытом под вашими нагрузками войска с ними давно с многими версиями и чем самый большой геморрой у вас маскирует вы же наверняка видите на своих как бы данных что но как далеко не всегда идеально штука да и что вас сам распространен на самой восприняла это разбой железо на самом деле то есть самое склеить в принципе проблем на самом деле заставляет здравствуйте здесь справа вот хотел бы дополнить вот предыдущий вопрос что происходит если допустим пользователь попадает на кладбище вы так делается при этом как бы и потом получается если восстанавливаете backup на dbt например и получается 2 пользователей буду в местах нет а как откатывается пользователь из кладбищ обновлений примерно следующим образом а кластер то же самое то есть это не отдельный кластер поэтому пользователь есть факт что помещен на кладбище поэтому это на самом деле заставляет пользователя делает учитывает код то есть он стоит поставлю что аспектирована кладбище у него отдельный флаг поэтому при миграции обратно мы проверяем если он на кладбище если нет то в основном реестре dvb-s под и и середина спутаете user1 нет это хранится минут базил вместе с пользовательской информации хранится у него его флаг быкам восстанавливать тогда но мы к нему взбить до хорошо если имеется ввиду возникновении дупле дуба и данных кот кот и может обработать то есть он проверяет что к пользователей с на кладбище и если он есть на кладбище собственно он тогда работает с активным она уровень на уровне продажа нет спасибо вы вначале упомянули что у вас есть платные подписки правильно эта информация тоже таблиц конечно а как делать сводный отчет и откуда открывается отводил биллинга кей ну там а теперь то конечно хорошо еще информация к хорошо когда пользователь находится на одном континенте до в одном шарди все него работает хорошо если начинаю общаться с другом который на другом континенте проблему в latency возникает каким задержка нет вы же общаетесь с ним то есть у вас задержка не будет хорошо мои данные в америке и водорода в европе да я пишу ему все равно синхронизации же она real-time у вас даже атлантикой то есть задержки нет у вас будет задержка на заставку сообщения пользователю вот собственно тот самая ртт данные хранятся в той же самой переписки и там и там сразу пишет спасибо добрый день и спасибо за доклад хотел знать такую штуку некоторые тебе часто советуют при дотрагивании структуры таблицы использовать методику когда вы создаете копию наверняка сталкивались таким вешаете триггере соответственно применяйте изменения к новой таблицы перегревайте данные вы используете блокирующие alter говорит что у вас примерно за 40 минут вполне за все миграции почему не использовали вот такой вариант потому что сильно усложняет схему и при этом выигрыш на то что небольшой то есть главный принцип а главный выигрыш от такой схему то есть это нас постоянно утилиты кто говорит об отеле с тем очень что тоже пин кода позволяет делать не блокирующий alter главный выигрыш это то что вы можете использовать таблицу все время пока идет миграция на новую схему alter так как спорт маленький alter 1с потом и таблицы в спорте занимает несколько секунд поэтому выигрыш от использования этой схема будет очень небольшим а нагрузка на систему повысится ну то есть основной критерий в итоге это продолжительность роста да спасибо пожалуйста 1 тем скажите пожалуйста то вы сказали про переписку если два юзера переписываются данные хранятся и там и там я правильно понял да данный а именно в сообщениях да да да а как тогда вот у вас путане бы капица в разное время один потом я не знаю сейчас выкатился 2 через десять минут получается что может лак возникнуть в переписке да может возникнуть нормально это обработать заклада мое сообщение будут вот тогда слова он появится в обоих еще мне такой вопрос по поводу репликации в самом мы скрыли там есть два вида репликации rock bass от и стоит нам бриз на как я понимаю вы блокируете только и вскоре запрос а если там встречаются конструкции типа на у там чё такое это как-то обрабатывается учитывается также примерно как в комплектации там пишется время таймс темп поставляется set temp и в случае если это делает но когда косах а я этот запрос он дал заменяет на конкретного текстом текущем а если это не только вот time spent не только время там чуть другое может быть apply a vast insert айди какой-нибудь или еще что то мы не используем структур то есть код в коде есть ограничение на использование вопросов такие запросы мы не должны использовать а когда искали запрос переезжает в другой дата-центр в другую другой часовой пояс том как то учитывается вот это вот что там время другого уже там время такой же вы делитесь и на всех сверху на стоит гитисе поэтому время одинаковое спасибо пожалуйста всем спасибо"
}