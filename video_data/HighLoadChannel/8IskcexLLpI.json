{
  "video_id": "8IskcexLLpI",
  "channel": "HighLoadChannel",
  "title": "Machine learning @ booking.com / Виктор Билык (booking.com)",
  "views": 2541,
  "duration": 2634,
  "published": "2019-01-14T00:09:00-08:00",
  "text": "дом день меня зовут booking.com где занимаюсь внедрением продуктов машинного обучения в промышленную эксплуатацию в продакшен сегодня вам расскажу где как зачем мы пользуемся машинным обучением об эволюции подходов к внедрению продуктов машинного обучения в продакшен о том с какими проблемами мы сталкивались о том как мы их решали но сначала давайте посмотрим где мы вообще применяем машинное обучение в наших продуктах то что на поверхности очевидно у нас есть большое количество рекомендационные систем для отелей для направлений для dat в разных точках воронки продаж и в разных контекстах например мы пытаемся угадать куда вы поедете когда вы еще вообще ничего не ввели в поисковую строчку это скриншот из под моего аккаунта и в двух из этих направлений в этом году я обязательно побываю у нас обрабатываются моделями практически любые текстовые сообщения от клиентов начиная с банальных спам фильтр off кончай такими сложными продуктами как assistent и чат бук где используются модели для определения намерений и распознавания сущностей а кроме того есть какие-то модели которые не так заметны такие как например фрод detection мы анализируем review модели нам говорят зачем люди едут скажем в берлин за что хвалят отель чтобы вам не приходилось читать тысячи отзывов самим в некоторых местах нашего интерфейса практически каждый кусочек завязан на предсказания каких-то моделей например здесь мы пытаемся предсказать когда отель будет распродан часто оказываемся правый через 19 часов последняя кому-то уже забронировано или например бейдж выгодное предложение здесь мы пытаемся материализовать субъективное что вообще такое выгодное предложение как понять что цены выставлены отелем на эти даты she ведь это зависит только кроме цены от многих факторов какие услуги предоставляет отель а зачастую совершенно от внешних причин что если например в этом городе сейчас проходит чемпионат мира по футболу или какая-нибудь большая техническая конференция но давайте-ка отмотаем на несколько лет назад 2015-ый год некоторые из продуктов о которых я говорил уже существуют при этом система которая сегодня буду рассказывать еще нет как же в то время происходило внедрение дела были прямо скажем не очень всё дело в том что у нас была огромная проблема часть который только часть техническая часть организационная мы отправляли да это санте став уже существующие класс функциональной команды которая покусилась на каком-то кусочки нашего продукта на какой-то пользовательской проблеме и ожидали что они как-то будут улучшать продукт но чаще всего эти кусочки продукты были построен на провел стеки и с первым есть вполне очевидная проблема он не создан для интенсивных вычислений и наш backend уже нагружен другими вещами при этом разработку каких-то серьезных проблем каких-то серьезных систем которые решали бы эту проблему приоритизировать внутри команды бы не удалось потому что фокус команда на решение пользовательской проблемы они на решение пользовательской проблемы с помощью машинного обучения поэтому ты тот человечек слева пиво продукт оунер был бы весьма против такого давайте же разберемся как это происходило тогда а вариантов было всего два я это знаю точно потому что в то время как раз работал в такой команде помогал да это сантис там выводить их первые модели в бой первый вариант это было материализация предсказаний предположим у нас есть очень простая модель с всего двумя печами страна из которой посетитель и город в котором он ищет себе отель это можно предсказать вероятность какого-то события мы просто вызываем все входные виктора ну скажем там сто тысяч городов 200 стран и того 20 миллионов строчку в мае сиквеле звучит как вполне живая тема таким образом можно выводить продакшен какие-то небольшие ранки и совсем пластинки и модели другой вариант это встраивание предсказаний прямо в бэг энд кат но тут тоже есть большие ограничения сотни может быть тысячи коэффициентов то все что могли себе позволить очевидно ни один не другой способ не позволяют вывести хоть сколько-нибудь сложную модель в продакшен а это ограничивало это было ограничивающим фактором для тех успехов которые да это сантис ты могли достичь в улучшение наших продуктов очевидно эту проблему нужно было как-то решать и первое что мы сделали мы сделали сервис предсказаний тут я наверное рискую получить премию за самую простую архитектуры когда-либо показанную на highload мы написали небольшое приложение на скала а косплей который принимал а просто входящие виктор отдавала предсказание обратно на самом деле а немножко лукавлю и система была чуть-чуть сложнее потому что нужно было понимать что это все работает нам нужно было как-то это мониторить нам нужно было как-то это выкатывать поэтому на самом деле все выглядело вот так в букинге есть система событий это такая очень просто доступна на всем железе вещь что-то вроде журнала для всех систем то есть да очень просто писать этот поток очень просто перенаправлять куда-нибудь на первых порах нам нужно было перенаправлять это в графе тогда фану для наших дашбордов чтобы мы видели что до работает отвечают на запросы мы отправляли туда клиентскую телеметрию сперси твой отец из и достаточно подробную информацию серверной стороны мы сделали простые клиентские библиотеки для первого мы спрятали весь рпц просто в локальный вызов поместили туда первые несколько моделей и сервис начал взлетать погадать такой продукт было достаточно просто потому что мы получили возможность внедрять более сложные модели и тратить при этом гораздо меньше времени tight ass on this ты начали работать с гораздо меньшими ограничениями а работа бы киндеров в некоторых случаях сводилась к на строчник у но давайте-ка ненадолго вернёмся к тому как мы пользуемся этими предсказаниями в продукте у нас есть какая-то модель которая на основе известных фактов делает какое-то предсказание базируясь на этом предсказании мы как-то меняем пользовательский интерфейс это конечно не единственный сценарий использования машинного обучения у нас компании но достаточно распространенной все же проблема запуска таких фич все дело в том что это две вещи в одном флаконе модель и изменение пользовательского интерфейса очень сложно разделить эффекты от того и от другого представьте если бы мы запускали этот бейдж в рамках оба эксперимента и предположим он не взлетает нет никакого изменения статистически значимого целевых метрик в чем проблема непонятный маленький незаметный бейдж или плохая модель как с этим разобраться плюс модели могут деградировать причин для этого может быть очень много то что работала вчера не обязательно работает сегодня мы могли внести какие-то ошибки в бэг-энд код который скажем собирает входящие виктора и могли просто этого не заметить к тому же мы постоянно находимся в режиме cold start a мы подключаем постоянно новые направления то есть новые города новые отели люди из новых городов приходят к нам и нам нужно как-то понимать что модель все еще хорошо обобщает и в этих кусочках входящего пространство самым наверное известно в последнее время случаем деградации модели был случай с алексой то есть скорее всего в результате переобучения она начала понимать случайные шум и как просьбу посмеяться и начинала заходиться хохотом по ночам пугая владельцев очевидно нам нужен был какой-то мониторе к предсказаний но что именно пардон мы немного доработали нашу систему точно также и зовем системы перед направленный поток в hadoop и начали сохранять помимо всего того что мы сохраняли раньше еще и все входные виктора и все предсказания которые сделала наша система потом с помощью узи job of мы их агрегирование в myspace и оттуда показывали небольшим к приложениям тем кто заинтересован в каких-то качественных характеристиках моделей однако что там показывать все дело в том что посчитать обычные метрики использующиеся при обучении моделей в нашем случае очень тяжело потому что задержка лэйбл af у нас зачастую просто гигантская то есть давайте на примере предположим мы хотим предсказать ездит едет ли пользователь один в отпуск или с семьей и предсказание нам это нужно тогда когда пользователь выбирает отель но правду мы узнаем только через год потому что сейчас можно забронировать отель на июнь 2019 и только уже съездив отпуск пользователь получит приглашение оставить review где среди прочего будет вопрос блага вон там один или с семьей то есть нужно где-то хранить все предсказания сделанный за год да еще и так чтобы быстро их мочить с входящими лейблами это звучало как очень серьезно может быть даже неподъемная инвестиция поэтому пока мы не решили эту проблему мы решили сделать что-нибудь попроще и этим попроще оказалось просто гистограмма предсказаний сделанных моделей то здесь на графике логистическая регрессия который предсказывает поменяет пользователь то ты свое путешествие не нет и видно что она неплохо разделяет два класса пользователь слева home это те кто не сделают этого справа home для тех кто это сделает на самом деле мы показываем даже два графика один за текущую период от вывоза предыдущий хорошо видно что на этой неделе это недельный график модель предсказывает немножко чаще смену дат с чем это связано в данном случае я затрудняюсь сказать это может быть простая сезонность а может быть та самая деградация со временем о которой я говорил уже только это привело к изменению того как люди работают до это сандис ты перестали вовлекать других людей они стали передавать над своими моделями быстрее они отправляли модели в продакшен в драй ран вместе с бэк-энд инженерами то есть виктора собирались модель делала предсказания но эти предсказания никак не использовались то есть в случае badge мы просто ничего не показывали как и раньше а собирали статистику и это позволило нам не тратить время на заранее провальные проекты мы освободили время fontaine de раф и дизайнеров для таких экспериментов покадает с antis не уверен в том что модель работает работает так как он хотел он просто не вовлекает в этот процесс других еще интересно посмотреть как эти графики меняются в различных разрезах слева вероятность смены дат на десктопе справа на планшетах хорошо видно что на планшетах модель предсказывает смену дат более часто и это скорее всего связано с тем что планшет часто используют для планирования путешествия и режет для бронирования что хорошо видно на графике еще интересно смотреть как эти графики меняются по мере движения пользователей по воронке наших продаж эта вероятность смену и дат на страничке поиска а это на первой страничке бронирования и видно что до страничке бронирования добирается гораздо большее количество людей которые уже определились со своими датами это будет хорошей графики как выглядят плохие очень по-разному иногда это просто шум иногда огромный холм что означает что модель не может разделить эффективно какие-то 2 классов предсказаний иногда как огромные пике это тоже логистическая регрессия и до какого-то момента она показывал красивую картинку с двумя холмами но одним утром она стала вот такой для того чтобы понять что произошёл внутри нужно понимать как вычисляется логистическая регрессия поэтому пардон краткая справка это логистическая функция от скалярного произведения где все эти x это какие-то фичи и одно из этих фич была цена цена ночь в отеле в евро и вызывать эту мадрид стоило бы как-нибудь так обратите внимание на выделенное нужно было сконвертировать цену в его но разработчик забыл это сделать написал что-то такое очевидно что валюты в итоге группе рублей многократно увеличили скалярное произведение и значит заставили эту модель выдавать значение близкой сидится гораздо чаще что мы и видели на графике еще одним полезным свойством этих гистограмм оказалось возможность осознанного и оптимального выбора пороговых значений если поместить шар на самую высокий холм этой гистограмме столкнуть его туда и предстоит где он остановится это и будет . оптимальное для разделения классов все что справа 1 класс то что слева другой однако если начать двигать эту точку можно добиться весьма интересных эффектов предположим мы хотим запустить какой-то эксперимент который в случае если модель говорит да как-то там меняет пользовательский интерфейс если мы пододвинем эту точку вправо мы сокращаем аудиторию нашего эксперимента ведь количество людей которые получили это предсказание это площадь под кривой однако на практике точность этих предсказаний престижен гораздо выше точно так же если не хватает стад мощности можно увеличить аудиторию своего эксперимента но понизив точность предсказаний кроме самих предсказание мы начали мониторить входящие значение векторах а большинство fitch в наших самых простых моделях они категориальные это значит что это не числа а это какие-то категории там скажем город из которого пользователь или год в котором он ищет отель что происходит внутри обычно мы пользуемся one хокинг один и превращаем каждая из этих значений в единичку в каком-то длинном бинарном векторе а поскольку в начале мы пользовались только нашим собственным вычислительным виду вам достаточно просто было определить ситуации когда для входящей категории просто нет места в входящими векторе то есть модель не видела этих данных во время обучения как это выглядит в норме например действенные шаги город в котором пользователь ищет отель это вполне нормально что модель увидела примерно 5 процентов значений мы постоянно подключаем новые города и цифра выглядит вполне нормально 20 процентов для визы струсить и едет тоже окей потому что да это сантис то иногда сознательно опускают этот длинный хвост направлении которые уже не так важен а в плохом случае это может выглядеть вот так сразу три фичи сто процентов значение которые модель никогда не видел в чем дело зачастую это просто использование каких-то форматов отличных от тех что использовать при обучении или просто банальная печатка вместо одной фичи подали другую и сейчас просто с помощью дашбордов мы обнаруживаем исправляем такие ситуации очень очень быстро но давайте поговорим о других проблемах которые мы решили после того как мы сделали клиентские библиотеки по 100 как мы сделали какой-то мониторинг сервис начал набирать обороты очень быстро и нас буквально завалило заявками из разных частей компании давайте подключим еще эту модель давайте обновим старую мы начали просто зашиваться фактически какая-либо новая разработка остановилась и мы вышли из ситуации сделав киоска самообслуживания для десанте став то есть теперь можно просто зайти на наш портал тот самый который мы использовали сначала только для мониторинга и буквально нажав кнопку загрузить модель production через несколько минут она будет работать и можно получать предсказание оставалось еще одна проблема booking это примерно 200 эти команд и как дать знать команде в какой-то другой совершенно другой части компании что у вас есть модель которая могла бы им помочь вы можете просто не знать что такая команда даже существует как узнать какие у нас вообще есть модели и как ими пользоваться традиционно внешними коммуникациями у нас команда занимаются пиво продукт оунер и это не значит что у нас нет никаких других горизонтальных связей просто они занимаются этим немного больше но очевидно что в таких масштабах коммуникации один на один и масштабируется нужно с этим что-то делать как бы мы могли облегчить их жизнь и мы так поняли что тот портал который мы делали исключительно для мониторинга начинает постепенно превращаться в витрину машинного обучения у нас внутри компании мы дали возможность дать о сандис там подробно описывать свои модели когда модели стало много мы добавили лейбл для того чтобы можно было модели группировать по каким-то темам по предполагаемым местом применения и так далее мы связали наш инструмент с эксперименту experimental это продукт внутри нашей компании который обеспечивает проведение бы экспериментов и хранит в себе всю историю экспериментирования то есть теперь вместе с моделью вы вместе с описанием модели вы можете еще и посмотреть что делали это в или команды с этой моделью раньше и насколько успешно это изменило все нет серьезно это изменило то как работает айти потому что даже ситуациях когда у вас нет дать о санте с в команде вы можете пользоваться машинном обучении многие команды держат наш продукт открытым там во время болезнь storm of когда они придумала какие-то новую продуктовую идея они просто подбирают модели подходящие и просто ими пользуется для этого не нужно ничего сложного во что же это вылилось для нас прямо сейчас в пике мы доставляем около 200 тысяч предсказаний в секунду при этом все это своей пенсии меньше 20 30 миллисекунд почему это включает типе round trip и хостинг больше двухсот моделей но может показаться что это была такая легкая прогулка в парке что все замечательно сделали заработало все гады такого конечно не бывает были и ошибки самом начале например мы заложили небольшую бомбу замедленного действия ну почему то предполагали что большинство наших моделей будут рекомендационные системы с достаточно тяжелыми входными векторами и стек скала а к был выбран именно потому что с его помощью очень просто организовать параллельные вычисления но реальность оказалась такого что overhead вот на всю эту поляризацию на сбор вместе оказался выше чем чем вы возможный выигрыш то есть в какой-то момент мы начали наблюдать чтобы у нас уже порядка 100 машинам от боба твоим всего 100000 псы отказа случается вполне характерными симптомами утилизация секу достаточно маленькая но мы получаем тайм-аут и тогда вы вернулись к нашему вычислительному виду пересмотрели сделали бенчмарки и в результате capacity тестирование узнали что теперь для того же самого трафика нам нужно все четыре машины конечно мы такого не делаем потому что у вас несколько да это центров нам нужно вариантности и все остальное но тем не менее теоретически мы можем обслуживать больше ста тысяч из всего с четырьмя машинами постоянно ищем какие-то новые мониторы которые могут нам помочь найти и исправить ошибки но не всегда делаем шаги в правильном направлении в какой-то момент у нас собралось небольшое количество моделей которые применялись буквально по всей вагонки то есть начиная со странички индекса кончая подтверждением о букинге и мы решили а давайте посмотрим на то как модели меняют свои предсказания для одного и того же пользователя начали просто считать дисперсию сгруппировав все по айди пользователя но пока что никаких серьезных проблем обнаружить с помощью этого не удалось предсказание модели стабильные дисперсия в районе нуля другой ошибкой было опять же и технической и организационной мы начали упираться в память все дело в том что мы храним все модели на всех машинах вот и начало упираться в памяти подумали что наверное пора делать шарды но проблема в том что одновременно в разработке находились и бочче это возможность предсказаний для одной модели но много раз представьте себе например страничку поиска и для каждого отеля там нужно что-то предсказать и когда мы начинали делать sharding мы посмотрели на живых данных и шагать собирались очень просто то есть по просто пойдешь нику модели и данные то есть и нагрузку и объемы модели распределялись примерно равномерно там со в деве 51 процент но когда мы закончили заниматься шар деньгам бачу жабу в продакшене использовался и у нас были горячей модели которые используют гораздо больше других и разбаланс был большой окончательном эту проблему решим когда мы наконец увидим в контейнер и какие у нас планы дальше ну в первую очередь мы хотим все-таки дать возможность да это сантис там наблюдать в динамике те же самые метрики которые они используют при обучении мы хотим выбил бы из metrics мы хотим престижен recall живой рилтайм алый в компания осталось еще какое-то количество внутренних инструментов и продуктов с которыми мы плохо интегрированы в основном это высоконагруженные проект и потому что всего остального мысли или павел клиентских библиотек для пирло и джавы и все кому нужна могут этим пользоваться у аналитиков есть удобная интеграция счас пока не могут вам для своего анализа использовать наши модели но однако например продукта которым на одном из складов расказывал иван круглов поисковик комнат свободных ночей до сих пор плохо интегрирован там есть небольшие технические сложности потому что в общем то обе системы серьезно биллу жены и не все так просто мы хотим иметь возможность вместе с моделями деплоить какой-то кастомный код дайте мне давайте я вам дам пример например представьте себе спам классификатор все процедуры которые происходят до получения входящего вектора например разбиения текста на предложение на слова steaming вы должны в продакшен окружении повторить еще раз желательно тем же самым образом для того чтобы избежать ошибок мы хотим избавиться от этой проблемы мы хотим деплоить кусочек pipeline разработанный для тренировки модели вместе с моделью и тогда вы сможете отправлять просто письма нам а мы будем говорить спам не спам мы хотим сделать асинхронное предсказание сложность наших моделей растет а все что медленнее 50 миллисекунд мы считаем очень медленным представьте себе какую-нибудь модель которая делает предсказание исключительно на основании например истории посещенных страниц на вашем сайте тогда мы можем запускать эти предсказания в моменты рендера страничке а собирать и использовать их тогда когда нам надо но теперь самое важное что я узнал чему я научился в букинге пока работал над внедрением моделей в продакшен что я хочу чтобы вы запомнили унесли домой и пользовались начинайте с малого мы своих первых успехов с машинным обучением достигли но это смешно сказать взрывая предсказание в мой сиквел машинное обучение на мой секрет возможно у вас есть тоже какие-то первые шаги которые вы можете сделать уже сейчас вам не нужны какие то сложные инструменты для этого я не знаю насколько я вправе давать такие советы я не специалист но у меня тоже совет с antis там если вы не работаете с видео если вы не работаете с голосом если вы не работаете с образа брожением если ваши задачи как то связано с транзакционными данными не берите слишком сложные модели сразу зачем вам нет одной сеть пока вы не попробовали логистическую регрессию мониторьте мониторьте все на свете вы же мониторить и свое программное обеспечение веб-сервера железа модель это такое же программное обеспечение единственная разница это программное обеспечение которые написали не вы его написала другая программа которого в свою очередь написал в десанте ст все то же самое входные аргументы возвращаемые значения знайте что у вас происходит в реальности насколько модель хорошо справляется со своей работой все ли идет штатным путем мониторьте думайте о том как устроена ваша организация практически любые ваши шаги в этом направлении изменят то как люди работают вокруг вас думайте как им можно помочь как устранить их проблемы думайте как вы вместе можете придти к большим успехом я поделился какими-то успехами какими-то неудачами какими-то проблемами с котором на столкнулись я надеюсь кому-то это поможет обойти те медленно которые мы сели делайте как мы но не повторяйте наших ошибок или повторяйте кто в конце концов сказал что ваша ситуация точно такая же как наша кто сказал что то что не заработал у нас не заработает у вас было быть и ошибайтесь делитесь своими ошибками спасибо да давайте начнем с первого ряда спасибо за доклад очень здорово может немножко конкретики как мне сделать так чтобы вот есть несколько сотен модели какие требования к моделям как организуется менеджмент работы этих моделей то есть вот немножко мясо можно чуть-чуть конкретный вопрос что означает менеджмент моделей ну например модели подставляют свои данные куда то есть модель который предсказывает что-то для пользоваться есть модель который присутствует предсказывать что-то для отеля разные кортежи данных над по-хорошему что все это работал вместе когда ты можешь взять модельку через админку куда-то загрузить по-хорошему должны быть какие-то правила работы с данными куда можно что заливать как этими данными будут пользоваться другие люди вот как вас это организовано у нас все достаточно гибко с этим в том плане что по большому счету мы предоставляем некоторые инструменты для того чтобы сделать например на сборы input викторов в каких-то продуктах несколько проще но мы не владеем всем наша зона ответственности кончается там где начинается input вектор и в скором будущем когда мы все-таки затащим pipeline и в внутри rs чуть-чуть это дальше но что происходит дальше откуда вы берете эти будут виктора что вы с ними делаете что это вообще за модель какая физическая природа этих предсказаний мы не знаем мы делаем платформу который позволяет вам их внедрять ну вот я хочу разработать модель какие требования предъявляют ваша система у нас есть несколько внутренних форматов которые мы поддерживаем которыми пользуются наши дети сантис ты кроме того можно внедрять то есть можно загружать точно также через веб админку tensorflow моделей и что модели вот для всего остального позвоните нам мы поговорим спасибо есть модели которые kanebo лидирует процессорное время на себя и все остальные ждут нет таких моделей сейчас нет но вообще почему мы двигаемся в сторону контейнеризации именно поэтому и потому что мы собираемся деплоить кастомный код мы не хотим чтобы чей-то код складывал весь кластер целиком поэтому я говорю позвоните нам обсудим у и и то есть мы должны посмотреть сначала на то что вы собираетесь выводить в продакшен если это не подпадает под стандартные сценарии то есть там наши внутренние форматы танцпол и что в этих вещах мы уверены все остальное нужна какая-то дополнительная работа и согласования следующий вопрос виктор спасибо за доклад вопрос такой страница отеля на нем красный виджет осталось только то или мест я всегда думал что мне впаривают чтобы стресса продать это суда тот отель и вопрос такой где граница когда нужно применять какую-то модель и машина обучение или на каждом третьем отеле randomizer показывать это сообщение на самом деле все очень просто вот я какое-то время действительно работала фантазия начинал там свою карьеру внутри букинга и одним из главных правил там было не врать пользователя то есть если мы видим что по какой то даже технической причине мы обманываем это было приоритет номер 0 до исправления поэтому когда вы видите цифры они и они настоящие сначала вот мужчина сзади потом вам виктор спасибо за доклад а вот вы когда рассказывали про неудачи сквозь я вас не вижу а вот сквозь упомянули о том что сначала за ложились на параллельные вычисления и связи с этим какой-то был overheat нашим проблемы с праведным числе не но собственно говоря то время которое тратится на на сбор обратно и на поляризацию дело в том что мы уже заложили не просто на параллельные вычисления на параллельные вычисления там где этого не следовало бы делать дело в том что если у нас есть например мульти номинальная какая-то модель скажем какой-то рекомендаций для городов то есть у нас есть там сто тысяч классов для каждого нужно вычислить скоро так вот оказалось что распадались 100000 и собрать немного медленнее чем просто сделать это последовательно хорошо спасибо за доклад я бы очень хотел попросить вас не быть ну пожалеть кошельки большая часть людей которые пользуются вашим сервисом я конкретизирую это на самом деле я замечал сейчас я просто правда не очень пользуюсь booking.com но вот года полтора назад была такая проблема там я живу нижнем новгороде не выставляю там один проезд я еду в командировку в штаты мне предлагают раза в два в три отеле подороже вы мой так скажем руководитель компании кому который работает просил чтоб я ему объяснил почему когда он хочет поехать в отпуск мы предлагают арендовать остров за 2 миллиона долларов то есть рекомендация не живите строится на основе а там множество модель ира ранжирование видимо ранжирование которое отвечает за прайс значительно более приоритета давайте я отвечу только на те части этого вопрос на который я имею права отвечать вот во первых динамического прессинга нет то есть нет такого что одна цена для одного одна цена до другого это во первых что касается рекомендаций дело в том что мы в отличие от сервисов скажем какого-нибудь там youtube или netflix видим своих пользователя очень редко то есть если в youtube человек приходит смотрят какие-то ролики буквально каждый день и выражает как-то свой intent практически постоянно посмотрел на это из предложенного набора выбрал вот то там и а своих пользователь знаем достаточно мало в среднем мы видим своих посетителей раз в год когда не бронирует свое свой отпуск а это значит что все модели они не персонализирует под вас они обобщают на какой-то большие популяции это единственное что мы можем делать давайте вот сзади молодой человек один добрый спасибо большое я здесь не вот такой вопрос вот сейчас коллега спрашивал если он ей допустим в командировку я так понимаю такие данные вы не собираете но я щас пример скажу допустим компания сделала бронирование для человека да вы же эти данные для вас будут полезны вы же могли бы их собирать то есть я на примере вот компании там smd я и сам билета не покупал однако я могу личный кабинет зайти и ввести номер брони для вас это будет полезная информация вы что-то с этим делать думаете у нас есть отдельный продукт для корпоративных клиентов то есть реальные специальные удобные инструменты для того чтобы компании бродила для своих сотрудников отель это ними нет я имею ввиду что человек может быть как и сам бронирует так и командировку когда он едет он же тоже как-то делает выбор самостоятельно насколько я знаю мы пока что не проводим спасибо такой же воспринимайте мои слова с щепоткой соли потому что я все-таки в большей степени занят выводом моделей в продакшн я конечно вижу и слышу чем занимаются и о чем говорят мои клиенты но я могу всего не знать спасибо юрий виктор прошу прощения спасибо хотел бы поинтересоваться в живот наверняка комментарии обрабатываете то есть задача обработки натуральных языков и оставить то есть на сколько целесообразно использовать свёрточная нейросети подачи задач я же не дайте сантис спросите у настоящего да это сантис дядя я нашел это сварочную маску на свалке виктор я здесь спасибо за доклад немножко оффтопик но тем ни менее терез на когда делаю поиск через booking количество детей до такой параметр который меняется нечасто устроен телефона с ноутбука он каждый раз меня просит вести эти параметры зачем ну давайте с наукой давайте я выдам свою гипотезу да я не знаю зачем но сколько я не занимаюсь этим я не работаю в групп search и но из того что я знаю я предполагаю что как я вам уже говорил мы встретим видим своих пользователей очень редко и интересы тип путешествия и так далее очень сильно меняются от года к году там от путешествия путешествия не знаю только так могу это оправдать еще такое еще еще последний вопрос на самом деле тоже вот это уже к вам когда куда-то ездишь в какой-нибудь город и ну допустим съездил к европейский город я туда только уехал он мне говорит booking что цены там снизились ну я как бы опять включить дата сайт сюда то наверное вряд ли я в этот же город поеду прямо завтра там послезавтра и предлагать там 2 три раза подряд про то что в этом городе снизились цены как-то давайте а значит давайте я отвечу очень коротко вы удивитесь когда узнать как дела обстоят на самом деле виктор добрый день тепла многих а вы скажите я правильно понял вообще что вы занимаетесь исключительно prediction нам то есть не занимайтесь обучением вот кто уже обучил модель засунул в вашу платформу и все посчитал но это не является нашим прямым фокусом мы немного трогаем и эти места тоже но в целом т.к. сантис ты вольна выбирать любое программное обеспечение любые инструменты которые им нравятся понятно допустим я такой и дата сатанисты обычаю модели загрузила я к вам всё классно считается а потом едут новые данные и вроде как модели нужно переобучать это всю ответственность за этот состав то есть пока что дамы мы потенциально не можем а у них 200 моделей сразу вот единственное что у нас там вместе с описанием модели есть обязательная ссылку на репозиторий где живет кот который сгенерировал эту модель есть модели которые перри обучаются постоянно то есть как там эту проблему итогам я бы не сказал что мы ее стопроцентно решили но мы заняты этим тоже окей хорошо да это сантис то у вас к moonduck сидят то есть каждая команда сама находит себе этого чувака как-то там что-то делает и вам уже идет к вам то есть нет какого-то центрального аппарата да это сами тестов куда все ходят и просят модельки но нет во первых нет центрального аппарата иногда бывают такие эксперименты то есть создаются там команды в какой-нибудь области целиком состоящее из дайте санте став которые обслуживают всю ту всю область все все окружающие команды трек обычно но чаще всего просто диплом десанте став команду в которой есть потребность в персонализации или в каких-то в каком в какому-либо машинного обучения в этой области при этом команда продолжает заниматься там я не знаю предположим оптимизация если команда занимается оптимизация конверсии в каком-то кусочки она продолжает заниматься этим и без машинного обучения просто мы и усиливаем да это сайт с тем чтобы он мог помочь команде найти какие-то и новые подходы к этому то есть команда не сто процентов времени занимается только тем кто решает ну понятно что 200 команд в каждой команде могут быть какие-то свои идеи одним вот такую модель другим другую там набору данных могут очень сильно отличаться кто то есть как человек который говорит так вот эти пять модели сейчас делаем это как то все не так просто все внутри команды то есть у нас этот процесс и ноут 200 команд пришли 200 заявок и вот чего вы делаете заявок в смысле вот пришли 200 конкурирующих моделей 200 команд сделали каждую свою модель куда носит ее вам и вот вы чё делаете просто вычел и манеж я садимся приходит на портал так и нажимают кнопку они работают вот мы сидим мы занимаемся разработкой продукта дальше вот если они приносят 200 кастомных моделей каких-то которые мы не можем сейчас через портал просто взять и отправить на наши сервера тогда да эта проблема но я думаю мы найдем способ приоритизации среди этих 200 моделей и посему следующий вот молодой человек здравствуйте спасибо за доклад у меня вот вопрос как вы внедряете именно туристический экспертизу когда-то сантис там в первую очередь все-таки do it is in this to the технический специалист математика а вот вы говорили о примере когда вы предсказываете туристическое направление куда то есть человек но очевидно первое что в голову приходит корпус которого он вылетает зато который выбирает наверняка еще какие-то более тонкие туристические моменты и дать просто может не знать как вот экспертизу добавляете но это собственно говоря нет какого-то формального процесса вокруг обучения десанте став как и других специалистов все начинается с ван борден команд где люди работают с кем-то более опытным перенимают опыт подходы к работе учиться доме на область у нас есть какие-то программы там выводит укв 1 га когда команды ездят просто в путешествия с целью исследовать какую-то часть доменной области типа как это происходит в реальной жизни как они могут устранить какой-то friction там и так далее то есть очень много очень много подходов очень много аспектов но в основном это вот горизонтальные связи очень много в компании держится на горизонтальных связях то есть перенимаешь опыт от коллег а ну то есть все таки большая часть здесь одесситами нация удается in this то конечно еще вопросы вот человек виктор спасибо за доклад у меня такой вопрос по поводу экспериментов с моделями как вот менеджер вообще эксперименты как принимается решение что ну я так понимаю вы все выкатывать и но как там на какой процент и так далее ну процент чаще всего 50 процентов то есть аудитория по полам потому что вы уделите свое аудитории непропорционально очень сложно потом будет доказать коллегам о том что ваша выборка в этом эксперименте было репрезентативной и вообще математика все сразу становится сложно если у вас выборки не равнозначен и поэтому мы катим все время обычно все на на 50 процентов до а если наложения происходит ну несколько моделей одновременно но у нас во первых есть аллаху для такого то есть когда эксперименты коррелируют мы об этом знаем это раз во вторых решаем это не техническими способами то есть для этого есть команде пи о который координирует в том числе работу команды с другими командами если есть какая-то область которой несколько команд хотят и работать если они понимают что но есть какой-то конфликт интересов и нельзя запускать эти эксперименты вместе но они договариваются в каком они порядке вот будет запускать например если другие технические способы решения то вот что если у кого-то есть какие-то вопросы их можно будет задать позже на дискуссионной зоне сейчас давайте поблагодарим виктора за его доклад"
}