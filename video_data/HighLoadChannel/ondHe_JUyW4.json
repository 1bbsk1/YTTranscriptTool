{
  "video_id": "ondHe_JUyW4",
  "channel": "HighLoadChannel",
  "title": "Анализ производительности запросов в ClickHouse / Алексей Миловидов (Яндекс)",
  "views": 12858,
  "duration": 3402,
  "published": "2018-11-19T03:03:17-08:00",
  "text": "всем привет меня вся я для house также как и в постоянно и интересные запросы и каждый раз меня волнует не только результат но это что это запрос делает ну например я выполняю запрос он работает одну секунду много это или мало я всегда думаю о почему не полсекунды хочу стал было пол секунды а потом например так беру чуть оптимизируем всего скоро он работать десять миллисекунд я конечно доволен обычно но я все таки стараюсь в этом случае сделать такое недовольное выражение лица и спросить почему не 5 миллисекунд и вот как просто выяснить на что тратится время при обработке запроса можно ли его в принципе сделать быстрее и конечно для этого я мог бы воспользоваться вот эти вот барабаном правда это не мой барабан поэтому не очень хорошо будет но на самом деле скорость выполнения запросов это я не надо спасибо это обычно просто арифметика то есть вот мы написали код мы написали его оптимально наверное и в системе у нас есть некоторое устройство и этих устройств и технические характеристики ну например скорость чтения из r1 каша мы это все знаем или скажем количество случайных чтений которые может делать ssd и нам нужно взять эти характеристики сложить вычесть умножить поделиться и потом свериться с ответом но это в идеальном случае а такого почти не бывает почти на самом деле вкх все такое иногда бывает так вот рассмотрим какие то реальные факты по поводу того какие устройства и какие ресурсы у нас есть на наших серверах процессор память диск сеть я специально упорядочил эти ресурсы таким образом начиная от самых так сказать простых и удобных для рассмотрения и для оптимизации и заканчивая самыми удобными сложными например я выполняю запрос я вижу что моя программа вроде бы упирается в тупого это что значит это значит я найду там какой-то внутренний цикл кокаин функция которая чаще всего выполняется перепишу каттеры контролирую и раз моя программа работает быстрее если у меня тратятся слишком много оперативки уже чуть-чуть сложнее нужно перри продумать структуру данных там by cirque какие-то ужать но в любом случае я перезапускаем программу она тратит наш оперативки правда зачастую этого шерп процессору если у меня диски все упирается в диске то это уже сложнее потому что я могу изменить структуру данных на диске но придется эти данные потом переконвертировать ясно я сделаю новый релиз придется людям делать какую-то миграцию данных то есть получается диск уже существа сложнее лучше думать об этом заранее ну опять я вообще очень люблю сеть потому что зачастую абсолютно непонятно чего в ней происходит особенно ясно это сеть между континентами между то-то центрами там что то тормозит это даже не ваша сеть это не ваш сервер и высоте ничего не можете сделать и делать на что вы можете сделать это просто заранее продумать как будут передаваться данные и как минимизировать взаимодействие по сети ну и разумеется бывает что ни один ресурс системе не утилизирован а программа просто чего-то ждёт и на самом деле это очень частый случай потому что система у нас распределенная да и всяких там процессов потоков может многое обязательно какой-то ждал другого и все это нужно друг с другом как-то увязать чтобы правило рассматривать и так самое простое что можно сделать это просто посмотреть на утилизацию ресурсов какую-то честно на величину например вы запускаете так какой топ и он пишет процессор сто процентов или запускается и астат он пишет диски сто процентов правда зачастую этого недостаточно то есть один человек он увидит программа упирается в диске что там можно сделать можно просто отметить это и пойти отдыхать что все ничего нельзя оптимизировать но на самом деле каждое из устройств она внутри себя довольно сложная то есть у процессора там куча вычислительных устройств для разных видов операций у дисков то у вас может быть raid-массив там из леса где-то там внутри свой процессор свой контроллер который делать непонятно что и просто одной величины там 50 процентов или сто процентов это недостаточно то есть основное правило вы видите что какой-то ресурс утилизированы на сто процентов но не надо сдаваться все равно можно что-то улучшить зачастую но бывает и наоборот например вы видите что на 50 против утилизированы но ничего сделать не удастся давайте рассмотрим это подробнее итак самый как бы простой и удобный ресурс это процессор вот вы смотрите топ и там например написано что процессор сто процентов но стоит иметь ввиду на самом деле это не процессор сто процентов это программа топ она как бы не знает а все что делает процессор она смотрит с точки зрения планировщика операционной системой то есть он сейчас какой-то поток программы выполняется на процессор процессор что-то делает и в этом случае будет показана стал процентов если это там за какое-то время усредненно но в это время процесса что-то делает но не понятно насколько эффективно он может выполнять разное количество инструкций затакт я сломал инструкция то сам процессор может что-то ждать например ждать загрузки данных из памяти при этом просто в топе будет отображаться все то же самое сто процентов мы как бы ожидаем пока процессор выполняет наши инструкции а что он там внутри делает это не ясно ну и наконец а бывают просто грабли когда вы думаете что ваша программа упирается в процессор это действительно так но у процессор почему-то низкая частота и тут может много причин она причин там перегрев другая причина ограничение мощности бывает такой почет в дата-центре ограничения мощности по питанию или просто включена энергосбережения тогда процессор будет переключаться постоянно с более высокой частоты на более низкую но если у вас нагрузка не непостоянная то этого будет недостаточно и среднем код получается будет выполняться медленнее ясно вас интересует настоящие частота процессора смотрите turbostar если хотите проверить не было там перегрева смотрите да визг и если там что-то было там будет написано что перегрев частота понижена если интересует сколько внутри было каш промахов сколько инструкции за так выполняется смотрите используйте перс это pr free card записывайте какой-то сэмпл того как выполняется программа и дальше можно будет это посмотреть с помощью перс стад или перф раппорт и наоборот допустила смотрится в топ и процессор утилизируем менее чем на 50 процентов но вполне возможно что у вас допустим систем виртуальных процессоров и 132 физических два раза меньше 16 на процессорах intel так и есть потому что гипертрейдинг двухуровневой но это не значит то что эти дополнительные ядра бесполезны все зависит от нагрузки скажем если у вас хорошо оптимизированы и операции какой быть линейной алгебры или вы вычитаете хэши для майнинга биткоинов тогда у вас код будет такой четкий там будет выполняться много инструкций затакт kh промахов не будет брать место иксанов тоже не будет иди потратил к никак не помогает гипертрейдинг помогает когда у вас 1 ядро чего-то ждёт и в то же самое время другое ядро может выполнять инструкции другого потока если рассматривает cliff house то там есть и та и другая ситуация скажем когда мы делаем агрегата данных грубой или фильтрацию по множеству то есть in sap говорим то у нас будет хэш таблица если хэш-таблицы не помещается в процессор ный кашель будут каш промахи и этого пасти никак не избежать в этом случае пейп-арт рейтинг будет помогать по умолчанию коли house использовать только физические процессор ноября то есть без учета гипертрейдинг если вы знаете то что ваш запрос может получить преимущество от гипертрейдинг а просто увеличится количество процессоров количество потоков 2 раза z макс пресс равно 32 и ваш запрос будет выполняться быстрее ну и конечно есть такая ситуация когда процессор прекрасно используется новый смотрите на график а график у вас например 5-минутный худшем случае да и даже ясно 1 секунды все равно там какая-то усредненная величина и получается вы там увидите номер десять процентов ну на самом деле у вас были запроса постоянно они выполняются быстро там за 100 миллисекунд каждую секунду и это нормально потому что treehouse старается выполнить запрос настолько быстро насколько возможно и вовсе не старается целиком на постоянное время использовать и перекрывать ваши процессоры давайте рассмотрим подробнее вот уже может быть немножко сложный вариант есть запрос с выражением что-то там in software внутри под запросы у нас 100 миллионов вроде бы я правильно прочитал и надеюсь вы тоже можете это прочитать 100 миллионов случайных чисел и мы просто поэтому росстату фильтруем смотрим такую картину кстати кто скажет что же что за такой инструмент с помощью которого я смотрю эту замечательную картину абсолютно верно перв и я очень рад что вы это знаете и вот я значит открыл перс я думаю что я сейчас все пойму открываюсь обзорный листинг и там я написано как часто выполнение программы была на определенной инструкции то есть как часто там был ян страшен по enter здесь числа в процентах и написано что почти 90 процентов выполнялось конструкция тест регистрируя dx регистр redex то есть проверка 4 байт на 0 спрашивается почему процессор может так много времени выполнять инструкцию просто сравнить четыре байта с нулем а кто знает да ну да нет остатка отделяют от битовые сдвиги потом сердце 32-ку инструкция есть но на ней вообще не страшен pointer никогда не бывает нет генерация случайных чисел тут вообще в этом рисунке нелл там отдельную была функция и она очень хорошо активизирована она не тормозит здесь кое-что тормозит выполнение кода как бы останавливается на этой инструкции тратят там кучу времени ну еще хотя бы один человек кто знает idol лук не зачем я вставляется там аттилу по тем более если вы я вставил просто клуб это было бы тоже видно как в perfeo да тут нет никакого делю на ноль тот просто сравнение старом значит причина о наконец-то вот я постараюсь вас запомнить что вы ответите на этот вопрос значит ответ я расскажу подробнее о процессор есть конвейер он может выполнять низкой инструкция параллельно и когда construction pointer в каком-то месте это вовсе не значит что он выполняет именно эту инструкцию может быть он ждать каких-то других инструкций которые были чуть-чуть до этого а до этого мы вот у нас есть хэш таблица для проверки того что какое-то число в каком-то множестве и для этого мы делаем lookup в памяти когда мы делаем внуков памяти это у нас каш промах потому что хэш таблица 1 6 миллионов чисел она ни в какой кэш гарантировано не помещается и так получается что для выполнения вот этой инструкции проверки на 0 должна быть чтобы эти данные уже были загружены из памяти а мы ждем пока не был загруженной ставите так что поздравляю абсолютно верный ответ спасибо теперь следующий ресурс чуть более сложные диски ну дисками иногда также называется счас не хотят и не совсем корректно и в этом пример тоже соседи будет скучно мы открываем и астат он показывает утилизацию сто процентов вот такое небольшое отступление часто бывает на разных конференциях вот докладчик на сцену и говорит так с таким пафосом базы данных всегда упирается в диск поэтому мы сделали инженеры базу данных она не будет тормозить вот я со к вам подходит человек а так говорит можете смело его посылать если какие-то проблемы вы скажете что я разрешил так вот допустим не стоит от программ упирается в диске утилизация сто процентов но это конечно не значит что мы используем диски оптимально типичный пример это просто много случайного доступа но даже и это доступ последовательной вы просто последовательно читать файл но все равно это может быть более или менее оптимально ну например у вас raid-массив там у несколько устройств скажем там 8 дисков и вы просто читаете последовательно но без ледоход и с размером буфера один мегабайт а размер чанка вашего strappy в роде тоже допустим 1 мегабайт и тогда получится что каждое чтение которой у вас есть она будет с одного устройства или ясно не выровнена тасс 2 устройства и там куда пойдет полная габай the cut анти шок был мегабайта и так диски будут по очереди использоваться то один диск то другой то 3 значит что нужно чтобы лари доход или если у вас а директ то ставьте больше размер буфера то есть правило такое 8 дисков размер чанка один мегабайт ставьте размер буфера минимум 8 мегабайт но это будет работать оптимально только я сочетание выровнены а если не выровнена там будут вначале кусочки лишнее и надо побольше поставить то есть до нажать еще на несколько или например у вас red 10 с какой скоростью можно читать стоит 10 допустим из 8 дисков какой будет преимущество четырехкратная потому что там есть mirror или восьмикратное на самом деле это зависит от того каким образом этот сайт создан с каким расположением чанков в стропах если вы используете emdi адам в linux этом можно задать не our loyalty фарлайт причем нир лучше для записи файла я уж лучше дать стене я вам всегда рекомендую использовать именно фар layout потому что для аналитической базы данных да пусть даже там намного больше записей чем чтение но когда вы делаете запись обычно это не так критично по времени это делать какие-то фоновым процессом но когда вы делаете чтение нужно сделать чтение как можно быстрее настолько быстро насколько это возможно так что лучше активизировать райт для чата не то есть выставить фар layout и вот как на зло в линуксе в м диадем по умолчанию создаст сверла ялта бы получиться только половину производительности и таких кораблей на самом деле очень много или скажем еще одни ужасные грабли это raid 5 и raid 6 и там он значит хорошо масштабируется по последовательным чтением хорошо масштабируется посылать в записям то есть red5 будет это кратность там будет количество устройств -1 хорошо масштабируется даже по случайным стянем но плохо масштабируется по случайным записям делается запись в одно место какой-нибудь и вам нужно прочитать со всех остальных дисков данные покорить их и записать другое место для этого использоваться некий кэш stripe of и вот ужасные грабли в linux мы по умолчанию такой что вы создаете 5 райт и он у вас будет возить и вы будете думать 105 райт всегда тормозит потому что это ведь и так понятно но на самом деле просто не правильная настройка или вот еще один пример вы делаете что не из осады и вы купили себя такой хорошие соседи там спецификации написано 300000 случайных сетей и в секунду а у вас что то не получается и вы думаете да врут они все в спецификациях своих не бывает такое но на самом деле просто все и значительно надо делать параллельно с максимальной степенью параллелизма и единственным способом сделать это достаточно оптимально это использовать асинхронный ввод-вывод который реализуется с помощью системных вызовов и о сабмит и agito винкс и а сетап и так далее и кстати данные на диске если вы храните всегда надо сжимать я приведу один пример из практики один человек обратился к нам в чат поддержки к хауса и говорит вот кликал сжимает данные я смотрю он упирается в процессор у меня очень быстрые диски с днём и там скоро чтения несколько гигабайт в секунду можно ли вк решался как-то отключить сжатия я его говорю нет никак нельзя отключить сжатие я точно вам на нужно чтобы данные хранились сжатыми он говорит дайте я там за canterville чем просто будет другой как бы алгоритм сжатия который ничего не делает noob я говорю да легко вот в эту строчку кода писать эти буквы вот короче через день он говорит дать остыть все очень просто я сделал и я спрашиваю насколько изменилась производительность он сначала ничего не ответил а потом через день говорит извините не удалось протестировать потому что данных стало слишком много и они теперь не помещаются на ssd давайте теперь посмотрим как может выглядеть то как вы читаете с диска запускаем de stat он показывает какой скорость чтения вот стал га царит 300 мегабайт в секунду мы читаем списков много это или мало я не знаю теперь я запускаю его статус чтобы это проверить мне и тут видно разбивка по устройствам у меня есть рейд это м д 2 и 8 жестких дисков у каждого из них утилизация показано она даже не доходит до 100 процентов где-то 60 50 процентов но самое главное с каждого диска я читаю всего лишь 20 30 мегабайт в секунду а я между прочим еще с детства запомнил такое правило что с диска можно читать где-то 100 мегабайт в секунду почему-то это до сих пор почти не изменилась я его сейчас мы проверим правда это или не правда что должно быть ведь 100 мегабайт в секунду или больше с каждого диска вот другой пример теперь чтение более оптимально я запускаю de stat и у меня с этого raid5 между прочим из 8 дисков читается почти гигабайт в секунду очень круто и что же показывает реостат до почти гигабайт в секунду теперь наконец-то диски загрузил на сто процентов правда почему-то 2 на сто процентов а остальные на 95 наверное они немножко все-таки разные но с каждого из них я читаю 150 мегабайт в секунду то есть даже еще круче чем может быть и в чём же разница разница как раз в том что в первом случае я читал с недостаточным размером буфера недостаточного и кусочками все все просто тривиальные прописные истины я вам рассказываю кстати если вы думаете что данная все-таки не нужно сжимать для аналитической базы данных то есть доклад на конференции халат + + сибирь вот организаторы решили так и самые хардкорные доклады в новосибирске сделать я собой это время можно будет посмотреть теперь следующий пример это память прописные истины во-первых linux никогда не смотрите что показывает free для тех кто смотрит специально создали сайт linux от mail.com заходите там будет разъяснение потом на количество виртуальной памяти тоже смотреть не нужно потому что какая разница сколько адресного пространства вызывало программа смотрите на то сколько именно физической памяти и скажем еще одни такие грабли которые даже непонятно как с ними бороться но запомните это нормально то что локаторы зачастую не любит отдавать память системе они сделали am up a em on map уже не делают память систем не вернется программа думает я лучше знаю как я буду использовать эту память оставлю к я ее себе потому что системные вызовы em up i am on map они довольно медленные изменения адресного пространства сброс кирби каша у процессора лучше этого не делать впрочем в операционной системе все-таки есть возможность освобождать память правильно с помощью системного вызова м адвайс адресное пространство останется но физически память может быть выгружены и конечно никогда не включайте своп на продакшен сервак с базами данных вы думать о ну не хватает памяти включил своп после этого запрос просто перестанет работать он будет отражаться бесконечная время это не поможет ну из сетью то же грабли типичная скажем если вы каждый раз создаете список деяния потребуется некоторое время перед тем как там будет выбрана правильно размер окна потому что tcp протокол не знает с какой скоростью надо будет передавать данные он к этому адаптируется или скажем вы передаете файл а у вас в сети большая latency и потери пакетов еще прилично в этом случае вообще не очевидно правильно ли использовать и сепеда передачи файлов и я думаю что неправильно потому что те цепи гарантирует последовательность а с другой стороны вы могли бы передать половину файла одну и половину другого одновременно использовать по крайней мере несколько тисе пи соединений или вообще не использовать api для передачи данных скажем когда вы качаете данные фильмы и сериалы торрентами то там тисе пи нету и конечно данные носа сжимать ну я не знаю если у вас в пределах стойки 100 гигабит сеть то можно не жевать пожалуйста но если у вас да там 10 гигабит номер stood at a центрами особенно между то в европы и сша кто знает как эти ваши бойцы будут под океаном там ползать сжимайте их пусть они ползут как мегабайт вот эту картинку все видели отлично поднимите руки кто видел ползала неплохо так что я спешу вас обрадовать если ваш ассистент все тормозит вот все инструменты у вас есть вы начать их использовать начнете разбираться с вашей проблемой и как правило обнаружить еще 10 других проблем эти инструменты достаточно мощные чтобы загнать вас на очень долгое время но я саппорт к есть некоторая база когда вам говорят что-то не так вы заходите на сервер и вот запускать подряд все эти инструменты из них например особенно можно отметить и о топ показывает по процессам сколько каждый реально читает и пишет на диске сколько там и abs of но даже в таких инструментах простых как топ есть некоторые маленькие хитрости о которых не каждый знает давайте посмотрим вот на продакшен сервер я запускаю топ он показывает cliff house сервер там используется сколько-то процессора сколько-то процессорных ядер но я не знаю что происходит внутри но я могу нажать h если правильно помню и он покажет разбивку по потокам и чтобы вам было удобнее в к хаусе потоки поименованы вот есть параллель парал input спрос это значит параллельная обработка запросов или вот bigger проц пол это значит мер g или скачивание данных для репликации то есть теперь уже более понятно на что тратится отдельные процессор надра что делают отдельные потоки да почему именно такие дурацкие б carprog full если вы читали исходе как трахался вы знаете что я такое не люблю я всегда напишу background processes in pool по-нормальному но тут вот такие дурацкие мин а потому что максимум можно 15 байт а почему максим 15 потому что это 16 минус 1 где 1 это 0 байт а почему максимум 16 я не знаю но но я почему-то представляется так что разработчики ядра linux это такие крепкие профессионалы бородатые которые думают 16 байт так лучше вот другой пример с использовали замечательной программы к house benchmark она входит в обычную поставку вместо вместе с какого с клиентом и на самом деле это не отдельный бин арк это тоже как раз клиент только sibling на него с помощью него можно взять какую-то ленту запросов или один запрос и устроить погрузочное тестируя он будет выполнять эти запросы с использованием фиксированного количества соединений непрерывно и выводить статистику вот я беру простой запрос с подсчетом количества уникальных посетителей запускаю как создать парк он пишет сколько запросов в секунду какие перцентиле выполнения сколько строчек в секунду обрабатывается и скорость чтения данных после разжатия в мегабайтах секунду я обычно его используют вместе с первых топом я захожу в pr top evod у меня разбивка по функциям и тут видно что вначале хэш-таблица вставка никаких хэштег для подсчета именно функция unic unic схож сет и агрегация я могу зайти внутрь посмотреть осин жирный листинг я обычно там ничего абсолютно непонятно но раздачами хорошая хотя вот например вызов функции по указателю был ну я на самом деле хотел другом и посмотреть вставку в хэш-таблицу и так я смотрю и тут есть умножение целочисленные битовые сдвиги к ссор и какие-то константы длинные что это такое кто его знает умножать это константа битовые сдвиги что вычисление хэш-функции то есть принцип я мог бы поставить туда какой сборе простую хэш-функцию единственная проблема я не могу это сделать потому что вот именно в этом куски кода это чуть ли не самая простая хэш-функция который может быть я мог бы поставить туда скажем сердце 32кл но проблема в том что в других на ставка диана уже используется и ясно я поставлю еще сюда будет нежелательная корреляция друг с другом хэш-функции который приводил к чудовищным коллизиям в хэш-таблице замедлению программы посмотрим дальше вот я тут рассказал про всякие ресурса но все это было применимо не только к хаусу вы можете для любой другой база данных те же самые правила использовать смотреть что происходит внутри но я хочу смотреть чисто про кликов и начнем самый такой базовые вещи чтобы посмотреть какие запросы выполняются никаких сюрпризов просто выбираете шел процесс лист просто понятно я тож самое что select from system process as там куча столбцов со всякими системного метрика в этом потребление памяти чтение сколько бы отчиталась можно также изобразить простой crack house top что вообще делает cliff house внутри базовой это две вещи выполнение запросов и background операции бэкграунд операции это в основном мир же ясно интересует какие мерзну палаццо просто смотрим select звездочка from систем мер час посмотрим как это выглядит вот production сервер я запускаю магическую команду и пожалуйста клика у стоп нотариальное пользователь реального сервера аналитического тут у них некоторые запросы выполняются о ужас больше минуты кажется мне надо остановиться и пойти их оптимизировать какой-то трав testing кто это но на самом деле эти запросы довольно сильно урезаны по ресурсам специально чтобы аналитики не мешали интерактивным запросам такое конечно в хаусе может легко обеспечить плана хватит на это смотреть идем дальше недостаточно только смотреть что происходит в настоящий момент времени допустим у вас были проблемы все вообще нагнулась загнулась и вам нужно понять что было в этот момент для этого достаточно просто включить к warlock по умолчанию он выключен исключительно ради того чтобы вы не беспокоились о том что вы из какого то сервера только читаете делаете select и но все равно какие-то таблицы записываются но нет никаких проблем чтобы включить его на продакшене везде а по умолчанию и на наших production сирах коверлок в обязательном порядке включен но если хотите отдельно можно и на сайте у на запрос включать и каждый запрос лакируется два раза когда начал выполняться и когда закончил ясно интересует что происходит с кусками данных там мерц и insert и скачивания с реплик есть системная таблица портулак ее можно включить в конфигурационном файле она тоже по умолчанию выключено с помощью говорил о как раз очень удобно и его использовать вместе с treehouse benchmark вы берёте и делаете select прямо ленты запросов какие у вас были а потом отправляйте ее вместо днк house beach park или скажем очень удобно пак веры логу найти какой-нибудь первый тяжелый запрос после которого система стала работать недостаточно хорошо и зачастую вам нужно все-таки прямо сейчас посмотреть вот прямо сейчас вы хотите выполнить запрос то непонятно что он делает для этого есть возможность трассировки запросов появилась недавно наверное пару месяцев назад просто выставляете в клиенте gas and lock словил trace и вы получите логе выполнения всех со всех серверов участвующих в обработке запроса посмотрим как это выглядит на действует что-нибудь вид вот запрос выполняется но быстро доходит до 98 процентов я хочу понять вот что он делает в эти оставшиеся там моменты времени и это очень просто я набираю send лог-файл trace значит выполнять и выводится куча какого то мусора но наконец-то with a virgin агрегат отдай то я успел заметить и именно это он делает оставшийся один процент времени и так раньше вы об этом дачные дома теперь все это понятно а еще в этом блоге вы вается идентификатор запроса и его можно использовать чтобы найти его прямо в каире логе давайте посмотрим select from систем коверлок вот этого запроса 2 записи правда теперь трассировка лишние я его отключу до 2 записи и теперь выберу а что вообще в этом кавере логе есть это выбрал и тут всякие метрики выполнения запроса типа количество раз когда файлы были открыты количество сжатых блоков количество попаданий в кэш засечек ну все такое и значит есть некоторые щечки и ресурсов прямо внутри cliff house of во-первых они собираются глобально для всех запросов и доступны в таблицах system events метр x и asynchronous metrics events это просто инкрементальные щечки типа сколько раз был были открыты файлы 100 раз или сколько раз сколько запросов было выполнено с момента старта программы 10 штук а систем меттрокс этот количество одновременных событий прямо сейчас например прямо сейчас одновременно выполняется 10 запросов которые используют в сумме 10 гигабайт памяти а система asynchronous metrics я кстати назвал это таблица так из вредности потому что очень сложно набирать ну ничего я как бы принципиально так что сейчас вот из вредности каждый раз набираю это с трудом это те метрика которая просто с какой-то периодичностью собираются скажем раз в минуту и все эти все . они доступны не только глобально но и на каждый запрос то есть смотрите шоу процесс листа там я счетчики для конкретного запроса смотрите коверлок и там тоже для тех запросов который выполнен из будут эти счетчики посмотрим какие они есть они есть те которые собирают сама программа например количество открытий файлов ведь мы же знаем когда мы открываем файл именно в этот момент . инкрементируем а есть те которые собираются из ядра linux гораздо более продвинутый это то что ядро linux думает про нашу программу честно говоря я даже не хочу думать что она думает про нас ну а затем не веришь считает сколько мы прочитали байт и тут есть совершенно разные метрики вот скажем о ice ride chars и ios рид бойцы чем они отличаются первое это то сколько вы прочитали байт с файловые системы причем часть этих байт могла быть прочитано из каша и реальность диска не читалось а второе это то сколько по-настоящему байт была прочитана блочных устройств дело в том что операционной системы старается реализовать каш максимально прозрачно чтобы вы просто читали из файлов и не знали откуда оно читается но к счастью все таки из ядра можно напрямую получить более подобные метрики которые нам просто так не дают просто так мы об этом не знаем давайте посмотрим как это выглядит вот выполняем какой-то запрос выполняем вроде ничего почти 40 миллионов строк секунду 6,7 секунды ну нормально теперь кстати эти данной фейковые я их специально испортил выглядят конечно странно выполняем то ставим второй раз и теперь всего лишь 1,3 секунды этого сколько в 5 раз меньше ответ почему очевиден я думаю для всех потому что второй раз использовался пичкаешь но как мы это можем понять из наших счетчиков для этого выполнен такой запрос он не очень простой ясно что потом сделайте скриншот и вот все наши метрики первого запроса там например было написано что при выполнении запроса был выполнил один запрос какая-то тупизна но она есть для полноты но есть и полезные метрики что было прочитано байт с диска 3,2 гигабайта а количество байт из файловой системы два с половиной гигабайта кстати интересно что на этот раз с диска была прочитана больше чем мы хотели а почему ну гипотеза например из-за того что во-первых есть ли доход то есть операционная система когда вы захотели прочитать мало данных она на всякий случай прочитала больше вдруг пригодится во вторых с диска мы можем читать некоторыми минимальными секторами типа 4 килобайта и ясно него ну или 512 вместо того как настроено и астане выровнена было то немножко хвостиков лишних про читается но тут скорее всего из за ледоход разница 1 2 запроса так это у нас был первый запрос тогда первый запрос но эти метрики будут уже другими и том что запрос стала быстрее четко видно по этим данным то есть отличается во первых рид бойцы количество байт который реально прочитано с диска было два с половиной гигабайта я даже 3 гигабайта стала всего лишь 3 мегабайта я кстати не знаю почему не 0 но это почти ноль нашу метрика и уэйд восемьдесят семь секунд тоже интересно вот запрос выполнялся 6 секунд ну почти 7 секунд а и a weight восемьдесят семь секунд почему почему да абсолютно верно много отрядов это считается на каждый thread то есть каждый thread ждал пока его данные с диска дадут и в сумме это получил сто восемьдесят семь секунд во второй раз мы вообще почти не ждали чего-то есть но какие-то миллисекунды другая интересная только это сепию white это не то время которое процессор использовался это то время когда наш поток был готов чтобы операционная система начала его выполнять на процессоре но операционной системы почему-то не давала его выполняться например потому что было больше потоков то есть голодание сепию но в данном примере процессор потоки не голодают посыпаю все время когда они готовы выполнять какие-то инструкции они их будут выполнять и все нормально и в качество дополнение еще есть простые метрики это время процессор но и время потрачено визор спейси почти не отличаются но во второй раз почему-то больше и я не знаю почему ну и ладно и процессор на время потрачено в ядре linux если вы делаете системные вызовы и там внутри что-то сложное то это все будет учтено и причитание с диска естественно тоже там тратится немножко процессора на всякие там вспомогательные операции а теперь самая продвинутая что у нас есть твари 3d logo с помощью него вы можете понять на что тратила время каждый поток выполнения запроса я вот смотрю для моего запроса выбираю покоя иди и выбираю метрику количество процессор на во времени потраченного визир спейси и вот наши потоки хорошо вот наши потоки на 16 потоков была выделена для параллельной обработки запроса каждый из них потратил 800 миллисекунд а потом еще 16 потоков была выделена для мер дженга состояния агрегатных функций и на каждой из них было потрачено четверть секунды так что смотрите теперь я могу точно понять на что потратил время каждый запрос спасибо пожалуйста есть время для нескольких вопросов но там далеко далеко а мы тебе дарим запись твои выступления на кассете в хаос и похвальную грамоту класс этот лучший шутка за сегодня просто лед а спасибо за микрофон я пришел на эту конференцию я первый раз слышу про плек хаоса и хотелось мне задать такой вопрос больше не связан наверное структуры клик house блэк хаус как известно есть индексы есть наверное да а если индексы по колонкам а именно вот я такой извращенец сделал то таблицу в которой 200000 колонны вот как ко мне быстро обратиться допустим 2540 4 колонки для начала все-таки 200000 столбцов сделать не получится приказ не получится это сделать вас получится где получится а сколько получится сколько получится несколько сотен или несколько тысяч это нормально в принципе есть примеры где десятки тысяч было столбцов но это уже замедляет insert и то есть оно не совсем расколол нечно ориентированный под совсем-совсем не слов жаловаться на ориентирована по настоящему колонн корректируемой база данных как бы от мозга костей самая колориста активно которая только есть том что вы имеете ввиду она называется по другому бывают системы который называется как бы light коллом на это бойца к ним относятся скажем big the beach boys кассандра суть в том что они больше похожи на база данных для пола структурированных данных когда столбцы они динамически для каждой строчки строчки мог быть разные нам дано и просто упорядочивается по столбцам откликался все очень по-настоящему каждый столбец хранится отдельно в отдельном файле и когда вы читаете ток где выполняется запрос то нужно несколько столбцов и только эти столбцы будут читаться хорошо спасибо алексей привет спасибо за отличный доклад я обещаю тебе тоже попробовать все что ты показал вот у меня к тебе есть такой вопрос к тому о чем ты не рассказал скажи пожалуйста почему когда мы логах видим агрегатор слова или около того ли house иногда перестает отвечать на запросы то есть все текущие connect и подвисают новых он не принимает когда он выдает агрегате да мы имеем одну табличку распределенную по некоторым количеству ноты и вот когда мы делаем к ней какие-то аналитические запросы да мы видим такую вещь енота и нодди где бежит какой-то запрос при этом нет утилизации процессоров мы ограничивали 3d то есть он бежит всего трейдер достаточно свободных процессоров но тем не менее вот эта проблема остается тут возможно два варианта один вариант это на память я ступаете не хватает то и она не ограничена то все таки процесс будет убита вам киллером но перед тем как а вам триллер убивает процесс он еще может так немножко про тормозить систему вообще целиком то есть она залипнет на несколько секунд а потом ваш процесс убьется если нету свопа если есть факту все просим нужно отрицать нет ничего этого не происходит с памятью достаточно ум киллер не приходит но тем не менее вот при некотором запрошена несколько причин с вторая причина очень интересна эта особенность работы с виртуальной памятью в ядре linux который никак не мог они могут исправить потому что там фундаментальные причины это то что когда требуется выделить больше памяти то иногда требуется сбросить страницы с . ш а некоторые страницы с пачка шамак быть грязными то есть требуется обсе на диск и вот программа выделяет немножко памяти делает поить fold и в этот момент операционных систем может зависнуть на минуту и целую минуту сбрасывать данные с диска план если операционная система не висит можно рядом как и не простенький и вчера повесить то он будет слушать спокойно свой порт и будет на него отвечать oakley house не будет конечно я мог бы еще предположить что можно с особенность по использование сети в этом случае вы это заметите сразу у вас остался в которого есть вы там нажимать пробел у вас через секунду курсов сдвигаться долго все эти пальцы закончились так стал ответ будет не знаю хорошо веком еще подойду алексей спасибо за доклад польше есть вопрос но он на самом деле не мой она мне уже задавали про cliff house мне указал что это очень хороший вопрос поскольку вы описали очень много на самом деле не стандартных настроек которые нужно производить в линуксе чтобы клика вас работа оптимально плюс у вас все слушала есть еще ведро свою не было ли космосе у яндекса не у вас лично вот не было ли у вас мысли сделать дистрибутив linux который был бы заточен под house или какой-нибудь не знаю пакет поставить которые выставит правильные значения по умолчанию чтобы грубо говоря можно молодым админом дать сказать вот cherokee поставьте этот пакет и все будет ну и не знаю через пересчитайте сервер по все будет работать с хорошей производительностью максимально которые рекомендованы лучшему собака водами спасибо тут сразу несколько вопросов первый вопрос во первых есть я декса свое ведро ну на самом дела но я стал действует напасти подделываются правда сейчас связано версия этого ядра недоступна так что можно считать что снаружи его нет второе это не собираемся ли мы делать свой дистрибутив linux даже почивать утром специально под treehouse честно говоря до того как у нас как раз был на концерте я об этом даже подумывал но не сейчас сейчас нет сейчас принцип столько house должно работать на любом linux он даже работать не только на линуксе и лучше такого избежать потому что я со начать с этим возиться то потом проблем я крепеж и третий вопрос это сделать какой-то такой софт драйвер скрыт чтобы вы его запустили на своей машине он посмотрел все устройства которые у вас есть померил их и выставила оптимальной настройки пока нет мы к этому только собираемся идти сейчас у нас даже такая глупость что скажем максимум reviews of по умолчанию 10 гигабайт я запускаю ли house на своем ноутбуке и там училась 16 гигабайт от этого у меня был старый там четыре гигабайта и даже эта настройка не меняется спрашивается почему кликал с не может при старте сказать у вас четыре гигабайта памяти я уменьшаю настройку максим бриус уже до 3 гигабайт такого даже еще нет и честно говоря не знаю когда будет всегда доклад просто к и у вас очень классно сделано по точности вот скажите какие основные вещи вы используете и как вы профилируйте эффективность но и по точности то есть у вас очень много распараллеливания там есть данные передачи данных потоков поток данный которых использует как вы смотрите на эффективность это организациями честно говоря тут всё сложно но начинается все с того что я просто смотрела на сколько все распараллеливания когда я увеличиваю количество потоков и ясно она сильно отличается от линейного масштабирования при увеличении количества потоков до физических театр я смотрю почему и обычно там никаких сюрпризов нет просто какая часть 1 проливается на какая часть мы ее не можем распараллелить и приходится перепродавать алгоритм есть даже такие самые важные вещи которые были сделаны еще давно это в агрегации что мы не только агрегирует данные параллельного всех потоках потом и когда мерзнуть состоянием это же это делаем параллельно ну оценки есть какие то что такое хорошо и что такое плохо премьер ребенок при полимером работе надо и это видно уже даже я со просто запустить топ самый простой инструмент я запускаю топ запускаю запроса там на сервер 32 ядра 16 физических я вижу сначала 1600 написано все прекрасно вот а потом вдруг там написано сто процентов это длится еще там минуту я понял что вот это вот место она не оптимизирована я запускаю pr в топ и вижу что делается именно в эти моменты времени или я делаю gdb thread up like all back trace тоже все очень четко видно так хорошо щеткой угроз у вас есть векторное исполнении виктора конструкций насколько это вносит вклад вашу ложь ускорение это колоссальный вклад вносят все системы которые работают хоть немножко похоже эффективно на то как работает клика us пусть даже не так быстро-то в два раза мятная допустим виктор вайс вести себя вылетом к тебе есть все они используют векторные вычисления это просто то что должно быть в быстрой аналитической базе данных если вы как-то он них смотрите управление работает или нет инструментарий есть этого естественно поначалу просто посмотреть инструкции в том что во первых топе если это будет вектор завывать компилятор я посмотрю этот внутренний цикл захожу действительная стоять там инструкции с я значит еще более менее нормально и не слишком ли они по-дурацки выглядят потому что компилятор он не всегда электризует данное параллельно там может быть алиасинг аргументов или так называемый лук пилинг когда нужно начала цикла выделить человек выравните все такое спасибо спасибо алексей пассивы друзья apple детьми а книгу мы подарили человеку который мы ты сказал не знаю вот уже подарили у запада для пташки когда ответ не знаю мы дарим книгу понятно а вот там было человек как бывает алгоритм это выбрал за тебя а крошишь бывает так яндекс такси ты хочешь на хорошей машине она тебя об спасибо тебе большое было здорово прости а есть еще одна книга кому-то хотел подарить мне не все нормально еще одна дать книгу тому человеку который сам на человека клада сказал что как промахи загрузка данных из памяти вот так ушел ушел а так часто бывает ну ладно тогда не надо ты уже ушел а машинка приехала на то так далее никакого приза лишь какой приз все так обнимашка а не отдал давайте еще вот человеку вот вы из вконтактика почему потому что они просто использовать crack house и на больших а в больших масштабах вот вообще огонь"
}