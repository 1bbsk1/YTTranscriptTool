{
  "video_id": "cW9Vk85QEjg",
  "channel": "HighLoadChannel",
  "title": "Как мы создавали Data Management Platform в OZON / Евгений Чмель (OZON)",
  "views": 1838,
  "duration": 2247,
  "published": "2021-10-04T02:32:03-07:00",
  "text": "всем привет сегодня речь пойдет о нем и о том как мы и создавали относительно молодой проект и ему чуть больше двух лет мой доклад будет состоять из вводной части в первой части грамм описанию как мы его используем какой профит мы от него имеем и далее перейду к архитектуре давайте начнем так agenda что такое game pe первое 2 интерфейс конструктора сегментов ключевая часть и последняя это архитектура так что такое гимпи гимпи это платформа для построения сегментов пользователей с целью таргетинга ключевым понятием game pe является сегмент что такой сегмент сегмент это просто набор пользователи которые собраны по каким-то правилам все это может быть там use ради либо сашины в качестве фильтров может быть использовал город бренд категории либо поисковый запрос типу от формы с которой взаимодействует пользователь с озоном дальше у сегменты есть ряд атрибутов это dish ник какой то номер до название ты цель есть время x время экспирации сколько времени будет находиться пользователь в сегменте type тип где тип сегменты у нас есть два типа это динамический и статический дейт интервал фактически это два вида то это дата создания сегмента да и дата окончания когда его можно удалить и юзер кончите это количество пользователей в сегменте примеры использования сегментов да то есть что мы что мы делаем на их основе то есть в чем они участвуют в каких механиках это отправка нотификаций рассылка писем можем показывать какие-то баннеры этом страницы с товарами так так так же мы используем сегменты в ценообразовании через маркетинг и маркетинговые акции в принципе как бы любая механика может быть завязано на сегменты мы даже об этом не делаем иногда так изначально сегменты создавались вручную то есть как это выглядело поступало заявка от какой-то команды от менеджера там маркетолога в общем не не важно от кого да и разработчик начина выяснять там на таких данных сделать сегмент сюда куда пойти за этой информацией хартфорде вовсе логику в общем на это уходило очень много времени да и в какой-то момент заявок стало очень много и пришли к тому что нужно создавать конструктор сегментов то есть как-то ускорять процесс как слишком много времени и тратит тратилась на разработку ну и первый вопрос который у нас возникает то на каких данных можно строить сегменты выбор выбор как бы у нас был до это либо использовать данные tracker tracker скажем так сервис до которые ответственны за агрегацию пользовательских событий то есть принципе вся пульс польская история может быть и ее можно получить и сколько us of cherry написав какой-то запрос да и эти данные ивенты попадают в клик через tracker также был был вариант использовать из dfs как бы но какие-то там тесты до небольшие показали что принципе через паркете там выполнять запросы да как бы то время выполнения как бы она была там в 30 раз бы ниже вот так как бы в сторону даже то есть только у здесь был как бы ну такое самое быстрое решение в общем позже мы ну и и кликал см и стали как бы использовать это как бы самый первый источник данных для построения сегментов позже мы еще добавили потом потому что в ней хранилось информация по заказам раз в сутки выполняется выгрузка из ума с это ордер management system то есть 1 сутки мы выгружаем инфу по заказу вверх и принципе по этим данным тоже можно строить там какие-то сегменты там допустим по среднему чеку то есть что пользователь покупается там допустим за последние две недели там за последний год так далее ну то есть то чем он интересуется этом слайде представлена прям примерно то как о пользователе взаимодействие с озоном скажем так то есть из чего появляется события там пустим пользователь может там что то нажать да там посмотреть какой то товар то есть у заходит сначала на озон открывать там допустим какой-то интерфейс до какой-то окошечко там ждали это событие улетает в трекере потом попадает уже в клик если пользуется оформляет какой-то заказ это все летит у вам а из и потом раз в сутки это все складывается как бы верте q ну как это может быть как это выглядит для пользователя допустим нажал на кнопочку добавить товар в корзину там да и либо на портиком меню в выпадающем списке и дальше этот эволюции летит как-то процессе c и сохраняется далее интерфейс конструкторы сегментов когда менеджер решает создать какой-то сегмент да там допустим га маркетинговые акции или еще еще для чего-то там для промо рассылки то есть первое что первый вопрос который мы задается это она по какому ивенту нужно каким данным нужно отфильтровать пользователи здесь он выбирает действие допустим просмотр товара на пи пи пи пи пи пи эта карточка товара далее выбирает параметр категория и в качестве категорий допустим может выбрать там рыба и морепродукты также задаёт тип сегмента динамически что означает что сегмент позже будет обновляться раз в сутки правило выбирает интервал в выборке в примере это три дня можно выбирать до 90 дней мы просто ограничились специально чтобы сильно клик не нагружать и там и также может выбрать сегменты с которым пользуется не нужно будет исключить ведь когда он будет попадать добавляться в текущей сегменты все будет валить для условиям который выбрал менеджер после того как он накликал кондишен его то есть может посмотреть примерно что у него получилось если он нажимается кнопочка там создать все сегменты и все и дальше уже происходит building в целях отладки мы еще добавили такую фичу что можно было рассмотреть запрос который сформирует конструктор сегментов клик запрос у нас формируется также не только для клика списаны для верочке том числе так теперь переходим к архитектуре как бы гимпи вообщем как был в сухом остатке как бы если взять тогда состоит из двух таблиц это таблица 1 м которая содержит связки или таблицы сегментами которые ссылается на эти связки и вот здесь мы что такое связка у нее есть корневой элемент это таргет айди который объединяет сессии какого-то пользователя связки может быть принципе от отсутствовать гадюшник юзера но может быть там много сессий для деньги одна связка как один юзер далее пример того как выглядят сегменты то есть таблица сигнал со всего лишь две колонки день периоде это тот самый таргет который ссылается на связке связка нас владимир хранятся до и в качестве ключей этого jison используются а техники сегментов 66 и 365 под документы это поляр source это источник данных до которой выгоняя источник который инициировал создание сегменты и сансе expires это таймс темп то есть время добавления пользователя в сегмента и время экспирации когда пользователь должен вылететь и сегмента как это выглядит то есть менеджер создает сегмент потом к сегменту происходит от touch расписание создается расписанию с условиями сборки и все это выполняет importer и далее importer на основе расписания порождают задачи периодически и на пире сборку сегмента здесь представлен пример определение фильтров да то есть это лесочек фактически здесь два фильтра они выделены в красненькими квадратиками а и b видите вверх самом верху это формула она говорит что нужно будет эти два фильтра потом объединить то есть они по ним формируется запрос в клик получается потом возвращается ответ видео нижников да и далее importer выполняет мир полученных результатов и получаем из результирующий набор сохраняет под каким-то сегментом пример запроса которые может быть в клик для одного фильтра вот таким как это пример простого запрос они могут быть очень большие мы пробовали делать как бы посылать строить один комплексы такой запрос содержащий несколько мелких он выполнялся очень медленно да то есть в принципе решили лучше делать разбивку выполнять их параллельно а потом применять алгоритмы сортировочные станции для того чтобы уже там отсекатель не ненужных пользователей по формуле темпами мая борт вернулся и сервис консьюмер который выполняет real-time сборку сегментов что такой real time в нашем понимании это значит что пользовать этот сегмент настолько быстро насколько можно при получении ивента и из кафки весь консьюмер слушает разные топике разных сервисов до в частности и трекера у марса и других в общем и при получении или vento да он подвергается к какому-то процессе лудо и далее users добавляется в сегмент вот такая логика на кода более добавление пользователя в real time segment она постоянно hard ходится разработчикам то есть конструктора для этого нет еще операция которую выполняет консьюмер это меж сегментов то есть когда нужно сегменты сессии и сегменты пользователя объединить эти то есть это происходит это первый дефекации да когда это nano допустим и если пользователи не был залогинен до было только сессия мы не знали его его одышку но для него уже есть какие-то сегменты с теми а потом залогинился мы вычислили что для его диске есть какие-то другие сегменты в этом случае мы выполняем объединение этих сегментов если вкратце то так там несколько сложнее ну и как бы также есть задача это вернуть сегменты по use ради либо саша надеюсь к нам ходят сервис и отправляет use ради какой в запросе да и мы возвращаем им сразу все сегменты которые есть для данного пользователя так и также ей задачи то есть и вернуть всех пользователей из сегмента и выполнить пересечения различных сегментов как мы это делаем был так как сегменты мы храним в подгрести до в общем выбрать всякие жиров как бы не предполагается возможном то есть это сложена это долго в общем и просто экспортируем сегменты раз в сутки в клик и далее сервис деньки статистика api позволяет выполнять пересечении таким сегментом которых хранятся в реке пример за пример запроса в статье six api то есть допустим нужно получить cal количество пользователей в сегменте то есть он может попав по формуле простите то есть можно передать формулу состоящую из трех сегментов и получить пересечении этих сегментов на определенную дату как правило используется текущая дата еще еще примеры то есть можно использовать операции прели приоритизации даты приоритета круглые скобочки или допустим да получить всех для конкретного сегмента ну из запрос который формирует деньги стать и скорпион может выглядеть так вот если мы хотели взять пересечении трех сегментов он сформирует такой запрос то есть на вход принимает формулу делает такой запрос внутри него есть билдер запросов и возвращает пользователя принципе выполните все это довольно быстро ну и проблема с которой мы столкнулись большие джейсон и сегмента мы храним же сон и бы в какой-то момент сначала они не быстро росли гони это не сильно ощущалась но как бы потом уже стала чувствоваться и сервис темпе сервис ггц как бы так как у нас глисон и растут до иногда остаются сегменты которые уже не используются их нужно удалить в общем мы решили сделать сервис который будет чистить джейсон чеки время от времени сейчас он правда в разработке еще не готов носку скоро завершил он то есть он должен будет как то время время от времени удалять старые сегменты и в том числе удалять сегменты какие-то по требованию которые больше бизнесу не нужны то есть никаких акциях нет никаких рассылках не участвует да и сейчас получается у нас importer и консьюмер два сервиса пишет в одни и те же базы то есть один конструктор это importer и консилер для построения a real-time сегментов да и вот здесь как это выглядит сейчас то есть конструктор формирует матч на обновление то есть он пишет матчами сегменты фар формирует базис пользователя и получается на каждый сегмент формируется отдельный batch то есть сегмента обновляются не независимыми задачами то есть это не очень хорошо потому что получается на каждый сегмент нам нужно отправлять отдельных за запросы как бы и появилась идея группировать сегменты по юзерам обновлять сразу несколько центов за 1 absurd то есть за одну операцию обновления и этим будет заниматься 7 мин сварки сервис тоже сейчас процессе разработки немножко осталось сделать совсем и как это будет выглядеть выглядит тобой так что imported будет отправлять пары сеть минтай де use ради в топик и сегмент консьюмер будет делать то же самое а бартер будет их вычитывать то есть и таким образом будет время от времени скажем так писать матчи в таблицу 7 езда ну и соответственно связки тоже то есть мы ожидаем получения какого-то там там профита ну и об общая схема сервисов она выглядит вот так в принципе я про них уже все рассказал так как бы такое самое большое и пробежимся еще раз что в говорю о тряслось то есть консилера используем для построения real-time сегментов да и для биржа день pr5 дает сегменты по запросу importer это конструктор сегментов да и плюс copy по добавлению пользователей в сегмент из любой сервис может повернуть ручку и добавить на даче юзеров сегмент экспортер это экспорт сегментов клик стати секс это получение пересечении и пользователей сегмента гоца это чистка до цель с целью уменьшения веса на чем меньше джейсон соответственно тем проще учитывая быстрее и переписывать мы переписывать же сон когда тогда когда нам нужно обновить хотя бы один сегмент для пользователя worker эта группировка сети сегментов по юзеру в бочке с последующим обновлением так первая проблема с которой мы столкнулись это частая смена сессии их очень часто меняет тестовый аккаунт и то есть из за этого стола притормаживать операциями ржа сегментов потому что возникали очень большие связки в общем ну как мы это решили мы поставили и лимит на количество адэшников такой связке немножко изменили алгоритм нержа об этом нужно помнить что принципе могут быть пользователь который очень часто меняются сессии второе в общем когда у нас был один мастер содержащие как в котором хранились сегменты да то как бы мы довольно таки быстро уперлись его лимиты нас инфо инфо и выставлены лимиты пустим на тот же диск то есть мы можем писать там то есть у нас есть ограничение на 17 к iops то есть выше его под поднять он не могут попасть на печен of the thames в случае допустим падение одной из нот чтобы можно было быстро восстановиться того поднять еще один из вас gresso другой тачки на чтобы было было достаточно ресурсов как бы эти ограничения общие для всех так ну и так как таблицы были большие до в общем мы время от времени стали вынуждены были выполнять побери пак для того чтобы сжимать таблицу 70 она росла репак выполнялся не всегда успешно длился 2 4 6 часов то будто как запись была очень активный принципе нам приходилось вообще-то записи останавливать практике ну и мы решили пошариться на 12 март принципе это помогло еще одна проблема это лишнее перезаписывание сегментов то есть вы на это на этом рисунке по вертикали это дней запуска об обновлении до а по горизонтали это это и каждый квадратик это грубо говоря день и и первый день мы убираем 90 дней допустим да во второй тоже и каждый раз клик и house про проходился по всем этим парте центом у него парте цианирование под по дням и на это и каждый раз он возвращал очень много пользователей и всех мы сохраняли очень плохо что мы сделали мы стали результирующий набор с пересекать пользовались набором пользователь которые имели хоть какую-то активность буквально за последние два календарных дня это помогло немножко метрик до шар деньгам и имели такие показатели по epson еллоу ты веришь оранжевый график оранжевая полоска на верхнем графике это мастер уперлись в лимиты всплеск справа это экспорт клик лоты в edge у нас вот таким был да получается у нас 12 ядерно каждой точке после шоппинга у нас получилось что-то по таблице 7 разнеслась и а дима стала седмица едем об стали храниться до как бы в разных местах да то есть здесь айди map и опции нет ой простите не достигает даже 3 до принципе это норм всплеска это тоже экспорт клик для нас это нормально но таблицах на серваках signals и abs и у нас принципе там на мастере не примерно 5 к до потребления на репликах там три ну и его решено соответственно такой на мастер реплики количество апдейтов до примерно на двух с половиной трех к на мастерах в секунду в выводы какие мы сделали первое что закладываться на real-time сборку сегментов то есть по сути это подтягиваем попахивает лямда туры то есть в этом случае надобность пересборки практически отпадает у вас второе что чем больше джейсон тем сильнее ощущается деградация скорости у нас есть экземпляры темп 11 килобайт как бы если помните что большие джейсон и подвергаются механизму то стинга то есть пожгли создает отдельную табличку тостадо которая хранит уже это в лесочке по 2 килобайты примерно разбивает эти фактически у вас одно поле джейсон может быть на несколько страниц разбитого как бы ну не и неё не очень хорошо но для для нас норм обновлять сегмента лучше матчами окей ну мы также экспериментировать по срочным моделью данных то есть нормализованный когда хранились и бинты в одной строке они в лесу на данный вариант приз пищу как бы потому что вы в в этом случае вы можете столкнуться сильная фрагментирован ностью данных то есть если мы и селекции все сегменты с джейсону там это может читать 5 страниц допустим ну в лучшем случае 1 а если он будет нормализованная модели у нас там будет 307 это поможет нам прочитать и 50 и 100 и и больше то есть ну и последнее когда лучше несколько маленьких таблиц чем одна большая то есть грубо говоря сша sharding лучше делать потому что это проще обслуживать спасибо за внимание всем оси выявление вопросы спасибо евгении суда кварта меня такой вопрос при использовании шарден га возникали ли у вас проблемы с не только выбором сегментах но и допустим с их сортировкой или таких задач еще не стояло сортировкой вы смотрите наш шар ник у нас фактически мы его делали на клиенте то есть мы сделали посла там получается под по таргитай ди маре реализовали под таргитай дину принципе проблем никаких не было то есть мы даже за ложились на балансировку что потом можно было как какой-то слот перенести там новую моду как бы с сортировкой но данные не сильно фрагментирован и у нас там грубо говоря используется и you did the targeted это юдит они разбросаны по таблице понятно тогда еще одну дополнительную вопрос если можно когда вы формируете baci для актеров вы подбираете юзер как-то релевантная или они просто услуга по очереди идут смотрим мы получаем пользователь допустим из клика то и доли и дроби на bacci ну для юзера димы призови этот паркет айди да то есть если его нет мы создаем получается создается в клиентском приложении то есть генерит и далее в бочке когда он управляется используется сортировка еще то есть мы их сортируем затяну в во избежание де блоков то есть если не сортировать то можно ставить дизлайки как бы мы это и словили вначале как бы так спасибо за доклад вопрос такой у нас есть сегменты который подклеили сжат мы достали юзеров из клика а вот дальше как у вас происходит то есть мы назначили код сегмент пользователь теперь нужно отобразить для него fronte там какую-то планочку либо скидочку то есть это куда-то должно пойти дальше по стрелочке ну смотри как сегменты лежат в прогресс если нужно по сегменту выполнить будет применить какую-то там акцию даты и мешаем баннер показать скидку да то есть это этот задач уже другого сервиса то есть у нас ходят какие-то сервисы другие там все весы связаны с маркетинговыми акциями там еще чем то там рекомендательные из они получают по use родили бы пососи сайт сегментов в общем и далее там как-то это применяет у себя это уже сторонам глазками не касается вы только предоставляем сегменты вот вы назначили какой-то какому-то пользователю сегмент его записываете базу данных пользователей или вот или пользователь заходит на сайт у него по потоки ну либо там поедишь нику каждый раз идет в описку ваш соответственно для получения сегмента если там есть сегмент он ему отдается нет смотри пользователь заходит на сайт как бы там такой относительно gridlink короткий путь то есть он проходит скажем так через луг есть сервис такой называется composer в общем учить через него происходит там оба говоря скажем такой резак виджетов то есть поход там в разные вертикали то есть он это как бы его страница это там куча разных виджетов за каждый виджетом может разные команды то есть и есть возможность себя там поставить какой-то iv чек на конкретный сегмент для конкретного виджета ну и помимо этого чуть ли там еще и цену сделать да как бы и когда запрос проходит через этот composer да получается он идет в дивизии mpi передает нам юзера иди там либо сессию мы возвращаем ему сегменты также помимо composer а мозг уходят другие сервисы то есть как бы фактически гимпи это про то что просто создать сегмент сбил ведь и отдать эти сегменты по use ради либо сашины или вот так и к ротике вопроса почему не использовали для хранения сегментов описания что не специфично там для тайсона там типа типа магии почему в позвольте смотри тут классный вопрос да манги из коробки же шарден то есть вообще супер вообще изначально как бы там отцы-основатели день по общим чего хотели aerospike ну потому что быстро то есть как бы но не не получили о прав на него кто то сказал что тип одинарных как бы делайте типа пожгли что было был persistent манга как бы она в зоне не используется вообще то есть как бы под gris редис кое-где еще не так давно появился aerospike и принципе на этом как бы практически все кое-где там есть тарантул очень недавно там стали использовать как бы так что ну к сожалению с манга нет мы проводили эксперименты с мангой да вот конкретно наша команда принципе по скорости примерно тот же самый путь глэсс проводил получается мог new не очень хороший там на маленьком количестве сегментов с распределенными транзакциями ну а мангу у нас так как никто готовить не умеет нормальная и в несколько раз еще вел в нерабочее состояние как бы ириш перекрестились решили что короче оставим на потом нужно научиться с ней работать инфа не поддерживать ну вот так спасибо у нас онлайн вопрос ну кто-то хочет еще на экране задавайте какой завод лучше слышит так ну и что так не очень слышно было так ну вроде бы первый вопрос то на каких данных мы собираемся гнезда или сегменты мы собираем только на основе своих данных на только на собственном в принципе есть возможность подгружать один ники вручную но как бы клипа пользователь все а зоновские такого нет чтоб там какие-то еще каких-то еще и zero встроили кабинет узи ради как бы за генерации именно use ради мы не отвечаем то есть для нас вообще как брэда питта как был просто едешь к user1 происходит не менее это другая вертикаль делает там при регистрации юзера там ему назначается визе ради и все дальше уже умному как бы попадает как-то в game pe то есть когда мы читаем ивенты и сколько уса там либо и is where текке что-то selecting либо можно загрузить вручную айтишники через интерфейс да то есть но вот как то так ну причем как сегменты у нас есть паб анонимом принципе и пор не на него но папа планируем этапа сессиям как бы сказать сколько сегментов там мы построено не на пользу им я как бы не могу смотрите у нас получается нет интеграция с другими системами пока что то есть никаких там кубке sing of ничего такого конкретно нос вот такого нет спасибо спасибо азиль и последний вопрос спасибо за доклад скажите пожалуйста вот последнем вопросе как раз поднялась на тему которую я хотел уточнить как вы работаете с теми пользователями которые не дают согласие на обработку своей персональной информации по сути которых нельзя потрогать и которых нельзя добавлять в сегменты спасибо так то смотрите перед выступлением доклада как бы это все там оговаривалось как бы те кто используйте инструмент то есть как бы да там все нормально должно быть как бы это мой перед переживать не ставьте ведь мы не нарушать я вас обманул давайте еще и на вопрос вот молодой человек рвался в бой спасибо за доклад вас был пример фильтра для сегмента где выбирается просмотр какого-то продукта вопрос какой подходит время между тем как человек посмотрел продукт тем как он появился в в сегменте и его увидели сервисы которые должны его таргетировать так ну допустим он посмотрел продукт далее создается event какой тогда которую 0 попадает в 3 третьих здесь может уходить там допустим три четыре пять минут то есть в зависимости от нагрузки на tracker как только это влетела в клик то есть уже можно как-то это выдернуть и создать сегмент как только в день ты записалась сегмент сразу же можно его использовать у нас там никаких каши нету нигде то есть как бы очень кажется и в итоге как во время получается что ребекка вы какую-то таки время просто сказали проектом 35 минут сейчас услышал это попадание пользу пользователь что-то на сайте сделал полетел event то есть проходит как как там где-то тревожит около 5 минут и мы уже имеем только только после мы имеем информацию как на который на основе которой можно строить все сегменты бывает быстрее то есть бывает по разному вать прям моментально в среднем где-то 35 минут бывает очень быстро спасибо еще раз спасибо евгений поаплодируем подержим"
}