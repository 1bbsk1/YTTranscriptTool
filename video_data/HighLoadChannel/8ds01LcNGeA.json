{
  "video_id": "8ds01LcNGeA",
  "channel": "HighLoadChannel",
  "title": "\"Заряжай\" или CDC из MariaDB и Postgres в аналитическую СУБД MariaDB Columnstore / Роман Ноздрин",
  "views": 1070,
  "duration": 2233,
  "published": "2019-05-15T03:21:16-07:00",
  "text": "что у нас сегодня будет программе начнём мы с того что обсудим что-то чем в общем потом посмотрим где его можно применять и рассмотрим отдельные важные элементы схемы после этого перейдем к методам чиндо это крепче и обсудим какие методы существуют какие методы выгодно использовать какие не очень и перейдём в конце к обсуждению двух схем переноса данных из марии де беф каллум стар и из-под gresso в салон штор поговорим что такое чудище ты крепче согласно английской вики это набор методик и по поиску и отслеживанию изменившихся данных и возможно какие-то манипуляции с этими изменившимися данными пример который мы видим здесь это таблица в абстрактной су б.д. прошу заметить то есть на этом слайде мы обсуждаем очень что это крепче который может сильно отличаться от того что реализовано в движках у нас таблица состоящий из четырех колонок и мы модифицируем какие-то данные в них в этой таблице вносим данные обновляем и удаляем обратите внимание на цифры в скобках они показывают на то какое количество строк было за эффекта на этими операциями в результате работает черного ящика под названием чине что это крепче мы получаем список состоящий из изменившихся строк рекордов собственно для того чтобы понять для чего он нужен рассмотрим несколько примеров начнём мы с использование чень что это крепче для синхронизации данных в разнородных хранилищах например если нужно перенести данные из оракулов позарез нужна конвертнуть типы возможно сделать какую-то нормализацию все это желательно сделать на пути пока данные летят и 40 love по згрлс в качестве примера из своей практики могу вспомнить опыт индекса по переносу метаданных почты из oracal впо сгрыз об этом был доклад который в прошлом году делал володя бородина не тогда перенесли 100 терабайт метаданных так вот во время переноса был этап когда нужно было сделать так что продакшен еще работает production 40 лет production на пост грехи нужно отлаживать и желательно это делать на боевых данных чтобы при переезде не возникло каких-нибудь неожиданностей собственно что они делали они переносили данные которые были вставлены или изменены ворог лиза день в по сгрыз используя сторонний агент и собственно это и был метод этой был чужд это крепче примененные в этой области следующий возможный способ применения чинишь да это крепче ит аудит изменений то есть кроме того что мы отслеживаем что данные изменились мы также сохраняем предыдущие данные и возможно идентификатор того кто в неё справку моей практике был случай когда я работал в платоне платона это такой оператор платных дорог в россии дальнобойщики его знают здесь дальнобойщиков нету так вот данные были изменены одним из сотрудников имеющих доступ фактически он увеличил тарифы в сто раз почему это привело очень быстро баланс и пользователей хлопнулись превратившись тыкву и движение остановилось но не везде но система в общем испытала очень сильнейший стресс в первую очередь пользователи нужно было решить две задачи в какие-то короткие сроки восстановить значение тарифы на тарифов и найти пользователя собственно в схеме таблицы в которая содержала эти данные был предусмотрен триггерный чужды это крепче который позволил сохранять изме изменившиеся данные то есть предыдущие значения идентификатор пользователя который ты сделал соответственно проблема была решена примерно за полчаса без раскручивания бэкапов что заняло бы много больше несколько часов а для того чтобы прокомментировать следующий метод применения я нарисовал архитектуру узкого ярус которая занимается вычислением корней квадратного уравнения на заказ просто в практике не было подходящего случая поэтому давайте посмотрим на этот слайд в центре у них мисочку на нем висят три микро сервиса которые вычисляют все знают что такое справа у нас находится базы данных куда мы складываем результаты вычислений а слева базы данных в которую клиент заносит свои задания в виде коэффициентов и вопрос где вот здесь вот выгодно поставить чиндо это крепче для того чтобы ускорить процесс запуска обработки задач и клиентской да абсолютно верно мы ставим че что эта крепче здесь и таким образом почти в real time у нас данные задания клиента прилетают мисочку и мы начинаем расчет следующий способ применить чужды это крепче и этот же способ мы будем с вами рассматривать течение оставшейся части доклада более детально более развернуто это наполнение данными до этого р х а за это чем-то похоже на первый случай то есть синхронизации данных разнородных хранилищах но есть разница которая заключается в том что мы данные можем переносить не из одной базы не из одного инстанса а из нескольких инстансов которые могут все держать сортированные данные то есть да и ты warehouse выступает в качестве такого агрегатора и собственно в качестве примера который демонстрирует что вот здесь здесь и здесь у нас чините крепче находится могу вспомнить задачу которая только поднималась в яндекс почте как раз перед тем как я ушел оттуда она заключалась в том что по тем самым статора байтом метаданных которые были в почте нужно было гонять отчётные запросы поскольку архитектура яндекса в тот момент предусматривал отчет там порядка 100 шар дав с данными соответственно нужно было как-то либо собрать их вместе либо сделать распределенное выполнении запроса с последующей агрегации данных вместе было принято решение использовать единый да и ты warehouse какие там варианты были рассмотрены это не столь важно но я думаю все знают а и собственно вот эту задачку мы будем решать дальнейшем рассматривая схема но для того чтобы перейти непосредственно к рассмотрению схем я расскажу немножко про каллум star мария дебетовым star поскольку что такое мари деби сервер и я думаю слышали многие и используют что такой postgres и тем более не надо рассказывать про него знает еще больше про этот аналитический движок знают не многие в россии на западе он используется так вот это движок аналитический колоночный использующий методологии мпп который обладает приятными свойствами в частности он поддерживает транзакции поскольку в качестве одной из основных частей у него используется мария baby сервер то есть он поддерживает транзакции он умеет д м л апдейты дэвид и он умеет он умеет des bains join для того чтобы джо и нить таблицы которые не влезают в память кроме этого он умеет выполнять запросы к таблиц запросы в которых участвует таблицу с другими движками поскольку идеология мои секула и мария тебе известно там используются и джайны для различного war клода соответственно если в колу истории могут может ранить хранится таблице фактов большая длинная to die меньше на мы можем хранить вы на дыбе и тем самым мы ускорим процесс процесс вставки в таблице dimension of которые которые хранятся на и no debe кроме этого он умеет расширяться то есть пользователи по запросу аналитиков тех же самым могут писать кастомные агрегатные функции с помощью специального и пей он поддерживает фичи мария де 53 это поддержка синтаксиса oracle был сиквел и вершинину themes кроме этого он умеет большие поля тексты блок до двух гигабайт размером коротко об архитектуре потому что это нам понадобится в дальнейшем слева у нас один из видов модулей он называется user модуль фактически эта точка входа для запросов то есть запрос пользовательские попадают сюда тут же живет оптимизатор который составляет план исполнения и запускает тоски которые в свою очередь уходят на так называемый перформанс модули которые исполняют запрос и в то же время хранят данные то есть это сторож и исполнитель запросов фактически давайте перейдем к тому как это делают делают мне каллум stora делают женщины это capture один из методов получения дефо которые у нас выходил из черной коробке это получение дефа с помощью snapshot а у нас есть таблица там есть какой-то набор данных мы производим мы сохраняем этот набор данных как snapshot его сохраняет внешний агент после этого мы модифицируем данные данные модифицируются модифицируются данные вода не модифицируется мы получаем другое состояние данных и мы составляем другой snapshot опять же внешний агент внешняя программа накладываете 20 фото мы получаем тот самый дейв который мы видели недостатки умеет да конечно существует допустим а если подумать о том сколько времени или места нужно для того чтобы сохранить snapshot там на миллион рекордов достаточно длинных ну можно оценить масштаб проблемы понять что и ресурса потребуется в виде рамы и время понадобится много для того чтобы пройтись по всем рекордам и сравнить что изменилось следующий подход это подход с помощью кстати с помощью чего вот здесь вот будет реализован через dt крепче как вы думаете ну да времени чтобы где будет храниться время т.а. но это один из способов до этой версии это скорее к версиям но фактически и да вы правы это будет отдельная колонка которая в данном случае содержит скорее state но также тоже так же это работает ставим с темпом из версии соответственно что мы получаем после того как мы модифицировали данные мы получаем в этой новой колонки состояние которое указывает нужно ли обрабатывать эту запись если нужно то пришедший внешней агент с помощью нехитрого запроса может внутри себя получить тот самый искомый div недостатки есть и здесь во-первых мы имеем в первую очередь отложенных делит то есть мы не можем просто так удалить строку она скорее помечается как удаленное после того как агент пришел он сделал свое черное дело строка может быть удалена из этого следует что tranque поддерживается очень плохо скорее не как даже и важный момент для того чтобы этот метод работал нам нужно добавить колонки во все схемы во все таблицы которые будут участвовать чиндо это кэптен давайте к следующему методу следующее это триггер и sbd для того чтобы поймать изменения в данном случае на каждую вставленную измененную или удаленную строку вызывается триггерная функция в качестве аргументов этой триггерной функции выступают предыдущее значение и текущее значение то есть обновленная недостатки этого метода заключается в том что мы ограничены набором действий которые могут быть выполнены в рамках триггерной функции скажем в паз грехе при использовании си мы можем сделать очень много но если мы будем использовать пиль сиквел то здесь мы ограничены в наборе действий кроме этого триггерные функции обладают приятным в кавычках свойствам они нагружают дополнительно базу некоторые суды не поддерживают триггерные функции по событию тран кейт некоторые как postgres ограничено поддерживает и последний способ который я хочу рассмотреть который будет использован при решении задачи переноса данных в lab субд э-это журналы предзапись и журналы транзакций свободы мы опять модифицируем данные и в этом случае на каждое изменение у нас пишется запись запись в ряду или онду лог зависимости от того по сгрыз это или оракал или мальчиков мария дебит соответственно здесь у нас три записи которые соответствуют вставки удалению и обновлению строки и прошу заметить важный момент если определите или апдейте пострадала больше одной строки будет записей по количеству изменившихся или удаленных строк это важный момент в результате мы получаем тот самый div но результат наступает не сразу потому что до получения дефо нам нужно разобрать этот журнал записи этим занимается опять же внешний агент какой-то и из этого следует главный минус который кстати если кто-то был на выступление андрея бородина и володя лискова из индекса они там рассказывали про то как устроена вал сегмент достаточно сложная штука такая крипто во ii под grease не выделяется в этом по сравнению с другими субд e во всех субботы журналы пред-запись и это страшная штука которую можно сломать голову соответственно читать их достаточно сложно писать паркер и журналов также нелегко но у него есть неоспоримый плюс это асинхронный метод он отражает последовательность транзакций и он не добавляет нагрузку на суде то есть журнал будет писаться в любом случае только если мы его не отключили я но это совсем для всему убить наверно собственно после этих водных давайте перейдем к рассмотрению двух схем первая схема это про перенос данных из марии де беф сервера в лапка амстор ну как бы для того чтобы перенести данные из серверов которые обладают немножко различающимися типами данных нужно приложить не так много усилий но тем не менее первым элементом этой схемы кроме двух упомянутых является мария де by max payne про него я расскажу чуть больше на следующем слайде в данном случае он выступает как клиент асинхронной репликации фактически вытягивая записи берлога то есть после подключения в качестве сливок мастера к нему начинают течь события внутри макс call находится белок рутер что нам в этом случае не очень важно но второе в нем находится а врачи не ждите крепче рутер это по сути сирия сирия лазер который в конвертирует записи берлога в формат авра после этого нам нужно как собственно преобразовать типы данных привести типы данных к тем которые каллум штор понимает и наиболее эффективным методом записать в каллум штор и этим занимается 3 мин дейт адаптер из набора дейта адаптеров для mac скала он подключается с помощью специального и 5k max steel в результате к нему начинают течь события в овраг или джейсон это зависит от конфигурации и он производит внутри себя преобразования в типы который поддерживает каллум штор и для того чтобы эффективно записать он использует так называемый балкой пи балка рай t5 который позволяет нам записать данные минуя уровень сиквела напрямую в стороны то есть данном случае у нас не происходит ни парса не запуска оптимизатора который составляет план долга мучительно мы просто пишем в файлы данных используя мета-данные которые позволяют нам сказать что вот в этот файл безопасно писать сюда можно записать и это не повредит ситуации в этот же момент данные могут быть запрошены то есть в этот момент на кластере калым старом могут исполняться какие-либо запросы собственно расскажу про макс hell немножко это как я говорил сиквел прокси главным двумя главными задачами макс тела являются осуществления лот баланса либо ретро от баланса то есть читающая нагрузка идет на реплики если таковы имеются пишущие только на мастер кроме этого он обеспечивает хай вал ability в случае отказа из строя текущая версия макс колос ты бл она переключает автоматически пишущую нагрузку на мастер внутри себя и про мутит мастер макс колчин что это крепче дейта адаптер это утилита как я говорил которое конвертик либо и соврали бы из джейсона и складывает эффективно в каллум штор о нем особо говорить нечего это просто ада адаптер давайте рассмотрим недостатки этой схемы которые есть первый недостаток даже нет недостаток особенность которая заключается в том как организовать high availability в случае использования этой схемы последовательно рассмотрим отказ каждого из элементов и посмотрим что с этим можно делать я не рассматриваю случай когда у нас выходит из строя сервер потому что макс call обладает приятной способностью он автоматически осуществляет переключение и про mode поэтому мы перейдем сразу к отказу самого макс крыла для того чтобы пережить это нам нужно запустить вторую копию макс кайла который подхватит то место скатаем на котором предыдущий макс кайл вышел из строя в качестве временной отметке будет использоваться джей tedglobal транзакций найди который можно получить допустим из half-life статус это самый простой вариант кроме этого для второй версии макс крыла будет использоваться свой стриминге то есть мы не сможем за использовать тот же самый стриминга и который уже существовал кроме этого есть проблема у этого решения по переносу данных из мария де беф каллум створ схема не умеют и не шил snapshot то есть оно не может перед взять таблицу из мария де беф сервера и перенести все данные в каллум створ но для этого есть простое решение поскольку у кого мстера есть набор утилит и в том числе утилита которая позволяет с стандарты на просто читать вход то есть мы можем с помощью простого мои сиквел клиента подключиться к мария baby сервера отправить запрос на получение всех данных передать через pipe utility которая называется сеппи импорт сейчас и она все эффективным методом положит в каллум старт то же самое что вот мы бы хотели при создании мешал snapshot а следующий кривят это отсутствие средств для масштабирования горизонтальной пишущий нагрузки на таблицу в случае если у нас таблица имеет большой кит и большой tps то мы не можем подцепить несколько макс krylov для того чтобы размазать нагрузку то есть одна таблица 1 макс call даже если table сапорте церовани и самая большая на мой взгляд проблема сейчас который для которой есть решение которые я буду упоминать чуть позже она заключается в том что при переносе данных с помощью этой схемы есть некий orchid который который заключается в записи вот этих вот служебных полей которые вы видите сверху у нас фактическая таблицы состоящий из одной колонке снизу строка которая содержит набор полей которые будут записаны но это позволяет очень быстро вставлять данные в случае если мы будем откажемся от этого набора полей мы можем использовать для осуществления dm эля то есть апдейты и делита out of band подключение по audi би си которая будет выполнять непосредственно дэвид и или апдейты на базе вторая схема как перенести данные из под грессов колумб top тут у нас слева под грез 10 в данном случае справа каллум штор и в качестве промежуточного хранились мы будем использовать кафку сама эта особенность она позволяет сделать но кучу интересного с данными пока те летят из под гальцев каллум star нормализацию приведения там какие-то сторонние микро сервисы могут питаться этими данными общем все что угодно и разделим эту задачу на две части первая задача это как перенести из-под грессов промежуточное хранилище то есть кафку для этого мы будем использовать а фреймворков к connect который сделан конфликтам и для него проект где бет сам разработал специальный плагин этот плагин подключается в качестве клиента к одному из двух плагинов но теперь уже живущих на пол грехи это про табов или волку джейсен ну из названия понятно что они и звала приборы превращают либо в про табу формат либо в джейсон про табов если кто не знает это такой очень эффективный протокол сериализации эффективнее чем джейсон при хранении документов но суть та же самые собственно после того как клиент подключился к нему начинает течь события либо в овраг либо в прато buffy либо в джейсоне и следующим этапом мы складываем эти данные в определенные топик кафки перейдем ко второй части балета нам теперь надо перенести из кафки в колумб top при этом опять же приведя типы данных и возможно сделать какие-то нормализации в этом нам поможет следующий третий адаптер который называется кфк и юра оврат дейта адаптер собственно из названия понятно что он берет из кафки формате авра и после этого он перекладывает это всё в каллум штор после того как этот дейта адаптер который фактически является кафка концу миром подключается кафки к нему начинают течь события в формате авра или формате джейсон и мы с помощью того же самого балка и 5 райт записываем данные напрямую в пмм минуя промежуточные этапы парсинга и оптимизации в схеме не хватает одного важного элемента который позволяет нам очень сильно уменьшить объем самих сообщений которые поступают в кафку то есть сэкономить нам мест пространство и не турок бендлер и в то же время позволяет отслеживать все изменения схемы которые произошли на пост грехи и в качестве этого элемента выступает конфуцием а ряды же джесс 3 чуть такое это то место куда складываются описание схем лавра формате то есть это хранилище метаданных описывающих схему данных в подгрести в данном случае собственно важным элементом в этой схеме является плагин тибетцы ум который появился в ну скажем 15 м году он уже появился и его и идейным вдохновителем был проект бот литва то который в качестве пруфа в концепт написал один из создателей контента это open source платформа для создания чиндо это captcha для различных суде в качестве источников данных могут выступать популярные суп open source они очень судя по сгрыз мои сиквел манга oracle поддерживается через extreme там сейчас идет работа какая-то по использованию другого метода получения chen j и с версии 09 появилась поддержка м с сиквел он умеет и не шил snapshot он умеет топик роутинг это возможность агрегировать данные спарте цера ван их таблиц и складывать их в один топик кафки то есть у нас есть несколько партиций таблиц мы можем натравить на них разная кафка connect плагины и они будут сливать все данные в один топик и он умеет smt сингл месяц transformation это приятно его часть это возможность осуществить какие-то простые манипуляции с данными то есть если допустим а из числового идентификатора нужно сделать буквенный в полете то smt этот как раз хороший способ решить это не привлекая отдельных микро сервиса в этой схемы также есть какие-то подводные камни в данном случае давайте рассмотрим ситуацию аналогичную предыдущей схеме когда у нас выходит из строя разные элементы скажем вышел у нас из строя источник пожгли в этом случае мы не сможем использовать не один из элементов которые использованы в схеме с умершим мастером но мы можем подцепить параллельно первому мастеру и первому кафка плагину еще одну копию еще одну пару реплика и к ней прицеплен еще один плагин для кафка cannelle в данном случае когда реплика становится мастером и начинает продуцировать какие-то изменения этот кафка плагин начинает складывать данные в топик если выходит из строя плагин то собственно у нас есть вторая пара которая полна полностью возьмет на себя всю нагрузку к сожалению нельзя настроить переключение имеющегося плагина для кафка connect для того чтобы он мог одновременно просматривать и один сервер который был мастером и реплику и выход из строя дейта адаптера к сожалению придется от отслеживать внешним каким-то сервисом в частности в дальнейшем на слайде у меня будет упоминание об одной секс истории которая как раз упоминает о том что в случае выхода из строя концу мира который уже успел что-то подтащите сказки какие-то события но в то же время не успел их закомитить в базу в destination базу то у нас либо событие пропадают либо они будут проиграны еще раз соответственно нужен какой-то внешней сервис который будет отслеживать ту точку во время которой произошел отказ и начиная с этой точке надо будет проигрывать данные заново большая проблема эта схема не может работать с таблицами в которых нет либо прайма реки либо uniq и еще один из киева тов которые кстати возник у одной русской организации это был начать в чате разработчиков они столкнулись с тем что при обновлении данных out of line to с полей то есть у них был достаточно длинный джейсон они не могли увидеть в сообщении об изменении данные изменившегося то с поля то есть оно просто не пролетела знаете скорее особенность настройки под gresso и это можно решить двумя способами либо мы используем реплика 1 entity full на таблице которая позволяет передавать в вол записи как и предыдущее значение так и текущие значения и либо использовать стр а также другую стратегию хранения для именно для этой колонке которая будет использовать хранение out of line то есть в таблице для тостов в крайнем случае как и в первой схеме есть некий overfit который выражается в том что вместо одного поля мы будем писать в таблицу вот с этими несколькими полями но существует workaround как я говорил использование out of bank подключение в qaf ковра адаптере но это менее эффективно потому что к нам прилетает скажем 5 записи об изменении нам нужно выполнить 5 апдейтов вместо одного который был на исходной базе на этом слайде вы видите ссылки на секс истории которые описывают где тибетцы он был применен в продакшене и достаточно успешно а если кому-то понадобится если кто-то захочет поднять схему то можете воспользоваться этими ссылками где приведены рецепты как это сделать в частности здесь надо зоне материал правда на английском языке в котором последовательно описана настройка схемы с марией хочу сказать в конце что каллум stor это хорошее аналитическое хранилища которая предназначена для исполнения запросов анализа данных либо каких-то длительных отчётных запросов и если вы захотите перетащить данные из под глэсс и или марии де беф каллум старта можете воспользоваться одной из этих двух схем благодарю вас за внимание есть вопросы я вас слышим здрасьте спасибо за доклад такой вопрос про теперь вот у нас такой ситуации есть оперативная база на пастбище есть 2 х 2 базы по хранилищем 1 на 1 шифти другая соответственно тоже на пост грызть то есть вот таким вот из двух вариантов и режима работы этого плагина это можно разрулить то есть получается канады как-то только через кафку и как разрулить и вариант что например как бы одна система уже все всосала изменений а вторая нет либо там как бы сети из амазона мы легла ну то есть что угодно может произойти вот вот такую двойную как беседе синод работает или нет отработает и в данном случае может даже кафка не нужно потому что можно использовать фреймворков как оно там есть как источники так и senki так называемые песчинки для паз gresso есть в том числе и для раньше вто то есть он может скидывать сразу в redshift минуя кафку если это лишний элемент point спасибо большое здравствуй вопрос по загрузке данных если мы берем бинарный лоб как я понял последние варианты используют первую очередь его стараются брать если мы говорим о маске или или марии а если у нас выбран raw формат все современно все красиво все понятно что он сделает если туда приоритет стоит нет вот просто в берлоге прилетел insert и в данном случае он не будет выполнять но если я не ошибаюсь это настраивается в макс кайли в конфиге макс крыла можно указать действие которое предпринять на поступления данных в таком формате то есть случае чего я могу настроить систему что смотри прилетел insert сбегать к в базу сделай select по этому ключу и получить данное в нормальном формате нет это перегруз для mac skylon так интеллектуально не будет делать теоретически вы можете написать запрос в жирок которая просматривается и который является источником данных для разработчиков вы можете записать туда запрос и возможно это будет реализовано но в текущей версии the lip никак либо остановиться а поверх я что-то свое могу нет но как я говорю можете написать фич request и возможно это реализует все эти на данный момент технологии неприменимы для миксер или стоит реплика то что тогда парсить android но на самом деле это и есть на самом деле данные в марии типе они прилетают из того самого там на самом деле два источника есть в том числе и онду используется для получения данных поскольку он более авторитетен румынские ли он умеет получать в исмаэль секула для мои секула никто не проверял совместимость поскольку как вы понимаете мы несколько конкурируем но вы можете попробовать второй метод использования кафка connect своему я больше проникнуть а да эти прямо говорят что мой секула не поддерживают соответственно это можно сделать я просто думал вы про первую схему места изобретения велосипедов с разбором биологов можно попробовать кафку connect и в договоре и он прямо санду независимости до a statement у меня mixed или еще что-то да должен сам все разрулить до"
}