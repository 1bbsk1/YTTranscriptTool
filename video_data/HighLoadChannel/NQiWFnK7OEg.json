{
  "video_id": "NQiWFnK7OEg",
  "channel": "HighLoadChannel",
  "title": "Могут ли данные управлять аппаратной конфигурацией дата-центра?/ Павел Лавренко, Антон Катенев (РСК)",
  "views": 338,
  "duration": 2603,
  "published": "2023-04-28T06:10:46-07:00",
  "text": "Привет Меня зовут Павел и мы его коллегу в зале зовут Антон мы работаем в компании РСК мы больше десяти лет занимаемся суперкомпьютерами возможно кто-то вчера был на экскурсии а поднимите руку кто-то был кто-то был отлично супер Вы видели наши большую систему в Питерском в Питерском Политехе А сегодня мы расскажем провокационная тема немножко Могут ли данные управлять аппаратной конфигурацией у нас был спор с Антоном Можно ли вообще управлять аппаратной конфигурации но мы считаем что да Вот и мы поговорим о подходах к решению задач управления дата центра как я сказал мы больше десяти лет занимаемся суперкомпьютерами что такое суперкомпьютер это на самом деле кластеры сервиров которые выносом такие серверов как у вас но кластер очень тщательно оптимизированный и выполняются на нем разные научные фундаментальные задачи информатика физика высоких энергий решаются задачи инжиниринка строятся цифровые двойники Но на самом деле есть у Вас например обучение это тоже суперкомпьютинг и основное основная особенность в том что вам всегда мало ресурсов нашим пользователям всегда мало серверов малосоров мало памяти слишком медленные сети и в общем Конечно можно сказать что закон Мура не справился с удовлетворением всех желающих отличается тем что в основном там используется специальный способ решения задач так называемые массивным параллельные вычисления и Если сравнивать с облаком Где у вас размер задачи очень часто меньше размер одного сервера и вы можете упаковать много задач на один например виртуальных средах контейнер на средах то у нас размер задачи почти всегда больше одного сервера то есть одна задача может занимать десятки или сотни серверов и считаться месяц и это требует очень тщательной подгонки очень тщательной оптимизации даже случайно Забытый драйвер который делает аппаратное прерывание в наших задачах барьерной синхронизации можно дать вам десятки процентов задержек счета А это на самом деле десятки и сотни тысяч долларов за электричество и таким интегрированным комплексом нужно тщательно управлять это нужно делать конечно же в обычном соде поэтому у вас есть разные инженеры дефопсы администраторы сетей у них есть какие-то свои инструменты которые помощью которых они решаются вы задачи не всегда знает что делает сетевик и зачем а связи спецификой наших задач нам нужно правда выжимать максимум И мы бы хотели чтобы все наши системы управления имели максимальную сквозную интеграцию Вот это и будет предметом сегодняшнего разговора Какие же это могут быть аспекты на самом деле все для нас даже инженерные инженерные системы в цоде система электропитания система охлаждения это то о чем мы хотим очень тщательно знать потому что те кто Были вчера на экскурсии видели что в одной и вычислительные стойке у нас может быть 400 киловатт Электричество и неплохо бы знать эта нагрузка какая она сейчас если запас мощности дальше Мы хотим все знать о серверах а сетях системах хранения данных Извините а дисках линиях как все это соединено какие операционные системы какая у них конфигурация если там контейнеры в конце концов Что происходит с данными с приложениями задачами где результаты каким проблемам это приводит связи с комплексностью очень сложно сделать на старте правильную архитектуру действительно на нашем архитекторе при проектировании конкретного суперкомпьютера лежит большая ответственность потому что ему нужно учесть и посчитать сколько взять серверов Какие взять процессора Какой должен быть соотношение памяти на и процессора в каждом сервере Какая должна быть сеть и конечно же у него всегда ограниченный бюджет денег всегда не хватает Деньги всегда являются ограничением размеры суперкомпьютера а если вы хотите такую конфигурацию чтобы она была изменчива потому что алгоритмы меняются появляются новые наши заказчики которые покупали суперкомпьютер начинают хотеть использовать алгоритмы машинного обучения то сделать такую конфигурацию и не Сделать ошибку очень сложно помимо этого мы хотим чтобы Наша задача могли выполняться в разных содах то есть на разных суперкомпьютерах и здесь возникает следующая проблема Проблема потери контекста потому что в одном супер компьютерном комплексе одна система хранения она у него одна скорость она в одном месте в другом месте что-то совсем не так И вам как-то с этой потерей контекста надо взаимодействовать То есть Вам нужно изолировать вашу задачу от инфраструктуры Ну и в результате часто все превращается в хаос ваша система хранения заполнена какими-то огромным объемом данных администратор не знает чьи они нужно еще хранить можно их убрать с этой дорогой системы хранения на более медленную или нет и вот наш опыт привел к тому что для того чтобы подойти к решению этой задачи и создавать систему управления в каждом из доменов управление аппаратной конфигурации управления сетями управления данными мы выделили общий принципы и сделали для себя внутреннюю платформу платформа разработки приложения управления что же она у нас делает во-первых она должна внутри себя поддерживать знания о всех слоях инфраструктуре сетях дисках задачах данных она должна оперировать произвольными объектами потому что очень часто в момент когда суперкомпьютер как железо уже готово не системы управления ни даже модели данных которые будут обрабатываться еще не закончены Либо они будут меняться и вживую придется управлять чем-то еще эти объекты будут очень разного типа и они связаны совершенно разных топологиях сетевых электрических топологиях движение данных задач и поэтому мы называем такую платформу мульти доменной и нам надо как-то упростить везде вопс в этой среде ее конфигурация вот на примере который я буду рассказывать Мы покажем кейс зачем мы все это делаем И к чему как это нам помогает наш пример это будет система обработки данных в объединенном ядерном институте в городе Дубна по факту это самый большой в России один из крупнейших в мире ускорителей частиц точки зрения обработки данных это аналог большого адронного коллайдера в Швейцарии того который собирался уничтожить мир с помощью черной дыры Но слава Богу нас всех пронесло а новый ускоритель который сейчас готовится к воду в эксплуатацию называется Ника и его задача Так коллеги у меня почему-то сами прыгают слайды его задача воссоздать в лабораторных условиях ту материю которая существовала сразу после большого взрыва так называемого кварка галионную плату плазму но мы сейчас не будем углубляться в физику высоких энергий А мы будем говорить о тех данных которые обрабатываются и требованиях к суперкомпьютер как я сказал данных Очень много они сырые в огромных объемах и чтобы из этого шума извлечь для научной публикации что-то осмысленное эти данные требуются обрабатывать нужно собрать весь поток выделить из них точки взаимодействий проанализировать выработать миллиарды траекторий проанализировать выделить события опять проанализировать причем в основном весь этот анализ делается статистически и способов обработки на самом деле очень много современная Физика вариативно и у каждого свои точки зрения о том как нужно какую модель нужно строить Поэтому приходится не только получать и хранить но и доставлять данные для обработки только одной научной группе то к другой то убрать в архив то поднять все обратно потому что кажется что мы что-то посчитали не так вот цифры которые видны здесь это реальный поток данных с ускорителя который эксперимента который длится 8 месяцев в году каждое событие столкновения частиц порождает порядка полутора мегабайт данных и того мы накапливаем до 40 петабайт данных в год все это нужно забрать хранить и не убирать на ленту А как ты этим уметь пользоваться сегодня мы поговорим из про систему управления только в части систем хранения данных и самих данных и жизни что же нужно с нашими данными делать на самом деле им нужно быть в нужном месте нужно располагаться на эффективное исходя той которой достаточно для обработки эти данных не занимать дорогую нужно не занимать исходя впустую нужно где-то надежно храниться и при этом быть доступными для того чтобы выдернуться и начать считать Что является источником управляющего воздействия как вообще весь этот комплекс должен работать Но обычно это главный инженер у него есть главный архитектор у него есть разные коллеги где вовсе администраторы сетей баз данных администратора исходя и они проектируют оптимальную систему выбирают для себя инструменты и с этим дальше Живут но как я сказал из-за изменчивости требований такой подход очень сложный потому что вот вы спроектировали супер компьютер выбрали такие-то сервера поставили не поставили туда GPU вы купили такую систему хранения данных и тут вы занимаетесь заниматься машинным обучением оказывается что одного GPU мало их нужно несколько собранных вместе они должны быть определенным способом И вам нужно купить новые сервера А теперь он просто моментально убивает ваш Темой хранения данных и вы просто не можете воспользоваться теми же пью серверами которые вы купили вам нужно исходя тоже менять мы понимаем что задача управления она стала не человека размерно и нужно выбрать какой-то другой источник управляющего воздействия мы проверяем гипотезу что таким источником могут быть сами данные но вы скажете Хорошо как же данные даже самые совершенные API как же они будут управлять GPU или дисками У нас есть на самом деле решение и на этот вопрос Давайте поговорим чуть подробнее про характер данных наши данные пакетные то есть Они собраны датасеты у них есть свой жизненный цикл своя интенсивность использования свои требования к надежности и длительность сохранения на исходя что пакетная обработка не является сейчас уникальным особенностью суперкомпьютинга Потому что если вы работаете с машинным обучением Вы тоже сталкиваетесь С пакетной обработкой данные не стоят на месте у них есть поведение они постоянно куда-то перемещаются так пользователю Только бы работчику то где-то хранятся пытаясь занять все пространство вокруг и четыре системы мы разработали четыре системы которые всем этим делом управляют жизненным циклом наших данных во-первых это система дата менеджмента это система которая задает правила хранения дает API разработчику для того чтобы он мог определять цикла данных дальше Эта система датамолвинга это система которая перемещает данный между различными местами но перемещает непростым способом а на основании третьей системы системы правил мы понимаем что управление императивная то есть полностью с помощью команд не позволит нам решить проблему сложности и поэтому мы управляем декларативно то есть на основании целей мы устанавливаем цели которые должны быть достигнуты и система пытается оптимальным образом их их достичь И последнее это система управления системой хранения данных по запросу это та система которая позволяет распределенные по кластеру элементы диски собирать в систему хранения сложности нужной степенью надежности с нужной производительностью по сути создает пункты назначения для движения данных вот сейчас мы подробнее рассмотрим Каждую из системы под систему дата менеджмент как я сказал ее задача обеспечить движение данных ток пользователю только обработки ток хранения или вообще принять решение что больше они не нужны они уже убраны в нужное место и их нужно уничтожить очень часто мы перемещаем данные для обработки в другие дата-центры А такие дата-центры разные у них разные архитектура разные схд разные администраторы разные пользователи разные правила и данные по факту оказываются в гостях куда же их нужно положить какую исходя выбрать вообще если подходящая Как долго их можно там хранить как потом оттуда забрать на все эти вопросы система должна уметь как-то отвечать в датасету мы уже знакомились но хочется добавить что дата сет Это скорее метаинформация это владелец уникальной идентификатор это метаданные а сами данные хранятся так называемых репликах копиях данных которых может быть много но есть одна главная которую можно писать И вот Система менеджмента двигает их по по всей инфраструктуре а данные сами хранятся в репликах отдельно и могут иметь множество копий и вот эти копии хранятся в таких местах которые мы называем резервуары это могут быть директории это могут быть база данных это могут быть объектные контейнеры кивали хранилища то есть любое место где вам кажется правильно их хранить и реплицироваться между резервуарами они с помощью специальных компонентов специальных агентов которые называются даты муфферы дата мувера позволяют вам двигать данные разным способом это может быть команда копии команды sing это может быть массовое параллельное копирование или любой другой пользовательский метод который Вам удобен и по дороге эти данные могут быть даже преобразованы например зашифрованы Или как-то сжаты например мы начали забирать данные с с базы данных и по дороге Они уехали на кластерную файловую систему в виде зашифрованного дампа что это сделает datamover как я уже сказал в императивном подходе очень сложно поэтому система оперирует набором цели мы можем эти целям говорить разные которые определяют скорость работы системы обработки которая определяют максимальную стоимость которая определяет маршрут следования время хранения и позволяет например переместить кратчайшим путем данные нужно исходя то есть работает в итоге это так система дата менеджмента устанавливает цели какие-то она ставит сама какие-то ставит пользователь после чего благодаря всей этой многодоменности система которая видит Граф из всех возможных резервуаров репликами и путями вычисляет суммарный Вектор Как давно Как долго как заполнены резервуар как занят канал связи она на основании этого И множество других параметров принимает решение о том куда эти данные нужно передвигать они начинают передвигаться туда сами и конечно Эта система связана с системой выполнения расчетных задач и систему выполнения задач ждет в нужном месте чтобы эти данные приехали тем самым получается что система управления данными адаптируется к той среде который она управляет адаптирует данные и это с одной стороны снижает сложность постановки задачи с другой стороны позволяет вам минимизировать цену ошибки за выбор неправильной архитектуры Но это еще не все просто адаптация нам недостаточно как я сказал мы бы хотели заниматься формированием самой среды где выполняются данные и современные аппаратные подходы так называемые компонуемые архитектура позволяет вам с помощью скоростных сетей низкоротентных с одной стороны с другой стороны современных накопителей на протоколе современной графических ускорителей формировать по сути виртуальные сервера подключая любое количество дисков через фабрику собирать нужный уровень отказа устойчивости рейд и выдавать это в любом нужном вам апе будь это кластерные файловая система или кивалиохранилище То есть получается что в зависимости от требования Мы можем создать в нужном месте нужную систему хранения с нужной производительности Ну я приведу три примера это может быть специальная с хд которая подключена к каждому серверу вычислительной задачи для создания контрольной точки поэтому вам нужно очень быстро принять данные чтобы ее сделать и не мешать ходу вычислений но скорее всего на следующем этапе вычисления выйти данные можете спокойно удалить или это исходя для параллельной кластерной обработки M5 задача И тогда вам нужно быстрые ласты или это просто какой-то NFS который достаточно для резервного копирования базы данных требования могут быть очень разные и вот чтобы собрать такую систему хранения кроме аппаратных компонентов правильной архитектуры сетей вам конечно нужно обо всем этом знать о всех серверах всех топологиях связях дисках и вся экспресс линиях И на самом деле вам даже нужно знать о электропитании потому что собирая правильно отказоустойчивую систему Неплохо бы понимать от какого домена питание питается тот или другой сервер чтобы предотвратить отказ например на шине питания и вот в результате слева виден развернутый в интерфейсе инстанс такой кластерной системы то такой вот много-много ниток на самом деле эта система объединяющая десятки узлов все их диски собирающие группы собирающие серверов хранения объединяющий Это в одну большую параллельную кластерную систему И несмотря на то что она временно всё равно есть dashboard вы можете мониторить и видеть как она себя чувствует несмотря на подход такие живущие во время системы хранения могут быть не только короткой живущие Но и на самом деле их можно считать постоянными здесь нет проблемы с надежностью и вот мы гордимся тем что три нашей системы находятся в таком новом международном рейтинге А ее 500 самых быстрых систем хранения в мире вот я иду мне рядом в Москве и Питерский Политех находится в этом рейтинге с помощью нашего стека и я обращу ваше внимание что в этом рейтинге соревнуются производителей производителей систем хранения А те кто был на экскурсии видели что система хранения отдельно стоящие там нет а используются диски распределенные по всему массиву вычислителей Ну вот резюмируя как это работает в совокупности нам удалось объединить системы включающие за очень разные домены управления то есть делать аппаратную компонуемую платформу зная о том где Что Как расположена собирать системы хранения по запросу и построить поверх этих же знаний систему дата менеджмента которым умным образом двигает ваши данные и управляет конфигурации вашего цода какой результат мы получили вот для самого главного для самой главной задачи в Дубне эксперимента mpd который по сути создает виртуальный эксперимент ускорителя еще не построенного такой подход позволил запустить свою задачу из коробки на трех разных дата-центрах тем самым сократив больше чем в два с половиной раза время выполнения вот такой наверное супер автодевов по всем фронтам иначе конечно было бы смерть от попытки это как настроить запустить я отдельно отмечу что дата-центры разные принадлежат разным владельцам никакой общей конфигурации в них сделать организационно нельзя Ну вот на этом я хотел бы с кейсом остановиться на самом деле обозначить Что делаем мы это на базе нашей платформы управления Но если бы мы не привели пример Было бы очень сложно понять зачем мы делаем какую-то платформу управления и Ключевое про нее то что она для неё задача управления также находится в графе и функции управления являются просто еще одними объектами которые вы размещаете связываете правильным образом и наш разработчик наш дивопс наш эксплуатант решает нужно ему задачи размещает функции в графе а система сама выгружает это в Control Pass вашей инфраструктуры И следит за ее жизненным циклом это наверное была Главная задача которую мы хотели решить вот сейчас я попрошу Антона ко мне присоединиться мы наверное ответим на вопросы а потом чуть подробнее останется время порассказываем про про платформу можно только как-то сделать чтобы у меня презентации сама не щелкалась такая меня слышно Да мне кажется что Павел сейчас немножко волновался и забыл достаточно важную вещь сказать собственно говоря который отвечает на вопрос поставленный наверное самым названии того что мы сейчас говорим Как происходит собственно говоря вся эта связь от начала до конца и каким образом данный как все это дело происходит у нас на самом верхнем уровне есть некие с одной стороны вычислительные задачи с другой стороны у нас есть определенные требования к самим данным который говорит о том задача говорит Я хочу видеть эти данные вот в этом месте в это время потому что мне нужно их считать куда-то еще чего-то происходит потом или ином классе другой стороны система говорит о том что здесь стоимость хранения такая здесь такая здесь какой-то объем и что данные помимо того что они нужны еще иметь какой-то поведение Ну например двигаться из более дорогой более скоростной хранилки там которые используются как Скретч как какой-то кэш двигаться в какую-то более долговременную из нее двигаться в какой-то еще более холодную из нее двигаться допустим на ленту на долгосрочное хранение или вообще выбрасывается если они есть какой-то собственный поведение и все это вместе то есть с одной стороны задачу У нас имеет какие-то свои требования данные имеет свое поведение всех естественно складывается буквально смысле как вектора и на стыке всего этого дела получаются цели и система пытается эти цели удовлетворить то есть система есть некий общий Граф связанности то есть вот этот самый Граф состоящий из резервуаров состоящие из дата пафов которые между ними этот Граф он может меняться с течением времени но он более или менее так сказать остается в каком-то порядке и соответственно говорит о том что вот здесь у нас такая есть такая есть такая есть такая-то и данные в соответствии у них какая-то цель они но в чем Весь секрет почему такая интеграция и почему мы говорим аппаратной части Дело в том что очень существенное количество точек в этом графике то есть Тех самых резервуаров которые там есть они на самом деле физически не существуют Это виртуальные точки виртуальные резервуары это есть те самые системы хранения данных по запросу а что такое система хранения данных по запросу естественно тут все достаточно понятно То есть у нас есть какая-то система можем ее создать если у нас есть некий запрос то что создать как это выглядит обычно что кто-то приходит или какая-то задача или еще да вот мне наверное нужна такая-то файловая система потому что я что-то хочу там хранить но этот запрос обычно исходит от какой-то среды выполнения в классической истории обычно от менеджера задачи какой-то задачи потому что ей нужна какая-то и вот этот подход неправильный потому что то что мы сделали это то что задачи на создание исходя по запросу то есть вот эти запросы они происходят непосредственно самого движения данных данные хотят двигаться в какую-то точку и в этой точке возникает соответственно этот самый вопрос который хранит и таким образом система которая знает все обо всем она знает о дисках о серверах там этот самый она может в нужной правильной точке выстроить соответственно нужные системы хранения по запросу и хранить там те данные которые нужны хранить ровно столько времени сколько это нужно потому что в тот момент когда они туда уезжают система естественно если она больше не нужна Она разбирается ресурсы высвобождается и получается что таким образом у нас как бы само движение данных данные которые в системе существуют управляют вплоть до уровня дисков аппаратной конфигурации нашего власти это таким образом ответ на тот вопрос который мы поставили в самом начале так давай на вопросы Да отлично есть вопрос это значит кто-то что-то понял еще коллеги давайте сделаем так Спасибо вам за эту часть звук и у нас будет еще наверно задача сложнее чем строить систему управления суперкомпьютера у нас за лучше вопрос будет близок генерального спонсора от гпб ждем вопрос Здравствуйте Меня Степан зовут Тинькофф Гугл значит создал кубернета для того чтобы управлять приложениями декларативно А вы создали я не помню как это называется чтобы управлять данными вот не совсем Так у нас более генерализованные регистратор чем тот же самый пубернацию губернатор это мы в том числе управляемый губернатором тоже как-то это распространяйте в плане там ну платно Понятно поэтому сюда пришли чтобы об этом рассказать Дело в том что суперкомпеттинг такой анклав в котором мы варимся сами себе приходим на конференции рассказываем друг другу о том что мы примерно знаем И для нас этот новый опыт прийти в другую аудиторию рассказывать о наших решениях которые мы в том числе планируем делать вообще у нас был план рассказать немножко более подробно той платформе на которой построена Похоже мы по времени успеваем где мы не ограничены да то есть мы можем все это по общаться а если мы извинимся чуть-чуть левее нас даже увидят онлайн зрители Спасибо И у нас есть Следующий вопрос было еще вопросы не совсем поняла Через что вы собираете данные Агент какой-то и каким образом если допустим система хранения была одного производителя больше не производится детские сменились вот как низкого уровня Давайте объясню смотрите у нас естественно просто это тема которая трудно уместить только короткий рассказ система наших предполагает достаточно высокий уровень изоляции между задачами и непосредственно самими исходя которые есть и обеспечивает конечном итоге она обеспечивает подключение нужной задачи нужного контейнера данных в общем относительно независимо от того какая исходя из всем этим делом стоит если конечно самой задачи не все равно не все равно бывает те которые нужно как-то определенные исходы Но если у нас по мере движения данных сами по себе типа исходные меняются то вот то что мы называем дату мувера та штука которая сидит на дата пафи как и двигает непосредственно данные Кстати на одном дату папе может сидеть бесконечное количество этих дата муверов Они вообще говоря в состоянии делать не просто движение данных А как там Павел уже говорил состояние делает преобразование например не делают преобразование из одной из ходы в другой вплоть до того даже что например если речь идет о люстре там и допустим до оси преобразовывает из почек здесь директории данные например Киеве базу и наоборот такое тоже бывает и поэтому если у нас какая-то одна из хода появляется какая-то другая исчезает то по сути дела Все сводится к тому что мы должны создать специализированные которые в состоянии решить эти ситуации И преобразовать контейнер из одного формата соответственно другой формат большая часть контейнеров которые мы сейчас имеем дело оно Позже это просто поисков это связано с задачами которые есть наших клиентов но так как они постепенно начинают внедрять более-менее прогрессивные методы работы данных это постепенно становится ближе и ближе к базам данных там контейнерам кивелю там к стоит там подобных вещах в основном-то даос и там просто такие большие Киева рес стороже вплоть даже до того что В некоторых случаях это дата мувер который двигает данный на самом деле производит еще и вычисление то есть мы сделали такой маленький шажочек к системе управляемыми данными то есть грубо говоря если где-то кто-то в каком-то месте хочет видеть результат но этого результата нет исходные данные переползает то место где нужно результат и по дороге с ними происходит вычисление они соответственно это результат образуется Это для физиков которые всем этим занимается Дубне это было достаточно большой они достаточно сильно увеличили производительность таким образом до этого они такого не делали и у них была всегда вопрос А когда и Зачем нужно запускать те или иные преобразования данных движение данных собственно этот вопрос немножко отвечает когда вам нужен где-то результат в процессе этого дела произойдет преподавание сюда вода но подробно опять же мы по эту тему можем рассказать наверное как-то коварно здесь Наверное в таком общем формате сложно но мне кажется Ребята это прям заявка на серию докладов у компании Будут еще конференции в этом и следующем году и думаю эту тему обсудим со всех сторон И у нас есть еще вопросы наверное о тех кто еще понимает О чем идет речь Здравствуйте меня зовут Роман Спасибо за доклад очень интересно узнать что происходит если в дата-центре по которому построена соответственно модель Граф происходит какие-то Перри конфигурации но кто-то пришел передернул провод там поменялся система управления она вообще говоря решает очень много задач От данных включает себя достаточно большое количество элементов которые актуализуют информацию там виртуальных каких-то вещах Например у nvmek линках о каких-то там виртуальных сетях и тому подобных вещах вплоть до там если нужно виртуальных машин контейнеров там и задач которые собственно говоря работают на этих машинах То есть у нас есть полный достаточно связанный игра в которой показывают все что собственно в этом классе не происходит если кто-то пришел и выдернул какой-то кабель и что-то такое сделал естественно там все это отразится и Понятное дело что например если это затрагивает допустим исходя компонуя в которой были те компоненты которые от этого пострадали это когда будет просто перестроена буквально на лету опять же если было бы больше времени показали как это делается но в буквальном смысле Граф перестроится те диски которые будут свободные будут туда подключены эти диски которые отключились они так сказать ничего страшного не произойдет физически это будет небольшая просадка производительности Примерно там 30 секунд потом все восстановится и будет вот это то что произойдет Спасибо за ответ мы сейчас ждем Следующий вопрос А я пока спрошу от себя а Слушайте а сколько Вас ушло времени на построение этой системы из-за чего вообще возникла Эта мысль сделать объясню смотрите как уже Павел сказал самого начала супер компьютеры Они именно из-за того что это как бы не кластер а именно компьютер требует очень высокой степени интеграции интеграции это вертикальная снизу вверх от уровня железа до уровня там непосредственно высокого приложения там задач пользователей и так далее естественно когда мы начали этим заниматься мы столкнулись с тем что нам нужна система которая интеграцию обеспечит потому что существующие системы регистрации типа или там еще что-то они на самом деле горизонтальное они работают на каком-то одном уровне нам нужна была система которая вертикальная которая бы охватываю все и которые бы она регистрировала эти горизонтальные системы управления и поэтому где-то в четырнадцатом году родился Этот проект он уже неоднократно менялся развивался там сейчас уже вторая версия этой архитектуры и в общем-то он вот уже сколько лет наверное 8 Том Или ином виде существует именно как кластерная система управления для вертикальной интеграции построены полностью на графовой модели но это не имеет отношения непосредственно к движению данных вот тому о чем мы сейчас рассказывали и вот на основании вот этого мы сначала построили наши кампануемые и программное определяемые исходя который уже давно внедряем заказчиками которые даже попали там всякие рекорды это самые быстрые сходы в России вообще это случилось когда мы начали где-то года три мы этим занимаемся но уже где-то через год после того как мы начали этим заниматься до этого мы вообще не занимались готовые мы попали уже соответственно было 500 причем Наши все системы они в первых 50 находятся и достаточно успешно соответственно все это развивали И вот после этого возник вопрос хорошо исходя есть они делаются по запросу Это хорошо работает клиенты довольны у нас был двигаться дальше дальше Мы ушли уже выше на уровень менеджмента непосредственно данных сделали систему сначала там дата-менеджмента дата мувинга а сверху на ней построили систему которая пытается этими данными управлять на основе там всяких разных интересных вещей там типа правил давление температуры там так далее там все достаточно сложно и вот это заняло уже совсем немного времени потому что на основе подобные вот развесистый большой кластерные системы которые знает все обо всем строит большой Граф который позволяет понимать что где и как происходит когда все это кончится на самом деле создавать подобного разрешения достаточно быстро и просто поэтому на создание вот этой вот модели движения данных вообще всего это у нас ушло не так много меньше года где-то полгода до нормальной работающего прототипа и где-то наверное еще месяца 2-3 до 1 внедрения физически работает провести пример то есть физики которые работают в Дубне используют нашу платформу В разработке своего приложения оно находится у них внутри как вы используете openstack создавая свое приложение большого там Клауд провайдера также и физики используют нашу платформу дата менеджмента для разработки своего физического приложения по факту опираясь на него они думая куда им положить данные скопировать папки и так далее да мы предоставляем некоторые они соответственно этим да то есть такая Клауд система для удивлен сегодня вас наверно не буду спрашивать выложить ли вы это компьютер не очень много а у нас следующий вопрос хотел спросить какая часть кластера нагружается для расчета вот маршрутизации и создание вот этих вот виртуальных сходств Ну а на этот вопрос смотрите нужно ответить наверное тут разбить на две части то есть Первое это та часть которая отвечает непосредственно за систему управления это не очень большая часть кластера это то что мы обычно в своей среде называем головой этого кластера Но это зависит от размера этого кластера Ну где-то наверное это там меньше одного процента Наверное трудно сказать 1 2 сервера из тысячи долларов в зависимости от размера кластера соответствует голова занимает больше или меньше места она занимается не только управление с точки зрения нашей системы она занимает там ещё дофига других задач включая является ещё и логинсером и так далее То есть она много чего вы делаете Вот и в том числе часто она ещё является для небольших кластеров голова занимается ещё связи с другими кластерами то есть являются нужно Мне кажется вопрос был часть касается того как мы выстраиваем системы хранения данных смотрите то как мы работаем У нас специфические клиенты наши клиенты требуют очень высокой производительности и очень низкой латинности данных Поэтому если Вы заметили наш выброс хода достаточно специфичен То есть например люстру мы считаем за низкопроизводительную систему А за высокопроизводительную систему мы считаем смертонос который работает вообще там с Face Memo и так далее это все естественно требует очень высокоскоростного интернета то есть это минимум 100 гигабитные там это требует на самом деле если там естественно везде кругом SSD причём достаточно большие то есть мы делаем системы там до петабайтов в одном юните Вот но штука в том что при этом мы не используем и не хотим использовать штуки типа Цефа и там подобных то есть распределенных подобных конвергентных историй То есть это именно распределенные файловые системы у которых есть скажем так выделенные сервера на которых они работают то есть часть кластера выделяется в качестве серверов для распределенные исходы какая-то часть это честно говоря зависит от ситуации тоже так это исходя по запросу зависимости от того какая ситуация Сколько нужно считать что нужно хранить может пол кластера выделено там на исходы обычно соотношение где-то там один десяти зависимости вот есть задача разные задачи например где нагрузка на вот вывод больше чем нагрузка на счет Вот Но эти сервера как правило сами по себе это обычные счетные сервера то есть они не содержат никаких там специальных дисков и прочее все диски соответственно собираются для них со всего кластера Либо со специальных дисковых полок грубо говоря у нас ответ на этот вопрос такой часть кластера Ну не знаю там какая-то часть выделяется как некий дул из которого можно брать сервера для системы хранения часть дисков как правило это почти все диски на всех серверах выделяется как пол дисков Откуда их можно брать для создания системы хранения и вот эта вот система дата менеджмента определяет Где Когда в каком месте Ей нужны какие эти системы из доступных пулов собирает Все ресурсы которые остаются свободными они как правило уже лежат в пуле ресурсов вычислительных и соответственно могут использоваться для чего-то еще если эти пулы пересекаются поэтому может быть даже такая ситуация что клиенту выделяется для расчета стол узлов из них он может выбрать 10 узлов углами хранения на 90 считать вот такое может быть но вообще однозначного ответа на этот вопрос"
}