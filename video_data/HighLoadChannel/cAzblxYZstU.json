{
  "video_id": "cAzblxYZstU",
  "channel": "HighLoadChannel",
  "title": "Apache Kafka как основа для велосипедостроения / Николай Сивко (okmeter.io)",
  "views": 14589,
  "duration": 3254,
  "published": "2018-11-19T02:49:27-08:00",
  "text": "ради приличия представлюсь небольшой он был до какой-то поры админские потом менеджерские сейчас и то и другое еще и разработчики и в общем-то я хотел рассказать вам про кафку но про кафку вакууме рассказывать ну тупо просто поэтому я вам буду рассказывать про то что мы с ней делали и зачем для этого ну будем говорить про наш time series базу данных кстати кто пришел послушать про кафку чество а про time series уа классно короче про time series быстренько то как у нас их было много и мы захотели еще одну новую потом ну так как мы изобретаем велосипед надо ознакомиться с велосипед строением с историей и поговорим вообще как ваш базы данных делать раз уж мы свою будем делать почему мы для все это приделали кафку как-то так и наше впечатление от кафки в продакшене а она у нас год и определенно есть но и что мы обрели попутно для того чтобы ну так в контекст погрузить буквально на одном слайде ок метр эта штука которая целью найти проблему даже найти проблема нужен контент этот контент метрики метрики собирает агент он их засовывать какую-то платформу и по этим метрикам считают какие то ли рты ну то есть считает какие-то сценарии проблемы показывает у вас здесь сломалась там сломалась и в общем-то мы только за контентную часть берем деньги вообще платформа вне зоны наших интересов мы ее поддерживаем только потому что мы ничего готова взять не можем к сожалению и это как бы история вынуждены у нас это все очень весело time серию с точечки и так далее но с точки зрения бизнеса это вообще не интересно ну и чтобы понимать о чем речь платформа это состоит у нас из двух кусков это метаданные описание того какие метрики у нас есть какие у них есть теги когда мы их последний раз видели чтобы иметь возможность поискать потом по этим тегам по группировать и соответственно метрик старт это где живут ключ метрики таймс нам значения и соответственно у нас изначально там лет 5 назад была самая простая база данных на кассандре куда мы вставляли точки просто вот метрика вот times stanford значение многие считают что мы до сих пор так делаем на самом деле это не работает это дико просто дико производительность точки зрения записи но это очень дорого в хранении потому что то кассандра еще хранит на каждую запись еще и там 100 мм для разрешения конфликтов ну и в общем и очень медленным на чтение то есть если нам нужно в для одного графика прочитать 5 тыс метрик нам нужно сделать пять тысяч запросов кассандру это как бы ей очень тяжело кассандра это в райт only сторож мы решили что мы возьмем и будем метрики накапливать и только потом писать кассандру с большими пачками мы сделали штуку которые в памяти это накапливает называется ты чанг это одна метрика данная 240 точек с минутным разрешением мы знаем интервал нам уже не нужно хранить time stamp 240 по восемь байт лотов и соответственно мы это можем даже пожать это даже как-то жмется и записать это в кассандру причем сделали так что при каждой точке мы перезаписываем целиком весь чанг соответственно так и храним это в памяти ненадежно мы сделали такую штуку чтобы не читать чанг при при записи мы сделали если у тебя этого человека в памяти нет сделай новую версию добавь то точку и запишет еще будет пустой а при чтении мы все версии берем имиджем соответственно получили мы из коробки от такого простого хода десятикратная где-то сжатие по месту мы чтение ускорили реально там практически не на порядок но в несколько раз точно при этом мы увеличили нагрузку на запись в кассандру то есть у нас в начале этого ну то есть все эти танки были синхронизированы и начинались в одно время соответственно в начале этого чанг ко чанг ку стоим хорошо зажат потом когда он начинает переписываться перезаписываться и так далее у него соответственно растет размер даже по сжатого и мы получаем такую пилу нагрузки на диск которые генерируют кассандра соответственно если кто знает в кассандре можно было бы уповать на то что апдейты бесплатные потому что они происходят в памяти но на самом деле эти чанки пишутся еще и в коммент лог это такое в кассандр русский вал и чапман происходит не только по размеру того что комменты был кончился но еще про то что 8 гигов комет logo кончилось parov ложится вне зависимости от того что там все хорошо и соответственно понадобилось экстра память надо для того чтобы эти чанки накапливать но при всем при этом мы тратим эту память но из неё мы читать не можем потому что пресловутой версии для того чтобы прочитать надежный человек нужно достать все его версии а их может вообще то в памяти на не на любом узле не быть соответственно мы как бы оставили пока это в таком виде дальше реинкарнация этого всего мы просто укрупнили чанг есть в один человек мы начали класть не одну метрику а много критерий того что это все можно положить в один большой блок то что эти метрики генерируется из одного места то есть они мы их получаем допустим это request и которые из одного лага посчитанные но у них разные допустим статус и или разные баки ты гистограммы и они же читаются соответственно рядышком все вместе поэтому у krupnye всю эту историю мы получили еще больше сжатия потому что у нас большой массив данных и того что там будут ну похоже и байтики на условно там не вдаваясь в особенности компрессии и мы в несколько раз вскоре чтение потому что когда нам нужно прочитать 5 тыс метрик как правило это означает что только тысячу таких чанков нужно за 1 достать но иногда как бы мы увеличив что-то точность выборки потеряли иногда мы читаем лишние но это в принципе не большая проблема ну и собственно идея которая возникала это что мы с этим пожили мы захотели все-таки это исправить мы решили что мы хотим данные хранить последние последние сколько это часов данных уметь хранить в памяти и хранить надежно то есть надежно чтобы признать показывается что это записан на диск а лучше на несколько дисков и что можем поднять и одновременно держать несколько более менее консистентных копий для того чтобы там переживать отказ железа и так далее и так как мы хотим попутно убрать нашей версии мы хотим оттуда читать мы хотим читать не из кассандры все как всегда мы читали мы хотим хвост читать из памяти а более такие исторические в кавычках данные мы хотим читать из соответственно уже кассандра и мы их можем тогда убрать вот это вот перезапись эти апдейтов кассандру ну и соответственно начали изобретать свой велосипед и для того чтобы правильно изобрести велосипед нужно понимать как вообще база данных работают любой базы данных есть вал он может называться ряду лак он может называться вал чистом виде но условно это лог в которой записываются все изменения для последующих про игры вания попутно эти данные когда происходит нас изменение данных изменяются в памяти базы данных mais quel и это buffer pool в подгрести то шарик баффер сна в общем-то смысл один и тот же что у вас память и есть snapshot of самых актуальных данных но еще они есть валя овдовев да это файлах их пока еще нет потому что их очень дорого писать туда синхронно поэтому мы их запишем потом когда-нибудь и вот для того чтобы переживать крэш когда у нас в памяти данные есть но мы их еще надо найти файл они записали и нужен вал соответственно мы стартуем мы понимаем да какой тачки у нас все данные есть да это файле и соответственно с этой точки мы знаем отметку овцы отвали от куда нам надо данные проиграть чтобы соответственно все восстановилось и это как бы вся эта история в базе называется чуть-чуть point соответственно к еще вал ну по крайне мере в пастбища в чистом виде на нем построены репликация мы этот все поток изменения передаем на реплику и соответственно реплика его у себя применяет получается что у неё синхронным как бы что у нее есть копия всех изменений в москве ли это как бы через отдельный урок сделан но неважно так вот соответственно в базе какая про самая простая схема если говорить про распределенности есть некие праймари мастером супер его нельзя называть уже это неполиткорректно влад есть реплики которые читают поток изменений и могут обслуживать чтения очень важно что между ними есть задержка это все происходит не синхронно в какой то момент мы клиента отпустили успешно приняли его транзакцию он наконец получил лог все хорошо а на реплику эти данные еще не доехали но если мы говорим про синхронную репликацию соответственно пишем мы только в праймари есть процедура промоушена любой реплике в праймари это соответственно всем известно но как бы вот соответственно читать можем с реплик если нас не пугает лака если нас пугает like читаем спрей мари так вот представим что мы делаем нечто подобное но у нас праймари не умеет обслуживать чтение читать можно только с реплик и там есть лак и мы его измеряем и с ним миримся и соответственно из этой концепции мы и будем строить нашу как бы там серию с базу данных мы вместо вала берем кафку и считаем что запись прошла если она прошла на праймари то есть в кафку соответственно все остальные изменения этой реплики и это уже их проблемы там из кафки passing оса соответственно кафка ну то есть много говорят что там типа кафка это токов к это все на мой взгляд вот для данной задачи будут считать что кафкой толок он конечно является логом то есть это не какая-то мне брокер очередей очереди эта штука на мой взгляд несколько там посложнее это надежный log то есть эта штука которая как-то реплицироваться на несколько нот соответственно продюсер это тот кто в этот лог делает запись в конец консьюмер из этой из этого logo может читать соответственно интерфейс на консьюмер может читать либо с какой-то конкретной позиции со все то 123 и до конца и сидеть на потоке либо есть у кафки механизм запоминать где вы закончили читать консьюмер группы и я все to commit честно это все все знают это документация и неинтересно лог в кафки называется парте шин эти партиции объединены в некую логическую штуку топик но топик нам практически никогда не не интересен соответственно как это работает надежно у нас есть для каждой партиции то есть для каждого logo есть один праймари которые обслуживают и чтение и запись есть какое-то количество синхронных реплик мы соответственно для то чтобы получить какие-то гарантии по отказоустойчивости можем при продюсер где то есть при записи в этот лог требовать что пожалуйста отдай мне успешный ответ если записалась на праймари и еще там два две реплики то есть если они уже пока ли то есть все как бы гарантированно это записали и соответственно что еще есть кафки это sharding то есть вы можете создавать несколько партиций несколько консьюмер of умеют обрабатывать по одной партиции там за раз соответственно вы свою задачу раз параллели войти и мы это собственно и все это применяют для того чтобы не броситься на одном потоке как бы все это обрабатывать sharding он не на только на гранулярный сохранения влияет но еще и масштабирование записи допустим у вас есть лидер укажите партиций свой лидер таким образом весь ваш поток данных вы можете разбить на n кусков и н лидеров будет его обслуживать так и с точки зрения концу мира то есть консьюмер если мы говорим о консьюмер группе ту одну партицию бы читать один консьюмер вот и или как бы несколько то есть вы можете запустить там столько по костюмеров сколько у вас портится если вы работаете соответственно на low level ok ну я сейчас покажу немножко про это естественно чтобы понимать что внутри в кафки бегает в этом логия я структуру искушенного клиента скопировал выкинула тут очень интересно естественно есть топик это просто стрельба есть ключ у каждого сообщения это набор байт слом строго говоря есть валют на грубой кафка особо не вникает чего там вместо догоняете есть парте шин это номер партиции куда вы соответственно в какой из логов в пределах топика вы записали есть офсет это грубо говоря смещение в конкретном логе которая присваивается брокером после того как вы туда практически сообщение есть time stamp с версии по моему 10 чего-то там брокер присваивает каждому логу время в которой она была записана то есть это брокер на и время у нас как бы с этим есть небольшие проблемы наши на самом деле в наших метриках у нас есть h 3 разных времени это брокер на и время агентское время и настоящее время по мнению концу мира но это сейчас в принципе не особо важен то есть как мы пишем с записью в принципе все просто вы должны определить ну то есть вы можете определить в какую конкретно партицию будет записано то или иное сообщение и мы делаем некий статический sharding то есть у нас есть некая явно заданная функция которой определяет что вот эта метрика с таким-то ключом вернее пачка метрик с таким-то ключом будет записано в партицию номер 2 и она туда будет попадать все все в или эти метрики будут выпадать ровно в партицию номер два нам это важно для чтения для дела колите то есть чтобы одна и та же метрика была в одном блоге ну и соответственно в кафки нужно всегда использовать большой в райт это прямо он реально сильно ускоряет запись ну и тут нет ничего особо необычного теперь про то как работает консьюмер есть три за и мало уловил интерфейс когда вы ничего не знаете ни про костю мир группы не просто вид а все ты вы можете сказать я хочу читать такую-то партицию в таком-то топики с офсета номер x соответственно офсет есть опция читать с конца то есть до меня с последнего nutella минусов без указания смещения или я хочу читать сначала но еще так как у нас сообщениях есть time stamp то кафка позволяет вам запросить офсет сообщения с таким the time стампом то есть она by сектам по-своему логу ищет вам смещения которое относится к ноутам плюс четыре часа и для нас это важно мы именно это используем но если вы хотите использовать ее как очередь и не париться про все эти консьюмер есть высокоуровневой интерфейс консьюмер группы вы говорите что я хочу читать такой тот топик и много контейнеров делают ровно та же самая кафка сама распределяет ты будешь читать этот ты будешь читать этот и сама разрулить ситуацию когда один из конструкторов умрет она его за работу отдаст другому и соответственно вы можете периодически сказать я эту работу сделал сохрани офсет и следующий раз когда вы поднимитесь она начнет вам отдавать сообщение ровно с того места раз которого за к метель в общем то все просто возвращаясь к нашим метрикам мы используем low'll интерфейс то есть мы в нашем займам memory старридж эта штука которая будет наполняться из этого logo она стартует пустая каждые то есть она знает сколько там партиции то есть у кафки можно спросить сколько тебя партиций потом форум наплодить условно портишь маркеры товар который обрабатывает одну партицию то есть наш каждый из нас моим ristora обрабатывает одну партицию соответственно и все данные которые получил за 1 партиций он хранит в отдельной области память ну условно там это набор кольцевых буферов соответственно когда стартует наш и вот эта штука она говорит кафки дай мне пожалуйста смещения для того чтобы я получил все метрики за четыре часа она дает смещение у нее есть пустые буфера и она начинает просто весь поток изменений проигрывать пока не достигнет конца соответственно данные которые ей априори не интересны то есть те которые были у которых вместо шкаф китайском нормальный внутри она понимает что такие старые метрики из прошлого там какие-то агента дослали она их просто выкидывает они не интересны и соответственно важно важно здесь критерий что непонятно как бы насколько я в конце вот вот это надо сформулируем ули ровать насколько я в конце можно определять двумя критериями 1 у кафки можно спросить так называемый хайлатер марк для этой партиции то есть какой номер офсета на момент моего запроса будет выдан следующему сообщению его можно спросить и посмотреть последний обработанный офсет таким образом мы поймем сколько примерно в штуках сообщений до конца осталось то есть мы на момент соответственно запроса будем знать что мы сейчас вот в этот момент отстаём от хвоста на тысячу штук и также так как у нас есть time stamp мы можем сравнивать брокер ну вот эту time stamp то есть получили очередное сообщение и смотрим что она датирована четырьмя часами назад значит мы где-то в четырех часах от конца соответственно мы в нашей штуки умеем как бы это все ну то есть программного вычислять то есть имеем ли мы право отвечать надо на этот запрос то есть достаточно ли мы сейчас синхронизированы то есть это как по аналогии с с кем-нибудь под гриссом а какой сейчас у меня лак относительно мастер и вообще могу я эти запросы обрабатывать ну и соответственно все эти штуки мы вывели на на half чак то есть хавчик губерн это запрашивает ноду она ему говорит нет я еще не готовы еще не налилось значит соседние еще диплоидный загасить нельзя то есть все вот эти пробы они как бы более осмысленные и соответственно так как мы оперируем потоком нам нужно понимать где мы в этом потоке то о чем я говорил две картинки приложил на левой это момент старта нашего приложения она запустилась она понимает что ему до конца надо читать чуть больше 75 миллионов сообщение и вот она этот лак живет и там за 15 минут она его до нуля сожрала 2 соответственно это скорость обработки сообщений из кафки то есть мы сообщим в то же время запустили приложение она запустилась начала фигачить там не знаю 130 сообщений в секут тысяч сообщений в секунду она начала процессить а потом дочитал до конца и сидит на потоке то есть она вышла на плато и на этом плоту она собственной работает ну из это ясно из этой штуки после того как она начала ради мы имеем права собственно уже обслуживают чтения соответственно на чтение мы отдаем ошибку если у нас большой лак то есть мы не на хвосте находимся значит у нас данные не консистентные и соответственно если нас просят диапазон больше чем у нас есть мы из хотели запустить кэш новым словно там м restore на 4 часа а у нас просит 8 часов мы не вправе отвечать на такой запрос мы отдаем ошибку ну и как бы тот клиент который запрашивает он теоретически знает кто сколько часов хранит нас есть разные пара по размеру часто раджа соответственно приходит запрос как правило это 1000 ключей за раз соответственно он бежит и по каждому ключ вычисляется какой он партиции то есть все эти ключи сердятся на партиции так как мы знаем функцию хэширования мы можем понять кто в каких партиях и соответственно вычитываем вот что у нас получилось мы там 99 перестаньте ли у нас меньше 20 миллисекунд это как в среднем обслуживание запросы чтения в котором три сплайн тысячи метрик запрашивается соответственно если мы запрашиваем там чуть меньше то есть наш 95 пир сантилли это где-то 600 ключей за 1 запрашивается она там вообще 3 миллисекунд соответственно получили быстрое чтение мы таких штук можем поставить сколько захотим это в принципе вообще делается легко нам не нужно базу данных перри конфигурировать нам нужно просто запустить instance мы ничего не писали не бар или при кация при этом мы имеем как системное состоянии то есть распределенное консистентная но мы ничего не писали на на про репликацию мы просто написали консьюмер а все остальное дала нам кафка а еще раз шарден это есть у нас несколько там сегментов памяти и все вот эти вот война за локи она у нас 18 раз ну как бы но 18 нас там партиций на 18 раз менее значимо с точки зрения задержек но сидеть на таком потоке метрик ну то есть на полном потоки метре которые нас есть сейчас это где-то занимает каждый instance полтора ядра то есть у нас там есть компрессия того чтобы сообщение обработать ему нужно ринг буфер раз компрессию ставить точку обратно за компрессии иначе у нас памятью не лезла а так у нас там в несколько раз сожмется ну и соответственно есть вот этот вот лак на то что у нас нет никаких snapshot of сейчас пока и мы каждое ну каждый запуск зачитываем сначала это долго и по ресурсам достаточно накладно дальше мы переходим к тому аналогия с базами данных взрослыми гдей-то файлом то есть long-term сторож в нашем случае эта штука называется чанки рано также сидит абсолютно независимо от тех компонентов которые в памяти хранят данные она сидит на потоке всех изменений и формируют и злобы которых я говорил соответственно она сама запоминает откуда и надо читать она в отличие от предыдущей стоит лишь штуки должна помнить да куда она все обработала и да куда она все эти чанки сформировала соответственно она для каждой пачке метре хранит свое все ты кранец в той же кафки из такая замечательная штука в кафки компакты топик бранью не буду подробно в документации все есть соответственно готовые чанки которые она понимает что-то 4 часа закончились она берет формирует блок и кладет его в ту же самую касс кафку просто в другой топик а если она понимает что блок этот был сформирован но пришла . из прошлого в тот же самый блок она в этот же топик кладет другой тип месяц же что типа это . из прошлого и есть другая штука которая сидит на всех этих на этом отдельном топике и читает если пролетает чанг она просто берет и перекладывает в кассандру мы сделали это специально через кафки через кафку для того чтобы иметь возможность потом экспериментировать с ломтем сторожами то есть вместо кассандра взять и на потоке вот этих вот блобов зачитать во что-нибудь другое файлики не знаю в маску или куда угодно а если пролетает . из прошлого она из соответственно из кассандра берет этот чанг распаковывает вставляет эту точку запаковывает и кладет обратно так как эти штуки находятся в одной партиции то есть и чанг и . этого чанка запоздало приходит как бы последовательно то никакого рейса никакой проблемы с данными нас не будет и соответственно для этих штук мы используем костюмер группы тесно чего удалось добиться удалось в 200 раз снизить количество записей в кассандру у нас было 30 тысяч в right of в секунду а стала 150 потому что мы тянуть блога пишем один раз и соответственно кассандру мы свою сдули так как у нас кассандра обслуживала хвост мы у нас было 12 нот и там хвост как раз был на ssd а теперь нам это все не нужно стала мы поставили три ноты с большим количеством sata дисков и полотенце нас все устраивает и создана больше собственно не нужен ну и соответственно немножко таких паттерну штук . мы так как мы имеем дело с кафкой у нас нету возможности то есть вот что делать случае ошибки у нас есть некий лак и мы встретили в середине обработки какой то не знаю там плохое сообщение вот надо понять что с ним делать отметить того что мы его выполнили мы можем только все там то есть только передвинуть маркер свой соответственно встроенного никакого механизма кафка не дает и я выделил 3 на самом деле таких принципиальных момента как это вообще делать можно если вы понимаете что вы должны во что бы то ни стало этот место чтобы работать должны просто хочется и встать и до успеха повторять ту операцию которую вы должны с этим местом выполнить и соответственно там ну понижая частоту попыток и так далее вы можете перекладывать в плохое сообщение отдельный топик и потом отдельно маркером это все обрабатывать или вы можете плохое сообщение перекладывать в начало этого топика обработать его потом а помечать что вот эту версию этого сообщения и от типа обработал мы соответственно нет никакого готового решения что делает так и никак иначе мы используем это в разных случаев то есть если провести аналогию с http ваш тебе есть хорошая классификация ошибок htp 400 ошибки это ошибки запроса то есть это ошибки клиентов вам послали неполный запрос вам послали какой-то не валидный джейсон это все ошибки клиента есть ошибка сервиса это когда у вас не знаю там тот сторож который хотите записать лежит или там еще какая-то непонятная ошибка естественно мы их как-то по классифицировали и для разных типов мы понимаем что стратегии действий совершенно разная то есть если у нас лежит the storage которую мы хотим записать то откидывать сообщение в соседний топик вообще бессмысленно потому что мы просто создадим себе большую нагрузку на на кафку мы как бы нам проще заблокироваться и дождаться пока это сторож будет готов обслуживать наши запросы если нам пришло какая-то битая штука или штука которая упирается в лимиты которых мы не ожидаем допустим очень гигантская то есть когда вы конфигурируете кассандра там есть максимальный размер того чего может это положить очевидно что этот максимальный размер нужно еще и на клиенте детектив и даже не пытаться это сделать потому что вы таким образом не дифференцируется уперлись ли вы или в лимит или просто кассандра тайма учиться или дает вам ошибку поставок вы свои ошибки классифицировали работать с ними уже как то более менее можно соответственно теперь про нашу продакшен инсталляцию большому счёту парковку рассказывать ты ничего это лог он работает если вы настроили нормальный уровень соответственно гарантии записи туда и понимаете как работать с консьюмер и про не про это больше нечего рассказать в продакш у меня с данный момент 6 брокеров мы находимся на версии 10 мы эти брокеры не выделяемым отдельные машины а на машинах скутер на это сам мы отрезаем кусок что значит риза им на машине есть два диска 2 sd и проц и память мы им отдаем целиком кафки 2 so the disco мы говорим что кафка ты но в систем д мы ограничиваем кафку уверен что тебе не больше четырех ядер доступно и не больше 10 гигов в кубер найтись и мы говорим что этих ресурсов тебя нет то есть мы зарезервировали 4 ядра и 10 гигов под кафку поэтому кубер туда ничего не scheduled и в общем то получается вроде как бы все по-честному ну и мы не берем сейчас и планировщики там борьба за ресурсы я тоже про это могу рассказать но не сегодня вот соответственно мы храним сырых точек вот те которые нас являются валом мы храним пять дней это занимается учётом реплики репликации в 3 копиях пять терабайт чанки его то что подготовлена вот эти было бы мы храним два месяца это занимает 3 терабайта есть сами посмотрите во сколько это все сжимается и был ли смысл сжимается это очень хорошо но при этом мы храним два месяца только в кафки в кассандре мы ничего не удаляем там все лежит моменту вот соответственно имеем сейчас около 20000 событий записи в кафку в секунду на этих шести нотах и суммарно вот эти шесть нот с учетом концу мин gopro девчонка и так далее тратит 10 лидеры то суммарно все шесть брокеров и 45 гигов памяти опять же суммарно то есть по большому счету ресурсы она не жрет вот это ясно чуть-чуть еще истории про на шпроты будем заканчивать соответственно rolling апгрейт мы делали мы обновлялись даже через одну версию делали все по инструкции и все в общем то хорошо а потом она сдохла но сдохла она не потому что у rolling не прошел rolling прошел воздух ломала версия в общем то был в кафки чудесный баг это моим relic соответственно то что это моим relic понятно было сразу потому что g вы им просто доходит до верхней границы hippo и и не коллекции ничего этот бак был связан с тем что когда консьюмер но в кафки топике можно еще и пожать средствами самой кафки ну как бы если клиент если продюсер говорит что мои сообщения зажаты был за 4 он их туда прям посылается за 4 а консилер понимает что это за 4 зажатые сообщение давай его распаковывать и вот у кафки там и из-за этого типа компрессии чет так не так срабатывает когда мы запускали консьюмер она начала течь именно консьюмер который читает зажатый топик мы соответственно ну паника downgrade штука стрёмная соответственно мы дали их и побольше чтобы она реже повисала то есть мы чтобы было время подумать хотя бы потом поняли что это за 4 то есть нашли тикет поняли что это именно вот происходит в этот момент нашли корреляцию с тем что мы делаем с тем ну как бы что как чувствуется кафка и просто решили выключить а потому что нам повезло и у нас не было в пародии сейчас нет за 4 зажатых топиков все что надо зажать мы сажаем зажимаем в природе сами руками ну потому что не знаю так сложилось серьезного просто все это отключили решили не даунгрейдятся и вернули хип обратно потому что большой хит зло вот и теперь история на самом деле это такой не особо показательной истории но то что бывают в кафки подобного рода баги вам знать я считаю нужно вот соответственно дальше история про то как кафку масштабировать и как вообще добавлять ноты удалять но да и так далее естественно когда мы добавляем в кластер брокер ну то есть мы запускаем еще одну кафку которая смотрит на те же звуки пиры и говорим твой брокер айди там n + 1 она запускается и и все видят все хорошо но на нее ничего сама не копируется и вам надо делать запускать некий touring который сделал ты это руками в кафки есть такой-то лекс заяц и кафка ряса импорте шанс о чем он делает он просто говорит что вот для этой партиции а ну то есть там сначала и штука стадия jennie reid то есть она генерит вам вы говорите вот вот у меня топик он сейчас вот такие-то партиции на таких-то брокерах находятся а я хочу чтобы этот набор participle размазан по нодам такие же + 1 или плюс 2 и нам генерит новую раскладку и в этот же сон вы можете подсовывать другой стадии которая ну типа применив все это она соответственно для каждой партиций которые есть изменения прибавит нужное количество дополнительных реплик дождется пока они все станут синхронизированными и реплики которые в новым в новой редакции но как кубер нету с новой редакции нет она прибьет соответственно если нужно в процессе этого если лидер был его быть не должна она лидера переизберем в общем-то все логично все классно но эта штука на стадии jennie reid она не заботится она заботится о том чтобы по вашему списку брокеров партиции в штуках размазались равномерно она ничего не знает про размеры она ничего не знает про то что должно быть меньше копирование то есть она не учитывает то что будет по факту происходить а нам так и был у тебя хороший список этих генерирующего лучше пусть там нахрен все переедет 10 раз в процессе меня это вообще-то не волнует то есть если вы хотите чтобы было optima линька если у вас большой поток данных перед перетаскивать to generate или есть тузы которые принимают во внимание количество копирований которые кафки придется сделать и соответственно самый важный момент что когда вы запускаете рясой она play или как она называется я же забыл и не поставите лимит на скорость а кафка достаточно производительная она умеет хорошо читать хорошо все это пересылать без лишнего копирования в сеть оно вам на хрен убьет и сеть и диски и чуть-чуть проц а ну и моя вторая история про то как мы the limit не задали мы не задали лимит сад с маковка нам все прибило ну то есть она по ресурсам все выбрала и оказалось что ну покрайней мере может быть мы такие рука зады но если лимит не задан задать его пост фактум нельзя битов для тех операций копирования которые уже в полете которые сейчас идут мы пробовали touring мы наспех почитали код вычета внуки перри поправили она ни хрена не применяется и соответственно как вся моя поучительная история мы лошары но сделать еще нельзя было поэтому мы просто дождались пока она закончится и больше так не делаем безлимита запускать это точно никогда нельзя но если у вас там нет данных запускайте ради бога если вы запустили с лимитом то конкретное значение лимита поменять можно в в онлайне то есть вот она копируется вы понимаете так чё то медленно и ресурсы есть добавлю-ка я еще парочку десятков мегабит в секунду это делается кафка это с этим справляется не понимаю я до сих пор что там было с тем когда лимит не задан с тем когда лимит задан но чет не сработало вот соответственно мы также не запускаем много переносов мы стараемся сделать так чтобы в одной итерации товаре assign a с одного лидера было только одно копирование то есть с брокером сойди номер пять не стоит копировать если он лидер для этого портится не стоит копировать все 3 партиции потому что что-то там они и переклинит и в общем то становится и не очень хорошо и буквально еще пару историй кафка ну так как она на уровне брокеров умеет данные распределять между разными has to me зачем ей сувать рейд и в начальных доках linkedin писал что типу ребята ставьте кафку на рейд все классно если у вас несколько дисков это нормально а потом появился функционалом который позволяет кафки сказать вот тебе 5 5 дисков использую их все но она но они видимо так же как нормальные инженеры идут от простого к сложному поэтому в нормальной ситуации когда она говорит что вот у меня кафка запущена брокер с двумя дисками я начинаю по нему размазывать партиции которые сейчас я реально не назначаю и она будет их распределять между дисками балансировка типа трафика она оперирует штуками партиции то есть если вы запустите 2 топика в одном 386 партиций размером по 5 килобайт в другом от 20 партиции каждая по 100 гигов для нее это одни и те же партиции соответственно перекос балансировки будет соответственно сказать ей там что-то перри балансирую в пределах роста и я так понимаю что были киты зачатки что она будет тот момент когда мы это делали их не было соответственно мы когда нам нужно забить два диска ну то есть надо понимать что вся балансировка данных происходит на момент создания партиции то есть дальше она как пишется в одну партицию так и пишется если у вас partition дружба слазь не влезает в диск вы с этим еще не сделаете на на и руками вмешиваться соответственно мы когда хотим новый брокер подключить мы самые тяжеловесные сначала берем партиции делаем рио-сан только на них ну и соответственно это не сразу потому что предыдущий пункт соответственно вообще кафка у нас больше года в праге к ней надо привыкнуть она достаточно такая штука специфичная но работает и по большому счету все наши вот эти приключения с downtime кафки она ну как бы я это сделал такие выводы что вот когда мы допустим обновлялись кассандру там у них что-то с качеством было все хорошо и мы такие ну релиз вышел ну подождали там борьбе дней нам крите кого нету и можно катиться кафки оказалось похуже то есть вот нулевые релизы я бы ставить больше не стал подождал бы прямо еще долго мы мы просто обновлялись с погоней за там еще вместо g появились заголовки федор и мы за ними погнались она просто как это все у нас купола моих даже юзать не стали в общем то лучше бы подождали вот и соответственно вот эти все монтэйн с операции они там с подковыркой то есть когда она начинает что-то копировать надо ее ограничивать чтобы ничего не убила ровно поэтому там несмотря на то что конфликт говорит мы выпустили классный оператор который в q бернетт оси вам все сделает он там уме и 3 балансировку и вот это все зная как мы там бились с этим рясой нам вот что-то мне пока не хочется кафку втаскивать в кубер несмотря на то что не знаю там на предыдущий оратор рассказал надо ли не надо чем я пока не хочу соответственно бонусы которые мы получили я считаю очень классные это легкость экспериментов когда у нас есть источник правды и сырых данных мы можем экспериментальные штуки мы делаем новый сервис другим с другой компрессией с другим всем ставить на и тот же поток рядом с продакшеном это ни на что не повлияет в клиенте мы можем сделать называемое сша до запросы то есть у нас есть запрос в основной сторож делаем запрос в экспериментальный сравниваем результат сравниваем latency мы это делали и это прямо круто ну то есть когда вам нужно напротив под нагрузкой все разрабатывать это прям реально ахриненно и также реально классно что так как это все секрет шеварийцы конечно write вы можете это использовать для этого дешевые диски вам не нужно ssd и вы можете хранить много поэтому если вам хочется получить данные за три месяца назад для ваших экспериментов реально можете это сделать и второе второй момент который я хотел бы сказать что соответственно кафка так как она сама надежная и распределенное вы можете переходить от кластера кассандры к набору независимых баз данных и это прекрасно потому что вам не нужно заботиться репликации вы хотите попробовать мангу для своих каких-то задач ну посадите ее на поток событий и посмотрите как она справится с этим размерам данных вы можете посмотреть не знаю насколько упа сгрыз а большое там в рай там префиксом по сравнению с mais quel им и так далее мы это как бы тоже используем это прям реально круто и при том при и при всем при том что если вы определите слогам то что я сказал ну то есть когда приложение может когда но консистентная когда не консистентной вы можете прямо как бы рассчитывать что эта штука надежно реплицируется при этом репликацию своем коде вы не писали и в общем-то и не нужна ну и соответственно подводим итог почему велосипеда строения потому что ну это все четно по большому счету то что мы сделали очень специализирована для нас она никому не нужна и это не наша фокусная деятельности я бы искренне не хотел этим заниматься но так как мы это все нам это нужно было мы это соответственно сделали если вы все-таки понимаете что для ваших задач для вашего бизнеса компании нужно такое подумайте можете ли вы по-прежнему это не делать если все-таки вы хотите сделать свою базу данных вы можете и должны изначально разобраться как работают настоящие большие базы данных хорошие истории с хорошими умными разработчиками и сделать что-то наподобие вот взять какие-то моменты репликацию отсюда вал отсюда соответственно кафка в качестве волна мой взгляд вообще оправдала себя она сильно позволило нам упростить то как мы делали свою базу данных распределенную надежную и соответственно часть задача нас себя сняла но взамен мы очень немного ресурсов потратили на нее она немного в эксплуатации требует от нас и общем то берите за основу как готовые компоненты дописывать недостающие куски кода и общем будет вам счастье все что я хотел рассказать спасибо хочу нормально все нормально вообще да друзья есть вопросы поднимайте руки мы дарим традиционные подарки спикера за лучшие вопросы потом дарим книгу вот но когда зададите вопрос можете уходить вполне к вам бежит специально обычная барышня с микрофоном тем временем у меня в кармане носки с логотипом хай-лоу да на стенде четыре коробки и организаторы просят не уезжает с этими носками им а уехать с этими носками вам поэтому подойдите запостите что-нибудь правильным хэштегом там вам все расскажут вот и возьмите с собой такие носочки я вот их вместо вместо платка засунул есть микрофон пожалуйста вопрос добрый день геннадий московская биржа спасибо большое за доклад очень интересно очень актуально кафка как вал действительно очень крутая идея мы на нее очень долго смотрим может быть наконец начнем вопрос следующий где-то полгода назад над же points и гамов рассказывал что они в кафку один втянули транзакции и вот как раз для обработка ких то сложных ивентов для того чтобы их было проще работать вы пробовали использовать транзакции вот в частности для обработки ошибок вывод вначале упомянули что с этим были сложности не ну то есть мы не нам не нужны транзакции там где мы сейчас используем кафку потому что все изменения которые нас есть они дым патентные мы можем их проигрывать много раз и в общем то делать усложнять ну то есть даже если в кафки что-то появится на этот счет усложнять это все ради того чтобы нет нет профиту для нас использовать транзакции общем-то и мы это не делаем такие спасибо еще вот так пожалуйста здрасть спасибо за доклад вопрос такой могли бы рассказать про выбор функции вот это хеширования по определению у номер партиции получать на правой стороны конфликт что должно быть все партиций одинаково сбалансированная вот а другой стороны функция основе достаточно быстрый мы взяли самую простую чтобы love кафки но взяли и переопределили и и сами для того чтобы если кафка клиент обновиться чтобы она у нас была зафиксирована у нас в штуках событий очень много поэтому любое распределение у нас получилось равномерно поэтому нам собственно с дисбалансом партиции нагрузки не пришлось ничего делать выбор который клещей вот этих вот в метре кнопочек метриках миллионы и они примерно там в штуках там распределяем получилось такое чтоб вот я показывал график там примерно одинаковое количество мы просто по ключу взяли некоторую функцию от ключа без знания о том сколько там данных сколько штук и то есть остаток от деления словно хэш она на количество партиций дала нам распределения да ну ка кафка клиент горный сарама то есть учетом других клиентах и nismo спасибо пусть обры припасть это за доклад теней или выебать сайт для ног одессе ря под размер сообщения или с дефолтным по что я занимался нормально работала но у нас batch в том плане что у нас приходит за раз условно тысячи метрик мы них не каждую пачку пишем вам и в пределах запросы делаем все по чем одним то есть между запросами как кафка клиент ничего не накапливает поэтому у нас нету особо не такой никакого тюнинга нет счет еще олаф когда вы писали в кассандру или и мама ресторане выпуском смерть описали как надо погромче как вы писали свой can сильно для записи в мире старридж и в хранилище да ну то есть у нас есть консьюмер для и мама рядом встроены да есть консьюмер который выгребает эти чанки и складывают несколько суперов под разные задачи а еще как . а по металлу сократит как базы для метрика во мне не подошли на какие базы они прошли карлсен flux там сервисов по моему еще что то то есть ну то есть она как бы не подошло ну то есть какие-то вещи мы тестеры тесте или какие-то вещи мы понимаем что они по дизайну нам не подойдут в принципе от спасибо спасибо есть вопрос по поводу того что вы сказали не использовать под кафкой рейсы у вас не уходят брокеры целиком когда ломается один из дисков я не скажу прополисе отказа дисков там что-то сейчас сделали по-моему это конфигурируемые поведение то есть я знаю в кассандры есть сконфигурирована и поведение когда вы даете jbod то есть либо не обслуживают запись на диск либо там как бы целиком ноту фейлить в кафки я затрудняюсь может быть может быть она уйдет целиком да это в общем-то и не беда спасибо пусть обры спасибо за доклад у меня такой вопрос в чем профит отрезать там ресурсы на тех же точках где у вас кубер чтобы дать это кафки это просто утилизации или потому что можете мы используем большие жирные железки мы не используем виртуалке поэтому давать кафки жирную железку мы не хотим мы хотим чтобы кавказа нагрузил там два диска и взяла немножко циpкa а все остальное циpкa и память мы хотим использовать для дела и ровно поэтому мы это делаем понял спасибо спасибо будь добра привет спасибо за доклад и я к сожалению присутствовал не сначала поэтому может быть я спрошу то что ты уже освещал как вы мониторить брокера кафки что они не отвалились что они живые работают у нас есть мониторинг не поверишь media monitoring у нас есть мониторинг мониторинга и мониторинг он умеет травку мониторить и он нам рассказывает про все бекки что с кафкой происходит но про это можно как то хотя бы чуть-чуть конкретнее рассказать но смотри ну да у тебя у тебя живы живо какое-то количество брокеров это значит что это будет работать мы бы мы смотрим есть ли у нас не до синхронизированной партиции мы следим за тем чтобы распределение партиции лидеров было равномерным по по брокером мы следим за тем чтобы диски не убирались в полку мы следим за тем чтобы кафка не убиралась ли мецица мы следим за тем чтобы звуки пиры были живы и у них не было там вылетевших not но и так далее и тому подобное на базовые вещи то есть есть софт его надо мониторинг и понял спасибо спасибо будьте добры 1 николай спасибо спасибо за глаз очень интересное опыт использование кафки у меня один вопрос и одно такое скорее замечание вот вы описали ваши сортирование но вроде так будто одна метрика попадает в одну конкретную партицию всегда может быть такая ситуация если к этом метрик станет очень жирный и один брокер но одну портится служит этим рокеров то есть может ли случиться такой что начнет мне справляться просто нет нас есть лимиты на размер метрики то есть мы так мы слишком жирную метрику но это должно быть очень очень очень очень жирная метрика мы ее просто не примем мы будем разбираться почему она такая чтобы потом восток моё за reject или понять как сделать так чтобы метрика бы пришла в нескольких там каких-то кусках и так далее то есть с этим сейчас нет проблемы не предвидится то есть это не зависит от объема трафика то есть одна метрика может одна метрика эта штука это какое-то количество флотов за какой-то time stamp то есть там не может быть гигабайт там и так далее а я это это это конкретное замер за вот это вот times 102 вопросы размещения вот вы говорили про возможность кафки использовать несколько дисков и on the что она не балансирует и может складывать на один диск на 11 много то есть жена и объема данных он другой не очень там судя по нашему буду кафка же у нее же есть такой понятия сегмента то есть она режет партицию на сегменты есть если a partition там за много дней это это терабайта данных вам не создаст много- трогать на файл он его порежет на несколько и в этом случае он раскладывает и минут файл на файловом уровне сегменты раскладывать в разных директорий которые есть у меня была другом составление если по факту так как вы говорите то это классно но у нас мы столкнулись с тем что было именно единица позиционирование на диск именно портится целиком но с другой стороны и кафки когда она это делает она не знает сколько там будет данных поэтому может быть в версиях они переделали что единица balancing а это сегмент но это было бы логично если они до переделали но круто значит я сказал неправильно или не на тот момент развития кафки она действительно несмотря на размеры но она просто рандомно размазывает сегменты спасибо спасибо большое последний раз ты николай спасибо за доклад а у меня так вопрос чем вас не устроили существующие там серия database они не тянут ну то есть во первых какие-то prometheus не умеют много копий но надежно раз раскладывать этапа но дома он не умеет хранить lts у нее с этим проблемы и те запросы которые мы отправляем на чтение содержащие там 10000 метрик на запрос prometheus под этим складывался извинить вот ну то есть у нас чуть более другие требования к time series baby но исходя из наших из нашего варкала да потому что у нас есть пользователи которые смотрят графике но большинство нагрузки создают много много много наших триггеров которые постоянно эти данные дергают и читаю мы их еще не переделали на поток и кстати это очередной такой но point который кафка для нас осознанный выбор потому что триггером будем проверять на потоке изменений мы будем следить на потоке не будем читать из этого стороны вот ну то есть вот как-то так прекрасности друзья остальные вопросы в кулуарах начала и по себе большое кому книжка отдадим за лучший вопрос про уши вопрос до 8 человек который сказал что я не прав я и я был бы счастлив оказаться неправым одно обращение отлично под ваши аплодисменты отлично супер"
}