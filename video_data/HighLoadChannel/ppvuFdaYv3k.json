{
  "video_id": "ppvuFdaYv3k",
  "channel": "HighLoadChannel",
  "title": "Управляем состоянием распределенных систем без боли / Илья Казначеев (MTC Cloud)",
  "views": 1305,
  "duration": 2472,
  "published": "2023-01-19T05:55:18-08:00",
  "text": "меня зовут и я казначеев я теплит вмт скво где мы строим к вернитесь и за сервис про которые я сегодня немножко расскажу так же я облачный архитектор основатель нескольких сообществ в том числе cooling воронеж google developer эксперт по направлению клауд сертифицированный облачных детектор и кандидат технических наук и сегодня вместе с вами я постараюсь найти ответ на вопрос как же управлять распределенном состоянии но рассказывать я буду не про это а про то как построить вернитесь и за сервис процессе чего мы найдем ответ на первый вопрос и для этого нам нужно обратиться в прошлое на два года назад когда у нас был mvp продукты который подтвердил его жизнеспособность и мы перешли к превращению mvp production на рейде сервис у нас были следующие требований первое и основное этой силе четыре девятки на доступность сервиса и на работу операции над кластер а как-то его создании удаление изменений прочие менеджер второе мы хотели быстро реагировать на инциденты и максимально сжатые сроки исправлять ошибки на продакшене чтобы у клиентов был приятный и бесшумный experience мы хотели максимально быстро доставлять новый функционал пользователю и очень хотелось чтобы все распределенные процессы которых в облачной про структуре довольно много выполнялись атомарные консистентную и не оставалось никаких не удаленных сущностей или не было в синхронизации данных между сервисами и так далее но конечно немаловажным является читабельность кода его поддерживаем оси что не было чем что было реализовано ввп но чего мы хотели добиться чтобы проще работать над кодом и быстро интегрировать новых сотрудников в итоге мы начинали со следующего у нас было два сервиса северский вернитесь и сервис праведника инфраструктуры 1 реализовывал достаточно высокоуровневую логику по управлению кластером а во втором создавались компоненты все эти подсети адресов балансировщик of виртуальных машин их конфигурации это всё создавалось поверх платформы виртуализации при помощи сервиса праздника но проблема была в том что логика кластера была в каком-то виде размазаны между сервисами например одной из команд было создание мастерноды в рамках чего создавалась и сеть и подсеть и блокировщики нагрузки и выделялись публичные айпи адреса это все было в сервисе для проведения это конечно очень сильно затрудняло разработку потому что по сути это было нечто похожее на распределенный монолит и первое что мы сделали это написали новый сервис provisioning который выполняет только атомарные операции как часть eos слоя нашего облака то есть создает все эти подсети балансировщик и виртуальной машины диски и все что с этим связано но не знает логике которая построена на основе этого а всю логику кластера мы перенесли лупу и упаковали в сервис нашего продукта и да таким образом достигли того что у нас ответственности разных сервисов больше не пересекаются и нет проблемы в изменений одного и другого и другого дальше мы перестроили логику нашего сервиса на пошаговый процесс где вместо того что все происходит по одной большой кучи у нас есть набор последовательных операций асинхронных относить друг относительно друга которые и определяют процесс о создании удаление или изменение кластера дальше я буду рассказывать именно про процесс создания кластера так как он наиболее сложный и наиболее интересный но надо держать в голове что аналогично работают и все остальные процессы на самом деле этот по шагу процесс разбивался на набор параллельных операций для перехода на следующий шаг необходимо было дождаться готовности всех предыдущих операций и в целом мы от такого совсем-совсем на колено степи перешли к не к тому состоянию когда в целом у нас была структура и пошаговый процесс и разделение на зоны ответственности между интро структурными компонентами но оставалась проблема того что логика того логика создания кластера очень сложны и запутаны и в не очень тяжело ориентироваться и также тяжело делать какие-то доработки тяжело делать транзакции базы данных тяжело выполнять logging потому что это все запутано и мы решили следующем федерации перейти на домен на ориентированный домен ориентированный дизайн и сделали такую модель в рамках которые у нас есть домен кластер домен группы not ноды load balancer и еще другие части которую я для простоты не стал указывать которые объединяются в так называемый доменные агрегат доильный агрегат или набор доменов у которых общий жизненный цикл они изменяются вместе то есть когда мы меняем группу нот мы скорее всю меняем кластер целиком каждый из этих доменов инкапсулирует логику вот этой части внутри себя то есть но до отвечает непосредственно за жизни цикл но да как она создается изменяется удаляется и так далее а группу нот за то как управлять несколькими нодами с одинаковыми характеристиками и таким образом мы смогли путайте вот этой куче логике разделив логику различных частей довольно сильно друг от друга это позволило нам очень сильно упростить код и сделать его намного более читабельным человек если посмотреть на то как это хранится базе данных то у нас есть следующая модель у нас есть кластер сойди ему принадлежит набор мастернод набор групп worker нот и не последствии сами worker и лот балансиры и так далее вот такая структура хранится в базе данных то есть это отдельной таблице если брать реляционную базу и про извинений мы можем прям поднимать целиком этот агрегат и выполнять на нем какие-то операции то есть там не нужно как-то пытаться это там бы создать или еще что-то мы просто берем и в рамках транзакций вносим необходимые изменения в итоге мы от такого последовательного пошагово процесса пошагово структуру перешли к доменом где все разделено в такую древовидную структуру и выполню это в рамках гексагональной архитектуры однако логика все еще была довольно сложный и запутанный и чтобы ее распутать мы сделали следующее если посмотреть на параллельные процессы видно что они на самом деле не просто параллельны они еще многошаговые и непонятно что делать случае когда например один из параллельных процессов сломался откатывать все или пытаться пересоздавать а когда он создался сломался если сломался например создание виртуальной машины в процессе старта можно попробовать рестор тонуть или еще что-то а если он стартанул и в процессе настройки возникла ошибка а если в другом случае ответов на эти вопросы у нас не было и приходилось городить градус ки которые было сложно поддерживать и разрабатывать в итоге мы решили внедрить конечные автоматы в явном виде а именно следующие возьмем пример виртуальную машину и и логику виртуальная машина создается проходит некоторый процесс инициализации и работает а дальше она выключает выключается проходит некоторый процесс выключения и удаляется при создании кластера мы создаем виртуальную машину но оду со статусом и нет и дальше стартуем процесс ее создания отправляем команду критериям сервису виртуальных машин и но до в нашей базе данных переходят в состояние вен кришны пойдем дальше когда операция завершилась успешно и мы получили ответ мы переходим к следующему состоянию поезд orthopedic и отправляем запрос на старт операционной системы и так далее пока виртуальной машины не перейдет статус running аналогично и с удалением мы проходим пошаговый процесс в рамках каждого шага мы отправляем какую-то команду соответствующему сервису но помимо этого удалось добиться согласованный абрам состоянием обработки ошибок то есть когда происходит ошибка мы не просто выполним какие-то действия а действие диктуется тем при каком состоянии ошибка произошла то есть если ошибка произошла из состояния wham кришна pending мы знаем что создание виртуальной машины не удалось нам не нужно ничего удалять мы просто переходим статус davydov но если например ошибка произошла статусе сетап pending то мы понимаем что по-хорошему нам нужно выключить виртуальную машину и только потом ее удалить в итоге детстве вернуться к доменом и доменом агрегатом то у нас в сердце каждого домена логика стала выглядеть как конечный автомат ну если брать язык на который мы писали а именно год это выглядит как большой switch кейс в котором описаны возьму все возможные состояния этого домена и события которые он могут быть обработаны в этом состоянии и какие-то действия которые нужно выполнить при наступлении события при переходе к следующему состоянию ну и соответственно для каждого из этих даме доменов конечный автомат свой со своим набором состояние для кластеры это одни состояния для группы но другие для note 3 для red ball 4 а здесь важно то что если вы разбиваете вашу логику на явный состояние и делайте конечный автомат состоянии должны быть полностью атомарные детерминированными это значит что у вас не должно быть такого что чтобы определить какую-то логику к ты кого-то следующий шаг вы смотрите не только на состоянии сущности ну и на какое-то еще поле там на флаг еще что то вот это быть не должно если вы при выполнении какой-то логики смотрите не только на состоянии но и еще на какие-то поля модели данных это значит что состояние неоднозначно и не описывает полноценно текущее состояние в этом случае состоянии просто нужно разбивать на несколько до тех пор пока они не станут полностью однозначно описывающими конечно и текущее состояние может быть такое что этих состояний будет очень много для какого-то одного 1 сущность например для кластер у нас больше 50 состояний но в целом это нормально потому что процесс очень сложный и состоянии все атомарные в итоге в базе данных мы получили то что для каждой сущности добавилось польстит который хранится текущее состояние и когда мы хотим выполнить какие-то изменения мы просто поднимаем из базы данных целиком весь агрегат и выполняем нужно операцию над нужным компонентом нашего кластер а так как у нас каждый компонент находится в каком-то определенном конечном состоянии мы всегда знаем в каком состоянии у нас находится кластер целиком вот прямо сейчас в момент времени и это позволило нам очень гибко сделать обработку любых состояний и любых ошибок на протяжении всего процесса в итоге мы перешли к логике описаны через конечные автоматы но у нас осталось следующие проблемы не было понятно изначально как правильно сделать обработку событий в рамках всего доменного агрегата то есть когда у нас события на который реагирует домен но домен не может полноценно обработать это событие пример при создании виртуальных машин виртуальной машины не знает что нужно делать при завершении создания в этом случае мы поступаем следующим образом приходит события о том что виртуальная машина создана мы переводим ее в состоянии running и отправляем родительскому домену события о том что она готова родительский домен группу нот проверять статус всех виртуальных машин в группе если все готовы то он что-то делает если не готовы просто ждет дальше приходит событий на вторую машину что она готова отправляем уведомление родители и родители смотрят все ли машины готовы да они готовы значит группа но переходит статус рейде running и отправляет своему родителю то есть домену кластера события о том что она готова классно проверяет все ли группы not готовы они готовы это значит что кластеры готов и можно отдавать его конфигурацию клиенту для того чтобы он начинал им пользоваться что интересно аналогично работать обработка ошибки то есть когда произошла ошибка при создании виртуале машины домен виртуальной машины может не знать что делать на глобальном уровне то есть он может знать что при ошибке нужно удалить виртуальной машины откатить изменения следующим образом что описывает конечный автомат но что дальше пересоздавать виртуальную машину пробовать и создать с другими параметрами или в другом дата-центры этого домен виртуальной машины ноды не может знать но знает группы но поэтому в этом случае мы отправляем события об ошибке родительскому домену чтобы он решил а если он не знает он отправит события соответственно своему родителю и это до тех пор пока как какой-то домен не будет иметь достаточно полномочий достаточно бизнес-логики чтобы обработать эту ситуацию и мы перешли к такой модели общение внутри доменного агрегата между доменами но у нас все еще осталось задача реализовать взаимодействие между разными доменами агрегаты например между кластером кубер нить из и сетью мы сделали следующим образом допустим у нас процесс описан и часть конечный автомат выглядит как некая последовательность в рамках нее например на создается сеть и мы хотим после создания сети создать балансировщик нагрузки в этой сети мы берем команду создание балансировщика нагрузки и отправляем ее сервису который создает ресурсы то есть ios уровня на создание было сиропчик нагрузки с указанием имени с указанием параметров для создания и так далее и в сервисе провяжу не нга инфраструктур начинается свой пошаговый процесс в рамках которых сущность проходит определенные состояния и когда доходит до конца сервис отправляет нам уведомление точки все готово мы его принимаем и продолжаем обработку со своей стороны таким образом мы получили механизм взаимодействия между доменами довольно хорошо работающий то есть мы просто общаемся через нашем случае очередь и у нас нет проблем с тем что мы потеряем какие-то команды или с тем что на что-то пойдет про синхрон потому что она и так выполняется синхронно но вместе с этим мы получили решение проблемы распределенных транзакций если вернуться к примеру с сервисом кластеры сервиса виртуальных машин и рассмотреть процесс создания виртуальной машины там увидим следующее мы отправляем запрос на создание виртуальной машины приходит ответ мы по идем по конечному автомату для но да и отправляем следующий запрос на старт виртуальной машины и так же приходит ответ и дальше мы отправляем следующую команду и получается что наш домен ноды через и pcm управляет процессом создания виртуальной машины то есть управляет ходом распределенных транзакций это немного похоже на регистрируем у сагу когда есть некий регистратор который говорит какие шаги нужно выполнять какой последовательности и какие компенсирующие действие нужно выполнить если что-то пошло не так но есть один нюанс допустим что сервиса виртуальных машин работает с платформы виртуализации ну не допустим так и есть и когда мы хотим создать виртуальную машину он идёт в эту платформу и говорит создаем виртуальную машину и начинает таким образом свою в распределенную транзакцию сердце виртуализации говорит о создана и сервис виртуальных машин дальше опеле к своей к своему конечным автомату к своему домену или логике которые так или иначе описано внутри сервиса он говорит а теперь в рамках создания виртуальной машины поди зарегистрирую ее в сети и так далее таким образом уже он выступает оркестра тарам для своей локальной распределенной транзакции при этом вот это локальная транзакция является частью более глобальной более высокоуровневой распределенной транзакции который управляет кластер сервис итоге получается что когда локальной транзакция заканчивается управление возвращается к более высокоуровневые распределены транзакций и продолжается дальше в итоге получается очень интересная ситуация когда первый сервис по факту оркестре рует распределенную транзакцию обращаясь ко второму сервису это второй сервис свою очередь офис 3 рует третий сервис говоря ему что делать и в этом случае логика того что как и когда нужно делать она не перетекает из одного сервиса в другой если сравнить регистрируемый сами там есть компонент в котором находится вся логика касательно всего процесса саги и часто бывают случаи когда из разных сервисов логика разных доменов затекает в этот регистратор и при изменениях новый команд начинает конфликтовать за изменение этого сервиса в этом же случае такого не происходит потому что логика процесса которая относится к кому-то домену он четко инкапсулирует внутри соответствующего сервиса и никуда оттуда не вытекает то есть сервис кластера регистрирует процесс создания кластера в рамках которого создается сеть виртуальной машины диски еще что то при этом ему не нужно знать о том как создается виртуальную машину этим доменом владеет сервис виртуальной машины который в свою очередь регистрирует процесс создания виртуальной машины общаясь платформы виртуализации в итоге если мы посмотрим на временную шкалу мы увидим что более высокоуровневая распределена транзакция включает в себя набор транзакции поменьше но напрямую ими не управляет и у нас в рамках создания кластера например есть маленькая транзакция которая запускает сетевой сервис и создает сеть маленькую распределенную транзакцию которая запускает сервис виртуальных машин и потом другая транзакция для дисков например более того распределенный процесс создания кластера может быть в свою очередь частью какого-то более высокого уровня процесса о которой мы с точки зрения сервиса кластера не знаем потому что это не наш домен и другой процесс может свою очередь управлять оркестре ровать разными распределенными транзакциями на уровне кластера таким образом мы получили что-то среднее между оркестре ру и мы их хореографически sagay в том плане что у нас с одной стороны нету единого центра для управления всем процессом распределенным между разными микро сервисами разными командами с другой стороны у нас и нет полного хаоса когда нельзя отследить процесс мы можем зайти в нужный сервис и четко посмотреть как происходит тот или иной процесс но мы делаем это с необходимым нам уровнем погружения то есть если мы хотим посмотреть как создается кластер мы пойдем и посмотрим на процесс и описаны внутри сервиса для кластера но при этом мы не обязаны погружаться в детали того как создается виртуальной машины для каждой ноги а если мы захотим посмотреть как создается виртуальная машина мы пойдем в сервис для виртуальных машин и посмотрим там в итоге таким нехитрым способом мы получили возможность управления распределенными транзакциями сколь угодно высокой сложности особенность заключается лишь в том что для каждого уровня этой распределенной транзакции есть сервис регистратор или правильный будем называть его медиатор внутри которого заключена бизнес-логика соответствующего домена которая описывает в какой последовательности какие действия выполнять и в какой последующие выполнять компенсирующие действие если что-то сломалось но при этом он не углубляется в детали того как эти команды будут выполнять другие сервисы с которой мы взаимодействуем это все очень хорошо и это очень сильно помогло но остался вопрос как быть с api как быть данными и как быть с параллельными процессами и мы решили применить здесь secures а именно разделение команд и запросов и сделали следующим образом в рамках наших сервисов мы разделили в отдельные api команды и запросы команды это то что меняет данный то есть какие-то мутирующий операции а запросы это не мутирующий операции которые просто читают данные это довольно популярный подход который позволяет добиться много разных улучшений архитектуры сервисов и системы целиком и я немного затрону их в частности чего мы добились здесь мы добились того что у нас а для команд выполняется доменная логика запускаются доменной транзакции базы данных какие то другие вещи в то время как для запросов нам не нужны в целом вот эти все домены и мы просто используем тонкий слой логики в которым мы не поднимаем домен целиком а мы отдаем по запросу непосредственно те данные которые нужны то есть можем использовать какие-то оптимизированы для чтения модели можем использовать просто view для чтения над базой данных которые соответствуют тому какие данные мы должны отдать на frontend например они полной модели кластера то есть это может быть например просто список костров с какими-то обогащающим и данными или что то еще что то еще и разделение на команды запросы позволяет развести модель для команд то есть создание удаление изменение и модель для чтения и они будут развиваться параллельно служа разным целям и не будут мешать друг другу далее была ситуация что все это выполнялось синхронно а если мы посмотрим на микро сервисную систему то когда приходит какая-то команда ее выполнение часто выглядит как цепочкой то есть сервис а получать команду он идет зачем-то сервис бы сервис б идет зачем их series x предыдущем примере кластер кубер нить из идет в сервис виртуализации для создания виртуальной машины то идет тот идет в сервис в платформу виртуализации для полне никаких действий если все это происходит синхронно мы можем иметь некоторые проблемы вот так это выглядит хорошим случае но в случае ошибки мы получим каскадную ошибку которая проходит обратно через все сервисы но это еще и неплохо а плохо вот что что если сервис x например платформу виртуализации просто перестал отвечать и мы получили таймаут на сервисе а ну самое простое степи тайм-аут или какой-то еще поймал и отправили ошибку а что потом а что здесь rsx выполнит свою работу и ответит об этом а что если еще где-то развал произойдет это очень большая проблема распределенных систем которая решается довольно радикально пониманием того что все распределенные процессы по своей природе асинхронные мы никогда не можем гарантировать за сколько времени выполнится тот или иной процесс особенно когда речь идет про управление инфраструктурой создания виртуальных машин сетей и так далее что происходит само по себе довольно долго поэтому мы перешли к асинхронный отправки команд и ответов на ее и делаем это через брокер сообщение кафка отправляем в топик сервиса команду и указывает какой топик ответить когда она будет готова и когда она готова мы получаем ответ между первым и вторым может пройти большое время может перейти плавится сервис может произойти какой-то сетевое разделение и восстановление сети и наши процессы за этого не развалится он просто выполняться немного дольше в итоге таким образом выглядит взаимодействие то есть мы отправляем команда синхрон и сразу же заканчиваем синхронной обработку а с клиента достаточно просто выполнить полинг статуса по создающийся сущности и все будет работать такой подход позволяет нам переживать падение отдельных сервисов падения сети может падение дата-центра целиком при этом процесс который например процесс создания кластера который может занимать 5-10-15 минут он не развалится не сломается где-то по пути не застрянем просто потому что один из сервиса был недоступен или произошло сетевая ошибка или произошла ошибка которая привела к рику сильному падению сервиса можно даже в таком случае выкатить fix выглядеть его на пруд но версия сервиса поднимется считает сообщение и продолжить обработку ошибки таким образом все наши процессы стали отвечать том усилий которые требовалось и в итоге мы получили асинхронную обработку команд и синхронной обработку запросов что позволило нам еще добавить туда различные механизмы например для запросов можно добавить или трой и circuit breaker потому что мы можем себе позволить несколько раз читать одни данные эта задача очень легкая другой стороны для команд мы добавили другие патроны как-то d2 терке или l-boxx по которой скажу позже для того чтобы выполнить какие-то сложные вещи на уровне матирующих аберраций например создание кластера в итоге мы получили достаточно большие гарантии доставки сообщения и выполнении длительных операций через secures и асинхронные команды но у нас все еще были некоторые задачи которые нужно решить в частности были вопросы консистенции sti данных простой пример мы выполняем какие-то действия обработку события приходит события о том что виртуальная машина создана и нам нужно запустить на ней операционную систему мы достаем данные из базы данных запускаем логику домена которые по конечного автомата смотрит а что следующее что нужно сделать отправляет соответствующую команду в кафка команда запустить операционную систему и дальше заканчивать обработку и меняет статус меняет состояние этой виртуальной машины на следующее что мы ждем запуска person системы и сохраняет изменения в базу данных это все происходит в транзакции базы данных но есть нюанс а что будет если вот здесь произойдет ошибка и транзакция не закончится откатиться у нас президент как ассистент ность то есть наш сервис думают что данные не изменились что виртуальной машины все еще в состоянии создания но в к сервису мы уже отправили команду что виртуале машин нужно запустить и у нас данные будут экосистем двух сервисах чтобы этого избежать мы внедрили патент бокс который выглядит следующим образом мы сначала все команды отправляем в нашу же базу данных в специальную таблицу a box где они сохраняются при к мите транзакции и потом job их оттуда вычитывает и отправляет брокер сообщения в случае ошибки в базу не будут сохранены как изменение в данных так и команда которые нужно отправить другому сервису и мы ничего не сломаем не получим распределенную некая системность также здесь были вопросы связанные с взаимными блокировками и параллельной обработки команд когда например запускаем набор виртуальных машин для worker нот и они начинают параллельно быть готовыми или еще что-то и нам нужно менять статус виртуальных машин их групп над и самого кластера в этом случае мы просто реализовали блокировку базы данных на уровне кластера и этого было достаточно для того чтобы развести параллельные операции чтобы они друг другу не мешали постольку поскольку у нас сервис не под очень большой нагрузки по запросам нам этого хватило но если это не слуги не ваш случай то блокировки можно делать не на корневой узел доменом агрегате то есть кластер а например на какую-то более низкую сущность так чтобы у вас не было конфликта на этом уровне в итоге мы решили наши вопросы с консистентными и не консистентными данными и у нас остался осталась последняя тема это наблюдение за тем что же происходит изначально у нас были только логе в небольшом количестве в этом и выпить сервисе этого конечно же не хватало для того чтобы наблюдать за всем им и первое что сделали это реализовали распределенный tracing для этого мы использовали стандарт у пациентов потому что окон телеметрии тогда еще был в бете и реализовали сквозную сквозной tracing через ищите пейджер писи и кафку и получили вот такие замечательные trace и когда мы в одном месте можем посмотреть целый процесс создания кластера который включает себя дюжину микро сервисов включает в себя долгие длительный процесс который может занимать десятки минут минуты десятки минут и здесь сразу же видны ошибки то есть когда у нас что-то происходит при приходит инцидент мы можем локализовать место ошибки за буквально меньше чем за минуту хотя раньше это занимало очень много времени потому что нужно было скрывать логе искать пологом в какой системе произошла ошибка как это ошибка связана непосредственно с тем кластерам который сломался сейчас же это стало занимать несколько кликов более того мы добавили влоги и в события центре который мы используем для мониторинга ошибок trace айди то есть по логам когда мы видим что какие-то ошибки происходят или по сообщению в центре мы сразу можем открыть нужный trace и посмотреть целиком процесс и быстро найти ошибку и это позволило нам значительно упростить как дебаггинга как отладку поиск каких-то проблем так и поддержку клиентов продуктивной системе где мы стали очень быстро находить проблемные места и сразу исправлять их и в итоге мы пришли к тому что мы имеем сегодня то есть система которая работает отказа устойчиво работает хорошо и работает относительно быстро при этом мы можем быстро выкатывать новый функционал быстро находить ошибки и легко понимать что же написано в коде и того процессы создания удаление изменения кластера перебалансировки групп но ты так далее стали отказоустойчивой мы можем себе позволить уронить один сервис или выкатить fix или восстановить целый дата-центр при аварии и не прервать процесс создания или изменение или удаление кластера и данные в разных системах консистентные за счет того что мы сделали и таким образом мы добились того самого магического числа в четыре девятки по доступности и по выполнению операции кот стал намного более читабельный он все еще сложный некоторые конечно автоматы имеют колоссальный размер но в нем легко ориентироваться он довольно простой довольно не нагружены каким абстракциями и сложная логика понятна и самое главное чтоб целый процесс например создание кластера он целиком видит в коде можно открыть код сервисов и просто почитать без запуска без за счет чего то просто по коду понять что и в какой последовательности фичи добавлять очень быстро мы можем позволить себе за несколько дней реализовать новый функционал и на следующий день вы хотите его пользователям и начать пользоваться и тесты автоматизированные также стала писать значительно легче потому что мы используем гексагональную архитектуру в рамках которой разные слои изолированы друг от друга и мы используем эту изоляцию для того чтобы писать unit интеграционные тесты для разных частей сервисов и выполнять их в автоматическом режиме но и главное что скорость локализация ошибок сократилось на несколько порядков от десятков минут иногда часов до одной или нескольких минут в худшем случае отладка при разработке при каких-то проблемах значительно упростилась и таким образом вы уменьшилась и выросла скорость обработки заявок по результату довольны и разработчики которым стало намного проще работать и намного проще фиксит баги довольно тестировщики которые в случае когда тесты идут не так могут легко открыть и найти что же конкретно сломалась и написать и что-то исправить и довольные клиенты которые всегда получают сервис на высшем уровне на этом у меня все я был рад рассказать про все сложности который прошел наш продукт и интересные вещи которые мы реализовали и буду рад ответить на вопросы спасибо так значит у нас сейчас времени буквально на один вопрос здесь вот кто готов задать прям самый крутой вопрос который он в принципе когда-либо придумывал вот я вижу слева человека добрый день меня зовут станислав мне хотелось поинтересоваться как происходит управление допустим trace айди для центре в рамках слоеной архитектуры то есть вот есть допустим уровень кластера под ним еще ниже уровень на каком уровне генерируется trace айди и чем это определяется до поэтому используем три сайте непосредственно из окон census а как это делается но если мы говорим про g'lang мы trace информации от ray свяжет контексте кодируется очки трясучки запрос для правильным образом соответственно когда нужно что-то за лагерю или когда можно отправить информацию в центр и мы этот трек сайте извлекать из рейса и подкладывал а центре нас интегрируем слогом соответственно с ними блока пишем что-то выше определенной severity допустим р и в этом-то и то же сообщение отправляется в соответственном и лагерь сообщение структурном виде формате вместе звука за него три сайте из-за стресса это попадает логе это попадать в центре потом когда мы откроем в центре работникам просто берем 3 берем идем идем и смотрим лиги что у нас от отлично спасибо большое илья давайте еще раз поблагодарим до пасибо большое за отличный доклад"
}