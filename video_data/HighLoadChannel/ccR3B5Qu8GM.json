{
  "video_id": "ccR3B5Qu8GM",
  "channel": "HighLoadChannel",
  "title": "Высоконагруженная VDI из Open Source для платформы киберучений «CyberCamp» / Семен Барышников",
  "views": 77,
  "duration": 1838,
  "published": "2024-10-29T03:07:37-07:00",
  "text": "Меня зовут Барышников Семён и опять-таки я расскажу о том как мы строили высоко нагруженную видя из он сорса в облачном кубернетес для нашего мероприятия сабе Camp Что такое вообще сабе Camp мы проводим открытое мероприятие Один раз в год которое включает в себя конференцию Федерального масштаба и также кибр учени в формате ctf о которых как раз-таки пойдёт дальше речь для прохождения заданий ки Беруни участнику необходимы как инфраструктура Так и набор специфического инструментария также мы делим наши задания на и blam тематики мы провели уже два больших Сайбер кампа по 3 дня каждый в дцать втором году мы пригласили 200 участников практических ки беруний в третьем уже 500 часто нам задают вопрос зачем вы вообще стали заморачиваться с просто дать конфиг ОТП и пусть подключаются к инфраструктуре сами на что есть несколько возражений во-первых видеа сразу есть абсолютно всё необходимое для прохождения наших заданий тем самым Мы обеспечиваем одинаковые условия для всех участников также это позволяет нам решать проблемы на лету так как вся абсолютная инфраструктура находится на нашей стороне мы имеем к ней полный доступ время решения любых проблем также здесь можно увидеть как выглядит В итоге в браузере участника наши vidi то есть прямо внутри неё есть браузеры для доступа к инфраструктурным компонентам есть также консоль само собой и весь инструментарий также это вот часть списка того что необходимо было иметь на своей рабочей станции в двадцать третьем году чтобы проходить задания и В наших глазах участники накануне мероприятия выглядели бы примерно вот так когда мы только начинали строить наши видеа ещё в двадцать втором году м первое чем мы задались вопросом а Стоит ли делать вообще это всё на виртуалка как это в общем-то обычно принято решили попробовать сравнить их с контейнерами и может быть оно окажется чем-то лучше начали сравнение конечно же с потребляемых ресурсов для начала м сравнили виртуалку и контейнер с идентичным набором инструментов и воспроизвели один и тот же абсолютно сценарий м действий а также полученные ресурсы именно для контейнера применили к виртуалке заведомо они оказались меньше И вот как раз-таки виртуалке оказалось работать э намного менее комфортно А в итоге мы для контейнера определили то что достаточными будут всего лишь одно Ядро 3 ГБ оперативной памяти для виртуальной машины же эти ресурсы были бы примерно в два раза больше далее мы начали строить планы по тому как мы будем устраивать сеть для виртуальных машин же нам понадобилось минимум серьёзный фалин то есть скорее всего какое-то й решение либо там вообще фв также у нас в любом случае Получилась бы сложная топология виртуальных машин потому что у нас 100 команд по пять человек и каждую команду было необходимо изолировать от других чтобы никто всё-таки не смог помешать другим проходить зада также нам ре и как-то бы пришлось назначать IP адреса и их инвентари в кубернетес же чтобы добиться абсолютно тех же результатов нам достаточно было бы всего лишь одной сетевой политики всё остальное делает куб А сетевыми политиками мы как раз-таки обеспечиваем фаер волин также у кубернетес есть достаточно серьёзные плюсы в плане развёртывания во-первых контейнер поднимается если конечно же на ноге уже зашивал образ всего лишь буквально пару секунд также никогда не может произойти конфликт IP адресов потому что Куп управляет этим сам также он имеет встроенный механизмы проверки состояния которые будут помогать в случае если всё-таки что-то развернулось неправильно Возможно с другой попытки это всё-таки удастся такое тоже происходило но у виртуальных машин есть один существенный плюс это простота управления ресурсами И всё-таки абсолютно жёсткое их резервирование если создать виртуалку там 2 едра 4 гига то что бы не происходило вокруг как бы не нагружать свои виртуалки другие участники эта виртуалка получит свои ресурсы в кубе же этого добиться немножко сложнее как минимум из-за того что да для процессора можно жёстко ограничить потребление процессорного времени но вот с оперативной памятью не всё так просто даже указав какие-то лимиты контейнер может за них выйти не зря существует такая вещь как он Killer развёртывать Мы наш контейнеры Естественно с помощью хим чарта м с самописец вых доступов как мы их формировали расскажу немножко позднее э в итоге м мы получали деплоймент сервис с уникальным именем с помощью которого уже можно подключаться к деплоймент и сетевая политика также мы задумались о том как бы мы администрировать всё это если располагали бы это в виртуальных машинах мы могли бы пытаться это починить не прогнозируемом и также результат не 100% то что это получится мы мог переворачивать виртуальные машино этого По време палка удалится пока развернётся новая м пройдёт существенное время также мы могли попытаться выдать виртуалку из резерва но во-первых этот резерв необходимо иметь э в случае чего его необходимо пополнять то есть много операционной деятельности и также Даже если мы эту виртуалку всё-таки выдаём её придётся так сказать ввести в сетевые политики м команды участника так как они все имеют уникальные сетевые доступа что же произойдёт если участник сломает Свой контейнер каким-то образом во-первых может отработать проба мы настраивали на довольно значимые компоненты нашего контейнеры их и если всё-таки участник себе там например внц сервер удалил то отработает она и контейнер автоматически перевернётся либо произошло что-то другое участник нам написал батате в поддержке мы просто руками пошли и удалили ему контейнер тут можно возразить то что Ну тогда же по идее участник теряет свой Прогресс у него контейнер же развернётся С нуля Да это Абсолютно верно но мы честно предупреждаем всех участников то что в любой момент без какого-либо предупреждения или причины ваша Рабочая станция может быть перезагружена поэтому ничего критичного и серьёзного в ней не храните Если вы там нашли флаг то сразу скопируйте его куда-то вовне благо работает в об стороны у нас В итоге он просто потеряет ОТК вкладки ВУЗ и какую-то там историю команд в консоли что в общем-то не так уж и тично и восстанавливается ЕС кратко подвести итог Томы выли to maret в угоду так сказать подходу и в общем-то у нас получилось то что мы задумали в какой-то момент встал вопрос Где же нам развернуть нашу всю инфраструктуру точнее как минимум именно инфраструктуру vdi мы начали сравнивать он прем либо облако в первую очередь облако естественно имеет свои преимущества по сю и зонам доступности например в Яндекс облаке их было три сейчас уже даже времен экс преми же добиться подобного стоит очень дорого больно и долго порог входа в облако можно считать нулевым в преме же это много миллионов на всего лишь оборудование уже вынося за скобки даже людей которые будут это всё обслуживать э также существенным плюсом облака является то что есть менедж сервисы которые в преми пришлось бы выстраивать и администрировать абсолютно самим далее встал вопрос Как нам доставить сессию пользователя до его десктопа м из Open Source решений мы нашли в общем-то только всего лишь одно это гуакамоли больше альтернатив практически не существует Либо они уже давно не поддерживаются гуакамоли уже хоть и медленно но постепенно развивается и даже обновляется буквально в этом году Было мажорное обновление по умолчанию что в официальной документации что в каких-либо гайда в Гугле описывается как два контейнера Клинт и сервер более никаких топологий в общем-то никто не пытался разрабатывать Но нам это не подходило потому что как мы выяснили эмпирическим путём способен подни Тём несложных математических вычислений можно понять что это как минимум в семь раз меньше чем нужное нам значение мы стали изобретать М В итоге в первую очередь мы отмашка моли клиенты проблемой масштабирование клиентов является то что сессии пользователей хранятся внутри контейнера и по умолчанию из коробки Go Коли не умеет складывать их например какой-то дис Мы пытались подключить дис но в итоге у нас это не вышло хоть и гомо внутри себя использует Tomcat нам не вышло подключить туда какой-либо плагин для редиса чтобы сессии хранились там в итоге мы просто с помощью липких сессий распределяли участников по различным контейнерам далее мы стали масштабировать GU сервер тут всё оказалось намного проще оказалось то что так как мы располагали гумо внутри Куба и сервер Мы располагали за сервисом то по имени сервиса с помощью внутри новое подключение случайным образом распределялось сервер и потом оно не рвалось то есть нам Тут даже изобретать ничего не пришлось всё работало и так стабильно также умоли есть поддержка некоторого перечня внутренних переменных одна из которых в общем-то будет являться именем пользователя который подключается в ито того чтобы на каждого пользователя создавать подключение и выдавать на него права и в это подключение передавалось Ну условно имя пользователя при каждом входе имя пользователя мы задавали с помощью нашего SS мы использовали Ke Clock и там с помощью мапперов это всё подняли в итоге в эту условную форму поставлялось номер пользователя номер его команды то есть namespace и далее остальная часть внутри кобо днса так каждый пользователь В итоге попадал каждый раз именно в свой десктоп Даже если он выходил закрывал сессию и открывал её потом заново для такого мероприятия как CF в первую очередь конечно же важна безопасность начали мы её сети нам у нас была задача создать уникальные доступа для каждой из сотни команд они не должны были друг другу мешать онил бы своей части инфраструктуры создано специально для них чтобы если они вс-таки сломают машину задания то это не офек бы на другие команды мы не нашли какого-то готового решения в котором можно бы это всё было сделать и Да мы использовали для этого Excel у нас все им умели пользоваться и в общем-то это на самом деле оказалось достаточно удобно чтобы инвентари получилось так сказать база данных далее мы это всё спарсить с помощью питона преобразовали в значение для хим чарта и в итоге Чар у нас э деплоя сотню уникальных политик также м у нас все задания открывались по расписанию и буквально за 5-10 минут до Мы раскомментировать всего лишь одну строчку в значения хильма шили это в репозитории и дальше arg CD это уже деплоя внутрь Куба и открывался доступ к следующему заданию когда мы говорим о расположении чего-то в кубе то зачастую встаёт вопрос об использовании контейнер Security решений по нашему мнению в первую очередь Коте Security решение должно хотя бы детектировать какие-либо события и инциденты зачастую самое любимое - это сканирование сети участники начинают сканировать не только машины заданий но бывало что даже нашу инфраструктуру что мы хотели бы видеть и естественно пресекать также такое понятие как dft prevention это можно сказать проприетарное понятие Ате sec но суть его в том что участник может всё-таки каким-то образом доставить себе какой-то Бинар на рабочую станцию либо там скрип илита запустить сообщить также м мы бы хотели видеть потенциально вредоносные процессы и активность То есть даже если участник всё-таки не доставит себе э ничего дополнительного на десктоп то он может даже с помощью стандартной оснастки линуса например поска нероева э порты э также многие решения умеют контролировать действие пользователей то есть выполнять inforce мы М разделили в общем-то типы Форса на два это завершение работы всего контейнера первое то есть Представьте участник выполняет задание вводит какую-то привычную абсолютно ему команду в консоль которую мы со своей стороны посчитали неприемлемой И решение просто выключает ему контейнер контейнер полностью перезагружается его любимые вкладок в браузере закрываются история команд пропадает что в общем-то было бы не очень приятно и участник мог даже с первого ра не понять это именно его действие вызвало завершение работы всего контейнера также есть решения которые умеют завершать конкретные процессы То есть если участник попытается что-то запустить у него это просто-напросто не выйдет весь остальной контейнер продолжит работать и он не потеряет свою сессию также есть ли вообще необходимость в контроле Честно говоря мы склоняем больше к тому что нам это вки необходимо нам в первую очередь хочется это видеть и по опыту двух лет мы поняли то что один-два человека буквально которые поглядывает в консоли решения которое способны хотя бы детектировать способны абсолютно спокойно переварить все инциденты потому что их Ну всё-таки происходит не так уж и много участники зачастую заняты выполнением заданий поэтому мы считаем что это скорее дополнительная м вещь которая может быть в какой-то момент нам стало любопытно А сколько мы вообще в теории можем расположить пользователей всего лишь в одном кластере м какой-то готовой информации не нашли пошли просто считать м в столбик оказалось что при двадцать четвёртой по сети узлов и использовании силиум можно развернуть Чуть более 7 млн подов всего лишь в одном кластере при двадцать восьмой же Поти узлов э это уже цифра переваливает за 8 млн ожидайте в д чертом году сабе на 8 млн человек Это конечно шутка но в теории это в общем-то даже возможно единственное ограничение с которым мы столкнулись в общем-то в Облаке по крайней мере именно в Яндекс облаке это то что невозможно управлять ресурсами мастеров напрямую то есть мы готовы были заплатить денег только Дайте нам нажать эту кнопочку которая поднимет ресурсы в итоге мы пошли в техподдержку и попросили их об этом м на что нам ответили то что да у одного кластера мы видим высокую утилизацию мы вам поднимем ресурсы без проблем А вот у второго кластера мы Такой необходимости не наблюдаем м на что мы конечно начали возражать В итоге дошли до Второй линии этих поддержки объяснили то что у нас на носу серьёзное мероприятие и будет не очень приятно потерять управлением кластером в самый неподходящий момент М В итоге нам пошли навстречу за что им Большое спасибо И заранее увеличили ресурсы мастеров второго кластера и даже потом во время мероприятия на второй день нам написали что мы всё-таки были правы И если бы они этого тогда не сделали то возможно произошло бы что-то неприятное когда мы проектировали нашу топологию сети в Облаке мы выяснили то что один участник в среднем потребляет только лишь на одно внц соединение 10 мегабит в секунду если посчитать то это получается на 500 человек как минимум 5 Гигабит так как мы использовали несколько зон доступности в общем-то официальным способом является использование так называемого роутера на палочке то есть роутера на Стик который будет подключён ко всем сетям и будет между ними маршрути Зро трафик так как нам опять-таки не нужен был серьёзный функционал какой-то фанга у нас это ВС обеспечивали сетевые политики Куба Мы решили использовать например Open так как он в общем-то нам был знаком и просто Open sce но Выяснилось что он способен пропустить через себя всего лишь 2,8 гиби в секунду Чего нам естественно не хватало и Open Sense В наших глазах именно в Облаке стал выглядеть примерно вот так подумали Том чтом ВМ практически любого ликс дистрибутива м Главное чтобы в нём был Хотя бы NF tables нам бы этого хватило с головой чтобы написать наши несколько правил э начали перебирать м первую попал первая попробовали у бунту м она выдала вообще всего лишь 2 гиби в секунду центос седьмой Фира тридцать пй и двенадцатый dban выдали по 4 с поно что нам почти хватало но всё-таки не совсем устраивало но на удивление CentOS Stream выдал аж 5,8 объясню зачем мы вообще начали этим заниматься нам не хотелось без крайней необходимости горизонтально масштабировать наши роутеры мы хотели всё-таки добиться хотя бы с помощью одного и в какой-то момент вертикальное масштабирование тоже работать переставала то есть это максимальные значение которые нам удалось добиться при вертикальном масштабировании одной сущности Э теперь про автомаш бирони и почему оно нам не подошло по крайней мере именно про ноды в первую очередь это конечно же стоили контейнеров если в какой-то момент контейнеры участников начнут просто беспорядочно переезжать с одной ноды на другую то мало кому это понравится также новые ноды могут развёртывать как несколько минут так и несколько десятков минут мы не знаем причин такого поведения но мы это испытали на своём опыте то что ты можешь полчаса час ждать пока развернётся новая нота и пому происходит также возможен резкий наплыв участников так как задание открываются по расписанию то перед началом следующего задания человек мог отойти там покушать отдохнуть а к началу он уже подходит и таких людей много И тем самым получаем резкий перерост нагрузки как-то можно ли использовать наш опыт для других типов мероприятий абсолютно дасть Вы можете взять друго Бао об бунту поставить туда всего лишь один браузер и для вашего мероприятия этого будет абсолютно достаточно Могут ли наоборот рабочие места потреблять больше ресурсов тоже да вам придётся лишь от масштабировать ноды либо вертикально либо горизонтально в зависимости от вашего количества участников особых проблем тут не будет Можно ли обеспечивать частичный или полный полный Наверное вс-таки нет Потому что во-первых это конечно же противоречит просто принципу контейнеров то что они по сути должны быть неизменяемые и каждый раз разворачиваться заново также бы это сломало принцип того что мы всего лишь одним рестартов у участника Но если хочется обеспечить частичный йф то есть хранить например историю браузера или там домашнюю директорию пользователя то это вполне реально объектного хранилища но стоит помнить то что если вы если какое-то из программного обеспечение которое есть у вас в контейнере использует например базу данных то оно туда Просто не сохранится тут необходимо уже будет использовать блочное хранилище которое в первую очередь всё-таки немножко сложнее администрировать и содержать если не используется какой-то мене вон другую при рестар то Придётся подождать какое-то также не особо известное время пока persistent Volume с одной ноды переподключиться на другую Также можно использовать другие протоколы подключения Мы использовали внц также GU поддерживает прямо из коробки ssh идп Также оно даже поддерживает EX в контейнеры внутри куба если вам там нужен просто консольный интерфейс а также м Куп в общем-то полезен в тифе как минимум потому что там можно разворачивать вспомогательные сервисы у нас там были и портал развёрнутый ССО и другие сущности также там можно развёртывать инфраструктуру Для заданий это могут быть как уязвимые машины у нас такой был опыт то есть машины которые необходимо участнику атаковать и вытащить оттуда флаг также это могут быть сзш м какие-то сзш можно обходить То есть у нас был опыт с обходом куве участникам необходимо было раздеть своё приложение обойдя политики которую мы настроили также это могут быть сзи которые необходимо до настроить либо же расследовать там инцидент также мы использовали для балансировки трафика http трафика контейнере тоже в Кубе в общем-то на этом У меня всё Надеюсь у меня получилось разрушить какую-то дому в ваших головах что вид может быть только на виртуалка будем рады увидеть вас на двадцать чертом Сайбер кэмпе Спасибо за внимание Спасибо за доклад А теперь вопросы Здравствуйте спасибо за доклад Илья из ВК А ну вот я правильно понимаю весь vdi - это кубернетес с ресурсами для пользователей и доступ это гко вот сам ГМО тоже в и на каких-то других нет Да он тоже расположен полностью в том же кластере что и сами контейнеры vdi то есть они располагаются в одном кластере как раз таки чтобы использовать имена сервисов То есть их ДНС для подключения Спасибо за доклад вос следущий там буквально на предпоследнем слайде было то что делали C уязвимыми машинами А как получилось сделать так чтобы контейнер sec не ругалась на уязвимые машины всё было немножко проще мы выносили это в отдельный кластер в котором не было контейнер Security и в общем-то для этого его не использовали пола спасибо Меня зовут Дмитрий бу Спасибо за доклад Он был очень подроб ло мил вопросов ме доклада они все у меня закрывались остались в принципе два Первое - это там плюс-минус какое соотношение между Ну там по оценкам было между вием и между собственно контейнерами И второй вопрос вот у вас на одну ну виртуалку на один контейнер приходилось 10 мегабит это в принципе очень много сколько у вас примерно по оценкам было а скажем так я бы так сказал не имеет ли в данном случае смысла использовать vidi потому что это получается примерно ну порядка п машин на один сервер так первая часть вопроса про ресурсы была по сути vdi потреблял наверное менее дети если не менее 5% от в общем-то мощностей которые использовали участники именно для своих контейнеров для конечного десктопа А по поводу пропускной способности в общем-то единственным вариантом который есть именно в это снизить качество то есть мы выбрали там приемлемый уровень который будет хоть как-то красиво вменяемость Нежа там совсем уж квадратики будут и цвета не очень хорошие а классический видя и разве серьёзно меньше потребляет в общем-то Да у нас сжатие было на стороне конечного балансировщика Семен ещё Вопрос такой прозвучал про то что у вас кубе мастер начали не вывозить нагрузку А не проще было бы и на нох вот мастера полить по компонентам так можно было но зачем если есть менедж сервис и часть с Мы полностью перекладываем на обла и за нам нужно было Хоть как-то себя разгрузить потому что и так фронт работ был достаточно большой А есть какие-то данные вы можете сказать сколько нагрузка у вас было по пользователям и Какие ресурсы были в двадцать третьем году То есть было 500 человек то есть там чуть-чуть поменьше пиковая нагрузка была но в итоге кластера у нас были если я не ошибаюсь Ну там оперативной памяти точно было больше теба суммарно на все ноды а процес Точно больше 300 ядер Точнее ну ближе к 500 вроде бы точную цифру не вспомню Спасибо Вы хотели вопрос задать Вот про первую часть доклада про выбор между vidi вы говорили что очень долго стартуют у вас классические виртуалки А вы в какой комбинации их пробовали собственно с какой средой виртуализации потому что вот мой опыт показывает что с Каширова золотым образом они поднимаются почти мгновенно может не 2-3 секунды как в этом самом но во всяком случае это время старта операционки То есть это там ну десяток секунд при нормальных дисках да то есть мы во-первых это располагали в Облаке то есть с помощ просто терраформа и провайдера для облака мы это вот как раз-таки проверяли вот Ну даже если там будет 1020 секунд Но это всё-таки больше чем пара и когда счёт идёт в общем-то на те же самые секунды при выполнении заданий которые там закрываются открываются по расписанию это может быть для участников критично и вызвать у них негативные эмоции так Ну что вопросов больше нет спасибо за доклад тогда а просьба выбрать самого самого лучшего вопрошающий Давайте молодой человек В жёлтой кофте Спасибо"
}