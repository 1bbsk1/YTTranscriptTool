{
  "video_id": "CCt-tKN7VrY",
  "channel": "HighLoadChannel",
  "title": "Нагрузочное тестирование синтеза и распознавания речи в SberDevices/ Андрей Чернопятов (SberDevices)",
  "views": 637,
  "duration": 2237,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "Всем привет Меня зовут Андрей черноветов последние несколько лет я довольно плотно связан с Темой тестирования различных систем синтеза и распознавания речи и в ближайшие полчаса минут 40 попробую вам передать какой-то дистиллированный опыт нашей команды чтобы понять откуда этот опыт вообще начался выбираться Откуда взялась задача и почему он такой как у нас получилось нужно будет дать небольшую вводную это быстро несколько лет назад Сбер банк такой решил начать делать физические устройства вселить в них виртуальных ассистентов изначально закладывалось во всю эту историю штука что именно должно быть возможно управлять голосом то есть они должны вас слышать и уметь отвечать абсолютно все устройства которые мы делаем на картинке Некоторые из них кажутся не все цифры на фоне она про то что у нас Купили уже больше миллиона штук этих вещей гайс говорят не видно слайдов Хотя вот здесь я вижу что вся меняется вот картинка устройство миллион штук купили плюс эти же виртуальные ассистенты живут в мобильных приложениях сбера живут в контактных центрах Ну то есть у нас есть в принципе довольно приличный трафик если у нас есть первичный трафик нам нужно как-то системно подходить к вопросу производительности и собственно делать нагрузочные тестирование чуть-чуть про то что вообще такое нагрузочное тестирование в нашем понимании есть часть которая просто про стабильность сервисов она в принципе такая же у нас как и в любом другом софте тесты должны проверять что сервисы не падают что память не течет дискрипторы не текут в общем такие вещи проекты я не буду рассказывать и вторая важная задача это чтобы мы могли по результатам тестов ответить на вопрос Сколько нам нужно железо чтобы какую-то работу сделать чтобы обработать какое-то количество вопросов Вот про то как правильно мерить Вот это и оценивать как раз сегодняшний доклад начнем мы с распознавания речи аббревиатура айсар это томатекспичеры как ниша Так мы называем внутри кажется что есть какие-то еще аббревиатуры но в общем в рамках вот этого выступления Если я говорю айсар то это распознавание речи Если вдруг кто-то не знает что такое распознавание речи это такие механизмы Когда вы даёте аудио в какой-то сервис а он обратно вам выдаёт текст Ну если там какой-то текст был наивный подход то есть вот вы сделали первый релиз вашего сервиса и вам нужно как-то проверить э-э как работает эта штука с точки зрения производительности самое простое решение в лоб это вы просто заранее подготавливаете аудиофайлики и эти аудиофайлики кидаете телефон как есть ваш Сервис через какое-то время вам приходит ответ время между этим вопросом мы собственно получением ответа Вот ваша задержка ваша способ оценивать производительность сегодня будет много вот примерно таких картинок здесь нужно сделать ремарку про шкалу времени она не Линейная То есть то что слева это всегда раньше того что справа но не обязательно если что-то в два раза более широкое то в два раза дольше было просто для наглядности сделано схематично вот Такую картинку можно прочитать как в какой-то нулевой момент все началось примерно через 100 МС мы смогли передать этот Файлик целиком на сервер Ну примерно Я говорю понятно там будет другая в реальности цифра и ещё примерно через 150 миллисекунд сервер нам ответил это простое решение его очень легко заимплеменники легко поддерживать в принципе его легко понимать но к сожалению оно не помогает нам ответить на вот этот главный вопрос э-э Сколько нам нужно железо почему оно не понимали не помогает потому что в продакшене так никогда не происходит а в продакшене происходит по-другому выглядит это схематично Примерно вот так вспомним что мы говорим о виртуальных ассистентах то есть вопросы к ним задают люди и они задают в режиме реального времени то есть они что-то говорят микрофон это записывает Это все сваливается в цифре в какой-то буфер и из этого буфера некоторыми порциями к нам присылается звук Поэтому чтобы нам делать нормальные нагрузочное тестирование мы должны тоже резать звук во-первых на кусочки А во-вторых эмулировать вот этот Real Time если мы прикинем что у нас эти кусочки будут например по 100 МС то мы должны 100 миллисекунд спать потом отправляете автомобиль опять отправлять Примерно вот так это выглядит как на картинке То есть у нас была какая-то значит аудиозапись пусть она была трехсекундная 3000 миллисекунд мы ее так поотправляли и там через еще 150 миллисекунд получили ответ это гораздо лучше чем то что было до этого такой способ больше похож на Production и честнее позволяет оценить сколько мы Сколько нам нужно железо Но на самом деле он тоже очень существенно отвечает отличается от того что происходит реально в пройдя а-а В чём состоит самое главное отличие а значит вот на этом слайде мы когда передали последний кусочек мы еще серверу говорим всё у нас звук закончился больше звука не будет Давай начинай распознавать в реальности мы когда говорим и друг с другом из виртуальными стентами Мы никогда не говорим что я договорил что-то Ну просто говорим например Салют Какая завтра погода и ждем что сервер поймет что мы договорились и на этом месте объявит что всё фраза закончена распознает и вернёт нам ответ вот этот механизм определения конца фразы Э мы называем его аббревиатуры Эу эндофанс конец высказывания это такая фундаментальная сложная проблема в принципе распознавание речи э-э он может работать с некоторой скоростью с некоторой агрессивностью например есть три фразы Салют Какая завтра погода или Салют Какая завтра погода в Питере или Салют Какая завтра погода в Питере вечером вот в реальности я вам заранее сказал что будет три фразы и вы знаете что нужно знать там конца на практике мы не знаем когда человек говорит Ну то есть можно рубить фразы там более агрессивные или менее агрессивно Если вы делаете слишком агрессивно быстро рубите тот длинную фразу никогда не скажешь и бывает что человек на самом деле в начале запроса сам не знает будет там пауза или нет Вот как приводили какие-то ещё коллеги здесь же на этой сцене примеры из музыки человек говорит Включи мне песню Гребенщикова начинает тупить вспоминает какую но непонятно должны быть дожидаться или он может в процессе передумать Он больше не хочет вспоминать песню Включи мне какую-нибудь песню В общем раз это такая штука про которую вот надо помнить и она в инте Обязательно должна быть если мы Тестируем Вот именно по виртуальных астентов по времени плюс-минус Ну так мы возьмём абстракт на занимает примерно секунду ей можно управлять там есть куча всяких механизмов э и в НТ она у нас есть если вот этот график разложить как-то по пальцам теперь это выглядит как мы взяли наши аудио нарезали его на кусочки спим отправляем спину отправляем на второй секунде у нас закончился текст внутри фразы но при этом мы не говорим про это ничего серверу мы должны продолжать отправлять звук а сервер на третьей секунде поймет что фраза наша закончилась при том секунду назад мы об этом все еще не знаем не сообщает об этом мы все Еще продолжаем слать звук там есть кусочек звука который здесь нарисован который идет даже позже 3 секунд сервер этот звук либо отбросит либо он идет просто в следующую фразу зависимости от настроек и еще через какое-то время сервер значит пришлет нам ответ из вот этого обстоятельства есть два важных нюанса при реализации таких тестов во-первых ваша аудио теперь не может заканчиваться там же где вас текст в реальности закончился То есть если Какая завтра погода занимает 2 секунды то вы не можете Вот это аудио у вас не должно быть ровно 2 секунд у вас там должна быть тишина Если вы знаете что индуфатор плюс-минус Ну хорошо бы иметь там 3-5 кратный запас в конце вот этот просто тишины а второй момент что нужно вот эта тишина она должна быть правильная то есть нельзя просто начать слать нули во-первых вас может сам распознавание Сойти с ума потому что на самом деле абсолютных нулей в реальных запросов практически не бывает у вас модели Таких данных никогда не видели всё взрывается либо модель наоборот начинает переучиваться И как только у вас Ну что-то говорилось а потом наступает резко полная тишина модель говорит О это наверняка Ну типа конец речи и в продакшене так тоже не происходит это будут неправильные тесты соответственно вам нужна такая же тишина ровно какая была в вашей фразе если это запись на фоне там радио или дороги или там ребёнок какой-нибудь плачет Вот это всё должно продолжаться в конце звука чтобы считался честно вот это вполне рабочий способ мы довольно долго тестировали Вот примерно так нарисовано на картинке но оказывается можно еще лучше чтобы понять Как можно еще лучше нужно понять как вообще выглядит ответ сервера там понятно что есть сильно больше полей чем вот я привожу здесь на слайде главное что там есть текст есть метка времени Где в аудио закончилась самовысказывание и есть метка времени Где Когда сервер понял что фраза закончилась для этого примера сама речь шла с нулевой секунды там по вторую А еще секунду сервер понимал что человек договаривает что больше не будет ничего говорить как это теперь как можно улучшиться значит почему вообще это не идеальный способ вот у нас есть аудио там три секунды значит оно идет мы порубили его на кусочки поставим миллисекунд и отправляем мы делали Здесь такое предположение что вот когда мы 100 миллисекунд спим 100 миллисекунд отправляем 100 миллилит ему 100 отправляем Вот это процесс происходит абсолютно точностью Ну прям вот ровно сколько мы замерили Оно так и есть в реальности это не так то есть на каждый такой вот один одну итерацию такой Да засыпания и потом отправка этого кусочка на самом деле набегает небольшая погрешность Ну как минимум вам чтобы что-то передать в Сервер это всё равно какие-то миллисекунды то есть хотя бы там две-три-пять если вас при этом есть не знаю шифрование что ещё угодно там какие-то работы с этими данными перекладка В общем это легко набегает там несколько секунд для трех секундного аудио мы если нарежем его на кусочки по 100 миллисекунд и получается 30 штук если на каждую будет задержка хотя бы 5 миллисекунд она Копится то получается что тот кусочек звука в котором было реальная отметка времени это 3 секунды мы его отправим в реальности в три секунды Плюс 150 секунд Вот это набежавшая задержка что из этого ответ сервер когда Значит нам даст мы замеряем как будто у нас этой Задержки нет то есть наш если вот эту картинку взять то наша старый способ измерения он вычитал из трех 250 3 то есть мы знаем сколько секунд звук было отправлено но в реальности надо вы читаете из трех 250 3150 то есть разница в оценке она будет там почти двухкратная для этого конкретного примера а что с этим соответственно нужно делать нужно запоминать время отправки каждого чанка способ оценки выглядит теперь вот таким образом то есть когда к Вам пришел ответ сервера ответьте сервер написано что индуфатаренс работал на третьей секунде вы идете ищете Где у вас был отправлен тот кусочек в котором был вот этот звук на котором отметка времени там три секунды будет неровная где-то в серединке У вас есть трек когда был отправлен каждый кусочек и вы находите время этой отправки и получаете вот для данного примера это будет собственно 100 миллисекунд Этот способ которым мы Тестируем сейчас он довольно честный и соответственно мы подаем больше и больше запросов и предел насыщения Да нашего NT это когда вот эта задержка начинает расти Ну то есть мы для себя определили какой-то порог что мы не хотим чтобы она там больше чем сколько-то миллисекунд вырастало выяснили где этот порог насыщается и узнали сколько мы можем реалтаем потоков обрабатывать вот таким способом мы меряем сейчас Этот способ точно не идеальный можно делать явно Лучше когда-нибудь наверное мы сделаем лучше Почему Этот способ не идеальный потому что пока мы все вот это писали разрабатывали несколько последних лет у нас пришли новые клиенты которым нужны другие способы пользования нашего продукта например есть ребята которые пришли которым вообще не интересно им интересно сколько сотен тысяч часов можно в нашем сервисе обработать там за день Например у них архивы звука и задержка для них критично Ну точно не миллисекундная их там подождать несколько минут совершенно нормально для них им мерить таких ребят нужно совсем по-другому а вторая сложность это что у нас появляется новые фичи кроме непосредственно распознавание речи Мы научились всяко раскрашивать звук например шепот не шепот эмоции какие-то такие вещи возвращаются тоже или вообще всякие штуки про то что недавно выкатили что теперь можно записывать кидать аудио в котором несколько человек говорят и оно их разложат там на значит отдельных говорящих и выдаст распознавание для каждого и вот эти вот новые способы использования новые клиенты если их перемножить на все новые фичи то получается очень большое многообразие и всё тестить нет возможности но хочется Каким образом это делать пока не придумали мы Тестируем просто на самом деле самые часто используемые конфигурации какие-то фичи остаются таким образом Ну как бы недостаточно тестируемыми хочется тестировать все но при этом Ну условно не тратить на это там миллион серверов понятно что можно запустить разные конфигурации на куче железа и оно быстро отработает но это будет типа дорого стоить пока не придумали что с этим делать но в общем через два-три года наверное доклад надо будет как-то апдейтить явно он будет другой про распознавание это на самом деле все Сейчас я расскажу про а для синтеза мы используем аббревиатуру РТС текст to Speech простой вариант выглядит ровно тоже как на картинке начало запроса мы кидаем какой-то текст в отличие от аудио мало весит на это несколько там десятков байт и например вот здесь через 4 секунды вся эта аудио сгенерировалась и нам отдалась примерно оценка Ну так чтобы мы как-то одинаково это видели 100 символов генерируется 4 секунды а звучат шесть понятно что этим можно управлять Ну то есть можно сделать какой-нибудь синтез на технологии Unit selection который будет генерировать типа 2000 секунд звука на одном ядре но при том это качество этого синтеза будет отвратительным будет совершенно понятно что это говорит робот и быть некрасиво если мы используем современный синтез с технологиями там с красивыми интонациями управляемыми с которыми очень сложно отличить уже от человека то примерно мы держим значит вот это соотношение в полтора за 4 секунды звука мы можем сгенерировать примерно шесть тоже можно было бы так тестировать может быть мы даже когда так и делали но в общем в Production всё опять не так поэтому Этот способ подходит плохо в продакшене всё выглядит могло бы выглядеть как-нибудь вот так то есть мы говорим сгенерируем например тот же какой-то ответ на прогноз погоды какой-то текст приходит понятно что звук генерируется не мгновенно на 4 секунде а он по времени То есть можно примерно сказать что если мы за 4 секунды сгенерировали 6 секунд звука то за две три секунды Ну в общем какая-то часть звука явно готова раньше чем в конце чем через 4 секунды поэтому теоретически мы можем прямо сразу начать отдавать какой-то звук по мере готовности так как мы знаем что он будет быстрее реалтаем и выпекаться то он ну успеет сгенерироваться и всё нормально срабатывает в реальности так никогда не получается Проблема в том что вот здесь вот эти значит кусочки они тоже идут равномерно они там какого-то качественного размера правильного в реальности возникают задержки э-э очень разных здесь местах и от этого звук получается плохой Это всё ломает То есть можно сделать какой угодно крутой красивый значит сочный синтез Но если у вас возникнет вот где-то при передаче этих пакетов задержка то человек у него сразу получается плохой пользовательский опыт Если задержка Ну типа на 5 миллисекунд вы даже не услышите ничего страшного но если он говорит там сегодня плюс две надцать и там Застрял на пол секунды то это прям крипово это очень плохо так не должно быть ломает все усилия То есть все понимают что это робот и в общем некрасиво звучит ещё хуже может быть только если эти задержки они так вот друг за другом идут говорит то нет западающий голос это очень плохо э-э соответственно Какие вообще бывают с этим сложности Например когда-то у нас синтез работал вот так значит мы кидаем запрос и у нас супер быстро Ну типа через 15 секунд приходит ответ ну вроде бы и мы по этому поводу говорим Ага Ну значит звук пошел Давайте включать динамик клиент начинает проигрывать но при этом типа к нам приехала байт там 30 А после этого ничего Нет нет никакого еще там ну долго может быть пол секунды секунду оказалось что когда мы добавили поддержку какого-то нового формата аудио то мы стали очень быстро отдавать заголовки Ну потому что они просто есть сразу это бесплатно а звук еще не готов и типа мы отдавали эти заголовки Но тот кому мы отдаем Они же не знают что там звука еще нет На самом деле они начинают проигрывать Это неправильно при этом так еще у нас был мониторинг настроен на продакшене что мы-то показали всем что у нас там вообще супер быстро стали работать мы там вместо раньше мы отдавали там примерно через 400 МС начало А теперь отдаём через там 40 миллисекунд Мы ускорились в 10 раз оказалось вот нет оказалось всё выглядит Вот так и мы звук отдаём по-прежнему такой же скоростью А что с этим делать Особенно с точки зрения НТ Надо мерить задержку не до получения первых Байков А до первых например там 100 миллисеку звука Ну тогда вы точно знаете что звук пошёл а ну наверное про это тоже надо сказать почему плохо мерить получение конца потому что вас просто каждая фраза будет генерироваться разное время и бесполезно на Таких данных какие-то выводы делать А вот начало будет для оценки подходит гораздо лучше когда звук пошел соответственно это вот примерно вот так выглядит то есть сделали запрос миллисекунд через там 300 наверное зависит от всяких факторов к вам пойдет какой-то звук когда значит пришло первые 100 миллисекунд или больше вы делаете отметку Вот это задержка получения ваших звука Это есть ваше целевая Метрика которую вы следите когда тоже наливаете нагрузки на сервер пытаясь понять когда это взрывается когда он начинает плохо Прям генерировать тут Наверное да надо добавить Мы в итоге выбрали такую стратегию если дать в наш сервис запрос на синтез и вдруг каким-то образом Он увидит что у него просто нет свободных ядер то он не будет синтезировать вообще Он решает Что лучше чем я дам синтез с дырками Я никакого не отдам Подождет пока Может быть ядро освободиться А потом просто вернёт что-нибудь 503 типа нет ресурсов простите вы пришли в перегруженные сервер реальности конечно в продакшне мы следим что у нас всегда там есть X2 там X3 большой запас Короче говоря в принципе мы не отдаем звук с дырками это считается ошибкой но это не все проблемы которые у нас бывают бывает что первые 100 звука пришли быстро а потом все равно возникла дырка это может быть от чего угодно на самом деле можно начиная от сети что у вас где-то эти пакетики почему-то там не знаю коммутатор решил переключиться пошли ретрансминты и все поломалось в продакшне Понятно происходит чаще У нас Интернет есть сейчас абсолютно в любой деревне и люди пользуются этим из мест где со связью не очень хорошо и там этот звук может идти с какими угодно гэпами Поэтому нам нужно это учитывать может стать так Ну это же нагрузочное тестирование что у вас просто в начале были ресурсы под то чтобы вот синтезировать когда это только начиналось процесс А в процессе они кончились Ну какие-то пришли ещё запросы всё закончился или там ГПУ заканчивался и не успеет В общем будет дырка такие запросы мы называем запросы с голоданием буфера здесь подразумевается что это буфер воспроизведение и их не должно быть Ну то есть вот этих провалов не должно быть все запросы должны быть без голодания буфера как это измерять то есть понятно что мы не включаем звук в реальности играть и вообще в серверах нет звуковых карт мы эмулируем просто этот буфер воспроизведения когда к нам приходят ответ мы его накладываем какой-то буфер и просто проверяем сколько там есть секунд чтобы играться Если вдруг когда-нибудь там возникает отрицательное значение то мы не успели за Реал тайм и возник э вот это голодание буфера такой запрос помещается у нас как сбойный Хотя человек услышит в реальности синтез и скорее всего поймёт даже о чём Там говорилось э-э нас такое качество не устраивает мы такие запросы помечаем как э значит с Фаины и еще момент про синтез который тоже надо учитывать это кэш запросы на синтез речи в отличие от распознавания прекрасных ошибокса и Кэш надо использовать Ну то есть какие-то штуки типа там Добрый день или даже прогноз погоды который для одного большого города он будет там несколько одинаковыми фразами говорится его спрашивают много-много раз и не нужно каждый раз его синтезировать его гораздо проще отдать соответственно если по этой диаграмме то получается что мы сделали запрос А через 50 миллисекунд нам прилетел полностью весь готовый синтез э-э в нормальном продакшене так должны выглядеть Ну много запросов больше половины Да очень редко бывает что синтез какой-то такой Невероятно Не повторяющийся в колл-центрах повторения как правило на самом деле ещё больше там загруженных в больших я сейчас говорю не только про колл-центры если там работает робот это какая-нибудь самая частая фраза это не знаю Я вас не понимаю за человек орёт Позовите мне живого оператора мы ему отвечаем Я вас не поняла Повторите пожалуйста еще раз вот эта фраза в топе и в неё может быть хитрейт там 90 процентов чтобы это нормально тестировать вам нужно управлять попаданием в кэш вы не можете во время инте как-то надеяться что оно как-то правильно за кэшируется с такой же интенсивностью как на продакшене для этого нужны механизмы чтобы Вы могли вот этот вот целевой хитрейт как-то им прям рулить он собственно У нас тоже где-то внутри есть и используется Но на самом деле это у меня практически все На этом слайде я свел супер супер сухо и максимально обезвожена методикой нагрузочного тестирования как они могли бы выглядеть понятно что цифры сами здесь это примерные они для каждого там софта для каждой ситуации будут подбираться другими просто Как пример а закончить на самом деле мне хочется на потом на том что про то как делать само распознавание синтез пишут кучу статей про всякие Лепс тоже люди пишут этим занимаются про то как делать именно нагрузку почему-то не пишут вообще хотя на самом деле доклад когда задумывался в два раза толще его пришлось прям сильно урезать там есть ещё кучу всего что рассказать кажется в России команд 10 занимаются такими вещами если бы мы как-то научились жарить вот такую специфическую инфу кажется это было бы полезно всем на этом У меня всё спасибо большое Да спасибо вопросы поднимайте руки будем сдавать Ну как раз такие конференции чтобы шарить инфу создавать чатик под это дело так понимаете руки и микрофоны вот у нас в первом ряду три вопроса очень красивые слайды Спасибо да да продолжит говорить просто да сейчас можешь вернуть сейчас девушка поможет включить Вот например что можно задавать вопросы чата кто нас смотрит онлайн Спасибо за доклад у меня такой вопрос На каких данных проводите нагрузочное тестирование это какие-то синтетические данные или вы делаете какой-то слепок с промо и пускаете на самом деле на разных чисто синтетических практически нет смысле мы не Тестируем распознавание на нашем же синтезе как правило это есть центр мы Тестируем примерно на колл-центрах запросах запросы про погоду на каких-то семплых запросов про погоду тогда такой связанный вопрос а если там какие-то персональные или платежные данные я надиктовал салюту номер своей карты и имя свое назвал я не просто спрашиваю работает у нас есть тоже огромное количество людей работающих в безопасности и спрашивающих у нас Это буквально но у меня моя работа она про то чтобы вот на эти вопросы отвечать примерно половина моего времени эта работа с друзьями из безопасности то тестирование которое нам нужно делать на данных в которых хотя бы теоретически может быть какая-то пирсуха или банковские данные проводятся в закрытом контуре Ну просто что-то уровни pcs и мы гоняем вот там же да то есть там может быть персональные данные но соответственно они оттуда никуда не вылезут запросы домена от уровня погода или Включи свет или ещё миллион команд которые наши штуки умеют они могут проводиться на контуре Ну где уже как бы всё почищено там есть специальные люди которые за тем что это за данные следят Спасибо всегда есть вопрос про безопасность так слева вот Давайте теперь первый ряд Так ты запоминаешь лучший вопрос потом будет подарок Да у меня вопрос по поводу собственно тестирования ты говорил что там в конце вы отправляете 6 секунд тишины или сколько там несколько секунд до несколько секунд насколько но и это не абсолютно любая Тишина это какое-то там серый шум который занимает сколько-то байт сетевой сети и эти сколько-то байт нужно будет обрабатывать на сервере насколько это собственно влияет на результаты теста и сразу же у меня второй вопрос практически про то же самое ты говорил что вы отчитываете в какую секунду было отправлен какой Чанг и потом сравнивать Вот это не влияет ли Вот такие расчеты на производительность генератора нагрузки а давайте со второго когда-то влияли потому что не весь код пишется сразу идеальным сейчас мы все эти данные готовим заранее то есть до того как вообще начнется стрельба Вот это даже нарезка почанкам упаковка в правильный протокол все готовится заранее а сама математика происходит после того как закончилась сейчас точно не влияет когда-то влияло и такое было Ну то есть генератор мог не успевать подготавливать да На это правда насчёт влияет Если я правильно понял вопрос влияет ли эндофатора на сами результаты вот это вот задержкой на результаты тестов но мы получается посылаем какое-то количество мусорных данных ну не мусорных почему это частная тишина в реальности так и выглядит Я говорю Салют Закажи мне там гамбургеры колу и я продолжаю слать тишину микрофон работает Просто и в продакшене так всё есть мы эти же данные то есть ну это влияет в том смысле что на это время тратится пока срабатывает индуфатор естественно там жгётся процессор и гпушка Но типа мы так и сделали специально Потому что так на продакшене типа слайд вот перед этим он про то что можно было там без без этого но соответственно тогда это нечестно мы вообще убираем оценку механизма а как оно девайсом отправляется Ну то есть девайс не может быть такое что делается отправляет там я не знаю час вот тишины нет но там сработает Он же шлёт в реальном времени То есть он не пошлёт больше данных чем прошло а он не будет слушать час понятно что его там ну просто потайма вот обрубит мы знаем что нельзя спрашивать про погоду условно там полторы минуты поэтому спасибо сколько максимально может слушать Как клиент захочет на самом деле Ну то есть есть такие клиенты которые хотят нам Подкасты отправлять и вот 40 минут аудио Окей так еще вопрос слева пятый ряд Спасибо за доклад Вопрос такой по кейсам вы как их вообще разделяете Ну например я для себя как понял что есть вот мы отправляем чанки это как один кейс или есть какие-то виды например Какая сегодня погода он также этот Вызов будет отличаться от других Или он тоже будет считаться как Посмотрите да Ну надеюсь Да я понял кажется это вот из вы не тестировщиком работаете значит в реальности У вас есть много файлов Ну прям тысячи может там десятки тысяч и они вас сгруппированы во-первых можно как-то назвать тест Да вот в этой терминологии что грубо говоря запросы из ассистента запросы из колл-центра запросы не знают куда-нибудь ещё про что наверное Нельзя рассказывать и всяких разных мест подготовленные пачки Это одна страна а вторая сторона что вы стреляете в разные модельки Ну то есть у вас сервер может один Но в нём разные модели тоже под разные домены и Ну один тест с точки зрения NT Наверное это типа пострелять запросами в ассистента модель для ассистента вот в таком виде Так давайте вопросы с чата не про производительность просто про алгоритмы Какие алгоритм инструмента используется для генерирования эмоций в речи вот распознавание наверное эмоций думаю что да ну не Ирочки всякое такое Ну в смысле там да это всегда набор моделей чаще всего Больше одной Ну то есть в полноценно вы исаре не знаю там может три десятка может больше может сотня То есть это как это называется так а цикличный Граф вычислений там очень много всего Какие конкретно модели напишите мне на последнем слайде или Найдите меня Андрей Чернов пятого сбербайса и можем рассказать Приходите к нам работать там тоже ребята все рассказывают так хорошо давайте Вот ссылка микрофон есть у кого-то второй третий ряд а да ты запоминай лучший вопрос Здравствуйте спасибо за доклад А у меня такой более технический вопрос А вам уже разные девайсы могут звук слать в разных форматах или у вас сильно проще чем с картинками у нас сильно проще чем с картинками потому что боль про боль с картинками Я знаю как раз от друзей из безопасности Надо уметь искать всякую нехорошую вещь в миллионе видов картинок всех на свете форматов мы поддерживаем довольно много разных чудовищный мир сколько видов бывает MP3 это просто можно застрелиться до сих пор появляется клиенты которые приносит аудио В таком формате Который невозможно переживать три версии 2.5 который писался только каким-то непонятными приемниками Sony выпускавшимися в девяностых вот типа такого А большая часть трафика идет в одном двух форматах на самом деле но какая-то Экзотика есть да мы вынуждены а можно я немножко еще копнула то есть у вас есть какое-то нормализатор формата на входе условно и внутрь там подается все перекладывается в чистый pcm и все модельки работают уже ну с pcm всё что приходит оно привозится спасибо спасибо привет спросить есть ли какой-то аналог профиля нагрузки с промо и учитывайте ли вы его не знаю сезона суточно что-то такое профиль нагрузки есть конечно же он в продакшене выглядит понятная волна у нас там всё очень очень предсказуемая сезонность учитываем в том смысле что как раз мы это делаем чтобы знать что когда например дети спрашивают всякую штуку про то как там решать задачки всякие вопросы и нам было понятно будь всплеск Ну мы вот к этому естественно готовимся мы знаем сколько будет что будет увеличение и делаем закладывание так чтобы прям четко повторять профиль промо Ну нет не очень понятно зачем то есть мы с запасом Просто берем много если мы там условно тысячу переварили Ну значит и 200 переварим"
}