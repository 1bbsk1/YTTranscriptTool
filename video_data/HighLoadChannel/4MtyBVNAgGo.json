{
  "video_id": "4MtyBVNAgGo",
  "channel": "HighLoadChannel",
  "title": "Жизнь без блокировок / Андрей Гончаров (ЦРТ),  Станислав Сидристый (EPAM)",
  "views": 2059,
  "duration": 7078,
  "published": "2020-04-14T11:18:12-07:00",
  "text": "меня зовут станислав сидре стай я из компании epam я гончаров андрей из компании crt да мы сегодня вот коллеги с товарищем хотя работаем разных компаниях и что у нас объединила для встречи это доклад жизнь без блокировок о чем мы сегодня будем говорить значит давайте несколько обязательно слов когда мы говорим о высоконагруженных системах то обычно ну сегодня подразумевается высокая нагрузка в плане когда у нас есть некоторые системы идет большой поток данных да и как обычно делается мы требуем чтобы у нас система была масштабируема на сегодняшний день чаще всего говорят о горизонтально масштабируемости то есть когда у нас есть некоторый кластер до для обработки и соответственно балансировка мы делаем за счет того что мы добавляем в этот кластер и новые узлы вот но есть и другая сторона то есть не только горизонтально масштабирование до есть поймем горизонтальное и вертикальное масштабирование это не когда вы с сервера так на друга складываете понятное дело это когда внутри одной системы вас много ядер да чем больше ягер тем больше вертикально масштабирование ну что все мы понимаем что если у нас одна ядерная система у нас планировщик который пытается стимулировать правильную работу всех потоков до пытают разделив время на кванты и раздельно разделяю эти кванты между потоками соответственно когда мы вносим новые ядра то наступают истинная параллельность и соответственно вертикальное масштабирование вот и возникает вопрос то есть как наш сервис будет ускоряться в случае если мы его перенесем на сервер в котором было если раньше допустим один процессор или несколько процессов но ядерных на систему где будет гораздо больше возможностей вычислительные возможности вот для того чтобы может для того чтобы такой перенос возомнил смысл да и ускорение произошло максимальная нам нужно чтобы код нашего сервиса был максимально раз параллелен для того чтобы его распараллелить нам нужно проводить анализ но что обратное мы можем сказать точно какие точки в коде мы не можем распараллелить такими коль точками является у нас точки синхронизации то есть места где мы выполняем синхронизацию между потоками до соответственно ну мы такой вводную даем до к нашему докладу соответственно что такое точки синхронизации их две большие группы 1 большая группа это сословиями блокировки да то есть это всякие мьютекс и семафоры ивенты вот и прочее блокировки уровня ядра вот но не только потому что что такое блокировка блокировка это когда кто-то один работает авторы все остальные вас ждут то есть например какие-то users блокировщики они тоже будут блокировкам относиться также есть синхронизация на основе не блокирующих алгоритмов ну сегодня о них и поговорим но для начала немножко опишем то от чего мы уходим картинка очень простая вот все принципе ее понимают прекрасно то есть у нас есть какой-то кусок до кусок кода который например защищен критичной секции вот первый потоку то случайно например поток б доходит до границы входит в эту секцию вот два остальных поток они в некотором смысле неудачники они пришли позже и соответственно встают да и ждут пока вы не завершит свою работу он завершил свою работу отпустил а зашел я зашел отработал вышел следующий зашел c + и ну это очень интуитивно понятно тем более вот мы работаем на платформе тут нет у нас есть все sharpie ключевое слово лак вот и на но настолько скажем так большинстве случаев беспроблемно работает что большинство разработчиков кроме него мало что используют вот и отсюда по это получает наибольшее распространение а так хорошо распространено она хорошо исследована и соответственно более менее понятно как тестировать потому что ну мы просто берем синхронный код и там где вам определенное приседание чтобы он стал асинхронным да просто лохом закрыли соответствующие участки все хорошо но есть соответственно минусы может привести к взаимным блокировка классический пример на собеседованиях но вот особенно если недавно них были вот это блокировка ресурсов в прямом порядке в одном потоке вам в обратном порядке в другом потоке если абэ заблокировали а в другом б атос там велика вероятность напороться на dunlop создает корреляцию между потоками да и есть некие предположения о том как будет работать планировщик потоков то есть например классический лук конвой то есть когда у нас есть некий цикл особенно то можно увидеть там не знаю начинающих разработчиков внутри сразу же после во его там или еще чего идет лог почему тогда фигурно открывается такая там куча куча куча кода фигурно закрывается и значит во ушел на начало то есть у нас получается что практически все время кот находится под блокировка и все остальные они как бы во-первых уходят в лоб конвой вот либо на самом деле все чаще идут автор вишен да вот краткий итог да то есть у нас есть алгоритму на основе блокировок и имеете недостатки мы хотим от них уйти потому что если допустим мы превысили количество потоков превысила значительно превысило количество ядер там и вот эти зависимости от планировщика и зависимости между потоками начнем наблюдать соответственно мы хотим до вернусь назад может и бируни мы хотим уменьшить количество критических секций и кроме того уменьшить сами критические секции то есть количество того кода который у нас точно не раз параллель чтобы достигать максимальное ускорение при переходу на железо более мощную да поэтому мы мы хотим отказаться от блокировок вот и второй момент то что я уже сказал это снижение корреляции поэтому есть второй способ работы с синхронизацией это синхронизацией на не блокирующих алгоритмах вот о которых мы как раз и хотим рассказать значит общие вещи выделяют три большие группы не блокирующих алгоритмов здесь одна не указано это abstraction фри или алгоритм без помех она довольно-таки редко возникает потому что и сложное в понимании в реализации и она наименее мтс трогаем вот чаще возникают две группы это lock free алгоритмы и алгоритмы with free то есть первая группа это алгоритм без блокировок они требуют того чтобы хотя бы один поток прогрессировал системе то есть или по-другому можно обратно сказать что если один из потоков вытесняется планировщиком то это никак не должно влиять на работу других потоков и вторая большая группа и так называемый 3 алгоритмом значит фри это когда мы алгоритм без ожиданий когда мы требуем чтобы каждый поток входя в метод завершил его работу за конечное число шагов вот ну и дальше мы можем требовать более строгие то что число шагов до может зависит от количества со исполнительные число шагов не должно зависеть от количества со спины соисполнителей отсюда растут плюсы и минусы до данных алгоритмов но во первых и в главных нет никаких условий для возникновения состоянии взаимной блокировки то есть но даже если сильно захочется получить невозможно нет корреляции между потоками вот но всегда есть минусы и основной минус это особенно если вы в первый раз вижу пытаетесь въехать в эту тему да будет по началу сложно то есть они сложны в понимании берете кого-то алгоритм пытаетесь понять почему ну вот и придётся реально там сидеть там зачастую это может быть там парочку дней до что понять почему вот так вот сделанном вот они сложны в анализа соответственно и реализации то есть если вы впервые опять же делайте если вы не впервые вас уже есть опыт и и стандартные блоки до из которых вы то будете строить вот но если вы в первый раз сделайте ну будет сложновато по первости и соответственно они сложны в тестировании вот потому что если мы берем на блокировка кто там примерно очень похожи на синхронный код надо просто как бы на всякие кейс и попытаться прогнать да вот но здесь истинно параллельность то есть ну надо смоделировать кучу различных ситуаций когда один попадает в начало работы методов конец середину там еще что то сложно вот ну и так как сложен то тогда вот сейчас в первом нашем докладе мы поговорим как это делается и далее мы приведем примеры реализации классически скажем так вот значит как строить алгоритмы такого типа и структуры данных но наиболее простой подход это рассматривать их как некоторые стоит машину машину состоянии вот у которой классический есть входной алфавит набор состояний набор переходов здесь же мы говорим о том что мы ограничиваем состоянии только набором корректных состояний и также ограничиваем соответственно переходы то есть мы должны переходить из одного корректного состояние в другое и может быть только определенным образом вот и теперь немного о принципах то есть тех двух группа алгоритмов принцип на котором не строится которых я говорил ранее толок free значит когда мы делаем log off и алгоритм то мы делаем предположение да оно должно выполняться предположение такое что конфликты привык при работе этого алгоритма из нескольких потоков должны быть и редкими то есть они скорее исключение чем правило но если они возникают у алгоритм со стопроцентной вероятностью определяют их и перри выполняет действие соответственно как это сделать можно до выполняется в 3 шага 4 будет первое мы берем состояние системы копируем его и и для изменения следующим шагом мы изменяем нашу копию и дальше пытаемся а там арно подменить текущее состояние на нашу копию если нам это удалось то хорошо никакого конфликта не было если не удалось там и соответственно возвращаемся к началу и повторяем сюзанну прекрасно какие можно сделать из этого выводы алгоритм на во первых должен иметь вернулся возможность откатить свои изменения да потому что если в этот момент какой-то другой поток начнете это делать он не должен попасть на какое-то разобранное состоянии раза на состоянии носить ну как бы структуры до или алгоритма должно быть постоянно код solid скажем тогда соответственно как по classic это делается мы берем текущее состояние копируемого к себе начинаем менять вот и дальше пытаемся уложить его на место какой-нибудь касс операцией ну вот если не получилось значит кто-то параллельность с нами пытается сделать то же самое если производство частичное изменение объекта то есть как нам кажется да то такое изменение должно представлять собой совокупность независимых шагов но почему потому что но опять же если мы будете по шагам менять например состоянии состоит там из пяти свойств и надо их по очереди поменять да если бы тебе по очереди менять и но при этом какое-либо изменение развалит solid-state объекта до он перестанет быть целостным это значит что опять же та же ситуация второй поток вошел попал на какое-то неправильное состояние развалил там все и вышел один развалился 2 развалился структура данных развалилась соответственно если вы можете разбить изменения состояния на части при этом каждое такое изменение будет приводить к целостному состоянию объекта то это возможно если нет это значит что вам надо будет как-то изворачиваться и делать это единый операции операция там надо вот но и вторая группа этого it free здесь обычно применяются два подхода первый подход это когда для каждого исполнителя копируются копируются копируются состоянии да он его меняет и далее отдает на слияние то есть все исполнители меняют состояние и кто-то отдельно уже фиксируют все изменения за 1 второй вариант это так называемая помощь соисполнитель надо взаимопомощь то есть когда у нас перед тем как что-то начать делать каждое исполнители регистрируют свои действия и пытается выполнить те действия которые были зарегистрированы ранее но еще не были выполнены в этом случае как бы не важно кто из них в конечном итоге пройдет весь цикл но кто-нибудь пройдет да и зафиксирует эти изменения следующая штампует о чем хочется поговорить это атомарные операции но the morn операция the easier space алгоритм до помощью которых мы делаем нечто вот что представляет собой скажем так единый шаг до что гарантирует изменения и что другой поток это все не поломает вдохните для таких операций есть целый класс энтерлак ну вот он в себе содержит инкремент декремент добавление какого-то числа вот и касс операцию комплекте и соответственно давайте поговорим как это все тестировать тестируется это примерно следующим образом представим да что мы поток но мы исполняем код и с нашей точки зрения когда мы работаем с какой-то очереди операция выглядит ну примерно так да мы там положили значение достали и достали там еще какое-то который раньше лежала положили еще какое-то вот если взять какой-то другой поток который работает с тоже со мной очереди с его стороны это выглядит точно так же то есть какие-то операции которые идут друг за другом да ну вот но если посмотреть на ту же самую идею со стороны структуры данных то все выглядит совершенно по-другому то есть все операции выглядит наложены друг на друга и с этим надо как-то жить до то есть получается что даже вот если мы разработали какой-то корректный алгоритм до построили стоит машину и и диаграммы увидели что наш алгоритм корректный то все равно реализация может быть при реализации могли быть внесены ошибки по разным причинам и соответственно мы должны ее протестировать вот мы видим что у нас есть наложение соответственно возникает вопрос что с этим делать как жить наиболее общий подход и он наиболее строгие это так называемая линеаризация историю то есть допустим вот у нас с точки зрения с точки зрения структуры мы видели эти наложения то есть у каждой операции есть начало у каждой операции есть конец и вся операция с весь да вся операция она выполняется какое-то время из разных потоков мы видим что операция накладываются друг на друга и возникает вопрос может ли быть какая то ситуация которую мы на тесте выявляем до валидный для этого мы что делаем мы должны найти в этих операциях так называемой точки линеаризации с точки зрения кода . линеаризация это . где фиксируется результат операции то есть вот после этой точке результат выйдем для всех остальных потоков допустим вот мы рассмотрим на очереди у нас первый поток пишет читает 2 только пишет 3 читает может ли первый поток вычитать двойку в такой ситуации я а третий единичку вот мы ставим точки линеаризации видим что да мы можем найти такую комбинацию их что такой выход мы будем иметь при таком ходе возьмем другую ситуацию то есть мы поменяли местами результаты чтения до его никак это просто такая ситуация нас устроит с учетом того что мы в первую наш лишь туда да у этой мы тоже мы можем найти такую комбинацию когда это будет правильно и соответственно но если мы сделаем вот такую комбинацию увидим на выходе то очевидно что она будет например если мы говорим о бы очереди оно неверно потому что мы или нервировать никак не можем вот соответственно всегда ли нужна стриме создавать теста на основе линеаризации нет если коротко потому что иногда бывает так что структура данных не требуют линеаризации истории то есть мы можем ее например даже не так она не не то что не требует мы можем ее проверить гораздо проще в условиях задачи либо же она даже не требует struct линеаризации либо мы не сможем либо она даже невозможно изменить ну протестировать без изменения самого кода структур но там простой пример и то есть у нас есть какая-то очередь да вот и в целях оптимизации это очереди мы решили пренебречь порядком выхода из нее то есть много потоков в нее пишет да вот но мы пренебрегаем что вот мы должны там с точностью до каких-то процессорных тиков снимать короче порядок да и вот точно в этом порядке они должны выходить то есть мы говорим что но примерно в этом порядке они должны выходить главно там не задерживаться в этом случае очень трудно поставить это точки линеаризации чтобы но проверить этот алгоритм на корректность протестировать его то есть можно только в целом да то есть туда много данных заслать данные прочитать вот и уже потом проверишь но он даст вот в целом все корректно ничего не потерялось вот порядок примерно соблюден значит все хорошо у нас устраивает вот дальше мы приведем классические структуру до к реализации их реализации который в общем обычно демонстрируют ну и мы как бы будем идти от простого к сложному обычно самые простые структуры можно сделать если мы наложим какие-то ограничения на внешние условия вот многопоточной системе достаточно сильным ограничением наверное самым сильным будет если мы говорим что многопоточный сводится к двум потоком и кроме того наложим на это еще ограничение что мы только читаем один поток только читает один только пишет вот да и дальнейшее примеры будет на очередях потому что это достаточно простая структура чтобы продемонстрировать алгоритма вот и соответственно наиболее простая структура в таком случае это будет циклический буфер для одного писателя одного читателя значит он максимально простой у него две операции и здесь в общем достаточно все понятно и здесь же можно увидеть точки линеаризации до в данном случае это строка 8 для пуш и строка 20 для поп операции вот значит то есть тот самый простая и тут даже не очень интересно давайте постепенно снимать ограничение тем самым мы будем видеть как переходим от простого к сложному с ним первое ограничение на количество читателей операция будет выглядеть следующим образом при нравлюсь а то есть здесь мы видим обычный цикл до установки значения через касс вот и первым шагом первыми шагами как и мы уже говорили до мы пытаемся снять состояние которое мы будем менять мы считываем head мы считываем tail вот и дальше если понимаем что у нас буфер пустой то сразу же очень выходим за чем на что-то делать после этого мы попытаемся понять как на каком месте будет хит на следующей позиции мы его не меняем на месте мы соответственно делаем копию после чего поскольку буфер у нас циклический мы проверяем что если мы в конце буфера мы приходим на начало после этого вычет его назначения и и к с операции пытаемся установить новый хит на место если у нас не получилось вот это значит что какой-то другой поток он вместе с нами пытается сделать то же самое если получилось мы соответственно пожили значения в у наша очередь и вышли да и и значит это реализация в лоб free будет на чтение но в данном случае реализация будет иметь ошибку серьезно изъян потому что потому что сейчас расскажу почему значит обрати внимание на операцию касс да то есть мы здесь проверяем изменился ли индекс указывающий на голову дано головной элемент который мы сейчас должны прочитать и если он изменился то мы выходим но мы проверяем именно значение индекса вот допустим самым простую ситуацию что у нас его три потока один пишет 2 читают вот первый поток дошел до операции касс вместе со вторым в параллели и он был вытеснен планировщиком в этот момент да то есть не сделав еще операций касс в этом случае поток 2 проходят операций указ успешно is a и возвращает r11 и совместно с полюс пишущим потоком они могут пройти весь цикл таким образом возвращая результату да и записываем в буфер в конечном итоге может так случиться что на момент возвращение возвращение планировщиком поток от этого потока t2 t1 управления опять-таки яндекс стал снова на тот же значение то есть на единичку в данном случае и в этом в таком варианте мы что получим что если ты один выполнит успешно cos а он выполнит если он первый туда дошел до то он вернет значение результат ну да и вернет r11 при этом мы что мы вернули дважды одну и ту же одно и то же значение из очереди и потеряли значение r 12 то есть это значение которому на второй итерации записали вот это классическая проблема в таких алгоритмах то есть то есть надо следить за этим эта проблема оба ее решают в зависимости от платформы от языка на котором работают парам по-разному то есть например у нас тут нет да как джавита управляемая автоматического управления памяти поэтому мы можем решить его ее очень просто обернув индекс в некоторый класс тогда у нас вход будет содержаться уже не значение индекса которые циклично у нас повторяется а адрес объекта который этот индексу себе инкапсулирует да но тут понятное дело мы видим оператор new вот и у нас все в этом плане я замечательно то есть когда делать оператор new то там срабатывает до 6 алгоритмов выделения памяти часть из которых очень быстрый часть из которых могут вызвать kollection но garbage collection либо обладает стоп зовут либо в общем текущий поток он нагружает ровно так же как и все остальные поэтому он не на данный алгоритм в очереди до он не теряет свой срок free вот но на других платформах другие операторы new и надо следить да то есть вы можете написать прекрасно алгоритм который будет lock free вывод амати стирайте там вы будете с ним учиться вот все будет хорошо но в итоге выяснится что вы за использовали зависимость до которой lock free не обладает то есть ну вы подтянули то что вас будет на тормозить ну вот это первое во вторых может возникнуть мысль давайте задействуем pulling вот но полем здесь не подойдет потому что оператором нее мы получаем рандомизированы какие-то индексы да ну адресов памяти а pulling вы получите тот те же самые индексы катод которых мы только что уходили скажем так простой pulling здесь не падая про тамошних лесах используется двойной pulling да и там все это лучше живет вот давайте снимем по очереди следующее ограничение то есть вот мы перешли к многие многие читают один пишет да с ней мы это ограничение с ним ограничения на количество элементов такое очереди или в таком буфере вот классическая реализация без таких ограничений это реализация на связанных списках то есть у нас в связанном списке есть но до в самой очереди хранится уже не индекса да а указатели именно на но дым и головную и на хвостовую вот что здесь какая проблема появляется у нас здесь когда мы вставляем да у нас есть две переменных которые надо поменять при вставке то есть если при чтении одну то при вставке 2 это соответственно указатель у хвостового элементу на следующий элемент и указатель на сам хвостовой элемент значит как происходит ставка вставка здесь достаточно просто то есть мы подготавливаем новую ноту мы считываем текущее указатель на хвост и пытаемся во-первых изменить указатель на следующий элемент если нам это удалось мы дальше пытаемся сдвинуть указатель на хвост и нам неважно удастся нам это или нет потому что если нам это не удастся то значит у какого-то алгоритма сработает то что внутри цикла while следующие значит допустим что какому-то другому алгоритм удалось это сделать потоков и соответственно мы приходим к тому что наш операция kasten заканчивается не успешно и мы проходим сюда то есть мы пытаемся сдвинуть хвост и перечитав состоянии заново повторяем до того как у нас будет успех прекрасно давайте посмотрим на операцию decker она очень простая вот здесь единственное что происходит это но опять же тот же цикл до попытки передвинуть соответственно head ну вот мы сначала проверяем мне привет так скажу сначала проверяем указатель на следующий элемент да вот и если мы получили нам значит ну как бы ничего доставать мы просто выходим вот и в противном случае мы опять же с помощью коса пытаемся передвинуть hide no heat next вот если у нас все прекрасно получилось not мы выходим из цикла достаем предпоследний строчкой значение и возвращаем если у нас не получилось мы опять же конкурируем с другим потоком крутимся дав цикле ожидая когда же он там отпустит вот и выходим значит здесь есть явная проблема с которой наверное многие так или иначе сталкиваюсь или понять в любом случае понятно это то что мы храним все элементы в связанном списке и каждому элементу в этом связанном списке соответствует узел то есть если у нас размер элементы которые мы храним сопоставим с указателем на следующие элементом и как минимум хранил два раза больше но по информации да и требуется на два раза больше память действительности мы храним еще больше вот и на примере lock free реализации lock free очереди от microsoft мы хотели показать как это как они обошли эту проблему и еще вторая проблема которая у нас здесь возникают при таких реализациях по крайней мере в том коде который был представлен это то что мы никаким образом не регулируем слуги на как не регулируем наше поведение в зависимости от того насколько часто мы видим конфликт а конфликты в данной ситуации приводят тому что мы теряем вот масштабируемости до microsoft они смогли смешать две концепции чтобы выйти за эти рамки и обойти все эти проблемы но не только мы просто такой например увидели соответственно как это строится есть конкурентки класс да вот и внутри этого класса вместо того чтобы хранить это массивы там или 1 связанные списки лежит односвязный список сегментов вот и каждый сегмент уже внутри себя хранит массив уже элементов ну вот когда соответственно мы его наполняем до первый сегмент он заканчивается создаем новый тем самым мы уходим от проблем и оба да вот что мы имеем самконг аринку содержит два указателя это указатель находите ну вот дальше это сегменты внутри каждого сегмента у нас два массива первый массив элементов второй массив состояний после чего идёт ссылка на следующий сегмент и внутри каждого сегмента соответственно у нас есть нижняя граница верхняя граница заполненных ну как бы элементов да потому что если мы складываем то у нас растет верхняя граница если мы делаем деки удаляем то у нас уходит вправо право great нижняя граница ну и соответственно ссылка на юридическую очередь как идет добавление элемента добавление элемент идет достаточно просто мы опять же входим в цикл вот и внутри цикла крутимся да не хочет его трицикла крутимся и пытаемся vtl соперник новый элемент есть у нас все прекрасно получилось мы выходим есть у нас не получилась пара пенить это значит что другой поток что-то тоже пытается делать этот момент мы просто делаем скрин vans спин vans это метод close of spin with что он делает он подсчитывает сколько раз его вызвали подразумевается что он вызывается в цикле он им управляет ну вот и если вызываются он например 1 там десять раз я не помню то он просто ох ну как бы сразу выходит тем самым делают текущий файл просто обычный цикл вот если он понимает что уже задержались текущем цикле он отпускать текущей квант другим потоком ну это and you выглядит снаружи так просто внутри она немножко сложнее но немножко значит сразу рассмотрим первые строчки пока откинем потому что дальше будет понятно что у нас происходит здесь обратить внимание здесь мы не крутимся ни в каких циклах да у нас здесь их нет мы здесь этом арно меняем указатель на после на последние записанные на последние записаны до элемент если мы при этом изменение остались внутри массива давно три сегмента то мы просто записываем наш элемент и записываем подтверждаем состоянии запись ну и дальше выходим со значением труп запись удалось или цикл соответственно которые снаружи он завершится если мы прям клементе то есть так как у нас атомарный то другие потоки смогли increase its инструменте дальше и соответственно когда мы если мы заприметили наш индекс и оказались далеко за пределами нашего массива да по индексу то мы просто выходим со значением фолз интересная ситуация когда мы с инкремент или все оказались точно на последнем яндексе в этом случае мы стандартно записываем и последним шагом мы что делаем мы начинаем увеличивать саму очередь созданию причем сюда может попасть только один поток потому что все остальные после этого шага они вылетают уже на первой строчке но и ровно поэтому а само реализация метода гром она очень просто то есть если вот этого места дошел только один поток нам нет смысла никакой синхронизации мы пропишем обычный кот создали новый сегмент да то есть мы наращиваем да у нас очень кончилось наращиваем создали новый сегмент ну вот mx текущему ставим новый ну вот и соответственно в тэйл указываем что на адрес нового сегмента как работает тройники тройники работает в принципе достаточно тоже просто снаружи снаружи вот есть цикл он работает пока немцы да то есть и 70 то понятное дело ничего вытеснять выходим но и в этом цикле мы считываем head и ухода пытаемся удалить один элемент забрать его до если у нас получилось то возвращаем true весе ну как бы сон не получилось то крутимся как работает is empty что такое и земли в понимании очень все просто если у нас хит не пустой значит немцы возвращаем фолз да если хоть пустой и при этом у нас next на а то есть у нас соответственно пустой следующего сегмента нет возвращаем true но есть еще один сочи этот случай попадается когда мы опять же с каким-то другим потоком ведем конкурентную борьбу до когда у нас хит пустой onext не пустой вот это скорее всего означает что кто-то тоже диоды пью вот сюда вытащил у него на середине мы туда попали вот и мы должны подождать когда состояние стабилизируется ждем мы точно таким же циклом но внутри которого мы ждем стабильность и состояния если и соответственно не видим не наблюдаем не к стабильности дело на спин vans вот как только видим стабильность проверяем если x равный ass anal возвращаем true если после стабилизации выяснилось что у нас очередь не пустая им возвращаем фолз что происходит внутри самого сегмента вот в сегменте то есть при удалении элемента из сегмента операции больше с чем это связано с тем что у нас во первых индексы меняются от омар на во вторых сама запись она не такая простая как как было вот например в 1 в очередях на на 1 связанных списках значит первое мы выясняем учитываем индексы так как яндекс и меняется там ornato они могут далеко уйти за пределы нашего сегмента поэтому мы считываемых как как сказать минимальное значение между длиной сегмента да и текущим значением индекса если мы вошли соответственно этот цикл то есть мы находимся внутри сегмента и там есть еще элементы то мы пытаемся сын приметить наш указатель на голову причем мы делаем это через касс потому что в данном случае надо учитывать что другие что другие потоки тоже пытаются это сделать и мы здесь читаем да и дальше у нас сложные изменения вот если нам это не удалось что мы стандартном прокручиваемся прочитываю значение заново если удалось это первое на что мы наталкиваемся нам нужно подтверждение что запись была выполнена в этот в этот массив по этому индексу потому что у нас запись идет не в один шаг av2 то есть вначале идет инкремент а потом только запись и только третьим шагом мы фиксируем что мы завершили запись если все хорошо мы считываем элементы за этому по этому индексу и в данном случае эта операция нужна для того чтобы показать для того чтобы освободить память чтобы гарбич коллектор смог отработать но горбач коллектор может отработать только в том случае и действительно удалить элементы с вами если не на эту очередь нельзя ни каких операторов иначе мы поломается вот дальше мы что делаем если мы находимся то есть у нас или мы стояли скажем так еще не в конце мы просто выходим если же мы стояли в конце то возникает вопрос есть у нас следующий элемент или нет следующий сегмент если он есть то тоже мы просто решаем если нет то вот такая ситуация может возникнуть только при одном условии что какой-то другой поток также вычитал точнее пишет и сейчас мы находимся в состоянии когда новый сегмент добавляется и мы должны подождать пока он добавится все в качестве заключения мы говорили о том что мы все это делаем для того чтобы лучше масштабируем да и больше кода мы могли раз параллель и соответственно для того чтобы снизить корреляцию вот соответственно отсюда из этих целей следует когда стоит смотреть на такого рода алгоритмы это первое если у нас canson скотт синхронизации значителен и мы предполагаем что здесь возможно можно применить какой-то из вот таких не блокирующих алгоритмов второе если у нас число потоков значительно превышает число ядер например даже может быть ситуация когда у нас одноядерный процессор стоит и больше ничего но мы хотим вот иметь систему прогрессирующую и работают как бы в несколько потоков поэтому тоже сюда можно посмотреть и третий вариант если алгоритм он возникает естественным образом то есть нам даже ничего не нужно думать мы видим что здесь просто на атомарных операциях мы можем уйти от лака и все сделать но прежде чем вот двигаться в эту сторону что нужно что нужно иметь нужно иметь конечно набор нагрузочных тестов да и будет маркин чтобы выявить где же действительности в нашем коде находятся узкое место и кроме того после того как мы вот сделали какой-то рефакторинг сдвинули в сторону не блокирующих алгоритм снова провести измерение увидит данному это эффект или нет вот и второй момент это конечно тест на корректность да и очень хочется добавить что мы сейчас сделали некоторую водную да это описали блокирующий не блокирующие немножко походили по не блокирующим в основном parlux добавок фри и соответственно последовать следующем докладе мы возьмем такую задачу вот о дронах огромных и системе ppv такую но вполне реально но такую его comida вот и на основе нее и попробуем сначала посмотреть что получится от слуг три и потом идем в it free вот и наверно будем усложнять усложняйте получим некий такие достаточно интересные результаты поэтому я еще один момент я хочу заметить мы тут говорим о масштабируемости да но мы не говорим то есть и вот мы говорим о тестах на нагрузку но при этом я хочу отметить что все не блокирующий алгоритмы они не всегда ведут к ускорению в том смысле что вот мы сделали на той же самой системе тестируем если это не ведет к увеличению масштабируемости раз параллелен то мы может быть не получим ускорение то здесь речь не про ускорение скорее а про прогресс все вопросы так кто с микрофоном помогать сейчас полезут судя по микрофону уже эта система пво включена здрав спасибо за доклад интересует такой момент а если какое-то понимание в чем профит по сравнить используем допустим того же семафор схема асинхронного которой не блокирует потоки либо использование блоков на основе редиса либо той же bgp горшке нет мы во-первых тут не говорим о распределенных до вот таких блокировках здесь именно вертикальная масштабируемость то есть то есть конечно мы можем редис примените на обычным сервере да на одном для этого устроить блокировки там предлог какой-нибудь использовать и так далее но мы здесь именно говорим о вертикально может уберусь то есть мы пытаемся распараллелить код какой профит вот еще раз если у нас допустим критические секции которые мы защищаем лаком до или спину там spylog муслим лог slim то там и как бы у нас есть некоторый код который мы гарантированно не будем параллели вот то есть у нас потоки будут вставать и ждать пока один из потоков выполнит если мы не говорим о и комбинированных вот а здесь мы хотим чтобы каждый поток пытался выполнить свою работу да и например в лоб free мы не считаем что конфликтов будет мало то есть почти каждый поток будет успевать соответственно время где они могут столкнуться у нас уменьшается количество кода уменьшается тем самым мы можем код еще больше распараллелить и не переживать что у нас вот такая большая секция в которой например один поток завис потому что его вытеснил планировщик да и могут стоим ждем вот такой вот просит повторите пожалуйста уже краху она синхронна сейчас при всем при этом это будет работа синхронный заберемся то есть у вас что вы на каждый ключ делайте свой симов ургантом поставили это значит что у вас вот эти вот группа потоков она синхронизируется между собой которые захватывают а другая группа потоком синхронизируется на своем ключе то есть это не то же самое мы говорим именно синхронизация когда у нас есть потоки вот они взошли в одну секцию да то есть вот то что вы сказали это как взнос своего рода сегментацией там fine grain да там блокировкой так далее мы не про это говорим мы говорим именно что мы хотим вообще уменьшить понятно но не совсем наша в деле потому что тут асинхронности поток возвращается в пол его никто не блокирует вообще то есть он вернулся на другую работу вас же есть синхронизм не очень но семафор лак семафор slim позволяет делать лак солей там сейчас это продукт продукт на это сейчас смотрите что такое семафор slim особой синхронность то есть имеется ввиду что поток отпустят но это тоже не то же самое мы отпустим поток но все остальные да то есть он что-то будет делать полезное но критическая секция которую мы заблокируем носил но осталось точно такой же дамы поток отпустили но работа то оно не выполнено потом мы снова вернёмся и дернем сюда потом отпустил то есть здесь для с точки зрения самого алгоритма вы ничего не поменяли вы поменяли только с точки зрения пул потоков вы начинаете освобождать потоки с точки зрения алгоритма у вас как с критической секцией осталось так она и осталась спасибо где в слиме здравствуйте же не совсем ну да она замена но она не так выглядит так вопрос я здесь здравствуйте спасибо за доклад у меня вопрос про тестирование не блокирующих алгоритмов вы так вам сказали только про то что мы гоняем наш яблоки ружье и алгоритмы смотрим потом на стерилизует на линии рисуем из каждой истории для каждого потока нет мы смотрим линии взаимность истории самой структуры у потока у потока в общем случае мышечным мы говорим ну и в общем так и есть за исключение перестану со стороны там инструкции так далее она и так линейную то есть но также выполняет как он выполнен операцию выполнять следующие операции у него нет наложения операция для одного потока но то что поток например что то сделал потом прочитал это уже начал что другой да такое может быть но в том смысле что с точки зрения структуры мы же видим как что у нас много потоков дергаются до дергать нашу структуру и в этом случае мы увидим вот это наложение в этом случае когда один поток вот линейно что-то выполняет и вдруг он из очереди выбирает другое значение почему потому что другой тоже положил что-то ну в общем немножко не об этом то есть в целом предлагается тестирования через вот именно ну как коли не резать или нельзя цену именно надо выгонять тесты то есть если какие то есть очень узкие места на которой там на гонки какие то какие то который срабатывает очень редко мы их можем не выявить то его тест пока тест он скорее в данном случае рассчитанную покажет только то что структура работать неправильно а то что она правильно работает она не да ну то есть от как тело вида мы можем только проверка не может доказать есть у вот у в джаве я знаю что в jet бренда используется библиотека который это делает сложнее то есть они там на уровне инструкции меняют и уход и так далее там у них это тестирование гораздо интереснее а вот не смотрели были в сторону там тела и плюс это вот темпоральная логика действие и там лэмпард придумал лет 30 назад нет и он нет как она как раз позволяет вот вы написали кучу блокирующий очередь хотите проверить насколько она корректно работает вы описываете свой алгоритм на языке в логике загонять этом специальное по и она как бы проверяет все возможные состояния ну грубо перебором брутфорсом все возможно состояния вашей там структурой вашего алгоритма и говорит что либо да это всё корректно ли поручика корректно работает либо некорректно то есть посмотрю посмотрите да спасибо добрый день я можно микрофон уже вас не сейчас секунду да я звал добрый день меня зовут петр спасибо большое за доклад у меня вопрос такой просто для личного понимания вот вот эти атомарные операции которые вот интерлок они же по сути точно так же с собой представляет критическую секцию если операция не выполняется нас ждет в чем в чем как бы город клипарт смотри рассмотрите значит профит вот в чем если вот критическая секция да еще раз она длинная мы в ней можем застрять по каким причинам например у нас есть обращение к сети или еще что то то есть это сама операция может длины допустим этого нет тогда у нас может быть еще 3 еще один вариант вытеснение планировщиком это длинная вещь да то есть мы можем попасть и на вытеснение планировщиком атомарная операция она очень короткая и в вероятность конфликта гораздо меньше чем вероятность конфликта на попытки взять блокировку с критической секции длины ну то есть мы просто размер этой критической секцией я так и говорил мы здесь размер критической секции до 1 еще один вопрос вот я честно говоря не сильно в теме но функциональное программирование она же тоже позволяет решать те же задачи не совсем потому что в функциональном программировании прикольно основываться на чем на том что у нас ну как я поселю представляю да я не большой специалист вообще не под специального функционально там значит у нас нет изменяемого состояния верно поэтому в общем например вот если у нас допустим есть какая-то структура как очередь например функциональном программировании то мы не можем то есть но как я себе всегда представлял мы не можем ей воспользоваться в том же смысле как у нас потому что у структур не должно менять состояние функционально программе то есть у нас есть проход да и на выходе мы получаем новую очередь и вот вот такого вот что как у нас до когда у вас здесь есть писатель здесь есть читатель ну не получится потому что у нас нет состоит изменяемого состояния понимаете на этом не меняется но в общем то не были захорони zerowatt спасибо больше сдаст я может пропустил начали что-то ну вот я у вас в ходе видел эти циклы подкрутки когда вы ожидаете изменения состояния но вот тот найти если на спин мог писать код то можно попасть тириан попадаешь особенно как вот сейчас писали что число потоков намного больше чем число ядер впадаешь на контент шина этих самых спину кв когда у тебя все весь процесс а встает в открутку этих спин луков и ты стоишь на сто процентов цепью и потом не понимаешь что вот я системе происходит а а здесь что с этим как можно в начале говорили я пропустил не защиту да ведь это я понимаю что вас не спину ок я понял но у вас цикл тоже крутится и вы тоже в цикле ожидаете освобождение там этого ресурса до тоже дружеский начать так ради создана мы не вначале дамы когда подошли к реализацию microsoft у них прекрасно реализации в dota эти значит вот когда мы вот мы сейчас говорим о лоб free именно там вот этот цикл есть и поэтому это и не выйти ожидания в чем проблема мы предполагаем когда выпишем что мы должны такой алгоритм написать чтобы конфликты минимизировать как это делается это делается например есть стратегия классе классическое это так называемый экспоненциальный быков и вот но у майкрософта как это сделано у них есть класс spin tires spin white да когда мы делаем спину once чем чаще мы вызываем тем больше у него там внутри поворотов до определенного значения когда мы начинаем прокручиваться в нем то есть цикл столько раскрутился что спина нас вызвался что у него внутри он больше крутится чем критическое значение он делает ел для потоков и дает другим потоком сделать работу то есть тем самым мы сильно снижаем вероятность конфликта вот в чем суть то есть мы не получим вот это вот когда они именно к одному ресурс все так можно у вас нет такого не я так понял такой штуки вас именно такого эффекта нет или вы не пробовали до что ладно долго крутить я может быть не очень понимаем вопрос то есть нет я понимаю while там микс из вот все у вас пойдут в эту очередь там целой толпой писать 20000 поток сейчас вот сюда зайдем нет все на одно и то же ожидания не попадут почему потому что у нас вот-вот спин до который спину once он для каждого потока каждый то есть вот один поток например неудачно прошел цикл и вот этот пин ван сон его задержит он не даст ему сразу вернуться и кроме того если он дважды тонного задержано более длительное время тем самым у нас вероятность конфликтов падает или у вас еще остались вопрос вот есть вопрос здесь сама жизнь пожалуй одну секунду человек конечно да лук привык free я сразу скажу что вот тут вопросу какой когда мы говорим во-первых это все зависит от самого алгоритма да насколько он сложен во вторых если он достаточно сложен и мы говорим о каких-то не простых вещах не типа атомарный там счетчик то вот free проигрывает ну вот сразу это видно почему потому что он проигрывает и по памяти там надо помять больше во втором докладе это будет видно как вот память тому лишь а во-вторых он проигрывает по количеству операций которые он совершает единственное в чем он может выиграть ну то есть вот вот скажем так в удачном случае у нас есть если мы будем сравнивать два удачно случае что вот твой 3 делает какие-то операции успешны и lock free то тогда количество операций который делает лоб фреза один раз успешный будет меньше чем не всегда но меньше чаще всего в 3 дольше чем лук фри поэтому и лук ну вот как я видел да и лук фри обычно проще в реализации и не всегда вытри удается ли заводь мы вот следующем докладе покажем как простые в it free и так и мы пойдем цепочку до от простого к сложному и сложной with free и в общем я думаю это будет понятно почему почему я так говорю спасибо за доклад тему вообще животы пищи и вы знаете вот ваш доклад был великолепен ну например на pentium 200 ну понять либо вы описали ситуацию когда несколько потоков работают на одном метре я правильно вас понял потому что смотрите давайте я закончу если нет то получается что каждый поток работать на свою у него нету вот этой памяти про которого горите у него есть кэш у каждого процессора свой кадр получается что вы когда великолепным образом про синхронизировать с помощью коса записали данные вы записали в свой крест вам для после этого нужно сбросить до понял память и понимаете в чем дело вы должны специфицировать какое количество памяти где вы сбрасываете да я понимаю эта проблема она но опять-таки мы считаем что у нас будет меньше конфликтов это как раз проблема о когерентности ки шею к шее вы имеете виду да эта проблема если у нас это происходит очень часто там и масштабируемость и в некотором смысле да мы теряем потому что мы говорим что мы бы то есть вот простой простой пример да у нас есть допустим расчет матриц вот классическая вещь как мы можем считать матрицы особенно если есть ну не будем об этом как мы можем считать матрица мы можем сегментировать да все это дело отдать каждому процессору или игру в процессоре на обсчет и они в параллели считают потом синхронизируется вот но бывают ситуации когда мы так сделать не можем тогда мы смотрим на следующий вот например критическая секция это же гарантированно когерентность решению вопрос мы же хотим просто уйти в минимум этого дела я понимаю о чем вы говорите это вопрос всегда возникает в или не до конца понимаем сейчас хотя бы поговорить собственно говоря о вопрос кто не был на предыдущем докладе почти хорошо тогда но в общем мы уже поговорили немножко зачем вообще лук фри и вы не блокирующие нужны еще раз мы говорили и масштабируемся что мы хотим снизить количество кода который гарантированно не масштабируется второй момент это про прогресс вот есть такая классическая но во первых есть классическая книжка мультик как это искусство мульти процессор на программирования есть работа статья о харли х ешь авито о прогрессе вот и там как раз пытаются ввести ну и я думаю им удалось характеристики алгоритму с точки зрения прогресса и зависимости с системы от как между потоками зависимости до корреляции так и между системой и операционной системы но мы не будем долго останавливаться нас интересует вот frelock free алгоритма еще раз да вот эта диаграмма на бумагу на прошлом тоже было докладе она говорит о строгости алгоритму дак требованию думаю что меняется масса повторяться пройдем плюс инструмент на но раз здесь люди присутствуют те которые были до можно пройти дальше какие задачи сразу к интересно так сразу к интересному какие задачи будем решать давайте попробуем решить задачу однонаправленно ограниченного товарного счетчика то есть но просто счетчик и скучно да давайте мерзкого ограничим как эта задача будет выглядеть до постановка да как мы можем поставить значит у нас если мы возьмем просто атомарный счетчик это неинтересно это реализуется очень просто мы возьмем более сложную задачу нам необходимо реализовать не блокирующий счетчик который работает в определенном диапазоне скажем так от а до б б не включая а меньше чем b и оба числа приближаться вaм числам и что мы от него требуем чтобы он нам выдал все уникальные значения то есть если мы его дергаем он дает уникальное значение из этого диапазона и если мы пройдем полностью диапазон он должен дать нам значит без повторений то есть мощность этого множества будет равна разности дам как мы определим api этого счетчика но класс выглядит по простому то есть у нас есть нижняя граница до которым он передает верхняя граница верхней границы вы включать не должны нижнюю должны вот и одно свойство с компьютера то что он соответственно закончил или нет обсчет нот и метод инкрементом который принимает указатель на целое число ну вот как куда он будет результат складывать и возвращает более узкое значение опять же у него получилось или не получилось почему так такая фишка потому что у нас блок фрида соответственно мы без блокировки это дело мы просто где-то в каком-то цикле или в промежутках между там ни за каким то другими расчетами делаем вызов этих методов вот и забираем результаты какие могут допустимой последовательности но первое допустимо последовательность если мы сначала сделали инкремент он вернул нам успех а из комплекта которые после этого был вызван нам тоже вернул типа все типы все замку завершилась если есть компьютер фолз то есть мы еще не завершили но потом сделали инкремент вот и у нас он вернул true есть из капли ты свернул ползти то есть еще пока не завершились компе инкремент вернул фолз не получилось я все завершил вот из капли that true у нас все завершилось после этого инкремент фолз вот тоже о том же сказал и запрещенная последовательность почему это вводим напомню мыл машины состоянии до перехода из состояния все должно быть solid вот а из completo true инкремент pernod утру то есть сначала все завершилось инкремент получился такой не может быть инкремент фолз сын комментить не получилось из компьютер после этого вызвали вернул фолз тоже такого быть не может и соответственно посмотрим как это все решается так я попробую нет не получается значит лазерный значит что здесь происходит сначала мы вводим 3 поля это внутри поля класса который при для этого состояния первое поле от аккаунта дату и соответственно значение счетчика второе поле это верхняя граница куда мы стремимся но не должны попасть вот и из компьютер ну собственно говоря завершили или нет дальше метод инкремент как он работает входим сразу проверяем мы завершили на самом деле линия то что все завершили делать ничего не надо зачем мы здесь собственно находимся выходим дальше антракт инкремент мы пытаемся нарастить значения счетчика нарастили вот в кайседо и делом -1 почему мы делаем -1 потому что мы это значение вернем вот а если мы например передали ну как нижнюю границу значения а то мы с янг ремень и ебучим а + 1 и а + 1 вернем правильно а должны были вернуть а специфика реализации удается к реализации мы вычитаем и вот нашли зал а если у нас все хорошо если мы еще ниже верхней границы мы сохраняем результат выходим с улыбкой и значением true если у нас не получилось мы говорим что он не получилось потому что мы все завершили вот и поскольку этот метод мог дергаться из разных потоков ну вот и сюда мама шип могли прийти из разных потоков то сын клементе смогли несколько раз вот и выйти за upper bound поэтому мы аккуратненько с этим каунтер vaper bound и выходим сполз вот да значит как здесь тестирование на прошлом докладе мы говорили что наиболее общий способ тестирования таллине ре зация но на наиболее сложный как мне кажется здесь задача такого во-первых реализация очень простая и мы сразу видим что эта реализация в it free да то есть не блокируя что что реализация не блокирующий мы это видим и достаточно естественно получается вот следующие как мы можем проверить и нужно ли нам здесь линеаризации в действительности нам нужно только что проверить что у нас значение уникальное всего даются нет повторений они выдаются скажем так без пропусков и они выдаются в этом диапазоне соответственно мы что сделаем в несколько потоков мы дергаем наш young инкремент у учетчика пока в каждом потоки не получим фолз на инкремент и либо же тру на из комплит и записываем значение которое мы получаем из этого счетчика записываем и дальше просто проверяем что все значения получены уникальные все значения лежат диапазоне и что нет пропуска все проверка правильности последовательности которые могут возникнуть ну соответственно отдельно краевые случае рассматриваем и можем тестировать в общем на негативный вариант это полностью покроет нам тестирование до но мы вам обещали идти от простого к сложному давайте немного усложним задачу многопоточном фильтре простых чисел постановка задачи то есть необходимо реализовать некий не блокирующий фильтр о простых чисел которому на вход подается массив до каких-то чисел пустой заполнены неважно вот и в этом массиве могут присутствовать а могут не присутствовать простые числа алгоритм должен найти эти простые числа и вы дать потребителю в отсортированном порядке как в определим описку оно будет выглядеть следующим образом вот он конструктор он принимает собственно говоря массив вот и в качестве второго параметра принимает количество потоков которым на которых он может работать дальше опять же по аналогии из комплекта property до которая говорит true если все завершено фолз еще пока идет об счет вот дальше результат откуда мы можем забрать и допустимое состоянии то есть мы помним да про машину состоянии допустимое состоянии из компьютер может быть волос после этого результат может быть нам то есть мы еще не завершили результаты дернули после от он вернул на потому что мы еще не завершили все еще is complex and falls но после этого дернули релиза в результате уже есть какие-то значения вот тоже допустимо потому что пока мы шли до резал то от из комплит это наш алгоритм но на втором и дымок все завершить дальше is completely true резал при этом содержит значение все хорошо то что в общем то мы и ожидаем в конце увидеть но есть и состоянии которую не могут быть дано который мы в проще мы должны протестировать наш алгоритм впоследствии это из комплект true нарезал канал то есть завершено на результат на у да то есть какой-то счет or other разобралась сломалась вот значит как мы пойдем сейчас как мы пойдем это учит но как своего рода учебная задача да поэтому мы пойдем самым простым путем по проверке простых чисел это метод перебора делителей реализовать его также просто вот и что мы можно сказать значит это самый простой с другой стороны это наверное один из самых медленных способов проверки простых чисел и отсюда возникает вот желание что весь всю проверку раз параллель как можно раз параллельно есть два варианта и два подхода параллельной обработки массивов эта сегментация и каждый поток выбирает свое значение сегментация когда мы часть делим массив на части и каждый поток работает с этой частью второй подход это когда мы каждым потоку поток в цикле выбирает некоторое значение из массива и обрабатывают его далее мы покажем именно когда у нас каждый поток в цикле выбирает свое знать не отдельно почему потому что в постановке задачи не было не было никакой информации о том какого размера у нас числа придут за исключением того что это там блонд по моему и в каком порядке и как они будут там отсортирован не отсортированные как они будут располагаться в этом массиве к чему это приведет привести может допустим у нас есть два потока которые работают и мы делали им весь массив на два сегмента и в первый сегмент попадают числа например от 1 до 12 грубо говоря а второй там от миллиарда до миллиарда там миллиард может даже мало там дальше до миллиарда 12 до 1 поток у нас от работает очень быстро он эту проверку проведет и все он больше не нужен второй поток будет очень долго проверять каждое число то есть получится что мы в общем то никакой вырос параллели не получили у нас фактически 1 1 по точно приложение поэтому мы пошли путем когда у нас два потока последовательно выбирают свои значения из массива поговорим про реализацию мы вводим два счетчика 1 атомарных ограничено до вот мы перес пользуем то что мы сделали раньше мы использовать два счетчика первый счетчик яндекс поговорим о нем мы имеем массив дам которую из которого мы забираем значения забираться значение 1 из разных потоков соответственно индекс должен быть но потока безопасным то есть чтобы к утру должен быть потока безопасным соответственно индекс это он и есть то есть каждый поток забирает значение in crime течек но для того чтобы понимать что все закончилось что все потоки все обсчитали мы должны понимать соответствует эту точку до на сколько потоков дошло до конца для этого вводится 2 счетчик это аккаунт то есть когда достигает конца обсчет очередного значения the counter in кременец а вот и признаком того что вся вся очередь задача была обшита на это есть аккаунт app достиг своего и своей верхней границы 3 поле the reasons это поле в котором будут храниться значение как собственно говоря и результаты так и промежуточные результаты ну вот над которым ведется работа конструкторов и 7 еще интересная представляет инициализируем вот единственное в конце конструктор у нас есть цикл по которому мы запускаем задачки на старт обсчета вот и соответственно конечно задача равно количество разрешенных поток в котором мы передали из completo свойства просто возвращает из компьютер аккаунты рада то есть если каунтер достиг конца значит все хорошо все потоки закончили все свои отчеты резалт возвращает результат но ты тут возможны два кейса если расчет еще не закончены не завершены он вернет нам вот если расчеты завершены то он возьмет врезался в фильтр отфильтрует там не 0 и почему потому что когда алгоритм пытается найти простые числа там где он находит непростой числом просто обновляет это делается для того чтобы не создавать каких-то дополнительных массивов еще дополнительного не овации ровать просто на месте сортируем и возвращаем соответственно массив ну и соответственно больше часть алгоритмы уже рассказали как работает сам нет wog до для каждого потока мы просто проверяем что у нас есть еще что считать то есть обсчет не закончен пытаемся получить новый элемент до для этого мы пытаемся сдвинуть яндекс и получить индекс от текущей который мы будем только наш поток обсчитывать если нам это удалось мы делаем проверку на простоту если проверка прошла успешно то мы просто проходим дальше если не успешно за 0-ем и в любом случае маркируем что мы отдельное число отдельный элемент массива обсчитали значит здесь вот немножко может быть вот эту вызвать вопрос если у нас инкремент мы делаем и мы вышли то есть он мы закончили мы не смогли с инкремент потому что им мы уже находились на правой границы и мы за неё вышли и здесь важен случай когда когда мы вот именно вот вот этот шаг делают именно наш поток в этом случае очень важно чтобы он сын кремень тела и маркирующий счетчик потому что по реализации у нас маркирующий счетчик здесь будет стоять немножко ну как валидным еще состоянии если мы его не sing ремень team если мы его продвинем он станет не валютное состоянии все будет хорошо если мы этого не сделаем и например будем тестировать на 1 поточном режиме то мы увидим что у нас однопоточный режим будет говорить что у нас еще обсчет не закончится и не закончен не закончится никогда если мы несколько потоков то мы получим out of range исключение тестирование как это все протестировать но во первых представлена реализации является в этой реализации вот и как протестировать очень прост мы просто продаю подаем на вход массива с различными чувствами там может пустой там полный огромный вот большие сначала в конце в середине и так далее вот и получаем на выходе массив простых чисел и сравним с эталоном то здесь не все такого сверхсложного нет да я отмечу момент такой почему мы говорим что он видит фрина потому что мы то есть структура или алгоритм будет вытрет только в том случае если у него все внутри тоже выйти то есть например если мы говорим про структуру то мы говорим о том что она в три если все методы with free если есть и мы должны говорить именно она имением строго методе если где-то есть с блокировками то мы должны указать что вот этот метод будет с блокировками этот мед lock free этот метод free вот мы реализации я здесь использовали только в три операции поэтому эта структура сама тоже то есть алгоритм и фильтр он тоже with free но это самые простые были задачки так для разогрева теперь пойдем от простого к сложному теперь поговорим о дронах ну надо какую-то практическую задачу до всех физических конях лаками можно говорить сколько угодно но тут вот на тоже сферическое дрона то у нас нет вот соответственно мы подумали вот в мире сейчас дроны производится в огромных масштабах уже миллионы штук ну вот каждая хочет поднять там посмотреть природу нота среди природа могут оказаться объекты могут может быть даже военного назначения ну вот или какие-то предприятие которое не очень хотят чтобы за ними смотрели вот ну какой там заводик не хотят вот они хотят защититься от нежелательных так сказать глаз соответственно есть такая задача мы летим на троне вот и не хотим его потерять поэтому он у нас облепим куче датчиков вот мы подлетаем и хотим соответственно понимать что нас начинают наводить какое-то излучение нас поймали да и чтобы как-то на это не буди разрушенными во время оттуда уде значит допустим такой то есть во первых если кто-то занимается такими стенам прошу громко не смеяться допустим система работает в трех режимах пассивный режим когда система просто от не отслеживает объекты она их просто скажем так регистрирует да то есть у нас излучатель какой то стоит он излучает просто в пространство и по отражению мы видим что некоторые объекты находятся в этом пространстве вот но если объект регистрируется что он прошел некоторые некоторые границу да ты подошел к охраняемому объекту на расстоянии меньшим некоторой критической система переходит во второй режим это режим подсветки для определения объекта которые мы наблюдали в пассивном режиме там можно реализует что это может быть определение геометрия объекта из отсюда что это за объект но главное что определяет еще скорость и направление движения до если объект представляет собой какой-то естественно пример стая птиц или камни на шарике то система не тратят свои силы на дальнейшее сопровождение если же оно определяет что объект например дрон или еще что-то она переходит в 3 боевой режим подсветки например лазером или еще более интенсивным излучением для там не знаю подавление сигнала дрону чтобы его опустить или например мне на взбить до для подсветки ракет вот значит описание задач от особенно следующим образом то есть нас есть некое изделия физическое как бы вот может она сферического коня в идеале физическое вот катал которого множества датчиков но вот эти датчики во-первых мы могут снимать различные там частоты дома во вторых по всем законам авиации они еще там продукт продублированы там не знают четыре раза чтобы если там один вышел из строя то все остальные соответственно ничего не потеряли и но со стороны системы внутренней до который делает об счету всякий для нас все датчики выглядят совершенно одинакого не для нас регистрирует некоторые сигнал и будем считать что когда дрон например находится в области пассивного наблюдения то эти датчики регистрируют в нашей системе сигнал от единицы до 100 если дрон попал уже под определяющую излучение то это допустим от 100 до 500 и если у нас уже дрон подсвечивается для дальнейших агрессивных действий это просто значением выше 500 а вот почему диапазон потому что ну понятно и излучения чем ближе тем она у нас интенсивнее будет дальше датчики получается для нас как вот весь набор каких-то датчиков да вот и есть некий in point куда они пишут свои значения пишет они значения но парой значению интенсивность излучения в конце целого числе которые андрей говорил и номер датчика в системе до дальше есть вторая система которая вычитывает максимум то есть пишет много данной среди них есть какое-то максимальное значение есть соответственно такая система она раз в какое-то время с таким интервалом заходит в этот темп аид и запрашивать у него максимальное значение которое там было зарегистрировано то есть скажем так этом мозги на которые нам должны как-то реагировать на то как где дрон находится в смысле излучения соответственно есть там излучения сильно то он должен бандой культа команду полный осознал да ну формализации да мы должны реализовать вот сим симулировать вот эту вот систему значит формализуем с точки зрения структуры мы будем именно реализовывать вот этот point да и вот требования именно к нему значит у нас есть набор писателей конкурентно производящих запись мы ничего не знаем про интервал между двумя смежными записями да и записями между интервал между разными датчиками записи есть единственный а читатель и это читатель читает с некоторым интервалом и мы хотим чтобы он вычитал не все значения которые туда были записано просто максимально почему потому что если у нас то есть что мы делаем мы по-настоящему делом дискретизацию сигнал до который мы снимаем с датчиков и мы хотим именно видеть максимуму то есть нас другие сигналы которые были записаны нас в общем не интересует нам нужен максимуму за вот это окно вот необходимо рисовать да то есть вот ну в общем тут все понятно что мы хотим реализовать хорошо давайте посмотрим как это все устроено давайте определим класс записи даты средине за записей то есть то что выдает на у нас датчик вот директор содержится значение и собственность зато детектора иди то есть кто это дело нам отдал сама регистрирующий система то есть and point до который в середине такой квадратик был ну вот содержит все два метода первый ответ это метод реджистер которая позволяет датчику зарегистрировать свое значение вот и второй метод это метод get max red hat который позволяет сервису забрать максимум который был зарегистрирован с момента предыдущего вызова этого же метода как реализуем на основе блокировок ну на основе блокировок все выглядит максимально просто вот то есть у нас для того же не работать с на ламе мы создаем дефолтную запись 00 вот создам объект блокировки дальше метод реджистер под лаком мы соответственно проверяем если вот переданное значение у нас не максимуму максим обновляем вот а если у нас запросил сервиса значения но мы эту контентом является являемся да и сервис на запросил значения мы просто мы уберем его под этой же блокировкой отдаем при этом обновляем на макс рекорд на 0 зачем это делаем потому что если мы не обновим то у нас это значение залип не да то есть она может так ура только расти забрали значения сбросили на ноль и начали заново счет искать свой максимум преимущество все очень просто все ну прям вот как это можно написал за сказал это будут делать месяц за вечер написал в продакшн вот но недостатки что сделан на основе блокировок поэтому если датчиков много если они пишу достаточно часто то мы получаем лоб конвой получаем может быть даже старейшин получаем кучу проблем и в итоге заказчик отправляется свой любимый дрон вот он падает он думаешь он сломан отправляя следующий потеряется и так далее приходит к нам что мы можем предложить мы можем продолжить новое реализацию да значит в лоб фрида то есть у нас здесь уже нет защиты критических секций поэтому первое что мы делаем мы получаем помечаем это тут нет овская часть поэтому не интересно в смысле вылетал то здесь мы избавляемся от оптимизации компиляторы каширования для этого поля а дальше мы делаем классический цикл как во всех локаций алгоритмах то есть у нас есть треки быков а дальше мы начинаем мы создали нашу запись считали текущее состояние пытаемся его изменить пытаемся во-первых проверяем наша запись больше либо меньше очевидно что если меньше то нам это не интересно если больше то мы пытаемся ее заменить если у нас удалось мы опять-таки выходим если нет перечитываем снова состояния и повторяем до победного как происходит взять и максимальное значение тут в общем ничего сложного не происходит опять же у нас есть цикл вот в цикле мы забираем текущем максимум и пытаемся сбросите максимум на ноль то есть мы создаем значение 0 до пытаемся сбросит на 0 вот есть у нас получилось значит все прекрасно мы возвращаем это максимальное значение если не получилось это значит что какой-то другой поток с нами конкурирует вот и мы прокручиваемся с помощью спин вонсо в ожидании на получение контроля над значение максимуму и как только мы получаем соответственно его возвращаем какие проблемы асана проблема является то что лук фри алгоритму не является старейшим free алгоритмами вот то есть может возникнуть легко ситуация когда у какого-то потока читающего пишущего может возникнуть ну прокрутка на какой-либо операции компрессия в этом случае нас возможно два варианта первом случае это когда у нас таким потоком оказался поток чтения вот для нас это является абсолютно неправильная ситуация потому что мы с раба тамбова кому-то таймеру вот и мы не можем залипать то есть это для нас может быть очень даже печально ну да то есть залипнем потому что если он залив допустим и не указывают нам что мы уже прошли критическую зону то в общем мы думаем что мы еще летим все нормально у нас уже в общем у нас даже в общем то нет да да нет тогда мы точно чего-нибудь да вот а второй вариант это когда один из таких потоков вот поток на запись вот текущей реализации это может привести к очень серьезным последствиям интересно очень интересно что у нас просто пройдемся допустим у нас датчики расположены и таким образом идентификатором присвоен таким образом что чем ближе они по идентификаторам тем ближе не геометрически вот пускай у нас 1 датчик снял вообще максимальное значение которое мы готовы были регистрировать 2 снял 08 от этого значение а система реагирует на на случай если у нас превышение будет 06 от критического от максимального и в цикле мы что делаем при первом проходе мы успешно записывает 08 второй датчик 1 датчик не успешно безуспешно пытается записать свое значение которое явно больше на вот дальше что происходит на следующем цикле он снова пытается записать но в это время сам сама система считывания да она производит сброс и он опять уходит в цикле на повтор потом допустим 04 удачно записала со второго датчика наши 5 1 неудачник и в конце концов через сколько итераций может быть даже через сколько-то итерации и считывания да вдруг нашим удочку повезло его наконец-то записал дрона сушу же ушел до сделано пример маневр ушел из зоны опасности и вдруг ему приходит что со стороны там допустим с какой-то опять такое же излучение он опять должен вынужден делать маневр так далее вот но не хотелось бы вот таких ситуаций вот для того чтобы уйти вот у всех этих star высшим и как-то ну вообще поменять все это делаю что мы начали преимущество недостатки у нас эта реализация опять таки достаточно простая особенно если вы много имели дело ну или даже немного но имеет дело с lock free она без маркировок то есть казалось бы мы ушли от всех проблем которые у нас были на блокировках но описанные описанной выше ситуации просто отбивает всю охоту работа с такой реализации поэтому мы что сделаем мы двинемся в сторону вот free первым шагом мы сделаем вот что мы во-первых скажем что мы хотим гарантированно быстро за за определи ну как сказать за гарантированное время вычитывать значение максимально с другой стороны мы хотим у нас при этом возникает ряд проблем там будет видно которые приведут тому что даже лоб free запись придётся модифицировать эмэдям предположение то есть поскольку мы работаем с кем-то всегда вам сигнал ну примерно постоянно не можно скакать наш дрон тоже не может перемещаться как телепортироваться в пространстве вот поэтому те сигнал который мы считаем с датчиков они ну имеет такой достаточно ровный вид да вот без каких-либо скачков поэтому мы можем сделать допущение что мы в принципе можем какое значение потерять так то есть возникает вопрос а можем ли мы потерять значение из тех которые мы пытаемся записать из вообще задача дается физических свойств мы говорим что дар предостаточно предостаточно частоте дискретизации мы можем потерять развлечение потому что мы не увидим сильных скажем так скачков нас функция непрерывна и достаточно гладко соответственно что мы для что мы вводим для того чтобы это всё сделать мы дополнительно вводим понятие поколение вот наши записи сохраняем записи и храним его дополнительно в месте inpointer дальше посмотрим как в таком случае будет доставаться макс рекорд на 30 boost достать следующим образом мы берем значение максимума вот и в этом месте инкрементируем значение поколения то есть поколения это когда наш сервис опрашивает назначение максимума наш in point как только опросил значение поколение выросло после этого уже поколения новое и соответственно возвращает эта запись потребителю то есть фактически что мы можем сказать что поколение это в некотором смысле номера канада когда за которая накапливает значение вот мы видим что реализация на ну точно в туре если у нас инкремент не какой-нибудь специфичный вот но возникает вопрос здесь мы что не делаем здесь мы не сбрасывали наш максимум и вот та ситуация залипанием она возникает ну как бы говорится возникает вопрос что с этим делать тогда мы меняем и вот поколение нам позволяют изменить в правильно и лаков ререйза эту запись и что мы делаем в лоб free теперь мы считываем текущее состояние создаем новое с учетом текущего поколения которое у нас сейчас в котором у нас сейчас находится наша and point дальше мы считываем еще раз поколение текущая и начинаем крутится в цикле но в цикле мы теперь крутимся до тех пор условно то есть пока вот повалил да пока у нас например не изменится текущее поколение то есть если у нас мы записывали в предыдущем поколении да ок но уже как бы началось то мы сбрасываем это стоит нам она больше не интересно она устарела а так как мы потери допускаем то ничего страшного дальше что мы делаем мы проверяем что максимум того же поколении что и новое значение что максимум у нас должен быть допустим если он больше то тогда мы сразу выходим если нет мы пытаемся поменять если нам это не удалось там и классически проходим цикл снова считываем теперь уже не только максимум но и поколение чтобы wild работал до правильно вот такой момент теперь по поводу того что мы не сбрасываем максимум обрати внимание что если мы допустим начали нашу операцию записи скажем так в тот же момент когда была считывание там и и или даже позже да но мы первые кто пытаемся записать после считывания то мы считываем у наше поколение будет отличаться от поколения максимума и вот этот условия вы фиана вам позволяет сразу сказать о кей сбрасываем то есть максимум устарел поэтому мы первые мы его перезапишем ну и дальше идем какие преимущества преимущества первое чтение максимально чтение максимального значения стала вий 3d то есть мы добились какого-то гарантированно времени до дальше мы избавились от возможности записи устаревшего значения но появились недостатки возможность потери некоторые значения с датчиков к нам пришел наш клиент и говорит например ребята вот мы хотим вот там полетать вот но мы не уверенны что мы можем подлететь на достаточно близкое расстояние вот но нас смогут погасить и соответственно забрать наш аппарат вот а полетать надо речку следовать мы не хотим терять значение вообще да то есть разделом вот так вот здесь даже такой подход мы даже готовы потерять дрон но мы хотим узнать как работает эта система на каких значениях какой режим она переключиться поэтому мы готовы потерять дрон с ним всего сигнал с него сигнал но не готовы пропустить значение да то есть для нас это становится критично и поэтому мы можем что прилежит мы можем предложить в эту реализацию соответственно какие соответствие какие мы вводим ограничения заранее известное количество потоков то есть мы выделяем по потоку на датчик вот и грифе катары датчиков мы нумеруем их от нуля без пропусков и до значения n то есть мы просто по порядку номеру и мы все потому что программисты всегда с нами начинают да дальше вот дальше вот исходя из прошлого доклады вообще да то есть из опыта мы можем что сказать чтобы не потерять значение мы можем использовать связанный список для ну то есть связанный список понятную узлы из чего состоят от неинтересно второй момент для того чтобы не потерять значение для того чтобы реализовать white free мы вводим такую штуку как массив команд этот в этом этот массив у него индекса совпадают соответственно с индексом датчика с иди и датчика и так как у нас к датчику привязана один поток и это гарантированно не меняется то есть поток всегда только один по датчику привязан то соответственно этот массив он в каком-то смысле так как с ним работать только один датчик уже изначально каждый элемент оба потока безопасны и здесь опять-таки у нас остается остается счетчик поколение и надо сказать про индексе яндекса да здесь чтобы понять что значит c02 там и так далее первый индекс это обозначает индекс в массиве спасибо второй индекс это индекс поколения дальше мы еще цветом подсветим зеленый у нас это будет необработанная команда серенькая уже обработки asset как это все будет работать нас идет команда реджистер да мы регистрируем новое значение значение в то есть там не знаю сто-двести 500 и передаем наш номер то есть нашего датчика на 1 2 вот что при этом происходит наса массив этих команд вот мы туда регистру новую команду но мы можем это делать совершенно не синхронизируется не там ничего не делал потому что мы пишем на свое место то есть мы ни в какой то случайно дамы вот наш номер 2 мы пишем по второму индексу и дальше мы вызываем там нет help мы его потом про него расскажу этот метод он соответственно чем занимается месте у нас есть много потоков кто-то читает и пишет ну вот и пример бы выйти с ним поток который эти команды начал обрабатывать то мы доделаем за него работу вот мы друг другу помогаем как это все выглядит в классах класс ноты до то есть одна односвязный список содержит в себе соответственно значение до которого получили от датчика вот айдишник который от какого датчика это все пришло ссылку на следующую ноту вот и таймс темп который по факту является номером поколения ну просто удачно до отдан вот так называет до поскольку номер поколение растет с временем то удобно назваться таймс темпом неким дальше и далее у нас есть команда у команды есть состояние про состояние что скажет что здесь интересно команд мы можем получить состоянии из команд до но заменить мы его можем двумя способами мы можем заменить либо атомарная записью не беспокоюсь там будет понятно почему либо же через операцию касс чтобы знать точно что это мы меняем да и никто не подменил значение параллельно с нами come on state она состоит и резких полей первое это но да вот с которой он работает дальше состоянии пнд то это означает что вот он находится в состоянии камеру бы его еще не обработали да и очень обработали вот дальше инициализация и проверка на то что он еще не был обработан с передачей tines темпа почему потому что он будет проверять что он не обработан до определенной границы времени то есть и до определенного поколения то есть когда мы проверяем да мы вот должны проверить до определенных поколение вот он это и делает да еще секунду обратите внимание если если команда у нас может менять свое состояние да то есть это у нас изменяемый объект то вот common стоит а он уже с мое состояние не меняет вот такие ну и теперь еще что теперь внутри структуру добавилось да у нас в отличие от предыдущего у нас появился массив команд у нас появился указатель на хет до указатель на конец в общем очень похоже на то как в очереди фактически и значение для следующего поколения то есть вот как раз наш счетчик и из него будут ну как выбраться значения для наших узлов но и некоторых константами как происходит инициализация мы создаем ноду добавляя туда некий дефолтную запись вот и специализирован хотел опять же чтобы не работать снова my то есть чтобы все у нас было дальше быстрее вот после этого мы инициализируем массив команд массив команд - или zero по количество потоков которым нам с которым нам разрешили работать вот ну все мы помним да каждый датчик пишется в свой в свою ячейку то есть мы должны изначально подготовить этот массив вот и опять же чтобы там не было никаких на вов и пустот мы туда добавляем команд стоит с назначением фолса который означает что эта команда уже был обработан и далее как происходит регистрация нового значения то есть датчик вот он получил значение хочет нам его отдать им комментируем счетчик таймс темпа то есть мы пошли вперед дальше мы создаем запись вот лицензируемого данными и эту для этой записи в массив команд мы создаем соответственно come on state инициализируем но дай все это короче инициализируем говорим что-то еще не обработана значение true в конце вот и с этим просто с этим без всяких там синхронизаций потому что наш поток может светить только вот в конкретное место другие туда никто не знает не будет лезть после этого мы вызываем некий метод hell по которым расскажет андрей значит очень простой метод снаружи но теперь посмотрим что внутри внутри поинтересней первое что то есть вот мы здесь цикле проходим по командам и что мы видим внутри каждой команды мы проверяем с учетом таймс темпа и ее состояние является ли она зафиксирована или нет если ее еще никто не финишировал мы заходим внутрь вычитываем текущее значение скажу так в очереди до ее следующее значение далее делаем проверку за то время пока мы это считывали кто-нибудь сдвинул хвост или нет если сдвинул тогда мы повторяем цикл заново если нет тогда мы проверяем это был действительно хвост то есть он указывал на какой-то следующий элемент если нет то мы переходим на финиш дальше будет понятно что это такое если если да если указывал на какой-то следующий элемент то есть отель был ненастоящих что мы переходим на финиш сразу если же нет мы заходим в оператор их до проходим что внутри у нас первое что мы опять-таки проверяем может быть кто-то завершил уже за нас эту операцию или нет если кто-то завершил потому что сделаем мы сделаем кантину сразу выйдем wild на условий вайл выскочим если же нет значит значит эту операцию значит хвост никто не сдвинул и указатель на следующий момент и мы пытаемся раздвинуть как в лоб free очереди если у нас это получилось не получилось мы снова проматываем ся если получилось идем финиш финиш еще проще мы считываем текущее положение значит и что проверяем что текущее положение в строй момента как мы вызвали финиш начали вызывать не изменилось то есть значит что мы здесь видим что мы в любом случае попадем сюда финиш только если у нас last перестал быть нам до соответственно проверяем next нал или нет если он не нал если он all the мы выходим если не нас значит все нормально продолжаем работу из узла мы берем идентификатор тяжело идентификатор по нему мы определяем текущее состояние команды достаем команду текущее состояние снова проверяем изменилось ли состояние или нет если она не изменилась если оно изменилось то выходим сразу если но не изменилось мы создаем новое состояние для команды и обратить внимание отличия только в одном мы показываем мы выставляем флаг что мы ее финишировали и дальше двумя операция микас мы первые пытаемся про финишировать команду и здесь важно что заметь нам неважно чем это закончится почему потому что если не мы ее про финишировали то кто-то другой никак иначе и пытаемся сдвинуть хвост и опять-таки не важно если не мы то кто то другой маленький момент почему казалось бы там есть цикл а мы говорим что это во ii туре потому что цикл никогда не будет крутиться бесконечно если не мы зафиксировали и у нас где-то случился вот contain да то есть состояние кто-то другой изменил то с учетом поколений с учетом как цик как идет цикл да он идет он идет последовательно по всем командам мы гарантированно когда нибудь выйдем и это зависит когда на сколько шагов он сделан от того сколько соисполнителей то есть длину массива от длины массива пам пам пам пам пам пам пам пам паузу небольшие вот как маг считается хорошо ада теперь посоле как происходит выборка максимального значения выборка максимальное значение она идет проще реально проще вот никаких скрытых вызовов тут не думают только не будем заходить так вот сначала мы инкрементом счетчик катаем с темпа заходим в help который в политике раньше вот тем самым мы фактически пытаемся закончить работу которая не закончил тот поток который был вытеснен книжечку планировщиком до инициализируем макс каким-то минимальным числом например 0 вот как заставляем на хиты все пошли под на связному списку идти остановимся мы либо на конце списка либо если у нас мы упремся в некий time spent вот который уже был создан после того как был создан таинственных вначале метод то есть если кто-то уже успел включится ищут там добавить вот этих мы не будем обрабатывать после этого если мы среди эти значения на связано списка находим какой-то более максимальным его запомни запоминаем вот передвигаемся следующую ноту и обновляем ход все все что здесь происходит к ней преимущества и недостатки но преимущество это полный with free вот работает без блокировок все хорошо нет потерь никаких значений вот но недостатком является то что мы усложнили работу выборки максимального значения теперь его сложность этого а это когда все протестировать значит вот здесь вот уже не уйти от линеаризации потому что у нас есть запись до из разных потоков есть чтения и мы кроме того говорим что есть некоторые окна в которых мы выполняем запись и мы хотим максимально значение выбирать из этих окон ну плюс минус вот плюс минус потому что в общем из вики что мы делаем значит в общем случае наш вот ттн это т т м плюс один скажем то наша система с точки зрения токов выглядеть вот таким образом пример то есть есть n потоков пишущий только пишущих один поток только читающие есть пересекающиеся операции значит что мы как мы можем тестировать мы создаем некоторую точку которая хранит что то есть операция на продолжительного времени есть начало и есть конец чтобы делом мы создаем некоторую точку в которых записываем начала записи или начала операции вот так конец операции тип операции либо либо деки и значение которое мы записывали или считывали дальше что мы делаем вот грубо говоря когда мы в несколько потоков делаем запись в один поток мы читаем то мы все значения которые считывали создаем вот эти поинты и складываем их какую-нибудь структуру очевидно она тоже должна быть конкурентной после чего после завершения прогона мы все это все накопленные значение в сортируем по по точке старта с точки то есть вот мы отсортировали получили вот тот скажем так массив до который у нас снизу и начинаем анализировать с этой точки зрения вот эту структуру до что можно сразу сказать лоб бы здесь очевидно понятно как работает у нас здесь точно нет никаких пересечений никаких совпадений запись после нее чтение все что лежало слева от записи это окно что все что справа это следующее окно и так далее мы между даже записями нет никаких пересечений это даже не интерес смотреть не блокирующий алгоритмы тут у нас возникает ситуация когда запись и чтение могут пересекаться значит вот первая ситуация когда запись и чтение начала окна до скажем так пересеклись данная ситуация тоже не интересно потому что мы в нашу коллекцию отсортировали по паспорту поэтому мы видим эту запись в нашем окне и увидим что в ситуацию что мы сняли именно ее до максимально значения темно-синие и ее прочитали вторая ситуация похоже что у нас максимум в самом окне тут тоже не интересно третья ситуация у нас уже пересекается с тем чтением где мы прочитаем но с учетом сортировки это тоже нас не волнует эта корректная ситуациям и и сразу выявим первым же проходом интереснее вот такая ситуация когда мы считали значение да и как раз встали вот на тот место где нам нужно искать точки линеаризации и что мы здесь можем сказать это значит что когда мы в структуре обнаружили что у нас справа слева чтение прочитал значение которого не было левее вода то мы смотрим все записи которые начались после чтения но точка старта находится до конца чтения если среди таких операций запись был наше значение искомой которую мы считали значит пока еще все хорошо но при такой ситуации мы должны просмотреть все окно и следующую запись почему потому что если мы вдруг считали этом если за все окно это было максимально значение и в конце мы снова считали его же ответственно мы имеем явную ошибку если мы считали другое значение то пока мы тоже считаем что все работает верно то есть вот такие тесты они выявляют только некорректности поэтому придётся запускать но много раз желательно там с разным числом потоков и 3 далее и гнать все вопросы а подождите пожалуйста вас просто на записи слышно не будет а люди очень расстраиваются когда не слышно вопрос вот скажите пожалуйста а инкремент поколения происходит только в момент чтения для войти да я просто не успел честно говоря я до знать нет в обоих каждая каждая операция увеличивают поколение просто не может у нас получится такая ситуация что у нас чтение будет неудачником и когда пока нуждам help уже все поколения увеличилось во всех а это нам не важно потому что потому что что мы делаем что мы делаем в прочтении если вы обратите внимание если вы не против я не буду что мы делаем мы увеличим поколение считываю пытаемся помочь остальным зафиксироваться а дальше нет никаких операций касс мы берем голову и начинаем бежать до и когда мы заканчиваем мы либо дошли до конца то есть все никто больше не успел записать ничего все ok либо же мы дошли до той точки где наше окно да вот вот то что мы сменили поколением и тем самым срезали окно до завершили его и мы говорим что все что правее этого окна во льве и все что левее этого таймс темпа это наше все что правее это не наша причем можно ну как бы почему это сработать потому что хоть мы тоже движим и то есть мы всегда находимся мы всегда движемся вот этим окном то есть она получается как бы от там этого текущего значения до бесконечности то есть если будет поколения выше то он вовсе она считает нет она вот-вот wild же есть проверка чтобы поколение должно быть меньше чем наши еще раз говорю мы считаем только то что попало в окно как только мы доходим до узла у которого поколения выше мы останавливаемся все окей вот обратите внимание на второе условие вот первая это проверка на нал next а второе это уникс то timestream если таймс тем больше нашего мы заканчиваем цикл но он был взят сам начале методом да вот мы его вверху сын клементе ли все от омар но да отомстит мы нас интересует только те узлы которые записаны нашем окне если таймс темп у него дальше все цикл закончится мы дошли до края то есть первая строчка мы забираем его инки вот дальше инкремента забираем клементин после этого может кто-то там что то там еще добавить но мы их не будем уже учитывать потому что они уже будет добавлено больше старых на более старших поколений ах вот то есть запись работает настолько быстро что чтение просто не успевает читать существующие поколение такая ситуация возможна ли не читает поколение она его инкремент это марны инкрементом и то есть номера колени у всех картах ранен да а ну каждому свое она растет о последующих то есть они записываются с инкрементом то есть я был но зато если вы смотрите вот мы сделали help да у нас поколение зафиксировалась какое-то до них мы сделали инкремент инкремента да вот у нас поколение зафиксировалась мы хотим прочитать значения из этого поколения правее этого поколение из этого прапора liviu все которые меньше все которые меньше а почему мы считаем что к моменту когда мы будем это читать они будут существовать а ведь если запись тоже энгри меня нет ни колени они могут и не существовать ну то есть тогда это значит что у нас запись была очень медленно и вот наша макне не был ни одной записи ничего больше но все мы не считали мы давно поколение вы просто этом случае мы вернем минимальное значение до с которым мы начали то есть все сорта здесь номер поколение там стемп это просто индекс операции фактически да вот ничего более да у меня такой вопрос там у вас был кот где вы проверяете значение перед вызовом interlock функции может ли так случиться что планировщик просто-напросто переместит исполнения на другой поток и в этом момент как раз произойдет обновление дан у нас это устраивает мы это увидим ну то есть не совсем понимаю сейчас мотивации зачем это делать хорошо в каком методе перемешали на качок за отмотать о черт в этом не вижу ну вот например например здесь да вот вы проверяете хвост не сдвинут ли хвост да если сдвинуть снова верни меня да вот как бы нет нет да проверка это оптимизация то есть но в том что эта оптимизация не оптимизация скорее для красоты кода иначе было бы много вложенности мифов и так далее если у нас кто-то хвост сдвинул то этот кто то есть два варианта он либо раньше нас начал работу вообще до его вытеснили он вдруг проснулся начал работ либо же он начал после нас в любом случае он идет по каждой команде которая младше его по времени нет старше его по времени до старше левее да по времени он идет по каждой команде пытается зафиксировать мы где-то с ним пересечемся возможно но самое общий случай что мы с ним пересекаемся это значит что либо он за финиширует команды либо мы но это же не важно кто из нас финишировать потому что в любом случае каждый из нас закончить цикл мы не уйдем в бесконечность это не лог fritos ник не возникнуть старейшин каждый из нас фиксируют команды мы зафиксировали команду окей другой поток тоже и потом зафиксировать тогда он видит а команд зафиксировано я выхожу то есть здесь не возникает такого таких циклов можете отмотать за там еще есть на место но опять же то есть я хотел встать маленькую ремарку что то что в этот ряд rabotaet зафиксировано времени уходит старейшин это не означает что мы ничем не платим мы платим сложностью говорит мы временем исполнения шагов до может быть душ суда а вот человек до драсте хотел вас спросить во-первых действительно права я убедился то что основной недостаток free алгоритмов это их читабельность надеюсь что и наш кот такой плохой я старался его максимально красиво смотрелся у меня был пришел более простой алгоритм ну как мне кажется как мне кажется на носках примерно по похож на то как отрисовывается картинка на экране то есть два фрейн буфера до в один видеокарта пишет пишет потом переключает как бы указатели экран удар полностью отрисовывать точно такой же сразу пришел сейчас я вспомню почему так не стал делать сейчас секунду короче мне нужно пять минут на воспоминания я точно помню что там есть проблема по моим проблемам в потере да вот как это можно сделать да то что вот вы говорите здесь нам нужно будет как-то указывать то есть мы чтением должны поменять указатель на буфер куда мы пишем но даже 0 или какой-то массив из которому вышли они подготовили его иначе тепла давай спешите пересу да да здесь возникает вопрос как мы сделаем переменную этого указателя nuvola понятную ссылку но проблема в том что чтобы его изменить это понятно тамар на операцию но если мы вот проблем с мы захватили в каком-то потолка лился в чем проблема вот я дальше мы поэтому буфер начинаем искать максимум согласитесь да и что возникает а допустим что когда мы меняли вот это значение до какой-то поток был вытеснить он же в цикле никуда настойка сохранила себя старый-старый значит он же не читает каждый раз до значению ну то есть вот я когда разрабатывал это я понимал что ну надо читать цикле но я не хочу часа цикле а если ты тоже старейшин а если каждый раз будет попадать но это изменение это старый уходим хорошо тогда мы не читаем это значение мы читаем его один раз но тогда при смене буфера а получится что вот этот за левший процесс который поток который был вытеснен он проснется и когда мы ищем максим вдруг запишет и мы будем смотреть мы его прошли он был максимальным а мы его прошли не заметили мы уже прошли мимо и дальше что получается что вот мы опять столкнулись потери потому что все остальные то пишут правильно уже в другой буфер а этот в свое максимальное значения вообще любое он записал туда и мы его потеряли потому что мы проскочили все и мы забыли если бы мы сказали что мы не можем терять значения но все-таки мы хотим в общем то выйти и да тогда вот это было бы гораздо проще там даже еще проще алгоритм получается гораздо проще вообще когда каждый поток просто пишет свой буфер отдельно но вот если мы не хотим терять так не получится писать я я пытался всего понял и что такой более общий вопрос писал какой-то время на 2 нити я знаю там дорогие потоки довольно он мегабайт жрут памяти первый язык где появился осинка вид и вот зачем там нужна многопоточность когда я стивен клуб которую в котором весь вот вывод можно в одном потоке сделать а какие сложные вычисления переложить на смотрите ранее маркеры какие-нибудь если вы говорите о том что dice кейсы вот этого в реальной жизни именно вот эти так вот тут и нибудь но почему мы сыны асада листа задать мне кажется нет подождите мы почему мы здесь то есть что именно в она между ног при структуры вдохните и как применяется или но конечно у нас есть конкурентки у конкурента стек который lock free там допустим dictionary у нас там по моему локти на чтение найти найти богатого тоже пытаются стала синкавы собственно говоря сделали потому что но чтобы на фото ну вот да короче рога всего короче с много по . там все теперь очень хорошо я может быть не не понимаем вашего вопроса поэтому не могу ответить да что вы хотите я про сказала сейчас современных приложениях чаще то веб-сервиса какие-то весьма тут можно делать в одном потоке но мы тут не про веб-сервис говорим с дронами да то есть она тут нить и потому что но мы пишем но тут нити так бы так это конечно пишется на себя новую на чем пишется я не знаю я в этой сфере не работаем и показать только алгоритма так чтобы сразу понятно спасибо спасибо за доклад у меня такой маленький вопросик вот эти примеры кода они полагаются на какой-то модель памяти или же они могут быть перенесены без изменений без дополнительной гарантии на процессоры с внеочередным выполнением команд очередной записью чтением из памяти либо требуются какие-то ещё дополнительные усилия для за рейс ориентация на модель память удод мета и тот же код переносится с минимальными усилиями правками на java вот ну как бы то есть я ориентировался именно на это если мы будем говорить о си плюс плюс то вот так вот просто написать это неудобно то есть тех барьеров памяти которые ставятся не трогал операциях недостаточно может быть недостаточно вот на это я уже не твичу результат на сейчас он мигрирует на разные система то есть вот это вот о том и речь что на тех же самых кормах возможно перри упорядочение записей например но вот вот насколько я знаю вот вылетал да у нас есть ключевое слово насколько я понимаю вот она рассчитана на то что мы не не за кашира вали в регистр да и на то чтобы не было вот этого перезаряда что есть мымре барьеру да ну это то есть то есть здесь надо уже тонко смотреть то есть если мы будем тут то есть тут надо вопросы ну как бы копать понятно спасибо образца больше нет тогда всем спасибо можете выбрать два лучших вопросов данного процесса выcушumь как кто-то встаньте пожалуйста общается вот процесс он кашам классно вопрос загнали в тупик вот вам вы же про процессор и спросили ну давайте обоим за процессоры как бы потому что железо это клево там от него далеко до ни к одному из них приготовились вопросов"
}