{
  "video_id": "BIwj8Qgiuss",
  "channel": "HighLoadChannel",
  "title": "Кластеры баз данных: делаем сложные вещи просто / Андрей Тихонов (Avito)",
  "views": 5623,
  "duration": 2519,
  "published": "2017-04-22T14:47:53-07:00",
  "text": "коллеги все мы знаем в теории знаем что такие вещи как редис memcache стран тут он воскрес и другие такие интересные штуки они могут работать в режиме крейсера это опять таки в теории а вот как оно на самом деле на практике нам сейчас расскажет андрей тихонов компания авито попросим всем привет меня зовут андрей тихонов я ведущий системный администратор avito.ru и сейчас я вам расскажу всякие интересные вещи ну начнем с того что просто посмотрим как может развиваться проект как он может дорасти до хайло да посмотрим как реализуется балансировка бэг-энда немножко теории про то как вообще масштабируются базы данных причем под базами данных в данном случае будут выступать и реляционные обычный базы данных и киева илью хранилище как редис тарантул memcache вот а дальше перейдем к практическим примером посмотрим как можно класть раза к власти рисовать собственно вот эти келью хранилища и с готовой базы давайте начнем с того что посмотрим с какой нагрузкой справляет совета потому что некоторые примеры они будут взяты из собственного из боевой конфигурации вот то есть что мы имеем мы имеем больше миллиона запросов минуту кабак онду больше гигабита исходящего трафика ну и больше сотни тысяч запросов в секунду уходит на backend при приходит на и джонс балансиры вот и плюс у нас много картинок давайте посмотрим как же у нас начинается в проекте хай лот жил был обычный сайт не был веб-сервер backend ну например php и базы данных которые хранились всякие данные жили жили потом поняли что мы делаем много одинаковых запросов к базе взяли и добавили кэш причем в данном случае можно уже считать что backend у нас много процессная то есть взяли какой-нибудь php-fpm вот и у нас много процессов php работают поэтому кэш мы используем не внутри процесса по хп а именно сетевой доступный из разных мест жили жили выросли еще поняли что у нас пока не хватает на одном сервере добавили еще сервер бэг-энда еще один или ещё сколько-то вот при этом в принципе на может до сих пор хватать снова веб-сервера который просто пробрасывать запросы к бренду и одной базы данных и 1 каша хватает выросли еще появились тяжелые задачи для этого мы сделали очередь сообщений чтобы обрабатывать шел из задач позднее ну и добавили хранилище вот прошли росли и росли росли и доросли до того что все у нас превратилась в кластер мы добавили балансировку на уровне железа на уровне каких-нибудь свечей либо специальных балансиров у нас много вечеров нас распределенное хранилище у нас там хавел ability очереди база данных стала кластером и каштан кластером вот как это произошло в случае совета у нас вот такая вот простенькая схема продуктовая вот можете посмотреть просто какое количество серверов с чем работает вот но в принципе то есть у нас 10 основных веб-серверов которые пробрасываю террора и терменируют этот ps трафик 68 пышных абонентов основных ну и там порядка 60 различных хранилищ редис тарантул чуть поменьше мкш вот это все хранится в одном дата-центре на разных серверах вот самая простая часть как балансировать backend ну вот был у нас один сервер нем был в яндекс который боксировал на practical запросы на backend сделали много брендов появилось несколько серверов одинаковых крутыми джон икса добавили просто кусок кода про up stream в нем описали сэра рабы кэндо вот и пробрасываем теперь мы на up stream engine x умеет следить за состоянием каждого бакан сервера вот если один выходит из строя он придает следующему запрос вот ну и так пока либо либо все хера не сдохнут либо не найдем живой сервер вот но он умеет на самом деле больше он умеет там различные vesa для разных сыров делать можно указывать что какой-то сервер в данный момент выведен из боя можно сказать что мы используем тот сервер которому в данный момент меньше всего активных подключений открыто но это уже подробности пойдемте дальше немножко теория про базу данных жила была база данных вот нам и не хватало потом мы выросли и у нас могло произойти принципе два независимых событий во первых нам перестало хватать и производительности база данных что делать данном случае в данном случае ответ простой делаем репликацию что такое репликации надеюсь все понимают в данном случае рассмотрим репутацию masters ли у нас есть основной сервер мастер который обрабатывает и чтение и запросы на чтение запросы на запись и мы делаем один или более слоев которые отвечают только за чтение вот почему эта схема популярно ну потому что как правило больше запросы приходят на чтение то есть случае совет у нас по моему разделения 1 к 9 на один запрос на запись приходится 9 запросов на чтение поэтому актуально делать славы которые только для чтения второй вариант что у нас может случиться мы могли просто превысить размер базы данных у нас база данных не умещается на одном сервере что делать делать шарди рования то есть разносить базу данных на отдельные куски при этом то есть у нас каждый кусок база данных и база данных хранится на отдельном сервере данные не пересекаются вот как разносить данные где где эта логика но по-разному мы можем это реализовать в самом маккензи либо можем использовать какое-то промежуточное программное обеспечение которое будет сортировать это за нас ну про этого дальше будет подробнее пойдемте дальше значит начнем с того что рассмотрим создание кластера для киева или хранилищ прежде чем создавать кластер посмотрим какие вообще проблемы могут быть когда у нас много брендов и один каширу ющий сервер проблемы такие случаи спеша у нас время она сильно ограничена вот и если кэшируются базе данных для того что получить данные надо просто сходить в пассивной память это быстро и вот так клиента чтобы подключиться по сети нужно сравнительно много времени поэтому установление подключения к каше ручку серверу это мы читаем уже долгой операцией дальше сколько у нас живет подключение ну запустился у нас скрипт php шина который генерирует страничку сгенерировал страничку подключился время генерации отключился как раз пишут базе данных вот завершил работу все соединение закрыл то есть у нас срок жизни подключения это столько нет они дольше чем нужно чтобы сгенерировать одно веб-страничку то есть мало когда у нас много одновременных включения на сервере у нас могут быть большие накладные расходы например ну там на всякие внутренние блокировки между процессами вот это менее заметно в memcached более заметно в одессе который например однопоточный вот как же решать эти проблемы ну используем промежуточное программное обеспечение например тем прокси это неясно программное сечения которые решают эти проблемы вот ниже есть список аналогов значит что умеет делать trim прокси он имеет кэшировать прозрачное проксирование прозрачно на уровне протокола поддерживает данный момент два с половиной протокола на два с половиной потому что для тарантула нужен отдельный патч от разработчиков тарантула что он делает этот самый там прокси он делает постоянное подключение к он он держит постоянно подключение к серверу с киева или хранилищем и клиенты включаются особенных прокси а ник хранилищу вот прокси обычно ставят локально на той же машине где backend поэтому подключается backend прокси быстро вот прокси не тратят время на то чтобы каждый раз переустанавливать подключение к серверу и просто соединение есть она висит она используется что еще он делает он снова меньше и соединение чем у него есть клиентов ну просто потому что обычно клиенты они не загружаются подключение на сто процентов то есть print подключился сделал запрос и соединение висит висит и висит вопрос просто простаивает вот когда у нас клиентов много у нас в принципе запросы наверно как-то разнесены по времени вот поэтому если мы сделаем одно подключение к серверу мы сможем через него пропускать подключение запросы от нескольких клиентов то есть мультиплексирование ключе нее клиентов одно соединение козерог честно подключение к террору вот это проблемы которые были до того как мы сделали кластер теперь кости разуйся обычный пример конфига совсем все просто мы указали адрес на котором слушали слушаем указали протокол который слушать и указали сервер на которой прокси ровать все рабочий конфиг поднять это дело пяти минут интересуемся но случае с ковшом у нас более актуален вопрос о том что мы хотим кэшировать побольше данных поэтому у нас обычно память на там сервер не хватает делают несколько серверов соответственно мы сортируем twin прокси умеют фактически сортировать мы ему указываем какой алгоритм хэширования использовать по какому ключ по какой части ключа хэшировать что чтобы поймать никакой сервер пробрасывать запрос вот и он автоматически сортирует то есть клиент то есть наш backend мы он не знает про то что там есть сортирование он просто работает протоколу редиса и лимон каша вот и он вообще не задумывается о том что там есть ли это же где где то есть хэширование вот вам про xe поддерживает алгоритмы стойка вы хэширования что это значит это значит что в случае если мы изменим конфигурацию бы консилеров серов вас хранилищем нам придется перефразировать минимальный объем ключей то есть по максимуму ключей останется на тех сферах где они были вот ну и плюс в такой конфигурации темп roxy умеет группировать i can very заводь запросы ответа что это значит но один клиент сделал запрос на один сервер в другой клиент сделал запрос который попал тоже на тот же сервер для прокси берёт и генерирует из них 1 метр запрос ну то есть например и несколько запросов get он превращает в 1-м get вот один запрос на сервер обрабатывается быстрее ну просто потому что нет у накладных издержек на то чтобы передать несколько запросам вот сервер отвечает мульти ответом тоже и м прокси его назад разбирают на ответы отдельным клиентам вот получили выигрыш на этом канале зация запросов это просто мы в одном запросе передаем несколько запросов на сколько я понял то есть вот в одном пакете данных мы продаем несколько запросов ну и в ответе получаем также вот конфигурация ну добавилось немножко ключей добавилось алгоритмом распределение ключей кассиром и алгоритм хэширования указали да и указали что несколько серверов есть все у нас будет фактически происходить что родирование вот поэтому код на бэг-энде мы не мы никак не поменяли мы просто подключились мы теперь подключаемся к трем прокси в proxy остальную работу делает сам теперь добавить давайте попробуем все-таки добавить отказоустойчивость потому что вот эта схема с родированием она у нас не отказоустойчивый если у нас какой-то сервер будет строя мы данные потеряем вот я буду показывать отказоустойчивость на примере родис а потому что ради сумеет сохранить данный на диск он умеет делать мастер слоев репликацию вот делать отказоустойчивость причем прозрачную опять же для клиента то есть чтобы не модифицировать клиент будем делать и три шага первый шаг мы добавляем репликацию со средствами редис ну поднимаем еще один сервис а вот в нем делаем такой же конфиг как на мастере но может не такой же конфеты указываем вкус строчку слоев все родис понимает что он sleeve такого-то сервера будет с него сам подсасывать данные актуальны следующий шаг это нам нужно автоматически переключать sleeve прижим мастера случае если мастер нас упадёт вот потому что точно так же как с другими базами данных при мастерство и привлекаться и у нас своих проблем может обрабатывать запросы только на чтение мы хотим все таки и писать и читать вот для автоматического подключения есть такой продукт как кредит sentinel он по моему даже встроен последних версиях редиса что он умеет делать он мониторить состояние всех нот кластером у нас может быть больше одного слова опять же вот он уведомляет администратора об ошибках которые происходят то есть вот у нас но до вышла из строя он может автоматически мать роль своего до мастера если мастер упадет и он может выступать в качестве проводя конфигурации если мы делаем продукт который заточен на работаем на с редисом именно сантино мы можем отличаться каналу и получать конфигурацию то есть в данный момент такой-то мастер активен все остальные слои вы вот конфигурация тоже достаточно простое указываем адрес мастера все остальные ноты цент не узнают от мастера указываем задержки и там через сколько миллисекунд считать что у нас мастер сдох если он не отвечает какое время мы перед но мы даем на переключение и сколько своего одновременно переключать на новый мастер ну потому что если много слоев сразу ломануться на новый мастер они могут его положить не хватит ему производительности там будет у нас бесконечно синхронизации общем может быть проблема поэтому здесь можем ограничить в данном примере у нас по одному слову будет переключаться вот и последний шаг мы должны сделать прозрачной для клиента переключения в этом нам поможет такой замечательный инструмент как х прокси в proxy потакайте себе прокси и балансиров он умеет делать много вещей во-первых он может сбалансировать нагрузку на несколько серверов разными алгоритмами там round robin то есть по очереди может перебрасывать соединений на тот сервер которому сейчас меньше всего включений может перебрасывать включение на первый доступный сервер может делать хэширование какого-то запрос какого-то параметр запроса клиента ну например ахахаха жировать тому исходящий айпи и порт чтобы у нас там одни и те же клиентов всегда попадали на одни и те же террора вот он умеет делать он умеет разделять роли серверов там праймари и backup группы то есть пока у нас жив один сервер из праймари группы запросы будут приходить на него будут блокироваться на праймари группы когда все праймари сдохнут будет балансировать а нагрузка на backup сервера и он умеет с разными способами проверять что у нас рабы конца на котором пробрасывать что они живы вот банальный способ проверки просто сделайте себе коннекта есть подключились на порт успешно все сервера жив может делать проверки на ровненько такого например сделать этот запрос 200 ответ получает значит сервер жив получать там 400 и 500 значит с сервером что-то не так вот мед и умеет делать кастомной проверку с помощью с and i expect то есть посылает по тисе пи какую-то последовательность символов и ожидают что ему сервер ответят какой-то другой последовательности символов сейчас покажу пример как это делается у нас в случае с редисом такая конфигурация х прокси указали название порт на котором слушаем указали опцию что мы делаем проверку по тисе пи вот и указано что мы посылаем строчку пинг и ждет что вам сервер в ответ ответит pong после этого посылаем строчку in for applications и ждем что нам сервер ответят что он мастер вот мы после этого закрываем соединение вот то есть такая проверка она будет показывать что включены будет показывать что животе сирано которых сейчас среди сработает в роли мастера вот славы будут показаны как их нерабочие вот она и в конце мы указываем собственно террора на которой она доходить до серого в данном случае вот три три таких шага сделали у нас может получиться примерно такая картина подходит подходит к тем прокси в proxy ходит к прокси то есть прокси шарди рует на несколько ярдов каждый шар ты на самом деле х прокси который делает который боксирует на мастер ради со в группе ради своей the masters life репликации вот и затем чтобы мастер был жив нас следит радио sentinel вот так многоуровневая схема она работает у нас ну давайте перейдем к созданию кластера по с gresso ну и опять же проблемы которые могут быть еще до создания кластера в случае с прогрессом у нас на дно клиентское соединение использую поднимается один серверный процесс вот это дорогостоящая операция потому что надо for гнутся там память скопировать и все такое вот дальше нас когда соединение есть у нас в рамках на воссоединение кэшируется планы запросов выполненных вот еще какие-то ресурсы могут котироваться ну например можем сделать пример statement вот и его позднее использовать это все живет пока у нас живо соединение вот когда мы перри подключаемся у нас все это теряется весь кэш теряется вот ну и опять же включение у нас живет не дольше чем мы генерируем страничку если мы их хотим напрямую из бэг-энда в базу данных вот у бэг-энда много worker процессов соответственно много подключения на сервере соответственно много накладных расходов то есть мы много процессов создаем а это долго времени мы много времени занимает плюс всякие между процессной блокировки они тоже могут в случае большого количества подключений замедлить работу решаем проблему аналогично с помощью прокси данном случае прокси называется пиджи bouncer вот он не не единственный есть например прокси пиджаку и наверняка есть еще какие то там логичные продукты что он делает но он практикует прозрачно на уровне протокола под gresso точно также как twin прокси он делает постоянно не постоянно долго и подключение к серверу и причем при подключении к серверу он может сделать какие-то специальные запросы вот то есть он отличается к серверу делает запрос который там делает как раз пример statement и вот а клиент когда будет ходить он будет работать уже с проклятыми соединениями вот то есть не будет задержка на клиенте вот ну и точно также как там прокси он может держать меньше соединение xero рот чем у него соединения у клиентов то есть клиенты опять же подключаются делают какой-то запрос после этого соединения висит вот если если бы мы подключались напрямую к базе данных у нас висели бы просто процесса на базе в данном случае у нас абакан подключается к пиджи bouncer а вот и он может более эффективно использовать подключение к серверу то есть делает меньше подключений террору вот и по-разному multiplexer уют клинские подключения вот ну что значит по-разному может за мультиплексирование уровне сессии то есть клиент делает подключение пиджи bouncer для него делает для него резервировать какой-то получение к серверу вот клиент отключился пиджи баузер свое серавно и подключение освободил второй режим это transaction pulling то есть клиент делает транзакцию и на время этой транзакции у нас опять же резервирует сайт одно подключение g баллон 40 серверу вот транзакция закончилась можно опускать контакты другого клиента вот ну и самый агрессивный режим и the statement pulling это когда мы работаем без транзакции просто на уровне запросов тогда просто какой-то клиент делает запрос этот запрос сразу же вылетает на сервер через любой свободно и подключение к серверу вот все какие режимы использовать вы решаете там зависимости от того какая у вас все-таки логика какой у вас бизнес то есть в нашем случае мы используем примерно transaction pulling нам этого хватает конфигурация bouncer а надо отдельно указать какие базы данных мы будем обслуживать баунти рун выступает в роли вас гск сервера вот но есть какие-то базы вот для каждой базы мы укажем разные параметры то есть куда ходить для этой базы на кого хвост там можно указать какой-то другой ими базы размер пула то есть сколько соединение максимум terrarum одержим ты тот самый пул says и данном случае указано указанный запрос который выполняется при подключении к серверу то есть прежде чем клиентские запросы буду про брошены и g bouncer он случается к террору если еще не подключился и делают этот самый connect кьюри вот но и здесь указано что же transaction pulling и максимальное количество обслуженных клиентских подключений теперь давайте поговорим немножко опять про репликацию более подробно какие виды репликации бывают по много разных видов вот например можно разделить репликации на синхронные и асинхронные а что такое синхронная репликация у нас мастер выполняет какое-то действие и отправит это изменение данным это изменение данных всем своим словам и ждет пока не подтвердят что они получили эти данные после этого он продолжает работу вот то есть у нас это репликация она более медленная потому что мы должны ждать всех слоев вот но она более надёжная потому что у нас не может быть такого что он на каком-то советом что-то не проигралась репликация может быть и синхронная в этом случае у нас наоборот мастер не ждет пока все слышишь там получит данные он ну как правило пишет данные в какую-то очередь вот и продолжает нормальную работу клиентам вот осла и вы они эта очередь читают и у себя проигрывают вот ну понятно что в этом случае у нас славы отстают от мастера вот и мы теряем одно или два свойства из и сет то есть мы теряем c мы теряем д что что же у нас там мы теряем consisting консистенции и мы теряем your ability вот но опять же какую-какую репликацию использовать вы решаете в зависимости от того какие у вас требования к приложению какой еще разделение репликации может быть catia бывает физическая то есть у нас слове получают полную копию всех данных мастера вот копируются на уровне хранилища база данных в случае с прогрессом это обычно right ahead лог то есть сервер прежде чем применить какое-то изменение он пишет его в лоб что я буду делать такую операцию после этого эту операцию делает вот этим блогом он делится со словами там локально как-то или по сети вот это репликация на загружает ввод-вывод ну понятно потому что есть у нас в принципе обдумывать ничего не надо нам пришла операции мы ее должны записать вот противопоставляется этому логическая репликация это репликация на уровне протокола на уровне операций с данными вот то есть нас когда происходит какая-то операция мы эту операцию тоже запись записываем куда-нибудь например в очередь вот это операция на это репликация на более гибкой мы можем выбрать какие данные мы записываем то есть мы ставим до для логической репликация мы ставим триггер на базу данных там на insert надует на удалении вот и в этом триггере мы можем принципе написать любой запрос который нужен то есть мы можем собрать данные не только те которые записываются можем сделать там какие-нибудь join и или какие-нибудь свои процедуры выполнить и записать короче любые данные как-то связаны с тем что произошло вот это рипли catia она загружает процессор вот значит важное замечание если вы делаете мастер слоев репликацию то в зависимость от того какую репликацию вы делаете ваш слоев должен быть не хуже чем мастер иначе он будет бесконечно оставатесь если у вас мастер ssd slave хода дашиной вот вы делаете физическую репликацию вас скорее всего просто будет не успевать записывайтесь на хдд то что мастер бывает писатель на ssd вот случае с логической репликации если у вас там более слабый процессор ну аналогично он просто не будет успевать все операции применять вот поэтому там самый хороший случай если у вас одинаковая сервера для мастера я для слова когда мы создали все-таки мастер слив кластер если у нас один мастер один slave мы успешно распыляем нагрузку на чтения при этом у нас скорее всего нет отказоустойчивости то есть мы изначально этот кластер сделали потому что там не хватало производительности вот теперь у нас 2 duo сервера у нас производительности хватает вот однако если один из этих сыров где-то строя у нас опять будет один сервер мы опять захлебнешься мы не сможем обрабатывать все запросы клиентов поэтому лучше иметь два и больше слова ну систему stem умыслом чтобы случае если у нас мастер упадет мы могли один из слоев сделать новым мастером и ушло как приучать случае падения это тоже отдельный вопрос то есть можно автоматизировать это как-то можно руками переключать вот мы например руками прекращаем только в том случае если у нас мастер падает то есть падение слова это не так критично что ещё можно сделать ну например у нас савита много много объявлений хе хе мы хотим чтобы пользователи активно пользовались поиском по нему пользователям это удобно не просто просмотрите объявления искать объявления которые будут им нужны для быстрого поиска у нас используется индексации ну я думаю найдется много похоже кейсов общему индексация нужно вот проблема индексации в том что если она ходит на мастер она вымывает ему весь кэш потому что индексации она проходит по там по большей части данных наверно вот и это большая часть данных она но всяко больше чем кэш процессора вот поэтому мы используем для индекса для реплики для индексации мы используем логическую репликацию вот во первых мы не трогаем конечно мастер а во-вторых мы копируем только нужные данные то есть только те данные которые нам нужны для индексации мы не держим полную копию всех данных вот а благодаря тому что мы держим только нужные данные у нас эти данные все умещаются в оперативную память на репликах или индексации вот поэтому они в принципе с дисками не работают вот это очень прикольно потому что у нас репликация мой у нас индексация проходит что-то примерно за 7 минут вот а там что-то порядка нескольких миллионов объявлений вот как раз про это где-то где-то был был или будет отдельный метод наверно верно уже был вот ну пойдемте дальше ну вот схема с килограмм слоев то есть опять же с помощью хоп аксим можем регулировать доступ к словам вот есть bouncer ходят х прокси в proxy выбирает какой слоев сейчас жив ну то есть один слой по наверно скажем что он праймари 2 слоев он backup либо мы можем сказать что они оба праймари вот и будем на них нагрузку распределять round robin а вот но опять же повторюсь эта нагрузка только на чтение то есть нагрузка на запись она идёт напрямую на мастер по другому нельзя никак вот аналогично с репликами для индексации их тоже две штуки вот их a proxy позволяет прозрачно для клиента ходитесь nature nature плек у которой сейчас жива ну и напоследок сортирование кластеров вас gresso для этого есть такой инструмент как пыль прокси вот он опять же не единственное в своем роде есть хорошо развивающий сейчас cirrus вот что такое прокси это расширение не закопал gresso но устанавливается на одной ноте с прогрессом так называемый прокси но я вот не принципе может не быть самой базы данных вот а может она может быть вот суть том что мы с помощью расширенного синтаксиса расширительного языка прогресса описываем дополнительные функции которые позволяют понять на какую из на какую из shard нужно ходить за нужными нам данными вот но для разных функций можем разную логику написать вот это все пишет все хранится в хранимых процедурах то есть на сервере вот и опять же клиент может не знать что он ходит на шокированный кластер то есть клиент просто исполняет сохраненные спальные от хранимые процедуры вот на сервере они оказываются использующими sharding вот так как логика гибкой можем даже сделать поддержку шарф с мастерство и компликации то есть если у нас какая-то функции нужно только для того чтобы читать мы можем ходить в том числе к словам если мы записываем выходим к мастеру вот ну и сама лично выглядит так совсем тупо вот собственно все итоге если у вас backend ходит напрямую к серверу баз данных наверное это плохо потому что много откровенных печенек серверу много накладных расходов много задержек для решение этой проблемы используем прокси если мы хотим получить отказоустойчивость мы используем мастер слоев репликацию вот чтобы у нас свои вы не оставались вы должны быть не слабее мастера чтобы мы были делить на отказы устойчивым нам надо чтобы слов было больше одного вот если данный у нас не умещается на вам сервер мы данные шар деруны сколько серверов и это все комбинируем при необходимости у меня все спасибо просто так значит как быстро у вас происходит переключение значит редис осла его на мастер если мастер падает соответственно и как на это реагирует бэг-энда там задержка проверки что-то около двух секунд то есть достаточно быстрого переключаемся в течение двух-трех секунд максимум что у нас произойдет у нас порвется подключение давайте я на схему назад русь максимум что у нас произойдет у нас может порваться connect между х прокси и 3 м процент потому что ты потому что х прокси приключилась одного сервера на другой вот ты прокси там сразу же попробуют повторно подключиться вот и просто попадет на другой сервер то он не будет значит этот другой сервер потому что включается к прокси там такой вот и то есть достаточно быстро это работает то есть в этот момент получается что данных нет то есть мастер решение определен backend ответ получит или не получит этом случае осмотрите у нас х прокси там прокси они ждут ответа то есть у нас не нас не будет такой ситуации что клиент не получит данных не вопрос просто запрос можешь до может там полететь некоторое время пару пару секунд спасибо сверху добрый день спасибо за доклад а как-то резервируется самих а порог сейчас который все осуществляется подключение у нас следую картина простая у нас к прокси там прокси на каждой ноги бэг-энда то есть вот этих вот этих самых тем прокси в proxy их на самом деле столько же сколько серого бэг-энда вот то есть но если у нас выйдет настрой один сервер бэг-энда ну и чо у вас и 68 стала 67 но в принципе понятно ясно спасибо да спасибо за информацию подскажите вас прогрев к как долго происходит и в какой случай самый тяжелый нагрев чего именно ну вот не знаю после перед нами от которого холодный старт и системы запускается от самого зарезервировано самом таком тяжелом случае то есть и sharding и резервирования и все все все ну вопрос скажем так слишком расплывчаты что можно было ответить то есть ну как правило когда у нас падает master пасс gresso сушину порядка нескольких минут наверное можем провисеть и подождать пока все прогреется но учитывая что у нас кэш redis автора наталья в нем каши это не очень страшно можно еще маленький вопрос а подскажите вот часто встречаю что используется именно сочетание radice i'm on tv а почему именно такое сочетание почему не достаточно родиться который прекрасно справляется с memcache он более быстро то есть если нам нужно хранить какие-то простые структуры данных то точно не скажу какие структуры в общем самые примитивные вот для этого можно использовать кэш redis он там мор можете придать я там же работаю я вас вынужден расстроить даже моим каша одного кластера недостаточно то есть например есть такие случаи если у вас большой проект у вас очень много разных кашей маленькие и большие вот их вместе и даже в одном моем каша и хранить нельзя иначе получается эффективно данный вымывают маленькими данными вымывается большие каши и наоборот вот случае с ради сами у родис они очень хорошо реализован алгоритм lru вот это вот ложные вымывание данных из кэша она у него прям остров болит соответственно в этом и проблема плюс у редиса дефрагментации по памяти сильно хуже чем у мам каша при постоянных перезаписи тут на предыдущем докладе докладчик из milrose рассказывал что тарантул работает быстрее гораздо чем вы не пробовали его использовать у нас тарантул используется несколько для других вещей не совсем для каширования вот какие то сравнительные тесты мы не проводили насколько я знаю спасибо большое за доклад вот вы сказали про 2-м прокси что там реализовано стойкой стойка и хэширование но видимо в этой схеме вы не используете эту фичу то есть при при отказе одного вот х прокси ведь не будет же узел там twin прокси запускать перераспределение данных наши осмотрите фокси включается к прокси стоковых столько хэширования но у нас указано здесь вот дистрибьюшен китам а она как раз consist of fishing дает соответственно но если какой-то из у нас мастера если вы regisseur слова расположены на разных серверах соответственно я не помню такого чтобы нас какой-то кластер целиком выходил из строя то есть нужно чтобы два физических сера разных одновременно упали нас слава богу такого не было ну если такое произойдет здесь на самом деле поведение настраивается разное можно сказать что мы вот эту ноту которая вышла из строя считаем все дохлый и происходит ришар ding либо мы будем бесконечно ждать пока она поднимется то есть запросы клиентов они про просто будут отваливаться от по таймауту либо любым буму ошибку отвечать у нас два варианта либо мы ждем пока надо поднимется какое-то определенное время либо мы просто говорим что nokia на сдохла значит на стало меньше значит надо данная перераспределить одно вот по факту вот у вас вот до этого была такая большая схема то есть atween прокси прокси рует запросы на х прокси да именно такие twin прокси существует в очень много экземпляров не делим прокси их a proxy они локально на каждом бэг-энде вот то есть но то есть тогда если вдруг на одном каком-нибудь бы кенди откажет х прокси и twin прокси решит что надо перераспределять данные то он начнет через оставшуюся х прокси и что-то там надо надо понимать что он он не будет пересказать все данные просто преследует брик при каждом новом запросе он будет использовать новую схему воспитанников расследование ключей то есть он будет уже считать что серверов меньше то есть он не будет все существующие данные перекладывать имеешь он вопрос он просто новые новые запросы будет пускать на другой оси какой-то сервер спасибо ну если каких-то в общих вопросов нету можем пойти в отдельными тапочек с водяными то пру вот могу сказать что-нибудь про кастомные чеки на х прокси вот ну и если другие любые вопросы возникнут пойдемте посидим skagen"
}