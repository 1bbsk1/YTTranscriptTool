{
  "video_id": "I-6SS6_C1Cw",
  "channel": "HighLoadChannel",
  "title": "YDB Topic Service: как мы повышали производительность очереди сообщений / Александр Зевайкин",
  "views": 399,
  "duration": 2738,
  "published": "2024-10-29T02:38:40-07:00",
  "text": "Александр расскажет же как не увеличивали производительность очереди сообщения и для чего это нужно Привет Привет всем я не буду дождаться секцию сразу же тамм вопрос почему не кавка расскажешь самом деле буду к этому заходить несколько раз Почему не в 2017 году почему не сейчас и поэтому давайте вс-таки послушаем хочу спасибо сказать всем которые кто Пришли ещё раз Здравствуйте Меня зовут зевакин Александр Я уже практически 20 лет в it Ну такой немного старичок имею разносторонний опыт начинал с преподавание в ВУЗе запуск запуска множество стади командами т момен Я работаю в Яндексе в самом таком высоко нагруженном месте это разработка распределенной базы idb И в частности в idb работа в Яндексе ставит огромное количество технических вызовов которые просто интересно решать и Один из таких технических вызовов это производительность нашей основной очереди сообщений в idb to год назад но на этой конференции мой кол ль дар анонсировал выход в Open Source в idb Topic и он сразу получил один из первых вопросов а как у вас производительностью целью доклада является ответ на на этот вопрос Мы хотим конкурировать с кавка И конкурировать не только функционально и хотим конкурировать по производительности и Для этого нам необходимо быть как минимум не хуже Для начала я расскажу про архитектурные особенность э как всё это работает внутри и начну с того что такое vdb Topic если очень-очень просто это большая и производительная очередь сообщения на которой работает весь Яндекс любопытно но в 2013 году Мы работали поверх кавка А мы начали чувствовать некоторые ограничения и в 2017 году Мы перешли на wdb А с прошлого года мы ещё доступны в Open Source несколько слов о ydb изначально это распределённая отказоустойчивые newl база данных которая с открытым исходным кодом которая А сочетает в себе как свойство новы SQL это масштабируемость высокую доступность отказоустойчивость так и классически так и свойство классических распределённых SQL баз данных это строгая согласованность и транзакции asset в настоящий момент wdb представляет собой же полноценную платформу состоящую из большого количества готовых блоков которые дополняют себя друг друга с архитектурной точки зрения и очереди сообщений я их выделил синим цветом это типичный блок который органично встраиваются в эту платформу и переиспользовать готовый сложный функционал например вроде распределённого отказоустойчивого хранилища хочу несколько слов ть об инсталляции idb Topic в Яндексе суммарно мы Прокачиваем через нашу очередь сообщения до 20 млн событий в секунду и скоростью до 200 Гб в секунду это 80 Гб в секунду на запись и 120 на чтение А в пик нагрузок мы Прокачиваем через себя Ну например в чёрную пятницу которая была Недавно мы Прокачиваем до 300 Гб в секунду наибольший объём потребляют логи и метрики Ну и конечно машина для асинхронного взаимодействия прикладных сервисов которым у нас занимается порядка 000 разных команд и обратить внимание на Любопытный правый столбик где написано один дежурный сре автоматика мониторинга доведена у нас до такого уровня что этот дежурный он просто не замечает выход строя диска сервера стойки то есть в асинхронном режиме создаётся тикет на починку который уходит например там в конкрет центр ну максимум что там дежурно придёт там уведомление в Telegram что вот тут ну Обрати внимание а очередь сообщения При этом продолжает работать как ни в чём не бывало или вот другой скриншот А из реального интерфейса мониторинга слева пришлось замазать название реальных сервисов вредине видно что некоторые сервисы состоят практически из тысяч топиков и справа мы видим скорость которая достигает десятков гигабайт в секунду далее я хочу перейти непосредственно к архитектуре очередей сообщений А после этого уже начну говорить про особенности отличия и про скорость Согласно определению очередь сообщения служит для асинхронного взаимодействия между писателями и читателями вроде всё просто потоковая очередь сообщений Она состоит из топиков То есть это семантическая единица группировки сообщения топики разделяются на партиции уже в целях производительности партиции содержат в себе множество упорядоченных сообщений и сообщения адресуется смещения и любая потоковая очередь сообщения гарантирует у порядочность сообщений в рамках одной партиции перейдём к кавка уже к одной архитектурной особенности кавка к которой я буду возвращаться по мере доклада кавка хранит да непосредственно на узлах обработки получив запрос на запись Она сначала пишет данные в локальную файловую систему а потом реплицируемый кэша если данные ещё свежие То есть например при типичном чтени мы не используем для ведомых узлов Кто не знает это более свежий аналог кавка он довольно-таки развит с точки зрения функциональности и имеет ряд интересных архитектурных особенностей и главной архитектурной особенностью Пульсар является то что он выделяет отдельный слой хранения полагаясь на такой проект как ач бу получив запрос на запись или чтение брокер Обращается не к локальной файловой системе а к и это является основным конкурентным преимуществом по сравнению с кавка так как выделенный слой хранения существенно упрощает масштабирование и отказоустойчивость и практически на всех конференциях зарубежных Пульсар это позиционирует как ну свою фичу номер один к также выделяет отдельный слой хранения полагаясь уже на платформу получив запрос начте брокер обслуживающий конкретную партиции обращается к так называемому BL storage это кубик который занимается отказоустойчивый распределённый хранилищем и Аналогично Пульсар данные свойства выгодно отличает в idb Topic от кавка с точки зрения масштабируемости и отказа устойчивости а пару слов хочу рассказать о режимах хранения idb наиболее отказоустойчивый режим это Mirror 3dc который применяется для трёх Датан кластеров Он поддерживает отказ одной зоны доступности плюс одной серверной стойки в любой другой зоне и плюс на слайде не отмечено есть замечательная особенность как автоматическая реконфигурации групп хранения которая снижает вероятность потерь данных путём восстановления избыточности Что это такое то есть например если вышел из строя диск сервер либо ройка стойка автоматика это обнаруживает и через час она пытается восстановить требуемую избыточность 3 Икса То есть она независима от дежурного копирует данные на нужные узлы чтобы избыточность это поддержать и вот это совокупная совокупное количество гарантий приводит к тому что Ну в принципе у капки Пульсар нету аналогичных режимов а с ними мы будем сравниваться в режиме так называемом блок 42 кото у нас применяется для одно доцентрового кластеров данный режим использует R encoding который потребляет всего полтора и хранимого места при гарантиях доступности сравнимых с трёхкратно репликации кавка и Пульсар как я говорил сначала у нас была кавка и у нас на самом деле есть даже статья в хабре от 2014 года где мы рассказывали как Мы работали в Яндексе передавали все логи а на базе кавка но в итоге мы отказались от кавка и Об этом я хочу сейчас рассказать но я сначала расскажу почему мы в 2017 году рассказали отказались а потом вернусь к23 году почему сейчас нас что-то не не устраивает Итак 2017 год кавка работает поверх зупер это распределённая сервис координация которая хранит всю Мета информацию о парти Ну и в частности одно из наиболее нагружен нагруженных данных которые передаются через зупер - это смещение всех косме это приводит к тому что когда идёт высокий поток на запись например шесть Там там там 5 6 10 миллионов событий в секунду зупер просто не справляется с сохранением всех смещений либо что для нас очень важно когда число партиции достигает например десятков тысяч то зупер тоже с эти не справляется из этого следует что для нуж Яндекса Яндекса требовалось бы сделать несколько инсталляций А в каждой поддерживать ещё по своему кластеру кипе гео распределённый кластер по состоянию на начало 2017 года ВЧ Кака В принципе не было поддержки зеркалирование генно там в принципе не было таких слов только в 2018 году там первы пропол давайте сделаем зер между разными дата центрами и вот мы с 2013 года по 2017 года по 2017 были вынуждены сами строить обёртки поверх кавка таким образом чтобы Мы работали в режиме герас продел кластера Следующий пункт изначально кавка Поддержи только это означает что мы Гарантируем доставку сообщения но мы не гарантируем отсутствие дублей и повторные попытки отправки сообщения приводят к тому что может появиться дубль почему это происходит наверняка кто-то знает из-за того что в том протоколе кавка на тот момент в принципе не было счётчика сообщений при записи А если нет счётчика при записи то соответственно мы не можем сделать дедупликация пить их в метаданные сообщения либо каким-то образом встраивать сообщения а на стороне конечного потребителя производить дедупликация Ну соответственно мы перекладывать заботу на сторону прикладной программы Что такое шумный сосед это когда один потребитель может помешать работе другого а использовав в моменте ВС процессорное время либо пропускную способность кластера на запись это в принципе неприемлемо ни для внутренних команд Яндекса ни для работы в режиме облака и первые пропол Кафки на разграничение доступа и на добавление кво появились только в 2018 году и всё это привело к тому что в 2017 году мыли вынуждены принять решение отказаться от каки и перейти на платформу wdb где многое уже было решено из коробки стоит заметить что в 2017 году потоки на запись составляли порядка 1 гигабайта в секунду а к настоящему моменту они выросли практически в 100 раз Ну и стоит заметить что кавка на самом деле Ну довольно-таки активно развивается и было бы интересно посмотреть что происходит в настоящее время кавка начинает планомерно отказываться от в пользу собственно реализации сервиса координации под названием K raft но окончательный переход у них запланирован в 2024 году и на их сайте есть замечательный раздел limitation and issues А в котором есть восемь крупных ограничения для применения в прод то есть кавка пока не рекомендует использовать кафт в проде геон кластер кавка поддержала Гере в упрощенном режиме под названием Что такое федерация это когда запись идт в один локальный дата-центр и в асинхронном режиме специальный процесса зеркаль торы реплицируемый дата-центр нет подтверждения о записи в другие дата-центры и в принципе невозможна поддержка EX и это приводит к тому мто дае ре случилась с ним авария то есть ну кабель с ним перебил что в принципе может быть и вс что туда было записано оно будет недоступно на какое-то неограниченное время например на сутки Ну а в худшем случае оно вообще потеряется а извиняюсь тут Я хочу остановиться ещё немножко подробнее общаясь на конференции Наблюдая за работой других так скажем дружественных крупных организаций встречался как минимум с двумя очень крупными инсталляция кавка но в одном интересном режиме Ну скажу на жаргоне - это растянутая кавка когда берётся топик и партиции этого топика по кругу кладутся на разные дата-центры то есть первая партиции на один дата-центр Второй на второй третья на третий и так они по кругу раскладывают и две очень крупные организации Ну практически там в первой десятке В России говорят что у нас всё работает всё замечательно при этом Я знаком с третьей не менее крупной организацией в которой это не получилось Там зупе не прокачал то есть они не смогли сделать такую растянутую кафку Я бы тут хотел бы предвосхитить возможный вопрос и обратиться к арбитру в виде документации кавка где чёрным по белом написано что такую растянутую кафку делать Можно но мы сильно не рекомендуем потому что каналы между дата-центра они слабые мы не даём уже тех гарантий латентности то есть мы уходим от латентности меньше 10 миллисекунд уходим в латентность там сотни миллисекунд И что самое страшное мы уже кавка уже не даёт те хорошие гарантии отказа устойчивости и катастрофу устойчивости ограниченный exactly по настоящий момент в СДК кавка по умолчанию включена семантика At least Once то есть они гарантируют доставку а борьба с дублями это Most V перекладывается на клиента Вы можете заметить что в кавка появился замечательный флажок не так давно Ну или уже там несколько лет а под названием А enable М potence что этот флажок даёт а он включает Порядковый счётчик сообщений на уровне между СДК и брокером и таким образом брокер может производить дедупликация сообщений то есть Может гарантировать это Most но к сожалению как обычно в каких-то там договорах мелким шрифтом написано что если писатель вдруг рестарт то этот счётчик сбрасывается в ноль и что хотите то и делайте вот Ну вот вот вроде есть Мо а вроде его и нету как с этим бороться опять возвращаясь к примеру двух очень крупных организаций они делают там простое решение в один топик они пишут данные а в другой топик они пишут порядковые номера этих сообщений Но на самом деле решение такое с архитектурной точки зрения довольно-таки спорное потому что ну тут как-то нужно гарантировать атомарность записи в два топика что Ну само по себе Не тривиально ну если чуть-чуть забежать вперёд А в нашем СДК в idb Topic у нас по умолчанию и обязательно включена гарантия доставки exact и ограниченный мониторинг кавка на самом деле обладает очень большими количествами метрик мониторинга дружит с заксом дружит с прометеус там на самом деле всё хорошо Но в кафке нет метрик мониторинга по клиентам то есть по писателям и читателям а там метрики мониторинга заканчиваются на уровне брокеров и либо топиков и Для нас это в принципе не годится при работе в режиме северлес то есть мы не можем просто разделить наших клиентов облаке ито с что в 2017 году наш переезд с кавка на ydb был оправдан потому что даже по настоящий момент времени кавка нас ограничивает возникает Следующий вопрос А почему мы переехали именно на платформу idb хочу опять обратиться к архитектуре и К устройству типичного брокера сообщения например кавка когда кавка получает множество сообщений она Их группирует в пачке присваивает это пач какой-то ключ и кладет файловую систему ну и потом может быть ОТП на другие узлы если внимательно подумать то в данном взаимодействии Нам нужен только интерфейс ключ значения А теперь обратимся к платформе wb в платформе wdb есть замечательны распределённый масштабируемый отказоустойчивый слой хранения поверх которого работает кубик под названием хранили имы сделали элегантное красивое архитектурное решение построили персистентное сообщение в пачке присваиваем ключ отправляем в qv и на этом наша зона ответственности заканчивается то есть оно там надёжно сохранится после того как основной функционал был реализован И решение заработала на объёмах Яндекса Мы вышли в Open Source и параллельно мы начали проводить серию экспериментов по нагрузочному тестированию про которые речь пойдёт дальше в целом нагрузочное тестирование имеет множество целей а Но в данном докладе Я хочу сосредоточиться на первой из них а а именно понять наше место среди аналогов чего мы боялись вдруг мы работаем там в разы медленнее на порядок медленнее А мы об этом в принципе не знаем мы об этом в принципе не знаем И это нужно каким-то образом исправлять первое Когда планируют какое-то нагрузочное тестирование ну нужно составить методику проведения экспериментов и один из первых пунктов методики проведения экспериментов - это стенд на котором мы сравниваем в интернете есть на самом деле большое количество статей по Нару нагрузочному тестированию Кафки и Пульсар но практически все из них построены на обычных виртуальных машинах Даже хуже виртуальных машинах для нас такие сравнения Не репрезентативные потому что мы работаем на довольно-таки мощных серверах которые отличаются в принципе по по своим свойствам от облачных виртуальных машин и Поэтому данное сравнение мы проводили именно на самом типичном сервере который у нас стоит в проде мы составили кластер из восьми таких машин и его сравнивали интересная особенность то что вот в данном кластере стоят ме диски современные и они по скорости быстрее чем сеть в отличие от тех же самых виртуалок то есть мы специально подбираем такие сервера с быстрыми дисками мы замеряем большое количество показателей системные показатели больше важны для понимание узких мест А сравниваем мы именно по прикладным показателям в ходе экспериментов мы используем штатные утилиты имитации нагрузки кавка предоставляет родные утилиты которые для неё хорошо оптимизирует которые предоставляет нужные метрики Пульсар предоставляет и у нас есть правильные утилиты которые могут генерировать нагрузку А так как утилиты немного разные мы выдвигаем базовые требования ко всем сценария например подтверждение записи от всех брокеров должно быть обязательно то есть должно прийти Либо мы пишем без сжатия сообщений Ну либо интересный пункт не должен расти лак чтения то есть в противном случае считается что чтение не успевает за записью то есть эксперимент неудачный и основные сценарии на которых мы сосредоточились они на на самом деле типичны для большинства там существующих сравнений это выявление максимально скорости то есть сколько мы можем прокачать через трубу или нахождение минимального времени то есть сколько времени пройдёт от того как мы сообщение сгенерировать до того как сообщение было получено конечным читателем очевидно может быть для вас но я хочу подчеркнуть что данный сценарий противоречат друг другу Ну например если мы максимизирует глаза на латентность или если мы минимизируем время то соответственно Ну скоростью тоже реч первые результаты по скорости дали нам понять что мы отстаём от аналогов то есть вот кавка например на нашем кластере прокачивает 20 Гигабит в секунду Пульсар 16 а мы всего 13 пристальное изучение показало что мы опираемся во внутреннюю сеть кластера это нас и огорчило ну и дало информацию что именно улучшать Ну и Хочу пару слов сказать почему пульсара отстаёт от кавка яма но догадались потому что у пульсара вынесенный слой хранения а кавка пишет большинство данных локально Вот то есть Пульсар активнее использует сеть кластера Поэтому вот она раньше упирается в порог и первые результаты по времени были тоже неутешительные мы отстаём от аналогов как в режиме без нагрузки то есть очень малень скоро и также нагрузкой причём под нагрузкой даже сильнее отстаём также пристальное изучение показало что мы упираясь избыточное копирование внутри программного кода Ну и на самом деле у wdb там из-за некоторой универсальности платформы есть некоторая любовь к побу Вот и поэтому стерилизация стерилизация побу это тоже замедляет наши узкие места Мы приступили к оптимизация и о нескольких вот архитектурных оптимизация и на уровне программного кода Я хочу вам рассказать первая оптимизация - это всё-таки написать правильный генератор нагрузки у нас в платформе wdb у каждого кубика есть специальный генератор нагрузки для Ke value есть генератор нагрузки для alttp таблиц для alab таблиц и даже для распределённого слоя хранения У нас есть отдельный генератор нагрузки и мы написали генератор для топиков который равномерно с постоянной скоростью нагружает кластер мы перестали упираться в квоты А и получили важные метрики мониторинга чтобы понять что же у нас происходит А по QR коду есть документация по данному генератору а следующее - это архитектурная особенность которую мы это архитектурная оптимизация которую мы применили Давайте посмотрим до на уровне СДК входной точкой для пользователя является прокси который существенно упрощает разработку клиентских СДК так как им необходимо поддерживать всего одно соединение с кластером То есть за прокс может быть тысячи партиции десятки тысяч партиции но СДК устанавливает всего одно соединение Ино нечет зна этих десятках партий заме работает для обычных таблиц когда мы отправляем сравнительно небольшой запрос и получаем Ну какое-то количество строчек результата то есть там нет нагрузки на сеть там нет нагрузки на процессор в части прокси и в части СДК Но это создаёт большую нагрузку для брокера сообщений потому что мы являемся трубой через которую летит трафик и поэтому каждый лишний хоп по сети это тяжело и мы решили это убрать Каким образом после когда СДК обращается к прокси оно спрашивает А где находится интересующая меня партиции из декана говорит партиции находится на том-то узле Иди туда и работай напрямую идк устанавливает отдельное соединение работая напрямую уже с нужной партиции и таким образом мы экономим один хоп по сети одно сетевое соединение что позволяет снизить нагрузку на внутре сеть кластера и заодно мы экономим процессор то есть ну лишнее взаимодействие убрали мы сэкономили процессор следующая оптимизация уже на уровне программного кода мы довольно-таки много времени провели в профайлеры Анализируя флейм графы реальной работы под нагрузкой то есть подавали мощную нагрузку запускали профилировщик на серверах снимали Гра смотрели где находятся жирные столбики подозрительные и разбирались с ними и вот тут есть типичный жирный подозрительный столбик где написано itb serialize если кто-то разглядит под которым находится множество копирования мы идём в программный код смотрим строчка Return и в этом тне есть три конкатенации строки Что приводит к лишним копированием к лишним конструкторам строк к лишним деструктора строк В общем нехорошо и мы применили самую типичную c+ Plus оптимизацию наверняка многие догадались Что надо сделать выделяем память под строку заранее передаём готовую строку в этот метод и просто в эту строку пишем Таким образом мы устраняем лишние копирование и как следствие устраняем столбик на флейм графе и таких столбиков мы устранили как минимум несколько то есть мы сильно сэкономили процессорное время следующее это уже некоторое архитектурные свойство я к нему вернусь ещё раз потому что я про него снова буду говорить А это реже кодирования когда мы пишем на диске мы пишем параллельно на шесть дисков на первые четыре диска пишутся сами данные А на оставшиеся два диска у нас пишется контрольная сумма этих данных это нам позволяет существенно экономить хранимые и передаваемые данные при неизменных гарантиях доступности сравнимых с трёхкратно репликации на самом деле не мы это придумали это довольно-таки известные алгоритмы которые математические Ну и тут мы ускорили на на уровне программного кода а посмотрите Раньше у нас была универсальная реализация Рже кодирования которая работала для любых параметров кодека А и данные обрабатывались в обычном цикле и мы чуть подумали А у нас же по же кодирование работает только в одном режиме блок 42 а давайте зафиксируем эти параметры 4 и 2 параметры кодека и мы викторио алгоритм развернули циклы и те кто глубоко работает с c+ плюсом Ну или вообще с языками программирования догадайтесь Что делает компилятор Когда видит такой вектори зова код он использует векторные sse инструкции процессора которые существенно ускоряет работу приложения Таким образом мы ускорили кодирование и декодирование практически в разы после проведённых оптимизаций мы решили повторить нагрузочное тестирование и результаты нас очень порадовали максимальная скорость у нас увеличилась в два раза и мы превзошли в данном тесте ана вспоминаем масштабы Яндекса то есть сэкономить внутреннюю сеть в два раза это приличная экономия появился и другой сопутствующий результат из-за применения кодирования Некоторые из вас а может быть большинство из вас знает что такое Рен в кафке либо в другом брокере сообщени сумеру сутки если вдруг читатель за ними не прил соответственно большой Рен требует некоторого объёма дисков И если мы зафиксируем ретеншн например сутки у нас есть какие-то конкретные диски которые константы мы можем подавать на кластер некоторую скорость и если мы превысить то что произойдёт диски перепони имы не сможем гарантировать прежний иу порадовали но они на самом деле закономерные кавка может подавать на данный кластер 177 Мб в секунду а мы можем подавать на данный кластер 280 Мб в секунду отличие в полтора раза И если опять вернуться к слайду с масштабами Яндекса экономия в полтора раза на дисках это очень существенная экономия попутно мы настроили регрессионное нагрузочное тестирование мы его запускаем автоматически в кубернетес отгружаем графики в dat Lens и проверяем нет ли каких-то ухудшении и вот наглядный пример что у нас произошло летом то есть был очередной какой-то комит А который нам существенно изменил нашу производительность то есть была деградация по производительность мы это увидели А мы это поправили и даже сделали лучше а как мы об этом узнали То есть к нам в Telegram приходит уведомление чтобы оперативно понимать что производительность упала на самом деле это дорогого стоит то есть Может быть для кого-то это просто примитивно но быть уверенным в очередной момент времени что твой комит ничего тебе не сломал не привёл к деградации это дорогого стоит Итого мы многое получали добились Я считаю что отличных результатов но не ВС мы е сдела мы е не добрались до полного времени до минимизации полного времени Объясню почему учитывая асинхронную передачу информации у нас основной объём Это логии метрики для нас всё-таки в приоритете скорость поэтому мы именно её пока оптимизировали до времени мы чуть не добрались мы сделали ещё не все архитектурные оптимизации по прямому доступу к парти есть е где ускорить Мы более агрессивно будем уплотнять сообще в пач что экономит процессорное время Ну мы будем стараться где возможно избавляться от про табов То есть например в парта був передавать только данные а сами данные передавать отдельно и это Например позволит применить интересны уже другие архитектурные оптимизации вроде Zero copia когда данные снимаются напрямую с сетевой карты и передаются в прикладной процесс минуя операционную систему хочу обязательно Вам ещё рассказать о двух важных свойствах не связанных с с повышением производительности у нас появились две важных функции первое мы понимаем что многие привыкли к кавка и ценим это всё-таки не могу не отрицать что кавка - это Стандарт дефакто в области очередей сообщения и мы добавили кака поверх idb to при этом мы сохранили все архитектурное преимущество платформы wdb и в том числе мы сохранили повышенную производительность и пользователи могут взять любое sdk кавка Java sdk например родной sdk родную утилиту генерации нагрузки и работать с idb topics по протоколу кавка важнейшей особенностью то является то что это доступно в режиме Server L То есть вы можете например взять так называемый тир бесплатный тоненький топик э по протоколу кавка который для вас абсолютно ничего не стоит Но если вдруг вы резко вырастите до 000 партиции с вашей стороны не потребуется Никаких действий то есть внутри платформы wdb всё само собой масштабируется это serverless ну и мы доступны в Open Source То есть можно скачать платформу idb и обратиться к ней по протоколу кака и второе важное свойство которое мы недавно запустили транзакции между токами и таблицами вообще распределённые транзакции - это безумно сложно там целая математика сложнейшая по доказательству того что транзакции являются верными с точки зрения томар согласованности упорядоченности событий но нам Повезло то что в платформе wdb эта сложная задача уже была изначально решена там уже есть транзакции и мы эти транзакции применили к нашим токам и возможен очень Замечательный сценарий когда мы берём большой топик например с 1000 партиции и пишем данные из него в таблицу тоже большую в которой тоже там тысячи партиции а и топики работают на одних серверах таблица работает на других серверах и распределённая транзакция работает поверх этого кластера Итого Мы перешли свка на ydb нас Можно попробовать и в Яндекс и в Open Source мы сильно ускорились Ну и традиционный QR код для голосования за доклад Спасибо за внимание Благодарю за отличный доклад я наконец-то понял почему не кавка маленький презент от организаторов и от спонсоров по подаркам газпромнефти и у уже вопросов сколько у вас ушло на это времени на эту всю конструкцию Ну мы вышли в 2017 году но и планомерно на самом деле несколько лет до этого работали платформа Она появилась гораздо раньше а мы начали переходить на платформу Ну как минимум несколько лет мы переходили А когда вы всё-таки имплементировать кавка а кавка мы имплементировать мы торопились конференции скел которая была этой осенью то есть этим летом то есть столько лет жели без капки как у нас есть другие неменее замечательные вопросы да Александр здравствуйте Спасибо за интересные доклад Вы действительно добились очень хороших показателей результатов мои впечатление после доклада Хочется взять и попробовать но у меня встаёт вопрос насколько вы дороже или дешевле каки в эксплуатации для обычной маленькой процессинговая система Слушайте если вы очень маленькие Вы можете работать абсолютно бесплатно в Облаке И на самом деле если вы типичный интернет-магазин Вы можете работать годами бесплатно в Облаке вопрос друзья насчёт коммерческих историй и прочее сегодня с 1430 до 16 на нте Яндекса инженеры Яндекса и и прочие люди покажут прямо всё изнутри будет демо Приходите смотрите щупать Да суть вопроса считали ли вы стоимость эксплуатации Кафки или еб Ну я могу апеллировать к слайду где у нас был показан один srg инженер то есть одного срг инженера хватает для инсталляции которая обслуживает 300 Гб в секунду на запись Понятно спасибо И у нас следующий вопрос здравствуйте Андрей симун ТС Digital у меня такой чисто программер ский Вопрос вот бывает кес когда нужно сообщения считывать не по одному а пачками то есть по несколько и в кавка это делать ну по факту невозможно то есть нужно какие-то делать свои костыли для этого обрабатывается или нет У нас на самом деле в idb Topic есть СДК под абсолютно разные языки программирования где Согласно той или иной привычной тем или иным привычным сценариям работы в конкретном языке это делается удобно можно читать и по одному можно читать и по несколько вот можно и c+ Plus из жава из питона Можно я добавлю сама по себе проблема заключается в том что у кавка топика несколько партий есть и несколько партиции их разные воркеры обрабатывают и получаются даже если сообщения связаны по смыслу они физически лежат в разных местах и вот не получается их как бы сразу считать разом нет но вы при считывании можете указать либо читаете либо а брокер балансирует сообщения за вас он считывает их со всех партиции по очереди Либо вы можете указать из какой партиции читать резюмируя ту проблемы которую вы озвучили она уже решена поэтому не кавка у нас следующий вопрос и друзья не забывайте голосовать за доклад давать обратную связь Это очень важны организаторам и спикеру добрый день спасибо за настолько академичный доклад это наверное редкость для этой конференции обычна такая хардкорная оптимизация Она приводит к тому что Урае куда-то в желе там в пропускную способность сети там реже в какой-нибудь ТПС на Северном мосту или в шину памяти Вот вы уже во что-то упёрлись или вы будете продолжать дальше стремиться Ну сейчас для нас очередное место в которое мы упёрлись это сеть и процессорное время то есть по сети по сети мы пытаемся ещё немножко пооп но и процессорное врем на самом деле можно оптимизировать бесконечно но три крупных оптимизации мы уже знаем я понимаю вы Яндекс вообще сторонник коммодити железа но не пробовали ли вы уйти куда-нибудь в сторону Нокса сдма А я боюсь У нас нет шансов то есть вот у нас есть некоторое большое количество серверов и они все буквально двух-трёх типов То есть под очереди за сообщение один тип железа под базу данных другой тип железа и всё у нас это планируется на много лет вперёд заказывается мне каже это интерес для дискуссии в кулуарах и у нас следующий вопрос стойте стойте вам сейчас дадут микрофон онлайн трансляция я Извините вы не сталкивались с проблемой иерархии важности сообщений какие-то сообщения там в более приоритетно надо обрабатывать чем другие Ну это вам лучше посмотреть в сторону скса потому что это мы говорим сейчас о потоковых очередях сообщения которые НТИ порядок это важнейшее свойство То есть первый зашёл и ровно в таком же порядке он вышел и у нас последний вопрос да Александр Спасибо большое вопрос чисто потребительский вот я пришёл пользоваться в Яндексе сколько вот в одну очередь я могу рассчитывать на количество там гигабайт в секунду пропускную способность сообщение в секунду Сколько партий я могу сделать там Могу ли 100000 Милн и какая будет задержка типич Ну задержку вроде ответили коллеги на коммерческие вопросы есть стн компании 14 до 16 вам всё расскажут и покажут задержка в простейшем случае меньше десятка миллисекунд в более сложных случаях мы к сожалению пока на сотни миллисекунд К сожалению мы это будем Е ускорять А количество партий в отличие кака мы как бы не опираемся в этот порог 10.000 партиции это было важнейшее важнейшее требование из-за которого мы ушли с кавка Спасибо Удалось ли достигать каких-то количеств партиции или просто не Урае Мы в принципе не упирается И на самом деле у нас не было цели чтобы мы там вот а Работаем или мы на миллионе партиции то есть покам потребителям всего хватает во кто их не успел задать у нас есть зона Куров где можно всегда это сделать И вступить в дискуссию спикером и тут самый интересный вопрос Выбери лучший вопрос Ну меня больше всего заставил задуматься вопрос про там вычитывать пачками не пачками вот я просто начал в голове перебирать возможные варианты То кто спрашивал там про разные СДК Кто спрашивал про раз язка выйдите пожалуйста на сцену Ну ещё раз хочу повторить что с 14:30 до 16:30 Благодарю за отличный вопрос всё спасибо А ро Да извиняюсь ровно на 2 часа а работает стенд idb куда придёт большое количество именно внутренних разработчиков поэтому Если есть каверзные вопросы которыми вы нас хотите помучить мы только 2 часа тут вот большего нам не выделили Приходите 2 дня и всего лишь 2 часа Да и на двадцатом лоде всем спасибо кто Пришли все Спасибо всем кто был с нами в прямом эфире"
}