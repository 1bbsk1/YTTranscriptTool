{
  "video_id": "qXrZjWfDz9k",
  "channel": "HighLoadChannel",
  "title": "Обзор перспективных баз данных для highload / Юрий Насретдинов",
  "views": 7395,
  "duration": 3171,
  "published": "2018-01-16T13:13:19-08:00",
  "text": "так всем привет меня зовут ирина с рединов и я буду рассказывать про так сказать перспективная но еще они очень распространенные базы данных для холода план доклада примерно следующее что я расскажу кто я такой немножко расскажу о том почему я решил выбрать и рассказать именно про эти три базы данных таран толкли хаос и как рощ и пару слов в заключение зовут меня юрий назвали легче с дедушки пока учился в институте написал свою базу данных на печке слава богу забросил это дело потом большая часть своей карьеры работал в команде который занимается инфраструктурой в компании баду и соответственно занимался в том числе решением помогал решение проблем с разными технологиями на продакшене сейчас в основном разрабатываемого зачем я решил искать этот доклад ну в какой-то момент ко мне пришло понимание то что я вот уже десять лет пишу на печке и как-то надо куда-то развиваться и в конце концов на печке все-таки потихонечку люди перестают писать не надо смотреть что есть на рынке и желательно в такой ситуации не оказываться то есть моему мнению стоит смотреть на те технологии которые только зарождаются и быть к нему готовым как по моему мнению стоит подходить к выбору технологии которые могут быть перспективными и которые можно при применять продакшене впоследствии во-первых мое сильное мнение что если вы перед тем как внедрять какую-то систему не понимаете как она устроена и не понимаете какие они сильные и слабые стороны то шансов на успех у вас мало потом часто забывает о том что помимо того чтобы правильно пользоваться фичами какой-то системы ее нужно еще уметь мониторить и бы копить иметь план по тому что делать когда это все сломается потому что обычно под нагрузкой на большом количестве серверов происходит самые маловероятные события и нужно к ним быть готовым поскольку все всем нас что продуктов в принципе невозможно изучить надо иметь какие-то ориентиры то есть как среди всего множества отсеять то что может быть получит распространение но это опять же мое личное мнение например если что-то разработана в крупной компании которую вы знаете которые она там применяется продакшене то скорее всего она хотя бы работает также если вы знаете разработчиков то в конце концов весь его что-то упало вы можете позвонить сказать и парень давай расскажи нам почему это упала помоги на мороз починить если может быть вы даже готовы за это денег заплатить но если вы разработчиков не знаете то у вас такой возможности не будет также я считаю что важно понимать как система устроена внутри это поможет избежать глупых ошибок как при использовании такой при эксплуатации и опять же в холоде обычно это может быть смертельно если вы используете какую-то систему неправильно какие например технологии есть который подходит под такое определение вот например москве получил распространение в тот момент когда у него не было никакого движка транзакций и в общем то он ему особо был не нужен то есть москве очень был очень простой очень быстрый имел понятно и ограничения тоже сам можно сказать про манга debes его движком и map то есть понятно какие у него ограничения что не не стоит хранить ним супер критичные данные но он при этом быстро работает или вот вам cacilie кто помнит free газ до 4 операционную систему она была очень такая простая и приятная стабильная то есть все все эти технологии объединяют то что они работают сразу не требует никаких существенных настроек может быть даже работают на вашей операционной системе это винда или макось например и что с ними нету явных проблем с надежностью то есть что хотя бы во время тестирования у вас система не падает и выдерживает ту нагрузку которую вы на нее даете или поскольку архитектура понятно то непонятные трейдов и то есть как я сказал например у моей самой и у манга тебе ровно те же самые проблемы то что они работают быстро на определенной нагрузки но могут терять данные и соответственно в некоторых условиях вам использовать их не стоит а вот углом к шоу free bsd вообще недостатков нет мне кажется ну и давайте перейдем к первой базе данных который пойдет речь от тарантул скажите пожалуйста кто слышал про тарантул я удивлен что не все хорошо кто использует продакшне вот собственно я надеюсь что после моего доклада вы хотят подумайте о том что можно было продакшн и выпустить давайте рассмотрим такую ситуацию у нас есть большой проект у вас там сотни веб-серверов и сотня ну допустим мускуле хотя в общем-то базу данных не очень важно и они как-то по шарлин это есть часть пользователь живет на одном сервер часть на другом и допустим они по шарден и по юзер айди самое логичное и нужно залогиниться пользователя то есть он приходит со своим емейлом и паролем нажимай кнопку логин и вопрос на какой сервер эти непонятно но вы скажете юрий ну что тут же все все очевидно надо поимел page or die тогда можно будет найти ведь но люди еще приходится номером телефон иногда и такой трюк не сработает поэтому надо где-то хранить соответствие между в традиционными данными пользователя и тему где он живет на каком сервере для этого ну условно паттерн какой-то авто райзер можно использовать когда у вас есть единая база данных который все это хранит который быстро обслуживают запросы а вот потому что она обслуживает естественно трафик для всех этих масках серверов и направляет на них да все это можно сделать например с помощью модификациям мкш то есть в баду первые реализации но так и работала то есть брался memcache в него добавились добавили поддержку вторичных индексов репликации и в общем то все работало но есть одна проблема если вы хотите добавить например новые индексы или же поменять логика работы то поскольку это у вас модифицированным кое-что вам нужно его рио стартовать а когда вы стартуете у него все данные исчезают и соответственно вы получаете downtime естественно это проблем можно обойти но это достаточно трудоемко в поддержке решения особых альтернатив все равно нет потому что ну кроме сша в тот момент по крайней мере ничего с достаточной производительности не работал то есть что еще можно исправить кроме сша например можно использовать маски или хэндлер соки это решение наверное неплохое и более того в баду она используется но у него есть один не осадок то что в новых версиях москаль хана versace больше не поддерживается там поддерживают протокол моим каша но все равно то есть это некоторые есть минусы у этого подхода если вы использовали редиску наверно знаете что вторичных индексов не у меня то есть решить эту задачу норе 10 в принципе можно но тоже вам придется попотеть если вы работаете в банке то наверное вам подойдет уроков хотя не знаю наверное нет или вот есть еще странное решение вроде за кипера который вообще для другого на самом деле то есть получать что особо альтернатив ты нет я думаю то что в моем роду были примерно так же и сделали по сути некоторый аналог persistent на вам кэша но в котором можно делать в котором можно писать свою логику на зло то есть тарантул in memory но при этом данные хранить на диске позволяет обрабатывать до миллиона запросов в секунду на одно ядро не верите моим словам побыть маркете сами делать это за счет конвейерной структуры ну вот как я говорил лично для меня хорошим знаком является то что я знаю некоторых людей которые разрабатывали то есть один из разработчиков москве скорее всего все будет хорошо как с высоты птичьего полета устроен тарантул вот как я говорил у нас есть сотни клиентов или там даже 1000 клиентов которые ходят в 1-м стенд и в классической архитектуре на каждый запрос вы например делаете то создайте отдельный трек или как не быть похожим образом обрабатывать запросы не используете кучу new кексов в тарантул я сделана немножко по другому там есть буквально там несколько отрядов не все из них показаны на слайде и например один thread принимает запросы от пользователей накапливает их в 1 очередь потом раз какое-то время скидывает это в очередь другого то это который занимается уже исполнением поступивших запросов записью этого в рэпе hotlog и потом передает сообщение обратно тоже большой пачкой все все эти thread'ы при этом работают по сути в один поток и не держит особо meetings of никаких за счет этого получается как искала конвейерной архитектура за счет этого получается избавиться почти от всех меню кексов и на порядок увеличить производительность работы в таком режиме потом очень интересно сделано и снапшоты в tarantul и это относится вот эта диаграмма как оказалось относится к версии не больше чем 167 и идея состоит в следующем то что например в отличие от редиса утром то вся память разбито на два региона 1 1 самая большая область это блажь аленой памяти и вся остальная память которая здесь отмечены зелененьким как правит и для того чтобы сделать snapshot родитель как бы замораживают изменением жареной памяти for каяться и child пишет snapshot в отдельный файл выходит а потом соответственно качают вышел изменения в шаре на память могут дальше продолжать идти как обычно для чего это сделано сделано это потому что на больших объемах оперативной памяти по крайней мере в линуксе хотя вообще-то справедливо любой unix подобный операционная система форекс занимает приличное время несмотря на то что все страницы не копируются а просто помечаются как copyright если посчитать сколько 4 килобайта страниц будет на 100 гигабайт резидентной памяти можно догадаться почему даже просто сам факт того что они помечаются как опиум нравится занимает секунды и соответственно если так если делать по-другому использовать общую память то она естественно как копи он рад не помечается иначе на работа не будет и таким образом обеспечивается намного меньше паузы при создании snapshot а но даже это создатели тарантула не устраивало в конце концов они сделали снапшоты на основе собственной трансляции адресов под названием матрас и в принципе схема более-менее аналогичные то есть просто делается с snapshot памяти и в отдельном тради она сбрасывается на диск соответственно при каких условиях стоит использовать тарантул но то есть как я сказал в него конвейерной архитектура то есть ловит нас сегодня будет не очень маленький то есть это будут миллисекунды но зато она может обрабатывать огромное количество клиентов и маленькие запросы если вам нужно соответственно централизованное хранилище в котором хочется поддерживать уникальный индекс это вот это как раз идеальное применение тарантула но и также таранто поддерживать ло процедура то есть вы можете вместо того чтобы делать непосредственно запросах в таранто вы можете написать процедуру которая что-нибудь там шустренько на считает и выдаст вам результат это будет февральских памяти и вот примеры применения этого тот же самый страйвер которая сказал можно например спокоен там сессии пользователей хранить счетчики посещений и такие вещи которые кажутся что для полноценного заданных не подходит но есть минусы вот если вам нужны цель автоматически sharding синхронная репликация с помощью рафта или paxus а или хочется иметь длинные транзакции я бы не рекомендовал использовать тарантул хотя авторы на самом деле во всех этих направлениях работают то есть пока что она просто не готова к production принципе авторы тоже не заявляет что она готова дальше если у вас буквально пара клиентов и вам нужно с минимальной задержкой получает данные то тарантул тоже для этого не годится потому что ну как я сказал другой модели работы рассчитан если рабочий набор не не влезает память-то на самом деле uttaran то есть движок винил но он тоже в разработке и соответственно пока что он для production не годится но если вы вдруг вздумали считать аналитику на таран туле смотрите следующий слайд есть другая база данных от известной вам компанией названием cliff house кликал создался создался индексом для задач яндекс метрики и соответственно нужно делать аналитику в режиме реального времени для всего интернета и хотелось бы естественно не платить за это бешеные деньги и вот на тот момент когда создавался коли хаусу что только можно было любые два выбрать из этих критериев что эффективно линейны масштабируем и в реал тайме и упал собственное любые два но не но не три сразу что соответственно можно было выбрать например москаль самом кажется вообще дубовый вариант но подождите потом верте к или за стол и прочие они платные для больших объемов ходу по крайней мере на тот момент никакого real-time а даже речи не шло и как мне странным индекс выбрал самое такое простое решение которое вероятно не просто очень хорошо умеет готовить просто за счет того что моя сам позволяет быстро данные вставлять а уж там на фоне пересортировать как-нибудь чтобы чтение сделать побыстрее но понятно что это решение не очень хорошо для аналитики подходит поэтому решили написать свое сделали ее сразу распределенный очевидно потому что в них уже сейчас четыре сотни серверов службы работают в кластере для яндекс метрики или даже больше не знаю соответственно если база не распределён ответ конечно смешно и обычно в таких задачах таблицы очень широкий то есть содержит очень большое количество колонок поэтому логично хранить их по колонкам потому что в запросах как правило требуется буквально несколько штук ну и с ездой до сих пор в пересчете стоимости хранения на один гигабайт намного дороже чем жесткие диски вот но и понятно что я мог сделать для себя они хотели сделать чтобы она максимально быстро работала при этом ну и да оно протестировано в продакшн и яндекса как оно устроено вот предположим у нас есть широкая таблица которая содержит в себе данные по авиаперелетом за 60 лет я честно украл этот пример и статья на хабре потому что мне было лень придумывать какой-то другой пример что он хорошо иллюстрирует задачу значит все данные хранятся в partition партиции я не знаю настраивал менее сейчас или нет но вот на момент выпуска partition представляли данные за один месяц то есть это как бы такой блок данных в которых по одному файлу на колонку и все данные внутри отсортированы в порядке возрастания первичного ключа и вы наверно посмотреть на диаграмму скажите юрий но не держит середину вставить данные да вы будете правы но об этом чуть позже также для того чтобы ускорить поиск чтобы не делать бинарный поиск а все-таки для выполнения запроса сразу же перейти в к нужной позиции есть еще так называемые файлы с засечками где каждой м записей которые задаются при создании таблицы вот эти вот 8906 каждой он записи делается отметка о том какое значение первичного ключа я и какое смещение в файле этому соответствует это позволяет соответственно выполнить вот например такой запрос очень быстро то есть двумя последовательными чтениями с диска для того чтобы осуществлять запись понятно что вот сортированный файла записать нельзя в середину по крайней мере на существующих технологиях и когда происходит запись одного блока данных который желательно должен быть быть желательно должен быть побольше данные сразу сортируются в порядке возрастания первичного ключа и записываются отдельным блоком на диске и потом фоне держится и превращаются в в итоге в конечный результат ну я думаю эта схема понятно каждому и это в общем то описание того как олехаус хранить данные что позволяет он с этими данными делать он поддержку цель join и весьма ограничены но поддерживает тоже до в кластере тоже умеет работать естественно я не знаю откуда я взяла не нашел подтверждение тому что в интернете тому что у них 17 алгоритмов выполнения грубая просто где то это слышу может быть уже даже больше то есть она оптимизирована для выполнения именно таких сложных аналитических запросов и большинство запросов выполняет очень быстро ну и также поддерживает некоторые другие вещи самое интересно наверное за тут и сэмплирование то есть предполагается хранить сырые данные и если вам нужно построить какой график за большой период вы просто делаете запрос который центрируют данные ими позволяет потом приблизить и увидеть полностью в деталях все поддерживаться только in стерты хотя принципиальных ограничений для того чтобы добавить деле ты и апдейты наверное нет но авторы решили не заморачиваться с этим особо и тоже существенное ограничение то что нельзя за джони две огромные таблицы которые не помещаются в память то есть промежуточные результаты для join a должны вылезать память иначе клиф хаус просто откажется запрос выполнять в принципе в похожих системах на самом деле ограничения при на такие же или же она работа с чудовищной производительности то есть все она даже если вы используете hadoop стоит задумываться о том чтобы join и делать с маленькими таблицами 0 до нету еще полноценных транзакций никаких и нужно вручную класть так полу ручном режиме управлять кластером но это в общем-то не очень сложно когда предполагается использовать ли house на самом деле здесь все очень маленький список представлен причина для этого очень простая то что cly house обладает производительность на несколько раз быстрее чем все даже платные решения а если например сравнивать муж клинтон там в 100 раз быстрее и сценарий для использования можете придумать сами то есть просто благодаря тому что индекс смысле то что cly house храним данные очень компактна и работает очень быстро его можно использовать для не только для задача налички но и например для хранения логов или для того чтобы например к врачу прогонов тестов собирать потому что обычно это огромный объем информации с одной стороны и с другой стороны бывает полезно по нему делать какие-то выборки да так же они добавили движок для графита под названием графа us и соответственно можно и time series данные накликал сохранить хотя это не прям самый эффективный способ когда не стоит использовать но очевидно то что поскольку в кли хаусе нету ни апдейтов не далитов не транзакции leap лтп нагрузка не годится я бы я считаю не являюсь репрезентативная аудитории но все равно что с деньгами на при работа не стоит потому что увлекался асинхронной репликации стопроцентную гарантию сохранности данных он не предоставляет ну про хранение только агрегатов и лима придется я думаю понятно а вот про полнотекстовый поиск хотел бы сказать то что вообще я написал на хабр статью как сделать полнотекстовый поиск на основе клик хауса вот ну так делать не надо то есть это как бы в качестве просто эксперимента есть намного более хорошее решение для этого но и давайте поговорим про последнюю но не про последнюю по порядку но не по важности базу данных под названием как рожь тебе кто из вас слышал про как роуч тебе кстати я ожидал что меньше будет людей хорошо кто использует как работе с биби в продакшене никого автор алина делаете а значит какие предпосылки были для как roach д.б. но предположим у нас есть социальная сеть или какой другой большой сайт и у нас есть сотни веб-серверов сотни мускуле я не по шарден и по юзерам каким-то образом или по другим критериям и нам нужно залогиниться пользователя по email что делать ну что вы не сказали что можно пошарить по емейл вместо и среди давайте усложним задачу нужно еще и по номеру телефона непонятно как решать эту задачу но давайте представим что веб-серверу смысл то что сервер баз данных у нас один как бы мы это задачу решили в таком случае нам создали таблицу назвали бы и users у нее был бы первичный ключ айди пользователя и имела телефон с уникальным индексом потому что если требование уникальности не нужно то у вас очень странное соцсеть прямо скажем и соответственно для того чтобы залогиньтесь пользователя мы делаем 2 запросов в базу по емейлу и по номеру телефона да но можно ли так сделать есть нюансы из окон собственных решений вообще никаких готовых инструментов для того чтобы можно было так вот не особо нечем задумываясь сделать таких решений не было спустя некоторое время то есть буквально несколько месяцев назад google разрешил использовать свою базу данных spanner которая как раз и позволяет сделать что то похожее то есть сквере интерфейс к распределенной базе данных и можно естественно сделать вот по такой схеме софта райзера или же вот если вы скажете манга гибели кассандра есть один недостаток этой схемы не манга деби не кассандра не поддержит уникальные индекса в пределах кластера то есть например манга' тебе поддерживают уникальные индексы если вы индексируется ключ хардинга но если вы хотите просто произвольное поле то такое не поддерживаются может быть у кого-то есть свой вариант как можно такую задачу решить меня таких неизвестно как соответственно что есть а представили как roach вообще изначально это кивали сторож распределенные авторы решили сделать авт авторы собственно google spanner и собрались решили сделать распыленные кивали сторож с транзакциями все дела но без киеве потом где-то на середине пути поняли что на самом деле просто киева или сторож это прошлый век и надо сделать все таки сколь полноценный и вот 10 мая еще до того как я начал готовить после того вернее когда я начал готовить эту презентацию вышла версия 1 0 то есть можно использовать продакшене спокойно никаких проблем у вас не будет это шутка если что вот он поддерживает склеили join и распыленные транзакции и сид семантику и в том числе уникальные индексы на кластере и вот сама балансируется и распыляет нагрузку то есть вроде идеально базы данных как и сказал создан авторами спайнер а написан на год по моему одна из очень немногих баз данных которые прошел тестирование джексон с минимальными оговорками и как оказалось использовав пойдут на продакшн не в буду в байду то есть именно в китайском поисковике я бы честно говоря на месте этих ребят побоялся но видимо они ребята смелые вот и он использует ровд и рокс тебе то есть не придумывает свой формат хранения до того как будут понятны все недостатки и это мне кажется очень правильно так делать как соответственно как и сказал то что это база данных киева илью но поддерживающий sql и в этом нет противоречия то есть например если мы создаем таблицу и вставляем записи в эту таблицу то эти записи можно представить в виде наборы ключей например мы назовем ключи следующим образом имя таблицы slash значение первичного ключа совершенное поля и значение и это вот в таком первом приближении то как хранить данные как roach если хочется иметь еще и вторичный индекс эту схему немножко усложняется мы помимо значения индекса будем кормить еще и имя индекса и мы получаем вот такую вот структуру вы наверно смотрите на это и говорите юрий ну как же так это же огромное накладные расходы на хранение имен ключей но на самом деле рокс baby поддерживают так называемые префикс на и сжатие то есть повторяющиеся префиксы будут максимально сжато и занимать место это будет не так уж и много когда конечно overhead есть вот и можно видеть то что префикс у яндекса другой то есть впоследствии будет видно то что этот индекс может попасть на другой шар как осуществляется шарди рование поскольку это киева или база то можно сделать следующим образом мы берем сортируем все ключи и разбиваем их на фрагменты по 64 мегабайта ну примерно 64 мегабайта плюс-минус лапоть и раскидываем эти фрагменты на сервера желательно раскидывать естественно максимально равномерно и у каждой тройки то есть каждый каждый range по умолчанию реплицируется три раза у каждой тройки есть ровд лидер который принимает чтение и запись и соответственно когда приходит запрос как рожь тебе сам разбирается на каком шарди это эти данные лежат и соответственно читает данные дает вам результат если соответственно какой-то кусочек начинает верни так перестает умещаться в 64 мегабайта то этот кусочек разделяются на две части и одна из частей уезжают на другие сервера соответственно если одна из машин выходит из строя то с помощью рафта происходит перевыборы и какая-то другая машина становится лидером соответствующего фрагмента и это происходит в течение сотен миллисекунд наверное несколько секунд максимум что можно ожидать при выпадении машины также к короче тебе поддержит распределенной транзакции на самом деле для того чтобы сделать поддержку уникальных индексов пределах кластера нужны распределенной транзакции как это работает я естественно можно пройти весь доклад прочитать как сделать но я постараюсь вкратце рассказать то есть есть системная таблица со списком транзакции и это таблица точно так же хранится в кластере то есть не находится ни на какой из машин а точно также распределена по всему диапазону ключей когда в транзакции модифицируются какие ключи рядышком кладется ключ с номером транзакции это кстати упрощенные схемы если что рядом кладется ключ с номером транзакции в которой этот ключ менялся и если при чтении обнаруживается что рядом есть такой ключ то идет и смотрится с список транзакции за комично транзакции или нет и соответственно последним этапом при нормальном завершении транзакции транзакция в этом списке которые находятся на одной машине конкретный она переходит в состояние за комичен и соответственно все изменения которые сделаны в транзакции начинают быть видны а там 1 то есть это транзакция но и потом вот эти вот лишнее ключи отдельного сборщиком мусора удаляются когда использует к короче тебе ну правильный ответ подождать немножко и вот когда точно будет понятно что она хорошо работает в продакшене вообще говоря можно использовать вместо базы данных которые вы используете сейчас если у вас условное соцсети то есть обычно в таких больших сетях нагрузка на каждый сервер не очень высокая но зато нужно иметь очень много серверов и данные естественно совсем не помещается в память когда не стоит использовать как видите список намного длиннее во-первых поскольку это распределенная консистентная база данных то производительность как в плане пропускной способности так и в плане лэйтон все оставляет желать лучшего также если вам не нужны и распределенные транзакции то скорее всего вы просто не понимаете что это задачу можно решить с помощью распыленных транзакций но все на если о нем совсем не нужны то конечно как врач вам не пригодится ну или же если вы любите написать половину логики в базе только кровь пока что этого не поддержит кстати говоря они совместимы по протоколу спас gresso мы стараются делать вещи который пуска рискуешь поддерживать так что все возможно может быть это и появится в будущем итак давайте подведем итоги насчет какие есть плюсы у тарантула он обладает совершенно чудовищные производительностью смысле хороший а не плохой но вот в данный момент у них нет асинхронной репликации работает каждый instance таранто на только на одном ядре но в принципе этого достаточно и опять же в данный момент есть только один движок пригодна для использования в продакшене он охранник данный в память но при этом они остаются и на диске тоже но они должны помещаться в память целиком и sharding если вам нужен то нужно его делать руками над этим тоже авторы работают но пока что этого нет про cliff house сделан он таким образом что сам параллели запросы в принципе это не очень уникальная фича для аналитических баз данных и у него совершенно нечеловеческая пропускная способность то есть совершенно спокойно заливается порядка 100 мегабайт в секунду в пик aus на сервер и при выполнении запросов он сканирует порядка миллиарда строк за секунду такой производительности ни у кого нет но не все бесплатно у него естественно нету полноценных транзакций джайнов и к сожалению нормально управления кластером но это все разработчиками нет не все конечно по транзакции вряд ли они добавят но например управления кластером сколько я знаю разработчики стараются улучшить ну и как тебе вообще идеальная база данных если вам не нужна супер высокую производительность зачастую нам не нужно потому что большинство данных в таких колод проектах это горячее данные они все находятся в кэше причем вы сами же их туда и кладете поэтому в основном нужно нагрузка на запись и как раз нужно уметь консистентные данные записать потому что чинить к системность намного сложнее чем чинить проблемы с производительностью но версия 1 0 только что вышла уже работают разработчики конверсия 11 и вот на какую производительность можно рассчитывать это порядка 1 тысяча заброс в секунду на одну но да вот на теперь вы узнали про три новые базы данных надеюсь узнали правду как применять может быть даже я вас убедил что можно попробовать хотя бы на них посмотреть не обязательно в продакшен пускает сразу вот и вообще не не слушайте что я говорю не принимайте на веру подумайте сами если у вас условия под которым база подходит и готовы ли вы смириться с их недостатками и соответственно проектировать систему с их учетом потому что production дело серьезное опускать туда всякую фигню не хочется но с другой стороны стоят на месте тоже вот спасибо я готов ответить на ваши вопросы так как как тут с вопросами и опять губы вопрос а почему для задачи хранения там по сотни миллионов пользователей по двум причем не хватает банально вопрос алиса причем здесь все под крис в чем у вас ну то есть там какой-нибудь частник едва индексы отдельный после стоящие все но этот ин сон спускаешься должно обслуживаться там сотни тысяч запросов в секунду вас тогда нету нету консистенции нормальный ну то есть как бы смысл из прогресс если есть тарантул который на одной ноте я прокручу понимаю почему как как роде он даст выигрыш ну то есть у вас пользователи тогда будут таблица пользователи будут жить на одной ноги а данные пользователя на другой и вам нужно как-то их синхронизировать между собой это нетривиальная задача бывает иногда то есть зачем об этом думать можно взять базу данных которые позволяют транзакции обновить ее данные пользователя и если вы хотите всех там 350 миллионов пользователей запихать на один сервер вай нот но мне кажется что попробуйте то есть по крайней в бодун он там конечно не под grease там с кем-то там вообще говорят 400 москаль серверов когда вас нужно иметь там сколько там под миллиард записей на меньшем он просто не нужен ну да естественно как рожь тебе нужен для случая когда вы делать такой проект в котором все данные в принципе на один сервер не влезают если они вылезают то стоит используем другое но вы никогда не знаете может быть у вас они перестанут лизать а вот делить базу данных на две части и той же ну 1 спасибо большое за доклад рога такой небольшой вопрос как roach обеспечивая такую вот крутую watenshi данных до точность и не повторяемость записью у нее как что вы имеете в виду новый год запись там 1 кило запросов я так понимаю точки нее нету то смешанная нагрузка рождение по идее вам из как roach ну то есть вообще принципе с базы данных нужно относительно редко потому что вы кладете это даны только насколько я знаю насколько я пробовал у нее сейчас в данный момент после релиза записью что-то очень печально там порядка по моему около 100 записей не важно сколько строк в секунду тоже пишет неважно сколько строк выставляете на учета порядка там столь записи в секунд смотрите тут даже вот почему я говорил про архитектуру что если вы делаете большие запросы то они скорее всего пойдут эту запись пойдет на множество not одновременно вы получите плохую производительность из-за этого потому что ну каждая транзакция становится распределённой сразу же она трогает большое количество постов до нужно синхронизировать их между собой то есть как бы намного более логичным было бы вставлять по чуть-чуть потому что она тогда ну то есть опять же зависит от того какой у вас первичный ключ то есть по идее вот в такой вот схеме когда у вас есть первичный ключ и значение первичного ключа должны быть рядом если они не рядом то это пойдет на несколько серверов это нужно если также соответственно вы скорее всего получите намного лучшую производительность если вы ну так ничего не бывает бесплатно это вообще распределенной системы обычного очень сложно и нужно понимать как ими пользоваться для того чтобы достичь максимального его просто неспособности но эта версия 1 0 перед добрый день добрый день доплат очень интересно у меня вот такое просто вначале был что ему нужно уделять внимание при выборе база да там рассмотрели какие то есть нужно понимать как она работает нужно дальше уделять внимание сильные и слабые места все отлично это все просмотрена было с мониторингом бэкапом и что делать когда суд упадет в этих трех решения что делать с этими тремя решениями смотрите вы знаете как она устроена я надеюсь теперь хотя бы имеете некоторое представление например что тарантул пишет снапшоты и райта hotlog вам нужно например если вы хотите его забэкапить то вы берете snapshot который уже закончил запись это просто файл и их пишите его куда-нибудь к себе там быстрее или куда-нибудь вот ваш backup мониторинг это вещь такая весьма интересная то есть я насколько знаю о тарантула прямо совсем встроенных механизмов мониторинга нет но вы можете например мониторить хотя бы потребление циpкa и потребление памяти если она начинает приближаться к ста процентам от тарантул однопоточный то вот вам стоит посмотреть что происходит это хорошо там просто с бака по мне так мы говорим про пульте узловые системы управляет ли все эти три решения обеспечивает его снять для того чтобы снять бкп стран то вам нужно бы копить каждый instance отдельно для того чтобы забыть об этих ли house я-я не знаю я думаю что его бы копить не стоит потому что у вас данные в единственном экземпляре скорее всего с трудом помещается а он пишет просто такими вот последовательными кусками до такими вот потерять данные в таком случае очень тяжело у него даже далитов нет но если уж пытаться все-таки сделать бэкап и для cliff house я бы делом персонаж шо ты просто файловой системы раз какое то время но скорее всего у вас бэкапы никуда не влезут откликался к сожалению а что касается короче кстати говоря это хороший вопрос у них есть две версии комьюнити enterprise и вот как раз отличаются они тем как сделаны бэкапы в коменте версии бэкапы делается в один поток в enterprise они могут делать накласть и соответственно пока вы маленькие вы можете накопить 1 какое-то время просто делайте select из базы и получаете консистентные состояние всего кластер и потом когда вы уже выросли если вы в это слита вы можете себе позволить enterprise версию такого них бизнес-модель мне кажется неплохая ну а что касается мониторинга насколько я знаю как роуча нету такого как например мускуле что можно посмотреть список запросов которые сейчас исполняются ну а не по уму над этим работы поэтому вот это одна из причин почему вот версия 1 0 обычно плохо пользоваться но в целом мониторинг будет кстати у них есть веб-консоль админской который собирается очень большое количество разных метрик например ловит он все запросов средние время исполнения там количество запросов нагрузкой цпу потребление памяти и так далее и я вот не знаю можно ли эти метрики забирать как-нибудь скорее всего можно и соответственно их надо забирать и куда-нибудь запихивать и мониторить это все да я же не зря сказал что это перспективная база данных как бы именно опыт эксплуатации продакшене обычно только в продакшене появляется спасибо за доклад собственно продолжить предыдущие вопросы про не понимаю что в текущем варианте как роуч можно запить это кстати очень хороший вопрос на самом деле конечно же я рассказал не все как рожь baby хранит данные за последние 24 часа по умолчанию и вы можете сделать select с of time и получить консистентной snapshot всего в какой то момент времени так все здравствуйте нет так спасибо за доклад у меня под клик house вопрос показывали схему как происходит вставка данных если в этот момент пока там это фоне идет объединение этих пар тишина запросить данные как он будет это все объединять так скажем во время мир дженга который естественно происходит постоянно на продакшен системе select делая но чтение делается с тех пор тиц то есть он выборку сразу всех вы до 0 и всех нужных партиций естественно а при этом время здесь на увеличивается до такого как правило вот эти вот не дамер жены и кусочки они горячие то есть вы их только что записали они все еще в кэше файлы системы и она ну конечно на какое-то влияние оказывает то есть и совсем мы кстати говоря вот но я это упоминал и совсем мелкие бачу писать the cliff house начинает реально деградировать по производительность а еще раз по поводу выборки данных то есть мы когда использовали ну пробовали так скажем эту базу столкнулись тем что выбирать единичной записи довольно таки проблематично бульон торт их случайным образом выплевывают какие записи ну допустим мы хотели выбрать там какую-то единичную запись не по индексов по кому-то условия но он как-то низ иногда не попадал не попадал помните данные возвращал ну это вам нужно в багтрекер гитхабе очевидно хорошо ладно спасибо то есть конечно такого не должно происходить ладно спасибо так вот кто задал вопрос про к системе book по вам сейчас выдадут что-то давайте еще вопрос мой поднос время есть какую файловую систему отпал дайте баз данных посоветуйте я так понимаю потому что допустим как роуч используется четыре мегабайт до логично что никсон работать немного лучше какой файл я система я думаю что это не принципиально то есть но как правило для баз данных file system мало ли это нормально но я не могу вам сказать вот сразу xfs вам нужно использовать или там xt2 может быть то есть принципе они же сами журнал все пишут урок с дубинками и и которого что же может быть вам вообще журнале мфс не нужно то есть это такой вопрос интересный но как правило на база данных file system влияет слабо песни были хорошо сами диском работы"
}