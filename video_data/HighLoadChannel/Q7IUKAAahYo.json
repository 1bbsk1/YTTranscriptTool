{
  "video_id": "Q7IUKAAahYo",
  "channel": "HighLoadChannel",
  "title": "Авито: root cause detector / Юрий Дзюбан (Авито)",
  "views": 664,
  "duration": 2248,
  "published": "2023-01-19T05:55:16-08:00",
  "text": "всем привет меня зовут юрий я работаю в компании авито и сегодня я расскажу вам про рацию отказ анализа разбоев и дотации чтобы лучше понимать что-то корпус анализ давайте представим ситуацию с которой все из вас наверняка сталкивались представим себе что вы отвечаете за какой-то сервис в котором подошел прямо сейчас сбои есть некоторые показатели которые играют оптическим для нашего сервиса и они выглядят неправильно очень хорошо если сразу видно причина того почему подошла деградация но так бывает не сюда поэтому иногда приходится открывать науку и начать разбираться когда вы начинаете разбирается вы можете выделить три основных направлений у которых нужно дарить причиной деградации может быть на стороне вашего сервиса также причина может быть в на стороне некоторого другого сервиса который за вниз с вашим и наконец причина может быть на стороне инфраструктура но каждое из этих направлений у нас довольно широк а когда вы рассматриваете конкретные кейсы ну их много на самом деле конкретно сценариев примерка каждого из них занимает некоторое время ну и вы начинаете это делать но вспомним про то что у нас ударит прочь и хочется найти причину как можно быстрее выдавать ипотеку мягких условиях инженеры начинает искать проблему одной рукой он смотрит метрики договора кроме смотрит логе так как инженер не всегда может проверить самостоятельно все свои гипотезы то он должен относить обратиться к сотрудникам смежных команд для того чтобы они ему помогли поэтому а третье рукой инженер начинает писать смертных чатиках другим людям и всех дергать хотя возможно сценариев очень много на самом деле они все неплохо автоматизируются собственно что это значит что мы знаем куда с примерно смотреть и какие значения нас устраивают они являются нормальными от изучения говорят про сбор но раз мы можем это автоматизировать значит это нужно автоматизировать и сегодня мы про это поговорим прежде чего начать погружаться в это дело я хочу уточнить одну вещь мы тут не говорим про то как должны уделить ей таких инструментов мы также не говорим про сервис который компания vita сделала и выложил open source или хочет продавать мы говорим про общие практике подходы которые в этой задаче применимы и так давайте определимся какую задачу должен решать версии rtos analysis он должен автоматически проверять какой-то список сценариев и по каждому из сценариев вынести вердикт тут все ок или тут всё не об таким образом он исключает те направления которых все хорошо и показывает возможное направление которое требует дальнейшего исследования которые скорее всего являются арт козам наши проблемы я выделил основные направления в которых нам нужно смотреть первая группа направлении 1 2 это савчак они относятся к самому сервисом во первых это некоторые сущности которые некоторые факты самого сервиса например логе например метрики или просто вы события центре которой относится к ошибкам ну и во вторых релизы что она делаем с обрезами мы сопоставляем временные окна то есть когда произошел релиз и когда пришла деградация это само по себе не является стопроцентным индикатором того что именно релиз был причиной сбоя потому что после не означают следствие но это хорошая возможная причина деградация вторая группа это зависимости что такое зависимости во первых это сервис и провайдера и сервиса консилера провайдера это тем сервиса которыми ваш халида данными акан серы и наоборот это тестируется которые ходят в ваш заданными кроме того зависимостями бывают базы данных которые взялись обладают кэш очереди и прочих точности ну и наконец третья группа это платформа платформы можно вынести оборудование железное оборудование а также кластеров обернитесь сеять dns и прочие сущности вот так мы разделили у себя эти направления вы видите что есть слс он проиграть все салфетки то есть и троицы и логин и релиза на запад в органы и проверки отвечают платформе hardware и запреты зависимостью отличают сторож провайдер со консьюмер это только примерное разделение она условно вы можете просто по-другому разделить кроме того бывают ситуации когда мы проверяем смежные сервис-провайдер сулит провайдер контейнер и мы выясняем что с ним в нем тоже проблемы раз мы это выяснили то имеет смысл построить так называемый рекурсивный отсчет то есть построить отчет уже по зависимому сервису это имеет делать с контролем глубина рекурсию смесь смысл делать контроль глубины рекурсия потому что иначе можно найти очень глубоко и прийти к тому что мы при каждой проверке одного сервиса будем каскадно проверять все сороса компании но это нежелательно сценарий поэтому глубину столь контролировать прежде чем ну помимо того что мы хотим понять что сервис делают нужно также понимать всего сервис не делают этот сервис перси детектор не является хорошей кран он не говорит каждый секунд времени что с этим сервисом все хорошо или все плохо он нужен для того чтобы расследовать причины деградации и так всего начинается сервиса само собой мы можем сбросить анализ вручную когда нам платил хочется ну когда вы так хочется когда мы узнали о том что в сервисе резьбой а само собой мы можем это запустить вручную но скорее всего мы узнали об этой злой и за лифтинга а dirting это такая система в которой мы прописываем некоторые метрики сервисе а также значение при которых мы считаем что все же солнце хорошо или все плохо то есть алевтину в любой момент времени знает когда сервиса становится плохо раз он это знает и раз мы говорим про автоматизацию иметь смысл а лифтинг научить чтобы он вызывал такие анализы автоматически конкретном и авито используем в качество лифтинга майору но разумеется это функциональность можно сделать рабом другой stephen king самоанализ происходит довольно быстро потому что мы рассмотрим разных сценарий параллельно в качестве визуализации можно использовать граф наподобие того что на слайде я тут очень мелкий текст но этот и графа он больше про визуализацию самого процесса визуализации то есть это ромашка у которой есть зеленые и красные и желтые листья зеленые хорошо желтый возможно плохо красный точно плохо ну и раз я упомянул про а лифтинг то имеет смысл в тред алерта который вызвал этот отчет скин ссылками на чел как эту подход применяется при массовых аварию во первых массовой аварии как можно пойти за при делении затрагивают несколько сервисов поэтому скорее всего overthink уже запустил отчеты по нескольким разным сервисам во вторых я до этого говорил про так называемый рекурсивный анализ то есть сервис был затронут его провайдер или консьюмер тоже был затронут и поэтому вызывается в стране что-то для провайдера и консилера поэтому при массовом сбою скорее всего уже будет запущена отчета по разным сервисам в этом случае очень наглядно бывает копировать отчеты по их причинам и показывать первую очередь те отчеты которые ты причины которые вызвали репутацию в наибольшем количестве сервисов такое изоляция называется карта инцидентов и мы его 2 себя сделали на слайде вы видите схему к от инцидентов давайте на примере пусть у нас деградировали сервисы a b c и е мы узнали об этом из за лифтинга сервиса и своя собственная причиной деградации он деградировал из очередей это причина и как и связано с остальными сервис-центр сам по себе вроде всем все хорошо но у него есть проблемы при обмене данными сервис md в конечном итоге оказывается что у сервисов быд причиной деградации это их база данных и так оказалось что эти базы данных находится на одном и том же физическом сервере таким образом сбой проблемы с оборудованием проблемы с одним сервером привлек массовой деградации несколько сервисов это наглядно видно на карте также наглядно на карте видны другие массы сборы такие как например доз или нарушение сетевой связанности или сбой в куда мастерами то тоже сервисе все указывают в одно и то же причем под видом на этом слайде и эта причина поднимается вверх итак я полагаю что достаточно рекламировал плюс использование такого инструмента теперь давайте поймем что нам для этого нужно конечно же в первую очередь нам нужно метрики конкретно мы используем фильтр house но это необязательно можно использовать любую систему украине метрик главное чтобы в ней были теми thread'а который вам нужны и была некоторая api которая позволит такие точки запросить давайте поговорим потом а такие метрики нам нужно сначала нам tir очередь нужны метрики физических серверов и контейнеров принят на корме трюк мы хотим увидеть утилизацию ресурсов мы хотим видеть и доступность по ssh и мы хотим видеть метрика вендора например на состояние контроллеров или температуру в эти корпуса или shop из вентиляторов на общем все то что рендер готов нам отдавать конкретно мы опять же используем для сборных вендора и оборудования плагины 3d также иногда у нас смотреть на само значение метрики бессмысленно потому что она ничего не значит иногда нужно смотреть на тренда метрик хорошим причинам является хорошим примером является функцией дизайна direction из графита которая смотрит во сколько раз текущее значение отличается от база на за некоторый период примером весть когда нужно использовать такой подход является например метрика лорд товарищ оно само по себе ничего не означает ее высокое или низкое значение тоже ничего не означает но означает тренд который скормите оно выросло несколько раз это скорее всего проблема следующий метрика который нам нужны это метрики база данных разумеется база данных хочется на жилье на серверах и нам точно также нужны метрика тех серверов на которых она хостится поэтому мы уже говорили кроме того нас могут заинтересовать статуса реплика сетов то есть в таком статусе лидеры таком статусе фолловеры статуса балансировщик of хоть это побега мастера погибаем сера и другие специфические метрика который вас интересует по данным цсу бады например если у вас после 100 вас может интересовать целей тенге кроме баз данных нам нужны медики выбран диск мастеров какие конкретно удивляться ресурсов кодами сервиса общий статус вообще здоровья данного plaster а насколько мне известно такие метрики насобирать через все отвозил далее нам нужны метрики связана сетью из dns например текущую загруженность балансиров и у тебя до царит пропускной способности статуса dns запросов особенно ошибки особенно те шаги которые не являются index domain ошибками состояние и курсоров dns если вы используете некоторые сервиса чудо дата так надо мне этот куратор то так же хочется видеть их метрика и наконец нужны метрика и приложение то есть данном случае сервисов этой метрики нужно тот потребление памяти циpкa тра еды гору терны ну и все против чтобы запечь и собирать по нашему приложению на этом с копейками все я сразу хочу отметить что возможно не нужны все метрики сразу работать с тем что вы имеете просто чем больше метрика тем больше сценариев вы можете покрыть ну и тем соответственно лучше следующие категории в масле который набрал без а это зависимости нам нужно топология сервисов для того чтобы понимали в топком уходим за данными такой информацию можно собирать по следующим образом например у нас есть файл manifest которым перечисляется для него причитается много разных штук при нем всего прочего в нем перечислены и зависимости каким именно сервис вам наш хоть заданными понятно что качество такая информация будет зависит от того написал разработчик эту зависимость ребенка это за был где-то нашей платформе по таким зависимости он делается автор генерация api клиента для внешнего сервиса проходить поэтому разработчика есть стимул не забывать потому что начал будет ставить или клиент самостоятельно кроме того как относятся а еще пару моментов собственно это отжимать соответственно в нефертити и праве катки она отправляется специальный сервис нас называется атлас таким образом после каждой клетки от на знает актуальную информацию о зависимости данного сервиса и он смог сложив спать в основании этого топологию и он может просто тибо момент кроме связи тебя создал с другом нам нужно принадлежность баз данных нам это нужно для того что понять сколько базу данных есть у сервиса какие-то база данных как они называются все это нужно для того чтобы тесто летать метрика как можно сшить такую задачу мы ее решаем с помощью того же файла мульти 100 и с помощью сервиса добраться которая у нас есть сервис de base используется помимо всего прочего для того чтобы автоматом поднимаете вас для сервисов он это делает на основании и суммации которой . сильно манифесте как побочный эффект он знает какие конкретно базу для данного сервиса имеется данными времени дали на понадобится информация о том сколько кодов есть у данного сервиса все это запада в тихонько страх и какие у них статусами список кластеров который раз диплом данный сервис мы берем и сервиса атлас поднимает говорил раньше а список кодов их статус и мы берем напрямую иск и папе это стандартные способы также полезно знать над их именно железных машинах раскатываем нужном пода тут нам помогает система 7 тебе я понятно подсказывал на другом накладе находиться с прошлым годом кроме того нам понадобится информация о релизах чтобы сопоставлять вибрацию с релизом тут все тоже довольно просто вы в свой первый поток вся идея добавляете push информация выкатки в некоторые сервис у нас это сервис называется релизе мы в нем аккумулируем данные про выкладки и про окружении в которых эти выплаты сделаны там стоишь против выдали ну и наконец нам понадобится артефакты нашего самого сервиса а именно логе троицы и круто вы события которые носятся по ошибкам для хране таких данных есть разные системы например условий может понять власти и или в хаусе события можно хранить центре я тут не буду на веки становятся они тоже довольно стандартами все что нам нужно это api во-первых и во-вторых некоторые единообразию записях для того чтобы вы могли каким-то универсальным способом для всех сервисов вытаскивать с некоторые общие данные теперь я покажу как этот сервис устроен принципе на самом деле архитектура у него просто им решение во первых нам нужна база который будет храниться а даша четными нам нужен сервис который кто-то будет писать и сервис который будет туда читать кроме того возможно вам понадобится кэш для того чтобы на какое-то время кашира вот некоторые данные еще одна вещь которую . это во внимание это следующая вещь надо понимать что art case сектор будет часто и много ходить во внешние источники это хранилища метрик и внешние сервисы которые представляют для вас данные в пример и как пример который называл это сервисы от вас с топологией дпс всем с базами данных релизе стремлениями и там еще есть разные любви сервиса при каких-то взрывных нагрузках в том числе на примерке массово деградация ваш сервис может приложить внешнего источника данных со своими запросами поэтому стоит обратить внимание на rate лимитер вам взять у нужен репентер иначе может быть плохо под конец своего выступления я хочу поделиться соображениями с чего стоит начать если вы захотели у себя в компании внедрить такие подходы начать пользоваться рб с анализом во-первых с помощью файла манифеста вы можете дешево начать играть данные про топологию сервисов и промежность база на сервисом также дешево начинаете можно часть давать информацию провели за просто добавляете свой топ лайн пуше правой кнопки кроме того не сложно ходить к папе и получать данные кодов ну и то что будет конце потому что это самый сложный шаг он вы начнете в.п. когда вы закончите неизвестно это процесс может быть вечным это видео набрать за метрик вам нужны разные группы метрика должны быть устроены единообразно для того чтобы могли всяких разных типов по произвольному сервису нармера запаситесь метрику response time и и получите и пока мы то универсальному пути или запросить над рекой его базой и получить это кадре к какому-то тоже универсальному другого пути вот ну и наконец последний о чём я хочу с вами поделиться это немного цифр про использования этого инструмента нашей компании всего сутки за сутки у нас люди плюс allure тонок запрашивают от 100 до 140 анализов мы показываю эти люди смотрят среднем за месяц 2.000 анализов и полный список по полный цикл проверки не сегодня сценария деградации мы сократили с более чем 30 минут до одной-двух минут на этом у меня все спасибо можете задаться вопросом пока неслышным спасибо большое за доклад так ну что давайте вопросы можно да спасибо за доклад александр hunter первый вопрос предположим у вас ни на одном сервисе не сработал какой-то порог ну то есть везде вроде бы небольшое количество ошибок но клиентам вы отдаете много ошибок то есть вот что делать в таком случае и второй вопрос там была картинка про база данных и что все они вели на одну железку ну как бы у нас сейчас стоим так не бывает что база лежит на одной железки то есть скорее всего мы и конкретную конкретный сервер не увидим просто в лучшем случае видим что проблемы с базой все спасибо 1 вопросы не очень понял то есть есть много ошибок и что дальше ну смотри предположим у тебя ну просто то есть в клиенты именно получает ошибки но то есть какой-то фронт отдает до ошибки а вот ты смотришь по нижележащим сервисом они очень пони были немного ошибок отдают то есть такое тоже может быть но возможно протезами проблема не является смежным сервисом является чем-то другим то есть причин на самом деле как и сказал может быть много разных идите скорее про то как будто есть таком случае вы анализируете как эту проблему то есть как-то самой верхней точке там какой-то входной не знают он стран то вы какой-то ноды или как если снежное сервиса показывают зеленый сад тут все из них то мы не запускаем анализ по ним то есть мы запускаем анализ только потенциально проблемных сервиса понял спасибо и мотать второй вопрос про второй вот смотри про это жесть когда да у тебя допустим кассандра но у тебя на 10 нотах да ты как бы хоп рисует что здесь проблему но это схема она такая упрощенная то есть реальность я хотел сделать спешат реально схемы там было очень много сложных нот и граф был большой запутанный реальные графа не более запутанные но что было иллюстрация про то что несколько разных бас действительно могут находиться на одном и том сервисы ананасе ну какой то как коммунальная манга например коммунальный сервис для манги на котором манги много монк вот и он может выйти из строя когда один сервис находится по нескольким базам тут ничего не меняется потому что если у тебя из-за одного сервера плохо нескольким базовым то все равно протяну тебя будет такая же понял спасибо еще у нас вопрос максим юрий на яндекс спасибо за доклад у меня два вопроса первые а если какие-то метрики по которым вы оцениваете эффективность вашего сервиса импорт на команды например скорость разбор инцидентов выросла просто это как инструмент варился вот как вы оцениваете как он помогает людям и второй вопрос а я правильно понимаю что в enforce сити а вот этот граф зависимости то есть нет физической связанности между сервисов если ты не опубликовала зависимость хорошо вопрос 1 мы это мы измерение такого пока что они пришли мы верим что негативный сценарий а то есть есть кнопка в отчете указать что вот-вот кос на самом деле не это а вот это то есть мы верим негативный фидбэк позитивный солдат потому что медики научились работаем над тем как какие медики туда вставляется второй вопрос если не указать зависимости то данных об этом нигде не будет то есть никакая машина не будет знать портов что этот сервис связан с этим сервисом и таким образом нос связь не не будет посвящена и она не будет подсвечена возможный roussos поэтому связи нужно публиковать спасибо максим ответили дополнительно вопроса на самом деле можно задать то есть прозвучало так что на самом деле можно физически сходить к другому сервису не сказав что я от него завишу и это ну потенциально бомба может быть исторические данные тогда как то использовать для того чтобы ну фактически чекать факт что человек может не опубликовал этой зависимости на самом деле сходил и по историческим данным там смажьте заотаров или сервис мешались чего-то еще можно это как-то про трепет ну вот есть какой-то такой механизм который помогает убедиться что разработчики честно зависимости декларируют спасибо механизма чтобы в этом столбце наладится я полагаю нету есть механизм проставляет разработчикам по которая уже говорил то есть не укажет зависимости не получишь до готового клиента пиши его сам да вот но можем стать разработчику молоток и сказать что по сломаешь ему руки что-то вроде то есть способы заставить нет нету спасибо следующий опрос спасибо за доклад подскажите а сколько человек и сколько времени занимались до тех пор пока это начало давать результаты хороший вопрос 1 начали маленькая командная на свече команда четыре человека начали пол человека то есть один человек на пол своей ставки это делал примерно несколько месяцев до mvp и примерно через полгода по моим воспоминаниям это начало давать какие-то реальные рассказы которые мы находили в праге спасибо привет меня зовут denis есть beerмаркет спасибо за доклад такой вопрос ты сказал что у вас вот эти метрики очень быстро стали собираться 40 минут вы снизили там до нескольких минут поделись пожалуйста что из такие действия привели к больше всего impact и вот в уменьшению сторону сбора и вот этих метрик за в отчеты спасибо еще раз пожалуйста такие действия привели к чему какие действия больше всего принесли людей impact на уменьшение к его имени сбора вот этих вот отчетов то есть все это у тебя на одном из последних слайдов была как раз та что в время сбора этих метрик сократеса к дотам нескольких минут наверное не совсем правильно описал что произошло то есть раньше до этого разбор инцидентов на расследования студентов было вручную происходило и инженер делал вот тоже самое что делал нервный мишка он одной рукой смотрел метрики другой посмотрел логи 3 работал связно часики и это занимало но потому что человек один обычно работает до плюс этого кота выскочил коммуникации плюс последовательность выполнения она занимала 10 минут вот что произошло мы сделали автоматику и мы установили разбираем вы много потоков поэтому в целом построения отчета с подсветкой подхода занимает на самом деле обычно меньше минуты вот эти вот отданы минута это когда мы делаем одновременно много анализов спасибо можно сориентироваться сколько у вас людей на мониторинге смотрит в один момент времени команда мониторинга смотрит куда как астана метрики то есть на этом инцидент стрельна вот amoled нашей команде община это в принципе не смотря то есть это не совсем наша задача мы занимались разработка все у нас есть дежурная смена я не помню сейчас на сколько там человек по моему около десяти человек которые работают на этом спина которая работает 24 на 7 они следят за метриками 24 на 7 и около десяти человека они работают в разные смены уточнение на оном спасибо спасибо спасибо за доклад у меня небольшое уточнение я слева слева от вот у меня небольшое уточнение потому как можно делать обнаружение зависимости у сервисов если наше приложение разрабатываются по 12 фактором то все настройки передаются через переменное окружение соответственно мы можем пропарсить переменное окружение найти там всякие dsn и адрес api сервисов и такое и как бы создать карту зависимости и но не заполнять это руками ну как как это идея на будущее хорошая деда спасибо еще вопросы здрасте спасибо за доклад был очень интересно послушать у меня такой вопрос на самом деле продолжение предыдущего вопроса можно мне кажется было бы узнавать продать зависимости через tracing учитывая что все друг с другом связаны и вообще в эгер его это же мы есть такая возможность показать такой граф зависимости кто чего зависит вот как вы думаете идей согласен согласен предоставить а также можно единственное что с ходу не могу сказать можно ли част раиса смотреть база данных зависимые если с ходу можно то ну наверное это полная замена но если вы пишете клиентские span и на каждый походит базу то почему бы нет да спасибо за доклад и кирилл в бирме тут тоже слева хотел понять ваша программа проект помогают ли вы являются какие-то ненужные метрики которые вот уже собираются обычно бывает куча метре которые не какую пользу они приносят хочется понять и были ли у вас какие-то кейсы в этот счет помогали оптимизировать у нас есть тоже одно из направлений которые мы занимаемся поиском нужных метрик но наш сервис никаким образом этого не находят иногда мы иногда бывает так что мы можем найти метрики которые не используются ну то есть принципе на такой случай на самом деле то есть это не назначение данного сервиса и у него не то что ты пацана власти которая бы это делала джон спасибо так если еще вопросы так вижу да выживет спасибо за доклад а вот мне было интересно какой из вас пользуется конкретно алгоритму кластеризации проблемы выявления not деградации да например у нас может тут же floss начать понемногу деградировать вы как-то там заранее устанавливаете планки и что будет например если деградировал по диску например ну не превысил эту планку но тем не менее из-за этого куча сервисов так или иначе той же пострадал вам вот вы велит ли система вашей это самостоятельно или вот как эта корреляция она ищет вот в этом узнать можно сейчас вы просто говорим лежит микрофона я половину меня ни дня не правым глазом но смотри ситуацию разберем как понять что деградирует ну допустим диск на какое-то в машине вы ставите на какие-то пороги после этого собираете trace с диска и смотрите там превысил он порог или нет вот ну может быть например такая ситуация когда порог был не превышен но он свернул был достаточно тормозной что привело в среднем деградации там нескольких зависимых сервисов которые там на этом христе работают там и так далее вот выявляет ли ваша эта система такие зависимости ну не очевидные ну и как оно очень расстраивается как настраивается сети пороге подбираются там а левая вопрос в общем 1 часть если мы смотрим на какую-то метрику то есть мы на какие-то метрики смотрим по определенным правилам например в случае это ты диском мы на можно смотреть на это медики но в америке вендора которые показывают что диск какой-то дохлый и люди с такой-то не дохлый вот если не только рендера показывает что диск не вдоха на самом деле он полудохлые боюсь что в ничего не поймем для таких более тонких сценариев которые вот вы указали но обычно мы замечаем что наш топ 5 то не поймал то есть получился фоллз негатив так сказать да и мы его просто учим каким-то новым вещам ну то есть допустим случай глаз и диска мы можем исследовать это мне утилизацию диска что-то в этом роде то есть мы там увидели увидели культа аномальную аномально большого уделяется диска но эта новость нами которому мы должны начать наш сервис по сути наш сервис это большой список сценариев часть из них можно принять типичную например проверка железных ростов там это для bас применимо это для кодов применимо где много чего применимо вот какие то сценария будут узкие то есть например проверка тренда тренда утилизация диска пороге обычно задаются экспериментальным путем а те было попыток ну какой-нибудь и ну там имели натравить попыток не было есть план на это спасибо спасибо вот ну да человек да давайте последний вопрос да я думаю нас и на один вопрос там хватает раз спасибо за доклад меня зовут слава вопрос системы это клёво и все хорошо но она тоже может выйти из строя что час она тоже может выйти из тонально система анализа вот это вот оповещение так далее как вы случалось ли такое как вообще с этим тоже хорошего правда вами смотрели тут частиц ситуация такая что у тебя но мы работаем в мониторинге instruct но в целом это плохая ситуация когда у тебя есть мониторинг твой просто лежит этого момента это плохой мониторинг тоже самое относится к нашим сервисом у нас есть инфраструктурные пастера в которых 80 ну как воплотиться . инфраструктурные сервисы и это делать для того чтобы если сдохнут они вместе то есть что-то подыхает обычно это что-то одно либо подыхает инфраструктур или просто тура ну то есть то что находится в просторной пасторов в том числе наш сервис либо подыхает проц но и простоту об этом жила ну то есть вот это такие способы разделения я даже добавлю разработчик и дежурные смены тоже может общем выйти из строя вполне у даже может не войти в строй вдвое там и вне ринга"
}