{
  "video_id": "ve2Ft4yceYc",
  "channel": "HighLoadChannel",
  "title": "Резервирование маршрутизаторов в дата-центре / Кирилл Малеванов (Selectel)",
  "views": 1551,
  "duration": 1545,
  "published": "2023-01-19T07:03:35-08:00",
  "text": "всем привет значит сегодня расскажу о резервировании маршрутизаторов в дата-центрах о том как мы зашли на и резервирование инфраструктуры чтобы все клиенты которые у нас размещаются в дата-центре независимо от того берут они одну виртуалку или какие-нибудь еще в услуги или расположена у нас взяли тысячи серверов есть такие клиенты чтобы они необъяснимыми чтобы они не испытывали проблем при перерывах сервиса при перерывах доступ в интернет а когда объявил этот доклад тогда в каком-то чатике проскочила что здесь делать возьмите джунипер микс 2020 и у вас будет все хорошо ну вот не будет она все хорошо а потому что джон термекс 2020 это железка рассчитанная на большое количество трафика они на 1000 клиентов которых мы сервируем к интернету при резервировании доступа в интернет мы заходим на историю о том что надо резервировать инфраструктуру если достаточно легко решается вопрос с резервированием каких-то конечных точек доступа и герой не маршрутизаторов и агрегации с резервированием коммутаторов доступа то остается маршрутизатор доступа то есть тот маршрутизатор который непосредственно является первым копом для серверов расположенных у клиента и как мы это будем резервировать традиционных сетях в enterprise сетях это задача давным-давно решается она решается путем так называемых протоколов все scale to ride on se протокол и первое что приходит в лоб а давайте использовать такие же протоколы только для резервирования доступа интернет внутри дата центра и тогда мы получаем первую проблему о том что хорошо это работает в enterprise сетях там мы резервируем одну две три сети а как же быть в том случае если нам надо зарезервировать много сетей то есть несколько тысяч клиентов какие проблемы при этом возникают как это работает почему это все взялось все схватка redundancy протокол протокол маршрутизации 1 хоппа на самом деле появилась это все очень и очень давно в 90-х годах и 1 появилась реализация данного протокола анапа приторная cisco вск а я чисто реализация она очень несложно и то что называется ascii совке сначала это работало сайте в 4 даже сделали стандарт но все равно это стандарта чисто cisco вский и используется только наци скользких маршрутизаторах не используется больше нигде а потом появилась вторая версия которые стандартам не стала но которое обеспечило резервирования и пиво 6 на смену о cisco всe caмa протоколу появился открытый стандарт появился стандарт вверх и но он также не сложный внутри версии различного стандарта вверх и а выделенный mac адрес используется для и zirve не машите zatarra три версии акивы 4 api вы 4 балансировка и ольги в 6 с учетом всех особенностей второй версии и это стало достаточно таким стандартным решением которое поддерживается практически всеми винда грамме сетевого оборудования на freebie езде и за лицензионных споров которые возникли езде о том что там совершенно другая лицензия там ней gpl использовался свой стек и своя реализация данного протокола которое получило название к отличие всех этих протоколов hs activecard они очень мелко детальные и все это очень просто реализовывается очень просто все это настраивать но это все рассчитано на то что мы настраиваем реализовываем это для 1 2 3 сетей по сути дела вендора начали заходить на свои реализации данных протоколов нивелируя эти недостатки протоколов которые есть в частности варис ты например это называется вард у других вендоров это называется я шеф пенисах и и так далее то что это все-таки венгерская реализация по такого она накладывает свои ограничения и поэтому сложность данного решения она становится немножко выше ты не можешь взять например два маршрутизатора двух разных when the raw и организовать на них резервирование по данному протоколу именно между двумя вин дарами то есть interoperability появляется чтобы решить проблемы interoperability появляется и выпьем так называемый не каски и творить но он очень сложной настройки на него сложно зайти просто так мы не можем взять что-нибудь работающий сразу натянуть на это unicast битвы и чтобы получилась у нас непосредственно работа interoperability также остается достаточно большой проблемой несмотря на то что его пены то в общем то стандарт и учитывая вот всю вот эту ситуацию с табличкой вас когда собрали плюсы-минусы собрали замечания мы поняли что мы будем заходить на меры и потому что это является стандартом и это достаточно не сложно и в понимании несложная в реализации штука как работает 3d прп по дефолту предназначен для резервирования все-таки 1 хоппа то есть дефолт битве на каких-то серверах на рабочих станциях и предназначен для работы в одной сети но вот для одной сети два маршрутизатора который мы ставим мы действительно для резервирования вынуждены поставить 2 железки маршрутизаторы r1 и r2 который образуется между собой веррев ты пару и они обмениваются между собой hello- пакетиками но у нас возникает проблема о том что verified предназначен для нескольких сетей а если этих сетей становится несколько тысяч первое решение которое в лоб это давайте продублируем все эти настройки на всех этих виртуальных маршрутизаторах по сути дел во всех этих сетях но возникает проблема о том что маршрутизаторы по-прежнему обмениваются хэллоу пакетами и r1 и r2 в случае виртуальных маршрутизаторов случай нескольких сетей нескольких тысяч детей они будут обмениваться пакетами внутри этой по сети много тысяч раз обмен хеллоу пакеты между маршрутизаторами происходит в том же самом было не в той же самой сети где находится клиент а это также вносит определенные коррективы потому что клиент на самом деле может вмешаться в служебный трафик или клиент когда хочет настроите себя вверх и для резервирования своего внутреннего там тех же самых веб-серверов или каких-нибудь апликэйшен серверов он может совершенно случайно выбрать ту же самую веры и группу на который уже работает служебное оборудование увеличивать количество целей на коммутаторе доступа но не очень правильно опять же клиент может писать здравствуйте вот я настроила но почему то не работает почему она не работает это увеличивает количество обращений клиентов и снижает уровень клиентского счастья наша задача в том чтобы клиент этого не замечал чтобы у нас все происходило автоматом каким-то образом и у клиента работала все без перерыва в связи чтобы было все замечательно high lords наступает тогда когда мы масштабируем данную сетку при масштабировании данные данного решения вот в лоб мы получаем очень много виртуальных маршрутизаторов которые между собой постоянно обмениваются холо пакетами этих и ло пакеты идут в определенных сетях в тех же самых сетях 10 от клиенты мы получаем достаточно но by служебного трафика это неприятный служебный трафик это мультиках мы открываем выход на циpкa непосредственно маршрутизаторов связанную с этим и служебным трафиком и клиенты могут вмешаться в этот служебный трафик самое неприятное в том что клиенты которые могут вмешаться служебный трафик в том что он делает плохо не только себе он может сделать плохо другим клиентам которые находятся на этом же самом машинки затари таким образом не реализуется система о изоляции клиентов друг от друга и мы можем по сути дела это изолировать только какими-то дополнительными решениями либо например взять несколько физических маршрутизаторов или пойти каким-то другим путем вот каким другим путем на самом деле мы пошли и увидели что маршрутизатору окей хорошо их становится много их становится много виртуальных маршрутизаторов и route zatarra физического r1 у физического маршрутизатора r2 которая обменивается между собою служебным трафиком хеллоу пакетами обмен hello- пакетами на самом деле должен происходить всего один раз между маршрутизаторами смысла никакого гонять эти хэллоу пакеты сто раз потому что на маршрутизаторе настроена 100 сети или 10000 раз потому что на маршрутизаторе настроена 10 тысяч детей и вы никакого нет выгонять надо только один раз и проанализировали мы документацию на маршрутизаторы и выявили что у многих вендоров у самых основных по крайней мере с которым не имеет место быть с которыми работаем что у них такая возможность есть что можно организовать какой-то служебный воланчик который будет сигнальный на котором будет происходить непосредственно обмена служебными хэллоу пакетами а все остальные клиентский интерфейс и сделают наследованием от него то есть если у нас 11 валом сигнальный на нем действительно происходит обмен трафиком маршрутизаторы понимают кто из них живой кто из них мертвый и так далее а все клиентские воланы которых там несколько тысяч штук на маршрутизаторе они наследуют состоянии от сигнального интерфейса эта настройка она есть в данном случае она красненьким выделено это для джинни перовского маршрутизатора так я же настройка есть у cisco такая же настройка есть у huawei такие же настройки есть у других маршрутизаторов в том числе у сотовых маршрутизаторов и у маршрутизаторов которые входят состав популярных облачных продуктов но у нас не решается еще задача о том чтобы обеспечить актив актив решение между маршрутизаторами r1 и r2 то есть у нас маршрутизатор r2 находится в постоянном backup стоите мы не можем проверять что он действительно в бою что у него все хорошо и он готов принимать трафик для того чтобы реализовать артефактов решения мы начинаем смотреть так если у нас 11 волан сигнальный а все клиентские у нас наследует состоянии от сигнального вилла на что нам мешает сделать следующим образом чтобы сигнальный было но у нас были 11 и 12 четные воланы например будут наследовать свое состояние от 12 нечетные вот 11 таким образом трафик от серверов в интернет пойдет через маршрутизатор r1 и r2 им трафик от интернета к серверам вниз он пойдет соответственно просто через анонсы на этих маршрутизаторах таким образом мы эмулируем работу редких актив часть клиентов у нас ходит через 1 маршрутизатор часть клиентов ходе через 2 маршрутизатор мы повышаем утилизацию непосредственно маршрутизаторов непосредственно линка в которые ходят на них и можем тем самым по крайней мере удвоить количество интерфейсов на которых мы обеспечиваем работу протоколов и резервирования 1 хоппа о чем собственно рассказал о том что зашли мы на резервируем не маршрутизатора данная схема нам позволило в том числе днем обеспечивать обновление например программного в течение маршрутизаторов без перерыва связи для клиентов мы заранее просто переключаем режим мастер на один маршрутизатор второй маршрутизатор выводим из работы обновляем на нем программном обеспечении проверяем выполняем все проверки у понимаем что он готов принять нагрузку упускаем теста вы нагрузку убеждаемся что все хорошо и пускаем на него клиентов и за счет того что мы разделили четные и нечетные мы получили так называемые артефактов решения позволяющий нам постоянно мониторить что с трафиком идущим через два маршрутизатора на самом деле все хорошо о и нету ситуации такой что клиент пишет что что-то сломалось а мы не знаем потому что это пошло через какую-то бы капли маршрутизатор модель да нет все нормально все должно работать а естественно количество зондов которые мы ставим среди серверов она также удваивается потому что появляется два маршрутизатора нужно два зонда для по крайней мере 2 ip адреса на зонт для того чтобы часть проверок шла через маршрутизатор r1 чаще из маршрутизатор r2 по лимитам данного решения о самом деле есть такое понятие как скорость погони рование сетевого железа когда мы меняем настройки на сетевом железе а в данном случае эти настройки также будут меняться только меняться автоматически вот прохождение не прохождение hello- пакетов тогда мы вынужден перепрограммировать так называемый chip asic тип через который ходит непосредственно трафик на сетевом железе он не ходи через пол и скорость программирование этого чипа она достаточно ограниченное кто-то говорит о том что это там 10000 провел секунду кто-то говорит о том что это 1000 павел секунду и именно скорость программирование может определять какое непосредственно количество интерфейсов какое количество клиентских частей как клиентских воланов мы можем выносить на один маршрутизатор исходя из того какое время перерыва сервиса для нас является приемлемым если это меньшая секунд а значит мы должны выполнять условия по лимитам и программирование для одного машине zatarra 1000 или 10000 воланов можем поставить если у нас 10000 буланов можем поставить действовал синтезаторов данном случае мы ограничены количеством портов навигации и их разумности использования 20 портов действовавших и задрав 3 из портов 15 маршрутизаторов и так далее но например там ставить еще одну пару коммутаторов облигации просто для того чтобы воткнуть туда еще одну пару маршрутизаторов ну немножко на годность финансовой точки зрения на этом все спасибо если остались вопросы пожалуйста обращайтесь спасибо вот у нас есть вопрос от центра 1 вот прямо здесь первый кирилл да спасибо за доклад меня зовут алексей вопрос такой какой силой вы даете клиентам на доступность 1 хоппа sleek select или я на выделенные серверы сто процентов это же не вопрос волшебных чисел которые мы дали нет я вопрос не важно на сколько мы готовы компенсировать деньгами или еще какими плюшками доступность или не доступность наших сервисов но я собственно почему что исходя из этого и можно как-то смотреть том числе решения выбирать выбирать техническое решение то резервирования котором ты говорил это применимо только к выделенным сервером или виртуальной сети тоже для виртуальных серверов в виртуальные сервера не все равно упираются в один физически маршрутизатор ну в данном случае в 20 глава к чему я предложу что не проще ли было вот взять сортовую реализацию например там на там же типа лифт по иметь больше гибкости в том плане что можно там сделать unicast проверка не multicast можно там сделать кучу разных условий и так как это стоит вас полнее счета это просто запускается в контейнерах там же за секунды и отказаться вот в ирак по реализации на железе которые но достаточно дорогая во всех смыслах она может быть достаточно дорогая да но заход на софтовые маршрутизаторы еще дороже потому что железный маршрутизатор если на нем заявлено там производительности 1 миллион пакетов в секунду значит он этот один миллион пакетов в секунду через себя пытаешься софтовый маршрутизатор потащит нам 40 тысяч пакетов в секунду есть маршрутизатор который могут гнать через миллионы пакетов в секунду но стоят они уже сравнимо железной минувшего эти заторами ну ладно спасибо спасибо вот у нас еще а ну уже в руках давайте потом вот следующего производит кирилл спасибо за доклад у меня вопрос такой вот не было сначала врп ду клин причин по старой схеме включения vr пили него прервет сервис или нет если у клиента в сети есть айпи адреса свободные которые он готов выделить для включения вверх и то мы это делали без перерыва связи а если нет если нет то с первым конечно если нет если это legacy клиент старый войти адресов не даю таки адресов номер пенёк то у нас реализовано так называемая то что мы говорим тепленькой резервирование маршрутизаторов она переключается вручную но это ограниченное количество клиентов которые с нами уже там больше пяти лет и вопрос такой были какие-то проблемы в интернет и между разными менторами на верят и были были там не смазывала заходит схема с дропом например там между хуем и джуниора есть определенные нюансы которые вычисляются в лобби проверяются и только после того как вы решили эти нюансы мы уже запускаем эту схему production так мы меняли в частности маршрутизатор одного вендора на маршрутизатор это угу без перерыва связь спасибо спасибо за доклад меня зовут спасен компания пресс меня интересуют каким количеством железок в центрах и если вы используете все таки конфигурацию они только нас так сейчас за код то каким софтом и пользуйтесь либо как вообще ходить конфигурацию количество железок какое именно количество железок вас интересует коммутатор или маршрутизатор и маршрутизаторы это около 50 маршрутизаторов конфигурация самописная система потому что она связана с sb с решением то есть панели управления пользователь может прямо накликать выделите мне еще одну сетку выделите мне еще один воланчик настройте мне i'll try with ящик это все уходит на непосредственно железной маршрутизаторы самописные решение через открытый протокол этой железкой мы работаем либо по ssh либо по нет con su спасибо спасибо за доклад а вот вы говорили про режим артефактов там фактически ручной balancing трафика происходит вот сюда что думали насчет динамического распределения в активе а смысла нету на самом деле вот при такой ручной балансировки на больших числах достаточно четко попадаешь сердце от распределения трафика сильного перекосы нет сейчас 2 на сайт авось и может быть это не играет не играет роли а автоматическая балансировка будет просто долго стоите разработки спасибо еще вопросы здравствуйте михаил такой вопрос почему эктив актив был выбран вместо того чтобы наоборот трафик только через один может завтра гонять потому что когда я cтив актив где гарантия что когда отвалится резервный можете затар все влезет в один как управляется как программе же того что все влезет в один это идет определенное количество трафика постоянно мониторится которая проходит через каждый из маршрутизаторов то есть есть олег который говорит о том что через маршрутизатор пошло больше 50 процентов его пропускной способности и надо с этим что-то делать то есть вот это мы контролируем и когда мы постоянно держим нагрузку меньше 50 процентов это как раз гарантирует то что мы влезаем в такой же 2 маршрутизатор но режим не только про трафик но и там про количество интерфейсов там и так далее или она условно одинаковое сто процентов маршрутизаторов power стоят как правило одинаковое количество интерфейсов акте интерфейсе уже подключены и там распределение другой идет и мы гарантированно попадаем его плинко вы и давненько вы интерфейсы если не случается случае двойного отказа например спасибо"
}