{
  "video_id": "bn024-QZv70",
  "channel": "HighLoadChannel",
  "title": "Приключения проекта от компьютера разработчика до серьезных нагрузок / Андрей Минкин (Mad Devs)",
  "views": 2754,
  "duration": 1925,
  "published": "2018-01-16T13:41:54-08:00",
  "text": "всем привет меня зовут амин мин ким андрей я из приехал сюда из бишкека и сегодня я буду рассказывать про какие-то основные частые проблемы которые возникают чаще всего при у тех людей которые вроде что-то писали а потом тут у них пришли пользователи все на сломали я из команды modems мы занимаемся разработкой на аутсорс и одни из самых наших крупных клиентов это служба такси в бишкеке на бы такси и службы доставки намба food но и ближе к делу как обычно все бывает мы сначала проект ходим потом его тестируем особо опасные люди это все дело не тестируют вот а потом запускаем в продакшн на продакшеном обязательно нужны какие-то глаза что и чем больше глаз тем лучше кто-то вообще по на этом слайде абсолютно каждый пункт отделали по каждому пункту можно сделать несколько докладов но вкратце не так допросы построить и хороший мониторинг вот кто-то собирает ошибки с бы кондо кто-то не собирает и в последнее время люди начали делать racing потому что на микро сервисной архитектура набирает обороты и нужно знать куда пошел за тот или иной запрос чем популярнее становится наш проект тем выше на него нагрузкой и нагрузка обычно бывает 4 на 4 основных компонента это на диск либо на чтении либо на запись на процессор это у нас какие-то либо вычисления вот и также на сеть и на память проблема вся основная нагрузка которая возникает у нас продакшене связано с тем то что ее нельзя так просто взять и воспроизвести и даже нагрузочное тестирование но не всегда не не всегда позвонить помогает потому что мы думаем то что пользователь пойдет по одному сценарию а на самом деле он идет абсолютно по-другому ну например когда мы собирались выкатывать софт для службы такси мы думали то что основная нагрузка придет на тот метод который выдает заказа всем водителям но мы не ошибались так вообще никогда потому что на самом деле большая часть нагрузки приходилось на метод взятия заказа и в один прекрасный момент момент прогуливаясь по рядом с таксистами увидел то что он сидит перед навигатор вот с козой вот почему он так сидел потому что он одним пальцем жало заказ и 2 которым пальцем жал на взятия заказа вот таким образом генерал с нагрузкой и вот вам пример того то что в реальной жизни она может пойти абсолютно не так как вы думали ну и плюс окружении у нас разные на продакшене у нас одни сервера на тестовому окружении у нас другие сервера и на компьютере разработчиков абсолютно 3 и иногда бывает такое то что но на наши макбуки ssd все работает быстро вот тогда мы выкатываем хотя бы она тестовый instance gained это все начинает работать в разы медленнее ну и частая проблема которую обычно начинающие разработчики говорят что вот у меня на компе все работает на самом деле это показатель того то что человек как разработчику он еще в на ранней стадии стадии развития и взрослые хорошие разработчики так не делают и в общем добро пожаловать в мир разработки с которые связаны с какими-то нагрузками что делать ситуации когда у вас когда вас настигла нагрузка но обычно это можно оптимизировать код либо по кэшировать ли базу масштабироваться как бы основные три варианта и на самом деле с оптимизации не все так просто потому что оптимизировать слепую ну никак нельзя сначала нам нужно собрать данные о том что можно по оптимизировать какие методы у нас могут генерить больше всего нагрузки потом эти методы найти по оптимизировать заде плоть но и повторить до тех пор пока мы все это дело не за оптимизируем ну и обычно после обработки вывода там того или иного профайлер либо анализатор логов вот мы можем прийти к выводу то что иногда бывает что 20 процентов методов они генерят больше всего нагрузки и это хорошо когда у вас она на самом деле так потому что вам есть что оптимизировать плохо когда профиль на углу нагрузки плоский и там активизировать особо ничего и единственный путь это вы живете просто и масштабироваться ну какие о самом как можно оптимизировать код можно по оптимизировать со стороны базы данных и р.м. это избавившись от n + 1 запроса переписав либо на join и либо как-то по оптимизировав за прошлый раз ставить индекса также если есть бесконечные какие-то циклы или вообще не эффективные алгоритмы то их можно и нужно оптимизировать но также можно некоторые вещи за кэшировать и за масштабировать но и каких-то подводных граблях самых распространенных и поговорим о последнем двух пунктах на самом деле кеширование внедрить просто непросто с этим жить и это поддерживать и самая первая проблема когда вот мы вне реле каширования она связана с тем то что у одного пользователя все работает шустро у другого все тормозит при этом у того пользователя который у которого работает шустро тоже периодически может все это дело тормозить и с чем это связанно это связанно с тем то что нужно знать как работает ваш кэш эффективно ли вы внедрили кэширования это нужно смотреть на метрики хитов и весов то есть есть если мы обратились в кэш и у нас по этому ключу есть данные то соответственно мы попали в если данных нет то это пойдет в метрику по мясом и хорошо если у вас чем выше этот показатель чем выше показатель процента хитов ну либо чем ниже показатель процентами saw the cage вашей работает если она ниже то это плохо и плохо по одному таком случае мы добавили новый компонент в которой мы ходим и у тех людей у которых все и так тормозил она стала работать ну чуть-чуть на дне потому что мы как минимум добавили немного времени на то чтобы сходить в кэш следующая проблема она связана с тем то что нам нужно запустить проект когда у нас нет данных в кэше такой обычно бывает когда у нас абсолютно сер сервера упали и нам нужно весь проект который работаем с подругой под нагрузкой поднять алгоритм довольно простой мы сначала убеждаемся в том то что у нас работают все наши серверы мастер турнули виртуалке и на этих наших virtual koch сверкнули все самые нужные нам сервисы эта база данных это каши это файловые какие-то хранилища и наши сервисы микро сервисы и у кого как при этом желательно проект закрыть от пользователей чтобы пользователи не generly нагрузку и нагрузка не попадала к нам потому что но есть у данных нет в кэш это и если наш код устроен так то что мы должны сходить за данными в к что в этом случае нагрузка может генерится очень высокая и это в общем мы проект так никогда не подымем и для этого нам нужно прогреть кэш прогревать кэш можно как автоматически так и вручную то есть все то что мы можем автоматизировать мы это автоматизируем ну и плюс мы когда закрываем наш проект от пользователя мы обычно открываем держим его открытым для нашего офиса и в этом случае мы можем проверить все ли сервисы стартанули все ли правильно работает вот и пример конфигурации был джон x для того чтобы закрыть ваш проект на балансировщик ах для всех следующая проблема которая может вас встречать это у нас нагрузки как такого нет но при этом мы лежим и и все у нас тормозит что обычно в этот момент происходит мы смотрим мониторинг и смотрим то что у нас все нормально по всем параметрам у нас все сервисы работают у нас не диски не про дни процессор не все не база данных ничего не нагрузил но при этом мы лежим и главное у нас не работает что у нас то что то что говорят нам графики с дисками все в порядке с памятью все в порядке и спросом все в порядке что у нас показывает сеть сеть обычно смотрят мы чаще всего самую последнюю очередь когда все тормозит потому что все это на либо работает либо нет но при этом у нас пинге ход входят все работает но что у нас просто с пропускной способности обычно трафик который генерит внутри сети он довольно слабый но в этот момент у нас сеть была загружена прям по сто процентов и был явный по ней перегруз что начинаем делать мы смотрим берем в руки тисе пи дампы white shark анализируем снимаем дампа трафика анализируем и видим то то что больше всего трафика генри самым кушон вот почему генерится потому что до этого мы за тепло или такую штуку мы положили в кэш по ключу данных на 10 мегабайт но при этом кто по этому ключу достается достается данной для главной страницы нагруженного проекта на котором одновременно может там сидеть 2 с половиной больше тысячи людей вот ну и при этом он она может сгенерить вот такой вот нагрузку по сети но и как вывод не нужно класть в кэш большие данные проблемы с масштабированием какие они могут быть и как с этим быть самые частые проблемы вот они возникают именно в масштабировании когда у нас система становится более распределенной в одной масштабироваться можно тогда как когда вот вы видите на слайдах все эти пункты вот при этом масштабироваться можно экстренно когда вы у вас нет времени на делать абсолютно все то что указано на слайде вот но и потому что вы лежите и какие самая самая проблема часто проблемах с которой вы можете столкнуться с тем то что пользователю было ги него это есть вы взяли добавили у вас вместо одного конца теперь два бы кондовые разбалансирован и их и одного пользователя может как вы лаги нибудь так и не была gene вать при этом это связанно с тем то что ну по крайней мере раньше так было все сие хранили файлах вот ну и соответственно мы перекидываем сессии в какую-то централи социализированное хранилище либо в базу либо в кэш и с этой проблемы у нас все становится более менее хорошо мы тоже самое с картинками так как у нас два бака нда и если мы на один из них залили картинку и при этом ни разу не разлить реплицировали на другую то тоже могут быть проблемы с тем то что на одном бы candy она есть на другом и и нет ну и в качестве решения этой проблемы мы можем использовать либо там документ на хранилище например я команда или что то еще мы можем использовать отдельно какие-то из 3 совместимы файловые хранилища например менее либо можем настроить каширу ищем модуль engine.exe и отдавать в картинке им вот ну и при этом основная штук когда вы масштабируете ваше приложение в том то что есть у вас не состояния то у вас нет проблем больше все случаев оно происходит так следующая проблема возникает тогда когда мы начинаем что-то деплоить мы за тепло или вот и у нас сайт по весны миграции потому что у нас легла база потому что мы решили за альтарес большую таблицу которая весит ну например больше духе га байт вот и под нагрузкой что нам скажет процесс лист то что alter висит таблица залочены если какой-то близ и есть частые запросы вот то все будет потихоньку книги рить больше и больше нагрузки и потом она все упадет чтобы этого не было есть первый способ это вы сначала закрываем наш проект то есть пользователь у нас ведет а что у нас тут технические проблемы то есть нас сейчас либо профилактика либо что то еще мы все это дело альперин без нагрузки вот и потом открываем проект либо мы используем инструменты например перку на вскипятим а майские матчей при котором мы можем на боевом окружении альтере таблицу и при этом не блокирую и и и делай это быстрее чем делает стандартный alter вот а также следующий шаг это изучить как делать ноут downtime альтеры для вашей базы данных что еще можно сказать про то где мы можем повествовать это например когда мы строим первый раз файлообменник либо файловое хранилище и при этом у нас нет какого-то опыта ну задача файлообменника это хранить файлы вот при этом файла нам желательно не терять и хранить файлы и не терять файлы первая мысль которая приходит это давай сделаем все на рядах 0 рейд который предоставляет который объединяет два диска в один он ненадежен но при этом шутере зеркало но в данном случае нам решить проблему с доступностью файлов вот но есть ещё вариант когда мы делаем зеркало из двух нулевых рейдов вот но в нашем случае под больше подходит 5 рейд потому что он более экономичен нам по дискам вот но при этом в нем есть минус в том то что 5 лет будет работать со скоростью самого медленного диска в рейде вот при этом это скорость она у нас не будет как-то масштабироваться вообще единственный способ за масштабировать скорость он добавить новый рейд вот и при этом какой бы он ни был у нас скорости больше не станет и со временем как мы все доллис со временем мы прилегли потому что у нас стало больше нагрузки и 10 пользователей и который работает одновременно с файлами они у них очень медленная скорость как на закачку так и на скачивание файлов следующий вариант как можно строить файловые хранилища это мы убираем рейды и и сделаем все на дисках вот при этом если у нас одна копия файла есть у нас больше чем 2 копию файла на двух разных дисках вот она решает проблему с тем то что мы файл в случае выхода из строя одного диска потеряем при этом из плюсов мы получаем довольно хорошую разницу в скорости потому что ну один диск это у нас стоило псов условно говоря рейд из 5 дисков это стая псов потому что 5 рейд работает со скоростью самого медленного диска в рейде вот 5 дисков это у нас 500 баксов и какие плюсы от этого мы получили во-первых система стала более живучи и потому что если глючит один диск то ключи только один диск они вся система как случае с рейдом и мы тем самым можно можем масштабировать как запись так и чтение на диске но из минусов минусы состоят в том то что придется писать свои какие-то изобретают свои велосипеды по поводу репликации вот и нужно хорошо и много внимания уделить надежности нашей системы который будет реплицировать файлы при этом как можно реплицировать можно раза репрессировать файл просто между двумя дисками можно реплицировать файл между двумя серверами одно мы выбрали в вариант то что лучше реплицировать серверами потому что при реплики чем фактору 2 у нас мы можем потерять как диск так и сервер потому что файл находится на разных серверах ними соответственно на разных дисках из плюсов не получили в том то что он нам больше не нужно разбираться с проблемами рейд массивов и геймерам которые он она предоставляет одно и диски стала обслуживать в разы легче потому что при смене при смене диска вот не запускается перья синкава не всего рейда вот соответственно не генерится не можешь нагрузки следующая проблема который может у вас возникнут при масштабировании это обычные дата рейса при этом как она выглядит ну вы рассмотрим солнце стороны ул м чаще всего те чаще всего проблема разработчики пытаются решить наивно вот если мы обновляем баланс мы проставляем баланс и используя мы просто при своему новый баланс и сохраняем запись тут проблема может быть в том то что если нам пришли два одновременных запросов там и с помощью рем их данные забрали сделали select сохранили их в объекте и в двух копиях одного и того же объекта у нас баланс остается такой какой он был до изменения вот и на себе получается мы баланс изменим один раз есть следующий вариант это когда мы используем наш р.м. мы пишем запрос который эквивалентен например там мы облетим таблицу вот выставляем баланс равен там баланс текущее значение баланса плюс то что мы тож и нам пришло на обновление вот мы с этим тоже могут быть проблемы и хороший вариант это использовать обновление баланса вместе со транзакций с транзакциями при этом используя необычный select все рекорды вот текущей код она он превратится в такой бы искал нотации вот и разница в том тоже сектор апдейт сделает он на время 10 загс и он уберет текущую строку вот из доступности пока мы не изменим ее и незрелым commit при этом на что стоит обратить внимание обратить внимание стоит на уровень изоляции данных в вашей базы данных и пару слов о разнице между рядками that i rep это был рид в мы с мамой скрыл и перк они редко редко метод работает так то что мы не можем читать данные пока с транзакции не придет к мид и в этом случае мы если пытаемся провести вторую транзакцию катать у нас идет текущая транзакция который не завершилась мы получим этому запишем и нажмите r и его можем если нам нужно это обрабатывать мы можем это обработать вот но из минусов в том то что иногда возникают локи вот при этом при реке тобол ритм и постоянно получается читаем тема загсу и если приходит вторая транзакциям и одна запись записываем перечитываем данные вот и обновляем уже на обновленных данных вот из плюсов она работает все шустрее не тут лаков но из минусов для кого то может быть кто то что нет индикатора того то что транзакция уже проходит вот ну какие выводы из докладов я могу дать вы видите на слайде вот то что ну и основная цель доклада в том то что бы вам нужно учитывать то то что ваш код работает не только на вашем компьютере и его нужно нужно еще принимать во внимание окружения на котором он работает вот у меня все вопросы спасибо за доклад у меня возник вопрос по ваши проблемы с разблокированным то есть до когда вы грубо говоря собираете у класть и ставить вперед балансир то есть балансиров такие методы как и пихаешь или айпи юную консистенцию то есть определенная ip-адреса попадают всегда на определенный сервер почему вы вот от этого отказались в пользу перевода сессий в базу ну как бы тут есть еще такая штука называется балансировка и балансировка это та еще проблема в общем когда у нас нет состояния нам легче разбалансировать трафик так чтобы нагрузить 1с одинаковое чтобы одинаково нагрузить все наши ресурсы вот при этом это тогда когда у нас не состоянии вот когда у нас есть состояние то с этим не много проблем ну да конечно можно использовать там сети балансировку но в этом есть в этом могут быть проблемы в том то что ресурсы будут нагружаться неравномерно спасибо спасибо за доклад открыть пожалуйста вы говорили что прогреваете кэш автоматически и вручную расскажите про автоматическое прогревание каша но мы пишем скрипты кроны но есть несколько вариантов того чтобы покласть данные в кэш там либо мы просто берём данные в сыра и мся получить на мы пока что из кэша если их нет мы переходим на генерацию вот это может быть не очень эффективна при нагрузке этот раз как вы выбираете какие данные вы сейчас разогрейте либо разогревать вообще все что у вас может и разогреваем все тот но у нас обычно есть какие-то кроме которые папа закидывай данные в кэш вот например мы перечитываем какие-то данные какого-то виджета на сайте вот и обычно это делается по крону то есть у нас есть эта штука ну и плюс есть какие-то скрипты которые один раз получат данные вот положим в кэш вот и таким большим вас но все делается какими-то скриптами понятно спасибо и еще вы показывали слайд мы прилегли где 10 клиентов teana или закачивают файлик по 10 там kbs собственно чё делать-то но мы ушли от рейдов напилили свой костыль вокруг репликации вот и стали хранить файлы просто на одном диске на разных серверах то есть мы пришли к тому то что мы отказались от рейдов в пользу обычных дисков это получилось шустрее потому что у нас мы можем масштабировать и опции вот получать больше больше производительность дисковой подсистемы вот и в этом случае когда мы grepolis уровень серверами вот при этом на каждом сервере на разные диски вот мы можем без проблем потерять все целые сервер вот а в случае с ритма силами ну можно конечно их потерять но это будет дороже спасибо и последний вопрос вот такси у вас какой рпс и какое количество нот обслуживает так но на текущий момент порядка 100 запросов в секунду от водители могут быть количество нот смотри там смотря смотря где смотря для чего ну вот в этом проекте фактор но и и не я понимаю ну как бы там сервисов много но очень если есть и говорит суммарно то там на все части может доходить до 3000 вот а всего сервисов порядка 60 которые запущены спасибо у меня такой вот вопрос вы сказали что вы отказали среду от рейдов сделали свое решение по репликация получается вот на мимо этого чувствует балансировщик которая выбирает откуда с реплицирует мы их инстансов получается забирать ваши статичные файлы которые вы реплицируются ну вы отказались от рейдов за счет того что вы можете сделать много реплицирует их вот этих нот сервисов своих и на них складывать файлы и основной аргумент пользу этого было то что рейды не дают такую производительность но в пересчете на количество дисков чем если бы вы расположили это по нотам так вы все-таки используете какой-то прокси для выбора и балансировки нагрузки забирания файлов с вот этих реплицирует их нот или вы таким образом просто скажем так backup делаете или этом failover какой-то там вся штука в том то что когда пользователь и закачивать файл вот мастер сервер куда можно закачивать файл он только один вот дальше этот файл реплицируется и там есть когда пользователь пытается скачать файл вот там есть хитрые алгоритмы которые знают где находится этот файл и просто пользователей редиректов на тот или иной сервер то есть все сервера которые файловые они все в интернете у них свои имена серверов и в зависимости от того ли этот файл мы можем также просто либо среди реактив на тот или иной сервер на котором он хранится вас если это какая-то картинка и она используется на ее нужно показать вот то в этом случае у нас то бишь вот если взять один какой конкретный файл а то он хранится я я так и не понял в одном месте или в нескольких местах и как вам хранится как минимум двух серверах да и ваш алгоритм выбирает на какой обратиться чтобы забрать файл на то бишь таким образом достигается вот это скорость скажем так то бишь один файл может быть забран скажем так с двух мест и при этом это может происходить параллельно верно но спасибо больше за ответ"
}