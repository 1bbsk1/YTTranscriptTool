{
  "video_id": "JPW3hw_eFaE",
  "channel": "HighLoadChannel",
  "title": "Как мы монгу физически бэкапили / Владимир Гошев (Yandex Cloud)",
  "views": 598,
  "duration": 2197,
  "published": "2025-01-17T02:35:25-08:00",
  "text": "Всем привет Меня зовут Гоша лади Я руководитель команды нереляционных баз данных в Яндекс облаке и расскажу как мы докатились до физических бэкапов А мой доклад сильно пересекается с предыдущим докладом Юрия и если вы его не смотрели возможно вам будет интересно потом посмотреть его в записи но в целом мой доклад самодостаточен и начнём доклад мой будет состоять из сначала введения о том что такое физические бэкап отличие от логических потом как мы создавали бэкапы как мы их восстанавливали нюансы шардирование кластере Мон А на каком-то среднестатистической кластере Мон потому что мы предоставляем услуги управляемой базы данных как внутренним так и внешним клиентам Поэтому нам нужно было решение которое будет работать для всех Вот это ну важное замечание потому что кому-то может показаться что оно избыточно в чём-то Итак логические физические бэкапы Наверное это очевидно но вкратце расскажу логически это когда мы сами да та данные дампе в случае монг - это бейн или Jon в случае с традиционных баз данных это SQL и мы игнорируем то как они физически хранятся на диске или даже не на диске физический же бкп или часто называемый бинарным - это резервная копия собственно физического представления данных но в случае монг - это файлики в случае почти всех баз данных - это файлики и у логических бэкапов есть как у любых бэкапов Есть плюсы и минусы из плюсов - это высокая совместимость причём в случае если мы не говорим про Мон а просто в общем случае Вы забка в условный mysql дампа можете немножко подправить Дамп и попытаться его экспортировать в тот же постгрес А в каких Ну в сложных случаях это не прокатит в простых прокатит а но в монге в целом тоже самое а его делать легко для этого есть стандартные утилиты мо Это мо в других базах ровно также называются он занимает Именно столько места сколько у вас данных его можно делать удалённо то есть просто подключились к монге сделали Дамп радуетесь и если вам нужно его частично восстановить это делается сильно проще чем с физическими бэкапа вы выбираете из него нужные данные их восстанавливает но и минусов хватает Первое это что данные не сжаты их нужно сжимать а далее а и самый главный Для нас это что бэкапы делаются долго и более того непредсказуемо долго а скорость снятия бэкапа она состо она зависит не только от объёма данных но и от их количества а то есть например если у вас одна запись на гигабайт это будет бэкапить сильно быстрее чем там миллиард записей по байту Хотя объём данных один и тот же а и это создаёт нагрузку на монго Ну соответственно вы к ней подключаетесь вы просите у неё п она тратит на это свои ресурсы а что касается физических бэкапов у них опять же есть минусы и плюсы Из минусов Ну это почти всё обратное плюсов логических это плохая совместимость между версиями то есть сняв бэкап с пятой Мон вы его сможете восстановить в пятую или в шестую а данные на диске могут быть фрагментированные системных данных ну то есть Вам сильно сложнее выбрать данные который вы хотите запивать у вас нет выбора и также нужно бэкапить журнал ну и главная проблема Это что не поддерживается в коммьюнити версии горячие бэкапы Ну горячие то есть без остановки самой базы данных но плюсы для нас перевес Первое - это минимальная нагрузка на мангу то есть снятие бэкапа с точки зрения ресурсов сильно дешевле клиенты не страдают пока мы снимаем бэкап и более в широком смысле В целом потребление ресурсов минимально что данные уже сжаты нам остаётся сказать монге что мы делаем бэкап скопировать файлики и радоваться жизни а то есть в итоге мы почти не тратим процессор тратим диск дисковый ео и сеть если делаем бка по сети соответственно и скорость зависит от ИО и диска и Ну как результат всего этого бэкапы значительно быстрее А что такое значительно я потом расскажу на наших примерах то есть скорость стремится к скорости диска или сети что у вас медленнее Ну и как следствие можно большие объёмы данных за то же время бэкапить А и главная проблема то есть главный минус - это то что в комьюнити версии нельзя делать горячие бэкапы то есть без остановки базы И как можно это решить первый самый очевидный вариант - это вы останавливает реплику рете у неё файли поднимаете реплику это просто это работает но вам придётся на очень большое время остановить базу А если у Вас одно стой кластер Это значит вообще он перестанет работать но в других случаях вам нужно выделять ресурсы на ещё один хост который большую часть времени ничем не занимается это дорого никто так делать не будет второй вариант модификация первого - это если у вас файловая система или файловая подсистема с поддержкой снапшота Ну в линуксе это либо lvm либо xfs либо zfs при xfs я набрал это btrfs ну есть различные файловые системы вы делаете snapshot Главное чтобы именно в этот самый момент Мон не писала на диск но для этого можно ей сказать в syn Log и ну делаете snapshot базу обратно Разблокируйте спокойненько копируете это в целом рабочий вариант Но нам он тоже не подошёл пото что у нас файловая Сима X4 lvm нет и прочее далее Это самый дорогой но в целом рабочий официальный вариант использовать mong db Enterprise Но это дорого поэтому мы рассматривать это не будем а самый доступный для всех - это использовать сборку от ны то есть Пина взяли коммьюнити версию сделали туда патчи в том числе для бинарных бэкапов и всем раздают то есть заходите качаете ВС работает но у нас как всегда свой путь у нас монго со своими патчами поэтому мы туда добавили патчи для бинарных бэкапов как это всё мы делали Юра рассказал и радуемся жизни но мало сделать поддержку бэкапов в самой монге надо эти бэкапы как-то делать если в случае логических мы просто используем стандартные утилиты в случае бинарных нам нужно использовать програмно обеспечение для этого из готового есть Ну и всё нам они не подошли но мы используем во всех базах данных и решили его приспособить под эти под это но вкратце что такое это свободная программа бес для управления это он наверное поддерживает различные базы pog mysql Green plam Mon redis etcd ну главное что он поддерживает монго возможно какие-то базы забыл Не суть важно а он это свободная программная бесс печение То есть вы его спокойно используете лицензия пач оно поддерживает шифрование что для нас опять же важно потому что у клиентов есть какие-то различные регуляции которые требуют шифрованный бэкапов оно умеет сжимать бэкапы нам это неважно но в целом в каких-то случаях важно оно поддерживает различные внешние хранилища мы используем S3 like хранилище Яндекс object и умеет Point in Time Recovery что очень важно и я расскажу почему Ну кроме того что Point Recovery Это важно Это очень важно для шардирование создание бэкапов в целом всё очевидно мы подключаемся к монге открываем п курсор получаем список файлив начинаем пинговать этот п курсор потому что копировать мы будем долго нам надо быть уверенным что монго не подумает что мы умерли копируем файлики и изначально мы просто скопировали все файлики ври Ну принесли обратно всё работает но когда мы взяли реальную базу данных большую оказалось что файлив там тысячи и сотни тысяч и Ну не то чтобы S3 от этого сломался но это не лучший способ это делать поэтому мы начали запаковывают с ограничением по размеру файлика В итоге у нас файлив не сильно много они не сильно большие Ну золотая середина не самая золотая но почти А после чего мы делаем этен курсор то есть запрашиваем файлы журнала их тоже сохраняем закрываем курсор монго начинает там делать свои дела и отключаем У нас есть бэкап Мы молодцы а но всё самое интересное - это восстановление с одной стороны всё очевидно мы скопировали данные мы возвращаем данные всё работает И если мы а если мы восстанавливаем тот же хост который копировали то действительно всё работает мы приносим файлики запускаем Мон она запускается но как только мы хотим восстановить Мон в новый кластер то есть новый реплика сеет который никак не связан с предыдущим у нас возникли внезапные проблемы монго поднимается видит что она в старом реплика сеете и пытается подключиться к своим бывшим соседям и Ну у неё может быть с ними связанность может не быть и Ну в целом это проблема на этот момент мы поняли что нам надо как-то её Ну мешать ей это делать И тогда в итоге у нас получился следующий план каж пункт из этого плана в целом содержит небольшую маленькую историю которую я наверное сейчас и расскажу а в первую очередь очевидно а но мы не сразу догадались проверяем что в ту версию монг которую мы восстановим действительно можно восстановить этот бэкап А ну на первый взгляд это очевидно но по факту клиенты пытались восстановить бэкапы там от версии 4 в версию 7 от версии 7 в версию 4.0 и прочее и прочее и это Нера Мон не понимала что за файлики тут лежат Поэтому просто добавили в проверку ну и нам стало лучше далее проверяем что мо не запущено опять же Это очевидно но не с первого раза стало очевидно нам это было нужно потому что если у нас восстановление не прошлого сделать заново мы могли забыть убить мон и Ну всё ломается а в общем случае логично что если монго запущена то Либо вы нечаянно запустили монго Либо вы нечаянно запустили восстановление из бэкапа автоматике это не понять поэтому мы просто падаем админист админ решит Что надо сделать либо убить монго либо не восстанавливаться далее мы удаляем все текущие данные это как правило мусор от прошлого восстановления приносим данные далее Мы помним что нам надо удалить информацию о реплика сеете мы запускаем Мон в Stand режиме То есть она не пытается подключиться к своим соседям удаляем все данные о выборах о реплика сеете и о шардирование про шардирование я потом расскажу почему это важно останавливаем потом опять запускаем говорим ей что надо восстановиться попло опять стопа Ну и в целом на этом у нас восстановлен а при необходимости запускаем как обычно и можем накатить aplog wg умеет накатывать аплок А ну это мы и делаем если клиент нас этого попросил Ну если не попросил то не делаем А после этого Вот Мы научились делать бэкапы научились восстанавливать бэкапы делать это достаточно быстро и у нас осталось два ну для того чтоб предоставлять пользователям больше данных у нас осталось две проблемы по факту не совсем связанными с бэками но тем не менее когда мы добавляем новый хост или старый у нас почему-то умер и мы его переливаем по умолчанию монго логической репликации наливает все данные то есть опять же нагружает кластер делается долго и не прогнозируем долго Мы подумали почему бы из более того в документации Мон есть небольшие ну такие отсылки что так в целом должно работать и попробовали сначала у нас ничего не получилось Ну с перенаем Хоста нет потому что хост добавляется у него логи все расходятся он переливается заново но после некоторого количества экспериментов мы поняли что работает следующий вариант сли хост сначала добавляем в реплика Хоста ещ не существует Поэтому при добавлении желательно его сделать скрытым чтобы он не мешал текущему кластеру мы его восстанавливаем поднимаем к нему подключаются соседи говорят Чувак ты с нами он понимает что он с ними накатывает аплок И все счастливы Ну с восстановлением уже ста который уже был в этом реплика е проще просто Прим информация реплика есть вс хорошо После этого мы и восстанавливаем и добавляем Хосты тоже из бэкапа и та проблема из-за которой Мы перешли к физическим бэкапа То есть то что медленно восстанавливаются медленно делаются бэкапы медленно создаются Хосты у нас ушла имы смогли предоставлять значительно больши обх клиентам Вот Но об этом ещ потом Кратко скажу после того как мы научились работать с одношаровий а и тут Наверное стоит начать с того что такое шардирование Поднимите руки кто вообще ну знает пользовался шардирование Ну примерно половина зала поэтому я очень кратко расскажу для остальных То есть когда у нас данные перестают влазить на один сервер на один шарт нам надо как-то сделать так чтобы данные были на нескольких серверах А в базах данных это это достигается шардирование То есть у вас есть какой-то координатор который знает где Какие данные хранятся есть отдельные куски данных шарды и клиент э при помощи координатора обращается к данным в постгрес для этого коллеги запили spqr в монге это есть из коробки и достигается тем что поднимается отдельный Мон S - это stateless сес к которому обращается клиент который всё координирует балансирует и прочее Мон cfg - это в целом тот же монд только запущенный в особом режиме он содержит метаданные для шардирование и каждый шарт он это отдельный реплика сеет который очень слабо связан с остальными и какие у нас возникают проблемы в плане бэкапов то что каждый шарт - это отдельный реплика сеет отдель река данные могут переезжать между шарми и консистентность сложновато если с переездом всё просто мы можем отключить балансировку на время то с консистентность становится сложнее А я чуть позже Расскажу какие есть варианты но с чего Мы начинали у нас значит есть бэкапы каждого шарда мы восстанавливали их в отдельные кластера потом как-нибудь вли кластер в целом можно использовать de безум мы использовали этот трансфер в Яндекс облаке штука для перекладывания байти ков и дальше надеялись что Всё будет достаточно консистентной работало и тут на моменте когда мы это всё переносим в шарди кластер у нас сначала возникла проблема ну самое логичное мы установили всё все шарды в отдельные кластера кого-то из них начали шардирование Ну мы подумали что что-то флап нуло удалили кластер сделали заново и он опять упал тут мы догадались что всё же это что-то системное после изучения мы поняли что у Мон в системных коллекциях кроме прочего написано что она состоит в каком-то шарнирном кластере Вот у неё монго фг сервера и прочее и прочее и когда мы говорим что она стала теперь в шарди кластере она ищет эти мор которы ей уже недоступ потому что нет связанности с прошлым кластером и Слава Богу что нет иначе было ещё хуже И падает поэтому мы начали удалять в том числе информацию о шардирование из бэкапа при восстановлении А когда мы попробовали ручной способ и поняли что в целом как-то достичь этого можно мы пошли искать Как же это максимально автоматизировать и в целом есть два подхода это как делает перна и в целом как говорил Юра мы во время бэкапа делаем экстен курсора до единой точки во времени а но в чём проблема этого подхода что вам нужен какой-то координатор который всем скажет До какой точки во времени надо делать бэкап Нам очень не хотелось этого делать потому что ну нам нужно было опять же какое-то общее решение которое будет работать на всех а на каждый кластер делать координатор дорого Один на всех - это дыра в безопасности делать какой-то гибридный вариант это и дро безопасности и дорого ещё и сложно мы обязательно где ничего Не сломаем поэтому мы попытались найти другой способ и нашли Ну Иначе бы я не рассказывал а вместо общего координатора мы делаем пы как попало но вспоминаю что лжи умеет в Point in Time Recovery он это делает путём сохранения ога мы можем восстановить бэкапы как попало а потом при помощи оло догнать до единой точки во времени мы попробовали и это прокатило В итоге А ну процесс создания бэкапа достаточно прост мы просто делаем бэкапы каждого шарда начинаем их примерно в одно время просто чтобы они примерно в одно время закончились и надо было меньшее количество облога нагонять а далее Это чисто наша инфраструктурная штука создаём такой Мета бэкап где говорим что вот у тебя есть такие-то бэкапы это опять же нужно для того чтобы пользователь не пытался восстановиться из одного бэкапа за сегодня одного за вчера одного там с прошлого года потому что как показала практика пользователи иногда хотят странного и процесс восстановления чуть сложнее но в целом очевиден исходя из моего всего доклада мы создаём кластер с таким же количеством шардов и тут очень важно что нам нужно именно такое же количество шардов а не там чуть больше чуть меньше нам не прокатит а потому что в монго cfg у нас хранится Мета информация где Какие данные хранятся и если у нас реальное количество шардов будет отличаться то Ну Мета информации будет неверной Поэтому сначала создаём восстанавливаем потом пользователь Если хочет добавить шардов удалить шардов далее мы смотрим Когда закончился самый свежий бэкап самый свежий бэкап из бэкапов шардов и запоминаем эту точку что мы можем восстановиться не раньше чем на эту точку Точнее не позже то есть ближе к сейчас мы можем дальше не можем А ну иначе он будет не консистентной восстанавливаем все шарды при помощи оло накатывать попросил ближе к нам то на более новую точку но помним что не можем на более старую точку восстановить запускаем правим информацию о шардирование и радуемся всё работает и в целом можно уже подвести итоги Я как-то очень торопился А что нам это принесло первое самое очевидное это что мы значительно ускорили создание и восстановление из бэкапов если раньше у нас кластера под 300 гигов могли б Капица целые сутки то сейчас мы ну экспериментировали на кластерах до 4 ТБ и в целом это работает но учитывая что скорость зависит от скорости дисковой подсистемы тут ну почти что в них упираются тут можно почти бесконечно Ну как бесконечно чем быстрее у вас хранилище тем больший объём Вы можете предоставить в нашем случае мы решили что безопасно предоставлять около 2 ТБ в теории можно больше но тут уже есть различные нюансы А мы также научились добавлять и восстанавливать Хосты из кПа Что также и тут я забыл уточнить Сейчас расскажу историю Ну почему добавление то есть кроме того что это было долго а добавление Хоста один из сценариев что у вас всё горит Ну у вас есть база есть какие-то Клиенты в какой-то момент база перестаёт справляться ваше очевидное решение - это или накинуть ресурсов А чего возможно Ну в каких-то случаях Невозможно или добавить ещё один хост чтобы нагрузка хотя бы на чтение размазала на хост но вы добавляете хост этот хост идт в Мастер ну или в реплику говорит Дай мне данные нагружает кластер ещё сильнее У вас вообще всё ложится вы бежите в Саппорт и говорите ой у нас всё сломалось вы плохие Ну кто-то не бежит но в целом ничего хорошего не происходит поэтому когда Мы научились добавлять Хосты из бэкапа получилось что хост создаётся тихо восстанавливается из БПА не трогая остальной кластер потом поднимается нагоняет аплок за прошедшее время и значительно меньше нагрузка на существующий кластер плюс Это значительно быстрее и последнее Мы научились Пите и главное восстанавливать шардирование что мне кажется интересным У нас есть некоторые Наполеоновские планы Куда дальше стремиться в этой теме А первое о чём я так скромно умолчал Когда вы добавляете хост или восстанавливается из бэкапа бэкап делаете вы как правило не сильно чаще раз в сутки Ну кто-то реже но чаще чем раз в сутки вряд ли кто-то делает бэкап но всё время мы откладываем алок в S3 если мы восстанавливаем СТ Ну добавляем или устанавливаем из бэкапа и в самой монге оло уже не хватает то мы просто зря потратили время зря Ну зря восстанавливали хост придёт в Мон монго скажет у меня недостаточно Лога иди перелива се с нуля но так как мы сохраняем мы этого ещ не пробовали но скорее всего должно прокатить Мы можем взять wg Взять реплику которая отстала и накатить этот олог из S3 и в ближайшем будущем Мы будем учить жи и нашу инфраструктуру этим делать далее один из плюсов логических бэкапов был в том что мы можем частично восстановить бэкап потому что частая причина почему вам хочется воспользоваться кпом это кто-то сломал одну табличку в случае Мон одну коллекцию там неважно подро пал все данные или сделал апдейт без указания условий то есть про апдейт всю табличку при этом не использовал транзакции или просто сказал комит и пофиг А ну то есть часто вам нужно востановить только одну коллекцию Ну или одну базу в случае с логическими это делается достаточно просто особенно если вы делали п не одним файло а ну каждую коллекцию В отдельной то физическими не так просто потому что у вас есть файлы коллекций более того в монге файлы коллекции с названием коллекции никак не коррелируют так скажем как минимум на первый взгляд во-вторых У вас есть файлы журнала который содержит в себе информацию не только о вашей коллекции но и остальных Ну и есть алог но с логом проще он логически мы можем понять что в нём находится А это и мы хотим научиться в такое восстановление опять же научить wg Ну и научиться сами в целом есть идея как это сделать И самое такое Кунфу которое мы хотим когда-нибудь в будущем сделать - это частичное восстановление в уже существующий реплика сеет то есть опять же вы сломали какую-то табличку или коллекцию а ну сейчас единственный вариант восстановиться в новый кластер и как-то данные перенести из нового кластера в старый А ну это не самое удобное было бы удобно восстановиться в тот же кластер тут Пока что нет идеи как мы это будем делать Но скажем так есть уверенность что у нас всё получится и на этом У меня в целом всё большое спасибо Ну и т подведены итоги Владимир Большое спасибо за доклад прежде чем мы перейдём к секции q&a по традиции Ребята пожалуйста оценивайте доклады вот QR код там сложно там надо будет попытаться его сканировать так чтобы второй не попал Вот но оценки очень нужны и важны Если вы смотрите нас онлайн Пожалуйста задавайте вопрос через платформу он попадёт там в чат и я его тоже зачитаю либо можно просто написать вопрос в чат зала и я вот прямо чувствую что будет очень много вопросов вот с этой стороны нашего зала вот поэтому начнём поднимайте руки есть ли Вопросы ожидаемо Спасибо Вова Спасибо за доклад Вот ты говорил что в модели перко обязателен какой-то внешний наблюдатель который будет следить за тем В какой момент был снят бэкап С какого шарда и запрашивать дополнительные валы Почему нельзя было сделать так чтобы на различных кластерах на различных Шарх сами общались между собой и как-то шари эту информацию Хорошая идея но тут дело в том что опять же Ну то есть нам Ну скажу честно мы не сильно рассматривали именно такой вариант когда Ну какой-то МШ условно говоря Ара выде координа Но что мне вится изб написать во лжи клиент серверную штуку которая типа вот тебе конфиг вот чуваки которые твои как бы соседи Найди из них кто Ну сейчас ну короче если коротко Мне кажется это пере усложнит если длинно Ну если Вопросов нет я могу на 5 часов этим порасскажу не бэками А вот созданием своей ш сети Кто главный кто не Главный где где бэкапы где не бэкапы сам это делай Спасибо ответ устраивает хорошо здесь ещё был вопрос Спасибо Да Привет Меня зовут Игорь Спасибо за рассказ Вопрос такой Я правильно понял что это всё в уже есть в Мастере а при этом это требует каких-то патчей в монго А да а то есть да в wg это есть и это есть уже пару лет как Ну и мы пару лет как используем А в монге да то есть у вас по сути три варианта либо вы используете Enterprise и wg тестируется на энтерпрайз Ну там лицензия позволяет для таких целей энтерпрайз бесплатно использовать Либо вы можете взять Мон от пико Это самый Ну я бы рекомендовал вариант потому что она это коммьюнити версия под Коти лицензией Ну она с какими-то фишками из энтерпрайза лучше у перко там посмотреть ну одна из них это бинарные бэкап третий вариант - это да пропатчить Мон Ну вот Юрий рассказывал как это делали мы Ну я бы рекомендовал просто па есть где-то Ну укон есть например ну то есть Наших патчей нет потому что ну тут начинается то есть если Мы выложим патчи мы начнём сри с монгой Ну ну там короче сложные юридические штуки то есть Наших нет но новки вы можете посмотреть Спасибо есть ещё вопрос первый ряд правая часть зала Спасибо за доклад вопрос будет работать с пиковский он будет сам это не смотри сейчас ну новская ну новское решение в лице монг - это монгас пропана она Ну в плане бинарных бэкапов пропана также как наша Ну там Наверняка есть детали но интерфейс тот же плюс у них есть отдельное Ну решение там пинап менеджер или как-то так назв которое ты ставишь где-то координатор на Хосты ставишь аген но вместо лжи как-то бы капит монго Ну я сейчас не не скажу Как проще это в у перко прочитать мы вместо этого используем лжи Ну и просто ему на каждом шарден что вот ты тот всё пятое десятое хорошо Спасибо ещё вопросы справа Нет по центру нет Лева есть второй ряд левая часть зала Э спасибо за доклад Меня зовут Роман Вопрос вот по прошлому и этому докладу я понял что мы делаем полный бэкап то есть вот у нас есть список файлив мы их все всесв пим вот если мы через неделю делаем следующий бэкап нам Придётся делать снова полный а построить инкрементальный вы не пытались у меня была Эта мысль Я кстати хотел это в планы добавить Спасибо за ложение скорее не вопро что нет понимания как это делать ну сейчас то есть мы хотим это если кратко отвечать мы это хотим сделать но не знаем как если Чуть более полно если взять там тот же кликхаус тот же гнп там есть специальные типы таблиц Где мы можем быть уверенными что вот эта часть таблички не изменялась то в монге Ну простого способа я сечас не вижу есть намдо вот ну понять что менялось что не менялось Мы конечно можем просто там ста тамм проверить Файлик вообще менялся за последнюю неделю или нет но проблема в том что вы там добавили один байтик в конец Ну по-хорошему вам Этот один байтик и надо за бэкапить А ну короче вот так то есть я пока не представляю как это сделать но мы не сильно исследовали но хотим но потом отличный вопрос Спасибо большое Судя по всему вопросов больше нет поэтому Владимир нужно выбрать тот вопрос который понравился больше всего или который ты считаешь лучшим Ну мне кажется последний вопрос Вот про инкремента вопрос да поддерживаю мы дарим кастомную матрёшку и книгу Ну и конечно Спасибо тебе большое что пришёл выступить мы тебе тоже дарим подарок от конференции Приходи к нам е и этом самом по как Вы наверно знаете у нас заключительный доклад"
}