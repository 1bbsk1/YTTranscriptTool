{
  "video_id": "oUdZOwX0Ilw",
  "channel": "HighLoadChannel",
  "title": "Наблюдательный пост пессимиста / Александр Афенов (Lamoda)",
  "views": 866,
  "duration": 2936,
  "published": "2020-04-14T11:05:19-07:00",
  "text": "всем привет спасибо что пришли не раз меня уже представили я сразу начну с классическое упражнение с поднятием руки у кого когда-нибудь системах что-нибудь взрывается руки подняли не все я полагаю что у кого то просто ничего нет продакшене да поэтому поэтому видимо так более того по своему опыту у нас обычно взрывается что-то и в киеве среде разваливается что-то связанное там у нас в каких-то этапах еще остался nomad например что-то там ломается иногда сломается дев среда я думаю те кто с командой из которой долго работал посмотрят доклад будут долго и грустно смеяться и плакать на тему того как у кого-то там на маке сдох докер о чем собственно пойдет речь и вообще кто и на этот вопрос я регулярно себе пытаюсь ответить ответ каждый раз разный и раньше я например был тем вредом и в моем видении была пара бизнес критику сервисов за которые надо было отвечать и если в них что-то шло не так то но это останавливало какие-то реальные бизнес процессы например заказы переходили там переставали выходить на склад или и клиенты не могли вернуть свои деньги за вещи которые они уже нам отдали обратно и так далее недавно ситуация изменилась я стал direction ли дом и теперь я отвечаю за в 3 в 4 раза больший объем и мне хочется хоть немножко понимать что происходит в каждой системе что в не может сломаться что в них хорошо и собственно в рамках этого доклада я поговорю о том как мы такие задачи в целом по компании решаем что мы мониторим как мы мониторим и что мы самое главное с результатами этих наблюдений делаем в связи с тем что систем много хочется иметь хотя бы иллюзию того что мы точно понимаем что все хорошо или что мы можем легко локализовать что конкретно сломалась и так как все системы так или иначе релизиться в них что-то меняется что-то случается с техникой то бомбит постоянно то есть открываешь смотрит что насыпалось пытаешься разобраться до бы уйти уже топаза стр акции перейти к примерам начну с первый из них мы используем мои сингл в качестве а лифтинга и вот одним теплым летним утром без объявления войны как это обычно бывает у нас сработал мониторинг который сказал нам примерно следующее что осталось 50 geg какого то жесткого диска где-то для кого звучит страшно нурук немного даже не пятая часть эту аудиторию окей хорошо а если так страшнее да согласен мне тоже стал немножечко нехорошо но в целом если подумать но что такое 50 гигабайт это такой заметный объем для база кажется то есть у многих вот с кем общаешься где-то там на собеседованиях про на конференциях в любом общении не у всех база столько весит то есть кажется что если столько места еще осталось наверное все неплохо но это не так если база весит полтора терабайта скорее всего 50 гигабайт это в общем капля в море она закончится очень быстро окей мониторинг сработал классно что он был здорово же правда мы решили посмотреть сколько нам осталось надо понимать что это не какие-то виртуалке это железные сервера базы под большой нагрузкой там стоит предположим как раз полутора терабайт на ssd и он скоро подойдет к концу и мы начинаем смотреть считаем кажется что нам этого хватит ну на 20 30 дней это очень мало нужно оперативно решать проблему потом через пару дней мы уже думаю о том как мы это за фиксе полнитель на проверяем сколько на самом деле из расходы израсходовалась времени за один-два дня и понимаем что 50 гигабайт хватит примерно на 5-7 дней после чего сервис который работает с этой базой предсказуемо закончится какие последствия у этого он классно что мониторинга вроде бы был до но впоследствии такие что тут же начинаем думать что сейчас мы сейчас супер срочно заархивируем по ударяем все исторические данные которые нам уже не нужны узнаем что у нашего огромного такого департамента дата analytics есть все наши backup этом десятки терабайт данных мы можем спокойно дропнуть все что старшая 2015 года пробуем удалить и вспоминаем что в москве ли это так с полпинка не сработает удаленные данные это замечательно но размер файла выделенного под таблицу и на тебе в нашем случае он не меняется мой скальп потом перри использует это место заполняя пустоты то есть проблема не решилась места больше не стал кризис продолжается пробуем другую историю филлеры the temples перевоз табличек с быстрых заканчивающихся ssd более медленные выделяем таблички которые вроде бы не жалко они не под большой нагрузкой намного весит для этого используем перка навский мониторинг пмм и смотрим где у нас самые большие индексы самая маленькая при этом нагрузка в общем смотрим на табличке там сотни гигабайт который можем перетащить на медленный диски окей перевезли и уже думаем о том чтобы переехать самими серверами уже был план это делать изначально мы разумеется это в итоге провернули сервера в которых теперь не полтора 4 терабайта ssd можно будет немножко подождать пока она снова вместо закончится и до решили в общем пережать очень как-то потушили и конечно пофиксили мониторит ну типа поставили что теперь варнинг будет зарабатывать там не на 50 гигабайт их и скажем на полутора байте critical значения мониторинга на 50 гигабайт но это в действительности лишь как я тогда называют затыкание тылов одеялом до то есть на какое-то время этого хватит но потом эта же история повторится только уже в более библейских масштабов и если мы опять допустим такую ситуацию в чистом виде не раздробив базу на части не задумавшийся шар денги о том как мы храним и какие данные закончится плохо и это один из пунктов которые я постараюсь в рамках этого доклада донести что не стоит просто тюнить мониторинге экстенсивно что-то менять свои системе оставляя все на самотек и приходя к повтора того же самого и один из моментов который мог бы нас спасти и которому хочется прийти это ревью мониторингов здесь я сделаю супер маленькое вступление рассказываю о многих концертах в этом докладе я говорю о том как мне хотелось бы все видеть каждый раз когда я готовлю доклад я стараюсь рассказать как у нас есть и чуть-чуть приукрашивают добавляю туда идеи возникшие в процессе с тем как хотелось бы с этим докладом точно такая же история то есть я с одной стороны рассказываю вам все то что мы уже умеем добавляю сюда то к чему мы хотим прийти так вот про review мониторингов если бы мы регулярно смотрели на то что у нас есть мы бы могли подставить это под сомнение обновить за фиксить не допуская такой ситуации для этого нужен какой-то внятный понятный список у кого есть полный список мониторингов которого заведены это страшно ну то есть я вижу примерно 5-6 рук а здесь человек приблизительно 200 вот еще одна рука несколько раз поднялась на она считается за 1 все равно соответственно список откуда-то нужно взять да это процесс на история больше не технической и желательно не в репозитории а вот сегодня обсуждали тему того как у нас и что конфигурируется у нас есть конфи кайтинге с абортами там сейчас четыре тысячи шестьсот семьдесят восемь строк в принципе можно туда конечно посмотреть закончится это скорее всего непониманием того о чем говорит каждый конкретный мониторинг что я имею ввиду допустим что наша метрика называлась как-то так db disk space лифт ok я-то знаю о чем речь другие люди скажем технической поддержкой так далее могут быть не в курсе ну что-то про свободное место здорово хотим копнуть глубже идем смотрим на конфиг этого мониторингов понимаем в откуда он берется нашем случае там например прометей в частности там сейчас мы заехали сделали танос у этой метрики есть название и есть ограничение соответственно когда включать warning мониторинг alert когда сообщает что ситуация критическая мне допустим стала бы понять не если б ковырялся в этом конфиге но предположим той же самой службы поддержки которые нас как правило спасает 1 получает все alert и дальше звонит дежурным скорее всего эта информация бы ничего не дала поэтому чего хочется хочется чтобы у мониторинга было описание то есть что это значит в понятных сравнительно простых терминах где этот мониторинг расположен что это за чисел k метрика чтобы с ним можно было как-то работать и скажем пойти потом в интерфейс того же самого прометея и посмотреть динамику как она менялась какой был трат хочется чтобы в описании мониторинга были последствия то есть чем закончится если мы с этим ничего не сделаем у нас часто полыхает куча мониторингов на которые можно запить и произойдет приблизительно ничего не для клиентов не для нас самих то есть это мониторинге сделаны это мой возможно зря об этом мы тоже поговорим и нужен понятно action points то есть что делать если мы говорим о том что служба поддержки первый ряд ведь на эти мониторинге было бы классно чтобы прикладывалась ссылка на описание у нас такая практика есть и даже в конфиге лесенке сразу валяется ссылочка на confluence где как раз описание мониторингов по системе которые я занимался на протяжении почти четырех лет таких описаний в основном нет болезни сейчас я занимаюсь процессом как раз такого но варит шеренгой попытки собрать всё это воедино как раз повод такой схеме и вот так хотелось бы по каждому мониторингу тогда можно выстраивать хоть какой-то процесс рири этого дела и корректировки иначе скорее всего все закончится плохо каким образом будет его еще можно добиться мы допустим служба поддержки передаем новые мониторинге по принципу хоп что-то пролетело в telegram это не всегда работает хорошо потому что если служба поддержки к работе с этим мониторингом не готова и нем ничего не знает надеяться на внятную качественную реакцию устранения последствий почти невозможно поэтому хотелось бы чтобы такое описание поступала на вход и если вы хотите чтобы вам об этом сообщали мониторинг вам сыпался он обязательно заводится сразу вместе с описанием это еще решает проблему осведомленности команды потому что был классный кейс когда наш технический директор проходил мимо команды показала пальцем на телевизор swap к одному из два пера в задал вопрос типа от что вот тот график значит а ему не смогли ответить кажется это не очень хорошо ну то есть а зачем он тогда там висит то есть кто в этом разбирается здесь есть кто-нибудь кто отвечает за системой понимает что вот он знает что делать если все разнесет а команда нет есть такие кто нибудь урок малого его стали все хорошо классно я за вас очень рад в общем предположим что мы тоже разобрались с этой истории возвращаемся к теме с базой у которой кончились диски предположим что мы решили куда-то переезжать менять сервера есть там стратегия по этому поводу и на каком-то этапе при перевозе потребовался ри стартануть мастер наверное в этом случае появиться какие-то ошибки мы предполагаем что есть dmtn в нашем случае он был порядка 30 секунд но запросы идут писать никуда все не очень хорошо посыпались какие-то ошибки даже может быть сработал некий мониторинг но тут мы переходим к следующему этапу куда кроме прометея все на сыпется прометея мы увидим какие-то чисел ки что там метрика не знаю там 500 их ошибок или там не возможностей создать заказ подскочил ok но мы не знаем деталей какой именно заказа например не создался да и тому подобные вещи мы используем в этом плане центре собственно позволяет прям онлайн наблюдать таким образом разворачивается очередную фиаско со всеми деталями и в этом случае мониторинг нам как правило например после релиза сообщает что что-то сломалось и что именно благодаря центре мы можем детально посмотреть как на конкретном контексте данных совсем stack trace а мы всем тем что еще мы туда смогли дополнительно присунуть в печке проектах мы используем рейвен клиент дополнительно обогащаем разными данными центре все это красиво агрегирует и мы видим по каждому пока папа каждой ошибки динамику как часто происходят и можем посмотреть на примерах какие запросы не удались какие к собственно вылетели стандартный нашу space мы выкатили какой-то релиз получили например alert и от нашего cabernet с т.к. он мониторится мы можем посмотреть на состояние соответственно кодов на то какие версии приложения куда бы то ни было выкатились чем закончился deploy все ли хорошо дальше мы заглядываем в уже упомянутый первым смотрим что у нас с базой с нагрузки на нее богров она бардом мы смотрим на примерное количество контактов крепи ту который иногда становится критическим потому что rabbit он клёвый умеет протекать у него заканчивается памяти и он имеет свойственно умирать мониторим эти штуки а потом проверяем центре собственно приблизительно так это выглядит какая класная штука по инн в том что можно обратить внимание на то что в очередном релизе к примеру ошибок стало резко больше чем обычно можно в итоге зайти внутрь посмотреть что конкретно сломалась и потом если нужно по контекст и доставить не знаю не удавшееся заказы их починить это более чем удобно и классная штука без которой все это изрядно бесполезно это привязка jiri нашем случае такой ticket tracker task tracker нажал кнопочку в жире создался изначально довольно бесполезный task со ссылкой на центре с так trace'ом и он помечается определенными лейблами как мы это используем это важно в центре что-то насыпается создаете задачки в jiri на то чтобы существующей центре проблемы исправить и один из разработчиков принес хорошую прям толковую инициативу такой проект под названием типа чистый проект чистый центре идея его довольно простая то что каждый раз когда мы планируем очередную операцию и мы прикидываем что мы возьмем из технического батллога мы закидываем туда хотя бы одну две задачи из именно задачи помеченных что они были созданы из центров поясню зачем если все время что-то светится все время что-то сломано то это неизбежно в итоге становятся ощущением ложным как правило нормы и эта история наверняка многие слышали башни волки волки про мальчика который постоянно кричал что прибежали волки есть совет хотя это было не так и ему перестали верить а потом все разнесло по настоящему этого кейса совершенно точно не хочется то есть сейчас вот у меня конкретно по системе есть мониторинг который взорвал взорвался 23 июля и он горит красненьким такой один остальные вроде потушились оперативно он вроде бы не критичный но тот факт что там постоянно что-то красное есть службы поддержки например вводит в заблуждение что это адекватная ситуация и когда сломается что-то по-настоящему страшно и это возможно будет проигнорировано и тут мы переходим как раз к таким косяком в мониторинге собственно фолз позитифон сны где в кейсе первое это то что долгое время наблюдалась по системам с которым я работал мониторинг который постоянно алитет у него есть какое-то пороговое значение там не знаю как только есть один негативный avent он тут же начинает спамить нас там в telegram флаг в службу поддержки повсюду и это постоянно отвлекает как раз замыливается взгляд и все привыкают что эту штуку все время ломается когда-нибудь это обязательно унесет кучу денег и обычно эти мониторинге в итоге тянет и тянет их как правило ну например дежурный которая все время будет классический кейс мы там проект который отвечает за разор processing он очень много работает с системой автоматизации склада передает туда данные если система склада релизиться это обычно семь утра у нас вспыхивает мониторинге все привыкли все в итоге на это забивают что они очень хорошо было бы разумно эти мониторинге по тюнить подобрать соответствующие окна и так далее например через прометей связать собственную факт релизов конкретной системы и некоторых alert of и просто не врубать их у этого есть свои impact в частности под импактом я подразумеваю этот факт что человек просто как раз воспримет это за норму перестанет реагировать и отвечать на звонки и службы поддержки и так далее еще бывает хуже тоже такой пример когда кругом все хорошо вы добавили какое-то количество мониторингов систему ни один из них не стрелял и кажется что все нормально допустим что авто тесты проходят все написанные все зеленое все здорово в действительности например какие-то данные из вашей системы уходит в другую в моем примере там система обработки заказов придут данные на склад но какие именно данные нигде никак не вы лидируете не подсчитывается и не мониторится например есть какой-то абстрактный счетчик того что обмен и уходят у нас где-то используется джейсон рпц где-то используется saab в этом кейсе saab обмен данные ходит значит все хорошо мы считаем что системой все здорово в действительности как-то так он может выглядеть где там зелененькая часть это входящие обмен и желтые исходящие например на самом деле есть конкретный кейс котором все было на самом деле совершенно не радужно данное действительно уходили но кривые конкретный например кейс в ситуация в которой заказа которые например не были изначально оплачены пометили как оплачены в этом случае конечный покупатель сможет их в итоге забрать бесплатно кажется что это страшно или еще веселье наоборот человек оплатил заказ приходит его забирать его просит оплатить из-за какой-то ошибки в системе которые не мониторится техническими метриками но в итоге выстреливает так вот в итоге все все равно заканчивается плохо несмотря на наличие каких-то мониторингов и тут мы все цена подходим к тому что какой-то вывод из этого наверное требуется каким образом этот защищаться предлагается наблюдать не только за техникой но и за метриками реального мира и бизнеса это казалось бы очевидная вещь которая постоянно почему-то оказываются забытой когда запускаются новые сервисы а мы это делаем часто и регулярно все обмазывают их по максимуму метриками сугубо техническими связанными с диском процом чем угодно и забывают про бизнес который этот конкретный сервис автоматизирует и призван ему помогать предлагается мониторить бизнес показатели так кажется хорошей идеей и в предыдущей кейс это могло бы решить ну например следующим образом есть конкретный такой мониторинг который следит за количеством заказов требующих оплаты при получении любые серьезные скачки в подобного рода метрики могли бы обратить на себя внимание и понять что что-то пошло не так и что несмотря на то что в технических метриках все хорошо если обмена ходят у нас что то очевидно поломалась например с очередным релизом еще мы смотрим на такую штуку критично опять же для нас как для интернет магазин и сервис провайдера который работает заказами только количеству созданных заказов то есть у нас есть понятный коридор сколько их обычно в какое время суток с поправкой какие-нибудь маркетинговые акции мы за этим следим если что alerts еще важная штука если клиент многократно заказывает на один и тот же адрес мы склонны не мучайте вообще не мтс колл-центром автоматом подтверждать заказ если в этой системе что-то сбоит она сильно влияет на клиентский опыт из-за этой штукой мы тоже стараемся следить релиза разные системы могут на нее довольно сильно влиять и это тоже чисел k требующая мониторинга в общем можно наблюдать на самом деле за очень и очень многим и вопрос кто это будет делать потому что команда разработки но не факт что с достаточной мере погружена в бизнес и сможет полноценно за этим следить и тут есть несколько направлений то есть у нас конкретно везде болтаются телевизора на которых есть куча разных технических и бизнеса вых метрик но кроме нас за этим следит службы поддержки у которой по большинству слова срабатывающих alert of есть те самые ранее мной описаны инструкции из которых можно сделать вывод что срабатывание определенно валерка ведет к определенному business impact уэда ситуация должна быть разрешена за какой-то небольшой промежуток времени критичность каждого возможного инцидента определяется совместно с бизнесом и для того чтобы еще бизнес мог за всем этим следить глаза перина своя небольшая систем к real-time дашборд изначально она делалась совсем другой целью мысль была в том что у бизнеса есть план сколько мы например хотим продать заказов в каждый конкретный день грядущего месяца это планирование которое как правило есть у любого магазина и эта система просто показывает график и соответствия сколько мы планировали сколько мы сделали по факту и были конкретные кейсы в которых например эта система она берет данные из продакшен базы читают оттуда на лету и показывает сравнение планы и факту она читает данные счастлива mais quel базы данных но была ситуация в которой у нас развалилась реплика на это не было мониторинга мы не успели об этом узнать с точки зрения техники но бизнес увидев что мы не до выполняем план прибежал с комментариями что кажется мы отстали на 10 там условных единиц тысяч неважно чего по количеству заказов которые должны были продать мы начали разбираться как так могло произойти что мы этого не заметили оказалось что просто читаются не актуальные данные сломаны реплики за фиксили поехали дальше то есть это кейс которым и бизнес наблюдает за интересными им показателям и при этом мы можем друг другу помогать при возникновении каких то проблем еще один мониторинг реального мира который есть который уже достаточно давно в разработке постоянно юницу там каждый из команд это специфическое такое название jira вэйдер система которая позволяет нам не следить здесь я лучше буду использовать другой термин наблюдать за процессом разработки что имеется в виду эта штука предельно простая печки фреймворк symfony ходит в jira api и забирает оттуда кучу разных данных о задачах спринтах и так далее зависимости от того что системе было дано на вход и регулярно пишет метрики связанные с командами и их проектами в параметре где они уже мониторится лица выводятся в grafana и так далее и благодаря этой штуке итоги можно следить за например такой вещи как work in progress то есть мы мониторим то как долго у нас задачи находятся в работе с момента когда кто-то нажал кнопочку in progress еду выкатывание в пруд если это число слишком большое скорее всего теоретически это говорит о наличии какой-то проблемы с процессами команды описанием задача так далее самой по себе недостаточно хотя это важная метрика еще можно смотреть на условно здоровье спринта что допустим подходит да ты его завершения все спринт и у нас синхронизированы календарные между командами а задач например осталось которые еще не выполненную слишком много либо например есть там проблемы с лакирования времени если для вас это важно если в принципе восприняты его логировать нехватка релизов слишком большое количество задач который в статусе ready for release но никуда не уехали в конкретный кейс у нас он часто бывает из-за предположим код фреза перед какой-то большой акции такой как черную пятницу просадка в тестировании куча задач и висит не testing за этим там никто допустим предметно не наблюдает это тоже можно мониторить зачем это в целом позволяет снять огромное количество ручной работы с того кто отвечает в команде за процессы будь то хоть менеджер хоть тимлид не суть состояние бак логов тоже позволяет оценить недавно мы допустим взяли технический backlog одного из проектов порезали там с-400 задач до 150 путем просто повальные отмены и понимание того что многое не будет сделано и факт разрастания этих бак логов тоже в общем подается мониторингу в общем при желании это может быть все что угодно если кто-то может быть смотрел творчество ребят из гитлер я допустим мониторе у себя такую штуку как количество паре квестов от разработчиков во внерабочее время в частности там после восьми вечера например и когда по кому-то подобные метрика выстреливает это может быть тревожным знаком что человек или бы что-то не успевает либо вкладывать слишком много сил и рано или поздно просто перегорит этот конкретный удобный кейс того что можно мониторить из процессов мы примерно так эта штука выдает данные это одна из многих страниц где есть в суммарной информация о том в каких статусах задачки в спринте сколько примерно весит каждая и так далее тому подобное вот такие штуки тоже собираются летят параметре и собственно чтобы как-то собрать это все воедино для чего я предлагаю мониторить совместно и технику и метрики имеющие отношение к вашим процессом и разработки и бизнеса хочется подчеркнуть что самих технических метриках в принципе мягко говоря не достаточно и было бы здорово ну собственно наблюдать за процессами бизнес и разработки мы для себя уже взяли за правило что если выкатывается новая система новый бизнес процесс как правило заранее формируются новые grafana барды куда выводятся все критичные для нового бизнес-процесса метрики соответственно заводится наперед лорд его и сенге и так далее чтобы мы предвосхищая ли проблемы на запуске и старте проекта отслеживать тренды то есть стараться все-таки делать мониторинге которые наблюдали бы картинку в довольно долгосрочной перспективе один конкретный кейс довольно важный для нас это когда посмотрев на то как постепенно растет количество коннектор к нашей базе мы выяснили имеющуюся проблему с кранами переехали на супервизор то есть просто наличие практике смотреть на долгосрочные изменения тех или иных чисел ок в мониторинге в прометея в частности привело к спасению системы при этом правда мы породили еще один серьезный инцидент спасаясь от этого но это бывает то о чем я говорил в плане review мониторингов эта штука которая действительно может позволить подчищать подобного рода историй устранить древнее зло которое заводилась непонятно зачем и кейсы типа мониторинга на базу данных о котором я рассказывал начали можно тем самым избежать исключать ложные срабатывания чтобы не было как раз проблемы с тем что что-то полыхает хотя на самом деле не должно чтобы не замылился взгляд и в целом делать так чтобы он мертв действительно отражали состоянием данных по системе конкретно моя проблема там в последние наверно год это то что если открыть центре там есть несколько страниц ошибок какие-то из них случаются миллионами раз и это хочется почистить и убрать чтобы можно было открывая система в которых сыпятся ошибки видеть по-настоящему вещи требующие устранение важные то есть чтобы в центре не попадала то что является там нормальным вывод поведением и чтобы там не было ошибок которые давно не устранялись про документацию я думаю что в целом я сказал достаточно и без этого никто кроме автора зависшего метрику не сможет понять почему оно важно и что нужно чинить ну и что самое главное до важно не просто тюнить мониторинге поднимая пороговые значения из за того что в системе что то постепенно разваливается действительно устранять первопричины не допускать повторение уже случавшихся fa cup of а теперь я готов ответить на ваши вопросы здравствуйте олег . спасибо за доклад вопрос такой на каком этапе формулируются требования к мониторингу да то есть что мы будем мониторить крым и будем это реализовывать и как это заносится как отдельная подзадача backlog свечей да как люди происходит процесс можно как подарок спасибо за вопрос пример такой мы распиливаем один большой монолит он должен заниматься обработка заказов на самом деле он еще занимается процессом возврата денег и мы в прошлом году запускали систему которая автоматизирует эту историю отдельный my car service на самом деле распределенный монолит в итоге но мы понимали что у нас большой монолит будет про 10 данные в кафку и другой сервис типа micro сервис будет их принимать и вообще говоря эти системы то есть сколько выпленул один столько должен принять 2 мы понимали что это может быть показателем того что что-то пошло не так и если эти числа разойдутся тут сразу несколько проблем с одной стороны ответ на ваш вопрос мы хотели быть уверенными в том что мы узнаем что что-то сломается потому что не вернуть во время деньги не выбить во время чеки не передать данные в налоговую это фиаско мы должны от этого быть защищены в попытке ответить на вопрос как мы придумали что окей мы посчитаем сколько выплевывает в кафку эта система сколько принимает то здесь есть другой косяк связаны с тем что кто-нибудь используется для микро сервисов саги кроме авито кто не будет нет а кто то есть класс у вас есть шанс собственно мониторить невыполненные транзакции у нас в этом плане пока что не доросли еще не принесли эту штуку но у нас уже есть бизнес транзакции размазанные там по 5 системам например в общем ответ на вопрос изначально мы думаем об этом перед большим запуском перед релизом чтобы ответить себе на вопрос поймем ли мы если что-то разнесет и мы стараемся добавить максимум чисел ок у нас в общем мы не платим за каждым метрику в прометея да то есть стараемся по максимуму все закрыть и дать этим метрикам осмысленность точки зрения бизнеса в первую очередь само заведение мониторингов если это какие-то обмен это зачастую это закладывается в div и нежна в дан задачи где этот обмен был добавлен систему потому что это супер дешево то есть это 1 балл request конфигурацию айсинга в нашем случае и метрика в коде это тоже одна строка если есть необходимость сделать это как-то масштабно и добавить мониторе не на весь бизнес процесс тогда отдельный тоску это по сути этих backlog спасибо за доклад для бизнеса который дашборд рассказывали делали ну во-первых вас и ждешь барды по выпущенным fi чем соответственно пора ли нам что ваш новый релиз сколько ведь какие фичи есть некие числу метрики для бизнеса числа за число заказов во-первых в чем делали до сбора для бизнес бизнес графа вы прям графа ну запустили либо что-то сами костыль или и второе есть ли какую-то связь мониторить или между выключенными фичами их содержанием их объемом и ростом или падением числа заказ тут никто такое оба тестирование там тут не совсем правда тестирование с начально про первая часть вопроса комбинация есть те кто действительно смотрят в grafana доступ есть from business card ну смотрит в том числе есть прям телевизоры которые стоят и у представителей бизнеса и технического директора есть свой отдельный телевизор где прям бизнесовые метрики в большом количестве ну потому что если сломается автоматизация бизнеса важно видеть именно эти метрики они там лоу ты веришь это во первых при этом есть свой костыль виде рилтайм дашбордов где свое отображение определенных метрик то есть это прям визуализация силами там железных библиотек и есть собственно в отделе даты analytics такая штука как табло известной в общем история для тех кто занимается этим направлением у них там есть свои dash барды которые предоставлены бизнесу большая часть статистики не real time ago а той которой более глобальная для отслеживания трендов предоставляется через то блок по поводу вторая часть вопроса выкачанные фичи и он их связь заказаны ну на самом деле это обязанность релиз инженеров то есть когда формируется dipline этикет в нем перечисляются все тоски которые едут в релизе в релизе есть fix версия есть диплом тегель дипломом пеките список того что поедет и такие теплей ноут на какие мониторе обратить внимание после релиза мы смотрим в графа ну а граф анри совершенно прекрасная фича простая в доску это вы наводите скажем мышку на какой-то конкретный график у вас много панелек он подсвечивает все одновременно можно легко видеть корреляции если допустим запихнуть у меня есть такой план данные о релизах в тот же самый прометея и выводить в графа ну то можно корреляцию наблюдать вещи прекрасному that a lot и как бы делали время релиза поехала сейчас это по сути делается вручную то есть этого нет в плане какой-то конкретным роли вот именно не не то что маркетологами то есть допустим релиз инженер конкретно смотрит вот поехал релиз он видит ошибки он смотрит если корреляция посыпались они не прожить на gopro вот бизнесменов да надо то есть заставляют отслеживания цели в общем красивого ответа нет есть несколько слоёв есть например у нас чатик диплом ф.м. mazda наклейки уже про него есть на стенде в которых крепятся данной обо всех релизах и как правило есть конкретные кейсы когда те или иные менеджеры отмечают проблемы с показателями скажем команда отвечающая за сервис по созданию заказов видит что что-то поехала такая думает кей открывает де playfoam видят что коснулось система которая обслуживает эту историю ну и собственно намочить это тоже 11 спасибо большое за доклад вопрос немножко про будущее смотрите задумывались ли вы об автоматизации метрик в графа нивки бани я допустим вы создаете монолите на приложение на симфония на зуб откачивается равен создается график раскатывается базу ли в реплике что-то такое раз выезжаем мы туда движемся если мне не изменяет память можете залететь на бит лап вас перебить лап гид хоп наношу учетку там есть bamboo посвященный метриками метрикам который мы постепенно развиваем и вот приблизительно в таком направлении очень-то и движется то есть мы стараемся вообще при работе в командах если кто-то сделал когда мы начинали использовать кафку в продакшн они сделали в бан был под symfony которая отвечала бы нашим требованиям со всеми необходимыми зависимостями пожарили между командами у нас есть довольно непростая система логирования потому что логов напишем гек по 300 в час сейчас под нее тоже есть свой балл был который везде перри используется то что можно выкладываем наружу в случае с метриками приблизительно в таком направлении мы движемся как раз этот банду лужи юзается вот в том же самом real thing даже точнее в дыры в very час подключен чтобы собирать их и продюсером этой спасибо за доклад вопрос больше наверное процессного характера чем технического но все-таки у вас была такая интересная метрика как среднее количество поста платных полна заказов допустим или что-то вроде и соответственно ванне и смотрите отслеживайте в том числе и по ней корректность работы бизнес-логики вопрос следующим бизнес обычно интересует достаточно длинные окна агрегации но серии там сутки или даже что-то а для отслеживания проблем нужны весьма короткие потому что даже за полчаса может на сыпаться кривых заказов столько что бизнес потеряет достаточно солидные деньги да и так как удается именно процесс на договариваться с бизнесом то есть у вас действительно шарится вот эта метрика между технический и бизнеса вай командой либо ну как удается договариваться вот непосредственно при их использовании вот таких вот сквозных сценариях но в том что касается сроков за который мы мониторим есть метрики которые считаются за довольно большой промежуток времени вот меня сегодня спрашивали по поводу того как мы храним метрики кстати в итоге я уточнил они все-таки сыпется ps3 псв то что четыре недели до она соответственно итоге попадает туда то есть есть настроены истории с большим окном в плане значения метрик их критичность и что они значат диалог примерно следующий ответ будет специфически но тем не менее общение с бизнесом в разрезе мониторингов часто происходит в контексте серьезных инцидентов если что-то сломалось когда-то то как правило собирается комиссия на которой в том числе присутствует бизнес и представители той бизнес скажем так того направление бизнеса кого за эффекте лотом нашим релизом или каким-то инцидентом на подобные встречи на разборе мэйджор инцидента решается почему он возник как сделать так чтобы он никогда пожалуйста больше ни в коем случае не повторился какой impact мы понесли сколько денег на чем мы потеряли бывает так что нужно подключить бизнес чтобы решить какую-то в созданную для клиентов проблему и так далее да и именно там обсуждается вопрос каких-то пару активных действий и при заведении мониторингов чтобы этого например не повторялось мы обсуждаем что такие можно смотреть сюда и эта штука будет говорить нам о том 3 о том то то есть мы обсуждаем вам и критичность скажем так остановки определенный бизнес процессов если раньше мы могли и не в полной мере понимать то бизнес это проговаривает и в частности обращаем внимание на то куда смотреть чтобы проблему предвосхитить как-то так спасибо за доклад вот еще вопрос боретесь как него эти проблемы что слишком много становится метрик за которыми хотелось бы следить и люди как бы уже не успевает не влезают на один даже борт там на 2 dash барда не влезает то есть тело проблема когда кто-то начинает прикручивать какую-то автоматику для анализа трендов еще что-то у вас что-то в этом направлении есть насчет автоматики для анализа трендов но скорее нет я очень хочу сказать что да и выдумать красиво ответ в том плане что у нас есть такие подвижки в этом направлении ночью от конкретного нет когда было понятно что не влезает это интересный кейс а например black friday акция которая проходит у многих магазинов я думаю никого даже из вас как там покупателя но не обходит стороной для нас оно очень важное подъем обычно собираем отдельный дашборд куда выводим критичные в этот момент показатели это в частности план по заказам рейд создания заказов тому подобные вещи она часто не вылезает мы настраиваем ротацию даже бардов это один из кейсов понятно что скролить их никто не будет все обвешаны телевизорами соответственно направлении такое в плане количества метрик которые например взрываются такого вопроса быть не должны ничего не должно взрываться то есть если случился серьезный инцидент понятно что и стингу можно скролить так долго вниз вот это ненормальная ситуация на является исключением и тонкий то есть пока что такого чтобы вообще не вылезала ну вот в конфиге котором я говорил в нем сейчас там тысячи полторы разных метрик но они все срабатывают в крайнем случае поэтому это не доставляет неудобств с точки зрения дашбордов вот пока что это просто ротация для визуального контроля а все остальное то что оперативно нужно узнать никто же не мониторит систему глазами по телевизору все остальное летит как правило в telegram например или флаг если туда летит слишком много мы начинаем ставить под вопрос о корректно ли настроен мониторинг если он так часто срабатывает или не сломан или что-то в системе и тогда бросаем силы на устранение так что на самом деле ничего полыхать не должно и поэтому проблемы такой возникать на мой взгляд тоже не должна спасибо за доклад тоже вопрос о процессах кто занимается решением инцидентов кто он находится между разработкой и саппортом с саппортом ну смотрите есть допустим alert и который куда-то сыпется предположим в тот же самый telegram slug не суть на них смотрят линия поддержки который дежурит 24 на 7 ну можно сказать что так они смотрят что конкретно взорвалась нормальная ли эту ситуацию у них есть инструкции есть инструкции которые даются на смену есть и которые зафиксированы в confluence вики не суть на постоянной основе по названию взорвавшегося мониторинга можно найти что это значит собственно то о чем я говорил да то есть для самых критичных мониторингов эта штука описано то есть что сломалось к чему может привести кого необходимо поднять есть календарь дежурств за каждую систему отвечает кто-то свой то есть мониторинг однозначно определяет где сломалась кто там в итоге будет виноват как это будет решаться уже дежурный договариваться между собой в каждой команде есть тот кто постоянно доступен то есть эта роль дежурного переходящий если что его поднимает если задача может быть решена силами напустим abs за этом развалился раббит кластер звонить разработчику смысла нет у него даже доступ нет на эту историю поднимает команду abs она соответственно фиксит то есть вопрос решается службы поддержки которые наблюдают проблему и инструкциями которые говорят о том в кого это коммуницировать александр спасибо за доклад мне два вопроса по командным метрикам первые как вы считаете часы на задачу этом видел на дашборде собственно эту метрику и 2 делаете или на основании метрик какие-то прогнозы когда будет доделан в print например если да то как здесь есть несколько подходов но как известно spring не будет доделан никогда но в целом расклад следующий по поводу часов тут есть различия дело в том что jira viewer and units а под процесса конкретной команды и свои хэндлер потому что не все оценивают в часах то есть лагают в часах например все logo мы не для какого-то непонятного контроля скорее для капитализации понимание того сколько у нас уходит времени на типовые проекты сколько они стоят что логирование в дыре в жире есть плагин называется истинным сбои роуз то есть возможностью чтобы кирилл о гале отдельно разработка отдельно это критично даже если у нас случается это редкий кейс div тест что разработка что-то тестирует друг за другом то это лаги руется во время разработки клей лагерю самостоятельно pajero пи собственный уивер просто собирает допустим среднее значение в задаче за несколько спринтов например или за конкретные указанные выводит это и врач значение по поводу планов и всего остального но для меня допустим диске есть простой и открывают жиры viewer я вижу что у меня в данный момент скажем спринт и у нас двухнедельный сейчас вторник спринт уже должен был условно сойтись мы должны были половину преодолеть если говорить там обернем чартах и это значит что если у меня сейчас есть 3 разработчика а в туда увести там типа 20 задач и у них евро соответственно определенно очевидно что они не будут сделаны и чтобы обеспечить корректировку kamik на тот перед бизнесом или перед самими собой так далее мне нужно задача начать интенсивно выбрасывать и спринта переносить следующий менять x версии так далее то есть jira whoever в этом случае является таким способом агрегированного увидеть процесс ную проблему в планировании в чем-то еще jira viewer это это велосипед ну то есть это своя штука которая я же говорил что это печки и sinfonie и она смотрит jira пи так что это отдельный прям instance с web-интерфейсом куда мы ходим и смотрим пока нет надо не ну дело нехитрое я думаю что можно к этому прийти jira плагины есть разные есть разного рода kontiki агрегаторы прочие истории но чего то что решал бы все проблемы разом нет жира и там есть специфика у нас не облачная у нас стоит своя мы периодически апгрейде мунас поднесенного куча там же снах костылей общем чего то что решала бы это проблема вот как надо нет хотя иногда хочется то есть мы не смогли нормально jira выводить допустим на телевизоры но вы так и сделали javier изначально из мотивации собрать метрики выплюнуть в прометее показать в графа не на телек например но сейчас к этому пришли если что можем после доклада ещё обсудить в общем вас есть мониторинге какие-то бизнес-показателей тепла среднее число пост оплата заказов при этом сам бизнес-процесса он супер длинные проходит там через frontend через сайт через десять каких-нибудь сервисов на байке еще инфра и вот там загорелась красненьким как вы понимаете как вообще происходит разбор где сломалась того что это не доски есть как мне кажется где можно сразу сказать какую команду надо призывать ручном режиме надо же вы поднимали руку kawasaki есть да у нас есть вода у нас нет ну в общем на самом деле плен в том что в для каждого бизнес-процесса есть метрика которой наиболее для него критично в частности для там создания заказов это там количество ошибок при создании заказа или количество заказов которые были например оплачены подтверждены не уехали на склад то есть это определенные точки в которых понятно что взорвалось у каждой метрики вообще есть определенный конвенсион как в их именуем то есть в начале каждой метрики есть вообще название системы то есть в этом плане зона ответственности она становится понятно то есть если метрику заводит тот кто отвечает за систему он именует и и корректным образом сразу понятно кому идти не дальше и вы можете понять это ошибка например бизнес-логики там после нового релиза образовалась или проблема в in free не знаю на жалей , не будь она одинаково может провести там к падение числа заказов но опять же часто корреляцию vision по той же сам и графа не то есть если мы видим падение этой штуки мы видим что начал 500 обмен со службой которая даёт нам информацию тома доступности курьеров и эта корреляция четкое заказы там допустим не подтверждаются потому что система delivery 500 вот она пожалуйста эта корреляция то есть есть определенные кейс ответы на которые можно получить быстро за либо за счет в визуализации либо сходи в тот же самой центре то есть случился спайк по ошибкам мы смотрим на релиз так в центре видим насытившиеся новые ошибки там видим контекст заказы по заказу можем быстрого ластики посмотреть полную историю того что происходило то есть это совмещение всех систему логирования мониторинга который в итоге отвечает на этот вопрос когда ты говоришь мы видим это всегда мы смотрим глазами мы видим alert и нас мораль орками глазами на другие метрики или есть кое-то там подтягивание проблемных метрик что-нибудь такое у нас просто самих очень сильно болит язона что и понесла его коллеги тут нет простого ответа я предлагаю обсудить счет сразу после что все успели задать вопросы что что по сути эта штука разрозненная достаточно если кратко и отключать 2 проц быстренько есть единое целое или внутренние слои от сервисов если есть то как вы считаете история следующее если отвечать очень кратко у меня про это и есть доклад называется танцы с саппортом есть кажется на ютюбе есть на хабре продолжением женщина хабре да я же вы редактировал точно в общем там это довольно детально описано то есть по инн в том что по срабатывание каждой метрики если требуется привлечение дежурного обязательно заводится task в jira с определенным и солей есть и свои плагины особый прописан в документации типа что бизнес процесс останавливается полностью тогда это приоритет p1 как у нас тут пошутил недавно один тимлид подождут год на самом деле по 1 этапа типа первый приоритет и это значит что проблема должна начать решаться в течение получаса и быть решена в течение полутора-двух есть соответственно вп-2 это если бизнес-процесс частично заблокирован есть обходные пути решения проблемы и тогда он был быть там начать решаться в чине двух часов и быть решен в течение например рабочего дня она и так далее то есть есть система приоритетов есть соответствующие сала и на устранения если он протекает мы об этом узнаем у нас горит крестники спасибо за вопрос время опросов закончилась александр какой вопрос по вашему мнению был самым интересным ну один наверно из самых интересных был вот-вот молодого человека встаньте пожалуйста он получает приз за самый интересный вопрос можно поаплодировать еще есть футболочки которые мы раздаём простите за такую нотификацию девушка с собой можно вручить футболку уже есть тогда не да хорошо тогда я хотел бы вручить вам потому что вопросы которые вы сегодня насыпали были более мы чем интересными теперь наша abs команда пошла выяснять некоторые из аспектов так давайте посмотрим есть ли она есть 2 x цель можешь подойдет м прошу вот и мода человеку колонный с телефоном до вам смотрите есть выбор xxl l еще excel и . в общем какой размер вам бы подошел давайте определимся и всем спасибо что пришли спасибо за вопрос и вам тоже александр спасибо мы вручаем благодарность за ваш труд и вклад"
}