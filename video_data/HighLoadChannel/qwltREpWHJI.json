{
  "video_id": "qwltREpWHJI",
  "channel": "HighLoadChannel",
  "title": "Оптимизация программ для современных процессоров и Linux / Александр Крижановский (NatSys Lab)",
  "views": 611,
  "duration": 2640,
  "published": "2017-04-22T14:47:46-07:00",
  "text": "а первый доклад это типа массе класса учебный трек по оптимизации программ для к шее и кашей процентов и 500 всем линуксом в принципе это материал мастер-класса 6 часового за 45 минут его нельзя успеете сделать то есть мы не будем сегодня смотреть код пытаться запустить смотреть насколько быстрее работает оптимизированный код насколько медленнее неоптимизированный и я расскажу сегодня только небольшое подмножество того что стоит рассказать это только по каше процессов работу с памятью и к структуры данных на втором моем сегодняшнем докладе по тем песню я сейчас затрону тему кэш кашасы к шабли виз алгоритмов на втором докладе уже можно будет посмотреть конкретно пример как они используются и посмотреть исходный код прежде всего давайте сейчас вспомним в каком мире мы живем потом начал работать наши программы прежде всего мы все знаем что так то частота процессоров она останавливается развитие становится много ядерных становится немного 2 то что у нас есть разные уровни памяти в принципе всегда так было сейчас их может быть даже становится больше давно вых процессах у нас появляется уже и 3 уровень и каша более частой раньше это было там да так силен и процессы сейчас уже на десктопных они появились 2 важно и третье важное point о том что у нас теперь есть numa архитектура раньше она была только на процессорах м.д. теперь она появилась на имперских процессах и fci у нас сейчас и 1 дна память и самое последнее то что от чего зависит наш пог'ом это о том что мы должны разделять данные между потоками процессами и соответствие между процессами глазами здесь небольшой пример базовых блоков программ который оптимизирован как бы обычный поток ввода вывода кэш какая-то очередь задачи много ваакеров до их здесь два может быть больше базовые вещи о том как мы оптимизируем по громада есть функциональной декомпозиции езди композиция по данным декомпозиции по данным самое такое часто встречающийся нечасто чаще все так то что о чем говорят по оптимизации это был у нас большой массив мы его делим на 2 части и на гитаре вам в двух потоках пример вот с рабочими потоками отказ декомпозиция по данным хорошо масштабируется функционал декомпозиции когда у вас газа на потоке отвечают за разные масштабируется плохо потому что вы вот этих логической сущности можете выделить из программы конечное число вот и как бы тоже интересная интересной особенностью о том что на самом деле наш код который работает на процессоре это тоже данные он тоже лежит в памяти он тоже кэшируется процессом мы тоже нужно соблюдать его локальность то есть современный пог'ом они достаточно большие они могут не влазить в кэш danquish инструкции соответственно об этом надо помнить и учитывать при оптимизации вопрос по тому что вы будете связаны архитектуры мы знаем что есть например mais quel который на потоков после он есть полис который построен на процессах и какой подход вообще вы быть когда вы начинаете писать свою программу с нуля или оптимизировать wapping надо начать того что фактически процессы и потоки это суть одно и то же после много грязные немного интерфейс одного и того же это с точки зрения операционной система абсолютно одно и то же пост так же процессы могут выделять данные как потоки через жареную память и есть хорошего посол продукты чипа под колеса apache и nginx которые то и делают они имеют shared memory в которых живут спину о'киф которые живут все данные и они разделяют между процессами процессов есть одно большое преимущество что например случае яндекс вы знаете что если вы пишете кастомный модули у вас есть мастер процесс engine.exe которые управляют этим есть вот воке в которых работают вашему адресу вас модуль важные если он периодически падает у вас индекс будет жить потому что он будет перезапускать этих блоков это большое преимущество процессов такой страны как как ни странно в основном люди сейчас пишут все на потоках потому что с потоком проще вам не нужно делать спин нокию их выдержать чайной памяти то есть нам все намного проще происходит потом сколько потоков запускать то есть у нас сейчас процессов много хочется иногда запустить под каждую задачу потоков или посту там сделать много потоков и как так сдавать между потоками за ваши задания на самом деле количество потоков это очень важная штука в богами надо всегда четко отслеживать сколько поток вы запускаете как они раскладываются по процессам и какую работу они выполняют как они вытесняются в принципе они используют много относить много памяти шествия не сможет быть это не так страшно на современных системах многим на горбатом гамом но все но мы посмотрим дальше потому что память объем памяти при том что у нас и и много очень стало все нужно экономить и здесь в самом начале есть в самом конце есть ссылка на книжку или haudry пиво все кто ее не читал я очень советую почитать очень хорошая книжка по делу и в частности вот в это график это взято оттуда и вообще висит это он взят оттуда он говорит о том что когда вы считаете свою программу то есть вы сначала сделали программно примерно по точные дата есть у вас например есть 10 процессов process of 10 ягер вы сделали 10 потоков и вы смотрите на том на то как эти 10 потоков используют кэш каждого ядра процессора и если у вас высокий к шкид то вам может быть не не имеет смысл водить многопоточность то есть здесь есть баланс в этот зеленая линия то есть по которым зависит вот где в зелёном диапозоне имеет смысл проверить код в к нам не имеет смысл суть в том что если у вас один поток уже имеет хороший кошки два потока они будут иметь меньше кика шли то они будут просто обольщают большему количеству данных соответственно вас кашмир будет повышаться и тем как вы увеличиваете количество потоков вы ухудшаете кэш хит с другой стороны вес у вас к шкид плохой то просто его не и на процессоре потока пока процессах ждет данных из основной памяти у вас другой поток может тут полезно делать поэтому надо смотреть на то что как потоков здесь сразу мы смотрим на важную проблему о том что большое количество потоков ли процессов стены они приводят большом контекст свечу контекст switch очень неприятная штука и к сожалению очень немногие знают чем конкретно он пах то есть обычный контекст switches вот как вы рассматривает в книжках в базовых о том что это просто сохранение контекста вот мы знаем что контекст это сколько это там пара десятков регистров это копейки то есть делать копирование в памяти этих регистров от копейки это недолго тем не менее кончак свечи очень дорога опираться мы посмотрим почему базовые вас 20 базовые примитива синхронизации по текст винные библиотек представляют примитивы я думаю что многие из вас их знают пробежимся первые там взаимоисключающие семафор 2 to ride глайд блокировка над дорожным you take so но имеет смысл при масштабе они намного много ядер вообще говоря когда мы говорим о многих ядах мы понимаем что производительность программы для 1 и 2 мы всегда снижаем когда мы оптимизируем по большое количество едем на зато получаем лучше лучше лучше масштабировать на большое количество ядер и в пакет как раз один из таких примеров он позволяет вам работать параллельно нам больше количество ядер но он более дорогой чем beautix примерно раза в полтора кондуит тоже известный примитив ожидания и интересно примитив это спинок самая 1 на по реализации самых простая штука который можно придумать другой стороны она становится очень интересным виза спейси потому что она там сделано концептуально немного неправильно и есть фундаментальной проблемы тем не менее на практике свои используйте сверло как правило участие наивысшую производительность кодом если вы можно использовать и в принципе все эти там три штуки которые так или иначе вызывают сон процесса потока они задействуют стены вызов ютекс вот здесь базовое представление уплощенное о том что и представляет себя бедный ответный бог взаимоисключающие то у нас в цикле есть атомарные операции вот to sing вечен дает это та же самая функция g c тома напиваться на от целом значение в цикле мы учимся поверяем свободной линии перемен а если она не свободно то тогда мы уходим состоянии сна и освобождаемся то снова проверяем ее и я все хорошо мы захватом блокировку так испытывает honda в этом связана проблема гремящего стадо о том что когда вы ожидаете какого-то события и вы побуждаете вас например есть один рабочий поток который что-то делает ты кладешь куют очередь данные другой десяток он лежит состоянии сна и ждет данных вот первый поток соответственно если вы возьмете побудете все ваши ожидающие процессы будет очень плохо это будет время часто да и прежде всего она плохо тем что у вас будет так называем кэш line bouncing то есть у вас будет кэш линейка летать от одного процесса к дугам мы посмотрим что происходит с этим но вот в этом примере мы видим что у нас есть переменная вау это некоторые чеков память она хранится в кэш линейки и если у вас полезно 10 процессов начинают побуждаются из fedex свои-то побуждаются и идут пытаются обновить вот эту перемену сделать в нее синхронно запись они все начинают 21k шинельку она начинает конкурировать кто же все-таки выиграет и запишет в эту к шинельку это очень дорога опираться и соответственно не имеет смысл побуждать много потоков с одной стороны у вас только один выиграть другой стороны вы потратите много ресурсов на этом я занят что скачать у меня почему-то крики вы плохо очень работает в принципе я здесь это уже сказал это проблема о том что контекст свечи одна из аспектов контекст свеча а то что когда вы переключаете поток то у вас текущей крышу от вас работу поток он набрал себе память и горячий набор данных которую который ему нужен и этот набор данных находится в кэше как только другой поток получают управление если это поток работы с другими данными то он наберет немного другие данные к себе в памяти какой вот так она и случаются поскольку мы видели что большинстве случаев мы все-таки делом декомпозицию по данным и соответственно каждый поток а вот со своими данными и если сын мы сделать такой декомпозицию поток 2 получают управление и вымывает кэш первого потока 2 1 поток когда получит полине снова он окажется на холодных данных 2 что здесь уже сказано что инвалиде от кэш и 1а или 2 и 3 а не вымываются мы чуть дальше посмотрим на эти процессы что конкретно с ним происходит вот пытается пин-ап давайте посмотрим чем он бог и сначала это вот та база его реализация здесь 2 особенные ставки они полностью ковалентно x86 архитектуре по сути мы пост вращаемся в цикле пытаемся захватить значение переменной лук и внутри тела цикла мы доставляем функцию пауз или реб нок к если вы делаете руками спину волк никогда не пишите его вот здесь принцип можно было бы просто написать вау и ; без вот это особенные установки она будет работа на будет работ немного медленнее у вас будет сервера больше от собственного времени больше не обижать дело в том что то реб нок либо пауз они как раз отвечаю за то чтобы у вас процесса немного отпускал шину данных и немного он замедляет его работу и у вас получается более осмысленной работы процессора и вы меньше сжечь и энергии вот давайте посмотрим на проблему спину ловко чем они плохие то есть я уже сказал что если у вас ну код позволяет заместить ответ мьютекс на портрет пинок это можно делать только тогда когда у вас код не засыпает в большинстве случаев вы увидите хорошие повышение производительности другой стороны есть сценарий когда вы можете увидеть что у вас пока он сам работает быстро но иногда у вас бывает по осаживанию производить то есть какие-то задачи выполняются очень быстро какие-то немного медленнее я в том что мы не можем внизу спейси обеспечить детям него ность такой блокировки вот например у нас есть два процесса и есть три потока первый поток сейчас захватил на первом процессоре захватил мог что-то делает и приходят еще два поток которые тоже хотят сейчас работают на втором процессоре а не хочется в азию пим им пытаются захватить блокировку вот сейчас у нас настал момент когда 0 поток еще по усвоит там слайс и все на планировщик его вытесняет собственно стены планировщик может вытеснить в любой момент и он вытесняют его с захваченным спину лаком соответственно два других потоком они не могут захватить эту блокировку и поскольку нам одном процессоре у нас работают как ревущие потоки один из них может быть при панин на 0 процессов да и вот в каком то момент время где сейчас находится 200 процентов сыпью usage у нас получается два и два который просто хочется в ожидании спину лог они ничего не делают системный планировщик иногда по ним может понизить приоритет процесса который процесса который себя так ведёт вот стал он считает что процессы которые полностью выживают системные ресурсы они жадно это число дробилки и они не настолько важны как процесс интерактивные такие как например там какой быть там skype там вот и так далее я понижают планировщик понизить приоритет такого каких потоков и получается что у вас вот эти два поток которым нужно что то делать а не во первых выживают посредственно время вторых они понижают свой приоритет и тогда когда они собственно коснется первый поток они смогут захватить ресурсы у них уже не будет там строится и у нее будет плохой приоритет вот вообще спину лог он используется в ядре операционной системы там работаем на другом уровне защиты и там мы можем запретить вытеснение и у нас поток который захватывает спину лог он не может быть вытесним то есть код который держит спину мог он всегда до работает на текущем процессоре до конца под виток в принципе я бы него уже рассказал он снижает его контент шин но достаточно медленный block content шин вы наверняка видели программу и знаете о том что иногда вы смотрите системную статистику что ваша программа она вроде как процесса все процессов но мы там не на 100 процентов память все в доме все хорошо но почему-то у вас и даже вот процесса если посмотреть в топе расширенную статистику то у вас получается что каждый процесс и что то делать но делать там скажем на 20 на 30 процентов не на 100 а тем не менее вы не можете получить больше фпс а чем у вас есть одна из причин может быть как раз его контент шин когда у вас несколько потоков или процесса дерутся за 1 new так заодно критическую секцию и они преподают самого процесса на другой по сути у вас участница 1 процесс иная система метод борьбы таких штук это снижение повышение g0 нас муки лавке то есть если у вас была критическая секция критической sex защищалась одним youtube сам вы можете перейти либо на redlight блокировку либо этот код побить на маленькие кусочки и быть разные блокировки зависимости от этого кусочка один из вариантов использования и спорт спорт как повышения наглядности это если у вас собой никакой код у вас сейчас никто переменной шарит и в и у вас начал выбрали мьютекс проверяли эту переменную если там она имела некоторое значение вы там что-то делали если нет вы просто выходили соответственно есть один из патентов в поколение это вот захватить сначала только рид блокировку посмотреть что у вас перемены если вы понимаете что у вас если надо делать какое-то действие перемены вы тогда отпускаете ритм блокировку и захватит tilite блокировку второй раз на нее и под в этом вы снова проверяете значение переменной тогда уже что-то делаете вам нужно обязательно перепроверить перемен а потому что между тем как вы отпустили блокировку взяли могло что-то измениться с одной стороны мы вместо одного газа берем 2 разблокировку мы два раза проверяем никто условия другой стороны если у нас программу работы так что чаще всего мы находим переменную в переменную шарит в таком в таком состоянии что ничего делать не надо то у нас сильно повысить производительность потому что мы большинстве случаев будем брать только рид в блокировка у нас полина процессы будут брать не скучающим блокировку работать параллельно и только очень редко у нас будут будет некоторые вайта который сильно потеть производительность но мы все он за счет бы сахаридов получим большую производительность то здесь зависит от того как работает программа еще варианты тоби gridlock он использовался в ядре linux теперь от него отказались идея такая что у вас есть сколько-то процентов на каждом из процессоре вы берете свою блокировку и каждая буковка не знают ничего о другой соответственно если процессов хочет почитать он берет свою локальную переменную никакого какой драки заказчики не происходит все происходит быстро быстро очень читает если же кому-то нужно что-то записать он идет по всем процессам и захватывать все эти блокировки понят дело что он может очень долго стоять в ожидании этих блокировок и запись становится очень медленно и хуже того что если у вас light и например пошел половину процентов вы захватываете блокировки она другой он встал то соответственно 1 половина ридов они тоже не смогут ничего сделать потому что и путевку уже захватил эту можно дальше делать redlight блокировки но в том после от этого подхода отказались потому что слишком тяжеловесная запись который может навредить ещё и рядовым здесь тоже не работает еще вариант как можно свой контент побаловать можно просто если у вас есть какая-то очередь из которой вы читаете данные да например там очередь пакетов вы можете захватить блокировка на читать 10 пакетов если есть дай ли вы читать все что есть до конца потом уже все сделать операцию по докам и потом уже отпустить его к то есть вот называется лоб matching тоже хорошо повышает производительность относительно новая штука по синхронизация that инфекционная память идеи и в том что все кто работаю соками руками знать что пока богам маленькая просто все хорошо как только у вас начинаются там десятки блоков разных они как-то между собой взаимодействует у вас появляются таки у вас там все сильно медленнее тяжело отваживаются тяжелого ведь баги и вообще как бы жить становится плохо соответственно появилась идея от инфекционной памяти она говорит что мы можем работ как базе данных мы можем просто начинать транзакцию в этой транзакции делать все что мы хотим систему уже сама разберется какие данные можно параллельно обновлять как и можно эксклюзивно обновлять и все это передаем на системы сначала она появилась в dc-версии 47 там она была реализована просто через большую хэш-таблицу у вас есть регионы памяти который вы добавляете в транзакцию когда компилятор com период ваш богам он смотрит где находится вашим данный завод для них хэш-таблицу даже для динамических переменных и когда вы начинаете вязаться он идет по вот этим вот это хэш-таблицы ищут вот эти данные там не выживут оки и для каждой ячейки памяти он берет лоб и соответственно вот это все очень медленно работает да то есть с прессой как это все будет руками сделать это будет очень медленно intel haswell он какая сделан аппаратную реализацию от этой штуки вот есть внизу ссылки где можно почитать по реализацию приглашал к нам в бок там я делал performance влей шинтэ tsx там есть графики если в двух словах то ин-т tsx во первых он очень специфичный он позволяет вам одессы на сильно быстрее спина лаков работать но очень на маленьких транзакциях маленькие ты с точки зрения объема данных из точки зрения времени если по данным и примерно вот глядя на код можем примерно понимать сколько данных мы обновляем внутри транзакции то со временем совсем тяжело и второе что поскольку мы знаем что из баз данных когда у вас например идут по олены транзакции на разных процессах да и они никак не кукри вы заданы то они идут параллельно становится все очень быстро как только у вас транзакции пересекаются по данным восстановит все очень медленно принципу разумно ожидать такого же поведение от intel tsx но его не наблюдается то есть на самом деле пересекаются у вас данными или нет на производить вообще не влияет вот здесь есть графики это первая потока влияет размер окна за акцию по объему данных вот мы видим что этот sx он начинается в самом в самом низу то есть до маленьких объем данных он в несколько раз обыгрывает спину локи но это очень быстро прекращается и ты сексу вверх и становится довольно медленным второе то по инфекционному по времени его вообще как будьте же оценить да что такое время но в ходе это как бы как много операций вы делаете с этими данными может быть вы там за ведь какие-то векторной арифметику может быть вы там в цикле как-то сложную бегаете но он зависит от того как долго вы сидите в транзакции у вас будет либо вы будете быстрее спиной к либо медленнее по tsx вообще мы его делали только один проект на нем и хорошо например вы использовать когда у вас есть какое-нибудь дерево например там спой trevi там какой-то бинарное дерево другое у которых есть там вращения до вам нужно за очень три элемента 3 но до 9 дерево бинарного это небольшие элементы их нужно за очень как бы если вы делаете просто руками спину лаки вам надо очень аккуратно делаю работа с педагогами персонажи память позволит вам взять транзакцию сделать вращение в дереве и относительно зонта есть хороший кейс где за сына ты секс может показать хорош производительность и еще последнее что по от sx то есть сказать недавно выбегали новости о том что находили баги в сексе и иногда как бог может не отпущен быть я его не видел ни разу но говорят есть вот guilloche к шее по железо к шее во первых у нас вот был раньше сампе у нас были как выдохе к шее или 10 2 и 3 и память потом у нас появилось новое у нас получилось что каждый процессор сидит на своей области памяти они как-то друг с другом общаются за доступ к этой памяти каши бывают газа заказные да там бывают большие маленькие они отличаются по скорости доступа есть еще dvb кэш tb кэш важная штука это же он опять же сильно может проседать при контекст свечи давайте посмотрим вообще по контекст switch почему это долго что происходит в кашу наша архитектурка свой 64 а называется у нее есть два типа к шее да это первый отель один очень быстрый который отвечает вот даже до того момента как натовских процессах появились контроллер памяти на борту даже тогда когда у нас процесса для того чтобы зарисовывать ячейку памяти ходил на северный мост и визовый память даже тогда у нас каждого уровня работу за 13 так-то то есть мы должны были тогда кэшировать данные по виртуальным адресам без задействования таблицы страниц задействовано северным мостом которые памяти соответственно первый уровень каша мы адресуем виртуальном на самом деле он не чисто виртуальный индексируем он в ритуальный алексей физики то героем ой то есть вас адрес раскладывается на две компоненты яндекс и так по тегу по индексу вы бежите по вашему кашу и так там хэш-таблицы и в каждом баке у нее живет там по 48 кэш линейка и пока вы бежите вы по это хэш-таблицы выдох даете запрос на контроллер памяти он вам возвращает физический адрес вот вы уже valena бежите по кашу вы находите ваш нужный bucket и вам приезжают ответ тот контроллер памяти с вашим физическим адресом и вот боккетти хэш-таблицы вы ищете уже ваши нужно ухаживать линейку кошелек ошейнику по физическому телу физика адресом а вот и 1 и 2 и 3 каши и они уже большие они медленные и они уже работали физических адресов и соответственно когда у нас происходит контекс вич понятно дело что разные процесс у нас могут использовать одинаково виртуального адреса для разной памяти поэтому мы должны полностью были делать или один кэш а и 2 и 3 они после вымываются поэтому вот чем плохо контекс вич что вы обязательно эти весь или один конечно ваш самый ценный кэш единственное исключение что контекст свечи-то также ключа себя не только как очень контекста между прикладными процесс многих приключений контекста текущий процесс едва и обратно в этом случае вы ничего не теряете потому что едва она работы в том же самом с той же самой таблице страница на ней были делают вам кэш пиво уровнем давайте еще посмотрим по тебе и по таблиц страниц во первых у нас когда мы рисуем адрес из виртуального физически мы да у нас есть в памяти вадик с деревом то есть вот мы берем физически виртуальный адрес мы отрезаем старше 16 битных выкидываем используем и 12 мальчик бить тоже от базовым это адрес страницы 36 бит пациенту это наша бит по которым мы рисуем адрес они тоже бьются на четыре части 1 часть это наш индекс в первом уровне дерева то есть вот я смотреть страничке представим в виде дерева до применено 90 нас получится дерева и каждого вин дерево это отдельное 9 бит от наших то есть 6 бит то есть как только вам нужно разрезать ведь виртуальный адрес физически вам нужно побежать четыре страницы памяти до то есть со всеми текущем что там каши как в кашах их не может быть вот этих значений из доступа к памяти соответственно это очень медленно вещь это то как можно посмотреть значение к шее под в таком мясо этапа то что тоже можно почитать у dre пиво это то что происходит у вас например на спину локи да когда в 10 есть другое сообщение request for any ship то есть когда у вас два процесса должны записать что-то в одну к шинельку они начинают двигаться и спать на шину между процессорами синхронизирующие сообщение от которые результате позволит определить кто и какой же процесса запишет в эту ячейку памяти очень долго это то что есть у дрейпера перемена архитектура андаин то они добавляют еще по пятам состоянию кашиике каждый своем примером того что вот вот это все работает есть у нас пустые си плюс плюс стиль шарик на шейный поинты которые используют как растамана операцию для аккаунта это как раз вот ответ на то почему шарик плохо использовать позвонить на мкаде да потому что вас все время идет в ад изменение вот этого аккаунта разделяемого то что я сейчас описал банку за к синей к это решается выравниванием то есть если у вас есть одна еще копаете такая как спины лорда значение ока вы ничего не сделаете другой стороны вы можете легко попасть на file sharing то есть если у вас есть скажем десяток переменных которые каждые или там массив из 10 элементов и каждый элемент пишется независимо в каждом потоки то есть вроде как у вас все хорошо на самом деле может быть плохо потому что и если у вас эти перемены они int и то в одной к шейке 64 байт у вас поместится 16 ваших антонов переменных процессу он не понимает в но пока этот по такого места я который отвечает за синхронизацию он работает на уровне кошелек то есть у вас одна единица и 64 байт это не энтони байт и так далее то есть если у вас независимые переменные попадают на однако шинельку вы все на получаете эту проблему соответственно нужно использовать выравнивание либо руками в обнять либо компилятор иногда это делать за вас по структурам данных о том как делать быстро у нас уже мы говорили про таблицы страниц на самом деле у нас вообще когда есть какое-то дерево прикладное в коде нас получается следующая ситуация если у вас данных очень много они не помещаются на ваш или один кэш l2 cache и вам нужно ходить в память рисовать адреса физически то вот чтобы при конечном 3 вот в этот зелененький элемент разрисовывать вам нужно пойти вот нарисован к одного элемента адреса этого элемента вам нужно пойти 4 физически странице то есть вы на один разминание указать в дереве идете 4 газа в память то есть у вас как бы 4 газа все увеличивается вес вы выходите из зале один каша поэтому вот когда вы видите отчета производительности пока у вас маленькие данные у вас там как то все может линейно дорастёт время потом как вы ходите зари один у вас там по экспоненте все скачет этот как асану соответственно по структурам данных у нас были структуры данных например b3 которые решили когда вы хорошо себя вели на дисках их потом решили перенести на память потому что же она вы как быстро должно работать на самом деле такие структуры данных работает не очень здорово и с основной памятью нас другая история нам нужны более прогрессивно структуры данных и такое шабли веса и кэш каши структуры данных testo туда на который работ не по советской аж линейками процесс который не работать просто с памятью вообще а понимают как надо использовать кэш по здесь после него ними небольшие интересы замечания о том что с массивом тоже можно интересно работать во первых что мы знаем что на процессоре нас есть при fetching соответственно в эти как линейное сканирование должно сильно обыгрывать какой-то поиски бобина но за счет того что у нас кэш death prophet процессы делать при fetching на самом деле это не всегда так и иногда даже внутри одной кэш линейки который казалось бы уже на процессах нам нам выгодные как бы хорошо запомнить pipeline да и все это линейность по сканируйте нам на самом деле даже внутри одной к шейке там где она живет 16 цветов выгоднее the tent искать бинарным поиском если мы используем инструкцию ассемблера который станет у нас получается быстрее то есть массивом тоже надо аккуратно по списке у нас есть узел не интуитивность списке если у вас интуитивный список который собственно сама структура списка находится внутри структуры данных вас получается хороший вариант что когда вы бежите по списку вас процессов вычитывать эти кошельки и в то время как вы рисуете pointer списка вас сразу же подсасывается вам нужные данные в кэш в процесс и вам хоть x3 при том что этот как раз то что используют the memory management юнит процессора на самом деле заступила данных очень медленно под свой фокус в том что операционная система когда выделяет адресное пространство виртуально она выделяет в очень близко то есть максимально близко друг друга у вас находятся все ваши митинги за счет этого у вас радикс 3 получается очень не ветвистые очень линейным и у вас есть шанс 1 время поиска если же вы можете управлять своей по гамме такой характеристикой будет брать x3 вести себя очень хорошо если вы будете посту до совать не понят какие ключ это будет очень медленным been an идея деревьев в целом я здесь не делал package каши с алгоритмы на втором докладе косы скажу немного по это дерево но в целом бинарные деревья хорошо ложатся на алгоритм exchange с в целом они не очень быстрый но их можно хорошо оптимизировать бы ты деревья на самом деле не очень хорошие структуру данных pst смартфон как работает бы дерево обычно мы берем для узора быть и расскажем одну страницу в памяти и когда мы опускаемся на ту страницу и ищем resort девам resolving следующем уровне мы запускаем been an ip бинарный поиск по страницы памяти соответственно мы на каждом спуске мы должны вытащить несколько линеек процесса да только в самом конце у нас элементы попадут в одну к шинельку соответственно у нас на дереве получается очень большой кашмир и b деревья это не самая быстрая структур данных который можно использовать для основной памяти хэш у нас уже время нету как бы здесь можно оптимизировать его пологом просто все все новерна знают структуру данных она простая первое что можно делать это можно делать глобальный лак для всей хэш-таблицы и отдельные а где а каждого пакета хорошо ускоряет улучшает позвонил воле ность структуры данных можно дальше есть не буду рассказывать о себе убедят последнее что хотелось рассказать это что иногда имеет смысл привязывать конкретный поток к еду здесь 2009 года о том как булан ума девятом году все было очень просто если мы смотрим на 2 патентную систему нас два и два на каждом процессоре между ядом и очень быстро между процессом все очень медленно современных нома интеловских там очень тяжело сказать между какими ядами быстрее между каким медленнее можно посмотреть также статистику есть разные методы привязывания прерывание и процессов и процессов к процессорам можно это делать руками есть специальные демоны которые выполняют спасибо анри меня зовут скажите пожалуйста когда имеет смысл привязывать прерывание к отдельному ядру и когда нет ха ха уж примет которую я быстро полистал это сетевой прерывание то есть выгодного упеха перед всем умеет сама делать долину к сейчас имеет рфс который у вас например есть htpc вы у него есть несколько процессов до которые читают и сокетов на разных ядах вы привязали как бенджен x можно указать например мой сам biofinity для того чтобы каждый волки работа на своем ядре и мешался с другими волки вами и операционной с тем способом 26 39 26 6 у нее появился fs и если вам приходит под пакет на определенное 2 отсчитывает его процесса уже на другом ядре то питон сему может мигрировать этот процесс на то же самое да где у вас приходит пакет пакет и разбрасываются по я дам уже самим адаптером соответственно вот в этой ситуации вам важно отслеживать чтобы всего трафик шоу на тот же самое ядро что и прикладной процесс опять же вот я на втором такое сегодня буду рассматривать эту ситуацию более детально по привязке сетевых пакет ну как бы вот этого всего стояка до о том как пакет приходит на его как он обрабатывается и о том чтобы у нас максимально эффективной работы рикошет процесса обработки трафика я надо понимать что я даже не знаю как называется так вот я просто пришел минуту назад но мне тем не менее вопрос значит один самый главный совет для того как писать код и один самый главный совет для того как значит поддерживать систему администрировать думать надо перепись начала подумать потом сделали хорошо на этой радостной ноте тестостерон спасибо"
}