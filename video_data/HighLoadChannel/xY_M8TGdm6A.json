{
  "video_id": "xY_M8TGdm6A",
  "channel": "HighLoadChannel",
  "title": "Борьба с нагрузкой в PostgreSQL, помогает ли репликация в этом? / Андрей Сальников (Data Egret)",
  "views": 8719,
  "duration": 3044,
  "published": "2020-04-27T12:10:27-07:00",
  "text": "всем привет сахара то вы видите тут в петербург оформление кстати сапоги синий шаг и сначала хотел бы немного интерактивчик а провести поднимите пожалуйста и те кто за экранами сидят и в зале за экранами прикольно будет зале просто я увижу кто из вас администратор баз данных или искал девелопер отлично а кто из вас разработчик который пишет на языках программирования вот по сути дела вы будете моей целевой аудитории в большей степени потому что администратора они так или иначе это все дело знают давайте я представлюсь я администратор баз данных работу использую с возрастом работы в компании дельта y мы как бы удаленные депо для многих других компаний также console сары попал в лесу и соответственно мы встречаем кучу типовых проблем который от компании компании от группы разработчиков группе разработчиков повторяются и имеют одни и те же корни и соответственно так как паулюса таган соурс решения то хороший тон это делиться своими знаниями с людьми и помогать им просто лучше его использовать и более эффективно поэтому мы довольно частенько выступаем на конференциях и делимся своими знаниями и опытом собственно у нас все давайте перейдем там первая часть доклада этот страшилки просто картинки страшилки из мониторинга о том как у нас нагрузка выглядит и с небольшими комментариями что ваня до этого рассказал очень много про то как конфигурировать что надо пользовать что не надо пользовать а как это все дело выглядит картинках сейчас мы с вами посмотрим типичные вещи диски в полку это может быть у вас как один запрос так как куча запросов это кстати снята с продуктовые базы данных и как бы реально работающая база с дисками в полку другая вещь как у нас проявляется нагрузка это количество транзакций на самом деле 50000 транзакций с одного мастер сервера это много для паз грицев нормальное число это там 20-30 но это тоже продуктовые работающие базу и чувствующие себя хорошо но если вы видите что у вас очень много транзакций значит ну что то вы наверное не так делаете и об этом и даже более подробно поговорим естественно к полу когда у нас но к сожалению на наших базах я не нашел где но в полку но когда она высокая это значит что тоже у нас достаточно большая нагрузка на базу данных вот на этой картиночке и при следующей я чуть подробнее остановлюсь контексте предыдущего доклада я частично его послушал блокировки в базе данных вот это совсем не здоровая картинка когда у нас 20 тысяч эксклюзивных блокировок в секунду вот эти синие пике шоссе попробую вот вот это вот штука это очень нездоровая и я не дума ну не хотел об этом рассказывать но в контексте предыдущего доклада расскажу это блокировки эксклюзивные которые возникают при создании временных таблиц меня позвали разобраться с одной проблемой и проблема бывает такого плана то что новый бренд по сгрыз а когда сессию поднимали не стартовал он стартовал пытался лицензировать свои переменные внутри нее там for кнут себе каталог системной форму и другие системные описания таблиц описание хранимых и все такое и не мог это делать зависал на этом процессе причем за весом по причине того что он не мог вклиниться в очередь чтобы встать в очередь ожидании блокировок то есть он даже вот в очередь очереди не мог вклиниться а реальная картинка по блокировкам в базе данных на этот момент было у такого вида то есть этот 40000 блокировок тысяч базе данных и суть в том что как бы для базы данных будь эксклюзивную блокировка на временную таблицу вроде бы не страшная вещь потому что этой временной таблицы мы пользуемся конкретной транзакции ну вот оказалось то что у нас возникает проблем с тем что мы просто не можем попасть в очередь на получение блокировки из за того что там большие таблицы этих блокировок и просто пробиться сквозь них не можем это же причина больших нагрузок который мы сами себе создали этот контексте от ну это еще один камешек в сторону временных таблиц с грехи и самые наверное важные проблемы это длительные транзакции которые очень долгие вот на этом графике вы можете увидеть то что транзакция у нас длительностью там по 10 20 минут и реально запроса который в это время выполняется укладываются в миллисекунды и это говорит о том что у нас что то не здоровы из базы данных происходит вот и нездоровый это делал выглядят если вы мониторите состояние своих транзакций то вот это нездоровые нездоровые вещи это вот как раз вот желтенькой вот это вот часть соединений которые называются и down transaction к краткая суть и down transaction это то что мы стартанули трансакцию забили себе транзак найди и перестали работать с базы данных и тем самым мы заставили страдать внутренние механизмы базы данных и делаем и себе плохо и базе данной похой и приложение потом тормозит и с этим тоже как бы вот это вот самая главная вещь с которой надо разбираться так и последняя страшилка которая тоже говорит высокой нагрузке которые не являются по факту рисованном высокой нагрузкой когда мы съезжаемся свободные соединения случается это от того что мы неправильно используем по полу connection of это может быть полукантонов которую встроенную ваш языки программирования там у кибернет гибер нет там свои поднимают у питона свои есть и если мы переборщил с этим потом мы будем держать с кучу бесполезных соединением база данных которые не работают реально работающих там единицу и как мы не увеличиваем не будем увеличивать количество единение мы все равно будем страдать от того что в базе данных нет соединений даже если мы будем использовать опять же баузер или детей которые сейчас популярность благодаря yandex набирает тоже при неправильном использовании сможем столкнуться с такой ситуацией в общем картинки страшилки закончились и теперь перейду к практической части собственно полезных советов доклад о том как мы можем сортироваться с помощью реплик но когда мы придем к этому моменту перед этим нам необходимо проделать некоторые вещи которые нужно ну который вам помогут снизить нагрузку до момента формирования и скорее всего каждый из вас найдет что-нибудь для себя что ему необходимо сделать у меня буквально несколько слайдов просто быстрый копанием пробегусь и скажу стопроцентно вы найдете тут свою случае 50 процентов времени пишем в базу не нужную информацию и это я еще по-доброму написал потому что скорее всего это 80 или 90 процентов времени как почему такие вещи возникают когда он у нас стартует проект мы не знаем какие данные нам нужны какие ненужные пытаются сохранить все если у нас проект живет и развивается то в какой-то момент нам нужно принять волевое решение и не писать весь тот хлам который мы писали до этого описать действительно нужные вещи это нам снизит очень сильно нагрузку по записи в базу данных если вы хотите хранить все обо всем эти вещи называются логин пишите логе складывайте там какие-нибудь паркет и и сваливайте в медленно и дисковые хранилища когда захочет аналитик варите там посчитать для этого есть специальные решения rdbms база данных не не для этого есть база данных они должны обслуживать более менее онлайн нагрузку они вот такие тяжелые неолитические вещи если это у вас конечно не специальной аналитическая база данных просто в контексте этой конференции в основном проекты это какие-то сервисы которые обслуживают там людей и это должна быть онлайн нагрузка поэтому дальше я буду именно в этом контексте говорит из этого следует следующее то что мы писать процентов времени читаем ненужные вещи то есть ну банально даже если мы забьем возьмем паспортные данные то реально когда человеку оденется ну вернее как его для авторизации информации о человеке возьмем нам единственное что нужно чтобы его авторизовать от его логин пароль но как правило разработка идет всем путем что читает целиком строку а там у нас может быть паспортные данные могут там какие-то пищу хотелки быть и чтобы понимали это выливается в то что мы пустите передаем не там 10 байт как нужно было одеть килобайт тем самым больше читая с диска больше передавать кости больше нагружая процессор и это я тоже все по-доброму написал потому что на самом деле нужно еще написать то что 50 процентов времени удаляем ненужную информацию поехали дальше справочники справочники вещь такая которая меняется редко и хороший тон при работе с действительно нагруженной базы данных не ломиться каждый раз в этот справочник особенно когда у вас десять строчек в нем один раз при старце вашего бэкенда прочитать его весь и хранить запиши рано если ты нему придет обновление то это обновление но часто они приходят редко раз в неделю раз в месяц раз полгода то есть можно придумать себе любую нотификацию там через механизм очередей тоже когда пришло обновление справочника и просто перечитать его советской же это вам сэкономит очень много ресурсов на чтение на мелких транзакциях которые все равно жрут процессорные ресурсы и сетевые ресурсы соответственно понятное дело что справочником в любом случае поймите будет лежать но если вы его за кешируется поближе конечному потребителю справочника только выиграет от этого избавив себя от лишних хождений базы данных разделение информации которую мы записываем этот вопрос он касается поиска и нужных ненужных данных тоже хороший тон на самом деле если у вас есть поля по которым вы часто ищите в базе данных да там это может быть айдишник там если вы поедешь ника обращайтесь если ищете человек то там фамилии имя хранить это в нативных для по сбросу и простых типов потому что под эти типы написано уймут индексов есть уйму методик как искать и вы будете просто быстро и более точно искать если это вы все запихаете в один джейсон вы просто будете тратить опять-таки ресурсы сервера на то чтобы прочитать json распаковать джейсон распарсить джейсон это не дешево даже по b2b джейсону прогуляться тоже недешево поэтому для быстрого для нужного важного часто используемым поиска поля рекомендую вы хранить в нативных типов для полос гриссом также если вы ну так как джейсон очень многие любят если как бы мы об базу в основном обслуживают какой-нибудь там frontend отображение информации визуально опять-таки основной контекст нашего мероприятия то то что выводится на экран у лучше хранить в компактном небольшом колесо не у нас может быть куча еще дополнительной информации которая не касается того что мы должны отображать пользователю это могут быть какие то примечания к что-то отдельное что что мы не читаем много раз это нам позволит снизить опять-таки сетевую и по ресурсам нагрузку потому что мы не будем брать ненужные нам данные из базы данных а только ровно только то что нужно это простое правило но как бы к нему обычно приходят через свою боль свои проблемы из-за того что там что-то где-то сложилось с или сеть забилось наращивать железо хотя решение они довольно просты и позволяющие меня просто практически примеры есть когда чуваки спилили себе запрос один нет трафик в половину упал просто не нужную информацию запросы убрали вот и как бы эта вещь будет полезно и вам очень важный вопрос а это эти все подсказки они на самом деле крутится около 1 то есть вот этим можно описать все вот это одна адекватность запрос в базу то есть на то насколько мы с ней адекватно работаем с точки зрения что нам нужны что мы оттуда получаем к сожалению практически жизненные примеры показывают то что гоняется кучи ненужной информации туда-сюда абсолютно бесполезным образом и любимые так скажем у ромы и не только улемы автогенератор запросов любят генерировать забрал свой больших размеров 1 мегабайт 200 мегабайт на нашей практике были гигабайтного размера запросу и просто для вашего понимания когда у вас приходит в базу данных запрос размером допустим 20 мегабайт базе данных банально нужно время чтобы его разобрать рассчитается разобрать разложить по полочкам и построить какой-то план выполнения то есть он еще не начался выполнялся вас а уже сожрали достаточно большое количество времени и прогрели воздух процессором поэтому такие запросы лучше всего конечно контролировать контролировать можно это с помощью логов возгорится потому что они туда скорее всего попадут если вы настроили логирование каких-нибудь долгих запросов другая вещь не менее распространенное если у вас сейчас объясню эту строчку если вы у себя видите distinct и какое-то количество джонов и the inner join и и вы видите что вы этом здесь think можете смело заменить на грубой у вас изменить не изменится ничего это означает что у вас что то не правильно в логике запросу неправильно вы сделали jojen и условия по джоном потому что всегда можно написать join таким образом что вы отберете уникальные поля то есть эти вещи тоже надо контролировать своих запросах и по сути дела это облегчит вам выполнение когда вы исключите операции поиска уникальных записей если они у вас предварительно гарантированно уникальные довольно распространенная ситуация когда же у нее две таблички джонни такими условию что получает кучу дубликатов чуть-чуть меняешь условия и а потом сделать distinct чтобы уникальной строчки получить меняешься чуть условие получаешь сразу уникальные строчки и у тебя запрос раз десять быстрее работает а быстро работающий запрос это у нас быстро полученный ответ бэг-энда мы быстро обработанные данные там как бы и снижение общей нагрузки ничего не тормозит следующей вещи это чрезмерное злоупотребление аккаунтами максом именами суммами всеми агрегатами функциями потому что эти вещи которые из раздела аналитики этим пользуются бухгалтеры когда считаю там зарплату они это делают 1 раз в месяц или 1 раз в неделю ну два раза в неделю но не каждые пять секунд если вы каждые пять секунд у вас активность базе данных с предстоит такими запросами значит что-то у вас не так слоги как работы с базой данных и вам нужно посмотреть на свои запросы и подумать о вообще правильно и я обращаюсь к ней может можно как-то переписать а скорее всего вы сможете найти более простое и элегантное решение и для базы данных и по читаемости запроса следующие такая подсказочка просто которое облегчает жизнь когда грн это довольно частенько если у вас лифт возвращает несколько тысяч записей тяжеловесной операции логичнее будет заменить это на экзист select и этого вам c срежет тоже потребление ресурсов сервера и ускорить запрос от таких вещей тоже ну как бы там нужно смотреть если select возвращает 2 3 строчки хорошо если там тысячами то лучше переписывать в под запросе очень часто left join можно заменить на такую же конструкцию экзист silex из таблички которую вас полив joy ну какие плюсы за когда это можно заменить когда из этой табличке слив join а вы не берете никакие строчки вам просто нужно проверить наличие в ней записи иногда это проще сделать через экзист если вы ничего не читается из таблицы убирается legend пишу пишите экзиста это будет быстрее читабельный и понятней очень важная вещь это уже в чуть-чуть сторону администрирования того как управлять ресурсами потому что у нас есть какая-то онлайн нагрузка как по которой мы должны отвечать быстро наиболее быстро без задержек и есть какие-то фоновые задачи которые мы должны там не знаю там балансов и считать какой-то отчётик собрать еще что то что выполняется достаточно долго что выполняется по ресурсам более трудоемко вот и такие задачи лучше разделять обычно вот просто в любой у нас проект ты книжка торый приходят ребята в начале у них 1 пользователь и уровень если это не под grease то есть ура если они создали другого пользователя назвали а еще дважды врать если он еще и не супер usa вот поэтому под разные задачи под разные как бы куски кода лучше создавать отдельных пользователей самый простой прием предпри пример я привел это как бы онлайн нагрузка когда мы должны отвечать быстро на короткие запросы и какая тяжелая аналитика лучше это развести по двум разным пользователям и тогда средствами операционные системы мы можем приезжать все по ресурсам пользователя просто процесса в операционке запущены от пользователя там но тут крон он называется можно там report его назвать как угодно и это нам позволит как бы делать и то и другое и при этом онлайн нагрузка не будет страдать и худо-бедно мы как-то посчитаем отчет который нам все равно не нужен прямо здесь и сейчас как правило всегда дается какое-то гандикапа времени позволяющий нам посчитать зачет большая проблема то есть если мы хотим иметь очередь пастбищ то есть если у нас есть очереди снаружи лучше использовать специализированное решение их полно это rabbit and user and you'll кафка там они все хорошо работают если вы умеете их варить лучших использовать когда хочется использовать в рамках базы данных ну все опытные дыба они все имеют грех за собой то что они писали свою очередь я тоже писал свою очередь но на самом деле есть решение которое написано был давно работает хорошо у него один недостаток плохая документация но если разобраться с тем какой функционал предоставляет там он на все случаи абсолютно жизни подходит пиджи пью на данный момент единственное решение для организации очереди внутри базы данных которые работают хорошо и не прогибают базу данных по ресурсам и не покатит потому что люди когда писали уже по всем кораблям прошлись она из недр skype когда еще skype не microsoft с кем был выше про соединения у вас в данных про нехватку но картинки страшилки вы видели то есть как бы там нагрузки 23 соединения было все остальное еду была забита с этими это на самом деле я часто вижу наворачивают накручивать накручивать много соединений на самом деле плоскорез не очень хорошо не очень любит большое количество соединений 100 200 300 это нормальное количество сессий которые он может поддерживать 1000 это уже извращения поэтому как бы посмотрите на настройки своих пулов в языках программирования срежьте до сессии по минимуму мог насколько это возможно и старайтесь не злоупотреблять ими потому что вы можете просто лишить себя соединение база при этом будет простаивать а у вас не будет работать приложение ну и самый лучший вариант это использовать пиджи bouncer пока тут у меня только пиджи баунсер транзакциям режиме это самое хорошее решение у него есть ограничение он не дает вам там prepared statements использовать нужно опять-таки следить чтобы не просочились какие-то сет устанавливающие там переменные сессии через bouncer в остальном только плюсы потому что он поднимает сразу нужное количество соединений и сам балансирует нагрузку с точки зрения того что выстраивается очередь запросы если вы уперлись одним пользователем в пуле соединений ничего страшного то есть у вас страдает только этот пользователь друг другие части в приложения работающие с этой базы данных не страдает штука важны и нужны надеюсь индекс свое детей допили то и будет у него конкурента балансира большие размеры таблиц чем это плохо но частично иван рассказывал на это один кусочек немного пропустил плохо это тем что технические процессы которые работают над таблицами типа wraparound вакуума просто вакуума они могут затянуться надолго и часами работать поэтому большой таблицы они ну не очень хороши и чтобы как-то облегчить жизнь нам работать с большими таблицами выборки из этих больших таблиц есть такая хорошая штука как частично индекс который вам поможет допустим у вас например проведем 100 назад сами вас валяться какие-то транзакции допустим финансовые и у них есть состояние обработанное состоянии ожидает обработки понятное дело что обработанных состоянию вас будет 99 процентов таблицы и ожидает обработки или от купленной транзакции у вас будет один процент поэтому вы можете составить яндекс и написать что в этот индекс за индексируется только те стройки в которой транзакции не являются обработанными у вас будет маленький яндекс и будут быстрый запрос это очень хорошо потому что читать большой много гигабайтный индекс это тяжело и парте цианирование секционирования я как мыши арок лист люблю парте цианирования но это не русское слово по-русски будет секционирование эта вещь помогает просто структурировать нам и развались большую таблицу на маленькие кусочки как правильно это делать ну и вам довольно много рассказал просто это действительно важная и полезная вещь и вот после того как вы это все проделали и вас вам стопроцентно полегчает и вы забудете о том что вам необходимо было шар жировать нагрузку вот и поживете какое-то время нагрузка у вас от роста проекта естественно вырастет тогда вот вы уже задумайтесь о распределении нагрузки с помощью репликации о чем скажу нагрузку на запись как свои выступления вы поняли то что если вы слишком много пишете значит это данные не для базы данных скорее всего для логов которые нужно хранить где-нибудь там батарейках там bigdata этого все отдельные товарищи то есть куча данных который никогда не используется но копится нам нужны данные с которым мы действительно должны работать это нужно понимать при работе с базы данных ну то есть как бы стремится к этому понятное дело что мир у нас не идеальные и мы ничего не знаем как какие основные повторные распределения нагрузки с помощью реплик это будет только читающая нагрузка вот потому что это единственная нормально работающей сковородке вариант без всяких отдельных extreme что на в дополнение обычно когда мы у нас проект начинается у нас есть мастер база данных который творится в это ведь этот беспредел тк с которым мы уже разобрались есть какой-то набор запросов которые у нас обеспечивают вып нагрузку они обычно идут по ключу что быстро прочитать то есть это какие-то строчки конкретно поедешь нику какие-то новые ставки и небольшой join и это все обычные онлайн нагрузка есть более тяжелая нагрузка которые являются ну так отчетный назовем да там или с какими сложными в поисками которые требует больше ресурсов больше там каких-то индексов дополнительных и больше времени на выполнение и есть ну назовём это за руку расчетам зарплаты очень тяжелые тому нагрузка которую выполняют крайне редко занимают много ресурсов и очень мучительный тяжелый процесс и хорошо если у нас есть реплика но если мы продвинутые ребята и озаботились of all tolerance и не доверяем одному серверу имеем 2 железные просто на случай если случится авария мы на него переключимся вот это исходное состояние что же мы можем с этим сделать как но как обычно происходит распределение этой нагрузки понятное дело что запросы которые каунт макс минин и какие-то долго выполняющиеся они вам не нужны прямо вот сейчас если запрос запустился вас условно говоря минуту назад вы получаете устаревшие данные ровно на минуту соответственно эти запросы можно отнести убрать на реплику реплика чем почему не любят реплики потому что у нее есть какой-то улыбнись и отставания но какое-то отставание по сравнению с мастером вот это касаемо наиболее используемого типа реплика реплика асинхронных реплик и все вот эти тяжелые длительные запросы мы можем с чистым сердцем и совестью убрать на реплику потому что ничего для нас не изменится единственное что нам нужно будет подкрутить один параметр мамок streaming delay позволяющий дни отстреливать эти длинные запросы грубо говоря он выставляется из расчета берем длительность самого долгого запроса увеличиваем в два раза задержку репликации и в принципе у нас не будет проблем мы будем гарантированно вычитывать данные с асинхронных реплики и нам уже сразу же полегчает потому что во первых два сервера на наполнение кашами разная то есть для быстрых запросов у нас к примеру могут нужны быть одни индексы для медленных другие соответственно двух серверах они в памяти кэшируется разные данные за кашированные мы живем хорошо вот быстрых данные у нас актуальные приходят всякие вот такие почетные длительной агрегации они приходят чуть позже красота что можно сделать следующим шагом следующим шагом мы можем сделать еще более долго отстающие реплику допустим но нам вот эти тяжелые отчеты которые когда приходит аналитики говорят эта модель хочу построить какой-нибудь или еще что-то пересчитать там перелопатить все данные понятное дело что на мастер и нам такая нагрузка будет мешать для этого мы можем или увести нужно синхронную реплику этот отчет или создать специальную реплику для отчетов который будет маг streaming delay вообще там сутки можно поставить как бы не страшно это отчеты тот который выполняется допустим несколько часов понятное дело никогда не будет у вас актуальный по свежим данных поэтому такая вещь тоже легко перенос и получается что вот на данной картинке у нас вот эти 2 2 реплики они более-менее онлайн нагрузку обеспечивают а это вот совсем для отчетов и как бы все хорошо никто не страдает и поэтому и мы по ресурсам еще от масштабировались и хорошо он для нас что можно сделать еще вот это каждый шаг просто как у нас обычно клиенты проходит стадии эволюции в сервер с базы данных то есть это жизненные примеры как это все порах проходит следующим шагом когда мы действительно в такую быструю нагрузку онлайн упремся это добавится реплику который будет синхронный или асинхронный с небольшим в kenshi небольшой в пенси в данном случае это там 10 миллисекунд 20 миллисекунд такие значения недостижимы мы помним то что все тяжелую мы серверу убрали на другие реплики и можно довольно быструю реплику построить а единственное что там требования к сети то чтобы сеть была бодрая и веселая и соответственно всю читающую нагрузку мы можем распределять между несколькими репликами но этот случай совсем крайней то есть когда вы действительно уперлись нет если идти по шагам свои слайдов как я это в начале шоу то вы скорее всего до этого этапа в большинстве случаев не доберетесь какая почему а и синхронные реплика написано синхрон или реплика ну и те кто был наверно такого дивана там есть небольшой нюанс синхронные реплика она заставляет страдать в вакуум в основном на мастере это нам выливается в болт таблиц и индексов и это выливается в итоге в ухудшении производительности базы данных поэтому лучше все таки асинхронное использовать реплики но если совсем надо совсем-совсем можно и синхронный но но их нужно включать гораздо гарантированно хороший сети так параметры сейчас я посмотрю что у меня там до параметрах то есть какие параметры нам действительно в практике полезны которые не работают и не сильно ущемляют системные ресурсы по сгрыз а внутренние маг streaming белый этот самый универсальный параметр то есть тут нужно просто для себя внутренний понять то что есть запрос который работает секунду он вас никогда не актуален и вы всегда можете отложить рипли к цию на секунду и получите ровно те же самые данные не что для вас не изменится если у вас часовой запрос в его час назад стартанули соответственно в него данные за к набившую ся в базу за час не попадут и вы можете спокойно реплику заставит отставать на час а если на частую на 2 тоже можете заставить отставать нету тут никакой проблемы просто этот с этой мысли нужно как-то жрицей и понять что как бы это работает это нормально это самый рабочий и это первый параметр который вам надо крутить hots can buy фидбэк то есть это когда нам нужно по каким-то причинам все-таки выполнять запросы и небольшое отставание в реплике иметь этот ну на самом деле все эти причины среди наших клиентов как правило разбиваются там а наши доводы но это предмет дискуссии большой к конкретной задачи бизнес но если вам это действительно нужно вы можете это включить только не злоупотребляйте этим у максимуму одна машинка отход стенда и фидбэка вы страдает of the vacuum растут размеры таблиц и индексов просаживается производительность запросов и базы данных этому понимаете это и для синхронных реплик по сути дела указывая в этом параметры на мастере именно реплик мы себе устраиваем двухфазный коми трехфазный ну сколько реплик там прописан там немного сложнее рога ритм но для общего понимания то есть ну и ждем подтверждения от куча реплик что везде у нас закончились данные и тут понимаете то что прописав синхронные реплики вы получаете к и системное состояние между базами данных в общем случае но при этом получаете просадку в производительности по записи потому что вам необходимо дождаться под подтверждение совершенной транзакции с каждой реплики и это может растянуться на очень много если у вас сетью проблемы или в какой-то момент пик сетевой нагрузки возникает очень параметр существуют к использованию не рекомендуется единственный действительно толковый это вот этот вот бак стендбай тренинги остальные ну очень редкие крайние случаи если вы задумывались нужен он вам или не нужен он мне нужен вам значит включать и так кстати у меня закончился и немного просто оставил о том как какие вообще типа репликации бывают для общего понимания в паз грехи именно такие ну почти из коробки скажем так то есть от мастер сервер и мы можем получать есть два типа репликации есть потоковая бинарная репликации когда мы копируем базу данных бинар на как есть есть асинхронные реплики то есть они идут с каким-то запозданием связанным с тем что данные нужно передать по сети и применить на сервер реплики их может быть установлена какой какое угодно количество к мастер серверу как правило мы на практике делаем одну две реплики не более того подключенный к мастеру и синхронная реплика это которую вы прописали в конфиге на мистер и от которой мы ждем подтверждению что там тоже совершился commit данных чтобы сделать его на мастере в общем-то единственная разница между синхронной и асинхронной репликой данные на нее так же медленно заползают как у вас случайно зависит от сети есть каскадные реплики эта штука была сделана чтобы не перегружать мастер и не перегружать сеть на мастер сервере потому что если мы пишем достаточно много с ним на мастер сервер мы можем просто сетевой сетевые интерфейсы забить патракова мире аппликацию если мы целый зоопарк реплик все натравим на master server поэтому придумали были сделаны каскадной реплики которые тянут изменения с любого типа синхронная синхронной реплики и позволяют нам но они обычно используется для запросов по которым не нужны совсем вот прямо свежие данные там смели секундными задержками очень удобная вещь большинстве случаев так и делают мастер несколько рельсовых огромных реплика нему реплика нему и дальше уже каскадные реплики если прямо уж очень сильно надо масштабироваться по нагрузке и к скальным репликам мы можем каскадной реплики но это уже такая так как это сказать реплицирования радио реплицирования практически пользы они не несут есть такая вещь как делает реплика о чем я сказал то есть есть файлик recovery ком в паз грехи и мы там можем ему указать что допустим эта реплика у нас должна быть отстающий на 3 дня и она будет стабильна на три дня отставать от мастер сера зачем это нужно для дипломов допустим мы зацепились там какие-то большой орды данных сделали а потом поняли через сутки что неправильно сделали и валя у нас есть как бы делает реплика где данные еще не испорченные мы можем оттуда их достать есть также поставленные реплика на паузу то есть местах делаем паузу репликации это в случае когда у нас небольшие дипой а то есть пазы на паузу поставили реплику изменения на нее не применяется с диплом или проверили все что хорошо и нет можем откатиться на да и еще куча от триггерные реплики и встроенного логическое это логические репликации которые идут кусочками вот в принципе пока в нашем контексте они нам не интересны этого доклада просто знаете что они есть у меня все вот он такой доклад про очевидные вещи но практика показывает что многие маги и помогают очень сильно вот на вопросы старыми я вообще тут как бы тусую можете поймать меня и задавать вопросы так вот я думаю тут еще этом ритуал нужно соблюсти спасибо я чуть не забыл кое-что спросить в настройках вала есть всякие параметры буферизации задержек вот в плане репликации если вариант чтобы через это сократить объемы трафика чтобы реплицировать не все подряд а то что поменялось какому-то моменту если у нас обновляется одно и то же по 200 раз подряд потоковой репликация она же непрерывная то есть остановка конкретным бинарных говорим и ну если мы много изменений делали никуда не денешься их будет много то есть мы тут в сетевой протокол больше упремся и в 1 поточность процесса как бы на кота репликацию и отдачей поэтому как то регулировать ну и смысла особого нет потому что реплики нужны чтобы там у нас были все таки данной более менее актуальной то есть сколько наделали делал в мастере столько должны какой-то моим получить в реплике просто как-то ну через файл можно через файловый архив то есть же люди репликации через за архив налогов то есть за него можно каким-либо образом регулировать потоковую не от на скидку нет все равно трафик не сократить это это дает трафик все равно не сократить до трафика будет ровно столько потому что нам нужно это изменение про страниц памяти как они хранятся на диске то есть они ровно так идут как бы там ни ничто не изменишь но единственное что там всякие вал джидда они как-то там выжимку делают но честно говоря доверия очень мало когда какая-то совсем к сторон я сделал выжимку данных ну и страниц а потом ее применил на реплики и уверенности в том что она это сделала корректно не очень много поэтому вот таким механизмом в системах бы копирования я не очень сильно . лучше как есть прямо страницами вы спасибо здравствуйте василиса доклад я хотел спросить по поводу соединений то есть вот насколько правильно вас понял самая оптимальная стратегия соединений это получается мы устанавливаем покопался в транзакционный режим и каким образом мы действуем мы pierre крест отправляем то есть держим соединение pirelli квест открываем его отправляем на погба унсар запрос и закрываем соединение а пока баланс оружия самостоятельно решает необходимо ли ему открывать новое соединение в рамках сейчас популяция объясню как он работает в режиме transaction балансиры создается пулы на пару база пользователь для каждой по базы пользователя он выделяет сколько-то виду соединение база устанавливает поднимает их все что приходит к нему снаружи но то есть для кого он как базу данных выглядит он вот эти все запросы пользователей база себе очередь помещает ее эта очередь обрабатывать по мере того как у него соединение освобождаются если вы будете бомбить долгими запросами то соответственно взобьются эти соединения старый будут очереди есть ну в общем он позволяет выигрывать потому что он не тратят ресурсы базы данных на перине цивилизацию сессии которые довольно тяжелый то есть правильно короткими запросами его бомбить чтобы нужно и большие запросы через bouncer ничего страшного приложение оно должно ходить через bouncer большинстве случаев можно в данном случае вы разграничивается ну он встает вас перед базой и вот это у вас краник которым вы регулируете для так тут какой-то регулирует поток запросов базу данных от конкретного пользователя вот это основной его плюс который вот позволяют и более эффективно баз данных использует спасибо здравствуйте андрей спасибо за доклад такой вопрос если успешные и да если успешные сценарии репликации когда реплики между дата центрами находится и худшем случае даже может быть в разных там странах есть канал живость канала когда нельзя как бы гарантировать ну то есть успешные сценарии географически разнесенных реплик это когда вы платите очень много денег за сеть между этими дата центрами если два канала есть но их живость нельзя как бы стопроцентно гарантировать ну тут вы должны понимать то что как бы у вас в любой момент в разрыв и реплика просто отстанет на какой-то момент все упирается в количество world сегментов которые вы храните на мастере или ли куда-нибудь архивируется и можете пережить такой разрыв ну то есть консистентные состоянии реплики мастера в разных dc а не только от сети зависит чем лучше читать все эти между ними тем они были can системного всех остальных случаях ну это чисто как это на случай если бомба упадет на главный dc у вас каких-либо данных это архитектурные приемы станут учений их нет совсем ласту расстоянии можно у вас будет замедлена обычно хотят чтобы было все быстро и хорошо то есть как бы нужно понимать что будет медленно и быстро там никогда не будет ну то есть быстро будет задорого ну спасибо так она дана всевышего заклад андрей вопрос вы рассказали про распределение нагрузки у нас есть мастер есть реплика реплика с отставанием асинхронная просто асинхронная еще где-нибудь сбоку есть какая-нибудь каскадная реплика и как в таком случае расстраивается файла wear я имею ввиду как будет настраиваться перетасовка какой из серверов станет синхронный с основанием понял в общем вопрос такой когда у нас есть много реплик разного типа и есть у нас еще отдельные как правило тузы которые позволяют of the full озеру для подвеса устроить и случай аварии с мастер сервером назначить за промо мутить какую-то реплику который станет мастер сервером и переключиться долга нагрузка какого-то общего решение нету то есть каждое решение но по своим каким-то при принципам принимает вот это решение о том кто станет мастером но обычно выбирается реплика с наименьшим отставание из у которой большие количества логов была проиграна к этому моменту та реплика и станет мастер-сержант но обычно но эти вещи настраиваемые потому что можно исключить некоторые реплики и завтра файла мир и чтобы туда никогда не переключалось это конкретно от каждого решения зависит который вы выберете то есть там спасибо заложить вырос на можно ли сделать реплику базы данных само в себя определить по одной таблице они по не напрямую скопил легче вот так еще раз пожалуйста можно ли сделать аппликацию какой-то таблицы само в себя в базу данных саму себя напрямую большую таблицу реплицирует уже базу данных но в другую таблицу с другими инеем которое секционирования индексирован по-другому и более удобно для других видов поисков но это вопрос а я сейчас рассказывал про в контексте бинару потоковой репликации бинарные то есть там весь instance адреса копируется как есть у вас вопросы о на из разряда того как использовать магическую репликацию все зависит от того какой инструмент вы выберете или устроена магическую или триггер ную или сами напишется но в принципе ничто не запрещает можно это сделать как бы подобрав нужный инструмент но это как бы дополнительный код должен быть написан вами сами из коробки эти вещи требует все-таки некоторого знания как сделать ну то есть это сторонние утилиты большинстве случаев и нужно покопаться с ними на так принципе да кому надо те так и делает друзья два вопроса раз-два и в кулуары привет спасибо за доклад у меня есть вопрос что делать с каунтом если они все-таки нужны в регулярных запросов например можно их триггерами считать или функциональные индексы или какой подход и вы порекомендуете вы смотрите если вы каждый раз задаете аккаунты ну во первых нужно задать вопрос себе зачем они вообще нужны то есть это больше вопрос наверное к бизнесу который затребовал этот функционал потому что ну по 10 миллионы там допустим возьмем таблицу который 10 миллионов строками мы считаем каунт по ней всей да понятное дело что эти 10 миллионов строк через пять строк добавленных или удаленных они сильно не изменится и останутся те же самые 10 миллионов и вопрос тогда она стоит задать из бизнеса зачем тебе это вообще знать каждый раз статичная ситуация понятное дело когда у вас к нам допустим вы считаете отбираете там пять или три строчки такой сценарий иметь то есть только именно нужно смотреть на запрос и смотреть именно адекватность вал то есть если у вас каунтом идет просто тысяч им строчек ну как бы эти 100000 строчек через пять минут также будут теми же самыми со 100 тысячами строчек а вы допустим этот раунд запускаете 1 секунду как бы не целесообразно то есть это именно вопрос больше взаимодействия разработчика и того кто ему стоят задание там по бизнес-логики приложения которое вам нужно то есть к базе данных она почти не имеет отношения и хорошо спасибо прошу андрей спасибо большое за доклад было интересно проследить вот за эволюцию проблем которые возникают ваших клиентов и за эволюцией как бы решение и вопрос собственно такой вот с вынесением аналитических запросов на отдельную реплику вот вопрос к коту наилучшим образом организовать в приложении но я имею ввиду и можно ли это сделать пейджа bouncer или в какой-то другой utility чтобы приложение сам у нее и не решала на какой инстанции конкретно ему идти но не поддерживала соединение с этим инстанциями если это момента практике да понял я ваш вопрос в общем это конфликт интересов между администраторами базы данных разработчиками разработчики хотят чтобы за них кто-то подумал распределил запрос есть ситуацию вас хранимая функцию да там какая-нибудь написано но вы делаете логику базе данных да там храним к как вы вызываете эту храним q select имя храним какие параметры что внутри храним ки это запрос на чтение на запись может там tranque таблице автоматически инструмента они в принципе есть природе но пользоваться ими крайне не рекомендую потому что это нужно опять-таки в контексте вашего бизнеса и того какая войников приложения приложения должна сама в нем должно быть прописано эти запросы могут работать только на мастере эти можно запустить на реплику то есть лучше будет если вы пойдете путем когда это сразу будет приложение об этом знать в него будет два соединения одно для реплики одно для мастера как получается эти соединения можно автоматически через сервис discovery можно прописать но все зависит от инфраструктуры которую вас используется при разработке но если вы пойдете путем когда это делает приложение и не искать инструментов вы избежите кучу бед пример я привел как бы одной среды и я понял спасибо на я имею ввиду что этот инструмент естественно предполагал бы что мы могли бы настроить его и допустим явно ему сказать какие там по маске возможно за просто или но а можете назвать для примера хотя бы какие инструменты есть хотя я понял что лучше это делает руками в приложения какие инструменты но бюджету есть который поможет но по факту мы его не рекомендуем использовать понятно спасибо андрей кому кого мы назовем лучшим вопросистый сейчас вот последнего молодого человека это это на самом деле самый такой неудобно жизнь жизни бьющий вопрос многих касающийся супер спасибо андрей осталось поклониться 28 января"
}