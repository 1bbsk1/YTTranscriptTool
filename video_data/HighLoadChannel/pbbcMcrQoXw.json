{
  "video_id": "pbbcMcrQoXw",
  "channel": "HighLoadChannel",
  "title": "Как VK вставляет данные в ClickHouse с десятков тысяч серверов / Юрий Насретдинов (ВКонтакте)",
  "views": 8689,
  "duration": 2448,
  "published": "2018-11-19T03:05:12-08:00",
  "text": "всем привет меня зовут рединов как уже представили меня я работаю я буду вас данных ли house но с нашей сервировка там десяток десятки тысяч и вопрос кто из вас был на таком же докладе но находилась сибири ну вот в общем можете промотать где-то до 30 минут и сразу и вот там будет новый но хорошо значит чем буду рассказывать ну во-первых ну что мы делали зачем нам понадобился crack house ну соответственно почему мы выбрали как вы производительность вы можете примерно получить ничего не конфигурирует специально и скажу дальше там правом буферной таблицы проблема которая у нас с ними были и про наши решения которые мы разработали закон совсем kitten house ale house зачем нам понадобилось вообще что-то делать вконтакте всегда все хорошо да вот значит мы хотели собирать дебаг логе их там было сотни терабайт данных может быть там еще статистику как-то по по удобнее считать и у нас парк серверов там десятки тысяч из которых это нужно делать ну вот как бы почему мы решили ну нажим наверняка был ли решение для хранения логов вот есть такой public by coin . очень рекомендую подписаться на него так и минут когда неполярной рекламы что такое logs этот движок возвращающую пустые массивы но движками в к называется то что микро сервисами остальные называет вот и такой вот стикер улыбающийся даже много лайков довольны как так ну слушайте дальше что вообще можно использовать для хранения log off ну например вот ну нельзя не упомянуть hadoop потом вот например там р syslog хранение файлов этих логов там лсд кто знает что такое возле нет ни не этот лсд и файлах хранить соответственно тоже там cliff house да странный вариант какой-то ну или вообще говорит свой смешной вариант что мы хотим мы хотим чтобы нам не нужно было особо парится с эксплуатации что-то на робота с коробки желательно или с минимальной настройкой хотим писать очень много читать быстро и хотим хранить это там все эти месяцы и годы то есть но долго то есть мы можем хотите разобраться в проблеме какой-нибудь которые нам пришли говорят нам нас то чет не работает а это было там три месяца назад и мы хотели хотя хотим иметь возможность собственно посмотреть что было 3 месяца назад ну это сжатие данных понятно почему будет плюсом потому что она сокращает количество место которое занимается и у нас есть такое интересное требованием иногда опишем output каких-нибудь команд например влоги они она может быть больше четырех килобайт спокойно совершенно и это если это штука умеет работа по египет и не нужно тратить у меня не будет никого вверх иду на соединение для большого количества граф это будет плюсом водка или давайте посмотрим что предлагает окон собственно нам во первых у нас есть logs энджин это наш движок он в принципе все умеет даже длинные стройками писать ну прозрачно да но нажимает на принципе можем большие колонки сами сжимать если захотим ну мы конечно не хотим по возможности единство проблема он умеет отдавать только то что у него помещается в памяти остальное чтобы прочитать нужно доставать белок этого движка и собственно довольно долго хотя данные он хранит что не может отдать поэтому она дает пустые массивы вот значит какие есть варианты до другие ну например вот hadoop простота эксплуатации кто читает или hadoop легко настраивается вот да и с записью конечно же проблема с чтением но вопросы иногда возникают то есть принципе как бы я есть я бы сказал что скорее нет то есть особенно догов долговременных ранения ну конечно да там сжатие данных до длины строки понятно что можно записывать а вот записывать с большого количества все на сами учет делать я все слова на самом деле мы его использовали как запасной вариант для того чтобы можно было без дан помело почитать но он не может в длинной строки в принципе больше 4 килобайта мне можешь записать сжатие данных точно также как бы самим над делать и чтением будет идти из файлов потом есть вот подушная разработка лсд то же самое по сути что я список длинной строки поддерживает но и теперь вот не умеет и собственно ну из-за этого к сожалению но там довольно много переписывать нужно поверить и и все чтобы 10 серверов записи осуществлять и вот а вот смешной вариант elastic search ну как сказать с чтением у него все хорошо то есть он читает быстро но записи не очень хорошо то есть во первых он данные если сжимает очень слабо скорее всего для полна текста поиска требуется более такие объемной структуры данных чем исходный объем эксплуатировать тяжело с ним как бы часто проблема возникает ну и опять же запись была stick все на сами должны делать но так ли house ну идеальный вариант понятное дело и единственное что опять же запись десятков тысяч серверов это проблема но хотя бы она одна мы ее можем как не попробовать решить и вот про эту проблему весь остальной доклад какую вообще производительность такое хаус можно ожидать кто из вас ну вообще про кликал с не слушала не знаю нужно рассказывать не нужно но в общем очень быстро то есть там ставка 10 гигабит в секунду всплесками там то там до 10 гигабит в секунду на самом деле может выдерживать она вот такой конфигурации то есть там ну 2 6 ядер на xeon а ты даже не самые мощные дома есть о 6 гигов оперативы доктора байт в еде который никто не настраивал дефолтные настройки сейчас алексей наверное плачет ну что мы ничего не настраивали у нас все работало так вот ну и соответственно скорость сканирования допустим порядка 6 миллиардов строк секунду можно получить если данный хорошо сжимаются если вы там допустим лайк пат текстовой строке делаете тону тону в сто миллионов строк в секунду можно сканировать но он кажется что весьма быстро а вот как будем вставлять но вы знаете что в к на печке ну вот на из каждого пить пиво рокера будем почти типе вставлять в кли house в табличку и аж три на каждую запись кто видит проблему в этой схеме булат почему-то не все подняли руки давайте раскрывать скажу но paper the server много соответственно как бы соединением это становится много дает плохо потом вообще мираж-3 лучше вставлять данные не чаще чем 1 секунду а кто знает почему ну ладно хорошо я расскажу чуть чуть подробнее об этом и еще интересного про что мы как бы не аналитику делаем нам не нужно обогащать данные соответственно мне нужны промежуточным сервера мы хотим вставлять прямо в кли house ну желательно чем приметил лучше вот соответственно как осуществляется вставках на шторе почему в него усы вставлять не чаще - секунды или реже дело в том что при hal столбцов и базу данных и сортировать данные в порядке возрастания первичного ключа и когда вы делаете ставку на самом деле создается там ну количество файлов как минимум по количеству колонок в которых данные отсортированы в порядке возрастания первичного ключа и это создается там отдельная директория или там не за набор файлов на диске на каждый insert и потом бы следующую вставка идет и фоне они объединяются в большего размера партиции поскольку данные отсортированы тасмит жить 2 сортированных файла можно без потребления большого потребления памяти вот но как вы догадываетесь если записывать по 10 файлов на каждый insert the как бы cliff house очень быстро закончится или вас сервер поэтому рекомендуется вставлять большими пачками соответственно ну мы схему первые мы никогда не запускали production мы сразу запустили вот такую которая здесь номер 2 имеет у нас есть там он здесь представьте себе что там где то около тысячи серверов на которых мы запустили там просто печки и на каждом сервере стоит наши вокальный агент который мы назвали kid in house который держит одно соединение с клик хаусом и 1 несколько секунд вставляет данные оставляет данные не в метре от буферную таблице у которой как раз служит для того чтобы не вставлять на прямой в h3 сразу что это такое то есть буферной таблицы этот кусок памяти page or die раваны то есть ее можно часто вставлять они состоят из нескольких кусков и каждый из кусков работает как независимый буфер и они независимых ложится то есть если вы делаете например короче говоря есть вас могу кусков буфера той и вставок будет много в секунду читать из этих таблиц можно тогда вы читаете объединение содержимого буфера и родительской таблицы но в этот момент блокируется запись поэтому лучше не читать оттуда и ну очень хороший кпс показывают буферной таблицы то есть вот до 3000 gps вас не возникло вообще никаких проблем при вставке и ну понятно что если допустим пропала питания у сервера то данные можно потерять ну потому что не только в памяти хранились при этом схема с буфером усложняет alter потому что вам нужно сначала дропнуть старую буферную таблицу со старой схемой данные никуда не пропадут при этом потому что они запрашиваться сначала перед тем как таблицы удалиться потом вы альтере те нужной вам таблицу и создаете буферную таблицу заново соответственно ну пока нету буферной таблице у вас данные никуда не льются но вы можете их как бы хранить на диске хотя бы локально об этом чуть позже вот соответственно что из себя представляет этот хаос это прокси угадайте на каком языке я собрал самые хайповые темы на своем докладе и так лихо us go там может быть ещё что-нибудь вспомню в общем да ногой это написано потому что я не очень умею писать на sip и не хочу с этой сна вот она держит одно соединение с каждым сервером умеет писать в память то есть если например мы пишем р-р логе в кли house то если калле хауса не успевает вставлять данные все-таки если их слишком много пишется то мы ни пуха им по памяти мы просто выбрасываем остальное потому что если у нас пишется там несколько бит в секунду ошибок то наверно можно какие-то выкинуть собственно kid in house это умеет плюс он умеет надежную доставку то есть запись на диск на локальной машине и раз в какое-то время там раз пару секунд он пытается данные из этого файла доставить мы поначалу использовали обычный формат в и льюс то есть не какой бинарный формат текстовый формат какой обычная сквере вот но дальше произошел вот такое вот мы использовали считая надежную доставку писали логе потом решили ну это был такой условно тестовый кластер на несколько часов его потушили и подняли обратно и вот с 1000 серверов пошла вставка и в общем оказалось что у crack house а все-таки модель трат на соединения соответственно в 1000 соединений активная вставка приводит к плоти врач на сервере где-то там полторы тысячи на удивление сервер принимал запросы и данные такие все-таки вставились через какое то время но очень тяжело было сервера это обслуживать вот ну какое решение для модели connection это индекс соответственно мы поставили нужен expired коли хаусом заодно настроили балансировку перед было сыров куна две реплики и соответственно у нас еще в два раза увеличивает скоро вставки хотя конечно не факт что так должно быть ну вот у нас увеличилось два раза мы ограничили количество соединений к хаосу кооп стрим и соответственно больше чем то 50 соединений кажется смысла вставлять нет ну вот и потом мы поняли что вообще эта схема имеет недостатки потому что у нас здесь как бы только один индекс и соответственно если ты нужен их сложиться несмотря на наличие реплик мы данные теряем ну или по-крайней никуда не пишем это мы сделали свою балансировка нагрузки также мы поняли что кликал все-таки для логов подходит и демон начал писать свои локи тоже при house очень удобно если честно до сих пор используем их для других демонов потом но нарушили так интересно проблема что если вы используете там не вполне стандартный способ вставки русские войска или режиме это фарсис и полноценный с келли парсер основе st который довольно медленный и соответственно мы добавим настройка чтобы такого не происходило никогда сделали да свою болтовку нагрузки hell стейки чтобы соответственно если одна на дубе умирает мы все она вставляет данные научились там у нас уже стало достаточно много таблиц чтобы она стала нужна разная класть иракли хауса иметь и еще мы начали думать о других использования например мы хотели писать блоги из-за нужен x модули они как бы по нашим рпц общаться не умеет ну хотелось бы там хоть как-нибудь их отправлять вот научиться например при типе принимать науку хвост событий и потом уже их пересылать ли house итоговая схема стала выглядеть вот так четвертый вариант этой схемы то есть на каждом сервере перед клик хаусом стоит индекс то есть на том же сервере причем и просто науках о спроектируют запросы с ограничением количества соединений в 50 штук и вот эту схему же рабочие вполне было то есть с ними было довольно все хорошо ну вот мы жили так где-то месяц все радовались добавляли таблицы добавлять добавляли в общем оказалось что то как мы создали буферные таблицы она не очень оптимально скажем так было мы делали по 16 кусков в каждой таблице и flash интервал там не знаю пару секунд у нас было 20 таблиц и грубо говоря в каждую таблицу шло по 8 ставок в секунду и вот где-то в этом моменте cry хаус начал все-таки иногда запись записи начинали тупить они даже не то что не проходили у engine икса по умолчанию была такая интересная штука что если connect и заканчиваются кооп стрим от она все новые запросы он просто отдает 502 и вот он где то пологом который собственно в самом же клик хаусе и посмотрел где-то полпроцента запросов вылились соответственно утилизация диска была большая много мейджи было что я сделал я естественно не стал разбираться в том что почему именно заканчиваются connect и кооп стрим а я решил что нам нужно управлять этим самим давайте так откуп яндекс яндекс не знаем про то какие таблицы в клик хаусе есть соответственно заменил дженкс на reverse proxy который тоже я сам написал он что делает он как бы работает на основе библиотеки fast очки теперь брошенный то есть как бы быстрый почти такой же быстрый как яндекс извините игорь миссию тут присутствует вот он умеет понимать что какие-то запросы это insert или это select и соответственно разные пола соединения держат для разных видов запросов и соответственно даже если например мы на вставку не успеваем выполнять запросы to select и будут проходить ее наоборот и группирует данные по буферном таблице мы с небольшим буфером чтобы если например были какие-то ошибки вставки там синтаксические ошибки и так далее чтобы они не особо влияли на остальные данные потому что когда мы оставляли просто буферная таблицы ты у нас были маленькие baci и все ошибки синтаксиса влияли только на этот маленький кусочек здесь они уже будут влиять на большой буфер есть маленький он типа 1 мегабайт то есть не такой уж и маленький и вставка синхронно то есть она по сути заменяет индекс делает по сути тоже самое в нашем случае что и делаешь индекс до этого кита house локальные меня для этого не нужна и поскольку он использовал степи он очень быстрый можно там больше ста тысяч запросов в секунду единичных insert of делать через reverse proxy вот то есть мы теоретически можно вставлять по одной строке в китае house reverse proxy мы конечно к не дело вот и соответственно схема стала выглядит вот так то есть kit and houses reverse proxy группирует много запросов в по таблицам и уже в свою очередь буферной таблицы вставляют в основные вот прошу прошение и стал такая интересная проблема кто-нибудь из вас использовав вас то есть и т.п. вот кто при этом использовал force touch дпс пост запросами ну да наверно так не стоило делать на самом деле потому что он буфере зуи тело запроса по умолчанию у нас размер буфера 16 мегабайт был выставлен и вот как тут вставка перестала успевать в какой-то момент из там со всех десятков тысяч серверов начали приходить 16 мегабайт ные чанки и они все бы фрезеровали в памяти перед тем как отдаться в кли house и соответственно память кончалось out of memory киллер приходил и убивал reverse proxy и так вот ну или cliff house который мог больше жира чем reverse proxy теоретически и как бы цикл повторялся не очень приятная проблема хотя мы на это наткнулись тоже там через несколько месяцев эксплуатации только что сделал я опять же я не очень люблю разбираться в том что именно произошло потому что ну мне кажется довольно очевидно что не надо бы фрезеровать память я не смог пропатчить fast архетипе хотя пытался но я нашел способ как сделать так чтобы не нужно было ничего патчить и придумал свой метод вычислите пин назвал водки там вот ну логично в крокет он ну как еще и соответственно если на если в метод китон приходит приходит запрос на сервер света дам kit and the server должен ответить мяу логично если он это отвечает то считает что он понимает протокол и дальше соединение переходит я перехватываю соединение у вас и степи такой метод есть если деньги переходят второй режим зачем мне это нужно я хочу управлять тем как происходит чтение из tcp соединений в цепи есть замечательное свойство что если никто не читается той стороны то запись начинаешь ждать и соответственно память особо не расходуется на это и вот я читаю где-то нос 50 клиентов за 1 то есть но с 50 потому что 50 и уж точно должно хватить даже если это из другого dc ставка идет потребление памяти уменьшилось с таким подходом как минимум 20 раз но я честно говоря не смог заметить во сколько именно потому что вы это уже бессмысленно то есть она на уровне погрешности стала протокол бинарная то есть там идет имя таблицы и данные нету http заголовков поэтому я не использовал вот socket чтобы ну между браузерами не нужно общаться я сделал протокол который подходит под наши нужды ну вот и с ним стало все хорошо вот и недавно мы с еще одной интересной особенностью буферных таблиц столкнулись и вот это уже проблема намного сказать больнее чем остальные представьте себе такую ситуацию у вас уже активно используется treehouse вас там десятки сервировки хаусом и у вас есть некоторые запросы которые читают очень долго то есть там больше допустим 60 секунд и вы такие приходите и делайте alter в этот момент пока select и в эту таблицу которые начались до alter они пройдут alter не начнется но вероятно там какие-то особенности того как работает ли house в этом месте может быть кстати говоря это можно исправить или нельзя алексей можно ли это из и избежать алексей ответил в своем стиле вот ну в общем понятно что на самом деле это не такая уж большая проблема в принципе но с буферным таблицами она становится больнее потому что если допустим у вас alter тайм-ауте c причем за той молодиться может на другом хосте то есть не на вашем да на реплики например то как бы вы такие значит удалили буферную таблицу у вас задавался alter ну или вернее какая-то ошибка altera произошло да ну что вы делаете ну надо же все-таки чтобы данные продолжали писаться вы создаете буферные таблицы обратно по той же схеме которая была родительской таблицы потом alter проходит все таки завершается и буферная таблица начинает отличаться по схеме от родительской и соответственно ну в зависимости от того что был за alter может и в тарка больше не идти в эту буферную таблица это очень печально еще есть такая табличка может быть кто не замечал в новых версиях ли хауса курит рад лак и по умолчанию но покрыли в какой-то версия была единичка вот мы накопили 840 миллионов записей за пару месяцев 100 гигабайт связано это с тем что туда писались ну может быть сейчас кстати не пишутся писать все стерты каком рассказывал у нас истертый маленькие у нас очень много insert of в буферный таблицы то есть понятно что это отключается это я просто рассказываю что я видел у нас на сервере почему это еще один аргумент против того чтобы все таки использовать буферной таблицы вот то есть спать очень грустит а кто знал что этого товарищ его зовут spotty подняли руки сотрудника vk ну ладно обычно планами не делятся да потому что мало ли вдруг вы не будете этой выполняйте потом будете выглядеть как то не очень хорошо да в чужих глазах но я рискну на мы хотим сделать следующее что буферная таблицы как мне кажется все таки действительно это костыль и надо бы фрезеровать самим вставку мы все еще не хотим фрезеровать ее на диске поэтому мы будем бы фрезеровать вставку в памяти и соответственно когда делается insert он уже не будет синхронной он будет работать уже как буферная таблица будет вставлять в радиусе к табличке ну когда-нибудь потом и по отдельному каналу сообщать о том какие вставки прошли какие нет почему нельзя оставить синхронные ставку она же намного удобней дело в том что если вы вставляете с 10000 хвостов то все хорошо у вас каждого hasta будет литься по чуть-чуть вы там раз в секунду вставляете все прекрасно но хочется чтобы эта схема работала из двух машин и что вы могли лить на на большой скорости может быть не выжимать максимум из гли хауса ну хотя бы там не знаю 100 мегабайт в секунду писать с одной машины через reverse proxy эта схема должному что берется и на большое количество на маленькая поэтому мы не можем синхронно ждать на каждую ставку по секунде поэтому она должна быть асинхронной и точно также асинхронные подтверждение должны приходить то есть после того как уже вставка совершилось мы будем знать о том прошла она или нет и самое главное еще что в этой схеме мы точно знаем прошел вставка или нет потому что представьте себе такую ситуацию у вас есть буферная таблица вы вне что-то записали а потом допустим таблицы перешел в редон ли и пытаются зав ложится буфер куда пойдут данные да куда придет данный алексей останутся в буфере но мы этого в этом уверена быть не можем а вдруг какая другая ошибка которая не останутся буферы данные или останутся всегда ну алексей нас убеждают в том что все будет хорошо ну у нас нет причин ему не верить но все равно если мы не используем буферную таблицу то и проблем с ними точно не будет но и соответственно в два раза больше таблица тоже создавать как бы ну не удобно хотя в принципе больших проблем нету вот это план а теперь давайте поговорим про чтение собственно мы здесь тоже написали свой инструмент до казалось бы ну зачем здесь чтобы описать свой инструмент а кто пользовался the big сам как-то мало людей поднял руки кого устраивает производительность табекс а ну вот нас не устраивает и он не очень удобен для именно просмотра данных всем для аналитики подходит нормально для просто для просмотра он им не оптимизирован вот поэтому мы написали ну я написал свою с в интерфейс он очень простой он имеет только читать данные он не умеет там графики показывают ничего не умеет вот на умеет показывать то что нам нужно например какое количество строк в таблице там сколько места она занимает без разбивкой по колонкам то есть просто он такой очень базовый интерфейс но это то что нам нужно вот выглядит он очень похожи на сиквел право но только сделанные на twitter bootstrap и прочим второй версии вы спросите до юрия почему на второй версии это как бы уже какой год и 2018 ну в общем делаю это на самом деле давно для мускуле и просто я там поменял пару строчек в запросах он стал работа для cliff house а за что отдельное спасибо что парсер очень похож на московские запросы очень похожи очень удобно особенно поначалу вот на уме и там фильтрация таблицы умеет показывать структуру то содержимое таблицы сортировать позволяет фильтровать по колонка показывает запрос который получился в итоге там affected ростом сколько в результате ну то есть такие базовые вещи для просмотра данных работать довольно быстро редактор тоже есть я честно попытался украсть редактор целиком из то бегство но не смог я не все таки не java-script ну как-то он работает вот значит в принципе на этом все я вам хотел сказать что cly house несмотря на все вот эти описанные проблемы у нас не очень хорошо подходит диалогах то есть он самое главное решает нашу проблему он очень быстрый и позволяет там фильтровать логи по колонкам в принципе ну да вот буферные таблицы как-то показали себя не слушай стороны но как бы обычно никто не знает почему вот может быть вы теперь больше знаете где вас будут проблемы вот те цепи ну вообще ввк приняты спросите и т.п. и когда я использовать о себе ну так не никто конечно не говорил что юрий ну ну ты что типа не зятем ну или пи вот оказалось что теперь не так уж и страшен единственно что новое с ростом десятки тысяч активных соединений которые у вас пишут надо чуть-чуть как бы аккуратнее его готовит но можно и довольно легко guide on how the lighthouse я обещал выложить на highload сибири если все подпишутся на наш паблик в кабак and и знаете не все подписались так что мы выложим ну вот я уже с вас и конечно требовать подписаться на наш паблик не буду вас и так слишком много кто-то может даже обидеться наверное вот но как бы все равно подписывайтесь пожалуйста и это даже такие глаза у котика и сделать вот типа пожалуйста а вот и ссылка на него кстати большое спасибо гид хоп нашего тут вот вот пользовались кли хаусом и ваши волосы будут мягкими и шелковистыми друзья теперь вопрос и сразу после того как мы вручим благодарственную грамоту и твой доклад на выходе а как вы смогли записать мой доклад новых с если он только что закончился ну ты что ж не можешь до конца определить как лихо у сразу заработает или не заработает можно пожалуйста вот микрофон юноша друзья пять минут на вопросы добрый день спасибо большое за доклад у меня два вопроса начну с несерьезного влияет ли количество букв в названии kid in house на схемах там 347 на удовлетворенность котиков сейчас количество чего букв ти там три идти где-то 2 ti неужели это не поправил ну конечно влияет то есть разные продукты я просто вам вас обманула все это время он я шучу не влияет в общем а вот здесь нет это одна это этой опечатался спасибо второй вопрос серьезный вы говорили но насколько я понимаю в crack house буферная таблице они живут исключительно в памяти на диск нибудь рисуется соответствие не являются persistent до при этом у вас на клиенте осуществляется буферизация на диск что подразумевает некую гарантию доставки этих самых логов но случае что на акре хаусе это никак не гарантируется вот поясните пожалуйста как осуществляется гарантия за счет чего вот этот вот механизм подруга теоретически противоречия здесь нет потому что вы при падении и хауса новыми до можете детектив там миллионом разных способов на самом деле при падении кли house и то есть не корректное завершение да вы можете круг говоря отматывать немножко свой лук который вы записывали и начинается с момента когда точно все было хорошо ну то есть допустим на минуту назад отмотать считают что за минуту назад вашего все то есть it in house держит соответственно окно длиннее и в случае падения умеют его распознавать и проматывать но это в теории на практике мы этого не делаем и как бы надежная доставка это типа от нуля до бесконечности раз но в среднем один а то есть нас устраивает что если cliff house падает по какой то причине или сервер работает и мы немножко теряем все осталось экстренных случаях ничего страшного не будет происходить спасибо большое за сим здрасте размер не самого начала оказалось что действительно вы будете использовать виде пилот сам начала бег доклада вас в ттп я там все такое и большинство проблем к этому вы описали как я понял были вызваны именно этим решением также мы используем т.п. ну по сути да не устаю семенов асхат atpl вас были проблемы с количеством соединений у вас были проблемы и так далее если вы просто используемый в типе сэкономили бы себе время но были бы проблемы там с длинными сообщениями там еще что то зачем были бы с длинными сообщениями но поскольку вам тылу может не влезть или еще что-то ну там свои проблемы могут возникнуть но суть вопросов в чем почему все таки почему все-таки не едите я верю в то что авторы которые разрабатывали эти секреты намного умнее меня и умеет лучше меня делать стерилизацию работа спать и ну серьезную пакетов до чтобы они шли одновременно как бы регулировать там игры окно отправки не перегружать сеть давать обратную связь о том что не читает не считают с той стороны и так дают все бы эти проблемы были бы но по моему мнению были бы и в египет только мне пришлось бы писать еще больше кода чем я уже написал чтобы все то же самое реализовать самому и скорее всего плохо потому что новое я никогда не ну ну как раз по мне нужно носить даже не очень люблю писать не то что там как раз удобно отправил лак и не ждешь ничего тебя абсолютного стены холодно а далее пришло уведомление уведомление о том что все хорошо значит пришло не пришло значит плохо мне нужно и то и другое мне нужно и уметь управлять без гарантий доставки из гарантий доставки два разных сценария некоторые логе мне нужно не терять ну или не терять в пределах разумного хотя он и не буду отнимать время это надо дольше обсуждать спасибо вот у кого есть вопросы ручки в небо был где-то среди не доклада привет я саша появилось ощущение что можно было кроме тисе пи использовать еще готовое решение там кафку какую-нибудь например рукав к но я говорил что я не хочу используя промежуточного сервера потому что ну в кафку все равно окажется с десяти тысячах оставь это на самом деле нас больше десятка в 1100 вставку прямо вот без каких-либо проксей кажется тоже может быть больно делать к тому же самое главное она всем дает лэйтон sean дает там лишних аст и который нужно иметь я не хочу их иметь я хочу в итоге уже так и получилось всё равно нет фрапси каких-никаких хостов не то это все работает на хостах с клих хаусом но тот китон house риверс который он где живет на хостесс cliff house ему не пишет на диск ничего ну допустим устраивает вас до можно зарабатывать можно до на самом деле просто много костылей и ради того чтобы получилось примерно тоже самое и вот предыдущий ответ на тему тисе пи как бы он противоречит на мой взгляд вот этой ситуации просто какое-то ощущение знает что можно было сделать на коленке за гораздо короче гораздо меньшее время а еще почему я не хотел исправить кафку потому что были в чатике хауса терминал русском довольно много жалоб на то что сообщение сказка терялись не и самые кафки а в интеграции кафки и кли хаоса и там или там не коньяк тела штата то есть грубо говоря нужно было бы тогда еще и клиент для кафки самого писать я не думаю что было чувство более простое более надежное решение спасибо мне еще вопросы будто на эту тему хороша вот на первом ряду бы stable скажите а почему какие-нибудь очереди не пробовали или какой-нибудь такую общую шину для раз вы говорите что у вас асинхронно можно было через очередь гонять сами логии в ответ получает уже асинхронную через очередь а предложить просто как какие например можно было бы очередь использовать любые даже без гарантия того что они по порядку идут родис какой-нибудь там рамку ну у меня есть ощущение что редис скорее всего не сможет тянуть такой объем вставки даже на одном посте который вытягивает 80 на нескольких серверах который вытягивает cliff house я не могу вам подкрепить это какими-то свидетелями не bunch макового но мне кажется что редис здесь не самое удачное решение в принципе можно рассматривать вот эту систему как такой импровизированный дочери сообщение но которая заточена под только вот cliff house юри спасибо большая на этом предлагаю закончить вопросы и ответы и сказать кому из-за давших вопрос мы подарим книжку я хотел подарить книжку первый человек который за вопрос прекрасно отлично великолепно спасибо огромное"
}