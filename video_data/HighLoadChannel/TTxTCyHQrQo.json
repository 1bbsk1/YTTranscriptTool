{
  "video_id": "TTxTCyHQrQo",
  "channel": "HighLoadChannel",
  "title": "Arc — внутренняя VCS для монорепозитория Яндекса / Степан Полохин (Yandex Infrastructure)",
  "views": 323,
  "duration": 2754,
  "published": "2024-10-29T02:57:15-07:00",
  "text": "приглашаем на сцену Степана палохил об Арк внутренней вес для занимается разработкой собственно системы контроля версии для Яндекса для моно репозитория Яндекса ближайший аналог ээ этого продукта наверное гид э который наверняка всем вам известен Сегодня я действительно расскажу о том как мы его делали что из этого Получилось С какими подводными камнями мы сталкивались и к чему В итоге пришли а курс у нас примерно такой сначала попробую попугать вас циферка наших масштабов затем слегка окунул ну после этого окунёво сначала расскажу о том что из себя представляет Arc vcs затем немного о том что такое виртуальная файловая система и почему мы её используем как мы работаем с историей Какие плюшки Мы за 5 лет существования арка успели создать Ну и в самом конце что нетипично расскажу собственно цель доклада Итак масштабы бедствия Я думаю ни для кого не сюрприз что в Яндексе мы используем моно репозиторий В смысле все проекты практически все проекты которые у нас существуют живут в одной большой манорен есть небольшой минус она большая Посмотрите на гистограмм если напротив красной полосочки названи вашей компании значит репозиторий очень большой примерно 12 ТБ э Если обратить внимание на шкалу можно заметить что она логарифмическая Это значит что репозиторий Яндекса примерно в 100 раз меньше чем репозиторий Гугла Ой простите в 10 раз меньше чем репозиторий Гугла но тем не менее примерно в 1.000 раз больше чем репозиторий хромиум Ну ещё немножко цифро ежедневно у нас в основную ветку разработки вливается примерно 8000 коммитов при этом в основной ветке разработки сейчас содержится 8 млн коммитов уже в последнем срезе В смысле в самом последнем коммите содержится около 11 млн файлов и все они суммарно занимают 200 Гб Для чего все эти цифры Ну большие большие побу и ладно вот на самом деле все эти фры нуж для того чтобы поняли репозиторий в гит просто так не положишь если честно я пытался В смысле у нас есть возможность конвертировать репозиторий в Гито вый репозиторий вот я сконвертируйте не менее статус или Т checkout который я бы там вызывал всё равно исполнялись безумно бы долго для того чтобы иметь дело с таким большим репозиторием нужна особая система контроля версий и вы тут мне скажете а зачем вообще что-то Выдумать можно просто не жить в моно репозитории предвид такие вопросы сразу посылаю вас смотреть замечательный доклад Насти атой выступала она с ним этим летом на лоде получилось очень круто Очень дискуссионное точил на том что моно репозиторий это реальность с которой нам приходится иметь дело только так и никак по-другому так можно приступить к историческому экскурс как мы дошли до жизни такой началось в тринадцатом году когда кто-то сверху сказал так репозитории всех компаний репозитории всей компании получается соединяйтесь Ну мы соединились получилось мореп и тут же сразу пришлось выбирать какую систему контроля версии использовать Ну тогда даже мысли не было о том чтобы писать что-то своё вместо этого мы взяли СН Почему именно расскажу немножко позже пока пройдёмся по ключевым датам следу жна точка Это шестнадцатый год Здесь мы решили попробовать курил забавный факт Facebook в этом же году рассказал о том что они для своего репозитории использует курил и тут мы решили его попробовать совпадение Ну честно не знаю но Вполне возможно что ими мы и вдохновились вот а теперь восемнадцатый год здесь рождается ацс на самом деле рождается он скорее как P Project В смысле Ну вдруг взлет вот за года усердной разработки челок взлетел мы достигли цели 51% В смысле арком пользовалась компанией больше половины разработчиков на 1% больше И в этот же момент мы подумали так три системы контроля версии это как-то перебор надо от чего-то избавляться избавились от меркурио закопали его и вот двадцать третий год на дворе ацс у нас основная система контроля версий и Мы приняли решение закапывать СН Теперь у всех наверняка должен в голове возникнуть вопрос а удри сжа целых 10 лет ещё и вместе с арком начну с этого А почему вы вообще изначально выбрали СН у него есть Киллер фича селективный чекаут Ну в тринадцатом году это была Киллер фича С недавних пор по-моему в гите тоже Появилась возможность как-то фигурно лобзиком выпиливать кусочки репозитория которые вам действительно хочется скачать Вот Но тем не менее тогда это было круто тем и команда которая выкачивает на самом деле могла выглядеть весьма и весьма монстро Ну вот примерно как на экране Ну то есть ничем не хуже чем новогодняя конфетти на улице со временем мы это дело облагородили написали вернее не так подружились зависимости из графа сборки передавать в СН и скачивать Только нужное только то что действительно потребуется помимо этого насыпали е кучу синтаксического сахара научились издавать реквесты Ну и так далее тем не менее Несмотря на то что получилась конфетка в последнее время мы решили что пора с сном завязывать пора с него уходить и оставаться на одной только Арк вцс почему Ну во-первых потому что доля пользователей стала слишком маленькая в смысле арком сейчас пользуется больше 95% наших разработчиков Ну и А зачем тогда держать две системы контроля версий если можно держать одну второе СН сложно масштабировать как горизонтально так и вертикально чтобы вы понимали чтобы см функционировал все его объекты должны лежать ровно на одном Хосте Ну то есть понятно что можно разного рода извращениями доводить с до нужного вам состояния патчи его сколько угодно вплоть до бесконечности и учить хранить объекты не на одном хасте А там в какой-нибудь любой вашей базе данных которые вы захотите Вот Но всё это время всё это требует времени на разработку и нам проще закопать СН чем пытаться как-то учить его масштабироваться нормально у с есть определённые проблемы с безопасностью Но это весьма скользкий пункт В смысле с аутентификацией авторизацией там конечно же всё в порядке просто ну интересный факт если внезапно ваш репозиторий сновский уедет в Open Source Вы скорее всего узнаете об этом постфактум Ну и последнее немаловажное Арк вцс завязано на работоспособность свм Ну Дело в том что репозиторий один а система контроля версии две а знат нужно как-то всё синхронизировать вот мы синхронизируйте Представьте себе что в арке вы создаёте какую-то ветку Ну в принципе допускаем что арка модель арка такая же как и модель Гита тоже комит тоже ветки Итак мы создаём какую-то свою ветку колбасим там свои баги в определённый проект и решаем о Сейчас пора вливать вы думаете Сейчас льётся в мастера Но на самом деле Нет сначала ваш комит из него сформируется патч который приедет в СН в сне из этого подчас сформируется комит потом этот комит обратно с конвертируется в Арк и только после этого он попадёт в основную ветку в арки Ну с этим приходится жить что тут могу сказать и большая проблема здесь состоит в том что если отказывает СН то Арк тоже лежит в смысле у нас 8.000 коммитов в основную ветку в день происходит значит если СН прилёг то уже не 8.000 уже гораздо меньше от свна в этом Круге ада хочется хочется избавиться ближайшее время попробуем это сделать так ну и пара слов о меркурие раз я уж его упомянул он с самого начала не снискал очень большой популярность им с самого начала пользовалось достаточно мало людей нам приходилось переписывать куски самого хг хг - Это если что клиент системы контро версии meral для того чтобы он мог нормально работать вот ну и у него такие же проблемы с масштаби масштабируемость как горизонтально так и вертикально так Ну и вот мы дошли до нашего мальчика Арк vcs красавчик воплоти модель модель у него очень простая такая же как те ну в смысле такая же простая как те и такая же сложная как те у нас есть коммиты которые соединяются в ациклический направленный Граф каждый комит в свою очередь представлен в виде какого-то дерева Ну аналог директории каждое каждое Дерево у нас представлено перечислением опять же либо деревьев либо Лобов блобы - это такие аналоги файлов единственное важное исключение важная особенность от Гита - это то что у нас есть рев какие-то очень большие файлы Ну больше 4 мб насколько я помню мы разделяем на маленькие кусочки и каждый кусочек представляем в виде бба таким образом большие файлы у нас представляются в виде односвязного списка интерфейс У нас тоже очень похож на гит Ну в целом Мы первые несколько лет задавали с целью догнать и повторить гит сделать так же как гите только лучше Вот уже в последнее время мы отошли немножко от этой идеи и стали делать так как хотим а не так как сделано где-то вот но тем не менее основной набор команд у нас совпадает Так ну и я тут распил о том что тяжело масштабировать тяжело масштабировать а этих проблем тоже шн Мы живём в Облаке у нас множество любую Погаси любую подними ничего особо не сломается какой-то мастер отсутствует Единственное что есть на хостах - это дисковый кэш который возможно будет жалко потерять все данные у нас хранятся в wb и тут целых два плю на запись А во-вторых то что мы храним это wdp позволяет нам горизонтально масштабироваться хоть до посинения так Ну теперь к самому интересному виртуальная файловая система в сне как я уже сказал мы решали проблему большого репозитория огромного количества файлов при помощи селективного чекаут будем скачивать с какими будем работать и скачивали только их в арки мы пошли По другому пути Мы решили То есть у нас нету команды git Clone Ну вернее Arc Clone вместо этого у нас команда Arc Mount которая на месте создаёт точку монтирования в которой располагается репозиторий на старте такой репозиторий суммарно весит не более 1 Мб Что происходит на деле когда человек вызывает Arc Mount в первую очередь порождается сущность Arc Demon А это фоновый процесс который будет отображать все ваши объекты на файловую систему вторая сущность - это Store там буквально хранятся все наши кишки Ну вот все объекты которые вы создали все объекты которые вы скачали все ваши ветки индексы Ну и так далее В общем всё то что необходимо для того чтобы репозиторий функционировал ну и последняя третья сущность - это собственно точка монтирования то место где мы отображая файловую систему то место где работает разработчик и читает код или пишет код вот для человека всё выглядит достаточно понятно В смысле каких-то существенных отличий от обычной нативной файловой системы он по идее не видит когда он открывает какую-либо директорию у нас создаётся файловый Запрос который летит в Демон в демоне мы пытаемся найти соответствующий объект смотрим и в кэша и в нашей самописный базе данных на диске и на сервере Ну и в конечном итоге находим и просто отображая если Вы самый обычный типичный энд разработчик просто открываете файлики просто их читаете просто что-то пишите вы вообще не почувствуете просадок н Вот Но существуют нюансы там например если вы попытаетесь НОД моли распаковать в репозитории то просадки нси вы ощутите с лихвой Почему так а о Почему так я скажу на следующем слайде тут пока немножко о том какие у нас в принципе есть способы взаимодействия с демоном первое Я уже сказал это файловые операции Вы можете прочитать записать открыть Ну и так далее В общем там список из сот файловых операций на юниксе все они пролетают через use Fuse - это модуль ядра который позволяет виртуалити дела своеобразный протокол для виртуальных файловых систем второй способ взаимодействия с демоном - это клиентские команды Например Arc checkout или статус в отличие от файловых операций они соединяются с демоном напрямую минуя какой-либо фьюз по гпц протоколу так вот а теперь о том почему всё работает медленно Ну вернее медленнее чем могло бы а для того чтобы файловая операция достиг Демона ей необходимо совершить очень нетривиальный путь сначала пользователь пытается открыть какой-то файл в этот мот Мы попадаем в расширение яд vfs там мы как-то прокси этот запрос преобразуем его в Понятно виду и отправляем рай модуль ядра после того как он прилетел рай он опять проходит своеобразную подготовку и посылается у в клиентское приложение в нашем случае arcon где его заботливо встречает библиотека lip Fuse своеобразная реализация интерфейса взаимодействия с драйвером фьюза Вот если бы мы работали поверх обычной нативной файловой системы здесь Было бы всего две стрелочки от юзера к FS и обратно вот в нашем же случае таких целых шесть штук и за счёт этого н любых файловых операций у нас существенно проседает в сравнении с нативной файловой системой и сделать мы пока с этим ничего не можем отдельно стоит упомянуть что в определённый момент мы избавились от фьюза и написали свою реализацию библиотеки фьюз Почему так случилось немного посмотрим на ту магию которая происходит в демоне когда вы с ней работаете А положим вы открываете какой-либо файл ну здесь он проходит через вот этот вот гамбургер фьюза и прилетает в демон арка на вход подаётся номер родительской аноды для тех кто прогуливал операционные системы среды и оболочки Ну или похожие курсы напоминаю ада - это такая структура на в линуксе которая хранит в себе и содержимое файла и метаданные Ну например Время модификации файла или биты доступа Вот и характеризуется номером так вот на вход демону попадает родительская анода вместе с этим заботливо преобразует её в путь для того чтобы клиентскому приложению было Ну удобнее работать а далее мы делаем простую вещь Мы у себя в демоне пытаемся те файлики которые человек прочитал те файлики которые он успел поре дактилит в древовидной структуре Ну мы по сути дела пытаемся в памяти Демона сохранять древовидную структуру тех файлив которые человек успел редактировать вот после того как ээ мы материализовать эту вершинку соответствующую этому файлу мы ко всему прочему возвращаем обратно по всему стеку файловый хендлер Ну или по сути дела информацию о том какой Файлик только что был открыт Какое у него содержимое какая у него Мета информация и так далее И вот здесь случаются различные приколы то есть по сути дела Сейчас у нас есть в демоне какое-то представление о том что лежит на файловой системе у нас на файловой системе есть какое-то представление о том что на ней лежит есть ещё и где-то в промежуточном состоянии в Юзе информация о том что лежит на файловой системе просто потому что ФЗ когда ему отдают всё содержимое прикапывать его где-то у себя в стод ine Итого у нас есть три различных содержимых которые в любой момент могут разъезжаться весьма экзотическим способом Ну например я могу сказать Сделай мне чекаут господин демон он пойдёт И переключит вам состояние файловой системы с одного комита на другой там буквально может быть другая файлова ру буквально может быть другое файловое содержимое вот в этот момент у нас поменяло содержимое файла номер оди тем не менее состояние которое у нас есть взе вообще никак не поменялось у нас просто нет механизма для того чтобы оповестить его о том что случились изменения поэтому Теперь когда человек попытается открыть файл после четан зат в скажет я знаю это ть вот на держи он Достанет из кэша старое содержимое вместе с тем ничего не сделав для нового случился разъезд то есть человек ожидал что после чка вот ему он откроет Файлик там будут какие-то новые данные а в итоге оказалось что ему что-то из кэша достаётся и он ничего с этим сделать не может Поэтому в один момент Ну то есть мы пытались решать эти проблемы безумное количество костылей было написано для того чтобы хоть как-то справиться с этим в конечном итоге у нас сгорело в общем мы сгорели и написали свою реализацию фьюза в этот раз мы не стали полагаться на то что ф Может у себя хранить А что ьз может у себя хранить аноды вместо этого мы сами стали хранить анод у себя в смысле мы буквально поддерживаем актуальное состояние файловой системы целиком полностью поддерживая состояние древовидной структуры Какие проблемы мы вместе с этим решили во-первых поскольку теперь аноды хранятся у наш У нас шд тоже хранится у нас Мы в любой момент можем инвалиди этот кэш А во-вторых мы можем отмонтировать репозиторий снова примонтировать репозиторий аноды нуно Они же у нас хранятся мы можем загрузить их Поэтому те изменения которые человек успел сделать и не закоммитить перед тем как отмонтировать никуда не пропадут ещё одна важная штука про которую я хотел бы рассказать ну Просто она мне лично очень нравится это тупое элегантное решение Я такие люблю положим простой сценарий Вот вы пришли на работу открыли вашу любимую иде пошли заваривать кофе а в это время иде такой о пойду-ка проиндексируют Ну так бывает но оно просто начнёт обходить буквально всю файловую систему и пытаться как-то связать ваши кодовые файлики естественно в этот момент в демоне материализуется вообще вся древовидная структура можно буквально весь репозиторий туда загрузить а дальше дальше случается интересное человек возвращается из кофе и думает о какая-то У меня старая ветка переключись Я на другую он делает А в этот момент ну понимаете да а ему нужно сменить одну файловую структуру на другую одно содержимое на другое содержимое причём во всех файлика если делать Это самым честным образом придётся обходить всю древовидную крутою успевать вж кореши появился ли здесь новый хш случились ли здесь какие-то изменения после чека или нет Если случились то ещё необходимо дополнительно скачать с сервера объект соответствующий Ну и так далее В общем чекаут может происходить там если не десятки минут если не часы то минуты это тоже очень долго а и что мы придумали ленивый чекаут всё очень просто вместо того чтобы проверять каждый обект в отдельно вместо того чтобы скачивать лишние объекты во время чека мы просто размечаем все вершинки особым флажком и всё больше ничего мы буквально обошли древовидную структуру и везде пометили флоком Всё теперь когда человек попытается открыть какой-то конкретный файл Вот именно в этот момент Мы попытаемся скачать актуальное содержимое таким образом фактически чекаут буквально размазывается на весь пользователя самка случается за секунду затем ра на операции человека которыми можно пренебречь Ну ладно это всё вфс а есть ещё вторая проблема это Граф коммитов Ну Сами понимаете У нас очень большая история 8 млн коммитов транки 195 млн всего теперь Представьте что во всём этом безобразие необходимо найти ровно те коммиты в которых конкретный Файлик поменялся как бы это делал Ну во-первых загрузил бы все коты в память Ну не разом конечно а последова вот ну за счёт того что он их загрузил они естественно Бут логически отсортированы А после этого необходимо буквально в каждом коммите найти ди В смысле узнать какие файлики там менялись Какие удалялись и так далее после этого необходимо выбрать те коммиты в которых менялся конкретный интересный вам Файлик Ну Сами понимаете алгоритмическая сложность здесь примерно О Боже мой что с этим можно делать когда у вас 195 митов вы не можете посчитать такое быстро Ну вообще никак какие есть идеи во-первых для того чтобы отображать историю нам не нужны коммиты В смысле каждый комит сам по себе - это отдельный объект чтобы узнать какие у этого комита родители Нам необходимо сначала загрузить комит после этого загрузить родителей чтобы узнать их родителей нам ещё необходимо загрузить и эти коммиты ну и так далее В общем на этом последовательном скачивании можно потратить очень много времени хотя на самом деле от все этого нам требуется только лишь топология вот мы придумали А что если брать и хранить топологию отдельно В смысле берём какой-то хэш комит и говорим у него вот такие родители у этих вот такие родители у этих вот такие родители и всю вот эту агрегированных в единую структуру получается существенно меньше чем если бы мы скачивали все объекты разом вторая важная идея - это то что история файла не меняется временем В смысле Ну буквально комит это своеобразная блокче технология А значит мы Ну ладно понятно что история Может немного нарастать Вот но ти та история которая уже закамини емае Что можно написать Хоть какой-то индекс по этой истории например для какого-то комита и конкретного пути можно завести информацию о том где этот путь менялся в предыдущий раз Ну и последнее самое важное на сервере уже есть все данные скорее всего они даже есть уже в кэше поэтому можно унести вычисления лого все на сервер собственно Так мы и сделали когда человек запускает клок он на самом деле запускает запрос на сервер и уже на сервере происходят все нужные вычисления периодически на нашем сервере подсасывает сериализовать сервере есть индекс нашей истории Так ну вот мы и дошли до практически самого последнего раздела это плюшки а существует уже 5 лет У нас есть очень много коллег которые сидят за нашими соседними столами они приходят к нам на кофе поинты и говорят хочу вот такую штуку Ну сделай ну сделай Ну вот мы и делаем первая наверно самая прикольная фича - это любит писать код там где красиво а собирать код там где где хорошо многие люди для того чтобы так делать используют команду rsn В смысле команда которая синхронизирует состояние файловой системы в одном месте и файловая система в другом месте мы не можем себе позволить запускать rsn в арке просто потому что там виртуальная файловая система если её постоянно обходить а именно обходит файловую систему получится нехорошо поэтому мы написали свой сво синхронизации человек пишет на мастер хасте одну команду arcing на другом хасте пишет arcing Follow и всё в этот момент весь код который Вы пишите в одном месте сразу же прилетает во второе место из важного поскольку эта команда системы контроля версии она учитывает особенности системы контроля версии Если вы на Хосте переключились на какую-то ветку то и на флоре Вы тоже переключитесь на эту ветку Если вы что-то добавили в индекс то и там это добавится в индекс вторая важная фича - это шарды и здесь я не могу не упомянуть ограничения которые есть в арке просто для того чтобы объять мотивацию создания шардов во-первых у нас чувствуются просадки перформанса файловых операций но я уже говорил там вот этот вот гамбургер фьюза второе в большинстве случаев мы не можем работать оффлайн Ну стоит только вспомнить графовые операции они практически все выполняются на сервере у нас нет команды Хотя очень многие привыкли к тому чтобы вести merge Flow а не rebase Flow у нас а мы можем работать только если работает и доступен фьюз без него не получится ну и наконец мы не дружим с xcode самый неочевидный на самом деле вариант но внезапно оказалось что очень многие хотели бы чтобы он дружил Ну не дружит если что потому что xcode Ну тупо не позволяет писать для него нормальные плагины он как медоед ему пофиг В смысле если он его запустить поверх виртуальной файловой системы но он будет работать с ней как с обычной файловой системой и любые подсказки будет игнорировать и тут Мы подумали Давайте научим АК работать поверх нативной файловой системы он на самом деле и так умеет но просто сделать это при помощи Гита гораздо проще идея следующая в арке у нас куча различных проектов Ну просто безумное количество в то же время мы можем любой из этих проектов превратить в маленький гит репозиторий то есть буквально человек приходит нам говорит Я хочу чтобы вы конкретный проект превратили в маленький репозиторий мы иму говорим Окей Сейчас будет мы конвертируем всю историю этого проекта буквально вычленять в отдельный гит репозиторий начиная с этого момента Вы можете работать над проектом одновременно в двух система контроля версии Ну трёх там СН всё-таки ещё есть а если вы пуши свои изменения в git они конвертируются и попадают в аркадию Ну в ак с другой стороны если вы путе свои изменения в этот проект они попадают в git таким образом формируется двусторонняя синхронизация из самого приятного и Возможно немного не очевидного факта мы можем Ну то есть рду на самом деле плевать что именно вы в него положите Самое главное чтобы это был репозиторий а это значит что можно взять любой осный проект на гитхабе положить его в и сказать Теперь это тоже всё с этого момента Open репозиторий синхронизироваться в аркадию В смысле в наш репозиторий А ну и да работает и в обратную сторону Если что то есть можно взять любой подрейко до развали Ну 5 лет Это конечно не очень долго но тем не менее какой-то срок и за ВС это время мы постоянно взаимодействовали и с нашими пользователями Ну взаимодействовали с пользователями и в саппорте и на кофе поинтах и вообще везде и в конечном итоге у нас появилась идея А что если сформировать свой собственный Фло работы ну то есть на самом деле большинству людей которые работают с системой контроля версии не нужно знание о том что есть какие-то ветки есть какието всё это очень сложно это реально переусердствовать в ваш по request Ну Напишите ещё вопервых кни пожалуйста поскольку это центри Фло нам необходима возможность выбирать среди Кстов которые у вас существуют для этого у нас есть команда Вот вместо того чтобы там смотреть список ваших веток которые вы успели на создавать переключаться на них ещё и путь по необходимости потому что они возможно отстают от сервера можно просто сделать сразу переключится на актуальное состояние вашего послед пока что команда которая у нас есть это Ну понятное дело все изменения которые вы совершаете в вашем репозитории могут отставать от мастер ветки В общем случае у нас принято рейзи В смысле сделал после этого сделал arb И пожалуйста у вас актуальное состояние ветки но сами знаете там могут возникать различные приколы в смысле различные конфликты которые необходи решать зная опции минус мину армину минус Минус что-то Там ещ возможно вам пригодятся стратегии ржа аус вот это вот всё эти знания вообще не нужны вам в смысле зачем об этом думать можно просто написать аркап после того как вы её пишите Арк буквально подтягивает самое актуальное состояние вашей астрим ветки Даше просто е раз Пите и все конфликты решаются мы намерены каким-то образом развивать этот упрощённый Фло Вот Но как именно пока думаем собираем метрики и всё такое так Ну а теперь собственно цель доклада А зачем вообще вы это прослушали Сегодня мы думаем о том чтобы выйти Open Source я тут особенно подчеркну Ну не планирую В смысле нету на конт что вот в эту точку мы выходим Мы просто думаем об этом и в том числе мы думаем о том что хотим поднять первый публичный Арк репозитории чтобы люди могли прийти потрогать посмотреть оценить вообще это то не то нормально Нет в том числе поэтому мы хотим узнать кому и в каком виде это в целом могло бы быть интересно ну то есть различные запросы которые могут возникать у пользователе мы сами можем придумать вот вопрос только в том что мы придумаем будет матчи с реальностью Поэтому если вас в каком-то виде заинтересовал Арк Если вы хотели бы его попробовать или потрогать обязательно Напишите и расскажите Возможно это очень сильно повлияет на то в каком виде Open Source у нас случится так Ну а на этом У меня всё большое спасибо за внимание Степан Большое спасибо вопрос пожалуйста ой Спасибо за доклад Скажите пожалуйста есть ли какие-то особенности работы с большими файлами Или допустим с датасета Ну потому что не только код не только как бы исходники хранятся в репозитория но и много чего ещё А здесь Наверное намёк на фс в гите Да фса в арки Нет ну в смысле смотрите влом ничего не мешает положить больш фа ф разобьётся на много маленьких кусочков в конечном итоге это отправится на в наш сервер и будет там лежать поскольку у нас ленивая файловая система В смысле виртуальная файловая система этот файл будет загружаться только в тот момент когда вы будете реально ну его открывать до него дотрагиваться и так далее поэтому какой-то острый потребности в том чтобы иметь как те у нас нет у нас буквально всё из коробки работает вот но тем не менее сейчас мы Мы в Аркадии запрещаем людям коммитить файлики больше 1 ГБ потому что ну не продумывать эти сценарии наверняка и хорошо то есть на самом деле нам бы хотелось какие-то очень большие файлы хранить не в idb например А в S3 Вот Но тем не менее даже сейчас возможность большие файлы писать в репозитории существуют Да Степан Спасибо за доклад А вот а да Вопрос вот э Вы сказали то что загружается файл когда мы делаем checkout Lazy то есть во время того как мы его открываем Может ли возникнуть такого то что если например у меня сейчас медленный интернет допустим то что я открыл файл увидел одно а потом оно подгрузило и файл поменялся нет такого конечно же не будет Вот после того как у вершинки в внутреннем представлении поставился флажок лези а в случае когда ты открываешь этот Файлик Ну ты не откроешь его ровно до тех пор пока его новое содержимое не скачается а а что я тогда Увижу когда открываю фал у себ усв Ну если он до этого когда-то уже открывался В смысле ада для него существует то Ну ты увидишь старое содержимое которое действительно резко обновиться в тот момент когда скачается новое содержимое Вот Но с этим Наверное мы ничего сделать не можем хорошо спасибо Привет я из Касперского и мы как любая уважающая компания тоже делаем свою систему контро версий куда смотреть и занимаюсь но что я видел Мы тоже начали пользоваться фьюзом а потом выяснили что вообще-то он много где разваливается в частности по-моему под маками Плохо работал были ещё проблемы Я знаю что у нас это решилось тем что мы по крайней мере пытаемся переехать на NFS для виртуально файловой системы А вы пошли другим путём вы сделали Костыль Ну не Костыль свой ФЗ Да почему не NFS Почему свой ьз не смогу пожалуй ответить на этот вопрос Ну в момент когда мы писали новую библиотеку для фьюза просто показалось что ну сейчас чтобы вы понимали единствен система контроля версии в мире которая работает с моно репозиторием есть примеры счастливчиков это Например Facebook у них есть FS и в используется в своё время мы вдохновлялись именно ими В смысле мы увидели что о у этих ребят получилось и работает хорошо почему бы у нас не попробовать также Вот поэтому в своё время мы выбрали нес Спасибо Здра Спасибо за в это сейчас используется всё-таки NFS как основная система Да из-за рисков связанных с Ну вот меня коллега как раз спалил потому что я как раз тот самый человек который сделал реализацию НФС внутри Касперского и у меня на самом деле к вам сотни вопросов Я надеюсь что у меня будет возможность после этой встречи их задать вот а у меня на самом деле тоже связаны сль ными системами вопрос А как вы работаете вот вы планируете выходить в Open Source как вы работаете с рисками СТ отказа со стороны прота операционных систем от какой-то возможности виртуализации что может закрыться на Маке нанде вообще не поддерживается сейчас хорошо Завтра может быть закрыт Я пою что Виндой там в Яндексе вы особо не пользуетесь но например очень актуально то есть Какие у вас планы вообще NFS NFS используется только на Маке на линуксе там всё ещё используется Fuse самый обычный Вот Но тем не менее по поводу операционных систем которые скоро не будут позволять себе нормально виртуалити NFS и это один из вариантов второй из вариантов недавно появился F который насколько я помню полностью держится в userspace он на базе NFS Я просто прокомментировал это просто фьюз реализация на базе NFS а Ну тем более я глубоко не смотрел но самое приятное ью то что там интерфейс взаимодействия примерно такой же останется и можно будет легко перейти вот по поводу винды Ну тут сложно В смысле мне неизвестно какие-то хорошие аналоги про фса я вот знаю например что в майкрософте есть Т4 vfs и там всё ещё написано всё при помощи проф кажется они за 3 года в восемнадцатом году они о за 5 лет получается у них ничего не поменялось вот известно что на винде можно писать свои мини фильтры И это тоже один из возможных вариантов подхода Вот но глубоко в эту сторону мы не смотрели просто потому что Виндой реально мало кто пользуется А где задать вопросы после вот выступления вот тут всё спасибо спасибо за доклад вопросик В Яндексе 10тб репозиторий в Гугле 100 Google пользовался г курим 201 а сейчас что у них а сейчас немного поправлю хг пользовался не Google хг пользовался Facebook какой размер репозитория Фейсбука я на самом деле не знаю А в Гугле сейчас Пайпер У них своя система контроля версии Ну и там тоже своеобразные приколы например у них практически полностью отсутствует локальное состояние Ну в смысле Piper он вообще ни в коей мере не повторяет git он скорее похож на СН То есть это какая-то пач работа ты совершаешь какие-то изменения у себя локальные эти почи отправляются на сервер там применяются из них формируется по реквест Ещё ещё небольшой вопросик вот ишка провела индексацию индексирование потом мы чекаут сделали Всё пометила Lazy и сейчас Получается что в IDE индексация не этот не актуальна он пока мы не этот он будет ли какую-то новую индексацию запускать Ну да конечно и ничто не остановит В смысле Ну переключился я переключился Ну и что Пойду заново всё проиндексируют Ну естественно Мы со своей стороны написали плагины для различных иде так чтобы сузить скоп и э проектов и папок которые действительно необходимо будет проиндексировать иде В смысле Мы научились указывать что именно нужно индексировать вот но без наших плагинов это просто так с коробки не работает Спасибо Да спасибо за доклад А у меня вот такой вопрос а вот получается есть серная часть от который сильно зависит А что как чинить Арк если он лежит а свм ну в смысле сейчас буквально единственный способ починить Арк в случае если Арк загнется и сломается - это СН в том числе Когда мы будем от него отказываться мы там думаем о том чтобы поднимать secondary Arc мы сохранить какой-то это отдельный инстанс Арко в который будет периодически реплицировать код вот так чтобы была возможность в случае отказа основной основного арка сделать какие-то пачи А так да СН за счёт вот этих зеркал и или Гита Да тоже работа Ну нет с гит шардам всё немножко сложнее В смысле они не гарантируют что у тебя весь репозиторий конвертируется в эти гит шарды вот а СН гарантирует в смысл у него отдельный репозиторий которые полное зеркало нашего основного репозитория Ну почти полное зеркало там всё-таки только транк есть никаких веток ещё вопросы Спасибо за доклад а такой вопрос А что делают плагины кде они как-то собой Тиф подменяют или они как vfs реализует и говорят какие файлы изменились а нет с плагинами всё гораздо проще ты говоришь плагину Какой проект ты будешь собираешься использовать а в этот момент про плагин вместе со сборкой решает Какие зависимости есть у этого проекта генерируют соответствующие конфиги для IDE которые говорят что именно нужно индексировать вот и всё никакой магии да Спасибо за доклад У меня вопрос вот э было про виртуальную файловую систему показано про Magic и у меня есть вопрос вот есть два разных сценария один сценарий что мы открыли а предположим какой-нибудь очень большой проект в иде оно начало индексировать и у нас вот эта виртуальная файловая система начинает загружать выгружать файлы Ну там когда потрогала загружает выгружает и это понятный правильный сценарий в случае сде но есть другой сценарий что мы где-нибудь на конвейере собираем огромный проект и нам нужно ВС что мы Потро оставить у себя как вот вот этот вот момент реализован Ну тут всё очень просто если ты собираешь проект например тот же самый CH у тебя создаются новые файлы которых репозитории ещё по идее нету ну или даже если они есть когда Ты совершаешь чекаут он совершается не так что ты полностью перезаезд есть в репозитории с теми на которые ты переключаешься если никаких конфликтов не возникает не в Ну это если что поведение как ГТ А если никаких конфликтов не возникает Ты просто переключаешься просто в этот момент э если мы конкретную вершину решили не переключать на новое содержимое то и анода у неё никак не поменяется То есть все те артефакты сборки о которых ты говоришь с ними ничего не случится после чекаут вот я не про артефакты сборки Я про сами исходники вот у нас очень большое количество исходников и Если я правильно понял то если Мы открываем это прок она их проиндексированы эти 200 Гб исходников Даже если мы открыли папку которая содержит 200 ги А на конве нам нужно чтобы они загрузились А я тебя понял ну сейчас во-первых если ты на конвейере будешь запускать Ну если ты не очень понимаю на самом деле как работает весь этот я буду говорить если Ты запускаешь сборку которая учитывает эти файлы вот если Ты запускаешь сборку тона сама прочитает фа В смысле не проиндексирован во время сборки прочитать и скачать эти файлы более того у нас если что Ну тоже браузер недавно заезжал и у них тоже есть необходимость собирать Хиро хроми вот буквально такая же задача перед ними стоит вот ну у нас в арке есть команда Arch которой ты можешь передать какой-то список путей и она заранее скачает все необходимые объекты вот браузер сечас делает примерно так обк которые необходимы там для сборки этого ромиу А после этого запускает сборку материализация Когда у нас все объекты уже скачаны происходят достаточно быстро спасибо Так ну что Большое спасибо за доклад и теперь просьба выбрать два самых интересных вопроса два самых интересных вопросов Ну меня определ точно самое сердечко с остальным э это на пожалуй самый лучший вопрос вот а второй э Да пожалуй про браузер про Chum вернее вот этому человеку Так ну что Большое спасибо вам большое спасибо за внимание да"
}