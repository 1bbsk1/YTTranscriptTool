{
  "video_id": "sd1E3DKRbzE",
  "channel": "HighLoadChannel",
  "title": "Apache Ignite Persistence / Артем Шитов (GridGain)",
  "views": 2917,
  "duration": 3517,
  "published": "2018-08-16T04:42:28-07:00",
  "text": "меня зовут артем я представляю сегодня компания этот день solution architect и хочу поговорить с вами обо патч игнайт позвольте 100 значит soft as a кто из вас слышу хоть что-то в apache и игнайт замечательно кто из вас имел опыт забота собачий игнайт я бы какой-то великолепно если у меня просили сказать что такое патч игнайт еще не знаю где то год назад я бы сказал что это платформа для распределенного хранения данных в оперативной памяти и вычислений поехать данных режиме реального времени сейчас это уже не совсем так чему и посвящена сегодняшняя тема не совсем так это в первую очередь в том плане что игнайт теперь может работать не только в памяти он может собой забота теперь еще и поездка диска тоже прошу тебя память или там дубы и давайте поговорим об этом с началом поговорим о том зачем это нужно зачем к этому пришли и вообще чем все это потом собственно что же изменилось и наконец как это работает внутри давайте начнем с того зачем я думаю многие из вас слышали сталкивались лично с тем что данные доступны будут вас тут стремительно у нас все больше и больше источников сейчас если вы посещаете какой то даже не знаю обычный сайт его записывают буквально каждое ваше движение повсюду стоят датчики кто ходу идет постоянный поток данных в логистике везде-везде-везде данных становится все больше и больше это что еще совсем недавно казалось достаточно большим внушительным объемом сейчас уже достаточно смешно сейчас внушительный объем выглядят вот так кто-то знает что это такое это да это amazon овский снова mobil amazon предлагает перемещать большие объемы данных быстро за счет того что они пригоняют замечательно большую фу так вашему саду отличают и по оптике вы загружать туда данные они по обычные замечательные дороге питьевой сто пятьсот подсовывается там по оптике выгружает их туда вот сейчас вот это вот большие объемы а еще через десять лет они будут представлены еще совсем начнешь остались этом кита катаете возят не нефть как-то топите возят ваши замечательные байтики и данные на самом деле хотелось бы не только хранить их хотелось бы еще обрабатывать и мы долго шли к современному состоянию изначально все помним одноядерные процессоры и вечно гоку гонку гигагерц кто-то казалось никогда не закончится мы помним многоядерные со теста когда мы поняли что 1 это недостаточно хочется масштабироваться мы сделали их несколько потом оказалось что здесь тоже есть потолок и ушли к потому что называется сейчас горизонтальное масштабирование по их close to the то есть когда у нас есть не только какой-то один или несколько многодетных процессов в одной машине но у нас большое количество машин ну дальше это будет развиваться и развиваться я думаю это фрактал также у нас большое количество close to have так далее тому подобное зачем это нужно принципе понятно я думаю каждый из вас своем бизнесе сталкивается с тем что данные нужно обрабатывать быстро если вы из я комикс компании например то то как быстро вы отображаете страницы вашего сайта насколько оперативно и надежно вы получаете заказ от ваших клиентов это ключевая часть вашего зонки если вы из банков как бы стал колоть и транзакции можете ли вы делать в онлайне в обнаружении мошеннических действий это важная часть вашего бизнеса даже если вы казалось бы из какой-то традиционные отрасли такой как нефтегазовые дашь там у вас есть бутильная установка на них большое количество датчиков если бы сильно установка ломается возможно по гарантии скорее всего windows заменят но пока она будь их не музеев ехать назад это простой этого хочется избежать как этого избежать нужно будет сказывать того что у нас нужно сказать то что она может сломаться как это делать поток данных датчиков машинное обучение поверх этого не должно происходить достаточно быстро чтобы и достаточно надежно чтобы могли экономически эффективно направлять соответствующие запасной части туда где они нужны поэтому данные важно не только хранить их важно отрабатывать быстро ключевой части разработки данных является хранилище откуда мы собственно их достаем и куда мы их кладем давайте посмотрим как у нас вот покашлять замечательные эти угощения наших вычислительных мощностей это завалить хранилище изначально у нас были классические телефонные базы данных но что мы их любили любим будем продолжать любить за то что у них уже не первый десяток лет из такие великолепные вещи как стога консистентных данных эти это все точность чем воспитывает сосед первую очередь с телефонными базы данных базами данных и обратно и и наконец сиквел можно долго говорить о том что кому-то нравится секунд кто-то считает что возможно лучше вместо секула было бы что то другое но ключевая часть здесь то что сиквел узнают все почти все то что он уже не один десяток лет впитывается с молоком матери молодым так за местами и в принципе его основная заслуга то что это стандарт от стандарт современного sli новый у классических реляционных б.д. такими они были есть и никто и существенные минусы но в частности они в первую очередь масштабируется вертикально конечно мы знаем то что нить этого так ли есть так но сколько максимальная столице так и вы видели несколько штук может десяток машин в одном саке первую очередь этого вертикальное масштабирование а как мы видели до этого вертикального масштабирования свой сидел и от рано или поздно мы начинаем приходить к тому что тебя нам хочется поставить что-то еще этот кредит на туска потом ещё ещё ещё больше больше больше 2 ограничения которые пили тут уже камаза на скоростном мобилю то что в основу телефоны bb5 тут по классической клэнси атласной модели у нас есть данные моих достаем в какое-то клиентское приложение там выполняемых работ q результат куда-то записываем оставляем делаем с ним что-то еще как замечательно работает пока в нашей выборки данных немного но когда мы хотим сделать что-то поверх массивного объема данных это перегонка данных из одной системы в другую может занимать огромное количество времени можно конечно пойти в сторону хранимых процедур на венда специфичных языках и погрузиться в какой-нибудь персик hell попытки поддерживать там тысячи этих процедур так чтобы они корректно отработали это завались бы не конфликтовать друг с другом ну и поверх них многие вещи сделать просто сложно за счет специфики языка в местном машинное обучение он opel сиквеле не будете делать в итоге там машины обучение построения и зонных сетей выливается в то что вы данные перегонять какую-то внешнюю систему долго мучительно где они водятся обучаются после чего на выходе получаете модель как ответ на эти проблемы в середине в такой половине нулевых стали активно развиваться но усику системы те но обозначает не нет not only секу они предложили горизонтальное масштабирование кто из вас работал с ходу помыли к сантой тщательно думаю даже те кто не сработали слышали о том что инсталляции ходу поэты могут быть оставляем сотни тысяч и узлов инсталляции к санкции аналогично netflix обожает к солнцева ней делали много замечательных тестов поводу и линейной масштабируемости до очень больших объемов с возможностью потому достичь на ужаться назад необходимости ответственно усекла предложил гид горизонтальную масштабируемость за счет того что он ослабил какие-то гарантии он предложил в принципе во многих кейсах более высокую производительность но это все естественно пришло не бесплатно поход дело мы во многих случаях под телефон консистенсии пакета ластик search с определенной санкции aside 1 из 2 и в большинстве случаев мы потеряли сиквел отчетом зачатки исключениями в чем видно что simple хочется потому что многие на сиквел базы тоже к санкам тебя они пытаются делать языки катод и приближается к сиквелу случае к санс это сиквел например но у них так или иначе есть свои ограничения сложность реализации определенную joy нам грубой фонд баев то есть видно что это хочется но у большинства решений здесь нет но зачастую здесь тоже студент сердца данная модель но уже все же потому что тот же hadoop например и где-то параллельно с развитием на усекла сталь 120 но мэтти да так деды которые решали в принципе в чем-то похожую задачу то что хочется масштабироваться и хочется быстрее но а тишале немного с другой стороны они посмотрели на то что память дешевеет посмотрели на то что в принципе что может быть самая быстро вот почему мы питаемся обычно там в cig вольных и на усика вольных базах данных часто это вот вывод как можно его убрать давайте использовать память давайте хранить данные в памяти получать данные из памяти это далеко не новая идея на самом деле даже распределённый нам это да так виды существовали там не первый десяток лет то станет будете за готти вы там крупных финансовых организаций кто-то работает с большими объемами денег и для кто ха ха высокая скорость это очень критично тамбов place to touch на nasdaq и и так далее но там как никто терпеть и на маке хотя бы каши централизованное то memcache я думаю из вас все слышали а memcache и кто не слышал о нем кашей поднимите толку ни одной атаки по сути моем штате дальнейшее развитие когда примитивный базовый memcache становится все более и более функциональным и включается постепенно в datagrid готова можно это триллионы вычислений а делать и в этом мы по возможности стараемся истоку консистентных занять 2 фазовый коммиты распределенные транзакции там в apache играет в кости подобных системах это куда большая классика секла к сожалению зачастую здесь тоже нет зато как характерная особенность фактически везде есть как раз таки возможности кого цитате данные и вычисления мы не перегоняем данные на клиентское приложение наоборот и в случае ходил к стае случай игнайта и случае других подобных систем мойка хитон мы наоборот можем оставить вычисление к домам что обычно значительно быстрее меньше по объемам с точки зрения софико и можно видеть что здесь в принципе проблем это казалось бы все хорошо ну сипло нет печально всем хочется сиквел все стремятся к седлу но часто его нет в остальном стали все неплохо я столько не обратить внимание собственно то что им эти даты где они in my mate они это с положены в оперативной памяти и соответственно если вы делаете предположим банковское ощущение это основным заняли чем являться не может но только если вы нить эти случаи кого-то деза 100 потерять все ваши замечательные транзакции то с чего вводить на себя гнев ваших пользователей с эгалитарных органов и так далее и тому подобное и как мы видим принципе называется все плюс-минус в одном направлении горизонтальная масштабируемость максимальная скорость и всем хочется сиквел в даже если мы посмотрим на классический селекционные б д в их современном приготовление они тоже пытаются стать горизонтально масштабируемые бездарно масштабируемые не thanked был доклад коллег из cytus как раз такие попытки сделать подвес сортируем масштабируемым дать им вот тут горизонтальную составляющую поэтому в принципе логично и понятно что хочется вот все вот эти вот моменты кто то есть утешение 1 класса другого класса попытаться собрать вместе смешать и получить принципе что-то более цельное в apache знает как раз таки это попытались сделать предложив две вещи повестка на над оксидов а еще несколько лет назад apache и гнать носил своими на целиком полностью классу и наносят это где-то впасть вот все о чем мы говорили сейчас была им присуща еще несколько лет назад apache и гнать начале работ над поддержкой сиквела и уже где-то 2 года с лишним даже почини night имеет полноценную поддержку ans и сиквел 99 на чтение и запись замечательна эта часть закрыли осталась часть in my mate это же случилось в этом году в его середине это как раз таки что кен memory добавился он диск чем и нам эти осталось основным хранилищем то есть не как у всех атак власти на море общем да и не только такла здесь немного обратный подход в первую очередь нам эти хранилища и диск как расширение памяти для обеспечения безопасности хранения как выглядела применение почитать до этого классика для подобных систем по сути кэш где-то посередине для быстрого доступа к данным наверху у нас есть приложение внизу у нас есть какой-то слой постоянного хранения кто-то обеспечивает сохранность и безопасность данных между ними находится и нам этот оксид в том числе об очевидной готов и подтягивает данные из нижележащего слоя либо полностью дублируют их если у вас есть достаточное количество оперативной памяти либо же несет только часть этих данных для того чтобы очень быстро обслуживать запросы на чтение казалось бы все замечательного подчеркнуть добавили сиквел почему бы не остаться на этой модели постоянное хранилище диска здесь уже есть зачем что-то еще в этой модели с несколько проблем 1 из них когда мы говорим то функции и надо так деда такие как сиквел ставка вычисление к данным и плачет . че там потоковое разработка так далее они все работают вот в этом сценарии исключительно поверх той информации что находится в кластере в памяти непосредственно в данный момент почему давайте это смотрим смеси сиквел а если мы не используем сиквел обращаемся по ключу то здесь это ограничение можно обойти мы идем по ключу в моем ухе datagrid мы видим что данных значения по этому ключу нет после этого мы идем вниз ниже лежащую б.д. например там какой-нибудь атаковали hadoop получаем данные загружаем себя к шифру modell наверх все великолепно приходит сиквел великолепие исчезает почему потому что там в кардиффа не например может быть какое-то абсолютно произвольные условия и мы получив данные выполнив от за кто спереди да опять в общем случае не знаем достаточно ли у нас данных или нет потому что мы не знаем какие именно данные лежат под видом внизу поэтому если бы мы хотели всегда отдавать этом случае консистентную информацию нам пришлось бы каждый запрос из каждый запрос дублировать вниз в этом случае вопрос зачем посередине вот откачивающей слой если он стал но по сути прост и отправляет а также запас вниз ну окей разве что если внизу что-то отказала отдадим какие-то фандомные консистентные не консистентные данные выгода неочевидна ну и вторая ключевая проблема это что предположим у нас случился деза 100 они к сожалению случаются иногда они случаются даже планово у нас этот слой умер он поднялся что происходит он пустой нам данным его нужно заполнять долго мучительно в зависимости от объема данных то есть например об очевидно это используется в сбербанке на сейчас нескольких сотнях узлах овцы ли вам состояние на двух тысячах на каждом узле там-то за байт памяти ясно можно читать все сколько займет перекачка этих то-то байт памяти в только что поднявшийся после краха кластер долго тесная интеграция с диском позволяет как раз таки эти моменты обойти за счет того что мы знаем что у нас лежит памяти что у нас лежит на диске мы констатируем перемещение данных между этими двумя слоями мы можем всю функциональность кто же у нас есть сиквел распределенные вычисления все-все-все выполнять поверх этого слоя и того слоя то есть когда мы интегрируем диск и когда мы говорим обо подчиняет начиная с версии 21 где появилось собственное дисковое хранилище мы говорим о том что теперь вся функциональность может использоваться по их полного объёма данных а значит что если раньше у вас на класс все могли храниться до фа байта данных но десятки таза байт данных в случае если это большая компания как сбербанк это сотни тогда байт данных то сейчас соответственно речь может идти уже значительно больших объемах этом тысячах то собой то десятках тысяч это за байт потому что архивные данные могут храниться здесь же и соответственно когда мы делаем тебя тот же сиквел мы гарантированно получаем всегда полный ответ и можем в том числе и на сделать те же join и потому что напоминаю сиквел это полноценно 99 с архивными данными для того чтобы получать какие-то реальные инсайты например поэтому сейчас если говорить о том как можно описать apache игнайт это скорее уже ориентирована на память но не ограничивающие с памятью платформа все так же платформу под которые можно строить разные приложения кто-то ориентируется на отказоустойчивость полный aside все замечательно высокую доступность имеет поддержку как киви лью api так и если необходимо полноценного антисекс 99 и замечательно масштабируется на 1000 узлов позволяя когда нужно работать с быстрыми данными делать это быстро полностью нам эти выделил достаточное количество памяти но при этом не забывать этих данных что на диске тщательно подавать или о том зачем это нужно для того чтобы быстро обрабатывать большие объемы данных там я кормят заказы банки транзакции анти флот мониторинге не знают с nifty газовые компании кемтипп maintenance все сказания поломок и так далее так далее так далее там подобное мы поговорили о том что в принципе изменилась и как созывалось технология и к чему собственно все и в том числе мы идут и как нам кажется мы все шли там одними из первых давайте поговорим как от работы внутри что под я была с изменить в apache и игнайт для того чтобы у нас появилось это замечательное тесно интегрирован одесского хранилище во-первых 500 собственно архитектуры хранения дальше об этом будет буду власти подробнее но там в двух словах если раньше у apache играет в лодке по сути были на каждый на каждом на каждом узле замечательном нашим топологии кольца на каждом узле были внуки конкорд х шмапы обычный java вский поверх них куча обвязки для секла для всего всего всего то сейчас мы полностью к ним все данные а вот теперь он хип теперь используется только как такое дополнительного twin каширование стилизуем их и страстном им их грамотно и быстро власти доставать также после того как мы изменили архитектуры непосредственно хранения данных чтобы можно было рисовать данные как в памяти так и на диске мы сделали свое собственное дисковое хранилище с на классических валах чьих пойнтинга ху похоже на к сансу в чем на самом деле только с полноценными сигнальными индексами почем клюшками для сиквела мы взяли h2 кто-то используется для постинга потому что спасать сиквел античной это нетривиальная задача h2 же используется для построения плана так необычного плана не опасного двухфазного потому что макета все прощается у макса дьюс и собственно исполнение плана это также просто водка почти 100 бат к комьюнити apache и гнать как выглядит архитектура хранения верхнему давнего вот так давайте опустимся поглубже весна основой всего этого являются станице у нас теперь в apache на теперь станичное организация данных накладывать том числе не и акцизы мнение кто-то на первый взгляд не очевидны так когда у нас были кант кастро шмапы например нас action то есть удаление данных из памяти полагаю что она не переносится в дисковое хранилище удаление было по концертной записи то есть могли видеть запись кто-то наиболее давно не использовалась театре если мы используем list is not льюс и ему из памяти удаляли а теперь снова станичной организация из памяти удаляется и в память поднимаются непосредственно станется с данными кто так может быть там разное количество записей а там опять одна запись это может быть там десяток записи в зависимости от размера записи от разметка страницы это накладывает на нас некоторые проблемы в том числе проблема вытеснил выделение памяти и проблему вытеснения самая логично что казалось можно сделать давайте выделим большие жирные станице их можно кусками запрашивать опер тонки классных за все замечательно великолепно вот власть в минус который состоится в глаза как только мы начинаем работать с реальными данными мы понимаем что они есть горячие они есть холодные все-таки мы стараемся делать не просто там сбоку пятое колесо что типом на диске там что-то храним как-то по стали сделать эффективную систему кто-то может безграмотно понимать какие данные нужно держать в оперативке какие данные горячие пактов можно быстро считать а какие лучше опустить вниз они обычно не используется вот с большими страницами не забота it потому что у нас вот есть эта замечательная большая страница вот синим выделены холодной данные кто танкетка возвращается красным выделены горячее и на больших станицах высока вероятность что среди всего объема записи кто-то останется находится есть какое-то небольшое количество записи горячих соответственно из этих записей страница будет постоянно подниматься в память даже если большей части она не используется эта вот синяя масса будет занимать драгоценные байт оперативной памяти а если память еще и не засчитано под вот эту синюю масса там почему бесконечно статус танец кто-то будет подниматься в память будем видеть что памяти мало теста не сказав наиболее давно не использовались будем отправлять на диск но у них тоже есть горячие данные поэтому они скоро тоже поднимутся в память будет плохо печальным получим ту же проблему ввода-вывода поэтому станица нужно делать маленькими почему мы пришли размер останется естественно настаивается и мы камин дуем устанавливать его таким чтобы на него помещалось только небольшое количество ваших записей чтобы как раз таки минимизировать ту проблему и для того чтобы не запрашивать у операционки там на каждый вот небольшую страничку не уходить там нет то не тратить на это время мы выделяем памяти сегментами то есть большими кусками внуки уже юзжд спейси намного быстрее сами это сбиваем это на свои внутренние представления по станицам там индексов станется с данными индекса у нас есть что б + деревья классически ok замечательно мы выделили станице но теперь возникает следующий вопрос вот я говорил кто это вытеснение из памяти то есть нужно задать какие-то лимиты что мы можем потреблять и хотелось бы эти лимиты как задать достаточно гибко потому что в принципе одна из ключевых вещей кто-то обычно подчеркнет предлагает то он говорит что есть куча разных сценариев для каждой потребностей концертной компании конкретного проекта есть какие-то свои ограничения и я подчиняет пытается нам предложите инструменты чтобы можно было настроить наиболее эффективно под данное ограничение потом там 1 что напрашивается давайте просто выделим глобально ограничение по оперативной памяти кто там можем занимать сделан там большинстве случаев по умолчанию в классических судьбы д когда есть какой-то объём кэша и на yamaha если б д как-то пытается понять что что то лучше класть что что да лучше не класть так можно сделать по умолчанию он так и будет работать но это плохо отрабатывать на том кейси когда в нас идет постоянный поток данных как операционных кто-то хочется обрабатывать так каких-то кто-то сразу в архив аппсалы забыл в принципе они лежат к ним иногда обратились там для реального чего-то но вообще их держать в памяти не хочется следующий шаг оказалась под давайте тогда на каждый условно cashel таблицу на каждый домен хранения выделим собственный объем оперативной памяти но тогда мы пойдем ситуацию когда много таблиц в итоге мы всю память подержим на маленькие кусочки и там ни на одну таблицу нормально и не хватит в итоге мы пришли к среднему варианту когда мы выделяем тоже называется регионы памяти это по сути группа таблиц и на регион задаем конкретное ограничение в этом случае вы можете сказать вот у меня есть операционные данные кто то с большей вероятностью гаффи отчет по этим данным я постоянно работах постоянно пишу я их постоянно читаю вот эту группу таблиц под неё выделено каждом узле смерти 100 гигабайт оперативной памяти а вот эти данные у меня активны они лежат никого не трогают иногда я поменяю там к нему защищаешь что-то но в принципе они не критичны к производительности вот под эту группу таблиц там выделив 50 гигабайт оперативки чисто для того чтобы их иногда перемалывать печати на настроили все работает все хорошо гибко позволяет адаптироваться под потребность в итоге глобально это выглядит где то вот так зачем с к той же схеме видим внизу страницы с данными с индексами с метаданными выделяются они сегментами муки уже бьются непосредственно на странице и поверх всего от в регионы памяти то собственно станет себе настойки то есть например если вы под какую-то группу таблиц временные вообще не хотите выделять дисковое хранилище начиная со починать 20 можно так делать то вы именно регионе памяти задаете что вот этот регион не нужно хранить на диск его только в оперативке пожалуйста замечательно выделили таблице определи под них регион записали таблица может создавать помощью xml джавы dota это или там где ели кассеты бу top people подняли таблицу заметить таблица но замечательно вот мы опять говорим сейчас про хранения хранения данных а хочется снимешь потом еще и как бы заботать получать их обрабатывать как от делается ошо давайте я хочу из таблицы б запросить что-то по ключу x положим я использую киваю api в данном случае что в таком случае происходит первое у нас есть такая вещь как называется фильм где функция от по сути небольшой кусочек кода кто-то говорит как есть ключа получаю идентификатор по птице по сути это уменьшение совместности и затем на каждом узле нашей топология причем там кольцо с клиентами кто-то встаёт там рядом с кольцом и на каждом узле вто пологие лежит мама по кто-то содержит себе информацию какая-то птица на каких узлах физических уже находится тесно получив запрос из таблицы б дай мне x я по иксу получаю эти позиции пойди патриции получаю на бот узлов на кто-то находится дальше зная таблицу я на узле понимаю в какой регион памяти мне нужно смотреть соответственно в этом регионе явишь пред таблица затем у нее и биту страницу с индексом по индексу нахожу в какой странице с данными лежит данная киваю паза куда мне нужно адресоваться в муке этой странице если она на диске поднимая в память если в память это все чудесно и наконец алика и атаки были по если у меня там было какое-то условие например в том числе стекольные подката подпадает несколько естественно записей то если могу их все найти через яндекс и просто от рисуюсь к ним ко всем через яндекс если это все в оперативке это очень дешево там есть какая часть на диске стрессом добавляется его офису из к ним всем по индексу отдаю если индекса недостаточно там часть колонок у меня по yandex прошло оно есть еще дополнительный вес на в этом случае по всем постам которые подошли по индексу я буду по ним проходить это считываться из к нам соответственно выполнять дополнительные условия опять же не мог быть сик вольны или условия могут задаваться любом java или dotnet кодом даже си плюс плюс на кстати замечательно а что же вот как все это ложится собственно непосредственно на диск на дисковое хранилище а кто там здесь все собрались верхнего это выглядит так никакой супер магии tast хороший код воловича points вал сайта hotlog то есть у нас есть файл в котором постоянно в конец дописываем каждую операцию которое происходит на каждом узле лижет свой собственный на каждом узле лижет свой собственный вал и каждый узел принимает те 15 записи кто-то эти левант на тем шар дам готовили наузы за который узел на данный момент ответствен дальше можно описать насколько мы хотим can систему сплотив скорости а также настаивается по умолчанию мы консервативны нам очень важно данные не терять поэтому мы делаем постоянно акцент на то что aside определенные транзакции в том числе между кашами все в точь и здесь мы также помочь они консервативны мы на каждая запись вал будь то insert апдейт дерек что-то еще делаем немедленно и в sing чтобы удостовериться что данные были записаны и так а после этого соответственно обновляемую информацию в памяти даем назад ок что все успешно записалась это можно ослабить можно выключить и в sing можно дальше включить вообще внутреннюю буферизации еще или можно вообще вал выключить оставить только там периодически чекпоинт ответ на меня я как система скотта 100 в зависимости от конкретных потребностей там периодически то что у нас память она скидывается в боль такой компактное хранилище потому что ну малость небольшой минус как если бы мы стали исключительно свала нам нужно было бы его кажется разворачивать теста на снос если у нас есть какой-то счетчик положим кто-то там обновляется 100 раз в секунду то если бы восстанавливались исключительно свала нам бы последовательно поехать памяти все эти операции выполнить то было бы долго поэтому периодически делаются чекпоинты которые позволяют оперативно восстановиться опять же чекпоинта не кажется с нуля мы пишем все что есть памяти это было бы огромное потребление диска накладывается на тот последний чекпоинт которые уже этом сохранен на диск тесно после этого кусок вала по которым и данные слепок записали он вставляется в архив то что было добавлено после этого она остается тесно случае если мы падаем и восстанавливалась после падения мы читаем данные с чекпоинта после чего накатываем поверх того что мы почитали тот кусок вала которых чип энд не вошел значит этого сохраняем все данные ну и наконец это все горизонтально масштабируется то есть каждый узел он всегда хранит только тот участок данных за кто-то над вес за кто-то он ответственен по сути мы данные шарди там все нам идти дальше где то данный шербета включая там вычислили нас в этом основу горизонтальной масштабируемости по умолчанию там данные раздетым фондом на случай над возможным тонким слоем это можно естественно настроить скала целовать необходимый для join of данных рядом чтобы скажем клиент всегда решила втянут в со всеми его транзакциями о том же узле но ключевая часть том что каждый узел отвечает за какой-то участок данных за какой-то участком отвечает полностью как хозяин то есть то дойдут записи именно через него еще какие-то участки у него могут быть backup ами с других узлов на случай если тугой узел им счет чтобы данные были опять же в сохранности защиту этого коэффициента избыточности и чтобы он мог подхватить на себя тот диск у нас стоит точно так же та часть данных за кто-то отвечает узел она может быть памяти она может быть на диске с на диске она будет на локальном дальше вопрос где-то хранить локальный диск это по сути то станете кто те ее можно подмонтировать непосредственно тот диск тот установлен в сети или в виртуалке его можно подмонтировать на какой-то сетевой диск главное чтобы это работало быстро потому что иначе мы опять же пойдем все чтение данных li-fi записи на его и начнем не утыкаться но даже если работает не супер супер быстро что мы здесь получаем какое ключевое преимущество горизонтальную масштабируемость стала вас стали питаться в можем просто доставить еще узлов на живую без downtime а данный утки балансируется то есть петь и размажется по новому количество узлов опять же потребность разработка запросов мы получим большее количество узлов более тонкие шарды и соответственно в меньше запросов и за счет на узел меньше будем питаться вот вот и наконец по их всего этого работает наш 90 тыс ecлu тапочек найти работает через либо java тут нет api либо через бибиси бибиси кински можно перечитывать тактический совсем ключевое чтобы запрос хорошо подлечитесь здесь их всегда можно зарабатывать как мухи устроен наш цикл по сути это марта dice упомянул для именно непосредственно с ботом нас пользуется h2h дважды стоит план на основе той информации по индексам всего всего вот этого схема хранения данных наша паста водка и исполнение запроса также наш iso 100 водка в итоге все это выливается в то что на каждом узле которые филе vantin данной таблице весьма до этого мы рассматривали пример когда мы по ключу искали узел бежали один узел шли туда и получали по ключу нужные значения когда у нас сиквелом и естественно в общем случае один узел выбрать уже не можем потому что у нас есть какое-то условие в кондишен у нас есть какой-то набор записи кто готов условий может соответствовать поэтому в таком случае мы на каждом узле который отвечает за данную таблицу а классов можно там делить условно на под кластеры это блюз размещать не обязательно везде на каждый узел идет не об часть запроса там мы вытягиваем нужной колонки выполняем whirlpool aws то есть собственно непосредственно фиксацию данных там скажем если эта транзакция в положим там по цене по сумме транзакции и вот там же выполняем лимитов сеты и вот то что получилось отдаем наверх на те тут следующий узел который формирует финальный результат делает операции грубое ордер buy частично рта сделается на мы потопили там делает соответственно финальной там же все меняется having то есть все эти операции для выполнения ката для вполне к так необходим уже полный набор результатов с каждого из узлов и результирующий ответ отправляется наверх опять же поджоге бесси вроде би си java api dot net api все плюс плюс api в зависимости от того что конкретно вы используете в вашем сайте these не то о чем мы сегодня поговорили почему сейчас поговорили поговорили об a patch игнайт ориентирован на память платформе для распределенного хранения больших данных и их обработки поговорили о том как в принципе куда идет как принципе развивался сынок хранилище баз данных и куда он идет что мы все хотим секунд секунд стандарт мы хотим максимальную скорость это и на махе мы хотим горизонтальную масштабируемость потому что когда у нас много данных по другому нельзя поговорить о тех ограничениях которые существовали в частности в новом эти до такси дах и поговорили наконец о том что в патче night начиная с версии 21 которое вышло в середине этого года паес постоянное хранилище и от мне новая слободка там взбить авто питаются уже больше года например и не только узбеки и наконец поговорили о том как это устроено внутри как у нас данные лежат в памяти на диске как мы обеспечиваем их сохранность что мы используем для того чтобы эти данные горизонтально масштабировались это то о чем я хотел сегодня с вами поговорить спасибо вам большое за ваше внимание с удовольствием отвечу на ваши вопросы и естественно после можно ко мне всегда подойти причем спасибо за интересный доклад вот я так и понял что у вас в памяти используется технология в дерево а что у вас за технология на диске у нас б дерево идет как по данным в памяти так и на диске вот есть ли там содержится информация по станице его все тануки странице мы из индекса получаем в какой такой станица лежит запись дальше понимаем это станет у нас как раз таки в памяти или на диске то есть яндекс нас общий понятно а вот там где то рассказал про и черты или ты отдай ты которые на диск приходят они вот прям вот прям выполняются обрету например на диске или там enter ты туда же иначе как это выглядит во первых у нас есть несколько режимов пиво пить этого не в принципе упомянутом что у нас вообще диск можно не включать тогда все будет если диск весь диск включен то дальше в любом случае до того если включен вал одновременно то до того как мы обновим данные в памяти и ответим клиенту что все успешно записано мы допишем эти данные вал дальше настаивается насколько мы консервативны то есть по умолчанию мы вот пришел он съест но его дописали вал в хвост принципе достаточно быстро немедленно сделали в sing чтобы данное действительно записались они остались где-то в кашах опять сон ки и только после вот этого стресс надо лет он сел этом сила танцы задержки отдали ответ здесь опять же томатами не обойти можно ослабить предсказать что моя псинка не делаем но тогда мы получаем ситуацию когда если у нас упал узел или там описан конак упала то тогда к shiny skin лист на диск и мы какой-то хвост можем потерять или можем вообще там не знаю вал выключить то здесь мы обитаем тега санте которые нам нужны тогда вот а как как вы поступаете ситуации при insert их вот если вы вставляете его быстро вот в конец вала как вы проверяете что ключ уникальный по сути надо прочитать сначала скрытое чтение должно идти эти скрытые чтение по диску получается но если я вообще про ли понимаю но если дома проверяем естественно что ключ уникальным у нас мудхи наши основы это то именно кивают они еще поверх которого ясик вольны индексы поэт готовая секу но основе именно есть келью ну а дальше у нас key value стресс на есть индексы потому что нас всегда есть яндекс непосредственно по ключу я даже хэш индекс почему они биты а не г плюс дерева и yandex у нас расположены в памяти поэтому для того чтобы заметить если ключ нам на дескать и не нужно понимать то есть момент проверяются наличие ключа да потому что ясно спасибо спасибо спасибо за доклад а вот вы показывали как и сколь движок рассылает своей команды на ноды о планировании где происходит на самих но до хи цель централизовано а центрации централизованного там той нотой которая получает этот sql план составляется централизовано той ноты кто-то получил запрос за план у нас встречает ассаж 2 install готовит ней свой обычный плана он готовит вот именно двухфазный план вторая фаза за ссылается на но ты там выполняется получается результат проект результат выполняется первая фаза а как вы статистику шерите между нодами на то есть может планировать нужно на ирак они статистика по колонкам гистограмм ки или или предполагается равномерное распределение в общем предлагаем обычно что у нас данные присунуть порезаны поровну или пока не местом makita большой сегмент этом девочек больше чем мальчиков камень таблицы или наоборот и типа войдет на тонкости отдельно отмечу чтобы не вводить заблуждение графстве спасибо за доклад расскажите пожалуйста что у вас с валом происходит когда по каким-то причинам транзакцию надо откатить вы записали то это до изменения за синклер а потом у вас ошибка как произошла эту транзакцию надо откатить как вы ее откатывать насколько я помню вот здесь давайте тоже подробнее отвечу отдельно позже нас к помним мы вал добавляем запись о том что транзакция с данным идентификации мне активно от передать и отдельно отвечу подойдете оставить контакты чтобы не будет заблуждения просто сейчас какого типа памяти и могу не скачиваться здрасте я вот хотел узнать но продолжу тему индексов по поводу индексов и сказали то что по ключу это кошмар поводу вторичных индексов этого дерева и оба типа яндекс они сохраняются на диск и необходимо ли прогрев индексов на этапе вот старта приложения на этапе поднять и игнайт и носом и приставьте то что у нас происходит это индекс поднимается в память начально индекса мы держим памяти потому что они в любом случае натягивать вот как бы ну сколько на это времени уходит до есть объема данных то время индекса в принципе это несколько страниц каждая страница записано последовательно поэтому обычно это не является узким горлышком но в принципе зависит конечно от объема данных если вас очень очень очень много мелких данных порядка . очень-очень много индексов то это может занять с на какое-то большее время но это в любом случае нужно сделать потому что индексы обычно горячие по ним так или иначе пойдут запросы даже если это будет мисс и если это не сделать сразу том что с помощью непосредственно после запуска сразу совсем у жесткие тормоза и можно еще 2 вопроса по поводу и балансировки и получается вот например есть кластер одна нота выходит начинается ри балансировка данные мастер бочче становится на другой ноты до там дополняется еще одной репликой и когда снова мода возвращается получается например там был теперь репутации 3 до становится 4 то надо возвращается и данный вот как как данные удаляются в этом со старой ноды или как удаляются избыточные данные как они удаляются как это спирте чистом там при любой взаимодействие по другому выглядит это выглядит не с той стороны что у вас вот пришла но да у вас коэффициент избыточно стал читать это выглядит так что вы задавить коэффициент избыточно скажем 2 вас может быть хоть сто not вызов для коэффициент избыточности 2 ногах у нас есть все данные но данные режу изначально находит количество шагов по умолчанию 1024 можно настроить дальше у каждого шарда есть узел один который является для него мостят узлом в чем его отличие он принимает на себя все записи поэтому шар ду и есть какое-то количество узлов в кольце кто-то является backup бэкап с точки зрения ваша да то есть они хранить все тизерную копию плотно томат изменение количества сам по себе как созвучность не меняется дальше когда у нас входит узел или исчезает узел тоже той сходите балансировка по умолчанию на автоматическое ее можно там за тот летят за не читал свою способность так далее может сделать вручную по умолчанию на автоматическое что случится мы посмотрим наш топологию после этого посмотрим посчитаем где учти жить поститься этом по умолчанию мы делаем там consist of ageing становимся по минимуму их двигать на больших топология это может быть там более заметно по 100 км и почитать по птице мы начнем пить оливку при этом все также то надо кто тогда то предположим было маститом худшем случае мы хотим сменить most это для шарда она все так же будет маслицем он будет принимать на себя записи и зеркалит в этих дальше туда вплоть до того момента пока петли вко не закончится там вплоть до кого-то очень небольшой дельты дальше в этом случае на ответственного время сейчас захочется мостят сменится на топологии это случится записи пойдут на нового мастерства для бэкапа все проще потому что там так жестко latch уже не надо как обойти проблему когда у нас очень большая топология у нас входит уходят мода на живую и получается там много шагов потенциально может все равно двигаться если такая проблема есть мы обычно рекомендуем делать ячеистую структуру то есть не делать одну топологию на равных правах а выделять мысли топологии какие-то ячейки скажем кратные 8 каждая чек отвечает зафиксирован набор шагов всегда их прицепиться не только мухи это ячейки естественно когда к нам приходит новый узел он падает в какую-то ячейку и данные туда будут перемещаться только изнутри этой ячейки то есть объем перемещений и там количество от разных связями с разной узлами будет меньше просто вот у меня такой вопрос возник а табличный движок только один то есть можно настраивать допустим включить диск для одной таблице отключить диск для другой пирсинг для одной таблице включить для другой отключите или только на instance можно вот как со 100 что говорил о регионах памяти регион памяти это газу под таблиц готова имеет общие настройки по работе с диском и с памятью как раз таки на уровне региона можно в принципе выключить хранения табличку можно отнести к одному региону для которой будет только память другого другой табличку другой ребенка который будет диск до момента что на каждую табличку отдельный регион выглядеть там вместо табличка много это будет неэффективно но с о том что да если по ким табличка мне хочется их вообще хоть на диске отдельно регион создается в нем диск выключается таблички привязываются к этому региону а еще у меня один вопрос вот никаких сравнений не делали с аналогичным решениями какую-то не на этом клик house у себя там на сайте выкладывает что вот мы сравнили 100 мс vertica еще с кем-то и вот тут мы быстрее тут мы медленные у нас есть на сайте сравнения сказал каста мультимен цифрами спасибо спасибо за доклад у меня такой вопрос как как контролировать процесс перелив ки данных в память но с жестких дисков после холодного старта как он контролирует мы сначала индекс загружаем всегда в память эта операция закончилась и дальше вот после того как мы подняли индексы дальше класс но то что мы называем лазит анд классных непосредственно готов сразу принимать запросы по мере поступления запросов те страницы на кто-то не падают будут подниматься в память то есть по сути если мы хотим завтра со 100 зарабатывать быстро то после старта нужно сделать какой-то прогрев там типичными запросами кто ты могут поступать или оставить это на усмотрение клиента понимаешь что первые холодные запросы они будут медленнее потому что вы данные будем поднимать с диска то есть память поступлении запроса вкладчикам и данные постепенно тянем а можно как то вручную как бы вообще все данные понять то есть он сам будет можно сделать без запроса можно запустить плату под сделать все напрасно все данные как часто снимаются делается чекпоинты вот и как в это время проседает производительность настаивается как часто делаются чекпоинты вы можете указать там любое время кто-то удобно полу того как то считает производительность здесь зависит от пропускной способности диска там есть диск быстрый то там на себе он там площать процент потому что 510 если диск медленные то там можете серьёзней принципе вот диск это если мы используем 5 из нас диск естественно это важно потому что спасибо за доклад можно еще один небольшой вопрос достаточно странный если у вас такая возможность если нет планировать или поддержать допустим что она за кашира на какая то значительная но не вся часть данных вот часть лежит на диске и мы хотели бы получить вот эту долю который лежит в кашицу наношу в гряде и возможно прочитать не все оставшиеся на диске а какой то часть чтобы получить какой-то гарантированный процент данных есть допустим 90 95 процентов это нужно будет для статистики мониторинга и на самом деле некоторые других задач вот но мало где встречал такое решение спасибо то есть если абсолютно понимаю вас можно ли при запросе выполните его там не по всем всем данным а только по какой-то части стараясь из этого вы таскаете спеша но и реально нет ответ можно на узи вот разлить какой-то java код 0 у нас там пивко slow link то есть можно до клиента может если у него есть соответствующие права оставлять java или dota от класса на класс то естественно мутиланс произвольный код nokia так можно более сложный запрос под стеклом плохо описываются иерархические какие-то еще делать соответственно если мы это делаем дальше ну как минимум ходит процент здесь уже можно получить особенно если у нас есть счетчик чтобы делся начал аккаунт по всему получив все данные по тому же процент еще и так чтобы в первую очередь из памяти читать на данный момент нет мы по пьяни предоставляем информацию о том где конкретно лежат сейчас эти данные спасибо за доклад подсказать просто если какая-нибудь схема данных здесь а то есть эта схема лес или задали какая-то жестко или так жестко схема зависит а если вы использовать наше гибелью api то это схема лес в этом кладете по ключу получаете по ключу главное чтоб потом в этом объекты могут выходить катод и вы хотите получить а если вы используете сиквел то здесь естественно есть схема где-то описывается да естественно вы но сегодня таблицей у можете одним из двух способов получить первое вы даете java dotnet классы и этих классов аннотации определяете поль актов должны быть доступны через сиквел фактом должны быть построены индекс так далее так далее на выходе получать что к этому объекту также будет создан таблица 2 вариант это использовать недель то есть сделать на нас там костей табл и все те был указать соответственно колонки их типом соответственно следующий вопрос подскажу если функция up her то есть h2 что я по мономер что называется между есть и последний вопрос вот вы сказали вас происходит автоматическая балансировка все это автоматом с коробки работает собственная функция отвечающая за поиск шарда она какая-то вшита стандартная и могу ли я ее изменять мечта автоматическая тебя вон ставка по умолчанию опек и можно настраивать гибко там ограничивает так далее можно вообще включить вручную можно общем выключить даже поводу функции мы поставляем стандартную функцию но это обычный интерфейс у нас практически всего по чайной тактики все компоненты можно заменять у нас даже теперь пи-связь между узлами от реализации интерфейса каменюкой шина spi реализация конфетное теперь иди ко мне конечно спять аналогично финки функций отводка стаки функция кто-то определяет как мы из ключа получаем шахт есть харда получаем узлы она вполне заменяемая причем она вы разных на тебя зуб таблица может быть разное и на все места используется для чего там некоторые наши клиенты не просто использовать коэффициент избыточности но еще и дополнительно настраивают чтобы когда вот эти вот backup это связь между узлами чтобы они лежали бы всегда не на той же сне в той же стойки где основная копия как раз в этом случае нам необходим для матки давать каждый узел кокаин стойки находится в запуске и функции учитывать когда мы расстреляем бэкапы чтобы они ст с ними лежали на узле кто-то матки roland той же стойкой спасибо да и последний вопрос наверное подскажите пожалуйста если у вас constraint и там вторичные ключи ссылочной целостности и прочие такие штуки нет у нас нет константа вторичный ключи в плане констант в плане индексов виду у нас там одна много колонок ну то есть я имею там ссылочной целостности как в реляционных нет спасибо пока пока не иметь нет makten называем секунде гель-пилинг фильм на старушка свистит оптом alt отъезд на добавление колонок потом будет удаления то есть пока нет но мы активно работаем над этим при сетевом сбою если узлы apache игнайт разъехались из кластера как можно это увидеть тома следить и вот этот сплит бренд девайсе аннотация тоски джейн вот как за этим следите с точки зрения сопровождения систему и вовремя отреагировать если какой-то инструментарий какую-то мониторинга device service и какой-то способ том каким систему мониторинга подключить что здесь есть два варианта первый но так я сказал деталях компанию гасят gehen wir gehen это компании кто-то изначально apache и гнать создала 2008 еще года и в двенадцатом вопрос непростой пан 100 патча отдала и легенд работает по принципу пинков то есть об очевидной кто полноценные функционально полностью там никаких ограничений нет но это продукт на патчи сообщество не позволил бы включить но поверх этого взять ген предлагает какие-то дополнительные плагины для обеспечения там мать иных опций по отказоустойчивость так далее в частности один из плагинов кто предлагает bergen как компания и так раз таки street and detection потом количеству зуб о ческим изменением топологии и кстати в этом случае настойка что делать там либо убивать весь класс that либо там убивать меньшую половину либо что то еще ответственно первый вариант второй вариант ну написать аналогичный самим то есть аналогично смотреть на изменение топологии у нас все изменения топологии это ссылается ивентами + dmx и торчат кто ты там к zabbix куда-то еще можно подключать и в детских изменениях топологии там делать собственный какие-то ты гитана это ясно просто вариант вы рассказали как апдейты insert и попадают к мите так сказать на мастера но я как они нас потом попадает на но все записи проходят через мастер если кладка там остаться слайд их на слои вы если чуть длиннее то дополнительно настраивается он будь то слать их синхронное leasing тонн а если синхронно то средстве на маслят получил записалась на слои вы слабы открыть или все чудесно мостят ответил все чудесно the matching тонн ответственно мастер получил записал ответил все чудесно и после этого фоне уже отправил нас live it up синхронности не совсем классический славы и асинхронности может быть такое что при падении мастерноды будет то есть синхронизации несколько версий в этом случае видят все а кто-то и больше их ее векторные часы победит то есть принципе какая-то из них победит здесь скорее может быть такое что мастер ответил все ок еще никуда ставить не успел момент клиент думаешь думай что все ока на самом деле мастер не успел момент такого же там класс тоф поедет не будет и еще я здесь а вы сказать что внешнее ключей нет а если вторичные уникальные ключи на данный момент нет вот по поводу consent of это у нас там в ближайших планов их тоже нет не помню есть более отдаленных или нет по поводу уникальных какие вторичных насколько помню они есть там плане на ближайшую там или после ближайшую ветку соответственно вытекающей а будет ли работать мерз по вторичным уникальным ключом эти так скотт мне отвечу что что мы сейчас говорим еще эта функция кто-то и в планах остатка еще нет поэтому давайте тогда отдельно и по схеме локи в итоге дед логе как это реализовано в tarantul и нету вот лаков сразу берлог идешь и отключается в реляционных есть вид локи когда идет период ожидания как у вас это реализовано у нас аналогично есть ну во первых у нас есть два режима как мы к мите ему словно пессимистично оптимистичный а то зависит берутся локи небе социологии ясно случае с пессимистично когда локи берутся здесь насколько помню нас тоже white ну давайте от тоже уточню это все настраивается до"
}