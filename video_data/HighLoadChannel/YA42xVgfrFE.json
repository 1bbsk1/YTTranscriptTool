{
  "video_id": "YA42xVgfrFE",
  "channel": "HighLoadChannel",
  "title": "ELK: менеджмент логов, быстрая локализация проблем / Сергей Шумов (News360)",
  "views": 40197,
  "duration": 3550,
  "published": "2017-04-22T14:48:25-07:00",
  "text": "Добрый вечер Меня зовут Сергей шумов я возглавляю команду серверных разработчиков компании New 360 занимаемся Мы тем что агрегирующие и распределённые Сегодня я вам расскажу как мы используем КК успешно используем к для Ну во-первых быстрой локализации проблем если они у нас возникают и во-вторых просто для того чтобы получить дополнительную информацию о нашей системе Итак для начала несколько слов о том что такое КК - это аббревиатура для трёх ключевых технологий в нашем пайла обработки логов это такая Тука кото разных мест логи перенаправить в другие разные места у не есть в данном конкретном случае используется она для того чтобы логи Ну в нашем случае по сетке переправлять сохранять используем Мы например не напрямую Почему нельзя напрямую вписать в самы он так устроен Что эффективнее всего в него спи нужно копить если у вас 10000 сервисов то есть они все начнут обращаться к будет ну не очень хорошо это фактически сердце всей системы именно он обеспечивает поиск и аналитику наших логов ну и соответственно - это очень удобный поиски интерфейс для поскольку сам Если вы не хотите иметь если вы хотите иметь дело с дном То есть все поисковые запросы к нему идут через что не очень прикольно если это нужно делать срочно ну и плюс у него конечно никакой визуализации то есть на вход у него на выход у него тоже как обычная база данных Какие основные кейсы приходится решать каждый день по лого Ну во-первых это быстрый поиск что-то случилось нам нужно найти события в ло рент к этой проблеме во-вторых во-вторых посмотреть какую-то аналитику Ну то есть если вы нашли допустим ошибку которая является проблемой именно изза этой ошибки у нас не работает система так как должна работать просто просто найти один если мы найдём сразу 10.000 ивентов таких однотипных которые содержат какое-то ключевое слово допустим е чтото бым было поть Като вторичную аналитику например по каким узлам у нас больше всего этих ошибок по каким типам пользователей Кай дополни информацию которая нам поможет как-то локали Зро потому что глазами просмотреть сотни тысяч интов просто невозможно конечно всё это нужно делать по логам с нескольких сервисов поскольку система распределённая распределены физически на физических разных машинах то это всё е нужно делать оче быстро все пробле возникают Тода когда мых нем ВНО нужно встать быстро ВС фиксить и чем больше тут трение тем дольше мы это фиксим А когда Каждая минута Дан тайма чего-то стоит то это реально проблема классический подход гин пала заключается в том что мы берём какую-нибудь либу типа и либо ещё какую-то которая нам даёт Три простых три простые вещ Это логирование она за на логит фа соно старый файл она как-то маркирует что они старые и дальше ну здесь либо либо теже некоторые либо сами умеют архивировать старые клок файлы чтобы они не занимали место на жёстком диске искать в этом подходе поиск у нас идёт через г старый добрый г соответственно аналитика нулика наме тобо поно стандартных The C C и так далее То есть здесь всё стандартно этого подхода есть свои плюсы и минусы Сразу говорю что мы этот подход используем наряду СК стеком просто потому что нам важна Надёжность логирования плюсы Конечно же да надёжно но Что тут может пойти не так мы пишем файл файл лежит на жёстком диске можно его прочитать это просто реализовать ничего не нужно то есть вы просто выбираете какую-то адекватную либу который умеет делать ротацию логов и всё не требует дополнительных ресурсов вам не нужно дополнительные сервисы которые эти логи будут агрегировать собирать хранить индексировать и так далее у вас просто обычные файлы и Core Ну обратная сторона этой медали конечно же то что нужно использовать п для фильтрации Почему Потому что например у вас есть веб-сервис и он логит результаты ответов вы хотите посмотреть найти все записи связанные с статус кодом 419 например 404 Если вы просто за бьёте г 404 то вам помимо того что выведут записи где 404 - это реальны статус код могут вывести записи которые вообще никак не относится к результатам ответа например что содержит 44 или 200 это проблема здесь нужно подбирать очень кропотливо регулярные выражения так чтобы попали именно те записи которые в которых 200 это вот это статус код это геморрой особенно когда опять же 300 ночи всё это нужно делать как можно как можно быстрее ну и соответственно разные сервисы у нас имеют разный формат и получается что мы под каждый должны подбирать чтобы чтобы ровать то что нам нужно с помощью corals не получится делать сложных агрегации быстро Ну например посмотреть топ ошибок не по количеству частотности в Log файле А например по количеству пользователей уникальных которые это ошибка задела Или например отфильтровать по временному промежутку за три определённые минуты это всё довольно сложно сделать но если у нас софт не помещается на один сервер ТО система распределённые и тогда у нас много-много этих файлов и нам как-то нужно с ними будет е сложнее сделать ЕС будет один фа много-много разных фа с разных сервисов Что можно сделать во-первых можно взять просто и собрать все файлы со всех физических хостов на один какой-нибудь ло сервер есть в принципе хорошее решение которые работают даже быстрее чем Потому что в них мех пзи и NG Какие проблемы То есть мы взяли и все логи просто вот слили в одно место у нас есть наш Лог сервер где лежат где лежит Папочка LS и там логи со всех наших сервисов абсолютно вопервых порядок событий нам не сколько важны сами события сколько их контекст причём не контекст самого самого события А какие события были до и какие после соответственно Чтобы это сделать вот этих вот простых продуктов которые просто сливают файлы Да кстати они работают только с файлами то есть они не могут по сетке принимать в каких-то сложных форматах тогда приходится ржать ржать фактически ивенты слогов для этого нужно как-то указывать во-первых где у нас время бывает такое что ещё время на машине не синхронизировано то есть на машинах синхронизация времени вло они пишут локальное время и тут увы чить рос сервисную аналитику То есть если мы слили всё в один сервер то есть на один сервер ТО с помощью например посчитать что-то сгруппировать по разным файлам это будет довольно трудно Почему Потому что у них разные форматы разное количество данных и так далее Ну и как вообще в принципе на баше это Это не очень хорошо Ну соотвественно если у нас файлов вообще очень-очень много у наш бедный Лог сервер просто начинает задыхаться у него не хватает ресурсов чтобы всё это обработать На данном этапе многие начинают писать скрипты для парсинга Лога на питоне на ещё чем-то там на баше Если вы это начали делать то вы уже выросли из этого решения И вам нужно двигаться дальше что мы можем улучшить во-первых проблема самого самой структуры Лога если мы Как в классически Просто берём пишем некоторый паттерн который потом агрегирующие через чёрточку и так далее А вам потом это нужно будет всё грем искать как-то что мы можем улучшить Ну во-первых изменить формат логирования в так называемый структурированный г Какие требования вообще к формату Лога могут быть во-первых он должен сам описывать свою структуру почему это важно сервисы разностные соответственно где-то документировать в каком порядке там где у них Ош пользователях В каком пор большой текстовой это это путь никуда поэтому формат должен описывать сам себя он должен говорить Какие атрибуты в нём есть и типы атрибутов формат должен быть расширяемый поскольку сервисы разные у них разные кейсы и логировать соответственно они тоже будут разные например веб-приложение имеет смысл логировать статус код время ответа какой-нибудь сервис аутентификации может логировать например сколько раз пользователь попытался залогиниться прежде чем он его забанил Я не знаю например г должен эти события они должны быть легко формироваться на в принципе любой технологии Например у нас система мы используем Python nodejs CSP используем с используем jav используем и везде если мы вводим структурированный Лок то нам нужно легко сформировать полностью ивент и также легко он должен парси То есть если вы захотите логи в проба например реализовать или ещ какой-нибудь кастомный формат то вы потом просто сами огре когда захотите что-нибудь распарсить вдруг Ну и конечно же должен быть КТА чтобы без к если просто положить его в файл сделать Или тот же греб мы могли просто глазами посмотреть что там вообще лежит по поводу содержимого что класть вло во-первых обязательно должен быть контекст не про что так всё что-то пошло не так вот ошибка и всё нуже ещё контекст например что пользователь запрашивал то есть его путь URL если мы говорим о веб приложении какие-то возможно атрибуты пользователя которые нам потом будут нужны например его айпишник чтобы сделать геолокацию посмотреть что у нас реально проблема только с пользователями которые к нам заходит из нью-йорка или из сан-франциско также должен быть максимум структурирован то есть не надо конкатенировать в одну строчку что-то то есть лучше допустим Если вы логи ту Code не писать Return with Status Code 200 а писать Например resp Return и отдельный атрибут должен быть статус код 200 далее Понятно Будет Почему мы выбрали для такого формата собственно Он подходит всем параметрам есть много критики джисона о том что он долго формируется занимает много мест если выбрать mcg какой-нибудь будет гораздо лучше но опять же если мы выбираем Кай бинарный формат мы сразу же теряем человека читаемость сам не сказа что он как-то что мы в него убираемся Потому что почти для всех языков медных для есть натив реализации и формирование сонно если у нас есть структурированный вне почему бы его не положить в преден Бау Дан для это отлично подходит elastic sech по ряду пат во-первых он но мас то есть ЕС у вас количество логов выросло в 10 раз Вы 10 раз больше исов вате и всё работает во вторых sech у него есть механизм High availability репликация Вы можете поставить replication Factor любой допустим 2 3 4 и если вам это критично сделайте полностью отказу устойчивый кластер elastic sech сам elastic Search его Концепция - это индексы То есть это если кто-нибудь с ним не работал в реляционной базе данных как просто база данных у индекса есть Тип тип - это как таблица в базе данных elastic sech дробит индекс на шарды фактически независимые куски и распределяет их по узлам ещё интересная особенность уча можно делать горячие холодные узлы то есть допустим для горячих данных если у вас используется в основном вы смотрите логи за последние 3 дня вам они критичны как тактические логи тогда вы можете часть часть исов поставить с SSD дисками а допустим за остальные 30 дней 27 дней будут обычные Сато диски elastic sech он его можно дать какие индексы по шаблону На какие узлы передвигать и он их будет передвигать в режиме background то есть будут приходить новые индексы старые будут потихонечку переползать SD дисков на HDD диски также очень удобный механизм шабунин сов что это такое поскольку сервисы разные данные индексируют разные иногда какой-то сервис генерирует Ну прямо уж очень много данных и если вот положить его в который индексирует вообще все поля то просто начнёт ВС Ува А если вот мы чуть-чуть покрутим то всё будет Зашибись это слать довольно просто просто делается шаблон определяется индекса пони в нём содержится имя сервиса надо брать вот этот вот шаблон и не индексировать какие-то данные или наоборот индексировать обычный паттерн для работы см - это держать индекс по дням То есть вы можете конечно индекс по месяцам индекс по часам в зависимости от данных но самый такой скажем так популярный подход - это один день один индекс почему это делают во-первых ротация логов гораздо проще То есть если вы положите в обычную базу данных какую-нибудь то удалять старые к записи вам придётся командой Delete здесь же идёт просто дроп индекса и он дропается вот на уровне просто удаления файлов с жёсткого диска последовательно за секунды elastic Search можете сказать Сразу по множеству индексов то есть не нужно бояться что индексов у вас будет много нет эта штука она умеет искать по вообще хотя хоть по всем индексам вообще что у вас есть также он умеет удалять сразу множество индексов Ну например вы хотите удалить сразу все индексы за месяц пожалуйста по маске можно удалить всё илит это очень быстро Ну и как я уже говорил перемещение индексов между узлами очень интересная вещь мы её активно используем в нашей компании са это как база данных к нему есть У нее к не можно в принципе кайто же и использ его просто как аналитический движок Но это неэффективно когда вам нужно быстро разобраться в логах поэтому для него есть очень классный пользовательский интерфейс под названием банана поддерживает почти все фишки полнотекстовый поиск поиск по атрибутам даты она понимает как с ними работать поиск по диапазонам значения агрегации но агрегации она поддерживает Не все сразу оговорюсь есть часть агрегации которые она не поддерживает соответственно агрегации сами агрегации в ки бане делаются довольно просто во-первых мы что мы должны Сначала мы должны отфильтровать массив логов Вот пример у нас происходит всплеск ошибок с тем работать как-то Ну видно Что не работает мы делаем смотрим Ага У нас есть спес ошибок там на Метрика ещё где-то мы заходим в ки бану Смотрим А дай мне топ ошибок по количеству пользователей которых которых она задела что мы делаем мы настраиваем агрегацию AG и мы настраиваем сортировку UN - это идентификатор пользователя и справа мы видим результаты количество ошибка и количество пользователе которые она затронула инт на текстовый поиск здесь очень интересно что elastic sech по умолчанию у него включена такая фишка как индексировать все поля в одно то есть если вы не помните В каком атрибуте у вас э то есть по какому атрибуту искать то задаёте без атрибутов просто как слово и она ищет по всем атрибутам плюс она подсвечивает результаты выборки То есть если вы там напишете слово Send то она его подсветить вот прямо в ивенте где оно встречается поиск по атрибутам собственно здесь либо диапазонный атрибуты либо точные атрибуты у кибана есть такая классная фишка это взять какой-нибудь ивент найти интересный посмотреть Ага а вот у этого ивента например он был к нам послан с такого-то Хоста А я хочу посмотреть ещё какие ивенты есть с этого Хоста де в один клик нажимаете на кнопочку с плюсиком напротив этого ивента и вс автоматически все ваши ивенты отфильтровывают по за одному критерию тем кому не хватает полнотекстового поиска просто как набор слов есть queries это не совсем queries это Search queries но они очень похожи Один в один там есть все те же фишки and or сложные условия not и соответственно тоже очень интересная фишка - это просмотр топ значения какого-то атрибута Например у вас идёт спе ошибок А вы хотите посмотреть Ага С каких хостов у нас больше всего ошибок приходит это позволит сделать в один клик кликайте по атрибуту слева и появляется дропдаун с фактически с списком значений отсортированных по количеству немного слов о том как организовать логи с разных сервисов в El есть два способа организации Первое - это каждый сервис или группу сервисов делать отдельный индекс Ну то есть Вот как вот в верхнем примере logs префикс дальше кроле тип сервис или группа сервисов и дата в в виде год месяц день либо же можно вот увас в Log Station например по умолчанию запихивать всё в один индекс то есть ш чёрточка и тайм мы рекомендуем хоя свого опыта всё-таки брать первую стратегию Когда разные сервисы писать в разные индексы Почему Потому что разный сервисов у них разный поток ивентов они могут генерить соответственно для некоторых сервисов мы можно хранить за 30 дней логи А за других сервисов можно хранить по полгода Потому что если мы разделим их то мы можем установить lifetime для каждого индекса отдельно у есть такая интересная вещь Это cator это уза который позволяет делать что-то с индексами передвигать их на другие узлы то есть отдавать команду что вот этот индекс ты пожалуйста elastic sech его подвинь там на на те узлы у которых есть л например HDD или наоборот SSD либо просто взять и всё удалить то есть вот все индексы старшие х дней просто удаляем скопом Поэтому если Мы настроим для каких-то сервисов отдельный lifetime Например у нас есть htp II мы для него держим логи не больше ТХ суток потому что там ну просто их очень много и они не имеют смысла больше ТХ суток и держать если что-то не произошло тро суток скорее всего мы ну вряд ли к ним вернёмся и опять же мы же его используем вместе с классическим подходом то есть пишем логи файло систему Если уж очень-очень надо будет то мы их поднимем Но это е ни разу не случалось А есть другие сервис например мы и за полгода то есть там очень важно иногда наши партнёры говорят А вот ребят что-то у нас цифр не совпадают с вашими а посмотрите вот быстренько что там и имея логи уже проиндексированы ВК стеке Мы открываем ки бану находим временной промежуток за которых у них вопросы находим им цифры и даём доказательства они говорят Да О'кей Всё мы понимаем ещё один кейс который мы используем которой мы используем успешно кстк это отслеживание сессии пользователя вот представим такую ситуацию пишет нам пользователь Я что-то в вашем приложении сделал а потом Теперь у меня сейчас всё всё решится ничего не работает мы смотрим Да действительно А что же что же произошло то есть там это это не массовое явление какой-то единичный случай что вообще он делал если мы в наших логах точнее мы в наших логах ведём трекинг идентификатора пользователя по всем сервисам поскольку у нас микросервисная архитектура и точка входа в нашу систему - это http приложение то есть H фактически который использует iOS клиент то запрос поиска обслуживается там десяткам Серви сервисов различных и посмотреть что же было можно с помощью той же ки баны когда мы отфильтровывает пользователя и видим хронологическом порядке события со всех сервисов которые относятся к текущему пользователю отф по временному промежутку можем посмотреть что было что пользователь делал как эти сервисы реагировали на его действия И что в конце концов привело к тому что у него всё сломалось Ну и хотя бы ради того чтобы это воспроизвести ещё один кейс у нас подскочила Метрика по 44 ошибкам поили почему-то идут на несуществующей странице что не так всё пере проверили всё работает всё О'кей посмотрели в ки бану что мы сделали Мы отфильтровали мы взяли топ пользователей по количеству запросов их http и отфильтровали всякий мусор UB Это позволяет сделать в один клик и мы видим что у нас есть пользователь один у которого количество запросов как-то подозрительно большое какое-то подозрительно большое то есть оно резко выбивается от всех остальных Это хороший пол пос что это за пользователь пошли в базу данных Смотрим А это пользователь он вообще не активен то есть от его имени видимо кто-то установил краулер либо ещё что-то которое долбила по нашему ipi что-то пыталось сделать а ссылки эти были старые поэтому он натыкался на 404 соответственно почему об этом рассказываю потому что пришёл Арт админам они проснулись ночью что количество ошибок резко подскочило Что произошло Ну вот собственно сделали Дрил и дошли вот до такого ещё один кейс исследования всплесков тоже пришёл Арт админам что подскочил подскочило количество ошибок в единицу времени понятно что всё время какой-то идёт какой-то шум особенно если у вас открытый II кто-то начинает долбиться кто-то начинает вас исследовать что там только не происходит Вот видим пик Что делаем дальше это у нас слева графана мы используем для метрик графит и фану и ки бану Почему так графит позволяет делать такую вещь как деградацию метрик То есть он очень классный чтобы именно хранить стратегические метрики за год за полгода Почему Потому что например вам нужно посмотреть како Каково было среднее время отдачи страницы полгода назад если хранить метрики по каждому запросу без какой-то предварительной агрегации как это делается в ки бане То просто не закончится ресу это не нуи Мет деть дею чем трика житте становится То есть если там это дни это до секунд месяцы это до десятков минут и года это может быть до часов дальше мы пошли в ки бану построили Точно такую же метрику подтвердили Ага есть пик что происходит Дальше Дальше Если бы у вас был греб Вы должны вы бы просто грепан есть такая интересная фишка как significant terms ви агрегации что он делает он берёт топ ошибок характерных Именно для этого выбранного промежутка времени то есть для вашего фильтра Как он это делает он их берёт по частотности и вычитает общий шум То есть он вычитает те метрики по каждому типу ошибок которые он получил на всём индексе То есть те ошибки которые постоянно идут допустим какая-нибудь там page not found Exception ещё что-то потому что куда-то долбится на ваш II неизвестно Кто он постоянно идёт То есть это естественный шум Конечно же он будет всегда в топе в выбранный промежуток времени но здесь есть отличный механизм это фильтровать то есть получить только топ топ три ошибки которые им характерны для выбранного промежутка времени после этого посто как мы убедились что Да что-то не то мы нашли какую-то ошибку которую мы хотим посмотреть дальше переходим на уже непосредственно ивенты события изло чтобы Поре Т ещё что-то Ну идём туда и мы опять видим 10.000 ошибок 10.000 ивентов с этой ошибкой Что же делать И у них разные сообщения разные начинаем смотреть их вручную просмотрели первую ошибку Ага Там встречается слово допустим H Мы хотим отфильтровать все такие ошибки с этим м без проблем Мы в фильтрах задаём мину нажимаем обновить через секунду у нас уже Нест идм второй смотрим второй ивент Ага он был создан с Хоста у которого там экспериментальные сборки стоят Мы хотим вообще отфильтровать все события от этого Хоста не вопрос отфильтровывает топсервис топ сервисов с какой-нибудь оттуда из выбо получа которы можем пройтись уже глазами посмотреть выявить причину и исправить её интересна такая ещё вещь дашборд мы её активно используем наравне с фано как она строится те агрегации которые вы делаете по вашим данным Вы можете сохранять и добавлять в один экран льем поде быстро перейти на конкретные события то есть мы видим всплеск среднего времени от дачи сообщения мы можем выделить временной промежуток быстро перейти на Discovery и посмотреть что же там было это ложная тревога или это реально что-то пошло не так есть интересная такая Метрика вот здесь 54 справа количество недовольных пользователей которые у нас являются одной из ключевой метрик это уникальное количество пользователей которые либо получила ошибку не просто ошибку определённый тип ошибки клиентское приложени не может обработать либо запрос которых ответ на HP запрос которых превысил Тай клиентского приложения 30 секунд в Киба это делается просто просто настраиваете фильтр настраиваете визуализацию в виде Циферки и выводите её что ещё делаем смотрим балансировку тоже очень помогает Когда ставим разные билды когда мы какую-то экспериментальную функциональность скажем Тестируем на каком-то маленьком количестве пользователей эксперимент над людьми немножко о том как и что логировать мы гиру Session ID для трекинга событий по нашим сервисам Ну просто если вы добавите Session ID Либо userid это будет недостаточно приведу пример допустим вы хотите посмотреть вы вы хотите такой ке в Киба что вы находите статью и смотрите А с каких других статей на эту статью перешли например Тестируем наш движок рекомендаций нормально он рекомендует статьи или ненормально Если вы просто сделаете article ID Session ID Казалось бы да сделать сортировку и всё Нет так не получится потому что группировок по факту у неё нету здесь нужно точнее здесь ну иовы Данные есть здесь не пров то есть то откуда вы перешли С какой страниц вы перешли соно Если вы сделаете просто S ID то здесь только простые агрегации могут быть то есть по вот все сессии количество статей уникальных Какие топ статьи были и так далее но таких сложных агрегации не получится сделать соответственно у есть альтернатива которую мы сейчас используем мы заменили ш на FL Почему мы проверили тесты поскольку мы чем хорош Хорош тем что он популярен у него есть различные адаптеры осно основной его кейс В чём он очень хорош Когда у вас есть готовый сервис вы просто его отдаёте кшу пишете там всяких всякие парсеки для него готовые например уже готовая для для дальше модифицируйте его ивент и отдаёте кладёте в ластик sech или куда угодно например в файл поскольку мы используем logstash чисто как механизм доставки то заме на f& мы ни в чём не потеряли а & сама обеспечивает при примерно таких же примерно таком же потреблении ресурсов в два раза больше поток событий а говорит что мы это тестировали в апреле возможно сейчас могло всё поменяться может быть кто-то потом дополнит вот так выглядит наш Н pipel В общем у нас есть Legacy на Доне монолитные проекты И микросервисы на докере чем крут докер тем что у него есть уже встроенный коннектор для FL То есть все наши микросервисы у них требование к логам примерно такое отдавайте в всё больше ничего не нужно никаких геров с библиотеками ничего обычный 10 строчек кода на питоне дальше доке уже добавляет и передаёт здесь него проко есть можно настроить у него есть отдача ВГ и там каких только нет протоколов отда и собственно Можно даже настроить мы используем потому что у нас сервисы которые на библиотеку и для здесь Пришлось сделать специальный с сконфигурировать его специальным образом чтобы она могла принимать именно по udp в опять же почему это сделали потому что у нас здесь есть такой здоровый монолитный сервис который генерирует очень-очень много ивентов и здесь мы вс-таки Урам в udp во-первых это локальные сборщики логов то есть туза который запускается и допустим слушать какой-то порт А дальше ваш сервис настроен таким образом что о делат мультикаст сообщений логов и эта штука ловит их локально отфильтровывает прямо на оставляют только те которые попали под фильтр и всё держит У вас локально Ну плюсы здесь какие конечно это подход довольно кустарный но иногда если е если не требуется городить какой-то Вот именно стек то есть какая-то раз Задача В принципе его можно использовать такой подход был популярен лет 8 наверно назад собственно то приложение которое вы справа видите это я его написал есть на на гитхабе исходники принципе написала для именно для этой цели потому что была распределённая система которой нужно было посмотреть логи в режиме реального времени вот чтобы они отдавались по сетке именно есть облачные сервисы по облов кае уних преимущества что платите деньги как бы ВС работает из недостатков вы платите деньги и оно иногда не работает Не работает и у вас случилась катастрофа то как бы ну у нас да ребята Извините плюс К тому что если вы будете из сго дата сервиса Дант свет будете платить то есть за трафик исходящий поэтому нас мнение такое что пала обработки логов должен быть в том же дата-центре что и ваша основная система сонно естественно всё это не бесплатно мы на основе своего опыта прикинули Примерно сколько стоит вот обрабатывать хранить обрабатывать логи такого порядка держа их скажем так на двух типов НОД это горячие и холодные горячие за трое суток мы держим холодный мы держим за 30 дней Ну включая горячий соответственно ВС поскольку у нас вся система аналитическая и поисковая основана на эче А эта штука масштабируется линейно то Циферки эти тоже будут масштабироваться линейно единственный такой нюанс что у него это вс-таки jav там крайне не рекомендуют отдавать ему хип больше 32 гигов потому что там отключается компрессия указателей и лучше держать 32 гига и давать ещё 32 гига ему экстра для кэша охи на этом всё спасибо Надеюсь у вас есть вопросы Добрый вечер спа вклад А сколько у вас НОД в elastic Surge кластере сейчас у нас сейчас э одна нода которая успешно обрабатывает около 10.000 сообщений в сутки мы планируем расти То есть у нас не вся система переключением около трёх Ну просто вот у меня кластер там 16 Note Вот И время от времени а возникает такая проблема что поменялся состав лого начинает приходить нечто Ну я ещё логи сами не контролирую формат у меня не и у меня эластик начинает непонятно чем заниматься вот умные люди говорят что он переиндексация вы добавили новое Поле в пинг и вы хотите чтобы по нему можно было искать Вам нужно будет переиндексация и в Ну ладно я Поня вопрос ещ второго плана артин вот у вас который после которого вы ходите в ки бану он на чём то есть вот вы Как вы ловите сам всплеск Да хороший вопрос мы используем Кроме того У нас есть некоторые скрипты которые подключаются напрямую берут метрики например вот э вот Метрика обно в возможность смотреть стратегические метрики То есть например полгода назад У нас среднее за час недовольных поез Сколько было Точно также у нас есть фактически скрипты которые из эластик делают агрегации кладут их в графити дальше Z настроен на артин Абик хранит айтемы эти все которые вот он Арт он их хранит в заксе Или он просто сам Арт динамически считает и забирает из карбона непосредственно не знаете он он он он именно хранит в зак то есть мы мы это денормализация такой вопрос а на схеме Видел у вас из дот нета вы отправляете посредством протокола udp логи да-да да да А Вы не боитесь там потерять что-нибудь например какой-нибудь биллинг когда логи или вот у вас отличный вопрос те логи которые мы отправляем по udp мы не боимся потерять это мы делаем только для одного ровно одного сервиса потому что он генерирует очень много данных и ну в дальнейшем мы планируем его распилить на более мелкие сервисы они уже будут отправлять по tcp Здравствуйте вопрос как раз касательно этой схемы вы говорили что ещё сохраняется у вас логи файлы есть и всё это ещ уходит в графит вот непосредственно здесь это где то есть это через потом идёт или это дальше из elch как-то попадает Да всё верно Это FL FL настроен на то что он пишет в sech и локально локально на диск уже сразу зипу их то есть они сразу сжимаются и фактически с помощью заката гре их Можно например точнее просто заката обратно переместить без проблем если нужно так чит чит Докера точно тоже самое таже самая схема идт настроен таким образом и п е сохраняет локально на жёсткий диск то есть фай с чтото поднять есть у консольные для рабо докумен Поэтому будет примерно так и всё Оно просто обратно заль Здравствуйте спасибо за доклад У меня тоже два вопроса У нас тоже одна но на ней же 800 шарт всего из них 400 успешных Что обозначает концепции эластика понятие шарт если это один сервер шар - это кусок То есть это кусок Независимый индекса который может перемещать Независимо А по какому принципу он и делит почему вот индекс документов 800 шар я понял Хороший вопрос по умолчанию если выдать индекс влак он ставит ему количество шардов п и степень репликации 2 То есть он реплицируемый едини масштабирования примерно так есть если вы хотите сделать систему для максимально быстрого для максимально быстрой записи максимально быстрого чтения у вас нода вы делаете соте индекс количество шар и репликации Но тогда это будет быстрее всего примерно так я понял Спасибо И второй вопрос Какое железо у ва и ско документов то индексов оно обрабатывает доча деи СРО начала откровенны тормозов грубо говоря до жёлтого Стасовой ластики Ну вот собственно те цифры которые я показал это вот примерно для очень комфортной работы а у нас у нас количество ивентов около 10 млн в сутки сейчас но оно будет расти в ближайшее время на порядки соответственно мы ориентируемся на вот эти вот цифры если вот конкретно сейчас то у нас оно вообще стоит в виртуалке на дохлых дисках и 10 млн ворочает и нормально в сутки Вопрос такой Здесь три вы используете како Почему вы вместо в ке ек стали использовать FL а не который в стандарте теперь уже позволяет пихать просто была такая Такой же вопрос Мы задавали себе когда переходили и в принципе если ВС у нас весь идт в J тогда он в принципе не нужен сам умеет в эластик запихивать данные во-первых Хороший вопрос во-первых У нас всё-таки есть некоторая маленькая предобработка то есть мы например вытаскиваем то есть мы хитрым образом создаём вычисляем имя индекса по гу который нам Отт доке домы указываем указываем адрес самого нди и указываем тег по которому который фактически вставляется сейчас скажу вот вот это тег тег в докере Ну влоги там есть условия там тоже можно в принципе это настроить значит посмотрим обязательно про Ну это недавно появилось вот второй вопрос - Это как в какой момент вы понимаете что пора масштабироваться сколько вы терпите там ну то есть можно дождаться тайм-аутов кибанов ских там 30 секунд что стоит у неё запрос А вообще скажем так если сколько вот есть ресурсов столько лучше и выделить потому что каждой вот это вот каждое зависание каждое неудобство оно в тической ситуации может чего-то стоить Поэтому если у Вас например изменение больше там нескольких секунд То есть идёт время ответа больше нескольких секунд отча пора масштабироваться Да масштабироваться можно несколькими путями Можно либо добавлять мощность то есть новые узлы там диски более быстрые а можно более тщательно логировать то есть что-то Может быть не логировать да то есть то то то просто вот решили всё запихнуть вот эта штука какая-нибудь маленькая она нам всё убивает поэтому можно оптимизировать сам Лог можно что ещё делать это сделать шаблон под какой-то сервис например там есть такая фишка интересная как шаблоны по полям Например если у вас поле содержит текст то что нужно делать нужно его тонизировать и не хранить исходник например вот так да И последнее - это храните ли вы логи файлом И как долго то есть ну есть ли у вас политика сохранения логов на длительный период времени Да есть хранимы их сколько у нас позволяет мест на самом деле по подло это пару месяцев Вот именно в файлах потому что они хорошо в принципе сжимают Спасибо за доклад в первую очередь второе меня вопрос решали ли вы проблему сетевой связанности или недоступности вот в вашем случае то есть Ну получается Вопрос гарантии доставки логов Хороший вопрос кстати недоступен и контейнер пытается запуститься а у него написан прописан как основной драйвер то отказывается запускать контейнер Вот с таким сталкивались А так что отваливается из-за сетки нет такого такого ни разу не было Работает как часы вопрос дальше в те всех этапах палана обработки логов сохраняется персистентность и опять то что мы не потеряем логи и что всё будет работать обеспечивается дором файлами как-то То есть если какой-то часть этого палай начнёт либо тормозить очень сильно либо просто свалится мы потеряем или как вы это решаете Хороший вопрос В данном случае ЕС используем теряет события Поэтому если у вас вообще супер супер критично если у вас фактически Это не просто Лог файлы это у вас например журнал биллинга тогда конечно же лучше дублировать его То есть это фактически у вас не логирование это у Вас бизнес сущность по которой вы потом что-то делаете А на практики такого не было мы мониторим & есть плагин по мониторингу очередей & то есть самое плохое что может случиться эта штука не не будет успевать отправлять логи в elastic Search по какой-то причине они будут накапливаться она упадёт по памяти например Ну она в принципе выдерживает и поскольку она простая вас это устраивает то что вы что-то там теряете у нас пока ещё ничего Не терялось ну а если будет если бы то тогда был бы Арт что подскочила очередь вот здесь и собственно админы бы разбирались с этим нет А если вот прям свалится вам это не критично нет нет конкретно здесь критично Спасибо Добрый вечер У меня вопрос такой я смотрю вы используете не совсем стандартную связку Исходя из этого вопрос Следующий А на каком этапе вы обрабатывает мультилайн сообщения по Если вы их обрабатывала мы не обрабатываем мы уже из наших приложений структурно отдаём фактически готовы события в виде джисона структура там нет такого понятия как Да с этим связана такая большая история что у нас есть Монолит здоровый на Доне и чтобы в него сделать структурный логи Это не просто как Многие думают там КНУ пальцем ан сделал для Log и всё заработало Нет это реально работа поскольку нам нужно сначала юзкейс составлять например по нашему мы составляли сначала кейсы что мы хотим увидеть вне например Время обработки есть которые привели к таймауту на клиенте прямо посмотреть их раз типы ошибок какие у нас два идентификаторы пользователей Посмотреть например топ пользователе по количеству по количеству запросов три То есть изначально мы составляли кейс и потом уже внедряли структурный Лог внутри нашего приложения Добрый день Скажите пожалуйста а вот кно там внес какие-то изменения модифицировать и например Хаус там поставить вместо эластика или там фану поставить вместо Киба Что вы на это скажете то есть насколько это перспективно поставить что графа Да ну вместо Киба графа кибана это немножко разные вещи у графана есть конектор Да действительно они В новых версиях сделали плагин она может по напрямую вот эти вот визирова как в дашборде только в фане но здесь опять же здесь Фишка в том что мы можем быстро перейти от метрики К событиям которые привели к её к формированию то есть подскочил дев пя перцентиль выделили посмотрели там допустим десяток каких-то запросов которые были которые проблемные их уже сразу можно разобрать прямо здесь Но графа мы используем для интеграции с графитом именно для стратегических метрик ха мы сейчас его рассматриваем для как раз ивент Лога То есть у нас есть проект Где идёт огромное количество м событий от пользователей и мы рассмотрим сейчас clastic Search Versus Click House Вот как раз вот сейчас этим вот занимаемся поскольку кликхаус Он только недавно вышел пока пока ещё не знаю вот может быть через неделю две не узнаю ребята сейчас как раз вот в это в это самое время всем этим занимаются Да Добрый вечер хотел немного дополнить вот на тему и всего такого там ещ в последнем эке который пятой версии там есть который на который маленький гораздо легче чем Он поддерживает уже нативное разворачивание если приложение пишет можно ему сказать бери все поля и отправляй тоже это получается довольно удобно и конт дост например вот если по сети он доступен любой может прийти и дропнуть все индексы вот с этим ничего не пытаетесь делать Хороший вопрос мы используем мы его развернули в докере и используем Over Network фактически для его доступа то есть Извне недоступен доступен только через щеп компания у нас небольшая То есть это не какая-нибудь там какой-нибудь банк где 1000 человек работает нет это 30 человек и Если кто-то захочет сделать диверсию есть 101 способ сделать это лучше чем просто логи уничтожить Спасибо Здравствуйте спасибо за доклад такой вопрос возник Вот про FL он принимает Ало уже сезонные в или нет Вся фишка что тут не нужно ничего крутить Под каждый сервис по идее его можно сконфигурировать так что у вас есть ин с голы просто вот который пишет файлы ноль конфигурации вы берёте сначала говорите что вот FL может брать его логи оттуда то потом вот у него там формат специальный уже готовый есть плагин для нса который фактически Вот это это вот стрёмное строки там регулярка разбирает уже в структурный лого и дальше он уже сохраняет sech для кстати для инса мы сделали довольно просто делается поменяли формат чтобы на давал Jon и всё то есть я понимаю То есть если у нас сервис который не отдаёт сейчас в Jon то это значит что нам его надо переписать для использования & сервис не переписать рекомендуется очень переписать его как он логит то есть чтобы он структурно Гил чтобы не просто конкатенировать строку там Бог пойми что то есть человека читаемого в машина читаемого то есть в набор структурных ивентов да да это есть такое Иначе просто все бенефиты к стека Ну не получат То есть у вас будет просто обычный полнотекстовый поиск Ну и что собственно с ним делать А если допустим Ну вот банально Warlock Messages То есть это как Как мне туда засунуть Ну там там в принципе точно можно выделить время да у вот хотя бы время будет и сообщение ну всё что вы сможете сделать То есть вы получите удобный полнотекстовый поиск но вы не сможете сделать агрегации например понял спасибо снова я сразу отвечу просто вопрос про если использовать стандартный то он сам ВС правильно разобьёт зант как надо по все Поля с тегами с ID приложениями спидами Ну всё будет правильно вопрос У меня Илье сно ми чно балансе Да да совершенно верно формируется на первичном балансе То есть у нас фактически если представить вот систему это набор микросервисов И вот это гей то есть то кто то есть у нас есть приложение АО совское оно обращается Извне к этому гей дальше ге обращается к внутренним сервисам Да он создаёт вот этот вот айдини для трекинга он его же пишет Лог и дальше он каждое приложение обязано его записать Спасибо Здра В общем ещё один вопрос про альтернативы рассматривали ли вы по-моему очень похоже на то что вы сделали на Ну плю эластик Плюс То есть это всё в одном скажем Нет мы не рассматривали У меня просто очень большой опыт рабо зна что спосо его плюс и мину и года для логов для аналитики масштабируемых системах и как бы ещ ни разу не подвёл Спасибо Сергей спасибо можно маленький вопрос Какой запас надёжности кластера вы держите То есть например логи вещь такая то есть например дежурная смена ночью поднимает бак и у вас логи соответственно вырастают в разы они его забывают выключать вы это ВС забираете себе соответственно Как долго эластик с этим может жить Хороший вопрос как долго может жить elastic но самое как бы вот новых версиях elastic sech его скажем упороть количеством данных ну почти невозможно раньше вот в старых версиях у него были такие фишки как Field Data которые очень хорошо заполняла весь Java Hip и но уходила просто в Out of memory Exception зависание сейчас они это исправили в DOC values то есть отключается F Data по умолчанию есть Doc vales Doc фактически это Memory структуры то есть в самом плохом случае у вас просто нач тайм-ауты на ваши ри Спасибо Это был последний вопрос Спасибо"
}