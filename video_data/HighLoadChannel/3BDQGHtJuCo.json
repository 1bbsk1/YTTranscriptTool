{
  "video_id": "3BDQGHtJuCo",
  "channel": "HighLoadChannel",
  "title": "Как сэкономить на масштабировании, переехав с Cassandra на Scylla DB / Михаил Малышкин (OneFactor)",
  "views": 1206,
  "duration": 2125,
  "published": "2023-04-28T06:10:46-07:00",
  "text": "Привет Сегодня будет доклад Как сэкономить переехав уйти уйдя с одной женщины к другой от одной женщины другой немножко про мифы древнего собственно про древние мифы и Греции мы знаем что сцил это был такая женщина которая при пророчила падение трое а Кассандра Ой это такой чудовище которое выглядит приблизительно так сверху Она прекрасно снизу у неё собачьи головы и собственно когда Одиссей проплывал мимо ее Мыса он потерял шесть своих моряков когда мы решили переезжать с Кассандра на силу собственно Мы тоже думали что у нас будут какие-то проблемы и мы боялись как раз нижней части этой женщины а немножко о компании почему вообще используем кассандру последующем силу у нас рекомендательный сервис который делает рекомендации для банков страховых то есть Это производится коры и собственно Нам необходимо быстро ответ для того чтобы когда приходит заемщик мы быстро могли его отскорить и дать для банков такой как это хороший заемщик или плохой все наши клиенты это порядка всех банков которые ходят в Десятку крупнейших в России и собственно 2019 году Мы вошли в гартер Call wenderlist что у нас за сервис собственно у нас нагрузка приблизительно 1000 rps но на текущий момент слать немножко устарела у нас нагрузка сейчас буквально в последние две недели поднялась почти в два раза а у нас есть требования что мы отвечаем на запросы нашими с Коране меньше чем за одну секунду и Нам необходимо в кассандром и собственно по следующему силу ежедневно загружать 800 ГБ данных нагрузка на базу 50 до 100 тысяч РПС но текущий момент опять же выросла и достаточно сильно и нас требования есть время ответа баз данных менее чем 100 миллисекунд каждый запрос мы использовали кассандру все было хорошо но нас что не устроило Вот на этом сайте вы можете посмотреть это всплески латенси причем они были достаточно неожиданно для нас мы сделали достаточно хорошее исследование и оказалось так как Кассандра написано на яве это срабатывал коллектор у нас это не устроило потому что мы пробивали время ответа от Базы больше чем секунду иногда это у нас очень сильно расстраивало далее так называемые фантомные данные что они из себя представляли так как у нас идет ежедневная загрузка 800 гигабайт и в определенный момент у нас случались авария на кластере потому что бывает такое что надо например вылетела мы заводим обратно делаем или делаем комиссию потом делаем комиссию ноды и мы видим что у нас еще появились какие-то непонятные таблицы откуда они взялись был не очень понятно мы делали расследование так как у нас Фактор репликации 3 то видно с каких-то нот эти данные подтягивались и собственно появлялись нас это никак не аффектило потому что у нас достаточно грамотная организация баз данных у нас грамотно называется таблицы в имени таблицы используется Хеш и собственно при переключении на новой таблице никакого эффекта не происходило то есть мы переключались на таблице новым хэшем и все у нас работало но у нас очень беспокоило что есть эти фантомные данные загрузка данных была более 12 часов что у нас очень сильно не устраивало потому что мы начинаем загрузку ночью и нам хотелось чтобы начало операционного дня в банках у нас все данные горячие были уже в базе но мы в этот в это время не укладывались и у нас это тоже очень сильно расстраивало ну и плюс дорогой масштабирование на тот момент у нас был уже 12 нот в кластере и собственно вкидывание туда новые ноды не давала нам такого прироста производительность которая бы нам хотелось поэтому мы в определенный момент решили собственно перейти на силу потому что нам это на тот момент казалось кликвином то есть мы берем и за два спринта грубо говоря делаем всякие там тестирование разворачивание инфраструктуры все подряд и за 20 процентов что мы сделали Мы создали просто банальный кластер из трех нот сделали факторы аппликации 3 собственно по одной реплике на каждую базу на каждую ночь далее при помощи Мерс сети в клубе если говорить конкретно то истину сделать зеркалирование всех запросов которые пойдут в кассандру они также шли в силу для того чтобы оценить как-то скорости выполнения этих запросов и скорость ответа и собственно мы настроили мониторинг естественно мониторинг на один даже порт мы увидели как Кассандра так и силу и собственно если вот посмотреть на этот график то видно то что время ответа у силы почти в два раза меньше и графики по 999 более ровный без всплесков какие проблемы у нас возникли целом не поддерживает если кто не знает составила это подготовленные участки памяти в котором наиболее оптимизирована оптимизирована находится в строке до такого степени что можно например этот SSD был прямо сразу загружать в память Проблема в чем мы когда-то делали загрузку в кассандру мы готовили сами со стрельбой при помощи с парка мы готовили ssdble готовый и прям сразу его закидывали в кассандру в цели же разработчики сказали что это уязвимость и они это поддерживать не будут поэтому мы начали загружать данные через стандартный драйвер Кассандры прям база данных ну собственно в целом есть коннектор но интернет конвертер так называемый который как бы вроде как может загружать напрямую но он делает все то же самое он через стандартный драйвер просто гоняет масло далее у нас была проблема с выбором правильной компактных данных есть кто не знает то компактных данных это уплотнение данных для оптимального хранения как в памяти так и на диске ссылку поддерживает порядка если точно сказать порядка 7 разных компактных данных в том числе вообще без компакции мы попробовали практически все кроме той компакции данных которые была в интернете мы используем Вот и остановились собственно стратегии это маленький sesteblade фиксированный размер который режется на каждом уровне мы пробовали также вообще бесконтактных данных Но кому если мы использовали без компактных данных ссылок то собственно у нас были проблемы с взрывным ростом кормитлона причем мы указывали ограничение но на тот момент в той версии которую мы пробовали до такой степени что занимал всем места на диске и приводил к аварийным состоянии пластика или одно из нот собственно И после этого следующее у нас проблема была прекрасно потому что но ссыло такой есть то есть У нее есть шарнирование которое на каждые каждый шаг занимает какой-то определенный трек и оказалось так что у нас некоторые ключи достаточно большое количество попадал в один шарт что привело к тому что у нас был перегруз по какому-то трейду все начинал медленно работать очень медленно отвечать по этим ключам и мы уже думали может нам вообще отказаться от этого варианта Ну в итоге пришли к выводу что нам просто нужно сделать более грамотное распределение ключей на уровне нашего приложения у нас все стало просто замечательно То есть можно посмотреть там ключ клиент Один он получает вэлью из собственного шара И так далее и Последний пункт это достаточно такой смешной а так это дело было понятно На тестовом стенде у нас инженер забыл прописать обратный маршрут к нашему сервису через три ВПЛ и собственно мы долго это искали потому что вроде смотрим трейс идет правильно почему-то у нас начались задержки какие-то на сети вообще что-то странное происходит но потом разобрались что у нас оказывается перекос сетевых маршрутах В общем разобрались с этим и все стало прекрасно Какие тест кейсы мы собственно проводили для того чтобы понять подходит нам ссылочка или нет первое восстановление данных собственно мы выводим аварийно одной из нот и смотрим после того как мы ее обратно подключаем мы смотрим как у нас данные все сходятся или нет У нас есть у нас был шаблон собственно и шаблон виде Кассандры могли сравнить такие данные автосандре Какие данные в цели и собственно при аварийной выводе ноды у нас все сходилось все было прекрасно второе это потеря данных приставьте кластера кассандре мы столкнулись с таким что у нас в один момент когда стойка грубо говоря Со всеми нашими нодами и некоторые данные которые были в памяти не были скинуты еще на диск они потерялись также мы сделали со сциллой очень хорошо все данные которые были в момент памяти они все потом мы их обнаружили в базе данных то есть с этим проблем тоже никаких не возникло дальше у нас был интересный кейс это деградация скорости диска собственно при помощи утилита стресса стресса Мы пытались загрузить диск настолько насколько это возможно при помощи этой утилиты если посмотреть на графике то мы там уперлись три с половиной гигабайтов секунду а дальше у нас начался потому что утилита начала и собственно дальше Мы решили тест не проводить Вот на этом графике можно посмотреть собственно где первый пик это когда мы включили нагрузку на диск если посмотреть то скорость ответа выросла порядка в два раза но не пробил Там те же 60 миллисекунд который мы хотели от баса и собственно делали еще тестирование выпадение одной ноты это надо было изолирована и мы смотрели как себя поведет власти опять же есть на Стрелке посмотреть на эти графики где красные стрелки то видно то что у нас есть опеки но в общем как бы если опять посмотреть на 999 то там Практически незаметно ничего и вот вывод вот на горячую то есть было интересно как себя база данных пойдет если мы выводим но сидел стандартный комиссию ноды и посмотреть на латенсе то есть так как факторы аппликации 3 в этот момент мы уже поставили 4 ноду для интереса и собственно Нам было интересно как какая задержка будет что будет происходить на графике также видно то что это надо остальные ноты начали очень активно обращаться друг друга обменяться данными чтобы восстановить факторы с этим тоже все хорошо было и в итоге что у нас получилось Мы Первое это избавились от фантомов То есть у нас сейчас база чистая никаких странных данных не является очень сильно Прости инфраструктуру На текущий момент у нас пять нот Но вот в последние две недели мы завели еще две ноты причем завод дополнительных кнопки у нас занял всего два дня то есть это вообще лайтовом режиме особо не напрягаясь У нас написано playbooki nclow который подготавливает сначала перцовку а потом собственно завозят туда асциллу и вводит ее в кластер кассандр нас было 12 нот сейчас у нас 7 мы посмотрели 7 много сейчас будем откатываться обратно на 5 в итоге нас сейчас будет 55 нот удешевили масштабирование как я говорил ранее это мы пять нот и 12 ноток немножко разные числа и 12 нот обслуживать гораздо сложнее ускорили загрузку был 12 часов сейчас 78 плюс у нас очень сильно выросла нагрузка очень сильно выросла загрузка количество данных и избавились от пиков сейчас достаточно ровные графики и мы очень радуемся этому что в итоге смотрите если смотреть на таблицу то видно если взять например Кассандра за X то сил нам обходится в текущий момент полтора раза дешевле причем палатессе мы на 40 процентов грубо говоря имеем преимущество то есть было 100 сейчас ну и время загрузки данных у нас уменьшилась 11 12 часов до 7-8 часов собственно Мы очень рады такому приросту Спасибо за внимание А если вы хотите еще сэкономить немножко денег то в 17:00 Лера вам расскажет как впихнуть не впихиваемая в парк и в ходу аплодисменты а сейчас мы будем обсуждать как впихнуть невпихуемое и за лучший вопрос У нас есть памятный сувенир от нашего партнера Garage прошу у тебя будет сложная задача выбрать и запомнить лучший вопрос Это тяжелее Спасибо за доклад хотел уточнить ты говорил что вот Кассандры были сложности там с Горбач коллектором стратегии решили переехать на сциллу можешь рассказать рассматривали еще какие-то варианты оптимизации Кассандры перед переездом мы делали исследование по кассандре но на текущий момент нам показал что мы берем так как они совместимы по протоколу то есть мы берем просто туда и как бы нам не хотелось тратить время на именно глубокое Погружение в кассандру как я говорил в самом начале это мы думали то что за 20 принта все заедем но в итоге это растянулась не на два спринта немножко подольше потому что там вот возникали проблемы со стейблами с надо было проверить кучу стратегий компакций и нужно было доработать наш продукт чтобы у нас было нормальное распределение по ключам Я правильно понял что вы кассандру остановили и на те же данные запустили ссылку у нас как я говорил был Mirroring мы просто отключили в кассандру и основной поток пошел на сцену все То есть у нас был вообще бесшовным мы это сделали за один день с помощью переехали как раз и можно сказать какие версии использовались целый Кассандры ой 4 часа самая последняя релиз насколько давно сцена вообще в эксплуатации есть какие-то проблемы с мониторингом вообще есть проблема достаточно смешные с мониторингом Проблема в том что ссылает порядка 150 тысяч метрик каждый сервер соответственно 5 серверов почти миллион получается 750 тысяч и прометел не очень себя чувствует когда отдается такое количество метров причём для наших разработчиков все эти метрыки нужны Мы пытались как-то там отфильтровать кое-что отфильтровали так было бы 170.000 но в итоге остановились на 150 и не знаем что делать с этим То есть под неё нужно отдельно прометеос там ставить и отдельно его мониторить а по проблемам могу сказать проблемы Но они опять же зависит наверное мониторинге проблема Первая это естественно смотрите за цикл Потому что ссылая если не ограничить тепло оно сожрет все у вас будет цпу операционка и все-все второе это естественно смотрим за памятью забирать всю память и начинается он Киллер То есть он начинает грохать все подряд нас был такой что у нас Я не мог найти поясаж потому что он Киллер грохло и Саша демон Ну и третья проблема Это не смотрели за диском отвалился алертинг не смотрели за диском хорошо Это было на этапе тестирования у нас диск на одной ноге сожрал силы собрала весь диск и много ушла в аварийное состояние Вот это основные правила проблемы которые мы видели с которыми встречались так проблему выпада ноды с дикомиссии комиссии ноды вообще никаких проблем нету Просто Спасибо можешь еще немножечко рассказать про сайдинг узлов что были целые что подкасом были под Кассандры сейчас целая используются физически это серверы железные сервера Почему как выбирали вообще сейчас я точно не скажу это Silver такой какой точно не помню 128 ГБ памяти nvme диски 2 собственного Страйке по 36 терабайт а камней в нем 1 2 4 сколько в нем физических процессоров было два физических процессора и того 48 тредов и у нас выделено Следующий вопрос пожалуйста это ее фича дичь железно туда забита или можно отключить потому что как бы мне на всю настройку чтобы это как-то можно железку отключить можно выделить определенные треды как бы самой силе а сил уже сама внутри трейдах распределение делает А тогда вопрос и как бы все таки свой про тишине что ли по ключам писали или как Как вы добивались более благоприятного распределения честно говоря не могу ответить на этот вопрос этот этим занимались разработчики и они подготавливают эти ключи может быть у вас просто ключи были да там изначально Да скорее всего так оно и было но потом это посмотрели просто на кассандре это не ответил потому что забирает весь CPU и как бы такого понять Как именно шагирование по трейдам такого не было а в цели оно вылезло Когда у нас был по ключам по одним который попадает шарт собственно мы сразу получили проблему Ладно спасибо примерно Понятно много ядер и хороших функция при такой архитектуре другие способы но трудно придумать Можно я наверное даже в продолжение от предыдущего вопроса Большое спасибо за интересное исследование исследователи Enterprise версия ссылок потому что там обещают какой-то магический ришардинг который типа Серебряной пули его должен как-то решить вот этот вопрос неравномерный загрузкой нет сожалению мы не пробовали потому что у нас на тот момент не было бюджета под это это было такой поп который в текущий момент тяжело вообще попробовать они не дают именно посмотреть вообще решила бы это теоретические проблемы или не решила тем что ключи неравномерно распределились и листинг там уходит миллион шардов честно говоря не могу сказать не смотрели То есть если они дают например на тест еще можно этим заняться нас инфраструктура готова к этому железо бюджет под железо и все Спасибо Back and справа вопрос как черезвести дублировали трафик на чтение я правильно понимаю что он дублировался Нет он не эмулировался это был зеркалирование А вот зеркалирование это запросов на чтения Да а что это такое можно рассказать как-то технически честно говоря не очень понимаю вопроса смотрите у нас запросы просто При помощи мировинга который есть в истео из коробки он имеет мерить степени запросы То есть это роутера степишный что еще раз дублирует я не могу честно говоря подсказать точную уже не припомню как мы это делаем хорошо технический вопрос всегда можно обсудить В кулуарах открыть ноутбучки связаться с командой и посмотреть Back and по центру Спасибо за доклад хотел спросить вот у вас Кассандра падала рассказывали отщелкивались и понятно что вы могли что-то потерять и проводили ли вы проводили какой и проводители сейчас на стиле и как он себя ведет нет ли проблем как кассандре ментально по крайней мере Честно говоря у нас были такие кейсы но проблема не заметили может быть мы неправильно что-то делали Просто но в целом очень довольны сейчас на текущий момент и вообще в сторону Кассандра например даже не смотрим то есть нас настолько стабильно Все работает Что у нас Вторая линия даже иногда забывать смотреть графики только в случае выпада например ноды только на это реагирует получается вы сейчас как-то производите производители плеер на сцене Ну то есть он какой-то недельный месячный или вообще на него забили и ничего не делает честно стабильно работает Мы даже не дергаемся я понял хорошо Еще последний вопрос такой вот вы говорили про кассандру про во время ответа и простыл количество со столиц которые настраивается на таблицу при создании у вас был одинаковое есть кассандрой И вы ничего не меняли на дисках там не меняли это Хеды утверждающее чтение ничего и получили такой производительность именно так хорошо спасибо коллеги Следующий вопрос прошу Middle Wave в середине Григорий StarLine Спасибо за доклад очень интересно мы Тоже планируем переехать на сцену вот мы начали тестировать ее нагрузочно вот и пришли к выводу что она не слишком стабильна По высокой нагрузке на продолжительное время Ну То бишь у нас происходила такая ситуация что минут через 40 где-то вот 50 тысяч транзакций до секунду и начинал валиться узел прокси Вот Мы создали вот еще несколько человек тоже добавились такой же проблемы Вот отметились но разработчики таким образом не прореагировали на эту ситуацию встречалась ли вас такая проблема вот Может быть вы можете что-то подсказать Там смотрите у нас основная нагрузка идет во время все данных То есть если у нас идет вот этот ночная загрузка данных 800 гигабайт там почти терабайт сейчас собственно одновременно идет компактный заливается идет компактный плюс идут еще запросы Но вот мы да заметили повышение латенте Но вот именно таких проблем Как у вас У нас не возникало Может быть у нас немножко другой профиль данных хорошо спасибо хорошо фронтенд по центру Добрый день подскажите у нас кейс такой есть Кассандра есть 10 лет архивов есть тоже желание переезжать на сцену намерение Пока даже до пенсии не дошли Вопрос вот эти 10 лет архивов мы как-то сможем безболезненно вообще без проблем есть как я говорил есть коннектор который просто состоит был из Кассандры прям перейдет вам в силу а может и хотя бы подробно вам немножко ещё так рассказать о сценариях и профилях данных Как вы её используете Если я правильно понимаю вы загружаете большую пачку данных в начале потом у нас есть холодное хранилище которое находится на ходу размещено А собственно горячие данные у нас находится в сцене и ежедневно после там обучения Модели там подготовки данных э-э из Холодного хранилища переводится данные в горячий Вот и собственно мы стоило использовать как горячие хранилище данных фронтен справа Спасибо большое Очень интересно маленькие комментарии и один вопрос Мы тоже вот в компанию все используем lsm базы данных встраиваемые Ну Рокс db например и там точно такие же проблемы с компактизацией Да и мы точно так же как вы используем маленькие файлы и чем больше маленьких файлов тем больше дискрипторов вынуждены открывать программа и тем больше затраты на оперативной памяти поэтому я могу предположить что возможно вот эти утечки памяти Да ну или высокое потребление памяти оно связано с большим количеством дескрипторов а вопрос такой вот вы сказали что если отключить стойку с кассандрой то все данные теряются которые нет не так немножко не все Не все данные теряются те которые находились в оперативной памяти правильно но если запустить силу тоже без режима синхронной записи без Осинка то тогда эти данные в памяти не теряются Мы у нас по сравнению с кассандрой когда мы делали собственно нас два эталона но смысле это он был в кассандре у нас проблем таких не было То есть это мы там была асинхронно единственное я скажу При таком косан ой Достаточно долго поднимается то есть она видна поднимает эти данные в оперативной памяти это время порядка 15 минут Ну понятно просто интересно везение это или что-то в ней заложено особое по сравнению не могу сказать К сожалению"
}