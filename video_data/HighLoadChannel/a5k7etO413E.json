{
  "video_id": "a5k7etO413E",
  "channel": "HighLoadChannel",
  "title": "Нельзя просто так взять и скопировать / Александр Токарев (DataArt)",
  "views": 3372,
  "duration": 2365,
  "published": "2019-07-18T07:49:23-07:00",
  "text": "собственно всем привет ещё раз представлюсь меня зовут александр мы сначала планировали говорить об оптимизации моделей данных моделей хромирования для область для облаков но в процессе подготовки я понял что на одних моделях данных далеко не уехать и возможны к счастью и к сожалению мы еще поговорим об особенностях самих главных баз данных я работаю в компании dataart где являюсь перформанс архитектором соответственно я участвую на всех этапах жизненного цикла разработки приложений начинает solution дизайна заканчивание performance тюнингом ну и занимаюсь этими исследования в целом я с мира энтерпрайзе ну сейчас все больше приходится заниматься клубными базами данных такие как redshift афина бык вере и snowflake прежде чем я расскажу вам небольшую сказку я хотел бы задать вопрос кто нибудь из вас использует клубные хранилища отлично что redshift big вере redshift но отлично будет о чем поговорить итак представьте жили-были боярин был у них свой замечательный бизнес и было у них маленько рак новый базу данных где-то 70 таро байт ну соответственно она не очень нервничали что ее владельцы продолжали богатеть поэтому они пошли консультантом и те предложили перевезти их хранилища в облака была поставлена базам а доллар унд shift и в течение какого времени базе становилось всё грустнее и грустнее соответственно все проблемы с производительностью решались просто подкидывание по очередь новых и новых нот ну соответственно компании пришла к точно такой ситуации что было и 40 лама они обратились к нам мы провели аудит системы и пришли к выводу что хранилище находилась не совсем в идеальном состоянии конечно же мы тоже консультанты можно было бы предложить им очередное новое какой кладно и очень быстро и хранилище но мы решили все-таки разобраться в чем же проблема проблема вскрылась очень быстро оказывается хранилищем пришло немало к через просто мастер миграция это привело к хаотичным выбору алгоритм в компрессии полностью oтцa механизма управления очередями структура данных была перемещена как есть ну и никаких конфликтов не осталось все это соответственно привело к тому что любые проблемы решались добавлением железо чем мы поговорим мы говорим о том что есть в облаках с точки зрения хранилищем о модели данных нашего клиента и как мы и переделали посмотрим что из этого получилось и я расскажу такие некие странные подходы к оптимизации хранилища с удовольствием отвечу на ваши вопросы и так что предлагает клауд неограниченную масштабируемость надежность отсутствие затрат времени и денег на инфраструктуру упрощенный тюнинг ну и в основном все крупные провайдеры камин дует это делать через 2 в лени железо потому что постулируется что не надо понимать как работает не база данных не как работает слой хранение а за счет этого все у нас очень дешево я бы немного поспорил с последними четырьмя пунктами но эти и бизнес итак кто у нас основные игроки на рынке клауд это amazon это snowflake эту google и в принципе сотни других компаний дверь я уверен что яндекс тоже думает что он имеет свое роль на этом рынке и так хранилище отличаются по типу процессинга и потому как они управляются клубными провайдерами процессе может делать целиком на одной ноги а может быть разделение уровнях ранений уровне вычисления хранилище могут быть полностью сервере с такие как big вере и афина а могут быть довольно детальной настройки такие как рыб shift и snowflake как можно сделать самому клоуны хранилище дома взять какой-нибудь принц устное решение типа просто получить amazon и афина можно сделать спорт фон гесса тогда мы получим и redshift можно попытаться написать все с нуля тогда у нас будет пиквери или snowflake модель ценообразование зависит от множества факторов от и затрат на вычисления от хранения она может и мирятся от того сколько данных у нас просканировано ну и соответственно перемешивается так например в дик вере в единице и цены является кластером не буквари просите врачу в те там есть и компьютере старший processing его старшим братьям рот шифти нам приходится платить и за кластер и за сканирование и за сторож и соответственно в афине мы платим за сканирование информации и за сторож google big вере ну собственно все тоже сканирование хранение но есть небольшой нюанс это уникальная главная фишка гугла он разделяет активные и пассивные хранения если данные в таблице не менялись в течение 90 дней то цена и хранение под два раза это принципе очень классно очень удобно ну и собственно snowflakes тут максимально четкое разделение между компьютеры процессингом отдельно платим за вычислитель наносится отдельно за сторож ну все знают разницу между колоночный мы построчном хранением в в одном и храним строки в другом мы храним колонки это дает нам некие преимущества по аналитике поддержки к лодочного хранения концу разными форматами такие как паркет и арк ну и соответственно хорошие компрессия в этих форматах хорошей компрессии значит можно сэкономить денег меньше заплатить провайдеру достатке тоже понятны необходимость сложных стратегий обновления и возникают нюансы с многопользовательской работой какие форматы колоночный используют клубный басс дар улыбчив ты свой формат убить клэри тоже свой раньше он назывался кому сейчас называется копать 100 выручку спектре мы можем использовать парке торг аналогично в афине как я уже говорил на некоторые вещи которые привели к провалу проекты с хранилищем влиять мы никак не можем потому что люди попали в ловушку клауда есть у нас слишком сильно нормализованная модели у нас много join of мы платим за вычислительной мощности если мы не используем уникальные фишки базы данных по у нас происходит регистре бьют данных между нодами мы все больше платим за вычислительной мощности сделали слишком ненормализованную модель уходит много места платим за хранение много платим за хранение платим за сканирование платить за сканирование и пьют нагрузка за вычислений аналогично по компрессии неправильно подобранных компрессии проблемы со сторожем проблемы со сторожем деньги за сканирование деньги сканирования деньги за secu то есть таким образом дизайна баз данных в claude должен быть максимально сбалансированный иначе вы будете платить за все постоянно что такое редис трибьюта котором я говорю представьте у вас есть две ноты кластеры join может делаться только в рамках одной ноты соответственно для того чтобы он случился вам надо декомпозировать данные переслать их почти на другую ноду за тратить кучу цепью кучу трафика с учетом того что в claude очень много машин это все весьма проблемная давайте перейдем к нашему кейсом сначала у нас было четыре ноты стоил это скромных 238 тысяч долларов в год но однако по истечению никого времени мы дошли до 11 нот и когда продукты попала к нам он уже стоило 650 тысяч долларов заказчиков посмотрим на модель данных модель данных она такая классическая в целом как бы есть несколько табличка фактов есть размерности все они посвящены ремонту потому что это франчайзинговая сеть центров по ремонту соответственно скидки по товарным позициям и оплата ну и важно соответствие грубо говоря одна строчка в этой табличке это одна позиция чек а у заказчика много было запрос но все они в среднем сводились каким-то числовым показателем эффективности и центров и scion в разбивке по регионам в разбивке по профилю с каким-то учетом date ну и то есть различные вариации но конечно как кучу абсолютно хаотичных запросов от аналитики если мы посмотрим на статистику по времени выполнения кажется что все очень хорошо запросы скакали в среднем от 2 до 12 секунд но так как инструмент бизнес-аналитики это табло то он эти запросы запускает в параллель и при запуске 1d сбор до одновременно работал до 20 запросов таким образом у появлялась кучу проблем у конечных пользователей и так перейдем к рефакторинга мы 1 рефакторинг который мы провели я так называемый факт ножек что для него надо сделать нам надо посмотреть какие у нас есть таблицы фактов измерения и если эти наборы измерений совпадают то надо посмотреть какие есть меры возможно эти меры тоже совпадают плюс-минус некими допущенным и тогда весь набор у наших таблиц фактов можно слить в одну если мы посмотрим внимательно на нашу модель данных мы увидим что абсолютно все размерности полностью совпадают все они отличаются только одним полем от это поле цена ремонта то есть величит начиная ремонта величина скидки и величина оплаты выбор самом деле это абсолютно одно и то же это просто денежное вычисление части услуги то есть таким образом мы берем объединяем все таблицы в одну а чтобы их как-то различать мы вводим более тип операции соответственно там появляется сделка скидка и платеж таким образом мы избавились от 3 таблицы радикально сократили количество join of но усложнили модель бей потому что в зависимости от типа поля нам надо подгребать разную таблицу поэтому в дело надо подключать другой рефакторинг этот рефакторинг называется дай managing мы также смотрим на той машины и убеждаемся что каждый time and шин он уникально принадлежит только определенному типу записи факта и смотрим соответственно поля на их похожести если нам повезет и этот рефакторинг получится то у нас будет очень просто и для и модель лучшая компрессия ну и соответственно будут много кола кети join of это очень хорошо итак если мы посмотрим на нашу модель на наше измерение то мы увидим что в них во всех есть четыре одинаковые в поля и некое отличающийся количество небольшой других полей то есть мы берём их это же сливаем в одну таблицам заливаем их в одну таблицу вот наши четыре поля вот отличающийся можно было бы вообще де нормализовать факта просто перебросить как бы часть измерений в них но тогда как бы было бы больше проблем потому что просто тяжело и этель делать то есть это самый как бы редко меняют измерений перебрасываются что ж у нас вышло по производительности в итоге когда мы слили факты измерения в такие таблицы у нас получилось около 20 процентов профита хорошо это или плохо но я считаю скорее хорошо но в то же время я вчера решила загуглить насколько мы изобрели велосипед и собственно как бы эта техника она активно применяется всеми для рецепта особенно и у народа удавалось получите профит до 80 процентов по производительности давайте представим другую ситуацию у нас есть большая большая таблица в которой нет ни дай меньше них нечего и мы берем в нее с кораблями просто все факты справочника что же тогда будет ну получится одна большая сверх широкая таблица вольём туда немного данных и равномерно распределим по всем годом кластеры когда мы посмотрим на меточки производительности и особенно это радикальная видно для google big вере на самом деле производительностью радикально вырастет по сравнению с моделью звезда то есть дар от шифта сверх широкой таблицы без каких-либо дай мне джиннов и прочего она дает прирост 20-30 процентов скорости а для google пиквери до 50 на самом деле для big верен это идеальный сценарий но у них для этого есть свой абсолютно подход который есть только в нем мне он очень нравится он очень удобен для тех параметров модели которые особенно участвуют именно в показе ну не участвует выборки это так называемый fleet and или nested структуры как вообще выглядит рекомендация гугла что-де нормализуете все максимально по возможному и тогда стар и snowflake модели будут вам абсолютно не нужны собственно вот наша таблица и мы уже получаем одну запись в таблице фактов на весь чек целиком они на каждую строчку чека говорим что вот у нас есть некая вложенные структуры с нашими полями у пиквери dml то есть ддл это некий джейсон это джейсон схема и если вы на ее посмотрим что мы увидим вот ту самую тип данных река три карты the flat on то есть мы берем рекорд помещаем прямо в таблицу базы данных мы при этом мы можем указать что этот рекорд он повторяется в рамках одной записи это можно сделать как для деталей чека так и для скидки собственно это этой это его атрибута работать с этим очень просто когда нам над получить какой-то запрос мы просто говорим разложи на вот эту ложную структуру и мы с ней работаем точно так же как и с обычными таблицами собственно если мы посмотрим на метрики производительности мы видим что прирост по сравнению со старым моделью составляет где то два с половиной раза это очень удобно тут я сделал такую большую сложную таблицу в которой я распределил все модели наши по скорости по простоте и тель по стойкости модели к изменению данных дай меньше ных даю и по потреблению место на самом деле как я сказал ранее ключевой в облачных системах это некий компромисс и вот модель бёрдмэн шин для redshift она как мне кажется она имеет оптимальные показатели производительности проблем для геля и для место но соответственно если мы делали бы этот проектный big вере я конечно же бы выбрал модель с тот факт как я уже сказал к сожалению при тюнинге хранилищ невозможно полностью абстрагироваться от того где он происходит поэтому давайте посмотрим на некие такие общие вещи пор отшив ту первую очередь нам необходимо выбрать корректно и распределение данных и определить ключи сортировки какие у нас есть варианты распределения это собственно вариант кей где мы раскидываем на соответствующие ноды данные с ключом вариант он где мы полностью реплицирует таблицу по всем нодом одинаково и вариант иван когда мы grown дроби там тоже разбрасываем данные есть ещё вариант аута это когда мы таблиц то есть как он работает внутри в ядре то есть поставили таблицы распределял это так же тогда ей redshift сразу ставит раз определению ул но как только он достигает некой порога величины он автоматически переводит его в распределении ван разбрасывает и то есть там какой-то идет такая буквально задержка где-то там ну для маленьких табличка секунды две и он или разбрасывает по всему кластеров какие ещё рекомендации но по нашим опыта если где-то 10 тысяч записей то можно их распределять типа мол это маленькие справочники если вы хотите оптимизирую joined ok но соответственно иван это для того случай если вы не знаете что делать но авто я просто боюсь потому что я не смог понять какая величина этого порога она в каждом случае почему-то разное ключи сортировки это них один физического упорядочивания записей на вашем диске соответствовали бы по одному полю либо по нескольким конечно же происходит деградация производительности от этого но при этом улучшается производитель join of поисков и различных операций с группировками есть два вида ключей сортировки и the compound ключи и есть так называемый interleaved ключи в чем между ними разница компаунд ключи они не все быстро все хорошо все здорово но проблема в том что предположим classiс компаунд ключ из трех полей если вы укажете в вашем запросе 4 например 3 только поле он не будет задействуем то есть он очень чувствительная к порядку interleaved ключи они более медленные при вставке они более медленные при поиске они медленнее при поиске чем и компаунд ключи но им абсолютно не важен порядок и в любом случае наличие interleaved ключа будет и данные по нему из cats и быстрее чем без него чтобы ваш кластер нормально работал надо ним как-то заботиться чтобы о нем забыть надо завести очереди надо делать регулярно вакуум чтобы удалять записи которые лишнее и при этом вакуум поддерживает порядок сортировки ну и конечно же надо и собирают статистику чтобы оптимизатору было хорошо на самом деле в последних версиях redshift а он сам собирает статистику после заливки данных и на неё можно целом сейчас забить если как бы результаты ваших заливок не используется сразу же следующим шагом вашей отель по и плане собственно давайте поговорим немножко компрессия как вы думаете какие алгоритмы компрессии можно как ими можно управлять в google big вере в самом деле не как google в биг вере ничем управлять нельзя собственно та же самая ситуация на основе китай этом компрессе не находится под управлением конечного пользователя как вы думаете из какой базы данных вот этот список алгоритмов компрессии но это наши операторы черта может старше я не знаю как бы это green план в принципе все то же самое если же мы посмотрим на список алгоритмов компрессии рук шифта то мы понимаем что выбор правильного алгоритмы компрессии это настоящий челлендж соответственно что мы делаем мы измеряем сколько у нас занимают наши колонки и пытаемся подобрать компресса встроенным инструментам на lights компрессор и собственно замеряем замеряем и так пока мы не станем довольными соответственно если нам повезло у нас очень хорошая производительность системы ввода-вывода и малый размер базы данных нам очень нравится алгоритм z с т.д. он хорош тем что этот один из тех алгоритмов которые не могут привести к увеличению размеров скомпенсированы базы данных если вы применили не к тому полю что касается пик very big вере сначала задумывался как база данных которые абсолютно на сто процентов абстрагируется пользователя от физической модели данных ну довольно быстро они поняли что ничего не взлетает и представили так называемый wildcard таблицы кто знает что к его линкора таблицы кто с ними работал ну смотрите это такой некий ручной механизм порционирования например у нас табличка называется transaction подчеркивание а дальше после нее идет дата дня за которые эти транзакции мы можем прямо в select написать лет звездочка from a transaction подчеркиванию звездочка и все и он будет автоматически обращаться к набору этих таблиц как парик экспорт ну собственно то есть там вот например в каких-нибудь системах но типа вот афины и проще то есть можно указать позиционирование к стриженова файлом как регулярное выражение тут примерно все то же самое у этих таблиц есть один недостаток в пиквери все запросы находится подрезал такой шум абсолютно и на них резал то конечно не работают они используются где ими там в бизнес аналитик повторяясь то ничего не получится соответственно так как это было довольно неудобно был не стандартный синтаксис то через некоторое время google пиквери представил позиционирование таблицы после того как ее sportiva цианирование таблицами как вы стали возникать нюансы то были представлен так называемые кластерные таблицы что такое кластерная таблицы собственно эта таблица в которых данные хранятся в упорядоченному формате то есть мы никуда не уходим они дают прирост производительности в 3-4 раза но самое ценное в этом другое как вы помните я говорил что пиквери он чарджит за объем просканирован их данных соответственно это кажутся невероятные цифры но их использование позволяет где-то 400 раз снизить вообще как бы цену запросу big вере более того в биг вере и был антипа тиран если вы делать select звездочка from table указываете например лимит 1 он все равно полностью просканирует всю таблицу и за чарджит вас по полной с использовать в кластер на таблице лимит перестал быть антипа терном это очень облегчает жизнью и когда разработчик и просто смотрела тестовые данные в таблице и съел там половину бюджета подразделения на это вообще и сначала кластерной таблице они позиционируются только как таблиц который работает с партициями сейчас и google и работать над тем чтобы они работали и не портится но на самом деле щас покажу как и доля обыкновенных их использовать создаем таблицу говорим что она close to rise равана поедишь нику и говорим что порционирования по полю wake дейт и собственного это поле мы просто записываем в одно значение всегда и тогда у нас получается мгновенное кости резеро ванна таблица в чем проблемы это само собой заменяет замедляет скорость вставки и конечно же в течение никого времени цикла апдейтов insert вы прочего таблица перестает быть упорядоченной соответственно ее надо перестраивать как рейд той было select атака это кино мычат кажемся за скан то это приводит к дополнительной трате денег посмотрим на запрос которые выполнены к николас терези раваной таблицы и класс терези раваной если мы посмотрим на финансовые показатели которые строятся из объемов данных мы видим что для николас терези равана таблице мы потратили на запрос 0 4 доллара стилизирована и вы потратили 0 0 12 цифра три три три вышло случайно вот прям меня порадовало ну и соответственно запрос работает в 3 раза быстрее устного фрейка который такой тоже довольно забавный продукт тоже есть опция кластеризации по таблицам но они работают чуть-чуть по-другому у них есть механизм автоматизм автоматическая рекла стилизация но из-за нюансов работы снова фрейка это мы и за собой его фишки time travelling кластерная таблица они могут весить даже в несколько раз больше чем обыкновенные таблицы соответственно вы будете за чар жены за место так как процесс рекла стилизация он выходит в рамки и как бы является ядром системы и вы не платите за компьютер вира которые там отдельно это за вас его тоже все равно за charged таким образом вы все равно заплатите деньги то есть как только вы пытаетесь играть в игры с физической структурой данных то тогда главный провайдеры начинают вас чарджить но это все равно как бы показывает что при данном уровне развить их налоги и шансов избавиться от физического понимания хранения нету давайте вернёмся к задаче удаление оборудования и так чтобы мы могли выкинуть пару ненужных not нам надо разобраться с очередями нам надо проверить ни слова и мы ли мы при этом работы конкурентной среде как у нас будет использоваться наш диск и не увеличится ли значительное количество дисковых запросов это запросы которые пойдут на диск при выполнении с ним не хватает памяти ну и соответственно как бы что произойдет с параллелизмом загрузки желательно это все делать до того как вы выкинули но да итак давайте посмотрим что же такое очереди очередь это очень простой механизм управления нагрузкой базы данных просто если в очереди полно запросов все ждет запрос вышел запускается следующий но значение по умолчанию они очень маленькие и я бы сказал не совсем правильно и ну и собственно по умолчанию настроены всего лишь одна дефолтная очередь что надо вначале сделать начале нам надо завести юзеров которые выполняют определенную нагрузку это это fox запросы и to be a и запросы этой еды или процессы и процесс которая ответит за поддержание жизненного цикла нашего сервера далее мы присваиваем всех этих пользователей призываем эти пользователям группы все дальше мы настраиваем сами очереди для каждой очереди нам надо указать возможности возможность пользоваться на карантин скиллинга не знаю вы используете конкорд сестре линк или нет но это механизм который упрощенно говоря может подкинуть параллельно рядом находящейся кластеры в период повышенной загрузки то есть например у вас есть как бы черная пятница вы не хотите закупать лишние но да не хотите переделать ваше приложение включать конкорд скай линк и все да уникальная фишка range of the snow flake а тоже такая штука есть перформанс boost соответственно он рулится параметр макс конкор натиск один кластер то есть сколько кластеров можно поднять как бы при повышении нагрузки необходимо для очереди установить количество слотов то есть количество слотов это по факту количество одновременно выполняемых запросов всего их против те и кстати как в google big мере их может быть только 50 но я вот не знаю как бы какую-то если у гугла родиться в саппорт и заплатить ему денег они могут снять это ограничение соответственно необходимо установить процент памяти от ноты для очереди ну и при этом важно понимать что память который мы выделено очередь она будет делиться равномерно между всеми запросами если нам надо мы можем выделить одному запросу больше чем один слот runtime новым параметрам это нам надо если например нас какой-то запрос тормозит какой деталь тормозит или нам надо быстренько сделать она live или быстро сделать вакуума ну соответственно чтобы закрыть вопрос об очередях нам надо потому тебя включение опции short коррекции решены такая специальная опция которая позволяет рту работать с маленькими короткими запросами но это вообще по факту антипатии ран и надо обязательно дефолтной очереди оставить хоть что-нибудь да потому что если в ней ничего не будет то теперь не будет возможности зайти в кластеры и попытаться спасти ситуацию собственно работа в конкурентной среде для работы конкурентной среде нам надо попытаться понять динамику того сколько у нас вообще запросы проводит в очереди поняв эту динамику нахождения мы можем как-то эмпирически попытаться оценить сколько у нас запросы про висят в эту очередь если мы уберем но до соответственно сколько они там будут жить утилизация диска это тоже очень важный показатель и проверяем его всё также динамики в течение какого-то периода времени вот и знаем как бы некий показатель считается is best practice а что если у вас занимают занята 78 процентов вашего кластер и это абсолютно нормальный показатель но соответствует всего понятно сколько нот мы убрались только диска ушло мы тут моего отца и тут следует обратить внимание что может захотеться использовать показатель из консоли которые есть в метриках и range of the этим показателям пользоваться не желательно именно до пользоваться select а потому что этот показатель учитывает не весь объем данных которые используются не используйте его собственные дисковые запросы когда запрос не хватает места в памяти часть его попадает на диск для этого тоже есть соответствующий метрики и с ними точно точно по такому же алгоритм надо поработать надо понять сколько у нас запросу попадет на диск если мы выкинули часть not ну и собственно на самом деле если как бы их больше 10 процентов надо попытаться разрулить дисковые вопросы грамотной настройкой очередей потому что чаще всего это чиниться тем что на какую-то очередь мы просто подкидываем больше памяти если такое не получается делать то у вас не получится выкинуть ноту диском запрос будет только больше ну если получилось собственно всю оцениваем для оценки нам понадобится некий запрос которым можно оценить сколько памяти занимает в среднем один запрос мы самое простое да это пролили зм загрузки эта команда лот который принято загружать данные собственно она работает в параллель сколько у нас not упрощенно говоря с такой параллелизм она у нас работает посчитали насколько у нас все изменится посмотрели в статистику ну и все хорошо собственно что стало с кластера после того как мы решили его уменьшить начале у нас было один слот 1 очередь запросы висели в очереди в день где-то 500 секунд у нас было 20 процентов запросов которые ложились на диск и девяносто один процент и кластера место кластера был занят но зато быстро работал вот мы взяли выкидывали три ноты сделали пять очередей это привело к тому что у нас время ожидания запросов уменьшилась до 150 кун в день у нас осталось только 5 процентов дисковых запросов и мы достигли утилизации диско 80 процентов достиг ли это потому что мы на самом деле грамотно и настроили компрессию ну и ключевое то что мы сэкономили заказчику в год 180000 долларов я вот говорил про constraint и вообще как бы что такое вообще constraint так зачем она важна в рецепте есть три типа constrain там четыре знаю почему написано 3 это уникальные constraint и это первичные ключи это внешние ключи важно то что эти три вида constraint они чисто декларативные то есть сама база данных никак их не проверяет базы данных проверяет только not налы constraint соответственно у вас гитель процесс должен обеспечивать целостность ваших данных и эти constraint и они используются оптимизаторам при его работе как используется при определении порядка джонов в процессе операции так называемый join ременная шин и при расчете каун distinct собственно к чему может привести использование не до использования constraint off предположим у вас есть расчет какого-то из таблицы мы делаем select distinct и мы сознательно в эту таблицу вносим дубликаты а потом мы этот же select делаем из таблицы на которой задан праймари кей constraint и когда мы делаем этот select мы видим что у нас появились двойники а почему нас появились эти дневники потому что constrain декларативно такими завтра верит тому что данный там уникальный и он делает sequence alaskan не пытаясь каким-либо образом где дуплицировать данные соответственно когда мы делаем запрос на таблице без constraint а дубликаты у нас нет но при этом тратятся сепию на операцию xn unic рассмотрим второй пример у нас есть табличка child есть табличка parent и в табличку чарт мы внесем парочку записи для которых нету записи вы таблички parent соответственно для запроса без constraint у нас довольно развэ чистый план в то время как для ворон и ки constraint а план простой in фактически состоит из одной операции но при этом кстати это все тоже самое последовательное чтение вот но при этом он возвращает неправильное количество возвращает он цифру 2 почему потому что он не делает честного джойана то есть да мы возвращаем результат очень быстро но к сожалению не правильно следует ли из этого что constraint они не надо пользоваться нет constraint и нужны мы ими пользуемся и будем пользоваться дальше мы доверяем нашим улетели процессу но проверяем раз в неделю у нас есть специальный job который раз неделю пробегает по всей базе проверяет уникальность проверяет фаренгейт ключ и за счет этого мы помогаем нашему оптимизатору и у нас очень быстрые запросы давайте я попытаюсь подвести выводы к сожалению клауд это не панацея для решения проблем производительности и до сих пор нет возможности избавиться от понимания уровня хранения данных начинайте все ваши действия с главной базой данных с оптимизацией моделей данных и в принципе я думаю предложены подходы они будут работать и для других обязательно использую уникальной фишки базы данных иначе зачем она вам есть на самом деле удаление железа из вашего кластер это не так и плохо добавляете его только если оказались совсем безвыходной ситуации ну и будьте очень осторожны с мастером миграции ну и конечно хорошая новость для тех кто работает с русскими заказчиками условиях in vitro замещения в россии нету клубных хранились у вас такой проблемы нет ну и еще раз хочу обратить внимание начинайте всегда с модели данных собственно всем спасибо спасибо большая вопроса исчерпывающие так отлично он есть вопросы заработал спасибо за доклад вопрос такой с облаками я не работал поэтому может быть достаточно глупой собственно есть цена за чтение с дисков вот и зависимости от профиля нагрузки я так понимаю будет достаточно эффективно посмотреть возможном просто добавление поймите очень снизить цену за процессом концепция облаков состоит в том что от инфраструктуры конечной пользуйтесь польностью абстрагировано то есть возможности добавить памяти не существует как класс то есть можно только подкинуть году все значит вначале не врали него спасибо за доклад подскажите пожалуйста сравнивали вы затраты на аналитические функции и если это делать уже на стороне клиента ну если честно нет потому что как бы она просто работает то есть в целом нет такого как бы не ставка потому что в том же самом как бы big вере до в основном идет full скан и как бы то есть она просто работает здесь спасибо за доклад а вопрос такой ойджер вы не анализировали тайской в хаос и может быть там какие-то свои особенности есть ну лично я нет кто то наверное да спасибо спасибо еще раз да ну наверное наверное я вот лично от себя выдал утку вот человеку который задал сам интерес вопросов можно ему передать вот можно ну и наверное кто-то был кто-то вот второй вопрос спрашивала не помню девушка ну давайте девушки тогда другой при зададим девушке должно быть весело"
}