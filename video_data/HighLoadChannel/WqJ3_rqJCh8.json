{
  "video_id": "WqJ3_rqJCh8",
  "channel": "HighLoadChannel",
  "title": "Как работает С++-движок рекламного сервера, с какими проблемами мы сталкиваемся/Дмитрий Корчагин(VK)",
  "views": 995,
  "duration": 1978,
  "published": "2023-01-19T07:01:38-08:00",
  "text": "здравствуйте меня зовут корчагин дмитрий я работаю в к и руковожу группы разработки рекламного сервиса в проекте made or did наша группа занимается всем что связано непосредственно с подбором рекламных объявлений это построение поисково яндекса сама обработка запроса на подбор банеров получения оценок релевантности для этих баннеров вероятность клика либо вероятность не стала если мы говорим о реклама мобильного приложения аукцион выбор наиболее подходящего баннера ну и форматирование про нашу нагрузку в пике у нас 530 тысяч рпс секунд 130000 руб с средняя нагрузка за сутки составляет 360 тысяч руб с все это дело обслуживает пятьсот пятьдесят с лишним серверов начиная от стареньких сиона в 2012 года и заканчивая свежими и токами 2019-го года нагрузка на каждый сервер в зависимости от профиля составляет от 300 до 6000 bs средне время обработки запроса 33 миллисекунды и в каждый момент времени в яндексе находится порядка 100 тысяч объектов среди которых осуществляется подбор и порядка 300 тысяч площадок на которых объявления может быть показано в ходе доклада я довольно часто буду использовать специфичные для рекламы термины так что я собрал в одном месте чтобы нам было проще друг друга понимать площадка японии уже упоминал это место размещения рекламы например лента вконтакте таргетинг это условия которые задают рекламодатели для выбора конкретного пользователя это может быть таргетинг на возраст либо таргетинг на регион компания это набор таких таргетингов плюс какие-то дополнительные лимиты например сумма трат сутки частота показано пользователя ну и баннер баннер это визуальная составляющая которую вы в конечном счете видите картинка видео в общем какой-то креатив общая схема работа таргета выйдет выглядит следующим образом когда пользователи приходят на какой-то сервис если этот сервис подключен к нашей рекламной сети то нам передается запрос на подбор рекламы в котором к нам приходит секатор пользователя идентификатор площадке баннерный демон как раз связь как раз осуществляет подбор и именно его мы в основном разрабатываем он получает данные из мускуле полип славу когда к нему приходит запрос мы в первую очередь идем во внешней сервису и получаем против пользователя после этого оставляем среди тех объектов которые у нас есть памяти только те которые могут быть показаны данному пользователю на этой конкретной площадке форматируем добавляем пиксели статистике которые впоследствии будут вызываться чтобы мы знали что с баннером было какое-то взаимодействие и возвращаем на площадку когда пользователь видит объявление вызываются как раз те самые пикселя они попадают в pipeline статистике которая всегда включает анти фрод charging и ряд других демонов которые непосредственного отношения к верному уже не имеют против рот как ни странно отвечает за обработку фродо charging отвечает за списание средств данные которые к ним приходят обрабатываются последовательно и бочками так что они пишут свою статистику с небольшой задержкой альфреда задержка порядка трех-четырех минуту charging задержку порядка 10 минут ну и по мере обработки они также пишет свою данную мускул статистику событиях которые произошли из компаний из нее она также попадают баннерный демон поскольку у нас целый зоопарк железо нам нужно как-то определять сколько нагрузки давать на каждый хост в нашем случае это решается через конфиге у каждого инстанса есть какое-то значение в попугаях которое он при старте модифицирует балансер ну и соответственно балансер знает сколько всего у него инстансов какой у них общий вес какой вес у каждого конкретного эта нагрузка пропорционально распределяется также есть отдельный скриптик который опрашивают этот балансер знает сколько у нас восток подключено и суммарная статистика вот этих попугайчиков она тоже попадают в мускуле из него баннерный соответственно каждый инстанции знает какую долю трафика он обрабатывает у нас это в дальнейшем будет использоваться схема баннер на вадим она устроена следующим образом у нас есть несколько типов задач которые работают в один или несколько потоков есть поток который отвечает за обработку входящих соединений и формируют задачи для майнеров майнеры это такой тип задач которые в роли задачи которого входит получение профиля пользователя и в общем то больше ничего только получает профиль и формируют задачи для worker of ну и наконец-то в маркерах происходят основная бизнес-логика подбора также отдельно у нас есть поток который занимается обновлением данных и все эти потоки привязаны кедром случае если у нас с потоки в основном идет работа с сетью то это несколько потоков на одно ядро это http и майнеры случае с маркерами это один поток на ядро чтобы избежать его тиснения и использовать железо наиболее оптимально работа с детьми труда представляет собой бесконечный цикл который ждет какого-то входящего соединения при получении этого соединения рождается поток который отвечает за обработку запросов которые именно в этом соединении приходят мы просим get запрос структуру которая содержит в себе собственно socket ответ и условную переменную после этого формируем задачу для майнера кладем туда эту структуру сами ждем на условная переменная пока кто-нибудь когда-нибудь скажет что все обработку запроса завершена ответ готов его можно возвращать когда майнер достает задачи из очереди в первую очередь он фиксирует хранилище и qamciq в который будет использоваться для обработки данного запроса запрос обрабатывается в несколько потоков хочется обеспечить консистентной данных между всеми обработчиками поэтому это первое что мы делаем далее мы партиям его лидируем запрос получаем профиль пользователя на этом этапе он у нас лежит бинарном виде только работа сетью получили все и формируем задачу для маркера типа и мид в которую кладем брани сформированный контекст запрос который раствор селену и сам профиль маркер может достать из очереди задачу одного из трех типов и нет select или файл это можно представить как такой на приют для бедных на одной машинки на фазе нет у нас происходит некоторая конфигурация и формирование следующего типа задачи на фазе selecta она соответствует фазе map и осуществляет фильтрацию ну и task файлов отвечает за объединение результатов и какую-то постобработку если говорить более детально то на фазе нет мы наконец-то портим парсим пользовательский профиль дальше берем все активные объекты которые у нас есть в памяти и применяем к ним индексный таргетинга индексные таргетинги это специальный тип таргетингов которые мы можем придать считать в оффлайне как раз в том самом дата менеджеры и затем быстро проверить в онлайне сразу для нескольких компаний реализовано это виде билета и если эти активные кампании у нас выглядит как набор единичек то каждый таргетинг которому компания не идут в которой компания не попадает на соответствующей позиции этой компании хранится нолики тут у нас это может выглядеть как у нас один рецепт для гиа один рецепт для возраста на самом деле самый хороший пример с возрастом там для каждого конкретного для каждой конкретной циферки есть свой биться свой рецепт для 17 лет сводится для 20 лет ну и когда к нам запросе передается вот 1 пользователя мы сразу видим какие компании стоит отсеять все эти таргетинги объединяются по и и в итоге мы получаем бесед с компанией где единички на тех местах компании у которых компании готовы показаться дальше это разбивается на шарды sharp представляют себя точно такой же билетик в данном примере у нас прошли индексной таргетинги шесть компаний и они пробились на 2 шарда по три компании в каждом ну на самом деле на практике у нас там может быть от 200 до 40 тысяч компаний в каждом билете и полученный шарды кладутся формирует у себя новую задачку типа select и возвращаются обратно очередь когда worker достает задачку типа select мы уже проверяем оперативные таргетинги это те по которым мы не можем как-то пример читать яндекс по различным причинам самый близкий пример которые мне нравятся это таргетинг на поисковые фразы множества поисковых фраз пользователя но бесконечно так что ну все варианты мы не переберём после этого проверяем лимиты рекламодателя например это может быть частота показано данного конкретного пользователя либо количество событий которые он готов получать сутки оставшийся компании у нас проходят через модельку машинного обучения мы получаем вероятности клика конверсии нам это нужно потому что в некоторых стратегиях это влияет на ставку которую рекламодатель готов потратить за показ этого объявления оставшиеся компании проверяются на лимиты площадки как правило это стоимость которую рекламодатель готов заплатить ну и соответственно стоимость которую площадка получит за показ этого объявления после этого у нас уже есть готовый набор баннеров которую мы можем отдать нам осталось только выбрать из них наиболее подходящий если мы видим что задачка фаза select все задачи фазы select выполнены то мы переходим к фазе войну на этом на этой фазе мы объединяем все результаты которые получили сортируем берем самое лучшее и все у нас готово баннера которым можем отдать форматируем как раз на этом этапе формируются пиксели статистики и говорим мошки тебе потоку что все обработка завершена можно отдавать ответ обновление данных работает следующим образом в памяти в каждый момент времени есть два хранилища пока из одного читаем в другое пишем по ходу записи обновления хранилище мы их также дополнительно еще пишем в очередь чтобы потом применить хранилищу которая сейчас используется для чтения какой-то момент времени получения обновлений приостанавливается и начинается процесс перестроение индекса ходе которого как раз образуются бесед и этот процесс занимают порядка 40 секунд когда новый индекс готов в манерах изменяется указатель на старое на новое хранилище 2 сначала приходят обновления из очереди а потом из самого muscled ну этот цикл повторяется каждую минуту скоростью обновления можно конечно управлять но поскольку при строении индекса занимает 40 секунд быстрее 40 секунд мы этого сделать к сожалению не сможем под капотом замена хранилище реализовано следующим образом у нас есть две сущности которые отвечают за время жизни остальных первое это data manager и она отвечает за время жизни хранилищ 2 это движок которая отвечает за время жизни майнеров когда новый индекс готов data manager вызывают у движке функцию set new star и передает туда сырой указатель на новое хранилище когда мы заходим эту функцию в первую очередь из 2 указателя мы формируем шерп better задавая ему кастомный деструкторов в этом деструкторы не происходит никакого удаления объектов но зато происходит notification условной переменной то есть когда объект перестанет использоваться мы кого-то где-то оповестим хорошо дальше мы устанавливаем хранилище для майнеров там не происходит ничего интересного обычный мьютекс заучили установили вышли за лоббировали и начинаем ждать на условной переменной зачем это нужно дело в том что хотя формально потребителем stora являются майнеры на самом деле они с ним прочти фактически почти не взаимодействуют а не только его фиксируют их передает в задачу чтобы потом с не мог работать worker таким образом у нас одно хранилище используется не только в манерах но еще и в десятках потока worker а и как только все маркеры переключились на новое хранилище то есть на указатель перестал использоваться умный вызвался деструктор произошла нотификации условной переменной и мы наконец-то смогли выйти из этой функции и начать писать обновление старое хранилище потому что до этого она еще использовалась ну и было бы как-то некрасиво писать обновление пока кто-то с ними еще играется и последняя часть касательно устройство баннер на во как у нас живет в памяти статистика статистика живет в виде очередей событий поскольку у нас оно пишется с некоторым запозданием события от одного демона вытесняются быть и из другого ну и если какой-то момент времени мы знаем что эта нить и фродо пришло двадцать одно событие то потом спустя там шесть минут танцев рады так задержка 4 минуты плюс еще лучше 6 минут пока до charging доедет мы узнаем что на самом деле в какой то момент времени произошло 14 событий как на примере всего 4 так что общую статистику нужно немножко поправить такая схема работы приводит нас к следующей проблеме мы не знаем в каждый момент времени сколько осталось у компании доступных событий и денег то есть у нас есть какие-то базовые лимиты у нас есть статистика которая приходит запозданием ну и казалось бы ничего страшного нет но на практике это приводит к тому что мы подобрали компанию на показалось пользователю попала в статистику прошла анти фрод все отлично честная компания хороший показ дошла до charging а очерчен говорит извините денег нет рекламодатель просил показаться только пять раз за эти сутки вы тут уже двадцать раз показывайтесь мы за это не можем взять деньги работаем и в один поток проблем бы не было подавай компанию уменьшая счетчик вышли в ноль останавливаю компанию там периодически получаю актуальную информацию статистике как-то эту накопленную информацию сбрасывай все хорошо но к сожалению в 30000 потоков мы не знаем где мы показались когда мы показались и как историка эту информацию синхронизировать непонятно в какой то момент мы докатились до того что доля средств которого мы не можем списать составляет 20 процентов от всех средств которые мы получаем а тот момент ситуацию решили довольно радикально нашли рекламодатели доля списания с которых минимальна там он был от рекламодателя с которых не списывали меньше одного процента и увидели что они заносят деньги на счет в свой рекламный кабинет ждут секунд 30 и выводить деньги обратно прекрасно соответственно информация о том что деньги есть успевала попасть баннерный хранилище обновлялась мы начинали показывать компанию пока статистика доезжал до charging а оказалось что все денег нет и списывать ничего ну решили мы эту на тот момент довольно радикально просто запретили ряду рекламодателей вывод средств в течение пятнадцати минут после того как они были заведены и на какое-то время про проблему забыли она нас не сильно беспокоило доля перекрут of упала с 20 до трех с половиной процентов ну и конечно настроили alert чтобы в следующий раз заметить быстрее частью таких рекламодатели было немного и в ручном режиме это продержалась не очень долго но тем не менее решение как решение хорошее решение для большой компании спустя год проблема снова себя проявила доля средств которые мы не можем списать начала расти примерно вот на 6 процентов мы заметили что что-то идет не по плану ну снова конечно посмотрели что там с рекламодателями в этот раз никакого криминала не нашли но нашли ряд рекламодателей которые заносят небольшую сумму денег на счет но при этом выставляют огромную ставку это приводило к тому что информация о том что деньги у компании есть попадали во все тридцать тысяч потоков компания начинала откручиваться и когда с каждого потока списываются деньги в итоге уходим в минус в принципе у нас уже был механизм который должен был нам как-то с этим помогать жить частично и отключение компании дело в том что наше хранилище для чтения она не совсем для чтения она еще немножко для записи если очень хочется в нем хранится вектор по количества маркеров которые можно писать какую-то промежуточную статистику потом как-то и в офлайне агрегировать и что-то с ней полезное делать соответственно в нашем случае это использовалось таким образом что если мы знаем что у компании всего шесть доступных показав зная вес каждой ноты в кластере мы можем определить какой какие лимиты у нас доступны на этой ноте но и знае количества маркеров на машинке также можем про масштабировать лимиты на каждый маркер соответственно в памяти демона хранилось информация о том сколько доступных событий было сколько произошло ну и если не хватало там и отключали компанию либо когда мы показали какую-то компанию и и счетчик вышел в ноль мы ее отключали эта статистика сбрасывалась при перестроении индекса из расчета что мы получаем актуальное обновление из мускуле зачем нам держать это в памяти если нам пришлось все честно и свеженькая а не какой то тут агрегированные с одной десятой доли всего трафика для денег был более печально механизм поскольку стоимость показа не лимитировано она может быть пять рублей может быть одна сотая копейки у нас нет какого-то критерия когда мы можем сказать что давайте на части worker of на компанию отключим остальном бюджет поделим на оставшихся это приводило к тому что если для показов ограничений работала строго то для денег она работала не так строго пока есть деньги мою компанию показываем отключаем только если она ушла в минус но масштабах мы имеем такой прекрасный сценарий что рекламодатель пришел с полутора тысячи рублей лимит на каждый worker остался всего 5 копеек стоимость 15 копеек ну вот с каждого worker и понемножку в итоге потеряли три тысячи рублей вместо того чтобы открутить полторы тысячи открыть или четыре с половиной тысячи не очень хорошо для нас удобно для рекламодателя но для нас все-таки не очень что мы сделали на фазе понял после того как мы уже выбрали баннера которая готова показать добавили еще одну проверку назвали проверка потенциала и она должна была отвечать за то чтобы с некоторой вероятностью блокировать показ несмотря на то что деньги у на worker в общем то есть работает через базовые формулы статистике берем доступный лимит делим на стоимость показа подбрасываем кубик соответственно с вероятностью 1 3 в данном случае мы компанию покажем а с вероятностью две третьих показ заблокируем и компанию на горке ряд ключем будем считать что она показалась где-то еще и все у нее хорошо и выйдем в ноль и действительно сработало стали выходить в 0 так что проблема с перри крутыми было решено но наступила другая рекламодатели стали приходить и жаловаться что их компании откручивается недостаточно быстро в чем же было дело представим такую ситуацию что есть компания с лимитом в 1000 рублей и со стоимостью показа 10 копеек она попадает в аукцион то есть проходит все таргетинги удовлетворяют критериям пока за один раз в секунду и выигрывает аукцион в 50 процентах случаях форма у меня тут нет но если посчитать получится что она должна получать 30 показов в минуту и открутить весь бюджет за 6 половиной часов на практике нам приходят наши 40000 потоков лимит на каждый поток остается 2 с половиной копейки вероятность показаться 1 4 значит мы получаем уже семь с половиной показов в минуту и весь бюджет спишем за 26 часов более того когда рекламодатели видит что его бюджет тратятся достаточно медленно самое очевидное что он может сделать это повысить ставку рекламодатель повышает ставку действительно начинают выигрывать сто процентов аукционов но при этом вероятность показаться падает еще в 4 раза количество показов падают в два раза благо он немножко тут получил за счет того что выигрывает больше аукционов ну а скорость открутки увеличиваются до 50 двух часов странноватое поведения для штуки которая называется аукционом когда ты поднимаешь ставку и начинаешь получать меньше событий что мы сделали мы начали работать с статистика которая хранится в памяти аналогично статистике которые к нам приходят из мускуле то есть мы ее не выкидываем теперь на каждом слоте а честно ждем пока нам придет событие от pipeline а статистики с более актуальными данными соответственно данная анти фродо также вытесняют runtime дельты как мы их называли данные charging работают как раньше вытесняют и данные анти фродо и данные которые хранятся в памяти все что плохо лежит вытесняет это позволило нам решить еще одну проблему это большую зависимость от базы раньше тут в начале октября если я не ошибаюсь это был 2019 год есть большая красная палочка которая свидетельствует о том что мы не смогли списать практически никакие деньги больше 70 процентов не смогли записать из того что показали сзади это было вызвано тем что у нас был сбой в получение обновлений соответственно у нас были компании которых у которых высокая ставка которая быстро откручиваются у которых довольно мало денег и вот эту информацию о подкрутки мы постоянно теряли и в течение видимо всего дня крутили наиболее дорогие компании несмотря на то что должны были давно их остановить также мы добавили к нашей проверки потенциала еще три флажочки это вероятность запуска этой проверки шаг с которым может меняться эта вероятность и целевая доля трат который должна получить компания которую мы бы хотели чтобы она получала вся эта проверка и machinery работает только в случае когда у компании не хватает денег чтобы совершить пакостный конкретно маркере пока у компании много денег все эти проверки не включаются и вообще не работают соответственно из ситуации которую мы видели выше мы получали следующую ситуацию вероятность запустить проверки 50 процентов количество показов увеличивается до 18 с половиной в минуту вероятность а скорость течение время течение которого компания списывает свой бюджет падает до десяти часов известно поскольку у нас информация подкрутки хранится в памяти мы можем посчитать сколько денег мы потратили за последний интервал мы знаем лимит если соотношение потраченных денег лимиту больше чем заданная в конфиге опция там и вероятность проверки повышаем чтобы избежать перегрузов если оно меньше чем за 1 в конце ганс опция там и вероятность проверки повышаем потому что это означает что компания откручиваться недостаточно эффективно и волноваться нам следующий интервал ни о чем эта вероятность может принимать нулевое значение соответственно мы тогда вернёмся к тому с чего начали 30 показов в минуту и шесть с половиной часов на открутку но если очень нужно то вероятность может принимать отрицательные значения и у этого такая семантика что если когда у нас есть набор керри какой-то бюджет и стоимость показа больше этого бюджета мы с какой-то вероятностью показываем компанию и и лимиты уходят в минуса мы компанию отключаем случае если у нас куча если у нас отрицательная вероятность запускать проверку мы это используем для того чтобы не отключать компанию даже если она ушла в минус соответственно с какой-то вероятностью если это минус 10 процентов то мы дадим 10 дополнительных событий если сто процентов то просто не отключаем считается что если компания не может потратить свой бюджет значит у нее при таких условиях значит у нее достаточно узкие таргетинги либо низкая ставка либо плохие гривой креативы ну либо это просто не очень интересное объявление непонятно что там рекламируется так что притормаживать и и никакого смысла нет лишнего на все равно не покажет собственно таким образом проблема с медленной открытка компании тоже было решено жалобы прекратились задачки на не списанный бюджет тоже перестали появляться доля средств которые мы не можем списать уже больше года не превышает половины процента таким образом и последняя проблема тоже была решена если у вас есть распределенная система которая работает на сотник серверов и в несколько десятков тысяч потоков нет необходимости гарантировать строго синхронизацию данных между всеми потоками зная вес каждой ноты переварить я просто так в гости зашел зная вес каждой ноты достаточно обеспечить ее сходимость через базовые формулы с теория вероятности и таким образом вы обеспечите сходимости системы если бы за внимание готов ответить на ваши вопросы пока готовится на первый вопрос скажи сходимость вот достигается ну как видишь ибис кафки для этой цели без каски где-то на глаз есть печенье кафка так я пытаюсь понять где у нас руки пока а о первый вопрос спасибо за доклад интересно все многие проблемы на себе тоже испытывали мы в рекламной сфере работа меня такой вопрос когда выбрали компании какие-то торги денги прошли у тебя было на складе что вы используете какую-то m-elle модельку чтобы оценить вероятность и клика вероятности view и так далее здесь вопрос составной у леры пробовали ли использовать для этого какие-то эвристики до прямые то есть до обучения модельки и если пробовали почему на модель перешли и если используете модель то какая детализация до конкретного юзера тогда это очень долго считать много места занимает вот какую глубину детализации или группы юзера каких-то немножко если можно больше об этом узле до я честно все отвечу возможно не совсем в том порядке в котором были заданы вопросы использовали мы ручные эвристики да мы их использовали они показывают чуть меньше и качество но как-то у нас так сложилось что мы начали наоборот с модели а потом решили может быть ручками сможем набрать что-то получше но на конкретных узких срезах получилось среднем не получилось среднему модель у нас все равно остается поэтому ручные эвристики работают только на ограниченное число пользователей сегментирован их до модель опускаются до конкретного пользователя и действительно это работает относительно долго это занимает больше 3 нет около трети все-таки работы всей всех ордеров половина времени тратится на проверку таргетинга в половину на работу модели но все-таки достаточно быстро быстро для runtime обработки насчет памяти нас там используются каскадные модели отдельно для кликов в отдельно для инсталлов но и весь каскад она весит порядка 88 тира 10 гигабайт что для нас совсем не критично обсчитывать и модели фоне да где то до обучаются на отдельном демоне и к нам периодически прилетают но не из мускуле конечно но из ходу по ну и последний вопрос в эту догонку когда доходит дело до аукциона вы же не по цене делаете аукциона в том числе вот а вот этим пониманием а вероятность клика вероятностью и так далее да и по цене если начальству и того что у опциона может быть разные стратегии конечно по просто рекламодатель стал 50 нет мы так не делаем у нас в случае когда мы оперируем ставкой за клик используется как раз эти оценки все правильно и на самом деле мы сортируем по систему в большинстве случаев ну известный термин это стоимость которой я понимаю спешим с рекламодателя за тысячу показов он второй сын этом у вас у нас в зависимости от настроек компании могут может быть и 1 и 2 и плавающий спасибо там еще у меня был какой-то ответ по этому поводу ответил алине со ссылками а могут быть другие стратегии аукциона мы можем ранжировать только поиграть на стекле к например на некоторых площадках нет человеку почему я пока спрошу скажи а вы масштабируете си каким образом ну то есть про worker of понятным про кучу машин понятно наверно балансировщик над этим всем стоит нам хочется узнать твой ответ балансируем чем и в основном горизонтально просто добавляя железо запаса по памяти у нас хватает основная проблема это с ядрами механизм для сортирования по памяти у нас тоже есть но использовать его на текущий момент не приходилось мы можем сортировать весь индекс ну и есть инструмент который работает над объединением результатов разных машин а вот тут несколько докладов вверх говорили про всякие дата локали те и всякие разграничение по данным использовать применяйте я к сожалению не было других докладах на которых про это говорили в кулуарах мы типа супер и живым спасибо"
}