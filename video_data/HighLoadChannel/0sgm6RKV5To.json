{
  "video_id": "0sgm6RKV5To",
  "channel": "HighLoadChannel",
  "title": "\"Акведук\": open source для быстрого ML в продакшне / Георгий Енукидзе (Авито)",
  "views": 1084,
  "duration": 2600,
  "published": "2023-01-19T05:55:16-08:00",
  "text": "всем привет спасибо что пришли спасибо что выбрали этот зал до меня зовут георгий я работаю во бита в команде под названием дата с вами сват и мы в свате делаем всякие миль фичи для авито не мы одни конечно но мы на этом прям специализируемся поэтому наша команда состоит из двух основных видов инженеров и the data science инженеры ребят которые занимаются модельками обучением с буром доцентов и всем что с этим связано и backend инженеры это мои коллеги те кто потом запускает эти модели в большой сложную высоконагруженных по структуре авито на самом деле нужно сказать что разделение это довольно условна и потому что конечно абакан тиром приходится вникать в домино области понимать как устроены процесс в машинном обучении едой inference а ну и в бою и работать с новым железом ну так же как и бисером приходится понимать как устроены большие микро сервисные высоконагруженные системы такие как у нас поэтому наши пока indir кое-что понимаю понимают право e-mail а наши dat ass on this инженеры в целом программировать сервису спокойно вот парочка примеров сервис который мы делаем это две классические мыльные задачи оптику то ли женщин модель и сервис который определяет ну скажем топологический центр объект на фотографии для того чтобы мы потом могли сгенерить кучу риса и зав укропов и при этом не испортить весь товара в данном случае вот эту страшного человека а справа пусть арка тоже свершая задача тоже наш сервис и раз нашей команды которая помогает она интегрирована в процесс подачи объявления в категории авто и она помогает не заполнять очень длинную форму с параметрами автомобиля можно просто сколько документы и о ярко все прочитают это не эта пара это не все чем мы занимаемся и на самом деле класс этот сердечных проблем это не все чем мы занимаемся но с очень много самых разнообразных разных моделей и ну пышных вот таких картин ночных других карте ночных и table с табличными данными по типу тех которые делают time we в итоге у нас сейчас уже более 40 микро service of my little late микро сервисов написаны одной только нашей команды в общей сложности все это многообразие употребляет уже сейчас больше двух коробочкой по памяти ездит на супер разнообразном железе которая за годы работы накоплен от стареньких к сороковых до самых современных а сотах которые вот только прямо сейчас подъезжают вам может показаться что это много что это какие-то очень большие числа но на самом деле не совсем так потому что эмаль фичи все хотят у нашей команды есть постоянный запрос на какой-то новой анель который нужно или разрабатывать новый появляются какие-то новые фичи давайте чудного и понимать там по картинкам по описаниям по подсчётам по диалогам по каким-то другим признакам текущее модели постоянных и какие-то новые применения вот например этого яркой почему почему мы должны читать только документ автомобиля моделью которой может салон читать можно много чего интересного еще вычитать вот ну и в том существующей модели они развиваются в архитектуру их обновляются не получают больше новых вещей зачастую требует больше ресурсов даже если бы мы всего этого не делали в целом авито это довольно большая штука и темпы роста у него соответствующие вот это число то что мне было легче всего найти это количество активных объявлений за последние примерно три месяца увеличилась на 9 миллионов в день то есть какой-то рандомный день там он написан я посмотрел сколько сейчас на вид активных объявлений оказалось что то 99 миллионов спросил у коллег не помню из-за этого кажется а сколько было три месяца назад они сказали ну -90 вот там было по нашим данным и получается что мы подросли на 9 миллионов только активных объявлений а это значит что в каждом из них есть по несколько изображений по каждому из них на кто-то написал отзыв кто-то мог обратиться в саппорт там было несколько чатов люди друга спрашивали о том продадите ли вы что-нибудь там подешевле эти 9 миллионов объявлений на самом деле целая куча контента это как бы генератор контента который постоянно растет и который требует новых и новых и новых ресурсов все равно на самом деле мы бы хотели завалить эту проблему деньгами или железом и сказать нокий если вы хотите типа большим или давайте просто больше железо покупать и все все кто там эти бюджета считает но с добавками к сожалению это не всегда так во первых производители до сих пор никак не могут побороть постоянный дефицит железа и зачастую вы можете найти себя ситуации когда вы хотите заказать новую партию но не все то что вы уже хотите заказать выделены это бюджет на самом деле где то есть и придется ждать вот и помимо этого наверное это следствие то что сервер в котором установлено современное актуальное мощный кабул зачастую кратно дороже такого же без нее без графического процессора и в итоге получается что мы постоянно то есть покупать постоянно gpu это долго и дорого и типа не очень хорошо звучит поэтому мы решали в очередной раз когда мы нашли себя в этой ситуации когда тепла текущей кластер уже там 90 плюс процентов утилизирован а следующая партия еще только подъезжает мы поняли что он чем-то надо заниматься в это время не бездельничать же естественно мы решили искать ресурсы искать возможности запускать больше на том что есть и иногда не просто запускать больше иногда прокачивать больше и мы решили свести эту задачу до 200 таких основных пунктов мы хотим улучшить утилизацию железу для того чтобы естественно типа больше модели запускать или более тяжелые модели запускать и унифицировать сервисы это тоже очень важный пункт потому что когда у вас 40 репозитория в самом сервисами вы зачастую можете время 3 мин находящим глупые какие-то проблемы и ошибки какие-то старые костыли которые со временем разрослись за ваших масштабов и начинают пожирать какие-то очень важные там десятки процентов производительности или какие-то лишние мегабайты поэтому унификация поэтому утилизации но при этом это бы бездельничаем в окне между поставками а наши коллеги которые занимаются тренировкой модели продолжают работать у них типа все хорошо поэтому мы хотим выцарапать ресурсы не заставляя при этом их делать дополнительную работу то есть мы не хотим менять фреймворке не хотим переобучать модели не хотим в тоской какие-то новые сложные инструменты которые заставят типа всю команду работать квартал это было не очень простая задача я расскажу частях мы с ним справились но исторически мы начали исследования того что есть потому что кажется что если у тебя уже есть пять лет команде и 43 по историк наверное там есть какие-то и хорошие приему тоже какие-то плохие но какие-то должны быть хорошие и в первым шагом просто прошлись по историям прошлись по сервису мы пошли искать хорошие плохие приемы но для того чтобы одни распространяют других избавляться какие-то систематические проблемы это схемка такого типичного микро сервиса в нашей архитектуре менталитет с моделькой вот она едет вот этот сервис обычно едет на какой-то железки сын видео видеокартой потому что но остальные в целом можно не считать они дешевые все наши железо под управлением coverings кластера . граница точно но все в кластере соответственно на самом верхнем уровне это контейнер и какие-то плоды в которой бегут асинхронные чиро асинхронные сервера обычно питання че и поэтому это речь типе внутри которого есть какая-то модель натренированная готовая конференция на где там вызывается слева и справа это входы и выходы который супер разнообразные я не буду на это много останавливаться это не та часть на которой получилось что выиграть там просто что угодно может прилетать что угодно может вылетать это могут быть очень большие картинки или очень маленький текст и как на входе так и на выходе там часов на интере интересного не удалось а вот если глубже погружаться в устройство сервиса оказывается что вот это взаимодействие модель и асинхронный сервак она очень легко программируется но легко программируется не самым лучшим образом то есть не сложно вызвать какой-нибудь модель искандера это типа там ваш класс модели . predict вот но оказывается что не для всех очевидно что модели вообще-то синхронное помимо этого они еще и ведут себя как считаю бомонд операцию то есть полностью останавливают все синхронно и взаимодействия с внешним миром и заставляют подождать собственно предиктор ну то есть результата как правило модель написано как то вот так здесь кстати кроется одна из технологических проблем зачастую вот класс который делает какой-то при processing после этого отправляет тендер на видеокарту дожидается результата и интерпретирует результат вот это все вместе называют зачастую моделью хотят фактически модель тут только серединке а вот это все вместе ну я предпочитаю говорить что это pipeline это будет pipeline модели хотя бы чтобы различать к где есть кто вот он вот такой почти всегда какой-то при processing почти всегда есть какой-то пост-процессинг почти всегда есть ну и inference само собой должен быть вот и все это запросто может занимать до 500 миллисекунд в бою на какой-нибудь картинки для самой по себе модели машину в обучении это неплохо это ну какие-то задачи да действительно делаются такое время но для сервера для общественной инфраструктуры и для серверов которые встроенную эта модель этого очень плохой признак потому что мы заблокирована в этом моменте в и о мире вокруг этой модели на самом деле теряем очень много пропускной способности например если вы проверяете они ты результатов текущего запроса в кэше может быть вы уже погоняли эту картинку через модель может быть от запрос уже приходил вот конкретный сервис если у банально собираетесь сходить в кэш прежде чем отправить в inference данные вы не сможете этого сделать если в данный момент какая-то другая задача находится в интенцию вот это вот блокировка очень сильно пропускную способность уменьшает если вы это место копать дальше оказывается что и сам pipeline то это не то чтобы какая-то однородная штука фактически несмотря на то что для внешнего наблюдателя это все там сидел bound но фактически при processing и пост-процессинг грузит только secu ядра довольно дешевый и почти всегда свободны и на этих конкретных машинах и только inference занимает как у и делает какой-то полезную работу ну или неполезную но самую дорогую часть работы если посмотреть на эту конкретной график и представить что это типа график натуральную величину то получается что в конкретно этом примере типа две трети времени вообще так и пол будет простаивать почему ну потому что вот весь что pipeline описан как одна конкретная функция которая просто вызывается там декларативность три вызова типа конкретно не буду вдруг летать вот эти две проблемы оказались довольно частыми и общими в многих наших рипа историях поэтому мы решили сконцентрироваться на таких формулировках типа у нас часто блокируется этот лук и часто простаивает готов давать этим что делать что с этим можно поделать ответы на самом деле тоже были в те же самые по историях потому что кое-где кое-кто вероятно в бою вероятно под нагрузкой встречал эти конкретные проблемы и в процессе анализа конкретного типа история находил какие-то приемы которые помогают избавиться избавиться от проблем простоя избавиться от проблем блокировок но все эти решения такие типа разрознены где то где то есть где то нет будет написан так где то по другому мы решили что неплохо бы собрать этот список и наверное как то не знаю сделать стандартом де-факто или договориться что мы везде будем так делать и список оказался вот такой то есть нужен асинхронно интерфейс между моделью точнее между pipeline им и веб-сервером гарантировано нужен более гибкий pipeline у которого предыдущие шаги не зависит от следующую для того чтобы можно было более эффективно нагружать группу чтобы она не ждала следующий следующих данных и последнее это очень удачный прием который но где использовался на не везде потому что его не всегда легко запрограммировать это группировка данных для моделей группировка данных для моделей это банальная штука это бачин наверное большинство здесь присутствующих значит вот такая но мне штуки sloppy расскажу если вы сделали какую-то картиночку модель который принимает данные в виде квадратика 3 на 3 с какими-то флотами представим что она интернет за 50 миллисекунд и вы получать какой-то результат оказывается что практически любая модель практически любой файл word практически любая архитектура имеет параметр бочонка который можно заранее за французская то я буду подавать в эту модель вот конкретно граф по 4 картинки разуму и оказывается что внутренние процессы вероятно куда-то run-time умеет оптимизировать такие задачи и выдавать в абсолютно времени конечно за большее количество времени но в среднем значительно быстрее результата для тех же самых наборов данных чем если бы мы делали их последовательно таким образом нас вырисовывается новая схема такого идеального pipeline а как его нужно строить каким он должен быть прокачанный pipeline будет вот так определенно нам нужен асинхронный интерфейс который дает легкий доступ к следующим шагом pipeline а который состоит из независимых worker плов вероятны который отдельно сканируются здесь нарисована что на семью там много worker of бегают в первом или в последнем квадратики а в середине какая-то 1 гб модель вероятно вот которой оба чем принимает запросы она там одна инстанцирован они прекрасно справляется вот так было бы делать классно было бы классно делать так на самом деле везде и нам показалось что это супер очевидно идея ну скорее всего такой инструмент есть вот это что такое типа стала не только локальная может быть как как-то покупать надо паниковать погуглить вот и мы решили поискать сначала прежде чем бросаться что-то делать поискать как системно можно решать что проблемы где взять готовое решение для этого решения есть еще несколько ограничений она должна иметь простой интерфейс потому что мы хотим продолжать легко делать всей команды наши сервисы мы хотим идти по втащить какой-то супер сложную технологию после которой но типа наши аналитики или там какие-то другие коллеги не смогут разобраться в нашем коде какая-то проблема оно не должно все еще street сменить требует framework или переобучить модель по понятным причинам ну и хотелось бы чтобы это было что-то монтэйн был что-то не чей-то эксперимент на гитхабе в первую очередь если такие вещи гуглить появляются вот эти вот три больших игроках tf-x с довольно новая штука когда мы начинали наши исследования вы в начинали эту войну за ресурсы тогда я то еще назвала стенда флаг surf вот но сейчас а не доросли до более большого пакета tf-x и для нас вот этот рост большой пакет на самом деле скорее минус чем плюс потому что вся остальная инфраструктура у нас уже классно работать все же написано все уже работает и dfx . торт на самом деле предлагают вам заменить ваши сервисы на то что они авто с генерируют и это хорошо подходит до случая когда адат останетесь не хочет или не умеет программировать сам сервис и вы можете на какой-нибудь один торт шарф закатывать ваши модельки закидываю туда и вокруг них будет магические появляться сервис там будет появляться пишешь к все хорошо это закидывайте данные у нас они так и переделывать всю нашу внутреннюю архитектуру под кого-то из них было кажется ну overkill нашим решением стал акведук у акведука целый куча преимуществ это библиотека или микро framework и вот так можно называть потому что супер легковесный который как раз сделан для того чтобы строить эффективные эмаль pipeline и не модели именно pipeline то есть запускать модель таким образом чтобы все остальное вокруг нее работал эффективно и помогала вам устраивать приличную скорость inference оно не зависит ни от какого конкретно вам варка то есть это типа не написала им виде для своих каких-то экспериментов или python который поддерживает только собственные модели вообще у нее нет зависимости то есть это zeropanda принц библиотека ну и она open source не был так один минус нам пришлось он им самим вот потому что до этого ее не было дальше я покажу несколько слайдов простых с примерами кода как это работает и там дальше сразу перейдем к результатам подписали себе вот такую вот класс модели который на самом деле pipeline в котором синхронно вызывается по очереди вот эти самые при processing module процесс и пост процессе мы уже знаем какой кучу проблем это приводит если при processing занимает там каких-нибудь 100 миллисекунд а эти 100 миллисекунд следующий шаг и по простаивает все плохо вот и вашему любимому синхронном в приборке это самый этот самый при плане эта модель была вызвана использована вот таким образом pipeline predict и там какой-то к этой меньше вы конечно получаете результаты теперь мы знаем что вот этот простой код на самом деле генерировать силу кучу проблем вот на предыдущем слайде мы видели проблемы со сканированием на этом слайде мы видим проблему с заблокированным трупом и если вы здесь ставите где-нибудь в поход в каше или вреден то он будет ходить значительно медленнее часто заблокирован будет с акведук вам эта проблема решается довольно легко вот первая часть превращается вот в такой простой класс достаточно инстанциировать flow это объект акведука он импортируется из библиотеки в котором есть три full степа который в которых описаны хэндлеры шагов вашего pipeline а я специально сделал здесь побольше квадратиков потому что там целая куча че есть ну вот я про эти три настройки час расскажу значит в первом киндере в первом flow степи написано intuos4 и это значит что этот конкретный шаг будет отсканирован в 4 worker а то есть там будет запущен 4 процесса между ним будет построенную очередь и они все в четырем будут разбирать задачки и подготавливать batch задачами для следующего шага кстати следующем шагу батчата из 10 это значит что при морг автоматически будет собирать в очереди между шагами собирать baci размером по 10 ну и ледовых вы тайм-аута сколько наберется вот и подавать их в moodle кондер именно такими пачками как только предыдущий блокеров будет их эту for дать последний размер очереди это ограничение нужно для того чтобы не текла память и для того чтобы между этим шагами не накапливалась слишком много объектов иногда это бывает очень полезно воспользоваться этой штукой еще проще буквально синхронный вызов pipeline а мы заменяем на асинхронный вызов вейпа процесс task вот и на этом практически все там появляется еще одна сущность самого тоска она нужна для того чтобы перемещать состоянии задачи между шагами pipeline а не расскажу дальше для того чтобы за маппить шаги pipeline и на вызовы вашего при процессинга ли вы с вашей модели мы использовали наверное самый простой паттерн это типа потому эндера вам нужно написать промежуточный класс интерфейс которого состоит из всего двух простых методов вам нужно сказать как инициализируется worker конкретного класса но там просто инстанцирует катаре сайтов и как варки этого класса будет хандрить следующую задачу очередной это второй метод findall и в нем написано что он просто проходит по всем тоска мы типа делать ресайз ему супер последнюю сущность единственное которая все-таки появляется новая это тоска котором я говорил задача она хранит в себе промежуточное состояние и оказывается это очень полезно вот такой микро распределенной системе когда ускуч и worker of может быть это похоже на actor ную модель это состояние важно хранить она потом на самом деле очень помогает вот здесь на примере например дополнительная проверка размер при инстанции рования докинза пловом 400 не бросит вы можете сами себе вам стать в итоге итоговая схема выглядит вот так она не сильно усложнилась вас все еще есть модель зеленые квадратики вас все еще есть api сервак какой то все равно какой и появляется только небольшой промежуточный слой с flow которым в котором вы описали хантеров и сказали что я их вот таким вот образом поочередно запускать так и будет происходить в observatory дает задачку задачка проезжается по flow и возвращается с результатом все профит оказалось что собрав вот эта вот экспертизу в одну небольшую библиотечку мы начали ее использовать на разных сервисах и оказалось что это супер удобно на самом деле неплохо работает потому что как раз помогает бить по вот этим основным нашим целям это помогает практически ничего не переписывать это помогает вообще не трогать модель аналитика фреймворке но при этом помогает высвобождать железо мы считаем что это происходит благодаря вот этому набору свойство типа там скрыто технические возможности она супер гибкая ну про треде и все остальное что здесь написано вот самый смачная самый лучший график самом начале ему смотрели на 2 модельки оси or и аптек в колледже вот за примерами далеко не приходится ходить это скриншот продакшна объем потребляемой кабул память этим конкретным сервисом из легко видеть что он похудел 60 до 12 гигабайт по другим параметрам он тоже уменьшилось облегчился потому что пропускная способность одного конкретного пода в котором находится один или несколько несколько инстансов модели она значительно улучшилась увеличивалась поэтому подав мы стали запускать меньше и все сопутствующие на самом деле потребление нам нагрузкой расходы они тоже уменьшились но основная все-таки группу 2 джек локализация тоже прошёл через этот путь тоже приехал на акведук это же похудел с 35 до 12 гигабайт это не самые топовые результаты у нас был прецедент со ста тридцати пяти до тридцати пяти супер вот но я решила именно эти два показать потому что несколько бы проникнуть сказал вначале вообще мы начали перевели только когда мы перевели только топ-5 самых ресурсоемких сервисов одной только нашей команды на этот микрофон work ну или типа библиотечку высвободилось более двухсот гигабайт skype памяти и что самое интересная пропускная способность увеличилась кратно потому что количество инстанцирован их кодов теперь стало меньше соответственно - осуждены на высвобождению память можем на инстанциировать больше модели которые на самом деле могут делать что-то другое не обязательно чтобы это было модель которая делает ту же самую задачу или похожую задачу никаких дополнительных ограничений нет особая гордость конечно нашей части команды банде raw это то что это все не эффект переписывания то есть реальный рефакторинга в этих сервисах не в этих топ-5 не в тех двух вначале не в текст последующих которые мы потом перевели никакого рефакторинга или переписывания кода бизнес-логики вообще не было там нигде не добавился какой-то кэш после которого мы стали там 8 10 центов хитрый ты средь изречь спать нет даже воспользоваться этой штукой настолько просто что некоторые из этих задач брали в работу даже наши стажеры ребята которые проходили стажировку мы ему давали говорили смотрел оптическая либо там все просто сделай какой-нибудь pipelines бери вот оно должно побыстрее работать и оказывается что это супер несложная задача при одном только условие модели нужно наблюдаемость если вы вносите все-таки какую-то сложность то это сложностью хочется следить нужно понимать чего вроде происходит поэтому в квебеке есть целый набор встроенных метрик мне покажу там парочку самых интересных на самом деле к сильно больше вот например такая ситуация легко помогает вам детектировать проблемы с выстраиваю щемиться очередями вы не дочитали немножко не знаю понедельничного трафика и вы видите что в очередях между шагами вашего pipeline теперь-то вы видите детализацию paperplane вы знаете что конкретный при processing тормозит или постараться сенатор носит вот супер важная информация она помогает эскалировать конкретный шаг и возможно тратить не больше группу больше всего скулы вот вот такие всплески тоже легко видеть это время транспорт шагов шаг иногда могут прилетать наполнены какие-то слишком большие задачи с каким-нибудь не знаю нетипичными картинками время работы любого шага естественно мериться для того чтобы понимать соотношение кто сколько времени занимает но это просто логичным кажется вот это мой любимый график потому что вот этот легкий трюк с базированием на самом деле помогает очень часто очень много экономить и затем ничего для конкретно вашего профиля нагрузки и для конкретного вашего сервиса для конкретно вашего боя это очень-очень важно поэтому с продакшена собираются в адские метрики да очень просто графика даются в кучу информации за какое время и какой размер бача успевает собраться на этом конкретном сервисы если что-то неправильно посчитали недооценили ли не переоценили вы не будете получать тот прирост производительности как на которые рассчитывали этот график поможет со временем переводя сервисы мы находили всякие мелочи которые могли бы улучшить ситуацию и типа почему вы не добавите еще вот такую фичу и очередную фичу и в итоге сейчас я не знаю даже какое количество свечей мы уже добавили в итоге но для того чтобы показать что это не какой-то лаконии эксперимента я хочу показать несколько штук которые мы походу собрали имплементировать и которые очень помогли во первых когда мы строим pipeline из процессов зачастую становится очень важным время передачи объекта из процессов process и на практике мы проводили даже эксперименты целое исследования на тему на практике в 9 из 10 случаев это время в принципе можно не учитывать почти всегда передачи она очень дешевая но иногда случаются ситуации когда все таки то тензор который переезжает шагов шаг он слишком жирный и вы начинаете замечать это время копирования тогда помогает вот такая фича shared memory мы ее встроили в акведука вы можете просто сказать а у этой задаче будет некоторое конкретное поле размещаться в по жареной памяти ну и тогда копирование очевидно не будет происходить вообще еще одна очень удобная фича кандел кондишен появился когда появилось такое бизнес требование как типа вот у нас есть pipeline и в этом плане иногда надо один из шагов пропускать ну для того чтобы его пропускать раньше нужно было либо сделать копию этой функции и запустить какие-то два pipeline а и либо в 1 либо во второй отправлять но в целом оказалось не очень сложно добавить вот каким был кондишн в которой ты падаешь любой cola был объект он вызывается на каждой задачки решает нужно ли эту задачку от проект вот конкретный шаг или можно передать просто дальше еще одна штука динамическое базирование некоторые виды моделей в целом не очень растут по времени если вы даете все больше и больше башню и поэтому в целом но неважно сколько любое количество работы все давай его сюда давайте выпускать в inference вот такая фича тоже есть можно просто включить флажок авто базирования и он будет просто выгребать всю очередь делать все что успеет если что-то накопилось не будет снова брать следующий патч динамического размера размеры очередей при этом очень важно контролировать потому что может так получиться что при наплыве трафика каком-то локальном не большом наплыве трафика в к.к. минуту или даже в какую-то секунду вы на генерируете очень большое количество очень жирных объектов в обычной ram памяти естественно в этот момент придет к вам и скажет все до свидания вот для того чтобы этого не происходило нужны вот такие штуки как ограничение на примерно размер очередь вы должны примерно понимать к размер объектов вас в памяти сколько памяти у вас есть вы можете выставить от параметров чтобы гарантировать что переполнение не будет появятся обратное давление на входе тайм-аут задачу тоже очень важная штука не везде она была сделана хотя супер очевидная идея вообще-то не каждый pipeline особенно вот тот который я показывал дойдет три вызова подряд не каждый pipeline при передаче из шагов шаг задачки проверяет а не вышло лениво тайм-аут может быть видюху уже вообще не нужно грузить вот такое случается мы это делаем автоматически стратегия завершения последний свечей но на мой взгляд одна из самых важных потому что когда вы запускаете пулы worker of помимо сервака кажется что нагрузку кажется что логическую работу делают вот как раз они вот эти пулы в них что-то происходит них сидит модель но механически если они отваливаются вести с ними что-то происходит не так центральным процессом в контейнере зачастую практически все сейчас у нас бегает в этих контейнерах остается веб-сервер которые при абсолютно не рабочем плане продолжает радостно принимать запросы были да еще все обработать все хорошо засовывает в паре плане задачки и после никого не большого тайм-аута забирает эту простую задачу кнут что не получилось вот и в таком состоянии системы может находиться достаточно долго пока возможно по бизнес метрикам не поймете что там чего плохой а вот для такого кейс мы его встретили в бою для такого кейс мы используем специальный watcher который генерирует исключение в главном процессе если что-то пошло не так ну естественно если исключение генерируется то их нужно куда-то отправлять у нас есть интеграция с центре ну просто потому что центре у нас используется внутри библиотечка upon source так что вы можете на самом деле добавить свой экспортер там есть специальный интерфейс вот мне подходит время концу поэтому это далеко не все фичи вот но я не хочу чтобы вам показалось что эта штука решает вообще все проблему поэтому последний слайд это пункты которые должны вам подсказать что к виду вам нужно взять использовать если у вас есть высокий фпс и ресурсы где была ограничена ну логично в обратной ситуации типа вы запустили торговую модель на ней нет трафика все хорошо и нет проблемы не надо усложнять не надо ставить никаких дополнительных библиотек акведука том числе и надо вот если дисбаланс при плане шагов есть если вы явно знаете что вас кроме при processing чуть притормаживает или занимает значительное время даже если он не самый медленный если его время это 10 15 20 30 процентов времени всего pipeline а зачем его терять вот ну соответственно если если это у вас не так увеличьте просто размер батч в 10 раз и быть так вот ну еще пара других штук которые для людей которые будут читать презентацию а не слушает доклад благодаря тому что нет никакого vendor лог а мы на самом деле сделали библиотечку который зерна помните и поэтому большого смысла ограничивать и одними только m-elle применения так что если у вас вдруг есть pipelines лескова и цапу нагрузки который никак не связан с мэлом пожалуйста тоже можно взять для течку все спасибо это последний слайд здесь я хочу на этом слайде сказать что напомнить еще раз что я влад и работу браконьерам поэтому не на все вопросы могу ответить особенно чем ближе вопрос к я молю тем меньше я могу ответить но все наши коллеги находится вот в чатике david m l заходите и можете пообщаться и порасспрашивать как мы это используем для каких целей с какими моделями и что такое вот а пока вы все присоединяйтесь вы хотели крольчат я отвечу на вопрос а здесь если вам пасибо огромное давайте похлопаем еще раз докладчику так начо созрели вопросы дед вижу пока вот вижу вижу то хорошая штука общем хорошая штука общего назначения как все решает классная задача но у меня был небольшой эффект дежавю лет 10 назад там плюс минус возможно на хай-лоу невозможно нет докладывали джаву project реактор и по-моему это повторить на питоне возможно теоретически ну и собственно кого если это библиотека против отличная 1 час опроса если эта библиотека 10 лет назад сделала ну типа куда-то было выпущены после этого про нее никто не слышал то это не совсем тип инсталлов reduction а она java узкая ну то есть про него слышали это то есть сейчас как бы актуальная тема вот я к тому что ты задавал вопрос по какому слову погуглить и они настоящие гедонисты да вот возможно что-то аналогичное было то есть в джаве это как бы совершенно стандартная технология которая лет уже много вот ну вот так что рекомендую посмотреть возможно есть аналоги другой стороны вот тушила некроз процессная то есть ну вот осинка его в принципе это тоже реактор только в одном концессия вот вот то что мульти процессинговый может быть и не было я не знаю но в принципе вот очень похоже то есть flux там вот тут эти слова там по публика супер спасибо большое и обязательно посмотрели мы оттуда что-нибудь своруем также как мы с ворвались по этот час топлив эти вопросы это большое спасибо за доклад очень классные teka у меня вот вопрос же пользуешься но есть честно хочу в общем вопрос такой если правильно понял она не использует никаких внешних зависимостей виде очереди сообщений да вот и я хочу спросить почему потому что буду бы это было бы очень удобно например вот ты говорил про то что очередь забилось и какая-то проблема отдается пустые результаты а так губерн эти смог быть в динамически поднять больше например обработчиков до условный ребят и быстро обработать все твои запросы или там например у тебя упала твоя задача теперь пистолета мне право а что-то неприличное там вот и в рыбе мог тоже условно перетравить тоску до посинения или до того миллиметра и захочешь да вот вопрос пакистана почему на такие почему почему не любят почему не рынке или почему не другой машины потому что для для этого конкретного масштаба задачи и the overkill инжиниринг или в целом просто не очень нужная штука смотри у нас есть системная библиотека который позволяет воспользоваться тем что предоставляет операционная система и просто фронте у импорт кью сделать или там from мульти processing импорт kill вот и все у нас есть система сообщений которые работают с соседями процессами и на самом деле этого нам достаточно потому что мы не хотим выезжать за границы одного конкретного контейнера это сильно усложняет архитектуру если вы хотите делать что то такое то это чуть-чуть как будто бы другой масштаб до вы не хотите внутри контейнера устраивать вот эти вот повод эти потоки пулы worker of полу процессоров хотите типа чуть выше подняться и делать это в контейнерах это должны быть другие инструментов возможно это будет делать tf-x или тот черт или кто-то из них потому что как раз они на другую масштабе работают но для них я должен вас предупредить вам придется вполне вероятно перестроить часть своей архитектурой и не только архитектуры в плане типа конкретного сервиса потому что я лично пока не знаю как из скомпилированные модели запущенные внутри тайтона сходить на премьеру redis кэш кажется что это невозможно да то есть вот такая архитектура но помимо этого еще и малека архитектура то есть вашей платформе придется конкретно поработать над тем чтобы поддержать эти штуки они очень-очень тяжеловесные для того чтобы этим воспользоваться тем подан самим 20 понял да немножко для других задач и где ему было чуть почти в другом масштабе ему она все вот локальному приятную памятью спасибо такая так вот привет слушай хотел узнать вот было оптимизация gpu но непонятно не было речь про то что произошло раньше она была низкая нагрузка но что же произошло после того кто оптимизировали как там ситуация произошла первый вопрос и сразу 2 догонку право снизили понятно что можно использовать если есть классов на какую можно активировать а если кластера на цикл будет ли это эффективно насколько вот образ супер спасибо это интересно первая часть довольно простая у меня есть слайд на котором я показываю вот парочку сервисов смотри рам и количество кодов ну не настолько же но пропорционально падает сокращается соответственно количество цифр на самом деле тоже становится меньше в некоторых случаях мы намерены размениваем более дешевые цпу простаивающие в этом конкретном кластер и размениваем на есть больше при процессинга запускаем и увеличиваем конфигурацию модель таким образом чтобы она обрабатывала большую baci типа по 50 картинок по 150 сообщений тестовых или там по тысяче заголовков мы намерены размениваем одно на другое там где это нужно но зачастую если все остальное не менять только добавить вот этот умный pipeline который уберет простое все ресурсы уменьшаются цикл в том числе пруда а вторая часть была напомни пожалуйста 2 было про то насколько эффективно это будет лиц и полу вот группа увеличу столько-то раз аджику насколько эффективно я не могу назвать никого конкретного примера потому что у нас пока сейчас таких применений нет я точно знаю что фактически это возможно то есть я вот говорил что там нет никаких зависимости от gpu from work off или там драйвер куды пока что не попалась такая задача я почти уверен что батч эмбоссирование не будет работать так же как работает на колхоз потому что там большое количество вычислительных ядер позволяет типа параллели эти операции такого количества ядер вне станка или мне с какими другими intel и метро играем все равно фактически не появится но тем ни менее вектор на операции кое-какие как то они оптимизируют поэкспериментировать можно по крайней мере в части разблокировки асинхронной части взаимодействия все точно будет хорошо попробую этом обратную связь спасибо присоединять заходи всяких задавай вопросы ребят из sico я тебя задам если можно скажи пожалуйста есть очевидно что эту как ты сказал есть какой-то набор сценариях есть набор pipeline где применении к виду к будет наиболее эффективным и случай который не будет очень здорово работать а можешь ли ты назвать привести какой-нибудь ну какой-нибудь самый такой вопиющей примеру без проекте с когда получилось действительно ну пупок максимально повысить эффективность совместной работы gpu powervr загнать под для какого конкретного случая акведук помог приводит чтобы был примерно которой мы могли ориентироваться у нас был сервис совсем друг по-другому построены точнее есть у нас есть сервис совсем по-другому устроены но не карте ночные поэтому вот такие же графики на нем тоже были я просто выбрал конкретно эти потому что я про них начали рассказываю но вообще-то мы большое количество сервисов чем более они нагруженные тем быстрее мы их переводим на группу потому что понятно от масштаба зависит вот это количественный выигрыш и я говорил что у нас есть сервис который похудел со 135 гигабайт заняты gpu памяти до 35 вот пока что это на моей памяти абсолютный рекорд ну а что это за сервис там на вход подается просто очень большие binary и поэтому я не знаю наверное граф больше поэтому inference было сложнее и в целом его ответы типа несколько секунд но это внутренний сервис это не фича поэтому ничего интересного наоборот как раз у нас люди собрались которую внутренние сервисы интересные"
}