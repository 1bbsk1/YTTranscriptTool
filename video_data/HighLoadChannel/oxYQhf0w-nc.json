{
  "video_id": "oxYQhf0w-nc",
  "channel": "HighLoadChannel",
  "title": "ArangoDB: Transactional information retrieval / Андрей Абрамов (ArangoDB)",
  "views": 2170,
  "duration": 2973,
  "published": "2020-04-27T12:07:57-07:00",
  "text": "это первую очередь пусть приветствовать вас на конференции спасибо что пришли я не ожидал что выездом людей вот и так как это верно сие вообще право ранга devi и это мой первый опыт выступления то я представлюсь меня зовут андрей абрамов последние семь с половиной лет я занимаюсь разработкой поисковых движков системы рекомендации данных а так занимаясь моделями релевантности похожести данных и в данный момент я руковожу разработкой поискового движка на ранги все оч в московском офисе а ранга деби и перед тем как перейти непосредственно к теме доклада давайте окунёмся немножко в историю и посмотрим как развивались база данных и к чему это все привело в наши дни кто знает а этот человек за фотографии и это майкл стоун breaker общем такая ключевая фигура в области разработки и исследования баз данных и считается что именно с его парадигм аванса из разных цветов появился вот этот вот случился бум nautical решений и в общем то теперь в нашем зоопарке есть много различных наук сиквел и не очень зверюшек вот ну а если серьезно то к 90-м годам в разработке консолидировались в реляционной базы данных дальше с появлением интернета интернет-компанией они продолжили свое развитие как кастомные баз данных в этих самых интернет компаниях дальше был бум вызванных stone брекером когда появилось огромное количество но в сиквел бас который хорошо решали свои узко специализированные задачи и что мы имеем сейчас сейчас мы имеем на то что то что происходит никогда не которых консолидации этих самых на усикова баз данных в мульте модельные базы данных каким образом как правило это происходит как правило это происходит то что есть нет некоторый фундамент который вылизано хорошо работает и сверху добавляется поддержка какой какой-то дополнительной модели данных например примером таких баз данных множество могут служить манган baby или напрямую или на которая недавно добавила как раз по поддержку графов или если не говорить о базах данных и поиска воды господь движках например elastic search разросся до такой степени что через икс пак предоставляет нам возможность обработки графов но через несколько лет после вот этого бума на усику начали появляться мальте модели базы данных так называемый на этих molti модель нет база данных в чем их отличие их отличие состоит в том что изначально они разрабатывались с прицелом на поддержку нескольких моделей это не был слой за слоем не эти модели не накладывались только слоем а изначально был фокус на них собственно об одной из них как вы понимаете сегодня и пойдёт речь но перед этим давайте посмотрим во что сейчас может вылиться вот это самая парадигма 2012 году one side а значит он и сейчас это будет пример архитектуры бэг-энда от который слава богу удалось уйти благодарите перед переходом на orongo одного из наших к стримеров что был в начале начале было в бэг-энде приложение которая работала с мангой все было хорошо все были довольны но в какой-то момент пола текстовых функций как это часто бывает перехватил их просто стало не хватать и что делают люди люди недолго думая берут elastic search ставят его отдельно естественно они не хотят дублировать данные поэтому они хранят нам первичные ключики что происходит в этом случае в этом случае разработчику необходимо теперь решить 2 дополнительных задач 1 задачи задачи и синхронизации данных между этими источниками это решается в более-менее стандартно с помощью кого у них манга коннектора или ластика и но что еще хуже нам теперь необходимо развить логику pride самого приложения помешав бизнес-логику логику доступа к данному идет время нагрузка растет и по нему люди понимают что каким-то образом необходимо сканировать backend что происходит они берут кластер а картина становится еще лучше то есть во первых это затраты на поддержку этого кластер а потому что их мы знаем кластер работать совершенно не так как сингла сервер всегда есть свои особенности внутри кластера кипит жизни то есть если как как когда мы делаем запрос на балансировщик он распределяет запрос по сортам собирает их и некоторые кейсы которые хорошо работы в сингл сервере могут теперь очень плохо работы в кластере что происходит дальше дальше например в приложении не требуется какие-нибудь рекомендательные функции например представьте что есть какой-нибудь список товаров пользователь хочет найти такой товар мы хотим показать ему рекоменду он и почему рекомендованными хотим показать не по прямым связям по некоторым косвенным связям что происходит ну все мы всем известный на выходные мы берем на f1 еще больше вспухает приложение 3 кластер итоге нам нужно три двери которые будут обслуживать этих мастера я много инфраструктура и в общем у нас в общем покер фейс что как как в этом случае может помочь а ранга и вообще что такое оргазм а ранга это мальте моду найти в молотим умотал база данных который изначально разрабатывал разрабатываю с прицелом на первых на масштабируемость и на одновременную подчеркивать одновременную работу с тремя моделями данных это пара ключ-значение графы и документы и собственно в 3 в 34 недавнем последнем релизе мы добавили на мой взгляд ключевую особенность ключевую не заставляющую фишку это поисковый движок orongo search который позволяет вам организовывать доступ назовем это в стиле ластика поверх всех этих моделей данных вы можете работать одновременно что это нам дает во-первых это каких как следствие то снижает затраты на инфраструктуру которую необходимо содержать потому что очевидно вам нужен не нужно хвостик три кластера например этом случае вам нужно ходить только один кластер и затраты с точки зрения структуры гораздо меньше во-вторых вам не нужно держать 3 baby if вам нужно 19 из для меня как что что для меня мы самые важные как для разработчика это то что такой подход позволяет мне к разработчику предложить вам как пользователем оптимизация так недоступные решению когда у нас есть несколько разнородных баз данных которые стоят и как-то общаются через приложения и особенно это заметно при работе с распределенными данными теперь давайте немножко я расскажу о том как устроена ранга чтобы чтобы было как-то более понятно дальнейший рассказ про кейсы в принципе orang дебиана имеет достаточно широкий спектр возможностей готов к как ее можно развернуть это сингл серверов акте файлов асинхронной репликации masters life но так как мы все-таки говорим о hallowed больших данных то я основном буду рассказывать о класть или сегодня кластер ранга тебе состоит из нот и в трех типов это координатор по сути балансировщик id&t надо на которых хранятся непосредственно данный и джинсы джинсы это некоторым мозги кластер а которые хранят его моментально моментальный снимок с точки зрения cup теоремы все знаешь и такой cup ok собственно точки зрения cup теоремы кластер нацеленным на консистентной и отказоустойчивость с точки зрения на то партнерша то есть если возникает natura park шум стараясь стараемся будет показать вам одну и ту же картину данных несмотря на какой координатору подключитесь в ущерб естественно доступности под такое решение далее с точки зрения отказоустойчивости данных для каждого то каждой коллекции воронка devil можете задать свой reputation фактор и количество сортов для раз проверь его ней соответственно и при отказе какого-то изгибе серверов соответственно ранга деби автоматически выберет новый мастер shard из числа реплик чем хороша такая архитектура кластер и он хорошо во-первых тем что вы можете подстраивать кластер под свою нагрузку каким образом за если у вас есть больше компьютер нужно больше компьютер добавьте координаторов больше тебе серверов добавьте деби серверов теперь давайте поговорим немножко непосредственно про ворон buy search и чем он отличается от обо все это более-менее привычных привычного способа интеграции полнотекстового индекса в базу данных обычно под обычно я имею ввиду какой-нибудь м с сиквел в данном случае как это выглядит выглядит так что нам у нас есть табличка или какой-то неважно там коллекции и нам говорят мы вы можете взять вот выбрать полю полнотекстовые да и мы по ним построим яндекс вот и все там не больше одного понятно не больше одного поля в яндексе можно два индекса имя и да естественно потом вывести на поле в данном случае мы говорим вам что вы берите столько с коллекции сколько нужно и скажите нам как их индексировать под как я понимаю какие поля индексируют или их может быть все поля индексировать и какой при processing к этим полям применять что такое при процессе при processing это нужно ли делать таки низации не нужно делать такие за цию нужно ли выделять основу слова или нет или этом приводить регистра независимый формат с точки зрения формовки данных ранга сечка носит привычный для дтп с pipeline три блока которые характерны собственно для поисковых движков как я говорил вот этого этапа анализа данных то есть перед самый приятный sing непосредственно поиск то есть получение данных которые соответствуют условиях условию запросы и renting брендинг это определение того насколько данные которые мы это фильтровали релевантным условиям эти на этому запросу ассоциации некоторого скоро конкретному там документы почему то еще есть результатов в таком сетапе многие могут подумать что такая история то есть поисков поступать с с движком как все говорят полнотекстового поиска дано валидно или имеет смысл только в случае работы с большим количеством неструктурированных данных на самом деле это не совсем так при определенной и интеграции мы можем получить огромный benefit для нас или для де беф в каком случае как известно реляционный базы данных они любят знать с какой нагрузка они должны работать для чего это делалось для того чтобы гибель построил индексы которые бы ускорили вам доступ к этим базам данных соответственно сейчас сейчас есть фации дыни сейчас принципе ну тут есть примите некоторый парадокс у нас обе стороны новых сиквелы и т.д. манга например а мы используем б дерево то есть нам нужно зерно проектирует структура у нас но не то что никто не только носику майским лес это не совсем такой схема лес он немножко с реляционным таким налетом скажем так вот и здесь можно добиться того что пропагандируется в космос baby то что называется схемой агностик и на писсинг это вообще не запаривайтесь про конфигурации ваших индексов а просто говорите про индексируем не все почему это возможно первых это возможно потому что джейсон стандарт определяет вполне себе четко определяет типы дано с которыми может вы можете работать во вторых это возможно то есть это бы не имело бы смысл без структуры инвертированные индекса которые хранить все данные внутри отсортированы me и мы получаем максимально настолько возможно плановых выполнение насколько это необходимо то есть это миражом всегда и при работе с не определенной нагрузкой лучшего не сделаете собственно в этом примере этот пример того как документ листон документ будет преобразован в какие поля собственно будут храниться в яндексе и как в нашем случае дальше давайте поговорим немножко эскизах ну и в первую очередь так как у нас есть кластер у нас есть поисковый движок то очевидно мы можем организовать просто распределенный поиск из коробки и запихать туда в данном случае это пример того как мы тестируем нагрузку для ранга search а мы берем комментарии реддит и за последние 14 лет и тестирование на кластер из трех модов собственно количество документов в таком яндексе в таком в таком да это сеть у нас больше двух миллиардов при размере сырых данных это в районе одного инноватора байта в кластере она сжимается приблизительно 30 процентов до 700 20 гигабайт как аран тысяч встроен в кластеров оренбургский так как я и говорил что на каждой коллекции у нас есть есть каждая коллекция может быть rush ардена и собственно orange для каждой для каждого шарда коллекции мы строим собственный индекс который храним там же рядышком почему рядышком да потому что нам нужно обращаться к мы храним там ключики первичной нам нужно обращаться как самой коллекции к самому что вытащить документ чтобы сделать это быстро и эффективно тут возникает и возможно резонный вопрос почему именно так почему не хранить не иметь один индекс на все шарды коллекции и ответа на этот вопрос является вот этот слайд как минимум есть четыре пункта почему это хорошо во-первых что очень важно в классе в классе теле очень важно чтобы у вас шарды были сбалансированы значительно да это модов пластик например вы подымаете еще один baby сервер на котором после поднятия нет вообще никаких данных и вы хотите чтобы нагрузка просто туда тоже таким образом orongo будет крепить потихоньку перемещать шарды на него размазывает на нагрузку и в этом случае собственно это это эта операция перемещение или удаления шарда для нас это константной операция констант на времени выполнения относительно количества данных которые лежат в этом самом яндексе кроме этого мы бы так и с помощью такого подхода мы можем уменьшить размер первичного ключа который хранится в яндексе который нам необходим для доступ к документам почему потому что нам не нужно хранить идентификатор коллекции с как с которой он связан в данном случае у нас все необходимо восемь байт для хранения самого первичного ключа и последние два пункта нет очень важный на мой взгляд это изоляция с моей стороны это изоляции с точки зрения чтения данных то есть если у нас есть in view или яндекс построены на коллекциях а b и c и мы хотим например в данный момент нам нужно только нам интересует данные с коллекции c то никаким образом данные из других коллекций не будут нас на нас влиять это и то же самое что еще более важно и потому что инвертированный индекс обновление инвертированных индекса это не дешево это дорого модификация индекса коллекции они как невероятно модификации индекса коллекции б то есть вот в случае с рейде там что мы можем сделать мы можем запихнуть старые комментарии в одну коллекцию и добавлять в другую коллекцию соответственно комментарии идут которых вновь приходит или модифицируется и сейчас в общем то уместно будет вопрос а ну собственно хорошо распределенный поиск это классно но он уже есть да что ты чего что нового вы сделали такого зачем все это и ответа на этот вопрос я надеюсь что будет кейс компании на себя и которую я слава богу могу называть кто такие на себя и во первых на себя это скажем центральные его первое то исследовать институт в соединенных штатах который хочет огромное количество научных статей таксономических данных геномных данных фенотипических данных вообще это такая центральная центральный такой источник данных для огромного количества ученых по всему миру все знают вот is life сайт все знают какой на себя что такое на себя и что принципе позволяет делать у них есть поисковый портал и они в стиле google и позволяют получать по вы пишите запрос тут о том что он да интересно там например вы хотите получить статьи про и кто-нибудь и рак груди вы пишете рога выводом вас то вы выставляете эти с эти статьи которую нашел но почему в чем фишка фишка в том что помимо этого он может выдать вам линки на другие базы когда я как эти ленте образуется например представьте что есть ученые которые пишут статью про утку и он указывает что вот у этой утки значит у него этого у этой конкретной породы утки не и допустим цвет там крыльев такой потому что в таком-то гения у нее есть мутация на таком смещении что коммутация это заметного нуклеотид другим и вот он себя и через свой api портал позволяет выдать придется пистолетом выдача не только самсон статей который отбирает условия поиска но еще и вот таких у данных которые вы запросили связанных то есть это какая-то комбинация рекомендательного и поискового движка в чем собственно было да еще забыл сказать что нагрузки собственно нагрузка у них конечно не глуп но 150 миллионов запросов день они должны обрабатывать i recommend по ответу по отвлекут на один запрос это в общем то да это они текла декларируют что должно быть меньше 300 миллисекунд как они это делали до того как в общем-то стали искать что-то другое у них был свой самописный поисковый движок интерес который хорошо работал был оптимизирован под их конкретные случаи все было хорошо но в какой-то момент они уткнулись то что им нужно расширять этот функционал и по их словам это было дорого и ваше руководство приняло решение смотреть на open source это с одной стороны с другой стороны была кассандра в которых хранили ситилинке вопрос почему кассандр для хранения линков честно говоря не могу найти ответ для себя на этот вопрос до конца могу предположить что ну то есть количество линков у них это там десятки миллиардов линков реально и до какого-то момента этелинг вот эту вот получении этих линков этих рекомендаций она им был достаточно получая получать только на 1 уровень то есть из вот этой базы pubmed в на краю геномную базу данных или в базу данных таксономическую но так как они хотят развивать руководство хотел развивать эту историю им расхотелось доставать линки скажем так не прямые связи когда появляется не прямой связи спекулируя на примере того же ученого который пишет статью про узкую например и тот и тот же ученый пишет статью про это желудку но не указывает там образом мутацию но известно что там что такая вот оборот указывает мутацию но и известно что такая мутация характерно для определенного типу так что это значит это значит что геномная ваза ссылается на базу таксономическую и таких связи на самом деле может быть очень много они как-то там связаны эти базы вот такие такие запросы они хотели как раз поддерживать первое что они сделали они посмотрели власти все очень естественно все смотрят на ластик вещь и что произошло они столкнулись с проблемой сейчас га нежен для меня тоже получения больших выборок данных что такое большие выборки данных и зачем они нужны в большими выборками они понимают выбрать и больше 50 тысяч записей за раз когда они нужны зачем им они нужны потому что у них есть api они только портал и собственно они рекомендуют исторически помочь людям обращаться получая данные данные такими вот кусками большими и они говорили о том что самая большая проблема была с организацией пэйлин газ то есть elastic например при получении 100 тысяч записей со стотысячной за чтение занимает пять минут в нашем случае они такого не увидели и в общем-то приняли решение развиваться дальше с нами в части поискового движка но оставался еще история с линками забегая вперед скажу что они выпали ярангу тоже и сейчас я остановлюсь на этом кейсе подробнее и для этого немножко поговорим о том как вообще в чем проблемы могут быть при работе с определенными графами мое личное отношение к распределенным графом и вообще графом такое если у вас есть какой то какие то данные и вы можете не хранить данные в графе то не храните данные в графе вы сэкономите много себя сил и времени но если все-таки это неизбежно неизбежно может быть это потому что исторически например данные они таковы что они хранятся в графе их очень много и вы не можете просто как они как сконвертировать то нужно что то делать и в случае когда вы ничего не можете сказать про этот graft вы не знаете ничего про топологию то я бы сказал что мало что можно сделать почему потому что этот граф в теории может быть как угодно распределён по вашим baby сервером и когда мы говорим про точечному обходе у нас будет огромное количество над фаркопов который по сути убьет весь этот ваш performance обхода но если мы сможем выделить какой то какой то фичу какой-то атрибут который будет говорить о локальности или а связанности вершин то мы сможем сделать увидеть на следующие мы сможем сгруппировать наиболее связаны вершину в одном месте так что количество на твой папа будет очень сильно уменьшено и общем-то а ранга предоставляет такую возможность есть фича который называется смарт графе пользователь должен вы указать желаемый smart атрибут и тогда ранга постарается максимально компактно расположить этот город на деби серверах вопрос очевидно как выбрать метод smart атрибут тут тут есть разные пути один из них самый простой это когда-то просто вставить на вашу space например уходить игра в социальной сети то такой атрибут ref играется достаточно легко например пользователь очевидно скорее всего имеет больше друзей воды в регионе своего проживания чем за рубежом в другом случае может быть такое что у вас реально такого атрибута нету но вы откуда ты вы можете взять и добавить в ваши например у вершин этот атрибут например у вас есть к стример какой-то который производит вам о какое-то большое количество данных заказов связанных не знаю но при этом с другими красным ли он не общается тогда вы можете добавить этот идентификатор каст и мира например свою вершину и использовать его в качестве smart атрибута в самом плохом варианте вы вообще не знаете ничего тогда вам возможно придется выполнить какой-то ручной при processing например какой нибудь исполнить выполнить службу по погибшим и посмотрите на определить комьюнити которые у вас есть графия и уже проанализировать эти самые к мнению на предмет наличия утопии в этих самых атрибутов как это сделать вы спросите в ранге есть модуль который реализует некоторые алгоритмы по принципу с как прегель мог модуль который армию для для процессинга больших распределённых графов и там реализован алгоритм вот этот вот самый либо про падение что вы можете это просто исполните посмотреть теперь что дает это хорошее распределение по отношению к плохому распределению синеньким это граф с каким-то распределением синий и граф а красный граф это так называемый smart граф и в самом бы в общем теперь в пиковом случае когда нам мы запрашиваем 10000 вершин связанных мы получаем разницу приблизительно в 10 раз на самом деле нужно получите больше зависит от того насколько плохо у вас распределился синеньких граф который отмечен синеньким дальше давайте поговорим о том как можно использовать полнотекстовый поиск с вместе с графами что это может нам давать и вообще когда может быть нужно ну в первую очередь это может быть нужно потому что если мы говорим просто графита мы не знаем с каких вершин нам начать обход как как правило берется какая-то рандомной вершины и мы мы ходим по графу дали бы в ширину либо глубину и что-то пытаемся понять но если мы будем рассматривать граф в первую очередь как плоскую структуру и про индексируем ее нашим а ранга сир чём-то мы сможем взять и получить наиболее релевантные вершины относительно нашего запроса а далее сделать обход относительно этих вершин обход делается обход учили вершина когда это необходимо за это когда это хорошо какой пример можно привести в данном случае это несколько и не такой искусственный пример но это это сделано чтобы подвести последующую space что это за пример это граф связей база данных им который представляет из себя игра граф фильмов актеров и режиссеров которые снимали фильмы из актеров которые играли хватай фильмов что нам необходимо сделать нам мы хотим получить всех все фильмы и список актеров которые советов как от которые играли в этом фильмы и соответственно наиболее релевантные фильмы в первую очередь нашему запросу и как это делается на ранга тебе сколько строчек кода нам нужно фактически нам нужно восемь строчек кода с учетом того что мы делаем агрегацию сортировку еще в этом как-то ограничиваем запись непосредственно поиск сам это вторая строчка на шестой строчке мы видим на пятой строчке мы видим непосредственно обход графа дальше немножко а сам о самом спарринге как скоренько организована в лицо в реляционных базах данных или вообще в базах данных как правило это некоторый magic который нам выдается и мы как ты как ты его используешь мы ожидаем что нам дадут хороший результат мы его собственно дальше будем по нему сортировать его как-то перес вешать еще чего-то но например в том же i'm a secure что происходит есть 2 2 функции два оператора free текста и был и контейн столбу и и эти две функции высчитывают в общем-то один и тот же ринг с точки зрения пользователя возможно но внутри в документации на наших то что а вот здесь мы считаем раненько вот так вот а здесь вот так вот по сути совершенно непрозрачны две функции какие-то функции подсчета рынке г когда то не может хорошо используя подойдет карат не подойдут непонятно в случае рнк search а мы стараемся быть более прозрачной и из коробки предоставляем два самых известных алгоритма развешивания компонентов вектор и этот f&d fbm 25 основы на частотные метрики и что самое главное мы даем возможность их тюнить под ваши задачки вы можете надо в данном примере соответственно я мы считаем б м 25 с некоторыми фондами коэффициентами в 22 выраженных случая bm 1511 еще перри взвешиваем оригинальный score относительно какой-то фиче там которые мы считаем нужно в документе для чего это может быть нужно мы успеем вы решаете задачку суставы и разрабатывать свои модели и фантасти которая должна хорошо работ под ваши данные соответственно вам нужно определить насколько х насколько это хорошо у вас есть очень очевидно какая тестовая выборка и вы должны прочитать точность какое вы находите данные насколько они релевантны ну собственно вы можете выбрав эти данные посмотрев эти споры сравните и что-то подтюнить там дальше и 2 что автоматизирует этот процесс дальше это хотел сказать aficio которая опять же присутствует во всех поисковых дышат абсолютно движках но абсолютно отсутствует в базах данных с поддержкой план текста во поиска это то что называется перед time пустим что это такое вы можете сказать попросите ранга сечь считать что одно условие запросы она более важно для вас чем другое условие запросы и в данном случае мы говорим что так пул он важнее чем то косам для нас и здесь мы ожидаем что документы которые содержат либо большое количество тегов cool она они они будут выше выборки в этом мы только можем это ожидать данном случае потому что фактически инвертированные частота у этого термо может быть маленько настолько маленький что это нам не поможет но все таки да то есть фактически это вы выражаете с ним некое желание никакие хину даете движку что вот я хочу чтобы это такие документы были выше выбрать и теперь давайте перейдем к еще одному из кейсу он опять из вас сайнс это наверное наиболее сложный и space исторически он был показан на выставке борите урок 2016 за несколько лет до н себя и на узкий со который был описан до этого и на данных на себя и тогда мы еще steam-е были знакомы и в чем сложность с логической точки зрения здесь необходимо работать с четырьмя различными разнородными базами данных что это за база и вообще что происходит в первую очередь за синтетические данные то есть это данные которые описываются момент ну состояние организма это это геномные данные что такое бинарные данные это результат секвенирования какого-то геномы человеческого или какого-то существа это по сути набор мутации в генах то есть это замены какой какой то группы нуклеотидов одного нуклеотида другим на определенном смещение с точки зрения данных и там огромное количество джейсона один ген результаты клинер одного гена это миллионы или десятки миллионов джейсон of и это 3 3 набор данных это база данных лекарств которыми когда-либо лечили болезни или будут лечить или какая-то база данных и 4 это ассоциации между всеми этими другими базами данных что такое ассоциации ассоциация это с такие научные публикации в которых были упомянуты все эти базы данных для чего это необходимо представьте что врач имея на руках результат секвенирования человеческого генома назначается лекарство под пациенту с таким-то заболеванием например с раком груди и он хочет право лидировать свой и перед назначением этого лекарства он хочет превалирует свое решение каким образом он хочет смотри какие публикации были и ну-ка как-то скорректировать возможно собственно в чем сложность сложность состоит в том что данные сами данные по крайне мере фенотипические данные это из такой же исторически это направленная цикличный граф и часто бывает такое что в ассоциации в статьях например указан подтип специфичные для конкретного заболевания то есть например какой нибудь карцинома вместо рака ученый пишет я хочу рак груди его словно и если мы не будем учитывать вот эти вот самые связи вот этих самых связанный список специфически конкретного типа заболевания его подтипы он просто ничего не найдем или найдем то что не будет релевантны и мы этого не хотим это первая проблема вторая проблема это количество вот этих вот маленьких джейсон of которые нам необходимо обрабатывать точки эта логическая схема с точки зрения модели данных опять же мы должны работать с графами и работать в стиле о том как я описал сейчас то есть мы проиграем q на какую-то вершину и обходим связано вершину с точки зрения геномных данных это структурированный поиск в основном по джейсоном как я и говорил ну и дальше это ским лес данные с которой легко никогда для которых необходимо полна текст в случае данных о лекарствах ну и статьи также полна тексты и структурированный поиск собственно такой вот кейс был решен с помощью а ранга гибель каким образом очевидно что когда речь идёт о таком количестве данных я такой сложности вот этой вот самой логике поискового движка нам недостаточно просто записать запрос в базу данных нам необходима какая-то обработка промежуточное то есть получить данные что с ними поделать возможно сделать щеку их запрос и если бы мы говорили о классическом 3 3 варианте приложение это означало бы пересылку данных между клиентом и сервером как а ранга решает этот вопрос возможно вы заметили что в левом верхнем углу координатор у нас есть fox такая надпись что такое fox fox это framework который позволяет вам писать бизнес-логику на java script и примечательно то что это бизнес логика будет выполняться в контексте сервера то есть вас не будет готова на пересылке данных на клиент и и дальше вы установите просто крестовый поход на которые уже люди делают запросов фактически это встроенными поддержками кратер уютной архитектуру и в базу данных вот такой сервис был написан и общем то решение было презентовано подводя итог может показаться из доклада что я хочу сказать что берите рангу и выкиньте все свои базы данных которые у вас есть на самом деле нет обычным и мы говорим что то есть не ванда это быстро уже мол за мол авангард роза мол понимая mlp не понимаем модели данных и естественно я думаю что есть огромное количество задач для которых это ну во первых это за числа science где а ранга просто отлично себя показывает потому что исторически там есть вот эти вот страшные данные казалось бы да их огромное количество и с ними ничего не сделал что он включён и пыталась пострадают их производить нет никакого стандарты с ними с этим как надо работать но и для более простых сценариев как я говорил если у вас вы когда-либо собираетесь развивать полнотекстовый поиск начинайте работать с графами вообще в пыль перспективе то имеет смысл посмотреть на рангу ну то есть во первых это open source у нас есть распределенный по масштабирования из коробки распределенный поиск работы с графами я если назовите мне другую база на который умеет делать то же самое из коробки я буду благодарен и немножко про саму компанию то есть хоть и хотя это до сих пор стартап но мы уже чего-то успели добиться сейчас работает у нас больше 50 сотрудников мы имеем больше семи миллионов скачиваний около 8000 звездочек на гитхабе и нескольких больших костюмеров из списка точно 10500 и самое главное мы имеем очень большой комьюнити в нашему слойки сейчас уровень 200 200 тысяч человек и будем рады видеть вас тоже спасибо за внимание задавайте вопросы пожалуйста сейчас микрофон это дед андрей спасибо за доклад давно наблюдаю за вашим продуктом скажите пожалуйста вот вы приводили примеры но я долине услышал то ли вы аккуратненько это скрыли количество документов потому что если мы говорим о документа ориентированных глазах или огров все упирается в количество в общем узлов и документов смотрите в был недавно собст откуда я взял данные на себя и да да на себя я взял не из 107 не мог бы это рассказывать вам не имея официального скажет об утверждении они говорят здесь количество данных от которые они перевели на рамку и ты стара байт тонуть в данном случае то есть все вот эти базы которые или скота запись количество запись я не знаю к сожалению потому что если эта научная статья это может быть 15 мегабайт на научность они они они смотрите но я объясню да значит они безусловно не хранят эти данные в непосредственно сами с вами статья небольшие они хранят джейсон которые которые они используют для поисков что все что в джейсоне дата публикации там допустим поле катках от которой сканка тонированные с других полей для пола сочетание полнотекстового поиска но никто не которые схемка описание они хранят там там в районе 5 5 7 килобайт данных на 1 документ вот считаете это это это то что касается победа вот это глаз новых баз данных пролин prolink я не скажу потому что приятель инков очень много лирикой таких миллиарды то есть я не знаю честно говоря по поводу линков вашим то вот классическая проблемам он у меня там например несколько миллиардов записи я хочу пробежаться и отредактировать какое-то поле это сколько неделя месяц год в к в каждом из документов высоко поднимается память наверняка каждый документ за не зависит зависит от того с какого с какого момента наблюдайте за оральный когда у нее был только m-files движок или когда вы же по его 49 тоже нет предыдущие вот-вот в m-files весна была такая проблема то есть до для для всех скажу что собственно исторически яранга развивалась как in memory базы данных потому что она была очень основана выходцами из специалистами поймаем либо базам данных и но потом в течение время стало понятно что да мы упираемся в памяти делать нечего и тогда взяли как 2 старой чем же вы можете выбрать рокс baby которые соответственно не имеет такой проблемы что все подымается в память вот пусть он подумает память там есть кэш блоков он понимает памяти те блоки если вы это делаете последователи то соответственно вы можете получить все все плюшки и доходы и так далее то есть это не поднять и всего в память ни в коем случае спасибо спасибо за доклад очень интересно вопрос такой основное тут мы активно сейчас против за и mongo db но и другие хранилище тоже убийством клик house основной вопрос вот типовой сценарий для скажем так отличающая ранга от манги ну то есть когда выбирая ранга когда манга и вот еще и сразу несколько вопросов но в контексте ужина я на документ ориентированного хранилища то есть манга основная проблема это количество индексов которые соответственно при поставке там начинается просто перестраивании индексов и также сплит policy есть какой то автоматически когда данные размазываются шар дам ну и наверное еще внешние lookup и если какие-то вещи из коробки которые позволяют грубо говоря подсасывать данные из внешних источников например капли к оси словаре очень удобная штука давайте с конца начну по поводу внешних источников нет часто кого нету по поводу как размазываются данные вы можете указать жарки или несколько полей шапки и соответственно ну как как и я думаю что везде вот далее по поводу когда использовать когда они использовать но смотрите опять же как я говорю в манге есть полна текст в манге есть фактически и яндекс изоляционного мира если у вас есть нагрузка под которой это каким-то образом не справляется то вы можете взять are on research и и получить его и речь заканчивая когда вы не знаете например вашего условия запроса или количество вариаций одного и того же условие таково что не целесообразно иметь индекса такое количество индекса под каждого условия потому что оптимизатор скорее всего не будет просто их использовать вот в данном случае до такой подход конечно лучше плюс если вам нужно или вы предполагаете что вам нужен более менее какой то мы ещё раз то что называется полнотекстовый поиск да опять же имеет смысл выиграв и графам он есть они клиентские то есть на этом все сказано вы постоянно пересылайте данных и то есть бенчмарки могло бы потом стать какую-нибудь ссылку на бенчмарки там есть манга вся эта история и самое главное что они открыты есть данные на которых мы делаем и как мы это делаем и состав каждой базы собственно они вызвали вот когда они публикации очень большой интерес свое время там был и погреться там очень много было шума в комментариях очень было весело здравствуйте спасибо за доклад очень интересно захотелось попробовать конечно же новой есть пару вопросов я не совсем измеренного сквайр или хотел бы услышать по поводу скорости работы потребления ресурсов на даче был то что тестовые данные занимает это 736 гигабайт ужалить а памяти как с этим работать как такового как распределение вообще нагрузки это выглядит давайте повторю да папа папа папа вопрос был по поводу каким о каким как загружается циpкa сколько мы живем память физическая и так далее значит смотрите конкретные цифры я бы сложно привести да потому что есть конкретный пример конкретные данные по поводу того что очевидно если у вас хорошие с при делении шортов то у вас будут равномерно нагруженные тебе сервера если мы говорим про распределенный кейс слушать индиану я считаю что если у вас база данных и вы отдаете серве под базу данных то если они не загружает там 90 процентов на ядро это плохо если зачем она просто стоит и там может быть делать какой-то моим просто не загружает вы полностью мощности с точки зрения обжирания памяти смотрите у нас есть бенчмарки который мы мере как а которыми мы миримся с люси нам потому что ну естественно с точки зрения ранга search а ближайший конкурент отключен потому что та же отсылает сирии мы движок и так далее но они java мы плюсы и помимо того что есть запросы которые так низко запрос по низкой четвертому тему я фиксировал что в тридцать пять раз быстрее этот запрос вполне в нашем случае по поводу памяти очевидным manage вы мы живем меньше памяти также то есть я знаю что многие пользователи ластика они очень как раз по поводу этого жалуются что он очень прожорливый опять же если хотите мы можем расширить это дети вот эти вот как раз результаты вот этих бенчмарков у меня просто сейчас нет на руках или ну я там можно на деталь прям посмотрите шею подадите давайте поговорим в покажу подробнее не проблема наружу из окон source андрей спасибо за доклад за доклад подскажите пожалуйста вот есть первый вопрос вспоминаю вот с мангой была такая история то что там первый протокол синхронизации внутри кластера когда его пробыв марка для сторонние люди то выяснилось что он как вы не безопасно ведет к потере данных вот со ранга вы что-то делали такое и есть сразу второй вопрос который возник процессе когда вы сказали что можно взять а рангу когда манга не справляется и там был вопрос про индексы вот вы можете уточнить я правильно понял что паттерн индексирование в ранге это создавать всевозможные индексы как в космосе без ноги она который предполагается нет это это не так и значит я я я не по неправильно донес свою мысль так как я делал фокус на комбинацию то это это просто будет как бы для меня как для разработчика давид эта всей истории это действительно как бы действительно советоваться с ким эскимо лес то что что пропагандируется космос baby но исторически и большинство костюмеров они используют именно индекса классические японские плюсов каши индексы и так далее почему потому что обновление дорогое опять же если вы на месте кучу анализаторов если вы на месте большие pipeline обработки данных то естественно эти индексы бузы будут дороги в обновлении если вам вас это не пугает да и и вы можете проиндексировать положить эти данные то хей или там если вы можете подождать какое-то время пока это индексируется там какой-то лак да то есть это скажем так чтобы быть честным на текущий в текущем варианте агась очень это называется events elegancies там то есть у вас есть лак в между как очень и им транзакции и момент когда выйти видите данные втором случае это сделано так и в общем то как в этом есть как раз и фишка что кому-то надо это кому то не надо мы работаем над тем чтобы сделать его полон страха за к транзакционному но опять же мы хотим разделов и переключаем им потому что у них не всегда хотите за это платить на уровень на уровне прилла жене сейчас не могу дождаться пока можете вы можете вы можете сказать я хочу дождаться но как райт концерну манги ну типа какой хостинг да вы можете дождаться хоть чего да я хочу дождаться вы дождались фонд спасибо вот по поводу первого ответа того чтобы протестировать как власти именно происходит синхронизация и что данное соответствует на там все еще помню как называется конкретно этот с это джек старк какой не умела я понял ну я так меняю что джексон ему надо платить чтобы он сделал какой-то тест вроде как этим ребятам мне ко мне кажется сном раунде ну то есть я знаю что в комьюнити многие про это спрашиваю то есть я точно точно все что джексона это не тестировал но запись организовывает с таким образом если запрос в мастер шанс прошел ну то есть и опять же если не пошел только в мастер шар и него не все реплики записались то запись считается успешный и в этот момент если все рекс отваливается ему не успели мгла мы потеряем спасибо то прежде не спасибо большое за выход ну вот возможно вы начали нужно отвечать по поводу традиционной модели могли бы подробнее рассказать до примеру к транзакция который большое количество данных и вообще как она устроена свои вы имеете ввиду какой-то патч или вообще вообще авокадо хорошо то есть значит в символ сервере а ранга этого традиционно если выражаясь в терминами реляционных базах базах базах данных на на уровне рядками that в кластере это транзакции сейчас нету то есть в 35 они появятся вот эти самые распределенные транзакции но вы понимаете что распределенные транзакции это вопрос до сих пор не решены до этого висит в 1 поделитесь ими он не решен поэтому всегда есть какие-то свои плюсы минусы и сейчас собственно вот в релизе который будет середине мая дабы вот в общем то и делается первый шаг в сторону этих самых распределенных транзакций общем как то так ну грубо говоря не я этим занимаюсь поэтому я могу не знать всех деталей но грубо говоря у вас выдается некоторые идентификатор когда у вас распыляется запрос ему и соответственно выдается индикатор он кого-то записываются у нее есть какой-то time to lev очевидно который больше чем тайм-аут которую выставили и соответственно если все хорошо все хорошо если что-то упало то ну возможно вас останутся какая такая той консистенции я имею ввиду если трансакций охватывает большое количество данных это все хранится пробитие смотрите в а ранги вы опять же с точки зрения сингл сервера чтобы выполнить транзакцию из несколько состоящий из них 100 низких ставок вы отправляете java java script сниппет который выполняется в контексте сервера вот так то есть все данные которые находятся в транзакции хранятся в памяти ну опять же если до какого-то момента да и , nsa акций охватывает данные больше чем серверной памяти это зависит от того и движка с которым вы используете внутреннего свете если это им files to в это это это будет запихнут в память если рок сгибе он периодически будет флажках спасибо андрей подскажите вот такую штуку я про fox хотел узнать координаторы это все выполняется на новых координаторов и соответственно в достатке у нас появляется нужда доставлять на коп обновлять его вы видите у самого самого приложение ну fox on board the если можно там пару деталей об этом расскажете типа как это было сделано в кейсе этой компании я так положить тот тип это хранимые процедуры например на типа аналог это это java script код графские приложение но вы его упоминали в контексте того что как раз пересылка данных туда-обратно исключается за счет того что есть некоторая логика который выполняется на сервере на нормально на координаты да и соответственно как мы это все догоняем и был кейс помню в туториалов раньше давно что типа отдавайте на фокси поднимать rest так и есть вот это вот и сделал то есть у вас торчит и растянуть воин то есть это не просто условный контекста хранимых процедур каких-то там да а именно это прямо полноценный интерфейс который поднимаетесь на координатора да и если мы это все разворачиваем то координатора догоняют с некоторым отставанием или так далее скажу сколько нот координатор например использует этот incipio смотрите координат координатор и они они не хранят никакой state когда-то не храня стоит там нет данных они хранят и вдоль только у только логику вашу работу ваше приложение вашего fox приложения все данные на них подсасывается тебе сироп когда вы распределяете запрос понятно спасибо"
}