{
  "video_id": "pJnx_O3yy8U",
  "channel": "HighLoadChannel",
  "title": "Проблемы приземления данных из Kafka и их решение на Apache Flink / Вадим Опольский (IT_ONE)",
  "views": 2567,
  "duration": 2589,
  "published": "2023-01-19T06:56:45-08:00",
  "text": "коллеги добрый вечер меня зовут all польский вадим я эта компания эти van date инженером иногда такие компании как лицо в тренинг центр и от уз приглашает меня поучаствовать в проведении онлайн тренингов спасибо всем большое за то что пришли на конференцию кто-то приехал из других городов это очень круто несмотря на всю ситуацию которая происходит сейчас в мире вот так же спасибо тем кто спасибо организаторам вот доклад посвящен проблемам приземления данных исков к их решение на apache fling в докладе будут скриншоты скриншоты из сериала foundation который был снят по одноименной книге азик азимова вот и также будут qr-коды по которым можно перейти на workshop и которыми тоже сопровожден доклад вот соответственно если вы видите q воркута можно взять телефон отсканировать его и потом например после доклада или когда будет время спокойном режиме повторить какие-то вот практические вещи с apache fling о которых я буду сегодня рассказывать вот коротко мы поговорим про следующей проблемы во первых это не равномерный поток данных вот про потери данных при передаче их из кафки в какой-нибудь сторож про скиллинг и масштабирование пробок пресса про проблема мелких файлов на hd fs и еще про разные фичи для стриминга во процессинга давайте представим как будто есть какая-то крупная логистическая компания в которой есть более 50 тысяч пунктов приема выдачи заказов доставок и соответственно клиенты приходят пункты выдачи оформляют какой-то заказ или доставку и вот таких доставок день получается более двух с половиной миллионов вот соответственно каждая доставка порождает набор событий набор событий которые говорят несут какую-то информацию о состоянии например доставки и так далее и таких событий в день получается 500-700 миллионов каждая из этих событий соответственно отправляется курьерами центрами выдачи и пересылки грузов и соответственно все они в реал тайме летят в кафку нагрузка в пике для отдельных топиков может достигать более 500 тысяч событий в секунду для соответственно беда ты и для того чтобы вот данная информация была полезна бизнесу необходимо сформировать историю историю или лог событий на основе которой в дальнейшем можно например запустить какую-нибудь матчевую обработку и в этой почивай обработки но получить какие-то в общем полезные для бизнеса вещи вот удобно для лога событий использовать сторож hadoop file system а для матчевой обработки например spark с другой стороны в стриминге и вбегает ио бывают такие задачи когда нам надо прямо на лету читать события и посчитать какие-нибудь онлайн агрегаты окна и так далее и сгрузить это все в какую-нибудь базу типа силы кассандры ну или еще какую-нибудь накрыть это все рис том чтобы предоставить бизнесу доступ удобный доступ для просмотра результатов с другой стороны в какой то момент времени архитектура может поменяться и например место ходу file system захочется использовать какой-нибудь распределенный кэш на основе по сгрыз а вот или например построить стриминговый pipeline кафка туков к где тоже будет происходить какие-то трансформации важный вопрос когда мы передаем данные из одного стороны в другой это потери и соответственно нас есть три уровня гарантия это мост вантед листву once i y vivance если коротко про у них to it must vans это когда никаких гарантий нету соответственно в источнике у нас то могут быть месседжи 123 24 и так далее а в получатели мы можем терять сообщения или они там будут за дублирована в виде поэтому следующие более как бы интересный уровень гарантий этот лист vans и в случае с артистом мансом мы точно получим все сообщения из источника получим получатели но могут быть такие проблемы когда в получатели месседжи некоторые месседжи будут дублироваться вот и в принципе для некоторых задач big дейта это норм но есть такие задачи которые соответственно требуют того чтобы у нас абсолютно все месседжи которые есть в источнике попадали в получатель и в получатели не было с ними никаких коллизий дубликатов и все это выполнялась в режиме стриминга то есть вот такую передачу для big дейта как вариант можно организовать как стриминговый pipeline который будет работать 24 на 7 соответственно какой же будет прогноз по работе такого pipeline а ну и есть в общем да определенные проблемы проблемы которые значит положит этот pipeline вот давайте рассмотрим эти по проблемы более подробно вот во первых не равномерный поток данных то есть так как у нас событие зависит от собственно бизнеса компании а бизнес компании такой что значит чем больше клиентов приходит в определенное время тем больше у нас событий соответственно в промежуток времени с восьми до двенадцати и например 4 до 8 событий будет много потому что люди имеют свободное время могут приходить соответственно вот что-то заказывать что то отправлять в другие промежутка времени событий будет поменьше и соответственно проблема в том что как при большой нагрузке так и при небольшой желательно иметь одинаковые лет инси вот следующая проблема это ну точнее как бы да не равномерный поток данных и следующая проблема это то что так как у нас big data и кафка это распределенный 2 что есть желание того чтобы и читать эти данные вы учитываете сказки в параллельном режиме вот и в таком режиме значит обработчики могут падать данные могут пропадать вот следующая проблема это так как у нас все работает в распределенном режиме то что будет если бизнес компании будет расти и например через год он вырастет в 10 в 50 раз то каким образом мы можем масштабировать этот pipeline следующая проблема это значит когда так как мы данный и читаем и пишем то чтение особенно из кафки которая в принципе придумана для того чтобы можно было туда что-то быстро записать и что это будет быстро прочитать вот чтение будет происходить быстрее чем запись например на hd с таким образом у нас будет накапливаться какой-то буфер данных и данные из этого буфера могут пропадать вот еще одна проблема популярная для ходу file system это большое количество мелких файлов на выходе ну и соответственно что если значит нам по дороге когда мы читаем и пишем надо делать еще какую то обработку окна и таймеры и так далее вот есть предложение можно же написать код на кафка клайн теперь используя скала java или python и собственно к сожалению это не решит все проблемы вот мы столкнёмся с тем что надо будет поддерживать консистентной в распределенной системе если какая-то часть у нас обработчиков падет другая будет работать соответственно что будет при этом получать или опять же exactly vans будет скорее всего реализован через коммитов цветов вот и разработчик должен будет подумать про это самостоятельно плюс если мы напишем код запустим его то соответственно для поддержки для devops of будет важно чтобы отслеживать состояние работы кода и всех проблем которые соответственно будут там внутри происходить у до того момента пока он не упадет например проблемы с ппш ну и опять же если у нас в кафки партиции и там будет перекос то есть какой-то партиции данных будет больше а мы хотим балансировать при чтении и записи этих данных чтобы файла появлялись равномерно то соответственно вот как это сделать надо тоже будет подумать разработчику поэтому все это может смягчить частично решить проблемы но по-настоящему решить их может apache fling apache флинн когда немецкий стартап с 14 года который написан на java и под капотом у него a-к значит с ростом его популярности alibaba вложил в него 90 миллионов долларов и fling изначально дизайне лс а именно для задач стриминга соответственно он поддерживает processing с гибким механизмам и хранения состояния то есть поддержка состояние в распределенном режиме ориентирован на низкие задержки и высокую пропускную способность поддерживает стриминга вую аналитику и распределена работает на кластере и масштабируется + apache fling есть более 12 коннекторов к самым популярным створ джим который поддерживают чтение и запись в параллельном режиме что важно для задач big дейтон плюс у клинка есть красивую ай пи ай и более тысячи метрик для отслеживания состояния джаббы метрики можно загружать в influx prometheus и потом еще куда-нибудь соответственно мы можем контролировать статус джаббы через впп и вот но в мире инструментов big bay то есть и другие инструменты такие как knife & stream сет кафка connect седой уже apache флим и молодые инструменты такие как гоблин и друид вот у этих инструментов есть определенное ограничение например ustream сет его knife ой нет возможности верси они ровать код в и те что в принципе удобно с одной стороны для разработчиков а с другой стороны для тех специалистов которые работают с продакшеном плюс фреймворк добавлю эти инструменты не рассчитан на реализацию фреймворка например на проекте на котором я работаю у нас была задача разработать инструмент который бы позволял вычитывать данные из одного 100 раджа из кафки вычитывать в разных форматах avro xml джейсон и потом с помощью конфигов можно было бы сконфигурировать в pipeline так чтобы он писал соответственно данные в один из рассматриваемых 100 раджей вот ну и также можно было каким-то образом конфигурировать формат ну соответственно у нас на продакшене сейчас работает более 200 white line of для fling а вот и соответственно доклад сопровожден дима проектом вы можете отсканировать qr-код скачать его в те и повторить воркшопы которые я записал на ю тубе дима проект сделан с помощью докер комп оуза есть генератор генератор отправляет месяцев кафку со скоростью 1000 mah сиджей в секунду соответственно apache fling который представлен координирующей но дай job менеджер и рабочими нодами так менеджер вычитывает данные из кафки отправляет их в hd фск сандру или в кафку в другой топик соответственно workshop с запуском и демонстрации тема проекта можно найти по qr коду презентации вот давайте посмотрим на проблемы и поговорим о том что какие фичи у клинка могут в общем то эти проблемы решить ну во первых не равномерный поток данных который может вдруг образоваться в исходном топике кафки вот тут стоит сказать что под капотом у клинка не только java но еще и а к actors вот который позволяет ну вообще модель акторов такая модель где в каждом факторе у нас работает один thread этот трек последовательно обрабатывает месседжи которые авторы получают и отправляют друг другу асинхронно вот плюс есть изолированный state изолирован соответственно он для того чтобы не было проблем с коллизиями skunk anansie и вот такая архитектура которая как бы реализован офлинг а то есть каждый job менеджер каждый task manager это по сути actor или система акторов акторов которые обмениваются сообщениями в том числе и на кластере на кластере находясь на разных машинах вот она позволяет соответственно во первых имеете очень маленькую задержку в обработке данных с другой стороны обрабатывать миллиона месседжей в секунду и соответственно благодаря этому мы решаем проблему мы решаем проблему с не равномерным потоком данных следующая проблема это падение обработчиков и соответственно риск того что данные могут быть могут исчезнуть посмотрите пожалуйста на слайд вот соответственно здесь нарисую изображен генератор кафка генератор отправляет продюсер отправляет в кафку массаж с номером один соответственно fling вычитывает этот массаж происходит его обработка мы фиксируем значит это сообщение в получатели наш dfs то есть мастер с номером один записывается на hd fs и после этого соответственно мы фиксируем контрольную точку которая называется чекпоинт и в этой контрольной точки фиксируется следующие во первых а в set of sight это номер месседжа в партиции кафки вот и также я предлагаю через механизм состоит а зафиксировать размер файла соответственно каждый месяц увеличивает размер конечного файла на 1 мегабайт вот дальше происходит обработка следующего месседжа массаж попадает наш dfs после его попадания на из dfs у нас фиксируется новый офсет это очень важно то есть это происходит не одновременно сначала мы пишем пишем бизнес информацию потом записываем номер офсета вот и при обработке 3 сообщения мы успеваем его записать в конечный сторож но не успеваем обновить чипа in происходит какая-то авария restart флинн к и появляется вопрос с какого офсета начинать чтение в рестарта ванный джабе так как у нас есть чекпоинты и мы зафиксировали что последний успешно обработанный массаж был мы с номером 2 то можно читать данные с соответственно 2 плюс 1 это в 3 месседжа и если мы это сделаем то у нас на конечном получатели ваш dfs появится дубликаты дубликаты masters номером 3 будет за дублирован вот какой тут есть выход и что можно с этим сделать так как у нас зафиксировано в check point и не только не только в общем номер месседжи но еще и размер размер файла в тот момент когда мы успешно и записали мысль и успели и вазочек воин сеть вот то при рестарте можно соответственно сравнить размер файла фактически с тем и размерам который мы зафиксировали в чекпоинты и в случае если эти размеры будут не совпадать то выполнить команду из dfs файл транг кейт которая у сечет файл в получатели до соответственно размера где у нас когда у нас был зафиксирован корректный чекпоинт таким образом мы удалим третий месяц из hd фрс и повторно обработаем его в ленком но при этом у нас не будет дубликатов на конечным в конечным получателем вот обработка будет продолжаться дальше пойдет четвертый месяц и так далее и можно предположить что это будет exactly vans плюс у клинка есть еще механизм барьеров который также позволяет помогает в этом кейсе в распределенной его работе вот что будет если например у нас будет не ешь dfs кассандра kassandra в получателя и в этом случае мы можем просто фиксировать а в сет и потому что кассандра это кей вылью сторож она и дым патент на к отправки дубликатов то есть сколько бы дубликатов одной записи мне отправили в кассандру в конечном состоянии у нас все равно пройдёт absurd по ключу и мы получим только одну уникальную запись поэтому в случае с кассандрой можно получить exactly vans как в общем говорят for free случае с подвесом можно применить следующий архитектуру когда у нас есть таблица с куда мы пишем бизнес данные вот в эту же таблицу можно добавить еще колонку со все там в этом случае мы будем одновременно записывать и бизнес информацию и одновременно будет фиксироваться офсет таким образом не будет возможность ситуация когда мы сначала запишем бизнес информацию офсет нет и запишем у нас запишется либо целая строка либо не запишется ничего и при рестарте если будет сбой мы просто можем взять максимальный офсет и прочитает следующий месяц за этим максимальным ну соответственно до случае pipeline акков коту кафка можно использовать транзакции которые доступны в кафки по моему с 10 ли с 11 версии и в транзакцию включить запись данных в топик и запись в коммитов сет таким образом если вдруг что-то пойдет не так например с обновлением офсета или записью данных в топик то так как они в будут входить в транзакцию произойдет откат и у нас тоже не будет проблем связана и с тем что значит какие-то данные у нас записались абсент не обновился соответственно демонстрацию рестарта apache fling с примерами того что данные у нас не пропадают они появляется дубликатов можно сделать также пауку аркаду ссылка на youtube вот и следующая ситуация это что если значит так как она стриминговый pipeline что если джабба упала посреди ночи или там были длинные праздники на праздниках вот о поддержке нету вот эта проблема и значит эту проблему в apache fling можно решить с помощью такой фичи как стратегии восстановления соответственно их есть несколько одной из такой стратегии является fix delay fix дела и позволяет автоматически ри стартовать fling джаббу через определенный интервал времени например данный код на java позволяет сделать рестарт флинн кого pipeline а три раза с интервалом в 10 секунд более продвинутая были продвинутый вариант стратегии восстановления является файл url рейд failure rate позволяет не только автоматический рестарт овать жабу на определенном интервале времени но и третичные через определенные интервалы времени но и фиксировать счетчик таких рестартов за определённый промежуток то есть если мы будем использовать файл write с такими конфигами то соответственно джабба будет рестарте c 3 раза на интервале в пять минут и соответственно каждые пять минут счетчик рестартов будет обновляться в последних версиях fling а есть ещё одна стратегия которая позволяет бесконечно ри стартовать fling вот причем время мы задаем время минимальное время максимальное время будет постепенно увеличиваться таким образом когда время рестарта ну точнее как бы время которое между рестарта my достигнет максимума то у нас будет происходить restart через это максимальное время ну и стратегия соответственно если мы не хотим чтобы происходил restart например когда надо pipeline протестировать то соответственно чем быстрее мы получим какой-то эксепшен с причиной того почему этот pipeline упал тем будет лучше для собственно всего процесса разработки то вот в этом случае можно использовать стратегию нам которая ничего не будет делать когда появится какая-то ошибка ну и соответственно да эту стратегию не рекомендуется использовать на продакшене а вот первые три вполне могут подойти соответственно такие фичи fling а как сейфа in check point и restart стратегии восстановления позволяют решить проблемы с падением обработчиков и с коллизиями в данных следующий вопрос это горизонтальное масштабирование и значит в чем тут проблема так как у нас поток достаточно большой и кафка это распределенный сторож то силами одной машины мы его обработать ну как бы сможем но это будет там не супер продуктивно поэтому хорошо бы чтобы мы могли распараллелить эту этот pipeline на кластер который состоит из машин ограниченной мощности соответственно давайте посмотрим на fling на fling pipeline из чего он состоит прежде всего это группа операторов source который вычитывает данные из кафки или откуда-нибудь еще вычитывают события каждое событие это вот какое то значит события из бизнес-процесса вот в дима проекте каждое событие представлена набором field of java класса это и delivery а иди и статус доставки время координаты айди курьера и так далее соответственно следующая группа операторов это abra операторы обработки например там фильтрация трансформация группировка что-нибудь еще и все это замыкается sing-sing эта группа операторов которые позволяют результат записать в конечный сторож вот каждый pipeline в клинки для того чтобы вот его реализовать необходимо написать код на флинн поддерживает java скала и в последней версии python и как примерно будет выглядеть этот код соответственно source операторы да и значит дейта у клинка это дейта стрим он типизированный соответственно delivery райт классом ну в общем как в спарке д стрим либо в тракте это стриминговый dataframe вот соответствие мы получаем дейта стрим из source кафки дальше происходит обработала обработка здесь используется ту string но конечно так делать не стоит если вам надо только привести к ту стринги но для дима проекта это вполне подойдет и значит все это замыкается сен com оператором sing вот кто знаком с okay so к stream то значит соответственно это немножко похоже на и пиалки стрим вот коллеги посмотрите пожалуйста на код и здесь в этом коде нету ничего про распараллеливание джаббы с помощью там каких-то java скала инструментов вот преимуществах линка в том что он распараллелить pipeline сам и сделает это на кластере то есть в кластере у нас будет создан и task manager и и соответственно каждый task manager может работать на отдельной ноте но с точки зрения разработчика это будет 1 pipeline который будет работать распределена и не только на кластере но также и внутри самого самого task manager а внутри фото контейнера или ноды у нас может быть при достаточном количестве ядер поток раз параллелен на несколько слотов соответственно это очень коррелирует с тем что у нас и источник распределенная система которая распределен по partition и брокерам и получатель соответственно у нас тоже это дата ноты вот который состоят в которых данные хранятся в блоках вот а еще apache link соответственно дружит с такими ресурс менеджерами как yarn кубы и массаж и еще он может работать в режиме standalone в общем точно также раз параллели вопрос с соответственно qr-код на ссылку вот где есть workshop с примерами того как как мы можем в общем pipeline в один поток перезапустить добавить нот в кластер и соответственно в общем никаких проблем не будет также в этом воркшопе есть кейс когда например что будет если значит при достаточном количестве ресурсов в кластере мы захотим но там сымитировать аварию например какие-то ноты которые будут на которых будут крутиться task manager и этот task manager и будут обрабатывать информацию вот что будет если их прибить вот как поведет себя fling поэтому я предлагаю всем посмотреть значит fling работает с одной стороны в распределенном режиме на группе машин ограниченной мощности в кластере и также позволяет удобно горизонтально масштабироваться то есть вот эта проблема тоже закрывается следующая проблема это когда у нас ну так как мы данные и читаем и пишем то может быть такая ситуация когда чтение данных будет происходить быстрее чем запись в этом случае у нас между читателем и писателем образуется буфер данных и этот буфер данных не может бесконечно расти с течением времени с ним что-то будет происходить месседжи будут либо скидываться с конца либо сначала либо джабба вообще полностью упадет вот соответственно да соответственно вот на слайде и собрать изображена такая ситуация когда у нас есть source source очень быстро данные вычитывает отправляет их дальше на следующую группу операторов с трансформацией а вот трансформация работает медленно она работает медленнее чем source и поэтому у нас где-то между образуется буфер соответственно данные из этого буфера могут пропадать вот у хэнка есть встроенный ппш механизм который позволяет информировать например source данном случае так чтобы source выполнял чтение медленнее чем ну чем в общем его там максимальная скорость таким образом значит pipeline будет распределен более равномерно и у нас не будет ситуации когда переполняется буфер и данные соответственно могут пропадать кроме того в юар и в метриках мы можем также отслеживать вот это вот рост переполнения данных вот это очень удобно соответственно встроенный механизм бэк пресса позволяет решить проблему с пропускной способности skype пропускной способности получателя вот когда она меньше чем у источников следующие значит проблема это неконтролируемый размер файлов на выходе вот соответственно кто работал с ходу пам с автор джами наверное слышали или может быть сталкивались с такой проблемой как когда есть много мелких файлов например по одному мегабайту вот так как наш dfs есть координирующая но до на им надо вот вот вся информация о именах файлов файловой системе и их расположение в кластере надо то нотах она содержится в оперативной памяти и чем больше у нас файлов тем больше записи в этой оперативной памяти соответственно эта проблема у клинка также предусмотрено вот и решить ее можно следующим образом то есть fling имеет интерфейсы для работы с файловыми системами значит изначально это эти интерфейсы были представлены баки тен-тен компотом он значит был переписан на streaming файл sing и значит сейчас этот интерфейс называется файл sing файл sing позволяет поддерживать работу с такими сторожем как hd фсс 3 и локальная файловая система вот а также поддерживает популярные структурированные форматы avro паркет и арк ну и различные слабо структурированные форматы типа джейсона текстового файла и так далее соответственно вот код с помощью которого мы можем во-первых указать таргет то есть конечную конечную цель куда мы данные будем записывать и некоторые политики вот одно из этих политик является значит максимальное время то есть после которого у нас будет происходить отсечка файла файл будет закрываться будет создаваться новый файл вот еще один параметр это инактив интервала который позволяет случай если у нас вдруг месседжи перестали идти из кафки не держать наполовину заполненный файл открытыми открытым а подождать 5 секунд это же его закрыть и значит киллер параметр это максимальный лимит файла который допустим на получатели то есть мы можем например указать что максимальный размер файла может быть 200 мегабайт в этом случае значит когда у нас его размер будет достигать двухсот мегабайт то файл будет автоматически закрываться и на получателя мы будем получать примерно одинаковые файлы примерно одинакового размера собственно да эти файлы могут быть соответственно в трех разных состояниях во-первых in progress это когда мы все еще пишем месседжи в файл pending это когда запись уже завершена но мы его еще не за к метели и финиш то есть когда очередной файл готов к обработке собственно гибкие настройки полирования файлов для получателя позволяют решить проблему с неконтролируемым размером с мелкими файлами на hds вот что касается стриминговый обработки то есть если у нас соответственно не только in put out вот операции но еще и хотелось бы что-то посчитать на лету вот сделать соответственно это можно с помощью следующих фичей мы их не будем так подробно рассматривать но соответственно можно это сделать самостоятельно или там тоже есть еще один workshop ну во первых это то что apache fling поддерживать не только streaming но ибо чую обработку в последних версиях они реализовали также batch плюс стриминге есть поддержка работы состоит он соответственно если стоит у нас очень большой туфли нг очень хорошо работает рокс дбм в этот базой который запускается на каждом таск менеджере вот кроме того он поддерживает работу с окнами это и там блин окна и скользящего окна саша на окна и global окна куда будут включены все данные вот кроме этого fling стриминге работает процесс time on ice event ой мам и в иван тайме есть поддержка вотермарк of то есть очищение данных которые чуть-чуть опоздали с приходом вот очень классная штука у клинка это таймер и с помощью таймера можно реализовать alarming сложную логику обработки месседжей вот еще одно значит одна из свечей это join стримов можно joy нить стримы причем даже использовать небольшой гуфер если у нас какой то и стримов данный в каком-то и стримов будет запаздывать вот ну базовые операции фильтрации группировки различные трансформации обогащение дедупликации и так далее и значит а синхронная запись в несколько получателей то есть если мы читаем данные из кафки и хотим записывать их и с одной стороны и на из dfs и в кассандру и куда-то еще и соответственно еще один небольшой workshop который также можно посмотреть вот небольшой life минут на пять на десять собственно да fling поддерживает стриминга вую аналитику и таким образом закрывает последнюю проблему вот которая представлена в этом докладе предлагаю подвести выводы у нас была задача был поток данных данной летели в реал тайме в кафку соответственно был вопрос о том что выбрать для того чтобы эти данные обрабатывать формировать историю делать еще какие-нибудь агрегаты вот мы рассмотрели проблемы которые собственно могут появиться и это не равномерный поток данных падения обработчиков горизонтальное масштабирование разница в пропускной способности неконтролируемый размер файлов и еще различные фичи для стриминга вы обработки ну и собственно рассмотрели подробно такой инструмент как apache fling и как он может решать эти проблемы у apache fling а к под капотом у него есть контрольные точки стратегии восстановления он позволяет очень удобно горизонтально масштабироваться есть встроенный ппш механизм вот плюс значит есть гибкие настройки полирования ну и поддержка различных стриминговых компьютером на этом всё всем спасибо можно значит ну да наверно обсудить вопросы в общем доклад можно будет сегодня или значит завтра на стойке а ить иван приходите буду очень рад пообщаться соответственно время 12 часов 1600 я буду на этой стойки и буду готов в общем поделиться опытом знаниями вот возможно кому-то это будет полезно ну собственно да мои контакты также можете писать телеграмму личку вот еще раз спасибо что очень досидели до конца спасибо вадим мы тоже тебя хоть и вручить как бы еще подарок от конференции вот держи такой классный мешок круто скажи частоты сам делал скриншоты из сериала и да прям сидел кстати да очень классный сериал советую всем посмотреть вот от компании apple двадцать первом году вышел вообще мне очень понравился я очень обрадовался когда узнал что в конференции тема будет именно foundation ази kazimova да давайте буквально вот один вопрос потом остальные вопрос уже принесли туда в цифровой кулуара потому что у нас именно в этом зале еще будет вижу х потом да спасибо большое за доклад можно попросить слайд ссылкой на git хоп чтобы сфотографировать это не вопрос да пока задам вопрос было написано что можно писать логику на питоне интересно как мысли overhead на это все питания еще медленнее это работает или это все трансформируется во внутренней конструкции честно говоря я не пробовал фильмах анапа это не у нас на продакшене используется скала но могу просто предположить что скорее всего да потому что task manager и которые непосредственно выполняют работу вот для того чтобы эта работа была возможен надо транслировать код который пишет разработчик то есть там по процессу получается мы пишем код оборачиваем его в jar ник этот жар них отправляется на джок менеджер и job менеджер уже рассылает модифицированный код на task manager и то есть вот эти вот кусочки которые у нас находятся в ли андах скалы java соответственно чтобы и вот в случае пайтона у нас ничего не меняется то есть на самом таск менеджере это все равно java код просто в процессе происходит ивану кода генерации кода генерация на java на основе python кода ну вот при запуске может быть overhead плюс также на пайта не ну по крайне мере в спарке я сталкивался с таким что недоступные некоторые функции там я не знаю работы состоит он или с чем-то ещё окей спасибо спасибо отлично давайте на этом еще раз поблагодарим вадима спасибо спасибо коллеги"
}