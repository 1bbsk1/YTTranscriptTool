{
  "video_id": "vxtSbPgYsT4",
  "channel": "HighLoadChannel",
  "title": "Что нового в плане мониторинга в PostgreSQL / Алексей Лесовский",
  "views": 3597,
  "duration": 2723,
  "published": "2022-03-21T13:13:02-07:00",
  "text": "всем привет меня зовут алексей лисовский и доклад про то что нового есть в паз где сколь в плане мониторинга охватывать я буду версию 13 и 14 13 версия вышла год назад в прошлой осенью 14 версия выйдет если мне не изменяет память 30 сентября то есть буквально через неделю-полторы вот пару слов о себе кто и такой я начинал карьеру системного администратора работал долгое время с индексами через какое-то время столкнулся с посольством начал администрировать его и потом уже в компании даты город я полностью сосредоточился на the ministry ранее под gresso в компании я уже проработал примерно семь с половиной лет и за все это время сталкивался в основу с посвистом ну и со всякими штуками которые вокруг подгрести сама компания занимается исключительно посредством консалтингом и обслуживанием вот среди своих любимых тем я люблю заниматься мониторинга my люблю статистику люблю различные визуализации и люблю сравнивать различные системы мониторинга их функциональности чем они отличаются друг от друга свободное от работы время люблю программировать и являясь автором таких утилит как пиджи центр но эссе bsdf и коллектор метрик для про метался погаси так вот как я сказал на предыдущем слайде я люблю мониторинге первая система мониторинга с которой я столкнулся это было когти наверное больше десяти лет назад это довольно-таки просто я рисовал к графиков построена на базе держит дату я с ней поработал какое то время потом столкнулся забег сам запись поразило меня своими возможностями по кастомизации и я долгое время работал именно zabbix он писал для него различные модули различные штуки чтобы мониторить различные сервисы редис и кэш и и так далее какое-то время короткая поработал с nike а сам а после zabbix он мне показался немного устаревшим вот и последние семь восемь лет я работаю с правительством с 2014 года у меня очень нравится и у меня очень хорошая в нём экспертиза но если говорить про postgres то в плане мониторинга после 100 есть тоже много всяких инструментов но если на них посмотреть детальнее так как правило какой-то агент который ходит в базу забирает данные какой-то простенький ей который рисует какие-то графики поверх всего этого раньше я и были у каждого мониторинга свои но последнее время тенденция идет к тому что люди просто берут графа ну и в graph они рисуют нужные для них даже борды очень удобно так вот если мы посмотрим на все эти мониторинге то окажется что под капотом всех этих мониторингов находится под крестовый статистика коллектор корректор статистике это встроенная в париж подсистема которая предоставляет интерфейс и для отдачи всяких метрик наружу через вскоре интерфейс если открыть эту ссылку то можно будет видеть длинную-длинную длинную портянку документации в ней описано что такое stats коллектор для чего нужен какие данные может отдавать какие под систему мониторить и очень много информации о нем в общем то там всего 2 примитива это функции и на основе этих функций сделаны представления так называемые вьюки делая сколь запросы к этим духом мы можем получать данные и собственно к этим и сколь духом обращаются все агенты мониторинга и получают данные то есть здесь заключается вопрос что в каждой новой версии получаются добавляются новое представление новые видюхи и с каждой новой версии мониторинг становится все обширнее обширнее так вот если представить адрес видя такое то упрощённые диаграммы разделить каждую там под систему прогресса в отдельный блок то получится примерно такая диаграмма и если мы возьмем все вот эти вот в ухе и функции которые есть stats коллекторе и наложим их поверх этой диаграммы получится примерно такая картина блоков много и функцию еще больше то есть в этом все можно довольно-таки легко запутаться и как бы растеряться с новой версии с 13 14 добавилось еще больше новых функций и как бы во всем этом как бы ориентироваться довольно таки становится сложно так вот в этом докладе и я расскажу что нового появилось 13 и 14 версии почему это появилось как было плохо жить без этого в предыдущих версиях и как этими штуками пользоваться вам если вы работаете с базами данных свой доклад я условно разбил на семь частей в каждой части я буду описывать какую-то из по систему после stylist какую-то из проблем и первая часть она связана со временем поднимите руку кто знаком с view high пгс that activity есть да есть несколько рук просто так 9 на мой взгляд очень клёвая вьеха она позволяет смотреть текущую активность если в базе возникает какая-то проблема это первое место куда нужно зайти посмотреть что происходит но как правило ее бывает недостаточно если мы видим какую-то долгую активность там долгий запрос долги выполняющийся wacom у нас нет представления о том когда он закончится мы можем представить что наверное он закончится через 2 минут или 20 минут посмотрели через 20 минут он все еще выполняется но наверное закончится через 30 минут и это тоже будет неправильно я приблизительно и такая вероятностная оценка начиная с версии 96 ситуация стала лучше и начали добавляться прогресс в ухе это штуки которые показывают прогресс выполнения других операций в 96 добавили юху для отслеживания вакуумов в 12-ой версии добавили стихи для отслеживания операции создания индекса индекса и операции типа кластеризации таблиц по индексу и вакуум full так вот в новой версии в 13 добавилась еще одна такая же вьеха она по названию можно понять что она для треккинга операций она лайза что такое она lays on a light это сбор статистики о том как меняются данная в таблице качественное или количественное для планировщика чтобы планировщик мог делать нормальные планы для запросов так вот что у нас появилась у нас появилась эта муха и в ней мы видим этап операции то есть мы уже представляем в каком месте выполняется оно лайс уже примерно представляем что происходит у нас есть информация о размере сэмпла который нужен этой операции и сколько обработано байт страниц в этом ст м при то есть мы уже можем делать процентные какие-то вычисления и примерно предположить когда у нас закончится операция ну и есть поддержка портится неравных таблиц когда у какой-то таблице есть много дочерних таблиц и мы можем по этой вики смотреть когда закончится выполнение обработки портится не раны таблицы но и самое главное есть поле перейди идентификатор процесса с помощью этого поля мы можем делать join из поста такие типы galax и брать оттуда расширенную информацию это может быть время транзакции это может быть состояние сессии адрес клиента порт это могут быть какие-то ожидания на чем допустим завис этот процесс то есть это очень полезно и поле которая позволяет получать доку информацию плюс можно присоединить пирилакс и получить блокировки то есть на мой взгляд это очень круто но это не все добавилась еще одна прогресс юха также в 13 версии она связана с трекингом резервных копий есть такая утилита по gps бэкап и у нее есть специальный ключик который показывает прогресс выполнения взятия резервной копии это было довольно удобно потому что резервная копия она выполняется довольно долго если база большая и тогда utility ты запустил ты видишь что у тебя выполняется прогресс и когда он примерно закончится но с точки зрения самого подгрести это посмотреть было нельзя и вот в 13 версии появилась это вьеха можно уже со стороны сервера посмотреть выполнение резервного копирования и примерно спрогнозировать когда оно закончится опять же у нас есть этап операции мы можем посмотреть когда на каком этапе делается резервная копия есть полный размер сколько нужно отправить данных и и уже сколько отправлено то есть мы можем опять почитать проценты примерно прикинуть сколько осталось ну и опять же можем соединиться с погоста такие типа голов и взять информацию о том откуда запущен backup на таких блокировках он возможно висит и расширенная информация уже из этих views последняя прогресс юха которая добавилась в 14 версии она связана с трекингом операций копии что такое копия это обычно логические дампы через утилиту по годам в которые берутся либо восстанавливаются через утилиту по гористой это начальное копирование таблиц при использовании логической и репликации когда у нас есть публикация есть подписка и мы какие-то таблицы стримим на удаленный сервер о логической репликации начальная загрузка то близко от раз таки осуществляется через копии либо это прямые вызовы команды копи пользователям то есть пользователь захотел загрузить какую-то таблицу файл либо наоборот в таблицу загрузить данные из файла и как раз таки вот это вьеха оно позволяет отслеживать прогресс выполнения и примерно понимать когда у нас закончится эта операция не висит ли она на чем-нибудь не заблокирована ли она и нет ли там каких-либо проблем но опять же классический набор полей это детали копи команды по ней мы определяем что за команда до запущена на для выгрузки данных или на загрузку данных сколько у нас байт обработано сколько строк мы сможем снова можем строить проценты и в процентах видеть прогресс выполнения ну и пойди для соединения с пк goes to take these типа белок можно смотреть блокировки ожидания это очень полезно про это обязательно нужно помнить что еще но впк startactivity как бы можно видеть не только долгую активность там по вакуумом о копия операциям даже простые д м л д д лиза просто тоже могут выполняться долго хотелось бы в будущих версиях что появились тоже прогресс юхи для треккинга прогресса выполнения там чек-поинтов ддл операции dm или запросу если это появится это конечно будет очень круто информативно следующий раздел также связан со временем и снова pg startactivity когда мы смотрим в ппс атаки эти мы можем получить информацию о том когда запустилась сессия когда запустилась транзакция запрос или когда поменялся state состояние процесса но прогресс тот activity не удобен тем что это снимок мы работаем со снимком и данная между двумя стенками нам остаются неизвестны но тем ни менее при работе с одним снимком мы видим a state процесса что нам это дает условно говоря у вас грязцова воссоединения есть несколько состояний условно говоря есть хорошие есть плохие условно говоря можно представить что сессия ничего не делает она находится в состоянии idol и ждет запроса от приложения когда приложение присылает запрос соединение начинают его процесс разгаре совы начинает его обрабатывать читать какие-то данные и результаты выполнение этого запроса потом отдает клиенту это активное состояние плюс есть два отрицательных таких плохих условно говоря состояние это состояние открытой транзакцией когда приложение с помощью команды бегин открывает транзакцию что-то в ней делает изменяет может быть какие-то строки читают какие-то данные потом уходит обратно в приложении и оставляет транзакцию открытой в это время в подгрести эта транзакция как бы может удерживать какие-то блокировки на другие строки вакуум не может вычистить эти строки то есть очень частое нахождение в таких состояниях она как бы негативно влияет на производительность самого полиса поэтому их следует избегать и она как бы считается негативным есть еще 5 экзотический state но он практически не встречается и в документации как бы помечен как не рекомендуемый для использования вот идет fast pace функции так вот в точки зрения мониторинга очень часто возникает вопрос а сколько времени наши сесть и проводят вот в этих состояниях то есть сколько времени сесть и проводят в хороших состояниях и заняты полезной активной работой и сколько времени они находятся вот в этих негативных состояниях и тратят время впустую если мы возьмем практически любой пожгли совы мониторинг есть вот такой классический график соединений мы берем из подвес от activity снимок берем разбивку по состояниям и рисуем график то здесь у нас есть какие-то процессы они находятся в каких-то состояниях если мы возьмем то что появилось в новой 14 версии у нас появились новые расширенные метрики которые позволяют нам считать время проведенное в сессиях впг стадо the bass появилось две группы полей первая группа показывает время проведенное всей всех вторая группа показывает статус и завершения сессии то есть нормальная сессия завершилась либо была какая-то ошибка она была завершена принудительно может быть какая-то аварийная ситуация возникла то есть мы по этим счетчиком можем отслеживать поведение и нормальность поведения приложения при работе с базой то есть это ну очень круто мы можем прийти к разработчикам и уже с конкретными цифрами сказать что вот здесь как бы приложение работает не оптимально нужно что-то в ходе как-то провести оптимизации чтобы время баз данных тратилось более рационально сравним два графика первый график верхней это классический график да на основе состояний и процессов он собственно у нас статичный ничего не отображает никакой динамики нижний график построен как раз таки на основе метрика вот этих новых сколько времени проведена в сессиях и здесь видно что приложение очень много времени 0 относительно много времени занималась выполнением запросов то есть на одну секунду реального времени база данных 2 секунды выполняла запросы какие-то и в какое-то время приложение перестала выполнять полезную нагрузку и перешло в состояние idol то есть нас время активно я перестала считаться и процесса у нас просто проводит времени в состоянии idol ожидая когда приложение отправит запрос и здесь мы уже можем более точно оценивать то куда тратится время работы базы данных сравним сайт ул transaction внизу нижние графике это классические графике то есть у нас есть опять же соединение с разбивкой по статусам этот график который справа и слева это длительность транзакций то есть видно что вот есть зеленые такие пятнышки какие то есть транзакции которые занимают там до 2 4 секунд вот но как бы сколько времени тратится непонятно с помощью новых метрик мы можем конкретно увидеть сколько времени уходит на эти вот этой транзакции в конкретно в этом случае на одну секунду времени ну реального человеческого времени уходит 4 секунды времени базы данных то есть у нас четыре секунды приложения где-то там что-то делает чем-то занимается непонятно база данных при этом находится от состоянии открытой транзакцией и ждет когда приложение и закроет то есть это более уже такая точная оценка которая позволяет нам эффективно отслеживать работу приложений давайте посмотрим на другую группу счетчики завершения сессий опять же классический график сверху показывает нам состояние соединений и нижний график здесь я стимулировал заведомо обогнут а и приложение когда на каждый запрос создается отдельно и соединение это неправильное поведение приложение в целом которое следует избегать дело в том что создание соединения в подгрести но не бесплатно и довольно таки ресурсоемкая и в данном случае приложение она работает медленнее чем могло бы то есть время которое тратится на установку соединения и на его завершения она как бы могло бы быть потрачена приложением на то чтобы исполнять запросы вот и такую проблему на самом деле в реальной жизни довольно тяжело искать в под глист не предоставлял раньше не этих инструментов для этого и приходилось точки зрения операционной системы смотреть что происходит там нужно было ставить количество форков это как бы не тривиально было особенно там где доступа к операционной системе нету вот сейчас есть эти метрики в подписи стала жить чуть лучше плюс есть еще аварийные статуса завершения соединений которые тоже также желательно отслеживать следующий раздел про планирование что такое планирование условно говоря выполнении запроса можно разделить на 2 части построения плана и затем выполнении запроса согласно этому плану и в под греси есть всего было всего два способа как можно получать данные по тому как работает планирование есть ручной способ с помощью explain а мы можем взять какой-то запрос передать его команде explain посмотреть какой получился план это удобно для какого-то дебаггинга каких-то отдельных запросов второй вариант полуавтоматический мы можем взять расширение off to explain настроить его чтобы при достижении какого-то порогового значения план этого запроса записывался в журнал потом мы идем в журнал гриппа и мы его ищем нужные запросы ищем нужное планы их как-то анализируем то есть полностью автоматического сбора статистики не было в 13 версии в пгс the statements добавилось статистика которая сохраняет себе время потраченное на планирование запросов существующие поля связаны с временем выполнения они были переви но ван и в y time и вдобавок к ним добавились поля лентами то есть у нас есть время потраченное на планирование время потраченное на выполнение и время потраченное на вот вывод то есть мы уже в пгс the statements можем конкретно посмотреть сколько ресурсов тратятся на выполнение запросов то есть это очень круто но тут есть нюанс по умолчанию она выключена его нужно включать отдельно выключили связи с тем что в некоторых инсталляциях tracking этого времени планирования может давать некий her head к выполнению запроса вверх от на уровне 1 процента но в каких-то нагруженных инсталляциях это может быть неприемлемо поэтому у нас печать отдельно кроме того в ппс the statements добавили отдельный флажок который показывает уровень выполнения запроса что это такое ну себя в практике на практике используем построение отчетов на основе пгс that statement то есть мы берем условно говоря сумму по всем запросам потом для каждого запроса считаем вклад вот этого запроса в основную этот суммарную утилизацию и считаем процент и так мы выискиваем как бы основные жадные до ресурсов запросы чтобы потом их можно было оптимизировать так вот есть уровень выполнения которое регулируется параметрам трек можно отслеживать запросы верхнего уровня и можно отслеживать запросы включая вложенный уровень то есть допустим нас есть функция внутри функции есть еще какие-то запросы то есть пгс the statements можем настроить таким образом чтобы считать и время выполнения функций и время выполнения всех вложенных запросов но тут есть проблема если мы в таком случае считаем суммарные агрегаты мы статистику считаем дважды и у нас вот эти вот totals и они посчитают ну считается криво соответственно чтобы решить эту проблему нужно как-то разделять вложенный уровень и от верхнего уровня и вот как раз таки в 14 версии появился флажок top level он позволяет решить эту проблему и наконец-то статистику можно считать уже нормально не ориентируясь на то что там мы не знаем а уровне выполнения кроме того опять же в пгт statements добавлены некоторые небольшие улучшения которые делают его еще лучше и еще полезнее например tracking количество строк для служебных операций раньше мы в подвести не было этой информации и как бы у нас не было полной картины о том сколько строк возвращено в результате нагрузки в результате запросов сейчас это немножко потеряли и для служебных операций также есть статистика это + добавлена дополнительная брюхо служебная пгс the statements info она показывает количество dio локации когда впг состоятельность и хватило места для статистики и ее размер нужно под увеличить плюс добавилось статистика утилизации байтах и блога поднимите руку кто знает что такое вред а hotlog writer's block по сути это как бы штука которая гарантирует сохранность данных прежде чем изменить данные мы эти изменения записываем во вратах этлок потом уже меняемся сами данные если произошла какая-то авария в базе данных база данных запускается читает в реках и блока накатывает все изменения согласно этому в red hat логу на данных и продолжает работу то есть так как бы реализован механизм надежной записи ваших данных в базу так вот в right ahead лак он довольно таки ресурсоемкий и если он работает запись журнала работает медленно то это напрямую сказывается на скорости выполнения запросов и теперь с помощью вот новые добавленной статистики мы можем по каждому запросу посчитать сколько было сгенерировано в рейдах и блога вот и следующий раздел он как раз таки посвященный проектах и блогу потому что вот в новых версиях как раз таки есть дополнительные вещи связанные с его отслеживанием и так мы можем посчитать через пгс the statements сколько у нас записано в реках и блога то есть мы можем условно говоря про суммировать все эти значения и получить какую-то общую статистику по серверу построить какой-то график рейд и отслеживать пике записи в реках и блога есть другой способ он более такой упрощённый можно взять текущую позицию в журнале транзакции и сравнить с нулевой отметкой мы получим такую большую цифру это будет как бы количество байт записанных в родах и блогом за всю историю за всю историю жизни сервера условно говоря мы опять же по этой величине можем посчитать график ритой посмотреть какие у нас есть пике провалы во время записи в рай так и блога но теперь все это не нужно с 14 версии появилась отдельная юха которая позволяет всю эту статистику получить из одного места без прибегания к всем этим как бы обходным путям у нас есть теперь статистика по тому сколько записей записанного это шерлок сколько f5 страниц сколько байтов записано то есть мы уже можем иметь количественно и качественные характеристики как у нас утилизация в реках и блога происходит есть информация о том когда не хватает буферов для записи вал и мы можем уже подкрутить конфигурацию раньше этой информации вообще не было и приходилось опытным путем как-то там высчитывать какой нужен размер буфера чтобы его потом выставить в конфиге другая клёвая штука это время потраченное на записи синхронизацию теперь можно по этим метрикам смотреть тормозов производительности запихивал раньше-то приходилось делать через операционную систему мы смотрели на литинский дисков на утилизацию дисков и по ним как-то косвенно предполагали что ну наверное запросы работают медленно потому что диски тормозят и как бы все медленно работает теперь можно просто смотреть по метрикам времени и напрямую сказать что у нас запись запросов тормозит потому что у нас много времени уходит на запись вал есть это как бы стало гораздо все проще ну и отвечу что вал также трека ица в пгт statements как я сказал раньше он 3 стал трек отца в утилитах типа explain и off to explain эта информация о том сколько было сгенерировал теле появляется там и появилась информация о том сколько волос сгенерил of the vacuum но эта информация обычно попадает в журнал системы следующий раздел связан с памятью в операционной системе linux довольно сложно довольно сложно посчитать память сколько памяти занимает один процесс потому что сама по системе виртуальной памяти довольно таки не простая и там есть объем памяти который затребовал процесс объем памяти сколько он сейчас используется есть активные неактивные списке есть файловой анонимная память плюс но это все накладываются большие страницы и посчитать ну если говорить конкретно про под grease посчитать сколько памяти занимает под крестцовый процент процесс довольно сложно я привел ссылку на статью где один из разработчиков пузыри со андерс описывает как он искал overheat на утилизацию памяти по с крестовым процессом там часть его на примерно 10 15 минут вот кому будет интересно почитайте но суть в том что любой взятых им способов как бы он с погрешностями и не дает точной оценки так вот начиная с 14 версии появилась функция которая позволяет с точки зрения под глиста показать раскладку утилизации памяти у нас есть информация о том для чего выделено это память для чего она используется то есть мы можем уже с точки зрения под глиста знать о том где какой сегмент какой по систему используются и для чего и есть статистика об утилизации сколько всего байт сколько использован насколько свободно но есть нюанс как всегда это муха она показывает утилизацию текущей сессии то есть вы подключаетесь к полюсу для вас создается сессия вы сделали какие-то запросы погоняли потом этой функции смотрите раскладку памяти чтоб посмотреть раскладку памяти другого процесса нужно вызвать другую функцию ей передать идентификатор процесса и она сделает дам раскладки памяти в журнал под крестовый на мой взгляд это не очень удобно но все-таки то что появилось уже лучше чем ничего раньше мы с точки зрения операционной системы смотрели на всю эту картину и не имели точные оценки сейчас можем хотя бы это использовали ства посмотреть и получить точную информацию сама функция больше всего пригодится в случаях когда нужно добавить какие-то старшины и случае там связанные с утечкой памяти либо если кто-то разрабатывает отгрыз им тоже будет полезно смотреть эти функции чтобы понимать что написано и функциональность как бы не течет следующий раздел на мой взгляд посвящен двум статистикам которые ну самые часто используемые ну как минимум я их чаще всего использую они как бы на мой взгляд самые наиболее полезны это pg сад activity которая показывает текущую активность и покажется statements который показывает утилизацию ресурсов запросами то есть если нужно искать какие-то проблемы в базе данных обычно это две таких статистике куда мы обращаемся так вот раньше не было возможности соединить эти две вехи в просто такие ти есть текст запроса в пгт statements есть текст запроса но он нормализованный все реальные значения заменены знаком и доллар и на глаз конечно можно посмотреть сопоставить ее до сказать что вот это один и тот же запрос это одни и те же ресурсы как бы знать что запрос используя только ресурсов ok но это все сложно и не работает стопроцентно гарантировано начиная с 14 версии появилась возможность считать идентификатор запроса куэрри я иди который есть в пгс the statements его теперь можно считать или для пгс от activity соответственно появилась возможность за joy не две эти вехи и получить полную статистику по запросу то есть мы видим в пока садах дети какой-то долгий запрос можем присоединить пегаса такие и получить суммарную статистику утилизации ресурсов этим запросам то есть это ну прям очень круто что еще также в пгт тактики появилось поле лидер пит начиная с версии 96 после сна учился некоторые операции делать параллельно в несколько процессов условно говоря есть лидерский процесс ему нужно запрос передал пришел запрос об приложения ему нужно прочитать таблицу лидерский процесс запускает несколько дочерних процессов эти дочерние процессы параллельно начинают таблицу читать после прочтения они возвращают результат лидеру лидера дает результат клиенту все круто но есть нюанс иногда нужно посчитать статистику по всей группе нужно взять и родительские процессы все его дочерние но тут есть проблема как раз такие вот отсутствие лидер педаль приходилось прибегать ко всяким уловкам типа по сортировать процессу по идентификатору процесса потом посмотреть на тех запросах если он совпадает то скорее всего это одна и та же группа и мы по этой группе посчитаем статистику но есть случаи когда этот способ не работает запросто в этой группе может получиться так что идентификатор и совпадают по возрасту по убыванию но при этом это там два лидера и два лидера запустили несколько дочерних процессов и мы получим как бы две группы но визуально будет казаться что это одна группа так вот лидер пит позволяет как бы взять конкретная группа необходимую посчитать по ней какую-то статистику например у меня есть утилита pg центр которая делает профилирование ожиданий для кого-то конкретного запроса здесь простой запрос select к он звездочка из таблицы видно что он выполняется 67 секунд причем 61 секунда уходит на чтение данных эта статистика без учета фоновых процессов то есть у нас нету полной информации о том сколько ресурсов требуется этому запросу помощью лидер пит мы можем конкретно найти все дочерние процессы и посмотреть сколько выполнялся этот запрос то здесь видно что сто девяносто шесть секунд он выполнялся и сто семьдесят шесть секунд уже ушло на чтение данных то есть мы имеем полную статистику по всей группе что ещё последняя часть в этой части я отнесу отнес все другие интересные новшества которые не отнесены к другим предыдущим частям но при этом как бы заслуживают тоже внимание pg шлема locations новая вьеха которая позволяет отслеживать распределение памяти в шарик baker's раньше была статистика которая показывала сколько таблиц и индексов находится в шарик baker's но не была информация внутренних структурах теперь можно получить это через новое представление п к статусу показывает использование сыллка шей и это полезно для дебага подсистемы транзакций когда у нас очень много транзакций был типе нагруженная системой что-то идет не так и не понятно что капать по goes to the soul позволяет начать хоть как-то делать дебаг этой подсистемы приведена статья тоже я здесь вам экономлю примерно 30 минут чтение вот она очень клёвая она показывает как раз таки пример использования этой статистики и кому интересно рекомендую почитать следующая статистика связано с мониторингом флотов репликации это обычно какие-то кластерная конфигурации когда у нас несколько узлов используется репликация используются слоты либо используются какие-то вещи типа да бизе ума когда мы захватываем все изменения в базе данных и опять же по логически репликации их передаем куда-то наружу во внешние системы как правило все эти вещи сделаны на остаток репликации и раньше был перед тетей шин слот такая вьюга но она показывала довольно упрощенную статистику и вот в новой версии у нас уже есть количественно и качественные характеристики утилизации по ним тоже можно строить графики и смотреть как у нас там работают эти подсистемы по galax очень крутая в ухо которая позволяет отслеживать блокировки возникающие при работе запросов очень часто бывает нужно посмотреть а как давно блокировка находится в ожидании раньше для этого нужно было присоединить погас от activity и по полям и прогресса тактики посчитать вот это вот ожидания теперь можно не присоединять можно попали уловить старт просто посчитать посмотреть без лишнего присоединения кроме того небольшое улучшение связанные с лагера ванием авто вакуума когда of the vacuum завершает работу дамп его работы попадают в журнал сервера там же появляется время сколько было времени потрачено на выполнение ввода-вывода этими операциями тоже нововведение небольшое но довольно-таки полезная и на этом все хочется подвести какой-то итог вот статистике очень много до задней очень легко растеряться и легко запутаться нужно помнить в ухе название функции имена полей вот вам как разработчикам нужно помнить все две вещи есть погас от activity погасил state fence она как бы позволяет вам отслеживать проблемы и искать проблемы с производительностью если что-то идет базы не так мы смотрим погас от activity если мы хотим найти запросы для их последующей оптимизации мы смотрим погостить у нас если есть какая то долгая активность мы смотрим соответствующие прогрессию на если вы делаете какой-то мониторинг у себя в компании или разрабатываете продукт можно пользоваться погоста т.ф. я сам им пользуюсь довольно часто это своего рода справочник в нем собрана информация о вельхе а полях об истории изменений то есть это более такой справочный материал для тех кто разрабатывает мониторинге либо пишет подсистема мониторинга занимается обсерваторию себя в компании вот на этом все спасибо за внимание меня зовут алексей из леса профи алексей лисовский спасибо тебе огромное быть очень благодарны за то что ты приехала рассказал у нас есть для тебя памятная рамочка а сувениры этот шарф конечно сезон я не знаю там где ты живешь актуально что он станет до круглый год даже летом не мешает вот так вот ну вот пригодится и термос значок можно вот на наградную планку повести ася ваши вопросы есть первый вопрос поднимаете руки заранее вижу вас добрый день и спасибо большое за очень интересно так на пожалуйста вопрос про мониторинг достаточно редки смотрите бывает приложение которые работают через корневую процедуру причем хранимой процедуры если транзакции крупные ветки они могут быть длинные например идет там 20 тяжелых рисковали операторов и в двадцать первом происходит некое торможение как узнать что происходило потому что воспроизвести контекст при котором вызывается в 21 оператор отдельно трудно уроки можно было сохранить план выполнения запроса в воздухе в этом месте план выполнения запроса хранить нельзя но хочется понять что происходило как вот тут есть два варианта если говорить конкретно про postgres то есть представление пгс that use of functions в нем сохраняется статистика выполнение как раз таки вот функций и процедур можно там посмотреть время выполнения найти медленную функцию которая вот во всей цепочке вызовов там использовалась и по ней посмотреть и уже в нее смотреть уже взять эту конкретной функции посмотреть ее текст и и пытаться де бо жить есть другой вариант с точки зрения приложения но он более сложный то есть в приложении нужно занести библиотеку инструменте рования которое будет строить trace и времени выполнения операций но это довольно довольно таки более сложный способ я как раз это и ты спросил то есть на самом деле функция уже найдена она из изнутри себя никаких новых функций называет вот последовательность и скрыли операторов вот как раз на своем докладе через одну действительно приходится строить свою систему суммирование ну вот хотелось бы чтобы какие-то ну есть везде багиры для pmdg sql функций вот можно воспользоваться ими не как-то попытаться но я в продакшене практически их не видел вот здесь нужно смотреть какие-то другие возможные проблемы возможно во время выполнения функций когда вот у нее были тормоза возможно были какие то другие вещи которые коррелировали с этим то есть может быть какие-то блокировки возникали может быть какая-то долгая транзакция висела то есть тут нужно смотреть как бы на весь скарб того что происходило в базе данных да понятно спасибо это часть того что может быть но когда химически чисто выделено что тормозит именно этот оператор именно в этой функции вот приходится вести к изобретательству к сожалению хотя бы интересно что возможно база она работает с тем что написал разработчик друзья либо и если вы в онлайне нажмите кнопочку справа от трансляции выходите в эфир задайте свой вопрос мы онлайн вопрос пустим без очереди алексей спасибо было безумно интересно уже примеряю на свой проект так мне тоже зовут алексей вопрос те процедуры запрос из которых запущены через pg крон также можно посмотреть через тезис да можно посмотреть через просто так ведь и они будут там отображаться так и если у меня не просто инстанса патроне сверху арбитр натянут то я могу как-то и агрегированного все многом получить статистику или мне приходится покажу ему это нужно писать уже свое что-то ну то есть можно по идее просто поставить под гриль с экспортер который будет со всех нот собирать метрики оставите хранилище а мы уже там на графа не поверх этого хранилища сделаем какой не дашборд в котором все эти метрики стать героем у давно говорят да то есть мы сделаем группировку по ну добавим какой-то идентификатор для кластер а у патроне например есть имя кластера ну например в метках метрик отдаем и меток мастера и можем по нему уже с агрегировать и получить статистику по всему кластеру целиком спасибо больше но это опять же ручные действия как бы из коробки ничего такого нету я вижу еще две руки поднимаете кто еще пути добрый день вопрос о хранении погостить statements а как вы его хранить и если провести то как и второй вопрос сразу как часто делать и нужен ли он вообще мы храним у нас довольно таки все упрощенно у нас в компании очень много клиентов и мы стараемся как бы работать неинвазивное ничего не устанавливать в базу данных и как правило у нас есть какая-то крона задача которая раз в сутки делает снимок пгс the statements и отправляет его в наше хранилище но уже там в этом хранилище по нему строим свои отчеты после того как мы взяли снимок пгт statements мы делаем reset статистики и она у нас начинается капица заново то есть мы делаем его раз слушай а если я в динамике хочу посмотреть по гостинице одежде розетки это буду делать если мы делаем и все статистики в этом нет ничего страшного потому что но взять опять же мой любимый prometheus у него есть функция рейд которая считает дельту от текущего предыдущего значения и она умеет как раз таки обрабатывает случае когда счётчик сбросился в ноль вот как раз про металл свой вопрос часто когда очень-очень много простов их довольно проблематично уже хранить фрагментация вы используете какое-то дополнительное хранилище и как под графа не делать либо закидывать ресурсов тут такой момент что у заказчиков которых нам приходят у них либо есть мониторинг либо нету но мы как бы их не включаем свои какие-то систему мониторинга потому что но мне всегда заказчика и ты готов идти мы обычно рекомендуем использовать api метр мы для них писали техническое задание на мониторинг прогресса и они хранят уже текст ну они еще отдельно у себя внутри там нормализуют этот запрос убирают там комментарии лапы вают одинаковые там доллары вот короче они делают еще дополнительно нормализацию они хранят весь текст запроса вот тут все зависит от того какая у вас система для долгосрочного хранения метрик то есть если мы говорим про prometheus это может быть томас де витт cortex и виктория metrics вот если у вас позволяют ресурсы вы можете просто в вашем экспортеры уменьшить длину значение в метки и передавать запросы сохранять понятно что там будет кардинально ну тут уже нужно смотреть на метрики системы хранения если она справляется то почему нет можно охранять прорезы как часто ты как часто очищать а как хотите можете часто ощущать если есть в этом необходимость можете не очищать то есть тут все же идет от ваших потребностей можно просто как бы оставить ее пусть она там копится какое то время то есть там же важно смотреть какие-то изменения во времени то есть это дельта какая-то или и там может быть какая-то агрегата по интервалу времени здесь сброс счетчиков не особо ну вреден оси выпуск супер я верю что у нас есть еще один вопрос да поднимите руку у кого будет вопрос снова скажите пожалуйста такие возможности диагностики базы данных и слепы или то причинам не могу в себе поднять то ли оно вообще не поднимается поднимается очень долго при этом минутами вы имеете ввиду песку или работает ну по и сколь не подключается да вы не можете восстановить сессию почти мертвый но если мы не можем подключиться к базе данных нужно смотреть проблемы в том окружении где работает база данных это или операционная система или контейнер на мы подключаемся в операционную систему там через ssh и возможно либо в даже бордах системных смотрим что у нас происходит системой я бы поступил просто так я бы зашел и ps сажи запустил топ посмотрел на утилизацию ресурсов если это циpкa или напустим диски я бы уже смотрел на работу плюс нужно еще посмотреть журнал и что происходит может быть здесь какой то проблема в журналах возможно что превышен лимит количества подключений да и либо сессия висит там на этапе окон дефекации то есть причины могут быть разные здесь уже нужно использовать обычные методы trouble суть инга которые используются там системном администрировании то есть смотрим утилизацию ресурсов там смотрим ошибки смотрим сатурацию утилизации ресурсов нет ли очередей скопившихся то есть какие-то такие подходы"
}