{
  "video_id": "z6irMP_X630",
  "channel": "HighLoadChannel",
  "title": "Оптимизации уровня CPU / Андрей Акиньшин (JetBrains)",
  "views": 9065,
  "duration": 2053,
  "published": "2017-05-14T22:53:06-07:00",
  "text": "всем добрый день сегодня мы действительно поговорим про оптимизацию уровня циpкa но прежде чем мы перейдем к рассмотрению процессоры того как он работает хочется в целом поговорить про оптимизации про общую методологию про то вообще как как стоит всем этим заниматься скажите есть кто-нибудь кто работает на high performance проектах так ну ладно несколько хорошо проще вопрос есть люди которым так или иначе иногда приходится заниматься оптимизацией делать так чтоб код попытаться сделать код более быстрым а уже получше отлично отлично вот скажите вот какой самый первый шаг нужно сделать перед началом оптимизационных работ самый-самый первый замерить хорошо какие еще варианты а а что будем замерять хорошо перед протезированием и нужно что-нибудь сделать хорошо сложность алгоритма еще что нужно сделать а лично нам нужно понять что есть проблема вот казалось бы пункт простой но половина народа минимум про него забывает людей появляются стороны идея давайте чего-нибудь по оптимизируем а вот я вижу здесь код написан не оптимально я знаю как его более оптимальным сделать вот иногда бывает такая проблема не знаю со студентками придут люди после университета их там научили умным алгоритмам не там подходит студента говорит вот здесь калгари там написан за н куб в четыре строчки я знаю как сделать n умножить на логан умножить налогом всего за неделю могу написать не надо потому что n10 и это не то место где нужно оптимизировать если у вас нет проблем и не надо ее решать про это очень многие забывают то есть какая проблема там заказчик недоволен говорит что вот ваше приложение тормозит мне надо в два раза быстрее от проблема или у нас есть конкуренты да и нам что быть конкурентноспособными но сделать не медленнее по крайней мере чем у конкурентов а у нас сейчас работает медленно это тоже проблема это проблема которую нужно решать как-то оптимизировать что нужно сделать дальше дальше нужно определить метрики поставить задачи то есть какие метрики для нас важны и что мы связи с этим хотим сделать если метрику поставить неправильно то решение тоже может оказаться неправильным вот у нас конференция называется back and cons и я разговорился умерли очень многие любят масштабироваться да там есть какие то проблемы с перфомансом до купим машин поставим в два раза больше сироп в четыре раза больше серов обе представьте такую ситуацию у нас есть какие-то запросы от клиентов и один запрос мы умеем обрабатывать например за 2 секунды до а пользователь хочет за одну секунду и у нас есть например там 100 машин и 100 пользователя вот сейчас мы каждый запрос пользователя обрабатываем за 2 секунды пользователи недовольны можно докупить машин до сделать машин в два раза больше и в этом плане у нас там пропускная способность теоретическая в два раза увеличится но пользователем жить от этого легче не станет потому что метрика выбрана неправильная дальше метрики нужно научиться корректно измерять потому что если вы не можете что-то измерить то улучшить это тоже проблем на всяком случае вы не всегда сможете понять действительно ли вы что-нибудь улучшили ли или просто поменяли код еще одна проблема не которые умеют что-то замерять но умеют делать неправильно а думают что правильно это тоже проблема потому что многие не понимают как как правильно измерять какая методология корректных измерений дальше когда вы поняли что есть проблема нужно найти так называемые узкое место да то есть место которым над перфомансом которого будем мы работать это про этот бунт тоже часто забывают вот у нас проект приложение по тормозит ну давайте давайте папки делим вон ту штуку да она выглядит медленный это не всегда правильно и действительно большая проблема найти самое правильное место которое нужно оптимизировать это не всегда тривиальная задача например это не обязательно там самый горячий метод в профайле как как любят делать взяли профайлер чего-нибудь померили найти нашли метод который живет больше всего времени и и давайте его оптимизировать или там как как-нибудь попытаемся избавиться от него это может быть например я не знаю этот метод кэширование он должен работать долго потому что но он делает очень важную работу и он должен делать и в большом количестве без этого метода у нас вся остальная программа будет работать там в 10 раз дольше поэтому нужно самое узкое место найти правильно то есть тот кот на tkat на оптимизация которого мы будем работать и вот самый тот здесь правильно совершенно сказал что нужно сделать это подумать ну что этот пункт тоже очень многие забывают не думают сразу начинает оптимизировать подумать вообще на тем что можно сделать с проблемой а сделать сделать очень много что можно во первых как я говорил можно по масштабироваться но делать это грамотно масштабироваться если это имеет смысл если это действительно эффективно еще в современном мире все очень любят параллель из а у нас много ядерно каждой машине давайте запустим задачу не в один потока в 200 потоков и сразу все начнет работать быстрее но вы не все правильно по умеют параллели поэтому тут тоже нужно подходить к аккуратным дальше нужно разумеется сделать хорошую архитектуру если у вас маркетинг дура плохая у вас уже может ничего не спасти выбрать эффективные алгоритмы правильные структуры данных знать как вообще работают ваши стандартные библиотеки да какой к перфоманса ожидать от какого-то метода как работает ваш язык как что означает там базовые синтаксические конструкции да кто какой performance на эффект он дает нужно аккуратно работать с памятью думать как вы работаете сетью какие у вас дисковые операции есть да можно ли кто меньше сделать например и многое чего еще то есть есть такой боль менее стандартный перечень проблем над которыми стоит подумать там в первую очередь понять какие проблемы актуальны для вас что конкретно вашей задачи тормозит вот в том самом узком месте и уже начать над этим как-то работать но иногда программисты попадает в такую ситуацию когда вот все вроде бы хорошо да мы там от масштабировались распараллелить архитектура прекрасный алгоритмы все там за константу в библиотеке самые правильно используем все замечательно скорости все равно не хватает приходит там начальник и говорит вон у конкурентов два раза быстрее нам тоже два раза быстрее еще проблема что очень многие не умеют замерять время правильно особенно это касается когда мы занимаемся каким-то микро перфомансом вот так выглядит примерно и примерно и обсуждение на stackoverflow каких-нибудь микро бенчмарков то есть человек столкнулся с задачей когда ему нужно какой-то участок кода разогнать начинает начинает что-то с ним делать начинает того как то замерять и замеряет неправильно получает неправильные выводы которые не может обосновать начинает обсуждать это с людьми и в итоге в итоге дискуссии скатывается у методологию микро бенчмаркинга и про исходного проблема все уже забывают это тоже большая действительно проблема в люди не умеют писать микро бенчмарки в в этом направлении лучше всего найти какую-нибудь библиотечку которой относительно хорошо работает и выполняет какие-то базовые вещи такие как прогрев за многократный запуск вашего то целевого теста почет разных статистик все это на считает посмотреть графики проверить в разных условиях в разных инвариантов ваш микро benchmark потому что если вы построили программу которая что-то измеряет и делает это неправильно то оптимизацию тоже провести неправильное только все ухудшить задачка из из реального проекта я несколько лет работал на проекте мы распознавали текст документов то есть у нам приходит документ на нем есть какой-то текст куча еще всякой ерунды кроме текста там background печать еще что то это нужно все аккуратно распознать и вернуть пользователи текст задачка не очень простая и задачки как раз одна из метрик по performance это лет ansi нам нужно уметь очень быстро распознавать 1 документ и эта штука не очень масштабируется и параллели c нам чаще всего приходится работать в рамках одного потока и если там у конкурентов там документы распознается например 10 секунд нам удавалось за одну секунду распознавать я получилось так потому что мы постоянно работали над перфомансом и вот я в очередной раз сижу в профайле ли изучаю код и нахожу метод который работает подозрительно долго выглядит он примерно следующим образом что делает этот метод у нас есть картинка картинка черно-белая представляет со условно говоря виде байта массивчик а н а н байтик означает там цвет в оттенках серого до там 255 белый 0 черный и задача сказать картинка скорее там темное или скорее белая у нас только два значения может быть как мы это делаем и пробегаемся по всей картинке и находим все такие пикселы картинки значения которых больше леброна чем 128 мы увеличиваем какой-то счетчик если счетчик оказалась там меньше чем n квадрат пополам то мы говорим что картинка скорее темная вот казалось бы такой не очень сложный код но он живет очень много очень много времени то есть примерно там 10 процентов всего алгоритму сюжет точность есть точнее 10 процентов всего всей процедуры распознавания это много это намного больше чем работает разные наши хитрые и умные алгоритмы мини-опрос как эту штуку еще можно за оптимизировать сильно значительно за оптимизировать на порядок это хорошая оптимизация датчик предлагает эвристику что если у нас например мы уже насчитали что у нас есть там н квадрат пополам там белых пикселей ли черных пикселей то можно остановиться и дальше не считать это хорошая в листика и она помогает когда у нас картинки там в основном там сильно белый до или в основном сильно черные отлично но к сожалению нас была такая специфика что у нас многие куски картинок они скорее напоминали такой случайный шум реальный шума много накладывается и вообще background такой достаточно нетривиальный и это эвристик а она просто не работает ее можно вставить но она нам не даст ускорение на порядок в нашей конкретной задачи до в общем случае хороший день какие еще варианты есть до отлично отлично что-то типа методом монте-карло да хорошая оптимизация можно действительно брать не все пикселы а случайно по накидывать например взять там 10 процентов пикселей или там 20 процентов можно подбирать константу случайным образом и посчитать посчитать примерный процент но увы нам это тоже не очень хорошо подходит потому что для нас было сильно критично допустить ошибку то есть представьте себе такую ситуацию пример этот метод используется при переворачивании изображения да то есть у нас есть картинка на она либо правильно положено либо вверх ногами и мы берем какой то кусок картинки и знаем что если картинка лежит правильно дата вот этот кусок он должен быть светлым если это не так там например верхней части соответствующий кусок темный мы картинку переворачиваем вот если монте-карло даст нам сбой да даже в каком-то там маленьким процентом случаев то у нас дальше абсолютно все пойдет неправильно абсолютно весь алгоритм мы еще ничего не распознаем это первая проблема вторая проблема это мигающие тесты на базе то есть представьте что у вас там есть база не знаю несколько тысяч документов вы по ней постоянно пытаетесь сделать регрессионное тестирование и иногда manta к 1 даёт сбой не очень приятно и не очень понятно как с этой статистики работать то есть хочется метод который максимально простой и дает точный результат есть еще какие нибудь варианты как хорошая идея да наблюдения обратите внимание что здесь сначала цикл идет позже а потом и цикл идет по и обращаемся мы к картинке да и и тому же там и пиксиву ну казалось бы можно поменять форике местами действительно и казалось бы и там н квадрат и тут н квадрат до университете нас учили что алгоритмическая сложность одинаковое значит и работать должна одинаковым но увы это не так вот есть такая табличка посмотрите внимательно табличку табличка очень хорошая и и утащил из книжки system performance энтерпрайз он за club всем кто интересуется перфомансом крайне рекомендую очень хорошая книжка и вот здесь приводятся разные mci силки сколько занимает та или иная операция и у нас кукиш циpкa есть так называемый cash cash есть нескольких уровней как правило на современных процессорах есть три уровня или один или два или три и данные с которыми мы часто работаем они попадают в кэш и дальше читать данные из кэша это дешево читать данные которых нет в кэше которые лежат в основной памяти дорого это так называемый каш мисс и то есть если прочитать вот по этой табличке это примерно боль мини современное железо прочитать чисел k is a leading сша стоит одну наносекунду а прочитать из основной памяти 120 секунд ну то есть разница в два порядка это это критично и очень здорово было бы если бы наш алгоритм был оптимизирован под crash как этого добиться смотрите снизу нарисовал такой условный левый верхний угол своим матрицы сначала я обращаюсь к элементу с индексом 0 0 до в любом случае вне зависимости того как умная меня идут форике что при этом что в этом случае происходит элемент 0 0 он попадает в кэш но попадает в конечном ни один у нас кэш не работает по одному элементу он работает по так называемым кашле не целом кускам памяти и в кашу меня попадает ни один элемента например сразу восемь если я иду по строчке то элемент с индексами 0 1 он уже в кэше элемент с индексом 0 2 он уже в кэше их читать будет очень очень очень дешево если я иду по столбикам то когда после 00 прочитал элемент 10 элементы 10 в кашине оказалась у меня произошел кишмиш да я потратил на это 120 секунд вместо одной и мне приходится в кэш загружать еще одну кэш линию потом я перехожу к элементу 20 его тоже нет в каше да и я опять гружу целую кашле не и это все очень и очень очень дорого поэтому когда вы работаете с какими-то структурами данных нужно пытаться обеспечивать максимально последовательный доступ максимум делать алгоритм максимально дружелюбным кашу и вот если мы возьмем этот пример и просто переставим приставим циклы ну вот на моих задачах получилось разница примерно в 3 раза да то есть мы просто за бесплатный без всяких монте-карло без всяких эвристик просто переставили 2 форика местами количество строк тот же самая performance проапгрейдился в три раза хорошая оптимизация что ещё можно сделать приходит начальник горит бойся ты молодец но нам надо еще быстрее да потому что до совсем попадет на вообще на решение gpu ok ok есть такой вариант но я уверен что будет будет значительный прирост должна хорошо сколько времени вы потратите на то чтобы закончить там алгоритм на gpu быстро а представьте что это не укладывается в ваш стек технологий вот у нас программка она написана на сишарпе все sharp не самых high performance язык но мы имеем его эффективно использовать и всякие наши проблемы с перфомансом они обычно находятся не на уровне сишарпа где-нибудь ниже но чтобы взять и вынести какую-нибудь маленькую процедурку на уровень gpu еще потратить время чтобы перекопировать туда-сюда данные то ну я привык сомневаюсь что будет особый эффект от этого вторых эффект может быть даже отрицательным потому что мы на копирование можем много времени потратить а времени у нас идет много да то есть это ввести ввести какой нибудь там методу чтобы все это на gpu как-то перекладывать подцепи чеки библиотеки все сложно нам нужно более простое решение есть еще идеи раскрутить картинку в виде одномерного массива сделать хорошая идея но она вам даст ну не знаю 5 процентов максимум самира вместо чего битовая операция хорошо а какой ну то есть как у в каком месте мы и вставим и в каком месте мы должны ожидать прироста я вам даю подсказку сравнение двух чисел до вот я там сравниваю что то она работает мгновенно до сравнение это вообще одна из самых быстрых операций которые общи так можно придумать инкремент перемены это тоже это просто мгновенная операция то есть эти операции они по порядку перфоманса не сравнимы с битыми операциями 8 бичик хорошо ок а какой performance на эффект вот этого ожидаете отличная идея отличная идея есть такая штука как ветвление они чаще всего возникают там где вы пишете оператор if i ветвления стоит очень очень дорого особенно особенно в каком ситуации у вас на уровне цыпа есть такая штука branch предиктор эта штука пытается понять выполнится и фиг или не выполнится и если предсказать предсказать переход получается хорошо то это крайне позитивно влияет на ваш performance если предсказать переход получается плохо то это влияет очень очень очень сильно негативно и общая производительность приложения может очень сильно проси есть если я вот в таком в такой программки возьму и заменю свою branch версию алгоритм on a branch лес сделал примерно так предложил на человек я буду каунта прибавлять просто ну а самый старший бить их числа даже что раньше дел проверял что число больше или равно 128 когда у нас один байт больше leben 128 когда у нас последний бичик установлен в единичку я просто делаю битовый сдвиг и и прибавляю то что получилось к результату то есть еще раз здесь я выиграл не из за того что я воспользовался супер быстрыми битыми операциями я выиграл за счет того же то я убрал ветвление если бы у нас картинка была полностью белая да то есть у нас и фиг там всегда срабатывало бы или бы не всегда или всегда я бы не срабатывал то вот такой подход он нам даже был худшим performance потому что он там если посчитать в конце каждой отдельной операцию нужно немножко хуже вот но если картинка случайная сравнимая шумом если у нас branch предиктор каждый раз где-нибудь не угадывает то такой подход branches версия она на наших тестах дала возрастание перфоманса примерно в семь раз то есть там 3 умножить на семь и мы получили примерно в 20 раз улучшение перфоманса на вот таком маленьком методе он уже стал работать совершенно какой-то вменяемое количество времени и все в нашей жизни стало хорошо обращаю ваше внимание что мы делали каких-то супер умных алгоритмов мы не меняли сложность мы не использовали ким будь там гриппа у или какие-нибудь там сент инструкции мы вообще не не сделали никакого рокет сайенс и мы подумали о том как устроен процессор внутри поменяли буквально несколько бантиков и получили расстояние перфоманса в 20 раз стоит вообще понимать как у нас работает циpкa это очень полезные знания я приведу еще парочку примеров интересных эффектов если вы возьмёте к нибудь современный ноутбук современном компьютер то чаще всего у нас есть четыре ядра и современный конфигурации выглядят так что у нас на каждом ядре есть два уровня каша это или 1021 совсем маленький 2 чуть чуть побольше и есть кэш l3 он общий для всех дядя это типичная конфигурация зачем нам вообще знает зачем нам знать что у нас есть там у разных ядер разные каши что какие-то что три у нас общий вообще зачем нам нужна эта картинка давайте представимся себе следующую ситуацию вас есть какой-то алгоритм и вы решаете этот алгоритм раз параллель да но не знаю вас все друзья все вокруг каждый день параллель от из-за этого их код начинает работать намного более быстро все счастливы решаете ваш алгоритм тоже взять и распараллелить и вот раньше у вас сочеталась в один поток а тут вы зарядили там в четыре потока и каждый поток у вас работает на своем ядре но у вас каждый поток работает с какими-то с одной и той же переменной да то есть вот представьте что мы предыдущий алгоритм взяли и решили за параллели разрезали картинку на четыре части но аккаунт оставили общий для всех и у нас происходит постоянное чтение и запись в этот каунт так вот у каждого ядра свой кэш и чтобы работать с каунтом на каждом ядре вам нужно вытащить вытащить этот кал на уровень там куда-нибудь el1 а теперь представьте что один поток взял и записал в каунт новое значение а второй собирается прочитать это значение но 2 же свой отдельный кэш правильно это проблема поэтому нам каши нужно синхронизировать вот такая ситуация когда среды с разных ядер работает с одними и теми же значениями она называется true шеринг то есть thread'ы делят одну и ту же переменную работают с ним и мы теряем какое-то время на том что нам нужно синхронизировать каши лишь приятная ситуация а теперь рассмотрим еще более неприятную ситуацию как for sharing штука которую найти намного сложнее представьте что у вас поток 0 и папок один находятся работают работают с разными переменными новом так не повезло что эти переменные и попали в одну и ту же кэш линию процессор и вообще не волнует что эти переменные разные его волнует только то что они находятся в рамках одной и той же кашле нее это минимальная какая-то атомарная операция с которой у нас может работать кэш на меньше меньше он просто не он не может затем полка шли не и поэтому он видит что и корр 0 ecor1 пишут читаются но это же кашле не неважно какие перемены нам все равно нужно выполнять синхронизацию и мы на этом все равно можем очень очень много потерять по performance у простая оптимизация по разведению разведению переменных по разным кашле ним то есть напихать там бантиков между ними грубо говоря она нам даст просто гигантский performance на эффект но если вот про такие вещи не знать и наступит на них то человек в здравом рассудке он никогда не догадается чем вызвана проблема почему у нас там на одной машине где байтики легли удачно все работает быстро да там где они оказались в разных кашле них а на другом смещение оказалось другое у нас все начала работать медленно то есть это он совал был задачка не понятно что с этим делать и вообще у нас нам на уровне ядра есть очень много разных прикольных штук например у нас есть такая штука кого-то ford казаки уж он у нас операции которые приходят приходят на уровне шел циpкa не обязательно выполняется именно в том порядке в котором в котором вы их там написали даже если вы пишете на ассемблере написали несколько инструкций процессор может их взять и переупорядочить причем процессор может заглянуть далеко далеко вперед если вы живете кто-нибудь sandy bridge то там вот это rear door баффер его размер 168 инструкций на ком-нибудь хаоса или современном 192 на скамейке у некоторых уже начинают появляться процессов 224 вот кстати на 224 инструкций процессора можно заглянуть вперед и что ты сделать полезное вытащить инструкцию которая через двести инструкции от вас вперед находится и выполните и сразу и поюзать этот как то результат заранее я такое не могу сделать мне нужно очень долго нас имбирный листинг смотреть что понять как там чё куда протащить в это процессор это может делать более того есть такая штука как construction был пару лизу у вас процессор сам может эти инструкции посмотрев на них взять и выполнить в параллель за счет того что так устроен конвейер что вы можете несколько инструкций ну практически параллельно исполнять на уровне одного ядра без всяких гипертрейдинг of это тоже очень клёвая оптимизация но она иногда срабатывает иногда нет и очень сложность не работать общая рекомендация здесь пытайтесь избавляться от зависимости между данными например если у вас операция б зависит от результаты операции а вы их как не старайтесь но в параллель сделать не сможете да это просто невозможно он сначала нужно закончить а потом вы сможете сделать б если у вас выстраивается цепочка таких операция чаще всего она выстраивается у вас б зависит от ация зависит от б д зависит от цвета практически убивает возможности цыпа констракшн ловил призму иногда возможно немножко поколдовать над dependency между вашими данными сделать так чтобы подряд шли инструкции которые друг от друга не зависит то есть например операции бойцы используют результат операции а а друг с другом никак не связано в этом случае их можно впихнуть в параллель если этого не хватает есть такая штука как сент кто-нибудь использовал в реальной жизни сент инструкции один час но уже хорошо но знаете что такие инструкции есть они позволяют вам эффективно обсчитывать достаточно большие объемы данных выполняя операции над несколькими элементами за 1 то есть у нас есть такие расширения процессоры как с с е а вы x в последних интеловских процессоров fx очень сильно прокачался имейте ввиду что такие инструкции есть иногда они очень могут вам упростить жизнь но увы не из всех языков их до них можно достаточно легко добраться но если есть такая возможность то иногда на вас очень сильно выручит какая какая мораль вот всей этой истории что знать устройство компьютера важно это очень полезные сведения они вам могут пригодиться в жизни если вы их не знаете как работает компьютером может стать источником очень больших проблем как случае например всяких true шиллингов волше рингов вы написали алгоритм параллельно собираетесь уже радоваться в жизни а в итоге у вас performance только проседает вы потратили несколько дней сделали какой-то очень сложную многопоточную систему в итоге у вас все стало работать медленнее вы не можете понять почему но если вы все это знаете то помимо того что вы сможете объяснить такие проблемы понять как с ними бороться вы можете сильно разогнать код в места где казалось бы его разогнать нельзя в принципе но то есть как случае с нашей черно-белой картинкой мы использовать какие-то простейшие знания разогнали в 20 раз код просто из ниоткуда просто потому что мы понимаем как она работает внутри у меня сегодня все и оставил побольше времени для дискуссий на случай если у вас есть какие-нибудь вопросы keydown вопросик андрей спасибо за доклад такой вопрос ты говорил про кэш мисс а что делать такую ситуацию в джаве как бы есть такая проблема что если мы создаем какие-то объекты то они у нас в памяти и как бы не будут вместе то лежать по нему про что я ну да да есть такая проблема приходится получателей будет вращаться и там создавать там примитивных типов данных до чтобы соблюсти либо что-то доделать можно как то с этим бороться другим способом то есть не делаю вот такие вот вещи в ходе ну во первых нужно вспомнить про вещь которую я говорил самом-самом начале это понять что у нас есть проблема вот пример с картинкой у нас была проблема и она сводилась непосредственно к каж мисом в реальной жизни у вас performance может проседать просто из тысячи разных вещей очень много разных может быть проблемы это далеко не всегда к смеси и в большинстве случаев нас это ну не так чтобы должно волновать и зачастую вы также не можете предсказать в каком порядке вы будете обращаться к данным в памяти то есть данные уже у вас как-то лежат а дальше запускается какой-нибудь пользовательский сценарий до пользователь нажал кнопочку или там не знаю попросил выполнится какую-то операцию с какими-то входными данными вы не знаете что он сделает и у вас запускается какой-то алгоритм который обращается к разным участкам кодов ну в ком-то произвольном порядке и ну здесь кошме сами ничего ничего не сделать если вы у вас есть какой-то конкретный алгоритм который работает с конкретной структурой данных то ну делайте эту структуру данных оптимальный под кэш делать ее там не знаю на массив чеках выделяйте память грамотно вы делайте так чтобы у вас доступ был максимально последовательно вот единственная общая рекомендация"
}