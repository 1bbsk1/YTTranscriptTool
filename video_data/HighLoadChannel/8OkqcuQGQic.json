{
  "video_id": "8OkqcuQGQic",
  "channel": "HighLoadChannel",
  "title": "Как нам удалось сократить время простоя backend при установке обновлений / А. Каблуков и Р. Зиганшин",
  "views": 1301,
  "duration": 2965,
  "published": "2019-01-14T00:13:53-08:00",
  "text": "я всего я расскажу вам как нам удалось сократить время простоя bk при установке а линий как мы до этого шли доходили эта история длительностью 7 лет и из этих семи лет мы четыре года и искали это решение о компании центр финансовых технологий ведущий российский фильм тех провайдер он входит в топ 5 крупнейших разработчиков программного обеспечения россии и у него у нас компании около 3000 сотрудников я являюсь старшим системным архитектором и в компании работаю уже 18 год 11 лет я разрабатывал отчетную подсистему затем я перешел в отдел анализа экспертизы и с текущий момент я занимаюсь разработкой системных приложений наподобие такого которого я сейчас вам расскажу системы которые должны работать все больше и больше к ним предъявляются требования 24 на 7 этот термин обозначает что система работает без длительных простоев и четыре девятки означает что в год у нас получается простой не более 50 трех минут мы получаем вносим изменения и в нашу систему благодаря тому что выходят постоянно нормативно-правовые акты которые мы должны реализовать системе особенно благодарной мы центральному банку регуляторы банковской деятельности но не только он выпускает такие документы но и другие там министерство службы фонды кроме того банк заинтересован в развитии собственного бизнеса и поэтому он может тоже инициировать какую-то доработку в систему ctb идет поток обращений о изменений и мы в свое время меняли количество изменений выпускали двухнедельное обновление кроме того собирали различные кумулятивные патчи и банк мог выбирать сам с какой скоростью ему с какой частотой меню ему выставлять устанавливать эти обновления в конечном итоге мы пришли к тому что ежегодно выпускается 6 обновлений это одно обновление два месяца и каждому обновлению выпускается от 8 до 24 дополнений существующей вариант обновления системы цех то банк заключается в том что есть обновление есть начало работ а потом вынужденный простой а потом продолжение работы как происходит это обновление то есть работает пользователи обслуживаются клиенты сначала прекращается обслуживание клиентов прекращает работать пользователи останавливаются интеграционные процессы и начинается обновление происходит обновление потом заново все запускается процесс и начинаются начинает работать пользователей и затем начинают обслуживаться клиенты то есть если кто то из вас в последнее время не получал доступа к интернет банку возможно а не обновлялись одно обновление сейчас у нас ставится за 38 часов то есть это простой который требуется в банке кумулятив из двух-трех обновлений он уже требует 620 6 до 24 часов вообще говоря это не полностью расходы есть еще накладные которое зависит от системы и банки отдельно доработок которые они делают и соответственно это время можно даже умножить на 2 то есть максимальная системе может происходить простой банки до 40 часов платформ развитие она предоставляет нам среду разработки среду развертывания и среду управления доступом для этого существуют специальные модули они взаимодействуют с технологическими ядром у нас есть вот то ядро которая разработана она представляет из себя словарь специальные таблицы в словаре это представляется описание предметной области я разработчик пишет код на opel плюсе соответственно есть транслятор пиль плюса цель плюс это язык наш язык верхнего уровня который в конечном итоге обрабатывается транслятором pelle плюс и в конечном итоге в словаре оракла появляются пакеты обычные пакеты стандартное представление таблицы ну кроме того можно сказать что технологически ядро она когда взаимодействует с разработчиком она дополнительно создает интерфейсные пакеты может для таблицы создать не только интерфейс ный пакет но и какое-то представление размеры баз данных у наших клиентов колеблется здесь представлен не полный перечень наших клиентов у которых установлена а б.с. автоматизированная банковская система цфт банк базы данных могут быть достигать до 40 терабайт в базе данных если посмотреть основные объекты которые бывают свободы за вот то количество времени которая развивается наша система достигла уже 7000 представление пакетов здесь приведенные цифры это вот как раз две цифры 1 цифра это сколько всего и в скобочках указано то количество которое является прикладным то есть это то число которое разработчики разработали непосредственно а всего это дополнительно то что технологически ядро создала интерфейс на какие-то объекты вот строк кода пили плюсового которые разработчики написали уже достигло 11 миллионов строк одно одно обновление когда происходит то вот из того количества объектов в базе данных оного может затрагивать у до такого уже количества достаточно большое то есть это не предел здесь можно устанавливать различные объекты обновления в котором будет другое количество еще больше количество объектов но вот такое количество достаточно большое тому обновления она и не является монолитным и нельзя допустим что-то улучшить вот чтобы весь процесс убыстряется она состоит из непосредственно из изменений метаданных это нюансы нашей системы то есть меняется сначала словарь а затем у нас транслятор транслирует это стандартная конструкция перец quelle и производит другие дополнительные изменения в базе данных то есть изменение в таблицах пересоздание представление создания удаления и вот модуль развертывание он умеет работать как в интерфейс нам режиме это графическая оболочка так и без интерфейс нам режиме поэтому можно автоматизировать каким-то образом далее у нас происходит в обновлении конвертации данных то есть когда пользователь а не надо заставлять делать какие-то изменения данных и можно их автоматизировать конечно лучше это исключить из процесса человеческий фактор соответственно есть скрипты перекомпиляции раздача прав сбор статистики но и опционально может происходить не только обновления нашей системы и но и версия субд oracle то есть это дополнительный простой общий и технологический игру тоже у нас обновляется ну порядка сейчас изменение ставится пупса вот самообновление если представить что она длится 9 часов то можно сказать что вот основные этапы они состоят его длительность такой примерно 5 часов установка обновления из них час будет компиляция и конвертация еще три часа соответственно что мы решили сделать для того что убыстрить мы решили разбить это обновление на 2 здесь происходит следующим образом мы сначала копируем базу данных делаем реплику и у нас происходит в какой то момент мы получаем две копии баз данных у нас соответственно все последовательности sequence и одинаково все совпадает на одной базе данных у нас происходит обновление она другое происходит работа пользователь причем смотрите от верхней верхняя строка timeline а это вот первая база а вторая это копия то есть здесь когда сделали копию и начали обновлять вторую руку в базу данных то обновление можно закончить когда нужно дождаться завершение его она основной базе данных можно продолжать работать и это полезно тем что можно выбрать наиболее подходящий момент времени когда нагрузка на все процессы какие-то бизнесовые она будет минимальной соответственно нам нужно затем когда мы остановили работу мы должны все новые данные которые там появились мы должны их перенести происходит репликация данных затем происходит вторая часть обновления вот среда развертывание вот тот модуль который это делает и разбивает его на 2 части он анализирует и разделяет его автоматически то есть первая часть сначала происходит такая что не изменяется происходит не разрушающая модель данные оракла то есть происходит только вставка каких-то объектов какие-то добавления колонок но не происходит удаление не таблиц не колонок в таблицах после того как репликация данных произошла происходит завершающий этап то есть происходит вот это удаление всего чего нужна и затем происходит конвертация данных нужно конвертация данных в итоге при применении такого подхода нам удалось у клиента сократить время простоя его 40 часов до 8 часов это его удовлетворяет и вклад в это время простое у нас 12 часов снизился до 2 часов то есть за счет чего происходит выигрыш за счет того что на первом этапе обновления у нас первый этап происходит не во время простое а просто на копии то есть в первый этап может входить большая часть обновлений за счет этого времени не тратится как не забирается у работы другого сервера а затем когда происходит остановка то какое-то время добавляется на то что данный нужно за реплицировать но и второй этап обновления он включает в себя в основном не большое количество изменений как происходит репликация данных здесь разработан для того чтобы это произвести разработан собственный механизм так называемая конвейерной обработки таблиц то есть здесь вот все таблицы которые мы знаем что в них могли появиться данные мы должны их обработать и перенести данные из одной базы данных другую то есть до этого мы такой подход нигде не применяли чтобы вот две базы использовать одновременно на двух базах работать в десятом году при миграции двух филиалов происходил такой проект и вот как раз там была разработана вот эта технология просто обработки то есть создавались задания которой я вот таблицы обрабатывались каждую конкретную таблицу эти задания генерировались справочники и было другое задание которое бежала по этому справочнику в нужной последовательности их выбирала в какой-то конкретной и таким образом происходил перенос но здесь следует отметить следующий момент что если обычно вы должны переносить таблицы обрабатывать отдельно каждую таблицу и в какой-то определенной последовательности да то здесь такой прием предпринимается опускаются в базе водка приемник или все constraint и и в многопоточном режиме несколько несколько заданий начиная переносить данные а потом константы поднимается почему это происходит все происходит нормально почему связность не пропадает потому что на одной базе у нас получились связанные данные и на друг и эти данные они один-в-один практически перенеслись другую базу во всех таблицах поэтому связанность осталось каким образом мы выявляем те данные которые нам нужно перенести ворог ли есть такой механизм как захват изменений для любой таблице он еще появился достаточно давно еще 10 версии 10 2 называется матери лазит вьюрок это фактически своя таблица отдельная таблица если вы используете другую субд и соответственно вы можете создать такую же таблицу и обеспечить такой же режим то есть на триггерах сделать захват я тут выделил жирным шрифтом первую колонку это колонка означает идентификацию то есть crate материала зид view идентиф and buy и определяется какая колонка будет delphi котором то есть у нас системе есть в основном все таблицы создаются с колонкой иди и есть единая последовательность откуда берется значение но соответственно есть таблицы у которых не создается эта колонка и дефекация пороге и вот здесь соответственно когда мы создаем для таких таблиц материалы материализованные журналы то указывается идентифицирует но и proua идеи тип varchar они не совпадают когда мы переносили получилось так что мы где-то полдня потратили на исследование вопроса почему там у нас запрос тормозил потому что вот как раз мы на основании logo создавали свою таблицу а потом из нее реплицировали и вот не соответствие типов она как раз влияло на план запроса мы создаем справочник всех таблиц которые нужно обработать и настраиваем для каждой таблицы правила обработки вот эта самая трудоемкая часть которая стоит перед оператором он должен представлять что в системе у него есть нужно ли не нужно переносить то есть там есть целевое предназначение таблицы может быть разной и соответственно есть таблицы которые данное не не нужно переносить например да вот эту же таблицу переносить не нужно также здесь настраивается количество параллельных потоков ну и любые другие например какие вам потребуются свойства для таблицы вы здесь можете добавить самостоятельно и смотри вот например здесь я добавил свойства такое что это лонг или не long то есть есть реквизиты в таблице с таким типом оказывается есть ограничение у оракла при передаче под и былинку командами dml здесь нет нет возможности переносит переноса таких типов данных лобо есть лонгов нету а те таблицы которые readonly перед загрузкой но их мы помечаем для того чтобы оставить их readonly ну какие то дополнительные свойства вот справочник для описания заданий он примерно вот такой то есть здесь генерируется вот то само задание которое какой-то отдельный job читает и запускает тот текст кода который нужно выполнить соответственно там текст примерно такое что enter to select реет из select пота былинку но осталось только разобраться со счетчиками то есть вы должны были задать вопрос что это не работает потому что мы можем перекрыть счётчики когда мы начинаем переносить данные из одной базы в другую нам как-то обеспечить нужно уникальность значений для колонок для идентификаторов что мы делаем в этом случае мы три раза сдвигаем счетчики на базе происходит следующим образом сначала мы на целевой базе данных сдвигаем счетчик на какое-то значение на которое мы опытным путем вы выявляем сколько у нас займёт значение обновления ну можно счетчик это 10 в двадцать восьмой степени получается где-то аленькие у нас сейчас в 14 15 степени может 16 у кого-то есть то есть по крайней мере сдвиг на 10 9 это очень маленькая и вклад будет здесь то есть миллиард это очень большое значение то есть если вы хотите просто протестировать можно сдвинуть на миллиард этого будет достаточно то есть мы сдвигаем на миллиард и копируем базу у нас здесь база со сдвинутым миллиардам и здесь со сдвинутым миллиардам на работе базе происходит работа и идет новое вставки вот со значением следующий а здесь у нас пустое окно здесь на копию мы вот этот миллиард отодвигаем назад происходит обновление это второй раз мы сдвинули теперь когда мы провели обновление а здесь на генерировались новые данные происходит 3 раза движка на приемнике мы сдвигаем на значение которое максимальное значение на вот этой базе таким образом у нас совместимость происходит когда мы разработали все мы месяц потратили на поиск той конфигурацию при которой происходила бы правильная обработка параллельных таблиц в параллельном режиме таблиц то есть вора клей есть механизм распараллеливания и он может настраиваться на разных уровнях он может настраиваться как на уровне таблицы так может настраивается и на уровне сессии и инстанса экземпляра oracle и если вот эти настройки они не будут конфликтовать между собой параллельности не произойдет и мы наблюдали такую картину что когда обрабатывалась вот та куча таблиц полой нагрузка она сначала была максимальная а потом падала и длинный был хвост это какая-нибудь большая таблица или пара таблица не вставали в очередь в один поток и могли два часа переноситься данные соответственно у нас специалист администратор базы данных он потратил нашел нужную конфигурацию соответственно мы в документации примерно там рекомендации какие-то выдали но основная рекомендация конечно вы пользуетесь рекомендациями oracle но не всегда то можно все правильно найти и учесть вот и соответственно к этим рекомендациям и какие-то добавили свои после того как мы разработали и система фактически могла эксплуатироваться у нас семнадцатом году оказалось возможность протестировать это на каких-то на серверах на серверах выделили время и прогнали стресс-тестирование то есть создали виртуальную машину развернули в ней систему на генерировали на генерировали мамат логе размер 320 там скрыто циферка и запустили репликацию генерация происходила следующим образом на генерировали просто пустышки как рандомным образом какие-то пустышки были как количество пустышек было зависело от размера базы данных примерно один процент от размера там самые большие таблицы взяли из шести там 7000 это оказалось где-то порядка 60 таблиц ну то есть принцип парето 20 процентов таблиц и кроме столах были и удаления и апдейты вот количество такое было 260 мегабайт нагрузка показала следующий результат что полтора часа вот это происходило причем тоже вот нагрузку поднялась а потом опустилась начали смотреть оказалось что у нас задание которое друг за другом стартует вот это она вот выполнилась подразумевается пошла репликация мы какое-то время должны подождать и там стояла 5 секунд после того как идти просто 5 секунд поменяли на одну сотую вот нагрузка произошла за два это репликация произошла за 20 минут нагрузка он сильно возросла но мы по еще посмотрели а что же вот этот хвост делал оказывается этой вот из 7000 таблиц вот оставшиеся которое 6400 они просто были пустые и там что происходило опускались constraint и потом пытался процесс определить какие новые данные поступили потом репликация соответственно данных отсутствие этой репликация фактически заново подъем constraint рф вот отключили эти задания у нас произошло сокращение времени с 20 минут еще в пять раз то есть в результате у нас получилось четыре минуты на которых тратилось репликация и после репликации операции конвертации за меня занимали еще там в компиляция конвертация 34 минуты то есть получалось 8 минут если вспомним что 6 минут у нас ой шесть раз у нас обновляется система то мы получаем 48 минут вот такая система по крайней мере виртуальная можно сказать что она она будет работать в режиме 24 на 7 в тот момент когда мы регистрировали доклад в январе 18 года у нас не было никаких промышленных использований нашей системы но вот в январе первый раз произошло случилось банк применил эту систему в результате у него вот как раз то о чем я говорил в начале вместо 40 часов было потрачено 8 часов сократилось до восьми из них вот наши 12 часов в первый раз они потратили 5 часов на обновление но три из них были там решались проблемы не связаны с нашей системой просто забыли сгенерировать задание пропускания конструктов и когда начались лить данные то там произошла ошибка не уникальность и значений кроме того две недели назад примерно 2 может уже три этот за банк применил нашу технологию для того чтобы перейти с 11 версии на 12 на вопрос на мой вопрос зачем вы это есть технология использовали вот был ответ такой как на слайде что выигрыша она не дала но была уверенность что если что-то пойдет не так то они справятся с этим что чем хотелось бы завершить вот свое выступление то что мы использовали средства субд oracle которая является там стандартными и которые вполне могут быть их других субд и поэтому вы скорее всего можете вот эта технология у себя повторить вот приведен список участников этого проекта достаточно много людей и вот история та та история которая была за эти семь лет она просто не уместилось в размер моего доклада я поэтому они готов рассказать после совещания а сейчас я приглашаю руслана руслан жиганшин это человек который на практике успешно применил тоже эту технологию добрый день друзья меня зовут руслан я занимаюсь поиском дефектов в инфраструктуру и и оптимизация мы развитием в расчетной небанковской кредитной организации платёж на центр с учетом специфики моей организации связанные с тем что кого платежный центр является оператором расчетным центром платежной системы золотая корона а также выполняет функции расчетного центра межбанковского расчетного центра федеральной системы город для нас сокращение времени простой это мэйнстрим если раньше мы могли стоять хоть все выходные мы ночью маленько то сейчас уже как-то бизнес занимает нишу вот в своей части доклада я бы хотел рассказать такой немаловажный момент связанный с тем как мы резервировали собственно при использовании магазе говорили наши системы использование данной технологии классический вариант резервирования если на технологию глаза закрыть они смотреть реализована как показано на свадьбе то есть праймари площадка из с тобой а это резервная площадка после того как технологии активируется собственно в тот в один из когда александр белл в технологический перерыв создается фактически база приемник так называемая то что то у нас на схеме она обозначена две базы это и если все это источник и destination 10 то есть 10 этот up to pdf который фактически будет потом изменение все сливаться и смотрю ок если оставить текущую картинку как она показана в таком виде как есть то фактически оставив приемник без резервирования будет не очень хорошо потому что надо будет потом создавать резерв создание резерва по и нашей базе размером около 6 гигабайт будет длится 8 часов то есть восемь часов будем сидеть вот так вот пальцы скрестив и ждать соответственно есть им этот стан bike rides в целом переключим на праймари ой выключим на ту базу которая у нас обновляется то мы оставим голом базу источник это еще хуже потому что если мы вдруг сломаемся то мы потеряем вообще все он останется там на половину обновленный приемник и наполовину соответственно там разломанный источник что мы сделали мы сделали следующие ну как бы есть такой еще немаловажный момент что создание всех вот этих копий оно должно происходить незаметно без простоев муса тысяч мин стрим мы же этого ждём хотели и соответственно мы незадолго до начала проведения работ создали две базы одну базу мы разместили на праймари площадке то есть поучили там промо и 2 дтп с и вторую базу мы разместили на резерве базы создавались тихонько эггманом скажу только одно из термо нам будете дублировать базы аккуратно роман работает по умолчанию на все деньги то есть учитывает как бы те максимальные значения чего-то мне зажать то можно получить прасад по вводу выводу особенно как бы с учетом того что здесь количество необходимых ресурсов ну да обеспечения резерва на удваивается но как-то чем-то надо жертвовать данная ситуация в момент включения журналирования когда у нас создавались по тревоге мы базу догоняли соответственно и потом их эти о гида копировали и мы фактически эту базу требует потоки мы разделяли получилось вот так то есть у нас оставалось базой источник на которые продолжали работать пользователей и собираться те изменения которые мы потом будем ее при целовать и получалось старая связка приемник на которую попутно катилась обновления у нее уже был готовый стендбай и соответственно во вторую технологическую паузу после репликации то что называется источник его стендбай потом с того оставляли останавливали стендбай удаляли его чтобы он не занимал больше места и у нас оставалось там праймари база для вас бога каких-то критической ситуации соответственно подводя итоги доклада я хочу поделиться тем профитом которые собственно технологическое решение предлагаемые коллегами нам того 1 1 фича который мы получили это то что процесс изменения эффективнее стал ну как бы у нас бизнес постоянно нам какие-то и какие-то задачки подкидывает не всегда они просто накатываются плюс есть какие-то тяжелые очень изменения которые приходят на пунктом уфпс законодательству то что их над ставить соответственно тем проще нам внедрять изменения тему тем процесс легче и практически психологически тем скорее не приходят в продакшн второй момент это то когда получается за счет того что идет параллельная работа то есть мы уже не вызываем людей в нерабочее время кто технологическое окно они у нас работы и спеша днем с обеденными пределами с отдыха мид а мы со всеми вытекающими последствиями соответственно мы можем второй этап отсрочить то есть фактически это тот простой на сколько угодно любое время соответственно это позволяет нам более гибко оперировать с этим временем простоя потому что зачастую бизнес может сказать о ребята постойте подождите надо чуть-чуть вот коллеги хотят пополнится например там какие-то счета соответственно мы не можем сказать нет у нас собой все там до свидания и самое важное это то что легко вернуть в случае файла бдв исходное состояние это психологически тоже позволяет нам откатиться есть у нас тут пошло не так огромное вам спасибо за внимание мы с удовольствием с александром ответим на ваши вопросы вы сказали по поводу то что переносится счетчики на некоторые значения а если вот не угадали и уже переполнилась что в этом случае делать тогда будет проблема конечно это нужно вы выявить на этапе тестирования смотрите я ещё добавлю мы тоже задумывались на данным вопросом как как быть если вдруг там у на большую боль 6 ну ладно меньшего плохо есть идея наверное в будущем применим monito виде значения счетчика то есть фактически там каждый день их куда-то записываете будет видно насколько в отчете cqi растут это вам две проблемы позволит решить то есть ну как бы понятно в это в данной технологии и бывают просто счетчики у которых стоит максимальное значение когда они выполняются то случаются неприятные вещи вот с таким сталкивались сейчас вот за счетчиками тоже приглядываем за 1 смотрим на сколько секунд там растут и какие то может быть их оптимизировать стоит может быть и такое же там навесить ладно здравствуйте у меня вопрос к александру скорее всего вот конечно здорово выглядит когда-то идет сокращение там на день на сотни процентов до обновления то есть до 40 до 8 часов там и так далее то есть но тем не менее 8 часов это тоже да очень много и до думаете ли вы над тем чтобы сделать из 8 0 до и если думать эту в каком направлении двигаетесь ну мы считаем что в нашем приложении еще не все не весь потенциал и использован и мы будем работать дальше накат над какими-то решениями кроме того вот если вы помните те три этапа то там есть и tab загрузки вот модели метамодель когда загружается она достаточно длительно у нас системе тоже происходит мы не отказались от идеи распараллелить этот процесс возможно это тоже появится но не в текущей версии вот среды разработчика из среды установки обновлений я так понимаю что при использовании вот это стандартных средств данный инструмент которое вы применяете это невозможно здесь может быть было какое-то движение в сторону своей разработки чтобы пользователи вообще не замечали чтобы мнение происходит да мы думали над этим мы соответственно когда искали решение мы просмотрели те существующие решения которые есть природе смотрели на оракал дешин bay среди финишем смотрели в сторону замахнулись было доработать свое ядро чтобы там version ность поддержать но в итоге у нас получилось по оценке ограничения оракал я был там свои и на нашу систему они легко вот сама система не встает доработка оказалась очень объемная поэтому пока здесь просто так это не получится но соответственно здесь надо работать с перечнем таблиц понимать для чего они и вот понимать какие процессы мы можем отключить какие для банков важны какие не важны и то есть может произойти так что мы запускать процессы будем раньше хотя это может быть сейчас не так очевидно кроме того те решения которые нам не подходят возможно подойдут вам мы нет никого не отговариваем от того чтобы вы попробовали и может быть вам они подойдут возможно мои и был также ещё раз посмотрим потому что с момента двенадцатого года прошло достаточно много времени и продукты тоже изменяется оси большая скажите пожалуйста я правильно понимаю что в данном решении требуются две абсолютно одинаковые базы то есть база источник и база назначение и после того как они меняются во втором этапе верно спасибо на самом деле там могут быть варианты смотрите то есть если в банке нагрузка постоянная соответственно у них должны быть вообще идеально одинаково сервера потому что мы переключаемся там нету спадов а если в нагрузке у нас происходит какой-то спад то в этот момент можно произвести и следующим образом когда мы скопировали две базы у нас логический копи одинаковые мы можем запустить процесс на слабом сервере обновление производить на более мощном сервере и когда он закончится обновление переключить уже пользователи на мощный сервер уже обновленные да да все правильно 4 базы данных с учетом санбой вам необходимо вот как показал руслан да да по железу все также александр руслан спасибо за интересный доклад у меня вопрос будет к руслану по поводу эксплуатации так вы собственно пробовали вы в докладе обмолвились о том что приходилось квартировать ресурсы при репликации вот вопрос как вы нашли этот баланс между тем что продолжала работать на прозе и тем что вы тратили на репликацию собственно говоря в dst опытным путем или вы продали какие-то исследования заранее смотрите у нас изначально как бы начале выступления бойся про мейнстрим мы подбирали себе аппаратную платформу соответствующим образом самые сервер то есть я расскажу поподробнее как делали на самом деле когда работает с их c будто база который источник в ней из рук состоят одни по максимуму те которые там продавшим конфига когда запускается вот эти вот 302 но единством бо есть два стенда дополнительных у них ресурсы минимальные то есть они работают там по чуть-чуть то есть главное в чем может быть беда если изменения много идет активное применение активных журналов после всех по-разному сбрасывать там привязан аттестата сброса у нас тут 1 5 минут по моему они приходят мы боится и соответственно она достаточно как бы нормально насчет репликации репликация тут не но стоит отдать должное коллегам они сделали очень оптимально я похвалил у ребят они молодцы там и присылаются они все там и прицеливаться div фактически то есть на таблицы на одной и той же записью может происходить много различных там операции фактически и призываются итоговое и то есть объем изменение он самый самый минимальный у нас вот например репликация но при объеме базис базы данных около 6 гигабайт сама реплика дневная вот этот объем которое итоговый получился мы считали там вводи в отдельное табличное пространство забили получилось опять спой на гигабайт он пришел там ну примерно минут наверное но с учетом того что мы мы ресурсы действительно поделили отдали четвертинку всего пожадничали у нас ушло где-то на минут 40 на аппликацию неспешно почему это было в такое достаточно спокойное время то есть у нас это было в субботу в субботу у нас нагрузка минимальная то есть стоять совсем там не рекомендуется но нагрузкой а какая то есть вот мы у технологический прорыв уже ближе к вечеру свели если тогда папа подгадать конфигу и подгадать когда у вас площадь нагрузки самым минимальным можно было остановиться и слиться уточните пожалуйста репликация вошла в субботу до но в дневное время в вечернее время то есть мы где-то в 21:30 начали закончили дету после 10 но дан для нас это вот как раз такой вот счас а сам самый легкий перевод то есть у нас не нагружен источник на нем минимальное пользовательская активность присутствует и соответственно мы можем себе позволить нагрузить уже приемник и не просесть после этого шли на второй этап да и счастливо пошли на самом деле да он там начинается момента публикации то есть мы начали дон т вы призывали и соответственно потом уже проявили второй этап там это об за него все что там минут 13 наверное все ясно здорово спасибо спасибо вам спасибо за внимание"
}