{
  "video_id": "bQFwdg69gQE",
  "channel": "HighLoadChannel",
  "title": "Кэширование данных в web приложениях. Использование memcached / Юрий Краснощек (Delphi LLC, Dell)",
  "views": 6153,
  "duration": 2415,
  "published": "2017-07-29T12:57:50-07:00",
  "text": "меня зовут краснощек юрий немножко расскажу вам про каширование но кэширование в общем то не сильно интересно чё там берешь и каширу ешь поэтому я расскажу ещё про кэш и такие довольные интимные подробности кстати вот новым качество об ще много народу знают используют о отлично ну должно быть интересным ну собственно вот в общем так про каширование начнем с того что просят вас разработать фабрику по производству во многих тэрсел метров стандартная задача главное делать скучно лицо и говорит что но мы применим типовую схему до для разработки фабрики но вообще-то ближе к фабричному производству то есть откуда проблема пошла фабрика работает очень быстро то есть производит вот эти наши тахеометры для калибровки каждого прибора нужно там чистая многие за которым надо летать там куда то далеко ну и соответственно пока мы в процессе там добычи этого но не приборы лежат не калиброванные ну и по сути дела все производство останавливаются поэтому мы строим рядом с фабрикой склад но это не бесплатно то есть принципе объяснят ничего теперь мы переходим к терминологии просто чтобы мы общались про кэширование на одном языке есть довольно таки устоявшаяся терминология источник называется origin объем нашего склада то есть это размер кыш кыш says когда мы идем на склад там за образцом нужной формы и ну кладовщик нам выдает то что мы просили это называется каши хит если он говорит нет такого это называется кашмир у ну данных у нашего вот этого многие ума есть freshness буквально эта свежесть ну вот freshness используется везде как только данные теряют свою природную свежесть они становятся stale дейта процесс проверки данных на годность называется вали дышим и вот тот момент когда мы говорим что эти данные не годные выбрасываемых со склада это называется инвалиды шин и да вот иногда обидно я такая ситуация случается когда у нас не остается места но нам лучше держать свежим но не ум то есть поэтому мы находим по каким-то критериям там самые старые выбрасываем это называется и векшин схема такая что у нас от нашего браузера до бэг-энда есть там масса звеньев цепи вот ну вопрос где кэшировать ну на самом деле кэшировать абсолютно везде и хотите вы этого или нет данные будут кашира ваться вопрос больше как мы на это можем повлиять для начала нужно найти хорошие хорошие данные для каширования как я уже говорил сложность вырастает то есть у нас появляется в связи с тем что мы делаем какой то кэш у нас появляется еще одно звено промежуточная в цепи и не обязательно к что-то ускорит если мы плохо подберем данные то скорее всего ну или в лучшем случае не повлияет на скорость там а в худшем еще и и замедлит процесс там всего производства всей системы ну естественно вот смысла нет жировать данные которые часто меняются надо кэшировать данные который используется часто размер данных имеет значение то есть чем суть если мы допустим решаем кэшировать в памяти там blue-ray фильм ну классно мы в очень быстро достанем из памяти но скорее всего нам потом его придется перекачать куда-нибудь по сети и это будет но все равно очень медленно поэтому большой объем такой такой данных там несоизмерим с с вот этой скоростью доставки то есть нам нет смысла держать такие данные там где-то в памяти можем на диске держать но нужно сравнивать по скоростью кстати есть вы можете погуглить program in late and cis program in лет ensis это называется там очень хорошо на сайте данным такие все задержки стандартные то есть например скорость доступа там secu кэш скорость там отправки раунд 3 пакета в дата-центре вот ну и когда вы вообще проектировать проектируйте что-то там прикидываете вот хорошо смотреть там очень наглядно чтобы посмотреть что сколько места по сносу сколько времени простите паз по сравнению там с чем занимает вот ну это собственно готовые рецепты для каширования вот это релевантный http headers я немножко расскажу там про некоторая но вообще про это надо читать то есть это в принципе вот в вебе единственно как мы можем влиять на кэширование это вот правильно устанавливая вот эти хедиры expires он использовался раньше то есть мы буквально говорим мы вот устанавливаем freshness для наших данных мы говорим все вот оно годная там этот контент он годен до такого-то числа его и сейчас этот header нужно использовать не только как fall back то есть более новый header но вы можете опять таки там цепочка это длинная поэтому вы можете попасть на какую-то прокси которая понимает только вот этот header expires новый механизм новый фидер который вот сейчас отвечает за кэширование так age control тэсс тут вы можете указать сразу же и freshness его людей шин механизм инвалиды шин механизм там это паблик данные это про его данное как их кэшировать вот кстати ну кыш очень интересно по названию же очевидно что мы говорим фишер уйти но kosher уйти везде пожалуйста там как угодно кэшируется ну если мы говорим на кэш но каждый раз когда мы используем какие-то данные из этого контента ну грубо говоря у нас есть формочка там и мы там делаем этой формой формочки сабмит мы говорим что в любом случае там все вот эти ваши за кашированные данные они не актуальны вам надо их перепроверить вот если мы хотим вообще выключить кэширование для контента то говорим на us top вот эти но конечно us top они очень часто применяются для форм аутентификации то есть мы не хотим аширова там вот эти вот не аутентифицирован их пользователей чтобы не получилась странноватой чтобы они не увидели лишнего или не было такого недопонимания и кстати вот этот кеш control научишь его можно если допустим кэш control федор не поддерживается то и вам это поведение можно симулировать мы можем взять вот этот header expires и установить дату какую-нибудь в прошлом еще раз ну вот эти все включая даже контент лэнс хедиры они для кэша актуальны тот же контент лэнс некоторые например там сырую ща прокси они могут просто не кэшировать если нету контент лэнс ну собственно мы приходим к нам кажд ну точнее так постепенно приходим к нам кажется каши на стороне бэг-энда у нас опять таки есть вариант ну кэшировать по-разному то есть мы можем но прямо мы достали какие-то данные из базы мы что-то в коде с ними дело ну по сути дела и такая же потому что мы один раз достали том чтобы много раз переиспользовать вот мы можем использовать опять-таки прямо в коде ну какой-то компонент фреймворк то есть вообще для чего это ну почему нужен какой-то компонент для каширования потому что у нас должны быть какие-то разумные такие limitation и наш продукт ну то есть все начинается с того что вот приходит там какой-то инженер по эксплуатации говорит объясни мне там требования на свой продукт и вы должны ему сказать что это будет столько это там оперативной памяти там столько от это место на диске такой-то прогнозируемый там объем роста у приложения будет и поэтому но если мы что-то каширу им мы хотим чаще всего иметь ограничения но допустим там первое ограничение которое мы можем легко обеспечить по число элементов кэша но если у нас элементы разного размера тогда мы хотим это обеспечить просто вот закрыть рамками там объектов фиксированный объем памяти то есть мы говорим там кто-то размер кэша это самый главный лимит самой главной бондарь вот ну мы используем библиотеку которая вот может такую штуку делать и ну или же мы используем отдельный каширу ющий сервис вообще стенду lawn то есть зачем нам нужен какой-то отдельный каширу ющий сервис но чаще всего backend это не что-то такое монолитно там один процесс у нас есть какие-то разрозненные процессы там какие-то скрипты и если у нас есть отдельный каширу ющий сервис то есть возможность сиу всей инфраструктурой бэг-энда видеть вот этот кэш использовать данные из него то есть это здорово ну и второй момент это у нас есть возможность расти то есть например мы ставим один сервис у нас заканчивается там как сайт вот мы ставим еще один сервис ну естественно это не бесплатно то есть не то что там а сегодня мы решили от масштабироваться то есть но это надо планировать такие вещи заранее конечно но тем не менее отдельный каширу ющий сервис такой возможность дает и конечном еще дает и вы выберете но практически за бесплатно то есть допустим у нас есть какие то данные в кэше и мы в любом случае в первую очередь пытаемся достать эти данные с кашей допустим у нас там что-то где-то падает но мы делаем вид что он ну ничего не упало отдаем данные sqashy она может в это время перри подымется там как-то и будет даже и вы выберете вот собственно мы подобрались к мамке шт вам кажется это вот такой типичный новый стиль почему новый скейт для каширования это хорошо ну просто вот по структуре там ну у нас есть обычная хэш таблица то есть мы получаем низкие latency случае с нам кое-что мы аналогичными вообще kill you store джами это не просто не скелет инси это в нотации вот этой big у нас сложность большинства операций это константа вот единицы и поэтому мы можем даже говорить о том что у нас есть какой-то временной constrain то есть ну например у нас там запрос занимает не больше 10 миллисекунд то есть можно даже договариваться о каком-то контракты таком на основании вот этих latency то есть это хорошо но чаще всего мы каширу им вообще что по палатам картинки в перемешку с сам там java скриптов какие-то фрагменты форм там при рендере ных что-то еще вот но это непонятно какие данные и вот структура кивал и она позволяет и хранить довольно легко то есть мы можем себе там завести нотацию что у нас аккаунт там . триста . аватар там эта картинка ну и все но там работает ну 300 это иди аккаунта в нашем случае ну собственно немаловажный момент а что прощается код самого 100 раджа если у нас сивиллы новый стиль потому что ну самое самое страшное вообще что может быть это мы как-то испортим или потеряем данным но чем меньше кода вообще работает с данными тем меньше шанс и испортить поэтому ну простой кэш с простой структура это хорошо ну про monkey штуки well you можно указывать вместе с данными expiration и поддерживается вот работа фиксированном объемной памяти можно устанавливать 16-битные флаги со значением произвольные они для мам конечно прозрачную но чаще всего вы будете сможет работать из какого-то клиента и вот скорее всего этот клиент уже загреб эти 16 бит под себя то есть у них как-то использует но такая возможность есть вам кажется может работать с поддержкой вершинах то есть когда у нас кончается место мы самое старое практически самое старое данные мы выписываем самое новое добавляем или же мы можем сказать не удаляя никакие данные то есть тогда при добавлении новых данных она будет возвращать ошибку out of memory это флажок минусом большое значит ну какой то структурированной такой документации единой поломки шт нет лучше всего читать описание протокола ну то есть принципе вот если вы наберете в google и там им кэш протокол вот это будет первая ссылка там в протоколе описаны ну не только форматом командам отправка том что мы отправляем там что приходит в ответ но там описано что вот эта команда она будет вести себя вот так так итак ну то есть там какие-то корнер кейсы вот ну картинка по командам get получить данные там set and let die литра place ну как как там историям эти данные то есть это то безусловно сохранить там то есть добавить новые либо заменить эту это добавить только если таких такого ключа нет удалить удалить replace собственно заменить только если такой ключ est иначе ошибка но это в принципе то в в среде когда у нас есть shard когда у нас есть кластер это никакой консистентной стенам не гарантирует но ну по крайней мере так более или менее ну с одним инстанциям консистенции можно поддерживать этими командами более или менее можно делать какие-то такие как constraint и выстраивать претендент это значит мы берем как бы перед нашими данными вставляем какой-то кусочек или там после наших данных вставляем какой-то кусочек они не очень там эффективно реализованы внутри мкэш то есть у вас все равно там будет выделяться новый кусок памяти поэтому лучше их разницы между ними и сет функционально нет никакой значит мы можем с данными нашими которые мы сохраняем указать там какой-то expiration и потом мы можем эти данные трогать командой touch и мы говорим что вот теперь expiration там но мы продлим жизнь конкретно вот этому ключу то есть не удалится есть команды инкремента и декремента то есть работает оно следующим образом в истории те какое-то число в виде строки потом говорите инкремент ну и даете там значение какое-то ну собственно на суммирует декремент то же самое но вычитает но там есть интересный момент 2 минус например 3 равно нулю но с точки зрения memcache то есть она автоматически handled in der flow но она не даёт нам сделать отрицательное число в любом случае вернется 0 вот единственная команда с помощью которой можно сделать какую-то консистентной это cos cos это а томик атомарная операция camp and swap то есть мы сравниваем два каких-то значения если эти значения совпадают то мы меняем меня заменяем данные на новое вот это вот значение которое мы сравниваем это по сути дела есть глобальный счетчик внутри мамка что каждый раз когда мы добавляем туда данные вот этот счетчик инкременты ценой соответственно наша пара кивал и она там получает какое-то значение с помощью команды гатс то есть это как год только с в конце мы получаем вот это вот значение и потом в команде касс мы его можем использовать ну по сути дела тут у этой команды есть все те же проблемы которые есть у обычного у обычных а домиков ну то есть можно наделать кучу раз кондишен of интересных тем более что у мамка что нет никаких гарантий там на порядок выполнения команд но как бы вот по крайней мере такая команда есть есть умом кажется ключик минусов большой она выключает касс и собственно что происходит вот этот счетчик он пропадает из кивал юппер если вы добавляете ключик минус эту вы экономите восемь байт потому что это 64-битный счетчик на каждом значении ну то есть принципе если у вас значения там небольшие ключи небольшие то это может быть существенно экономя как работать на красном кажд эффективно она за дизайне на чтобы работать с множеством сессии множество это сотни то есть начинается там от сотен и дело в том что в принципе в терминах рпс там request for second вы не выжмите из манки шт многого используя ну там две три сессии то есть для того чтобы ее раскачать надо много подключений сессии должны быть долгоиграющие потому что на создание сессии внутри мамка что там довольно-таки дорогостоящий процесс поэтому вот вы один раз там прицепились и всю эту сессию надо держать запросы надо бачить то есть мы должны отправлять запросы пачками для год команды у нас есть возможность передать несколько ключей вот этим надо пользоваться то есть мы говорим гад и ключ ключ ключ ключ ключ для остальных команд такой возможности нет но мы все равно можем делать патч то есть мы можем сформировать запрос у себя локально на стороне клиента с использованием нескольких команд а потом этот запрос вот так вот целиком отправлять тут но потом еще расскажу немножко значит memcache многопоточное но она не очень хорошо многопоточное у нее внутри там много-много блокировок таких да вот довольно отход вот поэтому больше четырех потоков ну как правило вызываю там очень сильный контент шин внутри в принципе одно мне верить не надо надо все все перепроверять самим но нам надо естественно с живыми данными на живой системе там делать какие-то эксперименты но очень большое число потоков работать не будет вот то есть ну надо поиграться подобрать какое-то оптимальное вот это число ключиком минус t и накажет поддерживает эдипе то есть принципе это патч который был добавлен им кажется фейсбуком то как использует facebook нам кое-что не делают все сеты ну то есть совсем все модификацию данных по тисе пи агата они делают по и дипе и получается что когда объем данных там но существенно большой но фейсбук вы можете там представить себе то youtube и дает серьезный выигрыш за счет того что меньше размер пакета вот они умудряются больше данных прокачать через сетку я вам рассказывал вот про энкодер вот эти команды они идеально вообще подходят для для того чтобы хранить статистику бэг-энда значит статистика но в хайло де это вообще вещь незаменимая то есть вы не сможете понять что там как откуда там происходит конкретная проблемой если у вас не будет статистике потому что ну там после получаса работают система ведет себя странно ну то есть и и все то есть чтобы добавить конкретику то есть например там каждый тысячный запрос там фелица но нам нужна какая-то статистика чем больше статистики будет тем лучше ну и даже в принципе чтобы понять что у нас есть проблема нам нужна какая-то статистика потому что ну например backend отдавал там за 30 миллисекунд страницу начал отдавать за 40 ну взглядом этот отличить невозможно но у нас вот performance просел там на четверть это ужасно то есть и само по себе тоже поддерживает статистику ну и как бы если вы уже используете мамка штурм в своей инфраструктуре то статистик ммк что это часть вашей статистике вот поэтому туда заглядывать надо туда надо смотреть но чтобы вообще понимать что ну правильно ли backend использует кэш там хорошо ли он данные каширы то есть вот первый атом по каждой команде есть хит и мисс то есть мы количество когда ну то есть мы обратились кашу нам отдали данные про инкремента сетом хит по этой команде ну то есть например там сделали дэвид ключ у нас будет там летит там один так по каждой команде ну естественно надо чтобы хит у нас было 100 процентов вниз не было вообще вот но надо смотреть допустим у нас может быть очень высокими среди а ну там самая банальная причинам и просто лезем не за теми данными вот может быть такой вариант что мы выделили под кэш мало памяти и мы постоянно перри используем кое-что есть мы получается там данные какие-то добавили добавили добавили добавили добавили на каком-то моменте там 1 вот эти наши данные выпали из кэша мы за ними полезли их там уже нет мы полезли за другим их там тоже уже нет но но вот вот так вот все это крутится то есть надо либо со стороны бэкенда уменьшить нагрузку на memcache либо можно увеличить параметрам минусы маленькая там объем памяти который мы разрешаем использовать vixens это вот очень важный момент как раз ситуация про которую я рассказываю она будет видно из того что и vixens рейд он будет очень высокий то есть это количество когда пригодное данные не не next ну то есть они свежая хорошие выбрасываются из кэша у нас туда растет число vixens я говорил что надо использовать бочча как подобрать размер бача ну опять-таки нету никаких там ну серебряной пули нету надо под надо экспериментально это все подбирать некоторые там используют это зависит в первую очередь от вашей инфраструктуры там вот от сети которую вы используете ну естественно от числа там инстансов прочие факторы но когда у нас batch очень большой представьте там ситуация что мы выполняем batch и все остальные ну connection и там стоят ждут пока там но batch выполнится вот это называется есть термин старейшин буквально голодание ну то есть когда остальные connection и голодают и ждут пока там выполнится один жирный вот чтобы этого избежать внутри мамка жить есть такой механизм он прерывает выполнение batch она сильно то есть реализовано это такие довольно грубо есть ключик минус r большой минус or большого который говорит сколько команд можно выполнить может выполнить один connection как бы подряд по умолчанию там это значение 20 вот и вы когда посмотрите на статистику если у вас вот этот конец стад будет каким-то очень высоким это значит что вы используете baci больше чем может нам кажет проживать ему приходится там насильно часто переключать ну контекст вот этого connection а то есть он тут можно либо увеличить размер бача ключиком минус r ну либо не использовать опять-таки со стороны бэг-энда такие матчи я говорил что мы мкэш вы выпихивает из из памяти там выбрасывает самые старые данные так вот я соврал на самом деле это не так и внутри мамка что там ну естественно есть свой memory менеджер то есть чтобы эффективно там работать с этой памятью чтобы выбрасывать эти атомы и вот он устроен таким образом что у нас есть slamz sleeps это буквально называется огрызок но это в в программировании там вот memory менеджеров такой устоявшийся термин для какого-то куска памяти то есть у нас есть там просто какой то кусок памяти большой он свою очередь делится на p джес p&g внутри мамка по мегабайту поэтому вы не сможете создать там данное ключ значения засунуть больше одного мегабайта то есть это чисто вот такое физическое ограничение мамка не может создать там данная больше чем одна страница и в итоге все страницы еще побиты начинки вот эти чанки они тачанки это то что вы видите там 96 120 это определенного размера то есть тут идут куски там по 96 мегабайт потом там куски по 120 но там с коэффициентом 1 25 32 до одного мегабайта и вот в пределах вот этого куска есть два связанный список то есть просто когда мы добавляем какое-то новое значение нам кажется смотрит на размер этого значения но так ключ + значения плюс expiration плюс флаги плюс там системная информация там которое мы конечно нужно там прядкой счет 24 50 байт выбирает размер вот этого чанка и добавляет в двух связанный список ваши данные причем если это данная новая она добавляет их в хет не она всегда добавляет данные вход собственно ну и таким образом получается и еще важный момент когда мы каким-то данным обращаемся то вам кажется вынимает их из связанного списка и опять-таки бросают в head таким образом у нас те данные которые но мало используются они переползают в тыл и потом в итоге они удаляются то есть если памяти нам не хватает тонкость начинают удалять память с конца и вот важно понимать что вот этот механизм ли стресс sing views он работает только в пределах одного чанка то есть вот эти списки они выделены для там какого-то с размера ну это естественно это не фиксированный размер это диапазон там от 96 до там 120 и там попадут вот этот 120 чем там ну и так далее ну влиять на особо на этот механизм но со стальным кэш никак не можем только со стороны бэг-энда надо подбирать там как-то эти данные учитывать можно посмотреть статистику по вот этим слабом кстати ну смотреть статистику моим кажет проще всего вообще протокол полностью текстовый мы можем town этом подсоединиться набрать стат enter и она выводит там такое простыню ну и точно так же мы можем набрать там 100 tslab статься айтюнс это в принципе но довольно-таки похожи информация но допустим slabs он дает как картину такую размазанную во времени там но больше то есть там какие статы что что было что происходило за весь тот период пока вот мамка шт работала 100 tokens там больше вот что у нас есть сейчас то есть сколько есть чего вот как то так но в принципе у обе эти вещи надо смотреть надо учитывать собственно вот мы подобрались к масштабированию значит масштабироваться можно ну то есть естественно там мы поставили себе еще один серверным как здорово вот что что будем делать как-то надо выбирать значит либо мы на стороне клиента решаем но какому с какому серы из серверов мы будем присоединятся там и почему то есть если у нас там evil ability все просто но записали туда записали туда читаем откуда нибудь там неважно можно там раунд роббеном как угодно ну либо мы ставим какой-то брокер и для бэг-энда у нас получается это выглядит все как один инстанциям кэш но на самом деле за этим брокером там прячется кластер в общем для чего используется брокер ну естественно чтобы упростить ну инфраструктуру бэг-энда то есть например нам там надо из дата-центров дата-центр по перевозить как-то сервера ну и нам все клиенты должны там об этом знак ну либо мы там можем чё там хак какой-то за этим брокером там сделать и для бы когда-то все прозрачно пройдет но вырастают latency вообще в принципе 90 процентов где-то запроса всего это сетевой раунтри то есть мамка внутри себя запрос обрабатывает микросекунды там то очень быстро вот по сети данные ходят долго ну и когда у нас есть брокер у нас появляется еще одно звено то есть у нас еще дольше начинают все выполняться ну естественно как бы если клиент сразу знает на какой кластером к штамму идти то он данное достанет быстро и вот собственно как клиент знает на какой там кластер мамка штамм уйти ну грубо мы берем значит считаем хэш от нашего ключа делим этот хэш берем остаток отделение этого кэша на количество инстансов memcached и идем там на этот кластер вот самый такой простой solution но добавился у нас еще один кластер в инфраструктуру значит нам надо сейчас грохнуть весь кэш потому что он стал уже не консистентными ну невалидным вот но и заново все пересчитать то есть это плохо для этого есть такой механизм придумали который называется consistent кашин то есть что что мы делаем мы берем значит with cash значение все возможные хэш значения то есть ну допустим грубо говоря там им 32 берем все возможные значения и располагаем их как будто на циферблате часов вот и таким образом у нас получается но мы можем сконфигурировать что допустим хэш из такого-то по такое-то идут нам на этот кластер ну то есть мы конфигурируем рейндже и конфигурируем кластеры которые отвечают за эти рейнджер ну таким образом мы там можем рисовать эти сервера там как как угодно то есть нам просто надо будет поменять этот в одном месте это кольцо перегенерировать и сервера уже будут знать ну то есть клиенты или там этот роутер брокер неважно они у них будет консистентная представление о том где собственно данная лежат у нас еще пять минут есть наверное я бы хотел сказать про консистентной немножко про консистентных данных как только у нас появляется новое звено ну то есть как только мы копируем где-либо как у нас появляется дубликат данных и все у нас начинает но у нас уже появляется проблема чтобы это эти данные были консистентными потому что но там есть много таких ситуаций то есть например мы записываем данные в кэш ну неважно там локально удаленный потом идем мы пишем эти данные в базу и в этот момент там база падает у нас connection с базой пропал то есть по сути дела ну по логике этих данных у нас нет но в то же время клиенты вот в это же время читают их из кэша эта проблема вот ну конкретно вот memcache плохо подходит для консистенции каких-то решений то есть это больше решение на и вы выберете но в то же время там есть какие-то возможности с касом что-то на колхозе принципе все вопросы на предпоследнем слайде вы показали консистенции ринг то есть то чем она лучше чем деление на деление с остатком на размер потому что если вы делите то у вас на этом циферблате был просто чередовать 1 2 3 4 1 2 так вас получается непрерывно интервал вы просто получаете более простую процедуру перераспределение при добавлении нового сервис да то есть тут тут проблема как раз в том что у нас может меняться число вот этих серверов вот и ну то есть например там такая стандартная там не знаю ну то есть просто пришли и добавили еще один сервер мы можем вписать его в этот хэш и drink вот а если у нас кашин ринга нету то нам надо а дропать весь кэш существующей ну и пересоздавать его заново ну а если у нас допустим но опять же таки в фейсбука 700 около 700 каширу ющих вот этих memcache tanks танцев ну то есть при таком количестве постоянно что-то падает что-то появляется или что-то в процессе переезда куда-то вот и поэтому довольно тяжело работать с вот этим остатком отделения ну то есть это в принципе это consistent cash in the устоявшийся такой механизм вот и липки там а это опять таки довольно устоявшиеся там реализация как раз вот это vacancies to consist in cash ринга такой вопрос ну наверное все зависит от конкретного приложения но может быть есть какие то там стандартные я не знаю универсальные рецепты что когда мы коллируем когда мы это ян го лидируем как мы это допустим считаем там все ли должно это посчитаться там через все через очереди мы там все посчитали там положили в кэш или ну вот что такое но смотрите то есть у нас всегда есть рейдов чем ближе кэш к конечному пользователю тем быстрее его достать но тем сложнее его права лидировать ну и вот вот представьте себе там вот этот ползунок как бы немедленный кэш но более но более валидный там до или надо играться я не знаю ну смотрите на готовые рецепты там как допустим если мы говорим про веб мы сгенерили там какой-то виджет погоды вот этот виджет включает себя там какой-то html какой-то там css какой-то java script какую-то картинку на у нас погода явно не поменяется там но ближайшие 30 секунд на но мы можем просто закинуть в кэше сказать это валим на там час и все потом там фрагмент вот этой этого html этом братья вставлять просто лепить ну как как вот пример здравствуйте монтаж по умолчанию не поддерживает легирование включить ну соответственно записи однако разные библиотеки для работы смотришь предлагают такой возможность я так понимаю что это идет на уровне наименования ключей грубо говоря через точку насколько удачно такое решение и можно ли его использовать потому что этот полный перебор к что ли ключ или получается я протезировании он не знаю но в любом случае у мамка что нет возможности эффективно работать с рейнджерами ну покрайней мере у дефолтная имплементация мамка шт в принципе уже давно про это идут разговоры в протоколе в бинарном есть заглушка специальная для работы с рейнджерами но конкретно вот memcache реализации нет там в любом случае мы достаем или одно данное то есть по ключу или все было сказано про вытеснение данных но было сказано что это делается франки облаках 1 чанга а вот с так слаб он позволяет это увидеть что конкретно до для как бы как я могу видеть что данными числе вы вытесняется в основном и часто в каком танке наборе чанков то есть возможно какой то куски памяти там мегабайт чтобы можно было как-то варьировать данных как это увидимся но вот как раз вот эта команда studs labs у нас нет слайдов ну как команда вот это studs labs показывает и fiction source lab то есть там там есть ну вот прямо что в этом слабит омс с таким-то размером там статистика так не не очень удачно показано ну там будет изначально там что-то типа 2 там slam says там 120 и потом будет там два века шанс и вот вы поймете что это есть число и микшинов в слабину который номер 2 мы вам это не интересно вам интересно что он там 120 гбайт можно ведь рада спасибо спасибо"
}