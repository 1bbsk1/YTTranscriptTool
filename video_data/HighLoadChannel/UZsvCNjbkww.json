{
  "video_id": "UZsvCNjbkww",
  "channel": "HighLoadChannel",
  "title": "Crash Recovery в Распределенном Хранилище / Антон Виноградов (SberTech)",
  "views": 602,
  "duration": 2432,
  "published": "2021-10-04T02:42:07-07:00",
  "text": "всем добрый день я занимаюсь разработкой опачки night и игнайт зверь эдишн это for который мы используем спирте хи и сегодня я хочу рассказать о том как я ускоряло восстановление после сбоев лапочек night и попутно разберемся в системах хранения репликации восстановление данных на примере этого продукта так что же такое сбой ну это природные и техногенные катастрофы ошибки в коде архитектуре человеческий фактор в принципе все что угодно что может привести к поломке или недоступности хранилище и когда мы говорим о восстановлении мы хотим его ну чтобы оно было автоматическим и желательно мгновенным и подразумеваю что мы получим полностью абсурдно и хранилища такое какое оно было раньше в реальности мы зачастую сталкиваемся с проблемой длительного или вообще бесконечно в ожидании этого самовосстановления это может нести большие риски для этого бизнеса которые это хранилище используют восстановление в принципе возможно не всегда например сервер мог банально сгореть и допустим если мы используем схему мастер пауэр то с некоторой задержкой мы получаем работ способное хранилище после успешного приключения фолловеров мастера и восстановление произойдет этой же если это возможно фоне и просто создаст нам гарантии восстановления на будущее если мы имеем схему шарнира ванием то восстанавливается будет только конкретный shorts опять же если он не сгорел дом и большая часть запросов продолжит обрабатываться на неповрежденных шар дах без задержек или с минимальными распределенный хранилище типовое она совмещает обычно в себе оба предыдущих подхода и это совокупность узлов которая образует кластер и работать как единое целое при этом каждый сервер honey часть данных это масштабируемость там дает каждый сервер они также резервные копии другого сервера и это дает нам устойчивость к отказам что же будет если типовому проторенным хранилище один из узлов кластера откажут в принципе кластер насчет процедуру восстановления и мы ожидаем что все автоматически восстановиться к сожалению это не так и в реальности правильный хороший кластер максимально быстро выведет проблемный узел и пусть от нагрузку на другие узлы для того чтобы минимизировать простои для клиента восстанавливать этот узел который вышел будет уже сопровождение в рамках регламентных работ это самый простой способ для именно для клиента минимизировать простой и сохранив при этом функциональность зафиксируем что главная задача крышей камере это восстановить работоспособность хранилища минимальные сроки при этом даже , вперед можно говорить о том что а также сдачи является минимизировать деградацию пары труп этой трассе на период этого восстановления и давайте рассмотрим один из вариантов решения проблемы на основе apache игнайт который мы используем здесь будет немножко информация о том как принципе работы распыленной хранилище кто знает очень хорошо кто не знают то надеюсь будет полезно apache и гнать это определенное киева или хранилища и по факту это разделенные канкана для шмапы собранные по единой крышей где каждая такая мапо называется кашу и для равномерного распределения данных используется хинди функция которая мопед ключи на парте шины об арте шин на ноты и например в данном случае мы маффин нечетные на первой парте шин отчетный на 2 prime марте праймари портится выделенные голубым цветом буковкой p она ответственна за синхронизации бака партиций которые зеленые буковкой p на коне на конце и обновление всегда идет через праймари партицию как минимум в нашем продукте backup партиции от резервные папе данных из них в некоторых случаях возможно чтения по каждому портишь на улицу времени можно только одна праймари ни больше ни меньше в противном случае мы не можем пустить нагрузку поскольку случится про синхронизация либо будет потеряно данные либо что то еще хуже позиционирован эй кэш это такой кэш которым от 0 до n резервных копий на каждую праймари партиции в данном случае у нас конечно s4 партиций и по одному бокалу на каждый теперь тоже самое но два быка по так для сравнения то чтобы вас одним мы копаем то что стало с двумя боковыми инфицированный кэш это такой кэш где на каждом узле есть абсолютно все копии пар тишина из кластера некоторые из них праймари проще говоря это позиционирование кэш где реализован и максимальным максимальное количество бэкапов для этой топологии при этом топология это набор узлов кластера у топологии есть версия и есть список узлов данная топология четвертой версии она предположительно было собрано последовательно и 4 узлов и поэтому я такая версия каждой избе и состава кластера инкрементировать и при выходе узла повышается версия топологии но уменьшается список узлов при входе узла топология снова повышается и увеличивается размер списка узлов переключение это процесс перехода с одной версии топологии на другую это может быть вход ноды выход ноды и в принципе любая другая операция которая ведет к изменению распределения артистов на кластере до версии 2 и 8 попахивает мы делали абсолютно любые переключения под глобальной блокировкой и это позволяло нам осуществить осуществить абсолютно любые варианты такого переключения например выход узла когда только что вошел другой узел или наоборот каскадное падение узлов вход узла с данными которые должны влиться в кластер все это можно было обеспечить синхронизировав это состояние глобальной блокировкой мы завершали обработку запущенных ранее операций и в случае если они были связаны с вышедшими узлами мы вы лидировали их и чинили если с ними было все в порядке там у просто ждали их завершении и после этого начинала у нас создавая . где мы собственно могли все сделать далее мы производили обмен состоянии партиций уже все операции прекратились поэтому состоянии финальная при этом это такая процедура которая стоит из двух частей на первом этапе все узлы передавали текущее состояние локальных партиций то есть где какие данные есть потом состоянии это позволяло координатору понять может ли конкретный узел на текущий момент выступить как праймари для партиции нужно ли будет ли были три блокировка данных и так далее после этого координатор аккумулировал полученную информацию вычислял новое глобальное распределение на данные топологии и передавал его если узлам кластера где каждый узел применял новое распределение ok давайте рассмотрим переключение внимательны нам примере выхода узла на примере входа до входа у нас есть узел на котором есть праймари копии и пустой узел который входит распределение выражается через массив массивов и таффи эти функции его рассчитывать афине форму affinity функция первое измерение это пар тишины второе измерение это узлы где они размещены при этом праймари это первый точнее 0 узел списка и праймари партнерства дальше будем называть просто праймари или про мире праймари клипе остальные узлы в списке которые после первого они бы copy ok на подключение пустому за очевидно что данных у нас нет и мы восстанавливаем реплик лишний гарантий по боковым и начинаем нагрузку после завершения загрузки мы получаем полноценные папе данных но для того чтобы некоторые дни переключить в праве марио некоторых бэкапы мы должны выполнить синхронизацию где в данном случае второй узел скажет что для тех пор тиц и которые праймари на нем он готов сделать их праймале для тех платице которые ставятся там быка fame он готов дать к ним доступ на чтение потому что данные полностью перезагрузились от глобальной блокировкой мы дожидаемся завершения всех текущих операций и просто правы производим переключение логическое переключили нам потребовалось два переключения для того чтобы ввести вывел первые когда мы вели кусты узел и после этого начали балансировать данные и 2 к dore балансировку закончилась и узел начал эти данные обрабатывать приходящие от клиентов случае выхода узла мы имеем ту же самую ситуацию но с одной неприятной особенностью мы теряем праймари партиции не можем больше через них обновлять данные что заставляет нас максимально быстро выбирать среди существующих backup партиций те которые станут праймари так как если вы помните обновление возможно только через праймари и он всегда должен быть для того чтобы классно функционировал следственно для первого пар тишина у нас праймари потерян есть только бэкапы и один из бэкапов на месте целевого праймари защитного affinity функции просто переключаем его праймари готова праймари 2 портишь нас тоже потерян и имеем только одну копию к сожалению она не на месте целевого праймари и будем временно делать ее там где она есть а потом когда сможем переключим еще раз окей переключили 3 пар тише так я не кажется здесь немножко ошибся нет 3 пар тишин тоже не имеет копии данных по целевому распределению поэтому время наставляем праймари на месте таки пропана не останется по целевому распределению оставили как есть 4 имеет копию по целевому распределению и мы сразу просто переключаем логически готово теперь фактически каждый портишь у нас with primary копию и мы можем пускать клиентские операции потому что с точки зрения функциональности кластеры нас восстановлен но помним что некоторые праймари копии портится нас расположены не там где хотелось бы а причиной тому является то что нас по некоторым партнерши нам нарушены гарантий по сохранности данных 2 3 пар тишина имеют данный момент единственную копию хотя число узлов позволяет нам иметь по две мы запускаем ли балансировку создаем копию там где их нет как только у нас кластер отремонтирован мы выполняем переключение под глобальной блокировкой получаем то распределение которые мы хотели ее вместе с ним максимально возможное гарантии по сохранности данных на оставшихся узлах справились мы за два переключения и главным плюсом этой схемы является то что после первого быстрого переключения где мы просто логически переключали про бэкап и в праймари мы полностью восстановили работоспособность кластера и пустили на него нагрузку потом возможно долго мыли балансировали данные которых может быть видно очень много это может занимать часы клиентские запросы при этом полностью обрабатывались возможность меньшей скорости потому что ли блокировка тратить ресурсы и мы снова приключились под очень короткой блокировкой и продолжили работать в том варианте в котором мы планировали это как все работало изначально до версию 2 и 8 и возник резонный вопрос а можно ли восстановиться быстрее да можно но только если очень сильно повезет и поговорим немножко о везении при выходе узлам данные которые были на нем автоматически начнут устанавливаться на всех других узлов кластера через механизм регулировки у нас слева 8 по две копии каждого портишь на и справа по две копии каждого практичность перспективе это в худшем случае 5 даёт нам два переключения первое на восстановления из бэкапов праймари второе на завершение острый балансировки выгнать сейчас не помню сколько версии появился механизм e2 in the повода и он позволяет зафиксировать распределение на узлах кластера вызван то получше да разработать для того чтобы в продакшене случае выхода узлом не начинались ли балансировки потому что они только усугубляли проблему и в случае выхода узла нас линии не меняется и балансировка не начинается из конечно и и не было до этого и при этом мы теряем гарантии по одному бы как у на один узел но это уже задача сопровождение и так выводим узел при наличии установленный боязно винта поводу той зафиксированной топологии мы как бы из распределения удаляем тот узел который у нас вышел отмечен красным вместо того чтобы рассчитывать новое распределение и те моды которые становятся первыми списке за исключением будет вышедших они становятся новыми праймари в данном примере нам повезло и у нас праймари должны находиться на месте двух существующих бэкапов просто переключим их окей с точки зрения праймари партиции мы сели воды при сведении достигли и пускаем нагрузку однако кластер нери сбалансирован рипли creation фактор нарочным нам нужно сбалансировать данные ли балансируем и сразу достигаем целевой топологии проблема в том что мы воспользовались вызван то получше и снова два переключения то есть не совсем понятно какой был в этом профит первые переключение у нас было чтобы восстановить утерянные праймари второе чтобы разрешить работу с ре балансира ванными бы к маме и проблема здесь в том что у нас изначально кластер не был отремонтирован и именно поэтому мы должны были сделать еще одно дополнительное переключение гарантировано при выходе узла в целом кажется очевидным что полностью отбалансированы кластер лучше чем кластер с дырками место партизанов особенно учитывая что активно регулировка еще и забирая часть мощности или себя ведь при распределении когда но прибито гвоздями и полностью завершенный регулировки сколько бы узлов не вышло мы всегда получаем состояние при котором рыб и балансировка нам не понадобится давайте попробуем предыдущий пример повторить на полностью отремонтированном кластере как он был бы в продакшен как мне кажется быка по на месте целевых праймари переключаем все управились за 1 переключение но при этом интересный момент у нас не было никакой необходимости синхронизировать состоянии кластера через обмен состоянии партизанов которые где-то как-то расположены и здесь идея в том что все изначально был расположен идеально полу affinity функции которая рассчитывается локально и кластер мог просто запомнить тот факт что он переключился на идеальное распределение и теперь при выходе узла ему ничего не грозит и по факту мы могли бы переключиться без какой-либо синхронизации просто обозначив локально где будут новые праймари при этом другие ноты сделали бы точно такой же выбор этого мы получаем крайне интересный корни кейс с крутыми гарантиями и возможностями по оптимизации сбалансированная вызван топология это такое состояние кластер которая гарантированно сразу переводит кластер в полностью работоспособный вариант без какой-либо необходимости а снижать нагрузку переключаться позже или что то в этом духе дай ну единственный момент что если нас выйдет больше узлов чем число бэкапов то конечно же мы потеряем данные и отличная новость том что такая ситуация характерна для принципе любого продакшн и поэтому можем сделать оптимизацию только для этого конкретного случая которая достаточно легко реализуется и которая будет работать ну в любом нормальном против и версии 2 и 8 появилась оптимизация премия phrases which то есть switch без п м е которая срабатывает если настроен bass line то есть распределение закрепленного за нотами и нет активный регулировки то есть кластер стабильной и он просто работает окей сравним с тем что было кажется мы перестали сделать самые затратные операции при том если бы раньше у нас вызвали не был зафиксирован нас было бы два переключения значит навестись и повторяли бы дважды теперь мы повторяем и вот теперь мы делаем его только один раз и не делаем из него самые затратные но опять же слова словами а только бенчмарки не врут и этот разбор мы написали целый фреймворк написали мы его на базе докта ipad который используется для тестирования кафки это фреймворк распределенного тестирование то есть позволяющий честный тестировать артериальную систему сейчас мы его готовим вмерзшего подчиняет но данные уже есть и так по имени free переключение дает нам несколько преимуществ давайте начнем с отсутствие синхронизации по состояниям портишь них распределение было идеальным и мы останется и раз уж мы в таком удачном корнер кейси давайте эксплуатировать эту возможность опять же повторюсь мы рассчитываем распределения просто удаляем узлы из зафиксированная фейки что на практике на практике мы взяли стенд на котором у нас было 46 серьезных виртуалок запустили на нем по очереди 276 версию 2 и 8 точнее запускали на по ходу разработки но макей на одну из нот кластером мы стримили путы и мерили худшее в этом си которая случалась за все время измерения далее выводили другой узел и неприятный момент здесь в том что мы видели практически тоже самое в другой версии в рамках некоторые погрешности то есть 200 миллисекунд и 100 миллисекунд но после этого мы добавляем 99 к шее и у нас появляется гораздо больше информации которая требуется к синхронизации в кластере по состояниям партизанов и видим что раньше мы бы потратили на две секунды больше а это в пять раз больше и при увеличении числа кощей эта цифра ну очень сильно возрастает в кластерах бывает нашей гораздо больше чем 100 окей 2 оптимизация теперь у нас нет повода ждать завершенных ранее запущенных ранее операции так как топологии у нас по факту осталось точно такой же единственное что по некоторым парте шинам мы потеряли возможность обновления данных или чтения через прайма если настроена если у нас будет попытка записи данных по ключу мы просто бросим exception в любом другом противном случае мы просто продолжаем выполнять эти операции допустим у нас нога ключевая транзакция которая работала до этого она спокойно продолжит работать после потому что для нее топологии не изменилось если не на придет на плохой prime и ok берём те же ноты тех же версий один кэш создаем абсолютно типичную пользовательскую активность в писе мистик транзакций мы делаем тут ничего не делаем 30 секунд и раубичи при наличии таких транзакций на каждом узле один из узлов кластера выводим и ожидаемый видим разницу в 30 секунд потому что в первом случае мы ждали во втором мы такую операцию не ждем она просто выполняться позже спокойно то есть теперь мы обрели возможность гарантировать что не самый лучший клиентский код не повлияет на скорость восстановления кластера как это было ранее и такие проблемы к сожалению случались напомню чего мы добились на предыдущем этапе и если вглядеться то кажется что да мгновенного переключения нам осталось разобраться только со вторым пунктом ну заодно разберемся что такое восстановление транзакций восстановление транзакции требуется если момент ее коммита то есть транзакция была подготовлена вышел и и праймари узел в данном примере у нас одна ключевая транзакция обновляет данные на одном праймари и 2 я бы капах при выходе 2 узла мы теряем уроки потому что локи у нас на праймари как минимум вы знаете и нам требуется дополнительная проверка состояния бэкапов на предмет того восстанавливаем о транзакции или нет полностью ли она была за конечно подготовлен то есть также нам требуется вас 0 и транзакции если вышел и и узел координатор это может быть клиентская но до или серверная с которой транзакция была создана вот только ну раньше мы такие транзакции тоже ждали а по факту нет никакого смысла такие транзакции ждать на переключение потому что они могут данном конкретном случае в премия free восстановиться и после него так как все праймари этой транзакции сейчас живы значит ключи потоками значит это обычно это 7 стих транзакция которая данный момент комитета и нет никаких проблем эту транзакцию продолжать ok однако если бы у нас был бы cup только один там и мы не столкнулись то вы проблема потому что есть два варианта либо вам войсками тли бату войсками туан войсками ты-то когда есть один праймари один бытом и такая транзакция в самоустанавливающиеся все изменения комитетов бэкапы и это гарантирует что в любой момент времени у нас изменение консистентной какая бы какой бы из узлов не вышел транзакция либо полностью закончилась либо ее нет для туфа из капитан tu fais коммент нам нужен если у нас праймари или бэкапов больше 1 и 2 фазы нам решают помогают решить проблему не кассет оси состояний транзакция во время восстановления будет за конечно если она подготовлена на достаточном количестве узлов ну например случай выходе праймари на ее бы капах и других праймари возможной оптимизации просто разберем пример 1 ключевой эту войска транзакций в первом случае у нас подготовлены данные на обоих бэкапов во втором к сожалению только на одном из бэкапов и 1 транзакция будет закончена на восстановление а вторая zara обычно об база вас recovery разобрались и собственно вопрос а можем либо становиться еще быстрее кажется что да и переходим к оптимизации которые получились версии 2 и 9 и были значительно улучшены в 211 будет сразу разбираться с последнего финальным вариантом мы снова стараемся найти корни рки из который был бы приемлем для продакшена в котором мы получали бы особой гарантии и такой корнер есть нашелся и идея в том чтобы мы минимизировали список узлов хранящих backup партиции для каждого из потенциально вышедших узлов то есть при выходе узла только часть узлов требовал восстановление посылка являлось для него бы kappa me есть проблема в том что играет используется рандеву affinity которая по умолчанию размазывает партиции по костру достаточно равномерно и при выходе узлом практически каждый другой узел будет являться ему бэкапом но можно схитрить разделим узлы так чтобы они образовывали виртуальные ячейки где праймари и все ее бы копы всегда были в рамках одной ячейки это можно сделать с помощью backup фильтров мы эту доработку тоже заметили вукан source и пробежимся по первой ячейке 1 parte шин 2 3 и 4 все расположены в рамках одной ячейки исключаем из нашего кластера узел праймари у него по 2 портишь ну и это разделяет кластер на зафиксирую и не замеченную область при этом в данном примере нам нужно восстановить операции только по второму пар тишину и только на первой ячейке а значит не засек что не узел мы можем переключить сразу много ключевые транзакции пока не затрагиваем там есть некоторые исключения итак мы полностью переключили 2 и по поводу за affection узла дальше свернуть да раньше у нас был распределенный команда удачно переключение всего кластера во время восстановления у нас все узлы за ждали завершение каждым это восстановление версии 211 мы полностью от него избавились для прими это и приключений в правые чеки у нас все хорошо и мы сразу же ее завершили левую ячейку мы мы и завершили и сразу пустили на нее транзакции код клиентский код какую-то активность все ночного начал работать левую ячейку мы проводим через процедуры recovery переключая на ней backup первом узле в праймари переключили и того правая ячейка сразу левые через png free на этом все мы получаем мгновенное переключение того что не было зафиксировано венное в рамках минимальной синхронизации на уровне там посылки 1 массажа и pm я при переключении которого мы сделали быстрым в 28 для всего что было захерачим и снова доверяем только бенчмарком делаем 11 ячеек теперь у нас но до поделены между ячейками непрерывно с 11 клиентов стримим на каждую из ячеек обновления то есть один клиент на 1 чайку перебирает на не папанин по очереди ключи по этой ячейки делают ставки мере худшую в этом 7 при этом что делали мы набрасываем 500 подготовленных транзакций на каждую ячейку судьба принадлежащего этой ячейки при этом нас получается узел создаете транзакции который мы его же ячейки и принадлежат то есть мы изолируем транзакции по ячейкам без пересечений и видим что на свежей версии у нас только поврежденной ячейка делает рекавери и вообще ну долго переключается по остальным ячейкам значительно купает гидратации watenshi мы не видим в принципе у нас операции выполняются меньше чем 1 мире секунды конечно же но вот те 22 там 64 это просто разброс по нашим конкретным стенду был это вот то время которого мы добились которое требуется просто на отбивка о том что надо переключилась и так замерим также вариант когда у нас нет транзакции потерявших праймари то есть транзакции которые нам нужно восстановить из за того что не вышел координатор но нет необходимости таких стран доска дождаться потому что они повреждены порожден только логически то есть все ключи у них остались потоками окей со второй ячейке мы опять же подготавливаем 1 ключевые транзакции избегая кричи предлежащей 1 и 2 ячейки первые чеки у нас будет контрольное мы по ней мы видим самый лучший скорость который мы можем достичь на второй ячейке у нас тоже не будет транзакций но одна из нот ячейке будет отвечать за координацию транзакции которые были созданы остальные ячейки запустить восстановления из за того что у них вышел координатор но если у транзакции вышел координатор но переключаться будут без его ожидания потому что это не необходимо эти транзакции спокойного становятся на следующий топологии и если по ним по этим по ключам этих транзакций будет доступ толоки нам все помогут защитить ok но есть нюанс к сожалению не к сожалению вот знаете есть репликейт от каши которые как я говорил раньше занимается тем что на каждом узле создают и праймари backup копии для всех партийных и сущий если нас выходит узел конечно же если есть реплики that cash и то все остальные узлы ну или почти все остальные узлы будут являться ему бы kappa me но здесь суть в том что нам не нужно же такие транзакции потому что если на узле нет транзакции привлекает от кашам то это означает что их или нет в принципе на кластере либо нам повезло и такие транзакции от рика варится то есть они где то есть подготовленный а где ты их не значные точно 3 говорится и ждать нам нечего мы просто переключаем это дело мгновенно то есть нет транзакции либо лечите подготовлена мы переключаемся мгновенно а если есть транзакции то конечно нет но справочнике обновляются крайне редко окей теперь интересный кейс надо ключевыми транзакциями которые не ускорились среди столь на чительно но все-таки мы делаем так нет и пока не проделаем пока если транзакции затрагивает ключи поврежденные и не поврежденные ячейки то естественно что обе ячейки будут ждать это восстановления и с версии 211 на не поврежденные ячейки мы будем ждать recovery как и ждали раньше но только по ее транзакциям они полного восстановления всего кластера то есть узел переключиться с такой скоростью который сможет не дожидаясь глобальности подготовим много ключевые транзакции таким образом транзакционных будут по три ключа на узлы избегая первую контрольную ячейку выведем узел и остальные ячейки запустил становление своих транзакций так как упал координатор но дожидаться будут только транзакций которые у которых вышел праймале получается что примерно у нас каждая 30 транзакция является такой то есть ждать не слишком много транзакций и видим что у нас не поврежденные ячейки устанавливаются значительно быстрее чем не значительно быстрее чем поврежденная происходит это по двум вещам во-первых неповрежденные чеки останавливаться через праймари транзакции то есть у них есть этот набор дааа поврежденные отсеки восстановится через backup копии то есть в два раза больше работать собственно что мы и видим на графике и здесь сожалению нет оптимизации который бы приоритизировать восстановление тех транзакций которые принадлежат ячейки и их требуется требуется и проставления для переключения просто оно еще не сделано как бы приходить его пан source мы любим комитет полезные и здесь в принципе можно было бы уложиться ну получается в 30 раз быстрее но пока нет пока просто лучше окей есть проблема в том что до по проблеме пак ладно резюмируем для неповрежденных ячеек при выходе вызвал мы теперь причащаемся практически мгновенно теста показывает что у нас в этом си ухудшается в среднем от 30 40 миллисекунд после поставив 227 276 и это очень круто результатов мне кажется но все не так хорошо и можно сказать что все изменения были практически бесполезны к сожалению и такие могут быть но являются очень часто проблема в том что мы разбирали работу абсолютно идеальных тепличных условиях настройки реального продакшена отличаются от этих условий и нужно еще небольшое погружение для того чтобы разобраться у нас есть выгода эти два типа discovery 1 работает по принципу кольца это общение между нодами по организации кластера а собственно закипел discovery общается через на кучу много лучевой звездой социально держит большую нагрузку по числу нод у нас сожалению узлы кластера могут выходить совершенно по разным причинам и некоторые из них это проблема узел может выйти планово получив сектором при этом он сообщает костру что он вышел у нас есть shutdown hook который гасит ноду если приходит сектором и оповещает вас о том что он вышел из лестно кластером почти мгновенно понимает что узла больше нет то же самое вы можете настроить файл handel которых случае ошибки выгоняйте или ошибки вашем коде будет делать то же самое будет опускать узел и сообщать к пастору что этот узел нужно исключить но есть проблема что иногда узлы умирают посетил допустим у администратора кончается сей все такое тоже бывает в crash живым операционки железо третья проблема что узел может молчит как партизан до последнего если он сейчас джесси ему не хватает процессорного времени или сей задерживает и фильтру и сообщения и в этом случае мы будем признавать его вышедшим только по истечении тайм-аута а дефолта вы и тайм-аут и большие в итоге я на мере вот такую матрицу деградации войти с помощью фреймворка которые мы написали на выход моды из кластеров случае чищу и чистого переключения на 500 транзакций 1 бар который мы рассматривали и несмотря на удивительный момент что ты по discovery замечательно обрабатывает сектор у него есть для этого интересный механизм могу искать позже видим что если у вас классных продакшене то вам нужно опускать но ты всегда пусик term настраивать failure хендлер иначе скорее всего некий оптимизации вам не помогут также вам нужно настраивать правильный таймаут на обрушит на обнаружение выпадение ноды или и проблем иначе ваши операции могут выполняться слишком долго ждать пока это надо выйдет на самом деле чтобы продолжить свою работу окей еще один момент важно понимать что ваше железо должно быть настолько хорошим насколько у вас высокие требования например для звуки пера когда мы тестировали эти бенчмарки мы не смогли развиться работа с области на тайм-ауте 500 миллисекунд пока мы не включили его в рай тоха блок синхронизацию на диск ну вот у нас были такие виртуалке которые нам не гарантировали быстрое сохранение на диск и мы могли работать только на тайм-ауте в 34 секунды резюмируя финально случае собачек знает тип discovery стоит выбирать исходя из того сколько узлов у вас есть в случае выхода узла планового всегда нужно использовать сектором этот не только для игнайта для любой системы система всегда знает как ей лучше остановиться поэтому нужно подхватить команду остановиться они просто kill -9 правильный файл finder который есть не только вы знаете но и привычки в любой хорошей системе он ускоряет recovery потому что сообщает кластер о том что на ноги проблемы и лучше исключить как можно быстрее не ждать тайм-аута дефолты сделано для того чтобы работать везде допустим failure detection тайм-аут нас 10 секунд и это значит что по дефолту случае проблем в этом все у вас будет 10 секунд плюс это может быть проблемой для конкретно вашего продакшн и оборудование должны следовать требованиям просмотрели на примере за кефиром и самый важный момент что ваша нагрузка ваше железо ваши операционки все все все это все абсолютно уникально и вам нужны профильные бенчмарки всегда но не только на так вы делаете работу войну на то как вы на только ваша система ломается потому что перед выходом пород вы должны как минимум один раз оценить что же будет если у вас будет отказ оборудования и потом это делать регулярно и начали ну иначе будет все что угодно скорее всего плохо и на этом на сегодня все огромное спасибо за внимание подробнее о фреймворке который мы разработали для тестирования замеров реальных условиях расскажу на играть сами эти 25 числа он в онлайне бесплатно и приходите и исходный код нас готовится к мертвым собственно доступен на гитхабе смотрите можно кормить не предлагать изменение антон если бы я был извергнут а я бы конечно тоже с удовольствием платил тебе за работу надо собственным продуктом единственно горох оговорка принято никаких договоров то есть простая чего не смерти ваши руки друзья есть нас на третьем ряду еще поднимаете у кого есть вопросы чтобы мы за родником успели подойти добрый день тысяча как над индекс простой вопрос вот вы выключаете хоть лоб на закипели звучит очень устрашающе с этим вопроса какие тесты корректности гоняйте там не знаю джексон игнайт умеет натравливать не умеют по поводу отключения радха блога это мы делали только для замеров потому что мы хотели понять того насколько пир может вытаскивать о performance у но у нас не было железо в этот момент когда мы мерили настоящий только virtual второй вопрос про джип сафари для резина и то есть в джексоне тесты они прям репозитории джексона насколько они гоняются для меня загадкой а не в курсе знаю что они существуют но надеюсь что гоняется а могу еще тогда вопрос если пока других нет вот хорошая идея про целы про то что вот мы в целых собираем такие группировки теперь один хост вводим и более-менее там бизон тайна переключаемся вот хост вышел а умеете ли вы добавляете назад другой хост кнопку что не заход сломался он там неделю будет чиниться очевидно не хочется жить там звание репликации вместо тройной все это время хочется ввести новый можно чуть-чуть в микрофон я некоторых вот есть сел в нем есть хвост этот хвост вышел на экран там обновляется не страшно вон там через час вернется допустим он сломался совсем хотим назад вернуть хвост вот умеет ли система такое система на данный момент на вход узла сделает максимуму работа это нужно делать регламенты часы сейчас как минимум каких-то до работа по оптимизации нет пойдет узел на него начнётся регулировка на длина то есть будет два переключения одно ну так быстрое переключение потом длительная и балансировка которое вам немножечко притормозит или множечко притормозит кластер потом еще одна перед выход быстрый обход все равно к сожалению да мы оптимизировали тот случай который несет риски то есть вход узла это регламентные работы вот так вот еще вопрос и если у вас если он кажется у вас глупый вопрос задайте его потому что лучше вопросы это те на которые трудно отвечать то кончику поднимите руку или из онлайна выйдите в и fergie два вопроса у нас все-таки есть спустя от 1 до кончика которая из них тебе понравился больше 2 просто теперь конечно или получаешь книжку за второй вопрос антоном и те благодарна очень выступление и вручаем тебе рамку именуют в нашей признательностью худи и значок с голодом можешь их прославлять замечательная встреча всего нашего сообщества ребята спасибо вам огромное за ваше внимание и поблагодарим докладчика"
}