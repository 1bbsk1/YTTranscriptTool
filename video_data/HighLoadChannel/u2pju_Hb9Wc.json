{
  "video_id": "u2pju_Hb9Wc",
  "channel": "HighLoadChannel",
  "title": "Хранение данных на виниле / Константин Осипов (tarantool.org)",
  "views": 4092,
  "duration": 3468,
  "published": "2017-04-22T14:48:15-07:00",
  "text": "это доклад про 17 наш новый релиз который сейчас в состоянии бета кто знает шутку про бету better на над и да но если говорить серьезно то мы у нас сейчас идёт уже 3 внедрения этого релиза как нагрянет внедрениях мы испытываем проблемы но мы эти проблемы решаем вот надеемся что все это стабилизируется до конца этого года параллельно ведется разработка следующего релиза и так далее то есть процесс такой значит доклад про основную фичу этого нового релиза и к боковой этот доклад можно там был по-разному предполагать какие как аудиторию придет но и то есть смотрите можно сделать доклад какой-то обучающий там про разная структура данных а можно рассказать про то что сделали конкретно мои я избрал второй подход потому что в первую очередь важно что люди которые этим пользуются не понимали что это такое то есть я предполагаю что у вас уже есть какое-то представление что из себя представляет система и буду рассказывать про как бы внутренности которой необходимо при для понимания того как пользоваться вот и тут надо еще сказать пару слов обо всем об этом то есть этот доклад был написан вчера за там несколько часов он написал себе несколько несколько листиков подсказки быстро набросал слайды поэтому я буду обращаться к флипчарта за визуальным иллюстрациями отпуск бывает такая значит 1616 мы имели такой экспериментальный рыжук который назывался софия это очень долго с ним учились и в итоге решили все переписать диска вы вообще desk top это очень такая сложная и пожалуй но тяжелая задача вот можно посмотреть на рынок вообще дисководы шкафы видно что во-первых хороший движков не так уж много вот есть сейчас там стабильный проверенный mais quel сына тебе которые много знают как людей как пользоваться и он действительно держит 1000 запрос секунды действительно работает хорошо немного проверены в эксплуатации я не благодари рупор коммерческие там не говорю про коммерческие базы данных на сигма сиквел oracle да там действительно уже тоже проверенные временем движке я говорю про open source есть рок сгибе который тоже сейчас активно развивается если мы посмотрим пророк на рук дебиторок zebeta for клевал д.б. то есть оказалось что внезапно google сделал что-то что нужно еще for cutie доделывать и здесь есть марк аллах он здесь есть слово прямо который разрабатывает рокс baby подойдите к ним спросите сколько людей работает на друг себе есть всякие другие экзотические вещи типа wild tiger force дбн еще что там нас д б л д б многих но реальная очень сложная задача то есть если сравнить там тоже фейсбук котором там 10 десятых может быть человек разрабатывает просьбе и нас то как бы возникает вопрос а куда вы вообще замахиваетесь зачем вы делаете свое почему вы не возьмете что-то существуешь и ну вот у кого такой вопрос возникает наверно тогда на него ну а значит получается так что мы это делаем потому что мы можем то есть это такая слове есть хуцпа у нас хватает наглости делать это когда мы все это ввязывались мы на самом деле не понимали вообще что мы обязуемся сейчас год спустя интенсивный там работает последние полгода очень интенсивный мы можем сказать что данный отчет добились то есть мы делаем это потому что мы можем это первая печь вторая вещь почему мы это делал это на самом деле обратная сторона техническое это то что тут denis говорил про всякие там современная история как можно сделать все супер эффективно и тарантул построен по актер борис архитектор то есть все сделано без зло кубизму takes off с минимальным количеством блокировок и так далее и если просто взять устроить существующей движок нельзя потому что он предназначен для встраивания в trapper connection скажем так системы то есть вот манга деби mais quel они больше рассчитан на трек про connection to joe rox baby который является на сегодня с самым сильным кандидатом и по чесноку сегодня делает как бы на собственный движок во всех кейсах кроме тех которые мы когда который мы заранее вот создавали то движок то встраивание вов тарантул бы такой тяжелой эффективной задач и в результате этого встраивания мы можем на самом деле получить то есть вот если говорить про параллельные пород проблем параллелизмы то есть мы говорим что вот actor байсерке так вчера она вот является следующим поколением мы все весь все базы данных будущего они будут построены по по таким архитектором вот для янамари это просто является как бы обязательным условием дисковые движки у них основном основное как бы ограничение узкое место это а я то есть вот вывод и там проблему параллелизма на несколько цикл они не такие серьезные на самом деле они тоже возникают то есть мама rebound work лауда readonly workload для них тоже возникает мы можем добиться на самом деле неплохого прирост конечно не в 10 раз ну пару раз можно добиться прироста производительности за счет того что мы перестраиваем даже существующей алгоритма на actor быстро архитектуру прежде чем говорить о том что мы сделали нужно сначала немножко разобраться в том как бы базовые алгоритмы волосами кто из вас не знает что такое last blog страх черт мираж-3 сегодня кто не понимает как он работает выше руки пожалуйста оценить я очень как бы а кто знает то есть не понятно есть неопределившийся вот а значит смотрите вот losing а где дерево это структур данных предназначены для оптимального цель на используя полосы диска то есть базовая такое предпочесть предписание завет на основе которой построена на самом деле это то что диски имеют медленный рандомный но давайте попытаемся избежать рандомного ввода-вывода и максимально работать с диском линейно и как это делается за счет того что на диске поддерживается множество отсортированных массивов им из массива постоянно перестраивается при этом задача алгоритма это снизить количество таких операций по созданию перед сортировки массива теперь как это работает конкретно вот здесь есть некая иллюстрация изображающий треугольнички треугольничек по сути это тот самый отсортированный массив когда треугольничек находится в памяти кстати в моем докладе вообще можно меня троллить я это с удовольствием да вот вот такой треугольничек то задавайте вопросы как только они у вас возникает такой треугольничек в памяти это просто допустим тот же std ordered map потому что нам нужен сон был сортированы по порядку лекси лексикографические до данные в нем должны быть отсортированной расскажу почему это просто допустим std map после того как с учетом того что dice которое то принципе история про то что давно может быть много больше чем оперативной памяти кустов как у нас это оперативной память заполняется мы записываем делаем дам записываем этот сортированный массив на диск и что такое наполнение ну допустим где-то вставки обновление это все наполнение массивов память select и пока у нас есть только данные на в память они прям идут исключительно из оперативной памяти то есть в этом случае этот движок не отличается от in-memory практически ничем дальше появляется следующей ситуации что у нас есть какие то данные в памяти из какие данные на диске и когда ситуация повторяется несколько раз у нас появляется несколько таких дампов на диске вот таких треугольников на 10 становится много соответственно select и то есть поиск нужно делать и в памяти и на диске каким-то образом объединять результаты я об этом чуть позже расскажу значит вот если просто взять это алгоритм от без без всего что дальше рассказал появляется проблема такая что чем у нас стоимость поиска будет н.н. на количество таких массивов нанести поэтому периодически много мелких массивов они пересортировать и сливаются в один то есть фактически сортировки там нет там есть второй шаг сортировки слиянием до слияние нескольких отсортированных участков эта ситуация повторяется это поведение повторяется рекурсивно при этом а вот почему как бы вот ловил тебе называется lordi bite называется лев толстой старается сделать так чтобы на каждом уровне данные как бы немножко оседали и каждый следующий уровень он больше предыдущего то есть следующий уровень начинает наполняться тогда когда предел размеры предыдущем уровня достигнут таким образом типично всм деревьях зависит конечно от условий эксплуатации каждый следующий уровень несколько раз больше предыдущем и на каждом следующем уровне у нас таким образом хранятся какие-то старые данные потенциальные старые данные кому пока что непонятно все понятно за счет чего диск диск а за счет чего диск линейный линий используется у нас объем оперативной памяти обычного все-таки не маленькие да то есть вот для записи когда мы делаем запись на диск мы дампир целый массив это обычно десятки мегабайт если не сотни за счет этого мы бомбим ну стоимость запись одного табло она фактически пропорционально размеру этого то при пересортировать мы также берём от сортировки слиянием таких отсортированных ранов мы берем уже уже большие файлы читаемых большими блоками и с пишем большими блоками то есть диска мы используем для записи по крайней мере и период сортировки максимально эффективно с пропускной способностью полосы при поиске у нас возникают проблемы почему там lsm считается в райт оптимальное the structures потому что при поиске нам нужно искать в нескольких уровнях и потенциально хотя каждый уровень отсортированы то есть мы можем там бинарным поиском например из когда это все равно долго кстати сколько может быть его допустим каждый следующий уровень два раза больше предыдущего сколько может быть всего уровней не больше чем на 1000 24 неплохой логарифм от чего количество элементов деленное на количество памяти на самом деле логарифм от этого значит теперь я уже упомянул что в этой структуре поиски проблематичны возникает определенная проблема при удалении то есть за счет того что удаление как таковым и не можем сделать ну во всех этих структурах то есть у нас есть разные версии данных на каждом уровне приходится удаление заменять на вставке то есть удаление делается с помощью маркера удаления делается вставка в оперативную память о том что определенный элемент был удален и дальнейшем при пересортировать вот такой вот маркер удаление там stone он записывается на следующий уровень на следующий in и в конце концов на последнем уровне мы можем его самого выбросить при пересадке рокки при создании последнего уровня нам tombstone сохранить нет необходимости до маркера удаления последнего уровнях не содержит никогда уж если данных нет на последнем уровне их просто нет поиск соответственно делается так же да то есть мы ищем сначала на первом уровне если мы их не нашли то есть у нас оптимально примет такой оптимистичный стратегии попробуй поискать здесь не нашли идем следующем то есть если ищут самые свежие данные то есть эта структура она предпочитает поиск по самым свежим изменением до когда мы доехали до последнего уровня до предпоследнего уровня он у нас переполняется мы запитаем ся вопрос значит я пытаюсь повторить мы пытались записать последний уровень перезаписываем ли мы весь последний уровень в общем случае да то есть базовый алгоритм такой что у нас каждый уровень он содержит отсортированные данные из всех предыдущих из из предыдущего уровня и мы его просто целиком перезаписываем значит теперь давайте еще есть такая штука в базы данных к короне запросы как корр как работает трель запросу допустим и сказали что пойнт запросы по запросы по одному ключу они могут быть достаточно эффективны но хотя бы мы не лезем во все уровни как только мы нашли мы возвращаем результат рейс запрос такой роскоши себе позволить не можешь потому что ну вот я здесь пока воспользуюсь иллюстрации как раз не хватает иллюстрации представим себе что у нас есть вот свежие данные там 13 произвольные цифры здесь у нас там я просто использую на самом деле то что данные по возрастанию не имеет никакого значения это все произвольной цифры вот у нас есть несколько уровней до 249 13 допустим мы ищем между диапазон мы ищем между 5 и 7 да то есть нам нужно поискать 5se мы смотрим здесь мы не находим можем ли мы удовлетворить с результатом нет нам нужно посмотреть и здесь вот эти вот данные проверить и здесь вот этот диапазон нам нужно проверить то есть рэй запрос волосам дереве должен смотреть на все уровни всегда я осуществлять интеллектуальное слияние данных на всех уровнях то есть с учетом того что допустим здесь здесь у меня все ключи разные но представим что здесь хранится предыдущая версия ключ опять таким образом нас здесь есть старое значение здесь есть новое значение да и в этой ситуации нам нужно отбросить старое значение конечного результата верны только предыдущие да еще нам нужно отбросить удаление значит давайте как бы проверка знаний какие здесь алгоритмические потолки то есть выше чего мы не можем прыгать прыгать если у нас есть базовая структура данных попробуем сравнить с до деревьев то есть block b это log по основанию b здесь б это на самом деле отношении отношения между уровнями то есть вот получается энное количество элементов а.б. это да размер блока да все правильно байта размер блока значит но здесь мы н делим еще на некое число которое соответствует соотношению количества оперативной памяти и общего объема данных то есть что что тут важно как понять во-первых вас основание логарифма она тоже самое но значит здесь у нас n прежде чем применяется к нему оценка делится на достаточно большой что-то в это обычно достаточно большое число 1000 замеряется тысячах то есть фактически на самом деле сложность такого алгоритма на зависит от ширины ввода а не от количества элементов можно так себе рассматривать как вот в радикс деревьях так давайте не пойдем в родах деревья значит что в чем что остается проблемой поиски до поиск потенциально многократно хуже это константа к она очень плохая и поиск в общем случае это бинарный логарифм мы попробуем сейчас поговорить о том как это можно улучшить но в общем случае это умножаем на константы берем бинарный логарифм что мы должны делать бинарный поиск в каждом уровне и забегая вперед есть очень много исследования о том как ускорить поиск в такого рода структурах там есть фрактальные деревья есть используем для фильтров кокин фильтров и так далее то чтобы ускорить поиск но поиска является самой большой проблемой в волосы далее если мы говорим о промышленной эксплуатации этих в этих структурах данных мы еще должны поговорить о каких-то проблемах до которые возникают что такого алгоритма в лтп выбор кладов то есть вот вопрос к залу на самом деле какие какие проблемы вы видите у этого подхода вот для а лтп часто отношении чтение и запись 70 на 30 хорошо допустим нас 50 на 50 у нас есть какой-то в райский часто и чтения мейджор будет хорошо давайте просто говорить не лтп для вы обладаете говорите просто у нас есть социальная сеть хорошо хорошо много записей мейджор умер на самом деле это все не те проблемы которые хотел бы услышать вот давайте просто задумаемся о том как как эта структура данных вообще работает когда у нас уровень переполняется что с ним происходит она блокируется то есть вот она же конкурентно должна быть да то есть вот и есть проблема реализации это первое второе давайте подумаем сколько места она вообще занимает на диске сколько вы допустим над каждым два раза больше предыдущего сколько места какой у нас overhead на папа места на диске может один максимум если все данные нового верха до нету вот как раз таки прикольно да а а какой худший случай худший случай бесконечность может быть одна запись настоящая так так вы если одна запись всего все остальное удаление то у нас худший случай бесконечности смотрите вот как понять сколько дерево занимает место такое значит представим себе что у нас есть последний уровень каждого предыдущий уровень растет как с коэффициентом 2 до таким образом последний уровень два раза больше предыдущего и так далее так далее то есть ну данные уж точно не избыточный на последнем уровне то есть на последнем уровне мы данные избыточным образом не храним а все предыдущие является суммой прогрессия 1 2 + 1 4 плюс 1 8 + и так далее да то есть у нас в случае коэффициента 2x по росту уровней у нас 2 в два раза больше хранится и данных такой недели но на самом деле два раза это много представим себе что один терабайт до назначен узнать двух терабайт диск теперь еще определенный возникает проблема со спэйс амплификация так называем то есть из более боле менее формально и понятия я сейчас попробую их да здесь да то есть вот мы мы упомянули есть три показателя ридом пресекаешь энрайт амплификация space амплификация и которые говорят о том что у нас может возникнуть много мусора соответственно нам приходится много хранить у нас может возникнуть много записей то есть на многих придется постоянно перемешивать уровне и у нас медленное чтение но еще по мере того у нас происходит такая ситуация что когда мы читаем внезапно кончается место в по оперативной памяти нам нужно сделать как-то перетасовать структуру дано соответственно нужно блокировать и за это нам приходится ждать технические проблемы реализации они теоретически полу теоретически из формулирования таком вот есть рамка джек шарит optima я straight optima спс optima что трейдов и у структур данных я предлагаю вам сходить почитайте вам эта тема интересна теперь давайте посмотрим каким образом мы можем эти проблемы адресовать вот у нас вот мы в лоб берем реализуемого смл горит значит у нас тарантул 1 3 давай соответственно в в целом всю работу конечно есть worker тренды все работа позором с диском должны должна работать пред пули продакшен процессор при этом выделенные вся работа с памятью может работать быть сделана прямо в нем соответственно мы можем сделать так чтобы in memory уровень был чисто в transaction процессоре что мы собственно и делаем отлично теперь появляется следующий следующий проблема вот у нас есть соответственно память и у нас есть что-то на диске там какие-то уже дампы сделаны в какой-то момент нам нужно записать заполнившей ся заполнить шоссе массив памяти на диск если мы это делаем слишком поздно то у нас фактически кончается память пока мы пишем соответственно нам нужно предсказать тот момент когда нам нужно уже опустошать оперативную память потому что иначе на свои просто не хватит и собственно этот подход у нас используется мы предсказываем что вот допустим у нас есть один гигабайт оперативной памяти скорость диска 10 мегабайт секунду скорость входящих вставок один мегабайт в секунду это означает что мы можем наполнять нашу оперативную память где-то до девиз 900 мегабайт потом эти 900 мегабайт за 90 секунд задам пим и пока мы бомбим эти девин 900 мегабайт за 90 секунд у нас накопится еще 90 мегабайт если мы опоздали то все как бы у нас возникает проблема слейд оси нам нужна оперативная память для получения нового за обработанного запроса на что нет соответственно одно из фундаментальных систем которые мы сделали должно быть структуру работала это вот такие такой системы с гистограммами когда мы собираем на каждый дампа скорость этого дампа когда мы смотрим и корректируем полосу на вход для того чтобы система корректно работал в онлайн сценарий чтобы lighten7 не скакал теперь возникает другая тема что если у нас вы просто запись и на записи больше чем вообще за диск справляется полоса диска просто не справляется ведь у нас же есть еще мир уже да то есть нам помимо дампов нужно делать еще пир сервировки вот этих вот сэр массивов перес сортировки уровней в этой ситуации опять же система должна деградировать не ну а бревна да она должна делать деградирует плавно и опять же мы это делаем мы вставляем задержки на обработку запросов для того чтобы система деградировал плавно дальше вот предположим что у нас есть это массив память мы его данным на диск в этот момент мы вынуждены заморозить по сути модификации массивов память если мы заморозим эти модификации у нас опять же не работает следующую ставки поэтому у нас появляется так называемый shadow массивы когда в оперативной памяти может содержаться несколько замороженных копий которые в настоящий момент в процессе дампа на диск находится мы их ещё удалить не можем но мы их ищем и мы мы их можем искать то есть они используют исключительно для select of после завершения дампа они могут быть удалены и освобождена до да пользовательские операция вставляется задержка да у нас же event система соответственно мы вывел клуб вставляем эти задержки то есть предположим что у вас допустим тысячу запросов в секунду и система не справляется с этой тысячи запросов секунду лучше сделать так чтобы на каждый запрос была задержка одна миллисекунда чем если вы получите раз там в 100 секунд задержку в пять десять миль пять десять секунд допустим да это приводит к на самом деле к замедлению чтения тоже там там немножко не так устроена получается что если это нет point lookup они идут через эту систему то есть потолка придут через отдельный пул задержка вставляет свой vin клуб то есть у нас в вент лупи может быть ограниченное количество фармеров то есть управляется этим одновременно в запрос в обработке допустим несколько тысяч запросов и на каждые несколько тысяч запросов мы вставляем мистики миллисекунду если есть этот запрос действительно если там point look up of допустим очень и очень много то они будут задерживаться но в целом они должны пролететь но вот другого способа это кстати . разумная критика мы очень долго ломали голову как как эту проблему решить и в итоге мы пришли к выводу что единственный способ это проблема сшить это вставлять задержки потому что мы не можем допустить как бы скачкообразного падения улыбнись если вы есть лучше идея то дайте нам о них знать опять же тарантул главные такой как бы бог это оперативная память если оперативная память начинают кончаться системника коем случае не должна сводится то есть вот по сути мы вставляем задержки мы вставляем тротлинг мы предсказываем полосу если всего этого не удалось сделать то уже включается ожидании dos об освобождении оперативной памяти до в задержке в одну в несколько миллисекунд в блогах не видите если если тролли включается да кстати х разумный вопрос мы просто должны добавить до разум ну на добавить большая просьба будет пожалуйста все вопросы после выступления и в микрофон спасибо я лучше буду повторять вопросы пускай ребята спрашивают просто запись идет запись и не слышно будет вопрос печаль а значит дальше есть еще одна проблема которую тоже какие-то другие системы могут решать допустим своим способом но у нас и на серию возникает из из-за нашей архитектуры power bass мы не можем освобождать большие объемы памяти то есть вот представим себе что вот этот тампон завершён нам нужно освободить этот shadow массив если мы будем освобождать данным табл байта пол доп одна строка за строкой то там может быть сотни тысяч строк мы просто убьем полу объем куча ресурсов на то чтобы это все подчищать соответственно для in memory мы пользуемся теми наработками которые у нас есть для моим текст движка и здесь используется специализированный локатор который умеет освобождать всю память просто одним вызовом то есть такая пен для локатор когда мы вставляем в номере часть мы просто накапливаем данный потом мы помечаем весь этот ранг как освобожденный это также позволяет нам избежать этих скачков фактически со скачками light насти мы боремся таким образом мы постараемся нигде не ждать я еще потом скажу об одной интересной проблемой слайд насти который мы получили на продакшене тоже мы с ней тоже похожим образом боремся теперь вот базовая структура допустим нас такая у нас возникает следующая проблема есть вот эти вот sort it runs на диске в какой то момент мы их перемешиваем получаем следующий уровень большинство известных мне систем они на несколько раз орт и транс поддержит только на первом уровне здесь уже идет слить слияние двух соседних уровней создания целиком 1 сорт литра то есть вот на втором-третьем уровень несколько сорта транс не может быть враг себе так то что уловил baby так сергей да они не пересекаются по значению ключа лена там на третьем четвертом уровне 1 сорт экран ну и но без joint диапазон дизайн по диапазонам но в одном диапазоне 140 стран вот наше отличие от других движков это то что на нескольких на каждом уровне том числе нижнем уровне у меня здесь иллюстрация не очень допустим этот поменьше этот побольше этот самый большой здесь тоже может быть несколько сорта транс то есть вот базовая поиск работает через слияние и это слияние может осветляться и сколько угодно большого количества источников если эти источники источники отсортированы по этому вот этот базовый трейдов которые делаются между ридом пресекаешь набирает амплификация мы можем мы можем играть на каждом уровне лоссом дерево это существенно отличием я не знаю насколько она пока что движок в бете как это как это проект production насколько мы сможем выиграть парит space amplify конечно конкурентов я пока не могу сказать но вот эту идею мы реализовали то есть в простом случае у нас значит есть in memory и каждый ловил более сложным с ты лучше на каждом лаваль и у нас есть несколько сорте транс теперь каким образом осуществляется слиянием вот здесь просто написано чисел и все удобно красиво в реальной жизни база хранит на самом деле вот чем отличается просто in memory сценарий яндекса там нам рисунок и винила в монте все мы храним данные в оперативной памяти плюс у нас есть журнал операций виниле мы храним сами операции в оперативной памяти журнале они отсортированы по времени в оперативной памяти они отсортированы лексикографических по по порядку но это по-прежнему операции список операций риплейс далит absurd кстати почему я здесь не написал про insert и апдейт обтер покрывает ensure that did какие еще есть варианты replace покрывает inserto а почему бы не хранить insert и апдейт эти операции дым патент на какие еще варианты почему у них а значит и скатерти слон вот смотрите по сути риплейс это то же самое что данные потому что в реплеях ранец и полностью строка да она заменяет строку целиком далит тоже по сути тоже самое что маркер но назначаешь нам искать дальше не надо absurd это наша собственная операции я про нее расскажу подробнее сейчас давайте про него забудем ensure that replace отличается чем ensure заселиться если есть данные апдейт заселиться если данных нет то есть insert и апдейты the reading операции они должны пользователю вернуть что-то вменяемые до сказать что данные были ли данных нет произошло constraint вела его elation по первичному ключу и на сам вот это фундаментально меняет то как вы должны думать о bright оптимист engels потому что если вы посмотрите на сиквел то в сиквеле большинство операций они предварительно читают данные перед проверяют constraints вы не сможете и воспользоваться мощью bright оптимист engine а если у вас все операции все равно сначала под капотом читают insert и апдейт это такие операции поэтому под капотом insert выполняется как селекторе place то есть дискант он его просто не видит но нужно понимать что и сорта обет никогда не смогут быть так же эффективны в райт оптимист engine и как они в овд эффективного бы дерево дерево тиранов и часа сначала блог да в кэш делается апдейт блоки и потом этот блок какой-то момент ложится на диск каждое значение в этой историю помеченный la sun и когда мы делаем чтению мы выбираем из каждого источника данные по самому свежим и лассе то есть мы объединяем значение не только по порядку по возрастанию допустим если у нас ранее запрос но и полоса плн по убыванию то есть чем более новые losses in timpul тем раньше для одного и того же ключа тем раньше он идет вывод и это базовый механизм который позволяет нам как раз вот сделать множество уровней поддержку множество уровней теперь давайте поговорим про такую историю как space амплификация собственно про ситуацию когда у нас есть один очень большой уровень внизу мы уже говорили что на самом деле вообще просто само по себе может до 2 2 до нескольких раз больше на самом деле худший случай это два не нескольких раз что основание логарифма увеличивается при увеличении соотношение между уровней уровнями но в любом случае у нас есть этот большой уровень представим себе что он что мы этот уровень начинаем пересоздавать так как из старого файлы продолжается чтения мы не можем его удалить пока мы пишем новый файл в какой-то момент нам нужно помимо вот это в два раза больше места нам еще нужно в два раза больше места ну или хотя бы в полтора к этим к этим двум для того чтобы создать новый файл то есть получается что система на самом деле требует ужасающе большого объема на диске если мы эту систему к каким-то образом не факторизуем и факторизуем мою следующим образом у нас есть представим себе что у нас есть этот lsm дерево с кучей треугольничков как только дерево становится достаточно большим ориентир это примерный объем оперативной памяти на самом деле очень сильно зависит от соотношения оперативной память диск мы его разделяем над на поддиапазона то есть находим срединный ключ и создаем два два дерева слева будет все что больше меньше по середина выключая справа все чтобы больше серединного ключа за счет этого этот этот эту структуру данных который фактически является лоссом дерево внутри до называется в нашей терминологии range вообще в новых стороны джесс очень много проблем с терминологией мы называем это ренж что позволяет этот этот подход добиться наличие нескольких раньше дарын заключив в разных раньше сне пересекается главное что мы за счет этого получаем это то что когда мы создаем самый последний уровень мы можем удалять мусор более эффективно то есть мы конкретный момент времени работаем только с одним рендж и этот рейс является представляет собой допустим одну сотую базы то есть если у нас общие места на диске там не зна 1 терабайт то мы работаем со 100 гигабайтами что уже неплохо и этот overhead который на временный файл нас распространяется исключительно это раньше но если разобраться то появляется еще одна хорошая хороший момент от такого подхода вот представим себе что у вас time series дейта да то есть вы допустим читаете из базы данных только последние значения вставляете монотонно увеличивающий увеличивающейся ряд в этой ситуации вот если взять классический lsm алгоритм получается такая история что в какой-то момент у нас переполняется уровень предыдущий нам нужно записать его на следующий но фактически эта запись просто перри создает следующий уровень впустую ловил тебе рок себе тоже решают эту проблему тоже решают а эффективно они не перезаписывают весь уровень целиком но проблема в классическом алгоритма остается то есть зависимости от сценария котором ваши данные песцы читается участвует из-за данные в принципе мир иногда делать не нужно и вот эта вот факторизация дерево на несколько деревьев позволяет как раз работать только с теми участками которые требуют мерз разные участки могут иметь разную степень какие-то могут быть более горячими на чтение какие-то могут быть более горячими на запись и это также позволяет нам по-разному с ними работать то есть получается что возникает необходимость вообще каким-то образом эти ренджи планировать то есть классом дерево вообще в принципе любая сумма деда на when driving где-то идет ставка она что-то делает если вставки нет ничего не делает но за счет того что нам нужно делать упреждающие работ у нас появляется вот эта активность связанная с которой делается бэкграунде и когда туда бы вообще говоришь на любой любой системе там структуру данных все такое появляется непонимание потому что не понимаешь как это все вот в динамике работает в нашей системе это все очень относительно просто потому что динамический компонент из независимый компонента только один это планировщик у него есть две очереди так как я вам уже рассказал что есть рейнджеры ниндзя . дерево факторизуем этой ой в этой в этих очередях сидят все так называемые ренджи отдам всегда имеет приоритет над какой-либо другой работы потому что если у нас кончилась память мы больше ничему не поделать не может поэтому если есть задача в очереди на дамп а очередь надо мб она так на земле v-триггер да то есть вот у нас начинает заканчиваться оперативной памяти все сразу мы должны сделать дамп то берется задачи с очереди на дам если нет задачи в очередь на дату мы начинаем обрабатывать и рассматривать очередь номер что есть наперед сортировку уровней и в этой у нас есть возможность каждый из rangers пересортировать независимо то есть зависеть от того например вот представьте себе что у нас есть очень плохое дерево в котором очень много сорта trance вот у нас есть какие то данные в памяти сейчас я уже рисуют так как будто у нас несколько рейндже садоводстве нас есть три rangers и вот у этого рейнджа оперативной памяти очень много сорте trance но чтение из него практически нет мы можем себе позволить себе никогда его вообще не сливать потому что если не чтение нет необходимости вот если задуматься мер это вообще работы которая направлена на снижение space амплификация и ридом пресекаются то есть на снижение объема работы необходимо выполнить в который необходимо выполнить при виде другой момент который мы получаем с режиме это то что планировщик может сказать да вот это тренч он на самом деле всего лишь поддиапазон одна десятая зубы д но он очень интенсивен на запись и планировщик отводит ему объём оперативной памяти не пропорционально его общему размеру то есть он может позволить фактически отвести сто процентов оперативной памяти в один под один range опять же если сравнивать нас с какими-то другими решениями ну я и других решений которые такого делать не знаю то есть вот мы может быть можете сказать что мы на велосипеде ли но как бы хотя бы какие-то теоретические результаты от этот от этих подходов мы видим вполне возможно видимо практически мы доведем их дом ардак в результате эксплуатации на теоретические результаты мы видим брок зебес режиме постят 4 мегабайта в как roewe подводя итоги для чтобы представить себе как это все базовый выглядеть на диске для каждой таблицы у нас есть директория допустим от директора обычно обозначается по айди таблицы числовом в каждой директория у нас есть по директория для каждого индекса первичного вторичного ключи в каждым в каждой директории допустим по номеру индекса у нас есть треть файлы и хранить файлы имеют монотонные айди который переказ запер сортировка создаёт новый файл снова моди то есть допустим идет 0 там 000 так далее 1 мы этот файл является open door ли мы создаем новый файл пересортировать создаем новую версию этого ренджа появляется двоечка при восстановлении мы соответственно сканируем директорию смотримся содержимое той директории находим последние раньше файлы с последними айди исключаем дублирующиеся диапазон и потому что дублирующиеся диапазона есть свидетельства о том что garbage collection не прошёл какой-то какая-то возникла ошибка и мы имеем более старую версию одного и того же рейнджа и объединяем все эти ранишь файловой противный память напоследок я бы хотел меня есть 22 вопросы которые бы я хотел на самом деле осветить вот зачем мы все это как бы делаем да вот опять же есть rock baby есть еще что-то преимущество которое мы можем себе позволить будущее интегрированным продуктом там сверху вниз у нас есть вектор модуль мы под этот актор модуль делаем engine у нас есть свой язык запросов это то что мы на самом деле можем находить решение которые выиграют на всех уровнях одним таким решением является absurd absurd есть во многих движках но и во многих продуктах но если вы посмотрите на семантику эта операция то в большинстве продуктов это на самом деле читающий операцию для того чтобы получить выигрыш от в райтон ли он же на нам нужно нужна какая-то операция которая была бы либо ensure там либо апдейтом но при этом ничего не читала если у нас есть такая операция у нас есть еще до лета мы можем вообще при записи не делать никаких чтений и это достаточно сложная штука по своей вот семантики потому что вот представим себе вы делаете какой-то апдейт а что если поле которую пытаетесь обновить не существует какой момент вы получите ошибку во время выполнения во время то есть поэтому собственно absurd а в такой семантики нет ни в сиквеле не там даже если посмотри там манга которая по сути создавалась как вот но и сквозь база данных то есть они могли играть семантика и могли юзер навязывать какие-то свои изобретения их absurd просто упрощает он объединяет insert и апдейт в одной операции но он все равно является в райт операции tarantul и мы сделали такую операцию для того чтобы целые сценарии работы с базой не делали чтений то есть вот если вы сегодня задаете себе вопрос а зачем это мне нужно вам нужно сначала посмотреть на absurd если у вас есть сценарий в которых вы можете наверняка знать что ваше апдейты не приведут к ошибкам эта операция для вас то есть absurd сегодня в tarantul если он приводит к ошибке он просто пропускается потому что он выполняется в бэкграунде как это все работает есть три как я уже сказал вида операций которые хранятся в брайтон жене и to replace absurd & david когда происходит absurd сам по себе absurd он содержит как значение значения которые нужно вставить если данных не существует так и ряд операций которые ну сделать если значение существует он содержит в себе две операции вместе сам по себе absurd он просто добавляется в субд м по этому ключу для которого он применяется в тот момент когда происходит мер на диске то есть влияние sort it runs несколько объектов аккумулируются вместе и мы получаем уже итоговый результат то есть мы избавляемся от этого от этой истории изменений во время слияния а во время соответственно выполнения операции никаких чтения не происходит теперь мы запустили это все в продакшен казалось бы создали идеальный вариант для обсе рта и так бывает что ну некоторые ключи обновляются рассудке а некоторые 1 секунду и соответственно вообще сценарий для работы базы был очень простой то есть вот но есть набор ключей они все обновляются спас с помощью absurd of какие-то чаще какие-то реже иногда делаются редкие чтения то есть идеальная идеальный сценарий для bright оптимисты джона и вот система не работает то есть периодически она просто очень долго работает начинаем копать оказывается что за счет того что какие то ключи более горячие происходит следующая история вот у нас есть допустим ключ один для него там накопилась там троечка пятерочка absurd а за всю историю его жизни дальше нас есть ключ 2 и здесь у нас уже большой большой большой большой шлейф absurd of когда происходит чтение по ключу 2 нам нужно выполнить вы применить историю резко накатить историю и на самом деле сделать слияние сотен тысяч изменения этого ключа что естественно приводит это фэйспалм да то есть вот база данных и на какой-то момент начинает делать применять апдейта для чтения то есть значит поэтому как бы на практике мы не только добавили эту операцию нас еще есть целый ряд ну я не буду называть это подпорками я буду называть это гениальными решениями значит который позволяет всему этого дела еще и работать то есть мы следим за тем чтобы очередь очередь absurd of по одному ключу не переполняло если это очередь переполняется мы в бэкграунде делаем слива слияние более того мы изобрели такую штуку которая позволяет нам несколько absurd of складывать вместе вообще не без чтения то есть вот представьте себе что у вас операция апдейта ты присваивания и у вас идет присваивание допустим вот вот следят присваивание то нового time stamp а при каждом обращении к полю соответственно мы все предыдущие присваивания можем на самом деле скипать вот мы видим что в истории изменений этого табло есть исключительно присваивание исключительно этого поля когда у нас приходит absurd мы запоминаем только последние изменения все остальные удаляют то же самое можно делать с множеством других простых апдейтов допустим применить прибавление единички убавления день что с арифметическим операцию такие штуки то есть какие-то операции которые можно аккумулировать без теней и то что надо будет называться ассоциативная операция да вот то есть поэтому центральная истории про вообще 1 от этого доклада помимо множества технических деталей как мы завели lsm структуры у нас является то что мы можем будущее но и сколь базы данных создавать решение которые работать на всех уровнях напоследок я хотел бы упомянуть какие-то ограничения все таки я думаю уже понятно из того что я рассказал но это bright оптимист engine если вы используете вторичные ключи и если вас insert и апдейт это вы чай скорее всего не получите преимущество отправит оптимист engine потому что допустим действие сторичный ключ у вас есть риплейс или insert не говоря уже об и сердце дано если стриптиз даже во вторичном ключе вам нужно удалить исторического ключа старые значения и для этого нужно прочитать это старое значение вывод по самому реплею не знаете то есть это стоит иметь ввиду винил поддерживает полноценный consistent reviews и и полноценной транзакции но нужно иметь ввиду что все-таки это менеджер транзакций рассчитан на такие вот на короткие транзакции то есть если у вас длинные ряды транзакции то они могут обратиться у нас нет как таковой воды блок менеджера и каких-то ожиданий внутри транзакции то есть просто коммент transaction винс тогда то есть если транзакция закончилась она побеждает и а портит все транзакции которые по которых а которая может потенциально затронуть кросс engine транзакции до сих пор нет и все таки bright оптималь структуру данных планируете ваше дисковое пространство разумным потому что они требуют достаточно большого дисковое пространство вот такой получился сумбурный и детализован эй доклад но зато я отлично отдохнул извините спасибо большое константина у нас осталось время на пару вопросов вопрос насколько я понимаю транзакционные нагруженная систему это достаточно небольшая часть и вот всех ваших систем почему не стали оптимизировать систему например под флеш то есть почему заточили семин на диске вопрос почему не оптимизировать систему на flash да через на диске мы не то что за точились прямо на диске вот lsm как алгоритм он хорошо работает слушок очень хорошо потому что он пинали финализирован оказывает чтение оценен в флэша гораздо дешевле чем запись запись приводит к износу вот то есть у нас до большой ридом при fiction я еще не упомянул несколько способов которые мы боремся с ним до но за счет того что flash относительно быстро почтением и относительно дешево то есть ну может делать сколько угодно их то все все также неплохо в свое время lsm структуры пиарили как его сам структуры для flash и вот если говорить про bright амплификация этот термин который идет из flash storage потому что там есть там есть внутренний write amplify конечно еще эласом позволяет внутреннего это конечно флэша свести к минимуму то есть я бы не сказал что эта структура оптимизирована для flash скажем для для для хдд скажем так эта структура оптимизирован для брать нагрузки на сегодня и вот если посмотреть на мой rocks the то что они делают это челенджи потому что они пытаются сделать lsm дерево как бы деревом общего назначения по сути я думаю что мы к этому придем но на сегодня мы вот наши главные там преимущество этого возможность интегрированности интеграции давать если вам просто нужен хороший движок то скорее всего там этом аракс манга рокси что такое вот такой ответ костя привет если вот тут самом углу ты сказал что вы начали с софией а потом все выкинули переписали так даже что именно переписали ином смысле в чем принципиальное отличие от той же софией например а принципиально то есть вот софия это движок это разобрать разрабатывался на три майл ру в течение трех лет если фактически наш эксперимент это мы говорим о том что мы переписали в первую очередь мы избавились от блокировок софия потому что она вся была сделана на максах мы все перлина акторы вон висит выбран оставили висеть софия нерабочий был создали с нуля вот он работал но он ни праха он собственно там тесты были такие что если есть две транзакции одна транзакция обновляет данные другая сторона кто читает эти данные и она редон лета и и портит то есть там очень как как бы был очень серьезно но это как бы там типа заявляется честный сериала и субал это что ты говоришь кажется соответствует уровню это же говорила ему знаете тот год но нет но это наверное уже отдельная песня так многие короче выкинули в сессии релиза на человеке говорю за на перевели перевели на эктор байс сделали мальте ловил комп action или делает доделываем делаем значит вы знаете команда из пяти человек работала с марта вот перечислить сегодня что поэт доклад и сумбурный но проблема сложная то есть объем работ который сделал вот у меня например один слайд посвященной репликации вот это да а и вот дизайн движка нужно на самом деле начинать с того как он будет реплицироваться то есть как и делается не шил стоит трансфер каким образом делается восстановление при при после после при рестарте и так далее то есть одной проблемы становлением посвятили очень много времени изменили структуру данных на диске прозрачно работает компрессия удалили множество неэффективных методов по компрессии оставили один который работает автоматически удалили множество ручек то есть ну вот сравнение то интересно то есть фактически интересно говорить о том как куда все это движется вот это движется в сторону сейчас очень много исследований о том как снизить рейда bright амплификация зависимости от структуры нагрузки и мы в эту сторону движемся например есть методика по удержанию горячих данных уровнем на уровень на нескольких уровнях власти на более высоких уровнях его сам дерево это дело не делает никто вот в эту сторону стоит смотреть дайте пожалуйста графон к сожалению наше время подошло к концу если у вас еще остались вопросы можете подойти и думаю лично и константину или в мид апах спасибо си большое следующий доклад"
}