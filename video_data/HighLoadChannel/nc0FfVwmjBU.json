{
  "video_id": "nc0FfVwmjBU",
  "channel": "HighLoadChannel",
  "title": "Exactly once-передача данных без материализации / Юрий Печатнов (Яндекс)",
  "views": 1165,
  "duration": 2336,
  "published": "2023-01-19T06:59:52-08:00",
  "text": "всем привет меня зовут юра я exe я занимаюсь поток рекламных данных это данные как рекламной сети яндекса так и рекламы на поиски это десятки гигабайт в секунду рекламных данных примерно 10 миллионов событий в секунду все их мы подвергаем различным операциям и облигациям по ключам для того чтобы было проще писать различные сервисы потоковой обработки дальше я буду звать их просто процессинга me мы написали фромборк пгт поддержкой и развитием которого занимаюсь я и моя команда сегодня я хочу рассказать об одной части этого framework а это наша технология для передачи данных между нашими сервисами почти без материализации для начала расскажу почему вообще я хочу рассказать про технологию передачи данных который называется swiftkey на холоде потому что эта технология используется в высоко нагруженным сервисе у нас есть сервис который состоит из двух частей первая часть читает множество различных событий по каждому событию определяет ключ по ключу определяет шар шар дерово на передает и вторую половину вторая половина вычитывает эти события и обновляет состоянии все это вместе потребляет больше 10000 ягер обрабатывает примерно 10 миллионов событий в секунду сами состояния в сжатом виде занимают терабайт данных и на дисках между первой и второй частью сервиса у нас материализуется единицы гигабайт в секунду сейчас я расскажу о том как мы эти единицы гигабайт в секунду превратили в сотни мегабайт в секунду расскажу я на примере игрушечная задача это очень сильно упрощенная версия нашего порода игрушечной задачей будет почет вард каунт в реальном времени что это такое у нас есть состояние состояние это по каждому слову количество раз которые она встретилась нам до этого соответственно на примере на слайде пусть кошка встретилась один раз табака три раза когда мы обработаем очередное событие с кошкой мы увеличим счётчик для кошки вы работаем собаку увеличим счётчик для собаки если придет новое животное черепашка то создадим новое состояние и для него увеличим счётчик теперь рассмотрим реальное решение игрушечные задачи мы будем проходить путь от реального решения в котором не будет использоваться нашей технологии к решение в котором технологии уже будет использоваться у нас большой поток данных поэтому мы хотим обрабатывать его распределена также мы хотим агрегировать события в состояние состояние у нас лежат в базе данных в который мы хотим их обновлять если у нас два сервера одновременно будут пытаться обновить одно и то же состояние в базе данных то так как мы делаем всегда клево мтс и работаем с базой данных по транзакциями то мы получим конфликт транзакции конфликт транзакции это во-первых потерянная работа раздраженное процессор на и время а потом еще и задержка в обработке данных поэтому наш сервис состоит из двух частей тут я немножко повторю то что же раньше рассказывал у нас есть входные события первый сервис вычитывать все эти входные события по каждому событию определяет какому животному но относятся какой кошки например по кошки определяет в какой шар должна попасть кошка и пишет эту кошку в соответствующей промежуточный sharp агрегатор вычитывает из промежуточной очереди сортированные данные и используя их обновляет состояние в кирилл ем вот держим в голове то что в примере агрегации это просто + 1 а на самом деле это выкачивание состоянии применения к нему абсолютно любой функции возможно расчет модели машинного обучения и сохранение обратно то есть это что-то сложная и требующая большого количества ресурсов теперь я немножко расскажу о том как работает каждый наш отдельный сервис при shorter и агрегатор расскажу на примере агрегатора на слайде слева изображена одна partition входной очереди ой и занять промежуточной очереди зеленым цветом отмечены события которые уже были обработаны агрегатором их эффект уже сохранила в кирове желтым цветом отмечены события которой мы хотим обработать сейчас источником истины для агрегатор а потом до какого офсета он обработал данные является табличка сетов дней мы видим одну строчку то что по 1 партиции офсет 42 это значит то что до 42 офсета включительно агрегатор уже все обработал и когда агрегатор хочет обработать очередные базе данных он в одной транзакции меняет значение офсета в данном случае 42 до 44 и обновляет значение в kill you то есть увеличивать счетчики для кошки и собаки при shorter в свою очередь на самом деле работает точно также просто вместо обновление состояний в севилью он пишет данные в выходную очередь а какая есть проблема в этом решении одна из нескольких но мы сосредоточимся на ней это промежуточная очередь у нас уже были все события записанные во входной очереди а тут мы записали в промежуточную и по сути продублировали эти данные продублировали нагрузку на диске давайте попробуем с этой нагрузкой на диске побороться такая первая идея которая приходит в голову давайте просто выкинем промежуточную очередь и будем передавать данные напрямую от ржд рака агрегатор у выкинули что при этом нам придется корректировать чтобы решение продолжил работать у нас теперь ришар der не пишет данные базу данных соответственно у него не может быть никаких транзакций под которыми он будет обновлять а все ты и писать в очередь он просто их придает агрегатор у а для агрегатора теперь изменяется ток как и к нему приходят входные данные теперь они приходят в каком-то хаотичном порядке а 3 шарди raw и они никак не пронумерованы последовательными номерами вот это создает некоторую проблему давайте я решим причем проблемам и так в агрегаторе теперь вместо c то числа будем хранить векторный are set это словарик в котором мы будем хранить информацию какой прогресс у промежуточные партиции агрегатора по всем входным портиком пусть посмотрим на слайд слева изображены но на события которые решал дыры отправили в первую промежуточную партицию который читает агрегатор то есть 4 шахты 7 шарф одной очереди и при этом отображены только те события которые будут ричарде раваны в 1 шард вот во все эти хранится информация о том какие события исходных очередей уже были обработаны то есть по четвертому шер туда 56 цвета включительно по седьмому до 23 включительно и на самом деле это все что требуется изменить потому что дальше агрегатор делает все то же что и раньше он просто в одной там аттракции обновляет kill you и офсет просто теперь это не одно число а уже такой словарик для ришар дыра теперь схема меняется полностью ему на самом деле не нужно ничего взять базу данных ему нужно просто отправить в данный агрегат ару подождать пока агрегатор подтвердит что он обработал и зака метил эффект этих сообщений и после этого подтвердите чтения данных в обходной очереди давайте договоримся о терминологии ключи в словарике я буду называть source видами это ключи которые определяют партиции входной очереди в нашем случае они содержат как бы имя очереди данном случае просто input кью ай кью и номер партиции в этой очереди значение слова реки я буду называть всех но sequins numbers или просто номера сообщений вот это будут значения в сетов в partition входных очередей если вы знакомы с записью вставка с продюсерами то можете заметить что эта терминология очень похожи эти термины используются в очень похожем смысле какая проблема в этом решении у нас отсутствуют отказоустойчивость как именно на отсутствует сейчас посмотрим мы конечно хотим чтобы решение было устойчиво катись частичным отказом если у нас будут просто выпадать сервера то это никакой проблемы нам не принесет поскольку наш фреймворк при выпадении сервера просто перри балансирует партиции которая обрабатывал на другие сервера и все будет дальше продолжать работать пусть теперь у нас начнет тормозить какой-нибудь по три чарджера какой-нибудь сервер шарнира если сервер решать дыры начинает тормозить он начинает медине обрабатывать данные они начинают медленнее доезжать до агрегаторов и на этом негативный эффект заканчивается когда ришар der сможет догнаться все до гонится и все будет хорошо а вот если начнет тормозить один из серверов агрегатора у нас будут уже проблемы пусть один сервер агрегатора тормозит тогда все решают дыры которые отправляют данные к этому агрегатор у начинают медленнее получать подтверждение что эти данные обработаны в них начинает копиться очередь потому что они не могут выкинуть данные пока не получат подтверждению рано или поздно очередь утыкается в свой лимит когда очередь убирается в лимит ришар der начинает медленнее вычитывать данные и соответственно во все агрегаторы данные начинают приходить медленнее то есть проблема в одном агрегаторе отражается на всей системе давайте это полечу возьмем и частично вернем промежуточную очередь между ришар диром и агрегатором пусть агрегатор тормозит тогда при шарнирах копится очередь на отправку данных в этот агрегатор они понимают по размеру очереди что 4 агрегатор тормозит и данный для него пишут в очередь на диск но мы снова сталкиваемся с проблемами которые надо решать а как теперь агрегатор у правильно поджоге не все события когда он будет догоняться рассмотрим на примере пусть у нас есть один сервер агрегатора который получает две пачки сообщений от разных режиссеров и еще одну пачку сообщений вычитывает из очереди можем ли мы эти сообщения обрабатывать просто в том порядке в котором мы их вычитаем не можем почему потому что допустим мы с начала обработаем собаку полученную от ришар дыра отлично обработали но после этого мы могли прочитать кошку которая была к нам записано через очередь когда мы прочитаем почку мы увидим то что сик но 41 меньше чем номер 43 собаки и подумаем что кошка это дубликат и на самом деле уже было обработано и просто ее выкинем то есть это потеря данных нас конечно не устраивает что же мы можем обрабатывать на самом деле мы всегда можем обрабатывать очередное сообщение из очереди почему потому что ришар der либо отправляет сообщение агрегатор у и получает подтверждение от агрегатора что это сообщение обработано либо он это сообщение пишет в очередь таким образом для сообщение из очереди все более ранние сообщения уже либо были подтверждены агрегатором что они обработаны либо они были где-то раньше в очереди поэтому очередное сообщение из очереди всегда можно обрабатывать как же нам но это хорошо из очереди всегда можем обрабатывать сообщению но это что получается агрегатор начал тормозить все данные идут через очередь и так навсегда нет нам бы хотелось перескакивать обратно на получение данных напрямую отдых шарниров для этого нам нужно научиться как-то понимать что два сообщения на самом деле идут подряд чтобы мы сообщение в из очереди могли перескочить на сообщение от шарнира как нам это понимать давайте в данные которым мы присылаем добавим новое поле привела sequence number прошлый номер сообщения как мы его получим и что это вообще такое ришар der когда обрабатывает входные данные он видит их в контексте и для всех записей с одним source и дам и которые будут отремонтированы в одну промежуточную партицию для всех сообщений кроме самого первого клона знает какое была предыдущая и если он например отправляет кошку а затем собаку-то в случае собаки он знает то что до этого была кошка и может сказать то что предыдущий номер был 41 а потом все эти сообщения видит агрегатор если агрегатор видит то что у кошки source и эти четыре и номер 41 а у собаки тот же source и и привез сик но предыдущий номер тоже 41 зачитайте сообщение идут подряд значит что не существует сообщение с номером 42 и поэтому если мы из очереди обработаем кошку то потом смело можем обрабатывать собаку полученное от и charger а давайте теперь рассмотрим это на примере чтобы стало понятнее пусть у нас есть наше текущее значение света пайки 4 segno 40 ай кью 7 и окно 23 и к нам приходит сообщение сообщение с арсеном пайки 4 segno 43 привез сик но не известен как может быть не из 200 она превысит но ну например если ришар der недавно перезапустил ся вот это сообщение приходит напрямую из ришар лера то есть не из очереди мы видим то что окно 43 по оке 4 а у нас соцсети 40 и смотря на это сообщение агрегатор не знает а были ли ещё какие-то сообщения с номерами 41 42 которые могли быть записаны в очередь поэтому прямо сейчас это сообщение он обрабатывать не может и вынужден его заблокировать до лучших времен едем дальше получаем новое сообщение source и т.п. 4 секунд 44 предыдущее окно 43 не из очереди в данном случае предыдущие сик но равно сик но предыдущего сообщения самого первого они идут подряд но первое заблокирована поэтому это тоже блокируются вынужденный в обход задержать дальше новое сообщение приходит может быть от другого ришар дыра source и таки 7 секунд 23 привез segno неизвестен сообщение не из очереди в данном случае у нас по собственной 7 сообщение с номером 23 а у нас а все эти номер 23 это значит а мы на самом деле уже обработали все сообщения с номерами меньшими или равным 23 значит это сообщение дубликат но его просто выкидываем дальше новое сообщение source это такие 7 секунд двадцать четыре предыдущая сяк но 23 не из очереди на этот раз а предыдущие сик но равно тому сид но что у нас в сети значит это сообщение очередное который мы можем обрабатывать поэтому source виду просто берем и обрабатываем пускаем в обработку и при этом увеличиваем значение 7 все эти от 3 до 24 дальше получаем сообщение из очереди с а все-таки 4 секунд 43 тут уже неважно какой был предыдущий сик но это очередное сообщение из очереди его всегда можно обрабатывать пускаем в обработку что сразу стоит заметить source и таки 4 сек но 43 это сообщение по тому же source виду по которым у нас были заблокированы и сообщения из очереди и при этом окно 43 теперь до 43 включительно мы все обработали поэтому одно из сообщений которая была заблокирована сразу становится дубликатом мы его просто выкидываем а вот следующая теперь разблокируется поскольку его предыдущий segno 43 равен segno сообщения которые мы только что из очереди пустили в обработку отечна и приходят последнее сообщение для этого примера source и tracker 4 сек но 45 предыдущая сяк но 44 предыдущие сик но равно сек но во все эти значит это очередное сообщение спокойно пускаем в обработку что еще замечу по этому примеру если сообщение из очереди нам совершенно неважно какой был предыдущий сик но этого сообщению потому что из-за череды мы всегда можем пускать в обработку и нам не нужно знать что она за кем-то следует казалось бы все хорошо теперь данные отправляются напрямую если агрегатор тормозит могут писаться на диск и при этом агрегатор может догоняться и снова начинать начинать получать сообщение уокер шарниров но при этом что будет худшем случае когда агрегатор весь остановится ни один сервера прям весь в этом случае весь поток данных начнет писаться на диск а эта проблема почему на то что был у нас поток записи на диск мы резервировали какое-то количество дисков чтобы у нас иметь резерв пропускной способности под такой объем а если сейчас у нас при остановке агрегаторов будет даже чуть больший поток данных на диске там и худшем случае не выигрываем и это плохо потому что мы хотим сэкономить железные диски чтобы они не работали точнее чтобы просто не платить за них давайте эта проблема решим возьмем и научимся ограничивать максимальной материализуем а поток сделаем это довольно просто давайте скажем что если у нас тормозит больше к процентов серверов агрегатора то наверное весь агрегатор чувствует себя плохо и можно приостановить работу ришар дира как это будет работать если ришар видит то что тормозит меньше к процентов агрегаторов то он работает как мы как я рассказал раньше просто пишет данные очередь и все если же у нас тормозит больше к процентов агрегаторов то решать dark перестает отправлять данные агрегатором но если он просто перестанет отправлять данные то может получиться неприятная ситуация допустим ришар дыры видят то что агрегаторы тормозят и перестали отправлять данные агрегаторы взяли и перезапустили агрегаторы перри запустились получили какие-то сообщения от их шарниров и подозревают что возможно до этих данных еще что то есть то есть они видят пришедшие к ним сик но и не уверен это что они могут их прямо сейчас обрабатывать блокирует их это плохая ситуация поскольку просто станет вся обработка как это полечить можно взять и писать мета информацию в очередь давайте вернемся к примеру который мы рассматривали в тот момент когда к нам пришло сообщение вычтены из очереди stores ведомой q4 isic но 43 на самом деле нам не нужно чтобы в этом сообщении были данные почему потому что если это сообщение к нам пришел в очереди то мы знаем то что все сообщения с сик но меньшими 43 меньшей мере равными 40 нет просто строго меньшими 43 уже либо были в очереди либо обработано а значит то что мы можем просто взять и разблокировать самое первое сообщение с окно 43 получено 3 шарнира то есть получается что для разблокировки нам необязательно чтобы в очередь была написана сообщение суданами хватит только мета-данных вот и по в случае режима деградации ричард и перестают писать сами данные в очередь но продолжают писать эту информацию что это заметно информация достаточно просто по каждому source еду в выходном буфере ришар дыра написать минимальные доступны сик но в этом буфере этого хватит для того чтобы агрегаторы разблокировали сообщения и при этом это достаточно маленький поток информации еще мы оптимизируем рестарта агрегаторов что это такое пусть у нас при стартует 1 агрегатор после рестарта он быстро получит сообщение от шарниров и он множество из них может заблокировать он их заблокирует ришар дыры будут видеть то что агрегатор не подтверждает обработку сообщений начнет расти очередь агрегата shorter запишет сообщение в очередь в агрегаторе сообщения разблокируется все хорошо но эта задержка потому что ришар дыры не сразу начнут писать сообщения в очередь не хотелось бы чтобы при каждом рестарте был какой-то долгий процесс поэтому оптимизация если агрегаторы стартует он сообщает при шарниром что он рестарта ну и ришар дыры сразу отправляют ему эту информацию такую же как при деградации в очередь это позволяет агрегатор у сразу разблокировать за блокирование сообщения и быстро начать нормально работать что же мы в итоге получили прежде всего что мы получили для нас для нашего самого крупного процессинговой сервиса мы сэкономили запись на диски между частями сервиса мы уменьшили ее 100 единиц гигабайт секунды до сотен мегабайт в секунду а также мы уменьшили latency бонусом поскольку раньше мы все выходные события писали под транзакциям раз какое-то время то теперь мы можем отправлять данные агрегатор у как только мы обработали очередной матч но от по сути теперь мы упираемся в то какого размера батч и фиг можно эффективно обрабатывать какие есть и общие плюс и теперь мы можем эти плюсы для коэффициента деградация 10 процентов теперь мы еще на диска в 10 раз меньше у нас довольно маленькая в пенси между шахтером и агрегатором также мы переживаем отказ и тормоза входных партиций мы переживаем отказ и тормоза до десяти процентов промежуточных партиций и неожиданные плюс то что остановка агрегатора останавливает и ричарде почему это плюс потому что раньше если агрегатор вставал то у нас сначала начинало расти промежуточная очередь она могла забить диски это неудобно когда это кпп одна проблема а тут еще а диски могут забиться вот так were шарниры включается режим деградации и он начинает очень мало писать на диске только эту информацию и из-за этого у нас пропала проблема с и за расходованием места на дисках при остановках агрегатора какие есть минус и минусы такие допустим что у нас агрегатор начинает чуть-чуть подтормаживать тогда он подтормаживает charger видит что тот подтормаживает включает деградацию агрегатор быстро до гоняется при шарнир подключает деградацию агрегатор снова начинает подтормаживать и так по кругу и получается что у нас начинается прерывисты обработка данных как гриша родили так и в агрегаторе это аномалии просто на всех графика и это существенно усложняет дэбак проблем вот не делает его невозможным но сильно усложняет вот так же у нас добавляются ограничение на логику обработки данных в ришар берри раньше мы могли прочитать и входной базе данных из описательного выход любой другой базе данных а теперь ко всем выходим сообщением мы должны писать сик но и sourced вот поэтому мы например не можем на уровне ришар дыра с агрегировать несколько строчек в одну если у них одинаковый ключ мы вынуждены каждую строчку как есть перекидывать агрегатор вот почему не можем сформировать потому что итоговой строчки нужно будет выбрать окно можно выбрать первый или последний в этом случае будут либо потери данных либо дубликаты при стартах это не то что мы хотели бы получить еще минус то что мы не можем построить схему когда один ришар der пишет данные в два независимых агрегатора то есть схему с двумя агрегаторами построить можно но они будут зависимыми если один остановится ришар der начал деградировать второй тоже остановится поскольку данных не будет и последний минус который ограничивает возможности к масштабированию этого решения это значительно поток мета информации через диски поскольку во всякие агрегатора у нас объем данных пропорционален произведению количество входных партиций на количество промежуточных партиций с учетом того что этот акцент постоянно обновляется это значительный поток данных его можно уменьшать различными приемами но в текущем виде это решение не сможет работать were сотнях тысяч входных и промежуточных партиций что еще можно решать с помощью этой технологии не только же нам в art cologne читать можно тронете два потока событий в реал тайме по сути join двух потоков событий это тоже агрегация по ключу просто в тот момент когда два события у нас встретились с одним ключом мы можем выпустить наружу новое событие записать его выходной в очередь также мы можем считать произвольные агрегаты над потоками входных данных в реальном времени это вот этот вард каунт просто с сильно более сложными облигациями мы можем не просто хранить счетчики а какое-то произвольное бает твое состояние если хотим пересчитывать какие-то модельки машинного обучения и еще что-либо подобное также можно играться с родированием например пусть есть поток данных сортированы по ключу а тогда мы можем пересортировать его по ключу б с помощью а swiftkey применить какую-нибудь операцию которое лучше работает при локальности по ключу б а потом перешел ли рвать обратно по ключу а в данном случае мы больше заплатим заметно информацию это будет уже не квадратик с произведением входных на выходные а кубик поскольку будет больше перри шарди ранее на этом основная часть от оклада все давайте обсудим уважаемые коллеги юра спасибо тебе большое за доклад и задавайте свои вопросы пока готовьтесь пока руки поднимаются я задам те а хотя нет давайте сразу от вопросов молодой человек поднял руку дайте микрофончик и если есть еще руки тоже поднимите чтоб я сразу отправил хлам девушку юрий спасибо за доклад у меня вопрос касательно exactly vans мне показалось изначально по анонсу что будет решаться проблема чтение за очереди что мы иногда леваду примеру дублируем либо теряем данные вот как-то мы хотим это решить в описанной схеме у нас есть промежуточную очередь и из доклада я понял почему можем доверять тому что в нее записано но у нас же все равно остается проблема с тем когда мы из нее читаем и мы опять видим между стульями либо мы теряем даны ли вы дублируем разве не так а сейчас а можно микрофон настрой чтобы было лучше слышно задающих вопросы я могу попытаться повторить поближе так лучше смотри мы решали проблему с тем что когда мы читаем из очереди мы либо дублируем либо теряем данные изначально вот теперь мы пришли к системе где есть промежуточная очередь и из доклада я понял почему мы можем доверять тому что в нее записывается но кажется мы все равно остались проблемы с тем что когда мы из нее читаем мы можем либо продублировать либо потерять данные кажется поняла вопрос смотри промежуточная очередь нам нужно всегда для того чтобы в агрегаторе было локальность по ключу для того чтобы он мог эффективно работать с базой данных вот этого очередь есть всегда каждый и за процессом да по отдельности она делает одно и то же он вычитывает событий из одной очереди а дальше делает какое-то изменение над базой данных в одной транзакции с изменением офсета в по входной очереди все понял мне просто казалось что мы где-то посередине отказались с использованием базы данных для синхронизации осмотри мы где-то посередине отказались от использования базы данных на уровне решают ира на уровне агрегатор это все осталось а на уровне ришар дыра происходит следующее он отправлять данные просто аббревиатуру и ждет пока тот подтвердит их получения то есть агрегатор сам все за комитет база данных потом подтвердить наш обзор что все обработал это первый вариант когда решат р понимает то что события надежную обработано и все хорошо второй вариант то что он это событие пишет в очередь уже под транзакции вот в данном случае ричард на выход выпускает все это лист vans вот но за счет того что рубрикаторе есть вектор на сет он может это есть транс превратить вот за клеманс расскажи пожалуйста я прошу прощение давайте вернем микрофончик вот в тот момент когда ты рассказал ситуацию когда у тебя затыкается некоторое количество агрегаторов и еще ли понимать что нужно деградировать вот какой там буфер ну какой там зазор сколько данных может быть задержано условно говоря когда понимается ришар der что нужно деградировать вообще ришар der у нас держит выходной буфер порядка отца 10 секунд до 2 минут в разных сервисов при разных настройках и обычно деградация включается с целью этот буфер заполнен хотя бы наполовину в больше чем к процентов выходных партиций спасибо так есть вот вопрос а тут молодой человек будьте добры микрофон на пожалуйста встаньте только и поближе к артур чтобы было хорошо слышно а seba seba и потом вот микрофончик туда спасибо постараюсь разобраться не раз спасибо за доклад такой вопрос как обеспечивается монотонность окна то первый вопрос давай там сразу 2 каким образом вы верифицировали эту модель сейчас я сожалел слышал только первый вопрос но на него отвечу всех но мы берем как овцы от исходного сообщения то есть ришар der читает сообщение исходных очередей в каждом сообщении есть are set и этот офсет используется коксик но при отправке уже в промежуточную очередь окей случае рестарта воропай мамечи рестарта в какой момент происходит и фсин грубо говоря можно идти по правде да это очень мило а в какой момент происходит в sing то есть тебе нужно синхронизировать и обработать ситуацию рестарта то есть я вам поясню вопрос у тебя в может возникнуть состояние когда на агрегаторе перешел к муза пересек муса счетчик она ришар дери еще нет у чая возникнет либо нахлёст вперед либо ну собственно дырка смотри ришар der когда посылает сообщение агрегатор у он каждое сообщение анонсирует сик но он посылает если он ри стартует то он откатывается чуть-чуть назад и может перри послать те же самые сообщения еще раз с теми же сик но но агрегатора есть его в сет и он по каждому source виду знает to seek но до которого он все обработал поэтому он по каждому сообщение понимает либо это дубликат либо это то что нужно обрабатывать второй вопрос как это было верифицирован а как это когда бы инфицирована как было верифицированным а и фикации сейчас не совсем понял вопрос как мы принимали что это технология работает или да а ну так этот шарик окажется в дискуссии поэтому давайте вернем микрофон и вот молодому человеку во первых теоретическим как продумывание им во вторых у нас я собирал специальный стенд который в 20 небольших virtual отсчет писал как бы из одного игрушечного сервера в другой при этом там очень активно работала хаусман кей и код агрегатора был написан так что он проверял что получает ровно те данные без потерь и без дубликатов то есть это был такой огромный тестовый стенд через который мы до сих пор принимаем все изменения вот поскольку как в теоретические обоснования в очень упрощенном виде сейчас рассказал но кода много сложный поэтому специальный стенд большой который именно для проверки этой технологии мы создали хорошо и давайте вот последний вопросик и добрый день спасибо за the club юра хотелось уточнить было ли если было решалась ли как-то задача порядка данных вот в этой промежуточной очереди из решать drove потому что и так понял решаете лишь ордер в параллели писали данные для агрегаторов туда и писали в одну очередь так про порядок данных у нас изначально если много входных партиций в каждой партиции может быть всего словно кошка поэтому изначально у нас если приходят события по кошки и если они из разных исходных партиций то порядок не определен вот это сохранилось но если событие из одной исходной партиции то в том же порядке в котором они были в исходной партиции так они и придут в промежуточную дара с области а то через одно из исходной понятно когда их несколько как доверять тому что в очереди когда у нас несколько источников данных а порядок ну тут нужно соблюсти чтобы агрегатор правильно все понял а сейчас если изначально в исходных партийцев события были сейчас если два события изначально были в разных исходных партиях то тут мы ничего не можем сделать и не пытаемся сделать там и гарантии нет порядка повторите пожалуйста нету гарантий впо по порядка сообщений провяжу что елочки по данному да то есть это нету как схеме с очереди на диске так и счастив таки выгорания я повел пачку ножом спасибо давайте поблагодарим юрием спасибо большое за так"
}