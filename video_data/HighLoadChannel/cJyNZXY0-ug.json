{
  "video_id": "cJyNZXY0-ug",
  "channel": "HighLoadChannel",
  "title": "Оптимизация инференса нейронок на CPU / Анастасия Торунова (Тинькофф)",
  "views": 812,
  "duration": 2472,
  "published": "2023-01-19T07:01:38-08:00",
  "text": "всем привет меня зовут настя я работаю в отделе распознавания и синтеза речи стейков и сегодня я хотела бы рассказать про то как мы запускали синтез речи для офисе on the back of production с какими проблемами вы столкнулись и как их решили и так перенесемся в сентябре 2018 года мы тогда только начали работать на sin сам речи у нас не было в этом экспертизы у нас было экспертизы только в распознавании речи и звуки но мы понимали что синтеза речи должно выглядеть примерно так мы берем какой то текст конференциях и мы должны на выходе из черного ящика положить в форму мы почитали статьи и поняли что современный этой план титул минут примерно вот так то есть мы берем наш исходный текст и подаем его на вход некоторым нлп батлой на этот клей может быть разной степени сложности он может расставлять ударение расставлять паузы рисовать акцентные слова записывать прописью даты адреса числа все зависит от того насколько выразительного вы хотите сделать аудио на выходе и изначально у нас этот новый план был не очень сложный но сейчас занимает значительная часть плана синтеза речи и наверное про него последовало рассказать больше но мой рассказ будет скорее про финальную часть и синтеза речи поэтому и так после того как текст придав работа нам п п п м м он попадает в акустическую модель акустическая модель это нейронная сеть которая из вот этого внутреннего представления делается пиктограмма что такое спектрограмма вот если взять аудио побить его на маленькие фрагменты по 20 миллисекунд и для каждого фрагмента посчитают призвание фри и запустить записать эти коэффициенты столбик подряд то получится вот такая матрица и вот эта матрица я часто рисую как картинку вот эта матрица и есть предлагал вот и на финальной стадии pipeline синтеза нам нужна вот эта спектрограмму преобразовать обратно в сам клаудио что такое сэмпла где вот представьте себе график зависимости времени от амплитуды сигнала и в этом это всегда мы взяли и дискредитировать дискредитировали с какой-то частотой обычно для телефонного канала это 8 килогерц а для более хорошего качество аудио например если вы нас от транса записываете это 16 герц и или больше вот потом понимаешь 100 pipeline должен выглядеть вот таким образом и нашим в плане в качестве акустической модельный выступает не разведки который называется это которого 2 в качестве его кадир и другая стоит азарт не равна сеть которая называется менты и придумал google и у нее очень хорошие качества звучания речи на выходе мы довольно быстро поняли что бутылка всем этом плане визит именно вмф потому что во всех статьях и портили что он очень медленно работает и что его невозможно в реал тайме и сейчас мы подробнее разберем почему это так для этого мы должны посмотреть на картинку на то как выглядит архитектуры от сети вот тут на картинке нарисована один слой вот этот слой принимает на вход делает несколько сверток и активации и передается ли вы это дальше либо в две последние свертки теперь посмотрим на вторую картинку вот на этой картинке изображена как вот эти слои зависят друг от друга то что было на предыдущем слайде это на самом деле только один маленький кружочек вот на этой картинке и видно что эти кружочки они зависят от выхода в друг друга и эта зависимость она растянуто во времени чтобы понять как происходит с аудио мы берем входной и sample например 0 или какой-то мы просто или какой-то удобный сэмплом делаем его дела ну из нее выход ректор подаем его на вход первом слое и так далее прогоняем слои до последнего в последнем на последнее у нас state of tanks то есть в конце у нас получается распределение по всем возможным следующем сэмплом вот мы берем с м прим из этого распределение получаем следующий год и дальше подаем его на на вход настоящим там стоит и вот так самку за сэмплом мы генерируем наш audio но нужно помнить что для того чтобы качество аудио был хорошая нам нужно 16 тысяч сэмплов секунду потому что 16 16 герц минимальные часа для хорошего качество аудио и нам нужно 16 тысяч раз секунду так сетку прогонять чтобы получать сэмплы и так же тут есть эти авто регрессионной зависимости которые также условно этого дела какие какие были на тот момент альтернативы этому подходу была другая статья от google это пару любовные отведение избавились от этого авто регрессионной генерации и все сэмплы или генерировали параллельно и вторая статья в иглу где также не было рекуррентной зависимостей но эти сети они довольно были железу и требовали многое в декард у нас на тот момент особо большого запаса видеокарт на просьбы не было и где-то за четыре месяца до запуска планируемого омега мы получили товар хорошее качество оригинального veneta но у нас не было времени на то чтобы проводить много экспериментов с другими архитектурами и как мы уже поняли нам нужно было real-time генерации аудио потому что да вы сдаетесь цент вопрос вы ждете что он почти сразу начнет отвечать они там через несколько секунд и для этого уменьшение light миссии нам нужно было начинать давай сэмплы как только мои резюмировала вот и соответственно скорость генерации тогда работа я должна быть отмене и машина с тобой в секунду и мы подумали и приняли решение что мы продолжим работать в этом и будем делать оптимизации под поскольку у нас не было ресурсов и пью вот и в этом докладе я расскажу про то какие мы оптимизации сделали и такие результаты получились итак первая оптимизация которую я упомяну это опция которая была описана в статье но на самом деле он довольно очевидная просто все лента ты с промежут промежуточные предыдущих the instant af нужно просто сохранять вот в таких конечно вуферов эти длинные буферов они зависят просто от параметров сверток следующего слоя то есть они констант нам известно заранее их как просто можно сохранять все эти различные вычисления мы как бы сразу использовали такую оптимизацию но на самом деле эта оптимизация недостаточно у этой статьи было референсный разорвал и она достигала только 100 самку в секунду что как бы не очень хорошо с помощью этого нельзя ничего генри ватте л д м а вот и второе что мы сделали мы не отказались от произошло потому что мы подумали что в первых в в нейронных сетях обычно почти все что нужно делать это делал осмотрительно и умножения для почти всех операции вот и все эти матричное умножение они были довольно маленького размера то есть это размеры были типичных матрицы то вся четыре на четыре есть су-2 с 88 то есть это не рана щетка она была не очень компьютер пенсию но в тандыр флагу существует довольно большие варкале на западе закраса и мы беспокоились что это помешает нам достичь нужной производительности вот второе что нам не нравилось назархан это то что он использует един для всех маточных умножений ильин очень хорошо оптимизирован для больших матриц и там очень хорошо через параллельно но поскольку нам нужно было в нажать маленький матрицы этого мне подходила вот и мы в итоге написали свою версию со своими монголами которые оптимизировали так чтобы они не из использовать тот факт что матрица маленький и для того чтоб понять что не так в обычном от 0 и давайте приведем небольшой эксперимент вот возьмем мой ноутбук вот на нем процессором intel core n какой-то вот если посмотреть его техническую спецификацию найти должна быть пиковая производительность одного ядра то и посчитает сколько операции в одном моем на матричном умножение то теоретически и получается что одном это приложение стало с 88 и должно работает за 60 микросекунд но если мы в реальность напишем код и запустим и по мере то получается 5 миллисекунд это получается если geofox перевести то получается где-то 08 the fox и это один процент того что теоретически возможно давайте поймем почему же наивным такой эффективный посмотрим на то как работает мы берем в каждую строчку и и вектор во второй матрице и начинаем их скалярное перемножать и таким образом мы получаем один элемент в этой матрице которые мы хотим получить у этого такого подхода есть 2 проблемы первое это то что плохо соблюдается локальность данных для второй матрицы то есть у нас загрузки в кэш идут там просто построить это поистине все матрица jet построчно управимся то загрузки конечно же будете построчно на самом деле нам бы выгоднее если бы они шли по столбца вот вторая проблема это то что у нас очень много будет загрузок из памяти и далее выше в регистры чтобы делать начисление и на одну загрузку у нас очень мало вычисления производятся то есть очень низкая арифметическая интенсивность вот такого подхода вот как это можно улучшить улучшали это с помощью используя векторные операции у нас есть в процессоре векторные операции который из наборов инструкция vx2 или а вы 512 на хорошие всех северных портах вот и они дают делать умножение между сразу векторами чисел вот что позволяет ускорять и дании мы посмотрим как это можно применить матер умножения вот первый подход вот мы берем во второй матрице мы будем выделять вот такой блок серой и по нему ходить вот такие меня желтыми строчками и загружать все элементы в строке будем представим что у нас размер широкого регистра это три вот и у нас в этом широком регистры как раз три элемента мы их загружаем и вот вливаем в левой матрицы мы делаем так называем процесс когда мы просто в этот широкий регистра записываем одно и то же число много раз вот и вот мы делаем вот такие перемены приложение между забрать качественным желтым квадратиками и живут и строчкой и получаем желтую подматрицы вы жадный в матрице которые мы хотим получить вот и таким образом у нас улучшается немножко арифметическая и добилась потому что мы на как бы перед занимаем немного моим идеалом рассказ и на него сразу делаем очень много вычислений вот и второе улучшение этого это мы можем хранить матрицу вот такими вот блоками серыми и вот вот так же как вот по желтым строчкам то есть вот как передвигаются жёлтые треугольники также матриц играть памяти вот и у нас в левой матрицы мы им делаем простые по-прежнему ах правой матрицы мы прошли мимо делаем загрузки все строки широкий регистр вот и таким образом мы суммируем вот эти серые блоки в желтые под блок резонируешь матрицы вот как это выглядит в коде вот у нас мы проходимся по всему энергии меньше энергии меньшим это среднем денежных по которому идут желтые желтые прямоугольнички вот и мы делаем вот здесь мы делаем матрицы b мы делаем загрузку регистр широкий мы тут используем clank некоторых станциях чтобы не писать и критики и вот здесь мы делаем естественно отказ ну это просто такой виктор цой такой синтаксический сахар чтобы можно было проще писать используя векторные инструкции вот и если посмотреть на то как это оптимизируется ассемблером то мы видим что у нас если у нас количество регистров которые простятся значение из матрица которое левая это рекс а регистров которые мы загружаем элементы из матрицы b это ребята у нас тут если посчитать тут экзо просто xb загрузок и рюкзак narex бы вычисление будет то есть вот этих и фарма самой инструкции которые фьюз эти планы от делают и таким образом у нас арифметическая интенсивность получается 1 одно число здесь на второе и если правильно подобрать вот эти рюкзак xb то там получится таким образом чтобы мы утилизировали по максимуму регистров первых у нас для вызова это 16 регистров для выпаса 12 32 регистра вот это не генерировала нашего ночи поэтому тут для vx2 вот и если там подобрать правильно там помню 434 это ригза я эрик смотри вот то получается самая оптимальная арифметическая интенсивность вот и такой способ оптимизации на twitch наложения называется регистр локинг по скрутим мы занимаем все доступные нам возможности регистры вот и пытаемся как можно больше вычислений и произвести с ним и значениями в которые мы разгрузили вот и это матричное умножение написанная таким образом она ну то есть тут понятно что написано блок для на одного блока матричное умножение вот и мы просто блоками такими ходим по пси-матрицы так вот на анимации было и таком одеянии достигает 8 10 процентов утилизации одного ядра вот и кажется что если бы мы написали просто все операции в нфс используя такого монтаж умножения то всё было бы хорошо то есть мы бы решили бы своему тону кажется что у каждого бы мы решили свою задачу но на самом деле мы как бы ускорились но все равно недостаточно нас получилось где-то 80 8000 сэмплов в секунду и мы начали это preferred профилировать и поняли что у нас большие затраты на то что мы матрицу привод которая была анонимов серия 2 мы все время перепакованная вот почему потому что эта матрица это на самом деле все время матрица вход и выход одновременно то есть мы берем вход мы его запаковываем так чтобы все элементы лежали так как по ним будет проходиться матричное умножение чтобы было локальность вот и потом когда мы получаем на выходе матрицу она уже не запакована она мне нужно в следующую свёртку запихивать вот и мы ее берем а пакуем и вот на это уходили большие затраты что мы сделали мы просто вот в этой если посмотреть на этом этапе уже не просто поменяли местами то увидим идеалом загрузку в регистр это мы где мы делаем подкасты поскольку мы делаем бродкасты последовательно то мы можем проходиться по матрица б тогда столбца то есть достаточно хранить матрицу попасться и выходную матрицы туры по столбцам и не нужно будет ничего перепаковать мы просто поменяли операции которые мы делаем прямо тушим уже не поменял их местами вот этот год был инструмент такое же только операции с другом отрезке менялись вот и достигли желаемого результата досталось быстрее но все равно недостаточно 12 в секунду и мы поняли что нужно копать куда-то другой другой немножко области вот что мы стали оптимизируем дальше это то сколько занимают наши леса мы заметили что 1-ый форвард от одного цента до другого нас должен занимает где-то 60 микросекунд это время одну секунду если поделить на 16000 вот и если поделить это на количество слоев то для 16 слой набивная получалось не то около четырех микросекунд однослойного грозные ты где-то полторы микросекунды вот но заметим если вспомнить иерархию доступов времени доступа к разным уровням памяти это загрузка и срам это довольно дорогая и медленной операции и она занимает одну микросекунду порядка такого вот и получается что если нам так не повезет и у нас что-то из кэша попадет случайно выпадет из кэша и попадет в равно придется сделать эту загрузку и мы можем не уложиться в эти 60 мексика вот и какое решение по возможности мы хотим все хранить в каше чтобы все получалось кэш но поскольку мы все делаем для одного ядра потому что не очень не очень компьютер танцев у нас выгнать и там просто особо нечего проверить на несколько in der то мы полагаемся только на одно ядро соответственно мы используя возможности реального кэш вот вторая проблема с которой нужно настроиться это нельзя просто уменьшать бесконечное количество слоев потому что мы должны сохранять качество звука который генерируется и минимальное приемлемое качество давала 16 слоеный вернет вот и но он все равно не могла не помещались в кэш у нас в на процессорах которые мы планировали использовать вроде вот и что мы сделали мы решили и хранить все веса и промежуточных вычислений в 16 или и но для окисления и конвертировать их в 32 вот и что у нас получилось у нас получилось что если просто хранить в по 16 то у меня сразу ускоряется потому что у нас сразу все весами и все про нужную целью здесь два раза меньше и у нас по сути мы сделали как бы производительность памяти как будто бы раз больше вот хранение в 8 у нас не так зашло как в по 16 потому что для того чтобы fat32 превратить в and 8 нам нужно совершить некоторые линейные сжимающие образование вот и и и обратно чтобы преобразовать в fat32 тоже нужно вот для это 16 мы можем просто там половина обрезается фото задевает спешность и обратно в основными тоже очень простое и мы думаем что из-за этого int 8 особый она не зашёл вот и какие у нас получились результаты действительно мы получили достаточно ускорение у нас получилось на наших процессоров 30000 секунду флот 16 и с инструкциями 512 маточных вложений мы на этом не остановились мы хотели попробовать колонизацию потому что мы думали что если мы сделаем вычисления в and 8 это мы все-таки получим прирост эту 18 вот что такое квантизация координации это когда вы берете число какой-то флотом или какие-то кислые из какого-то промежутка конечного и вы эти числа кодируете какую-то функцию высчитываете чтобы линейную чтобы эти леса эти значения перевести в значении нет 8 вот и соответственно вы делаете такую обратную функцию чтобы потом обратно результат получить вот и так как же нужно как же можно это применить вот первое что нужно сделать это нужно культивировать в себе со но у весов это небольшая проблема потому что они константные им или просто один раз притом загрузки и мы не считаем все промежутки допустим для матрицы наши стоим промежутке всех значений вот и определяем какую нам нужно ли или функцию применять чтобы кровать эту матрицу вот для всех промежуточных маленьких моторчик векторов мы не знаем как бы эти значения сразу вот есть для этого нам нужно прогнать какие-то аудио вот через этот вид и посмотреть какие у нее какие есть промежутке значений для конкретных выходов и их использовать вот мы так сделали мы приняли несколько раулем взяли вроде набора значений посчитали средние посчитали среднеквадратичное отклонение вот и в качестве промежутков мы взяли средние плюс-минус 5 7 среднеквадратическое отклонение 3 семена мы пробыли тоже мало там работала фигура какой плюс в том что нужно все промежуточные значения можно все промежуточные значения которые нас получается тоже хранить от 8 что дает boost тоже к утилизации памяти вот где мы применили колонизацию вот в красными точками показаны на картинке где мы делали колонизацию выходов делаешь либо координацию входов и выходов от медианой коннотацию выходов вот после гейта для не аргумента после последней свертки и после финальных фото активации реалу вот что у нас получилось во первых на самом деле мы обнаружили что если вот после последнего царя сделать делать координацию и то на самом деле получает шум вот наш ум не простая шум с такими паузами где должны быть паузы в тексте который произносится мой если их убрать экранизации просто вот так читать то получается хорошее качество но при этом в принципе метильная падает не сильно падает скорость вот в остальных местах мы оставили и и что у нас получилось если качество получилось довольно хорошие там аудио получаются с небольшими артефактами но их хорошо слышно наверное только в наушниках вот и второе что у нас немножко огорчило это то что все таки эти колонизации не дали нам того просто которые мы бы хотели вот и нам пришлось все таки остановиться на версией которую я говорила до этого три секунды мы думали над тем чтобы исследовать почему это происходит вот мы думали что в процессоре там не было таких инструкций эффективных которые бы пир нажали имхо синус раскладывали его fat32 они появились позже в нашем процессоре их не было мата и мы думали поэкспериментируй с ними но не довелось вот и сейчас я хочу показать сэмплы которые получаются нашим чем-то сам вот сажала я покажу сэмпл диктора чтобы знать как и звучит монастырях человек и как синтез на его снова это было очень давно что никто не знает как это выражалось в реальности а лишь догадываются если еще утром казалось что цель достижима то теперь когда вели ангер был травмирован четверо друзей стояли перед нелегким выбором продолжать подъем или спускаться вниз так и теперь я вам покажу сэмплы синтеза вот сначала ваш лот то есть он считается флотах медленно когда удаляя то можно было подождать карл у клары украл корралы а клара у карла украла кларнет теперь 16 карл у клары украл корралы а клара у карла украла кларнет лишь спасен карл клары украл корралы а клара у карла украла кларнет в этом вывод аудио возможно незаметно нутрь следующем точно заметные артефакты от 8 вот так это флот улица фонарь аптека бессмысленный и тусклый свет живи еще хоть четверть века все будет так исхода нет fat16 улица фонарь аптека бессмысленный и тусклый свет живи еще хоть четверть века все будет так исхода нет into a sin улица фонарь аптека бессмысленный и тусклый свет живи еще хоть четверть века все будет так исхода нет ну туда слышны хрипы такие 8 и того что мы получили мы получили 30 тысяч секунду используя в 16 и 12 векторные инструкции возникает вопрос стоит ли вообще этим заниматься 1 ответ нет потому что скорее всего и сейчас есть более превысили модели мы например недавно заменили свой вернет на более производительный хай фай га или второе у нас не было времени на исследования а если у вас есть время на исследования то лучше конечно его на них потратить и в конце я хотела бы сказать что примененные на мере оптимизации в целом полезно и и для других моделей встроенного например в такие модели которые встраиваются в на мобильные устройства первое что можно делать это хранить в 16 все и второе экспериментировать и квантизации то есть можно делать по стране квантизация как мы пробовали еще можно делать концепции во время тренировки на счет оптимизации и с низкими матричным на же ниями наверное этим стоит заниматься только если помочь очень интересная и ли у вас вообще нет выбора всем спасибо за внимание теперь я могу ответить на наш вопрос так спасибо анастасия сейчас настя подключиться к нам по зуму масть привет ты нас слышишь что-нибудь скажешь да все отлично так тебе аплодисменты за отличный доклад так здорово если есть тот вопрос поднимается руки если нет то я могу стать поспрашивать так все есть вопрос первый ряд мнение в микрофон к фонду задавай дорасти вы сравнивали скорость мкл умножением матриц им cal днк я не знаю просто там все эти примитивы есть для маленьких и для больших матриц так как такой комментарий но на мой вкус я послушал как будто бы в принципе and 8 тоже не отличим от человека вот некоторые люди говорят хуже чем то что у нас получилось это мой такой вкус обывателя так ладно щеки эти вопросы а у меня такой вопрос если бы было время на исследование то куда бы вот выдвигались если бы не переползли нa другую модель выполнена другую модель потратив временные мы пробовали помогает исследовать не получалось пока она получилась по ведь пока чем-то завод и поэтому мы заменили akane то есть он покосился самый такой оптимальный для вас по скорости и по качеству а есть вообще вот от продукта требования по улучшению качества или вот то что сейчас получилось оно достаточно и всех устраивает как меня вот например так просят сделать лучше звук честно говоря не просят вот вот мы еще продаем этот синтез вместе с узнаванием параллельного и такой запрос бывает так ладно еще кисть вопроса так давай вопрос давайте свой микрофон дам быстрее будет сейчас тоже насыпью применяете или же плюшки переползли тележки это окей так что еще вопрос да пожалуйста вопрос куда движетесь дальше после хайпа gun сложный вопрос наверное надо задавать или мне потому что я честно говоря уже давно не занимаюсь вот я занимаюсь распознаванием вот поэтому поэтому я не знаю почему"
}