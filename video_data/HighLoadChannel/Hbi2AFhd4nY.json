{
  "video_id": "Hbi2AFhd4nY",
  "channel": "HighLoadChannel",
  "title": "Основы мониторинга PostgreSQL / Алексей Лесовский (DataEgret)",
  "views": 19781,
  "duration": 2691,
  "published": "2019-01-14T00:12:31-08:00",
  "text": "меня лисовский я представляю компанию до этой игры и несколько вопросов чтобы понять какая здесь и аудитория поднимите руку кто работает с под гриссом как в качестве но базу данных проекта а кто непосредственно администрирует под grease занимается тюнингом конфигурации настройкой отлично очень хорошо а кто здесь из публики живет в новосибирске либо в окрестных городах недалеко от новосибирска и река прикольно клево отлично я познакомился с вами сейчас немного слов о себе как я уже сказал у меня зовут алексей лисовский я начинал когда-то давным-давно системным администратором администрировать всякие разные linux занимался разными вещами связанные с linux смита всякими виртуализации мониторинга my нужен иксами про xiaomi и так далее но в какой-то момент я стал заниматься в больше базами данных под гриссом мне очень нравился я занимался после сам в тот момент я стал заниматься в под грифом основную часть своего рабочего времени и так постепенно я стал под гриль словом дуба и на протяжении всей своей карьеры так скажем мне всегда были интересны темы статистике мониторинга снятие телеметрии и вот всякие такие вещи и когда я был системным администратором я занимался очень плотно zabbix а мы написал такой небольшой набор скриптов zabbix xt джонс и он был довольно очень популярны тут свое время и там можно было мониторить очень разные важные штуки не только там linux но еще разные компоненты сейчас я занимаюсь уже под гриссом я пишу другую штуку которая позволяет работать с подагре savoy статистикой называется в б-га центр мы небольшая вводная как обычно какие бывают ситуации у наших заказчиков наших клиентов происходит какой-то какой-то факап какая-то авария связанная с базы данных и когда уже произошло восстановление базу данных восстановили приходит начальник отдела или начальник разработки к своим коллегам и говорит друзья надо бы нам за мониторить базу данных потому что случилось что-то плохое и надо чтобы в будущем такого не происходило здесь начинается интересный процесс выбора системы мониторинга либо адаптации существующей систему мониторинга для того чтобы можно было мониторит свою базу данных там postgres это массе кол или еще что-то и коллеги тут же начинают предлагать вот я слышал там что есть такая-то база данных давайте использовать ее коллеги начинают спорить между друг другом и в итоге получается ситуация что мы выбираем какую-то базу данных но мониторинг адресов не представлен довольно слабо и всегда приходится что-то допиливать брать какие-то репозитории с гитхаба клонировать их адаптировать скрипты как-то настраивать и в итоге это все вываляться в некую такую ручную работу поэтому в этом докладе я постараюсь дать вам некие знания о том как выбирать мониторинг не только для подвеса но и для базы данных и дать те знания которые позволят вам допилить ваш мониторинг чтобы получить от него какую-то пользу чтобы можно было мониторить свою базу данных использовать чтобы вовремя предупреждать какие-то предстоящие аварийные ситуации которые могут возникнуть и те идеи которые будут в этом докладе их можно напрямую адаптировать к любой базе данных будет субд и иллинойс quelle поэтому тут не только под gris но здесь будет много рецептов как сделать это в подписи примеры запросов какие-то примеры там сущности которые есть в возрасте для мониторинга и если ваша субд и имеет такие же вещи которые позволяют засунуть в мониторе да вы тоже можете их адаптировать добавить ее будет хорошо чего-нибудь в докладе в докладе я не буду рассказывать про так как доставляйте хранить метрики я не буду сравнивать эти time series баз данных ничего такого не буду ничего говорить о пост обработки данных и предоставления их пользователей и не буду ничего говорить о полете нге но по ходу повествования я буду показывать вам всякие разные скриншоты существующих мониторингов как-то их критиковать но тем не менее я постараюсь не называть брендов чтобы не создавать рекламу или антирекламу этим продуктом поэтому все совпадения случайны и остаются на вашу фантазию ну для начала что такое мониторинг мониторинг это очень важная штука которая которую нужно иметь и все это понимают но в то же самое время мониторинг не относится к бизнес продукту и напрямую не влияет на прибыль компании поэтому на мониторинг всегда уделяют время по остаточному принципу если у нас есть время мы занимаемся белем свое мониторинг если времени нету но окей поставим там в backlog и когда-нибудь вернемся к этим задачам поэтому мониторинг часто из нашей практики мы приходим клиентам мониторинг очень часто не доработаны не имеет каких-то интересных вещей которые помогали бы нам делать работу лучше с базы данных поэтому many times всегда нужен выпиливать и базы данных это такие сложные штуки которые тоже нужно мониторить и потому что база данных это хранилище информации и информация очень важна для компании и нельзя никак терять но в то же время базы данных это очень сложно и куски программного обеспечения и не состоят из большого количества компонентов и многие из этих компонентов нужно мониторить если мы говорим про конкретно по дрифту его может представить в виде такой схемы которая состоит из большого количества компонентов эти компоненты взаимодействуют друг с другом и в то же время в под греси есть так называемая подсистема stats коллектора которая позволяет собирать статистику о работе этих подсистем и предоставлять некий интерфейс администратору или пользователю чтобы он мог просматривать эту статистику эта статистика представлена в виде некоторых некоторого набора функций и вьюг их можно еще назвать таблицы то есть с помощью обычного pqr клиента вы можете подключиться к базе данных сделать select к этим функциям и view хам и получить уже какие-то конкретные циферки а работе под систем пожгли со вы можете запросто забрать эти циферки вашу любимую стену мониторинга нарисовать графики там добавить функции и получать какую то уже ну аналитику в долгосрочной перспективе но в этом докладе я не буду рассматривать поголовно все эти функции потому что это реально может занять целый день вот я буду обращаться буквально к двум трем четырем штукам и буду рассказывать как они помогают сделать мониторинг лучше и если говорить про мониторинг базы что нужно мониторить но в первую очередь нужно мониторить доступность потому что база это в первую очередь сервис который предоставляет доступ к данным клиентом и нам нужно доступ мониторе доступность и некоторые качественные и количественные характеристики также нужно мониторить клиентов которые подключаются к нашей базе потому что они могут быть как и нормальными клиентами так и вредными клиентами которые могут наносить вред базе данных их тоже нужно мониторить и отслеживать их деятельность когда клиенты подключаются к базе данных очевидно что они начинают работать с нашими данными поэтому нам нужно мониторить это как клиенты работают с данными с какими таблицами в меньшей степени с какими индексами то есть нам нужно оценить workload который создается нашими клиентами но и workload состоит конечно же из запросов приложение подключается к базе обращается к данным с помощью запросов поэтому важно оценивать какие запросы у нас в базе данных отслеживать их адекватность что они не являются криво написанными что их возможно их есть какие-то опции переписать и сделать чтобы они работали быстрее с более лучшей производительностью ну и раз мы говорим про базу данных то база данных это всегда фоновые процессы фоновый процесс и они позволяют поддерживать производительность база данных на ком-то должном хорошим приятном уровне поэтому для их работы они требуют некое некое количество ресурсов для себя и в то же время они могут пересекаться с ресурсами и клиентских запросов поэтому жадная работа фоновых процессов может непосредственно влиять на производитель скин дронов запросов поэтому их тоже нужно мониторить и отслеживать что нет никаких перекосов в плане фоновых процессов и это все в плане мониторинга базы данных и остается системные метрики но учитывая что у нас по большей части вся инфраструктура уезжает в облака системной метрики отдельного hasta всегда отходят на второй план но в базах данных они все еще актуальны и мониторить системной метрики конечно также нужно но системными метриками более менее все хорошо и все современные системы мониторинга уже поддерживают эти метрики но в целом каких-то компонентов все-таки недостаточно и нужно некоторые вещи добавляйте принесет тоже затрону несколько слайдов будет про них но и первый пункт плана это доступность что такое доступности доступность в моем понимании это способность базы обслуживать подключение то есть база поднята она как сервис принимает подключение от клиентов и эту доступность можно оценивать некоторыми характеристиками эти характеристики очень удобно выносить на даже борды все знают что такое даже морды это когда ты бросил один взгляд на экран на котором съедена нужно необходимая информация и вы уже можете сразу определить есть проблема в базе или нету ну или какой-то любой другой продукт который вы мониторите соответственно доступность базы данных базы данных и другие ключевые характеристики всегда необходимо выносить надо же морды чтобы эта информация была у вас под рукой была у вас всегда рядом какие-то дополнительные детали которые уже помогают при расследовании инцидентов при расследовании пихта аварийных ситуаций их уже нужно выносить на вторичные даже морды либо скрывать в drill-down рингах которые там ведут на кита сторонняя систему мониторинга ли вы еще какие то другие вещи и пример 1 известная система мониторинга кто узнал эту систему мониторинга поднимите руку пожалуйста отлично хорошо это очень круто я стер мониторинга на собирают очень много нам их но с моей точки зрения у нее странное понятие дашбордов там есть ссылка создать дашборд но когда вы создаете даже борт вы создаете некий список состоящий из двух колонок некий список графиков когда вам нужно что то посмотреть вы начинаете мышкой кликать иль стать искать нужный график и на это уходит время то есть дашбордов как таковых нету есть лишь в списке графиков что нужно добавлять на эти dash горды но можно начать с такой характеристики как время отклика в под здесь есть такая view hotel is the statements по умолчанию она отключена но это одна из важных системных wheels которые всегда необходимо включать и использовать она хранит в себе информацию о всех выполняющихся запросов которые в базе данных выполнялись соответственно мы можем оттолкнуться от того что взять суммарное время выполнения всех запросов и поделить на количество запросов с помощью выше приведенных полей но это такая средняя температура по больнице но мы можем оттолкнуться от других полей минимальное время выполнения запроса максимальная и медиана и даже можем строить persantine в подписи есть соответствующие функции для этого соответственно мы можем уже получить какие-то цифры которые характеризуют время отклика нашей базы уже выполненным запросам то есть мы не выполняем какой-то такой фейковый запрос select 1 и смотрим время отклика мы анализируем время ответов позже выполненным запросам и рисуем эту цифру либо она отдельной цифра и либо уже строим бани график также важно отслеживать количество ошибок которые генерируются системой в данный момент и для этого можно использовать в ухо пиджи стадий the bass мы ориентируемся на поле doctoral бег это поле показывает не только количество румбиков которое происходит в базе но еще и учитывает количество ошибок условно говоря мы можем выводить эту цифру в наш дашборд и смотреть сколько у нас ошибок в данный момент если ошибок много это уже хороший повод заглянуть в логе и посмотреть что же это за ошибки почему не происходит и дальше уже инвестировать из этих можно добавить такую штуку как тахометр я и называю это количество транзакций в секунду и количество запросов в секунду условно говоря вы можете использовать эти цифры как текущую производительность вашей базы данных и наблюдать если пике запросов пике транзакций либо наоборот база не загружена потому что какой-то backend может быть отвалился и эту цифру важно всегда смотреть помнить и примерно помнить что для нашего проекта вот такая производительность является нормальной а значение выше и ниже уже какие-то проблемные непонятные нужно смотреть почему такие цифры чтобы оценивать количество транзакций мы снова можем обратиться к ухе пиджи стадий the bass мы можем сложить количество коммитов и количество ral беков и получить количество транзакций в секунду чтобы получить количество запросов в секунду но все понимаю что в одну транзакцию может уложиться несколько запросов поэтому как бы дпс и куб с они немного разные количество запросов в секунду можно получить вот пиджи is that statement и просто посчитать сумму всех выполненных запросов ну понятно что мы сравниваем текущее значение с предыдущим вычитаем получаем дельту получаем количество можно добавить дополнительные метрики по желанию которые также помогают оценивать доступность нашей базы и отслеживать не было ли каких-то down time of одна из этих метрик это об этоим но up at times в возрасте это немного хитрая штука расскажу почему когда после запустился начинается отчитываться об этоим но если вдруг в какой-то момент там ночью какая-то фоновая задача выполнялось пришел вам киллер и завершил принудительно процесс дочерний процесс под криса то в этом случае под grease завершает соединение всех клиентов сбрасывает область солидной памяти и начинает восстановление с последней контрольной точки и пока длится это восстановление с контрольной точке база не принимают подключения то есть эту ситуацию можно оценивать когда он time но при этом счетчик аптайма не сбросится потому что он учитывает время запуска пуст мастера самого первого момента поэтому такие ситуации можно пропустить также следует мониторить количество worker of vacuum а потому что вакуум все значит такое вакуум of the vacuum мозге все это очень такая интересная система в после все про нее написано много статей много докладов и много копий сломано в обсуждениях про вакуум как он должен работать многие считают твою неизбежным злом вот ну в общем-то да так и есть но это некий аналог сборщика мусора который чистит устаревшие версии строк которые не нужны ни одной из транзакций и освобождает место в таблицах индексах для новых строк но почему нужно его мониторить потому что вакуум иногда делает очень больно отжирает большое количество ресурсов и клиентский запрос это то начинает страдать просто-напросто и мониторить следует его через вьюгу пиджи стад activity про который я буду следующем разделе говорить это в ухо показывает активность текущую активность в базе данных и через эту активность мы можем отследить количество вакуумов который работает прямо сейчас мы можем отслеживать количество вакуумов и видеть если у нас превышен лимит это повод заглянуть в настройки прогресса и как-то уже optim пировать работу вакуума другой особенностью под gresso является то что под крису очень больно от долгих транзакций особенно от транзакции которые работают долгое точнее они висят долгое ничего не делают это так называемый state idol in tranzaxis такая транзакция она удерживает блокировки и она мешает работать вакууму и как следствие таблицы пухнут они увеличиваются в размере и запросы которые работают с этими таблицами они начинают работать медленнее потому что нужно лопатить в сети старые версии строк из памяти на диск а я обратно поэтому время длительность самых долгих транзакций самых долгих запросов вакуумов тоже нужно мониторить если мы видим какие то процессы которые работают уже очень долго больше 10 20 30 минут для цепи нагрузки то на них нужно уже обращать внимание завершать принудительно либо оптимизировать приложение чтобы они не вызывали сине веселье так долго для аналитической нагрузки это в принципе нормально 10 20 30 минут там бывает еще и больше дальше у нас вариант с подключенными клиентами когда мы уже сформировали дашборд вывесили на него ключевые метрики доступности мы можем также добавить туда и дополнительную информацию о подключенных клиентах информация подключенных клиентах важно потому что с точки зрения подвесок клиенты бывают разные бывают хорошие клиенты бывают плохие клиенты простой пример клиент клиент это я понимаю как приложение приложение подключилась к базе данных и начинает сразу слать туда свои запросы базу данных их обрабатывать выполняют результаты возвращает клиенту это хороший правильный хороший клиент бывает ситуации штук лент подключился он удерживает connect но при этом ничего не делает он находится в состоянии idol ничего не делает но бывают плохие клиенты например тот же клиенты подключился открыл транзакцию что-то поделал в базе и потом ушел в код например обратиться к внешнему источнику либо там сделать какую-то там обработку полученных данных но при этом он не закрыл транзакцию и транзакция висит в базе и удержит блокировки настройки это плохое состояние и если вдруг приложение где-то там внутри у себя упадет по exception у транзакция может остаться открыты на очень долгое время и это влияет напрямую на производительность по сгрыз а вот рис будет работать медленнее поэтому таких клиентов важно отслеживать во время и завершать их работу принудительное оптимизировать свое приложение чтобы не было таких ситуаций другие плохими клиентами являются ожидающие клиенты но они становятся плохими из-за обстоятельств даже самая простая его ющая транзакция она может там открыть транзакцию взять блокировки на какие-то строки потом где-то на входе там упадет придется останется транзакция висящая придет другой от ран придет другой клиент запросит те же самые данные но он столкнется с блокировкой потому что то висящая транзакция уже удерживает блокировки на какие-то нужные строки и 2 транзакция будет висеть в ожидании когда первая транзакция закроется завершится либо ее администратор принудительно закроют таким образом ждущие транзакции могут просто накапливаться и переполнять лимит подключение к базе данных и когда лимит переполнен то приложение уже не может работать с базой это уже но аварийная ситуация для проекта поэтому клиентов плохих нужно отслеживать и своевременно на них реагировать другой пример мониторинга и здесь такой уже более приличный дашборд есть информация по коннектор сверху наверное не совсем хорошо о нет видно здесь тебе connections 8 штук и собственно это все у нас нет информации о том какие клиенты активные какие клиенты просто idol ничего не делают висящие транзакции ничего этого нету нету информации о выйти нг ожидающих коннектов то есть это такая цифра который показывает количество контактов и все а дальше там гадайте сами соответственно чтобы добавить эту информацию в мониторинг нужно обратиться к системной view he is that activity вообще если вы много времени проводите в воскресе это очень хорошая вьеха которая должна стать вашим другом потому что она показывает текущую активность мозга и все что происходит на каждый процесс есть отдельная строчка которая показывает информацию по этому процессу с какого х 100 выполнена подключения под каким пользователем под каким именем когда запущена транзакция какой сейчас выполняется запрос какой запрос выполнялся последним и соответственно состоянии клиентов мы можем оценивать по полю state условно говоря мы можем сделать группировку по этому полю и получить те state и которые я сейчас в базе данных и количество коннектов которое вот с этим stay там в базе данных и уже полученные цифры отправлять наш мониторинг и рисовать по ним графики также важно оценивать длительность транзакций я уже говорил что важно оценивать длительность вакуумов но и транзакции в общем-то оцениваются точно также есть поля казактар тыквы restart они условно говоря показывают время старта транзакции и соответственно время старта запроса мы берем функцию на у которая показывает текущую отметку времени и вычитаем таймс темп старта транзакции запроса и получаем длительность транзакции длительность запроса если мы видим длинные транзакции мы должны уже их завершать для в тебе нагрузки длинные транзакции это уже больше 1 2 3 минут для лап нагрузки длинной транзакции в принципе являются нормальными но если они выполняются там больше двух часов это тоже уже признак того что где-то у нас перекос какой-то неправильный когда клиенты уже подключились базе данных они начинают работать с нашими данными они обращаются каким-то таблицам они обращаются каким-то индексом чтоб получить данные из таблиц и важно оценивать то как клиенты работают с этими данными это нужно для того чтобы оценить наш workload и примерно понимать какие таблицу но самое горячее например это нужно в ситуациях когда мы хотим горячие таблицы часто используем поместить на какое-то быстро и создать хранилище какие-то архивные таблицы которые мы уже давно не используем можно вывести на какой-то холодный архив на кита sas sata диски и пусть они там живут и к ним обращение идет к там парень по необходимости также это полезно для обнаружения для обнаружения аномалий после всяких релизов и дипломов допустим проект выкатил какую-то новую фичу добавили какую-то новую функциональность для работы с базой и если мы построим графики у использования таблиц мы в этих графиках сможем легко обнаружить эти аномалии например всплески апдейтов либо всплески дэвид of это очень хорошо будет видно также можно обнаружить аномалий поплывший статистике что это значит в подписи очень сильный и очень хороший планировщик запросов он такой в противовес оракла уму и и разработчики позы леса очень много времени уделяют его развитию как он работает для того чтобы строить хорошие планы разрез с некоторым интервалом времени с некоторой периоде кай собирает статистику о распределении данных в таблицах это самое частое значение количества уникальных значений и там информация на лах в таблице очень много информации на основе этой статистики планировщик строит несколько запросов выбирает наиболее оптимальной оценки так называемого каста и использую этот план запроса для уже выполнения самого запросы возвращения данных и бывает что статистика плывет данные качественно и количественно как-то поменялись таблицы но статистика при этом не собралась и сформированные планы они могут оказаться не оптимальными и если у нас плана окажутся не оптимальными собираемой собираемого мониторингу по таблицам мы сможем увидеть эти аномалии например где-то качественно изменились данные и вместо индекса стал использоваться постельный проход по таблице то есть если запросу нужно вернуть всего там 100 строк стоит ограничение limits to the для этого запроса будет выполнен полный перебор и это очень плохо сказывается на производительности всегда и мы сможем увидеть это в мониторинге и уже посмотреть на этот запрос выполнить для него explain собрать статистику построить новый дополнительный индекс какой-то и уже отреагировать соответственно на эту проблему поэтому это важно другой пример мониторинга и я думаю многие узнали потому что он очень популярный по 9 rue кто знает что это такое отлично кто использует у себя в проектах parameters кто использует этот продукция вместо с правительством дело в том что в стандартном репозитории этого мониторинга есть даже word для работы с postgres экспортером про метался но тут есть одна плохая детали есть несколько графиков и в качестве юнита указанной байты то есть там 5 графиков и to ensure дата апдейт до то отделить да да и речь перед аренда то 5 графиков в качестве юнитов измерения указаны байты но дело в том что по за рисовая статистика возвращает данные в тапках в строках то есть соответственно вот эти графики это очень хороший способ занизить ваш workload в несколько раз в десятки раз потому что to pull it any buy the pool это очень но эта строка это много байтов и она всегда переменной длины то есть вычислить workload в байтах с помощью то плав но это не задача ну либо реально но очень сложно поэтому когда вы используете там даже word какой-то либо какой-то встроенный мониторинг всегда важно понимать что он работает правильно и возвращает вам корректно оцененное данные как получаете статистику по этим таблицам для этого в поскрести есть некоторое семейства views и основная века этапе g-star юзер тейлз юзер тейлз это означает что таблицы созданная от лица пользователя в противовес есть системная в ухе которая используется самим пожгли сам есть сводная таблица all тейлз которая включает и системные и пользовательские то есть вы можете отталкиваться от любой из них который вам больше всего нравится по выше указанным полям можно оценивать количество insert of апдейтов иди литов тот пример даже гордо который использован как раз используют эти поля для оценки там характеристик вор клода поэтому мы также можем отталкиваться от них но пусть стоит помнить что это таблы они байт и поэтому мы не можем взять его и сделать байтами так вот на основе этих данных мы можем строить так называемые тупым таблицы например топ 5 топ 10 и отслеживать те горячие таблицы которые утилизируются наиболее больше остальных например 5 горячих таблиц там по вставке да где у нас тут таблице какие таблицы у нас больше всего тому вставка записи идет либо где удаляются либо где обновляются совместно по этим тупым таблицам мы оцениваем наш workload и можем оценивать всплески war клода после всяких релизов и апдейтов и диплом также важно оценивать размеры таблиц и потому что иногда бывает разработчики выкатывают какую-то новую фичу и у нас таблицы начинают пухнуть в своих больших размерах потому что решили дать писать какое-то дополнительное дополнительный объем данных но при этом не спрогнозировали как это скажется на размере базы данных такие случаи тоже бывают сюрпризами для нас как для детей сейчас не большой вопрос для вас какой возникает вопрос когда вы замечаете нагрузку на сервере на сервере с базой данных какое следующее вас вопрос возникает кто папа так еще все но на самом деле вопрос возникает следующий какие запросы вызывают нагрузка то есть неинтересно смотреть процессы танки вызывает нагрузку понятно если ход с базой данных там запущенным база данных и понятно что там только база данных и будет утилизировать но откроем этот увидим там список процессов пол листа они что-то делают как бы из топа будет непонятно что они делают соответственно нужно обнаружить те запросы которые вызывают наибольшую загрузку потому что тюнинг запросов как правило дает больший профит чем тюнинг конфигурации мозга риса или операционной системы или даже тюнинг железо по моей оценке это примерно 80 85 90 процентов и это делается гораздо быстрее быстрее поправить запрос чем поправить конфигурацию запланировать restart особенно если базу не стартовать нельзя и либо добавлять железо проще где-то переписать запрос либо добавить индекс чтобы получить уже более лучший результат от этого запроса соответственно нужно мониторить запросы их адекватность возьмём другой пример мониторинга и тут тоже вроде прекрасный мониторинг есть информация по репликации есть информация по пропускной способности блокировкам утилизация ресурсов все прекрасно но нет информации по запросам непонятно какие запросы выполняются в нашей базе данных как долго не выполняется сколько этих запросов соответственно нам нужно в мониторинг всегда-всегда в мониторинге иметь эту информацию и для получения этой информации мы можем использовать модуль который я ранее угол the igy is that statement на основе него можно строить самые разные графики например можно получать информацию по самым частым запросам то есть и запросы которые выполняются больше всех чаще всех да это тоже после дипломов очень полезно посмотреть на него и понимать нет ли менялся какого-то всплеска запросов можно мониторить самые долгие запросы то есть те запросы которые выполняются дольше всех они работают на процессоре они потребляют вот вывод какой то мы можем это тоже оценивать по полям total time when time там есть еще поля бог в right time блок рид times то есть они уже связаны с его мы можем оценивать и мониторить самые тяжелые запросы в плане использования ресурсов те которые читают с диска которые работают с памятью либо наоборот создают какую-то пишущую нагрузку можем оценивать самые щедрые запросы это те запросы которые возвращают большое количество строк например это могут быть какой-то запрос или забыли поставить лимит и он просто возвращает все содержимое таблицы либо запроса по заброшенным таблицам ну и можно также мониторить запросы которые используют временные файлы либо временные таблицы но у нас остались волновые процессы фоновый процесс это в первую очередь чекпоинты или их ещё называют контрольной точки это of the vacuum & replication другой пример мониторинга есть там слева вкладка maintenance переходим на нее и надеемся увидеть что-то полезное но здесь только время последнего работы время работы вакуума и сбора статистики больше ничего но это очень бедная информация поэтому всегда нужно иметь информацию о том как работают фоновые процессы называйте данных и нет ли проблем от их работы когда мы рассматриваем контрольной точки то следует помнить что контрольные точки они у нас сбрасывают грязной страницы из области ш рядной памяти на диск затем создают точку контрольную точку и это контроля . уже дальше может использоваться как некое место при восстановлении если вдруг пост был аварийно завершён соответственно чтобы сбросить все грязные страницы на диск нужно проделать некий объем записи и как правило на системах с большим объемом памяти это очень много и если у нас чекпоинты делаются с каким то ну очень часто какой-то короткий интервал то дисковая производительность будет очень сильно проседать и клиентские запросы будут просто-напросто страдать от нехваткой ресурсов они просто будут бороться за ресурсы им будет не хватать производительности соответственно через пиджи stand by gerald r по указанным полям мы можем мониторить количество случающихся чек-поинтов и если у нас за какой-то промежуток времени 10-15-20 минут полчаса очень много чек-поинтов там если их уже три четыре пять это уже может быть проблемой и уже нужно посмотреть в базу данных посмотреть в конфигурацию что вызывает такое билетик моментов может какая-то большая запись идет на повар клоду можем уже оценить потому что у нас графики war кладу уже добавлены мы можем уже подтюнить параметры контрольных точек и сделать так чтобы они не сильно влияли на производительность запросов of the vacuum да я снова возвращаюсь к авто вакууму потому что автово кому такая штука как я уже говорил он может запросто вам сложить производительность как дисков так и запросов поэтому всегда важно оценивать количество авто вакуумом количество worker of базе данных ограничено по умолчанию и хитри поэтому если у нас все время тревор кира работает в базе это значит что у нас в the vacuum не до настроен нужно поднимать лимиты пересматривать настройки авто lokomo и уже лезьте в конфигурацию важно оценивать какие у нас работают worker и вакуума либо это запущенный от пользователя либо пришел руками запустил какой-то вакуум это создало нагрузку у нас появилась к эта проблема либо это количество вакуумов которые откручивают счетчик транзакций до некоторых версии пузырь из это очень тяжелое вакуум и и они могут запросто сложить производительность потому что они вычитывают всю таблицу целиком сканируют все блоки в этой таблице ну и конечно длительность вакуумов если у нас долгие вакуум и которые работают очень долгое время это значит вам снова нужно обратить внимание на конфигурацию вакуума и возможно пересмотреть его настройки потому что может появиться ситуация когда вакуум работает на таблице долгое время 3 часа 4 часа но за время работы вакуума в таблице успели накопиться снова большой объем мертвых строк и как только вакуум завершится ему снова нужно вакууме эту таблицу и мы приходим к ситуации бесконечного вакуума и в коем случае вакуум просто не справляется со своей работой и таблица начинают постепенно пухнуть в размерах хотя объем полезных данных не остается прежним поэтому при долгих вакуум ах мы всегда смотрим на конфигурацию и пытаемся оптимизировать ее но при этом чтобы не страдали производительность клиентских запросов и последняя это репликация сейчас практически нету инсталляции под газ и где не была вы потоковой репликации репликация ну просто процесс переноса данных с мастера на реплику репликация в прогрессе устроена через журнал транзакций мастер генерит журнал транзакций журнал транзакций по сетевому соединений уютно реплику дальше на реплики он воспроизводится все просто соответственно для мониторинга логарифме кации используется в ухо пиджи стад репликейт шин но с ней и все просто версии 10 вьеха претерпела несколько изменений во первых часть полей была переименована и часть полей была добавлена в десятой версии появились поля которые позволяют оценивать лака репликации в секундах это очень удобно для версии 10 была возможность оценивать лак репликации в байтах но собственно она осталась в десятой версии то есть вы можете выбирать что вам удобнее оценивать лак в байтах либо оценивать лак в секундах многие делают то и другое но тем ни менее чтобы оценивать байты оценивать лак репликации нужно знать позиции журналов и транзакции и эти позиции журнала транзакций они как раз есть в you happy g-100 трипле кейлин условно говоря мы с помощью функции пиджи их слова кишинев можем взять две точки в журнале транзакции посчитать между ними дельту и получить лак репликации в байтах это очень удобно и просто в 10 эта функция была переименована в переживал lsn div вообще все функции все вьюки все названия утилит где была где встречалась слова ics lock она была заменена на значение вал это его в ушах и функциях поэтому это такое нововведение плюс 10 версии добавились строчки в которые конкретно показывают лак это в райт лак пошла к реплей лака то есть эти штуки важно мониторить если мы видим что у нас флаг репликации нужно уже исследовать почему откуда взялся и устранять проблему мы остались системные метрики с системными метриками в принципе все в порядке любой мониторинг когда он зарождается он начинает системных метрика это утилизация процессоров памяти свопа сети и диска но тем ни менее многих параметров там по умолчанию нету если с утилизацией процессора все в порядке то с утилизацией дисков есть проблемы как правило разработчики мониторингов добавляют информацию о пропускной способности она может быть вы об сах либо в байтах но они забывают про late in se и утилизацию дисковых устройств это более такие важные параметры которые позволяют оценивать насколько у нас загруженный диски и насколько они тормозят а если у нас высокие лад и леденцы это значит туда у нас какие-то проблемы с дисками если у нас высокая утилизация да это значит у диски не справляются это более качественные характеристики чем пропускная способность при том что статистику это можно также получить из файловой системой про как это делается для утилизации процессоров почему эту информацию не добавляет мониторинге я не знаю но тем не менее важно иметь это в своем мониторинге то же самое относительно сетевых интерфейсов есть информация пропускной способности сети в пакетах в байтах но тем ни менее нет информации алакенси и нет информации об утилизации хотя это тоже полезная информация ну и на этом у меня все мне уже показывает пять минут ну я в общем то укладываюсь что хотелось бы сказать любые мониторинге имеют недостатки к сожалению серебряной пули нету и какой бы вы мониторинг не взяли он всегда будет не соответствовать каким-то критериям но тем не менее они развиваются добавляются новые фичи новые вещи поэтому выбирайте что-то допили войти ну и для того чтобы допиливать нужно всегда иметь представление как что означает отдаваемая статистика и как с помощью нее можно решать проблемы и несколько ключевых моментов всегда нужно мониторить доступность иметь даже морды что вы могли быстро оценить что с базой все в порядке всегда нужно иметь представление о том какие клиенты работают с вашей базы данных чтобы отсеивать плохих клиентов и отстреливать их до важно оценивать то как эти клиенты работают с данными нужно иметь представление о вашем work лоде важно оценивать как формируется этот workload с помощью каких запросов вы можете оценивать запросы вы можете их оптимизировать и factory строить для них индексы это очень важно фоновые процессы фоновой процесса они могут негативно влиять на клиентские запросы поэтому важно отслеживать что они не используют слишком много ресурсов и системные метрики они позволяют вам делать планы на масштабирование на увеличение емкости ваших серверов поэтому важно их тоже отслеживать и оценивать если вас заинтересовала эта тема вы можете вот пройтись по этим ссылкам первая ссылка это официальная документация с коллектора статистике там есть описание псих вьюг статистических и описания всех полей вы можете их прочитать понять и ну там проанализировать и уже на основе них строить свои графики добавлять свои мониторинге но и примеры запросов это репозиторий наш корпоративный и мой собственный в них есть примеры запросов там нету запросов и серии select звездочка from что-то там там уже готовые запросы с джо и нами с применением всяких интересных функций которые позволяют из сырых цифры сделать какие-то человеко читаемое удобно и значения то есть там байты время все такое интересное поэтому вы можете просто их ковырять смотреть анализировать добавлять свои мониторинге строить на их основе своей мониторинге и на этом у меня все спасибо за внимание надеюсь вам понравилось если у вас есть вопросы задавайте спасибо за доклад у меня есть такой вопрос вот вы сказали что не будете рекламировать брэндон мне все-таки интересно в своих проектах вы какие даже борды используете по-разному по разному бывает что мы приходим заказчику у него уже есть свой мониторинг и мы консультируем заказчик о том что нужно добавить и его мониторинг хуже всего обстоят дела zabbix а потому что у него нет возможности строить top н графики сами мы используем алкометр потому что мы консультировали этих парней по мониторингу они делали мониторинг пузырь со на основе наших нашего техзадания сами мы двигаемся в сторону но я пишу свой такой пэт project который данные собирает через prometheus и отрисовывать ты в га рф а ну то есть у меня задача стоит там сделать про митоз экспортер свой и дальше уже там отрисовывать все в graph они еще образ вот мод мужчина в третьем ряду здравствуйте спасибо за доклад не вопрос такой министра тронг ла интересно а если какие-то аналогии avr отчетов или стать подаче на вход агрегат минута что-то в таком роде может быть известного да я знаю что такое verde крутая штука на данный момент есть самые разные велосипеды которые реализуют примерно следующую модель с некоторым интервалом времени пишутся некоторые бы из linea в тот же самый пузырь с либо в отдельные хранилища их можно погуглить в интернете они есть один из разработчиков такой штуки он сидит на форуме скаляру ветки прогресс вот его можно там поймать и такие штуки есть до их можно использовать но плюс там в своем pg центре я тоже пишу штуку которая позволяет делать то же самое пожалуйста так если вопросов ни у кого нет то спасибо за внимание вам всем хорошего дня если у вас будут вопросы про мониторинг то ловите меня задавайте вопросы буду рад ответить спасибо"
}