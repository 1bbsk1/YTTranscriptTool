{
  "video_id": "CYKN3rCep0s",
  "channel": "HighLoadChannel",
  "title": "CБОЛ. Архитектура слоя хранения / Илья Кайшаури (Сбербанк)",
  "views": 736,
  "duration": 3156,
  "published": "2024-04-17T01:10:23-07:00",
  "text": "а он так Всем привет как меня слышно Здорово отлично так Всем привет еще раз меня зовут кайшоу Илья я сегодня буду рассказывать про то как устроен мобильный бэкенд Сбербанка онлайн с точки зрения хранения данных собственно говоря кто Перед вами стоит еще раз кейшаурилья Георгиевич занимаюсь базами данных Сбербанке онлайн руковожу командой развития сбол сопровождение развитие внедрения новых стек Все проходит через меня У меня очень крутая команда и мы соответственно работаем над тем чтобы наш сохранение был недорогим надежным и доступным для всех разработчиков прежде чем в принципе нырять в тему хорошо бы понимать как Сбербанк онлайн устроен что он из себя представляет где он живет войти всего сбера начнем справа налево найти ландшафт сбера представляет из себя набор backend автоматизированных систем интеграционных шлюзов фронтальных систем и конечных клиентских приложений Back and это у нас Независимый автоматизированной системы каждый из которых представляет из себя мастер систему своего бизнес-продукта будь то вклады карты ипотеки отдельно кредиты и так далее интеграционный слой Это непосредственно набор интеграционных решений которые позволяют нам взаимодействовать фронтальная система по сути фронтальными системами являются каждый для своего клиентского сегмента таких сегментов всего три у нас все про них знаете на самом деле первый это Сбербанк онлайн Это фронтальная система физических лиц Это фронтальная система сотрудников для вас будет понятнее отделение сбера вот отделение сбера где получали карту туда идите это вот ко вторым и третий сегмент это юрики Сбербанк Бизнес Онлайн то есть мы имеем три независимые инсталляции фронтальной системы каждый из которых является мобильным бэкендом своего канала сегодня будем говорить исключительно про самую высокую нагруженный сегмент это физические лица не упущу возможности лишний раз отметить что наш небольшой стартап ему доверяют порядка 80 миллионов клиентов свой банковская удаленное обслуживание что мы обычный день Для нас это порядка 120 тысяч входов в Пике это 70 тысяч документов в минуту в Пике и роскошь в виде недоступности которые мы можем себе позволить это порядка часа недоступности в год все выдохнули теперь в принципе можем идти дальше единая фронтальная система физических лиц сокращенный efs в левом верхнем углу написано из чего же собственно говоря состоит состоит Она из оперативных клиентских блоков по сути Это шарды кто был допустим на выступление арюкина Артема ему будет проще С этой картинкой взаимодействовать то есть оперативные клиентские блоки это клиентские шарды они делятся на основные и резервные вот два внизу резервных куда тот или иной клиент попадает решает слой аутентификации маршрутизации то есть валидация логина пароля и соответственно маршрутизация клиентов свой блог выполняется при помощи некого слоя аутентификации маршрутизации о нем сегодня речи не будет потому что не является частью нашей автоматизированной системы и обслуживает на самом деле куда больше компонентов и сервисов Сбере чем просто Сбербанк онлайн и архивный слой архивный слой по сути это бэкап всего необходимого что у нас есть в оперативных блоках а вот тут я добавил немножко экшена скажем так что вот при успешном аутентификации клиента с мобильного приложения попадает непосредственно в свой родной блок в случае когда родной блок недоступен по тем или иным причинам Либо мы его специально увеличили для того чтобы обновить версию какого-то микросервиса либо у нас случился инцидент Что бывает мы благополучно маршрутизировали в резервный блок соответственно рассказ начнем с оперативного слоя хранения это те блоки которые непосредственно работают с клиентами оперативный блок представляет себя набор из огромного количества микросервиса их порядка 500 делятся они очень просто на бизнес микросервисы и платформенные суть разделения понятно и она очень простая то есть мы в свое время вынесли переиспользуемые функционалы которые так или иначе бизнес-продукту понадобились бы в отдельные платформенные компоненты и предоставили при помощи растаппе возможность ими пользоваться для бизнеса каждый квадратик бизнес микросервиса тут представлены по сути это отдельно кредиты платежи переводы p2p me to me и так далее таких порядка 400 за диплоидных у нас в контуре оперативном блоке разделение касается в том числе и персистатные хранилище также изолированы от бизнеса платформенный компонентами бизнес не знает что он что Украине знает конечно но как он это делает ему по сути не важно частью блока также является внешней и внутренние шлюзы по сути внешне принимают запрос Извне из мобилок версии и так далее взаимодействие платформенный микросервис на самом деле очень разные и выполняют самые различные функции но с точки зрения хранения мы их кластерилизовали следующим образом делятся они на профиль клиента это его история операции продукты остатки и настроечки которые он для себя выставил то есть некая персонализация клиента это конфигурация блока то есть прям настроечки которые говорят о том что этот блок работает Именно таким образом справочная информация То есть это справочники городов улиц уменьшительно-ласкательных имен всякого такого у нас чего только нету в виде справочников это сессионные данные данные которые по сути живут всего лишь момент жизни сессии и они актуальны только в этот момент это трассировочная информация которой на самом деле нас больше всего это журналирование это аудит для безопасности и это легковесный мониторинг для того чтобы вовремя фиксировать жизненные показатели нашей автоматизированной системы для функционирования нашего одного оперативного блока требуется порядка 180 терабайт дисков самыми крупными потребителями как мы видим являются журналирование аудит мониторинг и история операций то есть они практически занимают весь объем блока весь этот объем на самом деле не растет он стагнирован в части роста то есть мы его как бы зафиксировали благодаря тому что научились ротировать данные то есть мы определенным образом готовим данные для того чтобы они могли быть легко и безболезненно атрофировано то есть для тех кто занимается базами данных это обычный селекционирование либо это для исторических устаревающих данных это просто секционирование по диапазону Дат либо это селекционирование для данных которые консистенты только в пакетном варианте справочные данные выгружаются мы под них создаем собственную партицию имя хаш-версии справочника и он живет своей собственной секции таблицы и соответственно для некоторых данных мы оставляем в оперативном блоке например неделю месяц год и все что становится старше этого времени мы благополучно их удаляем и для справочных данных если бизнесу нужно хранить последние три версии справочников то мы допускаем то есть мы тоже даем возможность бизнесу спокойно мигрировать на новые версии справочников своих платформенные компоненты с точки зрения хранения данных делятся на три типа это те которые до сих пор работают с ораклом те которые работают уже на погрессе и встретил сервисы которым на самом деле персистентное хранилище вовсе не нужно для работы как имеют свою собственную базу данных так и могут коммуналиться в одной какой-то с другими компонентами с другими сервисными компонентами все зависит от нагрузки потребности которые платформы компоненту нужны то есть целые платформенные компоненты которые платформе микросервисы которые нужна прям целая база данных целый кластеры а некоторые десятерым живут ядерной нас интересует только первые два типа и начнем так тут должно было быть анимация И к сожалению нету роклы кластер представлен двумя продуктами это пакетом vertus highwaybility и опцией аппаратной репликации схд Я попозже объясню Непосредственно как работа отказ Сейчас я просто опишу все продукты которые мы используем этих пакетов то есть из верить и мы используем verts файл систем то есть непосредственно файловой системы ответят мы используем технологии которые предоставляет доступ к физическому по двум независимым путям по сути это резервирование сети сцен это мультипейсинг называется продукт и сердцем классного решения является веритос кластер кластер сервер он непосредственно помогает нам конфигурировать кластер из любого набора ресурсов которым на которые нам нужны помогает легко и просто сконфигурировать сценарий отказа и сценарий восстановления этого кластера что по сути мы имеем У нас есть два сервера в котором в один момент времени только на одном на одной технологической площадке поднята база данных к ней примонтированные файловые системы он работает только с одним исходы появляется надобность в случае отъезда этой площадки иметь полную копию этих данных на другом тут нам требуется опция аппаратной репликации схд то есть по сути это опция которая предоставляет нам возможность иметь логический том в двух копиях в двух разных технологических площадках и поочередно Иметь к нему доступ То есть сейчас мы имеем что у нас в одном дата-центре Point A база данных Она работает своими дисками и у нас есть где-то полная копия на другой площадке второй же сервер полностью не активен там нет ни оракла там даже не примонтированный файловой системы там исключительно работает Агент верит из кластер сервер который по сути проверяет работоспособность мастера в случае недоступности мастера кластер сервер принимает решение о том что нужно на неактивной ноте сама не активная нода пингует мастер понимает что там уже ничего нет Судя по всему и надо бы у себя локально начать поднимать базу данных соответственно он проверяет консистентность копии на исходе запрещает запись для первого цода разворачивает реплику ремонтирует ремонтирует диски и на локальных бинарниках поднимает по сути Оракул с этими дисками далее осуществляется перевязка кластерного IP для всех будущих потребителей И следующий Коннект по кластерам IP уже будет попадать абсолютно копию базы данных но на другой площадке а тут есть небольшой спойлер о том что как у нас данные попадают в архивный слой то есть golding Да и справа Тут видно примерную примерно копости нашей базы данных То есть вы действительно ресурсы как правило такого объема и диски самые разные вот 20 терабайт Басс данных может быть который мы считаем на самом деле маленькой до 90 представленсорсном патроне для тех кто работал с патроне картинка будет довольно понятно и суть в чем у нас есть две базы данных в один момент времени одна является мастером вторая физическая реплика так называемый на мастерегенерация журналы изменений они перебрасываются при помощи процесса определенного скажем так на удаленный сервер Там они накатываются данных и соответственно мы имеем полную копию этой базы данных достаточно осознанно кластер включён эти состояния кластера а в случае когда у нас происходит Сплит Brain и Оба плеча решат подняться например мастерами или наоборот репликами то есть мы должны иметь в третьем суде Лидер и tcd кластера для отслеживания подобных противоречий ну и соответственно также попасться баз данных в этом случае они уже виртуальные в прошлом варианте это прям железки конкретные тут мы имеем от 4 до 16 ядер оперативка 28 ГБ и объем от самых консервативных 200 Гб до 4 терабайт что считается по меркам достаточно много О Боже тут тоже должна быть анимация Ладно собственно говоря что мы имеем подытоживая главу про оперативный блок Я бы хотел в принципе указать характеристики которые мы в них вкладываем то есть первая характеристика которую мы хотели бы получить от оперативного блока это его изолированность каждый блок он изолирован никакие компоненты данные и так далее не коммуналятся не шарятся между такими же оперативными блоками клиентскими что там дает по сути мы имеем возможность независимой релизить версии микросервисов планово раскатывать изменения мы не имеем никакого взаимого влияния в части перформанса и блок так он зависит от наименьшего количества сторонних переменных так скажем очень легко воссоздан то есть мы можем просто его клонировать вторая характеристика которую мы закладываем его это легковесность блок содержит только свежие данные по сути это кэш клиентский в клиентских шортах мы не хотим чтобы там хранилось всякое барахло там только свежие данные хранятся и старые соответственно ротируется А что там дает помогает иметь базы которые ограничены ограниченного объема а управлять такими данными базами данных значительно проще Ну и деньги которые мы платим за непосредственно аппаратную составляющую всего исходя который имеет аппаратную репликацию что опция которая является национальной достаточно дорогостоящий мы можем аккуратно это все настраивать является быстрым то есть мы допускаем высокую нормализацию данных в этом слое она дает возможность иметь некий тюнинг запросов в случае когда приложению не нужно пересобираться для того чтобы мы смогли вмешаться в его взаимодействие с базой данных то есть мы можем не ждать здесь сейчас релиза предложения мы можем иметь Костыль так скажем по фиксации по запроса и благодаря тому что у нас нормально реализованная структура мы обладаем функциональной ссылочной целостностью вернемся на нашу архитектуру блока что просто вспомнить из чего мы состоим состоим из оперативного блока архивного слоя и все остальное на самом деле не является частью нашей АЭС и отсюда мы приступаем к путешествию в то как у нас устроен архивный слой опять плохо что тут нет анимации но суть в чем А я не просто так раскрасил в два цвета на самом деле полочки с архивным слоем Дело в том что он представлен двумя решениями это текущий Golden Gate текущее решение в виде годы гитовых реплик и нашим собственной разработкой виде клиент БК плеера то есть Господи нет ничего что же за функции Мы вкладываем в архивную стой Зачем нам нужен мы могли бесконечно просто расти в оперативных блоках Там просто закидывать его железом и каким-то образом выживать то есть первое что мы храним исторические данные в архивном слое помогает облегчать оперативные блоки второе архивный слой является источником для аналитических платформ сбера то есть мы снимаем аналитическую нагрузку с оперативных блоков вообще вся аналитика крутится на архивных данных архивный блок дополняет работу резервных клиентских блоков и Он участвует перераспределении нагрузки между блоками про каждый из этих функций мы поговорим как в контексте текущей архитектуры то есть голодный-гитовой так и в контексте символьной архитектуры то есть в контексте целевого решения архивного слоя для тех кто работал с Golden картинка будет достаточно понятная мы имеем активное плечо верится мастер сервера в оперативном блоке там поднят экстракт он осуществляет захват изменений необходимых нам объектов пакует их в trail-файлы два независимых пампа отправляет каждый свой этот сот каждый свой центр изменения в каждом технологической площадке стоит база данных со своим собственным исходы и поднятым репликатом который поехали по функциям архивного блока текущей реализации Ну собственно говоря что значит хранит исторические данные Это означает что каждый платформенный сервер сервис на самом деле знает watermark ротации своих данных то есть в момент когда ему нужно обратиться за своими данными дальше Вот Ремарка он сразу лезет в архивный слой То есть если он понимает что оперативном блоке как правило у него хранится хранится данные всего лишь за неделю запрос за 8 дней автоматически пойдет соответственно в одну из архивных баз данных а выбор данных происходит при помощи корректно с конфигуренной gbc строки то есть там фейер обратился в первую и получился обратился вторую минусы которые сейчас мы имеем каждый платформенный сервис который хочет иметь что-то в архивке и начать ротировать данную оперативном блоке должен подготовить под себя архивный слой то есть принести скрипты с конфигурировать возможно потом регрессировать тестирование проводить с учетом конфигурации голодные дальше это Господи неправильно то что сам платформенный сервис имеет непосредственно доступ к активному слою помощь gbc чтобы gbc не является гибким с точки зрения взаимодействия то есть мы не можем на лету сменить архивную базу данных нам обязательно нужно передиплоить его приложение далее архивный слой является источником данных для аналитических платформ сбера что имел ввиду тут аналитический платформы сбером Ее называем фабрика данных очень любит работать с данными клиентами Сбербанк онлайн по понятным причинам у нас большой трафик и реально есть что построить с наших данных по сути сейчас происходит при помощи etl процедур которые раз какой-то период данные забирают фабрики данных и наша и механизмы переключения сформирован таким образом что в одной базе данных на самом деле нагрузки платформенных компонентов и фабрики данных никогда не пересекаются То есть если мы работаем в платформе платформа работает с первой банкой и теле всегда будет смотреть на вторую и в случае если он стоит всего лишь одна то мы отдаем приоритет платформу сервису и телесе Подождет минусы Ну как минимум мы должны подготовить представление написать итиль и следить за планами выполнения запросов этой теме это всегда геморрой скажем так и представление которое мы имеем они имеют свойство разваливаться при релизе платформенного компонента и существует определенное отставание то есть фабрика данных наверняка не имеет актуальную версию данных То есть она там вот за этот конкремент который вытаскивает данные и имеет лак дополнение работы резервного блока Вот это самое интересное тут опять же должна была быть анимация потрясающая К сожалению придется как-то это Все описывать без анимации в случае недоступности клиентских блоков мы принимаем решение о том что нужно обязательно переключиться на резервный блок исторических данных резервном блоке на самом деле нет И мы должны отображать какие-то сценарии требуют этих исторических данных для этого мы идем в архивную базу данных так как нет никаких механизмов ни проверки версии данных В текущей архитектуре не нативных средств подогрева этих данных из архивного слоя на самом деле не можем работать с архивной репликой оперативного блока в readride режиме Мы работаем исключительно в ridonal-режиме То есть если мы решим все-таки поменять что-то в архивном блоке что мы не делаем то оперативный блок никак не узнает о том что эти данные изменились поэтому вынуждены возвращать Все изменения в родной блок клиента то есть вот есть специальная платформенный компонент который понимает инкремент который был совершён клиентом за время работы в резервном блоке и он возвращает все эти изменения в родную базу данных Какие минусы мы тут имеем на самом деле самый важный минус которым мы тут имеем это нарушение изоляции платформенного клиентского блока по сути резервный блок должен знать от топологии всех других блоков потому что в него для того чтобы переждать условный Шторм может прийти любой другой блок первое второе десятое может прийти в резервный блок соответственно он должен иметь возможность потом вернуть эти данные в нужную резервный блок в этом случае становится таким монстром Который знает о топологии всех блоков владеет всеми jdbc ресурсами этих блоков всех баз данных и поэтому у нас происходит усложнение резервного блока добавление новой шарды всегда приводит к тому что мы пересматриваем в принципе решение резервного блока мы должны добавить все ресурсы этого блока и так далее то есть нас резервный блок становится очень усложненным плюс нарушает все правила изоляции далее следующая функция перераспределение нагрузки между блоками случается Так что блок становится перегруженным по тем или иным причинам там особо допустим молодые клиенты начинают пользоваться определенным сервисом или мы не учли каких-то тенденций которые должны были учитывать и происходит такие события когда он приходится отливать данные из оперативно из одного блока какой-то другой как правило в новый То есть мы создаем целиком новый блок со своими 500 микросервисами со своими базами данных со своей архивной база данных репликой и вынужден каким-то образом переносить исторические данные именно по этой доле клиентов происходит это как правило полурусным миграторами что те люди которые писали когда иммиграторы могут себе представить какой-то ад особенно когда дело касается 10-5 миллионов клиентов помимо того что тебе нужно написать мигратор который должен учитывать всю специфику клиента Сбербанка онлайн Ты должен в том числе иметь возможность отката и тут откат также является некой сценарием реверсив реверсивным работам мигратора но еще с каким-то доп механизмом очистки всех данных после себя такие минусы все что я писал выше на самом деле касается исключительно текущего решения от которого мы всячески бежим который нас не устраивает чем больше блоков становится тем отчетливо мы себе это понимаем целевым же решением в части архивного слоя будет клиент БК плеер это наша хранилище распределенное которое мы сами разработали дальше покажу его архитектуру теперь за то чтобы данные попадали в архивные слои отвечает непосредственно само приложение так как символ является хранилищем плоской структуры сам платформенный компонент должен каким-то образом упаковать данные Либо это будет произойдет какая-то Джейсон нормализация либо будут хранить кидать данные в сыром виде но отвечает за них теперь сам в рамках транзакции с локальной оперативной базинкой что же такое себул по сути это распределенное хранилище которое состоит из десятков а в будущем и сотен шард с особенностью в такой что мы имеем клиент сайт балансировку на самом деле все клиенты Знают куда какую шарду ему сходить за теми или иными данными Так что представил попасть одной шарды и технологический стек из которой строится в принципе более детальная архитектура себула Из чего состоит для того чтобы понимать в какую Сколько в принципе у нас шарт есть в Промышленной эксплуатации в архивном слое Для клиента мы должны иметь некий координатор который бы отдавал всегда актуальную карту шарт То есть каждый раз когда что-то меняется в шорте всем потребителям об этом помещаются и все приложения имеют актуальную карту шарф этот момент также себу состоит из соответственно самих шарт каждый шарда представляет из себя представлена клиент адаптером это приложение Java это Spring Boot это кафки это подгрессовые базы данных и райтеры Reader и которые каждый работать со своей потресовой базой данных как же происходит чтение и запись себула чтение происходит непосредственно сам клиент адаптер То есть все приложения знают адреса всех рент адаптеров то есть они обращаются в клиент адаптер говорят Дай мне пожалуйста вот этому ключу эти данные всех ридеров которые у него есть самый не нагруженный и соответственно эти данные и соответственно отдает конечному потребителю теперь как происходит запись запись со стороны потребителя происходит напрямую в кафку то есть мы кладем данные в кафку в четырех экземплярах в двух отсюдах в двух центрах каждый Райтер слушает собственный топик и пишете изменения в подгрессовых базу данных то есть запись происходит непосредственно в кафку а чтение через клиент адаптер и мы имеем четыре копии одних тех же данных в шарде то есть факторы препликации шарды у нас равен 4 теперь по всем функциям архивного блока мы пройдемся уже в контексте новой архитектуры Теперь мы с точки зрения хранения данных не должны хранить исторических данных не должны готовить архивный слой мы не должны нести что-то в дистрибутиве типа конфигурации актуализировать и так далее мы должны готовить под себя инфраструктуру Потому что слой является единым и всегда можно к нему обратиться хватало места для записи и простой понятный интерфейс который положит Дай работает далее То что архивный слой является источником данных для фабрики тут мы хотим просто подписать фабрику на наши изменения условно сделать пятую копию наших данных и научить фабрику слушать эти данные с каким-то набором фильтров которые мы бы также Им спускали тут мы имеем что нет больше никакого лага это универсальный подход который сразу готов При появлении новой шарды и слава Богу больше не существует никакого прямого gbc коннекта в базу данных со стороны фабрики данных далее как изменения претерпел претерпела работа в резервном блоке по сути теперь резервный блок имея нативные механизмы подогрева Что это значит Это значит что если данные не обнаружились в базе локальной мы Обращаемся все за ними и прямо вытаскиваем их в локальную базу данных то есть мы знаем подогрев то есть при недоступности оперативного блока мы переходим в работу в резервный там полноценно работаем с той же самой копией данных и после того как мы выйдем из этого режима в оперативный Блок Мы уже ничего не обязаны возвращать в этот блок получается так что больше резервный блок не знает ничего топологии клиента топологии блоков ничего не несет в себе видит там дополнительных джиби-си ресурсов чтобы возвращать данные и так далее мы упрощаем принципе резервный блок и по сути грань между резервным блоком и оперативным полностью размывается оперативно становится обычным блоком резерв становится обычным оперативным блоком с точки зрения перераспределения нагрузки тут тоже Все очень просто случай когда у нас есть определенный набор перегретых шарт мы создаем отдельно новую и нативные инструменты подогрева этих данных при подаче нагрузке то есть мы выдали новую базу данных выдали новую оперативный блок создали перевели на него нагрузку допустим 3 миллиона клиентов которые мы хотим снять все компоненты понимают что у него под ногами Нет на самом деле данных и они начинают ходить в себу спрашивать наверное данные У тебя есть говорит Да есть он говорит он дает их обратно в шарду он их актуализирует в локальных базах данных и нагрузка соответственно снимается тут я хотел просто рассказать о том какой факт объем А какие объемы в архивном слоем в принципе говорим то есть сейчас это по факту порядка трех петабайт данных как правило Эта история клиентов то есть вся ваша история всех клиентов Сбербанк онлайн Мы храним храним с 2010 года в целом мы о вас все знаем И ничего не удаляем то есть реально архивка существует с данными 2010 года и 2025 году мы планируем как бы оседлать данных в этом смысле все остальные состав остальных данных конечно более консервативный профиль Это продукт и остатки настройки клиентов аватары адресная книга клиентов справочники справочная информация и конфигурация всех блоков которые работу работу оперативном слое тут также должна была быть анимация и подытоживая рассказ об архивном слое Я хотел просто семантически так сказать объяснить что мы вообще вкладываем в этот архивный слой при построении первое то что должен быть надежным это высокие настраиваемый фактор репликации то есть мы можем любое количество на самом деле этих базинок в каждой шар 10 было иметь добавляя просто копии накавки ставя еще одну еще один Райтер со своей базенкой делать пятую седьмую десятую копию этих данных благодаря надежному слою хранения мы способны в принципе начинать удешевлять наши блоки про удешевление Я поговорю на последнем слайде что имеется Под таким удешевления вторая характеристика это что слой простой То есть он использует компоненты которые он использует они все представлены в типовой конфигурации без усложнений То есть это подбросы стендалоновские там нету никаких дополнительных расширений которые мы используем и так далее То что мы как бы понимаем нас есть большой опыт работы с таких системах это есть очень много переменных от которых зависит каждого релиз Мы скорее уходим от этого то есть мы минимизируем риск при обновлении ПО уменьшаем вариативность отказа И самое главное что мы делаем в этом случае мы унифицируем набор аппаратных решений то есть мы можем очень простыми понятными для нас серверами схd без особых сверх опций от масштабировать наши архивный слой третье то что хранилище является универсальным хранить можем там хоть сторис хоть аватары аватары уже Джейсон файлы и так далее То есть широкий спектр видов данных единый подход к взаимодействию с ними И последнее это ивеншли консистент подход который нам дает возможность что по сути он назначает но означает что мы не ждем пока во всех репликах этих данных окажутся реальные данные мы считаем что данные записаны после только они попадают в кафку то есть Ок откатки для нас говорит о том что мы по факту запись провели и дальше как там будет распределено Мы у нас есть гипотеза что все будет хорошо вот мы архитектура строим именно подходе в части архивного слоя то есть мы быстро пишем и так это все-таки синхронная запись я могу опускать любой компонент этого себула без реального влияния на производительность на производительность доступность и так далее я могу опустить Reader и так далее половину координаторов могу потушить и работоспособность никуда не денется возвращаемся к удешевлению блоков пусток мы получим под ногами реальная масштабируемая хорошее решение виде архивного слоя надежная Мы отправимся в путь удешевление наших оперативных блоков что он по сути хотим сделать Мы хотим сделать так чтобы каждый клиент Работая в своем блоке работал всего лишь еще и в одном соде в одном дата-центре то есть мы идем по пути моно цодов это так называем то есть блок представлен всем своим аппаратным обеспечением в одном дата-центре благодаря тому что у нас есть все механизмы перераспределения нагрузок которые нам дает сибул Мы в случае отказа каждого любого из этих блоков на слой маршрутизации можем перенаправить перераспределить нагрузку то есть соответственно отказала одна баночка один блок мы на уровне маршрутизации просто взяли Этих клиентов по миллиону раскидали по другим банкам тут конкретно представлена конфигурация в трех центрах но также может быть сделанной на четырех на пяти все вопрос всегда стоимость и в целях которые мы преследуем Дело такого монстра всё Спасибо друзья у нас три минуты Возьми у меня микрофон а это только на вопрос Привет Спасибо за доклад Привет У меня вопрос я так понимаю сейчас себу частично у вас внедрен и часть данных все еще живет на старых культуры Вот именно архивные условия А тогда вопрос про архивный слой вот у вас есть много операционных блоков в каждом своя база Как вы разделяете их внутри архивного слоя также как под каждой операционный блок делаете отдельную базу куда дублируется данные каждый оперативный блок имеет свою свою пару архивную базу данных со своим железом Да это прям скажем оперативным блоком правильно ответ на это был вот там есть вот там есть Да здравствуйте А подскажите еще раз Для чего используется в архивном слое легационная база данных Почему не использовать кавку Она же умеет хранить данные что Какую функцию выполняет именно после в архивном слое Ну Дело в том что нужно работать таким образом то есть вы не можете из сказки вытащить по необходимому набору ключей данные которые хранится все более Ну это по сути данные которые так или иначе из оперативный блок попадают в архивку то есть та же самая история операции только в Киеве Кафка в этом случае исключительно мессендж брокер который помогает сам асинхрон Ладно я по-другому попробую используется и винтовые хранилища для того чтобы можно было заново перепрыгать события тем самым восстановить конечно то есть мы можем потерять целую базу данных и за счет какой-то другой Мы выбираем базу данных и с нее можем копировать исторически в Новую Или допустим мы масштабируемся на 30 Добавляем еще одну базинку мы выбираем мастер-классёнку из неё копируем в то есть snapshot реальное хранилище если вот вопрос допустим который вы сказали можно использовать саму кафку Она же Ну то есть точно также масштабируется красиво сможете восстановить состояние своё используя кавку именно для клиентского запросов Да по значению конечно нельзя использовать возможно может быть можно от них отказаться не знаю Нет нам все данные все более они так или иначе клиенту привязаны мы ходим именно по профилю клиента то есть мы должны прям по идентификатору клиентов вытащить данные то есть ключ определённый в которой лежит в базе данных по нему Спасибо не вижу Добрый день Иван Спасибо за доклад А мне интересно почему вы в первом варианте до того как изменили архитектуру прилетели фабрику данных использовали инкрементальную ATL а не логическую репликацию например Дело в том что конечная приемник он либо не хотел поддерживать эту репликацию Либо мы нам было сложнее Именно таким образом захватывать данный плюс все равно у вас есть проблема в том что позволяет более глубоко заглянуть в случае чего допустим Если есть гэп какое-то на фабрике данных Они поняли что данные были достаточно плохими запрошу-ка я снова за ту историю тот диапазон в случае если не сможем То есть через два года мы не запросите те же самые данные Но ведь во втором случае когда вы получаете данные сказки Вы решаетесь абсолютно Так для этого создаются определённый механизмы взаимодействие Дай мне пожалуйста тот диапазон данных по своему обычному API этот диапазон данных и до ссылка также будет работать используя нативные механизмы себула по Дай пожалуйста данные вот по такому типу будет работать Спасибо будьте добры Иван Спасибо большое за доклад было очень интересно Вот хотелось бы немножко уточнить Насколько я понял основная фишка миграции вот на так сказать на другой вот типа архивного слоя носи было это то что вы добавили кавку Да как промежуточный слой между базой сделали несколько реплик И как вы сказали вот мы считаем что данная записаны они просто положены в кафку А все-таки вот неужели не может быть таких ситуаций Что по какой-то причине у нас консистентность не состоялась и данные не были записаны Вот как вот такие случаи могут обрабатываться Ну как минимум У нас есть в локальной оперативной базе данных тоже копия данных только в революционном виде то есть мы же пишем Как в оперативку так и в архив откидываем в любом случае есть такой отдельная структура В вашем случае Вы имеете ввиду что Кафки по каким-то случаю по каким-то причинам лежат прям Оби в обоих содах вот это имеется ввиду саму базу или в сами кафки запись не прошла в базе если в базе не прошла то мы Ну если во все четыре базы данных не прошла запись но мы не сможем актуальные данные отдавать клиенту То есть он продолжит работать со старыми данными в оперативном блоке все четыре базы данных Ну такое конечно может быть что они отказали но мы должны рассчитываем Мы тоже не рассчитываем представить что с пенсионерами в России произойдет Да и плюс есть оперативное хранение оперативная база данных которая не позволит Ну то есть в случае недостаточно архивного слоя это где-то 30 процентов сценариев которые затрагивают Сбербанк онлайн вы все равно сможете перевод совершить сможете посмотреть баланс актуальный и так далее тут мы просто говорим про исторические данные которые вы не сможете вытащить из этих баз данных вот и всё и финальный остальной в кулуарах и остальное в чатике что на практике происходит при переключении оперативного слоя оперативного блока на резерв то есть допустим оперативный блок какой-то у нас падает мы принимаем решение что нужно переключаться на резервной вот в этом случае у нас все данные допустим лежат все более их нужно постепенно подтягивать они подтягиваются но тем не менее занимает там какое-то время как метрики приседают при этом чтобы пользователи ощущают Ну во-первых они не по всем клиентам сразу подтягиваются они подтягиваются только только по запросу клиента если клиент воспользовался функционалом которому потребовалось потребовались данные все были только после этого он их подогреет в блоке если клиент занимается чем-то другим сборе мы все будут ходить не будем просадок в этом случае вообще сейчас не существует То есть получается то что при отказе оперативного блока в целом все Булл справляется с нагрузкой на чтение да А вопрос Какие преимущества ва конкретного оперативного блока в этом случае по сравнению преимущество Да ну как минимум есть приснилось волка такое высоконагруженная отказы устойчивое хранилище которое мы очень верим и считаем что данные там с ним будет все хорошо плюс при поломке оперативного блока он способен справляться с нагрузкой вопрос Зачем тогда нам дублировать хранение данных внутри оперативного блока потому что большинству разработчиков проще работать с реляционной нормализованной структурой которую мы же раскладываем мы берем джейсоне когда восстанавливаем мы ее раскладываем в нормализованную структуру и как минимум это упрощает ситуацию в миграции То есть сейчас Допустим все привыкли работать нормализованной структуры мы сейчас говорим работать с киевелью они так не могут то есть мы сопутствующим образом делаем механизм который умеют из один нормализованной нормализованного структуру раскладывать эти то есть мы в принципе продолжаем давать возможность работать с нормализованной структурой второе Ну то есть у нас есть полноценный функционально слышная целостность некоторым разработчикам нужно там внешние ключи и так далее То есть ты не сможешь реализовать в киевери все-таки плюс абсолютно не все платформные компоненты работают все более у тебя есть платформенный компонент который исключительно работают с оперативной базой данных и ничего не откидывают все Булл все были лежат история операции в основном это конфигурация блоков справочники и так далее а все таблички типа там сессионных данных которые надо очень быстро обновлять актуализировать их статус они продолжают работу оперативном блоке оперативный блок он нужен и для ряда платформенных сервисов он всегда останется как бы вот единственным вариантом где они будут хранить свои данные вот и всё то есть для Таких сессионных данных они при отказе блока просто пропадает однозначно происходит переход клиен та то есть отказывает у вас сессия разрывается Вы снова входите попадать уже в резервный блок и там снова создается сессия по ней происходит какие-то изменения и так далее кому подарим книжку за лучший вопрос друзья махните руками кто задавал пожалуйста Вот кому книжку подарим таком месте уж одна книжка одну надо выбрать одного кого-то вот я молодому человеку из Яндекса после вопроса Мне прям очень понравился да начал и закрыл Да называется эмоциональный интеллект там нету Тебе тоже спасибо большое"
}