{
  "video_id": "82CX8qxv_-Q",
  "channel": "HighLoadChannel",
  "title": "Хэши в S3: как мы ускоряли прокачку трафика / Олег Кошовец (Mail.ru Cloud Solutions)",
  "views": 1240,
  "duration": 1860,
  "published": "2020-04-14T10:49:11-07:00",
  "text": "собственно всем привет меня зовут олег певец я работаю с сегодня расскажу вам про то как мы ускоряли прокачку трафика в нашем объектном хранилищ с 3 у доклада также есть альтернативное название как молодая неопытная команда из пяти человек полтора месяца воевала с суммой собственно ну начнем немного про себя кто вообще такой я простой backend разработчик ncs последние полтора года там работу и все это время я занимаюсь поддержкой развитием из 3 перед тем как я расскажу про то какие проблемы перед нами встали как мы их решали давайте немного расскажу про то как устроено наше хранилище мы вам с строим следить за последними трендами технологии войти поэтому ничего удивительного что у нас написано pearly вот в качестве хранилища метаданных об объектах пользователях access ключах картоха целях вообще всего мы используем тарантулы очень много талантов любимых умен эксплуатировать умеем готовить короче не можно радоваться и используем также есть сам старридж где хранятся пользовательские объекты в общем случае это куда более сложная штука чем просто очень много машин с дисками но в рамках этого доклада того достаточно и в качестве терменируют его слоя какого-то простого роутинга сср сессии мы используем engine x собственно проблема однажды к нам пришли наши менеджеры торжественно сообщили что файлов маршала бака заливается достаточно медленно ну насколько медленно ну из название доклада понятно что мы говорим про 30 мегабайт одного соединения является ли это проблемой вообще скорее нет чем да однако в рамках задачи общей которые перед mc сам видел ускорение бэкапов это становится важным моментом узко backup ускоряет везде и мы не стали исключением собственно как надо заливать файлы но задача была поставлена очень просто заливать файлы надо сильно быстрее никаких конкретных цифр просто парни пожалуйста в спорте но собственно чем и почему мы приступили давайте рассмотрим как заливается файл в наше хранилище собственно тут все довольно просто запрос приходит на яндекс engine экспортировать нашего кривого демона демон ходит за метаданными в наши тарантулы проверяю это цели проверяет policy проверяет cars и много различных проверок когда все в порядке все проверили берем идем старридж и начинаем проливать наш контент собственно когда контент про лиц успешно мы ходим тарантулы обновляем метафора на эту информацию о новом успешном залитом объекте отвечаем в яндекс успехом а яндекс возвращает успех клиенту что в этой схеме может тормозить ну на самом деле тормозить здесь может абсолютно все что угодно вот и в большинстве случаев нас тормозит и на клиент у нас всего лишь два процента клиентов способность заливать в нас файлы со скоростью превышающие хотя бы 15 мегабайт в секунду однако сейчас мы говорим про бэкап и backup стабильно упирается в наш наш 3 мегабайт секунду они льют довольно быстро собственно как узнать что это тормозит но мы берем нашу на 6 ч средам добавляем на нее нагрузочку как следует из дефран дома и собственно смотрим за тем кто кому то неплохо первым и ну как вы может может догадаетесь плохо становится и на пир лу он начинает уходить сотни подсыпку когда другие компоненты не так сильно замечают возросшую нагрузку хотя конечно замечают собственно если тормозить демон неплохо бы провести какие-то бенчмарки понять что конкретно в нем тормозит изучить этот вопрос собственно немного про bunch марки мы их не проводили потому что сделано в принципе так все понятно у нас уже есть некоторые известные факты и на горячую голову были приняты некоторые решения о фактах первый код нас асинхронный написан он поверх фреймворка и не event он обеспечивает асинхронность поверх session и библиотеки либо и мы давно уже его используя мы давно знаем что любой код который мы пишем на не ивенте для перво для работы сетью аналогичный код написан на си стабильно работать три раза быстрее соответственно но из этого напрашивается один простой вывод во всем виноват 1 вот как бы мы это дело лечить ну понятное дело если прокачка в перле тормозит мы берем прокачку 1 переписываем полностью носи это довольно стандартный подход четко мази припиши на насилие будут потрясающие тогда прилечь наверх это не будет тормозить нас и мы достигнем невиданных страстей боб заливки трафика собственно решение на горячую голову принято цель ясна методы понятно и уходим в себя на 2 недели переписываем прокачку возвращаемся мы ускорились был бы очень странно если бы мы взяли перловый код переписали носи получили замедление как сильно ускорились очень хороший вопрос задаю вы себе сам вот примерно вот так это процентах если чем да получается из этого всего что перо то конечно виноват но совсем чуть-чуть бенчмарки помните говорю про то как мы их не проводили вот на этом этапе солнца понятно что идея была очень сомнительная кажется стоило было посмотреть внутрь демона изучите его повнимательнее они просто снова каких-то старых догадках и задумках как работает прокачкой собственно есть перловый демон снаружи выглядит очень просто он открывает 1 socket читает в него в другой sockets сторож пишет все просто есть ли смотреть что происходит три демона внутри демона постоянно происходит огонь и бедняга 1 постоянно постоянно считает очень-очень-очень много хэшей зачем нам читать так много хэшей ну на самом деле кашин мы считаем для того чтобы ну обеспечить правильную работу а ps3 и немного для себя сейчас конкретнее значит от всего проливаем его контента в нас от всего мы считаем х sha-256 для того чтобы проверить и страшную подпись также от всего проливаем его контента в нас мы считаем md5 чтобы записать его в я так объекта ну в с3 каждый объект должен содержать и так это md5 сумма от контента этого объекта вот это все про стрaшнa часть но в прикол еще мы для себя считаем ш1 с некоторые солью потому что у нас собственно сторож он hard bass он основан наш одних и шах секретной солью который вам конечно же не скажу вот хэши очень много на самом деле есть интересный факт от с3 поддерживает две версии авторизации v2 и v4 так вот в авторизации версии в 2 не нужно эти хорошо 56 всего контента правда долгое время мы это делали вот сейчас не делаем уже и собственно это первый полезный факт с этого доклада если вы где то используйте ис-3 то при заливке файлов можете использовать порт подпись версии в2 и скорее всего заливаться у вас объекты будут чуть быстрее правда ребят из амазона де паркете тут подпись но планируете прикинуть в июне следующего года но это уже другая история собственно насколько все плохо но при заливке файла все просто катастрофически плохо 97 процентов всей работы на циpкa демона котором проводят это работа по расчету хэш суммы что эта ситуация делать ну надо очевидно посмотреть на то как мы считаем хэши с помощью чего мы используем библиотеку перловку дайджест в какой-то степени можно сказать что это стандарт языка ну кавычках когда-то надо же было в корень языка потом правда и вынули но собственно это самый популярный способ расчета хэшей заперли ее внутри написан на си собственно тормозить вроде бы не должно и что можно в этой ситуации сделать можно предположить что до дживса имеет сильную реализацию ну не самую хорошую соответственно все что нужно сделать это найти лучшую реализацию принести к нам и получить желаемый прироста скорости и зажить счастливой быстрыми bacopa my что мы искали в какие критерии во-первых никаких перу первым примите шум потому что хэши этой математика первых с математикой дружит очень плохо только чистый си вот просто работа должна быстро что нашли нашли много чего искали в том числе библиотеки которые необязательно поддерживают весь необходимый нам на борт и шей вот вещи про buncha ли их на разных теплушках цифры здесь особо не интересно и самое главное что он здесь есть это то что open с цель реализация поверху панель показывает лучшие результаты относительно вообще всего что там есть собственно берем об ан ссср в котором себе в рот это довольно простой и быстрый процесс однако ускорение прямо кардинального мы не получаем хочется все еще сильнее мы продолжаем поиски и вот мы нашли ее int уловы библиотеку ecaille расшифровывать как on the range . или rational обрели больше всего в названии конечно же привлекается его сочетание сторож acceleration что они пишут сам про себя они пишут что предоставляет набор оптимизированных низкоуровневых функций которые нацелены на приложение по хранению это очень нас будоража потому что кажется что в кои-то веки что-то написали специально для нас нам не нужно писать что-то самим собственно ну чем библиотека может быть настолько хороша если почитать ридми которую нее довольно короткие там написано следующее рекомендуется поддержка нас на определенной версии и наличие выйти 512 что такое от этого x 512 собственно это такая процессор на я фича которая реализует синглом старшему типу дейта содержит себе 32 регистр по 512 bit каждой довольно неплохо для тех кто не значит кастингу страшному типу да это я сейчас объясню в картинках представьте себе что у вас есть потрясающая современная электрическая мясорубка с кучей разных крутилок для настройки скорости режимов всего прочего это обычный регистр обычный процессор на регистр а теперь представьте старую дурацкую мясорубку который нужно придерживать рукой ручку еще крутить самостоятельно это символ регистр но один суть всегда в том что регистров просто очень много и у них ручки все склеены в одну огромную ручку которая который можно крутить так что все крутилки крутится одновременно вот соответственно если выгружать мясо по всем мясорубку то в принципе получать хочу немного быстрее собственно резюмируем вы 512 что так но регистров много регистр большие это чудо зверь уметь готовить на них ешь и собственно кажется что надо брать мы берем поднимаем virtualcz в x 512 начинаем проводить какие-то первые то по тестирования и как она на самом деле потрясающе хэши считаются очень быстро до пяти тысяч мегабайт в секунду на к некоторых конкретных и шах вот есть одно но хэши считаются неправильно они не сходятся да очень обидно собственно да как оказывается чудес в мире не бывает нельзя просто так взять алгоритм который должен считаться последовательно где каждый следующий шаг зависит от результата предыдущего как-то раз пихать его параллельно работающим регистром и типа сделать вид что все классно потрясающие сразу ускориться и на самом деле мы использование много нет а потому что мы ориентировались ним документацию она сигнатуру функции если функция вылет как будто то так как будто насчитать хэши ну возьмем попробуем собственно что мы использовали на самом деле штука довольно полезно кому-то из вас может пригодиться то что мы спали называется мультик ешь работа на следующим образом вот у вас есть входной поток данных он разбивается на потоки поменьше фиксированного размера все эти потоки собственно разгружается по этим параллельным 7 новым ллейном и после этого они считаются мо-ло-дец омолодиться мо-ло-дец а когда приходит время анализировать хэш сигнализируется все эти параллельные хэши потом хэши конкатенировать загружается в нормальную быстро мясорубку там она выплевывает новый кэш и собственно этот хэш и называется мультик шом соответственно например мульти хэш-код sha-256 он выглядит как hash hash адрес 56 он даже является чистым кэшем от какого-то контента но к сожалению не от того который был изначально собственно он прекрасно подходит для задач дедупликации для того чтоб просто какие-то уникальные идентификаторы по какому-то контенту быстро но к сожалению так уж вышло нам нужно считать правильные хэши мы не можем просто так проверь подпись по неправильному создаст нам это не подходит то что мы должны были использовать называется мульти буфер как он работает вот у вас есть эти linea на которых iso или меньше таких решил на нем не заводятся сущность называемая менеджер она контролирует распределение job of pop чатах и шейна эти войны и работаю как с каким-то своим утренним планировщиком на каждый поток данных который вы хотите обсчитать заводится контекст контекст отчетах сша и когда в поток поступать это данные вы берете буфер который получили заметить его на контекст контекст заметите на менеджер и собственно может так сделать не с одним контекстом их может быть много когда вы понимаете что например пора уже флешнуться когда уже пора что-то посчитать на менеджер ну вы отправлять команду flush он распределят полученный контекст и полей нам и они как-то что-то делала молотят не обязательно занимая все лайны потому что очевидно вы могли набросать не очень много собственно какие проблемы могут возникнуть при использовании мульти буфера ну довольно очевидно если вы привыкли жить по-старому что вы дали буфер там типа hashed и сразу же получили обновленный состоит своего контекста тону можно использовать это по тупому на контекст завели контекст получили буфер сразу же флаш 0 и сидни утилизируется и при этом 7 новый регистр работает медленнее чем обычные что ну как бы дает еще проигрыш по скорости также вас может погубить вашей же собственной жадности например вы очень очень очень хотите утилизировать все доступные лайны и у вас уже набралось достаточно контекстов и они в принципе готова флешнуться но войны вы заняли не всей например вы ждете когда поступит какой-то другой набор данных чтобы посчитать ваш хэш очевидно здесь нужно их искать какой-то баланс нужен какой то свой собственный scheduling над всем этим делом можно сделать по разному можно например вы получили буферный один контекст получили буфер на другой на 3 все они засоби чен ына менеджер и есть например на один из контекста в которой уже был за совмещаем поступает новый буфер вы флажки менеджер чтобы слюна сложилось и потом совместить и новый буфер на контекст к сожалению буфер который за сами чинно контекст нельзя апдейт по камере мы не нашли нормального способа предоставленных библиотекой блеск кишки не хотим вот если у вас есть какой то очень быстро писатель который может заставлять один контекст фашиста слишком часто в принципе можно крутить какие-то свои искусственные буфера тоже как-то наполнять и когда например один из буфера переполняется флашей менеджер со всеми контекстами которые успели набраться вариантов множество с какой работать лучше нужно смотреть на конкретном конкретно продакшена конкретной нагрузки на конкретных профилях собственно да как иисус догадаться мульти хэш реализуется поверх мульти буфера и секрет его скорость заключается в том что он не страдает от жадности потому что он просто утилизируют все лайны у него нет такой проблемы также у вас могут возникнуть сложности с архитектурой например допустим вас есть какой-то мастер процесс у него с довольно здоровый пул worker of и например на новый connection который прилетает и но должен быть обработан он выделяет 1 маркера и спала же какие здесь могут быть проблемы один worker обслуживает один поток данных и для того чтобы утилизировать симптомы регистры вам нужны потоки данных с других маркеров а это нужен такой-то шарин и стоит между маркерами ну короче проблемы могут возникнуть собственно к счастью это первое кажется проблема которая у нас не было наши worker обслуживают много connection of параллельно и такой проблем возникнуть не должно как все это дело работает на самом деле довольно неплохо в качестве константной ли не представлено скорость подсчётах и шейна open sl это кстати скоростью мегабайт в секунду еще и эта скорость для всех и шей которые мы считаем как я уже говорил много регистр работает мне для необычных и при использовании всего лишь одного лайна при не оптимальном использовании мы проигрываем по скорость о-па-на с целью однако при использовании уже хотя бы двух line of мы получаем выигрыш и скорость подсчётах и шеи растет линейно дальше что не может не радовать собственно да а вы x 512 довольно редкая фича встречается далеко не во всех процессорах которые скорее всего у вас про ее еще нет как кстати у нас счастью ребята из интела позаботились и об этом они реализовали подсчеты hash сумм и на других симптомах фичах таких какого x2 в xss я здесь собственно представлены графики как это все работает зависимость количества вейнов до вейнов там меньше но просто читал 16 чтобы было видно в масштабе сова x 512 если мне не изменяет память то кажется там выигрыш начинается уже хотя бы с 3 занятых line of собственно вопрос который мучает наверное всех как это чудо работать вроде я скажу честно она вроде не работает вот на самом деле не потому что концепция плохая а потому что мы еще не доработали стабильность своей обвязки перловой на 1000 библиотекой мы знаем некоторые корда кейсы когда мы словим sick of old мы сейчас работаем над их фиксом мы пишем свои тесты мы изучаем как нужно schedule ить флаши менеджера в зависимости от разных нагрузок ведь вопрос изучаем чтобы сексе джингу их продал приступить уже более-менее готовыми какие выводы из этого всего можно сделать собственно в первую очередь проводите бенчмарки пожалуйста не будьте как мы не тратьте две недели просто так потому что время деньги но самое страшное мы тогда очень сильно был демотивированы потом скорость это необязательно си си плюс плюс горазд внезапно даже такое как первый может давать приемлемый перформанс если просто приготовить им немножко правильно и немножко по хитри с кишками да потом стандарт языка стандарт опять же в кавычках это не всегда хорошо опять же живой пример из нашего первого мира даже сша считают хэши медленно опанас цель быстро этой другой есть лиц японии но все традиционно используют дальше процессор на и fitch оказывается работают и у простых людей я лично долгое время считал что процессор ные фичи и оптимизации на них это удел бородатых мужчин которые подсчет ядро и алексея миловидова вот у нас в команде нет ни тех ни других но как-то внезапно процессор на и фичи кажется помогает и нам экзотические оптимизации иногда работают очень хорошо собственно при оптимизации ваших приложений есть какой то более менее плюс-минус стандартный набор рецептов что можно сделать чтобы его ускорить скрутить буфер здесь накрутить буфер там подкрутить сескапиль том как поменять настройки файловой системы набор стандартный я мог перечислю не все но внезапно экзотический оптимизация например процесс иных вещах дает очень серьезный boost производительности и самое главное помните перо конечно виноват но совсем чуть чуть спасибо за внимание так вопросы и то есть еще последний слайд о боже это это же amazon вас реализован горячий холодные данные у вас во всяком реализован лайфхака реализованы все верно да у меня вопрос просто как это вот вот в этой структуре есть еще какой-то крон который крутится и смотрит на смотрите на самом деле как я уже говорил мы очень любим тарантулы в том числе мы их любим или за то что это не просто база данных а это полноценный сервер приложений собственно вся логика палачей клан и по любой какой-то ну работе с данными которые ведется от типа фоном само собой оно у нас реализуется прямо рядом с данными прямо в tarantul а мы в принципе уже давно пишем код влажный то есть из пульт ранту не прост как базу данных типов быстрый кэше и все такое у нас там прям честно логика и на самом деле работать рядом с данными действительно очень удобно и ну короче нам нравится то есть тарантул он дергает какой-то mover который движется данные из горячего стороны на холодный назад в офисах и которые мувы с одного стороны из горячего в холодный сторону нас пока нет у нас есть в цикл который удаляет объекты вот но в общем и целом да тарантул он содержит в себе информацию объекта в себе информацию о сиквелах он просто посмотрел взял данные рядом все круто супер спасибо еще вопрос вы раз всем спасибо за доклад в названии 300 мегабит в секунду откуда взялось это прогнозируемая получается выигрыш в ваш и откуда ну почему вы думаете что это единственное узкое место которое вам надо устранить какие ожидаемые результаты того что вы сделали до 300 мегабайт секунду собственно мы их пока нигде не получили и действительно как вы верно подметили это оценочная цифра ну у нас были какие-то формулы расчета того что может получиться если будет работать так и сяк вот почему мы считаем что узкое место именно в перле ну возможно если мы выкатим эту оптимизацию то даются новые узкие места но в рамках первичного бенчмарка когда мы дали нагрузку и первым сильно возрос а остальные не очень понятно что 1 то слишком узкое место вот собственно поэтому он очень сильно тормозит в данной схеме вот скорее всего после этого конечно же будем искать и другие узкие места и возможно даже найдем и скорее всего даже пофиксим вот я я не ответил на ваш вопрос да ну там спасибо за доклад на вопрос такой вот это in the sky библиотека наук ан source надо то есть визуально мы нашли то есть на то понимаю вот фича вы x500 именно там заложено да то есть да да там много там они предстают много функций для расчета на разных вещах вот мы вытаскивает из первых возможно даже за консорциум если нам будет не учит это за нашли но она как уже собранный поставлять или сами собираетесь сами собирать компилятор yankovski используя джесси ну просто я помню там есть по моему какая-то бага там если там 83 и линкера своеобразные то есть там какая-то бага которая отключает от этого x 512 но собственно кажется мы на ней не наткнулись потому что строительство 12 мы ускорение получили если бы она была отключена то график вот этих классных не дадут просто вот именно иногда бывают проблемы в сочетании компилятора и linker ну короче спасибо что сообщили возможно когда ему на них случайно наткнемся пока не натыкались что не может не радовать спасибо так кажется там где-то еще был вопрос о его плитам так все сложно здравствуйте скажите пожалуйста не рассматривали организм не рассматривали бы вопрос возможно считать хэши не на циpкa она г.п. да вопрос такой в принципе поднимался собственно в чем очевидно минус такого решения придется очень сильно обновлять свой железный парк вот и причем ну закупать довольно дорогой железо конкретно под одну фичу сначала попробуем конечно же выглядеть все-таки стабильный работающий код который читает на цикл будет не удовлетворять попробуем gpu может быть на нем какие-то другие минусы но до такой вариант рассматривался определенно здравствуйте спасибо за доклад интересно а вы не думали подойти к проблеме с другой стороны вот вы считаете 3-х ш-ш 166 md5 а если переделать архитектуру чтоб считать один хэш его везде использовать да это было бы очень здорово но так уж выше что api amazon s3 обязан начинать как минимум два вот плюс мы считаем своих h1 солью для того чтобы заливать файл на сторож на самом деле страншо выйдем она тоже читать этот хэш и мы обсуждали отказ от того чтобы стать его самостоятельно но решили этого не делать для того что потому что мы сверяем этих ешь и когда мы посчитали когда там 40 посчитал мы сверяем на всякий случай потому что всякое бывает там пакетик потерялся ну короче может быть страшно хочу ответить про gpu как было сказано в докладе последовательные расчеты hash-сумму очень плохо параллелях огпу это про параллелизм 1 а другой помедленнее поэтому вы их слова я фича позволило скажем так с одного ядра поднимать много но при этом все также иметь быструю скорость для одного соединения gpu просела бы сильно не живо по несессера даже там еще вот это там есть украшающий а вот скажи пожалуйста на графике у тебя был практически линейный рост при увеличении количества line of а вот этот график он как был получен это честный замер на железке с вот с этим с этой фичей или дочиста это честно наши данные мы честно сами замеряли ты понял про виртуалку с вот этой вот до 112 они исключают то что при увеличении но фактически параллельности у нас прямо вот совсем-совсем линейный рост без какого-то скажем так закругление прям подозрительный немножко ну на самом деле не очень потому что все таки уэйнов у нас 16 на 16 войнов мы прощаемся и судя по всему им тыловые либо иметь довольно хороший планировщик если задача например поставлен не слишком много задача может быть поставлено больше чем количество воинов и она как тоже по своим внутренним алгоритму начинает их растаскивать вот мы в принципе еще так прикол считали этому при увеличении количества параллельных считаем их и шей но на самом деле цифры не удивляют потому что ну как бы получал их лично я сам все видел своими такими глазками еще одна дорога чите где сравнении с да вот вот это вот просадка очень интересная до на самом деле этого уже и как бы она воспроизводится из раза в раз причем только на вы x2 я могу только предположить что это какая-то специфика работы внутреннего менеджера внутренних структур распределения внутренним scheduler а конкретно совы x2 собственно для того чтобы понять почему так происходит неплохо бы наверно покопаться в кишках особенного кода который предоставляется вместе с ecaille вот но мы этого не делали потому что мы пока если вы просто выпить 12 и это просто замерили до кучи суть ясна спасибо просто спасибо за доклад у меня как раз вот тоже вопрос по предыдущему графику мы проводили какой-то средние в зависимости от размер объектов данте до 100 об этом сказать короче экспериментальным образом был установлен размер блока пример буфер который хорошо закидывается на контекст очевидно что закидывать по 8 бит это очень оптимально накидываешь много потом flash вот для вы x 512 там просто экспериментально установили что 64 килобайта кажется довольно неплохо уважаться и собственно эти 6 4 килобайтах мы имели то есть мы кидали бомбам почти 4 килобайта до факт если использует блок и других размеров в графике будет много другими но этот график скорее показатель ность нежели ну возможно достал приложить зависимость размера было бы но что поделать могу как не пересчитать вам скинуть в личку пишут как раз интересно как себя поведет вот график на маленьких объектов да не вопрос placement он код еще лежит виртуалку еще не упала спасибо могу почитать напишите только в личку там где в конце telegram был тем как ведь отвечу вся вов раза больше нет тогда выбери пожалуйста лучший вопрос мы подарим подарок а там еще выбирать надо было блин а я все это время отвечал ну наверное наверное лучший вопрос это вопрос про gp ушки потому что попал в точку прямо то что обсуждали то что смотрелось поэтому надо человек гпу получите приз он мне ничего не будет вам тоже будет подарок у части мне нужно походить на камеру поработать да спасибо всем за внимание собственно если у вас какие-то еще есть вопросы там та зона обсуждения будет вон там"
}