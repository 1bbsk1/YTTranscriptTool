{
  "video_id": "sm1P0lXsxgM",
  "channel": "HighLoadChannel",
  "title": "Coub: как мы строили аналитическую платформу / Михаил Табунов (Coub.com)",
  "views": 854,
  "duration": 2149,
  "published": "2017-04-10T06:12:32-07:00",
  "text": "всем привет меня зовут миша табунов я основатель и технический директор проект копку расскажу про то как мы строили аналитическую платформу на несколько миллиардов событий в месяц и с чем мы сталкивались какие были трудности как и были варианты этой системы а кто не знает что такое коп есть такие люди отлично сейчас расскажу коп это короткое зацикленное видео и наш сервис про это 50 миллионов человек каждый месяц смотрит эти короткие зациклена и видео 400 миллионов раз а делают они это следующим способом у нас есть три основных продукта на самом деле скоро будет 4 в продакшене 3 это наш веб-сайт мобильное приложение и встраиваемая player в социальных сетях там где-то еще а все вот эти вот наши продукты посылают и себе информацию как люди их используют делают они это посредством событий что такое событие в нашем понимании событий это вот такой вот же сон в котором два обязательных полей и куча необязательных с абсолютно не знаю там разных два обязательных полей это тип события которые уникальна для каждого из типов событий на условно вот здесь вот на примере видно что это событие в этом лент подводит это событие приходит когда пользователь заходит на сайт у него подгружается его лента скобами и браузер отправляет вот это вот событий на букет префикс web означает что это произошло на веб-сайте все остальные продукт соответственно имеет свой префикс и таймс темп когда это произошло ну и тут еще есть там три дополнительных поля которые там несут всю эту информацию разное а у всех этих событий разная структура данных то есть событие с iphone приложения с имеет там не знаю какую то одну структуру за android другую структуру набор полей заранее неизвестен а когда у нас выезжает новая фича в продакшн в этой новые фичи зашита какая-то своя статистика как и там будут поля который понадобится продукту который выкатывает эту фичу не известно заранее а клиент выглядит следующим образом вот здесь вот на примере у нас java-script это простой буфер в которой накапливать событие раз в 3 секунды этот буфер чистится и отправляется прямо вот пачкой на сервер условно кодируется это все jason jason кодируется в большинстве 4 для того чтобы избежать проблем с разными древними старыми браузерами которые имеют свое понимание насчет из кемпинга специальных символов и все клиенты которые там в айфоне в андроиде flash player они приблизительно похоже на этот но они очень примитивно ничего там сложного нету а зачем нам это все нужно зачем весь этот огород во-первых очень хотелось бы понимать что там люди по ту сторону монитора делаются нашим продуктом и понимать это кроме как увешать весь продукт событиями датчиками какими-то и чем-то еще там не представляется возможным и вот эти события мы используем для понимания того как наш продукт развивать как и у нас есть проблема какие решения нужно принять для того чтобы компания росла там развивалась и так далее а есть конечно есть готовое решение этих готовых решений на самом деле очень много есть там не знаю несколько популярных вот здесь на примере ну kissmetrics mxp на это вот как раз такие штуки для анализа ну вот этих вот событий от ричарда то этот типо типо как ходу ну приблизительно то же самое самая история а главная проблема с ними-то что на больших объемах данных это становится дорого или очень дорого ли очень очень дорого несмотря на то что все готовы давать скидку это цены от 10 тысяч долларов 10 тысяч долларов это вполне себе сумма чтобы нанять разработчика дать им серверов там не за оборудование так далее и сделать аналитическую систему такой код как она же именно нам а это первая проблема вторая проблема то что все эти системы статистики считают какие-то метрики по своим внутренним алгоритмом которые зашиты у них под капотом и достоверно мы не точно не знаем как они выдают нам эти отчеты и мы на порывались несколько раз на всякие нюансы подсчета когда вопрос у нас была разница в цифрах по одной подругой статистики мы в чем дело потом выяснялось там что одна считают по уникальному другая считает пони уникального вот оно как бы разница написано это какой-то там 37 страниц и документацию которой никто никогда не заходил а третья проблема то что эти системы или дает ограниченный доступ к сырым данном или до этого 8а сырые данные нам нужны для того чтобы быть уверенным в том что любой отчет который вообще существует природе мы сделаем потому что какие-то виды отчетов там как бы в этих системах уже зашит и а мы хотим новый и непонятно что делать тому же сырых данных нет и как быть тоже неясно ну вот и зато это быстро и просто берешь заодно заходишь на сайт регистрируйся вбиваешь карточку все работает система у тебя уже есть а и мы решили писать свое на самом деле писать свою всегда очень страшно потому что так у тебя есть решение но конечно там со своим проблемам она уже работает решает ваша задача а тут писать свою а вдруг а вдруг это все вообще там не работает а вдруг это потребует не знаю там куча ресурсов кучу людей куча серверов но зато имеет свою систему мы можем решать вообще все проблемы которые только есть в бизнесе потому что она своя mail как бы под себя допилим и трудно представить такую задачу которая который было бы невозможно решить потому что опять же мы сами разработчики эта система мы сами там повернем как нам нужно и пусто как мы решили что пишем свое у нас появились первые требования что же вам все-таки нужно и главное требование было сделать что-то быстро и просто потому что надо было быстро проверить имеет вообще смысла это не имеет может быть там не знаем мы ввязываемся в разработку новой базы данных нужно было делать простые счетчики типа посчитать количество событий этого типа ну и делать примитивную аналитику фильтровать события какого типа там по нескольким факторам по например например по двум полян там или по трем делать distinct и самое главное что в принципе так как мы делаем быстро и просто если ничего не получится то ничего страшного и вот архитектуру первая система один сервер работалось очень примитивно просто стоял и джинкс он проектировал вопрос в лоб коллектор так называемые сейчас объясню что такое это и лог коллектор писал эти логе налог сторож короче простого говоришь на лоб коллектор это была программа по моим на языке кожи она просто вот она эти событий которые приходили чуть-чуть вида изменяла поставляла там какую дополнительную информацию например записывала там с какого региона пришел человеку из какого браузера и клава это влог сторож налог сторож вот в этой системе это бы просто диска там то в какой-то структуре файлов и директорий все лежало и дальше мы с этими логами делали следующее был руби worker он брал этиологии загружала в позы gres а в возрасте была вот такая вот структур данных очень простая табличка в не был 3 поле тип время когда случилось и все остальные данные лежали в фастове тогда еще по мне было а можно будет же себе вот и был бы один простой яндекс и мы вот эта вот система запустили в продакшен за две недели это но достаточно такой сжатый срок запустили в продакшен у нас уже были тогда готовы ну вот эти вот сервис и мы использовали микс павел поэтому прикрутите и ко всем продуктам не составляло труда потому что эти события не уже есть и нам просто нужно отправлять их ещё в одно место запустили поняли что в принципе те рабочие пользоваться можно и в принципе она проблема какие-то наши которые мы перед ней постель начала решать именно у нас была проблема что например мы не захочу происходит на плеерах потому что player это очень много данных это очень дорого и очень долго в общем мы поняли что принципе иметь смысл дальше с этим делом возиться мы об этом не знаю собрались обсудили чу как и сделали кстати вот как она работала работала очень медленно и очень ненадежная и очень и масштабируя но в принципе как хотел бы прототип и потому что опять же это но больше эксперимент чем он рабочий система помогла понять что же мы хотим и мы сделали как бы список требований в них оказался вот что данные на самом деле важны потому что как только по ним бизнес начинает делать какие-то отчеты там на на них операция то когда у бизнес этих данных нет они начинают ругаться но это естественно потому что как он принимать решения если мы остановимся на данных нужен latency тоже очень важно на самом деле потому что если в продакшн выезжает фича какая-то она например супер провальная и если у вас в этом вся система там не знаю день или 00 час то целый час у вас продакшне будет fitch которая там не знаю работает плохо и latency тоже очень критично ну а наевшись там плюсов и минусов предыдущий архитектуры все сказать что мы долго ждать не будем и давайте сделаем вот так чтобы нажимаешь кнопочку работает быстро и это на самом деле то же очень важно ну и последнее пожелание которое такое очень расплывчато и хотим сами не знаем чего строить сложные группировки нетипичные отчеты анализировать поведение возвращаем асти так далее а и мы пришли вот сейчас я расскажу тут есть две части в этой системе первая часть это запись и хранение logo вторая часть это собственно аналитика в frontend это как мы это используем фронтэнда выглядит следующим образом то вот их несколько там фронтэнда сейчас их четыре они в раунд робби не на каждом из vantin дав развернутая ну такие ну и джинкс джексон стать лоб коллектор пролог коллектор который раз расскажу попозже чем делает и logo плоды лоб коллекторов локальный кэш пишет эти логе logo плода загружает раз сколько ты уже готовых там файлы на amazon и мы используем amazon как такое persistent на и хранилище потому что она достаточно надежное и не очень дорогое и все все все данные за все время хранятся на амазоне а дальше вот эту вот аналитическая часть скачиваете logis amazon загружает этого в какую-то базу данных и в которую уже ходят как раз пользователь аналитики смотрит как что работает на лоб коллекторах на фронтах мы используем на джесс но джесс показывает себя очень хорошо продакшене реально ни одного простое за полгода по вене но джесс у нас не было несмотря на то что как бы многие говорят что технология сырая странная так далее на нашем примере на наших условиях это не так и но джесс это очень просто очень быстро в плане потому что все разработчики знают java-script ну все в по разработке знают java script а те кто не знает его выучивают приблизительно за дня два и вот эти вот фронтэнда на них выполняется очень простая логика добавляется страна то есть прогоняется через гэб и пешня пользователь добавляется вот-вот события страна город там что-то еще и он ставит 4 cookies эти четыре cookies нужно для анализа поведения дальнейшего 4 cookies это время последнего визита номер визита а номер страницы введите и сколько всего человек посмотрел страниц визит эта группа группа просмотров страниц которая закрывается через 30 минут неактивности пользователя анализ вторая важная часть на самом деле самое интересное потому что логе записывать в принципе это дело нехитрое а вот анализировать их это но та еще задачка мы очень много чего попробовали протестили у нас был список опять же вот из шести пунктов что можно было бы теоретически взять как она как инструмент для анализа вот эти вот наши наших логов а их к тому времени был немного это был hadoop и hive рад shift vertica друид манга и под grease с его сторону про пузырь со стороны уже немножко поговорили и так как много мы написали опять же критерии выбора что нам все таки нужно на самом деле один из самых важно это простота эксплуатации потому что опять же нам не хотелось содержать специальную команду которая занималась только вот этим вот поддерживать читать документацию писать плач и форки и так далее но и скорость работы естественная ну это наши бизнес требования и к простоте эксплуатации ну понятно просто поддерживать и если что-то ну например я не знаю если бы она хранила данные в каком-то магическом бинарном формате на диске которые нигде не задокументировано не хотелось бы вот в это все вляпываться там как-то пристать к киту парсеры ну типа не заработал мы просто взяли данные с диска вытащили и вот у нас получилась такая табличка сейчас пони пройдемся прямо по всем пунктам вот по этим двум критериям мы ставили оценку одного до пяти и ходок hive получили суммарно три я не знаю как бы hadoop hive не production решение абсолютно а кожи тут был доклад про hadoop в буду и как бы все что-то говорят это правда и очень сложная архитектурная система для такой задачи она очень странно документирована постоянно какие-то релизы которые несовместим с предыдущей версии или там странно совместимы в общем по сравнению например с production ими продуктами это просто небо и земля дальше раньше вт vertica простота раньше с vertica требует четкую структуру данных вот типа как табличка в ней такие тополя если бы мы выбрали решение которое ну а надо она хорошо работает но нам бы пришлось тогда отказаться от гибкой структур данных всех событий и всех бы разработчиков которые разрабатывают нам клиенты заставили бы как бы заранее говорит что все события только определенной схеме а если какая-то схема будет новое то вы об этом говорите это был бы целый процесс это нужно поддерживать и очень не хотелось бы в это вляпываться опять же если можно но зато они очень быстро работают redshift и vertica и как бы для аналитики реально классно дальше продукт такой друид есть droid это такой open source кластер как раз для real-time обработки событий но опять же не production рейде супер быстро работать все в реал тайме но не понятная документация на сколько я знаю полторы вы инсталляции в продакшене а это значило бы что мы бы были первые и все бы doppel его лесами и вот у нас остались два позорься ванга на самом деле мог здесь оказалась полу случайно я вообще не рассматривал потому что у меня был имидж такой на ум он вообще и стерео такой такого странного продукта историй про то что мы записали в могу она не работает и не понятно чем делать и так далее в общем под grease работает достаточно быстро но пришлось бы писать свой фреймворк для arma придется если он где то есть готовые то есть типа я хочу есть большой datasette я по нему хочу выполнить например сделать фильтрацию конкурентный потом собрать результаты но это можно сделать по зависти но это потребовало от нас каких там усилия так далее осталось манга и мы решили с манго рискнуть посмотреть как она работает и к тест показать что достаточно хорошо на самом деле умом gdb просто понятной архитектуры но это конечно вещи очень относительны и для каждого но мне показалось она очень хорошо документирована профессионально документировано на любой вопрос есть ответ комьюнити опять же хорошо документирована как она хранит данные на диске что происходит когда она выполняет запрос все это есть a плюс у нее есть и григоришин фреймворк который дает нам инструментарий для построения сложных нетипичных отчетов каких-то странных там и при этом всем она проходит по нашему требованию работать без обрабатывать события не навязывая четкую структуру данных всем не меняя вот этого бизнес требования и первые структуру хранения но как бы совершенно очевидно и логично это просто взять сделать мою коллекцию туда вот эти вот ситжес он который к нам приходится запихивать и как выяснилось где-то 10 миллионов лет 10-15 миллионов записей запрос и начинают выполняться но чем медленнее и начали разбираться как бы хотели от него отказываться там уж принципе 10 15 миллионов записи это не такой этот сет потом поняли прошлом каждый раз сделать агрегацию потому что нам как бы нужно график людям вывести она группирует данные и тогда мы поняли что как бы чтобы не хранить сразу в группе ровном виде пришли к вот такой структуре до нах в этой структуре данных все события хранятся в таких наборов по минутных то есть условно в одном в таком документе есть поле events и в нем сидит кучка события для более глубокой аналитики и вот таких вот агрегатов сильно меньше потому что они группируются поминутно один одно событие 1 минута 1 документ единственное тут стоит оговориться что у манги лимит на один документ 16 мегабайт а событий у нас в минуту вы хотели больше чем 16 мегабайт им это обошли тем что просто если бога не дает вот события новый документ записать мы ловим это exception просто создаем второе такое же и первому ставим is full true и будет понимаем что больше мы туда не пишем и все итого у нас 101000 вот таких вот документов за день это там сколько 3 миллиона в месяц и с такой структурой данных она очень быстро делает примитивные агрегаты ну такие штуки поляне за выбрать все собой как количество событий за день это очень простой запрос на маленьком достаточно дата сети но и мидаса быть какого-то определенного типа и загружается это все в волгу одним запросом absurd который тоже работает достаточно быстро вообще практически не тормозит хотя когда загружать слоги но это достаточно ну как бы затратной операция про железо и нагрузки у нас все работает на двух машинах у них 128 гигабайт памяти 4 терабайтный рейд и экспериментальным путём мы выяснили что оптимальная конфигурации мально и количество нот ноги 9 штук на машину соответственно эта коллекция сортируется и каждый из вот этих вот 18 мангу not хранит свой кусочек всего в системе где-то миллиард 200 событий месяц которые ну это число растет в секунду это где-то 1000 запросов а сейчас там восемь или десять миллионов объектов в этой коллекции вот этих вот агрегатов и есть и говорить про гигабайт это это в месяц где-то 600 гигабайт теперь право front-end и собственно как встроенную анализ во front-end это такой простой рубин раз приложение которое в котором есть все вот эти вот события как кто-то там продукт аналитик заходит или я заходит там можно отфильтровать эти события сделать какую-то несложную группировку и ну посмотреть график ничего такого сложного абсолютно нет и все остальные запросы которые возникают с течением времени ну как бы если просит что-то там часто какой-то отчет сделай мне пожалуйста тут и тут и тут а например по рекламе или там почему-то еще ну просто мы берем вот эту систему дописываем этот отчет туда вот запихиваем мы говорим потом что-то меня больше не просидела туда нажми кнопочку все будет вот такая простая штука да еще немножко про аналитику на самом деле самая лучшая инструмент для аналитики тексель как показывает практика потому что все равно рано или поздно появится тот отчет который не запрограммирован системе и на это случае у нас вот вы front-end и есть кнопочка выгрузить в excel он тебе дает какие-то сага реагирование данные открывает их тебе в экселе а ты уже дальше там чего хочешь ты делаешь накладываешь там из разных систем и так далее как мы все используем ну например решает это как какие вопросы решает ну например сколько у нас загрузок player украине вчера или сколько у нас за загрузок плеер которые не знаю пользователь ждал больше пяти секунд тоже очень важная метрика используется как используется в продукте например рекомендации на сайте опираются на данные которые хранятся вот здесь и раз сколько то там а не синхронизируется посылает запрос в эту статистику получает данные о том куда люди жгут и дальше нас на сайте отражается эти рекомендации а как часто в неделю люди пользуются лента или куда пошли пользователи фейсбук попавшую страниц кого всякие поведенческие метрики которые тоже нужно как-то анализировать и притом они бывают совершенно странные непонятные и наш практику показывать что мы заранее никогда не угадаем какой какой отчет попросит менеджер минусы естественно в этой системы полного минусов и самое главное - что когда данные не в памяти ну например не влезли потому что это с большой все очень очень медленно потому что к дэну как бы она берет это все читает с диска на тем не менее это не такая большая проблема для нас потому что мы намеренно 1 ограничили выполнение запросов по данным за последний месяц есть какие то данные нам нужны ни за последний месяц а это бывает прямо очень редко то это какой-то отдельный сценарий вот вторая проблема то что такая структура данных она как бы годится для рисования простых графиков и агрегации каких-то но абсолютно не годится для анализа поведения пользователей например и когда нужно смотреть или как это там выводить паттерны как что люди делают чтобы потом сделать еще что-то абсолютно не подходит и это проблема и мы ее как бы решаем отдельно ну и манга не можешь сделать большой агрегация там 16 мегабайт мана магический 16 мегабайт лимит на результат агрегация вот команда команда backend вот всю эту историю с магами и всем таким же занимался 1-я плюс там part-time помогал им помогали кто-то но разработчики клиентов 1100 долларов аренда железо вот этих вот двух машин это риск и долларов в месяц за amazon оставить то есть суммарно получается если не считать труд то 1500 ну короче не очень много сильно меньше чем хотят это эти решения а ну естественно планы планы глубже интегрировать эту аналитику в продукт сделать продуктовый wahler ты то есть например какие то количество ошибок загрузки на плеере выросла в несколько раз чтобы как бы мы какие-то метрики для себя продуктах вывели потом за ними следили и узнавали о наших проблемах первые ну интеграция с гугл докс настоящий real-time чтобы не ждать 5-минутную как бы хотелось бы и больше отчетов все ваши вопросы пасибо здравствуйте меня зовут максим спасибо за доклад я хотел бы уточнить у нас был слайд где вы оценивали простоту и скорость различных решений месте просто то это достаточно субъективным сбрось можно как поверить вот интересно как вымерли поможешь продукт совершенно разный тот же дэлио если он заточен конкретно под real time event аналитику там англо это более общая такая штука и но у нас было вот проблема анализировать но и скажем так был список проблем каких-то например посчитать количество загрузок плеера на украине это кстати вот с примера дальше посчитать количество уникальных сессий на какой-либо там страницы этой а вот так по памяти короче был список запросов каких-то даже не запросов а задач которые мы решали на каком-то то сети сырых данных то есть мы брали вот эти сырые данные загружали их там было чуть 30 миллионов события они все были за день что ли что-то такое и выполняли смотри как она работает то есть типа у меня это не за есть знакомые у них вот такой класс столе говорю суши типа давай попробуем вот быренько сделаем вот и короче говоря вот эти все оценка скорости это тоже на самом деле субъективный метрика потому что для кого-то одно быстро для другого для другого другое но в принципе мы как бы не на глаз это делали а просто брали там проводили эксперименты записывали их результаты и все это есть как бы вот это вот оценка скорость это то как эти продукты решить нашу задачу и но они все годны для решения этой задачи как бы друид он не только для real-time вот нравится спасибо за доклад а вот такой вопрос тень кажется что ты с 4 очень сильно в тот момент когда стал хранить агрегаты и если боя после того как ты сказал что а давай хранить агрегаты ты вернулся бы в начало и поставил бы такую задачу и рассмотрел бы еще раз все продукты в принципе для этой задачи сошла бы любая база данных но вот исходя из этой таблички на самом деле нет нет я сейчас поясню вот смотри может быть я не правильно тебя понял значит изначально ты говоришь что я храню сырые данные логе фактически до каждое событие это отдельная запись потом ты выбираешь мангу и говоришь блин чо-то не срастается давай я буду хранить при агрегаты таким образом изначально одну задачу заменил принципиально другой принципиально другой потому что за сутки у тебя получается услугу летом сотни тысяч записей и если у тебя получились сотни тысяч записей то у тебя уже и другие datasette и и другие требования если ты вернешься назад и говоришь на это но какой бы ты вот из этих всех взял бы для охранения агрегатов сушину с агрегатами упадут я вот не делал такого просто его так сразу я не скажу на просто вот но подождите вопрос именно такой не кажется тебе что вот именно посередине выбора вдруг произошло произошло резкое изменение первоначальной задаче просто за счет того что ты стал хранить агрегата нет не кажется сложнее я объясню задачу было не в том чтобы упереться и хранить все события там типа отдельно задача была сделать решение которое будет работать и как бы агрегаты это часть этого решения агрегата плюс могут что-то еще все это все вместе решение вот опять же из этого списка я не знаю что взять чтобы хранить игривой ты потому что они у них всех есть свои как бы недостатки исходя из нашей задачи вот а то что надо агрегаты но и что добрый вечер спасибо за доклад а я хотел следующий вопрос как я понимаю все эти данные которые вы получаете в итоге вы используете ли своих каких-то метриках и для рекламодателей либо но для ваших каких-то партнеров через которые вы планируете видимо романтизировать бизнес потому что на текущий момент я собираюсь слабо знаком с вашим продуктом поэтому их то спросить а каким образом вы монетизацию сейчас проводите и какая в планах опа на этом итог с технической конференции тихо тихонечко переезжаем на менеджер не здесь на самом деле вы просто следующий в том что сейчас как бы ну не видно монетизации и непонятно каким образом у вас например изменится нагрузка изменится ли метрики то есть теме-3 которые сейчас используйте получается вас просто выдают статистику каким образом у вас с каких платформах больше например загрузок ну это типа просто пример на самом деле мы эту штуку используем для того чтобы смотреть где как и отказы у нас то есть мониторинг еще используется этот для много чего используется то есть касаясь вопроса рекламы я могу так boring сказать что она есть и она настолько хорошо что вы даже не видите сразу в мозг 25 кадром ну проект практически спасибо большое вот с такой системой это касаясь немножко вопросы там счетчиков и так далее мы ее используем чтобы ну чтобы понимать где проблема вот это вот главная главная задача и у нас настолько много этих данных что ну не мне совершают какие-то там безумные объемы вот упаду столько в день например сколько у нас в месяц боль ну ну больше хорошо но как бы ни как и готовых решений для этого нет то есть эту проблему надо было решать все равно и мы не могли оставаться вот на эти хостить решения потому что они там нас разорят при этом всем ну не разорят но это как бы было бы напряжена и при этом всем они не решают все задачи которые мы хотим то есть это рано или поздно надо было бы делать вот здравствуйте можно вопрос такой я обратил внимание вы промежуточно складываете все логии в amazon они рассматривали сразу вариант складыванию в эту же мангу а страшное что именно ну а вот если например кажется что все что говорят про мангу это правда и ну то есть генетически вы рассматривали не оживают на работе вас понимаем связыванием и но у вас же хорошо еще вот мне не очень просто понятен вопрос высказать там показали что 16 мегабайт на агрегацию но если мне память не изменяет то данная агрегация можно направлять в коллекцию и по идее там не ограниченный размер до можно прям вот точно правильно все можно и мы так и делали до проб как бы искал я горю вот как бы решение из коробки да там вот такие вот ограничения и ее даже можно обойти сказав манги каширы все пожалуйста файликом там как-то ну это решаемая проблема не критичнее спасибо за можно за настоящей а вот и сказали что манга достаточно нос немного данных в день 600 гигабайт расправе да и вопрос вот вы со старыми данными что делаете вы их удаляете ли как-то пока не удаляем вот сейчас мы приближаемся к этой проблемы мы ее решим тем что добавим наш кластер еще одну машину и все данные переедут как бы ришар дерутся то есть как бы я считаю что нам нужен хранить старые данные потому что у нас бывает вопросы когда а что там такое было вот венгрии что теперь там три миллиона пользователей и вот надо смотреть что там вот в июле было и и это как бы ну да есть такая задача"
}