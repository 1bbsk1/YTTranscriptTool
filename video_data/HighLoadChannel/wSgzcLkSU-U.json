{
  "video_id": "wSgzcLkSU-U",
  "channel": "HighLoadChannel",
  "title": "Таргетирование в МТС Маркетолог: ClickHouse, C++ и битовые маски / Алексей Петруняка (MTC Digital)",
  "views": 448,
  "duration": 2616,
  "published": "2023-01-19T05:55:18-08:00",
  "text": "всем привет спасибо что остались хоть кто-то я расскажу о системе таргетирования в мтс маркетологи как мы ее построили изначально на основе базе база данных cliff house как потом наткнулись на проблемой и на неразрешимой в том числе и в результате стали переписывать эту систему с на in memory движок на си плюс плюс с использованием битовых масок мтс маркетолог эта система которая позволяет рассылать рекламу и основными получателями рекламы являются абонента мтс а ну соответственно то где показывается эта реклама это мобильные телефоны обычно и основное отличие от увиденных вами других презентаций где это обычно баннерная реклама у нас это реклама которая раз ссылочная ее главное отличие в том что оно более интрузивные она отвлекает получателя от своих дел то есть это надо например эсэмэски ну соответственно есть система мтс маркетолог по адресу маркетолог mts.ru в ней есть менеджеры которые обслуживают наших клиентов это могут быть клиенты которые ну либо взаимодействует с интерфейсом в маркетолога либо даже не взаимодействует а просто общаются с менеджерами ну и соответственно есть разные клиенты есть внешне которые работают с нами через рекламное агентство есть внешний клиент которые работают с интерфейсом маркетолога есть внешние клиенты которые тоже через менеджеров работают и есть наше внутреннее клиенты внутри мтс и которым тоже нужно искать аудиторию и рассылать ей таргетированную рекламу ну у нас конечно есть не только таргетированная но я буду рассказывать как раз про таргетированную рекламу и соответственно как же создается рекламная кампания в мтс маркетологи есть следующие пять шагов таких крупных первый шаг это подбор аудитории по основным параметрам то есть это в основном демография другие признаки доход интересы этой потенциальной целевой аудитории на втором шаге дополнительная фильтрация с отбором аудитории которая возможна с кем-то контактировала на третьем шаге и это пересечение с белыми списками и либо исключения каких-то черных списков либо это исключение предыдущих уже проведенных рекламных кампаний затем наш клиент выбирает канал через который будет доставлено реклама ну в восьмидесяти процентах случаев это из смысле bms и затем и после того как выбран канал он уже загружает свой креатив то есть это либо текст со ссылочкой либо это ужас картинкой и тогда это уже не из м с а м м с ну либо текст для емейла и так далее дальше наш клиент выбирает даты когда я такая компания должна быть проведена и на последнем шаге создается уже конкретный сегмент из той аудитории которая должна будет получить нашу рекламу нужно сказать что на всех этих шагах которые идут последовательно мы постоянно пересчитываем охват то есть показываем тот охват который наш клиент получит в результате кому мы разошлем рекламу ну за исключением некоторых случаях которые я расскажу чуть позже как же выглядит архитектурно взаимодействие нашего клиента и сервисов внутри маркетолога когда создается рекламная кампания сначала наш клиент просматривает охват по таргетом он заходит на наш портал по известному адресу и подбирает по таргетом и каждый раз смотрит какой же охват получился после того как он посчитал охват он считается уже создает сегмент для рассылки сервисом который занимается и подсчетам охвата и созданием сегменты для рассылки у нас является теле таргет и это собственно ключевой компонент в таргетирование и да далее доклад будет весь про него по сути после того как охват посчитан и настало время для старта кампании менеджер дает команду на старт в шлюзы шлюза приходят в теле торги за этим сегментом то есть за списком получатели рекламы и наши шлюзы проводят рассылку ну очевидно что все данные от орбитах и списках профилей потенциальных получателей рекламы все лежат в какой-то базе данных с которой наш теле таргет взаимодействует и так первый шаг создание рекламной кампании эта демография на этом шаге наши клиенты подбирает целевую аудиторию по региону возрасту полу ну и на самом деле есть еще другие всякие шаги например уровень дохода пол возраст но пропал здесь уже сказано что но что то еще еще там есть но неважно главное что на каждом шаге на каждом клике нашего клиента в интерфейсе мы постоянно показываем новый охват и вот это вот ключевая первая часть которая холодная совсем потому что объемы данных у нас большие значит следующий шаг при создании этой рекламной кампании это может быть биолокация наш клиент может либо в одном варианте выбрать потенциальных получателей которые регулярно бывают в какую-то диапазоне он указывает время и рисует либо кружки на карте либо вводят адреса и соответственно подбирает радиус в этот момент мы точно также пересчитываем кто обычно в это время бывает в в этой зоне и соответственно показываем охват дальше интересы ну типичный пример это салон красоты они хотят найти себе клиентов они вводят слова красота и соответственно ищут тех кто и посещают салоны красоты и либо интересуются услугами точно так же наш клиент кликает мы тут же пересчитываем охват что же мы получаем какие данные для того чтобы это все посчитать 1 файлик который мы получаем ежедневно из big date и это файлик под названием teradata по названию база данных на самом деле из которой все это грузится значит в нем есть следующие поля идентификатор профиля email поддержка simp ушей и куча запретов вот эти запреты они задаются абонентами они говорят я не хочу получать рекламу псм с или я не хочу по интернету получать рекламу мы при создании наших рекламных кампаний должны это учитывать мы не должны их не рассылать не соответственно показывайте нашим клиентам охват среди тех кто запретил и 2 файлик этой locations в нем тоже идентификатор профиля и 3 идентификатора самых популярных у этого профиля и идентификаторы в базовых станций утренний дневной и вечерний это то что нужно для гео-локации да я забыл сказать что в гео-локации есть еще второй вариант это когда наш клиент нарисовал кружочек то что точно так же на карте или адрес но сказал я хочу найти и тех кто прямо во время моей рекламной кампании будет попадать в эту гиа зону и в таком случае мы точно так же подготовим сегмент во всем остальным таргетом и затем когда уже люди будут из этого сегмента входите в этот кружок на карте то есть подключаться тему к базовой станции которые есть в этом кружке будет происходить реклама им если это возможно дальше какие еще данные мы получаем почти каждый день но с каким-то периодом мы около 300 файлов получаем из big date и с целевыми сегментами которым аудитория может принадлежать возраст пол устройства мобильные наличие детей наличие животных и так далее и тому подобное и регулярно мы также получаем файл сотами то есть теми самыми la casa лойди которые идентифицируют базовую станцию и широтой и долготой их примерно миллион строк и так проблема нам нужно все эти данные которые нам даются куда-то сложить и как-то по ним быстро находить сегменты целевой аудитории оцениваете размер для того чтобы показать охват на экране и последнее это забронировать их для рекламной кампании бронирование заключается в том что мы стараемся не зав память абонентов и поэтому мы ограничиваем количество контактов с ними в календарный период и так вводные данные у нас есть примерно 100 миллионов строк который нам каждый день выгружают и если эти данные все складывать по всем признакам которые наш клиент будет искать аудиторию то у нас получится примерно 200 колонок в таблице и у нас есть всего четыре месяца до выхода в продакшен нашего продукта ну какое может быть решение можно попытаться все эти две двести колонок 100 миллионов строк сложить в одну табличку и построить индексы на все эти 200 колонок но очевидно что это не работает 200 индексов заполнить за приемлемое время построить невозможно есть второй вариант потенциально очень хороший это попытаться вообще всю in memory реализовать и искать но к сожалению у нас есть вот это ограничение про четыре месяца до выхода в прод и более того нас еще и маленькая команда поэтому этот вариант нам тоже не подходит ну и остается очевидный вариант колонны и база данных каждая из этих 200 колонок лежит отдельно и фактически методом грубой силы то есть без всяких индексов мы попытаемся быстро искать аудиторию мы посмотрели какие есть колонны и базы и выбрали клик house итак мы готовим табличку в клика асиф которые сложим все эти данные она у нас реплицирования на кластере в ней есть колоночки со всеми запретами которые установили есть город есть соты утром днем и вечером есть регион есть операционной системы устройства и есть порядка 200 колонок который содержит в по сути булевой признак принадлежности тому или иному целевым сегментом нашей аудитории мы эту табличку парте церу им по региону потому что большинство наших клиентов выбирает регион в котором находятся его потенциальные клиенты до свою очередь и сортируем по запрету smf почему мы сортируем по запрету эсэмэс очевидное если у нас 80 процентов рассылок идет по если нас каналу то за счет этого мы чуть-чуть ускоряем тем что отбираем только тех у кого этот запрет не стоит при запросах в эту табличку ну соответственно для того чтобы эти данные положить в эту табличку у нас есть приложение клик house in fort она собирает все данные в оперативной памяти при этом очевидно что данных очень много и мы вынуждены каждый вот эти из этих булевых признаков хранить по одному биту иначе нам их вообще никак не уместить в оперативной памяти мы подготовили это все данные в памяти собрались всех этих нескольких сотен файлов сложили в csv-файл залили в таблицу в клика усе и заодно мы туда подготовили еще свои словари для того чтобы делать с ними проверки тех же запретов на сегментах которые не из main таблица и после этого эта таблица заменяется моим и заменяются словари через символьную ссылку и так как у нас считается по демографии наш клиент на первом самых шаги выбрала регион и нам соответственно нужно посчитать тех кто находится в этом регионе обычный вскоре запрос в котором проверяется что регион совпадает с выбранным и плюс проверка что хотя бы один из каналов по которым мы можем рассылать рекламу не запрещен для рассылки и соответственно следующий шаг когда уже наш клиент выбрал что это будет канал сэм с этот запрос укорачивается из него пропадают проверки всех остальных каналов и остается только проверка канала с м с на том что нету этого запрета как мы ищем базовой станции наш клиент нарисовал на карте окружность и нам нужно найти какие базовой станции находятся внутри этой окружности ну очевидно и хранение этого но small темы по широте камал со мной по долготе и дальше у нас список базовых станций которые находятся в этих конкретных координатах мы соответственно строим квадратик вокруг этого круга быстро с помощью рейндже находим набор внутри каждого из этих мал темпов находим список точных координат проверяем расстояние до них из центра и если они внутри этого круга то соответственно мы их оставляем если они в нету пропускаем тут я пропустил второй шаг и перехожу на третий шаг создание рекламной кампании это исключение предыдущих рекламных кампаний но наши рекламные кампании когда проводится у них есть свои сегменты и очевидно эти сегменты мы их можем потом вычитать но соответственно в запрос который строит для подсчета и либо создания компании мы добавляем соответствующий под запрос который выбирает из таблицы сегментов эти сегменты которые находятся в списке и если у нас исключается мало рекламных кампаний то эти этот список мы просто засовываем сам запрос а если их много то мы вынуждены загрузить сначала во временную табличку с engine мимо реплика us и потом уже из нее делать под под запросам выборку идентификаторов сегментов которые нам нужно исключить следующий шаг и это собственно который надо обсудить это выбор дат на тот момент когда наш клиент выбрал да ты у нас уже появляется необходимость учитывать контактную стратегию то есть те самые ограничения по количеству контактов в месяц которые мы установили ну и соответственно как только наш клиент указал даты и указал канал перед этим мы должны снова пересчитать охват который доступен именно вот в эти конкретные даты и соответственно когда он сказал да создавая компания мы должны уже конкретные профили выбрать для рассылки изначально мы реализовывали контактную стратегию четыре контакта в месяц то есть именно в календарный месяц и эти 4 контакта возможна в любой из этих дней этого месяца в пределах этой рекламной кампании которая создается наше шлюза определяют внутри этой рекламной кампании когда же конкретно конкретному получателю будет доставлено реклама давайте посмотрим как создаются вот эти 4 эти с учетом этой контактной стратегии рекламные кампании как один и тот же профиль попадает в эти рекламные кампании и так первая рекламная кампания у нас создалась и профиль попал в нее 2 тоже третьи тоже 4 тоже а вот 5 которое у нас пересечь пересекает границы месяца январь и февраль в неё попасть он не может потому что мы не знаем когда конкретно произойдет рассылка если бы он попадал бы в нее то возможно что у нас состоялась бы 5 контактов в январе что недопустимо ну соответственно в шестую 7 8 рекламной кампании тоже всё хорошо этот профиль может попасть при рассылке есть 2 разных стратегии это равномерной рассылка и неравномерная рассылка обычно равномерно рассылку заказывают наши клиенты с той целью чтобы не перегрузить свои call-центры в колл-центр если будет поступать слишком много звонков подряд им будет это не очень удобно не соответственно они заказывают равномерную рассылку и при этом наши шлюза определяют что в такой-то день столько то будет получателей и примерно поровну и их распределяют по датам если рассылка неравномерно это у нас на 1 день по попадает магом максимальное количество людей но на второй день по меньше обычного дня и все ну на самом деле в первый день тоже может попасть мало если наш клиент создал рекламную компанию прямо сейчас и прямо сейчас я хочу стартовать вот у нас сейчас уже вечер очевидно что мы до дальний восток уже рассылать рекламу сейчас не мужу и более того мы уже за уралом там уже наверно все уже по времени нельзя поэтому у нас вот может сместиться часть рассылок на второй день итак контактная стратегия у нас есть проблема с ограничением контактов четыре контакта в месяц и у нас все лежит флик хаусе а в клик хаусе не транзакций что же нам делать но единственное решение мы не даем создавать рекламные рассылки одновременно за счет за счет этого у нас наши клиенты по сути вынуждены ждать когда же создастся рекламная кампания для другого клиента то есть все идет последовательно по одной но вот такая ситуация следующая проблема это то что на сегменты которые создаются нужно удалять они во-первых компании завершаются они не нужны во вторых могут создаваться какие-то промежуточные сегменты которые тоже не нужны их нужно удалять но клика вас как известно с удалением не особо дружит что же можно удалять быстро очевидно что самый быстрый способ удаления в клика оси этого дроп тайбл удаляем всю таблицу и и это очень быстро и соответственно решение ты таблица на сегмент складываем все сегменты в отдельной таблице но натыкаемся на следующую проблему звуки пар начинает тормозить дело в том что вузу гипера есть проблема с тем что когда в нем количество нот на одном уровне становится слишком большим он начинает их очень медленно искать и соответственно слишком медленно отдавать ответы к хаосу клика us в этот момент говорит о тайм-аут прошел мы сейчас переведем таблицу в редон ли режим и все и соответственно вставка в нее невозможно поэтому сожалению такой вариант оказался не очень как же можно по другому быстро удалять второй вариант это быстрое удаление партиции alter tail и друг парте шин по условию в котором собственный идентификатор сегмента указан мы можем соответственно делать партиции на сегмент мы их быстро удаляем тоже все казалось бы хорошо но проблема за кипером остается закипел точно точно также тормозит но чуть чуть позже это эта проблема просто отъезжая чуть дальше но и следующие варианты это alter temple de литвы это уже мутации это медленный процесс но к сожалению при приходится жить с ним если удалять каждый сегмент по отдельности отдельной мутации то это будет приводить к тому что у мутации будут копиться только вас не будет успевать их производить и в конце концов он просто становится он вообще ничего не сможет делать у него фоне фоновый все thread'ы заняты тем тем чтобы попытаться выполнить мутации результате финальное решение которое мы будем пришли мы собираем в матче запросы на удаление и делаем синхронной альт р т ы был де литвы то есть удаляем сразу помногу большими большими кусками это тоже модификация фактически всей таблицы с сегментами но она как бы хоть и долго но оно одно и она не мешает но не так сильно мешает клик хаусу как вот эти скопившиеся мутации при этому мы вызываем и это действие уже в синхронном режиме и долго-долго ждем пока все данные удаляться после этого мы следующую пачку пытаемся удалить следующие проблемы которую мы наткнулись это триггер и в триггерных рекламных кампаниях которые я приводил пример это когда вот кто-то входит нарисованную на карте геозон получается так что это уже больше похоже на классические рекламные кампании которые баннерные например где у нас и не сразу формируется вся аудитория она последовательно собирается соответственно это получаются мелкие частые вставки клика us но crack house их не любит он совершенно не любит мелкие частоты и ставки его надо собрать батч ну блок вернее сказать из хотя бы миллионов точек чтобы ему было совсем хорошо и тогда вставки будут быстрыми мы к сожалению не можем ждать пока для каждой конкретной рекламной кампании соберутся соберется такая большая пачка и поэтому мы вынуждены прийти к были к следующему решение постоянные сегменты то есть те сегменты которые формируются заранее на всю рекламную кампанию они у нас лежат в единой таблицы а вот сегменты триггерных рекламных кампаний мы все-таки храним в отдельных за счет этого то проблема которая включалась возникает при слишком частой вставки the many parts которая обычно ограничено 300-ми уже и у нас не проявляется и соответственно мы на нее не натыкаемся и можем проводить 3 гранной рекламные кампании сейчас я вернусь ко второму шагу потому что для него нам нужны совсем другие данные это данные по контактам для того чтобы найти например потенциальных клиентов своих конкурентов наш клиент может загрузить их телефонные номера либо именно отправителей смысле бы их сайты и соответственно он хочет найти свою аудиторию которая могла с ними контактировать потенциально для того чтобы делать такие поиски у нас цен на отдельные данные они к нам приходят из кафки из когда ты через кафку всего там три поля идентификатор профиля кастомный сегмент юид и это собственно идентификатор того что мы ищем мы не знаем уже что и дата когда эти данные последний раз обновились они к нам идут через кафку складываются в наш кластер мы храним эти данные из tp-link две недели и у нас в результате накапливается примерно 60 миллиардов строк что надо добавить когда мы только реализовывали вот этот функционал в клика усе еще не было поддержки сервера сайта дефекации а у нас все secure у нас kerberos и нам пришлось взять исходники клика уса и пропатчить их и собирать свою версию для того чтобы наша кавказ смогла таки авторизоваться через него и так для того чтобы проверить что проходили какие-то контакты мы добавляем запрос вот примерно такое под выражение с выборкой из вот этой табличке кастом сегмент соответственно с идентификаторами кастомных сегментов которые были переданы я точно так же если их мало мы добавляем непосредственно в запрос если их много мы их складываем в память и потом в табличку с engine memory и соответственно из делаем подзапрос что же у нас получилось в первом теле таргете какие данные взаимодействия значит есть у нас стиле таргет в нем в оперативной памяти лежит информация о всех торги тах которые выбирают наш пользователь есть вот эти мальте map для поиска суд по координатам он взаимодействует с двумя базами данных с mais quel им где лежит информации от орбитах и метаданные созданных сегментов из клик хаусом где у нас лежит лежат вот 2 вышеописанной таблицы main и koston сигнал также словари и по таблице бронирования на каждый канал коммуникации а все клиентское взаимодействие стиль итоге там идет по rest api rest api у нас полностью синхронной то есть все запросы должны укладываться в обычные таймауту для наших клиентов это ключевые особенности написан на си плюс плюс 17 до production of дошёл за четыре месяца 18 года контактная стратегия в нем было реализовано четыре контакта в месяц и все или запросы обрабатываются сент урону превращаются в линейные простые джейсон чеки довольно-таки сложное из quelle запросы каждый из которых очевидно обычно содержат какие-то куски из предыдущих запросов которые делались для того же клиента который подбирает себе целевую аудиторию и тут у нас после всего лишь года эксплуатации возникло новое ограничение это новая контактная стратегия не больше одного контактов 7 дней какая проблема была с прошлой контактной стратегии малов могло получиться так что у нас один и тот же человек мог получить 4 эсэмэски 31 января а потом еще четыре эсэмэски 1 февраля то есть 8 эсэмэсок подряд это уже раздражает соответственно не очень удобно очевидно что с таким новым ограничением один контакт день нам уже самим нужно рассчитывать уже на самом деле таргете в какой конкретный день конкретному человеку будет разослана реклама и посмотрим по тем же рекламным кампаниям в те же сроки как будут попадать будет этот попадать человек в те же рекламной кампании и так в первую рекламную кампанию он попал в 1 января во вторую он попал 9 в третью он попал 17 то есть нам нужно соблюсти интервалы в 4 он не может попасть потому что 7 дней еще не прошло с предыдущего контакта в 5 он попадает в шестую он попадает уже не свое начало из за того что предыдущий контакт был слишком близко ну соответственно в 7 8 аналогично с каким-то интервалом соблюдением этого ограничения 7 дней что с равномерной рассылкой у нас появилась еще новое требование что если у нас есть рабочий день у нас нем много часов для рассылки а если у нас выходной то в нем мало мы стараемся выходные дни дать людям побольше поспать и вечером тоже самое что утром что вечером поэтому у нас часов доступную для рассылки в первый день поменьше может быть и плюс в выходные не может быть поменьше и в последний день тоже может быть поменьше часов рассылки чем обычно соответственно нужно вот это вот распределение по дням сделать еще и с учетом доступных часов в эти дни ну и случай неравномерной рассылки то же самое нам нужно попытаться по максимуму разослать первый день и потом оставшихся разослать в оставшиеся дни очевидно что вот такая контактная стратегия уже те миску или запросами ну достаточно простыми которые строились в первом теле таргетинга нереализуемо здесь нужно делать много много циклов пуадо там пытаясь добить количество до того желаемого которые мы нарисовали вот на эту рекламную кампанию то есть мы хотим прямо вот добиться идеальной равномерности например и поэтому мы приходим к выводам по эксплуатации 1 теле таргет и натянув crack house на глобус мы таки запустили мтс маркетолог но к сожалению из вот этой описаны проблемы что у нас повторно много раз одни и те же делаются под запросы но они никак не кэшируются в базе данных sql база данных не подходит для сценариев обработки данных мтс маркетологи oklick house подходит для долгосрочного хранения не слишком частого поиска по большим объемом данных нам нужен движок с горя сохранением горячих данных в оперативной памяти и каширования нам нужно лук фри реализация контактной стратегии чтобы создающие рассылки клиенты и проходящие триггерные компании не мешали друг другу как хранить данные мы будем теперь очевидно что множество удобнее всего представим их в виде битовых масок соответственно каждый признак принадлежности какому-то таргету мы будем хранить в виде битовой маски какие есть варианты в си плюс плюс для битовых масок есть стадо бесед но не подходит из-за qantas так на из-за констант на го размера есть будда и на миг бесед он уже хороший он динамически очевидно под название но к сожалению в нем нет оптимизации под синди инструкции современные и нет оптимизации под хранение разряженных данных а у нас очевидно принадлежность профилей какому-то целевому сегменту представляет собой довольно таки разреженные массивы большинство будет составлять 0 и а вовсе не единицы которые нас интересуют пусть те для хранения нет и вот мы нашли в результате библиотечку которая называется бит magic в ней есть ассемблерный реализации под сент инструкции и по дэн того и под arm есть темизации под хранения в оперативной памяти на диске разряженных данных и для больших объемов данных а у нас их очевидно большие у нас как как вы помните 100 миллионов сим-карту словно до которую нам нужно обслуживать обсчитывать есть самая лучшая скорость вот убит magic и получилось по сравнению с другими еще рассмотренными битвы мем осевыми готовыми и так как мы импортируем данные мы читаем файлик teradata складываем идентификаторы профилей в массив index авангарде ритм и после того как мы его весь прочитали мы перестраиваем этот торди ритмов быстрый константный кешмоб с открытой адресации мы имеем возможность его перестраивать долго с тем чтобы потом быстро с ним работать потом после того как он готов мы можем быстро преобразовать идентификатор профиля к индексу в бита вам массиве потом мы читаем параллельно файлы bigdata через густой грязи где компрессор поставляем биты в масках бит magica сохраняем после прочтения всего файла этот файлик уже на диск дебетовой маски с early сжатие без magica и в результате получаем кроме того что аналог клик house of ских колонок в виде файликов сбитыми масками мы еще и получаем сам импорт быстрее на порядок из-за того что мы можем процессить это параллельно все и главное что мы можем их отдельно они собирать в отдельные строчки как мы вынуждены были для вставки в кликов как мы с этим потом работаем ранее все подготовленные массивы мы храним в оперативной памяти адаптивно каширу им в оперативной памяти и на диске виде битовых масок данные выборка слегка с промежуточные результаты вычисления выражение и триггерные сегменты то есть если какой-то идентификатор профилю попадает или нет это определяется одним битом в битовой маски то есть все очень быстро и многопоточное однократно за день вычисляем выражение то есть у нас в кэше хранятся предыдущие вычисленное выражение соответственно мы их можем повторно использовать и в нашем сценарии когда наш клиент продолжает подбирать себе аудиторию это очень удобно поскольку результаты предыдущих вычислений у нас уже есть в оперативной памяти и мы нам остается только добавить например один битовый массив с ней с не взял tian de leur и на этом новый пересчет после того как наш клиент кликнул какой-то новый таргет на экране завершу мы реализуем новую контактную стратегию в ней уже in memory лог free алгоритму бронирование профилей мы там учли рабочие выходные дни при их распределение подарком рассылки и когда мы это все сделали мы наткнулись на проблему что наши рассылки ные шлюзы не готовы оказались к переходу на сегменты уже разделенные по датам поскольку в них была реализована своя схема раскидывая по датам и миграция вот уже наших рассылках шлюзов на 2 теле таргет идет дольше ожидаемого до сих пор не завершена как у нас проходила пересечение с аудиторией и либо исключения какой-то аудитории например черные списки либо предыдущей кампании раньше выделенный красным под запрос у нас выполнялся практически на каждом клике нашего пользователя соответственно это было тяжело для cliff house а теперь мы этот эту выборку делаем всего один раз из клика us а дальше она у нас лежит в виде битовые маски в оперативной памяти либо на диске в каше если уже выяснилось и после этого мы можем быстро опять же эту битву маску применять если надо а не гонять каждый раз клик house для того чтобы нам выбрал все данные как было в первом тилли таргете и как стал во втором за контакт на стратегия раньше у нас была долгая выборка всех профилей для того чтобы исключить тех кто не превысил тех кто превысил лимит на количество контактов теперь у нас или нет у нас был глобальный лог из-за отсутствия транзакций мы не позволяли пазла параллельно создавать компании теперь у нас во free all гадит в бронировании профилей и контент шон возможен только на одних и тех же профиль и контакт канале рассылки но давайте посмотрим какие у нас результаты по производительности получились и вот у нас есть два условно в таргета 73 и 74 один одни и те же данные в клик хаосе и в оперативной памяти 2 теле таргета мы сравниваем их скорости видим разницу на два порядка и самой верхней случае это случай когда первый теле таргет пришли и liftago 2 пришли за тем же 70 четвертом торги там и говорит дай ответ 1 теле таргет вытаскивает его просто спеша к нему пришел тот же запрос что и раньше он его вы тоски . каша 2 теле торги то он вынужден посчитать количество выставленных в единичку битов а все остальное он уже раньше посчитал и вот разница как видно здесь всего на порядок то есть даже с учетом того что необходимо этот подсчет выставленных единицу битов и сделать проигрыш вот по сравнению с поиском просто в хэш-таблица настолько вал и соответственно вот когда у нас идет переключение канала рассылки как я уже говорил нам нужно поменять в том выражение большом которое у нас было поменять условия на запреты и соответственно если это уже следующий шаг то поменять проверку канала но запрета на количество контактов ну соответственно вот четыре разных канала мы переключаемся с одного на другой у нас есть некое выражение в котором есть четыре элемента в одном таргетинг например это 4 3 3 диапазона возраста например и 5 интересов вот соответственно такие вот выигрыше у нас получаются у первого теле 2 теле таргета по сравнению с первым как видно у е mail а самый маленький выигрыш но это из-за того что у нас еще чуть чуть не до оптимизирована работа с именами а там нам нужно искать уникальные mail и очевидно что у нескольких профилей может быть один и тот же e-mail поэтому нам нужно проверять уникальность и тут чуть-чуть еще есть место для оптимизации какой же бизнес эффект вместо примерно 100 пользователей за интерфейсом нашим может одновременно работать десять тысяч одновременно создаются сегменты для рассылок нескольких рекламных кампаний триггерные компании у нас теперь не тормозят можно проводить сотни одновременно на итоге es que el базы данных не подходят для наших задач из из treehouse нам помог при старте но были помехи в нем нет транзакции в нем медленные мелкие ставки и медленный gelid и ужасно тормозящий за кибер решение под предметную область очевидно лучше чем готовы и мы продолжим использовать клик house перестав натягивать его на глобус моей благодарности разработчиков мы моей благодарности всем слушателям у меня все прошу задавать вопросы спаси большой алексей"
}