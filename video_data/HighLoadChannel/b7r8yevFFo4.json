{
  "video_id": "b7r8yevFFo4",
  "channel": "HighLoadChannel",
  "title": "Успеть за 100 миллисекунд: контекстная реклама на Sphinx / Дмитрий Хасанов (Avito)",
  "views": 822,
  "duration": 2031,
  "published": "2017-05-14T22:53:06-07:00",
  "text": "так меня зовут дмитрий хасанов я работаю во vita разрабатывая сервис контекстной рекламы все видели в поисковой выдаче у нас появляется нерв тические объявления рекламные объявления буду называть их так это кусочек нашего основного сайта авито сайт авито построен вокруг поиска объявлений и вот в поиске объявлений среди прочего появляется еще дополнительно и объявление рекламные для того чтобы их выдать нам нужно иметь какую-то базу объявлений и каким-то образом определить какие объявления для вот этого поиска подходят лучше всего год назад примерно запустили контекст первую версию и в тот момент эти объявления выглядели именно вот так прошел примерно год мы работали долго долго и делали очень много всего внутри появилась действительно там куча всяких решений кусочки рокет сайенс а машин линга и прочего прочего и спустя год контекстной рекламы выглядит вот так и на самом деле это очень хорошо сейчас расскажу почему система основные требования вытекли из того что у нас на основном сайте происходит у нас есть поиск туда приходит куча народу и весь вот этот трафик должен пойти на наш прикладной сервис контекстных объявлений мы должны среагировать на каждый поиск и подобрать какие объявления достойны размещен размещения на вот этих выделенных местах мест очень мало объявлений очень много мы расчитывали систему на 50 миллионов рекламных объявлений сейчас их бою крутится около пяти миллионов и система действительно активно растет скоро их там будет существенно больше 300 тысяч запросов минуту это реальные цифры у нас в пиках сейчас столько есть это трафик идущий с основного сайта запрашивают серб выдачу объявлений и тут же полетел запрос на наш сервис и мы должны среагировать и быстренько ответить набором рекламных объявлений которые подходят для выдачи и требование про 100 миллисекунд на ответ так как наш сервис прикладной для основного сайта мы должны максимально быстро отдать ответ чтобы пользователь не не ушел не увидел какие то там белые краны и даже в случае если там какие-то тайм-аут и мы упремся вот это возможная ситуация мы просто начнем терять деньги соответственно это достаточно критично и требования мы все вот эти вот весь трафик наши 300 тысяч запросов минуту на 50 миллионах рекламных объявлений должны обрабатывать максимально быстро соответственно вот она задача у нас есть огромная база объявлений и нам нужно очень быстренько подобрать те которые подходят для вот этого поиска пользователь искал мы знаем чего то пользователи мы знаем что он искал в какой категории в каком регионе также бывают разные другие таргетинг и называемых таргетингами мы учитываем все их сразу отсекаем те объявления которые нам не подходят оставляем только тот datasette который потенциально может быть выдам на сайте а потом самое важное объявление пользователь уже потенциально подходит но мест всего там скажем 2 как выбрать из 50 миллионов но и там плюс от сильных выбрать те два объявления которые нужно показать этому пользователю вот эта формула которая здесь указано битность or бит это ставка за рекламное объявление сколько готов заплатить рекламодатель если поэтому объявлений кликнут сетях это прогнозный предполагаемый стер сколько с какой вероятностью вот этот пользовать в этом поиске кликнет на это объявление это число от нуля до единицы мы усиленно меньше единицы скажем вероятность того что этот пользователь в этом поиске кликнет на это объявление три сотых процента и вот мы умножаем на вот эту ставку и получаем предполагаемый доход если мы покажем именно это рекламное объявление в рамках вот этого поиска от классика рекламные чуть-чуть ещё поясню у нас аукцион 2 цены то есть рекламодатели делают разные ставки и побеждает тот у кого но фактически предполагаемый доход фактически ставка больше всех но платит он не столько денег сколько поставил а столько сколько поставил предыдущий проигравший плюс шаг аукциона так вот в этой всей формул key для отбора все у нас есть пользователь предоставил запрос возможно это текстовый запрос возможно это ограничение по категориям регионом и так далее все эти данные у нас есть по базе объявлений про искать достаточно легко сортировка ставку который указал рекламодатель тоже у нас есть все быстро все просто но как нам предугадать вот этот свитер как его спрогнозировать насколько это именно этот пользователь в рамках именно этого поиска на этом рекламном месте готов будет кликнуть на это объявление здесь нам на помощь приходят математические модели у нас есть целый штат аналитиков фактически они пытаются построить какую-то формулу под условия первым пунктом не указаны параметры мы знаем что пользователь который пришел пришел с определенной операционной системой с юзер агентом браузера и так далее то есть мы знаем что там пользователь и также мы знаем что то непосредственно о каждом из объявлений рекламных среди которых мы производим выборку и третья группа мы знаем что-то об окружении мы знаем на каком на какую рекламную позицию мы будем выводить это объявление какая это версия это основной сайт мобильный сайт либо мобильные приложения нам нужно все это учесть потому что для предсказания витяра нужно подстроиться под каждого пользователя в каждом конкретном поиски десятки параметров конкретно у нас их около 50 мы их называем фичами вот эти все вещи передаются и должны быть проверены для каждого из объявлений которые находятся у нас в яндексе для каждого из рекламных объявлений вот эта моделька для нас с точки зрения разработчиков контекста с точки зрения пользователей это некая формула на форму мы передали входящие значение какой пользователь какие какое окружение оно выход получились какой прогнозируемый вероятностью от пользователь щелкнет по этому объявлению откуда берутся миллионы коэффициентов эти модели построены на принципах машинного обучения то есть внутрь зашита какая-то определенная формула которая учитывает помимо тех параметров которые мы на нее передали еще какие-то корректирующие коэффициенты а насколько нужно учитывать конкретно вот этого пользователя на сколько нужно учитывать влияние вот этого рекламного места потому что мы знаем что на первом месте этот пользователь кликнет с большей вероятностью на седьмом месте с меньшей вероятностью ну тупо достреливает он не так часто вода туда и вот все вот эти вещи нужно учитывать в комплексе когда обучается модель на нее передается обратная связь от нашего сервиса то есть мы показали объявление и узнали что с ним произошло кликнул этот пользователь ни кликнул помимо этого мы вообще узнали было ли объявление выдано мы блокируем победителей не передаем на моделей соответственно у модели есть куча сигнала в которыми они могут подстраивать вот этих а и коэффициенты для того чтобы давать более точные прогнозы как это можно оценить мы проводим всякие разные эксперименты и я бы тесты придумаем какие-то метрики сравниваем модели лоб в лоб соответственно в бою одновременно должно крутиться несколько моделей для одного места мы рассчитали по одной модели она сказала стер будет примерно такой по другой модели она сказала сестра будет такой а потом мы сохранили данные какой же он был на самом деле и сравнили насколько эффективно была та или иная модель и когда мы переходим на новой модели мы можем в бою держать одновременно до 5 моделей на одно место это важно поскольку это накладывает некоторые ограничения инфраструктура то у нас по железкам одна и та же но теперь вдруг нам надо чтобы в параллели крутилась 5 моделей на одно место для различных экспериментов тоже периодически предполагается что нужно вводить новые модели ну и соответственно для разных мест рекламных для разных версий сайта для applications of тоже могут использоваться разные модели как это все можно сделать поиск по нашей базе объявлений и использование вот этих вот моделей для предсказания сетях чтоб потом проранжировать и выбрать самые выгодные для нас объявления решение может быть действительно много реляционные базы данных уже отлично умеют искать кроме случая с полным текстом полный текст пришлось бы до реализовывать кроме того для того чтобы в них хранить вот эти вот все миллионы коэффициентов нужно задуматься каким образом их туда импортировать поскольку коэффициенты должны обновляться часто машинное обучение перри обучили модель подкорректировали коэффициенты снова нужно их потянуть опять прошла обратная связь опять нужно их подтянуть коэффициентов миллионы это не шутка у нас их действительно около 10 миллионов для одной модели и соответственно нужно подтягивать десятки миллионов коэффициентов с определенной частотой ну допустим раз в час там немножко размытые границы но интервал примерно такой соответственно надо было задуматься каким образом хранить эти коэффициенты как их подтягивать и как допустим если делать на хранимых процедурах каким образом все это делали ладить чтобы переключиться на использование новых коэффициентов трудновато было бы in memory база данных но тот момент тарантул был очень молод у него была не полная документация но мы предполагаем что на таких решениях как тарантул можно это сделать можно взять ло и дописать туда какой-то полна текст полна текстом нужен пользователь может водить текстовый запрос и каким-то образом а вот с коэффициентами там было бы все просто коэффициенты уже хранятся в памяти и доступ к ним достаточно быстрый вот короче мы предполагаем что in-memory база данных могла бы решить нашу проблему на тот момент взрослого готового решения удовлетворяющего у нас не было тарантул потом подрос мы на него смотрели можно было написать самописный инструмент это лучшая вещь которую можно придумать работает какой-нибудь демон этот демон постоянно следит за тем что происходит с объявлениями подцепили к базе его прилетают туда какие-нибудь изменения он знает короче у него всегда есть актуальный snapshot и он может быстренько отвечать но самописный инструмент нужно было сделать с учетом полнотекстового поиска довольно интересная и ресурсоемкая задача да и вообще сделать его скорее всего на каком-то легком языке типа сижки или go у нас пока нет таких специалистов которые готовы за неделю от все дела написать было бы долго и дорого то есть именно момент разработки но вариант очень хороший работать должно быстро и хорошо также можно было использовать внешний поисковый движок это все solar все люсена образная elastic сочи сфинкс и вот мы как раз на этом решении остановились потому что там был очень здоровый баланс эти штуки уже умеет искать вот у нас есть большая база объявлений как найти проиндексировали поискали все просто все умеют это чего она не умеет из коробки а кстати вот очень важно там полный текст есть тоже докручивать не надо чего не умеют из коробки так это ранжировать то есть вот нам нужно как-то предугадать прогнозный сетях сколько там пользователю кликнув конкретным по этому объявлению и так для каждого из объявлений которые мы проектируем значит нужно каким-то образом это дело расширить чтобы можно было там наши магическую формулу запихать да еще таким образом что все эти миллионы коэффициентов научит его в итоге нас фильм все остановились потому что у него нашелся подходящий инструмент для расширения для того чтобы мы смогли эти объявления проранжировать общая схема в итоге выглядит как и обычно в сфинксе индексации объявлений и поиск плюс в конце ранжирование по нашей вот этой формулы бит на прогнозный city or индексация максимально просто из базы данных мы вытянули объявление положили в csv-файл тоже что csv только разделенный потапом и дальше скормили это в яндекс тсв файл удобен тем что можно несколько источников подцепить допустим из базы данных достали а потом еще в эти же строчки разложили какие то при дрочи таны данные что-то еще и это все попадет в индексы будет лежать рядышком с этим объявлением их можно будет очень легко использовать на нем искать все что угодно с ними делать индексируем и все это на одном мастере сфинкса дальше разливаем arsenka сжимаем индексы развиваем все происходит быстро поиск максимально просто здесь у нас есть пользовательский запрос то окружение на каком рекламном месте мы будем показывать это объявление какие-то другие таргетинг и допустим день недели сегодняшний и так далее и мы сразу отсекаем те запросы которые нам не подошли среди параметров пользователя есть у нас там интересные штучки например назойлив чуть позже расскажу сколько один пользователь может увидеть одно объявление сколько раз максимум а вот самое интересное ранжирование от цикле мы уже из нашего дата-центра эти объявления которые не подошли и остался тот сет содержащие потенциально готовы и для отображения объявления теперь мы их хотим отсортировать так чтобы верхние объявление были с максимальным предсказанным доходом и вот тот самый инструмент который позволяет это сделать нам нужно разместить математическую формулу оперирующие куча и входящих параметров плюс кучей коэффициентов которые подстраивают эти входящие параметры их влияния на результат механизм иудеев эта штука позволяет расширять сфинкс с помощью личного кода делал библиотека shared лайнеры внутри которые можно запекать все что угодно соответственно наша форма у к там живет мы это дело компилируем на одной ноги сфинкса там же где индексация индекс перестраивается и потом диплом вместе с индексом там нас папа таймингом все так оптималь ника получается внутри этой самой и девки просто набор таких соглашений допустим самое самое первое ну понятно инкладится все дела это все что необходимо чтобы сделать you девку здесь всё описано функциям мдф это сама самая мякотка тут находится код который реализует логику works прилетели аргументы входящий те самые параметры пользователя окружения и так далее на выходе она должна отдать нам число насколько этот пользователь в этих условиях готов будет кликнуть по конкретному объявлению то есть эта функция будет выполнена на каждом из объявлений в поисковом яндексе и для каждого из этих объявлений она выдаст свое число дальше служебные штуки инициализация день единиц или зация версия вообще раз зашивается и забыли в инициализации можно например проверить и характер входящих аргументов если там их формат неправильно либо количеством то сразу ругнуться каким образом мы это делаем внутри верёвки мы сразу кладем нашу огромную пачку коэффициентов допустим 10 миллионах коэффициентов для одной из моделей мы подтягиваем ваш файл в котором лежат коэффициенты вытянутые спас gresso аналитики обучили там свои модельки и экспорт 0 и нам в под grease 10 миллионов коэффициентов подстроили модель по-новому мыс postgres а вытянули башкам у нас все просто и положили сгенерировали хищный файл в котором написали там с тракт такой-то и перечислили все все все коэффициенты а коэффициент это фактически ключ значения и у нас в текстовом файлике в этом ваш лежит 10 миллионов этих коэффициентов дальше подключили этот файл в наш сильный кот с компилировали и коэффициенты стали доступны то есть он у нас структур как рапс допустим содержит все что нужно и для получения результата мы вызываем какую-то функцию на которой в том числе прилетают коэффициенты рядом со значениями для того чтобы скомпилированный код но здесь . с компиляции есть шарить лайбрери компилируем получаем iso файл для того чтобы сфинкс понял что его можно использовать есть у него синтаксис creed фанкшн и у него есть еще красивый замечательный рилот о нем чуть позже тоже попробую упомянуть вот и когда подтянули вот эту функцию мы можем ей пользоваться шоу plug-ins показывает какие у девки существуют внутри свинца таким образом можно обратиться к тем самым девкам на вход они принимают очень большое количество параметров все что угодно но там есть фишечка если параметров будет много допустим 1000 то сам парсинг этих входящих параметров будет занимать сильно много времени и процесс ну и соответственно выигрыше от использованию девки уже особого не будет соответственно их надо держать в каком-то таком доступном окне скажем сотни максимум на выходе вот мы получили то что требуется наш прогнозный сетях допустим для нашего сервиса меняются входящие параметры будет другой результат соответственно мы можем за каждого объявления его получить но это понятно если мы можем строить результат вот этой функции в наш запрос мы можем написать то же самое там ордер buy вот эта штука и в обратном порядке по убыванию предполагаемого то есть беда умноженного на настя рассортировать наше объявление взять топ на чем это у нас крутится свинцовый яндексе отдельно живет у нас от самих search by демонов их пачечка обращается к полюсу ну там короче вся инфраструктура вот она основное это не считая манги манги редиса в подгрести живут объявлений их терять не хотим там же живут настройки наших рекламных кампаний ставки пользователей и так далее индексировать его проиндексировал search.php обратилась запросам отдал максимально быстро ответ уже в том порядке в котором нам нужно то есть топ по предполагаемому доходу сверху и в манго вот здесь интересный момент используется для того чтобы генерировать обратную связь на аналитиков их модельки обучаются слушая поток ивентов прилетающих манга создали несколько copied коллекции с ограниченным размерам и в эти коллекции постоянно льется поток сырых данных прошел аукцион победили там скажем пять объявлений топ-5 сразу экспорт 0 данные какие объявления с какими параметрами дальше показали пользователю объявления он кликнул ли больнице рыкнул и мы тут же сгенерировали события был кликни было клика отправили и вот на эти капельки коллекции там постоянно вот крутится крутится крутится этот большой поток из него потом подцепляется аналитики вытягивают в свою более удобное для них хранилища и обрабатывать каким-то образом затачивают модельки и дальше нам уже снова в паз газ экспортируют новые коэффициенты для этих формул обри ди си всякие интересные штуки типа исторических данных срезов для рекомендации победили тоже там объявление какие-то аукционе мы из них по на дергали всякие минутные срезы с этими своими победителями их параметрами а потом можем выдать рекомендацию либо какую-то статистику по аукционам хранить такое быстрое хранилище каким образом нам все-таки удается укладываться в эти мифические 100 миллисекунд если просто взять и в тупую поискать то может быть во многих местах медленно база это большая все таки 50 миллионов не shoot 1 штука который используем здесь она скорее не про оптимизацию скорости для удобства если мне хочется наворачивать какие-то штуки много много нот у вас есть финансовых там много слоев у них у всех разные индексы какие-то данные не хочется заморачиваться не там не особо критично вы можете загнать в дистрибьютор индекс распределенный это просто немножко снимается приложение дополнительной логике по синхронизации данных между индексами 2 штук а вот это уже клиника здесь есть сортировка по двум полям сначала отсортировали по быстро и вот сейчас про первый запрос говорил а потом до сортировали по медленной сортировки медленная сортировка как вы видите это вызов в виде функции то есть есть в яндексе кучу объявлений и мы для каждого из них начинаем насчитывать результат этой у да и функции а потом по этому результату сортируем до сортировки и вот в первом запросит получается достаточно медленно поскольку с винус будет пробегаться сначала быстрой сортировкой по всем а потом медленной сортировкой снова по всем выполняю девку для каждого объявления несмотря на то что лимит у нас стоит 100 и мы должны получить только 100 объявлений оптимизация такая переносим в под запрос на медленную сортировку и соответственно не девка будет вызываться только вот поэтому лимиту только для 100 объявлений а потом уже точнее быстрая сортировка будет вызываться для всего dc тасс ограничить лимитом 100 вот это наружу отдаст только эти 100 результатов для медленный до сортировки ну то есть смысл чтобы вызвать эту и древку только на 100 результатах вторая штука можно передавать несколько запросов через точку , какие то вот у нас есть два из практики два рекламных место и у них используется вдруг одна модель формируем запрос для которого все все все параметры похожи за исключением хвоста допустим там разные лимиты еще какие-то параметры если тело да да вот до ордер buy a одинаково это сфинкс один раз сформирует datasette и потом будет его пересортировать перегруппировывать разные элементы применять и выдавать эти все штуки наружу использовав тот же самый datasette вот эта штука дает прирост примерно раза в два при использовании двух запросов через точку , вместо двух запросов последовательных здесь про атрибуты сфинкс хорош но для полна текста по атрибутам он ищет медленно потому что six к нам это внезапные такие парадоксы атрибуты лежат в памяти но секстант медленный индекса лежат на диске но поиск по ним выстроить в синг се так вот чтобы искать по атрибутам нам это необходимо у нас тут они все лежат объявления и там все категории региона и прочее в виде атрибутов есть чтобы по ним как-то там отсекать быстро нам все равно эти возможности нужны вот мы переписываем запрос который был по атрибутам числовым на запрос полнотекстовый берем прямо вот в полях в яндекс полнотекстовым гоняем искусственные атрибуты какой-нибудь префиксы дальше число вместо просто числа с названием атрибута дальше это все дело мочиться уже быстренько надеюсь принцип понимаете и после фильтрации нас на стороне приложения если бы мы все кейсы все возможные таргет и сразу запихивали в сфинкс то все равно было бы медленно потому что бывают такие кейсы которые очень редко срабатывают допустим вот у нас есть не неселективные кейсы настройка у компании рекламной можно показывать объявление только в понедельник а в среду либо еще какие-то ограничения по времени эти штуки охватывает только два процента нашей аудитории мало кто этим пользуется если мы будем встраивать в сфинкс на каждый каждый каждый запрос вот эти вот дополнительные проверки это все будет тормозить мы выносим эту на сторону приложения и и сфинкса возвращается в сад который может потенциально содержать больше объявлений чем нужно то есть мы не все из них можем показать на стороне приложения проверили если сейчас не тот день недели хорошо и тут еще про дни недели заодно учитывается time zone и пользователя соответственно все равно нужно было бы выносить дальше то что от пользователя зависит например параметр назойливости один пользователь смотрит объявление ему одно и то же объявление попадается много раз он расстраивается мы делаем так чтобы он не мог смотреть одно объявление просматривать больше там скольки тарас и сохранили этот пользователь это объявление уже видел столько то раз больше мы не показываем в яндекс это запихать нельзя потому что это зависит от конкретного пользователя то же самое фильтры на стороне приложения ну это что часто изменяется то что может поменяться между индексами какие-то ставки там еще что то мы в принципе можем учесть тоже на стороне приложения и до фильтровать индекс сфинкса как уже сказал хранится на диске это все медленно даже с издержки современные работают недостаточно быстро монтируем втм pfs раздельщик в память свинг считает что он хранит все на диски на самом деле лежит все в памяти работает максимально быстро вот чего мы получили это у нас за один из дней реальная нагрузка количество запросов в минуту и среднее время ответа сервера запросов много ответ быстрый причем самое интересное что не зависит от количества запросов время ответа сама jfk отрабатывает максимально быстро там больше часть времени уходит еще на течение ненужных объявлений из data set а в общем кривенько такие дела надеюсь вас есть вопрос у меня собственно пока один вопрос не совсем понятно почему вы все-таки выбрали сфинкса не какой-нибудь там тот же соврали ластик сечь потому что вот смотрю на ваши проблемы и понимаю что там их вообще нету включая нормальная работа поиска по атрибутам потому что у них это достаточно эффективно между братом что писать это руками это вообще говоря две ночи я это писал например и на таких объемах там не надо бы в десять миллисекунд влезть они в 100 и общем проблем особых не возникало сфинкс легкий вот чтобы не говорили он требует мало железо как минимум у нас я когда показывал слайд наши с нашими с нашей схемой давайте вникнем вернусь и в двух словах тоже пишу php not у нас их 7 штук postgres там своя инсталляция большого вид а мы и так чуть чуть используем для свинца используется восемь нот одна из которых тут же индексирует перестраивает все эти дела и причем мы раз в десять минут умудряемся все периоды xi ровать перетянуть коэффициента и так далее то есть достаточно легкая штука я считаю при таких-то нагрузках вот то есть у нас мало железа и она работает хорошо и быстро сфинкс простенький это тоже писалось достаточно быстро то есть основная система нотка говорите две ночи то есть в этом мы не потеряли вот ну а дальше java я вас так какие проблемы на низком уровне когда из нее чего-нибудь большой вы падаете потом этих stack trace of и прочих дампов мы не понимаем что с ними делать вот так вы говорили выпуск не умеете работать я вы ним работали с явой надо все вот этот ключевой то еще нет конечно в первую очередь спасибо за доклад маленький вопрос по мониторингу по сфинксом вы что используете используете ли вот тот предложенный с на сайте сфинкса их не мониторинг который сейчас бы эти или что-то свое у нас там сверху накручено то есть у нас там график графа нас собираются метрики на более низком уровне я вас могу свести с людьми которые лучше объяснят вот но сфинкса сфинксов сказал сайты нет мы это не используем спасибо большое и еще один маленький вопрос ассорти индексами не работали до real-time которое ну как не работали где-то с чем только не работала ни и сфинкса всех видах в видео нет на самом сервисе контекстной рекламы rt индексы точно не используются спасибо большое всем добрый день меня зовут мария смирнова подбора эти персонала на самом деле я несколько далека от технологической начинки но тем не менее тем не менее мне интересно какие технологии вы считаете самыми прогрессивными сейчас и почему зачем будущее спасибо будущее за самописный будущее за своими песчаными демонами в таких случаях потому что большие нагрузки и подточить какой-то инструмент под себя это такое временное решение а дальше когда нагрузки растут уже там что то что другое но вообще надо брать нишу надо брать задачу сразу можете сказать пару слов про при подготовку запроса что то что вы делаете шарить или запрос при индексации используете летом поиска локации в тексте чтобы были точно будет запрос мочить с вашими данными так но у нас сейчас достаточно мало каких то таких parketoff специфических то есть в самой мы ограничиваемся категории регионом пользователя и какими-то и пользовательскими параметрами вот я прорекламирую андрея смирнова завтра будет крутой доклад про сфинкс то есть вот и там будет про всякие вот такие штуки там вот еще немножко прорекламирую там были всякие наши оптимизации как мы пытались там все все сворачивать чтобы как раз сэкономить время на поиске вот ну там спойлерить не буду вот но вообще при подготовка запроса нет у нас есть в планах знаете какая штука искать не только в той категории допустим которую пользователь запросил но еще какие-то соседние если мы не можем выдать ему в этой категории вот вот такие штуки будут подскажите там последнее время именно сама разработка сфинкса немного несколько приостановилось и про третью версию там давненько ничего не слышно если какие-то новости будет ли именно там в третьей версии много чего интересного обещаю я да я боюсь говорить за товарища ксилол он к нам приходит и как обычно улыбается видимо все хорошо расскажите пару слов о пост фильтрации если соответственно мы до 100 запросили дано приложение отсортировали выкинули фильтровали и получили пуст что делаем дальше до такой кейс действительно может быть какое-то очень очень очень низкой вероятностью потому что мы выдаем на сторону приложения так специально с запасом от сфинкса объявлений чтобы ну вот push при их при всех условиях там чего не досталось но вообще потенциально если сильно сильно не повезло такое может быть взяли и отфильтровали ну ничего не подходит в этом случае у нас уже особо не останется времени на то чтобы сделать повторный запрос что-то там еще соответственно мы просто отдаем от сервиса ответ ничего не нашли и дальше на более высоком уровне могут применяться какие-то другие техники допустим там одно рекламное место 9 не только авито-контекст но еще какие-то внешние рекламные системы какой-то баннер еще что то вот спасибо вам за вопрос хороший спасибо за доклад вопрос такой вот вы говорите у вас индексация происходит на одном мастер сервере можете подробней рассказать что за сервер и как а сейчас на него нагрузка и при увеличении допустим сейчас вы говорите 5 миллионов в явление это привлечение 10 раз на как на что вы рассчитывали будет ли хватать этого одного сервера или и вот у нас есть 8 серверов это железные сервер и рядом с ними живут редис и которые любят память вот а сфинкс и спрос железо хорошие точно марки модели он не скажу но опять же знаю людей если будет интерес могут подсказать и на этом сервере одном из восьми на него летят и запросы пользовательский и на нем же происходит переиндексация и перестроение перекомпиляции у дев сейчас все происходит достаточно быстро чтобы не опасаться за рост на один порядок например вот у нас вообще проблема проблема есть такая мы начинали компилировать вот эти вот огромные аж файл содержащий кучу коэффициентов оказалось что это неэффективно допустим на момент компиляции был огромный расход памяти когда мы ваш файл загнали 10 миллионов коэффициентов при компиляции джесси съел 11 гигабайт памяти в итоге мы получили на выходе 300 мегабайт ный файл и вот для компиляции 300 мегабайт на файл почему-то по 3 8 гигабайт вот наша лучшая оптимизация этот момент мы наняли специально обученную девочку которая умеет компилировать правильно и она взяла я сам ее какой-то там хитрой магией двумя другими словами и загнала вы тут drl файл какой то еще ресурсный файл dat файл содержащий наши бинарные данные и после всех этих манипуляций расход памяти снизился примерно до гигабайта вот то есть сейчас мы опять перестали опасаться что мы во что-то там у примусь скажите почему сервера выбрали именно железно ведь наверняка нагрузка в течение дня она ведь очень сильно нелинейная то есть возможно было бы выгоднее прощение что ж вроде амазона подключать в пике про amazon пожалуй нет потому что для него пришлось бы менять инфраструктуры очень сильно мы прогнозируем рост так чуть-чуть заранее и железки закупаем и так как это не java прочтите все равно расходы по ресурсам небольшие мы можем себе позволить держать железо чуть-чуть на вырост вот а когда бизнес скажет что все тормоза спускаем контекста всем мы опять же там заранее закупимся сначала себе буфер обеспечим а потом уже будем вот это делать мы все делаем постепенно мы умненькие спасибо"
}