{
  "video_id": "k-mlK-mnS3s",
  "channel": "HighLoadChannel",
  "title": "PostgreSQL: Ups, DevOps... / Алексей Лесовский (PostgreSQL Consulting)",
  "views": 74,
  "duration": 2134,
  "published": "2017-04-22T12:08:44-07:00",
  "text": "зовут меня алексей лисовский представляю компанию по игре сколь консалтинг вот мой коллега или я только что выступал здесь вот мы с ним работаем вместе и наша компания занимается каласан кинг консалтингом технической поддержкой баз данных на postgres quelle вот разрешаем всякие вопросы архитектуры производительности и масштабирования соответственно каждый день мы сталкиваемся с грейс сколь в самых разных ситуациях вот и у нас очень большой опыт решение таких вопросов вот кроме того я очень люблю администрирование linux вот и интересные вопросы виртуализации на том же самом linux вот сегодня мы поговорим о postgres quelle в сфере ее применение devops вот мы поговорим об актуальности проблемы в сфере управления конфигурациями и автоматизации задач в рамках эксплуатации суде пуск рискует вот проговорим про то какие задачи бывают администраторов баз данных про автоматизацию этих задач вот какие задачи можно автоматизировать такие нельзя какие можно но быть с этим очень внимательным вот поговорим о проблемах связанных с автоматизацией вот и об особенностях инструментов которые можно использовать вот об их отличиях какие лучше какие хуже и напоследок я расскажу немного страшилок вот какие возникают при использовании devops с базами данных вот как из своего опыта так из опыта своих коллег вот начну с актуальности проблемы почему нужно автоматизировать почему нужно убрать конфигурациями в сфере баз данных вот откатимся на некоторое время назад например лет на 10 и возьмем какую-нибудь обычную компанию которые есть там свои базы данных или свое оборудование как правило в этой кампании было кокаин стойка в дата-центре либо адаму своя серверная комната вот и там стояли сервера все прекрасно работала на определенную задачу был свои сервера вот затем появилась виртуализация то есть мы можем взять большой сервер нарезать его ресурсы на несколько виртуальных серверов то есть количество серверов нас уже увеличивается идем еще дальше появляются облака вот и соответственно когда у нас уже появились облака нам не надо покупать серверы нам не нужно там проплачивать этажа когда поставщик отгрузит нам сервера мы можем зарегистрироваться ногами диапазоне с помощью простого мастера нарезать и виртуальных машин запустить и начать работать то есть нас все уже упирается только в кошелек то есть сколько у нас денег на счете чтобы платить за эти виртуальные машины соответственно нас со временем количество машин выросла и если раньше у компании там были десятки серверов там 1020 то с помощью виртуализации облаков и можем позволить себе десятки сотни и даже тысячи серверов легко вот соответственно с увеличением количества серверов нужно как-то ими управлять соответственно вместе с этим появляются различные deux практики которые позволяют экономить время появляются инструменты которые позволяют реализовывать какое-то управление таким большим количеством машин вот однако с внедрением таких практик и использованию инструментов мы сталкиваемся с тем что в каких-то частях инфраструктуры то можно легко использовать в каких-то не очень таким образом вот есть мешал critical задачи которые как раз таки с ними нужно быть очень аккуратным то есть это задачи где мы храним анализируем данные собираем вот зачастую данное как бы потеря данных будет может быть очень критично и катастрофичной а для бизнеса данные могут быть самые разные это может быть наша информация финансовая может быть информация клиентов вот то есть это критически важные данные потери которых совершенно не желательно вот соответственно при обслуживании таких задач есть определенный круг задач которые новую возникают администратора баз данных эти задачи можно разделить на несколько классов самый простой класс задача та поддержка конфигурации серверов то есть это самый простой вариант это установка программного обеспечения и поддержания его конфигурации там в определенном режиме вот здесь все просто то есть мы установили а к нам пришел новый сервер но установили на него программное обеспечение ввели в эксплуатацию нас работает это сам простая задача которой возникают практически у всех администраторов под конфигурацией понимается версия под грецку или версии там связанных с ним утилит там где bouncer погиб ул вот и управление это вот как бы связано еще с другими системными вещами типа файл это за дата системные временные зоны вот следующий класс задач можно отнести уже развертывание каких-то там репликаций репликации в postgresql бывает самое разное они основаны либо на потоковой репликации которая идет из коробки ее достаточно легко настроить вот либо это могут быть триггер триггерные решения типа склоне лан даст или букардо следующий класс задача то обновление апгрейды вот если рассматривать после сквозь то здесь есть два типа обновления это минорное обновление и мажорно чем они отличаются минорным и просто обновляем postgres queen версию с одной версии на другую набор в рамках одной ветки например 931 мы обновили на 935 то есть вот вторая цифра который обозначает ветку оно не изменилось здесь все довольно просто то есть мы обновили бинарные пакеты заморозили соединение вот сделали перезапуск сервиса по сгрыз и разморозились соединения то есть для приложения так правило можно сделать прозрачно без каких-либо ошибок и мажорное обновление когда мы обновляем ветку то есть мы обновляем например с 90 92 здесь один на 94 такие обновления как правило более сложные потому что они требуют перри конвертации каталога в котором хранится база соответственно здесь увеличивается время которое мы можем потратить на обновление другие задачи обслуживания которые могут возникать это балансировка запросов от приложения для этого существуют пакет это как х прокси и g пол вот в сусе и это представляет собой такая прослойка между серверами приложениями и стираем баз данных те запросы идут к балансировщик у балансировщик уже на основе своей конфигурации раскидывает запросы по разным серверам все это работает достаточно хорошо и часто бывает такая задача что нужно какой-то сервер из пула убрать либо какой-то добавить новый перри конфигурировать вот и направить поток запросов уже к базе следующий класс задача то свечу where или failover это в случае если у нас есть настроенный кластер есть мастер который принимает запись есть несколько серверов реплик которые могут принимать запросы на чтении либо просто стоять как запасной сервер и если с мастером что-то случилось там упал сервер там сломалась железа нам нужно запасной сервер переключить в главный основной режим чтобы он смог принимать запросы на запись совместно здесь возникает задача свеча вера это ручное переключение либо автоматический failover вот эти задачи возникают довольно редко но они все равно возникают и могут быть потому что ничто не может работать вечно к сожалению следующая задача уже относится к повседневным задачам которые возникают каждый день которые приходится решать то есть основная рутинная работа администратора баз данных это анализ отчетов и мониторинг анализ отчетов представляет собой то есть какое-то программное обеспечение она обрабатывает логе и формирует небольшой отчет о том что происходило в базе ошибки запросы различные события и так далее и задачи мониторинга соответственно это какие-то с аварийные события которые могут происходить в базе либо это какие-то исторические данные по которым мы рисуем графики вот занимается это не всем badger джефф оуен вот либо мониторинг у нас работать через zabbix nagios инструментов достаточно много и выбирать можно из чего угодно следующем классом задач я бы отнес каждодневное обслуживание это задача типа построить и индексы сделать три яндекс или бывает что в результате интенсивной записи таблицы или индексы распухают вот нужно приведу приложить вернуть их их размер в нормальное первоначальное состояние вот задача идти есть такой момент что эти задачи нельзя предугадать когда возникнет в них необходимость то есть мы не можем сказать что завтра нам придется удалить раздувание этой таблице эллиот послезавтра вот нам нужно будет построить вот там индекс то есть задачи такие характер характера что такое они появились мы их обнаружили их надо решить вот ну и задачи резервного копирования валидации резервных копий тут я думаю все просто это значит класс он устроил забыл то есть мы создали алгоритм взять и резервных копий у нас работает мы взяли алгоритм взять и проверки валидации резервных копий все мы его настроили забыли касаться его можно уже уже больше не касаться только смотреть отчеты о том как проверились бэкапы если backup у нас битый то мы просто берем новый backup берем и старые не валит мы отбрасываем и того задачей можно разделить на два типа это типовые задачи которые делаются довольно-таки легко и просто изо дня в день вот у них довольно таки простой и простой уровень выполнение то есть мы сделали это это это все задача готова и ручные задачи это задача когда нужно сначала посмотреть какие-то данные глазами наметить для себя алгоритмы решения и потом уже приступать к их решению вот то есть у администратора баз данных всегда есть какая-то работа которой он занимается здесь мы подходим к автоматизации задач предположим если у компании небольшое количество серверов там меньше 10 4 5 6 вот то задачи можно делать руками то есть мы открыли там консоль посмотрели сделали и закрыли все готово если у нас много серверов 10 20 30 то выполнение действий на каждом сервере может занять довольно таки большое время для этого нужно как раз таки нужна автоматизация вот автоматизация к но мид время то есть мы можем сделать одно и то же действие на нескольких серверах это существенно сократить нам время чем если бы мы на каждом сервере делали ту же самую задачу автоматизации устраняет вероятность ошибки то есть мы от тестировали алгоритм задачи мы проверили что он работает вот мы его запускаем он у нас выполняет свою работу чем меньше входных параметров на выполнение задачи тем меньше вероятность ошибки вот и один из один из моментов которые мне нравятся больше всего мы можем сделать однообразие внутри инфраструктуры когда у нас на всех серверах одна операционная система с одним ядром системные библиотеки версия 1 этажа когда точки монтирования совпадают конфигурации совпадает то есть практически нет никаких расхождений вот то есть унификация и однообразие инфраструктуры таких задачах когда мы хотим внедрить автоматизацию либо управления конфигурацией может возникнуть некоторые проблемы вот проблемы я бы сказал так они очень такие простые их очень легко лишились жить и они как бы не стоит на них особо зацикливаться первичная проблема это база данных это один из важнейших элементов инфраструктуры то есть мы там храним данные мы там храним те данные которые не хотим потерять с которыми нежелательно чего-либо делать вот поэтому база данных это такое такое священное священное звено вот операция операции администратора баз данных зачастую носят еда на разовый характер то есть мы допустим хотим обновить сервер мы сделали восстановили его обновили все больше мы к нему не возвращаемся другое дело что это один сервер а когда ig20 там были еще больше то обновлять каждый из них это занимает какое-то определенное время очень долгая вот вторичная проблема это более относится к тому что они связаны с нашей компании мы как наемные администраторы наемные консультанты сталкиваемся с этими программ с этими проблемами время от времени первая проблема это недоверие со стороны штатных администраторов когда мы заключаем договор мы работаем с людьми о компании как правило же есть свои администраторы и они не всегда хотят давать там доступ в их инфраструктуру смысле вот кто знает чего там на делаете вот и гетерогенной инфраструктура это тоже как бы и следствие нашей работы у нас много компании у всех этих компаний разная инфраструктура разные операционные системы разное ядра разные версии postgres quelle вот все разное никогда не было такого что у нас один клиент и у него все также как у второго и соответственно вместе с этим у нас могут быть ограничены возможности внутри среды то есть у нас нет полноценного доступа как у штатных администраторов вот как правило мы не все можем сделать соответственно для этого мы разрабатываем специальные инструкции определяем регламенты как мы с ними работаем соответственно здесь увеличивается время решение каких-то проблем и задач то есть мы смотрим на проблему говорим что сделать вот штат администратору справляют проблему иногда в некоторых компаниях нам дают полный доступ здесь как бы эта проблема снимается вот варианты решения если вернуться база данных от один из важнейших элементов эта проблема решается предварительном тестировании любых задач автоматизации или управления конфигурации то есть перед тем как что-то внедрять в продакшн мы это все тестируем проверяем и смотрим что все это работает как положено единоразовый характер задачи он решается ad-hoc операциями то есть мы написали одну задачу которую мы хотим выполнить на нескольких серверах мы его тестировали запустили она у нас все это решило другие проблемы вторичные они решаются через дипломатию переговоры то есть мы с ответственными лицами договариваемся что и как будет делаться вот гетерогенная гетерогенная инфраструктура решается грамотным выбором инструмента то есть нужно выбрать инструмент который позволяет хорошо работать такой с такими средами то есть который позволяет работать с разными операционными системами и хорошо учитывать эти детали и моменты и так подходим вопросу где автоматизировать хорошим хорошими кандидатами для автоматизации нас подходит как раз таки задачи управления по задача управления версиями конфигурациями сервисов то здесь все просто мы устанавливаем люба удаляем обновляем пакеты вот изменяем бы их параметры конфигурации вот управляем сервисами там запускаем устанавливаем делаем их reload либо перезапуск следующий вариант следующая задача это развертывание репликации в принципе он похож на предыдущий вариант потому что репликация тоже по сути мы определяем конфигурацию для двух серверов запускаем сервисы и проверяем что репликации у нас запустилась и работает также хорошо автоматизируется задачи балансировки запросов по сути здесь мы меняем конфигурацию балансирующего балансирующего приложения вот и перезапускаем сервис значит тоже довольно таки просто и очень легко автоматизируется следующая задача свеча верфей lover это задача довольно-таки редкая вот но ее также можно автоматизировать и автоматизируете и зачем чтобы если возникла у нас нештатная ситуация мастер упал мы можем легко запустить failover там одним нажатием кнопки и у нас все сделает переведет приложение новый сервер выключит старый вот проверит что все работает что приложение могут соединяться с базой данных вот возобновить соединения что приложение могло дальше работать то есть это может быть частью восстановительных инструкций случае аварии обновление апгрейт это одна из тех задач которые нужно делать очень осторожно вот если минорный апгрейт минорное обновление делается довольно таки легко мы заморозили соединение приложений у нас ждет мы перезапустили после сервер он у нас обновился мы отпустили соединение все начал работать то есть приложение переживает обновление минорное довольно-таки легко и безболезненно the great нами норна мажорную версию делается не всегда тривиально если задача а если база простая и в ней нет никаких там кантрипов нет никаких там расширений каких-то библиотек сторонних то обновляется на тоже довольно легко однако если там месте такие вещи то здесь нужно все проверить такие же библиотеки подгрузить в новый каталог в новый кластер и также все это настроить вот после перезапуска со известно нужно проверить что все у нас обновилась что все загрузилось и работает исправно следующие задачи которые нельзя автоматизируйте почему анализ отчетов и мониторинг его нельзя автоматизировать потому что каждый день вы получаете отчеты они могут быть разные то есть сегодня вас топ запросов выглядит таким образом завтра вам будет другим то есть мы смотрим на то содержимое отчета которое есть у нас и уже на основании этих данных мы уже делаем вывод что он будем делать то ли мы создадим индекс здесь то ли нам следует переписать запрос в более другом виде вот и задачи простого обслуживания то есть нам нужно удалить какой-то индекс которые не используются этом а также смотрим по отчетам то есть мы видим что у нас этот индекс уже давно не использовался моего просто удаляем устранение blot тоже довольно таки такая такая задача которой непонятно когда делать мы можем обнаружить что у нас таблицы раздулись и мы вынуждены доделать то есть нельзя сказать что это надо будет делать там каждый день каждый каждую неделю каждый месяц резервное копирование валидация бэкапов здесь все делается через cron то есть мы в корм поставили задачу она каждый день работает там и все мы про нее забыли ее она и так уже автоматизировано громом инструменты которые мы можем использовать для автоматизации здесь есть две группы это могут быть самописный скрипт и которые написаны на цели пирлипат они либо на каких-то других языках программирования и которые выполняются с помощью подключения через sage либо через такие инструменты как подписавший кластер саша то есть когда вы набираете подключайтесь группе узлов и с помощью центрального плаваете команды и они исполняются на всех узлах следующий группу инструментов это специализированные системы управления конфигурациями и автоматизации это поперчив и джинсов транссибу если рассматривать первую группу the script и эти довольно удобно и в какой-то момент но не потом становится головной болью они появляются того что сначала администратор хочет решить какую-то задачу написал простой скрипт для автоматизации какой-то вещи и пользуется им дальше больше он придумает еще какие то скрипт и пишет их и пользуются ими этот вариант очень хороший поскольку он позволяет реализовать самую разную логику в этих скриптах и они довольно таки гибки однако если эти инструменты пишут несколько человек то здесь появляется такой момент как каждый специалист пишет по-своему и здесь появляется индивидуальность и программирования каждого человека вот соответственно здесь нужен регламент написание и code review чтобы кто-то смотрел что все написано правильно по правилам и все замечательно вот если регламент не соблюдать то есть высокая вероятность ошибок то есть мы что-то там написали изменились скрипте запустили его а он не работает или что-то сломал вот ну и поддерживать такие скрипты довольно тяжело если человек который писал раньше ушел на его место пришел другой то новый человек потратить довольно много времени чтобы это все разобрать вторая группа это уже специализированные инструменты вообще и инструменты разрабатываются компаниями имеет очень хорошую поддержку сообщества вот с помощью этих инструментов можно проводить в дефекацию инфраструктуры сделать все одинаковым то есть у вас не будет там разнобоя в инфраструктуре что там 1 здесь другое вы все сделали там одна операционная система везде на всех серверах одни конфиге системные настройки совпадают limit & cis ктл все это как бы более-менее одинаково сержа который plant одну и ту же роль и однако эти инструменты имеют дополнительные затраты на сервера как правило сервер центральные должен иметь как бы выделенное место в инфраструктуре агенты которые становятся на другие сервера они подключаются к этому серверу и берут там данные о том что нужно сделать вот поэтому это является таким минусом вот но с другой стороны снижается административные издержки человек который раньше занимался об этом или чифом в другой компании он легко сможет начать это использовать там в другой компании его не составит большого труда и не надо вовлекать проблемы вот и все эти инструменты имеют веб-интерфейс на на платной основе вот и позволяют как бы не совсем опытным специалистам начать легко их использовать проблема выбора что выбрать из этих инструментов я отнес проблемы в двух двум лагерям то есть первый лагерь это ч web api cf engine на мой взгляд они ориентирована на разработчиков поскольку для написания рецептов они используют языки программирования например чиф и пакет используют руби cf angel использовать свой язык вот и людям которые уже имеют опыт программирования им будет достаточно легко их начать использовать соответственно люди которые не имеют программировать или либо не программировали раньше им придется изучать языки и кривая обучения может вырасти вот и все эти три продукты имеют clean серверную архитектуру то есть при выборе стоит помнить что вам придется развернуть центральный сервер и использовать агенты на других узлах следующий лагерь это султан силу вот я считаю что не ориентирована системных администраторов и на людей которые не имели опыта программирования вот они используют своей внутри себя они используют так называемый ямале это формат реализации данных похоже на язык разметки вот то есть рецепты все пишутся на этом ям ли вот и исполняются с помощью но эти рецепты исполняется уже если рассматривать суд то у него также клиент-серверная архитектура и у него достаточно хорошие возможности масштабирования мастера сул довольно таки хороший но он все становится все уже не и жене и вот скоро он станет таким же как чиф и popped тут интересно рассмотреть и ansi вал вот у него достаточно интересные возможности вот он не использует клиент серверную модель вот у него нет выделенного сервера таким образом вы можете написать рецепт и хранить их в репозитории либо на локальном диске и при необходимости запускать то есть таким образом ваш обычный рабочий ноутбук разработчика становится центром управления инфраструктурой то есть вы можете находясь там где угодно подключившись по vpn к своей сервер серверной сети вы можете уже какие-то действия выполнять здесь нужно организовать грамотный доступ к репозиторию поскольку нужно защитить эти данные вот и также в этих рецептов может содержаться информация о том как подключаться к серверам а то есть реквизиты подключения пи адреса лагин и вот и несомненным преимуществом ancilla является то что он до жути простой вот именно легко начать пользоваться у него достаточно хорошая официальная документация и чтобы начать его использовать достаточно прочитать ее как начать это делать предположим что у вас ничего этого нет вы стоите перед выбором что нужно это все автоматизировать нужно что-то начать делать для начала нужно определиться с кругом задач что вы хотите решать этими инструментами если у вас много задач вы хотите покорить всю инфраструктуру то вы можете выбрать любой абсолютный инструмент вот поскольку в ходе реализации этих задач вам все равно придется выучить язык и использовать и в ходе использования вы поймете подходит он вам или нет но с другой стороны вы можете просто потерять время если выберете не тот инструмент в этот вот уже плохо нужно оценить время затрачиваемое на задачи то есть вы прикидываете сколько вам нужно потратить времени есть у вас время на реализацию задач автоматизации или конфигурирования если у вас мало времени вы можете начать использовать ansi был он довольно простой его можно сразу же начать использовать написали рецепты запустили отработали посмотрели результат не нужно разворачивать серверов агентов все просто написание рецептов на тестовом окружении то есть перед тем как что-либо внедрять production крайне рекомендуется все это тестировать зачем если вы что-то сломаете на продолжение то будет плохо это будут самые неожиданные последствия поэтому все рецепты необходимо тестировать таким образом вы сможете наработать опыт эксплуатации этих инструментов и убедитесь что да это мне подходит или не подходит вот ну и затем когда вы уже на тестовом окружении это все проверили вы можете переходить уже к использованию в продакшн нагружении и вот уже осталось и минут расскажу несколько страшилок вот самая банальная задача это выполнение задач не там где-то должно быть то есть мы разворачиваем какой-то рецепт мы запускаем рецепт вот рецепт отработал успешно конечная проверка вернула что все выполнилась хорошо однако но музыка закрываем в трекере задач задачу что все закрыты все сделано однако постановщик задачи говорит нет ничего не работает всё как было так есть начинаем проверять смотрим что в рецепте был указан не тот сервер то есть мы не нигде ничего не сделали сделали таком был совершенно другом сервере то есть следует проверять содержимое рецептов это что там внутри другая ошибка это вот помещение не тех серверов по балансировке то есть у нас были балансировщик и мы значит нужно было один сервер добавить туда то есть в эксплуатацию взбили реплику нужно было запрос на чтение послать на распределить между новыми узлами добавили задача завершилось все мониторинг начал сигналить о том что он не может прицепиться к одному из бэг-энда указаны в пули начали смотреть указали совершенно не тот адрес то есть тоже нужно проверять как всегда ошибка в регулярных выражениях это история которую мы рассказывали коллеги здесь задача состояла в том что нужно было провести массовое изменение в конфигурации мы в шаблоне сделали значит все эти изменения вот для поиска параметров использовали регулярное выражение запустили рецепт рецепт не сработал проводилась это все он тестовым окружении слава богу вот и что обнаружили в регулярной в регулярных выражениях были допущены ошибки в итоге после вскоре сервис остановиться остановился но при попытке подняться он завершился ошибки потому что конфиг файл был сгенерирован с ошибками и он его просто не мог прочитать get great здесь тоже задача была неправильного алгоритма тестировали на тестовом окружении вот и делали мажорное обновление когда провели ппв great он завершился удачно но до запуска новой службы старый каталог со старой базы удалили начали запускать сервис а он не запускается там были ошибки чтения и существующих файлов известно задача зафейлилась вот мы процедуру удаления старого каталога просто вернули вот следующая задача это из серии тяжелая миграция во время миграции добавляли колонку и проставляли дефолтное значение задача делалось на таблица с очень высокой конкурентной записью в итоге alter ты был зал учился ожидая когда транзакции завершатся а новые транзакции подвезли ожидая когда alter ты был за до работает ну и соответственно там кончились соединение вот и alt и был пришлось его грохнуть вот и alter ты был потом сделали без простановки дефолтного значения значение потом провели в фоне вот пачками все это обновили вот другая задача администратор решил почистить логе то есть в подгрести есть такой параметр логвин duration statement то есть он фиксирует те запросы которые больше определенного времени значение этого уменьшили соответственно лакируется запросов стало больше логии выросли в размере причем значительно и администратор решил почистить логе чтобы вернуть место ответственно удалил каталог побег слог где хранятся журнал транзакций базу данных остановили и с помощью утилиты расти так слог откатили изменения но часть транзакции потеряли вот следующий случай это тоже заряжало забыли что-то поправить делали диплом тест на астре джин hawaii окружении вот рецепт исходники рецептов взяли из уже существующего рецепта соответственно рецепт поправили под необходимые нужды но сервера которые указаны в рецепте их оставили как есть соответственно тепло и произошел с адресами для продакшена когда команда тестирования начала тестировать вот оказалось что они достигнут тестировали социальные сети они в группы социальных сетей на постели своих тестовых данных в итоге тест но социальных сетях в группах появились тестовые данные о слава богу они ничего другого не на портили вот и случайно вставкой из 6 в корневую knots sh ch это кластер из аж когда вы открываете несколько консолях сервером у вас есть центральная консоль для ввода команд выводите в этом консоли команды они исполняются на всех остальных серверах вот и администратор у него в руке была мышка средней кнопкой мыши как известно составляет содержимое буфера обмена нет он был и не 6 это перезагрузка здесь иногда он ставил и нет 6 у него был символ перевода строки он все сервера отправил в перезагрузку вот это такой случай у него был и ложный запускал то failover процедуры здесь та же история рассказана коллегами у сотрудника у одной компании было of the flower то есть если что-то происходило с мастером он запускал процедуру превращение резервной резервного сервера в мастер вот там что-то было с проверками в итоге они обнаружили что у них все там поехала все начала работать с другим серверам вот такая проблема вот какие уроки можно из этого вынести о компании должны быть должна быть команда дежурных инженеров которые должны входить как администратор так и разработчики это команда устраняет все аварии в любое время дня ночью судак вот то есть она должна быть наличие отлаженных процедур по устранению аварийных ситуаций это тоже неотъемлемая часть вот должны быть инструкцией на то как выполнять как пуп как искать проблема во время аварии как выполнять процедуры если вдруг что-то упало отказал мастер отказали приложение потеряла сеть то есть наличие таких процедур гарантирует что аварийной ситуации будут устранены быстро и в срок вот наличие тестового окружения для проверки это обязательно потому что все рецепты которые мы будем внедрять в продакшен они должны быть проверены что они работают как положено и не убьют нам нечего вот семь раз проверь один раз отрежь что всю нужно проверять потому что наличие даже самые совершенных инструментов совершенной техники но не может спасти от человеческих ошибок которые могут возникать"
}