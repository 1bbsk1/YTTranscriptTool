{
  "video_id": "nzuUad_8Avc",
  "channel": "HighLoadChannel",
  "title": "Серьезный ритейл / Александр Лищук, Дмитрий Цветков (X5 Retail Group)",
  "views": 854,
  "duration": 2661,
  "published": "2019-05-14T14:52:35-07:00",
  "text": "мы хотим рассказать вам историю формате timeline фторида про тот период когда мы превращались как нам показалось в highload про те шишки которые мы набили и так далее и надо по темизация системы нашей работает в большое количество динамичной команды большое количество людей и мы постараемся максимально раскрыть все аспекты мой коллега дмитрий цветков как бы сверху с точки зрения оптимизации по и я александровичу к с другой стороны с точки зрения оптимизации инфраструктуры какой-то ну и небольшая вводная часть что было понятно о чем мы говорим компания x5 retail group это крупнейший продуктовый ритейлер страны насчитывает включает себя больше 13 план тысячи магазинов различных форматов от магазина у дома до гигантского гипермаркета это пятерочка перекресток и карусель ну и соответственно в каждом из этих магазинов может быть от нескольких тысяч до нескольких десятков тысяч товаров в ассортименте ну и многие ключевые процессы бизнес-процессы для каждого за эти магазинов протекает в единой централизованной rp системе и ее производительность соответственно но край крайне критический показатель например каждую ночь для каждого магазина для каждого товара необходимо за несколько часов посчитать несколько вариантов цен учитывая множество различных факторов все это отправить в магазин и при этом параллельно получить какие то данные о текущем продажам опять же для каждого товара в каждом магазине спрогнозировать дальнейшее потребления поставки на завтра на три недели вперед сформировать заказы согласовать с магазинами и тогда ли тому подобное все по принципу домино если мы вовремя это не сделаем мы напрямую impac темно покупательский опыт в магазине то есть если это во время что то не сделать соответственно не успевают прийти товары покупать приходит магазин чего-то не видит он недоволен расстроен огорчен ну или например приходит с прошивкой по поводу каких-то распродаж и скидок а цена совершенно не такая соответственно ну айти x5 не rp единым это более 1000 различных эти специалистов сотни проектов множество платформ и стыков сегодня 2018 год и понятное дело что в ритейле без современных технологий уже некуда это аналитика больших данных и мобильной экосистемы роботизация в том числе и распределительных центров ну работа очень много и так далее но вернемся к виновницей нашего доклада немножечко тактико-технических характеристик что памяти понимаете о чем идет речь это классическая трехуровневая архитектура сервис на ленте ориентированными элементами сверху у нас более 5000 толстых клиентов непосредственно сотрудников терабайта информационных потоков между каждым магазинным каждым распределительным центром с от элитными системами которые занимаются другими функциями плюсы детей для аналитики так далее тому подобное в слое приложение у нас s&p а баб но сразу предупредим что в нашем докладе речь пойдет не конкретно какой-то платформе принципе здесь могло быть что угодно это какой-то open source с живые над живими что-то на других каких-то фреймворков 1с в конце концов мы скорее всего столкнулись бы с типичными одними и теми же проблемами плюс-минус и для понимания sap abap это вот наше решение это более 10000 процессов на сгруппированы на 50 a british на серверах linux каждый процесс упрощенно говоря это некая виртуальная машина который исполняет байт код на языке а баб достаточно ускоренным с множеством legacy и обратной совместимостью и в каждой виртуальной машине есть свой дпс кросс-платформенным диалектом опыт эскель свою рей мэмри менеджмент кэширование реализованы в виде буферизации и прочие такие вещи ну то есть в принципе много других платформ обладают теми же свойствами и снизу у нас oracle database на x power почти к энди соответственно это сингл база данных никакой кластеризации более 100 терабайтов данных около 15 и даже больше чем j в день судя пологом ну и соответственно интенсивность нагрузки полмиллиона запросов в секунду и это не пиковая нагрузка сейчас бафферкафф где-то в районе скромный в районе двух процентов от размера базы ну и дополнительную пикантность к этому к этой нагрузке добавляют то что она распределена по времени у нас несколько профилей нагрузки этой дневная и ночная пакет на параллельно обработка housekeeping в свободное время 24 на 7 тысяч пять дней в году система должна быть доступна 99,9 процентов времени в году к тому же плюс еще довольно жесткий и насыщенный релизный цикл которая добавляет некоторых трудностей но это сегодня это самая крупная sap erp система в россии стабильная прогнозируемая и готовая к росту и развитию далее но раньше было не так и 3 итак начнем историю с постановки проблемы далеком 2014 году компания насчитывала порядка пяти тысяч различных магазинов при этом система работала на дорогостоящем ханенде но уже ряд бизнес критичных процессов находились на грани срыва вкусовые и наряде ресурсов испытывался наличие ботаников к тому нагрузку системе было не масштабируема прошла нелинейно при линейном росте количества райдеров нагрузки нашем случае количество магазинов и количества товаров также головную головную боль для нас представляли планы бизнеса по росту количества магазинов два раза примерно до 11000 в течение трех лет мы понимали что у нас большая проблема и решите мы ее никаким наращиваем аппаратных мощностей мы не сможем и мы проработали методику оптимизации которая позволила нам достичь бы линейного роста нагрузки и сократить длительность выполнения бизнес критичных процессов методика оптимизации в целом представляют собой цикличный процесс состоящие из ряда этапов на и так мониторинга мы определяли узкие места и топ потребителю ресурсов в процессе анализа в ходе профилировки выявленных кандидатов на оптимизацию проявляли конструкции которые являлись причиной не линейного роста нагрузки либо наличием узких мест в процессе разработки применяли ряд приемов которые впоследствии включили в регламент разработчику чтобы в дальнейшем при развитии системы не было проблем с производительностью позже мы об этих приемов поговорим в первую очередь мы озаботились реализации инструментов мониторинга которые позволяли бы нам решать ряд задач таких как получение в реальном времени информации о здоровье системы с целью обеспечения работы группы оперативного реагирования также поиск узких мест и топ потребителю ресурсов которые порождали наличие этих узких мест и долгосрочное планирование наращивание мощностей в качестве инструментов мы в или пластик search графина с помощью самописных коллекторов мы реализовали сбор метрик как и из инструментов поставляемых вендорами так и обогатили мониторинг достойными метриками например такими как время отклика и пропускной способности специфичных для приложения компонентов и бизнес метриками количество магазинов длительность выполнения критичных задач впоследствии появились и новые метрики о которых будет рассказано в последнем разделе доклада прежде всего мы приступили потому что снижали снижали нагрузку на систему за счет более равномерного распределения нагрузки большинство критичных процессов большинство бизнес-процессов представляют собой объем представляет собой обработку большого объема данных по всем магазинам который является процессом состоящих из последовательных этапов обработки для обеспечения обработки в рамках крупных задач использовался самописный диспетчер него самописный диспетчера в пакет на параллельной обработки дальнейшем будем называть его планировщик нагрузки отдельная отдельный этап обработки по отдельным магазин в данном случае считаются пакетом изначально логика планировщика было такого что сначала выполнялся первый этап обработки по всем магазинам следом за ним второй этап и так далее это приводило к тому что в один момент времени в системе работала большое количество процессов которые подавали однотипную нагрузку и вызывали деградацию какого-то конкретного ресурса будь то вот вы в на базе данных тепло на серверах приложений или спал на базе данных мы переписали логику планировщика таким образом что теперь цепочка пакетов выстраиваются отдельно по каждому магазину и приоритет запуска но в пакетов выстраиваться не не по этапам не по шагам а по магазинам то есть если по магазинам завершился первый этап обработки то освободившийся процесс отдавался на выполнение следующего этапа обработки они того же этапы по другому магазину таким образом мы так мы достигли одновременного выполнения разнородных разнородных процессов когда которые подавали различную нагрузку на систему и более равномерное распределение во времени нагрузки на ресурсы достигнув более равномерное распределение нагрузки мы приступили индивидуальная оптимизация выводов процессию профилировки конструкции которые являлись причиной не линейного роста нагрузки либо наличием узких мест рассмотрим прием которые применялись в частности избыточная нагрузка на цп усеру в приложении зачастую была вызвана наличием не линейных алгоритмов в коде программы для решения проблемы заменяли нелинейно алгоритмы линейными например в наших случаях это использование линейного поиска в цикле заменялась двоичным поиском ну а также применялись более оптимальные алгоритмы слияние пересечения множеств избыточная нагрузка на цп у базы данных зачастую связана с неэтичными обращениями bt с одними и теми же условиями для снижения этой нагрузки применялась пищи ранее результатов первой выборке в памяти программы в глобальной переменной либо на уровне сервер приложений для обращение уже при последующих вы барков выборках казака ширан им данным в некоторые пиковые часы нагрузки на циpкa и вот вывод базы данных причиной этой нагрузки были частые join запросы конечно выполнять операцию джона желательно непосредственно в базе данных но с целью переноса нагрузки с не масштабирована во сервера базы данных на масштабируемые сервера приложений мы применяли расщепление этих зон запросов на простые выборки результат которых зафиксирован на уровне сервера приложений и выполняли логику join уже непосредственно в программе ряд ситуаций в которых мы упирались в потолок пропускной способности ввода-вывода на базе данных был вызван тяжелыми запросами для оптимизации которых применяли представление данных в менее нормальной форме более детально рассмотрим этот случай классический пример из нашей системы в нормальной форме в мастер в таблице в таблице заголовков содержится поле даты документа в поле позиций содержится палят товары магазин наиболее частые выборки влияющие на нагрузку на вот вывод эта выборка всех бухгалтерских документов по конкретному магазину за определенную дату при этом фильтр по дате по таблице заголовков примерно возвращает около полумиллиона записей аналогичное количество вращать фильтр и по магазину по таблице позиции при этом после склеивания на выходе по конкретным магазин за определена дата мы имеем три тысячи строк таким образом независимо от того с какой таблицы начинать фильтровать и склеивать данные мы получаем достаточно большое количество операций ввода-вывода которые нам удалось убежать приведя модель данных в менее нормальную форму мы дублировали заполнению поля документы в таблице позицией обеспечивали наличие индексов для более быстрого поиска по таблице позиции таким образом пожертвовав наличием место в табличных пространств для хранения нового полиса без позиции индексов для поиска мы в разы сократили количество операций ввода-вывода так как сейчас фильтрацию же производстве по средств сразу по таблице позиций и возвращают вещь требуем требуемый объем данных так команда по оптимизации проделала огромную работу система встала на линейный рельсы стала линейно реагировать на рост нагрузки на на рост драйверах нагрузки то есть магазин ассортимент все было здорово большинство battle.net в классических там а елси пью там сям и вот это все оперативно решалась или обходилась но без драмы тоже не обошлось где-то концу 2016 года мы все сильнее осознавали что мы уперлись производительность 1 кор сервиса платформы речь идет о так называемом сервер блокировок самой платформы sap abap это простой сервис его задача реализовывать лтп на уровне сервер приложений и он это один процесс обычно где-то рядом недалеко от базы данных он в одном потоке занимается простыми операциями с какой-то структуры в памяти несколько треков там еще ему помогают общаться с процессами сам рабочими процессами ну и соответственно это атомарные операции в памяти он кое-что еще там при этом бэк бэк ложит файловую систему скилла у тут не пройдет и наши попытки его ускорить во-первых разработчики это проприетарный код и разработчики выпустили для нас какой-то патч который немного ускорил его производительность и мы переносили его на более производительное по частоте процессора железо различные тюнинг на уровне операционной системы ввода-вывода и так далее ну и собственно серьезно это не помогало его паспортный пропускной потолок был где-то 5000 операций в секунду нам было нужно 10 ну мы кое-как до этого порога дошли соответственно синтетическим тесты нагруженным мы поняли что деградация происходит не линейно и у нас есть какой-то порог допустимо деградации этого сервиса до которого мы этого еще критичные ощущаем системе но даже несмотря на все вот подвижки по ускорению мы оказались в тупиковой ситуации потому что уже у границ его производительности а нам дальше еще по магазинам расти ну в общем что называется потрачено вердикт разработчиков был простой холодный ну и логичные это все он так работает это хорошо вам нужно переделать саму архитектуру вашего решения окей это грустно безвыходная ситуация но в любом случае чтобы переделать вообще целиком с решением большой такой р.п. нам нужно какое-то время выиграть и мы стали искать пути как собственно ну ускорить его хоть чуть-чуть еще было какое-то время дальше пройти ну и первое что необходимо было попробовать сделать очень много времени тратил сервис на операции ввода-вывода для того чтобы кое какие операции фиксировать файла системы это нужно для отказоустойчивости в случае какого-то дизайнера сервиса да он упадет поскольку мы поднимем эти операции информация не поднимется из файла системой ну и мы не получим ни какой там некая системности и так далее но для нас было важно лишь небольшая часть этих операций действительно longran и которые долго идут и случае дизайнера мы будем очень долго восстанавливать ну и соответственно мы попробовали ну это кроссплатформенное решение давайте поэкспериментируем с другой операционной системы потому что в аяксе мы уже покрутили все что можно и дальше не как он действовал практически синхронно достаточно олдскульный scheduler ввода-вывода и так далее мы попробовали linux перенести его туда и на той же машине на самом мощном фаворе который у нас был с частотой выиграли значительно по времени то есть сервис с включенной записью файл системы в принципе вёл себя точно так же как на exec отключен ну и главный выигрыш том что там оптимальный нужно еще постараться чтобы сделать нормальный синхронный вот вывод директ а ее судя по трассировка не происходил ну и соответственно использовался file system cache мы еще там потеряли scheduler и ввода-вывода и так далее то есть добились какой-то оптимальной скорости отлично у нас много времени классно мы подняли планку практически в два раза ну подумали но почему дальше не начать экспериментировать и взяли один из наших бойцов которые мы используем для сирот приложений и перенесли этот код туда и получили фантастически фантастическую еще более полога эту кривую деградации его производительности чем на предыдущих машинах ну это выглядело довольно забавно потому что ну можно подумать что сайкса малину sn2 разработчика просто дед не договорились и получалась такая разница но здесь уже влияние impact оказывает и архитектуры процессора и какой вывод мы из этого сделали не то что какая-то платформа круче другой это совершенно не так мы когда выбираем какой то message broker или базу данных для аналитики специфичные мы всегда выбираем из нескольких и для каких-то задач это платформа подходит лучше для каких-то хуже то же самое и с классическими серверными архитектурами то есть какая-то платформа сейчас может прекрасно жонглировать многопроцессорные огромными многопоточные базами данных обеспечивает отказоустойчивость и все такое но какие-то специфичные задачи вполне может справиться и и даже может быть лучше какой-нибудь процессами на другой архитектуре и соответственно если мы отказываемся сознательно на стадии проектирования от кроссплатформенность и может быть мы еще можем отказаться от некоторое пространство для маневра в случае если прижмет окей с этой проблемы мы вроде как разобрались запасов сервис стал работать три четыре раза быстрее этого запаса нам хватит на годы вперед и носить время как то наперёд передумать перепланировать свою архитектуру все отлично но наша радость была бы неполной если бы не следующий battlenet который мы уперлись буквально через полгода и фария и роста по рельсам мы стали ощущать серьезные проблемы сципиона бы цепью на базу данных они были необычные то есть понятно с ростом нагрузки у нас растет потребление процессора всего вроде логично но проблема в том что все большую часть этого процесса во времени стал занимать сиз time ну и явно что-то не так у нас в ядре почему то какая часть себе сколов начинает серьезно буксовать окей мы начали разбираться нам понравилось делать всякие синтетические нагрузочные тесты прошлых наших приключениях и мы сделали простенький тест в базе данных в 1000 табличек с одной записью мы там в тысячи потоков в их selecting мы с максимальной нагрузкой ну и соответственно тут работает баффер кэш цепова баз данных ядро операционки ядро самой б д ну естественно сетка и поняли что наша пропускная способность такая останавливается где-то на 300 тысяч операций в секунду то есть миллиард запросы в час дальше начинается деградация и она явно где-то в ядре операционки но в настройках сети потому что школы были сетевые ладно пока мы там сели разбираться с проблемой нужно было как-то спасать ситуацию потому что нагрузка на систему становился уже очень серьезную мы встали все медленнее впереди как бы паровоз едет дальше соответственно в оптимизации был принят новый постулат дополнительный который звучит так оптимальный запрос тот которого нет запрос может быть быстрым и классным оптимальным вызывать слезы радости у die bei но самый главный вопрос который нужно задать а так ли он вообще нужен и мы стали делать скажем так и ревизию тех запросов которые у нас приходит в базу это запросы с низким кпд который там сто тысяч select of вернул 100 строк или вообще ноль переработку если мы не можем избавиться от 0 результаты но это что же результат давайте попробуем сделать какой-то негатив кэш если это уместно конечно же или например у нас множество параллельных обработок разных вещей в принципе все крутится вокруг там товаров например да и на одном серой приложение они спрашивают ну похожие вещи из одной таблицы ok давайте поднимем в кэш целый набор этих данных и пусть они эти процессы мучают сервер приложений они базу ну или например для allowed by land для распределения нагрузки у нас в принципе в этой цепочке шагов обработки для одного магазина разные шаги могли скакать по разным хирон приложения и вроде классно только на каждом этапе они в принципе начинают спрашивать одно и тоже из базы тогда мы сделали так что первый шаг поднимается на при кончине что-то там кэширует и остается дальше на нем вот ну и так далее тому подобное многие разные такие мелочи тут пять процентов там 10 ускорений и так далее в итоге мы получили значительное снижение нагрузки на базу мы уже нам уже оказаться не нужен миллиард запрос в час здорово система жила все стало более-менее отлично и в это время мы как раз разбирались проблем этой сети на аяксе и по классике в принципе у нас никто не было проблем с леденцы сетевое дров гидросеть и был достаточно производительная и в сервере все шнуры ethernet вот эти вот они были сгруппированы большую широкую трубу ну во имя пропускные способности и неубиваемость и алекса есть некое такое приключение то есть он даст ну на том же железе который нас было мы достигали 300 тысяч пакетов в одну сторону в секунду это был лимит дальше начинал расти системе ну и соответственно не workaround в этой ситуации был такой что мы нашу трубу разбили на несколько сетевых интерфейсов и группу серого в приложении отражение разбили на группы и каждый обращался к своему таким образом там с добавления нового интерфейса общей максимальной производительность каждого она конечно немножко снижалась но суммарно мы разогнали сетку до миллиона пакетов в одну сторону секунду этого нам хватило вот так вот как бы проблема была в принципе решено а на будущее мы себе эту галочку отметили ну и сам подход что оптимально запрос тот которого нет он был добавлен великий манускрипт для разработчиков чтобы никто о нем не забывал в процессе уже написания кода вот и вроде бы катарсис дальше мы бы выросли все было бы прекрасно все костыли ошибки шишки набили но нет дима ну и перейдём к следующей проблеме которая случилась нас 2017 году и связано было с нехваткой ресурсов циpкa сервер баз данных при этом код системе было уже достаточно оптимизирован и избавлен от наличия конструкций которые вызывали не линейный рост нагрузки однако связи с ростом количества магазинов увеличились увеличилась длительность выполнения критичных процессов и некоторые крупные задачи стали пересекаться друг с другом по времени выполнения и в эти периоды времени мы стали наблюдать что чем выше нагрузку на полу база данных тем медли работает каждый процесс при том что запас утилизации составляют примерно 10 20 процентов таким образом в нашей системе наблюдалось действия так называемого закона отдала система обладала неким лимитом парализации которые мы нередко достигали и при превышении этого лимита при вовлечении в обработку все большего количества процессоров снижалась производительность каждого отдельно взятого процессора уточнил что на тот момент у нас на сервере использовалась порядка 125 физических процессоров с включенным мульти трейдингом равным 4 итого у нас на базе данных было 500 и логических профессоров основные варианты выход из такой ситуации это апгрейт процесс голосования апреля был запущен оставалось подождать несколько месяцев почти год и просуществовать на текущем оборудование без нарушения силы процессе мониторинга мы поняли что традиционные метрики очереди на цпу и текущие утилизации циpкa не показатель на нашем случае не позволяют определить факт наличия деградации в системе и мы решили использовать натуральную метрику производительностью которая однозначно нам показывал мы наличие или отсутствие факта деградации в системе в качестве этой метрики мы взяли длительность выполнения синтетического теста и определили что при нагрузке 67 80 процентов длительность выполнения теста начинает возрастать и при нагрузке 85 и выше процентов производительность процессоров многократно в 4 и более раз падает приняв во внимание показания новой метрики и критичные пороках нагрузки при котором начинает многократно деградация в пиковые часы нагрузки мы стали вручную ограничивать количество процессов отдаваемых планировщиком нагрузки с целью снижения с целью снижения нагрузки и повышения производительности процессоров однако ручной контроль был неэффективен так как в системе регулярно соответственно расписание выпускается большое количество планировщиков нагрузки и они успевают запланировать на выполнение пакеты до ручного вмешательства таким образом деградации системы иногда все еще наблюдалось кроме того нам надоело просыпаться по ночам с целью сдерживания подача нагрузки и мы решили автоматизировать этот процесс переписали свой планировщик нагрузки таким образом что теперь это планировщик с обратной связью который регулярно анализирует текущее показание метрик производительности в этом случае это очередь на пути пусть утилизация циpкa и длительность выполнения синтетического теста и при превышении настроенного желтого порога замораживает планированию пакетов при нормализации нагрузки приоритет планерный пакетов при этом был у бизнес критичных процесс таким образом в автоматическом режиме нам удается управлять интенсивностью подачи нагрузки таким образом что не наблюдается деградации системы и ресурсы используются наиболее эффективна в целом мы рассказали о проблемах с которыми сталкиваюсь в процессе развития нашей йорке системы и подходах которые применяли для решения этих проблем резюмируя можно сказать следующее обеспечите свою систему мониторингом производительности и анализом то потребителю ресурсов на старте проекта включите в цикл разработок процедуры по анализу производительностью и оптимизации с целью достижения линейного роста нагрузки при линейном росте количества драйверов нагрузки так как затраты на доработке в на порядок ниже чем затраты на android оборудование при этом могут иметь гораздо больший эффект оптимизируя сковали запросы помните то что быстрый час ты за быстрый запрос это хорошо но быстро и часто запрос могут могут привести к наличию проблем оптимально запросы тот который у которого нет возможности применять курсирования на уровне серверов приложений укрупнять и выборки экспериментируйте с различным платформами если вы испытываете наличие ботаником на каком-нибудь компоненте с гетеродина архитектуры возможно на другой платформе этот компонент будет более производительным также используйте в качестве метрик для мониторинга производительности не только традиционные метрики но и некоторую интегрального метрику которая однозначно вам будет показывать наличие наличие для отсутствия факты деградации системы в качестве эти метрики вы можете взять для есть выполнение синтетического теста и обеспечьте инструменты планирования нагрузки наличием механизмов контроля показания метрик производительности и снижение интенсивности интенсивности подачи нагрузки в случае многократно не градации системы на этом все готовы ответить на все интересующие вопросы уточнить интересующие детали спасибо за доклад что будет еще через пять лет допустим ваша компания поглотит конкуренты еще раз продолжите ну смотрите мы этот подход продолжаем применять и на новом оборудовании и применяя все эти самые приемы мы обеспечиваю обеспечен рост компании на текущем оборудование ну и таким образом мы готовы вызван мы сталкивались уже с какими-то ограничениями такого решения с какими-то архитектурными да есть узкие места и понятное мы это держим в уме им продумываем и различные варианты в будущем мы понимаем что в один прекрасный момент у нас сможет просто большая часть времени какой-нибудь курсор пин с происходить и мы с ним уже ничего не поделать да в базе данных ну и соответственно планы bcd и так далее обязательно прорабатывать текущий момент система вот и и оптимизации производительности вот эти подходы они позволяют нам в принципе держать в прогнозируемом в контролируемом в состоянии там с той скоростью роста компании в которой вот он сейчас добрый день спасибо за доклад а у меня к вам два вопроса первый касается того железа который вы используете под dd рассказали проволоку количество физических славянский процессоров интересно еще происходи послушать и каким образом вы обеспечиваете отказоустойчивость решения суда и есть ли у вас какие-то там наверняка есть да в чем заключается дерпи план да как вы планируете случае какого то деза старого устанавливать такие объемы данных в том числе ну в плане допустим текущего железо сейчас эта платформа power и aix некий вчерашний high-end в принципе достаточно мощный отказоустойчивость опять же средствами того же объема реализовываем и кластеризацию то есть несколько систем есть скажу так запасная который готов подключиться в любой момент но при этом мы и раньше рассматривали сейчас рассматриваем и тестируем проверяем испытываем и в будущем уверен будем тоже это все рассматривать все возможное решение платформы которые сейчас есть в том числе и кластеризация на каких-то реках например из мы говорим об иракли в том числе и x86 решение крупные большие мы это и тестировали раньше тут вопрос на это влияет множество факторов в том числе ну в первую очередь выгода никто не будет постели zero вать ради того чтобы куну что такое стиле zerowatt в какие-то времена когда шпиндельные диски были доступны и а флешек можно было только мечтать потому что ценники на них были космическими ну понятно можно было там с помощью той же задачи или прочих выигрывать очень много но сейчас например те же flash массива они по цене уже начинают сравнивать старыми добрыми шпиндель ными решениями из ходы и скажем так сингл дтп с вполне справляется на самом деле с нагрузками если достаточно тонкой хорошо и настроить ну а говоря об исходя из сейчас это flash массив спасибо за доклад я немного дополню вопрос вот предыдущего человека 8 класс называется распределением нагрузки поэтапной искать девушку секундочку такой это единственная не хочет я делать ну да был вот там была жёлтая линия момента когда начинается деградация если я правильно понимаю это момент когда через восемьдесят пять процентов переходится получен гауди by правильно такая ситуация на полу серверах на серверов приложений есть момент когда время открыты начинает увеличиваться я понял вопрос в чем почему а именно сингл тебе архитектура доживая до таких времен но просто и не слышал даже про masters life ну или мастер мастер репликацию вашему накладе если такие решения рассматривались то интересно почему от них отказались ну первое что мне приходит в голову это 100 терабайт мастер мастер лиц и ровать ну да сложная задача вот во вторых вы не ответили про что будет если один ляжет ну то есть у вас второй сервер я так понимаю на него все равно нужно и плит сырой данные чтобы он поднялся когда один мой друг газ горит просто там пожар будет не знаю как вы будете восстанавливаться вот наверное нет если речь идет о том если из строя вышла из ходы в данном случае это восстановление из бэкапа есть и такой план восстановление ну в принципе все зависит от требования бизнеса и тех границ которые мы можем допустить недоступности времени системы сейчас у нас нет такого требования чтобы система была недоступна максимум там минуту и в принципе репликацию восстановления мы можем делать и средствами схд и инструментами самой платформы и так далее то есть 12 часов то есть это упал полностью поднять с нуля если на соду пойдет бомбы допустим дата была день с нуля это где-то около 12 часов бизнес подождет ну делегацию recovery у нас опять же так прорабатывается есть различные подходы которые мы уже подготовили в принципе на текущий момент ну есть некоторые сложности а про мастер своих мастер мастер почему именно из сингла тебе из-за производительности то есть один огромный сервер на 250 логических процессоров оказывается быстрее чем хоть какая-то импликация был te pido вот на нашу за . шо спасибо спасибо за доклад вот вы много внимание посетили тому что многие ваши процессы задачи и патчи в каким-то образом это оптимизировали то есть вы за счет того что мониторинг ввели вы смогли такт оценить и за счет мониторинга более оперативно могли находить узкими стоит у потребителя ресурсов так как для анализа tix тех же самых а вы рассчёты филимонов нужно время а такой мониторинг в реальном времени с помощью графа навело sixer чон нам позволил меньше времени тратить на поиск проблем и больше тратить на их устранение спуститься каждая задача и мелкие то свои там оценки там процессор у неё топ 10 и 10 11 но другого рода составлялась портале составлялась профилировка профилировка только потребителей ресурсов и в ходе профилировки выявлялась да какую нагрузку порождает тот или иной процесс почему в принципе какое вообще какие требования времени выполнения задач требование времени выполнения задач это к утру к открытию к открытию магазинов основные процессы должны завершиться заказ или актуальные цены и у каждого бизнес-процесса у него свои требования они все описаны их их сотни различных задач у каждого есть свой если какие-то границы допустимого времени завершения соответственно профилируется и время одна работа одного потока потом параллельный нагрузок на грустный тесты с парализации что посмотреть как он растет от времени нагрузки до там линейный линейным я то количество драйверов нагрузки даже в нашем случае магазинов то есть каждым процессу индивидуальный подход каждой задачи которые просчитывается внутри системы совершенно индивидуально несколько часов чего или нет это не на это ненормально понятным и у нас запаса времени не так много поэтому в принципе когда речь идет о контроле авто контроль и вот этой нагрузки то приоритетной задачей это допустим задача пакетная параллельная обработка которая не ждет и по она должна быть обработаны в первую очередь какие-то пользовательские ну условно за них выстрелы каких-то задач мы их можем сдержать если это приемлемо если нет ну понятно мы их тоже переложим в приоритетной это в случае если не хотите нет не зависит в пятерочке будет работать независимо но если процесс не завершается в срок на этой каше будут не актуальные цены без учета и не замечание в срок не допустим себя нет это прямо напротив прям на той же инстанции на том же сервере где база данных у нас есть инстанцию sap abap и на ней регулярно запускается программа которая выполняет синтетический тест и замеряет длительность его выполнения и это все а для поиска да и такая система тестов у нас но там всегда всегда всегда можно проявить какие-то хитрости до всегда можно принять какие-то хитрости нам не нужно там 3-х эндо чтобы тестировать у нас есть их 2 запасной он пока он не нужен он играет роль для системы но там уже есть какие-то механизмы которые мы используем без без whisper ну или do the bass какой-то до быстро для этого подогнать спринт все зависит от платформы framework и так далее начнем работать сама брик"
}