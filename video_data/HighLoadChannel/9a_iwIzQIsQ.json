{
  "video_id": "9a_iwIzQIsQ",
  "channel": "HighLoadChannel",
  "title": "Трансляция HighLoad++ Весна 2021, 17.05, зал 2",
  "views": 876,
  "duration": 33652,
  "published": "2021-10-04T02:49:43-07:00",
  "text": "и да на то смысле первая профессиональная конференция разработчиков высоконагруженных и сложных систем проектов highload плюс плюс объявляется открытой я бесконечно рад вас всех видеть я бесконечно рад видеть вас вживую я не знаю как я ни пытался мы попытались сделать порядка 20 онлайн of и сделали хорошее и многие очень необычные я не смог его полюбить ну я не смог я пытался честно все-таки мы пандемию показала что мы все люди вот такой нежданчик что мы все люди что нам нужно общение что даже для того чтобы впитать в себя информацию чистой информацию на все равно нужна какая-то эмоция что потом прийти и и например применить мало что-то узнать на конференции ты должен еще потом по этим ножками убедить начальство том что нужно сделать по-другому сотрудников коллег вообще что-то открыть скачать не знаю репозитории запустить нужна энергия и драйв и мы собираемся в оффлайне вот здесь вот в такой красивой обстановке такой драйвовый обстановке именно для того чтобы эту энергию получить вот почему мы идем вперед потому что мы профессионалы этот этот гимн аж мы придумали в 2014 году я вчера специально посмотрел 2014 году и он очень простой он про то что профессионализм состоит из двух вещей это любви энергии и знаний и опыта вот именно такие нашей конференции добро пожаловать так а теперь небольшая экскурсия о том как пользоваться конференцию всем привет если что меня зовут олег бунин организаторы конференции очень много одни одни из организаторов конференции ребят нас а 50 человек над конвой сейчас в залах 150 волонтеров помощников халк тимов кто угодно 150 самая большая и маленькая армия да вот и первым делом пожалуйста надевайте маски обязательно когда вы ходите в фойе когда общайтесь с людьми соблюдайте социальную дистанцию в общем мы вас бережем мы очень много сил приложили чтобы дезинфицировать все-все riser курировать но вы тоже пожалуйста следите за этим смотрите по маскам то по маскам есть одна важная вещь кто переболел ребят нам с вами ничего не угрожает но мы все равно будем носить маски ну у нас же на лбу не написано что мы переболели и человек который перед нами он может волноваться может беспокоиться того что чувствую без маски ходим и так далее поэтому я просто оденем маску из из-за того чтобы из уважение для того чтобы создать и для него в тоже безопасное пространство чтобы он не парился по этому поводу так хорошо и если вдруг у вас нет маски у нас на территории множество масок на всех выходах на стойке регистрации у любого организатора спрашивайте вам дадут даже с красивой маски на каждого дальше кто вакцине роуз парня девушками нам с вами точно ничего не угрожает но мы тоже будем носить маски из уважения для того чтобы для всех а не только для нас было безопасно чтобы никто не беспокоился и не волновался еще пара вопросов мы никому это не покажем трансляцию не пойдет здесь есть к вида диссиденты но то есть том плане что он это просто же гриб ну то есть немножечко медийной раздутый есть такие а а там мы с тобой ведь все равно наденем маску да просто чтобы никто не беспокоился мы понимаем что они все ошибаются реально но мы ну понятно что грипп сезонность слушай это все ясно мы умнее но маску мы наденем хороша так а есть те кто уверен что маски не работают потому что ну вообще но не работает понятно мы понимаем что все что это истерика на то есть как бы они все все все беспокоятся начинает вирус не понимаешь что вирус маленький он пройдет через поры маски элементарно но мы сами тоже оденем маску у нас их много меняйте их каждый час если они там не знаю еще что то выходите на улицу подышать но пожалуйста всегда и везде и всегда и везде из уважения к другим людям спасибо а теперь когда мы так долго говорили про маски давайте быстренько поговорим обо всем остальном пожалуйста прямо сейчас выключите звук своих телефонов чтобы не мешать спикеру и не мешать сидящим рядом возле вас звук телефонах у тут три страницы электролизера съел программа комитет highload очень большая структура очень большая структура то есть мы проработали импланту более 200 окладов по 300 что лиц во всей программе программно комитетов несколько работает на hail орган раз несколько цифр то есть есть программный комитет по архитектуре по machine learning у и так далее ну неважно да то есть мы готовили ивану год год то есть началом и он был полностью готов в ноябре но его перенесли обновили ну в общем короче эта программа выстрадана лучшая программа за все время которое минимум за год до минимум за год идем дальше расписание у всех у вас есть чудо книжечка на шее в ней много полезной информации так но самое важное это расписание этим очень удобно пользоваться не надо вертеть мы специально обучили наш типографии переворачивать листочки они научились встретил пару раз ну один раз перепечатывали один раз мы разбирали кольца перри собирали вообще обратите внимание пожалуйста у нас есть три расписание расписание в залах зала всего 8 в них записываются доклады это будет следующий зал следующий слайд есть расписание выставки у нас огромная выставка это тоже по-моему самое большое количество партнеров которые у нас есть за последние годы есть отдельное расписание дема выставки где партнеры будут разыгрывать призы где вечером будет хабар награждением компания пробует награждать за лучшие блоги обещают концерт обещает сюрприз автор и вечерняя программа и и вы можете посмотреть в брошюре выдается в зоне раздатки вот в конце брошюры также есть оглавление вообще брошюра такая толстенькая книжечка в которой написано много чего о докладах и в том числе как выглядит спикер чтобы подойти к нему и задать ему вопрос какой нибудь мы сделали оглавление он пуфик имени и по секциям доклады собственно мы находимся в зале 1 и по кругу пошли зал и все доклады записываться бухгалтерию у нас получается справа от входа в выставку около 5 до так же вы можете увидеть кофе-брейк кофе-брейк у нас постоянный уже работает можно пить означать что в любое время можно прийти там будет кофе и немножечко пир пустить а сейчас вот наша гордость это гибридные конференции скажешь на мы попытались сделать так чтобы перемешать online so fly нам то есть у нас здесь будут перед каждыми докладами будут онлайн вставки для нас для оффлайновых ребят а оффлайновые ребята могут прийти к нам сюда в зал почти ножками а то есть они могут задать вопрос мы его увидим мы потом после каждого доклада выходим цифровые кулуары да то есть это специально оборудованное место куда тоже можно подключиться можно подключиться из онлайна и увидеть как мы стоим вокруг докладчика задаем ему какие-то вопрос мы это попробовали это выглядит очень прикольно попробуйте сами как-нибудь накрыть из наших конференций в онлайне зайти то есть ты стоишь в кулуарах ты видишь кулуары там камера специальная которая выйдет фокусироваться на том как только сейчас говорит носит выглядит очень прикольно ты начинаю задавать вопрос тебя в кулуарах слышат тебя слышат видят и отвечают а те кто нас смотрит онлайн это я в камеру обращаясь обратите внимание у каждого зала снизу есть две кнопки задать вопрос спикеру в эфире это значит вы попадете на экран сюда прежде чем пройдете фейс-контроль наших помощников и 2 подключиться в дискуссионную зону то есть после того как спикер закончит отвечать на вопросы на сцене он пойдет в цифровые кулуары старая дискуссионная зона и там зум конференции оффлайн онлайн сможете пообщаться наук онлайн ребята не стесняйтесь а теперь наша будущая теперь так будет всегда да то есть мы это сейчас внедрили через какое-то время ты внедряться остальные организаторы вот так теперь будет учитесь использовать возможности онлайна более полноценно нас смотрит две с половиной тысячи человек на дважды рекорде две с половиной тысячи в онлайне нас здесь 1900 и 2000 онлайн дальше обеды у вас в бейджик в кармашке сзади должно было быть два талончика если вдруг нет обратитесь на стойку регистрации кормим из 12 15 до 16 талончики можно менять кормим на втором этаже просто подойти к лифту мы на четвертом спуститься на два этажа вниз прямо под нами спускаетесь ли открывается и вы в центре импровизированную не знаю кто в столовой да если что на территории крокус экспо если вы хотите вдруг множество кафешек о том что втором этаже талончики с обедами можно менять время можно менять приходите на регистрацию меняйте на любой другой или в чате конференций устраивается торги обратите внимание наш хэштег наш чат где можно общаться наш канал наш канал пожалуйста на него подпишитесь мы туда будем писать если вдруг что-то отменится если что-то перенесется или какие-нибудь другие организационные новости и чарты в рот ли плееров но это больше для онлайн участников партнеры я говорила их много большое спасибо нашим партнерам и сейчас некоторых из них мы хотим пригласить на сцену чтобы они рассказали чего нас ждет вы же видели этот мини город который построен только очень-очень быстро поднимайтесь пожалуйста спасибо на самом деле на самом деле реально большое спасибо потому что мы выжили как команда как компания как конференции вообще благодаря им то что был период когда нам ну никто все остановилось деятельность нам сообщает о том что ребята а теперь вы закрыты теперь у вас нет и вы ничего больше не делаете ничего не умеете смысле ничего якобы никому не нужны и продавать вам ничего нельзя и только благодаря партнерам вот этим вот это это представители только там не за четверть тех кто нас поддержал за этот год поэтому им реально бесконечно благодарны каком-то смысле жизнью спасибо всем привет у настроение ребят татьяна сверкала компания select all безумно рада наконец-то видеть живых людей очень соскучились пожалуйста приходите на наш стенд давайте общаться давайте обсуждать все что было ненавидеть онлайн-площадки и обязательно участвовать в нашем квесте будут классные призы ждем всем привет я наверное присоединюсь тоже к уже сказанному наконец-то очень круто видеть всех в оффлайне потому что от от онлайна действительно очень сильно устаешь я желаю всем и каждому сегодня для себя и сегодня и завтра на самом деле знать что-то новое обязательно послушать спикеров и поиграть наверное большинство игрушек которые делают команды компании партнеров но и конечно же приходите на наш стенд тоже там тоже есть игрушки и в общем-то очень даже интересно но глобально наверное хочешь сказать что за эти два дня мне кажется 1 не побоюсь он оффлайн конференции за последние полтора года найдите что-то свое и унесите его домой и дальше рассказывает друзьям коллегам и обязательно посещая такие мероприятия в будущем меня все спасибо спасибо еще раз доброе утро всем черно-белый тандем дует языкам бей меня зовут настя шивайя черт директор компании компании моя наверно пресно речь будет очень короткой и в основном опять связаны со словами благодарности во-первых большое спасибо кончика за то что дали нам возможность побыть генеральным партнером такой крутой всеми любимый конференции себя это вам спасибо за доверие в первый раз генерального партнера придумали и тут и тут вы большое вам спасибо где это была ответственность челлендж и очень было любопытное сложно я надеюсь что все получится а безусловно большое спасибо всем нам за терпение всем вам за то что мы дождались все-таки оффлайн невского формата за то что дождались живой конференции живых выступить живые выступления но я буду не я если поблагодарю нашу dream team и компании за подготовку конференции за ваше выступление горжусь вами помашу вам там на стенде и конечно же одному из выступающих тебе удачи всем выступающим сегодня легкой аудитории нам да друзья всем реально очень рад всех видеть в живую наконец-то и огромное спасибо программному комитету за то что отобрал больше сотни крутейших докладов не деннис тандеме едиными и конференция это не только общение это еще и самый крутейшие так варды самое крутейшее спикера поэтому ходить и слушайте впитываете новые знания и уходите более лучшими самими собой ура всем привет всем привет меня зовут максим я представлюсь этим угол и у меня сразу вопросик такое кто сегодня на конференцию fly нам смог добраться нашим сервисом поднимите руки есть люди ну не очень много да спасибо вам спасибо за offline спасибо организаторам вообще что интересно сити мобилу ассоциируется у многих просто с такси у нас намного намного больше работы мы всевозможные интеграции делаем по mac мобильной доступности и по по настоящей такой городской мобильности поэтому классно что все здесь спасибо всем приходите к нам на стенд приходите пообщаться голосом поиграть рассказать про себя послушать про нас всем спасибо да всем огромное спасибо меня зовут стас образовательная платформа skillbox мы здесь для того чтобы помочь вам развить ваш личный бренд чтобы помочь собрать команду мечты и если у вас есть ваши проекты в которые требуются молодые специалисты и так нам приходите на наш стенд спасибо организаторам спасибо вам всем а еще сегодня вечером skillbox наливает всем привет меня зовут алексей я представляем the great solutions мы разрабатываем высоконагруженные сервисы продукты на базе некоторые платформы о которой мы поговорим лучше на стенде с вами мы очень ждём мне будет приятно наверное большинством из вас пообщаться поговорить узнать кто вы и узнаете что вас там ждет тоже и прехождение к нам вот так что я уверен сегодня будет очень интересное для вас конференция так что отличного настроя успехов и вынести здесь как можно больше и контента который позволит вам стать лучше спасибо всем привет я повел я представляю mail.ru и представлять не только тарантул которым я на спине но еще и mail.ru клауд solutions стандартно у нас есть стенд у нас есть мерч вы знаете что делать давайте просто послушаем классные доклады мы уже достаточно затянули и кстати первый доклад наши он будет здесь не уходите доброе утро всем верны штерна ли ты digital наш стенд находится перед этим выходом из этого зала перед входом в этот зал мы занимаемся ускорением изменений в командах в людях и культуре организации если вы встречаетесь своей трудовой деятельности с токсичностью с сопротивлением ригидности со всякими такими вещами ну что жизнь то все равно продолжает идти вперед добро пожаловать к нам и нон-стоп два дня решаем поднимаем эти темы и решаем ваши кейсы всем инсайтов всем обмен энергии и новых знаний dice десант культуры на нашем в нашем технологической технологическом мире большое спасибо еще раз благодарю вас и спасибо спасибо большое ну что поехали мы рассказали о том как пользоваться конференцией и последнее что нам остается сделать это ещё раз выполнить традицию представить нашего бессменного ведущего лёша образца алексей драсте давайте мы с вами познакомимся с нами сейчас онлайн я надеюсь что они нас слышит ребята если вы нас слышите напишите откуда вы смотрите из какого города из какой страны напишите в чат у вас рядом с трансляции есть оказала у меня тоже есть вопрос ребята пожалуйста похлопайте те кому удалось спасибо вот вот этого я понимаю это мотивация похлопайте те кому удалось похудеть за пандемию уау я честно сказать набрал но у нас с вами потому что вы понимаете да я хожу из комнаты к холодильнику от из холодильника из холодильника я просто так не могу идти здесь у нас будет с вами возможность потренироваться походить из зала в зал походить по выставке по прекрасной я кстати хочу вам представить нашего генерального спонсора генерального партнера е е компы этапу как вы понимаете фильм тех они занимаются aqua рингом они занимаются платежными решением по всему миру более 350 айтишников у них штате я думаю что там интересно может быть заходите пообщаетесь узнаете то что вы хотите посмотрим если у нас ответы уау москва супер севастополь деревне волоколамском районе краснодар россия интересно если у нас канада израиля вот этот европы но хотелось просто посочувствовать ребятам потому что слава богу что этот праздник у нас начался похлопать и пожалуйста еще раз те кто рад что в общем наконец-то состоялась оффлайн события и о а теперь похлопать и так как вы хотите чтобы для вас прошла конференция супер супер минск прекрасно очень всех вас рады видеть и программа огненная до 7 вечера я здесь с вами и первый доклад знаете вот едешь бывал на машине чет она как-то не не тащит или вообще но в собственный did выкинув кино смотрели по краям это останавливает машину открываешь капот смотрят счетом как же я его открыл много сирануш ни хрена не понимаю среди нас есть тот кто понимает он подготовил свой доклад и вы теперь тоже сможете разбираться если что-то работает не так в mais quel вы теперь будете знать об этом расскажет пётр зайца встречаете мы репетировали как хлопать спасибо всем привет но действительно мы поговорим о том как заглядывать под капот машины где машина это майское ли не какой-нибудь майской а майской 8 кто-нибудь из использовать майской или вы так пришли о несколько рук отлично ну что такое мы говорим о тебя обзора берите что такое и зачем это нужно да то есть на самом деле в систему которую мы используем текущий момент они часто достаточно сложные и с нею возникает много проблем которые сложные которые повторить просто в системе разработки может быть достаточно проблематично поэтому очень хорошо когда у нас есть информация до инструменты чтобы просмотреть продакшен посмотреть и разобраться что там станут там происходит на самом деле здесь есть две такие два подхода да там которую мы по крайней мере с пользуемся с одной стороны вы наверное слышали как концепт мониторинга когда мы ставим система она собирает постоянно данные с продакшена они собираются вот и мы всегда можно посмотреть что случилось вчера то там или час назад вот в случаях когда у нас что-то происходит воли но сложный нам этих данных может не хватать мы включаем сбор еще каких-нибудь дополнительных данных а вот я например на в прошлом году здесь на холоде рассказал про инструмент и ddf через которую можно подключать тем совсем сложные пробы как он ведь совершенно какой-нибудь конкретной функции в ядре да там или в процессе собирать да данная очень очень детальные что здесь важно ну хотя буду рассказывать про mais quel в моей презентации надо понимать что просто смотреть на мой сквер часто все проблемы не решит очень много проблем может вылезать из-за того что на стыке нибудь приложение проблемы с приложением что-нибудь там напортачили или может там с операционной системой особенно в современном мире у нас может быть много много уровней да там она железо есть какой вот там пайпер вайзер дальше может на нём бегает какой-нибудь там типа каберне this paper всего этого и у каждой этой прослойки могут быть свои проблемы и на все это имеет смысл смотреть вместе ну и так давайте посмотрим о том что у нас есть mais quel и какие данные нам майское непосредственно предлагает и как мы их можем использовать здесь данных достаточно много я буду двигаться достаточно быстро что у меня еще осталось время показать вам показать вам демку вот так что если что потом посмотрите славе дополнительно по медитируйте какие у нас май сколь 8 представляет данные ну вот это вот наверное основные шесть источников база источников данных который в нем есть шоу главу статус если кто mais quel использовал наверное знает что он там была всегда ну по крайней мере с майской 322 кто используемой сказать 322 здесь есть нас археологи о отлично есть вот что у нас шоу статус показывать шоу статус по большому счету показывают кучу аккаунтов которые позволяют отслеживать разные события в базе данных но вот например сколько запросу база данных выполнила что интересно что вот эти вот шоу статуса не поддерживается как на уровне глобальный так и на уровне сессии то есть вот в данном случае вы видите пример что я могу посмотреть как число запросов которые выполнили удалова базы данных вообще только сколько запроса выполнить какую-то она в данную конкретную сессию выставок мы быть они подсоединились к базе данных что бывает весьма полезно посмотреть вот я подключился что-то он выполнил кучу запросов давайте посмотрим а что же там реально накопилось вот здесь есть свои определенные тонкости что в некоторых случаях вот например и no debe статистика вы можете ее попросить как сессии переменных но на самом деле на вас до вам даст глобальный глобальные переменные и понять что она когда именно дает но не всегда так просто да эти вещи просто хорошо знать использовать стоил global статус можно например для такого простого достаточно просто линга что японии мы еще использовали многие многие годы назад да ты наверное даже 20 лет назад сделал шоу статус выполнил запрос после этого выполнил заново шоу статус и посмотрел что же там у нас изменилась но в данном случае мы выполнили запрос который делает full-time сканда то мы видим то что хандрит next затем это вот было выполнен столько еще число этих операций практически сколько но сколько строк в таблице да там плюс минус своей сколь поставляется также утилитка майскую админ который очень классная в том плане что она позволяет посмотреть данные в таком вот в формате как видим стад или ios то туда там куча разных linux утилиты можно сказать вот давайте нам данные как они меняются до там за каждые каждую секунду да там или можете поставить майонез и другой параметр и и можно смотреть что у нас происходит на такой вот как бы простенький trending геркона tool kit есть туза 5 микс называется которая позволяет другой взять те же самые данные и от рисовать их вертикально этом который позволяет посмотреть сразу на все шоу глобус статус и посмотреть ага вот у нас не знаю в эти 5 секунд был спайк числа запросов но да там в расстреле кинчев и другие ивенты часа на это смотреть более удобно чем использовать моей вскоре админ собственно говоря вот именно для этого мы его в свое время там много лет назад и сделали следующий инструмент в которую можете покопаться найти много интересных данных это информация схема он был добавлен попозже но тоже уже наверное близко к десяти лет назад который содержит кучу табличек из которых с помощью рискуете того же можно достать какие-то данные некоторые данные они не такие содержат информацию о объектах которые у нас есть база данных но вот например здесь показывается и информация о таблицах где и и уж когда там где можно посмотреть что это за объект какие у нее разные properties и так далее с другой стороны там есть и разные интересные метрики вот в данном случае мы смотрим на и на тебе и на деви метрики вот и таблицы и на деметре ксана чем-то похоже на шоу шоу статус да но как мы видим там колонок значительно больше вместо того чтобы просто показывать каунтер можно посчитать она считает и среднее значение и как показывает когда оно было включено выключено и так далее и тому подобное вот что надо знать про и на деметре кста что они в отличие от шоу статус не все включены по умолчанию какие-то из не читаются какие-то не считаются вот если хочется включить все нужно добавить опцию и нади мониторный в лол и в принципе они практически бесплатные да то есть если вот мы говорим там будем говорить про performance кимата там надо думать что включить что выключить потому что у нее может большой overhead то и на деметре кс они практически бесплатные вот performance кима performance кима это была разработана но уже тоже достаточно давно когда там с mais quel 55 и это вот тот подход да на котором майское сейчас стандартизируем а то есть идея такая что все фокус на instrumentation все это пытается делать через performance кима по какой причине такой причине что информации performance кем она дает все данные через table физик который можно получить через тот же язык sql и это очень хорошо работает в лаут решениях да там где доступ к таким данным у нас есть всегда какие-нибудь там данные сбоку влогах или там в чем вычищу это как-то но не всегда так просто добавлять performance кима очень много данных но не все они включены всегда и к ним нужно относиться а аккуратно потому что если взять и сказать о а я хочу вообще собирать все и всегда то это может быть стать дорого притом что еще интересно что очень много конфигурации performance кима они она динамическая то есть он тебе говорил что вот некоторые вещи мы хотим включить всегда некоторые использовать в роста для отладки когда нас там что-то не работает мы их можем динамически включить и посмотреть как бы под увеличительным стеклом что же там происходит вот performance кима поскольку она конфигурируется динамически во многих случаях она позволяет это делать как же на нас конфигурируется и конфигурируется она на самом деле сложно да там не вот честно говоря кажется что что-то они тут да там видим какого то не знаю да там очень умного человека посадили это дизайне теон что-то очень сложное на дизайнер как-то конфигурируется конфигурации можем через дать его таблички с этап что-то там что такое actors actress это конфигурирует какие пользователи с каких ростов у нас будет проводиться на то есть по умолчанию мы провалим всех но мы можем сказать что вам проверка хотим проводить только часть каких то пользователей следующие концу мерс концу нас грубо говоря это какие у нас есть таблички которые собирают вот это вот сумма не зиру информацию агрегирует информацию дата с разных точек зрения да здесь тоже можем посмотреть какие-то из них включены по умолчанию кейта выключены можно динамически включать-выключать следующий концерт performance кима это инструмент это собственно говоря вот эти вот точки входа в в коде которые собирают какую-то информацию до на текущий момент у нас более чем 1200 информа инструментов из которых 800 включены остальные выключены и некоторые из них еще таймс да то есть они вычисляются время почему сделаны именно вот такая конфигурация потому что есть некоторые инструменты которые дергаются ну кругу ряд а может быть миллионы time раз в секунду и каждый раз для них считать время получается overhead более большой но это в некоторых случаях если нам но достаточно для диагностики просто знать сколько событий произошло мы можем включить инструмент что вы считался счетчик но не требовать его тайминг ну и наконец объекты объекты нам показывают какие объекты базы данных мы хотим инструмен тировать да там таблицы триггеры хранимые процедуры и так далее и тому подобное и здесь вот что интересно да там что видите что схемы как mais quel performance элементы информация с кем и по умолчанию они у нас не инфицированы это не тебя хорошо это потому что нет случае америка таблицу нас информацию может существенно тормозить но через по умолчанию через performance кем это не увидим вот ну и ещё вот это вот новая фича которая появилась mais quel 8 именно этого можем настроить еще типы потоков которые мы хотим инструмен тировать и или нет да то есть у морской есть куча разных потоков какие-то из них вот например там фредди сказал want in action это собственно говоря но наши стандартные русские потоки остальные это разные системные потоки которые делают что-то у нас фоне вот пример как у нас данные показаны собираются в performance схеме и здесь что интересно если то вы видите что таймер старт старт таймер and да там начало и конец событие она какие-то немерено здоровые цифры вот потому что performance кем по умолчанию время мерит в пика секундах на то есть пика секунда это одна тысячная на на секунды то есть идея такое чтобы мы могли как целое число да там представить время с очень большой точностью но это значит что в его peg-perego идите нормальное время нужно делить на единичку с очень большим числом нулей вот и понятно что ручками работать со performance темой бывает часто не всегда очень удобно для этого с майской поставляется такая еще дополнительная схема которая называется система что то такое но по большому счету это набор вьюшек и там несколько хранимых процедур есть которые нам позволяют информацию которую собирает performance кима работать более более удобно при чем она позволяет делать юшки как для людей так и для машин где вьюшки для людей они делают информацию в таком виде как не знаю 5 миллисекунд или там три секунды до там понятно что если мы хотим написать какой то скрипт то вот из этих 5 секунд или там две миллисекунды обратно переводить нам все это очень неудобно поэтому есть 2 2 набор те же самых ушек которые используются x доллар с префиксом и там все данные хранятся в ну воли удобную машина redbull формате ну вот о чём я говорю да вот можем посмотреть пример мы видим да там что здесь statement лайла и tense car and memory да там она все сделано в таких удобно удобно варим формате вот если же посмотреть на те же самые данные для машины они собираются все эти данные в тех же самых пита секундах байтах и так далее без попытки сделать его более удобным для чтения ну вот есть еще несколько интересных примеров ну или каких-то там куча да там в performance кими например мы можем посмотреть информацию по нашим клиентам да кто то какие у нас хасты которые работают с mais quel им они используют ресурсы и здесь мы можем посмотреть что елки-палки к что какой-то хвост выделил 2 терабайта памяти как-то выглядит странно но на самом деле total номере allocate эта информация о том сколько всего вот этих вот разных молоков было за все время да там то есть они для того чтобы смотреть сколько текущей память использует надо смотреть на камере почему я про это говорю потому что часто люди пугаются говорят что у вас блин там performance кима вред другое интересное интересно что вот если мы посмотрим для тех же самых ростов вот вывод мы видим то что очень много операций вот выводы выводов она привязана к такому хасту к который называется до ground почему да потому что mais quel он многие операции по записи по крайней мере до то он пытается делать в фоне и они на этом уровне уже не привязаны к какому-то конкретному 3d кому-то конкретному has туда там они просто идут в a ground и для данной для данного рк лова да да там большинство окраски операции происходит в бэкграунде следующий интересный примерчик у нас это ну вот вот вот вывод мы можем посмотреть более более детально уже здесь и по и по хостам и по типу ввода-вывода что же у нас происходит это мы видим что у нас есть куча до ground например активности как в лог-файл у такого да это файлам и так далее дальше можно опять таки по хостам посмотреть например какие у нас statement и хасты выполняли сколько и так далее что может быть весьма полезно посмотреть какие хасты создают нагрузку на базы данных уже посмотреть по типам statement of вот а дальше то что я раньше показывал в в файловый вот он показывал просто по типу операции да например и на дивиди это файл но часто нам наверно хочется посмотреть более детально что же у нас там но за файлы непосредственно там который доступ тот это можно посмотреть через главу файлы и и борьба its вот здесь вот что интересно да видно что performance kimono делать такие вот разные ну разные вид на данные да например можем посмотреть рыбу хастам по типу операции либо не по хостам но уже по всем файлам но почему потому что если делать вот эти вот все полной при мутации например у нас есть там не знаю да там 1000 хостов и 100 тысяч файлов понятно что там где меньше нас получается большой чтобы это все собирать эффективны и в памяти блин потребовалось бы очень много очень много памяти ну и вот можно смотреть да там убрать чего нас там были до то можно более детально дата посмотреть опять-таки по типам в файлов самаре то то же самое вот в майской есть instrumentation тоже сейчас и сколько было выделено память для разных целей то есть если вы запустили там mais quel и вроде бы вы дать ему не так много памяти сможете блин вот он занимает дофига памяти вошел сломаться да там откуда что там выделяет память и это можно вот как раз таки посмотреть через вот это вот в это вот табличку вот еще в система есть такая табличка metrics который грубо говоря используя данные из шоу статус но она добавляет в нем вот эти ее надей metrics сливает их как бы в одну таблицу и показывает им ну тип ее там это глобус статус или нет включена она или нет и так далее майское лишь о процесс лист наверно многие этой терзай пользовались вот в эскимо есть свой процесс лист которые используют данные из стандартного просто sli из плюс добавляет еще куча разных дополнительных данных data вот здесь можно посмотреть а да там сколько это транзакция на данный момент роуз обработала да там и так далее и тому подобное следующая интересная утилитка если кто слышал в mais quel и ну и на самом деле в других базах данных часто бывают проблема то что люди ну кончайте индификатор и а то есть мы сделали int у нас там четыре миллиарда идентификаторов когда то давно это казалось что это хватит всем и навсегда а потом раз вдруг и кишки кончились и это большая проблема дата многие вот ресурсы писали что блин а вот пришлось делать какой-то да там downtime или что-то для того чтобы срочно альтере табличку чтобы расширить колонку из 32 бит на 64 вот в.в. российским а есть туза которая позволяет нам покраски посмотреть насколько у нас используется нашего этого то адрес space да там и соответственно если у нас уже там используя на 50 процентов то может быть надо начать планировать что с ней делать редант and index с что это такое другой тоже такой бич мая сколько многих базах данных часто люди когда у них тормозят запросы они идут да там читают или говорятся экспертами им говорят блин ребята вам нужен еще один индекс они берут яндекс и добавляют в итоге у них собирается много индексов и часто они но накладываются да может индекса она колонки а потом индекс на колонке а , б к там индекс на колонке a , b , c вот и такие индексы они на самом деле часто перекрываются дата может нам достаточно только вот один и весь индекс редан дан индексы с как раз таки туза которая нам это показывает какие у нас индексы были redundant и более того нам дает сразу даже команду который этот этот редондо индекс можно убить следующая вещь которую достаточно достаточно интересно да то есть мы можем через performance схема посмотреть какие у нас наиболее горячие горячие таблички на там и что с ними ну что с ними происходит число обращений сколько у нас время зашлось и обращения на диск и и так далее да то есть часто это достаточно ну полезно знать потому что дальше уже можно разбираться что с ними делать до может быть там какие-нибудь индексы убить или там колонки убрать может быть архивировать старые данные и так далее то есть такой вот взгляд о том какие у нас колонки тормозят прогресс весьма полезно следующая интересная штука которую можно нарыть из performance кима индексы которые были созданы в свое время да там может приложение эволюционировала и больше эти индексы не используют от их можно найти таким образом я высказал . с к не используем индексом надо подходить аккуратно потому что если вы индекс убили оказывается потом что он вас используется просто например раз в месяц и кинуть отчетом да там то добавлять его на большой таблица это очень дорого в мае сколь 8 есть такая классная tool за как invisible индексы с где мы можем яндекс просто временно выключить следующая интересная штучка вот кто здесь верит в security есть кто-нибудь но не так много верит наверное это не то слово да там вот ну покрайней мере заботиться о security вот в понятно что одна из в отходов к этому обеспечения безопасных базах данных это использовать тело с да еще как бы правильной версии для ваших коннектов с performance и мы можем посмотреть как что у нас используется в плане в плане этих в ну в плане тип security которые используют для каждой connect а вот следующий еще интересное тузы которую можно смотреть statement analysis табличка она нам показывает но по разному типу типу таблиц дате типы запросов что они непосредственно делали вот здесь вы можете обратить внимание что шоу ты его статус на самом деле создает кучу временных таблиц на на самом деле как бы это не глюк так она есть да там в современном а и сколько ты был статус он требует временно табличку куда он кучу данных там загоняет вот то есть так оно на самом деле есть если интересно посмотреть что у нас было с база данных и в порядке да там какие возникали ошибки вот что может не или вонь инге это может полезным для совершенно разных вещей да это может быть кто-то пытается сделать и сколь injection и загоняет туда кучу statement of которую нас парсится типа statement for да там или же какие-нибудь остались старые запросы которые обращаются к несуществующим таблицы в несуществующем колонкам все это будет видно в данной табличке я уже показывал а что можем посмотреть информацию по хостам другой способ смотреть на это часто можно на на уровне юзеров здесь есть как бы такая хорошая практика что если у вас есть много разных приложений которые используют базы данных используйте там разных юзеров потому что кроме всех других хороших окей закончить так закончить закончить так ну да я вижу вижу это я просто а про себя вот что мы ещё можем посмотреть в общем какие у нас есть войти можно посмотреть распределение по запросам надо мне просто среднее время выполнения запроса но и этого то что появилась моя сколь 8 у нас есть разные разные гистограммы ладно теперь давайте быстренько пробежимся по какие у нас есть логе майской у нас есть сэр логэйн perilous слог слова курилов которую можно включить мы очень часто пользуемся слуг брелок в нашем перкунас серверу mais quel мы его расширили то что там добавляются дополнительные какие-то параметры которых нет майской мой сколь 8 кстати его тоже ребята расширили на там добавив данные о выполнении выполнение запросов и часто это очень хорошо потому что можно посмотреть но и конкретные типы запросов варианты которые выполнялись и какие у них были там параметры выполнения следующая вещь которую нужно знать всем да там разработчикам operations и to explain да там как же этот запрос будет выполнять база данных потому что часто она его может выполнять совсем не так как вы в этом считаете нас есть базовые да там если вы просто используем explain получаем информацию вот такого вида опять таки эта штука была ну как минимум с моей сквозь 322 может быть и раньше есть у нас еще джейсон формат джейсен формат дает значительно больше данных по xb но относительно вот этой табличке поэтому для но более расширенной диагностики да там с ним хорошо работать проблемы с ним конечности джейсон его удобно обрабатывать скриптами но глазкам больно поэтому в мае сколь 8 появился теперь у нас еще и 3 формат да там который чем-то похож на на по сгрыз да там как у них сделан explain который показывает это в таком формате дерево да там кота который показывает более информацию расширенную чем-то в личный explain но более легко читать следующая классная штука тора есть появилась моя сколь 8 и to explain она ladies когда мы можем сделать выполнение запрос explain онлайн и он нам расскажет не то как optimizer думал он выполняет запрос а как он его на самом деле выполнил потому что там могут быть из-за но и из-за разных предположений неправильных optimizer может быть разница это очень хорошо когда помогает когда вы смотрите на план бланк классный выполняете запрос тормозит делаем explain она лайс смотрим есть и собственно говоря разница между тем что он думал да там когда он спрашивал explain и что реально получилось explain the connection тоже очень классная штука на мере если у вас выполнился запрос который вроде вы обычно выполнялся нормально а сейчас вот тормозит бежит уже 15 минут до там можно сделать explain the connection посмотреть что же такое у него там с планом что ж вот переклинило чем это полезно потому что иногда если вы просто тот же самый запрос углу где второй раз он может выполнить уже быстро там потому что это был но единожды факап optimizer еда там они то что постоянно происходит войска или также есть возможность стрейфить optimizer который создает такой большой файл в где optimizer типа рассказывает о том что вот я туда посмотрел я так подумал и в итоге я выбрал этот план это туза оно полезно либо для скажем так экспертом который очень хорошо понимает как это работает либо для того чтобы эти данные послать например там саппорте мы ли кому-нибудь до чтобы они разбирались в чем же там вот такой у вас не работает более детально чем вот почему ты меня explain получается странной окей ну что вот мы прошли по первой части я вам рассказал что у нас есть в в москве теперь у меня есть еще целых восемь минут на то чтобы вам показать маленькую демку про пи мы примем это инструмент который мы сделали именно для анализа производительности mais quel это полностью open source туза так что ставьте ее и и пользуйтесь вот ой чот у нас от кита а это у меня видимо барахлит здесь только вот и и более того если вы хотите ну если он нужна помощь чтобы поставить наши ребята на стенде беркана к счастью вам помогут если вас уже прямым стоит мы вам даже с радостью поможем посмотреть что можно интересного нарыть про вашу базу данных вот с помощью этого инструмента так что приходите будем общаться предметно ну что ж давайте посмотрим как насколько у нас наши брюки превращаются в шорт и или как там это положено о нет неё так господа как нам бы или мне нужно перетащить на другой экран как-нибудь я вижу о вот отлично оказывается не так все плохо так и так что у нас прямым мне представляется вот этом основная от ул за то что у нас есть запросы в данном случае запросы туза собирает и агрегирует во множество серверов а почему это очень полезно потому что если вас инвар мин большой сироп 10 может быть 100 до там-то смотреть на не знаю там performance скинов каждому из них из ковыряться запросам это не неудобно причем мы можем посмотреть не только в на уровне забросов но и например посмотреть с точки зрения нагрузки куда у нас больше всего нагрузки от 8 грамм базам данных то есть например здесь мы можем посмотреть что вот на майской 4 у нас загрузка 6 да там по другим но существенно меньше что такое лода такими мысли не понятно на самом деле это то же самое что среднее число активных запросов да там вот то есть если лот 6 это значит что среднем на этой ноте выполняется активно 6 запросов например в том же самом процесс процесс листе вот то есть то есть вот так вот дальше если мы можем посмотреть сбоку кстати с как будто мсфо сотен можно посмотреть собственно говоря откуда у нас происходит больше всего нагрузки например здесь видно что с точки зрения схему на степи сиси вован да там 60 процентов нагрузки на всей этой системе для чего это полезно пример очень полезно вносить sharding эта картинка очень часто у нас вылазит блин что вот у нас запроса все везде одинаковые но вот какая-то схема какой-то шар у нас перегружен да там или можно посмотреть в сервер сервером и так далее да вот например я могу здесь сфокусироваться и посмотреть теперь запросы только на для сервера майское 4 вот кликнуть на мирно она запросит и он нам что есть интересного скажет что вот у нас есть запрос вроде бы всего 60 запросов в секунду да там совсем немного и посылает он данным совсем немного немного да там всего вообще каждый запрос посылает среднем 11 сек но что интересно здесь это вот это вот циферка что на каждую строчку которую нам данные посылаются нужно проанализировать 20 тысяч строк да там это одна из саа но для меня это один из таких очень важных критериев к критериев эффективности да то есть что оно должно быть но там единица может быть десяток для эффективных эффективных запросов вот ладно давайте посмотрим на пример что же нас за пример этого запроса но пример на самом деле запросик ты неплохой да вроде делает одна табличка лука по индексу вроде должно быть все хорошо давайте посмотрим explain xp-g нам говорит что на самом деле у нас пол тип это означает full-time скан маску или и должно да там просканировать а куча куча строк каждый раз вот здесь мы можем посмотреть на табличку да там и увидеть что вот у нас есть табличка это этим ван на которой нет совсем ключей дата но теперь понятно да что если кто-то забыл создать индекс на данной конкретной ноги да там или дрогнул его случайно то вот у нас появляются такие такие проблемы ну и кроме непосредственно запросов у нас есть куча другой разной информации данный пример вот можно посмотреть информацию по загрузке системы по информации да там о том какие у нас нагрузка непосредственно на mais quel число запросов и так далее вот многие здесь у нас используют и no debe да там с точки зрения и на тебе можно коснуться собственно говоря значительно глубже посмотреть ну очень много операционной статистики да там по и на деви стороны джин если ну что на этом уровне вот еще пара интересных дешвордов которые есть одна из них это процесса да там который мне очень нравится почему часто бывает что но люди на хостах запускают какие-нибудь процессы которых там не должно быть дата можете это вас там баков запустился можете к нибудь там злобная java или бетон который жрет дофига памяти не делает ничего ничего полезного вот а все говорят почему и рук mais quel начал тормозить с помощью этого туза мы можем посмотреть что у нас ждет ресурсы так как с точки зрения процессора так например и там использование использования памяти на этом здесь например показывают какие у нас процесс использовали там много резидентной памяти и так далее вот вот и еще наверное в кратко покажу вот кто-нибудь слышит здесь про radiohead про анализа производительности типа request rsd ration нет ну скажем так в кругах фанатов обзор выбелить и это достаточно известный метод для которого я сделал дашборде можно собственно говоря посмотреть именно в рамках этого концерта что у нас происходит да там с точки зрения число запросов входящих да там потому что есть у нас число запросов друг либо резко возрастает его резко падает на то часто у нас что-то изменилось в системе число ошибок квиррел intense там и так далее ну вот ладно если вам интересно еще посмотреть на темы мы будем делать дымке у вас у нас на стенде так что приходите посмотреть и вот у меня уже тут человек пришел стоять над душой вот так что давайте мы вернем ему слова обратно у нас есть для тебя призы конечно же памятная табличка и саша да что это такое бричка это худи брендовые ходе с hai la danza теперь можешь ходить мерча вот рэндольфу театру да и у нас оси будет сессию вопросов-ответов давай пока поставим сюда ребята это гибридная сессии вопрос в ответ у меня есть условный сигнал с техниками если у нас есть вопрос из онлайна вы пожалуйста поднимаете руки и к вам подойдет человек с микрофоном кто готов задать вопрос и вот я вижу первую руку еще руки поднимайте сразу спасибо спасибо за доклад у вас был слайд explay man alive а вот у меня такой вопрос что должно пойти не по плану а чтобы фактические план выполнения запроса отличался от того чтобы что изначально нам показывала был обычный explain соответственно но на самом деле там очень много разных критериев может быть очень часто бывает что статистика она либо устаревшие просто распределение данных эстимейт неправильно то есть например когда вы делаете запрос на там что вот найти все где они знают am a равно 5 что mais quel дело да там он делал он смотрит в яндекс делать так называемые рэндом days и делает эстимейт насколько сколько у нас реально строчек соответствует этим у а равно 5 что-то получилось о это всего должна быть у нас одна строчка значит и мы используем этот индекс а если получилось так что он прикинулся там одна строчка там получилось 1000 то можете это индекс пока и получился и неэффективный могут быть и другие неправильно вещь над меры mascot есть как бы но опять как о многих базах данных да там statement on a light который позволяет обновить статистику о как бы среднем распределение данных по индексам если данные устаревший например в этом зале ли кучу новых данных совершенно другим распределением опять-таки optimizer может вы по может принимать неправильные решения ответил опрос если еще вопрос в онлайне чтобы задать вопрос нужно нажать кнопочку и в эфир она рядом с метро сказаться прикинь я надеюсь мы все это видим у нас от есть еще цифровые кулуары то есть также как обычно есть зона с флипчарта для того чтобы обсудить те вопросы которые остались это рядышком залам вот вот в ту сторону и из онлайн и вы тоже можете нажать кнопочку цифровые хлор и покажите мне если есть вопрос есть вопрос супер сейчас она ставит вопросы в центр зала а яйца если вы стесняетесь в онлайне выходить в эфир вы напишите в чат я тоже увижу и прочитаю представьтесь и задавайте вопрос сергей я здесь с перк он это же петр привет я хотел спросить вот тебя там 20 слайдов была про разные performance ким и так далее так и тому подобное вот у меня например база есть неужели нет ни какой то тузы которая как-то суммирует все это и скажет мне чувак тебя там база лежит у тебя все неправильно потому что вот эти там 20 слайдов это всего руками если просматривать но это время понятием вопрос не очень вопрос понятен ну ты тролль сергей вот нет но на самом деле вот идея и инструментария нашего пивом как раз такие как раз таки в этом да там то что мы движемся в этом направлении я вам показывал какие у нас есть графики что на них есть интересно на самом деле мы сейчас работаем над тем чтобы эту информацию еще предоставлять в виде alert of и от лазеров действительно чтобы человеку у которого ну который может не хочет с этим всем разбираться для него это как бы не не в кафе от люблю смотреть на графики в этом такая медитация можно сказать но если вам не в кайф то м м поможет есть вы просто 2 ряда здравствуйте представляют большое спасибо за интересный фильм доклад с удовольствием посмотрел потому что я действительно пользуюсь там на майскую вам вообще у нас есть разные базы не только москве и у меня вопрос такой вот примем это для масел для каких еще свобод это небольшой оффтопик я понимаю что немножко не в тему и для каких-то бы то еще у вас есть подобные вещи хорошо вопрос вопрос как я понял какие еще базы данных поддерживает пима вот то есть мой доклад про майской поэтому я вам показывал пмм у нас для mais quel также нас поддерживается по сгрыз и mongo db на данном этапе даже если вам интересно 5-1 ребята на стенде покажут как это работает что еще здесь классно то что имеем это открытый продукты в принципе мы надеемся что если кому интересно добавить какие-то другие базы данных то люди это напишут да там и мыса доволен и с удовольствием примем таких интервью шанс или может у нас руки дойдут когда-нибудь у самих друзья у нас осталось время на два вопроса один уже есть и поднимите руку если вы хотите задать свой вопрос кстати горя ты же помнишь да что вручать тебе предстоит приз за лучший еще один присела все просто супер ты будешь вручать приз за лучший вопрос давали нет я пожелать эта книжечка мы и забрали да сейчас все сделать на нем до представьтесь пожалуйста и задавайте до добрый день меня зовут роман спасибо за доклад было очень интересно я как раз попьем ему хотел узнать он только для 8 версии у вас разрабатывается или более старый мускул 5 6 5 7 тоже поддерживает так я что то не очень раз слышала вопрос by me i'm работает на более старом мы искали чем 8000 работает он с 5 6 5 7 лет mais quel 5 6 или 5 версальского 56 и дамой сколько часть работает ну кстати по май сколько честь как вы может быть знаете он теперь у нас уже закончился end of life так что надо обновляться не всегда возможно супер не появилось больше рук поэтому приск тебе идет вопрос приговор не понравился ну что так кто там вот на что он мне кажется был хороший вопрос у молодого человека желтым воротником и с бородой вот он наверное сейчас найдет вот про просто почему же optimizer может купить хороший вопрос city вот так что мы вам супер поздравляем участников подходите получите ваш приз вручат спасибо огромное ребят а хайлатер несколько минут пробудет ещё в цифровых кулуаров но они есть и в реальные жизни и с травой на тот случай если кто-то захочет тебе данный конечно если правильно понимаю ты все это время здесь и у вас есть стенд я здесь какой-то отлично спасибо огромное и мы с вами в этом зале продолжаем уже через минуту мы догнали расписание ребята круто а форум k-pop абакан а еще еще пять минут что ж друзья я очень рад что вы с нами что вы пришли подсаживайтесь чуть чуть поближе чтобы лучше видеть и лучше слышать и прежде чем мы услышим следующий доклад игната мы посмотрим небольшой ролик это технические разговора у нас в этом на этой конференции мы подготовили для вас интервью с представителями разных компаний сейчас вы посмотрите разговор году александр барановский внимание на экран ну привет я артем я бывший редактор хабра сейчас ведущий подкаста мы обречены рад познакомиться привет я саша 5 мбит в команде бабу занимаюсь processing данных наша задача взять всю всю всю статистику доставить ее до мест где у нас есть потребители ты говорил что-то про культуру кода в черном вашу особенность что такое используйте культура кода в моем случае я имел ввиду именно подход я приверженец теории что не бывает ни возможных решений не бывает ни не интересных решений во всём этом можно найти какую-то составляющую которое понравится либо конкретно тебе либо в целом команде и на этом драме можно делать безумные вещи выстраивать безумные системы которые будут потом удивлять вишню если они их рассказы и скучно не будет никогда важно это просто понимать если идти с этой тенденции с этой этим пониманием давить людей то использованием этого все можно построить прямо гигантскую интересную систему расскажу что пока это что-то между под этим безумен под безумными не скучно вершина да без проблем одна из систем которые мы делали это аномалии то так то есть система поиска аномалий на графиках тем они не новая но мы и решили для в универсальном видят для миллионов графиков это собственно и будет темой моего доклада я буду рассказывать именно о том как какие запросы мы боль не о самой системе а ее подходе мы ведь очень много веселились всякими научными статьями с поиском информации у нас не было изначально там большого опыта построения подобных систем но мы взяли cliff house мы взяли и реализовали на чистом михайловском бы сколько нечистых а у нас на этом используем реализовали модели предсказаний воткнули туда сотни миллионов графиков и она считается процессе с минимальным шагом в 10 минут и это все еще при этом не на самых больших кластера окей проект расскажу подробнее там слушаю откуда вообще такое ты берешь в себе такую силу для такого подхода ну просто люди когда начинают чем дольше работать индустрии тема не давайте возьмем приняты давайте будем делать так как надо не давайте не будем лезть за пределы того что за что обычно не лазит на тип откуда взять себе drive чтобы делать реально не скучные безумные постоянно придумывать и изобретать но здесь есть такая знаешь фраза он дает то есть когда ты находишься на самом краю индустрии это не какое-то физическое положение что вот я проработал 20 лет теперь я могу ступить первые ряды и начать драйве нет это не так происходит так как тогда когда ты начинаешь падать на индастри лавал структур киты делаешь работу ты ее сделал поставил галочку призмы что я умею делать или рассказал об этом какой-то доклад до что нового изобретена что нового продвину как продвинулась инфраструктура в синтез индустрия в целом если ты просто сделал то же самое что делали другие ведь намного интересней погрузиться во внутрь какой-то новой вещи взять что-то новое как-то по-другому повернуть под новым ракурсом сделать какие-то новые выводы используя те же самые инфраструктурные вещи о которых говорят там очень многие но повернуть его под таким углом под которым никто еще не поворачивал увидит что это работает может быть немножечко где-то подкаст и не без этого но результате добиться того что никто никогда не делал или благодаря тебе благодаря тому что ты привнес и рассказал о чем ты сподвигло у кого-то двинул двинуться дальше расширить горизонты своего восприятия мира ночь осознаешь как думают что особенно чем больше работать чем больше изучают вещей таки да все уже изобретено и все что изобретена довольно тривиально и придумано не лучшим способом да и особые улучшать никуда давайте просто этим пользоваться и не собственно можно так сказать но и слизывать возьмём ситуацию десятилетней давности начала десятых годов тогда тоже так все говорили но тогда не было cliff house а не было кафки не было куча языков которые сейчас используются повсеместно да тогда уже тоже было все изобретено но это не так мы двигаемся мы развиваемся и когда-то в древние века люди считали компьютеры что необходимо я не помню точно фраза что по-моему 2 мегабайта оперативной памяти будет достаточно всем и люди в это верили в раз ваша вера если вы не будете подвергать свою веру сомнениям не будете критически мыслить а действительно ли все изобретено а действительно ли нельзя эту конкретную тузу улучшить или как-то повернуть неизвестным углом таким образом чтобы она начала приносить пользу еще где-то без этого да можно действительно сказать что все изобретено сложить лапки просто начать это использовать а можно попытаться но что сейчас думаешь про industry вот она сейчас ты ее видишь что тебе мне кажется где надо изобретать где как слабые места чтобы ты стал принять вот даже в тех подходах который вы построили той системе который вы построили где эти решения где тебе приходится идти на компромиссы такой блин здесь не круто надо здесь сделать круче вот этого не хватает этого не хватает да я понял вопрос на самом деле это абсолютно нетривиальный вопрос можно выстраивать что-то новое во всех сферах и очень многие это делают тот же самый house продолжает развиваться и они решают основную нашу боль а если уже не решили честно не могу точно сказать это звуки пир к примеру заки первым боем у всех наших последний бой к нам приходил к вам киллер за звуки беру от потому что он немножечко разросся в памяти всего лишь 16 гигабайтами каждую систему невозможно сделать совершенный нету совершать это только цели к нему к ней можно стремиться да мы сделали мы процессе миллиона графиков но мы это не делаем бесплатно мы это делаем за счет конкретно известных там ресурсов которые мы на это тратим есть узкие места которые для нас являются проблемой тоже за мысом языке про для нас эта проблема невозможно постоянно горизонтально масштабироваться соответственно рано или поздно придется дальше развивать эту штуку чтобы оно было быстрее и эффективнее поэтому нет в абсолютно во всех сферах есть куда расти только для того чтобы это сделать необхо дима обладать знанием и опытом в этой сфере конкретно в нашем случае да мы очень не хотим избавиться за киперов у нас практически к любой сфере при так или иначе последова на привязан и он доставляет большую часть проблем вы уже пытались пока нет моргающий но то хотя бы к этот об этом думаешь как ты думаешь какую сторону здесь улиц как избавляться я думаю именно менять собственное решение решения которые были сделаны у нас таким образом чтобы и покрыть задачу и меньше учитывать заки поскольку он нужен нам опосредованным нас нет задачи сделать его идеальным у нас нет задачи на него тратить ресурсы у нас есть задача именно нашу проблему решить ее можно решить в том числе к примеру уменьшив нагрузку на зу теперь предыдущую идею которую мы реализовывали она это не учитывал будущее будет когда вы строили вот этим про который рассказывал у вас были какие-то камни преткновения из-за чего то вы спорили чтобы у сложенными всего проблем не да наверное вот лично для меня это было проблема ранжирование аномалий я говорю конкретно про она любит а также систему которую мы сделали для чем нужно объяснить проблему комбинаторного взрыва у нас есть примеру там график с параметрами у нас есть страна оператор пользователь там и еще с десяток разных параметров каждой из них если примеру 10 параметров каждой из них по 100 то мы получаем 10 в 20 комбинации параметров и каждый из них может потенциально обладать цифры это безумный объемы и с этим как бы ну никто работать не будет но как при условии того чтобы примеру определяете 99,9 процентов всех значений а то есть три девятки это у вас немножечко нем много мало но 10 в семнадцатой аномалий и вот как как найти среди них аномалию естественно там есть ложноположительные естественно там есть обычная нам они естественно там есть изменение ожидаемые которые как бы попали под аномалию но это все надо со ранжирует до цифры естественно взяты с потолка никто не работает с 10 семнадцатой степени графиков потому что ну это прям очень жестко но даже с 1000 графиков проблема ранжирования она стоит очень остро можно сделать самый простой и понятный способ это когда вы берете и говорите что чем больше цифра в графике и реальным тем важнее номоли но в этом случае какой-нибудь интегральный график пользователей во всем мире скакнет на полтора процента вверх и вы визуально даже на малину доска главное но это будет самая большая аномалия за счет того что цифра само по себе больше нежели так дела у вас какой-нибудь стране конечно пользователь упала в половину там это катастрофа а эта аномалия ладно окей будем жить дальше и вот именно эту проблему я пытался решить это было две недели когда я просто сидел с гигантским номера не меняет курс а вот это сразу роль остыл какие-то дополнительные это метрики как вы поняли трандл для поршней роль как-то вытащил этом ну и вкратце примерно как что было запишешь ли те кто попугаев но коэффициент который говорил о строении реальность значений использую его из используя нормализацию на общий вес графика то есть отношение его числа к общей сумме всех графиков внутри там какому-то reporto и еще нескольких других коэффициентов я получил более менее функцию которая мне позволит выдать цифру по которой могу сортировать и эта цифра мне уже сделала что график с большим разлет am график с большей аномалий визуальных именно визуальный будет выше чем график с меньшим визуальным разлет успехов вам в работе над этим до строить систему изобретает посему больше надеюсь вы избавитесь на звуки пиры и сделать это отличные других научить и тоже будем посмотреть или итак небольшая техническая пауза про того чтобы мы снова переключились на зал я вижу что у тех кто смотрит онлайн есть вопросы о том как разобраться в том что происходит ребята все происходит нормально по расписанию мы отстаём сейчас минут на пять мы догоним все будет порядке и синхронизируется то что вы видите расписание с тем что вы действительно видите на экране я хочу поблагодарить наших золотых спонсоров это баду ролик которую вы видели мы постарались сделать технический ролик чтобы они были интересны еще и технарям также integrity solutions luxoft и neoflex и сейчас наконец-то будет доклад о том что знаете как вот у людей нормальную справедливость по крайней мере каждый из нас знают справедливо кто-то поступает или не очень справедливо с компьютерами не совсем понятно как стать им быть потому что у них вообще есть такое или нет как справедливость но в эту сторону подумал наш следующий докладчик и он расскажет о том как справедливо распределять ресурсы в кластере из яндекса встречайте пожалуйста так как вы хлопали про настроения игнат колесниченко так всем привет меня слышно ну что поехали говорят надо ускоряться меня зовут кольченко игнат я занимаюсь разработкой планировщик в компании яндекс а фактически мы в компании строим большие кластер а вот я содержание доклада будет пример такой расскажу вообще зачем мы это делаем и почему перед нами стоят те задачи которые я решаю вот потом я расскажу про то а что такое вообще планировщик что это за сервис чем он занимается и потом мы с вами погрузимся немножко красивые картинки в алгоритмы в математику и разберемся а как же по честному делить ресурсы на классе итак поехали значит как вообще устроена жизнь больших компаниях ну смотрите наверное там не для всех из вас это знакомо но вот индекс это реально уже большая компания это там больше десяти тысяч разработчиков какая-то не знаю я не знаю сколько точно но мне кажется сотня подразделения уже есть разные поиск банерная крутилка марки дзен и так далее бесконечное количество сервисов никто уже не знает сколько их вот что есть у этих сервисов у них во-первых у всех есть куча железа у них есть куча данных который не собирается обрабатывать и что самое неприятное у них есть общие данные но мы все с вами живем в век в персонализации индекс хочет строить умные алгоритмы которые там показывают вам правильную рекламу делают правильные предложения сделают хороший поиск для вас для этого надо данные из разных сервисов иметь там в одном месте или по-крайней мере каких-то очень близких места чтобы уметь их совместно обрабатывать и на основе этого строить кит не на этом умные модели машинного обучения вот ну как я уже сказал есть куча железа то есть каждого подразделение чтобы его данные хранить и обрабатывать это уже какие то не знает сотни серверов и что самое собственный не даже неприятное они которая данность которой приходится иметь дело которые мотивируют нас сделать то что мы делаем это у всех этих подразделений скорее всего очень непостоянна использование ресурсов то есть не за есть подразделение она понимает что ага я хочу не знает там в 12 часов ночи все логе которые за день на здесь обработать перри посчитать перестроить модель вот мне значит надо там и на часов ночи иметь не знает 200 серверов чтобы успеть это там быстро сделать чтобы уже днем работала новой модели там не знаю все было замечательно вот но оставшееся время и железо будет простаивать ну и для большой компании это все игре невыгодно если каждое подразделение будьте по 200 серверов из которых не зная ни там три часа будет работать эффективно оставшиеся 21 так себе не будут загружены но значит куча железа простаивает собственно сейчас в графике которая объясняет то о чем я говорю вот этот график он описывает некоторую долю вот этому изолят нам наши самые большие кластеры посчитали долю используемых ресурсов на кластере разными подразделениями у вас должно возникнуть вопрос почему она больше единицы на этот вопрос вы узнаете ответ в конце доклада когда его до слушаете вот но пока это некоторая данность мы научились распылять ресурсы так что доля получается чуть больше единицы ну окей хорошо научились научились дальше то что а вот следующий график это тот же самый график сна на предыдущей картинке но в каждой точке я посчитал максимум за предыдущий 12 часов этот график объясняет почему людям подразделениям выгодно сожительствовать вместе если бы они ни а сожительствовали вместе то им надо было бы не знает am в полтора два раза больше ресурсов вот а так они все объединились в один кластер эффективно его утилизируют и при этом решают свои задачи собственно ну повторю ещё раз и ещё на самом деле одну мотивацию сейчас расскажу почему выгодно не 50 маленьких кластеров иметь каждому подразделению свой а иметь один большой кластер вот представим что не знаю каждое подразделение имела бы свой маленький кластером и не знает например hadoop а вот тогда если у вас не знай кластер hadoop она серверов вряд ли ваши разработчики захотят его поддерживать вам нужен быть какой-то и сырья который будет его администрировать обновлять не знаю диагностировать проблемы в общем ну пусть даже это будет там один ну или там не знаю в каких то больших подразделения два человека мы умножаем это на 50 получаем не знаю там от 50 до 100 разных там высококвалифицированных админов и сырья hadoop а вот у нас же единая система своя под названием войти единая команда который разрабатывает вот вся команда это 30 человек мы все инженеры все немножко и сырья ну выгодно на лицо компании у компании не 50 одиноких и сырая которые обменять свои кластер одна большая дружная команда которая новые фичи пилит и поддерживает текущие железо текущие поднятые сервиса собственно что такое войти ну это про что дальше будет идти ну дальше будете доклад про одну из компонент нашей системы собственно войти это некоторый наш внутренняя самописная система которой уже более 10 лет более-менее то налог ходу по наша система умеет хранить данные экзабайт и данных умеет их обрабатывать вот у нас как я уже сказал примерно 30 человек разработчиков и админов в отделе по факту такого разделения явного нету мы все хорошо понимаю какой код мы пишем имеем его же диагностировать выкладывайте и так далее вот у нас больше тридцати тысяч серверов в эксплуатации которые хранят данные обрабатывают вот ну и вот на самом большом кластере для которого я до этого показывал графике у нас примерно миллион сепию сейчас в обслуживании собственно чем занимается кластер а тоже это уже немножко проговорил значит чуть чуть больше деталей для того чтобы вы лучше понимали что будет дальше происходить есть такие сервисы называется мастера это такой аналог на i'm not языки пера в ходу пи то есть это некоторая репрессирован и стоит машина которая хранит эту информацию про то где какие данные живут на каких хостах она же умеет нам реализовывать локи в общем такой надежная in memory хранилище я собственно непосредственно ноды которая занимается полезной нагрузкой они хранят во-первых данные во вторых их обрабатывают и not очень много их там десятки тысяч собственно есть обработка данных которое производится на нотах и также вот есть та часть про которое бы рассказывать это scheduler планировщик но это аналог ярно в ходу пиво в hadoop есть такой я уже забыл как расшифровывается ета на за ресурс нига шейкер кажется вот есть такая система которая собственно планирует вам где какие впечатления запустить вот я разрабатывать такую систему только там в нашей инфраструктуры вот ну и это уже для нас не очень важно у нас есть не знает какие волю хранилище мы умеем данные которые мы мы приду сам как-то обработали получили по кнопке поднять не знает начать с них сервис нагрузку наружу то есть такой real time restore очень уже поднимать ну вот примерная схема показана как это все выглядит есть вот мастера собственно которые хранят в эту информацию нам эта информация уже очень много когда вот десятки тысяч долларов поэтому это не просто там одна тройка серверов это какой-то сложный протоколу общение между ними есть прокси который собственно стоят таким забором между тем что происходит в кластере пользователями есть планировщики которая собственно вот про них я буду сейчас рассказывать буквально через две минуты которые занимаются планированием к ним приходят пользователи говорят я хочу обработать эту табличку на петабайт а он решает где какие же бы мы запустим сколько мы параллельно и будем запускать и так далее есть агенты агенты собственно план составляет вот планировщик не думает о том как ему спи давай там данных поработать он говорит агент решили сколько у тебя будет рабов как это вообще все будет что в какой постоянстве запускаться планировщик только разделяет этим же бы на ноты вот ну есть собственно но до отвечу на не заданный вопрос который наверняка вы захотите задать а почему не ходу почему мы строим свою систему уже десять лет там вкладываем в этой силы почему просто не возьмем ходу ну вопрос как бы ответов несколько разных вот 1 ответ про то что hadoop не умеет в наши масштабы я уверен что не знаю кто то из вас наверняка видел hadoop на сотни not я знаю что из hadoop и на 1000 not не знаю что еще компании criteo у них кажется кластер на 5000 ноты 50000 цепью вот ходу пав нашего размера скорее не бывает либо бывает не знаю словно в фейсбуке но там это ходу в версии там 14 которая не от форк 0 это же 10 лет уже сами развивают что нельзя назвать в чистом виде ходу по ну еще часть мотивации стоит том что у ходу по достаточно большая кодовая база и туда достаточно сложно засылать очень многие патчи и которые мы видели как люди их дизайне то засылает занимает не знаю там от полугода до года для того чтобы добавить какую-то новую важную функциональность ну конечно коммерческую компанию это не очень устраивает ждать полгода год надо будет for cats hadoop как-то не очень хочется вот ну и кроме того про фичи на самом деле мы решаем задачи наших пользователей наши пользователи там десятки тысяч разработчиков яндекса вот и мы умеем поддерживать для них многие разные вещи которых в ходу пи нет например мы умеем нашим планировщики в интегральной гарантии если интересно спросить и потом в кулуарах я расскажу что это такое как они работают мы умеем решать задачи фрагментации накласть или ну и на самом деле мы умеем хорошо делить кластер hadoop этого не умеет опять же я не буду сегодня рассказывать про так как это делает hadoop и почему но как он это делает это некорректно но если вам интересно спросить и расскажу собственно поехали ко второй части давайте разбираться кто же такой планировщик какую задачу он решает вообще с кем он общается что он делает важный disclaimer если вы знакомы с хату по мто выдано знакомость про ноги и ходу по ходу пи жизнь устроена таким образом там есть job это собственно такая одна большая задача хочу обработать вот эти файлики в этой папочки вот таким то кодом положить их это другое место ну по историческим причинам у нас это же называется операцией а то что в ходу пи называется джо пам у нас это на самом деле то что в ходу пи называется носкам у нас это называется в жопу так как я это терминология пользуюсь буквально каждый день я к сожалению не смог доклада перестроиться и рассказать вам другой тебе ноги поэтому буду рассказывать в нашей терминологии но понимаете что операция это вот большая задача a job это уже конкретная маленькая задача которая будет исполняться на конкретной надя с конкретными там ресурс лимитами собственно с чем приходится иметь дело планировщику ну вот использовать или пользователи приходят со своими запросами но запросы там какие-то входные данные там не знаю список таблиц перечисленных кит выходные данные куда собственно пост о каком эти данные по фильтруем не знаю там или обработаем нашим замечательным бинарник а мы положим это собственно писание того о чем надо запустить вот ну у нас такой интерфейс более низкого уровня вы он не не вложен в java как не знаю как в ходу пи то есть можно запускать просто произвольный код который вы собрали вот мы важное для нас часть это собственно вот эти вот гарантии не знали clicker или нет это то сколько secu нужно одному джаббу для исполнения этого кода сколько памяти ему нужно вот ну и пул это вот некоторые вещи который будет важно для частности скоро вы узнаете что такое собственно кроме того планировщик общается с модами класс tera bond он должен запускать жабы модель общения примерно такая надо приходит сообщает начинаний уже бежит что запущена сообщает что а у меня тут вот эта задача доработал это задача доработала у меня теперь не знаю 75-ю свободное 20 гигабайт памяти а вы дай мне новые работы вот ну соответственно в ответ scheduler планировщик сообщает надя какие-то новые джаббы потенциально он может решить что что-то надо попортить прервать но потому что не знаю на вылезла за какие-то положенные ресурсы вот кроме того есть агенты который как я пускал составляет план операции ну там достаточно сложный протокол общение с ними планировщик рассказывает собственно ted успеху которое вы видели агент из нее составляет на большой сложный план а как операцию исполнять но это нас сегодня не сильно будет интересовать поэтому пойдемте дальше вот картинка иллюстрирующее что происходит если у них разработчик за своим ноутбуком он стартует операцию эта операция там превращается некоторые запрос пример каким-то агент составляет ее план после этого планировщик общается с нодами ноты приходится свободными ресурсами планировщик идет снова к агенту и говорит а вот у меня есть бирка на кластере найди мне тут окуните работу ну агент знает какие есть операции горит окей вот тебе чтоб под эту дырку немножко про нагрузку тоже протон с чем нам приходится иметь дело но вот кластер дорос до таких размеров и до такого масштаба что у нас уже 16 тысяч орбита в секунду то есть вот это единственный сервер то есть планировщик это сейчас один процесс на одном сервере он обслуживает 16 тысяч запросов в секунду от нот вида а мне этот счет закончилась найди мне какую-то новую задачку запустить вот ну по факту это 16000 очень непростых ирбисов это достаточно сложные тяжелые запросы и скоро станет понятно почему немножко еще статистике собственно наш планировщик планирует 7 миллионов операций в день примерно 7000 джабба в секунду заканчивается то есть на самом деле на каждой ноге достаточно часто что нибудь заканчивается примерно 600 тысяч раз планировщик пытается вот конкретную дырку освободившуюся на ноге пристроить какой-нибудь job ну его покинуть причинам не получается не знает о юните фильтр стоит на джаве что тут не надо не зная или там по ресурсам он фактически не подходит но общем примерно такие вот масштабы и цифры того что происходит в этом одном процессе окей собственно такая самое алгоритмическая может быть сложной она может быть и наоборот самая увлекательная часть про то как же наш огромный кластер наш огромный торт по честному поделить между теми отделами которые принесли в него ресурсы то есть картинка такая у вас не знаю есть много много разных отделов каждый из них самостоятельно покупает железа зато центр ну дата-центры единые там не знает и железо как-то ставят вместе вот и дальше они все говорят окей это железо ваши смысле мои наши вот нашей системы но так конечно не работает если нам просто дадут железом и никаких обещаний про него не дадим то люди скажут не хотим так мы лучше тебя собственной кластер hadoop а поставим будем сами заниматься утилизацией этого железа поэтому не просто должны принять железо мы должны про него пообещать что то мы должны дать каких гарантий собственно про гарантий еще буквально через пару слайдов будет а пока давайте поймем что же известно планировщику и какой то не знаю простой алгоритм посмотрим увидим как вообще планировщик мог бы решать задачу собственно планировку известно следующее вот из какие-то ноды на них из какие-то ресурсы вот эти вот два столбика это такой профиль ресурсов на самом деле первая часть 1 столбик это обычно быть сепию у нас второй столбик это будет рам соответственно есть операции и операции есть жабы но вот вы помните там уже оба были написаны 10 цепью 20 гигабайтам это вот будет как какие-то два столбика на самом деле собственно планировщику надо как-то вот эти вот столбики операции сопоставить свободные дырки у ног также можно это делать ну немножко еще на следующем слайде будет рассказано никто уже простая стратегия тут еще немножко вводных какой модели на самом деле будет делать планировщик значит водные такие в кластере очень много нот и средних с очень маленькой ну вот вы помните по 7000 дубов заканчивается в секунду ну если не знаю там на хвосте 50 цепью то примерно так и получается что средняя длительность одного джабба примерно минута вот как следствие мы не можем решать задачу не знает нам раз в минуту мы не можем 1 минуту прийти посмотреть на все операции посмотреть на все ноды решить ага давайте вот это сюда поселим это сюда постелем тогда мы минуту не будем ничего планировать на ногах очень быстро по заканчиваются какие-то джебы и ресурсы будут простаивать но все время будет такой мы загрузили кластер на сто процентов он так выдохнул и стал загружен на половину потом снова загрузили на сто процентов он выдохнул и стал загружен на половину хотим его все время грузить работой не хотим чтобы ресурсы простаивали окей теперь пора купить простую стратегию вот самая простая стратегия называется фифа мы берем все операции выстраиваем в очередь у каждой операции вот есть профиль рабов которое она хочет приходит к нам надо собственно с hard by там и мы вот на этом аду скорби там на ее свободные ресурсы хотим чуть поселить ну вот мы смотрим не знаю у нас есть первая операция есть первая операция вот оно ну она у нее но уже полностью все заселила смысле все за все запустила у нее юзать шрайн диман да она ничего больше не хочет поэтому я ими даже ничего предлагать не будем есть вторая операция вот она у этой операции есть свободные ресурсы но у нее профиль не тот вот видно что не первый столбик маленький он подходит а второй столбик большой он просто не вписывается в то что есть на надя ну не знаю там на надя освободилось 5 гигабайт a job хочет 10 ну сорян запустить не получится ну и вот есть третья операция которой есть и свободные джаббы и столбики вписывается можно видимо там взять один job этой операции и на этой ноге запустить победа ну тут справа немножко формализма введена про то как собственно работает такая стратегия сифон вот ну понятно дело что стратегия замечательно своей простотой но также она замечательные своей не практичностью мы-то у нас ни один клан то есть если вы были небольшой отделал и там кластер на 50 not to наверное вам тоже подошла бы фифа стратегии но у вас не знает что операций одновременно бежит как-нибудь все срастется если же у вас там кластер в котором сотни подразделений и запускает свои операции это очень странно выстроить все операции в очередь и так жить и что вот придет какой-нить аналитик запустит какую-то операцию которая делает куни гриб логов и бежит не знаю там полдня и все остальные protection процессов станут конечно так не годится собственно ну для этого предлагается ввести пулы то есть не просто пришел какой-то отдел принес свое железо поставил в кластер а дальше надеяться на чудо нет он пришел в отдел поставил свое железо еще сказал а вот вы меня теперь там ресурсы которые на этом железе были те цепью и память напишите пожалуйста свой конфиг и будьте добры соблюдайте тоже написано конфиге я ничего тут вот собственно получается такая модель есть конфиг в конфиге написаны какие-то отделы не знаю там поиск market зан написано сколько железо они принесли вот ну и дальше операции они запускают каждой своем конфиге ну понятное дело что нужно 5 система прав должно быть так что разработчики из поиска могли запускать операции только в поиске что ты не мог свою операцию кому-нибудь подселить ну это такая уже техническая деталь собственно все делать планировщику вот у планировщика встает вопрос пришел карбид на нем есть свободная дырка какой операции предлагать раньше была единая очередь мы шли по очереди находили теперь есть титул и непонятно как выбирать ну на самом деле на этот вопрос не сложно найти ответ собственно предлагается такая стратегия на основе pharmacy все следующей стратегии они будут иметь в целом такую же схему такой же план для каждого плащ time некоторым честную долю она будет называться у нас fashion честная доля по-английски и читаем некоторые ну как бы у нее есть юзать сколько реально ресурсов уже в этом поле потребляется вот мы будем этот usa что же переводить некоторую долю а вот то что здесь написано сокращённо называется юзать шер и будем сравнивать эти два числа и будем просто напросто искать тот пул у которого это отношения минимально это очевидно тот отдел который больше всего страдает что он уже захотел ресурсов а потребляет он мало вот понятно что наверное давать тому как бы сейчас больше всех обделен вот ну исходя из этого рождается простой алгоритм вот простой алгоритм описывается на своей для одного ресурса когда ресурсов многое уже возникает разные вопросы на которые мы ответим но пока ресурс один вроде бы всё совсем просто предположим у нас есть только сепию предположим что нас есть ресурсы нашего кластер это вот этот прямоугольничек синий водой и есть такие вот три пула здесь нарисованы значит что тут нарисовано каждый пол на самом деле вот его прямоугольник это то сколько ресурсов он вообще хочет ну вот пришли запустили операцию на тысячу шагов вот у вас там столбик высоты 1000 получился ну по факту столбик высоты 1000 умножить на то сколько сепию хочет один ваш стоп то есть еще гарантия то сколько у вас конфиге написано это вот оранжевые засечки тут собственно как делить ну вот предлагается мгновенную честную долю раздавать пропорционально гарантия но и не выше чем то сколько вообще хочет ну глупо если вы пришли запустили операцию на тысяч рабов глупо вам говорить окей мы вам обещаем сейчас прямо сейчас 2000-ого мне нужно две тысячи но как раз хотим пообещать 1000 оставшуюся тысяч распределить между остальными потому что они не просто так пришли сожительствовать друг с другом а для того чтобы пока один не использует ресурсы остальные в пире использовали но и за счет этого эффективнее и быстрее выполняли свои задачи собственно вот ну начинаем наливать происходит вот такой первый этап наливании пока во втором пули мы не дошли до диман да ну и потом до наливаем весь остаток 2 пол больше не хочет в 1 в третьем и доливаем пропорциональные и гарантия ну получается такая картинка вот собственно то что синие мы тут на считали это та честная доля на которому сейчас будем ориентироваться при планировании когда к нам придет надо со свободными ресурсами мы будем на вот это синее число ориентироваться а про оранжевое уже забудем собственно ну вот что происходит когда приходит надо пришла надо на ней вот есть там свободные ресурсы я например с одним ресурсам работаем у каждого пола есть какой-то юзать сколько вот реально уже там запущена врагов и потребляется и есть вот это частная доля ну вот мы выбираем просто тот у которого это отношение минимально но в данном случае это 3 pool ok поехали дальше ну ресурсов ни один на самом деле если вы начнете планировать в кластере только сепию быстро выяснится что есть всякие машинное обучения которые памяти хотят больше чем сепию них тип модели там на сотни гигабайт оси пью нужно там не знаю всего десяток и вы не сможете просто 0 вы либо запустите как бы не явно займетесь и пью либо запустить я памяти вообще не хватит и процесс упадет конечно так делать нельзя поэтому предлагается когда у нас есть будет на вектор ресурсов то есть какой-то такой не знаем два столбика предлагается смотреть в этой паре столбиков на такую доминантную долю то что называется то есть мы берем все ресурсы кластера суммарно по всем ногам суммируем это такой вот наш большой total который здесь нарисован слева а дальше есть не знаю зачем юзать же можно посчитать его долю теперь который который мы дальше хотим оперировать в нашем алгоритме планировать но в данном случае это доля одна треть относительно и потребление рама меньше чем относительно и потребление сепию вот поэтому доминантной долей вот этого правого набора столбиков будет одна треть ok собственно как теперь делить ресурсы мы делим мы на самом деле по-прежнему просто мы теперь на demand смотрим тоже как на долю такую вот у нас теперь есть такие уже пора плов у которых demand какой-то непропорциональный гарантии все еще будут такие не учитывающие то что ресурсов много то есть гарантия формулируется в доле кластер а ну и мы просто берем и доливаем эти ресурсы пропорционально гарантиям но не выше чем самый высокий столбик то есть если здесь у какого-то из полов вот этот прямоугольный столбик был бы ниже чем гарантия там и выше него наливать бы не стали ok что дальше происходит при планировании но теперь на самом деле надо как-то решить что такое вот это вот user поделить на пейджер раньше это были два простых понятных числа ну теперь мы не просто так выделять доминантную долю теперь на самом деле это просто отношение доминантных долей ну вот на этом примере видно что вот есть левый пул у которого какой-то фишер мы насчитали есть у него usa чем доминантный you such него явно по раму по второму ресурсу ну вот он там падает и отношения примерно равно пять шестых но право пола наоборот доминантной сыпью и там наоборот отношения по первому столбику считается то есть это 6 5 вот ну значит надо ресурсы предлагать вот первому полу окей что ж происходит более глобально ну вот более глобально происходит следующее у нас есть ну допустим у нас не знаю чистый кластер там написали какой-то конфиг запустили его и начали приходить какие-то операции запускаться джаббы но от процесс будет примерно таким образом устроен мы посчитали какие честные далее дальше орбиты хандрит их орбитах орбиты мы запускаем запускаем запускаем запускаем столбики растут растут и растут и растут но и вот тут видно что если есть два процесса и у них непропорциональное потребление ресурсов то они на самом деле с точки зрения честный до лидер сидят больше чем я несу кластер а первый съезд как бы 8 седьмых от того что ему обещанный второй съезд восемь десятых от того что ему обещанную ну и разумно они как раз один использовать скорее всего другой скорее память поэтому с точки зрения своей частной доля не как бы даже больше единицы кластеров могут потребить собственно ну я вот там на паре слайдов до этого была ссылка про drf это не то что мы придумали это была такая статья он реализован тоже ходу при этот алгоритм статья кажется 11 года он обладает разными доказанными математиками свойствами он во первых такой алгоритм доедайте ресурсы кластер а то есть всегда когда вы такой алгоритм используете и у вас есть достаточные demand от операции вы по какому нибудь ресурсу весь кластер должны будете съесть ну по модулю там проблем с фрагментацией он поддерживает собственно несколько ресурсов там secu epam в данном случае дает гарантий по доминантному ресурсу то есть к сожалению гарантий нельзя сформулировать вида я принес не знаю больше secu и меньше памяти вот не вот гарантируете вот то сколько я принес нет вы должны приносить столько ресурсов как бы как вот вообще в целом ситуация на кластере устроена не может быть так что на кластере миллион сепию и миллион гигабайтов памяти о вы принесли там 200 пишите пью и 50 тыс гигабайтов памяти так сожалению не работает вот ну это же полезные свойства излишки он раздает пропорциональную данным гарантия то есть если кто то не доедает ресурсы сейчас то всем остальным они будут равномерно наливаться собственно чего не хватает не хватает на самом деле двух вещей но вот одна вещь про которая уже сказал это про то что гарантии только были над мир искусства формулируется на этом через пару минут поймем а еще не хватает иерархия на самом деле вот нам яндекс поиск какой-нибудь там на одно из самых крупных подразделений в яндексе он очень большой и там внутри куча тоже разных процессов куча разных каких-то служб в которых тоже у всех свои вычисления это может быть немножко свои данные они не хотят иметь один пул в котором все будут становиться в одну очередь они тоже хотят внутри себя какие-то подплыл и имеется тоже как-то распределять ресурсы ну вот тут не знаю есть простой пример прям вот в консольки я запустил на нашу команду line утилиту корневых пулов у нас там 170 но из них может быть типа 70 технически х100 реально соответствует каким-то делом а вот если пойти в глубь то там плов уже больше двух тысяч вот то есть мы на самом деле хотим картинку примерно такую ну тут понятно делом так очень урезанном виде нарисована реально я думаю начать рисовать все наше дерево плов это будет такая очень монструозный дерево собствен предлагается сделать такой иерархический der значит чем мы будем делать предлагается очень простой план ну вот у нас есть схема как мы делили ресурсы в корне вот мы взяли ресурсы сего кластера есть полы в корне пошли в них навели ну давайте повторим это дальше просто рекурсивно ну там мы налили в какой-то пул пойдем в этот пул посмотрим на его детей и там тоже нальем ну вот есть корень налили пошли в ребенка сказали окей но там у нас уже там всякие demand и не так интересует вот у нас насколько мы в этом полу выдали давайте выдадим дальше ну пошли выдали вроде все нормально окей ну надо еще schedule ить уметь планировать ну точно так же будем выбирать пол с минимальным отношением юзать ширк фарша берем не знаю корень в корне выбираем вот опять же тот же самый вот этот верхний пул явно здесь отношения пять шестых поменьше ну вот у него есть какие-то двое детей ну и у двоих детей опять выбираем тот у кого отношении поменьше то есть вот этого ну казалось бы все очень просто иди зачем про это говорить но на самом деле есть проблема к сожалению мы не статический четырем кластер не то что у нас пустой кластер пришли какие-то операции запустились мы туда счет запустили и всем и задачу решили к сожалению операции приходят-уходят что запускается и возможно вот ситуация описана этом рисунке ситуация какая есть два пола в корне значит вот этот правый пул у него вроде как все хорошо по его честное доли ну не вот явно в первом столбце ему выданы уже больше чем пообещали есть 2 у которого ну как раз не до выдано очевидно надо идти давать второму точнее начинаете давать первому то что втором уже все хорошо но на самом деле у второго в его детях полная беда у него там есть первый ребенок который явно ему не докармливают его не дают ему ресурсов вот но мы этого не видим а за то что не из правой сосед у которого все хорошо ну и и так реально могло получиться потому что не знает нам левого левый под пул вот у правого под дерево запустили позже вот этого не было операций там было все хорошо был запущен только правый ребенок все насыщена все отлично потом запустили левого и приехали левому с точки зрения родители не видно что у левого проблемы у тем что же с этим делать но на самом деле есть простое решение называется satisfaction hdr off фактически ситуация такая есть даже статья специальный про her all our hair холдеров чуть попозже вышедшая чем статья проверив но там очень непонятная и плохо доказано и решение вот поэтому мы когда-то лет не знаю пять назад по думали и придумали свое решение очень простое давайте мы привод принятие такого решения будем смотреть не на текущие подпылы их вот эти вот удовлетворенности usa решили поделить на фишер а возьмем все под дерево и в нем возьмем минимум то есть будем идти туда где реально сейчас самая худшая ситуация но в данном случае когда мы посчитаем минимум вот в этом по дереве окажется что это минимум равен 1 2 поэтому мы должны когда предлагаем ресурсы освободившийся на ноге выдавать мы должны идти вправо и под дерево ну это мы уже понятно дело пойдем в страдающего левого ребенка вот но мы даже писали статью к сожалению не хватило сил чтобы ее довести до ума и там послать на какую-нибудь приличную конференцию вил би би или евро сиз но если вам интересно почитать как это работает и почему это тоже доказуемо корректно скажите мне я вам пришлю этот текст ok чего еще не хватает но вот как я уже говорил еще не хватает векторных гарантий на самом деле люди реально хотят гарантии которые непропорциональной по себе память в нашем кластере не зная пропорционально что-то в духе на один secu четыре с половиной гигабайта а есть не знаю люди которые занимаются только машинными обучения me никто большое дело не знает sale drawing app sync все процессы они там про машины и обучения так или иначе им нужна гарантия очень непропорциональные то есть они хотят платить поменьше покупать поменьше железа и за счет того что остальные процессы наоборот память хотят меньше чем сепию получать такие векторные гарантия собственно ну хочется как здесь нарисована на правой картинке вот так не хочется хочется вот так вот ну давайте это сделаем собственно что будем делать давайте скажем что гарантии теперь могут быть непропорциональны ну вот здесь нарисованы такие оранжевые рисочки неодинаковые для левой и правой части и начнём раздавать ну вроде бы понятно берем тоже пропорционально этим листочком наливаем ресурсы все налилось вроде бы сейчас вот там уже решение получится давайте раздавать дальше у нас графическая схема даже не только корень вот пусть у этого там не знали а вакула куда мы вот уже выдали какую-то частную долю вот это вот синенькая налитая жидкость пусть они и два таких постулатов пусть на самом деле его гарантия формировалась из гарантий такого левого ребенка а в правом не знаю в проулке там research процессу живут в которых гарантий никаких нет вот ну и продолжим наливать ну получится на забились очень странная ситуация то есть не то чтобы что-то сломалось но есть к этому вопросу некоторые то есть дамы тому левому ребенку которого есть гарантии нальем его гарань ну нальем этот частный фарша а правому ребенку нальем все оставшиеся на правый ребенок на самом деле не хочет такой пропорциональности него есть какая-то пропорция между его там потреблением secu epam а мы ему выдали честную долю которая этой пропорции не очень соответствует ну так странного-то на самом деле собственно эта сторона во то есть приводит к тому что ну такой алгоритм по честному не работает то есть если начать пытаться доказывать принимает свойства ничего не выйдет будет плохо будет даже хуже чем когда мы раздавали прямоугольники вот поэтому мы сели с моими умными разработчиками долго-долго подумали какие-то разные математические модели по применению и придумали как это сделать я к сожалению эта часть сложной я сейчас не буду рассказывать и в деталях в кулуарах могу попробовать рассказать но я расскажу путь в общую идею состоит в том что но не надо пытаться действовать наивно надо пытаться в корне раздать ресурсы детям пропорционально гарантиям и на этом как бы успокоиться на самом деле надо разобраться про каждый пул в какой пропорции ресурсы он хочет вот и дальше научиться эти пожелания ресурсов склеивать вверх по дереву то есть если мы для каких-то не зная там операции понимаем что у них там все живые гомогенные они вот хотят ресурсы в такой пропорции но мы можем их склеить и почитать в какой пропорции теперь полу во что ресурсы а потом для этого пула можем склеить его соседями и снова посчитать эту штуку вот получается в итоге такой вот график то что мы называемся чащин это вам предлагает какую-то долю кластера по оси x но собственно вот давайте и назвать yx а мы говорим - на вид для каждого ресурса строим график какую реально долю от этого ресурса мы можем потребить ну вот на этой картинке видно что у нас есть значит левый сын который потребляет сыпью иран равномерно поэтому в начале первая часть графика будет такая одинаковая у нас цепью epam вместе идут а потом когда мы 1 насытили у нас есть 2 по пунктам или 2 под операция которой нет гарантий ну и есть demand и вот ресурсы мы должны выдавать пропорционально этому диван да ну вот нам видно что график сепию и рама расходится возможно в какой-то момент не знает там если 2 подплыл был пониже то график бы даже не дошел бы до единицы в тот момент просто раз и превратился в константу ну что всем и весь demand удовлетворили дальше давать никуда ну собственно вот мы научились строить такие функции научились нам придумали как это математически их сочетать в под пулах неожиданным образом это можно там за линейное время даже вычислять вот вначале у нас не получалось ну и в итоге мы избегаем диспропорции между командами флэша мы имеем реальные ресурсы детям выдавать в той пропорции в которой они сейчас их хотят вот мы на самом деле мы планируем детали опубликовать в статье ну как минимум на хабре а как максимум все-таки в какой-то какой-то такой научной конференции вот тут видно собственно комет который это делает был он примерно чуть больше года назад сделан вот моим коллегой который к сожалению ушел в науку вот но на самом деле он сделал очень большой вклад большой взять спасибо андрей тонких его зовут собственно мы научились непропорционально выдавать ресурсы мы научились выдавать нашим пользователям гарантии который не одинаковы по secu и по памяти собственно пришла пора ответить на тот вопрос который был поставлен в начале и который был не отвечу почему же тут сумма больше единицы но смотрите вот этот график это на самом деле график того самого фар шерпа корневым под пулом то есть у нас есть корень есть вот отдела у каждого из которых есть свой пул и там есть график и в частные доли так вот за счет того что мы внедрили векторные гарантии здесь сумма стала больше единицы то есть какие-то отделы которые хотят скорее степенью чем ram но и мы для них эту долю считаем пасеку а есть те которые хотят с карьером чем себе мы для них долю что им парам в итоге когда мы все это просуммируем получится больше единицы с этой диспропорции вот такой вот ответ то есть на самом деле мы смогли более гранулярный более правильно гарантировать кластер в каком смысле смогли больше единицы кластер гарантировать нашим пользователям за счет того что они хотят цепью больше sepia меньше рама другие наоборот больше рама меньше себе и собственно ну на этом более менее все давайте буквально за минуту подведу выводы значит выводы какие ну во первых задач планирование такая простая как кажется когда-то когда мы изучали этом статьи не знаю лет 5 назад казалось но вроде все просто там вот есть ходу перелезать сейчас возьмем ее повторим не знаю вроде все понятно потом когда начинаешь вдумываться и вдаваться в детали оказывается что есть масса разных нюансов которые в частности в ходу пи решено просто некорректно необходимо уметь планировать несколько ресурсов хотим строгий гарантии на полах хотим и рожу полов это все реальные нашей бизнес требования открыть никуда не деться немножко еще расскажу про то что умеет наш планировщик вот как я уже играл он имеет обеспечивать интегральные гарантии если интересно потом спросить я расскажу что это такое ну идея на это более-менее когда мы хотим не мгновенно себе какую-то какие-то ресурсы получать грамм и хотим сказать что но нам в сутки в среднем 1000 сепию у нас тут ресурс процесса для них не знает во время выполнения так важно главное чтоб не знает за 5 часов она как-нибудь добежала сколько вы прям сейчас будете им давать ресурсов не так важно умеем на самом деле поддерживать планирование по чапаю у нас большой парк depay'a хостов и там есть свои сложности с тем что люди хотят запускать какие-то смешанные 4 сепию обучение хотят распределенные читы и обучения на десятки хостов запускать и они еще зараза очень непохоже на то что было мочи вычислениях там не средняя длительность ни одна минута и у джабба не знаю а там полдня если не день умеем на лету изменять гарантии то есть можно прийти и сказать ой а давайте в этого пола будут другие гарантии или в этой операции умеем также фактическое потребление учитывается то есть если пользователь пришел сказал я хочу 10 цепей оптом выяснять что эти степени потребляет мы берем извини друг но мы тебя сейчас подожмём до 5 опять будем давать другим людям которым они реально нужны вот ну как то так всем спасибо если есть вопросы задавайте спасибо большой игнат у нас есть ли тебе подарок конечно памятная рамка и если замечательное худи эмблемы highload поднимайте пожалуйста руки у кого есть вопросы 1 рука вижу и на первом ряду вторая рука а в это время руслан из из онлайн и задал вопрос говорит к сожалению не может подключиться он в эфир чтобы задать я задам за него можно тоже защитить зачитывать потому что приз достанется в том числе если человек из онлайна задал вопрос у него 2 учитываются ли локальность данных при выделении ресурсов 2 если в вашей модели механизм прям шум смотрите на оба вопроса ответ да на первый вопрос и он на самом деле такой с подвохом каком-то смысле то есть мы когда система писали мы локальность данных учитывали но потом с ростом пропускные способности сети просто способности дисков стало понятно что вероятно это не самое важное на сейчас континентальная поддержка есть да есть ощущение что вы можете даже выключим потому что связано сентри кластер очень хорошая и локальность данных реально не так важно а на второй вопрос если прям шиндо есть прям что это отдельная большая сложная задача про которое к сожалению в рамках доклада не рассказать но очень многие проблемы которые мы вот решаем нашим планировщик они так или иначе связаны с прям что без причины соблюдать честность конечно не выйдет все еще может прийти разработчик запустить глеб логов там выходные на миллион шагов он зависнет и дальше эти ресурсы будут заняты этим разработчикам и никому не не будут выделить поэтому чтобы обеспечивать честность надо надо вытеснять джаббы это супер первый вопрос пожалуйста представляетесь у кого уже есть микрофон вставайте и говорить о представьтесь и задавайте свой вопрос и 2 будет 1 ряда или не донесли хорошо у того кого есть микрофон вставайте представляйте задавайте вопросы здравствуйте меня сергей зовут спасибо за доклад вот у нас тоже систему есть которая распределяет ресурсы она чуть попроще моделью она учитывает только временно которая ресурс будет зданию то есть нету вот двух столбиков как быть если тот кто запрашивает ресурс он может обмануть и занять на дольшее время ну то есть в ваш в вашей системе это как-то применимы или нет так честно распределить в таком случае что с ним делать хороший вопрос смотрите в нашей системе мы естественно и ну как бы вот по место где мы не верим пользователя то что нам рассказал про памяти про secu и как я сказал мы умеем поджимать secu память про время мы не спрашиваем мы не знаем сколько она бежит но добывает системы где люди ориентируются на время и кажется в этом случае надо от пользователи требовать уметь такой мягкий прям чем делать вы можете запустить его на час он часто работает отпускать друг извини ты обещал за час за часом не ложился мы тебя вытесним из на еще через час митя запустим снова учись подниматься как бы своего промежуточного состояния и такой первая мысль пришла в голову нас намекаешь надо изучить литературу понять как как правильно ваша ситуация спасибо ребята поднимаете пожалуйста руки потому что мы успеваем протирать микрофон и дезинфицировать их перед тем как передаем следующему бы сейчас уже есть микрофон остается человека поднимайте руки заранее чтобы успели вам в принести здравствуйте меня зовут сергей я руководитель отдела поиска зонт спасибо за доклад я не совсем права планировщик хотел спросить салат вначале были отсылки hadoop он и вы сказали что он не выдерживает кастера таких масштабов можете прокомментировать во-первых проверяли ли вы как-то это на свои инфраструктуре там теоретически для на практике и второе в каких именно местах он перестает работать на таком масштабе кластером к сожалению очень плохо слышно можете мне помочь разобрать вопрос ребят давайте туда выходить на сцену и судоводитель у нас действительно немножко гулкий звук беги скорее это же не про смотря на чтобы тебя докладчик слышал рядышком до поднимайте руки дальше пожалуйста так не знаю отсюда слышно даже совершенно когда поднимайся вопрос был про hadoop вы упомянули что на вашем объеме кластер hadoop уже не будет работать первый вопрос пробовали вы как-то это проверить и 2 в каком именно месте он перестает работать смотрите пробовали мы мне кажется лет пять-шесть назад всерьез смотрели на ходу по мы его разворачивали на тысячах not перестает работать в разных местах смысле разные места начинает упираться в производительность не знаю там планировщик не тянет только задач где-то там утилизации ресурсов начинает падать потому что не знаю плите чем мастера не умеют так на такое количество нот распределять свои дома придет джебы но опять же если может быть часто чтоб поменялось что ходу пять лет назад х так сейчас немножко разные системы но пугает то что нету таких инсталляций то есть если кто то пришел и сказал посмотрите вот он уже работает все хорошо вот мы проверили мы там не знает такие же объема как вы обрабатываются замечательным можно было вернуться к этому вопросу а так к сожалению не дашь и у нас есть много свободных рук чтобы пробовать другие системы на таком масштабе что это очень дорогой эксперимент очевидно если вопросы у нас из онлайна дайте сигнал и таких сигналов я не вижу и я в том числе а есть вопросы sunline super нету нет сигнальная система помоете у нас аналоговой она не очень строго и поэтому не очень получается такие аналогичным способом вы можете поднять руку и задать вопрос последний шанс потому что дальше игнатов проводим в онлайн кулуары с тем чтобы вы могли лично да есть вопрос ура здравствуйте николай зовут спасибо интересная штука очень вопрос такое планируете ли вы эту штуку сделать коммерческое продавать кому-нибудь еще не знаю каким нибудь сравнимым по объемам данных компаниям хорошо например скажем честно мы думали над ним смысле мы несколько лет назад всерьез рассмотрели в том что он вложиться и сделать и вообще open source на мной летом после этого там в рамках я tanks облака тогда только появляющегося начать продавать есть следующая проблема что у нас там все интерфейсы своей у нас все свое и это к сожалению означает что у людей будет очень тяжело этим пользоваться что люди привыкли там как в хату пи запустить не знаю map комбайнер находятся так airflow находят рецептик копируют делают у нас многие вещи сделаны там гораздо удобнее гораздо лучше но нету никаких длинных инструкций нет такого наработанного опыта ответов и ощущение что большое препятствие потому что ну hadoop кластеров на размерах 50 not не то чтобы в нас есть какая-то супер ценность весят ноты и hadoop умеет кластеров на тысячи машин очень мало у кого есть люди все равно скорее свое писать чем нашем решении пользоваться скажем не гном какой из вопросов понравился больше всего меня вот последний понравился супер и приз получает представься пожалуйста тогда более официально николай завьялов вот из компании аркадия супер поздравим победителя нашего именно для тебя благодарю ассистент у тебя проводит цифровые кулуары с тем чтобы из онлайна могли с тобой тоже пообщаться мы здесь с вами в этом зале встречаемся в 12-40 и я прошу сейчас ребята всех быстро покинуть зал мы сейчас запустим жесткое излучение для того чтобы проветрить определенным цицеро вокзал оптимальная система уже в твоей голове она продумана до мельчайших деталей готово просто нагрузки и защищена от боев только ты знаешь как твоя инфраструктура решить поставленные бизнес-задачи собери свой идеальный сервер онлайн селектор у were привет я артём и снова здрасьте да я редактор обрушение рукой я бывший редактор хабра сейчас следующий подкаст и мы обречены раз познакомиться чем занимаешься сейчас начнем работать над чем работаешь глобально я как бы маленький предводители мама группы разработки просто в поисках овечки которые мы растим с грехи мои тяжкие мы все еще гоняем замшелые самописный движок сфинкс который я когда-то тоже видимость брики у темнила бы написал и мы под движок поддерживаем и развиваем всякому дописывать ты же его сделал давно и не для vita ты просто он вообще как ты считаешь выдержал те древние которым сейчас у него есть то есть они тоже тоже меняется видом сейчас 80 миллионов объявления завтра будет 160 миллионов но при этом у нас как бы боевой поиск это 80 миллионов объявлений а это то что оперативно доступно каждую секунду в каждом первом пользователю массы всякие внутренние системы которые нужно с миксов крутится в которых и побольше данна миллиардами измеряется например админ ты с архивом всех объявлением он что интересно это принципе тоже не сильно я знаю ты на светлом прошлом были инстанции в которых и еще больше до сотни тысяч серверов и этом засвечены большом количестве по большому счету мужские levis до достаточно некомфортно оперировать и был тогда и до сих пор может когда ничего с этим наконец сделаем вот но как бы я к тому что масштаб там порядка 100 миллионов документов модного 10 миллиардов документами когда мы привычно 10 но сейчас таких боевых условиях есть моменты на которые ты смотришь такой боли ну почему я тогда там 8 лет назад не сделал по-другому я 20 а что вы дружно все 13 ментальные возраст и вообще 11 но 3:20 а во вторых на эти моменты они есть вы понимаете постоянно все эти последние 20 лет в любой конкретно взятый момент времени хочется взять и все переписать на хрен вот 0 нет надо держать себя в руках потому что нельзя все ломать над на чем-то и сидеть а некоторые моменты наверно там наоборот тут удивляешься блин ipod какой-то замшелые а ты меня не работает до сих пор и честно говоря нет желания его люто бешено полностью переписать а в основном скорее ну наверно больше половины года который делается это все таки что то что будет меняться можешь например искать какие-то вещи которые ты был меньше всего готов который был сложнее всего интервью движок поиск но ты напеваешь сейчас у нас потом включает общем m-elle модули они 20 лет назад об этом думал что такое но 20 лет назад к их ожидания догадался о том что есть такая штука как им или которая по большому счету над статистиками цена стероидов и там линейная модель сотни входов они с тремя входами поэтому как ни странно в этой части все достаточно легко как раз интегрировать то есть интеграция той же самое эмаль модели ранжирования достаточно штука оказалась простая потому что довело был к нему по дому с 1 готов но гостям один прекрасный момент уже там вырос на концепция под названием utmost сигнал оранжевая форма выраженными так далее выросла некая считал к этих самых сигналов форма выражения и все что оставалось делать это просто чтобы обеспечить возможность подцепить удэ функцию и в эту да я функцию передавать достаточно большой бинарный блок со всеми сигнал беранже нами которые мы хотим туда передавать достаточно тривиально занятия вот поэтому это был сделан еще десять лет назад опять таки девять десять лет назад по моему мой первый раз как такие боли менее мои обычные модели в похожего ли делалось это в тот момент не для vita делалось для одного тогдашнего клиент которые строил там маленький региональный поисковик по одной тут среднего размера европейской стране вот там был соответствует уже сфинкс там выберем модели и нам первый раз смотрите самой модели поручили он тебя в консоль лежит лежал до определенного момента в open source все после определенных увлекательных событий переживаний сэм с одной стороны с другой стороны я внезапно понял что прямо сию секунду какой прок с этого ресурса не будет ни для какой заинтересованной стороны но смысле для проекта роток не вижу для себя так уж тем более вот и пока а потом закрытом режиме может быть калинин open source вернемся может расскажешь что такое случилось почему так решил а ну там это длинные увлекательный или наоборот длинная не очень интересная история вкратце и как бы это давай совсем большими масками следующим образом очень непросто зарабатывать сопин снова 2 шт а который ты абсолютно за бесплатно делаешь раздаешь и и пытаешься зарабатывать хрен пойми чего нельзя все отдавать за бесплатно надо что-то и продавать вот продавать у нас как бы всегда были некоторые сложности и поэтому на самом деле текущую версию который разрабатываемые тем боль поступить я ее прикрыл еще в годы когда попытки зарабатывать собственного движка не кончились уже там не знаю грубо говоря там четырнадцатом году если прогонишь уже был понятно так что то менять в кавычках в бизнес модель бизнес в гигантских кавычках потому что особого бизнеса в этом утра несколько счастью не было а и уже тогда где стать решила что маг будет делать где-то разрез версия за деньги вот версия без денег и поэтому никакие большие фундаментальные перья белки которые были за тельные еще тогда до дома в 400 вроде надо их прикрыть и потом где-то провести линию разрез соответственно после всех этих перипетий названием кассовый разрыв довольно бога получается жили до 1 нормального кассового разрыва с одной стороны но здорово снова ряд там 95 процентов так называемых стартапов в это дело заезжают на дистанции в 1 1 2 3 года и дергались несколько дольше в свое время ну а ну чё за то оказался достаточно фатальной очередной разрыв че ты там деньги кончились совсем самое главное что притока денег кончилось тоже ставьте вот там было еще масса неприятных моментов как сказать как в любом разводе скажем так но это уже наверное тема для отдельного рассказа и обычно там уклоном рассказанным с углем и мечами за четырьмя литрами пиво и постепенным переходом от и оон 1 когда он был в open source его легче было ним работать был какой-то вклад от сообщества значимой интересный вопрос вечере нет я бы сказал что хомячки как-то сильно комфортнее наоборот ну то есть понятно миску в целом себя удобнее работать когда ты не сам там какая . понемножку тут копеечку так отливку а вот снова нихера когда сзади к тебе прилетает гигантская компания со всеми ресурсами и возможностью эти ресурс так или иначе использовать могут будет понятное дело сильно более комфортно режим жизнь вот понятное дело что тут как бы палка о двух концах и естественно если у тебя твой проект люто бешено взлетает и сам начнет генерировать сильно больше денег чем у при большой компании у него в принципе когда не забудем за бюджете вы то наверное пора некий спин-оффа причинять от этой самой большой компании случае со сфинксом это случается сфинкс могут служить достаточно мало зарабатывал всю жизнь как бы это соответственно его независимая жизнь была не сказать чтобы как бы усеяна розового или питание и корпоративными с черной икрой с соответственно выдающиеся золотых чашечках бриллиантовыми ложечками вот поэтому в рамках большой компанией ну честно говоря одну жить легче балога чем по меньшей мере вот на этой там стартовые фазе под названием и еще пока там свои 100 миллионов долларов с шаре не делаем вот чисто теоретически чисто теоретически наверное можно построить разработку следующим образом что у тебя есть достаточно большое количество компания интересант of каждая делает важность которых делает счет достаточно новое хорошее и интересное и которая можно скажем так в общем утонула хорошо уложить а его проект замерз теоретически это возможно какие то вот прям супер комьюнити проекты такие есть тот же пост близ например по большому счету вот такой суперкар менти проект на котором трудиться далеко не одна компания и каждый из которых отбеливает что тут вообще devil's этой а swings до такого масштаба черт его знает то ли не дорос то ли в принципе невозможно чтобы он до такого масштаба дорос потому что насколько я смотрел и изредка смотрю на более другие проекты которые тоже про поиск в основном и понятное дело люсин и все что поведает нам о библиотечка люсин и тот сервер который в этом сезоне модно строить поверхность а они всегда у меня конечно может неверное впечатление потому что недостаточно хорошо там умею распарсить 250 мегабайт джавс кого кода 220 мегабайт из которого это в основном то мне нужны реальные комментарии и там тривиальный фабрик но у меня такое ощущение что по меньшей мере в ядре скажем так 2 что библиотека так далее где-то процентов 90 кода делается выбор там про не ограниченным кругом лиц который возможно формально входит по разным компаниям но их там допустим 5 да и стилю думает об opensource что это тоже очень мало люди на самом деле то есть он такой открытый но contribute a большой 1 раз контрибьютором там пара человек основных именно так большое количество контрибьютором при этом одновременно с этим может возникать в какой части там типа а вот ведром и лезть опасаемся но зато мы прикрутили вот этот плагин вот этот плагин вот этот план вот такая вот штука она конечно цветёт и пахнет сильно сказать все сели на шепчи чем привлечь к разработке ядра при каких условиях и повернул его вы пан source сложный вопрос вот на данный момент я натурально не вижу никакого там объективного плюс от open source а кроме никого имиджа и даже уже не уверен насколько как бы это важно или не важно для конкретных пользователей для того чтобы этот меч был вот если бы сейчас ты мог вернуться в прошлое с текущими своими знаниями о том во что превратится в проект и что-то одно сделать по-другому что это было не ну это ответ на этот вопрос мне к несчастью готов еще до того как я придумал сфинкс и он звучит примерно как в момент ваучерной приватизации я бы украл ящик водки украл ящик водки много ваучер на которой там вкладываться в с новыми газпром потом верти руется в биткоины и в принципе на данный момент как бы илон маск у меня где-то уже в подметки если стаки признанием ну ладно успеха теперь хорошо готовят сюда кладов надеюсь получится круто хорошо выступать ай да надеюсь не вы пасибо что же я хочу поблагодарить наших спонсоров золотых спонсоров это postgres коль professional авито течь и red head между прочим и сейчас без дальнейших замедлений я еще хочу сказать в онлайн ребята приезжайте позвала стакан на конференцию побудьте здесь вот вместе с нами посмотрите как это происходит мне очень жаль что мы на пару минут задержали вот мы очень ценим ваше время простите нас ради бога мы справимся и так о том как справиться с циклами неисправности расскажет нам георгий полевой додон инжиниринг аплодисменты встречайте привет вы слышали меня зовут георгий полевой я и сергей инженер в компании да да инженеринг мы строим и запускаем в производство системы на которой строится бизнес да да пиццы по всему миру это самая большая сеть пиццерий в россии и около 13 стран сейчас мы поговорим о сбоях в наших системах последнее время их стало меньше гораздо там за последние два года с пейджером стало совершенно спокойно находиться то есть когда происходит какой-то лет наша система сами восстанавливаться мура в 90 процентах случаев но было время когда происходили ужасающие отказы системой когда никто не мог понять что происходит сначала у пользователей происходит какое-то замедление потом через некоторое время инженера на графиках видит что увеличилось в этом си потом краситься базы данных и начинает крошиться сервера один за другим чем сам ужасное что они не могут стартовать потому что они тут же ходят в крошку вот при этом мы знаем что у нас нету какого-то бага в коде которые отвечают за эту проблему было бы проще мы бы откатили релиз такое сделали но этого бага нет и это проблема всей системы в целом вот у нас есть сервер на нем есть какая-то нагрузка мы считаем что ну там процентов 40 50 от того что серый вообще может выдержать в какой-то момент нагрузка начинает расти например мы запустили рекламную кампанию пришли новые пользователи для нас это очень хорошо вот но потом происходит вот такое мы превысили эту нагрузку например мы могли не рассчитать не согласовать что-то отдела маркетинга и они запустили слишком большой рекламу компания или это ddos-атака и очевидно что за сто процентов от графика не выйдет но дальше происходит вот такое и мы хотели бы чтобы если к нам пришло больше пользователей или нагрузка на систему извне подано больше что у нас осталась хотя бы те 100 которые на котором и сложились мы купили мощности в облаке там как-то рассчитали что хватит плод тестировали что такую нагрузку держит но происходит падение причем ну то есть до такого уровня когда считаем что это полная откажется система чем дальше видно что вот и вроде бы система еще там трепыхается вроде бы график пошел немножко вверх на самом деле всего лишь тень тех запросов которые пришли уже давно и вот тут вот вопрос такой сдает вообще в принципе сервер должен умирать под нагрузкой ну как бы если подумайте с человеком если там мы попросим человека сделать больше работы чем он может в принципе он не умрет он сделает максимум может разделит там откажется почему сервер должен умирать и вот на самом деле не такой риторический вопрос потому что наша тема как раз вникнуть в то что происходит внутри серверы понять как его защитить я надеюсь что сегодня вы уйдете с неким инструментарием которые на теоретическом уровне позволит понимают такие проблемы внутри серверов на этом графике я прошу посмотреть на синюю линию оно означает те запросы которые извне поступили систему то есть эта нагрузка зеленый график означает фактически выполненный запросто есть обслужено и успешно и мы видим что здесь не совпадение очень слабая то есть вначале еще более менее там где-то в самом начале график а вот потом как и у нас есть некая черта критическое больше который сервер просто не потею мы видим что после пика нагрузки у нас произошла такая ситуация фактически выполненные запросы сильно стали отставать от нагрузки вот здесь вот есть такая тень на графике то есть это тайм-аут и но и точнее это еще не тайм-аут и это просто задержка то есть запросы стали выполняться дольше потому что им всем как бы интуитивно понятным тесно внутри серверы да мы пока не понимаем почему вот ну а потом нагрузка спала и вроде бы ситуации стало выравниваться но происходит второй пик и после него как бы происходит то что мы рисовали полный отказ но на второй части графика видно подробно то есть вот некой вроде бы график уже ползёт вверх это на самом деле иллюзия потому что это те запросы которые влог записали отчитались о том что они выполнялись но просто это уже очень поздно было вот и дальше желтый график показывает полный отказ нему такой примерно такое у нас происходило это был это был чемпионат мира по футболу вот и откуда такая нагрузка с такими пиками то есть утром они покупают пиццу да там пользователь закупаются перед первым time потом по меньше нагрузка на 100 нормализировать стал обычно сша в середине дня у них первый тайм прошел у них нервы да они хотят больше пиццы этот самый большой пиксели дня ну и под вечер уже пенальти там вот и третий пик добивает систему одна из компонентов выходит из строя и примерно два часа неё не обслуживают клиентов нам очень важно что проанализировать что происходило формула little а в теория очередей есть такая терминологии количество клиентов внутри системы на самом деле но это никакие не джед ножевые клиенты это может быть вообще запросы 1 серверах другому внутри облачных инфраструктур где много микро сервисов royal ray то есть это как скорость поступления клиентов внутрь системы и время которое они проводят внутри и вот таким соотношением она регулируется но все это происходит если у нас система статическая есть оговорка для этой формулой а система статическая у нас орвилл райт не меняется и время который каждый вопрос выполнять не меняется тогда количество тех запросов которые в данный момент выполняется будут постоянным эта ситуация практически никогда не происходит в живом серые которая обслуживает клиентов потому что нам нужно дифференцировать и интегрировать вот части этого уравнения мы там сейчас заниматься не будем достаточно понять что это вот такой интеграл интеграл от количества поступающих минус количество убывающих систем то есть запрос который выполнились мы считаем что они вышли вот и тут такой вопрос почему конко рамси вот это новый термин да это количество пользователей внутри системы почему can караси выросла неконтролируемой и мы видим на этом графике вот где-то посередине и посмотрите такая куча есть она очень высокая да то есть и она однозначно коррелируется падением сервера вопрос почему она так выросла у нас вроде такого ничего не происходило на точную по графику нагрузки выполнены запросов видим что ну да они какие-то низкие вначале она была невысока а потом она стала расти и вот если мы на вот эту часть графика посмотрим то вспомнил что такое интеграл константы у нас конкурсе равно такому интегралу интеграл вот такое вот выражение где у нас количество поступающих примерно константа вот а количество убывающих у нас примерно равно нулю и интеграл константы у нас дает прямую линию идущую вверх что означает это прямая линия означает что сервер самостоятельно не выкарабкается уже никогда есть такой ситуации ему нужно чтобы скорость выполнения запросов совпало со скоростью поступления чтобы хотя бы держаться на том же уровне это происходит когда он выходит на плато вот но это уже слишком поздно это уже под вечер клеток к нагрузка спала вот соответственно мы понимаем что конкурсе на графике вот такая вот горах это равносильно смерти сервера и мы будем всячески бороться с тем чтобы в нашем сервере было излишняя конкор и вообще почему мы с ней будем бороться и тоже полезная такая модель то есть у нас в принципе есть много моделей concorde в программировании есть мол титры давая модель эта модель который нам позволяет делать вид что мы имеем дело со многими вещами одновременно эти термины термин часто путаются про лиризмом вот есть статья раба пайка на эту тему которое очень рекомендую он объясняет подробно что это такое но и объяснишь так вот я когда сюда ехал в пробке конкор ansi это примерно количество машин который стоял на светофоре в пробке вот а параллелизм был равен двум это количество рядов полос дорожного движения по котором автомобили едут в компьютерах это равно количеству процессоров и вообще говоря нам не очень интересно даже степень параллелизма с которой выполняется запрос нам интересно степень конкуренции и малаги почему-то путают они думают что если больше трендов например создать то как то как то вот запросы быстрее или там параллель не выполнится на самом деле конкор нас накапливается и это убивает систему как бы в мире есть много примеров как он караси накапливаться люди борятся например ни один бизнес не хочешь чтобы у неё на складе было много всего конкурсе это можно сравнить например в гидроэлектростанции вот количество воды до затопили целую долину между гор вот это степень con carne который требуется в этой системе и это конечно же не очень хорошо мы сыграем в игру чтобы вот как бы интеграл было наверно трудно понять мы попробуем представить игру fire scheduling когда у нас запросы стараются выполнить одновременно точно нет конкурируют за какие-то ресурсы и мы пытаемся честно раздать им эти ресурсы чтобы они бывают но это обычный malloc трейдинг вот у нас на каждый request будет work lot work lot 3 и параллелизм 2 то есть как бы что-то вроде двух процессоров и посмотрим вот пришел первый request и некий условный такт произошел было нагрузка 3 соответственно выполнился один такт у нас осталось нагрузка 2 следующем такте у нас зайдет что пришел второй запрос 1 продолжает выполняться они делят 2 процессора на двоих все хорошо числа целые а вот в третьем такте у нас происходит из-за фариш один раз происходит что каждый из них выполнился ни на один она две трети только и один вопрос уже застрял то есть вот мы видим он 4 такта он только сейчас выполнился дальше второй запрос уже выполнится больше чем за четыре такта и мы видим что эта картина и запросы наслаиваются конкурсе растет мы видим что степень конкор нас уже больше двух вот и response time вырос у нас в твои соответственно по формуле little а все правильно и к сожалению вот такая система уже самостоятельно не справится с нагрузкой никогда то есть как бы сколько бы запрос не поступало не все будут все медленнее и медленнее отдаваться и у нас ну что это может быть физическом там сервере это может быть оперативной памяти внутри сервера запрос он отнимает эти ресурсы то есть такая игра проиграна мы попробуем прибегнуть к такому паттерну это очень важный паттерн теории массового обслуживания night club banger на самом деле паттерн ваши баллы и редко кто называет его называют букет обычную переборка ну ладно что делает вышибала он следить за тем что в ночном клубе было весело весело там когда там находится определенное количество людей не больше не меньше ну то есть если их на меньше то не весело клубу вот а если их там больше то не весело самим людям ну вот те кто стоит в очереди они смотрят если уже в очереди стоит определенное количество людей те кто вновь пришли думают стать в очередь тюрьме вот и мы сыграем вторую игру он примерно как это будет работать то есть мы поставили конкор носили мид длину очереди 2 сделали конкор нас ли мин 2 и такой же вор клод вот у нас идет it work лоты уже в третьем кадре мы видим ситуация изменилась запрос который вновь пришел не начал выполняться он еще стоит в очереди в него троечка там вот первые два запросы выполнились за предусмотрено для них время то есть мой потому что они делили поровну на себя ресурс количество этого ресурса равно количество максимальному количеству запросов который может выполняться ну и дальше у нас накопилось в очередь уже два запроса вот они оба ждут а первые два выполняются но они уже видим что выполнится дольше потому что у них есть история они чуть-чуть по стояли в очереди дальше происходит вот такая вот история как бы конкурсе вроде бы вы возросло но на самом деле это не влияет на скорость как она работает сервер потому что это внешняя конкордии как как нашу систему увидеть снаружи вроде бы зашли на самом деле они в очередь стали вот и видим что пришел так тот кто не может уже стоять в очереди потому что мы ограничили очередь двойкой все он ушел домой и это продолжается и кто приходит уходит домой такая система будет жить вечно ну в теории по крайней мере вот здесь выглядит все хорошо буклет можно сделать из обычную семафоры собственно так он и делается и в библиотеке полип танк код гораздо сложнее потому что там есть еще очередь но суть в том что нужно просто войти в семафор вот на самом деле такой такой псевдоплоть то есть мы заберем полисе задаем 100 на 100 то есть что внутри 100 снаружи и дальше любой запрос мы пропускаем через букет игреки таких букетов может быть системе много можно поставить один общий на вход но лучше ставить на какие-то отдельные компоненты в зависимости от того на примерно какой url приходит наш сервер запросы чтобы для них отдельно рассчитывать вот эти от величины вот но на самом деле копчик чуточку посложнее внутри и снаружи вот так вот это выглядит вот на эти вот и мы получаем соответственно exception что запрос совсем не выполнилось посмотрим как это наш систем повлияет помним да вот это вот горка огромная мы и хотим просто срезать вот и мы этот паттерн он позволяет напрямую прямо влияют прям вот запретить все этого не будет но тут вопрос такой сколько у нас реально от бракуется сколько будет таких клиентов которые пошли домой узлом и вот видим что получилось уже секундочку взгляда вот эти вот я мы в обслуживанию они исчезли сервер пашет на сто процентов которые для него рассчитаны по крайней мере то за что мы платили мы на все деньги выполним полезные работы вот ясно что когда у нас есть чрезмерно пики нагрузки но это можно решить масштабированием там эластичным и еще каким-то другими вещами но сам по себе а как есть сервер выдержит вот такую нагрузку то что желтая это там тайм-аута и невыполненные запросы понятно с этим тоже как-то хочет побороться попробуем увеличить длину очереди и видим чуть-чуть вроде улучшаются системы то есть первый пик мы даже почти разгребли а здесь вообще шикарно да или нет вот мне здесь не нравится вот эта вот вещь у нас в конце графика мы видим что вот по формуле little а у нас получается что складывается степень конкор нас с длинной очереди и у нас в 11 раз увеличится время процессинга если будет чрезмерной нагрузки собственно что мы наблюдаем у нас в конце вот эти вот все вот эти оба пика они размазались но весь день и система идет с отставанием очень медленно выполняет запрос поэтому мы обратно все вернем сделаем вот так примерно даже можно длину очередь сделать меньше она нужна только лишь для того чтобы заполнять ночной клуб когда вот только только один вышел мы сразу туда нового пускаем человека в принципе можно длину очереди ставить там близко к нулю то есть ну вот такой вариант нам уже более-менее нравится на этой диаграмме изображен приблизительно приблизительно изображена схема работы с red bull а оказывается что сейчас как бы модно делать асинхронную все даты что мы делаем осинка тоски в разных видах в разных системах они присутствуют мы не используем стараемся не использовать молотый трейдинг вот и снижать количество thread'ов но если у нас был автоматический triple в приложении он выполнял роль букв е да и некоторое время он мог защищает систему от таких сбоев что мы здесь видим предположим у вас есть connection pool который справа величиной 20 то есть 20 соединений к базе данных и thread пул примерно 20 там thread'ов условно и вот пришел пить нагрузки не было 20 а стало 200 вдруг мгновенно они стали в очередь на трат пули этот пул эту очередь потихоньку раз гриппа и все и нет количество трудов не успела вырасти он выполнял роль букв правда очень плохо потому что он там стоит машин леоненко алгоритм который увеличивает количество трудов и это всё неуправляема но тем не менее такая защита у нас было когда мы несколько лет назад переписали всем осинки это защита просто исчезла никто не подумал о том что то есть кто-то по дому на самом деле все кто переписку осинки потом запускает в продаже не видя что они прокачали свой сервер он теперь держит сколько угодно соединения прекрасно вот но как только мы повышаем масштаб чего-то повышаем свою собственную мощность вы должны думать о том первые правила проектирования больших систем это то что есть большой не раздави маленького вот сервер ни один у него есть база данных есть масса ограниченных ресурсов которыми приходится иметь дело ну собственно вот на этой диаграмме мы видим что степень конкор расти в случае асинхронных task-ов это бесконечность и нам уже нужно совершенно другой connection pool еще один примитив отказоустойчивости это 3d который трой часто бываешь нам очень хочется что-то попробовать снова ну не получилось там эксепшен давай еще раз очень хорошо работает если у нас например что-то происходящее редко чем мы не хотим избегать например детлок белок это тот редкий случай который можно выстроить ретро ить то что произошло из-за отказа под нагрузкой лучше не ретро и потому что и все же если мы начали ретро вид нужно думать о том что мы увеличим степень как аракси сервисе на которую мы продаем нагрузку если мы ретро им через равные интервалы мне вот здесь первые строчки не нравится потому что ну предположим у нас recovery интервал то есть время за который систему восстановилась очень длинной и он нам нужен такой но за это время происходит много маленьких запросов ну то есть много запросов через короткие интервалы их очень много мне не нравится поэтому я увеличиваю этот интервал и мне теперь не нравится минимальный response time i'm a response time желательно сделать быстро но вдруг это был совсем кратковременный сбой и есть шанс получить ответ быстро соответственно вот это мне не нравится вот это мне нравится и на самом деле мне нравится у от м соответственно применяет экспоненциальной специальную формулу для расчета времени через которые ретро эти и в нем это на самом деле сумма степеней двойки и вот через эту формулу можно рассчитывать общее время которое мы можем ли тратить в принципе из количество литров и также можем высчитать длину 1 retro и мы получается все довольно хорошо то есть мы обе вещи мы соблюдаем что у нас уменьшенное количество общая request of у нас минимальный response time коротенькие потому что 1 литра и делом очень быстро и recovery интервал общем а длинный ну и кстати вот примерно как выглядит график конкурсе когда мы что-то ретро или то есть это были она накапливалась как квадратичная формула стала как логарифм когда мы используем специальный быков и вот у нас есть библиотека поле который мы вот на эти используем но она написана по следам he стрикса да то есть который используется в джаве вот соответственно библиотека поле нам позволяет вот так вот настроить ретро и используя компонент а мне эта формула не очень нравится потому что в гей применяется дискретная величина номер и троя это ведет к тому что мы получаем такой график чем этот график плох графиках тем что есть у нас за ретро велась очень большой кажется запросов то они будут ретро its через равные интервалы хотя и увеличенные хотя и уменьшило их количество вот но они будут чётенько по таймеру приходить все вместе обрушиваться и повышает степень конкор на сервере поэтому вот это мне нравится я добавляю сюда организацию организациям не дает такую картину мне всегда здесь не нравится что много пиков потому мы видим что ретро ведь даже с джиттером когда мы делаем какой то организацию и рандомизированы также просто оказывается не вот это вот все не нравится и приходится на самом деле достаточно долго мучиться вот все попытки сделать хорошо и мы где-то вот фиолетовая линия в пятой строчке это попытка команды а в с они публиковали статью как они уменьшили значит сбои в системе сделав джиттер на ретро ему построить гистограмму я вижу что здесь есть пик но там такой зуб неприятный потому что эту гистограмма не так же просто построить мне удалось построить получше вот вот с помощью такой формула я здесь не использую дискретной вершину в расчетах я рандомизированы перед тем как его возвести там степень двойки вычислить я получается гладенько все это сейчас значит долго велась переписка с авторами поле они сейчас это полировали в кантри печь-то них есть так называемые дикари лет и джиттер быков теперь вот и он вот такую вот гладенькое распределение дает очень важно на самом деле вещь потому что она не накидывает конкурсе нижележащий серию более чем хорош еще там пару слов скажу то есть инструмент интерфейс мы можем разные политики и примитива отказоустойчивости накидывает вот здесь вот два экрана текста грубо говоря если бы аналогичный код писать вручную который умеет и circuit breaker включить и ретро и и тайм-аут вот тут получится кода очень много и с ошибками скорее всего вот я упомянул circuit breaker кстати что же circuit breaker нам не поможет ситуации когда у на сервер ходит в отказ но в принципе он где-то применим то есть да у вас произошла там чрезмерной нагрузкой какой сервер стал падать начал сыпать ошибками и все вышибло пробки но для начала рассмотрим проблему cold start чтоб понять можно ли принимать церковь breaker вы длину нам полезен проблем холодного старта в чем заключается мы видим что от начала графика на 15 секунд один запрос запрос выполнять одну секунду тысячи рпс за 15 секунд пока сервер стартовал но уже считался включенным в lot better ну предположим даже уже приложению самый стартовал там шла jit компиляции все 15 секунд за эти 15 секунд у нас степень can карте возросла до 15000 эти запросы обрушились в первую же секунду не один запрос здесь не выполнены здесь зеленого ничего не видим на этом графике помнить там такая зелененькая знал выполненные запрос и здесь его нет ну то есть она номинально присутствует 0 только тайм-аут и это сервер который входит в крошку сразу когда стартует лечится это булка рядом очень прост на входе ставится букет соответственно все что нам накидывает конкор оси вот то есть то что мы увидели что конкурсе накидывается там где мы группируем запросы по времени из какого-то интервала все в один такое может происходить вот что они группируются на микро в масштабе на что это похоже как вы думаете то есть когда у нас есть остановка ничего не происходит а потом движение продолжается но это garbage collector здесь лимитированный деятельность garbage collector а который делает стоп зе ворлд знаю что не все garbage collector и так делают но тем не менее таких флуктуаций может быть очень много системе и любая которая приводит к тому что есть не снижая нагрузки делает какие-то паузы она нам накидывает конкурс мы видим что здесь на фоне слева направо конкор настолько растет что ещё нам может навредить нам может нарядить код который вызывает высокий степень контент у нас есть некий за контент данный ключ один и тот же котором делается лог из разных запросов и оба запросу один обрабатывается друга его ждет это все повышает степень конкор соответственно здесь у нас эта кассета с диаграммой мы видим ним вот сплошным залиты это те ресурсы которые в данный момент добавляет конкор нас вылечить это можно с помощью того что мы делаем по trample бэк пытаясь не самое важное данное вычислить не обязательно вычислять их опять же нам библиотека поле помогает мы делаем fall back ну что это значит то есть мы сначала запрос обычно мы запрашиваем какие-то подготовительные данные например из баз данных в одном самое важное в конце в конце идет самая важная операция если нам удастся вычленить помощью дизайна меньшую качественность это сложно но такие ситуации возможны когда самые тяжелые что мы вычисляем где-то в начале она не так важно и мы можем его искать и взять мы заворачиваем и the fall back берем например скажу таким образом мы не же не ожидаем эту операцию и у нас получается вот такая система которая если мы ее в развитии времени посмотрим она не согревает наши ресурсы не накапливает конкуренции ну и вот чтобы суммировать я скажу что can карася такая вещь которую многие упускают из вида ее очень трудно увидеть на графиках потому что ее нет в стандартных метриках обычных системах ну то есть есть там иногда это называется inflight request в разных системах или что-то такое но зачастую нам придет приходится самому придумывать как это должно работать это обязательно надо контролировать когда мы повышаем масштаб нашего сервера прокачу производительность если мы где-то упираемся ну то есть он у нас не резиновые ресурсы у нас в облаке конкретной машины которые должна нашу нагрузку держать если мы это считаем мы должны контролировать concord вот что влияет на конкурс ну естественно внешняя нагрузка влияет надо согласовывать свои маркин маркетинговые акции не подавая более чрезмерной нагрузки естественно если мы ретро им нужно проверять что мы ретро им только то что имеет шанс зови троится и не создает не имеет накопительного эффекта то есть это не по причине ны когда систему падает под нагрузкой нам нужно ли трафик и временная остановки всевозможные их нужно учитывать это нужно моделировать смотреть как с тем будет реагировать инок степень как она сможет в десятки раз прыгать особенно если очень высокий request right то есть там где разработчик он скажет ну у меня всего 5 запросов в минуту а когда мы смотрим на графике мы видим что в какую-то секунду произошло 50 ну вот запросы имеют свойство от пользователей пример иногда случайно совершенно случайно сгруппироваться могут не случайно может быть какая-то стива инстру инфраструктура притормозил эти запросы они сгруппировались вот ну и контент конечно же с контекстом бороться сложно немножко посмотрели как что можно сделать ну пожалуй это самые такие вот вещи которые хотел сказать я надеюсь что вы лучше поняли что такое конкор exe моего доклада что вы сможете применить эти техники которые показал будете понимать как как их использовать своих системах вот мы наши наработки то есть теоретически исследование которые были сделаны по следам каких-то отказов наших систем мысу миром в виде таких докладов или видео про собственных библиотек с примитивами отказоустойчивости готовыми к использованию вот и всячески распространяемые то там внутри нашей компании вот и приглашаем ознакомиться с тем что мы делаем спасибо георгий спасибо тебе огромное сейчас будет у нас сессия вопросов и ответов а мы тебя благодарим за выступление именной табличкой и вот такой вот худи вот как на мне надето на такое классное теплое общество вот такая штука у тебя там сумки прикинь да вот вот так а вот это вот обожаю вопросы ребята я верю что у нас есть вопрос из онлайна и как только он есть и вы я вижу руки в центре зала как только готов онлайн вы его включаете прошу и обращаются техникам каждый говорить да вот паттерн которого у вас был показан где поступает количество запросов в какой-то момент перестает справляться приложения я вижу что у вас там galant там же есть контроль буфера очередей как раз для этого и написан пишется свечи что все запросы выше какого-то значения просто дропа еца вот впоследствии и это помогает ну вот избежать вот такой проблемы как как прокомментируйте что в чем вопрос не удалось понять чем вопрос повтори пожалуйста но смотрите вы говорите что есть проблема когда очень много запросов приложение с ними справляется вот вы показывали код из гол анга который вот сумеров вот это все показывал наглядно что эта проблема была вот здесь вот там есть контроль размера буфера очереди для каналов которые как раз для этого приду чтобы через свич можно было дропнуть все те запросы которые помещают вас не будет больше чем допустим для 2 миллиона или там четыре миллиона во сколько поставишь все остальное будет толку то есть качество код будет написано вот а теперь вопрос но вот вопрос как это можно прокомментировать то есть вот вы в эту сторону работали смотрели колонки и не очень каком коде на голом я показывал вот это вот эти вот поэтому вообще и switch кейси пока не удалось возможно в кулуарах я верю про онлайн что теперь он к нам готов и мы ждем несколько секунд чтобы человек мог сказать представьтесь предохранитель как в вашем случае можно учитывать при выполнении запроса да конечно нужно учитывать время выполнение запроса и скорость собственно ну то есть форму little она показывает что con carne все равно скорости пребывания запросов на время которое они проводят систем все это во время нагрузочного тестирования мы должны определяют естественно есть и тяжелые легкие запросы у нас получается обычно что-то среднее вот мало того они могут плавать в каком-то диапазоне поэтому нагрузками тестера важного достаточно длительный период испытывает там нет вас на может пару часов например она там идет я точно не знаю сколько бывало по четыре часа сессия нагружен тестированием они бывают разные вот и мы в что-то среднее которая наш сервер выдерживает как рассчитывается этот порог мы берём то где он упал ну и условно начинаем играть от этого в нижнюю сторону естественно не будем ставить ровно ну то есть он выдержал сто-сто 105 уже упал мы не будем ставить такую лично мы поставим меньше мы поставим 80 или там даже 50 то есть мы будем уже смотрели то это вопрос тюнинга параметров как ну естественно ничего одинакового не бывает что то в среднем есть опять же в теории массового обслуживания у нас во все усредняется да то есть это как естественно какой-то имеется средний по больнице время выполнения но опять же здесь я говорил уже немножко что булка до нужно ставить на отдельные компоненты отдельные с разными параметрами собственном джаве откуда это пришло там вообще принято сотрет пулами отдельными работать вот и там собственно был корриды есть бред пыльные которые вот именно этим занимаются то есть как-то так но сервер можно их целиком защитить какойте пепси можно изучить отдельные какие-то его зоны я понятно спасибо георгий напоминаю что тебе предстоит выбрать лучший вопрос я вижу уже человек с пароходом нам кутянин следующий спасибо за доклад я здесь по центру и отлично смотрите вы упомянули про краткосрочные отключения на то есть приостановку работу временно в идеале хотелось бы да ну вот мы бланш картинку сочи виктора стоит клуб пытается сайте что те люди которые подошли к этой очереди увидели большие очереди прошли мимо потому что но они не буду столько ждать вас система работает ну пиццерии соответственно люди которые также приходят пиццерию если понимает что там огроменное очереди не захотят ждать до и они соответственно просто пойду дальше следующую пиццерию следующие заведение коту рядом с пиццерией правильно но это мы видим как бы верхнем лишние уровне во как у вас системе доносятся до кассиров ну вот эта информация о том что ребят вот давайте приостанавливаем двери на ключ закрывая сообщения в этом я понял вопрос дед это конечно же здесь немножко не о том речь шла теории масса обслуживание к старой системе это не живые пользую это у нас может вообще не быть пользователи это может микроконтроллер быть нет это понятно но нагрузка тем не менее же идет от пользователей вот то-то же огрузка пользователю да есть разные причины по которому нас могут приостановить деятельность пиццерии это может быть это какой-то фрод как или какая-то там так и хакеры там которые пытаются обмануть и что такое происходит но и писарю мог бы поставить стоп или например ну может что-то там произойти очень редко например не дай бог там закончилось тесто круга питере может поставить себя в стоп это дело эта функция в нашей системе есть такая но она мало отношения имеет где и как оказывающую деятельности наших систем но все это не связанные вещи окей тогда смотрите вот произошел но не знаю людей очень много пришло очередной чемпионат систем начала загружаться и просто железно не справляется да вот пошла в горку рост нагрузки и нужно что-то останавливать останавливать входящий поток что у вас системе произойдет вы приостановите на уровне сервиса 9 сервиса не абстрактные давайте вот что сделаем ребят во-первых у вас похоже дискуссии и для этого есть цифровые кулуары тех кто из онлайна захотят они смогут подключиться и в этом поговорить и да да окей спасибо договорились а я вижу нас есть следующий вопрос поднимайте пожалуйста руки кто еще хочет вот ближе ближе к выходу тоже будет следующим добрый день и на вич константин россельхозбанк это сколько я вижу вы работаете именно все равно с операцией поступающими от пользователей а этих не требуется обслуживать бесконечно долго то есть если мы идем так или иначе мы смотрим на заказы тут скорее всего это заказы какие-то операции на на обслуживание то ниже можно просто стрелять по времени вот в эту сторону вы не смотрели мы смотрели в сторону у нас сделано все асинхронно то есть у нас нет таких естественно запросов которые длятся столько сколько длится заказ у нас заказ принимается мгновенно игра условно да потом уже какие-то дополнительные запросы к серверу делается чтобы обслужить и только вопрос том что если у нас асинхронная обработка идет в любом случае человек не ждет свой заказ бесконечно то есть даже в асинхронном общение у него есть время жизни после которую можно не обслуживать и очень часто вот проблему таких пиков решается выбрасывание внутрь из моего опыта не на фоне только на входе да и но и в самой очереди вот в эту сторону не было ничего то есть выбрасывание дочери здесь речь идет об очень быстро очереди то есть это очередь она то ли но там секунды держится хорошо спасибо я задам 1 секунды я задам два вопроса коротких из часто из онлайн и потом последнего у кого сейчас микрофон и дальше в цифровых лорак можете продолжить значит такой вопрос задает никита от талкинг богат алгоритм не подходит ли для реализации на к токен baked таким баки для реализации на их лобовым сир потом я не могу даже скидку оставить на это вопрос никита найдите найдите георгию раз король задайте ему задачу таки а еще один вопрос из чата если паттерны с более чем двумя череды очередями для случаев обязательный стопроцентно обработки запросов обязательность стопроцентной обработки потребляют его у нас лидер системной в очереди используется там орбите они тоже не имеют отношение к примитивным мгновенный отказоустойчивостью здесь речь идет о in memory очереди которая умрет вместе сервером да и служит для предохранения точек быстрых таких сбор супер спасибо и вопросы зала да спасибо за доклад а у меня два коротких вопроса ных делать первое это не не очень понятно то что происходило на графике когда уголке до регулировали количество ну а и томов которые за пределами очереди находится то есть там когда было 200 500 1000 непонятно было то что не было видно вообще когда мы подняли до 1000 никаких отказов то есть этой молоток ничего и всей саги вопрос вообще вот в ожидании этой очереди есть ли какие-то тайм-аут и или нет это вопрос первый а второй вопрос такой вот ты сказал то что ретро it не нужно никогда но в том случае например если мы знаем что на сервер надежно защищены сервис надежно защищен высоких нагрузок тем что у него стоит bulkhead допустимо ли в таком случае ретро ить это всем спасибо допустимая ретро эти если у нас сервер защищен вопрос там имеет ли смысл это делать потому что мы трампа пойдем за пределы ваще и тут же вот есть мы по причине отказе бабахает режим получим ретро я бы это не литра его потому что мы тут же попадем на полную очередь вот если это что-то редко опять же ли тратить на то что гарантированно знаем ли у нас есть теоретическое подтверждение что это выполнится у нас нету подтверждения чтоб под нагрузкой сервер вдруг вне в следующую секунду на авось мы будем ретро и что балка или произошло почему должна быть причина веская для ретро я здесь я причину не вижу прямой в отдельных случаях наверное это 33 можно сделать через очень длительный интервал но нужно ли нам это делать скорее всего нет первый вопрос что тут длина очереди увеличенная и значит у нашего запросы выполнили да они выполнялись потому что нам хватило длины в очереди чтобы все эти вопросы всегда вобрать это и история у нас не будет ну как бы мы не будем этим пользоваться в природе нам не нужно использовать очередь для был кредо уход очередь был ведом нужно только чтобы обеспечить низкий вот эти вот высокочастотные флуктуации то есть чтобы он у нас не стоял в холостую не простоял а не для того чтобы набрать то что должно обрабатываться позже ни в коем случае прошу прощение можно все таки вот на первый вопрос ответ то есть там в очереди в этой есть тайм-аута или нет а нет в этой очереди в данный реализация нефти а понятно семья оказать думала об этом что хорошо бы их там иметь потому что есть там на случай если запрос и вдруг стали руки и вот но в поле нету их георгий такой запросов понравилась тебе больше всего потому что мне понравился последние потому что я мне кажется видите вообще полностью его понять вот так вот аплодируем погиб поднимись вот ассистенты ищет тебя счастливчик тебе книжку несут приза георгий продолжат цифровых кулуарах сразу налево и зала так чтобы из онлайна могли там с тобой общаться и так это совершенно я бы я пробовал кстати ребята это это реальная штука когда подключаешься через zune там такая классная камера и полное ощущение присутствует очень классно спасибо тебе большое через пять минут мы здесь с вами продолжаем оказывающий его формированию digital стратегии luxoft диоксид технологий компании ведущая глобальная компания оказывающие услуги по формированию digital стратегии и разработке программного обеспечения с клиентской базой по всему миру в россии luxoft представлен в москве санкт-петербурге омске нижнем новгороде и дубне мы вносим большой вклад в развитие автомобильной индустрии наши эксперты по встраиваемым системам идут разработку автономной системы помощи водителю которая объединяет в себе компьютерное зрение фокусирование на модели окружающей среды и другие направления идет работа над проектами 3 club 5 включающими unix дизайн и создание платформ и темой для производителей автомобилей премиум-класса активно развивается и направление digital инженеры который объединяет в себе проекты в таких отраслях как энергетика медиа здравоохранения retail и логистика телекоммуникации и туризм мы постоянно расширяем нашу экспертизу в облачных вычислениях devops машинном обучении искусственном интеллекте системах интеграции блокчейн специалисты нашего финансового направления выполняют крупные проекты для международных банков и хедж-фондов мы предоставляем клиентам эффективное решение для анализа и обработки моделирование и проектирование данных которые дают дополнительные преимущества для бизнеса заказчика люксов также активно вкладывается в развитии своих сотрудников привет я артем я бывший это краха бы сейчас вы подкаст мы обречены при этом знакомиться приятно познакомиться меня зовут ольга и не я занимаюсь в компании компаний безопасности приложений безопасностью приложений это что-то особенное не как сказать что-то особенно я стоял где-то такому важному моменту который связывает собственно мир разработки и меры безопасности потому что зачастую как решаются себя себе люди делают безопасности это ребята которые не знаю периодически запускают какие-то сканеры и узи масти и дальше приходит предположим к ребятам инфраструктуры со словами ребята у вас здесь и не знаю какое нибудь узел мои приложения но обычно эти со сканера связанные с безопасности венгерского по то если не знаю вы предположим на капельку in the patch и он может быть стервец если у вас есть компании своей разработка то разработчики пишет уникальные уязвимости которые сканер уже не найдут обычно это есть предположение знает о дженесс с которыми пользуется большинство компаний для уморительно нужен при собственно вот я пытаешься внедрять различные практики безопасные разработки а поиска узи масти собственно в разработке который ведется в компании работает и в чем заключается процесс как ишь какие мы пользуемся различными во-первых сканерами которые именно сделаны для практичности кереть это статический анализаторы к 1 безопасность мимический анализаторы код для безопасности различные сканеры зависимостей которые проверяют и вообще фреймворке какие библиотеки используются и все или там хорошо безопасности также пишем какие-то свои большие инструментами слизь какая-то специфическая позже логика который не можно поселить динамический анализатор из коробки то есть предположим тот же burgs youth networks юта прокаченного любовь писать enterprise они не всегда могут качественным проскочить на безопасность то есть например динамический сканер как работают они отправляют какие-то нелады с кавычками и дальше смотрит такой ответ пришел и не всегда таким сканером предположим по зубам какие-то специфические положение какие-то специфичных запросы и предположим одних мы пишем код свою логику и также проводим ручное тестирование потому что 1 делает безопасность когда не знаю какой нибудь кавычки ты можешь зайти под админом другое дело то что есть должен какое-то бизнес логика и предположим она может немножко несерьезная реализована и уже предположен какого-то типа узи масти надо проверять рука ну и также проводим какие-то тренинги и пытаемся всячески просвещать разработчиков помогает правильно составлять техническое задание консультировать на каких моментах чем ли могли подумать как это сделал безопаснее на моменте именно дизайн ну вот именно когда ты проводишь покидали глюкозу такое вообще существуют что ты учишься сборщиков как писать код так чтобы было безопасно чтобы не было уязвимостей мы проводим тренинги с точки зрения любви кода мы спали используем подход грей бокса тестирования когда мы одновременно имеем исходный код приложения положим понято дебаг режиме и дальше предположим отправляем поднимаем приложение локально подключаемся к и пешки и дальше смотрим а как же я себя пойдет тот или иной пилот котором мы отправились клиента и как он пройдет в приложении вот примерно с точки зрения такова ревью на безопасных 0 плюс поиск каких-то типичных небезопасных функций которые практически во всех языках программирования есть различные магические методы и валы которые не плохая идея использовать мало разработчики периодически во всех компаниях что-то использовать бездумно хотя не знаю вы х мануале к их языку написано что ребят если вы это используете на десять раз по дому но не всегда там устроит 10 раз подумайте собственности такие функции мы тоже ищем глазами если предположим вы по каким то причинам с этим не справился их статический анализатор но чаще всего статические анализаторы справляются с таким review еще мне кажется или часто встречали такое отношение к безопасности что это ну какие то просто формальности перестраховки паранойя нет ну я в принципе наверное могу конечно согласится штаты перестраховки паранойя но если у вас есть команда ищем security который занимается именно безопасностью вашего приложения вашего кода то мне кажется разработчикам если они научатся дружить и правильно понимаете эту команду станет легче жить потому что куда наверное проще когда теперь принесли уязвимость которую нашли еще на стадии тестирования над столицей джан чем когда какой-то хакер вынесет знает что-нибудь через приложение перебежит бизнес а посреди ночи сослали надо срочно что-то фиксить мне кажется без опеки шекспира помогать чуть спокойнее жить разработчик ну вот как на твой практики до них это доносить как мы это объяснять приходится на самом деле в большинстве твоем я сталкиваюсь с разработчиком которые сами хотят вникать и самих презентация потому что очень быстро до людей доходят то что если самостоятельно в этом всем разобраться если самостоятельно вникнуть и приходить ко мне по любому вопросу и консультироваться то скорее всего у них получится написать безопасный код и и когда он едет для меня чтоб я вам там уже будет минимальное количество проблем и им не придется это исправлять здесь же есть какие то еще не только какую потребность безопасности какие-то еще требования регуляторов например да конечно конечно требование от регуляторов есть мы например и компаний компонент и мы собственно должны использовать вот все что связано с жизнь циклом безопасной разработки это и нам статическими завтра динамически это можно надо подходить к этим требованием абсолютно по-разному и соблюдать их по-разному мы стараемся дамы эти с кривыми соблюдаем мы но мы стараемся делать больше чем требует регулятор потому что даже больше очередь да потому что это надо не для того чтобы быть вся действия компании да понятно это надолго в первую очередь как бы это безопасность который влияет и на нас и на наших клиентов и мы хотим предоставлять качественный безопасный продукт может быть расскажу какими надо скиллами будут чтобы заниматься тем чем ты занимаешься наверное понимать собственно как пишется код как работает приложение понимать собственно как работе база данных как строится запросы как наверное работает уязвимости и общем и целом как как работает в моем случае проводят в приложении потому что надо во первых еще но не определенную фантазию и наверное желание бесконечное желание узнавать что-то новое ну вообще звучит вроде как что это надо уметь чтобы уметь разрабатывать тоже имеют может 10 особенности чтобы именно вот ведь нюх на безопасность и если я не меня верны сложно про это судить потому что это ведь про себя и про друзей и коллег но я наверное мне сложно сказать если безопасники чем-то отличаются но возможно это просто какое-то специфическое специфическое мышление с большим желанием что-то сломать но она но мать она опять же без с одним желанием что-то сломать мне кажется уехать нельзя а поскольку надо еще понимать собственно как написан код потому что одно дело отправлять кавычки облака боксом когда ты видишь не знаю кому цветик и просто кидаешь кавычки другое дело разобраться и распутать общее а что же происходит напугать может быть даже небольшой короткий ликбез такой вкратце я пару советов как писать так чтобы у тебя было меньше вопросы к разработчикам у меня был ну такие основные его но наверное самый главный совет это хорошо знаете язык на котором ты пишешь если есть какое-то сомнение по поводу использования той или иной функции wi-fi и еще раз прочитать на сайте посвященному языку про это функция пример для pvp в большинстве большинстве функции если они предположению безопасные тот же ansi реала из большими красными больших большой такой текст выделены красным или были сказаны не использовать эту функцию если бы и никому не понимаете что она делает и не понимаете как сделать и безопасный наверное основное это самое главное просто хорошо знать язык и также читать материалы про то лежат такие специфичные для того языка вообще насколько того чтобы хакерские скилл и прокачано безопасника так интересно грань что и те и другие должны иметь и умеет что-то похожее ну мне кажется что хорошо запасников должна быть очень хороший хакерских стоит потому что в любом случае когда от и работы ощущение какой-то компании и занимаюсь с защитой если ты не понимаешь как ломать ты вряд ли поймешь а как защищать туда так ну ладно спасибо тебе за рассказ жила до самого пусть расскажет пишут безопасный код и чтобы проблем было поменьше и возможно когда это это будет итак я рад что столько людей собралось по крайней мере я вижу в зале думаю что могла не тоже много о том чтобы послушать о том как же сделать микро surf на архитектуру потому что нашли еще докладчик работает в крупной компании которую мы каждый из нас встречал просто своей личной жизни для того чтобы как-то воспользоваться ее услугами и он занимается там платформой на которой строится как раз все взаимодействие микро сервисов пожалуйста встречайте апплодисментами семён катаев авито так тебя не будет слышно в онлайне всем привет меня зовут семён я работал в компании авито над процессом перехода от монолитной архитектуры к микро сервисом вообще реализациями красивой архитектуры занимается несколько команд нам пришлось поменять процесс разработки сделать rior в компании начать использовать новые для нас паттерны проектирования и новые инструменты сейчас я дам краткий обзор того с чем вам придется столкнуться если вы только задумались над созданием надежных масштабируемых распределенных приложений и так что вообще есть до микро сервисов что у нас во это было до того как мы начали задумываться о микро серости и архитектуры у нас была классическая веб серверное приложение весь пользоваться и трафик встречают серия лот балансиров которые решают задачи l3 и l4 по модели осей и у вас может быть несколько уровней балансировки например его вид на мы сделали два уровня балансировки когда applications r или l севан по модели оси oy мы вынесли на отдельный пул серверов за которыми находилась приложение приложение формирующий ответ для пользоваться и запрос за приложением конечно же базы данных вот и мы горизонтально масштабировались у нас одно приложение не могло обслуживать весь пользу ский трафик запускали несколько лет балансиров затем запускали несколько инстансов приложение то есть это те сервера куда девалась наше монолитное приложение и вот отсюда мы начали двигаться в микро сервисы почему мы это сделали бизнес развивается появляются новой точки роста нанимаем новых инженеров в какой-то момент настал a400 инженеров компании авито то есть 400 людей которые ежедневно пишут код делать это фича запускают процесс и сиди и мы увидели что с ростом сложности проекта близком к сети отображено по оси x продуктивность отдельно взятого инженера отображенная по вертикальной оси будет падать то есть с ростом компании тенту market отдельно взятого инженера продуктивность отдельно взятого инженера будет падать что делать самый популярный ответ сейчас это идти в микро сервисы микро сервисный архитектура это модульный подход к разработке программного обеспечения основанный на использовании слабо зацеплен их распределенных модулей которые взаимодействуют между собой по какому-то либо протокола вообще микро сервис не единственный путь и для развития теперь заработала вообще микро сервис это не единственный путь до развитие вашей компании то есть с монолитной архитектуры можно тоже хорошо работать при условии осознанно и осознанного контроля так долго ну вот мы решили идти в микро сервисы как говорил там модульный подход к разработке программного обеспечения когда наше приложение дробится на много независимых слабо связанных модулей микро сервисов не от единого правила или критерия до какой степени гранулярный steam и дорогим наше приложение например у нас есть монолитное приложение которое работает с разными инструментами пазле свенсен джинсы reddy's манга дебит и новые фичи мы делаем в микро сервисах например когда стояла задача сделать messenger к примеру вы можете сразу делать его как отдельный микро сервис который реализует опять для мессенджера на всех платформах desktop опять мобильных приложений бэк-офис ultra micro сервиса будет своя база данных своя команда инженеров свой тех долг свой тех лиц свой backlog свои cup свой capacity planning и у этого микро сервиса будет свой план развития дальше например вы делаете микро сервис доставки микро сервис доставки тоже будет со своей базы данных своих крона демона тут максимально независимым для нас эти сервисы это как микро стартапы внутри одной большой компании и вообще изначально messenger был в монолите находился на php и только потом когда мы начали распиливать монолит у нас отдельная команда вынесла массажер в отдельное приложение скорее всего вам понадобятся какие-то фундаментальные сущности для работы для комфортной работы для комфортно обслуживания пользоваться трафика например вам может понадобится сервис пользователей который будет себя инкапсулировать все персональные данные по пользователям телефон и email авторизации историй авторизации там будет кроны демоны например крон сброса паролей отправка емейлов вот это все будет связано использовать в одном микро сервисе вы сделать его максимально надежным масштабируемым у него тоже может быть своя команда инженеров как у нас во вид а у нас во vita укоры service as есть своя команда инженеров которых развивает и поддерживать и предоставляет стабильно и опять для всех команд вроде бы все очень просто то есть ну вообще посмотреть на схему вроде дело отдельные микро приложение и вот тебе микро сервисной архитектура но на самом деле там все гораздо сложнее и прежде чем смотреть какие сложности будут у вас возникать процессе распила монолита давайте посмотрим на масштаба микро сервисной архитектуры у нас сейчас во vita больше тысячи микро сервисов на самом деле там тысячи полторы микро сервисов у нас просто есть парочка сотен микро сервисов который мы не знаем кому принадлежат не знаем кто их сделал и никто не хочет ими заниматься около 200 с микро сервисов помечены как критичные две с половиной тысячи баз данных то есть представьте две с половиной тысячи инстансов баз данных и до 200 тепло iv каждый день 3000 git репозиториев вот новый человек приходит в компанию и смотрят 3000 git репозитория в проекте но мы сидим на стыке atlassian технологий относительно продуктов и набит платите в общем один из вызовов микро сервисные архитектуры это сделать так чтоб не потерять комфортность разработки на таких масштабах сделать так чтобы объем тех долго не рос экспоненциально и объем краст грязная работа держался на одном уровне под грязная работа я подразумеваю задачи типа ну представьте в голдинг версии 115 выше лба гну нашли как-то уязвимость в galant версии 115 и мы такие о по нам надо 500 микро сервисов ведь или wav в четырехстах некрасовской надо поменять sdk для сбора логов это все грязная работа ее нужно как-то автоматизировать этот один из вызовов микро сервисной архитектуры а ещё у нас домик раз сервисов было одно монолитное приложение с одним профилем нагрузки который мы запускали на 70 серверах 70 инстансов одного приложения это очень легко управляется сейчас десятки тысяч микро приложений вот откуда цифра десять тысяч залазь на прошлом слайде было 1000 микро сервисов то есть у нас все микро сервиса запускается горизонтально мою стелется горизонтально для слабо нагруженных сервисов это минимум трин солнца для высоконагруженных микро сервисов такие как поиск рекомендации там от сервис пользователей там может быть до 100 инстансов то есть в среднем примерно 10 инстансов на микро сервис и это 10000 микро приложений а еще у них есть вспомогательные компоненты то есть у каждого микро сервиса может быть свой пк bouncer стас д д м н х прокси twin прокси инвайн джинс для полноценной надежной работы микро сервиса и вот эта цифра к может спокойно подняться до десятков тысяч микро приложений нужно как-то их запускать вот раньше было сервиса серверов а теперь надо 10 тысяч приложений есть похожая алгоритмическая задача задача наполнения рюкзака по условию вас есть рюкзак и груза и надо рюкзак сатаны вместимости и грузы которые надо уложить этот рюкзак максимально эффективно вот рюкзаке это наши сервера их тысячи а груза это наша микро сервиса их десятки тысяч и нужно их так разгрузить по всем рюкзакам чтобы не было переполненных рюкзаков чтобы они все были примерно данном уровне загруженности а еще эта задача усложняется разными правилами типа к примеру в каждый рюкзак нельзя ложить больше чем два зеленых либо в каждый рюкзак к одному синему добавлять оранжевый или например в каждом рюкзаке должен быть обязательно один серой эти правила называется полетите affinity indefinite то есть эти правила дают это делать это задача практически нереально решаемый в ну и вообще она решается перебором и есть оптимизация динамического программирования вот когда мы только начали техник на сервиса самой нашей первой микро сервисы когда у нас было всего лишь на 5 10 микро сервисов la vita не 1000 эта задача двп и пытались решать вручную мы ставили задача демопсы типа вот микро сервиса у него скорее всего будет такой профиль нагрузки мы надеемся он не поменяется придумайте куда его сзади плоть и devops и вручную подбирали сервера куда бы его положить чтобы не решать эту задачу вручную есть целая группа инструментов оркестра ции scheduling а вообще если вы только хотите идти в микро сервисы обратите внимание на фон клауд найти в компьютер fondation у него кстати буквально неделю назад была конференция формате онлайн это независимый фонд который ставит своей целью развития технологии контейнеризации контейнеризации приложения он был анонсирован в 2015 году вместе с купер notice 10 и поддерживаться разными крупными компаниями которые я не буду сейчас рекламировать в общем участники фонда развивают группы инструментов для построения надежных масштабируемых распределенных приложений и первая группа это инструмент оркестрация dallinga каберне this а точнее его подсистема scheduler решает на каких серверах какие сервисы запустить кубер notice от они не единственный инструмент из этой группы есть еще месяц написаны на си плюс плюс есть еще и dockers вором написанные на гол инге в общем вы можете себе подобрать как подходящий момент я сейчас не буду приводить сравнение чем они отличаются и какая у них архитектура я только скажу верхние уровни во что все они примерно одинаковые и у них есть они состоят из энного количества серверов на которых запускаются ваши микро сервисы например в обид и у нас около тысячи серверов в кластере купер на тесс и есть несколько мастеров которые управляют этим кластерам у мастеров есть свой сторож которые дистрибьюторские values to reach это отдельная тема для тема дистрибьютор киева или старридж в купер найти все по умолчанию используется дети сиди и мастера предоставляют опять для работы команд light интерфейс утилит и ей дашбордов и мастер кубер на тесс решает на каких на каких родах запустить ваш и микро сервисы и ноды могут постоянно появляться и исчезать то есть вы можете вводить и выводить эксплуатации нового сервера сервисы меняться с новые сервисы появляться купер ныть из-за вас решают эту задачу в общем купер notice решают я какие сервисы запустить но у вас получается так что на одном сервере сотни приложений вот до этого все ресурсы сервера принадлежали одному монолитным приложение сейчас сотни независимых приложений на одном сервере и нужно как-то делить ресурсы сервера между ними сделать так чтобы не было плохих соседей плохой сосед это когда один микро сервис начинает утилизировать все а циpкa сервера или забивают всю весь над варка либо всю память и не дает работать другим микро сервисом чтобы это избежать вам нужно контейнере zerowatt приложение контейнеризации это метод виртуализации когда приложение запускается в изолированном пространстве пользователя изолированных пространствах пользователей и она дает нам accounting ресурсов мы можем для каждого микро сервиса указать сколько ресурсов циpкa сети памяти он может использовать если сервис пытается использовать больше циpкa чем ему доступно то начинается тротлинг микро сервиса и дается процессор на время для работы других микро сервисов опять же в клад найти в компьютер есть множество инструментов из контейнера нe тайма и все они заменяемые этот фонд пропагандирует модульный подход делать так чтобы каждый компонент тег можно было заменить тот контейнер здесь это тоже не единственное решение из контейнер on time есть еще кривой ракет они верхние уровни тоже в принципе похоже работают и предоставлять одинаковый окей есть контейнер runtime интерфейс по сути вот контейнер runtime интерфейс по сути набор живописи вызовов типа запустить остановить получить состоянии докер-образ запущенного контейнера и куперу notice через эти джер писи вызова говорит какие приложения запустить на каких серверах в общем вот у нас есть инструмент оркестрация dallinga есть контейнер runtime и давайте посмотрим из чего состоит микро сервис микро сервис это может быть нет это не только одно запущенное приложение это может быть например бинарник собранный бинарный голлинг либо pitch пфм демон также в инстанс микро сервиса может ходить и james h прокси для high availability до внешних ресурсов pg bouncer и jinx reddy's как кей values to reach до каждого инстанция микро сервиса тоже можно так делать расти слог для сбора логов и вот это все вот эти все 6 контейнеров это один instance приложение и мы инстанции приложение с гелем горизонтально запуская много одинаковых инстансов и равномерно распыляет трафик по ним помнить игры вначале 3 микро сервиса для 3 инстанция для слабо нагруженных сервисов и до 90 100 для нагруженных микро сервисов так мы масштабируем наши микро сервисов опять же микро сервисы это по сути то к контейнеры контейнеры то запущенное приложение на базе какого-то образа поэтому вам нужно где-то хранить образы собранный образы приложений опять же вы можете использовать dota реджис 3 а вот docker hub примера либо ставить свои правят реджис ты для на своей инфраструктуре у себя в компании мы выбрали харбор и опять же они все взаимозаменяемые вы можете подобрать любой docker и джесс 3 себе с каким будет комфортно работать харбор для нас это клоун эти freddys 3 у него есть ролевая модель доступа есть политики репликации есть restful api есть дашборд есть бэкапы достаточно мощное решение опять же берите готовые кубики из фонда клоунов компьютер вот начали делать микро сервисы сделали например два микро сервиса продукт пэйдж и messenger у каждого своя база данных со своей командой свой backlog вот как как говорил все вот идеально но пользователи не знают какие у нас есть micro сервисы пользователи приходят в авито приходят на наш сайт и вводят в урне в в авито ру слэш iphone 11 или бывает русло штамп profile manager примеру нужно как-то научиться рауте трафик на конкретный микро сервис приземлять пользовательский запрос на конкретный микро сервис эту задачу решает обиде твой опять же опеки твой это не единственная задача роутинг это не единственная задача для беги твой от удачи можно положить а плетей шин firewall red limit own дефекация метрики мониторинг и логирования сср терминация сектор брейкера кэширования ретро и и так далее есть сотни инфраструктурных задач которые можно положить в папики твои я пообщался с нескольким компаниями почему-то большинство компаний делают свои аппетитные и мы тоже у себя начали изобретать своя беги твой мы не стали изобретать к брать коробочное решение возможно потому что не знали что они есть если зайти на фонд ло отметив то там есть пул аппетит wave open собственных проектов которые все это уже умеют делать вы можете себе подобрать опеки твой на любом стеки технологий которые вам нравятся например взять kong битвой на engine смыслу и где ло запускается на worker of engine со через опыт расти вы можете взять с and in all написанные на джаве кракен ты написанные на коленке либо ambassador там гулан cpython смесь и из коробки вы получаете сотни возможности для ваших аппетитов посмотрим что имеет конге твой в себе конки твой это платформа независимый твой есть готовые сборки для кубер найди садаки раствором месяц есть его можно запускать на обычных серверах в нем есть динамически алгоритма балансировки трафика есть встроенный секир breaker ахилл в чеке активный-пассивный мониторинг об стримов есть интеграции с разными ford party dns резольвер ами такие как консулы встроенный af20 и всякий механизма авторизации пользователя тот животе токенов до обычной сессионной cookies и он плавал вы на гитхабе можете найти много плагинов которые будут расширять его возможности у нас сайт сам описано пике твой мы просто начали делать очень давно примерно в одно время когда конки твой начал появляться и какие задачи у нас опеки твой решает вот видите три микро сервиса внизу они могут быть написаны на разных языках на питоне на коленке на php и к примеру им всем нужно модификация пользователя то есть нужно понять по пользовательскому запросы каток не пришел разобраться сезонную куку сходить с этой куклой какой-то сторож проверить активность пользователя проверить не заблокирован ли пользователь в общем мы можем по идее копипастить эту логику портировать его на разные языки а можем сделать так что пики твой это будет делать самостоятельно опеки твой в нижестоящий сервисы подмешивает заголовок юзер айди и нижестоящие приложение ему доверяют конечно же аппетит фильтрует те заголовки которые пользователь не может поставить сам в общем вам понадобится опеки твой и не пробуйте изобретать свои беги твое вы никогда не догоните эти готового решения берите что-нибудь из фонда клауд найти в компьютер fondation идем дальше у нас помимо прямого пользоваться кого трафика есть много межсервисный взаимодействий я помните говорил что нас 1000 микро сервисов вот на один пользоваться и запрос в среднем по рождается примерно 5 10 каскадных запросов у нас есть такие тяжелые странице типа страница карточка объявления либо страница подачи объявления где для полноценной отрисовки странице задействовано 50 микро сервисов то есть один пользователь запроса породил 50 каскадных микро вызовов микро сервисов и поэтому межсервисные взаимодействий выходит на первое место сразу договоритесь о протоколе взаимодействие между микро сервисами договоритесь о том как делать подписи запросов договоритесь о том как делать sdk клиенток микро сервисом то есть не делайте прямых cool запросов из кода вашего приложения делайте все через готовый sdk клиенты к вашими к сервисам про говорите про коды ошибок а делитель ошибки сетевого уровня от ошибок доменного уровня у микро сервисов опять же если я хочу начать работать с каким-то микро сервисом например вот из моего приказа моего микро сервис я хочу делать запросы в этом композиция 1 на примере я делаю через пакетный менеджер composer install пакета клиента к этому микро серво на случай из головы гогот вообще мы сейчас идём в кода генерации могу стали делать клиенты каждого микро сервису вручную на каждый надо на разных языках и мы сделали кода генерации когда одной командой мы генерируем клиенты в проект для тех микро сервиса с которыми хотим работать в общем межсервисные зама есть и выходит на первое место по важности и если вы вы вы выберете какой-то протокол общения между микро сервисами вот у нас 1000 микро сервисов протокол в дальнейшем вы уже поменять не сможете скорее всего у вас не хватит сил поменять протокол для межсервисный взаимодействий поэтому зайдите на фон клоун этим и посмотрите уже готовые рпц фромборке с поддержкой разных языков программирования вы из коробки получите поддержку java си плюс плюс с колен python и других языков обратите внимание на gr5 либо надо бы это хорошее рпц фромборке вас будет из коробки механизмы для тестирования отладки фолд injection of мониторингом сбора trace of вы все это из коробки получите в общем вот мы вы провели какой-то протокол общение для между серб между микро сервисами у нас вот есть два микро сервиса к примеру который взаимодействует по выбранному нами опять первыми красиво сделать запрос вдруг о микро сервис конечно мы можем обо всем договориться и надеяться что все инженеры будут соблюдать заданные договоренности то есть они будут к примеру честно прокидывать trace один честно покрывать метриками мониторинга и межсервисные взаимодействия честно настраивать alert и на межсервисные взаимодействия по факту когда нас 400 инженеров все эти договоренности быстро забываются теряются ломаются еще их невозможно обновлять и менять то есть если мы хотим что то поменять в наших протоколах на приходится вносить изменения в 1000 микро сервисов это дорого и долго вас мыть посмотрите на паттерн сервис прокси сервис прокси то паттерн когда у каждого инстанция микро сервиса поднимается сайт корр прокси и через netfilter операционной системы windows это то что проявляется че , balls утилиту весь трафик крутится через это прокси это распространенный паттерн то есть январь the service прокси становится еще одним контейнером ваших запущенных приложениях помните парочку слатин за ты показываешь нас 10000 запущенных приложений вот во vita 10000 запущенных проксей десятки тысяч проксей которые между собой взаимодействовать опять же не изобретайте свои решения как сервис прокси посмотрите наклон этих и увидите готовые сервис прокси который легко встраиваются в любую инфраструктуру которую вы все выберите будь так оберните smashes либо dockers вором мне больше всего нравится и двое и traffic in двое на си плюс плюс и трафик написанные на коленке это самое правильное место для выполнения retrieve самое правильное место для выполнения секир брокеров tracing сборы метрик и мониторингов то есть у каждого инстанция сервис этот сайт корр прокси локально собирает информацию агрегирует ее по межсервисный взаимодействий и централизовано сбрасывает в какое-нибудь хранилище например централизовано у каждого сервиса собирает все trace и мешке разных взаимодействий и скидывает в ее в систему хранения trace of up and racing протокола вот так кстати вылет рейса в мир сервисных взаимодействий в микро сервисах это рейсинге можно расширять то есть мы можем не только по request найти и восстановить хронологию какие сервисы были задействованы а у нас примерно карточки объявления 50 микро сервисов но эти trace и можно еще расширять из приложения то есть можно из самого кода приложения дополнять trace и например обернуть запрос в базу данных таймингом и отправит race ready либо во внешнее походы во внешние ресурсы либо просто какие-то тяжелые задачи оборачивать таймером и помечать их как помечать request найди и отправлять система хранит рейтинга и главное что это все легко между собак интегрируется берите инструменты для треккинга например мы у себя взяли я гири она просто из коробки подключилась к сервис прокси из коробки зашло в купер нить с это такие готовы кирпичики как из которых можно построить вашими красивую архитектуру и фон klout эти в компьютер фан дышат пропагандирует модульный подход когда один компонент можно заменить другим компонентом если идти дальше у нас на первое место выходит межсервисные взаимодействия то мы можем конечно же договориться что в каждом из тысячи микро сервисов люди делают сервис прокси не забывают добавить и раз прокси и еще все используют одну сервис прокси конечно можно договориться и надеяться что инженеры будут это делать но можно зайти дальше и есть пул инструментов называется сервис мышь когда мы централизовано артисты room всеми проксиме то есть 10000 проксей и мы из командной строки можем управлять всеми процессами в 7 их всех сервисов мы можем например сказать что окей вот в этот микро сервис никто не может ходить кроме вот эту на микро сервиса либо вот либо централизовано управлять расположение микро сервисов делать так чтобы допустим у нас есть десятки микро сервисов и мне надо сделать запрос в какой-то из них я могу сделать а п тесты между микро сервисами могу делать конри релизы для микро серов этот централизованный пульт управления для всех проксей если идти дальше то есть мы посмотрели множество инструментов для построения микро сервисной архитектуры мы можем всех инженеров обучать по идее и говорить им что использовать и как использовать но мы пошли дальше и у нас в обид и начали использоваться шаблона микро сервисов мы сделали шаблон и на php голлинг и ноги джесс основных языках из стека наших из из нашего techradar а мы сделали максимально платформа независимыми в коде шаблона микро сервис ни слова нету по кубер нить из ни слова нету про сервис прокси ни слова нету про сервис мышь есть только об то мол описания микро сервиса в котором есть название микро сервиса по которому определяется контроль доступа и вообще это все идет в метрике в мониторинг есть engine у сервиса где описывается наш там cert на каком языке сервис написан и размер микро сервиса например сколько ему циpкa или памяти выделять мы сделали коробку стандартной коробочки типа большой маленький средний сервис и команда выбирает сколько ресурсов нужно для этого микро сервиса автоматизировали создание баз данных то есть можно записать секцию окей пастбищ и в продакшне автоматически поднимается база данных также как и в деве в стейджинг окружениях в общем над этим пассам у нас работает целая отдельная команда и есть более подробный доклад про наш платовым а за сервис который рассказывает саша лукьянченко вы можете поискать на в интернете и видео где подробно рассказывается про наш пас помимо этого помимо этого чтобы построить надежную распределенную масштабируемой архитектуры вам понадобится еще и инструменты для стриминга и messenger га то есть в микро сервисах вы теряете инструменты для consistent насти данных вам придется идти в вэн шел консистенции и без стриминга и мастеринга вы не сможете построить надежное решение надежное приложение у себя мы используем кафку и пульсар есть готовые сборки или готовы инсталляции по базам данных для построения надежных распределенных масштабируемых решений есть коробочные паз и например heroku все вы тоже можете найти в этом фонде есть клоуна этих 100 раджей например с 3 cf меню есть инструменты для лакирования который тоже из коробки легко встраиваются в экосистему легко интегрируется со всеми остальными инструментами и есть еще многое другое в общем микро сервиса такая дорогая технология и если вы хотите зайти вам придется начать использовать множество групп инструментов это хороший вызов для ваших drops of и архитекторов и я бы советовал вам несколько раз подумать прежде чем вы будете те микро сервиса у меня все спасибо от white риск тебя бежит и это не понимаешь что тебе свои я классная was also with a ti но будет ещё одна спасибо да именно я рамка ребята поднимайте пожалуйста руки у кого есть вопросы вау круто но давайте первый ряд сначала в онлайне возникает вопросов что нет звука в самом начале когда мы переключаемся в технических толков наших спонсоров на зал а есть еще такое говорю ребята все нормально и развлекая залп аккаунт техническая пауза для того чтобы вы могли нас видеть со сцены и так у нас есть первый вопрос спасибо за доклад у меня такой вопрос вы нам рассказали про кирпичики по все как-то здорово и в тронули до у вас сервис мышь во вид внедрен или вы просто набрали кирпичик вы построили из них лекцию свое у нас есть отдельная команда которая занимается развитием платформа для микро сервисов вот кстати вначале меня немножко неправильно представили я не развивают не разработаю платформу и у нас да есть самописные решение на базе navigator ну самописные решение которое занимается контролем доступа какие микро сервисы где находятся то есть это централизованное управление всеми процессами всех микро сервисов она называется с навигатор сам описано решение вы сказали что на один запрос пользователя может возникать до 50 меж промеж сервисных запросов уже ваш инфраструктуре какой процент времени исполнения запроса пользователя лена уходит на вот это общение между микро сервисами ну мы пытаемся делать асинхронный запросы то есть так чтобы пришел пользуете запас мы сразу сформировали 5050 запросов рожна микро сервиса и по сути время ответа для пользовать это время самого долгого микро сервис ответ на самого долгого микро сервиса это требует большого рефакторинга реально большого рефакторинга и осознанно работать их долгом семён спасибо за доклад у меня вот такой вопрос вы сказали микро сервиса есть свой этих лиц отвесно технические решения принимаются отдельно внутри каждой команды и с одной стороны это наверное хорошо что каждая команда может выбрать там тот стейк тот прибор которым больше подходит но с другой это может привести к тому особенность у вас тысячи микро сервисов что у вас будет огромное разнообразие самых разных технологий для того чтобы все это поддерживает нужно будет универе на каких специалистов самых разных компетенций вот как вы с этим справляетесь есть такая проблема помните вначале был что есть парочка сотен микро сервисов которые непонятно кому принадлежат и и кто их делает ее нужно их оставить живыми и либо удалить как раз платформа за сервис этот подход который есть отдельный доклад у саши лукьянченко из нашей компании он он держит в рамках наш стек технологий у нас есть всего лишь 4 4 шаблон сервисов и вы не можете и инженеры не могут сделать какой-то сервис не на базе этих шаблонов то есть в микро сервисах лезть ни слова нету про вернитесь ни слова нету про сервис прокси промеж и инженер просто с нуля написав на расти он не сможет его за тепло продакшен этим мы как-то пытаемся ограничить techradar тексты и этим мы автоматизируем обновление микро сервисов если мы захотим переехать примеру из кубер notice of что-то другое вообще никому не надо ничего делать мы все сервис автоматически перенесем другой кластер либо в другой инструмент регистрации менеджмента либо поставим новый но либо переедем на новый сервис марш это все максимально платформа независимо но и как раз разработчики не могут писать какие-то сервисы на других языках все на готовых шаблонах он на спасибо у нас есть человек с микрофоном потом будет первый ряд вот здесь вот на первый ряд сюда принеси пожалуйста а дальше уже в пятом ряду просто кое-как управляете хранением данных то есть каким то микро сервисом нужно хранить там десяток гигабайт каким-то нужно терабайтами хранить пример сервис который занимается хранением пользователей или страницами объявления у нас самый толстый пользователь это сервис объявлений там сортированная база данных что-то около тридцати двух терабайт про тебя на каждую шарды в общем там гигантские объемы данных и когда команды решают что ей нужен микро сервис некоторые базы данных автоматически создаются то есть когда человек создает микро сервис прямо в пасе come on line интерфейс utility говорит что кевин от создать микро сервис и а утилита спрашивать там какие базы данных нужны редис и по сгрыз хоккея на след родис ip адрес то есть там спрашивать какие объемы данных какие нагрузки ожидаемые все это автоматизируется нашей команды по склад ума захера вас есть разные сервисы есть конечно сервис из сервис-листа есть они с костей класть которые вообще не тут хранилище бар и не хранилищу данных есть ну разные как бы то есть у вас есть какой-то один-единственный сервис баз данных они или нет нет нет конечно не поднимается один контейнер то есть нет ли у каждого сервиса может быть своя база данных один из паттернов проектирования до микро сервисов сделать так чтобы сервисах pussy расы были свои базы данных и не каких вот типа общая база данных на всех это вообще не нельзя так делать не стабильна и не эффективно работать у каждого сервиса своя база данных причем разные команды предпочитают кому-то удобно с манга тебе работать кому он потому что им не нужно набирать транзакционных кому-то нужно нужен позарез например в биллинге я говорил вначале вы помните был слайд две с половиной тысячи баз данных то есть ну вот ответ для спо 2000 баз данных у разных сервисов свои базы данных супер сейчас вопросы с 1 рядом и потом у нас тут около камеры есть вопрос а дальше совсем у задней стены и в какой-то момент все онлайн семен добрый день игорь борисов softline у меня несколько вопросов модератор разрешит пачку спасибо начнем тогда с первого вы когда выбирали докер был ли выбор он осознаны или это просто hyip тренд скорее всего это был hyip есть проблема в докере на самом деле мы команда 2 saw насколько разная пыталась перейти на другие инструменты когда контейнер антенны я меня не конформации чем это закончилось сейчас у нас контейнер и используются продажи их тогда второй вопрос если можно прокомментируйте как вы решаете ну хотя бы две наиболее массовые и известные проблемы которые связаны с а и в том числе с микро сервисной архитектурой это распределенная транзакция и сложности в отладке в дебаггер ну распределенных транзакций у нас нету мы их не используем это тоже не очень я бы не советовала строить распределенной транзакциям мы делаем все в парадигме иван шел консистенция шина данных событий до им события что нужно какое-то какое-то действие поменять текущий момент времени у нас нет консистентной sti когда все события шины данных обрабатываться мы приходим к is consistent нам у состояния до иван шел consistency мы используем помните я говорил есть пул инструментов для раньше для стилинга и массажа у себя мы используем кафку и сейчас переходим на пульсар а второй вопрос был про от типа к отладку как решается проблема отладки ну есть инструменты для трейдинга мы ну вообще если их использовать правильно паттерны проектирования то у вас должна быть низкая связано с между микро сервисами то есть нужно можно четко понять как у микро сервисе проблема при если у вас не получается распределенный монолит хорошо изолированная микро сервисы редко когда приходится тестируем интеграцию 10 микро сервисов ну начинаем все с рейтинга straight потрясете можно понять вообще какие микро сервисы были задеты какие запросы отправлялись и там уже как-то локализовать в каком микро сервисе проблема подключить ту команду которая владеет этими к сервисам я успею зачитать пару вопросов из онлайна у нас есть уже два человек с микрофоном в центре зала и в самом конце зала и на этом мы просто во времени уже не успеваем до травы в кулуарах можно будет продолжить они смысле реальные тоже просто у вас там вместе с вами те люди которым онлайн а ты выбираешь ты выбираешь лучшего просто помнишь я думаю что рано еще еще еще еще не все проданы спокойно хороша но претендент есть я понял вот был вопрос маленький сказали что около тысячи базу данных как распределены как взаимодействуют и рассказал что у каждого своя база да да конечно he а вот такое по поводу использование микро сервисов с кластером сетевых интерфейсов примеру dippy дикий под linux работали ли вы с ними и можно ли их подружить вообще на это центр я не смогу ответить увы найдите докладчик в чате побеседуйте если вам интересно его мнение хорошо и из центра зала вопрос и дальше их концерн да добрый день симеон спасибо за доклад вот хотелось бы вам такой вопрос задать у меня зовут валерий компании accenture технологический центр города ростов-на-дону вы как-то деликатно обошли тему несогласованности модели данных то есть я поясню вот вы говорите две с половиной тысячи баз данных понятно что все микро сервис и обмениваются друг с другом какими-то структурированными сообщениями то есть это может быть джейсон это может быть xml и вот люди составляют маппинге вот как вы уходите от проблемы того что чем больше у вас становится микро сервисов тем больше этих mapping of приходится делать вот сталкивались ли вы с этим и если сталкивались как какие инструменты решения вот вы посоветуете использовать что скажет мэппинг да но мы используем стандартный у нас стандартизировано формат сообщение для шины данных то есть и мы делаем сообщения в шине данных максимально простыми максимально тонкими то есть пытаемся не дополнять и каким-то широким повело водам в шине данных кидается событий типа создан объявление вот его дичь ник и дальше уже кто получает это событие поэтому адэшника получают нужную информацию поэтому объявление то есть события шине данных максимально тонкий и мы используем единый протоколы я вначале тоже говорил помните что 1000 микро сервиса хотя не будет все работать на разных протоколах это будет от в отладке они все у нас работает на едином протоколе и ну как бы ни даже не стоит вопрос вопрос мэппинга сообщений кстати а я кстати понял ваш вопрос да у нас есть реестр всех событий то есть и реестр всех событий описывается как каждое событие в шине данных она описывается контрактом и когда сервис хочет начать работать с каким-то событием подписываться на к это событие вот серво из кода ген ему генерирует мэп и mapping модели для этого события и ну и события разворачиваются в эти модели посетил больше и последний вопрос у нас есть да а вопрос был снят если вдруг последняя рука есть вот есть центре зала сейчас мы успеем ребята он в онлайн чате пожалуйста подключитесь потом цифровые кулуары то я вижу что вы писали вопросы просто мы уже не успеваем нам важно дезинфицировать зал подключитесь цифровые кулуара вы сможете задать вопрос свою докладчику там спасибо семён доклад алекс работает простить центр коллега компания экс нас хотела спросить такие блиц-вопрос сколько в команде платформу вас человек работает у нас целый кластер платформой там работает 50 по моему инженеров 50100 и нет больше ста инженеров в платформе вот что сектор занимается развитием paas распила монолита базами данных и замена замечательно выставлять небольшой проект который стартует его им говорите а берите вот эти кирпичики хорошие они все сразу вам дают и надо быть экспертом в этих кирпичиков и как с этим бороться когда у вас не 50 человека например 3 вопрос когда у вас не 50 человек платформенных инженеров а всего лишь 3 и они шарятся еще на все команды как вот как вот такой пул стек сервис мышь и так далее все что вы предлагали использовать как как найти таких специалистов которые будут экспертами в такой широкой область а зачем вообще нужны эти кирпичики когда вас всего три человека вам не нужны микро сервиса то есть micro сервис это сделать так чтобы комфортно работать было 400 500 ом инженером к примеру сделать так чтобы мини команды были максимально независимо если вас всего три человека вам микро сервиса вообще не нужны но не соглашусь нашей компании например платформенная команда составляет всего 5 на этом на этом я как mutter автор просто попрошу закуси на вы сможете дискуссию продолжают цифровых кулуарах ребята нам важно дезинфицировать зал и а ты выбираешь лучший вопрос даже если он из онлайна люди получат свою книгу ко мне больше заполнялся опрос про 50 каскадных запросов потому что это реальная тема болит про 50 каскадных запросов подойди пожалуйста дак сцене чтобы наша ассистента смогли тебе вручить спасибо огромное ребят а сейчас освободите пожалуйста зал моего дезинфицируем те у кого остались вопросы к семёну проходить из цифровые кулуары ногами или перед найти нажмите кнопку рядом с трансляции вы сможете там побеседовать спасибо вам и и и если и и они и на вот добрый день меня зовут александр сергиенко я ведущий разработчик направлении потоковой обработки и больших данных компаний neoflex нашей компании имеет более чем 15 летнюю историю и обладает обширной экспертизой в области фильм тех а банковском секторе сфере кредитных бюро не секрет что этот сегмент айти является одним из самых технологичных и требуемых с точки зрения объемов данных скоростью обработки такту market масштабируемости отказоустойчивости вместе эти требовали дают разработчикам широкие возможности для технического творчества и применен новых концепций подходов и технологий в этом тип толк я бы хотел осветить тему монетизации кредитных историй и выделить наиболее яркие с технической точки зрения моменты с которыми сталкивались в проект компании neoflex связанные с построением аналитической платформы крупнейшего российского кредитного бюро позволяет раскрыть тематику обработки и колоссального объёма данных на фоне высоких требований к отзывчивости стабильности и горизонтальные масштабируемости системы законодательства российской федерации обязывает финансовые организации передавать сведения о кредитных историях заемщиков в так называемые кредитные бюро каждый приобретенный кредит будь то покупка нового автомобиля или ипотека каждый платеж или просрочка даже сам факт запроса отчета по кредитной истории выполнены через интерфейс на веб-сайте все это становится частью истории входит в обширный и непрерывно расширяющийся массив данных кредитных бюро случае рассматриваемые аналитической платформы речь идет о сотнях миллионах хранимых кредитных историй и связанной с ним информации каждый день кредитное бюро обрабатывает десятки миллионов запросов отчетов по кредитным историям сотни гигабайт новых изменений от кредитных организаций и формирует миллионы уведомлений о полученных обновлениях для банков клиентов в основе бизнес и кредитного бюро лежат три типа продуктов обслуживание запросов отчетов по кредитным историям анализ изменений в историях и формирования уведомлений различных типов это так называемые триггеры а также оценки заемщиков с точки зрения его надежности и платежеспособности так называемые ско ринге триггер это некоторые события которые являются реакцией на то или иное изменение в кредитной истории чем меньше временной отрезок между изменениям и производным событиям тем выше вероятность успешной монетизации этих данных рассмотрим реальный пример михаил открыл счета в двух банках каждый из которых занимается потребительским кредитованием оба банка хранят кредитной истории своих клиентов в одном и том же кредитных бюро но банк номер два назовем его west best offer дополнительно приобрёл продукт триггеры в отношении ряда своих клиентов в том числе и нашего героя михаила михаил приобретает в кредит новый смартфон и по случайности для расчета процентов и переплат обращается к менеджер банка номер один клиентам которого самый является банк запрашивает кредитную историю михайлов бюро и после получения ответ и предлагает ему кредит под восемь процентов запрос кредитной истории от банка номер один также является ее частью аналитической платформы бюро обрабатывает запрос с точки зрения триггеров и генерируют уведомление для второго банка то есть банка в с best offer который ранее приобрела соответствую услугу реагирую на полученную давление банк номер два присылает михаил с мсс выгодным контур предложением кредита под более низкий процент и клиент с радостью его принимает рассмотрены сценарий описывает лишь малую часть возможных вариантов монетизации данных по кредитным историям ходе анализа требований и предпроектного обследования анти ландшафта кредитного бюро мы поняли что тех логический 100 кв asdasd а в основе которого лежит симбиоз уже ставший классикой big data и потоковых подходов к работе с данными может решить существующие проблемы и дать бизнесу возможность реализовывать принципиально новые продукты при разработке аналитической платформы критически важными для нас являлись следующие требования первое это снижение той тумаркин для новых продуктов второе переход от пакетные к потоковой обработки и real-time продуктом с минимальными задержками обработки третье внедрение технологий машин в обучения и жизненный цикл разработки моделей так называемый м.н. abs для задач с хокинга и 4 надежность некая горизонтальная масштабируемость и высокая отказоустойчивость платформы на достижение пацан их целей мы применяли лучшей практики devops и облек сработаем среди истории моделей мой flow и тепло реализуем процессы соседи используем современные фреймворке библиотеки потоковый как встретилась так и стоит в обработке данных light бен клауд flow оба чепмен капочи spark а к streams пируем до толик на базе тихо дуб используем apache cassandra до оперативного хранения данных и c в качестве хранилища файлов масштабирования отказоустойчивость обеспечивается рядом подходов и технологий в основе которых лежит платформа артист рации контейнеров от shift центральной части топологий аналитической платформы находятся высоко нагруженные потоковые приложения которые также называется под лайнами они разработаны с использую приборка apache их frank который располагается под зонтом продукты облачной регистрации разнородных потоковых сервисов который назвается live band клауд future платформы полностью соблюдает концепции реактивной архитектуры взаимодействие между отдельными сервисами и pipeline нами полностью асинхронно и реализовано с помощью датчиков к фактической платформа разделена на технологические под модули которые обладают слабой связностью независимо масштабируются и строго изолирован и можно выделить следующие основные модули аналитической платформ первый это pipeline и предварить на обработки данных которые обслуживают процессы захвата анализа и трансформации входных данных 2 этапа система master data management которые идентифицируют изменения или запрос и определяет к какому субъекта кредитной истории он относится 3 этапа клайн и триггеров и поклонись корнаков это основные и самые нагруженные потоковые приложения платформы который обслуживает соответствую бизнес продукции в том числе оперируют модели машинного обучения в скоринга система выявления изменений информирование виктору в данных для бизнес-парк line of и модели обучения это наш последний под модуль источники данных романтической платформы можно разделить на два сегмента первый сегмент это онлайн поток который включает запросу скоринга и отчеты по кредитную историю томашу these руется в платформу при помощь юриста и пиа и построенном на базе той книге клок этот поток обслуживается стекла с микро с сервисами и выделенными pipeline амин основе likelihood лулу и а к string на данный момент они обрабатывает около трех с половиной 5 миллионов запросов в сутки второй сегмент источников это пакетные данные которые состоят из файлов с изменениями по кредитным историям пакетом запросов спаррингов отчетом по историям а так же с сервисным файлами которые обслуживать бизнес продукта платформы например списке клиентов для отслеживания в отношении триггеров этот сегмент обслуживается высоко нагруженными потоками приложениями на основе по чаплин и в данный момент обработать около 80 миллионов изменений в сутки с неравномерным распределением нагрузки с пиками до 15000 событий в секунду каждый сегментов и модули аналитической платформы спроектирован с учетом гибкое горизонтальный масштабируемости пакетные данные 2 сегмента анализируется и разделяются на отдельные события с момента появления такого события платформы функционирует в рамках событий на ориентированной архитектуры каждое обновление или запрос проходит идентификацию в подсистеме master data менеджмент и обогащается средними о субъекте изменения эти обогащенные дискретные события в потоковом режиме передаются в подсистему выявления изменений и дали обрабатываются специфические зависимости от типа при обработке изменения кредитных историй рассчитываются дельты называемые состояние было стола и соответствии с текущими настройками формируются новые события для дальнейшего анализа в pipeline их триггеров и формирование онлайн уведомлений для клиентов беру давайте вспомним наш кейс с михаилом его покупкой подсистема оперативной обработки событий также занимается расчётами викторов так называемых печей для моделей спарринга при поступлении запроса на scaling вектор извлекать из оперативного хранилища и подается на вход модели бёдер из запроса сама же модель при этом сзади плана как обычный под кластера опыт shift разработка модели машинного обучения для сколько выполняется в отдельной области так называемой аналитической песочнице это 1-ый класс строкам shift и инсталляция cf или hadoop оснащенные инструментами для работы специалистов в области дата сайнс проект гипотез валидации моделей а также механизме вынос и модели в продакшен на базе репозиториев модели и мой flow результаты работы бизнес сегмента фанатической платформы . результаты запросов кредитных историй с колин гав а также события по триггером могут передаваться при этом в режиме онлайн через api а или с помощью сервер sun tent стиле пакет на с помощью файлов механизм получения результатов зависит от возможности и потребности creta и никак не ограничиваться стороны платформы в ядре технологического стыка платформы лежит фреймворк артист рацией гетерогенных потоковых pipeline оффлайн band плавать flow фактически это точечный фреймворк объединяющую camber найти с операторы apache spark апачи фринк и а который позволяет строить разнородной с точки зрения бэкенд pipeline в контексте единого метаописания и процесс в диплом это все дело пошлют эрику берну эти сразу действия между компонентами pipeline of асинхронная для этого используется пачиков единый цикл апачи frank я плачу спарки делегируйте соответствующим губернатор оператором подавляющее большинство потоковых приложений аналитической платформы работают сохранением состояния так называемый csl обработкой 90 процентов стрейф по обработке выполняется с помощью apache и fling остальные десять с помощью apache и spork-и в основном это касается работы с do the lake и ходу потоки встретил обработ инаба чаплинка зачастую шарнира ванны с высоким максимальном параллелей фильмом что позволяет быстро менять степень параллелизма операторов на более нагрузках участках проекты и выполнять горизонтальное масштабирование системы с появлением нативной поддержки губернатор привези оплатив young 113 перспективе мы планируем отказаться от текущего купить из операторов young от компании лифт не реализовать динамическое масштабирование fling гробов тоже настал момент делать выводы проект аналитической платформы для активного бюро позволил полностью перевести существовавшие ранее бизнес продукты на real-time обработку радикально повысило производительность отказоустойчивость масштабируемость за счет новые реактивные собаки на ориентированный архитектуры ключевой бизнес продукт триггера и теперь выполнять в режиме онлайн и задержка между получением обновление и формированием события для клиентов 90 процентов случаев не превышает 10 секунд при пиковых нагрузках политическая платформа обрабатывает десятки миллионов изменений ежедневно обслуживая высокие пиковые нагрузки до 15000 событий в секунду и при этом имеет возможности для гибкого горизонтального масштабирования с ростом числа клиентов средства разработки проверки и вывода production для модели машину обучения также позволяют повысить качество продуктов скоринга и снизить тайм ту марки для новых моделей и продуктов тела gifas дата и потоковой обработки в целом позволяют достичь внимание задержек и значительно повысить монетизацию ваших бизнес данных олег привет я артем я бывший редактор хабра сейчас следующий подкаст и мы обречены раз познакомиться здравствуйте добрый день меня зовут сметанин олег я технический архитекторы и delivery лид практики разработки заказных приложений и сервисов компании accenture accent я слышал очень большая компания да действительно компаний accents это глобальная компания официальным метрикам в ней больше 500 тысяч сотрудников 50 странных в 200 крупнейших организациях города компания глобально это глобальность видно когда ты находишься в диалоге или можешь обратиться там базу какую-то нас есть база база знаний и ты можешь посмотреть как примерно подобные проекты решались в японии там недавно или в испании как такие проекты делались такая хорошая к система который естественно приходится управлять это управление выглядит может выглядеть там примерно следующим образом сформировали но в этом направлении клауд first то есть это стратегическое направление в котором сейчас компания развивается определили в этом направлении там 70 тысяч сотрудников всех обязали я так стать не просто обязали способствовали тому что все начиная от аналитиков и заканчивая исполняющими директорами получили сертификаты официальные то есть прям это от рен даров сертификаты все по-честному со сдачи экзаменов и все это в массовом масштабе это сито это работает действительно и соответственно таким образом и идем и delivery мы ту историю дальше расскажет и каким проектом занимаетесь да ну вот наши заказчики это топовые компании с таких индустрий как бэйн кем-то финансовая сфера retail ресурсы они приходят к нам не вылетал чтобы мы помогли им развить новые направления бизнеса технологических обеспечить или модернизировать существующие бизнесе нет из тех проектов которые сделаны с микро сервисной архитектурой нашим заказчикам и delivery club на этих приложения с микро совместной архитектурой для современных регистраторов таких-то курильниц больших вот из таких приложений с которым вы могли наверное столкнуться можно отметить такое решение как кредитный конверт для банков решения позволяет с учетом рисковых моделей данных о клиенте данных а его доходе данных профиля клиентов банки размер разноплановых данных из внешних источников система анти фродо рассчитать преподобный предлагаешь предложение по кредитам для десятков миллионов потенциальных заемщиков ну и за 40 секунд например автоматизировано принять решение о выдаче кредита при вращении заемщика по существующим каналам связи то есть мобильном банке там обратиться и соответственно получит за 40 секунд ответ другим каким-то проектом решением с которым вы могли столкнуться является логистическая логистический сервис который позволяет заказать на алиэкспрессе какие-то товары онлайн и забрать их в ближайшем магазине это система которая интегрирует и большое количество лидеров и коммерса и предоставляет интерфейс и и 5 для скажем минорных участников этого и коммерс таких мелких скажем интегрировать систему управления складами системы управления транспортом систему управления лагерными сетями поста матными сетями вот и уже сейчас это решение перевозит порядка двух миллионов ваших заказов привозят их в магазине ну вот как жить как делать правильно чтобы вместо монолитного да не получите интеграционный от ну есть да ряд методик которые мы рекомендуем вот скажем так тогда когда мы внутри системы это сервис и наши мы и там формируем некую микро сервисную поставку она включает себя имплементацию самого сервиса это всем понятно дальше клиента к нему на том нативном языке на котором будет потребитель большой долей вероятности работы то есть он в последнем случае просто берёт нашего клиента который может работать по синхронным протоколом асинхронным протоколом и мы считаем что мы транспортном такой глупый microcap веса умные и мы поставляем красивую удобного понятного клиента так чтобы на этапе компиляции уже было понятно где там потребитель и и им этот поставщик то пропустим расходимся это вот там одна из первых мир 2 мера значит но если это потребитель какой-то внешней очистим эту самую спецификацию подставляем типа об анапе а если например из новой истории для того чтобы он смог на любом другом языке который там считают нужным использовать своих системах по практике мы интегрируем ся совершенно разными технологиями бывает там на той стороне и пойти например на java то там python и мы там допустим для них сразу там об анапе схему поставляем причем важно тут два момента несколько текущую схему поставить для сколько договориться о будущих изменениях то есть вот это вот самая большая проблема сказать что окей вот кто кому то релизу у нас будет вот такая ситуация и пожалуйста под нее подстраивать значит это очень важный аспект который я во многих корпорациях ну скажем так как на базе базовый базового менеджмента api не вижу часто истории это когда смешные интеграции вот у нас есть условный confluence и мы там документацию пишем там какой то плюс минус произвольной форме нет компьютерно читаемые они компьютера или это нельзя формальной спецификации щит считать естественно там много расхождений может быть таким подходом и когда и выясняется то всем на гораздо ну на поздних этапах таких как и фото из постели на стенды только там потом поняли что серьезно разошлись в понимании происходящего потому что человек читал не компьютер не машина вот-вот в эту же микро сервисную поставку входит там блоки связаны том числе своим то есть там перри используем компания каждый как бы микро фронт свой делают для своего домена разные аспекты и в том числе как это легкая интеграция и сём внутри компоненты которые прибиты гвоздями если по-простому говорить каким-то сервисом который легко использовать чуть-чуть под конфигурировал и все вот тебя весь элемент выбор и справочниками на локации до точки доставки с картами со всеми штука вот есть другие практики такие как вот контрактные тестирования и это еще гораздо более сложная история и сказать что тоже корпорации многие к этому не готовы то есть на уровне методологии мы этого не видим когда например консьюмер потребитель сервиса может выставить свою часть контракта сказать что вот пожалуйста провайдер я жду от тебя вот такие вот там поля какие-то значения в каких-то местах в таких-то структурах и ты не можешь выпустить обратно не совместим с не учтя этого опять же это управление версиями в общем набор техник вот виде микро сервис на поставки которые правильно артефакты для консьюмер а для потребителя выдает контрактные тест и вот они все помогли бы в значительной степени все это интегрировать без щёк ну ну куда бы не завел нас погряз я желаю вам успехов всем спасибо до свидания спасибо большое спасибо что пригласили и вот мы снова эфире вы заметили что наша конференция гибридная и поэтому иногда возникают технические паузу на переключения в этот момент в трансляции возникают вопросы по нет звука просто мы переключаем между роликами и и залам все нормально но этот доклад выводит нас на совершенно новую высоту потому что это доклад гибридный докладчик по личным причинам не смог сейчас приехать поэтому он потрудился и записал свой доклад заранее а после доклада он подключится к нам через удаленную связь с может отвечать на ваши вопросы из зала и на вопросы из онлайна посмотрим что из этого выйдет он нас видит вот в эту камеру и надеюсь что сейчас именно она в эфире и я прошу встречает доклад году алексей тимин аплодисментами привет давай здравствуйте я алексей теме ведущий разработчик в систему локализации буду в компании мы работаем над такими приложениями как баду и bumble чтобы локализовать эти приложения в системе у нас находится 150 тысяч фраз и текстов которые мы перевели на 50 языков и чтобы эти переводы фразы и тексты были доступны нашим пользователям мы привлекли четыре сотни разработчиков сегодня в докладе я расскажу о технических особенностях процесса локализации потому что огромное количество вопросов мне поступает периодически и самые главные моменты которые хотелось бы осветить этот то как мы синхронизируем работы разных команд как мы versio неру им как мы обновляем и как поддерживаем и согласованными переводы на мобильных клиентах на и на вебе даже если у вас в компании например не используется какая крутая большая система локализации а все основывается на google таблицах все равно доклад будет полезным потому что я рассказываю о процессах и о том на что мы обращаем внимание чтобы получалось качественно и я расскажу как мы достигли того что разработчики наши очень хорошо отзываются о системе переводов она и не доставляет практически никаких проблем начну я со снов потому что очень много людей не представляется чего начать процесс локализации собственного продукта кто знает для тех будет большая сложная история дальше а пока рассказываю что такое лексема откуда мы их берем и как мы их храним и так лексема это строка фраза или даже целый текст в общем любая неделимая единица которая приходит на перевод и показывается пользователю откуда мы берем лексемы представим что у нас есть символ шаблон это может быть как html шаблон так и например форма если вы разрабатываете приложение для десктопа мы извлекаем тексты из почтенных шаблона даем им идентификаторы как-никак промотает промо текст и переводим эти тексты шаблоне же у нас остается только идентификаторы вместо которых мы можем подставлять переводы на тот или иной язык и получать локализованное представление этого шаблона этой странице и так где мы храним лексемы которые мы извлекли шаблонов как я уже сказал алексеем и есть у данте секатор и переводы сама лексема и и переводы это как идея и перевода этой идеи на другие языки мы называем сущность эту целостность лексемы и переводов контент версия то есть это контент который может быть показан в том или ином месте в шаблоне идентификатор текста очень важен и используются в программном коде для того чтобы получать переводы поэтому идентификатор в основном хранится используется в ветке в детей а перевода хранятся в базе данных но для того чтобы обеспечивать синхронизацию синхронный релиз мы связываем ветку и запись в базе данных посредством номера жир этикета сейчас будет небольшой обзор процесса перевода без каких-то деталей но чтобы было понятно как он у нас в целом выглядит и на что мы обращаем внимание начинается всё с технического задания в котором мы готовим описание текстов зачем они нам нужны дальше техническое задание идет в команду локализации где прицеле команда локализации очень быстро переносят тексты системы в систему локализации и дальше параллельный идут процесс перевода и процесс разработки клиента и сервера как только оба эти процессы завершаются мы готовы релизе локализованную версию начнем с первой части нашего процесса подробнее поговорим техническое задание здесь сейчас расскажу как мы готовим лексемы и как мы их в базу заносим систему что касается подготовки основным элементом от технического задания является таблица лексем в ней и мы указываем сами лексемы это текст который может содержать переменные который может содержать html теги мы обязательно указан в этой таблице лексема будет отдаваться сервером или она будет интегрироваться в клиент это очень важно потому что пресекает споры и обсуждения уже на этапе разработки то есть заранее архитекторы решают как это будет реализовано также важным элементом в таблице лексем является ключ и здесь такой момент если лексема раньше где-то уже использовалась то у нас в системе для нее есть ключ строковый и он здесь указывается в этой таблице если же текст совершенно новый и нигде такой раньше не встречался то мы его заносим в пазу но ним прицеле команда локализации а в таблице оставляет порядковый номер чтобы разработчик когда начнет работать надо свечи на с функционалом сумма сумела перейти в систему организации и указать строковый индификатор который ему нравится который будет использовать программном коде что касается вот ключей и перья использование лексем есть очень важный момент о котором я сейчас расскажу начнем с истории однажды мы решили провести опрос на английском он звучал как дую смог варианты ответа были тесно у мы завели 3 лексемы перевели их на русский получилось все прекрасно вы курите корью не курю но потом мы решили провести другой опрос и создали новый вопрос английском звучало как сенситивной партии варианты ответа остались теми же самыми лексемами что и были изначально но зачем их менять и сноу все подходит при этом когда мы пилили перевели на русский сам вопрос но оставили те же самые лексемы для вариантов ответов у нас получилось вот такая смешная ситуация пойдете вы на вечеринку и вариант ответа курю не курю что отсюда мы вынесли что переиспользовать лексемы можно но нужно делать это осторожно и учитывать контекст в котором они раньше использовать дальше поговорим о том как мы заносим лексемы в систему скриншот интерфейса нашей административной панели как мы администрируемых темы и здесь собственно показываются основные моменты что мы создали лексем у для году указали ее текст указали текстовые описания зачем это лекси ему нужно где она будет использоваться и привязали алексей мука никиту к задаче это помогает отслеживать прогресс по переводам по подготовке текстов в самом ти кити поле лексем выставилась в нью ченчик это поле используется нашими локализатора me для того чтобы контролировать что в этом ti кити сейчас с лексемами как только работам для схема будет завершена это поле будет выставлена в дан и дальше уже по процессу пойдут следующие шаги но об этом потом так вот что хочется отметить говоря про этап т.д. обязательно нужно учитывать использование лексем разных контекстах если бы перья используете текст обязательно нужно решать стараться решать заранее какие-то технические моменты такие как отдается лексемы сервером или она должна быть интегрированных клиент это экономит время потому что разработчики не решают это уже в процессе разработки и мы это делаем обязательно я как бы советую рекомендую связывает лексемы тексты с задачами потому что это помогает отслеживать зачем этот текст был создан кем когда под какие условия и так далее дальше предлагаю перейти к процессу перевода и рассказываете что происходит на этом этапе важные моменты здесь это в каком порядке мы переводим с какого языка мы начинаем что мы делаем дальше потом как формируется очередь на перевод и от чего зависит перевод и так порядок перевода изначально все текст у нас готовится на английском языке дальше с него мы переводим уже на испанский французский русски на основные языки переводчики на эти языки у нас находится в штате и мы очень очень быстро можем приготовить переводе этих языков также мы можем указать переводы не можем указать а мы переводим уже на остальные языки после основных и среди остальных языков у нас например вот как интересный факт есть пять вариантов английского и три варианта испанского очередь на перевод как она формируется вот пожалуйста скриншот инструмента который позволяет для каждого проекта для каждой платформы указать список языков которые используются например баду веб и видно вот глобус там где глобус и яркие черные значит этот язык используется для баду для веба то же самое для бабло как только создали лексем занесли в систему для какого-то проекта мы по той таблице сразу определяем на какие языки нам надо переводить и дальше нас специальным на специальной странице у нас есть специальный монитор который вы очереди на перевод на конкретные языке также у нас есть инструмент который позволяет по задаче понять на какие языки нужно нам постараться поскорее перевести какие языки опаздывают в данном случае видно что mainline кучи среди и нам осталось перевести на три языка индонезийский тайские вьетнамский давайте поговорим теперь от чего зависит перевод у нас в системе возможно зависимость от 5 5 параметров это численно и переменная которая в тексте встречается от того кому мы показываем этот текст или о ком мы говорим в этом тексте или кому и о ком мы говорим в этом тексте также вариант перевода может зависеть от платформы на которой мы показываем этот текст ну потому что на разных по форме могу встречаться разные термины какие-нибудь системные разделы если мы инструкцию какой-нибудь переводим вариант перевода обязательно зависит от проекта для которого мы его делаем потому что каждый проект имеет свой тон вообще не из пользователями на вы над и и вариант перевода зависит от абед с т а п тест это когда мы пользователям показываем на 2 например три варианта одного и того же контента и зависимости от реакции пользователей понимаем что а вот этот вариант лучше чем но тот дальше очень часто встречается вот такая ошибка 29000 подписчика здесь число слова не согласовано с числом чтобы нам избегать таких проблем у нас есть инструмент это матрица падежных форм и перевод который мы показываем пользователю зависит от того какое число у нас сейчас будет фигурировать в тексте и от того какой падеж переводчик указал при переводе непосредственно только перед тем как показать текст пользователю мы выберем просто на пересечении строки и столбца именно ту форму которая сейчас нужно в интерфейсе переводов это выглядит вот так то есть здесь идет сначала переменная ну фигурных скобках потом слова people и вот после собачки 0 это значит первый именительный падеж 10 человек добавили тебя вы страны и две формы перевода переводчик стоит когда все perry выполнены и оттестированы команды переводчиков нас там есть специально человек который занимается тестированием то в пикете поля лексем выставляется как дан и ticket готов ехать дальше тестирования финальная и в на продакшн это что касается процесса перевода я рассказал о том как мы определяем какие языки мы должны переводить и как мы отслеживаем трек как на треке состояние наших задач дальше давайте перейдем к разработке разработка у нас идет как я уже сказал параллельно с процессом перевода у нас нету никакого смысла чтобы разработчики стали переводчиков или переводчик читали разработчиков абсолютно независимые две веточки здесь расскажу о том как мы организовали параллельную разработку с использованию локализации и как мы предупреждаем ошибки при использовании лексем параллельная разработка значит здесь все устроено вот как как-то разработчик начинает работать над какой-то задачей для него уже созданы лексемы в базе и ему остается скачать себе на машину набор лексем актуальный как это сделать разработчик должен перейти в по таблице лексем из перди на страницу администрирование лексемы указать текстовый идентификатор от систем сверху красным введен по которому разработчик собирается запрашивать переводы данного текста и обязательно надо указать ticket с которым поедет на прот текст потому что код который уедет на продакшн в рамках какой-то ветки по какой-то задачи ничего из себя не представляет без текста и надо синхронизировать релиз и текста и кода какие ошибки при использовании лексем могут возникать давайте посмотрим вот есть перевод на русский язык напишите там то то то то какому-то человеку за столько-то кредитов здесь мы видим у нас есть большое количество переменных причем секунд username у нас еще и с падежом форма будет выбираться дальше у нас есть кредит сама вот это число значение которое будет передано в процессе исполнения программы и это у нас будет задано разработчиком а вот если посмотреть дальше у нас есть кредит это как раз таки ключи слова форма которая будет выбрана автоматически потому что форма слова зависит после : кризиса mount то есть от переданного значения полученного код разработчика и от падежа который выставил переводчик вот все так сложно надеюсь понятно и какая только есть возможно в спешке или от невнимательности возможно что разработчик перепутает при передаче значений для подстановки ключ и значение и вот чтобы этого не происходило у нас есть специальный инструмент позволяющий контролировать как разработчики используют лексемы это абстракция вот в виде php класса реализовано но суть ее сводится к тому что эта абстракция знает о переводе какие используют в нем переменные какой у них тип и эта абстракция контролирует все ли значения были заменены и правильная ли правильный ли тип у подставляем их значений если все подстановки сделаны то абстракция превратиться в текст если же не все то при попытке привести абстракцию к строке что значит при попытке показать текст который скрывается в этой абстракции пользователю мы увидим варнинг не все подстановки произведены и это будет видно влогах и это сразу увидит разработчик процессе работы над задачей таким образом мы отсеиваем ошибки при работе с системами наших разработчиков что в итоге стоит особенно отметить говоря о разработке это опять же обязательно нужно привязывать лексемы крикетом потому что важно синхронизировать момент релиза момент тепло и кода и текста который используется в этом коде и желательно нашем случае обязательно это автоматически проверять подставляем ее значения перемен иначе может быть на продакшене вместо какого-то значения которые там подразумевалось ну просто пустота и получится кривой текст это уже это уже совсем плохо итак мы с вами рассмотрели быстро но основные моменты техническое задания разработку перевод сейчас давайте поговорим о том как мы релизе локализованной версии и здесь я вам расскажу о том как мы доставляем переводы какой формат файлов переводов мы используем как мы обновляем переводы причем так чтобы они были у нас чтобы обновление были согласованы на мобильном клиенте вебе и на мобильном клиенте в случае если часть контента показанного на экране пришла с сервера часть это интегрированная что-то и так версии лексем у нас может быть доступна в любой момент времени две версии лексем диверсии текста та которая сейчас у нас на продакшене так которые сейчас у нас в разработке но самое главное что мы привязываем версии крикетом через номер 2 всегда ветки с кодом связаны с текстом это дает нам возможность как отправлять в релиз ветку и текст так и откатывать просто благодаря тому что мы знаем по какой задачи это действует производилась этот текст заводился этот код какой задач создавался как только задачи с кодом с текстом попала в релиз в кете проставляется информация об этом когда это по сути зашифровано в релизе в маркере релиза зашифрованы дата когда он должен быть развернута продакшн это позволяет продакт менеджером например зайти спокойно посмотреть никого не спрашивать процесс контролируемый прозрачный готовность пожалуйста все все у всех перед глазами иллюстрация того что я уже сказал что у нас в момент времени может быть две версии текста 1 на продакшене другая в разработке так которой она продакшене не может быть изменена потому что если мы ее изменим нам придется перепроверить все переводы и пока мы не удостоверимся что все переводы корректные мы получается не можем их показывать пользователям это значит что если мы что-то меняем мы создаем новую версию текста прям с новым порядковым номером переводим его проверяем привязывают жир этикету и релизом когда уже все готово в данном случае мы заменяем текст мама намывала раму на текст мама мыла раму и очень интересный момент связано с тем что у нас таким образом организованную разработка что разработчики работают параллельно с переводчиками момент связано с тем что вторая и последующие версии текстов могут релизиться переводчиками независимо от разработчиков не надо просить разработчиков поменять что-то в коде просто создаем новый текст переводим удостоверимся что интерфейс не поехал и релизе пока мы хранили текст в коде в гите постоянно приходилось просить разработчиков как только мы перенесли текст в базу сделали связку через номер тикета у нас эта проблема отпала все параллельно и так теперь о том как мы доставляем переводы давайте посмотрим на этот пример на этот скриншот мобильного приложения здесь у нас есть перевод который пришел с сервера и перевод который интегрирован в само приложение мы у нас сейчас интегрирована примерно 20 процентов текстов сама приложения это тексты какие-то базовые например как видите ваше сообщение или тексты каких-нибудь б тестов которые должны проводиться непосредственно как только приложение запущено то есть еще никакой коммуникации не было с сервером а уже уже все должно быть доступно так как же мы доставляем эти переводы нашим пользователям есть разные платформы и первый способ доставки переводов это раскладка новых текстов с релизом который раскладывается на нашей production сервера все просто открываете в от версию видите новые тексты с телефона грузите какой-то контент который грузится сервера видите новые текст если мы хотим обновить интегрированные переводы то мы должны приготовить мобильный релиз выложить его в магазин приложений дальше дождаться пока пользователи обновятся скачают за пусть от и потратит много времени кроме этого у нас есть возможность доставлять через платформы для опросов мы иногда проводим опрос и доставлять переводы в виде по файлов широко известный формат файлов перевода мы умеем экспортировать все переводы в profile вот но давайте вернемся к интегрирована переводом это очень интересный момент чтобы не ждать пока все пользователи обновятся на следующую версию переводов мы разработали механизм горячего обновления который позволяет так называемые снимки базы переводов доставлять до наших пользователей максимально быстро насколько быстро за три дня обновляется примерно 90 процентов пользователей такое хорошая быстрая доставка этот инструмент мы использовали например для того чтобы в период празднования дня святого валентина временно поменять надпись у одной из опций кого вы ищете было dates стала валентайн стоит потом мы применяли все назад вот посредством горячего обновления давайте рассмотрим теперь какой формат файлов переводов у нас часто меня спрашивали вот сейчас наконец я показываю как это выглядит в интерфейсе и дальше покажу как это выглядит в виде php-файла а интерфейсе на что стоит обратить внимание у нас есть обязательного указания то что перевод зависит от пола и возможность указать перевод зависимости от пола вот два варианта перевода один из них универсальный для получается случая когда мы показываем мужчине или человеку неизвестному этот текст и другой перевод для того когда мы покажем этот текст женщине интерфейсе вот в таком на первый взгляд сложно все выглядит так а в файлах это выглядит вот так колючки все мы собственно тот строков идентификатор который был указан разработчикам дальше у нас идет номер лексемы который позволяет нам быстро находить сам текст если какие-то вопросы возникают по нему обязательно есть список всех переменных которые используются в этом тексте или же используется для выбора правильного варианта текста и дальше вы видите собственно список values список всех переводов ключ включите указано условие по которым мы показываем этот перевод то есть либо это дефолт либо это вот как перевод для женского пола самый нижний там включите указан gender name of дальше у нас система локализации позволяет показывать пользователям несколько вариантов перевода одного и того же текста таким образом проводить аб-тестирование в интерфейсе это выглядит вот так просто добавляется еще одна вкладка для тестируемого варианта предоставляются переводы данном случае три вот перевода значит контрольный вариант это изначальный и название второй вкладке это informal tone of voice то есть менее официальный тон в общении с пользователем вот проводим такая б тест собственно как это теперь у нас выражается в виде файла какой формат все тот же номер лексемы все тот же список с типами переменных которые используются в тексте ну типа переменных нам нужны что вы могли контролировать что непосредственно приходит для подстановки в текст дальше у нас есть список views это список базовых вот этих контрольных тех переводов по умолчанию которые используются сейчас относительно которых будем тестировать начну с там ключики дефолт нам singular и нам с формой то соответственно в зависимости от того какое число пришла мы выберем ту или иную форму дальше у нас идет список переводов для б тестов нас указано ключа б тест варианта pt100 то что оба теста может быть ни один вариант например 35 вариантов и мы тестируем какой из вариантов наибольший отклик получил по каждому варианту могут может быть свой список переводов и вот здесь вы видите как то же самый нижнего список шелестом ключик опять же нам singular нам ту в ключах массива и соответствующие им переводы только основной у нас у вас у вас у вас вариант перевода а тестируемый вариантом у тебя у тебя у тебя вот такая бы тест мы проводим и так это отображается файл теперь рассказываю о том интересны механизме который нас реализован горячие обновления переводов что это вот концепцию объясню в процессе перевода мы понимаем что вот на данный момент времени переводы в базе у нас хорошие мы их оттестировали мы убедили что они качественные мы готовы показывать их нашим пользователям как только мы это поняли перед периодически там мы тестируем и говорим что данный момент времени все круто все актуально все супер мы готовились переводчики понимают мы записываем что какой-то момент времени такой-то текст нас устраивает и получается у нас есть список меток времени которые являются идентификатором версий наборов переводах и мы можем соответственно понимать если у этого клиента версия перевода с такой-то меткой времени а у нас есть что-то новое значит мы можем сказать обновить и клиент скачает новый набор обновленный набор переводов на тот момент времени когда наших доступен максимально свежий как это вот реализовано когда пользователь запускает приложение приложение сообщает на сервер свою версию перевода который у него есть мы фоне рассчитываем для этой версии перевода персональный div персональную разницу есть вот у вас версия номер один а у нас на сервере уже есть более новые переводы и сформировал в на версии номер два для каждого клиента мы пошлем в ответе только то чего у него нет ни в не весь слепок не весь не всю базу ему отправим а только там поменялось 10 переводов относительно его версии ну значит надо шлемом 10 переводов сэкономим трафик ускорим обмен данными ускорим приблизим момент того как быстро пользователи увидят новые переводы все будет круто так как мы поддерживаем согласованные тексты как я уже говорил в веб-версии проблемы с этим нет мы обновляем атомарная версию кода и текстов на наших продакшен серверах и все прекрасно все отображается везде одинаковые термины которые мы используем везде одинаковые тонн с которым мы общаемся с пользователем если вы вдруг решили поменять а вот как быть с мобильное приложение здесь есть переводы пришедшие сервера есть переводы интегрированные и как как обновить одновременно и тут мы используем можно это хаком но я бы так не сказал в общем об и тестирование и таким образом мы поменяли термин суперсила на в аду premium как это было абэ функционала бы тестирования позволяет заранее на все платформы разложить конфигурацию я б теста и в этой конфигурации указать дату метку времени с которой мы начнем абэ тест мы заранее разгадываем конфигурацию с указанием момента начала теста и заранее раскладываем запускаем обновление переводов на все платформы и если мы знаем искать цифру 90 процентов клиентов за три дня то мы можем предположить что там через неделю через дела у нас прям вот все клиенты обновляться обновятся и будут готовы показывать новую версию тексты переводов и это позволяет нам had a more на в данном случае речь шла о название нашего сервиса и мы не могли допустить чтобы на одной странице была суперсила другой бату премиум вот таким образом мы решили проблему переименование название нашего сервиса что кратко теперь быстренько подведем итоги того о чем я рассказал я прошелся по процессу локализации и отметил важные моменты в техническом задании в разработке в процессе переводов и то как мы релизом локализованные версии надеюсь было полезно составляете всегда подробно и тоже обязательно привязывайте текст к задаче чтобы было понятно зачем для кого кто когда создавал этот текст износил как можно больше автоматизируйте контроль потому что в нашем случае 150 тысяч фраз и текстов помноженные на 50 языков получается цифры там под 8 миллионов текстов на разных языках на японском на тайском и надо как то это все контролировать кто как использует только переводит поэтому автоматизируйте контроль все всем спасибо вопросы пожалуйста на них отвечу так же вопросы можете направлять на наш телеграм-канал localisation митап очень много статей по локализации на хабре в блоге нашей компании и в нашем тех блоге на сайте на нашем сайте спасибо супер сейчас нам нужна минутка чтобы алексей подключился сюда мы подождем ребят может быть мы включим свет в зале для того чтобы алексей видео кто задает вопросы вижу на втором ряду есть рука на первом ряду есть рука и у кого-то уже есть микрофон да хорошо и спущусь вниз чтобы не слепил что рано рано рано так работает вот алексей нас видит добрый день алексей спасибо за доклад меня зовут валерия бы хотел спросить как много времени займет добавление нового языка на вашу платформу то есть насколько это сложно и как много текстов придется перевести гост р что касается времени которое потребуется на перевод текстов то вообще у нас есть целый 48 часов то есть масса 48 часов должны все языки все перевести но если вы говорите о том что мы должны добавить новый язык и все на него перевести здесь надо будет уже узнать с какой скоростью конкретный переводчик переводит и прикинуть то есть если мы заставим переводить 7 с половиной миллионов текстах добрый день игорь компания костес у меня вопрос два вопроса первый вопрос про падежи в разных языках разное количество падежей вот в английском языке насколько я помню 2 падежа финском языке по моему 12-16 падежей вот как вы обходитесь во-первых значит падежами когда она разные языки переводите и второй вопрос вот вы показывали в примерах фразы которые зависит от пола но ведь может быть так что фразы зависит от пола того человека которому она показывается и того человека в отношении которого она показывается на той страстью мужчины мужчине покаются фраза о женщине либо там женщине и мужчине либо мужчине а мужчине женщине а женщине вот поддерживает ли ваша платформа такие ситуации спасибо спасибо за вопрос я записал два вопроса первое падежи собственно как мы с ними работаем для каждого языка у нас в системе занесены все платежи и у переводчиков есть возможность для тех слов форма которых выбираются автоматически заранее проставить все формы перевода что касается зависимости от пол это да вы правы это может быть как как и о ком мы говорим также и кому показываем и и это все возможно учитывать у нас нет ограничения на количество вот этих меток для передачи и для того чтобы предоставить пол пожалуйста о ком кому все это доступно все это работает как бы сказали ребята кто сейчас в онлайне вы помните что рядом с player у вас есть кнопочка выйти в эфир у вы сможете задать свой вопрос алексей а ты помнишь что тебе предстоит выбрать лучший вопрос правда у меня все записано супер есть ли еще вопросы здесь если в онлайне вопросы не вижу знак спасибо тебе огромное за доклад во первых наша благодарность приедет к тебе я надеюсь своевременно это будет именно я рамочка признательность рассказ и фуде с надписью highload году тоже города и полезно до михайлова от города скажи вот тебе предстоит назвать лучшим вопрос у нас здесь есть книжкой мы вручим приз за тот вопрос который понравился тебе больше всего 2 человек который задавал вопрос о чем там было про зависимость от пола супер вставай получите свой приз поаплодируем победителю сейчас алексей переключиться в зум для того чтобы в онлайн кулуарах вы могли с ним пообщаться вы можете подойти туда ассистенты дадут вам микрофон и вы будете общаться увидеть алексея у нас будет слышать вы будете слышать все у вас хорошо получится спасибо вам огромное а сейчас освободите пожалуйста зал чтобы его дезинфицировать neoflex создает эти платформы для цифровой трансформации бизнеса помогая заказчикам получать устойчивые конкурентные преимущества мы фокусируемся на заказной разработке программного обеспечения используя передовые технологии и подходы наш отраслевой опыт и технологическая экспертиза усиленные готовыми программными компонентами акселератора my разработки позволяют решать бизнес-задачи любого уровня сложности сегодня многие проекты просто развития компании последних лет обусловлено тем что мы работаем на острие самых современных информационных технологий на любые технологии команде these руются и становятся общепринятыми чтобы обеспечить движение вперед необходимо постоянно находить что-то новое я уверен что neoflex такая компания которая иначе но верти развития сможет предложить рынку новые равна идеи вне зависимости от уровня сложности объема задачи и географии мы с заинтересованностью относимся к каждому клиенту мы ценим наших заказчиков и их доверие так как понимаем что именно их выбор дает нам возможность принимать участие в инновационных проектах влияющих на развитие отрасли а если мы беремся за какой-то проект мы обязательно доделываем его до конца и с нужным результатам если мы работаем с каким-то клиентам то мы делаем так чтобы клиенты получил то что он хотел тогда когда он хотел из тем качествам за который нам не просто будет стенда мы будем гордиться стремясь быть лучшими в своем деле мы постоянно осваиваем новые технологии и инструменты развиваем методологию своей деятельности и совершенствуем собственные акселераторы разработки для того чтобы обеспечить максимально качественный результат для заказчика сегодня мы старались делать то что мы не делали вчера если мы задумываем что-то на завтра то обязательно так как мы не делали и лет как бы по-новому мы строим команду или используем новые технологии или используем какие-то новые подходы но обязательно делать следующий шаг мы делаем его акта другому как-то интереснее как то лучше география наших проектов охватывает более 18 стран европы и азии и африки обладая глубокой технологическая экспертизу и знанием бизнес-процессов мы реализуем проекты для крупнейших финансовых организаций в партнерстве с ведущими вендорами эти решений мы работаем в очень высокотехнологичной сфере области информационных технологий преимущественно для финансовых институтов и сегодня компетентность выходит на первый план банки и компании укрупняются там работают очень высоко профессиональные люди кого же они выбирают в качестве партнеров для своих айти проектов они что эти организации в которых с их точки зрения есть необходимая экспертиза которые могут дополнить знания внутренней команда заказчика главное в neoflex это люди их знания и скорость мысли в отношениях с клиентами доверия мы знаем что такое ответственность подкрепляем каждое слово действиям и результатом об этом говорят сотни успешных проектов для крупнейших российских и иностранных банков и компаний лидеров своих отрасли павел привет я отринет я бывший до краха вы сейчас ведущий подкаста мы обреченным при этом знакомиться лавина чем ты занимаешься я архитектор в решении работы в московском офисе компании redhead последние года 4 наверное я делаю всякие штуки вокруг devops а вокруг выбираете сами красивой архитектурой все опять утечь да я прочитал что ты у вас компании популяризатора микро сервисов это маркетинговый ход да смысле но это видение нашего маркетинга я я более скромно отношусь как раз они в принципе да ну и что микро сервиса так действительно хороши как они все говорят последнее время потому что я частенько начинаю слушать критику критика была есть и будет это неизбежно в моем понимании это это неизбежно ну на ближайшие какой-то обозримую перспективу горизонт событий все равно все там будем часто бывает что действительно замечательная технология но технология подразумевает присутствие какой-то культуры и каких навыков вокруг этих технологии часто не хватает ну а какие то проблемы именно влил бы тут понимаешь что то как бы кто я такой чтобы критиковать с одной стороны с другой стороны в неформального общения часто вижу часто понимаю то что допустим вот ситуация с abs с командой сопровождении каких-то там технологических платформ часто бывает то что с административной точки зрения руководства не готовы инвестировать в эту команду люди несколько оторваны от вот общего какого-то глобального цикла им через забор передают задачи и говорят справляются как хотите с ними не ведутся какие-то диалоги о прекрасно получается на выходе то что у нас такая борьба за псевдо стабильность мы боремся за то чтобы просто продолжала гореть лампочка на самом деле мы сидим своем отсеке славы понимаем что вообще происходит и что делать что делать есть такая идея то что давайте попробуем переделать психологию методологию работа нашего abs команда в сторону и сэргэ чуть-чуть про наверно терминологии зачем это вообще нужно сергей сырья это сайт ривай ability инжиниринг я очень плохо солдаты фразы дальше это будет сильно аббревиатура а зарыдает стороне и по сути это такая специальная редакция на самом деле devops практик потому что делится devops абсолютно те же фундаментальные принципы концепции главная разница то что мы как про навеки пытаемся выстроить более отказываю устойчивую структуру с одной стороны с другой стороны мы принимаем перспективу наших конечных потребителей и это безумно логично моем понимании то есть мы мы воспринимаем любую операцию проблему как софт новую проблему то есть с перспективы того же пользователя абсолютно все равно каком уровне у вас что-то сломалось нас просто не доступен сервис и и спросите у нашего бизнеса на самом деле приблизительно то же самое поэтому все проблемы с табурета софтовые проблемы что проект порождает сдвиг в сознании abs команда садиться за один стол вместе с продуктовыми и разговаривать с ним на равных про и фактически получается что у нас разработчики становится функциональными заказчиками мышка пришить я не очень прямо зачем этот отличается просто культуры devops потому что dls они вместе работы для справедливо да здесь мы можем устроить глобальный холивар на тему разночтений именно терминология предлагает виде не делать то есть ситуация такая то что по факту да действительно devops описывает все все все на самом деле что подразумевается его сырые по сути на но по факту у нас не происходит вот этого сдвига но все равно есть некая изоляция команды нету понимания кто за что отвечает если мы идем в сторону и среде и разделяем вот фундаментальный парадигму скажем так и сырья когда у нас все у нас ведь одна большая софтовой проблема когда у нас не будет разночтение кто за что отвечает ну окей например я понял что у меня в команде если то проблема я такой говорю давайте строить о сергее как это давайте давайте нам нужен человек с определенным административным рычагом который в принципе сможет вернуть эту историю который сможет объяснить зачем это делать и что изменится это во первых во вторых наверное нужно следовать хорошую культурным практикам в в плане создания именно выпаса реками нити сари сари каких-то команд хотя на самом деле практике также применимо в принципе создание любых команд пятну большей части да это про культура про людей да я бы первым сказал то что провал это нормально ошибаться это это получило человеческие все мы люди и делаю не ваши тени в качестве ошибки в масштабах от ошибки а в том насколько мы поняли где мы ошиблись и что нужно делать чтобы эта ошибка не повторялось следующий момент наверное яблок предостерег гоняться за звездами в найме моменте на членов команды звезды я подразумеваю не просто одаренных и компетентных людей историю когда определенный набор софт скилов двигает человек в вот именно в какую-то такую звездность болезнь когда он порождает какую-то информацию борьбу за власть или как вариант и или на самом деле мы своими руками нанимая звезду или звезд загоняем себя в рамках наше предприятие в частный случай венгер но когда там 10 несколько человек действительно понимают как работает та или иная систему ну вот про звезд я как бы понимаю когда слышу говорят вот проблема звезд это очень сильно технические специалисты которые ни с кем не считаются с практиками справили объект просто очень так стараюсь деликатно эту тему как-то проговорить потому что это тоже холивар на тему то есть с одной стороны до звезды позволяет очень быстро начать но звезда с с перспективы стороннего наблюдателя будет для нас аномалии потому что у нас такой глобальную всплеск компетенция как и больная моли бы досрочно перспективой это катастрофа поэтому нужно отыскать какие-то такие середину все и но очевидны вот как как вывод из этого быть абсолютно готовы вкладываться в развитие своей команды гоняться не за идеалом гоняться за потенциалом смотреть нас of skill и причем софтовые не не только в моменте то чтобы очень хорошо умеет рассказывать какие смешные истории но то что он действительно понимает как и что он делает в плане бизнеса чтобы он чувствовал бизнес на самом деле все звучит безумно прагматично но акцент живу в реальной жизни этого очень не хватает я думаю если об этом говорит и может быть что-то изменится вопросы доверия вот например частности то есть очевидно то что команда способна сделать гораздо больше чем каждый из нас в отдельности но без без выстраивания доверия внутри команды без пропагандировали вот так такого рода культурных практик но мало что получается на самом деле мало того должно быть доверие со стороны руководства потому что без доверия люди теряют способность принятие самостоятельных каких-то решений и мы его получаем как тут командами не очень сообразительных роботов что тоже нехорошо вроде наняли людей мы долго беседовали мы выдворили с их навыками но с другой стороны постоянное убьем их по рукам и не даем принимать ему стать 5 на решение лайки должна в моем понимании водичка должна быть такая точка на теле специалист на берешь на себя ответственность и делаешь эксперимент понимаешь получилось не получилось но объясняешь сопутствующие риски какие-то чем мы можем поплатится за это мы так или иначе у тебя есть свобода самостоятельно принимать решение но это 3 будет очевидно мире мне кажется здесь немного по-другому эту проблему чаще слышу о том что доверие как раз очень мало при найме а уже после найма бросают как буду учить плавать сам обычно впечатление складывается прямо моменте найма на моменте первом собеседовании когда все же к строгие и спрашивают не всегда адекватные вещи и человек выходит на работу и продолжать жить в такой же парадигме то есть он боится как высунуть голову бы боится проявить инициативу и дважды на самом деле повторишь да звучит банально бы мои колени действительно важно вот наверно еще бы хотел рассказать про момент то что это вот классика open source комьюнити быть не согласны мы следовать курсу это на самом деле то же вытекает из смелости из доверия из-за такой умеренной борьбы системы здесь как-то противоречиво звучит вот здесь мысль заключается в том то что кей для того чтобы развиваться нам нужно экспериментировать для того чтобы для того чтобы экспериментировать нам нужно какое-то направление для этих экспериментов потому что мы очевидно не может имитировать во всех направлениях сразу быть несогласным это нормально и ничего ужасного нету но идея заключается в том то что раз мы приняли какое-то направление мы должны им исследовать до того момента когда мы поймем то что либо шаги в этом направлении либо направлении целиком ошибочно тогда мы фактически в реальном времени меняем вот это вот нашу направленность экспериментов ну в общем другими словами да мы должны избегать аналитический паралич иначе мы будем вечно натыкаться на одни и те же грабли до бесконечности причем такие серьезные глобальные грабли которые нам не позволяют действительно развиваться не просто какие-то мелкие штучки что-то там подхватили нас не получилось а именно такие концептуальные большие вещи но и как твои успехи вот в внедрение от культуры а это неизбежно происходит потому что так или иначе как вот с чего мы начали то что есть запроса и со стороны бизнеса стороны разработчиков стороны безопасности откуда угодно есть запросы на имплементацию вот каких-то практических вещей с культурой заре так или иначе это нужно делать просто если это делать более и не осмысленный если понимать то что рано или поздно мы туда придем the data наверно жизни наши станет немножко попроще но какие-то проблемы сейчас основные на твоём пути моем пути мусор и проблемы лак в понимании наверное бизнес и руководящего состава в сознании проблематике то есть опять же вот это вот порочная практика то что пока пока у нас каптерке горит свет это буквально у равно то что у нас все в порядке хотя на самом деле мы уже серьезно познали у нас уже есть большие какие-то комплексы проблему то есть и чувство что сопротивление идет не от с персонала от обычных разработчиков о псов и прочего а именно руководство да но это не то что сопротивление это отсутствие такого осознанного понимания что происходит того что очевидно из-за своей роли людям тяжело вникнуть во все нюансы и пока не случится что-то из их вот показатели которые близки очевидно ничего не случится и вот с чего я тоже начинал по поводу того то что в реальной жизни чудес не бывает для того чтобы случились изменения нужен человек с властью чтобы двигать эти изменения вот нужно найти холодное когда кто нас услышит о нас поймёт и о том подними тогда знаю я желаю тебе успехов чтобы это красиво большим лак непонимание исчезал и почти все получалось спасибо за рассказ спасибо что же друзья приветствую вас в этом зале я вижу что у нас квалифицированная аудитория на хайло де потому что доклад предстоит не самый простой пришлось чуть поменьше народу люди знают поймут они докладывали не пойму доклад вы поймете все хорошо надеюсь за то время которое есть у докладчик он сумеет вам объяснить что за не такое сделали с базами данных почему миграциям скачем не понравилось они сделали какую совершенную магию на первый взгляд но мы узнаем подробности встречайте пожалуйста аплодисментами фрол крючков авито всем привет как сказали меня зовут foo' крючков я темницу компании авито был начал как 2015 году начал как разработчик несколько то провел команды core services который занимался разработкой сервисов для продуктовых команд теперь нахожусь департаменте транснефти где виду команду авито паспорт когда я присоединился к вид а у нас было порядка двухсот человек сегодня это более 600 людей в техи тысячи серверов и сотни micro series of ну давайте перейдем теме доклада который звучит как meta data management system а план доклада будет следующий перед тем как я как мы перейдем в технические детали я расскажу о понятиями дотан их и как это понятие понимаем мы какую роль оно играет для нашего бизнеса а также затянем детали чем на не понравилась наша старая архитектура также перейдем в технические детали новые архитектуры рассмотрим плюсы минусы и в конце подведем итоги о том стоило ли это делать или нет итак что такое метаданные согласно википедии то метаданные то данные о данных но что это такие заданные в реальной жизни это могут быть весьма знакомый вам поля заполнения форм которые описывают а данные которые в этих полях хранятся вот например на слайде вы можете видеть форму подачи объявления которое состоит из четырех атрибутов то есть это заголовок категория цена описание объявления согласно википедия такой тип метаданных называется де скрипте в метаданные как правило он описывает общие данные у единицы метаданных и позволяет уникально дефицит собственно сами данные давайте я расскажу про еще один тип метаданных который называется строка черным и за данные о которых я узнал когда готовых доклад собственно в сравнении с descriptive это данными это тип хранить себе описание связи между данными например это может выглядеть следующим образом на слайде вы видите как два различных сценария один это подачи объявления а второй это поиск объявления как правило метаданные в обоих сценариях не меняются то есть мы все и также работаем с полями марки моделей марка модели цена модели автомобиля но как правило зависимости от сценарий порядок заполнения форм это как и из каких значить из каких списков выбирает пользователей иерархия этих списков отвечает вот это тип метаданных но как говорится то есть то что я сейчас рассказал это давно известный темой как правило существует достаточно большое количество фреймворков и библиотек написан на различных языках которые позволяют делать и автоматизирует все эти процессы из таких примеров как вам всем хорошо знакомая например jira которая позволяет хорошо описывать метаданных процессы описания метаданных более задач также вы можете добавлять свои собственные поля как-то управлять процессом разработки второй такой очевидный пример это система для управления контентом например wordpress в котором вы можете создавать контент категории теги как-то создавать иерархию из этого которое описывает собственно контент для сайтов но что касается сайта в классе файлов или как по-русски звучит это сайт объявлений поэтому для нас то есть для сайтов объявлений работа с метаданными это один из самых критичных элементов о котором мы даже не догадывались сперва как вы видите на слайде от метаданных зависит практически все компоненты сайта то есть от форм подачи и поиска до работы с ценовыми политиками как мы делаем рекомендательные системы как мы моделируем объявление как у нас работает seo то есть по факту метаданные участвуют во всех этих процессах и чем быстрее компания умеет адаптироваться под изменяющийся мир описывая его в метаданных тем более эффективно комп компания является для того чтобы быстро адаптироваться как правило необходимо вносить быстро в нее изменения но как правило это достаточно сложный этап которые не очевидны сперва то есть как правило внесения изменения формы подачи или форма поиска это это всего лишь один из шагов который необходимо сделать также нужно подумать о том как новый тип атрибутов будет варьироваться как он будет учитываться в рекомендательных системах или как будет работать в ценовой политике также нужно понять как новый тип индексировать и затем как его использовать в построении your love собственно все эти этапы занимают просто колоссальное количество времени если подумать о том внедрение его в целом на сайт они просто на форму собственно какие у нас были ограничения как правило раньше для того чтобы нам пройти путь объявления добавления изменений в метаданных нам требовалось пройти там требовать недели до нескольких месяцев то есть как вы понимаете это было достаточно неэффективно так как добавление просто какого-то нового атрибута занимала привлекало к вниманию достаточно большого количества разработчиков то есть это требовался front and back and требовались депо для того чтобы носить изменению схемы данных но ситуацию усугубляло то что у компании достаточно много направлений такие как авто недвижка услуги и как правило каждый из этих вертикальных стремится как можно более точно под подстроиться под пользовательские нужны и как правило со временем те как атрибуты которые необходимо было добавлять они были все сложнее с точки зрения их поведения таких точек с точки зрения катить количественного прибавлений то есть все больше хотелось проводить экспериментов различных направлениях на фоне этой ситуации как правило перед нами стали формироваться требования к системе управления метаданными и таким образом у нас появилась концепт инфо модель 20 то есть основные требования которые мы хотели видеть то есть это уменьшить время реализации сценарий по изменению атрибутов под изменением атрибутов имеется виду не только добавления на поле формочки но как это поле будет проиндексирована промо дозированно как она будет отображаться на различных платформах также мы хотели видеть иметь такое свойство что мы хотели для каждой платформы иметь свое собственное представление формы подачи или форм отображения атрибутов также один из критических и необходимых условий заключался в том что мы хотели проводить достаточно много обед с тоф один из основных сценариев то есть мы хотели посмотреть как будет улучшит увеличивается конверсия если мы добавим на форму вот этот атрибут а этот уберем нужно понимать что добавление атрибута приводит тому что нужно переделывать систему индексации объявлений они также для того так как мобильной версии с мобильной версии обновляются не так часто например у нас есть версии которыми должны поддерживать два года то мы хотели видеть versio не рование инфо модели так чтобы старой версии все тоже продолжали жить им имена могли вносить них какие-то изменения и сделать так чтобы это было управляема на момент когда мы пришли к этим требованиям наша архитектура было как у всех нормальных людей то есть все объявления хранились в паз грязь и а так как объявлений было достаточно большое количество это порядка 1 миллиарда то конечно это базы данных с объявлением была так шокирована по супер категориям и получается что в этих табличках хранились наше объявление как вы понимаете колонки этих объявлений описывали свойства объявления и получается таким образом что колонки сортированных таблицы это и есть собственно метаданные которая приходится менять здесь как бы все очевидно такую так все делают но так как помимо этого помимо колонок который описывает свойства объявления у нас были еще таблицы которые описывали свойство этих колоннах например нужно ли этот атрибут должен ли он быть обязательно при подаче или например нужно его отображать при редактировании объявления также на связях также нас была еще одна таблица которое описывало связи от их атрибутов в одной таблице здесь я уже говорю как мы знаем о структурных метаданных попросту например связь параметры его родители то есть наша прежняя модель была устроена таким образом что параметры например модель автомобиля мог иметь только одного родителя например модель модель ford имела только марку автомобиля и зайти там фокусами марк автомобилей там ford а это делать для того чтобы мы могли выводить правильные списке то есть если вы выбрали там ford необходимо было вывести там только модели этой марки для того чтобы такая схема работала быстро когда когда у нас есть еще одни таблица для описания метаданных то одним из этапов с при сборке сайта как это принято делаете мы брали брали эти таблицы описывающие свойства наших атрибутов и дам пили их с помощью кода генерации файлы таким образом мы могли таким образом мы могли использовать могли а траверсе деревья атрибутов вверх и вниз по не делать запросы во внешнюю базу данных то есть это позволял достаточно быстро производить валидацию объявления или отображать свойства объявления на карточке без дел и не дело никакие внешние запросы давайте рассмотрим как правило то есть это достаточно классическая схема когда вас есть колонки и есть табличка описывающие эти колонки и все это дампе cvv код который используется уже в ran to me давайте теперь рассмотрим основные недостатки которыми данная артура обладает 1 и это фундаментальный недостаток заключается в том что если вы хотите сделать изменения в метаданных то как правило вам приходится как вправо вам приходится перри выкатывать все ваше приложение то есть как правило вам приходится перехватывать все ваше приложение как вы понимаете таблицей с большим рпс м с большим объемом то есть не очень хочется сделать перекат часто делать изменение в таких таблиц и как правило это требует надзора инженеров которые смотрят чтобы все было сделано правильно во вторых такой подход требует перри выходку всего приложения так как необходимо пересборка словарей для того чтобы code mu мог работать с новыми данными основное ограничение нашей же реализации еще заключалась в том что все параметры у нас были реализованы все были уникальные все значения индикаторов были уникальные то есть например как вы видите на слайде сейчас два списка вы видите серию абсолютно одинаковых значений но для нас это были абсолютно разные диффе катары это делается для того чтобы имея всего лишь один индификатор значения понять восстановить структуру заполненного дерево вверх по поверх по зависимостям такая архитектура ограничено нас том что нам приходилось за дело достаточно большое количество дубликатов также на этапе сборка проекта когда мы делаем дам схемы базы данных в код одном изобретения заключается в том что калина количество таких метаданных на момент когда мы начали заниматься перестройка нашей архитектуры у нас было порядка 6000 значений 6000 значение на все категории но от нас требует так чтобы в как минимум в одной категории был 1 миллиона той до 1 миллиона таким образом такая схема перестала работать потому что это приводило к к падению приложения потом просто потому что траверс и восстановлению валидации форма подачи приводил тому что приложение просто падал то что жрала всю память и и таким образом к архитектура которая могла бы решить наши проблемы была следующая то есть одно из логические решение нашей цепи on my проблем и заключалась в том чтобы мы могли бы повысить уровень абстракции который заключался в том что колонки таблиц который описывает свойства атрибутов мы превращаем строчки таким образом мы добавляем динамику по изменению наших метаданных но за это приходится платить тем что вместо того чтобы базы дано выполняла за нас функцию управления и контроля изменение схемы теперь это приходится делать сами самим также такой подход к праву называется entity вылью эти театре бьют в или у модели и так и помимо то тех требований которые налога у нас бизнес к нам добавили еще следующие задачи которые необходимо сделать точном во первых необходимо обеспечить операторов которые делают работу с метаданными самим а во вторых нам необходимо обеспечить консистентной с этих меток это метрах данных давайте непосредственно придем к архитектуре к новой который мы пришли как вы видите на компонентные схемы мы выделяем три слоя то есть у нас есть backend это непосредственно сервис который хранит себе все метаданные и сопутствующие сервисы которые его окружают следующий слой мы его называем frontend слой это не фонтан в том смысле что это мобильное приложение или юань а это именно а бэкон сервисы которые предоставляют эффективный доступ к metadata сервису и последний слой сервисов это наши клиенты которые которые используют метаданные в общем ски в общем виде схема прямолинейной с помощью эти ели мы загружаем метаданные от наших партнеров и сервис мета-данных или заводим их ручками с помощью а затем этими данные которые у нас находится в яви модели выгружается в статические файлы которые затем интерпретируются слоем из frontend слоем east front end сервисов и с которыми уже непосредственно работают наши клиенты давайте подробнее разберем каждый из этих слоев бэкон слой который отвечает непосредственно за эви достаточно достаточно сложно реализован и достаточно это достойно отдельного доклада как это все сделано но я раскрою основные моменты которые нам необходимы здесь как правило во первых он решает предоставляет нашим оператором пользователем во-первых делать изменения работы с метаданными то есть и вносить новые атрибуты изменять их редактировать также он позволяет нам заводить различные apts ты и так же заниматься верси они раване им но так как количество запросов к сайту и как следствие к метаданным достаточно большой то есть мы имеем порядка сорока пяти тысяч рпн это только на один из сервисов мета-данных то мы не можем просто так взять и направить всю нагрузку на сервис метаданных которые традиционно я супер нормализировать а я модель и тогда для того чтобы оптимизировать вот эту читающую нагрузку был придуман frontend слой как правило frontend слой заключается в том что эти сервисы берут статические файлы которые представляют такое статическое описание мини-программу загружают себе в память делают интерпретацию этих файлов и на основе вот этих меню скомпилированных программ которые находится во front-end слой мы интерпретируем их на основе пользовательских данных давайте теперь перейдем к модели данных которая находится вот в этих статических файлов а как говорилось исходя из наших требований помимо того что мы должны уметь гранулярный классифицирует задавать и контролировать как и наши метаданные выглядит в разрезе разных платформ версии и а bt став то мы пришли к такой концепции как выглядит на слайде то есть это такой понять как layout layout состоит из основных трех компонентов то есть это rolls правило в этом компоненте состоит он состоит из бизнес-правил которые мы можем в юань накрутить сказать например что пожалуйста отобразить более метро если был выбран город москва или там санкт-петербург и вот вот этот первый компонент отвечает за вот эту динамику следующий компонент это relation решены как правило описывают как мы говорили ранее это структурно metadata и описательные метаданные то есть как правило это иерархия атрибутов и и их значение и следующий компонент это формы о них чуть позже то есть примером лейаута может быть форма подачи или поиска или например сниппет на карточке объявлениях то есть по факту это все разные layout и допустим мы можем отобразить форму подачи на десктопе отличную от того как мы делаем это на мобильных устройствах и это будет достаточно корректно также от понятные привычного понимания лейаута как визуальные формы и о том также может выступать например шаблон для формирования орла для того чтобы делать canonical url и для того чтобы оптимизировать seo или например это может быть конфиг для сфинкса для того чтобы индексировать данные как и говорил правило это это бизнес-правил валидации и визуализации то есть это такой джейсон like dsl в котором мы описываем условия при которых те или иные поля меняют свои свойства то есть например отображают какое-то поле делают его обязательно в определенных условиях или делает его невидимым relation а как я говорил то есть это иерархия атрибутов в зависимости от какой сейчас стоит и находится пользователь заполнении формы такие из от списке он выводит и последнее свойство это компонент италия вот это форма здесь мы делаем именно манифест того как эту форму необходимо рендерить и когда мы говорим о правилах которые меняют свой статус как правило эти правила оперируют над полями форма для того как мы можем какие-то поля меня например если допустим выбрана более новостройки пожалуйста сделай сделай поле там когда как снять сдачи например там неактивном какие такие визуальные компоненты то есть по факту получается что layout и позволяют нам гуру 0 арно контролирует поведение визуализацию и атрибуты из всех зависимости то есть гру 0 арно стиль работы до тех пор что мы можем сделать разные формы подачи или отображения разными для android ios там десктопа и при этом мы можем их сделать разные даже среди версии их разных андроидов и при этом это будет все корректно индексироваться модерироваться то есть все эти атрибуты будут правильно распространены в вдоль по всей системе давайте теперь обсудим как мы сделали versio не рование достается достаточно сложные компоненты по факту там реализован такая сагид система всей базы метаданных по факту мы можем сказать так что вот у нас есть сейчас какой-то state всех словарей всех значений но мы можем сделать ветку в которой что-то поменять и отдельно и и зарелизить что касается релиза что такое что это за понятие такое в юо и сервиса метаданных у нас есть кнопка которая отвечает за релизе текущие текущей версии там метаданных при нажатии на их происходит достаточно большое количество разных чеков мы убеждаемся что там нет никаких циклических зависимостей что все а б тесты правильно себя ведут и ник перекрывают друг друга но одним из фундаментальных вещей которые происходят в результате после того как прошел успешно вся вот эта нормализировать структура в электронной базе данных превращается в набор play out of статических файлов которые уже раздаются с помощью engine x а вот этим сервисом из слоя frontend при этом если мы зарелизили какую-то версию метаданных то мы уже никаким образом не можем сделать никакие изменения в нее потому что потому что это уже статика в которую мы не вносим ники изменений если мы хотим что-то исправить то по факту нам всего лишь приходится релизе новую версию tokyo дистрибьюция таким образом файлов позволяет нам достаточно легко масштабировать систему и это обходится достаточно дешево потому что мы можем бесконечно в прошлое вернуться и посмотреть какие у нас были форма подачи или понять какие там были ошибки совершены что касается бы тестирования то это реализовано абсолютно таким же образом за исключением того что у нас есть основная мастер ветка в базе данных и метаданных и есть параллельной ветке как это как принято в гите то есть мы можем какой-то ветки поменять описание поля с она б и таким образом параллельно крутить какой-то apts релиз происходит таким же образом сейчас мы говорили о том как происходит релиз инфо деле то есть из традиционного представления мы их складываем на статические к стати к и файлами а как сорта происходит дистрибьюция новые версии она происходит немного не привычным образом потому что мы по дефолту не отдаем нашим клиентам все но abs и только что заряженную версию мы делаем наоборот пусть наши клиенты сами знают какую версию метр метаданных им сейчас необходимо получить такой подход нам позволяет достаточно гибко контролирует то как мы распространяем новую версию и таким образом случайно не сломать каких-то клиентов которые не поддерживают новые фичи системы этот процесс мы называем роутинг клиент имеет road как показано сайте работы это по факту это такая строка которая состоит из трех компонентов это название раута версии версия эта инфа модели и категория то есть таким образом клиент знает какую версию какой и в какой части кода он сейчас находится если он хочет всегда автоматически получать самую свежую версию инфо модели то как правило он может просто указать alias вместо версии master и таким образом мы доставим до неё самую последнюю версию метаданных как это выглядит в действии то есть мы начинаем с пустого состояния формы то есть запрос сервис layout это один из сервисов из frontend слоя состоять из нескольких компонентов то есть как я говорила с началом отправляем road и описываем какую какой layout мы хотим получить какой категории и описываемые в версию данном случае мы используем мастер а также мы передаем туда текущее состояние нашей формы в нашем случае то есть оно пустое после этого сервис layout отдает ближайшего ли дна и состоянии формы которые можно рендерить то есть это от брат apisto такой текст текст и представления форма отдается на front-end и она рендерится помимо того что там описаны все поля там также описаны все значения которые из которых можно выбирать какие активные какие неактивные после того как пользователь напирали например меняет стоит формы там отдает например выбирать новостройки то мы делаем запрос в сервисный out а уже с выбранными значениями и взамен сервис слою то дает нам следующие валидно и состоянии формы если вы передали какое-то совершенно не валидно и состоянии the service at low допустим выбрали какой-то параметр которого сейчас не существует the service лайалл как правило подгонит следующий стоит до ближайшего корректного такое поведение такое поведение помогает нам в использовании такой механики в больших в разных вещах то есть как минимум мы можем вы лидировать все данные то есть у нас есть какой то какая то стоит формы которая возможно некорректно или которая была сгенерирована допустим 1 год назад но тем не менее если мы ее прогоним на основе отдайте все ли слоя вот на последнюю на сегодняшний день то он возьмет в последние валидно и состоянии согласно текущей инфо модели также например для того чтобы отобрать от тренда рид сниппеты объявление а то это свойство объявлений то есть мы идем базу данных объявления например мы объявления подали там два года назад и вот мы берем все свойства объявления в нормальной форме отдаем этому сервису и он нам может вернуть текущие корректно и состоянии там полей например если добавилось какое-то новое поле которую не существовало на момент создания объявления то он его заполнить заполнит их дефолтным значением давайте теперь разберемся собственно как устроен сервис layout который делает все эти преобразования при реализации этого сервиса были такие различные сложности то есть как я говорил ранее а сайт должен был работать быстро и количество запросов было большим то есть мы стремились от 10 до 50 миллисекунд на 99 просителей для того чтобы рассчитывать вот эти все state и помимо этого сервис как я говорил должен работать с целой аутами то есть и layout и такая единица описание метаданных на тот момент то есть нужно понимать что на тот момент у нас были десятки категорий десятки платформ под платформами не только android и айос но также это внутренний сервисы там и сфинкс например или модерация и вот это количество вариантов которые необходимо хранить в памяти она там исчислялось тысячами а один из одна из самых тяжелых категорий например это авто она могла занимать до 500 мегабайт то есть вот эта вся иерархия день иерархия занимало достаточно много места для того чтобы сервис как право был быстрым да то есть мы делали различные mvp для того чтобы особенно дети все данные хранить для того чтобы можно было быстро рассчитывать состоянии мы пробовали разные решения то есть на основе пас gresso тарантула мы даже потрогали графу и базу на фиджи загнали туда все у этого дерева иерархии как правило все решения достаточно были они они вписывались наши требования по времени но как правило они занимали все также 500 мегаватт нас ни каким образом не удалось сделать так чтобы один layout занимал там меньше 500 мегабайт собственно это достаточно было как бы такое сложное решение поэтому мы пришли к решению а где реализовали свой рид онли сервис в которые хранились с кэмпи скомпилированные layout и и собственно в нем же рисовали все в логику по интерпретации вот этих layout of так как сервис сервису необходим нет необходимости делать никаких внешних запросов то по большому счету вся вот эта логика про интерпретации достаточно там легко описывалось и покрывалась uni тестами что делал это сервис достаточно стабильным и достаточно легким к масштабированию потому что у нас есть только рид онли дата который мы можем бесконечно масштабировать под любые нагрузки опомниться после цепочка загрузки layout of память сервиса там выглядело следующим образом то есть клиент приходил с определенным рау там если сервис видел что этот layout уже скомпилированные находится в памяти то стоит формы отдавался на интерпретацию интерпретация возвращала следующий в 1 из 3 и отдавалась клиенту и если же в памяти ничего не находилось то по факту мы их нашли на engine.exe загружали оттудова статические файлы в которых было описано состояние программы компилировали ее и на основе этого возвращали следующую форму но как я говорил то есть над на 2015 год количество layout of которые конкретно нам необходимо было хранить заключалась было до полутора тысяч которые не было было необходимо хранить единовременно навес в 500 мегабайт как бы приводил тому что это там достаточно такие большие цифры там 500 гигабайт необходимо было хранить в памяти одного приложения как вы понимаете хранить один из такого сервиса на достаточно небезопасно поэтому для того чтобы минимизировать нагрузку на сеть нам там как минимум 10 версии его хранить не было необходимо хранить поэтому процесс оптимизации памяти был достаточно критично для нас и как и говорил ранее то есть один основных как и говорил ранее один из ценных компонентов бизнес-правила это это relation который занимал больше всего мегабайт поэтому мы и стали думать как собственно пути мизерд эту структуру например вы мы взяли дерево представляющая зависимости марки acura и такой недель вы можете достаточно весьма распространенная форма подачи где она имеет много узлов с одним наследником для того чтобы как то это реализовать в памяти и поместить то есть мы сначала попробуй реализовать трой на основе мафах в горном приложение но силу того что overhead нeкomopыe с одним значением был слишком высок а это не увенчалась успехом поэтому мы пошли следующим путём когда когда имели одну большую мапу в которой хранили ключами которое являлось путь до какого-то параметра значения его это старт стоп индекс для того чтобы понять какие значения для этого узла выбирать 50 мегабайт то есть таким образом мы смогли сбить с 500 мегабайт держать это все до 50 мегабайт но это все еще достаточно большая цифра и основная следующая точка для оптимизация была в том что вот эти relation на которые занимали больше всего места они как правило менялись а реже всего поэтому а мы организовали в сервисе такую структуру данных которая которая перри использовала кусочки под деревьев на основе для других layout of то есть например если какой-то layout версии 1 там касас версия 1 на версию 2 сама структура не поменялось то при компиляции лей аутом и при использовали вот это под дерево таким образом нам мы смогли практически минимизировать вот эти мультипликаторов по количеству абэ тестов и версии практически к нулю ну как я говорил чтобы как бы как бы ты память я презирал не оптимизирована ограничено и для того чтобы как-то понять собственно какую стратегию по вытеснению их выбрать мы пришли как бы к следующим учитывать следующие моменты разные layout и то есть layout для подачи форм используется на несколько порядков реже чем l'oreal для отображения сниппетов объявлений и и поэтому например i love you нам не подходил потому что вот эти менее важны из пике по отображению сниппетов вымывали бы вот эту более важную успеху по отображению по отображению подачи также i love you нам также не подходил потому что могли приходить кроны которая достаточно сильной пикообразное нагрузки могли вымывать все необходимые спеке но как бы для нас в данном случае подошел pattern of duty free placement кэш который стратегии вытеснение которого опирается как на частоту такие на так и на исторические использования данного ключа то есть поэтому это привело к тому что наши спеке даже которые имеют маленький трафик но при этом важные для бизнеса как например подача достаточно продолжали находиться в памяти и наверное последняя оптимизация про которая хотел бы рассказать это то как мы выкатываем и прогреваем кэш то есть перри выкатка такого сервиса может повлиять на то как работает монетизация или подача сайта и критически важно чтобы как бы на прогреве кэша мы не мы не давали большой рейтинг и поэтому чтобы обойти эти проблемы в процессе эксплуатации сервиса он дан пел состоянии каша во внешнее сторож что все спеке которые используются на данный момент и когда новая версия сервиса выкатывается он шел в этот внешний сторож смотрел а вот эти layout и на данный момент используется он их погружал и только после этого мы не давали на него нагрузку таким образом мы обошли проблему перри выкатки сервисы для того чтобы и никак не повлиять на различные части сайта какие плюсы какие минусы во первых такой подход нам позволил сделать наши функциональные требования то есть мы смогли как минимум без или вы к так достаточно быстро изменять мета-данные то есть изменять форму подачи формы поиска отображения атрибутов при этом это автоматически просачивалась в то как индексируется объявление в модерацию в анти фрод и прочие компоненты сайта также благодаря редон не хранилищем наших фонтан сервисах мы могу можем систему масштабировать горизонтальной практически бесконечно до тех пор пока как бы не съедим у ресурса кластер а также система получилась на удивительно хорошо для расширения то есть на такой же подходом по статистическим файлам и описанием правил были реализованы сервисы как по руль и джоном которые делают классификацию объявлений и урал builder который используется для того чтобы создавать поисковой вектор но какие собственно минусы такого подхода как вы понимаете основной минус основные минусы заключать в том что приложение получилось достаточно сильно а прожорлива к сети и здесь мы боремся с этим тем что мы используем бинарный формат передачи данных с нашими клиентами и также достаточно большое потребление сети si peu конечно получено архитектура наверное бесконечное сложная с тем которая у нас была но для ситуации когда у вас там большой классе fight с большим количеством различных направлений в котором вы хотите делать динамический не при этом сделать так чтобы каждая команда могла автономно это делает не привлекая вниманию всех инженеры всей компании то наверное это стоит реализовывать на таких масштабах все спасибо за внимание фрол спасибо тебе огромное за этот доклад мы тебе очень благодарны за него и к тебе вот бежит наша систем чтобы вручить персональную рамочку с благодарностью и худи в другой символикой но тоже очень почётный это highload спасибо спасибо ребята готовьте ваши вопросы поднимайте руки у кого не сформировались а есть вот здесь на втором ряду вопрос супер еще поднимайте руки заранее и в онлайне нажимаете кнопочку выйти в эфир для того чтобы задать вопрос привет спасибо за доклад а смотри ты рассказывал в начале что вас время выкатки изменения было там от недели донецких месяцев вот но как я понял сейчас как я понял сейчас получается выкатка изменений она все равно требует изменений в клиенте если клиент не подписан на алиас мастера и как долго сейчас это занимает я понимаю что телодвижение меньше но по факту наверняка есть клиенты которые сегодня запилены никита версии и если нужно закрыть и за когда последнего то как долго занимает такой змеи полностью по моему достаточно хороший вопрос по моему нас даже есть где-то на хабре статья как за одну или за полторы минуты там гибкой показано как добавление атрибута можно дотащить до мобильного устройства как она появится на форуме сейчас наверно это исключительный случай для демонстрации по факту сейчас нам не требуется никаких перри вы к так то есть вот этот конфиг с версиями которые запрашивают клиенты то есть в каких-то случаях они захардкожены но в каких-то случаях вот эти конфиге до наших клиентов также раздаются динамический например клиент попал версию об и тестировать но он появляется там какой-то в обед с и с этим обед с ним приходит версия какую-какую версии ты хочешь инфо модель получить по факту она больше формальная нежели необходимое техническое программирование здесь у меня получилось слева от тебя вот там вот есть глубине зала да нет вопроса ваш шанс задать вопрос ребята скажи пожалуйста это же огромное количество усилий все это сделать до то есть по факту этим занималась на практически вся компания потому что для того чтобы это протащить то есть мы привыкли то что здесь две колонки то есть там пошел дбн жене рыскают колонку добавил потом добавили объявления на подачу но при этом это сломало подачу на на андроиде например и по факту для того чтобы фундаментально решить эту проблему и так чтобы вот этих добавлений атрибутов работали корректно это пришлось работать практически всему авито для того чтобы затащить вот эту новую версию поэтому это такая очень дорогостоящая история которую то есть нужно дважды подумать нужно ли делать она ее хорошо у нас есть вопросы середину зала добрый день и спасибо большое за доклад было очень интересно один момент хочется прояснить понятно sb тестами когда у нас проходит абэ тест мы покупки или по другому параметру в принципе понимаем что пользователь видеть на своей стороне какая у него версия параметров формы и так далее но что касается весь versio нирования о котором вы говорили в своем докладе какая у вас глубина истории versio нирования то есть насколько старая у вас самая старая версия формы и судя потому как вы говорили о том как вы перестраивали конфигуратор как вы теперь понимаете на какой версии формы находится сейчас ваш пользователь у которого возможно какая-нибудь проблема с подачей или поиском спасибо спасибо большое спасибо за вопрос да то есть a bercy они ранее идет следующим образом то есть как я сказал дистрибьюция происходит таким образом что клиент сам запрашивают определенную версию метр метаданных и как правило он это он если какие-то происходит проблемы то это информация попадает в логе и мы знаем что вот этот там мобильное устройство конкретно запрашиваю вот такую версию и вот в такой версии у нас какие-то были проблемы что там это поле невозможно там выбрать например или там форма не валидно и в таком состоянии поэтому 10 весьма все прозрачные народы же позволяют как то быстрее диагностировать проблему то есть с вашей точки зрения оправдана хранить достаточно большую глубину версии нирования параметров для детектирования проблема дело в том что для нас это при их почти как бы бесплатно то есть у нас есть мы по факту старые все версии это не что то что находится там в реляционной базе данных и которые там приходится там каждый раз где-то рендерить каких-то юань то есть по факту очень древний версии мы храним просто статикой статикой на сервера которую раздаём джин иксом то есть там если это джейсон фани кидать зазимовать то есть они практически там для нас бесплатный поэтому хранить историю конечно важно но по факту не могу сказать что мы там возвращаемся в какие-то года да у нас есть там трехмесячный истории которые можно посмотреть и посмотреть предложить какие-то баги получилось получилось спасибо отлично фол я напоминаю что ты по дороге выбираешь лучший вопрос у нас есть вопрос из глубины зала и дальше будет на четвертом ряду рука фрол привет это я валера вопрос такой как бы вообще искали какие-то существующие решения в интернете и похоже может платная каком из да хороший вопрос то есть мы пытались посмотреть но на самом деле я не совсем представляю как можно какое-то внешнее решение интегрировать потому что по факту вроде методах как и сказал мне то данные то есть сайте объявлений это такая вещь которая связывает абсолютно все компоненты системы то есть мы говорим о микро сервисной архитектуры говорим о том что каждая команда должна быть автономно для того чтобы быть эффективным но атаки иначе мы все оперы в одной модели для того чтобы притащить какую-то внешнюю систему и и придется интегрировать во все во все во все во все то есть поиск в подачу в отображении в модерацию то есть и бы те решения которые мы находили то есть но они как бы не приспособлены были к хай-лоу то есть вот это вся возня вот этим статическими файлами вот этим слоем frontend сервисов то есть это исключительное решение вот под наши нужды для того чтобы очень с быстрой динамикой с большим объемах метаданных убер-заряд наш спрос но если даже это чисто под вас было подстроено но ведь классе fight of the в россии много дни вы одни не за это решение как-то унифицировать и и знаю продавать или вы или вы так вот endures но технически то есть это вот можно пойти взять как они там wordpress да там тоже есть форма то есть но это же его заново придется написать по факту под свои нужды то есть наверное написать система управления метаданными не так сложно то есть еве я думаю большинство из вас сами там реализовывали там делали какие-то ds цели которые там в конечном счете там интерпретировались вашим кодом то есть это колоссальная работа конечно но очень важную роль играет то как собственно на больших нагрузках вы можете с ней работать то есть и здесь нужно понимать здесь еще несколько измерений добавляется это историчность и и apts ты параллельно которая крутится то здесь такое несколько измерений которые их решения мы не видели у нас есть еще два вопроса вот до 1 и перед этим человеком сидит еще один желающим добрый день спасибо за доклад очень интересно один вопрос тоже по поводу versio нирования смотрите как у вас versio не руются сами значения то есть допустим было поле одного значения и значение изменили там схему валидации правила изменили следовать им нужно хранить другом формате каким образом вы это делаете то есть вы делать куда миграцию или вы создаете новое поле на основе старого или что подобное да хороший вопрос а как происходит миграция то есть как правило объявление подаются в какой-то версии инфо модели то есть вот сегодня пользователь пришел была версия 2 и это поле существовала и это был список как правило затем это там объявлением мы показали прошло несколько лет потом пользователь пришел но не несколько лет несколько месяцев пользователь пришел решил его реактивировать и мы увидели что сейчас это поле уже является там если бы раньше список то теперь это свободный вот например то здесь у нас бывает несколько сценариев иногда мы по действительно прогоняем миграцию и мы знаем как бы сообщить объявлений который нужно прогонять миграцию зная версию в которой она была подана либо же мы мы просим пользователя или заполнить ручками объявления это второй сценарий третий сценарий который у нас есть как и говорил вот сервис layout как и говорил он возвращает ближайшие корректно и состоянии формы то есть технически он может вернуть если раньше это был список то есть он может списочное значение подставить в свободный вот то есть он возвращаясь следующие корректно и состоянии форма и даже если имеется заказть эти значения какие-то то есть получаются то что у вас сервис слоя вот он сам по себе умеет как бабка с какой то да и ли у вас это отдельно описывается версиях то есть допустим в рамках версии 2 мы пишем как иммигрировать там поле x или y вот и так далее да мы хотели вот к такому описательном декларативным способ куда миграции но это было бы просто количество версий сумасшедшее количество изменений большое количество если бы мы заставляли ребят вот описывать еще миграции но это наверно было бы слишком больно поэтому вот сценарий когда мы пользуемся этим тебя способами ручками миграции либо пользователя заставляем либо кастом простых случаев уже в ран тайме мы эти вещи и fixim.ru чеками не заставляем писать как бы описание миграции полей либо же мы можем сделать следующим образом то есть добавить новое поле с дефолтным значением которые мы ожидаем это хороший вопрос когда мы говорим о к кости да вот кости значение было состояние одно осталось другое то есть например такой же подход используется для для того как есть поисковая выдача и поисковой выдаче есть поисковый какой-то вектор до набор каких-то значений параметров и пришел краулер запечатлил что вот эта версия что это вот это поисковая строка отвечает такому такой версии пришел краулер сохранил это при этом у нас поменялись значение такого параметра нет и вот такая же механика против all the позволяет нам пользователю кликнув шую щую на ссылку которая там месяц назад и которых поли уже не существует ближайшим образом отобразить поисковую выдачу максимально похожий к тому что имелось ввиду при этом и нет необходимости делать какие-то там редис с ключами там типа фильма пингом ссылок на новые на новые значения памятником спасибо супер и последний вопрос после этого ты выберешь лучший и можно будет еще продолжить дискуссию в кулуарах засада спасибо за доклад очень интересно ты много рассказал про изменения метаданных более о которой потом отображается в фронте в приложениях рассказал что вы можете очень быстро релизе неограниченное количество как вот эти изменения потом если вот какие то добавляйте новые метаданные поля вы выставляете другие системы потому что если у нас есть там систем аналитики либо еще что то ноги у нас эти это данные зашиты и как бы привязать релиз новой версии к обновлению информации в других системах как я говорил то есть этот процесс дистрибьюции то есть все наши сервисы допустим модерации да они знают какую версию они используют то есть мы их никак не выдам то есть если мы знаем что вот эти версии не критичные то есть то как правило эти авт то есть если ребята скажем так сделали такой хороший грейс пул если какая-то придет новая форма с новыми фичами то и ребята не бояться каких-то там ломающих изменит а они могут указать алису себя как мастер премодерация на основе такой набор метаданных для объявления говорит о том что он там допустим там какая-нибудь там бмв стоит 500 тысяч рублей при этом это там супер свежий год там не бита и все такое то есть скорее всего это какой то фродо и вот эти метаданные которые на основе которых они принимают решения они сами знают версию которая им сейчас необходимо использовать то есть по факту и либо это процессуально то есть они делают это 1 мин как бы там ручками либо они используют алия с мастером то есть я правильно понял к сервису вот хранения метаданных обращаются не только сервисы которые делают фронта и приложения а также и другие сервисы в которых зашит релиз этих наборы метадон ах да да по факту мы даем клиентам безопасной версии которые они могут использовать для работы по ним possible супер и какой же вопрос предпоследний вопрос был самый такой предпоследний вопрос пожалуйста вручить его там да да да да поаплодируем победитель у нас у маленького конкурса еще раз спасибо огромное друзья вы можете продолжить и пообщаться с фролом вот здесь сразу налево при выходе из зала а в онлайне подключаетесь зум тоже у вас есть ссылочка для того чтобы продолжить общение ждем вас здесь шесть часов дубль смывай горелов туда и его в туре вида санчес эра ведь муза словно с people feel канате твое чадо и к но так что connection под скромный фил да я авто дай мегафон mix dance collection штанга штанга пройти он модой вас instantly be complete вода или яиц мегафон мегафон определить имя каковой mouth and sam день малиновская корова c2 сустав с моим washed and damage ru идей л т а л т и и 20 млн грн пикантный мегафон спину гоночный клуб тет а тет а тет шанс fate of a и гигабайт список сайтов и весь твой день это был болты поймет когда соседи baby born and enhance . business solutions с матой даче шанс for upper колчан вы задавать юный царь давид мегафон осинами иногда еще на январь линзы people ой был вы дуба ну да но очень не и титул соберись от него почти на треть мегафон is driven год digital bout где не привет я артем я x редактор хабра и ведущий подкаста мы обречены рад познакомиться дашь приятно при at our team ну рассказывай чем занимаешься ты во всем по чуть-чуть вопрос в госбанке насколько это возможно но насколько я знаю если ты работаешь государства банки тебе немножко сложнее настраивать все и выбирать инструменты и соответствовать другим требованиям надо безусловно да если говорить про какой-нибудь например стартап конечно у нас очень большая разница но если говорить про какие-нибудь мировые гиганты где потом например гугла фейсбука мне кажется у них тоже не так легко и быстро взлетают какие-то активности просто не про это давным-давно узнали и раньше как бы нас могут это все протестировать проверить в них там есть на вышке какие-то лаборатории исследовательские команды рэнди отделы там не знаю может даже департамент который занимается у нас же это по сути ложится рядовых drops of которые так скажем на чистом энтузиазме предлагают улучшить там текущие современные процессы там теми инструментами которые востребованы сейчас в мире в чем для тебя самая большая трудность и разница по сравнению с тем что делал раньше до того пришел в государственный банк я пришел в банк там чуть меньше двух лет назад полтора два года назад вот пошёл к кнопке заниматься тем чтобы развивать с направления да и как-то привносить какие-то современные стандарты как раз таки в нашу компанию вот и получилось так что там у нас уже была небольшая команда там порядка 10 человек и мы активно разрослись сейчас нас там порядка действий мы очень сильно нарастили мощь как раз таки в автоматизации непосредственно потому что не буду скрывать раньше года там в 2017 наверно псб тогда это получается чем промсвязьбанк наши ребра денги все эти учитывают в банке обновления были практически ручного характера да то есть инженер это ручками заходили на физический сервер а то подкладывали какие-то файлики ребута ли какие-то сервисы что с этим дела на вот а потом это все начала активно как раз таки развиваться как раз тогда стало 20 это вся культура модно интересно и прикольно да и все стали мне переключаться вот и как раз вот где-то там получается в 19 году туда пришел я а вот меня позвали как в эту всю историю начать усилять развивать вот и краски завод почти такого году мне кажется не сделать большой шаг к современному ему так скажем да вот сюда вот прошло вот когда vox называют а мы с точки зрения культуры с точки зрения технологического стыка и процессной составляющей то есть очень сильно выросли и если поначалу набирали людей чтобы тушить пожар и потому что систем было большое количество digital как бы очень растет сейчас да там добывай системы расширяются просто колоссально быстро количество разработчиков нас команды там росли просто с геометрической прогрессии какой-то и вот как раз в этот последний наверное полгода у нас уже получается активно двигаться в сторону и рэнди то есть некое как раз таки развитие там походу дела так скажем обходилась обходилась тем чем есть вот сейчас большое внимание уже выделяем как раз таки развитию и каким-то новым современным видением который мы хотим использовать поэтому потихоньку переходим на декоративные описание инфраструктуры там использования вот с подхода инфраструктуру как кот там для написания скриптов описание описание непосредственно там наших нашего окружения можешь прям вот чуть конкретнее это пример написать например что ты не можешь использовать чтобы ты хотел использовать от чего тебе приходится отказываться в таких условиях допустим появился какая новая фича мы хотим и я тоже тоже естественно использовать мы начинаем это все там тестировать у нас соответственно есть разные тестовый полигон и тандыр стенды с твое окружения а вот на которых мы можем там что-то проверять вот в случае если используется что-то вообще новое что то так скажем с вероятностью каких-нибудь уязвимости до взять ту же контейнеризации почему ее не секрет же да говорят что в контейнер и образы это вообще не про безопасность то есть это не очень северные штуки и ну понятно почему да то есть и вот мы как раз таких как госбанк глубоко анализируем эти вещи то есть мы не просто будем работать с контейнером и да заходим docker hub скачали поехали нет мы покраски прорабатываем в блоке процессы как мы на проверяем там до круга реагируем компаниям создаем свои какие-то образы из каких-то базовых тонов образовал да там и так далее то есть мы выстраиваем целый цельный комплексный процесс но вам же вы же не отказывайтесь вообще это 9 подхода контейнеризации просто как ты ее не конечно услышано вы используйте вот эти все докеры губерн этис и то что сейчас пишут в резюме этого пса то что надо знать мы к этому движемся то есть я не знаю там могу говорить не могу есть какие то такие вещи вот production у нас пока такого не то есть мы к этому как бы активно идем готовимся нарабатываю тоже мышечную массу вот экспертизу очень часто со беседовал народ и люди настолько привыкли работает с вот виртуализации контейнеризации совсем и подверните с когда docker и так далее что забыли про уники вот прикладные уровне на что есть там железо которая как-то работает там ну и так далее адрес там балансировщик аппаратной этом какие телефоны с которыми там нужно бывает как который очень топорно там делят типа пользовательские ну то есть там много очень нюансов и как раз таки когда мы выстроен выстраиваем вот наши процессы это очень круто для наших специалистов потому что это заставляет и в первую очередь прокачивается более широко более глубоко как же наверное сложно нанимать людей при таких условиях и какова же уровня люди должны приходить сюда чтобы ты их брал совершенно тот сложный вопрос тут на самом деле наверное нам очень везет потому что у нас очень крутая команда очень классные ребята очень сильная но на самом деле так чуваки они как бы и так скажем за приклад секунд да то есть они знают как грубо говоря происходило там обновления там пять или десять лет назад то есть на более вот таком низком опорном уровне и при этом они у них есть понимание как так скажем на современном уровне сейчас происходят даты с помощью где распределенных кластеров каких-то вот этих всех служб играли в и но тут очень сильно конечно мы стараемся значит уровень наших сотрудников подтягивать мы регулярно проводим какие-то обучения отправляем на внешнее обучение зазываем спикером спикеров к нам банк чтобы приходили люди рассказывали нам что случае происходит в мире да какие есть современные штуки что все там давно в облаках что каберне tissot докера и самое главное как к этому прийти потому что понятно дело что ну не сложно поднять там настроить кластер да не сложно чтобы все это работало вот когда у тебя нет высота там никакого в интернет вообще ниоткуда вот это сложно вот это становится сложнее вот здесь уже включается как раз таки креатив и интерес что как все должно работать а как все проверки должны обеспечиваться как у нас там трафик должен исходить клиенты подключаться как у нас там несколько прокси-серверов там и так далее то есть здесь вот уже встает интересные вопросы интересные кейсы что не так просто как бы работать как раз таки в сегменте который вообще не имеет доступа никуда то есть вот он этот сегмент банк который спрашивает гособоронзаказ мы обязаны так скажем придерживаться всех передовых и возможность критериев по защите и соответственно конечно у нас очень но к этому относимся ответственно и безопасность у нас очень ответственно и поэтому этот момент дома не творится хорошо но естественно есть различные фронтовые системы сервис эквайринга там все прочь к которая конечно же в интернете там и так далее но к ним тоже повышенные требования безопасности которые мы обеспечиваем вот поэтому возвращаясь к вопросу значит провод как мы людей ищем то что как бы люди там эксперты по кубе рам и так далее это очень круто это очень востребована просто так получается что они не всегда с нами так скажем совместимы да то есть мы им не совпадаем вот этим штукам потому что мы сейчас это все только то есть нам нужно люди вот они ширшов широкого формата до которые как бы знает было как должно быть в будущем куда мы сливаемся то есть вот так получается что мы вот на пересечении как раз сейчас вот этих двух эпоху да когда мы уходим от каких-то вот вещей таких постулатах вот в 10 15 годах его двигаемся в новый я тебе желаю успехов справляться с этим чтобы все было надежно и дальше но и чтобы вышли и чтобы все получалось сделать удобно и современно совмещайте спасибо большое спасибо пользуясь случаем а у нас есть пар вакансии если кому то интересно краски более глубоко изучать так скажем стандартные вещи того пожалуйста просим ура я рад что мы все с вами собрались как мы только что выяснили в зале я рассказываю для тех кто в онлайне нас теперь видит что мы все еще бодрую быть аплодисменты были великолепными это была репетиция перед тем как приветствовать конечно следующего спикера мы все с вами знаем что в облаках в целом все хорошо когда речь касается баз данных там возникают вопросы насколько она вообще хорошо и как с этим разобраться как это готовить мы сейчас узнаем из доклада который расскажет александр зайцев и зал кинете аплодисментами встречайте пожалуйста александр дайте добрый вечер ну давайте знакомиться меня зовут александр зайцев как мне уже представили я 24 года уже занимаюсь войти хотя свой первый программы написал наверное в семь лет на листочке бумаги у меня еще не было компьютера и в настоящий момент я работаю в компании альпенсиа который я сосна соосновал по совместительству у меня черный пояс по айкидо и поклялся так любят говорить в наши sails когда меня зовут на какой-нибудь звонок с клиентами и я не брат петь и зайцева которые многие все знают и все задаются вопросами почему мы носим одну фамилия ну так получилось мой друг только хорошо знаем и любим вот все такой компании alte нити и почему я рассказываю сегодня про базах данных в облаках оттенить вообще занимается клик хаосом и мы предоставляем полный список enterprise услуг поддержка тренинг все что вам нужно и в последнее время мы строили свой собственный ольсен текла от который предоставляет клик house is еще раз публичных облаках и собственно на основании вот этого опыта я сегодня вам буду рассказывать как строить базы данных и как их готовить база данных в облаках то есть наша цель и как по наша с вами цель это строить приложение а все остальное за вас должны делать как бы другие облачные провайдеры счас провайдеры и так далее так что когда он говорят базах данных в облаках то это получается скрестить ужа с ежом я тут столько разных метафор подобрал что это и прокрустово ложе испанский сапог это все потому что это немножечко больно и не удобно и вот эту боль и неудобства я постараюсь вам рассказать и как с ней справляться когда заходит речь об облаках то есть некоторая такая мифа мифологема до что облака нам обещают несколько базовых вещей во-первых это масштабируемость то есть если мы в облаке мы можем очень легко система отмасштабировать она у нас не справляется мы там добавляем либо реплик либо добавляем ресурсов виртуальную виртуалке и начинает все работать вторая вещь которая часто обещают в облаке это простота использования вот эта вот кнопочка красивая это то что нам легко все делать то есть мы нажали на низкую кнопку на все заработало кроме того облака обещает высокую надежность и доступность то есть если мы живем в облаке мы предполагаем что у нас ничего никогда не падает а если падает то сама поднимается и продолжает работать так же хорошо как и раньше и последняя безопасность то есть в облаке облака обещают безопасность на на самом деле они обещают очень агрессивно именно потому что за безопасностью там не все так хорошо и об этом мы тоже поговорим одна из расхожих метафор когда говорят об облаках это стадо дам lick it all то есть облака это как бы 100 до чего-нибудь и по цитатами здесь понимаются вещи которые комодики взаимозаменяемые то есть если железные сервер они все одинаковые мы их ставим стойку одинаково и соответственно один выходит устрой его можно заменить виртуалке они тоже одинаковые там один и матч они могут отличаться только размером и той же леска на которые их развернули если говорить о cabernet если это под и они тоже одинаковые у них один и тот же 5 они работают примерно одинаково то есть вот это с базовые такие вещи и облака говорят что это у нас стадо имеем хорошо умеем управлять но база данных это не стадо да это котики и котики они не потому что мы их очень любим и лелеем а потому что все базы данных разные и разные они в первую очередь из-за данных которые этот котик несет за собой то и за каждым таким вот котиком из базы данных тянется чемодан с данными и именно это то что отличает база данных от многих других облачных сервисов то есть вот это вот состояние эти очень ваши ценные данные которые могут быть маленькими могут быть большими то могу быть терабайт и данных они делают жизнь в облаках очень сложный порой и порой даже невыносимой так как же нам выполнить облачное обещание то есть как для базах данных которое работает в облаке выполнить требования но не требования обещания надежности удобства использования доступности и безопасности собственном и этой задачи занялись года два назад и чему-то научились начнем с масштабированием масштабировать можно по-разному понятно что самый простой и простой способ масштабирования он был традиционен для баз данных в не облачное время это вертикальная у нас работает база данных медленно мы добавляем больше железа мы добавляем либо берем сервер побольше либо каким-то еще образом наращиваем память наращиваем цепью что происходит в облаке это то что если у нас есть сторож то мы не можем просто так нарастить размер виртуальной машины мы это можем сделать только в том случае если у нас хранилища сетевое то есть если у нас локальный диск то масштабировать вертикально у нас не получится потому что мы поставили более мощной виртуалку а данные то они где то в другом месте остались поэтому вертикальное масштабирование работает только сетевым хранилищам и это существенное как бы свойства облака но с другой стороны поскольку мы в облаке и если мы используем сетевое хранилище то его тоже можно увеличивать когда вы работаете в не облако то добавление новых дисков существующей как бы сервер это всегда сопряжено с неудобством и риском особенно если у вас нет доступа к датацентра а в облаке можно просто увеличить размер тома но либо добавить новые тома если база данных поддерживает такую конфигурацию то есть с точки зрения как бы облака и база данных чтобы они друг с другом хорошо сосуществовали в плане вертикального масштабирования облака должна уметь поддерживать масштабирование домов или добавлять несколько томов и кроме того если мы говорим о сетевых дисках они должны быть быстро и понятно что если у нас есть что-то медленно это баз данных будет работать медленно и и никто не захочет пойти в облака на какую-то медленную систему но а со стороны базы данных она должна просто уметь эффективно масштабироваться немногие базы данных кстати не все базы данных если им увеличивать в два раза количество ядер они будут работать два раза быстрее но хорошей базы данных так умеет клика вас в их числе работы с несколькими домами и сносно работает с медленным диском опять же почему мы можем говорить что с медленным диском можно работать сносно и это будет работать для ряда базах данных потому что говоря об аналитических например базах данных они всегда читают большой кусок данных сразу у них нет участок чтение нет участок записей то есть такой сценарий когда им надо бы много написать много прочитать и вот этот сценарий на сетевых дисках работает хорошо потому что один раз вам соединиться и дальше вы читаете или пишите данные горизонтальное масштабирование она как бы более известны и популярны в облаках и в базах данных здесь опять есть нюансы то есть горизонтально можно масштабировать в двух разных измерениях первое измерение это добавлять репликацию это такое традиционное для mais quel и например и для манги а для чего мы это делаем у нас не справляется с нагрузкой по конкурентности то есть по количеству одновременных запросов добавление реплик нам увеличивает возможность конкурентно обслуживать наших клиентов а второе измерение здесь это добавление шар дав и шарда что они нам делают они нам увеличивают возможность система в целом обрабатывать данные то есть чем больше у нас шар дав тем больший массив данных одновременно мы сможем обработать потому что у каждого шарда есть свой какой-то предел пропускной способности обрабатывающий способности еще и когда мы упираемся может быть в пределы одного одной коробке 1 виртуалке on добавление нескольких нам позволяет этот это перейти ну и здесь требования очень простые опять же и базы данных и облака должны уметь работать в таком режиме то есть облака просто отдавать нам в только виртуалов скука мы попросили а база данных поддерживать родирование репликацию и уметь контролировать состояние если мы что то вы здесь меняем последним пунктом здесь идет такая немаловажная штука как решать днк и сейчас мы посмотрим что это такое мы начнем с репликации опять же как бы облака обещает что все просто мы добавили реплику и сразу во все получилось на самом деле конечно это не так то есть мы добавили реплику и она пустая то есть мне еще данных нету и только через некоторое время из двух других реплику нас заливаются данные а что происходит в то время пока данные еще не залились но у нас какая-то частично частично правильная система и ей пользоваться полноценный нельзя поэтому типичные сценарии добавление реплики это мы сначала и добавляем потом ждем пока она до реплицируется и только после этого включаем ее в запросы казалось бы очевидно но этим надо заниматься иногда эти может заниматься базы данных сама ecли каллас это умеет делать то есть кликал ася если вы все запросы делаете через распределенные таблицу так называемую то тогда распределенная таблица сама понимает что какая-то реплика не готова что она отстает и на нее запросы не пошлет но как правило этим все-таки занимаются извне на уровне там лот балансира на уровне чего-то контролируя состояние реплики и только тогда когда она готова мы ее включаем в в обсуждении запросов с родированием ситуация примерно такая же но другая мы добавили новый шарф он пустой что нам делать можно не делать нечего а можно делать то что называется ришар wink когда мы данные с двух существующих шар дав часть данных переливаем на наш новый 3 шард соответствовать соответствие то есть у нас получается что на каждом шаге стала данных меньше у нас скоро систему от этого вырастает вот но сама эта операция очень непростая то есть когда мы добавляем sharp создаем схему то вот это вот перенос фоне он далеко не тривиален то есть во время переноса нам нужно гарантировать то что у нас данные целостные то есть мы взяли кусочек скопировали его на другой шар с этого надо удалить а в это время у нас идут запросы постоянно в какой момент и как их переключить что дело с тем запросам которые уже выполняется это все не такие простые вещи как кажется и база данных по идее должна с этим справляться ну например если там говорить о маску или моя сколь от делать не умеет поэтому есть компания вид с которая построила совершенно другой mais quel который поддерживать sharding решебник но это уже от моя сколько там осталось только протокол вот включался традиционно подход был ты правда простой вы добавляете шорты ничего не делаете потому что мы считаем что в клика устно все время данные добавляются и добавляются и добавляются да и вообще мы используем его для какой-то там real-time аналитики это последний день 23 неделя соответственно через несколько дней у нас данные уже спас единение за последние дни выравняются а что там в исторических данных неважно тем кому это не подходят они могут передвигать вручную или ждать пока кликал это поддержит и на самом деле поддержка ришар ленка включалась и не за горами в этом году она уже мы надеемся будет может быть вы заметили что все время я говорю на самом деле просторы что есть несмотря на то что вот сейчас вот сегмент про масштабирование я говорю про сторож потому что база данных это все вокруг сторону и где же мы в облаке хотим хранить данные почему локальные до локальные диски они как я уже сказал не масштабируются с одной стороны то есть мы если мы взяли какой-то instance на амазоне с локальном ssd и мы хотим увеличить то нам придется взять другой а этот выбросить и кроме того ненадежная то есть нет никакой гарантии что у нас всегда это все будет жить если она упадет мы диск потеряем поэтому раз мы идем в облака то надо пользоваться облачными средствами а это различные сетевые хранилища начиная с отжиг сторож или моего по традиции называем асти хотя в разных провайдеров разная имплементации штука хорошая достаточно быстрая но основная проблема что в ней очень дорогие индивидуально операции то есть записать файл это очень дорогая операция причем даже маленький файл записать большой файл уже накладные расходы небольшие записать маленький файл или много файлов это очень дорого поэтому с ним надо немножко по-другому работать не так как с традиционными блочными девайсами традиционными блочными эстор аджами есть несколько обычно выборов в облаке какие-то стандартные если говорить про amazon это же питу и gt3 вот или какие-то сетевые стороны с гарантированными и опциями с гарантированной скоростью они очень быстрые но очень дорогие и на большие данные это быстро станет неэффективном чуть-чуть с другой стороны взгляд опять же когда мы говорим про база данных в облаках то часто приводит такую аналогию разделение сторож и компьютер то есть классической амбер металл у нас всегда сервер и своя стойка с дисками или диск сервер диски сервер диски в облачных базах данных они продвигают концепцию что у нас есть общие сторож и к нему мы запускаем столько сколько надо рабочих нодов эти рабочие ноды выполняют запросы получая данные с этого общего обжиг старриджа понятно что такой подход имеет много преимуществ и должен лучше масштабироваться то есть мы просто добавляем добавляем еще хасты если нам не хватает скорости и или чего то еще на самом деле все работает чуть чуть не так во всех обычных базах данных у них между хостами и старый джим сетевым всегда есть прослойка локального старриджа как такой кэш этот размер этого каша может быть самым разным он может быть как и небольшим так и фактически равны размеру данных например если говорить про redshift да он хранит данные на s3 но при этом на каждом из нас и redshift а полная может дать копия данных который хранится на ис-3 но только локально это как бы хорошо с точки зрения производительности но плохо с точки зрения если вы поднимаете новый сервер сколько времени потребуется пока он закачает с сети себе на локальный диск данные такая же проблема существует и в snowflake и там и вертикали он то есть это как бы общей паттерн клик роуз тоже может работать с облачными средствами более таким нативным способом и в нем есть концепция который называется дискос 3des костре это диск в которым опираются на обжиг сторож или уже сторож compatible что-нибудь вот и кликал из при этом использовать совершенно другой способ работы с этими данными для чего другой потому что традиционный работает очень плохо и вот с этим другим способом получается не так плохо здесь результаты некоторых тестов которые мы делали осенью и разница между обычным сетевым сторожем s3 она от мало 2 1 до 10 по скорости выполнения запросов на достаточно большой таблицы это таблица примерно миллиард 300 миллионов записей такая стандартная тестовой таблицы достигается такая скорость за счет парализации всего чего можно то есть максимально параллельно читается с 3 максимально параллельно пишется используется крыши для засечек это специальные структуры который помогает клик хаусу быстро находить данные то есть никогда целиком файлики не читаются не читаются кусочками вот при этом решении такой экспериментальная и до сих пор неким толком не используется в продакшене потому что есть две большие проблемы первая проблема это то что когда у вас данные на ис-3 они уже с реплицировали но клика у нас об этом не знает и другая базы данных до если она признать изначально не было сделано для клауда она не знает о том что у него клаус нарочно же репрессирован и когда добавляется реплика не надо это делать второй раз и вторая проблема это скорость вставок из проблемы с файлами которые я упомянул окликал из он на каждой колонку в таблице создает иногда два иногда 4 файла если у вас становится стока лунок то один insert это примерно 200 210 220 файлов что дорого даже из 3 но есть некоторые способы вообще говоря говоря об архитектуре хранение до которая сделана вплеталась и и в некоторых других базах данных что то есть похоже то есть а смотреть снизу вверх то на самом нижнем уровне у нас физические устройства на который может быть диск может быть дискос 3 сейчас делается диск hd fs то есть то где реально хранятся хранятся данные то есть некоторое такое описание абстракция дальше эти диски могут объединяться в том а зачем это сделано например мы хотим определить что у нас данные хранятся на каком-то томми и мы можем в этот том добавлять диски потом не меняя больше ничего то есть для в стальной системы это будет незаметно поверх домов есть политика который определяет как этот там использовать но и уже самого сверху лежит таблица что это позволяет это позволяет например делать то что говоря называется называется оттирает конфигурации то есть когда у нас например данные сначала идут на быстрый диск а потом автоматически в фоновом режиме переписываются на медленный диск например на мерно не диск могут переписываться те данные которые старше семи дней таким образом у нас есть баланс от производительности для свежих данных исторические данные мы не выбрасываем а просто передвигаем в более медленное место они там продолжает работать естественно этой функции нетривиальная немногие базы данных это умеют это надо было специально делать большое спасибо ребятам из яндекс облака которые это включалась добавили следующая большая тема и обещания облака это отказоустойчивости надежность и здесь надо в первую очередь запомнить и как бы понять и что база данных это не веб-сервера это не веб-сервер и это значит что нельзя просто выключить и включить почему потому что в базе данных выполняется длинные запросы то есть если за полне выполняется select если это не какой-то тривиальная штука а какой мать аналитический запрос он может выполняться там сотни миллисекунд или секунды если это insert в зависимость от того как заливаются данные в базу данных один сорт может занимать и секунды и даже десятки секунд и минуты если мы сразу много много данных заливаем поэтому даже если делается плановый downtime его надо делать максимально аккуратно а в случае внепланового downtime а прежде чем бросаться и поднимать новую реплику всегда надо разобраться что происходит как мы делаем плановые downtime то есть сначала надо убрать этот сервер из балансира то есть чтобы на него не шли новые запросы никакие потом надо его убрать из внутренней конфигурации чтобы внутри не кликал ставки запросы на него тоже не попадали то есть клика вас изнутри он между серверами гоняет данные когда мы делаем распылённый запрос ну и любая распределенная база данных так делает вот и надо это выключить сначала после этого подождать пока закончится запросы подождать пока добежит репликация потому что может так случиться что у нас в этот сервер который мы хотим выключить только что пришел insert и он еще не с реплицироваться и только потом выключать то есть это такая нетривиально последовательность шагов которую надо сделать случае с внеплановый downtime а то мы не можем как бы делать таких шагов мы можем только подождать убрать из балансира причем многие балансиры это делают автоматически то есть они посылают запрос и видят что сервис нет ли не отвечают то они выбрасывают его из ротации и только через некоторое время может быть проверит и подождать разбираться в чем дело часто это восстанавливается сама и я объясню почему очень редко случае 18 их кликал ся требуется убирать полностью ноду и начинать с чистого листа димас талеров из фланта вот он и сегодня там настойки был он достойный год назад сделал исчерпывающую до крал доклад про база данных губернаторе в частности рассматривал эту проблему с отказавшей реп отказавшей репликой то есть то делать со сплит brain им и прочими делами на примере mais quel и увлекалась и немножко проще из того что репликация асинхронная и если у нас что-то мы выключаем то это не страшно потом когда мы включим а надо гонится следующая важная штука для надежности это география то есть мы привыкли считать что облако это что-то как бы одно монолитная на самом деле облако состоит из нескольких под облаков то есть в каждом регионе если это большой облачный провайдер там своя собственная абсолютно независимо инфраструктура если не дай бог бомба упадет на нью-йорк то европейский дата центр будет работать и и наоборот и внутри каждого региона есть то что называется зоны да наверное многие знают но как бы зоны владельцы зоны отличаются тем что они а независимым питание и на независимой сети часто сидят то есть если там кто-то обр убит кабель вот та вылетит одна зона они они все поэтому что мы делаем мы хотим базы данных разложить по разным по разным зонам это в первую очередь чтобы реплики лежали в разных зонах а что насчет разных регионов это тоже можно сделать но при этом нас появляется лет и носи на репликацию то есть если мы добавляем какие-то данные то они могут не сразу с какой-то задержкой добежать до другого региона и это не всегда не всегда допустимо поскольку наша основная ценность данные то как бы еще раз мы данные раскладываем по зонам плюс это еще недостаточно помимо зон еще имеет смысл делать бэкап это тоже то функция которая в облаках как бы предполагается что есть но если вы свои собственные базы данных облака вкладываете то надо этим заниматься и некоторые облака еще дают возможность делать снапшоты сетевой диск его можно за вас над шутить и наверное при желании восстановить опять же это не всегда работает но можно попробовать вообще по нашему опыту самая частая проблема которая может привести к потере данных это кривые руки поэтому руки надо держать прямыми например случай буквально на днях был когда один из клиентов они запустили crack house запустили его в cabernet если в каком-то облаке вот а потом пришли и ручками стали исправлять там размер волен клейма то есть сколько вы сколько диска у него диска не исправили а потом пришла другая утилита про который я еще расскажу увидела что размер отличается удивилась снесла все что там неправильно я создала новое и а не потерять данные то есть руки надо держать прямыми чистыми если хочется все таки держать как бы dear сайт в другом дата-центре в другом регионе это тоже можно сделать и часто такой сценарий используется если у вас есть еще и поток данных который заливается в база данных он тоже распределён по разным регионам например часть инфраструктуры в одном регионе часть инфраструктуры в другом и эта часть льет в клика os или в базу данных в своем регионе эта часть в другой в другом регионе при этом мы хотим чтобы с точки зрения наших репортов или аналитики это выглядело как единое целое это тоже можно сделать вот примерно по такой схеме здесь есть такое ещё квадратик или кружочек звуки perdo эта штука которая включалась и необходимо для репликации и для координации репликации поэтому она должна быть близка концертом поэтому где моим сердцем в один регион у нас там за keeper для этого под кластера и всем этим другой регион регион закипит для другого под кластера а потом мы их объединяем средствами кликал это выглядит как единый кластер удобства следующая тема как вы может быть заметили я все время говорил о том что это надо автоматизировать это нужно делать нужно делать раз два три 4 5 и на самом деле это потому что облака это всего лишь набор инструментов то есть вам дали набор инструментов но не объяснили как им пользоваться а делать придется все самим или же привлечь какого-нибудь помощником рулевого мы решили привлечь губернатор да и построили вот такую матрешку зачем то есть штуку берн это сдает в облаке казалось бы губернатор это как бы сама по себе публичного уголка само по себе но на самом деле губернатор он делает несколько важных вещей во-первых он абстрагируется само действие с облаком если вы научитесь жить в купер над если вы можете как бы жить в амазоне в гугле в ажуре в huawei callout где угодно то есть где угодно где есть cabernet с или же на бирме там тоже во вторых он имеет некоторые средств встроенные средства high availability который вам пришлось бы делать самим ну например самое одна из самых полезных и the life насечек то есть если у вас что-то случилось с базой данных у него лай наш чек засиделся куда на этот автоматически выкидывает этот сервер из балансиров из всего и на него не идут запросы а потом автоматически пытается ри стартовать его и при рестарте как правило все приходит в норму ну и еще можно так сказать что облако она развивалась со стороны железо и вот эти все облачные объекты они как бы начинали at low level все время как high-level с той страны со страны железо двигались губернатор развивался со стороны разработчиков и такие объекты более высокоуровневые юзер френдли с ним удобнее работать они естественно встречаются где-то посередке но вы работать удобнее кубер на это все при этом чтобы губернатор все нам что-то сделать и например поставить база данных то практически невозможно обойтись без того что называется оператор про оператора здесь на конференции рассказывают многое часто просто не потому что это модно а потому что это необходимо что делает оператор самой первой важную вещь вы когда вы описываете что вы хотите сделать и на основании этого описания оператор создает много разной инфраструктуры внутри губернатор соответственно внутри внешнего облачного провайдера но это еще не все то есть оператор продолжает смотреть за тем что происходит он мониторит он поддерживает состояние то есть на самом деле достаточно большую часть операционных забот оператор берёт за вас и это очень ценно и важно практически для всех базах данных если open source операторы и откликалась не не исключение для многих их несколько для майского липовом три оператора есть вот как вообще выглядит например небольшая база данных cabernet если то есть это много-много разных объектов мы описали что мы хотим кластером два шара до s2 реплики я не буду приводить описаниях нужно достаточно большой на может быть на две странички ямал текста вот в результате оператор создает стоит full set и создает внутренних контейнеры делать пирс тесным твоем клеем и создает сервисы и все это как достаточно быстро и вам не нужно об этом думать то есть за вас уже подумали как бы разработчики они упростили сильно жизни она помимо кубер нету с и если мы живем в облаке конечно остаются все облачные сервисы остаются в тоске лин группы авто остаются какие-то subbed и остаются лот балансиры не уровне cabernet осао уровня облака и с ними тоже нужно взаимодействовать то есть находясь cabernet афинам тем не менее нужно взаимодействовать с внешней инфраструктуры и губернатор света умеет делать то есть есть какие-то там штатные вещи например кластеров ты скейлер да это компонент cabernet оса который если у него не хватает not где запустить ваш новый сервер он идет в облако и говорит дайте мне ещё один инстанса там еще и сету instance он добавляется в губернатор и встает на него на него note то есть вам не нужно держать большой cabernet из кластер вы держите его максима минимального размера и он динамически масштабируется через of those келлер аналогично со сторожем вы попросили диск и storage controller пошел в клауд провайдер попросил а дай-ка мне пожалуйста диск с такими-то характеристиками он отдался под монтировался под монтировался капоту вы начали им пользоваться dns сервис и как бы аннотации то есть общение с облаком с точки зрения сервисами сервисов происходит через аннотации или же можно написать свои операторы например нам пришлось написать свой собственный лад было болот балансир который работает лучше чем оба амазонский и вот его например конфигурировать можно через аннотации то есть он понимает это стандартный сервис объект но при этом как бы оператор понимает что если есть какие-то аннотации то нужно сделать что-то дополнительно например сходить и создать dns имя выписать сертификат если мы хотим тела и соединение иметь сделать проброс куб портов до снаружи где у нас вход внутрь на наш на наш кликал себе наши базы данных есть средства внутри комбинации которые делают похоже но можно сделать и свои то есть эта система открыто что делать делайте что вам нужна последняя безопасность вот прямо перед этим докладом как раз показывали видео где говорили что безопасность в банке это как прежде прежде всего и все эти облачные штуки они просто не работают и на самом деле да когда мы говорим о бирме тогда мы привыкли что мы огорожен такой стеной нам нас периметр у нас там какой-то security сидит и никого никого не впускают снаружи не выпускают никто не входит никто не выходит и все у нас работает безопасно в принципе можно особо не заморачиваться о том как это каких-то реальных вещей в облаке все не так то есть облака она открыта всем ветрам то есть с любого там публичного адреса могут попытаться атаковать ваша ваш сервис и за этим это надо иметь в виду то есть что мы можем сделать чтобы себя обезопасить во-первых в писе это такая базовая штука в облаках которые делает вам как-то виртуальное облака со своими собственными внутренними api адресами и нет никакого способа извне туда попасть теоретически но мы же не можем жить как бы вакууме обычно мы все-таки открываем некоторые сервисы наружу например мы хотим чтобы она наша база данных могли приходить какие то извне наши другие сервисы которые не живут например в облаке это приводит к тому что x пользоваться много портов много интерфейсов наружу и это лишняя это лишнее риски поэтому правило номер два не открывать никакие внешние порты джен порт 123 открывается part 1 2 3 неких и другие этой маски нужен порт 123 открыли но только для тех айпи адресов которые мы разрешили и для тех по сетей то есть как бы подход должен быть не запретительный разрешительные то есть мы сначала запрещаем все он потом начинаем потихонечку разрешать потому что обычно сначала все разрешаем потом начинаем запрещать и можно что-то забыть шифрование всего трафика наше выживание всего трафика это нужно сертификаты и за ними надо тоже следить шифрование данных хотя мы предполагаем что инженеры google и amazon они когда они придут и не попытаются прочитать данные которые вы там храните объяснять это каким-то там начальником не всегда получается поэтому шифрование данных и трест это практически требования для всегда если вы в публичном облаке живете достигли на проникновение логирование мониторинг это хорошо иметь логирование мониторинг обязательно иметь то есть если что-то случилось вы всегда можете все-таки найти какие-то следы может быть если у вас есть какие-то тулы можно проактивно это увидеть в амазонии есть garden те которые пытаются смотреть ни странно и activity то есть поскольку это все открыто чем больше как бы мониторинг и логирование тем больше шанс что когда что-то случится вы отреагируете и тем больше шанс что какие-то другие средства могут предотвратить это это что-то плохое ну прямо же точно такой резюме перед тем как мы перейдем к вопросам база данных в облаках не работает из коробки и доклад назывался прокрустово ложе или испанский сапог так вот испанский собака это для тех кто пытается использовать до базы данных в облаках не не не знаю когда потому что им приходится мучиться им это все жмет им неудобно они представь постоянно натыкаются на на что-то странное неприятное облачное обещание которые мы все слышим не только для клауд на этих сервисов то есть вся инфраструктура которая есть в амазоне вся инфраструктура который в гугле она их выдерживает но как только вы приводите что-то свое и пытаетесь там развернуться то сразу приходится все делать заново то есть все приходится делать самим но почти с нуля и заворачивать кучу дополнительного softa губерн это здесь жизнь существенно облегчает и поэтому я советую сначала научиться в клубе шнек себя потом идти в публичное облако это легче и удобнее вот примерно так таким я крупными мазками это нарисовал можно в любую тему углубиться если есть какие-то интересные вопросы супер александр спасибо тебе огромное за этот доклад и у нас для тебя есть персональная благодарность в рамочке а также а также худи и там значок холодный спроса будет согревать им упоминать об этом вниз поставим что ребята поднимайте руки задавайте вопросы если вы в онлайне вот я вижу руку если вы в онлайне нажмите кнопочку выйти в эфир сможете задать вопрос оттуда прошу вас представьте себе задавайте вопрос александр здравствуйте меня зовут александр компаний sky box с вашей стороны много было сказано про вот так подали что использование баз данных купюрница очень хорошо да как бы купер никс облегчает жизнь одна из последних фраз а не кажется вам что использование баз данных в класс терек вернетесь это только несет больше болида чем это будет плюс потому что если у нас есть какая-то более менее производительная база данных которая требует ресурсов которые требуют памяти это выльется в то что она будет занимать там одну целиком там ноду worker классе руку бернетт с тогда зачем нам это лишняя обертка если мы не хотим чтобы намного занимала нам нужно поставить на ее какие-то лимита данному не очень будем рады если кто-то там он киля придет и убьет нашу базу данных вопрос хороший и он полностью имеет смысл но я сказал что cabernet с облегчает жизнь именно в облаках то есть если вы живете в бирме то то наверное cabernet с вам может быть и не нужен и это все правда а в облаках cabernet берет на себя вот куча всякой вот этой дополнительной машинерии которые в обычном случае придется делать самим вы можете развернуться на virtual koch визиту инстансах но если но тогда придётся заниматься вот всякими этими вещами например что делать если это и ситу сломалась как взаимодействовать там ссылок балансиром как выпускать сертификаты и прочее то есть придется куча всего дополнительного делать и в облаках есть конечно средства как кит автоматизации да какие там клауд фар машин и прочие вещи но cabernet вся не сделано просто лучше тот overhead и на дополнительные ноты которые которые будет вот он не очень большой во первых во вторых вы всегда можете сделать так что у вас на одну ноту сядет только кликал если больше нечего и мы обычно так делаем то есть мы берем виртуалку на нее прописываем там были решены до определенные вот и кликал встает только сюда и больше ничего сюда не встает соответственно мы ее используем целиком и полностью насколько это возможно может быть логичный подход если мы живем в и сели в google audi просто взять database а сервис и лишних лишних проблем избежать конечно конечно поэтому вот аль денте клауд это и есть то дтп с и за сервис котором вы построили для кликал ся нету сервиса в публичных облаках для москвы ля пожалуйста берете аврору rds прочее это все уже есть и это как встроена в облака сами провайдерами облаков если вы приходите со своей базе данных то вам приходится делать все с нуля спасибо александр вопрос слева от тебя из следующего после вижу вот здесь рука добрый вечер меня зовут василий спасибо за доклад у меня просто такое сказали про операторе что оператор это благо операторы это здорово и в то же время то что надо держать вам прямые чистые луки да вот нет ли здесь ловушке в том что оператор позволяет буквально по щелчку пальцев развернуть тот же самый пик house в кубе но при этом это можно очень легко сделать теми самыми немытыми руками как вот как как здесь быть как найти границу когда ты готов использовать оператор для того чтобы разворачивать базы в кубе и при этом не сделать себе жутко больно операторы всегда лучше чем не оператор потому что оператор пытается за тепло ить некоторым стандартным способом то есть вероятность ошибки меньше но может быть конечно бага в операторе вот но если оператор работает корректно мы предполагаем что софт в принципе хорошие у нас до уже опробованный то то что вы в нем напишите он сделает при этом вот эти вот ручки да они будут меньше гораздо лезть купер нетто смерть того чтобы 20 команд выполнить или написать какой-то сложный фильм чарт который разворачивает куча всякого разного вы пишете маленький коротенький манифест и оператор делает все остальное хорошо у меня есть два примера первый пример как-то google первый вывод архитектура до гуглим с 3 в кубе получаем цех что для цеха нужен pvc я гуглим pvc в кубе получаем меню и таким образом это случай которая видел буквально своими глазами когда у нас есть куб в котором развёрнут меню для pvc поверх которого развернуться в ds3 это вот как раз луки те самые немытые и операторы которые со сильно очень сильно облегчают ты все-таки вопрос так как нету для операторов каких-то не знаю без факт из описанных готовых для всего то как как быть людям которые хотят вписаться вот бы все с кубом с операторами если оператора такое благо и при этом говорю не сделать себе больно все таки и второй вариант 2 сразу пример приведу это как раз таки с клик хаусом опять же операторы таких хауса клёво для него нужен pvc что мы знаем мы знаем что проще всего сделать процесс с помощью анфиса развернули enforcer и подключили соответственно его как псф куб и на этом развернули crack house и опять же жутко больно ну еще раз мы говорим про публичные облака обычных облаках в перечисленные вашими правами проблемы они как бы отсутствуют то есть там уже есть стандартный набор сторож классов которые работают для многих из них родные storage controller и от клауд провайдеров вот там не нужно городить вот эта вот всякую дополнительную машинерию который вам придется делать если вы разворачиваете куб на бормотал и пытаетесь там вот сделать всякие нафс поменял тащите и так далее поэтому мне кажется что губернатор сна бормотали да это для баз данных больно и неправильно а вот если вы хотите публичных облаках то вы здесь вот cabernet из очень хорошо помогает базам данных случае если ваш точки зрения отличается том что говорит да клатч вы можете подготовить свой доклад на следующую конференцию завить мы с удовольствием вас послушаем сейчас на это спасибо у нас эти следующий вопрос и поднимайте руки заранее чтобы к вам успевать а вот мы просто просто когда сначала когда рассказали о же кресты клик house и соответственно и уже коллега тут сдавал на предмет того что там ли house менеджер ничего ничего про уличных облаках так есть же яндекс slaughterhouse яндекс яндекс яндекс карт и яндекс лауда есть magic house где это понимаю что ребята все это уже сделали то есть это как бы первый а второй может быть если не cliff house для реляционных субд этом вот вы говорили что он для маску или есть варианты переписанных встречали вы что-то похожее минджи дтп с то есть вот в cabernet же развернул развернута в публичных облаках как менеджер сервис для москве или или для пожгли со может быть ну то есть первый понятно но первый опрос понятием то есть есть наши друзья из индекса которые сделали индекс клава ты там сделали много разных сервисов в том числе мы начали house но наши облака небо не ограничивается янык сплаву там если мы будем в европу в америке куда то еще то там индекс планету и там приходится и просто латинице там появляется и там нет и они в принципе не могут использовать русский русский сервиса все понял принципе вот не залит инси вот поэтому там приходится идти искать другие решения и здесь как бы нам пришлось это строить вот для москвы лет после со здесь ситуация другая эти сервисы настойка мегапопулярной уже что практически все облачные провайдеры имеют свое решение нос армированного такого классного маску пост длится я не нашел то есть приемы судьбу большое достаточно для мы открыли вот виды на бал но для воды москва или для пастбищ вам тоже что-то они делали такого хорошего ну для для mais quel а нету шарди равного решения хорошего потому что mais quel сам плохо поддерживает sharding вот именно как буду как и позвать сюда как и после клика вас изначально строился для распределенной системы сша деньком рипли кации так же как например vertica как еще некоторые другие базы данных то есть это как бы разный класс баз данных на рисунке судебный публикует не туда я напоминаю что предстоит выбрать александр лучший вопрос и для этого должно быть больше если у у у нас три руки кому нужен крафа уже есть немножко микрофон спасибо большое за доклад вот смотрите опять про баланс как вот коллега говорил классно совершенно оператор уже вижу там что он замечательно шар диков создал пиве сижки все прекрасно развернул теперь смотрите такая ситуация низкий порог вхождения оператор подразумевая что чек мало знает но доверяет оператору это классно это классно продавать замечательно те смотрите ситуация клиент с низким порогом вхождения взял сделать кластер а потом выйти на что ему нужно этот кластер открылись скажем так о прохождении низкий знает он мало он умеет писать короткий манифест на основе этого оператора что позволяет этот оператор ему сделать например серьезно то в 10 раз увеличить дисковое пространство или добавить щупе ток-шоу дав причем хитрых что он будет делать и как вы при этом стимулируйте его увеличить некоторое количество знаний чтобы не отсечь себе базу одним неловким движением но оператор позволяет сделать то что вы попросили а вот если человек не понимает что он делает здесь мы им помочь не можем то есть запретить человеку сделать себе больно и плохо нельзя что можно сделать а только образованием и поэтому если вы начинаете пользоваться оператором то лучше посмотреть примеры там просить какие-то вопросы и так далее в принципе то есть то что вы сказали добавить сторож добавить реплики это все сделать можно и может быть это сработает вообще сразу до нюансы начинаются в сложных ситуациях это простая ситуация супер те три руки что были мы всех вас успеем значит на первом ряду и поднимите еще раз ребят кто хотел александр здравствуйте меня зовут максим спасибо большое за доклад мне кажется человек если услышит вас доход он скажет вам классно я хочу базу данных облаке и первый вопрос который он себе задастся сколько это будет для меня стоит вот если опустить экспертизу по кубу по конкретному облаку и оставить только старридж у вас был классный сайт где вы сравнивали скорость работы ценник вот у человека была база данных на n в моей он захотел то же самое чтобы работал с той же скоростью в облаке во сколько раз именно посторожить в него вырастет ценник надо посмотреть на цены в облаке то есть еще раз вопрос на то что он был в бирме curl и ушел в облака или он из облака пришел в облака но по другому но раз в разных облаках по-разному щи считается 100 раджи то есть я не хочу услышать конкретную цифру вот по вашему опыту во сколько раз увеличивается ценник ну сторож в облаках дорогой сетевой сторож дорогой то есть мы платим за удобство вообще облака всегда дороже чем пермь этого всегда то есть победит смерть невозможно это мы все знаем по цене вот платят за удобство за то что не нужно держать команду которая там дополнение где ваксов или что-нибудь за масштабирование за возможность масштабировать то есть это вот так скажем плата за удобство сколько это в деньгах я я не могу сказать но то есть это по-разному зависит зависит от объема данных скажем там и без стоит 10 центов за гигабайт в месяц соответственно терабайт данных стоит 100 долларов только за сторож месяц понятно что за 100 долларов можно взять сервер фесты в котором будет 20 терабайт может быть или 15 диска но это совершенно другое то есть это как бы сложно сравнивать вы получаете за эти деньги не только сторож но и возможность то масштабировать всякие еще полные другие плюшки и так далее про просто разные вещи так я вижу что у нас есть микрофон еще одного участника и кто поднимал рук напомните себе спасибо за доклад от меня зовут виктор и такой вопрос про горизонтальное масштабирование мы у нас пошло большое количество запросов мы захотели от масштабироваться и instance должен ну реплицироваться мы в этот момент не можем выстрелить себе в ногу за счет того что мы создадим нагрузку на уже существующие инстансы вот как раз этой репликацией 1 2 еще каких-нибудь всё новых и из танцев вопрос хорошая прямо в корень и то есть действительно когда мы добавляем реплику мы создаем нагрузку на другие реплики и здесь если вы заметили у меня было две реплики а добавил третью то есть в таком сценарии мы на каждую реплику за нагрузка меньше то есть у нас была одна мы добавили вторую у нас очень сильно просела бы первая реплика потому что стало бы реплицировать s2 на третью проседает гораздо меньше кроме того в большинстве баз данных и кликал с не исключение есть возможность контролировать вот скорость восстановления реплики если действительно такая ситуация что у вас очень сильно нагружены и вы боитесь что реплика еще сильнее про садит waste речь то надо подкрутить настройки чтобы восстанавливалась медленнее но медленней нагружала и эти реплики тоже да очень хороший вопрос я напоминаю что если вы не до конца получили ответ на свой вопрос что-то непонятно вы еще сможете в цифровых кулуарах которые и в реальной жизни существует до задать ваши вопросы сейчас у нас последние вопросы из зала просто лександр меня зовут егор компания swiss минск хотел спросить водку бернетт с оператор имеет для него значения версия crack house а то есть хаос он развивается развивается очень быстро и вот он оператор он вершин агностик или могут быть какие-то там прям ключевые вещи которые там все вот надо отпустим император придется как-то кастомизировать доделывать и делать его как-то вершин специфик оператор может использовать некоторые некоторые фичи базы данных но не очень скажем так на очень старых версиях ли коласа может не все работать вот и возможно потребуется какая-то кастомизация или использовать старой версии оператора мы стараемся по минимуму делать вещей которые несовместимы но какие то обязательно появятся ну например сейчас в хаусе появилась возможность хранить пользователей и описывать пользователей через сидел до create user так тогда там подобное при этом они хранятся в некотором локальном хранилище на диске вот эта новая функциональность если мы добавляем новые реплики то нам нужно этих пользователей переносить это сейчас не делает если мы это сделаем это будет завязка на новую версию клюв кааса и в старых версиях что-то может не работать но по большей части во-первых кликал из такая штука когда лучше все-таки не сильно отставать от мэйнстрима лишь миловидов считает вообще всегда использовать самую последнюю версию клюка уса но у него как бы есть свой интерес потому что есть чем больше людей использует последнюю версию тем больше они тестируют то что не до тестировано командой вот мы считаем что нужно как бы использовать не самый последний ну где-то вот состава нее может быть в полгода есть lts версии есть там версия который мы называем очень чистый был и вот для этих версии мы тестируем оператор очень аккуратно вот мы как раз all тенистой было использую которую сейчас 28 но в должно работать там все супер а что будем пробовать всего спасибо скажи пожалуйста какой вопрос тебя самым интересным был мне понравился первый и вот предпоследний так что делать что у нас выбрать 1 1 говорит есть подарок на тогда предпоследнее право добавление реплики под нагрузкой супер поздравим победители этого нашего розыгрыша спасибо интересный опрос друзья александр какое-то время еще будет сразу налево и золотом цифровые на школа может быть из онлайна кто-то решится все-таки задать тебе вопрос спасибо да а я андрей шокин буду с вами и завтра с утра приходите в 10 у нас будет доклад про кликал столько про то как и так ли house изнутри изменяется будет интересно сейчас в третьем зале будет небольшой ликбез для и хищников про астрономию а в восьмом зале дискуссия угол собственной разработки то что будет файлы сами знаете до завтра друзья"
}