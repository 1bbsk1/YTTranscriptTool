{
  "video_id": "Fzuu5WItl3A",
  "channel": "HighLoadChannel",
  "title": "Как мы построили модерацию рекламы с нуля и достигли потока 1 млрд вердиктов в сутки / Дм. Латышев",
  "views": 146,
  "duration": 2338,
  "published": "2024-10-29T02:56:34-07:00",
  "text": "Ну а Дмитрий расскажет Сейчас Как они это сделали Всё встречаем дмитри Всё супер спасибо за представление да меня зовут Дима Я являюсь разработчиком в Яндексе И сегодня я хочу как раз рассказать как мы построили модерацию рекламы и достигли одного потока вердикта в сутки Возможно это самая большая модерация рекламы в России Если знаете больше будет интересно послушать Давайте разберём сначала Что такое модерация А модерация - это проверка рекламных объявлений на соответствие требований закона и политики Яндекса а Но процесс модерации не заканчивается после создани объявления мы должны уметь перемороженная объявления бывают различных видов также они показываются на различных площадках но базово они состоят из таких компонентов как картинка текста видео и так далее Вот например другой пример объявление тексто графическое показывается на выдаче поиска медийное объявление Давайте разберёмся что у нас есть у нас есть объект который состоит из каких-то частей а что прозой ели решит изменить текст Ну Появится новая версия этого же объявления А что делать со старой версией Удалить Мы её не можем потому что она может быть уже в показах продевать прийти какая-то жалоба или ещё что-то и мы должны её суметь передерия вляется версионирование объектов а также на модерацию приходит не только реклам объявлено и связа сними обе Лие фразы из запроса при которых это объявление показывать А раньше отдельные части объявления такие как ссылки картинки тоже приходили самостоятельными объектами что создавало неден определённые трудности но об этом поговорим чуть позже Зачем вообще нужны связи Ну вот если Взглянуть на эту картинку и текст то по отдельности они выглядят нормально но сочетании слово фишки при виде денег могут иметь другой немножко контекст на пример отсылку к фишкам из казино с объектом разобрались А что на выходе из системы на выходе не просто бинарный вердикт да или нет а также мы классифицируемым тематикам возрасты ограничения в вердикте могут быть причины отклонения если таковые имеются Ну и для каждой части объявления мы генерируем отдельный вердикт Потому что некоторые части могут быть опциональные и показываться в зависимости от результата модера Давайте посмотрим что было раньше изначально была моде первая модерация первые данные которые мы нашли датируются аж 2003 годом написана она была на перле и весь ранта и база данных располагались на физических машинах и всё это мы администрировать самостоятельно Что влекло Спектр соответствующих проблем На помо ей пришла вторая версия модерации прон об у Вычислите ресурсами такой как Вана из Open sce аналогов это это уже Бава обработка данных написана была на питоне и в ней мы столкнулись со следующими проблемами это отсутствие обработки второе - это непосредственно сам Дулин операции Он не позволял запускать операции слишком сто и слишком много что пово Ну и вс это располагалось в разных графах весь код находился в разных местах что не давало возможности визуализировать весь пайплайн модерация объекта в одном месте Ну зачем менять то что и так работает ну Прогресс не стоит на месте появляются новые модели которые генерируют помогают рекламодателям генерировать объявления что увеличивает потоки в разы потому что гнева похожее объявления и дальше выбирать наиболее подходящее и хочется это всё модерировать очень быстро предыдущие системы не позволяли модерировать объявление за секунды то есть в лучшем случае это было минут минуты всех этих проблем Мы со всеми этими проблемами мы столкнулись на потоках порядка 100 млн объектов в день но из-за роста потока требо масштабироваться Также хотелось м выдерживать выпадение одного дата-центра и не сильно деградировать и всё-таки добиться exance обработки Ну и третье что хотелось достичь - это увеличить качество а зде и здесь требовалась помощь от инфраструктуры например в предыдущих системах не было единой точки для вынесения вердикта что иногда приводила к гонкам потому что вердикт мог выноситься в разных местах а также хотелось заложить в систему возможность смотреть на связанные объекты потому что как мы убедились объекты вместе могут изменить вердикт чем если их рассмотреть По отдельности Ну и хотелось добавить возможность вносить новые правила новые модели для расчёта фичей довольно быстро и удобно в систему и После всего этого появился bigm bigm - Это новая модерация в основе лежит itus это мы его используем как KV хранилище и транспорт для общения между бинарник нашими основной фреймворк для всех у неё есть поддержка stateful обработки если кратко это возможность шардирование клиентами Чьи объявление мы модерируемые Лок брокер это аналог оч каки и верхней уровн систему можно рассмотреть следующим образом то есть у нас есть клиенты которые пишут в топике свои заявки на модерацию мы их получаем Валиди и отправляем в ядро системы у ядра есть й в котором мы сохраняем все объявления там хранится и также информация о модерации и только он может вписать в это в этот стейт поэтому все мутируют через него а всю модерацию можно описать таким циклом между ядром и лучами где лучи - это определённые этапы проверки например там могут быть как походы во внешние сервисы по htp или ещё что-то результатом каждого луча является разметка которая является как раз ответом этой проверки и это всё идёт в ядро и запоминается и происходит следующий цикл как только Мы готовы вынести вердикт мы отправляем его и дальше рассылаем в сервис клиента на каждое объявление их вердикт все узлы в этой системе это грт процессинг а общаются Они между собой с помощью очередей нас что позволяет горизонтально масштабировать каждый узел так и очереди в результате чего можно увеличивать возможности отдельных узлов системы и всей системы в целом как же описать модерацию в нашей системе для этого используется он состоит из двух частей первая часть - это циклически ориентированный Граф в котором как раз описываются эти проверки в который мы посылаем физически это отправка в лучи а также этот Граф является динамическим потому что на основе текущей версии мы можем включать или отключать проверки а вторая сть это сами правила вые вердикта как на основе той разметки которую мы и сгенерировать его ну и так как типов объектов много и у всех у них разные правила модерации эти все конфиги Уникальны для каждого типа объекта вот так выглядит Граф модерации это какой-то его запуск например вот зелёный Узел это значит что этот этап уже завершился и мы получили разметку и перешли к следующим этапам си значит что этап сечас запущен ме а жёлтый этап мы его пропустили потому что не Выполни какое-то условие Ну а белый он ещё не запущен потому что зависит от запущенного этапа Окей более-менее с модерации разобрались А что представляет собой объект модерации Ну как я уже говорил объект Это набор каких-то стей в отдельные части были отдельными объявлениями что приводило к определённым проблемам Например если нам где-то нужно рассмотреть связанную картинку к баннеру то нужно её подтянуть и на всех таких этапах нужно дополнительно ходить в стейт и запрашивать вторая проблема - это синхронизация связанных объектов А что если одна часть пришла а вторая ещё нет Что нам делать в этот момент как нам дождаться Что делать когда она придёт соответствующие же проблемы возникают и в случае разметок этих связанных частей пото что если нам нужна результат какой-то проверки например картинки как нам понять что она уже готова и мы можем его подтянуть и продолжить свой процессинг Вот это всё приводит к проблемам и усложнению логики поэтому мы решили избавиться от этого и объединить все части в одно целое в результате получается меньше запросов к потому сразу об Ну и как следствие пропадает все гонки и некон систентки для всего единого целого Вот и для конкретных сервисов это уже единая точка с которой они могут работать и соответственно сами графы в объекте меняются следующим образом Теперь у нас есть не один Граф А есть множество графов так как например ссылок может быть много графов тоже для каждой ссылки отдельные графы это всё лежит в одном объекте Вот и все эти графы запускаются параллельно и моделируются О'кей А с объектом разобрались А как теперь устроена модерация представим что нам пришёл Новый объект он доходит до ядра и дальше мы у него есть какой-то конфиг вот допустим такой и мы запускаем первый узел в этом конфиге это у нас автомодерация что проверка на азартно не проходит потому что значение этой фичи меньше порога Ну а вторая проверка запускается и мы её тоже получаем ответ от неё сохраняем и и так продолжаем в результате когда мы собрали всю всю нужную нам информацию на основе этих этих разметок и правил в конфиге мы можем вынести вердикт эти Верди При появлении новых разметок может пересчитывать и выноситься заново что позволяет нам перемогли объекты в будущем просто добавляя новые разметки и с помощью них пересчитывают О'кей с модерации разобрались А как добавлять новые правила в модерацию всем этим занимаются аналитики А это люди которые следят за качество модерации добавляют новые модели придумывают фичи обучают модели и им нужно это всё как-то доносить до нашей системы для этого есть отдельный Луч как раз вот автомодерация при процессинг этот Граф актор то есть запускается в акторно модели что позволяет распараллелить вычисления Ну и для каждого типа объекта он конечно же уникален по для разных типов нужны разные модели разные проверки что порождает ряд проблем например разные графы могут выполняться разное время если их запросы раскидывать рандомно по шардам то при это приведёт к тому что процессинг в среднем ухудшится потому что тяжёлые будут точнее лёгкие модели лёгкие Граф которые выполняются быстро будут ждать пока выполнятся тяжёлые для этого мы сделали динамическое шардирование в данном сервисе то есть мы при отправке туда учитываем текущую загруженность очередей и тип графа и на основе этой информации выбираем наиболее точнее менее загруженный шарт и отправляем в него а единицы процессинга внутри это являются Бачи из атомов атомы - это какие-то объекты построенные на основе объявления например некоторые объявления могут генерить несколько атомов потому что в объявлении могут быть несколько вариантов текстов и все их надо промодель это очень сильно увеличивает нагрузку на автомодерация это уменьшить а иногда нужно собрать все эти атомы вместе и продевать объект в целом для этого есть отдельный тип узлов такие как аренный и вот например ЕС У нас есть конфиг в котором есть пять моделей а C D Ну и например D - это аренный узел то само выполнение в ран тайме будет иметь вид следующий вид ЕС У нас есть например два атома генерация от объявления 0 и о и все параллельные ветки выполняются совестно асинхронно вот Окей модели добавлять научились А что если требуется обновить модель ведь у нас есть какая-то история эти объекты уже могут показываться а новым правилам например не удовлетворять да для этого есть оффлайн они решают несколько задач например как раз пере разметки в прошлое строить регулярный процесс пересмотра вердикта технически можно решать миграцию базы Например если у нас изменились форматы данных Мы можем с помощью аланов переложить весь стей в новый формат соответственно у нас есть отдельный сервис который смотрит на й и обходит его с какой-то периодично но так как стоит большой обходить очень долго и для того чтобы сократить время реакции оффлайн проверок есть отдельные индексы в которые мы можем добавлять отдельные типы объектов и соответственно обходить быстрее тем самым увеличивая скорость реакции Ну и конечно же ещё один случай когда нужны оффлайн - это события из внешнего мира например жалобы рекомендателя на наши вердикт или жалобы пользователе на рекламу это на ВС это нужно реагировать име може на объявление нажать спам и мошенничество это создаться какое-то сообщение которое отправится в bigm в гмоде запустится офлайн модерация То есть это те же графы которые соберут какую-то разметку на основе неё может быть пересчитаны вердикт и вынесен новый Окей добавлять научились изменять тоже А как теперь проверять на самом деле автоматика была сделана для того что всё это модерировать все такие потоки модерировать вручную уже сложно и про Че людей сложно но чтобы проверить обучать и тестировать модели нужны нужна какая-то эталонная разметка её как-то нужно собирать но на текущий момент самый точный - это люди то есть всё это надо как-то прогонять через людей Ну и автоматика не сильна зачастую она отдаёт какой-то промежуточный вердикт то есть сомневается и нам нужно нужно всё-таки вынести финальный вердикт Вот и эти потоки слишком большие для ручной для этого можно заметить что множество объектов имет похожие текст или похожие картинки потому что например может генерируется несколько объявлений об одном и том же и это приводит к мысли к тому что мы можем собрать их вместе и продевать как единое целое А дальше эту разметку распространить на всех то есть мы можем Ну то есть мы не весь вердикт можем получить а только какую-то часть разметки например какие-то проверки мы можем сделать через агрегацию другие проверки через другую агрегацию и так далее Вот и первый подход у нас был с помощью связей то есть Нам нужно какой-то объект модерировать но у нас мы уже умеем модерировать объекты Давайте составим фиктивный Объект который будем модерировать то есть который будет обозначать Вот вот эту группу об вме и добавим его в А все совпадения все похожие объекты которые к нему привязываются мы будем хранить с помощью связи в этом же объекте это работает но это привело к тому что мы начали замедляться потому что этих связей может быть много Они все будут добавляться в этот объект из-за чего мых там будем хранить в виде ключей но объект будет расти что замедляет и чтение запись этого объекта на диск при каких-то изменениях в результате мы решили вынести информацию о связанных объектах в отдельный стей и соответственно у него появился отдельный сервис который это стоит и обрабатывает у нас остаётся фиктивный Объект который мы моделируем то есть это объект который разметка с которого будет распространена на всех кто попадут в его группу но в нём уже не хранятся связи на похожие объекты а вся эта информация хранится в отдельном йте там мы храним все похожие объекты выделяем одного представителя на основе чьих данных мы будем модерировать за всех и храним всю полученную разметку С фиктивного объекта тем самым мы имеем кэш на потоке То есть все следующие объявления могут переиспользовать эту разметку Давайте посмотрим как например создаётся какая-то новая версия Мы хотим как-то агрегировать например похожие картинки мы можем посчитать какой-то хэш от версии и это будет ключ и вот все объекты с одинаковым ключом будут попадать в одну группу этот запрос мы отправляем в агрегатор и который создаёт новую группу Если такого не было инициирует создание фиктивного объекта в ядре в его йте потом этот объект моделируется по обычным правилам у него свои конфиги И после этого отправляет разметку обратного агрегатор который уже рассылает на всех кто попал в эту группу за это время А если группа уже была создана то процесс в принципе похожий Мы также генерируем ключ отправляем добавляем эту версию в существующую группу и при наличии уже разметки сразу получаем ответ без дополнительно модерации Ну либо если разметки ещё нет нам просто её разошли из предыдущего этапа вот эти группы мы можем использовать для разных целей У нас есть два типа групп это динамические Они как раз имеют ограничение по времени и по размеру то есть если размер превышен мы просто создаём новые группы и живут они какое-то время то есть этот кэш не продолжительное время используется и статически они уже имеют не ограниченное время жизни Чуть более сложную структуру в базе данных Но это просто кэш который можно использовать вечно Ну и для управление этим всем У нас есть следующие операции с группами то есть добавление версии в нову в группу удаление версии из группы так как у нас есть статические кластера нам нужно как-то их очищать например версия Уже удалилась Или неактуальна мы их должны вычищать а перебирать представителя потому что иногда может прийти новая версия объявления которая который лучше чем предыдущая То есть она Например у неё картинка больше или ещё что-то и мы можем выбрать его как нового фиктивного и перемороженная это какой-то какие-то произвольные проверки и они не всегда могут гарантировать обработку Для этого нам у нас есть сервис который запоминает все наши события отправки в лучи регистрирует и напоминает нам о том что нужно их повторить то есть на узлы в графах модерации есть время через которое нужно повторить эту проверку Если через определённое время мы не получаем ответа повторяем и после нескольких повторений мы сигнализирует идёт не так на этом всём есть мониторинге который сигнализирует дежурном то есть мы там смотрим за живостью системы также есть какие-то продуктовые а то есть по типам объявлений которые приходят по например клиентам в модерации а входные потоки для каждого сервиса мы тротлит то есть выдерживать какие-то Гарантии и не заваливать систему например отдельными сервисами все бинарки живут в различных дата-центра что позволяет выдерживать поток при выпадении одного дата-центра для ручных вмешательств например чтобы изменить вердикт или посмотреть на текущее состояние модерации как-то визуализировать это всё вносить какие-то ручные правки для этого есть отдельный сервис и что мы получили в итоге в итоге мы получили модерацию на автоматических проверок за единиц секунд сейчас у нас поток составляет порядка миллиардов вердикта в сутки Мы также имеем возможность продолжать масштабироваться довольно легко У нас вносить новые модели расчёты новые фичи новые правила в систему а также мы перевезли все старые типы со старых систем в Новую цию без простой и без какого-то влияния для пользователей и рекламодателей в принципе всё голосуйте за доклад Спасибо так так отлично меня слышно Спасибо большое за доклад у нас механика такая сейчас буду задавать вопросы ты выбирай автора самого интересного вопроса мы дадим ему небольшой подарок хорошо поднимайте свои руки задавайте свои вопросы к вам подойдут с микрофоном Привет Спасибо за доклад тут интересный был поднята тема с акторно моделью и у слов графи которые Насколько я понял По сути обогащают исходное сообщение какими-то чертами на основе которых потом принимается вердикт о модерации и может быть я не слышал может быть не было озвучено я не понял Каким образом акторы друг с другом коммуницируют они коммуницируют через очередь или они коммуницируют Через rpc какие вызовы синхронные вот если они коммуницируют не через очередь то интересно как вы ведёте себя Если в цепочке динамического графа условно в последнем узле заваливается обработка и как вот с этим бороться Ага Ну смотри для выполнения мы используем fror Как точно там реализовано взаимодействие я точно сейчас не скажу а про какие-то завалы и вот это всё То есть если что-то идёт не так то у нас скорее всего встанет обработка всего шарда то есть у нас появится здесь Мы это можем отловить на этапе на стебле или на тестинг то есть такое скорее всего не дойдёт до прода потому что ну мы запускаем похожие модели Поэтому если есть какие-то проблемы они выявят заранее а не знаю что ещё сказать как конкретно реализован именно запуск Вот именно в Акто акторно модели это мы самостоятельно не писали мы просто используем фреймворк а нет мы нет мы не запускаем если если мы в каком-то акторе упали Мы останавливаем весь Ну весь всю весь граф Да спасибо за доклад вот такой вопрос Там много внимания уделялось тому что вы обеспечиваете обработку А общем-то зачем Что будет если там несколько разбое Ну на самом деле проблема может быть несколько Прим это момент может произойти следующее например мы получили какую-то разметку в первый раз и на основе неё вынесли новый вердикт а потом мы или запустили или у нас следующие этапы модерации зависит от этой разметки а второй а второй раз пришла разметка Нона немножко друть мы продолжили на основе первой разметки А следующий этап решения мы в этом графе динамической модерации принимаем на основе второй разметки она может немножко отличаться Ну потому что модели могут отдавать разное Или например в этот момент Может что-то там модель измениться в которой мы например ходим по htp или что-то ещё и соответственно у нас получается сложно восстановить на основе чего принимается модерация пото использовался вроде ответ из одного сервиса но он имеет разные какие-то чуть-чуть например отличается Ну то есть он у Вас как бы не детерминированный процесс на одном и том же запускаете объекте и могут получиться разные а ну процесс не обязательно детерминирован То есть у нас есть например лучи они ходят по htp в какие-то сервисы что как эти сервисы отвечают может происходить разное ещё второй небольшой вопрос вы там говорили что вы нагрузку на сервисы ролите когда большая вот допустим пример приходит жирный Клинт с тями графами Да там обработки он заваливает и приходит мелкий клиент там с одним-двумя там своими объявлениями как это будет разуваться ну сейчас в сервисах это для отдельных сервисов входной поток объявлений он просто он троли внутри системы Мы уже в основном ничего не тролим только в некоторых частях если приходит один жирный клиент нода сго на входе именно вот в систему в саму модерацию Скорее всего он что-то там ну застрянет Но на самом деле там лимиты такие что трот очень редко если честно да ну мелкие они вот вот все все всё что стоит в очереди именно в систему модерации оно будет продолжать стоять но там лимиты говорю сейчас такие что мы практически никогда не Тром вторых сервисах можеть прямо при каких-то супер пиках а так в основном нет то есть мы выдерживаем и нагрузку Да спасибо да спасибо за доклад э такой вопрос У вас было сказано в на слайде про стабильность что тли на каждый конкретный шаг выдаются Вот вы эти ТТ как-то как их высчитывали то есть типа посмотрели Ну среднее время примерно такое или вот как-то Пальцем в небо вот интересно как вы эту метрику взяли ну вы практически ответили в основном это пальца в небо А ну то есть мы с Ну и от части пальца в небо от части среднее время работы то есть есть какие-то лучи которые могут долго отвечать там какие-то тяжёлые проверки соответственно у них лимиты могут быть повыше Но в основном там лимиты Ну может быть там пару минут и и всё то есть ну это лимиты это нужны только если у нас происходят вот нужны какие-то ретрай зачастую Ну это в редких случаях нужно но да в этих случаях Мы немножко начинаем Ну мы теряем объекты но потом всё-таки нагоняем се но да выбор здесь то есть нет никакого то есть они задаются заранее мы их иногда подкручивает Но каких-то простых параметров типа пару минут достаточно для там например htp сервисов и ещё что-нибудь для обычных лучей достаточно да Вопрос Привет Спасибо за доклад У меня вопрос инфраструктурный даже таких два связанных ты говорил что вроде как инфра написано там стейт да очереди самописный они были изначально самописный платформы или это сейчас приняли решение делать самостоятельно и можно ли было бы что-то из какой-нибудь Open Source использовать вместо них так а про очереди это ну вот токи очередь общение между А смотри вот этот стейт и общение это всё это самописная внутри Яндекса но это не нами то есть есть фреймворк грт вот он как раз отвечает за весь этот процессинг общение А через иус с помощью вот этих очередей и также Ну ты - это просто KV хранилища вот А почему это было использовано просто это фреймворк для стриминга в Яндексе он как раз когда Мы начинали набирал популярность вообще в рекламе А ну а также он очень интегрирован ну просто интегрирован с вообще с экосистемы в Яндексе и поэтому его проще использовать чем какие-то свои сервисы поднимать или ещё что что то есть и сразу он и с Лок брокером например и с сеусом То есть это всё поддерживается Ну и ещё один элемент - это нам просто проще поде получать поддержку потому что команды по сути соседние Окей спасибо Привет Спасибо за доклат У меня два вопроса они немножко отвлечённые Вот вы упёрлись в то что существующая система там плюс ещё шедулер какой-то над ней не позволяет вам достаточно мелко нарезать Бачи и exactly One обработка Вот вы приняли решение делать своё полностью команда сколько это заняло времени Ну смотри Вот начало это дся год То есть 3 года назад Вот 3 года назад началась как раз разработка Вот это Биг мода и вот вот это всё результаты за 3 года и в прот это выкатилось первая версия Ой впт это по-моему я не помню то ли я не помню двадцать пер или двадцать второй год окей а второй вопрос я сам аналитик Вот мне интересно как вы то что у вас реи это типа маленькие базовые кусочки наверняка же можно накрутить дашборды замерять качество каждого кусочка то есть сделать жизнь аналитиков гораздо проще Ну аналитиков есть такие мониторинги то есть Ну смотри а вот эти реи даже тут не совсем на Рей нужно смотреть нужно смотреть на разметку которая получается потому что некоторые реи могут например одну и про одни и те же проверки быть немножко с разных сторон например вот и вот да на конкретной разметки и качество конкретных проверок Они конечно смотрят То есть это ну ну то есть это какая-то там у них например есть какой-то веб-интерфейс Ну то есть типа для по-человечески сделано Ну графики для графиков есть веб-интерфейс как это всё считается Ну у системы есть просто логи в которой мы записываем всё что у нас происходит всё что мы получаем и на основе этого уже строится Ну то есть это всё собирается А дальше агрегирующие Ну при обработке какого-то рекламного сообщения оно условно бьётся вот на вот эти вот лучи далее каждый Луч производит обработку и в конце принимается решение вот интересно используется ли при этом нечёткая логика допустим там при определённом коэффициенте допустим если там один из лучей там из десяти дал ошибку то тогда типа тогда сообщение может пройти либо же у вас там жёсткая если хотя бы одна из проверок дала отрицательный результат значит А я понял Да хороший вопрос А ну вот я говорил про как описывается модерация То есть у неё есть какой-то конфиг это Граф модерации и набор правил по которым мы на основе разметки выносим Вер про сами правила я рассказать не могу но то есть мы то есть не только что есть одна проверка дала Нет мы выносим нет то есть возможно какие-то условия то есть там есть оде есть арифметика какая-то рас вообще различ причин отклонений и так далее То есть то есть это Это довольно сложная логика потому как выносить вердикт на основе той информации которую мы собрали как её всю объединить и так далее Ну да да да да И каждый раз мы её так пересчитываются новые какие-то какая-то информация и вот сечас получилось то что те были в трансляции не услышали ваш комментарий ладно так вопрос ещё есть вопросов больше нет Дим тебе надо выбрать автора самого интересного вопросам по твоему мнению все вопросы хороши Ну давайте вот мне понравился вопрос про как мы всё-таки вы считываем вердикт это заключительный Да это интересный способ давать выбирать лучшим лучши вопрос заключительный очень удобно Я как ведущий часто такое замечаю давай как будто ты сам транжира заключите Не потому что запомнил после нет действительно выбирал между например вопросом о грт и вот этим А ну ладно верим так а пожалуйста подарок автору самого интересного вопроса А я сейчас вручу тебе подарок от нас А спасибо тебе большое за твой доклад Спасибо Вам спасибо вообще за ваши продукты которые вы делаете Это был Дмитрий Латышев из Яндекса Вы можете сейчас его помучить вопросами там если у вас ещё остались всё большое спасибо и мы расходимся на небольшой перерыв Y"
}