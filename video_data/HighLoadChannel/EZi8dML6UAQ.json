{
  "video_id": "EZi8dML6UAQ",
  "channel": "HighLoadChannel",
  "title": "Долгоиграющие приложения в PHP /Александр Пряхин (Авито)",
  "views": 763,
  "duration": 2899,
  "published": "2023-10-06T07:15:06-07:00",
  "text": "Приветствую всех Меня зовут Александр Пряхин и сегодня буду рассказывать вам о долгоиграющих приложениях в PHP чем занимаюсь в свободное от конференции время я руковожу командами в компании Авито вообще в руководстве командами с 2014 года пролить с этим преподаю Да и наверное хватит уже обо мне давайте приступать непосредственно к теме сегодняшнего моего доклада о чем говорим коротко об адвенти посмотрим на работу PHP скрипта by Design как он у нас соответственно должен работать сам по себе посмотрим на типовые задачи за пределами этого поведения посмотрим на разные кластеры задач которые могут быть решены параллельными вычислениями вычислениями поговорим о реализации демонов больших обработок и сделаем для себя конечно же выво если мы посмотрим на историю языка PHP то конечно же не сможем не столкнуться с фразой о том что PHP рожден чтобы умирать и когда-то давно если там полистать старые формы можно увидеть о том что информацию о том что PHP плохо обрабатывает большие данные PHP течет по памяти не умеет многопоточности вообще есть прекрасно язык и Зачем нам нужен PHP как раз таки на экране есть qr-код на статью одноименную печь перерожден чтобы умирать которых Вы можете При желании почитать но нахабре я думаю многие из вас ее уже видели по дизайн печки у нас работает Каким образом у нас есть запрос веб-сервер у нас принимает передает его на выполнение сапием дальше мы идем базу данных оттуда вытаскиваем какие-то данные и формируем ответ возвращаем его пользователю то есть инициируемся пользователем никто не помним между запросами и работаем по сути миллисекунды Ну на край несколько секунд если небольшая страничка homepage на sharposting но когда мы говорим о проектах которые живут уже какое-то время у нас появляются производные задачи например у нас есть проект и к нам приходит бизнес говорит что нам вот хочется построить отчет за год с разными средствами А еще мы не хотим по крону каждую минуту обрабатывать события Мы хотим сразу на ивент реагировать еще раз приходит очередь события Мы хотим их слушать а еще нам когорт и хочется вообще мы хотим двх построить и кажется что появляются какие-то новые задачи которые как-то надо решать и по сути из перечисленных задач что мы видим какие у нас есть классные проблемы с одной стороны у нас есть обработка большого объема данных для отчетов с другой стороны нам нужно данные в небольшом количестве обрабатывать но реагировать сразу и слушать постоянно и конечно же все это уже у нас не укладывается в PHP by Design работу то есть все это работает условно дольше нескольких секунд и требует какого-то более сложного подхода Капитан Очевидность приходит к нам и говорит лишь другие языки Давайте возьмем то же самое гор и будем писать на нем Замените по любым другим языком которым больше нравится но что мы здесь видим с одной стороны Мы можем взять и принести команде учебник курсы менторы как угодно и команда будет учить новый язык экспертизу команды при этом не будет команда у нас будет дорожать Ну ребята такие же выучил новый язык программирования Давайте ко мне повышать зарплату Я молодец и конечно же мы будем собирать здесь разные грабли Как видим не совсем идеальное решение не Серебряной пули с другой стороны мы можем нанять готового специалиста с рынка он придет заходит Все у нас все это появится но будет ли человеку достаточно задач и здесь уже явно идет удорожание потому что специалист рынка это дополнительное место в команде Дополнительные расходы на фонд оплаты Да и мы начинаем задаваться вопросом так ли плох PHP Действительно ли там нельзя решить вот эти задачи и Давайте попробуем разобраться на примерах как я уже сказал у нас есть два кластера проблем Это большие обработки и соответственно темы начнем мы с больших обработок вообще обработка классическая выражается чаще всего в том что у нас нужно обработать какой-нибудь огромный отчет что у нас происходит Мы хотим строить отчет наш мы набираем большой данных трансформируем как ты его преобразуем склеиваем эти данные строим какую-то структуру из них и в итоге формируем представление казалось но Естественно с ростом нашего приложения с ростом объема данных у нас естественно и проработка этого отчета она будет разрастаться по времени по ресурсам Это не круто чем здесь можем столкнуться во-первых если мы набираем скрытые данные у нас может быть очень много либо у нас может быть много различных источников откуда разбирать если данных много понятно там ненужных себя обойти если много разных источников Нам нужно в каждый источник сходить и понадергать оттуда данных с другой стороны в момент трансформации у нас уже собраны эти большие данные нам нужно соответственно как-то склеить и опять же их либо много либо какая-то сложная логика склейки либо это и другое вместе И с этим нужно будет как-то Бороться и первый хит которым можно соответственно уже идти и работать исправлять все что нужно это потоковая обработка то есть мы читаем только то что хотим обработать Здесь и сейчас например мы получаем порциями данные из ну скажем большого какого-то источника файла неважно чего то есть Типовая жидкость Я хочу получить все и сразу и обработать так делать конечно же не надо и здесь нам на помощь приходит старый добрый генератор на самом деле Здесь даже можно решать Это задача без многопоточности оборонности но у нас есть оператор собственно ялт это то что у нас выбрасывает данный момент получения их на то есть мы не собираем все что мы работали Из нашего файла в одну большую переменную мы выбрасываем сразу же по обработке полученные данные объем памяти у нас равен размеру самый большой части то есть мы не работаем со всем файлом например Мы работаем с одной строчкой не происходит аллоцирование памяти для промежуточного хранения по факту сразу выкидываем результат и на выходе Мы тоже должны обрабатывать этот результат правильно И на самом деле если вы будете примеров о том что действительно Давайте выбрасывать эти данные и сразу же все будет хорошо но на самом деле нет Если вы их будем выбрасывать и дальше с другой стороны какие-нибудь фары чем складывать их в какую-то консолидированную переменную или в массив И так далее У нас рост потребления памяти будет каждый раз кратным с каждым накоплением у нас это будет вырастать вырастать вырастать особенно если мы там начинаем работать с массивами там вообще рост будет очень интересный характер носить Кому интересно можете попробовать если мы хотим действительно экономить Память то и на выходе Вы должны соблюдать правила обработки То есть как только нам приходит какой-то кусочек результата мы его процессе и либо выкидываем промежуточное хранилище куда-то быстро и Кэш и еще что-то в этом духе но ни в коем случае не сохраняем то есть мы должны понимать что мы работаем с конкретно маленьким кусочком данных Только тогда мы будем действительно экономить нашу память в противном случае мы будем ее расходовать только не вместе обработки а на выходе там где мы это все дело консолидируем и начинает жрать ресурсы но опять же таки А если файл большой мы его обрабатываем при помощи генераторов возникает вопрос Это же долго как здесь быть нам не хочется ждать и мы хотим обработать все быстрее можем распараллеть можем взять и наш большой кусок данных попилить на кусочки поменьше каждый из этих кусочков своей обработкой обработать и промежуточные результаты консолидировать в один Google определился и получаем очень похожую картинку но по факту он как раз таки в этом и состоит параллельное вычисления в PHP Конечно же да Там могут быть представлены различные фреймворками параллельные и асинхронные если начнете гуглить опять же то у вас скорее всего там выдаст сволол потому что в принципе это Достаточно мощный фреймворк который помогает здесь крутить PHP достаточно классные штуки но как раз когда я работал над этой презентацией вот я столкнулся с таким интересным комментарием что это будет еще один доклад про роутера и прочее Но конечно же я перед собой такой цели не ставил Именно поэтому здесь я хочу вас познакомить непосредственно с труп параллельными вычислениями в PHP а именно библиотекой которая начиная сhp72 может организовывать полноценную многопоточность и параллельный вычисления в PHP по сути Что такое паралле это такая альтернатива Петра it который у нас уже был Достаточно давно и подвергался критике в отношении безопасности и так далее У нас при этом наш параллелол он доступен с версии 7.2 и выше и по факту мы здесь имеем полноценные потоки А не корутины а по qr-коду можете посмотреть на то что из себя представляет в документации но тем не менее Давайте немножечко здесь разберемся с терминологией потоки и корутины как бы их не спутать поэтому начнем мы с синхронного выполнения кода У нас есть системный поток мы запустили мы можем там стоп зайти увидеть нас есть PHP поток мы с ним работаем в нем У нас есть главный вызов у него есть дочерние так далее У нас есть полноценный стэк вызовов и по сути А если у нас условно есть два метода главный дочерний то один поток выполнения он нас так и есть в нем вызывается главный метод он вызывает дочерний и вот пока дочерние у нас не завершится мы в главной не переключимся то есть нас есть блокирующий вызов и мы ожидаем завершения то есть вызывающая функция ждет полного завершения вызванной если мы говорим про концепцию корутин которая кстати говоря в PHP тоже представлена С недавнего времени но сейчас это тоже углубляться не будем то в данном случае мы можем осуществлять квантование У нас есть главный поток Мы переключаемся в нашу рутину запускаем ее например начинаем отправлять запрос в какой-то момент мы из этой корутины можем передать выполнение обратно нашему основному потоку Например если мы знаем что запрос будет выполняться долго и мы хотим вернуться к нему только в тот момент когда он у нас будет обработан соответственно выбрасываемся обратно в главный поток работаем и возвращаемся к рутину только когда туда пришел результат по факту Мы работаем все в том же одном потоке и точно также Передаем выполнение между различными методами но один метод уже здесь не блокирует другой и другой метод Может в какой-то момент собрать на себя там работу мы можем передать туда выполнение и он будет сам по себе работать при этом мы можем еще асинхронно работать вне зависимости от главного потока вот если мы говорим про потоки полноценный то у нас здесь уже появляется независимые независимой обработка Параллельная то есть создание потока у нас является более дорогой операции но при этом все операции уже идут строго параллельно если мы отправляем 5 запросов все эти пять запросов будут идти параллельно они не будут блокировать друг друга и при этом данные которые будут получены будут оставаться непосредственно в потоках по сути разница между корутин и здесь если кто еще для себя не осознал в том что корутина она не блокирует основной поток Но работает внутри и обеспечивает асинхронную работу то есть работу по ивент Луку по событиям потоки это уже выделенные сущности с параллельной работой и зачем собственно нужны картины и потоки рутины специализируется на том чтобы снизить общую нагрузку на систему за счет того что мы квантуемся между нашим выполнением различных методов мы можем более эффективно расходовать выделенные нам ресурсы То есть у нас не будет как такового нет простое с другой стороны есть потоки и потоки они не про экономию ресурсов они именно про ускорение каких-то сложных вычислений то что можно выполнить в параллель и потом консолидировать но при этом конечно же в потоках про экономию ресурсов речи особенно не идет теперь посмотрим как это у нас выглядит непосредственно в фреймворке перлал как у нас будет выглядеть код Итак после того как мы подключили нашу библиотеку мы можем соответственно создавать основные классы которые нам там доступны Ну и самым таким базовым классом там будет класс runtime в которой у нас будет создавать новый поток на то есть мы сохраняем его соответствующую переменную вызываем метод Run если кто-то изучал какие-то другие языки со встроенными многопоточностью могут здесь увидеть сходство В общем здесь ничего не стали принципиально нового изобретать нас есть основной поток в этот момент запускается новый поток наш вот рантарь но при этом сам runtime когда у нас выполняется он может принять на вход некий метод который будет выполнять внутри себя по сути это Тип closer который представляет из себя какую-то функцию что-то мы делаем внутри нашего потока и в итоге естественно мы можем возвращать какие-то значения по результату работы Наш поток он отдает свои результаты в объект типа Future а то есть мы можем вернуть в основной поток то что наделал наш поток дочерней согласись это удобно для Обмена информацией при необходимости При этом когда мы соответственно Передаем эти значения Мы например можем Future вызвать метод вылью и он нас выведет то что возвращает непосредственно перед наш Task внутрь нашего потока но в целом здесь мы дожидаемся результатов работы потока и вроде бы все хорошо как правило многопоточность у нас возникает необходимость шаринга между потоками каких-либо ресурсов например хотим работать каким-то одним консолидирующим объектом в режиме реального времени туда будут поступать данные допустим когда консолидирующий объект набирает себе достаточное количество информации допустим завершаем выполнение и отдаем его наружу то есть какой-то некий общий ресурс условно перемены или еще что-то или объект и вот как раз таки в parell для этого существует класс Channel класс Channel здесь оборачивает эти общие ресурсы он передается у нас непосредственно в Task и через него мы уже можем общаться между потоками через Channel то есть обмениваться какими-то данными У нас есть отправка данных это метод ресив Чем точнее получение данных и отправка это соответственно с при этом Channel у нас является потоком безопасным вам не нужно Здесь заморачиваться на тему индексов на тему того что у вас будет состояние гонки то есть Чем является полноценной оберткой для расширенного ресурса и он уже решает все вот эти классические проблемы обмена данном то есть мы поддерживаем передачу замыканий В наши каналы при этом Обратите внимание что если мы в канал Передаем в Абакане оно у нас кашируется что круто то есть для каждого Нового потока не нужно будет по новой интерпретировать этот код у нас передается уже закошированные замыкание что у нас естественно ускоряет работу нашей системы в целом в этом если вам не нравится Channel по каким-то причинам Вы можете использовать класс Sync и написать своим ютексы и в принципе жить так как вам больше нравится в многопоточном мире при этом можно работать с Event loop то есть класс ивент Вы можете реагировать на события отправки получения данных и так далее В принципе библиотека достаточно богатая и по опять же qr-коду можете перейти посмотреть на еще одно видео с бенчмарком с примерами и комментариями как раз таки о том как расходуется ресурсы в нашем непосредственно многопоточным приложении и как оно в целом строится при этом есть особенности до работы нашего Перла во-первых это что пока еще достаточно скудная документация по нему Несмотря на то что появился он еще в версии 7.2 но небольшой опыт сообщества он дает о себе знать информацию найти попэрол достаточно сложно Поэтому пока это все еще нарабатывается тем не менее это действительно готовая библиотека многопоточности при этом сборка в доке она заставит попотеть вообще в принципе в контейнер потому что там нужно по изгаляться с подключением дивак потоков Естественно он будет требовать специфических решений потому что вам нужно будет смотреть в каком потоке произошел отвал то есть добавлять какие-то метрики было понимание там в одном потоке произошла ошибка в разных и так далее и еще раз это не снизит расход ваших ресурсов это позволит вам ускорить сложные большие вычисления поверх большого объема но опять-таки Да мы уже посмотрели с вами Channel но Channel это какая-то перемена А что если нам нужно работать Ну например с базой данных и здесь мы должны понимать что в любом случае шаринг ресурсов он нас возможен только между потоками между процессами А если у нас есть процесс который запустил у себя несколько потоков внутри и другой процесс который тоже запустил несколько потоков внутри уже обмен через Channel тоже точно также не получится то есть это просто здесь будет идти только через внешние системы здесь конечно же тоже есть аспекты которые вы должны учитывать когда работаете с многопоточным приложением Самый классический пример Да это состояние блоки У нас есть два потока в двух разных процессах которые лезут в одну и ту же базу У нас есть один процесс который читает количество товара а получать значение в этот же момент у нас второй поток во втором процессе читает количество этого же товара тоже получает количество X в этот момент у нас количество товаров допустим обновляется кто-то что-то купил на и тут же соответственно второй процесс 2 потока тоже обновляет Это количество соответственно они оба будут отталкиваться от x на полученного самом начале а не от обновленного значения конечно же здесь решением будет введение транзакций транзакции позволят нам обеспечивать Необходимый уровень изоляции данных и позволят нам не беспокоиться о том что один поток перетрет данные другого потока но здесь нужно понимать транзакции они могут снизить скорость работы нашего приложения Потому что когда у нас одна транзакция начинает блокировку обновление другие соответственно станут в очередь высокой нагруженных приложениях Да это может приводить к тому что какие-то транзакции с большим количеством обновлений данных они могут реально замедлять нашу работу вплоть до блоков Да иногда у нас два процесса стартанули транзакции сначала первой обновил количество товаров Table один Второй обновил у себя Table 2 и дальше хотят перекрестно обновить данные естественно начинают ждать друг друга в этот момент у нас случается деплок они не могут дождаться разрешения этой проблемы как мы здесь решаем проблемы Ну во-первых это товарность транзакция то есть не нужно загонять 25 штук обновлений в одну транзакцию и ждать что они там дружно выполнится то есть Старайтесь разбивать транзакции по смыслу например два запроса один Селект по апдейт второй апдейт все круто Здесь у нас получается Товарная транзакция два запроса Никто никого ждать не будет если у вас идет огромная взаимодействие то конечно же здесь Локи реально будут увеличивать свои шансы при еще одна интересная вещь Это порядок обновления посмотрите если мы сначала обновляем в одном потоке аккаунт один потом аккаунт 2 а во втором потоке сначала аккаунт 2 потом аккаунт один здесь нас случится дедлок это как раз таки пример из документации например пострия с которым можно столкнуться и вот если мы поменяем здесь порядок то есть сначала обновим аккаунт один потом аккаунт 2 к не случится вот такие аспекты тоже нужно держать уме именно порядок обновления чтобы у нас не было такой проблемы То есть помимо товарности транзакции нужно соблюдать именно этот порядок Ну и конечно же блокирующие запросы то есть запросы на обновление данных вставка апдейт соответственно удаление они все должны быть максимально приближены к концу транзакции для того чтобы другие запросы которые более низкий уровень блокировки успели в этот момент это соответственно аспекты именно больших обработок которые у нас требуют многопоточных вычислений Теперь давайте перейдем непосредственно к демону вернемся к нашему примеру с отчетом мы строим отчет набираем сырые данные трансформируем их и формируем представление набираем сырые данные А что если к нам сырые данные приходят поставщика и нам нужно их получать вот здесь и сейчас через API мы формируем крон ждем обращения но мы ограничены то есть крон у нас запускается раз в минуту если данный приходит например чаще мы не сможем здесь ничего сделать конечно же поэтому Давайте слушать события запускаем скрипт wild.ru ждем каких-то событий событий случается мы его обрабатываем и соответственно возвращаемся в ожидании У нас есть непрерывная работа перманентное соединение допустим с источником не обязательно у нас появляется мы не сами запускаем какую-то обработку А мы именно ждем события и мы можем ответить на события по результату то есть выполнить какой-то колбек Ну понятное дело что самый простой вариант этого выполнить wild.ru и все будет у нас вроде как работать но по факту процесс у нас никак не отслеживается на то есть мы его можем только грохнуть через хальт через консольку и по сути это процесс широки мы не понимаем что происходит внутри какие у него там внутри идут операции вообще как за этим всем следить поэтому конечно же здесь старый добрый писем тело нам помогает цикл внутри конечно же никуда не девается но если мы используем расширение наше то демон внутри себя уже будет знать свои мы запускаем основной процесс от которого делаем форк налоги на самом деле с потоками и мы уже можем здесь реализовать реакции на сигналы то есть мы можем например сделать если мы делаем хайп какой-нибудь то у нас что-то писалось базу данных какой-нибудь результатов мы сделали все Согласно половина не записалась данный покрашены потеряли консистентность и все очень не здорово а если мы дружим с позиции если мы дружим сигналами мы можем послать туда Grace for restar то есть мы понимаем что случилось старт и мы можем описать логику которая будет дописывать текущую на итерацию как ты коммитицы или еще что-то и после этого уже останавливаться как это выглядит на практике когда мы берем и запускаем наш многопоточный тест у нас запускается основной процесс и от него форкаются на вот здесь Как видите на верхнем экране 4 процесса и они же отображаются у нас в запуске тоже по ссылке на qr-коде Сможете посмотреть это библиотека на гитхабе с простым примером многопоточным с которым может сами поиграться такая песочница для тех кто хочет познакомиться именно я здесь упомянул слова многопоточность но в другом контексте это конечно же запуск именно форков процесс нашего многопроцесс так потому что можем запутаться здесь это немногопоточность это именно дочерние процессы при этом конечно же мы получаем здесь возможность реагировать на появление новых событий у нас работает демон он слушает события он сам по себе мы можем отслеживать появление новых записей например в базе данных если нас используется очереди там очках или мы можем слушать очередь И точно также реагировать там тут же на появление наших записи то есть уже не по крону а именно через наш демон более того мы можем вообще через демон слушать какой-нибудь unix или tcp Socket где будет уже более низкоуровневая передача данных на где мы будем непосредственно слушать клиента подойдет если клиент у нас железки например работает В той же инфраструктуре если у нас соответственно есть соединение с каким-то внешним источником данных Мы хотим более легковесные данные передавать для того чтобы ускорить об информация это тоже можно делать через непосредственно PHP во-первых потому что есть модуль Event на этот набор классов которые позволяют организовывать ивент-тревин логику И также у нас есть модуль сокет это набор классов которые позволяют работать с интернет сокетами сетевыми он так называется Это непосредственно соединение с unix Socket то есть с неким файликом сокета через который идет обмен какие здесь есть аспекты работы Ну во-первых да когда ходили по собеседованию наверняка сталкивались с серии Как устроена память в PHP и если кто готовился к этим собеседованию на то знаете что у нас задавал контейнер у нас живет в памяти пока на него есть ссылки что это для нас означает в аспекте демонов То есть если у нас есть какой-то массив или дата который мы накидываем накидываем наши данные на которые у нас поступают и никак не очищаем этот массив вы просто все сохраняем то с ростом с ходом времени Наш массив будет разрастаться разрастаться он будет достаточно быстро если у вас много событий появляется в системе накопление данных будет реально давать вам утечку памяти данные которые вы не используете они будут жрать вашу память в какой-то момент у вас процесс грохнется потому что сожрал очень много ресурсов киллеру бьет поэтому здесь помогают те же самые генераторы на то есть мы опять же возвращаемся к парадигме работает только с тем что нужно тебе здесь сейчас прямо в данный момент плюс у нас PHP держит открытым одно соединение к базе на пользователя в момент времени В нашем процессе и это соединение может залипнуть поскольку демон у нас работает днями часами даже больше и соединение вроде как есть но данный по нему не ходят до такое случается действительно не только базы данных но с другими ресурсами первым делом лезем на форумы видим там а Используйте персид Connect он здесь ничем не поможет у нас и так висит одно соединение с базой данных внешним источником и какая нам разница Персидском PHP соединение нас будет висеть пока не остановится процесс то есть как-то надо мониторить возможность соединения процесс Один работает долго и не получится быстро отследить отвал потому что Вы его запустили он вас где-то болтается там на сервере вы туда заходите там нельзя раз в неделю посмотрели Ну вроде работает он может через пять минут залипнуть вас неделю будет болтаться вот души процессы потом узнаете что у вас ничего не отработано можно решить конечно проблему в лоб Мы можем взять и рестартнуть демон принудительно Но это конечно снизит вероятность залипания но при этом не гарантирует того что их вообще не случится в рестартанули через пять минут процесс залипа он вас там допустим раз сутки рестартится оставшиеся сутки он висит залившей вы ничего не сделал решение по умнее мы можем отправлять какой-то тестовый запрос то есть мы должны сделать некую ручку проверки нашего внешнего ресурса нашего Демона когда мы туда Просто дергаем отправку запросы и смотрим если нас допустим запрос не укладывается в какое-то количество там секунд или секунд то мы считаем что демон у нас грохнулся А верте ему надо перезапускать это уже лучше потому что мы можем повесить мониторинг Можем отслеживать и работать и конечно же epm это уже Application performs мониторинг тузы здесь мы можем использовать эластика ПМ юреели пинба То есть все что умеет дешево и быстро сохранять трейсы Да ни в коем случае не XD бактебак вам демон очень сильно переусложнит он тяжелый и его используют в продакшн средах не надо нужно использовать именно ПМ расширение например на вашем экране ластика по сути вы ставите его как модуль к вашему PHP и он начинает автоматически собирать трейсы в себя и показывать проблемы если кто-то работал с нереликом юриллик Это вообще из коробки отлично делает а также может отслеживать какие-то ручки и так далее Поэтому в целом апм это уже следующий шаг который вам поможет сделать выполнение скрипта не просто отслеживаем но и смотреть как эволюционирует потребление ресурсов при помощи и Да если нужно где-то Вы можете там что-то уже оптимизировать понимаем Откуда вы Здравствуйте демон Может у вас зависнуть упасть и за критических изменений окружения То есть если допустим у вас расширился или сузился диск если у вас какие-то сетевые настройки поменялись Поэтому нужно отслеживать опять же состояние Демона и уметь его переподнимать Поэтому мы с вами уже обсудили тел и здесь он очень становится важным потому что как я уже сказал обязательно нужно иметь Грейс пол возможность рестарта для того чтобы у нас демон мог остановиться закончить текущей обработки и только тогда дать возможность его рестануть по сути У нас есть точка запуска демонов которые у нас создаются наши демоны при этом Вы можете прописать там запуск нескольких демонов которые будут висеть уже в системе на выполнение вы через эту точку доступа опять же можете посылать туда сигналы которые вам нужны да то есть жесткая терминирование и вы можете хранить соответственно айтишники запущенных демонов точно так же понимать а вот это вот демон у меня обрабатывает вот этот API вот этот демон следит вот за этой очереди И для этого уже построить мониторинг А и сюда же мы можем уже прикручивать холстек ручки к этим демоном который мы уже с вами обсудили А и подвешивать их в апм в общем-то можем контролировать наш демоны постоянно такие здесь еще есть особенности именно долгоиграющих предложений это DNS дело все в том что FM и PHP они могут кэшировать DNS на момент запроса и если у нас fpm отрабатывает за несколько секунд Все попроще то PHP демон который запустился из-за кэшировал DNS на момент своего запуска и работает он допустим полгода Если вы понимаете что у вас есть внешние ресурсы которым вы обращаетесь не по IP адресу именно доменами имени если адрес у вас демон приляжет поэтому здесь конечно же нужен мониторинг Вы должны понимать что лучше все-таки использовать более низкую уровень подключения потому есть такая проблема здесь реально есть Поэтому демоны у нас должны подчиняться следующим правилам то есть Демона у нас требует атомарности не нужно в один демон пихать все подряд то есть один демон один процесс как в докере соответственно Чем меньше зависимости тем лучше а не нужно напихивать туда сразу все библиотеки которые вам нравятся здесь примерно когда там контейнерами которых есть минимум того что вам нужно также здесь досмотрите отталкиваетесь от головы PHP потому что Чем больше тем больше будет расход ресурса тем выше будет риск того что вы где-то напишите код с утечками но здесь опять же не виноват PHP Да виноват тот кто на нем пишет И конечно же минимум в зависимости нам в этом плане помогает при этом аспекты сборки они тоже будут иметь свое место Потому что когда мы собрали протестировали упаковали наш демон старшая версия как я уже сказал опять же должна уметь завершить текущую обработку остановиться при том что у нас принципе демон терпит переключение мы остановились опустили новую версию мы должны отслеживать Какая версия Демона У нас сейчас работает на продакшене то есть Где он должен себя каким-то образом идентифицировать поэтому мониторинге неплохо Да там отслеживать какие-то сигнатуры этого Демона какой версии он нас работает в принципе можно сделать то же самое ручки То есть она отслеживает и то что демон работоспособен что-то ничего не залипла и Какая версия Демона сейчас крутится на проводе на то есть мы после этого перезапускаем новую версию и в мониторинге Видимо что у нас запустилась версия там 1:11 и мы с ней работаем какие выводы мы можем сделать из моего короткого и быстро рассказа во-первых то что PHP жив живее всех живых продолжает развиваться не обязательно брать новый язык программирования если перед вами встают принципиально новые задачи Посмотрите сторону того что вы уже имеете у себя на продакшне Как вы можете это переиспользовать при этом думаете не где а когда Как говорила И направленность фильма Назад в будущее когда вы разрабатываете демоны или большие обработки думаете на более далеком горизонте чем несколько секунд Ну и конечно не стоит забывать о мониторинге кэширование расшаривание ресурсов то есть добавляется потому что в принципе новый Пласт разработки но за счет этого вы получаете выигрыш в том что вы не тратите ресурсы на изучение нового языка на новых программистов и получаете конечно же пакет новый функциональности на этом У меня все по qr-коду на ваших экранах Вы можете перейти по ссылке и заполнить опрос непосредственно о выступлении понравилось не понравилось что можно было сделать лучше Ну и я буду Конечно рад любой обратной связи Надеюсь что мой доклад был для вас полезен Я готов отвечать на ваши вопросы здесь на последнем слайде пока у вас будут соответственно qr-коды на материалы которые я упоминал непосредственно в своем докладе и мои контакты с которыми вы можете ознакомиться Спасибо готов отвечать на вопросы а теперь нам должны Александра будут подключить Чтобы он смог в прямом эфире ответить на вопросы и у меня там естественно большая просьба которую буду много раз сегодня повторять не забывайте переходить по qr-коду и оценивает доклад как Олег сегодня говорил эти оценки очень важны для того чтобы сформировать программу следующей конференции потому что именно на основе этих рейтингов программные комитеты принимают решение кому в первую очередь идти и просить О докладе так у нас получится Александр подключить Ура Александр привет Привет всем так Ну что друзья у кого есть какие-то вопросы после доклада на самом деле это уникально очень история Александр Тебе наверное не было видно зал но у нас был практически полный зал для онлайн записи это прям такая исключительно и классная ситуация Итак друзья Если есть вопросы задавайте их пожалуйста Напоминаю что за лучший вопрос мы будем дарить подарки Я вижу руку Пожалуйста передайте микрофон Уважаемый хелперы Да все бегут уже вот сейчас секундочку Готовьте вопрос У нас есть достаточно времени Несмотря что начало чуть-чуть сдвинулось но мы все отлично успеваем прошу раз Александр Спасибо за доклад Меня зовут собственно Тарасов Сергей ламка вот у меня наверное такой вопрос Мы говорили про многопоточность много процессорность вот Насколько я понял а больше у нас создается процессы у главного потока Да и Если умрет главный поток и все дети его погибнут правильно понимает первый момент и второй момент Можно ли создавать а не процессы дочерние а сами потоки главные которые уже будут генерировать себе какие-либо процессы Возможно с помощью демонов как-то и так далее собственно всё хорошо спасибо за вопрос Если мы говорим про многопоточности многопроцессорные Здесь очень важно на эти вещи если мы говорим про точность здесь мы рассматриваем нас потоки запускаются в рамках нашего приложения не создаются на уровне операционной системы и тогда у нас все исполнение Если через мы имеем уже возможность создавать дочерние процессы Как через основной также с ними и работать на уровне операционной системы если говорить про создание следующих основных процессов то тут я бы попросил вас немножечко скорректировать что вы здесь хотите именно получить Я вот как раз про создание отдельных потоков именно на уровне операционных систем не чаял да под потоков А вот именно отдельного самого потока нового полностью отдельного независимого который уже в себе сам будет генерировать своих чаядов и так далее вот просто когда родители умирает насколько я знаю умирает все его потомки на уровне 57 Не важно кто его убил вот все потомки умрут а как-то разделить чтобы есть небольшой лак Поэтому да заканчивать вопрос я тогда закончил В принципе вот и понятно Спасибо здесь если мы говорим про создание именно мастер потоков то есть запуск то скорее уже стоит смотреть на системные инструменты которые будут явно запускать эти потоки по каким-то триггерам Ну что сейчас напрашивается Ну понятно в лоб это какой-нибудь там крон Да который это всё будет запускать но это совсем неправильное решение А лучше смотреть в сторону того же самого symd который уже позволит управлять запуском в более гибком формате супер Спасибо огромное У нас есть ещё один вопрос пожалуйста дайте микрофон Если вдруг вы стесняетесь задавать вопросы Ну во-первых капитанский совет не стесняйтесь А во-вторых можно задать в чате там может быть не так страшно и потом вопросы тоже можно задавать Александр будет рад ответить это на всякий случай за Александр отвечаю хорошо Александр здравствуйте Спасибо большое за доклад Меня тоже зовут Александр Александр вот такой момент если бы не поднимать глаза на конференцию И назвал то было ощущение что вы говорите про Go и отсюда холивар не будет вопрос зачем такую задачу перекладывать на PHP если мы можем прикладную задачу которая нужна для конкретного бизнес домена так скажем мы можем решить ногою где уже под капота всё супер мега тредовая оптимизированы и так далее Спасибо Александрович приятно Спасибо за вопрос так постарался зацепить эту тему в самом начале своего рассказа Зачем нам вообще PHP Когда мы можем взять гуг мы все прекрасно понимаем что мы работаем в которых деньги не являются бесконечным ресурсом и добавление языка в стек простить поскольку работа больше разработкой но тем не менее любой язык он стоит денег поддержание любого языка стоит денег предположим У нас есть компания там небольшой формат который есть уже ряд программного обеспечения написанного на PHP есть команда которая понимает как это все работает и внедрение нового языка это всегда достаточно большие накладные расходы что как я уже сказал либо нанимаем новых людей которые будут писать на Гоа на которые соответственно стоят отдельных денег Их надо загружать каким-то образом еще не факт что загрузим Либо мы переобучаем текущую команду и там собираем шишки там грабли и прыгаем Вот в этой темной комнате с граблями для того чтобы научиться действительно делать быстрые вещи на а не просто писать какой-то скриптик поэтому в первую я здесь отталкиваюсь от прекрасного постулата который есть в фреймворке Уже именно менеджерском айтил Может быть слышали этот постулат гласит starbaya то есть Старайся переиспользовать то что у тебя есть прежде чем будешь внедрять что-то новое и в общем-то PHP что меня в этом языке сейчас радует то что он движется Вот именно в сторону современных технологий которые позволяют на определенном уровне переиспользовать этот язык еще еще раз прежде чем потратить деньги на внедрение именно новые языка супер спасибо большое Если еще вопросы тогда у меня маленький тоже вопрос а в процентном соотношении у вас использование PHP eGo в компании примерно Какое именно в Авито мы сейчас используем в основном Go от PHP Мы уходим там Я бы сейчас сказал что в районе наверное процентов 10-15 остается кодовой базы на PHP но тем не менее Да здесь нужно очень четко держать в уме тот факт что это большая компания который там есть возможность обеспечивать такие проекты по переходу это раз во-вторых не могу не отметить что мы долгое время жили работали с PHP нагруженное приложение еще до появления там всяческих готовить и в общем-то себе хорошо с этим жили по крайней мере потому что мы сейчас существуем работы поэтому здесь это очень важно эту штуку иметь в голове она прежде чем принимать решение о том что вот Ага Александр работает в Авито у них голова он рассказывает почему-то про PHP Прошу прощения за каверзный вопрос но я же говорила Давайте задавать интересно ну что ж предлагаю выбрать Какой из двух вопросов Я понимаю что безумно сложно выбрать Но все-таки какой из двух вопросов больше понравился кому будем дарить подарок на самом деле реально очень сложно выбирать Потому что первый вопрос он был более техническим второй Он про то что все-таки А зачем нам PHP когда есть наверное с возможностью Два подарка или только один только один Прошу прощения один Хорошо Давайте тогда у нас Техническая конференция в первую очередь поэтому первый вопрос я Спасибо огромное спасибо за ваш вопрос Александру Спасибо у нас сейчас буквально 4 минутки на перерыв и в 11 часов у нас будет Тик Ток с Дмитрием крапивиным сбермаркет Тик Ток это записано семью которое можно будет посмотреть"
}