{
  "video_id": "NYUoewtMLqo",
  "channel": "HighLoadChannel",
  "title": "Нейронные сети: быстрый инференс на GPU с помощью TensorRT / Дмитрий Коробченко (NVIDIA)",
  "views": 6487,
  "duration": 2591,
  "published": "2018-08-16T04:59:31-07:00",
  "text": "коллеги всем добрый день меня зовут дмитрий коробченко я работаю в компании nvidia сегодня поговорим про такую замечательную тему как ускорение вашего inference и наверняка многие из вас использовать нейронные сети или собираются использовать и вы непременно столкнетесь с такой вещью как inference то есть прямое распространение прямой боевой режим работы вашей нервной сети и я расскажу как это сделать быстро с помощью g пью и библиотеки тендер rt план доклада вот примерно такой попробуем убить сразу несколько зайцев даже если кто-то из вас считает себя матерым дата-сайентистов все равно никогда не вредно послушать еще раз что такое свёрточная нейронная сеть и тем более они нам в конце пригодятся в демонстрации дальше покажу как с помощью тендер то собственно делать быстрый inference расскажу про фичи особенностей этой библиотеки и вторая часть это у нас будет полностью демонстрация тут мы с вами искендер фол поработаем и потом обученную модель квартиру на тендер рты посмотрим как быстро она у нас будет работать поехали свёрточная нейронная сеть он вообще с помощью такое просто нейронная сеть некоторый вычислительный граф входной вектор отображается в выходной вектор в нейроне у нас происходит композиция линейной и нелинейной операции связи между нейронами соответствует некоторый вес а это параметр который мы корректируем в процессе обучения отлично есть нейронные сети теперь есть у нас задача компьютерного зрения например классификация картинок такие вот простые архитектуры если мы в лоб их бы применять здесь не работают почему потому что в компьютерном зрение нам очень важные признаки желательно локальные признаки то есть какие-то особенности картинки которые если мы уже выделили дальше можем с ними работать и натравливать какие-то алгоритм машинного обучения как выделять признаки но одна пример есть такая замечательная операция свертки а если в двух словах свёртка это такое скользящее окно которое в каждой позиции вашей картинке смотрят корреляцию с некоторым шаблоном паттерном который называется ядро свертки и по сути в выходную карту мы записываем эту самую корреляцию то есть насколько хорошо этот паттерн приз насколько сильно этот паттерн активировался натальным на том или ином месте картинки получаем таким образом карту признаков теперь нам повезло и свёртка это линейная операция поэтому мы ее можем по так как слой нейронной сети таким образом получаем свёрточная нейронная сеть в которой нейроны связаны особым образом и связи между нейронами соответствует как раз вот эти наши ядра свертки то есть мы получаем обучаемые признаки очень здорово теперь можем использовать такие сверточек нейронные сети для компьютерного зрения хотя вроде как то это все поверхностно нужно спускаться глубже и строить не просто признаки а иерархию признаков то есть выделять признаки следующего уровня в пространстве признаков предшествующего уровня строят таким образом уже глубокие сети которая с которыми уже реально можно идти в бой а какие слои из твердых нейронных сетях но с wear точный слой мы уже рассмотрели в общем случае он просто может отображать какой-то набор карт признаков в какой-то другой набор карту признаков для этого нам понадобится несколько ядер свертки кроме того незабываемой обязательно про нее линейную функцию активации без которой просто любая нейронная сеть будет совсем даже не выразительная это свёрточная злой дальше очень немаловажный слой понижение размерности pulling например у можно дело с помощью локального усреднения или локального максимума по сути это просто сжатие вашей картинки в пространственных измерениях обеспечивает это таким образом некоторую инвариантность относительно небольших смещений и поворотов а также по сути отсеивать какой-то ненужный шум неинформативный который нам не нужен для например классификации ну и дальше полна связанный слой это просто элемент уже классических многослойных перцептивных когда у нас данный надо достаточно глубоком уровне уже хорошо развязана их просто добиваем с помощью какого-то количества полна связных слоев который просто вектор отображают вектор ну и собираем это все вместе как правило свёрткой pulling идут в начале и чередуются выделяем признаки обеспечиваем инвариантность и в конце все это добиваем каким-то количеством полна связных слоев и получаем уже выход в случае классификации выход как правило это распределение вероятностей по классам какому классу относится картинка с этим можно уже опять же идти в бой но что-то забыли да что мы забыли какую функцию активации взять но сейчас практически везде используется либо лилу вот здесь графикой он нарисован либо какие-то ее модификации кроме того используется замечательная вещь такая как батч нормали за помощь нормализация получат по сути это просто нормализация карт признаков который обеспечивает нам не лучшую сходимость и регуляризация дам никто не хочет переобучение мы хотим чтобы наша модель хорошо работала продакш ним по качества поэтому мы применяем dropout случайно и зануление каких-то нейронов который нам помогает наш миллиону сеть немножко регулировать и вы детей то есть по сути l2 регуляризации на параметры модели на весах отлично теперь как же обучать но вот есть у нас допустим огромная база данных какие-то объекты и к ним правильные ответы например картинки и лейблы мы будем обучаться с учителем у нас есть правильный ответ известны показываем одну за одной картинке наши модели на какой-то итерации пропускаем образец через нашу нейронную сеть уже какими-то инициализирован ими весами и получаем некоторые предсказания ответ теперь у нас есть правильный ответ и мы можем вычислить ошибку то есть как сильно мы ошиблись теперь зная эту ошибку мы можем вычислить градиент и сделать один шаг градиентного спуска то есть поправить наше vesa немножко таким образом чтобы эту ошибку конкретно на этом примере скомпенсировать и все это вместе называется стохастический градиентный спуск теперь как вычислить градиент но его можно вышли с помощью правила дифференцирования сложной функции или применить так неровностям это алгоритм называется бэкапа гейджем обратно распространение ошибки супер теперь с теории закончили приходим к практике вот как выглядит стандартный процесс вообще работы да это сантис ты вообще человек который занимается машинным обучением с высоты птичьего полета вот вас есть обучение вы да это сантис у вас есть обучающий выборка вы тренируете модель подбирайте гипер параметры крутить ее туда сюда и финально все получили натренированы модель готовы с не отправляться production а как правило все это делать с помощью каких то высокоуровневых фреймворков кафе торчите она и так далее то за ртом и как только вы модель натренировали вы ее внедряете то есть уже отправляйте туда где она будет работать и вот как раз вот это вот боевой режим работы неровности называется inference это может быть вас в дата-центре в облаке может быть какой-то embedded устройства или даже вообще авто пилотируемый автомобиль теперь в чем здесь проблема основная вот эти все фреймворке высокоуровневые которого использовать они очень хороши однако есть некоторые thread'ов всегда между гибкостью фреймворка и его оптимальности например вы можете вот как research are исследователь какую-то сложную задачу сложную модель запрограммировать на какому-то высокоуровневом фреймворке как правило все они имеют питон интерфейс то все это очень удобно делать и и даже несмотря на то что все вот эти фреймворке используют под собой библиотеку нашу кубику dnn которая реализует всякие различные сложные операции вот эти атомарные низкоуровневые типа как свёртка умножение матриц pulling то есть все вот эти вот операции которые используются в глубоком обучении они уже на куди реализованные сети библиотеки используют же пью однако этого мало можно на самом деле это все еще лучше то есть фреймворке вносят некоторую вот это вот замедление можно так сказать как нам с этим бороться и на помощь нам приходит библиотека тензор rtm если опять же с высоты птичьего полета на нее смотреть то она представляет собой как бы две части у вас есть обычная модель в ее подаете в танце рты первая фаза это оптимизация потом подробно рассмотрим что происходит тут мы улучшаем оптимизируем нашу модель и второе это собственно запуск в боевом режиме inference тендер это только про inference никакого обучения там нет то есть вас уже есть обычная модель в каком-то другом фреймворке вы ее получили рассмотрим подробней что происходит шаг оптимизация но тут есть обычная модель и чтобы подать ее в тендер rt оптимизатор вам нужно еще некоторые параметры зафиксировать все мы знаем чтобы что-то оптимально работал там какие то вещи приходится фиксировать заживать в константы not аналогия с тем что когда мы компилируем какой-то код если у нас есть там какие-то константы то это значит компилятор нам с большей верности это оптимизирует так и здесь нам нужно будет зашить например какой большая сможем использовать а если точнее какой максимальной обычной смогу использовать дальше с какой точностью мы будем считать это будет floating point или intel еще что-то и другие параметры опять же потом рассмотрим подробнее вот это все мы подаем на вход оптимизаторам он некоторые магические вещь делает и выдает на выходе уже скомпилируем такую модель полностью готовы конференцию называется она план и можем можем ее уже стерилизовать записать на диск это шаг оптимизация и шаг inference наш боевой режим он самый простой вопрос и загружаем наш план и в тендере runtime среде его выполняем и делаем это уже на наших целевых платформах там будь то это облако какой-то embedded устройства или автомобиль или еще что-то хорошо рассмотрено ты с этим шагом инферн все более менее понятно то есть просто взяли запустили как сделать оптимизацию давайте рассмотрим подробнее во-первых у вас есть моделью как-то надо импортировать если у вас модель в кафе или в тендер flown его у нас есть автоматический импортер модели у него есть питон интерфейс есть и плюс плюс интерфейс в общем очень быстро и легко можно модель импортировать и подать прямо на фото оптимизатор если у вас какой-то другой фреймворка или вообще вы сами все это дело написали то у нас есть некоторые 5 для того чтобы собственную модель эту задать это очень похоже на то как вы задаете модель в каком нибудь там высоко уровню в руки то есть в игру говоря описывать какие у вас слои и указывайте какие vesa у этих слоев как правило у вас уже есть если есть обычная модель значит у вас есть эти данные например какие-то тендеры выйти тендер просто загружайте и ассоциируете с теми или иными слоями то есть используйте этот нашей 5 для построения модели это же это все отправляете в оптимизатор это что касается импортом дальше какие слои поддерживаются ну есть какое-то количество встроенных слоев то есть уже который прям готовые практически все что нужно для компьютерного зрения есть кроме того с версии 20 есть были 21 есть гринин л стенджер юм в общем если что то здесь не нашли значит можно реализовать свой собственный пользовательский кастомный слой как это нужно сделать нужна грубая например на си плюс плюс если вы это делаете от наследуется от некоторого нашего класса интерфейсного и реализовать допустим функцию форвард и какие-то ещё дополнительные вещи типа там как ваш слой нужно стерилизовать какое у него там размеры все прочее очень важно чтобы эту кастомным пуль имитацию вы делали тоже на куда потому что иначе это будет battle.net большой то есть понятно что все это выполняется на джипе у все это оптимизирована под же пью если у вас там какой то есть один слой который вы почему-то сделать ее на джипе вам нужно ведь будет еще и данный скопировать с gpu памяти на обычную память то есть лучше это все делать конечно на куда писать эти кастомные слоя но в принципе не очень сложно делается отлично теперь мы начать загрузили модель знаем какие слои там подержат теперь собственно какие же оптимизации тендер т делает но здесь куча всяких вещей рассмотрим три основных значит первое это слияние или удаление слоев вот значит пример inception блока знаменитый сети google нет слева до оптимизации справа после оптимизации оптимизации вы смотрите у нас были блоки вот эти тройки допустим свёртка 11 без или ярилу в других модификациях это может быть свёртка батч нормализация lilu вот эти три операции они практически во всех фреймворков у вас будут идти отдельно опять же мы платим за гибкость однако может оптимизировать и все это смешать в один такой карл dancefloor это сделает это называется такая вертикальная свёртка слияние вертикально теперь если у нас какой-то слой и какой какая-то группа слоев имеет один и тот же вход например вот тут есть несколько сверток один-на-один которые имеют один и тот же вход можно все это тоже смерти такую атаку одну длинную широкую свёртку получается такое горизонтальное слияние это 2 и 3 у нас есть свой конкатенации ну вообще зачем он нам нужен когда просто допустим даже свёртка может сразу свой выход писать нужную область памяти чтобы от конкатенации сбоев сразу делать йога эту конкатенацию на лету таким образом мы приходим к такому вот оптимизированному графом и это нам дает существенный прирост производительности что касается удаление слоев теперь понижение точности как правило вы все ваше обучение делаете во флоте ncoin 32 таком диком диапазоне там 10 в 38 степени очень часто вам этого слишком много то есть все вот эти задачи классификация там регрессия они на самом деле чуть-чуть допускают небольшой люфт в этой точности то есть это у вас не какие-то там сложные вычисления ядерного реактора до какие-то погрешности в точности если вас особенно какая дискретная задача допускаются поэтому можно эту точность понизить начать с того что понизить до floating point 16 для этого практически ничего вообще не надо делать ее можно пойти дальше и понизить точность до вообще энтов and 8 то есть отобразить все в диапазон -128 плюс 27 ну понятно что у вас веса и активации могут в каком-то другом совершенно диапазоне быть поэтому для этого вам нужно сделать некоторую калибровку то есть некоторым образом веса привести к этому диапазону это в тендере rt делать автоматически однако для этого понадобится не только калибровочные datasette то есть вам нужно подать какой-то кальку найди например какое-то количество картинок лучше всего из эволюционной выборки или историй в которой у вас будет в реальной жизни и тендер т прогонит на этих картинках несколько раз inference посмотрим в каких вообще диапазон находят веса и параметры и активации и таким образом как-то калибровочные константы вычислят и поэтому тут можно видеть на правом графике что использование либо int 8 bfp 16 дает существенный прирост в производительности и 3 очень немало важный шаг это автоматический подбор ный лучших каналов смотрите вот вас есть g пью вы знаете на каком же пью все это будет запускать у вас есть все ваши параметры модели вы знаете ваш сайт и также вам нужно знать размер входа то есть все вот это фиксируем теперь когда мы все это знаем мы можем исходя из этих параметров выбрать наилучший kernal то есть наилучшую реализацию того или например свёртка или там чего нить еще в дозор rt есть имплементации вот этих различных алгоритмов во множестве вариантов теперь как выбрать лучший на самом деле очень просто когда мы знаем все параметры у нас вот есть та самая джип мы просто перебираем мы запускаем все вот эти inference и на всех этих разных алгоритмах из мы выбираем лучший то есть какой быстрее отработал тот и выберем из допустим какой из десятка сверток выберем самую быстро сверху которая отработала конкретно на этом железе конкретно с этими размерами потому что можно просто разную реализацию делать а можно вообще разные алгоритмы свёртка использовать есть там через умножение матриц через и преобразований в виноград и так далее автоматический подбор наилучших кормов но еще один слайд про производительность как можно ее лучи тут просто два примера про то что это и на сварочных сетях слева рязань от 50 и на рекуррентных сетях оппоненты то есть это машинный перевод виден прирост как в использовании значит тендер т так и в использовании допустим там последних g плюс поддержкой таких вещей как и тендер коры лед как раз вот это вот пониженной точность in 8 по 16 то есть все круто работает так все теперь значит переходим к демонстрации сейчас будет очень много кода так что держитесь за спинки кресел на самом деле хотел я все это показать прям так живьем но подумал зачем нам париться с проблемами с интернетом падающим ssh поэтому я дымку показал сам себе а вам покажу скриншот а чего получилась значит что у нас будет во первых мы обучим модель нато взорву опять же двух зайцев убьем я вам и tensorflow покажу и тендер rt обучаю модель на тендер flow потом сделаем такую замечает вещь как заморозка графа это нужно и для inference of tender flow и для собственно портирования модель на тендеров там потом начнут собственно посмотрим как собственно inference notice of love сделать чтобы потом сравнить сендер т после чего переходим к тент ррт первое делаем оптимизацию второе делаем inference поехали обучение модель на тендер флом делая все этого и питон ноутбуки если вы не успеваете за кодом следить смотрите хотя бы за такими штуками который я щас буду выделять просто в коде типа вот здесь мы делаем это здесь мы делаем это здесь мы ничего интересного не делаем просто импортируем tensorflow и кроме того я буду использовать библиотеку tensorflow slim очень такая удобная вещь для быстрого описания графов то есть если кто то из вас используют keros например над тендер фланта можете посмотреть в сторону tensorflow slim тоже будет достаточно компактным импортируем последней строчкой нашу модель которое выглядит следующим образом вот наш тендер клон slim и теперь что мы делаем мы говорим что для сверхточных и полна связанных слоев у нас будет такая the activation такая-то инициализация весов и такая-то регуляризация то есть вы decay 2 regular ризотто кроме того для сверток еще добавим batch нормализацию тоже вот так вот компактно сейчас будем описывать архитектуру которая есть в г г а и плюс они еще больше нормализация классической в гоа + патч нормализация поэтому здесь вот для сверток включаем batch нормализацию и вот так вот выглядит описание всей вгк очень компактным новым компактнее чем на террасе значит свёртка pulling свёртка pulling и так далее и в конце у нас все мы факторизуем с помощью флаттер потом у нас полна связанный слой dropout и так далее значит конце у нас два класса будем решать не стареющую классику эта классификация на два класса кошка и собака 2 класса на выходе вот так выглядит модель и поехали на что обучение сдаем некоторые параметры такие как размер бочче learning рейд и какие то еще вещи типа момент количество эпох и так далее то есть задаем параметры теперь подготавливаем наши данные я буду использовать очереди tensorflow если умеете все сокрыто вот в этой функцией можно дейта не суть важно там делается главное что вот она нам возвращает два таких тендера train и матче train лейбл из которых мы будем получать картинки и правильные ответы лейблы то есть дергать их потом в процессе обучения получили значит данные наши тренировочные обучающие теперь строим собственно сам граф саму модель это наш модуль от train и матч и на выходе мы получаем вы хотите логин это наш граф к нему накручен сверху лосс функцию потерь будем использовать на soft макрос энтропию то есть эта функция на вы хотите накрутить софт макс и мы подаем туда train лейбл и наш вы хотите логин и от этого всего возьмется кроссом тропе это классический категориальный классический классификационный такой лосс то есть чтобы сделать нам задачу классификации решить получаем лосс дальше еще какие-то некоторые структуры нужны для тазов лов здесь задаем такие как ленин crate он будет полиномиальная падать в качестве оптимизатор используем optima оптимизатор с моментом и вот третья штука этот тендер об мы получаем тот тендер который если мы будем дергать у нас будет делаться один шаг градиентного спуска то есть это вот то что нам потом понадобится train об и собственно само обучение вот эти две выделенные строчки и то есть все обучение то есть просто по всем операциям запускаем вершин . ран от train ap то есть сделано пожалуйста один шаг градиента спуска и кроме того мы сразу получаем лосс еще на этой операции все запустили полетели вот плос у нас начал сначала расти потом падать будет смотреть можно это все здесь до 3 вечно который можно смотреть бесконечно огонь вода и как падает лосс все это можно делать в среде тендер борт который идет месяца с тензор flow может найти как падает лосс можно сюда выводить какие-то другие метрики точность еще что-нибудь вот ленинград например можно видеть как мы опускали до нуля кроме того здесь можно посмотреть как выглядит ваш граф можно вот это все про кликать прощёлкать развернуть посмотрите внутреннюю структуру загляну то есть очень удобный инструмент вот если вот я буду переходить на python очень сильно будут скучать по вот этим инструментом так теперь отлично обучили модель теперь надо ее немножко заморозить что это такое но смотрите давайте значит чуть чего-то импортируем потом в настройках начну определим некоторые параметры а именно нам понадобится название нашего выходного слоя и по сути ну что откуда на что загрузить модели куда мы потом сохраним это фроузен . пиби будем сохранять его просто буфер заморожены но это все не так важно важно следующее шаг номер 1 мы создаем еще раз наш граф но теперь уже не в тренировочном таком режиме а в режиме inference а то есть начнем с того что мы напишем во-первых создадим в качестве входа placeholder то есть раньше у нас была очередь когда мы тренировочной картинки одну за одной читали теперь у нас будет placeholder нет in потом мы его знать опять строй модель как и раньше над out это есть модуль от нет in теперь мы ей придаем параметр из shining force это что значит значит внутри у нас всякие вещи типа дропауты и batch нормализации они будут в режиме inference а то есть они как бы эти вещи по-разному работать в режиме обучения в режиме интереса они сейчас настроены на режим интереса шаг номер два загружаем собственно весам модель нас уже обучена она хранится в некоторым с ним сотен сами весам его загрузили и все теперь как бы у нас есть и граф и модель и шаг номер три это собственно заморозка графа подготовка этого дела к обучению что здесь происходит первое мы убираем все тренировочные узлы да несмотря на то что мы граф создавали для inference а все равно там какие то дополнительные узлы нарисовались ненужный нам типы инициализатор весов какие-то там еще штуки все это убираем с помощью ремувера и не минут шаг номер два конвертируем наши все параметры в константы то есть по сути сливаем граф и веса то есть зашиваем все параметры hard кадим их внутрь нашего графа что получить такое одну целостную структуру и все это сохраняем на диск в замороженный граф запустили сохранили вот фроузен . пиби это наш замороженный граф теперь может с ним работать можно его и в тендер flow запускать и в тендер rt импортировать посмотрим что у нас внутри этого графа находится вот на сами видно что я распечатал все узлы этого грамоту собственно только то что нам нужен то и осталась чистая те операции которые нам нужны типа там свёртка батч норм и lumax pulling и как только параметры которые нам нужны они уже зашиты в graph это веса параметры batch норма и какие то еще константы все это наш граф можно на него еще посмотреть назад борт отдельно вот так он выглядит опять же без всякого мясо без сайт разветвлений то есть просто только то что нам нужно для inference ничего лишнего свёртка pulling и так далее однако если вот мы посмотрим например эту группу сад который соответствует свертки развернем и и тогда у нас есть три операции свёртка батч нормализация лилу это максима максимально для чего можем спуститься в tensorflow то есть помните я говорил что tensorflow у нас все вот эти операции идут отдельно of tender rt мы умеем их мер жить и вот видно что здесь они остались так и остались как бы размер джиннами дату поэтому когда мы будем делать inference данные будут в памяти туда-сюда гоняться по этим слоям то есть не очень оптимально лучше мы ничего сделать не можем теперь делаем inference тендера flow как мы это делаем ну для этого нам понадобится знать собственно файл в котором мы сохранили какая как у нас называется входная но да как у нас называется выходная но до или узел и в принципе все первое загружаем замороженный графу там уже в нем все прошито и веса и все на свете говорим вот этой функции импорт граф д в серединке пожалуйста верни нам два тендера нет open in it out with young мы будем подсовывать картинки это наш placeholder а is it out мы будем брать собственно ответы и вот красненьким выделены собственно название этих узлов чтобы да за фон знал какие нам узлы это собственно вернуть создаем сессию tensorflow но в которой все выполняется загружаем картинку здесь все просто единственные конечно надо подготовить том что нас вход фиксированного размера мы и resizer и обрезаем загрузили картинку и все запускаем inference это просто session ран от нет out и в качестве not in мы поём нашу картинку и мы получаем ответ out это просто распределение вероятности предательских классу смотрим где он достигает максимум и печатаем ответ кошка правильно распознали ура теперь давайте измерим сколько это все время занимала так как мы один раз уже это запустили все там каши и буферы уже прогрелись то есть это будет уже честно измерение sq как она работает уже прям совсем на лету измеряем все все тоже самое только еще добавляем той мид и видим что это работает 835 миллисекунд на картинку уже неплохо но вспоминаем что это тоже работать над же пью используем куда н.н. и без всяких лишних там операций тут мы максимально все что могли стенда flow вы жили здесь отлично едем дальше теперь тендер rt ну здесь всё совсем просто отпускаем спинки кресел все очень просто поехали первое во-первых мы будем загружать вот эту замороженную модель из тензор зло указываем к ней путь это наш бронза . baby во-вторых после оптимизации нам нужно будет наш план как-то стерилизовать на диск то есть сохранить куда мы будем сохранять это engine . план во вторых нам конечно а в третьих точнее понадобится конечно входная и выходная но до входные узлы и выходной узел это наш нет input и вот этот нет fc 8 без от это вот самый наш последний слой когда мы в последнем полна связанном свою добавляем без размер входа помните я вам говорил что здесь мы обязательно должны прошить зашить а то есть все оптимизация они из происходит исходя из известных размеров кроме того максимальный размер батч указываем 1 и максимальный размер рабочей области это некоторые просто оценка сверху сколько нам максимум может понадобиться памяти на все про все ну как правило и указывают просто какое-то большое число допустим там два в 20 так и все теперь просто начинаем считать шаги что у нас сделать шаг номер 1 загружаем замороженный граф и стендов лом в тандер то есть такой промежуточный формат так можно сказать интерфейс не для того чтобы из других каких-то фреймворков как то данный конвертировать это ю.ф. uni fight фреймворк формат загрузили вот этой строчкой тензор плавную модель все теперь нас есть wi-fi модуль это уже на наши хорошая некоторых структура просто некоторый стерилизованы граф понятном нам представление шаг номер два создаем парсер для этого графа ф модов и просто ему как раз указываем какая нас входная но да какая выходная но да как у нас размер входа и еще создаем просто служебную структуру лагерь чтобы тендеров ты знал куда выводить что-то и шаг номер три собственно делаем оптимизацию мы туда передаем наш лагерь нашу рф модель а парсер с помощью которого он ее будет читать максимальный размер бачи бачи и макс workspace ты сколько нам максимум нужна память подо все и все на выходе получаем engine оптимизированные готовы если мы это запустим и посмотрим в консоль что мы там увидим что мы там увидим изначально у нас было вот тридцать шесть слоев попытались удалить какие-то ненужные слои все равно осталось 36 она значит ничего не нужно идем дальше так у нас есть свёртка нормализация их же можно слить вот сливаем их и получаем уже двадцать восемь слоев идем дальше у нас есть свёртка и активация reloop их можно слить получаем на выходе 18 слоев смотрим еще что то нет все окончательному уже все оптимизировать 18 у нас на выходе сомелье вам достаточно простую модель показываю в г.г. очень многие модели они могут быть как то еще больше разветвление иметь вот тесте по слияния которые показывал типа горизонтальное слияние может быть удаление конкатенации еще что то здесь может происходить также удаляются если вы случайно оставили какие-то мертвые узлы которые но никогда вашим графини используется они тоже все будут удалены то есть все теперь у нас граф максимально оптимален и следующим шагом вот здесь не показано но следующим шагом тендер т начинает перебирать все как раз кернел и вы подбирая наилучший алгоритм для каждого слоя причем не просто вот нам у нас есть свёрткой мы какой-то один совершенно кернел найдем нет для каждого сварочного слой есть у нас 10 сварочных слоев в сети для каждого из них то что у них могут быть разные параметры разная раза размера например для каждого из них будет найден оптимальный терну ну и там где остальные слоев тоже все это запустили и все что шаг номер четыре мы engine просто стерилизуем в виде нашего плана сохраняем на диск то есть это уже та штука которая в нам только останется загрузите сделать inference ну и очищаем память и наконец inference так здесь нам уже не нужен ни tensorflow не ff ничего вот этого просто чисто тендер там здесь я кстати все показываю в питоне я все та же сам можно сделать было на плюсах а если у вас допустим не петрановская какая-то там среда на интернете а вот допустим в си плюс плюс все то же самое тендер рты все что нам понадобится это путь к нашему файлу с планом шаг номер 1 загружаем engine тут можно опять же это по-разному делать но для самых ленивых есть у нас такая обертка тензор rt light просто тендер т . light . engine от пути к плану получаем engine загружаем опять картинку все то же самое как было стандарту единственное отличие тендер rt ожидает картинку в формате csv то есть канала идут первыми поэтому мы и таким образом транспонируем сначала ставим канал это что питание у нас картинки обычно htc и мы здесь сначала поставим каналы такая такое соглашение так оптимальная загрузить картинку и все отправляемые на inference что у нас есть inference out есть engine . in her at и могу и все сразу получаем предсказанием кошка супер измеряем время здесь у нас получается 471 отлично лучше в тендер по у нас было 835 ну почти в два раза однако мы с вами не делали понижение точности мы с вами достаточно простую модель выбрали в плане того что там и так уже все достаточно пока компактно оптимально было и тем менее почти в два раза все равно мы это смогли сделать дальше можно было бы действительно все это продолжить усовершенствовать а именно добавить до конвертацию вфп 16 и это тоже дико взлетела бы сразу производить у меня просто цепью это на который все читал достаточно стара там еще это не поддерживается но начиная с pascal все это же 16-8 все это работает отлично почти в два раза ускорили есть цель достигнута и заключение что такое тендер т надеюсь всем понятно стало что это некоторая вещь который позволяет вам ускорить ваш inference три основные фишки тендер ты она оптимизирует ваш граф она подбирает наилучшие kernal и то есть программисты тендер туда за программе кучу кучу разных реализации тех или иных там сверток или доволь другу как выбрать лучшие прям прогнать на месте то есть просто все запустить и посмотреть кто на данном железе при данных параметрах работать быстрее всего их именно за жить в план отсюда кстати важная деталь что очень желает на оптимизацию делать на том же самом же бью на котором вы будете потом гонять inference ну потому что понятно тендер т заточена под это конкретное железо и значит а кстати то все эти реализации они не просто там разные алгоритмы они действительно используют информацию о том какой сейчас железо то есть там групп в этом если это там паскаль то в топ-4 тогда использовать такое карма вот буквально такого типа там и оптимизации и третье соответственно понижение точности тоже дает большой взрыв в производительности можно импортировать из кафе тендер flow или использовать и 5 для написания своего описания модели и поддерживаем кастомных слоев я собственно тоже это все использовал як не разработчик тендер то я тоже пользователь тендер т когда свой проект квартиру на концерты я буквально через всего это проходил и свои слои писал и в принципе жить можно на этом у меня в принципе все все весь код который увиделись что-то не запомнили не волнуйтесь все это вот есть на гитхабе правда я не так давно это выложил там пока что мало каких-то комментариев ридми нет но это очень скоро все добавлю кроме того здесь можете скачать посмотреть тендер rtm там есть очень много примеров но скажем так не очень много нот на каждый кейс есть примеры то есть я хочу кастомный слой а есть пример я хочу там и спой импортировать там из танцев но она есть пример я хочу рнн есть пример и кроме того если вообще вдруг случайно сюда забрели но новичок в глубоком обучении вот у нас есть тоже такой замечательный сайт deep learning институт где собраны различные лабораторные работы и курсы по глубокому мучениям все спасибо наверно можно какие-то вопросы сейчас принесут ну уже не успели дениз росси спасибо за доклад работает микрофон сейчас нет не работает так сочно спасибо за доклад а я так понимаю ваши аптека очень хорошо лет ускорять вопрос можно ли тендер то использовать для обучения нет там вот это целенаправленно направлен только на inference то есть даже как-то выдергивать оттуда какие-то функции чтобы их применять в обучении но это очень как-то криво что все равно оптимально не получится то есть тендер то он вот конкретно набрасывается на цель inference а потому что в обучении у вас и так все равно вот какие то там одна вещь они уже на qt н.н. реализованы то есть они уже достаточно быстро будут работать а вот эта вся связка она важна вот сендер ты вот эта связка между слоями она по сути только для интернете есть в обучении у вас будет этот тампе тонком нет только собственно кузен все во всей фреймворке так уже ну ещё у нас есть и nvidia digits но это такое домохозяина я накрутку на всем чтобы чтобы от все красиво там смотреть а есть работающий микрофон ну давайте пока так очень хороший вопрос почему то забыл сказать действительно когда мы понижаем точность вычислений давал я как раз повторяю вопрос когда мы понижаем точность вычисления например свой телефон 32 на fh16 лет восемь конечно надо ожидать просадку точности и вот если мы это делаем dfp 16 практически во всех задачах там распознавания классификации вообще практически нет никакого падения точности но может быть там какие-то там доли процентов если понижаем до and 8 то уже действительно может быть какая-то просадка вот тут числами уже нет но если вы пойдете на сайты в документацию там все все числа указаны какая будет просадка по точности но тут вам уже нужно выбирать либо уходить и очень быстро но готовы чуть-чуть пожертвовать точностью до но принципиально ответ такой что небольшие потери в точности то есть для этого дела за калибровка чтобы все-таки в диапазон не сильно потерять на небольшие потери точности из такой так время является ли время с учетом доставки данных на видеокарту ну я думаю да потому что все таки мы здесь это из питона дергаем то есть сначала питон в питоне у нас вот этот и мага она лежит на в памяти но в обычной когда мы вот это делаем да и то с учетом копирования на gpu до когда понятно вот смотрите если вот мы вот всякие такие графики будем смотреть сейчас то что я вам показывал такие ну маркетинговые графики там скорее всего да вот это замерена чистый inference однако то что я при вас замерил это конечно там от картинки в памяти обычный до соответственно до ответа то есть это наверное да чистый inference здесь то что я сейчас замерял в питоне но картинка лежала в памяти обычной то есть плюс доставка еще нет но смотрите модель не как модель вы ни посмотри вопрос был такой если аналог тендер борт для ужас конвертируя моделей единстве что вы можете сделать это вот посмотреть в консоли что у вас получилось то есть все эти слои вам там выпишут ну нет посмотреть не как мы вообще мало где вы можете смотреть эти вещи в принципе вы можете сделать это собственный руками например есть такая вещь как dot graphviz когда вы какое-то текстовое описание графа отображаете в картинку то есть вам нужно просто текст в описании создать но сейчас такого нет самый после интенсив смысле стакан насколько быстро стал работать вы описали доработать видим что у нас то есть медленного иметь то есть сделали интерес получили просадку и надо узнать где она постучала ошибка по качество качество просела не вам нужно скажем так тиндер это не даст вам ответ в каком именно слова что-то потерялось она групп в везде равномерно потерялась и по и по времени и по качеству да просто вся сеть целиком здесь работать то есть вы мы не узнаем да спасибо за доклад вот можно еще поделиться насколько данная тема является дыма либо это кусок с каких то может быть практических задач был взять взят и какие практические задачи вот в какие практические задачи например дальше этот кусок дому можно взять как бы за основу либо там как-то его развитие с помощью чего смотрите вот этот кусок дима опять же я не не пытался специально подобрать сеть для того чтобы показать вам тут приростов сто раз вот я реально у меня была какая-то сеть для другой задачи можно сказать я просто взял какая у меня была посмотрела действительно два раза узко раз вот и все что я показывал очень хорошо годится для любых задач классификации картинок на на самом деле этим это все не ограничивается утробу все то же самое для любых таких вот сварочных нейронов state of mine оно верно для любых вообще сетей если у вас нет пользователь пользовательских своих особенных слоев в архитектуре топ-уровня как я показал это все заведется то есть вас есть любой граф вам просто нужно знать его как у меня выходной узел какой выходной золото может быть картинка в картинку или там не знаю что это во что-то вы отображать вот вас вход в атлас выход искать может быть несколько несколько входов несколько выходов то есть по сути любой граф если у вас все слои уже поддерживаются нашим тендер rt то есть там был список слоев тут прямо с просто следуйте этой схеме вам по сути нужно заменить только там файл файл могу . пойми все а все остальное это вот точно такой же пайпа не единственная когда этого там еще в другом проекте применял я использовал не питон интерфейс а си плюс плюс интерфейс там конечно все чуть побольше да как известно один экран колтона плюсах это одна строчка на питоне но темень тоже жить можно лишь например у вас где то есть да если вы скачаете тендер rt библиотеку там есть examples примеры и там сэмплы есть и плюсовые питоновские спасибо ещё вопросы есть вопросы больше нет спасибо да и наклейку я пожалуй вам а там"
}