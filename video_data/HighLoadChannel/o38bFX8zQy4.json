{
  "video_id": "o38bFX8zQy4",
  "channel": "HighLoadChannel",
  "title": "Как научить фундаментальные модели читать, видеть, слышать и анализировать / Андрей Кузнецов  AIRI",
  "views": 250,
  "duration": 2900,
  "published": "2025-01-17T02:29:46-08:00",
  "text": "Всем привет Спасибо за подводку действительно сложный кейс всё время приходится какие-то индексы додумывать чтобы зарегистрироваться сегодня будем говорить продолжать говорить про мультимодальные модели и вот у Ивана была интересная презентация он в том числе затронул кейс который мы делали на в прошлом году и мы вот каждый год всё время придумываем какие-то новые решения чтобы новые задачки для того чтобы вот дать пространство для воображения для вот изобретения всяких интересных решений в части мультимодального дня сделаю такой небольшой экскурс в то Как вообще можно строить мультимодальные архитектуры что мы делаем в этом направлений и немножко покажу некоторые кейсы которые позволяют использовать мультимодальные модели не только с точки зрения атпу в виде текста то есть когда мы на вход даём картинку там видео аудио что угодно можем получать только текст но мы можем на выходе получать не только текст кратко расскажу собственно про лабораторию в айре которой я руковожу у нас есть несколько направлений связанное одно с исследованиями именно архитектур ЛК и мы там делаем реч того как они работают думаем на тему интерпретируемые иследования связаные с возни есть направление мультимодальные где команда как раз занимается исследованием различных архитектур возможностей создания новых энкодеров создания новых механизмов взаимодействия энкодеров и языковых моделей Ну и в принципе разные механизмы взаимодействия модели между собой это то что мы называем и привыкли называть агентами взаимодействиями есть ещё команда по генеративного искусственному интеллекту здесь мы тесно сотрудничаем с ребятами из лаем Кандинского и расширяем Кандинского Ну и вот команда Robo - Это всё что связано с мультимодальные именно работо техники То есть это специфические энкодеры это специфические механизмы смешивания энкодеров Когда у нас есть например не только визуальный контекст У нас есть ещё данные там с сенсоров сле Даров с других специфических источников информации и мы пытаемся из них вот жить какую-то информативную среду Ну и вот сегодня я кратко поговорю расскажу собственно про подходы в построении мультимодальных моделей расскажу про нашу технологию Ну и собственно дальше уже покажу там разные примеры и кейсы Какие можно строить и решать на базе мультимодальных архитектур собственно что же такое фундаментальная модель и почему мы когда говорим про языковые модели мы говорим про фундаменталь модели на самом обно из искусственного интеллекта то в целом фундаментальные модели очень хорошо это отражают то есть мы пытаемся вложить в языковую модель такую квинтесс сеню всех знаний которые есть в нашем мире Потому что основной источник информации Для нас - это всё-таки текст Несмотря на то что мы в коммуникации используем там и картинки и аудио и видео всё что угодно но так или иначе вся информация все весь ледж он хранится именно в МКА и понятно что всегда там думали на тему того как строить механизмы в которых можно с другими типами знаний и типами данных ну и собственно мультимодального оно Достаточно давно развивается Но вот с появлением таких ключевых игроков на рынке типа gpt gp4 эти технологии они начинают больше хапова И конечно больше людей начинают заниматься исследованием в этом направлении Есть действительно понятия про искусственный интеллект слабы в боши для задач мы привыкли использовать понятие слабого искусственного интеллекта это когда у нас есть конкретная моделька мы её учим на конкретном наборе данных и собственно получаем на выходе решение там одной двух задачек Ну более-менее они коррелировать эти задачи хороший пример - это там детектирование объектов это распознавание речи ещё что-то ну то есть каждая модель она решает определённую задачу она на неё направлена но когда мы говорим про сильный искусственный интеллект это такое Ну на самом деле не имеющее конкретного определения понятия но вкладывается в него достаточно много начиная от того что это может быть много модальности много типов данных на вход это может быть абсолютно не конечное количество задач на выход и это такие вот понятия которые действительно пытаются вложить в сильный искусственный интеллект это самосознание рефлексия возможность планировать Ну то есть что-то Что развивает и усиливает механизмы коммуникации с человеком есть вот добиться того чтобы у нас модель она лучше понимала с кем она общается персонализирована там как-то чувствовала эмпатичность какую-то проявляла Ну и Один из таких классических тестов он достаточно известен в мире и это тест тьюринга и задача этого теста - это научить искусственный интеллект так взаимодействовать и так общаться с человеком чтобы Человек потерял Вот эту вот ощущение что за ним Он общается с машиной чтобы в какой-то момент он в ходе коммуникации не мог отличить человека от искусственного интеллекта Ну и собственно тест тьюринга появился там в пятидесятых годах и постоянно появлялись разные модели которые умеют пытаются создать вот этот вот образ взаимодействия с человеком это и известная Лиза Она кстати до сих пор существует этой паре и там gpt 4 Понятно В современных механизмах Ну и конечно вот каждая модель она всё время пытается добавлять какие-то новые свойства в эту коммуникативную среду и вот Иван давая определение сильному добавил котив это дест важно потому что мы вс-таки говорим сечас когда говорим про мультимодальные модели мы говорим про диалоговые ассистенты То есть если у нас всё сейчас строится вокруг это ассистенты в той или иной сфере там в каких-то бизнес приложениях в узких доменах то в целом если мы говорим про пользу людям то это всё-таки ассистенты диалоговые которые позволяют нам решать разные зари кае за море моде искуственного интеллект у нас на вход есть какой-то один из типов данных у нас есть какая-то вот допустим Black B в виде этой и модели и на выходе мы решаем какую-то из задач это может быть абсолютно разные домены абсолютно разные модальности Ну и на выходе мы получаем вполне понятные какие-то кейсы Ну типа там анализ контекста там или тональности текста то есть каждое предложение оно может характеризоваться как негативное либо отрицательны типа там вот билеты на фильм Вспомнить всё можно купить в Евросети Окей это зелёный а Вспомнить всё унылый фильм это вот негативно Ну и вот как-то так модели работают например с текстом тоже классический кейс машинный перевод на вход текст на выходе текст на другом языке Всё понятно учим модели переводить тоже супер популярно супер важно переводчиков море один лучше другой хуже Окей текстовый диалоговый ассистент тоже в настоящее время это уже перестало быть чем-то таким новым и малоизвестным есть куча всяких приложений GAT Chat gpt Google B Google gem теперь уже Ну и всё Вот это строится на технологии именно взаимодействия в текстовом домене при этом текстовые ассистенты они могут решать абсолютно разные задачи они сейчас там и сумма текст и могут там написать какое-нибудь письмо собаки могут перефразировать письмо начальнику чтобы сменить контекст именно тональность описания можно там попросить его придумать какие-то подсказки Найти какие-то интересные приложения там для какой-нибудь штуки там написать сюжет там как я прол лето и так далее То есть приложений куча Но что возникает когда мы хотим добавить какую-то новую модальность вот например мы типа хотим поехать в какой-то город вот у нас есть фотка Я прошу объяснить что это такое модель Естественно с этим не справляется Потому что она не понимает что такое картинка и таких кейсов может быть много начиная от таких вот жизненных приложений и заканчивая тем что вот например у меня есть телефон Я не знаю какая у него зарядка Подскажи мне какая зарядка А я не пому что те фон потому что я его как бы не вижу я его не понимаю Ну и когда мы говорим про мультимодальной возникает вопрос А как же её добиться как же нам создать эту самую мультимодальной и как нам заставить модель научиться понимать разные типы данных отличающихся От текста а при этом у нас может быть абсолютно разное количество источников вот уже в доступных в современном мире с точки зрения данных с точки зрения различных источников ресурсов самое популярное - это изображение звуки видео Ну и есть ещё более такие специфичные вещи например последовательности событий или мы их ещё называем Event sequences Это например транзакции это могут быть данные с сенсоров С чего угодно Ну всё что можно каким-то образом специфически закодировать закодировать то есть превратить в векторное описание Ну и 3D 3D - это уже больше так скажем так про модель мира про картину мира про то как в том числе например понимать окружающую среду Ну и вот фундаментальная мультимодальная модель она в этом контексте представляет из себя некоторую синергию в том-то в том что она на входе умеет понимать разные типы знаний разные типы данных умеет их связывать между собой То есть если мы говорим про мку то ЛМ в этом смысле выступает как связующее звено то есть Нам нужно научить модель новым по сути языкам просто мы эти языки уже не можем каким-то образом символьное то есть у нас в любом случае для языковой модели нужно создать некоторый проектор который будет эту новую сущность или новый язык понимать изображени даже в статьях mof пару лет назад Они использовали Тай термин называют То есть когда у тебя как от английского То есть получается что новый язык изображений Тоже самое касается всего остального то есть мы по сути пытаемся переложить принципы мультиязычности на новые типы языков и по большому счёту если вот жить в этой парадигме и важно научиться Вот этому гибридного взаимодействию А ещё в идеале сделать это так чтобы это было вычислительное сложно потому что понятно что за обучение языковой модели могут взяться только бигтех и те у кого есть в ресурсе большие кластера Но для того чтобы решать там задачи более-менее понятные и несложные там для бизнеса для каких-то прикладных исследований здесь очень хорошо найти способ который позволит работать либо там без до обучения например вот как Иван рассказывал практически либо с минимальным обучением для того чтобы можно было не тратить и не закупать какие-то кластера А ну про ЛМ Я думаю в целом все уже знакомы что это такое в основе лежит трансформер это архитектура которая позволяет предсказывать Каждое следующее слово или токен токен - это часть слова как правило там четыре-пять букв то есть задача модели научиться по предыдущим словам предсказать какое будет наиболее вероятное следующее слово есть классические старые механизмы ещё до Трансформеров например там механизмы частотного анализа Это тип Т9 который есть у всех в телефонах Ты когда пишешь он тебе всё время предлагает следующее слово наиболее вероятное в контексте того что ты раньше там использовал в общении Или это может быть такой словарь частоты слов То есть после слова там приглашаю тебя на там скорее всего будет день да на день рождения а при этом текст он ограничен он ограничен в том смысле что мы как вот я показывал раньше в некоторых примерах мы не можем через него всё описать если бы мы хотели показать картину вот этого Зимнего Дворца нам нужно было бы описать эту картинку да Нам нужно было превратить в текст чтобы МКА её напрямую поняла А если мы говорим про телефон кейс с телефоном тоже нужно было его описать нужно было как-то там вот рассказать что там написано Самсун он вот выглядит так-то у него там такая-то рамочка Тоненькая и так далее То есть пытаться всё переводить текст но на самом деле это задача как раз адаптации вот этих новых языков к языковой модели то есть превращение не символьных данных не символьной структуры информацию в то что для модели Может в числовом виде представляться в виде нового языка Ну и вот если мы построим вокруг языковой модели какой-то механизм или вместе с языковой моделью какой-то механизм который научится это понимать то мы научимся а делать более умные ассистенты мы научимся понимать лучше то что хочет пользователь Ну и собственно будем идти по принципу а развития расширения языковых моделей а на самом деле вот это вот парадигма и подход в создании новых мультимодальных архитектур Это следующий шаг вот этой эволюции развития методов искусственного интеллекта скажем так вот в там девяностых 2010 все концентрировать на создании статистических алгоритмов то есть мы пытались детерминировано даже пытаться описать какие-то вещи мы пробовали вероятностные методы использовать для того чтобы там считать какие-то характеристики о данных там вычисляли стат характеристики на основе них делали разные предсказания потом появились глубокие модели а появилось при этом развитие и железа и мы стали уже там на более-менее таких домашних рабочих станциях учить какие-то небольшие модельки ты там efficient не и прочее и этого нам хватало для того чтобы в принципе решать достаточно большое количество прикладных задач там в сфере компьютерного зрения в сфере NP и так далее Ну и вот сейчас мы переходим в некоторый новый уровень когда есть вокруг огром СТ раз моделей В смысле предо обученных На огромном количестве данных и нам нужно понять о что нам с этим делать потому что в большинстве случаев нету достаточно большого количества ресурсов чтобы такую модель самому создать но надо придумать что с ней можно делать дальше для того чтобы эта модель нам пригодилась и мы могли использовать её в своих исследованиях либо в прикладных задачах Ну и вот тренд мульда он на самом деле сильно наблюдается с Конго года как раз когда вышел gpt как сервис первая версия стало с там января т д рего года очень активно набирать обороты именно создани разных мультимодальных вещей там Омки пошли и сразу стали появляться разные решение от крупных игроков там лава появилась где-то там в весной прошлого года ну и вот так или иначе это направление стало развиваться есть по Су за д же выросло количество разных приложений статей Open Source решений и в этом мире существует огромное количество разных подходов и разных комбинаций именно инженерных то есть здесь Наука на самом деле превратилась в такую инженерную науку и с этой инженерной наукой надо вот придумывать что делать дальше мы на самом деле занимались мультимодальный исследованиями ещё в д первом году когда это не было стримом и тогда же мы с точки зрения генеративных моделей тогда появись там мале если может кто-то помнит такую штуку это модель генерации картинок по тексту потом она уже трансформировалась в Кандинского вот в там прошлом году мы сделали небольшой релиз про архитектуру Рудольф я сейчас чуть подробнее про неё расскажу это другой подход не связанный с тем который сейчас в в основном используется для разработки мультимодальных так иние приво мы одни конечно же этим занимались очень много коллективов делал разные модели мультимодальные Но вот как я говорю как только какие-то публичные релизы появляются большие это даёт бу для развития направлений и популярности дальше хочется посмотреть и рассказать про то как же можно строить собственно эти мультимодальные модели Ну вот первый такой подход назовём его tooled LM это когда у нас есть предо обученная языковая модель у нас вокруг есть разные системы которые умеют работать с другими типами данных например с картинками с видео с аудио С чем угодно и мы хотим заставить языковую модель правильно использовать их как системы для понимания вот этого неизвестного инпута для того чтобы модель могла просто языком работать в языковой среде работать в контексте этих знаний очень очень понятный простой механизм выступает как оркестра то есть она принимает на вход запрос если она не знает что это за тип данных она отправляет его в разные какие-то подсистемы которые рядом находятся они выдают ответ в виде текста и она формирует для себя вот этот самый текстовый контекст о картинке о том типе знаний который она не понимает Ну и собственно понятно что самый большой недостаток такого подхода - это взаимодействие между модальностей такую штуку достаточно сложно потому что в какой-то момент она Понятно начинает ошибаться Ну вот Один из таких примеров это Например модель MM react или frw MM react построенный на chpt что Он позволяет вот механизм его работы Да у нас на вход приходит картинка М не знает что такое картинка но у неё вот в округе есть куча разных механизмов которые умеют работать с изображениями Ну вот здесь они чуть лучше видны Да это например распознавание объектов на картинке это imon когда можно по картинке дать какое-то объяснение это видео сумарин Ну и собственно мы отправляем эту картинку в все эти внешние системы получаем от них фид получаем от них информацию кто изображён Какого цвета объекты как они расположены друг относительно друга Ну и так далее То есть делаем некоторый ризон для языковой модели и это приправ как раз там бадин боксами которые выдала там какая-нибудь система детекции там типа лы это всё приправ информацией из условно поисковика потому что можем распознать человека узнать его историю то есть такой скажем так подход тоже подключается и мы на выходе получаем контекст в виде текста но модель Уже понимает что на картинке и знает как ответить на вопрос который приходит на от пользователя понятный механизм работает хорошо до определённого момента пока у нас ограниченный Спектр задач которые мы хотим решать вокруг картинок следующий подход а а что будет если мы зная и предполагая что у нас языковая модель может работать с языком в виде картинок представим что у нас просто есть токены картиночка адаптеров у нас просто есть большой перемешанный сет картинок и текстов это могут быть там спар данные с каких-нибудь сайтов где есть картинки с текстами с парош данные новостей какие-то мультимодальные диалоги и мы попробуем сразу прямо с нуля начать учить модель которая получится понимает сразу и картинки и текст то есть в целом она будет учиться разным типам токенов будет понимать и отличать эти токены но ей не нужно будет никакого внешнего энкодера она сама сразу будет его кодировать и сразу внутри себя понимать так как будто бы это новый язык и такой подход достаточно хороший он понятный и наверняка выбьет лучше качество но его лее для него нужны Хорошие чистые данные именно в в контексте перемешаны данных о картинках и там тексте и три если мы хотим добавить какую-то новую модальность у которой нет явной связки с текстом то нам будет тяжело Ну например сенсорика её нужно каким-то образом описывать то есть делать парные датасеты и добавлять уже существующую модель которая понимает уже известные какие-то для не пы данных тос мы учили From Scratch с нуля картинкам и тексту то для того чтобы добавить новую модальность нам нужно понимать а как будут картинки с аудио не пересекаться то есть как она не научится их путать и недавно вышла статья Florence 2 ну точнее они её выпустили ещё там в конце двадцать третьего года но вот недавно её заан сирова с он сусом с чекпоинта это как раз Модель которая позволяет вот иметь такой мультимодальный энкодер то есть у нас модель сразу выступает в виде такого мультимодального механизма понимание сразу нескольких типов знаний Ну и вот Рудольф он как раз относится к этому подходу смысл был в ЧМ мы взяли просто трансформер архитектуру разбили её по сути на три части левая часть это были текстовые токены в серединке это были картиночки и справа опять текстовые токены То есть получается текст картинка текст это такой унитарный механизм матип какого-то диалога то есть мульти в несколько реплик диалога Да И вот эта одна реплика она в принципе позволяет синтезировать как текстовые диалоги если мы маскируем картинку в середине мы можем сделать и решать задачу описания картинки если мы левую часть текста маскируем то у нас получается картинка с правой текст то есть это может быть вопрос по картинке Когда у нас ни одна часть не маскироваться текст в серединке картинка справа текст И вот это меним позво ставить за счёт маскирования в абсолютно разные задачи и вот здесь они перечислены То есть это в том числе генерация картинок авторегрессионная Когда у нас слева текст И мы просим там сгенерировать картинку она начинает её вот по токенам генерировать такой авторегрессионная определённую часть мы решаем определённую задачу что интересно а если мы например возьмём задачу чисто текстовую то есть там где нам картинка не нужна но не будем маскировать картинку то можно интересно понаблюдать как модель понимает о ЧМ её спрашивают Да то есть мы её учим с нуля мы её учим на смешанных данных Вот например вопрос ответь на вопрос Кто такой Чебурашка модель понимая и формально ей нужно отвечать только текстом но в серединке у неё остаётся картинка и мы её не маскируем она продолжает её генерировать Мы видим что она понимает о ком идёт речь и начинает генерировать в серединке картинку Чебурашки Или например если мы задаём ей вопрос про математически Каю математическую задачку типа там решим задачу даём ей описание Да Риа формально она должна из этих вариантов ответ выбрать один и выдать на выходе в виде текста определённый ответ но так как у неё в середине картинка она интерпретирует задачу как некоторое математическое описание и что-то там вот пытается изобразить понятно что это не имеет какого отношение к самой задаче но в целом это даёт понимание того что у неё внутри текстовые токены с визуальными перемешаны и она действительно понимает о ЧМ идт речь есть это к вопросу об Интер того что происходит внутри нез сза о следующем подходе когда мы говорим про самый понятный самый часто используемый сейчас механизм взаимодействия и создания мультимодальных архитектур мы говорим про механизм адаптеров или механизм таких мостиков Когда у нас есть действительно предо языковая модель у нас есть предобрый там обучены на каких-то специфических данных обучены на там картинках на видео на аудио то есть всё что может закодировать информацию Наша задача построить вот этот мостик и дать модели понимание что же такое что же такое собственно эта самая новая модальность и с точки зрения вычислительных ресурсов задача не трудоёмкая здесь достаточно иметь парочку карт о сотых и достаточно на них ставить эксперименты которые покроют большинство в принципе задач и при этом очень много возникает вопросов а как же там работать с той или иной модальностью если например там у нас Full HD картинка надо ли её нарезать потому что любой энкодер её всё равно жмёт у нас возникают вопрос А что если у нас специфические изображения например медицинские достаточно ли нам обычного энкодера и мы вот в этих направлениях делаем разные исследования и смотрим как для тех или иных задач подходит вот этот подход с точки зрения решения там и выбивания какого-то качества Ну вот в прошлом году на мы представили первую версию моде и вот в этом году мы её скажем так расширили мы в апреле выкатили версию на базе Open Source моделя и добавили там разные механизмы в том числе в оссе для смешивания разных энкодеров Ну например Мы можем взять не один визуальный энкодер можем взять несколько например классический вид - Это визуальный Трансформер и возм например Это который может на определенных примерах для того чтобы понимать например новую модальность ну скажем там медицинский домен или космоснимки что угодно и для того чтобы обучить такую модель у нас есть две стадии обучения это на котором мы учим как раз вот этот самый специфический адаптер или мостик между замороженными моделями и модель фна когда у на есть диалоговые инструктивные и мы на этих диалоговых инструктивные возможность модели понимать именно те инструкции которые можем задавать по картинкам мы в этом проекте активно сотрудничаем и нам помогают ребята и там из команды и из команды и мы пытаемся вот построив набор экспериментов прийти к какой-то универсальной штуке универсальному такому пауку в котором мы сможем понимать А для какой задачи нам Какой формат архитектуры Лучше подой где-то нам нужно несколько энкодеров где-то нам достаточно одного Может быть там очень маленький где-то нам нужно подумать как правильно научиться нарезать картинку на куски для того чтобы можно было усилить вот этот визуальный контекст Потому что если картинка там с огромным количеством маленьких деталей то если мы её просто сожмётся он как-то вот там вышел на первое место в целом мы довольны но там ещё очень много экспериментов которые мы не успели опубликовать но надеюсь что это дойдёт до какой-то вот финальной версии статьи который мы сейчас вместе занимаемся Ну и собственно что следует отметить что эта модель доступно в оссе я чуть позже там ссылку на неё покажу её можно взять потютьков абсолютно разные энкодеры конечно Следующий вопрос который может возникнуть На каких данных это всё учить Ну на самом деле так как э модель Open Source мы использовали для обучения исключительно Open Source данные и здесь в качестве трейна брали достаточно большие вот такие описания картинок и текстов Caption 3m это доступно в открытом коде Ну и собственно изображение с инструкциями и диалогами это там где у нас уже возникают разные вопросы про картинки где возникают разные инструкции типа там Ответь на вопрос Посчитай сколько предметов Что делает тот человек там и так далее взаимодействии предметов о их взаимном расположении и так Дале Ну и вот обучаясь на вот этих данных дальше мы переходим к задаче замера качества нашей модели здесь существует На самом деле ряд интересных Берков вот я их Перес некоторые самые интересные примеры из этих бенчмарком изображено три ребёнка девочка девочка и мальчик и вопрос заключается Ну следующий да А какой результат будет на доске По примеру которой пишет вторая девочка слева условно или там девочка в середине А и понятно что модели для того чтобы ответить на этот вопрос ей мало просто распознать Что написано на доске ей нужно распознать объекты в виде детей Да расположить их друг относительно друга понять их взаимоотношения друг с другом и потом уже ответить на вопрос что собственно нам нужно сделать И вот здесь написано required capabilities то есть что должна модель на самом деле проявить как качество для того чтобы понять как же решить эту задачу То есть тут и recognition тут и spal awareness расположение и собственно ACR как optical recognition распознавание текста Ну и дальше уже Математика это надо понять собственно что мы решаем за задачку Ну и в целом вот эти бенчмарки они сконцентрированы на разные области знаний которые можно вычленить из вот мультимодальной модели то есть какие можно ситуации в какие ситуации её можно поставить для того чтобы она могла правильно отвечать или вот ещё например интересная Задачка Когда у нас есть картинка с противнем на котором лежат куски курицы Они лежат не просто так они вот очень сильно напоминают атлас мира Ну и собственно интересно проверить насколько мультимодальная модель может не просто понять что это с ми курицы А что вот абстрактно если посмотреть на это то это действительно картинка которая напоминает некоторое расположение континентов и таких задач куча начиная там вот от такого подхода от таких примеров и заканчивая задачами из SQ Это задача из лекций по разным предметам то есть насколько у нас картинки широко покрывают домен разных знаний это тоже очень важно мы замеряли нашу модель Ну это вот как раз на момент написания репорта это апрель сечас стали получше но вот я как-то решил оставаться в контексте именно той версии собственно мы сравнивали с Open Source решениями по вот этим бенчмарком бенчмарком там восемь или там восемь штук основных А и задача как раз показать как в каждом из этих бенчмарком в каждом из бенчмарком есть определённая Метрика как правило это точность То есть если есть варианты ответов нужно выбрать правильный ответ А и проверять насколько модель там может объяснить например этот ответ Это задача генеративной Когда у нас не только выбор из там четырёх нам нужно дать именно правильный ответ на вопрос здесь каждая точка она показывает чем ближе к внешней окружности тем выше качества Ну вот жёлтый и синий - это как раз наши две модели которые мы пробовали из комбо энкодеров и с одним более усиленным энкодером делать это интерн вид на 6 млрд и сравнивались с моделями которые в оссе уже находятся и считаются вот эти Бенч на самом деле получилось выбить достаточно хорошие э показатели качества именно за счёт того как мы подбирали датасеты как мы их комбинировать в ходе обучения для э правильного Файн тюнинга Ну и дальше вот эти вот архитектурные штуки там с нарезкой картинок с правильной нарезкой картинок она может быть не обязательно равномерная А с разными механизмами из Как ни странно алгоритмов повышения разрешения есть такой механизм Pixel Shuffle который позволяет правильно переставлять значение пикселей формировать ЧНУ картинку с точки зрения визуального контекста располагать правильно пиксели Ну и собственно все вот эти подходы все вот эти архитектурные твики они дают куда больше качества и доливают определённых хороших результатов в части сравнения по бенчмарка чем допустим просто там заливать в прит данные и начинать там специфически доучиться конечно данные решают огромную роль и если мы концентрируя на повышении качества вот в таком постоянном пайплайн то данные могут решать очень много То есть если мы заряжаем разметку если мы заряжаем сбор данных по тем доменам где мы отстаём то мы очень быстро можем догонять Вот и добивать вот эти метрики в соответствующих лучах вот этого вот этой окружности да По качеству Но на самом деле это данные это одно но вот архитектурное решение и архитектурные подходы Это совершенно другая механика покажу несколько примеров того как модель Может сейчас работать она умеет работать с картинками абсолютно из разных направлений То есть она умеет и считать объекты на изображении может отдавать ответы в определённом формате например вот можно спросить там сколько на фотографии людей и попросить дать ответ там столько-то мужчин столько-то женщин и так далее Она может распознать разобранный предмет и предложить даже алгоритм его сборки Ну то есть там подсказать что вот там для того чтобы собрать велосипед нужно сделать раздватри и даже дать примерное время сборки оценить для повседневных задач так как модель языковая всё-таки Лайна и она не может давать напрямую инструкции она даёт рекомендацию что вот например в ситуации с разбитыми коленками нужно там обработать Рано ещё что-то но тем не менее надо обратиться к врачу То есть это уже особенность именно языковой модели потому что для неё так или иначе все механизмы алайта они остаются То есть если она там за этина за цензуре за обработана то она вот должна оставаться в этих своих ограничениях А мы попробовали решать задачу достаточно полезного на наш взгляд кейса для студентов и аспирантов это превращение картинок формул в их латех код тех - это кто не пользуется не знаю насколько это популярно там в it сообществе но в целом это один из ключевых языков для того чтобы писать технический текст и в принципе все статьи на конференции там в журналы они как правило Реда именно вот латех ну и собственно добавив специфический энкодер который лучше работает именно с распознаванием математических символов мы вот за счёт механизмов фьюза научили модель работать с такими картинками и при этом не просаживается какого-то смежного домена интересный кейс как модель пытается объяснять визуальный юмор потому что на самом деле юмор - это сложная штука как для языковых моделей так и для Понятно мультимодальных Ну вот здесь она как-то попыталась объяснить то есть тут вопрос был именно в том что же юристи в этой ситуации или что странного Ну вот помимо того что она Заметила и обратила внимание на батоны локоны она е сказать горо который я показывал в самом начале действительно добавление визуальной модальности сильно сокращает описание Ну и вот здесь ну здесь ответ на английском языке Но в целом модель может работать и с английским и с русским она сразу понимает что это за здание что это за дворец описывает что это Зимний дворец и даёт какую-то небольшую историческую справку тоже самое с телефоном распознавали модель сразу подсказывает не разводя какую-то демагогию сразу говорит о том что можно идти и покупать micro USB как я и говорил есть ещ и новые возможности потому что всё что я сейчас показывал это в целом говорит про то что мы на выходе выдаём только текст то есть у нас на входе вопрос картинка и на выходе только текст но Что будет если мы захотим работать с картинками например генерировать картинки на выход Мы подумали и решили связать модель Fusion с нашей же моделью которую мы делали там в прошлом году прошлой версии кандински 22 Почему Потому что архитектура и тот механизм 2 очень близок к тому который позволяет кодировать картинку на вход п визуальный трансформер и сделали связку только теперь на выход Мы научились генерировать специальный токен который позволяет по сути потом быть декодированных изобра сейчас модель эта работает именно с целиком как с картинкой То есть если она перерисовываю то она перерисовывать картинку целиком но в целом это вот механизм инструктивно генерации или инструктивно такого изменения изображений это такой интересный тренд и мы сейчас активно Вот Все в наших исследовательских командах работаем в том числе в этом направлении а также интересная штука она называется грандин или понимание расположения объектов это собственно позволяет оценить по плоской картинке где находится тот или иной объект и отвечать на вопросы о том что же собственно с этой картинкой там какие-то сложные вопросы о расположении объектов о том какое действие надо совершить например для робототехники это важная штука ну и в целом вот несколько примеров слева у нас как раз есть картинка И мы просим её там перерисовать в синих тонах картинка перерисовываю в синих тонах и далее приме распознавание какого-то обета когда мы придумываем специальный механизм кодирования графа знаний и уменьшаем моде моделирования Вот например Один из таких механизмов взаимодействия Когда у нас есть просто Мистраль которая отвечает на вопрос отвечает Нет есть другие планеты потом задаёт зачем вопрос в ЧМ разница между жизнью есть связки между отдельными сущностями уже говорит что да там Земля это действительно единственная планета которая поддерживает жизнь начинает какую-то давать справку но уже имеющее отношение к вопросу это тоже очень важно И это для мультимодальных моделей тоже будет полезно собственно выводы ближайший модальности это аудио-видео и мы стараемся в этом направлении сейчас тоже делать исследования мультимодальные аген архитектуры это что это действительно направление котором следует развивать Ну и редактирование изображений инструктивное тоже штука очень интересная и полезная в контексте генеративного и здесь несколько ссылок на р на веб страничку про Om Fusion там же можно посмотреть скачать веса забрать развернуть у себя и собственно поиграться с моделью наша команда мои контакты и ссылка на мой канал где я пишу про исследования про поездки конференции анонсирует там на все ваши вопросы Ну и собственно по классики ссылочка на отзыв лайки дизлайки очень всем приветствуется Спасибо большое за внимание друзья те кто смотрит нас трансляции кликайте по кнопке в плеере переходите в чат и задавайте вопросы там времени на вопросы как всегда мало И те кто хочет очень сильно задать свой вопрос задавайте его в чате те кто хочет поднять руку попрошу Давайте молодой человек В первом ряду Да привет подписан на твой канал Спасибо за доклад я на самом деле немножко в сторону уведу ты говорил про мультимодальной челленджи то есть это больше инфраструктурные челн потому видео это больший обм информации который нужно там как-то прогнать через модель или другие и ещ ты коснулся немножко алайта прямо в двух словах Если можешь Расскажи то есть Каким образом он обеспечивается потому что я там в эту тему не погружался мне просто интересно спасибо да спасибо говоря про это действительно особенность языковых моделей которые позволяет их держать в оден рамках для этого используются разные механи подходы которые позволяют на обратной связи от разметки да Или на определённых правилах э научить модель не отвечать или правильно отвечать на определённый вопрос то есть условно как только у него возникает эмбеддинг который близок к какой-то теме где есть некоторые ограничение то она за это ограничение не выходит и она начинает отвечать там я не могу ответить на этот вопрос Давай поговорим про другое ну то есть пытаться каким-то образом это обходить для этого есть куча всяких Авери подходов чтобы обманывать Модели там и пром и всем остальным но как бы вот так или иначе такая вот борьба двух направлений лаймен и взламывание по поводу челленджей большой Челлендж - это борьба с визуальным контекстом с его длиной потому что эмбеддинг которые выдают энкодеры картиночки есть механизмы которые умеют сокращать это до 140 токенов но в контексте того что у модели есть ограниченный контекст то есть мы же хотим чтобы у нас мультимодальный диалог развивался Нам надо думать на тему того как сокращать контекст но при этом не терять визуальную информацию и это касается в том числе видео потому что подходы которые существуют сейчас они делают что они выбирают из видео несколько кадров они их склеивают Ну типа там видео лава например они склеивают и у тебя видео превращается просто в набор вот этих визуальных токенов по каждому из кадров и ты начинаешь работать вот с какой-то короткой видео последовательностью есть море механизмов интересных есть рекуррентные Трансформеры которые использовались в текстах и на них кстати даже была ссылка в статье Джени это там ребята которые делали ещё в айре когда-то исследование про вот этот рмт визуальный контекст длина способы энкодинг модальностей потому что все пока сконцентрированы На замороженных энкодеров Ну а что если надо на самом деле по-другому их учить Ну и вот архитектурное решение типа end to end пайплайн как вот с рудольфом Я показывал н недавно анонсированы в этом направлении тоже стоит думать и думать как Ахи такие архитектуры не учить их с нуля там много челенже Спасибо Следующий вопрос Андрей да спасибо за доклад Я так понял что такое было введение Как варить мультимодальные модели и что с ними делать Спасибо И я хотел спросить вот вс-таки как будто бы сейчас то что видел всегда по центру стоит МКА большая и мы туда пытаемся вот эти можно какой-то следующий шаг сделать может быть есть какой-то новый Ну придумать новую архитектуру которая будет именно заточена уже под там видео под Ну под различные виды мультимодальной уже Ну сами по себе не пытаться грузить в существующую Ну вот это да спасибо это вот как раз к вопросу о развитии технологии Аля Рудольф э и там действительно есть над чем подумать Потому что они тяжёлые их учить тяжело такого типа архитектуры Но это интересно вот и мы сейчас возвращаемся постепенно к этому направлению э но в виду того что у нас ресурсы в целом тоже не бесконечные вычислительные мы пытаемся как бы вот находить то направление исследовани в которое мы пока укладываемся по нашему GPU но вот если мы вернёмся сейчас к этому то конечно это потребует дополнительных ресурсов потому что э там механики обучения они гораздо более сложный чем вот просто учить адаптер который там какой-нибудь тилер перцептрон по сути или там небольшой трансфор там Значение по обучению затраты на обучение гораздо больше Поэтому взвешиваем риски за и против но это действительно актуально направление Спасибо во втором ряду и потом микрофон пожалуйста Ивану Давайте поощрять спикеров за то что они выступают Спасибо за доклад Вопрос такой А насколько для развития мультимодальных моделей полезны которые вмещают больше информации чем линейные например гиперболические про которые Вы наверняка знаете что ещ раз полезно которы информации больше чем линейные например гиперболические динги или ещ какие-то варианты если если есть какой-то специфический механизм кодирования то он всегда может быть полезно его можно дополнительно подключить к основному эм беру и попытаться тем самым усилить вот это вот векторное представление о визуальной информации Поэтому если есть какие-то механизмы дополнительного эндинга мы стараемся их тоже подключать и вот делать фьюзы с другими специфическими энкодера если нужна сложная какая-то задача Ну например для медицины вот для медицина мы попробовали сделать такую механику мы взяли Дина прикрутили его к обычному Виту и выбили третье место на соревнований по там ответа на вопрос по медицинским изображениям поэтому задача полезная Андрей Спасибо большое за очень интересный доклад у меня такой вопрос скорее в развитии одного из вопросов который прозвучал про длинный контекст когда мы говорим о мультимодальных моделях связанных с видео С обработкой видео действительно длинный контекст он прямо Очень остро актуальной проблемой становится вы упомянули о том что например recent Memory transform можно использовать А насколько сейчас вот на ваш с вашей точки зрения актуально использование других альтернативных архитектур типа structure selective spac таких как Mamba например там ю Visual Mambo или наоборот Возвращение сказать к истокам есть же работы которые показывают что в принципе трансформер модели имеют ряд ограничений некоторые типы грамматик не моделируют А вот старые добрые рекут нейронные сети при всех своих недостатках Они обладают определёнными достоинствами в том числе могут удерживать длинный контекст и моделировать достаточно сложные грамматики вот Возвращение к обратно к чисто рекуррентным моделям э как вы можете оценить перспективы вот в одно в одну сторону двигаться э и в другую то есть два направления ухода Трансформеров в плане длинного контекста Я думаю что это полезное направление и что касается S4 вот этих подходов Space Model State Space Models и мы мы пробовали изучать вот Vis мам но пока у нас это лежит в бэклог экспериментов Но на самом деле там Ну много подводных камней с точки зрения того как это всё учить и что с этим делать но механизмы которые существовали в части рекуррентных последовательностей и рекуррентных механизмов Они конечно для видео почти наверняка будут полезны потому что невозможно закодировать каждый кадр невозможно отвечать на вопросы о длинных видео со сложным сценарием где ты извлечь только ключевые кадры здесь нужно думать на тему того вот как именно компактно представлять в каких-то спец ячейках информацию о там кусочках видео вот Наверно так можно будет это делать но архитектурно тут действительно челлендже очень много друзья Спасибо за вопросы Давайте те которые не успели быть заданными перенесём в дискуссионную зону после доклада нам нужно выбрать обладателя матрёшки дам мне понравились вот вопросы первые Давайте по аплодирую за классные вопросы про челленджи а также у нас есть подарок для тебя Андрей а Уважаемые слушатели и зрители дальше у нас в зале в 13:40 Ольга Кравченко расскажет про коллек тёмную сторону Data Science"
}