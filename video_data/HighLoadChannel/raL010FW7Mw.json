{
  "video_id": "raL010FW7Mw",
  "channel": "HighLoadChannel",
  "title": "Сквозное логирование с использованием транзакционных логов в Росгосстрахе / Александр Крылов",
  "views": 1212,
  "duration": 3049,
  "published": "2022-03-21T13:59:12-07:00",
  "text": "ну собственно всем доброе утро давайте знакомиться меня зовут крылов александр я являюсь ли дон белок совпало иска росгосстрахе параллельно с этим являюсь вокалистом группы terror inside убежденным мясоедом и гиком ну и немножечко преподавателям 2 онлайн-площадки каталоге соответственно если кто-то вдруг будет иметь какие-либо вопросы которые останутся как после кулуаров так и доклада вы можете мне также написать по контактам которые вы видите на экране что мы сегодня узнаем и о чем будем говорить во-первых язык краткая история про мониторинг в ргс связанная с частью пологом по технологиям а дальше мы поговорим о том как мы это выбирали тогда как мы пофантазируем как мы бы выбрали стек технологий под текущие задачи сейчас а какие у нас проблемы стояли на пути основной спич про транзакционные логин коротенечко затронем конвенцию логирование ну и собственно кейс с решением проблем если говорить язык относительно вообще мониторинга и логов которые присутствовали в ргс и где-то образца 14 15 года то здесь можно сказать что это были в основном блоге приложений каталина в эпплджек х проволок сетом докер логе в чистом виде и хорошо там где они были потому что были системы в которых не было от слова совсем ну то есть разработчики в данном контексте подходили примерно так мы пишем логин мы молодцы как что это уже дело десятое что касается технологий здесь все было достаточно просто во первых этот традиционный варлок месседжа из услуги логика про которые я упомянул ранее и perform он мониторинг собственно инфраструктуры что касается логов различных приложений это был большущий зоопарк который постепенно понятное дело несколько унифицирован свои приводился каком-то и дима у типу то есть этологии том кота выплат жкх прокси ее совские логе стандартные без каких-либо обработчиков engine ксо и всякое остальное не на всех системах было вообще в принципе такое понятие как logo rotate и все с этим связанным то есть это просто была большущая помойка которая контролировалась только админами конкретных систем поэтому в общем то это все можно в горбач практически всегда вносить и что собственно в итоге постепенно и происходило какие проблемы мы видели в тот момент а во первых о том что проблема в принципе есть мы узнавали только из сервис диска нет заявок нет проблем ну и собственно если к нам кто-то из бизнеса напрямую не приходил и не кричал о том что у нас проблема там продажи лежат еще что-нибудь значит мы считали что все хорошо если говорить про общую проблематику то это общая отсутствие лагов их разрозненность это не информативность логов ну то есть логе приложения да мы можем сын фона дэбак перевести но это не всегда рабочая история потому что мы видим только часть сервера приложений но при этом бизнес метрик и логов самого приложения если они его не пишут ну а не эти логине пишут то соответственно мы ничего не увидим а разные уровни логирования в каждой система писала как хотела собственно с услуг и warlock менеджер ну и отсутствие бизнес логов как класс вообще таковой то есть его попросту не было теперь вернемся немножечко назад это был семнадцатый год а год когда мы поняли что нужно что-то искать искать решение проблемы а перед тем как искать решение проблемы и выбирать какой-то tool set нам нужно было выработать определенный подход на основе которого мы смогли бы уже делать техническую реализацию и концепт выиграл в нашем отношении и соответствовал всем тем требованиям которые были нам необходимы это оппант racing мы взяли сам концепт посмотрели его плюсы основными из которыми является последовательность событий парсинг время операции которые всегда присутствуют соответственно от request a response а традиционность событий что для нас было важно поскольку систем большое количество и нам нужно было понимать сквозную историю пришел какой то человек который хочет там страховку купить осаго он пришел например в офис где сидит какая-нибудь тетя вася там кто-нибудь и во фронтовую систему вбивает все необходимые данные клиента и нам важно чтобы весь лоб событий от в битья на фронтовой системе и до выдачи полиса клиента физического мы сейчас не говорим про я сага и и тогда еще не было ну то есть электронная и вы весь этот путь мы хотели видеть что собственно в рамках концепции очень хорошо укладывается дальше нам эти события безусловно нужно было как-то видеть понимать идентифицировать то есть помимо сквозной историей мы же понимаем что здесь большое количество систем через которые идет прохождение всей операции там где-то это расчет где-то что-то положить где это нужно пройтись по черным списком клиентов и узнать что там он не является каким нибудь должником уже в другой страховой и так далее и в итоге мы пошли уже по тулс этом то есть концепт был выбран но нужно было понимать зачем мы все это будем реализовывать и возвращаясь немножко назад это по сути был набор tool set of который мы смотрели одним из которых являлся elastic что с точки зрения elastico он появился достаточно давно честно говоря даже цельную дату регистрации в открытых источниках не пишут но год популяризации этот четырнадцатый год и в шестнадцатом после первых elastic концов в шестнадцатом он стал уже идти на массового потребителя то есть в общем то кажется конак в канву а в пятнадцатом году пластику добавил силок стаж и собственно уже близок был тот самый л.к. но до того как у нас появился елка следует упомянуть и саму киба ну которую мы также рассматривали и которая наверное здесь такой самый мастодонт это десятый год когда она массового потребителю стало известно и в том числе ну чуть чуть позже понятное дело пришло на российский сегмент что касается самого елка стыка то это шестнадцатый год плюс минус и его популяризации этого 17 то есть в тот момент времени а это семнадцатый год напомню вам ёлка не был известен массовому потребителю и только какие-то точечные компании уже внедрили его к себе соответственно в тот момент времени именно компетенций в рамках данного стыка у нас к сожалению не было также с планк мы смотрели который появился еще ранее чем кибанов а именно в третьем году и популярны популяризация его в шестнадцатом произошла и крайней инструмент который мы также рассматривали это prometheus который в двенадцатом году появился и был популяризирован восемнадцатом то есть момент времени когда мы его рассматривали он еще был достаточно сырой и без дополнительного напильника далеко не все наши проблемы решал в итоге мы подошли к выбору между elastic ой классической которую мы бы чем-нибудь обернули ну потому что ел к в тот момент ещё не был повторюсь так популярен и собственно с планкам что мы рассматривали во-первых комьюнити наличие экспертизы по которой у нас не было собственно ни там ни там периодичности стабильность обновлений возможность обучения плюс саппортинга россии а собственно платность бесплатность и процесс внедрения в том числе с его вас потенциальным временем не только на уровне внедрения когда там если бы мы взяли какие-то консалтинговые услуги от какой-то из компании но и в том числе в совокупные затраты человеко-часов которые были бы сюда включены в проект на уровне там разработчиков аналитиков которые бы добавляли в качестве требований для новых приложений и в том числе для старых в релизной составляющие о том что теперь нужно готовить влоги так то писать туда там ну и в общем то безусловно у нас были проблемы которые если обобщить в совокупности своей они были более глобальные нежели то что я описал относящийся к лагам но мы их будем проговаривать по ходу всего доклада и я буду говорить в том числе как мы эти проблемы решали а именно разрозненные логии либо их отсутствия неинформативные логе приложений разные уровни логирования syslog варлок messengers отсутствие бизнес логов и тут мы подходим к тому какую вопрос какую проблему мы первоочередно и решали и зачем нам нужно это было решить поскольку ргс так или иначе контролируется регулятор на а именно здесь идет история центробанком и с российским союзом автостраховщиков часть каких-то событий которые подготовят регули турку попадает он на должен во первых быть на уровне отображения во вторых иметь определенную историчность и это важно потому что в любой момент может прийти проверка и сказать ребята нам нужно все события за такой то период времени и собственно что мы хотели видеть и какую самую первую проблему мы решали это возможность видеть операции по печати каско осаго для отчетности собственно от по регулировке и для бизнеса и за сама задача была поставлена примерно таким образом сделать прозрачность бизнес-процессов от попадания заявки в компании до продажи продукта для конечного пользователя то есть клиентам какое же было решение это та самая традиционность тора нам предоставляет концепция up and racing есть очень сильно верхние уровни во событие которое присутствует по тому пути который мы хотели рассмотреть с некой авторизация пользователя который работает на фронте дальше идет вот данных после ввода данных происходят различные проверки в том числе осуществления непосредственного расчета здесь мы также взаимодействуем как и все страховые для ни для кого это не секрет с пирса на уровне расчета кбм а и всяких других операций которые эрсо в которой мы собственно ходим сердца то есть это уже идет как внешний источник с которым мы взаимодействием как на уровне расчета так и оплаты так и собственно выдача фактической продажи выдачи полиса после оплаты у нас происходит печать полюса и собственно отправка его ну над на эту печать если это физический токен если это соответственно электронный осаго уже с текущий момент времени это отправка его электронной версией там по почту клиенту и эта гадость она как-то живет непонятно как но нам вот нужно понимать каждый шаг события и повторюсь это очень сильно вверх не уровневая история понятно что каждый шаг он сильно если его декомпозировать будет много событий мы взяли вот этот верхний уровень и разделили его на набор совокупных критериев безусловно у нас есть фронт есть бог и он они между собой взаимодействуют на фронте есть firewall который связан с авторизацией которая проходит также некий балансировщик есть некая система отправки введена дефекации там ну то есть нужно же подтвердится пользователю то что он это он и в каких-то случаях просто предъявления паспорта она может оказаться не до конца валидный поскольку в системе нужно авторизоваться то есть эта привязка мобильного телефона либо электронной почты и соответственно уведомления там с каким кодом подтверждения на авторизацию системы система ввода расчет оплата внешние сервисы как я сказал verso а собственно сама система печати и итоговая система отправки которая также используется на фронте для авторизации пользователя мы поняли что для того чтобы реализовать это все в неком едином виде нам нужно создать некий манифест постулат к хотите называть в общем свод правил потому как все системы должны писать таким образом постепенно начала появляться конвенции логирования я не буду прям очень сильно по ней углубляться потому что это отдельная большая тема но про говорить про нее стоит основной концепт и цели который решает данная конвенция это первое каждое событие имеет традиционный тип то есть начало и конец и она всегда пишется то есть у нас есть себя started и комплит it a file то есть события понятное дело они тоже должны ну если они имеют свойства ошибаться то они должны также фиксироваться файлам и тут еще важный момент что этот файл в зависимости от того этапа на котором он был завершён он не должен теряться то есть этот файл должен в итоге пройти по всей цепочке и нигде вдруг не стать comply там что тоже важно каждое событие имеет свой идентификатор то есть некий айдишник той самой операции по которой мы собственно будем искать момент совершения ошибки если таковой имеет место быть также каждая система пишет в свой индекс а то есть есть каждая система в каждой системе есть определенное условное пространство куда идёт запись логов именно под конкретную систему но при этом есть общий бизнес индекс в которой идет как раз сквозное идентифицированные для того чтобы увидеть весь путь прохождения этой цепочке котором мы видели ранее совсем коротенечко это выглядит примерно так понятно что я не уместил бы всю концепцию и все возможные поля но то что вы можете реализовать и написать собственно достаточно просто и понятно с точки зрения реализации там разработки я не призываю вас пользоваться конкретным только с планкам все-таки сейчас у нас есть елка есть там про метельский bonay и еще куча всяких других инструментов которые я также озвучу чуть позднее собственно индекс тот самый время совершения важность события система которая его написала некий до индификатор события или action собственно январе mind потому что у нас не все только есть пруд есть тесты которые нам так же нужно смотреть и проверять корректность доработок там будущего релиза который скоро пойдет в прод ну и собственно конкретно идентификатор той или иной ноды системы где могло произойти это событие и теперь как у нас все это выглядит с точки зрения верхнего уровня есть старт от общей есть комплит общей есть единый сквозной correlation по которому мы можем всю цепочку проследить при этом у каждого события есть тоже внутри свой старт комплит это же свой идентификатор некий экшена иди которые относятся там к тому или иному событию и здесь еще важный момент он относится к внешним сервисом нашем случае это пирса там либо какие-то партнера но в общем то эту концепцию можно применить для любой компании в которой есть любые какие либо бизнес событий которые вы хотите видеть и здесь идёт дополнительный нотификатор это объект айди и отжиг type который как раз показывает какая конкретно я интеграция с внешним сервисом по какому идентификатору может быть обнаружена и один из кейсов которые я буду приводить забегая вперед это мы знаем когда произошла проблема в интеграции на внешнем сервисе до того как они об этом узнали порой как это выглядит с точки зрения визуала есть некий блок есть экшн айдишник in warm and errors если они присутствуют собственно идентификатор ноды систему которая написала но и общее верить и понятно что полей достаточно большое количество мы сейчас говорим именно про основные но вы можете используя идею создавать свои поля в том виде и в той информативности которая вам необходима собственно вернемся к нашим проблемам напомню их это разрозненные логе либо их отсутствие не информативные логин разные уровни логирования syslog варлок отсутствие бизнес логов а теперь перейдем к конкретике как каждую из этих проблем применяя данную концепцию мы решали решение первой проблемы с одной стороны простое с другой стороны нет потому что любая доработка тех или иных систем это всегда деньги это человеко-часы и это трудозатраты которые порой могут стоить дороже чем сама система поэтому прежде чем делать подобные доработки особенно в legacy системах дважды подумайте будет ли эта система иметь развитие и так ли вам важно видеть логия в рамках этой цепочке иначе просто окупаемость она себя не покроет как мы решали следующую проблему то есть вот сейчас по сути мы решили проблему разрозненности логов или их отсутствие то есть повторюсь по сути мы написали к о какой-то некий такой универсальный коллектор пусть это будет коллектор для java приложений ну там java гасу spring but котлин и он в качестве некого шаблона используются для сервисов сном с небольшим там напильником с учетом особенностей системы этот коллектор типизировать и дальше был кинут в массы в команды где необходимо было внедрение для реализации этих транзакционных логов а вот теперь уже поинтереснее история тюнинг логов согласно конвенции напомню в конвенции мы определили набор полей часть из которых мы с вами посмотрели и в том числе было приведено табличка то есть одно но нам недостаточно просто выполнить доработку систему нам нужно писать согласно конвенции а именно каждое поле конкретизация события и это важно потому что если у вас будет некорректной записи в полях ну вы сами себе сделайте проблему потому что на основе всего этого в дальнейшем вы можете строить некий мониторинг бизнес-процессов вы можете делать отчеты для бизнеса ну либо там аналитики и в том числе вы можете видеть потенциальный реальный эффект она реальные продажи в случае если совершаются какие-либо ошибки там пост релизные ошибки либо ошибки которые идут факт потенциально связанные там с хардвар ли валом все это важно поэтому как только вы доработали системы вам нужно их даче не говорю то есть этот напильник то есть мы уже решили по сути две проблемы понятно что это было сделано не быстро не за секунду как вот мы с вами сейчас общаемся на это потребовалось некое время но это время окупаем а потому что повторюсь если мы выбираем условно вот этот топ 10 бизнес critical систем на основе торых у нас идут прямой поток продаж и заработок то бизнесу несколько проще обосновать эти трудозатраты нежели их отсутствие и в том числе подсветить те или иные риски дальше ну у нас были разрозненные уровне логирования безусловно нужно приводить их какому-то единому виду то есть у нас есть контура и на каждом контуре есть свой уровень логированием если событий слишком большое количество и мы начинаем захлебываться там где это не надо и хотим видеть например некие только ошибки они постоянно только самого совершении события мы просто переводили его в error ну и соответственно тестовые которая там где необходимо это временное включение 2 бага но ни в коем случае не на постоянной основе потому что индексы они не резиновые ну и собственно мощности с планка как сервера который мы используем также ну и собственно дальше помимо основного напильника из пункта 2 мы делали дополнительный рефакторинг логов для того чтобы вот этот сквознячок он шел в каждой системе единообразно да я буду это повторять неоднократно но это аду один из основных моих поинтов единообразия приводит к тому что у вас все сложено по полочкам как библиотеки и вы можете пока каталогу найти все что вам необходимо для кого это полезно помимо там потенциально нашей 1 поддержки или служба мониторинга это полезно для аналитиков это полезно для тестировщиков на предмет воспроизведения или не воспроизведения проблемы ну собственно для самих разработчиков разработчик допилил там починил баг или фича отдал на тестирование и ребята совместно там посмотрели все ли он действительно воспроизвел ось отеле не воспроизвел ось и собственно вот этот напильник под рефакторинг такой итоговый итоговая гран очка нашего алмаза собственно какие проблемы мы уже условно решили мы решили проблему разрозненность логов или их отсутствие даром путем доработок не информативность логов привели к единому виду и сделали их информативными а свели на нет разные уровни логирования и крайняя проблема которая у нас осталась это выбор форматов в котором мы все будем это писать конвенции логирование это классно но формат записи тоже необходим и в нашем случае этот формат стал форматом джейсоном где-то не далеко не все системы понятно что пишут по умолчанию джейсон путем преобразования доработки и написание определенных коллекторов дополнительных для парсинга приложений потому что часть внешних приложений они ну не в джейсоне передают они передают в том в чем считают скажем так нужным но в случае если идет вход никого нового проекта партнера мы все таки стараемся навязывать общей концепт чтобы все было в едином виде но к сожалению не со всеми это удается ну говорится всегда можно и так давайте рассмотрим различные кейсики одна из которых звучит один из которых звучит не можем определить проблемы на нашей стороне ли нет я немножко спойлерну в самом начале этот кейс мы рассмотрим именно работу с внешним регулятором эрсо но по сути этот кейс работает на любую внешнюю интеграцию которая во вне стен вашей компании наша задача звучит как необходимо снимать луги логе со шлюза при коннекте сердца и понимать когда хорошо из а когда плохо а еще лучше это декомпозировать каждый тип событий по которому мы warsaw ходим и по которым эрсо нам отвечает ну и собственно мы сняли логе с различных балансировщик of a proxy либо класса решение бегай по f5 с использованием определенных регуляров а плюс кодов ошибок и приготовили их единый вид путем того самого коллектора про который я говорил ранее и снимали их просто скрипта шлюза здесь что можно сказать мы за лаги равале балансировщик в нашем случае х прокси лет пять как я сказал а мы сделали дополнительный лог формат и rotate в виде регулярке как я сказал ранее в джейсон формат дальше мы отдаем собственно через форвардеров всю эту радость в отдельный яндекс и строим интересующие нас даже борды понятно что здесь не максимальная информативность и все-таки поместить это к сожалению на слайд не удалось но основной посыл в чем мы можем эту историю готовить с разных ракурсов один из вариантов ракурсов готовки по тому как мы можем смотреть за внешней системой это стандартные коды ошибок серверов приложений и в случае если они возникают у нас соответственно срабатывает некий alert на ответственную группу то есть по сути результат мы какой добились мы наблюдаем бизнес операции по коду ошибок по внешней интеграции по кодам ошибок соответственно серверов приложений как это выглядит в другого разреза то есть у нас все таки помимо кодов ошибок нужно еще понимать какую конкретную операцию мы выполняем и по какой из этих операций у нас это ошибка произошла собственно на слайде примера одной из таких операций это проверка платежа по осаде и собственно если возникает какая-то ошибочка у нас идет стрельбе ту то есть она стреляет после того как ошибка стреляет императивным путем по каждому из типов событий и на основе требований как регулятор ки так и бизнеса мы понимаем какое количество ошибок в какой квант времени у нас является плохим после чего соответственно у нас идет о лифтинг на ответственную группу и уже начинается пожар то что ребята все плохо и здесь результат у нас мы наблюдаем внутреннюю и внешнюю цепочку событий и имеем статистику по ним в том числе историчность здесь на самом деле есть еще один профит он выглядит неочевидным но тем ни менее про говорить про него стоит это возможность предсказания событий то есть потенциально у нас всегда есть будни есть выходные есть часовые пояса и так или иначе пик продаж в тот или иной момент времени мы знаем этот пик продаж мы понимаем что в случае возникновения проблем на системе или группе системы в пик продаж мы будем иметь максимальный эффект на основе этого мы можем написать определенную математическую формулу и сделать некий придет в виде предсказания потенциальных например продаж и мы примерно так же понимаем историю сезонностью то есть у нас всегда есть сезонность есть более частые периоду интервала времени когда всплеск на покупок страховок ну понятно что здесь я рассматриваю кейс касаемо именно авто но страховки то разные есть страховка жизнь собака там от клеща я еще от кого-нибудь и тем самым можно здесь уже подойти еще с одной стороны это бизнес в илью то есть понимая это аналитики могут составить на основе исторических данных определенная там формулу и по ней выстроить прогнозирование продаж и в том числе всю эту историю наложить на примерно гео-локацию по россии и видеть тем самым в какой точке продаж есть не эффективность и их падение особенно не только ну то есть прогнозировать это что это дает по результату есть там филиал уфа есть там филиал воронеж и в какой то момент времени но это я уже немножко фантазирую сменился какой-нибудь менеджер головной которая отвечает за это филиал или директор филиала и здесь если развить эту историю чуть-чуть еще пофантазировать то можно напрямую просмотреть а увеличение или снижение конкретных бизнес-операций при приходе этого нового человека и дальше уже делать или не делать какие-то волевые управленческие решения то есть в общем то кейсов здесь казалось бы чуть-чуть но полезный профит всеобъемлющ собственно про альтинг я уже коротенечко сказал один из видов allure тинга который вы видите на экране выглядит таким образом то есть есть некий шаблон сообщений в которой приходят по почте либо по эсэмэски и идет сразу прямая ссылка на конкретную барду с совершением того или иного события ошибки которого имеют всплеск и сразу isover там мы проваливаемся собственного это событие такие вещи у нас чаще всего приходит бизнес подразделениям тех рукам ну и собственно службы мониторинга целевым ребятам которые первые кричат алярм алярм если он возникает и по сути результат здесь такой же мы наблюдаем внешнюю и внутреннюю цепочку и статистику ошибок по ним в том числе на основе а лифтинга который можно также дополнительно ну скажем так историчность сохранять и при разборе каких-либо проблем более четко понимать почему эта проблема возникла она внешняя она внутренняя она связана с релизом внешним или внутренним и так далее здесь можно развивать эту тему на самом деле очень по-разному и крутить ее в разные стороны но мы пойдем дальше по сути напоминаю опять да про проблемы я не устану про них повторять потому что они были мы решили разрозненность логов их отсутствия не информативность разные уровни логирования отошли максимально от слова и варлок mis ojos и вообще всяких системных логов которые если где-то и остались в неком видео не больше идут на эксплуатацию на уровне хардвера и соответственно за конкретные подразделения ответственные их получают ну и собственно запилили бизнес логе согласно той самой конвенции про которую я упомянул ранее и казалось бы мы все проблемы решили но давайте посмотрим какие еще кейсы можно рассмотреть есть такой интересный кейс когда есть например какое-то приложение и это приложение в случае перезапуска должно прогреваться то есть у него есть кэш но по умолчанию если вы сервер приложение перезагружайте а чаще всего при релизе такое потенциально возможно нам нужно прогреться то есть у вас есть продажи у вас есть техническое окно с релизом и есть например кластерная по но данность мы понимаем что период времени на разогрев в конкретного приложения составляет x количество времени там допустим 10 минут и для того чтобы иметь минимальный скажем так эффектно наши продажи мы понимаем что помимо конкретного времени где у нас идет техническое окно которым соответственно мы выделяли на основе максимально низкого количества продаж в конкретное квант времени в сутках мы делаем релиз при этом делаем его пан 1 то есть по сути мы выкатываемся по нодди тем самым выводя из балансировки ту или иную народу это все делается автоматически выкатили прогрели кэш если никаких дополнительных ошибок нету едем дальше если соответственно проблема есть там и быстренько ролл тычемся и все идет по новый а там уже идем в trouble shooting разбор всю эту историю на уровне разработки аналитики тестирований собственно как так и почему это произошло собственно тоже один из неочевидных кейсов а считаем моего процентиля my девяносто девятом и 95-м и когда у нас есть понимание того что кэш прогрет мы едем дальше кстати здесь не знаю насколько видно но на одном из слайдов в одном из мест вот мы видим что был как раз релиз благ ну или не релиз а просто перезагрузка и операция не брались из кэша то есть и кооперации большой но при этом и тайминг времени то есть у нас если мы берем здесь икс игрек то по одному у нас идет именно время и количество событий а по-другому у нас идет именно время выполнения событий то есть мы его также считаем и накладываем на процентиль и как только у нас вот эта история нормализуется и мы дальше видим что все хорошо мы собственно будем можем ехать дальше опять же если не возникло каких-либо ошибок после самого релиза и какой здесь основной профит это раннее обнаружение сбоев и их расследование также какой еще здесь есть использования может быть мы можем проводить определенного рода расследования и давать обоснование бизнесу в случае возникновения проблем и показывать пальцем кто виновен и в чем то есть у нас есть определенные систематические метрики на основе которых мы понимаем систему ошибку бизнес операцию прямой или непрямой эффект на продажи и собственно все последствия которые идут за ними также это очень полезно особенно тогда когда нужно например обосновать до закупку железо то есть приложение развивается понятно что растёт там периодически тех долг может падать производительность в случае если quality gate и по юнит тестом при сборке не проходят и это все потенциально идет к релизу который также может иметь эффект если же у вас это произошло и при этом оно происходит не на уровне тех долга или плохого кода а именно из за того что в код добавилось много новой функциональности и по этой новой функциональности у вас идет большой списка активности вы можете перед бизнесом понимая релиз дату когда будет эта всплеска активность тут самое популярное эта история с черной пятницей из какими-нибудь онлайн-магазинами любых продаж вы понимаете что вас могут заддосить вы можете упасть вы благодаря этому и статистики с конкретными цифрами и данными можете подойти в бизнес и обосновать ребят у нас тут будет нагрузка нам нужны деньги на то чтобы масштабироваться и уметь масштабироваться там в виде горизонталки и потом обратно схлопываться и соответственно дайте денег и на основе всей этой радости как бы это печально ли не печально у нас также настроена лифтинг для бизнеса то есть если раньше мы чаще всего понимали что что-то идет не так по всплеску заявок от пользователей hal диске то сейчас мы сможем узнать о том что к нам уже вот сейчас идет бизнес до того как он собственно увидит эти месседжи нота здесь есть маленькая хитрость в виде отложенного сообщения лифтинга чтобы служба поддержки и могла его увидеть быстрее чем бизнес а еще лучше если бизнес это не увидит и не увидеть в том числе эффект ну как это пофантазировать то никто же не мешает а ну и здесь еще такая интересная штука как до композиция проблем на большие разрезы временем то есть есть проблема есть и и некая критичность и она напрямую влияет на продажи с учетом вот этого приедет и которой я говорил ранее и потенциальных прогнозов мы понимаем что если у нас проблемы случилось какой-то момент времени то у нас будет максимальный эффект либо в тот момент времени когда эффект не был максимальным и тем самым мы можем мы не можем мы это делаем в общем-то расследовать все эти проблемы отвечают бизнесу почему собственно и в том числе максимально быстро проводить расследование внутри самого дита ну и настроить безусловно этот альтинг с потенциальным приди там какие еще дискете использования могут быть ну например есть большая нога кластерная система и вы можете потенциально спрогнозировать выход из строя какого-то компонента кластер а то есть есть набор кластеров есть декомпозиция всплеска ошибок на квант времени и в случае если этот периодичность увеличивается ну нужно значит что-то делать явно что-то с но дай если уже сейчас не так то дальше будет явно не хуже ну здесь понятно решение там может быть на уровне кода на уровне инфраструктуры но если это все таки nicotine фра то мы можем увидеть из прогнозировать падение конкретные ноды там либо bare metal либо там виртуалке и собственно коррелировать ошибок по этим модом такой вот тоже не хитрый кейс вот пример один из вариантов отображения для мониторинговой стены как это все можно также смотреть здесь на самом деле очень интересная картинка и она показывает как раз мониторинг наших внешних интеграций на наших партнеров а некоторые конечно пришлось замазать но безусловно же есть и те с которыми есть взаимодействия и тут кстати на момент времени была проблема с одним луну на стороне одного из партнеров что я решил зафиксировать и скажем так не говоря вслух но показываем что такое тоже бывает давайте посмотрим будущее собственно мы хотим проводить испытание находить непокрытые места по например коду и находить ошибки интеллектуальную фильтрацию автоматическую али ртов и их декомпозиция развитие конвенции и и переключения ее в единый подход к мониторингу чтобы было понятно определенного рода объемы но понятно что это там не google не amazon но тем не менее по различным типам операции там те же самые расчеты у нас по сути в сутки это бог более полутора миллионов происходит ну то есть некий хайлов здесь тоже присутствует понятно что он не мега большой и все познается в сравнении но для нас это уже не мало маленькая фантазия как бы мы выбирали собственно систему и tool set сейчас если бы ее выбирали именно сейчас и у нас были те проблемы которые я озвучил в начале доклада собственно все просто концепция open телеметрия она очень хорошо решает проблемы связанные с логированием и объединяет в себе концепция up and racing и еще набор различных концепций которые сейчас достаточно широко набирает популярность собственно тем кто это только создает не рекомендую ознакомиться здесь также присутствует ссылка на блог с описанием данной концепции очень интересная штука ну и что касается стыка здесь есть история супер трейдингом и а по центру сам внутри которой она ну собственно не находятся внутри окон телеметрия и есть также вариант с гарниром который никто не отменял и топ-10 систем которые мы бы рассматривали эта война mix дай no trace тот же самый фланг ягер съел к ягер с прометеем слишком рано нусуп вот как мы видим по gartner он сейчас эти системы они в топе так что либо мы пришли бы к тому же на базе с планка либо выбрали что-нибудь иное ну предлагаю потихонечку подходить концу и делать заключения ну что я могу сказать наверняка во-первых традиционные логе это круто и если вы их используете и умеете готовить то вам большой респект ну собственно всем рекомендую дальше up and tracing это хорошо но окон телеметрии это еще лучше на уровне подхода описание концепция и тому как можно последствий выбирать tool set на основе в ваших требований дальше важный момент выбирайте те инструменты в которых у вас есть компетенциям потому что если вы выбираете инструмент вслепую без наличия компетенций по ней то вы будете тратится больше как минимум на консалтинг и на внедрение той или иной системы дальше при построении подхода к мониторингу внешних интеграции его всегда можно масштабировать то есть один раз реализовав подход и приготовив его вы последствии можете его пригнуть масштабировать на любые ваши внешние интеграции и дальше уже обвешивать всякими рюшечками и собственно итоговый итог скажем так заключением масло масляное выбирайте подходы инструмента которые актуальны сейчас то есть в архаику не лезьте если вы выбираете инструмент который условно умрёт через небольшое количество времени ну вы сами себе стреляйте в голову не в ногу собственно на этом все если у вас есть вопросы задавайте спасибо большое поблагодарим докладчика если есть доклада у нас в онлайне то мы попросим а сейчас вывести на экран и будем готовиться а сейчас в зале давайте так начнем вот у нас молодой человек начнем с него и потом и потом он туда да да вы говорили что даете ну то есть у вас бизнес тоже настроена epilogue то есть принимаются какие там и управленческие решения бизнеса вы решения под развитию то есть у вас получается пользователь из планка это не только там разработчики и сопровождения но и и и бизнес и и или вы какой-то отдельным визуализацию сделали да все верно понятно что первичные пользователи это эти подразделения но в том числе с какой-то момент времени понятно что с ограниченным количеством информации мы в том числе бизнес пустили аналитиков по ну и собственно те подразделения которые например создают новые продукты здравствует спасибо вы club скажите как вы решаете ситуацию когда возникает какое-то замедление вот на цепочке вот выполнение этой операции то есть логе они как бы про результат операции успех не успех если операция заканчивается успехом но допустим после диплома в каком-то из компонентов выполнение этой цепочке по операция стала выполняться дольше какой-то решаете ну как находите я понял хороший вопрос спасибо на самом деле здесь все очень индивидуально слоев много и эта история может быть как по перформанса и там выходу потенциального из строя ноды вот например и которые я показывал проблема может быть связано с внешней интеграции и например если у партнера что-то сбоит потенциально временно операцию может быть увеличена ну вот да как вы находите вот то что вот стала у нас есть если со стороны бизнеса и есть понимание транзакции на уровне request response а и понимание того сколько времени хорошо сегодня понял да это отвержен как раз alert и вот вы движетесь его в сторону опыт телеметрии какой у вас рот map когда как вы хотите достичь это замена wait up and рейтинга на опыте lamie3 ну на самом деле мы в нее не движемся мы по сути уже в ней повторюсь идей же была такая некая фантазия и просто постепенно модернизируя нашу конвенцию мы по сути практически полностью перри использовали подход телеметрии и получилось то что мы ненароком взяли и перешли в них давайте вопрос рейтингов обсудим в quark к сожалению да время ограничено всех кейсов показать достаточно хотя тоже проедет конечно спрашивать но я и папа попойки приду к тебе за твоей душой проблем да спасибо за вопрос и давайте вот здесь еще вопросик на статью в онлайне как есть нет да так давайте вопрос прости меня за трек 7 мне оди рисует больше по цифрам вы показали 20 миллионов событий в день сколько это в гигабайтах в 3 байтах но поскольку все таки мы если берем разрез объемов там и с нескольких сторон их контролируем но как правило непосредственно объемами регуль ну оперирует непосредственно админ с планка я сходу не смогу сейчас сказать эту цифру потому что она постоянно видоизменяется но объемы но понятно что это там не полне google объем есть несколько сожалению конкретную цифру не смогу сказать потому что в реал тайме не обладает информация на следующий вопрос был по краске сколько оборудования требуется для поддержания таких объемов ты понимаешь что цифр у вас тоже нет вряд ли а здесь я несколько иначе отвечу здесь даже дело не в цифре а в том какую глубину событий мы хотим видеть и там где эта история с регулятор кай это конкретное событие там за месяц за 3 месяца а там где со дна мне интересно историчность и храним там условно неделю и вычищаем постоянно а те события которые мы соответственно хотим видеть на достаточно большом промежутке времени мы их архивируем мы сжимаем а потом если необходимо соответственно достаем их если там хотим по регулировке ответить на вопрос либо там cut корреляцию просмотреть ну да конкретный объем и повторюсь как вы правильно заметили сожалению сейчас не назову но они не маленькие спасибо большое так и давайте вот уже барочным в конце спасибо большое за доклад саша на самом деле присоединяюсь к предыдущему вопросы я хотела знать пробьем и но может быть ты расскажешь сколько у вас там я не знаю свои втер че пользователей так далее вот может и про эти аспекты знаешь еще коротенький вопрос использовать или вы метрики и льете вы x-plan или вы пользуетесь другими приложениями спасибо большое за вопрос по пользователям приблизительно сейчас в данный момент времени если брать did и процент использования то есть аналитики разработчики эксплуатации это порядка где-то 1000 пользователей если брать плюс бизнес ну это наверное еще в районе 200 ну то есть где то грубо но примерно полторы тысячи пользователей с планка понятно что они не все в реал тайме имеет connect a real-time идет больше на мониторинг а там где это идет полторы примерно полторы тысячи пользователь что касается других средств у нас есть еще также отдай на mix но это уже другой слой от с планки uno ну то есть каждая система у нас отвечает за свой функционал есть purple он есть applications есть бизнес и лог tracing бизнес и лог tracing со всех систем который бизнес critical а не только с планки больше нигде их нет а все остальные которые относятся к персону либо к applications они находятся в других системах и вот полностью ответил база вопрос и давайте поблагодарим александра закрыта на вопросы зандер небольшой презент от организаторов конференции говори давай выберем какой-нибудь вопрос зале который тебе понравился а вот молодого человека вопрос давайте поблагодарим его брезентом и на этом мы будем заканчивать это выступление александра и он уходит в дискуссионную зону которая прямо здесь при выходе на право я попрошу всех проследовать туда вместе с ним а зал очистить чтобы здесь могли провести профилактику спасибо вам большое и жду вас на следующем выступление"
}