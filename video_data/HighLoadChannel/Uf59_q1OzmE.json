{
  "video_id": "Uf59_q1OzmE",
  "channel": "HighLoadChannel",
  "title": "Как мы делаем трейсинг в условиях тысяч сервисов и миллионов спанов в секунду / Игорь Балюк (Авито)",
  "views": 17449,
  "duration": 3032,
  "published": "2024-07-04T03:49:58-07:00",
  "text": "на сцене Игорь балюк Авита в правильном мерче Всем привет Я действительно Игорь и я работаю в Авито я делаю платформу платформа Авито - это некоторый горизонтальный слой некоторая абстракция которая под собой прячет тяжёлую непонятную инфраструктуру от наших любимых продуктовых разработчиков тем самым мы снимаем рутину с наших разработчиков не заставляем их думать как писать кубернетес манифесты как им создать сервис чтобы он правильно провинился и так далее более конкретно моя команда занимается двумя вещами одна из них другая из них - это обби под обби обычно понимают логи и трейсинг как раз-таки О рейсинге мы сегодня и будем говорить всю идею доклада Можно попробовать уложить в одном предложении как и зачем мы делаем трейсинг в Авито и здесь важна каждая часть часть как будет хитек какие у нас есть компоненты как эти компоненты друг с другом взаимодействуют и что мы там внутри наворот про мотивацию почему трейсинг - это что-то крутое и почему мы в него вкладываем Почему мы считаем что это будущее почему он нам помогает Ну и последняя немаловажная часть Авита - это не маленькая компания из-за этого некоторые стандартные решени перестают работать Давайте сразу закроем последний н что Авита не маленькая компания во-первых У нас тысячи сервисов абсолютно разных не похожих друг на друга много баз данных у нас везде кубернетес десятки кластеров я с собой принёс У нас очень развитая платформа и мы любим абстрагировать наших разработчиков от всех сложностей той самой инфраструктуры конечно же на Авито падает огромный трафик мы обрабатываем сотни тысяч квестов ВС это приводит к тому что платформа о которой я расскажу дальше обрабатывает более 10 млн снов в секунду но чтобы выровняться Давайте начнём с определения немного вспомним Что такое трейсинг под рейсингом обычно понимают некоторый способ или технологию отследить путь внешнего запроса в вашей системе Давайте представим что у вас есть большая система в ней много сервисов много компонент есть базы данных есть какие-то другие специальные хранилища и мы смотрим на конкретный запрос от пользователя внешний запрос Посмотрим по каким компонентам прошёл этот запрос запомним все из них запомним каждый сервис который участвовал в обработке этого запроса каждую такую промежуточную точку мы назовём Спан добавим в этот Спан информацию про имя компонента добавим туда какую-то Мета информацию например статус код ответа по http http путь что-нибудь такое соберём эти Спан вместе в рамках одного запроса и получим трейс уже выглядит интересно уже можно посмотреть А как в принципе устроена наша архитектура Какие компоненты участвуют в обработке каких-либо запросов но можно сделать интереснее можно на эту диаграмму добавить время каждый раз когда запрос будет попадать в сервис сервис будет запоминать когда он начал обработку запроса когда закончил это вот временное окно назовём длительностью спанна и нанес на диаграмму Мы научились делать две важные вещи во-первых мы теперь больше знаем про архитектуру наших приложений делает приложение какие-то последовательные запросы синхронные или это какие-то параллельные запросы что как правило эффективнее более того что на самом деле интереснее мы теперь знаем куда именно уходит время на обработку запроса запрос обрабатывал 10 секунд а кто ответственен теперь мы знаем что ага 5 секунд мы потратили в базе данных 3 секунды потратили в каком-то одном сервисе 2 секунды в другом можно понять что база данных для нас даёт самый большой оверхед повод оптимизировать ресурсы или оптимизировать запрос и базовый трейсинг позволяет делать анализ архитектуры что у вас есть в вашей системе и он сильно помогает во время отладки отладки таких больших распределённых систем он сильно ускоряет поиск руко сильно помогает понять а кто виноват в том что пользователь получил Ошибку кто виноват в том что запрос обрабатывал се так долго и дальше мы поговорим Как именно это устроено у нас начнём с некоторого overview большими мазками Давайте клике поможем отлично начнём мы с эволюции и трейсинг у нас существует довольно давно мы начали ещ в дем году и установили довольно стандартный для тех времён набор ерь И elastic sech какое-то время это посулов нутри этим не пользовался потом мы поняли что надо что-то менять увидели что все переходят наха вяли е и вместо него поставили кликхаус всё начало летать стало очень быстро и разработчики внутри компании увидели пользу в трейсинг он уже начал им как-то помогать и Они уже сами начали анализировать какие-то инциденты с помощью этого инструмента трейсинг нам начал очень сильно нравиться мы начали больше в него вкладываться и в какой-то момент заметили что все компании начинают переходить на новую технологию Open Мы решили что мы ничем не хуже давайте тоже это делать мы взяли протокол егеря отбросили его поставили новый протокол переделали нашу инфраструктуру и начали жить как современная компания по состоянию на текущий год мы продолжаем жить с кликхаус он нам очень нравится мы усложнили наши умет и пайплайн мы добавили туда больше данных и мы сделали собственные uui чтобы анализировать это всё вместе теперь перейдём к самому началу С чего начинается трейсинг Представьте один сервер в данном случае это куртис Noa на кубернетес ноде запущено много подов много приложений которые разработали наши разработчики но один из подов он специальный технический его сделали мы и задача этого пода Агента принимать Ту самую телеметрию принимать сны от приложений когда приложение генерирует Спан оно отправляет его в наш агент агентов очень много потому что кубернетес серверов У нас очень много после каждого кубернетес сервера следует некоторый слой балансировки нагрузки и данные попадают в коллекторы коллектор - это ещё одно наше специальное приложение коллектор получает данные обрабатывает их как-то и дальше отправляет в хранилище в лиха в нашем случае и агенты и коллекторы это собственные приложение написанные на го в рамках Open telemetry пайплайн Open telemetry - это некоторый фреймворк набор СДК библиотек коннекторов который сильно упрощает работу с телеметрией со всеми этими трейсинг логами метриками в текущем мире есть много готовых имплементации как для подключения источников данных для организации успешной обработки данных и для дальнейшей отправки данных в какое-то хранилище возникает разумный вопрос зачем вам два ваших собственных приложения которые стоят рядом более того на одном языке программирование использующее один и тот же протокол идея вот в чём агентов Очень много они заставлены на каждом сервере из-за этого агенты не должны создавать большой оверхед они должны быть супер простыми и супер эффективными их задача получить данные собрать какой-то батч данных и дальше отправить эти данные по конвейеру коллекторов в свою очередь существенно меньше в нашем случае 60 60 Для нас это мало Они опять-таки получают данные агрегирующие информацией и только потом отправляют в хранилище со стороны приложени со Роны сна его жизнь выглядит см образом создаёт Спан например Потому что пришёл новый htp запрос дальше этот Спан из приложения попадает в Агент Агент набирает какой-то кусочек этот кусочек отправляется в коллекторы коллекторы что-то там делают как-то это обрабатывают и всё попадает в кликхаус кликер сегодня грустит на самом деле ВС немножко сложнее между коллекторами и кликхаус у нас есть асинхронная очередь мы используем кафку разумный вопрос зачем кавка Зачем нам ещё один компонент который усложнит систему Хаус очень специфичное хранилище кликхаус не любит когда в него пишут слишком часто поэтому кавка у нас скукоживается тот объём данных который идёт мы его аккуратно собираем и вставляем в кликхаус большими чами очень редко тем самым мы начинаем лучше контролировать скорость записи в эту базу данных плюс Если с Клик хаусом что-то случится то кавка для нас служит некоторым durable хранилищем хранилищем которое сохранит данные в течение какого-то короткого периода времени пока база данных недоступна пока она деградирует интересный вопрос сколько это всё потребляет во-первых нужно сказать что мы обрабатываем действительно очень много данных для такого пайплайн событий в секунду если посмотреть на трафик от агентов до коллекторов сколько мы передаём данных по сети то это более 6 Гигабит в секунду но процентиль потребления на агентах у нас чуть больше одного ядра и чуть больше 1 гигабайта оперативной памяти плюс скачки там довольно небольшие то есть среднее значение отличается не так чтобы сильно если говорить про коллекторы то они действительно сложные приложения им нужно много ресурсов поэтому суммарно все наши коллекторы потребляют более 500 ядер и более 600 ГБ оперативной памяти но на самом деле интересно не абсолютное потребление а относительное Как меняется потребление ресурсов в зависимости от увеличения потока данных которые есть в системе и мы это посчитали на Верхнем графике отображено потребление процессора на коллекторах а снизу мы нарисовали объём данных который идёт в этот коллектор и видно что потребление ресурсов почти что линейно зависит от объёма данных который идёт в системе и это логично И это хорошо что у нас так получается на нашем объёме Это значит что мы линейно масштабируется и мы посчитали что если нам в систему начнёт идти на 10.000 спано в секунду больше появится новый сервис новая база данных изменится где-то специфика то нам в систему потребуется добавить ещё примерно одно ядро и чуть больше 1 гигабайта оперативной памяти мы посмотрели какие у нас есть компоненты базовые Давайте теперь спускаться вглубь посмотрим какие есть детали у этого всего какие есть сложности во-первых вам нужно как-то связывать спа вот у нас есть запрос от пользователя внешний он прол через много сервисов Через много компонент везде создался какой-то Спан нужно эти сны связать это можно сделать с помощью какого-то единого идентификатора идентификатора запроса или Trace ID если мы говорим про http протокол который используем мы довольно удобно пробрасывается внешний запрос в нём уже есть этот Trace ID ID запроса задача сервиса когда он начнёт обрабатывать этот запрос когда он нач внутри себя приложений вызывать другие функции всё время как-то протаскивать этот Trace ID чтобы когда сервис сделал какой-то внешний запрос чтобы получить какие-то данные например он мог в этом внешнем запросе сохранить тот же самый контекст сохранить Trace ID если говорим про htp или про другие какие-то веб-сервер про другие как-то его анализируют достают оттуда Trace ID в какой-то контекст его кладут и дальше запускают этот запрос в вашу программу задача программиста в этом месте не потерять этот контекст если мы говорим про язык Go который довольно у нас популярен то как правило всё обходится средствами стандартного контекста необходимо получить ID в каком-то интерсек это ID закинуть в контекст и вызвать обработчик запроса далее программист тот самый контекст прокиды будет дальше если вы пишите на Python либо на PHP скорее всего у вас есть некоторый глобальный й для текущего процесса или Rad Local storage и можно эту информацию засунуть туда всегда Иметь к ней доступ так будет работать в jav котле не можно что-то красивое придумать с рефлексией у нас так как го это популярный язык в первую очередь мы помогаем программистам с помощью готовых Тех самых интерс для обработчиков запросов они у нас есть уже в каждом сервисе Каждый раз когда разработчик Авита создаёт сервис он это делает по какому-то шаблону и в этом шаблоне мы уже подключили все нужные библиотеки уже есть красивая нужная структура кода более того у нас развитые платформенные библиотеки для похода в базу данных если разработчик хочет подключиться к посу редис и так далее мы советуем использовать наши имплементации которые используют другие имплементации допо спа тем самым мы покрываем рейсингом походы в базу данных со стороны клиента помимо этого в нашей системе есть общая шина данных некоторая обёртка над какой-то асинхронной очередью Когда в неё публикуется сообщение вместе с этим сообщением мы стараемся сохранить тот самый ID таким образом когда коню вычитает это сообщение начнёт его как-то обрабатывать выполнять другие запросы он сохранит этот Race ID тем самым Мы научились связывать создание события и его обработку и дальнейший анализ Но жизнь разработчиков по-прежнему сложна программистам по-прежнему приходится много напрягаться чтобы создать Спан в его сервисе Необходимо написать какой-то код явно подключить какую-то библиотеку а теперь Представьте что у вас 000 сервисов И вам нужно сделать какой-то обновление сделать какое-то обновление в библиотеке изменить правило по которому вы именует сны или изменить какую-то другую его часть и это делать сложно но на помощь нам приходит сервис smh Если попробовать базово объяснить что это такое то Представьте что каждому вашему приложению вы сбоку подставляется ещё некоторую специальный прокси некоторый Сайка этот Сайка будет перехватывать весь входящий и исходящий трафик из этого приложения и что-то с ним делать почему это полезно тот самый Сайка например Проси имея и зная про каждый htp запрос в системе может самостоятельно создавать сны на каждый этот запрос Как это работает у нас есть сервис в сервис сверху приходит какой-то запрос перехватывает этот запрос видит что это http протокол создаёт Спан и прорут запрос дальше в сервис сервис как-то обрабатывает запрос ихо сде вызов делает внешний htp вызов например htp этот запрос опять-таки попадает в тот самый й видит его ещё раз и создаёт ещё один Спан потом запрос идёт в другой сервис и картина повторяется всё тоже самое все Сны которые создаёт у нас идут по стандартному пайплайн попадают в тот самый агент который запущен на каждой кубернетес ноде Агенту всё равно кто создал Спан был этой или приложение как это помогает теперь благодаря этому нам достаточно снов от наших й каров даже если разработчик не подключил библиотеку для создания спано или не создал Спан Окей мы сохраним картину нашего сетевого взаимодействия мы будем знать как общаются наши сервисы так как за каждым сервисом стоит этот специальный сайдкар плюс мы делаем меньше вмешательства в код приложений мы меньше требуем от разработчиков и нам не так важно На каком языке программирования наши разработчики для сеш важен только сетевой протокол более того Так как эн воем в нашем случае управляет одна команда конфигурировать его умеем мы гибко прямо в ранта И если нам нужно обновить как-то правило нейминга этих снов Для нас это сделать очень просто так как это единый компонент нам не нужно поддерживать Это для множества языков которые развиты в компании хорошо поговори сервис smh Давайте спускаться ещё глубже Давайте обсуждать ещё какие-то трудности которыми у нас были начнём мы с данных довольно стандартная картина у вас очень много данных какой-то просто контейнер данных и в то же время Ну вот столько дисков очень мало к вам приходит менеджер и говорит ну надо что-то делать Первая идея - это Ну давайте как-то данные оптимально хранить как-то сжимать их так можно делать Оке вы сделаете Так что сможете сохранить на 5% данных больше но проб е не ула потом вы понимаете что нужно взять эту гору данных выкинуть оттуда 90% потому что они не нужны и сохранить только 10% из них это называние мы так и пост когда и начали с самого простого варианта который называется ирование сло Какая и пори самы вни зава когда мы создаём корневой Спан самый первый Давайте подбросим монетку запустим Рандом а Будем ли сэмплировать данный трейс и запомним результат вместе с ID если не повезло Рандом сказал что сэмплировать не нужно все сны будут откинула этот результат прокиды дальше по вашей системе чтобы согласовать работу всех сервисов меж собо опки ВВ довольно просто это быстро работает и скорее всего если вы будете делать сапли это логичный шаг Как можно начать его делать но есть проблема Когда вы подкидывает монетку в самом верху вы не знаете что это за запрос вы просто ориентируетесь на Рандом вы не знаете это важно для нас бизнес сценарий или нет можно сделать Лучше давайте сделаем симпли с хвоста сначала сорм все сны рейса и посмотрим на это интересный или нет этот запрос полезный для нас или нет хотим ли мы его сохранить или нет И уже здесь Можно придумывать умные эвристики например мы как правило отдаём приоритет ошибочным запросам Если в рамках обработки всего троса была где-то сгенерирована ошибка Мы очень сильно хотим сохранить этот запрос Почему Потому что потом когда разработчик придёт анализировать систему его как правило интересуют Ошибки здесь можно придумать много всякого интересного например Вы можете сохранять тросы по длинным запросам которые шли больше 5 секунд по запросам которые прошли через какой-то специальный компонент в вашей системе который вам очень хочется отследить Но это сложнее вам потребуется где-то теперь агрегировать ваши данные дожидаться пока вы получите все спа по вашему рейсу от всех микросервисов где были сгенерировано ваши спа и из-за этого коллекторы у нас потребляют очень много оперативной памяти хорошо мы сделали лучше но монетка вот тот самый Рандом по-прежнему несправедлив у вас большая система очень много сервисов и довольно стандартно что какие-то сервисы обрабатывают очень много запросов очень много бизнес сценариев участвуют в большом числе взаимодействии в вашей системе А есть не нагруженные сервисы в которые идт один запрос в минуту Но эти сервис оче ж ше бизнеса можете думать про сервис для выплаты зарплат вашим работникам в него будут обращаться несколько раз в месяц тем не менее он очень важен если с ним что-то хочет случиться очень хочется отследить Это и так как запросов туда идёт очень мало эти данные для нас весят почти что ноль ничего не стоит сохранить их мы увеличим объём хранения на 5% Но покроем нашу систему намного лучше если начнём сохранять такие редкие запросы и здесь можно зайти с двух сторон во-первых стандартный механизм принудительного сэмплирования Давайте интересные для нас тсы интересные для нас бизнес сценарии запросы помечать каким-то флагом что их нужно сохранить например с помощью некоторого htp заголовка если в тросе в его снах был этот самый htp заголовок мы его 100% сохраняем это можно включить и проставлять на Эх длях бизнес использовать во время отладки когда qa или разработчик либо кто-то ещё хочет отладить его приложение на продакшене или на стейджинг будем более аккуратными он может подставить этот заголовок И тем самым он потом увидит все свои запросы и сможет их быстро проанализировать но можно убрать эту рутину человеческую и попробовать в целом улучшить состояние в нашей системе сделать глобальное улучшение Давайте попробуем Посчитать все редкие запросы происходит в нашей системе как-то ведём некоторые идентификаторы запроса с точностью до сервиса и до например htp путя если таких рейсов было очень мало за последние 10 минут например Их не было вообще Давайте его 100% сохраним он не создаст много нагрузки Именно так мы и сделали с единственным исключением делать точные счётчики и считать число уникальных запросов в системе дорого для этого нужно какое-то хранилище в которое нужно ходить потом нужно как-то эти данные удалять не хотелось этим заниматься поэтому мы взяли вероятностный алгоритм Count mech поставили его в наши коллекторы тем самым мы не получили стопроцентную точность но получили довольно хорошее числа за очень дёшево mech не требует много ресурсов но для его хорошей работы нам пришлось синхронизировать его между всеми коллекторами Однако это существенно дешевле нежели точные счётчики тем самым мы сильно улучшили покрытие нашей системы при этом не нагрузил диски вспоминаем что разработчиков очень много и разработчики любят разные протоколы и подходы для формирования API нпои кто-то использует rpc кто-то использует ре кто-то в http путь подставляет какие-то динамические параметры например ID пользователя ID объявления ID операции пускай пускай так для это создат некоторую пробле во-первых такие данные сложно хранить они создают высокую кардинальность в наших хранилищах и индекс работают хуже во-вторых такие данные сложно анализировать Когда вы хотите отладить свою систему вас интересует не конкретный запрос вот по такому вот http путю с таким вот ID пользователям вы хотите получить некоторый overw агрегировать эти данные сжать идуть вме того самого числового льва параметр который будет мать все запросы которые подходят под эту регуляр мы так сделали и заходим Мы с двух сторон во-первых Каждый раз когда любой сервис Вита хочет предоставить некоторый API метод новый эта информация просачивается в его openi схему в этой openi схеме у нас есть patter и всё отпер этого э паттернам и заменяем оригинальный htp путь на тот который находится в регулярке с другой Роны есть не только сетевой взаимодействие не Получи всё покрыть openi схемами разработчики создают свои сны есть сны в баз данных и там никами схемами не пах че покрыть это как-то автоматически мы это сли вяли некоторый алгоритм 2010 года который смотрит на набор данных ищет похожие http пути выделяет какие-то общие токены выделяет какие-то высоко кардинальные данные и всё это схлопывается у нас в коллекторе после того что я сказал может сложиться впечатление что Рейн - это логи и где-то витает мысль что зумеры зачем-то перели те самые логи мы это умели делать 10 лет назад просто в логи добавляем request ID correlation ID и дальше ищем логи по такому параметру Да это работает но чтобы написать логи программист должен решить что в этом месте Я это буду делать Вот в этом месте полезно сохранить информацию что произошло такая вот такое вот событие такая ошибка нужно это руками написать спа генерируются автоматически либо на уровне сервис ша либо на уровне библиотек тем самым мы сильно улучшили покрытие вашей системы тем не менее логи - Это очень крутая полезная информация мы от них не отказываемся и именно в логах написана конкретная причина ошибки потому что её писал человек он объяснил что здесь была валидация ошибка потому что передано Слишком длинное тело запроса например Давайте объединим рейсинг и логи и Open Это позволяет нам сделать теперь наши агенты будут читать логи приложений а в каждый Лог когда приложение пишет его мы добавим тот самый Trace ID Теперь когда разработчик заходит наш интерфейс для анализа системы смотрит конкретный рейс мы ему показываем е и которая писало приложение когда обрабатывал этот запрос сильно улучшает отладку ещё один столп обсер били те это метрики Хочется к этой всей системе подключить ещё и метрики Open темет умеет в метрики есть для этого специальные обвязки но я сейчас про другое вспомним что у нас есть сервис smh который покрывает всё htp взаимодействие в системе весь трафик каждый htp запрос Он про него знает Давайте на основании этих снов построим очень точные метрики откуда был сделан запрос куда какой htp путь какой статус код ответа И сколько времени заняла обработка этого запроса и эти метрики мы считаем автоматически без участия наших разработчиков просто имея трейсинг и просто имея серс smh разработчикам не нужно что-либо делать чтобы у них появились эти метрики для их сервиса всё это что мы обсудили находится в коллекторе теперь я думаю стало понятнее что коллектор это действительно сложное приложение он получает данные как-то их дедупликация открыт по-прежнему один вопрос как этим всем пользоваться как этим пользуются наши пользователи То бишь разработчики или другие сотрудники компаний существует довольно много стандартных решений для визуализации Рейсинга и в целом оберти есть стандартный UI есть графана Плюс вы можете пойти к каким-то вендем к какому-то облачному решению сасу если у вас много денег заплатить догу закинуть все данные туда и получить какую-то платформу от них Но мы вспомнили что мы программисты а программисты любят делать что-то своё Мы решили что мы ничем не хуже чем те самые ребята которые сделали свои инструменты Мы решили что можем сделать более гибкий инструмент который подойдёт Именно под наши нужды естественно мы его сделали мы его назвали обр и обр это платформа неры который объединяет в себе логи трейс и метрики и позволяет получить общее представление о системе так как мы когда-то начинали с егеря и просто с Рейсинга довольно быстро мы сделали некоторые uui для анализа Тех самых рейсов но здесь всё довольно стандартно есть имя сервиса какое-то имя операции имя сна есть вот эта вот древовидная структура со снами с их временем отработки это Мета информация статус код ответа Запрос который был сделан в базу данных название кубернетес ноды название пода всё что может пригодиться при отладке но вы Возможно это уже видели в других системах дальше мы пошли в сторону метрик у нас появились метрики Мы очень этим довольны и хочется эти метрики как-то отрисовать Да не просто так же мы их делали нужно их где-то показывать теперь для каждого сервиса мы делаем автоматический дашборд с его сетевым взаимодействием по очень точным Метрика мы знаем Сколько именно писа приходило в сервис с разбивкой по API нпои и по статус кода ответа мы знаем время работы и время обработки каждого эндпоинт отобразить те самые центили плюс мы знаем как именно этот сервис связан со своими зависимостями и мы можем строить какую-то архитектуру отрисовывать её смотреть как именно сервисы друг с другом взаимодействуют какой процент у них ошибочных взаимодействий или всё там хорошо выглядит возможно хорошо но остаётся вопрос А как этим пользоваться Я предлагаю посмотреть как именно можно отладить инцидент с помощью такого механизма с чего всё начинается когда у вас происходит деградация что-то сломалось какая-то авария в идеале летит какой-то алер дружище Смотри Вот у такого сервиса вот по такой вот ручке увеличился процент пяти сотых кодов ответов тогда приходит разработчик и начинает разбираться Ага я смотрю на трисы этого запроса понимаю где произошла проблема но бывает ситуация интереснее Представьте глубокая ночь 300 ночи Все спят Даже те самые ребята которые перерабатывают уже ушли домой и не открывают компютер но не спят инцидент менеджеры в Авито - это специальные люди которые наблюдают за продакшена даже ночью если что-то сломалось они находят ребят с экспертизой разработчиков которые ответственны за этот компонент и могут их призвать чтобы они починили какую-то проблему но бывает так что в принципе непонятно что сломалось чуть-чуть сат не работает где-то работает какой-то компонент вообще отказа Като алертов непонятных можно позвать пол компании ночью тогда они разберутся наверняка но хочется как-то более точечно понять кто именно нужен не хочется всех будить в таком случае мы им помогаем со своим инструментом для каждого сервиса мы знаем Какой процент ошибок на htp запрос возвращает этот сервис и Давайте посчитаем Дельту Давайте посмотрим на процент ошибок который был час назад И сколько ошибок сейчас от сортируем по разнице наши сервисы если для какого-то сервиса сильно увеличился тот самый процент ошибок это Повод задуматься О том что скорее всего этот сервис деградирует скорее всего текущая авария как-то связана с ним потому что именно у него увеличился этот фон может быть причина в нём может быть в какой-то зависимости но это уже очень хорошая точка старта мы заходим в автоматический дашборд каждого сервиса и начинаем его анализировать видим что вот по этому конкретному API эн поту началась деградация очень много ошибок летит мы переходим дальше мы начинаем искать тсы От этого сервиса по этому API нпои ошибочные потому что у нас происходит какая-то авария и возможно нам интересны прямо сейчас именно долгие трейс которые обрабатывались больше допустим 50 миллисекунд Если для вас это долго можно сделать более узкие фильтры если мы знаем что деградация идёт в конкретном дата-центре либо это запросы с каким-то http заголовком всё это можно здесь выстроить и настроить точный фильтр и дальше мы переходим к анализу каждого треса мы смотрим на него и здесь мы видим что был какой-то внешний сервис большой самый верхний этот сервис сделал внешний запрос видим что внешний запрос сверху Спан длился 200 миллисекунд а снизу чуть дольше дольше чем 200 миллисекунд как это может быть на самом деле довольно стандартная проблема это таймаут верхний сервис не дождался ответа за 200 миллисекунд оборвал соединение плюс мы видим некоторый статус код 499 значит что клиент отменил запрос и мы явно видим что это был Тай мы понимаем Ага вот в этом месте случаются тайм-ауты изза этого пользователь получает оши наша система работает медленно но мы идм ещ дальше мы в том же самом интерфейсе открываем логи по этому тсу мы смотрим Что именно писали в логи приложения когда обрабатывали этот запрос Мы видим что верхний сервис пожаловался что произошёл таймаут Ну ладно мы это и так знаем что более полезно Нижний сервис сообщает о деградации он говорит что я ходи в ВТО ш почему-то очень долго получал эти данные и вот оно мы нашли причину скорее всего деградирует именно кэш у этого сервиса это уже повод позвать разработчиков этого сервиса дежурных по нему и специалистов например по кшу чтобы ребята распутать нам проблему тем самым наш инструмент позволил нам перейти от состояния когда мы не знаем что и где произошло к конкретным запросам которые сломались и к конкретным логам в которых есть причина то самы проблем Мы посмотрели какая у нас архитектура Какие трудности были и мы посмотрели инструмент который позволяет нам улучшить наблюдаемой нашей системы уменьшить время инцидентов ускорить время поиска того самого рудко трек можно использовать по-разному но вместо выводов у нас будут планы на будущее куда это Дальше можно развивать во-первых сэмплирование данных можно улучшить ещё сильнее сделать его более качественным сделать его динамическим разработчик приходит в некоторый интерфейс и выставляет параметры Ребята пожалуйста сохраните все тросы которые идут от этого пользователя проходят через этот сервис с таким вот статус кодом в течение 10 минут мне очень нужно для отладки сохраняем плюс открытый вопрос как делать биллинг и лимитирование событий в такой системе данных очень много и мы растём на несколько раз в год в начале года у нас были миллионы спано сейчас у нас более 10 млн спано в секунду нужно с этим что-то сделать придумывать кто именно виноват в том что сервис генерирует много снов и плюс последний поит можно добавлять ещё больше данных в нашу систему можно сделать профилирование ваших приложений автоматическое в ран тайме например с помощью пиро скоупа и эти профайлы можно соединить с Трей сами когда разработчик будет смотреть на трейс своего сервиса он будет видеть Ага запрос работал 200 миллисекунд в этом сервисе я там что-то в цикле молотилка так было долго и мы ему показываем профайлы в этом приложении время уходит вот сюда вот вот здесь Ты висишь в блокировке чего-то ждёшь А вот здесь у тебя неэффективная функция Просто тратишь свой процессор тем самым мы ещё сильнее ускоряем время поиска той самой причины того самого род коза разработчик быстро понимает что у него не эффективное приложение и может пойти его оптимизировать и на этом У меня всё всем спасибо большое вам было приятно рассказывать Сейчас самое время взять ваши телефоны и отсканировать этот QR код прекрасный оставить ваш фидбек которому мы и организатор конференции будем очень рады и это надо сделать до выхода из зала чтобы точно вы оценили если доклад огонь программному комитету надо об этом знать А теперь давайте зададим вопросы Итак все достали телефон двумя руками а теперь у кого вопросы есть да кто-то уронил телефон Нет вот можно с первого ряда начать Добрый день А чем ты занимаешься Ян разработчик красавец давай всё спасибо девос на тебя нет давай вот вопрос собственно про Open telemetry Да а все ваши примеры уходили в сторону хттп а какие ещё могут быть дополнительные Протоколы которые можно раздать с паны типа не знаю кавка например Угу я понял вопрос Давай скажу где именно мы создаём Спан Что именно покрываем во-первых это действительно htp просто потому что оно популярно в нашей системе плюс все походы в базу данных которые идут через наши библиотеки они тоже покрыты снами мы знаем за просто наме может быть запрос явно написан мы знаем что это был запрос и так далее мы знаем время его выполнения когда события идут через нашу систему асинхронной очереди Мы тоже сохраняем этот контекст мы не знаем куда именно ушло время Внутри там в кафке То есть как именно кавка это сообщение обрабатывала Почему кавка его доставила через 20 миллисекунд пока что мы не научились это делать Это сервисе в своём приложении могут разме с панами какие-то сложные функции да у них в приложении есть какой-то сложный конвейер что-то зачем-то выполняется эту всю инфу можно закидывать в Спан создавать свои собственные спано а Спан рождается при получении сообщения или при отправке сообщения в нескольких местах во-первых при отправке во-вторых наша обёртка над кавка тоже генерирует свой Спан и при получении сообщения Мы генерируем ещё один Спан Всё спасибо спасибо СБО большое Будьте добры Алексей лямов руководитель компании Спасибо большое за доклад это очень классный доклад У меня есть вопросы по ме три на самом деле пош первый вопрос Вы сказали что приложениям не нужно Да ничего там добавлять Вы можете собирать спа Как это будет работать если приложение ть запрос а потом делать куда-то запрос как состыковать потому что мы не мы теряем получается Trace ID если приложение его никак не прокиды да давайте скажу более аккуратно действительно вот эта вещь Единственное что нужно сделать действительно без вот этого прокиды Нея контекста мы не обойдёмся Я скорее имел в виду то что не нужно создавать Спан руками не нужно подключать библиотеку правильный Тулин чтобы эти спа создавались в приложении самом понял да Ну я подумал как это у вас так получилось хотелось узнать К сожалению мы не волшебники так ещё не умеем второе а в качестве заголовка вы используете стандартный й Пан Да я правильно понял в заголовке есть во-первых Trace ID во-вторых ID родительского спанак может быть Это ваши да заголовки кастомные на самом деле мы это Украли у егеря то есть использовался когда-то стандартный подход егеря у егеря это так устроено шили что в принципе нас это устраивает мы немного поменяли правила по которым мы генерируем разные идентификаторы чтобы сделать всякие фишки Но идея как у Ягер обратите пожалуйста внимание на стандарт w3c Trace context Называется он как раз таки Ну универсальная Ну соответствует он телеметрии потому что Ну по крайней мере стандартные библиотеки там dnet Java и так далее они из коробки с этим работают а всякие Графские приблуды придётся их хардко будеть Ну преимущество омет в том что мы можем создать несколько коннекторов на получение мы умеем Как принимать данные как по омет протоколу так и по ер протоколу старому Так и зпн туда можно закинуть То есть можно что угодно туда закинуть мы умеем принимать данные в любом формате и потом приводить их в Единый формат омет и уже работать с ним Ну и последнее чтобы не затягивать по поводу сэмплирования вот динамическая Там и так далее не думали о том чтобы там сделать несколько хранилищ а ошибки допустим хранить в долговременном хранилище Да какие-то сэмплы хранить в короткое время но все к примеру и в зависимости от разных правил вот просто много разных хранилищ с разным сроком действия это то к чему Мы стремимся действительно так хочется делать хочется разделить хранилище на какое-то холодное горячее выделить какие-то более важные для нас данные просто пока что мы не успели это сделать но обязательно сдела и ещё последний а нет следующий будет платным Будьте добры Ладно спасибо спасибо Добрый день Виктор кбнц Сбер У меня коротенький вопрос Ты классные графики показывал как у вас линейно растёт производительность Да не пытались посчитать вот какой overhead на сайд карах то есть какая нагрузка на кубер именно от сайд каров сколько это там 2 3 5 20% вопрос именно про то сколько сайдкар в целом генерирует оверхед или трейсинг в сайд каре Я имею в виду сколько сайдкар потребляет от всего кластера вот есть кластер который бизнес логику делает да плюс этот маленький Сайка вот сколько он генерирует Я тебе не могу сейчас сказать конкретные цифры Сколько именно потому что всё зависит на самом деле от многих вещей от писа который идёт в контейнер от в принципе объёма данных от того сколько коннекторов создаётся И на самом деле здесь довольно дорогостоящая операция - это создание тлс коннекта Э куда обычно уходит наш процессор Но вот не могу тебе в процентах сказать сколько уходит на это просто интересно чисто с бизнес стороны Сколько стоит ваша система для бизнеса Как именно на каждом кубер кластере Понимаешь Может Меня отключили может давать действительно Давай думать про одно ядро на приложение и это может показаться чем-то очень большим с другой стороны нас здесь нравится он нам потому что предоставляет очень много плюсов то есть есть какой-то оверхед реально Да но он решает какие-то конкретные проблемы делает нам какую-то межклассовая как-то в стейджинг нам организовать наше окружение и в принципе какая-то хорошая технология которая нам очень нравится мы не планируем отказываться от него сервис Ш - это круто Я даже не спорил мне просто интересно считали Вы или нет спасибо считали но ну такой вопрос Вот ну ты же взрослый человек подходишь в дискуссионной зоне и без микрофона не под запись говоришь Да спасибо доклад Да мо кто это говорит Магните рукой сверху где СР сверху Где Вот А по всё нас просто слепит но мы вас видим всё отлично давай два вопроса раз два и потом дарим постгрес спасибо спасибо за доклад А у меня такой вопрос есть пользовательские запросы которые вот приходят там с сайта и ещё что-то а ещё бывают случаи что у нас в сервисе по крону как-нибудь что-то начинается вопрос пытайтесь ли вы как-то группировать вот эти процессы что вот он начался у него какой-то выделенный ID пошёл пошл пошл и мы вот знаем что вот этот сервис вот как вы группировать стику метри и так далее да Вопрос в том как мы кроны покрываем правильно Да ну здесь задача программиста уже всё-таки создать Спан когда он начинает обработку какого-то крона е у нас есть довольно стандартные библиотеки какие-то обёртки для этих самых крон мы стараемся это делать если Ну то есть начинает работать крон сработала операция мы создаём СН Когда в рамках операции обработки крона мы сделаем какие-то внешние запросы тот самый ID и мы это всё свяжем то есть мы крон джобы покрываем тоже А разработчик может как-то добавить не обращаясь к вам какие-нибудь метрики что автоматически будут считаться в вашем коллекторе и так далее Это было бы очень классно но для этого нужно очень много ресурсов как только мы в наши метрики добавляем ещё один параметр кардинальность данных растёт очень сильно и хранилище мерик Оно просто лопается от этого Поэтому мы пока что не позволяем добавлять любое добавление должно быть с вами согласовано Да спасибо спасибо и финальный вопрос в режиме блица да Спасибо ещё раз за доклад у меня такой вопрос Довольно простой нано предполагает простой ответ коллектор сам по себе Он такой некий посредник который умеет в разные энды складывать трассировки в зависимости от Вот хотелось уточнить в вашем докладе не указано что вы используете в качестве бэнда он умеет умеет что угодно сам протокол в котом да Да давай на вход мы умеем принимать Open tracing Ну или yer протокол плюс Open telim потом мы обрабатываем данные в рамках Open telim и когда складываем их у нас по-прежнему остался Open tracing формат то есть на выходе в ха летит Open tracing но в принципе там на омет его легко заменить тут не будет каких-то проблем Главное наш UI научить правильно эти данные с Хауса забирать и как-то с ними работать но в принципе никаких особых Ну вот разностей нет между этими протоколами то есть не так уж и важно Это для нас Что именно хранится хорошо Спасибо Спасибо Игорь кому подарим за лучший вопрос сувенир Давайте джентльмену который три вопроса задавал и хотел ещё больше за старательность нуно там ещё был там ещё был бесплатный совет тебе тоже да да ну можно по аплодировать Ребята простите девчонки что не все задают вопросы тут лайфхак самый простой А пока пока ты тоже получаешь суперприз от конференции Спасибо за выступление красавец"
}