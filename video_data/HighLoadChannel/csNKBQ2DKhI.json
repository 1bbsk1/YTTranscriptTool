{
  "video_id": "csNKBQ2DKhI",
  "channel": "HighLoadChannel",
  "title": "Чёрная магия JIT-компиляции / Алексей Рагозин (Дойче Банк)",
  "views": 3555,
  "duration": 2585,
  "published": "2021-10-04T02:44:45-07:00",
  "text": "доброе утро коллеги вот я бы сам с удовольствием послушал права и бпф тем более на самом деле он тоже компилируется ходи конечно без чёрной магии в этом вся его соль но у меня доклад на другую тему и темы моего доклада черная магия джед компиляции jet компиляция это неотъемлемая часть платформ для многих языков которая позволяет им обеспечить производительность время выполнения сравнимую с языками которые компилируются ahead of time несмотря на то что даже семантика этих языков сложнее богач и по вроде jet комбинатор это достаточно сложная схема ну конечно сложно нельзя сравнивать как бы ahead of target компилятор говоришь там один проще другой сложнее но как минимум jit компиляция сильно непредсказуемые что она срабатывает в runtime как бы делает какие-то выводы из того как ведет себя ваше приложение и тут не вспоминается цитата фантаста артура кларка что любая достаточно сложная технология неотличима от магии магия это не очень хорошо магия ведет предрассудкам это это вредно в инженерной деятельности от предрассудков на избавляться чтобы от них избавляться неплохо разобраться в том как это магия работает пусть там не до уровня написание собственного jet компилятора но хотя бы понимать основные моменты почему компилятор может делать очень странный и неожиданные а для вас вещь ой я по роду своей деятельности там последние лет пятнадцать занимался высокое нагруженными системами на java платформы java jet компиляция очень связаны из вещи вещи и опять же как бы вопрос о производительности но если мы говорим про производитель производительность от него топа как вы пишете код производителя это про то как вы тестируете это производительность но все равно когда кот пишется часто возникают дебаты о давайте вот сделаем вот так а не этак потому что она наверное будет быстрее выполняться и так далее и и аргументация в таких дебатах зачастую как бы опирается на очень странное представление о том как работает компилятор и вот с ними надо немножко разобраться и так основные вопросы этого доклада в отличие от ahead of time компиляции jet компиляторы как правило работают с языками с другой семантикой более динамически java java script питон в вы конечно можете мне сказать что ну какая колледжа в динамическая как бы она там статически типизированный все дела но тем не менее на самом деле достаточно динамическое чтобы они невозможно было нормально скомпилировать ahead of time соответственно проблемы с которыми сталкивается компилятор класса джед они немножко другие и ключевые оптимизации которые на которых о том jetta дни отличаются от зачастую того что есть выходов time хотя эти вещи развиваются параллельно и так сказать догоняют друг друга следующий вопрос есть даже предрассудок что интерпретатор медленно компилятор быстро на самом деле ли это так и как бы тут я просто приведу некоторые примеры сравнения реальных платформ и наконец в заключение хочу немножко рассказать про том что такое грааль это новый компилятор в г н который позволяет вам создать собственный язык программирования just in time компиляции на яве и вообще не понимаю как работает генерация машинного кода который будет работать там на всех платформах который работает живем но при этом это будет как бы по-настоящему ваш собственный язык который будет из вашего языка компилироваться именно в бинарный код и так начнём с истории языков программирования и в этой историю нас неизбежно встречается такой концепт как объектно-ориентированное программирование которое сейчас подвергается большой критики так далее тем не менее мы говорим про историю ее уже не изменить и три основы объектно-ориентированного программирования т.н. консультация полиморфизма наследовать и буду их раскрывать ключевой момент здесь наследования потому что на наследование практически во всех языках построен полиморфизм не может быть на самом деле всех но вот как бы если мы начнем сравнивать а вот классический си плюс плюс а там к дни более динамическим языком то а здесь у нас как раз возникает вот эта связь полиморфизма с наследования как у нас происходит вызов полиморфного методов в си плюс плюс у нас есть ссылка на объект в заголовке этого объекта лежит ссылка на таблицу виртуальных методов таблиц виртуальных методов лежат адреса собственно бинарных процедур который реализует метод таким образом когда у нас в ходе встречается строка там объект . какой-то метод или стрелочка это метод если мы говорим про си плюс плюс что у нас происходит в процессоре значит нам нужно пойти в память по адресу этого объекта со смещением прочитать оттуда указатель по этому указателю опять со смещением сходить в память просчитать оттуда адрес после этого сделать переход на этот адрес это очень большая проблема потому что здесь у нас есть два прощения в память которая первая из которых с большой вероятностью пойдет мимо каша потому что это какой-то рандомный мм объект в памяти то есть если про таблиц виртуальных методов мы можем более менее быть уверены что она где-то в 1 к шее уже прогрузилось то про сам объект такого скорее всего сказать нельзя и только после того как две этих операций с памятью будет выполнено процессах понимает как бы какую инструкцию ему дальше выполнять и может загружать свой пайплайн обработки инструкции которые там может занимать 20 тактов чтобы вообще начать выполнение соответственно те кто по крайней мере вот в те времена когда я учился плюс галили виртуальный вызов это медленно как бы статический вызов это быстро хорошо не используйте виртуальных вызовов а потом я как бы начал писать наверно там все вызовы виртуальным о господи как вообще это может работать ну ладно это была история как бы люди научились на своих ошибках и парадигма более современных языков наследования исключила с картина если мы посмотрим на языке 21 века раз ты гол они этот трюк аккуратненько обошли то есть в этих языках ссылка на объект сама сам по себе указатель включает себя сразу указатель на условно таблицу виртуальных методов и соответственно до ссылки на объект у нас становится два раза больше но зато у нас исчезает вот этот вот простой когда нам надо сходить в память по адресу объекта чтобы узнать какую следующую инструкцию должен выполнять процессор это как бы работает лучше но это опять же работает с статические компилируем языками типа 1 ст иголка которые могут использовать всю мощь анализа типов чтобы в момент runtime понимать что вот этот указатель как бы он имеет какой-то тип либо это там динамический указатель в котором тип находится как часть указателя в общем там уже черная магия стать такой компиляции окей вернемся к нашим динамическим языкам у которых возможности нет как бы указатель это просто указатель и надо как ведь проблему того что вот у нас есть указатель и надо бы сразу как бы процессор занять делом а надо ли действительно ли вот это проблема того что в момент вызова операции на объекте мы не знаем какой именно код будет реализовывать эту операцию действительно это такая большая проблема как померить стоимость виртуального вызова тут есть некоторая проблема померить можно тысячи разными способами получить тысячи разных результатов и как бы все они будут совершенно правильный совершенно бесполезный в подавляющем большинстве ситуаций поэтому вместо этого я просто как бы стараюсь оценить значит какие у нас задержка 1 задержка это того что нам надо обратиться памяти то есть эту стоимость доступа к памяти 2 это то что пока мы не из памяти не учили значение у нас простаивает конвейер как оценить стоимость простоя конвейеры современного процессора это в принципе ситуации по сути своей близкое к ошибке предсказателя переходов . для того чтобы на каждом efi не сталкиваться с такой проблемой в во всех современных процессорах есть врач prediction который исходя из нехитрых правил предсказывает каким по какой ветке пойдет брать чтобы конвейер мог сразу грузить инструкции вперед если prediction оказался неверный ну откат происходит откат и соответственно converse загружается заново и эти цифры можно поучить в из документация и вот для современной архитектуры это порядка 20 циклов если говорить про память но тут у нас все зависит от кэширование но стоимость доступов память это уже вот если у нас объектов не оказался за каши раваном она вообще достаточно большая и доступ память это ключевая проблема производительности там современного прикладного пол года итак проблема есть и там быстро виртуальный вызов может быть в десятки раз быстрее чем хорошо оптимизирована компилятором нежели чем вот такой сделанный бесхитростно в лоб и в этом основная цель jit компилятора из динамического кода который вот как бы поведение которого сильно зависит от данных и и не понятно из кода предсказать оценить на спекулировать то как на самом деле он будет выполняться и соответственно для этого подготовить исполняемый код как выглядит pipeline компиляция будто just in time i lie ahead of time у нас как правило есть исходный код из него мы получаем которую от 1 porsche иную структуру абстрактной 1 дерево абстрактного синтаксиса и дальше в принципе у нас runtime может быть реализован разными вариантами как все эти варианты в жизни встречаются мы можем интерпретатор сразу натравить на дерево абстрактного синтаксиса это удобно с точки зрения написание кода это не удобно с точки зрения расширения и поддержки этого года мы можем превратить наше логическое представление программы в условный машинный код 100 км и байт-код то есть переписать его снова из деревянной в линейную форму но используя какие-то наши собственные простые команды которые потом могут быть реализованы интерпретатором это наиболее популярный подход для современных интерпретаторов потому что проблемы с деревом в том что она как бы в памяти лежит мне вокально в ходе компиляции оно могло раз кидаться совершенно произвольным образом а линейная структура байт-кода она нам уже дают неплохую локальность памяти по крайней мере для исходного кода нашей программы вот а если у нас еще сам по себе интерпретатор занимает 20 килобайт то вообще получается достаточно неплохо как бы вот у нас вообще кроме это самое кода который уже за кашира ван в в один кошель ничего не выполняется и это так сказать я к этому вернусь в теме мы строим интерпретаторы либо мы можем из этого а с т создавать машинный код либо мы можем машинный код создавать из байт куда опять же немножко проще из байт-кода потому что у нас получается как бы дык uplink между семантика языка у там парсером структуры и сущности языка и более простым более формализованном машинным кодом опять же как правило современной систематике пвм они идут по этому принципу то есть есть фронт-энд компилятора он видит какой-то интермедий презентация и уже из интермедиат representations создается в машинный код как правило just in time компиляторы тоже идут в этим путем потому что в runtime работать с подходом намного проще переходя к самую компиляция то есть как работает компилятор я думаю всем интуитивно понятно там берем процедуру функцию метод что угодно у него есть начало конец компилируем в какую-то в какой-то кусок бинарного кода у которого тоже есть . ухода точку возврата как бы просто понятно же страдаем compile можно сделать точно так же можно использовать те структурные элементы и языка который у нас есть функции методы так далее компе и ну просто компилировать не все сразу а компилировать вот именно то что мы видим по факту выполняется но здесь мы особо никак не решаем проблему непредсказуемости вызвав то есть мы оптимизируем как бы отдельно взятый метод а на самом деле как раз основная задача это оптимизировать то что этот метод будет вызывать чтобы возможности через за инлай нить этот код на этапе компиляции и так далее то есть внезапно задача компиляции jit компиляции на уже не методов она становится на порядок сложнее потому что от результаты этой компиляции как бы ожидании больше чем для статического компилятора который может произвести анализ типов и как бы заранее предсказать вот какие какие какой именно коп будет вызван в тех или иных точках чего jit компилятор не может потому что он работает с другим классом языков есть альтернативный подход это трассирующая компиляция он менее известен но я начну именно с него потому что он очень хорошо иллюстрирует день всего происходящего ставьте у нас есть какой-то код и функции foo и бар вот в какой-то момент у нас функцию full есть какой-то цикл и происходит важный вызов функции бар соответственно у нас есть цикл у нас есть какое-то условие которое производит выход из цикла у нас есть обратный переход цикла у нас запускается интерпретатор трассирующий компиляция всегда начинается с интерпретатором и вот у нас как бы выполнение программы ходят внутри цикла делает вложенный вызов проходит внутри кода нет функции бар возвращается обратно для трассирующий компиляции помимо того что у нас есть интерпретатор нам важно еще профилировать то есть сколько как часто мы каждый шаг выполняем и допустим если у нас этот цикл крутится 10000 раз то вот у нас какой-то счетчик связанные с этим байт кодом он увеличивается и в какой-то момент компилятор срабатывать рисков ага этот участок кода горячий я переключаюсь из режима интерпретации в режим сбора трассы в этот момент когда интерпретатор переходит в режим сбора трассы он каждую инструкцию которую выполняет он ее не просто выполняет он еще записывает в буфер трасса и соответственно у нас получается линейная трасса выполнения скопированы все инструкции которые были выполнены причем это инструкции и из куска цикла функции foo инструкции которые выполнялись в рамках этого цикла функций бара но ключевая особенность трасса то что она строго линейно то есть в нее включены только те инструкции вот как бы вот тем путем деления которые мы пошли в момент раз и соответственно те инсты которые у нас в нормальном ходе являются ветвления в трассе они ничего не делают они заменяются на инструк называются горда me то есть тоже самое условие проверяется внутри трассе но как бы его результат уже либо мы все еще находимся на трассе либо мы должны выйти из трасс соответственно после того как эта трасса собрано она компилируется в машинный код соответственно на этапе компиляции у нас происходит всякий оптимизации вроде рио локации и переноса переменных в регистры переупорядочить не доступа к памяти и так далее все эти важные операции для которых чем больше у нас контекст компиляция тем лучше соответственно получается вот этот вот вот эта бинарная скомпилирована я трасса и она подставляется вот туда на в байт-код на инструкцию начала трассы когда у нас следующая центр при такой до этой инструкции он переходит в трассу но если у нас какие-то условия изменились например у нас пришел вызов из цикла у нас в этот момент будет целиться гарт и срабатывать код который обратно возвращает выполнение программы в режим интерпретации вот 100 инструкция которая соответствует этому гарду это нехитрая схема позволяет оптимизировать как бы очень много проблемных с точки зрения статической компиляции кода то есть например у нас здесь автоматически получается оптимизация называемый инвайн каширования это оптимизация когда в точке вызова компилятор заменяет виртуальный вызов на статический но при этом вставляет гордон что соответственно essence объекта действительного тот instance на реализацию которого он был заменён соответственно а если у нас как мы знаем какой вызов это сделано мы еще можем этот метод zion вонять в том числе и в метод best комбинации в красивой чем компиляции у нас едва не происходит автоматически просто потому что как бы сама трасса включает себя и вложенные методы помимо вы обними методов то есть то о дике которое зависит от instance объектов в многих языках арки по java script того у нас сама структура данных тоже такая же динамическая то есть у нас нет фиксированных структур данных капель у нас просто все это dictionary и я вот точно такая же оптимизация sunline каширования она великолепно работает и для структуры данных тоже есть вот обращение к полю объекта nova то есть у нас есть объект у него есть некоторые метод вылью мы в него что-то записаны точки зрения интерпретатора это превращается в то что мы должны взять строку в илью считать от неё хэш поделить на и по модулю на размер хеш-таблицы получить яндекс по этому индексу прочитать все это может атрофирован быть атрофировано то есть в момент выполнения трассы мы сразу зафиксировали по какому индексу относительно начала объектов памяти находится property белье и поставили гарт и вот этот эти карты современные микроархитектуры они работают очень хорошо потому что они могут выполняться по сути параллельно с тем кодом то есть у нас началось началось выполнение вот этого горда вычисления некоторые арифметики условного перехода branch предиктор предсказал что условие будет выполнено в труп поэтому у нас сразу же операция доступов память пошла в pipeline и пока у нас вычисляется вот это арифметическое условия у нас есть шанс что из памяти уже приеду данные к тому моменту когда мы решим что гар действительно как бы выполнена успешно у нас уже будут даны то есть у нас нету простой по сути вот эти вот все горда они выполняются параллельно с определенными операциями доступа к памяти выглядит очень здорово то есть как бы все просто интерпретатор трассировка генерация кода до генерация кода это не просто но принципе проблема наука изученная библиотеками поддерживаем но на практике у трассирующие во кабеля трассирующие вотже то есть проблема какие платформы использовали трассирующие jet компиляцию flash ныне покойный java скрипте был интерпретатор в мозиле и trace мамки тоже использую но на самом деле это был компилятор который задонатил адобо из сша которые адаптировали для java скрипта но тоже в общем ныне покойный мало кому известный вариант питона paypal которому мы еще вернемся это очень интересно потому что как бы paypal это jit компиляция питона написанная на питоне вот такая интересно рекурсия мы не вернемся и вот вот как бы более менее активный хотя опять же отстаёт от extreme 2 но по-крайней мере слот же там я встречал людей которые реально используют ее в серьезных проектах именно для того чтобы получить большую производительность и оторван time ago почему почему jit компилятор не приживается потому что трассировка оказывается очень медленной нам надо интерпретировать еще писать трассу как бы создавать вот эти вот все структура вот и и разогрев трассирующий jet компилятора он очень дорогой и и как бы не всегда вот эти траты они получаются удачны опять же тут трассы получаются большие то есть как бы если трасса не срабатывает надо еще придумывать более сложную схему как эту трассу дробить на по трассы строить дерево трасс это в принципе плюс-минус решается то есть тот же самый logic он как бы оперирует не просто с трассами невозможно дерево трасс когда при срабатывании горда в одной трассе выполнения переходит не в интерпретацию как бы в другую трассу которую посчитано для альтернативной ветки он тоже соответственно горячего часто кода но то есть это работает только для систем которые словно говоря выполняют один и тот же код в течение длительного времени это великолепная работа для flash а то что фаршем писали вот всякие там анимации и так далее и так далее а на один рая танис не хитрый кот который как бы один раз скомпилировалось а дальше там у нас на каждый фрейм отрабатывает случае со скриптом у нас как бы взял процентов java скрипта выполняется один раз и вот там как бы история более интересная но опять же есть проблема в том что зачастую от самого динамического языка нам не так важно производительность потому что все тяжелые операции делаются в каких библиотеках которые все равно написано no se поэтому все-таки индустрия она ушла в сторону 200 комбинации это метод days компиляция она использует все те же самые трудные струйки что трассировка то есть мнение методов чтобы оценить какие у нас быстро и какие медленные делается профайлинг точек вызова чтобы собрать статистику какая именно реализация у нас в каждой точке вызова дергается там случае java script он здесь что похоже делается для предсказания физических индексов полей для объектов на самом деле даже для сложно там если мы обратимся к g8 компилятору там на самом деле в рандами для каждого объекта еще считается с как бы статическая структура его данных и отдельная история виджет комбинация окей итоге чтобы все более-менее заработала так сказать стек современного jet компилятора индустриального типа джавы или java скрипта это как правило многослойное выполнение то есть у нас есть режим интерпретация у нас есть быстро компилятор у нас есть более оптимизирующие компиляторы и соответственно у нас все начинается выполнять в одном режиме мы собираем статистику перри компилируем собираем больше статистики перри компилируем с большими оптимизация my потом у нас как бы меняется код мы это все не оптимизировал в общем как бы там постоянно идет какая-то движуха которую не всегда ожидаете от вашего нам time плюс у нас как бы компиляция всегда инструментально компилятор беретту там случае языков в java java script он берет метод компилирует отдельный метод но не компилирует весь ваш исходник и так далее соответственно поскольку у компилятора есть вот это все и вся информация времени выполнения он может делать об отце которой ahead of time компилятор делать сложнее тут опять же надо оговориться что ahead of time компиляторы тоже не стоят на месте уже давно существует такая так называемая profile гадит оптимизация когда вы компилируете например с джесси бинарник гоняете на нем тесты он собирает статистику в делает профилирование runtime а потом этот файл со статистики идет на вход компиляторы и вы получаете более оптимизированный бинарник для того же самого исходного кода ходу в катаем компилятор тоже такой момент просто там это все сложнее очень сложна и так сказать процесс сборки just in time at все происходит автоматически то есть все вот эти вот вещи вроде спекулятивного выполнения как как страться они возможно и в обычном режиме компиляции более того например возможно еще по ходу выполнения превращать например локации памяти в куче на локации памяти нас на стыке где это все намного дешевле разгружает сборщик мусора так ну я немножко ускорюсь а чтобы мы успели соберется рассказать обо всем ok значит компилятор jit компилятор требует очень черной магии вопрос действительно все это оправдан что если мы просто как бы напишем бесхитростный компилятор будет ли это хорошо работать скорее всего не очень потому что просто интерпретатор хорошо написано ставим будет быстрее и опять же если вот смотреть что происходит в индустрии это кабель от интерпретатора тоже могут работать очень быстро на примере v8 есть режим джастин тайм компиляции есть режима интерпретации как бы джастин танк компиляция в целом конечно быстрее но не в разы не на всех кейсах и как бы интерпретатор тоже имеет место быть но надо понимать что это очень оптимизированный компилятор интерпретатор чили случай с php есть php не умеешь ты там jet компиляция возможно там ахадов тент подзабыл хип-хоп вен разработанная фейсбуком и и здесь приведет сравнении с пхп 7 которым просто папки минировали как баран темпами тайны оптимизировали интерпретатор то есть папа остался таким же интерпретирующих но тем ни менее производительность показывает вполне достойно то есть сама по тебе компиляция это непал нация как бы эффект получается только того когда компилятор действительно может правильно оценить динамику работу программы и сделать все эти спекуляции заранее предсказать куда в память вы пойдем по какому адресу будет приход и так далее так он это я пропущу и так что у нас получается в сухом остатке как бы если вы друзья который наслушался окладов которого чешутся руки написать свой собственный компилятор как бы выглядит все не очень компилятор писать сложно интерпретатор писать тоже сложно что же делать если вы хотите написать свой классный язык программирования вот просто взять и написать как выглядит runtime какого какой то тут языка кого-то платформа сейчас у нас есть программа которая там либо в виде текста любили либо которая должна раз портятся превратиться в какой-то уже машины . более формализованное представление из которого происходит генерация кода и вот этот вот jit runtime он так сказать заточен под семантику конкретного языка java скрипта джавы так далее а можно ли эту картину поменять можно ли сделать универсальные джед рандом потому что ну как бы компиляция она принципе везде то же самое мы делаем один и тот же бинарный код для тех же самых интера структур в принципе те операции которые у нас есть в любых runtime их они плюс-минус одни и те же можно просто это все как бы скрыть в каком-то умном пап siri и казалось бы сделать вот такую универсальный оранта в принципе многие в качестве такого универсального runtime и используют jovi котлин скала все как бы новый язык на выходе получаем живым байт-код это в принципе работает но это работает не идеально потому что байт-код же омон сутки очень сильно семантически привязан к как бы именно от живым и некоторые трюки там сделать достаточно сложно и опять же если посмотреть на какие-нибудь реализации например java скрипта на джаве которые используют генерацию байт-кода там получается двойная jet компиляция сначала у вас java script runtime квот используя jit компиляцию компилирует java script в байт-код потом живем компилирует этот байт код в моем времени выполнения общем поэтому эта штука разогревается вдвойне медленно работает вдвойне менее предсказуемо окей вернемся к paypal котором я упоминал это очень интересный проект этот трассирующий компилятор на питоне который сам по себе компилятор написана на питоне и смысл в том что у вас фронтами работает интерпретатор питона который абстрактном компилятор вот эти move through the jet компилятором который транслируется и выполняется то есть вид компиляция происходит не как бы самого питона а работы интерпретатора интерпретирующие вопит он если вы на вот этом диалекте р python напишите интерпретатор другого языка то он тоже будет работать компилироваться то есть как бы питон здесь не является некоторым промежуточным необходимым промежуточным представлением в отличие от ситуации с байт кодом в же это все работает за счет того что компилятор трассирующий он таким образом может трассировать на то есть шутку интерпретатор на вход интерпретатор приходит инструкция там в ней какие-то параметры и эти параметры можно условно говоря за инлай нить в сгенерированный генерируемый код просто поставив горда на самом деле все конечно сложнее это работает не так гладко и боевая не очень популярная платформа но идея сама заманчиво здесь мы переходим к грааль в.м. это компилятор для java написаны jabber вот тут понимать что как бы грааль вам это очень широкое понятие как бы есть играть для ahead of time компиляции jal и есть грань джастин тайм компиляции чего угодно в дживы имран тайме но не используя байт-код как промежуточное представление вот соответственно для гриля есть фреймворк для реализации языков трюфель и собственно говоря есть сам джастин тайм компилятор если вы интеграция с трюфелем который работает очень похожи на paypal и of python то есть вы на джори пишите интерпретатор в ран тайме как бы работа вашего интерпретатора она специализируется исходя из того какой у вас так сказать исходный код вашего специфического языка и соответственно jit компилятор делает блоки для вашей программы за счет того что он вместе так сказать скомпилирует вместе и код интерпретатора и собственно говоря код вашей программы которые на вход поступает в отличие от or пайтона грааль использовать не частную трассировку он использует так сказать анализ так называем частичное выполнение то есть у него есть так сказать например код вашего метода скомпилирована из вашего языка в ваше представление у него есть интерпретатор и он может как бы аналитически понять что будет выполнена в вот в ходе выполнения этого кода без так сказать физического выполнения получить вот это вот абстрактное описание программы и скомпилировать его в бинарный код соответственно у вас получается такой с так у вас есть исходный код на вашем языке у вас есть интерпретаторы на фреймворке трюфель и все от вас больше ничего не требуется в runtime с ученым грааль jit компилятором вот этот так позволит вашему ходу быть скомпилирован а в бинарное представление опять же бенчмарки вы чего такие как обманешь марками совершенно не частными потому что здесь использовался в качестве примера эмулятор какой-то там ретро приставки написанные на ruby понятно девушка нарубим эмуляторов никто не пишет но тем ни менее время уже заканчивается вот просто пару примеров как выглядит интерпретатор награды то есть для того что в вашем интерпретаторе работали вот и все эти интимно оптимизации inline каши и так далее и так далее в вашем интерпретаторе должны будет в магическом аннотации то кто знаком с java синтаксис может заметить там такие собака конечно ты так далее их надо расставить достаточно много но сам по себе порог вхождения получается очень гладким то есть вы сначала пишите просто интерпретатор а потом не спеша начинаете тыкать всякие аннотации разбираться по ходу как это работает при этом у вас вам не нужно работ узнать как выглядит x86 ассемблер и так далее окей на этом я заканчиваю переходим к вопросам значит у меня здесь есть много ссылок они наверное будут в каком-то виде доступно вместе с трансляция спасибо за то что послушали и у нас может быть через немножко временно вопроса алексей спасибо за доклад плотно очень плотно поэтому сейчас мы пройдем сессию вопросов если что-то еще не успеем всегда можно против кулуары и там продолжить работает да здравствуйте алексей спасибо за доклад такой вот долгий разогрев и соответственно есть вопрос для сегодняшних не проприетарных живем машин если к это возможность переносить статистически profiles прошлого запуска для текущего именно profile нет есть возможность поговорить живем в живем есть возможность как бы дампа скомпилирован авокадо и перри использованием потом иди в принципе как бы есть возможностях этого time компиляция но там тоже садимся очень сложно вообще вот перри использование скомпилирована wakodo она в живым используется достаточно давно просто для runtime библиотеки не для причиной библиотеки изначально это было сделано что память экономит ну в принципе она сейчас доступна но там с этим очень много мороки с точки зрения того чтобы она на самом деле работал и создавал при начал больше пользы чем проблем спасибо да хорошо я повторю легко дать коду до помог говорили про утилизацию процессор и память и сразу возникает вопрос виртуальные среды проводили кинь попытки сравнивания одних и тех же задач на реальном железе виртуальной среде и также бытует скорее спекулятивные маркетинговые мнение что интерпретатором виртуальных средах работают эффективнее интерпретатор нойвирт у ответ будет эффективнее это не знаю я про то в этом are taking но если какое-то обоснование можно с трудом себе представляю потому что на самом деле разница между виртуальной средой и то смысле обычной виртуальная машина там как вы вот amazon до 5 виртуалок в коде часто не вижу откуда там может быть какая-то принципиальная разница потому что с точки зрения работы с памятью там сырыми современная виртуализация она как бы максимально стоит в стороне от работы с памятью там есть вложенная таблица адресов и не более того то есть как бы сам по себе само по себе обращение памяти она идет мимо гипервизора и кэширование работает мимо гипервизора так что не знаю не могу прокомментировать"
}