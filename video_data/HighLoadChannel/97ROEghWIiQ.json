{
  "video_id": "97ROEghWIiQ",
  "channel": "HighLoadChannel",
  "title": "Эффективное обновление состояний в БД из сервисов потоковой обработки / Юрий Печатнов (Яндекс)",
  "views": 1136,
  "duration": 2464,
  "published": "2024-04-17T01:10:27-07:00",
  "text": "Всем привет Сегодня я бы хотел поговорить о сервисах потоковой обработки сервис потоковой обработки это такая большая штука которая читает сообщение из большой распределённой очереди и создает какое-то полезный выход выходом могут быть сообщения в другой распределенной очереди или обновление состояния в базе данных именно об обновлении состояний в базе данных о том как это эффективно делать Я бы хотел сегодня поговорить Почему вообще я решил об этом поговорить Я около шести лет работаю в Яндексе и практически все это время занимаюсь сервисами потоковой обработке люблю придумывать архитектуры и оптимизировать сервисы и в настоящее время я со своей командой разрабатываю библиотеку которая позволяет достаточно просто реализовывать высоконагруженные эффективные отказывал устойчивые распределенные сервисы потоковой обработки с семантикой обработки Сейчас расскажу про холодный контекст Почему вообще мы тут наш типичный сервис потоковой обработки из Больших содержит себе порядка 100 ТБ состояние небольшое отступление что вообще делает сервис потоковой обработке такое довольно типичный он кушает события из упорядочной очереди и поддерживает актуальное состояние в нашем случае это будут состояния рекламных сущностей например стоит а баннера так вот у нас будет 100 ТБ баннеров это 100 миллиардов штук в одну секунду У нас происходит 10 миллионов обновлений и средний размер часто меняющегося состояния 10 килобайт Если бы не было всех оптимизаций о которых я планирую сегодня рассказать то мы читали и писали бы в базу данных по 100 Гб в секунду со всеми же оптимизациями пишем 3 ГБ в секунду читаем 8 Гб в секунду Сейчас я расскажу что представляет собой наш стейт упрощенная стоит протобуфа Ой извините упрощенный стоит баннера это важно Так как оптимизация которых я сегодня расскажу очень тесно связаны со структурой состояния причем в обе стороны мы делали оптимизации исходя из структуры нашего состояния а структура нашего состояния мы развиваем так чтобы лучше работали уже сделанные оптимизации что у нас есть в упрощённом столе баннера У нас есть ключ баннер ID есть несколько верхнеуровневых полей это поле с ресурсами то что задают рекламодатель title URL и так далее есть верхний уровня поле с флагами информация там включен ли баннер или он заархивирован в общем такое легковесное есть верхний уровень в поле со счетчиками их довольно много среди них например мог бы быть счетчик числа кликов по баннеру сделанных пользователям с 12 до 13 часов дня и полетинга в нем хранятся нерестивые бединги рассчитанные по баннеру то есть видим что поля достаточно разнородные и можно предположить что наверняка они обновляются не очень совместно на слайде показано упрощенная представление но храним стоит так как это более компактный формат и у него все хорошо с обратной совместимостью немного про размеры Раз уж мы говорим про потоки данных на слайде показано Flame Граф размера полей состояния баннера здесь вертикальная ось соответствует глубине вложенности полей а ширина полосок соответствует размеру полей Нижняя полоска занимающая всю ширину соответствует размеру всего стоит а полоски уровня выше это размеры верхнеуровневых полей полоски еще уровнем выше это размеры полей вложенных верхнеуровневые все размеры в байтах видим что довольно разнородная структура по размерам но при этом без каких-то явных перекосов одно поле не занимает весь стоит теперь перейдем к нашему дизайну той точке от которой я буду рассказывать про наши оптимизации самый простой способ работать с состояниями сервиса потоковой обработки это сделать в нашей базе данных табличку с двумя колонками ключ и значение в ключе храним наш баннер ID в значении храним стерилизованное состояние протобуфа как же мы работаем Ну довольно просто когда мы хотим обновить наше состояние Мы сначала скачиваем с базы данных затем распаковываем протобув обновляем соответствии с продуктовой логикой и пишем обратно в базу данных то есть на любое изменение состояние вообще любое мы пишем в базу данных сколько будет в новом стерилизованном представлении это наша Стартовая Точка на карте оптимизации потока чтения и потока записи из базы данных вертикальная ось оптимизация по чтению горизонтальная ось оптимизация по записи давайте сделаем первый шажочек по нашей карте Давайте добавим сжатия все используют сжатия мы его используем возможно немножко необычно мы сжимаем на нашем бэкенде на нашем сервисе потоковой обработки поскольку Так мы контролируем коде сжатия и экономим поток чтение записи до поток чтения из базы данных потоков записи в базу данных и места в базе данных на наших данных мы сэкономили так 15 процентов а затем мы сделали шажок побольше и сэкономили еще 40 процентов позволяет обучаться на сэмпле данных которые будут отжиматься и формировать словарик с которым можно зажимать более эффективно можно Представлять что в словарике будут содержаться часто встречающиеся фрагменты из наших данных таким образом в словаре есть уже как бы значительная часть на ваше состояние и поэтому он может сжимать лучше какие есть нюансы решения когда мы используем словарик у нас время течет мир меняется стоит и добавляются Новые поля старые уходят поэтому Однажды обученный словарик Начинает все хуже и хуже подходить к нашим данным Поэтому чтобы сохранять хорошее сжатие нужно периодически переобучать наш словарик в нашем случае мы сэкономили дополнительно 40 процентов от оставшегося применив сжатие со словарем Давайте пойдем дальше и по оптимизируем запись как Вы уже заметили мы умеем добавлять колонки в нашу базу данных Давайте добавим еще больше колонок и будем хранить наше состояние баннера ни в одной колонке со значением а разделим состояние по нашим верхнем уровневым полям и ресурсы флаги счетчики и так далее будем хранить в разных колонках за счет этого мы можем теперь обновлять только часть колонок за раз если к нам пришло событие которое меняет у нас всего лишь один счетчик то мы можем обновить только колонку со счетчиками за счет этого мы в несколько раз экономим поток на записи ещё бонусом мы на самом деле здесь экономим поток на чтение потому что мы ведь готовим стоит баннеры не для того чтобы он был просто где-то в вакууме этим стоит там баннера еще пользуются компоненты рекламы которые типа не показывают людям этим компонентом рекламы могут быть нужны разные наборы колонок и за счет этого на чтение от потребителей этой таблицы мы экономим чтение сделали шажок еще по нашей карте и в несколько раз сэкономили поток на запись базу данных но я вот только что говорил про то что на маленькое событие обновление одного счетчика мы перезаписали всю колонку счетчиков а верхнего верхнего уровня СО счетчиками может занимать эти десяток килобайт как-то грустно на обновление возможно всего лишь одного байта писать десяток Что же делать хотелось бы отправлять в базу данных только сама произведенное изменение То есть у нас изменилось один счетчик Давайте скажем что скажем базе данных что Изменился только он Наследие я показал упрощенные но у нас все-таки стерилизованный протобуфы Что же делать на помощь к нам приходят бинарные дельтаккодеки в частности X Дельта X Дельта позволяет вычислить div между любой парой и бинарных строк а затем этот div можно наложить на оригинальную строчку и получить новое значение Это как гид div и гид аплай только не с текстовыми файлами в репозитории А с любыми бинарными строчками как же теперь эти бинарные кодеки применить в работе с базой данных Давайте возьмем и для каждой основной колонки со значениями добавим парные колонки с патчами как мы будем ими пользоваться теперь в основных колонках со значениями мы будем хранить не самое актуальное состояние нашего наших верхнеуровневых полей а будем хранить некоторые устаревшие их состояния мы будем хранить разницу между этими устаревшими состояниями и самыми актуальными таким образом если мы захотим считать наши стоит баннера то мы прочитаем всю строчку из базы данных затем произведем наложение патчей на базовые версии верхнеуровневых полей и получим их актуальное значение и актуальность Окей сочтением разобрались Какая же у нас будет запись а запись у нас будет интересная вероятностное при каждом обновлении стоит там мы сейчас обновляем только те колонки которые реально меняются но теперь у нас пары колонок и теперь по каждой паре колонок основной и почевой мы будем подкидывать монетку из вероятностью размер патча делить на размер базовой колонки мы будем занулять патч и полностью обновлять базовую колонку в противном же случае мы не будем трогать базовую колонку и будем обновлять только патч то есть базовые колонки останется та же самая устаревшая версия которая там была до этого сколько мы теперь будем писать базу данных давайте для одного конкретного обновления посчитаем от ожидания количество байт записанных в базу данных и получим что у нас на одно конкретное обновление в базу данных в среднем пишется не больше чем два размера От текущего патча что довольно неплохо особенно если у нас такой профиль нагрузки что в нашем стыке постоянно меняются одни и те же байты в этом случае у нас размер патча будет примерно равен количеству измененных байт и получится что в базу данных мы будем писать всего лишь в два раза больше байт чем у нас реально меняется состояние очень хорошо но к сожалению не всегда так и обычно в состояниях меняется все-таки какие-то разные кусочки что же с этим мы сделаем Давайте оценим такой немножко утрированный худший случай предположим что в нашем стыке каждый раз меняются новые байты и из-за этого у нас размер патча при условии что мы не сбрасываем должен каждый раз увеличиваться на дельта P в этом случае можно посчитать что в среднем при каждой записи мы будем писать примерно средняя геометрическое между размером базовой колонки и приростом патча То есть если у нас в колонке 10 тысяч и каждый раз мы меняем то в среднем каждый раз мы будем писать по 100 байт что конечно сильно хуже чем могло бы быть в идеале но и сильно Лучше чем было до этого таким образом Делаем еще один хороший шаг И в частности на наших данных он экономил 50 процентов потока на запись база данных Давайте на этом приостановимся с оптимизациями записи и оптимизируем чтение никого не удивит слово кыши заголовке слайда все используют каши для экономии потока на чтение Мы тоже будем использовать каши но у нас будет один нюанс для сервиса потоковой обработки важно чтобы каждый цветов был консистентен с базой данных Почему Потому что Допустим мы обработчик из сервиса потоковой обработки и у нас вдруг образовался устаревший стоит в крыше тогда мы прочитаем какие-то события обновим с учетом этих событий и запишем в базу данных и тогда в лучшем случае мы потеряем какие-то изменения которые уже были записаны в базу данных Почему в лучшем случае потому что в худшем мы использовали базы и патчи и тогда мы могли посчитать новый патч относительно устаревшей базы базовой версии и тогда этот патч мы можем записать в базу данных и в базе данных окажется значение базовой колонки и почёвой колонке не совместимы друг с другом То есть это карапты данных остановка процессинга разбирательства очень грустная история не рекомендуем как же мы боремся с этой проблемой расскажу как работает наш сервис и почему у него крыши консистентные в первую очередь мы обеспечиваем шортирование данных что это значит что под этим я имею в виду Давайте определим функцию которая по ключу стоит там возвращает число от 0 до количества сортов не включительно функция использует функцию там никакой особой логики нет дальше мы все входящие в нас события предварительно разложим по партийцам промежуточной очереди в соответствии с номерами шардов ключей краткий Что такое партиция если кто не знает партицию упрощенно можно читать считать обычной очереди из-за курса алгоритмов в неё в конец попадают свежезаписанные сообщения читают откуда-то ближе к началу но еще важно что у каждого сообщения теперь есть номер офсет эти номера возрастают от более ранее записанных событий к более свежим событиям и у каждого сообщения надо никогда не меняется дальше каждый шар каждую промежуточную партийца у нас обрабатывает свой обработчик и у каждого обработчика есть свои локальные качества важно что локальный и обрабатывает единственный сервис потоковой обработки то есть наш сервис только он работает состоит нами никто снаружи с ними не работает как теперь у нас работает один обработчик одного промежуточного шарда прежде всего свой прогресс он хранит в таблицетами в той же базе данных Где хранятся и основные стойки Что такое таблицами по каждому по каждой промежуточной партиции хранится номер сообщения до которого включительно все сообщения уже обработаны и эффект от обработки этих сообщений уже закончен база данных теперь Если обработчик хочет обработать какие-то новые сообщения то он вычитывает значение офсета из таблички 541 из 542 сообщения начинает вычитывать сообщения из партий промежуточного черта вычитывает какое-то множество событий подгружает или берет из США по ним стыд и обновляется стоит и в соответствии с продуктовой логикой и хочет записать обратно также он это делает в первую очередь обработчик открывает транзакцию Затем транзакции он проверяет что наш Прогресс наше значение это ожидаемое То которое мы прочитали и ожидаем здесь увидеть дальше мы обновляем имени транзакцию и я утверждаю что такого алгоритма плюс того что в нашей базе данных транзакций стерилизуема достаточно чтобы все было хорошо Давайте предположим что все не хорошо Пусть обработчик один работал обновлял свой баннер Table Top а потом в какой-то момент у него Table Top оказался устаревший но он прочитал новые события обновил этот Table Top и попытался что-то записать в базу данных как такое могло произойти только если обработчик 2 того же сервиса тоже решил пообновлять Table Top в принципе два обработчика одновременно могут пытаться обновлять один и тот же ключ поскольку у нас нет транзакционная балансировка и в процессе перебалансировки два Хоста могут думать что они обрабатывают один и тот же жертв у нас это довольно рядовая ситуация но длится обычно очень недолго вернемся к обработчикам они обновляли один и тот же баннер но у этого баннера один и тот же номер шарда довольно логично А значит оба обработчика не могли пройти мимо обновления одного и того же значения в таблице сосетами мы обновляем исключительно транзакционно при этом логике то есть открыли транзакцию проверили что было ровно то что мы ожидаем поменяли на новое закомители и этот механизм нам гарантирует что тут хотя бы одного обработчика либо упадет проверка того что либо упадет а когда у обработчика происходит ошибка Он полностью перезапускается при этом сбрасывает весь свой кэш-тытов То есть обобщая у нас кэш стоит ток в обработчике либо консистентен с базой данных либо Это уже неважно поскольку этот обработчик ничего не сможет записать в базу данных из-за того что попадут проверки до этого я рассказал базовую версию кэша Давайте еще немножко подтянем Давайте использовать холодный кэш это значит что часть цветов в нашем клише мы будем хранить в сжатом виде за счет этого в тот же самый объем оперативной памяти мы сможем уместить больше цветов больше стоит большие кошки больше кошки меньше поток на за на чтение из базы данных таким образом с нашим и холодным кашам мы на нашем данных сэкономили 50 процентов потока записи Давайте теперь снова вернемся к экономии записи в базу данных и последняя оптимизация до этого я рассказывал про патчи и возможно У вас был вопрос А зачем мы делали какие-то новые колонки зачем мы получили какой-то странную корневую оптимизацию Почему нельзя было просто делать изменения считать патч соответствующей этому изменению и отправлять базу данных и пусть база данных сама бы его применяла Мы тоже задавались таким вопросом и поэтому так сделали сделали и у нас это даже работает вроде в нашей базе данных мы сделали специальную агрегирующую колонку Что такое корректирующая колонка это колонка которая Например можно последовательно писать единички А база данных будет все эти единички суммировать и при чтении из этой колонки возвращает нам эту защитную сумму но раз можно суммировать единички то мы взяли и написали свою агрегирующую функцию которая вместо простого сложения чисел берет и накладывает патчи на базовую версию строчки мы и так сделали получили Профит но тут есть важные нюансы о которых я сейчас расскажу для этого нужно поверхностно погрузиться в работу нашей базы данных нашей базе данных с агрегирующей колонкой по каждой строчке каждой колонки хранится некоторая базовая версия и несколько патчей записанные где-то на дисках когда мы хотим прочитать значение из строчки то базе данных нужно взять базовую версию взять все патчи посчитать результат применения всех почея на базу и вернуть тому кто хочет Прочитать то есть видим что чтение на самом деле довольно дорогое нужно много всего поднять дисков еще наложить патчи они еще каждый по отдельности накладываются и Чем больше потчей тем это дороже как мы пишем в базу данных запись база данных сейчас довольно дешевая просто пишем новый патч записывается на диске в базе данных и в целом никакого но так почти могли бы бесконечно расти своим количеством в базе данных Поэтому в базе данных есть периодический процесс так называемый compaction который берет базовую версию и несколько патчей и результат сохраняет на диск и важный момент сохранять на диск Это значит что база данных не может на каждую запись патча считать этот патч и сохранять точнее она может но в этом случае мы потеряем всю пользу от оптимизации записи Пусть Извне мы будем в базу данных писать мало байт но база данных внутри на дисках будет все равно перекладывать много байт а это значит что чтобы была экономная запись базе данных нужно довольно редко производить compaction если она редко производит compaction то у нас дорогое чтение возможно покажется что какой-то тупик но нет просто это решение для одного специфического кейса если у нас в всего стритов с которыми работает наш сервис потоковой обработки мало то эти стейты могут практически никогда не вымываться из наших локальных кашей-обработчиков А если у нас состояние всегда в крыше то мы их никогда не читаем практически А значит что нас и не особо волнует что чтение дорогое Может быть вопрос какие-то такие стоит ты но это такие интересные в которых по сути хранится эта информация её много Она часто обновляется не сильно И при этом всегда влезает на этом я рассказал про последнюю оптимизацию которая такая специфичная но зато посмотреть какой Boost на наших данных мы сэкономили 90 процентов всего потока записи в базу данных по этому типу State of на этом я рассказал про все Давайте вспомним Почему мы прошлись мы начали с базового решения где в двух колонках храним ключ и значение затем мы применили сжатие и сэкономили 15 процентов потока чтения записи и место в базе данных затем мы улучшили сжатие и начали сжимать со словарем и сэкономили еще 40 процентов от оставшегося потом мы пошли оптимизировать запись базу данных Сначала мы поделили наш State на много колонок и в несколько раз уменьшили поток на запись и еще для внешних потребителей сэкономили поток на чтение на карте не отмечено поскольку это все про сервис потоковой обработки затем мы применили патчи и X Дельта сверху вот уже много кого начнете да нам вдвое улучшение потока на запись затем мы повернулись к чтению применили кэши улучшили их применив холодные каши и выдавая сэкономили поток на чтение с базы данных и затем такое немножко ответвление которое довольно редко применимо но тем не менее очень интересно это агрегирующая колонка в базе данных и Очень мощное уменьшение потока на запись базы данных для этого случая на этом У меня все я рассказал про все что хотел и теперь готов ответить на Ваши вопросы и также готов послушать про Спасибо игроман за доклад мы теперь умеем состоянием либо думаем что умеем и у нас первый вопрос Спасибо за доклад очень интересно Я сначала хотел задать вопрос почему нельзя использовать просто менять то что у нас запись данных тогда будет большая как изначально Ну вот я не понял почему нас на графике скорость чтения не увеличилась и на каком из этапов Хотя при добавлении она должна была увеличиться у нас она снижалась Хороший вопрос Я просто забыл об этом на самом деле там действительно поток на чтение с базы данных немножко растет но размер Патча в среднем довольно маленький относительно базы поэтому там на наших графиках на самом деле даже видно не было То есть теоретически Да но на практике мы почему-то не заметили Понял все Спасибо за вопрос и у нас следующий раз у меня сразу три вопроса Я попробую сразу коллеги предлагаю задавать по одному иначе не сложно очень ориентироваться хорошо Вы упоминали про транзакции сразу ходу вопрос Если мы работаем с транзакцией на уровне очереди предполагается что очередь реализуется на том же движке базы данных Где основная шардовая таблица нет очередь может быть произвольной внешней Главное чтобы не были партийцы и были значения асетов Мы сначала нашу базу данных значение все это а затем уже после успешного коммита отправляем это знание в брокера очереди на самом деле интересный вопрос поскольку у нас есть очень много разных типов очередей некоторые интеллектуальные кэша например редис или еще что-то то есть кэширование тоже на уровне движка базы данных делается пиши прокторы я рассказывал это локальные каши внутри вводов внутри хостов на которых производится потоковая обработка сил на следующий вопрос Спасибо за доклад Что за база куда вы пишите но я из рекламы Яндекса Я сказал у нас везде быть который недавно стала танцами спасибо Так что вы можете попробовать такое завести у тебя следующий вопрос Вас не слышно раз раз спасибо за доклад очень интересно вообще как будто прокляхал шла речь какой-то момент про мержи вот этих вот пачей и так далее похожим образом работает я к сожалению не могу прокомментировать не пользовался и первый буквально 5 минут пропустил не в курсе вообще просто не было немножко под другое вот на 38 слайде можно вернуться можно нет предлагается транзакцию с campirents op как будто бы держать в одной BD и обновлять сожалению Вернуться не получится вы предлагаете транзакцию использовать для того чтобы закрепить чтобы какой-то один сервис этот условно мьютакс получил Да и потом пошел обновлять стоит так вот это всё в рамках происходит и обновление стоит и взять этого мюза или всё-таки сначала берёт и потом возможно с падением идёт обновлять сначала открывает транзакция потом идёт проверка мпр потом транзакции производится все необходимые обновления и транзакция кометтица это по сути стоп Окей сам стоит а на секунду сейчас принесут микрофон раз последний вопрос мерж является частью движка или его надо делать вручную а мерч чего и где вот этих патчей мерч патчей в первом случае когда у нас есть дополнительные колонки он делается внутри движка нашей библиотеки которые мы разрабатываем А если мерч внутри реагированные колонки то это мы на контрибьюторе выйти заурус специальный тип агрегированной колонки Спасибо за вопросы и у нас следующий Спасибо за доклад был очень интересно у меня вопрос по поводу Насколько часто вообще изменяются одни и те же данные одни и те же записи И не возникает ли такой ситуации что каши очень часто устаревают и сервис просто тратить время на то что он сбрасывает их постоянно и какой вообще оверхед от сброса кша потому что в этот момент сервис не может продолжать обрабатывать что-то на самом деле довольно мало поскольку изначально мы загрузили распаковали стейк чтобы с ним поработать Теперь мы можем удалить его сразу или какое-то время не удалять то есть по сути мы тратим только оперативную память процессорное время не тратятся удалять так и так придется на самом деле даже экономится потому что возможно мы переиспользуем этот стоит и сэкономим на разрушении а еще кажется была часть вопроса которую я забыл Ну насколько Часто вообще меняются одинаковые данные это сильно зависит от сервиса от того какой тип сущности Он обрабатывает Как часто по ним идут обновления То есть у нас есть процессинг некоторых рекламных сущностей которые практически всегда в кэше потому что их не очень много есть те которые вымываются просто мгновенно и поэтому мы даже кэш выкручиваем практически в ноль а вы не пробовали разделять каширование для каких-то часто меняющихся сущности для редко у нас это сущности разных типов это по сути разные процессинги вот так же у нас есть умные кэши которые поддерживают легковесно стоит по ключу и умеют понимать часто это встречающиеся ключ или нет Если он часто встречающийся то могут поддержать его подольше в ущерб тем кто встречается реже тут вопрос от меня А какой все-таки Линейная зависимость Чем больше тем больше памяти есть излом если использовать холодные крыши кстати про холодные крыши можно еще уточнить то что холодные крыши это на самом деле не дополнительное сжатие сверху в нашей реализации А мы просто удаляем распакованное состояние протобуфа и сохраняем стейт в том виде в котором он лежит в базе данных то есть опять же не делаем лишней работы по себе спасибо за ответы на следующий вопрос второй если я не ошибаюсь да второе если можно по-моему немножечко осталось не до раскрытая тема синхронизации кашей В итоге как она происходит как мы гарантированно обновляем кэш только тогда когда У нас конечно свои локальная у каждого обработчика каждый обработчик обрабатывает один шард когда обработчик стартует у него в Кошель ничего нет затем попадает то что нужно для процессинга то есть пришло событие мы загрузили стоит и потом его какое-то время не удаляем по сути мы просто держим те состояния которые мы уже трогали от устаревания она защищает то что если он устареет то кто-то поменяет офсет которые должны мы были поменять и мы просто свалимся под локально подразумевается в оперативной памяти именно сервис оперативной памяти хашмапа все теперь понятно коллеги Не забывайте голосовать правда доклад обратной связи идет напрямую до Клочков и на следующий вопрос Спасибо Юрий за доклад про холодное кошевые упомянули во-первых Почему было принято решение использовать холодный киши и насколько они добавили производительности вот Если сравнивать с горячим с обычным подходом зависит от сервиса в нашем случае про 50 процентов Я не знаю сколько точно было у нас не сохранилась исторического знания но у нас есть некоторые метрики кэш хита и это процентов 230 от всего от всей экономии именно холодный да то есть они 50 процентов сэкономили можно считать что процентов 10 из них это вот холодный Спасибо А насколько увеличилась количество используемых количество чего получилось насколько увеличилось потребление ресурсов целом а тут в том то что как раз холодные крыши у нас не особо увеличивают потребление ресурсов поскольку мы не меняем суммарное использование памяти а Просто берем не знаю 40 процентов стритов и начинаем вместо этих сорока хранить втрое больше стритов в Чуть более сжатом виде то есть мы немножко теряем CPU потому что потом их снова нужно парсить и поднимать память но и экономимся период поскольку возможно эти стыки теперь не нужно загружать из базы данных что тоже тратить ресурсы она не очень быстро и у нас следующий вопрос Вас не слышно Сейчас вы храните уже данные или вытаскивать их потом запрашиваете Почему вопрос статья мы храним состояние в том виде в котором оно хранится в базе данных поскольку нам это потом нужно чтобы рассчитать новые патчи и возможно обновить патч также мы храним в разных степенях распаршенности этот стоит спасибо спасибо за вопрос третий я смотрю никто вопросы задавать не хочет поэтому приходит только мне уже в третий раз Чем отличается тогда такой подход которого сейчас мы обсуждаем активно от того чтобы хранить сам патч на уровне сервиса оперативной памяти потом сбрасывать новости транзакции Повтори пожалуйста вопрос я не расслабился смотри у нас есть у нас есть патч мы иногда мы договорились хранить патч в колоночке в отдельную базе данных плюс у нас есть еще локальный кэш в сервисе чтобы там на чтение лишний раз не ходить на дорогое базу данных так вот что если мы будем хранить сам по себе патч внутри сервиса вместо кэша и периодически его сбрасывать базу данных то есть пожалуйста любое падение нашего сервиса не приведет к тому что мы потеряем эффект от какого-либо входного сообщения мы не потеряем у нас есть если мы обновляем в базе данных сейчас я не совсем понял вопрос Я предлагаю тебе после доклада подойти в зоне имеется кому сказать а на следующий вопрос Да спасибо за доклад А почему решили остаться в парадигме обновления документа точечного а не разодрали Этот документ на отдельные колоночки там Пусть их будет десятка или сотня не разобрали по колонкам Да каждая колонка имеет свою стоимость и у нас есть такая специфика У нас есть довольно длинный хвост цветов в которых практически ничего нет то есть если мы сделаем очень много колонок то мы по объему проиграем за счет текста и то где очень мало всего Ну и это ухудшает сжатие поскольку вот оптимизации по сжатии много колоночности патчами это все совместимо и в этом случае у нас сжатие перемещается на сжатие отдельных колонок и получается что мы тут ухудшаем сжатие и просто больше места информации тратим на хвост цветов в которых мало данных Спасибо за ответ так вопросов вопрос нету И тут Наверное у меня тебе финальный вопрос Выбери лучше его Вопрос шашающего было очень много хороших вопросов мне запомнился вопрос про сетов в исходную очередь вот поэтому подарок у нас Два подарка от вас и от онтика и второй два вопроса помнить это сложно да запомнил что девушка задавала интересные вопросы Спасибо тебе спасибо тебе за ответы Спасибо всем за вопросы у нас Через 20 минут будет следующее крутая штука"
}