{
  "video_id": "O0HiIT-xsuc",
  "channel": "HighLoadChannel",
  "title": "Мониторинг ожиданий в PostgreSQL / Ильдус Курбангалиев (Postgres Professional)",
  "views": 928,
  "duration": 1948,
  "published": "2017-04-09T09:48:45-07:00",
  "text": "Всем привет Меня зовут Ильдус курмангалиев Я работаю пост Professional А и на данный момент Я как раз можно сказать одним из моих задаче является мониторинг ожиданий по то есть добавление патча который там добавит такую возможность пос здесь ссылка на презентацию то есть там презентации есть пара картинок которые там плохо плохо видно будет их и будет хорошо Если вы е скачаете хотя бы потом посмотрите во-первых что такое мониторинг ожиданий мониторинг ожиданий - это когда это отслеживание событий в базе данных которые там происходит то есть там база данных может дать чего-нибудь там какие-то например сеять там или какие-то локов и вот это всё можно как бы использовать для определения узких мест в системе А где И зачем это нужно например если вы имеете там большой сервер например там 40 ядер и например они все там под 100% заняты то вас там-то там происходит там тормозить и так далее Интересно как бы узнать что происходит на данный момент то есть там база данных там может висеть на каких-то там причём чем больше ядер и процессов то они могут там друг другу мешать и так далее или ждать Там какого-то файла вот для определения таких мест и как бы используется Вот это мониторинг второй пункт то что уже есть такой мониторинг и многие мигрируют с окла и они хотят такой же инструмент иметь и пог тоже Ну и третий пункт - это то что этот мониторинг он должен быть как бы постоянно доступен То есть у вас есть работающий сервер в продакшене Вы хотите знать информацию о ней в данный момент а не искать её после уже возникновения проблемы задним числом с помощью ка с помощью каких-то инструментов какие есть типы ожиданий Ну есть диск сеть процессор может дать там Локи какие-то там или ещё какие-нибудь зависимости от баз Дан там может быть их много типов А в окле есть как бы он довольно таки продвинутый и по нему даже вот такого рода книги пишут какие есть типы ожидания по они как бы немного отличаются от того что есть в оракле То есть это вот как раз специфичные вещи которые именно есть постгрес постгрес есть три типа локов это вот потом есть Пинки также есть чи есть диск и как бы процессор а сразу расскажу скажу что такое лачи А лачи это когда процесс пост гресса в принципе спит То есть он просто ждёт пока его кто-то разбудит и в это время он ничего не делает то есть это просто когда вообще ничего не происходит А какие есть инструменты сейчас постгрес а для можно использовать Дат какую-то информацию в есть по которому мо можем получить информацию по запросу есть более продвинутые вещ типа SY можно вообще пользоваться иногда когда сов слу мо используют частенько гдб чтобы прям продакшене остановить сервер и посмотреть там Трей где вот именно что-то произошло например то есть там какой именно Лог там висит в данный момент А какие есть минусы вот этих инструментов они в принципе довольно-таки хорошие то есть они свои задачи выполняют хорошо их можно как бы использовать как бы всё равно надо использовать и но они не дают полную картину то есть по ним невозможно понять сразу где происходит то надо по очереди применять и надеяться что как бы найдёте ошибку там или какую-то проблему но Они внешне по отношению пер вообще как бы очень хорошая штука но мало кто им умеет пользоваться с например там какие функции за что отвечают и так далее ну в случае гдб там нужны как бы знания системного программирования Вот я как раз сделал такое вот расширение которая реализует мониторинг ожидани поре о называется это как бы новая штука пока работно впе компилирование поре Вы можете уже использовать добавляет профайлинг событий историю мо может смотреть и ещё есть ровка Это вот три типа то что сейчас реализовано как выглядит профайлинг например есть добавляется специальная вшка P есть ещё не сказал что Локи подразделяются на много типов то есть подразделяется там на восем вроде типов легковесные Локи имеет на самом деле очень много типов то есть там есть 41 41 как бы индивидуальный Лок и ещё есть разные группы там локов например для буфер менеджера там для каких-то предикатов или ещё чего-нибудь то есть там везде какие-то свои Локи есть и в принципе по названию лока можно ви Ну так вот по профа мы можем получить Сколько времени пог провёл на каком-то ожидании например Здесь есть есть есть то есть у нас есть общие пять типов там например вот эти вот как раз net сеть и эти все пять типов имеют какие-то е свои подтипы то есть в данном случае мы имеем ланей как бы lv Log под тип имеем val Log здесь мы присели там 88.000 микросекунд и про таких ожиданий было шесть есть вот такой вот интересный график это нам предоставил Яндекс в котором сейчас это этот патч работает и вот они как раз выгружают с помощью Вот как раз этой вьюшки профайлы и строят вот такие графики то есть Внизу там а время когда выгружена а а вертикальная ось здесь проведённое время в этом локе то есть здесь видно что был какой-то скачок какой-то момент и вот и скорее всего в это время как раз в системе были какие-то проблемы и уже можно как раз вот по таким графикам что-то уже начинать решать например уже смотреть вот эту историю это сейчас дальше покажу так да А какие есть наиболее частые Локи это вот то что как раз в Яндексе происходит это у них есть про и есть Локи ещё буферного межер это на самом деле их много но эти самые часты именно сначала расскажу про Н это вот как раз как это выглядит То есть когда происходит много локов буферного менеджера то есть мы больше висим на буфере на самом деле здесь и я вот показал здесь графике ничего не видно но я отделил что то что жёлтое это как раз буфер parti Lo и видно что больше всего Мы висим Как раз на этом локе и здесь уже понятно что надо что-то делать именно с буферами как вообще устроены Буе как бы буфера буфер менеджер пог Я как раз здесь можно понять почему эти Локи происходят буфер менеджер как бы состоит из ш таблицы и буферного Пула Когда вы указываете там вот это вот параметр SH он делится на блоке по 8 КБ и вы получаете какое-то количество буферов памяти вот этот вот этот блок памяти он делится не на количество буферов буферов по лока а делится на количество каких-то там Паршев то есть мы вот есть параметр на он прямо жёстко бит в коде в 94 он равен ми то есть весь там если даже указали там гигабайт памяти для это эта память делится только на восемь разделов и там есть только восемь локов и в итоге получается что даже если ваши процессы обращаются на разные к разным буфера если они в одной партиции то а они висят на одном и том же Локи и вот таким образом мы получаем Вот график который там находится вот на предыдущей картинке вот такую штуку А в 95 95 немножко поменяли там как бы на самом деле сильно поменяли количество этих парнов то есть там доба сделали уже 128 это кстати одна из причин почему как раз стоит сразу мигрировать на 95 когда он выйдет здесь ещё есть хэш таблица иш табли в ш таблице ключом является как раз таблица это номер блока это данные по буферу и здесь ещё висит когда вы меняется буфер висит ещё налог на самом деле то есть если много процессов обращаются КМУ буферу то и пытаются поменять то они висят на одном и том же локе как раз в этом месте а какие есть минусы профайлинга и плюс по профайлингу удобно строить графики то есть мы получаем сразу агрегированные информацию там всё очень точно то есть мы получаем там точность за микросекунд и как бы ну такую картину Это хорошо даёт такую общую картину Но потому что мы агрегирующие большой промежуток Неизвестно что было там за полчаса а вторая как бы второй пункт то что есть Это история событий А есть какое-то количество событий там последних там например 5.000 это как бы есть специальная настройка для этого и можно как бы вот это тоже выгружать а истории В истории побольше параметров там сохраняется по событию например мы здесь видим бы время событий когда Это наступило Но это время на самом деле неточное то есть оно именно когда мы сэмплированный или ещё что-нибудь А здесь мы видим Класс Класс Это Stage то есть есть Avent есть следующий слайд в котором всё это написано вот есть Это тип события есть дополнительные параметры то есть в случае име вот эти практически все параметры задействованы то есть мы знаем баз данных мы знаем знаем какой там вплоть до уровня блока и даже форка плюс истории в том что можно как бы сделать сначала профайлинг а потом уже как бы смотреть историю и понимать что уже конкретно происходило то есть такая детализация получается минусами является то что мы историю симпли то есть мы перебираем все процессы постгрес и когда мы если мы перебираем то естественно там пог может какой-нибудь эн там в начале там массива может что-то сделать что мы не успеем Потом взять когда мы Прим к нача массива Ну и то что Оно содержит как ограниченное количество там зада настройкой третья фича это трассировка мы можем например вот как бы здесь есть пример то есть мым запустить по как бы ну соединение к не узнать его Пит и запустить по нему как трассировку указываем файда мы хомса и здесь есть ти тестовый запрос по которому там-то происходит Так выглядит вывод трассировки то есть мы получаем всю картину всех локов там и всех ожиданий которые там происходили то есть здесь вот бы была было чтение сети запись запись записи здесь не было здесь было только чтение и была запись сеть кае есть минус трассировке очень большой То есть пока мы пишем файл ради каждого ожидания там их может быть очень много это вот как раз вот вот это запись файл может давать очень силь Ох потому что там происходит переключение ровка поэто ваде запросов есть когда ва зат пускаете трассировку по этому запросу и смотрите а плюсом является Что что в трассировке очень точно значение как профайлинг то есть событие началось оно сразу пишется когда закончилось сразу же пишется обратно файл а расскажу немного про устройство pgst wade А есть у нас как бы вот shar Memory есть бэнды и в энда как бы есть дополнительная структур в которой мы храним вот текущий то есть мы там храним начало Вета и когда заканчивается Вот это ожидание Мы просто записываем куда-то там сколько времени там Мы там провели через Мы не сразу скидываем это видимую вшку блокироваться Мы каждый сколько-то времени выгружаем вот эти вот эти данные из кэндо в отдельное место и уже вьюшка отдаёт данные именно оттуда а есть как бы отдельный Граунд вокер для истории То есть он который перебирает процессы про - это как раз вот массив процессов и у нас есть как бы текущая вьюшка то есть мы можем получить прямо по процессом Где мы сейчас висим оно прямо и берёт из бэнда оно может быть немножко не консистентные потому что там пока мы читаем оно может немножко поменяться и есть как бы история которая там куда-то там пишется просто-напросто история полностью консистентная Так выглядит сбор истории То есть у нас есть список кэндо А здесь Кстати реализован как бы алгоритм такой ну такой довольно-таки простой То есть у нас энды когда пишут в один пункт мы читаем из другого И когда мы прочитали мы переключаем вот эти вот два блока и читаем тоже уже по отдельности и таким образом у нас коллектор не блокирует энды ну как бы это сильно уменьшает Ух Ну и есть тесты как бых такая вот тестовая конфигурация У нас есть xion 24 ядра 24 ГБ памяти Мы запускаем pgbench со скейлинг 500 это даёт где-то объём баз данных в 1,6 ГБ поскольку у нас Мы хотим как бы получить чистые результаты мы Выключаем как бы влияние дисковой подсистемы то есть мы делаем fof и базу храним прямо как бы tmpfs ну Ram это вот как бы результаты ПГ бенчан что мы запустили 96 клиентов у них по четыре потока всё длилось там 5 минут и мы получили вот и такой результат то есть 131.1330 это этот как раз ПГ Бенч Он полностью загружает весь прод Ну как бы то есть там такой ну ваш топ например там полностью всё забито то есть мы получаем Как можно большее количество локов так сейчас вот P включен те же самые настройки и мы получили вместо вот то как бы там было 131000 здесь 130 то есть сам Ох В принципе меньше 0,5% нать так итог теста Вот именно в данном случае 042 Но это такой минимальный такой чистый оверхед то есть мы у нас получился такой синтетический тест мы какой-то там результат получили но и Понятное дело что в реальных системах Ух может скакать по-разному там разные нагрузки Там и так далее разные Локи разные разные структура таблиц и так далее А если выключить историю То есть если вам нужен только про Файлик можно просто выключить там в настройках и overhead будет ещё ниже как это вообще мы собираемся продвигать А5 уже полностью как бы уже закрыт то есть там никаких ничего нового не будет Поэтому ориентируемся на постгрес L 96 сейчас а там есть небольшие сложности А сейчас в коде постгрес сложно определить где мы как на каком мы ли косм локе например ВИМ на lightweight logs поэтому мы сначала продвигаем патч по изменению как раз этой системы то есть мы расширяем А как раз систему далико весны локов мы там добавляем как бы типы мы разбиваем на отдельные блоки в итоге получается что наше расширение Может прямо как бы по локу вычислить типы этого лока сейчас поре как бы это нельзя сделать сейчас патч уже лежит на как раз Кост он как бы ются там будут ещё некоторые изменения и надеюсь уже она скоро зако вторым этапом будет добавление то есть мы сначала не делаем вот этот весь мониторинг просто добавляем поле там когда вы сделаете там запрос у вас будет видно на каком например локе там висим то есть там будет и например каком-то столбце или будет то есть в этом запросе мы сейчас там читаем что-то там ия заго буде ядро пост гресса сейчас оно сделано как бы в виде расширения но как бы комит пост гресса явно Дали понять что лучше отстраивать этот сам постгрес типа чтобы не было как бы отдельной штуки то есть типа что то что это нужная штука и надо чтобы это было в ядре такие вот планы есть презентацию можете забрать здесь если интересно и можно попробовать сам патч То есть если вы компилирует постгрес Если вы знакомы там как Что как бы Как запускать его и так далее вручную то можно взять и попробовать А вопросы он создан Здравствуйте ещ раз текущий патч он против 96 сделан он сделан на Мастере то есть н там есть ветка мастер оно как бы сечас 96 и как раз нам делаем А насколько трудно его применить к 95 и взять там есть ветка 94 stable можем взять эту ветку и применить мой патч к нему и это всё будет нормально и насколько функциональность разбита между экстен и изменениями в ядре то есть большая часть она в экстен или большая часть это именно патче в само ядро Ну сейчас основное количество кодов 94 оно в ядре то есть во-первых там вот это рефакторинг мне приходится ки там довольно-таки сильно менять ну и вот как раз профайлинг там сейчас находится ам история и ровка они находятся а ровка в ядре история Эне Понятно спасибо слева от вас Здравствуйте Я немножко не понял По какой причине могут события пропуска в истории событий на процессов То есть у нас эмпер вот здесь он как бы по очереди идёт по массиву и вот в начале массива там что-нибудь может что-нибудь может делать могу показать слайде Так давайте Ну вот вот у нас есть массив то есть прой это как раз массив кэндо есть коллектор То есть это отдельный процесс если мы читаем например Из третьего блока который там Третий справа то первый энд может уже пару ожиданий там пройти в этот момент вот мы так и пропускаем ну как бы это минус Сплин то есть мы как бы трогаем сбоку эти процессы но Ну и получаем минус то что они могут делать что-то своё в это время когда мы где-то гуляем ещё вопросы Ну кстати я не рассказал про два типа локов ну давайте давайте микрофон а добрый день расскажите пожалуйста Результаты работы вашего софта планируется во внешних файлах держать либо типа оракла появится в системных словарях в пастри в дальнейшем чтобы это было удобно для анализа Там и так далее Ну вьюшки вот эти вот которые прой history Да да да они их не надо добавлять они как как обычные просто процедурки То есть их не не надо добавлять системные каталоги но планируется чтобы они что они будут как раз внутри да то есть то есть планируется что к ним будет доступ в любое время там для анализа и так далее Дада но как минимум профайлинг Скорее всего будет хорошо и второй вопрос Вы рассказывали про Локи которые связана с работой с оперативной памятью Планируется ли в пастри несколько моделей работы памяти типа Как это сделано H окле Там и так далее для того чтобы при Очень большом объёме оперативной памяти это не приводило к значительной загрузке ресурсов и вообще какой вы считаете оптимальной сейчас вот ну максимальный объём азу на пост гри а при котором это не приводит к фатальной загрузке цов на самом деле тут сложно сказать потому что есть какие-то общие там стандарты Но я считаю что лучше взять гбн и просто крутить свои запросы и по ним по ним определить сколько оптимально на самом деле то есть нельзя сказать там что там нужен столько-то азу Там и так далее не там процентах и так далее лучше просто взять и потестить То есть вы потратите один день на это Но будете знать как бы именно под свои там под свой Как бы как бы софт будете знать сколько вам нужно Какой у вас оптимальный как раз Какая настройка оптимальная Ну вот воркле например исходя из опыта как бы если объём памяти более там 256 ГБ надо H включать то есть как бы ну вот исходя из вашего опыта вы не готовы назвать такую цифру для Пари Не спасибо спасибо ну я больше разработчик я не администратор поэтому как бы Ну кстати планы там есть там есть патч который возможно уберёт вот эти все Локи как раз на буфер менеджере есть ещё один патч который там будет то есть там есть ещё внутри один Спинк который очень сильно на многоядерных уменьшает производительность и когда па будет сильнее как бы это шустрее станет Но это всё в 96 попадёт только Скажите пожалуйста Здравствуйте вы сказали что используется семплинг мы можем во Вью видеть агрегированные какие-то значения с периодом который мы снимаем и можно выгрузить файл Трей по какому-то отдельному пиду А есть ли возможность все метрики выгрузить файл сырыми данными то есть для того чтобы например провести общий анализ внешний можно с сырые данные по которым идёт агрегация представленная во Вью то есть там же нету таймлайна явного как-то они снимались там у вас некоторые агрегированные показатели а источник этих данных можно как-то получить с помощью вашего расширения Каких именно данных про по кото вас идёт агрегация по которому у вас идёт агрегация то есть несколько шарт локов такой-то Лок случа несколько раз И общее время их выполнения у вас там было на слайде указано там 8 секунд шесть раз он был и можно как-то посмотреть Это же было грубо говоря шесть замеров То есть каждый когда он происходил И сколько времени он занимал не по одному пиду конкретному выгружена А по всей истории вот которых эти замеры случались м Если я правильно понял вопрос то Ну в профайлинг Там как бы они агрегированные и там отдельных элементов вы не увидите вот я об этом спрашиваю мы можем как ну можно вот как раз за заюзал который там вот это вот history который на по смб и вы можете поймать там например четыре там из восьми этих как раз то есть конкретно настраивается С какой частотой есть период когда вот этот проходит и есть Сколько хранить истории ещё То есть можно это поиграться и там получить какие-то оптимальные значения для себя спасибо Ну и можно трассировку заю и тогда можно увидеть полностью все ожидания по как бы запросу Здравствуйте скажите а сэмплинг используется а из-за чего потом Ну то есть события же механизм событий он а рассчитан на то что событие возникает и система сразу должна его видеть зачем бегать по вот этому массиву исследовать все эти события А вы можете встать что-то Я не вижу вас а вот можете поставить вопрос что-то я е сказал Ну ещё раз вот мы используем сэмплинг для того чтобы анализировать события да то есть по идее механизм событий он он рассчитан на то что вот событие возникает и мы сразу должны его видеть то есть Зачем Вот Нам нужен этот сэмплинг то есть в связи с Какими особенностями связано использование такого механизма А если мы полностью ВС записываем в историю то есть получили ожидание записали в историю это даёт очень силь оверхед То есть это никто просто не запустит у себя продакшене там то есть это именно для уменьшения Дада то есть мы семплинг как бы у нас даёт вот как раз такие низкие значение оверхед если мы будем писать всё подряд то соответственно мы там там десятки процентов там 20% может даже получим У спасибо Ну если Вопросов нет то тогда всё спасибо B"
}