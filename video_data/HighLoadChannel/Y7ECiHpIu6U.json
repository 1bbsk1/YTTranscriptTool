{
  "video_id": "Y7ECiHpIu6U",
  "channel": "HighLoadChannel",
  "title": "Highload на GPU, опыт Vinci / Олег Илларионов (ВКонтакте)",
  "views": 1757,
  "duration": 2711,
  "published": "2017-04-22T14:48:15-07:00",
  "text": "всем привет я сегодня расскажу про такой вот интересный наш проект и а самое главное что это не еще одна версия предыдущие и при предыдущего доклада еще не еще один рассказ про там со всякими скучными схемами не гостей с фотографиями там котиков собак так далее а это будет доклад скорее про применение потому что я так же как и наверное большинство аудитории холода имеющий большой и долгий background в бэк-энд разработке то есть росно бэк-энд разработке и все новые технологии которые вижу вас понимаю с точки зрения вот того как мы все привыкли все делать нам и кэнди весь доклад будет именно в этом ключе то есть с точки зрения скажем так не россии с точки зрения backend разработчика и для начала вам расскажу что такое винчи это такой совершенно случайно родившийся проект который родился на внутреннем хакатоне вконтакте внутренних cotton это такое мероприятие которое проводится раз в год куда приглашаются некоторые люди но мы никогда не объявляем об этом и нет свободной регистрации то есть это такая закрытая тема в первую очередь для сотрудников но иногда мы интересующихся людей которые как-то об этом узнали или кто-то их пригласил тоже приглашаем поучаствовать соответственно после успеха признан создалось ощущение вот как многие наверное описали этом в комментариях и так далее да это git клон там git клон я тоже могу мы тоже так подумали поэтому собственно взялись за такую тему на хакатоне таки сейчас мы сделаем git клон и все будет зашибись соответственно в принципе предыдущий доклад показал что это чуть сложнее чем git клон но тем ни менее первых результатов удалось достичь именно за 24 часа причем первый фильтр который мы выжили то как раз была мо зайчика уже выпили но он удалось его до мучить и там и и много трачу нас был очень прикольный фильтр с картошкой который сделал всех картошку но мы его даже не стали запускать он он был очень клёвый но такой провокационный соответственно это такой проект котором мы очень чем и очень быстро сделали после после вот этого хакатона у нас было такое состояние что каждые где-то в общем каждый день мы запускаемся завтра поэтому не было времени все нормально сделался все время был на коленку то что завтра мы запускаем две недели соответственно чего удалось достичь то есть так как вконтакте есть такая внушительная медийная сила то есть как только что-то связанное с контакте запускается все сразу бегут смотреть в первый день у нас был аврал но тем менее за счет того как раз что был довольно большой опыт в мелодии в бэг-энд нагрузках до сделать так что приложение отличного пережила первый день не падала несмотря на то что за один день за сутки пользователя обработали 3 миллиона фотографий и соответственно первый месяц который стало приложение оно набрало миллион уников и соответственно продолжает расти то есть каждый месяц у нас больше чем миллиону сейчас вот соответственно приложение большое фактически от сейчас второе по размеру но по аудитории скажем так приложение после призмы про нейросети соответственно есть о чем рассказать в плане того как это внутри устроена но для начала хочется как бы сразу сделать сразу отметить что вот если нет вы не слушали предыдущий доклад то нам будет сложно и могу повторить если здесь есть кредит новый или как то в общем и целом работать но основная идея в том что у нас есть медленный алгоритм который там появился давно и который в общем и целом наиболее интересен с точки зрения технологии мне весь кучу минусов он медленно работает он скажем так на самом деле один большими он очень медленно работать есть быстрые алгоритмы когда мы просто используем медленно алгоритм для генерации datasette а и потом на быстрому алгоритме мы просто учим отдельную мира сеточку из исходных картинок делать обработанные причем это не розетка на как отлично годится для вообще всех преобразований картинок то есть там цветокоррекция super resolution как предыдущий докладчик говорил все что года мы делаем с картинками это в общем вот такая архитектура не все и поэтому собственно но и образоваться есть куча минусов получаем отличную скорость там 100 миллисекунд можно даже меньше есть еще куда оптимизировать скажем так в расслабленном режиме 100 миллисекунд когда мы там ничего не улучшали вот соответственно все зашибись это я говорю про скорость на видя щеках все зашибись но вот это вот тема на отвратительно сожалению универсальности то есть вы не можете взять там любую картинку и получить зова на и изображение сразу как с исходным алгоритмом который там вигдис а перед перри переносит через до долго историю через шум не хочешь на это отвлекаться то что доклад о другом соответствие несколько примеров работы и давайте сразу посмотрим что под капотом в общем и целом так получилось что в этой областью всех торт потому что конкретно при работе с изображениями сейчас . впереди ну и при этом на самом деле вот мы немножко изучали и сейчас торт все еще самое быстрое что у нас есть для работы с нейросетями все стороны решение они догоняют но там какие-то проценты отстают соответственно а turbo для того чтобы общаться и зло с внешним миром там по сети с другими серверами и так далее и на джесс гол вообще проект запустился на но джесси а потом на следующий день мы его тебя все это время пока он там запускался еще на коленке на голову писался варианта что она джесс с такими штуками не очень приятно ну вообще как с любым таким проектам где нет там какой команды для тестирования и так далее с языками в которых там лишнее слово может каким-то серьезным проблемам она где где нет статической типизации довольно сложно поэтому вот при первой возможности когда свободный выходной выдался все переделали на голову чтобы потом спокойно писать код и не переживать что все упадет из-за там какой-нибудь не поставленного вара и так далее вот но сегодня не об этом а у в первый чек проблемах и подводных камнях потому что делает проект мы смогли так сказать почувствовать вот это вот но нейронных сетей потому что там все на самом деле плохо вот как backend разработчик скажу что если вот прямо сейчас смотреть на нее носить они примерно также выглядит как вы наверное 2000 какому-нибудь пятом выглядело бы кант разработка вот там не напомнит как там было все очень плохо то есть например вы никуда не уйдете без кастомного супервизора который будет все время следить и время поднимать все что вас полить нашла все будет падать особенно там вот все что все что касается работы на выдержках потому что с и потом все окей но если мы говорим про видяшки проблема будет немерено ну и соответственно насчет технологии ubuntu незнаю что это необязательно чтобы у вас было чистую бунта вы можете использовать там докер на любом малину главное что в конечной коробки где у вас собственно весь так лучше не проводят ничего кроме бунт и даже с ubuntu лучше там версии последний не использовать вот там 14 там 1410 вот ну что что-то такое устоявшееся потому что с каждой новой версии там нужно руками все инсталляторы по читам таскать где у нас что чтобы они встали и работали дальше вот сразу вызов возникает дилемма когда делаете что-то мир сетях какую-либо у нас она была особо остро потому что наскучит кубу и вот когда мы сделали на ну вот когда мы были на хакатоне у нас была одна кобыла это не в дата-центре а вот у нас в офисе и соответственно был вопрос а может быть мы все там на кубу работает же все отлично но капу не лучший выбор во первых вам всем нужны в ящичке всего нужно много то что вам нужно быть что-то обучать вы не сможете сделать какой-то проект без research без обучения обучать на кубу эта боль и тоска потому что будет тратить на каждую трассу кучу времени значит вы будете медленнее чем все остальные потому что поэтому в как минимум на какой-то части ваши актеры вам понадобится губу на капу делать можно чуть позже я рассмотрю разницы в чем отличие как оно соотносится с целом оно соотносится где-то в 15 раз по скорости там какая-то для какой-то там для какого-то определенного ценового сегмента там серверный процессор и всегда быстрее но тем не менее у кого есть свои + соответственно какие плюсы у kaппa kaппa можете оптимизировать довольно интересно есть такие сопроцессор и особенно в мобилках есть очень много интересных вещей вокруг обычных процессоров там не он и тогда ли вы можете много всяких классных оптимизации применять и получать довольно интересные результаты то время как на gpu все ужас оптимизирована более-менее ну по крайне мере там куда и так далее понятно что вы уже там уровнем выше можете оптимизацию применять но там взять и заюзать какой-нибудь процессор вдруг новый там к богу пока не светит вот соответственно на капу вы можете вообще в целом когда мы говорим про какую губу у нас отличаются такие базовые подходы к нейросетями более-менее потому что нога у вы делаете широкие сетки такие так по-барски туда значит сразу архитектуру широкую то что вас очень много параллельных потоков и вам не жалко не жалко будет быстро работать на кубу вы начинаете считать так вот здесь вот мы там пошире сделали будет по лучший результат но это там очень долго по времени далее соответственно на кого вы делаете узенькие не розетки лучше сделать по длине и на паузу потому что будет работать быстрее вот соответственно следующий момент эта память потому что в целом если посмотреть на цены видяшек вообще на их там динамику то видно что память она как бы такой сейчас основной bootleg потому что ну в общем и целом сейчас там максимум для одной видяшки который доступен более-менее за адекватные деньги 12 гигабайт так там есть варианты с четырьмя но это уже так такой несправедливый ценовой сегмент вот соответственно с точки с точки зрения памяти вы очень сильно ограничены то есть 12 гигабайт это немного зависит конечно от задача то есть просто транспорт нормально для для обучения хватило всего хватит там в принципе 4 хватит cobalt но если вы хотите что-то более сложное большое то там надо все время держать в голове что если у вас там сильно большой объем памяти то лучше к полу ну и соответственно разработка отладка естественно но с вытяжками что сложностей доработать там чуть-чуть пытаться оптимизировать понятие так далее про квартиру и масть я вообще молчу потому что вы не только не можете там один и тот же код скобу доступного перенести на мобильный вы не можете там цены в колодце nvidia перенести на радио самом деле на радио не вообще лучше не смотреть там всего очень плохо тесте nvidia так вот соответственно угу есть куча плюсов в первую очередь производительность и она совершенно безумно важно при обучении потому что вы что-то обучаете очень очень важно чтобы у вас все было быстро и вообще очень важных да какие такие вещи делаются сделать так чтобы именно процесс обучения был хорошо построен потому что почти всегда от этого зависит результат очень сильно и угу все хуже с отказоустойчивостью то есть там не знаю на процессоре можно все что угодно гонять и не ожидать никаких проблем были менее но в общем это отрасль она постабильнее с точки зрения софта и с точки зрения железа соответственно мы начали анализировать какие вообще у нас есть перспективы и всерьез так как это совершенно такой типа проект был практически сторонний то есть он поддерживался но нам нужно было самим что-то придумать довольно сложно было организовать в наших датацентрах прямо сервера это стали смотреть может быть на амазоне поднять на амазоне конечно безумно дорого пока я надеюсь там через год через два все изменится на сейчас целом с точки зрения аренды сервера выкупу все очень плохо и очень сложно найти какие-то интересные хорошие варианты то есть детей ты та самая дешевая там вот порядка 250 долларов в основном сын виде я сейчас там видео 1080 там чуть позже объясню почему но вот самая такая основная в яшка для детей ted и в зависимости там от страны то есть вот в россии вы можете там найти порядка 200 50 долларов где-то там в штатах там вот в районе 500 долларов вы тоже сам будет стоять на то есть на самом деле дорого если мы говорим про там просто видяшку она сама стоит 700 долларов почему в месяц за сервер с ней нужно платить там 250 500 долларов соответственно нам удалось сравнить 4 видяшки единственное что мы сравнивали не последний титан а предыдущие потому что вот проект делался летом тогда еще не было последнего титана титана но я вот в табличку тут принес последние данные из последнего титана соответственно сколько где терафлопс сверху мы видим два серверных решений а то есть это теслы которые видео активно продвигает для установки в свои в до установки сервера там где вам крайне важна надежность потому что как я сказал с вытяжками все не очень надежно вам нужно быть готовым ко всяким сюрпризом то есть соответственно если вы там делаете медицинского робота то наверное лучше не покупать игровые видеокарты на ней пытаться там операцию на сердце проводить лучше в данном случае все это делать на курсе an action но в нашем случае в принципе нам не сложно там раз какое-то время у нас админа чтобы он там заменил видяшку от провел когда типа гарантию поменяться вот соответственно ценники в них разнятся катастрофически при том что в общем и целом производительность она одинаковая да там есть разные моменты типа там с точки зрения пример там скорость памяти еще чего-то они все отличаются не катастрофически то есть не в 10 раз там чтобы ценник так поднимать соответственно ценник довольно сильно разнится и вот мы посчитали сколько гигабайт вы получите за один доллар и интерес самый интересный вариант это видео 1008 самом деле мы в итоге остановились на том чтобы закупать именно их хотят столкнулись с проблемой что их просто довольно сложно закупать их довольно мало в целом на рынке потому что такая видеокарта очень нишу геймерское в общем нам пришлось там закупать и их и титанов просто потому что их там было очень мало в наличии при однодневные такой покупки у нас запуск был завтра каждый день поэтому не был особо времени что смотрите но хочется опять же при что вот тут сравнение в терафлопс ах они не всегда отражают суть то есть бывают специфический задачи когда у вас там ничего от скорости зависят опять же у них у всех этих видяшек разный размер памяти тоже важно но опять же там зависит от задачи нам например мне очень важно соответственно дальше хочется рассказать вам про архитектуру потому что на самом деле это не до конца понятно как как вот построить там какой-то такой сервис очень быстро на выдержках чтобы он там ну что чтобы с ним можно было нормально работать после запуска просто от того какую архитектуру вы сделаете на запуске все зависит в дальнейшем то есть понятно что можно там что угодно придумать но при первых же проблемах все упадет очень сложно будет починить соответственно так как в нас была пара дней на нагрузочное тестирование по краю пока мы его не прошли мы не релизе лись мы поэкспериментируем с разными архитекторами был довольно просто их менять и смотреть вообще что меняется начали мы с такой когда у нас есть фронты и каждый фонд общается с каждым бэг-энда мы ему задача раскидывает и при первой же проблеме когда что-то где-то застрял стало ясно что что-то это как-то ненадежно потому что вас что-то ломается вы не понимаете там это какой-то backend глючит и литов но он глючит или гнали довольно сложно локализовать проблему и очень сложно накатывать обновления то что вы накатили обновления и вас там все легло и непонятно кто виноват там частично не накатить обновления потому что вы если вы частично накосить вы не будете понимать где проблем опять же поэтому мы остановились на более простой схеме когда у нас соответственно есть фронты у каждого фронта несколько брендов и соответственно накатываем обновление только на один из них смотрим choco там как все окей окей на канале дальше и вот такая схема она даже лучше показал себя нагрузочное тестирование нагрузках и и так далее то есть вот остановись на какой такой архитектуре соответственно нее довольно много плюсов и конкретно такой плюс для нашей задачи соответственно у нас изображение загружается один раз на сервер потом обрабатывать всеми стилями которые прокликивать соответственно его один раз загрузить и за кашира вали на конкретном сервере точнее на как на конкретном фронте и дальше этот же фронт вам раскидывать на все бы кандаты изображения выигрываем немного в трафике в чем вообще проблема причем задача была довольно такая хитрая непростая с точки зрения архитектуры наше приложение смотрите у нас довольно много моделей для ненастий каждый стиль это своя модель модель это набор весов по сути для нейросети эти модели они довольно большие они сравнительно немного весят на диске но они довольно много весят в памяти соответственно когда вы загружаете в память особенно видеокарт это долго потому что в видеокарте нужно там пару гигабайт зафигачить стал каким-то числами и соответственно вы теряете на это время соответственно но при этом модель может висеть в памяти обрабатывать много фоточек потоком но так моделей дофига и их распределение неравномерно в пользователю там потыкали в этот фильтр потом там через пять минут они все побежали тыкать этот фильтр и так далее то вам нужно все ли менять это вот распределение моделей чтобы при нагрузках она хорошо распределялась и тут мы сделали довольно интересную тему мы сделали много много очередей много worker of которые работают с этими очередями и супервизор который переназначает worker of на разные очереди типа вот и теперь берешь задачи этой очереди но при этом от написали там такой довольно хитрый алгоритм чтобы он менял это очень так четко то есть только в те моменты когда то есть не чаще чем какой-то определённый момент времени там у них есть самые собственные лимит ордеров и глобальные элементы то есть чтобы он стал в общем задача супервизора менять очереди максимально редко и при этом получать максимально ровное распределение по очередям потому что распределение все время меняется соответственно все время нужно мы столкнулись с четырьмя battle.net им в разные моменты то есть в бреду момент нам не хватает году в апреле момент нам не хватает памяти видеокарте когда мы начинаем например слишком много моделей держать на каждой видяшки мы столкнулись с проблемой сетью потому что казалось бы там такая задача в этом на губу что-то обрабатываем а вот нифига сами картинки тоже весят до фига я не сеть просто забивают и нужно всем помнить что в реальном мире где всякие проблемы в сажен разных вещах опять же диск там сбивался буквально пару дней назад потому что кто бы мог подумать что на серверах где гигантские диски какой-то вот такое приложение может забить весь диск просто картинками которые он обрабатывает в папке temp но опять же вот все время нужно помнить о всех вещах которые есть в бэг-энде как раз в предыдущем докладе довольно подробно разобрали организацию обучения удивительно насколько у нас все похоже то есть даже тот же самое в галоп мы тоже используем но опять же все началось с ручного обучения когда мы просто сидели и смотрели вот вот вот этот стиль и он так прикольно выглядит или не прикольно давайте попробуем там поменять архитектуру поташ для каждого стиля меняется довольно много параметров тестом лёнинг рейд как мы вообще там чего смотрим мы меняем слои которую мы в разных фильтрах переносим и так далее то есть там пространство для экспериментов совершенно колоссальное и результаты они не где-то в одном месте в зависимости от стиля изображения они в разных местах то есть например вы хотите там вот такие толстые штрихи какую-то такую совсем абстрактность выбираете отнесла ее получается там один результат вы хотите такую легкую цветокоррекцию в каком-то комиксам стиле в сша на другие слои совсем другой результат соответственно нужно очень много подбирать это как раз вот минус быстрого алгоритма о котором идет речь соответственно чего мы добились что в итоге на во всей этой системе учитывая то что задача они намерены какое-то время держится в очереди для того чтобы мы поддерживаем все время равномерное распределение поведешь com все равно в средние время которое мы тратим вот нам на наших серверах на картинку учитывая то в то время когда они там в очереди лежат когда они передаются между там бэкон домов родном так далее она укладывается в 200 миллисекунд остальное это то время которое проходит уже на клиентам он качает у него медленный интернет и в итоге его страх не очень быстро картинки могут обрабатываться там несколько секунд пока у вас там скачивается обработанная картинка поэтому есть всего одно решение как уйти от этого это сделать оффлайн фильтр и вот как раз в отличие от предыдущего докладчика мы изучили этот момент и в общем и целом скорее скорее всего в самое ближайшее время за релизом версию с оффлайн фильтрами она у нас уже работает причем уже работает на андроиде и на айфоне на них время просто тестировать и довести до ума на те мнение это удалось это вполне возможным причем вот я покажу чуть позже картинки без очень серьезного ущерба для качества фильтров значит смотрите давайте посмотрим на то что у нас есть в самом начале в самом начале у нас есть два гигабайта оперативной памяти которые мы тратим на обработку одного изображения на губу соответственно будет то же самое не изменится у нас одна модель то есть каждый фильтр весит где-то 30 мегабайт довольно много и мы на циpкa если мы просто берем нашу модель и просто прогоняем на самым мощным мобильном девайсе который у нас есть мы получаем 20 секунд обработки меня серьезно нужно что то делать значит как выглядит распределение по времени который мы тратим на вот эту вот всю историю значит 42 процента времени мы тратим вот прямо на входе то есть когда мы получили картинку и соответственно там первые слои которые и уже к ширине ядра приводит то есть сильно-сильно сужают как раз свёрточная слои а дальше мы посередине пока мы делаем что-то с этой картинка тратим 10 процентов и когда мы и апс-м прям обратно увеличиваем нашу сеть до нужного разрешения чтобы получить какой-то стиль мы тратим 28 процентов соответственно на уже оптимизированной версии чуть дальше нас лучше ставить их расскажу как мы получаем вот примерно такое распределение по времени соответственно что можем делать во первых мы уменьшаем количество каналов не россетти что логично но что удивительно это позволяет нам не так уж и сильно испортить результат соответственно вот это катя мы в последнее время ее очень активно используем вместо лень лена это наши сотрудницы знаете лена картинка такая вот удалось сделать так что катя уже на двух научных работах вместо лена это такой тренд мы мы чувствуем вот я даже попросил эту картинку в open source выложить думаю в ближайшее время ее там справа starlight соответствуете строительство ну глаза стали менее красными там вокруг это стало более выспавшийся но нет никаких таких вещей которые бы сильно напрягали бы все все окей а мы уменьшили в кучу раз у нас был 128 каналов тут у нас 32 соответствие что мы дальше делаем дальше мы уменьшаем с вами матриц нас были 9 на 9 в разных слоях мы делаем 3 на 3 казалось бы тоже сейчас все станет супер ужасным то есть вообще как-то будет работать с матрицами три на три но конечно изменения стали более заметными то есть мы чего-то такое получаем уже видно что все изменилось видно что сетка стала че друга но тем менее мы сэкономили кучу ресурсов мы все ускорили а тут подумаешь там кожу поменяла оттенок на разных фильтрах артефакта они разные но тем менее соответственно на gpu мы особо ничего не выигрываем понятно что мы выигрываем в итоге там в ресурс нас меньше карточки будут греться еще чего-то но именно финальное время обработки не меняется особо поэтому это такая как у для история и все эти оптимизации они реальны играют роль только если вы делаете что-то на проце соответственно смотрите я говорил о том что сетка весит 30 мегабайт мы можем сразу скинуть кучу инфы которые там не нужно оставить только viso в нужных знать получаем 6 7 мегабайт все равно это много то есть если мы возьмем там 30 фильтров и запихнем мобильное приложение оно будет весить там какой-то астрономический размер по местам как facebook messenger никто не будет его скачивать соответственно что мы делаем мы самый вообще ultima тени и тем этом и нарисуем веса то есть генерация висят очень интересный как мы внутри сайта флота кучу-кучу-кучу флот в общем и целом они не сильно отличаются и в общем и целом мы не сильно потеряем если эти флот и приведем к двум флотом один положительный другой отрицательный они как бы останутся такими какими страшными числами типа там один и там 5 2 какое число и там минус там что но мы можем построить обучение так что у нас все время были одни и те же флот и всегда а потом мы когда мы сжимаем для транспортировки нашу модель мы эти флот и вообще заменяем на публике и модель становится супер компактный супер маленькой конечно мы теряем куча информации конечно наш фильтр становится не таким симпатичным как был раньше то есть чуть чуть позже покажу картинку что что у нас изменилась но еще еще один момент который мы делаем это вот то о чем и говорил раньше мы уменьшаем количество фильтров уменьшаем сеть это же за счет этого у нас сильно уменьшается размер модели потому что весов у нас становится сильно меньше тех кто впредь и соответственно изначальный файл файл был 30 мегабайт из них реально важных было 6 и 7 мегабайта в итоге мы получаем 152 килобайта который можно вот вообще запихнуть все фильтры которые когда-либо создавали в приложении все зашибись будет соответственно можем даже скачивать фильтр и потому что картинки обработаны который откачивает как же скучать фильтр весят больше можем прямо в реал тайме скачивать новые фильтры и так далее совершенно меняет ультимативную ситуацию и при этом продолжать работать до результаты отличаются да что-то выглядит по другому но кому он мы говорим про artistic стиле то есть в данном случае нам в общем и целом скажу так можем просто поменять весь процесс обучения и добиться того чтобы клёвыми фильтр появлялись именно таким способом на этих настройках собственно вот это сейчас и делаем сейчас заняты тем что генерируем новые наборы стилей которые работают уже нажатых моделях и в общем и целом получается результат который я не могу назвать хуже чем оригинал до фильтра получаются другие но они все равно по рекламе они все нормальные я уверен что когда мы запустим на статистике мы не увидим каких-то проседаний и все будет отлично соответственно в 44 раза удалось уменьшить размер модели это не считая потерь и кучи лишней информации соответственно быстренько какие есть основные проблемы с которым мы столкнулись самая первая проблема с когда мы столкнулись что git клон а оказалось недостаточно 15 парализовал на несколько часов на хакатоне но тем не менее мы нашли выход из этого соответственно debian он ли но это такая как бы проблема вопросы не нужно пытаться очень быстро поймете что не стоит лезть никуда и вернетесь обратно в бонте очень интересный случай общался с разными людьми из отрасли и не только мы с этим сталкиваемся реально есть такая проблема что видеокарты иногда зависаю причем зависают они не так что нельзя как мы привыкли у них зависает видимо input и output соответственно до них никак не достучаться никакой и nvidia там что-то там reset не помогает ничего stars только надреза то есть вы можете вернуть сервер в жизнь не только harder из этом возможно эта плата за то что мы не купили видяшки за 5000 долларов от nvidia и это происходит не очень часто то есть я думаю что если бы это был ваш игровой компьютер то бы даже не заметили потому что там раз там за пять лет у вас бы зависело там ведешка но тем менее не наверное это не касается игровых компьютеров потому что нас все-таки другая ситуация мы там 23:00 что-то крутим и самое главное мы крутим в нескольких потоках на 1 видяшки соответственно это немножко меняет правила игры я думаю что в игрушках таких страшных вещей не происходит плюс там но непонятно в общем что к этому приводит но многие люди которы экспериментируют с top чем они сталкиваются с тем что на больших именно о масштабах когда вы много чего считаете вас периодически видеокарте вам нужно соответственно мучитесь обменов что манеры были ли быть или сервера но так это происходит редко и плата за это это дешевые игровые видеокарточки то наверное это не очень страшно дальше экосистему ло сразу ну если вы делаете не на тендер flow она торчит все то нужно быть готовым к тому что нала вам будет довольно сложно то есть прекрасный язык отличный язык но эта система которая у него есть она находится на таком довольно зачать зачетный состоянии любую библиотеку который возьмем вы возьмете вам придется как-то тюнить менять апдейтить потому что там что то будет не работать там что-то будет глючить чтобы просто потому что слишком мало тестирования при переживает века система то есть там на других языках куча куча людей пробили некий такой вот безопасный паттерна использование когда все работает ничего не вылетает зло это не касается по крайней мере с ним говорим про бэкон потом общении почти и так далее нужно обязательно делать нагрузочное тестирование это вообще правило наверное жизни ноте мнение особенно касается неда сетей и у нас на самом деле вот то что нам удалось с каждой как брикс рулонах кота не то что в какой то момент мы там случайно заменили в 1619 первую половинку к тоннам умучили ввг 16-го g16 но вообще в в g16 уже в 11 раз сетки для распознавания изображений те на которых как их как раз мы datasette генерируем вот и соответственно мы мучали очень сильно любишь нас мы заменили нас и как бы после этого вдруг каждый следующий результатом все лучше и лучше и мы поняли что мы вдруг оказались на каком правильном пути вот и закончить доклад мне хотелось бы таким взглядом в будущее на эту тему как раз относительно backend разработчик вот как я это вижу дело в том что так как сейчас это устроено мне кажется неправильным мне кажется что этот подход он не позволяет нам быстро развивать какие-то приложения быстро что-то делать в прикладном виде то есть смотри как мы привыкли у нас вот есть базы данных там майский редиску и что угодно вот у нас есть база данных мы с ними просто общаемся по сети мы с ним какие-то таблички в них по сети любую конфигурацию тел он должен сложные вещи там иногда хитом очень сложная вещь с не расчёте мы не можем так работ я видел всего один проект от автора редиса как раз с ней розеткой которая имела сетевой интерфейс где всю работу вы делаете просто посети слоя команды для нее и соответственно вплоть до построения самой не все это правильно потому что если вы хотите там что-то сделать быстрый какой проект и вам нужно самим писать сервер самим писать интерфейса все это поднимать и самим писать супервизор чтобы она поднималась когда упадет вот эту всю ерунду это ну наверное так мы не уйдем очень быстро в течение ближайших нескольких лет если мы хотим увидеть это вот в прикладном виде чтобы каждый использовал своих проектах даже небольшое книга сеть что нам нужен какой-то другой инструмент опять же про масштабируемость ну все все очень плохо то есть в базах данных мы привыкли что есть офигенные инструменты для масштабирования тут нас в принципе но только мы типа распределяем нагрузку и это все все что нам доступно по сути квартиру и масти все тут у тандер flow еще более менее вы там можете на мобилках запустить но если честно это все тоже плохо потому что например вот прямо сейчас нет ни одного реально хорошего инструмента чтобы на губу мобилок чего-то запустить то есть единственно вариант отобрать металл под iphone и писать руками а с андроидом вообще непонятно что делать ну и с надежностью все плохо соответственно если все изменится и работать с ним сетями станет такая же как с базами данных что мы получим мы сможем в реал тайме обучать нейросети не делать это так что мы там выбираем какой то datasette обучили их получили какую-то модельку и там с ней работаем а мы обучаем не россетти в реал тайме используем real-time просто написали запросу на собой классе я очень надеюсь что через несколько лет это будет выглядеть именно так я даже уверен что наверное это будет активно двигаться в это в этом направлении большое спасибо хотелось бы выслушать вопросы можете просто спасибо за доклад можете поподробнее рассказать что такой бинаризации весов в вашем при сжатии то есть вы заменили все vesa только на один положительный и один отрицательный ну нет не совсем мы заменили виса на определенные числа которые конкретно в данном случае самое удобное со самой часты соответственно там не один и -11 там и что-то там и там я не знаю какие то флот и которые вот положительный отрицательный но потом мы сжали их в бинарный вид для транспортировки то есть мы не можем использовать не носить когда у на стамбул и ну по крайне мере нет софта да это хотя чисто теоретически это возможно но это опять же путь для кастомизации то есть если бы мы там все с нуля описали это наверное мы бы вообще написали бы что-нибудь 6 с бинарными сами работал есть даже научные работы и якобы кому-то даже удавалось там можно что-то почитать но по крайней мере никаких исходников примеров как с этим работать нету это исключительно решение для транспортировки в нашем случае и довольно низшего я наверное решение потому что это будет касаться думаю что только тех кто использует на мобайле не носите им нужно модели ужать вот у меня вопрос он связан с предыдущим вот ну для сжатия можно также например использовать вероятностные структуры данных их не использовали нет не рассматривали уже ранее могут вынести эффект ну не только из беды ну вот вы используете бинаризации вероятностные они с определенной долей вероятности смогут дать какой-то ответ а в случае если они не дают правильный ответ все равно это мы получаем какую-то нелинейность вы говорите о том что мы могли бы лучше контролировать тот объем данных который мы теряем да здесь у нас как бы довольно мы столкнемся с неким констант нам набором данных когда начинаем да согласен было бы интересно в данном случае мы скажем так нашли первое устроившие наше решение и стали двигаться дальше а кстати хотел сказать что все ввести размеры которое оказало не уже с учетом gzip и то есть после gzip и естественно мы мерили потому что там понятно что всегда можно чуть-чуть там какую-то кроху выиграть на сжатие здравствуйте спасибо за доклад а поясните как ваши фронты губу машины понятно как все схеме просто праве золотом и worker of понятно где стыкуются 2 инфраструктуры что чем находится да смотрите есть фонд есть бы confront и того скриптом он предпринимает запрос от лидера по api потом делать всякие хитрые штуки типа проверки подписи еще чего то еще чего то там была статья что у нас нет проверки подписи это не правда у нас есть проверка подписи в евро генте мы просто сейчас работаем с теми кто неправильную подпись нам прислал а просто потому что мы мониторим нагрузку и все нам все нормально у нас можно сказать что есть открытая api сейчас в каком смысле вот соответственно есть фронты и а есть бэг-энда фронт это такой прокси который получил запрос patch цепи и отправил запрос по и чистить и же на бока на бок индия висит ло и там для как раз для того чтобы общаться почти висит turbo показал что это лучшее решение конкретно вот сам самая надежная и в общем и целом там после пары патчи она стала действительно довольно надежным соответственно у нас эти front-end и back-end они между собой почти общаются получают задача там файл с перекачивают стоп а где в этой схеме worker и супервизор супервизор спрятанным внутри скрипта на голову это как бы дядя отдельный такой она отдельные грудь и на если вы говорите там языком гол это не отдельная сущность это просто по сути и еще один вопрос о пробовали использовать меза свеженький с поддержкой куты а не использовали как начнется привёз раз кого еще поверка силуэт висят супервизоры на боку на бок энди где у нас две пушки которые поднимаются время сломавшиеся ло потому что они там по разным причинам падают и за ними нужно следить и время поднимать нет не пробовали спасибо за доклад какие виды неработоспособности видеокарт вы встречали за период эксплуатации как вы их детектируется и если у вас какие-то промежуточные решения чтобы не доводить до ребута смотрите но он когда видеокарта за сайт мы ничего не придумали на то есть только reboot за все время использования на видеокарте сломалась ну опять же для того чтобы говорить о какой-то статистики у нас слишком мало цифр то есть там без если бы сказал что столько-то процентов видеокарт ломается там из такого-то количества на основе того что у нас на основе данных снос одна видеокарта сломалась это было бы не совсем корректно поэтому не могу сказать как часто они ломаются к сожалению хотя было бы интересно но тем менее они могут ломаться вообще напрочь они могут зависать соответственно там сильно чаще но тоже редко и паз по сути все дальше у нас можно только лук режется по каким-то непонятным причинам с с актрисами уходящими в дебри это еще чаще случается он тоже там все это случается сравнительно редко но тем не менее там когда мы имеем три миллиона фотографий в день мы видим это во влогах постоянно какие видеокарты чаще зависают вот как раз хотелось найти вот эту зависимость типа что там обвинить 1080i титан они зависают ну по крайне мере скажем так а статистически достоверных цифр не удалось получить они примерно одинаково то есть может быть конечно какая-то там на 10 процентов чаще зависает но мы столкнулись с этим слишком мало раз чтобы о чем-то говорить но хочется сказать что с точки у нас стоит старая титана потому что вы там давно ушли с точки зрения работы конечно 1080 гораздо приятнее потому что там у нас работают температуры 80 градусов не знаю это многовато или нет но мне кажется многовато потому что 1080 работать температуре там ниже 60 градусов средний именно рабочие ну у нас хорошее охлаждение и соответственно разница с точки температура накала сары и так понимаю что не касается последних титанов потому что они на друга архитектуре и они должны быть примерно такие же холодные как и второй вопрос на мобильном их на мобильных устройствах вы считаете на семью или на себя как раз вот и все пока довольно сложно потому что единственный вариант это металл и ios то есть на а у нас основной 2 на android с андроидом на джетту в общем скажем так простых путей не видно то есть пока только цветов на горизонте но у меня вопрос сейчас nvidia если человек блоге активно пиарит отчисления с плавен точностью 16-битный float и там собственно вы пробовали и был этот какой-то эффект а все цифры который приводил они с сингл престижен то есть единичной точностью не не пробовали но понятно чтобы эффект будет довольно сильной но там мы к сожалению в нашем случае нужно будет гигантское количество всего перед переписывать чтобы и между стежками кода для того чтобы попробовать половину точность и в нашем случае это опять же но не горит потому что как раз со стороны мощностями у нас нет проблемы перевод offline это в нашем случае совсем не спасение серверных нагрузок мы хотим и ускорить все пока план такой у нас будет работать обе технологии параллельно но в том случае если у гейзера медленный интернет у него будет работать офлайн потому что ну так по практике с интернетом очень часто мы получаем время обработки там больше пяти секунд и ещё такой вопрос по поводу ло не столкнул я прочту сталкивались с проблемами но то есть так насколько сильно проблемы именно связанные с языком потому что мы тоже как бы используем лода буквально недавно была проблема что в языке не правильно ли зова на функцию сохранения doblo в строку вот то есть от такого плана савченко безумный проблемы насколько это часто но нельзя сказать что часто нельзя сказать что у нас прямо очень глубокой экспертиза полу а потому что ну в нашем случае нельзя скажите нам много с тысяч строк кода на лоно писали есть только общее ощущение что большинство библиотек которые вы будете использовать nalu они работают довольно плохо из-за них они не прошли испытание временем вот как то так сам язык наверное классный сам он работает быстро единственное что бесит что он в купе с торчим довольно долго компилируется даже на мощных машинах но там это сейчас общие проблемы мне кажется для всех вы используете лоджик или блоджетт разумеется имеется к сожалению но да наверное зависит ситуацию спасибо тогда а да кстати подходите давайте тогда вот закончим и огромное спасибо"
}