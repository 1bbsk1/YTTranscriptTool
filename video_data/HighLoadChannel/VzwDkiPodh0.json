{
  "video_id": "VzwDkiPodh0",
  "channel": "HighLoadChannel",
  "title": "Частотный и байесовский подходы оценки TPR при неполной разметке данных / Алан Савушкин",
  "views": 442,
  "duration": 1852,
  "published": "2023-04-28T06:21:29-07:00",
  "text": "так всем Добрый день Меня зовут Савушкин Аллан Я являюсь датой лаборатории Касперского и сегодня мы доклад будет о том в принципе какую проблему Мы решили при неполной разметке данных Но по большей части Все мы решаем какие-то проблемы и все мы здесь Молодцы и больше часть доклада будет именно хотелось передать и поделиться математическим инструментами Как мы можем еще оценивать Когда у нас есть неопределенность а Сначала я расскажу Вообще какую задачу мы решаем какая у нас там в принципе откуда у нас берется это не полная разметка и почему Для нас это стало проблемой дальше мы рассмотрим два способа как можно решить эту проблему в конце сделаю общий итог но итог будет больше изложения моих каких-то эмоций переживаний что я пытался донести в докладе и в конце с удовольствием отвечу на все ваши вопросы начнем задачи Итак у нас есть продукт называется Он решает он предназначен для защиты инфраструктуры клиентов от Кибер угроз а Еще он состоит рассмотрим общий pipline Итак у нас есть Клиенты С хостов передается телеметрия но в общем это логика событий активности пользователей дальше из этой телеметрии выделяются подозрительные события и из них уже формируется алерты передаются сок аналитиком которые тщательно их расследуют и В случае обнаружения угроз предупреждает клиентов и дают рекомендации по их устранению теперь поговорим о цифрах Итак в среднем с Хоста может поступать 15 тысяч событий в день все это агрегируется собирается фильтруется и выдается В итоге ты в среднем 1200 оливтов кажется что немного но на самом деле аналитики ограничены во времени у них есть не более часа на расследование предупреждение клиентов но как часто бывает на практике когда мы хотим не пропустить мы должны быть слишком длительными и большая часть олертов является нерелевантными это может возникать потому что Для какого-то клиента активность может быть вполне характерной а для кого-то как раз подозрительный и здесь мы в принципе приходим на помощь аналитикам Мы выступаем вроде сервиса и решаем задачи фильтрации нерелевантных алертов то есть по факту мы классификатор который решает отдать Алерт аналитикам или нет и здесь мы как раз помогаем аналитику мы их оптимизируем их оптимизируем их работу поскольку они теперь меньше тратят времени на нерелевантные Лер ты и больше уделяет внимание реальному угрозам и соответственно мы здесь экономим потому что чтобы добиться похожей производительности без нас пришлось бы просто расширять штабы аналитиков Итак поговорим теперь вообще о требовании которое перед нами стоят и о целевых метриков нам нужно добиваться 50 процентов фильтрации потока и нужен тоже следить за этой метрикой и здесь у нас как раз проблем нет поскольку мы знали сколько мы отфильтровали и знали сколько мы Передаем и посчитать нет проблем но понятно что есть риски что мы можем пропустить релевантный алерты и перед нами здесь стоит достаточно высокое требование чтобы пропусков было не более двух процентов и соответственно нам нужно тщательно за этим следить чтобы в случае чего мы могли оперативно реагировать но у нас как раз и появляется Боль то что мы освободили аналитиков от работы Но мы потеряли разметку соответственно и нужно понимать как нам выполнить это требование и как следить за этим Давайте вкратце подытожим Итак и нужно оценивать поток фильтрации долю фильтрации узнаем как оценить степяр нам уже сложнее поскольку мы не знаем всех составляющих Давайте напомню как это считается и так трупойдете это то что мы верно отдали аналитикам Flash negattive то что мы неверно отфильтровали Если вдруг пользуетесь проблем нет аналитики посмотрели разметили а то знаете как раз проблема то что нам нужно как-то это получить Давайте посмотрим как мы можем это получить Давайте просто перепроверять наш сервис то есть мы случайно на потоке будем отбирать и передавать их налить им как будто мы не фильтровали аналитики отработают в обычном режиме они не будут знать что это перепроверка и Но для себя мы ответим отметим эти алерты соответствующим образом что мы ошиблись или верно отфильтровали Итак Мы вроде получили часть разметку Теперь давайте посмотрим а достаточно ли нам этого чтобы просто воспользоваться формулой а для этого просто сделаем проведем симуляцию на синтетических данных то есть посмотрим что мы будем получать и от того количества сколько мы будем передавать на проверку Итак первое Допустим мы ничего не Передаем то есть мы верим нашему сервису и ничего не проверяем Ну тогда мы будем всегда получать единицу Конечно мы этого хотим Но это сильно нечестно Хорошо давайте передадим кусок и тут принципе да конечно что-то находим но мы опять слишком позитивны слишком позитивно к себе относимся и придаем уже 50 процентов и нас сильно шатает мы можем как-нибудь мало найти можем как много найти и в среднем мы все равно оптимистично к себе относимся но и только передав все мы доходим до нашего целевого истинного значения Итак краткое резюме от того что мы сейчас увидели наивный подсчет дает нам завышенную оценку нам это не сильно не годится поскольку нам критически важно следить за реальным качеством нашего сервиса чтобы опять же мы могли видеть полную картину и оперативно реагировать вследствие этого нам нужна все-таки честная оценка И как мы видели нужно как-то не отдавать все при этом то есть сохранить пользу от сервиса И как мы видели стропозите у меня было проблем и вся неопределенность этой части которую мы фильтруем и как раз нужно научиться оценивать границы именно на эту величину Давайте посмотрим как это можно сделать начнем с частотного подхода частотном подходе мы строим доверительные интервалы я не буду давать определение расскажу о методах Как можно их построить И потом выберем как наиболее нам подходящий Итак самое такое классическое Это точно доверительный интервал в чем заключается прям какой-то статистику которая зависит от то данных и параметрам которые мы ищем и берем такую чтобы распределение этой статистики не зависело от параметра и это нам позволяет решить уравнение которое на слайде ниже и соответственно получить искомые нам границы Ну пример когда у нас выбор из нормального распределения оцениваем среднее то это будет точно доверительный интервал но часто так сделать не получается допустим если строить интервал на долю и реально выводить точную распределение там не избавиться от зависимости от параметра и Кто строил интервал на доле часто видел как мы используем асимптотический доверительный интервал здесь схема похожа просто мы берем удобное для нас распределение чтобы спокойно выводить границы еще есть метод называется быстрее здесь еще проще мы просто симулируем под выборки считаем нашу статистику делаем так много раз получаем набор значений и по ним уже тоже выводим границы но есть еще один метод о котором редко говорят но он существует А именно он берется из интерпретации доверительные Твайла и взаимосвязи его с проверкой гипотез если говорить вкратце то по факту доверительный интервал это те значения параметра которые согласуются с нашим с нашими данными при нашем уровне значимости давайте рассмотрим Как строить на самом деле процедура очень проста мы просто берем фиксируем значение и проверяем просто нулевой гипотезу если мы ее не отклоняем это значение нам подходит то есть мы не можем утверждать что ну то есть не можем Отклонить эту гипотезу и так делаем по всем значениям и собираем те которые нам подходят Давайте посмотрим как это применить к нашей схеме для начала нам нужно вообще понять какой у нас распределение как мы успели заметить когда мы отдаем аналитикам на перепроверку по сути они проделывают работу и эти алерты уже не могут считаться отфильтрованными соответственно Мы из нашей абстрактной корзины сделали выборку без возвращения давайте рассмотрим эту модель более формально но с картинками Итак N большое мы знаем Сколько всего объектов мы отфильтровали м Сколько объектов мы отфильтровали вот эту величину мы как раз не знаем И нам нужно как-то ее оценить поскольку мы знаем сколько мы отдали на перепроверку и Сколько в итоге в ходе перепроверки мы нашли Мы тоже знаем и такая модель описывается гипергеометрическим распределением Итак давайте теперь посмотрим какие методы нам подходят здесь какие нет Почему на них подходит первые три мы в принципе знаем некоторые величины и могли бы поступить так давайте просто оценим долю которая там есть а уже из доли попробуем оценить параметры м но здесь есть проблемы мы во-первых редко можем достать негатив соответственно Когда у нас крайние значения 0 для доли они все методы подходят для построения интервалы мы могли бы воспользоваться точным но другая проблема то что у нас М может быть дробным и куда округлять непонятно при больших им вроде нет проблем но при малых можем получать смещенную оценку но Последний Метод который основывается на проверке гипотез он как раз учитывает все сразу и он нам удобен давайте рассмотрим на каком-то примере как это строить Итак допустим мы отфильтровали тысячи олетов хотим оценить параметр м а 100 лет нападали аналитикам 25 нашли на перепроверг если мы посмотрим на наши гипергеометрическое распределение то какие-то величины может туда подставить можем и посмотрим как нам теперь вывести параметры м то есть его граница Итак повторюсь мы его не знаем но мы можем предположить что параметр M равен какой то какому-то значению давайте так и сделаем предположим тогда у нас появляется какой-то фиксированный гиперемерическое распределение как я уже говорил мы просто тогда проверяем на любую гипотезу что это равенстве параметры этому значению то есть мы считаем пивалью И сейчас мы ищем нижнюю границу интуитивно это будет так что мы как будто проверяем что они слишком ли много мы достали пока это Пока наши кривые ли больше нам это значение подходит тогда Давайте попробуем уменьшить как заметно просто сместилась распределение и вследствие этого пива или уменьшилась Но это значение пока нам подходит двигаемся еще дальше Вот сейчас мы на грани но пока не отклоняем нулевой гипотезу но если мы сместимся на единичку то уже отклоняем нашу гипотезу и соответственно мы должны взять предыдущее значение которое последним подходило а то же самое будет для верхней границы но все зеркально теперь м мы будем увеличивать игру говоря проверять Они слишком ли мало Мы достали при условии что м равно какому-то числу будем двигаться Все выше и выше пока не отклоним нашу нулевую гипотезу соответственно возьмем предыдущее То которое нам подходила последним и в принципе здесь как раз мы нашли верхнюю и нижнюю границу и теперь можем построить интервал для тебя просто подставив наши границы в исходную формулу давайте рассмотрим как это выглядит в процессе мы допустим только запустили сервис новичок отдаем 15 процентов эта цифра была выбрана как рядов чтобы мы наши интервалы не были широкими Не такой уж большой промежуток времени мы быстрее набирали данные но при этом могли фильтровать все-таки 50 процентов Итак пока мы только запустились данных у нас Маловато неопределенность достаточно высока но мы набираем данные и постепенно наши интервалы сужаются а также Я вывел на графике что нам дает наивный подсчет Ну как видно что мы как раз всегда позитивно слишком позитивно к себе относимся и нам это не очень подходит И что еще и как мы будем здесь действовать Мы видим что на наши интервалы покрывает наше целевое значение Следовательно мы не можем Отклонить гипотезу о том что наш тебя равен 098 нашему целевому значению соответственно мы можем быть спокойными Итак мы увидели что стандартными методами здесь Не совсем подходит данной схеме чтобы ими пользоваться но при этом рассмотрели более универсальный подход который на самом не сильно сложный то есть по факту прогнаться по значениям что-то проверить и в какой-то момент остановиться и здесь мы решили проблему завышенной оценки и если вам не очень нравится мостат и большие формулировки на тему Что есть будем повторять эксперименты и получим В итоге 95 процентов случаев такой-то результат то есть другой подход а именно он больше выражает нашу интуицию давайте рассмотрим его сравнение Итак первое общее это то что мы не знаем значение параметра и как раз два метода предназначены для того чтобы как-то выразить нашу неопределенность и вот здесь начинается различие в частотном подходе у нас значение параметра это фиксированная величина просто мы ее не знаем а в этом подходе мы уже начинаем как раз рассматривать распределение на искомый нашу величину а распределением мы как раз выражаем нашу уверенность в каких-то значениях каких-то мы больше будем уверены в каких-то меньше исходя из данных И как мы интерпретируем интервал Как мы увидели в частотном подходе это такое больше бинарный выбор подходит значение не подходит bisons подходе мы уже выражаем наши грубо говоря эмоции то есть мы говорим что с вероятностью какое-то значение параметра лежит в этой области Давайте посмотрим в принципе подход из чего он состоит мы собираем данные У нас есть определенные распределение это наш уверенность в значениях параметры Когда мы уже наблюдаем какие-то данные из чего оно состоит оно состоит из правдоподобие то есть насколько значение параметры согласуется с нашими данными это мы уже использовали в предыдущем подходе но здесь у нас добавляется новая штука априорное распределение это наше знание до проведения экспериментов до получения данных Ну например мы могли получить нашу уверенность в значениях и за Fine экспериментов и затем использовать уже напротив внизу Это просто обычная нормализация чтобы у нас суммировался в единицу Итак как это будет применимо к нашей задаче здесь я накидал сейчас больше символов Но ничего страшного Давайте разбираться Итак индекс N говорит нам о том что мы знаем сколько отфильтровали и действительно нашей схеме мы знаем эту величину знаем сколько отдали аналитиков на перепроверку и знаем сколько пропустили и также параметры То есть то что мы ищем внизу все та же нормализация и часто в литературе можно увидеть что там будет просто буква м мне не очень нравится потому что оно немного Судя по форуму смущает людей на самом деле нам нужно написать m-sk то есть у нас появляется смещение Давайте разберем почему оно появляется Но на самом деле у нас та же схема выбора без возвращения и когда мы отдали что-то аналитикам получили какие-то данные вся наша неопределенность остается в том что мы не отдавали и как раз там и мы выражаем нашу неопределенность Итак что-то Мы уже получили пока у нас Мы не знаем Какое у нас априорное распределение Но мы уже знаем какой у нас правдоподобие та же схема выборки без возвращения гиперемическая распределение пока знакомы и мы не знаем по стриорная но она будет зависеть от нашего выбора приложенного распределения а какое априорное распределение мы вообще хотим использовать если в общем мы хотим сопряженное априорно распределение оно очень классно потому что мы получим классный бонус Как пример предположим что наша априорное распределение является нормальным Мы как-то объединяем это с правдоподобием и в итоге если наше апостериорное распределение тоже является нормальным то значит наша априорное распределение сопряженное Итак Давайте снова вернемся к нашей схеме фильтрации и будем выводить наши априорные распределения на самом деле там интуиция очень простая но символы будет много но постараемся все разобрать Итак с какой-то вероятностью нашей корзине один налет может являться негатив валертом то есть мы не верно отфильтровали пока у нас один Алерт это просто схема вернули но у нас там куча алёртов То есть получаем биномиальное распределение круто но параметр P мы не знаем мы не можем оценить сейчас будем разбирать как это сделать Итак мы его не знаем но мы можем выразить нашу уверенность каких-то значениях еще до эксперимента до получения данных как это будет выглядеть Давайте снова зафиксируем какое-то значение параметра P тогда при фиксированном значении у нас будет определенный биноминальное распределение Я вывел здесь несколько а также внизу показаны наши априорное распределение но в каких-то значениях мы сильно уверены в каких-то меньше и каких-то слабо А в каких-то вообще не уверены то есть допустим если параметр параллельно единицы то значит мы то что все отфильтровали там все fulls Nexus ну это не так и мы все-таки верим нашу модель Итак у нас есть несколько Теперь у нас есть смесь минимальных распределений их несколько и чтобы получить какой-то но распределение нам нужно их объединить но объединить пропорционально нашей уверенности в каждом распределении Давайте теперь рассмотрим это более формально итак по факту мы просто это должны просуммировать и пропорционально нашей уверенности а Итак как мы уже видели при фиксированном параметры у нас просто биномиально распределение А наша априорное распределение мы вырезали бета-распределение и Сейчас будем разбираться Почему Итак здесь еще появляется бета функция но не обращайте внимание на это играл Просто давайте зафиксируем как Аргументы и куда они как аргументы переносятся в степени Итак подставляем в наш интеграл выносим константы и объединяем нужные нам степени как я уже говорил просто зациклился на том как наши аргументы бета-функции соответствуют степеням то есть мы получаем снова в эту функцию но с другими аргументами и здесь мы получили бета-бинное распределение и оно так и в принципе интерпретируется эта схема вернулись неизвестности вероятностью успеха параметры Альфа и Бета это наши априорные знания то есть количество foss негатив авертов которые мы видели до экспериментов Ну допустим на Fly эксперименты когда мы тестировали нашу модель об этом Это количество неудач Но для нас это хороший показатель поскольку это то что мы верно отфильтровали пойдем дальше Итак мы получили отстреленный распределение оно выражается таким оно будет иметь такой вид вывод немного там долгий но я привел свойства для вывода по сути там надо будет по жонглировать факториалами и сочетаниями и то что мы видим явную формуле выражается наше смещение на параметр м То есть это как раз этой схемы учитывает то что мы сделали выборку без возвращения Итак что мы здесь как раз и напомню что мы их искали сопряженное природное распределение и как раз это дало нам огромный бонус Весь вот этот бойцовский вывод мы свели простому сложению вычитании просто пересчеты параметров получаем данные пересчитываем чисел и все давайте рассмотрим на примере как это будет выглядеть Итак допустим мы изначально не уверены в каких значениях и сделали нашу перепроверку получили какие-то данные тупо пересчитали параметры получили новые бета-бинное распределение также отмечу что не будем забывать о смещении И теперь когда у нас есть обстрелы распределение мы можем выделить ту область значений в которых мы в наибольшей степени Уверены это будет она отмечена зелененьким Это и будет наш границы на количество тех алётов которые мы неверно отфильтровали Итак давайте посмотрим как посчитать нам теперь мы построили границу но помним о смещении и теперь то же самое нам нужно просто подставить в нашу первую форму а в чем еще здесь плюс на самом деле это распределение имеет реализацию и здесь надо просто по факту подставить значение и реально пересчитать занимает несколько строчек Давайте теперь посмотрим как это выглядит динамики то же самое запустили сервис неопределенность пока высока но постепенно получаем данные также сужаемся Когда у нас априорно распределение равномерное то есть мы не уверены ни в каких значениях очень похоже на доверительный интервал но важно помнить что это разные разные взгляд но мы также можем здесь принципе работать что если бы наши интервал с точки зрения было бы далек от нашего целевого значения то мы также начинали бы паниковать Итак давайте подытожим что мы здесь увидели здесь мы подошли к задаче с другой стороны на мой взгляд здесь выражается больше наша интуиция и здесь мы вывели явное распределение на параметр М что как мы увидели удобно но помним освещении И как мы видели получаем схожий результат но здесь совсем другая интерпретация и если подводить общий ток Да мы наши проблемы решили Это классно это круто а также мы рассмотрели два метода и вот как раз здесь хотелось бы поделиться тем что мы провели сравнивать методы Что лучше что хуже но здесь я хотел донести эту вещь что на одной и то же проблема можно посмотреть с разных точек зрения и как вам рассуждать то есть выбор здесь заключается в удобстве вашего рассуждения то есть чем вам удобнее оперировать Если вам удобно выражать Ну говорить фразу что с вероятностью 0,95 значение параметры лежит в этой области то Выбирайте бойцовский подход я допустим сильно придерживаюсь частотного подхода мне очень классно говорить эти очень длинные фразы что если мы будем проводить эксперимент много раз и с вероятностью 0,95 наш интервал будет накрывать целевое значение и мне этот подход более интуитивно на самом деле понятен то есть вот эта точка зрения что зафиксирует значение и просто сверимся нормально ли наблюдать такие данные Мне он Ближе Поэтому в нашем проекте мы как раз выбрали частотный подход на этом У меня все готов ответить на ваши вопросы мне скорее не вопрос У меня просто можете привести пример когда вы вот использовали именно бойцовский подход то есть в каких ситуациях но для меня байский подход Обычно я использую Вот как раз Когда возникла проблема с частотным подходом Ну то есть не сразу было понятно как строить интервал как раз я сначала использовал бойцовский подход Ну просто посмотреть а чтоб Ну хотя бы как должны выглядеть границы То есть как мы увидели там правдоподобие было одинаковое вот и мне сначала было удобно как-то Ну через это выразить Вот но этот подход Я не очень люблю применять на практике потому что другая интерпретация которой я не привык а важно пользоваться именно тем что ты хорошо понимаешь И что ты можешь быстро интерпретировать и для других донести Вот то есть это обычно для меня это такой способ когда надо что-то попробовать просто посмотреть на это но у нас просто больше именно распространен частотный подход и будет странновато если в разных проектах Ну то есть надо будет уточнять тогда явно какой подход там используется мы пытаемся одного подхода придерживаться вот к этому Здравствуйте спасибо большое за доклад вот на схем было изображено что эмаль как это единая сущность Как вы работаете с экспериментами то есть несколько разных моделей Когда вы используете сейчас у нас на слайдах был один фильтр так сказать условный что какие взаимосвязь когда их много сейчас я пока буду мотать и отвечать на ваши вопросы но смотрите у нас Мы у нас эти алерты еще хранятся какое-то время и соответственно у нас остаются исторические данные и в оффлайн экспериментах мы пользуемся именно размеченными данными То есть то что они размечено мы оставляем мы пробовали экспериментировать с тем чтобы это тоже использовать но такого значительного прироста нам это не дало От данных приходится забирать больше вот в офлайн экспериментах мы немного другую схему оценки используем Мы тоже используем точный Ну мы там используем точно доверительный интервал но там немного другая схема поскольку мы наши размеченные данные можно рассматривать как выборку из какой-то совокупности и соответственно трупозити Фолз Найдите в кому-то мы знаем Все мы просто взяли сэмпу но там интервал получается такая Такой можно сказать классический на долю вот проводим также гипотезу сравним если значительный эффект есть то значит хорошие изменения выносим впрот"
}