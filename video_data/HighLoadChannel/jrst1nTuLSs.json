{
  "video_id": "jrst1nTuLSs",
  "channel": "HighLoadChannel",
  "title": "Рост с нуля до 15000 сообщений в секунду. Мучительный и поучительный / Юрий Колесов (security-gu.ru)",
  "views": 4707,
  "duration": 2068,
  "published": "2018-01-16T13:41:37-08:00",
  "text": "коллеги добрый день меня зовут юрий колесов я занимаюсь безопасностью занимаюсь администрированием сочетая несочетаемое решаю нерешаемые я работаю со многими компаниями поэтому если у кого-то есть проблемы можете свободно со мной контактировать сегодня я в цветах компании тем connect в которой я занимался участвовал разработки архитектуры и строим серверную инфраструктуру минутка рекламы компании тем connect собственно первое вывела push-уведомление в качестве канала взаимодействия банка с клиентом и собственно компании чем занимается процессе эсэмэски от банков по возможности отправляет их как push то есть эти сообщения принимаются по smtp это не путать с если типе short место чп супер протокол такой прошлого немножко и соответственно улетают они в apple в google и в microsoft об ушами аспект наш написано и сэм типичная часть на сие пуше и topic взаимодействия с мобильными устройствами на питоне собственно задать история начинается с кейса когда бизнес пришел и поставил задачу для пилота в большом зеленом банки из топ 1 показать processing 15000 секунду ну и срок на вот это вот развертывание на стороне клиента на его virtual koch два месяца кому задача кажется простой поднимите руки а кому не решаемый немножко усложним задачу добавим такую вводную вот этот прогресс барр серенький он символизирует 15 тысяч сообщений в секунду у нас будет преследовать на протяжении всего доклада а там вот совершенно не видно я маленькая зелененькая слева это 15 см с в секунду который на тот момент процессе la самая крупная инсталляция но процессе лань и потому что больше не могла потому что больше их не было потому что но банки обычно просят там двести-триста секунду канала реально вот шлет 15 но вот факт остается фактом поэтому задача выглядела вот для нас вот так вот все в тот момент были похожи на этого персонажа известного понятное дело что к к этому моменту мы подошли не с нуля там что-то до этого пытались уже за оптимизировать сделать в первую очередь мы оптимизировали вот этот т7 типичный код мы хотели сделать чтобы он работал как engine x то есть быстро круто мало сжал памяти и каких-то успехов безусловно нам у нас получилось что-то сделать мы разделили нашу базу данных которая была изначально на минимальном продукте который вышел на рынок 1 разделили на две выделили отдельно очередь где собственно процессе сообщение архив г сообщения этих хранятся долговременно в первую очередь это было сделано с точки для обеспечения безопасности этого архива но оба вторую чтобы в дальнейшем их можно было разделять и как-то нагрузку на базу данных снижать еда у нас и очередь архив в базе данных базы данных mais quel в архиве парте shining и монолитное приложение разделили на но выделили отдельно мобильный api которое собственно принимает сообщение от мобильного телефона что push получено забирает полный текст сообщение выделили отдельно личный кабинет и отдельная модуль который отправляет пуше то есть надо изначально это было все единым монолитом не пошли дальше не стали делать микро сервис и потому что в контексте обработки сообщения очень важно watenshi я микро services добавляют определенные в этот оверхед и ну что что-то скорости обработки мы теряем мобильном api мы занимались личным кабинетом не очень она push вообще забили потому что но они улетали в достаточных количествах а пока проблема нет собственно зачем что-то менять собственно на тот момент мы считали что этого хватит для всех как оказалось нет соответственно прежде чем приступать нам нужно было как то сформулировать какие-то требования обычно когда возникает такая задача это не первая не единственная компания которая она возникает обычно бизнес предъявляет либо требование каких-то минимальных сроков в нашем случае это был некий дедлайн после которого собстна задача становилась не нужно у нас были ограниченные ресурсы в силу ограниченности времени мы в общем то у нас не было времени на то чтобы кого-то хантик привлекать в проект со стороны ну то есть это было достаточно сложно и нужно было по возможности обойтись теме человеческими ресурсами которые уже были а теме разработчиками которые были админами так далее ну и к счастью у нас было количество на определенная цель то есть нам надо было за процессить 15к принять 15к отдать в сторону smtp и по семь с половиной отдать в сторону а псы gcm но microsoft никому не нужен microsoft умер он есть но смысл ним никакого ну и прежде чем начинать очень хотелось оценить вообще достижимость этой задачи потому что если мы не можем достигнуть этих цифр ну вот не смогла то в общем зачем начинать потому что выкидывать два месяца из жизни разработчиков до срывать их с намеченного рот мапо тратить ресурсы и потом получать на выходе делать немотивированную команду которая не справилась с задачей но это печалька лучше не начинать нам нужно было оценить трудоемкость то есть если задача реализуем но мы ее не можем выполнить своими силами нам где-то не хватает человеко-часов то надо было как-то бизнесу возвращать эту информацию чтобы бизнес как это решал там какие-то процесс аутсорсить там нанимать кого-то ещё короче решал эту проблему ну и по условиям задачи мы должны были показывать это дело на виртуальных машинах у клиента поэтому нам необходимо было ну для себя в первую очередь определить какой же скиллинг будет разумным то есть например если мы попросим 10 лидеров но это будет очень круто и нам конечно эти 10 ядерно dude если попросим тысячу ядер то скорее всего на нас посмотрят как на людей не в себе и на этом разговор закончится но там сотня меньше сотни но где-то вот там в этом диапазоне мы решили что разумный скиллинг лежит ну понятное дело там еще и диски участвует все остальное память вот но для примера на ядрах собственно как понять что мы имеем сейчас и вообще насколько мы далеко в реальности от заветных цифр самый наверное единственный способ это нагрузочное тестирование вообще нагрузочное тестирование предполагает что мы тестируем то все сценария используем релевантный набор данных и общем это такой достаточно сложный процесс сделать это тестирование адекватным поэтому это не наш метод наш метод этом взять и быстро начать ее собственном на том что есть на то мы тестируем то есть мы не собирали изначально никаких стендов мы взяли тестовые сервера и давай их нагружать для того чтобы нагружать нужные генераторы нагрузки к счастью у нас был уже sm типичный генератор и даже было семь типичный приемник но нам нужно отправлять еще кучу сообщений в apple и google google и apple не обрадуется если мы туда начнем что-то слать таких количествах поэтому вот этот приемник нагрузки нам необходимо было создать что мы пока программисты думают я взял печки и написал там hello world приложения которые вызовут возвращает валидный джейсон на любой ответ запустил его под печь pvp мам и получил в общем печальную картину что 15 кмф принять то в общем наверно можем но ресурсов это требуя слишком много и с этой же задачей с тем же простым приложением я пришел к разработчикам они написали то же самое на питоне на котором мы все пишем запустили это дело под и уважаем получили рпс на одной и той же машине два раза больше это вот к вопросу о том что питон не продакшен ради вообще для хипстеров иной для пин тестеров по результатам исследования вот этой нашей сферической машины в вакууме мы получили три с половиной тысячи поясом пеппе и тысячу пап ушам в общем картина вот такая вот в этот момент мы почему-то подумали что с пушками ситуации проще что мы добавим worker of и все полетит она может чем за оптимизируем еще по мелочи а по smtp и это в общем как бы надо что то делать и еще одна проблема то что один программист может сделать за неделю 2 могут сделать за 2 вот этого нам хотелось избежать и поэтому мы решили что мы не будем собирать стенд целиком а мы возьмем ее за тестируем каждый компонент в отдельности то есть мы если мы тестируем вход то мы просто принимаем и отправляем в дивном если мы тестируем отправку то мы заранее генерируем данные в базе данных в достаточном объеме максимально быстро их выплевывает если мы тестируем базу данных то мы берем реальные запросы загоняем их страсть с этим стресс-тест базу грузим смотрим сколько она может получили следующую картину но поясом пеппе в общем все стало лучше по базе очередь показала нам те же самые три с половиной тысячи которые мы видели раньше архив архивная база почти хорошо такая разница между очереди архивом обусловлено тем что в архив сообщение пишется один раз то есть она от процессе ласси с финальным статусом попала в архив а в очереди она там операции записи проходят там примерно 4 в среднем раза на сообщение в зависимости от того там каким путем она летит мобильный api тоже в общем но и не хорошо неплохо и пуше наши под 1000 сообщений в секунды и мы опять как бы отправили одного человека их оптимизировать немножко и забыли про них казалось бы да вот наверное но на пир канале их я сомневаюсь она в прошлом хай-лоу де наверное думаю многие смотрели этот доклад про то что open source ную база данных там миллионы запросов в секунду а у нас такая печалька понятное дело что тесты все эти делаются на нагрузке на чтение а у нас там сплошная запись и результаты в общем наверное разные получаются ну а с этим что то делать мы начали генерировать идеи в порядке бреда мозговой штурм записывать их на бумажку тестировать первая идея была затюнить чё-то затюнены мы наконец-то достигли в архиве нормальную производительность из кому и в очереди мы ну чуть-чуть у нас подросло но все равно недостаточно мы пытались была такая идея у программистов использовать в качестве очереди мем ренджем кто использует маску или знает что это не сработает заранее он никто не знал почти никто не знает отлично тем кто не знает расскажу что мемориал джона в миску или он такой древний не транзакционные построены на мои сам движке и при записи там происходит блокировка уровне таблицы то есть как только возникает некая конкурентность на запись у нас все запросы висят выйдем фото и был ли вилок в общем работает это отвратительно но убеждать программистов в том что эта идея плохая в общем-то было бы дольше чем попробовать попробовали за час увидели что это плохо посмотрели на нашего процесс лист да и в общем идею от отвергли следующая идея была мастер мастер нас не пугает мастер мастер потому что мы его используем в продакшене мы начинали со схемы которую александр демидов из битрикс24 рассказывал мастер мастер для отказоустойчивости но в итоге пошли дальше пишем в оба мастера ну просто нам так удобно поэтому у нас это не пугает не пробуйте это дома да если вы никогда этим не делали в не занимались это там есть масса подводных камней мастер мастер реально дает некий небольшой прирост производительности на запись в случае если мы используем а синхронную репликацию мы исторически использовали маски 55 и на продакшене не переезжали дальше там мосин репликация синхронное позже появилась пол асинхронной репликации синхронные по моему вот в ситуации когда появляется глобальной идентификатор транзакций мастер мастер становится медленнее на запись чем один сервер чем больше у вас в кластере мастеров тем медленнее он пишет в случае с и синхронностью это чуть-чуть быстрее но два мастера не пишут в два раза быстрее к сожалению поэтому это тоже нашу проблему не решала 3 мастер мы решили даже не пробовать эту идею отвергли есть такая прикольная штука току д.б. это база оптимизированная для в райтон ли нагрузки дает она некий небольшой прирост производительности на запись по сравнению с на db и еще одно полезное свойство данные на диске меньше занимают места прям реально меньше там зависимости от условий там в разве может доходить там в два раза например вот это здорово но так как она нашу задачу все равно не решала мы остались на и на д.б. потому что ну что то менять непонятно каким последствиям это приведет была идея перенести очередь в редис потому что редис мы тоже уже использовали на тот момент для всяких вспомогательных данных которым часто происходит обращение которые часто идет запись но мы решили что переписывать наш сильный кот который хорошо работает на редис и поймать там корку в процессе тестирования но тоже не здорово поэтому эту идею отвергли и остался в нашем списке только sharding к этому наверно приходит все в конечном итоге в шар денги что самое главное это выбрать правильный ключ обычно шар дед для того чтобы когда не хватает места на одном сервере под данные их раскладывать на несколько серверов и собственно ключ это должен обеспечивать равномерность распределения данных по этим шахтам в нашем случае ты уже должен был обеспечивать равномерное распределение нагрузки по шару там нам все равно сколько там данных лежит в этих шахтах нам важно чтобы запросы летели по всем шар дам равномерно соответственно но мы посчитали что нам нужно 4 шарда можно 5 до но 5 это лишние ресурсы если мы можем показать заветные 15к на каких-то на x ресурсов дата просить у заказчика там x + n уже не здорово ключ должен участвовать во всех нужных выборках то есть вы не должны за своими данными ходить два шарда иначе все идеи прироста производительности от шарден га теряется первая идея была в порядке бреда разделить отдельно отделить трафик который летит в пол отдельно от отделить который летит google понятное дело что это не решало нашей проблемы потому что туда 70 половиной летит сюда семь с половиной это борьба за может только 4 и мы решили шортить по номеру телефона но нам казалось это самым естественным мы взяли а две последние цифры от номера телефона телефон всегда прилетает со стороны банка то есть мы его знаем мы эти данные дальше процессе узнаю номер телефона здорово берем две последние цифры как наиболее равномерно распределенные получаем 100 возможных значений как бы ключа группируем их в 4 шарда и получаем в общем-то прикольный вариант шарден га почему нет наступили на грабли мы о них помнили да но тут внезапно оказалось что со стороны api и от мобильного приложения номер телефона не прилетает тоже зачем он там нужен она за авторизовалась и дальше там сессионные talkin' какой то ходит и все переписывать backend переписывать api переписывать приложение общем не здорово совершенно нужно найти какое-то простое решение подумали посидели решили что мы будем на бэг-энде при авторизации клиента отдавать ему куку с номером шарда это кукла к нему прилипает во всех вызовах api приходит и дальше индексом мы разгуливаем это в нужный backend чем проблема решена еще один момент показалось что выборки те которые делает личный кабинет по статусу там не отправленных сообщений они требуют обращение ко всем шар дам потому что у нас данные теперь лежат в четырех местах и вот это вот похож 4 место пришлось ну тупо взять реализовать к счастью на производительность это особо не влияет личный кабинет но там нет никаких нагрузок и бонусом но так как мы придумали что у нас будет четыре шарда то соответственно все компоненты которые работают с этими шарды мы там smtp api они тоже должны укладываться в этих 4k они у нас укладываются здорово папуша да пап ушам у нас была 1000 на одном инстансе на 4 соответственно у нас получается 4000 это в общем очень плохо было у нас идея дамы они думали добавить worker of добавили мы worker of подросли она сказать что приложение общем достаточно было написано давно в эпоху когда компания была стартапам и создавался минимальный продукт то есть там каждый worker он в цикле вычитывает из какой-то очереди и шлет никаких там потоков ничего такого нет ну похоже на пост dress да только без connection pool а работает так же печально следующая идея была вместо добавления worker of разделить отдельно отправку сделать в пол в google и мы получили ту же самую картину что есть добавленными маркерами то есть ситуация какая мы добавляем процессы у нас растет на машине уэйд сечет ждут а производитель из не растет пытались это дело оптимизировать и тут вспомнили что как раз вот совсем недавно выкатили питон 3 5 асинхронность you которую все очень любят в not же с в общем это модно современное молодёжное и мы решили попробовать и оказалось что это реально круто на задачах которые по своей природе что-то ждут об отправка пуша это мы установили типичный connect отправили данные подождали ответа вы читали записали в базу задача такая сплошной ввод-вывод никаких мозгов вот этого вот эта вот асинхронность она отлично подходит но и получили мы примерно такой итоговый конфиг по результатам внутреннего тестирования у себя собрались темп тоже на виртуальных машинах чтобы определить скиллинг уже точные взяли в ажуре виртуала чик собрали на них все что мы будем показывать клиенту протестировали красота но это не все есть как бы на этом моменте мы конечно все взяли выходной и выспались но открывать шампанское был еще рано потому что но надо было это все показать еще у клиента и тут пришел такой вот нежданчик когда мы начали разворачиваться мы разворачиваем одну машину получаем на ней 4002 получаем суммарно 83 12 412 непонятно выключаем 12 в разных комбинациях включаем 12 ч делать поставили мониторинг на них на все эти машины оказалось что в момент когда мы включаем четвертую в работу на одной из первых трех проседает диск и они суммарно работают вот на эти четыре то есть они где то эффект и друг друга по вводу выводу и работать параллельно не могут что делать начинаем собирать доказательства убедительными до скриншоте мониторинг и астат и так далее отправлять это все инженером заказчика те пытаются это дело исправить такой традиционный подход был но в конечном итоге мы достигли наших заветных цифр к счастью и в завершение немножко выводов такой программисты почему-то любят оптимизировать код но на самом деле по моему мнению гораздо важнее правильно спланировать архитектуру то есть хороший архитектурой давно код они выживают а не масштабируются они развиваются и в нужный момент в этот код узкие места просто берете переписываете если же у вас супер быстрый код но архитектура ну не позволяет вам расти то в какой то момент вы просто этот супер быстрый код там на половина выкидываете и начинаете заново строить архитектуру это печально это намного дольше помните контролируете свой технический долг вы должны понимать где он где он у вас есть и что вы с ним будете делать если вдруг вы в него упретесь а вы в него упретесь рано или поздно безусловно чтобы знать свои пределы необходимо тестировать свое приложение те части которые мы тестировали с ними у нас был минимум проблем мы знали примерно сколько они могут им и в них нет не упирались те вещи которые мы не тестировали а ну просто прикинули что этого хватит по факту там оказалась наибольшей головная боль помните о том что масштабирование эта штука такая ведь всегда ступенчатая то есть вы можете вырасти там до каких каких-то показателей в рамках одного сервера и дальше упретесь вам нужно будет что-то разделяет этом вы выделили фронты уперлись в базу данных это тот процесс он всегда имеет какие-то свои пределы если вы о них знаете в результате тестирования или вдруг вы представляете это как-то математически это здорово потому что вот сейчас по результатам этого этой работы когда бизнес приходит и говорит скажите нам во что нам обойдется запустить систему там на 5 кпс да не вопрос вот такая эта конфигурация на 3 такая там на 1000 такая мы знаем что просить под конкретные запросы ну и кэп наверное да простые варианты всегда пробуйте вперед потому что если вы можете что-то сделать просто не усложняйте себе жизнь и сделайте это и идите дальше в одном из требований работодателя я как-то видел даже вот подобное условие для админа что если что-то можно сделать за час неправильное за неделю правильно то сделайте за час потому что может быть это никогда не понадобится больше ну и немножко позитива в завершение доклада highload может быть реально быстро мы не сложным но не всегда но даже если не всегда по крайней мере из этого может получиться хороший доклад спасибо за внимание вопросы спасибо за доклад такой вопрос а почему вы не решили использовать для очередей какое-то специализированные решением например ребят смотрите вообще изначально бизнес обоснование следующие а мы компания которая процессе 5 сообщений это у нас основной бизнес база данных это круто это acid это надежна в работе исида нет то есть как бы мы не хотели терять сообщение поэтому изначально мы полагались на базу как на вот это вот но понятное дело что для таких нагрузок база уже не может но мы на них как вы видите и не рассчитывали изначально ну в современном рынке есть вариант при котором он не теряют очереди при перезапуске ну да ладно это к вопросу разворачивали тестовый стенд а почему было просто и джинсы мне отдавать статический джейсон а кем индексом я об этом подумал когда готовил доклад что можно было вообще это сделать гораздо проще индексом отдать статический джейсон можно было там на лавочке что-то написать но хорошая мысля приходит знаете позже да вот и я вот тоже готовил слайды и подумала чужой вот так вот не сделали это сколько бы сэкономили себе вообще да согласен привет спасибо за доклад у меня вопрос он такой наверное находится на вершине идиотизма с push-уведомления my вам помог очень сильно python 3 5 со своими асинхронными штуками а был ли какой-нибудь план план б а может быть вы или еще что-нибудь если бы python бы все-таки не выручил но на тот момент можно было как бы от масштабироваться по ядрам да потому что процессы мы в ту конфигурацию перлись у нас была машина там с и кадрами мы в них уперлись но процесс отправки он масштабируются линейно вас было архитектурная особенность что мы не могли этих от прав щиков запускать больше чем ну скажем так вычитываю щенков из очереди то есть архитектурно у нас на тот момент вот этот push service он по нескольким машинам работать не мог в рамках одной машины он по ядрам рост линейно мы уперлись в тестовую машину и как бы предполагали что на virtual как у клиента тоже не будет да там семидесяти двух ядер вот она 72-я драхма бы наверное 15 коза процессе ли тогда на двух машинах по по семьдесят два ядра но это просто не здорово совсем и ну план б не было плана б нам повезло и такой еще вопрос как как как google как apple восприняли ваши с половиной тысяч в секунду а google и apple не восприняли нашей семьи винты в секунду потому что мы их слали себе вот на тот самый серый сервис который хорошо бы было сделать на чистом и джон exe но мы его сделали на engine.exe с пейтоном то есть мы подменили отправку и ну в dns до подменили и в итоге запросы летели дни в google и apple она наш сервис который отдавал валидный ответ что он сообщение принял то есть 15 тысяч это это были просто такие бизнес тревоги вблизи бизнес требовани которой нужно было показать на тестах реально такой нагрузки вообще ни у кого нет ну вот если быть реалистом то реальный транзакционный трафик там не знаю всей визы это примерно 20 тысяч сообщений в секунду это всей визы в мире вот поэтому понятно дело что даже банк из топ 1 такого трафика нет на всякий случай ну ладно это сила а как вы считаете но джесс мог бы стать вашим планом б в плане центральной отправки ну на другом проекте используем активному джесс вообще в другой компании в принципе примерно та же самая картина что есть три пятым питоном то есть там неплохо работает асинхронность но все равно если у вас вы в одно ядро не умещаюсь вам нужно запускать этих нот кучу и проблема решается точно не готов сравнить их по скорости кто быстрее юрий спасибо за доклад а можно все таки немножко поподробнее в чем же была проблема когда вы уперлись в 12 тысяч запросов хороший вопрос так как у нас никаких ручек вот облака заказчика не было да я были просто виртуальной машины то мы можем только по косвенным признакам судить о том что там происходит картина выглядела следующим образом мы начинаем пускать трафик на 4 машины у нас на 4 там на 2 например растет и way а производительность этой вот 2 машины падает и суммарно они процессе вот примерно столько же сколько 1 но мы как бы предположили что проблема где-то в том что они на один и тот же не знаю это может быть ssd cache на один попадают ли там нет ssd cache а да там куда то они попадают в одно место и по вводу выводу аффекте друг другу ну чё смогли определить то и зари портили да и как бы проблему это решали уже инженеры которые поддерживают облака"
}