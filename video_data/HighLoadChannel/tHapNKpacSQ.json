{
  "video_id": "tHapNKpacSQ",
  "channel": "HighLoadChannel",
  "title": "Как мы сделали PHP 7 в два раза быстрее PHP 5 / Дмитрий Стогов (Zend Technologies)",
  "views": 18460,
  "duration": 3121,
  "published": "2017-04-22T14:48:24-07:00",
  "text": "Добрый день. Я Дмитрий Стогов. Сегодня расскажу вам о том, как развивалась ветка 557, о том, какие технические решения способствовали особому успеху этой версии и о том, что можно будет отжидать от следующих 71 и 72. Последние 12 лет я работаю в компании Zen Technologies. Эта компания была основана израильскими программистами Энди Гудман и Зив Сураски. И именно они в тот момент были лидерами разработки PHP. Именно они во многом определили как сегодняшний вид языка, так и успех технологии в целом. Компания занимается как разработкой самого Open Source PHP, так и коммерческих решений на его основе. То есть и работать здесь приходилось, и писать расширение, и влезать практически во все подсистемы PHP, ну и даже заниматься коммерческими проектами, иногда же совсем не связанными с PHP. А наиболее интересными для меня всегда были вопросы, связанные с производительностью. Так получилось, что искать пути ускорения PHP я нашёл ещё до прихода в ZН, работая над своим собственным проектом, конкурирующим ЗНДУ. И именно работа над этим проектом позволила мне досконально разобраться в PHP и понять, что работа таким сторонним по отношению к мейнстриму проектам можно влиять только на отдельные аспекты исполнения скрипта. В то же время всё самое интересное и эффективное можно сделать только в самом ядре. Но это понимание плюсчения обстоятельств и привели меня в ZН. Ну, небольшой экскурс в историю PHP. На самом деле PHP - это всё-таки не язык программирования, а точнее, не совсем язык, не только язык. Это всё-таки инструмент для создания веб-сайтов. динамических веб-сайтов. И язык только одна из его основная его часть. Помимо неё у нас также имеется громадная библиотека функций, множество расширений для работы с другими сторонними библиотеками, например, для доступа к базам данных или парнемля, а также набор модулей для связи с различными веб-серверами. Первоначальный PHP был представлен более чем 20 лет назад датским программистом Расмусом Лердерфом. И на тот момент это был просто набор CJI скриптов, написанных на ПЛ. Ну, впоследствии он был существенно переработан на тот момент студентами теми самыми Goodзираске. И где-то к 2000 году мы получили прительно то, что мы привыкли видеть сегодня, то есть как с точки зрения языка, так внутренней архитектуры. И вот с тех пор вот с PHP4 у нас PHP развивается более-менее эволюционно. Основным таким моментом переломным был выход PHP5, когда полностью обновилась объектная модель. Именно она открыла эру PHP фреймвоков и поставила вопрос о производительности на новый уровень. И, собственно, предвид это, сразу же после выхода PHP5, PHP 5.0, мы в ZН начали задумываться об ускорении PHP и начали предводить как можно больше работы по над производительностью. И вот ветка версия 7.1, один, которая должна выйти в этом или в следующем месяце, будет уже на синтечестских тестах в 25 раз быстрее того, что у нас было 12 лет назад. Ну то, если посмотреть на изменение производительности в разных версиях, то можно заметить, что основные прорывы были сделаны версией 5.1, когда мы только начали работу над производительностью и всё же, что мы не брали, у нас всё получалось. Это было просто непаханное поле. И в версии 7.0 Ноли после трёхлетнего застоя, когда мы упёрлись в стену и просто никакие наши попытки усовершенствовать интерпретатор ни к чему хорошему не приводили. Но в конце концов, найдя куда копать, мы получили даже больше, чем ожидали. Так, на тестах мы получили более чем 2 с пократное ускорение по сравнению с предыдущей версией с 5-6. Но самое интересное, что то же самое 2 с пократное ускорение мы получили и на реальных приложениях, неизменных реальных приложениях. Это на самом деле феномен, потому что предыдущий фактор 2 мы нарабатывали в течение всей жизни пятёрки за 10 лет. Интересно также отметить, что вот громадный скачок, который был в 5.1 синтетических тестах, на реальных приложениях вообще не виден. Говорит о том, что при разных использованиях производительность PHP упирается в тормоза разные сраз связанные с разными подсистемами. Ну, а история PHP7 начинает вот именно с этого трёхлетнего застоя, начавшегося в двенадцатом году. Тогда, поняв, что мы не можем больше увеличивать производительность мелкими усовершенствования нашего интерпретатора, мы обратились в сторону GТ. Сначала мы генерировали очень простой код, по сути дела, просто последовательность вызовов для стандартных обработчиков, что наподобие шитого кода форта. Затем мы написали на собственный Runime Assembler, стали инлайнить какие-то отдельные обкоды, код для обкодов. Но в конце концов мы поняли, что такие низкого уровни оптимизации вообще никакого практического эффекта не дают даже на тестах. И тогда мы задумались о выводе типов, вот о высокоуровних фазах анализа, вывода типа типов для переменных. Ну вот реализовав этот вывод, мы сразу же получили двукратное ускорение на тестах. Ну, воодушевлённо этим попытались написать глобальные режителята. Ну, тут нас желание неудача, поскольку мы использовали достаточно высокоуровневое представление, и использовать его для распределения регистров было практически невозможно. Ну, чтобы не иметь проблем с низким уровнем, мы решили попробовать LLVM. И ещё через год у нас получилось так, что мы на тестах получали десятикратное ускорение, а на реальных приложениях вообще ничего. И кроме того, эти реальные приложения стали компилиться теперь минуты. То есть, если это первый реквестпрессо можно занимать там 2 минуты. То есть, конечно, это было просто неиспользуемо. Ну и переосмыслив причину нашей неудачи, мы решили ещё раз посмотреть, почему же, собственно, PHP тормозит. Значит, вот результат профайлинга, э, нескольких запросов к домашней странице Вордпресса. З можно видеть, что только менее 30% потрачены именно на интерпретацию нашего байткода. И при этом более 20% это надкладные расходы меморименеджера. Ещё 13% - это работа с хэш-таблицами, 5% работа с регулярными выражениями и так далее. Работая наджит, мы избавлялись только от части вот этих первых ээ 30%. А всё остальное мы у нас продолжалось так лежать мёртвым грузом. Мы практически везде были вынуждены использовать стандартные структуры данных PHP. И вот именно эти структуры данных влекли за собой накладные расходы, связанные с распределением и дераспределением памяти, референс каунтингом и так далее. Собственно, это понимание и привело нас к тому, что нам необходимо было заменить самые ключевые структуры данных PHP, то есть, по сути дела применить фундамент. И вот, собственно, с этого начался проект PHPNG. Во-первых, мы пообещали больше не использовать синтетические тесты для измерения производительности. Это, как правило, небольшие вычислительные программки, которые используют достаточно ограниченный сеet, то есть, которые помещаются полностью в кэш-процессора. А реальные приложения, наоборот, подвержены тормозам, связанные с посистемой памяти. И одно, это просто чтение из памяти может стоить там 100 инструкций вычислительных. Ну а проект PSPNG как раз и подразумевал оптимизацию этих структур данных для оптимизации обращения к памяти. И как менять эти структуры было, в принципе, уже понятно. В голове уже была хорошая картинка, но объём до зависимых изменений был просто огромен, потому что само ядро на PHP - это где-то 150.000 строк, и почти каждая третья нуждалась в изменении. Ну, а прибавьте к этому ещё порядка сотни расширений, которые входят в B distribution, десяток модулей для разных весерверов, вы поймёте, то есть грандиозность проекта. Поэтому, когда мы начитали, мы абсолютно не были уверены, что мы сможем довести это до чего-то хорошего и не знали, какие результаты мы получим. Поэтому начали мы проект в тайне и открыли его только тогда, когда у нас появились первые оптимистичные результаты. Это было в мае четырнадцатого года. На тот момент у нас было порядка тридцатипроцентное ускорение на Вордпрессе, и это уже казалось грандиозным таким событием. Пишпинчи сразу вызвал волной интереса и вскоре был принят в качестве ядра для будущей версии PHP PHP7. Это был уже другой проект с другим набором целей, где производительность была только одной из них. Ну, начнём с того, что сам номер версии сем - это так под вопросом 5 + 1 не = 7. Дело в том, что версия 6, которая разрабатывалась несколько лет назад, была полностью посвящена натинной поддержкой Юникода. Но очень неудачные решения, принятые на ранних этапах разработки, привели к такому усложнению кодовой базы, то есть как самого ядра, так и каждого расширения, что в конце концов просто всем это надоело, и мы решили отказаться, заморозить проект. А к этому времени уже было наработано много материалов, посвящённых PHP6. Были выступления на конференциях, написаны книги, опубликованы. Чтобы не усугублять путаницу, мы назвали PHP7. Ну, здесь нам повезло больше. PHP7 вышел год назад почти по плану. И вот сегодня уже на днях должен, не на днях, ну вот в ноябре-декабре должен выйти 71. Помимо производительности в семёрке у нас появились не некоторые нововведения давно востребованные. Это, например, возможность определять скалярные типы параметров и возвращаемых значения функций. Большинство ошибок фатальных были превращены в исключение, и, соответственно, теперь мы можем их ловить и обрабатывать. Появились зростосерты, анонимные классы, новые функции и так далее. Но речь сегодня не об этом, а о внутренних изменениях и, собственно, том пути, который прошёл симбно и куда этот путь нас может завести. И вот, собственно, всё это было небольшое вступление. Основной структурой данных PHP является Zel. То есть эта структура определяет, то есть является репрезентацией любого значения в PHP. Поскольку язык у нас динамически типизированный, здесь можно сразу выделить тип и значение, являющееся юнионом. То есть в этом юнионе может лежать либо целое число, либо вещественное, либо строка, либо массив, либо объект, любое значение PHP. Память, подказывающу такую структуру, выделялась отдельно на хипи. И здесь же у нас хранился счётчик ссылок на эту структуру. Таким образом, сама структура занимала 24 байта, плюс к этому накладные расходы меморименеджера, плюс ещё где-то указатель. Значит, а вот справа у нас картинка, какие структуры, собственно, создавались в памяти для простенького скрипта. Я, к сожалению, здесь не могу махать печём, чтобы показать. Наверху у нас строчечка из четырёх переменных. Соответственно, на стеке у нас выделась память под четыре указателя. И каждый этих указателей ссылается на значение этой переменной. А на хипе у нас два зивола распределены, поскольку у нас два значения и они шарятся между значениями переменных. И, соответственно, у каждого из этой переменной референс каounter равен двум. То есть не сложно понять, что для доступа к типу или скалярному значению нужно как минимум два чтения. То есть сначала прочитать значение указателя, а потом уже какое-то значение структуры. Если уже у нас какое-то нескалярное значение типа строки, то как минимум ещё на одно чтение больше. Значит, а в семёрке, везде, где мы до этого использовали указатели, вот как там было на стеке, мы стали использовать непосредственно зиволы, то есть имбедить их. Соответственно, мы ушли от референс каунтинга для скалярных звелов. Тип и значения у нас остались приблизительно без изменения практически. Но добавились ещё некоторые там флаги и заритерованные места, которые расскажу чуть позже. Собственно, вот слева у нас та же тотже та же картинка для 5P5, а справа та, как стала выглядеть для семёрки. То есть на стеке у нас лежат непосредственно сами зиволы для чтения типов искалярных значений достаточно всего одной машиной инструкции. И кроме того, все значения теперь сгруппированы в одной области памяти. А это значит, что, например, при работе с локальными переменной функции, печпишной функции, у нас практически наверняка не будет кэшмив и, соответственно, пенальти из-за этого. Но настоящая мощь включается при необходимости копирования. Вот сейчас у нас в скрипте наверху добавилось ещё одно присваивание. Я покажу несколько раз, переключусь тудасюда, чтобы вы видели, какой объём работ сделала пятёрка и семёрка. Значит, в пятёрке мы выделили из хипа новую память под новый л, инициализировали его интежером двойка, изменили значение указателя переменной B, а также уменьшили референс каounter того значения, на которое эта би ссылалось раньше. В семёрке же мы просто иницилизировали переменную прямо слону B прямо по месту. То есть это делается с помощью нескольких инструкций. То, что было у FPHP5, требовало, ну, наверное, сотни инструкций. Вот так ZЛ теперь выглядит у нас памяти. Это два шестичетырёхбитных слова, где первое это значение. Здесь может быть либо целое число, либо вещественное, либо указатель. Во втором слове у нас тип, который говорит, как интерпретировать значение флаги и зарезерированное место, которое всё равно добавилось бы при выравнивании, но оно у нас не пропадает. Оно используется разными подсистемами для сохранения косвенно связанных значений. Типы, ой, флаги - это просто набор битов, где каждый битик говорит о том, поддерживает ли мл тот или иной протокол. Например, если стоит из type, это значит, что при работе с данным диволом должен инкрементировать, декрементировать референс каунтеры. То есть, например, присваивании он должен увеличить, при выходе из области видимости уменьшать. Если референс каунтер достиг нуля, то, соответственно, уничтожить зависимую структуру. Из типов по сравнению с пятёркой у нас появился несколько новых. Появилось несколько новых. Это издеf, который является маркером неинициализированной переменной. На смену единому избу пришло пришли раздельные из false и true. Добавился отдельный тип для ссылок. Ну и ещё несколько магических типов. Типы от изн до изб являются скалярными, и они не требуют никакой дополнительной памяти. То есть для их копирования достаточно скопировать первое машинное шестидесятчерхбитное слов со значением и второ половину второго с типами и флагами. То есть, а с другими всё чуть-чуть сложнее. То есть все они представлены какой-то подчинённой структурой. И в зимле хранится просто ссылка на эту структуру. Значит, для каждого из типов эта структура своя собственная, но все они имеют в качестве в терминах объектно ориентированного программирования общего абстрактного предка или структуру zentrif counted. И она, собственно, определяет формат первого опять-таки шестичетырёхбитного слова, где у нас хранится счётчик ссылок и другая информация, необходимая для сборщика мусора. На самом деле всё это слово можно рассматривать просто как информация для сборщика мусора, а конкретные структуры просто добавляют какие-то свои поля вслед за этим первым словом. Так, например, для строк мы храним тут же вычисленное значение хэш-функции для данной строки, длину строки и, собственно, символы. То есть размер такой структуры у нас переменной зависит от длины строки. хэш-функция считается один раз ленивым образом, то есть по первому запросу и потом уже отдаётся. То есть, а в пятёрке у нас считалось каждый раз при каждой потребности. То есть, кроме того, у нас теперь строки стали референс каounми, каунтабми. И если в пятёрке мы зачастую копировали сами символы, то теперь нам достаточно просто увеличить счёсик ссылок на данную структуру. И также в пятёрке у нас же было здесь это немножко ещё улучшилось. У нас есть такое понятие, как неизменяемые или нтерны стринги. Они обычно существуют в одном экземпляре, но это не обязательно, но главное их черта в том, что они живут до конца запроса неизменными, а это значит, они могут вести себя как скалярные. Нам не зачем заботиться о чуке ссылок на них. И для их копирования нам достаточно скопировать вот только сам ZЛ, то есть с помощью четырёх инструкций. Массивы представлены встроенных H таблиц. Это мало чем отличается от PHP5. Ну, сама хоть таблица, правда, изменилась. Об этом расскажу чуть попозже. А про мовы я скажу то, что теперь это адаптивная структура, которая меняет своё внутреннее, немного меняет свою внутреннюю структуру и поведения в зависимости от хранимых данных. Так, если мы храним только элементы с числовыми, близкими числовыми ключами, то мы адресуемся к элементам непосредственно по индексу. То есть у нас по сути плоский массив, и мы адресуемся по индексу со скоростью, сравнимой со скоростью массиво. Ну, стоит нам в этот же самый массив добавить элемент со сторковым ключом, он превращается в настоящий хэш с разрешением коллизии. Вот, собственно, хэш-таблица или вот этот хэш, как он выглядел в PHP5. На самом деле это классическая реализация хэш-таблица с разрешением колизий с помощью линейных списков. Вот то, что наверху в правом уголке показано. То есть каждый элемент у нас представлен бакетом. Бакеты все связаны двухсвязанными списками для разрешения коллизий. Плюс они связаны ещё другим двухвязываным список списком для итерации, поскольку у нас массивы у нас упорядочные. Значения под каждый зивол выделяются отдельно в пакете. Мы храним только ссылку на него. И плюс ещё строки, сроковые ключи опять-таки могут выделяться отдельно. Ну и какое общее впечатление? То есть нам под каждую хэштаблицу нужно выделять очень много мелких блоков памяти. А чтобы потом что-то найти, нужно бегать по указателям. И каждый такой указатель может вызвать кэшмис и остановку там на 100 циклов процессора. То есть а вот то, что у нас получилось в семёрке. То есть сложно поверить, но вот логическая структура осталась без изменения. То есть изменилась только физическая структура. То есть теперь вот то, что вот справа, это вот хэст таблица. Память под неё под всё выделяется с помощью как ну с помощью одной операции. То есть это один блок, выделяемый из памяти. И вниз от базового указателя лежат, собственно, элементы, а вверх вот хэш-массив, который адресуется по хэш-функции для плоских или упакованных массивов. То есть, когда мы храним только элементы с индекс с числовыми индексами, у нас вот верхняя часть вообще не выделяется, и мы адресуемся ээ к бакетам непосредственно по их номеру. В обм же случае мы решимся через индекс в таблице наверху. Для обхода элементов мы просто перебираем их либо сверху вниз, либо снизу вверх, что современные процессоры делают наилучшим образом. Значения у нас встроены в бакеты, а вот зарезервированное вместо в них как раз используется для разрешения коллизий. То есть там хранится индекс другого бакета с тем же значением хэш-функции либо маркер конца списка. Память под строковые значения выделяется отдельно, но это всё те же самые вот стринг, которые я рассматривал чуть ранее. И, соответственно, при вставке в массив нам достаточно просто увеличить refence counter. Раньше нам приходилось копировать непосредственные символы. А при поиске мы теперь зачастую можем сравнивать не символы, а сами указатели настройки. Ну и точно так же, как у нас были неизменяемые стройки, теперь у нас появились неизменяемые массивы. Вот проник скрипт, который создаёт массив из миллиона элементов. Притом каждый элемент - это один и тот же массив с оединственным элементом hello. В PHP5 это на каждой итерации цикла создавался новый пустой массив. В него добавлялось hell и потом всё это добавлялось в результирующий массив. А в семёрке мы создаём на этапе компиляции один неизменяемый массив, который ведёт себя как скаляр, и он уже добавляется с помощью четырёх машинных конструкций в каждой из элементов массива. И это, как вы видите, ведёт более чем к десятикратному улучшению по потреблению памяти и почти десятикратному ускорению. Разумеется, ну, такие константные массивы там из 1.000 пиллионов в реальных прожениях не создаются, но практически везде так или иначе используются константные массивы. И на каждом из них вы получите небольшой новый игрыш. Объекты в PHP5 хранились в отдельном сторедже, и адресация к ним приходила происходила по хендлу. Не знаю, зачем это было сделано, но вот так было. То есть для адресации структуры нам приходилось как делать как минимум три чтения. Кроме того, все проперсия распределялись отдельно. И опять-таки нам требовалось ещё как минимум два чтения, чтобы прочитать значение каждой проперти. Ну, а в семёрке мы смогли всё-таки сделать прямую адресацию, соответственно, для чтения структуры Zent object нам достаточно одно одного машинного чтения, а проперти у нас, как и везде теперь встроенные, поэтому для их чтения опять-таки нужно всего ещё одно дополнительные чтения. Ну и также они теперь у нас сгруппированы вместе, что помогает data localлоality, то есть современным процессором не спотыкаться. Помимо предоплённых пропертей у нас здесь же также есть хранится ссылка на класс данного объекта. Некие хендлеры, это что-то типа виртуаль таблиц виртуальных методов аналог. Ну и также хэшта таблица для проперти, которые не были определены определены. То есть мы можем, в принципе, в PHP же добавить проперти, которая была не определена. И если для определённых проперти у нас достаточно несколько машинных инструкций, чтобы пристать их значение, то для неопределённых нам придётся лезть в хтаблицу, и это потребует, ну, там, десятков машинных инструкций. То есть это намногонамного дороже. Ну и, наконец, нам пришлось ввести отдельный тип для представления PHP референсов. Это абсолютно прозрачный тип. Он не виден PHP скриптам. То есть они видят другой зивол, который встроен в эту референс. Подразумевается, что на одну такую структуру у нас ссылается как минимум из двух мест. Ире reference counter здесь всегда больше единицы. А как только он падает до единицы, у нас референс превращается в обычные скалярные, то есть в обычное значение. То есть ZЛ, который встроен в референс, копируется в последнюю ссылающийся на него ZЛ, а сама структура удаляется. Понятно, что теперь работа с референсами кажется куда более сложной, чем с другими, но на самом деле вот это вот тот практически та стоимость, которую мы тратили на работу со всеми типами в PHP5. То есть, а, выделив вот эту более сложную более сложные алгоритмы в отдельный тип, мы тем самым ускорили работу со всеми другими и особенно со скалярными значениями. Я уже говорил, что единый тип избул был разбит на отдельно из фS из true. И сделано это было, то есть подсмотрена идея была в реализации low git, а сделана для ускорения одной из наиболее частых операций условный переход. Если в 5П5 нам требовалось прочитать тип, сравнить его, они були ли это, а потом прочитать значение и узнать true оно или fse и сделать приход на основании этого, то теперь нам достаточно просто проверить тип с true, то есть сравнить его с true. Если он равен true, то мы идём по true. Если он меньше true, то мы идём на false. А если он больше true, то мы идём так называемые slow puff, то есть медленный путь, и там проверяем, а что у нас, собственно, это за тип пришёл. То есть, если это integer, то мы должны проверить значение его с нулём. Флот опять-таки с нул и так далее. Ну вот, а следующая оптимизация подразумевает уже не только изменения в данных, но и в базовых алгоритмах. То есть так называе convention или соглашение о вызовах функции. Вот слева у нас небольшой скриптик, то есть функция и её вызов. Машины байткод вот этих функций, а справа стек. Сейчас я покажу, как это работало в PHP5. То есть первая инструкция SW должна была послать вот троечку в функцию F. Для этого она вынуждена была алоцировать новый зивол на хипе и записать на стек, ну, значение поинтера на эту структуру. Аналогично со второй, то есть. И теперь ээ upcд do call инициализировал callфame, резервировал места под локальные и временные переменные и передавал управление на вызываемую функцию. Здесь оператор рисиive был вынужден проверить первый аргумент, то есть он бы его мог бы ещё раз скопировать, но слава богу, здесь он уже просто увеличил счётчик ссылок на него. Аналогично со вторым. Теперь у нас, собственно, тело функции. Произошло сложение троечки плюс пятёрочки, получилась восьмёрочка. И теперь мы возвращаемся. То есть при возврате нам нужно освободить все переменные и аргументы, которые вышли из области видимости. То есть вот для каждой ссылки, которая у нас на стеке, мы должны для того зивола, на который она указывает, уменьшить счётчик ссылок. Если он достиг нуля, то уничтожить соответствующую структуру. Ну, тут две проблемы. Во-первых, даже такая простая операция, как посылка константа функцию требует распределения новой памяти. А во-вторых, мы копируем аргументы дважды. То есть вопрос, зачем? То есть в PHP7 мы это обе проблемы изправили. Ну, во-первых, так как и везде мы теперь храним не поинтеры на ZЛ, а сами зилы на стеке. Во-вторых, мы ввели новую инструкцию Initв call, которая теперь отвечает за выделение памяти под callфрейм. То есть именно она теперь инициализирует лфрейм, резервирует места под аргументы, временные переменные и так далее. То есть теперь копирует аргумент непосредственно в первый слот за колфреймом, вторая во второй. То есть здесь теперь самое интересное, то есть казалось бы, du call должна передать управление на первую инструкцию вызываемой функции. Ну, смотрите, у нас аргументы уже попали в те слоты, которые зарезервированы для переменных A и B, то есть для параметров. То есть и нам вот в этих инструкциях ресив не нужно ничего делать, поэтому мы можем просто пропустить. Поскольку мы посылали два параметра, мы пропускаем две инструкции. Если мы посылали три, пропустили бы три. Так что мы переходим непосредственно на тело функции, производим сложение и возвращаемся. При возврате нам нужно опять-таки почистить все локальные переменные. Но теперь нам дела делать только для двух слотов. А поскольку там у нас вообще скаляр, это нам и вообще ничего не требуется делать. Ну мой рассказ кончить упрощён. Он не учитывает функцию с переменным слом аргументов, не учитывает type, необходимость проверки та типов. Ну и кроме того должен сказать, что новая convention немножко поломала совместимость. Если, во-первых, в PHP есть такие функции, как F get arg f get arcs. Если раньше они возвращали оригинальное значение посланного параметра, то теперь они возвращают текущее значение соответствующее локальной переменной, потому что мы просто не храним оригинальное значение. Ну, собственно, также делают и отлачики C. Ну и, кроме того, нельзя теперь у нас объявлять параметры с помощью одного и того же имени. То есть это смысла небольшого не было, но вот код, как там доллар, доллар я видел. Ну и закончив с оптимизацией, собственно, структуры данных и базовых алгоритмов, мы ещё раз обратили на все тормозящие посистемы. Если вы помните, менеджер памяти у нас был один из самых тормозящих, он там занимал чуть ли не 20%. Конечно, после того, как мы избавились от множества а локации, он стал у нас чуть-чуть получше, но всё равно у нас продолжил тормозить. Потом уже не за счёт того, что он требовал много времени, за счёт того, что он спотыкался на кэше. А происходило это из-за того, что мы использовали классические алгоритмы догли, которые подразумевали поиск наиболее подходящих свободных участков памяти с помощью путешествия по ссылкам и деревьям. А опять-таки вот все эти путешествия ведут к промахам. А сегодня существуют куда более новые алгоритмы управления памятью, которые учитывают особенности современных процессоров. Это вот, например, Gлок, Пяти молок от Гугла. И вот, собственно, мы попытались использовать их непосредственно, но это у нас не получилось, поскольку нам нужно был специальный функционал, и мы написали что-то своё, скомбинировав идеи из старого и из нового. Ну, собственно, выиграли мы, то есть свели накладные расходы меory менеджера до 5%. Но я вам рассказал только о самых-самых главных изменениях. Их было, на самом деле, множество других. Некоторые очень простые, то есть где-то там требовало всего три строчки для того, чтобы включить дit в регулярных выражениях пёрловских. И это сразу всем помогло. То есть практически все приложения сразу ускорились там на 2-3%, а другие оптимизации затрагивают какие-то аспекты определённых функций. О них просто сейчас неинтересно рассказывать. Ну а вот, собственно, к чему мы пришли. Вклад различных подсистем на Wordпреess. Теперь уже в семёрке. Ну, во-первых, вклад виртуальной машины теперь увеличен практически до 50%. Memoryменеджер у нас уже меньше 5%. И это в основном не за счёт его оптимизации, а за счёт именно уменьшения количества вызовов. Если раньше он вызывался вот на данном тесте 130 млн раз, то сейчас менее десяти. Ну и кажется, что всё основное всё было сделано с помощью мемоory-менеджера. уменьшение количества структур, улучшение структур данных. Но на самом деле все абсолютно всемы были немножко усовершенствованы. Так интерпретатор у нас стал работать в два раза. Накладные расходы мемоory менеджера улучшились аж в 17 раз, уменьшились. Хэш-таблицы стали работать быстрее в четыре раза. И вот общая производительность на Вордпрессе выросла в 3 с2 раза. Ну, если вы помните, там на слайде в самом начале было только 2 с по раза. Дело в том, что там у нас реальная скорость в реквестах в секунду, а здесь у нас скорость, показанная профиларовщиком, и она у нас показывается в терминах CPU циклы, то есть циклы, когда процессор не простаивает, а когда он ждёт, например, ответа от базы данных, он простаивает. Это время здесь не учитывается. Это как раз составляет порядка 20%. Ну и WordPress, именно вот WordPress 36 был для нас одним из основных бенчмарков. Мы мониторили производительность на нём с первых дней работы. И в какой-то момент нам даже пришлось, когда из PHP7 выкинули экстмастикл, нам пришлось его даже специально поддерживать, чтобы продолжить вот этот вот график. Ну вот он показывает, собственно, основные прорывы были сделаны в момент работы на SP PNG, в первые месяцы работы до августа. К этому моменту было уже набрано 2/3 улучшение того, что есть было к выходу 7.0. Ну и потом ещё мы продолжали двигаться маленькими шажками и набрали ещё где-то трети. Разумеется, мы мерили производительность не только на Вордпрессе, но и на других популярных приложениях. Ну и практически везде мы показывали от полутора до двухкратного и даже большее ускорение. Э более того, по нашим по нашей версии мы везде обгонали и адекват актуальну на тот момент версию Hчvm. Но вот здесь сравнение со сторонним продуктом - это не всегда благодарное занятие, потому что сравнение может происходить на разных аппаратных платформах ээ с разными тонкими настройками. Ну и, собственно, субъективные факторы здесь влияют. Поэтому вот версия Hчvмm показывает немножко другие результаты. Здесь Hчvм везде пропорционально быстрее. Ну а пофиозом PHP7M стало, собственно, начало её использования действительно крупными сайтами. То есть пионерами здесь были китайские био, американские и наш баду. Ну, проверка холлова там вскрыла не неко нескоторые существенные проблемы. К сечасти они были очень быстро локализованы и пофикшены. А, ну вот, собственно, переход на 5P7 для AS, так для BDU позволил выключить практически половину сильверов вб веб-фермах. Собственно, вот и Баду оценил транзакцию в миллион баксов. И показательные графики, что на момент перехода суммарная загрузка процессоров уменьшилась в два раза, а потребление памяти аж в семь раз. На этом рассказ А70 можно было бы закончить, но на самом деле, то есть для меня 7:0 уже далёкое прошлое и 71 уже для меня прошлое. И, собственно, вот в версии 7.0, если мы пытались оптимизировать структуры данных, то 71 решали решили пойти немножко дальше. То есть мы вот накопили множество идей, ещё работая над git до 7.0. И теперь вот интерпретируем их, смотря на наши результаты без git. и на результат отведт, то есть и вообще применение джита для реальных приложений без ярко выраженных узких местляется стоит под большим вопросом. То есть в 71 мы решили пока что не использовать GТ, не продолжать никаких работ под ним, а опять-таки обратиться к нашему интерпретатору. Но если раньше мы пытались оптимизировать интерпретатор, то теперь мы попытались оптимизировать байткод, то есть используя вот тот вывод типов, который мы реализовали для нашего джита. И вот сейчас я вам покажу, как он работает на достаточно простой функции, которая суммирует числа отля до 100. То есть вот в такой код компилирует её стандартный phшpй компилятор. То есть он php компилятор достаточно тупой, то есть он однопроходный и сделан сделан это было специально, потому что первоначально у нас не было никаких кэшей, обход кэшей, то есть и компиляция могла происходить на каждом переквесте. Ну, а с приходом Апкэша мы стали уже оптимизировать, и какие-то методы оптимизации у нас уже давно встроены в ОБКШ. Это, как правило, то есть методы щелевой оптимизации, когда мы смотрим на код как бы через глазок, ищем знакомые паттерны и заменяем их на какие-то, то есть помощь, ну, каких-то правил. То есть эти методы продолжают использоваться и всем ноль. Так вот, например, здесь у нас есть две операции сложения и следующие за ним присваивание, и она может быть объедена в одну операцию Compund assignment, которая выполняет сложение непосредственно над результатом. Значит, другой пример постнкремент переменной, которая, в принципе, может теоретически вернуть какой-то результат. А этот результат может быть не скалярным возращением, он должен быть удалён. Для этого используется следующая за ним инструкция free, но если его изменить на преинкремент, то эта инструкция уже не потребуется. Наконец, в сзади у нас два оператора Reton. То есть первое - это прямое отражение оператора в исходном тексте, а второе добавилось просто по закрывающей скобке. То есть понятно, что этот код никогда не не будет достигнут, его можно тоже удалить. То есть таким образом у нас в цикле осталось всего три инструкции. И казалось бы, дальше уже и оптимизировать нечего. Но это как какой стороны смотреть? Смотрите, у нас есть инструкция преинкремент. Каждый раз, когда она выполняется, она должна проверить тип переменно, что какой тип ей пришёл. То есть проверить излонг ли это, потом сделать инкремент, проверить не при условии переполнения и только потом перейти на следующее. А ещё возможно будет какое-то исключение. То есть тоже нужно проверять, а не произошло ли исключение. Но на самом деле, вот если любой человек посмотрит на скрипт слева, то абсолютно понятно, что здесь у нас переменная А лежит в диапазоне от нуля до 100, и никакого переполнения быть не может, и проверок типов не нужно, и никакого исключения быть не может. Собственно, всем один мы попытались научить м компилятора это понимать. То есть для этого нам нужно построить ээ то есть вывести типы. И начинаем мы это с помощью построения так называемого Ctrl Flow графа, то есть или графа зависимости по управлению. Первоначально мы разбиваем наш код на так называемые basсик блоки. Это набор инструкции с одним входом и одним выходом. Поэтому мы режем код в тех местах, на которые у нас переходит происходит переход, то есть метки L0, L1. Мы также режем его после операторов условного, безусловного перехода и потом сочиняем дугами, которые показывают зависимости по управлению. Собственно, вот у нас и получился контрфлограф. Но его нам недостаточно, то есть нам нужна теперь зависимость по данным. Для этого мы используем так называемую static single assignment formта. Очень популярное представление в мире оптимизирующих компиляторов. Она подразумевает, что каждая переменная может быть присвоена только один раз. И вот мы для каждой переменной добавляем индекс или там номер реинкарнации. Значит, в тех местах, где мы записываем непосредственно переменную, мы сразу можем добавить индекс. А там, где мы используем, у нас ещё стоит вопросики, потому что мы не знаем, например, вот в инструкцию из Смола I может прийти как из блока L0, то есть с номером 4, так и из первого блока с номером два. Для решения этой проблемы SSI вводит псевдофункции фи, которые берут все возможные значения переменных, пришедших из разных мест, и создаёт новую реинкарнацию переменной. Ну и именно они потом используются. То есть вот у нас получилась saveформа. И опущу немножко. Собственно, теперь мы начинаем выводить типы. Начинаем это вот как как будто мы пытаемся выполнить этот код вот непосредственно по управлению. То есть в первом блоке у нас идёт присваивание переменным значений констант ноликов. Мы точно знаем, что эти переменные будут типа long. Дальше мыпадаем функцией φ. То есть видно, что у нас на вход приходит. Значение других переменных мы, конечно, не знаем. Делаем объединение. Считаем, что на выходе у нас лонг. Распространяем дальше. приходим к конкретным функциям, например, ad и prein. Значит, у нас приходит сложение двух лонгов. В результате у нас может получиться либо лонг, либо flу, если произойдёт переполнение. То есть эти значения попадают опять в функцию φ, происходит новое объединение. И так у нас происходит распространение, пока мы не придём кed, то есть пока всё не устаканится. То есть вот, собственно, мы получили возможное множество значений типа в каждой точке программы. То есть, ну, к сожалению, этого недостаточно. То есть хотелось бы ещё знать, ну, не то, что недостаточно, уже хорошо, конечно, но вот в данном случае у нас в инструкции prein, мы так и не узнали, что у нас i может быть только целым. У нас стоит либо long, либо double. Происходит это потому, что мы не пытались вывести возможные диапазоны. Собственно, тогда бы мы могли ответить на вопрос, произойдёт ли или не произойдёт переполнение. Ну, делается это аналогичным образом с помощью инференса рангов. То есть чуть-чуть более сложный процесс, но результат его сводится к тому, что вот для этой же инструкции мы получили фиксированный диапазон переменной I, и, соответственно, инкремент её не приведёт к переполнению. А скомбиниров эти два результата, мы можем точно сказать, что даблом она никогда стать не сможет. И вот, собственно, вот всё, что мы получили. А теперь для чего мы это городили? То есть происходят уже какие-то оптимизации. Вот мы смотрим на инструкцию AD. В общем виде, то есть старое значение суммы, которое пришло в эту к этой инструкции, могло быть, например, объектом. И тогда после сложения старое значение должно было быть удалено. Но в нашем случае мы точно знаем, что это либо long, либо double, то есть скалярное значение. Никакого уничтожения не потребуется. Мы можем заменить её на более простую инструкцию AD, которая в качестве аргумента использует сумму и в качестве значения использует переменную сумму. Для операции преинкремент мы точно знаем, что у нас всегда используется лонг и что приполнение произойти не может. Мы используем высоко специализированный обработчик для этой инструкции, который будет выполнять только необходимые действия без всяких проверок. Значит, теперь сравнение переменной вот в конце цикла. То есть мы опять-таки знаем значение переменной, что это будет только лонг. можем без проверок производить сразу производить проверку этого значения, сравнивать его с сотней. И кроме того, если раньше мы записывали результат проверки во временную переменную, а потом ещё раз проверяли на временную, то есть временную переменную на значение true false, теперь можем это сделать с помощью одной инструкции, то есть упростить. Ну и вот что у нас получилось в результате по сравнению с предыдущим скриптом. В цикле у нас остались опять-таки три инструкции, но теперь две из них высоко специализированные. То есть в результате код справа работает в три раза быстрее, чем код слева. Вот ещё раз хочу остановиться, что такое высоко специализированные обработчики. То есть любой обработчик обхода в PHP- это просто C-функция. Вот слева у нас стандартный обработчик, а справа наверху закон специализированный. Первый у нас проверяет тип операнда, делает действие, проверяет, не произошёл ли overflow, и потом проверяет, не произошёл ли exception, а правый просто в лоб склад прибавляет единицу и всё. То есть на самом деле он транслируется вот в четыре машинные инструкции и если бы мы пошли дальше и делали бы джит, то на самом деле вот только красная инструкция была бы нам нужна. Так что мы продолжаем повышать скорость PHP ветки 7 пока что без всяких джит. То есть и 71 будет ещё где-то процентов на 60 быстрее на характерных синтеческих тестах. Но на реальных приложениях выигрыш это практически не даёт. То есть там 1-2% на Вордпрессе. То есть практически ну не особо интересно. И сейчас вот где-то с августа, когда работа над 71 была заморожена, мы снова начали работать над товака. Сейчас мы используем для генерации кода DINASM, который разработан Майком Полом для Lagit. Ну и, собственно, чем он хорош? Он генерирует код очень быстро. то, что у нас версия для компилировалось минуты, сейчас у нас происходит за доли секунды, то есть где-то, ну, 1 и соответственно даже если он не ускоряет реальные приложения, он как минимум не мешает. То есть, и возможно он может быть применён только для компиляции каких-то определённых функций, которые будут выбираться либо самим программистам, либо каким-то ивристиками. ну, основанными на каунтерах, сколько функция раз была вызвана, сколько лопов в ней раз повторилось, то есть поиск каких-то ходспотов. Вот, собственно, то, что сейчас машинный код, который генерирует наш джит. То есть, как вы видите, многие инструкции скомпилированы очень очень-очень даже оптимально. То есть вот инкремент I скомпилирован в одну инструкцию. Инициализация переменных константам в две инструкции. Ну, там, где мы типы не вывели, там у нас приходится чуть-чуть больше повозиться. Ну и, собственно, вот в конце текущее место PHP в сравнении с другими подобными языками. То есть где вот мы сейчас находимся. Конечно, Молброт может быть не лучший тест, это вычислительный тест. То есть к реальному использованию PHP он мало подходит, но, к сожалению, не могу найти приложение, которое бы одинаково хорошо показывало и реальное применение PHP, и там других языков. На этом, собственно, всё. Прошу вопросы. Планируеть. Добрый день, спасибо за доклад. А можете, пожалуйста, вернуть слайд с новой хэш-таблицей, вот которая в PХП7. Слайд с новой хэш-таблицей. Можете чуть подробнее рассказать про то, как устроено итерирование с учётом вот порядка в массиве? Я немножко не осознал. Итерирование происходит просто перебором элементов сверху вниз. То есть от букет ноль, букет один, букет N. Ну а же а вставка тогда как быстро будет происходить нового элемента или онаставка у нас происходит обычно в конец масиво, если вы добавляете. Ну а если почему А если посередине, то у нас либо уже есть пред него место, то есть если у нас есть букет там с элементом, ну, с индексом один и с индексом три, то между ними стоит, соответственно, с номером два. Куда нам убежать от этого? Я думаю, вопрос, который волнует многих, планируется асинхронность ПХП. Значит, ну, асинхронность как таковая PHP пока что нету. То есть есть некоторые наработки, связанные вот с y from, которые по сути дела, ну, y from по сути дела то же самое, что, то есть он, ну, чуть-чуть по-другому оформлено. То есть на этом делается вот, может быть, вы знаете асинхронный сервер, веб-сервер, возможно, я не помню правильно название, но, собственно, он показывает очень очень интересные результаты. То есть 10.000 коннектов, потом этот веб-сервер описан на PHP и при отдаче, ну, там Hello World PHP, он обгоняет Enginix. Здорово. А вот про новые хэш-таблицы, да, про алоцирование. Вот UNIFT на PHP7, он быстрее работает, соответственно, или медленнее? Аншиф, насколько я понимаю, выбирает один элемент в начало, да, в начало, в начало. Ну, как минимум в PHP5 нам требовалось освободить элемент, то есть удалить из памяти один бакет. Сейчас этого не требуется. То есть у нас, ну, будет сзади один бакет лишний, ничего страшного. Очень хорошо должно быть быстрее. Нет. очень многие операции с массивом стали работать намного быстрее. И более того, например, если сейчас используете array field функцию или range, вы получаете упакованный массив, с которым будет, ну, если вы работаете, например, вызываете field, добавляете весь элемент там нулями, у вас получился, по сути дела, вот почти массив на C снтами, инициализированными нулями. То есть дальше обращение по индексу к любому элементу. Добрый день. Справа отхода тут. Спасибо за доклад. Очень понравилось. Скажите, пожалуйста, всем один была сделана оптимизация при компиляции PHP с выключенным офкэшем? Э не будет ли он вызывать задержек? Та оптимизация, которая сокращала сумму в массиве и так далее. Значит, все эти оптимизации делаются только сключённым апкэшем. То есть, и вообще весь оптимизатер - это часть апкэша. Спасибо. Ну, по крайней мере, на сегодняшний день. То есть дальше это возможно будет по-другому, потому что на самом деле, как вы видите, уже существенно ускоряются все CL скрипты, там бе PHP в три раза быстрее исполь с оптимизатором. То есть, соответственно, если мы встроим оптимизатор, ну, что у нас как называется-то? Упаковщик переспешный. Композер. Композер будет работать самое, ну, раза в два быстрее, наверняка. Здравствуйте. Спасибо большое. Я тут, я тут. Спасибо большое за доклад. Интересует такой вопрос: а планируется в ПХП добавить слабые ссылки на самого языка? Нет, нет, не планируется, потому что, ну, как-то изначально в языке их не было. И нет в них нужды. То есть ввели сборщик мусора, который уже давно достаточно давно, по-моему, в 53 или в 5:4, который позволяет избавляться от циклических ссылок повесших. Угу. Работает он достаточно эффективно. Как раз вот как раз на композере была проблема, что он замедлял там чуть ли не в 10 раз. Угу, понятно. Ну хорошо, спасибо большое за ответ. Это будет уже другой язык. А подскажите, пожалуйста, а перспективный перспективе явное указание типов аргументов может дать какой-то прирост по профиту? Да, разумеется, уже сейчас, когда у нас идёт вывод типов, то есть эта информация используется. Если мы на входе функции знаем типы переменных локальных, мы можем использовать его для генерации более хорошего кода. То есть, но, к сожалению, в реальных приложениях очень мало мест, где это реально работает. То есть существуют какие-то библиотеки криптографические написаны на PHP. И в них вот подобная оптимизация, вот, о которых я рассказывал, дают там где-то десяти десятипроцентное ускорение. Угу. То есть, в принципе, уже уже неплохо. Уже сейчас работает, да? Да. Всем один. Ну, ещё есть параллельные работы, которые производится Никита Попов, то есть, и его часть ещё не вошла в 71, то есть она уже будет, наверное, в 7:2. Возможно, будет 72. Ясно. Спасибо. Ещё раз здравствуйте. Скажите, пожалуйста, сейчас есть такая штука, как компостер, и такая штука, как пел, и тот, и другой установщик. Компостер это ПХП расширений, пекол ПХП модули, пожалуй, не планируется какое-то объединение этих компонентов? М, я ничего не отвечу на этот вопрос. Как бы я работаю быстно над ядром, а на не над инфраструктурой. Спасибо. Возможно, это можно поблагодарить нашего спикера Ja."
}