{
  "video_id": "Tl4xlA90tcU",
  "channel": "HighLoadChannel",
  "title": "Ищем товары по фото / Иван Красников (searchbooster io)",
  "views": 608,
  "duration": 2461,
  "published": "2024-04-17T01:10:25-07:00",
  "text": "Ну что ж немножко разогрелись И теперь я приглашаю на сцену следующего спикера Иван красников Search Booster прошу Иван встречаем аплодисментами Всем привет Я очень рад что вы свою все сюда пришли большое вам спасибо мой доклад называется ищем по фото и я бы хотел поблагодарить очень предыдущего докладчика потому что чем вообще поиска такая вижу большая интересная публика уже чуть разогрета и я технический директор компании Бустер мы как раз вот представители тех компаний которые делают поиск за вас и что-то типа вместо ластик ксюрча но мой доклад не про это то есть мы более сконцентрируюсь на одной из свечей и расскажу как можно самостоятельно сделать поиск по фото и затрону как технически какие-то подробности так и больше что-то алгоритмическое то есть как это вообще работает на таком математическом ритмическом уровне а поиск по фото с точки зрения пользователя может выглядеть примерно вот так то есть есть некий интерфейс куда пользователь загружает фотографию и соответственно поисковый движок находит какие-то визуально похожие товары также непосредственно может и не быть какого-то меню поиска то есть здесь например модуль похожие товары это вообще скриншот с Wildberries и соответственно он помогает пользователям отбирать какие-то похожие кроссовки Ну или такие же товары другого селлера То есть можно тоже использовать визуальный поиск не только для поиска но и для товарных подборок можно искать не только товары примерно теми же способами можно искать людей похожих людей То есть Вам нравится какой-то человек или вы сами себе можете найти каких-то похожих людей себе также принципе эта тема натягивается на что-то другое То есть на какой-то образный поиск то есть здесь есть два стихотворения мне не оба не очень нравится но это как иллюстрация То есть в принципе оба можно найти по запросу что-то про любовь соответственно забыл еще сказать можно подобным образом работает даже поиск по звуку по песням по музыке то есть целом какой-то такой не текстовый поезд достаточно широкий и в целом это все решает примерно похожими вещами похожими алгоритмами а давайте вот начнем с mbate с понятием бейдинге то есть что же это такое и представим что у нас есть некая табличка в базе данных такая классическая у нас там проект мы продаем сумки картины и мы можем мы имеем какой-то позыгрыш допустим базы данных и мы можем отправлять к ней запросы чтобы найти среднюю цену на товары где есть информация про енота очень часто у нас помимо название товара есть еще фотография базе данных и вот было бы круто научиться делать какой-то Вот такой запрос Давайте посчитаем среднюю цену всех наших товаров Где фото Вот примерно такое и какой-нибудь енотик и Вот соответственно сложность Как засунуть вот этого енотика в SQL запрос Для этого нам нужно преобразовать фото в числа и не просто числа То есть можно просто JPEG закодировать виде пикселей А в некий какой-то образ то есть числа должны характеризовать что есть енот и там не должно быть какое-то личная информация чтобы нас поиск вообще отрабатывал а человечество Достаточно давно занимается всякими интересными математическими вещами и вот для решения вот этих вот поиск по фото и подобных вещей если вот какие-то разбивать какие-то исторические этапы то есть такой большой прорыв 30-е годы линейный дискриминантный анализ и метод главных компонентов подробно не буду останавливаться Ну про метод главных компонентов представим что у нас есть какой-то многомерное пространство точек И это какие-то наши образы то есть там еноты бегемоты Ну вот как-то это все держится в каком-то сложном сложном многомерном пространстве и метод главных компонентов помогает нам упростить это пространство отбросить какую-то ненужную информацию для нас и сократить размерность пространства таким образом чтобы тем не менее разница между объектами сохранилась чтобы мы могли выделить какие-то сущности наблюдать их отдельно друг от друга какие-то группы а 90-е много что нам всем принесли в том числе такую вещь как МН Ist dataset здесь американское агентство стандартизация Как так он называется оно оцифровала данные переписи населения американской которые у них там ну рукописно люди вот там по всем соединенным штатам заполняет какие-то анкеты у кого сколько денег сколько детей и соответственно они приготовили датасеты из этих данных то есть видит чисел Кто как нормализовали это по размеру чтобы эти числа были одинакового размера разметили людьми и с этим дата сетом ученые математики программисты стали на нем соревноваться Кто лучше предскажет учёному дают фотографию числа ученые загружают в компьютер в программу свою и соответственно прогнозирует но говорит какая-то число и кто больше угадал тот и молодец это все очень сильно подсте действительно развитие и вот если смотреть показатель ошибки по среди тех кто суд этим работает то там вот Идут Идут прям одинаково одинаково одинаково потом кто-то совершает резкий прорыв и за ним уже остальные через какое-то время подтягивается потом опять еще один еще один прорыв и Вот соответственно это достаточно сильно подстегнуло развитие распознавания образа подобным образом есть датасеты Imagine net это миллионы изображений размеченные классами что изображено на том или ином изображении то есть енот где бегемот где корабль где судно где хаски и все такое И точно также на этом дата свете стали люди соревноваться то что лучше угадает и вот тут как раз проявляются некие Появляется такой глубокое обучение и архитектуры которые стали хорошо перформить На вот этом остановимся на трех вот вгг Google Net и в целом это уже что-то похожее что нам нужно для того чтобы компьютер научить понимать что есть енот что есть бегемот вот вгг получает в себя картинку 224 224 на 3 это размерность по цвету и внутри всякие разные интересные преобразования и на выходе он дает такой Вектор из чисел где вероятность того что этот эта картинка относится к тому или иному классу тут можно провести некую налоги представим что вы можете дома такой эксперимент провести взять какого-то человека посадить его на стул присоединить электроды к его голове и показывать им различные картинки и замерять соответственно показатели вот этих вот электродов таких достаточно много уже стартапов сейчас и в целом даже уже там научились действительно понимать что человек видит то есть показываем самолетики у человека там определенные участки мозга реагирует показывает на вертолетики там чуть-чуть другие но рядышком и соответственно здесь нейронные сети происходит примерно то же самое то есть мы можем вживить электроды как бы эту нейронную сеть но это намного проще чем с человеком сделать и мы можем считывать показания можно взять показатель с последнего слоя где уже Есть конкретные результаты можно взять допустим предпоследний слой где есть некий образ который вот внутри нейросети помогает ей как бы видеть и понимать что это вообще на ней изображено соответственно вот если мы будем считать им бейдингом как раз некое числовое представление какого-то образа объекта там фотографии и мы можем рассчитывать их загружая фотографию нейронную сеть и беря показатели вот допустим предпоследний слой там резнета или вгг и благодаря этому наконец-то наш робот научился видеть и он может подружиться с этим енотом и соответственно как-то Взаимно существовать А мы можем в нашу табличку исходную загрузить вот эти числа которые мы получили и вот у нас есть некий Вектор который это по сути вот вектор преобразована вот эта фотография то есть сумка там и прочее хорошо у нас есть векторы и мы соответственно понимаем мы можем проиндексировать нашу базу данных Возле каждого товара положить рядом его Вектор но как понять что вот эти товары более похожи чем вот эти два например и нам нужно понять векторного расстояния это самом деле школьная некая программа То есть если представить Вектор как некое пространство точек и соответственно здесь где-то у нас енот здесь где-то бегемота здесь у нас самолет и вот Чем дальше в этом пространстве объекты находятся тем меньше Они похожи друг на друга и мы можем соответственно есть математические методы достаточно простые Как считать расстояние в таком пространстве Все мы живем в трехмерном пространстве там проще всего есть вклидово косинусное расстояние Окей Мы уже научились читать расстояние то есть мы можем понять что вот эти там сумки похожи Вот эти сумки не похожи но тут всплывает такая проблема что вот для анализа в Imagine найти чтобы понять где енот где Мег мод где самолет цвет не так уж важен и нейронная сеть теряет по ходу своих преобразований практически всю информацию про цвет товара а для пользователей все-таки цвет достаточно актуально интересная вещь и хотелось бы уметь ранжировать также таким образом чтобы не только похожие по форме по очертанию товары были в начале но и похожие по цвету мы можем оперировать пространство RGB все знакомы с концепцией RGB То есть это каждый цвет мы можем задать тремя числами сколько в нем красного Сколько зеленого и сколько синего и Соответственно в этом пространстве мы можем точно также считать расстояние то есть если считать что два два пикселя Ну там похожих цветов они будут где-то рядом в этом кубике находиться и мы можем вот получить Вот это RGB числа и добавить их к нашему вектору который вернула нейронная сеть учить Ну если она плохо учитывает цвета и далее мы все точно также справедливому точно также можем считать расстояние мы можем нормировать вот этот цветовое представление числового представления цвета чтобы изменять вес его в рамках общего расстояния то есть чтобы насколько Нам действительно важен цвет может быть и не очень важно может быть критичен мы соответственно можем нормировать вот эти RGB числа в этом векторе для того чтобы задавать важность проблема еще чуть-чуть сложнее то есть мы вот видим пример допустим фотографии и что у нас есть у нас есть фон который мешает то есть нужно как-то понять где у нас вообще есть товар а где просто какой-то окружение и также товары бывают несколько состоящие из нескольких цветов тоже проблема вот для удаления фона есть опенсорсные всякие решения не Open Source подробно не буду становиться в рамках доклада то есть там нейронные сети которые могут решать задачу удаления фона А с проблемой нескольких наличие нескольких цветов у товара можно решить ее несколькими способами То есть можно решить методом забивания то есть мы можем просто игнорировать эту проблему не так уж много цветов товаров многоцветные и в целом не так уж это и плохо что мы там только один главный учитываем но можно немножко заморочиться и начать учитывать несколько цветов то есть допустим мы можем считать что у каждого товара есть основной и второстепенный цвет и мы можем соответственно в нашу вот эту допустим Вектор добавлять несколько чисел как также основной второстепенное и нормировать их важность окей Все мы понимаем что как бы даже между разными людьми восприятие цвета отличается То есть если вы здесь видите 69 значит у вас нет проблем со зрением и все отлично ну либо там 64 или 62 тут разные варианты могут быть точно так же как бы и у людей люди все живые и пространство цветов как они воспринимают цвета в реальном мире оно отличается от RGB и для большинства людей разницы Небольшая разница в синем цвете она будет достаточно сильно заметна и в то же время если есть там желтый там чуть-чуть другой желтый человеку сложнее увидеть разницу в этом и для решения этой проблемы были всякие исследования то есть брали людей точно так же показывали смотрели Кто как что по-разному видит и придумали вот такое допустим другое пространство цветов не RGB а допустим CE лапку Color Space И в нем там гораздо больше точек характеризующих синий цвет и гораздо меньше характеризующих желтый и расстояние в этом пространстве считается с учетом вот этого всего и для Мы тоже можем перейти на использование Lab Color Space для того чтобы более качественно находить разницу в цветах Идем дальше нужно как-то делать какую-то инфраструктуру и как-то масштабироваться и нам нужно где-то считать вот эти нашим бейдинге А имейдинге хорошо считать Ну тоже по-разному можно запилить свой микросервис с нейронками можно использовать какие-то готовые сервисы уже в принципе сейчас есть тоже выпенсорсе например вот это Джина I клип Service у них есть как свое Облако которое можно пользоваться так и можно локально их развернуть слать им картинку и на выходе получать имейдинге там еще много всяких прикольных плюшек есть они могут тональность текста определять и такие достаточно интересная штука ее можно внедрить но мы сделали использовали свой потому что просто не знали про эту штуку но и достаточно Давно это было Может ее не было на тот момент и получается то есть что у нас есть база данных в ней есть множество фотографий посчитанные вектором и в целом можем взять две картинки посчитать там делать питоновский скрипт который будет находить разницу между вот этими векторами и находить наиболее похожий товар Но для того чтобы это работало в Production нам нужна какая-то база данных которая может искать по векторам и которая там быстро работает и короче не хочется на коленках все это делать Вот мы выделили три варианта с которыми можно работать то есть у позыгрыша есть модуль под же Вектор который позволяет как раз считать эти векторы на расстоянии и можно прямо в SQL делать запрос Я хочу найти наиболее похожий на вот этот вот вектор и будет находиться товары можно использовать Search с модулем кнн и вот как раз разница то есть власти кёрчи это фича есть она в платно в дорогом серче она есть по умолчанию модуля достаточно легко устанавливаемого И opensearch умеет все это делать и также можно использовать фаис это вот фейсбучно библиотека То есть это именно библиотека это не готовый сервис и если вы берете фо из вам нужно самостоятельно писать отдельное приложение которое будет со всем этим взаимодействовать но это не так уж и сложно то есть Можем Ну пример программы использующий фаис то есть мы задаем размерность для примера на 64 генерируем тысячу случайных векторов и есть у нас 5 каких-то запросов для которых мы хотим найти похожие товары мы вначале нормализуем данные нормализуем как данные из Непосредственно так то почему мы будем искать создаем индекс вот здесь индекс Flat L2 называется чуть дальше подробнее расскажу про индексы добавляем все эти данные в базу данных фаиз в нашу как бы там память или там память диск гибридно и за непосредственно поиск вот в данном случае мы использовали использовали Flat Index и он достаточно так в лоб работает то есть его еще можно назвать брутфорс то есть для того чтобы найти похожие фотографии он просто перебирает все варианты То есть если у нас эти 1000 векторов он будет делать 1000 сравнений потом отсортирует их и выдаст самые похожие в чем плюс это стопроцентная точность то есть мы можем гарантированно быть уверены что действительно наиболее похожий но минус в том что если наш дата сет будет расти у нас соответственно будет значительно расти и время вот этого поиска всех этих операций То есть если у нас миллион изображений то есть на каждый поиск мы будем делать миллион сравнений это неэффективно а и Вот соответственно фаисе есть всякие прикольные штуки и другие типы индексов которые позволяют нам сократить количество вот этих сравнений допустим например инвертированный индекс в нем мы обучаем такую штуку которая называется квантизатор и на вход для примера подаем У нас есть четыре Вектора из двух разрядов И мы этот квантизатор учим как бы разбивать вот эти исходные наши векторы на группы и мы обучаем этот монетизаторы Под каждый наш существуют которые у нас есть Ну то есть допустим он закидываем закидываем их фотография такая Окей это что-то животное здесь машины здесь дама скорее всего Но он не понимает что есть животные машины дома Он просто учится кидать их по различным Куча и на выходе Допустим мы получили 10 куч И когда нам нужно делать поиск Мы точно также показываем эту монетизатор тут человек пришел что-то такое хочешь найти он говорит А это животное иди в отдел с животными и соответственно поиск тоже идет уже ищет не по всей нашей выборке А уже потому что скорее всего похоже на наш объект то есть таким образом сокращается количество сравнения и увеличится скорость работы минус в том что он может и не угадать И мы никогда не найдем действительно что это было максимально похожее объект Но ради скорости этим можно пренебречь и вот этот инвертированный индекс он также может стать неким составным элементом других более сложных индексов то есть начале мы там разбили на кучке потом уже в каждой кучке каким-то другим алгоритм Можно еще раз на кучке разбить уже ну на более детальные так вот он работает есть Local sensitiveations это похоже штука В целом то есть мы подаем ему вот этот наш вектор и это некая сложная функция то есть на которая возвращает номер ведра в котором лежат похожие объекты подобным образом работает словари там в питоне например в других тоже языках и примерно те же самые плюсы и минусы как у предыдущего варианта здесь Он вот это Хеш функция она одна как бы для всех то сегодня обязательно обучать на каждом сете есть еще более сложные такие интересные индексы например иерархикал navigable Small World Я пытался перевести это через Google Translate сказал Gear иерархический судоходный Маленький мир а чат gpt сказал навигируемый вместо navigables то есть в общем это иерархический навигируемый слэш судоходный Маленький мир и он работает с помощью графов То есть у нас Мы берем наши вот эти исходные вот эти все нашу базу данных и из нее выделяем Ну вот эти наши берем наши вектора и располагаем их в неком таком пространстве и располагаем связи между ними чем длиньше вот эта связь длиннее тем менее похоже эти объекты между собой и чем короче Тем более они похожи и есть определенная метода Как рассчитать Ну то есть нам не нужно все со всеми сравнивать как сократить число ветвей здесь чтобы были только необходимые нужные нам и когда на вход пользователь подает какое-то Вектор Мы у нас есть n3point с которым мы начинаем и мы начинаем сравнивать где наиболее похожее по какой из вот этих вот путей нам нужно пойти чтобы здесь скорее всего лежат наиболее похожие объекты и вот здесь мы пошли там направо потом пошли вниз потом пошли вверх и когда Мы оказались локально минимумами То есть когда у нас нету дальше ветвей которые ведут на что-то ещё более похожее не останавливаемся считаем что вот это есть наш наиболее похожий объект это вот был navigames More World Есть еще чуть более такая на следующий уровень переходим есть иерархически navigable Small World то есть мы создаем У нас есть слои и это похоже на Google Яндекс карты то есть допустим нам нужно найти на карте место где вот мы сейчас все находимся мы вначале находим Евразию потом увеличиваем масштаб карты спускаемся дальше находим санкт-петербург потом ещё увеличиваем там находим локацию местную и вот подобным образом работает иерархика navigable то есть мы в какой-то момент проваливаемся на Нижний уровень Потом проваливаемся еще на Нижний уровень и вот уже непосредственно похоже объекты Мы берем с последнего уровня Это очень хорошо и быстро работают вот эти файсы и для каких-то сложных задач обычно используется комбинация То есть когда вам Ну то есть можно взять эшн с ви в начале взять инвертированный индекс То есть можно из таких вот собрать Вот именно под если у вас миллиард картинок или там нужно там в Face ID какой-то сделать сложный и быстро все сказать похожих людей то возможно Вам нужен какой-то некий кастомный поиск на основе файса и есть интересная книжка где вот это все более подробно рассказывается там есть qr-код можно посылки перейти и там прям увлекательное чтиво как со всеми этими индексами Все работает все реализуется а что же вышло мы уже существующие такой там три с половиной года у нас какое-то свое какое-никакое Legacy есть и соответственно Когда мы это реализовывали мы учитывали то что уже есть в нашей системе чтобы ее сильно не переусложнять и не делать какую-то еще одну систему то есть поиск по товарам где-то там сбоку еще пояс по фото достаточно сложно было делать потом их как-то мирить между собой и у нас получилось вот такая примерно архитектура То есть у нас есть продавец у него есть разные товары он Эти товары создает фид потому что мы как бы внешний сервис у нас нет своей BD с товарами мы от клиентов получаем товарный хит на Лора вылечить хищные воркер берет этот файл подгружает отделяет из него картинки и в Москве или кладет это такая своеобразная очередь где у каждой картинки есть там или посчитано или не посчитаны далее Тоже ларавелины worker смотрят каких картинок не посчитаны им ботинки для их расчета обращается к питоновскому сервису на фастафе это такой асинхронный процесс То есть у нас есть время какая-то очередь не индексированных картинок и тихий спокойный аравельский воркер который в купе с питоновским поставьте сервисом которые осуществляют взаимодействие и рассчитывает ее и далее вот этот первый worker который загрузки товарного фида занимается он создает два индекса То есть он создает товарный индекс где непосредственно все что было в принципе в предыдущем докладе рассказывалось про поиск обычный пользователь интернет-магазина и рядом Он создает соответственно картиночный индекс где уже непосредственно картинки далее Когда нам нужно что-то искать и пользователь вы это уже не владелец интернет-магазина это пользователь ша или покупательница она загружает фото товара который непосредственно ищет у нас там микросервис на гошке который быстро хорошо работают что нужно там много запросов обрабатывать Гошка либо идет к себе в память и берет ответ из США но тут момент что тебе картинки которые пользователи загружают скорее всего это практически всегда будет кэш Мисс Ну просто там фиг знает что там люди загрузили плюс если мы даем возможность еще рамку построить Ну Какой объект на фото найти то вероятность того что мы уже найдем это в кэше Очень низкая но если мы используем поиск по фото для допустим для модуля похожих товаров похожие по фото то там в целом практически очень часто будут те же самые запросы Потому что есть iPhone 12 Мы хотим найти миллион Андроидов которые похожий на iPhone 12 и это в целом достаточно статичная информация и вот здесь Конечно уже помогает то есть чтобы нам каждый раз не нагружать ни расчётом бэндингов ни у панчёрдж и соответственно всего Чаппи может практически в большинстве запросов он вернёт всё из кша своего который прямо в память у него висит и если кэшмис он пойдет в питоновский фастап и сервис рассчитает им бэндинги их подсунет в такой Запрос к эластик сорчу слышал пэнсёрчу и непосредственно наш пользователь счастливый получит информацию о найдёт похоже ему товары вот здесь еще соответственно часто Нам нужно достаточно просто картиночного поиска Но иногда это когда человек нашёл что-то по фото было бы прикольно там отсортировать ещё по цене или ограничить поезд какой-то категории и вот как раз поседность тоже Ну в принципе так как у нас общий этот opensearch потому в целом можем реализовать там и фассетность то есть вначале мы находим там допустим тысячу похожих визуально товаров и потом идём уже в поисковый движок и говорим вот он у нас 1.000 товаров отсортируй пожалуйста их по цене по релевантности по наличию и всему такому что там по вибрировал где сервера с видеокартами У нас вот такой возник вопрос имбединги хорошо считать на видеокартах это быстрее работает И надо где-то их взять у нас их не было и мы провели небольшое исследование оно справедливо только для нас ну и может быть для кого-то возможно для кого-то из вас но она не претендует на какой-то абсолютно истину ни в коем случае и выбор серверов архитектуры такой всегда сложный вопрос к нему нужно ответственно подходить средство у нас были несколько вариантов есть вариант взять в популярном российском облачном сервисе который дает облачные сервера и там вот есть можно взять теслу T4 и она стоила бы нам 52 тысячи рублей ежемесячно и давал Вот примерно такую производительность второй кандидат был тоже популярный российский центр который дает выделенные сервера в аренду и там чуть мы посмотрели там GPU A2000 дает похожие FP 30 32-битном смирении и там тоже какой-то дополнительное железо нам есть память оперативка и это вот стоит 20 тысяч ежемесячно и есть еще такой более Хардкорный вариант А что если взять свой сервачок на него засунуть видеокарту допустим rtx 38s и это куда-то в дата-центр на colocation поставить по производительности все Ну во всяком случае в числах сильно лучше железо в целом получается лучше но и стоит это 128 тысяч на момент оформления презентации сейчас цены каждый день меняется и например пять тысяч ежемесячно за размещение своего тавера большого дата-центре посчитали исследование немножко углубились мы посчитали что свой сервак амортизируется на 20 процентов ежегодно Что необходимо его обслуживать менять жесткие диски и заложили некую дополнительные траты на него но все равно получилось что примерно такой график что довольно сильно дешевле нам обходится свой вариант со своими серверами и мы к нему в целом мы пришли в масштабах видеокарт но вот если посмотреть на как-то подытожить вот это вот наша мини исследование есть вариант с облачными или арендованными серверами там Все круто Все Прикольно можно быстро разворачивать если вам не нужно каждый день считать имейдинге Вы можете на сутки арендовать все посчитать там выключить ничего не платить не нужно структуру инфраструктуру вкладываться но минусы Это цена То есть если вам нужно постоянно каждый день что-то считать то это достаточно дорого обходится второй вариант это если разместить свой товар дата-центре он более дешевый но нужно купить сервера заранее вложиться на инфраструктуру если что-то упало это уже не больше сотрудников дата-центра это ваша боль То есть Вам нужно или самим туда ехать либо заранее договариваться и всяких центров есть услуга можно там жесткие диски положить в ящичек сказать если что вот мы будем звонить вы приходите их меняете они на почасовке это берут в целом приезжайте каждый раз не обязательно но все равно некий напряг дополнительная боль вот здесь на картинке Кстати это если не ошибаюсь хеттснер У них до сих пор вроде есть такие центры с товарами и они очень дешево народу поставляют и вариант еще более такой теплый ламповый интересный это если свой сервак купить поставить его в офисе масса плюсов То есть можно просто там терабай данных туда выгрузить там физически просто воткнув туда терабайт на жесткий диск легко починить легко сломать даже там платить за ничего не надо если у Вас уже есть интернет но минусы что это нестабильно но например для тестового для девелоперского окружения для стейджинга тоже вполне справедливый вариант и можно как-то использовать если подытожить если в зале есть математики люди которые придумывают алгоритмы большое вам спасибо за ваш труд потому что вы двигаете человечество вперед Спасибо поиск по картинкам это круто И не так уж и сложно то есть разбить большую задачник небольшие куски то в целом для этой задачи уже есть готовые решения нужно просто собрать какой-то общую систему из неё и подумайте Возможно если вам нужна какая-то большая вычислительная мощность не отбрасывайте вариант со своим со своей физической железкой с ней в принципе или Ну естественно железками надо брать много желательно центров с этим можно жить и для стартапа это может быть достаточно эффективно в плане денег что не так сэкономить деньги и получить мощную мощную производительность у меня все можете проголосовать за мой доклад спасибо вопросы Спасибо огромное еще раз напоминаю спикером действительно важно и нужно чтобы мы проходили по qr-кодам и высказывали свое мнение еще это очень важно программного Комитета и организатором чтобы понимать куда двигаться дальше на следующих конференциях кто слушает наша нас онлайн жду ваши вопросы в чате я буду их зачитывать и я видела очень много рук товарищей хелперов А все уже вижу пожалуйста давайте Здравствуйте До меня Александр зовут у меня три коротких вопроса Первый тогда первый вопрос Какая модель в итоге под капотом использовалась для обсчёта им ботингов Ну и два коротких маленьких какой размер имейдинга и размер до кассета финальный у нас резнет мы используем без последнего слоя Ну то есть он уже там два года Вот это крутится в принципе более-менее но уже со своими доработками чтобы цвет учитывался и таким всем dataset у нас разные клиенты и у кого-то ну там может быть 500.000 Ну не супер не миллионы какой-то 500.000 у кого-то 100.000 у кого-то 10.000 но клиентов много но у каждого не такое же прямо огромное ДТП чтобы это было проблемой для нас а третий вопрос прямо вот только что вылетел из головы если я не ошибаюсь вроде бы 128 но могу ошибиться Спасибо огромное Напоминаю что придётся выбрать один лучший вопрос большая просьба ко всем задавать по одному Но самое интересному вопросу А если есть что-то ещё в дискуссионной зоне после нашего выступления всё можно будет обсудить прошу Скажите а зачем городить весь этот огород с индексами Когда можно просто посчитать там 35 имбидингов разного размера и искать Сначала по самому маленькому и дальше больше но по сути это есть вот этот фаиси разные всякие индексы и нам нужно как-то оптимизировать количество сравнений и мы можем пойти дальше на 4 есть вариант если прям целиком Вот это векторный поезд сделать самостоятельно но и он может даже что-то будет работать но вот именно чуваки из Фейсбука которые выделенная команда писал этот Файз они очень много оптимизации сделать чтобы с видеокартами хорошо работало чтобы это без багов чтобы не падала по памяти со всякими эксепшенными трейсами там и всем таким естественно жизнь готовы тестировано решение не понял то есть вы просто считаете 3 числа 1 10 бита Одну ступит одну тысячу бит Сначала это ты же сначала ищите по 10 бит потом ищите любит потом уже нормально векторное расстояние там по самому большому есть подобные индексы действительно фаисия и но тут момент что с миллион изображений соответственно нужно как-то вопрос Там их хранить в памяти или частично в памяти частично в диске то есть если память не вылазят все эти вектора и вот у нас есть миллион изображений нужно там начать Ну если на Первом уровне сделать вот эти битовые сравнения то есть так действительно можно сделать и подобным образом один некоторые индексы они так и Работают но тут вопрос Нужно ли нам что-то самостоятельно здесь изобретать Либо мы можем эту часть взять готовую А в свое время потратить на там более какие-то пользовательские фишки Ну да это и был вопрос Я предлагаю продолжить обсуждению уже в кулуарах у нас я видела были еще руки пожалуйста Здравствуйте Иван Спасибо за доклад подскажите пожалуйста вот я так понимаю к вам приходят товары Да вы их Ну запихиваете в индекс Подскажите как вы актуализируете этот индекс то есть товары удалились какие-то товары там Ну каждый раз на каждую пачку вы строите индекс Или вы его поддерживаете как Но для большинства клиентов мы каждый раз делаем новый индекс целиком просто Потому что часто может поменяться все и допустим могут поменяться и То есть были одни одни товары а потом стали другие Но с теми самыми айдишниками и мы не можем отдельно обновить допустим картиночные индекс и не обновлять товары потому что могут какие-то непонятные вещи вылезти и для большинства клиентов мы обновляем всё целиком но есть определённые крупные с которыми Мы отдельно обновляем наличие и то есть допустим раз в день мы переиндексируем товары фотографии не так часто и соответственно допустим раз 10 минут мы синхронизируем наличие и цены в разных регионах всё понял спасибо спасибо огромное так еще вижу две руки хорошо да Здрасте Спасибо за доклад А мне интересно как выбирали алгоритм собственно векторного расстояния поиска по векторным расстоянием А может быть они же разные по точности как вы сказали и разные по скорости А интересно типа как выбирали может быть каким-то бизнесовым метрикам может быть как-то ещё мы взяли вот у нас уже был Open Search И в нем есть вот этот кнн и мы его чуть-чуть дотюнили ну там есть минимальные какие-то параметры связанные с поиском Но в основном это на самом деле завелось из коробки и возможно там есть какой-то дополнительное пространство для улучшения качества Но из коробки Уже более-менее стало работать то есть просто по удобству по сути что просто удобство для разработки подключили оно завелось оно работает более-менее и чуть-чуть там я не помню какие-то были кейсы Когда было не очень хорошо мы как-то под них подтюнели И вот оно вот так вот и работает Просто может какие-то есть метрики потом насколько она качественная или что-то такое Ну в целом Есть действительно поисковые метрики которые можно в основном они используют для классического текстового поиска но на картиночные это может точно также использовать То есть можно брать допустим среднюю глубину клика то есть вот человек искал что-то ему показали 10 картинок и мы хотим чтобы человек чаще кликал на первую картинку то есть мы хотим чтобы первая картинка была максимально похожа и соответственно Можно я не помню как называется Короче три слова каких-то есть как это Метрика называется средняя глубина клика и вот мы можем оптимизировать посмотреть что-то поменять и посмотреть где Но для картинок на такого к сожалению не делали а текст и мы ничего не делаете чтобы из текста искать по нему фотографии кажется что это гораздо лучше для поиска вот к сожалению попробовали и у нас даже кое-где используется Но для товарного поиска часто Ну то есть допустим Отцы и дети и завтрак для всей семьи с точки зрения векторного поиска это может быть похоже потому что это что-то про семью отцы дети это семья завтрак для всей семьи семья И вот векторном пространстве классических текста веков прочего веков оно где-то рядом лежит и пользователь не хочет Ну ищет книгу отследить он не хочет завтрак для всей семьи но у нас как бы есть такая даже фича вот в основном продукте но там ей Мне кажется 1-2 клиента пользуются если уже ничего не нашлось точности мы уже там по векторному ещё поисков вот делают получается по фото потому что не очень часто наверное меньше процента относительно обычного поискового фото Но если это использовать для фичи похожие по фото товары то там запросы достаточно много будет ну потому что на каждом человек заходит на карточку товара и мы должны похожие товары на ну на этот найти и вот там же просто достаточно много Может быть но там очень хорошо хеширование работает поэтому проблемы супер Спасибо огромное У нас есть время еще наверное на два максимум три вопроса прошу Да у меня такой вопрос пожалуйста что клиенты хотят Какая самая интересная к вам поступала задача что сравнить вы рассказали только про одну кажется про то что найти Похоже маркетплейсах да предметы А что самое запомнилось Вам самое интересное что Вы заказывали Но вот был фейл мы его так не смогли выполнить ну эту задачу и как бы это вот на фейлы хорошо запоминаются то есть пришёл у них картины всякие разные и мы говорю вот вам сделали поиск по фото то есть человек загружает фото Там женщины вот вам 100 женщин похожих визуально он говорит Что за ужас потому что у нас вот смотрите здесь работа карандашом А вы показали картину маслом и это прямо ужасно у нас так пользователи не выбирают мы думали что надо как-то дообучать там сделать отдельный классификатор Ну в итоге Этот проект так не запустился и э ну мы как бы зафейлились то есть вот эта задача мы не смогли выполнить слушайте Не могу говорить отлично обожаю файлы кто еще кроме меня файлы любит Ладно чужие кто любит чужие файлы слушать про чужие файлы все кто любит слушать про чужие файлы приглашаю завтра в 10 утра я понимаю что это будет очень мучительно сложно а на файл секцию послушать про чужие фейлы Ну что если у нас еще вопросы в зале кажется что нет в чате тоже нет У тебя сложный выбор такой вопрос понравился тебе больше всего они все были замечательные Спасибо всем за запросы запомнился первый вот мужчина бейддинги размеры Поднимите руки пожалуйста супер ребят подарок пожалуйста Спасибо огромное всем и тебе тоже огромное спасибо от лица конференции Спасибо"
}