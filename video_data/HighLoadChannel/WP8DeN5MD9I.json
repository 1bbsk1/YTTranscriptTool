{
  "video_id": "WP8DeN5MD9I",
  "channel": "HighLoadChannel",
  "title": "Мониторинг современного k8s-проекта глазами разработчика  / Сергей Спорышев (ITSumma)",
  "views": 1585,
  "duration": 2844,
  "published": "2020-04-14T11:08:49-07:00",
  "text": "друзья всем привет меня зовут серега из компания эти суммы и сегодня я вам расскажу про то как мониторить кубик как мониторить современный проект надеюсь будет полезно немножко обо мне ну и как я сказал я работа в команде компания эти сумма я бывший разработчик я ни разу не админ более десяти лет baby пишу на всем на чем пишется и последние года два в своей жизнью я тесно связан с кубиком из тела прометеем граф анной и хочу поделиться сегодня с вами своим опытом своими набитыми шишками и своими как бы трип-репорт там скажем так окей немножко о нашей компании ну кто не знает мы на рынке более 10 лет мы занимаемся круглосуточной технической поддержкой мониторингом построением различного рода архитектур консалтингом различных devops практиках нас уже больше 100 человек мы уже устали считать наших сотрудников нас 4 офиса и более десяти тысяч серверов у нас на поддержке вот такие вот у нас есть классные клиенты наверное все читают тот же самый хабрахабр наши клиенты ну что погнали а небольшой оффтоп этот доклад это третья серия у нас уже было два доклада про мониторинг первый был от нашего директора евгения потапова на питерском хайло die 2 серия была в новосибирске от меня и сегодня собственно говоря завершение этого сериала и давайте вообще посмотрим что было в предыдущих сериях какие во-первых мы рассматривали проблемы в современном мире очень сильно в в проектах возросла сложность архитектур сильно возрос стек увеличилось количество инструментов как например то выгнала 10 лет назад типичный в проект выглядел вот так у нас есть какой-то инстанции б есть база и и и все и больше ничего не было и мониторинг такого проекта был собственного очень простой какую-то часть мы спокойно могли покрыть забег сам и внедрить какие-то буквально не был небольшой процент ручных проверок то есть например то что у нас страница отдается что у нас какие-то заказы в интернет-магазине появляются и собственно грэм мониторинг ручной занимал примерно нам один-два процента времени мониторинга всего продукта остальное как говорится все работало из коробки что же произошло у нас сейчас примерно в наши дни когда мы смотрим на архитектуру проекта мы видим примерно вот такую картинку то есть штук 15 разных сервисов штук пять разных баз данных и как вообще это все мониторить понятно что автоматически инструментами покроется буквально процентов 20 нашего проекта все остальное нужно делать вручную как мощью с этим живем дайте мне множество им немного с вами проект поговорим а следующая проблема это изменение области мониторинга если раньше мы мониторили буквально там базовую инфу и чуть-чуть бизнес-логики а современных реалиях у нас доля мониторинга базовой инфраструктуры заметно снизилась увеличилась доля мониторинга уже уровня а уровней абстракции то есть если раньше у нас был барри барри металл на нем крутился джинкс vpn и мускул то сейчас у нас есть какой-то большой набор виртуалок в конспекте поверх него верхних раскатаем кубик и все наши сервисы запакованы в каберне тисе крутятся и как-то между собой взаимодействуют следующая проблема которая была у нас в предыдущих сериях это отсутствие волшебного инструмента теперь нет такой утилиты который мы поставили и навсегда забыли про мониторинг никогда к нему не возвращаемся также у нас отсутствует волшебный человек которому придешь за два дня скажешь вася за монитор пожалуйста нам наш проект такого человека больше не существует и последняя проблема которую мы рассматривали такая цитата нельзя за мониторить кафку то есть понятно что ее можно за мониторить но какой вот этого просит полу получите непонятно про этому сегодня с вами поговорим и какие выводы у нас были сделаны предыдущих сериях большая часть мониторинга это в данный момент работа разработчиков они abs of и современный мониторинг это уже не просто но инсталляция различного набора утилит это чуть больше ok давайте поговорим о том как вообще к мониторингу подходят у нас abs и как подходят разработчики и чего ты то вообще хочет бизнес abs и опций знают системным по абсолютно все они понимают как за мониторить отставания реплики в гузку ли они за по не понимают как за мониторить проц и так далее но они мало посвящены в логику вашего проекта они в принципе даже не должны знать бизнес-логику ваших задач и как вообще это все работает их вотчина это железки и системное по их реально меньше с другой стороны у нас есть разработчики они птички им такое сложно то есть я как разраб честно признаюсь я не знаю как за мониторить расставания реплики но мы их к разработчики мы больше посвящены в бизнес-логику проекта мы понимаем задачей нашего проекта и мы понимаем что нужно мониторить и нас реально больше то есть современный это проект это 15 команд 40 разработчиков каждый разработчик велит свой сервис понятно что купить админ там два обмена в отделе мониторинга когда к ним придешь и скажешь за мониторить и нам пожалуйста все они сделаю такое и и нет и ничего не будет как говорится что же при этом хочет бизнес бизнес хочет что проект работал что проект работал корректно и что проект будет работать дальнейшем окей с этим разобрались кто знает вообще какая конечная цель любого мониторинга что почти в точку конечная цель мониторинга это allure ты чтобы у нас была большая картинка что у нас что то где то отломалась давайте немножко поговорим про лифтинг такие общие принципы валер тенге современном мире есть мы должны первое что сделать это выставить так называемые индикаторы services sl ой то есть те параметры по которым можно определить работает ваш продукт или нет то есть например это количество 500 их ошибок количество залогинен их пользователей на сайте и так далее также у нас есть целый соглашение недоступности стерх сервисов и очень такой частый паттерн ошибка alert и вешаются на нарушение целый то есть alerts вы выстреливает тогда когда мы уже режим боль больше 15 минут а польза таких allure тов нет никаких поэтому у нас вводится третий термин соло и slow целевое получая состояние нашего сервиса и в правильном мире мы должны вешать alert именно на уровень услуг то есть получается при но такая картинка что для достижения целей мы должны лететь тогда когда нарушается и слов про инструменты для лифтинга я думаю рассказывать смысла нет все пабе знаю там alert manager все знает там пейджер duty есть решение вот вам нравится лично мне это alert а то есть какие-то могут быть сам описанная лестнице про это в принципе можем поговорить уже отдельно доклад немножко не про это также очень важный момент организация процесса когда у вас есть куча alert of причем весьма бесполезных в конечном итоге это будет какая-то либо папочка 1 почте которую как спам уже никто не читает либо замученный чат в телеграме такого быть не должно и про это мы тоже можем рассказать очень много давайте уйдём уже в мониторинг небольшая вводная для подготовке этого доклада мы с моей командой разработали тестовый демонстрационный проект на по которому мы прогнали вообще весь мониторингу вы вернетесь приложение это небольшой такой вы проектом из четырех сервисов в сервисе между собой общаются как просто пахать и т.п. так и ппц сервис мышь вынесен на есть и вот такая вот кухня ради доклада какой у нас будет план мониторинга первое это сбор и визуализация метрик и также в рамках этой задачи мы должны рассмотреть вопрос хранения метрик а сбор и анализ логов и up and racing как уже final финальная стадия нашего мониторинга окей приходим первому вопросу сбора визуализация метрик какие у нас есть инструменты для этого все знают про и графа ну так же есть решение нет даты есть do that dog телеграф не так давно австрия встретил даже zabbix авс к и решение для мониторинга кубера но в мире кубер нас есть замечательная как синоним фразы промышленный стандарт называется кабелей и собственно про митоз pro + графа на это soft это q белый если мы идем чуть чуть в бок от кубе вы это это примерно похоже на выстрел себе в ногу поэтому давайте из многих и не стрелять и пройдемся именно теми инструментами которые у всех на слуху которая все уже знают которыми все умеют пользоваться что нам собственно говоря предлагает прометею сыграв она первое с чем мы столкнемся это чистая инсталляция это ручно ручную ручная настройка нужных нам экспортеров это not экспортеры для сбора метрик с узлов край кластер а это кубе стоит метрик для мониторинга именно состояния кубер notice приложений например black box экспортер для мониторинга доступности уже конечных веб-страниц ну как бы про это можно рассказывать долго но это никому не интересно то есть с 0 асе топить это все ну зачем поэтому следующие к чему мы придем когда будем гуглить как мониторить пром это бромид и вас оператор кто пользовался нравится мне тоже нравится броневой чуть чуть позже еще подробно расскажу про некоторые его прикольные фишки также вместе с пром оператором часто поставляется набор дашбордов называется кубер notice миксин и вроде как бы если бы там этого хватало то я сейчас со сцены ушел и сказал всем спасибо за внимание если по внимательно посмотреть на эти dash барды на топ что приносит нам пром оператор начинает быть заметным что даже барда вас нам писались админами то есть большая часть метрик это проц память диски сети и все то есть как бы не как разработчику этого не хватает и буквально в нескольких dash бордах будет информация о количестве реплик приложение поднятых количество там рестартов контейнера и так далее мы задались вопросом а если какое-то готовое решение для покрытия вот этих нужд чтобы нам мониторить не только инфра а я часть но уже чуть-чуть мониторить бизнеса вы составляющая нашего проекта и первое что мы нашли а на сайте этот дашборд и которая в миксе не значит ведь видно видимо плохо ну вот здесь принципе видно просто память и вот чуть-чуть про количество реплик и погнали дальше и для мониторинга именно бизнес составляющие нашли такой замечательный плагин для граф она называется grafana кубер не this up вроде ридми все хорошо позволяет мониторить количество реплик количество запущенных подав дипломатов вроде все все замечательно из коробки только плагин не поддерживается уже больше года то есть последний коммент нам был в начале 18-го современными версиями кубе стоит метрик санду экспортера он несовместим и чтобы его завести нужно еще там колдовать буквально месяц нет ни месяц недель недели нервной почве придется покурить и зависти и поэтому у нас таким небольшим сайт проектом к этому доклада появился собственное решение для мониторинга кубер notice а это наш собственный плагин devops prodigy кубе граф up он выглядит вот так позволяет строить во-первых карту ваших сервисов в кластере то есть сгруппировать по namespace вам показать какие где deployment и под и запущены в каком они состоянии позволяет снять текущее состояние кластер а какие например у нас модель надо перегружены либо какие-то под и не могут защиту лица на мой взгляд очень полезный инструмент также есть отдельно даже борды для мониторинга состояния ваших приложений кто из количество доступных доступных red реплик количество контейнеров различным статусе количеству рестартов и так далее вот если хотите его поковырять исходный код на гитхабе есть также есть часть по телеграме где можно по поводу этого плагина пообщаться со мной по задавать интересные вопросы ok идем чуть чуть дальше по сюда вернемся этими инструментами которые перед перечислил мы закрыли только часть мониторингом и обмане tory lane froom то есть мои мониторинга состояния но от нашего кластер ac астане там дисков памяти просто так далее а мониторили немного бизнес-логику то есть научились понимать работает и наше приложение сколько реплик доступно то есть мы оба не торелли только часть нашего проекта теперь переходим к мониторингу именно конкретно самих приложений как бизнес-единицы начинаем писать метрики для приложения кто-нибудь бишь метрика jet мало рук ну а тогда крови побольше да тут руслом чекам то светит очень сильным прям глаза ok начинаем писать метрики для приложения то есть я знаю так скажем promt standard что наше приложение на слышь metrics должно план текстом отдать определенным на такую портянку метрик с лейблами и со значением как это писать для любого уже языка при программировании есть готовые модули доступны прямо на сайте про митоз а то есть там для но джесса для кошечки просто ставим пром клиент и в очень удобном формате описываем такую метрику когда снимать что она будет означать дальше после того как мы в приложении написали метрики мы их должны дотянуть до prometheus а то есть во первых мы можем написать сами скрип конфиг это вот такая вот большая портянка откуда снять метрику с каким тайм-аутом какие лейблы проставить и на мой взгляд это немножко неудобно постоянно обновлять этот параметр сканы config записывать туда при этом принципе вы нормально не сможете построить сервис discovery и мы по из-за этого чуть чуть возвращаемся назад и вспоминаем у нас есть про metals оператор вместе с собой он приносит замечательную картошку кубовую это service monitor кто не писал service monitor и еще меньше рук а что такое service monitor service monitor это кастом ресурс для кубер не tissot который позволяет вот так минут удобным я маликом описать откуда прометей должен забрать метрики то есть например в нашем случае мы должны сходить в сервис митинг people's на порт который называется вебс интервалом 15 секунд и после после применения этого сервис монитора конфиг relocker prometheus подтянет нужно новую информацию заведет новый таргет и ваши метрика автоматически появятся в кроме если допустим нам нужно добавить какие-то кастомные лейбла для метрик в этом же сервис мониторе в очень удобном формате мы пишем куда какую метр лейбл напихать откуда взять информацию очень удобный инструмент и на выходе мы собственно говоря вот пример для нот же снова приложения у нас есть там три кастомных метрики то количество записей в базе и количество request of нам на blade create такой фейк фейковая примерчик но работает поднятие как бы вот такой штуки для разработчика занимает ну может минут 15-20 то есть вывести метрики написать service monitor собственно говоря все хорошо все работает и вот после того как мы на применяли ниной плохо видимо видно а вот наши собственно играть графики с нашими кастомными метриками несет каких-то 717 сгенерированных увидав вот так оно собственно говоря выглядит либо например по этим таргетом мы можем собирать об метрику в данном примере мы просто собираем об конкретного сервиса в нашей практике был кейс когда но это был сторонний проект контейнер финальный отдавал еще цел с метрики то есть то что car service приконнектиться к базе то что сервис там принимает запросы и принципе пробку или мы-то все можно описать как бы всем и вот можно на выходе получить такую замечательную картинку что каждый ваш сервис работает ну и очень важна эта организация сервис discovery то есть при появлении нового сервиса при появлении нового дипломанта хочется чтобы он сразу появлялся нашем мониторинге то есть как это можно решить первое ну немножко неудобный способ это единый сервис монитор для лигу любого вашего сервиса то есть вы вешаете на коды как какой-нибудь один определенный лейбл и в этом не смей секунд срединный service monitor который будет поэтому лейблу подтягивать новые deployment и либо если вы там деплоить и свои приложение фильмом напишите небольшой чертик для de plaisir из монитора или собственного после диплома нового сервиса у вас будет появляться и отдельный service monitor для этого сервиса дальше вроде с метриками разобрались сняли уже метрики с наших приложений как бизнес-единиц очень важный момент который нужно учесть это разобраться с тем как ваши метрики будут храниться тоже есть очень много вариантов самый наверное популярны это хранить метрики в хаосе тоже небольшой оффтоп само решение для интеграции промо с криком и сам нам не особо устраивает и вот мы счастлив потихонечку пишем свой коннектор а в последнее время и ребенка бы это такой hyip уже много кто использует виктории metrics как систему для долгосрочного хранения метрик окей разобрались с нашими сервисами по отдельности переходим к уровню сервис миша то есть того как наша сервис и взаимодействуют между собой понятно что взаимодействие с сервисов бывают синхронным бывает асинхронным давайте начнем со синхронного у нас есть примерно вот такая картина у нас есть какой-то брокер для очередей и есть сервисы которая там через этой шины данных общаются как я уже этом в начале доклада говорил была фраза нельзя за мониторить кафку то есть если мы за мониторим наш брокер там и в этой схеме покроем только мониторингом вот эту часть то есть мы только за мониторили шину что у нас топике например разгибаются что у нас кафка жива но как бы саму бизнес-логику мы не проверили а корректно или у нас там данные на выходе мы можем за мониторить обработчики как отдельное приложение и тогда картинка будет выглядеть вот так понятно мы за мониторили обработчик мы за мониторили там у него где увидели культ метрику что он успешно там прочитал сообщение сообщение из shinee что он успешно его обработал но логику финальную мы немножко еще как бы ну не видим а корректно ли у нас работает весь процесс поэтому для мониторинга синхронного взаимодействия целиком нужно писать какие-то тестовые сценарии либо снимать метрики с интеграционных тестов именно в этом случае мы можем получить вот такую картину то есть самый простой примитивный пример если у нас есть какой-то интернет-магазин то с точки зрения разработки мы можем раз там в час либо в день по крону гонять какой-то тестовый сценарий тестовую покупку но очень важно в коде учесть чтобы у нас после прохождения теста вас сценария этом с банк банковской карты не снялись реальные деньги поэтому пускай деньги будут тоже тестовыми окей с электронным разобрались теперь давайте подумаем на сенат синхронным взаимодействием на мониторе нам синхронного взаимодействие между сервисами как я уже говорил в нашем тестовом проекте мы уровень сервис сервис миша вынесли на из тела кто не чистил работал нравится прям двумя руками тоже вверх для мониторинга систем из коробки во-первых приходят даже борды для граф анны и приходит замечательный инструмент называется кеа ли его щас чуть-чуть позже посмотрим также если например вы используете какую-то другую систему у того что валенки орды есть собственный набор дашбордов как как как келли для из тела также набор до сборов для графа ны мышь который основе натравить на трафик тоже приносит уже готовые даже борды давайте посмотрим как это выглядит то есть это типичный успешно даст дашборд мы видим что у нас как какое время ответов между сервисе какая задержка то есть прям все очень хорошо красиво видим как у нас сет service it was у нас тут секс с рейд как шить он машина работает вот 2 2 2 зелененьких квадратика что нас сервисы доступны и общаются между собой stone 100 процентах со стопроцентной успешности вот так тут у нас тоже какой-то дашборд по имя по трафику между сервисами видим там определенные пике видим что здесь у нас все ровненько шло мы видим нагрузку же которую нам дает наш инструмент для организации миша то есть все прекрасно понимают что тот же самый есть о помимо у своих хороших прелести приносит еще небольшой overheat собственно говоря на dash бордах который поставляется вместе с из тела это мы можем подсмотреть окей кимаки олли келли замечательный инструмент это как такой немножко до писаный дашборд до кубера который важный ключевой особенностью у него это построение карты взаимодействия ваших сервисов причем с анимацией того как в реальном времени гоняется трафик то есть у нас есть ingress gotway у нас есть три сервис на которой запри приходят запросы видно к в том какие сервисы обращаются к другим сервисам во время выполнения запроса видно там кто как ходит в базу в чем плюс во-первых из тела из коробки понимает каким способом взаимодействия эти между сервисами то есть зелененькие то у нас gr потешный трафик синенькие то просто ты пышный трафик то есть все замечательно все хорошо берем и тестова ломаем какой-нибудь один из наших сервисов есть и келли в реальном времени показывает что у а нас часть трафика отвалилась показывает сразу количество ошибок видно что у нас был скачок по ошибкам за последние пять минут очень удобно очень красиво и с этим очень приятно работать ну и так же вот наш тестовый эта панелька нас сразу видно что три сервис отвалилась вроде все хорошо все красиво с мониторингом чуть-чуть разобрались переходим к работе с лагами и стрекот рейсингу то есть про прологе тоже все уже хорошо знают то есть какие мы должны вопросом для себя решить во первых как мы будем писать блоги что мы туда будем писать их с каким инструментом мы будем работать в моей практике чаще всего мы работаем с е в qashqai понятно что louder нужно писать правильно не но не нужно писать туда лишний мусор при этом вы должны определиться что у вас будет в системе отдых логов индексироваться для того чтобы потом по работе с лагами нам как бы все это работало быстро и не нарушала нашу систему в последнее время в сети не так давно вышел инструмент локи это инструмент для работы с лагами от графа на и причем полностью у графа на capability то есть с 64 версии прямо есть уже набор плагинов для визу визуализации логов из системы хранения внутри графон и но мой взгляд очень удобный инструмент и для чего нам честно говоря это нужно во-первых работа с лагами нам позволяет анализировать ошибки нашего сервиса очень часто своей практике встречаю что в том же самом can дашборде граф анны количество там 500 их 400 их ответов берется непосредственно не системы хранения логов по ним строить определенной метрики allure ты и так же работа с лагами нам дает большой очень playground для работы с анализом аномалий того что наш какой-то сервис и он учил о шатать пока это не на не еще не привело к деградации системы но пологом уже начинает видно что какой-то сервис начинает шататься давайте посмотрим ok мне больше интересно рассказать вам про tracing прессе кто пишет что-то мало народу пишет трейси тоже очень это очень прикольно в чем прелесть из тела из коробки нам приносит лагерь приносит все же необходимый инструмент для работы с рейсами поэтому просто сиди и пиши и не думай по этой ссылочке мы можем найти уже кто же готовые библиотеки на например наподобие пром клиента для работы с рейтингом то есть под любой язык программирования любой фреймворк есть готовый библиотечки там npm install джаггер tracing но джесс все будет работать из коробки что нужно учесть при работе с рейсами в estel estel при пересылает заголовки на мне путин формате то есть это заголовки xb 33 среди xb tree spa найди и позволяет нам ловить trace уже с того момента как запрос попал в наш кластер на наш из теги твой очень важно научиться работать ими заголовками чтобы уметь определять root root span кто понимает что такое руслан это наш собстна говоря корневой trace который нам отдает из тела то есть у нас пришел запрос вместе мы оттуда выдергиваем их sb3 заголовки и наш рейс уже привязываем к этому то есть который идет о тесте и очень важно не забыть про сэмплинг из коробки есть его приносит ok сэмплинг скажем так это частота снятие trace of то есть если мы его в устройство им сто процентов то в конечный момент бы просто на пихаем рейсов в больше чем может вынести система хранения для них и прав положим систему поэтому очень важно trace и снимать не постоянно а с какой-то частотой которую вы должны определить для себя сами окей теперь небольшие пример чеки вот так оно собственно говоря выглядит trace от estee мы видим что у нас пришел запрос в истек gateway с него запрос пошел в room service но и в принципе видим вот такие замечательные картинки то есть мы можем вообще мониторить смотреть-то то как видешь ведет себя наш запрос в нашем распределенную тоном кластере в микро сервисной среде и собственно грамм на основе этих trace of уже смотреть где у нас система начинает считать или вот второй примерчик тоже нашего сервиса здесь немножко trace of побольше стрессами поговорили и собственно говоря отдельная боль это типа жить связку систем когда я готовил этот доклад именно кристи об рейсом и привязывали это была пятница в 12 ночи я отпустил свою команду и сел уже либо жить это все сам то есть понятно что мы локально можем поднять in fruit для работы с рейсами но пока мы не одни божим о получении рут спада который приходит от истину как бы с трейси будут бесполезны но это того это того стоило и давайте перейдем к выводам мониторинг современного микро сервисного проекта это уже сам по себе становится микро сервисным проектом то есть нас я перечислил сколько инструментов на используем про митоз grafana какая-нить а лестница лагерь какой-нибудь инструмент для работы с влогами кеа ли уже тут уже 6 инструментов сходный читал и с этим как-то нужно жить об этом предлагаю нам встретиться отдельно сегодня в день можно у нашего стенда и побеседовать о том кто вообще как с этим живет второй вывод который хочу сделать это следите за своими метриками в какой-то момент количество метрику вас вырастет в очень как будто вы большое количество у вас вырастет количество alert of и приведет это все просто к тому что в конечном итоге мониторинг будет игнорироваться потому что он будет создавать просто лишний информационный шум и какой-то момент если вы не будете следить за метриками это придет к этой замечательной притче про мальчика и волков когда мальчику к начал кричать мальчика никто не послушал и потом волки все съесть всех съели вот небольшой оффтоп по поводу того как подойти к работе с метриками что писатели замечательная статья на медиуме можно пас посылочки перейти в статье pride придавлены 3 методологии это юз от tom tom вилки red брендон грег и lts из книжки google сергей что это такое методология юз это сбор метрик по утилизации по насыщенности наших ресурсов и по чистоте ошибок red это частота запросов частота ошибок и время прохождения нашего запроса и тесс тут не знаю как правильно сказать утес это задержка трафик и так же ошибки и насыщенность нашей системы и третий вывод самый такой интересный обязательно заставляете писать мониторинг программистов заставляйте их писать метрики во первых это будет полезно всем и во вторых это реально интересно могу поделиться секретом даже как заставить генерального директора начать писать метрики всем спасибо вот по этим за те контакта можно меня найти здесь у нас есть отдельные чате про наш плагин пишите туда я обязательно с хэштегом hill 19 чтоб я в потоке сообщений вас не забыл ну и еще небольшой в топ очень хочу поблагодарить команду благодаря которой вообще появился этот доклад всем готов слушать ваши вопросы так а где у нас микрофон и вопросы а ну вот давайте вот так спасибо за доклад у меня собственно вопрос очень часто ну говори бизнес хочет вкрутить бизнес метрики уже свои другого буря в том же магазине это там чекаут и перехожу день и я в покупке вот мы как бы обычно пока покрасим войска уже костылем все это балалайку тоже в на графа не если тут решение но какие-то иные то есть группа варианта что у нас получается что грубо григоров она выглядит как свалка у нас здесь себя сбор да там с утилизацией процедур сетью там соседней там дашборд уже спас покупками как вот можно это все разрезать как-то раз зевнем как я уже говорил нужно просто следить за метриками то есть нужен какой-то дашборд на мой взгляд который будет показывать на ваш взгляд вы но вы сами должны оценить какие метрики важны для бизнеса то есть вам например неважно что количество зарегиться рига на этом пользователи на сайте чуть-чуть там упала вниз вам важно там количество продаж кто идет в реальный момент вам не знаю не особо может нам быть важно что где-то чуть-чуть начало начал его начала возрастать нагрузка на диск поэтому можно вынести на кон там сторон не дашборд от посадить отдельную команду который мониторит нтв руб на мой взгляд в этом случае самый такой оптимальный вариант это сделать конечно дашборд для бизнеса и пускай он он в него и смотрит то есть или собственного разделить что такие то метрики у нас должна обрабатывать эта команда такой-то метрика эта команда вот так сергей чуть чуть погромче не слышал сергей 2 началась то что готов рассказать как заставить снимать метрики генерального и не до рассказал вот можешь продолжить луч в кулуарах можно прямо его спрашивать вот он сидит отлично так а когда обсудим то когда стрелка так не вижу откуда вопрос как когда обсуждать когда стрелка и где подходите к нашему стенду прямо сейчас поставим поговорим думаю может быть соберемся и нам ими так чик организуем стихийный проект спасибо за доклад если берем меж поверх кубера с включенным trace'ом включенным контролем доступа включенный роутинга мы вот все все все все все сколько нам по железу нужно добавить много если в процентах вот предположим у нас там 500 лидер да там та ра байт памяти на кластер сколько нам нужно чтобы все это дело вкрутить себе но по моим примерным таким прикидкам процентов 50 минимум придется нарастить ресурсы но из тела любит много есть но можно немножко по лайфхаки и подрезать его хотелки пал этом есть у замечательной стать статейки то есть разного рода проведенные уже тесты среднем как бы выкидывание истек приносит задержку ну сверху может секунд миллисекунд 50 как бы ну не не сильно критично но тоже уже зависит от того насколько вы на ваш продукт работает то есть из коробки и помочь марком ли тону 50 может быть соточка да ну на прохождение всего все запросы по всей цепочке сергей привет так обижен спасибо за доклад tracing для кафки используете экспериментируем мне подсказуют вот экспериментатор как раз этим работаю сейчас на чем вы посмотрите вот она первым redux ментатов сядьте рядом поговорить не прям не стесняйтесь следующий так вот водку про в проходе смотрите и потом здесь и дальше в новосибирск перейдем пожалуйста у меня случай вопрос вот там на слайде было бы он поломали один компонент можно вы можно вывести картинку вот туда и было 33 прекрасный старый стали портит вот эта картинка следующими может быть что еще раз выполняли один компонент да и досталось красными dream да то есть вопрос в том сколько приходит ольмерта полета приходит один как бы на всю систему или приходит с трисс а тут уже как говорится на ваш выбор то есть на мой взгляд лучше повешать трейлер то что вас не работает 3 сервиса можно повешать один alert что вас не работает какая-то связка но в любом случае alert должен быть allure должен будет понятен и очень важно alert должен себе содержать куда бежать и что чинить то есть если вас будет один alert с фразой отломалась 3 сервиса то можем можно начать ценить не оттуда если у вас будет какой-то один alert но и он там пришел раньше что-то отвалился там в данном случае я погасил у них генератор если бы меня сначала прилетела лет что отломался и uid генераторы следом прилетела два лифта что два сервиса не могут получить у еды то у нас есть четкий понятный алгоритм алгоритм как чинить уже ношу на наш сервис то есть на мой взгляд лифтов должно быть 3 и они должны быть максимально полезными я на секундочку там был не просто количество alert of которые приходят от системы она фактически зависит от нужно по нашей практике она зависит от команды которая получает alert и соответственно если у вас есть один админ который сидит на пейджере получает alert и то высокая детализация прилетающих alert of чисто с психологической точки зрения с точки зрения работать как не дивный систем человека рано или поздно приведет к тому что у него будет меньше внимание к любому каждому из этих alert of поэтому ну с точки зрения как бы бой организационная бы исходил из того что чем меньше людей которые находятся непосредственно лифтинге тем меньше должна быть детализация то есть салоу вот этот сервис сливал объектов он зависит от количества людей если у вас их много если у вас например команда которая делает сервис отвечает за работоспособные сервисы как например там не знаю часто лекси делают в реддите то соответственно редакция будет очень высокая то есть вы бы хотели сервер получили себе по alert и по данному сервису и ну как бы команда разбираются если один admin 12 метров моменты должны быть ну типа происходит очень большая беда расстанется расследуете и дальше уже мониторинг должен быть настолько деталь немного ты слаб серво делите чтобы человек который получил один большой серьезной alert 2 то что зло пересечен дальше имел возможность за короткое время разобраться что происходит внутри системы короче главно нормально рундуки писать и тут женя проспорил ящик безлактозное молока в то что обещал не подниматься на новосибирска вы готовы с него даже и профи вопросы мы сейчас вернемся к москве просто этим мы городского конечно да у нас вопрос от но он туда смотреть добрый день драсте до чего технологии дошли смотрите вопрос такой у меня он связан с вопросами предыдущих ораторов вам слышно меня да да да все хорошо вопрос связан с двумя предыдущими ораторами он касается бизнес метрик и их количество соответственно мы пишем сейчас приложение для раков для call-центра и у нас есть задача от бизнеса контролировать работоспособность ряда процессов вот который максимально критичны и нам нужно мониторинг именно эти процессы написать вопрос такой в похожей ситуации как высчитать можно ли обойтись если инфраструктурными метриками или имеет смысл завести какие-то бизнесовые счетчики именно по тем процессам которые мы хотим мониторить и их мониторить обязательно обязательно нужно завести бизнесовые счетчики потому что столько name in free например у вас даже но как короче в какой-то момент может произойти его тут разделение что шепнула что-то одно на выходе там два каких-то сервиса и непонятно какой из них отвалился то есть поэтому мне кажется каждая бизнес единица должна будет отдавать им на свои метрики отдавать свой и hell статус именно по ней мы должны лететь то есть на уровне in free это завязывать нам на мой взгляд даже немножко некорректно вот девушка такое стремени но это соответственно пиццы уйти от меня пожалуйста вот и потом продолжать вопрос я такой же скромный как эта девушка воздержусь да у нас тоже такое же ощущение что нужно бизнесовый метрики вести поэтому мы в этом направлении движемся но соответствует надо тоже не как баланс держать видимо чтобы ну как я уже утром метрики не перевесила количество функционала который мы пилим это оверхед маша мониторинг дать не должен на мой взгляд можно чуть чуть чуть не уходи друг не уходи мне есть тети весят сказать как только при приза расширится там есть ссылка на статью как раз медиа wma pro 3 методологии снятия метрик я думаю прочитав ее ты найдёшь ответ на свой вопрос теперь все второй вопрос был до теперь у нас начался интерактив настоящий да теперь у нас 2 вопрос из новосибирска камеру туда можно пожалуйста а мы с этим мне смотреть на да вот туда или вот куда то туда и когда отвечаешь на 3 на камеру туда и тогда в глаза будешь смотреть вот всем строке девушкам новосибирска до вперед включите микрофон пожалуйста нам мы не слышим или это может быть звукорежиссер а сейчас вам принесут другой микрофон там вроде недалеко идти хотя камеру долго поворачивался срочно менять а теперь слышно отлично спасибо меня зовут алексей очень интересный доклад очень актуально для нас мне вот вопрос такой может быть немножко простой как я подумаю про me to you с операторы в другие тузы и ставят этот про метался в этот же кавер на это с которой мониторится если кластер начинает колбасить их тормозить этот prometheus тоже как я понимаю начинает колбасить и тормозить и он ничего не снимает не надо ли ставить его отдельно или вот как это было очень хороший очень хороший вопрос наверное года два назад евгению на сделал доклад нам был один из тезисов мониторинг должен тоже мониторится поэтому на мой взгляд именно работа с про мам у вас должен быть 1 пром внутри потому что это максимально быстро . . для сбора метрик из всех ваших приложений и также должен быть внешней пром который vaper либо в эти же самые экспортеры ходят либо подключен к нашему кластер нам управу пул как как тоже как отдельный экспортер оба варианта имеют место быть про то как правильно мне кажется можно ли варить песка бесконечно то есть здесь уже зависит от того как вы этой реализуете на мой взгляд должен быть как внутренний пром как собственно такой горячий горячий источник данных так и внешним пробно который мы можем переключиться случае чего то но в любом случае если вас начало колбасить кластер начал около вас прометей внешним параметрам вы же тоже не соберет метрикам у что он не сможет достучаться до экспортеров поэтому ну видимо берем в эшли пром его завязываем на внутренней промысле у нас собственно гра начало колбасить внутренней то мы уже по внешнему это спокойно сможем отследить вот так отлично спасибо спасибо теперь новосибирск мы вам любовь отправляем петербург есть вопросы denis как два есть красивые девушки есть интересные вопросы классно я попрошу задать вопрос нашего участника алло алло меня слышно да да папки в анталии и мне прям очень зацепил вопрос по поводу зала как заставить разработчиков я понимаю что генеральный директор это останется для кулуаров но может быть для петербурга и новосибирска для тех кто не может подойти в кулуары как бы кратенько концептуально эту мысль развернуть было бы очень интересно смотреть москва закрыли ушки поехали ну во-первых ваша команда разработки но она должна понимать зачем она это делает я вам я смотрю туда я просто так вот хожу чтобы они увидели то есть команда важно понимать важность этих метрик то есть про так как ее заставить нас принципе был хороший доклад на питерском холов элладе может его пересмотреть в целом вообще к написанию метрик как важности как разработчик я вообще дошел сам то есть у меня как бы не заставляли как бы я сам понял важность я сам понял то что кроме меня никто не знает как работает мой сервис если дать мониторинг этого сервиса админу но откуда откуда он узнает что нужно мониторить то есть как то видимо таким образом нужно донести это до команды что кроме вас никто не знает как она работает никто кроме вас не знает принцип работы вашего сервиса критичность связи между какими-то отдельными компонентами сервиса ну вот как-то так но если хотите кулуарные разговор подслушать а то как как это выглядит как раз пришел же не горит серёжа датчане пописать пожалуйста давно-давно ничего руками не писал ну я его и нагрузил отдельным сервисом для нашего этого проекта сделать нотификатор а потом просто скинул но уже готовый пример того как у нас пацаны мониторили отделе свои сервисы и скалы женя вот вот теперь библиотечка хочу понимать сколько пришло запросов направлении сообщения и хочу узнать сколько их было ошибок все делать очень просто ринг он взял и написал как-то так всякие когда воду открыл евгений напрягся всегда скажет да а петербург спасибо новосибирск спасибо москва давайте еще вопросы кого там вот здесь не скоро полный был вопросик да пожалуйста здравствуйте вопрос прологе там пару слайдов не очень интересно наверное да про мониторинг но все-таки последнее от буквы которая здесь что вы используете какая производительность вы про замеряли если у вас цифр по каким-то пиковым можно про цифры сейчас не скажу мы можем пообщаться этим на на стенде на мой взгляд мне больше всего коммуну понравится работать съев qashqai то есть лук стаж немножко сирона кнут тормозной file with как-то повеселее но на одном из проектов мы столкнулись вообще совершенно случайно с такой штукой что не мною не был настроен драйвер лак на корректному образом в вк убери и у нас под и постоянно вы летали по превышению эфемерного сформировал сторож то есть они писали своего теста даты и потом просто рандомно образом уже scheduler м грохнулись то есть главное все правильно настроить из уже наверное для себя решить какой вам инструмент просто удобней мы работали мне кажется совсем у нас есть кастомное решение для игры logo мы писали сервис который фильтрует входящий поток как бы выкидывает ненужный мусор и сохранит только ну там определенные логе по определенным критериям очень пока сам ручками не добрался хочу поработать с локи потому что сейчас прям hyip по этой по этому инструменту сергей спасибо кому подарим книжку чей вопрос понравился но кроме колорного я уже половину вопросов забыл бывает алкор bio первый вопрос был а кто первый вопрос задала кто самым-самым перди привлечь здесь на обижался человек убежал принять тогда тогда а давай отдадим за вопрос про меня уже забыл у меня спрашивали вас все спрашивали спрашивали вот так было поднимите ваши руки кто вопрос задавал кто еще здесь с нами давайте он вон туда отдадим книжечку вот я отлично все выбрал самого бородат военным можно было просто не спрашивать"
}