{
  "video_id": "EkMuu5a6Ip0",
  "channel": "HighLoadChannel",
  "title": "Как устроен поиск / Андрей Аксенов (Sphinx)",
  "views": 909,
  "duration": 3206,
  "published": "2017-04-22T14:45:52-07:00",
  "text": "специалист по поиску широко известен в узких кругах веб-разработчиков и сочувствующих как автор открытого полнотекстового поисковика сфинкс в прошлых профессиональных жизнях веб разработчик два раза технический директор с уклоном в 3d графику системный программист писал много кода делал много презентаций управлял командами разработчиков чину продолжает заниматься характер скверный ноги свои попугая нет момент эксперимента заключается в том что значит вот обычно я готовлю слайды последний там год-два-три в ночь перед рождеством ну то есть там едешь в поезде или самолете и готовишь слайды потому что как бы а когда еще в поезде или самолете у тебя есть время но в этот раз они поставил на огороде два доклада поэтому вчера я готовил словить для первого а на это времени не осталось и поэтому имеет эксперимент заключается в том что мы летим по словам который подготовлен за последние 30 минут не пончо из этого получится вот просто так бы судить как обычно наверно мои проблемы так вот не куда-то надо прицеливаться и тыкай куда-куда прицеливаться куда-то туда она вот так вот работает там нет ни фига на этому нет он принес значит для тех двух процентов которые знают кто я представлял сниму для всех остальных его зовут меня андрей воронежской будем интересует поиском на холоде и всякая рассказываю давно и упорно стараюсь последнее время рассказать про space потому что не интересны как всегда можно задать вопрос куда можете так далее и тому подобное когда-то делал и беру когда делать всякую теперь делу и поиск надеюсь что после поиска будет еще интересно потому что как можно заниматься одним и тем же приглашаю всех на доклад который бы вчера хотя уже был в этом докладе сегодня буду рассказывать на самом деле все то же самое концептуально высоком философском смысле то есть ничего нового все это написано в книжках все украденное как обычно если подал бы его imac буду материть наверно хочу речь о конкретном докладывают мне про все эти конкретные слова которые там связаны с поиском не про какую-то конкретную систему во первых и не про 2 даже большие части наверно составляющие поиск которые наука с одной стороны и рынок с другой стороны исключительно про то какая там внутри технология иными словами как устроен любой поиск внутри принципе вообще любой потому что отчет делать и как он устроен именно технологические они марки то логически все же знают анекдот или этом возможно даже бы как некая неизвестная компания малоизвестна самом деле забыл поршень как и называется устраивал слепой тест и вешаем резуль результаты выдачи бинга это мы вешаем результаты выдачи гугла и просим людей оценить вот качество результатов поиска вот что там нашлось слева субъективного довольны или нет и и справа там вы довольны или нет вот люди значит кликают оценивают там чувствуют ответственность что они выдвигают перед но по а потом чепак имени местами логотипа так вот после того как то меняешь местами логотипа вытащить не меняешь качество резко меняется то есть качество выдача очень сильно зависит от той под каким поисковым мере чем очень сильно зависит от того какой атаковать логотип над этой ручке висит у вас остановить такой факт вот над несчастью значит манипулировать такими штуками я не знаю потом буду про тупые штуки которые про технологию они все расписаны в книжках например вот это мечтал он внимательно просматривать неплохая и ну и понятное дело не единстве до 2 вот момент еще более подробно о чем речь дело в том что поиск информационные который тот самый информацию и travel это штука достаточно широкая такая он от телефона что-то зазвонит прямо в микрофон а я глотку широкое в таком смысле поиском по ключевым словам как бы он не ограничивается далеко и близко все падает началось и сейчас поиска там не по тексту книжек изменить друг говорит библиотека то есть нужно 1 поисковая система в мире от наверно александрийская библиотека в египте то чтобы ты приходишь и там по названию включил исламу замотаться хочет найти какой-никакой поисковой системы карточки все эти библиотекари социальный библиотекарши значит у роговых очках это мини юбках или а сексуальные в роговых очках и maps юбках все эти архетипы еще нет можно преступников искать там как с одной стороны проводить оперативные мероприятия так и с другой стороны вот берешь отпечатка пальцев снова собрал частичный провел там понравится форма этого дела там помнят декомпозиция там коэффициенте ким и считают потом этим коэффициенте коммуну начинаешь прибрать базу данных всех негодяев можно искать картинки по сходству как google и мое сердце у тела и так далее можно искать песни значит на ютьюбе которые украли по неким отпечатком звуковым это все информационный поиск это все поиски мы сегодня опять таки не будет говорить и ну или по меньшей мере перенесем этот мероприятия в кулуарах и тогда то уже вот с 10 до 15 можно так поверхностно пообщаться просто ради брату поиск по тексту вот такой он точнее не по на 4 условной стадий которые я выделил ну понятное дело данный надо отключить например спустить паучка и чтобы он их собрал с веб-сайтов и например взятия отсканировать 512 миллионов страниц или например как то еще там со стримить свитер с получения данных он сильно зависит от предметной области с одной стороны ее мать несчастью был частью набора ты не занимаемся совсем опыта нет поэтому вещать буду про те три части остальные три условной стадии по которой что знаю индексация поиск масштабированием часть набирать который индексация то есть предположим что данный у нас уже есть большая куча текста и не текстом каких документов с ними надо сделать как как от все устроены по искам движке вот так прежде всего ну понятное дело надо эти данные если не тексту и превратить в текст то есть из подается что-нибудь вон у тебя там за еще тем или возможно возможно если мы хотим этим заниматься еще в добавок учесть разметку этого самого html и посмотреть внутри каких того вчера возможно обратить внимание на шрифт свет там прочие спамерских fox под названием давайте больше автомобиль фоне чего нет напишем детектировать такие штуки за счет этого анализировать и значит документ этот этап номер один который год у нас есть данные мы их превращаем в текст что понимает что данный не обязательно текст следующий этап это это понятное дело кстати опциональный то есть если у вас откуда поступает хорошо очищенные данные то у нас на входе просто сразу текст ну либо там хорошо сформированный как это по-русски xml-документа с которой текст тривиально выкусывать мгновенно если нет надо текст развалить на отдельные ключевые слова потому что именно это наш поисковый единицу так называемые токены вот тут уже сразу начинаются фока фокусы песни и пляски потому что talkin' это не вполне ключевое слово то есть не обязательно ключевое слово у нас самый яркий пожалуй пример там всякие значит сложные конструкции со всякими спец символами но там например эти and cis ампер синдика мой любимый пример потому что заранее априорно может быть неизвестно как его развод у него что при тировать поле ампер сиддик считать одним словом то ли ключевым словом там и разваливать его на два или три ключевых слова вот в этом значит тонкое ключевых тонко отличие между такими ключевыми словами то что этот человек считаешь ключевым словам она с точки зрения машинной обработки за всяких странных спецсил может не вполне этим ключевым словом является приходится скрипнула мы сбили изгаляться ну например разгоняемся так что вот этот самый инси инси или любое другое королевство с пятью раме точками про ценниками минскими собачками долбаными twitter скими мы его индексируем по два раза по два раза иногда и по три раза во всех возможных вариантах считаю и не считая спец символами пробелами в dota майнинге говорят до сих пор очень любит нашу это такой фичи это обязательный процесс потому что очевидно я стать есть гигантский шматов top100 никак кроме как простите гриппом ты по нему искать не сможешь тебе его надо разделить на те самые токины установку ключевые слова по которым затем будешь искать после этого очередной опциональный шажок мутантам жирным не выделен следовательно опциональный это патологический обработка ну на самом деле штука тоже не обязательно она как бы всем привычно что вот есть 2 поиска он всех там приучил что мы как-то учитываем морфологии возможно даже переписываем запрос чтобы он ответ отвечаю так балла но опять же в зависимости от требований эта штука опциональная иногда важно иногда не важны и даже вредно бывают такие странные you спейси когда люди наоборот хотят искать по точному совпадению поточной по строке и так далее убийственный должен кейс на самом деле заточен потому что быстро быстро по одному ключевому слову найти список документов по другому их быстро пересечь и вернуть отранжировать вернуть результат те люди приходят и говорят строчки по теперь отстрочки там при изменении пришел отсрочки со всей разметкой с запятыми суток пробелами проценте каменских этими знаками которые потеряны символами являются проектами которые считают вообще частями снова начинаешь писать или поток собственно быть но и морфологической обработка ну это же самое она не папа терками иногда нужно иногда очень важно потому что в языках типа русского очень высокая в мире обильный сна в зависимости от той в каком он там падеже форме числе и так далее ну вот еще пара вот там странных аббревиатур которые на слайде есть пиво с iwsd это соответственно назначение идентификацию частей речи а это в спине что ген герани и частей речи мы смотрим на этот текст который назвали копны как на ключевые слова и пытаемся почесать репу понять а вот значит что же это за слово что это за часть речи и иногда если значит совсем сильно угорели и местам там как бане 15 лет писали марв обработчик в яндексе а теперь вообще заняться нечем они начинают невозможно пытаться понять этот банк вот это банка которое в тексте нам встретилось это это вообще о чём это банка москвы активы банка москвы составили там что-то там или это банка реки при силе там приморская то есть понятие что это за через речи с одной стороны прилагательное и существительное так далее и можно пытаться понять что значит ли что быстро выходим инфологической обработки и хуже того даже в пределах одной сети части речь может быть определенная неоднозначность вот банка банка то есть по этой слова ферме самой по себе не понятно о каком значении слова банк или там этот банк сочинительный пункта это существительное банка ripped марки вот пытается эту неоднозначность люди снять за ночь как близкие решена и все это как раз называется дабы гвоздева лицензии забегаешь снятием аниме и снятия неоднозначности задачи ну как бы с переменным успехом решаемые в достаточном самобытных системах типа яндекс своего дома перекусили места на троицу но как и любая задача обработки естественного языка она до конца еще не решена и вряд ли будет когда нити решено вообще потому что языком такой существует сильно многогранное большое и и правилам не поддающийся просто как мы всем этим значит увлекательным фаршем позанимались у нас были какие-то данные непонятно сколько документов но выбора из них текст развалины ключевые слова причем и снова прогнал через марта магическую обработку если совсем делать нечего попытались назначить части речи понятия чай встреча теперь самое интересное то есть но вот у нас есть пачка таких ключевых слов с примерки документа делать с ними что по-прежнему еще делать не может надо сделать следующий ключевой шаг создателю полнотекстовый индекс несколько идей формата скажем так победил один так называемый инвертированный индекс он вот так буквально не как первая часть общем не как там моя всей евангелие подряд а то такая же штука в конце библии это красный ментальная модель на самом деле вот если кто никогда не ну ладно читал это слишком сильно и требовать эту зубодробительный совершенно текст не фига не понятно опять же в конце почти любого издания библии есть так называемый конкордат то есть длинный длинный словарь вообще всех интересных слов ну за исключением там предлогов и матерных частиц которые в этой самой библии есть с отсылками либо на страницу на которой этот ключ в основе встречается либо на в отдельных случаях когда особенно матерый там кардан еще и на так называемый стих прекрасная модель полнотекстового индекса конский словарь и в этом словаре у нас есть указатели на странице стихи это в год горячо тени номер слова этом самый стихе pool data копаешь не доходит вот xpeeps устроим точно также можно писать за 15 минут при помощи mais quel значит кто не умеет пользоваться мой спальник я внезапно осознал что можно взять в ворде буквально берешь worlds и реально там на страничке выпустишь про текста индекс ничего сложного нет потому что принципа ему концептуальный значит сильно упрощена вся структура которая там есть большое большое соответствие между ключевыми словами и документами и чтобы к несчастью все эти 3 строчки они важны и нужны вот тут uniq ключ покемоны только один должен быть и должен быть именно в таком порядке учета к инвертированный индекса значит мультифункциональный к 5 структур который хранит ассоциации между ключевыми словами документ 1 и которая дает нам по ключевому слову быстро быстро выбрать все соответствующие ему документы 2 то есть понятное дело только как это сделать вам из ворда плюс взять тоже сам написать 1 текстом первая строка слова такое-то , номер документа , номер документ и так далее или наоборот там слова номер документа на второй строке слово номер документа чтобы быстро было искать возможно поэтому я против и все отсортировать по приему слову вы и номер документа построили по на тексту индекс в барде маленький незначительный нюанс он называется вот так google google знать что испортил человеческие проще вы все хорошему поэтому пользователь тогда вынужден искать использовать с использованием вот такого вот индекса в котором есть кейворды только один вылет вот так то есть в принципе во всем доволен и так бы весело корпоратив но чего-то не хватает или например чет не хватает причем формально пользователь как докопаться не почему то есть маленькие недоработки перечислены на слайде который этот движок и особенно движок который вы масс ворде и там исполнение запросов в котором осуществляется человеком который вас мордовский документ читают вслух не очень хорошо по сравнению с современными значек матерыми движками устроен что же делать например чуть подробнее но для того чтобы что то делать надо понимать с чем это что-то делаем чуть подробнее про яндекс вот значит новый как раз слайд так кто рассказал чистый джаз приходит за полчаса и слайды рисуешь индекс на самом деле устроит грубо говоря вот так это примерно половину не правим даже может может меч может больше но это скажем так это наиболее существенная часть данных индекс она должна быть устроена вот оплатить большой-большой словарик отсортированные по словам иначе мы в нём упаримся полным перебором все искать и к каждому слову нас при тренд список документов при этом список документов он здесь тоже на минут на отсортирован по номерам документов потому что если он будет несортированный то опять же с по одному ключевому слову нам искать будет легко и непринужденно а вот пресечь два списка документов хотя бы для двух ключевых слов мы уже упаримся то есть 2 в произвольном порядке два списка в которых чисел кино мира документов раз произвольном порядке ну блин алгоритмическое сложность квадратичное проще заранее отсортировать а потом линейно там как кнут завещала сливать два списка вот оно устроено вот так случае это сильно упрощенная модель потому что там еще там масса всякого фаза должна храниться но концептуально подчеркиваю в ядре бога поиска будет лежать вот такая же штука там обязательно будет гигантский словарь так или иначе в том или ином виде там обязательно каждому слову будет привязан длинный длинный список документов и обязательно этот список будет отсортирован если в список и соответствие привязанные к каждому слову список документов но иначе никак то есть базовая структура именно вот такая все что есть сверху это вот всякие дополнений оптимизации так далее понятное дело можно придумать чуть менее чем миллион проблема такая чтобы тот всякую был на этом слайде вот там эффективность ранжирования сортировка и так далее для того чтобы делать эффективное ранжированием как минимум и всякие штуки типа операторов поиска по фразе близости и так далее во вторых нам к несчастью нужны не только документы я не стал за принять преимущество и всем этим делом но типичном и вдобавок этот новый документ еще вдобавок иметь способ позиции внутри этого документа кстати уже начинается начинать всякие разные возможности можно все в один файл складывать помолюсь им как раскладывают всем все наоборот это все разнесены по двум важным файлам они не списка в документов отдельные не спуске позиции выяснила отдельно то есть вот тут уже начинается всякое время есть что данное можно по-разному разложить по разному пожар перезайти так далее но сами данные всегда одинаковые все равно что любом по тексту движке у вас все равно будет ключевое слово все равно будет соответствующий ему список документов все равно для каждого документа если вообще в принципе позиции поддерживаются у нас обязан там быть списке позиций но на самом деле без позиции еще особенно интересно не сделали к несчастью эффективность этого всего но тут опять же ключевой момент если не дай бог сохранил то все в городе в общем плохо машинной обработки документа затруднено если мы храним вот все вот этим мешком в кавычках за 15 мин который в базу кладет и keyboard еда пойди получается что у нас на борту она один раз присутствует в базе у нас вместо одного вхождений слова там высечки присутствует масса копий васичкин 7 васичкин 4842 васичкин 1917 то есть все капли слез на каждое обхождение слова либо на каждое соответствие ключевое слово документу либо не дай бог this у нас есть позиции на каждое вхождение слова она каждый раз копируется в такой гибели структуре еще нам надо сохранять идентификатор позицию возможно всякую морфологической информацию тогда и тому подобное и такой размер вот такой дебильным индекса которыми положили в базу данных он сильно разбухает и может дорасти в итоге размер базы да там нескольких раз от размера текста это очень плохо очень неэффективным совместим как это все можно устроить два ключевых приеме на предмет того чтобы устроить существенно более бодро это сортировка и сжатие данный они как бы их на самом деле сортировать как то разумно в любом случае даже там где зависимости от того собрать 100 бежать или нет потому что иначе он в самом деле пони сортировку мысль его рука отыскать упоминула если долг под строчку по маске там будет тяжелое по сортирует всегда все проще и поверх этой травиться сжатие примерно вот так на пальцев берем какой длинный список документ понятное дело что с коротким кстати списком документов особо ничего не сделаешь ну как максимум посчитай сколько на самом бить нужно на хранение этого удобного идентификатора документа я за кодирующего минимальным количеством бит основные значит основная экономия наступает в тот момент когда у нас есть длинный длинный список документов для такого снова моему меняем на дельты она отсортированный следовательно каждая дельта будет положить нам и более того больше либо равна единице только от этого пока не видно никакого но уже можно заметить что амплитуда скажем так числа когда становится меньше то есть у нас в списке документов самих ну просто длинные возрастающая последовательность чисел начала им надо всего восемь бит это халява быстро кончается очень быстро и нужно засрать все 32 бита и как хранить такие число эффективно никого понимание после того как мы их заменяем на дельты реки в этом сам пума текста с атипичной махонькие то есть есть один pequod 1870 при прыжке от номера 42 км умерла 1917 от этих пиков этих пиков не удастся избежать на в среднем в среднем просто так мы устроили труб и сдт кодированием у нас абсолютное значение вдоль будут в среднем меньше чем самих исходных и чеснок после чего медь и самой дельты су ён хва какой-нибудь классический код и либо битовый там хоффман арифметические так далее либо что более интересно байковый не помнишь в этом на следующем слайде анонсирование критуется хорошо значит минута история сейчас модно вот прям текущее состояние науки искусственные техники скажем так использовать интересные такие штуки под названием блочные кады то все это человечеству дошло ни слова ходила лет 50 то есть еще лет 50 когда значит мы занимались не тем чтобы мы как раз и не тем чтобы новый айфончик выпустить одним чтобы например взять и послать космический аппарат который бы совершил прогулку по всем планетам в системе задач компрессии данных уже вставали вот товарищ галлон по моему он меня забыл увы и ах позор мне для того чтобы видим сигнал джим которые передаются космического аппарата на землю вот он как раз придумал битовый код этом одноименного этого самого то ли улица толе голом бы кажется рез чтобы махонькие числа передавать маленьким количеством бит потом есть нос назначение 3 шаг на него трать 32 бита давайте лучше закодировать там в два бита длину что у нас нам на два бита на то чтобы значение 3 передать я еще в 2 бита передадим само значение 3 и давай потратим там четыре бита для того чтобы закодировать значение соответственно 1025 нам надо там четыре бита передать длину там и еще там в 10 бит передать само значение куда эффективнее чем сжатия куда эффективнее чем значение от храните в явном виде а каково явный вид может сожрать там невероятное количество бит но не чувствую жмут такие микробы данные достаточно хорошо но современные машины с ними работать не любят то есть они машины не любит ковыряться в битах для них доступ к отдельному битого отдельного бой то что в памяти что в регистре тубу блин муторно геморрой на занятия почему ветвление постоянной в зависимости от алло малик там единичка или что то есть это такая опасная штука которая вот там у некоторых как обычно у некоторых типа индекса любой так далее вырастают до дна ужасных нагрузок и соответственно надо куда эффективнее умеете сжатый данные быстро-быстро сжимать поэтому постепенно придумывали новую тройку под названием давайте же чуть похуже но кот использовать по байтам и с которым процессору удобнее всего работать и еще через несколько лет после этого придумали еще один кот он на самом деле кучу вариантов кодов так называемых точных копий наглядный скриншот как это все устроено идея мудрым лишь достаточно лет десять-пятнадцать о том как можно быстро быстро циферки сжатии war and mana вот так устроен там на каждом работаем исключительно с байтами и это хорошо процессору любят работать с байтами он лучше байт работать либо только с бородами верхней бит маркерной который означает есть там значение дальше нет нижнего 7 данных вот тем самым и какое-то значение в котором там на глаз сколько четыре бита в первом войти значащих плюс еще 16 backup на 20 битное значение пожали в 24 бита сохранили 24 бита понятно что меньше чем там в 25 раз нужно пожать само значение этому за исключением всяких поиск повторений так далее из матки сделал 24 там прикольно google придумаем возможно не только было на самом деле кучу разных людей придумал постепенно еще крупном ты там еще более эффективный код когда мы отдельно храним глины байт потом храним сами значения почему я на этом значит останавливает восхищают тот факт что человечество 50 лет значит работают над всякими технологиями сжатия и до сих пор продаются какие-то примитивные совершенно схемы типа либо варианта либо буковского но и не только гугловской групп гаранта по грузовым сформулируем так груб заранта которая первое второе третье 1 блин добраться до того что можно взять в одном бантики по два бита отвезти на то чтобы хранить 4 длины следующих 4 идущих значений после чего сохранить эти самые значения минимальным количеством брать все это хорошо уложить на архитектура современных процессоров поставить реальные деле понятно каждому баран даже мне но она придумана вот совсем недавно во первых она дает на буче практический эффект и вот получается что вот в этой вот на руки которые прожать и данных до сих пор значит есть где разгуляться и есть что интересного так сказать выжать есть таких интересных штук придумать и по на реализовывать меня это нападками на восхищаешься значит 50 лет боролись и вот тем не менее до сих пор фронтиру близко можно его пощупать руками вверх все этой структуры то есть с миной вот ради чего все эти пляски со сжатием а не ради того чтобы нашу примитивную структуру где там словарик дельты там снова точнее номера документов которые превращаются в dota эффективно сжать насколько эффективно кстати о птичках если у нас в яндексе не хранятся позиции слов во первых если выкинуть массу ненужных собственных во вторых если в общем забраться скажем так задачей максимально пожать индекс то отличие от нескольких раз до которых может распухнуть при хранении в ворде в базе данных индекс можно пожарить совсем крохотных величин там порядка 10 может быть 15 процентов от размеров исходного текста с позициями ситуация менее шоколадно там удается выполнить где-то до 30 в пределе и это невероятное хорошие результаты там скорее 30 и 50 размеров от исходного текста и у нас тупом около 70 80 процентов получается если без стоп-слов со слонами не помню но у нас не самые далеко и эффективный код у нас как раз working group групповой war inc как будет сделать до сих пор не удается почему это важно это важно по той простой причине что чем меньше у тебя данных тем меньше данных надо обрабатывать чем это все дико важно потому что объемы большие тебе этом на каждый запрос в худшем случае необходимо воплотить кучу данных и как бы опять же google всех приучить плохому что у тебя на каждый долбанный запрос со всеми подряд стоп словами должен удаваться в меня и мой ответ я вот старенький и еще помнят о святое время когда у куклы был понятия стоп-слов то хоть что-то запросит у be or not to be и как бы ожидаешь что тебя значат полное собрание сочинений шекспира вот идут на на самом деле ту би ё интерпретируется как стать этого остается для поисков несколько слова почему-то нот вот смысле понятно почему ну всем прикольно поэтому слова осуществляется поиск и догадайтесь потом страниц выпадает первый выпадало когда-то давно вы догадаться по мне возможно первой странице выпадало страницу гну . так что есть все она свободный и конечно потому что сок на дно рк со всех подряд зеркала невероятное количество вот результате туба именем в результатах поиска довольно долгое время пока google как бы не докупил еще пара-тройка миллионов фермеров и не научился ловко дра обрабатывает стоп-слова вот повторюсь значит губам всех использовать везде ожидании изменились о том что теперь ты послана на тубе все-таки те выдаст полное собрание сочинений шекспира уже веб-сайт гунны по понятным значит разработчику поисковых систем причинам на первое место выбрасывать по этому запросу недопустимо этим учиться поверх вот этих вот двух основных кусков который говорил словарь список документов есть еще кучу поверх те самые не части речи морфологической информация если есть возможно какие-то масочки полей возможно всячески skip листы bitmap и т.д. и т.п. повторюсь фокусов для того чтобы отдельные категории запросов и склеить либо ускорить поиск в целом поверх структуру под названием инвертированный индекс можно придумать много придумали много и многие из них используются в продакшене но базовая структура всегда одна гигантский сортированы словарь в каждом значит или медь к каждому элементу словаря слову привязан яблонский потенциально гигантский на самом деле для топовых слов гигантский для всех остальных быстро убывает по закону распределения ципфа список документов и список позиций все там ловко сортировка по же то быстро быстро зажимается при этом тем не менее фран серной ауте близко можно пощупать можно узнать что есть потратите теорию возможно придумать очень такой конкурентно способный новый клёвый код это интересно вот ровно на этом моменте в середине презентации мне сказали поставь точку но слава богу я так уважающий себя процессора я рисовал out of our door поэтому для оставшихся полтора частей меня тоже слайды есть значит как устроен индекс я надеюсь немного разобрались немного сталин а стала понятненько после этого всего делается собственный поиск там есть две большие части и 2 ортогональные скажем так науки постоянно конкурирующие во первых во вторых надо найти совпадающие с запросом документы после этого их надо отранжировать при этом это две вещи которые nouvelle vague чаду блогу если угодно то есть быстро быстро найти все совпавшее документы в том или ином понимании слова совпавшее с запросом и качественных отранжировать это два абсолютно ортогональны друг друга явление тоже быстро быстро найти на это минимальным количеством ресурсов найти все совпадения а качественно отранжировать это наоборот потратить максимальное количество доступных ресурсов но вы дать максимально качественный результат это все дело осложняется тем для деятелей типа нас которые пытаются делать вообще целевой поисковый движок тем что требование в зависимости от вертикалки бывают очень разные то есть вот требоний в поиске они примерно одни примерно там там внутри поиск одно общем мы скажем так актер запросов он простой пришел человек в вон те пару труп случайным образом насыпал ключевых слов пупсов поисковую строку и ожидать что ему дают хороший результат есть еще такой химера под названием поиск на естественном языке то есть попытки сделать так чтобы машина понимала что в тексте написано и якобы отвечаю на человеческим образом сформулированный запрос вот лично мне кажется что это религиозный вопрос лично и дорога пока не поддерживаю но с одной стороны с другой стороны ловкими переписывания my запроса то есть там например как зовут как какая должность если запрос какая должность у васи петрова переписать и расширить вдобавок фразы а давайте заодно за матчем все документы в которых написано вася петров был назначен на должность бла-бла-бла то наверное результаты поиска будут тоже адекватны вот такие вот правило переписывания верю а вот химера под названием давайте нарушим у робота там понимать что написано в тексте этом так сказать учитываться в суд и писать небольшой небольшой четкий реферат после чего сдавать кандидатский минимум вот в это я не очень верю в отдельный мир типа называется да это майнинг там совершенно другие требования там я вместо чтобы живой человек в строчку поиска в несколько ключевых слов приходят аналитик годами грудь свои запросы для аналитики вот меня интересует знаешь как люди о чем люди пишут в соцсетях про мой бренд давайте введем ключевое слово с мусором долго потому что меня в бренде каком-то мне частотное слова давайте напишем 100 правила исключений теперь давайте отфильтруем вот еще 200 прорыв из . его ведут запросы в итоге у клиентов которые этим занимаются топовым по-моему он бог отрастить обидно но и там пять тысяч ключевых слов они тут еще очень интересно там все повязаны через разные запросам давайте групп квартам поищем сразу барак обама аляска там по еще через орт поющим фразу барак обама техас и тогда альтам подобное но при этом не будем искать таким заражение который в принципе ты никогда не увидишь в поиске также для того чтобы ввести такое выражение в поисковыми строй потом для человеку придется там зато как видимо даже не знаю что за х к то есть не сам поисковый движок эту цепочку firewall и front end of который перед ним стоит нужно кто же нас предательского запрос длиной 30 килобайт в этом поиск это явно хотели добиться вот спим дальше он попросту все еще про простую часть под названием мачин то есть нам надо все найти ну и тут опять два момента попытки с общественным поиском бывает над найти все просто по тексту то есть вот эти сами вожатые списки ключевых слов пересечь ее счет из них вернуть надо найти еще вдобавок повесить ограничение но тут довольно все понятно что не там где у нас ограничений по ключевым словам это вымывается в операции над списками как кнут завещал перелом подтягиваем с диска либо из памяти эти самые сжатые списке их отжимаем пересекаем случае оператора and сливаем случае оператора он и так далее то что поверх этого если поверх этого надо сортировать по цене зарезать диапазоном да ты так далее но это делается при помощи самого вот этого полнотекстового индекса где словарь и ключевые слова это делается при помощи дополнительных атрибутов которые привязаны просто к самому идентификатор документов у нас с памяти лежит отдельный блок и мы быстро быстро по нему находим по индикатору документа нужны атрибута томсон автора идеи там в люси не по моему все эти штуки лежат прямо в яндексе хотя честно говоря но не смотрел в общем опять таки детали реализации важно то что вдобавок на текст участие у тебя скорее всего скорее всего практически в любом там современном так скрытую окладе у тебя вдобавок к самому документ будет приклеен ряд циферка 3 дополнительно надо используем то есть довольно похожи на базу обычную ценную но таким сильно отличается в двух моментах вот эти запросы которые там например для списка ключевых слов пересекают с точки зрения реляционной базы можно выразить в терминах либо junior либо минус операторов вот база такие штуки спал они в порт данные хранят крайне неэффективно у них никак не жмут много раз дублин тост ту часть где слово кейворды так далее и если попытаться тут запрос выкинуть на базе его можно сделать на бой здесь можно создать таблицу keyboard dock айди это будет настолько ужасны эффективно что краю это потому что не слишком общий недостаточно оптимизирована формат хранения раз и недостаточно хорошая поддержка соответствующих операторов union -2 и второе отличие которое значит за которой тебя с потрохами сожрут в какой тиверцев типа социально вот этим они для этого хуже поиска по юридическим текстом но которая канаде в поиске это то что если ты нашел примеру на документов-то с высокой вероятности можно остановиться на этом месте остальные 27 миллионов сообщений обыскивать то что здесь высокой вероятности в этих структурах миллионов уже будет достаточно хороший ответ достаточно качественный ты его пользователю покажешь меньшей меч мы переходим все более и более на мой взгляд интересным вещам более сложная часть под названием ранжирования заключается в том что он вообще не решаемые задачи потому что красота в глазах смотрящего жевательный запрос документу или не релевантен по хрен его знает это зависит и нет документы нет запроса это вдобавок зависит от пользователя которые этот запрос который ожидает какой-то результат получить что то момент в виду под своим запросам у науке неизвестно вот мне где там был пример вот а вот же например при сижу вводим в post запрос из наваливается значит 4 документа каких-то на самом деле существенно больше ну для примера пусть будет 4 какой из этих документов вообще релевантен запросу правильный ответ не существует в зависимости от того что именно в виду пользователей что имел ввиду пользователь может быть либо каждый первый из них либо ни одного либо вообще все и так далее еще раз люди расходятся в своих оценках релевантно но или нет спроси трех разных человек приставки ge птицы knits первый большой любитель огнестрелом 2 это мои любители писать документацию для питона причем они возможно 3 4 так болит четыре разных человека могут волне cricut в разные результаты поиска считать разные результат поиска релевантными вот так же быть если даже люди расходятся понятное дело что никакой автоматической обороны написать не удастся вообще в принципе ну поэтому вся борьба с качество поиска начинается ульях это большая головная боль для него для маленьких лавочек с человеческих оценок все всегда начинается с этих добрых человеческих оценок качества то есть сидишь любая куб не нашел хорошую различную коллекцию что запрос к dore vantin документу бы запросто номер один документ и и пользуешь и их оценка сидишь и подбирать их под соусом и заодно расставляешь это занятие кажется длинным и трудным на самом деле такой даст очень неплохую базу разметки можно собрать в достаточно короткий срок сами подумайте несколько минут потратили рабочий день сколько можно пар запрос документов самих довольно много десятки и сотни поверх дождаться наука от опять-таки меня в некотором роде восхищать потому что вся эта наука начинает свой дом не согласовывать возможно даже человеческих оценок но для того чтобы большую часть людей так сказать удовлетворить поверх этих человеческих оценок начинается нагромождение всяких разнообразных сложных математических конструктов поначалу легких метрики качества их но где-то там и проси жанре колы и масса еще ключевых слов но концептуально они довольно просты и то есть я люблю рассказать параметр престижем потому что это всего-навсего процент документов которые вот руки который мы показали пользователю пользователь черный land ным это уже начало с этим уже можно как то начинать работать проблема такая что это конкретно метрика не учитывать порядок не как она мало того что хотим просто документов хочу показать мы хотим его еще транжира вода сочилась какой то есть всплыть на максимально высокое место на первое поставить на второе поэтому человечество придумало достаточно оперативно причем еще несколько штучек которые очень грубо говоря устроены вот так то есть попадание релевантных документы на более высокое место мы даем болен большой вес то есть если при сен'джин это грубо говоря если считать что у нас факторы land насти бинарный но он либо единичка то престижен это всего-навсего в предыдущем примере престижен точность от все равно 25 умножить на рыло нтн или нет плюс 0 25 плюс 0 25 так далее эти веса можно поменять и получить вот такой взвешенное среднее на самом деле вот это абсолютно неверно абсолютно на самом деле метрика под названием юрьевич престижем считается существенно более более муторно сложно и вообще не так но смысл смысл такой что мы а когда оценит берем человеческие а целой человеческие оценки нолики и единички пытаемся по ним какую-то циферку посчитать которую собираемся оптимизм мы вот грубо говоря более высоким позициям вылечат даем более высокий вес после чего понятное дело по 1 запросу нельзя делать никаких революционных выводов надо этих запросов оценивать ее усреднить большую кучу и именно это является целевой функцией качеству мы по меньшей мере но в данную историческую секунду еще раз вот у нас есть куча запросов сотни тысяч и возможно десятки сотни тысяч для каждого запроса у нас есть какая-то пачка документов для этой пачки документов люди живой человек возможно даже не один написал нолик либо единичку в худшем случае в лучшем случае он еще и году на оценку на этом поставил пушка летом от двух до пяти например и по каждому запросу там для того чтобы проверить новую формулу ранжирования то чтобы сравнить две системы мы берем гоняем запрос смотрим на выдачу подтягиваемся оценки прописные которые есть и оценки которых нет мы считаем что они не голодны потому что не можем уже в самом деле считать а примерно релевантными считаю вот это взвешенная среднего средняя для одного запроса получаем каком то значит непонятную цифры на дачу значащую под названием средняя точность запроса усредняем все это поверх еще куча запросов и получил вот некую метрику волшебную то есть количество уровней которые как-то сказать количество уровень последовательности если угодно которой который нам встроенный между по настроены между человеческими оценками ноликами и единичками двойками тройками четверками и пятерками и вот это вот одной целевой метрики который мы оптимизируем когда работает над формулой не ну достаточно такое впечатляюще после этого следует с этим делать ну там хорошо вот мы научились считать так называемое качество какой-то циферку которой нам сколько ты показывает качество аранжировать так как хорошо мы можем мы знаем что оптимизм и знаем нашему целевую метрику цель себе поставили чтобы магическая цифра была не на 3 а 07 например ну или хотя бы на самом деле 035 ранжировать так как документы по прежнему не понятно тут немного на самом деле не изобретешь есть несколько цифр и все смотрят примитивной арифметики в итоге ну или там чуть менее рептилий примитивные алгебре но не более того в части формулу ранжирования примере есть называемый сигналы есть текстовые штуки которые можно посчитать по тексту ну то есть например вот у нас ключевое слово мы можем посчитать на сколько она редко встречается в коллекции можем вот одно ключевое слово встречается три раза в коллекции номеров документов а другой встречается 30000 раз наверное вот это слово который встречается три раза но более не интересно вот можно посчитать некую циферку га который называется иудеев документов и квинси обратно на частоту документов буквальном переводе которая характеризует это делать частоту вхождения слова в коллекцию можно посчитать может быть что ли количество вхождений этого слова документа можно можно их перемножить опять же можно получается уже какая-то формула ранжирования который придумал три сорок лет назад что интересно до сих пор одна из достаточно качественных результатов дающие одна из форм урожай до сих пор достаточно конечные результаты по дну всеми подряд использующийся либо как бы сливаем такой определенный механизм ранжирования эту форму больше нет смысла нет в википедию все интересующиеся посмотрит внимательно на то что она раз смотрит на статистику тупо на статистику сколько раз встречается документе сколько раз встречается в ой как его в коллекции насколько она редко и насколько часто встречается в документе и ещё немножечко учитывая длину документа с такой гипотезы что если документ покороче то наверно он более релевантно ну и всякие еще поверх этого сглаживающие функции есть что-то если документ сильно заставлен там слишком много и слишком многое честно оба рацион встречается ну на самом деле эта модель работает не очень хорошо надо наверно наоборот функцию там понизили не зря не повысить это пример одного из 7 который можно посчитать на самом деле современный пускай этих сигналов считают десятки сотни возможно даже тысячи и получается гигантской оптимизационная задача вот у нас есть сотни и тысячи сигналов у таких одним из которых является например функция db25 но на самом деле может быть там десятком из них являются разные варианты функций b25 и еще там 30 полей которые вообще никак стен в общении как с текстом документа и текстом запрос они связаны ранг вот раз домена там флажок это не в кипе delete случайно флажок а не пора ли это случайный так далее и тому подобное все это куча разнообразных переменных и иного так-то смешать придумать формулу у которого у которой нет у которых в принципе нет и быть не может никакого аналитическое выражение мы это формула в свою очередь для каждого документа каждого запроса даст какое-то число так называемую релевантность с помощью толерантности надо резаться переставить она порождает и те документа которым из матчей они же не меняются меняется в зависимости от такого форму ранжирование мы используем только порядок в этом множестве смачных документов таким образом этот вот адская форма прождать некий порядок на множестве этот порядок на множество мы натягиваем на человеческие оценки перемножаем там вес которые условно говоря вес соответствующей позиции на поставленную человеческую оценку все это сворачиваемся time композитный метрика все это пытаемся оптимизировать на идее не руками не классическими скажем так методами оптимизации с первого курса это делать нет никакой человеческой возможности для есть такое целого под наука отдельное под названием машинное обучение которое договора занимается конструированием алгоритмов даже не не решения задач алгоритмов которые будут конструировать вот такие формула им тоже таки оптимизационных задач высокую порядка приема слабо бы не полезем в руме не потому что нет уже совсем я и так уже наконец поступаю третья часть под названием масштабирования должна была быть я всем благодарен кто пришел в такой ромбик 10 утра потому что если бы мне не поставили до 6 утра еду лично опять же проспал поэтому все что знаю про масштабе ранее рассказов лорак рассказывать быть немного просто потому что порядке они изображены на слайде это порядке то есть я бумаги дам сколько блага конкретно машин 500 тысяч или 5 миллионов и он не дам сколько индекс конкретно машин 7870 веллитон 40 2319 но предки именно вот такие и привести их здесь хотел равно одной простой причине до тех пор пока вы не гу и не lindex у вас скорее всего поисковый plaster скорее всего можно пихать в существенно меньшее количество машин и ряд проблем с которыми приходится сталкиваться google дык sonic обочине инженерно интересно и так далее но она практически не ночник масштабах за исключением тех самых ли поисковиков с ними сталкиваться даже не придется потому что все обслуживаться существенно более скромными фирмами ну понятно и делать процент боев на миллионы машин на 10000 машину на одной сотни машин 2 большую разницу вот поэтому слава богу или наоборот там тоска тоска у меня свой опыт эксплуатации миру больших кластеров постичь машин нет она небольших объемах ну все достаточно тупо то есть все стандартные слова которые говорят на каждой первой конференции тут за шарди вы там супергерою результаты есть чтобы копы для всего есть отдельно но все еще пока работает никаких гигантских систем под названием давайте автоматически сюда палец эрин чтобы она там автоматически поднималась после сбоя от боев одновременно миллионы машин будет происходить на 1 или 10 тысяч машин их нет хуже того безлистный флагманской внедрение по количеству поисков у нас кто-то запросов в сутки обрабатывает 300 миллионов прокатиться на 30 машинах и скорее возможно эта оценка это оценка сверху на самом деле им опытом на 10 машина крутится поэтому все что я хочу сказать имею возможность сказать про мы шли обирания но масштабы этой части которой поиска но видимо вот что вот к чему сводится не пугайтесь масштабирование ваших примеров дорасти до такого значит либо чтобы возник лишь страны проблемы порядка яндекс и google и тогда этому подобной скорее всего не удастся все равно скорее всего вермут существенно более маленькой проблему существенно более местечковый вот наш собственный хомячок и поиск на нем если его уже там запустили встроить он крутится на одной десятой машине то есть в каком-то в прессе ресурсов не живет совсем это почти все значит теперь можно задавать вопросы но поскольку меня сейчас выгонят то все вопросы придется сдать этих как их кулуарах примерно до обеда я где-то тут бегаю по конференция после обеда медленно и печально ухожу в туман поэтому те кто не успеет мне поймать чудо блокнот могут писать вопросы вот видимо он примерно такой он работает вот так всем примет это был капитан очевидность"
}