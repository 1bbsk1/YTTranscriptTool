{
  "video_id": "y68RLr825VE",
  "channel": "HighLoadChannel",
  "title": "Проактивная оптимизация производительности БД Oracle / Александр Макаров (РНКО (ГК ЦФТ))",
  "views": 5752,
  "duration": 2733,
  "published": "2019-01-14T00:11:07-08:00",
  "text": "а а кто работает вот так хорошо разработчики тестировщики так нету аналитики менеджеры проектов а ну все понятно в целом администраторы баз данных все хорошо у меня до позвольте представиться макаров александр я ведущий администратор oracle работу в рнк платежный центр несмотря на то что у меня так такая должности реально а днестре рулением как таковым не занимаюсь крайне мало группа в которой работаю группы экспертизы развития состоит из двух человек от руслан жиганшин уступал предыдущем докладе мы занимаемся целым спектром задач связанных с поддержанием комплекса с его развитием и вот в вопросы производительности являются ли нас одними из самых приоритетных вот и мы эти вопросы зачем с разных сторон одна из тем наш один из наших проектов это вот был проект по проактивной прими зации производительности вот ну давайте сначала немножко поговорим по поводу того что понимается под словом проактивной оптимизация производительности иногда мы это те мы занимаемся уже где-то года 2 иногда можно встретить такие точки зрения что проактивной оптимизация то тогда когда мы еще приложение запустили начинаем делать какие-то анализ вроде какой-то анализ выясняем что там не хватает какого-то яндекс или еще чего нибудь ну то есть это делается где-то на тестовых серверах вот а тем не менее мы в рнк а вот этот проект делали на боевых серверах и и много спрашивали и много раз мне приходилось слышать что как так вы же это делаете на боевом сервере значит что восстание проактивной оптимизация производительности ну и тут надо вспомнить по про подход который культивируется в itil и с точки зрения и тела у нас есть инциденты производительности вот это то что уже произошло вот и у нас есть меры какие-то действия которые мы выполняем для того чтобы инциденты производительности не происходили и в этом смысле они эти действия являются проактивными то есть несмотря на то что мы решаем проблему на боевом сервере вот тем не менее сама проблема как таковая она у нас еще не появилось то есть это агент не произошел мне бегали и не пытались решить эту проблему в каких-то какие-то сжатые сроки итак в данном докладе под пар активностью понимается именно проактивный смысле itil то есть мы решаем проблему до возникновения цедента производительности какая у нас была точка отсчета в рынка платежных центр у нас есть две крупные системы которую мы обслуживаем этот фотобанк и orbeez retail банк вот и характер нагрузки на этих системах он смешанный то есть что то что работают очень быстро есть отчеты есть такие средники средне средняя нагрузка вот и мы столкнулись тема что не очень часто но с определенной периодичностью у нас были инциденты производительности но все кто работать с боевыми серверами представляете что представлять себе что это такое это значит что мы должны все бросить и быстро решать проблему потому что в это время наш клиент не можешь получить услугу то есть что-то либо не работает вообще либо работают очень медленно а поскольку рынка платежных центр наша организация завязано достаточно много агентов клиентов то ну нам это для нас это очень важно да на для нас это что-то стоит если мы не сможем быстро решать эти проблемы значит наши клиенты будет то в той или иной мере страдать например вы не можете пополнить карточку положить деньги или сделать период вот поэтому мы задумались над тем что мы можем сделать для того чтобы даже вот эти нечастые инциденты производительности но тем не менее чтобы как-то от них избавиться потому что все-таки работать в этом таком режиме когда необходимо бросать все и решать эту проблему это не совсем правильно потому что мы там ставим спринт и и мы выполняем какие-то ставим планы работы на спринт и так далее и поэтому наличие инцидента производительности это отклонение от какого-то общего фронта работ и так что же делать и мы некоторое время подумали и пришли к пониманию к пониманию технологии проактивной оптимизации но прежде чем я расскажу про проактивной оптимизацию я скажу несколько слов провод классическую реактивную оптимизацию сценарий простой да у нас есть боевой сервер что-то там произошло кто-то запустил отчет какие-то клиенты получают какие-нибудь выписки в это время идет какая-то текущая активность на базе данных и вдруг в это время кто-то решил обновить там справочник либо еще чего-нибудь система начинает тормозить и в это время приходит клиент и говорит я не могу выполнить то-то и то-то и надо найти причину почему он не может это сделать вот и в рамках реактивного подхода у нас а главная задача несколько даже найти саму причину несколько устранить саму причину сколько первую причину сколько сделать так чтоб система работала нормально а с устранением 1 причина мы можем заниматься уже потом позже главное чтобы мы восстановили быстро работоспособность сервера и чтобы клиент мог получать свою услугу дальше и выполнять то что ему нужно там отправлять отчеты и так далее вот реактивной оптимизация как правило можно выделить две главные цели это уменьшение времени отклика вот то есть мы выполняем какое-то действие отчет выписку транзакцию какую-то и эта транзакция должна выполняться какое-то регламентное время и нам нужно сделать так чтобы это регламентное время вернулось в те границы которые для клиента считаются приемлемыми но с комфортными то есть он может быть она работает чуть медленнее чем обычно но он а то считает что это допустимо тогда мы считаем что это один производительности мы устранили и потом дальше начинаем работать собственно говоря на первой причиной вот это второй момент это когда идёт пакет к пакетная обработка там транзакции отчетов либо еще чего-нибудь тогда нам нужно уменьшить время обработки одного объекта из пакета значит какие плюсы и минусы значит у реактивного подхода самый главный плюс наверно такой что с ним более менее все понятно то есть мы имеем проблему мы можем посмотреть в инструменты мониторинга и посмотреть что непосредственно чем у нас проблема у нас не хватает цыпа у нас не хватает потоков у нас там не хватает памяти или у нас просело дисковой системы или у нас логе там тормозят медленно обрабатываются то есть инструментов и методик по исследованию текущей проблемы производительности вбд oracle достаточно много вот и еще один из плюсов это в процессе такой работы мы вводим ситуацию до допустимого времени отклика то есть мы не пытаемся его там уменьшить до самого минимального значения мы доходим до некоторой величины и после этого действия заканчиваем поскольку считаем что мы дошли до приемлемых границ вот ну и самый большой минус у реактивного подхода это то что сами инциденты производительности при этом остаются потому что как таковую первую причину мы мы не всегда можем до нее дойти она могла остаться где-то стороне и несмотря на то что мы достигли какого-то какой то при приемлемой производительности функционала при этом первая причина она могла бы быть где-то глубже и так собственно говоря как работать с инцидентами производительности me если они еще не случились вот попробуем сформулировать подходы каким образом можно было бы провести вот такую про активную деятельность для того чтобы предотвратить такие ситуации ну первое с чем мы сталкиваемся с тем что мы по сути не знаем что нужно оптимизировать ситуация ещё не произошла и мы можем только предположить что может быть она будет там или может быть там вот и собственно говоря мы понимаем что мы должны найти какие-то потенциально слабые места в системе и посмотреть на них и попытаться оптимизировать работу функционала с этими местами вот собственно говоря общие идеи такие то есть основные задачи проактивной оптимизации как вы видите не отличаются от тех задач которые стоят во время реактивной оптимизации то есть нам нужно избавится от узких мест вбд и нам нужно чтобы уменьшилось потребление ресурсов собственно говоря вот этот момент является самым принципиальным то есть случае реактивной оптимизации нам уменьшению ресурсов у нас нет задачи уменьшение потребления ресурсов в целом у нас только есть задача привести время отклика работа функционалов допустимые границы вот ну и как раз когда мы начинаем думать над тем а как же искать узкие места у нас тут возникает сразу большая куча проблем если мы попытаемся на тест он комплексе эти проблемы воспроизвести то есть моделировать и попытаться решить их то мы можем столкнуться с такой ситуации что проблема которая возникла на тестовом сервере она в общем-то никакого отношения к боевому серверу ними ну причин летом что потому что тестова сервера как правило слабее вот если есть возможность сделать из серии шкаф-купе была серия то это хорошо но и это не гарантирует того что нагрузка будет воспроизведено таким же образом потому что нам нужно еще воспроизвести пользовательскую активность нам нужно воспроизвести еще множество разных факторов которые влияют в итоге в итоге на нагрузку итоговую нагрузку которая сформируется системе и если мы попытаемся смоделировать эту ситуацию то по большому счету мы не можем гарантировать что мы смоделировали именно то же самое что у нас возникнет то боевом сервере если в одном случае проблема возникла потому что пришел новый реестр то другом случае она может возникнуть из-за того что пользователь запустил какой-то большой отчет с требующий там большую сортировку из-за которого темперы tables прислушалась и в итоге там система начала тормозит то есть причины могут быть разные мы не всегда можем и их потока дать и поэтому фактически от попыток искать узкие сервера на тестах на тесту узкие места на тестах серверах мы отказались самого начала ну практически самого начала то есть мы отталкивались только от боевого сервера это и от того что на нем происходит что же нам делать в таком случае давайте попробуем понять какие ресурсы первую очередь скорее всего их будет не хватать вот ну исходя из наших комплексов которого у нас распоряжении наиболее частых нехватка наблюдается в дисковых чтениях рецепту поэтому в первую очередь будем искать слабые места именно в этих областях ну и второй важный вопрос и собственно говоря а как искать-то вопрос такой очень нетривиальные но поскольку мы используем oracle мы себя нашли такое решение такой инструмент это в расчет и вот в подгрести например посмотрел есть аналог есть тот спок есть в profile андрея зубкова вот но последний продукт появился так понял только в прошлом году и более-менее начал развиваться вот просто спад не скажу ничего вот сам вот этот подход вот он в общем то не привезут какой-то конкретный базе данных и если у нас будет возможность получить информацию по нагрузке системы из какого-то отчета то применяя вот эту методику который сейчас расскажу мы сможем выполнять работы по практичной оптимизации на любой базе к сожалению промо из куриной задницы не могу ничего не я не нашел у них таких инструментов и собственно говоря я не являюсь специалистом по москве и так краткое описание то технологий проактивной оптимизации которые мы выработали у себя и который мы применяем воронкова платежный центр первый этап это нужно получить отчет о в р за максимально большой промежуток времени почему максимально большой промежуток времени дело в том что бывает так что нагрузка в разные дни недели на комплексе оно разное наверно рпц был банк у нас есть характерные день в неделю это вторник когда приходит и реестре за прошлую неделю не начинает обрабатываться и целый день мы имеем нагрузку выше средней примерно где-то в два в три раза в остальные дни нагрузка меньше поэтому если мы знаем что у нашей схемы есть какая-то специфика в какие-то дни нагрузка больше в какие-то дни нагрузка меньше значит отчетный нужно за эти периоды получать отдельно и работать с ними тогда отдельно по вот этой технологии вот это если мы хотим оптимизировать конкретно вот эти интервалы времени если мы хотим просто по бти мизер овать ситуаций у нас на сервере то можно получить большой отчет номер 1 месяц и посмотреть что же реально потребляет наши ресурсы сервера вот иногда там бывают очень такие интересные неожиданные запросы попадают например случается фотобанков иногда бывает такое что отчет который проверяет очередь сервера отчетов попадает в там в топ-10 например при этом этот отчет он служит этот запрос он служебный и он по сути не не является выполнением какой-то бизнес логики как таковой просто проверяет есть отчет на выполнение если есть взял выполнил вот и так получаем отчет о в р за максимально продолжительный период и смотрим следующей секции значит is clearly запросы по времени выполнения по потреблению циpкa по логическим чтением это год и респа физическим чтением то есть в отчете в r есть отдельные секции где ну зависимости от версии oracle от показывается там 15 и большее количество топовых операций топовых запросов вот в каждый завод этих секций но эти запросы оракал в отчете vr показывает вперемешку например у нас есть родительской операция внутренние может быть там скажем 10 запросов он в отчете vr покажет и родительскую операцию в сети все 10 запросов которые были внутри вот и поэтому надо сделать анализ этого списка и посмотреть какие запросы группируются но какой к операции имеют отношение к ее группируются и в итоге после такой группировки мы на выходе получаем список операцию уже непосредственно и можем в этом списке выбрать самый тяжелый 5 штук например ну вот мы ограничиваемся пятью операциями не запросами именно 5 операциями вот если системы какие-то более сложные тонн соответственно можно брать больше на пир 10 за время применения этой методики мы смогли собрать небольшой список типичных ошибок проектирования они бывают вот некоторые ошибки не настолько такие простые кажется что их быть не может бывает очень такие козы сны и случае вот как это ни странно и бывает даже случае с отсутствием индекса на боевой схеме вот и в некоторых случаях это выясняется он был конкретный пример у нас запрос работал быстро без индекса там было полное сканирование и поэтому на него никто не обращал внимания но поскольку размер таблицы роз постепенного наросла-то запрос начинал работать медленнее и из кварталов портал он чуть чуть чуть чуть больше времени требовал в конечном итоге мы обратили на нее внимание и когда посмотрели оказалось что индекс там нету вот поскольку мы не разработчики этой системы мы передали это разработчик мы соответственно эту ситуацию справили вот второй случай это большая выборка ну это достаточно классический случай полного сканирования все знают что полное сканирование надо используя только лишь тогда когда это действительности объективно оправдана но тем не менее иногда бывают такие случаи когда в плане запроса попадаются полное сканирование вот следующий случай наверное может быть даже самые распространенные почему-то про него очень мало говорят на конференции вообщем мало где я про него слышал вот это так называемый название эффективный индексы длинный range скан то есть это что означает например у нас есть таблица по реестрам и в запросе мы пытаемся найти все реестр и данного агента вот но и в конечном итоге добавляем как какой-нибудь условий фильтрации ну например закаты период или с каким-то номером или там какого-то клиента вот и в итоге что получается поскольку до индекс обычно строит как раз по вот этому агенту и в итоге что получается вот в первый год работы скажем у агента было 100 записей в этой таблице в следующем году не уже 1000 там еще через год у него там уже может быть десять тысяч записей там проходит некоторое время этой записи становится уже там сто тысяч и очевидно что запрос начинает медленно работать из-за этого потому что в данном случае вопрос нужно добавлять не только сам индификатор агента но еще и какой-то дополнительный фильтр но в данном случае по дате иначе что будет получаться иначе будет получается что объем выборки из года год будут увеличиваться поскольку объем вот этих объем таблицы или данного агента будет увеличиваться соответственно эту проблему надо решать на уровне индекса следующий случай тоже такой курьезный но тем ни менее так так бывает то есть мы смотрим в топ запросов и видим там какие-то запросы и когда мы приходим к разработчикам и говорим а вот ну вот нашли что-то такое давайте разберемся и посмотрим что с этим можно сделать разработчик как думает думай думает потом приходит через некоторое время говорит ну в вашей системе у нас дистрибутив мы его делаем для всех от вашей схеме вот этой ветке коды быть не должно у вас нету вот этого функционала вообще в принципе не используйте его вот ну и соответственно не потом включают какую-то настройки у нас начинает работать обход вот этого участка кода и не выполняется вот эти действия теперь я хотел бы рассмотреть два примера из нашей реальной практике вот иногда когда мы имеем дело с топом запросов мы конечно в первую очередь думаю над тем что там должно быть что-то такое мега тяжелое что такое нетривиальные какие-то там сложной операции вот ну на самом деле это не не всегда так иногда бывают такие случаи когда в топ операции попадают очень даже простые запросы вот как вот в этом случае данный запрос всего из двух таблиц казалось бы чего проще и что самое интересное это не тяжело и таблице они в принципе там несколько миллионов записи всего лишь и тем не менее запрос попал в топ то есть это один из запросов которые кушает много ресурсов ну давайте попробуем с ним разобраться что же с ним не так это is price менеджер клауд control картинка по на по статистике работы данного запроса оракла есть такой инструмент вот если мы на него посмотрим то мы увидим что есть регулярная нагрузка по данному запросу вот мы это видим на графике сверху вот циферка 1 с боку говорит о том что у нас в среднем не больше одной сессии работает вот и если мы посмотрим на зелёным этот кружочек он говорит о том что у нас данный запрос используют только циpкa что вообще в двойне становится интереснее почему вопрос который работы только на цикл попал в топ но вроде казалось бы не должно быть такого ну давайте попробуем разобраться что же тут происходит я выделил табличку с статистикой работы по данному запросу в отдельный слайд вот давайте сначала посмотрим на количество запусков ну почти 700000 запусков наверно тоже этим никого не удивишь но 700000 вот но если мы вернемся чуть чуть назад то мы увидим что здесь интервала времени звезд слова time 15 декабря и и ласло вот тайма 22 декабря это этой неделе то есть если перевести это в количество запуска в секунду это получается один запуску секунду той запрос выполняется каждую секунду смотрим дальше время выполнения запроса меньше секунды ну в этом месте можно порадоваться это же здорово он работает меньше секунды что тут еще можно сказать про него он не тяжело запросу меньше секунды работает вот но тем не менее он попал в топ то есть он потребляет много ресурсов в каком месте он потребляет много ресурсов смотрим одессе строчка по логическим чтением мы видим что на один запуск ему требует почти восемь тысяч блоков один блок это 8 килобайт то есть если мы это перемножим то есть получается что запрос когда работает один раз он за секунду выгребает такое количество блоков вот мы видим что здесь уже что то не так но navi вот как раз надо разбираться почему такое большое количество блоков требуется данному запросу ну что ж посмотрим план данного запроса и мы увидим что здесь есть полное сканирование ну что ж пойдем дальше и что выяснилось что в этой табличке как я говорил строк немного всего лишь 5 миллионов вот и и среднее длина строки здесь небольшая но самое главное что здесь оказалась здесь не хватает индекса по этому полю который является соединителем то есть вот здесь под запрос запросам соединяется через поле я рнк и индекса по этому полю нет и более того даже если он появится на самом деле ситуация будет не очень хорошее чуть раньше когда говорил о типичных проблемах в запросах я говорил про инженеры раньше скандал 10 как раз та самая ситуация то есть у нас есть некоторые реестр и операции и эти реестр и операции ли данного агента они накапливаются вот я р-н кого-то как раз они который внутренней индификатор такого агента и они будут накапливаться с каждым годом количество данных которые будут выбирать этот запрос она будет увеличиваться запрос будут подтормаживать так итак индекса нет но и соответственно решение нужно создать индекс но не простой а с учетом даты тогда мы можем хотя бы как-то некоторой степени гарантировать что производительные запроса будет будет оставаться примерно в одних и тех же границах потому что когда мы добавляем в яндекс дату тогда мы знаем что у нас все конечном итоге упирается в объем операции которые были в течение там какого-то интервала времени то есть нам не нужно высчитывать всю таблицу и это очень важно очень важный момент ну и давайте посмотрим что получилось то есть у нас после оптимизации время работы стало меньше 100 секунды а количество ада было девяносто три сотых и количество блоков стала в среднем 8 с половиной а было тысячу раз больше так на чем здесь у нас все получилось хорошо следующий пример я вот начал с того что там обычно автобуса просто попадает что-то сложное это тоже это реальный пример это сложный запрос который в одной таблице идет и он тоже попал в топ запросов более того мы видим что в данном запросе у нас есть три условия из ну а как мы знаем они не индексируются такие условия то есть им нельзя использовать яндекс в этом случае и есть его лишь два условия с равенство тип тип равенство это поводе processing и по статусу наверное в первую очередь разработчик который посмотрел бы на этот запрос сказал ну давайте сделаем яндекс по процессингу и статусу но если посмотреть количество данных которые при этом выберется там их будет очень много то есть это решение не проходит но тем не менее он попал в топ запросов и и потребляет много ресурсов значит нам нужно что то сделать такое чтобы он стал работать меньше давайте по поводу попробуем разобраться собственно говоря в чем причины того что данный запрос попал в топ запросов это статистика работы данного запроса за один день и мы видим что он запускается каждые пять минут и основное потребление у нее получить цикл + диск вот если мы посмотрим статистику по количеству запусков запросов то мы увидим что целом у нас то все в порядке количество запусков примерно одинаково то есть оно не как в течение времени не меняется ну то есть достаточно стабильная ситуация плюс-минус небольшие вариации вот но если мы посмотрим время работы то мы увидим что время работы при этом меняется иногда достаточно сильно в несколько раз а это уже существенно вот но давайте разбираться дальше значит в oracle enterprise manager и есть такая утилита который называется сколь мониторинг вот и в этой утилиты можно посмотреть в реал тайме потребление ресурсов данным запросам вот в данном случае как раз для проблемного запроса сделан такой отчет вот тут много чего интересного есть но то что у нас 1 4 в первую очередь должно заинтересовать это вот яндекс range скан в нижние строчки которые требуют потребляет на выбирает вот эта колонка их челси астон и пчел аккаунт вот название немножко не пресс на 17 миллионов строк ну наверно 110 уже задумываться над чем-то если мы посмотрим дальше как выполнялся план то мы увидим что после следующего применения пункта плана из этих 17 миллионов строк остается всего лишь примерно 1700 спрашивается зачем мы сенат миллион 100 выбирали честно игре нам делать ничего что ли вот то есть этогого выборка осталось меньше одного процента то есть мы выполнили заведомо неэффективную работу ненужную работу более того мы выполняем эту работу каждые пять минут вот собственно говоря проблема поэтому он и попал в топ запросов вот ну что же давайте попробуем решить эту проблему как я уже сказала она достаточно нетривиальна такого индексы который напрашивается в первую очередь его не хватает явно не хватает нужно придумать что-то хитры и надо каким-то образом побороть вот эти условие зну вот ну и некоторое время мы посовещались с разработчиками подумали и пришли к такому решению мы сделали функциональный индекс такой хитрый функциональный индекс в котором есть вот эта колонка де processing которые там было с условием равенство то есть вот все остальные поля мы запихали в качестве аргументов в этой функции эта функция является детерминисты то есть она одном и том же наборе параметр всегда выдает один и тот же ответ вот и мы сделали так чтобы эта функция выдавала всегда значение но фактически в данном случае будет значение у большой он будет выдавать когда все эти слой выполняется буду большое когда эти условие не выполняется будет что-то другое вот оно будет вот и если мы создаем такой индекс функционале тогда мы получается не имеем возможность эффективно фильтровать данные и применение этого индекса привело вот такой вот картиночки вот тут четко видно старый индекс новый индекс 20 дней здесь одна колонка это один snapshot с напишут полчаса вот и так но видно что мы своей цели добились и этот индекс оказался действительности эффективным вот ну и собственно говоря и счастливы честно говоря плохо слышно ну тогда за потом зададите вопросик свой вот да тут время в секундах с левой стороны вот еще вернемся к этому графику давайте посмотрим там был ли у нас качественные характеристики теперь посмотрим количественные характеристики и мы видим что время работы уменьшилась два с половиной раза а потребление ресурсов буфер год в четыре раза примерно уменьшилась вот да и количество блоков данных которые считались диск диск они уменьшили значительно там больше чем то еще раз ну собственно говоря можно подвести некоторые итоги применения вот этой методике проактивной оптимизации вот то есть мы получаем снижение нагрузки на базу данных мы получаем увеличение стабильности работы база данных ну и то с чего я начинала доклад инциденты производительности они уменьшились примерно там как раз в десять точное количество мы не считали но субъективно где тот величина такая то есть если раньше у нас инциденты производительности проходили каждый месяц там 1 2 штуки были стабильно на комплексе rbs retail банка то потом они как то так сказать ну практически про них забыли вот и тут возникает у вас наверное возникает вопрос собственно говоря инцидента в производительности тут причем мы же не занимались именно прямую вот давайте посмотрим на этот график и мы увидим что вы помните там было полное сканирование 3 было сохранить в памяти большое количество блоков поскольку запрос выполнялся регулярно все эти блоки хранились в крыше оракла и он ими пользовался вот при этом получается что если в это время на базе возникнет какая тяжелая нагрузка то есть кто-то начнет активно пользуются памяти учитывать с диска ему нужно будет место cacilie хранение блоков данных то собственно говоря эти данные будут вытесняться часть этих данных будут вытесняться если данные эти вытеснили значит придется сделать физически чтение если придется дела физически чтение время работы запроса уменьшается уж мысли увеличивается сразу значительно увеличивается колоссально логически чтение этой работы с памятью это быстро происходит а любое обращение к диску это медленно это это миллисекунды получается если по временам смотреть если повезет и в кэше операционной системы или в кэше массива есть эти данные то это могут быть но саров но это будет десятки микросекунд если это берется из кэша самого оракла там получается времена очень маленькие соответственно когда мы избавились от этого полного сканирования мы нам уже нету необходимости хранить такое большое количество блоков в близко с доступности и соответственно когда этих ресурсов тонов происходит нехватка этих ресурсов запрос работает более-менее стабильно у нас нет таких всплесков больших как были здесь вот со старым лисом но вот такие больших не наблюдаются они есть до таких больших не наблюдается вот собственно говоря суть вот но и краткие итоги по применение методики проактивной оптимизация конечно же первичной оптимизацию нужно проводить на серверах тестирование смотреть как работают запросы и смотреть бизнес-логику чтобы что-то не делать лишние эти работы остаются но периодически раз несколько месяцев имеет смысл снимать полную нагрузку сервера и смотреть отчеты по полной нагрузке сервера и смотреть что там происходит и оптимизирует то что там попала в топ запросов и топ-топ операции так ну и несколько слов скажу про инструменты для получения статистических данных которые есть в рок ли и достаточно много это у нас и а vr это у нас а из h можно его использовать и squire мониторинг я показывал пример и вот и сквер мониторинг report я покажу чуть позже слайде ки вот и есть еще такой инструмент sql details актив report часть из этих инструментов работают в консоли то есть не привязаны к энтерпрайз менеджеру и ими можно пользоваться так да спасибо за внимание и если у нас еще немножко времени остается давайте я вам покажу несколько садиков с примерами работ и инструментов по сбору статистических данных вот это enterprise manager клауд kontrol s2 на то цен выглядит таким вот образом вот то есть верхний график показывает сколько связи с данным запросам работает в слева блок показывает сколько откуда запускается данный запрос в таких моделях он находится снизу информация по использованию шарит пола вот с правой стороны у нас получается вот эта диаграмма показывает событие ожидания которые системе данном случает только цикл поэтому это все зелененькая и снизу самое интересное то табличка с качественными характеристиками вот так они наиболее важны при анализе проблем производительности так москве мониторинг один пример чеки а там показывала раньше как это все выглядит являл тайме там дизель оника крутится это вот он часто работает так это содержимое внутреннее содержимое отчета теперь мониторинг он прям показать в реальном режиме времени какую строчку запроса он выполняет и сколько строк при этом он считывает вот колонка если пчела роуз вот в данном случае там уже сито на 5 миллионов вы индекс раньше scania вот в этом веселыми есть вот так вот текстовый инструмент искали мониторинг report вот в нем есть часть информации не вся вот и your details и актив report так давайте тогда с этим закончим и перейдем к вопросам грудень спасибо за доклад вопрос такой вы рассказали про достаточно ну может быть я не прав к что но очевидные такие моменты когда проблемы с индексами проблемы с какими-то большим выборками так далее интересуют как вы мониторите какие-то более сложные моменты например использований шарит пола простая как администратор недавно столкнулся с очень для меня странной проблемы с переполнением schritt пула и интересно мониторить или вы шарит по версии мы склеили и так далее вот какие-то такие более узкие моменты мун и мы это мониторим это входит задача нашей группы это не в рамках проактивной оптимизация это наш один отдельная деятельность вот в частности когда мы получаем отчёт фрс большие интервалы времени там есть один из разделов в но товары пива в мире это историй вершинка und и там бывает иногда очень любопытные случаи когда от данного запроса могут быть даже там сотни планов ему себя эту проблему решали как правило одна из главных причин которые у нас было на комплексе с этим связано это разный nls настройки на клиентах в целях да поэтому получается очень много плюс еще там какие-то свои там заморочки оракла где он реально находит разные планы которые в разных случай бывают по-разному эффективными но это связано с собяниным переменных то есть если гистограмм он использует он понимает что для таких то надо такое использовать для других значений другой план потому что выборки неравномерные вот ну вот кратко так напрямую у нас конкретно проблемой за шарит пула в чистом видении когда-нибудь то есть там кости на мы начинаем понимать что если парсинге идут часто им это даст ставим себе задачу что нужно понять вообще принципе что происходит шарик шарик пулом и и когда мы видим наличие проблемы делом отдельные проекты в рамках этого проекта решаем эти проблемы здравствуй спасибо за доклад вот давайте вернемся к запросу которую делали и вот последний да вот этот да не дерзнул которые вы делали индекс на основе этой самой вот вопрос такой вот дело в том что начинает тормозить я так понимаю когда достаточно большое количество строчек в таблице потому что вот реально если было мало строчек он бы умещался весь кашей вы проблем бы не знали обмоток и было с другую с другой стороны если вы на маленькой таблица сделаете вот такой вот яндекс как вы сейчас сделали он будет выполняться дольше правильно чем вот если бы просто ну вот так и есть то есть в чем их часть часть работы диска переложили кругу рэнд пол не совсем мы придумали эффективный способ фильтрации данных чтобы он лишние данные не выбирал с диска вообще принципе в этом в этом суть индексов да вот они были придавали можно сказать спросить сколько он строил они не там же все теперь на базе да да он строился недолго вот сейчас конечно я прибавляла лету на вставку нет у нас понятно что выполнение таких работ мы согласуем с клиентом у нас есть регламентные интервалы времени когда мы можем погасить и выполнять более того в данном случае мы могли просто остановить конкретный обработчик вот выполнить эти действия потом его поднять на 2 вопроса в таблице много запись откуда же берутся вставляют при вставке должен на лице иных повлиял этот индекс на производительность при вставке мы конкретно таких замеров не делали но обычно когда возникают проблемы индексы появляются с индексами нас обновлением индексов ворог ли возникают специальные событий ожидания индекс контент шин вот их не было то есть по наличию точнее по отсутствию вот этого события ожиданиям делаем вывод о том что это не повлияла на ситуацию значимым образом не повлияло"
}