{
  "video_id": "eWrRzOUaSBQ",
  "channel": "HighLoadChannel",
  "title": "REST-сервисы на ASP.NET Core под Linux в продакшене / Денис Иванов (2ГИС)",
  "views": 9734,
  "duration": 3585,
  "published": "2018-01-16T13:11:57-08:00",
  "text": "Привет всем Сегодня мы этот час попробуем поговорить о том как сделать сервис на spn под Linux запустить это дело в продакшн сразу скажу что информации в докладе сегодняшнем будет довольно много я буду какие-то вещи проговаривать быстро ВС будет презентации потом вы можете Поре если какие-то вопросы вас заинтересовали в то время пока я проговаривая Задайте вопрос либо после презентации либо где-то на территории конференции и мы обсудим если вас какие-то вещи будут интересовать более более глубоко обсудим Итак Меня зовут Денис Иванов Я из Новосибирска из компании дгис Кто знает компанию дгис все знают компанию дгис Замечательно а кто знает кто работает снем из тех кто прил все да все дотнет собрались здесь замечательно Так ну работа вги Я уже это сказал также я являюсь mvp Да Most profession награда которую предоставляет Microsoft даёт Microsoft Я mvp в области Visual Studio technolog вот на самом деле если опять же вопрос по mvp У вас есть то можем отдельно обсудить потом довольно интересная штука вот стек технологий А это Microsoft стек технологии и все ЛЗ которые там есть А зачем я сегодня пришёл сюда на самом деле для того чтобы поделиться своим опытом а разработки и запуска таких сервисов мы внутри компании их сделали А с с 1 апреля и это не шутка с 1 апреля он запустился в продакшн и работает на текущий момент уже там 2 по месяца Да чуть-чуть больше двух чем 2 месяца вот у нас есть определённые аа скажем так опыт эксплуатации прямо в продакшене поэтому все эти вопросы Мы тоже можем обсуждать О чём будем сегодня говорить кратко расскажу о самом сервисе что это за сервис Потом расскажу о том о той платформе на которой он работает тоже довольно интересная вещь а там есть свои нюансы дальше мы поговорим о том что такое dnet Core ispn Core и те базовые фичи которые нам хотелось бы иметь когда мы такие сервисы делаем а опять же из опыта дальше поговорим о том как как такие приложения билдить соответственно как их деплоить по факту такой CD Да поговорим о том как тестировать нагрузку на подобных приложениях и если вдруг проблемы при нагрузке возникают Они обязательно возникают в общем поговорим о том как скажем так применять стандартные Ну и на самом деле не очень средства для того чтобы повышать приложения так начнём В общем вот с 1 апреля как я уже сказал в наших продуктах двагис появилась Вот такая вот иконка А на которую можно нажать и начнёт проигрывать видео соответственно тот рекламодатель Да который вот у нас размещаются справочники он может прийти и купить новую новый способ размещения рекламы Вот и собственно все продукты которые у нас есть в компании Да там мобильные продукты онлайн а в общем все они ходят Вот как раз на тот самый сервис про который я буду сегодня рассказывать этот сервис занимается чем в общем топология Примерно вот такая сервис помечен обла в центре он по сути дела является эндом для продуктов Когда продукт приходит говорит Дай мне вот для этого рекламодателя всю информацию о видеорекламе сервис ему послушно это всё дело отдаёт в общем информация плана такого что вот такая-то обложка лежит на таком-то сине есть такой-то видеофайл в таких-то разрешениях лежит там-то и там-то само видео длится там такое-то количество времени и прочее на основани этой информации конечные продукты Вот наши Да дгис принимают решение какой видеофайл отобразить соотвественно если Это онлайн И большой экран у пользователя то проигрывается Ну и большой такой хороший канал то проигрывается видео большего разрешения если это мобилка то проигрывается видео меньше разрешения потому что там есть свои общем нюансы а используем мы для этого для того чтобы раздавать сами видео изображения и их транско используем на самом деле отдельную опиш про неё сегодня говорить не буду но вот всё то что касается обработки видеофайлов их размещение на CD там доступности самих видео Ну Медиа там скажем так файлов это за рамками сегодняшнего доклада это в общем для этого есть отдельная пишка наш партнёр которого мы за использовали в этом проекте Ну в общем пока партнёр потом возможно это будем делать сами вот это вот то что снизу там cdn и есть некое хранилище вот у этого сервиса есть ещё другая составляющая то что вот помечено всякими такими замочками Да есть скажем так внутренние процессы в компании с помощью которых В общем которые нужны для того чтобы пользователи наши менеджеры по продажам продавали эти рекламу да то есть загружали видео жение там выбирали загружали Да видео рекламу выбирали обложки Ну в общем полностью настраивали то как это будет выглядеть в конечном продукте там есть тоже В общем своя свой API у этого сервиса для таких процессов он закрыт для внешнего доступа он есть Итак В общем когда мы приступали к разработке этого сервиса и в общем подумали Да какая нам должна быть какие есть требования у нас для того чтобы этот сервис запустить и мы поняли что у нас сервис должен быть высоко доступен причём высоко доступен по всему миру у нас пользователи есть в России в странах СНГ есть ещё несколько международных продукт проектов есть даже Чили поэтому в общем нам нужна На самом деле доступность по миру Вот и время ответ у нас должно быть настолько минимальным насколько это возможно вот насколько нам предоставляет та пишка которую мы используем в том числе Да ну здесь мы выбрали цифру в 200 миллисекунд просто потому что мы не хотим иметь никаких проблем когда пользователь продукте открывает карточку какого-то какой-то организации и там ничего не должно тормозить Да поэтому должны очень быстро отвечать Ну соответственно там стоит звёздочка такая это В общем всё зависит да на самом деле с какого региона Мы открываем то или Ино там видеофайл Да был ли у нас уже в кэше не был там в общем много всяких разных нюансов вот команда Вот вми такими рекламными сервисами мы делаем систему продаж внутри компании Вот и по факту это на самом деле наш наверное первый опыт разработки сервисов именно для публичного доступа Вот Но мы как команда разработки очень хорошо умеем DN Да мы там 10 лет этим всем делом занимаемся вот в компании я уже 7 лет вот и в общем давно мы как команда делаем приложение Нате очень хорошо его знаем Вот для этого проекта мы но из-за тех требований которые я уже говорил да которые вот у нас есть а Прошу прощения здесь бот нас к нам пришёл из-за тех требований по высоко доступности которые есть мы поняли что мы хотим размещать наш сервис именно там же где и размещаются наши конечные продукты Ну то есть использовать Ту же самую платформу а платформа в гисе используется для этого на основе Linux поэтому в общем вот такая вот конфигурация на pnet Core на линуксе и на самом деле мы начали в в эту сторону смотреть начали понимать что для этого есть от Microsoft что для этого есть скажем так от от сообщества да те библиотеки которые нам понадобились бы для того чтобы запустить такой сервис на самом деле вот на тот момент мы начали разработку в начале года и на тот момент всё было с этим вопросом уже хорошо был зан в первой версии всё круто все те библиотеки которые нам понадобились бы они тоже были поэтому в общем стартанул да но а пришли к нашим ребятам которые занимаются как раз хостингом да всех приложений кстати вот был доклад нашего а товарища из компании гист который как раз занимается Вот организацией веб-трансляция котором должно удовлетворять ваше приложение для того чтобы можно было его размещать на платформе И на самом деле немножко вперёд забежал Простите Да ещё Почему Linux да или там те плюшки которые Linux нам даёт дополнительно немножко назад вернёмся Потом я расскажу одном О чём начал Вот кроме того что мы смогли за использовать Ту самую платформу которые есть дги да мы е получили дополнительных несколько плюшек Ну например такие как вот есть два человека Ну в общем на самом деле это на мой взгляд неплохой продукт имея опыт общения уже с ним могу сказать но на самом деле это вот такое вот решение которое помогает запускать процессы и хранить всю инфраструктуру Как там есть яфа в котором можно описать все Бип об этом сегодня тоже поговорим в общем они все выпо пго то есть там есть pipeline можно там запустить какие-то шаги автоматически какие-то там ручная ручная ручной запуск предполагает Ну в общем вот дальше в компании опять же существовала куча там си стартер китов они кстати орные поэтому всё что могу сегодня буду сегодня рассказывать тоже можно посмотреть на основе мейка ребята там внутри компании написали всяких разных кучу скриптов которые просто позволяют облегчить рутинные скажем так задачи Вот ну и опять же из-за того что Linux Мы в полном объёме да можем за использова доке у нас там внутренний dockerhub Ну на самом деле неважно создавать свои доке иджи и замечательно Да понятно что доке существует также и на Windows но пока как бы не знаю пока примеров продакшн применения технология довольно-таки новая Но вот на линуксе всё замечательно в этом вопросе Да кроме того Да если мы используем Linux мы можем делать свои приложение используя на самом деле любой технологический стек Вот это микросервис подход Там и так далее мы можем какие-то компоненты делать нане какие-то там на других платформах на самом деле мы вот этот эту штуку этот плюс Да за использовали для того чтобы выполнить нагрузочное тестирование своего приложения мы просто подняли рядом а тулз скажем так да для нагрузки на на на самом деле на скале и протестировали вот ну и кубернетес А можем опять же это использовать просто потому что Linux Кто кто знает что такое кубернетес и Кто использовал есть два человека но у меня там есть как бы слайды по этому поводу так вот те ребята которые нам а обеспечивают хостинг всех приложений они нам говорят типа ваше предложение должно быть как минимум двенадцати факторным про двенадцати факторной все знают Никто не знает немножко рук Да расскажу более подробно В общем на самом деле есть свод правил вот их 12 штук Да которые говорят о том А что если вы будете следовать этим правилам то ваше приложение будет такое хорошее изолированное и его можно будет поднимать вот используя все тузы которые касаются Докера и прочее да То есть вы можете по факту поднимать его либо в Private Cloud либо там ещё где-то вот здесь много всяких разных штук Об этом можно почитать по ссылке более детально Я хотел бы остановиться на нескольких на некоторых из них Да там вот второй строчка написано зависимости вместе с приложением Это значит что А наше приложение не должно требовать от той среды куда мы его развёртывать так предна роен их штук то есть там не должно быть Доне Да как мы вот любим на венде Что у нас там Windows Север там dnet стоит определённая версии всё хорошо здесь такого Ничего не должно быть мы должны таскать и приложение интай и те библиотеки которые мы используем прямо вместе с самим приложением так чтобы мы могли его просто грубо говоря скопировать и запустить ещё интересная вещь Это вот конфигурация через окружение то есть Понятно Мы все используем конфиг файлы для того чтобы сконфигурировать приложение для его работы в ран тайме но хотелось бы чтобы у нас были некие предустановленные значения в этих ког Файв А дальше мы могли передавать через переменное окружение какие-то дополнительные параметры именно самого окружения так чтобы заставить приложение работать Ну в зависимости от того окружения где оно находится в каких-то определённых режимах да либо это там де среда либо СН среда либо прок но код приложения и конфигурационные всякие штуки не должны от этого меняться да В Доне в классическом Доне Да который на Windows есть там такая штука трансформация фа трансформация конфигов xdt трансформации использует кто-нибудь использует пару человек вот здесь штука становится на самом деле не нужна и вс всё сильно упрощается А ещё одна скажем так важная особенность Да которые приносят двенадцати ктор это то что мы должны быстро уметь быстро останавливать и запускать новые процессы да то есть если мы используем приложение в какой-то среде Если вдруг что-то случилось с приложением мы не должны ждать пока там что-то там случится Да лучше бы среда сама погасила наше приложение запустила заново его вот ну в том числе пере конфигурации самой среды на предложение никак не должно влиять Вот и ещ одна важная веь Да это логирование то есть все логи которые производят наше приложение должны логировать в консоль А дальше уже в общем та платформа на которой работает приложение разберётся да взять эти логи положить файл взять эти логи положить там куда-нибудь к в ластик да Для того чтобы проиндексировать или ещё как-то там или просто на консоль показать дополнительно вот ДФА довольно важная ве кстати вот все те Все те примеры код и так далее что я буду показывать Они лежат вот здесь на гитхабе поэтому мо пос после доклада на самом деле можно взять этот код и поиграть если у вас установлен докер то прямо вообще всё будет круто а про dotnet Core Да ну у меня на самом деле есть парочка слайдов где я хотел рассказать о том что такое dnet Core вот Ну так как много ребят с в зале которые знают что такое поэтому быстренько по ним прогусь в общем вот С недавнего времени там пару лет назад Да 3 года назад Microsoft пришла вот к тому что как компания Да пришла к тому что вот есть dnet который старый добрый dnet который на винде у которого есть vpf Windows form sipnet внутри э под ним Да есть некая Bit CL Library Вот и в общем ран тайм и прочее всё это дело работало на а винде и всё было круто да Но с другой стороны существовал всегда существовал альтернативный подход взять Mono и в общем запускать по факту код написан на шарпи на других платформах вот Microsoft сделали ещё один стек да под названием dotnet Core где реализовали как раз возможность писать приложение которые будут изначально кроссплатформенные да Вот соответственно под это всё дело они многое довольно сделали для того чтобы сделать общую инфраструктуру компиляторы Да языки и ран таймы В общем это тоже платформе вот если говорить про там есть dotnet Core такой такой блок да то это отдельная штука на самом деле отдельный мир просто тоже про него скажу эта штука позволяет запускать в принципе dnet приложение Под разными платформами начиная от iot девайсов каких-то Да есть люди которые прям Я видел это ко которые запускают tot net приложение на Raspberry Pie tot net Cor приложение да и в общем смещ вся эта штука смещается там в сторону всяких ленсо там и так далее В общем Universal Windows платформа - это вот про это вот Но опять же здесь вот у нас есть на этой картинке там bas Library Library и Mon Library Да в общем с этим довольно жить было тяжело все это испытывали все проблемы там появились тогда Portable libr и так далее Это было всё очень непросто поэтому Microsoft пошли в сторону того чтобы унифицировать как раз ошки Да которые опять же являются кроссплатформа и работают на всех этих х и сделали вот на Тей момен это верси 1.6 то не весь тот dnet который у нас был всегда это некое его подно с точки зрения API Да но с версией 2.0 они обещают во втором полугодии уже сделать так что практически всё что было в старом классическом тте будет работать в принципе Крос платформе вот это что касается тех инноваций скажем так которые произошли в дот нете Вот и мы как раз вот будем говорить про dotnet Core и его под про его там часть которая касается aspnetcore Итак что же dotnet Core даёт нам с точки зрения двенадцати факторной а на самом деле двенадцати факторной здесь реализуется довольно хорошо мы имеем возможность собрать приложение и полностью контролировать его зависимости то есть мы можем сконфигурировать dotnet приложение таким образом чтобы после билда на самом деле там после паблиш да мы а в конечной папке в папке артефактов имели полностью всё что касается приложения ран тайма библиотек в общем всё-всё всё слх под определённую платформу которую мы сказали да Для этого нам нужно просто её выбрать будет это Windows Linux или osx здесь кстати вот у меня ма есть я на самом деле на Маке тоже это всё делаю и на самом деле всё замечательно работает поэтому могу с уверенность говорит о том что действительно так вот и как я говорил уже да Нам нужно выбрать фреймворк на текущий момент это Stand 1 и за референси две библиотеки собственно здесь на самом деле в общем довольно очевидно Да Нам ну нам нужна corr для того чтобы она таскала с вместе с нашим приложением и dotnet Host просто для того чтобы поднимать а приложение в общем на конечной системе про aspnet Core пару слов да как это работает знает как работает ipnet Core люди скажите кто знает кто игрался ползала Да в общем опять же кратко Да в общем вся идеология ipnet Core построена принципах middleware Да вот у нас есть какой-то какое-то количество Да какой-то с какое-то количество слоёв скажем так middleware когда запрос приходит в наше приложение в наш ранта на его пути становится первый middleware который что-то там выполняет свою какую-то логику И дальше пробрасывается этот запрос следующему Да следующий выполняет пробрасывается следующему и так далее до тех пор пока конвейер не закончился и обратно в общем этот Обратно мы отправляем респонс пользователю да Если говорить о прикладных каких-то аспектах Да это всё Мы на первом этапе можем делать какое-то я не знаю там Exception handler вставить Да в Как как middleware для того чтобы все исключения которые приезжают к нам в ратай полностью все отслеживали логировать и прочее дальше вторым midle W у нас может быть какой-нибудь там модуль безопасности который проверяет запрос можем мы его дальше пропустить или нет ну а третьем уже Может быть какой-нибудь там а mvc Framework Да который как раз занимается роутинг а даёт там либо данные либо странички Ну с точки зрения рест сервисов отдаёт данные вот Это пример middleware э простейший приме который на самом деле примерно такой мы и делали для того чтобы хостить приложение вне Давайте подробно посмотрим на то что здесь есть здесь вот есть в конструкторе это на самом деле тот следующий который в общем стоит за ним Да он инжектится в Конструктор и соответственно у нас появляется возможность Отправить ему запрос Да в общем этот Конкретно этот midle То есть если у нас там допустим платформа на которой мы работаем она требует от нас НТА ском Ну например вот таким В общем как раз этот для этого и нужен Да дальше если запрос пришёл не на этот путь Да не на этот пас тогда мы в общем отдаём управление следующего mle пробрасывается запрос не продолжает выполняться собственно на этом всё и заканчивается очень быстрая штука в наших тестах вот это вот это весь код который здесь он работает там буквально за 2-3 миллисекунды то есть он прямо так дальше поговорим про базовые фиче сервисов которые в общем нужны Обычно когда мы делаем такие вот такие приложения в общем понятно да что всем нужно логирование и замечательно было бы чтобы оно было структурным Да дальше понятное дело нам наверно Ну может быть не сильно понятно но в общем очень замечательно когда у нас есть версионирование API отдельная тема тоже можем подискутировать Но в общем очень хорошо бы если бы у нас такое версионирование было прямо из коробки вот ну и в общем замечательно иметь какое-то формальное описание API если у нас есть какой-то скажем так юк к нашему сервису который просто описывает какие у нас есть эндпоинты как к ним ходить какие там контракты данных какие мы должны пробрасывается тоже было бы круто вот начнём с логирования Кто знает что такое структурное логирование угу вот структурное логирование если визуализировать выглядит как-то Так здесь у нас есть консоль А в этой консоли есть какие-то строчки и они такие вот разноцветные на самом деле здесь если посмотреть более детально туда да то мы увидим что во-первых у каждого сообщения которое выводится в лог Да есть в общем дата понятное дело там уровень Там р вон инфо и так далее Вот Но кроме того что есть текст приложения есть текст лого Да текст сообщения есть ещё некоторые параметры эти параметры как раз и подсвеченный в общем у нас могут быть кроме логов ещё может быть какие-то пары ключ значения которые мы можем явным образом индексировать да то есть если мы хотим допустим скажем такро которы логировать логировать полностью всё что отдаёт наше приложение по определённому запросу мы можем сказать здесь Да что у нас есть некий request ID Ну на самом деле платформа нам предоставляет этот самый request ID а платформа Вот и мы можем влог добавить request ID и именно как пара ключ значения request ID равно столько-то Да и потом иметь возможность поэтому request ID во-первых наши логи где-то проиндексировать например опять же в том же самом эла Я говорю эластик по что мы его используем удобно Вот и в конечном итоге просто скажем так отфильтровать все логи по этому request ID мы можем найти все сообщения которые были сгенерировано этим квестом То есть мы сможем увидеть как как реквест к нам пришёл как он дальше отрабатывал если был Exception мы его же здесь увидим замечательная штука это вот в общем даёт нам структурное логирование для того чтобы выполнить структурное логирование в espnet Core Ну вообще в принципе dnet Core Ну и в принципе в Доне есть замечательная библиотека сек А есть также Log fed есть nlog но мы остановились именно на сери логе просто потому что там всё есть из коробки там есть возможность выводить логи в любом формате в любые А в любой форме да А в любые там а не знаю не только в консоли или в подсвеченный консоль Ну и сразу же там Если вдруг вам понадобится там не знаю ластик или файлы Да допустим в целях разработки иногда полезно чтобы а Log также лежал где-то у вас локальном в файле в общем всё всё в этом смысле есть и ничего делать не надо поэтому именно на НМ мы остановились очень хорошая библиотека показала себя замечательно вот таким образом она настраивается У нас есть понятное дело Да уровень логирования дальше мы говорим о том что мы хотим логи выводить в консоль дальше Мы хотим сказать В каком виде эти логи должны выводиться в консоль Да если мы работаем с де окружением замечательно если у нас есть такая подсвеченные на йн или где-то там в продакшн среде хотелось бы чтобы эти все логи выводились фор чтобы потом среда могла их забирать и каким-то образом эже индексировать вот опять же ВС это из коробки есть здесь видите типы данных самого Сега и дальше есть возможность обогащать все эти логи какими-то дополнительными параметрами например выводить ID requ ID и прочее прочее прочее вот таким вот декларативный образом Следующее о чём Хотелось бы поговорить Это именно версионирование вот мы вот сделали Всё у нас хороводи чтобы на того сервиса который мы делаем поддерживала таким же образом скажем так из коробки версионирование версионирование Очень полезная штука когда мы работаем именно с публичными клиентами и не знаем сколько их Да какие у нас есть Клиенты в принципе вот в нашем случае как раз это было важным потому что у нас есть мобильные приложения У нас есть онлайн У нас есть НУП скажем так меньше Да вот и на самом денен работы одной версии онлайн приложения в нашей компании может достигать там полгода а то и больше то есть пользователи могут Не обновлять приложение на устройстве больше чем полгода но тем не менее если это это устройство Да это конкретная версия приложения приходит на энд мы должны отдать данные именно по тому контракту которые которое предполагается для этого устройства для этой версии приложения вот если потом в течение времени Это обычно бывает Да мы взяли и поменяли что-то в опиш скажем так добавили или там чего хуже Да удалили какие-то данные из ответа или в принципе поменяли контракт взаимодействия это не не хотелось бы чтобы это сломало старые приложения Вот это собственно как раз Скажем так задача версионирование чтобы все эти вопросы решить вот замечательна есть библиотека опять же от Microsoft она полностью о Source как и всё остальное там называется ipnet Core isnet API ссылка там есть да она работает по тем сформулировал там публично да для своих сервисов и даёт возможность версионирование вот опять же есть разные варианты передачи скажем так информации о версии через quy string через ural Pass через ну в общем через хиде П заголовков В общем всё всё поддерживается скажем так из коробки как это делается делается очень просто вот допустим у нас есть такой контроллер всё что мы должны сделать это вначале сказать что вот у нас версия этого контроллера 1.0 соответственно версия API которая предоставляет контроллер 1.0 дальше мы должны сформулировать наши там написать наши заголовки так чтобы они поддержали версионирование Да если мы напишем просто там API Ну мы раздаём медиафайлы поэтому это как раз для нас важно там пример оттуда Вот соответственно если мы оставим такой ро тогда версия API будет передаваться каким-то образом не через да то есть это будут либо ринги либо хиры либо е как на самом деле там есть несколько вариантов если мы скажем что хотим наши улы Наши роуты формулировать в таких вот терминах да тогда версия API будет пробна прямо в ул до сервиса вот там пример справа на самом деле можем оставить и так и так это означает что клиенты могут ходить по-разному и все будут приходить по одному и тому же роту Вот например в общем простейший пример когда у нас есть какой-то запрос пош хотим что-то там отдать мы можем прийти либо вот по указав версию ipi сверху либо в World Pass вс все эти запросто заботится сюда если у нас с течением времени появляется вторая версия API нам на самом деле нужно сделать довольно Мало вещей Да Нам нужно прийти в этот же самый контроллер и сказать что вот у нас появилась вторая версия у этого же самого у этого же самого API Простите что-то там какие-то Да вот и на самом деле всё что нам нужно сделать это оставить тот метод который у нас был который отдаёт данные для для клиентов Наверное мне надо что-то сделать Да с этим сейчас секундочку оп вот оставить можем тот метод который отдаёт данные для сервиса для клиентов которые знали об этом Об этой версии API на тот момент также ничего в в нём не изменив Да в этом методе контроллера но можем Добавить новый метод контроллера и сказать что вот запросы которые приезжают на API 2.0 пожалуйста на заройте сюда Да И тем самым Будем отдавать уже абсолютно там ну либо какую-то другую информацию либо более расширенную либо более ос суженую тем самым мы не поломаем старых клиентов и добавим функциональность для новых клиентов Да это не обязательно делать в одном контроллере мы можем сделать контроллер рядом сказать что вот у нас контроллер 2.0 В общем есть много разных вариантов и делается очень просто да ещё О чём Хотелось бы поговорить Это о такой библиотеке как СШ который предоставляет возможность Swag Да кто знает прор кто использует Ну вот особо говорить здесь тогда не о чем Единственное о чём хотелось бы сказать это что подключив для мы получаем функциональность опять же из коробки и она на самом деле умеет дружить с той библиотекой про версионирование то есть сконфигурирован приложение сказав что у и просто пробежав рым по который там есть которы это провайдер предоставляет можем добавить СР документы То есть те самые формальные описание наших ашек Да по факту это вот сне который для свара нужен и после этого можем добавить Swag сказав что вот у нас есть SW на таких-то женах опять же в зависимости от API от версии AP кото У нас есть тем самым мы полум версионирование про который знает есть переключал есть возможность посмотреть какие в той или иной версии II есть все у нас эти методы всё всё круто на самом деле в том том демке в той демке которая на гитхабе лежит Всё это есть Можете посмотреть плавно перейдём к билду вот мы написали приложение У нас есть там все необходимые функциональность написали даже туда бизнес логику например да как нам это всё с билдить А да так чтобы потом затеить на самом деле довольно просто всё я говорил о том что мы используем gitlab C вот это один из фрагментов того самого gitlab файла это один Build steep вот у нас там есть какой-то Build steep на котором мы хотим сбить приложение что нам для этого нужно на самом деле очень немного Да Нам нужно базовый образ который предоставляется Microsoft в этом образе есть во-первых всё Что необходимо для того Ну в общем в всё Что необходимо для того чтобы сбить приложение там есть весь Тулин commandline там есть samnet определённые версии весь ранта всё-всё-всё этот образ довольно большой поэтому конечно тянуть его в прокш ни в коем случае нельзя его нужно использовать только для того чтобы сбил приложение это как раз про ту самую двенадцати факторной когда там стадия билда и там по факту эксплуатации приложения должны быть разделены используем этот образ говорим застой нам пожалуйста все зависимости которые есть в этом приложение именно для этой платформы на под которую мы хотим собрать Да мы используем там Linux вот дальше Конечно же мы написали Юнит тесты Мы хотим их выполнить перед тем как в принципе приложение собрать если Юнит тесты не прошли то ничего это и уже не нужно потому что приложение не работает говорим dnet Test указываем там тестовые проекты И если всё хорошо говорим dnet publish указываем как раз тот самый Run который нам нужен который нас интересует винда Linux всё что угодно и говорим о том куда это всё нужно делать за деплоя с точки зрения тех артефактов которые получатся вот у нас в папке там publish Back в этом примере будет лежать всё да что касается приложения и его зависимости тайма то есть в этой папке будет лежать Всё дальше после того как мы приложение сбили нам нужно собрать докер образ таким вот образом мы можем собирать Dock Robot прямо на каждый комит А мы сделали какой-то комит У нас есть ceg тот самый да на на уровне gitlab Si Вот и мы можем собирать и делать образы прямо на каждый комит да то есть это уже на самом деле Шаг к такому continous depl режиму вот указываем этот C конфигурируется и в общем после того как doer docker Build прошёл мы получили образ локально берём и пушим его на какой-то там dockerhub локальный глобальный куда угодно Всё тем самым у нас есть приложение собранное под необходимую нам операционную систему в Мом случае это Linux У нас есть образ этого приложения на до ВС что нам нужно дальше сделать это задеплоить и здесь немножко поговорю про кубе рне это как раз средство Оке оркестрация контейнеров о вопросах а вопро вопросе вопросах того как эти контейнеры запускать как их поднимать если они вдруг упали Как как следить за логами этих контейнеров в общем вот эти вот все вопросы кубернетес замечательно решает вот нашей компании развернут кластер кубернетес на самом деле даже не один а их четыре а вот и мы можем использовать это платформа для того чтобы деплоить как раз наше приложение в общем есть такие базовые понятия в нём первое понятие - Это пот под на самом деле это логическое объединение каких-то контейнеров там может быть один контейнер может быть несколько А почему логическое объединение потому что в общем все контейнеры которые лежат в поде предполагается что они жёстко связаны между собой используют какие-то общие ресурсы будь то файловая система сеть А там какие-то может быть процессы ещё чего-то дальше а для того чтобы сказать что вот такие поды у нас есть в самому кубернетес мы можем сказать что вот у нас есть лейбл зелёным цветом помечен некий вот мы задеплоил в кубернетес наш некий сервис вот куртис из коробки требует нам чтобы мы сказали ему как Как чекать наше приложение там есть чеки чеки в общем н Там и так далее да то есть все вот эти вот вопросы которые касаются как раз управление контейнером где-то в среде куртис решает За нас это что касается пода вторая штука которой тоже важно знать когда мы работаем с кубес это сервис сервис на самом деле довольно простая штука и говорят нам о том что или на самом деле позволяет Да получать внешний трафик на кубернетес говорить и говорить о том куда этот трафик перенаправить уже внутри кубер На какие поды да На какие контейнеры для этого ему нужно на самом деле две вещи это селектор вот тот лел который был проставлен для пода как раз нужен для того чтобы узнать все поды которые есть для этого приложения и порн если внешний пор допустим мым зать на контейнера или ещё на какие-то другие как раз сервис предоставляет эти возможности в целом выглядит это вот так вот у нас есть пользователи которые приходят на кластер кубес Ну или на самом деле на какой-нибудь baner Извне этот трафик мы получаем понимаем кому он нужен там по доменному имени Да Соответственно по селектору находим те поды которые есть внутри куне их может быть несколько Да там в вся эта штука очень хорошо скели вот и пере направлением портов пони отправляем этот трафик на соответствующие порты в контейнерах вот есть ещё одна такая штука под названием deployment у кубес на самом деле деплоймент даёт возможность развёртывать поды автоматически да то есть мы там говорим Сколько у нам нужно реплик этих подов там 1 2 3 10 15 Вот и указываем шаблон пода то есть деплой по факту позволяет нам развернуть несколько подов автоматически Ну сразу же да на на всём кластере кубернетес и вся картинка выглядит вот так вот да как разработчики мы должны написать деплоймент сказать сколько нам реплик там нужно Да какой у нас темплейт пода какие там контейнеры какие там чеки Там и так далее и так далее и так далее выставить все эти лейблы для того чтобы связать их с сервисом дальше написать сервис как раз который будет стоять на входе в кубес А вот и по сути дела Всё да пользователи потом будут к нам таким вот образом Вот для этого на самом деле и здесь вот есть примеры пример деплой Да Единственное что нет в самом кубернетес что нам пришлось скажем так дот самостоятельно но я думаю что это не только мы этим занимались Вот но пока кубер не предоставляет такую возможность для того чтобы задеплоить приложение конкретной версии на кубернетес нужно написать конкретные деплоймент Ну в общем сервис файлы не обязательно вот именно деплоймент файлы нужно написать конкретные с указанием какой-то конкретной версии У вашего приложения какой-то конкретной версии для того чтобы встроить всю эту штуку в pipeline именно такой depl pel да когда мы хотим сделать комит в git запушить всё это дело собрать образы и прямо этот образ вот с этим котом задеплоить на кубес пока На текущий момент кур не предоставляет такой возможности поэтому есть туза Да которая позволяет вот такие вот файлы кубер писать в виде шаблонов и потом эти шаблоны собирать уже в те файлы которые потребляет сам кубес вот вот собственно Это пример деплой что здесь есть да здесь есть вот тот л про который я говорил да соответственно мы можем указывать где-то сверху через шаблонизатор нам нужно указать где лежит образ нашего приложения и его версия вот здесь тот самый то есть на каждую на каждый на каждый Т Мы можем по факту собирать дальше что нам нужно сказать это нужно указать по карту Поа приложение порту нужно ходить к нашему приложению в этом самом контейнере дальше должны обязательным образом настроить настроить проби а чеги для того чтобы кубернетес знал работает наше приложение всё ли с ним хорошо или не очень Вот и можем передавать переменные окружение Да указывая какое-то там какая среда где у нас в каком формате необходимо выводить логи и прочее и прочее сервис выглядит таким вот образом Ну в общем Понятное дело что это сервис дальше мы говорим о том что внешний порт у нас 8080 а тот внутренний это вот через шаблон мы передадим и собственно селектор вот это вот и весь сервис собственно дальше что нам нужно сделать это указать все эти параметры для того чтобы с билдить по этим шаблонизатор сбил уже в общем файлы для кубес здесь мы указываем какой кластер кубес мы будем использовать говорим о том что вот у нас порт приложения там какой-то у нас есть про Pass Health Check вот тот самый midle про который я вам говорил да Да Image у нас берётся из переменное окружение вообще лаба то есть прям на каждый git комит мы собираем лежит лежат эти образы Вот там-то и en У нас например Stage да для Production там будет другая переменная всё что нам нужно дальше сказать это в общем что есть такие вот ресурсы для этого приложения и указать те темплейты которые которые я показывал выше вот после того как мы всё это сделали берм пишем ещ один ещ один степ ещ один по факту это у нас уже dely да De мы говорим о том что вот у нас есть такая-то туза для того чтобы как раз все эти шаблоны обрабатывать Она лижит там где-то на на докер и по сути дела Всё что мы делаем этол поднимаем контейнер с этой туой говорим этому говорим этой Зай и возьми вот из того ял файла который был Я показывал выше на самом деле Вот это и всё для того чтобы задеплоить вот на самом деле я говорил про spnet приложение на самом деле любое приложение на cuber так это работает на 32з и прям на самом деле особо проблем не доставляет и делается всё очень быстро вот это вот k8s handle тоже орная штука поэтому можно использовать дальше А вот мы поговорили о том что мы задело приложение как же нам дальше его протестировать как мы удостоверится там отказ устойчивым и прочее и отдаётся определённом определённом Н В общем что мы Для этого сделали Как команда разработки мы особо в тестировани не соображаем но в дгис опять же есть отдельная команда нагрузочного тестирования Мы пришли к ребятам и говорим ти ребят Вот Нам нужно сделали приложение У нас есть такие-то требования Мы там локально протестировали вс хорошо уже втроём это поделать В общем запросы отрабатывают давайте-ка Мы нагрузили в общем завтра мы к вам придём и всё сделаем мы такие а как как вы это делаете вообще Ну они говорят у нас есть там свои тузы вы на чём развертывается приложение мы вот ну на кубернетес они такие Ну замечательно значит всё будет круто В общем зачем они к нам пришли А они к нам пришли и говорят типа как как вы вообще что вы хотите протестировать какие эндпоинты мы говорим что самый самый критичный Для нас - это публичный endpoint и собственно нагрузочный контур У нас вот такой вот да у нас есть какой какие-то продукты Ну в нашем случае это как раз те толы которые гнет нагрузку У нас есть сервис и у нас есть провайдер прямо прямо вот тот та пишка прямо живая Продакшен ся которая а лежит под нашим сервисом Мы хотим протестировать именно вот таким вот образом они а они написали нам тесты тесты на скале на самом деле они используют gatling используют скалу для того чтобы а В общем выполнять те самые нагрузочные тесты здесь ВС просто вот здесь написано что у нас есть некоторые Асер Мы хотим что на количество квестов в секунду там больше или меньше кита Мы хотим чтобы наши заей реквесты вот там ноль Да мы хотим чтобы был сколько-то после этого мы говорим о том как как собственно нагрузочный тест нам проводить здесь написано на самом деле в двух строчках Ну довольно понятно На свам на нагрузку с одного там до 20 например в течение 30 секунд да то есть мы хотим чтобы у нас нагрузка росла а потом хотим долбить в течение 120 секунд ещё в течение 2 минут вот теми двумя дю пользователями которые у нас есть вот и всё что нам нужно в конце сказать что вот у нас есть такой-то тест с такими-то шагами По хттп време выполнение там 180 секунд Да в нашем случае и вот такие таер В общем это и ве нагрузочный тест их там неко Ну это один один из примеров вот после этого они нам написали вот такой вот те здесь на самом деле много всякого разного кода который касается конфигурирования тузы но сама туза вот здесь вот я пометил она как раз находится в этом образе На самом деле как она выглядит я даже не смотрел туда и мне по сути дела Ну на тот момент было не так интересно мне самое важное было выполнить задачу вот мы взяли этиз написали своп на основе этого темпле и по факту здесь вот запускали тест в двух вариантах Первый вариант - это Кати тест когда мы отправляли запросы по очереди ждали Когда респонс придёт после того как респонс пришёл отправляли следующий запрос и таким образом смотрели сколько у нас в принципе ёмкость Да нашего приложения то есть сколько запросов в секунду мы можем отработать А после этого запускали именно такой настоящий нагрузочный тест когда мы не ждали ответов А запускали эти запросы параллельно вот Ну и конечно же после того как мы это всё сделали в первой итерации у нас особо результаты были не очень хорошие В общем не те которые а которые мы ждали что мы что мы здесь сделали Да мы пошли в сторону performance здесь у меня остаётся не так много времени ещё Чтобы успеть поговорить Я пробегу может быть побыстрее какие-то детали обсудим может быть на вопросах В общем первое что приходит в голову чтобы повысить А Н Time повысить количество запросов которые мы можем отрабатывать и уменьшить resp Time мы можем сделать кэширование да а в общем если у нас есть те ресурсы которые мы можем сохранять в кэше зачем их зачем ходить за ними заново и заново для этого у нас в ispn есть старый добрый атрибут respon cash Но вот в dnet coree он приобрёл дополнительную функциональность Да если мы выставляем просто ш указываем там duration то мы получаем по умолчанию каширование на клиенте То есть клиент на своей ране сохраняет те данные которые ему отдали Да и в общем больше к нам запросов не шлёт тем самым мы вроде как бы разгружаем сервис Это довольно простая Вещь Вот добавили в isnet Core серверное каширование также есть такая вот штука под названием respon стандартная штука от майкрософта и позволяет довольно хорошо управлять именно серверным рованием на самом девать прямо ответы от сервисов в памяти процесса Да причём мы можем выставить как мы хотим разделять эти Ответы да то есть в нашем случае если есть версионирование Хорошо бы конечно же отдавать разные респонс на каждую версию API так чтобы не перемешивать Да вот и после того как мы это сделали У нас довольно Ну то есть на самом деле мы включили каширование на стране сервера включили каширование на стороне клиента ребята запустили свой тест у них полегло Вот потому что в общем они там как-то быстро ВС стало к ним приходить во-первых Ну и они конечно же на своей стороне потом отключили клиентское каширование чтобы в общем было всё более-менее а похоже на реальные какие-то условия Когда у нас есть разные клиенты вот вторая вещь которая приходит в голову когда мы говорим про performance - Это работа с потоками Да мы в общем у нас dnet всё всё таки зрения с точки зрения потоков всё замечательно А поэтому Почему бы не использовать и здесь есть две вещи Да асинхронность и многопоточность как вы думаете одно и то же это или нет Кто считает что одно и то же а кто считает что разные вещи все считают что разные вещи и правильно конечно же А можем использовать вместе многопоточность и асинхронность можем не уверен Ну вот в общем асинхронность - это вот то что показано слева многопоточность то что справа Да асинхронность когда у нас есть просто один какой-то поток какой-то один ресурс операционной системы процессор ядро На нём мы можем выполнять последовательно на самом деле ряд задач Да если у нас вот та 1 отправил запрос базу данных и ждёт чего-то мы можем этот поток дать в пул для того чтобы следующий запрос клиента отработать TAS 2 Да если он там что-то в общем тоже задумался мы можем сменить контекст потока выполнять таку О если там запрос пришёл от базы данных Да ответ пришёл от базы данных можем выполнять дальше функциональность и так далее То есть на одном ресурсе физического операционной системы можем выполнять несколько асинхронных задач вот вша это как раз про синхронность Вот Но есть такая веь как многопоточность когда у намного потоков есть много ресурсов операционной системы Вот и на самом деле никто не мешает нам запускать какие-то процессы параллельно но опять же никто не говорит о том что эти параллельные процессы внутри себя не могут быть асинхрон Вот поэтому ан не только про асинхронность Да но ещ и про поточность но правильно её использовать нужно вот это такой пример простой когда мым использовать многопоточность в дот нете там все шар Да допустим что у нас есть какой-то сервис который отдаёт там какие-то данные в виде коллекции и дальше нам нужно на основе этих данных которые вернул сервис ещё протерозое количество сервисов для того чтобы подтянуть какие-то дополнительные данные на основе тех данных которые к нам пришли Ну вот здесь Это пример прямо из нашей жизни у нас есть видео а видеореклама Да видеореклама может быть в нескольких форматах у них могут быть несколько изображений Вот соответственно в этих об этих всех форматах нужно узнать какие у них там есть разрешения какой битрейт Там и так далее В общем первый запрос капи мы делаем скажи-ка нам пожалуйста в принципе о том какие есть медиафайлы на твоей стране нам говорит вот есть коллекция данных дальше мы по каждому из них а идём опять же в апе и уже получаем детальную информацию о тех видеофайла о тех картинках там которые есть для этих видеофайлов вот написав это всё дело Мы конечно же особо там на производительностью не думали Мы писали бизнес логику написали это дело в цикле вот таким вот образом Да и собственно Наши нагрузочные тесты нам как раз это и показали что у нас что-то там а ответ от нашего сервиса был порядка секунды В общем чтобы было не сильно хорошо учитывая что А от нас ожидают гораздо большего ответа вот поэтому мы переписали здесь уже правильная версия Да вот ну в общем важно понимать что не всегда получается с первого раза написать правильный многопоточный код эффективный да так чтобы ещ и локов не было Вот здесь мы в общем делаем практически тоже самое но запускаем вот запросы к каким к той ашке уже параллельным образом причём ещё и асинхронно Да вот то есть мы получаем на выход некую коллекцию тасков и запускаем ещё одну таку которая эти таски будет ать то есть тем самым мы получаем по факту время ускорение Ну там в то во столько раз На сколько у нас этих видеофайлов лежало Да если у нас допустим на каждую видео на каждою видео рекламу есть три разрешения файла мы получаем сокра сокращение времени аж в четыре раза Да потому что нам нужно сделать один запрос на то чтобы получить все метаданные и дальше ещё параллельно там там три или четыре или пять запросов Вот и на самом деле они выполняются параллельно с Ну в общем все параллельно поэтому общее время их исполнения Ну примерно одинаково и мы можем получить серьёзный выигрыш по производительности В общем после того как мы это сделали Мы первое что получили от нагрузочного тестирования поняли что у нас есть некоторые лимиты по памяти и по процессору которые в общем ну здесь с одной стороны диктуется раймом Доне с другой стороны тем кодом который мы написали поняли что вот нас прям это конкретная цифры из продакшена что наше приложение может потреблять в Пике Да когда у не там есть довольно серьёзная нару вот столько мегабайт и столько процессора дальше синхронный капати тест нам показал что используя вот ту опиш для раздачи видеофайлов мы получаем 24 пса то есть 24 раза в секунду мы успеваем сходить до нашего бэнда Он в общем уже там параллельно и прочее прочее уходит дальше в в тот энд который мы используем Вот Но это без кэша если включили включаем каширование мы получаем такую замечательную вещь Да там 400 псов Ну просто потому что все запросы которые к нам приходят мы сразу же отдаём из кша и всё замечательно то есть время отклика там порядка там скольки 2 С5 миллисекунд Да вот и наконец-то т асинхронный тест который вот долбит наше приложение в это в этот момент уже прошёл и мы немножко подралась Ну в общем что хотелось бы сказать в конце Да много информации но тем не менее на основе нашего опыта можно сказать Что На текущий Использовать можно то есть всем не было никаких там у нас каких-то зависаний непонятных там не знаю нюансов с работой Garbage коллектора или каких-то работо с оркестри потоков или ещё чего-то то есть всё то что у нас есть в обычном Доне На текущий момент есть такого же качества и боятся его использовать Судя по нашему опыту не стоит вот опять же если говорить про Linux не было никаких опять же проблем которые касаются именно линуса да то есть если есть какие-то проблемы они скорее всего есть в коде у нас там были дедлок как раз с использованием потоков Я могу рассказать вам как их легко получить Вот и в общем Они как раз не от не зависели ни в коем случае от линкса зависели от программистов Да вот опять же докеры кубернетес как я уже показал сильно упрощают жизнь а в плане разработки dnet приложений и в принципе в пне в плане разработки приложений и использования разных разных стеков технологи для того чтобы выполнять задачи именно те которые А ну в общем требуются для этих для этих сервисов вот ну и последнее что хотелось бы сказать это что оптимизировать приложение нужно и всё это есть из коробки но думать надо всё равно чтобы не получать интересных а эффектов ещё раз вот здесь все вся презентация Спасибо вам что послушали Угу У нас есть 5 минут Давайте парочку вопросов Добрый день спасибо за доклад й вопрос Вот мы с dotnet ком давно живём так так не работает да примерно с февраля месяца прошлого года там наелись с ним много проблем Вот вы говорите на Linux перешли А как вы профилировать его как живёте без эвен Рейсинга без перформанс каун и прочих вещей а на самом деле Всё что касается в винде по поводу performance катеров оно тоже реализовано не очень хорошо Мы в своё время на этом Ну этим тоже занимались и как эту проблему решаем мы да у нас есть на самом деле Ну во-первых с точки зрения профилирования в линуксе есть некоторые тузы они касаются В общем того самого dnet кора есть Саша голдштейн он занимается там разработкой тузов для профилирования под линуса и приложений можем тоже я могу рассказать об этом Вот но нам не приходилось до этого доходить Да чтобы прямо посмотреть какие там дампы памяти и прочее Не ну вот вы профилировать как раз говорите дедлок у вас были а анализировали перформанс улучшали То есть вы же под линуксом это делали не под виной А как де нам нам хватило именно для того чтобы поймать дед Локи нам хватило логов просто мы поводили в логи номера потоков и видели что вот этот поток А количество потоков Да оно же в тред пуле ограничено если мы хорошо нагружен нагрузить наши приложение Ну или на самом деле искусственно выставив выставим ограничение в э тред пуле то можем получить такую ситуацию что все потоки получают запросы но никогда от них из них не выходит да то есть в логах Мы очень хорошо Увидим что этот поток начал исполнения этот поток начал исполнения этот поток начал исполнения и всё как бы да и дальше Мы не видим никакого аутпут от приложения видим что оно не принимает Больше никаких запросов общем таких более сложных сценариев выявления перформанса ещ на них ещё и не попадали Да что вы имеете в виду ну то есть гораздо глубоки то есть не просто дело Да а где-то Возможно там криво написанный Код кем-то Да там или ещё что-то какие-то вещи которые именно А профилирующий мы можем получить с каждой новой версией сервиса мы можем получить некую деградацию производительности для этого на самом деле мы используем а метрики но метрики не на основе перформанс канте или чего-то что касается операционной системы мы можем мы используем скажем так логические метрики на основе проте Севе есть такая штука Да мы можем публиковать эти метрики в ранта дальше выставить endp для проте сервиса он будет приходить там какое-то количество раз там в минуту в секунду или и так далее забирать эти метрики и складывать у себя да А вот эти метрики они могут быть любыми Мы так на самом деле смотрим Какое количество памяти у нас на текущий момент кушается приложением сколько раз запускается Garbage Collector сколько у нас потоков используется то есть ну вот такие всякие разные уже А ну а хардкорные метрики да уровня самого дот нета и уровня нашего приложения мы смотрим таким вот образом Спасибо Угу ещё вот здесь вопрос Спасибо за доклад А хотелось бы задать такой вопрос а вы изначально всё проектировали под Linux asp.net Core или же у вас была был перенос проекта с другой платформы именно вот это интересует изначально мы сразу же ориентировались на Linux Я уже об этом сказал просто потому что та платформа на которой нам предстояла развёртывать она требовала от нас чтобы приложение работало под линуксом поэтому именно этот сервис мы сделали изначально прямо с учётом того что он будет делаться под линуксом Вот но на самом деле если перенос У нас сейчас есть то есть мы можем об этом опять же поговорить мы делаем ещё один сервис с нуля как раз используя вот тот самый стек но у нас есть как я уже сказал много всяких разных проектов которые мы сделали за это время внутри компании на ДОТ нете которые под Винду Вот и получив все эти плюсы скажем так да или там ускорение разработки с использованием там Докера Там и так далее мы начали начали конечно же смотреть в сторону того чтобы переносить часть сервисов туда Но они такие продакшн критичные или там бизнес критичный поэтому относимся к этому аккуратно И на самом деле потихоньку этот процесс движется Да мы можем об этом подели поговорить Если интересно Ага всё время у нас закончило Спасибо Вам большое"
}