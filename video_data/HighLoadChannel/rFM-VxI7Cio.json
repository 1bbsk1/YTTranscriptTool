{
  "video_id": "rFM-VxI7Cio",
  "channel": "HighLoadChannel",
  "title": "Путь от монолита на PHP к микросервисам на Scala / Денис Иванов (2GIS)",
  "views": 896,
  "duration": 2761,
  "published": "2017-04-08T13:52:54-07:00",
  "text": "так всем привет здесь достаточно много народу хотел бы сначала такой немного статистики стал кто пишет на php поднимите руки пожалуйста отлично половина зала акта на скале я так и думал нас трое раз стальные интересно кто ну так ну немного я расскажу компании в которой я работаю и работаю в компании ту гис здесь есть те кто знают что затрат компании от одессы даже больше чем пхп шнеков со скалистыми работаю я в комп команде вы папе это backend нашего продукта для веба собственно из названия наверно понятно это web api вот мы предоставляем данные по х ттп отдаем джейсон чеки данных у нас достаточно много у нас сейчас 8 стран доступна в этих восьми странах у нас около 300 городов у нас 50 тысяч всяких разных населенных пунктов у нас около пяти миллионов организации но также у каждой организации еще есть куча филиалов например кинуть макдональдс и заправки банки и банкоматы то есть там на порядок возрастает количество данных нас около 50 миллионов деву объектов гиа объектом считается практически любой объект на карте эта остановка это даже этом ворота какие то это перекрестке все подряд вот и при этом у нас достаточно большая нагрузка ну и и особые rp сами или чем-то мерить нельзя потому что нагрузка на само по себе разные масс 30 миллионов примерно пользователей в месяц они генерируют в среднем на наш продукт около 2000 рпс то есть запрос в секунду и со всем этим нас сейчас справляется 3 дата центра чтобы быть максимально близко к пользователю который хочет нас получить какие-то данные сейчас у нас 16 нот обслуживает все это дело по 6 в каждом не по 618 not прошу прощение с математикой немножко сегодня проблемы по 6 нот в каждом дата-центр этой всего их 18 каждая но да она достаточно толстая там 16 ядер там 16 гигабайт памяти минимальная нагрузка ну такая ближе к среднее на 50 процентов на ноги то есть все достаточно грустно потому что у нас php ну вот и мы решили что это ну как-то совсем многое вот у нас это достаточно стек такой обычный как у всех у нас первичным сервером является джинкс потом php-fpm с php 5 4 вот ну так же у нас есть там радиус для кэша через х прокси мы ходим в базу пишем что-то в очереди вот у нас там есть всякие every sense у которые выгребают статистику серверов на то есть у нас ничего такого сверхестественного нет обычные stack технологий вот мы у нас есть с этим проблемы у нас скрипты работают достаточно долго что для нас долго это на 95 пирсинг или мы отвечаем за 500 миллисекунд среднем на девяносто пятом пирса теле полсекунды это долго это с этим надо что-то делать вот мы не можем параллельно многопоточное выполнять какие-то действия которые мы вполне можем делать например сходить в несколько сервисов одновременно дождаться всех ответов от всех сервисов сгруппировать эти данные агрегировать их и выдать клиенту мы должны все это делать в одном php скрипт с синхронно дожидаться ответа от каждого сервиса и такая проблема как наше приложение это один большой кусок php кода который вот надо взять вот так вот целиком как ящик положить на продакшен в 3d до центра даже если мы там одну какую-то строчку изменили это для нас проблема как думаю для многих также нас не спасает кэширование как я до этого говорил у нас там например геообъектов 50 миллионов и при этом попадание в кэше у нас 35 процентов то есть ну кэширование нас никакой не спасет к тому же у нас много команд разработчиков мы интегрируем ся с кучей сервисов каждый раз какой-то когда какой-то сервис обновляется нам это нужно поддержать и опять взять этот большой весь кусок и доставить в 3d до центра на продакшн и также у нас много тестов их у нас порядка 50000 вот не могу сказать что это даже в параллельном выполнение работает около полутора часов полная регрессии той все тесты целиком это тоже долго чтобы в опять же парили зить какую-то строчку нужно подождать полтора часа а потом это все доставить на продакшн это долго это неприемлемо для нас мы как уже не раз упоминалось за эти пару дней на high воде как инженеры решили подумать и ну может быть как-то поддерживать существующие но мы просто проблему производительности решим так что расширим еще парк серверов докинем кучу железа ну так тоже как-то не круто потому что у нас есть еще других куча проблем которые мы этим не решим и как вы думаете какая вот вторая мысль возникает такой ситуации на самом деле на переписать все нафиг как я думаю многих такое возникает желание но все-таки мы инженеры и надо действовать как то так нужно подумать нужно как-то попробовать может быть попилить наше приложение на несколько независимых кусков в интернете очень много по этому поводу информации сейчас как бы в тренде все это сервисной архитектура микро сервисные архитектуры мы решили а чем мы хуже вот как бы почитали сервисные архитектуры возможно большинство из вас знают это такая архитектура модульная которая инкапсулируется логику код отдельного куска вашего приложения которая слабо связана с другими кусками и у нас там есть какой-то протокол смежную с помощью которого обмениваются эти сервисы есть какой-то стандартизированный интерфейс для доступа к этим данным микро сервисной архитектуры она в свою очередь отличается тем что каждый из этих сервисов еще сильнее раздроблен каждый микро сервис имеет новый размер причем обычно пишут что там 200 строк кода какой-то вот эталонное число есть но при этом мы получаем более тонкое масштабирование то есть мы можем этот сервис взять и там в 100 экземплярах раскатать а какой-то который редко используется мы можем в двух экземплярах положить и все будет хорошо при этом мы еще получаем быстрый дипой то есть мы взяли вот этот маленький сервис и только его раскатали где-то поэтому при этом еще получаем легкость тестирование так как этот микро сервис инкапсулированы мы можем легко протестировать только его функциональности какие-то интеграционные зависимости ну и при этом они еще могут быть написаны на любом языке вот так как он имеет малый размер любой момент можно взять переписать его на что угодно там даже вдруг захотелось на эрланге там взяли написали что-то на эрланге потом пусть кто-то разбирается с этим вот но при этом кроме плюсов есть еще и минусы естественно мы получаем десятки приложений вместо одного это раньше у нас все замечательно мы клонируем репозитории там избита открываем своим любимым редакторе и вот она все наши приложения ничего не надо делать просто написали за к метели подождали полтора часа оно ушло на продакшен потом но вот здесь такого не будет здесь будет десятки приложений с этим как-то придется работать жить и мы получаем еще сложность в виде интеграционного тестирования раньше мы просто запускали тесты все протестировали за дипой я сейчас надо еще как-то интеграционной зависимости между этим микро сервисами проводить то есть это действительно минус и так мы начитались посмотрели на плюсы и минусы микро сервисов и решили поиграть в архитекторов папки напридумывать себе систему мы решили что возьмем докер докер тоже модная штука в тренде последнее время вот взяли ubuntu 1404 даже не брали qoros потому что в тот момент когда мы этим занимались он как-то еще не слишком был развит мы решили свою систему построим что мы хуже karos а вот взяли ubuntu с докером там все дается должно быть классно у нас каждый микро сервис будет завёрнут в контейнер эти контейнеры мы будем доставлять везде размазывать ну и какие то надо хранить у нас появляется такая штука как registry докера там эти контейнеры будут храниться у нас будет какая-то панелька для управления всеми этими контейнерами на даже смотреть какие контейнеры где запущен и что с ними происходит вот мы решили посмотреть страну шипи орды но в шип ярде надо регистрировать и наши контейнеры поэтому у нас все появляется такая штука как регистратор вот мы так делаем делаем дальше все как бы надо хранить еще где-то список наших backing сервисов чтобы все микро сервисы могли понимать где кто вообще находится что происходит с каком я должна центре нахожусь поэтому discovery нга мы решили использовать консул вот так же его поставили на все ноды нам же нужно еще как-то снимать монету мониторинге всякие статистики с микро сервисов сколько у нас циpкa сейчас кто потребляет для этого мы тоже папа рыскали по интернету нашли co2 за его кажется пилит google думаем классное тоже воткнули он умеет писать в influx baby воткнули еще influx baby ну еще есть всякие логин джинкс of вот мы думаем да их же как-то ужин тоже надо собирать куда-то доставляет смотреть у нас там будет 100 микро сервисов у всех будут свои логии как шинам снимем бороться вот для стыда от лагов в докере есть такая штука как vox поёт он тоже цепляется может писать власти кнр через voxtel унываем ладно классно ну еще же есть всякие наши бизнес метрики их же тоже не co2 zara мне вы страдал от не будешь писать поэтому мы еще решили взять привычный нам на тот момент сензу вот пусть он тоже собирает наши метрики пишет в графин вот так накручиваем накручиваем в целом такая бум и все покрываем вот мы еще как бы их надо же как-то балансировать нагрузку между базами чтобы отказоустойчивость бывает все такое вот есть замечательная штуковина называется консул template она умеет вычитывать изменения из консула и запускать какую-то командочка в данном случае она у нас перри генерировала конфиге х прокси индексов чтобы они в реальном времени у нас реагировали на какие-то изменения в наш инфраструктуре вот такая схема у нас увесистая получилось я немного расскажу подробнее об этих инструментах shipyard вот собственно ссылочка на него есть он умеет управлять контейнерами образами реестрами всякими различными модами которые к нему подключены умеет там можно в реал тайме просматривать логе каждый ноды можно ходить в консоль вот консул отвечает за discovering там есть key value хранилище она тоже распределена будет между нодами там есть какие-то базовые проверки что порт доступен что он прослушивается и там есть еще такая фишка как dns его можно подключить как стандартный dns и обращаться ко всем сервисам трампа has нейман выглядит он примерно вот так просто я достаточно панелька вот консул тимплей то тоже приведу на него ссылочку такая штуковина которая учитывает что-то из консула и шаблоне зиру it какой-то файл запускает какой-то сервис после себя выглядят can физики у него примерно вот так точнее шаблоны и того template стандартный вот на этом не будем особо заострять внимание к advisor можно его обнаружить вот здесь подключается также к системе мониторить состояние контейнеров отправляет куда скажете там у него очень много всяких точек он по их графит может по моему янв influx baby выглядит он примет по дефолту вот так вот то есть на нем можно were all to me посмотреть нагрузку что-то где-то выросла пойти посмотреть мы даже как бы после того как это все подумали мы придумали схему работы между микро сервисами у нас исторически так сложилось что у нас гид лап в принципе ничего плохого в нем нет но как бы будет куча репозиториев с ними как то надо бороться мы решили что будем использовать и my city туда удобно подключается к куче репозиториев всяких зависимости можно много выстраивать мы подумали почему бы нет все классно вроде вот и будет тем сити у нас брать какой-то репозитории запускать там мейк например собирать докер контейнеры выкладывать в регистре потом с помощью on seba будет это все доставлять тут по дефолту нас продакшен 2 потому что продакшна у нас три мы будем сразу на три продакшин и все раскатывать даже придумали как у нас клиент будет попадать в нашу систему у нас будет какой-нибудь джинкс какой-то роутер этих запросов по определенному запросу мы будем что-то делаете какую-то цепочку событий выстраивать мы написали этот роутер нога как бы почему бы нет это же микро сервиса можно писать на любом языке вот мы взяли go написали простенькие can физики что вот такой the road у нас будет обрабатываться такая эта цепочка в запросов будет запускаться придумали что вот такие основные критерии для цепочки запросах у нас будут какой-то ключ отвечающий за идентификатор этого запроса он будет дергать такой-то метод будет какие-то данные отсылать такой-то тайм-аут ждать максимальное количество попыток признак того что эти данные важны или нет то есть в принципе мы можем не дожидаться каких-то данных если все затапливает и просто от них отказаться в выдаче и те куски кода которые должны мы нам и дождаться их выполнения но их же должно быть несколько мы же не можем довериться тому чтобы у нас был один роутер для отказоустойчивость их естественно будет несколько каждый роутер у нас начинает выполнять всякие запросы собирать их и собственно как то так это все примерно работала и так мы пошли дальше и посмотрели что от как бы мы взяли базовый контейнер это ubuntu там образ весил целых 500 мегабайт это очень много потому что микро сервисов должно быть много но зачем нам как бы лишнее место тратить мы решили даже в эту сторону на стороне прототипа закопаться посмотрели что есть всякие бизе бокс и очень сильно с ними заморачивались мы пытались там доставить туда питон чтобы on seba мог заходить туда и что-то там делать то есть заморочили даже с этим мы даже начали пилить и sdk на джаве изначально мы думали о скале она нам показалось это слишком хардкорным и мы решили взять изначально java запилите sdk для наших микро сервисов чтобы она много чего умело взяли грейбл чтобы подтягивать всякие библиотечки взяли джетте как основной сервер сервер для обработки фото по запросов взяли балансе пи как у соединений взяли g dbc без всяких фреймворков чтобы работать с базами совсем подряд ну да как было все стоп мы подумали это все про длилось примерно два месяца мы совсем поняли что мы них никуда не уходим мы застыли на месте мы изобретаем какие-то непонятные архитектуры и как бы в итоге что мы задеваем это все на продакшен там сотни просто новых технологий будет и какой-нибудь один микро сервис который там выплевывает хеллоу ворлд ну и что мы на этом проверим мы решили что все таки нужно остановиться ну надо же подумать все-таки как мы распилим наше приложение мы немного не с того конца начали и так надо выделить каждую группу методов в отдельный сервис не нужно пока заморачиваться с тем как это будет работать на продакшне нужно подумать в каких местах надрезать приложения чтобы ничего не отвалилось найти какой-то самый мелкий и не связанный сервис который без проблем можно вытащить из приложения и он не помешает никому и постепенно таким образом можно будет выделять сервисы переходя к более крупным и распиливаем более крупные на более мелкие то есть изначально мы все таки пошли по пути сервисной архитектуре на втором этапе прототипирование и так нужен какой-то прототип уже не архитектуры а все-таки приложения потому что в первую очередь мы делаем приложения мы взяли тяжелый метод у нас куча поисковых запросов в различные сервисы у нас куча команд отвечают за различные данные у нас есть команда который занимается полнотекстовым поиском чтобы понимать что люди ввели что им нужно отдать у нас есть куча запросов б.д. у нас есть формирование нескольких тысяч маркеров с хэшами для статистики которые отображаются на карты на карте ну и там куча на самом деле джейсона то есть здесь мы первое что делаем это мы ждем от backing сервисов ответа что на php происходит синхронно плюс мы делаем кучу работы на процессоре это работа с джейсоном работа с алгоритмами хэширование что в принципе можно конечно вынести все модуль но тогда какой у нас будет смысла вообще от php мы взяли вот такие технологии для прототипирования решили написать один и тот же метод на четырёх разных платформах то есть мы взяли наш базовый php взяли php 7 который обещает быть очень быстрым там мол ненастным что он там даст прирост неимоверный мы взяли джаву и взяли скалу чтобы было с чем сравнивать мы рассматривали и другие языки и чтобы всяких холиваров не разводить я не буду называть причины по которым мы отнимаем от них отказывались потому что мне кажется нет объективных причин выбора того или иного языка есть они такие субъективные больше ну естественно инструмент нужно выбирать от потребностей и критериев была куча поэтому вот мы выбрали именно вот эти технологии для себя решили попробовать поставили себе условие по которому наш прототип будет годным или негодным это целый по которому на 95 перцентиле мы должны отвечать за 300 миллисекунд то есть какое максимальное количество fps выдаст сервис чтобы на девяносто пятом пирсинг или он укладывался в 300 миллисекунд ответа мы написали все эти прототипы забудь марка ли и получили следующие результаты то есть базовая наша версия php на машинке с четырьмя ядрами и четырьмя гигами оперативы выдавала 30 fps на 40 fps просто все на черного умирать элла возрастал все падало вот ты смерть это именно такой показатель когда у нас все сервер можно сказать труб php 7 действительно дал прирост даже чуть больше чем в два раза мы вообще ничего не делали просто поставили пах и по 7 взяли наш код туда запихали и вот действительно все работает в два раза быстрее но нам все равно это не понравилось и мы написали еще же два прототипа на джаве на скале они показали приблизительно равные результаты вот нам это понравилось что в принципе там можно сказать в 6 раз больше чем изначально наш прототип и решили что это круто и будем делать все на скале и осталось только выбрать все-таки использовать скалу которая на первый взгляд вообще пугает она конечно симпатичнее чем or long я не хочу никого обидеть на действительно ну и есть java enterprise все на ней пишут куча всего уже есть и перейти из от php javi будет намного проще чем к скале потому что скала все-таки имеет подход функционального объектно-ориентированного программирования в отличие от джавы но нашли кучу плюсов у скалы это те же библиотеки что и у джавы только плюс еще есть куча своих которые более адаптированы к функциональному программированию получается гораздо меньше кода чем на джаве то есть если на джаве нам приходится создавать под каждый класс свой файл кто здесь у нас синтаксис языка позволяет это делать гораздо короче компактнее и на самом деле получается гораздо удобнее и очень много саксэс историю в микро сервисах и очень много секс истории тег компании которые на скале пишут свои продукты мне все замечательно все работает но это как тоже уже на конференции упоминалось можно сказать такая реклама но мы повелись все-таки на рекламу поэтому все получилось классно и еще один несомненный плюс это синхронности многопоточность скале она все-таки гораздо проще из коробки реализуется и плюс куча есть всяких сторонних библиотек которые делают все еще круче ну и такой большой для нас был плюс но он ни для кого наверно кроме нас не будет плюсом у нас в компании было уже несколько команд которые писали на скале и вообще так странно получилось что на джаве у нас писали только те кто разрабатывали под android и больше ничего в компании у нас на джаве не писалась на скале было несколько команд и они нам тоже порекомендовали говорят что ну из что у вас ребята поддержим всегда сможете у нас спросить все все будет типа у вас получится собственно прототипы были написаны и все это надо было как-то выливать на бой как-то тестировать пока мы отложили в сторону то наше архитектурное решение с докером с там с виртуализация мы с кучей сервисов решили это просто усачева протестировать естественно изначально решили как мы будем это встраивать в нашу старую систему потому что мы переписали какой-то один метод он у нас сейчас получается и на скале написан и на php и надо как-то вот в эту вот систему которую я самом начале показывал встроить нужно как-то интегрироваться этой системой мы решили что вот так вот зайдем с боку мы пропишем джинкс определенные локейшн и которые будут вести на наши up stream и то есть что именно вот этот метод будет обрабатываться нашей новой системой так мы решили что в будущем когда все методы будут переписываться вот этот конфиг джинкс а будет расширяться доля php кода будет уменьшаться доля скалы будет разрастаться микро сервис еще будут больше дробится на явиться в целом как бы воде общее решение в лоб простое на нам подошло мы развернулись и вылили на естественно вот так вот выглядела наша система у нас эти сервисы запущены на машинке та же самая структура что из php только вместо php у нас там работала скала то есть мы также выгребали логе также снимали какие-то показатели потому что так как код api мы переписывали все интерфейсы ответы у нас вся как бы инфраструктура она сохранилась поэтому мы могли просто переиспользовать на первом этапе все наработки которые у нас уже были немного расскажу тебя библиотечка которые мы за использовали именно уже в при разработке на скале в качестве хдп фреймворка мы взяли спрей он достаточно удобный на него короткая запись очень удобно писать road и описывать какие критерии должны обработать и чтобы запрос этот обработать мы взяли спрей джейсон для обработки джейсона и залей от той пса и в конфиге чтобы все конфиги у нас также были типизированные так как язык имеет статическую типизацию мы взяли аку для работы со синхронностью эта модель акторов для скалы взяли хикари себе это такой же bouncy п только немножко лучше он у нас там бывают на проблемы с bounce теперь когда мы еще делали прототипа они у нас почему-то с х прокси очень плохо дружили мы это очень много google или и вообще везде в итоге на stackoverflow и везде советовали но просто перейти на хикари себе чем разбираться так было дешевле с точки зрения разработки и мы отказались от полон себе в сторону хикари хиппи и также взяли dbc для работы с базой конфиг точнее не конфиг х такой и так скать код для спрея выглядит примерно вот так то есть у нас все достаточно коротко получается мы описываем путь который будет обработан входные параметры вызываем какую-то функцию которая у нас возвращает асинхронный ответ дожидаемся и исполнение и отдаем все клиенту джейсон нами работать тоже очень просто все получается нативно на нативных классах мы разгребаем джейсон получаем хорошие красивые объекты и types ее в конфиг про который тоже раскалов он поддерживает кучу типов данных там и бульоны строки и чисел ки и даже для времени есть тоже специальные директивы все очень удобно он в виде вложенного такого своеобразного джейсона получается вот и собственно у нас в итоге получился прототип такой натовского как основной язык тем сити в качестве сборки этого всего дела и тепло и на продакшен вот собственно с помощью ansi было но после того как весь этот прототип был написан мы придумали как мы будем интегрироваться с на продакшене я немного рассказал о том какие библиотечки мы за использовали потому что все и всех их не уместить вот оклад поэтому я кратко по ним пробежался из того что мы за использовали оставался один большой и крупный пункт для того чтобы это все выложить это тестирование но здесь никаких проблем у нас не возникло так как мы изначально решили пойти и нет архитектурных задач и и нет микро сервисной архитектуре от сервисный все протестирую достаточно просто у нас же есть наши функциональные интеграционные тесты на продукт который мы можем легко за использовать так как мы код переписываем у нас ок сохраняются все интерфейсы все ответы мы легко это можем все протестировать но тесты покрывают не весь продукт у нас еще есть такие штуки как нагрузка как вещи которые могут быть не покрыты еще к тому же мы с нагрузкой тоже поступили достаточно просто у нас есть команда нагрузочного тестирования в команд в компании протестировали все это иных станкам гатлинга по на пуляли ну и тем более когда мы изначально разрабатывали прототип на разных языках у нас эти бенчмарки уже были и мы в принципе были уверены в том что это все работает и будет работать лучше чем раньше ну и хочу порекомендовать неплохой инструмент это гор утилита написано на год мы ее использовали для как раз таки reverse инжиниринга мы easier коллировали трафик с продакшна на наше тестовое окружения и несколько дней там крутилась эта сборка то есть весь трафик который шел на продакшен шел к нам на тестовое окружения и мы могли отлавливать какие-то ошибки это очень удобно потому что тестами там ручным тестирование мне покроешься то что пользователи творят на продакшене поэтому вот убора очень много настроек он может определенные руи только прокси ровать может записать лог запросов файлик потом его воспроизводиться определенной скоростью то есть утилита действительно очень классно и удобно и она нам очень сильно помогла мы нашли около пяти багов в пышной реализации с помощью нее что у нас это работало в php ну работал немножко не так вот мы написали еще один простой скриптик который берет блог с продакшена access wog и кидает два запроса на старую версию и на новую и делает div джейсона этот тоже было основное такое такое основной проверкой перед тем как это выложить на продакшен мы убедились что действительно у нас все ответы соответствуют тому что было раньше и так у нас в итоге получилось следующая картина сборка нашего проекта теперь занимает 2 минуты вместо полутора часов но не надо забывать что как бы старая версия все равно живет и постепенно от нее нужно будет уходить в сторону новый но новый код новый функционал уже можно гораздо быстрее собирать эти плыть так как что это будет сервисной архитектура что микро сервисному выкатывать будем только тот кусок который изменился плюс если какие-то интеграционной зависимости появились тесты вместе с нагрузкой у нас теперь походит пять-десять минут потому что мы можем протестировать только тот участок который изменился не нужно тестировать все приложение дипой теперь занимает пять минут потому что у нас уже собран готовый jannik с нашим продуктом мы его просто доставили включили все работает и серверов у нас теперь есть вместо 18 и в их 6 они три потому что отказоустойчивость все-таки нужна одна нота теперь она стала гораздо тоньше у нас теперь там по 4 ядра 4 гигов оперативы точно так же как мы это то есть тестировали на продакшене средняя нагрузка на ней пять процентов максимальная которую мы только засекали на продакшне было 30 процентов вот собственно все переписали все выложили но естественно небес граблей мы наступили на несколько достаточно весомых граблей несмотря на то что мы против все протестировали нашими тестами мы прогнали нагрузку мы прогнали зеркалирования логос продакшна мы сравнили джейсон и и собственно все равно через неделю после того как это все работало на продакшене к нам прибежали ребята из других команд искали что у нас сегодня упала мы кидаем запросы на продакшен джейсон отдается все хорошо как вы думаете в чем могла быть загвоздка что могло произойти но я могу сказать что это достаточно такая странная для нас была вещь и мы ее не проверили это джейсон п это курсах и дыры мы их ставили вот и так как мы проектировали все запросы через наша старая опьянит этих ядер и дублировались и браузер и просто ругались на то что по федоров приходит 2 и запросы просто откидывать вот эту вещь невозможно было протестировать нашими тестами ничем вот не падала на течение недели потому что команда которая у нас работает с нашим api тот метод который мы делали они это был список просто наших регионов и и но этот метод который мы первым выкладывали он просто у них кашира вался и каждого организма соса когда сбросили она все упало и также так как мы работали через несколько прокси вторые грабли на которые мы наступили был грипп вот мы совсем про него забыли естественно тестами гриб тоже не покрывался и просто количество трафика у нас накопилось достаточно большое вот ну вот написали мы этот прототип чик выложили его на продакшен архитектурные все решения по поводу докера а тогда отложили в сторонку но как-то же дальше нужно развиваться и что я могу сказать что нужно просто продолжать распиливать сервисы выдирая кусочки из вашего приложения которые независимы друг от друга стараться эти зависимости максимально просто разрешить и вот так таким образом можно постепенно выдирать куски из приложения и переписывать их на что угодно нужно двигаться к поставленной цели все-таки которые изначально хотели там пусть у нас допустим целью был какой-то крутая платформа с виртуализации из контейнеризации с дагерами вот нужно к ней двигаться но постепенно я и тягать и вина и немножко хочу подвести итоги все таки наверное много раз это советуют все-таки поменьше велосипедов потому что все мы инженеры все мы хотим пилить чё то новое что-то крутое и хочется какие-то большие классные продукты выкатывать на продакшен но все-таки лучше это делать постепенно и не выкладывать кучу нового функционала сразу же на продакшен не нужно целиком переписывать весь продукт и как-то по-новому его туда выкладывать ставьте себе четкие цели цели которые достижимы то есть но опять же как я сказал уже не не нужно полгода что то делать а потом целиком все это на продакшен и как-то подменять и решайте проблемы по мере возникновения не пытайтесь преждевременно что-то оптимизировать что-то продумать что-то решить как бы продакшен он все покажет и все вам бы станет ясно куда дальше двигаться в каком направлении и как что делать и на этом у меня все спасибо за внимание 1 раз можно огромное спасибо за доклад на самом деле один злую что я сегодня слышал ее вчера с игорем я очень много вопросов ну вот один из первых наверное в итоге джокеру вы будете стремиться или совсем забили на него и на вторую еще один вопрос как вас получилось на скале быстрее чем над жареными вот так начну наверное с докера докера сейчас на продакшене нет это как я уже сказал что это как бы сложное архитектурное решение и вот так вот взять его резко выходить туда у нас пока не хватает наверное смелости это сделать вот но мы постепенно к этому двигаемся мы какие-то наработки ведем чтобы тоже опять же какой-то сервис взять выделить отдельно запаковать контейнер и пусть он там поживет вот он то есть чтобы не не целиком это все делать по поводу того как на скале получилось быстрее чем на джаве как я уже сказал на у нас компании на скале писала несколько мантра на джаве только те кто писали под android на естественно в приложение под android не пишет и просто скорее всего мы что-то сделали не так ну или возможно как так как была куча синхронных задач с которыми скала более правильно справлялась могу только так сказать еще короткий вопрос а какие нагрузки вас что еще раз нагрузка какая нагрузка на что на весь ваш сервер ну общая нагрузка на все api вообще сейчас это 2000 рпс этот вот тот сколько сейчас мы обрабатываем спасибо день и спасибо большое за доклад подскажите о первых сравнивали ли хип-хоп м то есть я смотрю изначально не ставили ее как вариант да мы его не не рассматривали у нас вообще были еще идеи даже из-за использовать возможно какие-то зефир и фэлкон и там вот хип-хоп машину в кпп мы решили что если рассматривать парапету например пхп 7 а если внедрять еще кучу каких-то новых технологий опять же но мы все равно не избавимся от проблемы с асинхронности то что мы не сможем обрабатывать что-то синхронно мы не избавимся от того что на php все-таки алгоритмы и хэширования и обработки там джейсона в трептов и прочих они будут работать медленнее чем на каких-то других платформах как ни крути и выносить это все все модули но это будет бессмысленно потому что ну зачем тогда вообще php нужен если и так что то выносить все модули поэтому размера образа если что говорится в кулуарах обращайтесь но они можно ubuntu ужать меньше чем 100 мегабайт и нормально это отличная продакшене то есть даже не тратьте время на xbox то есть все вот эти рекомендации когда говорят давайте мы сейчас джинкс засунем вместе с битбоксом контейнеры что там будет крутиться это не работает на продакшн это лажа пасибо осиба тоже за мороз еще раз спасибо за доклад очень познавательный вопросы у меня 2 1 технический уже использовали а крема утако кластер и для каких то целей нужно отзывы разные слышал но никто меня там у них ответить не можем нет к сожалению нет что да моя снежинка между микро сервисами использовать итак еще раз по для мессенджера между самими сервисами что используя для мыши джинга да сейчас на данный момент мы используем этот тип с джейсоном просто так исторически сложилось что мы делаем в папе и мы отдаем джейсон эпоха ттп поэтому мы решили тоже не накручивать пока кучу каких-то новых технологий там какие-нибудь про табов и 3 вт и еще куча очередей и это будет надо покрывать а будет тестами это надо будет проверять как это все работает эта куча будет overhead аюб а пока у нас все держится на этот тип с джейсоном между сервис вопрос второй более менеджерский не сталкивались с такой проблемой что просто разработчиков таскали не найти пока не не сталкивались так как вот у нас есть команда из 15 человек и мы постепенно людей перетягивали просто на скалу и перри переучивали цпп да я могу по себе сказать что вот через месяц уже люди вообще спокойно сидят и фига чуют на скале ну зависит от желания на самом деле так вот лю любой человек который хочет развиваться в эту стоил он будет развиваться из он не хочет но его как были заставлять же никто не будет поэтому у нас все все равно как бы и ну и php очень много в компании из скалы тоже присутствует другие команды они набирали людей они просто брали java разработчиков у которых тоже было желание например и попробовать их на скале и учили и внедряли в компанию понятно спасибо большое спасибо большое за доклад меня два таких вопроса первый вопрос вот я так понимаю что в итоге решили переписать и маленький кусочек вот и интересно сколько времени заняло переписывать маленький кусочек и какие есть эстимейт и поводу того когда будет переписана там все или большую часть на данный момент у нас переписанная одна из версий последних стабильный целиком на скалах и это у нас целиком самого начала когда мы еще делали прототипы в виде докеров и прочего это полгода прошло то есть за полгода мой целиком продукт перевели на скалу по поводу того чтобы вот этот маленький кусочек переписать но где-то по моему пара недель ушло на то чтобы ими написать еще пару недель ушло на то чтобы вообще понять что такое скала как она работает и как с ней общий жить понятно а сколько в объемах кода я не знаю было напишите сколько вы переписали за полгода в объемах кода мы к сожалению не измеряли вот ну так даже не скажу если честно ну наверное приблизительно столько же получается может быть где-то меньше где то больше то есть тут сложно сравнивать вы именно в строках ржавый могу точно сказать что кода было раза в три-четыре больше когда пили пили лик это сравнительный прототип с php точно не могу сказать это еще второй вопрос для сравнения были использованы печи печь себе 7 java искала а до этого вы упоминали что был как сервис нога написан а почему не выбрали года же для сравнения вот на первоначальном этапе да вот мы рассматривали очень много языков мы да мы думали и на java скрипте чего нибудь написать и на питоне not имеет если конкретно говорить про go to нас пока оттолкнула малое количество библиотек но все равно их действительно мало то есть тот же самый 3вт мы там три дня пытались завести чтобы хоть какая-то реализация 3вт онаго взлетела с этим ну может быть у нас к это сложность возникла ну и второй момент это было наличие idieyoudie багира хорошего ну то есть все равно от всеми нами известные фирмы под гору нету и даёте поэтому тоже это было бы весомый критерий у нас понятно эти большие у меня вопрос скажите почему тимси тяни классический дженкинс pipeline только потому что вы любите фирму или носите что-то предоставляет больше чем дженкинс но на самом деле просто дженкинс был уже давно в компании и хотелось чего-то нового попробовать вот мы использовали гид лап хотели попробовать гид lapsi а и но как-то тоже он нам не сильно понравился этим сети как-то так вот взлетел понравился и как-то вжился но тем более это такая вещь которая на сам продакшен на наших конечных пользователей особо не влияло и тут можно было в чем-то поэкспериментировать поэтому это был просто можно сказать эксперимент ну и плюс в тем сити нативно сбт сборщик для скалы нативно в поддержке идет ну то есть там более все-таки это как-то у-у-у нам показалось удобнее сделана из каких то прям объективных причин я не назову деннис спасибо вам за доклад всем спасибо тоже"
}