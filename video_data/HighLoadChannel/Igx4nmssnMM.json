{
  "video_id": "Igx4nmssnMM",
  "channel": "HighLoadChannel",
  "title": "Визуализация активности клиентов по всему миру в реальном времени / Александр Сербул (1С-Битрикс)",
  "views": 476,
  "duration": 2644,
  "published": "2017-04-22T14:48:19-07:00",
  "text": "коллеги добрый день александр сербул не зовут 1с битрикс я надеюсь мы пройдем полезным время с вами посмеемся поговорим о практическом опыте вот и уйдем с хорошим настроением вообще конечно я не думаю что у нас просто вид секса frontend поэтому я буду стояние фран . а бакенщик но пришлось заниматься фронтэнда вам пришлось бы делать карту мира визуализировать наших клиентов по всему миру значит чтобы это еще может обернулась еще поэтому не стесняйтесь задавайте пожалуйста вопросы я с удовольствием отвечу я сам как бы код писал и проектировал и разрабатывал там и анализ проводил из яндекс карты работалось javascript с джавой общем-то всего хватило но я бы хотел немножко начать другого с того что мы использовать парк streaming вот и хотелось бы надо тут хайланд написано вот что типа крутые технологии открыты до как бы все они знают но проблема с алгоритмами то есть явно в веб-разработке больше 10 лет и могу сказать что надо нам работать всем кто и веб-разработки может быть его front энди не знаю как надо алгоритмами потому что чтобы решать типовые задачи которые нам преподносит жизнь клиенты надо знать хорошо теорию а обычно все хороший программист это физики или инженеры это не математике вот и приходится как бы получать постоянно смежные знания и учиться я сам например учился в лес выглядит приборостроение приборы точной механики но 12 лет программирую поэтому приходится учиться читать там и математика это мы нейронные сети алгоритмы и постепенно-постепенно там лет через 5 мин допустим ты уже начинаешь ориентироваться более-менее ощущать себя уверенно в каких-то областях где то экспертом вот языки программирования семечки то есть почитал там выучил там бо удовольствие получил за прогорим что-то но опять же языке чем больше знаешь тем тем как бы пошли пишем более проста и лаконична как она сегодня цель но общем у нас есть сервис я не буду про него рассказывать им пользовались по всему миру это типа portal core портал в облаке возникла идея отобразить клиентов на карте так чтобы вот земной шарик крутишь и видишь клиентам о реальном времени приближаешь и видишь как они значит там копошатся приближаешь при ближайшей видишь прямо близко допустим вот данный момент где там клиенты чем этом занимаются но и они наиболее активны вот у нас около 2000 событий в секунду совершают клиенты по всему миру в принципе не то чтобы там сильный хайло но это не детская нагрузка согласитесь вам почти две тысячи событий агрегировать на лету наносить на карту это задачи интересная я сказал тут всплывает потока алгоритм агрегации естественно мы мы мы их пройдем потихонечку поговорим про них дальше как это всего визуализировать чем на чем java апплет html5 чем или застрелиться лучше поговорим как рисовать масштабирования хотелось бы масштабировать карту и чтобы работало быстро да и голова не болела ну конечно начале мы ищем готова одно из их правил разработчика опытного следующее правило чем меньше кода тем лучше вот это баги ему поддерживать нам поэтому надо уметь выбирать готовая первое куда сохранять события давайте определим у нас клиент выполнен действий сервисом регистрируется там запрашивать страницы на портал в облаке вот нет понятия ночи то есть он сервис у нас как бы со всем мира клиенты с утра до вечера ходят пользуется и америка и недели китае там и россия куда сохранять события около 2 часа быть в секунду как доставать обратно а как агрегацию делать это возникает вопрос и алгоритмические надо сначала значит разобраться так что такое это я у нас хранится быть и дальше ну конечно глупо предложение давайте все москве ли писаете табличку и потом оттуда забирать ну шальная мысль приходит но это как бы сарказм на самом деле не было все так смешно как печально потому что часто мы встречаем такие извращение когда пишут всю воду базу или башар едят базу вот а потом начинаются проблемы потому что нет по ним понятие алгоритмов то есть не понимают что там на самом деле дальше будет подходить ну из таких из интересных вещей которые есть на рынке которые можно взять используй готовы на мой взгляд вот есть мы начнем спин было закончим ходу пам мы пробежимся быстренько у нас будет теория и практика я просто хочу чтобы как бы вообще сухой хардкор не давать что мышка размять довольстве начали получать настроение повышаться и так пин-бар кто не знает вину bimbo это инструмент для онлайн агрегации данных реальном времени его написали гениальные ребята из из буду это алексей рыбак антон афгане многолетие используем в общем как она работает это движок внутри москве или куда сливаются события грамотно по протоколу hype без подтверждение доставки то есть эта штука работает при близком колоде они сливаются в память этого движка мой стиль а дальше вы идете простой агрегации выбираете исповедь и данные и можете рисовать играть каким образом вы понимаете как у вас данную минуту работает весь front-end и back-end добавляем метрики в разных участках у да и вы видите вы как бы вас рука на пульсе у вас там происходит серверами первое что можно было взять этапе ну потому что у нас в основном у нас продукт на печке бильбо понятно но ее сложно масштабировать мы пошли дальше а ну естественно и ботинки все знают что картинку все знают вообще штуку messing with enterprise машин что это такое мы значит клиент отправляет на кучу событий мы их собираем в очередь а потом обрабатываем ну известно всем что рыбинске написан эрланге or long этот замечательный язык для пункта ниже своей вот это классика как работает очень я думаю все знают мы вспомнились очереди хорошо но мы идем дальше что есть еще все знают до этого автора франц кафка конечно я не хочу не хочу проникнуть сказать я просто хочу чтобы вы знали что есть что капкана названа в честь франца кафки великого писателя немецком миска язычном значит кафка я думаю это наверное следующее поколение очередей кто не сталкиваться с кафкой как она работает кафка устроена вообще по-другому это очереди по теплу сам дурак то есть если рыбе think you накапливает очередь себя и выдержит у всех клиентов на контроль и кто читает очень он ru лететь-то кафка работает по-другому она работает так она сохраняет все события в один несколько файлов под названием шарды конец записывать но просто на диске файлы а клиенты говорят привет я клиенты дайте мне прочитать файл тебя жду этот куда сначала на тебе итератор читай сначала следующий клиент а мне дай пожалуйста нам середины файла и вот она тебе дают эту позицию и сам клиент говорит что он хочет почитать личку здесь то есть есть один файл и по нему бегают клиенты и каждый клиент сохранить у себя позицию откуда он читает чувствуете разницу тут есть очень хитрый по 2 так как клиент хранит состоянии позицию себя то кафка вообще ни за что не отвечает она так отпускать к этому файлик и считывают данным пошел клиентами и данный с этой позиции на 1 а также сначала на а я и ушел на понимаете вот ногти практически нагрузки такой как вода рынке нет теоретически потому что не нужно держать кучу клиенты уже держать кучу там и соедини статус в них и позицию каждого клиента все то есть ребята реально схалтурили ну эта штука стала развиваться она появилась linked in и теперь самое интересное самозванкой nazis использовать это решение как используя свое решение базированы как мы видим судя по api на кафки мы решили взять аналог кафки потому что у нас такой большой поток событий и мы не знаем сколько событий будет завтра потому что сервис развивается поток событий неуклонно растет понятно да как она работает идея то есть мы будем класть событие сюда дальше что еще у нас на поверхность на рынке есть апачи штурм apache штурм популярная тема такая toast породил сюда выполнение событий в которой может гибкий вал flow написано на кожу языке вот но у нас он не пошел а мы посмотрели как бы не совсем то что нам надо мы решили как бы молотком один одним все гвозди забивать сделать проще идем дальше уже hadoop поможет сохранить будем знать или груда вот тут я скажу очень кратко в общем есть году туда можно налить большие данные сохранять потом анализировать и потом запад рисовать карту мы используем hadoop активно топом и снова как бы опасения эта штука это несколько другая система это java hadoop добрый дерусь это спаркс туда попотеть то есть куча потрохов которые требуют достаточно интенсивной подготовки и там некий такой урок порог входа то есть обычном linux в админ открыть большие глаза выпучил скажу что это джоуи то что кластеру а где книжки читать книжки нам айда полгода книжку читать и все это риск но при этом эта система как бы она достаточно но у нас мы активно используем как бы для другим ножки других задач и вот но не увлекаемся hadoop вам как я уже сказал и слоны могут взбеситься у вас все запутается у вас станет бэкон сложным у вас появится кластер pdf из вас по яйцам определюсь который будет там где-то работать где-то нет надо будет короче программировать на java там и правда на печке программировать первое время для ходу по то есть с ходу пам аккуратно сразу предупреждаю ну вот не надо использовать технологию если просто оно есть не надо это риски что еще какие вылазит вещи в ходу были тур на поверхности не описаны это локальность данных чтобы работало быстро у вас данный должна брать хранится обрабатываться локально если алгоритм этом не способствует у вас будут проблемы дальше для обработки больших объемов данных с помощью ему придется необходимо друге lga ритм которые умеют они понимают повредился вот дальше могут возникнут сетевые издержки нас синхронизации и так далее вы потеряете скорость поэтому иногда и часто можно клуб заменить обычным сервером алгоритму алгоритме которые распускаются внутри на этом машине вот в оперативной памяти и это будто бы дать бы встречи в ходу то есть не надо сразу лезь в эти красивые слова просто пишите простой код и попробуйте более провести решение и все измеряем дальше так сейчас - микрофоном что-то слышно хорошо дальше естественно если вы рассмотрите ходу бы вы рассмотрите spark кто сталкивался с парком spark ну я так скажу это можете это развитие инфраструктуры hadoop для параллельных вычислений что дает spark он дает более быстрый вычисление за счет того что вычисление происходит обработка данных происходит в оперативной памяти в основном вот и данный там кэшируется пока развертывается просто быстро но опять-таки и помните пройти длинный потроха я и без всяких слонов потому что в ходу при все вот так вот связаны между собой и там человек потянешь куча конфигов библиотек куча парту в каких то надо открывать и так далее в парк мы используем значит что по поводу sparco и по поводу обработки событий из парка значит что нужно знать нужно следующим аппарате купап радиус легко перекладывается на я закрыть он алгебре наш любимый это решен алгебра вот книжечка маньяков мы ссср царского лишь те так отлично книжках скачайте почитайте и лучше вы пришли несколько раз это алгоритмы по работе с большими данными будущем там есть целый раздел как переложить операции лицо на алгебры и стиль а-ля сильно повредил таким образом мужчина с парка вы можете выполнять произвольные операции лицо набью по обработке данных по тот потасовки по обработке события группировкой там об это фильтры to join так далее и тому подобное старый добрый стиль в общем получается вы можете делать из какие запросы по данным которые у вас размещена есть в серверах если вы скулите hadoop из парка либо используйте hive который выполните запрос либо использовать квн с этим понятно как это выглядит продакшене с barcode ну это java в принципе простой код работать коллекциями если этот если у вас было восемь там используется уже эти функции поддерживать анонимные явно то там вот это вот потрохов уже не будет будут более лаконичной структуры в принципе то есть проблем с раб обработка в парке мы не нашли внедряется легко работает быстро задачи выполняет хорошо и если данных много не помещаются в базе пожалуйста в их выбрал работать в парке вот теперь алгоритмы у нас идет поток событий агрегации так далее надо знать что когда у вас онлайн поток у вас уже не работает классический алгоритмов почему потому что данный постоянно льются вам надо допустимо надо данный вот у нас дальше будет мы будем пока что говорить наши задачи класс резать данные вам как вы будете класс 3 заводь но есть классический бардак алгоритм известен который уже проходит в первом классе средней школы ты cummins вот в потоке он работает медленно потому что алгоритмическая стоимость если я не ошибаюсь в кубе от количества элементов страшно то есть сумасшедший алгоритмическая стоимость вот то есть опять вы будете искать потока алгоритм пастеризации вот самый известный алгоритм наверно самый известный которые вот понятен которые можно объяснить за чашкой чая вот выйти объяснить за кексом это блин фильтр как он работает это самый красивый наверное из-за потоков алгоритмов божественно простой и понятный дальше встречу говорит им это выделю поиск уникальных элементов потоки агрегация значит дальше количество там единичек в потоке и так далее то есть такие задачи как количество элементов уникального где-то видел в программе был доклад просто знаете что там есть алгоритм и другие их надо знать книжкой напугал какую одну из книжек можно взять из компьютер останется вот я дальше еще момент я прошу прощения как бы вы как бы ехал вам про как должен сказать я вам рассказывал остальном на тему я готовлю готовлю потому что мы пришли понимающе как эти проблемы теперь война систем honey а чем я хочу тут сказать сейчас на самом деле война идет всей при тяга делал на себя с одной стороны классика майский майский этому рак мозга из они говорят что это но и стильность и фигня вот мы у нас все это можно по можно делать может быть и но мы знаем что там не все так гладко и дальше начинающий лагерь . как вообще . знаете это был amazon в котором давили на и хищников давайте сохраняйте гады заказы корзины не теряйте они собрали кучу к его истории джим в кольцо и получилась у них решение под названием зон где нам тебе потом переманили одного программиста индусам в фейсбук и он написал кассандру то есть это такие бизнес-решения который принимать под давление по сути это набор ты был у стороже объемных простыми алгоритм который крестил сохраняют хорошо что-то еще могут делать но уже скрипя то есть транзакции нормальных там нету там через дикий костыли их можно делать ну то есть они не совсем для этого но они не поддерживают абстракцию весит атома раз коэффициент изолированности и надежность которая есть в классических и решениях в задачи которых истории мешали коды дайте то есть но и склеили такой упрощённый для бизнеса дальше третий лагерь сейчас появился появился не сейчас но он сейчас активно как пробивает себе дорогу в жизни это массив marvel процесса решения impala просто amazon решит vertica это такие вот до товаре house и которые претендуют на то что они гораздо лучше справляются задачей аналитики чем вот эти решения классические на самом деле часто да но в них опыт нас показывать наши указывать мы пробовали redshift вот там смерти кой то есть писать мне гораздо медленнее зато что-то под не покуда витьку быстрее опять это еще и лагерь и все они говорят что мы мы и big data типа друзья наши значит выбрать теперь ну и четвертый такой вот тоже вот такой вот есть направление это из цельного бранился но то что он сейчас показывал version алгеброй мапри deus ребята говорят что если в выпить достаточно пиво то можно в принципе виски или исполнять помощью х его киберспорт и склеили ореховых достаточному на самом деле да и вы будете выполнять огромной скале запросы по данным но склон склонен запросов если это моли мало данных маленький запрос она будет конечно медленнее чем с помощью классических решений поэтому я не даю рецептов я показываю что есть проблема такая мы используем у себя скажу что мы опытом делимся динамо тебе качестве скейлер кости классики mais quel здесь мы частично используем hive вот эти штуки попробовали но они подают паб это та штука падает по памяти то есть впечатление что это еще сырые решения и как ты бы мне не особо у пока не нашли у нас дальше лямда архитектуры помните да лямочка вот еще момент и архитектуры конечно мы сталкиваемся с вами здесь нам таких случилось из потока событий что-то в онлайне будем работать что ты будем в плане возможно класс телема приди сюда выходу им что-то будет в онлайне висеть какую-то процесс вывод на карту такой леандр архитектура знаете это batch processing ночью что-то запускаем процесс на 5 часов это у нас real-time processing когда мы общаемся с картой в онлайне в принципе все это нужно что нужно знать или архитектуре я не мог не вставить проект слайд про эту игру кто помнит ну почему потому что лямда ну как минимум и так значит как устроен наш облачный сервис рекомендаций с которая перехожу на карту как мы собираем данные у нас есть события которые совершают люди в облачном сервисе и в интернет-магазинах тип четырех типов заказ оплата события просмотр товара добавление в корзину мы всех в склеиваем к одной cookies то есть объединим по cooking у к отдается с отдельного домена и человек с этой куклой что-то делает естественно потом приходит события по этой cookies мы потом данный накапливать что тут происходит на название товара категории тогда дальше мы принимаем их все и привет из twin запросов сохраняем и дальше у нас что-то типа происходит с для архитектуры брать противника и ловим процессе выдает это ключевая информация рекомендация как это устроено и глубже на входе у нас как ни странно старый добрый джин x спасибо нашему мнению игры со слоем вот но так как программировать наряженных трудно он плохо документирован и модуль написать но доноси программировать и полгода потому искать утечки в памяти есть более простой решения вы пишете на lua lua джи ти вот и вставляйте в джон этот модуль а так высоко у него логика ну вот и коля javascript можно сказать язык придуманы я так понимаю монахами бразильские католическим которых бразилии я разделил этот модуль в этом модуле мы обрабатываем данный пригодич пакет и сохраняем их в amazon кризис будет вот эта очередь которая оля пачиков к никаких нареканий на работу сервиса у вас нет мы сами в амазоне в несколько дата-центрах размещены по всему миру то есть сохраните в буду если вы не помазание то это допустим в кадку с пробитым kill если как бы хотите там ночь не спать дальше это все обрабатывается worker in a beach ну я потом программу чем скажу потому что часть для карта барбадосе джавы дальше это все сохранится в динамо диагностика или решением дальше значит часть выгружается файл в истре это объектные хранилище но если у вас ней стрита вас наверно будет тогда что-то типа openstack свифт друг box оля объектный хранилище затем происходит обработка классе или spark событий вот и что-то на карту а что-то мы выдаем мы еще будем персональной комбинации людям позитив на ваши сайты с помощью математики и the apache и том кого то почему библиотека и выдача рекомендаций теперь конкретно мы пришли к карте принципе вспомнив различные наши технологии и так для карты мы используем spark стримингом что это такое эта технология которая вот здесь вот я вам покажу вот здесь a spark streaming как он работает у вас льется поток данных sporting вводят абстракцию это кластер некий выпускать его на n машину в случае там на 2 небольших машинках у нас окружности поддержка карт и то есть каких-то три водных ресурсов морских нет этот кластер создает абстракцию под названием окно он дискредитирует потом перевозить поток он в радовать на кусочки данном случае эти кусочки по 30 секунд до такие ds3 этот дискретных дискретной кусочку только для вас значит ты за 30 секунд все что было вам приходит он дергает ваш обработчик вы пишете обработчик который данный затрите культурный кластер обрабатывает обработчику пишите на языке спарка то есть это на языке коллекции спарка чтобы там делаем там джалла я вам дальше расскажу что происходит но я принимаю эти все события которые произошли во всем мире я определяю координаты по адресу из этого процесса мы взяли баску макс mayn't вот и пришлось записать кэширование потому что напрямую там она у них специально есть файл хранения в ней можно будет пустить загружать ну можно в принципе и уступа на рыбалке страшно форматом для этого в этом фишер написать письмо каширин ответы памяти немного там данных она кашира затем ну просто мы удалось решить задачу просто на 1 но не надо и сервис сформировать хеш-таблицу это java стройны хэш-таблица месте к специальной структура данных гиа . доменов вот затем выгружаем там раздают определён оторвал джейсон а дальше еще стоит 1 3 затар назвать совет который формирует reserator 2 карты как это выглядит вот живу я вчера снял скрины эти запущенного spark кластер вот значит это статистика по обработке 100 последних матчей spark стриминга то есть вот у нас 1700 примерно в среднем 800 почти событий секунду приходит и мы обрабатываем их ну в среднем ладен секунд то есть пришло к но за 30 секунд я за 1 секунду обработал данные потом через какое то время вы уже их джейсон дальше стоит уже 1 3 затар таким образом если поток бы увеличиваться но просто данный будет больше вот это время будет и значительно расти то есть если я буду не успевать за 30 секунд обработать дискретный stream тогда я просто увеличиваю не знаю там прожарки либо второй процесс запущен отжарен в принципе этого хватает оказалось что дохлого кластера на spark стриминге на 2 машинках слабеньких вот и процесса на джаве достаточно чтобы поддерживать в 2000 с обойти секунды которые приходят и агрегировать их и еще нас мы еще с запасом в нем как это работает более детально 7 жало вот значит дальше kinesis amazon мы из него читает sports 3 мин то есть адаптер для amazon кризиса ну или для кафки в принципе вы если ласков к затем я обрабатываю данные spark стриминга не sporting возвращает синхронно данный последовательно вот эти окна по 30 секунд дальше к и получи окну и дальше могу это окно обработать тоже на классе risport на 3 машины на 20 мне достаточно я пока даже локально обработан в памяти них то есть я к тому что если у вас данных гораздо больше вы тут очень любить вот я кладу данные ogio точках и стандартные структуры джалла это хэш map а чем я говорил вначале алгоритму to the programmer если уже есть готовая jarik куча готовых хороших структур данных качественных шмап стенька это координаты ту часть . , информации о точке вот в точку я кладу важный момент вот здесь я по это объект 50 строк я кладу в линьки глист связанный список я кладу time stamp и точек мне надо знать сколько было событий по данного типа в данной точке ну то есть у нас события по всему миру они привязаны к точкам каждая точка меня списке по разным типом события идут вот лист вот то есть и естественно и происходит очистка причем бана происходит синхронным образом 1 3 секунд но очень быстро пробегаю полностью все геоточки их порядка больше двадцати тысяч больше двадцати тысяч точек это если да да больше двадцати тысяч всего вот в которых данный хита хранятся там уже гораздо больше данных вот я их прочищают дальше значит загружают эти все данные собирай домены в точке happy выгружаю их ребекка пробегаю по оператору принципе всему все это вся эта кухня вместе в онлайне на сервере занимает в памяти всего около 5 гигабайт то есть оказалось что весь мир кучу клиентов хайло там две тысячи событий в секунду если нормально запрограммировать аккуратно на нормальном языке то 5 гигабайт и у вас все точки живут дальше как это устроено более подробно барс пор streaming хэш-таблица где геоточки скорбя этим накапливают лемке крис листах примитивностью карданов такая информация хитах garbage запускается регулярно дальше мы думали замутить с vip сокетами но оказалось что пока даже не надо пока принципе визуализируется все нормально клиентам нравится нам самим нравится мы остановились на том что мы выгружаем джейсон файл а дальше мы его роста рисуем об этом я сейчас расскажу подробно кристаллизатор этот работает и дальше уже в яндекс карты дальше я потом нас крутые яндекс карт и яндекс карты какая была проблема мы выбирали google яндекс и от ближе к бриллиантах в принципе документация есть яндекс карте но такая вот не ко всему лезть в исходнике про тем более в java скрипте как-то не хочется а пришлось когда мы в лоб по пытаясь нанести все объекты где у нас есть клиенты это вот больше двадцати тысяч на карту отдать когда тебя карта все наши объекты короче на вот тебе горе и наноси она браузер завис все заглючила короче стала долго висеть то есть сериала скрипт умер вместе тянуть карты потом мы решили использовать строю кластеризацию all big ниже кто-то использовал кристаллизацией из карт глубоко то есть у вас три у вас несколько этапов вы сначала вы в лоб наносите объекта на яндекс-карту просто берете и наносите и все если объектов около тысячи вы же у вас просто все лежит они сами в этом говорят то есть тут они честны дальше вы можете использовать встроенный кластер из 13 у вас и надо все объекты в этом узнаете только объекты основные объекты ну например что потом приближайте карту раз там еще 100 объектов приезжайте еще стать таким образом волосы десятки тысяч объектов а больше они как бы отображаются но сразу в 20000 изобразите властью там замажется все будет меньше 0 и кластеризация тоже оказалась работать медленно потому что javascript потому что в памяти браузер это все потому что я знаю почему тут в общем решение из коробки не заработал мы взяли уже реализовали самую сложную технику это ремонта big тоже это сервер closer а то есть мы кластеризацию реализовали у себя на сервере таким образом что карта карта обращается к нам и говорит привет я карта но мой масштаб там такой-то вся карта мира дай мне точки я говорю вот там 15 . тебе и в каждой точке самое важное я считаю сколько внутри внутри компании объектов я дальше то есть вся математика на сервере причем на печке и оказалось что божий задачу быстро и дешево дальше вы говорите анакапри бесит удар кликайте на карту система приблизилась говорит мне слушай теперь я уже здесь какие у тебя точки масштаб увеличится говоря теперь точек 50 дальше и таким образом вы снижаетесь до низкого уровня приближения я дальше это покажу как работать вот это то есть как нужно было выглядеть все тысяч десятки тысяч точек в в онлайне а там же ты по карте так едешь как мышка кликаешь постоянно ты постоянно к этому раз театру должны обращаться как и врезалась чтобы не тормозил чтобы он работал там в десятки сотни миллисекунд не больше как то есть делать cummins кластеризации или потоков гастрита какую-то оказалось гораздо проще оказалось достаточно было разбить карту на вот такие начат на квадраты посчитать количество точек в квадрате и дать объект в центре то есть объект координаты которого равны и центроид то есть центральная точка между этими . все то есть фактически это растеризации получилось то есть просто очень простой алгоритм кластеризация даже не cummins и гораздо проще и он оказался работает и наглядно и эффективно и быстро и удобно опять же задача решили просто голод хотя можно было забыть как бы центроид фактически мы выводим сам код app store за таро на печке занимает сейчас вам скажу стоп 30 наверное все вся математика но там хитрым этим хитрого не ниже мужчина объяснил квадраты суммируйте точки еще исчислению точку выводите считать количество математика казалось божественно просто и эффективно в этом мне кажется это решение то есть сначала мы вывели вот так вот карту нашу это первая версия на полгода назад запущена было вот мы выводили круги и количество компаний в каждом круге все это можно пробежать удалять и в это было не все у нас животам раз в одну-две минуты обновления а потом мы мы доработали вы стали сохранить все хиты вообще все события в каждой точке в мире мы стали писать в память сервера который данный момент происходит все а тут мы только конечно компании считали вот потом мы решили нарисовать термитов дня и ночи с ним расскажу принципе архитектура чуть-чуть была доработана чуть чуть чуть чуть стало больше жать процессора ну не то мне семь процентов 12 память чуде стало больше не забывайте есть сохраняя все хиты ну в принципе достаточно казалось текущих ресурсов и у нас получилось вот такая вот карта она часто как раз отображается во первых терминаторам не и ночи во вторых он это зеленое зеленые круги при зеленым цветом это интенсивность активности клиентов здесь то есть тем больше китов в точке совершенно за посление этой минуты тем этот цвет будет зелени то есть генерального эта карта висе на большом мониторе и вот это длине дни и ночи двигается постепенно и активность меняется на выходные такая активность потом начнет мы заметили что вот латинской америки активность днем растет нужно чистить что это наркотрафик находили значит пользоваться сервисом битрикс24 сам что там ну так такой фольклор у нас появилась конечно не так вот потом например когда здесь мочи и некоторые прям точки горят можно промеж отца глубже потом например интересно когда здесь вот восток уровень день начинается здесь вот еще как быть им ну а уже начинают компании гореть зеленые огни ты приближайся приезжайте виде в каком городе в каком там зеленом пункте кто-то там пользоваться сервисом в общем интересный эффект но так как это выглядит при приближении то есть вот до города мудаком ведь и как работает и 1 3 зации то есть мы увеличили мы если в нужной точке показали всему миру а мы их показа мужу на минимальном уровне приближение причем это все планы происходит вот как эта точка будет мы говорим это будет мигать вот этих дней меньше мигают общем получилось такая очень интересная штука мы делать для себя ну и сейчас как бы это добро жим клиентам и как бы такой вот вам получился интересным и с хайло дам из разрезаться из javascript вам так далее вот потом мы решили пойти дальше ну так можно визуализировать оказалось это несложно и на я вас ко мне надо долго программировать в принципе как бы мы поняли как то можно принципе весь код на javascript этом занимает но тоже муж ток 100 уступил и больше дальше если по яндекс карте дальше мы решили у нас есть сервис скоро сайта суть такая а фронтэнда тем более на секция то есть в ней сайт на него приходят клиенты я каждому клиенту внедряю в javascript логику которая выполняется после загрузки страницы которая собирает метрики нарежем тайминга обязательно видишь этой метопе и отправляем нам в облака таким образом я знаю о том с какой скоростью данной странице загружалась каждой странице сайта загружалась у клиента в браузере и мы сыграем эту статистику себя и мы мы можем сказать что на этом сайте части себе все нормально времени выполнении строительно серве то есть со временем когда запрос отправил и получил первый байт ответа все нормально со сервер работает хорошо админ может спать а я скрип тормозит потому что же время рендера которые на выигрыш то они считают он большую то есть фонтанчики на глюки тут у нас вот или там ресурсы долго загружались то есть еде например работает неэффективно и мы это дело считали раньше и выводили вот так вот на графике вот так вот видите 100 гр клиент заходила видел какие страницы у него с какой скорости загружались и здесь именно отображали распределения именно что тормозит то есть не именно как на сервере понимание тормозит клиентов браузере tor настоящий отладка отладка front-end а вот как это выглядело выглядит сейчас вот то есть это время это последний тысячи хитов у нас и разноцветно то есть вот это вот теперь это он по моему общем то посмотри что значит корчик видно что вот ответ сера то есть это именно сервер пи пи дон майский админ да иди сюда а это уже фран . иди сюда чувствуете разницу удобно вот таким и мы решили информация собирается мы решили вывести еще на карту чтобы я понимал кто на мой знаете у данный момент ходит после точки тут у нас получилась достаточно просто мы вывели и это уже включили вдоль сервис мы выйдем формацию с помощью 5 яндекс карта и вот этого уже 1 3 zatarra их инфраструктуры теперь человек видит значит вот сайт у него служу здесь и увидишь что клиент скорость клиентов здесь вот она достаточно быстрая а здесь медленная да где то красная получился такой инструмент дополнительно визуальные отладки где у клиентам плохо на карте мира вот и она тоже очень нравится и мы им этим инструментом активно пользуемся ну вот пример плохого сайта день оптимизирована скорость загрузки страницы отработки сразу чек заходят и виде что у него тормозит плохо если здесь будет отсюда это можно списать например на мобильный интернет это можно фильтровать да ну то есть при сдаче к все хорошо то это у этого сервера все плохо и надо копать уже дальше смотреть что у тебя за проблема потому что всем клиентам со всех точек которые к тебе ходят им плохо вот вот еще пример пример когда-то ужасать в украине стоит когда плохо человеку плохо стоят и вот я заканчиваю выступление наши рекомендации значит первое что нужно искать технологий который подойдет не надо забивать молотком одним лавкам там все гвозди не надо надо развиваться таким образом то есть мы из разного кучей технологий мы выбрали амазонка и nazis выбрали spark streaming мы выбрали джаву для реализации бэг-энда очень там кот кода получите сотен строк всего и был выбор или яндекс карты и простой раз редактор на печке который на занимать несколько десятков строк а можно было а можно было полгода программировать и три года исправить баги пример что не надо так делать дальше надо нарушать круга заручиться потому что мы видим чувствую сколь наступает мы видим технологий наступала spark hadoop и так далее надо разбираться особенно это касается визуализации фронтэнда потоков алгоритмов и так далее надо же чтобы он проектирование и классические алгоритмы потому что можно было в джаве сидеть выдумывать структуру данных о которых готовы это линьки для ест их ашманов и не все программисты к сожалению знают что для чего хэш могу использовать его язык используется к сожалению это нужно знать дальше теория с мишкой сложности если мы не понимали это мы был с камин сам до сих пор бы пытаясь стоимость n в кубе у ускорить или 1000 строк на песок на печке обычно разрезаться класть классический думать вот и побольше практике коллеги я закончил пожалуйста задавайте вопросы спасибо здравствуйте спасибо за доклад очень интересно познавательно у меня два вопроса первый по фронтэнда почему взяли именно яндекс карты а и слышали ли вы про бокс г л г с тянуть карты взяли потому что они отечественные вот и там как бы догадаться по русски мо бокс lg с нет но я вам настоятельно просим задам когда мы делали линию дни и ночи вот это казалось казалось диким кошмаром потому что готовлю ли отёк данных карт мы не нашли мы даже готова даже мы вытащили библиотеки какого-то бородатого last родового любителя которую выкатил javascript с этими видами значит поставили их вот десять раз вызывали шамана потому что куча математики но это не против нас область ну в общем то есть на сколько я знаю google в google картах там как-то проще там даже под готовы решить какой то есть терминатору это термин кстати это довольно сложен был на удивление по поводу терминатор кстати есть еще такой open source библиотека картографической лев лет для нее есть готовы плагины терминатором который отлично работает и для чего для военных картелей для google она ну ее можно использовать в яндекс картах но как бы ни по лицензионным соглашением по моему это не разрешено но ее можно использовать окон street map on допустим вот ленты сказать например там же вопросу как это визуализирует чем ну то есть у меня есть там есть допустим canvas да я могу что там рисовать то есть был бы было желание там как-то там через кого-то сделать быстро это тоже и сэкономить можно разрисовать на комати все чудесно по поводу вам бог сделал джесс он сделан на в jel и как бы в современных браузерах работает гораздо быстрее там также есть библиотека кластеризации и там отрисовывать 20 тысяч точек это вообще не проблема едут карты не google карты это да хотелось совместить нам хотел чтобы дома были города были его лишь там есть через и даже куда недавно берут openstreetmap вот если ты маг и суда нет это свободные данные то есть карта это не понятно да я посмотрю placebo но покрытие по россии допустим порой даже лучшим и яндекс было интересно так что советую посмотрите мой бог гаджет с очень хорошей библиотека и второй вопрос по поводу сервера не думали вы допустим взять postgres то есть сразу обрабатывать данные складывать их в под брестом vr дерево допустим и также считать там кнн допустим тот же самый но бэг-энде это тоже бы по моему быстро довольно работал не проводит известен так сильно не дружу как бы когда такие когда данным количеством растет там все больше больше не страшно нормально да я рекомендую тоже посмотреть и попробуйте это довольно team esko как бы кроме у нас если у нас несколько дата-центров там почти миллиону москве запущен у нас москве продакшен используется активно но когда такие потоковые задача встречаются мы стараемся традицию вообще традиционной теории уйти в сторону онлайн-хранилище а под где сумму наверное да там он поумней мы открыли конечно я здесь расширение как раз для этого и написано как бы для всех пространств операции как бы та самая на мой взгляд лучшего комфортное решение ведь мы обошлись обычно крышках и шмап памяти то есть там даже получилось база не нужно там можно просто мы там задача была spark стрип для того чтобы мы не писали свою логику там вот это вот time time time рядов готовое решение а то в джаве мы просто хэш табличка то есть там даже не дерево получилось у нас достаточно когда казалось обычных хэш таблица с ленкой глистами и все почти большое вам спасибо тоже коллеги чьи вопросы о чем-то добрый день спасибо за доклад подскажите пожалуйста вот во время сбора статистики по скорости загрузки страницы учитывается ли погрешность не загрузку дополнительных модулей в сторонних например там онлайн-чат так далее потому что в общем в тайминги приплюсовывается к общей скорости загрузки зачастую вот клиенты заблуждение приходит от них претензий что почему страница загрузится по всем то минному она кроется отлично все оптимизирована вот но там как какой-то мой консультант добавляет так сказать перца скорость ну пока мы просто замеряем даст им данный загажен taming то что он дает той да ему недели пока по модулям пока просто и этого саба статистика оказалась очень успешной для клиентов они увидят не пользу просто серая статистика админ показывает а именно что у тебя браузерная творилось понятно можно ворлд оф танкс играть против будет тормозить до у тебя то что все это подмена рендерится в это гораздо лучше в статистике чем был до этого спасибо коллеги еще вопросы есть если это вопросов можете помочь в кулуарах спасибо"
}