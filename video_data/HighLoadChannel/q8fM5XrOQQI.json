{
  "video_id": "q8fM5XrOQQI",
  "channel": "HighLoadChannel",
  "title": "Укрощение мифического чудовища: реальный опыт промышленного использования ScyllaDB / Илья Орлов",
  "views": 201,
  "duration": 2036,
  "published": "2023-10-06T07:20:29-07:00",
  "text": "раз раз монго Кассандра науськуэль все работает Всем здравствуйте я Орлов Илья техлит компании STM labs мы разрабатываем высоконагруженные решения для всевозможных задач для бизнес-порталов с использованием собственной платформы для мониторинга фискальных данных и много чего еще еще мы любим эксперименты Так мы развлекались с разными базами данных применяя их под различные задачи hbase Click House А в планах еще тарантулы в idb и вот какое-то время назад нам выпало возможность поэкспериментировать со сцилло диби да еще и на промышленных мощностях как же нам так повезло представим крупную Track and Trace систему отслеживающую судьбу каждой единицы товара от момента регистрации до продажи конечному пользователю объем информации в mongo db ранее выбранный в качестве оперативного хранилища растет неумолимое стремительно ведь даже если товар завершает свой жизненный цикл Нельзя просто так взять и удалить его из системы Представьте гору ненужных бумажек стоит ее выбросить чтобы тот же с более Осознать что там же был и гарантийный талон А так внезапно сломавшиеся посудомойки Что же делать с данными вероятность обращения к которым близка к нулю близка но не равна поэтому удалить их нельзя а загромождать ими оперативное хранилище непозволительная роскошь куда же их девать в архив там Им самое место требования к архиву существенно мягче чем к основному хранилищу читать оттуда будут редко Хотя Угадайте какой был первый запрос от бизнеса когда мы порадовали клиентов возможностью отправки данных в архив читая по губам правильно Как вернуть данные из архива скорость записи должна быть сопоставима со скоростью перехода товаров в конечное состояние то есть 3-4 мегабайта в секунду нам бы вполне хватило Главное чтобы данные хранились максимально компактно чем не поле для экспериментов хороший повод на деле опробовать альтернативную СУБД чтобы как гласит народная мудрость не класть все яйца в одну мангу Ну что ж Вызов принят рассмотрев несколько подходящих субдд мы наткнулись на силы db внимание дальше пойдет откровенная замануха во-первых заявленная производительность силы 12,5 тысяч запросов в секунду на физическое ядро учитывая что один запрос предполагает Пилот в 1 кб на 32-ядерном сервере мы получим РПС 400000 Ну или примерно 400 мегабайт в секунду понятно что это как заявленным расходом бензинового автомобиля в автосалоне но у нас привыкших карпес 40 тысяч такие цифры вызывали если неуважение то профессиональный интерес тем более было Разумное обоснование такое производительности реализация на c++ хотя и на плюсах реализовать можно так что получится усердный бобер но мы были настроены оптимистично так как осыре было множество восторженных отзывов на официальном сайте Но от известны в том числе отечественных компаний в одном из таких отзывов рассказывалось о возможности диплоисциллы на HDD дисках а не SSD как указано в официальной рекомендации такой эконом вариант С rps-записи 240 тысяч не 400 тысяч но нам этого бы хватило с избытком такой эконом вариант это четвертых в-пятых интерфейс сциллы заявлялся как аналогичный интерфейсу старой доброй Кассандры с которой какой-никакой но опыт у нас имелся performance тесты при этом по отзывам показывали что у сциллы скорость записи вдвое выше чем у Кассандры К тому же фастеле официальной документации в открытом доступе море а если чего нет посыли Наверняка есть По родственной ей кассандре думали Мы ну и наконец седьмых открытое сообщество и поддержка в лаке Что есть то есть В общем с тылла нас соблазнила решили мы с ней познакомиться поближе что она из себя представляет сцилла эта колоночные СУБД собственным алгоритмом утилизации памяти scpu на который как оказалось повлиять Извне особое нельзя это вам не Кассандра Дело в том что ссыла рассматривает весь кластер подключенных серверов как общую совокупность доступных процессорных ядер и именно между ядрами распределяет данные то есть одно ядро один шард Это позволяет для каждого сервера обеспечить нагрузку сопоставимую с его мощностью конечно ни о какой возможности ручного перераспределения потоков между задачами речь не идет ссылочка знает за вас просто коробка автомат Вот только неспроста даже в формуле-1 далеко не все болиды ездят на автоматах определившись СУБД мы стали готовить инфраструктуру развернули кейспейс логическое объединение данных в кластере из пяти 32-ядерных серверов с оперативной памятью 312 гигов каждый установили факторыпликации 3 все по без практики и решили начать с эконом варианта выбрали HDD диски а не SSD Типа если что переедем в силу уже легко можно добавлять новые мощности на горячую Ага схема данных который мы планировали архивировать идеально ложилась на концепцию кейки вэлью обозначенную в официальной документации ссылок в качестве образцовой иначе говоря словарь словарей выглядел это так первичным ключом записи и по совместительству ключом партиции стал product ID уникальный идентификатор продукта поэтому ключу располагался набор атрибутов описывающих состояние продукта на момент его выхода из оборота получалась такая таблица продактс на неключевые поля exect Date типа Data owner типа строка Мы решили сразу повесить индексы мало ли вдруг потом придется по ним поиск выполнять лучше сразу проиндексировать чем потом по миллиардом записи из нуля индекс устроить что осталось определиться с алгоритмом архивации решили архивировать в три этапа копирование из основного хранилища в архив валидация проверка что продукты ранее скопированные читаются из архива Удаление из основного хранилища Почему так сложно Дело в том что операция удаления сильно тормозило основное хранилище поэтому выполнять ее можно было только в периоды наименьшей нагрузки на систему валидацию же мы добавили руководствуясь правилом доверяемым проверяй скорее даже сработало профессиональная Интуиция и ведь как воду глядели пригодилось Разумеется прежде чем выкатывать решение в прод мы провели множество тестов в частности нагрузочное тестирование с использованием стандартной кассандровской утилиты Кассандра стресс-тест оно в частности показало что данные сциллу лучше отправлять пачками мы взяли запись размером 10 килобайт и получили производительность 5000 запросов в секунду примерно 45 мегабайт в секунду не 400 мегабайт и даже не 240 но все равно более чем достаточно Ура Теперь впрот если мы архивировали со скоростью такой же как Кассандра стресс тесте мы бы получили 400 миллионов записей в сутки на деле же Скорость одного только копирования составила 138 миллионов а с учетом последующих этапов получалось вообще 20 миллионов записей в сутки меньше скорости перехода товаров конечные состояния их выхода из оборота ничего думали Мы система стабилизируется откажемся от этапа валидации И все пойдет как надо и вот когда размер архива перевалил за терабайт Всё пошло но не туда более 50 процентов операций записи стали завершаться по тайм-ауту ссыло не успевала не записать не переварить отправленные в нее данные скорость копирования деградировала более чем в 5 раз со 138 до 26 миллионов записей в сутки а скорость архивации в целом снизилась даже не до 3 мб/с А еще сильнее из-за сильного замедления этапа валидации Это во-вторых в-третьих сила как и многие другие но используют реализуют коммуникацию данных и компактификация это занимало до 100 процентов ресурсов сциллы Мы конечно же захотели вмешаться ограничить количество потоков под эту операцию в кассандре же так можно значит и в ссыль и тоже можно не пока чудовище не переварится что съела пусть весь Мир подождет в-четвертых влоги ссылок стали появляться многочисленные сообщения об ошибке сохранении партийцы со слишком большим количеством записей речь шла О так называемых материнства на основе которых в стиле строится индексы иначе говоря Если значение индексируемого поля совпадает у слишком большого количества записей такой индекс строить нельзя Стоит ли говорить что у нас в тот момент в головах было только одно слово конечно же Это тупик но мы не сдались первым шагом на пути к решению проблемы должен был стать переезд на SSD диски но когда мы провели архивацию на SSD на тестовых серверах к нашим Великому зачарованию число тайм-аутов не поменялось Вообще практически не изменилось Да и особо прироста скорости копирования не получилось более того сам процесс переезда на SSD принес множество Сюрпризов борьба с которыми вполне заслуживает отдельного доклада если в двух словах То не стоит полагаться на документацию Например у сциллы есть конфигурационный параметр автобудстраб от которого во многом зависит Будет ли добавляемая в кластер машина с пустой базой подтягивать информацию с других серверов кластера или сама станет источником данных что соответственно придет к затиранию информации во всем кластере документация гласила что по умолчанию автобус трап равно True то есть первая опция но не уточнялась какой версии Угадайте повезло ли нам следующим шагом мы попробовали отключить автокомпотив как потом включали обратно на этапе простой сциллы то есть Удаление из основного хранилища на самом деле особых проблем с автокомпликацией с её отключением не случилось но такое отключение помогло решать части число тайм-аутов чуть снизилось но сама компактификация стала занимать несколько дней те кто имел дело с подрезкуль наверняка узнали дилемму с отключением автовакуума важный момент почему не стоило просто задирать тайм-аут завершение операции по тайм-ауту вовсе не означало что отправленные в силу записи не сохранились наоборот как показал весьма пригодившийся здесь этап валидации большая часть данных успевала записаться и валидация позволила даже в условиях многочисленных тайм-аутов продолжать перемещать данные в архив не увеличивая время операции до таймаута что касается проблемы с индексами от них пришлось отказаться по счастью в нашем случае они действительно были балластом но потенциальным пользователям ссылок стоит иметь ввиду это существенный недостаток который так и не был исправлен за время подготовки доклада Итак проблема медленная архивации никуда не делась после многочисленных профилирований и Брейн штормов мы пришли к выводу что сцилла просто не тянет установленную нами компрессию данных мы поменяли алгоритм сжатия с перестраховочного ZTE на приемлемые Z4 и наконец-то прогресс число тайм-аутов сократилось до нуля возросла скорость копирования до 200 миллионов записей в сутки и компактификации более того ссыла теперь даже позволяла проводить компактификацию параллельно с копированием решение проблемы с тайм-аутами позволило отказаться от этапа валидации нагружавшего многочисленными запросами на чтение отнюдь не приспособлены для этого сциллу но в алгоритм архивации стал значительно проще и вот теперь мы уперлись производительность mongo db который отказывалась поддерживать требуемую скорость удаления эта проблема решилась запланированным переездом на шарнированное хранилище это уже совсем другая история в итоге после применения вышеуказанных действий мы добились скорости архивации тогда именно архивации 300 миллионов записей в сутки Ну или 3-4 мегабайта в секунду что в разы превышало требуемое значение Это конечно не 400 мегабайт в секунду и даже не 240 но все же Ура товарищи проблема решилась резюмируя вышесказанное Что нужно принять во внимание если вы все же захотите использовать силу ха-ха во-первых сила подходит для хранения данных таких которые убираются формат словарей словарь словарей не больше не меньше и стоит забыть про индексы во-вторых компрессия имеет смысл как и в нашем эксперименте начать с максимальной и менять алгоритм сжатия Когда начнутся тайм-аут это позволит по крайней мере на начальном этапе экономить место по счастью сцилла позволяет поменять алгоритм сжатия легко и безболезненно в-третьих компактификация в силе практически Неуправляемые можно выбрать стратегию оптимальная стратегия инкрементная доступна только в платной версии для большинства же задач вполне подойдет дефолтовая СТС но она особо погоды не делает скажу только что автокомпозицию лучше не отключать и настраивать силу так чтобы одновременно и кушала и переваривала в-четвертых завершение операции по тайм-ауту вовсе не означает что операция не выполнилась поэтому валидация особенно начальном этапе будет не лишней это позволит предотвратить многократное повторное копирование одних и тех же записей ну и наконец в-пятых Не верьте документации на слово и обязательно проверяйте любое действие на тестовых серверах Особенно если это действие связано с изменением инфраструктуры даже простое добавление сервера кластер может привести к потере всех данных Как вы уже наверное поняли рекламировать тем более рекомендовать силу Я не собирался и не собираюсь сыровато еще но наличие таких решений особенно опенсорсных очень важно мы могли бы взять ту же mongo или кассандру и не заморачиваться экспериментами Но это путь в никуда Это убивает конкуренцию развитие по можно и нужно исследовать новые субдд и делиться своим опытом выскажу также крамольную мысль такое исследование должно быть предусмотрено в бюджете любого программного продукта ведь это же хорошо когда есть альтернативы Спасибо за внимание мои контакты ваши вопросы что Ну спасибо я на самом деле хотел завершить словами опыт ошибок трудных и там у тебя прям на слайде то же самое в общем мысли сходятся Надеюсь что кто-нибудь слушателей в трансляции или в зале воспользуются твоим опытом и может быть сэкономит какое-то время но я вижу уже вопросы есть Так что Илья перехватываю микрофон а я вот возьму и задам сам вопрос первый а Весь вот этот ваш богатый опыт вы разработчику сциллы отправили рассказали как какой у вас был замечательный опыт переезда на неё последний актуальные данные они еще не знают то что нас все хорошо то что плохо да на самом деле для них это не новость Благо ветхабе есть бак трекер у них и где все подобные проблемы описываются быстрее чем даже мы их находили отлично Ну что перейдем вопросам У меня вопрос возник по компрессии а компрессию удалось прямо на лету изменить без пережатия старых данных То есть он способен получается использовал использовал один алгоритм переключились и он старые данные все равно читает понимая каким алгоритм записаны они каким записаны новые или Пришлось все данные иммигрировать нет ничего не греют не пришлось всё действительно удалось сделать на лету то есть переключили там стоят данные сжатые по старому данные сжатые по новому Дай базе Спасибо Так кто А вот здесь вопрос Здравствуйте спасибо большое за доклад вот возникла два таких небольших вопроса Первый Вот вы сказали что все ваши проблемы решили смело говорить нажатия Но вот что за что 4 Ну они поддерживают конфигурацию Вы пробовали просто понизить уровень сжатия Вот и второй вопрос скорее эксплуатационный вот там уже есть у них как бы коммерческая лицензия рослицензия которая заставляет опенсера весь Исходный код проекта вот как вы с этим боролись что в итоге получилось а первый вопрос насчет варьирование настроек алгоритмов сжатия по факту разница между Z4 за этой стеди позволяет сжать до трех процентов от исходного результата Ну представляете Да какая там компрессия ls4 где-то до 20 с лишним процентов то есть поменьше и вот этот коридор который позволяет настраивать он менялся где-то на плюс минус 5 процентов не больше то есть мы естественно тоже сначала пытались уменьшить компрессию оставаясь рамках того же алгоритма но нет Пришлось применять более кардинальные меры второй вопрос насчет применения сложных решений но в принципе она у нас еще как экспериментально идет Поэтому особых ограничений насколько я помню страны лицензии быть не должно Ну и по факту мы когда общались с техподдержкой силы что интересно там отвечает сам Сити осылы а Вики Вити он никаких особых Замечаний не выказал хотя мы ему рассказывали что мы применяем вот это вот Open Source решения у себя но Естественно для коммерческой разработки Окей спасибо Так кто еще хочет у нас так вот вот там вот рука есть слушайте такой вопрос Вадим подольна Меня зовут у нас был опыт для кастомной задачи небольшой кастомной СУБД потому что просто мы не нашли ничего того чтобы подходило бы под решение наших задач конечно же видели скиллу и много чего другого Мы например для себя получили впечатляющие результаты которые нам были нужны Но мы писали сами там что из этого вышло это там другой вопрос А вы не пробовали решать свои задачи просто разработав под себя свой движок Это же не так сложно не то что полноценного движок который будет решать вашу задачу а нет ну можно конечно это для этого чтобы писать свои движки хорошо бы попробовать предметной области уже что-то имеющиеся скажем так посмотреть как Готовое решение если после того как Готовое решение Вы у вас не возникло желание чего-нибудь свое сделать а что касается желания скажу честно мучение со сциллой немножко убили такое желание как-то продолжать экспериментировать с ними Но вообще уже потом когда отпустила конечно такие мысли стали появляться Ну особенно вот после того как активно пообщались с евангелистом Тарантула Владимиром перепелицей тоже это вдохновило на какие-то идеи не скажу что насчет создания движка Но по крайней мере каких-то Спасибо Вам спасибо наверное подобные проекты всегда начинаются с того что Да тут на две недели работы давай так вот в конце зала У нас есть еще вопрос и потом здесь Привет меня зовут Кирилл я из почты mail.ru Спасибо за доклад в первую очередь и у нас в цели точнее в посте есть довольно много инсталляции сцил и тоже был разный опыт внедрения вопрос У меня тоже про компрессию то есть разница между форм и за std в основном в количестве процессорного времени которое требуется на сжатие и вот две логично гипотезы которые я вижу Первое это то что просто не хватает CPU для вашего кейса а вторая это то что могут неправильно быть настроены обработчики прерываний и тогда тайм-ауты начинаются из-за того что обработчик нам сетевого прерывания находится на Том трейде который сейчас запустил сжатие и вопрос У меня собственно в том пытались ли вы определить какой был когда у вас был и исключали вы именно эти две гипотезы Спасибо Кирилл вчера что именно вы задали вопрос потому что вот это вот идея с применением HDD дисков было как раз была озвучена как раз в докладе Кирилл он даже есть на сайте ссылок насчет проверки гипотез а Ну естественно мы полагались на результаты профилирования мониторинга там сразу было видно что CPU зашкаливал прям буквально сразу как компактификация начиналась правильно сожатием сразу все сто процентов насчет исключений наверное точно не скажу но учитывая что не встречалась мне Ну кейсов связанных с решением Но если пологом искать Что можно сделать не было там Вот таких вот кейсов указываешь найти Exception так и у нас вопрос еще здесь Большое спасибо за восхитительный доклад меня очень вдохновил ваш совет вбежать каждого проекта предусмотреть бюджет на вот эти вот страдания борьбу с чудовищами но не лучше ли будет потратить все эти многочисленные бюджеты на создание новых чудовищ вот как предлагали люди Чем бороться с существующим Угу спасибо за вопрос тоже связанный с энтузиазмом может даже и лучше но все-таки для того чтобы писать свой движок так чтобы он потом пошел в прод и начал решать задачи предусматривающие высокую ответственность должен быть высокий уровень экспертизы ни у одного не у двух ни у трех разработчиков все-таки чуть большего количества и Хорошо если этот опыт можно где-то наработать но уже имеющихся решений но продолжать искать дальше копать в сторону дальнейшего усовершенствование No SQL Ну наверное все еще знаете про эту перспективу нее SQL который этой идее которая хочет себя вобрать плюсы подхода и новый SQL и стать новой идеальной СУБД на все случаи жизни для любой ситуации Если есть возможность создавать новый движок пожалуйста если нет то хотя бы исследовать то что имеется потому что качественные исследования проверка тестирования опенсорных продуктов это залог развития не только собственные этих продуктов но и вообще всей отрасли Так мы создадим тестировщиков чудовищ они создатели чудовищ а чем плохие тестировщики чудовищ прекрасны Особенно если они с опытом разработчиков которые могут сразу ткнуть в больное место чтобы чудовище сказала что у него болит Ну или просто проскурила Спасибо большое Так кто еще хочет задать вопрос мне почему-то сразу вспомнила шутка про 14 конкурирующих стандартов вот когда стали обсуждать создание своего чудовища Так кто еще хочет обсудить Укрощение чудовищ Ну кажется что все вопросы заданные поэтому настало время выбрать кто же получит подарок за самый лучший вопрос тебя есть Два подарка да первый подарок за вопрос который скажем так всколыхнул самые сильные переживания по поводу этих алгоритмов сжатия это вот кто первый сдавал вопрос да сюда и второй второй вопрос который заставил чуть больше задуматься об использовании опенсорных лицензий сюда пожалуйста Так кто у нас так Ну что у нас традиционно есть подарок для спикера давайте мы сейчас"
}