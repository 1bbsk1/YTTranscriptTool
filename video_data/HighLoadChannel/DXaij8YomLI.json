{
  "video_id": "DXaij8YomLI",
  "channel": "HighLoadChannel",
  "title": "Делаем бэкенд нового поколения на FoundationDB / Олег Илларионов (Capture)",
  "views": 3348,
  "duration": 3015,
  "published": "2019-05-15T02:25:58-07:00",
  "text": "для начала хочется начать с моего бэкграунда власть в убита лет 10 назад и в самом начале меня было два уникальных умения которыми очень гордился это писать супер страшные гигантские регулярные выражения и писать адские и ужасные скорее запросы однако со временем когда я пришел работать в vk я выдел примерно вот это это меня очень удивило то есть вместо сложных интересных и классных выражений весь код был написан очень примитивными запросами тогда мне объяснили что это масштабируемости так в общем и целом началось мое знакомство с хай-лоу дом со временем конечно мы переписали большую часть века тогда и переписали на движке но проблема которая хочу рассказать никуда не делось то есть движки решили проблему производительности но есть другая проблема есть когда вы пишете масштабируемый backend который распределяется большое количество серверов есть проблема синхронизации данных по английски называется консистенции и вот хочется эта проблема посмотреть на очень простом примере о предположим у нас есть два человека не добавляются друг другу друзья там в языке сложных если запрос фото 1 на самом деле не сложный и скорее запрос но когда у вас все от масштабирована и разбита на сервера ситуация становится чуть сложнее то 4 тоже простых совсем простых но четыре отдельных искали запросы и в нашем случае были четыре запроса в разные места первый запрос мы добыл человека в список друзей человека b второй запрос мы добавляем человека b в список друзей человека а и дальше мы должны сделать два запросы чтобы поднять счетчики количество друзей обоим людям и проблема в том что все эти данные лежат на разных серверах потому что мы их запасы вашего и мы не должны быть сгруппированы то есть грубо говоря мы запрашиваем счетчики каждого человека вместе с их профилям и они должны лежать там же где их профиль а списке друзей они должны лежать отдельным точно не должны масштабируется они иногда большие и так далее соответственно вся все веселье начинается когда у нас все работает не очень хорошо когда какой-то из серверов отвалился например где лежат какая какая-то из этих данных и происходит непредсказуемые вещи потому что вот в данном примере я назвал четыре сущности и любая из этих сущности в любой момент может пропасть на имя виду любой любой зафиксировав может пропасть и когда мы пишем эти данные у нас происходят интересные ситуации то есть либо список друзей какого-то из человек из человек не пополнился либо счетчик не про инкремента и так далее соответственно как можно бороться с этими вещами вконтакте мы делали 2 2 приема чтобы решать проблему первые это мы писали код который разрулю разруливает все в процессе в волне и запросов то есть например счетчик не проставился мы откатили все вернули ошибку пользователь увидел ошибку зато не произошло никакой рассинхронизацию он кликнул снова там все получилось либо если движок там лежит продолжительное время но у него два часа не не добавляется кто-то в друзья но зато у нас консистентные положение в базе и все замечательно второй способ это мы в процессе выполнения кода добавляли дополнительные проверки то есть например у нас идиот какой-то скажем так процесс не знаю к загрузке профили и в одном случае из десяти тысяч например мы смотрим а действительно него правильное количество друзей проверяем вытаскиваем там все счетчики сверяем видим ага тут есть ошибка пересчитываем исправляем а синхронизацию но оба этих способа довольно плохие дело в том что например при первом способе если у вас лежит не какой-то конкретный сервер а например глючит весь backend но нас периодически были такие ситуации это довольно занятная вещь приду пример например в центре вырубался электричество и из-за ошибки например инженеров которые все настраивали сервера перезагрузились потому что и писи врубился не сразу электричество подалось там задержкой 100 миллисекунд и все все все города лодзь все серверы reboot 0 и сивас ушел кэш ушел кэш глючит весь москаль тогда был мескаль сейчас движки сейчас все чуть лучше но все равно как бы все всё глючит и часть запросов довольно хаотично не приходит то есть не приходит запрос они в какой-то конкретный класс стр они приходят вообще везде запросы то есть где то приходит где-то нет и вот в этой схеме который показывал брючек слайде у вас может вообще в любое место отвалится любых два места и ситуации рассинхронизации возникают совершенно безумный и очень очень сложно что-то с этим сделать этим летом в самом начале лета в весной я покинул вконтакте чтобы основать новый проект вместе с алексеем мусиенко мы основали компанию коптеров технолоджис и уже подняли миллион долларов инвестиций в долине и у нас довольно интересная задача мы хотим немного немножко поменять то как люди коммуницируют не в рамках графа друзей а в рамках открытых каких-то обсуждений то есть это форуме reddit и так далее и для того чтобы решить эту проблему мы должны представить продукт который на десять порядков лучше чем все что сейчас есть и чтобы решить эту проблему настолько хорошо нужно применить весь арсенал который у нас есть выход в закромах то есть у нас будет очень сложная технология нейрона который может быть через год следующий раз мы расскажем и будет очень сложная технология по части бэг-энда о которой хочется рассказать сейчас и что чтобы вот так подвести к этой теме хочется сказать про такую как об теорему cup теорем это на самом деле никакая не теорема это эвристическое утверждение сформированная профессором берлинского университета или компьютером лет 18 назад и она гласит что при построении любой система распределенных вычислений очень скажу так невозможно добиться всех трех из представленных сущностей то есть можно добиться только целостности и доступности под целостностью имеется ввиду как раз вот консистентной из данных о которых я говорю о которой говорил ранее под доступностью имеется в виду что при нормальной работе база данных вы не отказывайте в каких-то запросах пользователям потому что понятно что can системности можно добиться очень легко если просто от отказывать от части запросов то есть например там не буду выставлять этого пользователь не верну вот этих пользователей сейчас и так далее масштабируемость в оригинале это портишь intolerance когда вы можете в любой момент разрезать ваши данные на две части и в общем и целом система продолжит работать практически все текущие решения находятся вот по в плоскости этой теоремы то есть пересечении каких-то двух кругов по середине загадочное место время от времени на это место претендуют попасть разные базы данных и это довольно занимательный процесс потому что много чего появляется и много баз данных заявляет что вот они вот та та та же здесь но с этим практически всегда проблема те базы данных которые максимально приблизились к этому месту обычно страдают дьявольский низкой производительностью это самая большая проблема в общем и целом таких систем и какое-то количество лет назад появилась довольно интересная технология в котором за вас foundation db и они представили очень интересные свойства своей базы данных них довольно сложный путь был они появились уже не поминали на в 2013 году про существовали несколько лет а потом их купил apple и купил довольно жестко в том плане что все пропало из skype пропали их репозитории все исчезло и все-таки а где вообще все наши разработки идут к то подход и тогда в общем про него все забыли потому что ну какой смысл там продолжать что-то делать с базой данных которая вдруг исчезла из всего интернета но как раз вот в этом году 2017 про open source all вдруг видимо не передумали эту базу данных она под открытой лицензии появилась на гитхабе и так далее а до этого она была платная но как раз интересно и что предлагает foundation тебе это как раз решение всех описанных проблем за маленькими исключениями то есть понятно есть свои трейдов и но зато с очень большой заявленной производительностью причем под производительностью имеется в виду не в не время выполнения запросов а именно общей из пут то есть сколько вы можете на одном сервере параллельно гонять транзакции и причем эта система которой она заточена под именно большие серая to see и тестирование вся разработка проходит в большие кастера проходит под скажем так под в масштабируемых таких январь моментах то есть эта база база которая работает хорошо ни на одном сервере а в кластере соответственно чтобы вот немножечко ввести в курс дела хочется объяснить что такое а как сетка транзакции все знают на что такое транзакции мы привыкли там мы искали везде писать трансакцию на есть его в общем и целом ацетат некая некий список требований который мы хотим получить от транзакции чтобы она в общем считалось правильные хороши чтобы могли пользоваться и не боятся ни за что и вот небольшое отступление что далеко не во всех базах вы можете делать транзакции которые скейлится между серверами то есть на самом деле очень мало бас сейчас существует где вы можете делать транзакция между данными которые будут работать на кластере не на конкретном сервере неограниченно конкретным сервером и на кластере и это как раз то что мешает и решать вот описанного мной проблема ранее рассинхронизации соответственно чем интересно fondation тебе что она поддерживает оксид транзакции если честно там все работает часть транзакции то есть любое действие которых делать из базовой вы делаете внутри транзакцию и все транзакции работают между всеми серверами то вы пишете транзакцию она работает везде для того чтобы упростить себе задачу разработчики foundation тебе сделали просто киева или сортов пива или это не какая-то конкретная интересная база где вас танк и не запросы документы еще что-то а это просто киеве лью работаете с ним соответственно уже вы как хотите для того чтобы сделать систему производительные разработчики написали небольшой такой свой язык называется flow меня твой слайд нет но очень важно сделали язык slow flow и он на самом деле настройка надо си плюс плюс а мы она позволяет просто писать такой гул стоял код с картинами с с чернилами и так далее которые просто компиляции вниз караульных си плюс плюс без какого-то вверх и до соответственно это не позволяет делать такие классные вещи как google для того чтобы там например грудь и мы распределялись между процессами там пока у вас там например восьмиядерный ком 8 процессов и грузин между ними много путешествуют а во float это исключительно на поточная история за счет этого в общем и целом такая дикая производительность и нам скачет вообще весь foundation тебе он сингл требует то есть и идея в том что вы каждый процесс запускайте на отдельном ядре и то есть если у вас 8 ядер вы запускаете 8 фонды это просто такое небольшое упрощение опять же чтобы разработчикам было проще сделать вот такую революционную штуку соответственно простаки и вылью просто одна процессор на я штука но зато решает все проблемы причем она сама масштабируется все добавляете новый сервер кластеры и все данные переставляются сами более того если один из серверов упал например то происходит очень интересная вещь данный не теряются если вы поставили в конфиге некий коэффициент репликации можно поставить два три это то на каком количестве серверов каждый ключ будет присутствовать соответственно если у вас каждый ключ и пришли на двух серверах один сервер какой-то упал то соответственно все ключи все еще доступны единственное что в определенных случаях зависимости от того какой сервер упал какую роль он выполнял потому что мир цитируемость пылятся разные роли какие-то из них отвечают за распределение запросов какие-то захоронения и так далее в некоторых случаях будет небольшая задержка обычно это где-то две секунды когда вообще весь кластер зависит от это неприятная вещь когда вас один сервер падает а зависает весь кластер но это довольно низкая цена особенно с учетом асинхронности клиентской библиотеке то есть это значит что вас не целится все будет две секунды а просто все запросы подвесной системе на две секунды дальше поедем как как как как раньше то есть вот такой маленькой ценой решаются на самом деле все проблемы со соответственно самое важное и самое вообще волнующей темой то что меня сподвигло вот ввязаться в эту всю историю и начать изучать fondation тебе это отказоустойчивость дело в том что и есть очень много видео статей как разработчикам удалось добиться отказоустойчивости и там довольно интересный процесс и дело в том что вообще отказоустойчивость в распределенных базы данных это безумная вообще вещи совершенно нереальная потому что вас в любой момент на любом сервере может случиться целых гигантский на борт неприятностей то есть например может отрубится сеть может сеть работать в одну сторону то есть input и не работаете от пут сломаться диск может тормозить диск и работать медленнее чем все остальное и и так далее то есть сервер может вырубиться может там зависнуть и часть чего-то будет работать часть нет того чтобы все эти моменты отладить flow встроили интересно такую вещь как симуляции это возможность прогонять разные сценарии в никому не реальном времени в том плане что ускорять течение времени то есть обманывать стены этой меры делать вид что там прошло столько-то времени что-то произошло и прогонять всякий сценарии например за ночь можно прогнать очень много сценариев и там исправить ошибку этот прием разработчики использовали чтобы общем и сделал и целом сделать действительно отказоустойчивые очень надежную базу данных fondation тебе позволяет хранить данные двумя способами это настраивается при конфигурировании есть два способа memory с sd memory это значит in in memory хранилище такая родная вещи всем кто работал с редисом то есть когда мы не можете хранить больше данных чем помещается в оперативку это самое производительное решение для хранения данных самое главное производительность то вот мои married правильное решение это единственно решение которое будет более менее эффективно работать если у вас нет детей потому что альтернатива это вот ssd режим когда все данные работают можно карантина больше чем позволяет оперативка но при этом если у вас есть среди диск то это будет работать отвратительно соответственно для ssd используется быть дерево изыскать light хочется отметить отдельно что обидно что это бы дерево не b плюс дерево потому что бы плюс дерево как мне кажется позволяла быстрее бежать снова пара сорта тресту сказкам делать но тем менее тут как бы у меня не хватает компетенции критиковать разработчиков наверное они знали что делают и в общем и целом теперь главная часть доклада как построить backend на основе всего этого потому что просто сорт от киева или это довольно обидно я штука в том плане что с ней надо работать руками и кажется что это сложно интер как сделать такие хитрые индексы на накивале вот об этом он будет доклад соответственно немножечко про backend в основном я буду говорить про синхронно языки то есть моем случае того хорошо меня поймут те кто пишет на ноги чуть хуже будет понимать тем кто пишет на там печка и так далее но буду объяснять детям прими примерно следующее что изначально fondation гибелью предлагали примерно такую схему что вот у вас есть кластера foundation тебе и вы должны написать некий или взять в open source техники слой дата был этот отдельный сервер который будет принимать от вас запросам в привычном вам языке там эскель еще что-нибудь какой-нибудь graph api и так далее и уже работать напрямую с fondation это до сих пор самое правильное наверно решение то что пропагандируются разработчиками но вот я например для себя решил делать множко по другому так как достаточно синхронный и в общем целом нет причин добавлять какую-то еще прослойку почему не делать на не использовать простой библиотек который быть напрямую работает fondation тебе будет более тесно интегрирована с вашим брендом на моем опыте это очень хорошее решение потому что можно не делать огромное количество вещей которые то есть вам нужно придумывать какой-то язык общения с вашим слоем там граф документа рита какой-то и так далее вы можете просто сделать такой о р м style обертку где вы будете просто работать с данными и все это будет работать на внутри cave илью соответственно как положить из киева илью какие-то объекты но самый простой способ это вот вы бьете ключик на определенные части в клиентской библиотеке fondation тебе для этого есть целый инструментарий да есть такая конструкция как типус во всех бензин гав по физике и соответственно можно бить любой ключик на на его части и записывать по частям ваш составной ключ и соответственно если вы хотите например сохранить users куча полей в киеве ли вы можете сделать так вы можете в первую часть включает и айдишник юзеру в бинарном виде как-то представлены как хотите дальше строчка это название в поле например и вы ли вы кладете уже значение поля альтернативный вариант который как раз вы можете делать за счет транзакций и то вы можете просто положить по ключевой лишних юзера а в и льюс упаковать как хотите самого юзер сразу отступление вот я до сих пор не дописал такое решение но хочу записать хочу сделать за счет понад акций очень интересную штуку а именно сделать чтобы вылью укладывались не просто заархивированы юзер а заархивирован эй со словариком то есть использовать архиватор со словариком и сделать что база когда что-то пишет сначала анализировала смотрела составляла со словариком раз в месяц например а дальше клала уже зафиксировано значение слова ли кого то было бы вообще космически я думаю что чуть позже добавим эту тему и со соответственно иногда вы можете в келью делать так называемые составные праймари индексы в общем и целом там тем кто успел работал это знакомая штука то есть когда вы хотите дни по одному индексу доставлять доставать людей а по двум вы можете сделать какие-то два последовательно ключа с разными значениями это дает небольшой бонус когда вы хотите например выбирать не только по двум значениям а делать некий скан по например в данном случае второй пример ниже это вот как можно хранить сообщение и предположим вы хотите не только доставать сообщение по прямому могильнику там chateau de plus messenger а хотите доставать через список сообщений вот пожалуйста вы берете и просто достаете все ключи с префиксом первый ключ от первого подключать 1 тепла chateau de соответственно как делать индексы в простом киева или тоже довольно на самом деле тривиальная вещь предположим вы хотите достать пользователей по имени там всех олегов например берете username начало ключа дальше евро идея были можно ничего не писать можно написать какие нить мета-данные если хотите и соответственно вы просто делаете скан по всем ключам которые начинаются с username и получаете всех олегов точно так же можно делать со стороны индексы когда вы хотите получать всех олега в санкт-петербурге например в два ключа в начало с моим сити дальше и за родишь ник и вылью что угодно когда нужно сделать уникальные индексы можно просто из родишь ник перенести из второй части ключа вэлью и тогда вы не запишите два индекса с одним и тем же объектом иногда нужно проверять что индекса нет чтобы например дать пользователю ошибку что что-то пошло не так с сортировкой чуть сложнее то есть нам привычные запросы в frome там что-нибудь что что-нибудь или когда нужно отсортировать данные по какому значению есть следующий прием 1 это просто ключик который отвечает за значение сортировки предположим у вас есть там какой-нибудь рейтинг у пользователя его вот этот рейтинг в начало ключа кладете и потом делаете скан севилью по этому идиш нику точнее по какому-то диапазону префиксов то есть опять же вот мы решили пивка дискотеки там есть great range специально функция на общем и целом это легко и самим сделать когда вы просто получаете раньше от таких то ключей до таких то то есть пишите первый ключ там например все кто украл у кого сортом первый ключ это 132 ключи 250 и поехали сильно сложно сложнее вещи становятся когда вы хотите пересекать например 2 in the вых параметры например вы хотите найти всех кто там выше 180 метров ростом и там например 20 до 30 лет возраста вот как уложить такие запросы в киеве ли это на самом деле уже не тривиальная вещь да это делается через z курс это такое алгоритмы на самом деле большинство я думаю знаком тем кто работал с гиа хэшами когда-нибудь потому что она х х ха ха хорошо есть ну в общем используется в геокешинга идея в том что это алгоритм который описывает функцию которая скажем так бесконечно уходит в глубь найдет такая как z и дальше по частям идет так вниз вниз вниз то есть основная идея в том что вас каждый битник он скажем так увеличивает точность каждый байтик простите каждый байтик в на вашем ключа на вилле увеличивает точность никакого значения то есть в первом байтики вы понимаете что вас значение например от там 1 до 1000 во втором байтики вы понимаете что от 500 до 1000 в третьем байтики вы понимаете что там от 750 до 1000в 4 понимаете там от 750 до там 785 и так далее вот так вы плавно приходите к нужному значению соответствия когда у вас диапазоны значений вы по вот этим вот батика можете сказать делать выстроить такую как бы двумерную табличку и смотрите какие префиксы вам надо вытащить набор префиксов для того чтобы получить диапазон нужных значений если значение несколько то тут еще все сложнее есть такое такой алгоритм называется пространство герберт а он на самом деле делает ровно то же самое просто чуть-чуть другим способом чуть-чуть сложнее читать но опять же это не та что берется просто panzar соберутся библиотеки которые то делают и встраивать у себя и работаете с ними соответственно пространство гилберта позволяет чуть лучше работать когда параметров несколько когда вас нет два измерения три четыре и так далее и чуть бой более тучность создает скажем так чуть плотнее укладывает ключи по префиксом соответственно вот по сути все то есть если вы хотите например пересечение двух карен jay-z курс + там равно кому-то какому-то значению вы добавляете еще ключик сорт то есть в общем и целом это на самом деле такое быстрое представление как вообще она работает в большинстве баз данных потому что скажи-ка них большинстве в тех базах которые на деревьях работают внутри вот разные миксы представляются примерно таким способом соответственно это все можно писать руками можно для этого писать какие-то библиотеки вот собственно как я и сделал я в конце доклада представлю библиотеку который можно томск улица посмотреть как я это эти проблемы решал я чувствую активно разрабатываю продвигаю и так далее соответственно немножечко про то какие еще бонусы дает именно работа с транзакциями 3 foundation тебе api выглядит примерно так вы создаете замыкание вызывая крейг transaction очень важно что создается именно замыкание они просто какой-то объект с которым можете работать потому что клиентский ecophon дачный думаешь в любой момент перевыполнить ваше замыкание например когда она понимаешь сейчас с базой что-то не так начинает просто долбить перевыполнять и вы в виде клиентской библиотеке этого не замечаете либо когда у вас какой-то конфликт ключей происходит то опять же вы не видите никакой разницы вы просто это замыкание бегает и в какой-то момент вам вернется результат пока конфликт не решится сам по себе какой-то ключ и пойдет какой то нет и так далее вот соответственно создали замыкания дальше вы работаете с ключами дочери вы делаете get какого-то ключа вы делаете сетка кого-то ключа и так далее и это в общем и целом все api то есть по сути вы создали замыкание делаете get и set и и и все казалось бы что это должно работать очень медленно потому что представьте вам нужно там не знаю какой нибудь по индексу вытащить элемент какой то вы должны сначала вытащить его айдишник из индекса то есть сначала вы получаете ключик вот вот яндекс дальше вы должны получить его реальный объект а дальше следующее хотите какой-нибудь апдейт сделать то вы должны там посмотреть на реальный объект поменять какой-то из полей на принесли умеете одно поле алан упакованы у вас лежит или это сделаете set но вот эта конструкция она позволяет очень гибко работать с базой делать безумные вещи например вы можете хранить объекты в виде упакованных каких-нибудь джейсон of например если хотите менять в них а там арно только одно поле то есть вы делаете get джейсона распаковали его поменяли один одно поле и сделали сет и так как эта транзакция вы можете всегда быть уверены что параллельно никто не поменял ничего и не вас не возникло никаких конфликтов то есть параллельно вашему запросу не происходит никакой фигни с тем что кто-то другой достал это поле там что-то тоже поменял и в итоге вас там записалась что-то не то что вы хотели соответственно помимо каких-то распаковок с упаковок можно делать всякие при дрожат и например если у вас есть какой-нить индекс который состоит там из двух трех значений вы хотите индекс которые там это плюс это там и это это например яндекс сортировки то пожалуйста здесь же в коде можно написать что там ключик такой трек равен это плюс это и проставили индекс соответственно вообще что угодно можно писать можно какую формулу какой-нибудь хитрую сортировку это кстати говоря очень классно помогает писать всякие discovery то есть у нас есть такой раздел диска воры реально это такой челлендж потому что пока я писал несколько дисководов это всегда большая боль потому что когда вас опять же масштабируемая система вам нужно очень много метрик собрать с разных серверов их как-то проанализировать и куда-то записать и в общем мой опыт написания из ковра всегда сводился к тому что это не зайдет в реальном времени нужно сначала собрать все метрики и потом их проанализировать и сохранить куда-то в отдельный индекс а в реальном времени сделать такой полноценный discover там когда вас много много данных это вообще печаль и боль соответственно вот с приходом такого рода транзакции эта проблема уходит еще один такой момент что нет еще рано еще один такой момент то что вообще вообще как решает проблему лаков классическую для всех баз данных fondation ними у него нет лаков вообще соответственно вы не можете там вас ничего не встает когда вы что-то пишете у него есть конфликт ренджи это когда вы например записали в какой-то ключик и параллельно вычитали из какого-то ключика например что-то и и или например в два раза писали в 2 правильных транзакциях и заново ключика и в общем происходит непредсказуемые вещи для этого fondation тебе делать вещи он выдает разным запросам приоритет их можно ли дагаре гули ровать и запрос когда запроса более на временно пришли он выполняет только запрос с большим приоритетом а остальные просто возвращает обратно и клиентской и к не просто перри отправиться сразу как вернуться соответственно в результате вот эту ситуацию вас происходит следующая история у вас нет лаков но у вас многие запрос эпилятор отправляются выпустите гонять чуть больше данных знаете вот опять же после большого опыта работы могу сказать что сеть дешевых данном случае когда вы работаете базы данных беспокоиться что у вас там по сети как как теперь отправки будут много жрать ресурсов это последнее о чем вы должны беспокоиться если только вас там все не повезло вот опять же вы случайно он дышит по моему опыту она не сильна виснет поэтому можно не беспокоиться соответственно немножечко хочет сказать про оптимизации которые вы можете делать вообще на самом деле ради этого весь доклад был потому что вся эта история с киви лью все вся эта проблема которая описал с рассинхронизация me to самом деле не то что меня беспокоит проблема синхронизации меня беспокоит только потому что они не позволяют делать классные крутые оптимизации потому что когда вы боитесь оптимизации вы не можете придать считать кучу данных вот например опять же пример из ранней работы в к у нас была проблема счетчика всегда то у нас было левое меню и там куча куча счетчиков там мои сообщения мои группам а еще что там вот эти вот индикаторы бесячие и очень здорово это просто ключики там в табличке мы их просто инкрементом все зашибись на они все время и синхронизируются вот прямо вот все время тогда было и у нас даже был мы делали кнопку в какой-то момент пересчитать мои показатель эта кнопка была нужна потому что вот тот способ о котором я говорил когда мы через раз какое-то время пересчитаем все показатели смотрим нет ли у нас раз низации он дергался слишком редко и часть пользователю пустыне дожидалась не дожидались когда же у них все пересчитается от дергаться чаще он просто не мог потому что он делал миллион всего их слишком сильно нагружал систему соответственно казалось бы почему эти все счетчики общине положить в одно поле чтобы вы когда загружаете страницу пользователя супер часто и действия не тянули просто одно поле где вообще все и все индикаторы ответ потому что тогда расин вернется и будет еще больше и будет вообще боль соответственно про оптимизации поехали значит первая самая известная оптимизация которая известна многим из обычных бас это d нормализация когда вы кладете данные в несколько мест то есть это это общая классика потому что в принципе не выжить если вы будете так скажем так стараться все хранить атомарные не будете какие-то данные храните там и сям и так далее но вот опять же здесь можно выйти на новый уровень когда вы например предположим у вас есть какой-нибудь индекс предположим вы доставите иногда пользователи по городам да и вас этот супер час тэги кейс вот представьте вот у вас есть камни знака не главное где вас список пользователей по городам и вам бы надо в классическом варианте сначала тащитесь типа список пользователей а потом тащить сами данных пользователей поедешь ником и это предположим большая проблема потому что это все равно нагрузка на кэш это лишнее запросы там и так далее вы можете написать на за акцию где вся работа с вашим юзерами будет писать и туда и туда то есть и и яндекс посети и яндекс поедишь нику при этом соответственно вы вот это вот эту табличку посетишь можете масштабировать на что понятно что вы можете всегда сделать яндекс посети внутри таблички с юзерами вас все будет зашибись казалось бы но тогда это не будет масштабируется в том плане что если у вас есть слишком много вы не сможете их доставать там посети потому что они будут у вас пожар дам разбитые вам тогда нужно будет делать моя придется от не очень классно вот соответственно тут ключевой ключевой момент что дано организации мы распределяем данные по серверам еще один классный пример для нормализации это вот из нашего кейса это скриншот из лака это не наш кисть но идея тоже вот у вас есть текст есть реакция реакции это классно очень вещи вообще messenger если у него нет реакции например это уже не messenger по моему верно и реакция сделать очень тяжело на самом деле без ну . однако их очень легко сделать но опять же про синхронизации потому что вас есть объекты сообщений есть объекты реакции нужно посчитать чтобы грубо говоря один и тот же узор не ставил две одинаковые реакции потому что он может только одну поставить при этом нужно посчитать что нужно считать общее количество реакций сколько таких то реакцию такого-то сообщение так далее то что может набежать много пользователей и там будет много там какашечку словно и нужных вывести какашек там 1328 вот мессенджерах это чуть проще потому что там очень ограниченное количество людей если вы хотите сделать реакции в чем-то где будет там гигантский травиться очень большим количеством людей это уже довольно сложно вас пункты появляется есть такие ну ты такое классическое простое решение у вас есть там база табличка мама с сообщениями табличка с реакциями и вы сначала делаете запрос по сообщениям уже чуть более сложный запрос по реакциям где вы их ещё и суммируете считаете либо вы добавляете у каждой реакции индекс добавляете еще одну третью табличку где в основе записано кто куда положил реакцию но это все та же боль потому что вы в какой-то не будете мучиться срочность организациями который довольно запарно пофиксить и вот этот пример решается вообще супер легко когда вы просто записываете в транзакцию и вас и вы кладете реакции вместе с сообщением то есть чтобы полу то есть борьба говорилось и сообщение и все его реакции на имеют уже спас предпочтительными счетчиком лежат в одном ключе соответственно в этом случае вытащить вот такой список сообщений уже с готовыми реакциями это просто один скан по ключам вопрос получать ключи от такого такой-то и вот они все сообщения с реакциями предпочтительными и так далее все зашибись все работает очень быстро в то время как без транзакции no es que el это было бы сложная штука и если это например центральная часть вашего приложения это было бы реально долго второй момент и парализация у он лишь на тебе синхронная пить соответственно там идея в том что вы не делаете get какому-то ключу а вы делаете вы делаете get и получайте не значение в ввс вы получаете объект фьючер это знакомо многим там из но джесс это у них там называется promise и это в общем и целом не важно там ищешь namapi такое же open соответственно это можно прокинуть там чуть ли даже на печке если вы пишете билдинги например и и и так далее соответственно идея в том что вы все все все все ваши вот эти get и set и должны укладывать параллельно т.е. сначала вы api описали get и получили все фьючер и потом вы достаете все значения и так далее тогда в общем и целом работа с вымышленными не будет такой долгой в том плане что запросы будут чуть побыстрее выполняться когда вы все за параллели были того если у вас несколько поз скажем так транзакции в эти транзакции тоже параллели ти можно их сливать в одну транзакцию если они не никак не блокируется еще один такой момент что фонды шиноби есть такая вещь как снапшоты это очень важная вещь и чтобы конфликтов избегать то есть большинство гетов на самом деле нам делать через снапшоты они просто так потому что snapshot это когда вам не важно что пока hf чтобы что грубо говоря когда он неважно самая последняя версия этого объекта то есть грубо говоря вам окей если например на каком другом сервере уже есть более новая версия тома вас репликации еще что то но вам пришлют там версию на 10 миллисекунд более старую это просто все узкая ускоряет а точнее убирает конфликты когда вы шлете и сеты и get и параллельно потому что если вы сделали snapshot get у вас конфликт если параллельно сет был не вернется и соответственно ваш гид мне период правится потому что все то обычно приоритет выше например в свои библиотеки для работы с foundation и б сам слоя сделал возможность вообще все все запросы проверить очень легко сделать какой pipeline когда можно написать там select что-то потом сделать push select что то пусть select что-то а потом и за результаты сделать поп поп поп в конце и раз вы все все все запросы параллельно выполнены на самом деле и получили результат довольно быстро огромная тема на бой масштабируемых штуках это миграции все с этим сталкивались это вообще же больно самом деле когда у вас есть распределенные данные у которых должна быть какая-нибудь asic consistent когда вы хотите поменять например структуру как вы храните данные то есть например вас там не знаешь какие телевизор и есть какой ничего что ты вы хотите хранить как-то по-другому либо вы хотите перевести что-нибудь из одного из одной базы в другую и при этом эти базы немножко отличаются там форматом и вы получается должны взять например там юзеров вы должны взять их список друзей и перенести в какую другую сущность как который как-то по-другому и хранит вообще как таковых там таблички перестраиваете огромная боль сделает миграцию так чтобы никто не ничего не заметил обычно это решается там тем что миграции делаются в 6 утра когда все спят там или в 5 утра и соответственно все все нас на самом деле все прыг проходит не очень хорошо и супер гигантская проблема когда вас краж нос миграция посередине от представьте вы запустили миграцию и тут у вас что-то крашнулось и в рандомном месте причем вы и делали например высоко параллельно то есть вы там сразу куча серверов слова для запросы тут у вас что-то крашнулось какой-нибудь миграционный скрипт и в итоге вас там на кучу сервировка кайтэн коэн консистенции плюс не понятно тут что-то записалось там не записалось и вообще боль с транзакциями это просто сказка вы просто пишете транзакцию которая работает с конкретной с несколькими конкретными связанными объектами с которой в основном нужно мигрировать выброс например их там получили удалили поменяли там какие-то данные поменяли индексу каких-то других объектов и зака метели транзакцию и все зашибись даже если ваш скрипт крашнулся вас просто какие-то транзакции не завершились то что а важный момент если вы начали транзакцию послали какие-то данные но не сделали commit ваш скрипт умер соответственно естественно tran акция не выполнится анапа в эти данные которые послали просто вы кинуться вот соответственно миграции превратились в просто любимое занятие и последний момент как я вообще устроил работу сыром вдруг этот опыт но с работы с базой вдруг этот опыт кому-то будет интересен потому что по моему опыту это пока самый мой приятный экспириенс который я испытывал при работе с базами данных потому что до этого все было очень больно я прям языке объявляю какую структуру например юзерам делаю в google есть такая штука аннотацию не пугайтесь это справа то тема там старт равно что-нибудь в общем и целом монтировать можно в любом языке как и данные можно там в джесси можно обернуть объект вне киана теру ющий другой объект который будет описывать каждое поле ну в общем всегда можно что-то придумать но идея в том что это просто не не некий river raid reference поля для того чтобы было понятно как назвать внутри базы каждое поле я считаю это довольно важным потому что внутри вашего кода можете любое поле поменять переименовать еще что-то в базе все-таки не хотелось бы переименовывать поля просто так каждый раз когда вы меняете поля по это нужно reference а дальше просто создаю объект создаю всякие индексы и так далее в этот момент строится схема у меня этот кусок кода в инициализации либо это тоже опыту гораздо удобнее чем классические там какой-нибудь с келли летом ямал файл описывающий схему базы потому что вы прямо в коде описываете схему и за счет этого у вас она работает подсказка syntax а еще что то вы и вы сразу там подключить все они файл видите какая структура и дальше вы просто работаете с созданными объектами то есть там дабы user id юзер все у вас есть объекте к вы кладете получаете и все зашибись а теперь о проблемах которые есть фонды стрельбе потому что они есть в первую очередь гигантский лайла и танцы это значит за счет того что fondation бы все батчат то есть вы шлете на самом деле там всякие get и set и и так далее пришлете томс разных грудь им трейдов и так далее и фонду из них не отправляет сразу на сервер и клиентской оками виду она их батчат в один большой патч отправляет на сервер на сервере она тоже там наполучала всякие ключики там есть какой-нибудь роутер он получал их он тоже батчата в один большой патч и там распределяет между всякими серверами и все это ходит гигантскими бочками как которые уже потом обрабатывается за счет этого получается впечатляюще это spud то есть впечатляющая производительность новый танцы страдает жестко на момент сделать один какой жалкий get это целая миллисекунда там мой стиль за миллисекунду можно сделать но дофига всего там можно силе какой-нибудь по нескольким полям и сделать а тут нам не знаю получается сделать какой-нибудь реально сложную транзакцию с кучей всего это уже 10 миллисекунд за 10 минут можно кучу всего сделать это на ненагруженной системе соответственно когда преднагрузка будет там в два в три раза больше второй момент это типа идея поднимать фонды тебе на каком-нибудь микро инстансе в амазонии плохая потому что он вот просто будет весной сразу над pride причем на ровном месте в этом сделать запрос один там ключик положили он взял завис то есть ему нужно реально 4 giga не пишут что нужно 4 giga в общем им им нужно 4 giga можно там конечно играть там с конфигом с настройками еще что-то может что-то пойдет но это не лучший способ использовать базу то есть они все-таки имеют некий pop-rock оптимизационные начиная с которого нужно сделать и к сожалению пока работать вам лично тебе очень сложно потому что киева или нужно писать какие-то свои библиотеки им всем кто пишет на голову я предлагаю присоединятся вот к моей библиотек которая начал писать полу request приветствую и так далее потому что мне кажется вот собственно цель моего доклада здесь это давайте обменяемся сделаем классную библиотеку чтобы наконец-то решит все наши проблемы которые у нас были при написании багандов спасибо большое сейчас время для вопросов и организаторы хотели предупредить что автор лучшего вопросы получат от них оркни жку вот спасибо большое вы сказали что он там повторяет транзакция да то есть я тогда правильно понял что с по сути вся логика приложений и ушла в базу данных по большому счету комната между вот моталась был слайде где букет из эт но между ними как вы понимаете какие-то вычисления на собственно говоря вся эта полезная логика которая что-то делает она вот где нет самом деле она полезная логика она снаружи потому что внутри каждого замыкания нужно делать только те вещи которые вы будет безопасно что они будут перри выполняться например без вашего контроля несколько раз обычно в логике приложения вы не хотите чтобы вас несколько раз там картинка загрузилась или еще что-то и плюс вы изолируете все запросы отдельно дать грубо говоря там нет сделать вот это вот действие там зарегистрировать нового пользователя и например подписать нового пользователя на какой-то чат это разные вещи и их нужно в разные транзакции делать ну что опять же вы не хотите чтобы они были внутри одной транзакции то что конфликтов больше будет если вы их обвинить трудовой пенсии еще более кошмарно будет ну а то есть ты писал что-то типа там армандо типа гармадон то есть для ноты работы с ландышем а вот собственно вопрос такой вот ты говоришь там из слау которое быстро можно писать просто чисто на гол я писала давали я повторю что было слышно трансляции вот вопросом что можно было писать на flow а можно начисто могу я писал на год на потому что я писал как раз тему срм когда в грубо говоря слове для работы с базой данных встраивается в ваши приложения меня просто бэкон тоже на без на это очень получается красиво когда вы просто грубо говоря как rm подключаете как библиотеку и работаете с базой данных просто на уровне библиотеки а уже там внутри она уходит какие вылью если вы пишете например именно как слой к клэр как отдельный сервер катар будет поставщикам между там в вашей логикой и foundation тебе тогда конечно лучше написать сразу сиона flow потому что общем си плюс плюс а чуть-чуть расширенные просто получится если мы напишем то строить в год будет довольно тогда безусловно и нет нет никакого смысла там вот если именно вы как работаете по схеме такой рамта они говняный смысла писать на все при плюс потому что в головы получаете плюс от использования рутинно у вас как минимум синтаксические в том плане что в привычном для вас образом описываете пара реализацию запросов а в прочем случае вы наверное поленитесь сделать все правильно спасибо привет олег меня зовут алёна она страшно страшно меня зовут тоже олег но я из одноклассников такой вопрос про вот ты говорил что все эти таблички они сортированы на самом деле да и там вопрос то и ну вот эта сортировка насколько я понимаю на к это статическое она просто лексикографическое задается и все в этой табличке все ключа не бинарные это байкеры выкручивать батарей и до бинбин от на самом деле там просто по байкеры сортировка то есть грубо говоря байтик больше выше ключик броник меньше это вот между нодами сортируются данные по какому принципу вот в этом рекорд что грубо говорят представьте вас один большой типа key и value да и он просто распределяется между серверами соответственно сам фонды шляпе пытается именно вот места слайсинг а где он эти как сказать это полотно ключей и значений разрезать он сам меня и данных перекидывает иногда соответственно там предположим точно не могу сказать в начале он держит их посередине как только у вас пошла какая то нагрузка и она оказалась неравномерный он сменил вместо средства мигрировал часть ключей на прием все время данные туда куда более того если вы клик для значение репликации в конфиге проставили то есть храните все ключи на нескольких машинах там соответственно разных машинах будут разные наборы ключей то есть она будет немножечко по-разному порезана в зависимости от нагрузки опять же но остается вот это вот классическое требование что на один ключ и слишком много нагрузки не надо потому что единственная вещь которую а сама она не решит это если слишком много нагрузки на один ключ то то тут уж царя она тоже проблема разработчика который работает включаем здрасьте а я хотел спросить этот проект у вас уже в про depot реальными пользователями крутится вот с бэндом на этой базе нет вот как раз вот собственно где сказал ничего не значит и мы вначале лет в начале это все описать то есть я думаю что после нового года у нас будет релиз я пока только на виртуальных ну то есть там на амазоне тестил нагрузки у нас сейчас мы крутиться под такой фейковой нагрузкой мы сами создали себе нагрузку мы примем огромное количество данных среде то и играем в таком мы говорим эти когда у нас как бы чужие пользователи что-то делают но под реальными нагрузками пока не тестировали единственное что могу сказать что в общем и целом на тестах все довольно хорошо то есть проблем с производительностью вообще нет реально за счет оптимизации получается сильно быстрее чем искал есть несколько проектов которые попробовали уже в продакшене эту историю но вот и одному что это лучше оставить на следующую секцию уже можно можете потом подойти расскажу и хотел спросить транзакции если она трогает ключи которые лежат в невских разных сортах как да вот возможно в этом вся и сути то есть об этом весь доклад что все транзакции которые делаете они меняют все ключи в нескольких разных садах и все вот это вот синхронизируется то есть если вы ну понятно что у bас которые позволяют вам ключи транзакций меняется в одном шарди их полно там вы берете редис и поехали вот как раз так чтобы транзакции работали на всем кластере а там арно ну вот акс полноценная цитатам за акции были вот это на самом деле довольно большая редкость сразу к этому образ хочется отметить что это я на самом деле вот не сильно хотел бы доклад именно про fondation тебе сколько про подход потому что еще одна базу которая вот именно такой же подход делают называется тип тики и вылью на ней сделано ти db там это это искали слойки поля mais quel только который вот позволяет сам масштабироваться и так далее вот соответственно мне нравится очень этот подход я считаю что будущее вообще бэг-энда строение то есть в будущем мы будем вот как-то так делать соответственно кто победит в этой битве еще один вопрос может быть fondation тебе окажется не лучшим игроком спасибо"
}