{
  "video_id": "Qnw7s8290Cs",
  "channel": "HighLoadChannel",
  "title": "Архитектура высокопроизводительной и высокодоступной системы мониторинга / Сергей Половко (Яндекс)",
  "views": 3156,
  "duration": 2971,
  "published": "2019-12-05T12:53:57-08:00",
  "text": "меня зовут сергей я работал в компании яндекс и последние два года я провожу команда которая занимается разработкой систем мониторинга эта система мониторинга используется внутри яндекса для того чтобы обслуживать потребность в мониторинге различных сервисов которые разрабатываются там в этом году мы выпустили мы зарелизили нашу систему мониторинга отдельную инсталляцию в составе индекс облака и сейчас это доступно видения про структурного сервиса и можно приходить пользоваться и пока что система находится в стадии превью и не тарифицируются о чем пойдет речь сегодня в первую очередь хочется рассказать про то с какими данными приходится работать системе мониторинга и исходя из этих данных те или иные решения они специфичны дальше мы рассмотрим архитектуру той системы которая вы нам удалось построить в частности поговорим про хранилища которые мы разработали и немножко затронем дополнительное средство которое у нас есть визуализации и оповещений и так модель данных система мониторинга работает с какими-то данными которые с показателями которые изменяются во времени уникальной особенностью таких данных является наличие временных отметок на самом деле временные отметки систем мониторинга как правило опрашивает с каким-то фиксированным интервалом поэтому мы имеем дело с синклера ванием из какой-то аппроксимации реального процесса в системе как правило может быть много метрик и возникает необходимость различать отличать одну метрику а другой возникает необходимость как-то их идентифицировать и организовывать в какое-то логическое пространство чтобы пользователям было удобно этим пользоваться в качестве идентификатора в нашей системе используется следующий подход мы разделяем это нефиг котором и два на два компонента первый компонент это обязательно и имя эми должна описывать эту величину которая собственно измерялось есть опционально я возьму есть опциональное опциональное множество меток которые представляют собой ключи и значения и эти метки позволяют организовывать некоторые пространство каждой такой метрики может соответствовать временной ряд временной ряд это набор точек таймс темп и какое-то значение в качестве временных отметок используется используется миллисекунды в качестве значений можно использовать вещественные целые числа а также гистограммы рассмотрим такой пример есть некоторая метрика которая показывает количество операций чтения которое производится на определенном устройстве на определенном диски describe обсе это имя метки и это имя метрики и у этой метрики есть два измерения по хостам и по дискам если посмотреть внимательно то эти данные можно разделить на два таких условных блока есть мета-данные метрики и данные при этом при этом метаданные они состоят из строчек и как правило предназначены для того чтобы человек мог прочитать и понять что-то из этого а данные итачи силки которые в таком виде человек естественно не не сможет нормально воспринимать для этого для того чтобы их человеку показывает нужно как-то их визуализировать и позволять предоставлять какие-то функции для предварительного анализа это понимание о том что данные метрик делятся на метаданные данные в целом позволило нам в дальнейшем построить архитектуру системы таким образом чтобы она продолжала масштабироваться в нашей системе захоронение мета данных и данных отвечают различные системы хранилищ для корней и метаданных используется как нетрудно догадаться из названия me the storage и для хранения временных рядов используется data storage такое разделение на очень необычно во всяком случае мы достаточно редко такой встречали в своей практике оба эти столь же работают поверх внутреннего решения индекс do the bass в своем докладе я не буду подробно рассказывать о нем завтра мой коллега выступит и подробно расскажут что там происходит внутри в целом эта система позволяет нам абстрагироваться вот физических устройств и переживать различные проблемы связанные с этим такое разделение named after the data storage позволило нам оптимизировать эти решения под конкретные данные которые там хранятся и подпись специфичную нагрузку и масштабировать эти решения независимым если очень упрощенно то метод сторож представляет собой mapping человека читаемых идентификаторов число вы идентификаторы a data storage предоставляет представляет интерфейс маппинга силовых идентификаторов во временные ряды такое введение таких числовых идентификаторов связана с тем чтобы данные словно в каждой системе были замкнуты и не зависели друг от друга числа вы идентификаторы это слово идентификатор метрики состоит из двух компонентов в него включен идентификатор шар дай и уникальный идентификатор метрики в этом жерди помимо систем крайне хрень систем который отвечает за хранение также есть компонент который отвечает за серов discovery и опрос то есть скачивание данных из разных сервисов и этот компонент также отвечает за партиям данных и передачу уже раз про шины данных в метод и data storage для того чтобы данные можно было вычитывать есть компонент мы называем его gateway который предоставляет верхнем уровне вояки всего сервисы средства визуализации есть как касторное внутреннее решение так и поддерживаются граф она популярна и против разрешения также гей твой api предоставляет качестве одного из методов предоставляет интерфейс для записи данных то есть система поддерживает как пул модель так и push модель передачи данных для того чтобы автоматизировать процесс наблюдения за изменяемыми личинами есть компонент который называется лифтинг он предоставляет богатые средство по настройке нотификации и поддерживает разные способы нотификации там смски письма телефон так далее чтобы обеспечивать высота чтобы масштабировать эти решения к каждая из каждой из этих компонент запущен в нескольких экземплярах и нагрузка балансируется между ними для того чтобы обеспечивать надежность битвы и allure think запущены в нескольких зонах доступности вечер и стороны же запущены в одной зоне доступности но мы запускаем два независимых кластер а которые полностью дублируют себя и ничего друг о друге не знают такой подход позволил нам упростить имплементацию систем хранения и сделать здесь сделать это намного проще стало как эта система масштабировать система разрабатывалась яндексе уже более пяти лет и используется внутри многом многими разными сервисами которые передают в нее достаточно большие объемы данных и если сравнивать последние показатели за последние три года то можно увидеть что мы увеличили объем поступаем обрабатываемых данных почти что в 50 раз это достаточно существенный прирост и если система изначально была спроектирована неправильно было бы достаточно сложно масштабировать ряда подобных размеров помимо того сколько данных системы обрабатывать хочется отметить еще несколько показателей а именно зафиксировать то что вечер в целом опрашивает около 1 миллиона урлов и делает это каждые 15 секунд достаточно большой объем данных скачивается процессе c и нужно успевать делать это за фиксированные интервалы времени как правило это 15 секунд но люди бывают настраивают и меньшие интервалы хранится всего в системе уже около девяти миллиардов метрик это тоже достаточно существенный объем который приводит к определенной проблемы и нам приходится с этими проблемами сталкиваться их решать система data storage принимает в себя около двухсот двухсот 50 миллионов точек и позволяет учитывать но сейчас поток на учитывание примерно 30 миллионов точек в секунду и если говорить про валентинка alert нам сейчас вычисляет около 400 тысяч или рта в каждую минуту и делать это тоже нужно нужно нужно успевать делать это фиксированные в сжатые сроки потому что иначе мы можем пропустить события у кого из вас продакшен не используется мониторинг можете поднять руки почти треть зал она подняла как какой объем данных у вас там хранится за какой период времени может быть у кого то больше года хранится так две руки может быть у кого-то месяц кормиться и больше месяца вот больше рока а может быть у вас неделя данных хранится совсем малую отлично в нашей системе данные хранятся вечно это существенное отличие от конкретных решений которые в этом месте достаточно плохо масштабируется как мы это делаем собственное будет основной темой моего доклада хранилище метаданных элемента сторож как мы его называем те задачи которые он решает основная задача это mapping человека читаемых идентификаторов число вы идентификаторы в этот сторож прилетают очень много запросов на поиск потому что люди должны каким-то образом находить метрики они собственно в мета стоишь прилетают запросы на поиск по поисковым запросам и понимаем как понимаем число вы идентификатор этих метрик которые будут учитываться бачу и мы отправляем этот запрос в дату стоишь помимо этого так как все данные прилетают через мета сторож мы точно знаем когда какая метрика последний раз обновлялась это позволяет нам настраивать политики удаления метре например если пользователи хотят мониторить какие-то временные сущности или динамические сущности которые появляются и через какое-то время они становятся интересны все автоматически происходит на то есть можем автоматически удалять api это столь же выглядит следующим образом есть три метода первые три метода по созданию метрики призову и удалению они работают достаточно просто и понятно как в любой другой хэш-таблицы на этом не хочется останавливаться а метод который позволяет искать метрики по запросу вот на нем остановимся чуть поподробнее допустим у нас есть несколько метрика про потребляемые ресурсы например по и опции на дисках и пользователь когда делает запрос он придает он указывает какие метрики ему интересно то есть указывает имя и с помощью меток он позвал может указать собственно какие пространство ему в данный момент интересны синтаксис очень похож на сами метрики на их идентификатор и затем исключением что в качестве значений можно использовать блок выражение можно использовать различные операторы сравнения например если пользователь хочет увидеть и опции по дискам которые заканчиваются на и один он задаст так следующего запрос либо можно делать сопоставления по полному совпадению поддерживается различные операторы например помимо тех которые уже были показаны это сопоставление по регулярному выражению либо по отрицанию также поддерживается специальные значения которые позволяют определить есть нужный нам ключ или ключ-ключ метки ибо он отсутствует нет в метриках как устроен такой поиск для этого мы используем те же подходы которые используются в поисковых системах а именно мы все множество метрик нумеруем то есть каждый каждый метрики назначается уникальный уникальные числа к ее последовательно фактически номер далее все метрики разрыва разбиваются на термо и для каждого термо составляется список номеров где этот терм присутствует также мы запоминаем какого типа этот термин был то есть для делаем такой процесс для имен для ключей и для значений для значений а также запоминаем какие какому ключу соответствовал это значение в дальнейшем это нам сильно поможет в итоге у нас получаются такие списки по всем ключам и значения но horny такие списки в памяти достаточно накладно напомню что в системе сейчас хранится у порядка девяти миллиардов объектов и подобное подобное решение она бы не масштабировать для того чтобы эти списки сжимать используется опять же те же подходы которые используются в большинстве поисковых систем а именно мы используем сжатие с помощью битовых масок если посмотреть на эти списки то на самом деле они содержат в себе номера метре то есть по сути это целые значения положительные и мы точно знаем количество общее количество объектов в системе поэтому мы знаем ширину маски и для того чтобы закодировать такой список с помощью битовой маски мы каждому элементу для каждого элемента взводим в соответствующей позиции бить их в итоге вместо трех чисел и можем хранить всего лишь один байтик таким образом наши списки легким движением руки превращаются в элегантные маски но даже такие маски хранить будет накладно потому что если метрик много например 9 миллиардов то ширина такой маски будет очень большой при этом пространство метре как правило сильно разряженной поэтому такая маска будет заполнена будет сильно тоже разряжены для того чтобы и сжимать мы используем концертную библиотеку который называется вроде убит maps и она использует различные подходы для того чтобы зажимать подобные маски то есть там rambling encoding и прочей техники используются посмотрим теперь как работает запрос помимо того что такие маски хранятся памяти очень компактно мы также можем использовать эти маски для быстрого поиска все что нам нужно сделать разбить запрос на термы потер мам найти соответствующие маски и выполнить над масками простые логические операции например пересечение для того чтобы найти что этому запросу соответствует метрики 1 и 2 таким образом запросы получается обрабатывать очень быстро и весь индекс в таком объеме в таком виде на 9 миллиардов метрик занимает порядка 400 гигабайт памяти не так уж и много весь этот индекс можно было бы положить и в память одной машинки отвечать используя ее но запросов достаточно много и приходится делать приходится обслуживать их достаточно быстро и иначе пользователь начинает испытывать какой-то дискомфорт потому что даже борды грузится очень медленно для того чтобы эту нагрузку распределить между несколькими машинками мы используем сортирование и для кодирования используется достаточно простой подход то есть мы в какой момент приняли решение что в каждой метрики должны быть обязательными метки прожек сервисы кластер которые позволяют с одной стороны пользователям организовать какое-то логическое пространство своих метрик то есть все метрики делится теперь по проектам внутри проекта они делятся по кластером и сервисом а также с помощью значения этих меток можем кодировать то есть разбивать условно множество на на небольшие компоненты в качестве примеров можно привести следующие шарды условно взятые про просто в качестве примера то есть есть некоторые сервисы джинкс который используется в проекте такси есть два окружения продакшена тесты значение которые могут использовать пользователи они абсолютно произвольными могут быть не фиксирован то есть все что придет в голову хорошо разобрались с мета стороны джим то есть мы смогли размочить человека читаем и идентификаторы в числовые как же данные хранятся в дата стороны во-первых те задачи которые решают но в первую очередь это быстрое и надежное хранение временных рядов потому что 250 миллионов точек в секунду не каждая не каждый что врач может в себя принять помимо этого сторож позволяет эффективно кэшировать те данные которые учитываются из него и в большинстве случаев яда дальше про это расскажу мы обслуживаем запрос на чтение полностью из памяти интерфейс да ты столь же достаточно простой есть всего лишь три метода который позволяет записывать временные ряды учитывать и удалять у каждого из этих методов есть аналогичный метод который работает в бочки режиме то есть можно передать сразу несколько временных рядов которые нужно записать и или например прочитать их каждый из этих методов принимается числовой идентификатор который как я уже говорил состоит из двух чисел ок это идентификатор шарда и уникальный идентификатор метрики в этом шарди такое представление позволяет нам сделать достаточно простое опять же системы сортирования все множество подхода кодирование используется статической статический подход то есть мы в самом начале задали вот эту чисел k магическую что у нас будет четыре тысячи родов и пока это количество больше существенно больше чем количество нот которые обслуживают все эти шарды можно достаточно как-то равномерно балансировать нагрузку по этим надо для того чтобы балансировать эту нагрузку на ноги сначала выбирают мастера и задачи мастера входит распределение шар дав по тем или иным надо для этого он периодически опрашивает но смотрится сколько ресурсов они потребляют физических диск цепью памяти и если видеть что здесь есть свободные слоты и он туда просто асане этот этот шарф также он может забрать sharp если видит что эта машинка перегружена при этом каждый шар тон абсолютно независим то есть обслуживает только свои данные ничего не знает про соседние шарды и это сильно упрощает его реализацию как шар построим внутри то есть по сути весь сторож это набор этих сортов и описание того как как хранятся данные это словно описание то того как данные обрабатываются этим шердом центральным центральной точкой каждого шарда является актер который это такая одна поточная сущность которая обрабатывает запросы на чтение на запись 1 поточная для того чтобы упростить себе жизнь и делать не делать каких-то сложных механизмов синхронизации для тех данных которые лежат в памяти все те данные которые записываются в сторону они упаковываются и упаковываются с помощью алгоритма который описано в статье от facebook горилла мы немного доработали эти алгоритмы для поддержки целочисленное значение и гистограмм после того как данные были сжаты они виде бинарных таких архивах хранятся как в памяти таки на диски на диске все эти архивы записываются в один такой большой файлик snapshot есть разные уровни snapshot of про них мы подробнее поговорим так как архивы имеют произвольную длину и записывается последовательно нам нужно где-то дополнительно хранить информацию о том где начинается конкретной архив и где он заканчивается эта информация хранится в яндексе в яндексе хранятся идентификаторы метрик и собственно позиции где соответствующий архив лежит в яндексе данные упорядочены по идентификатором это позволяет нам использовать бинарный поиск достаточно быстро находить нужную позицию и вычитывать и и высчитывать этот архив с диска как происходит запись все запросы поступают в начале в очередь так как вектор это одна поточная сущность он может быть заняты какой-то работой в данный момент например отправляет запросы на чтения заниматься каким-то фоновыми задачами пока он выполнял эти действия в очереди накапливаются запросы следующим шагом вычитывают все те да все эти запросы которые пришли за то время пока он условно был занят другой работой сжимает эти данные в один такой файлик и делает всего лишь одну запись на диск это позволяет системе автоматических балансировать нагрузку в том плане что если в этот в какой-то момент актер был занят чуть дольше работой чуть больше данных находится в очереди за то за 1 за одну операцию он все эти запросы обработает и запишет на диск после того как данные успешно записались на диск мы обновляем структуру те данных в памяти одна из структурах данных это текущее состояние логов это компактное представление всех тех логов которые мы записываем на диск она нам понадобится в дальнейшем для того чтобы быстрее компакте теологии которые ранее были записаны также обновляются все эти данные в кэше которые ранее были прочитаны то есть условно если пользователь открыл даже борт и увидел там сотни метре эти метрики записывались и после того как после того как они записывались мы будем после каждого после каждой записи обновлять этот кеш и следующие запросы на чтение будет обрабатываться полностью из кэша все это все что делает вектор для того чтобы сделать запись то есть мы работаем только с ssd с диском за счет этого мы добиваемся максимальной производительности и делаем на ssd диск всего лишь одну запись компактного представления всех тех запросов которые в очереди накопились за счет этого мы добиваемся очень быстро работа и здесь следует отметить что все те данные которые пишутся на диске они пишутся через vdb в adobe и анализа the bass позволяет записывать данные с избыточностью сразу на несколько дисков это приводит к тому что мы спокойно можем переживать различные падения выпадения дисков и наша система полностью полагается на то на те возможности которые есть в тебе и за счет этого становится гораздо проще с этим работать и писать эту систему этот процесс может продолжаться несколько раз и таким образом мы накапливаем логе на ssd дисках также мы копим данные в памяти если бы эти объемы были бесконечным бесконечный объем памяти у нас был бы и бесконечно ssd-диски это в принципе на этом можно было бы и остановиться но это не так и что то с этим нужно делать для того чтобы заменить все эти отдельные записи логов на какой-то один файлик мы просто сбрасываем предыдущее состояние лог сайта из памяти то есть за одну транзакцию это позволяет воде и удаляем старые логе и пишем новый файлик один файлик в принципе содержит этот файлик лог snapshot содержит всю ту же информацию которая была записана в несколько предыдущих файликов но за счет того что они пишутся последовательно сенсор пишется метрики пишутся последовательно они гораздо более компактны представлены на диске этот процесс также продолжается мы периодически сбрасываем снапшоты приходят еще записи копится логе копится snapshot этих логов что с этим опять же нужно делать раз в два часа мы сбрасываем текущее состояние логов которые мы копили в памяти специальный файлик который называют 2-часовой snapshot при этом все предыдущие логином больше за становятся не нужны мы их удаляем для того чтобы не вычитывает индексы с дисков мы информацию об индексах ранен в памяти и просто в этот момент ее обновляем все мы записали 2-часовой snapshot все данные которые до этого писались надежно сохранены состояния в памяти мы дрогнули потому что больше нам не нужно мы начинаем следующую итерацию следующий раз следующие запросы на запись также начнут накапливать это состояние и также записывать все продолжается снова накапливаться двухчасовые снапшоты они пишутся также на ssd диск и понятно что ssd диски сейчас очень производителей но достаточно маленькие по объему поэтому нужно что-то с этим делать делаем следующее периодически двухчасовые снапшоты сбрасываются в дневной snapshot который записывается уже на пдд на хдд место гораздо больше поэтому там такой файлик там там такому файлик у самое место освободившееся место на ssd мы будем использовать под новые записи логов еду часовых snapshot of хранить файлик в дневном станом счете хранить все данные в немом суп с лапшой и будет достаточно расточительным потому что придется каждый раз в мир жевать в него все эти 2 часа вы и снапшоты которые ранее были накоплены поэтому периодическими этот файлик тоже компактен для этого у нас в системе есть это eternity snapshot который содержит всю историю данных конкретных метрик и не реже чем раз в день мы производим мер этих двух snapshot of между собой также обновляем информацию информацию об индексах в памяти и все это происходит в фоновом процессе как теперь давайте поговорим теперь как устроена чтение для того чтобы прочитать данные из конкретных шарда они также сначала попадают в очередь 99 процентов всех запросов на чтение сейчас обрабатываются только из кэша то есть попадание в кэш очень большое плюс то политика который мы используем с обновлением тех данных которые есть кэш и то есть если данные туда попали то мы будем и поступающей свежие поступающие данные в крышка бы доливать поэтому не нужно будет откуда-то дополнительно эти данные вычитывать если же по каким-то причинам мы промахнулись с каша то мы сделаем следующее чтение мы во-первых посмотрим за какой интервал времени пользователь запрашивать данные если это меньше чем один день то скорее всего эти данные лежат где-то в двух часовых снег шуток и в блогах последних последних записях для этого мы сделаем несколько чтений ssd диска что достаточно быстро происходит если же пользователь запрашивает всю историю то в худшем случае мы сделаем 2 сика на хдд диск и это очень экономит снижает время учитывание данных существенно после того как данные вы читали мы их смерть жили все эти кусочки отдельные положили в кэш и дальше все последующие чтения этих же данных из будут приходить из кэша как устроен на этом у меня все про то как устроена система хранения и дальше хочется рассказать немного про то какие есть средства визуализации естественно система мониторинга должна предоставлять некоторые средства которые позволят те все эти данные которые ранее были записаны в каком-то виде представить для этого как уже мы рассматривали существует язык запросов например мы захотели посмотреть как работал сборщик мусора для старшего поколения на всех хвостах наших для некоторого нашего джов процесс но графиков но на этом графике линии настолько много что человеку из этого графика очень сложно будет сделать какую хоть какой-то вывод и что-то из этого понять поэтому нужны какие-то дополнительные средства позволяющее анализировать данные либо производить какую-то первичную очистку давайте в первом первое что хочется здесь сделать с таким графиком это избавиться от пиков и давайте применим функцию скользящего среднего такой график становится намного стабильнее но линии все еще многое кажется они просто перегружают от график давайте применим функцию топ с параметром 5 оставим только топ-5 холстов которые на которых действительно сборщик мусора работает существенно долго и таких функций достаточно много красивее про них рассказывать не буду есть функций для вычисления процентили есть функции для вычисления взвешенных процентили если мы говорим про гистограммы различные функции агрегации трансформации все это поддерживается работает как правило очень быстро потому что как уже было ранее сказано практически все данные учитываются из кэша помимо самих графиков есть конечно же даже бороду и то есть логически связанные графике можно объединить в один красивый дашборд куда-то вывезти на телевизор и на него смотреть поддерживается популярная система у принцев раз на для визуализации временных рядов grafana то есть есть разработанный нами datasource который позволяет учитывать данные из системы мониторинга но постоянно смотреть на графики достаточно неэффективно и хочется в этом месте иметь какое-то средство автоматизации для этого есть компонент под названием alert wink и этот компонент позволяет гибко настраивать политики или правила по которым на блюд происходит наблюдение за изменяющимся временными рядами поддерживается различные способы нотификации и если говорить про alert и есть два способа создания land of по порогам ему значению тут все достаточно просто выбираем функцию агрегации выбираем интересующий нас пророк и условия его пересечения как только метрика будет как только значения метрики будет превышать либо упадет ниже этого порога то мы получим нотификацию удобным для вас способом если хочется сделать какие-то более сложные вычисления более сложную логику или математику применить для этого есть встроенный язык и запросов которые позволяют все это делать все это богатство функций которые поддерживается системой можно здесь применять и настраивать достаточно сложные alert и на этом у меня пожалуй все про сам сервис то как он устроен внутри можно достаточно долго рассказывать но сложно это все поместить в один в один доклад поэтому еще раз напомню что сервер запустился в яндекс облаке его можно пойти попробовать пока что не тарифицируется кажется самое время поэкспериментировать все сергей выпадет либо спасибо тебе вот тебе на память грамота спасибо таргет от организатор программного комитета и небольшой подарок у тебя сейчас будет задача выбрать лучший вопрос и кстати ребята кто смотрит доклад сейчас из зала иркутска в трансляции хочет задать вопрос идите сюда идите в зал tomska будете задавать я вижу ближайшую ко мне руку на третьем ряду и потом вижу в центральном проходе здравствуйте спасибо за доклад очень интересно было у меня два вопроса первый небольшой насколько индекс мониторинг совместим с prometheus и про металась по сбитый и второе как насколько удобно там делать будь миграции метрик когда он бывает когда мы добавляем какие-то метрики либо расширяемых насколько как как как процесс живет в этой стены ну давайте начну сначала со второго как насколько легко будет добавлять метрики сервис мониторинга в яндексе существует уже давно и ну собственно он является сервисом то есть мы предоставляем другим разработчикам его как счас решения и они все настраивают сами то есть мы на самом деле понятия не имеем про природу тех данных которые там собираются то есть разработчик когда выставляет например какую-то ручку по которым мы забираем эти данные в эти данные может положить все что угодно и может как угодно их расширять добавлять какие-то новые метрики старою удалять изменить существующие можно переписывать сейчас можно в систему писать данные по произвольным . то есть мы позволяем любую в любое место писать пожалуйста то есть можно существующие данные просто переписать либо дописать историю не обязательно записывать данные только в конец по поводу интеграции с периметру сам примет вас действительно сейчас очень популярна и решения и у нас внутри уже есть поддержка во-первых протокола кроме the us и в облаке мы думаем для над наверное более тесной интеграции с этим решением мы разрешим канджан по третьему ряду теперь вот с этой стороны третий ряд вопрос раздразните спасибо за доклад меня такой вопрос вот все что вы описали это по сути дела prometheus только сортирование и подобными вещами то есть ну масштабированием и меня вот такой вот вопрос немножко длинная прозвучит извините но хочу очень задать если для мелких команд мелких эти проектов то вы достаточно про метался поднятого на одной ноги и пусть он там себе собирает метрики хранит их сколько влезет настраивается ретенция policy все отлично работает для средних команд как бы ну примите вас просто побольше сервак берется потому что он плохо сортируется и в случае необходимости просто некоторые метрики пишутся в 1 prometheus а некоторые на второй сервер то есть в принципе можно как-то поиграть производительностью и решить этот вопрос вот для крупных команд скорее всего уже будет писаться какое-то свое собственное решение там например как в банкинге будет писаться решение которое вообще основана наконец source коде но свое то есть чтобы обеспечить безопасность вот собственно говоря мне не до конца понятны на кого рассчитана эта система яндекс мониторинг зачем вот вот я конечный пользователь я devops мне задача разложить сервисы на какой-то кластер с них собираются метрики я должен их кушать в какую-то систему я выбираю либо какое-то open собственное решение которое могу вот установить сам и в случае необходимости переехать с яндекс облаков какой-нибудь там digital оушен в с меня полная свобода в этом в этом виде в то время как яндекс облака я если буду использовать яндекс мониторинг то я буду привязан к нему в одном претендующий прямо самостоятельно доклад по мы меняемся когда было количество времени за дай пожалуйста вопрос уже зачем западе это второй раз когда ты его задано услышали хорошо давай я коротко объясню зачем затем что не все хотят настраивать систему мониторинга как минимум потому что по нашему опыту часто бывает так что в каких-то продуктовых командах этим занимается инициативный человек ему хочется в этот момент что-то по настраивает что-то понаблюдать но как правило этот человек потом либо переходит другой продуктовый проект либо там у него заканчивается интерес к этой области и ему становится это неинтересно второй момент это он заключается в том что да прими то вас можно настроить но насколько будет надежно это решение если он пишет данные всего лишь на один диск диски выпадают по нашему опыту диски выпадают чуть ли не каждый день и наше решение оно надежно она протестированная уже годами нас насколько я и зверь насколько мне известно аналогичных инсталляций примет импорт просто не существует которые и смогли смогли бы привести переварить такую же настроек уже вы будете проводить дискуссионную зоне прям реально там есть о чем поговорить об отеле у вас есть какие-то свои мнения и сразу сейчас во время ответ на вопрос вы не придете к кому-то мнению на перейдём к следующему вопросу чтобы дать шанс и еще ребятам меня достаточно короткий вопрос скажите пожалуйста почему не используется как хауса для метрик этого они пишут что для метрика на сайте греха остается на достаточно этот же вопрос предлагаю почему не задник своих будет хорошо это достаточно популярный вопрос на самом деле да люди часто слышат про то что в крик aussi хранятся временные ряды и он хорошо с этим действительно справляется но клик house условно или хаусе появилась поддержка сжатие временных рядов не так давно в нашей системе она есть уже годами не знаю поддержка горилла in кодинга появилась чуть ли не сразу после выхода этой статьи еще там не знаю никто особо не поддерживал подобное решение ну и плюс не знаю изначально так то так сложилось можно сказать там рядом вот в предыдущем наружу главное и поднималась и база доклад у меня такой вопрос вам больше про систему уведомлений то есть то лифтинг модуль есть такая проблема как там и обвешивать систему алё ртами на разные уровни то есть там запросов стала медленнее проходить нагрузка на процессор и так далее всегда есть вероятность что они между собой связаны и и грубо говоря alert и начнут каскадно друг друга влияет то есть у них есть какая-то одна причина но абсолютно разные уведомления будут приходить то есть у вас есть какая-то система которая позволяет вот найти взаимосвязь между этими уведомлениями между причинами почему эти алерта срабатывают и сразу смотреть в корень или вам приходится каждый раз разбираться то есть предположим я знаю вас там жертвы паладин и началась проблема с производительностью сразу там 15 литров начали орать образных проблемах а причина у них одна сейчас таких именно в нашей системе количество мониторинга такой возможности нет потому что а лифтинг это один из самых молодых компаний который появился и существует наверное чуть больше года но помимо количество мониторинга в яндексе есть еще система событийного мониторинга и она позволяет достаточно гибко агрегировать те нотификации которые отправляются через нее то есть у нас есть интеграция между двумя этими системами то есть если пользователь настраивает какой-то alert он может настроить отправку нотификации через вот еще одну систему которая занимается именно уже отправкой нотификаций и там есть достаточно богаты и средства по группировки по там интаймом и всему такому основная проблема просто что админу придет 50 емейлов и за одну проблему но с разными причинами неправда разными названия действительно такая такая проблема существует как свечи вопрос вот справа от тебя сергей смотри и потом мы на первый ряд придем спасибо за доклад ближе держи микрофон здравствуй спасибо за доклад вопрос такой для абортов и использовать графа если вдруг граф она упадет таким образом для let off используются негров она не для агентов используется свой сервис которые периодически ходит в хранилище вычитывает оттуда данные применяют какие-то правила и делают нотификацию в нужный момент понтовых граф она использует только для визуализации grafana только для визуализации всем спасибо seba с первого ряда вопрос поднимать руки привет я возможно пропустил но вот когда у вас вечно хранится вот этот вот временной ряд он как-то вот разряжается ну то есть вот каждые 15 секунд мы запросили вот эту метрику да то есть интересно ли мне там что было год назад вот каждые 15 секунд то есть она же там наверное стоит его как-то более даже мер живут вот этом интернете то есть вода кто более плотная храниться до выполняется функция прореживания выполняется она как раз в тот момент когда мы выполняем мир между деле снапчатом или terms с учетом в любом случае мы делаем такой мер и в этот момент переживать данные становится но достаточно дешево то есть мы вычитываем данные из двух источников делаем выполняем операцию пример жевания и записываем уже примерные данные в соседние snapshot а там уже вот вот этот период между разными ну вот 7 серии он там как он динамически как-то меня это его можно динамически настраивать то есть пользователь когда передает метрику он может прийти в настройке своего конкретного шарда но позже кластер сервис и сказать что я хочу чтобы эти метрики придерживались там вот по такой политики порежу то есть все что старший недели например проживать до пяти минут сегодня ну как его как правило использовать такая политика вот все данные в истории хранятся с гранулярный до пяти минут то есть меньше ну вернее больше интервалов до больших натуралов пока что не порежу и нет необходимость сейчас вопросы глубины залу и потом снова на первый ряд вернемся zdravstvuite где копятся метрики значение метрика до того как их считает вечер они копятся в приложении и в этом в приложении когда вечер их то есть как как-то устроим приложение выставляет какую-то ручку как правило почти типе и может через эту ручку передавать метрики либо накапливать эти метрики то есть у себя если например она внутри себя каким-то образом но с фиксированной сеткой например там опрашивает так часто бывают например люди хотят по секундные точки но передают раз 15 секунд то есть они за каждый такой fitch придают 15 точек вместо одной либо переходя в эту ручку нам возвращают последнюю точку по конкретный метр то есть где то еще настраивается за что дернуть приложения вечера как правило да но если этот долгоживущий процесс есть библиотека которая позволяет все это делать то есть ничего сложного в этом нет а если это кратко живущий процесс то приложение может просто сама периодически пушить в гей твой свои информация metric спасибо спасибо сейчас вопрос из центра первого ряда и потом вот это не было бы хорошо а тут говорил что когда один из узлов входящих шарды получается чем 100 загрузку система начинает переносить шарды на другой узел и тем самым не возникает ли лавины текста и так загружено узел начинаем еще сильнее грузить читая с него огромный объем данных если узел загружен мастер мастер эту ситуацию отслеживает он видит что нужно оттуда какие-то шарда убрать и при этом он руководствуется тем ну информация о загруженности остальных узлов вот у нас был он и так был загружен возникла что этих же хардов их нет других узлах величать переместить тем самым повысив чтение ну такой ситуации фактически это задача рюкзаке то есть ну понятно что она достаточно плохо решается на самом деле в ран тайме и если возникают такие ситуации либо призу производится какие-то ручные манипуляции либо но не просто разбираемся на как правило такого не происходит если он розы для для для того шарады и как бы делает чтобы распределить нагрузку более менее равномерно между ним поднимите руку кто хочет задать вопрос я просто не вижу вот отлично и еще поднимите руку последующей хочет добрый день спасибо за доклад я вижу узкое место лично в ssd-дисках можно такую практику сколько живут то что логирование чтения-записи постоянно юзание создать и xcaret как бык не jell-o для них то очень хороший вопрос диски сыпятся очень часто к сожалению производителя я конечно не буду называть компании но они подкладывают определенных кораблей в этом месте вы пожалуйста а у тебя есть еще вопрос вот этими недолга гриб давай скажи его дайте микрофон третий ряд третий ряд 3 ряда у меня такой вопрос по шар дам вот вы говорили что там используется два независимых шарда которые на который записывается абсолютно одинаковые данные ну я так понимаю это дело распределенная хранение кластер 2 класса 2 master of с абсолютно одинаковыми данными и собственно а у меня вот один вопрос а как бороться с при дворе и нами в этом плане если она развалится то сейчас класть кластер и друг овне может случиться так что например в один из кластеров просто вас не записалось что-нибудь а в один в другой записалась и как как с с педро и нам бороться с то для этого битвы и вычитываю данные из двух кластеров и в процессе ну после того как они вы читали эти данные они производят наших мы работаем с временными рядами поэтому как мер жить при мной ребят все достаточно просто то есть у нас есть фиксированные точки как правило пользователь запрашивает эти точки с каким-то демпингом то есть с какой то фиксированной сеткой поэтому те данные которые будут вычтены из сейчас из этих стороны из этих стороны они будут выровнены по общим сетка мы все что нужно сделать это правильно их смерть в одну варим в 1 грамме на ренту за до задачи очень пространство ну ладно спасибо еще вопросы сергей тебе предстоит сделать выбор я уже вопросы утро он мне не понравился вопрос парадиски потому что это прям куриного шкурин человека и дисков да да да выходи сюда пожалуйста автор а пока ты идешь вспомни как тебя зовут где-то работаешь и почему-то этот вопрос задал скажи нам коротко пожалуйста нападениям не зовут ди не стучали компания персонала на тихий шум house менеджмент значит вопрос родился потому что очевидно это услуга которая будет в дальнейшем продаваться ну очевидно почему вы этой завершение использовали потому что вам нужно достигнет скорости для обработки всех клиентов своих сейчас в облаке но в дальнейшем если такая же решение сохранится это будет достаточно дорогая услуга потому что диски будут сыпаться быстро спасибо но в этом месте на помогает войди by потому что выпадение дисков мы переживаем без какой-то деградации но есть стоимость владения есть стоимость музеями то понятно"
}