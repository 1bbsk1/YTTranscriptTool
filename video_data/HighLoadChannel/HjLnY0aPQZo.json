{
  "video_id": "HjLnY0aPQZo",
  "channel": "HighLoadChannel",
  "title": "Топ ошибок со стороны разработки при работе с PostgreSQL / Алексей Лесовский (Data Egret)",
  "views": 87328,
  "duration": 3159,
  "published": "2018-11-19T02:53:37-08:00",
  "text": "спасибо всем меня ставили да и 45 ошибки которые работники при работе с после сам и немного слов про себя которые такое да чтобы вы примерно представляли кто я я раньше работал системным администратором работал с линуксом мне нравятся всякие виртуализации всякие систему мониторинга и постепенно я начал работать с полисом и в какой-то момент работа с под колеса у меня стало занимать большую часть времени потом я стал д.б. сейчас я работаю в postgres корпус gliss kur дебаф дата и град и это консалтинговая контора и соответственно у нас очень много компаний с которыми мы работаем очень много общения с разработчиками и очень часто одни и те же проблемы мы видим там из месяца в месяц из года в год они постоянно повторяются то есть хай лот существует довольно давно но при этом люди ходят на highload но допускают те же самые ошибки что и про которое говорили давным-давно вот так слайдов будет довольно много говорить буду быстро поэтому заранее извиняюсь итак у нас новый компании но тем не менее компании бывают разные в маленьких компаниях используются базы данных ошибки случаются всякое бывает бывает что падает в крупных компаниях тоже используются базы данных но даже в крупных компаниях при отлаженных процессах все равно случаются ошибки и базы падают таким образом получается что неважно какого размера компания ошибки все равно случаются и базы данных могут там периодически обваливаться рушится и что семьи могут может происходить и немного истории о том откуда на мой взгляд могут происходить эти самые ошибки но и взгляд одна из проблем это то какими фичами пользуются компания при работе с после сам начинается все просто сначала нас есть просто postgresql набор каких-то данных простые запросы там с дроидами мы как-то берём данные select им их там пишем мы все просто потом мы начинаем использовать более расширенный функционал под криса добавляем какие то новые функции добавляем их сын жанны и становится ещё больше мы там подключаем потоковую репликацию начинаем как-то шар дится вокруг появляются всякие разные утилиты всякие разные обвес для того чтобы работать спускались на всякие bouncer и pg пол и патроне и так далее и в итоге тихий снится настолько много что хочется взять дежурный пистолет как бы положить его в ящик иногда доставить застрелиться убрать и продолжить дальше и вот на всем этом появляются ошибки дальше ошибки могут браться откуда они могут браться туда как мы храним данные опять же у нас есть проект только появился у нас есть данные и таблиц довольно мало мы можем дам простыми запросами оттуда взять данные записать но потом таблиц становится все больше и больше мы берём данные отсюда сюда потом отсюда еще joy ним и запросы получается уже такие сложные они включают все самые разные конструкции там с этой с abc вере и им списке и lateral и и допустить ошибку и написать какой-нибудь кривой запрос становится гораздо легче и оказывается что это еще верхушка айсберга еще у нас есть это 400 там каких-то таблиц партиций которыми мы тоже изредка пользуемся иногда там оттуда читаем данные так вот третья история она о том как продукт сопровождается и продукт он всегда с базой данных нужно же где-то хранить данные и как развивается продукты как с этим развивается база данных у нас есть девелопера с одной стороны они заняты своими языками программирования они пишут они развивают свою свои скиллы вот как раз таки в области разработки программного обеспечения и они пишут свое приложение они развивают именно его они не обращают внимание там на сервисы на то как работают там кафки и под грипсы мой ускорили так далее им как бы это неинтересно и они разрабатывают новые фичи в своем приложении и до остального им по большей части дела нет из другой стороны у нас есть админы они праве женят новые инстансы там в амазоне на баре металлы еще где-то и как бы заняты автоматизации настраивают диплом чтобы все там работала чтобы выкладка кода работало нормально занят этим но и остаются конфиге то есть настраивает взаимодействие между сервисами и смотрят что все бы это прекрасно работала то есть складывается ситуация когда на тонкий тюнинг компонентов и базы данных том числе не остается времени либо нет желания и такая база она работает с дефолтным и конфигами и в какой-то момент получается так что про эту базу уже давно все забыли и она работает и как бы и черт с ней работает и пускать там работает так вот получается у нас такой набор граблей которые разбросаны везде и разработчики периодически наступают на эти грабли делают себе больно и в этом докладе iohk раз таки постараюсь эти грабли собрать вместе в собрать в неком таком сарайчике чтобы они были вместе чтобы вы про них знали и при работе с после самых не допускали так вот доклад будет состоять из нескольких частей первая часть это планирование мониторинг 2 то масштабирование 3 это немножко там будет немного теории про приложение только к приложение работает с транзакциями затем чуть-чуть про велосипеда строение когда нужно сделать что-то что уже давно изобретено и чуть-чуть заступлю уже на более такую админскую поляну это про автоматизацию и контейнер из оркестра ции итак поехали первая часть это планирование мониторинг и сразу также небольшая преамбула предположим что у нас есть новый проект новый проект навсегда активная разработка проверка гипотез проверка реализации новых фич как это все работает и в этот момент когда приложение только-только появилась и развивается в этом приложении мало трафика мало пользователей мало клиентов и все они генерируют достаточно небольшие объемы данных и получается так что у нас в базе работают довольно простые запросы и они отрабатывают довольно быстро нам не нужно терять большие объемы данных нам не нужно лопатить там все эти гигабайты данных мало трафика и все это работает шустро и быстро и прекрасно и нет никаких проблем но когда приходит трафик увеличивается количество пользователей появляются новые данные база начинают увеличиваться в объемах и старые запросы они перестают работать нужно уже достраивать какие-то индексы нужно переписывать запросы как-то их оптимизировать появляются проблема производительности и все это рано или поздно выливали выливается в то что у нас появляются какие-то ошибки в 4 утра админы становятся недовольными начальники становятся злыми и все становится довольно таки печально так вот давайте смотреть что не так чаще всего на моем опыте не хватает дисков простой пример мы открываем график мониторинга утилизации свободного места на диске видим что место заканчивается начинаем смотреть что не так сколько места чем съеденное оказывается что у нас есть какой-то каталог побег слог админы и особенно админы баз данных они знают что это за каталог и они его обычные но не трогают как бы существует он и существует но разработчик особенно если он где то там на свои девелоперской машине на stay дженги он такой чешет голову так и думать блин но какие-то логе давайте его удалим все удаляет каталог база перестает работать и следующие чем начинается это гугление как же поднять базу после того чтобы после того как журналы транзакции были удалены это первая история первый пример второй пример опять же открываем мониторинг смотрим что места не хватает смотрим на сей раз у нас место занято какой-то базой мы начинаем искать какая база занимают больше всего места какие таблицы и индексы объясняется что это какая-то прекрасная таблица с историческими лагами ну супер исторические логином некогда были не нужны они может там пишутся там со времен там второго пришествия мы давайте зачистим что-нибудь там старшие октября до составим кокаин тебя выдает запрос запустим его у нас отработает строки удалит и как бы все нормально но запрос работает работает работает работает 10 минут потом мы смотрим как бы таблица занимает по-прежнему столько же места то есть тут уже проблема связана с тем что под gris он удаляет строки из таблицы все верно но он не возвращает место операционной системе и такое поведение после со оно неизвестно разработчикам большинству разработчиков и они как бы иногда с удивлением воспринимают этот факт так вот объясняем что чаще всего не хватает дискового пространства на 2 вместе опять же не хватает дисков разработчик например составил какой-нибудь интересный запрос ну и ладно не разработчику рим обычно все меня том что м составляет плохие запросы который вычитывает несколько таблиц то есть там есть несколько join of они читают таблицы при этом делают это параллельно в несколько потоков потому что под gris он умеет параллель эти операции работы с данными и может читать таблицы например несколько запросов но учитывая что у нас несколько серверов приложений этот запрос и вычитывает все таблицы несколько тысяч раз в секунду получается что у нас сервер баз данных просто становится перегруженным диски не справляется и все это приводит к 500 ошибки с бэг-энда то есть база просто недоступна но это еще не все нужно вспомнить про тормоза фоновых процессов потому что в под здесь есть всякие чик pointer и вакуум и репликация и так далее есть еще накладные расходы от виртуализации случаях когда у нас база запущена на какой-то виртуальной машине сбоку есть еще одна виртуальная машина на этой железки и они там могут как-то конфликтовать за ресурсы и запросы базы будут тормозить можно вспомнить хранилище про китай от китайского какого-то производителя которая в пиковые самое неожиданное времена начинает просто тормозить там какой-нибудь ребаланс сделать внутри себя ли rebuilding и та же база начинает страдать плюс дефолтной конфигурации это моя любимая тема просто приходишь к заказчику он говорит у меня тормозит база ты смотришь а у него дефолтный конфиг все почему postgres дефолтный конфиг под колеса предназначен для того чтобы запускаться на самом слабом чайники и база запускается работает но когда она работает даже на каком-то уже железе среднего уровня то этого конфига недостаточно его нужно ценить и таких историй на самом деле довольно много и все на на каждую такую тему можно еще по несколько докладов написать так вот выясняется что чаще всего по адресу не хватает либо дискового пространства либо дисковой производительности к счастью с процессорами с памятью сетью как правило все более-менее в порядке как быть в данной ситуации в данной ситуации нам нужен мониторинг и планирование это казалось бы очевидные вещи но в большинстве случаев никто не планирует базу и мониторинг как правило не покрывает те необходимые моменты которые нужно отслеживать при эксплуатации под gresso но при этом есть вполне как вы все работает и это все как бы нормально да очевидные вещи мы всегда все планируем сюда все мониторим но увы никто этого не делает если делают то очень немногие люди однако есть набор каких-то четких вещей которые можно соблюдать и в принципе будет все работать нормально когда вы планируете базу данных размещаете ее на ssd если он туда будет говорить что ssd это не надежно что это не сыпятся они валятся как бы это уже давно не правда и создается давно перешли тот порог когда они надежные и стабильные и производительные интер праздные модели ssd они работают годами и у одного из наших заказчиков к которым мы стояли одним из первых intel и они до сих пор работают и никаких проблем другой момент эта схема данных всегда планируйте схему данных не пишите в базу данных те вещи которые вам в которых вы сомневаетесь что они понадобятся потому что они гарантированно вам вам не понадобятся простой пример вот такой таблички у одного из наших клиентов я немножко поменял даминов чтобы меня не побили эти заказчики у нас есть таблица прекрасных логов и в нем есть колонка дейта с типом джейсон то есть условно говоря мы в эту колонку можем запихать что угодно вообще там любой джейсон любого размера так вот если посмотреть последние записи этой таблице окажется что они занимают 8 мегабайт нет проблемы в подгрести хранить записи такой длины пузырится очень хороший сторож который прожевывая такие вещи но проблема в том что когда сервера приложений будут таскать данные из этой таблицы они запросто съедят пропускную способность сети и другие запросы просто будут страдать в этом заключается проблема планирования когда люди пишут в базу все подряд без разбора и конечно стоит использовать парте цианирование при каких-то любых намеках что у вас будет какая-то какая-то история которую вам необходимо хранить больше чем год два года парте цианирование иногда кажется какой-то такой сложной штукой и кажется что нужно заморачиваться с какими-то триггерами с какими-то функциями которые будут создавать партиции на самом деле это один раз сделал и она работает простой пример с тем же апдейтом с тем же дарит им который удалял данные 10 минут в первом случае он работает 10 минут но когда у нас данная рассортированы по партиям портится удаляется буквально за несколько миллисекунд и место отдается операционной системе сразу то есть управлять данными в историческом плане гораздо легче проще и безопаснее мониторинг тут тоже есть некоторые конкретные рекомендации вообще про мониторинга можно делать отдельные доклады и в плане базы данных есть несколько рекомендаций вообще по умолчанию многие систему мониторинга они предоставляют мониторинг процессоров памяти что там сеть диска выводились дисковое пространство но как правило нет утилизации дисковых дисковых устройств информации о том насколько загруженной диски о том какая пропускная способность в данный момент на дисках и какая late in se то есть эта штука всегда должна быть добавлена в мониторинг и мы можем быстро оценить как у нас загруженной диски второй момент это пузырь из мониторингов под колеса как ну очень много их очень многое на любой вкус и довольно много долгой долго и долго можно выбирать но тем не менее есть некоторые моменты которые обязательно должны быть в таком мониторинге во первых это подключены и клиенты мы должны отслеживать статус этих клиентов с какими статусами они работают мы можем быстро находить вредных клиентов которые вредят базе и быстро их отключать от базы ошибки мы должны мониторить ошибки потому что мы можем отслеживать так хорошо насколько хорошо работает база нет ошибок замечательно появились ошибки это повод уже заглянуть в логе и начать разбираться что что идет не так ну и конечно за же запросы мониторим запросы их количественные и качественные характеристики что примерно оценивать нет ли у нас медленных долгих запросов либо каких-то ресурсоемких на сибирском хайло diy я делал доклад для делал доклад по мониторингу пузыриться и вот по этой ссылке можно его посмотреть там более детально все эти моменты расписаны ну и конечно пост грессов в подрисовал вики есть страница посвящена я мониторингу на ней всегда можно найти какие-то инструменты попробовать поставить себе поиграться и выбрать что-то интересное так вот мы вроде обмазали с мониторингом вроде все склонил спланировали но все равно проблемы какие то есть надо смотреть дальше что не так и тут мы подходим к масштабированию обычно разработчик когда работать с базой данных база данных ему видится некой строчкой в конфиге с которой он как бы может работать и дальше ему не интересно как работает база ему не интересно там внутренности как устроен вакуум как работает чекпоинты репликация планировщик все это как бы и так как бы есть чем заниматься есть своем любимом языке программирования много интересных вещей которые в ту ду листе стоят и хочется попробовать но тем ни менее как работает база как правило не интересно база выглядит виде одной строчки в конфиге там в каком-нить земли или джейсоне и база представляется одной точкой входа то есть разработчика и пишет данное и читает оттуда его как бы все устраивает приложение работает и нормально и вот в этом плане а вот это вот незнание предмета она приводит довольно к интересным последствиям когда разработчик начинает писать запросы которые работают в этой базе и тут надо немножко теории у нас есть два типа транзакции в лтп и о лап велосипед а быстрые короткие легкие транзакции которые выполняются там буквально доли миллисекунд и они отрабатывают очень быстро их очень много и в противовес им есть olap это такие аналитические запросы которые читают большие объемы данных они вычитывают там большим силы таблиц и там считают какую статистику они работают как правило долго медленно и они тяжелые так вот последнее время последней этом 23 года я все чаще слышу такое слово и штаб гибридная транзакционные аналитическая транзакционный аналитический processing так вот если вам некогда думать над масштабированием и разнесение olap запросов olap запросов и will be by запросов можно так и говорить у нас и чтоб но как бы все хорошо но все равно практика показывает опыт и боль ошибок показывает что нужно эти все вещи разносить и лтп olap должны как бы жить отдельно друг от друга потому что olap это долгие запросы они там выставляют свои блокировки и они мешают быстрыми короткий мультик транзакциям которые должны работать быстро так вот мы подходим к вопросу масштабирования как раз масштабировать по сгрыз так чтобы разнести нагрузку и чтобы все остались довольны чтобы был типе транзакции работали быстро olap медленно есть несколько вариантов во-первых самый простой вариант это потоковая репликация когда у нас приложение работает с базой мы на эту базу к этой базе подключаем несколько реплик и выносим разносим нагрузку у нас получается что запись по-прежнему идет в мастер базу а чтение мы разносим по репликам и масштабироваться так можно очень очень широко плюс мы можем к отдельным репликам подключать еще реплики и получать каскадную репликацию и уже отдельные группы пользователей выносить на эти реплики либо отдельное приложение которые читают ту же самую аналитику например можно выносить на отдельную реплику другой механизм это механизм логических публикаций и подписок когда у нас есть несколько независимых подогреть серверов у них свои отдельные базы свои отдельные наборы таблиц мы можем бродить и наборы таблиц и подключать в соседние базы и они будут видны приложениям приложение смогут с ними нормально пользоваться то есть все изменения которые будут в источнике происходить они будут реплицироваться на базу назначение там будут видны работает прекрасно с десятой версии под колеса другой механизм это декларативное парте цианирование и механизм внешних таблиц опять же мы можем взять несколько адресов и создать там несколько наборов таблиц которые будут хранить какие-то данные за какие-то диапазоны например это могут быть данные за 2017 18 и 19 год либо как-то согрев собранное пары вижу какого-то и с помощью механизма внешних таблиц мы можем объединить все эти базы в виде парте цианирование таблицы в отдельном подгрести и приложение уже может работать с этой profits и они равной таблицей но на самом деле оно будет качать данные с этих удаленных партиций то есть этот такой sharding когда объемы данных уже просто не влазят в рамки одного сервера ну и конечно это все можно объединять вот получаются такие развести конфигурации и всегда можно придумывать разные топологии pascal совы и репликации и все это будет в принципе работать без особых проблем но всегда возникает вопрос а то мы пишем данные читаем данные из одной базы с чего начать самый простой вариант это начать с репликации то есть самый первый шаг здесь это начать разносить нагрузку на чтение на запись в данном случае мы получаем что у нас в мастер идет запись мы пишем туда а с реплик осуществляем чтение то есть мы так и масштабируем нагрузку и выносим чтение с мастера ну и конечно же не забываем аналитиков аналитические запрос они работают долго для них нужна отдельная реплика с отдельными настройками чтобы долги аналитический запросто могли там работать другой момент это балансировка у нас по-прежнему остается та самая строчка в конфиге который оперирует разработчик ему нужно место куда он будет там писать и читать на тот конфликт здесь есть несколько вариантов идеальный вариант реализовывать балансировку на уровне приложения когда приложение сама знает откуда ему читать данные и выбирайте реплику иногда важно прочитать данные с мастера потому что допустим это могут быть какие-нибудь баланс пользователя например да то есть важно брать его всегда актуальный а если это какая-нибудь картинка товаров или информация о товаре я ее можно прочитать с некоторой задержкой можно прочитать это с реплики поэтому идеальный вариант это все-таки на стороне приложения другой вариант это балансировка на уровне dns но на мой взгляд это такая не очень они очень удобная реализация поскольку она работает иногда долго и не дает необходимого времени при переключении ролей мастера между серверами в случаях файла вера более интересный вариант это использования keep-alive их a proxy куда у нас есть виртуальные адреса для мастера и для набора реплик и эти виртуальные адреса они перекидываются между серверами х прокси ахав roxy уже осуществляет балансировку трафика и самый на мой взгляд более интересный вариант это использовать патроне в связке с какими штуками типа звуки перейти сиди консул то есть сервис discovery у нас отвечает за то кто сейчас за ту информацию кто сейчас мастера кто реплики патроне управляет кластером пост грессов осуществляет переключения если топология изменилось эта информация появится в сервис discovery и приложение смогут оперативно узнать текущую топологию ну окей мы с масштабировать и данные разнесли нагрузку но все равно что то идет не так какие-то бывают проблемы и самая частая проблема это лак рипли кации возникает лак репликации и как можно поступить можно сделать как git love можно просто дропнуть базу но мы же мазались мониторингом мы открываем мониторинг смотрим и видим там долги транзакции подходим к третьему пункту как работает приложение с транзакциями так вот в общем случае если не забегать далеко то медленное и ничего не делающая транзакция не в целом приводит к снижению производительности не к резкому скачкообразно muack такому плавному дальше расскажу почему так же ничего не делающие транзакции приводит блокировкам еду блоком потому что долгие такие транзакция не удержит блокировки настройки и мешают другим транзакциям работать так возникают ошибки и это в целом приводит ко всяким 500 м на бэг-энде и к ошибкам там в интерфейсе и еще где-то и все становится гораздо интереснее когда появляются у нас всякие задачей типа отложенной обработки данных например очереди там еще гораздо все интереснее получается и уже к блокировкам этот локон добавляется еще другой род ряд проблем и тут немного теории о том как же возникают эти проблемы и как вообще почему этот механизм долгих и ничего не делающих транзакций idol транзакции почему он вреден в под здесь есть такая штука энди сиссе это условно говоря движок базы данных он позволяет он позволяет клиентам конкурентно работать с данными не мешая притом друг другу то есть читатели не мешают читателям в писатели в идеальном случае не мешают писателем есть конечно некоторые исключения но не в данном случае не сильно нужны так вот получается так что в базе для одной строки может существовать несколько версий этой строки для разных транзакций то есть клиенты подключаются они базовых дает им снимки данных и в рамках этих снимков могут существовать разные версии одной и той же строке соответственно когда у нас жизненный цикл базы идет транзакции сдвигаются заменяют друг друга появляются какие-то версии строк которые уже не нужны никому ни одной из транзакций так появляется необходимость сборщики мусора так называемом auto lo que me и получается так что долгие ничего не делающие транзакции они существуют они мешают авто вакууму вычистить эти версии строк и вот эти вот мусорные данные они начинают кочевать из памяти на диск из дисков память и на это тратятся ресурсы циpкa и памяти чтобы хранить весь этот мусор ну и так выходит что долгие транзакция не является источником проблем так вот откуда они берутся с точки зрения приложения и с точки зрения приложения всегда получается так что при именно приложение виновата появление долгих транзакций то есть если база будет существовать само по себе транзакции долгие они ничего не делаешь и ниоткуда не возьмутся и на практике бывает так приложение открывает транзакцию делает что-то в базе потом решает сходить куда-то во внешний источник win cash в радистом прочитать или обновить там данные и в надежде что он а потом вернется в базу и там продолжит работу и закроет транзакцию но в этом внешнем источнике происходит где-то какая-то ошибка приложение падает и и все и транзакций остается незакрытой и так она существует пока и о том кто незаметно сильно не убьет с другой стороны может быть проблема обработки ошибок когда опять же приложение открыла транзакцию поделок какой-то какую-то задачу в базе потом вернулась обратно там в код в себя по делать какие-то функции какие-то вычисления чтобы дальше потом продолжить работу в транзакции закрыть но вот на этих вычислениях она обвалилась по какой-то ошибки кот вернулся там в исходное начало там свои петли какой-нибудь и транзакция опять же осталось незакрытой пока я кто-нить не найдет мы остается человеческий фактор когда админ там или разработчик или аналитик они работают в каком-нибудь подменили дыбе very и они просто работают работать работать там открыли транзакций учетную в нее делают потом его отвлекли он переключился на другую задачу потом на третью потом оказалось что и пятница вечер он забыл про это ушел на выходные и транзакция продолжает висеть и как бы производительность базы постепенно страдает так вот что делать в этом случае мы используем мониторинг соответственно нужны alert и в мониторинге любая транзакция которая висит там больше часа и ничего не делает это уже под посмотреть откуда она взялась и разбираться что не так следующим шагом конечно же отстрел таких транзакций то есть это может быть какая-то задача в кроне это может быть в посредством конфиге может быть такая крутилка которая отстреливает такие транзакции то есть нужно выставлять пороге которые автоматически отстреливают транзакции которые там дольше 10 20 30 минут ну и конечно же нужно рефакторинг приложение выяснять откуда берутся такие транзакции почему они происходят и устранять такие места и итогам к этой части его можно сказать чтобы следует избегать долгих транзакций любой ценой потому что они эффект от производительность базы очень сильно и все становится интереснее когда появляется задача выполнение отложенных каких-то задач например нужно аккуратно посчитать какие нить агрегаты и тут мы подходим к вопросу велосипеда строение это одна из наболевших таких тем как правило бизнесу или ну со стороны приложения нужно какую-нибудь осуществить фоновую обработку событий например там посчитать эти нити агрегат это минимальные и максимальные средние значения разослать какие-то уведомления этом пользователям или клиентам дам счета выставить еще что то либо настроить и камень от пользователя после регистрации там какую-то отложенную обработку там зарегистрироваться в соседних сервисов еще где-то истории довольно много но суть у них одна мы эту задачу откладываем на потом и не делаем ее здесь и сейчас и у нас появляется в базе вот такие вот таблицы которые у нас как раз осуществляют очереди то есть у нас здесь есть айдишник джо бы есть время когда он был создан когда был обновлен хендлер который взял количество попыток сколько это jolla пыталась выполнить то есть если вы видите у себя вот такую таблицу которое хоть как то отдаленно напоминает это значит у вас есть очереди сам описано которой вы пытаетесь реализовать так вот все работает прекрасно пока не появляются долгие транзакции когда появляются долгий транзакции таблицы которые работают с очередями они начинают тухнуть в размерах потому что джо бы все время добавляются старое jobo удаляются происходит апдейты то есть это очень интенсивная на запись таблица и старых версий строк появляется очень много и эту таблицу нужно регулярно чистить от устаревших версий строк чтобы ее производительность при этом не страдала так вот долгая транзакция она удерживает блокировку на устаревшие версии строк и не мешает вакууму ее почистить и такие таблицы пухнут очень быстро потому что записи очень много и когда таблица увеличивается в размерах время обработки начинают тоже увеличиваться потому что нужно прочитать больше страниц которые содержат мусор нужно дольше делать вычисления все это перелопатить и время увеличивается и очередь просто в какой-то момент перестает работать вот например топ запросов от одного тоже нашего заказчика у которого было самописная очередь и все запросы они как раз связаны с очередью и обратите внимание на время выполнения этих запросов они работают по двадцать с лишним секунд есть конечно один запрос который работает сорок шесть миллисекунд но даже сорок шесть миллисекунд это плохо так вот что делать в этом случае давно изобретено такая штука как bbq это менеджер очередей для под gresso то есть не нужно разрабатывать свой велосипед нужно просто взять по bbq один раз настроить его и забыть про очереди но есть некоторые проблемы во первых для pq мало документации когда открываешь официальную страницу читаешь и складываться ощущение что ничего не понятно вот начинаешь пробовать что-то делать разбираться с ней оказывается что она работает но ты там что-то поделал она заработала и ты не понял как так получилось какая-то магия есть очень много таких вот джедайских техник чтобы она заработала + очень много информации в мае линк листах это не очень удобный такой формат для получения информации но тем не менее очень много интересных вещей находится именно там где-то надо читать но с другой стороны работает по принципу настроил забыл условно говоря мы создаем функцию которая у нас является триггерной функцией мы эту функцию в качестве триггерной функции вешаем на таблицу с которой мы хотим там получать изменения и она работает так надежно долго и практически вспоминаем про пеку только когда нужно добавить еще вы queen таблицу там в очередь ну и конечно использование по как у она дешевле чем поддерживаете настраивать отдельные брокеры тоже очень такой хороший плюс так вот какой здесь можно сделать вывод вывод в том что если вы столкнулись с какой-то задачей с которой возможно кто-то уже столкнулся попытайтесь поискать инструменты которые возможно уже изобретены это в первую очередь относится именно к очередям мы на своей практике выпилили очень много самописных очередей заменили их на pq и она работает конечно есть какие-то большие инсталляции под грессов там например вы вид а когда им возможности по какую не хватает но это такие яичные кейсы единичные случаи это уже отдельно как бы решается все но тем ни менее пгк очень решает большой проблем с кого проблем связанный с очередями здесь уже автоматизация у вас начинается тут я уже захожу на поляну админов так вот как мы уже знаем админы они чего хотят автоматизации они хотят раскатывать инстанции чтобы диплом работал без их вмешательства и чтобы конфедерат скатывались мгновенно разработчики же со стороны хотят чтобы диплом работал чтобы они там только за коми телике это изменения они дальше там подтянулись под тестировались разлились и хорошо все было ну и конечно же они хотят катить иммиграции без каких-то ручных вмешательств чтобы не надо было логиниться на сервер руками выполнять какой-то alter чтобы ничего такого не было ну еще все хотят авто failover чтобы вот работает кластер под криса чтобы он там работал себе если вдруг какой то с бы в нем произошел чтобы автоматически там роль мастера перекинулось на другой сервер и мы об этом ничего не знали что все там под капотом работала есть несколько очень серьезных проблем которые мешают использованию в авто файла вера во первых эта ситуация сплит брейна когда у нас есть нормальный кластер пожгли со мастер несколько реплик запись осуществляется в один сервер чтение осуществляется с реплик происходит сбой какой-то сетевой или еще какой-то сервер выключается но как уже говорил дима стали ровно на докладе про базы данных обернитесь отсутствует механизм хельсинга если механизм хельсинга отсутствует может случиться ситуация когда приложение по-прежнему пишет старый мастер и новые переключившиеся приложение начинают писать в новый мастер получается ситуация в сплит брейна и вот попытка восстановить собрать обратно консистентной она бывает очень тяжелая и тратит очень много нервов тот же самый вид хоп когда у них там неделю назад была проблема как раз они столкнулись с прибрежном и они в итоге там из бэкап и восстанавливали свою базу чтобы прийти и перевести ее в консистентной состоянии другая проблема это каскадный failover у нас есть опять же мастер несколько реплик мастер падает мы переключаем нагрузку на новый мастер на реплики на оставшиеся но старый мастер не успел стать репликой он не успел перемениться резеро ваться как а этот момент падает у нас с другой мастер практически там это бывает за секунду происходит вся нагрузка у нас ложится уже на единственный сервер он не справляется с этой нагрузкой это же складывается то есть такой каскад фолловеров он тоже бывает это та же проблема и когда мы сталкиваемся с задачей of the flower а когда от нас клиенты хотят ftp failover какие решения бывают какие мы чаще всего видим во первых это ваш скрипт и это такое хрупкое решение которое нужно постоянно тестировать постоянно отлаживать и админ ушел другой админ пришел он не знает как этим пользоваться но там если вдруг что-то сломалось очень тяжело найти в каком месте но сломалась и постоянно нужно его дорабатывать другой вариант это использование ansi вал play буков это тоже не знаю мне кажется это баш скрипты на стероидах тоже нужно тестировать постоянно смотреть что она работает там на тестовых своих кластерах там прогонять и тоже очень много головной боли есть патроне на мой взгляд это один из лучших продуктов потому что у нее есть авто failover у него есть мониторинг за состоянием кластера плюс у него есть там функция отдачи топологии кластера в сервис discovery можно об этом оперативно уведомлять приложения другой вариант это под grease off the file a wear он основан на ps мейкере тоже интересная штука но она довольно таки уже сложнее и требует знания по из мейкера то есть это уже дополнительный слой зданий который нужно освоить ну и конечно же есть столом но столом он больше такой предназначен для облачных задач для каберне часа например столом он гораздо но на мой взгляд он по сложнее патроне но в принципе они взаимозаменяемые их можно использовать можно выбирать между ними и последний пункт это контейнер и регистрация в сердце наверное знают что в последние годы там докеры кубер ничего не растут это довольно трендовые вещи все знают что такое докер нет того как такого админа который бы не пользовался и штуки это динамично развивающееся в них очень много появляется всего нового динамичного то же самое же скруббер нынче сам каждая новая там версия она добавляет очень много интересных вещей при этом старые вещи могут перестать работать и тут возникает мысль что если развернуть базу в кубер найти и тут возникает самые разные истории во первых база это всегда стоит и ее нужно где-то хранить возникает вопрос а где хранить до у нас is open source решение есть сэв глаз рфс и линз top gear башней но фундаментальная проблема в том что это не будет быстро это работает очень медленно и не будет работать быстро 0 никогда наверное вот и плюс к этому вы получаете дополнительную головную боль по саппорту этой кластерной файловой системы например там если вы знаете только кубер нить из вам еще нужно знать будет и процесс очень много потому что это очень сложная система там с очень многим большим своим багажом проблем и нужно наращивать свою экспертизу будет и это работает ровно до тех пор пока размер база небольшой пока вам не нужно терять там гигабайты данных и десятки гигабайт данных между между нодами пока нет требований к производительности клей tense потому что это очень важно и из лилий tense увеличивается там до десятков и не дай бог сотен миллисекунд это уже как бы не рабочее решение совершенно не рабочие ну и конечно если вам не страшно потерять данные то есть купер нить из он развивается в нем находят какие-то баги движки которые позволяют делать shared storage для кубер начаться они тоже развиваются тоже находят баги и в какой-то момент можно просто напороться на бак там когда данные можно просто потерять либо заняться их восстановлением и вот весь вот этот скоб он подводит нас к тому что хорошим местом для использования кубер на часы и докера для баз данных и to stay дженги это девелоперские тачки и от всякие такие вещи либо какие-то приложения на начальном этапе где там происходит такая проверка гипотезы летит не залетит там можно использовать но для холода на мой взгляд кубер нить из и шаре дна и хранилищ они не очень хороши вот но если сильно очень хочется то оптимальным вариантом будет использовать локальное хранилище без использования шаре данных там файловых систем использовать нативную потоковую репликацию когда у нас через потоковый репликации идет синхронизация данных ну и конечно использовать после вскоре операторы которые предоставляют нам такую оля кнопку нажал и она там заработала вот и на данный момент есть 2 оператора это zalando и crunchy они отличаются по функциям по набору фич но тем не менее они как бы уже предоставляют функционал который можно использовать и конечно же стоит помнить что это все динамично развивается посмотрите на количество echoes of полу request of появляются новые фичи и нужно тут без фанатизма выбирать и на этом я уже заканчиваю быстро так прям пришло что в итоге когда вы занимайтесь планированием и мантии и мониторингом не жмитесь на ssd-диски они уже относительно дешевая но они по крайней мере отложат вам проблемы с производительностью на год а то и больше старайтесь не писать в базу все подряд то есть вот эти вот практики и с джейсоном с 8 мегабайт им это плохо так делать нельзя и мониторинг если вы делаете мониторинг не оставляйте его в дефолт на настроенном состоянии мониторьте под gris и даже когда мы приходим клиенту смотрим на мониторинг многих вещей просто не хватает старайтесь не писать и не читать данные из одного места то есть postgres очень хорошо масштабируется есть очень много вариантов его масштабирования выбирайте на любой вкус разносите нагрузку ну и конечно же избегайте ничего не делающих транзакций они снижают производительность и очень медленно и верно убивают базу если вы что-то и делаете что могло понадобиться уже другим людям посмотрите вокруг возможно то что нужно уже изобретено это напрямую касается очередей не изобретайте самописная очереди используйте pq и последний пункт это автоматизация и контейнеры если приспичило-то локальные волю мы потоковая репликация и операторы то есть с этим можно хоть как-то работать но без фанатизма потому что все очень быстро меняется и на этом пожалуй все спасибо за внимание алексей пасиб большое в этот твой сувениры и почетная грамота друзья вопросы утверждения предложения свои переживания свои были переживания не указанные файлы да перед эти вот мужчине микрофон просто да и про просьба подносите микрофон поближе потому что тут я слышал есть еще просто не слышно добрый день спасибо за доклад у меня небольшой вопрос мы но в докладе говорили что бывает таблицы которые сами по себе разбухает начинает но позже сама логирование то есть там допустим мы удаляем все записи а там у нас таблиц все равно 60 гигабайт весить до как по сгрыз но вот с этим справляется чтобы обратно все память вернуть в пол здесь есть механизмов то вакуума да то есть появляется устаревшей версии строк которые не нужны в должен прийти вакуум почистите эти версию строк ну то есть он освобождает место для новых строк и на самом деле нужно потяните вакуум чтобы он срабатывал как можно чаще и как можно быстрее таким образом таблица которая в ней появляется устаревшей версии сток когда появился какой то небольшой процент устаревших версий строк то уже стриги рилз a vacuum пришел почистил освободил место под новой версии строк если же мы столкнулись ситуацию как описано выше мы удалили большой объем строк и у нас осталось места то нужно использовать утилиты pg репак и compact tail они как раз позволяют за несколько циклов вакуума обработать таблицу таким образом чтобы строчки утащить в начало таблицы в начало физического файла который на диске хранится и потом освободившийся пустой хвост отрезать и тогда свободное место она появится но будет видно в операционной системе то есть правильная понимает что позволит автоматически сам защищают эти пустоты защищает автоматически если у вас обновляемая но часто обновляем и или часто данные из таблицы удаляются ну то есть вот та же самая таблицы очередей часто вставляем часто удаляем часто обновляем если таблица от как логе то нужен по гарри пока это уже отдельная ручная операция нужна самому запускать самому следить мать самому мониторить спасет слева всей спасибо за доклад вопрос такое но вот понятно стадо там отучили от длинных транзакций но они все равно не любит отдавать подключение к базе данных они держат присасываются их там сотни тысяч и на 10 разработчиков bouncer работает в режиме транзак фонда отваливаются prepared statements начинается боль и вой и вот как с этим жить хорошо вопрос хорошо вопрос не надо будет подарок потом кому говорить я наверное у его дома у меня нет ответа с ходу я думаю вам надо подойти на стойку вот я задам дополнительные вопросы и мы посмотрим как это решать вот но если у вас там десятки тысяч и bouncer не используется в надо посмотреть на то как работает bouncer нет ли у него затыков по производительности потому что bouncer однопоточный нету затыков вот то есть нужно еще дальше покупать еще у меня будут наводящего простая вы их задал спасибо друзья но договоритесь с на стенде пожалуйста есть вопрос по поводу of the vacuum и вы сказали что нужно делать четко и громко вариант росла шло воду арта вакууму вы сказали что нужно делать его максимально злым то есть он максимально быстро отрабатывал охота типа крутится в настройках но насколько я понимаю если делать его максимально злым то он будет площадь таблицу на время своей работы если мы не имеем дело с большой таблицей то мы получим посадку на время работы вакуума ну там когда мы делаем агрессивный вакуум то есть по молчанию не порок сработки 20 процентов мертвых строк от общего числа а если мы делаем один процент он срабатывает один процент и она отрабатывает довольно быстро даже на больших таблицах на на моей практике такие проблемы они не особо заметны и любой настройки он начинает чистить таблицу когда там образно один процент буферов заполнить 8 6 то сразу же как только появляются какие то ну практически сразу за хорошо спасибо спасибо здравствуйте и спасибо за доклад такой вопрос поводу сплит brain а вот предположим что он произошел произошли несколько записей в один мастер в другой потом сети восстановилась сосна появились конфликт этот вопрос какими способами вы их ловить руками разработчиков только вручную разработчик он делает снимки конфликтных там таблиц и с точки зрения бизнеса какие данные должны и уже он занимается что вот в этой таблице данные вот эти вот как бы неправильная вот в этой правильной то есть некие автоматически триггеры вы для этого не навешивайте да то есть только все так вот dark ой спасибо здравствуйте и спасибо за доклад а подскажите пожалуйста есть проблема взгляд почему-то в большом экране нам запросе с выборкой там из нескольких десятых таблиц в одном месте перестал использовать яндекс начал фигачить sequins скан при этом выборка где-то составляет там 35 процентов данных то есть нет смысла все крыска не вот по таким ситуациям вообще какие могут быть рекомендации вот куда смотреть с чего начинать анализ планировщик после со работает на основе встроенной статистике это табличка пиджи статистик то есть там когда у вакуума есть отдельный суп процесс она лайс вот она лайс он сканирует таблицу берет там сэмпл данных 30 тысяч строк по моему и по ней строит эту статистику и статистика она является представлением и количественными и качественными характеристиками того какие данные лежат в столбце так вот проблемой того что используется кривой план может быть поехавшая статистика возможно нужно по таблице сделать она лайс вот команда в по здесь есть она лайс вот потом возможно нужно подкрутить параметр собираемой статистике дефолт статистик star гид по умолчанию он равен 100 и он как раз таки отвечает за размер сэмпла который берет она лайс для подсчета статистики то есть нужно возможно увеличить вот этот дефолт статистик таргет чтобы сэмплы брался больше чтобы планировщик мог собрать точнее вакуум мог собрать больше статистики и построить более точную статистику вот возможно нужно подкрутить вот параметр сбора статистики вот но может быть какой-нибудь благ бак планировщика вот есть например такой хак как при сортировке нужно сделать там имя поля и сделать имя поля плюс 0 то есть по факту как бы это никак не повлияет на качество запроса на то какие данные он будет отдавать но это немножко правит мозги планировщику под gresso это короче такой известный баг то есть можно много про него в google и почитать то есть вариантов очень много когда выбирается неверный план вариантов много то есть сделать она лайс поправить статистику либо уже там погуглить либо можно кастами поиграться в по здесь есть касты которые влияют на оценочно оценки для выполнения операций допустим всех скан там операций asics она может занимать столько то там ведь можно поиграться с костями то есть вариантов много можно подойти также на стенд можно тоже обсудить эти вариант у нас там еще коллег больше которые в этом разбираются больше чем я можно еще у них поспрашивать спасибо спасибо и последний алексей приветствуем спасибо вам за ваш вот все работа которую вы делаете смотрел множество ваших докладах есть 1 комментарий и видимо вот он подтвердился в вопросами страну что вы не упомянули москве в practice это агрессивный of the vacuum агрессивная сборка статистике все то что спрашивали это все про это агрессивная сборка имеет свои минусы но ну скажем хотя бы какой-то тюнинг он необходим а второе вот вы говорите про велосипеда строение не кажется ли вам о olap в подгрести велосипедисты велосипедом в принципе и по сути факт того что под гнет в текущий момент не готов в каком-то более менее серии я узнала лапу находит ли это подтверждение в вашей практике до в полисе довольно сложно слабом потому что можно даже посмотреть на форте позы риссов которые возникают там сайту с green plant как бы для аналитики отдельные форки есть вот но в то же время как бы пузыри 100 развивается там появляется декларативное позиционирование фарин таблице можно разносить шарди данные вот но увы под глисону ну может быть рекомендовать или использовать подходящие база данных просто не надо нужно просто возможно пересмотреть использование под грифом может быть подойдет какой то другой продукт если объем ебаных данных большие да и вы постоянно пишите это пример там собирайте данные с нефтяных вышек там раз в секунду со ста тысяч выжег там то наверное подает конечно больше клик house например они пузырь то есть отталкиваться от задач спасибо за внимание алексей почти большая кому книжку отдадим за вопрос был хороший вопрос он был второй по счету вот молодой человек сидит раз-два-три-четыре до поднял руку и то он вот у него был прекрасный вопрос на который я не нашел ответа и прошу подойти настоек но вот прекрасно прекрасно алексей аплодисменты ещё разок друзья спасибо большая"
}