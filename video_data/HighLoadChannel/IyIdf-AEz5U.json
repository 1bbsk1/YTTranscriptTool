{
  "video_id": "IyIdf-AEz5U",
  "channel": "HighLoadChannel",
  "title": "Масштабирование реплик PostgreSQL под нагрузкой / Андрей Бородин,  Владимир Лесков (Яндекс)",
  "views": 1293,
  "duration": 2307,
  "published": "2019-05-15T04:27:43-07:00",
  "text": "меня зовут андрей бородин и сама еще есть выступать володя лесков мой разработчики из яндекса довольно длинным названием ну этот доклад про масштабирование реплик под газ и конечно очень любим по сгрыз кроме того это доклад про масштабирование под нагрузкой и в облаке потому что мы из яндекс облака ну и вообще говоря это доклад про технологии резервного копирования которые используются в облачном по сгрызть а если по простому то наш доклад называется так и разгоняем backup вообще у нас это 4 серия в довольно длинный в довольно длинном сериале из предыдущих докладов вы мою если вам интересно вы можете посмотреть и предыдущей серии в которых вы добавляем все более и более интересные и сложные технологии ну давайте начнем с облачной технологии которая называется high в кластер подвеса это означает что у нас есть множество копий множество ей при базы данных которые растянуты между некоторыми дата центрами какая-то из них является мастером в каток служащего и обслуживает пишущую нагрузку какие-то являются репликами released in buy серверами и принимают репликацию кроме того для обеспечения безопасности данных необходимо время от времени снимать резервной копии и архивировать журнал изменений называемый райт их и блок в архив ну и для того чтобы топология было проще хотелось бы чтобы сервер резервного копирования был один в него отправляйся резервной копии и в нем в него же щурился журнал но поскольку мы в облаке нам хотелось бы чтобы это все было облачная технология и наши данное шерсти хранились в истре совместимом облачном индекс о бок облик стрэнджа типичные сценарии использования технологий зеленого копирование вы и выгляди так что вам нужно восстановить ваш кластер на определенную точку во времени вы создаете новый кластер указываете ему параметры на какую точку времени вы хотите получить ваши данные на нем восстанавливается резервная копия и докатывается до целевой точке во времени это тот сценарий который мы сегодня не рассматриваем он был хорошо рассмотрен в предыдущих сериях нас интересует сегодня два сценария это во-первых и добавления нового узла из-за того что ваш кластер не может обрабатывать нагрузку он перегружен вы хотите добавлю добавить читающую реплику либо перри наливка метеора этому что это такое мы обсудим чуть подробнее ну добавлению в нового узла означает что вам нужно выделить где-то хост который который будет новая репликой по возможности вы не хотите нагружать мастер потому что он уже загружен ваша база данных и так уже работает на максимальных возможностях поэтому взаимодействия с мастером должно быть минимальным вы должны до максимальной точке времени догнаться из архива и только после этого подключиться к мастеру начав использовать использовать его пропускную способность сети метеор это значительно более редкая ситуация когда у вас произошло падение мастера например network парке shining пропала связь с мастером вы промолчите одну из реплик назначаете новым мастером а при этом старый мастер мог выполнять какие-то запланированные действия и уйти в своей истории немного вперед история в базе данных в подписи измеряется в так называемых и лосинах это байты журнала опережающий записи с момента начала работы кластера у вас есть новый мастер который создал новый timeline истории а старый мастер убежал немножко вперед и после этого его называют метеором вообще у вас есть технология rewind который позволяет выгнуть мастер в строй сейчас есть интересный патч который сделает количество метеоров значительно меньше тем не менее в кайф или был кластерах высоко доступных кластеров метеоры это просто факт они случаются и их проще всего просто переносить из бекапа что мы ожидаем от облачной системы резервного копирования в первых мы хотим конечно же чтобы наши данные были сжаты этого почему-то нету в хорошей версии из коробки мы хотим использовать максимальное количество ресурсов но управляема то есть мы хотим параллелизм и тротлинг ресурсов тропинках диска так и сетевой сетевого интерфейса мы хотим шифрование потому что мы в облаке хранятся вообще говоря не только наши данные данные наших пользователей которые не должны храниться в открытом виде нигде ну и хотелось бы графика цию и управление backup ами в части чистоты чистоты снятия резервных копий у нас есть некоторый трейдов мы можем снимать часто резервной копии этим занимая место в нашем хранилище и потребляя ресурсы наших реплик из которых мы снимаем резервной копии но при этом мы можем восстановиться быстро на любую требую на нам . во времени либо мы можем делать бэкап редко но тогда восстановление новые верной копий занимает время и потому что накат журнал опережающий записи последовательный и там проблема большинстве случаев вы используете когда вы создаете свой кластер вы используете какие-то стандартные и очень распространенное решение типа например kaji borman который поддерживается компанией квадрант либо пиджи бы крест который поддерживается кранчер да это и у таких такие решения подразумевают что у вас есть сервер резервного копирования куда вы складываете ваши резервной копии и архив такого подхода есть главный плюс он распространен если у вас возникает вопрос вам достаточно ввести его в поисковик и вы скорее всего попадете на страницу stack overflow де очень подробно будет разобран именно ваш случай вам достаточно развернуть один сервер резервного копирования и вы уже смогли защитить все ваши базы данных из минусов ну самым главным минусом в облаке является то что определенный момент вы не можете обойтись одним сервером резервного копирования их становится все больше и больше и больше вам нужно балансировать нагрузку их нужно точно также мониторить они потребляют ресурсы ваших дежурных администраторов в случае отказа сервера резервного копирования вы не можете легко сказать какие из баз данных сейчас находится в опасности и как произвести быстрое восстановление уровня гарантий от системы резервного копирования для того чтобы решить все эти проблемы мы используем система резервного копирования которая называется вал g вол'джин описан нога в 2017 году прототип создавался компании ситу state об катили и дэниэлом фарина сейчас его поддерживаем и развиваем мы яндекс и главное философия и идеология вал g изображено на этом слайде во лжи должен быть простым как балалайка но мы не нашли вы все балалайке нашли укулеле укулеле четыре струны поэтому во лжи 4 команды две команды которые отвечают за архивирование журнал опережающий записи и две команды которые отвечают за снятие резервных копий соответствовал пушу алфи отправляет или принимают один сегмент и вала бы копушей backup вещь снимаю эту резервную копию отправляют в облако либо забирает из облака и разворачивает резервную копию конечно команд существенно больше потому что есть множество других тасс задач по управлению пикапами по их в верификации и просто снять и резервной копий довольно сложный процесс но в первую очередь нас интересует производительность именно вот этих четырех команд одной из из необычных фич вал g является возможность снятия дельта копии иногда их называют инкрементальные бы kappa me иногда их называют дельта бы kappa me они есть в том или ином виде во множестве инструментов но мы сочетаем все возможные фичи которые есть для такой в дельте копиях это во-первых дельта копии на основе времени изменения файла файловой системе эта технология например есть в пиджи бы крест кроме того у нас есть то что мы называем lnb из дельты это означает что при снятии дельта копии мы делаем резервную копию не только тех файлов которые отмечены как измененные но из них забираем только те страницы которые были изменены между началом одно между началом предыдущие резервной копии и началом текущие резервной копии это позволяет существенно сократить утилизацию сети утилизацию других ресурсов существенно сократить размер дельта копии сами дельта копии позволяют существенно быстрее вернуть кластер к текущему моменту во времени потому что дельтой копии накатить значительно быстрее чем проиграть журнал опережающего записи например за сутки api дельта копий очень простое мы просто указываем количество дельта копий которые мы считаем разумными максимальное количество и указываем опционально указываем от какой резервный копий мы хотим получить дельту это все что нужно сконфигурировать чтобы во лжи начал делать в большинстве случаев именно дельта копии при разворачивании вам ничего не нужно указывать вы просто говорите что вы хотите получить backup например последний или какой-то определенный его уже разберется какие дельты копии ему нужно использовать для того чтобы восстановить данную резервную копию формате дельты копии мы используем мы используем дельты копии только для дейта файлов которые организованы как страничные файлы кроме того которые содержат правильные lsn и в каждом заголовки каждой странице это означает что мы не можем великим об и free space мэтт использует бэкапить как дельта копии но для дейта файлов самых тяжелых файлов резервной копии мы используем именно дельта ярость и мы учитывая весь data file мы ищем те страницы которые изменились между пикапами записываем номера блоков изменившихся страниц после чего записываем все изменившиеся страницы главная идея которая была заложена в lg еще даниилом это параллелизм всего что можно заправить мы выяснили что за погреть можно все например то что было в прототипе при восстановлении резервной копии во лжи хватает сразу несколько архивов в облик старриджа и начинает их разворачивать одновременно таким образом он уже существенно быстрее чем например какой нибудь без backup который будет создавать резервную копию в один поток ну на этом мы конечно не остановились к нам пришел алексей кукушки я сказал давайте будем еще и взял эту копию создавать поверели на поэтому теперь у нас есть один конвейер на отправку в сеть и один канве на чтение с дисков таким образом вы можете гарантированно упереться в какой-то из ресурсов либо вы утилизируйте в полку сеть либо утилизируйте в полку диски ну но это случае есть тропинка вы можете сказать сколько байтов в секунду вы считаете разумной нагрузкой и волны будет забирать только столько байтов но это еще не все у нас есть параллелизм восстановление из архива как известно под gres выполняя restore команд запрашивает из архива вал файлы последовательно ну потому что это линейная история изменения базы данных стерилизованной история изменения базы данных но во лжи понимает что если мы считали вал файл xtu скоро нам формируется файл x + 1 x + 2x + 3 и старается запустить максимально выровненную нагрузку так чтобы следующие файлы когда их возраст попросит уже были на файловая система и достаточно было их только положить в то место где под раз хочет их видеть ну и это не все к нам снова пришел алексей кстати алексей алексей видимо не пришел на доклад ну ну в общем он где-то здесь когда мы когда позже спросит нас заархивировать один вал файл он тоже делает это последовательно он выполняет archive команд который получает ровно один файл но во лжи видит что рядом лежат еще файлы которые уже готовы он считывает формат archive статус и видит что файла готовы к архивации и уносит их заранее с тем чтобы когда подрос попросит не делать лишние работы таким образом последовательный интерфейс под газ а преобразован в последовательный интерфейс последовательные алгоритм архивирования во лжи и графики с внедрения lodgy тут видно на графике что у нас есть в предыдущей версии вал и это тоже самое только написано на питоне очень неравномерная нагрузка по сыпью на на базе присутствует какая то нагрузка ночью но при этом вал и вызывал всплески пасе пью мы от этого избавились у нас во лжи все время снятие резервной копии занимает стопроцентная утилизация диска на этих графиках когда они создавались еще не было троттлинга то есть поэтому диск загружен на столько на сколько позволяет контроллер ну и сама сама блочное устройство сейчас они были бы вдвое ниже потому что мы ровно пол с половину полосы пропускания выделяем все эти используются не полностью но тоже достаточно эффективно используется сеть изменение нагрузки насыпью практически несущественным по сравнению с фоновой нагрузкой на базе какие-то запросы на базе выполнялись ночью если мы же мы снимаем дельта backup давайте дельта backup рассмотрим поближе у нас видно один большой синий зуб который короче чем синий зуб у полного бекапа потому что нам не нужно учитывать все файлы нам нужно читать только изменившиеся файлы но в изменившихся файлах нам нужно прописать каждую страничку для того чтобы найти ее lsm сравнить с его сыном предыдущего бэкапы и понять нужна ли она в дельте копии и вот этот вот вот это чтение с дисковой системы это основная нагрузка единственной огрузка который дельта backup создает на сервере и этой нагрузкой как раз занимался володя который сейчас продолжит этот рассказ так всем привет я сейчас расскажу вам про нашу технологию вал дельта это та технология с помощью которой мы собственно спилили этот зубы нагрузки на диск о котором говорил андрей что такое по сути вал дельты вал дельты это такой способ извлечения изменившихся номеров изменившихся страничек из лога опережающий записи то есть под бесовского райт каталога который позволяет нам теперь не читаете каждый постраничный изменившейся файл а читать в не в каждом таком файле только изменившиеся страничке собственно как то происходит у нас есть мастер на котором у нас пишется райта hotlog из него мы извлекаем журнал райт hotlog в виде сегментов вала из которых мы извлекаем изменившиеся номера изменившихся страничек в базе баски они попадают в дельта файлы которые мы потом преобразуем в карты изменений для каждого по страничного файлом устроим а в точности одну карту изменений в которой мы содержим все изменившись страничке ну а после этого эти карты изменений мы используем на бы капищах накопившимся христе для того чтобы сделать бэкап к сожалению сделать вал дельты оказалось не так же просто и сейчас я подробнее расскажу как мы их сделали с какими трудностями мы встретились при их реализации первая трудность которую мы встретили это было парсинг right ahead logo это очень сложная структура и сейчас 1 1 несколько сайтов я поясню вам как она выглядит на самом деле как андрей уже упоминал в во лжи все сделано параллельно и загрузка файлов в архив top сделано параллельно поэтому и парсить эти вал файлы мы тоже будем параллельно поэтому у нас 4 джеки чан собственно как мы пара символ давайте сначала рассмотрим немножко как он выглядит на этом слайде самое главное это то что red hat лог как вы наверное уже знаете разбит на сегменты по 16 мегабайт каждый это так называемые вал файлы которые там хранятся в папке побывал а каждый вал файл в свою очередь состоит из страничек по 8 килобайт который идут в точности друг за другом каждый у каждой страничке есть там какие-то заголовки что более важно каждая страничка содержит после заголовка часть right i had logo но тут все немножко сложно сам rate и hotlog по сути состоит логический из записей так называемых их слог рекордов и все эти их слог рекорды они идут просто подряд собственно это и есть история того как у нас живет там база но то как райт и hotlog идет подряд как там идет это история вообще никак не связана и никак не выровнять не выровнена относительно страниц из которых состоит состоят вал файлы вследствие чего у нас может получаться всякие интересные спецэффекты вроде того что страницы там режут пополам у этих слуг рекорды или 1x log record там может быть целиком в страницы или целиком в пяти страницах то есть все это достаточно сложно а собственно все эти эколог рекорды сами по себе они тоже образуют из себя образуют некоторую структуру которая состоит из кедра самой записи и состоит из блоков данных для каждого из которых у нас тоже есть хедер по-моему там пять видов или что-то около того я надеюсь что послушав про структуру и про то как там все взаимно связаны right i had лаги вы поняли откуда здесь джеки чан но из хороших новостей мы реализовали библиотеку для постинга vol 1 поскольку мы пишем на год она называется вал parser и лежит во лжи так что если вам вдруг она понадобится то вы можете заходить использовать ее мы будем рады теперь давайте много по грим о том что мешает нам парсить вал параллельно если возвращаться к тому что записи эколог я когда содержится не целиком страницах это в частности означает что каждая запись содержится не целиком кажется запись может содержаться не целиком сегменте то есть у нас может быть запись которая лежит и в первом сегменте и во втором сегменте или допустим записью которой ну так же конец лежит на во второй сегменте я начала в третьем то каждый сегмент может содержать до двух кусочков записей это кусочек из прошлого и кусочек из будущего и самостоятельно этот сегмент нам практически бесполезен но эти кусочки в сегменте нам практически бесполезны потому что мы не знаем что с ними делать как из них достать информацию для того чтобы решить эту проблему мы используем дельта портал файлы это такие файлы в которые мы собираем эти кусочки из каждого сегмента его начало и конец после этого когда нас настает время собрать целиком дельта файл мы берем дельта пошел файл все кусочки склеиваем по 2 и все склеенные кусочки записываем но уже парсим достаем из них изменившиеся странице баски и помещаем в дельта файлы теперь я думаю вы понимаете почему то 4 джеки чана следующие проблем с которым мы встретились это непосредственно передача дельта файлов nabucco ищу ногу ну то есть как вот нас есть дельта файлы у нас есть быка обещая нога и нам нужно как-то раз так и совместить их как мы делаем для того чтобы делать это мы пользуемся командой во лжи под названием волп уж если раньше она просто брала вал файлы и помещала хранить в хранилище возможна такая чего какие-то вал файлы перед тем как ей сказали это сделать то сейчас мы также парсим эти вал файлы и всю информацию которую мы из них получая мы помещаем в дельта файлы которые пытался мест на с вал файлами также помещаем в хранилище пока выполняется вал push собственно что происходит дальше вот я рассказал вам первый шаг о том что вал файлы вместе с дельта файлами перемещаются с мастера в хранилище привел push и дальше когда настает момент когда мы захотим за выкатиться сне брики мы просто by забираем из хранилища нужные нам дельта файлы поскольку каждый дельта файла представляет из себя некоторый отрезок сегментов вала то у нас может быть какое-то количество дельта файлов это количество сегментов валак которые не попали не в один день то файл в конце но это пока что потом они конечно же соберутся в следующий дельта файл но сейчас для того чтобы нам не потерять изменившиеся странички из них мы также докачиваем и их на быка пищу си реплику после этого строим карту изменений и делаем backup сейчас немного будем о том зачем нам все это было нужно вот так вот у нас сейчас выглядят графики загрузки загрузки процессора при бэкапе если при вас n bass дельтах у нас видно что backup длился примерно 220 там 210 что-то около того то сейчас у нас загрузка процессора она осталась такой же но она у нас просто выстреливает за буквально минут минут и 20 может 25 примерно тоже самое можно понаблюдать на графики загрузки сети но самая интересная как раз таки эта график загрузки диска по которому мы можем понять что мы достигли цели с реализацией вал дельт и спилили этот огромный огромный зуб который сейчас нас грузил база во время backup а сейчас у нас вот такая вот маленькая маленькая штучка в общем то сейчас получается что у нас есть трудов между процессором и и сетью но он уже решается непосредственно методами сжатия которых возможно мы вам тоже когда-нибудь расскажем бани в этой серии и немного про то как использовать эти вал дельта бэкапы как вы можете их потестировать и как вы можете сами убедиться в их эффективности вы просто берете скачайте новую версию воды из репозитория и прописываете настройку вал джею звал дельта равно true а сейчас андрей немного расскажет про еще одно использование вал дельта файлов спасибо да кроме использования вал дельта файлов во время зимнего копирования им нашлось еще и применение во время на кота журнала при накате при восстановлении резервной копии примерно треть времени у нас возникает занимает в время восстановления бы из бекапа треть времени в восстановлении например 4 дельта бэкапов и еще треть времени реплей истории за несколько часов которую все равно при нужно проиграть последовательно но тут базе тоже можно помочь пару месяцев на четыре месяца назад на конференции пиджак он компания joined представила расширение которое называется пиджи при полтора тоже кстати написанного это расширение которое тоже парсит вал правда немного другими способами пока что они не используют наш poster но только пока они считывают тоже изменившиеся страницы и пытаются параллельно прогреть кэш файловой системы пичкаешь для того чтобы когда однопоточный реплей вала столкнется с со страницей он не поднималась жесткого диска а достал из из кэша это позволяет утилизировать контроля блочного устройства более эффективно загрузив его параллельно множеством запросов когда вы используете его лджи вал prefetch он считывает из объектного хранилища дельта файлы и точно так же как и пели джипы ифолдер подготавливает кэш вашей базы для того чтобы быстрее проигрывать вал теперь о том что пища представляет в элджи у нас но мы используем во лжи в яндекс облаке если вы создаете у нас кластер вы уже делаете резервной копии при помощи вал g кроме того у нас есть внутренние инсталляция индекс облака про которую сегодня скажет владимир бородин буквально на следующем докладе завтра завтра скажет владимир бородин там у вас какие-то тысячи кластеров какие-то сотни терабайт данных ну в первую очередь хотелось бы поговорить еще про будущее во лжи конечно мы развиваем но технологии которые мы используем они становятся уже довольно далеко от существующего инструментов коробки gps backup конечно мы очень хотели бы наши технологии портировать но их пока слишком много но думаю что со временем мы займемся и передачи их в up stream для того по их придется переписать на сим ну а на данный момент в нашем коде порядка 70 тут душик приходите к нам за пол и квестами мы все обязательно рассмотрим и скорее всего все покажем но на этом спасибо что прослушали ждем ваших вопросов и мост и возьмите просто микрофон добрый день и спасибо за доклад у меня несколько вопросов но я понимаю что индекс что все это хорошо но сам первый вопрос насколько это все стабильно потому что как как все понимают вал там это очень такая непростая штука там все что можно можно продолжать ну вы можете открыть вкладку ишиас убедиться что во-первых они есть люди пользуются и у людей возникают проблемы мы стараемся помочь опять же предоставить какие-то гарантией сказать что звоните мне ночью я не могу да в системах резервного копирования встречаются баги в системах high availability встречаются баги и в возрасте встречаются баги на их чиним вот выберите люди пользуются которые потому как они там крупная компания там new за это не юзает не узнавали о кроме индекса zalando например вот у них был доклад насколько я знаю ни говорили что они использовали вал джетом для чего-то сколько я знаю секунды это собственно авторы первых версий используют во лжи ну спасибо и последний вопрос по поводу того что вы ставили себе цель и чтобы там была шифрование что чтобы там было сжатии сейчас я такой у него там этого не опущу нет конечно есть поступает уже мы рассказывали предыдущей версии у нас есть много интересных экспериментов с сжатием у нас мы экспериментировали с за 400 сброд ли std но эта тема для доклада еще на 40 минут и самое главное там еще нету под точки то есть вот алексей кукушкин топит за братли а вот мы хотим std но нам нужно вот именно решить что будет лучшим для прогресса поэтому такой доклад пока мы еще не делаем шифрование обязательно есть этот же пиджи шифрование мы рассматриваем может подключение lip sodium сколько я знаю кто-то уже делает pull request на эту тему вот спасибо скажете вот эти вот все новые возможности во лжи такие как вал дельты и также многих реальный bacopa блочный бэкап это все можно использовать с опытным инструмент гриссом или же что-то часть вот после с professional потому что вот на предыдущему где-то час назад был еще доклад про разные способы бака попадались мне кажется там комментатор упомянул что вот что-то работает только в postgres профессор но не будет работать в мэйнстримом смотрите во первых где можно использовать вол'джин наши интеграционное тестирование конечно проходит на ванили мы не проверяем на фотках но скорее всего они используют то же самое снять и резервных копий специфичных api-функций есть технологии петра i кв по сгрыз про enterprise это хорошая технология но мы стремимся к ванили и мы мы поддерживаем их разработку стараемся каменки участвовать в обсуждение в печерский hackers но на данный момент вы не ли этого нету поэтому мы это не поддерживаем если вы зайдёте на гитхабе увидите что у нас есть ветка с экспериментальной поддержки петрика в ней не гоняются интеграционные тесты и мы не катаем ее на наш testing поэтому сложно сказать работает она ну то есть тогда когда мы сделали экспериментальную ветку она работала это классная технология когда к она будет в об стриме мы сразу же сделаем поддержку но сейчас у нас есть замена которое нашего вал дельты вот и в принципе трек работал бы сложно сейчас сказать чтобы работало лучше спасибо за вопрос ту спасибо за доклад я здесь ветку до слайда вложить их можно скорее пожалуйста как это сделать ну как-нибудь хорошо я выложу ссылку в чат ференци сейчас как только году за компьютер включен тогда вопрос такой может упустил дельты чего требует то есть например баловала кохинхин что нужно включить чтобы доработать чтобы дельты работали но каком я уже упомянул во первых все все разработки трое делается во лжи они прежде всего работают на ванильном полюсе ответ никаких модификаций делать а чтобы включить дельты нужно просто скачать новую версию вопрос не проеби вопрос прости что нужно сделать с базой чтобы это было безопасно когда вы используете онлайн бы технология online backup а то есть используйте функции перестают backup restore backup тогда же можно использовать вал дельты смотрите если вы использую выполнить функцию пиджи стоит backup если ваша база данных не находится в состоянии в котором можно начать online backup она сделает и report и все правильно но только перестал без бэка берет все данные если нужно взять дельта вы должны понять какие странички мы хотим забрать если у нас hand band и менялись по умолчанию волокон стрелок волохин спутаю все время а у нас выключен в подписи волны попадает информация о том какие странички изменились вот hand in the менахем бен ты в какие страничках меняюсь вот это да а ответ если можно я попробую ответить на самом деле у тебя пейджем и избытка придет забрать страничку на какое-то состояние на самом деле у тебя запись но изменения him это в этой страничке может произойти уже после того как придет бы из баков в этом смысле гарантий can системности у тебя точно такие же как у быть backup а то есть эти изменения hand битов у тебя не применится ну смысле ты их не получишь и при очередном чтение когда-то базу из бэкапа развернешь они у тебя обновятся и будут записаны если мы сравним a production backup а может немножко отличаться у скорее всего вы будете использовать сербию вы будете использовать контрольную сумму страниц которые встроена заставят вас включить логирование hand of вот там вопрос давай день спасибо за доклад на сколько я поняла последнее что вы сказали это что для того чтобы выпустить этого постоим вы хотите переписать уноси если да то почему за день не расслышал а отлично сразу на сколько я поняла последнее что вы сказали что для того чтобы выпустить это вам steam придется переписать носи это повода для того чтобы получить аналогичные технологии в программе пиджи bass backup которая находится в коробке с каждым релизом подвеса придется написать все то же самое на языке по сгрыз а то есть носи 89 спасибо да здравствует спасибо за доклад а подскажите эта технология применима только для с 3 совместимых облаков либо можно использовать на других площадках и насколько я понимаю streaming репликация там вообще никаким боком не относится до получения в череде спартаком да все так мы используем я начну с конца мы используем эту технологию основном в highway люблю кластере когда за гарантии сохранности последних батллога отвечает синхронная реплика поэтому нам синхронная архивация не нужно но если у вас минималистичный такой дизайна и то вам понадобится borman синхронный бармен синхронно синхронной архивации да так сейчас первый вопрос зубы а с 3 до приходят black приходят и чувствую на гитхабе люди просят свифт где люди бросят и же blocks to reach если bulbule request и мы их обязательно покажем при фиде люди которые обещали но пока не возвращались поставить раз проходили в мае с вопросом проезжу и обещанием сделать и"
}