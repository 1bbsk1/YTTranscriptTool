{
  "video_id": "0o7uNUOS-Ho",
  "channel": "HighLoadChannel",
  "title": "Последние изменения в IO-стеке Linux с точки зрения DBA / Илья Космодемьянский (Data Egret)",
  "views": 4090,
  "duration": 2877,
  "published": "2019-05-15T05:00:25-07:00",
  "text": "меня зовут илья космодемьянский работаю в компании детей играть мы занимаемся консалтингом поддержкой пожгли со и поэтому как бы наш сегодняшний разговор будет протоколы один из краеугольных камней важных для работы с любыми базами данных а именно про особенности устройства операционной системы на которое эта штука работает в нашем случае это linux сейчас не вдаваясь в глубокие холивары я немножко расскажу почему именно linux и мы будем говорить не просто о том как она устроена хотя конечно мы туда будем постоянно заглядывать а еще и говорить в таком как бы жанре новостей то то есть что нового интересного произошло почему сейчас все не так как было пару лет назад итак я прошу прощение что слайды на английском говорить о буду по русски но соответственно как бы в принципе только предлоги астаны останется перевести потому что в нашей нашем деле все обычно очень англии фиксирована потому что изменение происходит настолько быстро что не все успевает попасть в язык во первых почему этот доклад почему он важен с моей точки зрения linux сейчас самая важная самая основная операционная система для вас данных то есть до в энтерпрайзе по-прежнему применяются там solaris и где-то там даже и пи x по-прежнему достаточно большой кусок занимает microsoft что является там отдельной истории потому что это общение unix подобная система там все по другому но там поскольку мы много и все больше используемого под собственных баз данных linux уверенно завоевывает позиции как такая главная операционная система для баз данных почему ввод-вывод почему вообще все это в быстрый ввод вывод это самая критичная вещь для администраторов баз данных до я думаю вопрос вот а потому что ну все знают да все пью можно конечно упереться особенно раньше это было на машинах без большого количества цепью довольно критичная вещь там в память памяти тоже можно много достаточно поставить но вот вот вывод это такая вещь которая способна изгадить все то есть если у вас плохо с дисками если у вас слишком много ввода-вывода то ваша база данных будет стонать и это будет батл на ком проблема начинается в следующем что для того чтобы вас все хорошо заработала вам нужно настроить все не только базу данных да там даже у акул который очень высокоуровневый сам фактически местами представляет собой такую операционную систему вот если вы посмотрите у installation гайд там написано там такие параметры лидера поменять такие параметры поиграть поменять андрейка балкер но он в принципе уже там много чего включает по дефолту в него за шитова на раковых линуксах если мы двигаемся там от энди проездных баз данных типа оракла в сторону там под флюсом мск или то там уже как бы этих изменений надо делать еще больше потому что все эти технологии они опираются на операционную систему на ее механизмы да то есть два который работает с после сам близ mais quel им или с современными коммент на войску елями он в любом случае должен быть таким linux первичном дженнер и крутить разные гайки операционные системы проблема наступает какая проблема наступает в том что когда мы хотим разобраться с настройками ядра нас посылают дружно читать lw н.а. несмотря на то что как бы ресурс совершенно гениальный очень крутой и там много всякой полезной информации он написан разработчиками ядра для разработчиков ядра ну как бы так он устроен что лучше всего умеет писать разработчики ядра естественно ядро они статьи про то как это ядро использовать поэтому как бы вот я и попробую вам это объяснить немножко подробнее и да вот эта вся штука она многократно усложняется тем что последнее время development ну как developing ядра linux пошел быстро так собственно говоря и переработка elastico пошла быстро потому что это было долгое время такая штука которая где-то там сзади отставала значит сначала мы поговорим на примере пожгли со поскольку все мы любим под глэсс поток как вообще база данных взаимодействует с вводом-выводом не знаю кто работает с мы см и сиквелом к кто работает с под гриссом это хорошо а 40 вам отлично значит я тогда буду рассказывая о подгрести немножко деталей добавлять о том как с этим делом работают другие базы данных мы немножко вот этому делу пройдемся потом рассмотрим linux новую стык ввода-вывода и потом поговорим о то что мы что же нового что же хорошего значит смотрите typical дейта bass в данной ситуации можно легко догадаться что мы говорим о postgres quelle потому что буфере зова ный ввод-вывод она имеет следующую вещь и она имеет жареную память которым мы jets а в юзер space с точки зрения операционной системы и имеет фактически то же самое такой же кусок каша в каше ядра в kernal спейси и соответственно основная задача современные базы данных это странички с диска подымать в память и когда у нас произошел кают изменения помечать или странички как грязные записывать предлог и после этого синхронизировать память чтобы она была консистентной диску в ситуации с подвесом это постоянно путешествует туда сюда из жареной памяти который - упускали сам в пэйдж ядра и далее на диск через весь весь весь linux вой стек с той или иной разницей если вы используете базу данных на файловой системе она у вас будет так работать более менее с любой unix подобные системы и с любой базой данных если вы используете рксм у вас будет немножко другая история вокал сам будет взаимодействовать там с диском но в принципе принцип такой же может быть с директором может быть . шел но задача как можно быстрее про сосать вот эти вот странички через весь стек ввода-вывода каким бы он ни был и вот на этом месте проблемы могут возникнуть практически на каждом этапе пока у нас все readonly у нас проблем нет мы прочитали если нас достаточно памяти весь dataset который нам нужно читать вмещается в оперативную память мы его подняли у нас все в памяти все работает все хорошо то что у нас при этом там в случае пост грессов баффер к шее лежит там то же самое нас не очень волнует проблемы начинаются когда нам это все нужно записать потому что когда нам это нужно записать но он сильно большее количество памяти уже нужно туда сюда гонять и соответственно нам надо настроить там под газ или там mais quel чтобы жареной памяти это все хорошо поехала на диск но там случае преисподню сам нам надо еще хорошо настроить багра умное списывание грязных страниц в линуксе чтобы она дальше ехала на диск это одна сторона проблем с вводом-выводом дату синхронизация вот это вот самого каша вторая сторона с которой тоже часто сталкиваться добра это за ты к записи собственно говоря в рейдах от logo когда у нас настолько мощная нагрузка что даже последовательно записываемый журнал упирается в диск и в этой ситуации тоже его надо как бы записать быстро и фактически она мало чем отличается от ситуации синхронизации каша с тем то стоит такой разницей что там меньше приспособлению для этого да то есть вот подгрести там мы работаем с большим количеством жареных буферов в базе есть механизмы как эффективнее это списывать на диск в этих и дракон и без этого там до предела оптимизированы и вот здесь нас возникает задача что единственное что мы можем в общем то сделать чтобы сам блок писал описался эффективно это только там поменять настройки linux чтобы он эффективнее писал значит основные особенности вот этого бас данного вклада вот сегмент жареной памяти может быть очень большой то есть когда я начинал об этом рассказывать на конференциях там в двенадцатом году я говорил ну сейчас память стала дешевая даже встречаются сервера с тридцатью двумя гигами оперативной памяти ну сейчас это как бы уже сейчас ноутбуки встречаются с таким количеством оперативной памяти и даже больше то есть сейчас всё больше и больше встречается там 128 1056 и туда дальше во первых это действительно много памяти то есть ну даже банальный сэм это будет писать это просто занимает время ресурсы и так далее во вторых технологии которые мы для этого используем они очень консервативны и база данных они старые до их давно разрабатывают они потихоньку эволюционируют и в них механизмы не то что прямо вот по последнему слову техники соответственно когда мы синхронизируем вот эти все крыши у нас возникает очень большой вот вывод и дальше возникает еще одна проблема что мы не можем что-то покрутить посмотреть на эффекта да то есть мы покрутили какие-то параметры в подгрести настроили чекпоинты эффекты не увидели то то есть мы не можем сделать так вот степ бай степ как ученых принято делать там покрутили понаблюдали эффекту дальше покрутили мы вынуждены настраивать сразу весь стек это приносит там свои дополнительные сложности что в случае под gresso генерить большинство его это чекпоинты то есть я не знаю из тех кто работает с под гриссом кто сталкивался с тем что называется check point spikes когда у вас такая пила на графиках периодически со мной ну вот в принципе как бы раньше очень много людей об этом поднимали руки сейчас в принципе есть как бы manila как это чинить стало как-то попроще плюс там еще и ssd стали сильно спасать конечно картину но в принципе как бы у пожгли со редко что-то упирается непосредственно запись вала упирается вот эту синхронизацию когда происходит чекпоинт и вызывается и vsync и происходит как бы на ежа ни одного чекпоинта на другой слишком много ввода-вывода не как бы один чек-поинт ещё не закончился не сделал все свои стенки которые ему нужно и начался другой чекпоинты началось у кузнеца есть еще такая уникальная фишка как of the vacuum до который в принципе как бы такой многолетняя история поставления костылей паттайю архитектуру которая была сделана там честно скажем и в принципе если у вас of the vacuum не справляется вы обычно настраиваете его чтобы он работал агрессивно да то есть у вас был много ваакеров авто вакуума он по чуть-чуть срабатывал часто обрабатывал таблицы быстро и соответственно не мешал остальным вещам потому что иначе у вас будут проблемы с dd элем у вас будут проблемы с блокировками но когда of the vacuum настроен вот так вот агрессивно он у вас начинает как бы жевать его и вот эта вот вся радость она еще например если накладывается с чекпоинтами у вас большую часть времени диски утилизированы но почти сто процентов и это все источник проблем как ни странно бывает такая проблема как кэш refill то она обычно меньше известно надо было ну как будет типичный пример это вот у вас база данных стартовала и какое-то время все очень печально тормозит поэтому даже если у вас огромное количество оперативки нужно хороший диск иметь чтобы стек обеспечивал как прогрев этого каша но на самом деле на перфоманс эта штука имеет довольно серьезный эффект даже не после рестарта базы данных а когда у вас например прошел чекпоинт большое количество страниц было запачкана там во всей базе они были сдам блины на диск потому что ну как бы нужны синхронизовать а потом ваши запросы запрашивают новую версию этой самой странички из с диска и у вас борьба за начинает проседать и вы можете на графиках видеть что у вас кэш refill после каждого чекпоинта вносит тоже какой-то там процент в нагрузку и самая неприятная вещь в воде выводе касательно там пожгли сада и и разных других баз данных это так называемый маркера и то есть такая вещь которая там в орг ли это проще несколько и в пост грести может быть проблемой когда у вас worker каждый варки в котором вы обращаетесь запросам начинает генерить свое и о например потому что у него больше не хватает каша для того чтобы про сосать новые страницы с диска то есть у вас все ширины и баферы они все папочками чекпоинта еще не было например такая ситуация и worker для того чтобы выполнить там не знаю простейший select нужно сначала нужно взять откуда-то кэша для этого ему сначала нужно запить это все дела на диск и у вас worker они специализированный процесс чек-поинтов начинает выполнять и в sing чтобы немножко себе освободить место и чтобы она она как бы вот могло быть заполнена чем-то новым тут возникает еще большая проблема что в арках собственно грани специализированная вещь и весь процесс вообще никак не оптимизирован да то есть здесь мы можем что то на уровне там linux где тасс оптимизировать но в общем в подгрести это так чисто аварийная мера как найти слив-перелив навальный да то есть как бы не предназначен для того чтобы что-то там сливать он для другого значит смотрите какую задачу мы решаем когда что-то тюнин как максин они заводь вот этот вот путешествие поток грязных страниц между диском и памятью и задействован диски памяти пью виски dollar с файловой системы и настройки самой базы данных и часто бывает так что этим вещанию не прямо вот касаются диска то есть вы можете видеть какие-то проблемы но типичный случай вы смотрите вот и вещь очень большой потому что например там кто-то ждет диска и все остальные процесса тоже ждут от процесса и начинается как бы нет явной вроде утилизации дисков по записи просто что там заботилась например а как бы проблему все она с вводом-выводом сейчас мы пройдемся по этому стыку и по смотрим что мы с этим можем делать и что нового хорошего в линуксе изобрели чтобы это работало лучше смотрите как исторически сложилось вот в принципе никто не занимался оптимизацией много каких из этих стадий это при перехода с одной стороны с одной стадии на другую там латинский задержек потому что диски долгие годы были страшно медленные то есть не имело смысла заниматься какой-то супер оптимизацией там i've seen к тому подобными вещами потому что у вас вращающийся диск по которому как по грампластинки ездят головки и вот этот вот sick он был настолько длинный что какие-то проблемы не всплывали ну как бы если работаете с базами данных вы знаете да база данных не настроена топ запросов смотреть бесполезно да потому что вы настроите там достаточное количество жареной памяти там того-сего 5 10 вас будет новый топ запросов надо будет заново его настраивать тут та же самая история так по моему otg отключился микроф а снова снова включился микрофон и весь стек там linux в том числе он тоже был из этого расчета сделан смотрите в принципе максимизировать вот этот вот поток страничек через весь стек до определенного этапа было очень просто мы придумали там сделать вспомогательный процесс бага right of подгрести чтоб он разгружал чекпоинты рано там стало чуть более параллельным можно еще надо добавить параллелизма вот а вот история как минимизировать вот эту самую ла-тэна сида чтобы у нас там в итоге это приписывать это такая задача последней мили да то есть нам уже нужны какие-то супер технологии этим супер технологиями стали на самом деле ssd эта вещь которая просто вот попала в этот мир и резко дробного вот этого трассе и на всех а альных этапах стека стала вылезать куча разных проблем которые нужно было теперь решать и это было как бы и со стороны и производителей баз данных и со стороны производителей linux в промежутке мы были вынуждены заниматься каким-то такими странными расставления my подпорок то есть как жить с текущей инфраструктура и linux но уже с новыми дисками и было совершенно не трудно догадаться что когда мы смотрели какие-нибудь perfomance test и от производителя бывают очень много там разных всяких abs of вот базе данных сильно лучше не становилось потому что база данных она в общем не только и не столько про и опция то есть очень часто бывает как мы можем там 50 тысяч iops of в секунду пропустить и в принципе как бы это наверное хорошо но если мы не знаем latency не знаем распределение latent не знаем что а там все равномерно и мы вообще ничего не можем сказать о перфомансе вообще да потому что вот в какой-то момент наша база данных начнет делать чекпоинты в этот момент ровно latency скакнет долгое время это было большой проблемой производили сейчас есть производительности на virtual koch для баз данных потому что virtual ооо ему свойственна вот это вот неравномерность watenshi и это влекло проблема значит смотрите вот это линуксовые стек ввода-вывода мне тут не очень удобно показывать указкой так поэтому я буду в словами говорить у нас есть use space то есть та память которая там менеджер базой данных самой и мы в нашей базе данных как-то настроили так чтоб это все было хорошо в этом можно там отдельный доклад и даже больше делать дальше она все неизбежно там либо через пашкевич либо через интерфейс директа и попадает вот так называемый blog in put out put слой что это такое ну представьте себе вот у нас есть там интерфейс файловой системы через него съезжает вот эти вот наши странички которые у нас были в больших каши изначально как они там были в базе данных то есть такие блоки вот этот блок и о слой он занимается чем ну есть сильная структура блок в ядре описывающая которое берет эти блоки и собирает из них такие виктора массивы request a free квестов на год или на вывод и соответственно вот на вот этом вот bio слое дальше под ним находится так называемый слой и квестов на этом условии соответственно собираются виктора как они туда поедут и долгое время все вот это вот хозяйства два этих слоя в линуксе они были заточены на то чтобы эффективно писать на магнитные диски из уж было совершить такой переход у нас есть блоки которые удобно менеджер базе данных странички и нам нужно эти блоки собрать в такие вот виктора которые удобно записать на диск су желательно там с наименьшим сиком чтобы они где-то рядом лежали и для того чтобы это эффективно работала придумали так называемые элеваторы или scheduler и и о чем они преимущественно занимались они занимались тем что они брали эти вектора и мер geely сортировали и каким-то образом чтобы в блочный драйвер то есть в драйвер сдв драйвер skazi дисков приехали вот эти вот ему там в удобном порядке расположены и блоки которые надо записать a driver свою очередь производил как такую там трансляцию из блоков в своей там сектора и соответственно писал это все на диск и соответственно проблема была в том что нужно было делать несколько от этих транзисторов и на каждой на каждом транзишен не нужно было соответственно свою логику как это оптимально не сделать имплементировать до того как было 2 6 ядро был так называемый войну сальватор это был самый такой простой примитивный и и скинули и написан он был сами догадаетесь кем поэтому естественно долгое время он считался абсолютно незыблемым таким очень хорошим но по мере того как только один человек оставался который считал что он хорошим люди начали новое всякой разрабатывать и он имел много проблем потому что но фактически он мир джоу испортил в зависимости от того как эффективнее записать это естественно в случае смотрите на диск с вращающимся механическими дисками приводила к тому что возникала такая ситуация старейшин да то есть если у нас есть диск чтобы на него эффективно записать его нужно повернуть так а теперь нам внезапно нужно с него одновременно эффективно прочитать а он уже так повёрнут да и соответственно читается такой штуки плохо то есть постепенно постепенно стало понятно что это очень неэффективная вещи нужно что-то с этим делать и поэтому начиная с ядра 26 стали появляться такие разнообразные зоопарк scheduler of предназначенных для разных для разных задач тут возникает некая путаница я поэтому как бы заранее скажу что очень многие путают эти scheduler и с scheduler am операционной системы потому что у них похожие названия то есть севку это комплект комплект free queen то есть это не не тоже самое что scheduler операционной системы просто называется похоже и он был придуман как такой универсальный что такое как бы универсальной schedule а вот вы работаете с базами данных кто считает что у него в cloud какой-то такой усредненные да а кто считает что у него там уникальный высоконагруженные какой-нибудь это стесняются просто смысл в том что на самом деле очень плохо с универсальностью баз данных то есть на самом деле универсальный workout который вот мы можем себе представить это обычный desktop ноутбук да то есть там черт знает что происходит там музыку слушаем там и текст в ворде набираем то еще что-нить в этом роде и для этих вещей как раз вот эти универсальные scheduler ее писались то есть у них основная задача какая что мы делаем для каждого там блинами случае linux для каждого виртуального терминала для каждого процесса мы делаем свою очередь запросов и соответственно когда мы хотим не знаю там послушать музыку в какому-нибудь аудио проигрыватели вот вводом-выводом для этого аудио проигрывателя занимается вот это вот очередь если мы хотим там забэкапить там не знаю что-нибудь с помощью там команда себе этим занимается там что-то еще какая здесь проблема возникает случае с базами данных база данных как правило это какой-то процесс которая стартовала от него чего-то от for классе летом параллельные процессы возникли в общем короче эта штука всегда заканчивает в одной и той же очередью ввода-вывода потому что это одно и то же приложение один и тот же родительский процесс он как бы туда цепляется соответственно для каких-то очень небольших в окладов баз данных такой же доля подходил а так он как бы был абсолютно бессмысленно то есть о было проще там как говоря выключите не использовать если это возможно постепенно появилась такая штука как дедлайн schedule of ну как бы немножко более и хитрая вещь но опять же базовые то все равно тот же самый мир джон консалтинг для вращающихся дисков то есть мы с учетом того как у нас устроено конкретная дисковая подсистема мы собираем вот эти вот вектор и блоков чтобы их оптимальным способом записать у него было меньше проблем с старейшим но они все равно там были и поэтому к началу третьих лидер linux стала появляться такая штука как на up- ну хотя наверно правильнее ли нам и вот эта вещь она как выяснилось гораздо лучше работалось с источниками которые тогда уже вовсю появлялись и базовую идея была такая что включая scheduler но мы фактически scheduling отключаем у нас нету вот этого вот сортировок мер дженга и тому подобных вещей которыми занимались евклиду 1 почему это стало лучше работать с источниками потому что и создашь ник от природы параллельные да то есть у него есть там ячейки памяти соответственно чем больше мы этих элементов на пихаем там на 1 пися и там платья грубо говоря тем у нас эта штука будет работать лучше и эффективнее а дальше мы выясняем что у нас делает соответственно наш schedule of age и доля у нас соответственно из каких-то совершенно своих потусторонних с точки зрения ssd соображений собирает какие-то виктора и куда ты их посылает и фактически это все заканчивается такой воронкой да то есть мы убиваем и тем самым правильным создашь ников мы не используем их на полную катушку поэтому просто это отключить чтобы эти виктора ехали как попало без всякой сортировки срабатывало в результате лучше с точки зрения производительности и поэтому народ там любил говорить что у нас ssd pny key лучше всего идут какие-то там рандом риды рандом райта и так далее просто потому что он для такой задачи не был приспособлен но тем ни менее начиная с 3 13 ядра по моему немножко раньше был прототип котом туда было можно замёрзнуть но в 313 это впервые было замерзли на уже как такой scheduler в ведре появилась такая штука под названием балкам q и в общем на самом деле сложно называть scheduler am это фактически замена вот этому request в эру в ядре то есть архитектурно эта вещь которая совершенно как бы стоит отдельно начинался как scheduler и потихоньку полегоньку это привело к очень серьезной переработке всего linux вас т.к. ввода-вывода какая идея идея такая давайте мы использовать для ввода вывода будем нативную возможностью ssd делать эффективный параллелизм это собственно говоря и произошло то есть там зависимости от того сколько мы параллельных воду потоков ввода-вывода можем использовать у нас есть соответственно очереди очереди честные и соответственно мы через эти очереди просто пишем из на наши ssd pny key и в принципе там для каждой ну считай что для каждой сыпью это как по свою очередь для записи в настоящий момент эта штука активно очень развивается работает и сейчас принципе нету причин не использовать это дело то есть в там современных там четыре с большими цифрами ядрах от долг амку выигрыш там ну не на десятки процентов может быть там достаточно большим то есть ощутимые это не то что там 5 10 процентов это больше и сейчас мы в принципе считаем что это наверное лучшая опция для работы с источниками надо понимать что в нынешнем виде балкам q эта вещь напрямую завязано на так называемый envy me driver linux есть не только драйвер для linux есть например то майкрософтовский драйвер но вот именно вот это вот идея сделать балкам queen with driver это вот та самая приработка стыка linux от которой база данных очень здорово выиграли это был консорциум и сейчас он есть из нескольких компаний которые собравшись вместе решили сделать вот эту спецификацию этот самый протокол сейчас уже как бы он в продакшн версии отлично работает для локальных писей и создашь ников но в принципе практически готовая история для дисковых массивов подключаемых по оптике чтобы эта технология работала с ними давайте мы в нее немножко больше погрузимся чтобы понять что это такое опять же как бы спецификации ними она очень большая и поэтому как бы все подробности мы сейчас не рассмотрим мы только пробежимся по ним значит старый подход к элеватором вот у нас есть сыпью есть вакуум и соответственно как это идем на диске более какие-то продвинутые элеваторы они работали так у нас есть там несколько secu есть несколько очередей и каким-то образом например в зависимости от того какого родительского процесса от пачка варис вот эти вот наши маркеры там базу данных там чек-поинтов какой-нибудь вот она идет в какие-то очереди и там попадают на диске соответственно балкам киу это абсолютно новый подход когда фактически каждый сепию каждый атом numa зона там будем точными она соответственно засовывает свой вот вывод в свою очередь и дальше она попадает на диске неважно как подключенными потому что как бы драйвер новый там нет sd драйвера которые там оперирует даже с источниками понятиям цилиндров блоков и так далее собственно говоря на самом деле был переходный такой период если кто-нибудь обращал внимание в какой-то момент все вендоры raid-массивов стали продавать такие donna которые позволяли обходить кэш рейда то есть напрямую писать если у вас подключен и создашь ники прямо вот туда вот напрямую можно было писать фактически они то же самое делали они отключали применение sd драйвера для своих продуктов значит как выглядит новый стек в новом виде принципе сверху там осталось все то же самое то есть база данных например довольно сильно отстают от реализации этого дела на потому что как бы это вот сейчас вот происходит на наших глазах вот вывод база данных точно так же как раньше попадает в блока и и слой и там соответственно есть этот самый вот балкам кук который заменяет на самом деле request свой он не заменяет scheduler когда он был едва 313 как бы это было примерно все но в современных ядрах стали делать новые подходы новые технологии стали появляться специальные scheduler и для балкам q которые на более развесистые параллелизм рассчитаны из двух которые сейчас современных четвертых ядрах linux считаются зрелыми это так называемый кибер и bfq а я скину лях который вот рассчитаны на работу с параллелизмом и с балкан ти чем они отличаются bfq это такой как бы аналог севки они абсолютно непохожи хотя один из другого как бы вырос основная идея это такой schedule of со сложной математикой как сделать хорошо б это budget и идея такая что каждое приложение каждый процесс то есть не то что там отпочковался от этого родительского процесса а вот каждая в зависимости какой он умело генерит она имеет некую квоту на его и согласно этой квоте согласно этому бюджету она соответственно вот вот имеет такую полосу мы в нее пишем насколько хорошо эта штука работает вопрос как бы сложной если кто интересуется есть там масса статей с огромным количеством математики лежащие в основе этого дела котором можно почитать в принципе альтернативно был сделан вот этот самый кибер который представляет собой все тоже самое только с оторванной математикой да то есть у нее как бы очень небольшой scheduler по количеству кода его основная задача это то что мы грубо говоря там от этого happy you пришло ну вот дальше туда поехала и она соответственно легковесная легкая и типа призвана работать лучше соответственно вот такие новые scheduler и появились на этой штуке но очень важный момент для всего стека заключается в том что бал комки он не смотрит в sd драйвер то есть у него нету такого очередного слоя конверсии на которой я жаловался когда показал как раньше выглядела с так то есть из балки мку все приходит в ногами и драйвер в таком виде в которому нужно там никто не пересчитывает блоки в цилиндры и так далее и вот в этот момент возникла несколько интересных моментов о которых следует упомянуть и с там на последних слайдах а них еще расскажу резко упал watenshi и вот этого слоя в том числе то есть сначала мы как бы представили ну как бы появились и создашь ники которые хорошо работают стала нужно перерабатывать вот этот слой как только мы перестали там конвертировать туда-сюда все эти вещи выяснилось что у нас вот и в январе вислу и в болтанку есть свои ботаники которые тоже надо оптимизировать ясно них немножко поговорим ну вот это вот диаграмма который вам сейчас показываю она такая упрощенная чтобы было только то что нам нужно для этого доклада если кто интересуется есть такой томас крен в германии живет у него есть постоянно обновляемая к актуальным я драм диаграмма стыка ввода-вывода linux посмотрите в принципе как бы если кто интересуется там видно кто над кем стоял и так далее то есть какие взаимоотношения между какими драйверами какие элеваторы являются частью такого слоя и так далее поскольку она регулярно обновляемая это вообще такой хороший способ смог следить за тем как эволюционирует ядро что очень нужно на самом деле администратору баз данных и любому чайку с базами работает хотя там есть конечно какие-то такие специфические вещи то есть какая стрелочка куда идет иногда показать очень сложно потому что ну там сильные структуры там нету квадратиков из квадратиками рисовать такие вещи довольно непросто давайте дальше немножко за копаемся в январе me как я уже говорил это такая спецификация стандарта и в линуксе она сейчас хорошо имплементировать в принципе linux одна из таких движущих сил как это сделать сейчас в продакшене третья версия и в принципе вот этот драйвер он по своей спецификации через себя может пропускать очень много то есть третье по моему там в районе 20 гигабайт в секунду там на там один какой-нибудь там мы создали блог а соответственно современная 5 у нее там вообще не что ничем не ограничена через через sd драйвер в принципе у него нет ни интерфейсов не механизмов внутри чтобы такую пропускную способность обеспечить то есть в принципе вот это вот спецификации она существенно быстрее чем все что было до этого возникает вопрос готовы ли к этому база данных то есть насколько база данных вообще способны проживать такую нагрузку потому что они тоже в принципе ориентированы там у них есть индексы в виде бы дерева и так далее анин когда ты тоже писались под вращающиеся диски и этот вопрос открытые на самом деле сейчас активно происходит взаимодействие да то есть вот если вы смотрели недавно упал в под брестом пара коммитов про в райт и тому подобные вещи в рассылке в принципе как бы разработчики там под колеса и mais quel и они взаимодействуют с разработчиками ядра хотя конечно хотелось бы чтобы больше было этого взаимодействия и соответственно базы данных потихоньку к этому тоже адаптируются важный момент который был сделан в последнее время но как последнее время последней там полтора года наверное в индии мы добавили так называемый и о полинг что это такое как я уже говорю у нас была проблема да что у нас был очень высокой latent ssd а тут соответственно вращающихся дисков а тут у нас появились ssd который гораздо быстрее и возник у них некоторые косяк да он возник в том что у нас идет и в sing начинает что-то писать и на очень низком уровне уже там глубоко в драйвере отправляется ли квестом вот непосредственно в железку запиши и механизм раньше был очень простой отправили и ждем пока обработается прерывание и в принципе по сравнению с тем что такое за писатель на вращающихся диск подождать обработки прерывания это было вообще как бы вот никаких проблем да то есть настолько долго надо было ждать что как только у нас запись закончилась прерывание вот она у нас как бы тут сработало в результате были вынуждены сделать механизм поскольку и создает и делает очень быстро как время от времени опрашивать собственно гре железку о том произошла ли запись то есть в принципе там до 50 процентов насколько я читал в первых версиях было возрастании скорости ввода вывода из за того что мы не ждем прерывания а сами активно умеем спрашивать железку собственного произошла запись или нет это называется ее полинг он вот был в последних версиях представлен в версии 412 появились вот эти о ее scheduler и специально заточенные для работы с балки мкф и и 2-ми по который сказал киберы обивки и они уже официально в ведре их можно использовать сейчас уже в пригодном для использования виде есть так называемый и attacking да то есть это делается в основном производителями облаков и виртуалок any country бьют в это дело она грубо говоря там вот от определенного приложения можно затыкать и дать ему какой-нибудь приоритет это вещь которой пока не готовы база данных ну как бы следите за обновлениями до то есть очень скоро я думаю это будет мы нсд римом и много мелких вещей по улучшению директа и но тут как бы сразу возникает вопрос что например в плоскости директа и сейчас мне поддерживается есть ряд проблем проблем которые мешают включить поддержку этих вещей то есть сейчас это только для вала и только если у нас не включена репликация поскольку надо очень много кода который специфичен написать то пока что все как-то с этим делом так воздерживаются и несмотря на то что лайнус например очень сильно ругается на этот на эту идею директа и и на то как она сделана но в принципе все базы данных туда идут то есть сейчас там world ли директа и активно используется в мае сиквеле тоже в общем на этом более менее все и если вы хотите задать какие-то вопросы то задавайте у нас есть какое-то время мне тут дали какую-то книжку не знаю я все время на нее отвлекался думал не почитатели за лучший вопрос каким то образом определенный будет вот эта книжка говорят новый день спасибо за доклад а у меня вопрос такой в презентацию несколько раз мелькали слово хорошее ssd современные ssd и спасибо дело в том что есть такое понятие как хороший сервер на ssd есть характеристики дисков отношение к перегреву к вибрации и так далее все эти вещи и в принципе десктопный создаешь ник дешевый он этим всем не обладает он просто может внезапно выйти из строя но главный признак хорошего техника это наличие конденсатора то есть грубо говоря смысл в чем представляете как кроить с батарейкой работает здесь кэш , батарейка и если вы миру электричество мы соответственно за счет этой батарейки держим в каше данные стартуем они проваливаются на диск с воздушников есть похожий механизм более интересный там есть конденсатор который позволяет из временной памяти записать в постоянную если пропало электричество и он лучше батарейки потому что он как бы вечный практически он живет дольше жесткого диска и нормально работает если вы возьмете какой-нибудь там хороший интеловские 37 или там какой-то там серия 36 какая сейчас актуальна я не буду точно цифра говорить то они всеми этими свойствами обладают а если вы возьмете какой-нибудь дешевый samsung для ноутбуков я туда базу данных не ставил потому что пропадет напряжение и все привет вам нужно тогда держать барьер на файловой системе и отрезка убьет все по производительностью вот так такая такое разделение так дальше вас 8 спасибо большое за доклад в очень вкусно рассказывайте про н в мае ssd на из тех людей которые используем может десктопный ssd hdd 80 самсунге пока к сожалению как вы правильно заметили параметр по глубине очереди до для стандартных sata ssd порядка 32 и для иного моей солдатам порядка шестидесяти четырех тысяч там никакое сравнение вообще не не происходит в общем два вопроса я так понимаю уже настал настало то время когда можно отказаться полностью от sata ssd в том что enterprise и полностью приехать на его моей ssd и соответственно такой второй вопрос если мы переходим на и в моей то соответственно мы ядро используем не менее 4 версии первый вопрос да то есть грубо говоря я могу увидеть какие-то резоны для каких то систем с небольшой нагрузкой супер требованиями к надежности где можно использовать счас и да а вот sata ну это такой для серверов и баз данных это мертворожденные стандарт на самом деле потому что грубо говоря это и дает смеха по механике с более быстрым интерфейсом то есть у них надежность очень плохо отсосав да надо отказываться что касается отца то надо отказаться что касается второго вопроса до 4 ядра сильно лучше если вы используете пися экспресс иные вещи то можно и на более ранних я работать push там уже это все включено там нету опции других scheduler of там написано на но на самом деле это был балкам пью но в принципе как бы s4 вот 10 412 4 там дальше все гораздо вкуснее по скорости стиль я благодарю за доклад так вопрос можете немножечко осветить тему про пузырь из xing surprise больше точнее как него защититься в смысле как смотрите там есть несколько задач 3 задачи я вкратце сейчас скажу поскольку это долго там найдите меня на стенде я вам расскажу подробней первая задача это настроить чекпоинты чтобы они грубо говоря были реже больше и в соответствии с тем сколько вы можете там реально записать второй момент это настроить бэкграунд raider чтобы он помогал чекпоинты чтобы не было в sing of постоянно крутящихся в системе зная задача как редкие чекпоинты с большим количеством в sing of распределенные между двумя чекпоинтами там 09 параметров ставить этот самый как он называется в общем расскажу заскок и третий момент of the vacuum то есть of the vacuum нужно тюнить чтобы не было лишнего паразитного ввода-вывода а дальше уже возникает вопрос куда там смотреть в линуксе из в некоторых случаях имеет смысл потяните пройдете в соответствии с тем сколько у вас файла дисковая система пропускает и вот его там подобные вещи но это как бы это и на еще один такой доклад поэтому я вот бегал обозначив какую сторону смотреть а дальше приходите расскажем тут тут здравствуйте меня зовут дмитрий такой вопрос вот если использовать бекеш и базу данных поверх этого бекеша ну вот получается такой кисту какой щедрых лучше всего использовать я бы честно говоря не сказал что это в клуб что это такая как бы сетап предназначенный для баз данных ну просто бывает делать как бы хранение общего назначения где и сайты колотится и база данных на пост вот сделаю сделали одно решение на все сразу и туда запустили все контейнеры всех пользователей и вот как это лучше настроить изделий я бы сказал так я бы сказал что имеет смысл попробовать на новых относительная дорог сравнить балкам q с но пам и если будет разница значит лучше использовать балкам q а если нет то но но не может так получиться что когда она будет опираться в их от одышки балкам q в долг внезапно будет давать какие-то очень плохие у вас какие диски под этим делом ну там хадис ну как там 3 с предыдущей работы просто интересно там в качестве создавших использовались intel 3710 ну то есть нормальные создашь них это даже как и стрижки уже точно не скажу какие типа если она наедет на художник то будет плохо ну ну просто это не моя мысль в том что использование был кмк можешь добавить непредсказуемости и новый когда она будет работать строителем их одышки может произвести фиг знает что и даже если на первых тестах покажется что работает лучше то является ли это целесообразным ну скажем так если у вас там есть непонятные хдд жки то лучше конечно не рисковать лучше конечно от них там избавиться но возможно до в такой ситуации использовать но он будет безопасней на хорошо спасибо вам"
}