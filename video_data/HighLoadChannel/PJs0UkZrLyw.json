{
  "video_id": "PJs0UkZrLyw",
  "channel": "HighLoadChannel",
  "title": "Пайплайн машинного обучения на Apache Spark / Павел Клеменков (Rambler&Co)",
  "views": 4781,
  "duration": 2468,
  "published": "2017-04-22T14:47:47-07:00",
  "text": "всем привет неожиданно много народу собралось и сейчас не ожидал потому что все группы на разогрею уже выступили пришло время хэдлайнеров я сам собой по спору что придет человек десять получилось довольно много ну надеюсь я вас могу что-то интересно рассказать так давайте начнем с самого главного самое главное самое главное что вы можете вывести из вынести с моего выступления заключается пример в следующем если вы когда-нибудь будете выступать на конференции убедите пожалуйста что весьма от организаторов не попадает спам тогда вы не будете хэдлайнерами будете выступать там где попрохладнее воздуха больше и и и пораньше так кто я такой меня зовут маш клименков я работал руководителем отдела машину обучение в компании rambler н.к. давайте про это немного поподробнее поговорим когда-то rambler был поиск когда-то он был первым поиском в россии самом крупном эти времена позади сейчас rambler он остается формально поиском но теперь работает на поисковые технологии яндекс ну и бог с ним на самом деле сейчас rambler и к это крупнейший медиахолдинг в россии он объединяет такие кажется известные многим ресурсы как lenta.ru gazeta.ru афиша секрет фирмы lojer нам но кроме того что охотник является медийном rambler появляется на самом деле еще и технологической компании думаю что за последние год-два многие часто слышали выступления моих коллег на разных мероприятиях ну и вот я тоже внизу кое-какую лепту о чем будет доклад изначально тема доклада это как мы сделали pipeline с помощью apache парк но потом кажется потому что стоит переформулировать эту тему и тема примерно следующее я разговариваю с коллегами из разных компаний прямого части каких-то мероприятиях часто животрепещущая интересующая тема это найм дата-сайентистов кто такой дата-сайентистов он должен делать частенько и особенно коллеги из небольших компаний говорят что дата-сайентистов такой чувак который пилит модели вайпа этом ноутбуке задает вопросы проверяют гипотезы получают ответы и все все что дальше это делают специально обученные программисты каким-то образом и это меня не касается в общем мое личное убеждение заключается в том что так не работает это сайте ст это вот реальная чувак который посрединке это диаграммы это хакер хорошим слышит смысле этого слова то есть он может писать клево код и доводить его до продакшена это математика статистик то есть человек который обладает хорошими в том числе теоретическими знаниями в области машинного обучения ну и домена экспертиза она к прикладывается само собой когда ты решаешь конкретно задачу и в чем же заключался заключала заключалась идея когда мы переделаем pipeline помимо того что мы решали чисто технических проблем и мы хотели еще решить такую штуку нанять вот этого человека который по серединке диаграммы очень сложно особенно в россии и поэтому нам бы так сделать чтобы мы вот этого среднестатистического российского to the site is the которые не очень хорошо программируют могли вот в эту диаграмму засунуть и сделать из него настоящего the sun теста который может доводить кода продакшна поддерживать его и решать возникающие проблемы начну с мотивационного примера представим ситуацию при которой бота в компании где есть отдельная делал это сайт отдельно программисты которые реализуют модели сделаны дата сенсиз у нас была вот такая ситуация есть команда которая занимается при диком сетях там условно 2 человека один человек занимался собственно обучением настройка модели проверка эксперимента в другое дело в это время сервис который должен был выдерживает большие нагрузки и там и там используется выпить очевидно сервис написан на джаве поэтому там исход за своего по обе джиной и вот чувак который дело модель сделал ее с помощью бетоном и в общем большая часть вещей стараемся делать на питоне о чем я скажу отдельно и получил некое качество предиктор predicted что то что во пропорциональная базовому сетях у которой у нас имеется то есть это похоже на правду дальше мы берем эту модель загружаем сервис и получаем predict и которые совершенно не сообразуется с реальным миром они в общем-то не похоже и кажется чтобы произошло ситуации когда есть один дата садист отдельным отдельно программист программист реализовал выкатил в рот нагрузку держат на груше на тестируем проведён отчета predicted и все когда вроде эта штука была за руку зарабатывает на и сработала неправильно что нужно было бы делать разбираться с этим то есть вот этот самолета сайте 100 все равно придется программисту и начнет россия идет рядом с ним и начнут выяснять почему это происходит в итоге два человека занимается одной вещью одновременно это как бы нерационально трата ресурсов поэтому так как мы старались всегда нанимать именно дата-сайентистов они у вас называются математики и программисты второй чувак который делал сервис в принципе довольно быстро заметил что так и попова be that поддерживает спас формат не хватало фичей которые приходили запросе в сервис и соответственно при диктовать не совсем то что обучалась и такой мотивационно пример в общем в итоге чем hotel в очередь мы вот что мы хотим от собственно от математика программисты чтобы он делал работу to the sun тесто при чем дело ее хорошо использовать самые последние научные разработки если мой последний тулы очень делал качественные эксперименты после этого доводил эксперимент это продакшна и в течение жизни этого продукта в продакшене следил за тем что он работает если что-то ломалось чинил такой вот чувак вообще мы хотели получить из вот этого человека который вам приходит смотрит на продакшен вот этого человека заметим папа меня и так что же я имею ввиду под вот этим тем что мы хотим от математик математикой программиста что такое качественный эксперимент качестве эксперимент проводится обычно хорошо в знакомом окружении когда у человека есть какой-то опыт он уже знает с набором инструментов которого может использовать свои работы кроме того если появляется что-то новое крутое знаю какая то новый архитектура нейросетей fast текст что угодно он хочет использовать сразу для своих экспериментов мы должны дать ему возможность это быстро заюзать ну и кроме того как мы выяснили очень хорошая штука это витрина фичей я поговорю об этом отдельно эксперимент можно довести до production что для этого нужно сделать в идеале ничего то есть и сделал эксперимент в своем знакомом об этом ноутбуке после этого с учетом там небольших изменений в том чтобы это выглядело нормально ты написал тесто на этот просто нажал кнопку протестировать выкатилась пруд работает все должна быть максимально автоматизирована чтобы люди не занимались вот этой вот диво пускай работает которая тоже очень важное крайне полезно это я наверное упомянул ну и соответственно когда-то столько работает вроде человека нужно понимать что сломалось именно ты отвечаешь за эту штуку тебе прилетает notification что сломалось и дичи не fix баги для этого нужно понимать как фиксит баги иметь быстрый доступ к логом к кремом и в общем-то отлаживать то что то что то что непонятно как работает итак чего мы стартовали стартовали мы наверное с типичные для многих архитектуры она выглядит примерно так у нас есть ходу это какое-то количество кластеров кого-то количество серверов у нас сейчас их 70 туда каким-то образом разными абсолютно способами довольно к стильными наливались праздные логии все что мы делали весь продакшн это был он был построен на high стриминге то есть мы делали все данные сохраняются каковой таблички дальше выборками формировались обучающей выборке производилась локальная настройка моделей эти модели дали сохранялись и потом на этапе применение модели все тот же х и вова запрос на все фичи которые необходимы этой модели посол модель собственно настроенную и ее применял регистрируя все управлялось это сам описанным дело нам блокировок который запускался по крону он это был просто консольный интерфейс в нем не было ничего понятно если что-то сломалось вообще ничего не разберешь и было самописный мониторинг он выглядел как такая табличка с квадратиками как бы не недели джо бы посчитала снипа считалось зеленый красный свет и все если не посчитал ась не понятно ничего и это была проблема мы начали думать как бы эту проблему устранять продумать новую архитектуру и пришли примерных следующему решению я сейчас пробегаюсь немножечко по каждому изменившемуся этап нашего pipeline они будут они на них заострять внимание потому что по каждый из них можно рассказывать отдельно первое что мы делаем сделали это наладили единую но в данных давайте поиграем с вами в шара два чувака справа вы наверное узнали кто это да да да точно вот есть победитель это это это кафка и гоблин собственно вот это вот красная часть которая была непонятная поддерживает разными людьми превратилась вот в эту часть все данные которые у нас есть том числе те которые мы генерим сами наливается в кафку и забирается оттуда гоблину гоблина то такое определит библиотека который умеет читать из кафки параллельно и загружать данные в разные в разные в разные части куда угодно в принципе но в данном случае нам интересен только hive тут еще сейчас у нас добавился паспорт streaming но я про него не могу рассказать потому что в деталях не владеем формации это делает другая команда дальше у нас был собственно в основном все модели работали offline то есть мы настраиваем модель apple и мы ее на всю базу пользователей или событий которые у нас есть и соответственно predict и складываем в hive после этого отдельная jobo загружает их фрёйдис для того чтобы быстро отдавать наружу в какой то момент времени когда мы начали делать со своим пи и мы поняли что мы упираемся в производительность квартира редиса и были вынуждены переехать на другое решение мем стал р спайк сара спайком есть свои собственные проблемы но в принципе он достаточно крутой очень производительны и в общем то все денежки которые я знаю по крайней мере в россии aerospike использует это хорошо дальше собственно мониторинг у нас был сам описаны мониторинг в нем бою мало чего понятно мы решили что мы должны обвешать мониторингом все компоненты которые у нас есть для того чтобы люди ты-то сайты которые так этот код до продакшена могли быстро реагировать на кита проблему получать оповещения для этого мы заюзали в принципе стандартную схему графиков она была так стало так появились связи со всеми компонентами то есть кафка google and streaming ходу они все пишут метрики в графит и ascii рисуется граф они и рф а вот эта красная часть самая больная была самописный демон блокировок все что нужно было этапа крон запретить задачу и убедиться что еще одна задача с тем же именем не работает в это время это было очень неудобно потому что это было абсолютно не визуальный морфо менеджер в нем вообще не было понятно что происходит что сломалось где зависла но только известно на какое на какой машине задач запустилась когда ее имя собственной перешли на арфа менеджер от команды rgr by air flow это очень крутая визуальная штука которая написана на питоне и мы специально выбираю workflow менеджер который написан на питоне и потому что как я уже упоминала все пишем на питоне не зря кстати мы это сделали потому что матчи телефон приходится регулярно помимо того что он крутой визуальные клёвые к нему регулярно приходит патчи в том числе от нас некоторые даже попадает в up stream ну в общем то вот так и соответственно еще одна часть которой я упомянул они могут не буду много говорить это дженкинс мы решили все автоматизировать пришли на 2 дженкинс в нем собственно настроены pipeline и где есть этап сборки кода тестирования этого кода вы к выкатки на стычку остер и соответственно дальше выходки в рот все это делается 1 кнопка то есть чувак после того как запущу все свои все свои наработки в git поучил review от своих коллег он дальше может нажать кнопку раз протестировать кнопку 2 выкатить настичь и после того как все необходимые требования по и финише на в данной задачи выполнены выкатить от на прот все это делается автоматизировано одной кнопкой и вот самая веселая часть там где собственно появляется spark hive streaming со стримингом по нашему опыту есть одни проблем скажите кто использует hive в своей работе регулярно есть такие люди кто использует х streaming один чувак он меня понимает со стримингом реально одни проблемы вот пример мы написали какой-то скрипт который обрабатывает табличку в ходе через streaming он написан на питоне запускаем этот запрос и он валится с такой вот очень яркой и понятная ошибкой из джавы но сломался под процесс которые собственно форквут бутончик сломался что с этим происходит не понятно это все что вы видите в интерфейсе мы видим интерфейсе ярым например нашего ресурса менеджеры дальше чтобы получить собственно непосредственно 3d cad питона нужно лезть в логе ярно там yarn applications лог трали-вали еще не факт что это сработает потому что может не включена быть агрегация для этой задачи агрегации логов и тогда ты остаешься вообще ни с чем казалось бы логичный вопрос ну смотри у тебя есть как бы вот это мяч и скриптов весь его тестами чтобы он логику проверял итак давайте они не сломается не работает тесты вот боевой пример раньше раб примерно работала так вот у нас есть модель попал в gta которая боится на какую-то табличку с вещами и streaming падает до тех пор пока мы не приключение прикрутили к настоящему скрипту центре мы не знали почему это происходит потому что streaming упал ты берешь сам пол данных из этой табличке прогоняешь локально streaming все работает берешь идиш ники пользователей на которых упал streaming прогоняешь локально все работает что происходит так как streaming работает через стандартный вход то есть запусков аркой , чей процесс дальше хайфу него стримит собственно текст вот на этапе этого перегонки через стандартный вход склеились две строчки файловые и в итоге у нас скрипт ожидают получить три значения a dish не эти две вероятности а получат 5 модель кроме того своем есть еще одна очень вымораживает это садистов штука когда-то работы с большими данными вообще это самая самая печальная ситуация когда тебе нужно запустить запрос и пойти и ждать когда он выполнится так вот до этого в конференц-зале ребят из яндекса рассказывали про cliff house мы теперь все молимся на клик house и думаем что вот наконец-то нам это поможет отчасти в общем типичная алгоритма работы дата-сайентистов это сделать сам пасхой в сконвертировать его любимый dataframe в панда си в бочке какой-то эксперимент провести понять что чот ты не загрузил еще раз сделать сам пускай во и все это повторяется постоянно то есть после того как каждый раз тебе нужно делать новый сам пол и это очень болезненная штука я прям прям напрягает вот тут соответственно раздается барабанная дробь оскар вручается леонардо дикаприо ура наконец то парень дождался выглядеть окончательная схема вот так streaming конечно же никуда не ушел точнее это даже не streaming скорее ты файловые запрос и потому что мы так как работаем с большими данными часто наших фичи это какие-то аккаунты аккаунты считается по своим рогом срывом аккаунта по сырым лугам просчитать обычным а придется как бы не нужен spark но вот другая часть которая счас парком сразу на она собственно появилась и дальше я вам расскажу про нее чуть подробнее почему мы выбрали spark на самом деле изначально причина была их две было во первых спок работают в памяти значит он должен быть быстрым и второе у него есть api шичко на питоне это значит что мы можем продолжать писать какой-то на питоне и все круто вот и это было действительно круто потому что в спарке начиная с какой-то версия не помню точно с 15 кажется появились появилась такая сущность как sparkasse quelle и dataframe и эти dataframe и своим этим мимикрирует под обычный пандусов ский dataframe то есть вот слева это личный код вайпа этом ноутбуке вот там есть выборка из хай во дальше читаем csv шкаф pandas и дальше обычные операции подготовки данных которые все делают и а справа то что вы получаете с park то есть это очень похожа кроме того и 5 до строчки очень хочет очень похож отдельная крутая штука с парка и spark секула в данном случае заключается в том что вы можете читать данные из кучи разных источников вы можете читать данные слова hadoop и из его из кассандры язык б за из обычных реляционных баз данных можете читать просто текстовый файл типа cs cs cs флешки джейсон что угодно и при этом и 5 практически не изменяется вы всегда просто делаете какой-то запрос к данным и вы на выходе получаете либо рдд либо раза фрейм и работаете с ними абсолютно унифицированным образом это сильно упрощает жизнь ну и кроме того в спарке очень многое помимо собственно мексике жены джона нем есть куча всяких библиотек которые написаны поверх это библиотека его машинного обучения то библиотек работы с графами это спок streaming но в общем все выглядело круто бери и пользуйся осталось только развернуть но на самом деле не все так просто с парк изначально программировали на скале и он ведь запрограммирован на скале с какого-то момента времени мартина дерзкий поняв что скала среди программистов популярность не особо пользуются годы идут аскола как бы не растет он сказал он решил помогать ребятам из парка и допиливает java java и пей то есть java этой сейчас в парке он практически идентичен скалы пиво то можете делать все что угодно а вот питания чая 5 до версии 20 которая вышла относительно недавно он был вот таким не хватает того не хватает всего этого метода нет пути реализации не работает и это очень сильно било теперь небольшая часть может быть и большая про архитектуру спарка для того чтобы в принципе понимать что это такое как с этим работать кто использует парк сейчас и вы все используете его в продакшене свой продакшн задачи пока нет отличная стоит очевидно стоит кроме того сейчас уже появляется fling он активно развивается спарку острожной так долго основа sparco это рдд идите это такая сущность которая представляет собой граф вычислений вы соответственно загружайте какие-то данные делают и над ним какими над ними какие-то трансформации эти трансформации превращается вот в такой вот граф вычислений ответственно как это примерно выглядит основная единица параллельности спарки это partition портится это какой-то кусочек данных кусочек данных на котором производится вычисление собственно параллельность вычислений с парке заключается именно в этом у вас есть какое-то количество worker of каждый из них хранит какую-то партицию над этой партиций параллельно делается вычисления которые определены графом вычислений и в итоге получается то что вы хотите вы хотите получить модель именно устройства архитектурного спарка выглядит примерно следующим образом спарки спарки есть так называемый драйвер драйвер эта программа которая запускается локально где-то которая собственно в которой собственно определяется вычисление которые вы хотите производить произвести драйвер делает собственно из тех трансформации который вы хотите произвести этот самые граф вычислений и в него встроен планировщик который выполняет те или иные вычисления над каждой партиции набор query на маркерах это обычный какой-то горки в кластере вот в кластер менеджер это любой класс стр менеджер это может быть яр мазаться то может быть марковский кластер менеджер мы используем yarn задачку автор мажора просто запустить контейнер в контейнер уже запускается экзекутор спарка guitars парка этот живьем живьем запускается многопоточная и соответственно каждый поток в экзекуторы обрабатывают одну партицию кроме того часть памяти джова машины отделена под так называемый кэш в котором собственно сохраняется те кусочки данных над которыми производятся вычисления и как-то так всё и работает дальше я в ходе своего доклада буду озвучивать какие-то уроки которые мы вынесли себя при работе со с парком надеюсь что они вам тоже будет полезно при запуске задачи в спарке необходимо явно показывает сколько ресурсов вы хотите под неё выделить то есть количество компьютеров сколько и от каждый зек ютаро будет использовать ядерное он будет использовать памяти это сильно упрощает жизнь потому что когда вы пишете мо придешь джуббу обычно все эти вещи не явно за вас вычисляю вычисляются фреймворком ну по числу блоков файлов в файловой системе или по числу в настройки количество байтов которые может обработать каждый и среди серов но общем это делается неявно это проще потому что вам не нужно задумываться насколько насколько ваша программа требует ресурсов но в нашем случае это было не проще потому что мы изначально были на первом ходу пи а потом переехали на yarn первом ходу пи никаких никаких ограничений на контейнеры не было явно имеет отстреливать контейнеры если он выходит за границы выделенных ему ресурсов но когда вы переехали на yarn мы не смогли включить ограничения на выделяемые ресурсы потому что задача были написаны плохо ну то есть как бы мы не могли равномерно распределить ресурсы на кластер потому что задача могла требовать сильно больше ресурсов и поэтому когда он перешли на spark у программиста есть осознанный выбор сколько ресурсов ему необходимо свои задачи и он может оптимизировать свою задачу так чтобы укладываться в эти ресурсы с одной стороны это круто с другой стороны это не круто доводка приложение спарка до продакшена это процесс стохастического дебаггинга вы запускаете spark задачу с определенными ресурсами она начинает работать и падает вы идете смотрите что произошло около джива им потому что хикс ps мало вы ставите больше ресурсов и делаете так до тех пор пока наконец то задачка не отработает это не круто еще одна важная штука на который нужно обратить внимание при работе со с парком это то что он конечно в памяти все вычисления делает старается делать если памяти достаточно но все мы знаем при работе раскаленного систем основная проблема это чтение с диска и пересылка данных по сети собственно в спарке есть трансформации узкие которые делаются без пересылки данных по сети а есть трансформации широкие to join и ready усы сортировки по ключам тогда когда все ключи должны попасть на один экзекутор вот еще один урок который стоит вынести это то что нужно избегать избегать шаффла ну то есть пересылки данных по сети это сложно сделать на самом деле потому что spark в парке есть определенное ограничение например когда вы читаете данные из какого-то источника вы не всегда можете задать количество партиций которые необходимо создавать и то есть парк прочитывают данные и создает партиции исходя из своей логике а потом вам нужно делать метод репортаж in которые разбивают данные на большее число или меньшее число партиции это всегда shuffle это очень плохо и нужно стараться избегать spark ей dataframe и все дата-сайентистов dataframe и они вари есть они есть пандусы dataframe это круто это табличками который можно производить разные манипуляции вот сравнение производительности hdd базового типа в парке dataframe а и на реализацию на разных языках на скале на пати dataframe как видно он сильно производительнее чем ардити почему это происходит это происходит по следующей причине ардити это базовая структура данных которая собственно формируют архитектуру s-park при вычислении графа когда вы считается граф собственно никаких оптимизаций на борде не делается то есть если вы хотите супер оптимальную программу вы можете руками спроектировать и и таким образом чтобы она была оптимальной но мы же хотим упростить жизнь to the side as the чтобы он как бы квад минимальным усилием это production доводил поэтому в dota фрейме есть крутая штука называется catalyst catalyst это в принципе достаточно обычный оптимизатор запросов к базе данных то есть dataframe это часть парка с quelle и соответственно все вычисления data frame переводится в некое абстрактное синтаксическое дерево оно оптимизируется и соответственно таким образом вы получаете практически бесплатно код который работает лучше чем вы попарились описали его ну собственно это урок номер четыре используйте dataframe тогда когда вы можете и не испортить орден во втором с парке появилась такая сущность как datasette и это еще более крутая штука чем dataframe еще более производительная поэтому если будете более 2 spark сразу использовать datasette урок 5 который мы извлекли у нас же все данных heavy мы с ними работаем через парк в хайве данные парте циане руются и баки these руется партиции то просто разделение на директории bucket боккетти зации это просто разделение на файл и собственно когда hive spark читают даны искового таблички он создает ровно столько партиции сколько пакетов таблицы поэтому это собственно проблема с которой мы сталкиваемся регулярное нам сейчас новые таблицы необходимо проектировать таким образом чтобы они правильным образом читались в спарке либо нужно делать и портишь report тишина пересылка данных по сети ее нужно избегать собственно где же машинное обучение вот она мы не используем с парком el да почему мы не используем с парками это есть ряд причин причина номер 1 в старом по и плане у нас использовались его по выбиты где boost а такому переходили на новую архитектуру и переписывали много кода мы не хотели чтобы на качество наших моделей влияли еще и другие реализации модели слишком много было ручек которые могли повлиять на качество и поэтому мы решили просто переносить все как есть кроме того vape выбит из уст очень быстро и ведь груз вообще оптимизируется на уровне чуть ли не перестановки by тиков а вот увидит быстрые ну потому что это стохастический градиента спуск и кроме того он тоже супер оптимизированный и он быстрый причина номер 2 это все та же тот же багтрекер в с парком или там не реализовано методы там реализованы сохранения моделей здесь вообще все плохо до определенного момента наверное только во втором спарки интерфейс стал конфетка систем thin ice парком el можно уже начинать использовать причина номер три это график просто качество одного из наших классификаторов на обучение тут соответственно оси x от объем обучающей выборке на по оси y некая метрика качества можно заметить что с определенного объема выборки наступал на 100 насыщение и то есть качество на трения принципе не росло это будет понятно что связано с разными вещами потому что модели у нас такая можно было использовать более более изощренную модели тогда качество могло расти и можно дело было делать еще чего-то но мы хотели перенести pipeline именно в части машинного обучения с из поэтому нам не нужно было масштабирование которое дается парком el но мы верили что все изменится здесь должна была быть картинка с инопланетянином но я нет поэтому мы весь код который писали мы пытались реализовывать именно вып из парка то есть мы хотели чтобы как в как в тот момент когда нам понадобится использовать парком el мы могли просто частью нашего плана безболезненно заменить на библиотечной реализации и ничего бы не сломалась здесь есть два метода отдельные лотоса и они необходимы по двум причинам первое это то что стерилизация плохо работала по этому поводу были картинки тикетов инжир и второе это то что такая штука позволяет реализовать витрина фичей то есть вы можете напилить вещью сохранить ее за определенный темп и к тому моменту когда она вам понадобится просто за какие-то даты выгрызают необходимые фичи и работать с ними просто без дополнительных каких-то вычислений почему я затронул вопрос про цивилизацию и и и и и питон планок этого переходим вот так работает пасть парк есть беленький части это то что происходит внутри и том этапе татары оранжевые это то что происходит же время spore контекст запускается на драйвере это питания чей объект дальше все что происходит это условная рпц скала вских методов то есть питон через библиотеку пай fuji дергает методы из калужской реализации sparco и таким образом производится вычисление на стороне worker а все еще проще там просто for car , чей интерпретаторы и в них передаются данные соответственно в тех местах где у нас есть взаимодействие питона я и j видимо а не нужно силе завывать это в принципе довольно затратная операция дай питон сам по себе не быстрый поэтому урок номер шесть в работе спать парком есть overhead это worked самого питона overheat носи реализацию поэтому если вы хотите производительное что-то поучить то обращать внимание на эти вещи возможно вам нужны какие-то вещи делать на скале или вообще все делать на скале но мы этого не делаем потому что datasource делается на питоне в основном и мы его делаем на питоне поэтому нам это в принципе не критично и урок номер 7 для сериализации в паспорте используйте библиотека клал пикали это такая надстройка над обычно библиотека пекли стандартной стерилизации в питоне которое может делать много вещей но он не всемогущ и vcl частенько бывает ситуация когда вы определяете какие-то питания че объекты пытаетесь их использовать в spork-ов ских методах и серьезно сломается и тут раму ломается весь pipeline это не круто на это нужно обращать внимание всегда держать это в голове ну собственно один кусочек кода я вам показал вот еще кусочек кода в нем есть две важные строчки это как бы применение обученной модели вот в первой строчке в красном квадрате делается так называемый бродкаст бродкаст эта штука которая позволяет избежать избежать шаффла то есть если вам необходимо какие-то данные иметь на каждом ордере вы просто делаете бродкаст они записываются в память каждого worker и и после этого шаффла не делается и далее есть еще очень удобно метод map марте шанс то есть есть базовый метод map которые применяет некую функцию каждой строчке рдд или dataframe и попортишь нас позволяет делать то же самое только на уровне отдельных партиций и кроме того в нем реализован как бы интерфэйс императора который позволяет вам сразу батч получить функцию и узкая ускорить ускорить вычисление smart ресниц ускоряет наш pipeline примерно раз в десять наверное ну и чтобы не быть голословным я покажу таблицу с таймингом она прям скажем не фантастическое spark не позволяет делать вещи за секунды и даже за минуты самая затратная операции как вы видите это применение модели в данном случае применяется классификатор базового создаем а это пол на всю нашу базу пользователи это 450 миллионов кук вот это самая затратная операция какой вид настройка модели это очень дешево и очень быстро поэтому тут как бы нам с парком el не особо не особо бы помог ну в целом я наверное закончил был бы неплохо если бы вы задавали свои вопросы спасибо это самая печальная ситуация когда нет нет вопросов это значит что плохо рассказал есть спасибо за доклад spark 20 вы используете уже продаж и буквально за час до моего выступления мой админ написал что spark 20 готов использования готов к использованию мы очень хотим быстро на него перейти потому что там калеченные всякие важные вещи касающиеся питонов skype фишки там сделано очень много всяких оптимизации вычислений в catalyst и в бэг-энде собственно вычисление поэтому мы на него перейдем к как сможем так и перекрасил спасибо за доклад большое у меня пара вопросов по технической части больше вы для обработку все видете в одном дата-центре хорошего просто потому что sparco также как выходу по и вот это вот всего очень плохо до центра власти ну она там не столько плохо сколько его придется мутить самостоятельно руками и второй вопрос и у вас соответственно нет такого решения пока что нет а второй вопрос в качестве альтернативой airflow не пробовали луиджи использовать не пробовали мы общались коллегами из мою которые используют луиджи они в принципе им довольны за исключением того что там зависимости между задачами как и понимая необходимо обрабатывать самостоятельно то есть как бы следующий этап вычисление должен каким-то образом расспросить выхлоп предыдущей задаче и сам сам принять решение о том необходимо это делать или нет ну не совсем так ну в общем ну как там нет автоматического разруливания его нужно прописать vr flow нам понравилась именно то что как бы он это делает за нас но как выяснилось делает не очень хорошо поэтому возможно если есть выбор между я for и луиджи он стоит по тестировать для конкретно своих задач и принять решение хорошо спасибо драсти спасибо за докладе был очень интересно познавательно у меня такой вопросик вы сказали что вы запускаете spark популярным но дальше сами руками все равно указывать сколько памяти кушать экзекутор но явно уже позиционируется как ресурс менеджер он сам должен выдавать вам грубо говоря квоты на ядра и на память зачем вы тогда руками все дальше пилить той зачем может быть тогда нужно ему отдавать просто весь кластер не спускать пар в чем фокус хорошая сила хороший вопрос на самом деле yarn эта штука которая за вас то ничего не делает потому что как бы вся идеология она заключается в том что у вас есть некий applications мастер который выполняет собственно такую надзорную функцию за задачами именно он ходит в yarn и запрашивает контейнеры которые ему необходимы в общем все что может делать yarn это после того как вы запросили необходимые ресурсы следить за тем что вы за лимита не выходите если вы уходите их собственно контейнеры пилять что происходит обычно обычно происходит то что hive сам затем за вас определяет сколько ему нужно май пара сколько сколько режиссеров вы над этим над этим не задумываетесь в спарке такая штука не работает но в спарке есть другая вещь она называется кажется дело динамическая локация вы запрашиваете определенное количество контейнеров которые вам необходимы и ресурсов но spark в принципе в вычислив граф может понимать что вот сейчас ему необходимо только часть этих ресурсов и по мере того как граф продолжает вычисления новый контейнер запускается динамические таким образом опять же spark занимается тем чтобы разруливать эти вещи то есть мне на самом деле не известные способы каким образом автоматически составляется парк управлять перекладывать работу с выделением ресурсов именно на яр если есть такие такие решения то я очень-очень рад за них услышать ну кажется все спасибо большое мне кажется была отличная конференция удачи и встретимся еще когда-нибудь"
}