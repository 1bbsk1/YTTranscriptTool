{
  "video_id": "7GM9ac6ojtw",
  "channel": "HighLoadChannel",
  "title": "Жизненный цикл ML в боевых условиях / Сергей Виноградов (Front Tier, РАНХиГС)",
  "views": 1674,
  "duration": 3144,
  "published": "2019-05-14T14:39:10-07:00",
  "text": "сегодня хочу рассказать про наше виде циклом модели машину не в боевых условиях какие возникают проблемы с их реализации эксплуатации и рассказать в нашем пути как мы попытались решать собственно говоря о чем проблема в реальных внедрениях собственно говоря обучение занимает тома четверти от силы читать усилий я поясню что это ношение которое видение именно основанная на достаточно своеобразные предметной области в которой мы все это дело используем то что финтах это telekom остальное всего все старшие работы занимает эта подготовка данных подготовка инфраструктуры deploy причем тепло и зачастую в закрытом контуре с которого нет доступа в интернет которой осуществляется там очень странными телодвижениями с переносом данных туда-сюда мониторинг того что происходит и прочее при этом постоянно столкнуться ситуации что дата сантис там не интересны скучные вопросы эксплуатации им интересны разработай какой-то алгоритм добиться приемлемого качества отдать это кому то вдаль и не заморачиваться тему как это все в дальнейшем живет обычно жизненный цикл от в нашей предметной области выглядит примерно следующим образом там от бизнеса поступает задача дат инженера либо dat ass in this подготовили данные построили модель хорошо если они согласовали качество этой модели с бизнесом и вот дальше начинается очень забавный house 2 ситуации когда dat ass in this либо дат инженеры имеет доступ на пруд ему говорят отлично дружок ты всё это сделал иди сам это ставь человек берет и питер на табук пачку этих нот и буков рассматривает это исключительно как артефакт деплоя и начинает радостно это дело тиражировать на каких-то серверах все наверно как бы хорошо но не всегда позднее потом про это расскажу вторая история более затейливо уже с обычно бывает с компаниями в которых эксплуатация достигла какого-то состоянии легкого маразма то есть эксплуатация когда-то сантис приносит свое решение в эксплуатацию они открывают ту черную коробку которую принесли и видит какой-то ужасно если точки зрения не где-то какие-то над ибуки они видят какие-то pixl и в разных версий пик его не видит ворох скриптов которые непонятно где и когда им надо запускать и которые порождают какие-то странные данные которые надо где-то сохранять они сталкиваются с несовместимостью версий они столкнутся тем что дата сантис не указал например тут конкретной версии библиотеки которые ему нужно они взяли самую последнюю версию этой библиотеке то спустя некоторое время прибегают даташите с криками вы мне поставили с calor не эту версию мне теперь все дни таки поехали давайте откатиться на предыдущую версию это полностью ломается и прот эксплуатации жестоко страдает вторая история например всякие компании с зелеными логотипами приходит dat ass in this tv это уже эксплуатации приносят модель они мы в ответ вручают документ листов на 800 flaming дорогой друг сделай пожалуйста как здесь написано иначе твою изделие никогда не видит жизнь вот и dat ass in this грустный выходит некоторое время страдает увольняется бросается на полпути и ему это не интересно этим всем заниматься допустим все в итоге за тепло или возникает следующая проблема как понять что все работает как нужно кому опытов в те же благословенных банках нет никакого мониторинга продуктов которые делают dat ass in this ты хорошо если он пишет какие-то результаты своей работы в базу данных спустя какое-то время он может получить свои результаты посмотри что там собственно говоря внутри происходит но это бывает не всегда и получается что и бизнес и do the site's верят что все замечательно отлично работает но это в отваливается например такие кейсы и который был в в реальной жизни мы делали как там на скоринговой движок для одной большой микрофинансовых карп организации они не пускали нос на прот они просто взяли от нас модель каскад моделей поставили это себе запустили их вдоль при результаты тестирования тех моделей спустя шесть месяцев они пришли с вами вы знаете как то нам плохо стало бизнес у нас не идет на мыслям хуже и хуже вот вроде бы модель ваши отличное но выдачи падают поток фродо увеличивается поток дефолта увеличивается кого краю количество дефолтов увеличивается а где деньги собственно городов что мы вам заплатили давайте разбираться при этом просто так доступ к моделями дать не могут они месяце выгружали блоге причем блоги и там 6 месячной давности мы это дело в месяц почти изучали после чего пришли к выводу что в какой-то момент их айти подразделения изменила входные данные и местом документов джейсон стали присылать документов xml вот соответственно наша модель который ожидала джейсон она грустила она считала что данные на вход не поступают и совершенно по-другому все оценивала происходящее проблема нет мониторинга не понятно что с этим всем делать при этом еще помимо от описанных проблем с чем мы сталкиваемся постоянно модель работает все хорошо сделали по какой-то причине новую версию модели при этом я опять же нужно как-то принести то и заново проходить этот весь круг ада который был соли модель хорошо если они используют те же самые версии библиотек если нет опять начинается весь deploy по-новому бывают ситуации когда нужно использовать каскад модели когда у вас результаты работы следующих модели зависит от предыдущих моделей и вам нужно каким-то образом налаживать между ними взаимодействия и где-то это все взаимодействие опять же сохранять бывает возникает ситуация когда у вас работает модель по ней к примеру там выдают деньги если это говорить про скоринг вы сделали новую модель вы не готовы сразу эту модель выводить наборе но вы хотите ее протестировать вывести ее на прот посмотреть на том же потоки трафика убедиться что она хороша вам опять же нужно проходить весь все цепочку вот этого тепло и при этом еще нужно каким-то образом настроить систему таким образом чтобы по этой модели реально выдачи не происходило происходил только мониторинг запись результатов для дальнейшего анализа вот из нашего опыта как это вы сами в этом участвовали видели как это обычно бывает люди решают такие проблемы в ручном режиме есть там особенно это маленькие компании один человек который знает как все это дело работает он знает держит в голове все версии модели все версии библиотек он знает где какие скрипты у него работают какие витрины они строят это все прекрасно нашего же опыта в одном маленьком веселом уральском банке добрые люди там работал такой добрый человек он в какой-то момент уехал южные страны и не вернулся туда по разного рода внутренним причинам нам досталась всего наследство мы выяснили что да отлично есть куча кода который генерит какие-то витрины на которых работают эти модельки код прекрасный он работает но мы не знаем какая точная версия скрипта генерит ту или иную витрину потому что они все присутствуют на bayou все запускаются и прочее мы потратили примерно два месяца для того чтобы вот этот весь затейливый клубок разобрать и каким-то образом его до структурировать вот вторая история есть суровый enterprise люди не хотят замарачиваться всякими питонами ноутбуками там скалярным и так далее как отлично давайте мы купим фас мы купим там проблемы с псв них в то ли иной мере все это дело вершину мы себе поставим все замечательных проблемы с реагированием проблемы с источниками данных проблемы в диплом нас не волнует там все это каким-то образом решено это решение в принципе имеет право на существование единственное что не все люди добрые люди могут себе позволить это и во-вторых это такая на моем понимании качественная игла зазубренная на которой люди подсаживаются потом годами слезть не могут стоит это обычно очень дорого для фазы слаживания третья история это люди прошерстили интернет нашли массу open source решение которые в той или иной степени решают такого рода проблемы это тоже на самом деле отличный способ но опять же исходя из опыта наши предметной области мы не нашли таких решений которые бы на сто процентов удовлетворяли именно нас поэтому мы перешли к четвертому пункту мы подумали что мы сами лунное и напишем свое решение вот свои костыли ки велосипедике и прочие замечательные средства передвижения мы для себя сформулировали чего мы хотим во первых все таки мы не хотим все писать сами мы хотим взять компоненты особенно инфраструктурные которые уже хорошо себя зарекомендовали с которыми знакомы тоже тоже эксплуатация этих учреждений с которыми мы работаем мы лишь напишем окружении которое позволяет нам легко изолироваться в работу dat ass in this to от работы devops of мы хотим решать проблемы обрабатывать данные в двух режимах как в пакетных в бочках так и real-time am наша задача придут должны придут в наши задачи предусмотреть и такой режим работы и такой режим работы третья история мы хотим в легкость и тепло и причем легкости deploy в закрытом периметре когда мы имеем дело там в чувствительными приватными данными нет никакого выхода в интернет но нам нужно чтобы все очень быстро и аккуратно доезжала до prada поэтому мы стали смотреть в сторону beetle оба стали смотреть в сторону себя сиди под line of внутри самого гид лобо и стали смотреть на docker мы поняли что для нас модель в общем-то это не самоцель потому что на самом деле мы не решаем задачу построения модели мы решаем какую-то бизнеса вую задачу и по сути дела для нас важен pipeline то есть некий бизнес процесс внутри которого вписано какой такой конгломерат этих самых моделей которые обладают следующими свойствами во-первых должна поддерживаться версия неровность всех компонентов которые участвуют в этом плане я чуть позднее расскажу что такое план с нашей точки зрения в этом плане должны присутствовать правило то есть данном случае правилам примеру есть такой чудесный в россии федеральный закон 115 о противодействии отмыванию доходов финансирование терроризма там 16 экранов идет только оглавление рекомендации центробанка это все довольно простые тупые правила которые банк может выполнить основную все-таки дан или не может выполнить с у него таких данных нет и бизнес-процесс например оценки какого-то заемщика или оценки каких-то финансовых транзакций подразумевают что этот поток данных который мы обрабатываем должен пройти через подобного рода правило либо какие-то иные и эти правила может достаточно простым способом сесть и описать аналитика он не dat ass in this там просто знает хорошо этот закон о но ли какой-то или какие-то иные наставления и он садится и на простом понятном ему языке описывает какие проверки должна пройти те или иные данные мы хотим строить каскады моделей как-то уже говорил то есть в у нас часто возникают ситуации когда вы разорвали для следующая модель она использует для своей работы значение полученные в предыдущих моделях вот мы хотим быстро проверять гипотезы при этом опять же повторюсь предыдущий ты лишь что дата санте ст сделал какую-то модель она крутится на бою она хорошо работает он по какой-то причине придумал лучшее решение он не хочет рушить устоявшийся рабочий процесс но он на тот же боевой трафик в боевой системе вешает свою новую модель которая на самом деле не принять участвовать в принятии решения но обслуживает тот же трафик считает какие-то выводы эти выводы где-то у нас прикапывается мы хотим чтобы все достаточно легко перри использовался потому что на самом деле задачи многие достаточно бывают однотипные какие-то компоненты особенность этих компонента связаны с какими-то с каким-то извлечением фичей либо с какими-то правилами соответственно если мы уже сделали какие-то кубики мы хотим эти кубики достаточно легким способом перетаскивать в другие pipeline и мы хотим мониторинг причем мониторинг мониторинга два вида первый это технически то есть если на у нас за тепло и на какие-то компоненты pipeline а эксплуатации должна видеть что собственно говоря целей компоненты происходит сколько на потреблять памяти сколько она есть циpкa что у него там не знаю с диском например либо еще какими-то прочими историями 2 момент это бизнесовый мониторинг то есть dat ass in this ты должен быть дан инструмент который позволяет ему абстрагироваться от технических нюансов реализации но позволяет ему на уровне проектирования конструирования своей модели определить какие метрики этой модели должны быть доступны в мониторинге то есть примеры там распределение фичи и результаты работы в колин гого сервиса и он просто определяет эти метрики и его не должно волновать как эти метрики долетят систему мониторинга и вот только должно волновать что он определил эти метрики возможно он определил дашборд внешний вид даже борды на которой ти метрики отобразятся загиб закрутилось запустился это дело на на прот это все за тепло и власти спустя там какое-то время эти метрики полились в мониторинг и он не имея доступа к пруду тем не менее может видеть что на самом деле происходит с его моделью что внутри еще одна история мы хотим тестировать все до чего можем дотягиваться до тестировать и первым pipeline paypal тестируется но на консистентной учитывает специфику этого pipeline это по сути дела некий вычислительный граф соответственно мы нашли понимать что этот граф реализуем что мы можем его обойти и найти из него выход в конечном итоге 2 что этого графа есть компоненты и эти компоненты состоят из разного рода модулей и все эти модули должны проходить какой-то юниты интеграционное тестирование и все это должно происходить опять же достаточно прозрачно и легко дата санте станет дергая его по мелочам то есть человек описал свой модель человек описал он или кто-то еще описал тесты все это дело положили в git лап pipeline на встроенный континента гришин поднялся это дело от тестировал показал результат и если все хорошо побежали дальше не хорошо давай начинаем все сначала это go to those in this должен сосредоточен быть на нам на модели и не знает что под капотом для этого ему дается несколько вещей первое это api для интеграции с ядром самой системы через шину данных при этом от него требуется в данном случае описать что у него будет на вход что у него будет на выход из его модели ему нужно описать точки входа и точки стыка с разными компонентами внутри самого pipeline и дальше собственно говоря писать там грубо говоря он обучил где-то модель у него появился какой-то артефакт не зная там файлы кгбуз то либо пекли и у него есть какой-то джеку тэр для работы с этими артефактами и это он должен интегрировать внутрь компоненты pipeline а мол должно быть даваться достаточно легкая и прозрачны для него api для мониторинга работа про него я уже как бы рассказывал dat ass on this то должна быть даваться инфраструктура достаточно простая и прозрачная для него для интеграции с источниками данных и сохранением результатов работы у нас часто история что работаю с какие-то модели спустя какое-то время приходит аудит и говорит ребята мы хотим поднять всю историю работы данного сервиса и для того что проект что он работал корректно что не было к примеру какого-то фродо например с вашей стороны соответственно должны быть достаточно простые инструменты чтобы любой аудитор смог знающий там к примеру из клей мог залезть в специальное хранилище и посмотреть как на самом деле это все жила как это работало какие решения принимался и почему такое решение принималось мы заложили основу по две истории достаточно важных для нас 1 так остро аграрной то есть мы дали возможность использовать механизмы сохранения всей клиентской истории того что происходило с клиентом в рамках тех под бизнес процессов которые реализованы на этой системе для чего это делается к примеру ездить скоринговая модель приходит заемщик его оценивает ему выдают например кредит он начинает платить наш процесс интеграции предусматривает что мы получаем информацию о тех платежах которые приходят мы сохраняем при этом у нас могут быть какие-то внешние источники данных например деньки платформы от которых мы получаем поведение человека в сети поведение человека там в мобильных каких то устройствах и это все может оказать влияние на какие-то all these его модели на скоринговые модели и в дальнейшем если к примеру человек просрочил какой-то платеж мы можем предсказывать что это не злой умысел какой-то у человека от момент возник какие-то проблемы и с ним на самом деле можно сделать там soft collection с ним спокойно и мягко поработать и не прибегая к каким-то жестким мерам или наоборот человек второй раз пришел за оказанием какого-то сервиса и его как повторного клиента зная всю его историю которая наглядно и просто достать именно dat ass on this той самой модельки можем его поспорить уже в каком-то light режиме и вторая история то как раз детекция на мале мы постоянно сталкиваемся с таким очень сложным миром например всякий микрофинансовые организации когда добрые люди нащупывают слабые точки внутри ускоренную score card этих организаций и умеют организовывать массовый фрод особенно автоматический вот концепция кастами разговорной концепция как раз быстрого и легкого доступа к потоку данных которая идет через модель позволяет строить довольно правда довольно просто строить разного рода детекция задирай аномалий которые могут частью фродо обнаруживать в момент его вот массово возникновения как все это у нас устроено ну не мудрствуя лукаво мы взяли в качестве мы судьба собачка фку подумал что решение не самое плохое во многих наших клиентов то система используется эксплуатацию умеет с ней работать мы тоже умеем с ней работать сделали сегмент данных собственно говоря через нее здесь еще нужно понимать такой момент что часть компонентов из которых построены наша система не могут вообще от нас использоваться в самой компании уже и мы не строим не закатываем заново еще какую-то систему которая у них используется мы можем перес пользовать то что у них есть внутри у нас есть чудная когда съехал почему-то экран вот чудная система под названием data storage данном случае что здесь имеется ввиду это хранилище которое как правило уже есть у самого клиента это может быть в ходу по тому же быть какие-то реляционные не реляционные базы данных мы умеем нормальные нативно из коробочки работы с вич dfs мы умеем работать с high вам сам палой взгляд блюмом из-под гриссом данных хранилища мы рассматриваем как источник для каких-то витрин данные поступают в это хранилище проходит через наш этель либо итиль заказчика если на него существует мы строим какие-то вид рынке которые в дальнейшем начинает использоваться внутри моделей по сути дела до постройки для нас используется в режиме readonly следующая история это уже нашей разработки под названием black board название было взято в общем то с одной довольно в странной практике математика в тридцатых сороковых годов это по сути дела менеджер pipeline of которые живут в этом в обмен системе у него есть некий мы-то сторож в котором сохраняется сами pipeline и и сохраняются конфигурации которые необходимы для инициализации всех компонентов живущих системе pipeline of по сути дела вся работа системы начинается именно с бигборда в каким-то образом там чудом pipeline оказался вместо старриджа billboard спустя некоторое время это понимает вытаскивает актуальную версию pipeline а инициализирует ее и посылает сигнал внутрь кафки с криками рта смотрите я принес радуйтесь есть runtime environment runtime varmint у нас построен на докеров и может быть растиражирован на марсе серверов живущих непонятно где в том числе как бы в приватном облаке заказчика из коробочки там идет основной фактор это инициализатор это по сути такой некий джин он умеет делать деве еще он умеет строить компоненты разрушать компании компоненты больше ничего не умеет он получает команду от бомбарда на тему того что вот тебе pipeline paypal а не нужно запустить вот на таких то серверах с такими-то ресурсами в таких-то количествах работай дальше начал он собственно гарри начинать это делать запускать вот что из себя представляет так трактор здесь имена в концепции математической то есть это некая функция которая по сути дела на вход принимает один или более объектов имеет алгоритм изменяющие состояние этих объектов и на выходе порождает либо новый объект либо изменение состояния существующего объекта сами акторы о существовании иных акторов не знают единственная сущность которая знает что помимо какого доктора существует весь pipe анселом это black board он отслеживает состояние выполнения всех актеров внутри системы и ведет актуальное состояние которое выражается в результате на мониторинге как мониторим всего бизнес-процессов в целом вот соответственно акт инициализатор порождает докер контейнеры во множестве в разных местах со своими акторами все это дело расплывается и даже иногда запускается помимо этого значит actor умеют работать дата сторожем и акторов есть дача в самой системе есть такая компонента под названием event старриджа в качестве вентс тораджа мы используем кликал задача его достаточно простая вся информация которая проходит которые меняются между собой акторы через кафку оно сохраняется в клик хаосе делается это для несколько вещей первое как я уже говорил это для дальнейшего аудита то есть здесь по сути дела лог того как обработка работает сам pipeline вторая история кастами journey здесь могут быть разработаны и акторы которые видят изменения самого logo pipeline а и в этот момент перестраивать на лету какие-то витрины которые нужны для работы модели и либо на бароном компонентов с правилами уже внутри самого pipeline а то есть это некий такой непрерывный процесс изменения данных которая с которыми работает сам pipeline monitoring у нас построен на прометею си достаточно примитивно actor удается базовая пион закрытым не прыгнут прозрачен достаточно разработчика самого автора посылает в кафку сообщения с какими-то метриками сказки про metals учитывает сохраняет своим старриджа и для визуализации всей этой истории мы используем графа ну вообщем то не никакого официально все достаточно примитивно вот плюс есть какая история у нас здесь на самом деле есть два две точки интеграции 1 . интеграция это с источниками данных проходящих через эти ель и прикапываю щихся в дата столь же ее там . интеграция когда сервис используется уже потребителям данных примеру это какой-то скоринговые сервис мы взяли apache сервис mix зачем по опыту эти точки интеграции они как правило однотипные там прям с однотипными протоколами это либо флоп либо rsl сервис либо в редких заселенных случаях это какие-то очереди то есть мы не хотим каждый раз разрабатывать какой-то свой конструктор или свой какой-то сервис для того чтобы сгенерировать очередной слаб сервис мы берем сервис микс мы описываем всд в котором конструируем высотных говорим модель данных этого сервиса и методы которые нам существует подписываем роутерам внутри сервис микса он соответственно едет сам сервис единственно что добавили мы от себя здесь у нас есть такое достаточно хитрая синхронно и асинхронно и преобразование потому что все запросы живущие внутри система не синхронные идущий через мой съебался в массе своем скоринговые сервисы они синхронные то есть поступает запрос сервис микс там через rift либо слаб в этот момент он проходит через наши битвой который разбивает то есть он посылает он сохраняется знания о той сессии в типе цессе которые момент установлена сообщение он посылает в кафку сообщение пробегая через какой-то pipeline порождается решение при этом решение о самом деле может быть и не быть то есть пример что-то отвалилось либо у нас есть жесткий слой на принятие решения и данный битвы отслеживай что окей я получил запрос он пришел мне в другой топе кафки либо мне ничего не пришел но у меня сработал триггер по таймауту соответственно дальше опять идет преобразования синхронного в синхронной и в рамках таджикские песни сессии идет ответ потребителю ска результатом какой-то работа это может быть ошибка это может быть там нормальный какой-то прогноз в этом месте кстати мы съели забавную собаку опять же благодаря великому и могучему танцор су мы использовали сервис микс одной из последних версий а кафка у нас была там каких-то предыдущих версий все прекрасно работала в этот битвы мы даже не писали мы использовали мы его написали но основываясь на тех кубиках которые были уже всерьез миксе и тут выходит новая кафка мы радостно ее схватили потащили себе у него много вкусного замечательного и тут выяснилось что поддержка тех лидеров внутри сообщение в каске которые раньше существовали она они изменились и битвы и внутри seras mi casa больший мир вот не умеет вот ну потратили массу времени на то чтобы понять вообще происходит и в результате напилили свой готовый которые умеют работать с новыми версиями кафки написали разработчикам сервис микс они сказали ну как прекрасно что есть такая проблема спасибо мы обязательно вам по сочувствуем следующих версиях вот и поэтому мы вынуждены сейчас этой истории следите и регулярно что-то менять вот и инфраструктурная история это гид лап с дипломом и пользу им практически все что в нем есть это собственно говоря сам репозитории кода это континент и грешен continues delivery pipeline которых существует внутри гид лобо это registry который мы используем а ведение реестра докер-контейнер в которые у нас собираются в этом я чуть попозже расскажу того компоненты которые мы разработали сами которые живут внутри этого pipeline а это облако борт то есть управление жизненным циклом самого pipeline а это фьючерс трактор извлечение фичей это в меру простая штука который мы говорим что мы на вход получаем вот такую та модель данных это модель данных описаны например том же сон схеме мы и затем исполнять их данных за выбираем те или иные поля мы их мы пируем в такие-то значение ну к примеру там вы получаете дату рождения клиента вам на самом деле дата рождения нафиг не нужна вам нужен только его возраст вы вычисляете этот возраст этот возраст до держать тем используется как фича в работе каких-то моделей плюс fitch extractor отвечает за обогащение данных то есть примеру вы работать еще с каким-то спаррингом который живет где-то вдалеке там регулярно мимо вас пробегает от и вы хотите к нему к нему обращаться в реал тайме к примеру и обогащать какой-то объектные свойства того субъекта на котором вы работаете обогащать его знанием об этом вскоре нге собстна говоря сделано в physics тракторе третья история это руды стенджер это собственно говоря некий язык описание мы на самом деле даже не стали выдумывать ничего нового мы взяли один вопрос портные продукты на базе его немножко и вот depileve до нужного нам состояние породили систему которой можно простым языком человеку в знакомому с повторением блок с кем-то мы files и так далее описать те правила которые нужно проверять внутри системы вот это из 100 машин для рынка джен это исполнение моделей м.л. в данном случае здесь просто компонента которая позволяет запускать некий зик и лютер позволяет инициализировать обученную модель и подаватель на фото и данные данный у нее на фут забирать при этом здесь есть нюанс что на самом деле модель то может исполняться как локально к примеру там не знаю candida обученных за boost там или не важно обычный загрузка там приходит запрос он там залез модельку отдал какой-то ответ может быть более сложная история когда это нужно запустить на спарке прошерстить по каким-то витринам что-то посчитать то есть в данном случае мы от этой история развязаны это спокойно может исполняться как на спарке это спокойно могут исполняться как локальный какой-то модуль есть 10 джин engine это движок принятие решение вот эта штука для чего по сути дела это выход из графа у вас может быть построен каскад каких-то моделей разные ветки принятия оценки там того же заемщика и в каком-то месте вы должны принять решение давать ему денег или не давать ему денег и здесь должны быть набор простых правил почему давать пример autocad autocad отсечка ниже или выше значение которого вы не даете у вас то может быть анализ милтези моделей что если вы прогнозируете что можете заработать на нем такую-то сумму денег то получается прогноз меньше то нет смысла с этим клиентом где отсюда вот эта штука которая отвечает на вопрос поставлен перед pipeline если это скоренко сервис к примеру там дать денег не дать денег как выглядит pipeline в таком вычурно мне в синтетическом примере примеру есть у нас скоринга сервис есть два набора входных данных это анкета заемщика который сам заполняет эта кредитная история с бюро кредитных историй который повествует о финансовой дисциплине разработчик этого pipeline описывает вич extractor то есть какие свечи какие данные вы извлекаете из анкеты с кредитной истории в каком виде в этот затем подаете в модель у него есть набор правил который например проверка в тот факторов что паспорт который указал вообще существует валидный код и у него 3 дата рождения правильная и ему старше 18 лет поэтому это мы можем в том же steam сделать описывается набор модели к примеру зависимости от типа этого ящика он может проходить оцениваться одной моделью или другой моделью потом вы подумали придумали еще одну модель которая свою очередь используется и спорить результаты работы предыдущей модели тоже здесь описываете вставляете в pipeline формируете некий 10 женой джен в котором записывать и правила принятия решений на основании результатов работы модели и правил и порождаете какое-то решение вот все это дело мы описываем с помощью я мало у нас нет пока на текущий момент никакой визуальные формы описание все это дело мы думали об этом но сил времени ума сделать это нам пока не хватило поэтому мы как люди живущие в консоли мы это сделали вот с помощью текстового редактора языка яму на при этом здесь есть важная один нюанс что разработчик этого pipeline а он написал все компоненты компонентов он указывать тип этой компонентов unix through the rules модель десь engine engine он указывает его имя и его версию и это очень важная история потому что на основании этого имени этой версии затем генерируется докер-контейнер который является ссылкой на реджистер где живут эти докер контейнеры и actor инициализатор которых вызывает он stopt обращается по этому имени поэтому если здесь знак ася чить с именем тот с таким же точно именем в дальнейшем при сборке будет сделанную докер-контейнер это сможет остаться на века вот на чем все это сейчас сделано мы из-за того что хотели сделать это как можно быстро мне были уверены в том что мы делаем никого не полную фигню мы стали писать это дело на питоне посчитав что мы его знаем и умеем на нем писать достаточно быстро поэтому фьюче экстракторы правило модели и всем нужен и мы все породили на питоне у pipeline мы нарисовали ноября здесь мы не доделали еще то есть сохрани нужно хранить описание системного окружения в митоз торджи это делается руками то есть если у вас runtime environment растиражирована 10 серверах the blackboard и должен знать что он этот pipeline должен запустить на этих 10 серверах вы можете в принципе указали что какие конкретно компоненты где вы можете запустить то есть модели крутятся на это их сервера правила крутится на этих серверах все точка входа подключения кафки вот адрес такой топор такой-то топике таки это все пока это делается руками вот все артефакты сохраняются в git лобби это наш такой корневой инструмент нас очень любит devops он у него молятся каждый вечер а ты старательно его допиливает плюс вся все развертывание изначально инициализация делается ansi блум вот оказался что это достаточно сложный процесс в принципе большую инфраструктуру там условно большой инфраструктуры там примерно пару десятков серверов она разворачивается за несколько часов опять же наш замечательный devops и написал порядка 50 тысяч строк кода нанси были вот это очень ужасно наверное а как выглядит процесс тепло и есть pipe and guide лобби разработчик за к метил это дело в git лап вся и в процесс увидел что у него появился новый артефакт прогнал тест и породил какие-то результаты если все хорошо пошло дальше он порождает битва про нир так компонента самого гид лобо которая поднимается где-то на какой-то специальной машинки в ней конструируется докер контейнеры всех компонентов описанных по японии и если вы ему удалось собрать все это дело прикапывается в режете в чем здесь плюс в данном случае с дагерами потому что мы действительно хорошо развязываем ся от различного рода проблем с version ностью у нас каждым докер контейнер для каждой компоненты может существовать своя версия нужных ему библиотек вот итогам вся pipeline сохраняет само описание pipeline а в бизнес процессов место старик с которым работает blackboard blackboard регулярно pulid этот мэтта вторич увидел новые изменения достал право лидировал их вот разослал сообщение автору инициализатор у он свою очередь подтянул докер контейнеры все это дело радостно спустя несколько минут как правило растиражирован поднял запустил при этом в чем момент еще что как раз фактор инициализатор он получает от барда из ментов тораджа все необходимые для запуска конфигурационные параметры то есть будь там какие-то подключения к базам данных подключения к кафке подключения к системе мониторинга и так далее из любая какая-то информация которая давно быть конфигурируем и до докер-контейнер изначально про нее ничего не знает он свято дело получит момент инициализации ну и считается что все загорелось лампочками в мониторинге появились эти докер контейнеры засветились и pipeline готов если это может эксплуатироваться изначально мы разрабатывали это дело в не читала уж они потом мы научились это деплоить в амазоне научили тепло и те скалы и хотя опять же скалы и мы не очень любим по определенным причинам вот и но главная история с которой мы выходили в нашим заказчикам все это дело может крутиться внутри его периметр то есть весь pipeline весь инфраструктурой the pipeline а она находится под его управлением нет ничего каких-то левых вы дырок наружу все крутится внутри защищенного истории насколько все это быстро но тут сложно оценивать на самом деле потому что формальные критерии они сегодня они непростые то есть пример самой сложной pipeline который мы делали на real-time а в запросах было такое что было два фьючерс трактора входных данных причем размер входных данных это было порядка чуть меньше одного мегабайта то есть за пролетала гигантская джонсон портянка в которой содержалось какое-то колоссальное количество данных а примерки и для заемщиков было 8 моделей соответсвено 8 экземпляров малин джона все они крутились на базе где пусто было 18 блоков наборов правил по 115ф уже вот в этих 18 блоках было описано порядка тысячи правил проверки на отмывания доходов вот и один здесь уже не джон в результате сейчас это сервис крутится обрабатывает примерно 200 запросов в секунду на принятие решения проход все это история через два ключа экстрактора 8 моделей 18 блоков и денди сезон и джим занимает у него среднем чуть больше 1 секунды вот что сейчас на мой взгляд плохо нас нет никакого discovery ресурсов то есть мы не можем автоматически отслеживать что у нас отвалились какие-то сервера и поэтому эти серверах где плоть мы не можем и об этом том что он отвалился в момент диплому заем когда туда диплом и у нас это не получается вот над этим мы сейчас работаем все ресурсы мы по сути делал руками описываем mitas тораджи у нас нет визуального проектирования pipeline а то есть мы хотим внедрить некий движок похожий набитыми bpm вот для того чтобы разработчик этого pipeline а не писал в ямале совершая кучу синтаксических орфографических ошибок вот а мог визуально дергая кубики доставая из репозитория какие-то готовые кубики рисовать всю эту историю мы проводим сейчас эксперименты на то чтобы actor был написан не только на питоне но и на гравано скала inoar то есть самое труда но написано на питоне но так как actor это на самом деле независимая компоненты может быть написано на чем угодно и так как и она исполняется независимо от всей системы в целом это нужно обеспечить достаточно точнее обеспечить набор api на этих языках для того чтобы разработчик этого pipeline а мог акторы писать на том языке которым он знает вот что в итоге мы на всю эту разработку сумме то есть на первую версию потратили порядка одного месяца работы двух человек потом мы до продуктового решения пилили его порядка полугода результате мы получили некий конструктор которым сами с трудом мы учились пользоваться в трудом почему потому что было несколько итераций подходов к тому как должен выглядеть этот конструктор и вот то что я сейчас рассказывает о по сути дела нынешнего состояния которое не исключено что может уже еще измениться вот но в ходе попыток наших собственных эксплуатации этого конструктора мы натыкались на различного рода любопытные грабли обходили их в результате научились вот мы наверно осознали что сделали его не зря и нам эксплуатацию тех клиентов у которых эта штука сейчас используется в действительно на мой взгляд стало легче жить процесс понятен для разработчиков процесс понятен для эксплуатации мы исправили ушли от кучи проблем связанных с того как этот несчастный ноутбук вывести на пруд как эту модель мониторить как эта модель деплоить вот пожалуйста все вопросы спасибо за доклад большое хотелось бы узнать подробнее про актер это демон отдельная программа скрип сколько он съедает на машине лидер и очень уж этом брокеру да это отдельная программа то есть скрипт программа не знаю имеет все это программа в данном случае на текущий момент это набор программы на питоне которая запускается в докер контейнеры со своим окружением вопрос сколько чего оно отъедает здесь решается либо никак в том плане что ну если у вас какая-то модель которая должна есть максимально большое количество ресурсов и вы просто подними выделяете эти ресурсы либо вы на уровне докера говорите что я хочу чтобы там был один циpкa там один мегабайт памяти и все и больше ничего не будет выделено то есть это задача больше инфраструктурная она решается на уровне конфигурации контейнера но вторую просторную акторы каким образом они меняют конфигурацию докера если он как хочу не знаю 205 6 мегабайт оператив вы поставить да а у меня их нет ну как бы что произойдет как то значит как такого рода конфигурации вообще инфраструктура на сейчас сохраняется в mitas тораджи вот в чем говорю проблему что мы это записываем руками то есть мы в моменте проектирования мы проектирование pipeline а мы говорим в толпе и вот это должно хватить столько-то память вот это вернулся во столько-то циpкa то есть разработчик либо эксплуататор да как правило именно эксплуататор всей этой системы он задает такого рода конфигурации если он скажет укажет памяти льва циpкa докер-контейнер больше чем есть физический докер-контейнер повтори стартанет и своего лица ошибка на свалиться в мониторинг то есть ответ на это потребует изменения самого pipeline а спасибо же большое спасибо за доклад а у меня вопрос про билды актеров можете вернуть пожалуйста слайд вот так наверное да да да да и он самый вот смотрите вас есть ямал описание pipeline есть в pipeline в этом описании наверное некоторые такие узлы которые рассказывают что в этом месте нужно дернуть какой-то actor ну передать ему полу какую-то эмаль модель вот первый вопрос pipeline целиком уходит в докер-контейнер второй момент как в докер контейнеры оказывается натренированная модель то есть она хранится уже будущем да значит во первых в докер-контейнер уходит не весь pipelines докер-контейнер уходит отдельный компонент это pipeline а второй натренированная модель человека где-то натренировал то есть эта система не про тренировку модель это проект запуск положил ее в git лап то есть там отдельно на файловую систему гид лобо лег какой-то мега бинарник которые в дальнейшем как раз в момент сборки докера он доставляется в сам матч докер-контейнер а то есть вот этот вот я могу files pipeline am он реально близок к исиде битла pipeline у и он рассказывает как сбил дать это окружение как провязать связь а сути дела да понятно спасибо спасибо за доклад скажите пожалуйста как у вас а реализовано оркестровка докер контейнеры можно уточнить что в данном случае вы имеете ну распределение нагрузки по кластеру как сколько инстансов докер-контейнер поднимает яркина на текущий момент это проблема над которой мы сейчас вот в новой версии работаем по сути дела она делается в ручном режиме то есть на уровне проектирования pipeline of my toes тораджи администратор системы указывает где и сколько контейнер поможет запустить в каком количестве ну сколько до нас каких серверах может запустить сколько экземпляров каждой компоненты внутри докер-контейнер а то сейчас это делается руками собстна гарая в конце говорил что мы хотим сделать некий discovery ресурсов для того чтобы это было более менее автоматизировано вы планируете использовать кубинец с мы думали про это дело и наверное до этого доползем пока еще маленькие зелененькие хорошо скажите вот модели запрос на исполнение принимает через кафку правильно но компонентов которые аризона модель дауна слушает набор топиков на самом деле то есть она может ни один топик слушать вот и получив от нее набор к и входных какой-то множество объектов который необходимо для исполнения уже в этот момент начинает исполняться этот последний вопрос как модель у вас подключается к базе данных это опять же это через кафку да смотрите здесь какая ситуация изначально я как поклонниках мы математических акторов я планировал то так что актор ничего не знает про база данных он просто посылает запрос еще какому-то автору через кафку который умеет работать с базой данных он свою очередь данные ты получил вернул через кафку назад у нас есть такая версия она даже работает но она работать не оптимально то есть очень много накладных расходов на текущем есть на небольших задачах это хорошо на каких-то больших задачах но требует состроить такую значительность кластер кафки чтобы он сидел обработал поэтому мы здесь схитрили построили костыли в внутри макак классов которые окружают модель есть соответственно некий гибели р через которое он подключается к нужной базе данных спаси большое спасибо за доклад хотел спросить про blackboard рассматривали возможность использования airflow вообще и рф о мы используем у нас например лифте гель который построен в качестве scheduler а как это ромеро используется как раз airflow backward по сути дела история очень похожа на r flow вот но отличающиеся там в мир в мелких технических нюансов есть потенциально в принципе может быть вам про тот открыл игра думаю может быть мы выкинем blackboard и сделал просто на самом деле изначально когда все это дело проектировался нас не было опыта в airflow он появился в поздние поэтому у нас по родился 5 в некий собственный велосипедик понял спасибо спасибо за доклад вопрос такой вот вы подключитесь к базе к базам данных вы говорили что у вас разные коннекторы вы можете с разными базами данных работать скажите вы с ними вы писали какие-то обертки для единообразия работы с базой далее затачиваете под каждую они нет есть как раз общий класс ноги bel air в котором унифицированный интерфейс и работа с базами данных но под каждым у них скрывается еще своя реализация сова коннектор у меня такой вопрос все классно спасибо за доклад на вопрос как вы с попапами работаете вот вам начали данные плохие сыпаться на вход apple и развалились или вам одессе арчер положил плохой бенарес плохой моделью и она начала хреново вскоре вот как раз для этого мы изначально все от этого вылезла что это была общая практика то с чем мы столкнулись поэтому мы прикрутили мониторингу эту историю то есть обязательное требование желательно чтобы разработчик моделей компонентов кита pipeline а он делал мониторинг соответствие мы видим в мониторинге что модель начинает себя вести не так как от ожидала то есть сама эксплуатации как правильно понять не может это может понять разработчик этой модели поэтому ему отдельно из закрытого периметр выносится этот экран мониторинга ну просто визуально глазами видел что у него пошло что-то не так если есть технически какие-то сбои да например там бинарник ли новый так далее то в момент инициализации это станет понятно это опять же породит некий alarm но вот если не посмотрел все дальше там деньги потеряли мой с 1 sl он не посмотрел дата вы потеряли деньги все печально но тут вопрос уже больше дисциплины и регламента эксплуатацию самой окей а если входные данные то есть вам начали просто складываться какие-то штуки которые через ваши rules и стали проходить а модель на них стало ломаться вот как раз это вопрос мониторинг как мы видим что похож ну это не так это повод начинать разбираться то есть есть две точки до 1 мониторинг мы увидели что что-то пошло не так вторая точка это клик austin старичку да все события которые пролетают через pipeline сохраняются и ты можешь туда залезть и глазами посмотреть а почему почему я поступил в этот момент именно так то есть у вас просто не критично просто и бывает сервисы что если она упала так это конец света а тут вы можете разобраться по тюнеру что значит мы никогда не критично если она упала то для нас на при нашего клиента они прекращают давать деньги это вполне себе критично но здесь нужно понимать почему такое произошло то есть это технически какой-то косяк что-то не так сконфигурировали бы еще что то либо начался косяк в данных вот здесь еще в чем мужчин мониторинг и все и в самом они толики настроены и детекции аномалий и настроены какие-то определения пороговых значений когда мы понимаем что у нас модель должна работать на тестах примерно вот таким образом если она внутри моей мониторинг уже на bayou показывает другое поведение the alarm эксплуатации и привлечения уже разработчиков попытки пони что там вы откатываетесь при этом то есть общий от пошло не так и вы быстро быстро отката вот здесь фишка в чем заключается то есть ну пропустим факт что когда вообще ничего не было да вдруг у нас создал какой-то pipeline который работает сделали новую модель обычная практика такова эта модель не идет в принятии решений он остается внутри этого pipeline а просто еще одно ветвление которое не уходит здесь уже не джон и эта модель порождает только логе в эванс тораджи и полового рождает событий в мониторинге и дата санте стон видит ну эксплуатация тоже они видят что на том же самом потоки трафика что-то пошло не так то здесь не нужно откатываться на предыдущую версию здесь можно просто убить из pipeline а этот контейнер и начать разбираться почему такое произошло"
}