{
  "video_id": "bbdk2UGkWR8",
  "channel": "HighLoadChannel",
  "title": "Просто о сложном как работает драйвер распределенной базы данных YDB / Алексей Мясников",
  "views": 727,
  "duration": 3205,
  "published": "2023-10-06T07:22:18-07:00",
  "text": "Все любят и сквель ну и скрильку классная это декларативный язык Вы просто пишите что вы хотите и пусть там СУБД сама разбирается делает то что вы хотите Можно даже бенчмаркать разные СУБД чтобы они там одна лучше делать другая хуже и когда мы говорим об SQL почему-то забывается всякие вопросы связанные со сложностью того чтобы оно наконец заработало Особенно это касается больших систем и Меня зовут Мясников Алексей я старший разработчик в команде vdb я вам буду рассказывать про особенности работы драйвера для распределенной системы управления базами данных в idb часть доклада про вообще общие проблемы работы с распределенными базами данных а часть специфика нашей СУБД для того чтобы понять сложность работы с распределенной базы данных надо вас подвести подвести к этой сложности и я сделаю небольшой обзор как мы работаем с традиционными базами данных подведу к тому Почему мы вводили такие немножко специфичные покажу какие-то общие места какие-то нюансы наши обосную требования к драйверу и проговорю про API vdb конкретно нашей СУБД и мы немножко про дизайном драйвер для распределенной базы данных Итак как мы работаем с традиционными базами данных У нас есть хост базы данных есть приложение и чтобы к нему подключиться нам по сути нужен только Host hostname Иногда нужно указать порт Иногда нужно указать Database или некий скоб или Space чтобы ограничить те данные с которыми Мы работаем И все хорошо когда у нас небольшая нагрузка если нагрузка растет то велик шанс что хост нашей базы данных перестанет справляться и тут проблема которая ну традиционно решается двумя путями вертикальные масштабирование и горизонтально вертикально все мы знаем там можем докинуть оперативки ядер процессора HDD на SSD поменять но все равно в какой-то момент времени мы упремся либо в свой бюджет своей компании либо вообще физические ограничения технологий которые существуют на данный момент и так или иначе мы подойдем к тому что нужно горизонтально масштабироваться вот здесь на слайде один хост базы данных распилен на 3 я специально здесь использовал максимально абстрактное понятие хост база данных потому что за ним может скрываться как Праймари secondary репликации readwrite ridonlip реплики может быть какой-то шортирование с диапазонами ключей и тут уже сложности возникает например сложность Как подключиться Мы можем как-то клиенту клиентскому приложению сообщить что сейчас у нас три Хоста базы данных раскатать конфиги например консулом все приложение стартовали подключились как-то работают сложности опять возникает когда нам нужно еще немножко поскелиться горизонтально или наоборот изъять хост например для maintends для какого-то обслуживания замены дисков опять Мы вносим изменения в конфигурацию опять раскатываем конфиги на клиентские приложениях или как-то на горячую сообщаем что нужно переподключиться другой подход заключается в том что мы можем Хосты базы данных спрятать за DNS и Для клиента это выглядит просто То есть он подключается на какой-нибудь example.com обращается к DNS серверу получают списки IP адресов и может подключиться к одному из хостов для клиентского приложения Это довольно просто и точно так же просто добавить Хосты в конфигурацию мы просто в DNS записи Добавляем еще один айпишник или удалить Ну сложности в том что мы за DNS можем спрятать там 25 IP адресов версии 4 и еще меньше ip-адресов версии 6 по дефолту определенная кунг-фу Можно побольше там спрятать но так или иначе это не масштабирование на тысячи хостов баз данных если другая проблема у нас абсолютно нет никаких гарантий от о том насколько часто Клиент будет перерисовывать вот этот вот fuden Full qualifi domain То есть если клиент один раз при подключении узнал ip-адреса и больше никогда не не оттудализирует эту информацию то велик шанс что со временем жизни приложения ip-адреса станут не актуальными продвинутый вариант подключения к базе данных это через балансеры Для клиента это тоже простой относительно способ То есть все клиентские приложения подключаются к некому интрипоинт А этот repoint является балансером L3 или L7 с этим способом можно очень мудро распределять нагрузку между хостами базы данных и все хорошо Но балансеры это отдельный сервис он достаточно сложен он требует каких-то инженерных усилий чтобы он хорошо работал распределял запросы между хостами баз данных и другое ограничение что весь трафик льется через балансер то есть мы не можем массивную ставку данных делать непосредственно в базу данных так или иначе упремся в пропускную способность балансера добавление Хоста или удаления Хоста в случае балансеров это довольно простая процедура она выполняется на горячую как только балансер узнал о том что у нас изменилась конфигурация хостов баз данных просто направляет трафик на актуальные хосты Так мы подошли к тому что такое войти би работает не один не два ни единицы хостов имеет под собой в кластере от 1000 и работать с такой СУБД видимо нужно как-то иначе пара слов Что такое тебе распределенная SQL база данных созданная для транзакционных нагрузок хорошо горизонтально масштабируется обеспечивается гарантией в нескольких зонах доступности вы тебе разрабатываем разрабатывался довольно давно внутри Яндекса и мы жили в условиях когда примерно все может отказать и научились обеспечивать работоспособность и автоматическое восстановление в случае отказов Кроме того в itb поддерживает некоторые алапс сценарии для аналитических запросов также выдебе реализуют координацию распределенных систем и доставку сообщений вот эти вот фичи нам позволяет говорить и позиционировать себя как платформа данных то есть не только про таблички А вообще про хранение передачу обработку данных есть свой сайт вы тебе этого пон собственная база данных соответственно все исходные тексты можно посмотреть в githubby У нас есть свое русскоязычное англоязычное сообщество кластер vdb с точки зрения клиента выглядит как набор нот в нескольких дата-центрах клиенты подключаются ко всем нодам одновременно и выглядит как отношение многих ко многим надо сказать Наверное Что такое нодовый db но давай тебе представляет собой исполнительный узел в кластер vdb может быть представлена виртуальной машины подам cubernetis или отдельным самостоятельным процессом на самом деле мои коллеги когда рассказывали о внутренностях vdb там было много страшных умных слов что у нас есть слой хранения компьютер всякие координаторы таблетки и прочее с точки зрения клиента это не видно клиент видит вот какие-то ноды особенностью нотвой db с точки зрения клиента это то что ноды однородные то есть примерно Если ты пришел на любую ноду badybit и получаешь примерно тот же самый функционал ноды vdb волатильные нет гарантии того что надо будет жива сколько-то времени она может быть изъята эксплуатации или добавится новые ноды вы тебе в случае если кластер является мультитентным разделяет На физическом уровне ноды для разных баз данных для того чтобы нагрузка на одни базы данных не влияла на клиентов других баз данных но давай девиз глазами клиента выглядит как эвку д н плюс спорт в кудрян фу квалифида майнэйн свой надо общаться через Джерси соответственно бодибил поддерживает динамическое расширение освобождение лишних ресурсов надо заметить что в больших системах примерно все может отказать даже если вы имеете бесконечно надежный элемент в системе то как только этих элементов становится много то вероятность отказа сильно не нулевая и разрабатывая его db в этих условиях надо смириться с тем что отказы не просто возможны они будут и поэтому клиент водили должен это предусматривать также надо отметить что vdb это база данных которая эксплуатируется в режиме 24 на 7 без остановочно какие-то ноды могут выниматься для обслуживания Ну например для замены дисков или установки свежих версий программного обеспечения серверного в идеальной картине мира клиенты должны такое переживать незаметно я писал какие-то нюансики связанные с vdb и мы можем в принципе уже сформулировать требования как должен работать драйвер то есть некая программа Библиотека или пакет который упрощает жизнь клиенту работающему с такой распределенной базы данных Итак драйвер bdb драйвер распределенной базы данных должен переживать отказ на ты отказ дата-центра должен быть готов к транспортным ошибкам к серверным или каким-то логическим ошибкам а также драйвер должен реализовывать клиентскую балансировку То есть все запросы из приложения должны примерно равномерно распределяться между известными нодами vdb и опять же драйвер должен быть готов к тому что сервер серверная сторона Может вмешаться в этот процесс То есть когда множество клиентов эксплуатируют один и тот же кластер с точки зрения отдельного клиента он может думать что равномерно распределил запросы но когда накладывается нагрузка от разных клиентов некоторые ноды могут быть перегружены и сервер в этом случае будет вмешиваться еще приходится наверное ввести такое понятие как пессимизация соединения Возможно это вычурно звучит на самом деле концепция проста если мы пошли в какую-то ноду и получили некоторую ошибку например overload и не надо пытаться в это в эту же ноду направлять запросы лучше Найди от этого не станет И так сейчас очередь запросов перегружена процессор в полку и надо дать возможности этой ноге разгрузиться поэтому мы с точки зрения клиентского балансировщика должны перестать туда направлять запросы выглядит это Примерно вот так то есть произошла ошибка мы записимизировали соединение и распределили трафик между неписимизированными соединениями Подходим к тому что такое vdb с точки зрения программных интерфейсов каждая нодовая тебе представляет собой совокупность джер PC сервисов все эти сервисы обеспечивают работу с таблицами сервисами координации там какой-то лимитирование доставку сообщений Вот то самое что в нашем понимании должна уметь платформа данных магия никакой нету каждый сервис что-то умеет и его функционал описан в соответствующих протоспехах на слайде есть ссылка на репозитории где эти проспеки выложены в данном докладе Я буду рассказывать только про два сервиса Про Сервис таблиц и сервис Discovery сервис Discovery это наш Source of trues это некая сущность которая знает об актуальном состоянии кластера Какие ноды есть в классе или в каких они зонах доступности каким базам данных принадлежат для того чтобы начать работать свой db нужно сходить примерно на любую ноду и со специальным запросом Discovery Listen Points и указать свою базу данных сервис Discovery вернет из всего кластера только те ноты которые принадлежат соответствующей базе данных далее мы можем уже подключаться напрямую к нодам сервис таблиц он оперирует основной такой сущностью Как сессия сессия это однопоточный стейт фул актер он достаточно легковесный долгоживущий и долгоживучесть как раз нам позволяет реализовывать механизмы серверной балансировки сессии имеют срок жизни опыт эксплуатации показал что у нас бывают клиенты которые создают сессию и забывают ее закрывать Может потому что они упали А может просто плохо код написан и поэтому не используемые сессии закрываются сервером автоматически по дефолту у нас это время жизни сессии 10 минут 10 минут не трогаем сессию она будет закрыта на ноги довольно много сессий можно создать потому что они легковесные но тем не менее ничто не мешает клиенту на создавать столько сессий что получите Лонг килт и примерно все будут расстроены и серверная сторона и Саппорт и клиент потому что не получит желаемого мы подошли к тому что в принципе уже есть вся необходимая информация чтобы спроектировать драйвера vdb распределенной базы данных У нас есть исходные данные У нас есть некий интрипоинт если это войди би который эксплуатируется в режиме serverless то есть плата за запрос то это будет верхний вот адрес если это Выдели в режиме ddkated то соответственно Нижний адрес начальный inpoint он может быть неким прокси-сервисом балансером Именно так мы внутри Яндекса долгое время использовали vdb потому что мы точно знаем где наши клиенты находятся это были только внутренние клиенты Мы точно знаем где находится нодовый db и использование балансера было довольно просто эффективно Однако Когда мы вышли в Open Source у нас а также в некоторых других случаях оказалось что нет некого прокси сервиса который может корректно с маршрутизировать запрос и мы поддержали DNS балансировку которая дает ip-адреса конкретных исполнительных узлов в ADB второй пункт что нам известно для того чтобы начать работать свой это имя базы данных например вот такое как приведено на слайде все данные известны мы можем инициализировать драйвер для этого выполняем запрос Discovery Listen Points указав имя базы данных нам вернется массив поинтов а также метаинформация например где эти in поинты расположены в каких зонах доступности Какие сервисы запущены на конкретных нодах получив список инпонтов нужно инициализировать клиентский балансировщик клиентский балансировщик это некий алгоритм который определенным образом выбирает следующего кандидата для запроса и чтобы не оказаться в ситуации что состояние кластера давно уже уехало нужно периодически запускать этот фоновый процесс и перезапрашивать Discovery listencoints чтобы иметь актуальную информацию о состоянии кластера по дефолту в наших драйверах это одна минута этого достаточно для того чтобы отслеживать изменения в кластере драйверы инициализирован он ожидает запросов попробуем выполнить запрос вот такой вот спросить название доклада из списка докладов на этой конференции параметризируя именем спикера простейшей реализации мы должны создать сессию выполнить запрос на сессии закрыть сессию запрос на создание сессии проходит через клиентский балансировщик который выбирает там случайно надул на слайде это надо идентификатором один успешный ответ возвращает идентификатор сессии это соответственно клиентское представление сессионного актера на Нади 1 в идентификаторы сессии также указан идентификатор воды на который физически эта сессия существует далее Далее мы все запросы должны направлять на ту наду на которой существует эта сессия соответственно успешный запрос мы указываем сессию сам запрос и параметры запроса и получаем успешный ответ это такой положительный сценарий бывает нюансы например когда мы пришли на наду 1 и хотим создать сессию а алгоритм серверной балансировки считает что надо один сейчас перегружена не надо там создавать еще одну сессию за счет механизма взаимодействия НОД vdb называемый интерконнект сессия может быть создана на другой ноге более свободной клиенту вернется успешный ответ но будет указана другая нода Это значит что следующие запросы направлять уже на на до 4 как вот здесь на слайде Ну и да направляем запросы на на до 4 есть нюанс А что если мы пришли с идентификатором сессии на ту на ту на которой этой сессии Нету тоже ничего страшного вы тебе интернет пробросит запрос на правильную наду и Клиент будет иметь успех но надо понимать что у нас серверные хопы хотите быстрее работать получать ответ надо отправлять запросы на правильном наду в конце Вот это наше простейшая реализация мы должны закрыть сессию Ну отправляем опять на то надул где эта сессия была создана вроде все просто может здесь все программисты и понимаем что оно вообще не оптимально мы создаем ресурс а потом его закрываем мы подошли к понятию Пула сессии это достаточно простое понятие Мы в конце не закрываем сессию А складируем ее в некий клиентский пул соответственно при повторном запросе мы вынимаем эту сессию из Пула и используем ее для выполнения запросов все круто но надо помнить что сессии имеют время жизни поэтому нужно выполнять для клиентского Пула сессий фоновый процесс типа Life То есть это запросы по сути не несущие Никакой пользы Кроме того что клиент сообщает что я еще знаю про эту сессию Я про нее не забыл я ее буду использовать сервер освежает информацию о последнем взаимодействии сессии и не закрывает ее какое-то время дальше мы вот с оптимизировали один хоп на открытие сессии на закрытие и пытливый ум подумает надо бы что-нибудь еще по оптимизировать потому что допустим 5 миллисекунд тоже не устраивает Или 150 мы же все-таки с распределенной базы данных взаимодействия и надо рассмотреть Вот эту вот Центральный прямоугольник если его достать большую лупу и рассмотреть что там происходит в кишках то там какую-то не маленькую долю занимает компиляция запроса То есть это парсинг строки как SQL запроса это составление плана запроса для запросов которые отличаются только параметрами кажется что тут тоже есть возможность что-то с оптимизировать и так мы подошли к понятию серверного кэша запросов он реализуется с помощью простого флажочка кипенгаш То есть клиент отправляя запрос он добавляет опциональный параметр скомпилируя запрос товарищ сервер скомпилируй запрос и Сохрани его у себя в кэше если я второй раз приду с этим запросом просто Достань из кэша при первом запросе произойдет компиляция Результаты компиляции будут помещены в Леру кэш по дефолту он имеет емкость 1000 кэш вытесняемый Но это дает нам следующий Профит что запросы на других сессиях тот же самый запрос на других сессиях на этой ноге они будут гораздо быстрее потому что мы упразднили этапы компиляции нужно просто сходить в кэш и забрать оттуда результаты компиляции запроса Итого мы по оптимизировали по оптимизировали и получили что можем сократить сильно время выполнения запроса круто же Итак флаг кэширования запросов уменьшает общее время выполнения повторных запросов упрощает клиентский код защищает от рестартов нот и вымывание серверного кэша и позволяет клиенту не задумываться на какую наду стоит направить запрос все нады в этом смысле будут равноценны если это первый запрос на надет произойдет компиляция если повторно это просто будет использован кэш И мы этот флажочек включаем по дефолту во всех запросах с параметрами запросы без параметров которые созданы конкатенации или интерполяции строк мы не кэшируем по понятным причинам далее надо сказать про серверную балансировку одно ее половинку вы уже знаете что сессия может быть случайно отставить не случайно сессия может быть создана на другой ноге и клиент должен быть к этому готов вторая половинка серверная балансировки заключается в том что сессии могут быть закрыты сервером принудительно звучит страшно на самом деле там гораздо все более грейфу серверная сторона дожидается когда на сессии будет выполнен последний запрос то есть сессии которые в работе Они не закрываются выполнен запрос сессия свободно от запросов вместе с успешным ответом на очередной запрос прилетает дополнительная метаформация клиенту что сейчас сессия будет закрыта пожалуйста забудь про неё не используя больше никогда если все корректно поддержать то механизм серверной балансировки проходит Для клиента незаметно и обработка ошибок Это примерно тот раздел про который не принято говорить ошибки случаются С ними надо уметь жить надо уметь их обрабатывать до этого были примеры как мы успешно ходили выполняли запросы Но на самом деле нам может вернуться ошибка ошибки могут быть это отказ над и Отказ закрытие дата-центра какие-то транспортные или серверные ошибки и мы же опытные программисты мы такие подумали надо написать retrier вот здесь написан ретрайр безелуп мы до последнего пытаемся выполнить свой запрос а если у нас запрос кривой Ну то есть миллиард раз попробуем 100 500 кривой запрос не будет выполнен никогда плохой код все согласны мы можем вести некий лимитер попыток чтобы не задосить серверную сторону и все равно у нас будут неприятности потому что с кривым запросом нету смысла даже вторую попытку выполнять Яндекс имеет колоссальный опыт инцидентов и в ID конкретно Тоже имеет большой опыт инцидентов в том числе из-за того что люди пишут ретрайеры которые не предусматривают возможности серверу выжить То есть можно постоянно хотеть от сервера что-то он будет честно пытаться выполнить что-то но загрузка будет там в полку а успеха нет соответственно инцидент расследование там вот это все и проблема-то в том что ошибок много и реакция на них разная верхние половинки слайда это транспортные это по сути grpc коды в Нижней половинке наши серверные какие-то логические ошибки и на них нужна разная реакция например одни ошибки позволяют безопасно по ретроиться запрос а другие нельзя вообще ретроить есть промежуточные слой что можно поиграть если пользователь явно сказал что это патентная операция и все будет хорошо если мы повторим этот запрос если притравить не до патентную операцию например мы реализуем сервис биллинга и делаем начисления У нас ретрайер вот тот самый 10 попыток мы 10 раз с клиента что-то спишем он будет недоволен будет инцидент мне надо обрабатывать ошибки для ряда кодов надо удалить сессию надо забыть про неё не использовать можно поиграть но уже на другой сессии для некоторых кодов нужно использовать медленную экспоненциальную задержку Быков для того чтобы дать возможность серверу разгрузиться или чтобы некое там ресурс накапал квота там не знаю если это лимитируемый ресурс на слайде есть ссылка потом у вас будет возможность скачать эти слайды про кликать все ссылки здесь вот посылки собственно кусочек кода где мы закрепили поведение драйвера в случае получения тех или иных ошибок все перечислили даже немножко сверху этого списка на часть ошибок можно использовать быстро экспоненциальную задержку цель этой обработки в том чтобы обеспечить Для клиента успех в конечном счете и не за досить серверную сторону такой компромисс клиент должен уметь пессимизировать соединение суть этой концепции я уже рассказал мы должны ограничить трафик на те ноты vdb не засылать туда запросы с клиента на те ноты по которым получены специальные ошибки Но обычно это транспортные ошибки Или например серверная ошибка overload это та самая ситуация Наде плохо не надо туда направлять запросы и кажется что пессимизация соединений это путь в один конец то есть мы один раз разметили соединение что оно плохое не надо туда направлять запросы и так можно собственно весь кластер пессимизировать и успехов в конечном счете Для клиента не будет Выход из этой ситуации следующий что у нас Discovery сервис Этот сорт софт трус если мы туда сделали запросы и получили ответ что какие-то ноды присутствуют то мы абсолютно доверяем этому ответу и считаем что даже если соединение было пессимизировано надо переустановить его и направлять туда трафик если ноге правда плохо Она выпадет из списка НОТ про который знает Discovery сервис и соответственно естественным образом туда трафику перестанет идти есть еще механизм Force eri Discovery который подразумевает что если мы примерно 50 процентов соединения пессимизировали Ну например что-то сетью случилось моргнула она например возле клиента вы там Пользуясь вайфаем но продакшн системы на wi-fi такое себе строить но у вас моргнула сеть Пользуясь логикой что все транспортные ошибки это путь для пессимизации вроде все оптимизировали А как дальше работать надо просто перезапросить не дожидаясь той самой минуты у нас было много инцидентов расследований Что происходило не так смотрели код клиента и пока мы не написали ретрайры во всех своих драйверах эта ситуация была массовой мы написали ретрайры так или иначе пересадили клиентов на этот код и массовость проблема ушла у меня есть хейтеры на самом деле то есть когда ты написал некую там функцию которая помогает поиграть запрос и не дал возможности клиенту как-то обойти Это обычно синьоры Они все понимают они все про все ошибки знают лучше разработчиков они говорят Ну что ты вот для детский сад развел здесь ни на что нельзя повлиять но массовость проблема ушла а с хейтерами я как-нибудь справлюсь Ключевое понятие в этих ретрайверах что нужно ретрайтом не отдельный запросик а целую операцию то есть вот здесь вот нарисована некая лямда И эта операция должна возвращать ошибку клиент который пишет код работающий свой db он при любой непонятной ситуации выбрасывая ошибку отдавая ее вот в наружу Пусть драйвер сам разберется что с ней делать если драйвер про нее знает он сделает наиболее рациональное Full Back такое слово то есть корректно ее обработает может быть паритетрает может не станет ретроить может какой-то экспоненциальную задержку Ну то есть это не на уровне вероятности это закреплено в коде и Суть в том что нужно всегда возвращать ошибку есть опять же опыт когда клиенты используя какие-то возможности языка например замыкание сущности волатильные сущности полученные из волатильной сессии вытаскивают вне кода ретроера и дальше с ним работают например вы делаете стримовой запрос У нас есть такой запрос conquery для широких чтений из таблиц и запросик он коротенький типа создать Стрим и все а дальше его надо слушать Вот люди помещают в эту лямду создать Стрим Стрим вычитывают вне ретрайра Ну естественно Они получают ошибку расстраиваются приходят к нам и соответственно инцидент расследование и так далее Все что волатильное нужно внутри этой лямбды обрабатывать поначалу Мы пытались как-то конфигурировать эти ретрайры достаточно широким набором параметров Количество попыток какая-то специфичная обработка на отдельные коды ошибок но в итоге пришли к тому что важны всего два параметра это дедлайн до которого хочется получить успех и флажочек импотентности операции здесь гошный код и дедлайны и концелей обеспечивается за счет объекта ctx контекста Ну а флажочек нужно явно писать можно сколько угодно рассуждать и на берегу выдумывать там всячески эти инженерные концепции как все круто было бы но если кот не работает считайте что вы не сможете защитить свой код и Один путь потестируется это продакшена наших пользователей такое себе Да а второй путь это некое слово мы написали на всех наших официально поддерживаемых языках приложение это Киеве или нагружалки которые просто создают нагрузку против ломающегося кластера то есть вот здесь сеансы работы приложение написано на разных языках использующих разные драйверы разные версии драйвера против ломающегося кластера мы там специально искусственно ломаем ноду фризим ее делаем там Грейс волшебдаун и смотрим на это глазами клиента то есть если Клиент не заметил что с кластером в тебе что-то стало плохо какой-то частичный отказ то все считайте успех то есть драйвер нормально написано и это такой маркер для того чтобы успокоиться или наоборот в режиме аврала что-то чинить такое такое село тестирование у нас используется внутри Яндекса и у него периодичность 12 часов Итак драйверы распределенной базы данных должен уметь выполнять начальный запрос Discovery Listen Points И периодически перезапрашивать актуальное состояние кластера должен уметь клиентскую балансировку и должен быть готов к серверной балансировке должен уметь привязывать сессии и ноды и иметь собственный пул сессии а также выполнять фоновые типы Лайф драйвер обязательно должен уметь корректно обрабатывать ошибки и должен иметь встроенный ретрайр это вот Маст хэв но в ADB Мы же говорим что это платформа Это же не только табличные запросы и у нас есть табличка фича парити ссылка тоже будет на слайдах на сайте vodybittech соответственно мы там плюсики проставляем если фича реализована как-то минусы вопросики нарисованы когда мы не уверены что она хорошо работает естественно у нас в планах чтобы везде стояли плюсы а не только в плюсах не только все мы разрабатываемся командой аптим Оптима это про драйверы vdb Мы разрабатываемся полностью в github и в github создаем сами себе ишью или наши внешние пользователи создают сами делаем пиар сами мерзжемся отводим релизы В общем Живем по законам Open Source Если у вас есть какие-то безумные идеи Где вы их помощью сделайте себе хорошо то по законам Open Source наверное можно прийти в обстрел в наш репозиторий нанести добро и себе и остальным пользователям Так что пул реквесты приветствуется С вами был Алексей Мясников старший разработчик в команде vdb мои контакты на слайде слева qr-код чтобы скачать эту презентацию справа голосуйте за мой доклад Спасибо Давайте поблагодарим докладчика отлично и Давайте попробуем Задать несколько вопросов вот я вижу вот уже рука поднята Давайте вот несем микрофончик пока идет микрофончик вопросы с чата А как определяется что запрос совпадает с кэшем на данный момент само тело запроса это string собственно ключ в кш это текст запроса но мы немножко думаем дальше у нас есть определенные планы как это место улучшить в том числе отказаться там от инструкции деклара которые на данный момент обязательные Спасибо так и вот молодой человек пожалуйста Да спасибо большое Очень интересно Скажите пожалуйста за ту минуту Пока Клиент не знает Ну может не знать о актуальном состоянии кластера не может ли клиент записать данные куда-то не туда Например если происходит решардинка и балансировка ноды добавляются удаляются наверное можно упороться и все-таки эту ситуацию как-то сделать но должно сойтись много звезд у нас каждый запрос grpc запрос сопровождается какими-то коридэншилсами Нужно обязательно указывать базу данных то есть прийти примерно очень велик шанс что ваши вот эти вот метаатрибуты вообще не подойдут даже если там сейчас вот база данных уже ну на конкретном адресе база данных другого клиента очень сложно себе всю эту историю представить я правильно понимаю Слушай давай сделаем так мы же находимся можно на это написать какой-нибудь тест да да в том числе нас можно ломать Да программа Я так понимаю работает Ну это же одна из целей Open Source чтобы мы нашли какие-то у себя дырки в безопасности но мне не видится способ как подменить например токен который коротко живущий так чтобы имя база данных и прийти на правильно ноду и взять фальсифицировать данные по характеру Спасибо большое за вопрос я думаю что надо преследовать этот вопросик Давайте вот на четвертом на пятом ряду молодой человек пожалуйста и микрофончик Давайте передадим вот сюда на второй ряд Спасибо за доклад хотел спросить драйвера получается нет смысла знать о распределении данных Да потому что данные и вычисления у вас не связаны между собой на разных нотах находится или все-таки актеры имеют какой-то кэш и драйверный имеет смысл сходить на какой-то актер которым данные для его запроса хранятся И второй вопрос вот этих полов внутри драйвера достаточно то есть Сколько актов может быть на конкретной ноте и не требуется ли какие-то еще пулы более общие на несколько там клиентов драйверов Давайте начну со второго мы по дефолту используем пулы с лимитом 50 сессий этого обычно хватает И это параметр который может клиент повлиять Ну то есть он понимает примерно свою нагрузку своего конкретного приложения он может подвинуть этот лимит там в ту или другую сторону хватает то есть эти сессии будут распределены по разным нодам odb первый вопрос Напомни второй все-таки Сколько актеров на одной ноте может быть одновременно когда там плохо у нас по-моему стоит вот какой-то лимит в районе 10 тысяч на одной ноте это процесс или просто структуры в памяти структуры в памяти это легковесный актер Ну в акторная модель вот это все А первый вопрос был про то нужно ли знать клиенту где физически лежат данные да я стараюсь в этом докладе упростить выдеби глазами клиента видимо настолько упростил что выплеснул ребенка сложно в том числе вот дата шарды они спрятаны за компьютер слоем за этими нотами которые видит клиент и получается что когда вы делаете там запрос на самом деле дальше идет перезапрос на соответствующий дата шарт Где хранится конкретно данные по конкретному ключу поэтому клиенту не надо про это думать Спасибо большое за вопрос микрофончик на второй ряд А сейчас молодой пожалуйста реально редко интересно Также вы реализовали довольно таки большое количество функциональных требований сложных интересных реализовали Вот но ни слова не было сказано про нефункциональные требования То есть можно хотя бы какие-то цифры там по нагрузке сколько записи в секунду там какая латентность то есть вот как влияет балансировщик на нефункциональные требования вы сейчас я хотел бы уточнить про какой балансировщик клиентский или серверный Ну вот у вас в середине на входе кластер стоит балансировщик единый это клиентский балансировщик отмотаем на какую-нибудь вот Вот как вот она клиентской страх это единая точка влияет на нефункциональные требования это же runtime клиентского кода То есть это не какие-то походы по сети Ну сходить в балансировщик это в свою структуру данных памяти там ты ограничен по сути только возможностями языка Если какая-то кошка или плюс это вообще отлично очень быстро Спасибо большое вот здесь на втором на втором ряду пожалуйста молодой человек и микрофончик туда да спасибо за доклад очень интересно было заявлено что в ADB для oltp нагрузки и аналитические Влад чем мы заплатим если попытаемся ее использовать в традиционном лапе там например вместо подвесы ремонт что будет хуже бывает не бывает хорошо магии нету соответственно у нас транзакционность обеспечивается какими-то механизмами блокировки У нас есть специальные ручки ручки для выполнения запросов и они сейчас не конкурентоспособны например сравнение хаосом который специально создан Для нагрузок Мы работаем У нас вот пока здесь одни люди докладывают другие сидят в офисе и делают алаб делают поколоночное хранение и я думаю что в ближайший время мы сможем порадовать пользователей vdb тем что алаб нагрузка стала конкурентная с алабазами данных То есть сейчас Тупо медленно сейчас мы можем сделать там Селект фронт Table без условий и даже и даже получить результат Ну как какие-то есть которыми а как бы так сказать чтобы себя не обидеть не конкурентные да то есть ответ будет но летензин наверное будут будет не самый Радужный Зато в idb это про массивную вставку гарантированную гарантиями висит поэтому вы можете успешно вставлять массивно Потому что много нот Да потому что клиентская балансировка Хорошо давайте Спасибо большое последний вопросик Сейчас возьмем здесь в зале просто молодой Спасибо за доклад такой вопрос не уникальная класс и ваша проблема иных кукуру очередь аналоги У нас у руководителя любимый вопрос Когда мы на каком-нибудь рфц обсуждаем очередную фичу любимый вопрос а как у конкурентов просто вот ни одна фича не делается чтобы не посмотреть на конкурентов и вот про ретрайеры никто не говорит о все используют потому что надо обрабатывать ошибки надо вот если детализировать вопрос про каждый конкретный случай то естественно у нас проводился анализ с тем же по порядку все большие базы мы на них смотрим и даже как бы внутренний бенчмарки делаем чтобы собственную самооценку поднять не ударить в грязь лицом перед клиентами в idv хорошо Спасибо тебе большое Давайте поблагодарим докладчика А еще очень важный момент у нас здесь есть стенд где Куда можно подойти детально просить провод db это можно сделать за пределами зала Но прежде прежде чем коллеги Разойдутся давай выберем какой-нибудь вопрос который тебе больше всего понравился вот что-то запало прямо в душу могу подсказочку Давайте бросить вот смотри вот у меня тут а мне понравился вопрос Где нас пытаются ломать Можно ли записать данные куда-то не туда Так вот молодой человек вот пожалуйста подарочек передайте и у нас есть небольшой подарок презент докладчику от организаторов Давайте поблагодарим еще раз докладчика спасибо большое А на этом мы с вами прощаемся здесь в этом зале и встретимся после перерыва до скорых встреч"
}