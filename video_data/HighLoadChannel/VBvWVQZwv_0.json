{
  "video_id": "VBvWVQZwv_0",
  "channel": "HighLoadChannel",
  "title": "Высокопроизводительный  промышленный сервис для компьютерного зрения на Python / Григорий Алексеенко",
  "views": 280,
  "duration": 2793,
  "published": "2023-10-06T07:21:05-07:00",
  "text": "Привет всем тут Наверное важно отметить что доклад именно про компьютерное зрение не только про питон Меня зовут Алексей интерьевой Я работаю в компании Сбер девайс в команде layer наша команда занимается монетизацией фото и видео контента с помощью компьютерного зрения и Для начала я расскажу немного о себе работаю в Lays 21 года сентября в принципе в компьютерном зрении пятый год пишу на плюсах и питоне и успел за это время сделать много разных проектов впрочем почти все где можно применить компьютерное зрение и чтобы вести вас в контекст я расскажу что такое это монетизация фото и видео контента и с какими задачами Мы работаем я расскажу на примере наших продуктов первый продукт называется innamage работает он так вы просматриваете статью в ком-то в каком-нибудь онлайн-журнале где например выложены фотографии звезд с какого-то важного мероприятия вы смотрите и думаете классно выглядит Я хочу себе такой же лук наш алгоритм как раз помогает подбирать похожие товары на те которые вы видите на фото у наших магазинов партнеров особенностями этого продукта будет то что здесь каждый день выходит новые статьи на этих статьях большое количество просмотров и нам нужно следить чтобы данные были актуальны мы не хотим показывать пользователю тот товар который вышел из обращения или если вдруг появился товар уже новый который Хорошо подходит Мы хотим чтобы он был показан и как источники здесь джипеги png и прочие форматы изображений следующий продукт называется Visual Search вы могли видеть такую историю в онлайн-магазине вам рекомендуют похожие товары на тот который вы смотрите в текущий момент обычно это история работает на классическом машинном обучении и по описанию товара по его категории и разным характеристикам подбирается похожий наш продукт отличается тем что он работает именно на изображении оценивает то как выглядит товар и рекомендует похожие точно также по изображению здесь Как особенности будет то что в магазинах очень большое количество товаров их все нужно обработать также их нужно постоянно обновлять мы здесь можем встречать непредсказуемые форматы изображений например есть такие marketplace которые позволяют продавцу самому загружать фото здесь можно ожидать разных подстав например изображение которое названо джебегом на самом деле таковым не является картинки могут быть биты или что-то такое и здесь мы ищем по большому индексу индекс это наша база с обработанными товарами мы обрабатываем не сетями фото товара кладем его в индекс и потом когда мы ищем похожий товар мы его точно также обрабатываем и ищем похожие внутри этого индекса там хранится очень много товаров по нему нужно искать быстро и генерировать его тоже нужно быстро потому что на самом деле это разовая задача мы подключаем магазин Нам нужно обработать большую кучу товаров а потом только обновлять появляющиеся новые и те которые вышли из обращения и еще есть один продукт называется nvideo работает он так вы смотрите какой-нибудь сериал или кино и в онлайн кинотеатре ставите на паузу наш алгоритм распознает те объекты которые находятся в кадре и предложат купить вам похожие у магазинов партнеров здесь пример с сериалом друзья Не очень видно затеняет но кадры где Джой и чендлер сидят на креслах в общем-то наш алгоритм предлагает купить очень похожие кресло как у главных героев Ну или кресло в каком-то таком же стиле чтобы они подходили но были немного другими а этот продукт отличается от предыдущих тем что он работает в реальном времени в случае если видео имеет 25 кадров в секунду то мы имеем максимум 40 миллисекунд на ответ и Ну как источник здесь у нас видео hls vapertc формата которые нам нужно декодировать мы динамично развиваемся и пробуем много разных продуктов разные точки в рынке поэтому для того чтобы быстро выкатывать продукт мы сделали так чтобы все наши продукты смотрели по итогу на один и тот же сервис вот поэтому у нас получается такой один большой высоконагруженный сервис также мы распознаем различные категории Кроме тех которые вы увидели до этого аксессуары мебель Надежда мы можем распознать еду то есть предложить вам заказать блюда Как видите в кадре или купить ингредиенты которые помогут вам это блюдо приготовить распознаем локации это если фильм был снят в каком-то интересном месте видно какие-то достопримечательности то мы предложим вам купить билет и посмотреть где же снимался та или иная Лента и есть распознавание актеров по лицу чтобы выдавать информацию что это за человек Где вы могли его видеть и так далее немного об архитектуре со всех наших источников данные попадают на бэкэнд где декодируется видео и передается в балансировщик балансировщик собирает Бачи и решает на какой сервис мы отправляем данные по итогу сервиса мы получаем векторы признаков или имбидинги которые описывают объекты эти векторы уходят в поиск по индексу там мы находим похожие товары Передаем их бэкэнду Back and и контент уже дает конечному клиенту рассмотрим примерно paypeline распознавание на примере задачи одежды У нас есть входное изображение на нем девушка идет машет рукой и мы хотим найти одежду похожую на ту которая на ней для начала нам нужно локализовать объекты То есть за детектировать или сегментировать одежду на фото по итогу мы получаем группы в случае детекции или маски в случае сегментации и нам нужно их распознать получить для них Вектор признаков Передаем другую сеть для этого получаем бединги отдаем в индекс также например чтобы усилить наш pipline мы можем добавить какие-нибудь дополнительные части например распознать лицо человека по лицу распознать пол возраст И тем самым рекомендовать например детскую или недетскую одежду или мужскую женскую и так далее Я примерно описал как выглядит наш продукт изнутри и мы много работали над оптимизацией и здесь можно выделить примерно 3 основных пути развития где можно что-то улучшить начнем с модели здесь речь идет именно об самих нейронных сетях и архитектуре и всем таком Есть основные достаточно популярные методы например browing Когда у нас уже есть готовая сеть мы ее немножко подрезаем чтобы не сильно потерять в качестве но получить прирост скорости и в потреблении и уменьшить потребление памяти можем изначально выбрать более легковесную модель обучить ее на исходных данных или воспользоваться новостью когда мы берем большую модель которая уже до этого обучили используем ее как модель учителя кажется что это все но на самом деле в зависимости от задачи можно применить какие-нибудь специфичные методы Наша задача выглядит так Мы один кадр подаем в несколько разных сетей каждый отвечает за свою категорию одежда мебель и так далее Как можно оптимизироваться и вместо того чтобы использовать пять разных нейросетей использовать что-то попроще Мы можем взять и объединить все в одну сеть у нас получится так Здесь нам нужно разметить все данные на все категории это получится очень дорогая разметка чего мы не хотим для своего проекта И на самом деле будут такие вопросы к качеству Мы хотим от одной сети получить совершенно разные предсказания Ну потому что мебель там диван сильно отличается от очков и Еще довольно хорошо отличается от яблока и сети может просто не хватить мощности для того чтобы все эти категории В себе совмещать окей Какой есть еще способ есть подход который называется multitask Learning например Мы можем взять точно также одну и ту же сеть и последние слои разделить чтобы каждый отвечал за свою задачу В таком случае проблем с разметкой у нас не будет потому что мы можем если у нас есть изображение размеченное на одну категорию момент обучения на этом изображении мы можем остальные слои заморозить и обучить только необходимую нам часть но этот подход также не поможет нам с точностью потому что он страдает ровно теми же проблемами как и предыдущие описанный Что можно сделать чтобы к тому же не потерять в точности нужно выбрать хорошо архитектуру для этого есть разные подходы я пишу такой берется обученных моделей и считается корреляция между сопоставимыми слоями То есть например первые слои у нас довольно хорошо коррелируют Значит мы можем все эти слои слить в один смотрим дальше какие-то слои коррелируют хорошо между собой какие-то нет мы отделяем ветки для того чтобы уже все последующие слои отвечали за эту конкретную задачу и таким образом проходимся По всем слоям получаем какую-то итоговую сеть в которой будет больше параметров чем в одной меньше чем в 5 это будет что-то среднее по скорости но при этом не будет потеи в качестве у нас такая разработка называется мы вдохновились идеей компании Tesla у них есть много на эту тему докладов Андрей Карпаты рассказывает о том как они делают это для беспилотников у них тоже похожие задачи они делают много разной аналитики на одних и тех же кадрах с автомобиля на эту тему в интернете можно найти много статей Но если вы захотите посмотреть на какой-нибудь код с этим будут проблемы и нужно все писать самим на этом по моделям все перейдем к infinition и батчингу данных если у нас есть NVIDIA GPU то очевидным решением будет использовать тензор довольно приятная библиотека с кучей инженерных оптимизаций под конкретные задачи под конкретные ваши параметры на что здесь стоит обратить внимание параметры стоит выбирать довольно тщательно об этом чуть попозже также есть такая фишка как динамический батч и при квантизации модели Нужно следить за тем чтобы вы не потеряли в качестве по поводу динамического батча на слайде я привел график линии показано как будет выглядеть если мы работаем с бачсайзом 1 То есть как только приходит изображение мы его отправляем по оси Y у нас время обработки по оси X размер боча видно точками я отметил Что будет если мы пользуемся батчингом видно что если использовать батчинг то модель работает быстрее но есть такой вопрос у нас сервис работает в режиме онлайн то есть у нас есть четкое ограничение по времени и нам нужно все равно успевать отвечать на запросы пользователей Окей давайте для себя условно Нарисуем линию которая будет перемещаться по графику вниз с прохождением времени и будем отмечать точкой наш текущий размер бача в принципе когда эта линия начинает подходить близко к нашей точке или ее пересекает в этот момент мы отправляем данные на inference получаем результаты и успеваем отвечать пользователю Таким образом мы и работаем онлайн и при этом мы немножечко оптимизируем внутри и за счет батчинга выигрываем в производительность всю эту логику можно имплементировать внутри брокера сообщений для этого есть много разных решений и в принципе все они работают хорошо как особенность здесь получается такой интерактивный процесс то есть Сначала мы собрали модель и запустили сервис потом нам нужно собрать статистики посмотреть какие Бачи в среднем приходят чтобы оптимизировать нашу модель под именно эти параметры но после этого статистику нужно пересобрать снова потому что время infins меняется снова посмотреть возможно параметры поменяются самые частые батюг поменяется снова конвертируем модель и так далее пока этот процесс не сойдется также как решение можно хранить несколько моделей с разными оптимальными параметрами если они уже в виде готового движка то здесь реализуются они довольно быстро на этом принте все теперь о вспомогательном коде помимо самого применения нейронной сети мы делаем разные операции то есть Нам нужно подготовить изображение обработать результаты и все прочее И на самом деле эта штука занимает очень много времени мы для себя написали модуль на плюсах который все эти операции выполняют довольно оптимально К тому же все эти операции выполняются на GPU как основные здесь будут вычислили кодирование декодирование джипедов различные обработки как нормализации все прочие конвертации между различными форматами и последние в списке но не по значению Центральный менеджер памяти Почему вообще все это важно рассмотрим пример у нас есть задача распознать котиков на изображении как это будет выглядеть в стандартном виде получили изображение оно у нас хранится в оперативной памяти мы его подготовили для детектора отправили на GPU и детектор получил нам координаты боксов после того как мы получили результаты копируем их к себе на CPU дальше также на цпу мы вырезаем мордочки подготавливаем их снова для infins отправляем на GPU дальше на GPU уже распознаем распознаем мордочки и отправляем результат на CPU получается довольно много копирований и это можно оптимизировать если мы все операции выполняем на GPU и храним исходные кадры на нем же то мы избегаем лишних копирований на ГПУ и наоборот Что еще можно оптимизировать в использовании памяти на GPU после того как мы познали какой-то кадр мы можем не удалять буфер который мы уделяли в памяти а пере использовать его потом особенно если у нас идет потоковое распознавание то есть мы распознаем какой-то фильм понятно что следующий кадр будет иметь такое же разрешение как и первый вот поэтому после инференса можно не удалять буферы хранить некоторые набор самых часто используемых и подбирать подходящий под текущий запрос и просто копировать туда Тем самым мы избегаем локации которая тоже является довольно дорогой Также можно использовать буфер большего размера для изображения меньшего знающие люди которые понимают в промышленном компьютерном звенье могут сказать все это есть в тритоны сервере зачем писать свое решение Почему не взять готовую штуку вспомним пример с джипедом который на самом деле не JPEG дефолтный код тритона Просто на этом изображении упадет нам будет очень приятно и как вывод как минимум код тритона нужно допиливать он весь написан на плюсах чего мы как дата саннитисты не любим также в нем очень много всего содержится внутри и большую часть функционала на самом деле не нужна в одном конкретном проекте Вот и немного на тему скорости при ввожу небольшой график здесь у нас по оси X размер батча по оси Y количество обработанных изображений в секунду здесь мы декодируем jpg красные Столбцы это светилс нашей библиотека черные Столбцы это библиотека дали которая находится в составе тритона как раз для декодирования Несмотря на то что обе библиотеки используют под капотом наша работает Чуть более производительно и Ну в общем можно получить такую выгоду в скорости Несмотря на то что кажется что и так можно и так уже есть готовые оптимальные промышленные библиотеки здесь отмечу что производился этот эксперимент максимально честно на одном и том же сервере библиотеке все были собраны с максимальными оптимизациями и порядок набора изображений был один и тот же Окей мы перенесли все операции на GPU и довольно собой смотрим Что же происходит на сервере на сервере происходит то что GPU у нас старается в поте лица но при этом CPU довольно таки чувствует себя комфортно у него небольшая загрузка и кажется что тут что-то можно с этим сделать как-то загрузить по так чтобы и он выполнял задачи и мы получили большую производительность мы для себя вынесли некоторые операции которые мы переносим на CPU распаковка png VP попытка восстановления битых джбеков То есть все библиотеки декодируют по-разному и поэтому некоторые могут восстановить побитый jpg некоторые нет Также можно использовать гибридные режимы в некоторых библиотеках такие есть тот же бег он если ему дать еще и доступ к CPU он его расходует очень хорошо и библиотека работает более производительно чем если бы она была только на ГПУ небольшое размышление о языках мы для себя были готовы взять какой-нибудь любой производительный язык и написать на нем библиотеку и наш сервис чтобы получать довольно хорошие числа по производительности какие были варианты есть популярные довольно быстрые хорошие языки Джулия го Rust но у них есть небольшая проблема так как мы работаем с компьютерным зрением нам нужно иметь возможность хорошо работать с изображениями Для этого нужны библиотеки типа Open CV или и тензор у Джулии например нет тензор и опен Сирии есть оба Но это биндинги которые написаны кем-то из интернета выложены на github на репозиторий 5 звездочек на стекле есть пара вопросов на тему этих биндингов без ответов конечно В общем выглядит довольно грустно и страшно брать и тащить такие штуки и также есть вариант плюсов Плюсы это отличное решение официальная поддержка всех библиотек для компьютерного зрения Ну в общем они на нем и написаны но немножечко страшновато Писать много кода просто запомним для себя этот вариант какие варианты ускориться не выходя из питона есть жидкомпиляторы типа Нубы есть сайта но здесь тоже Проблема в том что поддержки компьютерного зрения в них нет то есть с помощью например можем оптимизировать функцию для вычисления косинусного расстояния она для нас достаточно важна но не так не так важна как возможность загружать изображение на карту и на ней как-то хорошо немного подумав Мы пришли к решению это что-то посередине написать небольшие модули на плюсах которые будут понятны в принципе даже человеку который не знает плюсы хорошо просто понимает программирование и подключать эти модули в наш код на питоне тем самым оставив себе гибкость возможность быстро писать прототипы и все остальные плюшки питона вот на тему кода это все и Давайте немного подводить итог мультитаскинг в модели дает нам прирост примерно два с половиной раза по производительности для всего paypeline манипуляции с инференцем и сборы бочей дают прирост около двух раз и вспомогательный код дает прирост тоже около двух раз по итогу мы получаем примерно 10-кратное ускорение относительно стандартного pipeline Ну написано на питоне с использованием например торчат как бонус мы взяли наши модули довольно быстро подоткнули их в обучающий код тем самым мы получили еще и ускорение тренировок что довольно приятно можно проводить в два раза больше экспериментов Ну или просто получать конечную модель быстрее на этом все здесь есть qr-код чтобы оценить доклад указаны мои контакты в телеграме также указан канал команды по этому каналу будет выложены слайды Так что Подписывайтесь мы там помимо слайдов выкладываем какие-то новости Лизы и некоторые наши размышления По новостям Спасибо Гриша в общем лайк Шер репост оценивайте доклад это очень важно и для спикера и для программного комитета сейчас будут вопросы а я Да кстати есть чатик канала Вот можете задавать вопрос Там если вдруг стесняетесь я прокомментирую один момент мне очень понравилось что-то сатанисты ленится писать на си плюс плюс это очень честно прикольно Итак ваши вопросы Ну давайте вот мужчина здесь а потом там наверное сначала стоит сказать что у нас есть подарок Да конечно конечно естественно подарок какой-то там причем такой кастомный интересно Смотри у меня три Раз у тебя три блока три вопроса Смотри первая такой двойной А ты говоришь у вас серединке высоко нагруженный сервис какие цифры Окей смотри Ну примерные Дело в том что как я говорил нагрузка довольно плавающая Например если мы генерируем индекс мы это делаем один раз мы подключаем к себе ретривер и нам нужно за индексировать все его товары как можно быстрее А их миллионы прямо конкретных чисел я тебе не скажу За это прошу прощения но примерно я могу описать То есть это там не знаю в часах или в картину ты какая-то там сколько миллионов может пройти в сутки или там то есть индексирование большой ритейлера это понятно у тебя там миллионы позиций товаров и по каждой позиции товара может быть по 5-6 изображения то и больше Да окей по видео Я не могу сказать сколько у нас пользователей смотрят и все такое но Так что я тут могу сказать много да скажи что идеи все Да ну по сути просто это чувствительная информация которую я не очень могу говорить но на самом деле много есть церетелерами со всеми остальными Понятно А вот кейс видео по сути Ну представим себе что человек смотрит Какое кино кино оно какое-то где-то на какую-то площадке тоже самое публикуется единожды Почему мы работаем в онлайне огромный вопрос почему нельзя просто разделать а потом хранить какие-то индексы и все Да Но это такая фишка что мы не храним данные и если вот здесь про видео то это происходит Вы можете посмотреть это на Сбер устройства Сбер девайсах и такая история что есть ограничения которые нам не позволяют видео хранить Поэтому нам поэтому у нас появляется такое ограничение что нам нужно работать в онлайне а второй части смотри оптимизация модели А ты сказал что вы берете послойно и смотрите идет корреляция или нет Если коррелирует то просто схлопайте их вместе Это один и тот же слой по сути хорошо А вы не смотрели не пробовали использовать блоки слоев потому что очень часто тебя идет некоторая последняя слоёв они могут не коллировать на каких-то конкретных слоях Но если блок в целом кластер он по сути его вход и выход будет практически идентичен просто там идет за расхождение в локальных минимумов грубо говоря и таким образом у тебя блог это один один но конкретно слой это два раза Да я понимаю твой вопрос на самом деле для слайда тяжело визуализировать и блоки и слои но подходы здесь используются разные и здесь показан в принципе ну как один подход оценивать корреляцию есть еще разные варианты этот вариант более такой хорошо визуализируемый чтобы понимать О чем идет речь Да и здесь можно использовать как блоки так и слои соответствующие друг другу но И последнее у тебя extention коды То есть вы просто напросах отдельно модуль написали каким-то образом инфраструктуры их связали какой-нибудь шины Или вы просто через питон вызываете какой-то код который написали на плюсах это именно модуль то есть бендица внутри питона там вот был Да молодой человек сзади Спасибо за доклад у меня такой вопрос может ли нейросеть отличить какую-то из реалистичную игрушку или фигурку вот реального изображения Вот например тут звук раздает таких голубей реалистичных и может не рассеять отличить реального голубя от вот этой реалистичной игрушки но на эту тему Есть много мемов в интернете где Помогите отличить мою собаку от кекса Это довольно сложная задача и в принципе часто ответом на такие вопросы является смог бы человек Особенно учитывая то что как правило мы получаем разметку от людей если это действительно такое изображение что человек с трудом отличает может отличить по какому-то контексту То есть если мы видим голубя который находится вместе Где находиться вообще не может то человек поймет что Это скорее всего не настоящий голубь но если мы оцениваем именно изображение именно то как выглядит голубь то здесь зависит то есть действительно реалистично похожую фигурку скорее всего не различит по-настоящему Гриша контекст учитывается Когда происходит анализ А где-то да где-то нет ну то есть можно сделать сеть которая будет учитывать плюс-минус контекст Но на самом деле прям глобальный Нет спасибо там по-моему тоже было Давайте молодой человек был там потом туда Да спасибо большое за доклад У меня два вопроса Первый используете ли вы в начале детекторы чтобы понять начали что что на фотографии так можно быстрее определить а потом уже Пускать на модели допустим на другие Просто я начала пропустил и второй вопрос в качестве брокера сообщений что Используйте просто поподробнее хотелось чуть-чуть увидеть Потому что если много серверов много большой поток идет надо правильно распределять все спасибо за вопрос ответ на первый Да используем вот Ну например слайде показано как бы часть экстракции объектов то есть Сначала мы получаем боксы или маски для конкретных объектов вот второй вопрос я не могу называть конкретные решения Вот но на самом деле мы для себя используем такой достаточно популярный брокеры который как бы первый в Если будешь гуглить брокер сообщений предлагаю угадать с двух раз но я не скажу Какой можно угадать но ответа и не дам там молодой человек потом туда Вопросов много Это хорошо хорошо время есть а Да привет Спасибо за доклад Слушай ты сказал что вы генерируете индекс из векторов Подскажи О каком количестве векторов идет речь и как вы их храните и как по ним ищете и перебираете ли все вектора Каждый раз при поиске смотри есть такой общепринятый так сначала как количество в среднем десятки миллионов по одному ритейлеру где какие у него есть товары дальше есть довольно стандартные подходы к индексу там идет речь о оптимизациях таких что он ищет за логарифмы у нас разбивается по кластерам потом внутри кластеров ищется Вот то есть здесь я в эту тему не углубляюсь потому что у нас не используется ничего такого сверхъестественного есть стандартные подходы например иерархический называется Суть в том что разбивается на под кластер где кластеризуются Похожие и ищется сначала главный кластер потом ищется внутри спасибо Вот здесь Да вот на первом ряду еще кто-то будет А еще там потом тут вы задавали помни Нет меня зовут Дмитрий хотел спросить про Тритон Versus собственный какой-то Model Server Да ты говоришь что там Тритон он не полностью подходит и так далее Вот а если мы маленькая компания стоит ли нам лезть собственный модуль сервер или лучше Вот взять и использовать не мучиться Смотри Я бы немножко переформулировал твой вопрос Если ты не против если вам подходит Тритон Стоит ли его использовать То есть в принципе любой компании стоит использовать уже готовые решения как минимум для начала чтобы не тратить время на разработку Вот другой вопрос Есть ли какие-то ограничения которые уже не позволяют использовать эту библиотеку или требует Там допилов просто в нашем случае получалось так что сделать свой продукт или допиливать Тритон было бы примерно одинаково по затратам плюс мы сделали по итогу Так что поддерживать наши модули нам довольно удобно они написаны понятным нам языком без лишних нагромождений Вот поэтому я бы посмотрел так первое Подходит ли Тритон если с ним проблем нет вы маленькая компания не хотите запариваться пожалуйста отличное решение если есть проблемы с тритоном то хорошо бы понимать их как бы их причину сколько у вас там например потратит времени ваши разработчики на то чтобы допилить Тритон вот Ну и как итог Если действительно много то какие-то маленькие модули которые решают ваши локальные проблемы это хороший выход рекомендую сами пользуемся Круто Круто Спасибо и маленький еще вопросик как кроме тритона есть ещё посоветовать чтобы посмотреть разные варианты если говорим именно про оптимальный infins на NVIDIA GPU то по сути это ритон так как это в общем-то NVIDIA библиотека вернее это NVIDIA решение которое использует nvid-1 библиотеки и все довольно оптимально Спасибо большое вот туда и потом туда Спасибо за вопрос Да привет Я прошу прощения может быть вопрос уже звучит ответ звучал Раньше я опоздал на доклад хотел спросить используете ли вы для inference CPU подходы какие-то и Ну то есть сеток на CPU процессорах И второй вопрос такой Какие используете ли вы Open CV какие-то другие такие высокопроизводительные фреймворки для компьютерного зрения также оптимизированные под x86 под степи Привет Спасибо за вопрос так по порядку используем ли мы CPU для inference Нет не используем мы его в грузили другими задачами например часть декодирования Ну там разные обработки изображений они на нем и в принципе ему хватает вот так как у нас есть GPU на котором мы можем все быстро фигачить я говорил о том что мы можем даже не уносить кадры с ГПУ то есть мы не тратим много времени на копирование поэтому мы не используем на CPU Хотя у меня опыт был и на Intel Intel Это довольно приятная штука по поводу Open CV всех прочих Да мы их используем для себя мы их пересобирали там с максимальными оптимизациями с той же с тем же подключением коды с использованием инструкций вплоть до vx512 это все на все ответил дальше Спасибо за вопрос Добрый день спасибо за доклад про постановку задачи немножко Можно еще раз пояснить человек смотрит видео нажимает паузу ему показывает Какие еще диванчики можно купить которые на кадре откуда возникает 40 миллисекунд Мы же нажали паузу отправляй спокойно и анализирую какие там есть такая мебель на кадре есть Добрый день спасибо за вопрос нам нужно это обработать так чтобы показать сразу то есть Нам нужно когда человек нажимает на паузу это происходит довольно быстро и нам нужно уже иметь заготовленный ответ чтобы его отрисовать вот тут еще повторный вопрос я смотрю Ничего себе И вот вы хотели да потом туда первый доклад людям хочется поговорить Классно Классно я только за еще раз Привет Смотри Мы очень много говорим здесь про оптимизации То что приходится использовать много extension of много разного кода вокруг питон там подобное везде оптимизации Как вы ищете battle.net у тебя очень много экстеншинов плюсом который ты просто забандил если у тебя просто питон по факту ты можешь просто Егерь повесить с панами и у тебя получается Ну нормально трассировка Ты можешь посмотреть как у тебя внутри функции Все ходит но особенно когда у тебя там интерсервис идет еще в индекс нужно залезть вот а как у тебя как бы с таким количеством оптимизация выносов за рамки классического бетона происходит поиск Battle Neck of Хороший вопрос Смотри это можно делать Так мы можем например как первый этап включить профилировщик внутри питона и посмотреть сколько у нас занимает вызовы тех или иных функций в плюсах то есть время мы получим не подробно не детализированной и но Будем иметь представление о том сколько в этой части у нас потрачено машинного времени дальше мы можем подключить плюсовой профилировщик плюсам если Ну в общем и посмотреть воспроизвести для себя вот использование этой функции и глянуть насколько это Антон у нас уже нет времени к сожалению вопросов мы заканчиваем надо выбрать Кто получит приз самый интересный вопрос Я думаю что приз получит Антон за самый большое количество вопросов он старался и честно его заработал У кого остались вопросы можно попытать спикера еще дальше на выходе вручаем Антону приз и тебе за участие в конференции Спасибо было интересно вопросов прям Ну ты видел народу интересно было Спасибо Спасибо за внимание"
}