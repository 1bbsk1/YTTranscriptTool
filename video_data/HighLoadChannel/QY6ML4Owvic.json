{
  "video_id": "QY6ML4Owvic",
  "channel": "HighLoadChannel",
  "title": "Linux API с точки зрения разработчика веб-сервера / Валентин Бартенев (NGINX, Inc.)",
  "views": 2291,
  "duration": 3396,
  "published": "2018-01-16T13:10:28-08:00",
  "text": "then бартенев я работаю в компании john x и сегодня мы с вами поговорим про такую тему как linux пии в общем то как его использовать чтобы написать какой-то быстро и серверное приложение в общем то я начну с довольно базовых вещей потому что вероятно не все занимаются написанием северных серверных приложений а тем более на таком уровне поэтому мы поговорим вообще что такое linux api что он из себя представляет в принципе в принципе это набор системных библиотек и системных вызовов чаще всего системной библиотеки они просто создают нам такую удобную обвертку которую мы можем использовать в виде функции вокруг этих системных вызов а системный вызов это тот способ с помощью которого прикладные приложения общаются с ядром и непосредственно заставляет его выполнять то что нам нужно ядро ядро по своей сути является такой программный прослойкой которая выполняется роль управляющую железом она предоставляет нам интерфейс удобные для ввода-вывода для использования всевозможных файловых систем для использования разных сетевых протоколов и как результат мы можем запускать наши программы на огромном количестве железо оборудование различного и не заботится о том как это оборудование функционировать на аппаратном уровне существует стандарт posix который призван стандартизировать все unix подобной операционной системы и в частности в него входит в том числе и стандарт который специализируется некий набор системных вызовов и оберточный функций вокруг него которые должна предоставлять пасек совместимой операционная система и большинства unix-систем они являются пасек совместимым таким образом если вы используете эти только этот посох совместимый интерфейс то вы можете рассчитывать на то что ваша программа может собраться и запустится на любой такой системе без внесения каких-то существенных изменений в код но зачастую различные операционные системы предоставляют также всякие дополнительные механизмы которые призваны предоставить более эффективный метод для решения ваших задач и в частности о таких механизмов в разрезе ядра linux мы поговорим потому что если вы хотите писать какой-то быстрое масштабирование веб-сервер то вы скорее всего будете использовать именно эти интерфейсы а почему linux ну потому что это одна из самых популярных на северах операционных систем и вторых у меня просто больше всех больше всего опыта с данной системой итак собственно обработка любой веб-сервер он должен заниматься обработки больших большого количества соединений и существует два таких основных подхода к тому как это делать первый подход назовем его традиционном это когда вы на каждое новое соединение порождаете отдельный процесс или отдельный поток а дальше уже в этом потоке непосредственно занимаетесь этим соединением то есть вы допустим последовательно сначала что-то читаете прочитали данные обработали записали данные все это время у вас обработка вот оно выполняется последовательным в этом потоке если данных нету то вы их просто ждете если данные ещё не отправились то вы ждете когда они отправятся соответственно когда у вас десять соединений у вас десять таких потоков когда вас их становится тысяч у вас тысячи но в наше время низ не редкость когда сервера обрабатывают и сотни миллионы соединений и это все очень плохо масштабируются до таких размеров потому что все таки даже поток вам довольно тяжелая сущность для ядра и когда их во столько много у вас mapper'ов память рано или поздно заканчивается и уже переключение задач переключение контекстов она вносит довольно существенный вклад и существует второй метод который собственно использует engine x это когда вы multiplexer уйти множество соединений множество потоков ввода-вывода в рамках одного процесса или потока неважно как это делается кто то думает что это какая-то очень сложной магия на самом деле это довольно просто самый примитивный способ это сделать это просто написать вот такой простой цикл я написал на псевдокоде но чтобы было понятно но в принципе все что вам нужно это если у вас допустим есть 10 соединений то вы просто в цикле обходите все эти 10 соединения и пытайтесь что-то с ними сделать в зависимости от того состояния в котором находится ваше соединение то есть для каких-то соединений вы будете из них что-то читать для каких-то уже вы что-то прочитали вы будете писать и так далее но как вы понимаете непрерывно бегать по этому списку и что-то делать это в принципе ресурса емко и ваше приложение в таком случае просто будет потреблять весь процессор на ненужную деятельность просто процессор быстрые а сеть она как правило медленная и в итоге большую часть итерации цикла ничего происходить не будет важный момент что при этом соке ты у вас работают в не блокирующим в режиме что это значит для вас это значит что когда вы просите прочитать сколько-то байт то ядро вам ядро не останавливает ваш поток и не ждет когда эти байты реально придут вы сможете их прочитать она возвращает в упа управление вам сразу и либо вы прочитаете эти 10 байт или сколько-то либо она вам скажет их нет данных нет и вы можете продолжить обработку и перейти скажем к следующему соединению что тут можно сделать как можно усовершенствовать этот цикл ну во первых можно для начала взять и скажем добавить какую-нибудь задержку вот как меня в примере 200 миллисекунд в этом случае вы обошли все соединения что-то с ними сделали а дальше подождали 200 миллисекунд в надежде на то что что то за это время произойдет то есть придут данные отправятся данные и после этого вы проснулись и дальше опять обходите обрабатывайте то что произошло по сути какая тут проблема есть ну во-первых 1 проблем это то что вы всегда ждете эти 200 миллисекунд и а данный у вас могли уже к этому моменту прийти и таким образом вы просто наносите дополнительную ненужную задержку в обработку если вы будете уменьшать этот интервал то вы будете больше кушать процессор больше делать не нужно работы задержка будет меньше плюс проблемой и когда у вас будет 1000 соединений даже нет из 1000 то мало скажем 100 тысяч то вы все равно будете проходить по всем этим 100 тысячам соединений а реально лазайте 200 миллисекунд но может быть там что-то случилось какие-то события как его ты процесс произошел на 1000 из этих на одном проценте от вашего количество соединений и не получается 99 процентов времени вы опять делаете ненужную работу так вот чтобы этим не заниматься современных операционных даже уже довольно давно не сказать что в современных на вообще по моему вызван пола select уже больше двадцати лет был придуман такой вот механизм его можно проиллюстрировать таким вот образом в данном случае вы не просто ждете какое-то фиксированное время а вы ждете ровно до того момента как на каком то из ваших соединений случиться какой-то процент прогресс то есть либо данные придут либо наоборот буфер освободиться данные отправятся либо и случится ошибка или клиент может закрыл соединение более того вы не только ждете ровно то количество времени которые нужно и обрабатываете событию моментально но вы еще знаете те соединения их количество на которых собственно что-то произошло то есть какие-то события вы не бегайте по ним по всем соединение обрабатывайте только те на которых что-то действительно случилось и стандарте posix есть для этого два вызова пол и select пол чуть новее у неё чуть лучший интерфейс но в целом они оба построены на одном и том же принципе об этом достаточно неэффективны неэффективности заключается в том что оба этих вызова на каждый каждый вызов то есть каждую итерацию вот этого цикла обработки ваших событий вашего прогресса по соединениям они требуют передачи полного всех дескрипторов всех ваших соединений в ядро к чему это ведет ну скажем вот у вас сто тысяч соединений и каждый раз на каждой такой итерации цикла вы передаете ядру 100000 дескрипторов и ядро вынужденны обходить все эти 100000 дескрипторов и проверять а случилось ли там что-то если на них на всех ничего не случилось ни на одно соединение чего не произошло это вполне может быть потому что у вас одна итерация цикла она там микросекунды может длиться а сеть медленная часть соединений вообще в keep-alive и ничего там не происходит в итоге ядру обходят все эти дескрипторы что-то проверяет а после чего ничего не произошло но должно их еще обойти добавить их в ит лист каждый из них чтобы когда что-то произошло можно было носить notify целовать об этом ваш процесс соответственно это не масштабируется то есть вот объем работы которые нужно проделать он линейно зависит от количества ваших соединений в итоге в итоге а в принципе в принципе вот когда эти вызовы были придуманы и интернет был ещё очень маленький когда типичный сервер там обрабатывал ну максимум несколько тысяч соединений это неплохо работала но в наше время по мере роста интернет-сервер и стали обрабатывать десятки сотни и порой даже несколько миллионов постоянных соединений что приводит к тому что данные методы очень неэффективны для дна таких объемах и каждая операционная система предложила свой метод обработки такого количества соединений у них разный интерфейс но по сути по сути они все построены на одном и том же принципе принцип заключается в том что они разделили вот сам способ передачи дескрипторов в и дров и опрос не случилось ли что то на этих соединениях то есть что происходит вы вам нужно отслеживать события на каком-то соединений на каком-то дескрипторы в принципе это может быть даже слушающий соки то есть не обязательно дескриптор какого-то активного соединения вы с помощью специального системного вызова регистрируете этот дескриптор в ядре один раз после чего и ядро заносит запоминает его у себя внутри в определенном списке и когда на нем случается какое-то событие она это событие добавляют у себя в некую внутреннюю очередь после чего на каждой итерации цикла вы вместо того чтобы передавать сотни тысяч этих дескрипторов ведро вы просто бросьте его а дай мне то что у вас у тебя там в очереди накопилось ядро вам выдают список событий которые произошли на всех зарегистрированных вами соединений как правило этот список существенно меньше того что того количества соединений которые вы обрабатываете ну потому что там из 2 600 тысяч соединений что-то произошло может быть на сотни соответственно это прекрасно масштабируется и эффективно работает поскольку мы сегодня говорим про linux поэтому мы рассмотрим и пол более подробнее базового он состоит из трех системных вызовов первый системный вызов это и полк рейд с помощью него вы по сути создаете вот ту сущность в ядре которая будет хранить те дескрипторы которые вы хотите мониторить то есть там создается некая внутренняя структур к в которой будет уже запоминать то что вы регистрируете у apple apple крейт вам возвращает специальный дескриптор который указывает на вот этот самый экземпляр я була внутри ядра после чего вы с помощью вызова и пол сетей или как apple control правильно сказать мы можем регистрировать конкретно те соединения те дескрипторы те слушающие сокеты на которых мы хотим отслеживать какие то события и управлять ими то есть мы можем скажем регистрировать одни события потом другие переключать какие-то режимы работы и так далее и у нас есть и получить с помощью которого мы собственно ходим в ядро и забираем вот этот список событий которые произошли на в наших дескрипторов посмотрим на интерфейс и full control подробнее потому что по сути это основной вызов который вы будете использовать не более часто собственно основное это то что ну он устроен очень просто вы передаете туда вот этот самый дескриптор которую получили из apple крейт то есть указатель на вот этот экземпляр и пола в котором вы хотите зарегистрировать мониторинг данного диска соединения их может быть у вас в принципе несколько вы можете даже создать иерархию из них то есть вы можете один дескрипторы пол экземпляров поместить внутрь другого у вас такая получится иерархическая структура по отслеживанию событий в некоторых случаях это нужно но чаще всего нет это такая излишняя функциональность можно без этого обойтись можно использовать один экземпляр непала и все дескрипторы добавлять непосредственно в него у вас есть тип события это то что вы делаете вы хотите добавить вы хотите удалить мониторинг дескриптора или вы хотите поменять его какие-то флаги настройки у вас есть собственно дескриптор который вы хотите мониторить и такая структурка которая содержит во-первых битву маску с флагами тех событий которые вы хотите отслеживать например чтения-записи ошибки и так далее и плюс какие-то режимы работы плюс также пользовательские данные то есть вы туда можете поместить указатель на некие связанные данные с конкретном дескриптором с конкретным соединением например и когда у вас это событие случилось вы получите этот указатель обратно в свое приложение сможете по нему достать например какой нибудь свой собственный обработчик который это соединение должен обработать сработать на это событие пуск плюс к этому обработчик у вас будут еще какие-нибудь данные которые хранят текущее состояние обработке вашего запроса соединения и так далее то есть ядро в принципе не смотрит что туда вы поместили вы это делаете для себя чтобы потом своем приложении проще обрабатывать то что случилось подробнее посмотрим на битую маску как я уже сказала она содержит набор флагов с помощью которых вы управляете тем о каких событиях вы хотите получать уведомление из ядра это может быть событие чтения то есть когда вы должны прочитать что-то и соединение или когда вы должны принять новые соединения это может быть запись то есть когда в буфере на отправку освободилось место то есть какие то данные ушли вы можете снова писать это может быть ошибка когда клиент там закрыл как-то соединение прислала рст все что угодно могло случиться из начиная с некоторой версии ядра это уведомление о том что клиент закрыл соединение при этом соединение может быть закрыто только с его стороны ас ваша еще лежать данные и до определенного момента отслеживать это с помощью и полу было практически невозможно то есть что приходилось делать приходилось каждый раз когда вы получали событие на чтение вычитывать во первых все данные а потом делать еще один вид просто чтобы узнать о в каком состоянии находится соединение а если вы не хотели читать все данные ну бывает такое что вы допустим что то пишите пишите пишите и не хотите пока читать данные потому что вас буферов не хватает или вы находитесь в той стадии когда их считать еще рано скажем вы обрабатываете чипе запросы вы начали обрабатывать первые запросы а у вас там на вход еще следующий запрос прилетел называется вошли типа и planning но тем не менее по какой то причине вы их не хотите читать и вы тогда в этом случае в принципе не можете узнать что клиент уже закрыл соединение с той стороны так вот со времен версии ядра не добавили специальный флаг чтобы это можно было отслеживать но сделали они довольно криво потому что в результате на старых играх если вы указываете этот флаг то он просто не работает ядру об этом никак не сообщает то есть вы хотите отслеживать закрыть с идеи вы указываете флаг интерфейсу ядра такой что он просто в битвой маски те флаги про которой тебе текке про которые он ничего не знает ни как не отслеживать не проверяет в итоге вы задали флаг вы надеетесь что вам события придёт оно не приходит и вы не можете узнать оно не приходит потому что соединение еще не закрыли ли оно не приходит потому что просто не работает notification а если от этого еще и зависит в принципе работоспособность приложения скажем ну вы просто ждете когда клиент закроет соединение если вас нам никакого тайм-аута еще при этом нет то вы получите утечку соединения что приходится делать ну первый вариант можно например проверять версию ядра это отдельное такое упражнение потому что как это может быть покажется кому-то странным но получить версию ядра linux программно в каком-то числовом эквиваленте которые можно сравнивать невозможно можно получить строчку эту строчку как-то распарсить теоретически в этой строчке может быть все что угодно там мы разные производители разные контейнер дистрибутивов туда пихают всякого плюс нумерация версий может измениться то есть не факт что то что вырос parcel и вообще превратиться в какую-то лолитную версию которую можно сравнивать более того вы некоторые некоторым интерьер и дистрибутивов портируют из более новых ядер в старые какие-то возможности и теоретически на некоторых дистрибутивах например версии ядра которую по идее должна не поддерживать и то оно будет поддерживать новые оставите своих пользователей без возможности использовать такой эффективный полезный флаг второй вариант второй вариант вы можете например вначале работать так как будто вы у вас и пули джихад не поддерживается то есть всякий раз делать дополнительное чтение не полагаться на него проверять отдельно статус вычитывать все данные до тех пор пока у но в один прекрасный момент ядро вам его не вернет если виды ядро его вернула то значит он поддерживается с этого момента вы можете переключить режим работы на режим с поддержкой этого флага проблема заключается тут в том что после запуска вашего сервера вашего приложения какое-то время она работает чуть менее эффективно чем должно в нежин exe мы сделали так что при запуске engine x он фактически тестирует работоспособность этого флага в ядре то есть он создает пару сокетов соединенных между собой создает экземпляры и пола помещает один из сокетов этот и пол на другой socket закрывает и дальше и пол вы там вытягивает событие смотрит пришел ли данный флаг или не пришел если он пришел то и worker engine x он начинает уже работать в режиме с поддержкой данного флага и не делает дополнительных чтений вот это вот такой первый момент очень неприятный дальше посмотрим также на такую вещь как тип событий это очень интересно потому что по сути я вот честно не понимаю зачем он нужен интерфейс мог бы обойтись без него но смотрите у вас есть битовая маска с флагами с помощью которых вы устанавливаете те события которые хоть хотите получать уведомления если вы не хотите получать ни по каким событием уведомлений если вы хотите удалить дескрипторы за отслеживания то почему бы это не делать просто 0 битовой маской то есть без всяких флагов если вы хотите от жильцы события вы устанавливаете конкретные by текке если вы хотите поменять отслеживаемые события поменять какие-то настройки то и просто сдаете другие биотики при этом apple вам все равно не позволяет указать один тоже дескриптор дважды то есть по сути вот этот вот это вот этот тип события он частично дублирует то что у вас задается битвой маской и в случае например когда вы упали указываете удаление то битовая маска она вообще ничего не значит там может быть указано что угодно в этом случае ядро набитую маску не смотрит она просто удаляет данный дескриптора из своего внутреннего списка почему сделан именно такой интерфейс ну не понятно наверное что то они не подумали далее какой еще момент вот это вот это вот статистика по оси сколам который делает engine x в процессе проектирования дело в том что вот эту операцию по ул control и и приходится делать довольно таки часто потому что в процессе обработки события у вас меняется в процессе обработки соединения у вас меняется какие-то вещи у вас вы хотите сначала отслеживать чтению потом не хотите отслеживать чтении и в итоге на каждое такое изменение на каждый такой дескриптор вы вынуждены делать и пул control отдельно неприятно что во всех других реализациях например в солярисе или фрипп везде какие у там вы делаете не по одному все школу на каждый дескриптор а вы можете это делать сразу на целой пачки дескрипторов то есть передать целый большой список и там это будет оденсе скол где в линуксе будет стасе сколов или 200 в разы он не очень дорогой на все равно каждый раз это приключения в контекст и драк там внутри всякие локи берутся и ну приятного мало причем я видел патче в списке рассылки где предлагали нечто под названием и full control бич по сути такой чехол в котором вы указываете ни одно событие ни один дескриптор а целый вектор массив вот этих дескрипторов и связанных с ним параметров чтобы за один сиквел сразу все их зарегистрировать или поменять какие-то флаги в них что довольно удобно и человек продемонстрировал там прирост производительности не сказать что большой но он был такой видимое по крайней мере в его и бенчмарках мы не пробовали потому что патчи были довольно сырые уже на довольно старую версию ядра и так она там насколько я понимаю лишит этим патчем уже несколько лет никто их не развивает что еще интересного интересно это поведение полы в случае закрытие соединения когда вы закрываете соединение то мониторинг связанных с ним события он автоматически удаляется то есть она связанный дескриптор который находился на мониторинге во всех экземплярах и полон а тут вы удаляется вам не нужно это делать явно тем не менее если вы в начале удалите дескриптор из мониторинга а потом сделайте клаус вот эти два вызова у вас будут работать быстрее чем просто один клаус связано это с тем что случае клаус там берется один очень неприятный глобальный лог на все насколько я понимаю это сделано для того чтобы предотвращать какие-то райс кондишен или зацикливание связанные с помещением вот этих и пол дескрипторов друг в друга и в определенных версиях ядра скажем так вот с ну неважно в определенных версиях ядра этот глобальный лак он брался в том числе при при удалении дескриптора в итоге и разницы никакой не было но вначале они это добавили потом они это убрали починили в итоге сейчас опять выгоднее делать сначала удаление дескриптор из и пол а потом закрытие соединение это работает быстрее вот такой вот нюанс про который имеет смысл вообще знаете его использовать что же касается всего интерфейса и палата это не только тряси сколы о которых я говорил в интерфейсе полу можно отслеживать разные вещи например сигналы можно обрабатывать сигналы через него можно устанавливать обрабатывать там специальный таймер можно отслеживать изменения связанные с файловой системы там изменения связаны с айподами с директориями и так далее для всего этого нужно куча си сколов причем зачастую первые версии этих си сколов они были какие-то неудачные или потом решили расширить и функционал добавили еще какой-нибудь параметр в итоге мы имеем двигаешься одного и того же си скола пример сигналы в и сигналы в d4 то есть в одном столько-то параметров потом они подумали что их не хватает сделали еще один syscall где еще больше параметров в итоге у нас огромное количество си сколов при чем работа с ними зачастую довольно сложно и вот взять например интерфейса и на тихой это отдельная интересная штука потому что если вы хотите допустим отслеживать изменения по нескольким енотом вы создаете специальные экземпляры этого и на тихой запихиваете туда некий набор вот того что вы хотите отслеживать а потом вот то что вот эту вот коробочку в которой вот эти вот руки вы запихивать еще внутри пола в итоге вас есть коробочка который уведомляет вас о том что у вас есть изменения в некой другой коробочки из которой вы уже можете уже вытащить то что вам нужно и все это делается просто чудовищным количеством в сравнении с интерфейсом free везде чудовищным количеством кода чтению мануалов и всеми сложностями с этим связанными я не могу сказать что вот интерфейс какие у скажем полностью эквивалентен всем этим списком где то есть возможности которых допустим нету в пул они есть в какие у каких-то возможности нет в как ёну они есть и пол но в целом интерфейса эквиваленты при этом интерфейс какие он очень в сравнении со всем вот этим набором дескриптор фон во много раз проще это просто одна страничка мануала достаточно ну побольше чем дал среднестатический может быть но ее реально прочитать ее реально понятие там ну вот расы и прочитав вы понимаете как это работает и вы можете делать все вот эти штуки которые вы сможете сделать только изучив вот все вот эти вот вещи и мне было очень интересно и удивительно учитывая что как у был придуман да и пола то есть когда люди изобретали пол какие уже существовал я стал искать в списках рассылки в архивах собственно от огня был была ли какая-то дискуссия почему они решили сделать так и я нашёл вот такой вот заключение линуса по поводу какие он ну я не буду приводить скажем так он посчитал его перри усложненным прошло много лет и ну просто чтобы сравнить я решил посчитать количество слов в мануалах там если выкинуть всякие экзампла и так далее просто реально в слов которые описывают интерфейс во всех связанных и полом вызовов и в какие и получилось вот такое вот соотношения причем она в принципе довольно релевантно то есть по моим ощущениям это действительно вот в столько раз сложнее всу столько раз сложнее понять чем интерфейс в рибизи перейдем дальше значит второй момент которым то есть вторая задача которую вы хотите скорее всего будете заниматься если вы пишете какое-то серверное приложение веб-сервер вы наверняка будете читать файлы и как ты их отправлять и если вы делаете это способом мультиплексирование ввода-вывода то вам соответственно нужно интерфейс для синхронного чтения файлов иначе вы просто заблокируйте вот этот ваш цикл обработки событий упа каллас файл будет считаться с диска никакие другие события не будут обрабатываться ты год хочу сразу сказать нормального интерфейса работающего в линуксе для синхронного чтения файлов нету нету по сей день есть интерфейс пасек солью который сделан просто в виде галиб session и и обертки над рядами он очень эффективен он сделал просто для того чтобы пасека совместимыми программы хотя бы запускались и хоть как-то работали а какой-то высокой производительности и масштабируемости говорить то мне приходится есть ядерный интерфейс у него есть один очень серьезный недостаток который сводит возможности он нормального применения для наших задач практически в ноль то что он требует там выравнивания это решаемо но он также требует установки флага ударов что означает что все чтение у вас будут происходить непосредственно с диска минуя кэш страниц в итоге вы увеличиваете в разную нагрузку на дисковую подсистему в некоторых случаях это допустимо но чаще всего у вас есть некий горячий контент который оседают в каше в страницы которые можно было бы раздавать непосредственно с из памяти со скоростью в несколько раз выше чем позволяет ваша дисковая подсистема поэтому использовать терну лаю в линуксе для синхронного чтения файлов в большинстве случаев просто невозможно и приводит только к худшим результатам чтобы как-то решить эту проблему мы в engine.exe разработали свою свою систему полу в потоков для выполнения вот этих блокирующих операций чтения в отдельных потоков которые работает эффективно об этом я написал отдельную большую статью и эта тема на самом деле еще для одного 40 минутного доклада поэтому сейчас я подробно об этом рассказывать не буду если вы хотите можете сфотографировать вас сейчас этот слайд и дальше пройдете по ссылке почитайте там интересное в принципе изложена в очень подробно и понятно как все это устроено как всё это работает хочется отметить также отдельный момент что интерфейса опять же с использованием своих собственных наборов потоков для обработки этих операций он оказывается неэффективным из-за отсутствие в linux ядре возможности узнать о находится вот находится ли те данные которые мы хотим сейчас прочитать в памяти за кеширование ли они в каше страниц либо они лежат на диске потому что обработка чтение или запись и внутри тула потоков она имеет определенные накладные расходы и если все-таки данные находятся в памяти что для горячих данных самой распространенной ситуации то выгоднее их просто взять и из памяти скопировать чем обрабатывать это как-то в отдельном потоке и так далее поэтому я видел списки рассылки предложения разных интерфейсов которые бы позволили эту задачу решить но никакого прогресса в этом направлении нет то есть как они лежат почти соответствие так их никто не развивает не смотрит не проверяет другой момент опять же связаны с операциями с файлами чаще частые задачи когда вам нужно просто взять и отправить некий файл в сеть и для этого для этого вы можете стандартно брать его читать в какой-то собственный буфер потом писать его в socket читать писать считать писать или вы можете использовать такой системный вызов как сын файл который позволяет просто брать и отправлять файл непосредственно в сеть минуя вот эти операции копирования ваше пользовательское пространство вашего приложения что гораздо эффективнее проблема тут в том состоит что сейчас пошел такой тренд повсеместного внедрения и чтить ps повсеместного внедрения happy 2 который в браузер работает только с использованием тела с и в итоге вы просто не можете взять и какой-то файл отправить сеть вы должны его прочитать вы должны его зашифровать и дальше уже посылать то что у вас получилось из infile в таком случае не применим вов в системе free free везде есть наработки которые позволяют делать это шифрование в ядре и использовать сын файл сокетом который работает по тел с то есть вы используете сын файл сын файл в ядре начинает берет вот эти вот странички из печки ш шифрует их и уже отправляет socket в том виде в котором нужно в линуксе ничего такого еще даже я не почти не видел ни наработать никаких тем не менее если вы телесно использовать это вы можете использовать эффективный вызов сын файл и до недавнего времени до повсеместного вот этого внедрения ешьте без практически все все файлы которые вы отправляли engine иксом они отправлялись с помощью сын файла и это было быстро и эффективно поскольку сын файл не входе с пасек 100 опять же каждая операционная система реализовал его интерфейс на свой манер сожалениях linux как всегда сделал это хуже всех вот можно сравнить интерфейс и кажется что у solaris и free bsd интерфейс сложнее больше параметров все дела но параметры реально нужны и по крайней мере некоторые из них точно дальше я объясню почему а в linux sunfire просто взять и отправить некий файл socket вы указываете дескриптор сокета вы указываете дескриптор файла вы указываете смещение в этом файле размер отправляемых данных делайте с вызов send files in file возвращает то количество байт которая отправилась или какую-то ошибку при этом также если вы задали смещение то смещение будет переставлены во free bsd они подумали о том как вообще люди будут этот сын файл использовать они решили что его будут использовать преимущественно в в серверах но в принципе почти без серверах наверно еще в некоторых других протоколах это может быть полезно они сделали так что вы можете за один сет файл отправить несколько буферов которые указывают на данные в памяти затем отправить файл а потом можно еще несколько буферов в памяти отправить и все это сделать за один вызов это удобно в частности вы можете одним вызовом сын файл отправить ищите типе заголовки которые вы сгенерировали и дальше данные собственно файл который вы хотите отправлять и free bsd это делает за один вызов в солярисе сделали еще удобнее там просто указывается массив 0 правильно говорить вектор в котором вы можете указывать в произвольной последовательности файлы и буфера из памяти то есть вы можете одним вызовом отправить сразу несколько файлов несколько буферов с памятью и они могут перемешаться в произвольном формате то что сын файл в линуксе такой примитивный они на это недавно наступили причем наступили они совершенно неосознанно в ядрах который по старше чем 43 сравнительно свежая ядра сын файл если его прерываю был в принципе ну как то сказать он был не intractable то есть его не невозможно было прервать там сигналам или чем-то он либо прервался сразу не отправив не байты возвращал и enter либо отправлял все и только потом прерывался они подумали а что это у нас он так работает давайте ка мы его будем прерывать на середине в итоге если вы работаете с асинхронными с не блокирующим ся с соединениями с не блокирующим сокетами то вы не можете отличить теперь если у вас infile послал меньше байт чем его просили ситуацию от того что его прервали или от того что у вас просто заполнился socket ный буфер то есть вы вынуждены делать еще один затем вызов сын файл только чтобы либо еще отправить байт либо наконец получить я game то есть сообщение о том что мы отправить просто больше не можем каждый раз нужно делать на один syscall больше потому что вот в соке дной буфер чаще всего все же меньше чем размер файлы которые вы хотите отправить то может быть там картинка на мегабайта и вот он вам вернул меньше байт а почему он это сделал потому что его прервали или потому что ракетный буфер заполнился в одном случае вам нужно просто отправлять дальше а в другом случае вам нужно ждать пока соки тный буфер вместо там освободиться и как мы об этом узнали что вот это произошло а нам просто пришли завели ticket у человека утекали отваливались соединение по тайм аутом а не отваливались по таймауту потому что мы использовали сын files and файла брат отправлял меньше болеть чем его просили мы думали что это потому что сок 1 буфер закончился на самом деле его прервали просто и в итоге в итоге у нас данные socket на boost буфер они уходят потому что он не декан не достаточно заполнен для формирования 1 пакетика а мы думаем что он заполнен и ничего не происходит происходит таймер через какое-то время мы считаем что клиент ничего не считает свежих и и равно не говорит он не устанавливать случае сын твой сын файл он возвращает либо количество отправленных байт либо вот непосредственно ошибку которая произошла то есть если ничего ничего не было отправлено то это будет статус ошибки и enter или и again либо error там допустим а если он вернул количество байт то все они через р нол никак иначе не вытащишь эту информацию только делать еще один из колы только узнавать о состоянии соединения помимо отправки файлов и обработки большого количества соединений нужно также зачастую обрабатывать большое количество новых поступающих соединений для этого можно использовать частности такую опцию который появился сравнительно недавно как сорью спорт она работает в линуксе dragonfly везде несколько иначе чем других системах типа solaris или free везде вы можете открыть несколько слушающих сокетов на одном и том же адрес и порту и соединение которые будут входящий поступать на этот адрес порта не будут раскидываться по всем этим соки там в итоге вы если если вы используете скажем несколько процессов или потоков для обработки входящих соединений вы можете открыть с данные опции нужное количество соль слушающих сокетов по одному на этот процесс и принимать соединения на всех вот этих потоках независимо друг от друга то есть вы там не наступаете на внутренней лак на слушающим сокете и вырос раскидывайте соединение равномерно по вашим обработчиком но в линуксе есть проблема вот скажем если вы указываете и и спорту engine.exe то он открывает по одному такому слушающему сокету на каждую пару адрес порт для каждого рабочего процесса но если вы после этого захотите изменить количество рабочих процессов меньшую сторону то какие то и сокетов вам нужно закрыть и при закрытии те соединения которые уже лежали в очереди на акцепт в данном сроке тяни просто пропадут ядро про них забудет и в итоге вы потеряете просто некоторое количество соединений которые уже прошли полную процедуру тисе пи хан шейка когда разрабатывали аналогичную функциональность dragonfly визиту разработчик dragonfly без дела пришел к нам и показал нам свои пальцы в свои патчи мы их протестировали мы указали ему на проблему в итоге он сделал по-человечески теперь dragonfly везде когда вы закрываете один из таких тов то те соединения которые же были по пахать шейкин и лежали в очереди в данном сроке эти они будут распределены по оставшимся и ни одно среди не пропадет в linux проблема сохраняется они об этом не подумали собственно вот подводя итог моему сегодняшнему докладывать все эмоции которые у меня возникают от когда я работаю с интервью linux api они могут быть выражены в данной картинкой собственно на этом у меня все если есть какие то вопросы у нас еще видимо есть девять минут до доклада можем наверно минут пять оставить на вопросы остальное если хотите я буду тут рядом подойти задать не стесняйтесь спасибо большое за доклад вопрос следующий так вы занимаетесь я думаю с разработчиками ядра linux каким-то образом и что они вам на эти претензии сказали или вы к ним не приходили с этими проблемами спасибо понимаете эти проблемы как бы это не я их открыл они известны просто linux он разрабатывается довольно так ходить хаотично вот есть у кого-то там желание сделать так то и что-то и он этим занимается он присылает патчи эти патчи попадают в ядро и в итоге происходит так вот мы сделали вот это нате вам пользуйтесь как хотите а дальше уже наша задача как бы пользоваться этим так чтобы все работало я на самом деле я хотел пофиксить некоторые из этих проблем к сожалению к сожалению времени пока на это нет есть уже какие-то наработки и наверное если ситуация будет продолжаться в таком состоянии то я найду на самом деле время давиду этот момент до конца по крайней мере то что касается оптимизации обработки асинхронного чтения файлов в отдельном пули потоков они очень необходима нужны если ничего никто другой этим не займется придется этим заняться самостоятельно просто поливаете я не кинул разработчик я плохо знают there на лапе внутренней и у меня это займёт просто колоссальное количество времени по сравнению с людьми которые этим занимаются которые работают в крупных компаниях именно занимаясь разработкой непосредственно ядра и работает снимка каждый день я в него чаще всего только просто посмотрел смотрю посмотреть как оно там внутри устроено и найти объяснение каким-то вещам которые я не понимаю например как тормоза при закрытии соединения без удаления его и сыпала мы оба не понимаю что у пункт mail пишет а как раз вещают который экономит на системных вызовов открыть и закрыть его да верно open file cache он просто афиширует открытые файловые дескрипторы то есть индекс в этом случае не делает лишние вызовы там вот он файл или клаус файл проблемы это дает харон неплохой прирост во всяких там микро бенчмарках на реальной ситуации наверно польза от него не очень много спасибо большое за доклад интересный у меня наверно такой дурацкий вопрос будет вы сейчас рассказывали о системных вызовов но мне всегда казалось что users пресные приложение они должны использовать но функции которые в липси вот идут которые как бы обертки над этими системами вызвать то есть хотелось бы понять это то есть у этих си сколов есть аналоги или psy и можно их использовать они все делают вот так как вы мы конечно же используем обертки гиллис техника в том случае если они есть но например для некоторых сих сколов оберток до сих пор нет и приходится их делать через но опять же все равно и безуспешную функцию все school который подготавливает там параметры все что необходимо для вызова я просто для упрощения в данном докладе я говоря системном вызове я не отличал скажем там не делал различия между обертки над ним и непосредственно самим системным вызовом понятно что сам системный вызов он может там отличаться по названию но большинство просто знает и их имена в виде оберток и смысла в общем-то искала использовать в том случае если есть обертка использовать его напрямую нет этому не очень портабельная не очень хорошо то есть вы стараетесь использовать ребенку когда она есть да ну да да да и естественно например для и полы где по-моему до сих пор обертке нету спасибо вопрос про сын файл если цифры которые сравнивают эффективность инфа по сравнению с классическим ретро и и сравнении с только райт если у нас уже объект целиком из песен я во первых не очень понимаю как сравнить сын файл с чисто в рай там когда у вас уже в памяти я думаю что даже в этом случае на самом деле сын файл будет чуть чуть побыстрее потому что опять же 1 1 копирование меньше безусловно есть бенчмарки сын файла если бы он не давал прироста то и вам никто не использовал сын файла уже много-много лет и можно просто нагуглить и огромное количество материала на эту тему более того когда мы в engine.exe сотрудничали с такой компании как netflix который занимается раздачей огромного количества видео и на самом деле генерирует 30 процентов всего трафика в сша то основная работа шла она тем чтобы оптимизировать сын файл в ядре free везде потому что они используют при въезде и сейчас send file free бейзил очень эффективный в последних рядах более того он еще и асинхронный уважаемые участники к сожалению время лекций подошло к концу продолжить обсуждение вы можете переговорных комнатах ряду с нашей аудитории"
}