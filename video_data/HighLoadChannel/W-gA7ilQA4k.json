{
  "video_id": "W-gA7ilQA4k",
  "channel": "HighLoadChannel",
  "title": "Виртуальный ЦОД для корпоративных клиентов / Д.Канаев (Caravan), Д.Лунев (Virtuozzo)",
  "views": 557,
  "duration": 2925,
  "published": "2017-04-22T14:48:18-07:00",
  "text": "коллеги здравствуйте меня зовут дмитрий коняев я технический директор компании караван караван aero это один из наших проектов я постараюсь чтобы не было похоже на рекламу но помимо этого мы являемся оператором связи оператором сода процесс это важно кто мы что мы что мы мы не разработчики там зачем тут я что я могу вам как разработчикам в той или иной степени сказать мы собрали и эксплуатируем высоко нагруженный кластер который является собственно говоря сердцем нашего облачного решения караван aero и от нас поступает достаточно влажной на мой взгляд denis не даст соврать если что фидбэк о том как же собственно говоря конечные пользователи и живут с тем продуктом который предоставляем и как сервис-провайдер и этот feedback но помогает ребятам изменять свое виртуальное решения собственно говоря разработчикам изменять решение подстраивались под быстро изменяющейся рынок опять штамп такой получился он так вот собственно говоря что же мы делаем что мы предоставляем клиенту ну можно сказать что мы являемся одними из пионеров облачных услуг если помните ли это так несколько тому назад примерно там 5 когда у нас маркетологи стали активно говорить о оу клауд клауд компьютинга бы облачные вычисления ну и что же такое спрашивали тогда все до кто-то вообще не понимал кто-то из тех кто там давно в отрасли тоже такой вот смотрите какая плотность хостинг-провайдеры мы в том числе гривну плотность и что собственно говоря а не хотите 400 сайтов там дано дух сионом сервере со старыми ищу катионами ну вот они 400 живут вот мы их вот плотность и знаете пять лет назад до на этом обычно как-то диалог и заканчивался это сейчас мы знаем не буду цитировать википедию все вы знаете что там клауд это не только плотность это еще и оплата ресурсов по требованию там да и пула ресурсов и миграции все дела ну собственно говоря дорога облака для нас по крайней мере начиналось плотности но клиентские требования растут мы сервис-провайдер до нашего цель основная это собственно получение выручки привлечения клиентов и мы вынуждены были меняться вслед как бы за пожеланиями клиентов наш там старый хостинг был помните такой free bsd джейл и верой и правдой служил отказа не было отличной шаевич но как я вам рассказал приходится меняться и два года назад мы запустили на базе виртуоза и прочих компонентов о которых чуть чуть позже наш центр облачных решений караван аир что мы имеем сейчас мы имеем vps ну цифра на все прекрасно видят на базе контейнеров туда же поехал наш виртуальный хостинг который уже упомянул представлял себе free bsd джейл эмигрировал вообще без вопросов всем все нравится благо того что конечные клиенты вот они видят панель управления что-то внутри ну практически всем все равно iaas более простая услуга выдаться на котором восстановлю чуть подобные последним мы запустили вот облачный бэкап на базе округе начинали мы с иоаса который представляет из себя на 1 подписки клиентской там любое количество виртуальных машин или контейнер да как виртуализацию мы используем виртуоза который обязательно потом мы перейдём собственно говоря пожалуй самая простая наша услуга ну проще только vps и которые просто на просто на базе контейнер эти два слова как это устроено внутри используем и даром средства виртуализации этого везде виртуоза 6 сейчас собираемся переходить на ту самую семерку который будет посвящена часть выступления мы в моего коллеги используем и виртуа же виртуоза виртуоза сторож собственно говоря программно-определяемой схд такое модное сейчас слова нам признаться очень нравится есть безусловно свои недостатки но эта тема там для отдельного для отдельного выступления или готов на ответить вам на вопрос и по эксплуатации его вот завтра на одном из этапов будет тема про то как мы разносили этот сторож да обязательно упомяну в качестве обвязки для праве женин к и биллинга используем и решение там оси 1 автомашин cloud infrastructure или инграм микро сам признаться немножечко запутался словах до изначально все это было решением от одного пропал одного поставщика параллел сейчас они немножко поменялись но в честь и собственно говоря всех участвующих компаний мы пока это не очень чувствуем то есть одна одна точка входа по поддержке у нас как было так она и осталась команд разработчиков изначально было несколько того биллинговые части вправе женевской части счастье в виртуализация и так далее так вот вверху справа основной наш продуктивный кластер архитектура точно такой же кластер только поменьше используется для управления всем этим делом до собственного первую очередь для отказоустойчивости там же будут виртуальной машинки на которых базы данных собственно говоря веб морда извините для для для клиентов для захода слева plaster нашла бараны которой мы все новые апдейты до новые продукты проверяем и вот там слева вверху последнее запущенное нам acronis backup услуга для нас внешняя единственный мы ее сопрягли с нашим модулем у нас можно нашим модулем управление очень хорошо так вот как я рассказал запустили мы в первую очередь iaas сторож наш нас на основе виртуоза виртуоза сторож был свободный все замечательно все хорошо все летало пошли клиентам и порадовались но как только стало все нагружаться вы поняли чтобы наступили на очень много как бы детских болезней и на очень много грабили ну например виртуоза скорость до когда мы запускались мы использовали гигабитная сеть два гигабита турчин или изначально все летало замечательный клык классе он начал загружаться нам перестало хватать пропускную способность перешли на 10 же я все замечательно кластер летает стал загружаться чувствуем не хватает и abs of ну банально пришлось расширяться добавляя определенное количество дисков экспериментальным путем вычисляет о соотношении которое нам нужно там по количеству дисков по их по их скорости для обеспечения качественной работы стороны вроде бы и все хорошо и тут бабах наступаем на следующие грабли мы сначала использование использовали универсальные ноты до в чем для нас было было одно из преимуществ решение которое мы использовали что в принципе не нужно никакого специального оборудования до это там самые обычные серверы в которых там есть диски и эти диски используются в том числе и для сторону все очень хорошо сторож совершенно замечательный мне как человеку там отвечающему за эксплуатацию сидела на высоком уровне все очень понравилась вот простой пример вы тут все специалисты но вот там не специалист где действует убойно просто бетон raid5 там знаете да диск вылетел челок делать держать надо менять диск бегом гореть не успели но есть не успел то все ну окей там бывает еще там в какой вход с вами диск там крутятся да ну неважно запасной диск в чем прелесть нашем решении которым применили но вылетел там один диск да все перестроилась он уже не нужен выглядела целая нота дисковая система хрюкнула перестроилась до просадки опять же зависит от количества этих самых дисковых нота стороже и система опять работы ну понятно если их там нет рио а там не знаю штук десять то уже можно совершенно спокойно и не опасаясь ставить но ставить ставить цель сервер новый и как бы жить жить обеспокоен но мы получили неожиданный эффект на практике что когда но до виртуализации до физически находящиеся на том же сервере произошел какой-то сбой да причем мы раза три по разным причинам наверное наступали происходил замедление всего сто раз и в результате мы сделали простую в общем-то весь разнесли отдельно ноды виртуализации и но ты под сторож опять же все стало там более-менее хорошо тут мы начали получать фидбек от наших клиентов которых мы там определенное количество получили и поняли что достаточно простых услуг да вот там где то они были а именно вот в псы и aac и не хватает причем не хватает для клиентов там ну более крупных назовем их условно корпоративные клиенты да ну хотя там они есть разные по-настоящему корпоративные клиенты у которых много различных виртуальных машин контейнеров а также и там частных лиц о замаскированная под корпоративно ну не важно короче клиенты назовем и корпоративные с потребностями в плане сетевой инфраструктуры да и к сожалению наше первое решение иоаса но было достаточно скудно в отношении сетевых возможностей в отношении там или два туннелей в отношении роутинга поэтому мы добавили в наше решение в dc flexo на торги strata да тоже готов про эту штуку потом отдельно поговорить или коллегам нашим опять же стала жить чуть чуть лучше начали появляться крупные клиенты смогли ему удовлетворить их потребности в плане сетей научились работать там с чужими автономными системами с их айтишниками начали делать туннеле да как вы помните я говорил мы являемся оператором сода и у клиентов было ну обычная такая всегда потребность а сделаете мне его туннель да там или связанность между оборудованием железным которые находятся в суде и облачным сервисом я буду там постепенно ресурсы переводить или буду расширяться с внедрением flexo на регистратора мы смогли сделать и это процент помните говорил что это важно мы этот вы должны были переви перевести на 600 и надо сказать что облако нам в этом плане очень сильно помогло давно так был был приличный на переезд соды опять же отдельная тема хотите расскажу мы перепили возили оборудование стойками это было ухо downtime получился весьма приличной и вот многие в том числе достаточно крупные проекты нам удалось спасти от этого downtime а загрузив их на время переезда в наше облако собственно говоря на этом мне надо закругляться ибо вот важно да про ложку дёгтя в бочке мёда и все у нас хорошо и замечательно и плотность высокая и контейнеры работают у виртуальные машины работают из сеть в более-менее разобрались но появляются новые запросов клиентов мир не стоит на месте мы сказать обязаны если хотим расти на эти запросы реагировать из минусов что у нас есть не научились мы до конца хорошо работать с windows server машины там не знаю с линуксом контейнеры работают быстрее чем виртуальную машину с windows сам у нас это наш этом очередная задача из актуальных потребностей клиентов это возможность управления своими ресурсами и изменение их на лету виртуальных машинах так же как в контейнер вот мы слышим от наших клиентов подобные обращения что было бы хорошо а мы как сервис-провайдер хотели бы увеличивать плотность собственно говоря клиентов на серверах вот собственно на этом моменте хотел бы передать слово единицу который расскажет более подробно тома планах направлениях развития и т.д. и т.п. если будут вопросы то там лучше потом обязательно на все отвечу для них прошу ну на самом деле я немножко расскажу про то что мы делали с производительностью в последние года полтора а че так случилось что мы вынуждены были разделиться как говорил виктор на несколько команд и в связи с этим разделением нас открылось какой-то окна возможностей окно возможностей которая случается очень редко и в результате этого окна возможностей мы приняли решение о замене to enforce топе серверная инфраструктура которая использовалась в проекте изначально в parallels клауд сервер 6 которая сейчас находится продакшене мы использовали наш собственный гипервизор который был целиком и полностью разработан нами и получи нами как наследство некоторого другого интересного проекта parallels desktop это было хорошее интересное решение но скажем так компания стала существенно меньше и вести полностью собственную разработку было принято решение о том что это не целесообразно мы посчитали подумали на что можно заменить и в общем-то появилось такое достаточно натуральное решение перейти на яму кого им но миллион разных хороших интересных вещей которые в гу ему есть которые нужно было реализовывать в десктопе заново своими собственными силами нужно было реализовывать поддержку выгрузки страниц виртуальных машин в своп нужно было под реализовывать поддержку ксм много разных таких вот вещей можно было попробовать использовать эмуляцию устройств которая была у нас в parallels клауд сервер 6 и использовать стандартный квн таковым это standalone вещь можно мы тоже это попробовали от моделировали и пришли к выводу что это тоже не целесообразно силу того что мы имели возможность отказаться от некоторого нашего тяжелого наследия ну почему потому что q яму с точки зрения серверных вещей с точки зрения голые технологии она существенно лучше че там более гибкая система конфигурирования большие возможности по эмуляции что на полностью открытой поддерживается довольно большим количеством компаний соответственно мы можем взять эти наработки и попробовать внести туда какие-то изменения лично наши которые сделают эту систему лучше он что значит лично наши это значит что мы вносим изменения мы получаем некоторое преимущество за счет внесения этих изменений но после этого это естественно падает mainstream потому что мы это не можем поддерживать без каких то других людей если мы говорим о том что мы используем какой-то open source нужно определиться что мы используем в качестве базовой системы ну компонентах здесь естественно 2 это ядро и будем брать mainstream на и ядром версии скоб там 46 47 48 нецелесообразно в силу эксплуатационных причин потому что если мы возьмем мои стрим на ядро она но скажем так не работает или возможны разные интересные ситуации значит если мы рассматриваем mouth я сам довольно давно работаю с linux я беру это ядро компилирую на свою машину в такая у запускаю все замечательно работает никаких проблем с этим нет почему а в коммерческой эксплуатации нельзя так использовать но очень просто потому что заказчики совершенно разные и мы несколько раз сталкивались с ситуацией когда у какого-то клиента в южной америке стоит какая-то замечательная сетевая карточка или какой-нибудь замечательный skazi контроллер единственном экземпляре из всех наших клиентов а в мы в москве его даже заказать не можем он в россию не поставляется а у них какие-то проблемы в этом смысле в этом смысле вот единственное какое-то разумное решение это пользоваться ядром с протестированной аппаратной поддержкой и в этом смысле в этом смысле мы когда-то давно выбрали приняли решение пользоваться радха тн им ядром да она кажется немножко старым 310 по сравнению с нынешним 48 на самом деле это не так дело в том что то ядро 310 которая там есть она на самом деле совсем не 310 значит в него влито такое количество разных протестированных радха там патчей что если говорить про квн the red hat 72 эквивалентен воинственному ядру 42 значит сейчас выходит 73 значит он эквивалентен по этому ядру 44 по моему я говорил с ман тренером радха то они постоянно это бы квартируют и то количество работы которые мы вынуждены проделывать для того чтобы у нас все было хорошо и замечательно она на самом деле не так велико как может показаться ну и если мы используем в качестве об стрима red hat то в этом смысле совершенно логично использовать в качестве up stream а то что выдает red hat и в коем ровно по тем же самым причинам потому что жить с этим намного проще хотя на самом деле с точки зрения q ему это такого значения не имеет все наши разработки доработки до настройки они попадают в мейнстрим ecu ему в этом смысле она намного проще то есть можно было бы взять но вот мы приняли это решение наверное сейчас об этом не жалеем это была такая небольшая предыстория а теперь собственно говорят о чем мы занимались этот год мы пытались сделать то что было нужно нам по бизнес причинам для того чтобы у нас функционал был не хуже чем в parallels клауд сервер 6 но это неинтересно самом деле потому что но это уже то же самое это уже сделано но чего на этом заостряться а интересно это то что мы провели какой-то свой анализ производительности и плотности этого решения и нашли нa некоторое количество разных интересных маленьких штучек и собственно говоря вот эти вот маленькие интересные штучки они очевидны вот когда ты находишь эту штуку ты удивляешься ну как можно было вот это не заметить а вот это вот маленькая штучка дает какой-то свой вклад в производительности когда они все складываются как сложение бесконечно мала получается вполне приличная разница которая в общем-то ну наверно я как проделавший эту работу могу немножко погордиться ну и так значит если мы будем говорить про оптимизацию то что имеет смысл оптимизировать имеет смысл оптимизирует сетку диск память ну и какие то какое то использование процессора в сети сознаюсь мы ничего особенно интересного не нашли значит возможно было была одна маленькая вещь которая нам облегчило жизнь это доставка прерывание про нее поговорим чуть-чуть позже поэтому начале мы все таки с диска первая самая простая вещь которая существенно как оказалось влияет на производительность на стандартных не очень быстрых дисков если мы возьмем там какой-нибудь дисковый массив из пяти или шести сасовский дисков которые там очень быстро работают так далее ничего не увидим она стандартным дисках в первую очередь играет объем метаданных которые хранятся внутри у эму для доступа к диску все диски хэн провяжу нет которые работают которые хранятся в том или ином формате соответственно там есть таблица локации дата блоков и собственно говоря вот в стандартных настройках руку ему вот в памяти держится метаданные которые покрывают 8 гигабайт дискового пространства гостя и этого оказывается мало как только мы увеличиваем этот размер жить становится существенно легче на самом деле если говорить про анализ разных интересных вещей которые влияют на производительность именно вот формате кукол 2 год с небольшим назад на квн форме 20 15 года был очень интересный доклад вот собственно говоря я привел тут ссылку на него значит если вы этим интересуетесь посмотрите там можно найти много довольно интересных деталях дальше 2 вещью которую все упираются это количество флэшей flash очень дорогая операция и даже если flash никаких реальных данных не записывает все равно на физический диск высылается специальная команда которая дисковый барьер которая тормозит производительность других виртуальных сред совершенно банальная вещь если у вас диск не было никаких изменений не не надо делать тот flash который прислал гость простая оптимизация но тоже существенно помогает и последняя вещь которую мы нашли пол точнее не последние вещи это то что всегда является головной болью это не выровненные операции записи первая проблема которая есть она довольно странно linux новое ядро ведет себя очень плохо тогда когда мы выполняем операцию записи и буфер который мы записываем не выровнен на страницу минимальное требование при выполнении записи с директом это выравнивание buller она 512 байт вот в этом случае дисковый запрос разбивается ядром она 2 даже если мы записываем довольно большие куски на 2 или на 3 и в результате мы имеем падение производительности на 35 процентов счастью если мы говорим про запись из гостя этих ситуаций не бывает гостевая операционная система всегда присылают болеро выровни на страницу но если мы выполняем какие-то операции копирования блоком для миграции или еще для чего-то то вот в этом случае у нас выполняется аллокация памяти внутри q ему и если она не выровнена мы теряем нашу замечательную производительность запись из гостям когда мы выполняем расширение нашего образа когда нам нужно дописывать в конец новые блоки в этом случае в случае если у нас эта операция записи не выровнена на блок нашего замечательного формата фактически мы вынуждены проводить операцию записи два раза но представьте себе мы пишем 4 килобайта но так устроена мы должны записать целиком весь блок соответственно записали 4 килобайта записали конец этого блока после этого приходит следующая запись и мы записываем этот блок еще раз в два раза больше пишем вот подпорку в это место после вставления подпорки в это место нам стало немножко получше значит мы вместо того чтобы записывать целиком блок мы блок провоцируем и пишем ровно то что прислал гость дальше какие-то маленькие вещи которые мы нашли для оптимизации именно работы с процессором но самое простое тупое это если мы хотим чтобы у нас была нормальная производительность нужно отключить изменение тактовые частоты потому что изменение тактовой частоты занимает время занимает время все ну к сожалению да мы вот не экологичные в этом вопросе про сара будут греться но тут уже нужно выбирать хотим мы достигать какой-то максимальная производительность или не хотим на самом деле на самом деле случае когда система работает со верхами там а система подсыпку всегда работает с верхами там потому что если вот мы посмотрим на цифры которая показывал виктор значит когда на машине крутится 40 fps это означает что у нас эта система работает с верхами там по циpкa ну наверно раза в четыре как минимум кабы не 8 поэтому мы все равно не будем зелеными пушистыми поэтому нужно отключить то что никому не нужно а дальше вот собственно говоря тот самый вопрос доставки прерываний в тот момент когда мы выполняем операцию доставки прерывания посылаем меж процессное прерывание обычно после этого система уходит в хальт и ждет того как ее разбудит ну точнее виноват когда мы например посылаем сетевой пакет из одной виртуальная машина в другую виртуальную машину мы хотим наверно получить ответ есть простая оптимизация процесс процессор не нужно переводить хальт стоит потому что если к нам пришлют ответ единственный способ прислать ответ и разбудить нас из халь то это послать мяч процесс на прерывание меж процесс на прерывание как всем наверное известно очень дорогие если мы можем этого прерывания избежать мы существенным образом можем поднять производительность систем ну вот простая оптимизация по спине ца некоторое время перед выходом в хальт чет банальная вещь но такая оптимизация дает порядка тридцати процентов производительность именно на тестах латентности сети и наверно самое вообще мерзкая вещь во всем нашем решении это сбор статистики почему я говорю что эта вещь мерзкая потому что это проблема в мейнстриме на текущий момент не решена для того чтобы собирать статистику поедается очень много процессор на во времени гостевая статистика собирается внутри гостя после этого она поверх его посылается в госдуму после этого иску ему она забирается liberton по запросу который инициируется liberton и после этого ее забирает тот кто эту статистику каким-то образом агрегирует это огромное количество контекст свечей огромное количество процессор на во времени затраченного впустую все что пока на текущий момент сделано это мы хотя бы сделали то что либерта дает статистику по всем виртуальным средам в один запрос но все дальнейшие шаги нужно продолжать оптимизировать это проблема ну в стеке на текущий момент не решена ну и последнее наверное самая нужная всем это вопрос с памятью потому что чем больше мы хотим использовать виртуальных сред тем больше у нас будет а верка мид по памяти здесь к сожалению или к счастью есть два противоречивых требований а в тот момент когда у нас виртуальных сред на компьютере мало очень выгодно всю память виртуальных машин завопить большими страницами это даёт примерно 10-15 процентов производительности но как только мы начинаем виртуальные машины размещать в большем количестве нам хочется чтобы у нас одинаковый странице виртуальных машин лежали в одной физической странице вот в настоящий момент это можно сделать только разбив большие страницы на маленькие мы теряем в производительности новые героем в плотности альтернативная вещь альтернативная вещь это numa affinity сейчас все современные большие сервера имеют numa архитектуру то есть у нас есть память привязана к одному процессору и память привязаны к другую по-другому процессору вот собственно говоря процесс объединения страничек в одну физическую страницу конечно же работает лучше когда мы это делаем между но мы нодами но в этом случае мы опять-таки теряем в производительности потому что в этом случае когда нам нужно страница с другой ну моды это занимает большее количество времени и здесь вот мы можем попробовать поиграть этими двадцатью процентами чтобы разбивать большие страницы именно в те моменты когда нам это нужно и объединять в большие страниц когда нам не нужно много памяти и последняя такая интересная особенность она является возможно фичи нас выглядит она как бак дело в том что система которая объединяет маленькие страницы в большие делает это по каким-то стандартным правилам и вот най в этих стандартных правилах в стандартной прокатной системе есть маленькая ошибочка хип q ему тоже объединяется в эти большие страницы но она делает это ошибочно и по умолчанию если вы посмотрите через какое-то время работаю систему вас может оказаться так что процесс q ему занимает в памяти 200 мегабайт вместо 20 потому что его странице типа объединили в большие бы не провели по неправильным правилам может быть это конечно немного но когда мы запускаем 200 инстансов на одном узле начинаются большие проблемы встретиться а просто изменением настроек как и прежде ну и самое наверное может быть интересно для всех это то что можно сделать гостевой windows ну прежде всего вот то что забывают люди которые живут в linux мире прежде всего прежде всего нужно включить эмуляцию гипер и иск сказать что теперь для гостя квн выглядит совсем не как в как гипер ли в этом случае гость начинает работать более не менее правильно и надежно у него начинает правильный ти гостевое время релаксирует какие-то тайм-аут и на дисковые операции и так далее с этим можно жить боль не менее уже нормально ну это на самом деле не нова это было сделано и до нас в мае стриме что сделали мы значит мы реализовали гипер вину interact контроллер потому что мы надеялись что более быстрая доставка прерывание нам поможет нет она на мне помогла к сожалению это пропало в некотором смысле впустую при этом при этом обнаружилось интересная особенность то что гипер и заключенным синтетическим interact контроллером не может работать и включенной виртуализацией опека которая появилась в седьмом xiaomi автоматическое подтверждение прерываний которая реализована в microsoft оском interact контроллере напрямую противоречит этой фиче невозможно реализовать эти две технологии работающими вместе поэтому для windows гостей а пик в работать к сожалению не будет в таком режиме что мы сделали мы реализовали гипер реки и сипаев то есть запрос времени теперь не требует в м экзит в результате все планирования все тесты планировщика windows работают примерно на 20 процентов быстрее значит это попало в mainstream ну вот наверное ещё не замерзли на значит это лежит в очереди к вам нам man тренера ладно наверное я всех замучил своими мелкими детальками значит теперь самые интересные красивые картинки чего у нас в результате получилось виртуоза 7 с windows виртуальными машинами оказывается на 20-25 процентов быстрее рост с точнее на 20-25 процентов полнее за счет всех вот этих вот интересных технологий но на самом деле не совсем так потому что все технологии которые про которую я говорил в parallels клауд сервере 6 они были но общее серверные вещи а именно страница виртуальных машин которые могут уехать в своп kernels mph merging numa affinity и так далее они дают свой вклад то есть в результате мы имеем примерный паритет по им улице он им технологиям но лучше по лучшую структуру работы в серверном режиме за счет этого мы имеем вот плюс 25 процентов случае linux в.м. разница гораздо больше потому что parallels клауд сервер наследие десктопного продукта десктопный продукт затачивал ся под windows linux поддержка была существенно хуже вот переход на квн для linux виртуальных машин дал нам практически полутора кратный прирост ну и скажем так значит это тоже linux машины другой тест то есть это не единичный тест 50 процентов прироста производительности это не дни синтез это фронтальный прирост по довольно большому количеству тестов ну и последнее это сравнение с тем домам которая есть и поставляется в архате седьмом в принципе говоря на windows машинах у нас получилось быть быстрее на 30 процентов наверно вот такой вот интересный для нас результат а сама что называется главное все-таки несмотря ни на что для linux нагрузок контейнеры по-прежнему лучше виртуальных машин но это и понятно когда у нас есть единый memory management на всю систему а не надо двухуровневой внутри инстанса снаружи все работает намного лучше вот это наверное и есть самый интересный результат пока не будет реализован кооперативный memory management для виртуальных машин контейнера всегда будут лучше спасибо какие-нибудь вопросы коллеги виртуозы сервер 7 значит с downtime am вмк перья переносится из шестерки в семерку после этого производит производится конвертация эмулируем у или конвертации эмулируем оборудование стартует и взлетает то есть для довольно большого количества стандартных в мак а мы сейчас можем выполнить эту операцию нет но подожди у нас все-таки верна виртуальная среда у нас был в хостесс 6 red hat был хвосте 5 red hat какая разница сейчас костей 7 редко значит в гостей сидит не 7 red hat в к здесь сидит виртуоза 7 у нас отличается довольно большое количество пакетов в качестве базы берется red hat но на эту базу накатывается какое-то количество изменений еще вопрос они тоже бы хотел рассказать это целая отдельная тема значит завтра по моему у нас митап на тему как же мы этот сторож разносили и чего мы с ним только не делали ну тогда если рассказывать эта тема для генерации диссертации собственно говоря сравнивать там система хранения так в лоб не совсем правильно когда мы выбирали решения для наших продуктов собственно говоря мы остановились именно на этом тому была масса причин до что это там из 1 флакон от одного производителя и в целом на наш взгляд очень красивые и эффективное решение есть там безусловно как свои плюсы так свои минусы но это лучше к команде разработчиков именно peace тораджа он же виртуоза сторож да если какие-то вопросы если по эксплуатации ну не знаю нам нравится если как то уточните свой вопрос и я постараюсь на него ответить тут присутствует человек который у нас его эксплуатируют собственно говоря вот этими самыми сова самыми руками вот я воздам сейчас александр мираж у него можно чинить узнать такой более конкретно в плане и фишечек и живот и еще что пришлось сделать до пришлось какой-то момент разнести отдельно ноды виртуализации и notepad хранилища хотя использования not таких универсальных дает определенный выигрыш в производительности ну то есть там система ходит на локальные диски со скоростью больше но мы тут пошли именно в сторону надежности сейчас ожидаем от разработчиков vertu 100 раджа очередного апдейта который позволит увеличить производительность за счет добавления в один кир да то есть там существует терры можно сделать отдельный киртана создай дисках быстрый отдельный there на других дисках кого сейчас мы ждем решение которое позволит добавление в 1 тира разных дисков за счет внутренних алгоритмов существенно повысить производительность кирилл сказал что они выпустили сессии ну да вот мы ожидаем когда мы сможем это уже у себя поставить прикрутите чтобы 1 сезон сказал что он заработал верно можно качать все заканчиваем и бежи вставить нет сторож у нас это сложная история это совместная разработка на самом деле нет это разные вещи это принципиально разные вещи прп шито объединение данных нескольких контейнеров в знай это дедупликации данных контейнеров а вы сторож это распределенное дисковое хранилище поэтому это совершенно разные вещи так понимаю и время уже кончил и пожалуйста а можно еще вопрос open в одессе будет есть берите качайте давно есть она есть уже пол глава полгода как более того на самом деле если говорить про open в z7 в этом смысле она более дружественно и по сравнению с api назад шесть потому что ты назад шесть от parallels серый 1 6 ушло очень далеко значит сейчас они разрабатывают совместный это ну они отличаются на какой-то набор пакетов то есть если вы захотите перейти с окинавы за всеми на высот 7 началом нужно просто будет доставить там пару пакет выключить лицензию это сейчас одно и тоже ну все коллеги тогда большое спасибо"
}