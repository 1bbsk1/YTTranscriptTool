{
  "video_id": "ZLOFOxsDJIY",
  "channel": "HighLoadChannel",
  "title": "Остаться в живых. Крупный проект на одной NoSQL / Айк Саргсян (Юла)",
  "views": 9908,
  "duration": 3354,
  "published": "2020-04-27T13:29:41-07:00",
  "text": "про но и скиллы как мы с этим живем что было многие при старте стартапы проекта они думают вот сейчас начну на но искал базы данных когда все уже будет хорошо перейду на майский ласкал и какое-то под такое более серьезные решения или наоборот кто-то начинается с решения в будущем планирует переходи заново и скилл но 1 чаще всего вот и в таких ситуациях с ростом когда приходит некое состояние проекта уже решается что нет пора переходить мы этот этап тоже проходили но сначала расскажу как мы к этому пришли вообще что такое юла юла это уже существует три года как уже сказали и быстро развивается на текущий момент все наши и системы это но и sqweel не считая там аналитика где hadoop и с ним связанные вещи и мы с этим живем хорошо у многих есть и такое ложное ощущение что на но искал решениях там жить и развиваться дальше невозможно но наши примерно статистика до 30-го миллиона активных объявлений у нас это только активная база не считая то что уже в архиве удалено и так далее у нас двадцать миллионов 27 миллионов активных пользователей приходят реальным миллиарды документов в базе и терабайты данных еще и картинки и так далее собственно я с первых дней в юлии вот можно сказать с этими руками создавал всю эту архитектуру которая там есть но искал ну 2019 году рассказать что такое но их наверно уже не стоит так что можно сказать что вообще кто может у кого но искал базы активно используются проекте как ни странно не так грубер ну но эскелла это считается разные типы баз данных это колодочные киева ли у документная базы и графы в базы все они общим названием считаются но и скиллом то есть в данном случае идем дальше как но и склеил используется июля у нас здесь много много разных вас тут я привел пример только тех трех который про которые мы в основном будем говорить и каждая база используется например в mango тебе у нас это наша основная база данных все пользователей товары объекте все что связано с продуктом все хранится как первичный источник данных это наш мамба тебе ради сунул все мы используем какое-то слой кеширование мы используем райс в проекции хранится временно кеш рэнди хранится долгосрочный кеш об этом чуть дальше и ластик ластик сердцу мы используем с первых же дней эластики хранится ну все поисковые и таргетированные запросы которые нужны проекту например вот главная лента это просто лист товаров на все хранится в ластики ищется там индексируется там мы еще используем тарантул используем тарантул для очередей используем и postgres у нас есть и клик house даже есть но от печи что у нас почему-то не получилось кассандрой мы туда залили слишком много данных и не смогли его хорошо сконфигурировать поэтому пока что отказались какие требования были на наш пакет да почему мы наносим выбрали так остались самые такие важные требования которые ставился это конечно же высокая доступность думаю всем новым проектом и старым проектам высокая доступность так как мы поработаем с пользователем и это один из самых важных факторов и четыре девятки ставилась изначально быстрое и простое масштабированием нам нужно было что проект масштабироваться быстро потому что на старте когда это маленький старта это как ходить по туману войны не зная что будет следующим шагом что-то откроется и мы решили что нам нужно применить такие технологии чтобы было возможно масштабироваться в любую сторону какой нам будет необходимо ну изначально мы поставили перед собой такой лимит что как минимум и должны выдержать трехкратный всплеск роста базой просто базой за рост аудитории с чем это связанно это первое связано с тем что у нас изначально распределили систему так чтобы можно было выжить даже если что-то из дата-центров какой-то из дата-центров падет плюс были даже вот этот это правилно спасло той ситуации когда у нас от начала месяца до конца месяца роз вырос на 25 и 27 процентов такой рослый sql базе очень долго мы мучились были что-то там менять и тут немножко маркетинговые слова time to market но с очень важно чтобы продукт который мы делаем максимально быстро дошло до рынка то есть так сказать придумать много механизмы mvp и так далее и для нас это было важно потому что мы заходили высококонкурентный рынок нам нужно было делать максимально быстро максимально лучше вот но опять-таки как ни странно 2019 году некоторые мифы связанные с но и зрелом остались какие мифы мы можем об этом говорить до сих пор считаю что но я не готов для серьезных приложений то есть это эта банковская сфера все есть сложные бизнес-операции транзакции так далее я могу сказать отчасти это правда но уже но и скилл баз данных дошли до такого уровня развития что уже нету проблем с доступностью сертифицированием с масштабированием все это уже пройденный этап для нас колбас еще один миф это не aside complaint ну вероятнее всего все кто работали с базами данных знают что такое есть компании буду акцентировать но можно сказать что многие но искал базы уже давно ну даже так вы там aerospike что считается только кеш он тоже aside complaint и многие базу делают even шел консистенции многие базы делают атомарные обновление объектов и как-то покрывают в те части которые там необходимость следующем не требует проектирование все думает вот но и спел там нет структуры нету схемы мы можем ничего не проектировать просто поставили базовые все работает это к сожалению это не так и проектировать нужно даже если у вас но искал базой даже есть ли у вас а не малую часть общей структуры берут на себя но если лучше и хуже искал вход в постоянные холивары то что лучше но и спелой скилл если мы посмотрим текущей рынок из пивной спел баз данных видно такая некая синергия происходит искал базы стремятся к но и спела как вы уже наверное во многих докладах слушали там внедряются сонный там индексации и так далее и наоборот многие но искал базы вливаются в москве пытаются то какие-то примитивные синтаксис есть крелл и поддержать плюс соответствующие тот aside complaint есть четкая разделение но искал и искал про который я уже сказал уже эти границы очень такие шапки и не знаем да через пять лет через десять лет возможно будет одна единственная база который будет делать это это например тут же облачные многие сервисы предоставляют база данных которые делает все есть еще правило что легко масштабировать легко тяжело одной из скал базой по мере того что там ну из коробки так сказать нет у членов нету свежим таблиц их легче масштабировать поэтому если у вас таким тем более сейчас самое популярное то микро сервиса и архитектура вот таких случаях но искал базу я думаю лучше всего подходят многие но искать считают очень молодой технологии вот мы со склеенными базы мы жили очень давно 30 40 лет но если посмотреть немножко истории открыть википедию прочитать собственно даже с появлением первых моей фреймов уже были некие зачатки но из колбас и они даже были раньше чем те стены и вазы вот поэтому это тоже миф почему-то все до сих пор с этим мифом живут я сейчас немножко про акцентирую на мог бы тебе так как мы мог бы тебе использовали как основную базу данных вот манга тебе и многие из вас пользуются почти все те которые поднимали руки когда я спросил про на искал да реально манга тебе стал в таком синонимы мной успел документы ориентированных баз данных многие когда слушает документная базу манга тебе в начале мы тоже посмотрели сравнили ну что и знаю скилов брать на тот момент мог бы тебе был намного зрелым чем другие технологии мы решили его и взять вот как развивалась юля использованием он бы тебе но мы начинали с октября 2015 года это вообще такой соус soft start и что у нас была хоть и все стандарт стартапы поставили одну ноту mongo db ну там реплика sightmark тебе это один мастер и минимум 2 реплик слова не буду говорить неприятно некоторым просто это слово собственно 2016 году база постепенно выросла мы поставили еще два shadow нас было три шарда баз данных по сути это ричард вас данных такой целый год мы ничего дополнительных ресурсов не тратили он держит всю нашу нагрузку постепенно с ростом проект мы 2017 году был такой переломный момент мы поняли что может быть все таки с ной скалам как-то жить дальше будет плохо хуже проекта развивается но решили переходить знай skrill это такое было серьезное решение сравнили что брать там пускались нет майского нет что-то еще сравнили поставили внедрили маленькую функциональность поняли что не можем хорошо масштабировать откинули sql и продолжали расти с но и скиллу и с тех пор уже и даже не думаем переходить ну и дальше уже 2018 девятнадцатый год у нас а начала активно развиваться база и мы перешли тому же у нас было одиннадцать шар дав это один из мастеров со своими репликами и мы уже перешли на новую подход так сказать разделяй и властвуй и мы разделили уже под конкретную функционально отдельного базу данных но это потребовало и микро сервиса это потребовал и сервис-ориентированной архитектура вот разделили какие плюсы и минусы вообще команда тебе я не буду рассказывать я скажу чем нам помог какие плюсы были умом к тебе у нас нет схемы но это все документы ориентированные базы первым плюсом все говорят несколькими да реально это очень удобно когда мы не знаем как у по какому пути пройдем куда пройден какие схемы будем делать при добавлении какого-то отдельного поля не нужно долго думать о и топорик в какой таблицу добавить и так далее но тут маленькая оговорка донецкими но лучше его держать хотя бы в коде то есть если у вас есть некие найти объекты и структуры которые показывают какая примерная структура у вас базе гибкая масштабируемость как и уже в истории развитием он я сказал реально масштабирование почти что линейно есть исключение проекту можем отдельно то есть добавили еще 1 шард нужно еще еще больше там еще терабайт данных хранить еще один шаг может добавить распределить и все будет хорошо огромные массивы данных да у нас было очень много данных мы храним очень много исторических данных что-то появилось удалилась и так далее и все эти данные хранились изначально в манге и до сих пор большинство хранится и воду любая но искал база данных намного лучше справляется с большими объемами данных но это еще и полностью сортирования потому что данное хранятся позиционирована всем разным серверам легкость администрирования тот можно сказать что вот от предыдущих пунктов принципе это истекли ожидать из предыдущих пунктов потому что также вот разработчику нужно увеличить там новую функциональность добавить нам не хватает базы давайте новые сервера поставим мы администрированием этого очень легко мастер своим умом и теперь почти все из коробки автоматически делается ну нет миграции очень большой плюс на она для нас было что в базе данных не было миграций потому что ну мы все знаем да и скверная база еще когда проект чуть увеличивается там нужно в таблице одно поле добавить это целое там разные книги пишут люди как миграции устроить как перенести сначала есть методика на словах потом в мастере переключиться и так далее очень много разных методик вот бомба 9 такого конечно же нету документная база добавили поле все счастливы разработчики счастливы отменить тем более счастливы ничего не надо делать но с этим положительными аспектами еще есть у нас недостатки ну так же как их некоторые 1 скил базы в манге типе не было транзакции вот уже в четвертой версии они добавили но это пока не то собственно нам маленькой но условно 2 3 процента функциональности понадобились транзакции но могу сказать что если реально посмотрите эти транзакции можно было можно решить и у нас есть так это пафосные комета и сага то есть транзакций распределенных системах это все работает и как вчера коллеги говорили 2019 говорить про ту факторный комменты леса к это будет неправильно но мы используем это лучший вариант нет членов может быть наши специфика данных но у нас нет большой необходимости членов необходимость дюймов возникает в тех случаях когда у вас большой монолиты все данные там одним запросом искал нужно идти в базу взять огромное количество товары вместе с юзерам вместе там еще и какими-то данными юзера так как у нас изначально была сервис-ориентированной архитектура не скажу что игра сервисы в начале такой делать наверное стоит сервис-ориентированной архитектуры к у каждого сервиса были свои данные в базе мы даже не использовали внутри mongo db есть нативный добрев когда он может 1 запись ссылаться на друга и мы даже добавив и не используем просто храним айтишники ссылок условно есть продукты есть юзеры продукты из авнер продукта ссылается на идиш не кьютер а если нужно это юзер достать из базой то полетишь некую базу и достаем это еще и потребовал вследствие сортирования которые нам очень помогло во время роста многие говорят что вот но искал баз данных специфический языки не стандарт каждая база успел сделать свой язык тот же сон кто-то текст обычные стринги текстовый протоколы каждый делает по-своему а вот в мире и скверы все хорошо есть базовые скилл но каждая поза 5 делать свои надстройки но все-таки если ты в одном месте написал select там звездочка from the blitz продукт то это будет работать почти все sql база но и скиллами к сожалению не так но немножко защиту манги тебе скажу что язык запросов ну что сталкиваться и тот же сон он очень простой то есть разработчику нужно ладно пусть тень весь этот языках 1 учиться но и конечно есть очень много оберток ты мыл которые покрывают 90 процентов нужды писать самому писать запросы тоже до относительно молодая вот тут в недостатке есть некоторые вопросы которые в мозгу тебе решались очень долго мы столкнулись с проблемами это было когда во время сортированы нужно балансить данные между разными глазами и там были проблемы об этом чуть дальше расскажу вот и комьюнити есть коми то есть что-то правится что-то нет хотя могу тебе довольно активно развивается но нужное нам функциональность появилась наверное через год с оговорками ну и меньше коммунити дам относительно новизна и меньше команде команде реально играет важную роль но мы не сталкивались с такими серьезными задачами смогли тебе который потребовал бы в лице команде почителе что-то еще сделать немножко про схему как мы распределили база тут я привел пример 3 маленько трех ярдов вот у нас изначально и чтобы было как сказал высоко доступный сервис изначально все сервисе у нас находятся в 3 дата центрах либо реплицируется либо мастер в одном дата центре стола и в другом и для мозга тебе мы применили ту же самую то же самый подход у нас из 3 шар дав мастер каждого находится в отдельном дата-центре реплики у у каждого мастера есть реплика соответственно вдруг других датацентрах что это нам дало например это реальная история у нас был отключении питания в одном из дата-центров на восстановление системы то есть когда полноценно все работает у нас ушло четыре секунды 4 секунды это еще мы сказали о как-то очень долго нужно с этим что-то делать то есть пользователи максимум четыре секунды видели не доступность сервиса это частично потому что из трех ярдов по сути не работало всего лишь 11 шар то есть одна треть всей базы нагрузка я взял пример какой-то день нагрузки то есть это типичная нагрузка не в пекине в падении взял днем если вы посмотрите 170000 рпс на запросы в мунго это у нас база из 11 шортов и примерно 25 процентов это делает апдейта insert и 75-80 процентов это запросы это большая цифра если вглядеться 200000 orbeez то есть база из 11 но там он к тебе держит 200000 hps это с учетом того что у нас есть запас трехкратного роста как мы подразумевали что вдруг если какой-то дата-центр упадет то вырастет нагрузка еще 2 duo там центра упадут у нас останется один дата-центр и примерно трехкратный рост будет держать такого слава богу не случилось только с одним дата-центром справились но запас мы всегда держим любой наш сервис это должен быть на максимум 30-процентной нагрузки все остальное на запас вот дальше чем мы реально столкнулись при работе смог бы типе то есть при росте база сложность выбора ключей сортирования как мы знаем там из двух проблем программирования там выбрать имена переменных и и валидации кеша к нам добавилось еще один это как выбрать ключ картирование чтобы данным распределились максимально ровно равномерно но при этом доступ к этим данным был оптимальным то есть мы не распределили так чтобы любой запрос ходил на все шарды так как много тебе по сути роутер видят либо поедишь нику либо пожар включу все остальные запросы которые не используйте один из этих двух параметров они идут бродкаст им на все ноты то есть если вы неправильно выбрали шарнирный ключ на большинство ваших вопросов падет на все ноты и это будет но ботаник всего лишь одна нота может быть причиной падения всего кластера проблема балансировки нодов когда есть открытые курсор вот я намекнул что с чем мы столкнулись ну у нас была база из какой-то момент была базой 7 шар дав каждый shaft это мастер и две реплики точнее три с hit in репликам вот и мы решили в у пора уже увеличивать базу данных давайте добавим еще 404 мастера то есть i7 перейдем в 11 что произошло мы добавили сервера наши админы все настроили все хорошо мы смотрим всего 2 процентов данных балла surf перенес на труд новые ноты непонимание что происходит открываем логе смотрим да балансер все время говорит извините я не могу перенести чанки что произошло оказывается в mongo db если у вас там читается данные по курсора и курсор на какой-то чанг данных открыт то балансер ждет пока этот курсор закроется чтобы потом перенести данные с балансить а так как у нас это protection база там постоянно идут какие-то запросы с курсором тем более ночью там кроны начинают работать что-то архивирует что-то поднимать наоборот и из-за этого balancing не происходил во многих если посмотреть в интернете многие рекомендуют писать свой балансер но мы решили что зря тратить ресурсы на да давайте по ним поймем что за проблема первое посмотрели код мы поняли что изначально ещё в самом начале наш драйвер мы в драйверы поставили параметр бессмертные курсор и любой курсор который открывал приложение по сути был бессмертным мы надеялись тогда наверно что вот скрипт в конце закроет курсор но оказалось что некоторые скрипты не закрывают и курсоры оставались памяти соответственно жили всегда первым делом сделали временное ограничение неактивный курсора 12 часов немножко стало лучше но это тоже ничего сделали принудительное убийство курсоров при неактивности не больше шести часов это нам помогло к сожалению сейчас информация по конкретному курсором он к тебе пока не сделали чтобы хорошо давать и точно мы не знаем в нашей версии манга тебе точно мы не знаем к под каким курсором какой запрос идет нужно вручную взять и зло гадюшник курсора запросить понять и может быть закрыть вот эта проблема до сих пор остается но убийство не активы курсоров нам помогло у нас очень быстро все шарлиз пара спонсировали так что будьте внимательны есть такой у вас тоже случится сортировка по полю ну но искал базы какие-то запросы делаются и есть сортировки условно уберем все товары отсортировано пo дате публикации что происходит у нас есть яндекс хищнику товара все хорошо по отдельности берется но когда нужно что-то сортировать то получается такая ситуация мы взяли огромный объем товаров от сортировали и взяли там первые 20 или 30 но мог бы тебе нужно столько действий делать потому что в яндексе дата нету он изначально все в памяти считает и рекомендую если вы используете такие сортировки то используйте композитные ключи ну поход для вашего запроса и в конце конце индекса композитные индексы и в конце индекс поставьте то поле по которым будет сортировать кстати в могу тебе нету неважно сортировка просто либо скин тенге ли диск то есть яндекс поддерживает этой то можно я с кеннеди тенге на обратный индекс автоматически есть собственно таким способом мы очень сильно увеличили время очень снизили время ответа от базой потому что по сути и тореро вался только яндекс и не хотел заданными а данные в могут себе там это бы сон но они не очень оптимально хранятся вот с чем еще и не то да с чем еще мы столкнулись перепутал не сортирование коллекции на ноде по умолчанию ну понятно у нас есть большой кластер очень много сортированных calix но бывают ситуации когда коллекция маленько там из 1000 2000 элементов и чтобы его распределить и сделать запрос и там по всему кластеру собрать нецелесообразно и вот эти коллекции жили на одной дефолтной нодди могу тебе это конфигурационном играется нота на котором создается несортированные кластера коллекции что произошло у нас шли запросы на очень много запрос как маленькая коллекция выросла и очень много запросов пошли к нему например такая коллекции у нас было праге а точки маги тебе и так получилось что есть там москва большой трафик у нас из москвы приходит и из-за этого все запросы падали на эту ацильную ноду ну и эффект сортированных кластеры если одна нота тормозит и все за собой тянет приложение по сути начинает замедляться вот поэтому есть такой лайфхак если конфигурационном можно дефолт но надо менять то есть если вы катастрофически вам нельзя сортировать какую-то коллекцию ты вы можете постепенно менять дефолтную надой новой коллекции которые пешего разве не будут создаваться по очереди на всех мастерах это лайфхак это неэффективно но работает вот есть еще одна проблема это проблема большого массива внутри документа ну когда у нам дают разработчику руки документ ную базу решая то как хорошо я сейчас поставлю тут товар внутри юзера внутри данный юзер еще идти васи юзера внутри юзера что хорошо документ структура час он все индексируется все работает но в чем мы столкнулись у нас были и пользователем объекты пользу там имя данный номер телефона и так далее и внутри объекта пользователи решили что каждый пользователь может но иметь сколько девайсов можете местом 11 android еще десяток планшетов дома пусть будет но будет там 1020 девайсов и решили массивом девать их хранить внутри объекта юзера юзер его девайсы что произошло изначально мы были только мобильные то есть api работал только с мобильными девайсами потом мы решили что пора делать феб как только сделали wep wep тоже некие divo si каждый браузер и наши любимы пользователи начали заходить с кухни то мода инкогнито мод каждый раз по сути и базу добавляться новый браузер был новый девайс так количество девайсов нашего юзеров резко выросло чистка там не происходило да и собственно пришел момент когда мы там размеры этих массивов был настолько большое что при вышел дефолтный лимит одного документа манги это 16 мегабайт можно менять но при дефолту 16 мегабайт 1 документ мы это превысили и поняли что так делать нельзя и сейчас уже все что потенциально может расти в виде массива мы не храним внутри объекта отделом отдельную коллекцию просто ссылаемся на него это тоже помогает сильно еще один пункт это кеша vixens что происходит в мало тебе очень хорошо работает с индексами есть ли они находятся в памяти ну наверное все баз данных в памяти и намного лучше индекса и происходит то что детстве нам нужно запрос который требует какого-то нового индекса там он к тебе идет диск загружает это в памяти начиная с ним работать так случилось что название товаров мы для административной панели поставили текстовый яндекс нормально все работает очень быстро и нам ничего специфического не надо будет нужно по названию быстро искать текстовый яндекс и за административной панели то есть продуктов и такой необходимости не было потому что все находилось в эластики что произошло все работает все работает в какой-то момент какой-то модератор приходит в админку хочет по тексту искать мало тебе о текстуре яндекс его нету в памяти давай все под ними поднимает все в память и убивает из памяти все нужные индексы для production and запросов и после уже когда приходит продакшен запрос поднятия опять индекса из диска это тяжелая операция происходит долго ответа тайм-ауте то есть конечному пользователю по сути мы выйдем time at потому что у нас предложение минимальные тайм-аут и на ответы собственно кеша vixens это в статистике мозга тебе можно посмотреть у нас она мониторится там графа не отдельным графиком даже если больше одного то это алермо бегите правьте чтобы такого не произошло начинаем исследовать проблему ну и про сортировку уже сказал по сути можно сказать что спокойно вот за все это три года с манга теперь не было такого что потерять данные или там пользователь что-то сделал мы потеряли не хотя и у нас и вешал консистенции то есть даже если в один мастер записался мы не ждем мы отвечаем пользователь что все хорошо даже с падением дата-центра все было хорошо так что я наверное всем рекомендую если нужные детали после могу рассказать как используя смог бы тебе рекомендую его использовать у вас проектах не пожалейте вот пройдись немножко быстро перейдем кризису потому что я смотрю по времени мало редис ну как и все мы для хеширования выбрали редис как потому что нам нужно было немножко там долгосрочные графики she то есть при сохранении эти из кризиса нам понадобилось как изначально редис у нас развивался ну опять в начале проекта а что-то сотен сервы хадиса все отлично все работает пришло время начали развиваться ну поставили 8 not afraid со и начали клиентское сортирование то есть ключ сортирование прочитывал ся на клиенте и ходил 8 из 8 серых почему 8 так cry эмпирически просто взяли 8 серверов поставили вот на таком импровизированном кластере у нас жила долго и все работало хорошо на тот момент ещё ради склад был хорошо развит sentinel не знаю кто и наверно сталкивался сантино но родис кластер на тот момент ещё был не очень развит поэтому мы поставили просто сантино ли 8 физических нодов потом уже мы поняли что рейс кластер дошел до нормального релизного стабильной версии и уже 2017 поставили родис кластер сначала это был у нас один глаз торопиться с этим тоже жили долго один кластер или сам много нодов там 30 нодов многие но ты так как кризиса однопоточный можно многие но тайно одном физическом сервере разместить ну и там мы каждый из его там десяток ноты в покор у процессора можно развивать вот но пришли к тому что 2018 девятнадцатый год и уже пришли к тому что один глаз ты родился нам не хватает что делать опять разделяй и властвуй взяли райтис кластера и вместо одного поставили 8 родис кластеров но тут мы уже внимательно отнеслись к этому делом и разделили так чтобы можно было по-разному конфигурировать например у нас есть m-class тов ну прям так темпы называется там кластер в котором хранятся только временные объекты то есть эти те объекты которые потеря этих объектов не проблема пойдем либо в базу либо куда-то еще их возьмем и опять-таки шерру то есть там не купим никаких проблем все там побег ты там вал файл не кладется ничего носить исковым операции не делается если сервер даже упадет не проблема взяли другой кластер назвали его то то там начали хранить все те ключи ключи которые сложно прогреваемые то есть теоретически их можно прогреть какие-то счетчики какие-то вещи которые долго сидят в кеше но их трудно прогреется или большая нагрузка будет на базу если мы их потеряем и на этом кластере мы поставили нормально там вал файлом кешировать space ножи кешируется бы капица и вот разделили то есть есть быстрый кеш и чуть медленнее работающий но зато долга и надежный мы пошли еще дальше и таких кластеров по мере необходимости сделаю словно есть кластер все хранятся хранится кеш продуктов из кластеры тех райских юзеров и так далее на платили таких кластеров хорошо то что редис масштабируется тоже почти линейна в кластере плюс можно на одном и том же физическом сервере поставить несколько кластеров к главное чтобы их не ноты и просто по количеству core of процессора не превышали вот-вот первичная схема как у нас было до это сортирование на стороне клиента просто 8 модов и отсортировали знак клиенте но потом как я сказал мы перешли более глубокий схеме то есть каждом из трех дата-центров хранили определенное количество нодов например десяток в первом дата-центре десяток второй десяток в третьем 30 нодов одного кластера и сделать таких кластеров опять это 3 дата центра при потении любого из них у нас приложений живет и так и случилось ray диск сожалению когда мы упали восстановился где-то через 20 с чем-то секунд дата кластер это происходило из-за того что мы сделать слишком много нодов и метаданные очень медленно обновлял то есть они выбирали мастера двух других дата-центрах между собой такое случилось мы это потом оптимизировали ему первый раз так но я могу сказать что 20 секунд конечно пользователь тоже не заметил потому что те данные которые нужно из кеша брались из базы брались базовый держал там 200 тысяч orbeez коротко быстро перейду к использованию elastico кто-нибудь elastix r1 продакшне использует а кто использует сфинкс что-то не так почему вы выбрали эластик search да при старте проекта вспомним что это 2015 год сфинксе к сожалению не было геев индекса а юла это гиа распределенная база nokia появился потом мы этому очень рады вот не было геев индекс мы сравнили ох как так то свин все нашем любимом свин все нету гиа индексы ладно давайте что-нибудь другое придумаем взяли elastic search взяли эластик сердце до сих пор живем с ним ластик search очень легко да нам давал возможно сделать гею текстовый поиск совокупности то что происходит нам нужно найти товары которые максимально близкий к пользователю например от сортирования по удаленности это было наш первый один из первых фич которые мы выделялись были и другие вот и где область должно было работать хорошо конечно мы могли бы самому писать какой-нибудь сергею индекс том же мангу тебе или попытаться с ним все это реализовать но решили у нас нету времени руки-то всего 2 и лучше мы возьмем готовые технологии взял и elastic сергей был момент когда перед нами не почему вот elastic нам очень еще помог был момент когда продукции пришли сказали нам нужен кольцевой поиск что означает кольцевой поиск в каждом километре чтобы товары от сортировались по дате публикации той с каждым кольце в пределах одного километра всего отсортировали в дать по дате публикации той самой свежей поближе с одного километра до 2 и так далее почесал голову на тот момент в ластики работали отдельные скрипты вот что сделали это первое что пришло в голову честно скажу поставили работает кольцевой поиск у нас есть то есть скрипта ванеева ластики нам очень помогло с этим скрипта ванием мы жили долго сейчас немножко подходы там поменять это groovy скрипт на языке грове был тогда реализован сейчас elastic новые версии не поддерживаются собственно на этом жили очень долго но потом понятно это стало слишком тяжело когда у нас уже миллионы товаров и уже внутри кода реализовали кольцевой поиск ну пользователю нужно все товары которые в рамках там 50 километров но самые первые там первую пачку товаров это 60 товаров условно что делает elastic идет по всем нотам берет все товары которые есть базе сортирует их дистанции и дает нам первые 60 как-то слишком много операций на одно одно действие ластика вот и мы решили что сделаем кольцевой поиски будем его в коде то есть что делаем у нас по дефолту радиус 50 километров у хорошо но в большинстве случаев мы знаем что в радиусе одного километра это 61 точно найдем дилеры в коде просто увеличение товара леса и тонировали если вдруг пришел какой-то очень стального место у кого-то близкие не нашей 60 товаров в километры вот сейчас elastic стал у нас большим поиски таргетированная лента у нас примерно 40000 рпс то есть это когда лента категории открывается в приложении мы разделили ластик на 3 опять и разделить на 3 кластеров первый кластер это основная продуктовая база второй кластер человека в котором оптимизирован под карты игил поиск то есть там есть у нас недвижимости карта те в квартиры можно посмотреть на карте и это отдельный кластер со своими настройками и что делать в административной панели давно уже хотели чтобы вы искать там товаров юзеров по всяким параметрам опять таки поставил ее ластик и там больше двух миллиардов документов уже хранится ищется ещё при этом так что мы очень довольны elastic ай и с ним еще думаю надолго собственно что сказать да я так очень быстро галопом прошелся по трем основным технологиям которые у нас используется что можно сказать точно не бойтесь использовать свой скилл но и спела это реально круто это реально помогает и тем более когда у вас команде очень ограниченное количество людей нету времени делать сложные большие там придумывать схемы механизма но и скейл помогает нам во всех этапах можно и искренно я база используется как но и скрыл все это потертом в одну строку помимо документов по сгрыз секрет хаос и но не одним бонус крисом богаты значит не бойтесь знайте предметную область да я только пришел сказал но и сказать-то круто всем рекомендую использовать ребят посмотрите на свою предметную область может быть там будут моменты когда вам нужно не нужно использовать новый скилл не делайте так но и скилл не всегда хорошо вот те несколько 3 4 процента случаев . и он не очень хорошо например графа вы и базы данных очень сложно масштабируется вот вы просто умрете их масштабировать начинайте проект с кластерных решений это не замедляет разработку очень многие при старте проекта тумане кластерное решение тоже администрировать там очень сложно там не нужно еще три ноты создать там а что делать в одном сервере создать и три ноты но начинаете проект кластерных решений вначале кажется что это излишне там молотком бант экскаватором поглотил но все-таки потом поймете что это во время роста вам очень помогает и распределить их все-таки хотя бы на два отдельных вылепили те точки то есть на 2 дата центра или два серго физически если в офисе два сервера один в одной комнате ставьте другой в другой комнате поможет вам потом ну и не надейтесь поменять базу в середине проекта очень многие там воздано quad вот у нас по да мы сейчас напишем на моей съели потом когда все будет хорошо поменяем на пол игр с или наоборот это когда пройти реально вырос это почти нереально насколько бы вы универсальный код не написали базу потом менять не сможете так что можете конечно все можете но это будет очень сложно очень долго и дорого для проекта и для продукта в целом так что спасибо что слушали вопросы у нас буквально пять-семь минут на вопросы постарайтесь быть сжатыми добрый день и спасибо большое за доклад вы упомянули о том что у вас административная панель тоже ищет какие-то определенные документы в манге и у вас для этого есть отдельный текстовый индекс а зачем почему не отравитель административную панель бы тот же elastic вот как раз я об этом и сказал что сначала у нас был текстовый индекс манги по названию товара мы искали мы поняли что это не так потом во время блок elastic я сказала что мы перешли на elastic примерно там 22 миллиарда документов и товара сейчас находится на ластики ищется в административную панель минусинске прошу прощения здравствуйте меня зовут хотел спросить у марины и white e-mail и доклад про него сидела где тарантул тарантул у нас используется я не успел и доклад узкий слишком был у нас и тарантул используется и клик house используется массив майский нет но есть плоскость поэтому тарантул мы используем на таран туле очередь и очень быстро работает никаких проблем поставили и забыли уже года три зачем ради стыдно чтоб редис тогда зачем про игры gizmo кластерное решение у редиса кластер не в обиду тарантула но пока что в одессе кластер реализован лучше чем в tarantul а я могу с этим поспорить да конечно спасибо за доклад я здесь вверху он послед но не видно ну значило спрятался соответственно меня два вопроса первый вопрос наверное предложение которое заключается в том что вы говорили часто что падение тома дата-центров было для вас неожиданностью поэтому такой вопрос и проводите ли вы учения по отключению дата-центров или например применяете ли вы halls инженеринг когда есть какие-то обезьянки которые там что-то отключают бегают это вот вопрос предложения собственно варя еще вопрос заключается в том что вы упомянули что делали хитрую финики для манги может быть чуть чуть поподробнее раскроете что там какие решения были и применялись извините хитрое что хитрая finiti функция которая распределяет данные по узлам так чтобы они были как можно ближе друг другу она не была хитрая в реальности сортированные ключи сортирование данные чтобы максимально было и условно продукты мы можем сортировать сподвижник у автора то есть все продукты 1 у мира попадут в 1 шард и при запросе будет возможность там только ходить в 1 шард и такие случаи то есть тут нету конкретного единого решения серебряной пули для всего для каждого конкретной коллекции мы решали отдельно но это хитростью не назову вопрос если вам там справа я был еще один вопрос ну точнее прошил в чеке мы базируемся на то по центрах майло эти дата-центры постоянно проверяются там могут отключить проверить сервера стойки и так далее это учение проводится у нас здесь очень много have чеков которые проверяют систему и продуктовое технические метрики у меня тестирование тоже проводится здравствуйте спасибо за доклад просто вот меня 2 комментария первая вас какой-то очень странный профиль потому что на таком профили но у вас уже его нету но там были картинки где греет для чего-то там и вот на таком профиль у вас удаление должны очень долгими быть очень долгим если вы удаляете не коллекциями это первое замечание и просто в манге удаление коллекциями работает и второй момент выговоритесь там нет джейн авто мне силу копы и это не совсем честный joy но это так они на работают просто плохо и вопрос 2 и когда вы говорите про кластер и вот про такую структуру вы пробовали когда-нибудь вообще большой-большой мигрировать версии до версию то что есть подозрения что при такой схеме мигрировать на каждую последующую версию это боль и если да то расскажите хотел в двух словах как первый вопрос про нет там был один вопрос именно про миграцию все остальные комментарии остальные комментарий хорошо про миграции у нас было migrate перенос базы как я уже отметил могу тебе у нас уже не один то есть да есть основной кластерной с много других кластеров то есть мы уже раздробили функциональность на отдельный сервис со своей базой манги и обновить отдельный сервис намного легче большой миграции но мы столкнулись с 32 на 3-4 кажется мог бы тебе обновляли сейчас если честно не припомню как мы это дело но это просроченная кладка мы тоже не заметили то есть можно там step down и мастеров сделать обновлять потом их поднять и так как совместимость был у ног логов было совместимость с двух версиях то там сложности не было снова последний вопрос да здравствует среди меня зовут в 2017 году почему вы собственно задумались о переходе то есть вот конкретного что больше всего аффект тела и почему вы не перешли до скажу честно аффект теле мнение некоторых экспертов нам говорили что могла теперь дни и эффективен таком в такой профилей нагрузки могут из пенная базы данных будут эффективнее чем могу тебе то есть можно такой же сортированный кластер делать изыскала и спит работает быстро но в реальности мага тебе мы сравнили мы не просто так голословно сказали что нет ни переходим мы поставили sql рассортировали moi ce qu'il поставили и на нем перенесли маленькую функционально сейчас не могу сказать этой функциональности уже нету мы поставили то маленькую функциональность и протестировали на реальных пользователях реально пользователи шли и ходили в мой скил кластер но администрирование этого кластера нагрузка профили и даже ответы майского были медленнее чем на такой же структуре данных давал нам о.г. может быть мы что-то не так сделал ну можно экспериментировать разные варианты не знаю поставить еще плоскость проверить но у нас к сожалению не было большого времени там проверите это 2 3 у нас слишком ограниченные ресурсы и быстрый рост проекта поэтому решили нет пока пусть хватит спасибо поблагодарим докладчиком лучший вопрос нужно выбрать лучший вопрос лучший вопрос наверное тут который коммент комментарии вопрос но я хотел даже на комментарии ответить"
}