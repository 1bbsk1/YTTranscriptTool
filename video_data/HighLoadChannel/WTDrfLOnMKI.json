{
  "video_id": "WTDrfLOnMKI",
  "channel": "HighLoadChannel",
  "title": "Istio Service Mesh в федеративных топологиях Kubernetes / Максим Чудновский (Сбертех)",
  "views": 3429,
  "duration": 1637,
  "published": "2023-01-19T07:01:38-08:00",
  "text": "как уже сказали мне зовут максим фамилии janoski есть гортена а вертеть и я занимаюсь разработкой сервис маша немного кубера и разных штук вокруг сервис вышла собственно поэтому сегодня об этом я хочу с вами поговорить тоже спросили у кого есть кубе в продакшне а у кого есть больше одного кубера в продаже не супер но собственно давайте с этого и начнем посмотрим а что такое когда у тебя больше чем один кубик production ig нужно подружить для иллюстрации я взял простой пример у меня есть 2 applications apple 1001 oblique что два вот apple тишина один получает ingress трафик ну и соответственно вызывают уже apple тише 2 и соответственно что нужно сделать чтобы затолкать и как убирай чтобы это работало но по большому счету две вещи нам нужно собрать докер-образ из исходников чтобы он появился в регистре и подготовить артефакты deployment а ну кто-то будет использовать нативный ресурс кубера кто то есть будет использовать шаблонизатор it on home чар цели up in certain place кто что любит кто-то будет использовать провайдера форма под кубер иск оставаясь не суть важно у нас есть артефакты дипломанта у нас есть образ все это отправляется в один кластер и все хорошо все прекрасно работает никаких нет проблем когда кластеров несколько встает вопрос а как обеспечить консистенции с deployment а как бы нам сделать так чтобы кластера один от кластера 2 не отбегал в плане того что там за тепло и на и это на самом деле первая проблема которая называется проблемах играть федеративных дипломатов нам нужно понимать что и как де поиск uber решение разное это может быть detox самый простой вариант у нас есть чай в одном кластере в другом и там и там марга седин например ну собственно раздевались су хорошо кластера один сломался ничего в кластер 2 не переехала чтобы переехала можно использовать какой-то контроллер тепло и внешней кластеры все равно нужен какой-то сервис который будет за это отвечать это первая проблема мы классного дипломата вторая проблема это трафик трафика у нас есть два вида один сходящий которые не суются за границами кластера который идет как говорят с севера на юг и 2 который идет запада на восток поговорим про первый соответственно в кластера нужен трафик завести кластера дин проблем нет взяли ngos контроллер взяли балансировщик поставили или заказали все хорошо когда кластера 2 нужно трафик между кострами распределить а потом появятся требования чтобы этим трафиком как-нибудь поуправлять чтобы вывести один класс там на тех работы а потом выяснится что выводить 1 класса слишком дорого давайте выведем один сервис а у нас ungars контроллеров многое соответственно как-то нужно этим управлять и желательно чтобы те люди которые будут использовать наши кластера ничего про это не знали чтобы у них был простой яму файл они говорят вот у меня есть битвой мульти кластерный я работаю хорошо дальше платформу сделать земель это вторая проблема трафик который идет севера на юг третья проблема это трафик который идет запада на восток ну соответственно у нас может быть инициирован вызов как снаружи так и изнутри класс террористам инициированный внутри кластера у нас нарочно блики один вызывает applications 2 то пока кластера в это все живет внутри кластера все работает как только плите чем 2 в кластере один сломал страсть во второй кластер не ушел хотя рабочая реплика там есть и соответственно нужно как-то плети чем 2 сделать мульти кластерными это собственно известная проблема есть даже в кубе рыться в комменте пропал на эту тему может быть кто то слышал называется кабинета суть классов сервисы сайта и ну и соответственно эту задачку нам нужно точить решить ну и последний вопрос абдирова белить мы все пользуемся егеря мы знаем про панд racing мы используем prometheus кто-то использовать викторию чем у нас есть метрики логе мы собираем молодцы вот и на самом деле здесь как бы на первый взгляд проблемы то никакой нет мы поставим внешнее хранилище для всех этих данных которые будет внешним по отношению ко всем кластерам и все будет прекрасно работать и все он так и есть но есть одно но нам бы потом пойти метрикам еще понимать и что произошло кто кого вызывал какие-то данные есть и так далее пока мы живем в одном пластыри все хорошо когда у нас мульти кластерный сервис то непонятный помогут мы были в одном кластере потом улетели в другой кластер как это трассировать непонятно собственно мы должны эту телеметрию отдавать в нормальном варианте то есть с хранением проблем нет а вот как собрать сформировать проблемы есть не собственно в целом вот такая картинка она и характеризует вот такую вот общую систему а при которой мульти кластерные дипломаты будут работать хорошо и в целом это будет без боли для пользователей нашего вашего класса про каждый житель проблем можно говорить очень долго прочнее который интересно про некоторые не очень мы с вами сегодня поговорим про одну про multiple остальные сервиса то есть трафик у нас инициируется внутри кластера мы хотим вывести его в другой кластер слушать томас работал при лове чтобы работала балансировка управлять этим всем делом и так далее как это можно сделать и как это вообще делать если есть несколько вариантов первый вариант который строится на базе но он ещё называется gate & bass и суть очень простая у нас есть сервис на штраф сервис мышей есть такое понятие как инверсии где твои оправа не только мыши есть но несут ну и соответственно мы можем управлять трафиком внутри мыша соответственно между мышами выглядит так что трафиком поуправлять тоже можно мне как-то этот мультик la star можем сделать а собственно между кластерами туннеле у нас будет просто с в общем-то выглядит так что там мы сможем управлять трафиком потому что сервис мышь ну как это выглядит пока непонятно мы чуть позже посмотрим второй вариант это берлина сеть нигде сидевшим в кубе и так если берлина я сеть и здесь подход заключается в том что трафик попадает ваш контейнер попадает начинает покидать и wear линию сеть куба попадать в карстовую сети проваливаются в новую вершину сеть которая bennett костра по такому принципу работают на примеру под собственно проект в маринер может быть кто то слышал подход в целом неплохое у него есть недостатки там есть вопросы когда булла и айпи адресов носить кодов и сервисов пересекаются в мари мире там делают одну глобальную сеть плюс мульти кластерными сервисами там большие вопросы потому что сложно организовать discovery но подход есть его ну как бы он имеет право на жизнь и третий вариант это самое простое это трафик снова народу вышли за берлин ой сети и прям с моды ушли в другой кластер это делается на базе на уровне вашего сеянная плагина то есть на уровне имплементации overlay-сети примером такого является на собственное решение селимом в этом зале при нем говорили и бпф великая технологии только нужно правильно использовать тоже подход хороший основной недостаток если вы сделали федерацию на базе синай вы с этим хина им останетесь надолго если на себе вот и это может стать в будущем для вас проблемой собственно так как я размер так как я занимаюсь разработкой сервис мышата я буду говорить про подход номер 1 и 2 мы оставим за кадром но там чуть-чуть в конце про них будет почему сервис мышь почему мы сегодня говорим провести а но сервис мышь понятно мы все используем это уже очень популярный поттер никого не напугаешь не удивишь а если один из самых популярных одной самых популярных реализации есть другие но тем не менее как бы провести почти все знают почти все слышали я не буду долго рассказывать идея очень проста у нас есть сайты размещаются рядом с вашим контейнером перехватывают весь сетевой трафик и за счет этого могут им управлять вот для того чтобы можно было управлять есть центральный компонент который называются контру play вот он работает как discovery соответственно он идет ваш идя сервер кубе узнаёт информацию о всех ваших водах и кластерных сервисах и дружно это отправляются в виде таблицы маршрутизации соответственно дальше после того как эта информация туда загрузилась вы можете через эпическому файлы управлять балансировка и распределением трафика ну там еще есть часть про безопасность для нас сейчас важно сервис discovery запомним из тела присматривает за потом и отправляет их на сайт кары и так работает маркетизация внутри сервис nusha а есть он поддерживает мы с пластины режим из коробки и на самом деле можете не стоило делать доклад потому что есть такая картинка а как бы выглядит сложным на первый взгляд но она очень простая просто есть несколько месяцев каждый живет в своем кластере и каждый излишнего присматривают за кластерам соседа но это весьма экспансию медиасервер говорим из тела ты живешь в кластере номер 1 среди за одним из от отец ким 2 делает тоже самое и соответственно таблицу маршрутизации в удвоенном объеме начинают рассылаться по всем вашим сектором это можно починить но до определенного предела здесь пример когда сети между пластинами независимы и security domain тоже разный поэтому на границах стоят 12 и это инверс игр с битвой стандартные страшные в общем схема простая так говорят разработчики изд-во схема это работает но как показывает практика у нее есть несколько дней есть несколько вопросов во первых открытой 5 сервер потому что estel чтобы работал discovery ему нужно следить за всеми кластерами которые входят вот этот вот в этот вот гигантский мышь может быть это и не большая проблема но представьте у вас есть такая инсталляция в облаке вы заказали себе кастера и у вас есть он примесь инсталляция там у вас тоже есть пастора полностью закрытая сесть это ваш резерв на случай каких-то вопросов с вашим клауд провайдером или чтобы не было клауд локон такой случае в таком случае велика вероятность что и перри сервер вы не откроете для истек история с multipla старом вот такой вот гетерогенной архитектуре облачные для вас закроется второй момент это высокая нагрузка point по индийского ли но я уже сказал раньше мы гоняли адреса всех входов в одном кластере если кластер достаточно большой то есть подав там начиная там тысячи и если ищете тысячи еще и в одном нам спейси из тела уже начнёт задавать вам вопросы почему так много хоть когда кластеров больше вопросов становится больше это может стать большой проблемой а про внутри кластерное финансирование собственно здесь идея в том что вы не можете объединять сервис в мульте кластерный сервис которые живут в разных namespace of например в одном пластырь или образных они обменяются очень просто namespace и совпали имя сервиса совпало ну значит это один и тот же сервис мы можем сказать что будем балансировать между кластерами других вариантов нет ну и механизмов контроля публикации подписки тоже нет здесь вопрос и создают как правило специалист по безопасности потому что старое видео друг друга можно ходить как угодно никакого контроля никакого учета нет и это может стать большой проблемой но собственно целый слайд проблем вопросов получается что идея из уже и так больших мышей делать один гигантский мышь не очень хорошее потому что есть вот такой слайд а что тогда делать но ответ очень простой еще делать если этих плохо давайте просто не будем их объединяет вот и все и соответственно есть другой подход который позволяет нам добиться желаемого и он называется генерирование мы не будем строить один гигант снимаешь мы построим федерацию полностью независим от мышей как это сделать очень просто а мышь позволяет нам управлять трафиком соответственно мы можем просто зарегистрировать внутри из тела некий внешний сервис сервис диктовались тела и пробросить маршруты на выход на шлюз безопасности выходной на игры дальше завести это все на энгр с другом кластере оттуда зарулить на наше приложение все просто все это стандартная функциональность сервис меж но есть пара моментов о которых я бы с вами поговорил собственно внешней сервис как его сделать я говорил что есть у присматривает за пудрами discovery работает что творится за вашим кластерам и стива не знает соответствие ему нужно об этом рассказать есть механизм который называется сервис-центре мы скажем привет из тела вот есть внешний сервис пожалуйста два филдес товаре и будем управлять трафиком на этот сервис собственно сервис-центре это делаем нам нужно указать свой две вещи его dns имя и in point и куда этот трафик собственно слать с именем возникает вопрос потому что в машинах устроена когда приложение хочет кого-то вы поэтому сначала самостоятельно делает длинный запрос получает айпи адрес потом делаете сетевой вызов этот сетевой вызов ловит мяч и дальше мужичок с ним делаем марте зиру им там переадресуем и так далее то есть первый длина запрос всегда делает приложение это сделано специально чтобы подключением мыша было бесшовный новый уровень предложения и что не надо было менять и поэтому просто так длинна 7 мм и вписать сюда не можем оно должно резолвится оно должно резолвится в пластыре ну как проще всего сделать так чтобы в кластере появилась dns имя но про сделать кубовый сервис да он добавит спорт для секса вопрос решён а так можно сделать есть одна проблема он будет во внутрь пласта van damme нет у нас то есть у нас появится сервисе вида там федерейшн мой сервис . - с точки цикла стрелок вот так себе идея потому что это сервис внешним мульти кластерный а выглядит так как внутри кластерный сбивая с толку есть второй вариант зарегистрировать полностью федеративное доменное имя можно это сделать но здесь нам нужно продумать rhoda inez как она будет резолвится самом деле все просто можно поставить 2 dns который будет либо перед кластерном либо после лучше поставить после чтобы не было единой точки отказа тут то там прописать роутинг для нас трафика исключительно на свой федеративный под домен моем случае с вот цикла скорлупу и все это прекрасно будет резолвится если не хочется заморачиваться с dns он просто на диплом эти добавьте нужные адреса и они сами пропишет вырезав он фонд напади но придется каждый раз модифицировать deployment так себе историю собственно с именем сервиса разобрались есть варианты второй момент это адрес куда нужно направлять трафик ну собственно картинка у нас была простая там бы выиграть битву этот мы его туда и добавляем прямо вписываем адрес кубового сервисы которые на него смотрит и добавляем и все это работает и нюанс 1 если у нас есть локально рядом с игре сам коды которые должны участвовать меж пластиной балансировки то есть мы должны оставаться внутри иным space если есть какие-то проблемы улетать в другой в каком-либо другом кластере как то сделать если есть у вас свежий и нет никаких ограничений и замечательный механизм workload n3 который позволит вам это сделать вы просто в service and и пропишите селектор и сервис центре будет смотреть на ваши поду и точно также как обычный памирские сервисы нет никакой магии все будет прекрасно работать если по каким-то причинам вы так сделать не можете например вас старая версия есть где этот механизм либо отсутствует либо работает плохо соответственно вы можете использовать областями свип должна этот кофе но сервиса а ну очень быстро по два сервиса это обычный сервис типом кластера эти у которого по старой пи нет у мол вот соответственно в таком случае резолвится этот адрес будет а в качестве ответа на dns запросов будут адреса всех входов добавили это выстрел сказали что механизм discovery dns и все коды добавились discovery стива механизм работающий у него есть дроу бейки останавливаться не буду если будет интересно на лапу на вопросов расскажу собственно все мы добавили внешней сервис теперь будет балансировка у нас и внутри по старой снаружи кластера простыми и сложными конфигами ничего сложного дальше у нас идут маршрут здесь просто регистрируем удаленный пастор опять через сервис сам пин это тоже внешнем сервисе внешние сервисы но здесь мы просто пишем там длина 7 1 verse gateway его айпи адрес не важно в этом сервис-центре нет ничего интересного дальше мы собственно конфигурирование игры с битвы чтобы он выпустил трафик вот собственно виртуальным сервисом говорим игр с gateway маршрут пожалуйста вот пришел те трафик на 80 порт отправляя его на эндерс в таком-то кластере это тот самый сервис ничего сложного в принимающем кластере обычный эндерс маршрут он простой совсем то есть у нас есть энгр с битвой мы просто завершаем входящий трафик и отправляем его на нужный нам сервис больше ничего делать не нужно мы и так это дело место у нас есть кистью соответственно все наша федерация готова давайте посмотрим какие у нас были проблемы и что с этими проблемами произошло но первые открытые 5 серверы и перри сервер больше нет потому что нам больше это не нужно почему нам больше это не нужно потому что он с большей этом поезд discovery вот мы больше не следим за подали в удаленных кластеров этого нам это не нужно да есть момент нам нужно следить за шлюзами заявив удаленно остров ну их кратно меньше чем кодов зависит от вашей системы deployment а если бы столько же сколько нам список либо вообще один на кластер как захотите соответственно нам больше не нужно следить за имплантами и высокой нагрузке здесь тоже не объединились поинтов рамках namespace да пожалуйста как угодным их объединяем мы сами строим маршрут сами управляем трафиком в любые ным space в любых постерах если ваш а ваши версии есть то поддерживает финансирование то есть в одном кластере вас может быть больше чем один одна инсталляция из то пожалуйста в разных инсталляциях делаете обвиняете все будет работать ну и собственно внутри поста на это монтирование тоже и последний пункт публикация подписка контроль понятно что у нас теперь полный контроль потому что мы делаем эти маршруты и по дефолту по умолчанию 100 робки никто не видит никого а сетевой трафик полностью закрыт между постерами и это очень любит безопасность вы почти всегда если никто никого не может вызвать это просто прекрасно соответственно каждый раз уже строится каждый мачту под учетом мы всегда понимаем что происходит с нашим трафиком в кластеров и кто кого может вызывать мультиклапаном режиме ну получается так что вроде бы как способ предложили он не имеет недостатков которой есть вести из моих слов все прекрасно работает и на этом наверно можно доклад и и заканчивать но в анонсе был еще один момент мы говорили про паттерны обеспечения отказоустойчивости и надежности мульти кластерной среде что имею в виду сейчас мы сделали только маршруты у нас только начал ходить трафик но у нас нет мульти кластерных retrieve у нас нет мыть и кого кластерного сухих брейкера то есть автоматически между лигой пластырь не выйдем если что-то сломается и нам это нужно сделать как это можно сделать и можно ли вообще на самом деле можно вот наша схема мы ее помним она очень простая собственно мы добавляли регистрировались disnej не сервис конфигурации местью если мы хотим сделать распределение трафика между кластерами сделать canary снились мы делаем просто трафик сплит стандартным ресурсам если используем механизм который у них называется локали тела balancing и все работает можем выключать сервис-лист он сервиса в нужном пластыри на тех работы либо обновлять его потом завести туда там 10 процентов трафика посмотреть что все работает самом деле есть и другие возможности к наличным релизом в этой схеме если будет интересно я потом расскажу ретро и то же самое то же место единственно выстрел ретро и считаются не правилам балансировки а частью маршрута поэтому мы используем не destinations а ваша сервис собственно там литра и настроиться четыре строчки и у вас будут ретро его мульти кластерной среде причем вы можете сделать так рассказать как или троится если локально не достучались уходите в удаленный кластер или попытаться достучаться все-таки локальное потом уйти если сработал britain ну и прошли комбики я уже говорил собственно тот же самый шнуру потому что эта функциональность является частью балансировки в выйдя из него соответственно здесь мы это настраиваем а и все прекрасно работает то есть все паттерн отказоустойчивость в распределенной среде для федеративного трафика мы настраиваем точно так же как мы делаем это выстрел мы ничего не ухудшились дело в федерацию все осталось как есть только на multicast ином уровне ну вот теперь кажется что все надо не все собственно локализация трафика еще один момент мы можем оставлять 10 процентов трафика вам спейси 90 процентов раскидать по удаленным пастором мы можем использовать для этого стандартную топологию костров кубер на то что есть если у вас но дух уберу это все размечены аннотациями из нам space а то получше поверни таз и о это реализован провайдеры скорее всего да если он привез зависит от вашего инфраструктурного провайдера если размечены все будет работать по этим зонам то есть трафик может уходить из одной зоны в другую вы можете как угодно им управлять если этого нет вы чуть-чуть меня эти конфигурацию про которую я говорил и добавляете свою собственную лака лице потому принципу какой вам только придет в голову например вы не хотите чтобы трафик переключался пола колите хотите чтобы он переключался панель space on то есть из нимс происходили в нам space 2 но вот такое организационное деление у вас принято пожалуйста чуть-чуть меня эти конфеты и вводите свою собственную лака лети главное чтобы по уровню она вписалась выставочную там есть sq бери два уровня коллективы силу три уровня вокалистом еще сад зоны есть собственно все задачи мы решили проблем больше нет мы нашли золотой топор сахар известное архитектурное типа торце идеальное решение все прекрасно работает на самом деле нет потому что все равно новое решение новые проблемы первая проблема это сложности стихи и и что я имею ввиду когда мы работаем с эти пешки теперь два у нас все прекрасно у нас есть эстетики запросу него есть заголовки мы знаем хост мы знаем порт мы знаем юра ему что угодно можно сделать с этой информацией если приложение работает по какому-то пропитанному протоколу то в сервис мыши мы видим это как просто тисе пи трафик например кто-то вставку хочет подключиться и вот здесь пространство для манёвров у нас а уже ну совсем немного потому что ну если есть лес хорошо мы знаем имя хоста вас иной больше мы ничего не знаем и соответственно как только мы пришли на выходной шлюз понять очень сложно куда этот трафик то дальше отправлять в покой plaster какой сервис что с ним вообще делать и на самом деле чтобы решить эту проблему вы наверно уже догадались что нужно делать ничего бы не нужно делать потому что как правило если вы используете какой-то сервис пробита рн импорта к вам например ту же кафку в этот протокол уже инкапсулированные механизмы обеспечения ну какой то кластеризация отказоустойчивости балансировки поэтому просто не мешайте им работать вот скорее всего они будут делать то что вам нужно другой вопрос что если вы разрабатываете сервиса своим пропитанным протоколом не хотите внутрь своего протокола добавлять поддержку хоста лизации и хотите отдать это ребятам которые делают сервис наш можно так сделать ну конечно можно собственно для того чтобы это сделать но как я говорил вариантов все равно немного первое это разруливать все по хостам вы снова dls трафике второй вариант просто резервировать порты на игру битва и понимать что за трафик идет по портам третий вариант самый сложный научитесь игр с где твои понимать ваш паразитарный протокол это вариант самый дорогой самый сложный но тоже работаете пример это и есть и вторая проблема это сложности с конфигурирования собственно когда мы регистрировали внешней сервис мы сделали 4 я могу файла ну я имею ввиду не ямал файла а именно кубинских ресурса и запер бы iso-файл то может быть физический 104 ресурса мы сделали вот что вы сделаете игры с маршрут мы сделали еще четыре яму файла и на входе добавили еще 2 до считает что получилось слишком много я могу файлов ну а то считает что много но пойдет хорошо собственно что можно сделать с этой проблемой но с этой проблемой бороться чуть сложнее первый первый вариант это не использовать а 50 совсем может использовать только первые фильтры и использовать сервис наш только как инструмент дистрибуции конфигурации на сайт карина прокси без использования истерикой варя скажу сразу так себе у него есть набор draw back off ну вот и лучше бы так не делать потому что мы завязываются напрямую на и 1 выступили могут быть изменения эта информация может не проскочить до сайт каров в общем там хочет проблем есть второй вариант можно все это дело автоматизировать чтобы эти маршрут устроились автоматически потому что это полностью алгоритмически решаемая задача и пользователь навык на входе увидит простой яму файл хочу придется скажет хочу федеративный сервис вот и все это произойдет автоматически так тоже можно сделать но о том то как это сделать это уже тема наверное совсем другого доклада вот у меня все спасибо вам большое за внимание спасибо ваши вопросы или же 1 добрый день коллега спасибо за доклад возможно немного оффтопа вопрос вы упомянули что вы собираете все метрики prometheus а много у вас была некоторая проблема определения принадлежности этих метрик и маршрутов где кто как куда ходила в эту проблему как решили вы добавляете какой-то идентификатор сквозной как вы определяете кто параде умеет рекой кто посадил помощниц погромче проблему метрики которые вы отбрасываете то что вы собираете все метрики вы говорили вот так вот ближе к началу на как вы в итоге определяете где метрики кабели а какие метрики какие но на самом деле это рядом с доклад на потому что то как отбросит метрики куда их собрать это прям отдельная история но на самом деле метрики формирует сервис меж но да то есть как бы с уровня ну точно сайт как мы понимаем кто кого вызывает вот соответственно если реализация мультиплаз ты растешь на это есть важные site or и понимают что это мульти кластер и умеет отбрасывать но выстрел на самом деле всего 4 метрики поместил request to the у историка вы со мной из 4 просто мое было разные поэтому строится все графы взаимодействий просто ливийского просто лэйблы добавляют до но для multiple остальной среды в случае если у нас федерация и стилей бы не добавляет вот и это решается через васан фильтры которые загружаются на сайт кары но это как бы там отдельная тема это отдельно разработку то есть у по нему лишь пластами сервис сделать можно спасибо"
}