{
  "video_id": "8pUupAGDR0w",
  "channel": "HighLoadChannel",
  "title": "Построение самодиагностики в живой высоконагруженной системе / Глеб Тильтиков (МТС Digital)",
  "views": 574,
  "duration": 2472,
  "published": "2023-01-19T06:56:45-08:00",
  "text": "как рассказал андрей да я занимаюсь коммуникаций но необычными коммуникациями а умник анальными коммуникациями а именно я руковожу инженерами которые у нас в телекоме создают наши и высоконагруженные сервисы и платформы всем и как инженеры когда разрабатываем какую-то новую эти системы мы должны и продумать гибкую архитектуру им предусмотреть возможность наплыва нагрузки должны выстроить средства наблюдений самое главное что в конце зачастую заказчик в конце просит нас что мы доказали ему что наша система действительно надежная что наша система на уровне систем конкурентов и она в каждый момент времени выполняет тот с елей на которой рассчитывалась поэтому давайте мы с вами сейчас пройдем весь путь который ну по сути проходит любая эти системы на примере нашей вы на пути к своей зрелости немножко погружу вас в предмет вот наверное сейчас редко кто пишет кому-то эсэмэски вот но тем не менее с мск до сих пор актуальны каждый год на рынке происходит какой-то вброс что эсэмэс технология устарела что с омскими не пользуется и каждый раз жизнь показывает что это не так кстати поднимите руки а кто любит отвечать голосовые сообщения на текстовые о вижу четыре руки ну это лишь подтверждает что нашему рынку все еще ничего не угрожает мы получаем sms от банков когда выполняем транзакцию тем более сейчас когда у банков есть проблемы с получением push-уведомлений и с работами с мобильных приложений мы получаем эсэмэски от мчс когда просмотра gun мы получаем эсэмэски в не выборов от курьера от почты и каждый раз смску нам отправляет какая-то большая система нашего партнера она называется наш 30 applications а мы как потребители называемся пиры или еще мы говорим person его такие коммуникации между большими системами и нами они породили целую нишу рынка нишу нишу а toupper коммуникаций и всем на этом рынке с мск нужно мгновенно что такое вообще омниканальности это еще все канальные такой опыт взаимодействия с брендом когда клиент может работать взаимодействует без шел в но он может как общаться в одном канале так и переключаться между каналами при этом у него остается комфортный контекст а у компания обслуживающего у соответственно тоже удобные средства для коммуникации наша платформа она главным образом отвечает за услуги и за бизнес с мск вообще говоря пока доходят наших телефонов проходит большой путь и наверное вот мы где будет в центре но путь ему сердце этого пути на картинки вот я как раз обозначил нашу самость платформу слева это большие наши крупные клиенты это applications например то банки сверху это интеграционная шина с корпоративными продуктами это уже мтс на и сервиса разные им тоже нужны коммуникаций вот ну они же ссылка на ссылка на большие большие интеграции с нашим внутренним сервисы например такими как биллинг или скажем вот есть у нас такой сервис который позволяет узнать дату выпуска сим-карты и если скажем симка свежая то вот этот момент ее выпуска является может являться одним из правил в у маршрутизации соответственно если клиент захочет проверку то ну соответственно сообщение не будет отправлена на свежую симку случае получения одноразовых паролей это нас с вами продать предостерегает от ну от мошенничества далее у нас находится коннекторы к различным нашим системам и нашим партнерским системам ментам сервис e-mail рассылок ну в общем это то куда интегрированным и ну и в конце это пир как я уже сказал это абонент я уверен что вот вы все уже являетесь этим нашим пиром хочу еще отметить что все каналы коммуникации двунаправленные они работают как сторону и крики шум toupper так и перту applications итак давайте посмотрим как стояла наша задача нам было необходимо выстроить систему которая будет выдерживать 20 тысяч запросов в секунду при этом скорость обработки каждого из них должна быть не более 100 миллисекунд мы должны быть доступными три девятки и 5 здесь 195 ну по умолчанию мы сейчас дело зарезервированы и необходимо выстроить смену которое будет мониторить эксплуатирует нашу платформу задачей мы справились таким образом нагрузку каждый клиентский запрос добавляет нам внутри массу это внутренних различных под запросов параллельных поэтому нагрузку на действительно высокая доступность мы обеспечили латентность ну как видите тоже она в порядке мы разобщены на 3 дата центрах ну и соответственно по техподдержка тоже она была выстроена давайте последуем совету тамады марка и чтобы проанализировать работоспособных давайте поговорим про метрики и инструменты вот первый шаг к решению любой проблемы осознать что у нас вообще проблема есть и давайте поймем что же мы хотим узнать измерять мы хотим знать объем трафика как по каждому внука как по потребителям так и и по обработке у поставщиков его поставщиками знать и мы хотим скорость знать скорость обработки трафика то есть light in se мы хотим узнать как быстро у нас растут очереди ли разгибаются или например нашем процессе есть какие-то проблемные обработчики мы хотим тоже об этом знать какие то подвижки задачи мы хотим понимать когда все это началось и кто в этом виноват и также мы хотим значит если мы делаем какие-то изменения меняем настройки то ну чтобы увели как систем на них реагирует еще мы хотим что вот это вот все как-то в сама работала и какую-то рутину брала на себя и предостерегала нас от в про максимально сама предостерегал нас от проблем мониторинг требует продуманной стратегии я вижу что нужно изначально просто смириться с тем что построить сразу правильно не получится будет эволюционировать ваш информацион система будет эволюционирует мониторинг соответственно от сразу на первый момент у нас нет ничего ей столько команды инженеров которые умеют писать микро сервисы они будут писать какие-то компоненты будут делать какие-то первые барды и вот с них мы начнем просто визуально наблюдая значения на графиках далее когда мы уже немножко по экспортирован платформу мы увидим что есть какие-то экстремумы значений мы поймем какие потребители и как на кого влияют сколько у них трафика соответственно мы сможем выстроить как какую систему alert of и понятных и их на каких таких же не достижение таких значений будем собирать статистику как по всему трафику так и по выйдем каких-то топовых наших самых потребителей хочется дальше чтобы наша система смогла автоматически принимать какие-то решения ну и в идеале подсказывала нам что какие-то уже есть они аномальные моменты там в трафике или в работе платформы который на скорее всего приведут к какой-то нестандартной ситуации первое что с чего очевидно стоит начать это собрать все доступные показатели потребления утилизации ресурсов собирать их надо смотреть на них надо но ориентироваться на них бесполезно они нам покажут что ну просто сет система работает сервер моргают лампочками там server service и наши живых живы ну как они работают они не покажут ориентироваться мы можем только на функциональным какие-то функциональные показатели он надеется что у нас все будет хорошо эта стратегия плохая а давайте поговорим какой должна быть стратегия хорошая и давайте начнем с взгляда на архитектуру вот примерно схематично так выглядит поток трафика в нашей платформе это в общем то схема схема нас тема работы платформы это один большой request response и когда к нам предъявляются высокие требования по скорости и надежности нам позволительно некоторые разумные избыточность мы размещены в 3 дата центрах в первые 2 мы работаем в режиме active и ход стендбай и третье это просто некий резервный отдельный instance также закладывали и возможность грейс ву и или деградации хочу еще обратите внимание на крайний компонент с центр с центр как таковой в телекоме это некий софт задача которого просто получить эсэмэску и сразу отправить ее всегда всю сеть на мобильную антенна то есть этот сервис сам не принимает решений так алагир уют все что через него проходит и выполняет действием как раз таки нашу платформу выполняет различные бизнес-операции проводит биллинг и является таким центром доставляющим и с услуги итак если мы начнем хочу показать как непосредственно проходит трафик все наши компоненты находятся в одном и боли экземпляров соответственно поправь падает на один из портов либо по протоколу smtp которую краски общепринят телекоме либо по одному из других популярных известно протоколов пузырь далее проходим сервис быстрых проверок например просто чтобы понять что номер отправляй абонент он же в корректном формате далее в работу включается маршрутизатор это как раз таки елемент которые принимают решения но чтобы принять решение ему нужны дополнительные данные и он эти данные запрашивают сервисов обогащение вот например services обогащение нам подскажет что какому оператору принадлежит этот номер также подскажет нам включена ли соответствующая услуга у этого потребителя либо подскажет вот свежесть симки и многое что еще но далее трафик перенаправляется на коннектор или на исходящий порт и уходит в соответствующего партнера обратно мы получаем либо хлебов это входящий трафик либо это отчеты о том что сообщение об оставленном очертили доставлено соответственно тоже проходит через компонент обрабатывающие входящие услуги далее попадает на маршрутизатор и тем же образом возвращается был получателем хотел вам показать один из подход который мы использовали для упрощения мы максимально старались сделать критичные сервис и надежными и простыми как молоток вот и мы решили отказаться от базы данных чтобы от нее не зависите смотря на то что он автору в кластере вот но мы сделали таким образом когда через интерфейс управления администратор менеджер там кто-то меняют настройку например канал марш какой-то канал маршрутизатор меняет через api gateway в работу вступает соответствующий бэкон сервис в этот сервис тут же сохраняет новый набор данных базу и генерирует соответствующий ямал файл или группу файлов дальше в работу вступает так называемый сервис доставки конфигурации это elsen г с определенным набором скриптов и он уже по определенным правилам все эти яму файлы раздает скрыл потребителю конечному то есть то есть micro сервису ну а сервисы к ноге мгновенно вычитывают и применяют можно бесконечно долго смотреть на три вещи на огонь на воду и на графике давайте начнем строить наши первые графики существует обычно выделяют четыре уровня критичности это мишна critical бизнес critical business operations и офис продукте витте вот я выделил нас весь наш real-time контур как мишин критика он помечен красным и желтым помечен бизнес critical и фиолетовым бизнес продукте витте вообще класс критичности зависит от тяжести последствий и скорости их наступления единственный критерий который используется выявление то cla-class это убытки которая понесет компания следствие остановки системы нам важно например понимать что объем трафика на входе как-то соответствуют трафику на вы хоть каким-то правилам важно понимать что данные синхронизированы между компоненты не между у инстанции между центрами важно понимать какая насладитесь и обработки важно понимать что у нас не накапливаются в очереди что у нас и накапливаются ошибки вот это очень интересно но ничего не понятно и это именно то что мы получим если будем смотреть сразу на все барды причем часть бардов будет условно доступны сразу просто из коробки и принтер подключен соответствующим над экспортеры получаем барды по инфраструктуре таки где-то половина ну с этим работать нельзя нам нужно что-то такое с этим работать будет можно однако в суран давайте займемся еще дальше уместной оптимизации и будем уходить от массы бардов к единой сигнальной лампочки вот и больше нравится сравнение с системой check engine наших машинах если нас загорается лампочка чек то что мы положено что делает остановиться подключить сканер читать так называемой логе и понять можем нему ехать дальше или мы уже приехали вот здесь я нарисовал борт нашей платформы который у нас появился вас на получился в следствии у где там нескольких итераций мы в основном используем гистограмму по квантиль им вот здесь можно заметить несколько квантили и 0 5 в том числе и вообще как однажды сказал сити амазона вернер фон гильз что серединные значения показывают вам на то что половину ваших клиентов вы обслуживаете еще хуже на середины значения ориентироваться нельзя можно сравнивать там их для стать для себя получать можно ретируется нельзя ориентироваться можно на 0 9 quanti там должны быть хорошие значения на 0 95 квантиль там должны быть удовлетворительные значения или на 0 99 квантиль там просто они должны быть чем больше у нас нагрузка тем больше у нас the land of и далеко не все alert и страшные например любую получать масса лет в структуре что там скоро закончится место на диске мы знаем что пройдет ротация логов место освободится и нас будет куча времени для того чтобы еще как-то отреагировать поэтому нам важно поделить alert и на указом по критичность и отфильтровать кроме того очень полезно бы иметь разные каналы для получения allure то пусть это будут разные мессенджеры и там как таким-то образом они называются какие-нибудь страшные словами чтобы точных узнали по понятным причинам нашей платформе мы для лифтов не пользуемся с масками также иногда например когда платформа рабы находится в режиме обслуживания сути нормально если случаются случается alert и просто их нужно добавлять в стоп-лист и и все тогда ну ну а пристаем них реагировать когда ехал на работу утром у меня загорелась лампочка про ветки двигатель я проверил двигатель был на своем месте давайте теперь мы начнем сами генерировать трафик будем строить некий супер alert мониторинг может быть активный может пассивным пассивный будет анализировать данные которые приходят от клиентов активный будет строить создавать данные сам этого нужно написать генератор и соответственно с одной стороны с другой да будет заглушка либо зубная заглушка к это эмулятор и самое главное здесь критерий это максимально чтобы она была похожа на наши живые данные ну то есть чтобы она могла например в рандомной промежутки времени генерирует запрос чтобы запрос был какой-то зашумленным но все тут как фантазии разгуляется ну чем ближе к реальным данным тем лучше первое что мы начинаем делать это просто давайте посмотрим нашу платформу глазами клиента для этого мы совершенно независимым дата-центре ставим генератор трафика на один из на один из наших протоколов и какую-то систему а лифтинга у него которое нам будет просто подсвечивать что он случился alert поначалу это вообще может быть наши случает просто было с места который уходил на реальным на мертвом раз в минуту ну и когда мы поняли что в целом это не очень правильно москва предлагает они часто номер его так бомбить вот они начали разрабатывать эмуляторы которые начали заворачивали трафик появились стимуляторы вот синенький вы там видите квадратики и также появился еще один компонент который проверял правильность отправляемых намекал беков вот идеально даже борт я уже упоминал он в нашем автомобиле он простой ненавязчивый и информативный и почему называет процессом лампочкой только фронт это вершина айсберга процесс состоит из инициатора трафика состоит из правил которым он генерируется состоит из наблюдателя состоит из за канала и состоит из того что у скрипта и обладательниц какой то скрипт как в случае проблем и ну какие диски правой случае проблемы и так и от взгляда со стороны клиента давайте начнем само диагностироваться обучать наши компоненты самодиагностики ну то есть внутри себя первое что мы должны сделать это задача самодиагностики это выявление а нам они соответственно нам нужно поправить и солей по каждому компоненту чтобы понять что нормально а что аномально самодиагностика работает непрерывно жизненный цикл у нее вот такой постоянно проверка also что alert если что она при она же сама принимает решения и дальше под формула возвращается в обычное свое состояние в нашем случае самый наш супер alert выглядит как рост неожидаемого поведения и это тот тот кто событий по которым мы принимаем решения мы принимаем решение кардинально и об этом я раскрылся вашим слайде и так как я уже сказал наши из компоненты находятся в нескольких экземплярах и мы над каждым нашим принимающим входящим портом поставьте такой маленький микро клиента под этот маленький двигателей каждый из них генерирует трафик на каждые sport of traffic проходчик с платформы по обычному пути заворачивается обратно на эмуляторе возвращается происходит это там периодически раз в количество времени и этот двигатель и он анализирует получена ли количество ответов ожидаемое у него если нет и течение 1 2 минуты это это 1 2 1 минута то просто alert после после первой минуты это принятие решение мы можем также представить над каждым двигателем такого самурая с катаной который готов любой момент действовать и если сервис если вы проведет мне ожидаемое поведение это сервис ответит за это головой прямом смысле мы просто врубим контейнер перед этими сервисами нас находится балансировщик на самом деле ничего не произойдет балансировщик просто увидит что существуют другие порты перри балансирует трафик на них это произойдет совершенно совершенно бесшовно почти там может быть будет перебиться и все в общем клиента практически не заметит как вчера я слышал много спикера то что упала и быстро поднятого упавшим не считается это не тот случай она не упадет вот и действуя просто нет сервиса нет проблем но действуя таким образом мы можем убивать все наши входящие порта естественно этого мы не хотим ну сначала мы убьем порта на первом дата-центре потом убьем все порты на втором дата-центре что же произойдет а продукт вот что у нас один из портов работает в режиме байпас вы поставите паттерну который позволяет некий а показывают называется обход то есть это такой обработчик который и в себе имеет только самые главные проверки ротко маленькая монолитная версия платформы и задачей трафик принять главной операции провести и направить в партнерскую канал данном случае он выполнится наша мишин критиков функция также важно что при этом этот байпасный порт он создаст определенный логов после как по которым мы потом будем восстанавливать статистику как понятно что щит все-таки happens и было бы странно это скрывать что произойдет когда у нас работает самый диагностика ну понятно что мы найдем место которая была виной допустим у нас был тепло и скажем какой-то из компонент какой-нибудь там сервис быстрых проверок был с ошибкой понятно что мы его поднимаем возвращая версию кода в предыдущее состояние дальше мы поднимаемся единственным с этого компонента и убеждаемся что между ними синхронизированы данные после этого мы включаем обратно поднимаем порт балансировщик обнаруживает спорт с большим приоритетом со мною перенаправляет трафик ultrafit возвращается вот и после этого мы задействуем наши инструменты для который возьмет лог-файл сгенерированный и обратно запустят их на платформу с флагом не отправлять таким образом к нам добавится вся статистика и биллинг до клиенты эту статистику увидят чуть чуть позже вот когда у нас что-то случается существует такие роли устранения инцидента и вообще это очень хорошо описывает google и сырья бук фактически можно сказать также даже называю первая роль это пожарный вот пожарные это тот самый инженер который в данный момент и исправляет ситуацию и задача всех нас ему максимально не мешать вторая важная роль это координатор пожаров это уже роль менеджерская и координатор делает все что пожарный он обеспечит коммуникацию делал все что пожарные не мешали друг другу идёт блок инцидента вот третья роль эта роль лидера коммуникации это тот самый пускай будет сотрудник человек который оберегает нашу команду супергероев от внешнего мира а внешний мир от нее например на хозяйством в трейси какой-нибудь босс позвонит чтобы он не позвонил инженеры не сказал вас все лежит да я вас всех уволю лидер коммуникации выступит а скажи да вы нас всех уволить и но это будет завтра потому что если у нас будете сегодня она так и останется лежать эта тема очень хорошо раскрыл виктор попов полна раскрыл на прошлом хайло де поэтому если интересно дальше вот править про эти роли то пожалуйста я привел вам ссылку более того виктор сел там вам расскажут существует 4 роль эта роль сопровождающей задача которого какой-то момент либо пиццу ребятам привести либо вести лог изменений следить за изменением каких-то критических показателей показатели работы платформы которые чтобы не например великую настройку и потом не забыли и о круто за меня строки и потом верну назад тестировать напротив можно даже просто необходимо но речь идет не про привычные нам тесты которые выпишем вся если конвейере а slv тест и почему собственно говоря портирует проди можно так как мы наши сани самодиагностику наделяем властью принимать решения и самодиагностика работает на разных наших портах она нам этих решений она принимает и запросто может случиться такое что отключив там где-то один порт у нас поломается что-то другое вот чтобы с этим как-то следить и не позволять вести себя как угодно мы решили что мы расширим наши привычные тесты себя и сиди на seo и сиди и city тесты kontinius чек это специальные такие тесты для непрерывной сам диагностики для того чтобы их запускать разработали свой тестовый фреймворк тестовый из детей это собственно это отдельный напитка под система сама библиотека языке тут самая подсистема состоит из контейнера и которые выполняют тесты и эти которые могут использовать тестировщики вдохновлены мы были диалоги это видео которая предоставляется иди на библиотеку с наделенным сразу же он никому не канальный функциями из коробки вот так же наши из дикий позволяет сделать прямой запрос базу данных например сделать герпесе запрос отправить psn теперь эсэмэску ну и очень глобально глубоко коснуться платформы разрабатываться эти тесты у нас инженеры мёртвости of a тестирование пишем мы как и все у нас нога и такой подход нам позволил еще одну ситуацию разруливать например какой то клиент хочет чтобы у него был какой-то кастомный маршрут скажем если у него его какой-то кастомный канал отвалился то пожалуйста переключите меня на мой другой кастомный канал вот это спокойно мы можем сделать просто написав такой тест и тут мы ничем не ограничен сами интерфейсы этих тестов не в соответственно разрабатываются инженерами и есть возможность как запускать тесты непрерывно в бэг-энде так ее собственный frontend где также можно любой из тестов по нажатии кнопки запустить и посмотреть что произойдет вот так выглядит в вернее я нарисовал место ты стал фреймворка наш схеме это уже компонент появился он тоже как и самодиагностика может обращаться в ходящим портом запускать трафик трафик будет на эмуляторе назад ну и соответственно то пойдет тестовый фреймворк и там будет принято уже решений вот архитектурно тестовый фреймворк пример выглядит вот так то есть схематичного так архитектурно здесь задействован два паттерна это реестр и некая цепочка обязанностей вот сереньким обозначен реестр тестов его настройки синеньким цветом посередине processing тестов и самодиагностика ответственного processing тестов подхватывает сам файл для вен где расписано алгоритм этот файл выполняет по правилам который мы лупанул передает сервис самодиагностики из настроек взятых из реестра соответственно процессе теста выполняют эти тесты и прощается платформе она ему там что-то делает возвращает результат и если результат неудовлетворительный то самодиагностика allure тип или принимает решение вот этот тест на наличие успешного соединения с вайпером он не показывает глубину проверок но он показывает просто объясняет принцип что там команде 10 строками кода можно проверить какую-то фичу а вот так это увидит инженер мониторинга зелененький соответственно все хорошо красненький тест не прошел черненький тест не выполнялся оранжевый означает что сам тест упал с ошибкой чтобы преуспеть в делах планировать мало надо уметь импровизировать давайте мы сейчас немножечко добавим сюда творчество вот в пассивном мониторинге у нас мы проверяем данные по клиентскому трафику соответственно давайте начнем собирать клиентский трафик выглянуть этот опытом 50 клиентов будем агрегировать их специальную культа статистику отдельную собирать именно таким образом собирать только те значения которые нам нужны будут для дальнейшего анализа дальше будем в нашем случае нам интересно анализировать данные за период например специфика такая что скажем трафик в понедельник похож на трафик следующий понедельник но не похож на трафик в четверг вернее конечно похож но не так сильно как на следующий понедельник нашем случае этот подход подходит мы собираем трафик за определенный день за определенный час и можем его сравнивать и можем можем описать это формулы который дальше покажу вот так же это позволяет нам еще и диагностировать самого клиента поскольку некоторые клиенты подключены не напрямую они тоже могут быть заинтересованы в том чтобы есть лишь пестрит проблемы с трафиком и их же об этом не думать потому что как правило бизнесы и не всегда они стали себя проверяют вот на картинке приведен наш обычный наш день по трафику и какой-то один из часов по часу можно заметить что он вообще по картинкам что в начале каждого часа происходит всплеск и дальше затухание использовав просто обычно аппроксимацию полином пятой или шестой степени можно описать одну и другую картинку формулой ну и соответственно просто по этой формуле и полнеть проверку или например второй подход когда мы можем выстроить и линию тренда использовав хотя бы даже простую линейную грейс регрессию мы можем анализировать так актов нам наш поставщик отвечает например там доставка в какой-то из мессенджеров трафика его тоже две картинки в разный период времени может заметить линии тренда немножко меняется соответственно если мы или опишу формулой то мы можем понять что там из через x часов наш трафик достигнет конечно значение повысили нужно принимать меры или же не ненужная ты же у нас все хорошо на картинке я нарисовал новый компонент сервис агрегации событий которым сейчас рассказал то есть это некая новое хранилище данных и также у нас появился новый компонент который позволяет некоторые добавлять и уже машин learning функции это отдельный отдельно такая подсистема рядом с тестовым фреймворком тем не менее она отдает нам доступным также использовать из пользоваться ею у них некоторых сервисов обогащения таким образом мы можем там параллельно что-то вычислять использовать это в том числе в обогащение данных а теперь я бы хотел бы вернуться к тому о чем я сказал самом начале все-таки как нам гарантировать заказчику то что мы надежные как утверждает максим илья have для того чтобы вам поверили информацию нужно подавать фактами вперед наши факты вот такие то есть мы выстроили единый дашборд мы отфильтровали типизированные они рты мы вы 100 мы создали внешней мониторинг режим байпас децентрализовать и где можно настройки дальше мы создали эмуляторы по всем каналам и создание тестовый фреймворк теста тесто самодиагностики собираем статистику по каждому из каналов примитивно оцениваем так как нас обслуживают наши поставщики и уже не прячусь и готовы м л модуль для дальнейшего расширения функционала перед тем как я передам микрофон вам отвечу на ваши вопросы хочу подытожить что зависимости коллеги от ваших потребностей ваших систем вам решать на каком этапе остановиться или пойти ещё дальше ну ключ к успеху здесь и там начать прост простого но гибкого механизма check engine спасибо большое давайте скажем спасибо глеба прекрасный очень подробный доклад мы тебе еще хотим вручить в конференциях и лаут подарок и давайте ваши вопросы вот я вижу слева вопрос спасибо за доклад меня зовут евгений и у меня отпер вопрос по поводу как вы обеспечиваете доступность 9995 случай если байпас тоже упадет и второй вопрос как вы обеспечиваете консистентных данных при тестировании и как справляетесь там возможно с нагрузочным тестированием 0 может быть делаете у на продакшн системе у него так что не делал литвы и стричь что касается если байпас упадет то будут проблемы на 9995 если мы посчитаем время в год у вас мы себе позволяем бежать какое-то время там какие-то true сколько там 10 15 минут байпас в целом не падает с момента старта поэтому наверно просто такого не происходило кроме того есть еще во средства более жесткие у только морских дел можем нашу систему вы вывести с эксплуатации пусть и трафик напрямую но это тоже частью делать не приходилось по поводу консистентной еще раз пожалуйста ну вот вы проводите тестирование до с помощью функционала и как вы консистенции поддерживать вы отправляете какой-то трафик через него и как это влияет на продуктовые данные никак не влияет это просто трафик такой же как и остальные наши данные все никак не разделяете принципе на на платформе нет из статистики он тоже не мешает обычные потребители но созданным тест тестами данными получается во двор даже там машине лингам тесто выданы создает регулятор или самодиагностика это просто обычный запрос такой же как и остальные остальные запросов на платформу что что он тестовый на эмуляторе он будет завёрнут тем не менее статистике он будет находиться так же как и все остальные понял спасибо я еще тут мешаюсь я нашел вопрос в интернете одну точнее в нашем чате где из онлайн трансляции а мон шер курбанов спрашивает когда автотесты гоняются на проди они обычно 3 gaillard alert и как под этим живете делали какие-то автоматические гноры таких alert of нормально живем нет ни мини-генератор ну просто находится напротив вернее их задача генерить allure alert и который мы ожидаем они не будут генерить allure ты какие-то новые то есть они сгенерили лампочка зажглась мы посмотрели а если появляются стандартные order to ну да мы их будем рассматривать как обычно один пришедший там неважно откуда а тесты для теста плохо если будут какие-то allure дополнительны супер я тут по центру где-то видел вопрос на до клип спасибо большое меня зовут филип два вопроса первый сколько по времени какой команды реализовывался этот мониторинг и 2 используете ли вы бизнес метрики для определения жизни приложения я бы не разделял мониторинг от разработки команда большая скажем 50 инженеров всего в том числе дженнер эксплуатации разработка чего-то подобного ну давайте назову год год и разработка продолжается например вот м л компонент это свежий сервис и он расширяется он фактически только начат а второй вопрос используете ли вы бизнес метрики для определения здоровья вашего приложения нам количество принесенных денег в канале например количество чего принесенных денег нет таких метрик мы не используем ну так или иначе перед тем как вообще такой отличать поведение ожидаемую не знаем и мы проговариваем высылает заказчиком и все вот это для нас является бизнес метрикой но денег деньгами нет мы не мере да спасибо глеб спасибо за доклад я тут слева слева вот здесь привет меня зовут павел вопрос такой насколько я понимаю тестовый трафик эмуляторы гоняют через всю production систему и направляют опять же на эмулятор и каким образом происходит маршрутизация по какому признаку как вы тестовый трафик отделяете вот production ну очень просто там очень уж от маршрутизатора очень много правил и маршрутизатор специально направляет его на тот порт который работает в режиме эмулятор и все то есть именно саму суть и затраты определяет насколько я знаю в протоколе smtp нет какого-то флага который бы показать все правильно да снг и протокола ход только на входе платформы дальше мы уже внутри него перегоняем через с либо кафку не badger писи и там уже совершенно другой наш пакет данных который мы обогащаем и работаем дальше только с ним спасибо да давайте еще один вопрос и дальше же переместимся в цифровой кулуары да вот тут вот есть спасибо за доклад такой вопрос заводе the halls чеки да что у вас происходит на бои а если вы позволите в каком ну как поддерживайте актуальное состояние потому что кот постоянно и так понимаю дорабатывается half чеки нужно как-то догонять до этого труда он поддерживается приходится какой процент у вас реальный актуальный ну актуальных процентов 80 залива фона много создается вот реально кто то есть какой-то кто-то команда работает по seo и сиди там допустим что-то ломается именно из-за кода то есть она аналитики много приходится делать по сломавшийся проверкам да нет обычно спасибо и второй вопрос вот вы показали чуть-чуть и прогнозирование да вот реально линейность отделение прогнозирование в текущих условиях когда все партнеры работают под каким-то бизнес с кейсом грубо говоря ну вот мы пробуем в банке мне там предсказания какие то делать но все равно ну почти нереально предсказание какие-то генерить и что-то там кому то советовать и грубо говоря что ваш тренд пошел вниз значит скоро вы там бьетесь или что то такое вот реальности практике применением пока не получается ну там какой-то открытка срок только если мы это делаем для того чтобы уложить резервные каналы резервные поставщики если мы понимаем что какое-то и стрэнд honda поставщики пошел вниз мы можем просто переключиться и мы должны знать что-либо давайте там готовится переключаться либо давайте выясним что происходит его можно автоматически переключится это для этих целей хорошо но я потом тогда еще к вам подойду удалось отлично давайте тогда еще раз поблагодарим глеба прекрасно открывающий доклад"
}