{
  "video_id": "rUbdi_UmrCw",
  "channel": "HighLoadChannel",
  "title": "Как 100 000 раз в секунду выбирать правильный рекламный материал / П.Бейзман (Data-Centric Alliance)",
  "views": 1562,
  "duration": 2948,
  "published": "2017-04-22T14:48:17-07:00",
  "text": "всем привет спасибо что пришли меня зовут паша я работаю в компании дата-центре к alliance работаю там архитектором и тема моего доклада называется как сто тысяч раз в секунду выбирать правильный рекламный материал programmatic платформы где бит . одиссея изнутри что такое вообще про грамоте платформа прерывать платформа от система которая в режиме реального времени занимается покупкой показов рекламы по отдельным временем я здесь понимаю время пока в браузере у вас грузить страничка пока вас грузить страничка браузер и мы должны решить какую именно рекламу лучше всего вам показать что он будет интересно то есть к нам с одной стороны приходят рекламодатели которые хотят рекламировать свои товары или услуги или приложения они заводят у нас рекламные кампании заводит настраивают либо самостоятельно либо через наших менеджеров с другой стороны к нам подключен это казуальную бирже трафика которая является по сути посредником между нами и конечным пользователем то есть пока у пользуйся грузиться в браузере страницы или или загружайте приложения на эту биржу ходит некоторый запрос и это биржа рассылает этот запрос другие таким таким платформе как наша говорит вот нас есть такой пользователь на такой-то страницы и он очень хочет посмотреть рекламу соответственно на 6 м к получает такой запрос она из всех компаний должна для этого пользователя подобрать наиболее релевантные в него либо же бывает такое что запрос на совсем не интересен и мы говорим что нет мы не будем показывать рекламу чтобы понять какую рекламу показывать пальцами нам нужно как можно больше об этом пользователь знать до этого мы обращаемся в сервис который называется data management platform это система которое собирает данные о пользователях в интернете о том какие сайты они посещают чем занимаются дракон пути ездят на работу и прочее это платформа оно само по себе является достаточно сложной и технологической платформы и кстати у нас будет сегодня по моему в 11 часов доклад артем маринова про то как работает это на нашу платформу документ на форм очень интересно всем рекомендую сходить но с точки зрения текущего доклада нам интересно что это платформа нам она сегментировать пользователей и выдает нам список сегментов каким этот пользуюсь предлежит он пример сегмент это может быть любители кошечек либо же там мужчины который имеет высокий доход такого вида сегменты для нас это просто какой-то набор строк который нам помогает таргетировать наши рекламные кампании хорошо это планшет платформы обогатили запрос до данными о пользователе теперь нам интересно есть мы покажем этому пользуюсь тот или иной баннер с какой вероятностью он например кликнет по этому баннеру или если он кликнет по этому баннеру с какой вероятностью он там на сайте совершит покупку или поставить приложение чтобы почитать эти вероятности нам мы используем сервис который называется предиктор мы ему отправляем все необходимые данные и он на основании разных математических моделей при помощи машину обучения читает вероятность некоторых действий например клика и возвращает от вероятность нам уже на основании всех этих данных мы считаем ставку сколько мы готовы заплатить показ этом за показ баннера этому пользователю эту ставку мы возвращаем обратно в биржу и бирже среди всех ставок так от нашей также от систем наших конкурентов например проводит аукцион кто готов больше всех заплатить за показ тот и выигрывает этот показ и той системы банер уходит в бра weather пользователя приведу немножко чисел нам приходит сейчас в секунду 100000 вот таких вот запросов на показ рекламы то есть 100000 1 секунда спрашивает если у вас что показать таком-то пользуюсь и на каждый такой запрос нам нужно выбирать из десяти тысяч рекламных материалов из десяти тысяч рекламных материалов надо выбрать наиболее релевантный причем оба этих показателей они непомерно растут например к мы начинали 2013 году но оба этих числа были на порядок которые на 2 меньше причем этот рост далеко не всегда является равномерным например нас однажды была ситуация когда вот одна из бирж трафика и причем достаточно крупная это по сути был основной поставщик трафика и он нам должен было слать запросто показ рекламы для только для пользуются из россии а у них произошел какой-то сбой и они нам начали слоиться запросы со всего мира в результате у нас буквально за считанные минуты количество трафика росла наверно 1 5 и нам даже в таких ситуациях надо уметь корректно обрабатывать и у нас достаточно жесткие ограничения на время ответа это у нас есть 50 миллисекунд на ответ есть мы не будем укладываться в это время то ну держи начинаем начнут игнорить наши ответы просто наша реклама не будет показывать с пользователем но естественно этого не хотим теперь немножко скажу про то как как мы каким образом мы подбираем наиболее релевантна рекламный материал когда он приходит запор запрос первым делом попадает в систему таргетингов торги тенге это такой механизм который позволяет из всего всей массы трафик из всей массы аудитории выбрать ровно ту которая интересна конкретной рекламной кампании то есть когда настраивается главная компания не настраивается какие-то критерии в котором она будет критерий трафика как который будет показан пример это может быть просто список доменов на которых она будет показывать то есть показывать рекламу только вот на таких то доменах и никаких других также может быть данные о пользуюсь и какие-то сегменты из из нашей data management platform то есть например покажет рекламу только мужчинам любителям кошечка также бывает торги таргетинг географические по местоположения по городу по стране в региону либо же по точного местоположения которые там по gps координат источником до 50 метров и даже есть таргетинг на погодные условия при мы можем показывать рекламу зонтиком зонтиков только в тех местах где сейчас идёт дождь соответственно все эти таргетинга объединяются и если запрос проходит все таргетинга для конкретной компании то эта компания рассматривается то чтобы показать рекламу пользуюсь и как мы производим вот эта вот фильтрацию рекламных кампаний на основании таргетинг но изначально это была такая совсем наивная реализация com просто по очереди перебираем все рекламные кампании для каждой рекламной кампании по очереди перебираем каждый таргетинг и если рекламная кампания под проходит все таргетинг и по всем критериям удовлетворяет значит хорошо если в каком таргетинг у наш запрос не удовлетворяет эту рекламную кампанию это рекламную кампанию отбрасываем и рассмотрим только те компании которые прошли все таргетинга хороший простой алгоритм и он у нас хорошо работал пока у нас был там ну 50 рекламных кампаний когда же количестве clam от компании стал расти мы поняли что вот это вот линейной зависимости от количества компаний она никуда не годится и мы столкнулись с бешеной деградации производительностью ракатов стало 200 рекламных кампаний нас просто количество запрос которыми можно успеть обработано стала бешено падать вы стали думать а можно ли придумать какой-то алгоритм что вот эта фильтрацию производить там одинаково эффективно как там для 50 рекламных кампаний так и для 50 или почти одинаково мы его придумали причем что интересно мы используем платформу rtb кит и буквально одновременно с нами разработчики этой платформы в экселе точно такой же алгоритм как как как и вы придумали основывается на следующем давайте каждый запуска рекламной кампании присвоим некоторый яндекс и вы работаете с битвами маской носками этих индексов то есть например некоторое множество любой множество компаний будем представлять в виде битую маски например а если вас запущена 8 рекламных кампаний то от нас такая битва я маска представляете себя множество в которой содержит первую ее 8 рекламную кампанию как теперь у встроен нашу систему таргетингов каждый таргетинг представляет из себя некоторые фильтр который на вход принимает запрос на показ рекламы ну по запросу здесь понимается все вообще возможные данные которые мы имеем это данных утром пришли запросе плюс данные которые нам пришли от нашей data management platform и сегменты пользователей все что все что может понадобиться для вычисления того или иного таргетинга это все принимая фильтр принимает на вход на выходе он должен выдать битую маску тех компаний которые даны конкретные таргетинг таргетинг прошли в результате эти битвы маски от разных фильтров пересекаются и на выходе мы имеем результирующую битую массу которая представляет из себя множество тех компаний которые прошли все таргетинга это как раз то что нам нужно стоит заметить что если после выполнения какого-то из фильтров мы пришли к пустой битую маски то есть все у нас все компании выпали медаль дальнейшей фильтр уже не выполняем это приводит нас к тому что на самом деле порядок вычесть порядок вызова этих фильтров он имеет значение есть нас например фильтр б отсеивают очень много рекламных кампаний то имеет смысл его поставить пораньше потому что в этом случае мы быстрее будем приходить в том множество и меньше работу выполнять соответственно мы можем собирать статистику во время выполнения и в зависимости от того какой фильтр сколько рекламной кампании отсеивают мы автоматически можем менять эти фильтры местами теперь у немножко подробнее о том как может работать каждый из этих фильтров давайте рассмотрим на примере белый список доменов то есть компания таргетированная на показ рекламы только на конкретных доменах и больше никаких ну давайте в каждом фильтр их вообще в этом фильтры храните хэш-таблицу в которых ключом будет являться домен а значением будет являться битовая маска тех компаний которые таргетированный на этот домен ну вот например у нас если тоже 8 рекламных кампаний то домен хаббл хаббл в этом примере таргетированный первые 3 и 6 рекламной кампании и так далее также у нас есть рекламной кампании которые у которых и таргетинг не установлен то есть они должны показываться на любом домене им неважно какой домен мы их будем хранить в отдельной битую маски битва битва москве без таргетинга эта компания который у нас всегда проходит от фильтра у них это таргетинг а там уж не установлен когда пусть он нам приходит запрос на показ рекламу на сайте avito.ru все что нужно сделать это найти вот и хэш-таблицы запись по этому домену вот она и объединить и эту битую маску с битой маска без таргетинга результате у нас получается результирующая битую маска это это множество компаний которые либо таргетированная avito.ru либо вообще ни на что не таргетируем то есть это как раз наш ответ на наш фильтр торт то что нам надо то есть вот мы видим что у нас фильтр от села компания номер 3 и компания номер шесть потому что обе эти компании таргетированный на хабрахабре ведомости но не таргетируем на авито соответственно все что нам потребовалось сделать это один пояс в кэш таблицы и одно объединение битвах маска если говорить формально то на самом деле на все равно осталось линейная зависимость от количества компаний потому что размеры вот этих битовых масок они предложили я не зависит от количества рекламных кампаний но блин эта зависимость она от линейной зависимости она во первых не по каким-то там сомнением строк или поисков хэш-таблицы анапа битовым операциям который процессор выполняет там чуть медленнее чем мгновенно и это зависимость с коэффициентом 1 64 потому что битвы маски работать на вся четырех битных чеслав и мы просто объединяет 26 четырех битных числа мы сразу то материю можно c64 рекламных кампаний пера есть у нас запущена 10 тысяч рекламных кампаний вырабатываю работаю с битвой москве в которой всего 166 четырех битных чисел это в отличие от вариантов предыдущего когда мы вынуждены были вот награда такого уже фильтрах перебирать каждую рекламную кампанию в ней там как-то смотреть входит ли в ее список доменов вот этот конкретный домен ну на самом деле не всегда все так просто выходит с фильтрами то есть большинство фильтров выглядит примерно так но бывает более сложный пример список доменов от хорошо но его надо откуда брать от q catcut подкачивать и возникает желание сказать а давайте будем показывать рекламу только на тех страницах вёл которых встречается такая то под строка тут нам хэш-таблицы уже не подойдут почему потому что мы не можем сказать хорош таблицы дай нам значению папа строке таблицы умеет работать только с полным падением и тут нам приходит на помощь такой алгоритм который называется аж карасик вот вопрос в залог кто-нибудь знает про это алгоритм поднимите руку отлично этим не все равно расскажу алгоритмах карасика что он умеет делать у него есть набор каких-то строк произвольный он умеет по этим строкам построить структуру данных который называет называется бор использует структур данных он умеет для любого текста быстро сказать какая из строк в этом наборе является под строкой этого текста причем сказать это может линейно по длине этого текста вне зависит от того сколько на строк наборы и соответственно еще один вопрос залу кто-нить может привести пример какого-нибудь продукта известно о котором мы все часто используем которые без этого алгоритм просто услугу обойтись да абсолютно правильно антивирус у антивируса есть большая база сигнатур нам гранж то миллионов этих сигнатуре он должен просканировать каждый файл и компьютерами предмет наличия этих сигнатур причем он абсолютно одинаково быстро это делает как есть в его базе был 100 сигнатур также быстрого делать как и когда у него более стабилен сигнатур как раз благодаря этого этому алгоритмах карась потому что он один раз построил от структур данных из тех сигнатур и уже по ней умеет быстро искать я не буду вдаваться подробности как именно устроить структур данных труш так что вот для четырех слов к это закат фоны фото структур данных выглядит вот так это такой конечный автомат упоминающие дерево в котором каждая вершина соответствует не которому слову чтоб понять какого слова нужно пройтись от корневой вершины до текущей и прочитайте буквы соответственно вершины которые соответствуют словам из нашего набора они помечены здесь жир на жирном цвету есть два вида ссылок зеленые это основные ссылки которые просто нас ведут в конечном итоге каком-то и слову в нашем наборе и синенькие так называемый пунктирные трюки так называемые уксусные стрелки они из каждого слова ведут вершину которая соответствует слово которое является на и дальнейшем с уксусом этого нашего слова результате к нам поступает некоторый текст и нам нужно сказать какие спад строк ним встречается мы анализируем построчно этот текст и перемещаемся по нашему дереву приятнее всего мы перемещаемся по зелененьким стрелочкам если же мы не можем переместиться по зеленой стрелочки мы пытаемся переместиться по оси ник и стрелочки оттуда повторить эту операцию если же у нас не осталось ни зеленых не синек стрелочки мы возвращаемся в корни этого дерева соответственно есть мы на пути встретили какие-то из наших жирных вершин значит вот этот слова которую которым это жирное решил соответственно включается наш текст соответственно применительно к нашей задаче таргетинга на по строку в ссылке теперь становится все просто по аналогии с примером с фильтром на домены мы в каждой вот это конечный вершин был хранить битую маску тех рекламных компаний которые таргетированные на вот такую строку ну и соответственно приходит запрос мы берем ссылку из этого запроса пробегаемся по дереву и на ход находим эти конечные вершины объединяем с ними и x друг с другом и после этого также не забываем про те рекламной кампании которого которых и таргетинг не установлены объединяем смазка и без таргетинга вот собственно и все это все что я хотел рассказать про нашу систему таргетингов теперь после того как мы отфильтровали нашей компании дам для оставшихся компании надо узнать вероятность что пользуется например кликнет по баннеру этой компании это нам помогает сервис предиктор он мы им отправляем запрос она возвращает вероятность сложность том что нам надо делать эти запросы для каждого вообще баннера в системе ну то есть потому что для разных банеров вероятность разные естественно соответственно если нам приходит 100000 запрос в секунду и у нас 10000 банеров то сколько надо включать сделал запросов яндекса 100 тысяч на 10000 это миллиард запрос секунду слава богу мы конечно перед этим уже провели торги деньки и они нам конечно сильно сократили количество рекламных кампаний ну там на несколько порядков на самом деле это сокращает путь и менее все равно вот график запросов предикторы он в пиках он достигает миллион 200 тысяч запросов это достаточно серьезные числа что даже для того что просто эти запросы отправить и обработать их ответ перед тем как я расскажу как мы это делаем я расскажу пример что вообще мы отправляем туда какие да ну собственно то отправишься данные которые виктору могут понадобиться для подсчета вероятно с первую очередь это параметры площадки на котором будет показываться нашу рекламу то есть это может быть ну домен какая-то я тематическая категория например сайт про компьютеры это также относится места на странице где будет показ если это показ а где-то сверху верху то вероятность клика наверное больше чем если показ будет где-то там глубоко внизу до которую фиг то до крутит вторая группа параметров это параметр нашего пользователя его пол возраста все сегменты которым он пролежит момент мнению наши и платформы обработки данных сюда же относится некоторая история пользователя это в некотором виде то почему в числовом виде представлен кой-какие он нас видел рекламной кампании каким кликала все что делал и третья группа параметров это параметр непосредственно нашего баннера ну это его идентификатор размер может быть тоже к тематическая категория что это там bayer по телефону например ну и так далее предиктора у нас используют платформу уолпол бэббит это такая опасная платформа для машинного обучения и она принимает запрос вот таком вот виде это запрос в текстовом виде он представляет из себя набор всех параметров которые могут потребоваться ли определение вероятности разделенных пайками ну особо обращаю внимание что запрос в текстовом виде что нам в принципе еще сильнее ослабляет нашу задачу сгенерировать миллион таких запросов в секунду как уже от задач отправляемся ну первое что вам приходит голову что вот параметр который относится к пользователю а также к площадке к сайту мы верим только один раз потому что назад послать запрос для каждого баннера но вот это вот часть строки она остается неизменной всегда поэтому я генерим один раз а потом к ней уже дописываем небольшую часть которая соответствует параметрам баннера и от про и отправляем это мы это сделали нам это прям такой хороший прирост производительности дало но мы все равно не остались довольны стали профилирует код и профайлер нам показал что у нас почти все время тратится на перевод и из числа в строку потому что формат текстовым и данный на ночь из нас в памятью бинарном виде естественно хранятся на надо конвертировать в строку но стали думать как это оптимизировать стали искать может какие-то супер оптимизированные конвертеры функцию перевода ничего особенно нашли писали свой его особенность в том что он не использует никаких выделений памяти то есть он там есть номера стандартные в си плюс плюс там метод tostring возвращать строку которая для которой от выделить память наш естественно это не использует но на самом деле есть и стандартный который тоже не какую память не уделяет но мы как за счет чего получили преимущество мы не не используем переворачиваем числа то есть обычно как делать ну разряды числа получается сначала младший этом отделении надеюсь потом от ваших старшим в и кстати число записывать сначала там перевернутом виде потом его переворачивать мы сделать это вот этого переворачиваю смогли избежать таким образом мы передаем функцию буфер который мы хотим чтобы был записан число его размер и функция записывает от число начиная с конца этого буфера и просто возвращает указатель в этом буфере на начало этого числа так мы избежали переворачивание и нам ну по сравнению с ближайшей там по прародителю стандартной функцию а там было примерно в полтора раза прирост вам захотелось еще больше и мы решили посмотрю как это казалось бы что тут еще можно оптимизировать но мы решили посмотреть на то какие у нас вообще данные бывают какие нам числа приходится переводить смотрели получилась вот такая картинка что числа от 0 до 10000 составляют почти половину всех значений на 45 процентов остальные числа составляет 55 процентов соответственно что он можем сделать мы можем гаити 10000 просто один раз при старте программы посчитать перевод их строку и сохранить в массиве соответственно в половине случаев наш функция теперь вообще ничего не делать там просто берет уже готовую строковое значение из нашего массива и возвращает ну а вы стали в остальных случаях использовать вот наш быстрый алгоритм без переворачиваю строки но получилось добиться вот таких результатов сравнению со стандартными аналогами не очень стандартными наши зато в среднем 27 секунд что почти втрое лучше чем с printf стоит заметить что это числа получены на моем ноутбуке поэтому если их на каком-то более мощном сервере запускать или ранен там 1 2 будет меньше ну и стоит заметить что это именно для наших данных то есть именно для тех чисел на кота на которых мы работаем мы собрали статистику и наверное не запустили этот тест конечно на других каких числах в произвольных они наверное разряд будут чуть менее впечатляющим хорошо мы отправили запрос в предиктора миллион запрос в секунду отправили сколько отправили запросов столько же нам пришло ответ эти ответы как-то надо обработать вот код представлен код потока который обрабатывает ответы от предиктора ну на самом деле в системе очень много есть не почти все потоки выглядят примерно так то есть надо каких-то данных подождать и обработать данные ну подождать мы можем примерно ждать там получение данных из окита или из какой-то блокирующий очереди или там какой-то условный переменный ждать что кит данный подготовиться куда коленочки почти все все потоки выглядят вот примерно вот так на самом деле если есть у нас высокие нагрузки то лучше производительность можно добиться если переписать этот код вот таком виде мы ожидании данных заменили просто на сон в одну миллисекунду что здесь произошло мы немножко пожертвовали временем нашим временем отклика в среднем на пол миллисекунду потому что когда запрос приходит ему в среднем до окончания слепа надо ждать еще полмиллисекунды но зато мы здесь экономим на переключение контекста ну что если вот в этом варианте этот поток вынужден просыпаться каждый раз когда приходит запрос и обрабатывайте обработает запрос и снова заснуть то в оптимизировал варианте он спит одну миллисекунду и все запросы которые за это одну миллисекунду накопились он обрабатывает соответственно если нас запрос в больше чем 1000 в секунду мы уже начинаем здесь выигрывать по переключению контексте если на запрос в 100000 секунду мы выиграем староста переключением контекст это дает существенный прирост правда как побочным эффектом так такого подхода является что если мы запускаем нашу систему вообще без трафика без всего то в ней на самом деле кучу таких вот потоков которые каждую миллисекунду просыпается она там начинает рожать 20 процентов система я ничего не делает она сразу же 20 процентов young ну это иногда просто вопрос у кого-то возникает почему так семейные у стольких нагрузках и такой подход начинает выигрывать у нас такой подход спрос не только при обработке ответов от предиктора ну и вообще достаточно где но стоит понимать что ну мы нам надо понимать сколько мы готовы пожертвовать нашим время отклика потому что например если вот была система какой-то высокочастотной торговли потом у них счет идет не на миллисекунду этом на микросекунды идет они конечно для них поспать одной миллисекунды от преступления но у нас все такие ограничения 50 миллисекунд или ну одну миллисекунду мы потеряли осталось 49 ну ничего страшно глядя на этот поток возникает вопрос а что будет происходить если наш поток перестанет успевать обрабатывать данные то есть будет настолько также он просто будет захлебываться но произойдет перегрузка сотку я перегрузка это когда данных данных поступ данные поступают быстрее чем мы успеваем их обрабатывать в этом случае они где-то копится в какой-то очереди один один за другим каждый следующий запрос обрабатывает все через более дольшее время через более дальше по сути система перестает работать ну потому что если мы не отвечаем за наш 50 положенные миллисекунд нам уже от этого цвета очень никакого толка нет хочется что то с этим сделать как-то эту ситуацию разруливать ну в первую очередь хочется иметь какую-то честную характеристику того на сколько у нас наш поток хорошо справляется насколько он или насколько он сейчас загружу ну на самом деле как можно это оценить можем посмотреть можно сказать что если поток почти все время спит и только изредка обрабатывает данные значит что он совсем не загружу или наоборот есть или наоборот если он все время обрабатывает данные не совсем не успевает поспать то значит он почти полном загружен еще чуть чуть больше нагрузки он уже произойдет перегрузка ответственно как мы считаем эту нагрузку мы вот перед нашим с лифом и после вставили такие счетчики нас в переменные total sleep time аккумулируется общее время сна этого поток вообще сначала запуска программы и у нас есть какой-то внешней поток который через какие-то промежутки времени краю 1 секунду читает это значение total слив times и зная и зная значение total слетаем на предыдущем измерении он может почитать нашу нагрузку вот таким образом дельта это сколько он за прошедшее время поток проспал соответственно я ношу нагрузка это единица минус этот день 3 деленное на размер этого промежутка одна секунда соответственно есть вот эта цифра лот нас приближается к единице это значит что потока все время обработал обрабатывает данные почти не успевает спать и надо с ним что-то делать если же она где-то там в районе меньше 50 меньше 0 5 то значит потоков все нормально он еще половину времени спит и еще и на него можно еще подгрузить что мы делаем винить я попью что мы делаем с этим числом но в первую очередь мы на него смотрим мы его выводим в графит вот такие у нас замечательные графики и мы в разрезе по потокам видим какой из поток на нас насколько загружу соответственно что она выдает она дает нам на самом деле массу информации в первую очередь мы видим что есть у нас какой-то из потоков приближается к единице то это наш сигнал о том что например нужно расширить железо потому что еще чуть-чуть нас увеличится входящий трафик и мы уже перестанем успевать превзойдет перегрузка что еще в первых это для нас как такой первичный профайлер мы можем еще без запуска кого-либо там стороннего профайлер понять что вот вот этот поток у нас съедает больше всего на больше всех загружу не может быть не стоит обратить внимание на оптимизацию этого потока что то что то он может такое тяжелое делает соответственно если мы провели какую-то оптимизацию мы можем выложить например на одном из серверов оптимизированную версию сравнивать вот эти графики на оптимизированы версии на неоптимизированные версии это нам дает понять насколько наши оптимизации удалось насколько какая разница между оптимизированы оптимизм соответственно обратный пример если мы добавили какой-то новый функционал например ну новый таргетинг какой-то и он может быть например сжирает нас производить он очень-очень плохой по производительность мы тоже благодаря вот этим графиком это очень быстро увидим и решил что делать ну либо как-то оптимизируем либо вообще откажемся от этого таргетинга либо забьем и скажи пусть будет как так как будет ну и плюс эти графики там дают общее понимание того как ведет систему вот например если посмотреть на график предиктор от как раз графика обработки ответов от предиктора то видим что в районе там 8 утра это появитесь и на самом деле 11 какое-то падение произошло самом деле отпадение потому связано с тем что нас аккаунт-менеджер включили какое-то большое количество рекламных кампаний с большим количеством банеров соответственно запросов предиктору стало меньше и вот так нагрузка упала средство это нам дает возможность видеть что вообще происходит как у нас какие действия влияют на нашу нагрузку но и во время расширять железо но как и говорил я пример привел вначале что нас иногда за там за одну минуту нагрузка может вырасти там в 5 раз и в этом случае мы можем просто не успеть за расширить железо да и на самом деле не всегда это надо потому что если на версус пять раз то скорее всего это какая-то аномалия и на следующий день она вернется к нормальным значением целей нам хочет чтобы в этом случае не происходило никаких перегрузок что можно сделать мы вели нектар порог 95 процентов если у нас какой-то из потоков из всех превышает нагрузку 95 процентов мы говорим эта опасность еще чуть чуть и всё что мы можем сделать мы можем просто начинается обрезать входящие запросы трафика обязательно смысле что мы на самом раннем этапе разворачиваем их и говорим нам их запрос не интересен мы не подобрали для него реклама то есть для страны наших партнеров рекламных бишь отвыкли как нам просто запрос не интересно нас нет рекламы для него а мы же это делаем вообще на самом самом раннем этапе так еще доп до какого либо парсинга чтобы не создавать лишнюю нагрузку на систему которая вас итак перегружу естественно количество этих обрезанных запросов мы пишем графит это же для нас сигнал что система уже сейчас не справляется и нужно расширять но тем не менее вот этот про нас есть некоторый процент трофи которые мы режем и из них процент трактором которые мы можем обрабатывать мы продолжаем обрабатывать также как и поэтому это вообще очень замечательный механизм дает нам спать спокойно мы знаем что даже если кто-то ночью пока мы спим включит нас лишний trike мы просто излишек которые мы не успеваем обработать развернем сразу а все остальное обработай мы ответим за 50 миллисекунд который нам положен и не принесем там никаких имиджевых потерь и прочего соответственно мой доклад подходит концу хочется сделать какие-то выводы выводы первый алгоритм узнать все таки полезно хотите спорный вопрос но полет на самом деле полезно потому что ну вот как я привел пример с таргетингом по по строке если бы мы не знали что существует такое алгоритмах карасик мы бы ну сделал беатор летим в лоб там перебора всех рекламных кампаний проверки там на подстроку увидели бы что он просто деканом просаживает производительность скорее всего мы в этом случае бы уговорили бизнес отказаться от этого таргетинга просто но ничего хорошего был один получил для того что мы знали что такое алгоритм есть мы его применили и сделали очень оптимально не обязательно конечно знать досконально каждый алгоритм как он работает но хотя бы примерно представлять что вот есть там обувь алгоритм на подстроки которые имеют который умеет там по-разному искать подстроки если мы знаем только вам приходит такая задача мы можем поесть в интернет и посмотреть какие есть алгоритмы подходящие хотя бы знать надо область которую искать в интернет можно полезть на есть хороший сайт химок ссору с описанием почти всех алгоритмов из не всех правда распределю строчку стоит заметить что вот конкретно алгоритмах карасик на нем приведем с ошибкой ему там в комментариях это описали но общем-то авто до сих пор не поправил 2 вы как хочешь сделать это что нужно использовать некоторые особенности своих данных это как мы сделали с функцией перевода из числа в строку соответственно но обычно все стандартные функции а не рассчитан на вообще на произвольные данные поэтому они не всегда могут работать оптимально для ваших данных а знает что у нас большинство чисел небольшие то возврат 10 тысяч мы смогли это особенность применить и сделать более оптимально третий вывод это что у нас время отклика и пропускная способность и зачастую это такие весы и нам нужно найти некоторый баланс вырос как мы можем пожертвовать временем отклика в угоду простой способности или наоборот ну такое вообще достаточно часто бывает что это весы например самый такой устроим пример это размер буфера тесте пиво person системе если буфер маленький это соответствие что мы быстро его наполним и данные отправиться у нас не skylight вести но прошлая способность тоже низкая потому что каждый раз надо отправляйтесь в пакет если буфер большой то мы ждем когда он полностью наполнится это ты у нас late in se ухудшается но зато улучшается просто моя способность вы потому что задира скопом все данные отправляем следующий вывод о том что стоит мониторить и внутренности систем почему то зачастую люди забывают что мониторит какие-то бизнес метрики например сколько всего было пользоваться и сколько денег заработано там сколько кликов так и такое но забывает фрумин торин каких-то внутренних внутрь иных показателей а сколько у нас там был попадание в кэш сколько было переключение контекста какая загрузку потоков как нашем случае эти данные они очень сильно помогает понимать что происходит вообще в системе и быстро отлавливать баги и прочее и следующий вывод что не надо допускать перегрузок достаточно очевидный и надо подумать если у мамы приближаюсь к состоянию перегрузки можем ли мы например чем-то пожертвовать чтобы это при русским сгустить вот мы например нам повезло мы можем просто развернуть этот запрос и сказать мы не будем него делать ставку но в любом случае стоит подумать как то можем ли мы можем можете ли вы в данной ситуации что ты сделать наливай что это не всегда возможно например есть какие-то системы биллинга которых запросы какие-то деньги конечно нельзя так отбрасывает запрос но может быть их можно записать какой-то интерлок чтобы потом работать или что то в этом духе такие вот выводы на это у меня все спасибо за внимание sa8 отвечу на вопрос для ста тысяч запросов в секунду сколько железа вам требуется под базой подобрав очки но под базой немного потому что у нас база используется для того чтобы озираться из нее все в память там все рекламной кампании считать и памяти мы лидеры мы потом обновляем там ну по каким местом механизм как обновлять с базы для обработки всех запросов у нас сейчас на данный момент используется 20 дров они расположены в 3 дата-центров основной до центра to europe на него приходится наверное 85 где-то так процентов травкой в нем 13 ров то есть у нас вот 13 суров обрабатывать где-то 85 тысяч запросов в секунду примерно вот так вот ну я не удерживает рассказывать и на самом деле не боюсь хороший бицепс я могу точно не знать у меня такой вопрос вот вы показали график загруженности потоков ну сколько поток спиц скука не спит но у вас есть такой же поток который таргетинга считают то есть вы горите есть ли поток который считает to this добавили тяжело на самом деле этот поток поток роутер но он просто и еще такой вопрос от промышленник то есть вы используете упал лепит 2pm и за какие там алгоритмы то есть закрыть линейной регрессии что логистическая регрессия там но я вот какие-то слова на самом деле точно я досконально не знаю знаю что используется логистической регрессии можно можно еще что то у нас есть там целый отдел крутых аналитиков которые там этим занимается они хорошие математики они ты сюда очень много времени потратили ну конечно дают очень важный компонент еще так образ почему aerospike я дорожу манометр пасть лицензия нет нет вас не раз не enterprise лицензию open source не обычный он нам но он действительно наш тест указали что он очень хорош изначально была редис редиска конечно не справился там ни с какими объемами данных мы перешли на я распайка и в общем в полосу довольно он отвечает в пределах одной миллисекунды на 11 запрос процентов запросов вроде просто только в платной версии позволяет репликацию делать репликацию между разными дата-центра дамы этим не пользуемся мы там сделали свои обходные решения для этого спасибо скажите у меня такой вопрос а почему все-таки один креатив ты уходит в редактор но мы поняли что кэшируется вас информация запросе а нам один креатив ли компания нет один креатив просто вы говорите что у вас приходится тысяч запросов там 10000 вас креатив того почти миллиард дара компаний миллиарда просто предиктору почему нигде не агрегировать почему у него ну мы можем послать один запрос огромный но это не будет сильный очень большой прирост но либо 1 либо один огромный либо много маленьких не такая уж большая свой плюс мы ограничен тем что у нас вот есть волку выбиты мы должны стать в том формате попробовать это ограничен систем за счет чего можно получить при роза то что мы пошли даже вот эти данные пользователей сайта мы их не только с гирей возрастных и пошлем один раз нам приходится слать каждый раз ну а так собрать не вижу ok он человек спасибо за интересный доклад у меня два вопроса первый это мало кому протоколу происходит общение с предиктором а вот собственно его показал это вот такой текст и вакуум ну а именно по степи поверхность пиво такой протокол от контекста они даже теряются перевода строки а во второй вид внутри себя и на второй вопрос он не повторять эти операции по переводу из текста повторяет ну то есть получается как там 33 этих циклов сначала вы переводите из числа строку потом был выбит из строки в число и потом обратно он обратно можно облучье а в ночь ставшего возвращает вероятность ли там 50 процентов срезали я просто ну то есть вы быстро переводите из числа страну даже любит стандарт не знаю не знаю сейчас как как отделать waplog но он работает тоже очень шустрого нас не так много серверов обрабатывают вот эти миллион запрос в секунду спасибо можно пример когда рекламодатель хочет таргетинг по строке что именно какого вида я немножко не понял но смотрите примеру если у нас воруя странице есть подстрока телефон-то предположение что реклама телефонов на этой странице будет хорошо работать ну по тегам площадку таргетировать и так далее ну это не такой гибкой сдает во первых то это будет египте тегировать . не все наш партнер это сделают и но так нас рекламный сайт какую захотел она мне знать какие у нас ей бывают теги какой захотел такой увел плюс отдает там еще часто этим пользоваться на какую-то часть страницы например нам чтобы там убрать под домен и какие то вот так вот так это можно использовать спасибо все вы говорили что при ранжировании вы используете еще данные из темпы а в темпе они оттуда откуда вы на каком уровне их лагерь отливов покупаете эти данные но как я говорила вот будет доклад артема маринова конкретная про нашу дмп очень интересный доклад я уже слушал рекомендую сходить он будет я могу ошибаться не по моему сегодня в один в 11 часов он зовут хотя нет я все таки не в один может 12 называется сегментирован 600 миллионов пользователей каждый день очень клёво вам все это расскажу про это хорошо спасибо вас по всем спасибо"
}