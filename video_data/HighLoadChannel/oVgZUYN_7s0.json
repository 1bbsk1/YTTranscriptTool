{
  "video_id": "oVgZUYN_7s0",
  "channel": "HighLoadChannel",
  "title": "Авито Автозагрузка: как качать миллионы фотографий в сутки / Евгений Толмачев (Авито)",
  "views": 8207,
  "duration": 2737,
  "published": "2023-10-16T00:08:09-07:00",
  "text": "а спикеры за Вита Встречайте друзья Евгений под музычку Готовьте вопросы раз раз Всем привет Меня зовут Женя толмачев я работаю в компании Авито и руковожу командой которая разрабатывает продукты Это автозагрузка это инструмент для продавцов который позволяет им массово управлять своими объявлениями на нашей площадке Так а это Знакомьтесь это график роста нашего сервиса на нем количество активных объявлений на Авито которые управляются через автозагрузку наш продукт не Молодой ему уже более 7 лет за которыми он прошел путь от небольшого стартапа до одного из ключевых продуктов компании и все это время нагрузка на него росла в основном Линейная очень хорошо прогнозировалось каждый год мы увеличивались где-то в полтора-два раза и привыкли к этим темпом вообще это достаточно стандартная история про органический рост который я уверен знакомо многим из вас и это мог бы быть самой скучной доклад на конференции если бы не Вот это это тоже график нашего роста если в двадцать первом году мы выросли с 5 до 9 миллионов активных объявлений то уже в двадцать втором набрали какие-то невероятные темпы и отросли до 40 миллионов а в первые месяцы 23 пробили полку в 60 миллионов пока Я готовился к докладу мы поставили новый рекорд и управляем уже 70 миллионами объявления на Авито и это примерно половина всего контента для сравнения когда четыре года назад пришел в компанию Наша доля составляла всего 2 процента и такой стремительный рост связан с запуском новой модели оплаты за размещение объявлений вы можете увидеть что она оказалась очень востребована среди наших клиентов а для нас самих это был самый настоящий вызов если в конце 21 говорили что готовы поддержать рост На горизонте Еще пару лет прежде чем нам придется менять как-то существенно нашу архитектуру то в новой реальности весь наш запас прочности превратился бы ты в тыкву буквально за полгода и с этим нужно было срочно что-то делать И вот в своем докладе я расскажу о том как мы выживали и решали проблему масштабирования автозагрузка Это большой продукт состоящий из множества разных микросервисов и Сегодня я расскажу только об одном но очень важном ее компоненте сервисе который отвечает за скачивание фотографий объявлений я покажу архитектуру сервиса как она выглядела в конце 21 года расскажу про основные ее проблемы Вместе мы попробуем эти проблемы решить а в конце подведем итоги и посмотрим на то что у нас получилось я не буду рассказывать как с нуля строить какой-то дикий hellout и всегда Быть готовым любой рост пережить и не буду много времени уделять нашей инфраструктуре это большая и очень интересная тема которая могла бы потянуть на отдельный доклад Я же хочу сосредоточиться именно на архитектурных подходах Но прежде чем начать нам нужно разобраться что такое автозагрузка если коротко это инструмент массовой публикации объявлений основная идея проста у клиента есть файл каталог его товаров и любое изменение в этом файле должно отображаться у нас на площадке Если клиент добавил объявление файл мы должны его опубликовать если отредактировал то отредактировать А если удалил то снять публикации он может загрузить нам этот файл разово через личный кабинет или API или выложить его на хостинг и настроить режим автоматической выгрузки по расписанию такие клиенты могут выгружаться 7 дней в неделю хоть каждый час и составляют составляют более 80 процентов всего нашего трафика Для нас это значит что каждый час нам нужно запустить Все запланированные выгрузки и как можно скорее распространить волну трафика по всем компонентам нашей системы это нужно для того чтобы успеть доставить до площадки изменения до того как у клиента начнется следующий выгрузка и вот эти пики на графике это как раз моменты запуска выгрузок как-то избавиться от них или сгладить нагрузку мы не можем У нас есть продуктовое требование запускать в начале каждого часа за этот час через нас проходит десятки миллионов объявлений для каждого из которых нужно определить А если в нем какие-то изменения относительно предыдущей выгрузки клиента или относительно того что на вид сейчас если такие изменения есть их нужно применить чтобы опубликовать объявление нужно выполнить как минимум две вещи проанализировать данные о нём из этого файла каталога и скачать все фотографии ссылки на которые тоже указаны в этом файле Вот только после того как мы все это сделали объявление можно отправлять на публикацию для скачивания фотографий у нас отвечает один отдельный сервис каждый час через него проходят сотни тысяч объявлений это до 4 миллионов фотографий в час которые нужно попытаться скачать вообще стоит остановиться и рассказать А как вообще фотографии попадают задачи на скачивание попадает в этот сервис это происходит когда у нас появилось какое-то новое объявление у существующего объявления как-то изменился список фотографий или же предыдущие выгрузке мы не смогли скачать часть фотографий и нужно Повторить попытку уже в рамках новой выгрузки И сейчас я покажу архитектуру сервиса то как она выглядела в конце 21 года Она состоит из трех слоев оранжевый слой отвечает за сохранение входящих задач синий слой за скачивание фотографий а фиолетовый за отправку результата потребителем можете ее внимательно не рассматривать потому что каждом из них я сейчас достаточно подробно расскажу оранжевый слой состоит из http который прилетают пачки задач на обработку объявлений чтобы обеспечить максимальную производительность и отказоустойчивость этого API он не работает с базой вместо этого просто перекладывает весь необходим его трафик в очередь на который уже подписан по уоркеров которые взаимодействуют с БД получая задачу на обработку объявлений worker смотрит а нужно ли вообще хоть что-то качать если хотя бы одна из фотографий еще не была скачана то создается задача на обработка всего объявления и по одной задаче для каждой фотографии которую нужно скачать А если ничего качать не надо у нас уже все есть он просто достает результаты с базы и отправляет его дальше Далее в работу вступает синий слой он состоит из крона планировщика задач который работает всегда единственным экземпляре и запускается один раз в минуту его основная цель для каждого клиента достать из базы задача на скачивание фотографий но за один свой проход не больше задач чем указана в настройках этого клиента здесь получается такой очень простенький метр построенный на эвристике и нас это в целом плюс-минус устраивало так каких-то требований очень жестко соблюдать У нас не было И главное здесь не залить трафиком и не положить сервера наших клиентов после того как планировщик достал задача он публикует её в одной из очередей для скачиваний У нас есть два Пула воркеров это быстрые с таймаутом на скачивание в одну секунду и медленное с тайм-аутом на скачивание в 30 секунд они архитектурно абсолютно идентичны и разница лишь тайм-аутах и размере Пула Горький быстрый воркеры попадают все новые задачи А в медленные все попытки повторного скачивания Сам же процесс скачивания очень простой мы идём по ссылке и пытаемся скачать фотографию если у нас получилось то мы полученные данные заливаем во внутреннее хранилище получаем оттуда информацию которая сохраняем к нам в базу она нужна для того чтобы не пересохранять фотографии которые мы могли уже ранее скачать ссылки на которые могли поменяться скачанные фотки Мы увидим что она у нас уже есть и не будем ничего сохранять здесь возникает вопрос Что делать если фотография скачать не удалось мы разделяем ошибки скачивания на две группы Первое это различные 403 404 в целом всякие ситуации когда доступ к контенту либо ограничен либо его еще не существует по ссылке такие задачи мы не будем обрабатывать пытаться обрабатывать еще раз в рамках текущей выгрузки клиента Но если у него начнется следующая выгрузка они снова к нам прилетят и вторая группа это ошибки которые есть смысл попытаться обработать В текущей выгрузке это различные пятисотые таймауты всякое такое и вот для их обработки как раз существует отдельный Пул медленных ретроблокеров после того как задача завершены я картинки скачанные настает время публиковать результат и за это отвечает последний фиолетовый слой он тоже состоит из крона-планировщика который получает из базы все задачи на обработку объявлений у которых завершены все задачи на скачивание фотографий здесь уже никакого рейтинг нет так что крон может запускаться как можно чаще полученные из базы данные он публикует в очередь на которую подписан пол воркеров которые занимаются формированием и отправкой результата и в итоге мы имеем вот такую вот достаточно простую архитектуру которая тем не менее служила нам на протяжении нескольких лет и была бы прослужить готова прослужить года два если бы наши стремительный рост на самом деле здесь Я хочу остановиться и зафиксировать парочку важных На мой взгляд мыслей первая мысль что не нужно пытается строить космолет там где в этом нет необходимости простые решения могут служить нам годами а сэкономленные ресурсы можно потратить на то что принесет пользу уже сейчас и наш сервис служит здесь хорошим примером и вторая мысль что все же может настать момент когда придется строить самолет и самое главное уметь этот момент вовремя поймать здесь в идеале у вас должен быть какой-то План Б или хотя бы понимание Что вы будете делать если случится И вот именно это с нами произошло 22 году у нас ожидал ожидал резкое изменение профильной нагрузки и тот запас прочности который мы имели нам уже не помог его хватило бы максимум на полгода беззаботной жизни а потом потом эпичное падение и вот для того чтобы такой рост удержать нужно сделать одну очень важную вещь побороть себе желание срочно бежать что-то делать а выдохнуть и спокойно сесть и проанализировать все проблемные места чем мы с вами сейчас и будем заниматься я скажу вот такие вот проблемы сервиса это производительность планировщика задач рейклиметр который по факту никак не защищает нас от ddos-атак на сервера клиентов и медленные хостинги которые могут тормозить собой работоспособность всей системы и первая проблема это планировщик задач его пропускная способность ограничена А сам он может работать только в единственном экземпляре если мы возьмем и добавим рядом еще N таких планировщиков мы лучше не сделаем вместо этого получим состояние гонки дубли задач и даже поломаем наш Реквием при этом мы уже начали сталкиваться с ситуациями когда его производительности не хватало когда к нам разом приходило несколько очень крупных клиентов с большим количеством фотографий его заливало трафиком он начинал тормозить вот такие тормоза можно увидеть на этом слайде вот эти вот выбросы это моменты прихода каких-то очень крупных клиентов давайте заведем блок задач такой Список проблем с которым Будем дальше работать и добавим туда планировщик вторая проблема это медленные хостинки доля фотографии которые получают ошибку скачивания и перетекают составляет около 60 процентов это значит что 60 процентов всех задач мы пытаемся скачать минимум два раза Это лишнее и по сути бесполезная нагрузка в самом ретро контуре мы качаем фотографии с максимальным тайм-аутом в 30 секунд когда нам приходят несколько крупных клиентов с очень медленными хостами фото с которых как раз и качаются за эти 30 секунд они забивают на очередь система начинает работать медленно и образуется пробка в которой простаивают фотографии которые могли бы скачаться быстрее эту ситуацию усугубляет наши лимиты а Если точнее то отсутствие обратной связи между воркерами И планировщиками если в системе образовалась пробка планировщик не останавливается продолжает активно накидывать задачу очередь А чего та еще больше раздувается медленные фотографии рано или поздно кончатся и очередь дойдет до быстро здесь может образоваться реально лавина трафика который мы зальем и Возможно даже положим кого-то из наших клиентов Давайте вернемся к нашему клубу и добавим туда еще одну задачу нам нужно сделать честный метр который будет защищать нас от таких ситуаций вообще медленные хостинги это очень интересный случай можем пытаться качать максимум из всего того что будет нам приходят и тогда будем терять минимальное количество контента но при этом несколько крупных клиентов с медленными хостами будут тормозить нашу систему у нас возникнут задержки в публикации объявлений и это повлечет за собой негатив клиентов или мы можем качать максимально быстро и пожертвовать фотографиями с медленных остов тогда производительность системы будет высокой но при этом мы начнем терять контент И это тоже вызовет негатив клиента здесь нужно найти какой-то баланс между высокой скоростью работы всей системы и минимальные доли того контента который мы теряем эти Вернемся еще раз к нашему кругу и посмотрим на то с чем нам предстоит работать наша первая цель научиться масштабировать планировщик по сути это задача про организацию параллели параллельного доступа к какому-то разделяемому ресурсу мы используем Манго тебе и в решениях о которых я сейчас буду рассказывать будет присутствовать работа специфика работы с этой базой вообще я постарался выделить именно общие подходы которые будут работать вне зависимости от того что вы используете себя и разница лишь реализации Давайте на время забудем прометр Мы его уже обозначили как проблемное место а сейчас хотим сосредоточиться на максимально быстром эффективном получении задачи с базы и первый подход про который я расскажу пессимистичный системах с параллельным доступом могут возникать конфликты и этот подход предлагает эти конфликты предотвращать для этого используется блокировки для того чтобы поработать с ресурсом компоненту нужно поставить Лок на его обработку А все остальные компоненты которые хотят поработать с этим же ресурсом должны выстроиться в очередь в ожидании того когда блокировка освободится такой подход гарантирует нам полную консистентность и отсутствие каких-либо состояний гонок для его реализации достаточно добавить редисы сразу увеличить количество планировщиков при старте каждый из них будет ходить в редис и пытаться взять эксклюзивную блокировку работа с базой если у него это получится то он продолжит свое выполнение а если не получится и блокировка кем-то уже занята уснёт и повторит попытку через какое-то время это подход очень легко реализовать и он даже представляет там какое-то отказываю устойчивость но производительность по факту это никак не увеличивает все компоненты в системе будут работать последовательно их общая пропускная способность никак не изменится в сравнении с тем если бы планировщик работал единственным экземпляре и вот это решение нам точно не подходит нужно попробовать придумать что-то еще второй вариант это портицирование я буду рассматривать его как развитие пессимистичного подхода где такая давайте разобьемся наши данные на части сделаем так чтобы каждый компонент мог работать только со своей порцией данных и никак не пересекался со всеми остальными здесь у нас тоже будет полная консистентность Но помимо этого мы еще и получим возможность для честной параллельной работы для реализации нужно разбить всю нашу базу с задачами на части некий партии А каждая задача Добавить новый атрибут идентификатор партиции который будет вычисляться момент ее создания а список всех доступных партий будет храниться в редис при старте планировщик будет ходить в редис рандомно выбирать никем не занятую партицию ставить Лог на ее обработку после этого он продолжит свое выполнение имея эксклюзивный доступ только к своей части данных этот подход тоже достаточно просто реализовать и здесь у нас уже появляется возможность для честной параллельной работы к минусу можно отнести сложность масштабирования Нельзя просто так взять и увеличить реалтаем количество планировщиков если пропускной способности уже существующих нам не хватает для этого нужно заново разбить всю базу задачами на части и только потом наращивать планировщики более того их количество должно строго совпадать с количеством партиций а в идеале как-то превышать его чтобы при потере одного из экземпляров планировщика какая-то спартица начала простаивать и это решение в целом хорошее но мы хотели получить больше возможностей для гибкого горизонтального масштабирования и пока мы его отложили последний подход оптимистичный предполагает что все компоненты в системе работают параллельно вместо предотвращения конфликтов Он предлагает их решать в случае возникновения и первая мысль здесь Давайте тогда вообще откажемся от единого компонента планировщика и перенесем логику работы с базой на сторону локеров каждый из них самостоятельно получает из базы и назначает на себя задачу Это очень хорошо будет наша цель тогда логика работы с базой будет прекрасным масштабироваться по количеству планировщиков Чтобы это сделать нам научиться нужно Научиться решать конфликты по сути ситуации когда одну и ту же задачу пытаются взять работы сразу несколько оркеров для этого Давайте добавим каждому экземпляру в поле наших блокеров два новых атрибута блокира it это уникальный идентификатор и количество задач которые Может взять работу за один свой цикл при старте он будет ходить в базу и в рамках этого лимита пытаться получить список айтишников свободных задач потом он будет пытаться назначить эти задачи на себя по сути просто делать апдейт запрос пытаясь проставить им свой ID в этот момент какой-то другой worker может украсть часть из этих задач поэтому запрос вернет реальное количество документов которые удалось в апдейтить если оно меньше запрашиваемого лимита то у нас возник конфликт для его решения достаточно просто повторить цикл набора задач и делать это до тех пор пока worker не наберет нужное количество задач или пока в базе совсем не закончится свободной задачей Вот только после этого он начнет свое выполнение этот подход тоже дает возможность для параллельной работы Но в отличие от прошлого он приносит еще и возможность для очень лёгкого горизонтального масштабирования чуть ли не в реал тайм минусом можно отнести достаточно высокую сложность реализации в сравнении с предыдущими решениями и лишнюю нагрузка на базу которая возникает из-за необходимости повторять запросы так Пока нет но вообще Мы решили остановиться именно на этом подходе Но прежде чем прикручивать его к нашей системе мы хотели убедиться что это именно то что нам нужно чтобы это сделать мы реализовали прототип и провели нагрузочное тестирование три воркера смогли обеспечить нам пропускной способность 270 тысяч задач в минуту вот при 120 каких-то запредельных цифр получить не удалось и она составила всего 1 миллион задач в минуту такие потери связанные как раз возникновением конфликтов брокеры банально друг другу задачу Зачем приходится повторять запросы в базу у нас это скорость устраивало так как она была на порядок выше того что мы уже имели Давайте посмотрим на то как поменялось наша архитектура с внедрением этого решения у нас полностью исчез единый компонент планировщик логика работы с базой переехала на сторону оркеров и теперь очень просто масштабируется на этом мы с вами решили первую задачу из нашего быклога время переходить дальше следующая наша цель сделать честный рыт-лиметр Если вы когда-нибудь делали свой собственный redlimeter то знаете что есть много разных алгоритмов его реализации я расскажу про Один который мы использовали у себя Называется он сладин клок он достаточно просто в реализации точен и неплохо ведет себя на границах минут его идея в следующем предположим У нас есть какой-то ограничение измеряемая VPN давайте заведем множество размером R по максимальному количеству запросов которые мы можем отправить течение одной минуты в нем мы будем хранить временные метки запросов которые разрешили перед тем как выполнить запрос мы будем ходить в это множество и первым шагом удалять оттуда все временные метки старше минуты если после этого в нем есть свободные места то разрешать запрос и добавлять его временную метку вот если свободных мест нет то мы наткнулись на ограничения и запрос выполнить не может для реализации нам понадобится редис для каждого клиента с настроенными мы будем хранить там собственное такое множество будет ходить конкретного клиента с количеством задач которые он хочет выполнить а тот в ответ будет возвращать количество задач которые может выполнить по количеству таких свободных слотов как и в случае с планировщиком здесь мы тоже Пошли по пути прототипирования и провели нагрузочное тестирование из всех сценариев Я сейчас вам покажу один худший случай когда у всех клиентов настроена очень жесткое ограничение всего в 10 rpm на самом деле это очень мало и скорее всего даже не реалистично но мы хотели вогнать нашу систему в состояние максимального стресса вторая интересная Цифра это максимальная скорость это тот производительность которую мы в теории можем выжить из нашего стенда по сути это просто количество клиентов умноженное на рык лимит мы тестировали три сценария без эмуляции скачивания фотографии то есть по сути чисто работа с базой симуляцией скачивания за одну секунду и за 5 секунд и наши стресс-тест показал что решение в целом рабочее но его пропускная способность очень далека от той цифры которую мы стремились 4000 задач в минуту такая низкая скорость связана опять же с конфликтами если брокер Раньше просто воровали друг друга задачу то теперь они еще упираются из-за чего им приходится лишний раз повторять запросы в базу и в редис и для того чтобы как-то оптимизировать это решение нужно снизить Этот уровень конкуренции между Здесь нам на помощь придет подход с профицированием о котором я уже раньше рассказал Давайте ограничим количество воркеров которые могут обрабатывать одного клиента общий рейтинг клиента поделим между воркерами так чтобы каждый из них работал собственным ограничением Здесь нам на помощь придет концепция распределенного семафора для каждого клиента в редис будем хранить счетчик равные количеству океров которые могут его обрабатывать для того чтобы работать с клиентом worker нужно будет сначала закрепить его за собой для этого он будет ходить в реестр пытаться уменьшить значение этого счетчика А сам лимитер переедет в оперативную память каждого из воркеров И как я уже сказал В нем будет собственное ограничение может обрабатывать сразу множество клиентов Но лишь небольшой промежуток времени по истечении которого он будет отпускать клиенты чтобы с ним мог работать кто-то еще это нужно для того чтобы защититься от падения и от падения и обеспечить равномерное распределение нагрузки после оптимизации мы опять провели нагрузочное тестирование и результаты здесь нас уже устроили мы получили выпускную способность в 19 тысяч задач эта цифра нас абсолютно устроила и на этом мы решили остановиться если посмотреть на нашу архитектуру после этих изменений Это можно увидеть что у нас появился редис который используется для закрепления клиентов заборкерами А у каждого из воркеров появился собственный redlimeter в оперативной памяти ну а мы с вами решили уже вторую проблему и пришло время переходить к последней но не менее важный нам нужно научиться как-то иначе работать медленными фотографиями сделать так чтобы из-за них не тормозила вся система но при этом не теряли контент если внимательно посмотреть на наш контур то можно увидеть что у него попадает около 60 процентов трафика от того который от того который проходит это нагрузка которую очень хотелось бы встретить срезать данные в этом ретроконтере очень разнородные там есть фотографии которые качаются как за пять так и за 30 секунд нужно как-то изолировать медные фотографии быстро чтобы они не мешали Здесь нам на помощь могло прийти мог бы прийти подход разделением трафика по сути мы можем просто добавить новые группы воркеров с нужными таймаутами И завернуть часть трафика в них Чтобы это сделать нужно определиться Какие вообще мы провели такое небольшое исследование и выяснили что 40 процентов всех фотографий успевают скачаться за одну секунду еще 40 процентов успевает скачаться за 5 секунд и только 20 процентов качаются в диапазоне от 5 до 30 секунд пока мы решили остановиться только на этих таймаутах Но вообще хотелось построить гибкую систему куда мы с легкостью могли бы добавлять новые группы брокеров Если возникнет такая необходимость для этого достаточно ввести новый атрибут workertype он появится у каждого из варкеров будет район таймаута который в нем использоваться также он появится и у задач на старте будет равен всегда 1 секунде при попытке скачать фотографию если мы получим ошибку и хотим Повторить попытку скачивания с большим таймаутом мы будем просто расставлять задачи worker Type следующего Пула и она улетит в него такой подход позволит нам отделить медленные фотографии сделать так чтобы они никому не мешали но при нём останется одна проблема фотографии которые попадают в 30-секундные воркеры по-прежнему нужно пройти всю цепочку и чтобы избавиться от этого лишнего трафика нужно научиться роутеть задача сразу в нужной группы брокеров для этого на стороне каждого из воркеров необходимо сделать механизм сбора статистики времени скачивания фотографии и добавить новый компонент krong который будет заниматься расчетом статистики среднего времени скачивания для каждой связки пользователь плюс домен на основании этой статьи статистики мы будем раунтить все новые задачи пользователя сразу в нужную группу воркеров Например если к нам придет клиент с очень медленному хостингом мы накопим и рассчитаем статистику на основе которой Будем пробовать все его задачи сразу в 30-секундные оркеры Но если что-то случится он и хостинг начнет работать быстрее мы пересчитаем эту статистику и будем проводить задачи пулы уже с меньшим тайм-аутом если посмотреть на то Как изменилась наша архитектура мы можем увидеть что у нас появилась новая группа воркеров вообще у нас получилось гибкое решение в котором мы с легкостью можем добавить еще группы если вот этих нам не будет хватать и у нас появился новый компонент крон который занимается расчетом статистики времени скачивания ну а мы с вами решили все проблемы из нашего бэк-лога и самое время подводить итоги после всех этих оптимизаций нам удалось пережить вот этот рост помимо этого мы и еще и обеспечили себе запас прочности на пару лет вперед вообще на пару лет громкости сказано на год точно если помните я вначале когда я говорил простые решения я говорил что всегда должен быть какой-то План Б и вот мы его тоже подготовили и готовы к нему вернуться Если возникнет такая необходимость после того как мы отказались от единого компонента планировщика мы по сути убрали узкое место для масштабирования на уровне архитектуры но когда-нибудь блоки он станет уже наша база банально в неё упремся и Увеличение количества орков уже не поможет а сделать только хуже вот если помните я говорил что подход сертифицированием мы отложили мы к нему когда-нибудь Вернемся и прикрутим его к тому решению которое мы выбрали мы добавим новых железок и шортируем нашу базу тем самым от этого вторая Интересная история это эффективность использования ресурсов если посмотреть на статистику кодов ответов то можно увидеть что от 60 до 80 процентов из них составляют ошибки то есть по сути больше половины всего трафика в системе бесполезно если изучить еще детальнее то мы можем увидеть что значительная часть из них из этих ошибок составляют 403 и 404 это ошибки которые могут месяцами не справляться клиентами потому что например в каких-то категориях нашим у нас можно публиковаться без фотографии и или же клиенты просто устраивает что какие-то объявления не публикуются если клиентам то нам Нет мы видим что Если учесть именно эти ошибки то мы видим что около 40 процентов трафика в нашей системе абсолютно бесполезно это происходит из-за того что мы повторяем пытаемся обработать эти ошибки каждую выгрузку клиента Ну то есть если у нас В текущей не получилось то мы попробуем это сделать следующее и так далее здесь мы пока ничего не реализовали но на стадии переговора с продуктом о том чтобы изменить именно эту логику И от и перестать повторять обрабатывать Эти ошибки от выгрузки к выгрузки вместо этого мы хотим вести такую прогрессивную шкалу которая позволит нам их размазывать идея такая если В текущей выгрузке условили 403 или 404 мы не будем повторять попытка в следующей выгрузки повторим это через попытку потом через две через три и так далее с максимальным делом 24 часа похвастаться Пока ничем не могу но потенциал рассказал это 40 процентов всего трафика который мы можем срезать то есть на ровном месте по сути мы можем получить почти запас почти в X 1,5 ничего особо не делаю и в качестве резюме хочу поговорить о том что вообще нам помогло с таким стремительным ростом справится изначально мы не пытались строить самолеты отдавали пользу предпочтение простым решениям но при этом строили систему максимальной гибкой и готовой для внесения изменений Мы хорошо знали ее запас прочности имели предсказать момент когда его перестанет хватать также мы знали и основных проблемах своей системы и примерно понимали чего мы будем с ними делать и когда и вот когда момент настал мы не побежали бежать и что-то кодить а вместо этого подошли к решению со стороны данных описали новые требования к системе реализовали прототипы сравнили их между собой и потом выбрали то что нам больше всего подходит и на этом У меня все голосуйте за мой доклад А я готов ответить на ваши вопросы а вот теперь скажите мне пожалуйста кому показалось это неправда ты знал очень часто так бывает что волнуешься это не видно поэтому можно просто выступать правда красавчик вопросы раз у нас 10 минут на вопрос поэтому мы должны успеть все в режиме блица погнали можно было достать большим пальцем простой вопрос Вы сказали про мангу и вы используете ее для взятия этих джобов Почему не за использовали pasgress это selectapdate скип локт и соответственно у вас нет проблем с заблоченными записями У меня на самом деле на этот вопрос несколько ответов первый такой спойлер предлагаю обсудить В куларах у нас был когда-то по заказ я готов рассказать очень подробно почему нас не устроил подходить второй менеджерский я руководитель и буду отвечать со стороны руководителя у меня команда экспертов и все все наш сервис автозагрузка использует вся Манга тебе на которую заточены вся наша Экспертиза и вот в основном это такой организационный вопрос на уровне инфраструктуры и каких-то решений серверов Спасибо раз те Дмитрий такой вопрос вот рассказали про один контур да получается у Вас всего вот Вас всего один контур вот этот или у вас несколько таких контуров контуров каких вот вся цепочка которую показывали до обработки тут она одна получается да вот вся то есть сначала до конца именно в этом сервисе Ну да в этом сервисе вообще наша продукция стоит там по моему из 15 сервис они все здоровы Я показывал рассказывал сегодня про один вот это вот вся его архитектура и каких-то еще контуров нету но Здесь не указан просто количество то есть воркеров у нас там несколько сотен вот этот фиолетовый один вон тот синий один он тех фиолетовых воркеров там тоже несколько сотен там тоже десятки То есть если в будущем понадобится увеличение нагрузки вы создадите еще вот еще один такой слой за скелимся Ну то есть мы сейчас знаем Во что упремся и будем решать проблемы Что Ну с тем Во что уберёмся чтобы просто скелить количество кодов и у вас не указано у вас Как на вас реализовано точки балансировки скажем если ну нужно добавить ещё один воркерлинг да то есть получается Если если да да мы у нас в губернете и у нас рекламировать Но у Авито есть крутая платформа пас называется я всем советую сходить на наш Хабар почитать про неё там вот ответы на такие вопросы описаны если вкратце это у нас губернете у нас есть огромная команда инфраструктура которая за это отвечает и платформа которая тебе как разработчику позволяет не сильно думать про инфраструктуру про тепло и про ещё что-то то есть надо заскелиться за скейлишься и вот Так что Ну если что можем там тоже пообщаться или на стенде Авито лучше да спасибо Да друзья ещё вопросы у кого махните рукой вон там уже третий раз отлично сейчас придем пожалуйста Да Привет Большое спасибо за доклад А подскажи пожалуйста ты упомянул про задел под нагрузку А как ты понимаешь Какой у твоей системы задел То есть у вас нагрузочные тесты или вы на тренд нагрузки смотрите роста смысле Это очень хороший вопрос связи с таким ростом мы провели вообще большое исследование насколько Авито готов вот к этой пиле вот я рассказывал что когда-то у нас было 2% всего трафика сейчас 50 если для Авито это ну там рост в полтора раза в два раза то на нагрузка на некоторых сервисы в которой уже мы ходим Выросла не в два раза в 30 40 50 и вот чтобы Понять насколько Avito готов к тому что у нас активно развиваются средства автоматизации которые мы предоставляем мы провели не просто нагрузочные тестирование Мы сначала построили карту всех наших зависимостей определили мы знали по этим зависимостям куда мы с каким FPS и так далее мы ходим мы определили бизнес метрики который на это rps влияют и попытались построить прогноз исходя из этих планов по этим бизнес-метрикам Какая нагрузка в Какие компоненты системы будет а потом уже провели большое такое всеобъемлющее нагрузочная тестирование после этого на нашей карте зависимости у каждой нашей зависимости появилась такая полочка отсечка типа сколько они максимум готовы держать Ну и мы по прогнозам нагрузки по каким-то Real Time графиком можем здесь сделать выводы когда мы в эту палочку прямо всё Ну если стараемся держать её актуальной вот Привет стой стой подожди электронная очередь был с берега вот Привет Спасибо за доклад тут на фейл митайпе звучал интересный риторический вопрос не придумываем ли мы кафку вот на первом этапе Когда вы первые проблему решали можно было рядом с базой данных поставить например кафку и попросить всех воркеров забирать задачи оттуда она как будто все с партиционированием сама бы порешала и остальные дополнительные данные можно было бы ну подгрузить оттуда и не хранить в самой Кафки Ну то есть воркер были в базу знаю что ему забрать конкретно Слушай вопрос на самом деле хороший и я в нем не знаю либо я может идей не понял но по сути можно заменить кафку на что угодно Да там сказать почему не робит мки например или нет не Ну вот база вы продались как-то заставить воркеров не конфликтовать Когда вы данные тут забираете как будто просто можно было воркер Пула оранжевый заставить класть всё в кафку а синенькие забирайте сказки а большие данные уже забирать из базы И никаких конфликтов не было потому что как-то умеет этот автоматически Это я понял Смотри здесь э-э особенность Израиля То есть ты же не просто читаешь это как партицию читаешь ты тебе нужно У тебя есть какое-то ограничение которое тебе нужно как-то решать То есть если в базу Там же у каждого клиента Вот это запрос с лимитом на кафки э-э можем в общем обсудить и интересная идея честно говоря не смотрели нет коротко вот не думали Спасибо будьте добры спасибо наконец-то Вот спасибо большое доклад о реакции Тиньков один из вопросов уже ответил Вот другой спросил И второй вопрос на шестьдесят пятый слайд если переключишься А какой 65 Давай попробуем у меня не Кликаешь Включите пожалуйста 65 слайд вот заработал а вот вот она может попробовать А можете вместо нас 65 слайд воткнуть пожалуйста вот он Смотри оп Спасибо Да вот примерно здесь не до конца понял вот когда worker берет себе Чанг и снижает счетчик Если вдруг воркер упал то кто возвращает счетчик обратно плюс один я здесь упустил многие детали реализации снижает Что случилось Вот я там сказал что worker может работать с клиентом небольшой промежуток времени и там реализована защита так то есть либо он сам когда через какой-то тайм аут идет его увеличивает Либо мы вот эти чанки мы короче когда хочет работать с клиентом в редис Сетелем записывает свой идентификатор напротив этого клиента и там вот с этим работаем по сути эти есть которые протухнет вредите и все вот не стал так глубоко нырять Всё спасибо Спасибо друзья еще вопросы вот сейчас отправляем отправляем курьера к тебе Да друзья еще вопросы у кого еще воркеры едят кафку на завтрак Да пожалуйста Здравствуйте спасибо за доклад Привет вопрос был по поводу статистики И набора во-первых не получится ли Так что каждый воркер когда попытается статистику обновить или пересчитать возьмет и положит ее вот а во-вторых как вы в принципе считаете используете ли вы скорость скачивание или там исключительно по номеру варкера который справился наконец по поводу накопления статистики накопление статистики worker сам эту статистика не пересчитывает он просто замеряет для связки пользователей его домен насколько фотка качается все это сохраняет статистику считает крон и только он раз какое-то время запускается и пересчитывает вообще мы просто читаем пока просто среднее время скачивание для пользователей домена нас пока это устраивает но Может это не оптимально но пока вот очень просто делаем вот так Давай 3 4 спасибо спасибо всем друзья махнись пожалуйста кто сдавал вопросы потому что нам надо вручить мерч со знаниями вот вспоминай очень про очередь пропасть Хороший вопрос Давайте вот да за вопрос про получаешь болит отлично супер тебе тоже памятный приз от конференции молодец двигаемся дальше друзья сначала на экране тех кто потом следующий спикер конференция продолжается в Питере жарко"
}