{
  "video_id": "DJKDTOgSn4E",
  "channel": "HighLoadChannel",
  "title": "Реклама со скоростью света DMP платформа / Сергей Жемжицкий (CleverDATA)",
  "views": 95,
  "duration": 2658,
  "published": "2017-04-22T11:44:35-07:00",
  "text": "меня зовут сергей джим женский с компанией clear data сегодня буду рассказывать вам сказку про то как мы пытались научить дмп платформа отрабатывает сто процентов на запросов на пользовательские профили вот про то чего делали что сделали какие цифры намерили вот начали немножко предыстории наверняка все из вас знакомы так или иначе с экосистем rtb вот из каких компонентов на состоит потом мы расскажем и выясним про то чего же с какими сложностями сталкивались ч но сначала что мы мерили что намерили вот результат которые получили и соответственно какие-то нюансы выводы которые сделали для себя чтобы понимать с такими черри джами приходится сталкиваться в рамках требований каждый нас компонент в этой системе д.б. вот у нас есть картинка на самом деле чё тут показано камин дарует приходим на какой-то от пользовательский на какой-то сайт на какую-то страницу странице есть где-то порядка 100 миллисекунд для того чтобы а триндец были сделать запрос нарекла использовать секретного места про на ней есть вот как эта башня экосистему на самом деле все происходит это ссыпается и сайт платформ которая делает на самом деле одну простую вещь она отправляет предложение нам же взять три мышкам живет аукцион аукцион проводится среди в селе доспешных платформы которых на принятие решения о том интересен ли какой-то пользователь какой-то профиль пользователя на самом деле наш профиль есть 30 миллисекунд и на самом деле дсп на должны чем-то руководствоваться делать ставку на пользователя moto руководствоваться она должна его интересами намерениями возможность с дымом геопозиции пример этого девайса из которого мы пришли вот и все и тогда на самом деле хранится в днт вот слава богу товарищ коллега который предыдущий выступал он рассказал по всяким машинным некоторые на самом деле очень часто там используется и в принципе процессы эти достаточно на наверное не быстрые и в принципе по природе своей платформы поправляли данными она достаточно медленно и но в рамках rtb она должна иметь отличается 20 миллисекунд приблизиться жилище мы встретим лучше все этот при ходящих более чем десяти тысячах запросов секунду вот то есть какова роль дмпп пошли к системе есть куча данных калек стримы влоги партнерские логе какие то свои внутренние давно не все загружаются какую-то огроменную платформ аналитическую наверняка большинстве случаев отелей по вертикали бы какие-то hadoop и хдс и определился колодочные дата базы кассандры вот данный там структурируется как-то обрабатывается считается ровно так как рассказывал предыдущий докладчик вот на выходе получаются профиль пользователя эти профили должны держать они складываются какой тэрнер быстро хранилище данных вот которая способна работать с тем и солей который необходим в рамках экосистему вот яндекс диск состоит чтобы которое называется бёдер которая делает непосредственно те ставки в принципе профиля пользователя необходим этом бибером вот то есть на самом деле хочется получить какую-то такую картинку у нас есть с вопросиками какие-то картинки приложения которые будет ходить из типичный запрос в основном в рамках rtb все происходит ну за их взаимодействие происходит по опыт такого как окажется разработал google и придумал вот чем мы хотим поиметь у нас есть наши какие-то внутренние dlp маленькие либо по крайней мере каждый компонент в котором хранится этот длинный кусок профиля он может быть в рамках одной большой темп и есть внешние поставщики профилей данных у которых мы также хотим получить профиля для того чтобы как можно более полным образом представить информация пользователя который посетил wear страницу у нас есть 20 миллисекунд по истечению которых на самом деле нужно давать ответ в любом виде даже несмотря на то что какие-то запросы могут обрабатываться значительно большее количество времени вот и собственно те кто это необходимо для того чтобы иметь возможность как раз таки обрабатывать сто процентов если 100 процентах ходящий запросов если какой-то внешней дмт тупит то на самом деле мы просто напросто получится таким образом что мы никаким образом не поучаствуем в аукционе за текущего пользователя трафика оплачен вот затем все кто успел ответить все профили отданы внешне и внутренне маленьким какую тандем точками они агрегируется в итоговый профиль вот соответственно как тут чего-то делаться вот наверное для того чтобы научить don't орбит быстро нужно поставить смиренном какой-то носик вал стоящий как бы это хранилище которая удовлетворяет вот тем самым 20 миллисекунд вот чем будем набирать вчера уже рассказывали что про всякие такие вот модные известные слова то есть нашему сиквел должен быть линейным масштабируемым почему потому что большинстве случаев tracking юзеров осуществляется по cookies вот которая периодически x париться естественно никто никогда не знает когда на проект спорится вот когда мы с вами их почистим и мы выкинем нафиг из браузеров из этого в принципе вполне себе шустро объем данных растет соответственно sharding из коробки не хочется опять таки иметь какие-то сложности с поддержкой того решения которые мы выберем не хочется и хочется тратить огроменную кучу времени денег сеула на то чтобы шарды данной ручками вот распределенность она и так предполагается наверное первыми двумя пунктами то есть в принципе в принципе какой-то на сиквел столь в большинстве случае он так распределенный данные должны быть избыточными для того чтобы если что то где то сдохнет или отвалиться никто это не заметил кроме нас и соответственно платформы или все решения даже целиком должно удовлетворять тем самым 27 миллисекундам этому времени вот только вот мы когда столкнулись задачи начали считать реку жестко потому что понимали осознавали что принципе из огромного числа различных морских баз данных однозначно все протестировать не получится и в бою так что же еще не получится вот принципе каким-то ощущениям на то чтобы ознакомиться с какой-то технология более или менее нужно хотя бы наверно на полгода вот если даже знаете на самом деле на сайте который называется кажется носке да это барак там наверно порядка 150 вот таких вот всяких словечек будет перечислено мы начали решили выписывать вот те функциональные требования которые предъявляются носику сторону для того чтобы хотя бы как то представлять еще хотя бы осуществлять выбор масштабируемость рассматривали сандр не все из этих решений мы протестировали но тем не менее посмотрели на несколько из них эти цифры по каким-то и опять таки из этих решений они есть в интернете все про мире госари на тот момент когда мы решали задачу сейчас ведется появляется реальность кластер который на самом деле наверно под в 30 верстах от вращения выпущено вот условно он не может обернуться это вообще точно и приложение хотя очень на шар ник все так или иначе сортируется опять-таки кризис тоже сортируется но руками я но не в последней версии последней версии должен быть закрашивал парик ли кации принципе опять-таки все все обладать такой щит избыточности данных на вот и так или иначе реплицируется уедет это мастер slave с какими-то оговорками с асинхронной репликации под и кусочки данных могут потеряться если мы пациент какой-то профиль пользователя ничего страшного то есть в принципе это не какой-то банкинг не инвестиционный бизнес если тут произойдет ну то есть потеря trance акции грубо говоря на тони сейчас страшно не произойдет во времени отклика все эти решения должен быть на принципе очень круты единая точка отказа от основа редис я сейчас скажу что мы во всём тестер и потому что очень быстрый по требовательности мы подразумевали вот что на потребуется на стены оценивали сколько времени сколько трудозатрат усилий вы идет на то чтобы развернуть решение в продакшен и начинается его саппортить вот и с учетом роста объема данных каким образом его потом сортировать обеспечивать его доступность и так далее мониторинг в принципе это такая на самом деле весьма наверное условная весьма условный сетей наличие графического пользуется интерфейса какого-то для того чтобы можно было управлять но сиквелом вот что в принципе могло бы пригодиться админа а потом мы начали выбирать уточнение начали убирать начали тестировать чего то чего у нас было вот и тонны что он все должно было работать вроде то есть мы не ставили перед собой задачу протестировать носику старриджа для этого есть целый фильм оргиях уж не не ставили задачу выяснить какой из но стекло снаружи круче мы тестировали все ну то есть прототип решения которое мы могли построить целиком с учетом вот таких вот штук чего нужно сказать тут внимательно всегда смотреть еще скрывается под звездочками как обычным хостер который предоставлял такое оборудование на смотря на наличие гигабитных интерфейс об сетевых где-то там снизу на написал что гарантированно если вы гарантированно пропускная способность интерфейса 200 г вот такие дела так как мы проводили тесты мы взяли 200 миллионов записей условных на самом деле предполагали что в целевом решений будет такого 600 700 миллионов хранится взяли средний размер профиля которые предполагали на гриле условно говоря каких-то фейковых место джека 512 байт начали все запускать на 1 по келли simon г-н дженкс тажетдинова мире и смотрели собственный отец это которое получается каждый тест проводился по 5 раз течение трех минут затем выбирался результат с наименьшим временем отклика то есть только тройным в принципе больше всего понравился по сути нагрузку делали кстати шли кемский который называется верка вот по мне себе она работала с максимально возможной скоростью мы ее даже не останавливали tags вот на самом деле все официальные данные которые опять-таки можно найти центр акция по каким-то но сиквел старриджа моделей но опять-таки повторюсь что мы не ставили перед собой цель протестировать отдельным носику сторож чего тут видно тут графики зависимости от то есть триллион сколько вот пропускной способности и чего из этого всего видно и можно сделать вы за вывод по правой половине это то что условно кассандра тупит при чтении ну и начинает потому что она якобы хотим про под под запись но это выводы выводы вот того тех людей про эти графики рисовали вот амунга тупит соответственно при записи лабиринтус мы вооружились не этой литературой но кто хочет может на самом деле взять это все и для пущей прокач настей из учиться за 24 часа мы уверены что он точно стальным каким-то гуру дальше начинаем разрабатывать тестировать взяли джинкс выкинули из него все все все у нас было были четырехъядерных спам поэтому собственно вооружиться булочки и worker of развесили их по каждому круто с каждый маркер помешали поездку на свое ядро а на одном костя у нас желудка который должен сэр джеймс с максимальная скорость с которой только можно то есть верил генерировал максимальный трубу вот engine x при этом никуда не ходил он просто отдавала файлик размер вот этих самых целей у нас обоих ученом мире то есть мы предполагали что imagex будет боязно мем он выдаст но когда он никуда ходить не будет ну или наш софт который мы разработаем менеджеры цели сами нагретая лишком оставим никуда ходить минут ну то есть это воспитание будет вот собственно цен на хейли про мы получили а почему тут пропускная способность этих пакетов пакетах я расскажу на столе жить попозже ну в целом на самом деле наверно очень круто ну или по крайней мере не плохо это то что маска мне выжить один индекс выдавал огласились или запрос в секунду при этом 99 процентов было вот в рамках одна идея миллисекунда перед наверно там для того 300 до 500 микросекунд появился вот петр на самом деле чего под удар еще больший запас оставался вот неважно дальше начали имеет элис потому что он крут развернули его так как нам оказалась бы он работал в против если бы мы решили взять его на одном хотя тот же верка он долбится в джинкс ходит через genesis плагин бредишь вот айда с лазерным следующим образом на опять-таки каждой ноги под 2 мастер instance редиса повешенные так при бензина на свои циpкa вот и опять таки на других картах живут эти цацки если вы будь которые на оставшиеся два ядра повешены в каждый из инстансов где-то там условно 20 миллионов делить на сколько 63 34 миллионов записей заливалась дженкса шар де равале все по ключу джинкс выбирал правильные обстреле просто опять-таки подключим правильном стримы которой которые уже соответственно был ассоциирован с тем или иным инстансами dice а вот чем нас получилось ну да релиз приносили оказался неплох 99 персонаж с упала но на самом деле если смотреть достаточно внимательно то упало она судя по всему из-за того что еще один хоп появился дополнительный и сэм джинкс а вреден вот производительность вот такая то есть принципе результаты тоже неплохие и их бы нам хватило потому что вы обслуживаете самое но та нагрузка которое планировалось по всяким типу выше крыши запасов по сети количество сетевых пакетов которое было доступно то есть на 1 балл способен пропускать хост с индексом и соответственно каждый из эстонцев каждый из трех coast of studies on едем дальше морга решили имеется чуть-чуть тоже поскольку вроде бы как самое ну наверное одна из самых популярных баз данных которые пока я не имеет трендах и которого всех на слуху на взяли тот же врк взяли дженкс ну то есть только на одном хостеле джинкс на другом на том же хостел роутер ангарский нгс в начале это сидел разворачиваться осознали что в принципе развернуться там он где можно но не так проста как другие решения даже для того чтобы хотя бы как это базовый production лайк конфигурация поиметь нам потребовалось развернуть сколько тут около наверно 15 различных процессов и 1513 транс процессах манга sket причем конфиг сервера вообще рекомендует выносит на отдельные хасты то есть но инфраструктура на самом деле наверное будет расти на вопрос не по-детски вот то есть по сути реплика сет это по отдельному инстанцию на каждом из хвостов нет реплика сет является шарда вот начали до пользовали в яндексе манга скилла плагин но тайским джинкс у engine control ну аресте монгол вот начались начальница не очень хорошо но мы-то связываем с чем связан во-первых нам может быть с нашими кривыми руками может быть с тем что у нас пользовался но г-н дженкс а вот но поимели тем не менее вот такие результаты принципе они тоже на самом деле неплохие то есть способен там отвечать за 15 секунд 9995 person силе составлять 15 секунд это на самом деле неплохо вот и циpкa с индексом то есть там был установлен джинкс он вот чуть-чуть свой раз был вырастут благодаря на самом деле большинство в основном благодаря морга роутер вот то есть если тот прикинуть этот прикинуть насколько помню нас ситуация была следующие 45 процентов циpкa вот из этих 70 кидал в ангарске процесса стальной джинкс вот чего поимели поимели мод чего с точки зрения пропускной способности сети для манга мы еще нарисовали локальной сети интерфейс потому что в принципе ну то есть на самом деле мы посчитали что не стоит забивать трафиком а там джинкс команда раутеру на основность в интерфейс и пустили его просто через локальный ну по сути капча товарища рассказывали на первом докладе про sharding на это морга он на самом деле является тем самым прокси между классом и клиент поэтому в принципе мангас плагин процесс имеет ставить смысл вот прям рядом с вашим клиентам который будет туда ходить наконец-то решили память также распайка тоже то чуть-чуть предыстории начали писать плагин на самом деле все пишется достаточно просто не дженкса 4 маркера вот это главное вот теперь сменим взяли рожать развернули на 3-х стах начали смотреть лиц с нашим плагином вот просто офигели когда вы видели эти цифры потому что они оказались очень плохими вот ну пока тебе не то что мы ожидали от вендора от сорта которые там говорит совместно компетенции так далее вот но не знаю тут наверно подсыпал еще сверхъестественным почти все простой с точки зре то в то же самое потом начали еще раз мериться раз парик начали увеличить количество на горке of engine вот чего в принципе минимальный тынц и падает с смотреть на 50 персон вторая колонка максимально она остается на том же месте вот после какого-то количества бургеров принципе пропускная способность тоже перестает расти это это вот rs 5 короче 6 6 дошло ну то есть мы осознали вот осознали чего что выстрелили попали 70 совершенно случайно взяли клиент раз панковский который был блокирующим вот попытались его против мне блокирующий джинкс убили джинкс вот своими руками до начали смотреть 6-го распайки ищем днём оказывается есть клиент который написан с использованием либо event то есть are a spike предоставляет меня блокирующий клиент на ли бы в ленте решили колбасить на нем взяли еще штука которая называется любим этот такой более более на более хороший библиотека грубо говоря которая предоставляет многопоточных этот пышные ну то есть реализации многопоточного страшного сервера по верхней был and для баланса по умолчанию живет на поточных т.п. начали верит снова вот тут мы уже как бы чуть-чуть порадовались на порадовались тому что на самом деле в принципе цифры они сравнимы с редисом который достаточно неплох и достаточно близки вот и в принципе они не совпадают с тем что там не заявлял эндар а вот с точки зрения cited пакетов вот такие картинки очень похоже на то что было увидеться ещё похожие и соответственно сравнение всего-всего чем мы намерили and bass line прочерки там где это 20 ч не было никаких database на редис красненьким хорошие цифры манга тоже хорошему не такие хорошие блокирующая арабский клиент не блокирующий ножницы вообще где-то знаем не в том месте где должен быть и и матирующие принципе сравним каком-то виде здравствуй с матрицы условно говоря мы ожидали что в принципе распай должна быть не хуже чем он декларирует себя то есть мечта личной рельс достаточно быстрая база данных но всех мало вот красным выделен на самом деле два условных победителя по цифрам который мы намерены вот зеленым вывезла инсеем то что мы решили просто дальше не рассматривать вообще а до остановились на распайки вот чем прессует про себя на кроме того что он спасся рисует можно еще сказать что он теперь open source огнем или секунды индексы причем хорошие который работает не через мап редис и и в нем есть еще также пользовательские типы данных на какие-то определился и так далее которыми в принципе для kiwi лью почти никогда не пользуются 5 на вот так вот приблизительно выглядела выглядели те компоненты на которых мы в итоге разрабатывали наш сервис то есть я напомню мы должны были в кучу dlp одновременно каждый из но до 20 миллисекунд успевать к ним сходить потом это все на агрегировать и отдать бедро качестве фундамента легенд или ехать дальше какие-то сервисы там bootstrap логики и так далее вот сервисы по прайсу у каждого из профилей и из на самом деле дмп ростовских это тэпэшки много из поставщиков профиль a2dp профиль пользователя вот если интересно самом деле чё там за кирпичи затылок логирование джейсона джейсон гриб парсинг формирования окон дтп глеб коллекции плюс плюс еще конфигурация про табов транспорт хранения на диалог мимо и пол вот memory пункт для того чтобы просто не заморачиваться с выделением памяти на не знаю то есть на каждый чих выделили один красный запрос потом пользуем этот пол после запроса удалили и забыли про то что где-то условно говоря нужно еще на очистить память вот и графит с точки зрения мониторинга то есть вот приблизительно таким образом были дела наше приложение файлов какие выводы мы для себя сделали нужно на самом деле обращать внимание на не блокирующий и он не пытаться скрестить не скрещиваем и то есть несколько пытаться хороший не блокирующий год пытаться построить как вчера рассказывали взять библиотеку и строится и ожидать что будет хорошо дамы на самом деле на эту граммер наступили все что можно сделать на камеру нужно обязательно делать на калина тут вот какая история с этим делом мы отсылали все метрики графит на каждый из запроса в принципе тренировалась в 5 да наверно 20 метрик различных то есть у нас было порядка пяти внешних дмп которые плохо ттп давали плюс несколько внутренних ну то есть на самом деле это таблички в и распайки если все посчитать хорошенько при 200 тысяч запросов на каждый запросов по 15 20 метров grapher цию сколько 150 200 тыс графит возражал против таких вот нагрузок не по-детски вот и мы начали делать при до двигаться каждый из метрик то есть раз там секунду ли 1 5 секунд берем собираем метрики то есть и собираем просто накапливаемых и флашем графит вот нужно быть ленивым потому что когда мы разрабатывали свое приложение на либо вентилем ехать дпм и уже представляли чего из себя представляет тян джинкс и очень много идей посмотрели и посмотрели в нем и стырили вот это те же не mare pool и это плагин ная система то есть мы в принципе точно так же могли подключать какие то ну то есть на уровне как бы статике подключать внешние днк то есть каждый раз пересборка мы соответственно ником америками задних официальным данным не даже самим себе вообще когда вам нужно чет померять можно мерить самостоятельно именно в рамках то инфраструктуры на тех компоненты тех целевых решений и просто тех решений которые вы собираетесь применять при разработке ваших систем вот но собственно тут наверное все меня есть еще пару минуток и я готов ответить на вопрос . расти большое спасибо за доклад а aerospike же двухуровневая база данных дату на стены в памяти хранит и на диске для ну то есть у него там radice редис памяти только вот когда вы делали тестирование у вас собственно профили но в одессе понятно не были в памяти а в распайки они где были мы старались поставить насколько это возможно все базы данных в одинаковые условия то есть мы его распайки это все дело держали тоже в памяти у него есть не только в ну то есть он не только гибридный там сторож когда охранник какие-то данные на ssd условно и какие-то в памяти мы в данном случае загрузили в память чтобы как бы не имеет тех сайт эффектов которые были бы связаны с хождением дополнительно на диск то есть мы просто решили посмотреть а насколько себя хорошо пойдет то или иное решение вот в нашем продать нам приложение нашим softy а вот такие же исследования записью вы не проводили то есть это вы чтение проверь это чтение записью тут интересный момент мое дело в том что ожидали что в принципе в принципе в 95 процентах случаев база данных будет нагружена на чтение записи это просто обновление каких-то данных на вот периодическое и эта тема следующего доклада спасибо здравствуйте кого линтон компания там так я увидел наши графики что очень приятно в прошлом году мы выступали с похожим докладом где мы как правило сказала докладчик тестировали субд и не только на чтение но и на запись вот поэтому есть кое-какие вопросы первый вопрос да показалось мышка странным что aero спать первую себя позиционируют как очень быстро работаем с сдм мы прям супер быстрый ssd и было очень странно что вы не проверили как раз ту работу ну и сравнить на прям как тот же regis пример может работать с ssd или манги так далее теперь вопрос и второй вопрос и я могу ошибаться но в вашей специфике нет такого кейса что к примеру у вас есть кластер какая там и начинает отваливаться и посмотреть влияние такой ситуации на в целом весь кластер потому что когда наших исследованиях мы как раз политики случае и было заметно что примеры тот же я уж bass у него падает общая скорость кластера начинаются расти задержки начинает расти дивятся и так далее то есть были такие исследования спасибо за вопрос на самом деле про графики распайка значит взял ваши графики но либо вы вместе с ними как-то сотрудничали потому что мы если честно язык не презентации взяли на графике по то есть по зависимости между трупу там леденцы с точки зрения того будет ли какие-то зависимости между тем когда данные хранятся на sd и просто именно моей мы к сожалению не успели провести на виду ограниченное количество времени и денег ресурсов вот но тут какая история на самом деле в принципе чего говорит are a spike они ssd пользу как linux у девайс с directx api все остальные товарищи ну то есть они могли пользоваться просто как не знаю как через обычные файловое и а и на там все таких исследований не проводили опять-таки ну потому что чего rides a memory манга по большей части той же in memory вот это для распайки эту вещь оставили в качестве дополнительного бонуса просто из-за того что понимали что вы сможем воспользоваться еще и вот сущее того если нам не будет хватать trama мы сможем воспользоваться хранением данных на ssd с точки зрения отваривания одной из над тут история следующий на самом деле все ну то есть большинство из систем которые рассмотрены кассандра ольга каждый сэра спайк они просядут по производительности во время отваривания одной из нот потому что ну то есть и если идешь простой бит потому что начнется и sharding то есть начнется миграция данных из отвалившийся ноды на по тем анодом собственно которые остались живыми если ее включить назад начнется обратная миграция данных и в принципе в принципе тут нужно посматривать чтобы они не отваливались я вот-вот что могу сказать то есть понятно что проседание по производительность будет да ну спасибо вам то что вы в прошлом году за нас это протестировали здравствуйте три вопроса во-первых в одной из ваших первых съемок была нарисована 30 миллисекунд между ссп дсп если женою самой первой сейчас вот да там 30 хотелось бы узнать собственно откуда взялась эта цифра потому что из всех ссп допустим с которыми работаем мы самые строгие так сказать ограничению гула у них 100 миллисекунд у всех остальных больше это вопрос номер один вопрос номер два вы рисовали графике собственно загрузки по сети почему не использовали для коннекта к базам данных unix сокеты и вопрос номер 3 в редис 3.0 обещают много классных крутых штук которые называются родис кластер и так далее и тому подобное смотрели ли в их сторону пробовали ли и собственно если какие-то мнения по этому поводу спасибо я пожалуй начну отвечать с последних вопросов registry он насколько мне известно собирается релизиться только вот вот вот вот поэтому нет не смотрели потому что не успели потому что он ещё не завели жан-клод уже сейчас на решение это полгода год назад дальше с точки зрения unix сокетов можно было померить но не мерили вот почему потому что на самом деле все это дело живет ну то есть клиент к распайку он есть один то есть какая-то основе дней некой распаковка любой из донбасс вот они живут на своих холстах принципе не обязательно можем быть только ну то есть клиент опять таки для того что масштабироваться может быть установлено точно нот вот с каким нибудь балансировщик am перед ними и собственно поэтому просто те цепи но и на самом деле я думаю выиграли бы что-то но немного то есть тех цифры которые мы увидели их было достаточно с точки зрения они на помните первый вопрос 30 миллисекунд это щадящий перед нами то есть восстал нас 30 нет ни гугл нам говорят 30 те товарищи которые но на самом деле смотрите картинка она вот мы на самом деле между ссп дсп но пусть там вашем случае сторону мы вот этот красный квадрат активизировали но это может быть на самом деле многом и вот со стороны со спреем на самом деле дни с одной как бы не работали вот и все но согласитесь что 30 лучше чем 100 важно здесь удачи вопрос если никто не прочь спасибо сергей александр петросян компании телегин я хотел спросить у вас на одном из слайдов нарисован грудь без такой весь зеленый во всем столбцы но почему-то вы про него не рассказали это первые простой такой вопрос да потому что условиях но то есть я могу рассказать вам почему вот я пожалуй так отмечен хорошо тогда следующий маленький вопрос очевидно с тех пор как вы выбрали это решение прошло уже какое-то время такой же у вас даже презентации замечательно очевидно вы какие-то в практике наработали что-то хорошее плохое про aerospike в реальной жизни она скажет день пару цифр сколько запросов в секунду скобках что чего бывало интересного так на меня смотреть с точки зрения опять-таки сопровождения ли ещё чего-то моего вот единственный момент до который с которым как как бы нам пришлось столкнуться он связан с чем с тем что в принципе нужно опять-таки внимательно читать документацию и обращать внимание на то что пишет мелким шрифтом трудности с которыми мы столкнулись это то что распайка втихаря ну то есть у него на самом деле есть свои ограничения это не духи montale ты стоишь которые можно хранить документ любого размера у него насколько я знаю размер одной записи там что-то около 128 килобайт все остальное нужно условно горящие из пользовательские типы разруливать на потом с точки зрения жизни в продакшене вот у нас есть случае живет там наверное распайки порядка 600 50 миллионов записей на на 64 гигабайта памяти но то есть там на самом деле пользуется ssd и с точки зрения даже размера ключа этой памяти уже начинает не хватать раз пока размер ключа 64 байта с фактором репликации считаем что на каждый но это будет там по 128 условный под ключ вот распайка есть такая штука называется high water марки по достижении которых он начинает просто самый вик нет никого не спрашивая записи с минимальным значением то тель ну то есть не с минимальным рассказал с минимальным на текущий оставшийся момент времени то есть в принципе мы ожидали что мы туда чет положили с отелем там 5 и эта штука умрёт через пять если памяти не хватает она может умереть если кто то есть моделям 6 то вот это вот то что мы положили 100 делим 5 он умрет тут же вот и такие вещи нужно мониторить как бы отслеживать с точки зрения как бы саппортов вроде я могу сказать что как бы каких-то вот супер пупер телодвижений мы не предпринимали у него есть опять-таки скрипты ну сами а распаковки 1 peg овцы разработали скрипты которые пушат это все графит нужно просто внимательно посматривать затем прошел нами и просто либо хостов подкидывать либо памяти в этом в табличке возле в колоночки которая относится к радису есть и минусик напротив сортирования если мне память не изменяет то что повинуясь такая которая называется твоим прокси которая позволяет повесить редис на любое которые мы хотим количество портов и по любому из этих 10 портов получать ответ собственности для этой базы данных пробовали ли ей если да то чем не понравилась вот к сожалению не пробовали сожалению не правы спасибо хорошо работает вы пробовали здравствуйте меня зовут алексей харламов компания говорит dynamix у вас указано достигнутое значение пропускную способность порядка тридцати пяти тысяч запросов в секунду до это был составной запрос 1 или это было 1 детки и белье и второй момент размер вэлью значения размер эллипса 12 байт запрос не составной почему такие цифры потому что нужно читать то что написано мелким шрифтом вот к сожалению хостинг-провайдера не позволял нам почему-то мысли начали бороться но так не добавились потому что проект заканчивался от те цифры которых мы намерили их было в принципе достаточно вот не позволял пропустить больше чем там условных 75 тысяч пакетов вот спасибо"
}