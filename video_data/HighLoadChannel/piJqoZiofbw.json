{
  "video_id": "piJqoZiofbw",
  "channel": "HighLoadChannel",
  "title": "Высокодоступный MySQL на конвейере / Дмитрий Смаль",
  "views": 105,
  "duration": 2964,
  "published": "2023-10-06T07:24:30-07:00",
  "text": "Всем привет ещё раз Меня зовут Дмитрий Я занимаюсь разработкой менеджмент mysql в Яндекс облаке И не только но сейчас мы будем говорить именно про mysql в начале презентации Обычно нужно контактировать с аудиторией вопрос за Кто считает что постгры лучше чем Майская или поднимите руку Что за люди а кто считает что лучше уже пойти и поесть бургеров выпить пиво не Ну даже даже так не проходит но смотрите на самом деле то что я буду рассказывать оно очень похоже и для постгаса и для майскойля предыдущий доклад был очень Хардкорный этот доклад будет промахиваясь по кликеру этот доклад будет практически специально под этот доклад Мы за Open Source или утилиту которая помогает нам обеспечить высокую доступность myscale в Облаке ее выложили на github Вы можете прямо сейчас посмотреть github.com Яндекс и можете поучаствовать в развитии по сути доклад будет Про какие про то какие проблемы есть возникают при эксплуатации баз данных в Облаке и про то как мы их решаем для начала что у нас есть какой инсталляции мы говорим У нас есть две инсталляции с mysql одна из них внутри Яндекса для проектов самого Яндекса она поменьше это 600 терабайт данных Примерно там около 500 кластеров 1000 хостов и кластера очень разные то есть ну кажется что в каждом классе два Хоста Судя по соотношению ростов-кластеров на самом деле это не так есть тестовые кластера с одним хастом есть кластера в которых 15 реплик и они очень разные и у нас есть еще внешняя инсталляция в Яндекс облаке Где находится кластера наших клиентов и там больше кластеров То есть это такое количество когда их уже невозможно администрировать руками То есть их можно там чинить по некоторым случаям но понятно что их просто слишком много чтобы обслуживать их руками Тем более что происходит некоторые вещи которые на которые нужно реагировать по сути дела есть два разновидности событий Первое это некоторые ожидаемые вещи которые иногда случаются о которых мы знаем более-менее заранее Ну к ним можно отнести учение в data-центрах в Яндексе периодически закрывают полностью один дата-центр Firewall становится недоступной об этом мы знаем там ну грубо говоря за месяц на самом деле даже раньше бывает плановые работы на гипервизорах то есть когда мы понимаем что гипервизор нужно чинить либо на него Нужно обновить ядро и все все базы которые работают на данном гипервизоре нужно куда-то увести Но это мы тоже знаем заранее Ну и плюс клиенты могут захотеть обновить например mysql сделать что-то какую-то операцию при которой база данных перезагружается длительное время во всех таких случаях нам нужно заранее переключить мастер с одного Хоста на другой при этом это нужно сделать с минимальным даунтаймом и в автоматическом режиме то есть без участия дежурных а есть сценарий неожиданные те которые происходят без предупреждения это разного рода поломки может ломаться самое банальное это железо то есть там память диски гипервизоры падают это происходит довольно часто Ну фактически там ежедневно какие-то машины уходят а также может ломаться сеть причем сеть может ломаться очень интересными способами это наверное самое хитрая вещь и не все из этих способов мы можем обработать Ну и к тому же в маске или довольно большое количество багов есть некоторые из них проявляются сами по себе некоторые проявляются под нагрузкой То есть клиент может постараться и уронить mysql вполне В таких случаях мы не можем отреагировать заранее нам нужно каким-то образом определять живость кластера и делать переключение собственно говоря мастера уже постфактум когда что-то случилось а фактически фактически когда мы говорим про облако мы как бы живем на вот на таком Вот в такой игре полото лава у вас тут есть небольшие там островки вы на нем стоите некоторое время а потом вы понимаете что нужно срочно перейти на другой а потом на третий и вот так по вот этим островкам переходите если вовремя не перейдете ваш кластер утонет и сгорит вот в таком окружении где постоянно у нас уходит железо Мы хотим достичь Вот таких вот параметров то есть ну Циферки я взял из наших предыдущих презентаций довольно большое количество девяток на чтение Чуть поменьше девяток на запись и главное наверное чего мы хотим добиться это Спокойный сон дежурного чтобы нам не приходилось руками решать проблемы чтобы это все происходило автоматически а как это можно сделать То есть для того чтобы mysql существовал в такой нестабильный конфигурации когда постоянно ломается железо и происходит прочие радости нам нужно автоматизировать некоторые вещи есть сценарий минимум и есть еще желательный набор в обязательном порядке нужно сделать автоматику для трех вещей switchower Switch Over это как раз плановое переключение когда все Хосты кластера Живые и мы хотим переключить мастер с одного хаста на другой это может кстати сделать и пользователь то есть сам попросить переключить мастер это может сделать автоматика У нас есть специальная автоматика которая общается с внешним миром у нас системой которая управляет железом называется cms кластер менеджмент System и вот эта автоматика она может тоже переключать сервера например переключать мастера перед учением дата-центра второй сценарий это файловер Это то же самое но только когда у нас происходит какая-то авария И третье нам нужно уметь переналивать старые мастера Вот это просто Маст хэв то есть в большом количестве случаев после переключения мастера старый мастер Он портится его больше нельзя Он может просто физически сломаться там может не остаться данных а может получиться Так что данные не консистентные его нельзя вернуть в строй То есть он не сможет стать репликой его нужно переливать Желательно чтобы переливать можно было не с другого Хоста А из бэкапа то есть желательно делать периодические бэкапы Желательно чтобы у этих бэкапов был Point in Time Recovery тогда мы сможем наливать новые Хосты не повышая нагрузку на кластер Но это такой опциональная Вещь и еще одна вещь кроме переналивки это какая-то интеграция сервис Discovery То есть у нас мастер переключается туда-сюда с одного Хоста на другой мы должны проекту как-то дать знать об этом в случае с пазгрессом клиентская библиотека сама умеет определять кто сейчас мастер подключаться к нужному случае с mysql для этого используется либо какие-то там консулы Либо мы используем просто DNS запись которая указывает на текущий мастер а когда Мы начинали запускать myscale мы посмотрели какие есть решения самая популярная github архистратор с ним С ним Мы разбирались довольно долго это то что используется github Это прикольная штука но у нее Было пару недостатков ipv6 не поддерживался и во-вторых это такое центр управления полетами он вот хорош Когда у вас там пару кластеров вы их администрируете вы их очень любите их всего Там две штуки и вы за ними руками следите вот он вам помогает Но сами кластера могут быть довольно сложные когда кластеров много им пользоваться крайне неудобно кластер Control он был платным сейчас платный и были разного рода утилиты например вот лабилити это такая штука написанная на пирле которая тоже умеет в принципе делать все то же самое что делает my sing но она предполагает наличие некоторого выделенного Хоста То есть вы как бы у вас есть Хосты с Майской лиме и у вас есть какой-то холст на котором вы сидите администрируете и вы предполагаете что вот этот хост авария не затронет то есть там Майская ли могут падать А вот этот ход останется жить и вы с него будете там администрировать свою систему для нас в Облаке выделенные Хосты Это очень неудобно очень намного лучше чтобы весь код он работал вместе с вот самой базой данных а поэтому мы решили написать утилиту которая называется mysing который мы сейчас обсуждаем и которая решает вот все озвученные проблемы Итак давайте поговорим про архитектуру как это выглядит а для того чтобы для того чтобы вот эти сценарии переключения переливки они работали на большом количестве кластеров нам нужно следовать нескольким принципам первый принцип это все Хосты внутри кластера они должны быть эквивалентны кластер гомогенный зачастую делают майские кластера таким образом что у них есть какие-то выделенные Хосты Там специальный большой хост для бэкапов всего есть хост куда сливаются разные репликационные потоки есть таблицы которые только на одном Хосте потому что на других не нужно вот это все не работает мы говорим что у нас все кластера они все все Хосты кластер они совершенно одинаковые и взаимозаменяемые второй принцип все операции над кластером они должны быть импотентны то есть если утилита что-то начало сделать ее прервали это не значит что вы должны идти чинить руками перезапуск операции должен чинить проблему и третья вещь Мы хотели бы все это делать без потери данных потому что мы не можем за клиентов решать там можно ли потерять какие-то данные или нет а окей теперь немножко про архитектуру моя сила представляет собой демон который работает рядом с базой mysql вот у нас здесь есть три Хоста Праймари две реплики и рядом с майскилем запущены мои симки а что здесь нужно отметить мы используем еще одну вещь которая называется dcs dess это внешняя по отношению к кластеру базы которая обеспечивает хранилище такое устойчивое сетевым сбоям у нас это за Кипр в принципе Можно прикрутить наверное CD благодаря этому хранилищу мы не Решаем проблему с распределенными транзакциями мы не хотим реализовывать никакие рафты и паксосы внутри массинка Мы хотим чтобы это было реализовано снаружи мы используем внешнее хранилище среди майсинков один в каждый момент времени один является главным мы его называем менеджером этот менеджер процесс он отвечает за управление кластером то есть Выполняет все операции тот который остальные просто отправляют состояние здоровья они опрашивают который находится рядом с ними и отправляют в Кипер статус здоровья а причем и менеджер держит Лог и вот эти статусы которые содержат описание здоровья кластеры они тоже являются локами Что это значит Лог зу кипере называется фемерная нода это некоторая запись которая существует пока есть соединение за кипером то есть менеджер пока он подключен к экиперу он может держать Лог если например Машина на которой работает менеджер она как-то оторвалась от сети пропала сеть пропадет И первое что произойдет это менеджер станет другой mysing то есть они соревнуются за роль менеджера И один из них всегда становится менеджером а то есть мы здесь видим что нам не требуется грубо говоря отдельная внешнее железо у нас софт который переключает обслуживает кластер он работает прямо рядом с самим кластером это нормальная ситуация что у нас допустим менеджер и Прайм ренода находится на разных узлах это вполне себе Окей Окей теперь давайте рассмотрим как происходит процесс переключения мастера процесс принципе Довольно простой что мы делаем если мы хотим переключить мастер первое что мы делаем Это переводим все ноды кластеров состояние редонли это нужно для того чтобы мы могли как-то сравнить и понять кто из них впереди нельзя сравнивать кластера А если в них продолжается запись Сначала мы просто отключаем процесс записи А кто может сказать в чем здесь проблема Кто знает в чем проблема перевести кластер а я знаю кто знает да ребята понимают проблема в пользователях они туда пишут и они могут писать очень длинные транзакции но об этом чуть позже Окей перевели кластеров Red Only останавливаем репликацию это нужно для того чтобы у нас реплики не меняли свои позиции то есть после этого мы выбираем лучшую реплику тут есть небольшой подвох лучшая реплика это по идее Таны который самые свежие данные но В некоторых случаях Мы хотим выбрать какую-то определенную конкретную то есть мы хотим переключить мастер вот на ту реплику хотя она не самая свежая В таких случаях нам нужно ее еще подождать пока она догонится и станет самой свежей Ну после того как она догналась стала самой свежей все остальные поворачиваются на неё мы ее промоутим она становится мастером и дальше мы обновляем записи в ДНСе и запись в общем-то все то есть здесь очень тонкий момент в том что вот этот сценарий он и демпатентный то есть его можно прибить в любом месте то есть прервать потом перезапустить и он опять придет в то же самое состояние то есть его не нужно будет чинить вот этот процесс его довольно долго отложили это мы поговорили про переключение свечовер когда все хорошо когда мы говорим про фейловер то возникает еще одна дополнительная проблема нам нужно проверить решить принять принять решение о том что вот у нас мастер каким-то образом сдох это кажется просто то есть ну вот взял Да проверил на самом деле это нетривиально потому что Существует очень много разных способов каким какими мастер становится неработоспособной мы здесь были вынуждены просто выбрать некоторую модель которую мы обрабатываем модель Такова наличие сети мы проверяем по наличию соединения за кипером то есть Пока хост держит соединение мы считаем что у него есть сеть мы считаем что кластер Майской лежит если он отвечает на Select 1 все это некоторая модель но есть 99 способов ошибиться файлы с тема может перейти в ритон для mysql может не упасть То есть он как бы он не работоспособен но на Селект Один он отвечает а он может быть перегружен настолько что у него там tcp соединение в течение минуты устанавливаются у вас может быть проблема с dcs то есть вас может как бы кластер нормально работать азу Кипер просто сломался У нас были прикольные ситуации когда текущие соединения все работали а новые не устанавливались вы понимаете что такое Для клиента когда они устанавливаются новые соединения он не может подключиться к базе репликация работает репликация старые соединение соединение с гипером работает mysing там пишет что все нормально там все живые но так некоторые проблемы не обрабатываются Да такое есть еще интересные интересные случаи был когда мы ошиблись и неправильно Разместили зубкиперы по дата-центрам То есть по-хорошему когда когда вы проектируете вот этот dcs вашу базу которая обеспечивает устойчивость повреждениям сети вам нужно Если у вас есть три нода зу кипера их расположить по разным дата-центрам у нас получилось так что две ноды оказались в одном дата-центре это дата-центр оторвало от сети но поскольку там находится Две ноты они обеспечивают квору для звуки пера тот кто находился в этом оторванном дата-центре продолжал считать себя мастером То есть это Мисс конфигурейшен с которым мы боролись руками такое случается а ну я не Уэй то есть вот есть такая модель Так мы проверяем состояние мастера когда мы решили что мастер каким-то образом перестал работать мы делаем еще некоторые дополнительные проверки то есть мы проверяем что А если все реплики все-таки с него реплицируют то наверное Он все-таки жив где-то какая-то другая ошибка то есть там есть большое количество дополнительных проверок прежде чем мы решим что мастер сломался Таким образом мы Решаем проблему с фрейловером А теперь Хотелось бы поговорить как мы не теряем данные а как на самом деле показала практика мы слишком бережно относимся к данным и клиент клиентам чаще довольно как бы менее важно что их данные не потеряются но тем не менее для того чтобы не потерять данные используются синхронная репликация Как это работает Как работает вообще репликация в маскеле То есть вы выполняете транзакции на Мастере они записываются в бане релог bine relock передается на реплику там он называется жерелей Лок реплика выполняет изменения а что делает синхронная репликация это специальный плагин который запускается на Мастере на репликах и он не позволяет майскойлю ответить вам Окей То есть когда вы закамителю транзакцию прежде чем Майская или вам ответит Окей он дожидается что вот эти данные в байно-релогии они физически доехали до реплик и после того как данные записаны на реплике Москве вам отвечает Окей то есть так работает синхронная репликация это выглядит просто но на самом деле есть нюансы то есть обычно все думают что можно просто включить у вас будет надежно смотрите вот этот слайдик наверное о нем можно остановиться поподробнее он такой как бы про науку но чуть полегче чем предыдущий доклад поэтому Давайте его разберем смотрите у нас есть распределенная система из N узлов мы записываем данные на какое-то количество узлов и читаем данные с какого-то количества узлов вот как должны эти цифры соотноситься чтобы мы гарантированно читали актуальные данные если мы допустим у нас есть N узлов и мы записываем данные на W узлов то отчитаем данные с R узлов мы читаем Это значит что мы как бы вы опрашиваем R узлов и выбираем самые актуальные среди тех что запросили так вот есть такое утверждение W + R должно быть равно Ну либо больше чем N плюс один То есть множество узлов на которые вы пишите И множество узлов которых вы читаете они это множество оно должно быть как бы покрывать ваш кластер в случае с My SQL Ну и спазгрессом R Это конечно не количество узлов из которых вы читаете количество узлов среди которых вы выбираете нового мастера а W это количество узлов на которые гарантированно записано транзакция в случае с mysqлем у него есть такая настроечка РПЛ семи Синг мастер Wave Это количество реплик А количество W оно будет на единичку больше давайте рассмотрим на примере вот у нас есть кластер из шести хостов которая находится в трех дата-центрах мы читаем читаем так скажем давайте начнем с того что мы записываем данные понятно что в Мастер и плюс у нас есть настроечка что мастер ожидает одну реплику Сколько реплик нам нужно для то Сколько реплик нам нужно поиметь живыми после инцидента нет Если у нас есть Мастер и он еще ожидает одну реплику то же время нам нужно иметь 5 Ну 6 всего W у нас 2 соответственно R должно быть 5 то есть после инцидента должно остаться живыми 5 реплик для того чтобы мы не потеряли данные очевидно что в таком случае мы не переживаем падение дата-центра Потому что при падении дата-центров живых остается только 4 А поэтому в такой в такой конфигурации Когда у нас шесть кастов 3 Вот это центрах мы должны как минимум ожидать записи двух реплик чтобы достаточно было иметь четыре реплики и тогда мы могли бы переживать падение дата-центра фактически вот эта настройка РПЛ семи сингх бла бла она показывает Какое количество Мы можем потерять хостов То есть если мастер дожидается одну реплику Это значит что в инциденте Мы можем потерять один холст если дожидается двух реплик означает что в инциденте Мы можем потерять два Хоста и не потерять данные а вот я вам советую запомнить эту формулу как бы она полезна при проектировании распределенных систем как бы как самая базовое представление В чем сложность так это немножко рано В чем сложность управления семисинхронной репликацией синхронной репликации в том что Хосты могут уходить то есть у вас может сломаться не мастер А какая-то реплика при этом настройки нужно поменять так чтобы мастер ждал меньшего количества реплик иначе он просто как бы остановится А вот следить за набором синхронных реплик - Это довольно сложно и в массинке это сделано аккуратно и протестировано с помощью japson тестов то есть тесты которые вот ломают кластер и при этом Потом проверяет что данные не потеряны Окей давайте теперь перейдем к дополнительным фичам которые есть мои симки Ну просто полезные штуки А есть поддержка каскадной репликации и приоритетов Что такое каскадные реплики это вот немножко плохо цвета вижу это синие те которые реплики второго уровня реплики реплик зачем эти штуки нужны это ну собственно говоря мы делим Хосты кластера на два вида Мастер и высокодоступные реплики ха они вместе образуют группу и это те Хосты которые теоретически могут стать мастером и каскадные реплики каскадные реплики никогда не могут стать мастером на них работает асинхронная репликация то есть реплики в классическом смысле они нужны для бэкапов они нужны для аналитических запросов Вы можете там гонять любую нагрузку и не переживать что туда попадет Мастер и они нужны для того чтобы проще обеспечивать кворум У нас например есть хороший пример у нас а в Яндексе 3 дата-центра основных есть разные кластера у которых 15 хостов там ну грубо говоря в кластере вот Давайте попробуем разложить по трем 15 хостов и посчитать Как должна быть достроена настройка чтобы мы не теряли данные То есть если нас 15 хостов трех дата центрах мы должны ожидать подтверждения от 5 реплик это очень медленно то есть при синхронной репликации удобно делать Вот так мы делаем небольшую группу А все дополнительные реплики которые обслуживают нагрузку мы делаем каскадными а my sing соответственно поддерживает топологию и исправляет ее по необходимости есть такая штука Как приоритеты Там есть написано Циферки смысл следующим Когда мы можем выбрать куда переключать мастер my sing выберет наиболее приоритетную это сделано для того чтобы мастер не попадал в какие-нибудь нежелательные дата-центры там на старое оборудование и что-то такое это возможность выбрать приоритеты при прочих равных Если получается так что приоритетная реплика сильно отстает по каким-то причинам будет выбрана актуальное есть режим мейнтейнанс это очень простой режим который фактически временно отключает автоматику отключает синхронную репликацию и mysing не делает никаких изменений режим мейнтенонс нужен для очень простой вещи Он для того чтобы руками что-то починить или мы его отключаем в процессе модификации кластера когда другая автоматика там апгрейдит mysql его переключает чтобы не конфликтовать следующий момент последний сценарий который нам нужен это переналивка реплик my sing не занимается переналивкой потому что это этот сценарий он зависит от окружения то есть в разных окружениях он может быть реализован по-разному но у нас есть такое простое соглашение если my sing понимает что реплика не актуальна она покорявчина он ставит специальный тач файл То есть просто вас на файловой системе появляется стать файл и вы сами пишете скрипты которые каким-то образом перенальют данную реплику все после того как реплику он удаляет Файлик она считается перелитой массинг ее возвращает в кластер а то есть это на вашей совести как переливать реплики что мы имеем в результате если все идет хорошо то есть все работает Just esplano то у нас происходит довольно быстро и свечой ртом 10-20 секунд этот запасом на ненагруженных кластерах может быстрее происходить и Flower там одну-две минуты причем большая часть времени файловере это специальные ожидания на случай что оно вдруг если мастер все-таки успеет очухаться перезагрузиться восстановиться Просто такое дело небольшой при этом переключение происходит без потери данных и мы умеем последовательно деградировать То есть если у нас там есть три Хоста мы можем последовательно пережить две аварии сначала переключиться на один хвост потом там на второй а но но все можно испортить то есть грамотное использование mysql или неграмотное может все сломать что плохого Может сделать пользователь самое плохое что может сделать это делать большие транзакции вообще в ЛТП системах не надо делать большие транзакции транзакции должны быть маленькими после еще это не так не так плохо в Москве или это плохо потому что большую транзакцию тяжело прервать Если вы делаете свитчовер А у вас бежит какой-нибудь там апдейт часовой уже час бежит вам нужно что-то с ним делать все что вы с ним можете сделать это вы можете сделать Килл то есть прервать транзакцию но она не остановится она начнет откатываться еще час будет откатываться не делайте большие транзакции вторая проблема которая может Создать пользователя это отстающие реплики но здесь все просто если мы хотим сделать фейловер на отстающую реплику Нам нужно будет подождать пока она догонится соответственно вместо 10-20 секунд обещанных это будет там то время которое она догонится Чудес не бывает Ну и плюс можно неграмотно настроить mysql Так что так скажем он будет падать чаще но мы будем разумными мы не будем делать плохо Мы будем делать хорошо небольшие без практики того чтобы это как-то работало вам нужны Таблицы с первичными ключами желательно с компактными синтетическими там первичными ключами которые маленькие в таблице должны быть индексы и все запросы должны работать более-менее по индексам мы загружаем данные небольшими транзакциями если нужно загрузить много Грузии маленькими чанками это Окей и мы не делаем больших альтеров если нужно сделать большой Альтер мы используем Вот например из перконовская утилита онлайн схема change либо что-то делаем свое там на триггерах В общем чтобы это тоже не было большой транзакции синхронной репликации большие транзакции работают особенно плохо Ну и вот некоторые настроечки Как хорошо было сделано чтобы их не видите чтобы репликация репликация работала чуть побыстрее что тут можно сделать можно включить параллельную репликацию она действительно ускоряет процесс можно включить репликацию на основе logical Clock а когда у вас маленькие независимые транзакции Они будут на репликах исполняться параллельно можно включить параллельность аппликацией на основе в райцентов тоже еще чуть Будет побыстрее но тоже не панацея Так давайте перейдем к завершающей стадии как это попробовать то есть проект мы выложили Open Source Вы можете его скачать с гитхаба Яндекс My Sync Вы можете его собрать это гошный проект он чисто на гон описан поэтому компилируется он вот так но там есть еще мои файл получаете один бинарник раскладываете на свои кластера и пробуйте прежде чем его использовать вам нужно написать видно вообще отлично Я не вижу вообще ничего вот сюда смотреть А здесь пример настроек my sing А что ему вообще нужно знать ну основные настройки что мы вообще делаем фейловер какой-то кулдаун то есть фэйловера не чаще чем Раз в час например Потому что если пользователь ломает кластер нагрузки он и реплику сломает не надо слишком часто делать некоторые Delay это это время которое мы даем мастеру чтобы он там очухался прежде чем мы сделаем фейловер настройки подключения киперу настройки подключения к mysq документацию настроек мы сделаем чуть попозже не добрались руки настроек много мы задокументируем нужно настроить Майский Эль чудеса PowerPoint рекомендуемые настройки mysql что как вообще Нужно настраивать во-первых нужно настроить Бен логи конечно должны быть включены причем они должны быть включены на репликах тоже потому что реплика в любой момент может стать мастером реплика тоже должна писать своей бен-логе формат бинлогов строчный то есть чтобы данные не расходились мы делаем репликацию по строкам они по statement'ом и мы используем gtd а кто знает что такое джитида Ну хорошо кто-то знает короче это эта штука это Маст хэв это некоторые аналог лсн в постггасе эта вещь которая позволяет вам понять в каком состоянии вас вообще находится база то есть ваша позиция в базе дальше Мы хотим чтобы наши данные не терялись поэтому мы включаем в симке мы синхронизируемлоги singing единичка и мы делаем флэша trx commit 1 то есть мы все наши транзакции Гарантируем записи в симкам диск Я знаю что очень часто люди любят оптимизировать эти настройки отключать в симке Как ни странно мои сингтость нашу утилита она помогает таким людям то есть после того как у вас майские оптимизированными настройками с отключенными всем упал данные на нем уже какие-то потеряются но за счет синхронной репликации мы переключимся на реплику и Для клиента данные не потеряются то есть Поразительно Но вот эта утилита Она позволяет более безопасно использовать mysql с Вот такими небезопасными настройками Проблема в том что после перезапуска вот этот хост практически гарантированно придется переналить он уже станет не консистентным его нужно будет выбрасывать но Такова цена А вот еще мой любимый блок Что нужно делать если произошел Сплит Брейн Если вы закомителя данные и которые разошлись с основным состоянием базы что нужно делать нужно не признаваться пока вы не признались в это Вычисли перед пользователем Поэтому настроечки запускаем mysql в режиме редонли и в режиме оффлайн мод в этом состоянии он не принимает запись и он не виден для пользователя он запускается невидимым а my sing потом посмотрит что хост входит в кластер или не входит если он входит в кластер он его вернет и откроет она по умолчанию Host запускается закрытым так настроили mysql здесь Наверное уже плохо видно но смысл в том что нужно прописать те Хосты которые принадлежат вашему кластеру мы их добавляем И после этого можем использовать собственно говоря my sing Как через командную строку можно с помощью команды mysing Switch переключить либо на конкретный хост либо с конкретного Хоста то есть либо выгоняем мастер либо привозим его в нужное место можно включить maintains либо выключить его а еще парочка слайдов в мастинке есть дополнительные дополнительные плюшки он умеет чинить кластер не только в плане вот состояния мастера Он еще реплики чинит То есть он их поворачивает в нужное место если на них там не включен редон ли он его включает короче он приводит состояние кластера к ожидаемым к ожидаемой топологии он чинит постоянно массинг управляется свободным местом если свободное место на Мастере либо на всех репликах приближается к Красной границе мы аккуратно Закрываем кластер на запись если этого не сделать он закроется неаккуратно и починить его будет тяжело еще масинку умеет закрывать отстающие реплики Ну и открывать их потом если реплика отстала больше чем на часов она будет закрыта и не видно приложение если она догналась там до м минут она будет открыта но это не все мы как бы хотим сделать еще больше И еще есть что улучшать можно поддерживать разные каналы репликации то есть чтобы в кластере помимо вот этой топологии которая поддерживается mysing была еще какая-то там внешняя пользовательская репликация между кластерами для импорта экспорта данных можно поддержать Мария диби можно поддержать место закипера эти сиди а можно сделать библиотеку для работы с вот этими структурами зу кипере потому что но сейчас есть два способа управлять мои синком либо через commonline Вам нужно зайти на хост либо нужно идти в закипперы правильным образом редактировать записи Ну вот редактирование записей его можно аккуратненько обернуть то есть квесты принимаются здесь есть куда копать вот собственно говоря на этом все Я надеюсь что вы попробуете и что вам это пригодится мы это используем используем уже больше трех лет это работает в продакшене и наша дежурные отдыхают вообще говоря то есть так Спасибо Дима Дима Спасибо разбавил Тарантул сциллу немного поиграв мускулями Давайте с переднего ряда и и мы переходим к сессии вопросов и ответов и вопросов уже много мне кажется у нас такое очень много вопросов действительно давайте начнем знаете как будем с конца вперед идти вот рука поднята в центре зала Пожалуйста микрофон последовательно у нас время вроде бы еще позволяет всех послушать Да просто очень плохо видно вот девушка хотела что-то спросить Спасибо за доклад очень интересная утилита очень интересная разработка У меня есть вопрос мне не очень понятно было схема со слайдом кворум там где был расчет р плюс V равняется N + 1 получилось так что в случае шести хостами синхронно реплицироваться должны были две реплики случаи с 15 хостами синхронно должны были репрессироваться 5 реплик и на этой картинке Мы видим что эти две реплики находятся в одном дата-центре нет красный красный мастер А две желтые это реплики мастер ожидает еще двух желтых реплик и хотя бы одна из них находится не в этом дата-центре а если они находятся в левом центре обе Нет мы рассмотрим конкретную топологию 6 реплика разложены по две данные дата-центр если мы их разложим по другому например там 51 дата-центр то мы никак не переживем уход этого центра так это утилита проверяет что они находятся в разных это Такой тонкий момент она не знает про расположение profold домены То есть вы должны сами понимать как располагаете Хосты и выбирать вот эту настройку правильным образом значение получается 2 в данном случае да должно быть значение РПЛ семи сингмастер вейд равно двум то есть нужно ждать двух реплик эти две реплики могут находиться в dc1 нет две реплики кроме мастера имеется ввиду и мастер падает Здесь всего по две реплики в каждом центре не может быть две реплики кроме мастера в одном центре тут уже понял спасибо большое пожалуйста Так ты кого-то сзади Да видел Давай все-таки последовательно пойдем вот следующий ряд примерно 5 там 2 руки пожалуйста разберитесь Здравствуйте У меня вопрос по этому же слайду у My scoillication есть такая замечательная фича что если она не дождалась ответ от этих вот Синг мастер формы начинает неожиданно молча становится асинх мастером и пишет Это плохо ошибок это обрабатываете там есть настройка таймаута время которое оно ждет вот мы ее выкрутили в бесконечность там Сколько можно То есть не откатывается на асинхронную репликацию этим следит mysing должен следить Ну да следит Спасибо за вопрос по этому же ряду У нас очень высокая плотность Да здравствуйте Меня зовут Владимир у меня такой вопрос Скажите пожалуйста как пользователю в Москве вам не страшно находиться на конференции с таким огромным количеством фанатов пас Греции Да не Нет они безобидные на самом деле на самом деле в пазгрессе все те же самые проблемы все практически те же самые решения отличия passgress от mysql вот в плане обеспечения высокой доступности в том что А в Майской или вы можете сходить по сети и поменять конфигурацию а в пазгрессе вам нужно находиться на одном Хосте с базой чтобы поменять настройки Ну там еще есть мастер каскадная репликация вот это вот все в моисекуле Ох ну да есть не надо так делать Нет мастер не надо давайте наверное вот сюда в вопросе Почему не надо все сделают Ну ладно На прошлом хайлоде был прекрасный доклад от людей которые делали мастер-репликацию и там за он так весь прыгал хочу спросить а как это работает Что делать если вот вы два ключа записали Вот так и вот они начали реплицироваться по кругу и пришли и конфликт что делать что делать Ну влоги ошибка напишет у нас есть отдел людей которые многие смотрят ошибки руками справляется у нас тысяча кластеров мы не можем ошибки руками исправлять Поэтому такие штуки мы не делаем доклад про то как вообще не надо делать очень горячая Давайте передадим дальше возможность Вопросы задать а это унесем в дискуссионную зону пожалуйста Да есть вопрос касательно того А если мы хотим наоборот отстающие он умеет поддерживать Это нет То есть это мои дизайн или есть какие-то возможности именно разрешить это делать Это короче задача которую трудно сделать она приносит не очень много пользы У нас есть отличный проект дата трансфер который мог бы это сделать проблема со стоящими репликами в том что сделать отстающие реплику не сложно что вы с ней будете делать когда вы поймете что она вам нужна Вам нужно будет срочно ее сделать мастером отключить её чтобы она перестала реплицировать и у вас время будет тикать то есть вы понимаете что у вас есть три часа когда нужно исправить ситуацию нам Иногда надо иметь возможность заглядывать на день назад словно что у нас было час два три назад то есть не откатиться а просто заглянуть Да интересно Давайте пообщаемся правда после здесь пока нет кажется но еще наверное вопрос по поводу того что она уже поддерживает именно вот ашанеша конфигурацию да у вас же есть ка Но это в Облаке А в вот этой опенсорсной она одна и та же мы переложили вот просто Спасибо так отлично был вопрос уже от пользователя функциональности Давайте первый ряд да Привет Интересно что утилиту опубликовали попробуем но у меня вопрос о наболевшем Мы давно используем базы данных в Облаке всегда использовали Гугловский И по весне решили что нужно переезжать в Россию сначала попробовали переехать на Яндекс но затем оттуда уехали Объясню почему проблема возникла как раз таки с вашим переключением у вас переключение в отличие от Гугла и от Huawei Cloud Где мы сейчас остановились осуществляется за счёт того что вы просто DNS запись мастера перенаправляете на реку то есть какая-то реплика по ДНС установится мастером но из-за каких-то проблем с ттллом в вашем ДНСе периодически раз допустим в 10 минут хост на мастер на минуту резонавится перестаёт почему вопрос Вы я причем У вас есть ticket мой в поддержке я запускал тесты из трех разных дата-центров я запускал тесты прям в вашем э-э этот cloudfunctions и даже ваши клаудфаншен свалились не могли Достучаться до вашей же мастера и я решил что неспроста наверное ребята из Гугла и ребята из Huawei Cloud сделали такой механизм когда реплики назначается айтишник бывшего мастера то есть единственное что смогла посоветовать ваше техподдержка это залезть в хост и прописать э мастеру жёсткий айпишник но соответственно я в этом случае поднимаю телефон и сам переключаю Почему так сделано э-э этого это вопрос на который лучше ответить люди которые делают сеть в Облаке с плавающими айпишниками проблема кажется в том что у них диапазоны разные То есть у вас же в соцсетях разный диапазоны и я не уверен переезжает вот тут есть три дата-центра Финляндии я понимаю из одного в другой переезжает мы бы тоже хотели иметь плавающий айпишник То есть это не ограничение mysql не ограничение вот этой утилиты вот в принципе Вы можете и это как бы точка для роста Если вы будете сами использовать вне облако такой утилиту вы могли бы сделать интеграцию и перебрасывать а ipшник э-э а ваша утилита она куда-то кидает событие что сейчас надо переключиться то есть для того чтобы мне BB сессию изменить Мне нужно знать что вот сейчас утилита решила Давай переезжать Есть момент в последний момент она делает запись в гипер То есть можно брать оттуда можно я думаю это очень просто сделать какой-нибудь колбэк чтобы она вызывала команду в операционной системе и э приносила айпишник например то есть ну поднимала просто айпишник на локальном интерфейсе это сделать Можно но вот Яндекс облаке это нужно сетевыми людьми говорить Ну да смотрите он действительно здесь такой стек Дима в менедж mdp завязана инфраструктурную Да часть и так далее поэтому стали очень интересный фидбэк эскалация наверное надо обработать это уже в оффлайн сейчас режиме Давайте не теряться нас вышло время Да не расходитесь но выберем вопрос Лучше едим один я забыл значит можем не один выбрать Ну вот первый вопрос про кворум был да наверное хороший Ага не все хорошие а ну наверное первый второй вопрос Давайте авторы первого второго вопроса про кворный прокорм во второй про Какой Про что был про фолбэк к синхронной репликации тонкий вопросик такой сцене мы сейчас после всего подарим вам подарок и Диму тоже поблагодарим да Давайте еще раз ему похлопаем Спасибо за отстаивание чести моей скеля У нас остался последний доклад предлагаю короткие перерыв и все Возвращайтесь Диму ловите в дискуссионной зоне выхода"
}