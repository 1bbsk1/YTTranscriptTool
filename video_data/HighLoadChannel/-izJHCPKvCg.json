{
  "video_id": "-izJHCPKvCg",
  "channel": "HighLoadChannel",
  "title": "Отказоустойчивый микрокластер своими руками / Виталий Гаврилов (Ленвендо)",
  "views": 5565,
  "duration": 2420,
  "published": "2017-04-22T14:47:43-07:00",
  "text": "добрый день уважаемые коллеги уважаемые слушатели я пожалуй продолжу тематику высоких нагрузок несколько по другому и разрезе и мы поговорим о том как построить маленький компактный но надежный кластер для решения абсолютно любых задач прежде чем начать рассказывать о микро кластер и давайте в принципе определимся что же мы понимаем под терминологии кластер большинство людей скорее всего в ответ на вопрос что такое кластер ответят что это что-то очень мощное быстро считает главное не падает а если что-то из узлов кластера и падает то это никак не сказывается на работу остальных узлов собственно эту задачу мы пожалуй и будем для начала решать да действительно эта штука работает плохо строить мы будем некую фирму которая позволит нам размещать на ней виртуальные машины основным критерием к этой ферме будет являться отказоустойчивость и для решения этой задачи нам нужно решить несколько основных моментов первое это получение отказоустойчивой дисковой системы в компактном масштабе несомненно можно подойти к вопросу вот так купить несколько десятков а то и сотен стоит купить хорошие дорогие hitachi узкие например старриджа все это дело за огромные деньги настроить собрать вместе получить дичайшую вычислительную мощность и начать этим пользоваться так тут я думаю единицы из этого зала потому что это стоит очень дорого и вряд ли оправданно для не очень больших проектов можно подойти вот так то есть взять много-много разношерстных серверов собрать это все каким-то образом в кучку и заставить работать мы на нашей практике постоянно сталкиваемся с тем что очень многие делают именно да практически любой проект трек нам приходит на поддержку выглядит именно так у нас есть десяток серверов половина из них работы под деби а нам еще две-три штуки под free bsd еще зачем-то вот тут вот есть у нас centos непонятно кто и зачем вы поставил и главное какие задачи он решает и как следствие выход любого узла из строя обычно приводит к очень серьезным проблемам на работе некоего проекта которые мы пытаемся обеспечить надежным решением это собственно то чего мы уходим а получить мы хотим некую понятную простую конструкцию которая позволит с одной стороны стабильно и эффективно обеспечивать работу наших виртуальных машин с другой стороны будет достаточно дешевый и понятно как масштабируемый и с третьей страны будет унифицированной то есть не будет зоопарка котором было сказано чуть чуть ранее строя кластер мы хотим обеспечить его надежной работой следующая пара слайдов посвящено тому как это сделать большинство современных серверов имеют либо звали b4 сетевых интерфейса 4 естественно предпочтительнее два сетевых интерфейса мы объединяем в бонд и отправляем их для связи с внешним миром еще два сетевых интерфейса мы отправляем в бонд направляем их для связи между двумя хостами я чуть-чуть вернусь к тому что мы строим мы берем пару железных серверов предельно идентичной конфигурации линкуем их между собой и на этой паре собираем газа устойчивые решение подобные пары серверах можно фактически в любом количестве объединять при этом должны выполняться требования и я скажу чуть чуть позже и так как мы хотим нашу ферму 2 под виртуальные машины была мы смотрим на следующий слайд видим что у нас после мостов после бондов появились bridge интерфейсы которые собственно позволят нам обеспечить обмен данными между виртуальными машинами которые будут крутиться на этих постах дойдя до этого момента мы построили физический уровень у нас есть сетевая связанности между нашими железными машинами и мы движемся дальше дальше у нас стоит задача выбора операционной системе почему мы используем ту операционную систему который вы сейчас видите на слайде мы очень долгое время у себя в компании искали надежную кластерную файловую систему которая бы позволяла с одной стороны имела с одной стороны легкую настройку а с другой стороны обеспечивала нужную rain доступности таких серьезных файловых систем по сути было 2 2 это решение от компании red hat названием в боксе steam версии 2 gfs 2 и собственное решение от компании oracle oracle as the file system тоже версия 2 в ходе многократных тестов мы пришли к выводу что во-первых у сейф с 2 быстрее причем как на больших файлах так и на маленьких файлов что в принципе не свойственно кластер нам файловым системам во вторых на ее гораздо проще на дестра ливать из 3 ханаан гораздо надежнее вот как и любой клон серверной операционной системы oracle linux имеет продолжительный период поддержки несколько превышающей рекомендованная к эксплуатации время работы серверов соответственно обновление парка серверов тянет за собой обновление версии в общем то мы ни на что не накладываем проблему построив выбрав на ценную систему можем двигаться дальше берем диск понятно что у нас везде дисковые массивы типа рейд хотя бы уровне 5 в самом худшем случае желательно 10 вот важный момент что это локальные дисковые массивы почему потому что во первых внешние дисковые устройства если она недорогое имеет низкую скорость а если она имеет высокую скорость высокую надежность то это будет гораздо более дорогое решение и его обслуживание будет требовать за собой обычно сертифицированных инженеров и кучу дополнительных затрат поэтому мы возвращаемся назад файловая система у нас в крае на у нас есть некий дисковый массив мы с ним работаем разбивка классическая выделяем загрузчик все остальное отдаем потом куда собираем корневую файловую систему и основное место оставляем свободно почему корень в.м. но все просто всякого же не случается выйдет новая версия не знаю захочется кому-то чтобы поставить нам на has новой машине не хватит места поэтому в но обычно написанный здесь цифра 10 гигабайт под корневую файловую систему бывает достаточно а дальше мы переходим к слайдам связанным с конфигурированием сетевых интерфейсов если кому-то будет интересно мы улыбнемся более подробно и рассмотрим детали ну и скорее всего многие знают что тут написано я смотрю многие фотографируют чтобы потом можно было посмотреть важным моментом является то что у нас пара интерфейсов которые соединяются между собой явным образом заданной mtu 9000 что включает jumbo frames и позволяет нам гораздо большими пакетами производить обмен между внутри нашей фермы между двумя серверами ну и следующий слайд в принципе тоже самое но с режимом бонд с режимом борисполь и рогонда опция stp внутри мы обычно выключаем просто потому что виртуальный switch внутри двух машин не оправдан снаружи зависит от масштаба либо мы используем либо мы ее не используем ну а дальше не забываем что у нас есть необходимость взаимодействия между имеющимися машинами открываем внутренний интерфейс прозрачно либо делаем какие-то более хитрые правило зависит от конкретного решения и начинаем двигаться дальше у нас появилось две железные машины на них установлена операционка между ними есть сетевая связанность на достаточно высоком его не отказоустойчивости потому что бабы кати со швабры никто не застрахован она может случайно провод зацепить вот видимо у людей были случай но и аналогичные каналы у нас за дублированы выходить в интернет у нас есть операционная система которая поддерживает fs и мы можем двигаться дальше собрать блочное устройство в чем основное требование е усилив sfs требует чтобы дисковое устройство с которыми мы работаем были соединены физически присылались одним и тем же виртуальном блочным устройством обычно для этого используются некое внешнее а исказил устройство которое раздается всем хастам одновременно и они обмениваясь между собой информацию о том то что поменял обеспечиваются централизованное обновление данных мы же в нашем случае имеем два независимых диска на которых мы создать создаем раздел и в этот раздел у нас будут писаться данные чтобы это все собрать воедино нам нужно их объединить опять же решение было довольно много обсуждалась во время много вариантов но тем не менее мы в ходе экспериментов пришли к выводу что старый и проверенный drd которые уже по моему не один десяток лет оказывается до сегодняшнем железе очень эффективным для этой задачи мы собираем наш и мы собираем две наши машины таким образом что имеется у нас некий виртуальный ресурс в данном случае его зовут shad создай аще и из физических ворьем или блочных устройств через lvm и эти замечательные две машины по сути имеют единый диск то есть запись с любой машины на этот диск придет тому что на второй машине данные тоже обновятся написав указанный выше конфиг мы замечательным образом запускаем синхронизацию drd последователь проведенное здесь здесь приведена исключительно для того чтобы те кто с drd не сталкивались могли это сделать я не знаю вряд ли все здесь работали с данным инструментом но тем не менее вот это последовательность придет потому что через некоторое время зависимости от объема хранилища оба компьютера наших оба сервером будут обладать идентична блочном устройством и она будет синхронно едем дальше дальше мы хотим настроить все fs5 же вряд ли много кто это делал поэтому идём по шагам устанавливаем необходимые пакеты то всего-навсего сев и стул и настраиваем конфигурационный файл информационный файл простой как грабли как принято обычно говорить в котором описываются в нашем случае только две ноты потому что больше физически у нас отсутствуют машины соединенные между собой на к всего 2 вот общее дисковые устройства значительно между ними поэтому они описываются указываются имена полное указывается внутренняя пи адреса и запускаем конфигурацию конфигурацию единственное что мы в не делаем указываем что сервис надо запускать автоматически все остальное достаточно в общем случае оставлять по умолчанию запускаем монтируем взлетела у нас есть некое блочное устройство смонтированная на обе машины проверяем что все работает создаем на любой из машин точки монтирования некую папочку видимые на второй машине пробуем туда-сюда убеждаемся что все у нас красиво если посмотреть на этот слайд то видно что в некоторых местах здесь варианты взяты в скобочки например при создании файловой системы можно использовать два разных варианта типа файловые системы под нашу задачу это либо data files либо vm 100 честно скажу пытались почти продуктивные различия между этими двумя вариантами не нашли и то и другое дает одинаковые показатели производительности есть еще третий вариант если не ошибаюсь мою файл с который действительно при больших файлах оказывается медленнее и но в принципе он предназначен для другой задачи когда шарит file system предназначена для почтовых серверов либо как единая точка монтирования для нескольких вот машин дальше все интересно перезагружаемся и убеждаемся что ничего у нас после перезагрузки не заработала связано это прежде всего с тем что ядро linux абсолютно уверена что файловая система осев с должна быть запущена до того как будет запущен драйвер dvd и при попытке запуска мы убеждаемся что точка монтирования у нас еще отсутствует соответственно шаг монтирование файловой системы пропускается спускается д л б д находится с дает большие устройство но сервис уже сам решил что файлы система нет правим порядок запуска как запускаемся убеждаемся что все заработало вспоминаем что машины 2 и аналогичные правки надо ввести 2 одну секунду вот до шлема к тому что у нас есть два физических сервера каждый из которых великолепно справляется со своей задачей у них между ними есть файловая система единая централизованная и на этом замечательном микро кластере можно начинать создавать виртуальные машины наконец-то мы нашли того что мы делали создаем в нашей точки монтирования некую структуру как мы будем это делать размещать я привожу тут то как делаем мы у каждого свои варианты просто дальнейшая часть доклада будет основан на этой структуре файловой системы соответственно у нас есть внутри единой точки монтирования бабочки дата где будут лежать образы виртуальных машин и папочка xml и будут лежать их конфиге достаточно важным моментом является не забывать после изменения конфигурации виртуальной машины сохранять изменившейся конфиг в единую в единое хранилище дальше станет понятно почему мы создали нашу виртуальную машину установили запустили сохранили конфигурацию все у нас прекрасно работает виртуальная машина видит сеть и и диск физически присутствует в некой общей точки монтирования доступность обоих машин и случилось страшное наши любимые изучать или операционной системы выяснили что в больше появилась очередная страшная дырка его срочно необходимо обновить вот ну а допустим тянет за собой это еще и ядро обновить ядро без перезагрузки даже в линуксе к сожалению нельзя перезагружать машину на которые работают другие виртуальные машины да еще и вполне возможно критичный тоже нежелательно поэтому нам нужно с этой совмещала с одной потом со второй машины нашей пары временно снять нагрузку делается это путем живы миграции тонкости расскажу чуть позже но вот команда поживы иммиграции здесь приведена она великолепно работает второй неприятный случай процессор сдох в одном из серверов вот если сдохла памяти бы с ним а когда сдыхает процессор обычно система перестает быть доступна через доли секунды ты завести ее вряд ли можно достаточно быстро зависимости от того насколько умная материнская плата и насколько она поймет что его надо просто выкинуть из обработки вот а машина нам очень нужна виртуальная наделала очень много нужных дел соответственно спокойно на втором посте без всяких нервов определяем на основе имеющегося конфига виртуальную машину и просто и запускаем в течение там одной минуты машина снова жива она снова работает единственное чем надо помнить о том что ресурсов то должно хватить главным ресурсом данном случае является память вот руками здорово красиво работает но как-то не хочется руками поэтому есть некоторое количество инструментов которые умеют делать автоматически есть связка красивых пейсмейкера который мы чуть чуть позже обсудим предназначенная для автоматизации отработки ситуаций слежение за службами между несколькими узлами настраиваю эту связку так как речь идет об аппаратных серверах не забываем о том что у нас есть вероятность когда каждый сервер будет считать что 2 недоступен и нужна гарантия того что в случае если один из сериалов оказался недоступен он действительно будет недоступен для этого в этом инструменте есть так называемые 100 мисс девайся шансы а за но до н за счет вот которые призваны быть уверенным в том что вторая машина будет выпущено обычно они работают на инструментах от вендора это управление через реки амой управление через и вот для управления через брат дел и так далее мы бьем тоже свой интерфейс вот это может гарантировать что машина будет выключено в свое время умельцы ухитрялись даже собирать физические рубильники которые через релюшку выключались да таких интерфейсов не было вот дальше мы все стоим на мониторинг потому что любая система неизбежно имеет ошибки проблемы тоже чуть чуть позже скажу какие ну и периодически все равно проверяем руками потому что а вдруг у нас мониторинг famous а мы чего то не увидели или мы что-то забыли про мониторить что нам это дает все что мы сделали выше оперативный запуск машин случае если они вдруг неожиданно сломались но не всегда этого достаточно поэтому есть возможность большинстве случаев иметь машину дублер у нее меньше ресурсов она в общем то толком ничего не может но эти ресурсы в последний момент можно накинуть так можно поддерживать ну допустим нам кэш потому что он сам по себе ничего не ест висит себе в свопе у соседней машины если что память и накинем вот но так допустим нельзя поддерживать mais que или просто потому что он должен быть запущен чтобы работала реплика вот ну и спас гриссом будут некоторые сложности поэтому для сервисов которые не поддерживают возможность те пассивного дублера есть ли возможность активного дублера на которых просто не приходит нагрузка но он включен и работает любой пассивный либо активный дублер требует от нас возможности доступа со стороны приложения к предоставляемым сервисом на сегодняшний день абсолютно все приложения насколько я знаю общаются друг с другом по неким сетевым ethernet протоколом процентов 99 этапе отказоустойчивость я вижу коллеги не согласны потом обсудим коза устойчивость айпи можно обеспечить до большим количеством различных вариантов от аппаратных решений вот cisco до программных решений разного уровня чуть-чуть по ним пройдемся по сходной таблички аппаратное решение от cisco замечательно работает обеспечивает нам гарантированный доступ некоему сервису нашему но понятия не имеет о том работает сам сервис или нет то есть с того что ip адрес придет на другую машину совершенное следующем там будет запущена и тот же самый memcache там вот полный аналог по своей функциональности по сути представляет протокол карт который поддерживается пользовательским юкар вот он тоже работает тоже обеспечивает гарантированно переброс айпи адреса между хостами но тоже ничего не знает о запуске сервиса тут немножко попроще программное решение можно в старт скрипты что-то дописать и обеспечить более менее высокую вероятность того что сервис будет запущен в случае переброс айпи адрес такой достаточно забытый на мой взгляд инструмент хит бит забыть он просто потому что он устарел идеологическим тем не менее он все еще существует позволяет обеспечить связку между переброс самой пи адреса сервиса и запуском различных служб и сервисов и придали сложность его прежде всего включается в том что у него совершенно не читаемый конфликта есть я в свое время убил несколько дней на то чтобы разобраться как написать этот замечательный конфликт чтобы все заработало именно так как мне хотелось вот при этом после того как там какой то что та отказала еще там через пару месяцев выяснилось что конфликта все-таки не идеале его пришлось писать дальше вот и пришедшие по сути ему на смену инструмент связка пейсмейкеры карасин она уже работает на основании обмена xml файле коми между собой она имеет человеческий инструмент правление серым и до определенного момента тоже работает хорошо почему до определенного момента но в моей практике мне пришлось как-то развернуть данные кластер на 16 честных узлов вот так вот когда на одном из вычислить их узлов нагрузка сильно скакнул autolog она была которые не 50 70 плоти вирадж то карасин q просто не хватило ресурсов на то чтобы обменяться информацией с соседними узлами соседнего решили что номер покласть его пошел полный кошмар потому что он появлялся то исчезал это было очень неприятно чем его в итоге пришлось выключить объяснить всем что действительно нету дождаться чтобы нагрузка у кого и вернуться его обратно вот теперь разобравшись как нам их встретить газа устойчиво сервиса какие есть инструменты и какие у них есть подводные камни вернемся к нашей замечательной схеме из двух физических хостов предложенное решение падает следующими ограничениями достаточно важными и протри нельзя забывать мы запустили виртуальные машины но за пределы своей пары хостов без тяжелых преобразований мы эти ритуальные машины перебросить не сможем это просто физически будет затруднено потому что блочно единое устройство у них между этими двумя х стали операции ввода-вывода в виртуальная блочное устройство которые отдам самой виртуальной машине существенно медленнее чем через мвм и немножко медленнее чем если у вас его при была реальная файловая система типа x 34 вот еще пожалуй на мой взгляд самый важный момент понятно что наши пули и виртуальных машин всегда присутствует их много моих для того и делаем чтобы максимально задействовать ресурсы вот наш коллега до меня рассказывала возможностях эффективного использования один из вариантов активность повышения эффективности использования как раз развертывания виртуализации полноценный потому что это отдельный доклад этим они были в него глубоко погружаться вот так вот если у нас среди узлов оказывается критичных узлов обеспечивающих работу нашего сервиса в целом больше чем противной памяти на одном на каждом узлов это означает что мы не сможем их все запустить случае если у нас вдруг неожиданно совершенно выйдет из строя сервер поэтому об этом надо помнить когда мы размещаем и следить за тем чтобы этого не происходило вот теперь самое неприятное типовые проблемы мы эксплуатируем данный подход уже больше двух лет суммарно на достаточно большом количестве проектов и за все время было только одна серьезная ольгу только один серьёзный тип проблема когда в случае отказа как раз связи между двумя хвостовыми машинами который произошел до того как ты машину выключилась а это было в случае когда из-за какого-то непонятного скачка по питанию который дошел до шины ядро linux решила что почему-то у нас больше нет сетевой карты на 1 лучше всякое бывает в этой жизни скачок копия решения в messenger заскочила что все у нас все кончилось вот и машина еще в течение там трех минут работала в парком это дело заметили по мониторинга мы успели принять меры вот после запуска машина каждая из двух машин утверждала что ее копия drd самое правильно вот и единственный вариант как можно было вернуться к жизни это сказать что вот нет так которая умерла ее копия трдд неправильно вот мы имели неосторожность опять же сделать это днем вот убедились что второй машине стало тяжеловато остановили на фиг запустили ночь вот ночью синхронизация прошла успешно все вернули к жизни все заработало вот на этом я принципе даже во время заканчивая и я думаю что будут вопросы готов их выслушать коллеги но точно есть вопросы я хочу рассказать что связка peacemaker crossing довольно интересное решение эту ситуацию которую вы описали с выходом из строя одного сервера по высокому его что он не отвечал и так далее значит здесь есть решение решение заключается в написании агентов для из мейкера которые могут следить за всяким подобными штуками и как только основе что-то происходит они сами могут проверять допустим доступность определенных сервисов которые вам интересны и выводить ноду при необходимости или не выводить сообщать реальный какой-то статус к росинка пейсмейкера на уровне вашей например бизнес логики или там чего угодно и таким образом пластик будет работать гораздо эффективнее и более приближенным жизнь будет но когда мы мы агента писали было такое в принципе решение есть данную это то есть понятно что никто не мешает отслеживать тот же самое вот и врач с новым ли приложи агента пейсмейкера на уровне статуса и говорить что какому-нибудь индексу на входе что подожди пока не кидай сюда запросы решение хорошее но такая довольно интересная доработка спасибо да я еще сказать по поводу отказоустойчивости что называется бюджетным бюджетный отказоустойчивости иногда на самом деле по моей субъективные оценки связка по и смерть пейсмейкера с карасин com в настройки все-таки сложна и требует как бы она не сложно когда ты все досконально знаешь но ты никогда досконально все не знаешь связке с письма и краска росинками то есть там довольно много очень тонких нюансов не очень хорошо документирован их и поэтому если наверное у вас есть возможность не использовать эту связку лучше не использовать есть гораздо более простые в настройки решение например вопрос если то есть если вы используете например tcp для работы да и лес там что то что работает поверх к себе то можно смело использовать х прокси здесь есть свои нюансы но настройка гораздо проще и вероятность отказов тоже гораздо меньше ложных срабатываний гораздо меньше но есть свои нюансы с более поверхностный логикой тестирования на работу в ваших приложений он так я позволю добавить и есть еще одна сложность доступность самого уха прокси между доп сервисами поддерживающих a proxy конечно здравствуйте такой вопрос что делать если у вас серверов больше 2 2 например 3 и д л б д в этом случае работать не будем не будет тогда вам надо 4 как опять если надо нечетное число как ваша схема будет работать и как вы будете восстанавливать далее если если сервера все время нагружены нет такого момента когда они ничего не делают как вы будете восстанавливать даже при двух серверах сбой в дбд как я уже озвучил в конце что надо понимать что виртуальные машины и критичные и не критичные в любом случае то есть есть ну не знаю там у вас 10 веб машин да вот и две машины базы данных вот база данных очевидным довольно является критичным узлом a web машина критичным не является если у вас вдруг какой-то момент вместо 10 станет 5 но это будет очень печально несомненно но каком-то режиме вы продержитесь до момента пока сын произойдет синхронизация но там очень активно идет например запись данных на этот диск и если ты включаешь синхронизацию drd положиться все поэтому делаем это мне нагруженное время вряд ли вам нет такого времени там все время что-то пишется тогда ваш случай наверно первый в предложенном вам нужно большой красивый кластер спасибо здравствуйте такой бусы я правильно понял что ваше решение является актив пассив еще раз я правильно понимаю что предложенная вами решение является этих весов то есть одна машина не работает а вторая машина нет нет нет правильно обе машины работают несомненно д л б д работает в режиме dual праймале как на пир девается синхронизация баз данных мы положим mais quel работе кости или в этом случае не могу положить базу mais quel на сетевой диск но он не совсем сетевой диск мы делали это и решение но при этом мы старались чтобы все-таки siggraph mais quel было два и это было майскую multimaster с учетом имеющихся ограничений и знания их проблемах какой-то какое-то преимущество использование ширины файла системы если можно использовать просто apple пишем 0 еще раз какой смысл использовать сетевую систему в вашем случае если мы же пуска поставить две машины и сделать кино для пар sharding это или или дублирование данных главный бонус то как раз в том что есть возможность перебросить нагрузку для проведения сервисного обслуживания на сто процентов при этом не теряя самого сервиса понятно всего здрасте объясните пожалуйста различие между кластеризация приложения кластеризации виртуальных машин и железо то есть мы понятно что мир внутри виртуальных машин у нас есть например там условно говоря apache который ну и внутри виртуальной машины он может допустим там следить за доступность этого апачи и запускать или поднимать apache на втором кости второй вариант запускать или или поднимать виртуальную машину на втором кости и третий вариант уже как вы говорили это через api мая стрелять в голову самой железной машине какое именно говорят ну какие плюсы-минусы подводные камни каждого подхода так еще раз я сейчас озвучу то что вы сказали пытаясь свою интерпретацию да то есть у нас есть три уровня у нас есть сервис которые мы можем выпускать и подымать у нас есть виртуальная машина которые мы можем мигрировать очень необходимости у нас есть железная машина и мы тоже можем делать нечто аналогичный правильно ну да совершенно верно получается мы можем работать с виртуальными машинами как с физическими то есть там будут эти там к росинки внутри виртуальной машины и они будут думать что они работать на железе и допустим можно до стрелять в голову самой виртуальной машине с другой можно какие подходы используются используете именно вы и что вы предпочитаете данным сочи но вот как правильно заметил видимо мой коллега мы действительно стараемся минимизировать использование к росинка уже внутри виртуальных машин как раз по озвученной выше причине им довольно часто сносит голову и они начинают лечиться неадекватно более того даже на уровне хостовых машин это делается только там где ну совсем совсем быстро надо это сделать вот тому что вероятность ошибки все таки достаточно высокая то есть класс there'sa ванными сервисами является с вами виртуальный машин такой стилизованным сервисами являются виртуальные машины именно так спасибо какую типовое количество виртуалок у вас железа зависит от железа и от того что делает virtual просто там десятки сотни десятки не думали в локальный диск mobis к нам допустим на много домов и а д л б д их на разных ost ипатова распределять на самом деле если у вас машина умерла чтобы там допустим 100 виртуалок поделились там на 10 разных ростов ну чтобы они не все на одну переезжали допустим вот это 10 диска там на один вы так далее мысль я понял вопрос забивать не вес диска выдавать например там не знаю по 50 гигабайт и сликом место допустим больше половина использована можно потихоньку до работы рисовать но то есть речь идет о том чтобы чтобы ограни на трафик через свечи утопись на нормальном свечи это соединяете и какая у вас машина умирает то не вся нагрузка перекидывается на соседнем вода не 2 допустим берется com 11 машин 1 умерла она и виртуалке распределяется по остальным 10 тут я боюсь будет сложность как раз в работе самого drd с большим количеством подписчиков то есть у нас получается каждая хвостовая машина будет там дружить еще с десятью но она поддерживает там допустим 10 соединений мысли интересное не пробовали небесного русского спасибо мысль интересная скажите пожалуйста будут вы презентацию говорили про стонет да как можно сделать стонет nabucco узловом кластере они же начнут друг друга стрелять смысле корова кворума же не будет если две машины кворума не будет да естественно будет явный признак того что я кворум законом мы не следим реально по 1 успеет а то убьёт 2 останется не будет такого что они обе друг друга убьют в на моей практике не было 1 успевает раньше у них там некий тайм-аут ronin 30 секунд ставит и второй вопрос virtual канала cfs тораджей как или бэкапить можно snapshot уже нет snapshot of нету во первых можно тупо снимать дамп вот во вторых на мой взгляд снапшоты это не самый эффективный способ но лично мое мнение да правильно снимать данные сервиса они образ всей машины а про кластер или вам что нибудь можете сказать могу сказать заставить его нормально работать нам не удалось даже на двух узлах я уж молчу про большее количество здравствуйте скажите пожалуйста почему вы используете квн они up on газета я видел вас там вид он стал да то есть и таковым и да и то в данном случае это квн но это может быть и xin это в общем не очень важно вот но это не оупен в и z больше изоляция возможности иметь разные ядра внутри разных виртуальных машин иногда это бывает критично но об он вызывал xt вы используете или есть какие-то причины по которым вы принципе это не делаете мы этого не делаем но скорее это так сложилось исторически всем спасибо большое"
}