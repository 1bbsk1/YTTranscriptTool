{
  "video_id": "Gk9K1NkYCww",
  "channel": "HighLoadChannel",
  "title": "YTsaurus SPYT: помогаем планировщику Apache Spark быть ещё эффективнее / Алексей Шишкин (Яндекс)",
  "views": 1905,
  "duration": 2378,
  "published": "2023-09-01T03:13:41-07:00",
  "text": "Алексей Шишкин Яндекс прошу аплодисменты спикеру Алло алло Все спасибо Всем привет Меня зовут Лёша и мой доклад будет посвящен Apache Spark А именно как мы в рамках войти делали его еще эффективнее ну для начала знакомства Я со школы занимаюсь спортивным программированием примерно с 8 класса в университете заинтересовался распределенными системами пошел в Яндекс и попал в проект который занимается спортом Вот и уже как два года адаптирую его к внутренней инфраструктуре Хорошо мой доклад будет состоять из следующих пунктов Сначала посмотрим что такое Спарк в эти залаз далее как он делается просто Что можно сделать получше сделаем это лучше и далее уже протестируем А зачем все это делалось и начнем с первого пункта Кто пользовался спарком поднимите отлично Ну это популярный стандарт для etl и lt-запросов пишут бедные задачи пишут обработки машинных моделей поддерживается огромное количество баз данных разных источников из технических деталей стоит отметить in Memory исполнение запроса все запросы происходят оперативной памяти из-за чего все это работает очень быстро и очень мощный оптимизатор запросов который делает даже плохо написано запросы довольно быстро Что такое войти Ну до этого Паша это сказал немного о нем о технических деталях Ну мы так обзорно тоже глянем У нас есть хранилище называется Кипарис в котором хранятся все данные все таблички это все очень хорошо масштабируется буквально жестких дисков миллионы CPU и поверх хранилища доступны аналитические инструменты такие как Kick houseuel и всплыть вот сплыть это такая прослойка между спарком и выйти заурусом которая берет сильные стороны одного второго и исполняет все эффективно из таких сильных сторон можно отметить сортированность войти зауре все таблицы имеют сильную синтезацию то есть мы знаем из таких колонок состоит таблица как например отсортирована таблица и это можно использовать мы можем пропустить какие-то Шаги на этапе исполнения запроса и за счет этого сэкономить деньги ресурсы время в общем все должно быть классно Давайте перейдем запросам вот у нас приходит какой-то дата инженер пишет свой запрос возможно пишет неэффективно чаще всего так и есть вот далее включается планировщик который видоизменяет этот вопрос он работал эффективно и выдает вот уже готовый план который достаточно исполнить и результат будет точно такой же как хотел пользователь Однако работать это все будет намного эффективнее и вот то что получилось в итоге называется физический план это уже то что можно исполнить то есть написали мы вот какой-то запрос почитали логи затем Достали из нее колонку преобразовали и записали это назад это внутри хранится в виде такого графа исполнения которые исполняется сверху вниз У нас есть кран это чтение данных Далее идет проекция мы оставляем одну колонку Map преобразование данных и сейф это все сохраняет в итоговую таблицу но мы все-таки имеем дело с движком для распределенных вычислений и понятное дело внутри Это не все так просто внутри у нас все таблицы поделены на кусочки которые называются партийцами вот изначально мы читаем таблицу и она делится на примерно равные части далее Все эти части можно Независимо обрабатывать мы можем вот опять же выполнить мэп фильтр много чего еще и вот насколько у нас хватило денег ресурсов вот так эффективно мы это исполняем и далее это все собирается снова в единую табличку и записывается в хранилище но бывают случаи пострашнее Вот например такое Это настоящий запросы вот так они выглядят в качестве физического плана вот у нас есть привычное чтение трех табличек далее У нас есть фильтр Union Union объединяет какие-то соседние таблички далее У нас есть сортировка Join Сохранение и какой-то загадочный и вот почти все представленные операции они очень эффективны вот мы можем как говорилось ранее поделить это все на мелкие кусочки и на каждый отправить машинку чтобы она преобразовала эти данные но у нас есть change и второе его имя это Shuffle это очень тяжелая операция потому что она перемещает все данные между таблицами между кусочками лучше посмотреть на то какой бывает шафл он бывает двух типов это Range Partition и Hash Partition первый делает так чтобы самые маленькие данные оказались на Первом кусочке потом из оставшихся самые маленькие кладутся во второй и так далее по итогу данные У нас упорядочены вот также у нас есть кэш артишин мы считаем для каждой строчки Хеш и вот то значение которое получилось Мы кладем в ту в тот кусочек тупо птицу по итогу если у нас есть одинаковые строчки Они обязательно попадут в один кусочек потому что это все происходит плохой шум и что мы можем здесь сделать оптимальнее мы можем избавиться от лишних шафлов когда табличка у нас отсортирована изначально мы можем порезать ее аккуратным образом и тогда она будет уже поделена на кусочки которые каждый меньше предыдущего То есть это Shuffle уже исполненный по сути а также каждый кусочек то есть мы экономим целые две операции одна из которых очень тяжелая и собственно мы будем этим заниматься но когда этот шаффл возникает потому что обычно я думаю те кто писали запросы знают Они не пишут Shuffle какой-то Это репорте шинин потому что А зачем он возникает сам собой Когда вы пишете агрегации или Join и мы рассмотрим каждый из них вот у нас есть облигация что это такое у нас есть ключ это какой-то под множество колонок мы смотрим по всем строчкам группируем по одинаковым ключам и далее запускаем какой-то общее вычисление Например у нас есть таблица с заказами мы друг другу по пользователю далее считаем сумму его покупок и записываем в конечную таблицу в итоге для каждого пользователя мы знаем Сколько денег он у нас потратил Сколько денег принес и физический план для такого видите справа у нас есть чтение потом какая-то операция положит одинаковых пользователей одного пользователя в один кусочек за счет этого в каждом кусочке у нас будет один уникальный набор пользователей и уже на каждом на каждом таком кусочке мы можем запустить агрегацию то есть посчитать то что мы хотим и так в каждом уникальный набор пользователей потом это все совместим и получим ответ довольно эффективно А вот этот оберегает который перед шафлом он заранее посчитает частичный там суммы например и это позволяет чуть-чуть сжать данные до того как их шафлить потому что Shuffle это тяжело и тут мы задаемся вопросом а что будет если таблицу уже отсортирована Что нам может предложить Spark мы добавляем сортировку и ничего не происходит Вот он взял и вытянул ее спойлеры Он взял и выкинул почему он это сделал он увидел что у вас есть сортировка далее группировка но весь результат что мы добились своей сортировкой будет отброшен Зачем ее делать он взял сэкономил ресурсы выкинул операцию а результат не изменился Он молодец вот но мы-то хотим увидеть Что будет если данные все-таки отсортированы для этого мы прибегнем к такому трюку с кэшированием мы добавим операцию кэш и Кэш сбрасывает данные на жесткий диск в процессе вычисления за счет этого так как не может влиять на результат на тот видимый эффект от наших операций он не может выкинуть то что было до этой операции И после этого мы вернем сортировку и что мы видим Shuffle исчез то есть Spark понял что раз данные Уже отсортированы и ничего с этим делать нельзя допустим данные уже приходит отсортированы то нам этот шаффл не сильно то и нужен потому что и так уже все лежит так как надо Окей давайте посмотрим А что такого есть в классе сортировки что позволяет ей говорить остальным что вот данные у нас уже лежат отлично У нас есть четыре основных Поля это выходное упорядочивание и протекционирование а также требуемая и это лучше смотреть на схеме вот у нас текущая операция она выдаст данные следующий и позиционирование это то как данные будут разбиты на блоке А упорядочивание это то как данные в каждом блоке будут храниться а следующее операция может выставлять требования на то как данные должны быть разложены что следующая операция хочет чтобы данные были отсортированы а текущая говорит что нет я так не делаю он добавляет промежуточные шаги и Именно поэтому мы видим шафл и сортировку Хотя мы сами не писали Окей и тогда мы понимаем А давайте обманим спорт и добавим свою сортировку которая ничего не будет делать но при этом будет говорить всем что данные уже отсортированы и он тогда увидит ее поймет что шафлить не надо вытянет Shuffle И все счастливы и тут тогда нужно сделать небольшое отступление в том А как можем вообще вставить что-то свое в план исполнения ведь это все происходит где-то внутри спарка А значит мы прямого доступа не имеем для этого мы поговорим Какие вообще виды планов бывают вот у нас есть физический который мы видели это Конечный результат но перед этим запрос проходит несколько стадий во-первых потому что вы написали строится сырой план логический это исполнение которой если у вас нет синтаксических ошибок то он будет сделан далее проявляется соответствие используемых функций типа в данных если все отлично если он переходит на вторую стадию и вот он уже проверен все информацию о типах данных о таблицах внесены в этот план и все значит запрос будет исполнен теперь вопрос А как вы исполнить лучше и тут Spark начинает применять свою магию он видит план у него зашиты оптимизации вот те правила по которым он может сделать запрос лучше он видит дерево которое изображено слева и понимает вот область помеченная фиолетовым что вот а если я переставлю операцию вот так то это будет работать эффективнее А вот те которые помечены синим их вообще делать не надо они бесполезные и вот за счет того что много много раз это исполняет мы получаем оптимизированный план и далее из этого уже рождается физический план он приходит снизу вверх и заменяет каждую такую вершину на вершину физического плана он буквально вот и до листьев Скорее всего промежуточно он может добавлять какие-то вершины свои за счет тех несостыковок добавляет Shuffle сортировку и тогда процесс Независимо по каждому дереву и по итогу мы получаем вот такой красивый план который будет исполняться и вот мы хотим строится в этот этап Мы хотим добавить свою стратегию которая увидит скан отсортированный и добавить свою вершину а со станом предложит разобраться с парку и мы делаем такое вот мы видим Стан мы говорим сварку мы умеем с таким работать Просто добавь нашу фейковую вершину а дальше сам как-нибудь он такой Окей я сделаю так добавил потом он опять видит стран и снова думает а что же можно сделать листает свои варианты и видит опять нашу стратегию которую он может применить и он снова добавляет и в итоге что мы сделали Мы зациклили планировщик не работает Абсолютно ничего Ну бывает Вот и для того чтобы это обойти Нужно вспомнить что вот пару минут и ранее мы говорили о правилах давайте сделаем свое правило которое будет встраиваться на этапе оптимизации он это правило увидит агрегацию между ними а затем уже стратегия увидит пометку и сделает из неё физическую пометку вот которая будет проецировать вот ту информацию которую мы хотим и тогда итоговый алгоритм он выглядит так мы у нас есть правила которые увидят Одно второе добавит пометку а затем стратегия это превратит в ту вершину которую мы видели Ну все мы помогли планировщику мы смогли вставить то что хотели и это даже работает но тут есть еще одни грабли Мы обещали спарку что данные будут поделены очень аккуратно что вот в то в каком виде хочет их представлять после того как произошел шафл мы ему уже дадим Но мы его тут обманули А он такой не прощает поэтому он больше ни за что не отвечает после такого и вся ответственность на нас вот допустим мы написали запрос опять тот же самый и вначале хотел уже говорил таблица делится на примерно одинаковые части если у нас есть четыре строчки это поделится пополам и на двух машинках будет исполнено мы посчитали ответ на первых двух и на вторых двух и по итогу у нас получилось дублирование пользователя с id0 Ну бывает Вот это барбер который нужно исправлять И для этого нужно чуть-чуть поменять чтение вот у нас изначально таблицы делилась на примерно равной части но из-за того что ключи могут быть большими может такое получится что в разные кусочки попал один и тот же пользователь и мы увидим дублирование результатов вот мы видели пользователи встретился дважды поэтому давайте что сделаем Мы подвинем каждый такой распил который мы хотим сделать до ближайшей границы между ключами чтобы один ключ не порезать пополам и часть умеет такое делать мы ему говорим читай от начала таблицы до первого упоминания зеленого ключа потом от первого упоминания такого-то ключа зеленого до первого упоминания красного и по итогу у нас один ключ лежит в одной таблице в одном кусочке таблицы и агрегации и по итогу что мы имеем до этого был какой-то тяжеловесный шаффл А после того как мы сделали У нас есть легкая операция сортировки которая на самом деле ничего не делает и на этом мы победили агрегацию можно чуть порадоваться и мы переходим к джойну Join что это такое Это такая операция когда мы склеиваем две таблицы на основе какой-то общей колонки То есть у нас вот есть заказы что пользователь купил предмет с ID таким-то а далее У нас есть еще таблица что на самом деле предмет с ID имеет такое-то имя и тогда мы делаем Join на этом нас получается информация о том какой пользователь Какой предмет купил в нормальном описании и физический план для такого он непростой мы написали Всего один всего И зачем он это сделал он добавил и сортировку это все происходит за тем что вот у нас есть Join двух таблиц мы для каждой строки первой таблицы хотим и стать соседа из второй таблицы Как сделать это наиболее эффективно Потому что если мы ничего не будем с этим делать то у нас просто будет для каждой строки первой таблицы проход по всей второй таблице это жутко не эффективно для этого мы сначала их пошафли если мы пошали по хэшу то строки с одним ключом в двух таблиц попадут в кусочек с одним и тем же номером и тогда соседа для первой таблицы для каждой строчки можно будет искать во второй таблице Вот тоже только в том маленьком кусочке обычно на практике таких кусочков 200 штук Каждая таблица нарезается на 200 маленьких частей а если мы добавим еще и сортировку тогда это можно делать еще эффективнее какими-то более умными алгоритмами и например это Окей И если мы посмотрим на то как устроен Join что он хочет чтобы ему подавали мы увидим все это То есть у нас есть сортировка он хочет чтобы и левый правой таблице были отсортированы одинаково и также он выдает требование на распределение он хочет чтобы и левый правой таблица была нарезана по ее хышу и тут мы понимаем что случаев у нас может быть в ноль вот была агрегация что-то более-менее простое у нас таблица всего одна она либо не отсортирована тогда мы не лезем со своей оптимизацией либо отсортировано Да мы применяем и радуемся А тут пустая у нас одна таблица уже отсортирована как нам надо 2 может быть тоже отсортировано тем же удовлетворительным способом либо она может быть отсортирована по совсем иным ключам или нет сортирована вовсе и поэтому логично разбить повествование на две части Когда у нас все хорошо когда мы можем делать оптимизацию и на остальные случаи когда ну что-то нужно изобретать чуть иное Вот давайте посмотрим вот если у нас есть две таблицы отсортированы одинаково мы создаем аналогичный Fight Shuffle который просто вставим скажем что он и Shuffle и сортировка и больше ничего делать вообще не надо и Spark опять же нас послушает он скажет все больше ничего своего не добавляю эти операции на самом деле ничего делать не будут они вот в том виде которым данный им приходят в таком виде вернут но мы опять чуть слукавили с тем что таблицы должны быть поделены одинаково то есть мы обещаем Джой Ну то что вот кусочки с одним номером У первой таблицы и второй будут одинаковые данные Поэтому нам нужно поделить обе таблицы вот так-то одинаково для этого мы посмотрим а как делится первая таблица это делится 2 по каким ключам На какие сегменты ее уже разбили а затем мы объединим эти сегменты То есть если 1 делилось Вот начало таблицы до ключа один отключая один только 7 до конца и вторая каким-то образом мы объединим набор этих ключей и скажем обеим таблицам делитесь Вот так мы чуть-чуть уменьшим деление таблиц но при этом оно станет одинаковым и тогда наша правила и стратегия выглядит так что мы видим Join и у него два страна мы говорим Поделитесь одинаково Окей И после этого мы можем добавить пометки о том что здесь должен быть фейтшаффл операция которая ничего не будет делать Просто пользоваться готовым супер остался второй случай Когда у нас отсортировано только одна таблица а со второй нужно еще что-то поделать Ну что мы можем сделать Ну логично что мы добавим Ту же самую пометку 1 который уже все хорошо мы ее добавим а ко второй добавим пометку которая говорит о том что здесь все плохо Тут нужно пошафтлить но учитывая что у первой таблицы все хорошо таким способом которым уже как будто пошафли на первой таблице И для этого мы пишем код вот небольшой код на скале кто-то не видел Вот такой красивый мы идем по той таблице которая пошла никак Вот мы ее хотим для этого мы реализуем такой вот свой шафл мы говорим возьми строчки из таблицы каждый из них далее Достань ключ по которому это все происходит под которым происходит Join далее Посмотри у первой таблицы А куда она бы положила строчку с таким значением мы получаем номер вот этого кусочка и возвращаем и спад перекладывает эти данные так как мы ему скажем но мы разобрались shuff мы разобрались с тем как поделить данные на кусочки Но мы ничего не говорили о том что данный после этого еще отсортированы должны быть а так как мы ничего не говорили с парку о том что мы это предоставим он сам увидит что данные нуждаются в этом и добавит это То есть он нам как бы помогает Окей и тогда весь алгоритм выглядит так что мы с помощью правила находим тот случай который мы можем оптимизировать добавляем свои пометки и далее ничего не делает А вторую пометку в зависимости Ну и зачем были все эти мучения Нужно же протестировать для этого была взята какая-то таблица которая отсортирована по трем колонкам и на ней мы запускаем аккредитацию по двум колонкам например подгруппировать и посчитать количество уникальных элементов и что мы делаем что мы получаем у нас время запроса упало на 10 процентов Ну такой неплохой хороший результат но Давайте посмотрим что случилось с джойном первое таблица была отсортирована по трем колонкам вторая таблица по двум и Джонни мы по двум колонкам и время такого запроса а он довольно частый упала на треть То есть если мы сделали побольше данные исходные то время примерно уменьшалось на 30-35 процентов а что будет если подменить по трем колонкам а тоже результат отличный время запроса уменьшается на треть и Подводя итоги Вот резюмирую то те результаты которые получились 10 и 35 процентов на каких-то кейсах и хочу пожелать выжимать из инструментов максимум смотрите как они устроены Что можно делать оптимальнее как можно им помогать и посмотреть эту оптимизацию Вы можете в публичном репозитории выйти заудовса можете его попробовать в демке ваша сегодня рассказывал о нем его демки и Всем спасибо за внимание супер Спасибо тебе огромное Ну что друзья задавайте пожалуйста вопросы Я уже вижу руки в зале сейчас вам хелперы принесут микрофоны Если вы смотрите онлайн Не стесняйтесь задавайте вопросы если вдруг вы в зале и всё-таки стесняйтесь Вы тоже можете задавать вопросы в чате а пока мы слушаем вопросы и ответы не забывайте переходите по qr-коду обязательно оценивайте доклад как я уже много раз говорила за сегодняшний день И не только я во всех залах Нам очень важна обратная связь Итак первый вопрос прошу Спасибо Алексей за доклад за классный хотел спросить такой момент Спарк на самом деле же умеет работать сетами и оптимизацией которую вы делали он тоже умеет делать есть вот и это Мета записывается например в Хайф Спарк Может её прочитать и соответственно пропускали хача э план он пропустит нативно Почему тем более войти эта штука то есть вы сравнивали с физическим слоем когда как с файлами Да работать когда нет у спарка никакого понимания как оно внизу написано вот почему бы вам в это в мету не прокинуть было и Спарк бы оттуда не взял эту информацию также как он ее может из хайва например взять Дело в том что Ну вот Spark это один из многих инструментов которые могут создавать таблицы как-то их изменять и таблицы вообще хранятся в собственном каком-то формате который удобен пойти и это пришлось бы тогда просить вот все остальные инструменты также поддерживать актуальную мета-информацию Да в каком-то виде не научиться парк его читать Вот года два назад Саша Белоусова рассказывал о том как были реализованы методы для того чтобы войти войти на этом низком уровне связать со Старком Я думаю что если просто это было может быть это не просто в этом и вопрос как раз вот это поддержать набрать или на риде это можно было вообще ничего не переписывать Ну вот а когда мы смотрели Ну что мы можем сделать в этом моменте там буквально в исходном коде Spark были заготовки какие-то методов но самих рабочих методов чтобы именно указать источнику данных что а данные у меня уже отсортированы или что-то такое такого было нельзя ну и плюс тому же у нас какая-то своя логика в том чтобы поделить таблицу на части и вот она как раз ломает у сортировку которая и могла быть до этого ну то есть я бы не сказал что это сильно что-то упрощает не понял спасибо большое Следующий вопрос пожалуйста Добрый день Спасибо большое за крутой доклад Вопрос такой вот на сваде согрегацией вы показали что для того чтобы не было дублирования нужно делить на партиции в стыках где меняется ключ чтобы один тот же ключ не попал в разные партиции как тогда в таком случае бороться с неравномерными партициями Можно ли это как-то делать или Тогда весь все эти усилия идут понапрасну если например есть я не знаю в случае это если логи пользователи есть пользователи которые хочет быть длинные логики они будут делать супер жирную партицию и таких быть много и тогда будет очень сильно разброс Ну это на самом деле проблема самого активного спарка потому что ему однозначно нужно положить все данные на одну машинку и как бы и в том виде в котором мы это делаем и самостоятельно он и не умеет как бы работать с этим разными способами он всегда добавляет предварительную агрегацию для того чтобы сжать данные и потом следующую редакцию уже финальную Она всегда происходит в два этапа и как бы если этот запрос действительно такой жирный то у вас и обычный Спарк из вот этой оптимизации они беспомощные в том плане Спасибо огромное Следующий вопрос пожалуйста Вопрос такой я за этих хаков Spark обычный если видят то что данные допустим на втором стоит же можно уже использовать в третьем то он запускает третий встреч не дождались второго вот с этими хаками кажется это возможность убирается Особенно с кашем нет кэширование в финальном виде у нас отсутствует мы не добавляем вообще мы тестировали это на детектив planning то есть такая новая фишка с парка адаптивное планирование и он корректно с этим работает то есть умеет пользоваться нашими операциями и тут же использовать их для перестройки плана или для работа с данными это остается фича Спасибо огромное Следующий вопрос пожалуйста Привет Спасибо за доклад такой вопрос тесты вот которые показали производительность Джона на 35 процентов лучше а какие диски писали Shuffle это были шпиндели или SSD это было все использовано вот в нативном виде в котором она есть там SSD не было Вот интересно было бы на SSD посмотреть потому что они сильно улучшали бы производительность шкафа еще такой вопрос в чатике эти заурус говорили что планируется ванильный Спарк понемножку водить всплыть Какие планы на этот счет и как чтобы прям исходный Спарк использовался в Да выйти но у нас есть некоторые наборы таких изменений которые мы используем То есть это на каком-то низком уровне ввиду того чтобы прокинуть нужные какие-то токены для работы с войти в сам вот до места их назначения И там параллельно как-то зашифровать чтобы когда ты читаешь логи не было токена пользователя по которому его можно его аккаунт увести Ну то есть Пока У нас подготовлен набор патчей которые можно воспроизводить на ванильном Спарте чтобы делать миграцию к новым версиям как-то полегче просто буквально патч Но именно изменения кода так чтобы можно было просто новый спад привести он работал пока нет подключить которые бы специфику войти Ладно последний вопрос может ли сортированные таблицы его ускорить больше меньше ну видимо в таком виде Джона у нас нужны все данные из второй таблицы то есть опять же тут не видно как можно сделать лучше мне кажется не будет работать но можно протестировать Я понимаю что это очень редкая штука но мне просто попадались такие у вас такая есть можно кстати обсудить потом дискуссионной зоне Вдруг у кого-то из ребят был такой опыт и так друзья есть еще вижу есть вопросик Спасибо за доклад Вопрос такой не проверяли насколько удобно на White is aurus реализовать якорную модель поскольку она как раз подразумевает большое количество Джона сортированных и насколько вообще эффективно может быть реализована такая модель данных может быть есть какие-то практические кейсы уже есть такой метод проектирования данных называется Якорная модель когда данные разложены по таблицам и таблицы имеют один и тот же ключ но при этом атрибуты находятся в разных таблицах для того чтобы получить какую-то аналитику приходится эти таблицы очень часто и за счет того что данные Как раз сортированы мне интересно насколько эта модель может быть успешно реализована на Уайт и заурс Ну я считаю что максимально успешно потому что у нас есть мета-информацию которую вы можете указывать То есть вы берете табличку как ты создаете или переливаете из сторонних источников вы указываете что данные у меня отсортированы это запишется метаинформацию буквально добавить один стажер или уже когда она записана именно у готовой таблицы тоже это можно изменить и вот оптимизация для этого и служит Я считаю что Да все будет хорошо интересно Были ли такие практически кейсы Вот то есть Ну мне кажется команда вида Яндекс такси Постоянно работает с такими данными руки переходим дискуссионную зону где будем продолжать обсуждать я чувствую Ну что что-то еще у нас из вопросов Ага Нет рук нам надо выбрать два и могу сказать что лучше мне кажется все вопросы были классные сложные интересные Это здорово но нам надо выбрать два вопроса за которые мы подарим подарки один атончик а второй от Яндекса какие-то будут вопросы вот этого молодого человека раз и первый вопрос первый вопрос Поднимите руки А наша замечательный хелперы передает Вам подарочки и от лица конференции хочу сказать тебе огромное спасибо за подготовку доклада за то что так классно выступил Спасибо большое небольшой Презент Спасибо"
}