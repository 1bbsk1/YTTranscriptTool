{
  "video_id": "eK6SxIf_PBQ",
  "channel": "HighLoadChannel",
  "title": "AnalyticOps: конвейеры для поставки моделей машинного обучения / А.Задорожный",
  "views": 583,
  "duration": 2282,
  "published": "2020-04-14T11:31:59-07:00",
  "text": "меня за тонну задорожный я работаю principal инженером в компании teradata компании то что широко известно в узких кругах то есть это компании специализирующейся на аналитических решениях в этом году мы отметили 40-летний юбилей компании она давно на рынке и этот доклад вам методологический мы занимаемся разными аспектами аналитические платформ аналитических систем и процессы поставки модели машинного обучения в промышленную эксплуатацию эта часть многих проектов компании работает разных отраслях от медицинских исследований до автопроизводителей конечно банки телекомы рознице и у нас сформировалась некая методология обобщающая весь опыт вокруг переведении машин машин модели машину обучения в продакшен собственно вот это будет рассказ но для того чтобы перейти к методологии мы должны задать определение и постановку задачи и мы с этого пожалуй начнем как вылить нашу задачу в самом простом виде я буду приводить примеры не какой-то конкретной отрасли глубокой внутренней там фотографии сварных швов а это будет пример проекта который будет понятен всем и может быть если вам это будет интересно вы можете потом помочь этому проекту это добровольческий проект итак задача такая люди теряются в лесу дроны облетают площади и присылают фотографии площадей лесов полей перелесков есть поисково-спасательные отряды которые ходят их вещь отлизали вот сам известно такой отряд фотографии с этих дронов нужно изучать и находить на них потенциальные цели после этого надо взять координаты и за xiv часть фотографии и сообщить спасателем что нужно пойти и потенциально может быть там находится человек пропавший без вести как это выглядит буквально ну вот у нас есть несколько фотографий и просто качестве примера приведу это фотография из вас это для обучения поэтому это добровольцы на фотографиях видны это ведь летний datasette поэтому здесь людей хуже видно на зимние соответственно лучше видно как выглядит посоветовались действий чтобы нам реализовать приложение помогающие у такой активности во первых нам нужно собрать фотографий мы можем попросить людей которые занимаются этим прислать нам эти фотографии в хорошем разрешении следующий этап нам нужно разметить эти фотографии это значит указать там людей указать там те объекты которые мы хотим обучить а нейросеть распознавать обучить модель это самый нейросеть дальше нам нужно проверить что модель работает хорошо нет ничего хуже чем а большое количество позитивных срабатываний в этой отрасли потому что если мы говорим что потенциальная цель то туда пойдет поисковик это тяжелая работа и там никого мой муж не быть это это время потрачено зря хотя нам надо торопиться когда мы ищем людей поэтому мы должны проверить что модели работают хорошо на берегу после этого нам нужно править модель на устройство поиск происходит в местах где интернета нет или он очень плохой особенно для передачи фотографии высокого разрешения поэтому нам необходимо модель обученную каким-то образом поставить на устройство на ноутбук сотрудника поисково-спасательного отряда чтобы он там смог ее применять в приложении и после этого нам нужно получить отклик от производительности модели в полях этот оклик может быть формальным то есть нам могут прислать новый пачка фотографий где отметят людей либо может быть неформально но при могу сказать что у нас очень много ложно позитивных или модель вообще ничего не не находят и затем мы переходим к пункту один такой вот производный процесс разметка фотографий это отдельный процесс я просто немножко на нем остановлюсь на ток где том числе нужны добровольцы фотографии тщательно изучаются людьми на них отмечают отличаются потенциальные цели самом простом виде прямоугольника и различные фотографии формируют два набора данных и мяча сотов один набор это набор для обучения а другой набор это набор для оценки оценка модели проходит так мы даем модели фотографии без разметки смотрим где она нашла людей и сравниваем с результатами разметки таким образом и точность модели устанавливаем что перейти к определи здесь мы передём к определениям я не мог немножко отличаться между командами между практикой между компаниями которые занимаются поставкой моделей в продакшен но вот я предлагаю таки такой набор определений первое деление это обычная модель это объект который непосредственно используется либо для предсказания чего-то либо для классификации чего-то этот вот тот самый часто бинарный файл который поставляется на устройство или поставляется выпей для того чтобы сделать эту мамой не и этот главный предмет наши поставки крутой есть просто модель это кот порождающая опущенная модель как любой код он эволюционирует у него есть версии он развивается в нем есть какие то проблемы они фиксируются со временем и этот код в каждом в каждый момент жизни может породить нам обученную модель следующее определение the data set для обучения это те самые размеченные данные для обучения модели которые нам нужны что получить обычной модель datasette для оценки это другой набор размеченных данных и он нужен нам того чтобы показать как модель ведет себя в условиях использования близких боевым и развертывание модели это процесс передачи модели для использования так с определением все понятно теперь собственно на какие вопросы нам нужно ответить когда мы переходим к работе как быстрый процесс развертывания моделей во первых что уже гарсиа не ровать ну вроде бы код это довольно очевидно как насчет параметров которые идут в процедуру обучения модели как насчет результатов обучения модели самого себя артефакта результатов оценки мы впахивать поговорим как контролировать качество нам нужно поделить во первых что такое качество в каждом в этом случае для каждой конкретной модели каждого конкретного процесса качество может быть видно по разному как это связать с данными как мы знаем из предыдущего доклада данные постоянно меняются и то это жизненный процесс и нам нужно построить систему который позволяет нам однозначно сопоставить получившихся артефакт с теми данные кота данными которые были использованы для его получения как построить аудит существует большое количество отраслей где модель не может просто так быть за тепло и на продакшен должен быть процесс когда специальный человек может быть описана я роль смотрит на модель и говорит что например вот эти данные нельзя использовать для моделирования ну например в акрит нам спарринге в некоторых странах запрещено использовать фичи основанные на 1 или на поле человека нужно ли вообще автоматизация в принципе это не такой сложный процесс зачем нам нужно автоматизации какие вызовы есть здесь но первая проблема это так называемый drift car drift моделей вообще есть несколько видов дрифта есть дрифт концепта это когда мы например взаимодействуем с таким вот противником каким-то словно бы тоже делать фрод как anti-fraud модели и его действие изменяются зависимости от того как мы с ним взаимодействовать как мы ставим противодействие и таким образом сдвигается наше понимание мы должны обновлять модель бывает дрифт данных когда просто изменяются данные из за того что каким-то несвязанным образом изменяется поведение наблюдаемого объекта и нам нужно переобучаться превышение часто ручной процесс и в можем ситуации когда это сантис это самый дорогой человек в компании один из самых дорогих и те компании и каждое увеличение его в ручной процесс стоит компании больших денег другая проблема что если переобучение ручной процесс то процесс оценки модели после переобучения каждый раз ручной и непрозрачным как и говорю отраслей где у нас есть аудит где мы должны рассказать регулятору почему модель выглядит так почему она так существует мы должны показать прозрачный процесс оценки моделей отдельный аудит кода моделей показателей и разнообразие фреймворков м.л. разнообразие flavor как это скорее вызов то есть нам нужно сделать такую автоматизацию которую бы не прибила всех одному конкретному socket лен или python нам нужно сделать гибко автоматизацию наравне компании и затем дать людям возможность выбирать фреймворке не вставая на их пути давайте тогда поговорим о по дороге аналитик ubs как и сказал оно основано на опыте и мы видим что она хорошо применимо в разных отраслях кредит отраслях шаги могут вы рождены я об этом скажу но в каких-то отраслях все шаги присутствуют это история четырех workflow чтобы расшифровать немножко давайте посмотрим на процесс процесс получения бизнес выгоды бизнес-целей или или просто выгоды от данных применение например к нашим с наш пример с дроном сначала мы начинаем с осмысления мы пытаемся понять что мы вообще делаем любой аналитический процесс связанных машинным обучением это либо предсказание вероятности чего-то либо классификации чего то есть мы оптимизируем когда процесс что-то здесь пытаемся улучшить стартует у нас такая петля с одной стороны у нас есть получение обработки данных здесь участвуют люди которые занимаются строительных хранилищ данных to the lake of нашей компании под инженеры который участвует во всем этом они готовят данные загружают их систем источников и предоставляют их да это союз с другой стороны есть часть связанные с экспериментальной исследование и моделирование здесь буквально исследования это поиск зависимости будет польза взаимосвязей между данными и тем событиям которым пытаемся предсказателю классифицировать и так эта петля она на самом деле друг на друга может задеть за и молиться с разных совершенно направлениях например вы сделали моделирование и вы поняли что у вас недостаточно я ценность дам информацию вам нужно еще больше данных вы пошли снова в процесс получения данных вы сделали моделирование вы собрали больше данных и у вас изменилось понимание задачи например в примере с дроном мы конечно сразу понимаем что у нас есть зимние datasette и у нас есть летний datasette и но также у нас есть лесные дата с этой перелески поля мелкая застройка такого рода datasette и все это вдруг подруга влияет и вот такой петли взаимодействует в какой то момент мы добились нужной нам точности ну или у нас ограниченное по времени наша это рация таким образом мы переходим следующим шагом это автоматизация и собственно потребление модели потребления вот этого на готического результаты которым мы получили и в нашем фреймворке нашей методологии мы фокусируемся на вот этих двух шагах на автоматизации и потребление что это значит что это сайт сможет жить как он хочет до того этапа когда он хочет выдать нам какой-то результат и отправить его в продакшн мы здесь ему не особо мешаем но когда мы говорим о потреблении то мы накладываем трудно условии у нас исправно и соглашение по жизни касались если конечно где участвуют разные люди и поэтому разные практики отсюда название аналитик ubs хотя многие говорят м эллипсе или сиди формой рака дизелем реформа жилье не мы больше фокусируемся на инженерах стараясь как можно меньше мешать да это союз так история четырех варг лом эти четыре workflow нужды для того чтобы принести модель из devil in the production по 1 workload обучения это понятно мы делаем из данных и каких-то параметров этот самый артефакт обученную модель следующий warhol эта оценка здесь обычная модель показывает как она ведет себя условие приближенных боевым но еще не совсем боевые 3 workflow это администрирование мы могли скам называем долгого нас это тот workflow где мы принимаем решение что решилась моделью как я сказал у нас есть отрасли где нужно необходимо провести аудит то есть вы на этом workflow происходит это научит но даже если у нас нет аудита мы должны сопоставить результаты оценки с предыдущими годами оценка для предыдущих артефактов и как-то двигаться дальше и 4 workflow это развертку давайте по порядку обучение обучение превращают код модель что нам нужно на вход версия кода модели как правило весь код хранится у нас системы контроля версий где-то в те и нам нужен сам простом виде гид хэш чтобы сослаться на нужно версии кода модели следующий параметр это параметры обучения это могут быть параметры гипер параметры что-то с чем хочет дата сайнс обучить модель в конкретном как этой ситуации следующий параметр на вход это ссылка на datasette как правило мы храним datasette а где-то снаружи потому что больших данных все большое дорастёт может родиться в базе данных быть таблицей большой базе данных он может быть файлам в объектом хранилищем таким как ис-3 например и мы здесь ссылаемся на этот datasette нашим и pr следующий кусочек это договоренности о скрипте запуска обучения мы их называем land on which бэннинг привязки на язык но это некая конвенция которых возможно быть несколько например если ваша набор поддерживая сразу арв и питон у вас есть договоренность о том как выглядит . фото для обучения условно это может быть договорим и своим не скрипта в нашем случае эта договоренность имени сигнатурой функций функции train функции влияет функцией predict на выходе у нас есть артефакт обычной модели и метаданные что это за метаданные это идентификаторы и ссылки то есть мы сможем сослаться на тот набор параметров на ту версию кода на ту версию это сета который был использован для обучения и так это первый урок ловко называется обучение 2 full эта оценка здесь моя модель показывает свою производительность на вход у нас новые нити карты досыта но уже для оценки и доливка tarte факта обученной модели здесь мы достаем то что мы получили на предыдущем workflow из какого-то стороны где это хранится нам также нужно соглашение скриптах которые выполняют эту оценку то есть опять это может быть соглашение о приемной сигнатуре функции и валит в питоне или определенном скрипте который вы запускаете до того что получить оценку и дальше процесс оценки выставляет артефакт в виде отчета по модели вот как еще выглядит оценка как правило это скоринг или inference то есть применение модели плюс расчет показателей поэтому он расчет точности пьеса и и все стычки и проверки которые только можно себе представить разных видах они есть по разному разных видов моделированием но какой-то отчет всегда существует этот отчет может быть просто джейсон файлам с метаданными это может быть какие-то метрики но и там его в общем виде всегда называем отчет и отчет мы также читаем артефактом мы также его сохраняем и используем для следующих шагов слышат администрирование на этапе администрирования мы не получаем от отчеты об оценках и тайма этой версии обычной модели всех предыдущих и принимаем решение что с этим делать это может быть ручной или автоматически процессом простом виде у вас есть одна метрика это актёр оси и точность модели и в вас простая логика если точность новой версии обычной модели выше чем предыдущий то двигая эту модель дальше workflow выдает версии идентификаторов моделей и способы развертывания дело в том что вы можете разворачивать модель разными способами в каких-то простых допустимо только обновление текущей модели это называется чемпион challenger подход когда у вас есть чемпион та модель которая находится продакшене используются для принять решение и у вас есть претенденты challenger эта модель которая только что обучилась на новых данных и мы их сравним другой способ это оба тестированием во всяких разных выдох выдох это выкопка новой модели и направление части трафика части решений на эту новую модель их мониторинговые потом сопоставляется еще один способ это различной ансамбле это когда модели в зима работают друг за другом взаимодействуют с другом всяким нога руки бандиты и прочее и так это администрирование мы взяли пачка отчетов по модели и приняли решение что здесь вообще бывает кроме автоматического этого принятия по хироси очень часто в регулируемых отраслях нам необходимо сгенерировать документ формальный документ pdf и сгенерировать письмо человеку который занимается вуди там и он должен там специальном ей поставить галочку он согласится что это новая версия модели пойдет в продакшн бывает такой вариант бывает вариант когда у нас необходимо цепочка аудиторов то есть есть люди которые отвечают за домнин это люди из седел читы это офисов офиса есть люди которые отвечают за эмаль и они тоже смотрят на лишь готов где-то если они оба согласились на модели уехал в продакшен ну и автоматически принять решение пример уже сказал и 4 workflow это развертывание модели я все просто у нас на входе есть стратегии развертывания идентификатор и факт обученная модель мы вытаскиваем из хранилища и диплом в самом общем виде что нужно хранить и отслеживать здесь давайте об этом и говорим и так очевидно что код обучение оценки мы храним как кот мы храним его в детей есть иногда мне в моей личной практике не попадались на и заказчики которые используют проприетарное решение такие как сосна пример unicode хранится в поем репозиторий но какой-то repository при сборе для хране куда всегда есть следующее что нужно хранить это обычные модели это артефакты часто это бинарные иногда так самой например ммм или используем их там тоже где-то складывать в самом простом виде это файловая система в половую систему вы можете положить файл по соглашению по определенному пути и доставать просто по имени это может объектное хранилище такой как из 3 или кукла вас что-либо система хранения артефактов на как к концу или артефактами следующие 3 часть это datasette и то цвета обучения и оценки и здесь на наш взгляд не нужно пытаться хранить у себя внутри фреймворка для аналитик ubs какие-то данные мы ссылаемся на datasette его внешних системах то есть мы храним это данные что это может быть например если вы обучаетесь из базы данных из подвески то мы храним параметры коннекта коты подвеску и имя схемы имя таблицы может быть какая-то новая коз ограничение по таблице для выборки datasette обучения и другого для выборки datasat оценки но это метаданные который мы сохранили мы не храним сами данные также может быть с файлами у вас могу может быть файл в формате например а про какой-нибудь лежащим в с3 мы храним путь к этому файлу в нашей системе ханней методом на и отслеживаем зависимости обычных моделей от этих файлов и четвертый элемент который надо сохранять это отчеты по оценке отчет об оценке тоже является артефактом и мы храним их аналогично любым другим архивах ну то есть уже файловой системе в объектом хранилище или системе хранение артефактов есть еще целая сон данных которые необходимо сохранять это данные о мониторинге но они часто чаще всего специфичные для конкретного юз кейсы для конкретного домена проблематике которые вы решаете но все сказано предыдущем оплате промониторить провели водитель на это то что нужно строить и и и сохранить данные и и по ним принимает решение и так совета по реализации что и как делать здесь я хочу сравнить аналитик ubs или малек соседи классическими супер development pipeline ами для выкатки кода приложений в продакшен давайте посмотрим носящие сначала pipeline и собирают тестируют и выкатывают программное обеспечение одна версия находится production здесь есть конечно звездочка то есть самые продвинутые из вас наверняка имеют фича флаги готова с разной версии вы настройкой внутри там сервис discovery ли конфигурации меняете какие клиенты на какие версии ваших fitch приземляются но в общем случае это справедливо нас мы не стараемся не держать продакшене сразу много версий мы считаем старую версию legacy и тут же и отрезаем как со стороны инженеры развертывание зависит только от кода тестов то есть если у нас есть цикл разработки люди пишут код ли люди пишут тесты какой-то момент мы собрались про тестировались и если нет изменение кода и тестов то мы не будем заново собирать и тестировать нечего все что за тепло и нато заде плавно работает в аналитику обсе немножко всё по-другому прежде всего pipeline и обучают и оценивают модели то есть у нас есть кот и модель это применение данных к этому коду очень часто больше одной версии в бою и это считается нормальным и решение развертывание зависит от куда и от данных то есть у вас код стабилен он не меняется но вам приходит новые данные для обучения это значит что вам нужно запускать workflow для обучения оценки если у вас не меняются данные для обучения только могут эта сеть для оценки то вы для готовые обученные модели запускайте workflow для оценки и так только вода лети капс у нас артефакта меняются без изменения кода то есть workflow обучение оценки может быть запущен когда есть новый datasette и артефакты порождают другие артефакты без изменения кода отчеты по оценке случае но вот это сад оценки так например что дальше какие советы начать простого скелета это методология не требуют никакого специального дорогого или проприетарного программного обеспечения вы можете ее сделать при помощи файловой системы где вы храните все и guitar больше ничего не нужно то есть сам простом виде в котором я это видел страницы в те это данные хранятся в джейсон ямал либо в самом гите либо реалом артефакты хранятся файловой системе и workflow реализовано гид lapsi алина дженкинс и мы рекомендуем интегрироваться своим горками для экспериментов как можно раньше в идеале в самом начале слышали уже продукт фрибурге пмр flow про девисе есть еще ряд фреймворков здесь концепция такая что если ваш дпс уже используют фреймворк для экспериментов там уже очень много ценности там же есть версии уже можно говорить о повторяемости логирование параметров экспериментов и всего такого вот осмотрит очень полезная вещь дальше мы советуем связать ваш фреймворк аналитик ubs с дата каталогам и do the pipeline ими зачем это нужно но прежде всего у вас появляется возможность аудита например если вы в европейской резекции tab a jedi pr вы должны сказать из каких данных была обучена эта модель если это персональные данные второй момент от упрощают регулярно и переобучение то есть вы можете отследить вот эта каталога что появился новый инст нас новый экземпляр datasette а который используется использовался в других моделях тогда вы можете автоматически толкнуть при обучении мой можно сделать регулярно переоценку аналогично на 100 то цветами для оценки и такая рекомендация написать свой сервис для метаданных яркий страции это то что делают наши клиенты это то что делаем мы вот в этом проекте с дроном и пример такой реализацией буквально вот краткая покажу то есть здесь у нас самый простой spring бутовый сервис который который следит за готовым репозитории по изменению китом репозитории он запускает 4 workflow обучение оценки governance & diplo мента и дальше мы цепляемся просто уже гид flow битла psy ai дженкинса обучение может происходить где-то на клоуна кубер не тисе дипломе может происходить hadoop и и так дальше такой сервис сильно упрощает жизнь то что он позволяет вам автоматизировать ответы на те вопросы которые могут создавать вам ваши т.к. сайнс ваши специалист по качеству данных или ваши аудитора мой главный совет не мешать да это сайнс дело в том что мы находимся и как говорил в рынке где-то the summit очень дорогой это люди имеющих правил башевис компании и если вы как я инженер работающий войти и вы поспорили это сайнс да это скорее всего окажется прав хотя бы в политическом смысле ну и в конце я хотел сделать вот этот шлем с флаг прекрасный проект лакмус под эгидой лиза alert он занимается разработкой вот этих вот нейронных сетей для поиска людей через фотографии ипподрома он открытый вы можете присоединиться к нему через сообщество опыт да это сайнс и особенно если у вас есть инфраструктура в россии с gpl для переобучения поймать меня потом нам надо поговорить и вы готовы пожертвовать отлили зарядки небольшом там tesla в 101 1 я больше не прошу на этом наверное все прошу задавать вопросы спасибо вы сентри задорожный примите благодарность давайте перейдем к вопросам и за самый лучше вопросики нефть любви падальщик здравствуйте спасибо за интересный доклад вот вы упоминали что вы разворачивайте вашу систему не только где то там в облаке но еще на ноутбуках вот как в таком случае выстроить процесс доставки обновления например на ноутбуках см и следовало в топах или на на лаптоп ах ну случае если это работает на лаптопов то нам нужен где-то в какой-то сервер для совместной работой хотя бы 2 да это сайт это просто может файл файловый сервер в таком случае мы на файловом сервере просто кладем то что нам нужно царство данные модели и договариваемся о том как выглядит метаданные просто джейсон файлы или яму файла пиона формате и дальше мы обсуждаем вот например у меня есть коллега да это сайте рст мы с ним обсуждаем как эти файлы формируют ученых к эта модель хочет за тепло и пишет он создает новый джейсон файл для описывает там пишут gytrash из какой версии ge то он хочет построиться ссылку на datasette буквально пути например но там же файловом сервере им этот женщин файл дальше храним и используем его вот в таком сам сам простом виде совсем один ноутбук наверное ну кого если вы один пользователь то вот вам на дно ноутбуке можно его как файловый сервер использовать но если у вас уже двое то надо какое-то общее сироп для этого иметь спасибо здравствуйте спасибо вот вопрос вот какой вы неоднократно упомянули что дата-сайентистов очень дорогой человек в компании а с другой стороны вы упомянули про авто м.л. и вот соответственно здесь вопрос что вы вкладываете в понятие html и правильно ли это что вот вообще этот какой-то автоэмаль есть ведь то что делает дата-сайентистов достаточно сложный трудоемкий процесс и вот например мы рассматриваем что автоэмаль это какой-то начальная стадия то есть что можно сделать без дата-сайентистов какой-то дефолтный workflow который потом от которого потом мы будем уже плясать и повышать качество вот именно разработки и разработчик впоследствии он не постоянно сидит выкатывает новые версии а вот когда бизнес понял что модель перестала его удовлетворять он нажимает вот эту некую кнопку и по этой кнопке не выкатывается новая версия а приходит сообщение разработчику что давай-ка начинает думать об улучшении текущей версии ну что такое авто и мы как бы интересно и понимание отель я не встречал честно говоря такое раньше то есть для меня автоэмаль это такой ускоритель некоторых видов деятельности который делает это союз фичер инжиниринга вот этих всех аспектов больше больше автоматизации вокруг этого когда вы можете одну модель использовать для выбора fitch для такой модели на ушло на в таком виде и поэтому я бы наверное не рассматривал это как маша людям без да это сантис это сайте все равно нужен вот но all time или действительно на некоторых предметах областях это классное ускорение у вас например может быть разработка новых фич происходить независимое в этот автомобиль отбирает эти фичи сравнивает их на машину и используют их в новых моделях но для построения этого конвейера вначале и посреди мониторинга вы сказали какой-то момент нам нужно понять что у нас дрифт случилось оно там статистические оценки вам нужен человек который хотя по статистике понимает поэтому до автомобиль просто ускоритель в этом смысле вот в контексте моего кого на секундочку извиняюсь я конечно далек от этой цели но попрошу не растягивая такси на свои вопросы быть покороче и поконкретнее спасибо большое спасибо большое за доклад расскажите пожалуйста вы уже столпились истории автоматического отслеживания деградации модели если да то как вы решать какие метрики вы смотрите систему не творить эту историю да ну тут действительно эта часть которая делает это сайте рст я когда-то был сетевого в одной компании которая делала машинный как сервис и у нас был такая золотая метрика prediction stability index is ой как на которой мы молились это был кредит и скоринг вот но я не тот сандерс я инженер я просто вижу как бы вокруг чего это все построено обычно это набор статистических оценок это распределение те живут статические тесты на стабильность лучше конечно это спросить нашего рак в этом смысле не пробивает ничего властями это просто часть мониторинга обычно так спасибо за доклад они могли бы вы по поводу дороговизны дата-сайентистов оценить стоимости ну и при на емкость автоматизации всех четырех марк флопа которые вы говорили но вопросы с визитом с картинкой гугла до что чистый дата sites to the sun с которой вот именно наука занимает ну плюс минус наверно процентов 5 10 от всего что вокруг тут надо сказать что то как я рассказывают об истории четырех workflow она конечно не покрывает от инжиниринг штаты в картинку глодать инжиниринг это цифра большой до от всего этого то есть эта вся часть связанные с получением преобразованиями данных эту часть стоит автоматизировать это однозначно но если говорить про вот аналитик ubs то это делается буквально одним инженером там за пару недель даже если нет никакого готового framework а заранее это очень в сам просто видео я показывал это очень-очень просто выглядит это больше нужно не только для ускорения работы да это sens но больше нужно как такой стандартный язык взаимодействие айти это это санс форматов и катки моделей то есть все мы здесь договариваемся о том как выглядит эти артефакты и как часть который нужно в регулируемых отраслях чтобы пришел аудитор и мы могли что-то им показать это так небольшая нагрузка просто если можно пожалуйста вермут дантисты они привыкли работ с питоном но бывает что например нам надо скурить на потоке да и там у нас например там джим то вы в этих случаях конвертируйте модель для или когда говорить с между двумя платформами то что чистом виде а если наджаф запускать там бетонных будет да это будет тяжело ими так быстро уже но здесь есть несколько вариантов мы смотрим как выглядит процесс моделирования то есть что это за модель и спит он такой прибор конкретно используются самые популярные в энтерпрайзе например подход этапе mml тревино workflow это барахло вокруг формата пмл это открытый формат серии зации моделей он такой довольно кондовый ну не все поддерживать далеко не всеми человеку не все но часть enterprise of там где у вас не очень сложная логика он он он работает особенно если у вас например счас используется для разработки модели они они выдают пином и в другом случае мы у нас есть такая оснастка мы выставляем модель как и пьянь но потоки и у нас там у стандартных интересовал jaar писи в зависимости от требований скорости и людям которые отрабатывай стриминга приложение мы выдаем 3 и просим их интегрироваться и вот тогда по это просто выход к новой модели этого кота новые инстанции сервиса который используется для inference а и еще вопрос по технологиям да вот эти фромборке платформы котизм из них использовали вот типичный дунаем отеля что можете посоветовать тандыр из workbench предлагает ну ка дар workbench это все-таки больше ноутбуки куда где ждет жизнь сами фреймворке маши игра на грани другие с ноутбуками на самом деле такая история что они конечно в инженерном смысле это просто безобразие да то есть там ноутбуки этому буки которой нельзя нормально хранить детей это джейсон файл то есть между ними div и нельзя сделать в них нельзя нормальная функция адресовать то есть это известно известная проблема мы обычно рекомендуем использовать то с чем то союз наиболее продуктивен как и говорил тот самый дорогой человек кнопка если мы вот сами инженер по чердаку поговорим the data сайнс это люди которые не делают деньги большой корпорации если у вас есть модель которая чуть-чуть юнит какой-нибудь вот у нас в производстве есть такая вещь как гарантий на резерв это куча денег которую держит автопроизводитель на случай если все гарантийные сломается им надо будет за свой счет компенсировать гарантию чуть-чуть подтяните модели покажите что вы можете на одну сотую меньше гарантийный резерв даже в какой-нибудь от шкоде это сразу там 10 миллионов евро свободных денег это это люди которые реально делают из данных деньги и мы здесь обслуга такая это нормально якобы я без каких-то коннотаций говорят и я иду от того что мне нужно сделать так чтобы трение между это со ин сон и все инженерии дат инженеры из автор инженерии было минимальным и давайте последний кусочек задаст не так ситуациях данные изменяются некоторые частотой то есть они непостоянные и на хотелось бы как-то автоматически оценивайте на новых данных новые модели вы думали возможно ли это как-то автоматизировать этот процесс это вот скажем в кредитном спарринге где у вас вот этот учитель до данное для обучения и данные для оценки поставляются постоянно потому что это дано и скажем о дефолте или таком это буквально pipeline аналогичных любом этель pipeline у когда у нас формируется но вот это сет мы скажем забираем его по размеру dota сами сказал какой-то сиськи нужный размер изнашиваете или framework или pipeline фреймворка дергается аналитик ubs и говорит вот эту обученный модель период цени пожалуйста новым быть с этим очень все так прямолинейно теперь задать самый мне понравится вопрос про у тайны я под не слышал такого определения да спасибо большое"
}