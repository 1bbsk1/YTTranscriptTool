{
  "video_id": "8aWwRgorR4U",
  "channel": "HighLoadChannel",
  "title": "Фаззинг или тестирование мусорными данными / Максим Бакиров (2ГИС)",
  "views": 2180,
  "duration": 2257,
  "published": "2020-04-27T13:27:05-07:00",
  "text": "меня зовут бакиров максим я работаю в компании 2гис в качестве разработчика на языке си плюс плюс я работаю в команде поиска часть нашей команды можете видеть на слайде наша команда ответственна за разработку поисковых алгоритмов приложения это та самая функция которую также можете видеть на слайде это кейс и когда мы с вами как пользователи ищем какую-то информацию об адресах об организациях в интересующих городах и на первый взгляд выглядит достаточно просто мы вводим какой-то поисковый запрос происходит магия мы получаем результат ура ура все хорошо но помимо текста запроса поисковый запрос может содержать около двадцати пяти разных параметров и это такие данные как местоположение пользователя участок карты который видит пользователь информация о его персональных предпочтениях и прочая прочая служебной информации которую мы используем в наших алгоритмов плюс к тому пользователи могут искать на карте могут строить маршруты из одной точки в другую . могут искать допустим магазины в бизнес-центрах в торговых центрах и каждый из этих режимов накладывает свои особенности обработки параметров поискового запроса и естественно ним и как разработчики не наши тестировщики не в состоянии предусмотреть все возможные комбинации параметров поискового запроса и тем более гарантировать что во всех режимах любой запрос будет работать стабильную и надежным в то же время нам хочется быть уверенными в том что поиск работает при любых поисковых запросах в любых режимах адекватно не происходит никаких падений и поэтому мы задались вопросом а есть ли какой-то способ быть в этом уверенным или хотя бы быть более уверенными в этом и сегодня мы как раз поговорим о таком подходе к кв 1 тестирования я я расскажу о том что вообще такой фазе тестирование затем мы с вами погрузимся в тонкости устройства фазе нга на примере библиотеки ли pfizer и я буду рад поделиться нашим опытом внедрение этой библиотеке этого подхода в pipeline разработки поиска 2гис итак fighting это такой подход к автоматизированному тестированию который предполагает генерацию случайных неожиданных каких-то совершенно неадекватных входных данных и передачу вот этих мусорных данных на вход а целевой тестируемые функции с целью спровоцировать в ней какое-то неожиданное поведение баги возможно даже спровоцировать аварийное завершение этой функции этой программы и мне кажется ближайшей аналогией мы можем назвать monkey тестирования да то есть тестирование пользовательских интерфейсов с помощью хаотичного набора манипуляции с целью опять же найти обнаружить какие-то проблемы окажется можно назвать monkey тестирования частным случаем файтинга то есть частным случаем тестирования с помощью случайных данных и на первый взгляд может показаться неочевидным как с помощью каких-то там случайных сгенерированных данных мы можем обнаружили функции какие-то проблемы как вообще мы можем извлечь из этого пользу будет ли это вообще работать и чтобы ответить на этот вопрос я предлагаю взглянуть на слайд и предположим что у нас есть функция которая принимает какие-то разнообразные входные параметры и с вероятностью одна миллионная в ней происходит бак мы можем утверждать что практически наверняка функция от работать стабильно при очередном вызове но если мы подготовим достаточно большой корпус входных параметров и будем вызывать функцию ну например миллион раз то мы обнаружим что вероятность стабильные работы уже меньше половины и значит мы можем достаточно близко подойти к тому чтобы вызвать нее бак найти какую-то проблему соответственно разобраться починить и сделать эту функцию более стабильный и надежный в этом основная идея за примером давайте обратимся к реальной жизни и я хочу спросить вас попросить вас поднять руки тех кто знает что это за логотип кто узнает что это такое давайте поднимем руки тогда знают знаете отлично а если я скажу что это логотип уязвимости под названием hard blit давайте подними руки те кто слышал что такое hard блит больше людей слышали чем виде little ага тип я расскажу подробнее чтобы все мы были в курсе и так show 2011 год библиотека open сесиль активно развивается и на минуточку это библиотека которая стоит за шифрованием соединений защищенным ресурсам в сети эта библиотека активно развивается и по иронии судьбы 31 декабря 2011 года в код этой библиотеке попадает новая фича под названием hard бит которая позволяет устанавливать зрительные соединение без необходимости повторные период тори зации и чтобы хорошо счастливый разработчики идут праздновать все релизе от в праздники в новый год в пятнице правильно и все бы хорошо но вместе с этой фичей в коде библиотеки возникает уязвимость которая открывает доступ к несанкционированному чтению памяти клиентов памяти серверов и по сути дает злоумышленникам в руки любую информация которая то может быть это могут быть cookies пользователей логины и пароли могут быть даже закрытые ключи шифрования но самое страшное даже не это а то что публично этот бак был обнаружен лишь спустя два года и к тому моменту порядка 17 процентов всех защищенных сайтов в сети были подвержены этой уязвимости около полумиллиона сайтов почтовых клиентов платежных сервисов сайты крупнейших банков по всему миру были подвержены этой уязвимости вероятно это одна из самых потенциально вредоносных уязвимостей вообще но к счастью сегодня существуют инструменты которые позволяют обнаруживать подобного рода баги очень быстро буквально за секунды они за два года и делают за нас это в автоматическом режиме и одним из таких инструментов который мы сейчас с вами обсудим является ли pfizer значит ли pfizer эта библиотека которая требует встраивания в код приложения и требует реализации одной функции в которую он будет передавать сгенерированные случайные наборы байт и даже эта функция должна их передать в целевое приложение целевую функцию с тем чтобы протестировать значит исходя из этого факта ли pfizer из коробки неплохо подходит для тестирования таких утилит как а парсеры регулярных выражений криптография компрессия словом утилиты которые работают должны работать стабильно на любых входных наборах байт значит почему мы выбрали именно ли pfizer почему выбрали эту библиотеку в поиске во-первых наш поиск написан на языке си плюс плюс ли pfizer также написан на языке си плюс плюс и предоставляет удобные api для интеграции и даже адаптации этой библиотеки под специфику конкретного приложения другой немаловажной причиной является то что наш поиск это кросс-платформенный продукт который мы собираем тремя пожалуй основными компиляторами языка си плюс плюс в том числе компилятором clang и кланк имеет широкую экосистему которая включает множество инструментов для диагностики выполнения программы построения отчетов покрытие кода и естественно мы в рамках нашего клан к pipeline а ими пользуемся али fazer также является также входит в экосистему clang поэтому для нас было достаточно легко подключить еще один инструмент в наш pipeline разработки поиска конечно нельзя не упомянуть хорошую документацию туториалы и что самое интересное можно в интернете скачать примеры софта в котором ли pfizer находит уязвимости и в том числе скачать ту самую уязвимую версию окон сиссель сразу слив азерам запустить ее и убедиться что ли fazer обнаружит hard блит очень-очень быстро разобраться с тем как работает ли pfizer я предлагаю на примере простой игрушечной функции которая принимает на вход массив символов размер этого массива делает внутри какие-то проверки и возвращает результат я хочу спросить вас видит ли кто-то в этой функции какие-то недостатки шероховатости может быть даже баги давайте посмотрим повнимательнее подними ru последняя строчка до в яблочко очень просто действительно если мы передадим эту функцию вот такую строчку фас функция проверят первый символ он окажется равен f второй символ you и третий символ z функция проверит все три символа которые были переданы но попробуй проанализировать 4 символ которого никто не передавал эту функцию и соответственно которое лежит за пределами этой области памяти которая была и предоставлено это практически наверняка говорит о какой-то опечатки какой-то проблеме что-то здесь не то или fazer ли fazer ориентирована на нахождение и на поимку подобного рода багов на следующем слайде я хочу чтобы мы с вами увидели как это произойдет мы запустим в окне терминала ли pfizer он будет печатать для нас строки которые генерируют и которые передает в эту самую целевую функцию до тех пор пока не обнаружит именно вот эти самые три символа также он напечатать нам отладочную информацию stack trace информация в ошибки и и так далее давайте посмотрим так здесь должен должен быть терминал хорошо здесь нет терминала на представим что он есть ли pfizer ли fazer генерирует строки которые выглядят совершенно неадекватно передает их в целевую функцию и довольно быстро обнаруживает баг в этой самой функции фазами который мы только что видели и конечно это игрушечный очень простой пример в котором в принципе все более или менее очевидно реальные проблемы случаются в коде в котором подобного давайте ещё раз посмотрим подобного рода проверки могут быть разнесены друг от друга на сотни и даже на тысячи строк кода могут скрываться под вызовем и других функций могут зависеть от вычисления третьих переменных и в таком случае нахождение подобного рода багов может оказаться задачей нетривиальной или fazer как раз пробует находить такие баги показывает нам что произошло и сопровождает все это информации с которой мы можем воспроизвести и бак и соответственно его починить как это устроено как это работает чтобы ответить на этот вопрос я предлагаю поэтапно обсудить fighting и сперва взглянем на общую картину как же это устроено скажем буквально пару слов про кажи это первым делом ли fazer прогоняет тестовый корпус но о нем я расскажу чуть позже далее вызывает целевую функцию анализирует ход ее работы определенным образом на к плевы это тестовые наборы который он сгенерировал их мутирует как-то меняет и повторяю до тех пор пока не найдет баг после чего оставляет артефакты так это устроено в общем в двух словах начинается все с того что мы говорим клан гу о своих намерениях и он подключает дополнительный инструмент под названием сани тайзер коврик этот инструмент снабжает код программы дополнительным кодом который позволяет обрабатывать и анализировать ход ее работы прям уран t'aime и плюс к тому позволяет перед обрабатывать такие операции как обращение к массиву сравнение двух целочисленных например и прочие вещи с анитой зеркал используется множеством инструментов экосистемы clang и в том числе pfizer ли pfizer получает из этого инструмента таблицу инструкции из которых состоит программа грубо говоря набор адресов из которых состоит программа и пробует генерировать входные параметры для целевой функции и при этом анализирует покрытый код каждым конкретным тестовым юнитам таким образом сопоставляет покрытый код с общим ходом программы и такие тестовые наборы которые дают максимальное покрытие всего кода максимально разнообразно и покрытие кода откладываются в следующее поколение и по достижению определенной критической массы начинают эволюционировал начинают меняться с помощью с помощью из механизмов самого лимфа zero под названием мутаторы мутаторы это такие такие механизмы которые просто напросто удаляют байт могут вставить байт поменять местами два байта выставить какой то бит словом делаю что-то очень простое и на слайде я привел 3 или даже половину тех ему татаров которые ли fazer предоставляет из коробки слома это что-то совсем примитивная для работы на уровне на уровне байт и естественно в этом кроется проблема потому что большинство программ работают намного более структурированными входными данными и наш поиск не исключение как я уже говорил поисковый запрос содержит множество параметров и представляет собой достаточно сложную структуру состоящую из списков других структур например из списков точек из списков строк из перечислений и тому подобное и поэтому подобного рода запросы очень плохо ложатся на сырое набор байт и когда мы приступили первой итерации мы не получили ничего ничего лучше множество исключений которые говорили нам о нарушении формата поискового запроса поиск просто отказывался с ними работать тогда мы вспомнили про те самые протоссам и решаемые api и вот тут оно и выходит на сцену она позволила нам написать наши собственные пользовательские мутаторы и научили тем самым ли pfizer менять каждый конкретный параметр поискового запроса сохраняя в целом валидность ну его валидность поиск стал лучше относиться к таким запросам но множество алгоритмов которые работают с этими параметрами либо игнорировали данные потому что они все так же состояли по сути из случайного набора байт только уже более структурированный в правильном формате либо также бросали какие-то более разнообразны исключения и тогда мы сказали эй fazer а ведь у нас есть информация об организациях об адресах об улицах москвы новосибирской и прочих городов используя ее для того чтобы сгенерировать поисковые запросы значит перед запуском лимфа zero мы даем ему эту информацию которую он использует в наших ему татарах и получаются запросы которые в целом выглядят валидный имеют правильный формат и каждый параметр этих запросов также имеет правильный формат и более того содержит абсолютно реальные абсолютно адекватные данные конечно человеческой точки зрения это полный мусор и какая-то ерунда но поиск видит верный формат и пробует что-то искать по таким запросам совершенно справедливо и иногда даже ли pfizer ли fazer удается сгенерировать поисковые запросы по которым есть какая-то результативные поисковая выдача то есть о чем идет речь поиск вообще как результат представляет какую-то выдачу она может быть пустая да когда мы видим что вы не по вашему запросу ничего не нашлось либо может содержать какие-то результаты и тогда можно сказать что выдача результативное так вот когда мы видим результативную поисковую выдачу по запросам сгенерированным лив азерам мы считаем что fighting удался что это эффективно и эффективный инструмент потому что нам удалось затронуть большую часть наших алгоритмов оценку результатов их перри сортировку и прочие-прочие вещи значит ли fazer смог доставить свои свои мусорные данные до каких-то уголков основных уголков нашего поиска но мы на этом не остановились и мы сделали следующее мы разрешили ли pfizer у мы решили скрестить наш высокоуровневый генератор поисковых запросов которые используют ли pfizer с его примитивными му татарами которые работают на уровне байт и сказали мы попробуй как-то искажать портить на уровне байт наши поисковые запросы и отдавая их поиск тем самым далее лимфа зиру в руки инструмент для нахождения баланса между мусор ностью поисковых запросов до какой-то ерундой и сохранением его адекватного формата найдя какую-то проблему какой-то баг в поиске либо в каком-то другом софте на даже в той самой примитивной функции которые мы видели и pfizer у важно понять что произошел какой-то баг и сделать это с помощью таблицы со всеми инструкциями и покрытым кодом достаточно сложно поэтому или fazer подключать дополнительные инструменты из той же экосистемы клан га под названием с анитой зиры с анитой zara это такие инструменты которые получают информацию из они тайзер ковыряешь и имеют свои собственные алгоритмы свои собственные эвристики на предмет каких-то багов в ходе выполнения программы это могут быть баги связанные с дата рейсом в случае с многопоточные средами либо связаны с утечкой памяти с обращением к массивам по неверному yandex обращение к не инициализирован им переменным и тому подобные вещи можно сказать что ли pfizer сам по себе тоже является сани тайлером который использует еще другие сани тайзер и обнаружив какой-то баг саня той веры сигнализирует об этом ли pfizer перехватывает этот сигнал и печатает проблемный вопрос да проблемный тестовый юнит который в данный момент обрабатывался печатает stack trace информацию об ошибке и прочие вещи с которыми мы можем работать можем воспроизводить этот баг соответственно разбираться и более-менее льву его легко починить вот как-то так это устроено так выглядит основные этапы работы файтинга я предлагаю еще раз взглянуть на общую картину в целом чтобы закрепить то что мы поняли и я расскажу про тестовый корпус как обещал значит тестовый к apus это такой трюк для улучшения эффективности работы файтинга и заключается он в следующем еще до начала файтинга мы предоставим мы собираем такой тестовый корпус входных параметров для программы для функции на которые она рассчитана которое она на которых она адекватна совершенно правильно работает и этот тестовый корпус должен содержать разнообразные тесты в июне ты такие такие входные параметры которые по максимуму задействуют весь функционал этой функции все его содержимое это важно для того чтобы ли pfizer еще до начала файтинга собрал максимум информации о том какой именно тестовый у не дает определенные покрытие накопил их в поколение для последующих мутаций и тем самым сэкономить уйму времени на генерации на получение того же самого покрытия дали или pfizer вызывает целевую функцию передает е зап придут и тестовые юниты либо из корпуса либо сгенерированные с помощью sanitizer кого врач оценивает ход ее работы такие тестовые наборы которые дают максимальное покрытие подбираются для мутации в следующие поколения мутируют с помощью встроенных мутатор of либо с помощью пользовательских мутатор of и так повторяется до тех пор пока ли pfizer не обнаружит банк либо не истечет время его работы либо число запусков какие-то опциональные условия выхода если был обнаружен баг или pfizer оставляют артефакты которые говорят о том какую который говорят о проблемным тестовым кейси и могут быть могут говорить нам о об аварийном завершении программы либо про тайм-аут и случай зацикливания либо про слишком медленные тестовые юниты да это может быть неприемлемо какие то такие вещи что у нас получилось в поиске что мы добились применив file and как подход значит мы нашли порядка десяти потенциальных краше в нашем поиске и какие-то из этих краше были сугубо теоретическими но некоторые таились в задача которые были сделаны были протестированы и дожидались только лишь интеграции на бой прежде чем оказаться в руках у пользователей мы внедрили ли pfizer в наш pipeline разработки запускаем его на регулярной основе и с помощью этого также можем оценить регрессию о чем идет речь ли pfizer умеет обновлять тестовый корпус который мы ему предоставили делают он это так что обнаружив тестовый юнит который даёт новое покрытие кода программы такой запрос откладывается в тестовый корпус и таким образом постоянно пополняется постоянно обновляется расширяется есть отдельные инструменты для работы с этим тестом корпусом о том как его уменьшить и прочее но фактом что ли fazer умеет обновляя тестовый корпус и когда обнаруживает какой-то баг когда обнаруживает проблемный тестовый юнит он естественно попадает в этот тестовый корпус и в будущем мы уже подчинив этот баг можем быть уверены что его его больше нет да при следующем запуске fazer а однажды это очень сильно сыграло нам на руку потому что наш разработчик столкнулся с проблемой столкнулся с тем что приложение подала под windows и только под релизной сборкой все отлично работало под отладочной версии под линуксом и вот только релизная версия windows почему-то подала ему пришлось потратить день или даже два на поимку на поимку элементарного на самом деле бага сродни тому что мы видели в той самой игрушечной функции он конечно его починил все было хорошо но потом в ходе одного из коралловых межиева огромной ветки в основную ветку этот баг буквально буквально восстал из мертвых снова возник в коде приложения но тут или fazer сразу я поймал сразу указал что вот вот вот это проблемный запроса такая проблема и конечно нам уже было делом техники его починить и потом быть уверены в том что его больше нет потому что тестовый у нет проблем на тестовую не тут оказался нашем корпусе и соответственно прогонялся последующем какие есть мысли на будущее есть идея попробовать так называемый перекрестный fighting то есть фазе нг одновременно двумя библиотеками для файтинга и хотим попробовать интегрировать fn fal это еще один очень известный fazer который также имеет широкий послужной список багов которые он находит или fazer и дает инструмент по легкой интеграции вот этого отеля с тем чтобы обмениваться результатами работы обмениваться тестовыми корпусами тестовыми юнитами которые дают разное покрытие и кажется что вместе можно получить энергию можно усе увеличить эффективность файтинга плюс к тому несмотря на то что мы очень сильно заботимся о скорости работы поиска постоянно снижаем потребление памяти и сжимаем наши индексы ускоряем саму работу поиска но в случае с фазером руки так и не дошли до того чтобы отлаживать и устранять медленные тестовые юниты это конечно стоит сделать плюс к тому наш мутаторы очень очень примитивные на самом деле и конечно их нужно улучшать можно им добавить больше гибкости больше настраиваемости чтобы сделать фазе нг лучше в качестве завершения я хочу сказать о том что сегодня все больше компании обращает свое внимание на фазе нг как подход пробует использовать его в рамках своих pipeline и в рамках своей разработки и меня особенно впечатлил один доклад ребят которые пишут компиляторы джавы если не ошибаюсь и использует fazer который пишет какой-то совершенно страшный жуткий java код который они скормлю свой компилятор и проверяет насколько правильно он работает сейчас я приведу ссылку на этот доклад очень интересно и я хочу верить что также как никогда unit тестирование стала неотъемлемой части разработки также и fighting все плотнее будет входить нашу жизнь и с его помощью мы будем мы сделаем наши программы более стабильными более надежными и главное главное избавим пользователей от таких страшных багов как hard блит и стресс на сделаем в более счастливыми я подготовил слайд со ссылками здесь ссылки на некоторые fazer и ссылки на на хард блит и обязательно посмотрите ссылку с инструкцией как скачать hard блит сразу вместе с фазером и убедиться что это очень быстро этот баг очень быстро находится также ссылка на доклад который только что упомянул да спасибо вам за внимание я буду рад ответ ответить на вопросы в зале либо в кулуарах также пишите мне в telegram либо на почту я я всем выбирать спасибо вам определить спасибо большое за доклад первый вопрос кто принял стратегическое решение применять этот подход разработка прибежала менеджер сказал что я тут на хобби нашел такую статью давайте попробуем или тестировщики сказали что слова для закончился мы не знаем чем еще ломать дальше вас поиск на самом деле дело было так что руководитель наши разработки давно слышал про этот подход смотрел доклады и ему показалось вот эта идея хорошие что попробовать максимальное количество комбинаций поисковых запросов проверить что они хорошо работают поэтому это все-таки инициативу был от руководитель разработки ясно спасибо меня считали маленький вопрос в селе баги вы исправляете после файтинга либо вы смотрите на вероятность того что пользователь сможет такое вообще ввести здравом уме и решаете что ну вот это можно и оставить но тут речь идет о богах сродни падением то есть аварийным завершением это что-то ну совсем неприемлемой поэтому мы сразу и в чине им вот как правило там нет чего-то сложного правило просто какие-то логические ошибки сродни лишнему инкремент у яндекса типа того поэтому сразу чинил приветствовать его доклад а просто три наверное первое это она в план разработки то есть в какой момент fazer запускается там до review кода или когда вы считаете нужным и запускать во второй про сколько он есть ресурсов и какова его скорость так ли pfizer запускается у нас автоматически и выбирается какая-то вент как правильно такая-то стабильная ветка ну например мастер то есть мастерим его запускаем и соответственно это происходит уже после review после влить я задачи но в эту ветку сама задача по себе не проверяется уже такого мастера то не знаю налили 10 задач и потом уже ловим проблем но не так мы и делаем один раз так делали на очень большой задачи которые вот как раз наш разработчик levall но обычно это на какой-то одной ветки просто прогоняется на выходных так про ресурсы да но с ресурсами то есть я не скажу точно сколько памяти какой процессор но это машина чуть слабее чем машину среднего разработчика вот так то есть в среднем у нас по моему 16 оперативки там а i5 или i7 процессор средств на серверах чуть-чуть попроще которые мы используем вот то есть не какой-то супер железо насчет того как быстро работает тут очень сильно зависит от того какие режимы мы используем ну поиска то есть у нас есть режимы которые быстрее работ которые медленные зависимости от этого но скорость бывает разной но я попробую не соврать на я очень боюсь ошибиться мне кажется что то есть получается мы сутки он работает по моему сутки и чё-то типа 12 от 12 до 80 тысяч запросов прогоняется счет такое но я очень боюсь ошибиться честно говоря хорошо относитесь быстрота кайся и когда не знают релизимся почти по 30 на дачу день и вот как его встроить 30 задач в день ну fazer у конечно нужно время чтобы находить баги если у вас очень быстро какое-то приложение то есть чем быстрее работ приложение тем естественно эффективнее будет fazil то что он максимум запросов сможет но сможет обработать и быстрее находить баги не понял спасибо скажете вы используете статические анализаторы так статически дано раз по себе by check pvs-studio pvs-studio нет себе печать дома используя многие просто тот пример который вы провели его сто процентов найдет любой статически анализатор вот хотелось бы понять вот это соотношение то есть я знаю что fighting работают но хотелось бы понять соотношение для applications года то есть не регуляров не вот подобных вещей обычной бизнес-логики применен как ну то есть действительно ли он помогает там лучше чем статический анализатор applications коде ну или fazer заработает но в ран тайме из они taser и ну насколько я знаю есть не все то многие работают тоже в ран тайме и какие-то вещи можно только вратами обнаружить компилятором но не обнаруживается ну например обращение к ней из резервной переменной да насколько я знаю но не не получается на этапе компиляции однорукий получается себе печать не сможет за обнаружить эту проблему одной надеюсь это ответ на вопрос поэтому это разные инструменты и fazer бран тайны работает обнаружит росте спасибо за доклад скажите пожалуйста как вы выбираете размер словаря который проверять будет потому что его же можно уменьшить и тогда будет время меньше и как часто вы обновляете тестовый корпус имеет просто есть еще фишка у фазе райс фишка как словарь которая не упоминал это отдельная вещь тестовый корпус сначала мы выбрали просто какой-то ну там тысячу например запросов самых разных а потом ли pfizer начинает его наполнять начинает его наполнять дополнять но он растет и чтобы он не занимал слишком много времени на прогон и pfizer умеет его уменьшать но там порядка порядка мне кажется 4000 наверное запросов вот я тоже бы себе ошибиться с конкретными цифрами но честно говоря как-то осознанно мы не определяем размер вот этого корпуса вот так ну просто примеру можно было бы сделать совсем маленький словарь про к нам прогонять вот для каждого паре квеста полноценных примерно 1 сутки но может быть да да но тут надо разбираться что будет более эффективную шаблон долго-долго-долго работал либо там чуть-чуть работал не знаю нужно экспериментировать с этим спасибо и спасибо за ответы на вопросы пока мы выносим благодарность пожалуйста выбери лучший вопросах до кучи вопрос так что мне понравилось вот предложение про быстрый fighting вот отлично спасибо большая самом спасибо"
}