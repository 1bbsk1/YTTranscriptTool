{
  "video_id": "lCXuN43vQ8Y",
  "channel": "HighLoadChannel",
  "title": "Десятки ветвистых ETL-пайплайнов из сотен источников / Михаил Славошевский (ЦИАН)",
  "views": 2302,
  "duration": 3043,
  "published": "2020-04-14T11:19:49-07:00",
  "text": "что делать когда ваш продукт развивается столь интенсивно что для того чтобы удовлетворять потребности бизнеса вам приходится подключать все новые и новые источники данных тем самым кратно увеличивая количество ваших этель pipeline of 5 сложности при этом возникают и как не превратить жизнь этель разработчика ватт как закончить это четыре всадника апокалипсиса а я между слова шерсти я отвечаю за дата инженеры в компании циан вы скорее всего нас знаете если делаете что-либо связанные с недвижимостью в интернете аренда продажа ипотека оценка вот этот все про нас значит мы за последние пять лет довольно активно набираем обороты и штат разработки за последнее время мы увеличили в 10 раз все эти люди занимаются каждый день тем что пилит новые фичи для наших драгоценных пользователей а новые фичи порождают потребность во всякой разной аналитики и для того чтобы ее проводить нужно много разных данных мы собираем действительно разнообразное количество всякой информации это может быть extreme то есть действия пользователей на сайте в приложении кто куда заходил что нажимал сколько времени там провел это могут быть какие-то боковые события где-нибудь пользовательские платежи изменению логов объявлений ну то есть какие то данные изменения ну и заменой области знаний ну и это может быть например что-нибудь сугубо технической а какие-нибудь access логин drinks а какая-нибудь телеметрия с фронта какие-нибудь метрики здоровья приложений все эти события мы отправляем в краску формате джейсон оттуда мы заботливо их перекладываем в ходу и дальше они мигрируют в красивые структурированные разложенные таблички в ходе почему hive ну потому что из первых универсальный язык который под силу широкому кругу пользователей будь то аналитик разработчик инженер кто угодно значит дальше эти данные уже is high во разлетаются по потребителям например это может быть какие-то модельки машинного обучения которые ранжирует выдачу делают рекомендации что-нибудь такое или ищет лохотроны на нашем сайте q их еще немного осталось а ну или это может уходить какую-нибудь бизнес-аналитику какая-нибудь регулярная отчетность какая-нибудь продуктовый анализ чтобы понимать куда мы развиваемся и где сейчас находимся значит для того чтобы это все работало чтобы все люди могли делать свою работу просто и легко нужен какой-то общий котел где все это будет вариться ну или платформа основной ее задачей является чтобы каждый человек в команде которому нужно или пришлось создать новую регулярную джаббу мог это сделать быстро просто и без каких-то безумных усилий такая платформа может помочь вам пережить вот такой вот рост когда у вас кратно увеличивается количество pipeline of у нас такой платформы не было и вот этот период мы проживали довольно болезненно оставил нас была у нас было некоторое количество репозиториев довольно крупных где большом запускался успел и все хорошо значит какие проблемы с этим могут быть казалось бы ну собственно когда мы начинали никаких проблем не было а при росте мы познакомились вот этими товарищами ну давайте с ними знакомиться плотнее вначале мы с вами обсудим зачем нужна вообще я артист рация pipeline of обработки данных какие плюшки она привносит и как ее можно использовать последствии мы поговорим с вами о дипломе телек действительно важно когда вы начинаете делать всё больше и больше задачек вам придется если вы это делаете руками тратить больше времени на никто раскатку поэтому это добро хочется как-то автоматизировать ну и об этом собственно обсудим потом поговорим зачем и как тестировать успели запросы ну и закончим тем как нужно поменять процессы разработки когда у вас не только количество задач и к растет и количество компьютеров людей которые делают эти идеи ну давайте по порядку начнем с артист рации давайте представим что у нас с вами есть какой-то pipeline данных он там каждый день считается какие-нибудь аудиторные показатели ск риск из клик стрима тащит какие-то показатели sbk вот это все как-то обсчитывает ну и в конце выдаёт отчёт что вот за сегодня сегодня мы находимся тут раньше находились там там там там неделю назад квартал и ну и дальше вся компания смотрит и понимает куда мы движемся давайте представим на минуточку что мы никак не управляем зависимостями что это означает это означает что у нас какая-то джабба могла например свалится а мы-то не заметили ну или например какие-то данные не подъехали а мы продолжаем считать ну что тогда коллеги увидят следующий день 0 и падение сто процентов паника очередь к чарам ну другие люди поймут что в чем дело ну значит что-то не так посчитал значит для того чтобы обрабатывать такие ситуации исключительные для того чтобы уметь управлять этими зависимостями нужен orchestrator во первых его задача первое чтобы у нас все выполнялись в каком-то органичном порядке а не абы как помимо прочего у нас носки могут валится по каким-то не систематическим причинам это может быть что угодно нужно готовиться к чему угодно и из было бы здорово чтобы артист ротар умел филиппины выйти пытаться переплыть тоски ну вдруг нормализовалось значит в этом в этой области человечество шагнуло давно я далеко вперед есть куча разных артист ротар of мы в сани используем луиджи это питоновский ну для пользователя который делает стельки это питоновский модуль и для того чтобы добавить новую тачку нужно не так много нужно от наследоваться в какого-то базового класса выгрузка и определить несколько переопределить несколько функций знаешь все отмазки могут быть параметризовано ну то есть какие значения можно передавать никто извне например дату исполнения а также в ходе мы прописываем зависимости то есть это тоска она должна считаться после того как выполнится 1 2 3 как считается что зависимость выполнишь то есть что тоска готова луиджи в этом плане отличается от остальных систем регистрации тем что выполнен из тоски эквивалентно наличию какого-то утку то выхлопа это может быть что угодно это может быть файле чек на файловой системе это может быть таблица в хайвее partition что угодно вы g довольно хорошо расширяется и любые капризы и фантазии он может удовлетворить если вам нужна какая-то специфичный put вы вольны его переопределить ну и собственно метод для запуска самой-самой тоски когда мы попытаемся запустить с вами вот эту сам task что произойдет вы же чахнет появился люди есть ли у неё тут если вы тут есть начнут идет ты не надо дальше будет строить граф зависимости ну в нашем случае он должен простой а и будет исполнять по очереди все тоски и после того как все зависимости выполнены запустить нашу а при каждом переходе от одного звена к другому вы дополнительно будет чекать что помимо того то что танская не свалилась она еще породил out food который должна была породить ну и вот такой вот толпу мол вот я нашел такие тоски таки это не были выполнены я их исполнил все хорошо что еще хорошо луиджи сам что он очень хорошо расширяем и если вам что то не нравится вы вольны это переопределить вы собственно так и сделали мы написали свои modules xr шинами и разработчики у нас не использует родной луиджи а вот использует просрочку почему первое что мы сделали это переопределить работа луиджи sky вам потому что в дефолтной имплементации не очень хорошо работать также мы добили ли туда всякие утилитарные вещи которые нужны в каждой и тоски но который обрабатывает самостоятельно и мне хочется это сбор метрик по утку там то есть сколько мы записали если записали в какую-то табличку дальше все можно репортить в графа ну настраивать или рты и смотреть динамику или узнавать о том что что то не сработало он неправильно ну и сбор ошибок x опционов в стороннее системы например мы используем для этого центре где можно посмотреть для каждого кода для каждого файл а что собственно случилось каком контексте и где именно была проблема ну и мы ведь хотим чтобы нашу платформу использовали разные люди вы же очень прост для разработчиков но если речь заходит о например каких-нибудь аналитиках которым не задача которых разбираться в том как устроена код им нужно какой-то простой интерфейс мы собственно его и сделали все что нам нужно для того чтобы добавить новую темку хай богу это от наследоваться task ну от базового класса переопределить схем таблицу дату начиная с которой это все будет считаться и поле из которого забирать меточки ну то есть да да ты сегодня мы записали 8 миллионов записей ну значит будет фильтровать по этой дате и запишем в графон нуаре кларис это стандартный метод значит когда следующий раз мы запустим эту тоску луиджи будет искать spellcheck который лежит в том же модули что и код этой клан тоски пеленочки все параметризовано да ты вполне естественно для того чтобы если вдруг мы хотим с вами пересчитать что от задним числом понимаю что есть такая потребность где-то мы ошиблись что-то читаем неверно ну или применять логику мы это можем перри проиграть значит как обычно все у нас устроено обычно мы набираем разные всякие данные за ней ночью запускаем митенки которые все как-то агрегирует и насчитывают за вчера то есть ночью считают за вчера за прошлый день что произойдет если я неаккуратно запущу эту тоску сегодня за сегодняшнее число она считается у небе появится out put но output будет ну состоять из неполных данных и тогда дальше во все остальные pipeline у нас пойдут данные из не закрытого периода времени и во всех таблицах быть чушь значит для того чтобы такого не было мы чуть-чуть переопределили доит параметр мы и не разрешаем запускает за дату не прошлую то есть если ты запускать что за сегодня вероятно ты ошибся хорошо протест рацию поговорили был у нас четыре больших репозиториям на большой плюс успел теперь четыре больших рыб репозитория на питоне и масштабе плавится просто где пальчик поехали а потом ну значит думать как бы мы хотели вообще чтобы это все размещалась у нас в инфраструктуре первое чего хочется это наверное иметь какие-то скрипты запуска в репозитории если вас если ваш регистратор не поддерживает собственного тренинга и всюду линга вторых хочется наверное чтобы разные деньги могли запускаться в разных окружениях потому что ну не знаю по какой-то причине какой-то индийский pipeline использую панда с одной версии а другой использует панда совершенно другой версии вот надо как-то это разнести ну и хочется это все автоматизировать чтобы не тратить время на выкладку ручной труд и если вдруг нам придется мигрировать на машину на другую но это все можно автоматически пири-пири деплоить не скатываюсь какую-то ручную рутину что мы с этим поделали завели отдельную машину куда же вы не ходят там есть вот один пользователь framework луиджи пользователь мая его задача что под ним настраиваются краны и только из поднимает все запускается то есть живые под собой панчер живые под собой ничего там не запускают не настраивают ну и для каждого и теперь процесса мы настраиваем отдельное виртуальное окружение тем самым изолирую их друг от друга ну коли уж виджетом капитанским пакет-то и и деньги должны быть тоже сформированы как пакета то есть мы там храним вот собственно сами шпильки кот за с досками и обратить внимание во первых sata пай который позволяет нам из этого всего делать пакеты заниматься таким пакетирование во вторых политик с кранами он выглядит примерно следующим образом это какой-то идентификатор тарский крон выражения которое можно будет уже в последствии автоматически настроит в машине значит в итоге тепло и и телек состоит из трех несложных шагов настроить виртуальное окружение настроить краны ну и для истории было бы неплохо сохранить этот модуль где-то ну мы используем в качестве хранилищами японских артефактов двп на самом деле это все замечательно и автоматизируется мы используем такой инструмент как я забыл он позволяет выполнять удаленные задачи на разных картах и даже группу на разных группах хвостов и в специфичном политики формате ямы мы описываем что последовательность действий которые мы хотим на них использовать все эти стельки теплица одинаково поэтому если нам придется копировать вот все вот эти шаги из репозитория в репозиторий получится что-то такое ну недостаток виден да но это единственное что видно значит для того чтобы этим не заниматься и не переносить нечитаемый код от репозиториях репозиторию мы за использовать или такой прекрасный инструмент к galaxian забыл он позволяет вам иметь репозиторий с общими ролями которые на которые можно ссылаться из других репозиториев при деплоя и каждый раз когда мы будем запускать нашем выпуске playbook который теперь уже выглядит гораздо более компактной и четаева мы можем ссылаться на вот томске определенные в этом общем репозитории это очень удобно с одной стороны представьте что мы хотим что то поменять в наших процессе например при заливке пакетов двп хотим писать в сраку друзья у нас вышла новая версия и тельце возрадуйтесь для того чтобы это сделать в такой системе нам достаточно просто переопределить общую роль и все изменения предстоит очень тепло и подтянуться из репозитария и с другой стороны с этим нужно быть очень аккуратным если вы возьмете себе на вооружение galaxy r был пожалуйста будьте очень аккуратны это отличный способ сломать все например он хорошо в итоге это выглядит как в итоге мы наш код сетей коми он оказывается в те запускается джабал джон квинси которая дергает энджи был которая тащит роли из был galaxy настраивать лесу дульные машине виртуальное окружение краны краны запускают собственные доски и тоски хорошо значит мы с вами разобрались с артист рации pipeline of разобрались с диплом и телек теперь давайте поговорим про тестирование почему она важна когда у вас очень много когда у вас почти весь этель на хайвее вам приходится внезапно сюрприз использовать ошибки и когда структура очень ветвистые этого репозитория внеся изменения в один какой-то кусочек кода вы можете сломать совершенно в другом месте логику все же помнят замечательную книгу рэй брэдбери где мужик вернулся в прошлое раздавил бабочку вот и услышал в настоящем уже звуки грома вносить изменения в успеем тоже в каком-то смысле путешествия во времени ты вносишь изменения в одно место у тебя ломается совершенно в другом ну от коллег вместо звука в грома ты слышишь немой вопрос значит тестировать успели нужно как и где можно руками это занимает много времени ну реально много времени очень много очень высок шанс ошибиться и вас история комментов репозитарий может превратиться лучшего что-то такое значит мы исправили опечатку исправили другую опечатку но и спустя полгода она заработал значит чтоб такого не было хочется это все как-то автоматизировано тестировать к сожалению мы когда приступили к этой теме мы не нашли ничего в немова чтобы подходило для регулярного тестирования шпиля поэтому мы не отчаивайся написали паузу сами давайте подумаем вот у нас с вами есть какая-то тоска судя по ее коду она обрабатывает данные ровно из одного источника но у меня только одна зависимость действительно ну там какая-то портянка с кого это агрегации как бы мы могли его протестировать что если мы бы с вами взяли вот эта табличка статистика статистика отличное название а и например создали бы какую-то другую с такой же схемой налили бы туда каких-то заранее определенных фейковых данных прогнали бы поверх нее эту истину и сравнили ожидаемый результат он же есть потому что данные заранее детерминированы с тем что получилось в итоге ну собственно так мы и сделали мы храним вот эти сосочки в репозиториях то есть мы пишем тестом на шпиль храним вот эти гольдин файлы в репозитории с ожидаемым результатом и с файлами которыми нужно макать входные таблички ну и как это выглядит вот у нас основной код какой то дальше в папочке тест есть отдельный модуль для хранения вот этих всех артефактов но и структура повторяется структура основного кода для того чтобы было понятно куда вносить изменения в двух тесто не работает ну и собственно сами тесты код их код мы написали свой helper который под капотом просто все запускает сверяет и если вдруг что-то не работает ну рейзит xf дальше это все запускаем по и тестом значит чем поняли после этого во первых очень хорошая практика один файл использовать ровно в одном тесте потому что я понимаю что есть соблазн протрясти все целиком сразу и быть очень уверенно во всем что происходит с другой стороны давайте представим ситуацию мы пытаемся даже не внести изменение в ходе давай придумаем добавить какой-нибудь один the space если мы правим одну ложку значит нам нужно править ожидаемый результат а если это табличка используется где-то еще у нас опять вот этот эффект бабочки мы начинаем везде все меня художник поэтому если поэтому предпочтительнее использовать один файл с маками на один тест еще бывает ситуация когда у вас таблички содержит 200 тот колонны довольно глупо их все определять в ваших the space их если например ваша ваш запрос используя всего 15-20 из них ну поэтому нужно на ту зулу если вы соберётесь такую же у тебя внедрять и адаптируя к тому чтобы можно было указывать только тех колонки которые вам нужны и после того как мы это сделали у нас вырабатывалось все было здорово до тех пор пока не свалился первый тест ну там чар там уже под капотом сравниваются 2 dataframe а ну они разные иди разбираюсь что с этим можно поделать но 6-ти за фреймы и глазами и не очень приятное занятие поэтому можно как-то разработчику подсказать что еще ошибку там как-нибудь намекнуть на самом ли деле одна строка в ожидаемом результате это по сути один-то space это не всегда так в общем смысле но мы стараемся делать именно так и вот зачем если это строка отвечает ровно за один случай то мы можем написать человеческое описание у тебя свалилась твой вопрос свалился отработал неправильно на случай когда не знаю какой то колон канал ну да там rubber журнал например ну после этого всего что у нас происходит мы это запускаем во-первых локальный когда тестируем новый год ну и организовали вот ежедневный прогон и там в случае того если у нас вдруг что то не работает это все приходит с лаку и мы разбираем это нам позволило во первых а снова узнавать о ошибках заранее то есть не ночью когда я только считается этапы то что судорожно просыпается и пытается его починить мы об этом узнаем чуточку заранее в 9 вечера любой страны внедрение такой штуки нам очень сильно помогло отлавливать ошибки на ранних этапах то есть если раньше у нас не знаю было очень много ошибок каждую неделю просто несметное количество после того как мы его взяли на вооружение практику тестирования успели нас наверное за полгода была только одна серьёзная ошибка все остальное мы отлавливали гораздо раньше хорошо давайте теперь представим у нас теперь что у нас теперь четыре больших репозитория на большой ура уже на питоне с успехом которые сами тепло и ции все здорово но вот какая проблема что произойдет если у вас раньше было два человека который фига чистить эти а теперь их 18 тогда по несложным подсчетам оказывается что к концу дня вся их работа оказывается сконцентрирован на небольшом количестве репозиториев и что произойдет если вдруг вечером мы узнаем что этот репозитории не работают все эти люди которые сегодня делали новые кенте завтра буду заниматься тем же самым ну потому что мы всё откатим и только потом будем разбираться что можно сделать для того чтобы изменением были не такими больными в конце дня можно попробовать распилить все эти репозитория на репозитории поменьше это кажется довольно логично идея было бы здорово как ты все эти недельки разбить на какие-то модули желательно изолированные какие то чтобы чтобы в коне в конце дня у нас там грубо говоря был один репозиторий в нем было не очень много изменить это может сработать но все равно остается задача нужно ведь как-то управлять зависимостями другого пакета меня может быть какая тоска которая зависит от таблички которая читает совершенно с другом месте ну у нас же все это пакетированный давайте просто сетапа и пропишем зависимости и все будет хорошо и действительно было хорошо пока мы распиливали вот наши большие по территории а потом внезапно у нас начал исполнять старый кот чо за фигня подумали мы ну на самом деле правда жизни заключается в том что у вас не все и дети всегда корневые у вас всегда может быть так что кто-то репозиторий строит какую-то утилитарную табличку которая уже дальше различается в других в других репозиториях сама по себе она не строится на остается только язык и зависимость ну и в таком подходе мы же хорошие разработчики нас учили прибивать версии работе в школе в институте вот кого то даже в детском саду но вот с этими это не работает потому что если вы сделаете какое-то ломающие изменения например добавите в хайвее колоночка у вас старый фильм не будет работать что мы с этим попытались сделать мы больше не прибиваем версии вот но каждый день мы выкатываем вы простите каждый день выкатываем дженкинса все эти джаббы и таким образом мы гарантируем что у нас во первых у каждой репозиторий в последней версии и зависимости у него поставлены тоже в последнюю актуальную версию и проблем с запуском старого кода больше нет я довольно быстро все рассказал ну давайте я поподробнее расскажу о том почему же мы научились во первых выбирайте артист ротар как можно более рано как можно раньше потому что это та потребность которой с которой можно столкнуться даже имея это не 80 pipeline of a всего один но достаточно такой ветвистые широкий и при росте это наличие такого оркестра таро вам может очень сильно сэкономить силы и сон значит понимаю что когда вы только начинаете делать этель по формы есть соблазн все напихать в один большой репозиторий мы собственно этому соблазну мы повелись на него но это очень плохо при росте и пытаетесь сделать эти репозиторий как можно мягче и делать их какими-то изолированными что тестируйте свой код понятно что если у вас например недельки написанные немножко или а там java скала питон spark вот это вот все тогда вы можете покрыть юнитами но шпион тестируете он скорее всего где-то будет какой-нибудь аналитики где-нибудь еще пожалуйста акцентируйте особое внимание на его тестирование ну и выходку нужно тестировать это простить автоматизировать это сэкономит вам время силы и поможет например когда вы будете переживать машину машину значит пользуясь случаем хочу прорекламировать мы недавно завели блог на хабре там пока одинокий на гордый пост скоро там будет больше поэтому следите за ним у меня на этом все я прямо гонщик спиди до лучшая по совку спасибо большое за доклад я хотела узнать о первых как вы работаете с жетонами что вы делаете когда структуру бессонов меняется насколько они плоские ну и ожидаемый вопрос почему нерфа смотрите про работу с джейсоном это отдельная большая история я привет рассказывал на москву с парте шестом кажется выглядит у нас это примерно следующим образом дина и вас не вижу ни я переместил сустава лучше знаете как у нас это устроено мы валим все что есть в кафку она имеет структуру потому что оно сыпется из кода и значит там это отвечает за какие-то сущности к чему все эти сырую джейсону перелопачивает в себе в хайфу в ходу сначала ну поставь пальчик самописный толстой который а вот рекламировал на мозг у спарте значит а дальше гоняются этель ки которые это преобразуют к структуре значит раньше было действительно больно в том смысле что мы пришли говорим нам нужно много разных данных ну нужно забирайте но вот поменяется структура мы вам сейчас не скажем а сейчас у нас немного перестроился процесс то смысле что эти данные нужны самой компании на самой команде который отправляет ну ты делаешь новый функционал например события платежах ты добавляешь не знаем флажок авто пролонгации платежа если ты это делаешь значит тебе нужно будет аналитика если тебе нужно будет аналитика будь добр сделать так чтобы что-то для этого появилось вот это очень действенный подход значит почему не р flow значит здесь чем отличается уиджи вот вообще от всяких разных других систем регистрации во первых чем подкупает это что выполнен из тоски гарантируются наличием output а у тебя сама тоска жестко прибыть бригитта к наличию данных и если вдруг возникнет такая ситуация что вот простой пример давайте я буду каждый день ходить в какую-то описку из бежать оттуда как этот справочник если я туда сходил и чет забрал это же хорошо у меня ничего не свалилась все произошло нормально а а что если а что если я схожу в эту пешку и чек на что у меня данные это свежее и это вы же разваливается наличием output а то есть фастовская успешно не тогда когда кот отработала все хорошо а тогда когда еще и данные появились вот это наверно ключевое потому что у меня паническая боязнь наверное из-за профессии потерять данные вот поэтому я очень люблю от пут и а с другой стороны катнул и джон выглядит немножко проще чем на верху как мне кажется но это субъективно значит ну ионыч просто расширяется в том смысле что и коли у тебя все каждый task & to close ну это там бери шаблоне зиру и на пили вы ими то классов и вот всяком разная магия которая помогает облегчить жизнь я очень плотно сверху не работал и когда вот мы выбирали между собственно луиджи рф у лыжи мне показался в этом плане гораздо проще но и команда меня поддержало у меня вопрос добрый день я хотел спросить по поводу 2 вопроса вы сказали что иногда может не работать репозиторий вот когда много команда работает потом в другую почему-то в конце каши не работает это спросите мне прямо как чтобы они работали в истории вот и я не второй вопрос это вот вы кричал тут типа наличие путает хорошо а если его пути как бы неправильные данные некорректные ну как бы а тут у меня есть окей ну как бы не тот который нужен и тоже ничего не защищает первое я уже я бы когда-то слышал сразу вопрос 1 значит репозитарий на работ не работают это видимо я в спешке проговорил имеется ввиду что вот меня территорий в которой комитет восемь человек за день и концу дня у меня оказал я могу оказаться в ситуации когда кто-то из них слукавил ничего не протестил и как результат как результат концу дня в момент прогона тестов мы определяем что а тесты не проходят значит кто-то заметил не рабочий код нет нет разные конечно ну каждый отлично это превращается в избыточную ручную работу значит вечером кто-то должен посмотреть если что-то сломалось он начал там это нажимать рычаги видите кажется гораздо проще сделать так что в такой ситуации не оказываться в принципе значит второй вопрос про output значит действительно у нас может записаться ерунда и действительно у вас может сложиться ситуация что да я отработал вот меня там записались циферки но вот не 10 миллионов как обычно 10 чем хорош луиджи вы можете все что угодно переопределять и те же самые от пут и вы можете поднастроить так если например вы знаете кого нет медиана и значение ну 10 это совсем перебор да вот такие вещи вы довольно просто можете отлаживать отхватывать переопределение mode фута и говорить что существует ни тогда когда именно данные to this rifle до данные существуют и там их ну не слишком мало например привет с разных сторон два вопроса первый насколько я понял то что у вас много разных этель и каждый на каждый из них отдельный крон если между ними какие-то зависимости если есть только к не разруливают вот второе то что каждый этот не так каждая тоска тестируется по отдельности не для какого-то процесса который тестирует гейского flow со всеми зависимости хорошо значит первое про кран и когда мы делаем тоску мы это на самом деле не всегда правда мы можем знать что она сугубо утилитарный сама по себе не нужно прямо крон очевидно не будем настраивать она будет дергаться и зависимость если вдруг так случается что мы сделали какую-то супер классную витрину которая идет например в отчетность а впоследствии хотим от уточнить какие-то данные для того чтоб тренинг замечательной модельки никакой проблемы в этом нет почему если ну вот будет два крана по сути да значит что будет происходить лыжи когда строит граф зависимости он работает не совсем бинарная то есть не готовы не готова он лучше понимает что этот энистон сейчас этот instance тарский сейчас работает другим вором и будет дожидаться его окончания тогда чек не что выполнился и пойдет дальше то есть это в данном случае не такая большая проблема на второй вопрос я забыл про тестирование отдельно да значит нет на самом деле мы тестируем только вот точечные запросу действительно это можно сделать так чтобы тестировался целиком pipeline окажется сложно поддерживать вас pipeline тем и хороши что вы можете их решить бесконечно тогда вам придется работать на два фронта тестировать и сам новую тачку и как-то встраиваете в тестировании целиков его pipeline ну и другая история и то что у нас не все пайпа и не изолированы друг от друга то есть они могут разрастаться в разные места и тут понятия pipeline она растягивается михаил спасибо за доклад такой вопрос решали задачу лизации данным данный источник куда по каким витрин com разъехались при этом может быть есть частный случай когда вы каким-то образом хотите проконтролировать безопасность ну что там данные клиента затерлись в нужном месте и качество общем-то на протяжении всего line уже контролируйте значит про визуализацию потоков данных вот в рф очень красиво она визуализируется вы же не очень красиво так я должен оставайтесь на линии значит вы же есть стройная утилитка но кажется это может они самостоятельно и спи . натыкать которая строит игра в зависимости и для вашей и тоски фастовская анализа но она олицетворяет собой какую-то табличку правильно ну и эту визуализацию можно собственный смотреть в веб-интерфейсе луиджи ну или можно вводить консоли графом значит про качество данных значит качество данных в том смысле что мы его лидируем что при перекладке из одной таблицы в другую данные не потерялись это кажется покрывается тестирование успели а то что к нам входные данные пришли все но здесь уже это каждый может изобретать свой велосипед у нас есть здоровые преимущество в этом вопросе перед непосильной задачей у нас очень много разных данных которые могут сохранить ну и содержать одинаковую информацию например у меня сто через белен голыми платежами то есть какой пользователь сколько заплатил и у меня есть очередь например с логом изменения объявлений давать вот такой простой пример только ну тогда я могу находить продал бы и ошибки если я вдруг в одной очереди вижу еду пользователя который которого больше нигде нет ну и вот так вот отталкиваясь от каких-то базисных например очередь по изменение объявлений я нахожу пользователи которых здесь нет ах были замечены где-то еще ну это больше вопрос процесса то есть одно делает настроить регулярную сверху тут гораздо более сложная задача как сделать так чтобы расхождение были пофикшены довольно быстро без ущерба для аналитики гораздо более сложная история всеми я здесь принц спасибо за доклад ты ук рассказал что как вы разбили после на репозитории внедрили механизм зависимостей и как я увидела то есть у половины там вы сделали выйти ст а у половины войти все еще на версии даже не кладите трубку еще раз еще раз значит смотрите вот у ели км и прибитые версии выбирали мы оставили прибитые версию собственно пакетов именно питона stick ней телек the sea утиль всегда последней версии и то есть нет разрешения на одну версию на другую золотистую то есть этих предыдущих версий может быть несколько эти загружу несколько раз выполняются нет сейчас такую версию потому что вы перешли на выйти из да да да именно поэтому а как если ну то есть кто то поменял корневую запросы туда как вы портите чтобы все остальные обновлялись ну я говорю мы каждый день у нас впереди поют впереди появляются все этики соответственно эти версии потягиваются не понятно то есть это вот кто-то в корневую им сказали изменить они изменили между ночь в корневую ну то есть вот ну вот наверное да то есть основная на которую я совать если она изменилась от нее зависит еще 10 и как за 100 они лишь то типа после того как вы изменили сломалась 10 других а как других 10 заставить изменить смотрите у нас обычно все изменения оказываются в репозитории но обычно там до какого-то фиксированного времени ну там девять десять одиннадцать часов в зависимости от усидчивость и работоспособности соответственно выставляя огромную диплом на чуть-чуть попозже мы гарантируем что все последние версии уже есть итак залиты то есть по сути в этот период и плавание она не затрагивает но она не изменяет состояние репозитория например vdp она изменяет состояние только виртуальных окружений где эти эффекты используются как то так понял привет вопрос co2 из первой сначала озвучил первые звучит так вот что вы делаете ставками во время тепло и то есть же какие-то длительные тоски и вот происходит тепло и чтобы вы устанавливаете вы ждете их завершении достичь назад верните большинство извините перебила не дал задать второй вопрос его не поздно память у рыбки поэтому давайте сначала на первый наш мир устроен так что большинство job работают по ночам поэтому днем обычно вертится что-то либо исключительные до либо исключительно значит что можно делать приди play можно действительно тоску останавливать ну это зависит мы пытались вообще так не делать но если ты знаешь что тебя панской вертится днем но зачем только днем будешь изменяет ну здесь так это уже на усмотрение разработчика стоят чуть награждать деплоить и тогда когда она завершилась ну да это было бы правильно но еще раз говорю мы обычно не днем у нас не так много всего сердца ну и в нем днем кластер сгибают нет живые люди лады лады тогда такой второй вопрос вот допустим приходит бизнес и говорит вот мы хотим сейчас запустить систему куча аналитиков которые могут только писать с келли они не умеют и бетонщики приказ потому что это первое условие второе условие чтобы как только они написали с кем они хотят что было но он сражаетесь эта этель к и запустила скажем через полчаса без перед тепло и все остальное вот как бы ты отнесся вообще вот к такой такой идеи чес этим можно сделать понятно чтобы бывают люди которым это все еще будет сложно здесь можно уже фантазировать можно делать какие нибудь лайки тип вставляю сюда и сквере сюда вставляя это таблички которые тебе нужны нужны для него их даже автомата можно изучить доски мы же тебя с генерим код настроим зависимости все будет хорошо еще нажми когда это запускает 1 штука значит второе ну ситуация когда нужно запустить какую петельку прямо сейчас ну ты всегда можешь самостоятельно и запустить и в своей очереди там на данных своему танки текущего шляп кофту и расскажу для от х к ну да хаков и даже не нужно значит если тебе нужен срочно какой-то там pipeline регулярный что вот считалось каждый день там репортёр табло ну приходи ночью это быстро спасибо за доклад так у нас тут у меня я рискну два вопроса если что повторю 1 что вы делаете с приоритизации когда есть и тильки которые медленные есть которые быстрые они все живут там время процессор на кластере как вы разруливаете вот это вот вот такие вот люди и второй вопрос про бахилы если у вас автоматически ручные как это все работает то что вы рф обучил типа надо там упала за прошлый день одну тачку запустить вот это вот так но у нас есть кажется выглядеть лучше вопроса это никак не связано что мы знакомы а значит первая про приоритезация обычно эту стройную следующим образом мы вот знаем ключевые какие-то pipeline и которые насчитывают самые важные вещи из которых там строятся какие-то фундаментальные вечеринки их мы запускаем ночью когда обычно люди не работают но опять таки все очень индивидуально и тогда класть и свободной и все это просчитывается если вдруг ты запускаешь что-то не днем ну подстраивайся мы на самом деле чудила мы собираем метрики ирна о том когда в какое время примерно насколько загружен кастер и это визуализируем графа ней супер сайте и если вдруг приходит кто-то и говорит блин вы хочу job чтобы она запускалась не ночью а вот хочу вот прям вот днем обсчитывать и толкаться с ней ну вот открываешь ящик смотришь сад и записывались вот примерно так пробег силы о круть круть круть знаете у нас вот в тоски на самом деле есть старт point и хоть недавно посмотрел в рф ул кажется такой же есть ну типа начинаю с какой даты считать зачем он нужен на самом деле вам нужен не для того чтобы мы не запускали там за мы управляем не время его запуска вот чем очень много to suck рекурсивные некоторые рекурсивные по дизайну то есть например если ты хочешь каждый день наконец дня иметь snapshot последний слышу от каждого объявления тебе не обязательно всю базу перелопачивать ты можешь взять за вчера del тачку почитать про у на оборону вставить и вот для этого нужна здесь рекурсия натуральным образом а бывает так что у тоскане посчиталась об этом в течение суток с этим никто ничего не сделал во первых такого не бывает во вторых если вдруг бывает и данные не посчитались ну тогда у нас вот эта рекурсия она посмотрит на себя за вчера скажет ага я не выполнено нужно посчитать то и соответственно что делается на самом деле то есть это тоска зависит не только вот от репозиторий деле ну еще от себя за предыдущий даты вплоть до star пойнту это очень удобно например ты сделал новую темку за и хочешь запустить и за последние десять дней ты не хочешь делать руками ты запустил и старт моим кисти он и в чем вы счету здорово другой стороны вот эта штука которую я про которые я говорил в я эти луиджи есть визуализация графа ну он немного портится но вы сильно в смысле то есть рекурсия это становится очень и читаемая штук вот еще один изменение графа как это выглядит fly gets когда у вас там исполнять пасочки потом добавили новую как строится граф именно в ран t'aime то есть ему он не один раз бегать по репозитории ага вот так и все теперь будут только так что он вы пересчитывает каждый раз то есть если у меня так изменилось то старые данные будут кито не не валидные ну если ты добавил новый слой и не знаю добавил еще одну табличку на которую за развиваешься ну при очередном запуске у тебя появится вот эта вершинка ну а старый останутся прежними кнопки у меня ещё один вопрос по поводу дидили где вы храните определение таблицы как это определение таблиц связано с этими тестами и как это вообще кто накатывает их и второй вопрос это сколько у вас тестов как долго не бегут да хорошо значит первое про недель так сейчас были чужими такой большой презентации я такую рассказываю о отлично смотрите вот здесь есть полячки great balls и alter если ну и значит когда мы создаем новую табличку мы записываем эту структуру в репозиторий ну чтобы потом если вдруг там нужно будет что-то alternet нас от осталось для истории начну еще раз мы значит у меня встал авторы которые были потому что второй раз аль тани проделать это как бы нет еще раз эти скрипты не исполняются автоматом а как теста ты накатывают их ароматические тесты не на карту а значит опрос схожую структуру но смотрите у нас ведь есть знания о структуре таблице которую мы хотим протестировать правильно мы можем полезть если мы можем полезть в дозор х его и узнать ну собственно мы так и делаем ну или вы можете написать хэвик retail лайк где и когда я запускаю тесты ожидаю что таблица уже создана правильное созданы правильно нет ты сам создает ну копию вот этой вашей таблице по структуре копию откуда еще раз у вас есть таблица значит статистика статистика выяснить насчитывать ходить запустить тест который проверяет что с переводчик по ней хорошо отработать чем мы для этого делаем мы создаем фейковую табличку критобул фейковая табличка лайк оригинальная а у нас в одном этаже базе происходит да это на самом деле у нас не разделен мог даже если это разделена нет проблемы ну то есть это правильно как правильно иметь отдельный стенд на котором вы все работает ну проблемы никакой нет поднимайте hive клиент лезть в мид осторожно узнавайте структур 100 давайте такую же но это кажется не очень большая проблема хорошо так 2 вопроса конечно же размер тестов сколько раньше когда вот у нас был и вот котятки репозитории тесты занимали очень долго час-два чуть больше частью после распила но потому что смотрите вам для того чтобы запустить один тест с что нужно сделать создать таблички наполнить их фейковыми данными это нухаев ская джабба которой она тоже занимает какое-то время там же сильнее есть большая overhead и сейчас это не очень хорошо значит на самом деле к счастью после того как мы собственно одна из плюшек которую приносит распил репетиторы хвосты стоит меньше на один репозитории тестов меньше приходится вас запускается провели ну точно также можно запускать не знаю это создает свою отдельную да да да конечно чтобы они не конфликтовали не пересекали и если это все живет на одном и том же кластере то как бы в параллель у нас бежит как бы живой идей который и в параллели бегут эти тесты и все это бежит за час и всем хватает всего они не очень толстые тесты в кайф но и там больше времени на выходили за вон там больше времени на выход о самом деле спасибо большое спасибо за доклад у меня следующий вопрос как интегрировать с мониторингом то есть alert янгом и у вас как я поймал несколько этель может быть у вас есть какой то даже борт до второй такой маленький вопрос вот я просто не услышал объем данных какой вас в день приходится давать смотрите нас ведь а вот второй пункт сбор метрика логов на самом деле нам мало ловить ошибки нам еще хочется знать сколько всего мы записали правильно в конце каждой тоски отрабатывает код который собирает и суд путами таки . ун-та то есть сколько записей мы записали и дальше и тори портится в графит из графита даже борды в графа не ну из граф она и дальше ваше любимое средство оповещения о джинни slug электрошокер все что угодно это будете знать да да пока проблем данных так пробьем до некоторых проблем данных значит в сыром виде то что мы забираем в день это около 500 гигабайт ну дальше понятно что это все там раскладываются строятся агрегаты значит вот самый входное число я могу прям вот честно сказать около 500 гигов это самом деле не очень много вот дальше вот во что это все превращается ну там много я даже и не беру считать товарищи очень удобно так ну собственно алексей скафандры вот товарищ"
}