{
  "video_id": "OigQ3sD8-B8",
  "channel": "HighLoadChannel",
  "title": "Централизованный self-service ETL / Андрей Гончаров (Garage Eight)",
  "views": 611,
  "duration": 3034,
  "published": "2023-04-28T06:10:46-07:00",
  "text": "Здравствуйте меня зовут Андрей Гончаров я дата инженер в компании гаражей мы международное продуктовые эти компании нам уже 11 лет И мы строим экосистему с нагруженных финансовых продуктов на международных рынках тут есть у нас ссылочке на социальные сети Приходите туда Подписывайтесь Приходите на наш стенд Будет очень интересно И вообще когда кладу готовился я думал что буду волноваться из-за доклада но последние события показывают что поводу для волнения могут быть другими Однако начнем мой доклад будет про дата инженерии я расскажу о том какие бывают проблемы при не оптимально построенных это инженерных процессах расскажу о том что есть наша сервисы TL платформа Что такое наша платформа данных которую мы разрабатываем и расскажу как мы с ее помощью Подходим к инженерии у нас в гараж также Надеюсь что мой доклад может быть сломает какие-то шаблоны и может быть даже картину мира некоторых из вас Однако переворачивать мир одному задача сложная поэтому Разрешите представить Это Андрей он работает в компании Смарт Solutions и он дата инженер и в один прекрасный день Компания Smart Solutions решила что она должна стать dreven компании чтобы это для него не значило однако для дата инженеров Это точно значит большое количество источников данных большое количество аналитических и маркетинговых систем с которыми они должны будут работать и большое количество потребителей этих данных естественно все манипуляции с данными должен производить именно дата инженер у него даже есть слово Data название его роли и кажется что поначалу Все идет хорошо в нашей компании мало потребителей данных анализ достаточно ограниченный это инженеры прекрасно обеспечивает потребности пользователей в данных и наша система paypeline простая понятная и прекрасно можно поддерживать Однако оказалось что дата древом подход для нашей компании Smart Solutions он очень хорош выгоден и актуален и бизнес начал расти стали появляться больше потребителей данных больше аналитиков больше маркетологов больше всех все хотят знать статистику Все хотят строить какие-то гипотезы и система наша по доставке манипуляции с данными становится все сложнее сложнее для поддержки В итоге Наш бизнес становится очень большим У нас очень много сотрудников пользуются нашими данными строят гипотезы анализирует это инженеры отвечают за доставку и качество огромного количества этих самых данных система по доставке данных сложна там много компонентов много инструментов и в связи с тем что инженеры тонут в рутинных задачах у нас растет тех долг наша система по доставке данных мы уже не можем так быстро модернизировать обслуживать поддерживать Как нам хотелось бы и такие процес масштабируется только одним способом нам нужно больше дать инженеров чтобы все эти задачи между датой инженерами размазывать Я считаю что такой подход не оптимален и главная его проблема в том что этот инженеры получаются обладают у нас каким-то сакральным знанием и единая точка доступа к данным это как раз таки получается дата инженеры поскольку это инженеры владеют чужими данными они за них и отвечают хотя на самом деле качество данных от них может не зависеть как-то что это должна быть задача потребителей этих самых данных и чем больше у нас появляется задач тем больше даты инженеров должно их поддерживать кажется что процессы построены не оптимально получается что раз у нас много рутинных задач и дата инженеры занимаются перетаской данных то они получаются У нас уже не даты инженеры а дата грузчики вместо того чтобы решать инженерные задачи они у нас заняты Только рутиной хотелось бы чтобы все было построено немного не так чтобы данными владели и манипулировали их потребители а дата инженеры бы обеспечивали уже инфраструктуру для манипуляции этими самыми данными Однако кажется что порог входа в дата инженерию высок У нас очень много подходов Практик целый зоопарк инструментов и условная аналитик который занимается большую часть времени например написанием запросов ему сложно будет влиться инженерные какие-то задачи инженерные процессы однако я считаю что мы в гараж эйд решили эту проблему и раз порог высок его нужно снизить и нашим решением было дать пользователям удобный инструмент и предусмотреть какие-то ошибки или оплошности которые они могут допустить когда с этим инструментом работают таким инструментом стала наша платформа данных немного статистики у нас больше 30 пользователей платформы в месяц они обрабатывают больше трех петабайт данных и в самом нашем нагруженным отеле проекте ежедневно выполняются 2000 задач сотни задач выполняются уже ежечасно в центре любой платформы данных Я считаю должно лежать надежное и отвечающая потребностям хранилища таким хранилищем для нас стал Google bigvery в первую очередь мы его выбрали потому что это часть Google экосистемы и многие наши продакшн сервисы работают в Google облаке кажется что логично выбрать другую часть этого облака для удобных каких-то интеграций bequery обладает также большими преимуществами облачных сервисов такими как масштабируемость отказоустойчивость нет нужды каких-то администраторах нет нужды в нашей ручной поддержке этого сервиса все как будто просто работает нам не нужно думать где мы будем хранить в 10 раз больше данных когда они к нам приедут не нужно думать как мы будем обрабатывать эти данные с гораздо большими объемами кажется что когда задача решается за тебя это хорошо также биквери обладает богатым эскильдиэлектом который с каждым месяцем становится все лучше и лучше И с ним очень-очень-очень приятно работать и чем богаче SQL тем удобнее получается аналитиком манипулировать данными хранилища также важным для нас моментом является то что биквея не требует чрезмерной оптимизации кода потому что нашим инструментом пользуются сотрудники совершенно с разными компетенциями кто-то уже можно сказать продвинутый пользователь SQL хорошо пишет запросы кто-то только начинает и нам не хочется требовать от всех какого-то жесткого кода очень оптимального быстрого в принципе за счет масштабируемости распределенности бикере все запросы он прожевывает если что-то работает долго Что бывает крайне редко мы уже это оптимизируем вместе с автором понятно что данные сами собой у нас в хранилище не попадут поэтому Нам нужен какой-то оркестратор который будет управлять у нас регистратором у нас является патч airflow мы его выбрали как надежный и зрелый инструмент также он легко у нас масштабируется мы будем уверены что в 10 раз больше задач у нас будут выполняться мы сможем легко найти ресурсы для их выполнения и airflow расширяем и позволяет динамически генерировать графы задач что для нас очень важно Были времена Однако когда нас airflow не устраивал и это был ровно один день в прошлом году когда мы обновились с первой версии на второе и все у нас Снова стало хорошо С тех пор никаких проблем с ним не испытываем классический подход к написанию пайплайнов данных организации TL в случае сверфлоу это описание всех пайплайнов на pyth У нас есть много примитивов в airflow какие-то коннекторы для работы с данными операторы для описания конкретных получается связок источника и назначения все все что мы делаем Мы описываем через Python И это не всегда кажется удобный подход главным образом Потому что если мы будем писать много кода то кодовая база у нас будет расти и раздуваться и поскольку у нас будет большая кодовая база если нам в один прекрасный момент нужно будет масштабироваться Например если Наш бизнес запустил какой-то новый продукт и мы хотим тоже собирать по нему данные допустим для начала у нас основной продукт и новый Они похожи для них похоже то через какое-то время их функционал расширяется различаются и непонятно что мы должны делать Мы должны клиент как-то копировать в два это держать два продукта в одном отель проекте не совсем понятно Какой способ лучше также Несмотря на то что очень много встроенных каких-то примитивов операторов и прочего функционала все равно не всегда хватает и не всегда реализация какого-то способа перемещения данных она удовлетворяет нашим потребностям поэтому мы реализуем в основном все операции сами используем чисто как регистратор чтобы реализовать какое-то решение данных проблем Мы разделили функциональную часть и декларативную часть описание потоков данных то есть функциональная часть содержит у нас просто способы как мы работаем с данными а декларативная часть уже говорит что конкретного перемещаем в рамках проекта такой способ расширения разделение функциональности и декларативности позволяет нам очень легко масштабироваться наша функциональная часть называется генератором графов нами и делает она именно то что есть свое название она динамически генерирует Граф airflow на основе описания задач и единица каждого графа получается узел каждого графа это так называемый нами тип задачи то есть способ как переместить данные из одного места в другое из источников назначения У нас есть много сервисов много интеграции с которыми Мы работаем и среди них есть как аналитические системы так и маркетинговые системы хранения данных очень-очень-очень у нас много всего и постоянно появляются новые интеграции и стараемся мы чтобы все эти интеграции были реализованы именно нами чтобы не быть завязаны на airflow типа задачи по природе своей модули То есть например чтобы переместить данные из Москвы или bequery Мы сначала выгружаем результат мы перемещаем его легко просто быстро бесплатно Что приятно И эти модули по сути компоненты из которых состоит тип задачи мы можем по-разному компоновать и создавать новые уже связки источников назначения все это у нас получается очень просто и быстро что касается декларативной части она у нас уникальна для каждого проекта В то время как функциональная часть генератор графов реализован нами один раз и постоянно переиспользуется что же содержится в наш декларативной части понятно что раз Она своя для каждого проекта она содержит конфиги для этого проекта мы содержим какие-то уникальные параметры вроде имени проекта вроде Хоста где он крутится все что угодно Все что нам может потребоваться мы указываем там кредо для доступа к информационным системам сколько у нас много интеграции нам нужно много этих кредов где-то хранить также мы описываем список коннектов к микросервисным базам данных чаще всего источником данных изначально у нас является именно база микросервисов Поэтому нам показалось удобным описывать их своим каким-то способом и не быть завязаны на Flow потому что он тоже позволяет Коннект по идее описывать каждый Коннект характеризуется именем типом база данных все что угодно и мы описываем строку соединения как мы к этой базе подключаемся и в дальнейшем Когда мы описываем уже какую-то задачу которую нужно сделать мы не пишем какую-то конкретный тип по типу источника например переместить данные из повозгласа или что-нибудь такое подключиться туда то мы просто указываем конкретный Коннект а генератор графов уже знает что нужно понять какой тип базы у нас имеется ввиду понять строку подключения и на основе этого построить уже задачу задача Мы описываем ямах и самая простая задача может содержать у нас всего два каких-то поля То есть это ID задачи Понятно нам нужно как-то задачу назвать и тип задачи в данном случае это видимо перемещение каких-то среди данных по странам из какой-то традиционной базы в эклере естественно нам нужно описать источник данных с помощью наших коннектов про которые говорил выше Мы это можем сделать очень просто одной строчкой и плюс ко всему мы должны уже указать Какие конкретно мы данные забираем в этом случае нам нужно указать скрипт который в случае с назначением раз у нас бикверит то мы указываем это сет в который мы данные переместим и имя таблицы имя Клауд проекта мы не указываем оно у нас одно на весь наш проект один на всю платформу данных поэтому нет смысла лишний раз описывать его в каждом определении задач важным ключом для нас является расписание когда сдачи выполняется мы имеем дело с процессингом и задача у нас выполняется как-то регулярно в данном случае задача выполняется ежедневно и Ключ расписание важен нам еще и потому что все задачи в рамках одного интервала например в данном случае ежедневного интервала Мы компонуем в один Граф То есть у нас есть Граф ежедневных задач есть Граф ежечасных задач пятиминутные графы все что угодно сколько у нас есть интервалов столько у нас есть графов мы не требуем от наших пользователей создавать какие-то уникальные графы нас много пользователей и все равно никакого порядка бы из этого не получилось нам проще держать все данные потому как часто они обновляются и раз мы говорим о графах то у графов есть узлы и между узлами Есть зависимость в данном случае у нас какая-то исходная задача которая принесла привезла данный из микро сервиса и у нее никаких зависимостей нет просто привозим данные если мы хотим написать задачи уже зависимость ничего особо сложного нам менять задачи не нужно например в данном случае мы создаем таблицу с юзерами в каком-то сайте приготовленными данными и чтобы сказать что как у нас получается данные приехали откуда взялись сырые данные мы указываем список задач которые у нас эти данные привезли в данном случае это сырые данные по юзерам и наш Граф задач получив те определения понимает что сначала У нас должна стоять задача которая приводит сырые данные а потом уже стоит задача которая собирает подготовленные данные Кроме того в наших задачах мы шаблонизируем скрипты допустим возьмем задачу описанную выше которая содержит запрос получить все данные из таблицы вот так вот мы не пишем Потому что если в нашей изначальной задаче что-то поменяется если мы будем называть таблицу иначе или если проект появится какой-то другой то из-за того что мы явно описали могут возникнуть какие-то проблемы нам приходится пришлось бы потом все эти задачи изменять как-то поэтому мы делаем так Мы каждый таблицу которую нас используется Каждая таблица которая у нас привозится нашей платформой мы описываем просто через шаблон через имя задачи и уже на этапе сборки графа этот шаблон из имени задач мы получаем уже таблицы в том виде в каком они существуют на момент выполнения на момент сборки графа надеюсь что в этот момент пазл уже начал складываться генератор графов получает на вход набор ямлов описание задач конфигов графы у нас компонуется и задача указанных типов из типов которые мы указали в наших писаниях задач наша декларативной части и Граф у нас содержит задачи с одним расписанием также задача у нас использует уникальная для пряники конфиги как connectic базам креды и все прочее получается что мы не завязаны на airflow весь функционал мы реализуем сами верховный нужен только для оркестрации и для построения графов если в один прекрасный день рфло не будет удовлетворять нашим потребностям мы можем легко перенести наш функционал на какой-то другой регистратор и обернуть Его какие-то другие примитивы У нас есть единая кодовая база но есть разные наборы задач и Чем это полезно тем что инкремент мы можем один раз реализовать и потом его транслировать на все наши проекты которые есть и это очень полезно кодовая база не дублируется все полезные плюшки сразу появляются на всех наших платформах развернутых которых у нас к слову в данный момент 5 5 проектов которые друг на друга который никак не зависит друг от друга и которые работают абсолютно параллельно что же на практике какие у нас есть возможности в нашей платформы данных например классическая задача у нас достаточно много табло отчетов больше 200 и отчеты у нас жирные очень их витрины порой занимают сотни гигабайт и естественно мы не можем работать с ними в Real Time получается что эти отчеты нужно обновлять и стандартным способом было бы примерно понять во сколько обновилась витрина у нас у отчета и в какое время мы можем этот отчет обновить с помощью средств того же табло Однако это неудобно и отчетов много их как-то все это сделать по прикольнее И что же нужно сделать у нас аналитику чтобы отчет обновился его вовремя когда данные приехали ничего не надо ему делать потому что мы реализовали клёвую интеграцию с табло мы регулярно получаем список табло отчетов мы смотрим на их определение чтобы найти витрины данных которые они используют и мы пытаемся определить какие из этих витрин наполняются ими нашими платформами И когда нам нужно сформировать задачи для графа Мы в него включаем этот Граф еще и задачи по обновлению отчетов и включаем эти задачи после всех зависимости после всех витрин которые обновляются и получается что когда у нас не обновились витрины обновляется Они быстро обновляться немедленно отчет обновиться тогда когда нужно и кривые данные в него не попадут никак следующая задача Допустим мы хотим мониторить какую-то метрику и не хотим постоянно лазить в отчёты прожимать фильтры хотим просто посчитать две цифры и отправить их себе допустим в slack как это сделать сделать это очень просто мы пишем скрипт который будет эти цифры считать мы пишем Ямал описание задачи которая будет говорить нам о перемещении данных из одной информационной системы в другую вот эти 8 строчек которых я говорил выше кажется немного и мы отправляем нашу задачу в репозиторий Новую через 10 секунд задача у нас оказывается уже на проде и уже готова к работе Как же так получилось очень просто у нас есть сервис который постоянно поддерживает репозиторий задачами в актуальном состоянии и Air Flow у нас каждый раз строят актуальный Граф нам не нужно делать каких-то диплоитов если наша кодовая база не изменилась наш репозиторий Наша задача всегда последним свежим хорошим актуальном состоянии и в slack мы отправляем также возможность запустить эту задачу Но мне хочется дергать от инженеров для запуска задач не хочется использовать там VIP мордой Flow которая не лучшая конечно же медленная и все такое прочее поэтому автору задачи после того как он задачу отправил репозиторий мы отправляем предложение эту задачу запустить говорим какую задачу можно запустить отправляем кнопку и каждый раз когда изменяется состояние мы обновляем это сообщение Он видит статусовые задачи Он может посмотреть логи свои задачи и в случае успеха он может заниматься своими делами в случае фейла он сможет понять что конкретно пошло не так чаще всего это какая-то ошибка а если допустим у нас есть какой-то функционал какой-то новый тип задачи еще не реализованный и я как разработчик какой-то микросервисной команды Хочу чтобы этот функционал появился что же сделать на самом деле Добро пожаловать мы держим наш код открытым наш генератор графов доступен для редактирования всем кому это может потребоваться и после провод с нашей стороны и при наличии вас компетенций ваш код может появиться как новый тип задачи которые реализуете вы пользоваться опять же ими смогут все кому это может потребоваться а если например у нас код но который вообще не на питоне и все равно данные для него мы готовим с помощью нашей платформы данных и опять же хотим чтобы код запускался когда все зависимости приехали такая возможность тоже есть мы имеем способ запускать контейнеры как задачи нашего склада данных и все что вам нужно это обернуть ваш код в среду которая нужна для его запуска и создать задачу и ваш код будет запущен в нужное время получается что автоматизация новой задачи по обработке данных занимает несколько минут Сколько нужно времени чтобы написать Ямал коротенький из восьми строчек любой желающий может заниматься инженерией потому что описание задач и процесс создания задач он достаточно прост в основном нужно просто написать как данные достать А что будет сделано для этого уже реализовано и наша платформа данных не только используется но модернизируется теме Кому нужен функционал То есть все не завязано дата инженеров не только в части доставки данных части функционала платформы и мы не ограничены Python как языком разработки мы поддерживаем возможности внедрять какие-то задачи написанные на любых языках Однако у всего этого удобства есть цена и цена это то что нашим инструментом пользуется и вот одна минута это то за сколько мы обрабатываем Наш первый бесплатный терабайт каждый месяц и вот я ранее говорил про наш самый крупный проект в котором 2000 ежедневных задач и Граф из двух тысяч задач выглядит примерно Вот так и конечно не может его отрисовать Поэтому я в других инструментах визуализации рисовал Но кажется что достаточно сложная штука поэтому система наша надо поддерживать и случае с данными важнейшим моментом является дата линии то есть происхождение данных мы должны понимать Откуда берутся данные что они из себя представляют делать какие-то описания метаданных и прочего вообще наша платформа по своей сути уже содержит эта линия само описание задач мы явно говорим От чего Наша задача зависит мы описываем все задачи которые привозят для нее данные но Для большей функциональности Мы также интегрировались с системой описания метаданных которые позволяют нам указывать происхождение данных которые позволяют нам описывать сущности делать описание таблиц полей Чего угодно и также важным моментом является возможность указать владельца данных чтобы когда нам потребуется задать какой-то вопрос Когда нам потребуется понять чистые данные или нет нужна консультация мы можем сразу понять кому с этим вопросом обратиться Однако мы были бы не мы Если бы мы тут не сделали удобную интеграцию и каждый раз когда схема данных хранилище изменилась Все изменения у нас летят Вот это ха б как мы это сделали мы сделали из нашей платформы данных и при изменении таблиц мы изменяем их схемы данных дата хабе и когда автор задачи у нас таблицу изменил и задачу выполнил ему прилетает предложение изменить описание этой задачи точнее изменить описание таблицы и вся схема уже за него заполнена схема содержится в свежем актуальном виде ему нужно просто добавить описание не нужно рисовать каких-то таблиц самому не нужно описывать типы данных Все просто работает и еще есть интеграция со slack чтобы сразу можно было все поменять с качеством данных все еще проще поскольку данные лежат в ответственности в их владельцев они даты инженеров то именно качеством данных им самим заниматься чаще всего они делают какие-то тесты которые падают если ключевые показатели не выполняются задача тест упала и зависимость ее тоже упали например чтобы в отчете у нас каких-то плохих данных не появилось после того как тест пройдет можно будет снова перезапустить кусочек и получить уже актуальные данные еще одним способом является отправка себя каких-то для их легкого мониторинга и чтобы не лазить опять же отчёты а иметь какую-то возможность быстро проверить какие-то несколько ключевых наборов данных Я уже много раз сегодня говорил что у нас есть интеграции со слег и их на самом деле очень много мы получаем алерты если у нас что-то идет не так например если у нас отводилась какая-то микросервисная база мы можем сразу связаться с владельцами не ждать Когда у нас будет очередная итерация обработки графа Мы в момент падения сразу понимаем что проблему как-то надо решать также мы видим выполнение графов slack видим текущие задачи которые выполняются видимо павшие задачи можем перезапустить задачи которые упали или перезапустить также нам доступны логи задач и не заходя в тот же airflow не пытаясь найти там нужные нам конкретный запуск графа и конкретную задачу мы сразу можем перейти и понять в случае фейла например где у нас произошла ошибка и у нас есть общий бот для запуска команд то есть вот эти все кнопки они реализованы с помощью этого Бота и все наши проекты имеют возможность для запуска задачи через этого Бота один контракт много проектов и все очень удобно Однако бывает у нас конечно оплошности все люди и какой-нибудь кривой ямы которые к нам прилетает репозиторий а он сразу прилетает без каких-то дипломов он может наделать дело поэтому мы этот момент предусмотрели и мы имеем какую-то обработку ошибок и проверку ямах которые к нам прилетают и случае если мы получили свежую ревизию мы проверяем Можем ли вообще построить Граф с помощью текущей версии нашего репозитория с описанием задач если графом построить не можем мы отправляем помещение автору задачи отправляемые Крещение мои тренером Что что-то сломалось мы откатываемся на последней работы еще ревизию и получается наши пайплайны продолжают работать последняя версия какая-то есть кривая но предыдущая версия на которой все работало которые были довольны она функционирует И как только мы получим работающую версию все после всех проверок будет запущена дальше И мы получим новый код напротив примерно такое сообщение Мы отправляем в случае ошибки автору мои тренером У нас есть ссылка на комит У нас есть ошибка которую мы получили при попытке сгенерировать Граф например в данном случае кто-то видимо отправил какую-то кривую зависимость которая не существует и мы видим список файлов которые изменился получается что мы можем провести какую-то диагностику и думать об исправлении ошибки даже не выходя из этого сообщения можем понять где мы могли там накосячить и после всех этих инструментов наверное интересно чем занимаются когда платформы данных модернизирует уже не они задача делают не они все как будто бы работает Ну к сожалению нет хотелось бы но нет у нас еще есть задача и важная их часть является онбординг мы учим работе с нашим инструментом рассказываем про возможности рассказываем про какие-то практики которые мы используем чтобы у нас было как можно больше пользователей и наши технологии распространялись поскольку мы живем в облаках то нам нужно думать про ценовую эффективность и очень часто можно очень много сэкономить путем каких-то простых манипуляций также мы занимаемся оптимизацией производительности наших процессов оптимизации производительности нашей платформы Мы стараемся чтобы Наша задача запускались быстро запускались без какого-то оверхеда чтобы все работало максимально эффективно мы часто внедряем новые инструменты Это когда-то инженерные инструменты так какие-то новые аналитические инструменты Недавно мы например с интегрировались с системой продуктовой аналитики конечно же важно заниматься безопасностью и мы ей занимаемся мы следим за доступами как к исходным данным так и к назначениям чтобы Только у тех у кого доступ должен быть он собственно был в наших планах переезд cubernetis Я думаю такая тенденция есть только в нашей компании во всех остальных мы сможем проще масштабироваться Например у нас основная нагрузка приходит ночью когда он выполняется основные наши задачи ежедневные и все остальное время нам большие мощности в кластере чаще всего не нужны по сути мы держим его просто так а в кубе мы могли бы Например ночью класть раздавать А днем обратно его сжимать что очень кажется полезным и мы хотим сделать удобный веб-интерфейс для описания наших задач чтобы не иметь дело уже с яблоками чтобы задача проверялись переход отправки чтобы все работало и функционировало еще лучше и удобнее для наших пользователей завершение хотелось бы сказать пожелать даже чтобы вы занимались инженерными задачами чтобы вы не были до погрузчиками и Да прибудут с вами эффективные процессы дата инженерии Спасибо за внимание очень очень хороший тайминг и теперь пока спикеру Некуда бежать со сцены У нас есть вопросы а за лучший вопрос у нас будет специальный подарок от горячей у тебя будет очень тяжелая задача Нужно будет выбрать лучший вопрос запоминай пожалуйста чтобы потом по одному вопрос У меня на самом деле два вопроса верю но ты показал что у вас на этапе проверки конфигов прогоняется тесты Да насколько Соберется корректно Граф вы запускаете интеграционные тесты для этого добра чтобы Понять насколько корректно не знаю там аналитик разработчик или еще что-то все это реализовали Но тут скорее в своем функционале сбора графов мы уверены он просто Работает Он работает он логично интеграционные тесты соответственно насколько корректно запросы аналитика там или разработчика построен что он выведет то что нужно чтобы он не переделывал Это 1500 раз Ну мы же не знаем что он хочет второй вопрос чуть позже у нас реально много вопросов генерируйте питон файлы и потом уже яму файлы обрабатываются на лету airflow или вы генерируете дополнительно Ну мы как бы собираем кэш вообще и чтобы каждый раз когда графу нужно собраться airflow у нас продвигает Граф же всегда когда он воркер работает и прочее поэтому у нас есть кэш и если у нас репозиторий изменился мы кэш заменяем а вообще у нас вот есть готовые определения задач и мы по сути только строим сам Граф мы не храним мы храним готовые вот эти вот определение подготовленные со всеми конфигами то есть на двух тысячах задач Вы еще не уперлись еще не уперлись в том что на каждом бургере не успевает отрабатывать или выперлись так прошу Добрый день Спасибо подскажите пожалуйста Вы сказали что вы можете запускать какие-то нестандартные истории через контейнеры как вы это делаете из РФ Ну на самом деле я говорю что мы в основном стараемся использовать наш какой-то функционал но верфлоу мы используем докер оператор в данный момент и ну в Кубе есть под оператора или что-нибудь там еще похожее вопрос из телеграма от Николая как мониторится стоимость выполнения конкретных пайплайнов и стоимость задач конкретного заказчика или аналитика Ну у нас достаточно сложное такой мониторинг и наверное стараемся там делать какой-то топ по задачам смотрим эффективно и смотрим сколько данных у нас каждый запрос обрабатывает Исходя из этого мы уже можем посмотреть нельзя где-то с оптимизить нельзя ли где-то сделать партиции что-нибудь такое ну мониторинг конечно же ценовой эффективности и сама ценная эффективность на нас ну отчеты отчеты Следи за лучшим вопросом прям вот очень важно Это как нейрофизиолог говорю привет Слушай у меня вообще такой тупой вопрос Подскажи Зачем вообще генерить этот Граф большой огромный Почему не пошли по истории когда у вас просто много маленьких графов до каждого расчет Ну у нас допустим есть у нас было там 30 наших пользователей там 40 пользователей 40 контекстов Наверное мы могли бы им говорить вот пожалуйста работа в своем графике поскольку у нас там меняются сотрудники у нас какая-то одна задача может быть зависима то от одной задачи может зависеть нас много данных чтобы не усложнять какими-нибудь там сенсорами нашу систему Чтобы проще было и у человека не возникало мысли какой Граф ему нужно сейчас указать какой Граф эту задачу включить может быть у него задача по своему какому-то по своей сути она у нас в несколько графов может входить Так у тебя для каждого расчета был бы один Граф сингл Если у меня будет какая-то одна исходная задача которая используется в 40 отчетах ничего У тебя написано жетон твоим ямлю ты бы просто ждал пока тут посчитать я просто был бы ну не такой задачи как бы каждая вершинка это маленький Ну наверное Мы про это как бы не думали просто это один из способов но там на самом деле есть трендов которые вы сможете обсудить на автопати да Там не все так просто Следующий вопрос Спасибо вопрос как эта штука работы под капотом Если вы используете яму то есть оно динамически как-то внутри Flow берет airflow и операторы запускается Мы сначала что мы делаем мы считаем явно мы собираем уже у нас в памяти определение этих задач пойдем в кэш или собираем и дальше когда нужно построить Граф мы уже продвигаемся по вот этому самому нашему объекту Где хранятся у нас все определения где скрыты у нас уже точнее заполнены все у нас конфиги и в общем да я мало читаются но когда они прочитаны мы уже про них забываем и держимся в памяти связано с этим вопрос Если у вас приходит новая интеграция но вы сказали у вас там открытый Код Да от инженер приходит что-то пишут появляется новая зависимость вам придется продать перезагружать ради добавления Ну бывает бывает конечно как бы если говорить про задачи то тут мы вольны делать что хотим и сразу у нас идеи Но если контейнер нужно пересобрать которая у нас в котором запущено естественно нужно всё перезапускать как бы но если только код изменился но не изменился сам контейнер не изменились версии lip то мы просто не перезапускаем потому что у нас кот маунтится в контейнер А поскольку airflow у нас каждый раз запускает один тот же код то Ну нам нет нужды Следующий вопрос по центру зала прошу Да спасибо за доклад я опоздал немножко может быть я что-то пропустил а вот мне интересно документ хорошо там сгенерирован какой-то яму конфиг который описывает процесс и теле Да я могу представить как там с помощью ямы конфига описать процесс экстракции процесс загрузки данных вот как кастомная логика Вот именно на этапе трансформации закладывается в том плане что если Ну какой-нибудь инженер хочешь с этими полученными данными что-то сделать разработчик добирает откуда-то данные чтобы манипулировать каким-то образом эти данные как без использования кода на ямы конфигах это реализовано на логика Ну мы это делаем вопрос мы это делаем через разнообразные типы задачи то есть допустим у нас есть какие-то небольшие там э таблицы и таблица допустим у нас как-то плохо Изначально реализовано и она может себя меняться и у нас есть задача полностью у есть задача сделать инкремент То есть у нас указывается в таблице этой поле какое-то инкрементальное и в зависимости от того какая глубина нам нужна и он тоже указываем задача Мы можем что-то писать Например чаще всего это реализация не через кастомизации какой-то одной задачи А с более каким-то Старая добрая традиция стернал DSL сперва мы их делали на xml потом их делали на джейсоне сейчас мы их делаем на ям ликах Следующий вопрос Привет Спасибо за доклад вы как реализовали синхронизацию синхронизацию я генератор Как у вас работает когда генерируете Граф Вы должны синхронизировать его с метабазы Ну вот когда диплой происходит Вы должны в базе синхронизироваться и только потом будет запускать их Да как-то нас наверное Вы не реализовывали у вас под капотом сам это делает Ну как бы да там время есть синхронизация он сам подхватывает Просто я даже не припомню Что мы что-то вообще делали с расписаниями синхронизации Ну Запускай какой-то тоже тепло и когда у тебя не работает чего-то крупного чтобы она там вот например вы за тепло или подхватил изменения и будет запущена задача Ну вообще даже когда те источник те задачи которые будут запущены они запустятся которые в момент нашего диплои запустились они работают у нас со старой версии А когда у нас пойдет следующая задача Она же все равно на каждом воркере собирается заново Граф А когда у нас собирается Граф у нас перечитывается все конфиги и всё такое прочее поэтому мы можем быть уверены что у нас будет запущена именно последняя актуальная версия это же самое делает и я понял Не парились спасибо такие задачи в принципе достаточно легко решаются с помощью Generations там и других приёмов Здравствуйте а можно вернуться на слайд с яблоком просто для понимания предположим я аналитик да я хочу собрать себе витаминку там на 15 джоинов с парой окон у меня видимо этот запрос описан вот файлики или Да все правильно Откуда я знаю по этим 15 таблицам название задач от которых у меня зависимость на самом деле я про это не сказал но у нас есть возможность но когда наши пользователи собственно задача наши отправляют они просто делают пуш они делают запускают наш скрипт и с помощью этого скрипта мы пробегаемся сами и заменяем там именно таблицы на имена задач Всё достаточно тривиально и банально если рассказывать Следующий вопрос с правой части зала прошу меня может быть немножко глупый вопрос не рассматривали Луиджи как часть как часть этой системы потому что мне показалось что вы более-менее придумали Луиджи Ну вот когда мы это все запускали Года четыре назад airflow был наверное на хайпе Я бы так сказал и все-таки надо пробовать когда мы реализовали базу функционал мы каких-то особых сложностей в генерации графа мы уже не делали там у нас генератор графа был написан Мне кажется за пару дней и поскольку все работало не было смысла искать какой-то дополнительный функционал или искать простоты которые нам может дать Луиджи что у нас такой большой сложный такой более доступный низкий пород в принципе все просто работает и говорю когда она не устраивала Мы обновились думали останемся на нём или нет остались Следующий вопрос справа части галерки ты всё ещё пытаешься запомнить лучший вопрос Ну да Пока что мы усложним твою задачу прошу Где хранятся корриды вообще ну Кредо у нас хранятся в общем болте А когда они приезжают на тачку но они как бы лежат в конфигах просто мы записываем их в наш общий файл с параметрами ну или в случае каких-то там систем типа Гугла он обычно хочет курить один jsonic там ну мы храним кредиты в файлах редко храним в Вот и Ну естественно на этапе сборки графа у нас Кредо уже подсосались систему и мы через какой-то один модуль вообще можем секреты получить Следующий вопрос из левой части зала Спасибо за доклад У меня вопрос Вы рассказывали Как вы иммигрируете данные из Москвы в биквери и делайте это через клаустроен и соответственно Я подозреваю что если бы я пришел с таким решением потому что мы решали такую же проблему то мне бы операциям сказали бы зарево пилите за консистентность данных и соответственно Как у вас контентностью проверяете ли вы потом данные как вы это делаете и рассматривали ли вы альтернативные решения там дата Fusion того же Гугла вот мы как изначально пошли про какую-то модульность про маленькие как бы манипуляции с данными там выгрузить из одного в другой и так далее обернуть У нас есть возможность указав ключик например И вообще наверное Мы хотим чтобы если наши данные успешно были выгружены что то чтобы задача пошла дальше если данный согрузились неуспешно хоть какой-то этап пошел плохо Ну мы все фейрим я бы наверное так это назвал и Ну кажется что если нас успешным получили Коннект базе выгрузили все данные получили этот Файлик что кажется что если процесс завершился успешно то Следующий вопрос Спасибо большое за доклад вопрос про то как это работает а не то как устроено Я так понимаю мы имеем большое количество пользовательских объектов каждый из владельцев отвечает за качество данных в этом объекте получается такие цепочки вот не возникает проблем у потребителей этой системы с тем чтобы найти Ну грубо говоря виновного или ответственного в том что что-то не так чаще всего если цепочка большая то конечно может возникать потому что если много трансформации А у нас система построена Так что трансформации много и трансформации делать Просто и нередко проще сделать трансформации Чем сделать какой-то то конечно проблема могут возникать но опять же вот про целостность целостность качество наверное у нас не возникает много каких-то проблем Ну а если возникают то придется разматываться куда-то куда-то в прошлое фронтенд слева Спасибо за доклад Андрей Подскажи вот исторически сложилось что любые селф-сервис системы они подразумевают тем что там ими могут пользоваться там от технички до генерального директора Вот но практика показывает что это не так вот у тебя был слайд что там Да я занимается онбордингом есть какой-то чек-лист когда вот к вам приходит какой-то там бизнес подразделения Да и после какого-то бординга вы говорите Нет не приходи больше со временем от технички до генерального директора все становятся программистами вообще нет Мы стараемся чтобы все-таки наша система пользовались и стараемся делать задачи манипуляции с данными какими-то простыми и предусматривать что-то может пойти не так минимальный порог минимальный порог знать знать что такое яму написать из кель Я думаю чаще всего да На этом этапе люди просто хотят себе какую-то там посчитать витрину чем больше у них потребности допустим в ту же MP3 у нас Недавно была задача интеграция Всем привет И там уже сложнее там же ты уже должен не всё можно с нашей стороны сделать абстрактным и нужно понимать как это устроено но всё равно учим чтобы ну вот эти какие-то инженерные компетенции они распространялись потому что мы такие Следующий вопрос фронтен справа нас еще про то как вы заставили аналитиков притащить часть своих задач к ним ну то есть у нас аналитики очень загружены и чтобы сказать им пишите Еще плюс 8 строчек кода это будет скандал скажем так то есть вы заблокировали все остальные возможности написания и обработки данных или как Да нет пожалуйста просто не знает что если они хотят допустим в тот же отчет что-то доставить и не гадать когда им там стоять расписание и получать какие-то плюшки то как будто бы ну человек может в первый день прийти и такой Что такое яму поискать И будет уже описывать какие-то простые задачи и даже там когда мы разворачиваем какую-то нашу небольшую инфраструктуру для вот этого допустим замена задач на имени таблицы на имя задачи даже там как бы проблем не возникает это просто Ну чаще всего это момент отбординга и когда приходит онбординг у человека он готов уже наверное на все Он такой ну в этой компании это так работает и мы как-то наверное сноубординга еще приучаем Ну вот к нашей системе как у нас проходит процесс И как мы с ними ещё один вопрос А по поводу чистки мусора При таком легком выкате напротив то есть условно если я хотел себе витринку и там 9 вариантов накатал запушил с транзакциями на десятый посадил отсчета 9 валяется как вы это отслеживаете ну у нас же бикере там нет транзакции вообще я сделал условно 10 фактами многомиллярных пользуйся на самом деле одно остальные девять были очень легкий пуш наоборот поэтому когда закинул они там лежат Ну мы следим еще за тем что как часто Короче у нас используется данные смотрим за размером потому что и нам хочется вообще понимать За что мы платим мы смотрим за чистоту использования таблиц у нас же есть список мы можем понимать как часто нас таблица используется можем понимать как часто таблица модифицирована и если возникают какие-то там у нас такие старые огромные таблицы которые наполнились или только нами наполняется не используется уже как бы возникает вопрос Может быть они уже и не нужны порой проходит у нас какой-то такая чистка мейнс и самое неугодные отправляются истории Здравствуйте спасибо за доклад подскажите есть ли у вас ограничения доступа Ну то есть там как-то может по группам чтобы с другой группы не смогли запустить тот Дак который не принадлежит Ну у нас скорее ограничения по тому Куда В итоге приехали данные То есть если тебе положено к этим данным иметь доступ они у тебя будут ролевая политика это то о чем мы всерьез будем такая расширенная ролевая политика то чем всерьез Будем думать в нашей вот этой версии которые мы все мечтаем которая будет вообще супер"
}