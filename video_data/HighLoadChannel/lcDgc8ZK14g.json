{
  "video_id": "lcDgc8ZK14g",
  "channel": "HighLoadChannel",
  "title": "Как мы расширяли систему, построенную под Oracle... / Сергей Луговой, Евгений Чуканов (ЦФТ)",
  "views": 752,
  "duration": 3297,
  "published": "2019-12-05T08:50:44-08:00",
  "text": "всем добрый добрый день в нашем докладе вы расскажем не о формах отчетности по интересней будет а именно о том как мы расширяли систему построенную подарок возможно там и есть формы отчетности вот как мы и расширяли и делали умею с помощью машинного обучения и всяких новых модных штук виде новости или решений именно вообще как мы дошли до такого как это делали с чем столкнулись ну и что результате у нас вышло из всего этого сначала хочу вам представить коллегу евгений чуканова он у нас ведущий дата аналитик машинного отделения группы компаний cypher это вот как раз нам умные модели да и умеет делать да я в свою щель представляю вам его сергей лугового руководителя группы инженеров данных который занимается у нас разработкой проектированием и архитектурой вы с нагруженных систем цфт помимо всего прочего они занимаются разработкой системы для поставки данных для разработки машинного пути обучения ну и так же я рад представить вам нашу компанию эта группа компании центр финансовых технологий компания занимается разработкой и продуктов для ощущения всех видов банковской деятельности и банковской деятельности вот америка вам это все знакомы ну и более подробно познакомиться с нашей компании вы можете на нашем прекрасном стоянием надеюсь вы там уже побывали забрали какие-то сувениры на память или вы или ценные призы вот переходя к теме нашего доклада хотелось бы начать с того что у нас есть из чего мы начинали а есть у нас система обработки транзакции основанный на уроках не лишь основа норки hydra написано по иску или но требования рынка постоянно меняется потребности бизнеса тоже растут и и возникает необходимость внедрения каких-то новых инструментов ну как это происходит обычно приходит бизнес заказчик и говорить дат аналитиком ребята перейти данные которые вам нужны делать с ними все что хотите но нам к определенному сроку например следующему кварталу нужно повысить наши бизнес метрики ну скажем прибыльности на 5-10-15 чем больше тем лучше процентов ну что ж дат аналитики берут данные куда-то инженеров начинают крутить вертеть их в ноутбуке смотреть анализировать строить какие-то регрессии обучать нее рамки все как полагается и в конце концов говорят бизнес заказчику мы все сделали мы все проверили мы сделали новую какую-то систему прогнозирования прогнозирование которое сделано новую модель а если внедрить это повысит нам вот не только прибыльность но скажем еще и посещаемости еще будет выгодней для клиента ну что ж если действительно все так если все тестировали по доверили это все правда то конечно же нужно внедрять а как это делать ну как процент мой особенно трогать не хотим он прекрасно справляется своими обязанностями которые на него возложены мы просто рядом поставим микро сервис еще один куда мы упакуем и нашу новую модель машинного обучения процессинге местное что мы обучим что на этапе подготовки транзакции например когда мы посчитаем хотим посчитать скидку для клиента сначала нужно сходить это некрасиво запросить к это прогноз скидки той же самый причем сделать это нужно синхронные обязательно потому что клиент стоит здесь сейчас ждет какая же сейчас мне будет скидках и тут есть одни такой подводный камень что модель который стоит центре этого микро сервиса само по себе работать не будет ей для прогноза нужны какие-то данные если раньше processing учителя скидку для этого потребовалось всего лишь там не знаю содержание корзины товара и там в катар клиента и собственно все то теперь и потребуются и такие штуки как категории клиента средняя цена товара за последние полгода или может быть даже дали каких-то премиальных покупок которые были у этого клиента за последний год и в этой ситуации получается что бизнес заказчика он молодец он правильно сформируешь сформулировал требования к задаче и благодаря чему получил очень быстро способ решения от аналитиков дата аналитики тоже молодцы они сделали прекрасную модель которая точно повысит на все характеристики а вот даты инженеры не очень молодцы потому что они придумали как бы достать данные внедрить эту модельный конец production мне ну казалось бы все данные это уже есть они лежат ворог ли все нормально берешь сделаешь селекции строишь join и все достаешь пожалуйста но однако если посмотреть на все это дело попристальнее то получается просто так и select и не сделаешь возможно нужно добавлять дополнительные индексы а каждый дополнительный индекс это вставка в таблицу начинает проседать join и нужно делать опять же по данным который иногда нужны ладно там за последний час м да все что было по транзакциям клиента за сегодня а для некоторых моделей нужно чтобы там и за месяц а то и за год что-нибудь узнать поэтому как бы мы видим что из клей начинает исправляться и тем самым даже если мы будем работать на словах раковых все равно мы можем не успеть вовремя передать и данной для модели ну да раз уж у нас шла речь о том что данных многое что у нас сложно с индексами и там все плохо возможно поможет другой альтернативный способ по решения такой задачи это вот использовать мощности когда-то решений но действительно мы можем взять например все необходимые нам данные и выразить их на hd фосфатов и периодически запускать какие-то задачи по насчет у нужных нам данных на спарке но там тоже будет куча технических проблем связанных например с задержкой поступления данных а значит нужно очень как подлива очень правильно спроектировать и цель этих данных также если мы например будем запускать вот эти задачи по на счету признаков или вот данных от которой нам нужны периодически например 1 день 1 час то нужно очень серьезно заботиться с мониторингом срабатывание этих всех задач ну и наконец наверно самая главная проблема которая касается всех разработчиков и бизнеса и вообще всего это время внедрения то есть если этот аналитики придумали q это еще более новую модель скорее всего он работает потому что там еще какие-то признаки используются а поставка каждого нового признака это фактически ручная работа это нужно спроектировать это нужно сделать нужно выделить ресурсы не только технические но еще и разработчика туда поставить и наконец сделать это протестировать и потом еще когда провождение чтобы это не сломалась и в коем случае но получается что этими традиционными способами ну для каждой области для аналитиков инженеров мы задачу решить не может поэтому нужно переходить кардинальное иным подходом и начинать сначала сначала мы как бы подетальнее проанализировать требование получили вот список который но самый важный на его для нас то есть нам там по условиям задачи нужен нужно объединить данные которые составляют профиль клиента предоставить их высокую и быструю доступность в онлайне нужно чтобы это все работало максимально без программирование один раз сделали систему дальше и конфигурируем и и и работаем с ней луи нужно так подготовить данные чтобы разработкой перепроверка новых моделей для дата аналитиков стала легкой приятной задачей первым делом мы обобщили требования с группой и сгруппировали их по похожести и определили базовые наборы элементов с помощью которых мы можем решать задачи которые от нас требует бизнеса первое что у нас появилось это счетчики это всякие количественные суммовые характеристики там рублей штуки килограммы и всякое такое все что нужно запоминать за какие-то периоды времени следующее это свойство которые в совокупности составляют профиль клиента магазине на еще и какой и других сущностей есть так же одна штука интересная которая появилась у нас это отношение к то это факт и взаимодействия например клиент с магазином и иногда эти факты нужны сам факт в принципе что такое взаимодействие было иногда нужны что вот была ли она вчера или на прошлой неделе ещё одним важным элементом это является аккумуляторы аккумуляторы очень нужны для дата моделей для того чтобы например посмотреть быстренько что было в последних десяти транзакциях клиента то есть ограниченные хранилище там с вытеснением старых более новыми записями ну и последняя наверное тоже очень важная штука это история транзакций она ничем не ограничено по количеству проводилась что штука непростая но у нас была задача предоставить к ней быстрый способ операции от более свежих событий к более старым но да и а самое главное что такая категоризация она отлично зашла для того чтобы строить признаки на ее основе ну то есть например при помощи счетчиков можно выражать любые количественные признаки например при помощи них можно даже речники это заставлять или там доли все возможные конверсии ну например для вычисления любимой категорий товаров достаточно просто для каждой категории возвести свой собственный счетчик но этот счетчик который будет самым большим наверно тот и будет самым любимым хотя сама любим и категории пример отношений это ну просто записи в профиле клиента где именно клиент делала покупки какие то их тоже можно быстро и шустро достать в онлайне как-то проанализировать и понять с кем из клиент имела отношения хороший пример коммутаторов это например дата последней покупки в категории ну то есть мимо нас протекать транзакция мы запоминаем дату и время тогда это произошло как только пройти следующая транзакции она вытеснит предыдущую и у нас аккумулятор получается емкостью 1 чтобы проанализировать какой-то типичность покупок по сравнению с предыдущими десятью нам потребуется же аккумулятор емкостью 10 то есть тоже все очень легко и хорошо ну и наконец свойства это более такие сложные какие-то признаки которые не покрывают предыдущие категории которые насчитывается некой эвристик ой по взаимоотношению с клиентом ну например как тут указано это какая-то категория скидки у клиента которое получилось ну таким образом она ли сделала приступили к разработке видения систем сначала надо понять как она в принципе будет устроен ну начнем с того что как бы у нас есть processing он обращается к микро сервису он свою очередь идет заданными к нашей системе система собирает целый пакет данных который запрашивает микро сервис упаковывать их и передает их обратно тот уже на этом пакете данных который там может состоять и счетчиков там транзакции аккумуляторов и так далее так далее разных свойств делает некий вывод передает его процессингу processing на основании этого вывода там что-то подправляет в транзакции например скидочку предоставляет клиенту и проводит эту транзакцию по факту совершения транзакции processing нам передаёт как раз что там было то есть всю информацию о том что с этой транзакции произошло и задача нашей системы быстро провести учет этих данных которые содержатся в транзакции правильно их разложить вот поэтому как бы первое такое самое важное наверное под система нашей платформы это вот именно система учета ну поскольку мы определили элементы хранения да у нас получился такой красивый ограниченный набор нам позволило это создать сделать систем учета настраиваемый то есть мы в рамках не и описываем сценарий как мы будем чтобы вам как будем разбирать это данные то есть мы их разбираем делаем трансформации например необходимые данные чуть не в том формате мы можем там чуть переиначить потом делаем обогащение данных например их берем там каким дополнительные данные туда же вставляем строим план исполнения учета то есть какие счетчики нужно обновить какие свойства записать и потом уже как бы именно этот план исполняется в результате всего исполнении после того как данные помещены в систему хранения также система их помещают в архив для дальнейшей аналитики но и хранение уже обогащенных данных но да и при чем тут именно на обогащение тоже тут следует сделать особенный упор потому что когда мы им имеем дело именно с на счетом в онлайне каких-то признаков у нас часто бывает что к нам поступают события где данные неполные ну например при инициализации транзакции у нас есть на руках все данные которые только могут быть ну например это и продавец и покупатель который участвует в этой транзакции а вот когда идиот завершения транзакции все что у нас есть на руках это собственно номер транзакции и статус что она вот завершена успешно а нам нужно на считать именно например праздники относительно успешных транзакций по тем двум ребятам который продает и покупает и покупатель а сделать одно основание просто номера и статуса как-то не так-то просто и поэтому нужно в обязательном порядке чтобы события завершения транзакции было обобщено данными из ее инициализации кроме того это ещё более важно на этапе ретроспективного анализа ну то есть когда когда мы уже постфактум смотрим на транзакции нам очень важно еще не только какие данные были в сама транзакционные контекст при которых оно происходило ну например какая это же была средняя цена на товар а именно тот момент когда проходила транзакция до 0 из скажем хороший пример это на 3 погода какая там погода имена в том месте в то время мало кого справочник об этом скажет и поэтому данные нужно обогащать ну и наконец до когда уже они полностью все поглощены максимально как только можно их нужно положить в архивы эти события будут ждать своего часа что побывайте в ноутбуке аналитика или там пони прошелся spark ну вот уже тут представлен пример схемы учета кажется много букв ничего не понятно но на самом деле с некоторой привычкой эти документы очень хорошо читается и их структура хорошо подходит для того чтобы запрограммировать frontend для пользователей системы которые будут эти строить сценарий с помощью мышки для доступа в данных в онлайн-режиме система у нас будет предоставлять не предоставляет уже листа пить вот по rest api вы можете обратиться ко всем коллекциям выбрать счетчики сказать что мне нужны какие-то отношения там взять части профиля аккумуляторы или взять итератор на историю событий микро сервис наш может использовать детей запрос или стоппи хочет последовательно хочет параллельно ну понятно что это не очень удобно поэтому мы для удобства к чтобы облегчить жизнь писателем микро сервисов сделали возможность опять же описывать планы запросов и сохранять их в схеме учета вместе с ней в том же документе этот план запроса позволяет задать сразу несколько действий которая должна система сделать чтобы выбрать данные и разработчиками графе 1 of нужно всего лишь передать идентификатор параметры к плану запросов и они получают большой такой документ где там уже лежит все все готово все пожалуйста давайте свои алгоритму исполняйте на нем в этом наверное что-то похожее на при предстать на той вышке ели будущем мы планируем также внедрять граф дверь мы поскольку у нас система не имеет четкой схемы данных то есть нам не совсем как бы вот так легко внедрили raw курю сервер готовы уже готовые мы конечно не можем придется что-то самим думать в принципе эта тема кажется нам перспективной ну вот например маленький планчик запроса сначала мы находим идентификатор клиента по кровь в профиле по его телефону или имени и потом уже пойдут это мой дефек идентификатор удостоен профильную информацию общего характера а также то что относится к шопингу берем там некоторое количество счетчиков и аккумуляторов тоже ничего в принципе не сложно и хорошо читает ну да но это та штука смотреть сергей сказал то что касается именно взаимодействие онлайн а то есть взаимодействие между микро сервисами между процесс никому про сервисом то есть получение данных онлайн какие они есть здесь и сейчас здесь придет код как вот при таком подходе при подходе когда его на здании обогащены и лежат уже в архиве можно легко и просто читать собственно данные но тут просто собственно написано аналог как спарки дело с насилиях звездочка фроммом какая-то таблица по условию что нам нужны только успешные транзакции из такого то время это по такой то время все очень легко и просто раньше для этого требовалось сделать джон мы куча таблиц подтягивание куча справочников флагов и всего чего только еще можно собственно как выведение есть все в принципе готова и у нас получилось вот какая то такая архитектура системы и у нас есть подсистема приема данных кстати например и 40 ламы данные получая с помощью джеймса там на арке создается очереди сообщения мы к ним подключаемся и потребляем событие оттуда может быть по и ждите ставки по ристопии можно к нам дано и загнать точно также подсистема учета производит трансформацию обогащение данных строят план учета и вырежу дать его исполнении то есть все данные складываются в под систему хранения уходят в архив либо отправляется в не происходящую очередь например если у нас есть другие системы которые тоже вы хотели после у нас что-то с этими транзакциями поделать но и есть выдачи данных парис топи с помощью спарка можно делать большие всякие штуки умные ну и давуд и уже кафку и говорилось как исходящего очередь сообщений ну все понятно что надо делать но прежде чем что-то делать нужно разобраться с подсистема хранения потому что мы хотим использовать ну что-то уже существующие не будем же мы и сами разрабатывать порой то есть велосипедами мы дружим других производителей тоже ну собственно с чего начать ну в принципе вот наши архитектурой вот эти наши элементы они хорошо ложатся на тему become баз данных годы диктатуры около family & big tree dvb-s данных в то что там не надо четко определенную структуру легко добавить новую колонку это не живет лишний памяти и места на диске но самый легкий способ пойти в яндекс или гугл спросить что за у нас есть популярное хорошее быстро и модно и так далее но яндекс или гугл у них отцы как бы на первых строчках идет из близ и кассандра но и там список может быть длинный но поскольку у нас была уже claude рано которая как раз наших дата аналитики вертят своей модели атома лишь бы из в коробке мы начали анализ ведь вы за еще у нас до этого были проекты в которых так иначе мы использовали кассандру то есть уже был с ней его под проанализировали кассандру плюс к этому в да тут нас было тыкать иди бы из кассандра близко того нам показалось что профильную информацию ну хорошо подходит манга почему бы ее тоже не потестировать посмотреть чего я сейчас не буду вдаваться в детали как мы чего выбирали что мы тестировали это наверно тема для большого отдельного доклада но в результате у нас победила кассандра нам на ней наверное более универсальным способом удалось сделать это и это и все более-менее адекватно почему именно кассандра ну в первую очередь нас интересовало скорость учета чтобы все с минимальными задержками ложилась по системе хранения и в общем это было самое важное ну и по тестеров так кассандру если обойтись без транзакций там нет то есть обойтись еще и без lightweight транзакции их них то действительно даже на моем ноутбуке там десяток-другой тысяч операций вставки и в секунду можно получить я уж не говорю об нормальных серверах нам удалось вырази все наши вот эти элементы хранения через и дым патентные операции косовский то есть что надо скорость и плюс мы не имеем проблему с повторными приходами одних и тех же событий то есть мы его спокойно по новые обрабатываем результаты обработки ложится на те же самые места то есть мы обсе себе не греем воду это тела ну и масштабируемости то есть мы сделали такие рекомендации для составителей сценариях что нужно раскладывать данные максимально по разным хранили чем это нормально то есть не надо тут пытаться придумывать какую-то сложную модель по разным хранилищем по разным коллекциям раскладываются счетчики отдельно для клиентов для магазинов тоже отдельно что позволяет нам параллельно запрашивает сразу кучу dota кассандра в кластере и собственно с таким широким потоком получать данные по нашему запросу так ну да тут у нас еще предыдущий опыт опять же с кассандрой сказался вот хочу немножко напомнить на тему того что сыч бэйзел у нас была проблема что запуск воду лишь api и в общем немножко становится грустно как же с этим работать в к самой все такие более-менее похоже что-то похожее на и сквер сильно упрощает жизнь но и доступ из парка да есть носили коннектора некоторые он евгений не даст соврать но как бы конечно без трудности это не обошлось не все так просто было то есть если у нас отношения свойство аккумулятора история так нормально легли без проблем а вот со счетчиками до пришлось попотеть то что в кассандре есть механизм для того чтобы работать со счетчиками дат но что такое счетчик его нужно увеличивать там или уменьшать это атомарная операция то есть тут у нас либо транзакции начиная дата маячит на горизонте либо еще какие-то другие механизмы в кассандре и то есть то есть есть можно завести специальная коллекция счетчиков и она позволяет атомарная их там увеличивать уменьшать однако нам в рамках например учета одной транзакции нужно ни один счетчик посчитать мы должны там несколько счетчиков на считать и желает она все это более-менее там одной пачкой сложить если у нас мы будем бороться с дубликатами то есть если мы инкрементируем счетчики нам нужно знать не w или это запись нам опять прилетела то есть опа опять мы тут смотрим нарисовалась транзакция в полный рост чего бы вы хотели избежать поэтому была разработана решение что мы и счетчики все-таки на первом этапе сохраняем это патентным именно способом как в виде старых записей и по истечению там астрономического часа все что за предыдущий час мы насобирали мы агрегирует и уже перекладываю другую как к лицу там уже с другим ключом парте shining ли чем то есть данные уже загримированный там чуть-чуть по-другому лежат и вот по таким агрегатом у нас очень быстро мы можем доставать счетчики за любые периоды времени мне у нас легко суммируется а если нам нужно еще и за этот час который не до завершенный или еще не да а бильгя рованный запросить данные та-дам и вот за последние там час или полтора грубо говоря данные уже по сырым до агрегирует запрос ну и в общем это показало по скорострельности неплохое решение как бы мы зато полностью независим от транзакции с профилями тоже была некоторая не задачка потому что все-таки это это кришне киева или база данных она поинтереснее есть даже вторичные индексы однако вторичный яндексе имеют свои ограничения там нельзя было их и уникальных индекса вторичных кассандре нету что тоже как бы для профилей не очень хорошо потому что нам нужно понимать а если у нас такой профиль или нет такого профиля и там если без уникальных индексов то у тебя ты должен на приложение перекладывать головную боль и как справляться с этими проверками так далее так далее но есть конечно техники но хотелось что-то поинтереснее решить и мы иоанну и их там у них есть ограничения на то что списка вы поля объектом списке или map и сеты они не могут там тоже в этих во вторичных индексах нормально участвовать они-то потеряла did you неважно мы решили эту задачу через заведение рядом с основной таблицы с данными дополнительных таблиц которые уже по-другому перестроен ими кручами мы храним ссылку на основную таблицу и это позволил нам быстро искать быстро вставлять но как-то решили эту проблему получается еще одна проблема с которой мы столкнулись это когда пытаешься в кассандре добавить колонку например из 2 applique инстансов приложения ты можешь попасть на два разных на 2 разных нот и кассандры и попытаться добавить колонку то есть изменить схему базы данных можно в общем добиться того что в результате мы базу данных можем убить таким образом то может у них начинается конфликт то есть одна нота успела создать колонка другая пытается создать такую же а еще в обновлении схемы с другой ноги не пришло для этого нам пришлось все таки реализовать внешний внешнюю блокировку изменение схемы базы базе данных это мы реализовали через у keeper ну в общем вздохнули потому что как бы ни хотелось но такие вещи наталкиваться ну да и то что сейчас сергей рассказал это как раз то что касается именно трудностях мнения трудности как эти данные представьте как карте вообще надо жить но также у нас были проблемы из непосредственно с самими данными на втором слайде когда вот мы показывали чем занимается cctv фото есть много бизнесов которые ориентированный на клиента и где я технически исторически сложилось так что данные об одном и том же клейте могут храниться абсолютно разных базах данных которые напрямую никак не связаны возможность различными полями возможно там несколько бы может быть даже разные форматы но тем ни менее это один клиента с точки зрения детали аналитиков наиболее востребованные признаки это признаки который касается непосредственно клиентов то есть что делает как и вообще и поэтому перед нами во весь рост стала программа проблема с объединение профилей вот из этих звездных разных мест ну а вообще в машинного обучения задачи объединения для сдачи поиска похожего эта задача обучения без учителя сдача пастеризации и при которой есть свои инструменты такие как например к ближайших соседей или специализированные какие-то алгоритмы для поиска этих ближайших соседей например оной а spotify и их объединяет то что в них записи представляет виде векторов ну то есть в данном случае если мы идет речь и пользователем и пользователя расклад на какой то большой длинный вектор а похожесть записей она оценивается по расстояние между векторами ну то есть если два вектора расстояние маленькое ну значит они похожи если расстояние большое ну наверное какие-то разные ребята и одри нас так как мы имеем дело с финансовыми транзакциями с вообще с клиентами очень было важно интерпретировать говорит ну то есть если мы две записи как нас лаковыми вместе то должно быть всегда железное обоснование почему мы так сделали как так получилось и мы использовали алгоритм объединение записи через граф ну для этого что требуется для этого 3 нужно выработать некие критерии с которыми многие согласятся ну то есть и бизнес и аналитики это будет все исследована например на первую картере говорит о том что если у двух записей совпадает полностью e-mail и номер телефона скажем не обращай внимание на fila то это наверно запись об одном и том же клиенте а второй критерий говорит о том что если например для записи о них по фио отличается на 2 опечатки или две ошибки то есть расстояние ливень штейна будет не не больше чем 2 и у них с помощью совпадает скажи номер телефона то это еще один критерий и вот эти критерии нам дают как бы ребра этого графа вершина будет собственно записи наших которым вы обеднять и потом впоследствии мы можем это обеднить через алгоритм connected компонент мы использовали для этого опять же spark выгрузили необходимые данные на gfs да и вот на этом слайде представлена собственно код как именно это делается на спарки спарки есть встроенный политика graphics она сейчас на момент уже несколько даже устарело но тем не менее она работает то есть сначала мы читаем выхлоп каждого из алгоритмов то есть вы там семлер ideas как бы кандидаты на и объединения затем мы из этого всего добра строим граф из этих ребер и затем уговорим граф сделай нам connected компонент на спарке достанем оттуда вершины замок их обратно в int и обратно к идентификаторам и собственно выгрузили навестив с дальше мы можем это либо обогатить данные то профилей и как-то исследовать либо можем просто против это грузит систему но тут есть ещё одна сложность тем что пока мы возились тем чтобы выгрузить и данные пока в этом раскатывали кит алгоритмы и критерии лет это ново уже появились транзакции идут об этом что-то копаемся и чем хорош еще вот этот подход с критериями с графом тем что вот эти критерии можно свободно раскатывать в онлайне ну то есть если летит какое-то новое событие а там есть данные клиенте которую мы ещё никогда не видели такое можно прогнать все те же самые критерии на этих данных проверить и если какой-то критерии сработал ну значит мы можем отнести этого профиля этого клиента эти данные какому-то уже существующему профилю но если критерии ни один не сработал значит новый клиент и мы создаем новый профиль вот поэтому данные для критериев должны быть очень быстро доступны да окей собственно проанализировали архитектуры и так далее и так далее все реализовали ну и приступили к развертыванию и как мы видим разворачивались мы в кубе одной из важных систем и здесь в центре зелененькие кружочки у нас система динамическая система динамических конфигурируется и мы конфигурацию храним закипели ковром кстати тоже пользуется кафка например на время для того чтобы создать новые сценарии учета мы создаем документ как вот я показывал помещаем в репозитории пера создаем тоже маленький документ который описывает источник данных например еще другая очереди за оракла указываем что этот источник данных будет обрабатываться в этой схемы учета и полетели то есть система тут же подымает джеймс через джеймс кук коннектор конектится каракал и приступает к работе все это про можно задавать количество потоков и так далее ну и так же через руки пир мы конечно распределенные блокировки проводим и другое взаимодействие между компонентная обеспечиваем кассандра у нас тоже развернута в кубе была не просто пришлось в результате прийти к тому что использовать хост networking припевать лодок под и кассандра уже конкретным нодом чтобы съесть нормально на локальные диски в общем это там отдельной эпопеи мы также сделали для наших админов специальный командный интерфейс уважение некоторые привыкли мышкой конечно но большинство все-таки как любили так и любят командочки и с помощью команда чик можно найти джейсон документы помещать в репозитории смотреть там как себя чувствует очереди кафки и так далее так далее кафку мы кстати используем для того чтобы в сущий там например время на чего-нибудь не работает связи нет и так далее мы получаем событие 40 мы видим что связи нет мы можем поместить события в отложенную очередь кавказскую и потом ее потихоньку оттуда потреблять когда у нас восстановится связь на кафки кстати удобно там с помощью со спины freeze you move реализовывать о заке отложенные очереди которые можно там через минутку я приду и события заберу понятно поскольку мы кассандру развернули на хост нетворкинге мы предоставили к ней доступ и снаружи так что у нас иск lauder и spark может прямо к ней ходить можно job бы создавать которые потому кучу коллекции могут запрашивать ну и система также может писать архивов ваш dfs и потом уже на 5 же нас парковки их job of можно из этих обогащенных данных строит про перепроверять модели можно строить новые модели и так далее ну и сервисы по ареста петров ходят все довольны но до сергей рассказал про то как система уже поставлена стоит но тут самое время вспомнить а зачем мы все это дело и чем огородили а делаем это для того чтобы опять же насчитывать признаки признаки без данных не бывают не нас питаются они сами по себе и тут возник вопрос а где мы собственно эти данные это взять как нам эти признаки получить но самый первый вариант который пришел в голову это просто подождать ну действительно спросили аналитиков в какой глубины нужны данные ну годик-два ну что ж подождем годик-два она когда-нибудь там сама накопится надо считается неплохо но руководство идея как-то не оценила и поэтому ну раз уж моду этого насчитывали какие-то признаки на спарке был опыт почему бы не посчитать все что нужно опять же нас партии выглядите далее наш dfs берем считаем погружаем систему систем получаются некие некий начальный отчет которого она может уже дальше щелкать счетчиками чита свои агрегаты но это уже не понравилось разработчикам то есть это придется сделать всю работу заново то есть сначала описать ту систему теперь написать отдельно как это спор будет делать потом еще это сравнить и пока мы все это будем делать насчитывать вполне возможно первое время было не так уж и плох и поэтому мы остановились на третьем варианте который мы назвали назад в будущее ну что для него требуется нужно взять пласт данных который нам нужны ну например там за несколько прошлых лет превратить это событие для системы как в том виде как на это дело потребляет и погрузить их как будто они происходят рамзи сейчас только с поправкой на время что там происходило именно тогда и вот на следующем слайде показано как именно мы это делали то есть мы взяли все необходимые данные которые были в оперативных таблицах оракла использовали utilities куб для выгрузки наш dfs данных выглядели формат паркет как самый быстрый и удобный для работы среди fsm и наша задача была при помощи спарка сделать полную де нормализацию этих событий превратить это в те события как про игру употреблять эта система тут же мы столкнулись с другой проблемой то что как именно эти события хранятся в базе а в базе не хранится как любой нормальный нормализованной таблицы именно в виде конечного состояния но то есть эта покупка то там она будет висеть в статусе совершена а нам нужно восстановить полностью весь путь к кое-какое на проделала то есть от начала как она была введена может быть оно даже к это перешла потом возвращена и собственно потом уже завершена в этом нам помогли помогла магия опять же big data мы смогли потянуть нужные нам справочнике которые мы сумели наскрести ну и конечно же логе куда без них в общем после всего этого долгого пути наконец-то джейсон события были подготовлены они были тут же упакованы и отправлены в кафку с позиционированием по и дани в котором транзакции чтобы сохранить очередность как события именно происходило и отправленная систему и систему уже смогла нащелкать счетчики который все пленник ну таким образом чего мы достигли всего этого дела всем этим мы получили обобщенный профиль клиента и с помощью наших внедрений проверки признаков и так далее мы его получили всегда актуально что у вас профиля не разъезжается они с помощью опять же учетных схем там они дополняются с помощью например аналитических алгоритмов можно считать некие данные опять же помещать в свойства какого-то профиля то есть всегда актуальная информация все наши данные которые мы собираем мы рады предоставить микро сервисом очень быстром режиме то есть минимальные там милисекундные задержки для больших реально объемов данных также довольны и бизнес потому что мы без программирование позволяем легко реагировать на новые нужды нужен новый счетчик да пожалуйста можно подключить другой очереди тоже легко в общем очень и система получилась гибкая и очень удобно и но до игры очень сильно я бы лишился код для сбора данных для аналитики то есть вот на предыдущем слайде там был от где нормализации всех данных раньше чтобы расставить данные для построения моделей машину обучение приходилось все делать это заново ну и скрести по этим блогом по этим счетчиком а теперь достаточно просто пройтись фильтром по архиву и все выбрать данные которые нам нужны ну и также благодаря тому что данные обогащаются нас контекстом тоже очень удобно не нужно не нужно теперь же коллекция со всякими разными справочниками и отслеживать их целостности ну и наконец это умный поиск профилей которые теперь устойчив к печатка какой то возможно неполноте данных тоже можно спокойно эти профиль по каким-то вторичным признаком вывод из его которые мы это сделали для себя что старые системы не нужно торопиться выкидывает ампутации переделывать не знаю новое железо под них покупать нужно просто хорошо подумать о какую несвойственную не ну то есть не базовую функциональность вы можете старая система немножко выдвинуть да чуть чуть наружу высунуть забрать и новыми всякими системами можно их обработать и как обычно всегда есть некие функциональные есть не функциональные требования вот не совсем функциональные требования можно дополнительными системами легко решать ну казалось бы вот такой подход приводит к тому что у вас и данные все пахнут и пахнут да то есть вот у вас были оригинальные транзакции сейчас какие-то счетчики количество данных возрастает вместе с ними и не терапия в нашей вселенной но оказалось не все так страшно потому что эти данные во первых ложатся на не такое дорогое железо и доступ к ним мы можем предоставить очень быстро соответственно как бы не надо бояться этого нет нет нет ничего страшного в этом нет а ну и чтобы у нас это быстро работала в общем то что нам удалось все наши базовые элементы из по айдын пакетной схеме реализовать это существенно упростило в нам жизнь и в общем мы счастливо ты но в конце концов у нас система учета я там эта потребность прямо отлично ложится тут а если нам нужны какие-то новые признаки то есть готовились и поняли что хорошо повести еще день нового признака . он нам понадобилось еще год назад так мы можем взять эти же самые все данные за на торговали систему и все хорошо старый праздники от этого никак не испортится потому что все и дым пакет на ну и наконец теперь уже и бизнес заказчик молодец и дата аналитики молодцы и дата инженеры тоже молодцы ну конечно вы все молодцы что выпустили этот доклад мы были очень рада спасибо спасибо самое время задать разгромный вопрос чтобы все молодцы и запугали serve начнет ведь судя по всему в этой системе храните всякие данные типа имя фамилия телефон там транзакции выглядит так что это ну такие достаточно критичные используете ли вы какую-то функцию шифрование чтобы соблюсти протокола хранение персональных данных и прочее но конечно используем и например в на разработке чтобы выгрузить данные разработку дать разработчикам сначала проходит но это делает spark как раз да да и как раз выгружать 7 of us и раны и данные но нету в бою там уже как данные хранятся на в соответствующих контурах которые там не имеет доступа и так далее так далее то есть сохранностью персональных данных все хорошо дедовы спасибо вопрос такой вы когда совершенствуете алтарь и профилирование пользователей выполнять или перегрузка данных исторично и если да то обеспечивает непрерывность работы могли перегрузку данной что вы имеете ввиду актуализация то есть вы улучшили алгоритм то есть резак и там допустим какие-то исторические данные может быть лучше мы объединились допустим да это это да если например мы поняли что мы например кластеризация у нас работала как-то не точно то есть например 2 хлопку два профиля мы не до объединили то опять же вот это категоризация вот счетчики аккумуляторы они тоже отлично ложатся на объединение профиля но то есть если это счетчики они просто суммируются за определенные промежутки времени вообще для каждого и для каждого поля для каждого признака который делает в системе есть некая политика что делать в случае если например у нас мы решили два профиля обеднить и именно следует и политики там вот как раз и это опьянение идет сложнее конечно с разъяснением профиля если вдруг кластеризация сработала очень сильно ну зазря обеднела там уже немножко сложнее там приходится немножко подумать как это делать коллеги и спасибо за доклад прозвучало несколько раз большая нагрузка в цифрах можете столько транзакций в секунду только того гигабайт столько-то терабайт петабайт витрины вы просто непонятно сколько пар и обслуживать много вопросов много вопросов да и как бы они такие большая нагрузка давая мая все я я могу сказать что как бы именно в при учете в этом при загрузке старых данных то есть у нас часто вы там несколько нам нужно было про грузить 200 миллионов транзакций что такое примерно в этом идет речь сотник транзакций в секунду именно при ретроспективном поэтому дохожу до сотни мало не надо как бы это не целиком там не знаю не маршрутизация чего-то но тут надо понимать что как бы мы все таки очень много параметров храним и нам важно здесь их быстро было выдавать то есть мы справились задачи что у нас мы быстро учитываем но самое важное было очень быстро отдать вот в чем прикол спасибо еще такой момент что господа могут выключить петлички это назвать какие-то да да да пожалуйста всем привет коллеги спасибо за доклад вопрос такой и есть пара когда processing региональность все понятно есть глобальное хранилище данных кассандра как бы тоже все понятно а вот есть архив ждет вас так я понимаю данные выдвинулись нарисовали на схеме что данным 40 за какой-то период попали против для машин линга все это обрабатываю и выдает какой-то отчет с кассандры через какой период попадают данными архив и посредством чего то есть время идет транзакции в кассандру приходят приходят приходит приходит прошел год или два выглядеть в архив нет не совсем так вот если вы видели да у нас как бы сама сама платформа пишет данные и в кассандру и в архив то есть в процессе учёта то есть это происходит одновременно a spark в зависимости от может ходить в hd с если нам нужно покрутить модели да там папа старым данным и есть еще возможность из парка ходить в кассандру как раз у нас для маркета логических целей потому что там уже данная гриль агрегированный уже сконцентрированы и по гораздо лучше по ним ходить чем опять же там все подымать по из хдс а вот то есть это гораздо меньшие объемы поэтому быстрее происходит то есть все зависит от задачи что нужно посчитать его последний ряд видимо последний вопрос на здрасте спасибо за доклад едут записал пару вопросов вот первый вопрос прозвучал носит безопасности данных у меня записано так вообще как бы при обогащении вы говорите что-то пообещать какие-то там контекстом насколько потом можно доверять этим данным условно говоря есть контекст сама транзакции а мы потом еще добавляет что где вообще хранится в первоначально первоначальную общая информация о самой транзакции чтобы мы могли как-то перепроверить завали делать все верно мы более сохранили обогатили эти дары происходит ли какая-то валидации помещение на ну то есть мы данные получаем оригинальный из некой платформы оригинальные да то есть во первых если сильно так стоит задача можно их сначала записать в один архив еще не измененный это первое второе можно там что-то добавить обычно это слово добавить до они изменить по большому счету и уже добавлены обогащенные тут вот как раз слово обогащен это ключевое что мы ничего не меняем мы простоим делаем более красивыми более богатыми и они больше не нужны я не знаю ни для валидации мышь по ним ничего не считаем то есть как бы подальше топ они производятся только о каких обучение моделей там еще отчетах ну вот собственно если мы ничего не испортили то 6 рецепту видно зеркально что вот они должны изначально не просто обогатились мы имеем ну опять же зависимости от того что мы именно анализируем но опять же вот если это у нас уйдет инициализация транзакция там есть один набор полей когда идет завершения транзакции там но гораздо меньше например по линии речи этого оповещение о том что нужно как бы получить из них но на это опять завершения нужно богатеть и взять данные из int или зации потянуть то есть как бы сохранить этот тут некий с определенной да да да то есть тут немного не понятно что именно во лидировать то есть на этапе обогащение проверять родители такие данные были нанесли зации а если идет речь именно контексте более широком которые вот именно как погода или или там какие-то вот другие признаки но так они по большей части либо поступают из процессинга то есть а это источник который мы вы должны верить просто по умолчанию ну либо это какие-то агрегированные тоже данные ну которые покрывают ее не тестами их насчет и собственно как то так ну то есть в рамках этой именно система к такой задаче точно не стоит конечно мы конечно лично то есть мы берем оригинальные данные до оригинальная транзакции она приходит мы дополняем и какими то еще данными и потом это идет в архив это нам просто позволяет потом уже вот для ретроспективного анализа этом модели вертеть уже как бы потом не париться на эту тему что мы должны оттуда отсюда тын дын дын все собрать чтобы понять а что ну то есть какой контекст был в то время вот он у нас есть документик там в нем все написал спасибо сергей евгений спасибо огромное остальные вопросы я так понимаю какого рода"
}