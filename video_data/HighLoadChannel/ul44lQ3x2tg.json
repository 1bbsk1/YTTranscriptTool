{
  "video_id": "ul44lQ3x2tg",
  "channel": "HighLoadChannel",
  "title": "TechTalk \"FlowSchema и PriorityLevelConfiguration: как не \"задушить\" api-server K8s\"/ Дм. Крапивин",
  "views": 106,
  "duration": 681,
  "published": "2023-10-06T07:26:40-07:00",
  "text": "Всем привет Мы на конференции хайлот с вами Григорий дебриэл в компании euron и Дмитрий из сбермаркета Дмитрий Расскажи пожалуйста немножко о себе где работаешь Чем занимаетесь вот это вот вся история Да Всем привет Я Дима Крапивин Я работаю в компании сбермаркет Это самый крупный в России по доставке продуктов Я думаю все уже сталкивались с этим Вот я этим летом команды инфраструктуры живем Мы в облаках и в основном используем cubernet для кручения наших сервисов это сервисы как клиентские в которых клиенты непосредственно делают заказы это мобилка это веб- часть и там все бэкэнды части для сборщиков доставщиков и а для всего персонала которого у нас тоже довольно много как и наших клиентов Вот и сегодня я бы хотел рассказать немного о том как мы боремся с высокими нагрузками как мы боремся со сбором метрик с наших приложений Поговорим немного об этом кубы Это самый девопс который не человек а практика смотри нагрузки в кубах Там могут быть очень разные нагрузки это могут быть русские на приложении это могут быть нагрузки на хранилище ходят слухи что у кого-то даже нагрузки на тепло и случается Вот Но мы сегодня хотим поговорить про нагрузки на систему сбора метрик потому что это необычно Ну система сбора Метрика это что-то там сбоку приклеена прометеос графана посмотреть Казалось бы Откуда Там могут быть нагрузки откуда-то могут быть нагрузки А на могут быть когда у тебя огромное количество приложений которые запущены в кубе когда у тебя огромное количество нот которые в этом же самом кубернете запущены так как с каждой нотой с каждого приложения мы собираем огромное количество метрик в моменте цифры доходят примерно до 40 миллионов мы собираем этих меток Вот соответственно это крайне негативно сказывается как на пещеры самого так и на Прометей которые уже стал скажем так отраслевым стандартом для мониторинга самого бернатиса и для мониторинга который приложений которые там запущены вот собственно начиналось все с малого но разрасталось разрасталось в какой-то момент мы дошли до того что у нас стало 128 в конфигурации там половина примерно 48 CPU 250 рамп половина 96 CPU 596 а у нас сейчас в одном из наших кластеров которых у нас 10 но самый жирный кластер у нас это порядка 10 тысяч кодов 1000 неймспейсов примерно 3000 дипломатов Ну и как я уже говорил выше 128 нот вот под такое количество меток сам Прометей потребляет порядка 300 ГБ оперативной памяти и порядка 50 CPU При этом когда у тебя такое количество на импспейсов такое количество кодов Что делает Прометей он через куберетесь до конфиг опрашивает опишку чтобы получить актуальный поинты для сбора метрик вот хоть у опе-сервера есть и кэширование и другие различные хищения чтобы с него снять нагрузку но это не особо помогает когда у тебя такое огромное количество кодов особенно все начинает лагать когда идут какие-то диплои то есть самые крупные наши они могут скейлиться до порядка 300 подходов когда у тебя идет передиплоид 300-подов одновременно Это утилизирует ресурсы IP сервера в два-три раза больше чем в спокойном состоянии соответственно мы ловили очень много инцидентов связанных с тем что мы просто душили один описервер в одной зоне доступности так как он падал мы переключались на другую зону Он падал следом и так материале последовательно той зоны по сути получали распределенный отказ а здесь поначалу мы боролись с этим путем того что у нас было вертикальное масштабирование в итоге мы дошли до самой максимальной конфигурации которую можем себе позволить это опять же 96 CPU и 596 грамм но это тоже оказалось не совсем скажем так панацеей дальше надо было скалироваться горизонтально мы пошли немного другим путем в губернатисе двадцатой версии появился механизм пайоте and fairness который позволяет распределять запросы к описанию губернатиса по различным категориям и выделять квот на эти категории соответственно мы как только этот механизм появился мы его очень ждали и сразу же начали соответственно использовать то есть мы выделили отдельно критически важные запросы такие например как вопросы от администраторов самого кластера это запросы как раз таки от систем мониторинга и там самыми низкая приоритетными являются запросы от аккаунтов разработчиков которые хотят что-то посмотреть как их приложение работает то есть мы пытались с помощью этого механизма соблюсти баланс между тем чтобы никто не ловил отказы Никого мы не ставили в очередь чтобы никому не пришлось слишком долго ждать чтобы никто не получал ошибки но в то же время чтобы описать чувствовал себя хорошо и критически важные компоненты соответственно запускались вовремя и приходилось ждать появление метрик например до 5 минут как это случалось раньше мы провели тестирование и на всех наших кластерах это дело настроили но это тоже время не решает нашу проблему сбора самих метрик потому что В общем в какой-то момент просто метрики у нас растут в геометрической прогрессии у нас появляется Каждый день новые приложения которые из коробки уже поддерживают огромное количество меток соответственно мы просто упаемся в какой-то момент что мы просто не сможем справляться с таким потоком потому что у нас не будет машинки нужного размера Ты наверняка помнишь этот комикс где огромный даже борт и один человек показывает другому что смотреть у нас такие такие метрики А что это у вас маленькая в углу где график вниз идёт Ну это Метрика того насколько хорошо мы понимаем все эти метрики А прежде чем мы немножко поговорим про ваши планы на будущее Скажи вот когда ты упомянул 40 миллионов метрик это в секунду в минуту в час в день Это 40 миллионов метрик - это в моменте то есть мы скрепим в основном каждые 15 секунд Вот и в моменте получаем такое количество метрик а-а некоторые не особо критичной метрике мы можем скрепить каждые 5 секунд каждую секунду вот здесь точных цифр нет Какое количество этих меток но тем не менее как бы Прометей все это держит в памяти для оперативного доступа как минимум последние два часа он держит в своем волходе вот Собственно как мы решили с этим бороться в то же время на рынке появилось довольно много ошейник которые предоставляют распределенных хранения метрик которые позволяют строить отказу устойчивость Да кстати забыл упомянуть что Прометей К сожалению он не отказывая устойчивый То есть у него нет никакой схемы соответственно если у нас например запустилась нода под прометеем то есть запускается сам Прометей то При таком количестве меток его Старт занимает порядка 20-25 минут 25 минут ты просто сидишь без мониторинга и приятно и не знаю что у тебя происходит в этот момент произойти может все что угодно соответственно мы пошли в сторону решений которые начали появляться на рынке это cortex это Танос и Виктория метрикс мы проводили сравнительный анализ и больше всего Нам понравилось Виктория метрикс с ней скажем так познакомились наверное года три назад но в полную силу начали использовать примерно месяцев 8 и как впечатление впечатление прекрасные замечательный продукт мы смогли расставить во-первых распределенно расставить агентов во всех зонах доступности соответственно даже если у нас отваливается целиком зона там остальные зоны мы получаем по ним метрики мы сейчас находимся еще в переходном процессе То есть у нас есть и Прометей и Виктория метриксы они работают параллель друг другу Так как наши пас диплои завязаны в том числе на пивку Прометея мы не можем с ней так просто соскочить и над этим сейчас активно работаем вот но то есть мы получили отказы устойчивую схему и у нас есть сразу из коробки аппликация во все зоны доступности То есть даже если мы теряем целиком зона у нас остается исторические данные в Прометей мы раньше могли хранить метрики максимум 60-90 дней в зависимости от нагруженности кластера сейчас мы храним метрики три года и планируем увеличить этот срок до 10 лет по ресурсам там все крайне экономично с таким объемом метрик и например с фактором аппликации 2 а у нас появляются всего лишь три ноты каждая из которых там по 10 CPU и примерно 150 ГБ памяти Слушай ну вот сетап про который ты рассказал это такой золотой стандарт как сейчас смотреть за метриками бизнес intelligence и я думаю гость конференции с удовольствием обсудит это с тобой а на стенде Напоминаю что мы оба прямо сейчас на той же конференции что и Вы на стенде на стенде evron так Приходите к нам чтобы поговорить о том что сейчас происходит в it Ну что ж мы Прощаемся с вами из прошлого и встречаемся настоящим"
}