{
  "video_id": "NYTCXfkorZM",
  "channel": "HighLoadChannel",
  "title": "Построение масштабируемой и гибкой системы потоковой обработки данных / Игорь Яцевич",
  "views": 885,
  "duration": 3211,
  "published": "2021-10-11T13:38:04-07:00",
  "text": "ребят всем привет спасибо что пришли меня зовут игорь как них уже представили и да мы сегодня будем говорить о проектировании масштабируемые системы потоковой обработки данных я покажу на примере нашего продукта как мы дали возможность 4 с половиной миллионам компаниям загружать информацию о товарах и услугах собственно несколько лет назад я столкнулся задачей когда мы решили запускать новый продукт и на старте было достаточно мало водных и мы только знали что у нас будет много данных нам их надо достаточно быстро обрабатывать и нужно придумать это решение и реализовать его собственно за то время как раз за эти несколько лет мы решили эту задачу и накопился некоторый опыт которому хочется сегодня с вами поделиться чтобы когда вы сталкиваетесь с подобной задачей у вас были в голове зацепки либо в идеале план того как подходить к решению этой задачи таким образом если ориентироваться на кого на кого я сегодня ориентируюсь в роли слушателя то это я несколько лет назад backend разработчик medal winner уровне который ранее не сталкивался с подобной задачей и не имеет у практике хочется ее как раз таки получить для начала пару слов о себе собственно в бэк-энд разработке я с 2007 года за это время удалось позаниматься как достаточно простыми проектами так уже более сложными в рамках 2гис и с 2016 года я попробовал язык разработки горе до сих пор его не могу распробовать все с ним замечательно в данный момент я являюсь руководителем команды разработки 2гис товары и тема связана с проектированием архитектуры сервисов она не всегда была очень интересной и я всегда вписывался все-таки и движухи собственно как раз в команде вместе с ребятами этой темы активной занимаемся ну и когда у меня остается какое-то свободное время всей этой деятельности я его посвящаю музыки а именно игре на электро бас-гитаре кому интересна эта тема них и лот можем тоже поговорить после вступления и прилетел я сегодня вчера в питер из новосибирска именно там находится историческая родина рэнди 2гис а вот недавно у нас открылся офис разработки в санкт-петербурге на литейном кому интересна эта тема приходите на наш стенд мы расскажем подробнее вот таким образом сегодняшнее мое выступление можно условно поделить на две большие части 1 из них будет про то как же все-таки выбрать архитектуру и 2 когда мы и выберем понять какие хранилище использовать как выбирать и я очень люблю примеры сам всегда на них хорошо обучаюсь поэтому вам их тоже обязательно очень много приведу чтобы было понятней можно было по задавать какие то вопросы ну и начинаем с архитектуры погнали для начала пару слов такое что что представляет собой 2гис товары собственно цель нашего продукта нашего проекта это собрать информацию о товарах и услугах либо предоставить какие-то сервисы для загрузки этих данных затем обработать их и после этого дать возможность уже конечным пользователям возможность найти то что им нужно либо ознакомиться с ассортиментом в компании то есть если показатель на реальных кейсах то мы можем найти интересующую нас компанию зайти вкладку цены и посмотреть что же в ней есть и по какой стоимости также можно решить и обратную задачу когда нам нужен какой-то конкретный товар мы хотим его найти в городе где он продается по какой цене хочется тоже этот сценарий решать окей более менее понятно какой продукт мы хотим делать но с чего начать начать лучше всего всегда с требование а именно когда вот у вас большая энтропии хаос в не понимаете вообще с какой стороны подобраться надо его структурировать а именно попытаться понять что же вам нужен то есть те самые требования как раз к системе составить и первое про что мы начали думать и оценивать это как раз то с каким объемом данных нам придется столкнуться и по по факту как раз наша аудитория это четыре с половиной миллиона компании которые справочники 2гис и и нам надо для всех этих компании дать возможность загружать информацию о товарах и услугах при этом если посмотреть на распределение товаров то есть четыре с половиной миллионов компании это хорошо а товаров то сколько мы провели небольшое исследование и видим что у нас делиться следующим образом что достаточно большое количество компаний в которых ли небольшая товарная номенклатура и есть конечно небольшое совсем количество виде одного процента у которых очень много товаров вот мы и порядка десяти процентов тех которые по силе единства интервал находится замечательно мы поняли про объем данных следующая важная часть нам нужно понять с какой скоростью мы должны собственно обрабатывать эту всю самую информацию то есть с момента того как данные поступили на вход когда пользователь будет иметь возможность ими уже воспользоваться и а поговорив с бизнесом собственно с нашими основными заказчиками кому интересно и замещение мы поняли что 95 посвятили в 1 час это норм при том что текущий 50 и persantine размер составляет несколько минут вот окей хорошо это мы поняли дальше нужно понять а что у вас будут за данным то есть кто вам их будет загружать в каком они будут виде это будет структурированная формации как часто она будет обновляться то есть это все что важно продумать и от этого отталкиваться мы если рассматривать про наш проект видим что полнота данных для всего проекта имеет очень важное значение поэтому у нас будет точно множество источников виде каких-то партнерских интеграции различных способов загрузить данных ну и собственно с разным периодам обновления всего этого дела окей это тоже нужно держать голове даже если мы сделали спроектируем нашу систему идеально с первого раза мы закроем какой-то наш скоб задач то нам и и однозначно потребуется развивать и вот это самое развитие должно происходить без остановки процессов то есть мы не можем в которой какой пересказать так сейчас по ребят подождите вот учета остановим она пользователи не будут иметь какой то результат то есть это очень важная тема ну и в конечном счете нужно все-таки посмотреть кто ваши пользователи которые будут собственно конкретные сценарии бизнесовые решать и в нашем случае активная аудитория пользователей в месяц сейчас составляет 57 миллионов и при этом надо понять кто эта аудитория в как она географически распределена нашем случае опять же это россия и страны снг окей с требованиями определились это очень важная часть вашем проекте для того чтобы в дальнейшем вы могли бы лидировать просто все решения принимаемые в тот или иной момент времени и после того как мы поняли какие у нас есть требования нам нужно высоко уровне во представить архитектуру нашего как раз сервиса нашего большого проекта и здесь очень здорово и классно идти от бизнес-модели того как устроена собственно описание нашего сервиса то есть что у него под капотом происходит также здорово делай как раз декомпозицию на реальной части системы если вспомнить мой рассказ то можно выделить первую часть которая отвечает за источники данных здесь могут быть как абакан сервисы для возможности загрузки к нам каких-то данных от представителей компаний так и различные сервисы по сбору этих данных из интернета ok с первой частью понятно что у нас дальше дальше мы собрали данные из разных источников нам их нужно уже обработать что если мы их привели к некому общему виду и эту информацию нужно теперь обработать ну и после того как мы обработали и подготовили срезы по которым как раз нужно искать пользователем и и как-то отображать вот уже поверх всего этого дела можно строить продуктовые api который будет реализовывать конечно и пользовательский сценарий наших продуктов ну и выглядит что так вообще это все похоже на микро сервисы кто не любит микро сервиса можно просто назвать сервисы суть особо не изменится мы приходим к тому что вот высоко уровне во у нас есть такие достаточно три большие части системы и потока данных устроен таким образом что мы получаем когда имеем такую схему ну собственно как раз логика вот этого бизнес какого-то этапа логика каждого сервиса у нас она не капсуле равана то есть мы подробности какие-то хранима у себя внутри при этом на границах сервисов у нас получается стабильные контракты которые уже используются другими частями системы замечательно при этом каждый из сервисов может выбирать удобные для своего кейса хранилища то есть выбор серебряные пули но это достаточно тяжелая сложная задача и по факту лучше к ней все не сводить ну и собственно в данной схеме мы видим что у нас есть сервис и у нас у каждого есть свои сторож а как же они будут собой общаться то есть что у нас будет находиться на вот этих самых границах и здесь неплохо как раз посмотреть на изначально и требование которые есть в нашей системе и по вы лидировать то есть насколько вот это вся архитектура подходит и видно что от того способа который мы выберем для организации взаимодействия у нас от требований развития без остановки она очень сильно будет зависеть тут возможны два сценария либо это будет синхронной либо асинхронная схема синхронный как раз сделать возможность релизов без остановки будет либо невозможно либо очень сложно мы и поэтому в данном случае мы выбираем асинхронную схему асинхронная схема представляет собой по сути общение через очередь то есть когда у нас выделяются некие в потоке данных и коммуникация происходит сервисов друг с другом через очередь окей и собственно мы приходим к тому что я сейчас рассказываю про реактивную архитектуру есть такая замечательная вещь как манифест те активной архитектуры кто незнаком могут можете потом перейти почитать подробнее но пару ключевых моментов которые мне хотелось бы выделить собственно основывается она вся на том что у нас взаимодействие сервисов она представляет собой асинхронную схему то есть нет прямых обращений от одного сервиса в другой мы передаем какую-то информацию либо событии и потом уже сервис который потребляет вот данную может на него реагировать вторая очень важная вещь это то что у нас реализовано пул модель потребителей данных то есть каждый сервис который какую-то информацию получает обрабатывает не в него заталкивают и и очень много а он наоборот сам с той скоростью с которой может ее обработать он ее забирает пачками обрабатывает и выплевывать свой результат таким образом какие мы получаем полезные сайты эффекты от этой схемы у нас получается своевременное реагирование то есть мы обрабатываем данные максимально быстро насколько это возможно у нас при возникновении какого-то события она постепенно проталкивается подхватывается и обрабатывается при этом если у нас какая-то из частей системы перегружены в по разным причинам the pool модель потребителей она позволяет нам делать ппш и мы тот сервис который сейчас страдает от повышенной нагрузки как раз он не упадет он будет работать чуть медленнее чем вся система но при этом обрабатывать данные с той скоростью насколько он может данный момент времени ну и собственно когда мы такие ситуации обнаруживаем мы можем разрешить их масштабированием сервисов то есть если у нас недостаток в какой-то части системе по скорости мы увеличиваем количество инстансов в этой части системы если же у нас наоборот какие-то сервисов очень много они курят то мы можем уж подрезать окей к архитектуре мы вроде пришли но теперь встает закономерный вопрос а собственно что же с транспортом и здесь тоже нужно начать с того что понять а что же вам нужно то есть какие у вас требований есть к транспорту и уже дальше и мего лидировать конкретные решения нужно с первую очередь посмотреть а что у вас за данное то есть если говорить про нос то все взаимодействие организована в виде двух типов объектов это сущности те объекты которые имеют свой идентификатор и они с течением времени меняют свое состояние имеет nickelas state также есть события событие это собственно действие которое происходит вашей системе на них нужно реакция и исходя из вот этих вот данных мы понимаем что нам нужно вообще-то линии рисуем из той чтобы при обработке событий у нас не терялась причинно-следственная связь чтобы при обработке сущности мы получали всегда актуальную последнюю версию домов и с точки зрения гарантии которые нам нужны для обработки данных то это будет отлиз plans гарантий гарантий для потребителей а именно мы не будем терять ни когда ни одно сообщение которое было отправлено при этом если у нас будут дубль и то за счет того что мы свою систему делаем и дым патентной для обработки эти дубли будут пропускаться и никак негативно не влиятельна 6м важно также посмотреть кто у вас будет сколько у вас будет писать именно тех частей системы которые пишут данные собственно в нашем случае если смотреть на различные потоки данных и будет составлять по порядок этой десятки систем то есть это те сервисы которые собирают из разных источников данных информацию и выплевывают ее для дальнейшей обработки ну и собственно нагрузка на от них на запись будет превышать будет исчисляться тысячами рпс точнее сообщение в секунду вот так же очень важно посмотреть а кто будет являться потребителями ваших данных и здесь мы видим что в нашей системе есть ситуации когда одни и те же данные могут читаться несколькими сервисами то есть у них не один потребитель а.н. и при этом мы должны всегда поспевать как раз за той скоростью с которой пишут мы должны успевать это сидело обрабатывать окей и теперь когда нам понятно что нам нужно от транспорта для организации вот этого-то синхронном взаимодействии между сервисами мы приступаем к поиску решения что же нам подходит здесь мы выбираем что у нас есть на рынке что есть в компании и просто по критериям сравнивая что нам лучше всего подходит нашем случае это был ребятенку это был кафка но и также были запасные варианты виде других технологий которые в принципе тоже подходит данном случае и мы пришли к тому что остановились и выбрали решение видео пачка вко почему потому что очень высокая скорость записи и чтения очень классное свойства то в карте того что сообщение после потребления они никуда не пропадают собственно это позволяет нам данные хранить в одном экземпляре при этом большое количество потребителей собственно не практически никак не влияют на на скорость чтения этой информации минусы в этой системы конечно тоже есть то есть будьте честными не пытайтесь найти систему в которой есть только плюсы найдите какие есть минусы и то что мы заметили отметили это в общем вся инфраструктура построена вокруг г-н это египта что касается драйверов и таких технологий как кафка стримов вот мои по сути то это не универсальная система то есть оно не подойдет для абсолютно всех сценариев но так как в принципе нам не надо было абсолютно все системы все сценарии реализовывать на ней и у нас как раз на части процессинга данных использовался g em stick для нас это вообще не проблема собственным поэтому мы на эта технология становились давайте же посмотрим на топологию данных которые на примере использования кафки может быть на примере нашего сервиса как я говорил у нас может быть несколько источников данных то есть это те сервисы которые либо откуда собирает информацию о товарах и услугах либо же предоставляет api для их загрузки ok все эти сервисы они пишут в некий топик который разбит попортится и они туда складывают сущности представляющую собой товары замечательно с потребителями у этой очереди является набор маркеров то есть так как у нас в топике он разбит на них определенное количество партиций у нас поднимается несколько worker of которые могут эти данные обрабатывать и обрабатывая данные они складывают свой результат работы тоже в некую очередь некий топик в котором мы берем оригинальное сообщение поступившая на вход и обогащаем его дополнительными какими-то признаками в результате обработки которые мы получили я про это еще позже расскажу собственно этот результат обработки он позволяет нам из таки это плоская структура данных получается мы можем необходимые нам агрегаты необходимы какие-то срезы данных мы их можем всегда из вот этого множества оригинального построить и собственно когда мы сталкиваемся с задачей получение нескольких различных срезов данных которые нам нужны в конечном продукте например с разбивкой по организации либо по городу либо еще как-то мы на основании исходных данных берем и делаем некие кавказ три новые трансформеры которые по сути делают агрегации преобразование и свои результаты также складывают в отдельные топики и их можно считать их можно использовать помимо этого всего результаты процессинга часть на них необходимо например смотреть тем же модератором то есть processing нож может сказать что вот вот это подозрительный контент его нужно отдельно проверить и вы видите собственном этот поток данных мы выводим в бэк-офис там у нас ведут свою работу модераторы после этого они принимают некие решения это и вылета которые собственно лет о том что вот такой товар либо эту фирму ее нужно заблокировать и эта информация у нас опять уходит processing мы ее можем использовать для дальнейшей обработки всех данных таким образом получается за шум т.р. система если говорить про специфику касаемые кафки и того как мы работаем с разными объектами собственно у нас есть сущности и для их хранения мы используем компакты топике в роли ключа у нас всегда выступает идентификатор сущности а в роль и значение это собственно вас стоит данных либо журнал если у нас произошло удаление если говорить про события тут еще прочим мы используем обычные топики и ключом у нас является поле по которым хотим получить лири ну юность ну и в случае данных эта информация о произошедшем событии и если посмотреть теперь на общую структурную схему того как у нас все организовано то есть у нас появляется очередь и конкретно эта кафка то посмотрев на эту систему мы пришли в какой-то меньшую штука впо у нас перестаю быть просто учить а еще оно становится чем-то большим а именно когда у нас есть какая-то получаемые на входе информация мы ее обрабатываем минимально необходимое стоит сохраняя в базе сервиса его по рублевым полный результат тоже в какую-то учить у нас топик кафки с результатом выступает в роли pure system снова хранилище это очень крутое свойства что это дает нам пробился в нашем случае вообще не обязан сохранять всю информацию которая касается состоянии данных у себя для того чтобы ее потом куда-то период править нет мы уже ее обработали сохранили в топике кафки она есть и для консилеров это тоже очень круто что данные вот есть контракт у нас есть сложно сюда данной если ему нужно что-то перечитать он не просит сервис который выплевывает эти данные он просто их скидывает овцы ты смещает их еще как то он их перечитывает и перри обрабатывает плюс опять же можно добавлять различных потребителей это очень крутое свойства она позволяет нам уменьшить дублирование данных вот как раз мы огородились сервисную архитектуру и получили дублирование данных там случае кафка нам как раз позволяет от дублирование там где это не нужно отказаться таким образом давайте небольшую подведу небольшие итоги по моей первой части если говорить про организацию потока в данных и архитектуры то нашем случае отлично подошла реактивной архитектура и в целом она подходит здорово для масштабируемой обработки данных и как конкретный транспорт это apache кафка он помимо того что является очередью еще является сторожем данных на границах сибсов это очень важное и полезное свойство обязательно я про него еще держится скажу ну и если говорить пытаться собрать умные мысли в целом по архитектуре то всегда идите от того что вам нужно по ст поймите осознайте что представляет собой ваша система какие у вас есть ника требования собственный если система связана с обработкой данных то отлично для взаимодействия подходят использовании асинхронного режима общение сервисов и общение с помощью сущностей и событий вот мы и до когда речь идёт о большом количестве информации всегда старайтесь избегать дублирования и смотрите на то какие данные есть вашей системе отлично давайте же теперь посмотрим на то как и какие хранилище данных можно выбрать и тут я буду показывать на каких-то конкретных примерах на кейсах чтобы было понятней чем мы руководствовались и что и в каких ситуациях мы делали один из сценариев это будет собственно про сервис который позволяет вручную управлять товарами и услугами в личном кабинете компании также мы посмотрим на сценарии патч загрузки информации либо же из прайс-листа либо поп какой-то ссылки где мы от внешней информационной системы и периодически загружаем туда информацию и актуализирует ну и в конце посмотрим например сервиса который как раз отвечает за процессинг за обработку данных что же ему нужно под капотом какие у него есть сценарий ну и начнем мы с ручного управления товарами джадис здесь должен быть скриншот того как это визуально выглядит но я его забыл вставить растите можно додумать здесь но не забыл я добавить про то что собой представляет данный сервис то есть по сути мы имеем некая крут api которая позволяет нам управлять двумя видном сущности это товарные категории и собственно сами товар и по сути это некий круто перине получаем список у нас есть возможность добавить что-то какой-то объект по редактировать его и удалить ok в данном сценарии пользователи в представители фирмы они прямо заходят юань и вводит руками эти данные то есть мы их не откуда-то забираем это прямо труд человека и это ключевая важная вещь то есть данном случае мы становимся мастер системой как раз о товарах и это данные те которые потерять ибо коротить как-то уже становится достаточно страшно ok и если горит про аудиторию то в пике она у нас будет на самом деле достаточно большой вот первый шаг от которого мы отталкиваемся это охватить аудитории в полмиллиона компании но исходя из текущего количества фирм и видим что он на самом деле количество обращений по статистике использования нашего личного кабинета то с чем нам надо будет работать ну составляет порядка десятков fps и к этому всему мы договорились с продуктами что принимаем некое ограничение на количество тех данных который к нам можно будет в данном режиме загрузить для чего потому что чтобы лучше посчитать как раз ограничение системы ну если фильм не нужно вручную через наш личный кабинет управлять с порядками сотен тысяч товаров что-то идет явно не так то есть мы должны охватывать вполне понятный конкретный кейс вот и наш собственно личный кабинет компании находится в одном на центре нам здесь не нужно географическая распределенность ok давайте же посмотрим что нам выбрать для как раз таки для хранения данного вида сущности что нам подходит ну и первое что стоит памяти это конечно это реляционные базы данных и на узкий найдутся одни люди которые давайте майское ли другие будут давайте мои руки давайте пройдемся по этим все варианты собственно для того чтобы корректно выбрать я рекомендую тоже составит требование понять что вам нужно теперь от базы данных и первое с чего нужно начать это собственно понять актива сценарии использования что вы с этой базы хотите делать и мы видим что наше самое использование по сути нда представляет собой те же самые круто perazzi и нам нужно по ключу что-то отредактировать удалить нужно что-то добавить новые получить какой-то список ok мы понимаем что в сервисе я говорил что это master system данных и мы должны здесь очень относиться внимательно к тому должны ощущать ответственность того что данное мы не можем потерять и сохранить как-то неправильно то есть это master system поэтому нам нужны здесь достаточно сильной гарантии по консистентных седана если оценивать вот те все цифры про которые говорил что у нас есть на старте нужно понять как а еще у вас есть объем данных то есть вам база данных она нужна для чего какие ресурсы вам под эту базу просить и если посмотреть на на шоссе на использование том поняли что речь идет об порядка нескольких терабайт например и это то с чем нам надо будет работать ну и собственно то количество запросов которые к нам приходит опять же на основании использование статистике личного кабинета позволяет нам построить красот текущее утверждение что большая часть запросов будет на ощущение и небольшая на изменение данных собственно требование по географической сплю насти у нас здесь по-прежнему нет и ну что ну надо же науськивали использовать манга хорошо там например для этого всего дела подходит да она подходит ее можно использовать но смотрите есть некоторые моменты я их пометил как раз желтом который вызывает некие вопросы например у меня а стоит ли она того то есть если использовать какую-то и но искали решение то нам надо поднимать кластер то есть это не на той же машине должно быть ради одного терабайта поднимать кластер не сомнительный десятков фпс при том что никаких предпосылок или иного на старте у нас для этого нет и а и но при этом вам нужно прямо заморочится на то чтобы мы прямо те данные которые редактируем сохраняем они в общем все эти операции происходили консистентной и здесь нужно будет снова с превышением еще прям разобраться получить нужную гарантию короче убедиться что вы делаете все правильно окей носка или подходит но давайте глянем может быть что то лучше есть и да блин если использовать обычную реляционную базу данных то выглядит что мы как раз таки тега за счет использования механизма транзакций мы можем получить высокие гарантии консистентной sti данных мы можем справиться с 1 терабайт он кажется это большая цифра но мы сможем найти такое железо на котором данный объем данных будет обрабатываться но и количество запросов она не высока поэтому если сравнивать то подойдет все прямо как бы можно выбрать и то и другое но если быть честным с собой то выходит так что именно в нашем случае было разумнее проще всего использовать тот же самый реляционную базу данных у нас это пост близкое по умолчанию плюсы можно есть дополнительным еще добавить то что мы его достаточно хорошо знаем как бы с ним все проблемы обошли и для данного сценария он подходит вот собственно если выводы именно из нашего опыта по этой секции туда как бы реляционная база данных нам здесь подошла точно для старта ну и когда мы подойдем к пределу того что вот у нас все место заканчивается нужно с этим что-то делать вообще-то нам надо посмотреть когда вы к этому будете подбираться и по исследовать ситуацию то есть вас может измениться продукт у вас может смениться профили использование ваших данных вообще ситуация на рынке может в яндексом еще какую-нибудь данных напишет которую надо будет обязательно использовать в общем это то что реально можно решить ситуация когда проблема возникли и из общих рекомендаций я бы здесь точно советовал собственно составе требования хранилищу ваших данных понять что вам нужно какой вас самаре использование и что вам от него надо ну и оценить общем то тот объем данных с которым вам придется работать может выйти так что в принципе для старта и нормально будет использовать реляционную базу данных не всегда имеет смысл тащить нос quelle как первое решение ok те рассмотрим следующий кейс он будет про загрузку информации о товарах и услугах уже другим способом а именно из прайс-листов если его сравнивать с ручным способом загрузки данных то разница здесь будет следующим нам уже не нужен крут api для того чтобы мы могли просматривать список товаров редактировать не дай бог эти все данные удалять их или еще что-то мы эту просто информацию личном кабинете никак не отображаем также мы здесь снимаем какие-либо ограничения на количество загружаемых данных то есть мы просто берем и говорим что практически любой объем информации вы можете своем прайс-листе загрузить мы понимаем что в данном случае нам становится чуть-чуть легче потому что мастер системы является какая-то некая внешняя система информационная в компании а откуда они выгружают данные мы их себе затягиваю то есть тут у нас уже появляется права на ошибку что-то сохранить не так потом у нас есть возможность это перезагрузить окей хорошо что еще мы теряем и вайпа управление товарами но при этом получаем ей для управления как раз такими загрузками там по какой-то периодическому обновлению по ссылке либо загрузки из файла то есть никому я у нас есть но он манипулирует уж эти пять другими сущностями другими данными аудитории здесь у нас становится меньше к сожалению количество компаний с автоматизации их заметно меньше поэтому здесь мы по текущим оценкам понимаем что эти цифры будут такого порядка и здесь мы получаем уже теперь пул модель обновления данных случае ручного управления это было push пользователь заходит и модифицирует у и здесь мы должны с какой-то периодичностью опрашивать информацию если мы обновляем данные по ссылке ну и собственно здесь у нас появляется такая вещь что нужно ее делать либо скаку с какой-то периодичностью это могут быть для части каста меров часы для части какие-то там десятки минут ну и собственно вариативность данных у нас здесь тоже становится выше мы можем загружать как прайс-листы с десятками товаров так и сотнями так из тысяч с десятками тысяч вот давайте же теперь посмотрим какие данные у нас есть и каков их объем чтобы понять что нам лучше всего подойдет для решения данной ситуации собственно если мы как раз у нас появляется такая сущность как некий импорт прайс-лист это собственно то информация описывающая файл либо какую то ссылку откуда происходит загрузка данных то здесь у нас будет им порядка сотен тысяч объектов таких что у нас еще есть у вас есть информация об отчетах о том как мы ранее загружали данные какой у нас был результат чтобы мы могли в юо и отобразить что вот предыдущее обновление привело к вот таким то изменениям окей здесь данных будет на порядок больше то есть потому что мы все ну как раз оставляем только часть истории затираем совсем старые данные вот и все что касается товаров и категории вот тут у данных будет уже очень сильно больше то есть если нам посчитать с учетом опять же всяких выбросов больших компаний ты вообще становится тяжело определить мы будем считать что у нас такое количество объектов а товаров нужно будет обрабатывать можно быть и не готовым собственный и здесь ограничение это в принципе на объем практически никаких нету таким образом если мы отталкиваемся вот мы знаем что теперь вы знаете что мы любим плоскость такие давайте попробуем решить это способе сам ведь ручных товара же мы это сделали как бы да он нам знакомые любимую замечательно но мы здесь уже сталкиваемся с той проблемы что объем информации стал несоизмеримо больше нам здесь на одну машину будет уже весь объем данных о товарах и услугах достаточно тяжело сложить если мы используем какой-то ванильный пользуюсь окей это же проблема решается с помощью носке и решений то есть мы получаем масштабирование кластеризацию из коробки давайте его использовать и все будет замечательно ну как бы мы минусом получаем здесь более слабую гарантии консистенции насти и так как мы храним всю информацию о товара загруженных базе данных у нас будет достаточно большое количество чтений по фирме то есть когда нам нужно обновить информацию из last это представленного в прайсе на можно будет построить их понять какие данные нужно удалить какие обновить какие добавить манку ска на базу большая и при этом у нас кластер да у нас еще нагрузка сильно повышается на сеть и в такой ситуации когда вы видите что и одно не подходит другой не подходит неплохо бы задастся вопросом а вообще все ли правильно мы делаем то есть как бы вот вообще надо ли делать именно таким образом как вы придумали и здесь мы себе поставили как раз такой вопрос поставили под сомнение а нужно ли вообще сохранять всю информацию о загружаемых товаров базе данных и ответом стала вообще нет не обязательно не пришли гибридной схеме у нас есть по-прежнему здесь и мы здесь его используем сценариях когда мы сохраняем не то данные это история импорт off это собственно то информация которую нас контролируемое по количеству ее немного окей ну а все что касается теперь большого объема данных мы сохраняем в других системах а именно все эти прайс-листы которые мы загружаем от компаний мы их складываем себе в неизменном виде в распределенную file system нашем случае это цех че за стресс интерфейс и вот она просто мы берем этот артефакт она загружаемых и к себе складываем и работаем уже непосредственно с ним потому что нам не нужен или на весь класс state и когда речь идет о том чтобы куда нам сохранять результат ведь мы же данные обрабатываем мы импортируем прайс лист и выгружаем его в кафку ну вот отлично выглядишь что вся информация которая касается финального стоит а у нас есть буфер в виде карте который позволяет сохранить эту информацию он распределенный он может хранить много данных таким образом задача решается то есть здесь именно гибридное решение она позволяет нам решить нашу проблему нашу задачу а именно большое количество данных хранить всех системах которые собственно не позволяет это легко делать не предназначен для этого и загружая информацию о товарах а прайс-листах вот прямо в сыром виде вот у нас есть прайс-листы на к себе и берем так складываем это очень крутое свойства такая над обильность мы не искажаем у нас может быть какая-то ошибка о том что мы не правильно прочитали этот файл и если мы перекладываем в другое место здесь же нет мы всегда работаем с файлами даже если мы где-то в алгоритм допустили ошибку потом всегда можешь перечитать при этом у нас еще и сохраняется мы делаем историчность загружаемых там данных можем посмотреть все прайс-листы которые там месяц назад были добавлены какую-то динамику цен построить и так далее вот и при этом если у нас есть какие-то метаданными информация которая нам нужна в реляционной базе данных мы по-прежнему там храним и как бы ситуация velden при этом как бы минусом можем данной схематичности из-за ее гетерогенности то что у нас нету одного инструмента для того чтобы работать со всеми данными то есть данном случае так как может результат обработки находятся в каске мы не можем просто сделать select какие-то join и посмотреть на результат и его оценить то есть это задача в принципе решается может другими инструментами ну некоторым неудобствам она приводит таким образом что здесь можно посоветовать на примере данного кейса здесь ключевое важное для себя вывод которым мы сделали нужно с вопросом в точно нужны все те данные которые вы в обычную базу дома собирались складывать мама прямо не обязательно нужны и может быть так что только часть минимально необходимую информацию можно сохранять базу данных этого будет достаточно при этом большой объем сырых данных которым не требуется строить по ней какие-то индексы их можно хранить файловой системе распределенной файловой системе а финальный результат как раз у нас сохраняется в кафки мы уже для всех остальных случаев а может как раз подойти база данных которые вы используете по умолчанию отлично мне осталось совсем немного времени и последний пример который хочется показать это сервис обработки данных что мы с ним делаем у нас собственно там есть фильтрация информации поступающей к нам согласно правилам размещения мы также те информацию о товарах которые получаемые и обрабатываем если это текста то это какая-то может быть чистка вырезание тегов нормализация так и мы обогащаем дополнительной информации полезными какими-то признаками как техническими так и семантическими такими же как категории товара решение модератора и так далее и собственно вот у нас есть много информации есть некая описательная часть которая говорит о том как данный нужно обрабатывать она может меняться то есть это справочнике какие-то алгоритмы того как мы обрабатываем никогда не меняются то что мы уже раньше обработали это надо все перри обработать снова не правой именно этот механизм нас называется ян валидации и если теперь разговаривать про данное что же нам нужно хранить в базе данных нам как раз нужен нужно хранить настройки какие-то справочники и словари которые мы в процессе обработки используем помимо этого вторая большая группа данных это вот то что нам пришло на вход нам для инвалида ции нужно во-первых сохранить оригинальные где-то сообщения также по части из полей из этого сообщения но нужно построить индексы чтобы мы могли выбрать с abs от его будущем перри обработать по количеству данных мы видим что в случае справочников словаре это небольшое объем данных исчисляемые миллионами записи и собственно сам достаточно редки обновления и много извлечений по ключу при этом сценариях с обработкой данных нас здесь заточены все объекты которые поступают на обработку этих данных будет много там бачок и самарии записи с нагрузкой кому помню более тысячи сообщений в секунду ну и собственно больше записей и очень мало чтения для того чтобы выдать эту информацию и затем перри обработать если отталкивается здесь опять же от решениях которые у нас есть на рынке и вы лидировать их то мы видим что реляционные базы данных кажется вроде подходит хорошо для справочников и для метаданных окей но при этом вот тот большой объем данных и большое количество записей прямо он чтение мы позвали скажется использовать совершенно данном случае не разумно потому что данных много еда у нас большое количество записей поэтому мы здесь тоже пришли гибридной схеме и данном случае она представляет собой союз плоскость и ластика то есть в подписи мы сохраняем информацию о метаданных и все те данные которые мы обработали мы складываем их власти ксир чьи к вам нужно полям строим нам индексы ну и собственно извлекаем когда нам требуется для инвалида ции тот sab se данных которых нужно обработать таким образом в данном случае что можно рекомендовать как раз если у вас есть ряд какой-то справочная информация которая используется в проекте ли не ешь определенное файл носке и решения кажется будет избыточном используйте здесь простое решение которые у вас есть в вашей объеме при этом нашем случае когда есть очень много записей и нужно вот только части данных строить выборки на март отлично подошел ластик search вот и общих выводов можно рекомендовать то что вы делите как раз группы данных которые у вас есть и к ним как раз требование могут приводить тому что будет подходить разные решения ну и собственно выбирайте наиболее подходящие решения под каждый из этих сценариев и масштабируемой хранилища в данном случае обоснованно ему отлично подходит в тех кейсов где много данных отлично мы поговорили об архитектуре и о том какие же хранилище данных можно выбрать давайте я проведу краткие итоги того основные мысли которые я хотел сегодня вам поделиться и донести самое основное всегда и разберитесь что вам нужно сделать какая у вас система поймите что вам нужно и идите от задачи от проблемы какому-то конкретному решению от вашего проекта технологиям когда вы именно таким путём идёте очень высока вероятность что вы сделаете хорошее правильное классно инженерное решение когда же вы наоборот послужу не разобравшись проблематике того что вам нужно будете отталкиваться от какого-то решения от практики которые используются в гугле там еще где-то в яндексе в одессе и пытаться свой проект это тянуть вот тут возможно как раз будущими проблемы то есть самое основное если быть про архитектуру собирайте требование делать или сердцах решение которые уже действенно рынке вы лидируете вашими требованиями вы видите то что лучше вам всего подходит нашем случае получше подошла are happy реактивной архитектура про транспорт и то же самое поймите что у вас можно от системы транспорта какие сообщения у вас есть какой их объем поток и так далее ну и собственно выберите подходящий вам решение нам для подобной задачей отлично подошел apache кафка и если же говорить про хранилище их тоже на рынке достаточно много они все подходят для разных задач поймите что вам нужно от хранилище то есть будьте честны между собой самим собой и разбейтесь какая система лучше всего подходит электронные базы данных дает достаточно сильные гарантией целостности данных но и они отлично подходят там где не нужен какой-то кластер из коробки носке решения как раз здесь уже лучше подходит ей нужна кластеризация из коробки фишка этих систем не в том что там нету эскивель а как многие думают ну и собственно если у вас большой объем данных которые не требуют построение по ним индексом и обрабатываются патчами здесь могут подойти решение виде файловых систем как распределенных так каких-то локальных для того чтобы всю эту информацию хранить но не забывайте что если вы используете apache кафка то у вас всегда есть возможность использовать его просто как очередь и буфер данных на границах сервисов которые у вас есть собственно на этом у меня все спасибо за внимание давайте же перейдем к вашим вопросам давайте поблагодарим воды и весьма сегодня большое и я напоминаю что можно задать онлайн вопросы задавайте соответственно меню там есть сбоку кнопочка красненькая пока пока мы постараемся выводить на экран а пока давайте вопрос вот молодой человек у говорим привет спасибо за доклад вы очень интересно и у меня такой вопрос как у вас с вашей системе с отказоустойчивостью то есть как насколько она зависимо от того что один из компонентов например ваш какой-то сервис или какая-то беда этажа кафка если что-то упадёт откажет и как долго вы восстанавливаетесь после отказа в таком случае спасибо я понял вопрос смотри он достаточно широкий основные ты здесь какие-то хочу потом можем продолжить общение то есть мы здесь основную ставку делаем как раз на то что он тех случаях где критична как раз иметь отказоустойчивость высокую мы решаем это готовыми решениями пример падение того что какой-то из нот в кластере кафки вылетит но это решается дизайном кафки то есть там есть репликация как раз если одно надо вывалилась мы сможем это потом продолжить было стики ровно все то же самое в случае пост грессов это будут бэкапы и ход стендбай то есть в принципе это та часть на который нужно обязательно обращать внимание и не забывать про нее у нас это семью собственно команды которая занимается инфраструктуры и реагирует на то что происходит системы либо это автоматически происходит либо точную подробности можешь можем говорить позже спасибо так спасибо за рекомендую кстати кто нас смотрит в онлайне сутки задавать вопросы и давать его сейчас молодой человек и потом вот девушка здравствуйте спасибо за доклад о вас хотел спросить вот когда у вас гибридная система несколько хранилища как вы обеспечиваете целостность ну то есть в кафку может записаться о вас груз нет или в истре может не записаться и а возраст записаться то есть вот и как у потом если у вас такое произошло как вы потом останавливайтесь хороший вопрос спасибо то есть здесь конечно это то с чем мы сталкиваемся с этим обычно возникают трудности но они решаемы то есть если говорить о проблемах общем у нас данные они схема гибридные у нас одни и те же данные не сохраняются в нескольких системах у нас часть данных они могут разделяться по разным частям этой системы и грубо говоря мы завершаем последний этап только когда все предыдущие гарантированы выполнения то есть если мы говорим про импорт из прайс-листов мы берем прайс затягиваем его в цех убеждаемся что он сложился все нормально при этом тоска у нас в работе еще находится у нее статус обработки in process затем мы собственно обрабатываем информацию публикуем результат в кафки и дожидаемся подтверждение в кафки того что все обработано корректно все обработано правильно после этого когда у нас все части этой системы мы про аккумулировали они обработаны нормально мы берем и подтверждаем статус выполнение нашей тоски что дан если же у нас на каких-то середине этого всего процесса произошли сбои ну вот как раз промежуточные фазы трека им статусами то есть что статус например сохранение в цех прошел успешно и в случае если у нас что-то упало в арке поднимает задачу заново он начинает ровно с того шага с которым произошли проблему то есть если мы например слали в кафку а на весь кластер сеть сдохла и вообще все поломалась мы могли отправить часть информации а часть нет мы не заморачиваемся так как у нас это лишь план гарантия мы берем и все данные еще раз отправляем когда мы получили подтверждение мы по статусу переходим дальше я ответил наш опрос спасибо я правильно понял что вот вот эта вся цепочка это не как единая транзакция это набор отдельных зубов кадавры последовательно выполняют тогда оси большой так и вот сейчас у нас девушка и потом вот молодой человек будет и задавайте вопросы в онлайн если что мы вас выведем на экран здравствуйте спасибо большое за доклад очень интересно хотела вас спросить по поводу хранения sarah dunn вы храните данные и соответственно они вам не нужны для частого использования на получение вот у меня как раз вопрос в этом отношении а каким образом вы устраиваете чтение этих данных и постобработку конкретно что касается например микро сервиса какого-то отдельного то есть как у вас это работает я понял у нас эта информация которая нас скажем так если вспомнить ту схему где есть сервиса него так вертикально поделены это та часть которая инкапсулированы никто не знает дальше что у нас есть танцев него сохраняется какие-то прайс и так далее это то что внутри поэтому если нам нужно устроить историческое хранение данных где-то дальше для аналитики для ее использования и так далее то логично выстроить некую часть системы который подключиться к топику кафки прочитает и служит себе так как надо как избавиться от проблемы того что данные хранятся постоянно и не удаляются нас просто есть джо бы которые периодически запускается например все те прайс-листы которые мы загружали к себе им уже больше полгода в масле потребитель их обработали мы просто удаляем как бы экономим место и бережем наш шеф спасибо пожалуйста вопрос и наверное будем а вот еще будет один последний вопрос здесь добрый день вопрос про интенсивность потока но внятного просто 1 начались прошел насколько интенсивный поток у вас кафку идет сообщение секунду мегабайт в секунду но вот что такое и скажите насколько большой ваш шеф если большое то какая команда или как вы поддерживаете чинить его как решаете проблемы с конкретно с цехом давайте я здесь какие-то общие наверное вопросы дам потому что это выходит за область моему профессиональной компетенции здесь именно про цифры говорить какие у нас нагрузка танцев то есть если мы говорим про поток сообщений которые у нас идет в кафку то средний он сейчас в данный момент до тысячи сообщений то есть бывает всплески когда до несколько тысяч сообщений в секунду он поднимается то есть мегабайтах я если это очень важно интересно я могу посмотреть либо сам либо глянуть попросить тебя они предоставят информацию про цех это решение ну собственно она у нас находится в инфраструктурной команде там точно достаточно много серверов то есть какой порядок и порядок наверное десятков это точно у них достаточно много дисков там конфигурацию я не буду врать я не помню общем если вы очень важны подробности по этой теме подойдите ко мне я уточнил ребят и донесу эту информацию так ну давайте предпоследний вопрос и последний потом там спасибо большое за доклад очень интересно скажите пожалуйста какой промежуток времени вы храните данные в кафки ну то есть бесконечный такой локи ли у вас какой-то жуткий временной на временной интервал при котором вы там она чистится нас политика используется то есть мы используем компакты топики для сущностей и собственно ну это первое то что сокращает объем данных то есть старая версия они все постепенно умирают и они в итоге политики в результате коллекции политики com компакте зации они пропадают а дальше у нас стоят ограничения на объем занимаемых данных то есть у нас реально большой кластер как бы кафки это там до десятка если не больше уже сейчас машин и политика compact у нас именно по объему занимаемых данных то есть по времени так как у нас это или по большей части это сущности там и компактен по времени не делай спасибо за вопрос так спасибо и вот последний че вопросам молодчик просто здравствуйте спасибо привет от как вы поддерживаете обновляете схемы данных с учетом compact кафки и других хранилищ хороший вопрос в этом случае то есть мы всегда придерживаемся политики обратной совместимости то есть тут бывают разные ситуации они достаточно классические когда добавляются какие-то расширяющие изменения ну это по сути обычно проблему не приводит берете избавляете то у вас было структуру в не было 5 полей добавляете еще несколько и они опциональны это не проблема проблема когда было что-то по контракту опциональное она стала вдруг резко обязательным либо когда у нас что-то пропадает к этому мы стараемся в основном не переходить не когда то есть у вас должны данной все-таки эволюционировал и если можно операцию добавление новых полей и собственно отказа от каких-то старых мы их разбивая ну то есть как с миграциями в продакшен базе данных так и здесь если же вдруг мы все-таки сталкиваемся ситуации что нам нужно данные как раз такие схемы сильно поменять то мы создаем отдельный набор топиков которые уже будут новыми добавляем логику в код который пишет из старой и в новый постепенно переводим всех потребителей которые есть с первого топика на его новую версию это может быть достаточно долгим процессом быть какими-то месяцами потому что потребители может быть много и когда мы только перевели уже последнего мы собственно отрубаем старые вы гашимова skoda убиваем эти топике в кафки таким образом это процесс очень легкий для всех и ответил наш опрос супер спасибо спасибо давайте поблагодарим его за выступление за ответ на вопросы и у нас есть небольшой подарочек от организатора себе я бы попросил тебя просит выбрать кого-то из тех кто задавал вопросы просто лучший вопрос вот какой тип она вот наверное тот который ближе ко мне было мы сами сталкивались и потратили много усилий про тему связанную с консистентную данных и вот вопрос от парня был именно про так как происходит до обработка в случае у нас не большой воде за это корректный вопрос отлично вопрос красиво да спасибо большое тотчас поблагодарим спасибо вам"
}