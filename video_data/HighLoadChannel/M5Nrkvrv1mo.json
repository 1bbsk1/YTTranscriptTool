{
  "video_id": "M5Nrkvrv1mo",
  "channel": "HighLoadChannel",
  "title": "Собираем облачную AutoML-платформу для создания голосовых роботов / Артем Бондарь (Voximplant)",
  "views": 463,
  "duration": 2800,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "всех еще раз хочу поприветствовать Как вы можете догадаться из доклада сегодня хочется поговорить про наш опыт Вокс имплант как мы создавали автоэмэль платформу для голосовых роботов на базе Трансформеров Я надеюсь что на доклад пришли не только email-инженеры поэтому хотелось бы коротко рассказать вообще про то в каком состоянии сейчас находится технология НЛП и рынок решений вокруг вокруг неё и почему дать немножко мотивации Почему именно сейчас мы решили что правильное время зайти на рынок со своим продуктом А дальше рассказать немножко про технологические решения которые мы принимали создавая это автомобиль платформу и при этом дать Хотя немного каких-то чисто технических деталей но чаще мотивацию тех или иных решений как мы действовали с учетом достаточно жестких ограничений бизнес-требований технологий там сжатых сроков и ресурсов и начать хотелось по-быстрому с истории НЛП Я думаю все таки люди на eml-треке примерно представляют что происходит машинам обучении поэтому максимально коротко все помнят классический НЛП до примерно десятых годов который уже давал достаточно хорошие результаты Но с другой стороны был достаточно ограниченным мы были ограничены тем как мы викторизируем текста соответственно это были какие-то спортсмены и представления которое было сложно засовывать в глубокие нейронные сети соответственно получались какие-то решения Но это были там квазилинейные модели тот их модели несмотря на это получалось создавать какие-то Продакшен промышленные решения которые уже приносили все сильно поменялось когда началась потому что мы получили компактные представления начался настоящий и наши решения очень сильно поумнели в стал развиваться именно в этот момент Но самое главное это некоторые сдвиг парадигмы работы в том что появилась концепция трансфер лердинга то есть мы решали какую-то задачу на неразмеченных данных получали какие-то хорошие представления этим занимались как правило такие research reented команды и потом они выдавали результаты которые могли использовать Production команды для решения своих бизнес-задач и такое при использовании данных и технологий позволило добиваться хороших результатов Имея не такие большие объемные объемы данных то есть доступ машинное обучение к модифицировался конечно максимальный расцвет этот подход получил когда берд зашел на рынок с биртом энкодер-трансформеры который сейчас по факту стал абсолютно стандартный болванкой для решения любых продакшн задач абсолютно доминирующий подход То есть сейчас immer инженер Как вы видели из многих предыдущих докладов чаще всего берут Берт дистиллируют его делают там какие-то с ним другие приседания и используют в продакшн-системах сейчас конечно начинается разные интересные движения в плане использования концепции Zero Shot Learning а в плане мультимодальных моделей Но если брать чистый напишные задачи то чаще всего мы остаемся в парадигме взяли берд и работаем с ним если переводить всю эту историю в некоторые цифры то на каких-то таких очень абстрактных дата сетах Это конечно не тянет не на какой серьезное заявление Просто чтобы был понимание порядка цифр есть ощущение что этот график насыщается на каких-то стандартных задачах соответственно в чем мой Поинт то что кажется что каких-то супер глобальных прорывов в текущих задачах у нас не произойдет текущие технологические стойка инженерные решения с нами надолго соответственно настраивая систему прямо сейчас скорее всего это будет что-то что проживет Достаточно долго вот так что с точки зрения research понятно с точки зрения инженерии Мы тоже имеем очень зрелый стек если раньше заниматься машинным обучением требовало очень серьезной инженерной подготовки помимо чисто теоретической то сейчас расцветом один фейс Трансформера по большому счету инженером не так сложно взять эту модель и применить ее к своей конкретной задаче буквально это настолько же сложно насколько написать там с десяток строчек кода с выкладкой в Pro тоже все стало очень неплохо у нас появились во-первых несколько доминирующих стандартов упаковок моделей я тут упомянул о NX естественно есть некоторые другие и появились некоторые среды исполнения тоже достаточно стандартизированные если мы хотим выполняться на своем железе то в этом случае есть NVIDIA Triton inferent Server который занимается очень большим количеством дает очень много функциональности в плане упрощения выгодки очень много оптимизаций фактически об этом думать нужно все меньше и меньше если не хочется заниматься инфраструктурой есть решение от провайдеров То есть как правило это offering Google я конкретно называется Сейчас в общем серфингом моделей тоже в общем-то ситуация достаточно простая Но если все так здорово Почему мы видим что хотя тех гиганты большие компании которые часто рассказывает про свои решения они буквально пронизаны эмаль салюшинами Но если посмотреть на компании которых технологии это не основной Спектр экспертизы там очень часто возникает ситуация что они не могут использовать не могут не хотят использовать eml наработки и мы как вот имплант B2B платформы очень часто с этим встречаемся вопрос Почему ответ достаточно простой потому что все еще нужны очень сильные технические специалисты естественно дорогие и компании не очень хорошо понимают как их нанимать не очень хорошо понимают Как ставить задачи и настраивать весь этот процесс соответственно даже если говорить очень небольших пилотах это становится для них какой-то большой ментальной болью Вот соответственно рынок это понимает и рынок предлагает автоэмэль как некоторые попытку решить эту проблему по сути это попытка если говорить общего попытка автоматизировать работу eml инженера и команды машинного обучения и в каком-то идеальном мире это просто система в которую пользователь заливает данные системы и тренирует модель и занимается инференсом то есть инженерия уходит под капот естественно на рынке уже много таких игроков как я упоминал это часть оференга больших провайдеров и WS и Google Services их решение позволяет решать ряд задач в области обработки естественного языка в области компьютер Vision predition на табличных данных в общем Там прям ряд конкретных решений которые можно взять и использовать если говорить про Standalone компании то конечно я и там одна из первых компаний которые приходят приходит на ум но нужно понимать что это все еще конструкторы для инженеров они требуют сильной технической подготовки и для того чтобы создать какое-то решение то есть это часть конструктора нежели полноценная коробка но есть ряд вертикалей где ситуация немножко другая там получается запаковать эту работу в более коробочное решение которое требует меньше технологической экспертизы и если говорить про конкретные примеры то в вертикали чат-ботов одна из самых известных решений это Google Flow если говорить про поиск то это алголия они тут еще и поглотили еще одну такую компанию из этой области стали совсем большими и в области рекомендаций это продукты которые работают плюс-минус по принципу то есть есть некоторые из детей есть некоторые API которые позволяют интегрироваться с бэкендом начать стриминг данных и получать либо email рекомендации либо Умный поиск либо готовый к работе чат-боты и большой плюс этих решений что по факту не требуется какого-то вмешательства или инженера то есть компания может попробовать поиграться саморешениями до того как она решила серьезно инвестировать в это направление конечно за все это счастье надо платить естественно как деньгами так и не гибкостью таких систем однако для многих компаний такое решение более оптимальное потому что они могут хотеть просто про пилотировать свою технологию про пилотировать или технологии на своем продукте либо же у них Пока что нету ресурсов чтобы собирать команду получать плоды уже хочется либо же кто-то вообще готов жертвовать качеством ради чтобы не тратить свои усилия на поддержку им или решений или иметь высокую скорость и тарирования у некоторых компаний может Соблазн может появиться Соблазн даже пойти дальше и попробовать собрать собственную автоэмаль платформу Например если у компании есть какой-то однотипный конвейер однотипных моделей которые они создают и менеджеры занимаются достаточно рутинной работой это часто встречается например в B2B бизнесе где приходят клиенты с одним и теми же запросами хорошо бы для них попробовать собрать какую-то единую платформу где можно делать решение Не будучи Менеджером А еще Как показывает наш опыт то что модели сами по себе однотипные может привести к тому что вы сможете снизить Касты На инференс разными трюками Но об этом чуть попозже Зачем конкретно нам нужно решение мы руководствовались той же логикой что я только что описал ваш продукт в целом позволяет создавать сложные коммуникационные сценарии Это saas-платформа где зарыта телефония зарыты провайдеры is rtts есть возможность описания логики с сервер с JavaScript кодом соответственно единственная технология которая не хватало во всем этом зоопарке чтобы мы стали полноценным конструктором стоит of заработок которые могли бы как-то конкурировать in House решениями Или другими вендорами это качественные и об этом как раз Вот хотелось бы поговорить в этом докладе а изначально мы добавили поддержку стороннего вендора в нашу систему но практика показала что этого оказалось недостаточно Да немножко просто промыть его еще чуть больше мотивации Зачем пилить что-то свое когда есть вендоры вроде Google dialogflow очень много компаний у нас занимается созданием научных платформ для чат-ботов но в своей практике мы поняли что этого не всегда достаточно Потому что некоторые не достигают нужных метре качеств на наших бенчмарках некоторые не давали достаточно гибкости чтобы описывать какие-то Корнер кейсы которые всегда возникают когда это реальный клиент и было тяжело интегрировать эти решения с нашей собственной платформой которая тоже предоставлял разные интересные фичи Поэтому решили делать что-то свое Вот и Теперь наконец перейдем собственно к самому решению Перед тем как мы это сделали хочется немножко рассказать что мы конкретно сделали А те кто немножко знаком с областью conversational я и знает что есть два класса голосовых ботов это чат боты это такие роботы болталки которые просто пытаются поддержать правдоподобную беседу э пример компании которая превратила эту технологию в какой-то бизнес продукт который приносит Вью это Например реплика ребята делают Бота психологического помощника и там ценность продукта именно правдоподобной беседе э-э в B2B чаще же история про боты гололен этот боты это по сути некоторые голосовой интерфейс к набор функций в котором человек может выразить своё намерение в естественной форме Ну и часто оба этих подхода соединяются если говорить про голосовые помощники с которыми мы часто встречаемся вроде Алексы Google Assistant Алиса то там как правило совмещаются оба подхода если робот понимает что пользователь за действия хочет от этого робота Он работает в режиме голый рента если не понимает то просто пытается поддержать беседу в режиме check-чат соответственно мы как B2B компания больше приносим пользу клиентам если мы создаём гол Red ботов соответственно Мы сфокусировались на этом направлении Ну и чтобы немножко понять А что за задачу мы должны решить в голове ботах хочется быстро проговорить про стандартный Flow в таких системах То есть как правило пользователь например голосом выражает свой какой-то запрос мы при помощи технологии SR преобразуем его из голоса в текст соответственно дальше нам нужно понять в общем-то intention пользователя Это задача классификации Intel как правило intent и дизайнерса команды которые создают робота это набор классов с примерами пользовательских запросов на каждый класс помимо этого часто недостаточно просто понять intent нужно еще извлечь некоторые параметры запроса для этого пишется отдельный компонент который занимается задачей на intentitycation извлекает данные из текста и нормализует в таком виде чтобы эти данные можно было дальше передать например в конце дальше все эти нормализованные данные передаются в компонент который управляет собственным ходом разговора Это задача имеет разные подходы к решению Как emailbase так и это просто что-то заскриптованы задача дайвок стоит трекинг в нашем случае мы решили сильно не уходить в эту область Поэтому наши пользователи могут описывать вот этот менеджмент при помощи Java скрипта соответственно этот JavaScript как правило возвращает какие-то ответы делает какие-то действия и нам остается только озвучить реплики робота человеку для того чтобы получилось беседа немножко саморезируя из компонентов для нормальной платформы нам необходим классификатор Intel компонент по извлечению именно их сущностей и стоит менеджер естественно нужен какой-то E5 для управления всем этим хозяйством и в данном докладе Я хотел бы сфокусироваться именно классификаторе intent of как на компоненте где наиболее ярко вылезли все проблемы создания солсервис платформы и как может выглядеть вот эта система по классификации intens то есть во-первых пользователь должен иметь возможность залить данные в систему это дайвок менеджмент какой-то фронтенд который укладывает на бэк данные соответственно с бэка ставится задача по тренировке нейросети или другой какого-то алгоритма машинного обучения то есть должен быть какой-то тренинг сервис тренинг сервис укладывает свои результаты работы в какой-то registry и потом из этого регистра модель доезжает до сервиса инференса который уже обрабатывает Real Time запросы от наших пользователей но выглядит достаточно тривиально Но в нашем случае на эту систему накладывался ряд ограничений во-первых Мы работаем с голосом то есть нам принципиально чтобы система была очень отзывчивая мы должны быть конкурентные на рынке и часто мы должны конкурировать внутренними rnd-командами которые будут скорее всего какой-то стейт Азарт подход потом из-за того что это сел сервис платформа мы должны быть устойчивы к наплыву пользователей То есть какая-нибудь статья на тех кранчи не должна нас обвалить и все это еще и должно естественно быть достаточно дешевым чтобы тоже иметь возможность конкурировать на рынке Ну еще очень важно что мы только начинали этот продукт и понимали что лучшая идея это двигаться итерациями как можно быстрее получается фидбэк рынка что мы действительно даём то что необходимо поэтому желательно было не из-за дизайнеть работу на несколько лет и начать вести какими-то итерациями получать деньги после каждой операции это привело нас к следующему подходу это немножко так заглядывая назад В итоге у нас появились такие три большие итерации во-первых мы начали с абсолютно не масштабируемого прототипа потом мы решили проблему масштабирования и в итоге стали выжимать из этого решения эффективности и начнем с первой итерации как я говорил мы хотели получить фидбэк как можно раньше и inten классификатор еще был Хорош тем что этот компонент сам по себе был очень ценен для рынка то есть очень много кейсов где его было достаточно для того чтобы получать например это всякие умные ivr звонках это классификация результатов НПС запросов и разные прочие кейсы на который у нас реально был спрос и наши сейвы подтверждали что это хорошая идея мы сознательно не стали думать о масштабируемости и эффективности и сфокусировались на качестве модели на первой итерации и скорости работы системы поэтому верхнеуровнево мы решили просто создать некоторые внутреннюю систему для внутреннего использования нашей проектной командой которая просто автоматизировала тренировку xlm robertowatch на некоторых пользовательских данных и выкладки этой модели в прот и сербинга чтобы наш Проектная команда могла заниматься этой работой без привлечения инженеров минус такого подхода очевиден что если мы не сможем придумать как это решение масштабировать то как бы не очень понятно что делать вот с теми клиентами которых мы уже подсадили на эту технологию Мы решили что Ну да это будет такой наш небольшой текст небольшая система за которой придется приглядывать Но хотелось все-таки не распугать первых клиентов низким качеством В общем некоторые план б у нас был и такая задача очень просто реализуется берем готовые компоненты берем уродливый bootstrap берем остапе берем постгресс для управления данными просто кидаем даже просто в рейде с даже не вребятам задачки на тренировку просто потому что можем тренинг сервис выглядит какой-то Wild цикл В общем Все выглядит очень кустарно Но работает соответственно и строение глупо результаты артефакты укладываются вместе с метриками тренировки и для инференса мы используем NVIDIA Triton сервер и небольшой питоновский сайт который занимается со вкладкой модели в этот NVIDIA Server вот выглядит как быстро и прототип но он сразу же ставит ряд проблем во-первых как подбирать гиперпараметры мы отдавались и отчет что в условиях жестких ограничений мы не сможем придумать какую-то хорошую схему которая бы работала для всех Поэтому чтобы хоть как-то двигаться Мы решили начать с какой-то простой евристики которая просто подсчитывает количество тренировочных шагов в зависимости от топологии dataset его размера распределение по классам звучит красиво на самом деле мы еще упростили задачу мы просто попытались построить некоторую зависимость между размером dataset и количество тренировочных шагов для этого у нас было большой набор дата сетов наших клиентов и в итоге мы нашли эвристику уродливую которая не всегда хорошо работала но она позволяла нам делать какие-то первые шаги Но самое главное что Мы понимали что это будет работать скорее всего не очень хорошо и чтобы как-то решать эту проблему и чтобы добавить транспарентности в систему мы обязательно трекали Все вымыли Fall для того чтобы была возможность проанализировать Как там качество последнего сабмишина то есть каждая тренировка проходила в двух режимах один раз в режиме кросс валидации второй раз уже на всем дата с этим пользователя с использованием этой ивристики и мы смотрели насколько это вообще все работает И помимо этого нам очень сильно помог с вопросами хранения моделей и версионирование и доставки их на продакшн он предоставляет функционал Model regis 3 который трекает артефакты привязывает к ним метрике и предоставляет API для того чтобы подгружать последние версии модели и что мы сделали Мы просто подкладывали последние версии с NVIDIA Triton который в свою очередь имеет функционал пуллинга своего registry То есть он просто опрашивает с какой-то периодичностью файловой системы если видит новые версии модели новые модели то просто подтягивает их бесшовно в память То есть получается что простенький сайт Car на питоне который связывает эти две системы воедино в общем-то решает наши проблемы в итоге буквально за несколько месяцев у нас получилось собрать базовый plc на котором можно было реализовывать кейсы нашей проектной команде довольно быстро и затащили в эту историю несколько ритейлеров и провалидировали эту идею деньгами и стало понятно что это и правильное направление остается просто развивать и заниматься масштабированием но глобально конечно главный Инженерный Челлендж был впереди система удовлетворяла первым нашим двум требованиям Ну ладно проблема каждая модель на GPU Жирова по 2 Гб и соответственно если к нам придет много клиентов которые захотят воспользоваться нашей платформой есть высокая вероятность что мы не успеем за ними масштабироваться потому что они могут просто создать какой-то Hello world особо им не пользоваться А 2 ГБ видеопамяти Вы недополучно то есть любая любое пиковый наплыв пользователей все разрушает Но из плюсов можно сказать что да мы как команда заработали некоторые кредит доверия и смогли собрать Костяк то есть теперь оставалось решать вот эту проблему а как мы это сделаем благо Мы понимали что опции у нас предостаточно Нужно было лишь подобрать правильный компромисс между стоимостью качеством И масштабируемостью какие же опции мы рассмотрели во-первых можно закрыть проблему чистой инфраструктурно при каждом создании нового проекта в системе авоцировать новые gpu-ресурсы и дальше сделать это проблемой нашего дивапса но эту схему можно безусловно улучшить добавив некоторую логику ротации моделей соответственно загружать из памяти то что реально не используется и можно посмотреть в сторону каких-то более легких моделей которые можно инфектить на CPU потому что все-таки ресурсы масштабируется гораздо проще чем GP юшные и там могут оказаться дешевле первый подход мы отмели сразу потому что не были уверены что развертывания наших ресурсов будет поспевать за системы Потому что тут был фундаментальный косяк в том что а мы должны были скелиться не на полезную нагрузку на систему А на темпом создания новых проектов то есть уровень утилизации ресурсов в таком подходе просто чудовищно низок что еще хуже на таком подходе очень сложно строить разумную модель тарификации То есть если посмотреть автомобиль системы они стараются тарифицировать по запросам потому что Ну это понятно прогнозируемо Если мы будем говорить что просто на создание проекта у вас будет уходить там 100 долларов в месяц это наших пользователей можно улучшить эту ситуацию как я говорил ротации но грузить такие большие модели видео памяти Достаточно долго хоть это можно придумать как ускорить но в целом это не выглядело как какой-то фундаментальное решение И самое главное все равно было как-то сложновато выстраивать модель тарификации Ну и конечно же мы могли брать немножко сделать шаг назад брать более легкие модели но нам не нравилось то насколько сильно деградирует качество при переходе на предыдущее поколение моделей но в целом как бы казалось что это какой-то интересный подход который можно чуть-чуть покопать поэтому здесь есть пункт что-то еще как мы рассуждали про переход на более легкие модели во-первых мы можем полностью уйти на CPU inference вернуться на worder beating какие-то модели на базе wartem bending дистиллировать Трансформеры до какого-то очень небольшого размера и в целом рабочие подходы но нам не нравилось насколько сильно деградирует качество при этом вторая история была связана с гибридным инференцем Мы например могли иметь один Бирт на всех клиентов которые просто занимался бы энкодингом данных а соответственно на базе какого-то сентенбединга Мы бы уже строили какую-то легковесную модель с которой гораздо проще манипулировать либо же просто перейти к режиму например knn классификации в котором модели Как таковой нету нужно там развернуть фаиз на клиента и искать ближайших соседей но мы подумали что все-таки компромисс качество слишком высокие начали думать Можно ли это как-то улучшить потому что вот второй подход казался более перспективным мы много работали С Трансформерами и в принципе знали у него его особенность то что задачах стрима обычно верхние веса Трансформеры меняются гораздо сильнее чем нижние в целом это Разумное высокие свои занимаются за семантику низкие за какие-то низкоуровневые фичи языка Конечно все гораздо сложнее но как бы так на пальцах Да ну чтобы провалитировать идею Мы конечно пошли читать про бертологию и нашли набор обзорных статей которые в общем-то подтверждали наши догадку что если в процессе тренировки просто заморозить большую часть Трансформера и finetunes только финальные слои компромисс в плане качества не такой высокий Вот то ресетчеры пришли в общем-то таком же виду выводу и там Алена НЛП недавно буквально в июне выпустила тоже интересную статью с похожими идеями Как сделать более эффективную тренировку и сербинг Трансформеров и фактически это могло решить нашу проблему потому что мы знаем что им ботинги и нижние свои достаточно тяжелая вещь они могут занимать там колоссальную часть объема к опасности Трансформера если мы оставим на fantuning только несколько верхних слоев их можно тренировать под конкретного клиента и перед тем как думать про то как вспомнить это инфраструктурно мы решили проверить с точки зрения качества на наборах некоторых наших дата сетов и мы взяли фолк какой-то золотой стандарт попробовали несколько разных подходов в плане использования Трансформера как мейдера потом просто зафанить юнили его или там с некоторым количеством замороженных нижних слоёв и в среднем на стоимость Вот примерно такая картина не на всех дата сетах но она как-то более-менее типично и мы поняли что компромисс качество оказался достаточно приемлемый мы все равно работали сопоставимо состоит из Арт поэтому казалось что это хороший подход как он помогает инфраструктура Он решает проблему масштабирования таким образом что у нас появляется какая-то Общая часть на всех клиентов и получается маленькие модельки на каждого клиента почему это решает нашу проблему потому что самая дорогая и не масштабируемая часть это вот это больше часть Трансформера она одна на всех и она должна масштабироваться не по количеству проектов А по количеству полезной нагрузки по весу соответственно сделать масштабирование gprps это не так сложно маленький же кусок сверху он достаточно быстро и легкий он быстро поднимается в себе память соответственно можно устроить просто инференс на CPU и моделька очень быстро ротируется то есть мы можем поднимать ее он демонт с достаточно хорошим временем прогрева менее чем за полсекунды она поднимается у Nine X runtime в память в общем получается все хорошо Для нас это допустимое время на некоторые прогрев финальная картинка же инфраструктура получается такая что пользовательский запрос попадает на NVIDIA Triton где он мэдится первыми 22 сваями Трансформера потом этот набордингов для сабвурдов отправляется до считываться на CPU где если пользовательская моделька уже при кэширована это все считается меньше чем за 100 миллисекунд в среднем Если же моделька не оказалось в памяти она подсчитывается с дискового кэша и это еще добавляет там порядка 200 миллисекунд что не очень хорошо но хотя даже и в худшем случае мы подтягиваем эту модель прямо и Что добавляют еще там порядка нескольких сотен миллисекунд то есть худшем случае до запрос может выполняться до пол секунды но учитывая то что крыша работает это происходит на самом деле на практике не так часто то есть вопрос правильный копать эти нашего кэша что еще очень важно в этой инфраструктуре то что запросы получаются унифицированные то есть неважно на какой вычислительный cpu-pod наш приходит наш запрос в любой момент времени в худшем случае это просто вопрос прогрева кэша нах но в целом если под отвалился то в этом ничего страшного другой под тоже способен выполнить этот запрос это снимается нас проблемы по созданию некоторой системы роутинга запросов между кодами аллоцирование конкретных поводов под конкретных клиентов то есть такая унифицированная архитектура которая гораздо проще скиллить и что еще важно мы можем построить очень понятную модель тарификации фактически сделав нагрузочное тестирование в разных режимах работы мы можем прикинуть количество запросов которые может выдержать одна нода прикинуть что полная утилизацию Какая полная утилизация в рабочие часы сколько запросов мы вот в это время можем выполнить и просто разделить стоимость аренды этой машины на количество этих запросов то есть при полной утилизации мы получим цену одного запроса и заложив туда несколько иксов на всякие неучтенные моменты которые мы до сих пор можем не понимать И накинув чисто бизнесовую маржу мы получаем цену которую уже можно отдавать нашим пользователям по итогу Мы решили главную нашу проблему а-а масштабирование не пожертвовав очень сильное качеством и получив внятную модель монетизации оставались последние штрихи в нашей системе которые позволили бы спать спокойно Это вопрос подбора гиперпараметров и поддержки языков в нашей системе То есть у нас была на успех подобрана еврейстика а-а хотелось проваледировать насколько она адекватна а с другой стороны надо было понять какая наша стратегия в добавлении новых языков потому что в общем имплант работает в в принципе с клиентами по всему миру поэтому у нас было четыре языка которые надо поддержать учитывая что наша система рассчитана на людей не особенно знакомых с машинным обучениями мы сразу отмели подходы а полноценного говорить всё ещё гиперпараметров Потому что часто они требуют какой-то ручного анализа а-а и оставили всё также единственным гиперпараметров количество шагов тренировки соответственно можно было тут тоже подойти к подбору этого гиперпараметра двумя подходами либо делать сначала кроссовали на сайте и примерно прикинуть Сколько тренировочных шагов необходимо для того чтобы модель сошлась и сделать некоторые критерии или стоппинга а либо же всё так же продолжать работать с формулой с первым подходом мы не стали очень сильно двигаться вперед потому что даже первые эксперименты показали что на дата сетах где очень мало данных Fusion Learning такой подход часто показывал какие-то сумасшедшие эпохи это работало не очень хорошо поэтому мы решили продолжить работать с формулой в этом нам помог наша dataset dataset Massive отметки на них мы смогли нарезать огромное количество небольших дата сайтов с разным распределением данных между классами и соответственно попытаться построить некоторую регрессию между топологией этого дата Сета как-то количество классов количество данных дисперсия средняя и количество оптимальных эпоху тренировки которую мы могли проверить по кросс валидации и в итоге с удивлением для себя обнаружили что на разных слайсах этого многомерного распределения мы все также видели какое-то подобие обратной зависимости то есть всегда был какой-то двухмерной плоско которую это зависимость мапилась довольно хорошо И это была как раз таки зависимость между средним количеством примеров на класс и оптимальной эпохой то есть по факту мы просто взяли примерно ту же формулу с которой начинали и уточнили ее на большем количестве дата сетов Вот примерно это так получилось за это естественно пришлось расплатить качеством у нас была ошибка а проксимация оптимальной эпохи но мы не сильно расплачивались финальной метрикой на которую мы смотрели как все-таки на целевую В общем даже с учетом нашей неэффективности мы все равно были плюс-минус на равных решениями с которыми мы хотели конкурировать Последний вызов касался языков языков в связи с нашей географией и мы хотели понять одну простую вещь стоит ли нам брать мультиязычные Трансформеры как некоторые backbone для нашей системы или же нам нужен трансформер Под каждый отдельный язык соответственно а в нашем конкретном случае конечно всегда очевидно я думаю любому кто работал Что за funtune на конкретный язык трансформер на ваших данных неразмеченных Скорее всего будет лучше мы хотели Понять насколько серьёзный компромисс и в итоге мы просто взяли и до тренировали xlm Роберту на наших дата сетах в режиме э-э в режим ну в режиме москва-моделинга и получили что финальное качество на наших датах оно в принципе Нас устраивает Понятно Что Лол ресурс LG вроде португальского они не так хорошо работали там как английский или или испанский где данных было больше но в целом как бы качество сопоставимое с тем что можно выжить с других венторов Ну и русский язык у нас стоял немножечко особняком потому что всё-таки Домашний рынок и там смогли просто из-за объёмов данных тренировать больно уж хорошего сингладеле Поэтому в итоге мы остановились на ситуации где у нас был backbone для русского языка и один мультиязычный трансформер для всех остальных Это был одна важная инфраструктурной точки зрения потому что все-таки GPU память на одной ноды ограничена соответственно если надо держать много разных бакбонов получится что надо иметь много специализированных нот под разные языки в какой-то момент усложняет инфраструктуру Хотелось избежать пока что избежали в будущем конечно Видимо нам всё-таки надо будет двигаться в эту сторону но пока вроде хорошо вот в итоге получились примерно за 9 месяцев работы полноценный инструмент для создания гибких сценариев коммуникации на базе почти что и сервер скрипта который глубоко интегрирован в телефоне в конце небольшое саммеры во-первых мы для себя обнаружили огромную пользу от гибридного инференса оказалось что его достаточно несложно реализовать У нас есть NVIDIA Triton который сам по себе очень хорош Он позволяет там динамический батчики запросы Он позволяет подтягивать модели в память в общем инструмент потрясающий еще и как бы если использовать не One X а тензор тишиной Модели там вообще все хорошо про перформансу а с другой стороны сам по себе классный инструмент который быстро поднимает легкие модельки у него есть разные тонкости с тем что он очень любит внутри себя прикишировать графы вычислений поэтому там надо аккуратно выставить в флажки сессии но в целом как бы мы не встретили каких-то проблем которые стали для нас шоу стоппером второй вывод немножко про то что может быть более такой философский общий про то что как показали наши опыты там работа с данными она все-таки чаще важнее подбора гиперпараметров мы там на нашем опыте подбора этих самых эвристик мы все чаще видели что именно топология дата Сета влияет на финальные результаты гораздо лучше чем тонкая подбор параметров оптимизатора по крайней мере в задачах Нью Понятно есть области где это совсем не так много можно сказать что это действительно подход Эндрю ина который он пропагандирует про работу сданные Мы скорее подпишемся Под этой идеей Ну и в трансформере хоть он и оверпиометризован большой не всегда очень эффективный на самом деле таится огромная к опасности для всяких улучшений то что вот мы рассмотрели в докладе только что не затронута много разных идей про то что не все имейдинге на самом деле всех субардов нужны можно часть из них выкинуть Вот и в целом читать статьи по бертологии Это не просто там увлекательно иногда это может навести на какие-то интересные подходы в плане более эффективного серфинга и тренировки модель на этом все Я надеюсь что доклад оказался вам чем-то полезным и Если у вас есть какие-то вопросы то мы можем обсудить и тут и можно написать всегда мне по этим контактам Всем спасибо Спасибо за доклад было очень интересно пару вопросов первый Это насколько построение модели сложная для нового языка у вас то есть вот просто там 5 языков построили до берем какое-то 6 насколько это трудоемкая история и Ну хорошо Да да Ну это очень хороший вопрос Это очень сильно зависит от языка у нас такая ситуация что мы зависит от языка и от того Какое количество данных для этого языка есть Вот как я говорил у нас проблема была например с португальским то что ресурс Language в нас в режиме маска модулинга всегда начинает вопрос возникает сэмплинга Как правильно сэмплить эти языки в тренировки чтобы попасть эти модели как-то равномерно между ними распределялась то есть до 10 до 10 языков обычно Ну как бы все хорошо Это даже не из этого опыта там из предыдущего опыта там больше всего проблем возникает Примерно вот на 10-15 там очень сложно устроить какой-то очень правильный сэмплинг чтобы качество на Low Resource legagers не деградировала по сравнению с основными Вот но в целом Ну еще у нас такая ситуация что у нас достаточно дженерик домен на котором в принципе даже там изначально при traint Transformer там которые меты сделан в принципе относительно неплохо работал то есть нам оставалось просто немножко подтюнить под чисто разговорные данные но в целом именно проблема это наличие данных под конкретный язык и то и вот в какой-то момент возникает проблема Battle Neck А когда количество языков там превышает десяток второй вопрос Когда нужно построить решение одновременно разговаривающие на нескольких языках когда смешанные вещи Да это еще лучше вопрос к счастью нет Вот я прям честно покажу и опять же до возвращаясь к некоторому предыдущему опыту когда приходилось такое строить трансферник между языками из нашего опыта эта вещь очень ограниченная особенно если языковые пары дальние То есть у нас там был например английский корейский там Трансформеры почти не работал то есть там объемы данных которые надо было корейских размеченных добавить для стрима было чуть ли не сопоставимо с тем как если бы мы Ну типа только на них тренировались вот поэтому нет но это как бы да очень тонкий момент не всегда взлетает а Артем здравствуй Спасибо большое за доклад у меня такой два вопроса Первый это больше такое уточнение по докладу Я так понимаю что данные от клиента всегда приходят и новые и они дополняется и модель переобучается Ну backbone мы чтобы натренировать backbone То есть у нас была там договоренность некоторыми клиентами Что они были не против мы там давали им какие-то скидки чтобы мы Их использовали Вот но в целом нету системы что вот мы их прям до обучаем дообучаем потому что разговорный домен хороший или плохо тем что в целом по тем вертикалям по которым мы работаем там разговоры фундаментально не меняются Понятно возникает ситуация с какой-то там новой лексикой там каким-то новыми оборотами Но обычно мы рекомендуем клиентам забивать эту проблему увеличением дата сетов именно Да он Стрим таски Вот потому что но в целом как бы это такой процесс у нас не автоматизирован просто раз какое-то время мы смотрим если смысл как-то вот нашу болванку Чутка надо в Фэн тюнить на МЛМ чтобы это все работало Спасибо И второй вопрос вот там вот на картиночки где был pipline нарисован самая самая там первый там было Вот момент Flow и Push на Production модели вопрос как выбирается лучшая модель потому что модель может обучиться и она будет например хуже предыдущей Кто принимает решение Вот это да это тоже отличный на самом деле этого тоже огромный минус сервис автоэма или платформы что мы просто полагаемся на качество пользовательского дата Сета и какой-то такой прям валидации там не происходит то есть мы просто берем из То есть когда появился новый дата сет мы его просто обучаем и отправляем и перекладываем эту про на голову человека который создает решение с помощью automl-платформы потому что они могут вообще в них очень много разных стратегий валидации Иногда и мне интересный файл метрики Потому что им важнее именно результаты какой-нибудь там более высокоуровневый бизнес метрики например конверсии там в решенную проблему Вот И там типа дата сет мог просесть На каких-то классах но как бы в целом клиент для клиентов Это какой-то маргинальные вопросы это для них не сильно проблема поэтому чаще Вот именно в B2B для людей которые вот не сильные в машинном обучении они бы все равно не смогли правильно интерпретировать оффлайн метрики поэтому мы просто выкатываемся и типа решайте на б тестах чего лучше клиент сам решает идея на самом деле очень хорошая конечно Давайте хотя бы какие-то хинты по поводу того что с каким-то классами у вас проблемы это то о чём мы задумываемся надеюсь Спасибо Спасибо за доклад у меня такой вопрос Вот получается что та часть которая с низкоуровневыми слоями она у вас как бутылочное горлышко да то есть как вы решаете Какое количество таких нот должно быть поднято и что будет в случае если у вас произойдет резкий всплеск там количество клиентов да то есть что будет деградация по времени или просто не будете давать возможность поднимать новый сервера да То есть как это устроено у нас кубер развернут для этой части вот который с GPU на notex GPU соответственно там настроен мониторинг Вот и у нас есть некоторая по сути к опасности то есть помимо той нагрузки что мы есть мы держим там процентов 30 еще ресурсов которые вот на всякие всплески Вот соответственно у нас есть какие-то альтинги и в случае если срабатывает пока мы как-то побаиваемся делать Прямо полноценные авто скейлинг то мы просто вручную там добавляем какие-то ноды и стараемся вот не не попадать в ситуацию что вышли За ресурсы Спасибо"
}