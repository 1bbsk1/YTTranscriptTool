{
  "video_id": "ChMKNf9P1e8",
  "channel": "HighLoadChannel",
  "title": "Репликация данных из MySQL в ClickHouse / Владислав Клименко (Altinity) и Валерий Панов (Ivinco)",
  "views": 2337,
  "duration": 1814,
  "published": "2019-01-14T00:08:48-08:00",
  "text": "всем привет меня зовут валерий по тимлид команды админов комп новинка мы больше девяти лет эксплуатируем большой business to business search проект по большому объему данных вот он называется борт reader у нас около 200 терабайт данных москве или и двадцать пять терабайт данных в индексах мантикоры мантикора если кто не знал это ford сфинкса привет андрей аксенов но сегодня речь о да какие данные сначала это были награбленные самостоятельно данные по message boards основного мы из англоязычного сегмента потом мы ставили караулить блоги микроблоги появились деньги начали покупать поставщику данную поставщиков и на данный момент проект большой у нас партнерка с ютюбом мы получаем от них данные мы покупаем данные о джинни айпи у twitter у нас партнерское соглашение с контакте com лицензии на использование данных для research и маркетинга от своего врача у нас контракт сыновей байс это не знал это китайский twitter в общем много чего но сегодня я буду говорить о небольшой части нашей системы о перформанс да и то что мы понимаем под перформанс дейта это регистрация событий в нашей системе поисков через нашей 5 соответственно под ним под перформанс этим понимаем вот такой топал ту пол это время когда запись была записана и url ключ api по сути нить в катар клиента идентификатор уникальный идентификатор странички и еще куча куча различных параметров по времени затраченным на разные компоненты системы есть больше на самом деле в реальности понятно все хуже там еще и колонки который описывает количество запросов мантикору количество запросов mais quel пост данные если они были ну и так далее там очень много всего так вот собственно у нас около 4 миллионов запросов и пиа и в день что общем то ерунда на запрос очень тяжелое они могут исполняться 300 секунд каждый и поэтому для нас 4 миллиона это много плюс там около полумиллиона чуть больше событий по перестройке индексов мантикоры тоже все лакируется в отдельную табличку исторически ну это было еще созданной 9 лет назад все это пишется в моей сам таблички в москве сервер и сделано порционирования на коленке то есть каждые сутки мы начинаем писать в новую табличку и имени таблицы присутствует timestream то есть называется там перформанс влог 1806 25 например вот примеры того что мы делаем с перформанс дейта у нас на них завязан мониторинг и аналитика вот на этих слайдах вы можете видеть например как раз сведенные на один del port графа навский выжимку из данных по реке обь и вот это как раз собственно контактик вещь новое мы недавно разработали и вот вы видите что здесь середине примерно драматический 1 95 процентный перцентиль и вот голубенький сфинкс time вырос практически с нуля до 1 секунды мониторинг это заметил и оказалось что на самом деле это не страшно это момент включения боевого мониторинга на боевых серверах то есть до этого мы ничего не проверяли а тут стали слать периодически запросы которые под по секунде выполняется вот пожалуйста а вот пример более позитивного события это количество событий индексации скопированного там по моему по пять минут увидите что вот она подергала си упала в полтора-два раза это я починил систему блокировок при перестройке индексов и получилось что мы в два раза меньше стали строить индексов потому что до этого был баг и слишком часто строили индексы сэкономили считаете в два раза по ресурсам баз данных по ресурсам машин который бойцы копают вот это уже аналитическая задача кроме того там есть множество вещей которые использует отдел маркетинга всевозможные отчеты и еженедельные ежедневные ежемесячные просто кастомные запросы которые у аналитиков на кончиках пальцев где-то там пички мая 2 не забиты и как бы последнее время с этой системы нас начались проблемы во-первых захотелось хранить данные долго а точнее всегда до этого мы хранили данные только за последний месяц больше не вылазила выяснилось что стоимость хранения мой скорей даже мои сам довольно высоко хотелось бы дешевле то есть просто нужно тупо слишком много винчестер слишком много серверов если мы об этом говорим на данный момент у нас там два средних сервера там что-то 32 ядра и по 4 терабайта рейд массив raid 5 по моему и вот этого хватает на месяц плюс немножко служебной информации дальше запросы от отдела маркетинга они долгие тяжелые как правило довольно дурацкий с точки зрения техника и поэтому чтобы их оптимизировать нам приходилось создавать много индексов вот сейчас там помним 40 индексов и никто уже даже не помнит зачем нужны первые пять поэтому ну это становится неудобным потом в москве в неудобной очей для таких целей вы понимаете у нас понятно есть репликация и если мастер упадет например то мы начнем писать slave но когда потом мастер поднимется возник необходимостью обратно синхронизировать это ресурсы а ведь это всего лишь перформанс влоги то есть это не основная продакшна часть системы и она требует внимание это на мне нравится соответственно мы решили эту систему заряди зимний и начали думать о том как это сделать вариантов решений было рассматривалось несколько было конечно гораздо больше первых можно было все оставить как есть просто улучшить мы скрыли очень понятно хорошо изученная штука есть много паттернов можно было многими способами решить те проблемы которые нас есть не придумывать велосипед вообще не раза но не хотелось это было просто скучно потом рассматривался вариант перейти на elastic search ластик lacoste скиба на стек но он был сильный 0 представляете человек привык и через певички мой админ получать результаты и аналитической за кто-то генетического запроса а тут elastic все совсем по-другому кроме того у нас есть опыт борьбы с и ластиками на в продакшене мы им коллег тим logis наших боевых серверов и вот пластик она мне очень нравится дальше был вариант хранить это дело в новую сквер но когда речь идет о хранении большого объема исторических данных чтобы они были доступны там не ломались и все такое у нас были очень плохие ожидания в на узкую вечно находятся какие-то проблемы и баги которые выстреливают много в самый неподходящий момент и хочу ничего плохого сказать про современного ска или решения но два года назад например просто было бы смешно говорить о том чтобы хранить что-то важное долго новость поэтому пропустили кликал собственно в тренде и мы решили попробовать но надо понимать мы решили не просто перейти на крик house типа был мой skype стал приказ мы решили попробовать и причем попробовать так чтобы не было сильно больно если не взлетит соответственно мы сформировали сна сформулировали такие требования к внедрению crack house а что это должна быть во первых очень плавно и постепенно не напряжена с минимальным с минимальным количеством часов разработки и при этом не трогать заветный код который блокирует в миску и потому что он был написан 9 лет назад соответственно начали мы с того что просто поставили один маленький debian сервер зрители туда crack house тогда откликался еще не было в пакетах и попросили разработку все-таки и нам сделать небольшой лагер который выписал параллельно смазку и собственно на первом же этапе выяснилось что у нас есть несколько проблем во первых лекала см и готовить не умели и выяснил что какие-то вещи в кликал оси нужно делать самого начала когда вы только еще начинаете прототипирование иначе потом придется все данные менять перелопачивать вот смотрите чтобы в классе получить очень то есть сделать кластер вам нужно будет потом менять историчен для табличек alter table хаосе до сих пор не поддерживается и это означает вам нужно будет седана и копировать неудобно лучшую часть сразу мы в самом начале сделали праймари кей для табличка приколись и такой же как был мой склеили плюс запихали за все что можно у нас получился праймари кей по 20 колонкам это оказалось очень эффективно при к власти про америке должен быть минимальным то есть м в чем почему вас действительный всегда обеспечивается уникальность все излишнее в праймари кей понятно сильно очень портит перформанс и опять же тертый был нельзя хотя в бете вроде уже можно значит для смены prime реки вам придется перепало перелопачивать все данные ну и в конце концов вот тот маленький заливчик который девелопмент для нас сделали на коленке он оказалось плох он discarded данные из упрекал становится недоступным он не буфере зa это не пытается заново перезаписать данные которые по сети не пролезли наконец он умеет реплицировать только табличка с определенным именем это фактически захардкожены архитектурно в 35 в местах и поменять это простыми способами невозможно оказалось что тот разработчик который делал вот маленький проектик он ушел в другой большой крупный проект дёрнуть его брат невозможно экспертиза утеряна по сути для нас черной коробкой работать нельзя пришлось бороться во первых с длинным прайма реке проблема вскрылась на звонке когда мы позвали еще одного из экспертов по клика усу кстати si alte нити и начали обсуждать проблемы почему все работает не так быстро как могло бы быть хотя их было приемлемо и вот выяснилось что нужно сделать маленький праймари кей повторюсь в 3 классе нельзя делать alter the ebook поэтому нужно просто выглядите данные какой-то промежуточную табличку создать новые туда все вернуть обратно так вот я прям на звонки запустил этот процесс но с тому времени там был 600 миллионов записи за несколько месяцев что такое ну то есть довольно много но не так чтобы капец как так вот все это перелопатила скрипка вести где-то за полчаса на маленьком девин сервере там с четырьмя ядрами и концу звонка как раз я бодро стартовал знаете про америке проблем с прометеем решена спасибо это было прям чудо потом мы за тепло и или crack house кластер и для этого нужен звуки пир два года назад на хайло ради меня очень пуговицу кипером говорили что вы же не уметь готовить свою кипер как выйти с ним жить возможно у кого-то с ним есть большие проблемы но мы настроили три машины поставить до закипит использовали конфиг рекомендованы как раз в документации клика уса и все и забыли о нем до у нас он обвешен мониторингом и он никогда не ломался даже когда у нас случился network шторм в дата-центре и вся сеть оказалась разорванно вкусов куски закипит выжил и никаких проблем не давал в общем базируясь на моем где-то годичном опыте эксплуатации могу сказать что за кипером проблем у нас никаких не было дальше с лагером проблема была самой острой а потому что было непонятно как ее решать вот представьте у вас есть приложение которое генерирует 5 миллионов событий на запись мой скальп день ну то есть не сильно много приложение вы менять не можете вам нужно эти данные еще копировать другую систему вот я уже думал написать какую-нибудь перловку которая бы свежие данные смазкой или перекладывал frico ac или может быть там что-то сделать на прокси вскользь чтобы она ответвлением в клик хаос как-то работала но тут как раз узнал что вот мой друг владислав из команды оттяните из компании оттяните разработал как раз решение для вот таких вот миграций они понимали что люди возможно захотят когда-нибудь переносить данные смазкой или из полос grease или ещё куда-нибудь в пика us и решили сделать это заранее здесь я хотел бы на сцену пригласить владислава клименко разработчика из компании оттяните он расскажет про детали реализации добрый всем день меня зовут владислав и я занимаюсь разработкой по в команде альпи ники давайте сейчас вот из того эмоционального рассказа в проблемах которые валера нам поведал попробуем немножко сформулировать вот краткую формулировку задача что же мы хотим решить вот и как мы хотим к этому подойти то есть ключевая задача как бы ключевой краеугольный стартовый коммента что у нас есть некоторая система которая legacy очень сильно legacy и к сожалению это встречается намного чаще чем хотелось бы то есть такими проблемами сталкивается не только иринка от не только валера есть эта боль но при этом хочется потихонечку заниматься плавными град именно с возможностью сделать это легко и как можно менее напряжена вот при этом еще хотелось бы иметь дополнительную такую возможность чтобы данные при миграции из моих геля флик house как-нибудь можно было конвертировать обрабатывать то есть чтобы иметь возможностях не просто der коллировать что-нибудь с этим сделать то есть схематично это можно представить так что у нас есть такая вот большая система которая в левой части нашего слайда нарисована которую мы практически не можем никак от трогать то есть она пишет какие-то данные майские и к сожалению с этим ничего сделать нельзя но при этом хотелось бы заполучить как тут с правой стороны там где у нас получается стрелочка рид и при этом как бы работать с клик хаосом в попытке все это дело как-то сделать ускорить и сделать ярче то есть нам хочется как так произвести стыковку системы при этом понимая что слева мы менять не можем практически ничего и при этом чтобы это все было как можно более плавно не напряжно и требующая наименьшего внимания со стороны вот как бы админов опять-таки потому что конкретно в данном случае это была даже не главная система это какие варианты решения можно предложить то есть но самые простейшие то что мы делаем какой то инструмент который делает select грубо говоря с майской или делает insert в клик house но решение прямолинейно и конечно же вот она в общем то работать будет на его недостатки очевидно то есть начиная от того что это полинг в чистом его виде вот и заканчивая тем что в общем то как в этом надо будет сопровождать при этом как бы как выясняется что проблема миграции данных именно из моих геля и в при house и вообще стыковки москаля настолько актуальна что вот как бы команда разработчиков самого crack house озаботилась этим настолько что они сделали mais календжин то есть принципе клик house может даже заниматься как бы представляться fontaine дам и самостоятельно читать как бы как house может читать данные из удаленного мои спели это уже лучше то есть это уже прямо почти то что хотелось бы но все-таки еще нет а то есть какие недостатки у такого решения видны тут есть несколько недостатков то есть первые это то что все таки это будет выполняться во первых со скоростью москве или потому что кликал сбыта и длятся всего лишь зеркалом подбор фронтэнда мысли это можно сказать а скорость будет обеспечивать москве которая все-таки иногда не то что нам и хотелось вот потом вот такого решения весьма ограничены как бы возможности по модификации данных у нас есть третий пункт нашим требованиям это чтобы мы имели возможность в процессе миграции данное не просто зеркалирование что-нибудь с ними делать вот и наконец третий недостаток это все-таки тоже полем хотя конечно намного более удобный вот и хочется сделать это как то по другому то есть во первых не хочет не хочется полить хочется это все делать более контролируемы то есть хочется сделать так чтобы у нас наш майской данный нам передавал самостоятельно и в принципе такой вариант тоже есть он уже достаточно давно существует а называется он applications life то есть принципе что мы можем сделать схематично это как можно представить что мы можем для кластером а если представится и ари плетей шин словам с точки зрения моей спели он будет думать что у него как бы появляется еще один еще одна но да еще одна банка вот в это вот картинки на правой стороне в то время как на самом деле это будет наша система которая будет получать данные из москве или и.п. как бы внутри быть устроена совсем по-другому то же время с точки зрения мазке ли это будет абсолютно прозрачно при этом у нас появляется тут возможность как бы обрабатывать полностью все проходящие данные и даже не только процессе данные но и реагировать на прочие события которые происходят маски или то есть то мы можем как-то обрабатывать апдейта делита то есть получаем возможность контролировать вообще происходящие процессы этот подход нам понравился настолько что в принципе мы реализовали инструмент который позволяет таким образом производить плавную миграцию данных из моих крыльев при хаус с фоне максимально как бы без модификации уже существующих систем то есть что должна предоставлять данная система для максимальной простоты эксплуатации то есть типичная задача выглядит как что у нас есть некоторый массив данных накопленные за какое-то время и нам бы хотелось omax мально легко и непринужденно мигрировать в клик house и плюс потом чтобы все обновления которые продолжают описываться тоже на лету плавно заходили и смотрели в плит хауса вот собственно предлагаемое решение в которое мы описываем это и предоставляет то есть у нас есть миграция существующих данных и репликация которая еще как бы предоставляет такие дополнительные возможности как автогенератор шаблонизатор таблиц на практике тоже как выглядит то есть естественно у нас обычно большие таблицы широких много вот и при этом нам бы естественно мы не хотелось заниматься руками переписыванием этих всех таблиц то есть в принципе мы можем попросить чтобы у нас автогенератор полностью одет коллировал структуру данных из моей спеллов прикол самостоятельно это вот если мы что-то хотим там поправить то можно воспользоваться шаблонизатора вот и получается что мы создали какую-то структуру данных либо совсем зеркально либо с какими-то модификациями если мы это хотим после этого мы можем начинать перекачивать собственно данные при этом в процессе мы можем выполнять как фильтрацию так собственно говоря какое-то отображение множества входящих данных на множество исходящих то есть самый простой вариант и широко распространенные то слить допустим множество таблиц в одну то есть на практике это наиболее широко встречающийся вариант в частности вот в случае который мы рассматриваем сейчас на практике валерий это именно это и есть что сливать ежедневные таблицы в одну большую таблицу клик хауса в которой хранить данные завсегда для более сложных случаев когда у нас не получается какими-то стандартными фильтрами обойтись то предусмотрена возможность делать плагины практически то есть плагин это у нас класно питоне написаны который может сделать практически кто угодно у которого интерфейс стандартные и логика его весьма прямолинейно то есть он получает на вход какой-то набор записи которые соответственно поступают парик реке ишим своих протоколу вот и на выход он может предоставить от 0 до м каких-то записи причем начинают 0 это если он решил что все надо отфильтровать и записям может предоставлять больше с только хочет любого формата то есть принципе получается что общая схема решения вот такая протекание данных от источника в точку назначения то есть и получается что у нас есть какая-то подсистема входящих данных обработки в большинстве случаев это конечно же моя спина в принципе мы можем работать как с файлами такой с другими источниками потом какой-то набор конвертеров и в конце у нас соответственно система целевая в большинстве случаев это клип хаос но опять-таки может быть все что угодно то есть принципе чаще всего еще файла встречаются вот теперь для удобства использования но мы постарались как можно больше это предоставить опции конфигурирования для всего этого вот в итоге получается достаточно гибкая система у которой четыре основных направления по опциям то есть это настройки системы в целом описание каких-то источников данных вот почему и так акцентирую внимание на описание источников данных потому что это может быть весьма сложная структура то есть если у нас множество таблиц множество баз данных а нам надо там из пяти баз данных из таблиц причем заранее не известно как они будут именоваться мы только знаем допустим шаблон именования что они будут по датам именоваться покачивать данные для но воссозданных таблиц и в итоге получается что это выливается в некоторое описание источников абстрагировано вот и вторая секция описания потребителей данных которые обычно намного проще потому что большинстве случаев надо все вклад house какую-то одну большую таблицу он закатать и описание конвертера то есть как мы хотим преобразовывать данные на ходу начинает встроенных конвертеров и заканчивая плагинами которая по которой упоминалось ранее то есть ну что в принципе на текущий момент имеется практическое внедрение неоднократно но хотелось бы дальше развиваться то есть напрашивается естественно увеличение количества источников данных то есть сейчас это в основном наиболее востребованы это маска или файлы в общем то мы можем представить себе развитие в сторону под грейс к или ли каких-либо данных и естественно как можно больше конверторов до предлагаем и инструментарию это полностью open source и поэтому если кому то интересно то естественно с большим удовольствием будем готовы принять полу request и ну а внутренний как бы структуре данного инструментария миграция наверное достаточно вот давайте теперь послушаем насколько это удачно удалось внедрить на практике вот валера расскажи нам пожалуйста что у вас в итоге получилось передаю слово валерия себя ну инсталляция тузы очень просто собственно ставится через пип в документации все описано и есть пакеты под centos 7 у нас к сожалению centos 6 андрей не стоял поэтому пришлось так у нас знаете у нас две серии таблица синхронизируется первое это перформанс лака 2 это indexing лак событие индексации сервис на данный момент к сожалению имеется синхронизировать только одну серию таблиц ну и krause поэтому у нас запущен сервис а рядышком скрине на коленке еще второй поток синхронизируется но оба инстанса тузы покрыты мониторингом то есть мы мониторим что сервис жив процесс есть и также мы смотрим разницу в возрасте записи в москве фрикасе достаточно легко реализовать простейшим скриптом это оказалось достаточно кстати по поводу инсталляции собственного аль keenetic кроме этого проекта есть еще много связанных вещей для клик хаоса и вот одна из самых для нас полезных и нужных вещей это прямо на репозиторий для centos 6 7 напомним дальше больше операционных систем поддерживается и вот я сколько ни искал я находил только еще один публичной репозитории с рпн коми как хаоса и там не все было хорошо степен даме вот в той версии по истории что alte нити делает там все прекрасно пару слов еще про особенности хотел рассказать ну во-первых он запоминает белок позиция для последнего успешного записанного ряда в приказ и поэтому если что-то пошло не так и все развалилось то вы потому перезапустите он возобновит все он может реплицировать набор таблиц по префикс матч то есть все таблички который начинается с п но прям или там с перформанс как угодно этого принципе для нас уже достаточно есть неприятные особенности там по моему у нас что-то несколько записей вот из пяти миллионов в день теряются и мы пока не поняли почему но бог request тоже запилили и в общем я думаю в ближайшее время все будет исправлено теперь самая сладкая что получилось в итоге во-первых обошлись без задач в разработку тот маленький кликал лагер которые они для нас написали не в счет мы же вы выбросили потом crack house кластер скалится горизонтально и вертикально вот у нас две машины в которых копия каждого шарда хранится на каждый из машин мы можем поставить еще две машины и удвоить capacity по емкости мы можем поставить еще две машины и удвоить количество реплик для чтения и это все без особых каких-то проблем нам не нужно будет ничего делать не с данными не с клиентами ну собственно кликов для этого был разработан приятно по времени реализации вот здесь вы на экранах видите сколько всего получилось скажу что вот ниша он стал attempt был ошибкой потому что следовало сразу использовать готовые рекламные сборки и если вы лучше управляете своими людьми то у вас конечно получится быстрее собственно что в итоге я бы хотел сказать что кликал сейчас это не просто модная штука я тоже целая эко-система куча народа там понаписала всяких вещей раундхаус и собственно можно попробовать приказ без всякой боли и без рисков поставили сервер попробовали не зашло выбросили и не сильно жалко это не что-то вот несколько лет назад помнится были холивары на тему мой скрыли под бисквит вот и кто-то нам задавал вопросы типа не рассматривали вариант миграции в по адресу но вы понимаете что стоит терабайт postgres мигрировать без downtime а это такая задача особенно когда железо не бесплатно а вот сколько сам все пожалуйста можно до собственно вот с еще раз ссылка на git хоп где можно взять репликатор и ссылка на как раз все проекта альт инете всем спасибо мы готовы ответить на вопросы что если у кого есть вопросы можно поднимать руку вот давайте спасибо за доклад мне вопрос про репликатор какую семантику копии он поддерживает атлас mance в рай clans или рюкзак рюкзак линз получается репликатора у нас умеет работать как через нативный протокол клик хаоса собственно говоря которую нас точно так же он может делать дамб и потом с и давай через тулу которая клик house клиентов то есть и получается что в итоге у нас получается этому лсд wynn's atmos монстр следующие еще вопрос тогда плотва то дальше здрастя все таки какая задержка у вас между моей скрыли и лик хаосом для нас там не принципиальны миллисекунды но задержка в пределах 30 секунд это alert носу более 30 секунд в реальности мере литл анна и в районе секунды и мы ничего не делали чтобы оптимизировать потому что ну понятно для нас of the historical data и в принципе задержка в пределах часа было бы наверное были менеджер приемлем я еще могу по этому вопросу расширить то есть немножко там можно конфигурировать максимальное время буферизации то есть секунда это стоит там по дефолта можно как раз таки cliff house предпочитает себя принимать данные не построчно облаками чем больше блок тем лучше поэтому соответственно в метро тори можно накапливать либо по максимуму строк либо отсечка по времени вот и соответственно это можно на конфигурировать но при этом надо понимать что если в итоге получится запись построчно это прекрасное оптимизирован для то то есть это всегда поиска кого-то компромисса между размером буфера котором мы туда хотим запихивать а временем задержки ну то есть вот у нас задержка в секунду это как раз листа того что дефолтный буфер одна секунда здесь мы сделаем по-другому будет всего немножко начинать и нища вопрос о кого-нибудь ну чтож если нет вопросов но непонятно вается диметром а был кто туда нет а вот подождите секундочку сейчас микрофона мы понесем вопрос по инструменту собственно если мы в моей спели используем транзакции это будет адекватно обрабатываться в том числе случай когда транзакции отменяется есть и были какие-то промежуточные изменения получаются транзакция по репликам своего заходит уже целиком готовая я думаю что если не использовать там 7 sing репликацию то это будет точно также transaction сейф как и обычной репликацию между двумя мы скрыли серверами то есть это должно быть бог все еще вопросы то есть как я начала говорить если они еще в дальнейшем появятся можно их будет задать на дискуссионной зоне который находится прямо напротив входа а сейчас поблагодарим за доклад наших гостей"
}