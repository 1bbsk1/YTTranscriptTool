{
  "video_id": "RCO7MywWXFc",
  "channel": "HighLoadChannel",
  "title": "ETL-сервисы и таски для Такси, Еды и Лавки / Владимир Верстов",
  "views": 1464,
  "duration": 3004,
  "published": "2022-03-21T12:55:00-07:00",
  "text": "я руковожу разработкой того что мы называем платформой управления данными в яндекс такси идея лавки и сейчас мы помимо вот этих и известных юнитов которые обитают внутри приложение яндекс гол начинаем внедряться еще в яндекс-маркете соответственно чтобы понять вообще в принципе масштаб все наши проблемы с которыми столкнулись хорошо бы оценить с чем мы работаем работаем мы с достаточно большим количеством пользователей то есть у нас порядка пяти или шести сотен менеджеров которые постоянно работают с данными они не только смотрят какие-то готовые отчеты но и часто делают различные txeq запросы и соответственно данные для них должны быть доступны постоянно чтобы они выполняли свои операционные обязанность есть несколько сотен аналитиков данных и мэрлин жене raw и соответственно работ по ряд тоже завязано данные даты инженерные команды которые по сути готовит все то чем пользуются люди она у нас тоже достаточно большая это только для такси еды и лавки порядка там 30 40 человек настоящим большая команда и соответственно есть технологический стек про которого я сегодня буду как раз рассказывать который состоит из каких-то систем из фреймворка которые мы для себя написали и справляется со всей этой нагрузкой 0 пытается справиться со всей этой нагрузкой которая на него сваливается о чем я буду рассказывать сначала я расскажу кратко достаточно то вообще в принципе до какого состояния мы дошли что у нас есть сейчас какая архитектура как мы работаем как мы функционируем дальше расскажу про то как мы к этому шли потому что архитектура они не рождаются в какой-то определенный момент времени что вы сидели у вас ничего не было потом бабах и какая-то сложной архитектуры расскажу про фреймворк который мы написали для решения своих задач и соответственно то что у него немножко под капотом спрятана и подведу итоги собственно начнем оклад о том или рассказ о том как и что мы делаем я всегда начинаю вот с такой вот достаточно большой картинке она большая непонятная в ней много всяких разных квадратиков прямоугольничков 5-6 систем много разных слоев данных понять практически ничего невозможно но ли возможно если приглядываться поэтому я и стараюсь разбирать по кусочкам с чего начинаем начинаем всегда с источников данных и их и способами которые помогают этим самым данным попасть в то место где мы с ними уже можно будет работать в нашем случае сейчас есть специально написанные сервис репликации в на стороне бэг-энда такси который помогает подключать различного рода источники переживает всевозможные катаклизмы есть лук брокер который аналог яндекса вы аналог кафки и соответственно через него протекают почти все логе которые есть что наступает с данными дальше дальше данные попадают в наш дату like обычно дата лайк это ходу ps3 например из аспаркам поверх него у нас это не так у нас есть инхаус аналог экосистемы ходу который называется уйти или ведь и в нем есть много из того что есть в экосистеме hadoop там есть например аналогич bass там есть аналог hive и наша команда прикрутила к нему спарка чем был доклад на хелди в москве в этой весной вот александр белоусов и соответственно здесь уже данные становятся доступными для аналитики аналитики могут что-то с ними делать большой кластер все казалось бы хорошо но не всегда достаточно поэтому за ним у нас находится green план на которой мы строим наш data warehouse green плат для тех кто не знает это такой вот ford под gresso из которого сообразили mtp базу данных которые иногда работает иногда работает хорошо и очень часто ломается вот например для dos версия 6 green club это просто какой-то от вот мы и как поставили начиная с 6 1 минута вниз 61 62 или 6 3 вот до 617 мы продолжаем страдать потому что находятся либо какие-то запросы либо какие-то нюансы которые не дают нам нормально жить вот даже сейчас я делаю доклад ребята у меня очень от очередной фака в грентленд за green club стоят соответственно же биосистемы в нашем случае это есть какие-то in-house решения коне них рассказывать не буду есть достаточно стандартные the table и есть то что может быть вызовет удивление это microsoft analytical services в которых мы делаем olap кубы и отдаём их на откуп менеджером почему это удобно несмотря на то что кажется такой достаточно странный стек для для того же яндекса потому что есть большой менеджерский состав менеджеры любит excel excel прекрасно работает с olap кубами менеджера сводная таблица под капотом какая-то чудо система где которая ворочает а миллиардами заказов и строят менеджеру нужны средства нужно метрик очень удобно и самое главное это позволяет не клепать очень много маленьких каких-то чертиков даже бортиков с нужными агрегатами под это все дело потому что предусмотреть и хотелки 500 человек очень тяжело вот это некое текущее состояние много сложно как мы к нему пришли с чего все начиналось проект по сути стартовал в шестнадцатом году я на него пришел в семнадцатом году то есть почти почти самого начала и могу рассказать в целом эволюцию того как что вообще происходило итак изначально такси и стартап внутри яндекс все хорошо есть несколько баз это в основном мозга аналитики в них ходят ну наверно них продакшен конечно но какие интересы ки все хорошо все работает питоне по грудь погрузил данный повертел работает а дальше москва платная парковка экспоненциальный рост заказов и и что случается backend масштабируется пока не запрещает себя насиловать какими-то непонятными выгрузка meat аналитиков и возникает вопрос а что делать как дальше работать было принято решение что соответственно нужно делать хранилище данных занимаются несколько дат инженеров они начинают страдать с тем что есть что есть ту понятную есть какой-нить облака там есть коменти virtualcz ubuntu крон питон скрипт и все поехали как это может выглядеть но для как это выглядело в нашем случае нашем случае это выглядело что вот у нас есть какие-то источники это в основном манга из них выгружаются сильным для нормализованные жирные такие документы которые обрабатываются питону преобразуются в некую уже плоскую структурированный типизированную структуру почему типизированные потому что вы войти есть понятие таблица и таблица войти может быть структурирована и типизированные это удобно дальше это такие промежуточные данные допустим это stay jing преобразуется мы определю сам витрины витрины для того чтобы поверх них работали отчеты быстро удобно перекачивается допустим прикрылась нужно чтобы аналитики это хаки побыстрее diary все вроде тоже хорошо работает в чем проблема ну т.е. по сути просто сказал в чем я ecли как это работает ну вот просто питания чей скрипт прилетели аргументы что там по делали внутри завершились все больше ничего нет в чем есть проблемы первая проблема в том что это у нас стартап активный рост и пока ты добавлял очередной источник к тебе аналитики прибежали попросили добавить еще 10 потому что им нужно они вот запустили этом 50 экспериментов на 40 им в принципе плевать а вот 10 надо отследить и дальше по помимо всего прочего backend тоже развивается нанимаются новые разработчики данные постоянно меняются хранилище манга меняется схема данных манга толстеет начинают думать этот эльф все сложно страшно и непонятно как жить что мы делаем мы вносим дополнительный слой в свое хранилище мы говорим что окей у нас был какой-то промежуточный 100 виджет который мы плод или сразу с источников пяточки нет давайте это мы назовем что это будет у нас уже некий operational дату 100 г д с а перед ним поставим слой с сырыми данными зачем затем чтобы не думать о структуре входного документа и тем самым как раз вот взять и защититься от всех возможных изменений которые могут быть в источнике то есть добавить новый источнику кей мы берем сваливаем это как-то и к себе в войти когда-нибудь потом делаем поверх этого ds аналитики уже могут работать серыми данных блага того что инструменты для этого есть потому что например аналог как раз к его достаточно хорошо работает в том числе с не структурированными данными все вот казалось бы есть снова какая-то архитектура которая немножко вице лена эволюционно развивается в ds мы начинаем уже задумываться о каких-то стандартах что раз мы делаем какую-то дополнительную работу она должна принести какую-то пользу пользу это например naming convention копеек первичные data quality так далее то есть уже что то более менее стандартное что с чем-то может упростить людям жизнь идет дальше помимо того что нужно абстрагироваться от изменений источников нужно быстро и обычно какими-то стандартными способами доносить данные о какой-нибудь таблиц и мы первое что сделали выделили несколько основных паттернов обновления этой таблице допустим это какой-нибудь snapshot это некий аналог absurd а когда мы обновляем по ключу это пример snapshot но не за всю таблицу не на весь период за какой-то кусочек то есть допустим у нас есть заказы они там двенадцатого года а мы хотим обновить не знаю там последние две недели этих заказов вот и начинаем задумываться о том что историю где-то неплохо бы хранить все вроде работает работает как это начинает выглядеть нас вдруг где-то в нашем этом питание чем скрипте возникает какая-то функция которая вдруг всем рассказывают где-то здесь где-то там внизу функции лот возникает функция snapshot которая говорит о том а что что происходит и и иногда можно эти иногда не очень можно найти потому что скрипт может быть большой что еще возникает у нас есть какая-та инфраструктура данных много пользователей много всем нужна надежность нужно соответствовать каким-то страшным требованиям сокс аудита потому что токсин начинает при генерировании быль что это означает это означает что для индекса вдруг какой-то непонятный стартап становится заметным большим и нужно чтобы его отчетность тоже соответствовал каким то нормам которые приняты вот сокс это про нормы которые предъявляются к компаниям которые торгуются на бирже принято опять-таки у нас что все должно переживать отказ одного из дата центров и много еще всего а у нас тут на коле ночные решение и что мы делаем в окей времени на нормальной нет давайте напишем просто несколько казачек для крона и придумаем какой-нибудь клеш то можно было обеспечить необходимые требования для аудита то есть в чем они основное требование оно какое это отрубить всем доступ на запись вроде то есть чтобы никто руками без какого-то набора регламентных действия летом сбор акков не мог внести никакую правка данный который находится на продакшн вот делаем получаем какой-то крон файлик опять-таки все вроде тоже работает какие проблемы у нас остаются основная логика это мой придется ли его допустим аналог в виде нашего вай kellys равно мапри deus медленно клик house что такое клик house сейчас в нем уже отчасти где-то починили join и но в то время когда мы все делали это семнадцатый год join и в как aussi когда ты хочешь поджоге две большие факторы и таблице не работают ну просто вот не может он так сделать и соответственно это боль тебе нужно делать либо таблицу на все случаи жизни не знаю там триста-четыреста полину это невозможно это поддерживать или или не использовать как раз вот еще данные зараза такая имеет свойство меняться глубоко в истории это тоже отвратительно потому что кликов еще начинаешь изображать какие-то транзакции например грузить в какао с целыми партициями и надеяться что ты вот дропа испортится вставляешь новую партицию значит он все будет хорошо когда у тебя вот весь запрос от бежит мы это больно поэтому мы принимаем такое страшное для нас на тот момент решения давайте попробуем green план мы пробуем гринд лам начинаем заливать в него о ds и делать уже витрины в нем что он получаем мы получаем то что большинство сложных расчетов на самом деле легко заталкиваются и работают green пламя мы получаем join и получаем транзакции и получаем хороший инструмент который позволяет ускорить разработку ok идем дальше казалось бы ну когда уже эти все проблемы кончится и никогда не кончится команда у нас растет у нас становится все больше источников данных данные разъезжаются как-то по микро сервисом появляются разные идентификатору одного и того же то есть просто вот полный хаос который только может произойти его нужно каким-то образом консолидировать и сводить вместе и успевать реагировать на все возможные изменения которые происходят что мы делаем мы принимаем для себя решение что во-первых нам нужна очередная новая архитектура нам нужна отдельная выделенная команда которая будет заниматься непосредственно инфраструктуры и данных но не заниматься решением конкретных продуктовых задач аналитиков которые просто некогда поток не заканчивается мы сегодня не кончился то есть задач всегда больше чем например людей которые пытаются сделать продуктовыми задачами я здесь имею ввиду сделать очередной отчет очередную витрину и стремимся уже каким-то взрослым таким концепциям начинаем стремится к датам аж например когда вот у нас есть дать понятие домена все данные мы на них нарезаем и приходим вот эта вот картинка с которую я начал что в ней получается нового относительно предыдущей то есть это на самом деле продолжающейся вот сыр он такой эволюция того что у нас была у нас появляется не только сырой слой но и еще история изменений практически по всем данным в сыром виде как где мы просто берем и говорим что вот у нас был rose life который был айдишник и просто документ а теперь у нас есть дата изменения и дисней документ удобно можем пересчитывать историю не теряя каких-то изменений это удобно до тех пор если вы это можете хранить потому что опять даже мы не все можем хранить дальше у нас появляется dts про то как он устроен внутри что то что это 6 нормальная форма был рассказ о жене ермакова нашего архитектора тоже на high ладеном этой весной совету тоже посмотреть потому что это интересное и самое главное она работает и соответственно витрины в 3 начинают строиться уже поверх д д с а с консолидацией взрослого dv х все казалось бы хорошо мы очертили некоторые границу систем что у нас есть дата лайк это войти у нас есть green плам это dr house у нас есть витрины которые мы иногда считаем но войти когда не особо тяжелые большинству мужчин читаешь time на грин план мы их экспортируем туда-обратно чтобы аналитик мог работать в любой среде которые ему комфортно потому что например него может быть клик стрим который мы не грузим в green план может быть найти и с ним тоже нужно поджарить какую-нибудь рынку поэтому делаем обратный экспорт и соответственно reporting работает только из green плавал что о чем мы тоже начинаем думать в этот момент мы начинаем думать о том что у нас есть много разработчиков и их работу нужно стремиться постоянно улучшать все разработчики что делают они на самом деле пишут некоторые тоски процессы которые условно делают из одних табличек другие табличке мы начинаем задумываться об этом дизайне и для себя принимаем несколько основных вещи и одна из них может быть даже основная вещь это то что тоски должны быть и попатенко чемодан патентные по-особенному почему по особому потому что я в этом не сказал ранее но у нас не классическое хранилища у нас постоянной микро бачка тебе каждую минуту что-то где-то обновляется просто вот постоянно данные обновляются поэтому определение дым патента стелла сама такое своеобразное то есть мы говорим что мы считаем что тоски дым патентный если вдруг случится такая веселая ситуация что он два раза запустится на одних и тех же данных она такая ситуация на самом деле никогда не случается или почти никогда не случается ну и проблем томске не создают потому что они написаны таким образом что они не могут например породить дубли или не знаю создать какую-то дырку в данных то есть они гарантированно делают определенную семантику обновления целевой таблицы ничего не ломаю мы их ретро им за счет этого это удобно соответственно сантос мы тоже немножко вестербо него явно кусочки говорим что у нас есть какие-то стандартные вещи это из разряда способ прогрузки в целевую табличку способ того как нужно выбрать не знаю этом данные из какого источника или из просто таблицы которые каким-то образом особому секционирование или у нас есть например наш ds слой который нормализована до 6 нормальной формой там бы хочется что из кода генерить потому что к нему ручками писать select и у на самом деле невозможно вот и формулируем некие задачи которые ставятся перед нашей платформы в чем они заключаются в том что ли основная цель вообще в принципе в том что дата инженер должен тратить основную часть своего рабочего времени на то что бы писать логику изменения данных нет логику того как правильно и эффективно образом очередной инкремент погрузить или как правильно его вычистить откуда-нибудь а именно логику преобразование данных и начинаем строить свою платформу вокруг этого это скорее не платформу свой фреймворк вокруг этого утверждения и собственно приходим к фаре уборку что здесь возникает да то есть когда мы говорим о том что у нас есть какие-то эти процессы возникают какие-то стандартные инструменты которыми все пользуются допустим р flow луиджи ли там что-нибудь еще страшный языка системы ходу как узи или что нибудь такое на xml как в чем мы видим у них некоторую недостаток они не раскрывают семантику происходящего то есть такие у нас есть какой-то до кверху окей у нас есть 1000 дагов дыры flow у клей у нас есть пример 2000 дагов airflow что там происходит внутри них нужны какие-то соглашения так или иначе чтобы разработчики результаты инженеры могли понимать переиспользовать fix баги в чужих например flow то есть как принято вообще вы разработчик и мы подошли к фреймворка не стоит страничного нужно какую-то инфраструктуру под него переизобрести а того что нам нужен некий выразительный способ описания того что у нас делается и мы начали его писать а что там под капотом на самом деле не очень важно соответственно какая у нас абстракции что вот есть тасс у него что-то на вход на выход вот первый важным здесь момент что чаще всего выход на самом деле один почему потому что так проще тяжело когда у тебя вот такой вот расчетам огромные вот так вот так вот так и он еще генерит с десяток таких таблиц и потому что вносить правки в такое обычно не неприятный неудобно поэтому выход один это не знаешь что у нас запрещено делать много выходов это значит что платформа нацеленное framework нацелен на то что выход у какого-то task должен быть один что мы какие задачи соответственно должен решать task рассказывать о семантике или в нашем случае это заключается том что рассказывает о том как происходит обновление целевой таблицы отвечает кто у него на входе кто у него на выходе потому что хочется например видеть дату lineage хочется его запускать запускать при этом не как-то сложно за тепло и куда-нибудь а просто вот взять и не знаю кликнуть к нам на кнопочку в пач армии вот чтобы он запустился и посмотреть упадет или не упадет и собственно иногда хочется это объединять графы но всех всякие стандартные какие требования чего мы начинаем на самом деле мы вот часть соглашения по структуре кода это было одно из первых вещей которые мы только приняли что кот повторяет структуру хранения это удобно это позволяет появляется такая вот нативная навигация ты знаешь либо где данную тебя лежат либо ты знаешь какой крутых делает тем самым понимаешь где данные что здесь у нас есть соответственно у нас есть название сервиса я сразу скажу что у нас не какое-то вот монолитное до верха которая целиком и полностью deep ловится а много много много небольших сервисов которые работают и в которых живет кусочек ваты 2-х и соответственно здесь есть в структуре кода дальше есть слой слой это соответственно по сути степень преобразования данных это вот эти наши road sdd с витрины домен домен соответственно описывает то собственно к чему данной относится допустим это в случае источника название источника в случае например витрина им название обычно потребителя данных допущено финансы какие-нибудь идем дальше и соответственно каждая таблица живет за счет каждом лиц свои папочки почему в своей папочки потому что на самом деле расчет это редко когда один файлик только если он так не совсем тривиальный там же допустим у вас есть какой-нибудь иск мельник он хочет отдельный свой файлик чтобы там красивый синтаксис был у вас есть task на питоне которые его знают как правильно там отформатировать или еще что нибудь с ним сделать у вас есть описание таблицы потому что мы мы прописываем таблицы в коде сразу их там документируем я это покажу и еще кучи каких-то вспомогательных вещей вокруг этого тоска то есть допустим это в нашем случае это некие рецепты которые нужны для его разработки позволяющие воспроизвести все необходимые в некой песочнице это проверки на data quality и намного все коту другого что мы получаем в итоге в нашем фреймворке мы получаем некий пятнами через эльфик не шибко сложный я надеюсь по крайней меньших и сложный в котором есть по сути 2 абстракции 1 абстракция которым мы может быть не очень удачно назвали source и это на самом деле чтение данных откуда-то плюс трансформациям то есть мы взяли и объединили два момента и получаем как бы источник данных для тоска которые определенным образом обновляет целевую табличку ну допустим как здесь вот snapshot который берет ее полностью как затирает и вставляет на ее место новые данные дальше понятно там субсчет с ним все просто почти ничего нет бывают понятно чуть посложнее что значит посложнее ну во-первых сложный расчет значит сколько-то табличек на вход и вот мы их описываем сколько табличек на выходе 0 нашем случае одна табличка мы тоже здесь это никак не хардкоре мамы параметре зa им например запрос как вот было в снапчате то есть все давайте я вернусь чуть чуть назад вот здесь вот было что мы выбираем данные из какой-то там таблицы который туда подставляется это помогает делать touring например для разработки и тестирования и вот здесь мы соответственно тоже это все делаем мы получаем некий статический анализ что мы можем построить lineage от источника до конечного от чего-то или витрины потому что нет все видим но с этим возникают некоторые страдания потому что например параметр расчета мы тоже начинаем описывать с помощью своего dice или чтобы не было такой необходимости строгой когда ты хочешь просто получить входы-выходы что тебе нужны ещё какие-то параметры подставить на стуле нгу непонятно какие параметры нужно вставлять чтобы он правильно я тебе вход и выход это поэтому параметра без описываются статический и по сути вычисляются лениво уже в мы только в момент выполнения тоска но не в тот момент когда мы начинаем загружать например питания модуль дальше соответственно тасс имеет определенную семантику работает с любым источником к вы просто нужно прям случае green плавно вернет ему некую временную табличку с данными который по структуре свои совпадают с выходной ими все вот оно работает тоже это вполне себе реальные примеры когда от озк считается например нас нам на основании 3 табличек без и skillet просто 1020 . безус келим вардов допустим окей это spain а вот у нас есть парк spark выглядит по-другому ему на пресс парка сквер не пишем мы пишем spark ps парк на task остается таким же вот он один в один остаются такими же как при этом выглядит сам расчет на спарке мы просто делаем некую обертку что вот есть питание отчаявшимся она принимает dataframe и на вход и выдает dataframe соответственно что именно за dataframe и к ним прилетают на вход анонсируется в декораторы где мы просто используем те же самые классы определения таблиц я до них еще пойду покажу как это выглядит и все и разработчик соответственно задекорировала запускает к нему признают уже готовые dataframe и dataframe и как то там с собой join its группируется считаются все у нас нас соответственно the flame in a вход dataframe на выход выглядит примерно так же как эскель при желании можно вынести логику spark джаббы в отдельный файлик написать на нее например там тесты и все вот все готово соответственно что мы из этого всего получили плюсы что у нас единая структура которая форсит использование только себя и больше ничего куча тестов на это все дело а минусы на самом деле главный минус в том что это достаточно дорогая разработка и требуется время у дата инженеров на то чтобы разобраться в том что собственно а что же у нас происходит как все работает это вот такие важные ограничения или минусы которые я вижу то есть с моей точки зрения адекватно такое начинать только если у вас большая команда потому что иначе такие вложения вряд ли я купить идем дальше так вот все время показывал ссылочки на таблице а вот как это выглядит нас несколько систем несколько систем у нас было по сути самого начала сначала просто был войти и crack house сейчас это войти green план на самом деле тоже при krause есть описание таблиц выглядит выглядит для всех одинаково то есть это декларация carrot который похоже на какой-то стандартный or в котором есть класс таблицы документация к нему каждое поле какие-нибудь специальные атрибуты которые описывают на самом деле где это таблица будет находиться в какой схеме или по какому пути войти она будет лежать войти считаете вы живы вожди фск какой вот пусть будет к тому месту где лежит табличкой это все декларируется описывается прорастает в документацию потому что на code review условно если ты не написал комментарий к тому что ты сделал тебя заворачивают этот такой получается очень хороший контроль расчет не расчет без документации данные не данные без документации идем дальше первое тоже важная фича это создание dv среды окей я написал весь тоски я хочу его запустить как мне его запустить если данные где-то там на пруд кластеры у нас есть инструмент который позволяет например домашний папочки или на тестовом green пламя воссоздать такую вот песочницу в которой будет все что нужно для разработки конкретного тоска и вот этот сценарий разработки мы описываю специальном файлики где опрос прописываются какие данные за какой период с какими особенностями нужны случае с green планом это работает через backup таблицы продавал рекламы и бы копируются в ис-3 ис-3 на как не накатываются соответственно джеффри на тест класть случае войти это 7 линки или копии данных внутри самого большого к очень кластеров войти чаще всего это 7 линки прекрасная возможность которая просто льда и даже копирования самом деле работает очень быстро потому что операции над метаданными дальше чтобы это все работало вместе определялись как аргументы автоматически schedule велось в нужное время и так далее есть специальные мета базы вот в этой специальной базы это базе которая здесь называется ситель есть 2 основных сущности это последнее загруженное business data в таблицу и дата синхронизации то есть когда именно эта таблица был обновлен а потому что не для каждых не до всех данных есть некая business data которая при что ты их описывает их по сути свежесть есть так можно сказать вот и как выглядит на самом деле код любого тоска на самом деле тут не знаю насколько хорошо видно но смысл в том что каждый тасс внутри себя имеет некоторую логику которая знает о собственно может вернуть последнюю загруженную бизнес дату и и либо нужно вставить вот базовых либо не нужно вставлять если она почему-то не больше чем то что уже там было потому что данным движется исключительно у нас вперед если ты хочешь сделать интро исторический пересчет это не эффект это текущий процесс и же не должны комплекте noise дату синхронизации обновляем всегда дальше понятно у нас появились какие-то параметры мы на них подвязываем scheduling наших джебов каким образом мы говорим что вот у нас есть одна дата допустим мы хотим запускаться если вдруг мы отстали этой даты от реального времени на какой-то промежуток времени она определенно на пять на десять минут или нам наоборот приехали например новые 5 10 15 20 минут свежих данных или у нас есть какие-то готовы уже на это дело триггеры или их комбинации ну допустим несколько примеров того что можно таким образом описать то есть допустим мы хотим запускайте таблицу в которой приехал новый час данных выпишем что вот этот расчет запуская когда в такую таблицу таблицы ты приехал новый час данных или когда эта таблица не обновлялась последний час данными или когда в например первую таблицу допустим таблицу фактов с каким транзакциями приехал новый день целиком и справочник обновился уже сегодня значит можно запускать расчет какой-то витрин такие вот достаточно простые триггеры которые закрывают почти все на самом деле кейс который существует для чего еще эти даты используется ну естественно для из lf который выпишется задаются прямо на таблицу то есть поговорим что окей вот есть такие-то даты есть такие ты стоишь таблица например должна обновляться каждый какой-то определенный промежуток времени или данные не должны отставать от реального времени также видеть task-ов у нас есть проверки data quality которые тоже самом деле принимают просто некий source который может быть паркам и скверам неважно смысл которого вернуть какой-то прочитанный агрегат по которому бетонщики можно будет выдать внести решение например а это ошибка или это нормально выдается наносится решение если ошибка то соответственно и тори портятся в кучу разных мест которые настраиваются прямо здесь же так и офлайн проверки качества ну и последний кусок фреймворка это миграции соответственно миграция это тоже такая рутинная операция который постоянно есть постоянно нужно добавлять новые колонки удалять колонки пересчитывать и так далее и тому подобное окей мы делаем некий denzel который в себе инкапсулирует какие-то сложности которые с этим есть как я уже говорил на сми краба чем то есть процесс работают постоянно и соответственно нужно постоянно отключить с текущего расписания то что то пересчитываю или мигрирует потом не забыть включить и так далее и тому подобное это на самом деле много рутинных операций а если еще вспомнить что у нас любая операция с данными на прозе требует согласование это как бы хочется их уменьшить это количество этих согласований поэтому описывается сценарий его можно от review ить отладить и уже запустить один раз пользу что момент работу и что вам получаем мы получаем некоторые итоги которые у меня получилось вынести и которые я надеюсь будут в кому-нибудь полезны 1 номер 1 нам важный вывод это то что любая структура любая архитектура даже если эта архитектура данных под может подвергаться ри факторы расширению допиливание и так далее не нужно этого бояться можно делать хорошо если получилось подумать о расширении заранее но не страшно если это не получилось потому что если вы этого не делаете то на вам с комом катятся какой-то жуткий технический долг он постоянно будет нарастать ну и соответственно на второй главный выбор вывод который есть это то что да ты инженер должен тратить свое время на что-то осознанно и осознанно это логика к с помощью которой он превращает какие-то разные данные в нечто такое чем пользуются реальные люди менеджеры аналитики или эмали инженеры вот нужно делать все чтобы упростить ему жизнь поэтому меня наверное все спасибо за внимание владимир спасибо сейчас перейдем к секции вопросов я сначала напомнил коротенько правило за лучший вопрос у нас полагается подарок по мнению владимира поэтому запоминай кто тебе понравился для слушателей из онлайна у нас также это правило действует поэтому а не стесняйтесь задавайте вопросы у вас есть специальная кнопка выйти в эфир кажется так называется ну и сушите зале просто поднимаете руку и мы вас будем приглашать рассказать ну точнее будем давать он просто микрофон добрый день спасибо за доклад у меня такой вопрос этот фреймворк он открыт и где-то его самому потрогать можно к сожалению нет там был где-то слайд на котором ставил такой вопросик а что можно ли его выложить ваккун source на самом деле сам фреймворк при некотором усилии с нашей страны выложить можно но это нужно приложить много усилий чтобы его почесать какой-то вид в котором его можно выложить в концерт потому что сейчас мы на самом деле с ростом количества людей которым пользуемся им пользуется сам немножко тонем в поддержке просто во внутренней поддержки спасибо здравствуйте я остался тут не просто лепит немного мне интересно как обеспечивается контроль качества на то есть приходят менеджеры данные не те данные собираются из кучи разных таблиц как профилировать как найти место которое не так трансформирует данные или не так и записывать как хотелось бы конечному потребителю этих данных ну наверно у нас самая простая рекомендация это обвешать в чем основная проблема в том что у тебя все может работать и не падать а исходные данные каким-то образом поменялись то есть не поменялось ли схема поменялось именно логика того как они формируются и становятся все неправильно и вот чтобы это контролировать мы по сути и написали свои дата чеки смысл которых проверять определенные бизнесовые инварианты что логике не противоречит здравому смыслу и соответственно если какой-то pipeline важный там и вот всячески рекомендую даты инженером обвешивать основные его шаги проверкой каких-то инвариантов чтобы данный не нарушали здравый смысл вот правда точики кто выдвигает требование к этим датчиком конечные пользователи или до инженер данных должен их прийти и другие на самом деле те и другие потому что если пользователи это аналитик он может очень хорошо ну допустим строится как инцеси аналитик имеет представление о том как в принципе в реальный мир устроен и понимает какие там инварианты должны быть соблюдать какие-то отношения там длительность или еще что-нибудь и тогда вода является автором требовать а иногда какие-то вещи они придут от даты инженеры что вот в этом поле на лане должно быть еще маленький вопрос и правильно понимаю что процесс не пора ли лица то есть нельзя одно тоску запустить проверено нескольких надо чтобы ускорить процесс перегонки данных из 1-го источников цель под таски таски это не у нас не классически только либо достали что-то начинаем в процессе ти положили куда-то а это по сути какая-то кода генерал к для того же спарка или того же green плава где появляется из пильник который где-то там выполняется весь ответ на параллельность это вот на утку 5 системы которые выполняют спасибо здравствуйте вопрос опять про фильм work вот вы сказали что основная фишка в том что вот можно писать код на фреймворке а потом в качестве бэг-энда использовать там луиджи airflow ли может быть индекс нирвану а вот но в реальности становится ли слишком сложно писать от в таком общем виде что вот он хорошо будет исполняться на всех этих там разных брендов я думаю в реальности может так получиться что вы думаете что вы можете в любой момент перейти на другой фреймворк на самом деле вы завязались какие-то конкретные особенности реализации чего-то там в ж-л флауи будет сложно на самом деле заскочить так может ну тогда и нет смысла в таком приборке вот какой то проблему решили наверное это не основная проблема которую мы решали это просто дай свечей которая у нас появилось сейчас вот у нас под капотом используется луиджи и вот условно луиджи это не знаю может быть пять сотен из строчек кода то есть это просто teka трансформация декларации тоска в classic луиджи или там несколько классов луиджи которые друг с другом как-то связано которые можно отдать на откуп слова луиджи но вот и рофла уж совсем по-другому допустим устроен архитектуру мы не как вы ведь и то и другое могут запустить питон ну да ладно и вот еще один вопрос от вас история чисто пропитаны ли вы умеете там как-то позволяет людям писать и на джаве скале других языках spark мы сделали специальную обвязку чтобы людям было удобнее писать юдаев кино джаве почему на джаве потому что скалы в яндексе не существует как язык нельзя хорошо хоть и ковать даже не существует владимировича стакан здрасте такой вопрос у вас устроен вот именно pipeline разработки то есть вам приходит уже pull request стас com или вам приходит какой-то т.з. там дальше соответственно вы там что-то его делаете или просто поправить review и пестики соответственно дальше вы же его на веру как в деплоить и у вас надо там чтобы одни тоски зависели от других чтобы там в первые не выехали да вот после вторых или перед старыми чтобы вот разрешаем конфликты f я понял вопрос наверное нас происходит все что вы писали в вопросе потому что ну во первых у нас есть разделение что вот есть команда которая отвечает за фреймворка есть продуктовой команды которая собственно реализует конкретную вещь соответственно каждая продуктовая команда она делает pull request икеа нас себя review it она выкатывает какой-то кусочек кода который делают именно ее объекты таблиц если есть аналитик который готов немножко погрузиться во всю эту кухню и тоже написать какой-то из приемник запустить его то окей у него тоже есть на это все возможности или например по контроля рабочих можешь добавить репликацию или тоже тоже для себя на самом деле на поверх данных для в хаос читать какие-то вещи это тоже виде пол request понятно когда приходит человек в первую очередь он приходит к нам в help чат мы помогаем консультируем там сдаем нужные ссылочки спрашиваем раз сценарии так далее все дальше стандартный процесс написания кода локальный запуск отладка выкатка в testing выкатка впрок про зависимости что нужно понятного есть во первых про зависимости task of a task of мы стремимся к тому чтобы тоски зависели на самом деле отдано то есть потому что тоску нужно на вход не другой тоска ему нужны какие-то данные которые посчитала этот самый другой dos другой тасс поэтому зависимости они по данным и вот вся реактивности на выполнение которое нас есть она строится именно на вот параметрах таблицы вот что сейчас какие данные если входной таблицы и те и так вот рвется вот это вот границы что допустим одна команда пишет расчет 1 таблица вторых другая команда пишется расчет другой таблице они не связаны между собой жесткий pipeline на нем подвязываются друг друга через данные не знаю получилось меня ответить да ну то есть я спрашивала крафт как и заполняет так чтобы вот его заполнив в нужном порядке всегда когда много людей когда много люди камала понятно ну вот у нас построено все на то что есть зависимости на данные и как раз ты понимаешь что вот твой расчет ему не очень важно кто данный готовит важно что он пирату а приехала вчера туда приехал час или что-то еще лида обновилась от табличка до относительно недавно владимир спасибо за доклад снова влево надо посмотреть влево от влево королева меня вела бы я вижу руку ну нормально пойдет пойдет смотрите как бы вы рассказали прям действительно большая работа была проделана и вы сами сказали что это прямо дорого и много всего а вы не рассматривали вот окон собственное решение из них же можно собрать что-то похожее там где 5 играет expiration арго daxter все вот это вот чтобы из этого сделать готовые ну относительно готовое решение там напильника пришлось бы поработать но просто мне кажется на порядок было бы меньше своих каких-то телодвижений в чем критическая как бы особенность вашей системы что вы прям сели писать все с нуля вот можете канале нас в один момент так попробую на самом деле первый момент что когда мы начинали у нас с того что было уже хорошо на сухой это семнадцатый год это airflow edge то есть это сейчас есть например мета flow от netflix где тоже есть красивые to those очки есть daxter и они все уже прошли какие то хоть об этом не знаю год-другой что она за релизе лассе работает вот каких многие инструменты они на самом деле облачен и а нам это просто в принципе не подходит в случае airflow нас изначально например могу просто рассказать про и flow потому что его больше ресеч и вот на момент когда мы принимали решение у нас было какой потому работа это очень много микро бачей то есть это реально 1000 процессов которые могут стартовать каждую минуту в этом каждый несколько минут на каждую минуту на бирме цену и в случае r flow это получалось какое-то большое количество дагов которые ему нужно создавать часто а вот из серии весе реальный опыт на тот момент который и в чем back power flow который могли получить говорил о том что альфа очень любит крошиться он таких вот паттернах своего использования и и мы по такому пути не пошли и второй момент это secu шиндо и соответственно такой некой вот так вот временная течка что я например считаю сегодня считаю завтра ли там считаю час друг друга и следующие так далее а у нас как бы время но непрерывное то есть у нас большинство to suck они привыкли к тому что они могут вот прямо сейчас посчитаться не знаю с 20 00 по 2353 следующий расчет скажет почитается с 20 не знают 350 до не знаю 4 и вот такие паттерн и закона запихивать в airflow была по крайней мере тогда точно не очень очень неудобно сейчас есть честно не знаю потому что многие фичи появились особенно в третьем air flow если правильно помню версию которые возможно бы изменили наше вернем представления до чего-то вопрос еще вопрос надо однако происходит управление ресурсами бар на той схеме это на водку в конечном систему тоже или как-то вставки можно задекларировать в описании что бы ватности соблюдалась как тот порой не ресурсами ресурсы хороший вопрос самом деле у нас здесь есть много того что нужно делать потому что случайно при войти по сути ресурсные управления отдается на его счет то есть нас заведены проекта говорить про абстракцию это несколько вычислительных полов которые разделены по нагрузке то есть пул для процессов которые считают маленькие им клементе кино часто а есть пул для каких-то тяжелых задач которые запускаются достаточно редко и соответственно в томске просто говорится о том где ему нужно запускать в рекламе на самом деле сделано так же то есть там ресурсная группа для запросов полегче ресурсной группа для запросов пожирнее в экране разные лимит и соответственно по ресурсам которые там доступны вот чего не хватает это честный например какой то приоритизации троттлинга того же green плава потому что сейчас у нас периодически может складываться от того что не вас пришло слишком много запросов слишком много коннектов и так далее и это то что вот мы их планируем активно начать делать или переиспользовать напрячь тут готовы из того же лучше у нас уже времени совсем почти не остается остался наверно время только на один буквально вопросы и вода владимир спасибо за доклад а вот извините я из слайдов не понял как у вас данный оказывается в до товаре хауса то есть вот непонятно как делать именно извлечение данных отслеживания изменений как они оказываются в data were house и я ищу на слайдах не увидел ни где очередей на которой можно было бы честью просто но себе реплицировать нужные данные они были в самом-самом начале самом начале работы у вас до данные через очереди качаются и они именно так и вы не знаете ничего про исходную структуру данных которых базах и знаем и не знаем разные случаи просто источников десятки или даже сотни то есть все по разному бывает стараюсь ответить быстрого то есть сервис репликации на самом деле такая вот штуковина которая умеет условно вычитывать инкремента из каких-то известных ей источников чаще часто это нечестный сидиси я просто запросы допустим mackenzie мы договорились что люди создают таблички пустим вот грести с дата и обновления каждой строки которое заполняется для любых изменений мы просто учитываемого дельту которая изменилась за последний какой промежуток времени очень простой поттер который работает в 90 процентах случаев когда есть проблема когда есть удаление и не получается договориться на флажке удаления не-физическом удаления или когда люди начинают делать в базе каким брин длинные транзакции тоже плохой поттер есть сидиси инструмента внутри яндекс они и есть логе это льётся через луг брокер который по сути кафка точнее который аналог кафки просто индекса вы это честная такая очередь все спасибо"
}