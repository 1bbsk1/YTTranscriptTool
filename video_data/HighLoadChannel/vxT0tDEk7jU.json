{
  "video_id": "vxT0tDEk7jU",
  "channel": "HighLoadChannel",
  "title": "Подводные камни высокодоступных инсталляций OLTP СУБД / Андрей Бородин, Дмитрий Смаль (Yandex.Cloud)",
  "views": 1682,
  "duration": 2257,
  "published": "2021-10-04T02:37:55-07:00",
  "text": "мы с дмитрием делаем менеджер services for под газ по мы mais quel также у нас есть там управляемая манга управляемый microsoft сиквел сервер много разных управляемых баз данных которые все вместе называются индекс клауд да это платформ и отнимется таким наиболее интересных отличий управляемых база в яндекс клауд является то что самым крупным пользователям этих баз данных являются сервисы яндекса и так получается что например сейчас в базах данных индекс почте которых живет в управляемом под гости уже что-то около петабайтов данных и что-то около миллиона запросов в секунду влетает в эти базы данных поэтому нам нужно чтобы с точностью до байта все работала надежно все работало эффективной все работало корректно кроме того у нас достаточно большие инсталляции сейчас маски или например яндекс директа какой-то значимой частью своих данных живет в маске или всего в управляемом москве ли у нас сейчас около 400 терабайт данных под нагрузкой этот доклад планировался в девятнадцатом году и пока было пандемия я успел рассказать значимую часть этого доклада прогресс поэтому часть про подогрев будет максимально сжатый и если вас какие то моменты интересует более развернуто то я после доклада обязательно на все вопросы отвечу в деталях сейчас я просто упомяну основные камни чтобы перечислить их и в основном доклад будет посвящен вопросам маски ели что нам нужно что мы хотим от облачной базы данных мы целимся в четыре девятки доступности на чтения в месяц и три с половиной девятки доступности на запись нам нужно моста масштабируемость база данных которые растянутого несколько дата-центров и нам хочется иметь копию базы данных в аналитической системе вот примерно и вот в общих чертах все что нам нужно в это сервер из таких серверов мы делаем базы данных тут может сломаться ну может посыпаться диск может сломаться память может выйти из строя прос с материнской платой может пойти что-то не так вот этот этот центр ну тут может закончиться электричество кабель кабель может быть перекопан трактором метеорит на него может упасть мы работаем с вещами которые сделаны людьми эти вещи ломаются и мы должны быть этим к этому готовы но есть и более интересные виды отказов например вот у нас виртольд гипервизор в котором виртуализованных несколько виртуальных машин и какая-то виртуальная машина вдруг ей нужно значительно больше ресурсов чем раньше это тоже своего рода отказ это от отказ возможности предоставить необходимые ресурсы и стандартный способ решения таких неожиданностей эта избыточность в ренан дэнси поставить оборудование которое готово к тому чтобы как как-то предотвратить проблемы связанные с выходом из строя чего-то ну например вы знаете у самолета обычно несколько турбин если одна турбина не летит то можно на на оставшийся долететь дальше и вот эта идея того что у вас есть больше железо чем нужно на всякий случай она в технике достаточно распространена и она используется для построения высоко доступного кластер а вот типичная топология под грешного кластер а когда у нас есть какая-то пишут какой-то пишущий узел праймари обычно мы его называем или лидеры про рипли кации с него идет поток логической репликации в аналитическую систему с ними с него идет архивация райт их и blocked для point in time рекавери и в него приходит пишущие запросы также у нас есть некоторая кворум на я репликация на бинарные копии базы данных которые могут выполнять читающие запросы какие же проблемы могут возникнуть с таким кластером самая первая проблема что в этом кластере надо вообще куда-то пойти нужно где-то выполнить пишущий запрос ну в случае позарез а все довольно просто используется стандартная технология которая называется также цешина торс когда вы в строке соединения указывайте несколько хостов и указывайте желаемый уровень соединения то есть говорить я буду выполнять пишущие запрос или я не буду выполнять пишущие запросы и в этой схеме все работает хорошо пока не приходит смена мастера пока не приходит failover тогда вам нужно как-то понять что запрос больше не выполняется и самым первым таким критичным камнем подводным в случае управляемого пуск вообще отказ высоко доступного полоса становится корректная настройка таймаутов потому что ты молод это тот способ понять клиенту что его нужно идти в какое-то новое место если вы используете кластер с автоматическим файла миром то обязательно проверьте 10 утра тайм-аут и настройки сетевых тепла и вов потому что это основной способ получить ошибку о том что что-то пошло не так с кластером который с узлом кластера который не доступен по сети чтение с данных с со стенда с реплики тоже имеет набор проблем самая первая проблема с которой чаще всего сталкиваются если ваш балансировщик умеет переносить нагрузку то есть одна реплика упала нагрузку перешла на другую веб лику это потенциальный каскадный отказ который нужно планировать то есть если нагрузку в состоянии пристрелить одну реплику нужно не дать ей поставить весь кластер следующая проблема чтения со стенда я состоит в том что стендбай по архитектуре своей может показывать не консистентные данные то есть либо данные из прошлого что является тривиальной ситуации накопился какой-то лак но на асинхронной реплики либо данные из будущего то есть когда вы комитете транзакцию на праймари вы значит берете локи на данные отправляете logo репликации получаете подтверждение что репликация дошла на праймари эти данные еще не видны они подлодками она стенда и вы их уже можете наблюдать они как бы могут немножко забегать вперед хоть и на незначительные промежутки времени ну и следующая проблема со стенда им это конфликт репликации поскольку стенда является копией праймари если вы выполняете долгие запрос на реплики она должна либо отставать в репликации то есть на ней должен либо накопиться лак либо она не может вам выпал позволит выполнять длительные запросы но это общее свойство которое характерно для oltp систем вне зависимости от того логической или физической у вас репликации эту проблему как-то нужно решать ну и есть какие-то алгоритмические проблемы ну то есть например сейчас не очень хорошо до 14 пресса не очень хорошо работает snapshot пол получения консистентной snapshot of подгрести если у вас комбинация длинных транзакций и коротких транзакций и направим 1st нба я иногда возможно ситуации повышенного потребления центрального процессора и там и там условно на ровном месте но мы над этим работаем интересные проблемы возникают в связи с возможностью отменить выполняющийся запрос в высоко доступном кластере базовая гарантия которая предоставляется нам синхронной или кого ровная репликацией если клиент выполняет запрос мы не подтверждаем запрос пока результат этого запроса не доехал до некоторого кворума реплик то есть мы предоставляем гарантию что клиент не получит подтверждение вроде звучит просто но существуют способы это гарантию нарушить самый простой способ это отправить запрос в момент файла вера клиент отправляет пишущий запрос в этот момент происходит потеря связности праймари со всеми репликами он ждет какое-то время отправляет отмену запроса и локально снимаются локи сейчас в прогрессе как бы данные становятся видимыми из той подсети которая видит старой праймари аналогичного эффекта можно добиться и перезапуском с gresso это эквивалент быстрой отмены всех запросов либо просто крышам внутри одного из бэг-энда который тоже поведет крыши рекавери и быстро и отмене всех запросов мы работаем над тем чтобы эту проблему устранить обсуждаемые с обществом вот есть патч если вы хотите привить какой-нибудь почту приходите на коммент fest прогресса и он достаточно простой позволяет предотвратить проблемы отмены запросов в возвысим но проблема с возможностью рестарта сервера все равно остается это проблема обсуждалась также на по вековым конферанс может быть и в этом году мы снова про нее поговорим хотя уже год прошел а почищу не закончен проблема которые возникают в захвате изменений то есть ваша аналитическая система подписывается на логическую репликацию и получает новости с кластером сейчас погрейся логическая репликация возможно только с праймари ноты и ноты не могут отправлять логический поток в аналитическую систему и это отчасти проблема но самая главная проблема состоит в том что высоко доступном кластере праймари нота может гулять по любому переходить на любую из узлов перезапустить логическую репликацию можно только с точки на который узел находится сейчас если в кластер происходит failover аналитическая система приходит чуть-чуть с небольшим опозданием на этот узел на новой праймари узел пишущий запросы она может опоздать и не успеть начать streaming репликации с того же места где произошел failover это приводит к необходимости перри синхронизацией каких-то там терабайтов данных заново потому что продолжить с того же места не получается чтобы решить эту проблему мы создали расширение g dm aux странно его так называли но просто у вас был тогда трансфер менеджер теперь это data transfer менеджер которого мы сделали расширение которое позволяет создавать слот логической репликации в прошлом вот но мы надеемся что нам ближе к 15 вам позарез удастся этого почините в обстреле не только создание и сделать создание слота при помощи расширения ну и самая такая критичная проблема сейчас как мне кажется в логической репликации в аналитические системы состоит в том что логическая репликация аналитические системы может быть немножко впереди физические репликации отказоустойчивого кластера мы пока не придумали хорошее решение как правильно затормозить логическую репликацию чтобы она не получала данные из будущего которые приходится перри синхронизировать ну путем полной передачи всей таблице если у вас есть хорошая идея топ пожалуйста мне об этом сообщаете ну а на этом спас гре сам все я передаю слово дмитрию он расскажет про маски ель спасибо так я хотел бы начать немножко с того чего мы вообще хотим достичь когда запускаем файл ability базу каких какой модели consistent насти мы придерживаемся по сути мы хотим чтобы high visibility база работала точно также как обычная база на одной ноте которая просто не падает никогда для пользователя это означает следующее он должен иметь возможность прочитать данные которой он записал то есть если пользователь сделал транзакцию сделал комит и база ответила ok эти данные не должны быть никогда потеряны то есть пользователь всегда может их прочитать немножко нетривиальный момент если база не ответила окей это ничего не значит данные как могут быть записаны так и могут быть потеряны то есть тут ничего нет как этого достичь если у нас есть кластере зова ный майский для этого нужно использовать синхронную либо коварную репликацию чтобы мы знали что наши данные лежат как минимум на двух нотах и плюс к этому нужно соответственно читать и писать данные только с мастера по поводу чтения с реплик да конечно можно читать с реплик но клиент должен понимать что он делает если реплика отстает на час то чтение с нее это своего рода потеря данных то есть вы читаете эти данные которые записали но их на реплики еще нет окей если читаем и пишем только с мастера то все должно быть нормально немного о том как устроена синхронная репликация в москве в москве есть два logo грубо говоря есть bine релог который используется для репликации и есть ряду log если говорить про in baby тут который используется для крыш recovery движка а как выглядит процесс коммита транзакции которые готовы закомитить данные они собираются в группу и пишут данные с начала войны релог а потом соответственно к месяца все движки хранения в мае съели есть специальный плагин называется 7 sing плагин он вставляет хук между записью в белок и коми там собственно говоря движка и он ожидает того момента пока данный записанный в баннер в bine релог будут переданы по сети записаны на реплики не применены а просто записаны на диск соответственно клиент получает ответ окей только после того как данные записаны на одну из реплик здесь написано синхронная репликация на самом деле это настраивается вот для тех кто хочет попробовать настройку здесь проведены субтитры что нужно написать на мастере на реплики чтобы они стали синхронными из интересных настроек здесь следует отметить две во-первых мастер тайм-аут по дефолту плагин умеет откатываться на а синхронную репликацию то есть если он долго долго не получает ответа от реплики репликация перестает быть синхронный этот тайм аут нужно выкрутить в максимум иначе смысла никакого не будет у вас репликация она будет становиться асинхронный сложных ситуациях а во вторых вы можете с помощью счетчика в эти условия слоев каунт указать какого количества реплик вы ждете вот например на предыдущем слайде у нас две реплики но мы дожидаемся записи только в одну реплику то есть у нас получается коварная репликация ok что должна сделать х утилита то есть что нужно делать если происходит failover падение мастера во первых нужно понять что происходит падение мастера как-то закрыть его если он еще не закрылся нужно выбрать лучшую реплику всех повернуть на эту реплику и сделать ее мастером а старого мастера нужно закрыть все казалось бы просто и понятно но у нас есть несколько подводных камней с которыми мы столкнемся первая вещь которую нужно решить это кто будет управлять процессом если мы не выберем одного управляющего то ситуация может быть плохая то есть они могут принять разные решения и каждый за промыть от своего мастера здесь есть несколько подходов 1 которой используется например в майской ли и в похожем open source решение от гитхаба называется orchestrator заключается в том что всегда есть одна один экземпляр который управляет файл озером кластера в данном случае мы видим что у нас есть 3 х 100 на каждом есть экземпляр майский экземляр х утилита у нас на называется мой sing экземпляр х утилиты держат лог внуки период то есть это система распределенного консенсуса можно использовать другую и именно вот этот экземпляр мосинка он управляет переключением кластера гид хоп оркестра тарон вообще располагается на отдельных нодов то есть он вне кластер оживет есть второй подход который используется в паз грейси когда лог держат именно та но до которая является мастером то есть каждый каждая х утилита она контролирует только свой свои свойства с базы данных здесь несколько ситуация получается концептуально сложнее потому что при файла бери вот эти утилиты они должны действовать как распределенная система они должны с помощью алгоритма договориться кто будет следующим мастером случае когда у нас выбирается 1х утилита главная она собственно говоря как человек выполняет все действия проблема номер два нужно понять что мастер мертв существует несколько степеней мёртвости мастера самая простая отказ железо когда кто-то питание выдернула либо что-то упало и у вас просто мастер ушел все просто он не вернется 2 второй вариант это отказ сети отказ сети бывают разные вы можете потерять сеть на конкретной железки можете потерять сесть сеть в дата-центре при том что в дата-центре все будет работать внутри него нормально есть еще более неприятные ситуации такие как крыши miss kelly out of memory и самая противная эта перегрузка hasta у нас была ситуация когда клиент нагружал майской до такой степени что подключение длилась просто создание нового подключения к москве 20-40 секунд призов dns имени тоже примерно 20-40 секунд а при этом клиенту было нормально то есть он считал что это робот способный кластер как мы подходим к этой проблеме то есть мы считаем что ошибка мастера это любая любая проблема при которой мы не можем сделать select единичку вот х утилита которая работает рядом с мамой спилим она делает эти запросы постоянной отправляет их в дистрибьютор консенсусу keeper если у нее не получилось сделать это файл мастера но при этом есть несколько как бы такая система сдержек прежде чем начать failover мы проверяем что кто-то еще видит эту проблему то есть не не только с 1 х 100 это проблема детектируется но из 2 мы проверяем что у нас работает репликация если репликация работает то вероятно эта проблема связанная с у кипером либо с нами то есть работающая репликации запрещает нам делать хэллоуин мы дожидаемся что проблема она возникла не один раз а повторяется в течение какого-то конфигурируем а во времени то есть грубо говоря течение минуты происходит вот такая ерунда и не делаем failover слишком часто потому что смотри про out of memory и crash mais quel а если клиент умудрился довести до out of memory одну ногу он это сделает и со следующей нельзя делать failover слишком часто проблема 2 в москве ли один thread получает данные от мастера 2 the thread применяет изменения поэтому реплики могут отставать и они могут отставать довольно сильно тут есть два варианта плохой и отвратительный плохой когда у вас просто две реплики отстают и вам в процессе файла вера нужно выбрать как бы реплику и дождаться пока она догонит отвратительно это когда они отстают по разному например здесь есть 2 реплика которая скачала тысячи транзакций с мастера то есть она получила все данные но сильно отстаёт есть третье но сосули анализ реплика 2 называется которая получила почти все данные но не отстаёт то есть казалось бы мы могли на нее прям вот сейчас сделать failover но не можем потому что на ней не все данные в такой ситуации вот мы как облачный провайдер принимаем решение промыть-промыть реплику 1 то есть ту на которой все данные несмотря на то что она сильно отстает потому что мы не можем терять данные не можем за клиента принимать такое решение что можно сделать чтобы уменьшить рипли кей шон лок и сместит свести такую ситуацию к минимуму тут к сожалению очень многое зависит от самого приложения правило основные такие нужно использовать индексы в таблицах то желательно что в каждой таблице был либо праймари либо достаточно индекс хороший селективностью нужно использовать небольшие транзакции то есть не надо делать апдейт всей таблице грубо говоря в одну транзакцию в частности если вы хотите сделать alter большой таблицы используйте какую-нибудь утилитами типа от перка на онлайн схема cinch которая делает изменения небольшими кусочками ожидать чего не происходит большой транзакции если доступа к приложению нет то есть мы не можем повлиять на то что происходит внутри базы можно попробовать немножко покрутить настройки в частности от поиск строки на реплики можно configure по конфигурировать можно попробовать включить параллельную репликацию и даже можно включить такую настройку как flash локатор x commit равняется 2 это означает что запись в ряду локон они не будет ложиться на каждую транзакцию обычно так делать не рекомендуют но поскольку у нас есть кластер есть синхронная репликация то это в принципе нормальное решение проблема номер три что происходит с тем мастерам со старым мастерам когда на нем потеряется сеть запросы которые писали находились процессе коми то они подвисают в таком состоянии как удвоить 8 и синко ок они ожидают подтверждения от реплики но не дождутся его никогда то есть у нас тайм-аут год самое плохое в том что с ними мы сделать ничего не можем мы не можем их убить они не остановятся мы не можем перевести мастер в режим readonly потому что вот мы видим запрос на включение readonly режима будет сдать завершения таких транзакций такие транзакции будут ждать реплики а реплика уже никогда не ответить потому что происходит failover и у нас выбирается новый мастер что можно сделать таком случае вариант номер один рестарт сервера вариант номер два более такой элегантный мы можем отключить оси missing плагин на мастере и при этом эти транзакции за к месяце они закончатся в любом случае то есть мы уже находимся в процессе коммита и у нас нет возможности отказаться сказать вот этих транзакций мини комете они будут закончены подробности можно почитать примерно в том месте исходников москве альвело коротко мид и но тем не менее мы вернем управление nas-сервером мы дальше сможем с ним что-то делать потому что пока эти транзакции не закончена мы не можем сервером управлять им и переходим к 4 проблеме у нас тут появились на мастере лишние транзакции упс произошел сплит brain первое что нужно делать когда произошел сплит brain это не признаваться никогда не говорите что вы вот так вот этого суд базовую вас плит brain случился мы не признаемся что значит сплит brain мы видим что на старом мастере появилось несколько транзакций которых которых уже нету на новом мастере они не были от реплицировали но краше к вере их восстановила старом мастере что делать не признаваться нужно правильным образом нужно сделать так чтобы клиент просто не увидел эти данные во первых ваш сервер москве должен запускаться примерно с такими параметрами readonly и оффлайн мод он это означает что он не доступен для записи чтобы в него не начали писать после того как он там крашнулся перестал при старте lsa и оффлайн мод означает что он доступен только для суперпользователя приложение его видит не должно теперь мы можем попытаться что-то с ним сделать ну что мы с ним может делать во первых мы можем просто перри налить эта технология должна быть отработана если вы эксплуатируете большое количество моих келий в х режиме вас должна быть отработана перри наливка чтобы вы всегда могли старый мастер навить есть более элегантное решение сделать rewind к сожалению она пока доступна только в мария baby они сделали такую вещь как флешбэк то есть возможность проиграть белок изменения в берлоге в обратном порядке отменить их и есть обертка вот опять таки от гитхаба которая позволяет это более удобно делать я думаю мы напишем примерно похожую вещь только независимую для маски то есть либо откатывает изменения либо перри наливаем в принципе с файлами рам на данный момент все но это бы не все что требуется от х утилиты на самом деле существует еще довольно большое количество вещей которыми должна заниматься х утилита первая вещь это switch over switch over the переключения мастера в нормальной ситуации когда нет никакого падения например мы выполняем обновление кластер и нам нужно по очереди при старте но ты нам нужно уметь переключать мастера нормальной ситуации тут есть тоже такой подводный камешек при переключении мастера нам нужно убить запросы на старом это не так просто в мае съели в отличие от пос gresso убийство запроса при убийстве запросе он начинает откатываться то есть применяются онду логе это занимает время если вы делаете длинную транзакцию и убиваете и прям перед самым концом вам нужно будет подождать примерно еще столько же чтобы она откатилась то есть убить запросто тоже долго х утилита может управлять еще не х репликами то есть теми репликами которые используются для аналитики но не входят в к группу их тоже нужно поворачивать в процессе файла вера но нужно сделать так чтобы на них никогда не оказался мастер то есть они по смыслу должны быть всегда replica mi ha утилита должна следить ну это может делать не она но все-таки полезная вещь следить за свободным местом когда в маска или кончается место он в отличии от пос gressoney крошиться он переходит такой режим только чтение но им практически невозможно управлять то есть все транзакции которые пытаются закомитить они держат к митлаг соответственно вы не можете например там сделать turbine релакс потому что упираетесь в этот же самый к митлаг когда вместо кончилось единственное что можно сделать можно руками удалять старые берлоге тогда немножко место освободится и вас будет немножко времени чтобы что-то предпринять что-то починить в нормальной ситуации х утилита должна закрывать кластер за некоторое время до исчерпания место то есть когда нам 95 процентов место занято мы должны переводить кластеров readonly чтобы хотя бы не потерять управление над ним здесь есть еще один подводный камень пользователь может делать длинные транзакции я уже говорил что делать не нужно но он все-таки может если пользователь делает длинную транзакцию белок может занимать больше места чем указано то есть мы съели можно настроить штамбе ноги и грубо говоря там по 200 мегабайт но если транзакция длинна это белок может 10 гигабайт быть и этот белок он может занять что свое свободное место и мы можем не успеть отключить запись то есть перевести кластеров readonly ну и плюс есть такая фича как закрытия ставший отставших реплика реплика сильно отстает и и иногда имеет смысл закрыть нагрузки вот собственно говоря с какими вещами вам придется столкнуться если вы захотите там написать ho утилита которая будет вам обеспечивать переключение мастера но это не все что нужно для availability то есть есть еще некоторые вещи которые вне этой утилиты первое нужно как-то балансировать запросы то есть так чтобы запроса всегда приходили в мастер сожалению в маске или нет такой фичи как балансировка на клиенте торги тошнота раз как вас грейси поэтому приходится делать dns аллиасса либо использовать какой-то сервис discovery для того чтобы показывать клиенту кто сейчас мастер нужно перезаливать отставшие и упавшие хосты уметь это вещь опять-таки зависит от того окружение в котором вы работаете то есть система виртуализации от система бэкапов и нужно делать резервное копирование потому что не всегда можно перезалить с мастера то есть когда вы переживаете реплику вам нужно откуда-то взять данные с мастера иногда брать данные не хочется потому что это может дать дополнительную нагрузку и даже полностью заблокировать мастер поэтому нужно делать правильно и резервное копирование чтобы уметь продлевать реплики из backup а вот собственно говоря если вы хотите делать это самостоятельно теперь вы знаете с чем придется столкнуться если не хотите то вы можете использовать какой-нибудь обычный провайдер которая это сделает за вас на этом все спасибо за внимание можете задавать вопросы я подумал что это все очень похоже на управление автомобилем только ведущее колесо постоянно переключается середину за три назад слева направо и еще колес обычно нечетное количество автомобиля все-таки 465 до багажнике 1 да действительно это очень похожи на управление автомобилем спасибо за внимание давайте отвечать на вопросы спасибо за доклад а я напоминаю что у нас победитель человек который зато сам интересный вопрос по мнению докладчиков получат памятный приз мы надеемся что в этот раз у нас получится также заслушать вопрос из онлайна но начнем мы с оффлайновых вопросов пожалуйста добрый день меня зовут сергей спасибо за доклад могли бы вы можете пару минут тысячи рассказать и остается вопрос а почему нельзя аналитическая хранилище наполняется стендов что в подписи что в москве или актуальность или какие то другие можно но для того чтобы в подгрести это сделать нужно наложить патч актуального коммент festa чтобы сделать это частью ванильного под gresso нужно пойти по review эти этот патч по чьими-то хэнде кара pro logic decadance then buy просто кот не написан немножко на себя программировать про маски в мазке ли это сделать можно вы можете наполнять любого с любой ноги главное чтобы клиент который перекладывает данные поддерживал джи ти до той самой скайлер здесь проще такой проблемы нет здравствуйте спасибо за доклад вот вы сказали что и запись и чтение у вас происходит на один сервер чтобы сохранить константность а как проблемы с масштабированием решаете случаев но нет я сказал чтобы достичь вот такой консистенсии модал как мы описываем нужно читать и писать в один сервер но писать понятно у вас один мастер а читать это рекомендуемая вещи клиент может читать с других хостов но он должен понимать что он делает то есть он должен каким-то образом мониторить отставание хоста и понимать какой какой лак для него приемлем то есть например не нужно читать там данный относящиеся к деньгам а какую нить историю там или статистику вполне можно брать то есть некоторые некоторые запросы можно выполнять на репликах это нормально есть какие-то инструменты чтобы переложить эту задачу с приложения и не знаю балансировщик на какой то есть сказать что вот я хочу чтобы ты за следил за этим есть какие-то готовые ну в прогрессе мы хотим написать на уровне кулера отстреливая отставших реплика то есть там можно будет задать consistent модель консистентной sti типа не читать с реплик если она стала больше чем на пять секунд например в большинстве случаев так ну то есть если мы говорим именно про модели консистентной обычно эта логика не очень применила потому что ну например там интернет-магазин человек сделал заказ обновляет страницу его заказа на реплики нету потому что чтение происходит ровно в тот же момент вот мы короче в прогрессе пока над тем чтобы не читать старые данные с реплики каких-то стандартных подходов я не знаю но вообще не должны быть но по хорошему надо делать несколько грубо говоря алиасов или записи там в сервис discovered текущей мастер самая свежая реплика там все реплики они только аналитические реплики но понять какие запросы что требует может только само приложение то есть мы же не можем сказать какому запросу нужны актуальные данные какому подойдут отставшие там на несколько часов если я не ошибаюсь внутри мир вот есть базу да ладно давайте-ка след молодой человек хочет спросить спасибо за доклад к вопросу кто валяет да все работать у меня слышно даже здесь так вот к вопросу кто у руля и так для этого используется какой-то дистрибьюции stavrovich и вдруг он сломался и мастер не может подтвердить сам для себя что мастер никто из реплик не может взять блокировку чтобы сказать теперь я мастер чо происходит смотрите дистрибьютора чон нан отойди скребут истории чтобы не ломаться то есть три но да он стоит как проект правил там из трех тот они располагаются в разных дата-центрах и сама технология за кипера она обеспечивает отказоустойчивость в как раз спроектирован для того чтобы быть максимально отказа устойчиво если ломается sisteme de ses тогда мы ничего хорошего сделать не сможем ни sms ни с моей спели вниз под грессов остается надеяться только что в этот момент не происходит падение мастера но если происходит тогда мы просто не сделаем failover такой риск который принимается не расслышал это такой риск который принимается до отказа de ses это маловероятная ситуация потому что de ses ненагруженная система отказ здесь я связана с обычно с отказом внешних компонент то есть например 22 центра упали или такую штуку из-за коммунальной инфраструктуры что мы словили такую штуку из-за коммунальных со структурой на виртуальном хостеле работала над языки пера и какой-то другой виртуальный сервер завалил физический хвост ну в данном случае правильное решение это хороший мониторинг и как бы все ну то есть если вы обеспечиваете если у вас есть 33 узла вы обеспечиваете -12 центр если у вас есть пять узлов вы обеспечиваете -2 дата-центра вот стандартная модель отказа спасибо"
}