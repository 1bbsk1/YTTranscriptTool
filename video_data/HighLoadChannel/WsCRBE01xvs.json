{
  "video_id": "WsCRBE01xvs",
  "channel": "HighLoadChannel",
  "title": "Как заставить Stable Diffusion генерировать не только аниме и котиков, но и тебя / Кирилл Семин",
  "views": 334,
  "duration": 2754,
  "published": "2024-04-17T01:10:20-07:00",
  "text": "и в прошлом докладе мы обсуждали что мы можем сделать генеративными сеть сетями с текстовыми моделями и сейчас настало время пойти дальше и поговорить о том что мы можем сделать с генеративными сетями которые будут генерировать для нас изображения и расскажет нам об этом сегодня большой ценитель генеративного искусства Кирилл Сёмин из VK Приветствуем нашего следующего спикера Да всем привет меня зовут Кирилл работаю я ВКонтакте занимаюсь его проявлениях как бы странно не звучало основан LP но и диффузионные модели естественно тоже причем в частности полный обо мне давайте поговорим о вас я уверен что как сегодня так и вчера куча всего услышали про различные высоконагруженные системы терабайты данных кредитной истории Ну и хорошенько там развлеклись в общем отдохнули мы будем говорить про по-настоящему важную тему Ну и как вы думали что это конечно аниме Куда без него аниме я значит генерировал довольно много сидел там целыми днями вообще проводил и мог даже не работать Порой просто заниматься генерацией Однако генерируешь сидишь красивые картинки Но рано или поздно даже красивые случайные Девушки вам надоедает вам хочется чего-то другого совершенно новое иного и кардинально прям нового например можете генерировать себя полностью переместиться в мир потому что ну это наверное самый прекрасный мир который победил как все мы знаем Однако если вдруг вы хотите чего-то другого и например Они Вас не устраивает я конечно не очень понимаю почему но тем не менее Вы можете переместиться вообще в любой мир можете переместиться в мир где Вы являетесь есениным можете переместиться в мир где вы будете солдатом-разведчиком и то что для этого нужны были генотипки Но неважно даже можете святым быть если очень сильно захотите Все зависит только от вашей фантазии и навыка подбирать фронты но мы конечно поговорим не оправдах разберем весь payplay по получению таких картинок сначала пройдемся кратко диффузия Ну если в частности потом научим их персонализировать соответственно нас они просто каких-то непонятных парней и потом оптимизируем это настолько что вы даже у себя напока сможете это запустить Ну и отклиться если нужно поехали диффузии очень коротко У нас есть картинка прекрасная курица в данном случае что мы делаем мы немножко зашумляем подаем нашу модель она Таким образом мы обучаем мы просто нормального какой-то шум потом подаем опять нашу модель которую научилась расшедлять делаем так очень много раз и рано или поздно получаем конечно нашу картинку это если очень коротко полагаю они все были накладе кондинского и понимают вообще как это работает поэтому я немножко углублюсь у нас все еще есть прекрасное изображение и мы его зашумляем Однако в чем идея мы защемляем наше изображение подаем все также в нашу модель Но в данном случае например Зашумели в принципе понятно что это изображение ру шумит очень легко но делаем Это еще раз уже становится не так понятно какое-то изображение совсем в пикселях и модели становится сложнее расширять делаем Это тысячу раз конечно в итоге мы скатимся просто в какой-то непонятный шум и не совсем понятно Когда модель должна из него что-то восстанавливать Но даже тогда мы будем ее просить Итак мы обучаем нашу модель Ну то есть когда мы уже обучили хотим получать какие-то красивые картинки мы начинаем с опять же стандартного шума стандартного нормального и сэмплируем оттуда то есть берем этот шум подаем нашу модель она возвращает изображение до конца мы делаем Это много раз тысячу раз и в итоге получая нашу картинку красивую Ну хотелось бы конечно может подумать наверное очень долго на самом деле нет сейчас есть очень много сэмплеров которые позволяют это делать за 40-50 шагов причем Даже более качественно чем такое простой метод поэтому все работает на самом деле быстрее а хорошо как работают диффузии в целом мы поговорили наверное пришла пора подумать о stable de Fusion Но прежде чем это делать возникают довольно очевидный вопрос А зачем ты будешь ужин Можно же например как здесь показаны стандартном таймлайне очень простом взять нашу картинку зашуметь подать в Unit модель которая будет принимать картинку выдает картинку такого же с такими же dimensional она шумит Ну и все Да можно делать так на маленьких картинках 32-32 это работает будет вам генерировать неплохие изображения Но есть одно но здесь видно что мы считаем все картинки изначально и проблема в том что считаете Мы все когда у нас огромное количество пикселей хотя бы 112 на 512 это очень затратно для во-первых во-вторых обрабатывать такие большие картинки в целом очень тяжело поэтому именно эту проблему решается Ну или стебель очень часто называют В чём идея а у нас есть картинка большая Ну хотя бы опять же 512 на 512 мы не можем ее подать в модель это будет очень долго работать поэтому простая идея Ну давайте эту картинку сожмем делов-то Однако делать мы это будем не с помощью какого-то глупогорит сайза А с помощью другой модели которая называется воен как она работает на самом деле нам не очень волнует важно лишь понимать что она может сжимать изображение И разжимать причем очень хорошо поэтому подаем берем нашу картинку подаем ее в воде она сжимается например до 64 на 64 и дальше у нас тот же самый производит расширение только работает он не на пикселях а На сжатом представлении хорошо мы теперь можем генерировать большие красивые картинки Однако генерировать какие-то случайные картинки Ну не очень интересно поэтому еще мы добавим другую модель клип который умеет обуславливаться на текст она будет взаимодействовать как она будет это делать мы разберем очень подробно потом сейчас же достаточно Этого Ну хорошо что мы узнали Первое это как выйдет по плану обучение напомню что машину обучение жизнь модели стоит из двух частей обучение где В данном случае мы учим модель расшулять и inference когда мы берем стандарт нормальный шум и постепенно расширяем и второе мы знаем как выглядит Fusion Это тот же самый Юнайтед но при этом мы добавили пару моделей одна из них сжимает изображение Это факея другая обуславливается на текст это клип Как работает диффузии плюс минус поняли Но мы же хотим персонализировать правда диффузия умеет в частности обуславливаться на текст Хорошо Давайте напишем фото в Кирилл чтобы сгенерировал меня в стиле аниме получится ли у модели это сделать теста Нет она ничего не знает обо мне генерирует аниме стайл даже человека но со мной не имеет ничего общего поэтому модель нужно дообучать Давайте этим и займемся Однако прежде чем да обучать модель нужно разобраться с данными это Сета как мы уже выяснили у нас подается модели какой-то промт это текст который мы хотим генерировать и картинки просто достаточно написать фото в Кирилл Мэн этого более чем достаточно с картинками немножко сложнее насколько я убедился вообще не у каждого человека есть много фотографий себя где только если вы больше ничего а нам нужно их 10-20 чтобы получать хорошее качество можно Конечно даже с одной картинкой но там придется помочь с обучением хорошо 10-20 фоток есть требования причем довольно много самый важный это первые два фотография должна быть портретная или селфи чтобы Ваше лицо было очень крупным очень крупном плане и второе это высокое разрешение должно быть хотя бы 512 512 пикселей теперь перейдем к моделям как мы выяснили у нас клип есть клип UN это воен здесь мы поговорим про воде ну или большей части даже unet Потому что есть огромное количество моделей которые затянены на различных стилей поэтому вы можете просто поискать и выбрать тот стиль который Вам нравится Однако если вас интересует какие-то General модели то может просто брать Например если взять что-то более фото реалистичное Можете брать ремень шейпер получается очень качественные картинки но при этом более реалистичные Хорошо теперь еще поговорим про метрики А как вообще хотим понимать Ну получилось у нас насколько хорошо получилось у нас есть первые метрики это которые отвечают за само изображение за ее качество то есть насколько картинка в целом красивая первое второе естественно Мы хотим сгенерировать себя а не просто красивую картинку потому что это мы так уже умеем и еще три аспекта это время обучения Потому что если мы хотим скелить это на пользователей виде какого-то сервиса то пользователь не может условно ждать несколько часов он при нём просто надоест он идет ГПУ память не хотелось бы чтобы нам нужны были только соты хотелось бы запускать на каких-то более дешевых видеокартах Ну и размер весов потому что вдруг если вы захотите модифицировать сохранять нашу обученную модель для пользователя и использовать ее потом вам конечно нужно сохранить веса Хорошо что будем обучать у нас есть и совершенно непонятно что из этого нужно трогать что нужно оставить поэтому Давайте разбираться по порядку как я уже говорил в воде умеет сжимать и сжимать изображение поэтому Давайте приведем тест Да наше изображение сожмем его и посмотрим на то что нам выдаст если оно справится то понятно дело трогать не нужно Ну естественно исправляется причем артефакт будет просто минимум поэтому не будем нет никакой нужды у нас остались а на эту пару можно смотреть следующим образом юнет Это художник он рисует прекрасные изображения вообще в целом Ему больше ничего не нужно Однако рано или поздно хочется кушать он обращается делает на заказ свои рисунки обращается он клипу это его Агент причем работать они очень долго и понимают друг хорошо но заказчик в этом случае мы когда мы приходим к липу для него Наш заказ он как бы совершенно неадекватен Он не понимает что мы от него хотим поэтому Давайте научим клип понимать что нужно делать идея называется следующим У нас есть огромная модель клип там на самом деле сотни миллионов параметров весь это очень много а мы будем обучать всего лишь один вектор Казалось бы один вектор и у нас мы будем сможем генерировать себя да это правда и Давайте углубимся в то как работает клип на самом деле клип текста который не работает напрямую со словами он сначала бьет их на токены которые очень часто это какие-то части слов редкость составляет Которые теперь нас будут играть роль слов и естественно там нет недовольных бединга который отвечает например за мою сущность поэтому Давайте добавим новый Вектор принципиализируем его чем-то каким-то понятным словом например Man и будем обучать его вот и все получаем очень плохо прям на меня не ну на меня немножко похоже какие-то черты лица есть прическа например какие-то что-то еще но качество очень плохое Ну совершенно не удовлетворительное при этом все это обучалось два с лишним часа я понимаю что если на самом деле пообучать подольше и больше фоток закинуть то возможно получится лучше потому что в интернете есть довольно много результатов обычных знаменитостей работает но уже даже это требовал достойно часа что не позволительно дорого и мы потратили Однако мы потратили всего лишь 8,5 памяти гигабайт ГПУ и мы запускать поэтому хотим по большому счету и если вдруг мы хотим хранить эти векторы для переиспользования то это очень дешево потому что один доктор есть около 4 килобайт но качество нас не устраивает Давайте подумаем еще мы разговаривали только с клипом причем решили обойтись с малой кровью и обучать всего лишь один Вектор Давайте теперь обучать например и клип unet будем разговаривать из художником если его агентом чтобы лучше объяснить что на него хотим а именно метод называется dreambook и обучать мы будем вообще весь клип Все параметры и все параметры и Казалось бы если мы обучать будем всю модель то она гораздо быстрее обучиться и поймет что мы в целом нее хотим Ну погнали получится На самом деле очень круто и фотографии в начале были обучены с помощью этого метода как мы видим получается первое качественно второе это действительно Я на меня очень похоже И третье это время обучения которое сократилось в данном случае до 20 минут Однако есть два огромных недостатка это то что чтобы это обучить Мне потребовалось 31 Гб на ГПУ Ну и вы наверное Можете подумать что Откуда у меня 31 гигабайт Ну и обучать такое можно только на сотых и картах такого калибра естественно это огромный минус Но мы его поборем обещаем и второе это размер весов 2 гигабайта весов это то что мы поменяли это исходит из того что мы буквально обучали все параметры Ну естественно хранить нам нужно их всех Поэтому если вас миллионы пользователей Ну навряд ли у вас это получится хранилище Point Окей мы обучали Сначала один Вектор получилось так себе обучали всю модель и получилось очень крутое качество То есть наверное дело в том какие веса нужно обучать Давайте разберемся возьмем нашу модель и сделаем для копии весов первая копия мы так и оставим трогать не будем а вторую копию от обучим тем методом который только что объяснил будем модифицировать всю модель Ну соответственно первое W штрих что мы хотим увидеть Мы берем разницу весов которые были в каждом слое и считаем норму логично что чем норма выше тем сильнее вы ставите поменялись А значит они более важны по крайней мере так можно предположить и более важными являются кросс atention и Self Attention они очень сильно выделяются о том что такое Attention Мы очень подробно поговорим а сейчас нам достаточно лишь понимать что на самом деле там всего лишь есть три матрицы которые обучаются под названием Что это значит мы тоже поговорим потом а пока оставим что мы делаем мы наверное могли предположить Ну вот есть три матрицы обучать Кирилл будет именно их Ну нет так скучно ему делать не будем Мы поступим следующим образом они участвуют эти матрицы слоях То есть просто y равняется Мы немножко по-другому будем поступать будем изменим это произведение на W + Delta W то есть будем добавлять какую-то маточку кушать текущий весам и обучать именно эту маточку эту добавку А изначально веса трогать опять же не будем Вы можете подумать Ну класс теперь нас еще больше стало Весов и параметров которые мы хотим обучать в чем была идея идея на самом деле Лора заключается в том что вот этого добавка которую мы будем обучать она на самом деле низкоранговая что это означает что вот Матрица W которая была в самом начале она размера Дельта W это произведение двух матчей причем они очень маленькие они размерности ДНР где R значительно меньше чем Порой даже один Вектор буквально будем обучать довектору Как работает на самом деле очень красиво но не совсем я потеряли это не очень круто да и время обучения У нас увеличилось до одного часа Однако есть и плюсы мы обучали гораздо меньшее количество параметров поэтому теперь нам требуется всего лишь 11 ГБ то есть мы можем брать практически все что хотим и размер весов тоже небольшой от 40 до 10 мегабайт зависит от того какой R вы выберете поэтому вы в целом можете хранили своих пользователей Окей давайте подведем промежуточный итог что мы добились Сначала мы обучали метод Texton Virgin и он заключался в том что мы берем только один Вектор из клипа из текстового нашего энкодера и обучаем только его затем мы посмотрели на качество подумали ну как-то совсем не очень и времени много тратим давайте мы будем все обучать получится у нас очень быстро очень качественно прям очень классные картинки это называется dreamboof но затраты 31 ГБ памяти не У каждого есть такие крутые большие карточки и в целом Это очень дорого Если вы хотите скелеть и мы решили более точечно посмотреть на то что на самом деле нужно обучать и пришли к методу Лора который заключался в том что мы будем обучать ранговую добавку только вы Спросите что в итоге выбирать Там какой метод Ну естественно я думаю по изображениям больше всего нравится именно дримбов потому что он дает очень качественные картинки и при этом они хорошо сохраняют indentity то есть именно в вас рисует модель Наверное это самое важное что пользователь хочет видеть чтобы рисовали Именно его Поэтому мы будем оптимизировать потому что он как мы выяснили требует очень больших ресурсов и разберем несколько оптимизации А пока зафиксируем мы обучаем 20 минут и требуем 31 ГБ памяти поехали 1 и наверное самое банальное о чем можно подумать это а нужно ли нам нужна нам большая точность А сегодня мы храните веса модели в fpr32 например вообще не обязательно можно обучать fp16 на самом деле лучше в микс престиживании потому что не всегда fp16 хороший результат и тогда мы сэкономим очень хорошо на памяти и даже будет быстрее потому что современная видеокарты они хорошо работают с такой точностью более оптимально второе оптимизатор с оптимизатором на самом деле есть небольшая загвоздка потому что оптимизатор такая штука которая нам читали клиенты И на самом деле делает шаг она не такая простая Потому что сейчас все используют оптимизатор под названием и он хранит первый и второй момент то есть средняя для наших Весов и как бы вы должны понимать что у нас есть веса Теперь мы храним градиенты для этих весов потом еще и первый момент и второй момент буквально две дополнительные копии и хранить можно на самом деле 8 а не вп-32 с помощью автоматизации Это нам очень сильно поможет сохранить памяти еще одна штука поговорим про войну на самом деле когда я говорил про detoset еще раз напомню нам нужно было 10 20 фотографий фотографии у нас небольшое количество но при этом шагов на во время обучения мы делаем очень много там условно 200 шагов на каждую фотку получает две три тысячи фотографий это очень много и каждый раз когда мы делаем шаг Мы берем картинку и переводим ее сжатое представление получаем наши латенты но картинки одни и те же поэтому на каждом шагу сжимать эти изображения мы будем по несколько раз то есть они же будут повторяться представляем их одинаково поэтому мы можем взять наши картинки сначала изжать а потом производить обучение То есть просто закушируем эти латентные представления Это довольно сильно поможет нам увеличить скорость обучения Ну немножко даже сэкономить память поскольку Теперь мы не должны хранить модель а чекпоин градиентов на самом деле очень простая штука И все что вам нужно знать чтобы ее понимать это чейндрол школьный Chain Roll как бы нам дифференцировать брать производную сложные функции представим себе следующее ситуацию У нас есть X изображение и очень простая нейронная сеть настоящая из двух слоев же в конце мы считаем естественно лосс какой-то что мы делаем выдаем xg потом в Давайте посмотрим повнимательнее на F Пусть это будет какой-то линейный слой Нам сейчас не очень важно линий слой то есть y равняется что мы делаем на самом деле следующее когда мы считаем Мы хотим взять Мы хотим обновить потому что мы обучаем модель и поэтому нас интересует производная разворачиваем ее очень роллу получаем надо Градиент который к нам приходит сверху Нам сейчас не очень важно он будет известен мы сейчас можем посмотреть на дф когда находимся в то есть буквально нужно посчитать производную функция функция Линейная просто умножение на матрицу Поэтому если мы возьмем частную производную пояса то получим просто Y производную мы посчитали соответственно получили каша довольно просто Однако Y в данном случае это результат работы функции же то есть Мы помним что сначала X прошел через G чтобы попасть в таким образом это все разворачивается в DL на DF умножить на GX и это мы считаем во время бекфорда то есть когда уже делаем шаг и обновляем сам модели что здесь стоит заметить то что же от x к нам пришло нужно хранить результаты вычисления функции которая была до этого нужно хранить даже соответственно и поэтому простая идея просто вот и все И перевычисляем эту функцию Каждый раз когда нужно Да понятно это очень медленно и мы не можем делать так со всеми слоями моделями но кое-где можем например активация следующая штука это классический механизм внимания Ну или тот самый Attention про который я вам столько раз говорил сейчас будет очень душно Поэтому вот заранее предупреждаю напрягитесь Ну или сразу ложитесь спать потом будет результаты Как это работает у нас есть X это какой-то вход нашего слоя Что такое X он размера LD Это матричка где L это длина последовательности в качестве последовательности Вы можете брать представлять себе пиксели пришли пиксели у них есть какие-то представления их или штук как я уже говорил внутри Attention слоя есть три маточки дабы на самом деле не нужны для того чтобы Каждый элемент входящий последовательности разбить его на три новых элемента Кука и в то есть зафиксировали у нас был X1 какой-то элемент Теперь стало Зачем вообще все это сделали очень простая вот у вас есть картинка и Наверное вы хотите сделать так чтобы каждый пиксель он извлек информацию из других пикселей то есть как-то вот перемешать и замешать информацию очень простая это взвешенная сумма в первой строчке показаны мы Просто для каждого вектора это выходной элемент последовательности работы представляем люди взвешенной суммы в векторов в векторы в мы с вами Так что посчитали просто маточку умножили надо как-то посчитать веса Альфа житое И на самом деле считаются не очень просто это скалярное произведение Мы берем наш Вектор Q и считаем скалярное произведение Чтобы проще было понимать вот Представьте У вас есть база данных базе данных хранятся значения Это в каждом значению соответствует ключ к и мы хотим сделать запросы базы данных но брать не один элемент а сразу несколько с помощью как мы это делаем мы проходимся по ключам наши базы данных считаем скалярное произведение и соответственно чем больше скалярное произведение Ну логично Что тем более релевантные мы получили ответ и с такими коэффициентами мы хотели сложить значение которые лежат базе данных все понятно Однако мы еще мы читаем взвешенную сумму поэтому мы от нормируем эти значения с Максом эта штука которая приводит все значения 01 и сумма их тоже будет единички равна а в некоторых в маточном виде все записывается так У вас есть какие-то кью кв и все Что вы делаете Это считаете Q на к транспонированное де нормировать это чуть-чуть и берутся Макс то есть в маточном виде это очень просто буквально сколько два матричных умножения Q на к и потом это все умножить на V работает эффективно Казалось бы если не одно но Матрица А вот Матрица с коэффициентами она размера и здесь есть небольшая проблема потому что нам нужно ее хранить и соответственно она квадратичная зависит от длины последовательности А вы понимаете что длина последовательности в нашем случае это Например пиксели а пиксели у нас 64 на 64 64 в квадрате это пикселей А мы еще Это в квадрат возводим то есть 4 степени это там просто миллионы выходят и в общем что я хочу сказать Она очень много весит и естественно нам бы хотелось снизить затраты памяти поэтому будем разбираться с этим моментом так еще раз Матрица пока у нас затраты памяти квадрат и мы хотим ее уменьшить что мы делаем ну самое очевидное Что можно сделать это просто считать эту матрицу построчно соответственно в каждом этом времени хранить только одну строку и тогда у вас будет затраты памяти отель потому что одну строчку Но мы сделаем так что у нас все это работа от единицы то есть константное количество памяти для любого входа как мы это делаем заметим У нас есть слов Макс что он из себя представляет я такой числитель деленный на знаменатель как бы это просто не звучало поэтому когда мы работаем с векторами Z зачисляем выходной последовательность мы на самом деле можем делать это итеративно сначала посчитать числитель То есть все скалярные произведения по порядку там экспоненту их возводим и умножаем на V вот сначала числитель посчитали параллельно знаменатель а потом просто одно взрывлено другое Таким образом мы в каждый момент времени не храним никакие длинные последовательности все что нужно хранить это ваш штрих и Казалось бы все вот единицы победили но нет не победили потому что экспонента это к сожалению функция которая очень быстро растет поэтому для Аргументов больше насколько я помню 89 она дает переполнение причем переполнение Даже для 32 как бы это побороть на самом деле очень просто когда мы читаем Soft Max его принято считать так чтобы мы вычитаем из всех значений максимум поэтому их порядок никак не поменяется никак на работу функция Не скажется но теперь все аргументы экспоненты меньше равняется нулю понятно что нам нужно сделать именно это делается это очень легко мы просто на каждом шагу поддерживаем текущий максимум это будет MG и делаем обновление то есть Идея заключалась в том что нам нужно вычесть из всех аргументов максимум Поэтому вот если Вы посмотрите на форму справа это то же самое что и слева буквально но мы домножаем на экспоненту в первом слагаемом мы нажимаем на экспоненту а именно на разницу м глобального максимума до текущей операции мжиты текущий Максимум в чем идея например мы не Обновили текущий максимум тогда им жить равняется M и мы получаем экспоненту от нуля то есть единицу это именно то что нам нужно потому что раз мы уже вычитали максимум то заново это делать не надо второй случай когда у нас Мы Обновили новый максимум тогда будет какой-то отрицательное число то есть буквально разница между предыдущим максимум и текущим которые нужно вычесть из всех предыдущих экспонентов именно это мы делаем когда просто нажаем на экспоненту разницы и то же самое делается справа во втором слагаемом когда мы считаем разницу между скалярным произведением и максимум буквально то что я описал в целом на этом все поэтому те кто уснул и отвалился можете просыпаться потому что мы переходим к результатам мы все это делали Не зря потому что теперь вместо 31 гигабайта наш метод требует всего лишь один с небольшим мало того мы еще и ускорили его потому что вместо 20 минут мы все обучаем за 13 то есть можем спокойно использовать этот метод и хорошо его скелет потому что видеокарт который имеет хотя бы там 12 Гигабайт на самом деле очень много финальные мысли если вы хотите проследировать себя точнее чтобы генерировать себя Вы можете использовать метод очень хорошо работает супер классные качественные картинки Ну и как мы уже выяснили с помощью оптимизации Вы можете сделать так чтобы он работал На огромном количестве видеокарт даже думаю наших постоянных компьютерах тоже будет работать второе оптимизации все оптимизации которые писал сложные вещи они уже реализованы вам не надо все это писать Вы можете половину из них взять библиотек причем настолько бесшовно что одну строчку нужно поменять либо что-то уже так будет работать например рассказывал он торчал второго уже просто из коробки работы там ребята Уже все сделали по плану обучения вот весь по плану обучения который я описывал Вот его нужно написать самому Однако это тоже небольшая проблема потому что комьюнити настолько развиты что есть огромное количество коллабов гитхабов Где вы можете посмотреть как это другие люди сделали причем они сделали оптимально на этом У меня все Если есть какие-то вопросы Буду рада видеть Спасибо поднимайте руки получайте микрофон задавайте в него вопросы Здравствуйте спасибо большое за доклад у меня чисто практически вопрос Может быть я не услышал докладе на чем мы сейчас и на каком железе инферите И сколько по времени примерно происходит да пустил я естественно обучал на 100 потому что мне нужно было максимально тоже как-то запускаете поэтому все время и так далее был на нем на 100 А много вас осотов теперь можете гонять Спасибо за доклад супер мега интересно и не менее интересно А хотя бы примерное направление что дальше Потому что есть какие-нибудь китайские модельки которые делают это лучше быстрее как в какую сторону можно развить это еще дальше еще быстрее чтобы это условно на мобильном телефоне работало смотрите на самом деле сейчас такой тренд на то чтобы мы делали и мечты имидж какая-то картинка Мы хотим стилизовать её Да это не то же самое что по правду говорит что хотим Но сейчас делать занимается основным этим это работает супер быстро например ну каким-то сервисом более-менее адекватные вам это сделать за 5 секунд любую картинку в стиле которую вы хотите по правоту она стилизует причем Это очень красиво например недавно выходил snaf Fusion эта моделька которая работает на Айфоне за 2 секунды то есть люди идут именно в этом направлении оптимизируют очень сильно диффузии поэтому это первый момент и мы читаем еще второй момент мы теперь еще очень много видосов наверное видели в Инстаграме или еще где когда мы прям все видео стилизуем А там всякие статуи танцуют и так далее вот второе направление картинки и видео Ну вот конкретно вы ВКонтакте будете чем заниматься Мы прям чем конкретно вряд ли смогу сказать но очень интересно которая рассказывала и также Спасибо большое Здравствуйте Очень интересный доклад Спасибо У меня два вопроса Первый такой ну со стороны пользователя больше если Ну предположить что вы здесь рассматривали только вариант генерации картинки по своему по своей фотографии если предположить что например надо сделать картинку с двумя людьми разными Да и возможно в полный рост насколько вот ваши методы оптимизации увеличится в нагрузке Да и вообще Подойдет ли dreambus способ для этого да Вопрос понятен смотрите проблема заключается в полном ростом сразу скажу что эти места работают довольно плохо и только если вы в тренировочный выборку мне добавите много таких своих фоток тогда можно не в этом в том что вы сказали что вы хотите генерировать несколько людей и вот это действительно проблема потому что у нас везде здесь заключается в том что мы впромт добавляем какой-то токен Кирилл он всегда добавлялся и модель учится смотреть на него обращать внимание на него поэтому Когда вы добавите туда то есть например какой-то токен он будет во-первых должен соответствовать сразу двум людям потому и вы не сможете генерировать только одного человека можете сканировать только пару во-вторых дримбов им это короче работает очень плохо но есть методы которые помогают проблемам побороть во-первых Texton Virgin можно обучить на одном человеке на другом использовать сразу два имбинка работать будет ЛОР тоже только может так можно использовать но есть более хорошие методы которые например оптимизируют текстовый и они действительно позволяют например двух людей генерировать Ну идея заключается в том что вы на одном обучили на втором можете потом генерировать мир таких методов можете привести как он Я могу Вам позже сказать просто название статьи меня еще другой вопрос тогда больше такой математический там вы хакс с экспоненты делали чтобы аргументы были меньше нуля соответственно сама экспонента будет меньше единицы до А в чем тут смысл там же то есть там же точность мы либо точностью тогда жертву либо там получается число с плавающей точкой которая тоже жрёт память Я вот тут не понял момент зачем это типа было смотрите экспоненту и мы считаем экспоненту постоянно произведение то какие будут скалярные произведения мы не можем прям вот сильно контролировать поэтому Ну они естественно могут быть хотя бы 90 А если она хотя бы 90 уже тогда переполнение просто флота происходит у вас там надо будет вылетать условно вы не сможете это обучать поэтому Довольно простой Хак это просто вычет максимум Ну это буквально не меняет результат результат работы он будет буквально такой же то есть точности там сильно не зависит это не аппроксимация это прям то же самое буквально ладно ваш вопрос я здесь если мы вычитаем максимум то Вы не боитесь что у вас наоборот пойдет за счет Ну как бы если вы вычитаем при значениях меньше минус 90 Он просто обнулится тогда да но будет много нулей вам эту модель не испортит Нет на самом деле в этом Да я понял в этом проблема нет потому что смысл отношений к ростом заключается в том чтобы посмотреть на то как взаимодействует друг с другом если там 0 то значит он просто и релевантен поэтому в нуле особо проблемы нет знания которые вас выскочит Ну понятно что Спасибо в глубинезоло у нас вопрос Спасибо за доклад у меня вот какой вопрос насколько я понимаю клипу Абсолютно без разницы насколько осмысленный текст ему подают в качестве токенов Почему бы не использовать для начала модель которая преобразует лицо Вектор выделяю какие-то отличительные характеристики Ну условно для нас большой нос там широко посаженные глаза и так далее и потом на этих данных обучать клип рисовать не конкретное лицо а лицо подходящее под описание вот виде этого вектора Когда у вас получилось бы возможно Чуть более универсальная Модель которая могла бы взять любое лицо один раз преобразованный вектор и нарисовать уже что-то похожее на него или вы хотите обуславливаться А на какие-то другие фичи да то есть вместо текста который говорит это конкретный человек чтобы у меня были фичи этого лица Да я понял есть небольшая проблема умеет ну взаимодействовать только с текстовыми свечами Поэтому если вдруг ни с того ни с сего будете делать условный кросс Attention это то как он работает своим байдингами текста на какие-то не текстовые ботинки на какие-то фичи которые вы сами придумали не важно что они действительно имеют смысл то на этот вопрос будет плохо работать вариант как можно такое сделать что-то похожее что вы возможно имеете ввиду это контрольная контрольная позволяет замешивать какую-то дополнительную информацию например очертания можно нарисовать человека вот тоже дополнительных обучаться Так можно Да крутой метод прям Тут не совсем понятно как его применять хорошо но идеально то же самое Короче если коротко Нет не может обуславливаться на все что угодно он обычно устанавливается на текст Это первое Второе естественно у вас будет текст поэтому спасибо Вот у нас здесь рука а большое спасибо за доклад собственно возник такой вопрос Когда показывали фотографии 10 2 штук которые нужно желательно загрузили выборки вы проговорили что есть условие что они должны быть обязательно цветные собственно стало интересно что быть если они черно-белый то есть нас будет цветная картинка черно-белое лицо на фоне Да я сначала когда обучал думал что действительно Ну черно-белая картинка будет короче работать плохо но потом я мне к сожалению некоторых людей это обучал у них были только черно-белые картинки хоть непонятной причине я такой Думаю ладно белых да у них тоже работает и даже когда вы будете потом всё это у вас будут Нормальные картинки если обучать нормально а потом помните прописать что мы хотим черном белый стиль это тоже нормально Привет Круто А вот внутренняя часть она значит там mms-e optimized и вроде бы все такие сидят и думают Ого ничего себе мы съешкой можно все еще оптимизировать будут красивые картинки А ведь собака порылась в воде по ходу воето училась на какой-то более хитрый лосс тогда какой-нибудь вот можешь рассказать А что там было в войне Ну давайте так когда мы учим с нуля делаем который нам просто может каких-то картинки генерировать даже тогда я не трогается уже просто заранее предобучено оно почти никогда не обучается очень редкие случаи когда вы хотите взяли стебель там 1,5 Хотите его затюнить там на какой-то стиль или просто на более качественные изображения вот тогда вы можете чуть в и это дает небольшой бус но в целом его не трогают вообще обычно насколько я использую насколько я помню воде там это выкуган то есть это микс выкува Е плюс ганов еще Понятное дело что не такой просто но это просто довольно спасибо если у нас еще вопросы не вижу вопросы раз вопросы два вопроса три продано давай же выберем Лучшие из тех что звучали А у меня есть Два подарка Значит первое наш прекрасный персик насколько я помню Наверное самая красивая милая игрушка которая смог найти и вот кому-нибудь подарим ее Я думаю я подарю вот вопрос который был здесь Спасибо большое за вопрос И еще у меня есть книга про Ганнибала как она Хорошо подходит но можно заиграть именно я вот хочу подарить человеку Вот вам спасибо для тебя у нас тоже есть подарок да да всем подарку большое вам спасибо тебе большое спасибо за твой прекрасный доклад Давайте поблагодарим нашего спикера вам большое спасибо за ваши вопросы за ваше внимание А на этом мы уходим на перерыв и всех ждем на следующих докладов Всем спасибо"
}