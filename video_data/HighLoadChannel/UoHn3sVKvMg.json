{
  "video_id": "UoHn3sVKvMg",
  "channel": "HighLoadChannel",
  "title": "Без A/B — результат XЗ, или Как мы построили платформу A/B-тестов в Ozon / Евгений Пак (Ozon)",
  "views": 4151,
  "duration": 2908,
  "published": "2023-04-28T06:21:30-07:00",
  "text": "руководителя разработки легендарнейшей платформы AB тестов от из озонтеха Евгения пока Приветствуем его Всем привет Тема моего доклада без АБ результат хз или как мы посоли платформу-тестов компания Озон так как вот он кликер нашел и прежде всего Я бы хотел сказать большое спасибо вам что вы пришли на мой доклад это большая честь Я бы хотел чтобы те люди которые продакшне запускали бы тесты подняли руки чтобы был понятен аудитории Я общаюсь на чем стоит делать акцент так Ну где-то наверное 10 процентов зала отлично значит вам всем будет интересно этот доклад потому что я буду Описывать как базовые вещи такие вещи поглубже также стоит сказать про особенность этого доклада что я не видел докладов про то как можно построить платформу тестов тем самым будет интересен С чего мы начнем начнем с компании Ozon и стоит сказать о том что компания Sun это огромная компания которая за 1 квартал этого года составил 177 миллиардов рублей которые работают больше чем 3800 человек войти и конечно же эта компания не могла обойтись без платформы AB тестов которые дает возможность измерять эффективность включенных фич и обеспечивать возможность проведения экспериментов для нашего бизнеса Если Вы посмотрите на экран то вы увидите что наши платформе 4 года и что в девятнадцатом году нас Максимум в месяц то здесь по оси Y у нас количество экспериментов которые мы заводили вместе видно что в девятнадцатом году эту платформу в основном использовала наша команда Вот то есть там максимум было 12 экспериментов но в этом году спустя 4 года мы пришли к тому что экспериментов стало относительно девятнадцатого года в 20 раз больше то есть в апреле мы открывали шампанское потому что месяц было запущено в Озоне более 100 экспериментов и все на нашей платформе здесь стоит упомянуть о том что увеличение экспериментов было в кратном размере также в кратном и пошла нагрузка на нашу инфраструктуру и о том как мы справились с ней как мы выдерживали большой НПС я опишу в этом докладе также стоит сказать что первыми Кто использовал его была наша команда Это был интересный опыт потому что мы отодвинули алгоритмы рекомендаций и к нам приходили ребята с дата сайнс и говорили о том что Ребята у нас есть супер пушка алгоритм типа он лучше всех остальных и всё будет круто дальше мы включали этот алгоритм делали тест и вот 8% всех этих супер пушка алгоритм не показывает значимых улучшению тем самым мы сделали инструмент который позволяет команде дата Санс исследовать эффективность своих алгоритмов и улучшать их сейчас наши алгоритмы стали намного лучше и стоит сказать о том что в двадцать втором году количество команд бэкэндок которые сейчас используют нашу платформу их стало чем 150 выглядит как история успеха Итак без а б Как измерить результат хз для того чтобы мы могли показать Почему нам всем именно необходимо обтесты и почему не можем без них обойтись Давайте с вами ответим на вопрос который интересует как it Особенно тех людей которые пришли так и бизнес для IT вопрос звучит так для чего мы упаиваемся в оптимизации за мили секунды а для бизнеса он звучит так как скорость ответа влияет на деньги это очень интересный вопрос и для того чтобы ответить на этот вопрос нам нужно что сделать нам нужно сделать ухудшающий тест то есть мы включаем слабоумие отвагу и просто замедляем весь сайт и смотрим сколько денег мы будем терять августа Вот и какие у нас ожидание что мы э допустим жили в моей решили сделать тест для для в котором у нас замедление сайта будет на 100 секунд мы его сделали дальше Мы ждём что мне такие упали вниз значит к нам идёт бизнес говорит о том что it вы просто красавцы вы экономите намного денег Респект и уважуха Однако же на самом деле если мы запустили этот эксперимент в реальности в мае на 100 секунд то данный могли быть такие что JV наоборот пошёл вверх и типа как так вот а так может быть потому что просто в то время в котором мы включили На что сделали эксперимент наш у нас пошёл Высокий сезон бизнес стал прокачивать маркетингами акциями пошёл дополнительный тайф И за счёт этого больше и получается так что у нас нету ответа как мы можем изменить эффект нашей фичи с замедлением Что же делать Как измерить и на помощь к нам приходит команда обтестов с девизом слабоуми отвага и контрольная группа Итак что нам может помочь нам может помочь конечно же обтес в чем суть AB теста в том что как обычно мы включаем замедление на 100 миллисекунд только группу всех наших пользователей мы бьём на две одна из них это контрольная группа в которой мы не включаемся медленнее и оставляем их как обычно есть вторая группа это группа слабыми и отваги в которых мы берем части юзеров и просто включаем на них замедление не получается так что в одной и то же время есть две группы которых мы можем брать бизнес медики и по окончанию нашего эксперимента мы можем посмотреть значимые отличия Вот и сделать вывод о том сколько денег тебе и мы от того что замедляем скорость нашего сайта и о чём здесь очень важно кто эксперимент важно сказать о том что мы не можем просто так взять и сделать эксперимент перед тем как эксперимент Нужно обязательно аналитику считать Сколько времени Его необходимо вести иначе Вы можете видеть что метки будут пока значимые отличие а на самом деле не будет в аналитике это называть подглядывание что нам нужно уметь делить юзеров быстро в порции где часть из них будет видеть фичу часть у них не будут И третье что по окончанию эксперимента нужно посчитать метрики и посмотреть Было ли значимое отличие и чем интересен эксперимент тем что те ожидания которые у нас есть что мы сейчас включим медведем сайта бизнес начнете деньги как мне друг о том что Женя это херовый пример потому что очевидно что бизнес будет терять деньги на самом деле это не так если вы сделаете себе эксперимент на определенные количество секунд вы можете быть удивлены что на самом деле бизнес не теряет деньги и поэтому нужно сделать экспериментов которых вы будете делать разные время и вы увидите что будет время после которого бизнес начинает терять деньги это время есть эластичности скорости ответа который вы можете найти и знать ту планку до который ваш бэкент не должен падать иначе у Вас начнется ваш личный ваш личный Армагеддон о том армагеддоне который был у нас я расскажу далее ну и если Вам эта тема интересна то вы можете Открыть книгу которая на экране главу номер пять что все-таки скорость значение имеет Итак В чем особенность обтестов это очень интересная область потому что находится на пересечении трех областей первая область эта область бизнеса потому что бизнесу нужно уметь измерять эффективность тех новых ячейка которые выпускаются продакшена также нужно иметь инструмент для проверки гипотез области этой области аналитики То есть каждый эксперимент который мы делаем его необходимо спроектировать то есть что нам надо сделать нам нужно определить ключевые той мы оцениваем наш нашу гипотезу нам нужно посчитать сколько времени эксперимент необходимо ввести также какой статкой термином нужно использовать для каждой метрики потом посчитать телевизор результат и посмотреть что с ним все в порядке У нас нет ложных докрасов Ну и конечно же дальше идет Техническая обувь нам нужно сделать инфраструктуру для того чтобы вся эта штука работала и на пересечении всех этих трех областей находится платформа AB тестов если описать основные составляющие в технической области то их есть две первые это нам нужно платформы спиртование то есть платформа который был тайме будет очень быстро сплитовать трафика в которой будет идти спрашивать Какие фичи включены для текущего иллюзия что мы это штука давала быстро чтобы мне были интеграции и так далее есть вторая часть в техни глупости это стенд метр у него специфика другая абсолютно Здесь нам не нужен вилтаем Но нам нужно за нужный интервал времени в дата лайки обсчитать метрики для всех экспериментов которые есть из разных источников данных и Для этого нам необходимо обрабатывать терабайты информации делать красивые отчеты которые смотрят бизнес для того чтобы понимать решение то о чем я буду говорить в текущем докладе поскольку нас тема связана с хайлоудом я пишу именно есть хайлоут и это будет платформа сплитование И узеров где же у нас то есть вы меня заключается в том что у нас каждый запрос на Озон идет некий шлюз так дальше этот шлюз практически сайт может таксироваться до 15 запросов бэкэнда и все эти 15 систем бкндов могут идти в платформу AB тестов таким образом если прикинуть порядок НПС который может быть платформе AB тестов той архитектуры которые есть есть у нас идет просто 30к РПС на наш Литвы то есть на сайт то на платформа бы тестов внимание будет РПС пол миллиарда то есть 500 тысяч полмиллиона был с миллиардом звучит намного круче полмиллиона и Это огромный РПС как же ставить нам с этим РПС мы узнаем Из нашего доклада где я пишу возможные подходы к архитектуре но перед этим что нам важно понять важно понять чего начиналось все и от чего мы стоили нашу архитектуру А как обычно все начинается с боли Вот и у нас была боль аналитика даже необычного руководителя аналитики и всея озона которого у которого как у каждого менеджерси уважающий blixel к так в которой были все эксперименты озона он смотрел в неё и думал что все отлично и здорово но как обычно то что происходит в жизни отличается от наших ожиданий как и то что есть конфликт бэкенда где были включены эксперименты которые очевидно Не начались никак и получается так что были продуктовые которые подпольным образом могли подключить этот конфликт делать эксперименты не прикол в том что этот конфликт был не один а их было два то есть один был типа для мобилочки и получается так что там это можно было подкручивать XL понимать никак И это была огромная боль э-э и для того чтобы решить эту боль как раз мы не стали делать нашу AB архитектуручку далее я опишу подходы которые мы используем во время той истории которая была но важно знать что это не просто история из прошлого это реальный паттерны проектирование который вы можете использовать в вашей платформе тестов и всё тем Какие ограничения у вас есть если начинать нашу историю про б архитектучку то конечно же наша история начинается с 90 А какая архитектура девяностых это безусловно архитектура прекраснейшего Монолита в котором У нас есть иллюзия который идёт в сервис авторизацией чтобы получить такие фронта дальше мы Для этого юзера определяем ключевую вещь в a/b-тестах девяностых его обо группу Что такое группа Мы для каждого его авторизация Рандом от по моему значения от 0 до 99 это указывает тот процент в который попал юзер Ну то есть он попал в первый в пятый в Двадцатый так до 99 в чем плюс что дальше мы на эту обои группу на тот пацан куда попал наш юзер можем делать лифчики на включение feech кэнд который отеки тащи всю компанию озона В общем все очень прекрасно вот ну и мы отдавали данный дальше Вы можете увидеть примеры конфига который было это реальный пример что указывает что он из 90-х что это xml-ка вот дальше Вы можете видеть что у нас есть ключ это типа фича флаг его имя и дальше Вал у нас указан интервала бы в которой для которых мы включаем это значение То есть если наш юзер допустим попал не знаю в 15b группу то мы включаем для него вариант один и включаем обыгрывал скип регион юзер мы включаем две этих фичи дальше от них меняем то отображение которые есть и получается так что мы с вами в девяностые из 90 конечно нужно перейти в современное настоящее время в котором У нас есть что модная мультисервисная архитектурочка Молодежная в которой я опишу ее на примере того как мы делаем отображение в мобилочке на странице PDP как я описывал что у нас есть юзер каждый запрос идет на Литвы который знает в какую именно бэкент необходимо пойти в данном случае чтобы отдать данные для станицы описания товара и он идет в Back and PDP это как раз сервис отвечающий за карточку товара он идет в рекомендательный чтобы внизу показать наши рекомендации также отзывы мы этот на своем первом уровне и этому бэкэнду для того чтобы данные Нужны еще данные про этот iPhone и товары которые рекомендуем и Для этого нам нужно обогащать данные ценными либо описанием для этого уровня где у нас идёт поход или продукт sedes таким образом вы можете увидеть как представлен общий поход молодежного архитектуры Давайте с вами представим что мы сделаем Если на этот подход мы нацепим архитектуру 90 который мы взяли из Монолита что мы сделали в первую очередь Конечно мы в каждый бэкен добавим Конфи как бы в монолите мы его добавили отлично потом мы пошли все авторизации Взяли бы группу отдали эту группу всем брендом дальше по всему локальному конфигу определил на бой включенных печей как-то отработал так в принципе так жить можно Ну какие есть минусы У этого подхода о том что у нас нету истории экспериментов то есть мы меняем конфликт в принципе можно пойти но аналитику это делать неудобно очевидно Особенно для каждого бэкента о том что мне нет возможности планировать эксперименты что вся информация в каждом и также что остановка и запуск новых ипов идет только через deploy backend что очень больно и пользователи неравномерно размешивается между спами какой же из этих минусов главное минус Конечно же это Real Time Ой ну еще что нету возможности питаться юзеров главный минус это минус Lil Time и получается так что как мы можем решить проблему Time для этого можем использовать опять-таки современный подход это какой подход который сделать нам настоящего то есть мы в нашей схеме добавляем сервис событий тестов которые будет оповещать все Ясный бэкенды о том что у нас либо добавился либо остановился либо были внесены каким-то изменения получается так что прикольная архитектура Какие минусы У неё остался на что нет фильтрации юзеров что пользователи неравномерно распределяется между экспоме что нет истории экспериментов невозможно планировать их и что информация инструменты развоознена Давайте обратим внимание на все эти три минуса получается так что мы их можем решить всего лишь одним патентом проектирования и этот патент синглете то есть что мы делаем в системе наши мы убираем конфиги у бкндов 1 2 уровня и переносим это все в одном месте все будет отвечать за XP это у нас идут в Озоне тестов и дальше как минус нашей архитектуры небольшое что теперь каждому бкнду чтобы взять информацию по своей группой нужно пойти Через AB тестов Какие же у нас есть минусы этого подхода То есть он прикольный но очевидно что у нас остается проблемы с тем что всегда неравномерно перемешивается между спаями что нет возможности фильтрации и теперь есть новый минус что у нас высокий FPS потому что каждый сервис идет за Испания Давайте с вами посмотрим как же мы можем решить одну из основных проблем аналитики проблему с тем что юзера могут не равномерно перемешивать между X спаями и за счет этого 11 может влиять на второй что мы можем сделать для этого для этого можем отказаться от глобального группы которые есть определять уникальную группу юзеров в каждом эксперименте то есть мы что делаем мы убираем поход авторизации уходит лишняя зависимость уже прикольно мы убираем эти оба группы и вместо них Передаем сервиса бы тестов идентификатор то есть в котором мы указываем его ID если он не авторизон мы можем дать уникальный идентификат девайса который он приходит дальше обтесты в динамике как мы это делаем мы берем идентификация добавляем некую уникальную соль для каждого экспобе берём остаток от деления на 100 и таким образом у нас в каждом XP у юзера есть свой процент если хеш-функция подобрана верно то все ваши э юзера между всеми эти спаями будут равномерно перемешиваться что обеспечить нам прекрасную аналитику Какие же минусы У нас остались минус с тем что мы не можем фильтровать юзеров А это нам очень необходимо если у нас есть необходимость включать инструмент на определенный сегмент юзеров которые мы с вами можем сделать и то что у нас на самом деле еще остался очевидно высокий FPS потому что все бэкенды всех уровней идут в теста как же мы можем решить эти две проблемы как об этом говорится место тысячи каскадных запросов патент Литвы то есть мы что делаем мы запросы убираем идем так чтобы гид вышел один раз в сервис AB тестов и брал конфиги для всех бэкендов но перед этим чтобы мы могли сделать условия нашли этого идет файл который дает нам информацию а бы тестов и аб-тесты на свои стране смотрят каким экспериментом удовлетворяет наш юзер оставляет только их и по ним уже отдают конфиги в Литвы дальше перед нами встает проблема о том что до этого каждый быкан сам брал Данный проект SP и теперь нам во все бкнды нужно как-то передать из Gateway информацию по всей эксперименты которые есть у каждого сервиса если это делать в лоб то нам нужно снести явным образом указать параметр с конфигом АБС и передавайте эту штуку в каждом запросе и получается так что это огромная переделка долго и смысла не имеет и на помощь нам приходит смекалочка с михалочка это как некий патент использовать глобальную переменную то есть мы все эти данные можем создавать каждому запросе как мы сделали то есть мы взяли самых в Хеды и каждый бэкенд искать нужно себе конфиг оттуда берет XP и как бы живем мы прекрасно и получается так что из минусов которые есть у нас остался один который уже не такой большой который был до этого это что нас все еще остается высокий НПС потому что каждый запрос на сайт идет платформу AB тестов и Давайте же решим как мы можем справиться с этим большим НПС для того чтобы ответить на этот вопрос Давайте посмотрим на наш Full добавление экспериментов и он у нас сделал так что у нас есть продуктовом который идет специальную админочку веб-интерфейсе где он добавляет информацию эксперимент это информация уходит в контроллер и обконтроль очевидно ту информацию данных Так откуда можем Дать данные но если мы будем обращаться базу данных на каждый запрос очевидно это Epic Fail это будет наша узкое место и мы будем отвечать долго Поэтому мы добавили еще один Киев это CD в чем его кайф что это Киева на Который наш бэкенд Может подписываться на его изменения то есть типа это наш и как сделано что AB тесты подписываются на все изменения То есть это CD информация их прикранивается локальный кэш и получается так что на любой Запрос который к нам идет у нас все находится локальным кэш и мы быстро можем отдавать информацию что это нам обеспечивает обеспечит нам ключевую вещь любого хэллоуна это горизонтальное масштабирование то есть чем больше у нас становится FPS вы просто тупо добавляем поводов и живем отлично то есть не нам любой СТС не страшен архитектура типа идеальная что же мы с вами забыли а Забыли мы-то то без чего не может не могут жить обтесты это без нашей прекрасной аналитики потому что нам нужны данные отправить в аналитику Давайте посмотрим какой Full озона отправки данных аналитики значит как мы уже смотрели У нас есть бэкент который пошел он взял данные что сделал отдал на мобилочку дальше юзер тыкает на мобилочку идут ивенты мобилка накапливает эти ленты Бачи и дальше отсылает их дальше третья каждый вент который ему отсылает вилочка обогащает информацию пойти эксперименты в которые попал юзер То есть он идёт в a/b-тесты а/бесный модуль nfp XP и дальше уже трекер ивенты с явным знанием про то как какие были включенные эксперименты дают в дата Лейк что мы имеем мы имеем теперь дата лейки что у каждого ивента есть инфопосты которые были включены И тем самым любой аналитик и может легко анализировать любой эксперимент что и делает стенд метрик Какие же у нас минусы получается так что минусов нет И как сказал бы не что клянусь ты джом что их нету Почему именно Stage Давайте Ну то есть в принципе я бы доклад мог оканчивать сказать том что все Удельная архитектурно у нас остается вопрос и этот вопрос чбд Что было дальше то есть наш доклад не оканчивается Так а что могло быть дальше А дальше был Армагеддон То есть тут стэтч которым я только что клялся он упал у всего озона и получается так что настал прекрасный день в который встал весь Озон мы наши задачи не можем и все стали искать в чем проблема и получается так что наши архитектура очки все-таки остался один минус И это минус связанный То есть как было чтобы дальше Как вы могли видеть больше И когда их стало типа много то мы привычные ограничения на 4000 килобайты дальше что был бум то есть наш Stage взорвался и Слава Богу что истеч потому что еще бы чуть-чуть и упал бы весь и тогда мы стали думать что же нам делать Но для того чтобы понять в чем именно была проблема И почему мы вышли за ограничение в 4 килобайта Давайте чуть-чуть окунемся в том что было в этих для этого мы представим что у нас есть два сервиса поиск и корзина в которой есть эксперименты поиски есть эксперимент атрибутом Linkin LG типа Sting То есть это алгоритм ранжирование которое мы включаем в эксперименте я оценим Ну и В корзине был булевские атрибут показывали мы новую или нет и получается так что если мы для этих двух передаём данные входы то мы конечно же передаём прекраснейший жизнь солнца избыточной информации чтобы у нас было имя поле чтобы это всё было в стоке значения скобки и также у нас есть масса личная информация проводить эксперимент потому что нас на бэке в принципе интересует это значение атрибуты как здесь поиске Алга что мы используем новый как и в ньюкасе что мы включаем ее и получается так что если X становится больше то Джейсон сильно растет и у нас все становится очень плохо с двумя минусами которые описан на экране Что же делать Что же делать мы думали и подумали что нам нужно этот же сон убирать и до этого была починка проблем что мы сделаем этот Джейсон сократили просто тупо воюет то есть место огромного джейсончик у нас стандартное количество байт который мы Передаем как же мы это сделали сделали Мы так что когда идет в аб-тесты а б тесты вычисляют этот джейсончик конфиг и дальше Потому уникальным виду который мы сгоняли в abts тогда обычно и дальше уже бэкен с этим хэдлом идет в аб-тесты а б тесты теперь идут дополнительную зависимость этими видами кэш тут большой конфиг из этого конфига дают данные и получается так что в принципе это решение проблемы с которым можно жить из тех минусов которые у нас есть том что у нас есть высокий РПС что до этого данный браслетов идем в тесты и также есть доп в зависимости от кэш в зависимости это больно то есть мы думаем что мы конечно но когда идёт с тест не обходима масштабировать И это тоже нужно уметь готовить и получается так что мы опять таки жили Но мы же не можем жить просто так Потому что есть руководство вот все приходят руководители говорит оптимизируй оптимизировать оптимизируй оптимизировать оптимизировать оптимизировать и дальше нам нужно как-то эту штуку оптимизировать чтобы мы могли просто иметь супер идеальную кристально чистую архитектуру И для этого мы придумали решение и как об этом говорил Жак перее что Все новое это хорошо Забытый стая и поэтому Ключевая идея этого подхода что мы опять всю инфу будем передавать в чем для того чтобы избавиться но тебе зная тот Армагеддон который был чтобы он не наступил Мы подумали что нужно бороться и придумать настолько сжатый формат данных информацию чтобы мы не упирались ни в какие ограничения и получается так что для этого мы придумали определенный формат данных я пишу дальше и также для того чтобы нам нужно сделать конечно упадет Итак что же мы придумали А мы придумали бинарной информации сжатие данных я вам покажу на экране то есть что мы придумали что у нас есть которые мы отдаем под ID нашего сервиса дальше у нас есть 4 бита которые мы отдаем под номер ревизии что это такое после того как у нас идет любое изменение в эксперименте мы меняем номер ревиз и дальше этот номер весь идет наш Back and если он изменился то мы инвридируем наш кэш и дальше пополняем его то есть тем самым мы решаем одну из ключевых проблем войти навигации у нас будет прямой и дальше у нас остается битвы маски с вариантами в которых юзер попал в данном бит и за счет этого наш вот этот огромный Джейсон в бинарном виде очевидно 64 хоть такую прекрасную компактную строку который очевидно есть ограничение чтобы мы не попали в наш Армагеддон это ограничение на то что те сервисы которые могут использовать этот бинарный протоколах может быть не больше чем полторы тысячи то есть для этого у нас запас огромный мы имеем ввиду текущее ограничение Как же это устроено У нас под капот мы убираем кэш и дальше у нас идет архитектура в которой идет в обтесты могут бинарный протокол дальше Литвы этот бинарный ключ отдает бэкэнду 1 уровня 2 и дальше что мы делаем мы кэнде смотрим если в каше данные поэтому ключу или нет Если нет то мы идем в тесты легко по этому бинарному ключу понимают Какие включены то есть абы тестах мы этот формат докодировать чтобы взять инфу про XP дальше информация и таким образом что мы сделали мы сделали Так что до этого одна из проблем которая была что у нас был большой LPS для сервиса 2 уровня И теперь я попрошу вас посмотреть на экран и представить что будет если мы уберем эту ширму насколько наша оптимизация поможет и насколько ИП станет меньше Я думаю что вы уже подумали У вас есть своя картинка в голове и 321 мы убираем эту шину и видим что НПС вообще фактически нету то есть здесь одного бэкенда это было 5к и потом P стал типа 510 То есть фактически мы этот ТПС не ощущаем и конечно получается так что это успех платформы тестов и вот это уже архитектура чистая и Кристальная как догадываетесь что вот и только здесь важно сказать что опираясь на то что мы видно наши архитектуре у нас были интересные открытия которых я скажу далее Итак о чем сказать важно чтобы могли остановиться опять-таки на том что прекрасно наши архитектуры Но для того чтобы успех а бы тестов этого мало И помимо скорости ответа что нам важно нам безусловно важна быстрая интеграция что если к нам приходит любой клиент можем буквально за 5 минут сгенерить для него уникальный клиент который может использовать и это обеспечивает то что что мы можем обхватить абы тестами любой бэкэты на это не нужно много времени Итак Какие же есть подходы к интеграции Одна из основных проблем которые есть о том что AB тесты отдают данные нечеткой структуры дают некий Джейсон потому что мы тем что у каждого сервиса могут быть свои эксперименты где атрибутами каждого из них может быть свой Тип и поэтому у нас нету как бы для каждого строгой типизации данных и получается так что если мы стоим напиху типа на интерфейсе с gson то есть в мире гошки это вообще типа зашквар вот и так делать нельзя вот и что же мы можем сделать для того чтобы уйти от этой проблемы и тут на помощь мне пришел мой друг Ой а где Да авто минимака Максим чечень который говорил о том что если что-то можно сгенерировать то надо это сгенерировать и получается так что мы для каждого можем генерить для него уникальный контракт который мы будем работать Давайте посмотрим например Значит у нас есть как обычно есть идея допустим поиски отодвинуть новый алгоритм идет ребят надо срочно отодвинуть новый алгоритм бэкент отвечает ему семью сейчас все сделано Что же он делает он идет в отдельную специальную админку где он идет свой сервис и добавляет параметры которые будут участвовать в тесте в нашем случае мы идем дальше дальше мы знаем про тот набор атрибутов который есть у сервиса просто в гошке одним нажатием на клавишу гениальным клиент который будет обрабатывать равно ту структуру которую мы описали в админочке то есть там у нас было linkinal Go вот у нас есть в типе в конфиге также моего отдаем в методе config и за счет этого мы можем обеспечить супер гибкую удобную интеграцию в которой вообще не нужно думать ни о чем и когда я иду навстречу мне описывают о том что интеграцию с платформы тестов делать типа две недели две модемы за пять минут показываю как они могут с нами интегрироваться Тем самым у нас один У нас есть быстро интеграции за счет этого бэкенте интегрировано больше более 150 о чем стоит сказать еще о том что обтесты это не просто платформа Это не просто бэкен А В первую очередь для того чтобы у вас был успех в a/b тестах вам нужно менять процесс в вашей компании и для этого необходимы сделать регламент обтестов которым вы описываете что нужно чтобы все что вы делаете было измеримо чтобы все фичи которые ходят просто не шли через AB тесты для того чтобы выйти данные могли анализировать Вам необходимо чтобы продуктовом сделали и метрик по которым они будут оценить эксперименты и все это ведет к тому что наша платформа AB тестов ведет к дата дизайн то есть оно идет к тому что все решения которые принимаются компании основываются на данных на тоймеримости которые нам обеспечивают и конечно здесь вам важно не забыть Что нужно чтобы была отдельная команда валидация BTS потому что все аналитики пытаются чуть-чуть приукрасить результаты которые есть чтобы мы шли к боссу показывали что сидят наверх чтобы нас неволе получается так что команда валидации вас от этого спасает Какие же можно сделать рекомендации на основе этого доклада что нужно стараться максимально упростить архитектуру которая у вас есть даже если для этого нужно упороться как в мультивар что мы придумали бинарный протокол это нужно делать независимо от той системы которую вы проектируете и у нас на этот счет были очень интересные исследования которые вы можете увидеть статьи которые вчера вышел на хобби где описано как мы будучи уверенными в платформе абы тест архитектуре доказали команде о том что проблемы с тем что мы отвечаем долго не в нас а потом клипе который был в Озоне и благодаря этим исследованиям и наши вообще из команды мы нашли решение не уменьшила рам 3 в 997 раз о том как это было сделано вся история указана в статье поэтому можете смело открывать телефоны фотографии если вам понравился мой доклад ставить лайки потому что я участвую в конкурсе если статья наберет много лайков мне будет прекрасный приз который Я дам свои любимой жене что дальше дальше важно думать о пропускной способности который у вас есть иначе наступит Армагеддон который был у нас Используйте коды генерацию Если это возможно мне эти процессы иначе у вас компании будет об этой тестов и конечно же Для всего этого необходимо учиться поддержка вашего руководства и в конце Я бы хотел сказать тем людям перед которыми низкий поклон это команды платформы abts которые есть аналитики заднюю и продуктовые это те люди без которых не был бы столь прекрасный архитектурой и хорошего продукта Большое спасибо вам за внимание в конце есть ссылка статью на Хаба и также очень прошу вас чтобы вас не мой доклад для того чтобы я знал над чем необходимо поработать вот ну и также можете посмотреть статью на отлично дополнять Все то что я описал Надеюсь что доклад был интересный Спасибо вам вы лучше аудитория которая была в жизни жду ваших вопросов Спасибо за доклад и у нас есть вопросы вот я первый увидел прямо здесь а не первый Привет зал Георгий хочу вопросик задавать коротких Вопрос номер один насчет мультитентности в группах насколько пользователь может попасть в кучу обретестов сразу И как вы потом отскребаете аналитику по вот этой множественности И второй вопрос сразу Почему городить свой бинарный протокол со статичным форматом с ограничениями если можно использовать например связать почти 2 Используйте пак для компрессии заголовков не смотрели в эту сторону Спасибо большое за ваш вопрос отвечу на первый вопрос и как аналитике можем анализировать то что юзер может одновременно быть мог получается так что у нас на самом деле эксперимент есть одни XP которые мы можем это пускать спокойно с всеми инструментами дают в Озоне и благодаря наших функций которые использованы все окна также есть XP которые в одно и то же время запускать не можем допустим у нас есть эксперимент на главной странице на которой мы в одном XP на верхней полке показан один блок в другом на верхней полке показан другой блок и получается так что данный момент в этих пойти не могут я об этом накладе не описывал для этого у нас есть у нас есть он все XP которые находятся в рамках одновременно два эксперимента и у этого есть уникальная соль Ну и тем самым добавлении эксперимента определяем Нужно ли чтобы он был в определённом Лагер или нет Если нет то мы спокойным можем перемешивать его за другими и спамии дальше Смотрите аналитику по ним из нашего дата лайка Отвечая на второй вопрос сейчас он был про то что не думали Мы использовать какой-то стандартный бинарный протокол который есть в http2 здесь идея в том что мы-то познакомились можем Но сколько будут весите данные которые нам в него необходимо положить нам нужны данные то все XP которые сервис попал юзер и получается так что не один протокол на мне обеспечит это так чтобы это было супер компактно и для того чтобы это было супер компактно У нас есть особые алгоритм Да как мы это все можем шифровать и в кейсе который мы бы это делали явно мы оценили эту наш объем данных был бы сильно больше Следующий вопрос Спасибо за выступление вот у меня тоже пара вопросов есть первый это касательно того когда через вас проходило полмиллиона РПС а была ли какая-то у клиентов из-за этого дополнительная задержка связанная с обработкой собственно говоря б тестирование и второе больше методологический вот как Вы определяете наверное определяют аналитики но все равно есть ли какие-то ограничения сколько респондентов выбрать для тестирования которое там явно может быть негативным к примеру там насколько повысить задержку что они начнут отваливаться потому что это всё-таки уже будет потеря для бизнеса в этот момент если вдруг они реально там трёхсот миллисекундные задержкой значит отваливаться не могли вопрос Повторить ещё раз Ну вот допустим изначально группах но каких-то тестированиях невозможно сделать равные группы просто потому что это будет нести слишком большие убытки Например если вы там на 50 процентов пользователей делаем Пинг там плюс тысяч миллисекунд то бизнес принесет большие потери вероятность из-за этого вот как с такими ограничениями вообще работаете кто их устанавливает Да я вопрос понял Ну и получается что отвечает на первый вопрос был про то что вот у нас было 500к РПС значит было сделано так что поскольку у нас тот бэкент который у нас шел их было в начале не сто пятьдесят А меньше тот изначально был меньше и у нас был тот график на котором я показывал да вот эту историю где был большой так вот и в кейсе в котором мы бы остались архитектуру которая была НПС был бы больше и мы бы умерли то есть могли спать это железом используя горизонтальным масштабильно но за счёт того что мы сделали клиента кэш то у нас количество стало сильно и таким образом как бы остался но он стал идти в кэш Вот и за счет этого все стало отлично"
}