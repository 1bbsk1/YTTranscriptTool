{
  "video_id": "SaQDP-JMlBI",
  "channel": "HighLoadChannel",
  "title": "С чего начать внедрение Hadoop / Алексей Еремихин (Badoo)",
  "views": 947,
  "duration": 2679,
  "published": "2017-07-30T00:47:27-07:00",
  "text": "я хочу навести порядок в головах чтобы люди поняли что такое и что им такой про продукты вокруг ходу также для чего собственно не только ходу не продукт вокруг него вокруг него можно использовать на примерах именно поэтому с чего начать внедрение hadoop в компании структур доклада достаточно вы не какой-то их страны структур доклада на экране я расскажу какие задачи я предлагаю решать с помощью ходу по на начальных этапах я расскажу что такое ходов как он устроен внутри что есть вокруг него и расскажу как году применяется в баттл в рамках решения задач с первого пункта clicker задачи хранения данных на самом деле как правильно тут данила подольске сказал никому не нужно хранить данные всем нужно читать данный вопрос только сколько времени вам потребуется для того чтобы прочитать эти данные если они были записаны там год назад два назад задача чтения архивов данных это давайте следующий слайды будут собственно про это задача по очереди там уже про каждую конкретную задачу расскажем первой задачи хранения архивов во-первых данные нужно хранить долго чтобы уметь их читать нужно хранить год-два-три вот нужно хранить нужно предполагать о том что за год 23 откажет железо может отказать диск может отказать сервер и данное желательно не при не потерять на что да и желательно обязательно не потерять объемы данных растут по примеру группы бей в компании bada я знаю что у нас данные растут каждый год в два раза меня пугает цифра просто до ужаса я просто знаю что через год у нас будет два раза больше данных и соответственно хранилище для этих данных нужны масштабируемые и нужно предполагать что она будет расти но и как видите объект содержащий единицу информации предполагается файл можно использовать другие способы на файл это универсальный способ хранения обработки передачи информации присутствует почти во всех операционных системах именно поэтому файл картиночка нарисована это архив министерства обороны самое главное отличие их архиву от тех архивов которые нам нужны и это то что их архивы читает единица мы как бы должны читать архивы массово данные должны читать что как бы хочется от читалки архивов чтобы она позволяла как-то унифицирована читать разные логе потому что логе могли собираться в разное время и разными системами исторические данные менять как как правило достаточно долго и сложно альтеры какие то делать так как объемы данных большие соответственно предполагать что данные нужно читать параллельно но там если вы там 100 мегабайт и почитаете разливаете данные из них вытаскивать у вас там это занимает несколько секунд а если вам нужно разрисовать несколько терабайт ну вот здесь вам уже придется параллели цели бы вы сами будете параллельно либо среда будет это делать за вас и как бы если ваша среда уже позволяет вам параллели ца это здорово и сквозь доступ это вот честно применяя заказ quelle самый универсальный язык для доступа к данным и для решения различных задач и с данными важно понимать что искали ты не только таблицы это в целом в трактире так верил english все что можно описать там в виде таблиц или чего-то похожего на таблицу можно описывать запросы к этим объектам в на языке sql это не что-то новое так думают многие поэтому а про задачу чтение архивов как я уже сказал это задача раз параллель cipro читать быстро и уметь быстро обработать что значит быстро обработать это нам например собрать какую-то быструю статистику сколько данных была отгребать отфильтровать какой-то какого-то юзера какую как какую-то сессию с данных просто найти нужный кусок в большом архиве сделать из него маленькую выдержку вот как отдельная подзадача число уникальных событий когда к вам приходят десять миллионов пользователю с 10 миллионов уникальных соперников ну вот собственно это нужно тоже уметь делать и было бы здорово если бы система это могла делать то есть это еще одна задача именно получение статистики то есть когда из большого количества данных получается немного уже таких значимых данных также отдельная задач конечно разбивать по параметрам планками как правило нужно узнать из каких городов события пришли из каких стран событий пришли завидным все зависит от системы который вы проектируете и четвёртая задача 4 задача это подготовка данных она более хитро она похожа конечно же она тоже связана с обработкой данных чтением данных но самое наверное главное отличие от предыдущего пункта если в предыдущем пункте мы я предлагал там быстро байтов данных доставать килобайта данных то здесь я там предлагаю и старо байтов данных доставать например мегабайта данных или гигабайты данных то есть вы храните очень-очень много данных и вам нужно предоставить какую-то систему которая на выдержках из этих данных может работать ну как пример он сам внизу написаны решение задачи рекомендации вам нужно посмотреть кто что с чем покупал и выдать рекомендации к какому продукту нужно рекомендовать другие продукты то есть у вас есть логе кто что покупал но эти самые самые логе еще достаточно бесполезны потому что нужно сделать связки продуктов вот и получается то что для того чтобы связать продукт и между собой их нужно связать через непосредственно логия покупок и задача сводится к тому что нужно взять в очень много данных которые есть как правило там чем произойдет декартова произведения этих данных на какую-нибудь ерунду до данных станет еще больше а потом вы сделалось просто какой-то выдержку которую положит положите в морской эльф с грейс quelle вообще в любое хранилище который может обрабатывать не очень большие объемы данных хорошо и будете с ним работать на 110 пункт пролетел это такая штука из мира bio extract transform лаут по большому счету просто перекладывание данных когда вы данные берете с одного места приводит и к нужному виду и кладете в другую базу данных как правило там это сбор с нескольких баз данных в одно изменение форматов каких-то соглашений опять же вот под эту задачу тоже очень хорошо ложится es que el но опять же не как язык который вернет нам немного данных а как язык который может в котором можно скрыть ты был с select и там будет уже много данных то есть вы создадите себе таблицу собственно вот четыре задачи первое это чтение данных и 3 задачи про обработку данных вот эти самые задачи я предлагаю решать решить с помощью hadoop х тут наверное не единственное предложение на рынке которая позволяет это делать но из-за концов снова бесплатного и решающего все три задачи верны единственное что особенно конференция называется highload ходу он такой из мира бингата как хай-лоу соотносится с bigdata ну по большому счету для того что когда highload начинает писать слоги для обработки этих логов уже нужно bigdata вообще когда-то это очень широкая область машинным обучением с какими-то семантическим анализами с кучей всего и отдельной конференция по этому делу проводятся и hadoop это наверное не примерно атрибут чуть не каждого доклада в области big data проект карту по стартовал он как видно в 2007 году как у концертная открытая реализация идей предложенный гуглом еще в 2004 году названный мой предус мы определился это такой способ организации алгоритмов когда вы определяете две небольшие процедурки мы привезли обработки данных и эти процедурки уже по большому счету запускаются за вас то есть это такие call бейки которые запускаются в куче место с параллелями обрабатывают большое количество данных для ты именно способ организации алгоритмов потому что сам определюсь это не алгоритм сортировки поиска или еще чего-либо это способ ему такой паттерн проектирование алгоритмов так вот как открытая реализация идеи предложенный в 2004 году углом в 2007 году появляется ходу как мы придешь и проект развивается развивается развивается обзаводятся кучи проектов вокруг себя связанных сильны связанных слабо и в частности в ядро ходу по попадает для ходу по проектируется и создается распределенная файловая система из dfs собственно в этот момент hadoop начинают подходить для решения задачи хранения данных везде fest распределенная файловая система которая но она не пасек совместимая конечно же не пустяк совместимая вообще про файловая система будет доклад в этом же зале прям сразу после меня файла система позволяет хранить очень очень много данных но не очень очень много файлов то есть вот предполагается что в ней будут лежать большие файлике и данные будут писаться туда условно говоря один раз то есть перезаписи данных не предусмотрено и вторая часть ходу по изначально называлась мапри диска обработка данных сейчас ходу вырос буквально там года полтора назад идеям определился вообще код написанный для определился распался на две части на явно мимо previews yarn это это на за ресурс снега шейкер это такая штука который собственно отвечает за запуск задач на куча машин то есть управляет ресурсами вычислительными ресурсами кластера и просто знает и просто передает задачи на выполнение она не знаю какие задачи передаю там определился уже непосредственно задачи которые запускаются чуть поподробнее прочь dfs вот просто файл это кусок данных с именем наверное самое точное определение файла и вымени можно все что угодно если вы добавите слышен например в имя файлу вы получите идей директории и при проектировании с dfs они как бы сразу подходили к деве того что система должна быть отказоустойчивый то есть данные должны храниться в на разных серверах на разных дисках система должна быть распределенной чтобы можно было там легко добавлять и удалять новые сервера устройство очень простой то есть файл представляется в виде имени и его содержимого содержимое разбивается на набор блоков по умолчанию 64 мегабайта но можете указать свой и данные получается в виде списка блоков вот дальше я service name not который просто помнит из каких блоков состоит файл про сами блоки не знает ничего мы просто помни то что файл это блоки abcd и помнит и знает на каких хранилищах data not 1234 эти самые блоки хранятся вот как видите на картинке каждый блок хранится в трех экземплярах вот три жёлтеньких 3 зелененьких три фиолетовых это означает что фактор репликации 3 если коротко то это означает что можно потерять 2 любых сервера и даны все равно че будут доступны и можно будет их восстановить и добавить еще копий файлов фактор репликации в ходу в отличие от многих файловых систем он по файловый то есть вы можете сказать что вот этот вот файл для меня очень-очень важен и я хочу чтобы мы его точно не потеряли и поэтому я хочу чтобы его блоки лежали вообще на всех серверах кластер поэтому в этом случае вы выставляете фактор аппликации равное количество серверов в кластере и получаете положившись на использование диска также повышенной отказоустойчивость то можете сказать о том что вот этих данных у меня очень очень много и они в принципе как бы мы потеряли потеряю не так часто теряют данные факторы репликации выставить один но потеряете часть данных мы вроде как выживать опять же зависит от вашей задачи как эта штука для решения задач hadoop это не вещь себе это не галочка которая надо повесить эта штука нужна для решения задач что с кликером а собственно те кто работает систем linux как правило проблем работа с ходу помни и исполни испытывает потому что команды для работы с файлами найти более менее все те же самые наверху вы их видеть в комментировать по большому счету ничего вот есть специфичные ну тоже очень очевидная команда из серии положить локальной файловой системы на удаленно файловую систему забрать данные обратно с и требует установить фактор репликации и текст это сказать ходу потом что у меня файлик и лежат там в разных форматах зарипова на и разгибаем них пожалуйста дай просто увидеть текст и я не хочу там сам по расширению файла догадываться каким архиватором разрисовывать это из командной строки конечно же api работа с данными при непосредственно внедрение то есть вот это вот с командой строке работает нам разработчики обмена когда работает руками как правило все таки работа идет через api hadoop написано джаве и поэтому open конечно для вас к но есть классная штука называется выбусди fest это это тупой растопи обертки есть уже по моему для всех языков то так что не как везде где есть url у вас есть доступ ходов это удобно собственно вторая часть связана с обработкой данных это треть вторая третья четвёртая задача как я уже говорил это на за ресурс не мешает мы принес что я могу сказать принципу устранения такой же какую из dfs есть мастернода которая рулит всем подряд и есть ног менеджеры это демоны запущенные на каждом из сервировка на которых вы хотите обрабатывать данные и они прознают сколько ресурсов осталось на данном сервере просто говорят на у меня еще есть ресурсы может течь еще запущу для внедрения вот это наверное всего знать не надо просто показываю как устроена собственно вот здесь закончился центр ходу по то есть есть такая штука hadoop ком он называется вот hadoop common это по большому счету распределенная файловая система и определил фреймворк вот мы определяем word предполагает о том что вы взяли джаву и стали писать на джаве под под этот фреймворк оптимизировать свои задачи для тех кто предполагает хочет от ходу по что-нибудь еще должны взять что-нибудь еще один один из старых проектов и в то же время со стабильной хороший является hive вообще вот этот желтый слоник он вокруг хода по всем ется вьется вьется различным способам михай в переводе с английского это улей поэтому так как слонику не мигрировал в челку идеях айва было собственно предоставить доступ к файлам лежащим в езде фасе в виде иску или то есть любой лак более-менее структурированный можно описать каким-то способом можно сказать о том что это джейсон там лежит можно сказать о том что это запятыми данные разделены тогда получается там commence a comma separated values csv можно сказать о том что там пробелом разделены какие-то способы структурирования данных и как и задать именно для этих частей данных вот сейчас мы очень сказал на этом слайде я просто расскажу о том что песку эль доступ к данным осуществляет в первую очередь hive другие проекты тоже есть но они единственные вот как я уже сказал сколь удобен и с точки зрения вытащить пример данных из точки зрения собрать какую-то статистику потому что у вас есть аккаунт и макс но различные реагирующий функции вот есть группировка вот а также es que el в виде crate ты был с select подходит просто для преобразования данных как пример стянутый туториалов к его это как распарсить apache axis lock на самом деле формат который лежит логе apache акса слог называется комбайн format комбайн плуг и самый простой способ для х его его описать в виде регулярка то есть вот внизу увидите регуляр очки такая есть вот просто регулярка писали что у вас лежит строке и сказали о том что первая часть это лежит хост 2 the identity юзер time что что записали в логе что описали в регулярке то и видно регулярка это наверное самый неэффективный способ описания данных потому что регулярное выражение будет применяться к каждой строке и это достаточно накладная операция в то же время я бы сказал наверное один из самых гибких способов для доступа для описания данных собственно какая пятая строка снизу она описывает что именно регулярка и будет парсится в конце видно то что это григгс сердце вот сергей это сериал о зельде сериала и зарыта штуку которую это java class который который для х его описывает как распарсить строку в данные как из данных снова сделать строку мы по большому счету для доступа к данным вы делаете создается таблицу такой виртуально говорить о том что она лежит по какому-то пути в офисе и все вы можете уже делал select из этой таблицы и получает свою статистику что случилось с кликером а я рассказал сейчас про hadoop common и про hive это два таких продуктах вообще вокруг ходу по есть много различных приложений систем и можно их попробовать разбить по категориям по управлению данными то есть это файлы ресурса это то что вы распределяете вычислительные ресурсы фреймворк это то что организовывает вам вычисления то что запускает ваши там мапперы режиссера или какие-либо другие приложения и собственно приложение это когда вы уже как пользователь под не пишите пишите хотя бы sql для обработки данных вот желтеньким отмечены это то про что я вам рассказала т.е. dfs йаран mapreduce streaming чуть-чуть попозже про него тоже расскажу все остальное зелененькое то все отдельно стоящие продукты какие-то продукты предоставляют только фреймворк какие-то предоставляют управление ресурсами какие-то являются полноценными то есть они занимаются просто обработкой данных например вич беседки и вылью хранилище которые просто свои данные своей файлик может хранить в издеваясь файлы файловых систем тоже куча забавных можно сказать что необязательно данных хранить выжди фесе пардон их можно хранить просто на диске просто всегда для организации вычисли нить эта система когда-то в ходу пи кто-то ввёл использовал забавная слова экосистему и так называли все продукт имеющие отношение к ходу по я нашел списочек где перечислены 150 различнейших про продуктов и систем имеющих отношения к дубу среди них и системы сбора данных и машинное обучение sql новый сквер ищите подходящие продукты под ваши задачи я не знаю какие у вас задач я рассказал самое базовое те которые есть кто-то мне говорил что есть другая какая то классификация там 300 продуктов существует вокруг hadoop но как я уже сказал hadoop это такое слово которое описывает очень часто всю экосистему все продукты все это семейство вот теперь немножко ходу бы в аду зачем вам эти цифры могут оказаться полезными цифры могут оказаться полезными в той точки зрения что ходу пам масштабируется достаточно ленина то есть если вы предполагаете объему даны в два раза больше вы просто умножаете цифра на 2 если вы планируете объемы данных два раза меньше вы могли выделить цифры на 2 естественно все это имеет отношение к задачам потому что зависимости от задачи которые вы решаете вы будете упираться в различные вещи кто-то будет упираться все кто-то будет упираться в процесса кто-то будет упираться в производительность дисков ничего обещать никто не сможет не только я никто не сможет просто прикидываете смотреть кластер на самом деле небольшой 15 серверов собственно все написано почему два сервера подготовки данных потому что буду располагается в двух дата-центрах один находится в праге другой находится в майами вот в каждом дата-центре мы подготавливаем данные это значит как вы собираемся всего дата-центра все то что мы хотим положить в ходу взади полого и мужа между до центра мы передаем заархивирован ими зархи раваном видя объему данных которые мы собираем написаны здесь в принципе вот платному сервера в каждом так центре стоит там получается что приходит 1 гигабит трафика то есть по большому счету скоро начнем операцию в сеть моим наверно с каждым до центра стоять еще по одному серверу что еще интересно вот файлов и блоков похожее количество файлики мы специально делаем не очень большими потому что большие файлики в заде полном виде читаются очень плохо расскажу чуть чуть попозже средний факта репликации 275 они 3 просто потому что у нас есть большой кусок данных которые мы реально не очень боимся потерять вот но просто приятно его имеете тратить на хранение двадцати терабайт смотреть получается вам нужно сохранить 20 терабайт вас фактор репликации 3 значит вы должны подготовить 60 терабайт дисков если вы решаете поставить фактор репликации 2 у вас тут же появляются лишние 20 работ дисков это вкусно данные обязательно сжаты потому что у нас все самое наверное используемая самой проблемной вещь это именно объемы данных это была первая задача то есть вот это слайд это про хранение данных про то как встроенную распределенная файловая система это первая задача про хранение данных вторая задача 3 задачей 4 задача это про обработку данных инструмент который используем использованием hive spork-и еще используем streaming если нужно просто подготовить какие-то данные например раз в день собрать суточный счетчики пользователей еще что-то используем hive для ручного доступа для ручного анализа hive тоже подходят как бы какой бы базе данных написал и вскоре получил результат можете сразу какие-то визуализатора прикручивать потому что по-моему у него или джей би би си далее прикрутили есть у нас такая система она есть нас в компании система старой она еще организовано на rrd нос и в том что хранит так называемый time series time series это когда вы хранить какое то значение во времени и чем как бы ближе к нас сегодня вы хотите тем более детальные данные вы хотите знать то есть например данная за сегодня вы храните в разбивке упомянуть данные за три года назад вы храните в разбивке хотя бы по дням то есть вы увеличиваете в целом вот штука называется time series вот чтобы кормить time series хранилища нужно собирать данные и собирать какое-то значение за последний день или за последний час но с два основных окна в принципе мы с разными ватными работаем вот для такого онлайн совсем процессинга его часто называют рилтайм и real-time в мире ходу по это значит то что вы что-то сделали в течение 5 минут это не совет совсем you real time мы используем spark spark когда-то появился как еще одна реализация mapreduce потому что как бы ходу был отчасти монополистом на рынке и хотели создать ему альтернативу сделали в парк и парк отлично вписался в экосистему hadoop в общем вошел семейства там mais quel доступ есть там и streaming есть там и машинное обучение в спарке есть это такой еще один комбайн который вокруг себя всякой ерундой обрастает streaming это такая маленькая штука которая входит в ходу в ком она позволяет писать мам определил задачи вообще на любом языке вот хотите на баш и напишите на баше организация очень простая вы передаете ему две утилиты которые на вход принимают то что было прочитано из dfs и на выходе сов на то что вы хотите получить ну про организацию мапри views я надеюсь что либо вы знаете ли бы вы выучите потому что промо принес мне потребуется еще примерно час рассказать как он настроен и формат который мы используем джейсон это все пары это два основных формата tab separate от используем когда мы точно знаем какие столбцы хуков каких логов мы хотим хранить и никаких сложных данных них не предвидятся джейсон ужин на тот случай когда мы хотим хранить абсолютно все в одном был в одном блоге но данные нужно как-то структурировать потому что в зависимости от типа записи вы хотите видеть разные столбцы разные типы что туда можно на самом деле можно сделать вывод как бы что-то никакого не сделают ерунда просто советы вот вот слайд просто советы это где-то грабли на которой мы наступили где-то то что нам очень сильно помогло в процессе внедрения ходу по и что то что может быть вам полезно когда вы скачаете как когда вы придете танк себя в компанию и вдруг начнете внедрять ходу просто такой полезный слайд который вам даст кучу подсказок а хранить данные дом чуть-чуть расскажу про него нажимайте данные естественно данные лучше сжимать вот нету хорошего или там единого универсального алгоритма сжатия который бы подошел всем вот все три алгоритмы они разные g zip он жмет средний быстро и вообще универсальный формат используется очень много где вот если б д 72 с ним сравнить вот bzip2 он требует в 10 раз больше процессора коэффициент сжатия у него там процентов на 10 всего то есть на 10 лучших процентов на 10 лучше очень тяжелая штука но самое главное отличие между гриппом у гриппом то что вот если вы взяли один терабайт за типа валеева чтобы его прочитать обработать вы на самом деле возьмете его самого начала этого закованного терабайта и будете его читать вы не сможете запустить второй поток который считается середину вот если взять формат bzip2 его можно читать середины и ходу победив большой файлик попытается его разбить и читать в несколько потоков или зато штуку которая практически не есть не ест процессор но жмет хуже чем gzip и есть какой-то еще атрибута из-за то то что он бывает индекса ты тогда его тоже можно разбивать как deep нарезается данные нарезайте на файлы но опять же как это связано но в принципе с архивации если вам если вы все данные за один день положили в один большой файлик за zippo валеева гриппом вы никаких раз параллельных вычислений не получите вы получите одно ядро которое разлитого это второе ядро которая парсит содержимое файла это два ядра с там 150 вы получите чем больше файликов тем больше потоков вы можете запустить собственно какого размера файлики вот тут написано что размер файла это несколько блоков тоже не совсем правильно правильно сказать о том что как бы если у вас есть минимальный набор в данных с которым вы хотите работать например один день то вот файлов в этом одном дне у вас должно быть столько сколько у вас я der в процессоре это наверно самый оптим в озеро в кластере это самое оптимальное описание нарезайте в директории по дням часа многие продукты не смотрят на имена файлов они достаточно просто игнорирует и поэтому сказать о том что у меня вот файлики называются 2015 05 22 то сегодняшнее число они не могут вот но можно сказать о том что данные за 22 числа у меня лежат в этой директории 2 данный за двадцать первого числа у меня лежат вот в этой директории в этом случае вы сможете описать не храните данных в пути файла скажем так если вы храните да если вы хотите получить доступ к данным который лежат в пути файла вам часто придётся очень сильно велосипеде проще эти данные положить прям внутри файл в каждую строчку backup тина им но дунаем на дубы кафе это не опечатка это правда на им надо это единственная точка отказа hadoop кластера на за которой нужно следить за которой нужно ухаживать и потери и и приведет проставленной полной потере данных то есть вы записали 150 терабайт данных молодцы у вас есть т-50 продать мусора что у меня а чего не надо делать не надо запускать ходу на слабом железе это первые три пункта его можно запустить новые при этом получить и куча ограничений если вы возьмете и запустите все на одном сервере ну вы не получите ни избыточности ненормальной распараллеливание масти ничего если у вас маленький проект вам и вы хотите его поставить каток не нужно для одного маленького проекта это иллюзия на одном сервере можно поставить все но тогда вы получите например довел или какое-то тестовое окружении меньше 1 гигабайта памяти до демоны ходу бы они просто при старте живут там достаточно приличный поэтому если у вас есть один гигабайт памяти на сервере да вы сможете запустить ходу но какие тяжелые вычисления уже в принципе не сможете сделать если у вас есть сервера с кучей дисков и слабыми процессорами вы можете организовать хранилище но это именно будет хранилище они они читали щи то есть по большому счету данное оттуда сможете читать но эти сервера не будут участвовать в работе данных маленький проект невыгодно ну опять же если у вас маленький проект та самая идея поставить четыре сервера под hadoop кластер может оказаться кому-то показаться очень странной в то же время если в вашей компании много маленьких проектов вы все данные этих проектов можете объединить в рамках одного ходов кластера что еще одну из того что надо делать если ваша компания существует на рынке уже лет 5 как правило остаются какие-то сервера которые просто стоят стоят в стойках греет воздух и их надо утилизировать а утилизировать это как правило просто деньги еще требуется бизнес они их не утилизируется готовы можете утилизировать их ресурсы добавив ходу по ходу достаточно хорошо принимает слабое железо в пласт выводят с кластера так что можете продлить жизнь старым сервером вот старый сервера часто отказывают нам как я уже объяснял ходу по в принципе это не важно потому что году к этому готов когда проектировался для систем где работают тысячи серверов и поэтому там отказ или одновременно и простой одного двух серверов это абсолютная норма больше расстроило это то что в ходу пенетрат разноса под дата-центра чего бы нам очень хотелось но вы нет не стоит на это рассчитывать три книжки по ходу по все три на английском возможность перевода на русском не знаю это реально книги которые нужно считать вместо мануалов потому что мануалы не всегда хорошие книжки отвечает на гораздо большее количество вопросов 1 это ходу где finiti в гайд она нужна всем тем кто работает с ходу вам так или иначе вас снизу две книжки этом определилась design patterns и ходок operations вот левая книжка для разработчиков права и для админов если вы занимаетесь и тем и другим то читай тебе ну все собственно спасибо я рассказал время как раз моя подошло к концу очень удачно вот собственно жду ваших вопросов за вопроса какие книжки кем мы раскрыть вам дадим на стенде здравствуйте менее михаил зовут опыт применения ходу бы у нас есть компании вот но он не совсем удачный хотелось бы узнать с чего вы начинали до скольки можно вообще попробовать начать серверов какое должно быть железо чтобы его как бы ну скажем грамотно применить они просто на одном сервере до вопрос без описания задачи бесполезен hadoop это средств для решения задачи опишите пожалуйста задачах хорошо мы у на мы разрабатываем rtb систему и у нас в принципе данных для обработки довольно много вытекает у нас где-то 250 300 миллионов запроса в сутки соответственно мы должны хранить анализировать эти данные вопрос наверно как лучше хранить мы пробовали хранить их ваш basic сначала сейчас я услышал что вы храните файлы ну давайте мы встретимся потому я я так чувство этот разговор просто не на пять минут не на 10 вы более подробно расскажете про задачей может быть я там смогу чем-нибудь помочь давайте рошел взять заклада спасибо за доклад вот эти вопросы советы которые выдали чего не делать они относятся также ко всем альтернативным там обнаружим продуктом в сфере ну в экосистеме фату по но с точки зрения требований по железу да они все ожидают достаточно как в 2015 году это не очень мощное железо там в 2008 году это уже считалась там достаточно мощным железом просили а как hadoop ведет себя при балансе ну когда то есть ульта этом две ноты и потом добавляется там значит восстановление отсутствующих блоков то есть идет рассуждение на уровне блоков то есть достаточно ли у блока находится копий вот если в копий не хватает в течение примерно пятнадцати минут тайм-аута настраивается течение 15 минут начинается создание новых почему делается тайма потому что вы могли просто перезагрузить какой-то сервер и создавать копии еще рано если вы ввели какой-то сервер сервер говорит у меня есть куб копии блоков вы получаете оверы плетей шин то есть когда у вас копи блока больше чем запрошена в этом случае не нужно и копий блоков будут удалены балансировки уже существующих данных по серверам регулярный нет нужно запустить скрипт который сбалансирует но наверное вот ответ про balancing вот еще один вопрос или же здравствуйте нина такого практически вопрос вы написали что нужно было бить на и моду еще раз это повторили а можно ли и нужно ли при этом останавливать будет ли она доступна организм бы к пану и потом recovery нга есть два наверное способа первый это дело три года регулярные копии просто файлов на диске то есть бы копить на им надо это не что-то волшебное то просто забирать копию данных с диска регулярно причем вплоть до того что в предыдущих вот уже нет слайдов в ходу поперек шанс это достаточно хорошо описано то есть вы файлы с по нфс монтируется там данных передается немного это файлы по нфс еще забирайте на второй диск вот и делайте бэкап из двух дисков при переключении вы просто запускаете на и моду на вот на том месте где была копия нфс есть проект high availability hadoop который позволяет там с минимальным downtime переключать на им надо из коробки никаких a high availability решение нет здравствуйте извините пожалуйста а вы сказали что разнесение по 2 дата-центром не существует из коробки а как вы решили проблему тогда мы положили все в одном дата-центре до данные в каддафи у нас не дизайна recovery это правда ну мы пересылаем возможно возможно что мы сделаем эту потому что все больше и больше внутренних проектов и смотрите ходу появился как решение задач маленькой группы там из десяти человек который занимает системы бизнес-аналитики нужно было собрать много данных можно было получить с них статистику регулярно вот мы сделали поняли что у нас в руках есть мощная технология реально мощной технологии которые просятся в бой и мы обнаружили в бизнес еще кучу задач которые тоже решают который тоже можно уже решить на той на обкатанные технологии на уже обкатанный на этих новый которые мы используем и мы готовы с ней работать собственно вот так появилась куча данных так как проект генерал эту кучу данных они достаточно пилотные поэтому мы не боимся данные потерять мы собственно как только проекта становится уже достаточно значимо мы под него уже предполагаем дополнительные ресурсы докупаем железо дизайнер recovery наверное пока ни один из проектов не затребовал вот возможно сделаем здесь пожалуйста на еще раз вы видели то есть существуют и решили которые делают ходу где за старика вы их нет существует в принципе я видел что у некоторых компаний то есть вообще дистрибьюторов ходов есть очень много можно взять hadoop из торцов на сайте apache вот а можно взять уже какие-то решения от hartan works at клал дыра вот дистрибьюторы в ходу по их там штук 20-30 который представляет hadoop как правило в рамках каких то проектов в рамках каких то проектов если я не ошибаюсь то это у dat ass такса есть при интеграцию с системами а не какой то вот дизайнера защиту какой-то защиту от катастроф предоставляют"
}