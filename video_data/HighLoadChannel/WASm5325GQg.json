{
  "video_id": "WASm5325GQg",
  "channel": "HighLoadChannel",
  "title": "SOA: послать запрос на сервер? Что может быть проще?! / Иван Круглов (Booking.com)",
  "views": 5375,
  "duration": 2947,
  "published": "2017-06-28T07:13:22-07:00",
  "text": "Всем привет Ну я уже поздоровался Всем привет кто смотрит трансляцию Я Ваня Booking.com Давайте я вам ещё раз тут я уже успел немножко рассказать ээ повторюсь ээ Вы наверно слышали про компанию Booking.com слышали что мы много экспериментируем часто плом се и вообще мы не Тестируем плом без тестирования и Может вы ещё где-то слышали что у нас один по сути один большой репозитарий на 4 Гб в нём 4 млн строчек первого кода И вообще у нас монолитная архитектура вот в то же самое время BC меняется нельзя сказать что это прямо такая кардинальное скачкообразное изменение Но вот медленно но уверенно мы меняемся У нас меняется стек мы постепенно внедряем Яву в тех местах где это актуально и в том числе термин сервис ориентированная архитектура со слышится всё чаще и чаще во внутренних дискуссиях Какие плюсы мы видим от перехода на сервис ориентированную архитектуру первые три слабая связанность Независимый деплой и независимая разработка они как бы обще понятны Я не буду на них более подробно останавливаться Давайте сразу перейдём к четвёртому четвёртой - это быстрее онбординг вообще в в компании когда находится в фазе интенсивного роста теме быстрого включения сотрудника в рабочий процесс нового сотрудника уделяется достаточно много внимания и сервисно ориентирована архитектура тут нам может помочь за с снижение сужения и фокусировке нового сотрудника на какую-то определённую меньшую область То есть ему проще получить знание про какую-то отдельную часть как бы э а всей всей системы и Последний пункт пятый быстрее разработка он как бы подытоживая все остальные то есть от перехода на сервисную ориентированную архитектуру А мы если не столько сколько э убыстрить сможем разработку Но по крайней мере сохранить текущие темпы за счёт меньшей связанности ээ компонентов это про плюсы чего У нас есть с минусами значит минус номер один снижение гибкости тут под гибкостью я понимаю гибкость в в перераспределении человеческих ресурсов Ну например если в монолитной архитектуре для того чтобы вам внести какое-то изменение в код вам нужно обладать знаниями о том как работает там какая-то большая область Да чтобы внести там изменения и не сломать что-либо и При таком подходе получается что перебрасывать человека между проектами становится просто потому что с большой долей вероятности вот тот человек в новом проекте он будет уже знать достаточно большую область Да ему будет проще то есть и то есть как бы с точки зрения менеджмента система получается гибче в в сервис ориентированной архитектуре получается Всё как бы немножко наоборот Потому что если у Вас например там в разных командах используется разный технологический стек то там переход между командами Может может быть эквивалентным переходу в другой Компани где там всё совершенно может быть по-другому это как бы менеджерский минус остальные минусы технические это сложность внесения атомарных изменений атомарных изменений Не только как бы в данные Да но мы теряем то есть в распределённой системе мы теряем возможность транзакций и плюс атомарных изменений в код на Ну один комит на несколько репо растя следующее это как бы сложная отладка Ну распределенную систему фундаментально сложнее отлаживать элементар там Элементарно у нас нет никакого де багера куда можно куда там встать и посмотреть куда мы пойдём дальше Куда полетят наши данные следующие Куда полетят данные в следующем шаге и например Элементарная задача там анализа логов У вас есть два сервера для того чтобы понят есть логи и т есть логи Элементарная как бы задача помани вот этих вот логов чтобы понять что к чем относится это как бы сложно и в общем получается что в сервисно в сервис ориентированной архитектуре инфраструктура в целом сложнее появляется много поддерживающих компонентов Ну например там нужна распределённая система логика нужна распределённая система трейсинг Вот про это всё более подробно вам расскажут коллеги из Авита и и Хантера ихние доклады следующие с разум за моим Если вы хотите более подробно знать вам ничего не надо делать Просто посидите в зале следующие там 2 с по часа свой же доклад Я хочу сфокусировать на ещё одном минусе который называется rpc процедур Call он истекает из того что если в монолитной архитектуре нам для того чтобы там позвать какую-то сделать какую-то операцию нам достаточно было позвать какую-то функцию А в соло нам нужно делать удалённый вызов тут сразу хочется сказать о чём я буду и о ЧМ я не буду разговаривать я не буду рассказывать про взаимодействие Букин Кома со внешним миром это не фокус моего доклада фокус моего доклада - это внутренние компоненты букинга и как они между собой взаимодействуют более того если взять гипотетический сес consumer и Service провайдер Да в котором у нас наш Application через библиотеку клиентскую библиотеку через транспорт взаимодействует с сервером на сервис провайдере Да и обратно и вот мой фокус именно вот э тот фреймворк который обеспечивает взаимодействие вот этих двух компонентов История одной проблемы хочу вам рассказать э одну историю и тут э я ещё раз сошлись теперь уже на свой доклад архитектуры поиска Booking.com который рассказывал на этой сцене полгода назад там я рассказывал как э развивалась э поиск Booking.com и на одном из этапов Мы решили сделать свой самописный Map produse Framework это вот выделено красным цветом и Давайте чего у нас как этот mwk э должен был работать на входе у у нас должен был быть поисковый запрос который прилетает на мастер ноду мастернода делит этот запрос на несколько под запросов отправляя на воркеры воркеры выполняют какую-то там свою работу формирует результат отправляет обратно на мастер то есть ну классический маюс на воркера выполняется фаза Map на редьюс на Мастере выполняется функция reduce это то Как оно должно было работать в теории Сейчас мы посмотрим как это должно было как это работало на на практике на практике у нас не было Вот это вот иерархии То есть все воркеры они были равнозначные и когда у нас прилетал какой-то клиент он рандомным образом выбирал Кеме в данный момент Work 4 этот вокер в рамках вот этого запроса становился мастером он делил он делил этот запрос на подзапрос и также рандомно выбирал себе как бы в под мастери Ну например вот второй и пятый воркер со вторым запросом тоже самое рандомно выбираем первого первый делит отправляет на третий и на пятый но была такая особенность то что вот это вот дере дерево как бы запроса оно было многоуровневой и пятый воркер мог в свою очередь тоже решить поделить свой запрос несколько под запросов и он также рандомно выбирал себе в под Мастере какие-то ноды Из этого же кластера и так как ноду выбирались рандомно могло получиться Так что он берёт и выбирает ноду первую и ноду вторую как свои как бы подд подд мастери и тут я надеюсь видно Я попытался это изобразить то что у нас между воркеров которых может быть не быть так вот так делать не надо это плохо это рецепт катастрофы которая собственно гово у нас в определённый момент и случилось Чего случилось в определённый момент у нас в кластере запускалась Цепная реакция из-за которой все машины покидали кластер в течение 5 минут ти Ну вот Яме помню Я участвовал в этом прекрасно помню как список всех машин вот так вот он просто так и ВС и в кластере машин не осталось кластер впадал в Deadlock То есть если мы даже из него убирали то есть мы на кластер убирали входящий трафик и он оставался вот в этом вот заблокированном состоянии для того чтобы вывести Вот это состояние нам нужно было постать все машины в кластере вот прямо все это был единственный способ Это по-живому по-живому потому что мы не знали в чём причины нашей проблемы и мы мы не могли то есть точнее так мы боялись переключить трафик на другой кластер на другой дата-центр потому что боялись запустить Ту же самую цепную реакцию Ну то есть как бы выбор был между потерей 50% трафика и 100% трафика Ну мы выбрали как бы потерять 50% трафика Вот и тут я вам хочу э рассказать и объяснить что что происходило и я решил это сделать через демонстрацию сразу хочу сказать то что демонстрация не на 100% отражает вот прямо что происходило в той системе потому что её уже нету Мы уже от неё отказались в том числе вот в виду архитектурных проблем то есть мой как бы сетап максимально близко Элит но не полностью Ну как бы ключевые моменты отражены плюс я буду объяснять и объяснение будет упрощено в целых простоты понимания и и просто экономии какой у нас сетап Ну значит на стороне сервера у нас 24 воркера за у нас mro с 96 керами и смешанная CPU workload вот там два параметра list по 2048 пока как бы примите как данные вы поймёте Почему они здесь важны на стороны клиента у нас простой хттп клиентский Тай в 500 мсн и клиент посылает много маленьких Много мелких и среднего среднего размера запросов и демонстрировать я вам хочу это с помо А и все мои демо Бут проходить по одному тому же сценарию то есть вот на графике то есть будет утилита который будет посылать запросы на серверы будем смотреть как сервер реагирует на них И это утилиту то есть будет прогин сценарий то есть здесь как бы три основные вторая фаза когда примерно до 4000 запросов в секунду вот на второй фазе У нас вот этот вот выделен зелёным зелёным цветом зоны это вот самое интересное это та зона когда сервер достигает точки на освещение интересно посмотреть как он в этот момент реагирует и потом третья фаза - это когда мы смотрим Как сервер реагирует после точки насыщение когда запросы там вырастают до 7.000 запросов в секунду вот демонстрировать я вам это всё буду с помощью тузы самописный я буквально на днях я её зарезал её можно поискать у меня на гитхабе вот так она выглядит что тут есть значит самое первое - это гистограмма результатов запросов за последние 10 секунд да то есть каждая звёздочка - Это значит что какое-то количество запросов завершилось успешно и е - это значит То что какое-то количество запросов завершилось ошибкой слева временные интервалы от нуля до примерно 1но секунды и тут такой момент то что шкала логарифмическая да то есть дельты то есть разница между интервалами не неравномерные И сверху выделено жёлтым это текущий требуемый rps так Ну давайте начнём демо готовы да поехали значит смотрим вот мы начали с 2500 запросов в секунды количество растёт 2800 2900 видно да нормальное распределение то есть где-то в районе 5 миллисекунд теперь в районе Когда у нас сервер подходит к зоне на освещение запросы постепенно перетекают в более запросы становятся более медленными видно они перетекают перетекают перетекают и потом в резкий момент в определённый момент происходит резкая градация качества обслуживания и все запросы все запросы ушли они ставили все ошибочные да то есть всё стало плохо система упала ждм когда мы пом до 7000 в секунду и всё демо у нас Почти закончилась и видно да то что у нас как бы в результирующей состоянии у нас появилось как бы ну то есть 100% запросов по фейле причём Они они чётко разбились на две категории на медленные фейле который вот там в районе полсекунды занимает и на очень быстрый который занимает примерно одно секунды почему так происходит А сейчас я вам хочу по шагам рассказать что происходило я буду повторять части вот этого Дема сначала объясняю что там происходит А да забыл сказать Значит это вот если посмотреть на графики запросов то вот выглядят они примерно так да то есть количество ответов запрос в секунду видно да то что в определённый момент произошёл как бы качественные изменения то есть в определённый момент у нас все все все положительные запросы сменились на все отрицательные и время ответа 99 перцентиль существенно деградировал что там происходит значит м с того как система обрабатывает запросы в нормальном состоянии когда она не под нагрузкой ещё раз уточню то что объяснение упрощено Значит у нас есть ngx на входе у него на вход он получает какой-то запрос в нём есть какое-то количество воркеров 24 и запрос проводит в к какое-то время Ну пока он там обрабатывается далее делает Connect на macro W в нём тоже есть какое-то количество Ну конкретно 96 и вот э запрос вот эти воркеры макро это собственно говоря перловый процессы естественно Мы тоже там проводим какое-то время А ну которое собственно говоря сумма вот того времени которое мы провели в никсе и в ма это является суммарным временем ответа который мы видим а О'кей теперь я повторю вам часть демки сначала первую часть значит вот мы начали э мы сразу Я немножко Укоротил мы сразу Подходим к зоне деградации то есть наши запросы медленно перетекают в более в более медленный тут пауза да то есть вот сейчас это пауза поставлено в таком интересном моменте потому что Если обратить внимание на количество inflight запросов то количество запросов которые происходит прямо сейчас их 94 А я напомню то что у нас 96 воркеров то есть на Да у нас 96 Маров именно в этот момент происходит качественная то есть происходит существенная деградация качественного обслуживания То есть у нас резко все запросы переходят в очень медленные и всё в итоге завершается ошибкой да то есть я здесь также поставил на паузу что происходит возвращаясь к диаграмме значит когда у нас запрос попадает в eng на самом деле в первую очередь он проводит какое-то время в очереди которая ассоциирована с tcp с tcp сокетом которая есть на входе кса да то есть вот мы провели какое-то там время далее когда worker кса коннектится к макро даю запрос также проводит какое-то время в очереди ассоциированной с к сокетом macr и э суммарное время на самом деле суммарное время запроса на самом деле складывается Вот из этих четырёх компонентов но тут есть такая особенность то что вот NG X Ну это очень хорошая отличная программа обеспечения Он очень быстрый Кроме того worker eng X они асинхронные Короче говоря nginx в состоянии очень быстро процеси Вот эту вот очередь которая которая у нас есть в tcp сокете воркеры Маро наоборот они синхронные это по сути первые процессы и Когда у нас количество тех запросов которые прилетают в систему начинает превышать количество доступных воркеров то есть они все заняты начинается формироваться очередь начинает формироваться очередь в Юни сокете и вот в сепе я вам Я вас акцентировал Ваше внимание на вот там было два параметра backlog 2048 и liston 2048 вот они определяют длину вот этой очереди то есть вот в данный момент у нас ВК сокете когда Закончились все воркеры начинает формироваться очередь она будет длиной до до 2К до 248 И в этот момент так как запрос проводит значительно он запрос начинает значительное время проводить в к сокете просто вот Сидя в очереди и ЖД ждя своего шанса на то чтобы ке в mic освободился и начнёт его обрабатывать И в этот момент прилетает То есть у нас вот в этот момент прилетает 500 миллисекунд таймаут То есть клиент что что делает клиент он просто рвёт соединение но рвёт он соединение только до нса Да с точки зрения micr ничего не происходит это с точки зрения micr - это полноценно установленное соединение так как запросы маленькие они все лежат в буфере То есть когда там воркер освобождается берёт запись берёт элементы из очереди читает буфер То есть как бы с его точки зрения это абсолютный валидный вопрос который он продолжает выполнять и на слайд это не стал добавлять Но если в этот если в этот момент посмотреть на сервер то он будет на 100% загружен он будет Вот он будет продолжать обрабатывать вот эти вот Оборванные соединения Оборванные запросы То есть получается такое состояние что у нас клиент делает какую-то работу он там шлёт запросы но он получает 100% ошибок сервер же со Роны со своей стороны получает запрос он честно их описать пытается обратно отослать данные говорит этот ответ уже никому не нужен у нас есть Клиенты сервер которые друг другом как бы пытаются говорить но друг друга Они не слышат так вот Алло работай чтото перестало работать Следуй эп у нас деградировали все запросы в ошибочные и мы продолжаем расти э продолжили расти у нас количество запросов в секунду и у нас стали формироваться Что такое со с кликером запросов мало ребят кликер не работает Сделайте пожалуйста что-нибудь Ага ага Вот что тут происходит происходит следующее кеса пытаясь подкоренного ответ получается очень-очень быстро по сути ИС нужно только распарсить п протокол сделать конект на квы сот и всё вот и ну работай У нас ещё один кликер есть да давайте наверное другой кликер И тут я хочу вас вернуть вот к первоначальной проблеме и рассказать уже более подробно что там происходит происходит следующее значит по какой-то причине у нас какие-то воркеры стали медленны я не буду сейчас останавливаться более подробно почему они стали медленны потому что для этого мне нуже ещ один сомит доклад примите как данный про воркеры стали по какой-то причине медленны изза того что они стали медленные у них начинает заканчиваться вот эти воркеры в поэтому из-за этого они формируют перед собой очередь Теперь когда у нас прилетает запрос прита запроса клиента воркер первый шлёт запрос на пятый и ему вот этот вот запрос должен отстоять свою очередь Да после этого как бы Окей он как бы отстоял свою очередь он начал процеси пятым воркеров рвётся но пятый воркер Про это ничего не знает он успешно продолжает обрабатывать вот тот оригинальный запрос а воркер Первый он берёт и делает ретрай тот же самый запрос в свою очередь пятый воркер продолжая обрабатывая в нём тоже случается тайм-аут потому что мы отстояли очередь в первом Да он обрывает свой запрос и пятый War также делает ретрай Да я думаю понятно да то что если вот этот процесс продолжать раскручивать этот маховик Да у нас В итоге получится Так что вот вся система забита вот этими вот э запросами которые никому не нужны по сути получилась как бы такая система С положительной обратной связью И вот это собственно говоря и ложила нашу систему А теперь вот когда мы э дебажить э вот это вот вот этот вот случай который кстати заняла достаточно много времени потому что было совершенно непонятно что происходит Мы подумали А вот так как мы проводим очень много времени вот в этом никсом сокете У нас он очень длинный 2К элементов Давайте попробуем сделаем его меньше Давайте попробуем сделаем длину такую чтобы у нас в нём на каждый воркер приходился всего один элемент Сейчас я вам хочу показать демку Как ведёт себя абсолютно та же самая система с единственным изменённым параметром - это длина очереди сценарий тотже самый начина с также поднимаем 1900 3 3100 32 входим вот в эту зону Когда у нас система нестабильная запросы потихоньку снижаются вниз но они не деградируют то точнее так они деградируют но не так фундаментально то есть они буквально то есть система стабилизируется где-то в районе 40 миллисекунд да то есть вот сейчас система как бы то есть система продолжает обрабатывать успешно запрос у не Начинает появляться вот эти быстрые ошибки быстрые е и и дальше когда мы растём когда мы начинаем поднимать запрос ещё больше вот 5000 сейчас 5500 6 то система продолжает успешно обрабатывать какое-то количество запросов но при этом какое-то количество запросов фейли если про если посмотреть на графики то вот они выглядят так тут я думаю понятно что здесь есть то есть у на смотрите в определённый момент времени усе вст количество запросов которые она может успешно обрабатывать при этом Вот в тот момент когда произошло стабилизация начали формироваться ошибочные запросы вот эти ошибочные запросы - это собственно говоря то количество запросов которые система не в состоянии обработать в данный момент То есть получается так что у нас за счёт длины очереди мы система всегда возьмёт только тот Запрос который с большой долей вероятности будет успешно выполнен и получается по статистике Так что он этот э этот объём запросов он всегда фиксированный всё остальное система просто игнорирует она Просто говорит 002 ошибка типа я я не в состоянии вот это вот с этим больше э работать и вот третья фаза э Когда у нас начинает когда я начинаю резко задирать количество запросов система по-прежнему сохраняет свою работоспособность более того она сохраняет свой Quality of Service да то есть как бы вот на времени ответа девяносто девятый перцентиль он не растёт он ээ стабилизировался и э тут э как бы вот это то с чем мы как бы запустили э в продакшн Об этом я ещё расскажу Но вот готовясь к этому докладу я поэкспериментировать с длиной очереди и Получается примерно то что по сути длина очереди э определяет ваш по крайней мере в нашей системе она определяла а наихудшее время ответа вот если то есть на графике видно 9 центили Когда у нас например вот средний график это когда очередь рана 96 верхний 192 то есть видно что система стабилизировалась на чуть-чуть более высоком н но по-прежнему она стабилизировалась если взять попробовать запилить очередь там буквально в 20 то она практически вообще практически не растёт то есть раст буквально чуть-чуть на неско миллисекунд вот хотел вам показать И как мы решили свою проблему в краткосрочной перспективы мы взяли и снизили длину очереди Да что нам это дало в первую очередь нам оно условно разорвало цикл Почему условно потому что ну как бы цикл вот эта вот циклическая зависимость Она по-прежнему присутствует но а свойства изменились Дело в том что конкретный сервер если в нём нет Э достаточно ресурсов на обработку входящего запрос этот запрос будет просто порен и причём это будет сделано очень быстро то есть с минимумом накладных ресурсов А если с минимум накладных расходов А если в этом сервере есть достаточно ресурс то он будет принят То есть как бы вот этот цикл если если данный конкретно сервер нагружен о рвётся более того вот эти вот в первом демке вот видели то есть быва класса ошибок были и очень очень быстрые ошибки зелёные и очень медленные ошибки красные то есть вот за счёт уменьшения длины очереди мы все медленные ошибки перевели в ряд дешёвых то есть мы их сделали очень быстрым за это у нас стал дешёвый повтор то есть перестало повторяется такая ситуация то что когда Ну то есть когда мы ретра мы по сути ещё разгружаем какой-то второй компонент в долгосрочной пекти нам коне же было переть двухступенчатую архитектуру вот которая совпадала бы с логической архитектурой собственно говоря что мы сделали в следующей э итерации когда мы разрабатывали э замену вот этому поисковому сервису на этом а как бы с историей У меня всё но доклад не закончен далее Я буду рассказывать про э компоненты которые Если Вы у себя э хотите построить э предсказуемые систему rpc вот этот вот реворк в котором вы хотите увидеть предсказуемые поведение системы в каких-то граничных условиях Какие компоненты вам нужны и что нужно что нужно держать в голове при этом я не буду привязывать ни какому конкретному сервису буду просто рассказывать как бы вот что у нас есть какие подходы мы используем возвращаясь вот к диаграм которую я показывал в самом начале серс коню серс провайдеры вот кли Клин взаимодействи между собой мы уже с вами затронули таких два кирпичика которые ну нужно правильно настроить на мой взгляд это во-первых очереди на стороне сервера и во-вторых тайм-ауты на стороне клиента это вот на это диаграмму Я в дальнейшем буду добавлять другие компоненты пока вот пока у нас есть два компонента А смотрите вот у нас были вот эти вот в обоих случаях у нас были быстрые ошибки да то есть про медленные ошибки как бы мы уже Э мы с ними разобрались мы их перевели в категорию быстрых Давайте теперь посмотрим что с ними делать Ну тут есть тут Нужно рассмотреть два разных случая во-первых это что делать когда система находится в фазе насыщения Ну тут собственно говоря ничего не не поделаешь Потому что когда система в фазе в фазе насыщения значит то что Ну вот собственно горя У меня закончились ресурсы и ничего нового ничего больше нового Я не могу обработать Ну при этом я могу унести 100 кг Ну если вы дадите мне 101 то я не унесу Я просто оставлю и скажу я не понесу вот и это очень хорошие свойство потому что вот когда мы говорим с Вами когда то есть вот мы видели с вами поведение это по сути мы с Вами разговариваем про такие два компонента два таких очень важных свойства любого фреймворка на мой взгляд во-первых когда она делает Fail Fast Ну то есть когда если мы если у нас происходит какая-то ошибка этому мы делаем Это очень быстро и второе мы говорим про мягкое деградировать graceful degradation это когда система Какую Ну конечно нельзя сказать какую любые нагрузку мы не дали Но вот э при наличии какой-то существенной нагрузки система обработает только система всегда стабильно будет обрабатывать какой-то э процент запросов успешно то есть вместо того чтобы полностью крашиться как у нас было до этого там со 100% ошибок Да система успешно обрабатывать какую-то долю запросов Вот и второй случай который Нужно рассмотреть это что делать если Если наша очередь переполняется кратковременно это возможно ну вобще такой случай возможно Например если у вас там в сети Ну если у вас в сети например случилась какая-то задержка в ней скопились какие-то запросы и потом какая-то часть какая-то группа запросов разом прилетает на сервер менно переполняет это мы берём и просто делаем повтор и вот на нашу диаграмму как бы ложится ещё один кирпичик Давайте посмотрим чего важного в логике й в логике повтора вообще в моей практике логика й - это такой очень мощный механизм который позволяет вам в очень многих случаях выйти сухим из воды например вот на графике сверху это количество количество ошибок на стороне сервера А внизу Это количество ошибок на стороне клиента да Ну видно то что у нас сервер по какой-то причине он периодически генерирует не периодически а постоянно генерирует ошибки на стороне клиента мы ничего не видим то есть вот у нас достаточно часто случается Так что даже если мы имеем какие-то проблемы на на серверной стороне по любым причинам до клиента они не долетают из-за грамотного трая что важно иметь в виду когда мы говорим про Рей в первую очередь это конечно то что трайни должен быть бесконечным То есть он должен быть всегда ограничен каким-то бюджетом у себя Мы обычно используем три попытки второе - это то что безопасно трать можно только импотент ную операцию импотент операция - это та операция в которую сколько бы раз Вы не применяли результат будет один и тотже Ну например вот увеличение счётчика это не инная операция потому что кажды раз получатся разные результат когда мы отправляем ТТП запрос вот до того момента когда мы отправили данные на сервер то есть по сути записали в сот вот всё что произошло до этого это как бы безопасная операция потому что ну мы собственно говоря на на на сервер Мы ещё ничего не отправили Например если у вас там произошёл какой-то фейл Когда вы там пытались позвать ДНС адрес или просто там сервер не доступен То есть это это всё О'кей всё что произошло после тут как бы под вопросом под вопросом потому что ну по идее как бы по хттп стандарту у нас Get - это как бы Окей То есть это как бы только операции на чтение на извлечение данные они по умолчанию и потент когда мы делаем пост то не Окей это вот как бы в теории но на практике по-разному в зависимости от систему Например у нас есть ряд систем которые пишут там куда-то там отправляя вопрос поэтому тут как бы ну надо смотреть на конкретную систему что ещё важно важен такой момент то что быстрый повтор неэффективен в моей практике поясню например Представьте что у вас произошёл в сети какой-то Ну какая-то кратковременная проблема например не знаю там у вас маршрут перестраивается Вот и какой-то хост о стал недоступным буквально на какой-то короткий промежуток времени так вот если вы сделаете конект один раз Потом следом конект второй раз Потом следом конект третий раз То есть вы по сути вы как бы вы вы сожгём в течение нескольких миллисекунд и это как бы неэффективно То есть вы не дали никакого шанса системе восстановиться и тут Что обычно применяют это применяют так называемый Back Да И вот на нашу диаграмму положим ещё один кирпичик bof Что такое фкф - Это основная идея это то чтобы вставить попытку вставить между попытками какую-то паузу для того чтобы увеличить шансы на успех то есть мы даём как бы системе какой-то шанс то есть мы ждём на своей стороне надеясь что система сама восстановится есть мне известно несколько алгоритмов боков Но вот фиксированы это когда между попытками мы отступаем на какой-то равнозначны промежуток навы запрос 100 миллисекунд попытались второй Он тоже полился опять отступили на на 100 миллисекунд либо экспоненциально Ну думаю ту понятно То есть там первый раз делаем отступ там на 10 миллисекунд потом на 20 потом на 40 Ну и так далее и ещё один важный фактор когда мы говорим про боков это важна рандомизация вот этих вот интервалов отступа по-английски называется почему это важно потому что например Представьте что у вас есть к вам на сервер летит например там 100 запросов они вот прямо в один момент прилетают на сервер и они его э кратковременно перегружают то есть там все запросы Ну все запросы получают ошибку Теперь мы делаем отступ на 100 миллисекунд и те же самые запросы опять летят на сервер ситуация по сути повторяется потому что они точно также перегружают сервер а если мы возьмём и вот каждый сервер локально добавить некоторую к своему отступ получится Так что все вот эти вторые запросы Они они размажу по времени и запросы прилетят на сервер не разом То есть у сервера будет на намного больше шансов их э обработать у себя в букинге мы используем э экспоненциальный рандомизированный интервал вот примеры на экране э например вот э первый отступ у нас 53 мсн потом 129 потом 55 мсн Ну и так далее вот так про ф мы с вами поговорили ещё хочу вам рассказать про тайм-ауты на стороны сервера но я хочу вам рассказать про тайм-ауты на стороны сервера а точнее про согласованность таймаутов на клиентской и на серверной стороне то есть эту тему мы уже с вами немножко затрагивали то есть важно чтобы когда клиент отваливается у нас как бы сервер не продолжал обрабатывать вот тот вот запрос В современных фреймворка есть такой механизм как отмена запроса request cancellation наш фреймворк такими свойствами к сожалению не обладает поэтому мы сделали как бы такой обходной путь workaround А у нас клиент Когда летит на сервер он выставляет http header X booking Time Out mise в котором он говорит что вот Мой Тай вот столько-то после этого сервер берёт эти данные и он выставляет свой локальный Тайт свой серверный Тайт на основании клиента плюс некоторые дельты Ну чтобы там дать запросу долететь до сервер то есть теперь получается так что как бы Когда у нас клиент наприм отваливается через 100 миллисекунд то сервер у нас отваливается буквально там ну наприм через 110 миллисекунд То есть как бы запрос отменяется смотрите у нас как бы тут уже на нашей диаграмме пять пунктов и у них такая особенность то что вот эти вот эти они вам не нужны когда система работает стабильно они вам нужны когда ВС плохо как бы по сути как пы да то есть когда у вас пы в нормальной жизни не нужны Но когда о вам действительно нужны они вам действительно нужны и люди как бы ну есть люди которые бэкапы не делают и которые ещё не делают да то есть вот люди которые периодически восстанавливает и мы вот по сути для тех же самых целей чтобы тестировать весь наш тек мы используем маки да то есть насколько понимаю изначально эта идея была в том что мы берём каким-то Ну там берём и Выключаем дата-центр Смотрим как наша система реагирует Ну до такого масштаба Мы ещё пока не дошли у нас масштаб поскромнее но есть как бы такие интересные вещ про которые хочется рассказать у нас есть три типа Первое - это OS маки когда мы хотим проверить хттп клиент да то есть в этом то есть от клиента мы ожидаем особенное поведение Когда например к нему прилетает 502 ответ да то есть 502 ответ от NG Знаем мы это что дешёвый ответ поэтому клиент автоматически его ретрай чтобы вот проверить эту логику как определённый процент запросов берёт и выкидывает э там 502 или 502 ответ То есть он искусственно генерирует это по-моему у нас 1% Таких вот искусственно созданных ошибок и вот это всё работает в продакшене то есть вот мы реально OS маки Фет у нас один Флит 1% внутренних запросов для того чтобы убедиться что когда придут настоящий запрос система корректно их обработает второе более интересное второй тип osman более интересный мы пытаемся добиться что мы называем мягкое деградировал что это значит чит вот Представьте себе что у нас есть поисковая страничка поисковой страничке есть как бы основной функционал поиска Да который как бы ну вот это вот прямо наш основной бизнес и этот основной функционал обвязанной тоже делают удалённые вызовы так вот теперь если этот второстепенный компонент у нас пофлиртовать прилетела ошибка от какого-то второстепенного запроса у нас Мы не сгенерирован И для этого наш сервера периодически берут и генерируют чес ответы 00 ответ значит то что запрос был некорректно сформирован и поэтому п клиент пробрасывается его на самый верхний стек пробрасывается в Application который виден и такой механизм работает только внутри Компани потому что понятно да то есть если мы будем запускать это в бизнесе то мы мы можем поети конверсию что не есть хорошо и так как здесь мы реально говорим про фелинг какой-то каких-то части функционала У нас есть всегда список критических за запросов например вот то же самый основной поисковый запрос который в данной логике не участвует И последнее - это как бы этот вид киос манки Стоит немножко в стороне У нас есть э этол система когда к ней приходит Клиент говорит Вот у меня есть 000 записей дай мне их все но эта система она использует мускули для хранения данных может получиться Так что какая-то часть этих записей только Была записана и запись мастер ещё не успела долететь до слева да и соответственно периодически случается Так что когда клиент приходит там говорит Дай мне 1000 запи на там система говорит у меня 900 А 100 ещё нет потому что ну Вот потому что она долететь приди чуть попозже они там появятся и вот мы опять же с помощью механизма мы Тестируем Вот это функционал То есть у нас система генерирует корректный 200 ответ но Элия Элия логическую ошибку что какая-то часть какая-то часть записи просто отсутствует это тоже У нас работает в продакшене так возвращаемся к нашей диаграмме вот смотрите у меня уже должно было закончиться время далось буквально 2 минуты то что это то про про что у меня хватило времени рассказать на самом деле компонентов гораздо больше только из того что я знаю это на стороне сервера было бы хорошо иметь какую-то приоритизации за за опросов было бы хорошо на стороне сервера иметь троттлинг на стороне клиента есть такая интересная вещь как ccit Breaker Когда у нас клиент локально принимает решение не слать запрос на сервер для того чтобы просто сделать чтобы ваш там сервис коню знал с кем разговаривать нужна какая-то логика Discovery нужны умный Load балансинг И вообще нужно много чего ещё и это мы говорим только вот про как бы стек над транспортом А ещё есть куча всего внутри транспорта что нужно как бы правильно настроить чтобы система ваша работала предсказуемая заключение э чего хочется сказать предсказуемая отправка хттп запроса - это сложная задача э очень много компонентов которые нужно правильно атю неть все системы разные никаких серебряных пулей нету Короче говоря тестируйте проверяйте На мой взгляд это единственный способ как вы можете сделать так чтобы ваша система работала То есть пойти попытаться её поставить в какие-то граничные условия и посмотреть как она будет реагирует в букинге у нас нам пришлось немножко поизон не работаете поэтому вам повезло чуть больше Посмотрите на такие фреймворки как grpc и fle и если вам больше нравится прокси сервера то linkd сразу хочу сказать то что продакшн опыта у меня работа с этим системам нету как бы ничего конкретного порекомендовать вам не могу и последнее поэкспериментировать с очередями у себя на своём опытом мы поняли то что очереди может кардинальным образом менять поведение вашей системы что у нас произошло Поэтому Ну вот положите себе как бы на Запишите себе где-нибудь блот попробовать поиграться но пожалуйста не копируйте вот ээ вот этот пример берите опять же и проверяйте тут есть такой важный момент то что если вы хотите поэкспериментировать важен контроль над клиентом потому что у вас меняется поведение системы и важно также адаптировать вашего клиента и вот то что я вам показал работает только э с Когда у вас за никсом стоит веб-сервер который работает через unix Socket то есть IP Socket ведёт себя по-другому на этом У меня всё спасибо за внимание Спасибо у нас остаётся время буквально на два вопроса Сейчас мы попросим наших любезный девушек помочь нам с вопросами поднимайте руки у кого есть вопрос две два вопроса мы сможем успеть задать докладчику пока у нас Техническая небольшая пауза мы переодеваем микрофоны вот вопрос Что делаете когда количество параллельных запросов больше воркеров Ну слушайте если у вас Ну то есть у вас есть два варианта либо Ставить их в очередь либо фейли те которые не могут обработать то есть что соответственно Если ставить в очередь то при ограничени очере один запрос всё остальные запрос фейли Ну да то есть то есть смысл в том смотрите если ваше решение то что я хочу чтобы у меня все запросы выполнились успешно да то есть они встанут в очередь и в зависимости от длины очереди они будут там стоять они проведут там какое-то время теперь вопрос готов ли клиент столько ждать если клиент ждать столько не готов всего Скорее большой вероятности у вас получится Так что клиент сервер что-то сделает а клиенту это уже не надо он уже ушёл понятно Да поэтому есть смысл просто взять и в сам то есть в этом случае у вас получается клиент чего-то там ждал прождал там сколько-то секунд Да там и после этого он сказал типа ну всё короче я типа ушёл Да это одно поведение второе поведение Когда вы можете в самом начале сказать Окей клиент типа у меня короче вот в данный момент нет столько ресурсов поэтому поэтому нет я те не готов обслужить но этот этот ошибку клиент получит очень быстро То есть он не будет ждать он может там не знаю там попробовать в другое место сходить там на другую ноду либо ещё куда-нибудь спасибо И у нас ещё один вопрос Спасибо за доклад Я здесь Да я хотел задать вопрос Почему у вас 96 воркеров Вот и Равны ли количество воркеров количеству ЦП потому что переключение между процессорами То есть у нас 24 ядра 96 воркеров потому что как бы опять же установлено экспериментальным путём у нас как бы не миксит CPU I Load То есть у нас грубо говоря Если это было целиком только CPU bounded workload то количество воркеров равнялось бы количество ядер так как у нас есть немножко о то есть воркеры периодически ждут можно как бы сделать количество воркеров больше чем количество доступных ядер Ну вот Судя по вашей презентации вы в цпу упёрлись у вас 100% неэффективное использование процессора потому что у вас 90 воркеров 96 количество ядер у вас меньше не успевает система вызывать системные вызовы на переключение вот этого ядра на ваши два воркера Нет она то есть там есть определённая математи математическая составля кото нужно поть это потому что количество запросов много то есть смотрите у нас вот я показывал да то что количество запросов в определённый момент как бы выравнивать переходит в ПТО да то есть это вот то сколько наш процессор может обработать запросов в секунду потому что в нём есть как бы CPU составляющей то есть да мы уплисцихе на один воркер один процессор но у нас воркеров меньше чем сло процессор потому что есть ещё система которая это обслуживает Но это тема отдельного доклада"
}