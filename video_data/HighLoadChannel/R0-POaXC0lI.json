{
  "video_id": "R0-POaXC0lI",
  "channel": "HighLoadChannel",
  "title": "Использование Tarantool и UDP multicast для синхронизации нод очистки трафика / А.Барабанов (Variti)",
  "views": 573,
  "duration": 2615,
  "published": "2020-04-27T12:12:12-07:00",
  "text": "добрый вечер коллеги и тех кто нас слушают по трансляции меня зовут анна разработка нагруженных сервис уже более 10 лет за это время успел поработать почты и с поиском с базами данных немножко сейчас занимаюсь системами фильтрации трафика в основном это защита от ботов ну и как естественное следствие защита от dos-атак когда мы решали эту проблему мы самого начала про ставить задачи так что мы защищаем именно сервиса то есть мы не делаем защитой пи транзита да мы защищаем и чтить и pepe игровые сервисы таким образом мы терменируем трафик на е34 на уровне 70 цепи и паба своими а дальше значит от того мы не беспокоимся по поводу защиты 34 это все происходит автоматически потому что ну потому что мы эти терменируем соединение да все что ниже но остается соответственно на шторах всегда немножко сложнее полу сравним алексеем здесь у нас появляются во первых отдельные люди и даже приведения это бот вот и появляется структур кластер это сервера это сетевое оборудование соответственно в этом случае нам нужно разбивать трафик нам нужно смотреть на сайте и так как мы поставили еще одну задачу мы не блокируем по ip-адресам нам нужно внутри одного присоединиться новая 5s разбираться кто там бот не бот человек и человек соответственно все это уметь хорошо анализировать и быстро что у нас происходит внутри классе внутри класть у нас происходит именно следующее у нас есть независимые ноды что из этого следует это следует то что каждая нота само по себе то есть каждая нота знает только свой кусочек трафика мы балансируем внутри случайным образом до теста если от одного пользователя прилетела 10 соединений то они разъехались по разным серверам и от есть некая проблема соответственно далее у нас очень жесткое требование по производительности чего он заключается скажем ну так и мы работаем же мере на с помощью то трафика переводится на нас через dns записи таким образом если человек заходит на сайт чек в швейцарии заходит на сайт во франции на сервер у нас кластер стоит во франкфурте то у него уже плюс 15 миллисекунд просто на сетевое на сетевые задержки на то что увеличился вы еще длина маршрута и если мы добавим еще 15 20 миллисекунд внутри своего центра обработки то это будет уже очень много поэтому во первых поэтому во вторых потому что если мы будем 15 20 секунд обрабатывать каждый тебе запрос то а так там достаточно простая в объеме 20 fps слушать на весь кластер это недопустимо и далее нам необходимо отслеживать не просто вот запрос пришел на нее посмотрели пропустили во нам важно понимать контекст запросов почему положим пользователь открывает веб-страницу он сделал запрос там наслаждать после этого загрузилась странице сайта 11 браузер сделал 10 соединениях банду и в 10 потоков пошел запрашивать стать к пошел запрашивать динамику делать а як запрос поцапался какая здесь специфика если вы где то в середине начнете что-то отдавать начнете как-то проверять то вы сломаете саму страницу black если на самый первый за он вы отдадите captcha хотя это очень плохо или отдайтесь какие также челленджи или еще что то сделайте redirect куда-нибудь эта проблема и не будет любой браузер как обработает и все будет хорошо и уже после этого после того как такое тестирование планет вам может распространить во всем кластером информацию о том что данная сессия хорошая тогда у вас все будет хорошо если этого не будет то соответственно другие ноды получат информацию поучиться и середина да и не будут знать что с ней делать и нам необходимо оперативно отреагировать на все скачки нагрузки на все изменения в трафика то есть если на одной ноте всего лишь на одно и что-то скакнул это значит что через 50 100 миллисекунд каком-то всех остальных а лучше если они будут знать об этом заранее заранее выставить параметры защиты чтобы ну даже если мы что-то немножко пропустили на одной ноте мы не пропустили на всех остальных дополнительным сервисом к защите от ботов у нас стал сей раз прост разметки банальны когда там где-то ставится какой-нибудь пиксель на сайт и просто мы записываемся информацию бот не бота демотт и пайпер и здесь возникла еще одна сложность связана с тем что нам важно эти вердикта где-то сохранять то есть если раньше мы говорили про то что мы синхронизируемся внутри кластера то сейчас мы говорим о том что нам нужно синхронизировать информацию еще и между пластинами это было дополнительно сложностью собственно на уровне тему такая съемка получилась здесь добавился контекст вот этот самый вот и добавить некая связанность чуть позже расскажу как мы и сделали далее мы собственно сделали вот этот самый кластер мы осознали что у нас есть придумали как его строить и начали естественно масштабироваться и строить несколько кластеров и как мы это сделали мы работаем через бюджетников то есть наши подсети анонсируют со всех мастеров и опять приходит туда где ближе то есть проще говоря из франции на кластер в формате из петербурга на кластером москве на m9 то есть таким образом кластеров формально независимым и если вы и потоки на них допустим они зависимы что это значит в реальность нас с вами в москве два кластера соответственно и даже пусть это будет франков да человек едет на машине человек работает сайт с мобильного интернета человек память о какой-то рубикон и внезапно переключился на другой кластер это первый кейс второй кейс человек просто перестроимся маршрут называется свои где-то сгорел switch где-то сгорел роутер где-то что-то упал сегмент сети отключился и перестроились вашу таким образом в чик принесло другой кластер здесь важно отслеживать внутри функционал тот факт что на стороне человека то есть мы снабжаем как бы браузеров куках например да или еще как то достаточно информации о том что перейдя на другой кластер он смог сообщить ему все необходимые параметры о том что скажем проверки определенного уже прошел ли он еще их не проходил или еще что то вот но во всех остальных смыслах можешь стать сетевые потоки независимыми и вот этот самый небольшой лаг мы можем просто перейдем речь далее значит при всем при этом нам необходимо все-таки между кластерами синхронизировать режим защиты почему потому что наиболее коварный тип атак это такие лавалем так называемая когда идет атака не флудом когда идет атака не просто забить канал или еще что то это очень просто фильтруется то чуть просто отражается и так далее вот не даже не когда идет атака типа там ваймс да когда волнами идет это тоже довольно легко фильтруется их отравляется когда идет от около уволим это значит что на ресурс есть какое-то у зима и место значит что на ресурсе есть там пояс какой-то медленный запросы или какой-то очень большие файлы соответственно 30 запросами всего лишь этот большой то 500 мегабайт файл с бы страх каналов ресурс укладывается потому что исходящий канал от него собирается на дачу вот и вот это самойлову лима таки они чаще всего проводятся под прикрытием флуда то есть запускает плод запускает уволим атаку люди курорте с флотом люди думают что им стоит ломает флуд вот и ловле маток они при этом не видят с ней не борется и поэтому сайт лежит заслугам они против вполне эффективно поэтому необходимы между кластерами синхронизировать режим защиты для того случая когда на воле пришел на один кластер оплот пришел другой такое случается например когда для флуда берут международной да там вот на это для уволим берут конкретный один маленький сервачок где-то в москве ну такой это реальный кейс вполне ну и между постираем а как я уже сказал нам к необходимо синхронизировать те самые вердикт которые мы накапливаем отдаем пей-пей при этом вердикт в этих может быть много их нужно кодировать надежно то есть если режим защиты мы можем даже потенциально внутри кластера мы можем потенциально даже где-то что-то потерять то между кустиками мы терять нечего не можем и второй момент между костями большой лотностью то есть опять же если кластер во франкфурте класса москве это лотность и 20 миллисекунд здесь нельзя сделать никаких синхронных запросов я и взаимодействие должно уйти из комнаты жиме и получилась вот такая вот схема соответственно здесь mlp это некий параметр технически которой имеется виду тот самый режим защиты технической обмен между кастерами и и 1-ю давая то некие пользователи не к это самый разметка до плохой хороший вот и так далее и вернемся внутрь значит когда мы строили когда мы осознали что нам необходимо построить интерфейс взаимодействия между нодами фильтрации изначально конфету запустили на самом деле фильтрация на уровне елисеем новые приложения по запущена всего на одной ноги для двух клиентов стартовых это работал хорошо ну для уже 10 это работает очень плохо понятно что это будет справлять мы начали с того что естественно написали что мать этого от этого всего хотим во-первых мы хотели максимальную максимальную оперативность том смысле что latin седова первых должен быть минимальным во вторых затрачиваемые ресурсы по цеху на обработку таких пакетов должны быть минимальными то есть не подойдет там взаимодействие через и т.п. подобного рода вещи во вторых очень важным было обеспечить минимальный накладной расход не только в смысле цеху опять же да не только значительных ресурсов но и смысле пакет рейтом то есть так как мы говорим о фильтрация так мы говорим о фильтрации а ситуации когда нам заведомо не хватает производились то есть обычно когда мы строим веб-проект мы просто берем там x3 до x 4k нагрузки и уверены в том что этого нам хватит здесь у нас нету x3 их 4 здесь у нас всегда x1 то есть всегда все что у нас есть может быть забита а так и всегда может быть я так и такого масштаба поэтому пакет теряет нам тоже необходимо было минимизировать при всем при этом ну наверное не секрет что для разработки подобных систем используйте си плюс плюс и к сожалению программа которая написана си си плюс плюс она нападает горку вот иногда их надо перезапускать для того чтобы обновить иногда их нужно перезапустить просто для того чтобы перезапустить потому что конфигурации там скажи мне перед читалось но мало ли что случилось вот и в этом случае если мы перед пускаем моды под атакой нам необходимо где-то взять контекст который она чувствовала то сервис не стоит лишь сей раз помнят о том что есть некая множество людей которые мы заблокировали есть некая может людей которых мы проверяем тогда это сама внутри коммуникация и соответственно ему необходимы где откуда-то вот этот первичной за информацию достать вот были мысли в принципе подставить наверное рядом какую-то базу данных data мы не знаю sql lite вот их быстро отбросили потому что ну потому что это какое-то странное решение на каждом сервере писать такой input all вот памяти понятно это будет работать плохо то есть еще одно требование к этому интерфейсу само действие это какое-то место куда мы будем что-то писать откуда мы потом сможем вычислить по помощи состоянии находимся и фактически у всего этого безобразия есть всего три операции три функции функция отправить чем отправить не кому-то отправить на все но да это например касается сообщение по синхронизации текущей нагрузки до то есть каждая нота должна знать общую нагрузку на ресурс рамках этого кластером для того чтобы отслеживать и самые пике д вторая операция это сохранить этапе реконструкции вердикт проверки да вот и третья операция корпоратива сохранить это как раз те самые сообщения по состоянию которые меняются состоянии о которых мы отправляем вообще на всех и потом куда-то сохраняем чтобы потом иметь возможность это вы черти и получается что сейчас у нас вот такая вот схема со взаимодействием и в нее мы еще должны будем что-то добавить о сохранении какие мы варианты посмотрели ну во-первых мы посмотрели некую классику докладе который ботинки у классика это редис тарантула так далее почему мы это отбросили но просто потому что все это работает медленно просто потому что это те цепи просто потому что это за 20 ти питу это x2 к макету сразу это плохо ужасно вот во вторых потому что есть некие некая но до отправки до соответствие если мы отправляем с него сообщения на всех то нам или либо этих нот нужно очень много либо это но до сможет управлять одну 16 этих сообщений которые 16 машины могут брать в нее понятно что это недопустимо вот таким образом традиции rabbit мы опросили собственно тебе бенстер см от бросили по тем же причинам но еще и потому что это довольно странно пилить тоже самое ну чуть лучше чем есть закон сосуда что в итоге взяли взяли и тебе multicast почему потому что в этом случае центром отправки выступает сетевое оборудование и стива оборудование здесь не ограничена никакими лимиты производительность сколько мы в него плюнем столько она обратно у нас вы принят соответственно здесь у нас простор для творчества если производительности и здесь у нас решаются полностью проблемы с скоростью во первых отправки во вторых скорости приема понятно что случае эдипе мы сразу не думаем никаких текстовых форматах мы отправляем бинарные данные естественно что мы сразу добавили туда еще и пакетирования то есть отправляем группа кусками накапливаем поправляем на копьем отправляем и так далее вот это провели к этому базу данных взяли мы базу данных тарантул почему тарантул очень просто потому что во первых изначально в компании было три технических специалистов основателя и у всех у нас троих был опыт работы той базы данных собственно мы пришли в эту компанию мы начали и создавать уж и уйти вот поэтому она была знакома в отличие от родиться во первых во вторых она была максимально гибко то есть на ее основе можно было можно сделать все что угодно это некий applications сервер не только базы данных в третьих я уже знал тогда и тогда это уже развивалась ту тарантулы 75 то есть не только на ло можно все это делать что можно делать еще и на языке c и это очень принципиален для нас момент почему потому что опять ну у нас система фильтрации ботов и система защиты от ddos атак и нас критично максимальной производительности ни один язык репетируем и максимальный процент планеты причем обеспечить им может сим может с тобой идеальным решением и здесь в этой схеме я базы данных добавилось внутри кластера то есть здесь мы в ней храним вот то самое состояние внутренней коммуникации и по сути это две головы да да и два мастера внутри одного кластер что мы в ней храним когда мы придумывали как скрыть информацию было два варианта либо мы храним некие стоит до конечную какую-то структура объект как угодно можно это назвать и его постоянно обновляем и изменяем это в принципе хорошая идея но довольно сложные примите ruim и это нужно отслеживать эту структуру это сложно его обновлять не очевидно что это хорошо мы взяли немножко другой подход мы взяли простую идею что у нас есть структуру этих самых отправляемых данных по и т.п. и она некое унифицирована довольно простая там есть тайминг есть какой-то кода есть какие-то три четыре поля данных мы просто и ту же структуру фактически пишем tarantul ней space и добавляем туда запись статей по о котором мы знаем что это структур уже устарел и и надо оттуда удалить таким образом у нас в tarantul и накапливается лог-сообщение которые мы защищаем зачищаем заданным таймингом то есть грубо говоря записи чья старше чем 1 час они нам уже не нужны мы их можем оттуда спокойно удалитель вот естественно это вызывает определенные проблемы но мы они сейчас мы позже поговорим и что у нас есть здесь у нас еще есть этот момент во первых у нас основные операции это записи почему это сложность это сложность потому что эта операция на диске вот опять же хорошо что этот тарантул потому что он на диске пишет достаточно оптимальным вот я здесь написал что взяли мутанту эксперименте это действительно правда мы использовали эксперименте изначально для того чтобы удалить вот эти самой старой данная посредстве на пришлось от него отказаться из-за того что он взывал определенными проблемами вот и того у нас сейчас есть такая структур к которой мы попозже добавили еще дополнительно две базы данных на каждый кластер а зачем как я уже говорил нам помимо хранения состояния кластера необходимость организовывать еще и вердиктом вердикта мы синхронизируем наш кластер на соответственно здесь добавляется еще дополнительно инсталляция таранто странно было выбрать другое решение потому что тарантул заезда да вот опять же он идеально подходит для этого случая в котором мы пишем все вердикты и соответственно репетируем с другими кастерами при этом мы не используем мастер слив мы используем мастер мастер причем во всех случаях и не секрет что сейчас таран то есть только один горный мастер мастер для многих случаев это плохо это не подходит для наш случае это идеально подходит почему потому что та самая история достала пенсий между кластерами 20 миллисекунд синхронная репликация здесь было бы большой проблемой вот асинхронная проблем не вызывает какие у нас были совсем этим проблемы 1 блок проблем так который хочется поговорить был связан с собственной иди пешком не секрет что едите это такой патоку который умеет пакет и бить в теории на практике это встречается не так часто но все таки вот и youtube и может пакета тереть ну бывает вот вторая проблема была интереснее она была связана с тем что мы отправляли вот эти самые информацию об изменениях операции изменения на другие ноты на все ноды все ноты и принимали внутри себе изменяли состоянии это изменение состоянии генерировал новые сообщения в общем возникал такой взрыв забавно было на это смотреть первое наверное 2 секунды дальше перестала быть забавно но срочно отключили естественно исправили вот это просто история про то что нужно думать перед тем как выкладывать вот про проблему упорчик макеты в их потери мы решили методом страус и без известный метод в нашей индустрии просто вставить голову в песок почему так потому что проблемы порчи пакетов у нас нету у нас коммуникация идет вам х 1 свеча забить их просто некому нету нигде не стабильных соединений нету нигде не стабильных сочинить нестабильного сетевого оборудования вот тоже самое касается их перестановки местами опять же это проблема просто нету потому что им негде перед ставится вот нет у разных маршрутов по которым они доставляются вот проблема потери она есть то есть если машинка подзависла где-то возник tutta la pute где-то ноды перегрузилась еще что-то случилось здесь есть два момента если оно такое зависание произошел на небольшой период времени скажем это 50 миллисекунд это очень плохо это ужасно но это решается просто увеличенными очередями сестре летать беремся с целью ним размер очередей и получаем в этом случае просто гуфер в котором это полежит пока все не заработать снова а если у нас случился более долгие за долгое зависание на аноде то у нас проблема не в том что кластером синхронизировал сюда нас там случае проблема в том что часть трафика которая на эту ноту уходит мы сейчас просто теряем тоже если надо зависла на трафик нормально не фильтрует вот и никакого fall back а нету потому что все это работает в режиме реального времени в этом нужно бежать нужно исправлять вот не знаю нас таких случаев не было но понятно что в этом случае проблема потери связанности это не проблема проблема в том что ноту надо починить вот поэтому с проблемы и типе мы собирались очень просто вот немножко сложнее было осознать проблема оцинкованной репликации the round вы-то как с ними жить здесь проблем наверное несколько первая проблема связана с тем что изначально мы взяли не мастер мастер мастер slave более традиционны для модели модель для эксплуатации и все это работал ровно до того момента пока вот этот самый слоем и взял на себя на длительное время нагрузку мастера почему это стало проблема потому что естественно вот этот expiration да он работал на на на мастере и удалял данные на мастера на слайде его не было когда мы переключились на слоев туда писались дан они там и остались purchase на мастером так далее сделали несколько итераций нас новинка плюс только до ног что он какой-то момент он сломался вот тесно пришлось переключиться на мастер мастер репликацию асинхронную вот и здесь проблем несколько проблем от того что данные записались но еще не доехали до других нот и проблема того что ключи могут пересечься между разными репликами то есть предположим рамках одного кластера мы записали сюда данные в этот момент соединения порвалась мы побежали на слив если мы держим на уточнения стоит повышение на 2 мастер да вот с ним мы тоже держим постоянное сидение всегда este mai stiu соединений записали сюда после этого они давили друг друга репликацию синхронно увидели что у них одинаковые праймеры ключ его спейси и репликация рассыпалась решили мы это очень просто мы просто взяли такую модель при которой у нас про америке содержит обязательно грубо говоря адрес фактически имя до ноты тарантулов которые мы пишем благодаря этому нас никогда не возникает конфликтов но при этом возникают ситуации когда пользовательские данные все-таки и там и там мы записались и про дублировались это очень редкий случай поэтому мы просто опять же пренебрегли вот если мы увидим его в частотном случае в частотном виде но опять же это будет не проблема потому что тарантул много разных индексов вот и всегда можно счетчики посчитать сделал бы говорить и дупликацию другая проблема проблема того что данные записаны на мастер здесь еще не оказались здесь на другом мастере да вот отсюда уже пришел запрос это проблема касающиеся как раз сохранение вердиктов да но если быть честным то мы ее не решали по сути почему потому что но это интернет это так он устроен поэтому мы просто говорим ребят перейдите на 5 минут позже за вердиктом и все вот как правило даже пять минут не нужно достаточно одной секунды сделать или потом какой вот это 1 момент 2 момент но если с другой стороны это недопустимо значным организован просто некие push да о том что такой то едишь ник забирайте данные или вот его данные вот примерно так мы справились мастер мастер аппликации проблемами были некоторые у некоторых блок проблем связанный star антон непосредственно с ним и с его драйверами из его модули теперь и шенги в чем заключался в том что когда мы все это запустили цвет ночи вы работать мы в какой-то мы это обнаружили что атаки к нам уже приходит каждый день и не по одной атаки соответственно количество сообщений которые мы сохраняем да вот в этом самом вот и самой базе для синхронизации для хранения контекста она уже очень большое вот и при зачистке удаляется настолько много данных что garbage collector перестает справляться таранда просто столов то потом в циpкa и мы утеряли не как мы это не смогли решить вот решили просто переписав переписали мы все это на свой модуль и expiration не назвали воя xp вот и переписали вопрос на этикете вот этим решили проблемы с garbage collector ком все хорошо с ним все замечательно но есть ещё одна проблема с xperia шандец который мы не справились и пока не очень я понимаю как всем справляться полной мере эта проблема того что expiration работает только на одном мастер то есть если у вас скажем там не знаю 6 мастеров да на 3 кластерах вот и как бы по идее у вас вы везде прикрыты да на каждый пластика по 2 но да вот если что-то упадёт всегда все будет работать не совсем если упадет the same одна нота с expiration of the кластер теряет функциональность которая для него критично потому что если мы данные чистим все данные старше одного часа то понятно что если она прольют скажем 5 часов то количество данных будет x5 потому что должно быть обычным вот и если в этот момент придет крупная так а то есть пойдёт вопреки две плохих два плохих кейса то достаточно будет даже не пять часов а два часа и ночью то есть принципе это очень очень нехорошо не знаю кости бороться пока еще раз то есть такие мысли есть но пока не придумали вот expiration есть такой момент что она проверяет за эксперта по улице kimko la boca мы сделали проще мы просто смотрим передаем грубо говоря в функцию вызова какой-то посмотрели то что достать время заходим вот этапу сравним с текущим значением функции time если это так соответственно уже старый мы удаляем мне кажется что и достаточно универсальная модель вот вторая проблема касалась драйвер тарантул то реально драйвера для чья сразу сейчас уточню что проблема это было год или а дачного на полтора года я невинна текущее состояние потому что с тех пор у нас этих проблем не было вот в чем она заключается в том что у нас просто все плода подавал где это непонятно где то есть это были пара из кондишен либо memory leaks не мама реликтов ключник это просто память вот для тех кто пишет очисть кускус ясно что такие проблемы очень долго отлаживать и очень долго искать где это происходит вот поэтому мы просто взяли и написали свой драйвер торрент вот на самом деле это не как бы камень в огород таранто в это наоборот респект этим ребятам потому что их маток очень простой но для нас этого вопроса потому что особую готов с точки зрения с точки зрения поддержания паукан акта все это у нас уже была вот примите рать по так он это ушло пять дней с тестированием с отладкой запуском всего это дело в продакшн вот по моему опыту это просто супер то есть когда мы в яндексе пытались то же самое сделать с oracle им мы об этом ходили и думали где-то год вот кончим сяк насколько я знаю переходом яндекс почты на подсказку или вот дальше мы все сделали внутри и пошли с наружу наружу еще раз у нас уже готова репликация между тарантулами мы уже умеем синхронизовать вердикта но у нас все еще не готова инфраструктуру для передачи тех самых информационных сообщений между кластером о том что идет какая-то атака какая-то проблема где-то происходит еще что-то опять же полу много разных мыслей в том числе опять-таки свой какой-то сервис тисе пи еще что-нибудь о все это очень быстро мы отбросили почему потому что есть этот самый модуль таран дуку которая команда тарантул любит вот и у нас уже были тарантул smash кластерные репликации были уже парка у чины дырки то есть не нужно ходить к админам вы просите ребята откройте то пожалуйста здесь порты вот разрешите нам еще и здесь погонять трафик вот все уже готово опять же готова интеграция в свои решения опять же готова само решение к работе с этим инструментом но все еще есть проблема проблема с тем что у нас есть там n независимых not внутри кластера и нам нужно выбрать одну ноту которая с этим с этой очереди на запись будет взаимодействовать то что иначе будет отправляться 16 сообщений или будет 16 раз учитываться из очередь одно и то же сообщение отправляться 16 внутри о чем проблема есть проблему мы решили сейчас очень просто мы просто пишем 2 точный space что сейчас за это отвечает на воду такая-то скажем ноту с номером один или с номером два и если она сгорит упадет не знаю уборщицу по три прядки то мы пойдем просто отдаем раз ps если не забудем вот если за путем ну значит за путин эта проблема которая тоже мы хотим в будущем решить этому учили сейчас вот такую схему взаимодействия здесь уже есть более менее детальная схема самого кластером те самые базы данных и тот самый третей взаимодействия что нам хочется будет есть еще лучше что нам хочется здесь еще добавить ну во-первых хочется вот это сама xp выложить в консоль ну просто потому что нам кажется что это модуль полезная да потому что он позволяет делать то же самое что делает expiration не только с практически нулевыми ходом но при этом как это делать хочется добавить туда индекс то есть вот этот отель да по которому смотрим устарел запись или нет его может загнать финики сортированный индекс 3 яндекс и не делать полный риск on space а удалять только те tab которые смотреть только на самые старые да и удалять их вот обязательно сделаем но я не уверен что для нас это будет полезно почему потому что у нас как помните основная операция в таранто от операции запись соответственно лишний индекс это лишняя нагрузка для того чтобы вот этот самый индекс поддерживать вот скорее всего мы это сделаем после этого прогоним проверим что у себя мы потеряли не потеряли сделаем а скорее вторым режимом очень хочется нам переписать всю нашу ложку на цепи здесь я думаю понятно у нас все еще есть какие-то методы сложные которые мы вызываем вызываем реал тайме и ну когда вы один раз столкнулись с проблемой того что база данных падает из-за гоца вы будете всегда этого бояться и думать о том как бы этого избежать в будущем полностью совсем она всегда вот и есть проблема проблема которую я не знаю пока как наше точнее я уверен что в режиме асинхронный мастер мастер аппликации и полностью решить невозможно то есть проблема того чтобы выбирать мастера для expiration а то есть если у пола но даст где работает expiration выбирать какую-то другую ноду и запускать expiration на ней почему мне кажется что это не возможно потому что репликация асинхронная соответственно все равно будет возникать ситуации когда на этой ноте самый еще что-то удалилась до того как она выяснила что она вышла из кластером и к сожалению эти данные запишутся в обслуге и потом эти технологии только ну как-то удалять не знаю редактировать общего автоматически это работать не будет вот не знаю как мы это будем решать может быть посоветуемся с командой тарантул и последний момент что мы еще очень хотим сделать очень меня беспокоит тот факт что у нас вот эта самая репликация до для таран толку и сохранение вердикта мир кластерного это репликация все ко всем это хорошо работает пока кластер очистка 3 когда кластеров очистка становится 100 до 200 но все ко всем это ужасно во первых это ужасно просто потому что количество соединений за которым надо следить она невероятно большое и постоянно будет что-то звенеть во вторых то ужасно просто шидевер что тарантул ты выдержишь не знаю я пока что с ним сделать опять же и наверное когда мы пойдем в такой специальный рост кластеров мы покажем в команду тарантула и наверное будем снимать дает осуществим делать вот собственно примерно такой адский мы сейчас хочется добавить вот сюда вот вот этот самый что-то сделать с большим количеством реплик и вот здесь что-то сделать с этим самым смешным какие я бы хотел наверное всего этого сделать выводы выводы два блока два вывода первые выводы касаются кирпичиков которые мы использовали кирпичик это multicast виде пышный и кирпичик этот тарантул по multicast не надо его боятся то есть когда я работу в индекс нам говорили чуть не группа multicast вообще под запретом вот не надо бояться multicast вам multicast внутри и кластер это хорошо это правильно это быстрые есть много кейсов когда у вас идет постоянная синхронизация и через 50 миллисекунд уже неважно что произошло до этого да то есть вы получили уже новое состояние в этом случае скорее всего потеря одного сообщения проблемы не будет в этом случае использовать и теперь multicast каши правильно потому что вы не лимитируется производительности по пути трея то и получайте оптимальные тот самый по китае вот второй момент тарантул наверное опять есть написал что ей нужен напильник напильник нужно если вас очень серьезных allow то есть у нас он очень серьезно потому что diedas случается вот скорее всего в текущем состоянии он уже применим я думаю и без напильника если у вас какая кошка паха пышкой так далее вот но если большой holod то напильник нужен ног разговорчивость будем честны напильник нужен всем если он большой прыгаем по большой fallout напильник нужны поскорее его вакулы вообще всем вот второй момент заключается в том что сейчас популярно точки зрения что не надо пилить велосипеда это правда и успел пилить не надо второй момент что не на то есть если у вас маленькая команда да берите готовые берите там для синхронизации редис берите стандартный пас gres берите стандартный там гол пайтона так далее не делайте своих решений не правда если вы точно уверены в том что вам решение то нужно если вы поработали с решениями у под соснами выяснили в чем вам почему они вам не подходят или точно знаете заранее что тоже нет смысла пробовать то свое решение перейти к нужны это полезно другой разговор что важно очень вовремя остановиться то есть не надо писать свой тарантул не надо реализовывать свой проки обмена сообщениями если вам нужен брокер возьмите уже рать вот мы если вам достаточно multicast из вам достаточно данного кейси да вот тарантула возьмите их и будет частью примерно так спасибо задавайте свой вопрос 20 антон спасибо большое за доклад у меня вот вопрос вы показали то что вы добавляете к остро новые но вы не рассказали как вы просто беру и центрируйте ли вы вообще костра внутри то есть если вы видите что допустим каком-то кластере не хватает места чтобы уместить все данные вам нужны то как вы добавляете ноды в кластер внутрь подростки из ситуации нет гораздо проще поставить новый классе где-то рядом хорошо и 2 у меня вопрос вы говорите что синхронная репликация это плохо что там приходит запрос надо ждать результата другого класса так нельзя ли просто ну то есть вы ждете вердикта другого кластера нельзя ли просто как бы сказать что хорошо этот запрос мы пропустим но как бы следующие мы будем для следующих мы дождемся когда он будет тогда мы будем принимать решения на основе доехали данных нельзя ли так сделал нет песню о fitcon репликация неплохо это хорошо но у нее есть ограничение какую синхронный то есть это разговор про то что пользователи запросил данные отсюда страницу она забрал отсюда до то есть предположим апексе спасибо отсюда вот вот это те отсюда пришел на другой кластер он отдам страницу пришел за вердиктом vertigo так сюда не успела доехать на землю нужен для того чтобы определиться нужно запрос пропускать либо нет либо зуба нет вердикт чаще всего нужен ли статистике то есть ситуации когда кто-то хочет фильтровать ботов они встают за нас мы зададим петровне в принципе некритически будет если мы видим то что данных нужных нету они пока не доехали поэтому мы как бы пропустим этот запрос но последующие будет фильтроваться больше того на самом деле для уже совсем крупного бизнеса сейчас в принципе неважно что при нем приходит бота и даже не важно что и выкрикивают и важно просто фактов знать где были под и где люди чтобы корректно проводить функционале ты снял связи с этим вопрос то есть тарантул настройки а знает armstrong консистенции система не рассматривали ли вы какой-нибудь софт консистенции системы кассандру допустим нет не рассматривали просто потому что там тоже есть то есть брать can сандру это интересная мысль но я сомневаюсь что она попытаетесь вытянет нашей нагрузки на и нам потребуется много ресурсов у вас поздно будет стоять много серверов чтобы поддерживать дорого хорошо спасибо спасибо за интересные доклады что вы не скрываете проблемах вашим да и тех неудачи которые там у вас бы вот у меня вопрос такой откройте мушка занавеса сколько например трафик там у вас держится один сервер и несколько серверов в кластере просто какие-то параметры такие вашего решения да это не секрет сервера тех же трафик на уровне свой сетевого интерфейса то есть десятка грубо говоря на сервера десятку серого держит болеет он ставил задачу о том что серая обязан держать полную сетку вот есть это кластер то обычная конфигурация кластер а это 16 машин то есть . египет кластер девушки вот если это три-четыре атака то это крупная таки то это уже фильтрацию на выводе пограничных бодров наших на лидеров до нас она просто не долетает примерно так это еще одна причина кстати по которой мы защищаем только через то есть мы просто фильтруем весь в дипе трафик где-то там далеко и там емкость и затем далеко за терабит а можно чуть подробнее про подключение приложений к таранда у власти то есть вы сначала сказали что он актив актер и тогда здесь бы вроде как какие-то конфликты могут быть их его как-то решаете настройка тарантула решен акта или вып одном уточнили что sharding что ли свой делаете на приложение когда пишете ключ с именем мастера есть грубо говоря если есть счетчики то есть ли ситуация с конфликтами как она мерзавца либо вы целиком на приложение делаете свою логику по шарден гу и не допускай по сути это актив пассив актив пассив наоборот из двух маленьких кусочков как бы ну асинхронный мастер мастер отказ есть актив пассив актив мы сюда то есть нас нету sharding у нас есть только репликации и мы не не обновляем одно и то же поле это еще одна причина по которой мы пишем лобная нужно ботан она нам потом был сказать то есть каждый раз мы пишем новое поле новый этапу и так как в этом новом тамплиеры не уникальный праймер ключом гранте он уникальный потому что содержит имя надо в которую на которые записали то таким образом конфликты репликации они полностью исключены а вообще вот с точки зрения выбора на какую ноту тарантулов и спешит приложение они все по умолчанию в одно пишут потом синхронно так переключаются или в разнобой вот так им достаточно что они именно воды туда по умолчанию мы пишем в одну читаемость другой сад и от но что-то случилось переключаемся на другую спасибо бюджетами ещё вопросы есть видимо вопросов больше нет мы к вам просьба выберите пожалуйста из большого числа вопроса который вам понравился больше всего наверное елку из кластеров спасибо вам еще раз за доклад очень интересно было спасибо"
}