{
  "video_id": "FF-GZ7iipwc",
  "channel": "HighLoadChannel",
  "title": "Микросервисная архитектура, подходы и технологии / Кирилл Ветчинкин (TYME)",
  "views": 188741,
  "duration": 3237,
  "published": "2018-11-20T12:31:42-08:00",
  "text": "а компания time зовут меня кирилл мы проектов завод elfin тех проекта платежной системой крупная интеграции и соответственно поскольку это большие системы мы практикуем красный подход причем поскольку мы делаем разные проекты для разных заказчиков у нас были как положительный опыт так отрицательный опыт мы набили много шишек и как раз сегодня мы все эти шишки разберем как вам их избежать таки есть модерные от типа тарна и и вы можете использовать их налоги и какие лучше использовать в среднем нашим проекта выйдет примерно так что это 200 рпс пике это не сильно много но в принципе немало в среднем в каждом проекте около 25 микро сервисов и они охотятся на 18 виртуальных машинах иногда больше тогда меньше часть из этих машин это обслуживающий система для самих микро сервисов отводятся чуть меньше машин давайте посмотрим про что вообще в принципе буду рассказывать про что будет доклад сначала мы очень кратко вспомнил саму идею самого подхода для тех кто ее не помню затем мы посмотрим нужно ли вам принципе микро сервис и потому что опять же таки в нашей практике мы пытались воткнуть микро сервиса в те проекты где это было совсем не нужно и просто тратить на это время и силы посмотрим нужные мне нужны и соответственно посмотрим на архитектуру систему то есть у нас будет маленькое типовое приложение электронный банк где мы его будем разбивать на монолитно маленькие сервиса и проектировать и учитывать разные нюансы которые при проектирует архитектуры вам будет необходимо конечно же микро сервис это не серебряная пуля у нас появится проблема и соответственно мы рассмотрим каждую проблему в отдельности как ее можно решить то есть мы посмотрим и разберем все минусы данного подхода найдем решение и конечно же когда мы всю систему спроектировали так или иначе и нужно развертывать посмотрим какие есть варианты для развертывания эта виртуальная машина контейнер и оркестрация и так далее ну и конечно же здесь будет про немножко про технологию в чем сама боль в чем боль большую систему большая система она огромная если вы разрабатывает такие системы то вы понимаете скорее всего у вас много legacy кода у вас плохое горизонтальное масштабирование плахой отказоустойчивость потому что вы вам сложно горизонтально масштабируется соответствовал сложно обеспечивает отказоустойчивость вам сложно внедрять новые технологии то есть вы сидите на каком то старом языке и можете уехать на более современные более быстрые либо то же самое с базами данных то есть вас таким образом в конечном итоге систему становятся legacy и тут появляется три важных проблем и первая проблема то что вы не используете те новые средства которые могли бы использовать вашу система работала бы просто быстрее второй момент он больше организационной к вам не хотят идти разработчики у вас большая олега система и мне интересно разрабатывать на каком-то старой версии фреймворка работать какой-то старой версии базы где 5000 хранимых и так далее ну и как компания тоже страдает она не может все просто найти ров разработчик то есть вам это же должно быть интересным суть подхода достаточно просто есть большая сложная система разбивается на много маленьких и якобы маленькие кусочки нам делать жизнь лучше и проще но на самом деле это не так просто проблема перетекает в другой уровень у вас теперь проблема на уровне взаимодействуете самих сервисов подходы у того подходит как плюсы так и минусы в кратце их перечислим как мы уже говорили мы хотим решить проблему горизонтального масштабируя microsoft проблему решает отказоустойчивость позже вас появляется за счет того что вы можете какие-то части разносить по разным серверам что-то выносить облака делает несколько кратных дублирования и так далее тоже немаловажная проблема есть у вас систему разрослась то ваша команда скорее всего разрастется и вас 50 человек начинает коммитить в один репозитории здесь можем людей немножко развивается мозг от того что они обслуживают очень большое количество функций в данном случае мы можем отдать разные сервиса разным командам каждая команда занимается каким-то своим как летом сервисом и отвечает только за него и конечно же при использовании если вы делаете одну большую систему то есть вас продуктовая разработка для вас это быть может и не очень актуально но у нас разработка больше заказная то есть мы делаем одну систему потом делаю вторую и третью четвертую пятую и у нас переиспользовать и микро сервисов очень часто нам мы мы это используем те же самые самой сервис отправку имела и так далее мы один раз его запилили и в разных системах по использовали жаром случае это возможно в случае монолит ему никакой кусок не можем переспорить другой системе но конечно же мы поговорили уже про избавление от legacy я начинала свою карьеру в банках мы работали в банке и по сути там была одна большая огромная база данных которую уже не обновляли несколько лет потому что я просто уже вышла новая версия этой спенсер это по сути была бабушка искала сервера и весь банк на ней сидел просто потому что там было написано кучу лига секунды он просто не мог от нее избавиться то есть они были заложником данная технология чтобы ваша компания не было таким заложником вы можете как раз использовать микро сервиса вы можете один сервис написать какой-то legacy переписать его там за две недели перейти на другой язык более быстро другую базу дарах и так далее то есть мы достигаем key + т.к. ну конечно же есть и минусы как вы понимаете у нас была одна большая система мы ее релиза ли одним у карьером у нас была там одна система мониторинга и так далее мологе рассыпались в одно и то же место сейчас у нас маленький систем стало больше у них несколько кратное дублирования они могут быть в контейнерах могут быть виртуальных машинах могут уезжать из одного места в другой и так далее все сторон гораздо сложнее просто сложнее разрабатывать и мира поэтому для стартапов и для простых проектов это не очень хорошо подходит это дорого раньше вы писали монолит у вас допустим культа функциональность вы реализовали и все вы можете и просто там с помощью наследования с помощью других средств по использовать других частях система здесь же у вас каждый сервис он абсолютно atam aram то есть какие-то вещи вам придется писать несколько раз в разных местах то есть вы пишете больше кода у вас больше карьеров развертывания вы на это страте деньги это в начальном этапе это дорого в конечном это будет дешевле когда вы как раз извлечете плюсы из этого подхода я одел самые популярные как раз минус это и согласованы данные поскольку у нас пропадает транзакция поскольку в каждом сервиса своя база данных у нас нет просто транзакций между ними тем привычных жестких тогда которых мы привыкли слышать давайте поговорим когда вам микросфер из и не нужны как я уже говорил мы применяли микро сервис в разных проектах и были как раз те проекты в которых мы применили неудачно это были маленькие небольшие проекты которые нам нужно было быстро выкинуть на рынок но тем не менее мы по аналогии думаю но вот мои большие проекты спилили микро сервиса давайте здесь тоже на них запилим но тем не менее мы потратили только деньги и время в маленьких проектах в вам это не нужно микро сервис для вас могут стать просто блокером то что вам нужно думать будет одна в обсе о контрактах об архитектуре о взаимодействии команд и прочих вещах второй момент если у вас просто нет нагрузки есть вас маленькая нагрузкой ранее про полагается быть большой вами красавица тоже не нужны в этом нет никакого смысла любой монолит который вы можете купить сервер помощь не та же самый небольшой моделей разделить на разные сервера если нагрузка небольшая это не проблема теми же кашами вы справитесь но другая совершенно ситуация если у вас все таки высокая нагрузка либо к вам приходит заказчик и говорит что сейчас у нас 200 тысяч клиентов а через год мы планируем tab 3 миллиона и у вас мало не будет 150 тысяч тут вам уже нужно задуматься что наверное вот запилить маленький небольшим монолит не получится здесь уже вы думаете в сторону микро сенсор или система растет то есть у вас уже есть какой-то небольшой кусок система начинает расти вы понимаете что в опять придете к этому большое количество нагрузки большому коду вас будут много комментов репозитории и большая команда который будет сложно коммитить в этот один репозиторий и конечно же нужно отказоустойчивость то есть не прирост бизнес-систему большая скорее всего и пользуется много людей и если она у нас а рухнет то мы потеряем очень очень много денег поэтому здесь очень важно отказоустойчивость микро сервис как раз это отлично поддержит и соответственно мы хотим более быстро выкладывать новые фичи на рынок то есть там релизы не раз в месяц делать а допустим гораздо чаще за счет того что мы не релизе мне всю систему а только отдельные кусочки тестируем только отдельные кусочки то в данном случае гораздо это проще делать данным подходом давайте начнём проектировать саму систему типовое приложение это электронный банк в нем есть несколько функций они достаточно просты и вот у нас монолит контракт лайк и слой доступна в данном классе к базовой т.п. транзакционные соответственно база для аналитических отчетов как мы можем разрезать данную систему весьма изощрённой случае но тем не менее такие тоже встречал в основном в энтерпрайзе где люди говорят о кей мы режем а micro series and пускай у нас будет сервис доступа к базам данных сервис like i sure с фронтменом вот но в таком случае вы собираете все минусы а то сетевого взаимодействия и добавляйте никаких плюсов правильно было бы разделить таким образом то есть мы выделяем некое бизнес-контекста некий конкретная атомарные бизнес-функций и соответственно из этого делаем сервис в данном случае у нас получается платежи история платежей акции сэм из отчета одна основная идея microcap снова подходит что micro series они должны сильно имеет сильных зацеплении друг за друга в данном случае раз платежи почти никак не зависит от эсэмэсок история платежей лишь косвенно зависит от платежей акция и отчеты вообще в принципе не зависит от других сервисов поэтому разрезаете по бизнес-контекста мы не разрезайте как я сначала сказал по слоям горизонтально но после того как мы разбили важно понимать какой размер сервиса что такое микро что такое макро большое но настал маленькие так далее правильным вообще в принципе разбиение это сделали развивается на основе бизнес-контекста мы уже проговорили второй момент вы можете понять что вот сервиса нужно объединить есть вы видите что двумя между двумя разными микро сервисами у вас происходят слишком большие сетевые взаимодействия то есть они в 90 процентов случаев работают в паре вам это ни к чему скорее всего это просто один сервис нужно их объединить и не тратить скажем ресурсы на сетевое взаимодействие следующий момент транзакция как я говорил что поскольку раз база данных у к сервиса своя то транзакций между ними просто пропадает в нашем привычном понимании но есть такие моменты и так и бизнес-функции нам эти транзакции просто необходимо к примеру платежи поэтому платежи лучше не разбивать на разные сервиса положить как можно ближе для того чтобы обеспечить как раз эту транзакционных как я уже говорил мы стремимся к тому что каждый сервис был полностью разделён и отделён от других соответству нас один сервис это должен храниться в одном репозиторию он должен иметь собственный контейнера сборки и собственных контейнер развертывания мы допускали такую ошибку что в начале когда только начинали заниматься устроить такие архитектура мы подумали сервиса мы разбили все прекрасно там базового каждого своя но теперь почему бы не положить в один репозитории очень уже удобно они все в одном репозиторием их диплом точно так же в конечном стоит конечном итоге получился по сути монолит распыленной по сети то есть меня я что-то в одном сервисе вы передаете все сервисы разом у них у всех версия поднимается никаких плюсов и не извлекли вы получили по сути монолит со всеми минусы сетевого взаимодействия поэтому нужно максимально их разделять про база данных я уже вкратце тоже говорил если у вас есть одна большая база данных и несколько микро sense выходит в эту базу данных по сути это единая точка интеграция если для одного какого-то сервиса нужно понять версию база данных а для другого не нужно в данном случае вас будут проблемы потому что они ходят в одну и ту же версию поэтому базы данных мы тоже разделяем у каждого сервис должна быть своя база данных здесь как я уже говорил мы теряем а транзакционных но мы с этим справимся чуть позже после того как вы все разделили у вас микро сервиса должны как-то с друг другом взаимодействовать взаимодействия не могут двумя способе синхронно и асинхронно наверное первый вариант который приходит в голову это нам при вич привычный rest взаимодействовать синхронно но тем не менее вы сразу должны подумать о как вы будете обеспечивает у самой отложено согласованность как вы будете делать широковещательные сообщения как вы будете делать отложенные запросы и так далее поэтому конечном итоге events асинхронные взаимодействия на шины данных о нам более подходит под микро сервисный подход поэтому мы выбираем его мы в своем подходе используем mtp протокол и ребятенка но сами протокола бывают полежит тоже двух типов они бывают специфичным это платформа и неспецифического то есть когда вас может один миг раз арестом быть на python и втором аджай with retina тут нити и как раз это то к чему мы идем то что мы хотим добиться чтобы мы могли использовать в разных местах разные языки поэтому очень важно выбрать независимо от формы протокол иначе вы вынуждены будете писать все микросфер из к примеру в данном случае натравили на тот найти эти протоколы реализовывать брокер сообщение мы используем как я уже говорил ребятенку и вся идея в том что как раз мы разделили сервисы на уровне их релизного цикла на уровне баз данных но еще мы хотим чтобы сервис и не знали друг от друга напрямую то есть у них не было точки которые они вызывают и как раз брокер сообщения синхронно взаимодействие в этом нам помогает то есть сервисы взаимодействия через ивента то есть данном случае произошел платеж сама сервис история платежей они сами знают как себя повести прямой ссылке между платежами эсэмэс историй платежей у них нету мы можем потом позже добавить еще несколько сервисов которые обрабатывать данный контракт и они отработают так как они ну как показала логик не заложено здесь очень важно вспомнить про хореографический принцип что раз нет какого-то центрального мозга который всем сервисам говорит что вот началом отправлен платеж потом он делает нас маску а потом добавляем в старый платежей и добавлять нужно вот таким вот образом каждый сервис у него вся логика в него инкапсулированы и в случае возникновения какого-то сообщения он сам знает что ему нужно делать мы понимаем что у нас все-таки есть клиенты какой-то фронт-энд может быть какой-то публичный api в интернете у нас в основном это аж теперь с популярен frontend скорее всего тоже хочет с нами работать по rest api и поэтому мы есть такой тип сервис как аппетит твой это единая точка входа это тонкий тонкий по сути фасад только на сетевом уровне где мы все микро сервисы к нему подключаем и выдаем нашему фронту единую точку через которые может войти очень важный момент что в нем почти нет логики если вы захотите в нем реализовать какую-то логику по у вас опять же таки может получиться монолит потому что вас будет вот этот фасад в нем будет много лайки вас много будет маленьких глупых сервисов по сути вы сделали монолит который используют какие-то внешние системы это тянет туда просто данные поэтому очень важно понимать что здесь логике должно быть просто поменял либо ее нет либо совсем мало чисто для координации и второй момент делается под клиента поскольку у нас клиентов может быть много у нас будет мобилки могут быть там в админке и так далее то есть мы для каждой системы делает тот api которые этой системе нужен мы в своих проектах разделяли вот таким вот образом то есть в одном случае раз веб развивался с той же скоростью что мобилки мы сделали один rest api и для админки мы сделали отдельный лист апию в котором был другой тип авторизации совершенно другие запросы и таким образом жизненный цикл этих фронтов был тоже разные поэтому сделали два разных аппетит твой другой проект у нас был публичный api private на япе точно также разделили по тому же принципу и было админка выглядит все примерно вот так схематично то есть 2 пики твой наши сервисы брокера сообщений но как я говорил что микро сервис это не серебряная пуля в них как есть плюсы так и минусы но к счастью к со всеми минусами можно бороться сегодня мы как раз про это поговорим допустим у нас может упасть брокер сообщение все системы падают конечно же мы его понимаем отказываться очень классный потемнели у него есть шанс что он упадет у нас может упасть база данных раз конце концов может обновляться любой упасть какой-то сервис поскольку мы работаем по сети у нас сама сеть тоже может упасть и может произойти и согласованность данных то есть основная проблема которая всех интересует как вы то есть транзакции нет как же быть то есть я транзакции возможно и согласовывать мы допустим платежи добавляем новый платеж он отправляет ивента в шину шина падает в итоге в истории платежей у нас новая запись не добавляется у нас получилось что клиент платеж делал а в своей истории он его не просто не видит вам нужно посмотреть на свою систему скорее всего вам не везде нужны транзакция прямо вот жесткие транзакции скорее всего вы можете каких-то местах использовать отложенную согласованность в по предложение которые мы сегодня рассматриваем в принципе историю платежей и платежи там не требуется жестко транзакция то есть мы можем спустя 10 секунд добавить какое-то сообщение в другой сервис и через 10 секунд клиент увидимся в мобильном приложении то что у него появилась транзакции даже если через минуту это произойдет и будет ничего страшного вот если примеру мы молодежь не сможем провести по причине того что мы не дом не можем добавить в истории операция то это скорее всего будет проблема делается каким образом в сей раз есть своя собственной базы данных мы туда добавляем платеж платеж добавляется в 1000 рублей есть таблица с ивентами в которых хранятся ивента который мы собираемся отправить в шину сообщения и весь фокус в том что то делать с в одной локальной транзакция то есть если мы изменяем состоянии сервиса мы также в одной транзакции гарантированно сохраняем event и потом мы допустим пытаемся этот ивент отправить брокеры сообщений но он упал мы не можем отправить ему тем не менее prevent у нас информации уже есть поэтому существует здесь надпись терлась но здесь в общем у нас находится scheduler некий крон который постоянно просматривает эту таблицу и посылает эти винты в шину таким образом рано или поздно эти винты дашь им и дойдут если шива сообщение поднялась этот крон отправил посмотрел по этой табличке какие сообщения он очень отправлял ворот просто досылает шинах принимает ascii нам уже гарантирует доставку до получателя здесь просто рациона все в порядке шины сообщения работает и как следствие рано или поздно в истории платежей появляется плюс один платеж все в порядке но здесь важно учитывать один момент такой момент как эта потребность то есть если вы три раза отправить ивентов в историю платежей у вас будет у человека в истории операции там 33 транзакция авто одинаковых и он сразу же вам позвонил скажет я такие операции совершал поэтому все повторы неизбежен и у нас может сеть моргать мы можем посылать заново сообщение это вполне нормальная ситуация в данном подходе поэтому делайте методы дом патентами и вы можете в принимающей стороне регистрировать айди ивентов которые вы уже получили обработали чтобы не обрабатывать их заново и второй момент очень важно что если вам ивента приходит в разном порядке вы должны учитывать их храма логичность то есть более старые менты не обрабатывать обрабатывает только те которые самые свежие то есть вы уже сама свежий зафиксировали и отработали по нему вам приходят было более старые вы ему просто игнорируйте поговорим про логирование когда у вас большой монолит все достаточно просто вас есть допустим вы пишете логе либо файлик либо какую-то елка система либо в базу не важно куда суть в том что у вас логия и тут хронологическом порядке вы конечно можете там параллельно вычисление делать но тем не менее в большинстве случаев у вас будет все в порядке и у вас она система пишет в отделок все достаточно просто здесь у вас в том же платежи с мск мем у нас работает api где твой платежный сервис srs и еще внешняя система которая те самости отправляет четыре системы если произойдет сбой то мы просто сложно будет очень эти концы в каком месте у вас произошел сбой поддержки будет очень сложно искать более того все эти сервисы могут распределены быть по нескольким машинам иметь несколько дубликатов и так далее поэтому все запросы связывается едином а иди на запрос этот запрос формируется на пике твои начни запрос айдишник формирует свой пик где твои для нас атакует и потом соответственно все ивенты все запросы которые идут во внешние системы он везде добавляется таким образом можно использовать activity один это известно подходит вы можете делать интерцепторы и там соответственно такси добавлять во все запросы этот по сути свой велосипед второй момент использовать библиотеку который уже существует мы ее показывать не использовали потому что мы уже изобрели несколько лет назад свой велосипед и вырос почти в принципе устраивает но в новых проектах мы скорее всего по ощупывали библиотеку она выглядит очень сносно выглядит примерно так мы клиент делает платеж и смазка отправляется jetsam оператору ложится это внешняя система клиент расстроен звонит поддержку говорит у меня эсэмэски не приходит начинается разбор полетов и как раз в данный момент активны дяди нам помогает потому что мы все запроса связали этой марки ведь и один для простоты он у нас один два три четыре когда мы будем смотреть влоги у нас с разных микро сервисах ванну централизованная систему мы используем ластик search сольются логе из разных micro series of the мы они все будут связаны единым activity иди и картина будет примерно такая мы видим что у нас было запрос в опеке твой платежи потом отправились из армейского и jetsam оператор ответил 500 мыло героем все запросы все ответы плюс эксепшен соответственно мы можем посмотреть что мы отправили оператору все ли параметры мы отправили чему нам ответил и соответственно очень быстро разобрать данную ситуацию более того если в этот activity идея даёте клиенту во front-end либо вашим фонтанчиком и либо в принципе в ошибки в браузере выводятся то есть клиент сделать принскрин потом службы поддержки у нас находит данной ошибки буквально за две три минуты начни понимает причину ошибки за две три минуты мы говорили что мы хотим сделать нашу систему гибкой делать релиза как можно чаще поэтому здесь очень важно и versio не рование это нужно для обеспечения обратной совместимости версий нерона муж может быть как в обиде твои где мы работаем пореза так и в самих контрактов таким образом мы можем разные сервисы развиваться с разной скоростью и аффекте при этом их клиентам выглядит примерно так у нас вы выпустили первую версию наши клиенты начали работать с первой версии мы выпустили вторую версию какие-то наши новые клиенты уже работают из первой версии со второй версией здесь очень важно вспомнить о такой вещи что мы versio неру им контракты внутри приложения то есть внутри одной кодовая база мы не делаем там раньше в гите и не выпускаем там какую-то отдельную ветку и здесь и вашем второй момент что вы не сможете в одной кодовой базе поддерживать там миллион этих версии и то есть какой-то конечный как бы размер потому что он будет потом просто сложно поэтому когда вы делаете такой цианирование контрактов вам нужно с бизнеса на говорится что мы держим максимум три контракта потом начинаем просто отрезать первую версию мы максимально держали таких 7 контрактов после 7 стало просто очень сложно и мы потом договорились и отрезали несколько первых когда вам примеру там заперто kool-aid говорит что все больше не могу работать или тоже вот самом говорит что либо обновляйся либо ничего не будет этот как раз та самая ситуация сэм купе протоколом все точно так же там вы также можете в контракта добавлять версия тестируемыми красе раз на подходе все очень похоже на маллет но есть одна ключевая особенность то что юнит-тесты интеграционные тесты прогоняются для каждого сервиса индивидуально допустим мы хотим зарелизить два новых сервисов платежи и эсэмэски первую версию для платежей мы сейчас выпускаем для siemens ag у нас уже допустим была выпущена первая версия мы выпускаем вторую все наши тесты пройдено и что раз теперь больше всего интересует что работает ли версии 1 платежи из версий в2с м.с. поэтому каждую ночь мы гоняем up and тесты которые собирают все версии нашей системы как новый который мы так что зарелизили так и не собирают от тестируют те версии которые нас были залили за сегодняшний день как новые так и те которые были зализина счет достаточно давно потому что как мы говорили у каждого сервиса свой карвер развертывания если сейчас не меняется он просто со мной версии может жить нам неделю 2 3 и так далее здесь мы как раз экономим на сборке в том проекте где говорил что мы все сервисы за положили водил репозитории у нас сборка занимала 40 минут в данном же случае сборка занимает ровно столько сколько нужно то есть один сервис собирается там буквально по паре минут и и сам можно зарядить два сервиса это соответственно 3 минут а еще мы также допускали ошибки в самих сервисов мы естественно раньше разрабатывали монолитов мало ли так как мы знаем мы очень сильно заморачивались по поводу архитектуры выделяемого разные слои применяем перес пользование кода и так далее и мы подумали что micro series of america все точно также и даже самые простецкие сервисы пытались делать с нами дравин n и так далее добавляли решений репозитория конечном итоге просто потратили на это время сейчас мы делимся росла две части этого умные сервисы и глупые сервиса умра это-то как раз где нам нужен как раз ddd там где у нас сложная логика там где имеет смысл разделять на разные слои а глупый сервис это сервисы которые должны просто что-то сделать допустим сервис отправки смсок это 15 строк кода который просто получает внешней библиотеку создает объект и просто отправляет эсэмэску не нужно там городить каких-то лишних слоев то есть ключевая идея в том что каждый сервис удалим не нужно делать какой-то общей архитектурой заставлять все команды исследовать мы говорили то что мы часто перри используем сервиса в наших проектах поскольку есть некие типовые моменты примеру как отправка сам язык и так далее вы можете тоже такие сервис выделить их достаточно часто видно сервис решает какие-то типовые проблемы и в идеале данный сервис можно положить в контейнер мы сейчас раньше были на виртуальных машинах сейчас используем контейнеры это очень удобно вот пример из сервисов которых перес пользуем и которые мы выделили в нашей системе это отправка sms e-mail сборщик логов и так далее мы этот сервис и больше не разрабатываем какую попробую систему мы не начинали мы просто берём этот сервис выключаем туда и они там просто работает нам не нужно тратить время на эту реализацию то есть это такой некий оля синтаксический сахар на уровне микро сервисов и здесь очень важный момент как вы будете конфигурировать свои сервиса наверняка вы быть может и большинство приложений configure this какие-то конфигурационных файлов которые хранятся в детей и так далее здесь ситуация немножко другая лучше про фигурировать из переменных окружения на примере как раз перес пользу ему сервисов можем это рассмотреть вот тот самый сама сервис здесь sms написано с версии 037 и второй сервис тоже такой же версии то есть это одна и та же одно и то же скомпилирована и приложение только которая работает в двух разных системах если бы у нас были бы конфиге доставлялись до этих средств из репозитория вам на иначе пришлось бы сделать два разных репозитория в данном случае мы конфигурируем приложение из окружения то есть мы один и тот же код кладем в разные места в одном месте у нас айпи это с мастеру втором это tele2 то есть наше самое сервис работает и там и там без перекомпиляции более дальше зайдем скорее всего вам понадобятся какие-то секреты хранить вы же не будете в базе данных хранить пароли то есть в базе данных в гите хранить пароли от базы данных поэтому это тоже заход на всякие системы типа вальта секретов докере так далее configure the system через окружением общий код будет мнение что microsoft общий код это злой вред и вообще никогда его не используйте на самом деле сегодня множко не так здесь вопрос компромиссом во первых если вы так или иначе у вас появляется к это общий код лучшего скопипастил это так на самом деле но с другой стороны если у вас сервисов много есть какие-то фундаментальные вещи типа логирования того же activity иди про которые мы говорили вы же не будете в каждом сервис это реализовывать если у вас разные языки здесь как бы понятно вопросов нет у вас компания разрабатывает примеру на одном языке раз это так мы разрабатываем attended кори то лучше если все-таки выделить какую-то общие вещи которые при изменении не будет эффект с сервиса в таком случае нам помогает могет как это выглядит у нас есть ноги от сервер есть два сервиса и есть ответственно ноги от пакет здесь слово rugged пакет написано с лагами он соответственно имеет свой собственный жизненный цикл и допустим версия 1 0 1 у нас уже с пакетом слугами существует платежи эсэмэски могут себе установить эту версию поскольку ракета основная фишка в том что для того чтобы получить новую версию библиотеки мы должны вручную зайти прописать то что в платежах вас теперь другая версия и тогда он получит поэтому есть у нас выходит версия 102 и она оказывается ноги от сервера наши сервисы то никак не эффектен и пока мы не поднимем эту версию они будут также работать с тем общим кодом который раз версии 1 0 1 мы теперь можем допустим в одном сервисе поднять версию до 102 и опять же таки не объекте первый сервис и соответственно мы можем начать их релизе у нас как первый сервис за релизиться допустим с сервиса лизиса с версии 2 в котором стоят будет совет пакет 102 а платежи с версии 1 0 1 то есть у нас вроде бы как бы есть общий код мы его где-то в одном общем месте редактируем но тем не менее у нас мы сохранили раздельность релизных циклов и нет какой-то точки зависимости обоих сервисов давайте посмотрим про развертывание когда мы говорили что вас монолит там все достаточно просто большая система скорее всего одна база данных быть может две базы данных как систему мониторинга в любом случае у вас вот этого не так-то много когда опять же такие работал банках там релиза вас происходили таким образом что мы релизе ли в какую-то папку звонили обменом говорили ребята мы зарелизили они брали перекидывались папки в папку запускали скрипта это был наш диплом здесь ситуация абсолютно другая у вас сервисов много в данном случае допустимую 25 вы хотите отказоустойчивости делается шестикратный дублирование это не такая большая цифра это даже сказал что мало то есть вострецова в каждом по 2 сервер и ту же 6 и теперь может это уже 150 вам нужно раскладывать в 150 папок вашего мира просто не смогут это сделать есть откатиться нужно и постоянно команда к мите то есть если не сделаю хотя бы 2 комментов день это будет уже 50 сборок мы говорили про теста то что после изменения каждой версии ночью мы должны гонять тесты мы же не можем команду тестировщиков надо составлять что пару они всю систему ночью перед тестировали и соответственно мы хотим добиться частных релизов релизов будет тоже также много и соответственно в этом если суть проблемы поэтому решение этот бокс микросфер из этого опыта как два брата вы не сможете делать полноценными красавицы без того пса от вас без микро сервис будете сильно интересен поэтому ты в abs здесь по сути закрывает все те проблемы которые мы только что обсуждали вас конвейеры появляются управлять инфраструктурой kontra низации регистрации и так далее когда мы разворачиваем микросферы сыну вам придется выбрать между виртуальными машинами либо контейнерами это основные два орк виды развертки где вы можете их развернуть мы раньше предложение разворачивали и одним способом и другим способом и соответственно велик не как плюсы так и минусы и забоях виртуалке долго поднимаются контейнеры понимается гораздо быстрее он понимается 50 раз быстрее а инфраструктура виртуалке вам придется настраивать в лучшем случае если вы его строится с помощью каких-то средств регулирования типа нлп подшив и так далее в контейнер и большой плюс то что момент капсуле ruim инфраструктуру внутрь то же самое сама сервис он знает как у него стоит версия dotnet фреймворка мы его перемещаем разным местам просто там работает если там стоит докер здесь же вам придется сходить и сказать что ребята поставите на такую has новую машину такой версии фреймворка когда-то версия вы поднимете вам придется опять и мытья 5 и поднимать здесь не очень удобно и соответственно мы хотим обеспечить отказоустойчивость масштабирование и соответству нас будет все переезжать если что-то упало все должно переехать как виртуалке так и контейнеры умеет переезжать просто контейнеры делает это чуть легче конечно же при помощи разных систем оркестрацию на виртуалке есть добрую плюс что ими люди пользуются уже долгие-долгие годы на них уже есть стабильная система которая стабильно работает с контейнерами ситуация немножко хипстерская то есть сейчас еще в она более стабилизировались но 34 года назад там было сложно у вас какая-то новая версия джокера могла поломать старая но тем не менее мы перешли на контейнеры с микро сервиса меня не нас очень устраивает нам это очень удобно но как мы знаем контейнеры они могут падать мы используем покер в сочетании с купер на это нужно какое-то средство которое будет их поднимать масштабировать и так далее сравнимо оркестрацию с виртуальную машину авто стелек то есть чтобы у нас происходило масштабирование здесь вам придется сделать вручную точнее использовать некие системы которому придётся настраивать здесь же это делается с коробки автодиск rr где вы можете искать новый сервис восстала сервисов большая система должна понимать что не существует здесь вам придется использовать разные средства типы консула здесь вы опять же таки из коробки это получается понимать сколько вы хотите держать сервисов то есть вы говорите что допустимы самости раствора должно быть по две копии на 2 виртуальных машинах здесь вам приходится настраивать вручную здесь опять же так вы получаете это из коробки и ты поясом то есть не прерывать диплом для того чтобы когда клиент пользовался вашей системой в этот момент выкатывайтесь у него на экране никто не появлялось сообщение что система ближайшие 5 будет доступна то есть он продолжал свои как бы операция использовать блин глинда play то есть мы одну ветку выкатываем в этот момент все клиенты сидят на 2 ветки серверов затем у выкатываем другую ветку клиента перемещается на первое виртуальных машинах мы это все расстраивали это все настраивается пишутся длины длинные скрипты дупло и тем не менее это все можно настроить но здесь опять же таки это все идет из коробки может балансировкой ситуацию можно сказать аналогично здесь опять же таки вам нужно поставить будет и джинсы х прокси и прочие вещи здесь она условно из коробки потому что ее все таки придется крутить руками но тем ни менее как вы видите что в большинстве случаев все таки жить в контейнерах в сочетании с регистрации достаточно комфортно мы это используем что мы в итоге получили в данной системы когда мы решили что вот раз было монолит моего разрезали то к чему вообще в принципе шли в данном подходе мы можем масштабировать у нас была одна машина стала две машины можем поставить еще четыре машины если мы отлично управляем конфигурации то нет проблем поражать и кнопку поднимать эти хасты инсталлирует туда надо купюрница он сам поймет что у него стало больше машин сама размажет эти контейнеры по себе их станет просто больше у вас здесь есть отказоустойчивость то есть нас есть те же платежи если одна машина полностью падает или один контейнер полностью падает а на другой машине у нас соответственно появляется ну то есть клиента ходит на неё и в принципе мы сохраняем функциональность более того мы можем по-разному нагрузку точнее нагрузку распределить процессор на и время в принципе по систем то есть платежи мы можем делать трехкратное дублирование то есть у нас получается 6 копии контейнеров акции допустимых никто не потребляет там они за кашированные там дергают один раз день они в двух экземпляров всего лишь находятся и таким образом мы выделили больше ресурсов платежам более того если вы все инкапсулируем в контейнер и у вас все достаточно гибко если у вас идут платежи допустим в пик с 16 до 21 вы точно так же немножко поковырявшись можете уехать в облака насколько мы делать финансовая система у нас секретные данные там банковские карточки там и мира фамилий людей мы облака не используем но тем ни менее об этом нужно знать что вы можете заказывать машину увози туда контейнера потом их убивать на этом все ваши вопросы спасибо спасибо а и так коллеги мы задаем по одному вопросу если у вас несколько то ждете пока к вам вернется микрофон если у вас есть дополнения замечания или что обсудить потом в кулуарах из тебя нужно будет запомнить какой вопрос самый крутой и потом нам ткнуть пальцем и сказать что спрашивали так кто первый прошу вас алексей компании патрон у меня первый вопрос по поводу тестирования компонентов in the end вы говорите о том что все компоненты должны протестировать в разных версиях друг с другом вот у вечером спускаете тестирование нефти в тех версиях которые были зарелизили контур как это все выглядит вот у меня например новая версия там и сама сервиса и я вот его выпустил и я должен написать тесты для абсолютно всех остальных сервисов которые работают ну там платежи например у меня там 1 2 3 редакция есть и вот я выпустил третью редакцию sms-сервис а я должен написать для каждого сервиса платежей там сервис еще какого-то написать тесты для тестирования с третьей версии sms я понял у нас есть вы дали команду тестировщику который занимается именно эту это то есть я тестирую это не загните пользовательский сценариях они кодируют это на питоне то есть они сначала все прокликивает руками и после этого кодируют тестовый питоне 2 пи тесте у нас появляются некие регресс теста вот эти регресс тесты как раз и функционирует каждый ночь они их соответственно дописывать оперативно то есть это отдельная команда тестирования я я имею ввиду то что вот у меня по три версии каждого микро сервисы я должен написать огромная-огромная огромное количество тыла платежей первая версия что у меня будет работать с третьей версии микро services отправки там е-mail отправка еще еще кое-то микро серость и щеку это микро сервис я должен покрыть тестами каждую версию своих прошлых микро сервисов с новым выжившим микро сервисом там затормозить и здесь какая ситуация получается тесто которые мы уже написали для определенных версиях мы просто перри используем если эта версия не поменялось в контракте место есть появился новый запрос но в него версии не поднялась ответственно его будут проверять те же самые тесты это делается с помощью как раз библиотек когда мы разрабатываем юзер стори то есть тестировщики сидят вместе с нами и они соответственно свои эскизы которые будут писать а не учитывает то что у нас вот в этом методе версии поднимется и они соответствие пишут новый тест keys это как раз новые контракты которые у нас поменялись старые контракты гоняются теми же самыми тестами за счет просто перес пользованию перри использование рулит коллеги следующий вопрос я вижу там вопрос я здесь спасибо за доклад вот у меня один вопрос по поводу использования очередей при общении микро сервисов просто мы пробовали у нас большая боль с этим было и мы в итоге ушли на http вот вам не кажется что это через ночного усложнение нашли теперь вот сколько у вас сервисов как общаетесь как кирпичи делаете можете поподробнее до записи здесь есть некая проблема то что мы одно систему делали наши теперь суть в том что как раз я говорил о боге проблема мы не можем с помощью кисти теперь решить такие их можно решить но это весьма сложно ивента это решает гораздо проще даже самой отложено согласован студентов делается как я как раз показывал вторых у вас может быть каскадные зависания если вы поставите тайма вот это пусть его в разных местах и вас там 1 c 1 начинает работать медленно другие сервисы начинают ждать по тайм аут и другие еще ждут этих сервисов потом от вас по сути каскад на зависание здесь можно использовать rpg maker давненько вы его используете но что касается очередей герпесе мы реализовываем средстве mass transit а то есть у нас идет на рыбе темпе в сочетании с масс транзитом там у вы можете как раз про стать event зная его иди ожидать его ответ на этот ивент то есть рпц у нас нет такого что он все на ментов тут все асинхронно где то нам необходимо все такер писем и его ли способ реализована таким вот образом что мы живем один ивент и ждем ответной айди этого вы поняли да это рисуется с помощью mass transit а там эта стандартная функциональность скажите вот вас если там новой очереди или я не знаю рафтинге ученик используйте вот это тоже же боль мониторить когда на продакшен допустим выкатывайтесь вас допустим добавилось там два сервиса у него там пять новых роутинга в какое-то поддерживаете в актуальном состоянии на различных средах можете еще погромче что что поддержим но состояние роутинга в рыбе те которые анализирует сообщение там в принципе опять же таки mass transit вам все это делает из коробки мы используем данную фитчу то есть у нас появляется новый какой-то консьюмер у нас автоматически создается качаешь и q спасибо показанный проблема особо не сталкивается быть может когда-то возникнет придется разруливать здрасте кирилл евгений мне завтра стану можно предыдущий слайд там где были квадратики скажите пожалуйста вот на этом слайде где тоже у вас есть стоит база данных вы говорили она вот в этих квадратиков купер нет все нет или кроме база данных если где-то еще стоит вот здесь и как вы обеспечиваете вот стоит в приложении смотрите стоит мы не вносим а в контейнерах то есть мы все база данных ребят и мы все врозь им на виртуальных машинах в эта хвостом но тем не менее мы как раз применяем управление fun структуры skoda то есть это энцикл т.е. для того чтобы нам понять нового рода ноту cabernet с или новую базу данных ну там развернуть полностью позже с нуля мы нажимаем кнопку скрипт запускается раз создается то есть весь петли с мы храним вне контейнером в контейнерах у нас только исполняемое приложение 1 процесс один контейнер поспорим ap оси больше добрый день вопрос такой вот когда вы говорили разбиение компоненты на микро сервисы то что у каждого должна быть своя база данных и там каждый владеть своей сущностью которым оперирует как быть если там внутри системы там эти записи будут обладать какими-то метками там жареными типа владелец кто-то создал эту запись там права доступа к ней там еще что-нибудь да смотрите если у вас есть сервис который должен отвечать за какие-то права доступа просто это будет храниться в одном сервисе другие сервисы быту не в эту информацию запрашивать и он может эта информация отвечать то есть примеру те же самые с этими он хранит его кто когда заходил с какими там когда у нас isis текут и система можно соответственно запрашивать у него есть и клали такая система отвечает нет ни стекла и так далее тут два варианта во первых вы можете сделать избыточность то есть вы можете чуть больше то на хранить в образно сервиса главное чтобы их они как-то синхронизировать второй момент поскольку сервис отвечает за конкретный функциональность вашем случае нужно посмотреть где эта конкретная функциональность про как раз права и нести туда другие сервисы могут и запрашивать третий вариант когда у вас есть какие-то справочные данные то есть обычно там у курсы валют код и стороны так далее несколько сервисов тоже могут и детально использовать тут варианта два либо вы просто копипастите если вы понимаете что вы копипастите две таблицы еще ладно куда ни шло до сих 5-6 10 здесь уже имеет смысл соответственно вы видели тот самый глупый сервис про который говорил котором вас будет просто к вере и который просто по запросу будут отвечать отдавать коды стран добрый день меня зовут голодный зорг утка у меня к вам такой вопрос вот вы говорили что вы используете ластик search для того чтобы хранить логии своих микро сервисов если их много очевидно что там большой достаточно поток может существовать вот этих вот логов которые к вам приходят плюс вы даете этот сервис опять же службе поддержки для того чтобы потом разбираться каким то конфликтными ситуациями пожалуйста у вас есть это это как единая точка отказа ватой ластик search или у вас там какой то есть дублирующие решение потому что если он умрет у вас есть поддержки отключится и из там разбираться ибо жить будет сложным как вы в этой ситуации поступать вот смотрите тут во первых два варианта во-первых мы используем связку файл бит + аластер все rus + key бара такую связку и каждый сервис ворвался пишет плохи все-таки под себя файлы то есть если ластик сюжет опустим прилег file pid потом спустя время эти все файлы тут отошлёт они так или начатом окажется второй момент самый ластик search можно отказоустойчивый кластер поднимать если он упадет у вас будет работать просто другая база это больше от минска тему как там это работает я не в точности не знаю нас поднят отказываться еще классно здравствуйте здесь подскажите просто как вы versio неру и те события которые вы отправляетесь если вы фиксируете это в таблице каждое событие если у вас структура события меняется вы отправляете это событий несколько раз с разными версиями нет она не меняется мы добавляем новые событие у нового события соответственно появляется новый диффе которого это та ну когда она в эту таблицу кладется а если сервис еще работает со старой версии событий а что с ним делать и как это все выкатывает соответственно а вы имеете версии контрактов виду соответственно старый сервис просто путем открывается 2can сюмера который поддерживает новую версию старую версию сначала выкатывайтесь сервис который слушает потом уже тот кто генерится быть и seba вращалась алексей у меня ещё один вопрос по поводу версии микро сервисов вы говорите что вы поддерживаете максимально три последние версии микро сервисов и микро сервисы у вас общие для разных систем то есть вы повторяете вы разворачиваете же одни и те же микро сервис используйте в разных системах у вас получается какая-то зависимость то есть если вы там поддерживаете систему и она не очень часто обновляется то при обновлении там пример микро services м.с. вам придется обновлять все все все системы которые от него зависит я правильно понимаю у вас интернет банк там знаешь в банк и интернет-банк там не знаю еще какой-то интернет-банк еще какой-то и у вас там последняя версия там выходит 4 версии с микро сервиса а вас там альфа банк который уже практически не работаете с ним и работает там на первую версию вам придется и и систему альфа банка также обновлять чтобы он работал с другой версии микро сервиса наверное всегда зависит во первых у него будет три версии в которых он может осознать то что ему нужно перейти то есть мы выпускаем 1 версия начинается не работать потом мы выпускаем вторую уведомляем их тоже у вас вышла вторая они соответственно бизнес-процесса уже настраивает на то чтобы вторую версию используется третью вот когда мы уже выпускаем какой-то 4 версию которая просто разносят весь функционал конечно же мы подключаем этот функционал но это в больше коммуникации между партнерами соответственно они обычно переходят и все в порядке мне было еще случаев когда не не переходили в основном мы вот как раз тот случай когда мы 7 версии держали это был тот случай когда у нас внешняя система говорила что пока мы ещё не можем перейти а бизнес другой страны говорил давайте добавлять новую функциональность и вот мы дошли до эти 7 версии но потом все осознали и соответственно чили уменьшать но это наверное когда есть возможность принудить или заставить просить клизму возможность есть у всех вот буквально вчера обновы открыл ватсап а он сказал что он не откроется пока не обновить версию это как раз было примерно та же самая ситуация то есть это неизбежно поддерживать все версии вы не сможете что в одной версии вам допустим нужно в одном формате то в другом абсолютно в другом формате то у вас есть метод где-то вы удалили в следующей версии олеге переходим к следующему вопросу рядом с вами у меня микрофон да спасибо за доклад такой вопрос вы на одном слайде показали что вы разделили умные сервисы и глупые сервис вот допустим два умных сервиса взаимодействию да через шину и к примеру умный сервис послал сообщение на шину и другой сервис хочет его обработать ее возникла исключительно ситуации но там например бизнес-логика сработала там неправильно или у него база недоступна или там вообще косяк там в сообщении ну допустим нет поле какого-то и он не может его обработать чего с ним происходит как зам случайно завещаю защищает больше брокер то и сообщение просто вернулся обратно к нему он просто будет опять же обработка будет пытаться ему послать их заново потому что когда консьюмер обрабатывает иветт он выполнен все бизнес-логику есть она корректно и правила он отправляет сообщение о том что он его обработал этот ивент его помечаются как и работали соответственно в данном случае у нас возник некая ошибка мы просто не подтвердим обработка этого vento он будет передано другой системе ну то есть другому сердце там тоже такая ошибка top будет так висевший бокам от ним очень то есть по сути у самого первого сервисы будет накапливаться тогда видится событий бывший не будет накапливаться в шине будет на сервис и сервис это таблицы так и так на как накапливается мы ее не ощущаем мы просто меняем статус с new на обработан то есть мы не удаляем запись на тот случай как раз если что-то пойдет совсем не так и нам нужно будет все все таки да отправить провести какую-то повторную синхронизацию у вас есть какой то механизм допустим исправление событий автоматическому допустим накопилась там их не знаю несколько десятков тысяч и пока такой ситуации не было пока такого механизма нет коллеги последний вопрос после чего ловим спикера в кулуарах здравствуй александр такой вопрос вот вы перечисляли минус и плюс данного подхода и я хотел уточнить насколько критично с точки зрения производительности вот разбиения такую монолиты на большое количество микро сервисов то есть если мы там ночным в одном жизненном цикле гонять данные по множеству микро сервисов то есть там через интернет или ещё как-то то есть насколько сильно может упасть при невыполнении этого жизненный цикл я пола вопрос смотрите тут ответ достаточно простой если вы неправильно диком позируйте расами сервиса вы соответствовать система просто станет явно медленнее так или иначе выигрыш-выигрыш происходит на том что мы можем маленькие кусочки выделить им отдельная машина и там они будут выполнять свои задачи более быстро если мы допустим на одной машине это поставим будем пытаться эта машина вертикально развивает из добивается добавлять оперативки добавлять процессов и во первых очень дорого вот а здесь мы можем маленькие кусочки разнести на разные виртуальные машины сетевого планида в сетевом плане вы как раз понятно что вызвать процесс внутри процесса какой-то метод гораздо быстрее вызвать его посетил это так но если мы провели диком позировали делать какие-то отложенные запросы которые вас принципе устраивает что попросили через три секунды вы можете набросать примеру 10 тысяч сообщений в тоже ребят и потом поставить несколько десятков кантемиров которые будут обрабатывать они разгребу те же самые смазки достаточно быстро в монолите это будет сложнее уточнить мы сможем в кулуарах спасибо кирилл аплодисменты"
}