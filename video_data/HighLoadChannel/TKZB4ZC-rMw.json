{
  "video_id": "TKZB4ZC-rMw",
  "channel": "HighLoadChannel",
  "title": "Микросервисы для Machine Learning / Дмитрий Ходаков (Avito)",
  "views": 2056,
  "duration": 2482,
  "published": "2018-01-16T12:22:48-08:00",
  "text": "а где мы ходоков давайте поприветствуем его здрасте друзья меня зовут дима и я занимаюсь в авито занимайся авито рекомендациями то есть у нас есть команда людей которая реализует фактическое машинное обучение сегодня будет небольшая история что вы наверно уже стали столько слышать различные доклады я вам расскажу историю о том как мы даже две истории первая история будет про то как мы в принципе достаточно традиционные микро сервисы использовали для системы раздачи контента на наших рекомендациях и применение моделей в реальном времени вот а вторая история будет не такая традиционная она будет про то как мы весело распиливали наш монолит pipeline а рекомендательные системы на микро сервиса ну или почти на микро сервисы вот ну что ж давайте приступим потихонечку значит я постараюсь поменьше внимание в этом докладе уделяется непосредственно машинному обучению которую мы применяем но к сожалению придется немножко про это рассказать рассказ будет такой очень обзорный простой вот и постараюсь побольше акцент сделать на то как нам сосны микро сервисы помогли почему без него у нас скорее всего ничего не получилось и так сосна мы его вид а иногда рекомендациями занимается занимаемся что это вообще собственно такое вот у вас есть сайт с объявлениями есть обычное объявление обычных юзеров то есть они как правило не проплаченный не реклама и их очень легко потерять массе контента у нас где то 30 миллионов чем-то активных объявлений они постоянно обновляются кто-то закрывает что ты счастлива продав кто-то закрывает что-то не успев что-то продать мы бы хотели чтобы пользователи поскорее находили вещи которые нужны открывали для себя что-то новое и продавали вещи те люди которые продают вот собственно какая наша миссия простая мы свои рекомендации при этом показываем через несколько каналов то есть один из них это рекомендации на главной странице мобильного приложения открывать мобильное приложение если вы залогинены или вот сейчас тоже есть не залогинены вот скорее всего вам показывается что-то вроде близко к вам какие-то интересы возможно по категориям которые вы смотрели и в них уже всякие штуки в основном я сегодня буду рассказывать так так это я буду рассказывать про то что здесь написано call обороте фильтр рынка recommendations но и немножко про все остальное еще мы показываем рекомендации в письмах то есть человек что-то делал если он подписался на каких новостные рассылки то ему иногда будут эти штуки приходить так это в общем кратенько про то какая наша была цель значит теперь поехали прямиком в вегас у нас как говорится было 30 миллионов активных пользователей 22 миллионов активных пользователей 30 миллионов активных объявлений и в наше хранилище уже очищенных действий по экстриму ну собственно то как пользователи кликают или врачей воздействует с какими-то это маме у нас сыпалась 1,3 миллиарда событий в день но это примерно там когда больше как на меньше выходные праздники вот сейчас уже наверняка гораздо больше там я не проверял наверное полтора миллиарда сейчас уже точно есть в среднем событие вида юзер айди взаимодействовал сайтом айди каким-то каким-то определенным образом и наша задача в самом самом простом виде будет выглядеть так давайте найдем сейчас каким-то образом похожих пользователей вот в данном примере пользователя 1 и 2 вместе смотрели ой там 10 как бы все понятно давайте теперь пользователя 1 по рекомендуемой 30 которой он не смотрел за то смотрел пользователь 2 ну пользователь 2 free каменную майкл 20 вот такая вот очень не замысловатая штука это такой прием называется коллаборативный а фильтрация это то чем мы занимаемся в некотором роде такой же только намного более сложной ну намного более хорошо работающий потому что как правило мы можем взять попробовать зацепить 2 пользователей оба из них у возник смотрели какой-нибудь один интересный там например пивной аниматор которого просто посмотрела там за один день 300000 человек потому что он за for sale so где-то в социальных сетях и это интересная работа за 50 тысяч рублей надо уметь vip выпить 8 литров пива вот это это объявление смотрели почти все а вот поэтому 20 30 могут быть совершенно различными начиная от того же пиво заканчиваю платьишко и вот какому-то любители пива и мы подарим платьишко вот будет не очень хорошо ну ладно в общем это примерно как ставится наша задача мы должны можно наши машины чем на чему-то должны учиться и показывать это реальным людям вот самая большая проблема здесь на самом деле пока с реальным людям потому что как правило сейчас далеко не всякий алгоритм машинного обучения может действовать быстро то есть давайте подумаем нас примерно есть 200 300 миллисекунд на то чтобы подумать а потом что-то пользователю показать далеко не каждый алгоритм способен одно предсказание сделает за 300 миллисекунд вот а если способен то мы будем сильно ограничен в выборе инструментов собственно потихонечку вот тут начинаем подходить как основатели мое моего рассказа почему микро сервисы как они нам собственно помогли строить вот такие вещи у нас во вида если вы были на предыдущих докладах этой секции наверно уже рассказывали про то что у нас есть большой монолит как и у многих других людей сначала мы построили какой-то большой монолит а потом начинаем распиливать его на микро сервиса этот хороший естественный порядок вещей нужно сначала убедиться что какая-то вещь полезно а потом строить из неё космолет если это нужно так вот мы начали делать рекомендательный сервис а где то год назад и к тому времени мы уже активно уже активно внедряли вот эта микро сервисной архитектуру основном строя и и вокруг авито то есть ну ребята вот распиливали монолит они другие ребята которые задавали что то новое а не просто приделывали так сайты вот наша сервиса это по сути вещь которая приделана к сайту значит и вот больше всего от нее мы хотели поначалу быстрого роста кодовой базы чтобы быстро имплементировать новые фичи потому что скорость разработки этого монолита она одна скорость разработки новых сервисов нравился совершенно другая то есть можно там где плавится по три раза в день никаких проблем и аккуратненько делать все на совершенную другом стать а вот совершенно другой стэк это одно из ключевых условий здесь потому что вот вы садитесь хотите реализовать какую-то систему машинного обучения как правило вариантов которыми можно сделать масса можете не знаю взять hadoop spark можете взять на питание через escalera все сделать можете сесть и написать на тензор холл с использованием его то есть и причем никто не знает пока вы пока вы не попробуете по-настоящему как это все работает скорее всего не узнаете что из этого лучше что из этого более правильно поэтому надо пробовать быстро и мы не хотели зависит от какого-то определенного стока технологий микро сервиса тут очень сильно как мне кажется мы могли помочь потому что совершенно независимые вещи можно одно сделать на одном стаке другой сделать на другом стать и потом связать их совершенно прозрачна друг для друга и получить прибыль если нам нужно быстренько переписать какой-то сервис никто из других участников регаты не поймет что произошло просто один сервис подменил за другим предсказанию остались примерно в таком же формате вот и к сожалению у нас есть один нюанс то есть мира сервис они как правило подразумевает некоторые stay close то есть у нас нет внутреннего состояния но в машинном обучении почти все приседания которые нужно сделать они подписываются тремя шагами нужно взять какие-то данные нужно на них научить модель что-то запомнить вот ее внутреннее состояние это и есть ваша обычная система а потом нужно ее применять к сожалению между шагами 2 и 3 есть передача какого-то состояния то есть у нас фактически стоит full service и зачастую получается можно решить эту проблему по разному ну вот сейчас я расскажу как то есть вот что мы хотели значит ну я сразу расскажу к чему пришли потому что мы писали это все наверное сразу по нормальному если вы были на докладе сергей орлов у или на предыдущем докладе коль этого уже наверное знакомая картинка сбей twain есть замечательный паттерн авито сайт он большой монолит и вносить него изменение дорого давайте просто пусть он будет один раз обращаться в нужном месте с одним и тем же api к одному gateway вот погиб и уже дальше будет сам решать что с этим обращением дальше делать мы знаем что у нас есть некоторые некоторое количество различных представлений рекомендаций то есть какие-то из них показывается в одном месте одним образом какое-то количество в другом месте другим образом и вот так можно их условно по рекомендательным бэкон нам разнести то есть есть то что будет показано грубо говоря в блоке гиа рекомендатель бэкон так в блоке коллов там backend b и еще какие-нибудь там рекомендации который мы хотим довольно быстро кстати добавлять то есть сделать это максимально прозрачным для сайта то есть стать просто знает места где надо размещать бэкенда уже сами решают как это собственно будет передана дальше будет показана еще важный момент мы в процессе разработки быстро поняли что даже когда мы стараемся сделать рекомендаций быстро это не значит что нам это удастся вот представьте въезжает запрос там usa радиста какой-то контекст и знаю что сегодня день что человек запросил из кремля что то и значит давайте покажем 3 блока что собственно может произойти плохого боке а и b могут быть быстрыми и ответить там за 20 миллисекунд блок c может задержаться он полез в какую-то базу для сейчас все очень грустно или он решил рассчитать какую-нибудь сложную вычислительную сложную вещь и вот вуаля мы имеем таймаут на всех этих сервисах поэтому здесь gateway не совсем прозрачный точно он вообще довольно прозрачный но в нем есть какая-то логика юная придерживается это логика в том что если один из брендов не успел ответить за допустимые тайм-аут ничего страшного просто собираю ответ из них ну просто его исключим как за тайма ученая все остальные ответы будут собраны вместе и показаны тоже все вместе без недостающего вот этого друга вот и гид в ней в некотором роде распределяет нагрузку на каждой из этих брендов сам дожидается асинхронно того что происходит вот но это как бы очень короткий план вот такой же короткий план только со стэком технологий просто чтобы просто чтобы рассказать что у нас там есть еще можно использовать значит ну gateway и того потому что на него из всех этих блоков которой здесь нарисованы наверное самая большая нагрузка и он должен уметь асинхронно еще в целом в нем немного сложной логики то есть там все довольно просто слава богу мы любим когда сделано просто вот чтобы поменьше инстансов плодить вот здесь рекомендует фейк нога каждый из брендов мы сейчас спишем на питоне потому что они в целом не настолько высоконагруженные к сожалению не удается избавиться от какого-то количества сложной логики в них мы просто исторически так сложилось что у нас та команда да это санс который занимается рекомендациями так как практически на каждая команда у нас lavita это сами занимается мы пишем на питоне вот на питоне и нагнулась и вот и потому что этот стек хорошо совпадает с тем стеком машин ринговой штук который мы используем вот и значит нас каждый каждый backend каким-то образом ему приходится взаимодействовать с этими внешними штуками например вот тому тому битвы этому бренду который показывает рекомендации похожих ему требуется сложная комплексная модель которая к сожалению за 300 миллисекунд прямо сейчас не способна отвечать на вопросы что какие айтемы вот этому человеку надо порекомендовать она думает намного дольше вот задержка у нее конечно просто кошмарная а еще запускать эту модель в продакшене по крайней мере в класс старику бернейс возможности вообще никакой не представляется потому что ну она очень ресурсоемкая то есть очень очень очень она много-много считает на циpкa и поэтому тут мы просто взяли и сказали а давайте возьмем результаты ест будем регулярно кэшировать то есть задержки настоящие рекомендации сейчас вот в этом блоке в половине случаев я не более наверное полутора часов то есть пульт человек какие-то действия сделаю сайт ушел вот потом возвращается через какое-то время снова его для него новые рекомендации до тех пор пока этот тайм аут не отчитался будут старая рекомендация мы берем значит это все и просто копируем в dice вот есть те кто пытается отдавать рекомендации онлайн ну прямо на ходу что считая там более простые более линейные модели который умеет отвечать за менее чем 300 миллисекунд и вот они используют тоже всякие бэкенда для получения данных типа вот у нас есть но сиквел тарантул у нас есть сфинкс и какие-то простые модели которые зачастую просто при дрочи таны вот примерно как у нас устроено раздача рекомендаций это в целом достаточно традиционная схема наверное для микро сервисов и тут нам очень здорово помогло то что мы можем использовать какие хотим бэг-энда то есть мы возьмем чего не захотим переписать на go никто ничего никогда не заметит мы можем добавлять бэг-энде самостоятельно когда хотим это очень быстрый процесс делается на раз два в отличие от внесения изменений непосредственного вида и все это довольно легко менеджер лица потому что кругом все в метриках вот володи рассказывал историю про то как правильно делать мониторинг и вот с точки зрения юзера это выглядит все замечательно берешь сервис быстро описываешь в нем ямал файл 9 вешаешь всякие alert и эсэмэски тому на какие метрики на то что что надо собирать что является критичным он автоматически при деплоить и создает все alert и в море пути есть дашбордов графа не где ты прекрасно видишь что идет не так в общем в целом удобно здорово нравится быстро деплоить еще у нас есть вот у нас питон ну как материал для изготовления этих брендов используются мы там используем торнадо вот сейчас с новыми питонами осинка можно дружить сторона до довольно легко вот написали свой свой фреймворк для написания микро сервисов на торнадо называется hurricane и очень удобно steam с его помощью писать микро сервиса то есть там от такой замечательный бойлер plate где от необходимости создания новый сервис нового сервиса до тепло его в продакшен проходит там не знаю час итого которые тратятся на написание тестов и кода такого для основного хендлера вот теперь давайте поговорим немножко про то что что под капотом более умных рекомендации который не является онлайн моделями и про не совсем традиционный микро сервисы которые как мне кажется удалось здесь имплементировать то есть чем мы начинаем оффлайн модели для нас как вот для тех кто занимается рекомендательными системами сейчас это факторизации он ее машины вот регулярно проводится конкурс приятелем системам про который я вот только что рассказывал почти уже не знаю много лет может быть лет восемь доминирующим наверное в этой области является подход который одевается авторизационные машины это по сути если если очень коротко у нас есть матрица пользователей пользователей и атомов и их взаимодействия это матрица в она может быть очень разреженный потому что пользователь берет и смотрит в день 10 айтемов всего аваль это 30 миллионов атомов и соответственно он грубо говоря какие-то оценочки 10 объектом из 30 миллионов проставил вот и так сделал каждый пользователь и каждая строчка на каждого пользователя и это каждая колоночка на каждая этом и вот нам по сути что нужно сделать вся задача заключается в том чтобы теперь взять и попытаться проставить машиной оценочки недостающий то есть остальные двадцать девять миллионов а цены чек который пользователи мог поставить попытаться их проставить и вот есть вариант решения когда ты пытаешься создать две такие матрицы которые при умножении дают по некоторой мере максимально матрицу максимально близкую к исходной матрицы с оценками вот одна из этих матрицей будет отвечать за пользователей а другая будет включать за это вам если у нас есть какой-то а этом или пользу пользователь который ничего например не проставил или ой там котором например мало людей посмотрело это в принципе ничего страшного для факторизации он их машин это небольшая беда итак для того чтобы делать вот такие штуки существует большое количество окон собственных решений почти никакой из них хорошим не является к сожалению то есть они правда когда начинаешь смотреть быстро приходишь к выводу что вот популярное направление в машинном обучении там нейронной сети деревья решений они реализовано один раз и очень хорошо проблема рекомендации она именно в том что очень сложно выработать какую-то объективную метрику машинного обучения которое позволит один раз с высокой точности сказать что да вот это были хорошие рекомендации ну к этому мы вернемся еще чуть чуть позже к объективным метрикам их метрикам которые вырабатывают математика взяв однажды вот такую набор решений мы пробовали много разных значит пришли в итоге какому-то своему которые tune ли tune ли ну получая более правильный ответ и с нашей точки зрения более хорошие рекомендации мы сожалению остановились на том варианте это был один из самых легковесных в котором мы 5 часов грузим наши данные 6 часов обучаем модель на кластере и 7 часов применяем эту модель на кластере использование пошел количеству чтить их ресурсов в целом для многих задач машинного обучения такая ситуация типична но к сожалению в общем тяжеловато соответственно это все можно очень просто представить четырьмя кусочками которые как вы наверно догадались можно легко слепить в монолит потому что естественным образом разработка таких вещей она ведется итеративной много раз делаешь пробы различные давайте попробуем вот это давайте попробуем вот это давайте сравним между собой потом таких вещей образуется 25 вот это все образует такой монолитный pipeline данные они кочуют из вот из одного квадратика в другой данных этих получается довольно много то есть каждый квадратик передает наверно друг другу гигабайт по 100 за 1 и таким образом мы получаем полное время доставки модели в продакшен где-то 20 часов то есть пользователь что-то накликал через 20 часов это окажется в продакшене то есть она это реально увидеть во время передачи этих данных в вообще в этих моделях там что угодно может пойти не так потому что мы пробовали большое количество различных штук некоторые вещи показывают совершенно прекрасные результаты например но очень весело отлаживается когда вы так просто где-то там внутри сиквел ты просто смотришь думаешь ара отлично неплохо там хочется запустить gdb или в окно выйти что то одно из этих двух надо сделать ну так как я здесь пришлось бы запускать мы постоянно меняем внутреннюю реализацию и то есть однажды зафиксировав этот прекрасный 20 часового монстра мы не факт что даже на тех же новых данных ну просто придут новые данные с немножко другими параметрами кто знает что мы узнаем в процессе скорее всего будет ну может может результаты могут отличаться как говорится вот и самый главный момент конечно всегда хочется проводить аб-тестирование потому что это очень объективный способ отличать зерна отправлял в машинном обучении и это очень важно потому что есть объективная реальность бизнес метрики то есть наверное на эти рекомендации пользователи кликают они им нравятся они не оставляют негативного фидбэка и конечно вот на такой вот штуки watch дочь сложно вообще как-то двигаться вперед есть команда к тому же разработчиков который этим занимается не очень большая но мы занимаемся иногда разными частями и дипломант вот такой штуки который работает 20 часов это развлечение так себя значит чему мы долго думали значит и решили сделать каким-то таким образом у нас было 4 квадратика в рамках одного монолита давайте теперь мы каждый квадратик сделаем неким демоном неким сервисом который будет сидеть и обмениваться информацией с другими квадратиками сожалению мы не можем просто кидать и теперь и квесты передавая друг другу по 100 гигабайт это был в ну просто крайне нецелесообразно и к тому же это надо было бы делать редко поэтому мы передаем только сообщение с контрольной информацией то есть например это контроль информация обычно выглядит следующим образом я такой то такой то я закончил свою операцию и данные по ней с таким то едишь ником можно забрать примерно там то вот быстро также стало понятно что информацию информацией о том откуда надо забирать данные должен владеть тот кто кто их кто их по три ляет дальше то есть вот в этом конкретном примере мы сначала загружаем какие-то данные когда когда загрузка завершена мы просто кидаем сообщение дальше куда-то в какую вко в какую-то корзину потом мы туда подключаем могу обучать иры моделей а и b вот они сами подключаются к этому их чтению и слушают вот получив это сообщение они начинают работать дальше обрабатывая данные потом кладут свои данные куда то другое место и передают дальше контрольное сообщение вот так вот можно подключать друг другу как деревом в вот такую систему позволяющую делать различные бы тестирование то есть чтобы одновременно учились разные модели и не повторялись такие дорогие для наши шаги как вот загрузка этого клик стрима как обучение модели потому что зачастую именно различия находятся на каких-то более поздних шагах нет смысла два раза учить модели особенно учитывая то что она берет и занимает весь сервер там с 56 ядрами занимая по 500 гигабайт оперативной памяти там лапать это 5 часов это очень такое дорогое занятие вот ну и конечно у нас тут сразу сплыла необходимость ну точнее необходимости скорее такое технически решением решили использовать ребят как среду для передачи этих контрольных сообщений ну естественным образом потому что можно сделать фанаты клинч и не обязательно знать тому кто произвел какие-то данные кто их потом заберет то кто хотите подключаетесь создавайте свою очередь и слушайте на фанаток очень я все получат это сообщение свою копию этого сообщения также на нем прям сразу можно балансировать то есть например половинку рекомендации будет делать один предиктор половинку рекомендации будут делать другой предиктор вот это такой некий способ создавать вот об этике рования то есть здесь каждый квадратик это сервис отдельностоящий можно их таким образом совершенно по-разному деплоить значит ну вот это примерно примерная схема который мы в итоге пришли но это еще на самом деле не все в процессе процессе работы вообще с программами за час часто сталкиваешься с тем что у тебя что-то идет не так какие то внешне внешние факторы когда эти программы чему-то учатся в процессе это вдвойне правда потому что ну не все мужчины они модели детерминистической то есть вы в них разные данные суете они выдают вам иногда разные ну разный ответ логично иногда вы них одни и те же данные суете при немножко другом положение луны к нему вред другой ответ и ваша задача сделать это все предсказуемым то есть ну это нежелательное поведение вам надо с этим бороться и чтобы понимать что происходит надо все время держать руку на пульсе но когда распиливали вот этот монолит сразу же естественным образом появилась куча барьеров на нашем пути но таких ну в позитивном смысле барьеров как барьер синхронизации когда завершил работу загрузчик можно сразу же четко сесть проверить данные которые мы загрузили на кучу sanity чек вот мы как-то сидим вот у нас есть конечно всегда and the end тестирование это когда ты просто смотришь на бизнес метрики и радуешься что вот эта модель оказалась лучше чем вот эта модель на это больше кликают вот как хорошо потом смотрим чего-то 0 просто 0 м м так что за дела ну пришлось какое-то время по раскапывает собственно что пошло не так и по какому оказалось что ларчик просто открывался поступило 5 миллионов пользователей на вход quick stream дан ллодра но он что там по делу немножко я осталось 5 ну как 5 не 500 тысяч не 5000 а просто 5 вот и от этого все все очень сильно расстроилась потом бывает так что загружаешь какие-то данные в них просто физически и ошибки там не знаю айдишники другие и модель тоже чему-то научилась но ты не знаешь чему скорее всего чему-то плохому такое ощущение что она там упадет схватит дробовик начнет сару коннор их расспрашивать в общем за этим тоже надо следить поэтому помимо таких человек читаемых метрах там не знаю как какое количество каких-нибудь определенных данных и ну их другие какие-то человека читаемые характеристики мы зачастую смотрим на всякие сходимости то есть в огромном количестве случаев алгоритм машинного обучения это просто какой-то вычислительный процесс цикл в котором ты пытаешься уменьшить какую-то метрику ошибку ну и начиная с ошибки в один ты через двадцать-тридцать циклов не знаю приходишь помашешь к ошибке 01 это значит она чему-то научилась научилась устранять эту ошибку этого мы и добивались вот на это очень сильный мне кажется имеет смысл смотреть почти всегда берешь сервис и сразу же навешиваю на него такие метрики и сразу же автоматически смотришь потому что если внезапно даже эта метрика начала быть не 01 001 это возможно тоже не очень хорошо если ты сама этого не ожидал не изменив каким-то образом эта модель она почему-то сама решила так ошибку сбросить это повод начать расследование вдруг она правда стала какой-то слишком хороший и так конечно бизнес метрики это очень хорошо к сожалению в нашей конкретной задачи с din с метриками не так все понятно как они хорошо коррелируют с традиционными метриками для машинного обучения то есть ну давайте там посмотрим престижен recall вычисления таких штука но требует некоторого количества времени то есть вы во время обучения своих моделей просто отделяете кусочек данных обучаете модель без этих данных а потом на этих данных пытается сделать предсказание получаете в целом некоторые объективную величину как это объективная величина коррелирует всем будут люди кликают на рекомендации или нет на самом деле довольно трудно сказать то есть мы долго старались выбирали именно такие метрики которые позволяют предсказать скажем так настоян настоящий бизнес метрики бизнес-задач там есть ну как сказать в общем такая довольно непростой тасс но проводить его точно надо и к сожалению даже несмотря на то что это там занимает нескольких часов вычислений вот такие штуки посчитать даже не смог даже для моделей которые просто deposits of production для которых мы всё равно узнаем бизнес метрики для них почти наверняка имеет смысл провести это вычисления потому что она может на ранних этапах позволить вам чего-то если вас модель что-то плохо посчитала что ты не заливать то есть это вот уже как а скорее не про микро сервиса это просто для машин unique вых моделей потому что есть модели которые показывают такие высокие числа ну например который по региону умеют угадывать машину ну то есть человек что посмотрит смотрит смотрят баха ему одни лады приоры выдаются а потом выясняется что дело в том что он просто что он просто смотрит откуда-то из горных регионов а там все именно так ну даже как-то проводили исследование человек например подает объявление вот мы хотим забор себе поставить поэтому продаем свою приору дома геометрия забора материала из которых нужно построить там человек хочет там что-то одно продать и продает как ладу приору проводили опрос они сказали да вы просто не разбираетесь мы всегда у нас ничего другого не смотрят поэтому высший способ счет продать это размещать как привода вот так что не знают вообще хорошо или плохо но мне метрики типа дает эти оказались не очень а люди реально кликают вот значит делая вот это все что я сказал мы пришли каким-то некоторым выводам для себя таким чему мы собственным научились в процессе когда пытались при помощи мика сервисов улучшить наше мышление штуки мне кажется во многом это удалось главным образом dekra сервисы позволяют нам не боятся менять внутренности то есть мы просто берем одну штуку изменяем другой это некий набор взаимозаменяемых модулей и это очень удобно распиливать монолит их перевалив него какую-то совершенно другую технологию которая не знаю начале мы считать на джипу придется все переделывать вот не всё придётся переделывать только часть потом микро сервиса естественным образом строят на ваших моделях барьеры где можно сразу собрать готовые данные и померить все возможные метрики на них и это очень очень очень хорошая мысль мне кажется потому что как бы сразу держишь руку на пульсе сразу понимаешь все ли у тебя в порядке и даже если там потребуется нескольких часов вычислений скорее всего не стоит бояться просто поставить какой-то sanitec просто чтобы быть уверенным мониторинг весь автоматическим автоматически у нас автоматизируется очень приятно и здорово так хорошо и когда даже когда получается таки не очень традиционный стоит full service а как вот те которые я описал во второй части когда один сервис другому там по 100 гигабайт передает внутреннего состояния сидит и слушает на реддите какие-то непонятные сообщения есть хороший план чтобы сервис не знал кто подписан на его обновление и таким образом можно прозрачно для этого сервиса подключать к нему новых qamciq пенсионеров то есть вот нам нас очень спас шаблон продюсер консилер в этом отношении так ну на самом деле это все спасибо за внимание если какие-то вопросы буду рад ответить кто-то хочет задать вопрос никто не хочет этот вопрос есть если сзади ещё один будет а какие инструменты вы используете для обучения моделей вот что думаете по поводу там то взрыв ну например не обожаю здоровская вещь но не всегда для наших нужд это хорошо подходит мы сейчас только начинаем использовать картиночки для обучения у нас в основном много много всего из и скалярно конечно ну вот у нас основной стаккато питон много вещей которые используются берем просто какие-то страшные библиотеки для мать точно факторизации ну и для других сложных задач и дописываем их обязательно руками то есть вот есть допил копилка напильником и это не похоже на то пилку напильником это берешь циркулярную пилу и все под нож пускаешь потому что зачастую о концертные проекты вот в области которые не так хорошо исследована как например там сварочные нейронные сети был какой-то студент который делал какую-то выпускную работу и очень хорошо сделал например обучение модели какой-то необычный вот которой интересно было бы потрогать пощупать она вроде дает неплохие результаты вот а потом он свою работу защитил не знаю видимо купил себе ящик его и потом решил запостить оставшийся вечер доделать все что он не хотите все чтобы выложить это все в фан source и как бы смотришь тренировка прекрасно inference ужасен то есть надо все переписывать а так как зачастую там много считать тут придется приходится писать все носи вот это довольно весело но не всегда вот какие-то такие инструменты мы используем ваш вопрос привет как вы проводите бы я не очень понял глобально вот у нас на первой схеме где мы раздаём рекомендации у нас есть некий рекомендательный backend и он в ответе на запрос сайта он всегда рассказывает откуда он эти данные взял то есть мы грубо говоря вот здесь видно да вот здесь мы можем даже поставить несколько сервисов вот здесь по за backend м2 и каждый из них будет выдавать данные из немножко своей модели то есть можно так сделать можно вообще в редис просто классе с нужными ключами и когда данные будут загружены самого вид уже за лаги рует в наш калек стрим от какой модели пришли эти данные пользователь пользуюсь или на входе супер уйти или что пользователей на входе суммируете пользователь как правило фиксирован какой-то группе по какому-то хочу то есть можно взять юзер айди брать взять от него хэш да можно так можно другим образом сэмплировать можно там по куклам это смотря какая б тест хочется провести вот можно сделать эти группы плавающими можно наоборот фиксировать как мы потому что есть такой интересный момент ну то есть долгосрочное влияние моделей друг на друга если просто взять и начинать менять поисковую выдачу ли или рекомендациями на человека воздействовать глобальным образом поведение человека меняется там например начинает понимать ух ты вот это интересно вот я буду теперь и кликать а вот это типа перестану потому что можно было не знаю купить дешевле можно было вообще вектор своих интересов куда так сильно в другую сторону сместить и вот модель как бы меняя поведение своего пользователя а потом знаете что делает берет и учиться на этом и вот начинается какая-то такая странная штука если пользователей ловко ротировать между об и тестами можно такой штуки избежать но это не позволит получить полное представление о том что же собственно в этой модели конкретно происходит потому что она может как нибудь знаете сильно повысить конверсию в какой-нибудь определенной категории а потом сильно все дропнуть в результате каких нибудь негативных эффектов которые она сама там перри обучилась вот ну как то так какие еще вопросы скажите у вас поиск отдельной рекомендация отдельная то есть у вас windows пользуется он чисто для рекомендаций на самом деле это тот же самый сфинкс который мы используем для поиска для настоящего просто просто в нем лежит много нужных штук но это единый поисковый движок на самом деле скорее было бы правильно использовать отдельно какой-то свой а вы его используете как последний шанс типа если вы ничего не подобрал они тут просто иногда нужно быстро доставать айтемы то есть он используется как хранилище мы знаем некоторые свойства атомов которые индексирован и в некоторых случаях вот который не глубоко опускается в инфо модель иногда нам достаточно для некоторых случаев просто выбрать набор атомов а потом самостоятельно их проранжировать как я уже сказал для вот оффлайн штуковины который мы сейчас используем типа матричные факторизации нам нужно просто взять и для каждого пользователя проранжировать 29 миллионов атомов на самом деле иногда бывает неплохим планом не 29 миллионов атомов проранжировать а только тех которые гарантированно ему интересно ну хоть сколько-нибудь а потом выдавать из не на 10000 только 20 тех которые хорошие вот например так можно делать может у кого то еще появился вопрос спасибо интересный доклад а интересно узнать используете ли вы какие-то другие системы машинного обучения кроме как те на основе сравнения использования другими пользователями то есть без юзер фидбэка нет ни один . вот вы берете и предсказываете что если пользователь использовал там ой там 10 до и этим 20 минут на она на первом слайде вы потом совмещайте ну конечно по большим параметрам используйте любые другие то есть можно взять какого-то пользователя взять его развития да то есть они по совместимости да конечно спасибо за вопрос очень интересный на самом деле я это в докладе не осветил но то что мы делаем не очень похоже на то что показано на этом слайде то есть это это это самое ой вот это самая самая простая на свете коллаборативный а фильтрация вот уже достаточно хорошо понятно что почему все может плохо работать и факторизацией машина умеет восстанавливать очень сложные зависимости между интересами пользователей в том числе и контекстные то есть в том ну если грубо говоря правильно настроить этот резонный машину то можно понять что пользователи есть эволюции интересов то есть например не знаю человек смотрел собачек и уже много смотрел собачек потом ему скорее всего потребуется там не знаю миска для собачки корм для собачки что-то вроде этого вот это иногда можно отследить то есть задача видимо в том чтобы правильно настроить есть целый набор всяких интересных вещей вот прошлогодним rig se si были ребята которые делали улучшение за счет того что они делали нечто вроде марковских цепей то есть пользователь приходить при одних условиях сделал кто то это значит что дальше если время будет развиваться то он возможно при других условиях сделает друг другие вещи там не совсем марковские цепи там немножко другой подход но в целом да люди с этим экспериментирует есть вообще глобально три наверное вида вот таких вот рекомендательных систем одни из них контент bass то есть вы делаете рекомендации ясно на основе контента этих атомов и смотрите например схожесть поэтому который пользователь смотрел есть кола братишка чистая как это как показано на экране ну можно сделать вот правда по-разному а есть гибридные вот авторизационные машины это гибридные они не принимают во внимание и контент и контек контента и томов и контекст и какие-то свойства пользователя в них можно засунуть и собственно вот можно искать схожесть по пользователям не конечно есть свои недостатки но это уже за рамками еще вопросы если просто больше не давайте поговорим дима за отличный доклад"
}