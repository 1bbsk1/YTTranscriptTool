{
  "video_id": "bFj063mBAkg",
  "channel": "HighLoadChannel",
  "title": "Масштабирование системы хранения секретов на базе HashiCorp Vault / Виктор Корейша (Ozon)",
  "views": 518,
  "duration": 2912,
  "published": "2025-01-17T02:23:01-08:00",
  "text": "Всем привет Меня зовут Виктор корейша И сегодня я хочу поговорить о масштабировании системы хранения секретов ну для начала пару слов обо мне а я работаю в Озоне возглавляю направление мед Services Это значит что я и мои коллеги отвечаем за такие инфраструктурные штуки Как как шина данных на базе Кафки как S3 на базе Цефа А ещё кши такие creeds mim cash Ну и в том числе Vol hcd тоже в нашей зоне ответственности ну А в свободное время я люблю участвовать в разных конференциях и даже являюсь членом программного комитета некоторых из них А ещё веду два подкаста один из которых называется кода кода а второй три тимлида заходят в бар если вам сегодня понравится моё выступление будет клёво если кто-нибудь из вас ещё и на мои Подкасты тоже подпишется Ну давайте Ближе к делу о чём мы сегодня поговорим а я хочу рассказать вам о секретах о том что это такое И сколько их у нас разных есть а ну секреты Мы храним в стандартном для отрасли а инструменте это hore Volt а соответственно Volt это штука которая требует какого-то бэнда и про Stage Бэн мы сегодня тоже поговорим Ну и раз мы говорим о масштабировании Значит у нас должна откуда-то взяться нагрузка под которую мы будем масштабироваться чтобы не заниматься каким-то Овер инжинирингом вот мы поговорим о том что это за нагрузка и что мы делаем для того чтобы эту нагрузку выдерживать Давайте начнём про секреты У любой компании есть секреты и эти секреты нужно где-то хранить Ну мы конечно говорим о креда базам данных разных паролях сертификатах и так далее в азоне около 6.000 микросервисов каждый из которых является агентом у которого есть некоторые свои секреты каждый микросервис работает с ними отдельно е есть какое-то огромное количество сертификатов которые необходимо не только хранить но и периодически генерировать и обновлять и разные airflow крон джобы и даже секреты самого волта тоже нужно хранить где-нибудь они у нас хранятся в другом волте А если говорить о наших масштабах то у нас примерно 250.000 секретов в активном использовании и ещё примерно 200.000 токенов О токенах мы сегодня ещё поговорим это очень важное понять в рамках мира лта вся наша система в стабильном в нормальном в обычном состоянии выдерживает постоянно фоново порядка 2000 РПС но в пиках бывает существенно больше о чём сегодня тоже пойдёт речь - это не хранилище само по себе это некоторая система которая отвечает за шифрование и каширование секретов за доставку секретов потом клиентам соответственно вту необходим некоторые хранилище где собственно данные ном виде будут лежать то есть Клиенты ходят в Volt А сам Volt ходит в это самое хранилище данно забирает потом их расшифровывает и клиентам предоставляет уже ПО Access токену а storage backend Volt поддерживает очень большое количество разных Ну то есть в целом любое хранилище которое умеет в k value может стать таким Stage бэндо Вы можете сами написать некоторый плагин и Volt сможет его поддержать но на сайте шико Мы можем посмотреть что Volt считает что все бэнды для него делятся на две категории это High availability то есть такие бэнды которые не вызывают тайма при падение одной из нот а также при падении одной из нот лта Ну например такие штуки как кол Z Keeper или etcd есть и другие бэнды которые поддерживает Vol Ну например это cantra mong или pog а они могут вызвать некоторый downtime вот поэтому они считаются не High availability Ну надо сказать что у лта есть ещё один специфичный кнд он называется integrated storage и его смысл в том что Vol хранит данные в собственной файловой системе Ну то есть фактически хранит рядом с собой а при этом он сам реализует алгоритм консенсуса а соответственно raft и в документации они так и называют его R backend А если мы зайдём на сайт ши корпа мы увидим что он рекомендует два бэнда Если вы готовы хранить данные там же где Vol то рекомендуется integrated storage если вам хочется хранить их отдельно то рекомендуется Консул Ну вероятно потому что они сами его и пишут в том числе и для волта нам не очень подходила Эта история изначально потому что у нас есть достаточно большая экспертиза в эксплуатации atd поэтому мы именно эту базу выбрали как основу для хранения секретов и от неё отталкивались изначально но нам необходимо конечно убедиться что наше решение оно как минимум не хуже чем то решение которое предоставляет по умолчанию он сам рекомендует поэтому Давайте сравним etcd с рам эндом с inte Stage для того чтобы сравнить нам необходим некоторый бенчмарк да то На чём мы будем понимать как эта история работает а есть очень важный параметр этого бенчмарка это количество соединений которые у нас являются щими се Да и количество соединений которые разовые которые рвутся сразу после получения первого ответа экспериментальным путём мы выяснили что наши клиенты в общей своей генеральной совокупности ведут себя примерно соответственно нагрузки в 65% соединений которые закрываются сразу и соответственно 35% соединений которые э ну на некоторую длительность выставляются поэтому Давайте смотреть именно на эти строчки а в этих строчках мы можем увидеть что на нашем паттерне нагрузки мы выбрали вполне конкретную конфигурацию волта А если не ошибаюсь кажется там было во ядер и 16 ГБ оперативки чего вполне достаточно и в целом это рекомендованный размер а можно увидеть что на маленьких квантиль например на пятидесятой время ответа integrated storage ожидаемо меньше Ну поскольку лту не нужно ходить куда-то отдельно Он вытаскивает данные те которые у него уже есть соответственно он отвечает достаточно быстро но на больших квантиль например на девяносто восьмой Мы видим что integrated Stage отвечает значительно хуже А в картинках Это можно увидеть примерно так то есть видно что при подаче большой нагрузки в целом генерально и версия с etcd и версия с рафтове себя примерно одинаково но периодически вот этот внутренний их алгоритм консенсуса начинает очень долго выбирать себе нового лидера для того чтобы договориться о какой-то записи и мы видим такое точечное проседание во время этого проседания естественно ун у нас подрастает во всех квантили а это не укладывается в наш SL Потому что при этом у нас уже начинается деградация мы не можем отдавать секреты так быстро как хотели бы получать наши сервисы соответственно такой вариант К сожалению нам не подходит а Итого чистый integrated storage нам не подходит нужно сказать что я здесь пишу слово чистый потому что в целом Volt поддерживает вариант когда часть данных хранятся в одном бэнде часть данных хранятся в другом бэнде в рамках этого доклада я этот вариант не рассматриваю Вот но в целом такие опции такие варианты Мы тоже пробовали делать Ну и того мы остались на и используем его в качестве основного бэнда Итак Мы закончили с общим введением поговорили о том сколько всего секретов бывает в ЛТЕ у нас и какой Stage Back мы используем Вот на этом этапе Я буду рассказывать Все остальные истории для того чтобы поговорить О всём остальном для того чтобы приступить к теме масштабирования хочется поговорить о том откуда вообще у нас Бер нагрузка что это за нагрузка стоит поговорить про операции которые происходят с лто А все операции хочется разделить на те которые происходят достаточно редко и относительно часто Ну потому что редкие операции естественно имеют меньшее влияние на общую нагрузку в моменте Ну и также я условно поделил их на простые операции и тяжёлые понятно что простые и тяжёлые они могут быть немножко в разном контексте Да там в контексте использования CPU или в контексте обращения к кду Вот Но я объеди эти факторы вместе для того чтобы у нас с вами было попроще вот этот квадрант из частых операций и тех которые являются относительно простыми это Например стандартные операции с ти это Например чтение секретов или продление аренд про Лизы и аренды мы с вами сегодня ещё поговорим а есть И относительно простые операции которые происходят реже Это например там добавление ролей или изменение политик Ну то есть действие с тем кто Какие доступы будет иметь а операция которая очевидно происходит значительно реже чем чтение это запись секретов она понятным причинам является более тяжёлой Да потому что оно требует вызова бэнда требует некоторой синхронизации есть ещё более тяжёлые операции которые происходят ещё реже например Это операция асил То есть распечатывание волта она происходит каждый раз когда волт находит Кэн заново либо у бэнда меняется Лидер это момент когда волт вычитывает все данные из бэнда расшифровывает их и готов их отдавать из собственного крыша Ну и совсем редкие операции такие как смена ключей они происходят тоже с определённой регулярностью это когда мы для того чтобы избежать возможности компрометировать вычитывает обратно в волт перешиваем их новыми ключиками и кладём их обратно в энд понятно что эта операция тоже супер тяжёлая но когда мы говорим про нагрузку нас с вами конечно же интересует вот этот верхний правый квадрант это операции которые происходят часто и являются относительно тяжёлыми Удивительно но для волта это операция связанны с созданием токенов здесь стоит вообще поговорить о том что такое токены дело в том что Vol - это AP First система и абсолютно всё что вы делаете с ЛМ читаете ли вы секреты изменяете ли вы политики и Ну все операции которые перечислены здесь это некоторые вызов метода в каждый метод мы аутентификатора получать в ЛТЕ существу два разных формата токена первый называется сервисный токен фактически сервисный токен является ключом к некоторой сессии которая хранится внутри лта То есть все данные записываются вэн А мы отдаём только Ну айдини этих данных Да которые уже шифруются и находятся в самом токене такие токены могут иметь абсолютно люй уровень доступа в томс мотке поют выполнять все админские операции и очень важно что такие токены могут быть отозваны если мы вдруг решаем что токен скомпрометирован почему они могут быть отозваны Ну потому что сами данные токена мы храним внутри лта соответственно если мы по какой-то причине считаем что один там или какая-то группа токенов скомпрометирована Мы внутри волта можем удалить их записи или изменить соответственно ТЛ на их Лизе и считать что больше этот токен недействителен независимо от того что с этим токеном всё ещ может прийти клиент другой формат называется Ба токены и фактически это целиком зашифрованные права в виде блоп объекта который отдаётся клиенту соответственно батч токены они больше по размеру и размер их зависит от количества прав которые есть у конкретного клиента и у них заранее заданы и фиксированы ТТ ну это может быть и 5 минут там и 5 часов в зависимости от того как вы это настроите но важно что этот ТТ вы не можете поменять со своей стороны вы выдали бакен и каждый раз когда с ним придёт клиент вы этого клиента Пустите у вас больше нет никакого способа этого клиента ограничить а именно из-за этой особенности бакенов Несмотря на то что они не создают дополнительные нагрузки в качестве записи в storage backend мы используем сервисные токены и Ну наверняка кто-то из вас уже догадался что как раз создание сервисных токенов - это относительно тяжёлая операция Но кроме того что она тяжёлая у неё есть ещё несколько важных особенностей во-первых У нас очень много клиентов я говорил об этом с самого начала а есть подход когда клиенты агрегирующие поэтому такую штуку не используем То есть каждый сервис является нашим клиентом С одной стороны это хорошо с точки зрения безопасности с другой стороны это лишает нас возможности хорошо контролить Этих клиентов А многие из этих клиентов мы живём в микросервисной парадигме соответственно Они исповедуют полностью й парадигму Ну Особенно это важно когда мы говорим например про крон джобы или которые каждый раз запуская полностью забывают О всём что у них есть и заново авторизуется получают какой-то токен а мы никак не можем ограничить клиента в факте получения токена и это важная дизайн особенность Валта потому что в целом никто не мешает клиенту получить например два разных токена с разным уровнем прав и использовать их внутри себя каким-то образом по-разному соответственно сюда мы тоже лезть не можем для того чтобы никак не нарушить историю с EB А ну и важно что если клиенты начинают получать токены достаточно часто чаще чем мы эти токены инвалиди внутри себя эти токены засоряют базу Ну то есть база пухнет неограничено потому что мы например инвалиди там их Раз в 5 минут а клиент получает токены Ну например 1.000 раз в секунду а Это значит что нам необходимо каким-то образом ограничивать таких клиентов возможно кому-то покажется что это надумано история но она абсолютно реалистично я подобрал здесь а график одной конкретной ситуации от одного конкретного клиента когда сам клиент сошёл с ума и начал запрашивать токены внутри себя в бесконечном цикле соответственно один клиент - Это всего лишь один пот который начал бомбить во со скоростью 1.000 rps и количество ключей в волте резко выросло вот тут Не очень видно циферка Но примерно с полу мил там почти что до 2 млн дорос если бы мы этого клиента там неожиданно не остановили то в целом Этот рост мог бы быть неограниченным это очевидно очень опасная ситуация Да потому что ну мы должны каким-то образом ограничивать клиентов для того чтобы вот эту общую общий ресурс общий волт предоставлять всем кто в нём нуждается в чём проблема которая у нас есть ну для начала у нас есть вот проблема прямо здесь и сейчас конкретный клиент который сходит с ума может создать для нас очень высокую нагрузку А что с этим делать самое простое решение которое есть которое Ну можно считать некоторым костылём но спасает нас здесь и сейчас это мы можем подложить Рей лимитер и сказать Ну хорошо но от одного клиента мы не принимаем больше чем там X запросов в секунду а в ЛТЕ есть встроенный Rate лимит который можно использовать но у него есть некоторые особенности во-первых он работает только perp на конкретный Mount Point Mount Point - это грубо говоря Ну блок сохранения секретов Ну или если хотите некоторая Входная точка которых может быть несколько и у них могут быть разные внутри движки а точность которая обладает этот й лимитер не может быть выше секунды соответственно если наш клиент ну совсем плохо себя ведёт то в целом в рамках одной секунды он может успеть сделать нам нехорошо А ещё одна важная особенность Рей лимите внутри волта что он будет потреблять ресурсы самого волта То есть если сходить с ума будет большое количество клиентов одновременно то мы всё равно будем тратить Некоторое количество на ресурсов процессорного времени на нода хвата для того чтобы ну Этих клиентов отсеять каким-то образом их отпустить и главная проблема в том что у нас нет возможности гибкой настройки Ну то есть я уже сказал что это настраивается целиком только на M Point и например не может быть настроено отдельно для количества запросов на авторизацию отдельно на количество запросов на получение секретов а некоторым клиентам необходимо получать секреты достаточно часто но при этом нет никакого смысла так часто генерировать токены есть второе решение мы могли бы использовать некоторые внешние прокси Ну проще всего это использовать то что уже есть в компании У нас есть довольно большая экспертиза по использованию джинса как я думаю и у большинства коллег в зале соответственно мы могли бы поставить некоторые внешни лимите главное его преимущество в том что нам никто не мешает начать использовать его на тех же например тачках Где находится во и в будущем вынести его на некоторое внешне если мы захотим справляться там с большим объёмом вот этого для на трафика Ну и очень большое преимущество заключается в том что максимально гибко настраивается И если мы ставим его перед ЛМ мы получаем ещё некоторые преимущества Ну например мы можем бесшовной один MP в другой просто методами rite потому что как я уже сказал любой запрос - это просто Запрос к некоторому AP методу мы выбрали второй подход соответственно Перед каждым перед каждой Ной волта поставили ИНН Ну и здесь упрощенный формат как примерно могут выглядеть некоторые правила то есть мы можем для каждого пути А значит для каждого действия задать своё правило относительно пса по которому мы будем его блокировать и ста там в первую секунду Но это конечно не главная проблема Да это вот такое решение заткнуть дырочку в моменте главная это проблема в том что если клиент начнёт таким образом бомбить нас он ну займёт всю нашу базу то есть наша база будет расти неограничено и прежде чем поговорить об этом стоит сделать небольшое отступление и сказать Пару слов про такую сущность внутри лта как Лизы или контракты на аренду Что такое Лизы значит это некоторая запись внутри Stage бэнда которая содержит в себе ТТ и возможность продления для любой другой сущности Валта в том числе и для токенов как только аренда истекает если она не была продлена то соответственно вот эта сущность она будет удалена как только клиент придёт с ней в следующий раз важная особенность Лизы что каждая Лиза - это запи Ну а е если потребители пользуются этим механизмом и они могут продлевать токены если Лиза позволяет это сделать Ну и небольшой пометка что в целом У нас есть возможность хранить Лизы не в том же самом энде в котором хранятся основные данные А например в энде это то о чём я говорил чуть раньше но у нас хранится в том же самом Итак в ЧМ же проблема Ну роли он очевидно коррелирует с общим количеством ключиков очень хорошо потому что на самом деле Ну очень большое число ключиков внутри TD это и есть те самые Лизы которые постоянно создаются фактически Вот то самое замусорено базы мы замусорено А Лиза на эти токены Ну вот тут хорошо видно что если взять за некоторый большой период то при росте Лиз также примерно растут и сами эти CD ключики Кстати вы можете заметить что здесь есть ещё такая ребёночка небольшие всплески это дневные всплески связанные с тем что часть ж запускаются по расписанию соответственно они на создавали себе какое-то количество токенов потом эти токены потихонечку истекают мне хочется поделиться с вами одной офигительно историей во время одного обычного сервисного обслуживания когда мы поняли что в нашем тцд набралось слишком много лис нам захотелось Ну чуть-чуть почистить базу А для этого уменьшить время жизни части токенов делается это в три шага Это довольно обычна процедура для начала нужно найти те токены которые на наш взгляд живут слишком долго и отозвать Лизы для них После этого мы получили порядка 400.000 аренд которые были помечены как просроченные и вот тут стоит отметить что Лизы не удаляются сразу а просто переходят из одних ключей Ну фактически из одной директории стод бэнда в другую и соответственно будут удалены при первом обращении когда мы заметим что их ТТ истёк вот эти 400 сыграли нам злую шутку о которой я расскажу чуть позже А третьим шагом Мы хотим почистить базу etcd Дело в том что сам etcd устроен Так что когда мы удаляем какие-то ключики размер его базы не уменьшается потому что он пишет только в конец App Only для того чтобы размер базы уменьшить Нам необходимо вызвать специальную процедуру фраг которая соответственно Ну все лишние все ключики не использованные уберёт и запишет всё по порядку и мы увидим нашу стеньку базу в которой куча мест мы запускаем фраг что в свою очередь вызывает смену лидера etcd и наш волт не распечатывается А надо сказать что после того как меняется лидеру бэнда во должен заново перечитать все секреты которые у него есть договориться э ну в о том что это тот самый кнд которому мы имеем доступ расшифровать все эти секретики и дальше уже отдавать их клиенту это обычная операция которая называется unal или распечатывания волта Ну а не распечатанный волт - это значит неработающий волт который просто не отдаёт никаких данных наружу что делать Ну естественно когда у нас есть какая-то проблема Давайте будем смотреть влоги в влогах волта мы можем увидеть примерно такое сообщение в котором написано о том что тот Запрос который Volt делает в сторону etcd слишком большого размера и он просто не может быть тоже можете обратить внимание оно довольно любопытно А если посмотреть в логе самого etcd мы видим на тот же самый запрос что etcd говорит о том что слишком долго выполняется запрос А что это значит Ну это значит что во время распечатывания Volt приходит к etcd и говорит Дай мне что-то это что-то очень долго формируется Но после того как оно всё-таки сформировалось оно не пролезает через jpc Казалось бы почему так происходит если залезть в код самого волта мы можем увидеть там кусочек в котором он запрашивает Лизы при распечатывании э происходит операция которая внутри кода называется collect leis А смысл в том что мы должны получить список тех самых Лиз по которым должны дальше пробежаться для того чтобы проверить каждую на то не истекла ли она А для разных кэндо э метод collect leis он выполняется по-разному Ну потому что соответственно вот поддерживает большое количество разных вариантов с которыми ему необходимо работать конкретно для истории с etcd во вызывает под капотом вот такую историю он говорит как бы etcd ktl Get и дальше некоторый префикс и этот префикс содержит все Лизы внутри себя а Возможно если Вы много работали с tcd то сразу догадываетесь В чём здесь проблема Дело в том что по умолчанию когда мы говорим Get мы получаем не только ключики но и значения этих ключей то есть всё что внутри этой Лизы хранится Что делать то есть мы делаем слишком большо запрос получаем все Лизы которые есть вот эти самые 400.000 которые нам нужно по тлю удалить а они соответственно не удаляются Какие есть варианты как решить эту проблему Ну самый простой вариант Давайте просто подвиг ползунок значения Ну не пролезает нам в какое-то значение давайте это значение задер Вверх а к сожалению в нашем случае так не работало по одной простой причине Дело в том что это значение устанавливается как переменная типа int и оно просто не может быть больше того значения в которое уже установлено а О'кей есть хорошее долгосрочное решение которое заключается в том что давайте научим волт не вытаскивать все Лизы одновременно а делать некоторую пагинацию вытаскивать их по кусочкам естественно в итоге мы так и сделали Но это довольно длинная история которая требует э ну следить за этой самой пагинации Да затем Как нам не пропустить никакую Лизу Ну и есть решение которое сразу приходит в голову а почему бы нам не забрать только ключи Дело в том что для большинства кэндо на самом деле волт забирает только список лис а потом всё равно идёт по ним циклом вычитывать каждую Лизу заново и понимая Ну Необходимо ли её просрочить или можно пустить токен с этой Лизой дальше А в нашем случае мы получали абсолютно все значения А но в hcd начиная с третьей версии протокола есть такой параметр как Case Only который по умолчанию выставлен false который позволяет получить только ключики здесь стоит сказать что во второй версии протокола такой истории не было и коллеги из hcp вероятно просто продолжая историю с работа с atd со второй версией протокола на третий Ну не использовали ту возможность которую нам дал новый atd Ну и вот так вот выглядит наш контрибьютор Т собственно Это всего лишь одна строчка которая добавляет тот самый параметр Case Only по большому счёту к самому запросу и позволяет нам Вычитать не 2 млн батиков А всего лишь 200.000 2 млр ну забегая вперёд скажу что конечно же видел наш КСТ Они сказали что они сами всё знают и скопировали его и полностью добавили в Стрим точно так же как мы это сделали для них Ну а если вы переживаете за нашу ситуацию то конечно же в этой истории мы просто почистили tcd вручную и видно вот там резкий скачок вниз когда мы собственно смогли продолжить действовать Ну а чуть позже всё-таки навели порядок во времени жизни токенов и вот эти вот ежедневные всплески и постепенные накопления у нас прекратилось что ж до сих пор Мы говорили о некоторых нагрузках о некоторых проблемах но я так ничего и не сказал о масштабировании а чтобы говорить о масштабировании нужно понять А во что же мы упирается Ну вот при большом количестве запросов И здесь нужно вспомнить тот Запрос который является самым частым А это конечно же ну не создание не продление токенов А это чтение секретов то что происходит в общем-то на регулярной основе обычно у нас чтение секретов выглядит примерно так то есть ну приме с 2000 rps в сумме все наши сервисы вместе ходят в Volt это не очень много Почему Потому что ну обычно приложению не нужно вычитывать секреты постоянно большинство это делает только один раз при старте ну или там достаточно редко А можно заметить что большая часть секретов Т отдаёт прямо из кэша вот то что здесь зелёненькое - это то что уже хранится в кэше волте и то что мы отдаём сразу Ну естественно Некоторое количество секретов оно идёт на запись в Кэн Ну либо не попадает в кэш Да и проваливается вниз бэнда Но бывают ситуации в которых сразу большое количество сервисов стартует например такая ситуация происходит при отключение одного из дата-центров Когда в других дата-центра поднимаются те самые поды и им необходимо Вычитать секреты для того чтобы стартовать и начать там работать с собственными базами данных и так далее А это скриншот с одного из таких учений видно что в общем-то э количество rps может подпрыгнуть в принципе до любого значения Нам повезло что у нас подпрыгнула до 7.000 что в целом наш волт более-менее справился но только благодаря тому самому Рей лимиту Вы можете заметить что здесь есть три таких чётких Пика эти пики вызваны тем что лимит ответил соответственно приди попозже и приложение просто перезалог это довольно опасная ситуация потому что количество сервисов количество подов растёт и мы должны каким-то образом тоже научиться это контролировать и под них масштабироваться в целом 7.000 - это уже верхний порог если помните из начала измерений мы до 7.000 не добивали там наша н начинает уже очень сильно расти и здесь стоит сказать о том что может быть кому-то из вас покажется что там 2.000 rps даже 7.000 rps нуно это какая-то фигня в целом один какой-нибудь подик легко с этим справится и могу с вами частично согласиться но дело в том что в случае лта именно что один пот обрабатывает абсолютно все запросы неважно куда приходят клиенты и неважно какие это клиенты это могут быть поды из кубернетес это могут быть джобы это могут быть просто люди которые в веб-интерфейс что-то набирают они приходят в кластер лта но в любом случае все запросы просится только в Мастер ноду то есть Т работает с одной мастерноды здесь стоит сказать что я говорю конечно о коммьюнити версии волта и в целом Ну весь мой рассказ посвящён именно коммьюнити версии Но поскольку у нас по большому счёту Нет с вами возможности работать с какой-то другой то будем продолжать обсуждать именно её Ну собственно это вот мастернода она уже ходит в storage backend Вы помните что наш Stage backend - это etcd и ма Noa она конечно же держит соединение до всех etcd но при том что соединение о на держит до всех это же High ability да то есть если даже у нас одна нода е CD выпадет то мы всё равно продолжим обслуживать клиентов без паузы и Для этого нам нужно соединение постоянно для того чтобы не тратилова и на одну ноду ец а конечно же словы тоже держат все соединения ко всем нодом etcd зачем Затем чтобы если у нас мастернод волта выпадет да то соответственно сло егова нода сразу же имеет доступ к hcd и не нужно опять же устанавливать соединение но все данные они только через жирную стрелочку всё остальное только там Херби А что это значит Это значит что у нас есть некоторая ситуация в которой У нас меняется Лидер и при смене лидера мы можем увидеть примерно такую картинку Казалось бы картинка довольно красивая вот довольно быстро снова вычитывает всё в кэш и снова начинает с помощью кэша всё обслуживать А если присмотреться к таймлайна то видно что примерно за минуту мы всё что есть в ЦД вычитывает расшифровывает снова хорошо обслуживать клиентов Ну Казалось бы это не так много и не так часто тот самый Лидер меняется Ну и до этой минуты Мы в целом Тоже замечательно отвечаем А что в это время происходит с нашим эндом естественно происходит тоже всплеск который мы очень чётко можем отследить на графиках то есть в этот момент наша с нода которая стала мастером в случае волта либо мастернода который вычитала из другой CD ноды она полностью вычитывает всё что есть и делает большой всплеск на энд Итак резюмируем в чём проблема с одной мастерноды волта во-первых вся нагрузка идёт только на один пот и значит всё масштабирование которое нам доступно оно только вертикальное это проблема по по понятной причине Да вертикальное масштабирование оно рано или поздно упрётся в некоторые ограничени при смене лидера У нас есть большой всплеск запросов причём и на ВО и на ноду бэнда А ещё у нас нет никакой возможности локализации трафика то есть поскольку всё идёт только через мастер ноду независимо от того в каком дата-центре мы находимся весь трафик все секреты Они обязательно проходят через ту ноду которая сейчас является лидером сейчас является активной мы очень хотели уйти от этой ситуации и сделать так чтобы клиенты которые генерируют нагрузку на одну ноду волта распределились как-то по разным ном Это значит что мы хотим сделать мультимастер кого-то из присутствующих может напугать Эта история потому что вы знаете что мультимастер в какой-нибудь базе данных - это очень сложная штука которая требует сложных консенсуса который иногда долго сходится Ну в общем у неё много проблем но Volt напоминаю это не база данных это система которая занимается шифрованием и кэширования с шифрованием никаких проблем нет проблема есть с кэширования которую я и хочу с вами обсудить В лта есть несколько уровней кэша внутри мы Ната и или штук Смотря как считать но в целом можно поделить их на три больших группы основная часть секретов хранится в быстром эру кэше этот кэш фиксированного размера Но если вы правильно его настроили то скорее всего все актуальные секреты будут у вас лежать именно в этом кэше из него они отдаются быстрее всего и быстрее всего обслуживают запрос на чтение ключей а также внутри есть in Memory база данных которая называется гоб это тоже разработка шикор которая в том числе внутри волта в ней находятся те ключи которые не попали в ру кэш а также все другие identity такие как политики или роли А ну и есть Кэн если соответственно наш ключик не находится в кэше то дальше он проваливается в мдб если его нет там то дальше мы проваливается до бэнда и оттуда забираем ключик кстати интересная особенность заключается в том что другие НТИ мы не забираем из бэнда и если их не оказалось в мдб то мы считаем что этой роли не существует главный вопрос который нам предстоит решить - это как инвалиди кэш Казалось бы абсолютно простой и одновременно абсолютно сложный вопрос потому что это штука которая встаёт абсолютно везде у нас есть возможность инвалиди кэш по каждому запросу в этом случае у нас есть большая вероятность некоторой ошибки но дело в том что запросы могут быть очень разнообразны у него довольно широкие возможности А и В целом мы должны контролировать что каждый запрос который прит об инвалиди каждый уровень кэша в каждой слой в ноде это основная проблема а но при этом мы получаем меньше суммарную нагрузку потому что мы можем её распределить по времени а а главное мы можем гарантировать консистентность за то время за которое у нас происходит синхронизация того самого а ключа который сейчас изменился есть другой подход в которым пошли некоторые другие компании которые шли примерно тем же путём что и мы например ребята из Одноклассников выступали с подобным докладом это инвалиди кэш раз там в н секунд Ну например раз в 5 минут целиком чистить какую-то ноду А главное преимущество что это совершенно точно работает потому что внутри бэнда у нас точно всегда есть хорошая консистентность и значит если мы Чистим ноду Раз в 5 минут А ну например производим там асил то есть она полностью выгребать всё что есть из БК энда и она точно будет вот Раз в 5 минут консистентной никаких проблем с вводом и выводом НОД если в первом случае мы должны следить Какие ноды находятся в кластере и как-то реагировать на тот факт что нода допустим вывелось чтобы не делать бесконечных трав здесь у нас никакой проблемы нет ввод и вывод ноды - это та же самая операция unal которая полностью вычитывает все секреты но главная проблема в том что мы получаем регулярную по нодов деградацию того самого кэша то есть та нода которая сейчас дёргается которая он сили она прямо в этот момент ну получим Ту же самую деградацию которую мы получаем при смене лидера Ну то есть не получим тот выигрыш который мы вообще-то хотели получить Ну или не целиком его получим поэтому мы выбрали первый вариант при любом пишу запросе в любую ноду ЛТЕ у нас происходит точечный сброс кэша который ходит в каждую другую ноду для этого мы форкнуть там вот эти ручки которые позволяют сбрасывать кэш точечно А что получили Мы в своей конфигурации здесь надо сказать что в первой строчке Я сравниваю вол целиком поскольку работает у него по большому счёту мастернода но запросы они могут распределяться и на сй ноды тоже А ну и сравниваем мы его с тремя мультимастер нодами они чуть-чуть по-разному у себя ведут потому что ну какая-то вошла чуть раньше какая-то чуть позже как-то чуть-чуть по-разному распределился трафик и это в целом нормально но вот при нашей конфигурации с тремя нодами мы получаем честный выигрыш почти что в три раза конечно чуть ниже из-за того что нам приходится тратить ресурсы на синхронизацию но почти в три раза выигрываешь мы получаем Казалось бы мы получили бесконечное масштабирование Ну конечно оно условно бесконечное Почему Потому что если мы увеличиваем количество нот дальше то у нас раст вот количество Тех самых связей Да каждая должна сходить в каждую и происходит некоторая деградация А в нашем конкретном примере мы провели а измерение и поняли что мы достигаем максимума при девяти нода и при этом получаем примерно семикратный увеличение того пса который мы держим с необходимым нам с Ну надо сказать что вот эти все Циферки там девять штук семь штук - это не волшебное число понятно что там под ваш профиль нагрузки под ваш конкретные вот эти Тачки они каким-то образом могут меня но понятно что они опять же во что-то упр Итак выводы во-первых мы получили продакшн систему которая готова к нагрузкам примерно в 30.000 ПС что существенно больше чем мы получаем даже в самых больших пиках и у нас есть некоторый запас на вырост мы выяснили что в целом тот энд который мы выбрали изначально он хорош и мы умеем залезать внутрений вой даже если найдём в нём какие-то проблемы Но ещё важный вывод который я сделал лично для себя и хочу поделиться с вами что кажется абсолютно любая прок система может оказаться Не такой уж прок Когда ваша нагрузка вырастет за определённый порог Или ваши паттерны использования станут не такими как рассчитывали изначально Но на этом всё будет очень клёво если кто-нибудь из вас оценит мой доклад Вот по этому дику я очень мечтаю получить честные очки и чем их будет больше тем Конечно мне будет веселее школь А внизу под этим есть ссылочка на вот эту самую презентацию если вам очень захотелось получить её прямо сейчас то вы можете сделать это со своего телефона на этом всё С вами был Виктор корейша я готов поотрываю - это наша традиционная супрематическая матрёшка возможность вам лично сделать вклад в конференцию и получить артефакт физический артефакт за участие и второе от озона начинаем от озона машинка гораздо круче чем Матрешка Я считаю Привет Спасибо за историю первый вопрос про мультимастер вот этот вот форк который вы сделали если он где-то в паблике или он делается там на коленке за 15 минут а второй вопрос а чем вы забираете секреты из вота и из кубов Спасибо нет Э По одной понятной причине лицензия лта говорит нам о том что нам нельзя повторять Enterprise версию вот а там есть соответственно фича мультимастер а второй вопрос Чем мы ходим из Куба чем забираете а нука я понял Это довольно сложный длинный вопрос Обсудим в кула каже кажется лучше в кулары перенести Давайте следующий вопрос из зала да скажи пожалуйста а вот клиенты собственно они Как используют эти токены потому что они получается ходят потом в бэнды вычитывает данные из этих кэндо потом приходят в ты и как бы с помощью Валта расшифровывают этим токеном мы просто очень много в начале говорили про эти токены но как будто не обсудили зачем они нужны смотри каждый запрос Vol идёт с токеном то есть Сначала ты обязательно получаешь этот токен Там есть разные способы как его получить есть Али есть возможность коче это говорили про токены которые нужны чтобы сходить в Вот и дадада это способ соответственно аутентификации Спасибо большое так следующий вопрос с правой части зала Да спасибо за доклад такой вопрос лицензия волта запрещает повторять Enterprise версию но лицензия нет повторять не запрещает запрещает выкладывать публично выкладывать Да но лицензия форком вроде бы не запрещает соответственно собираетесь ли вы ехать в какой-то форк и не хотите ли вы занести ваш функционал туда Ну это интересный вопрос пока у нас такого конкретного плана нет в целом вот штука которую мы сделали Она кажется не супер сложная вот на основе того что я сейчас рассказал то есть там какой-то S внутри нет всё на что надо было решиться это понять что мы хотим сделать и как Ну пока что у нас плана опубликовать нет Виктор у тебя два вопроса Нужно запомнить поэтому ставь пожалуйста пометки И следующий вопрос прило Ино познавате самом отдельно получает свой токен или целиком Допустим или с одним и тем же токеном ходит нет обязательно каждый под получает собственный токен потому что надо понимать что поды могут подниматься в пло в разное время Ну у нас какой-то пот Умер да поднялся снова ему снова нужно Вычитать секреты он заново получит себе новый токен Спасибо за ваш доклад У меня вопрос качест же э есть в постгрес Почему не постс потому что не ну то есть любая история с тем что у нас выходит из строя Лидер лта либо выходит из строя соответственно мастернода поса приводит к некоторому простою Ну за время пока у нас не остановится новый конект не произойдёт заново Ну имеется в виду то что в онлайне это делает А постгрес нуж какие-то перевыборы время да пере Ну вот Время сах переборов оно скорее всего нече болье катастрофическом сценарии Когда у нас там все посы выходят из строя могут быть проблемы Вот Но большую часть времени мы потратим на вот эту операцию полного асила то есть мы заново установим соединение с новой мастернод заново всё вычитаем заново всё Расшифруй мы не будем обслуживать клиентские запросы Следующий вопрос из дальней части зала справа спикер вопрошающий спрятался от тебя за телевизора обойду Спасибо за доклад Подскажите нач мультима инци то есть когда вы выбрали точный запрос получается с остальных нот вы это делаете синхронно или асинхронно И второй вопрос Если асинхронно то как вы вернее Если да асинхронно то как достигается консистентность и плюс что тогда с пользовательским пишущим запросом очень клёвый вопрос Мы тоже долго про это думали и Сначала мы сделали синхронный сброс номы прик ситуации кода если у нас вывела из строя какая-то НОД волта и соответственно мы получаем бесконечный луп и тот же самый отказ в обслуживании Поэтому мы вынуждены были сделать сброс этого крыша синхронным он там трается Некоторое количество раз которое у нас внутри настраивается и если оно не смогло отравиться то оно поднимает флажок о том что волт какой-то находится в некон систентки и может отработать история с полным он силом какой-то ноды если у нас одна нода не консистентная соответственно инженеру по эксп руками это разрулить детали Обсудим в ларах следующий вопрос из центра зала Да спасибо большое за доклад А вот есть ещё такой вопросик вы тестировали на мультимастер как будет себя чувствовать мавок Ну то есть отзыв допустим 500 тысяч токенов просток - это как раз Ну по сути две операции самый главное это отзыв то есть обнуление Ну это получается нужно отозвать очистить кэш и заново записать и тоже сбросить кэш да то есть это вот Каскадный двойной сброс он как вообще аффект систему естественно мы этот сценарий проверяли потому что была та история которую я рассказывал чуть раньше когда мы в общем-то попали на массовый отзыв токенов на некоторую неприятную ситуацию да Мы проверяли Ну для того чтобы это хорошо сработало Там просто настроены некоторые тайминги что это происходит там по Ну каскадно но не одновременно мы не получаем каскадного сбоя Вот Но для того чтобы это случилось нужно было отдельно поприседай чего я Ну в этом докладе не рассказал но да это клёво е можно будет обсудить В ларах следующий вопрос снова центр зала Добрый день вопрос используете ли вы автосил Если да то как вы договорились с шника или может быть вы как-то делаете Это транзитивное волт А всё верно У нас есть отдельный Транзит который может произвести асил основного волта вот при этом п такой что транзитный волт находится на тех же самых нода что и основной и держит данные вот в том самом integral сторедж А идея Какая что если нода будет физически скомпрометирована Ну то есть мы взяли сервак вытащили его из стойки то засилва ключика ставят повернут Ну два или три там уже в зависимости от настройки транзита А вот Но если это сбой который вызван там тем что у нас поменялся Лидер допустим etcd то основной волт расси транзитом внимание вопрос из чата что планируешь делать когда производительности девяти нот не хватит а это хороший вопрос кажется что сейчас у нас есть очень мощный запас прям ну сильно на будущее и даже на большие всплески более того этот запас ещё и больше там чем те самые 30.000 потому что у нас есть лимит который его каким-то образом размажет но понятно что это решение в какой-то момент всё-таки во что-то упрётся и да не может Ну дальше мы будем наверно масштабировать тем что создавать разные лты между ними как-то Шарова секреты в целом многие это делают и на масштабах меньших Ну что ж наше время этой сессии вопросов и ответов подходит к завершению Давайте последний вопрос Из зала А вы сказали если какой-то запрос не прот до другого мастера там выстави лаж так а если они все друг До друга не смогут дойти и у всех этот флажок будет стоить везде нужно инвалиди данные Ну смотри В любом случае история с лешем происходит и какой-то волт знает о том что все остальные лты сейчас существуют в кластере То есть если у нас развалился кластер волтар у нас в любом случае Ничего работать не будет то есть независимо от того что у нас мультимастер Но в одно нодом режиме он не работает он работает в режиме когда хотя бы две ноды живые там из трх Ну или большинство из нечётного числа то есть истори сом потому что ну выбор мастерноды есть просто Э мастернода не обслуживает запросы обслуживают все ну что ж ещё раз Аплодисменты нашему спикеру несите сюда наши подарки и пока их несут Я бы хотел сказать отдельное спасибо нашему партнёру МТС который не только экосистема цифровых и услуги связи но и продукты в области кибербезопасности облачных технологий развлечений финансовых сервисов и многого другого Скажи кому мы подарим подарок от Озон Больше всего мне понравился вопрос про автон сил потому что на самом деле это кусок доклада который я выкинул из-за тайминга и хотелось про это отдельно рассказать поэтому подарок подымайся к нам на сцену прямо вот подымайся это отде приз от Озон спасибо спасибо за вопрос и кто же получит нашу супрематический артефакт за личное участие в добавлении крутотень нашей конфе вопросы были Очень клёвые но мне кажется Логично отдать матрёшку за вопрос о каскадном сбое вот тут в середине тоже Поднимайся на сцену тебе специальная кастомная спасибо супрематическая трёшка ну и наконец Давайте ещё один раунд аплодисментов нашему спикеру и специальный подарок нашему спикеру за участие Спасибо Спасибо а"
}