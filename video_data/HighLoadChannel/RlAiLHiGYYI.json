{
  "video_id": "RlAiLHiGYYI",
  "channel": "HighLoadChannel",
  "title": "Когда трансформеры врут: как мы \"дружили\" NLP-решения с высокими требованиями к качеству /А.Бондарь",
  "views": 490,
  "duration": 2574,
  "published": "2021-10-04T02:27:59-07:00",
  "text": "меня зовут артем я соответственно занимаюсь машинным обучением samsung next и перед тем как мы начнем хотел бы начать с небольшой личной истории в самые отчаянные дни пандемию я умудрился установить тик ток и прорвавшись через просто мириады танцующих молодых людей какие-то сомнительные шутки лайфхаки я в итоге добрался до интересного мне контента про технологии машинное обучение в частности вот это вот энергичного молодого человека который просто с упоением рассказывал про нашумевшую сеть от опытная и g5 3 его point был в том что это просто какое-то совершенно волшебное изобретение она и кот за нас напишет она и любую задачу решит просто представьте ее на естественном языке вот мне показалось ироничным что примерно в это время один из наших продуктов написал мне что после последнего апдейта наша state feat на цилиндр сетка внезапно начала видеть продукцию компании apple в текстах кулинарных рецептов подсвечивая яблоки не как обычные продукты а как бренд ну я отшутился что горе от ума и вообще эта участь не обходит даже лучших из нас то есть даже опытная есть такая проблема они выпустили статью где показывали как легко дурить их сетку просто наклеив вот такой вот stickers текстом на яблоко после чего сеть на чистом глазу рассказывают что это продукции apple и мне кажется на самом деле это довольно типичная ситуация у нас в индустрии что в академической среде однозначно есть большой прогресс сквозь линзу сми этот прогресс кажется очень притягательным для бизнеса но между ними есть целая пропасть практической реализации в которой гибнет большинство инициатив соответственно про эту пропасть и хотелось бы поговорить конкретно в рамках этого доклада мне хотелось бы рассказать про очень простую продуктовую задачу и двух подходах к ее решению первое это просто ортодоксальная я бы сказал по учебнику решение с точки зрения машины орден га а вот второе решение может быть не такое очевидное но как оказывается она более практичный с точки зрения бизнеса и соответственно помимо этого сравнения хотелось бы рассказать в каком ключе мы рассуждали о задаче чтобы прийти к такому какому-то более приятному не ортодоксальному подходу и естественно в рамках этого доклада я не буду сильно углубляться в конкретной архитектуры нейросети вот это все то есть это будет довольно верхние уровни во то есть нейросеть для нас это какой-то относительно черный ящик который часто ошибаются но во второй части доклада хотелось бы упомянуть несколько чисто практических аспектов связанных с аннотацией данных и реализации всего процесса о которых хочется поговорить потому что мы дорого заплатили за то что сделали ошибки здесь буквально пару слов о себе я учился в инфо ты и учился инжинирингу в parallels потом отучился от индустриальных практик будучи и тех ли дом в нескольких стартапах и в итоге в какой-то момент был окончательно очарован прогресса в машинном обучении вернулся в эту область и сейчас я возглавляю команду по машинному обучению в самсунге вернее даже не совсем самсунге а в samsung next это американская бранча самсунга у которой основной фокус на mn и покупках каких-то многие обещающих стартапов в области искусственного интеллекта интернет of tanks соответственно дальше samsung стрельбы помогает добиться какой-то синергия этим компаниям с основным самсунгом либо же просто вводит внутрь большого самсунга эти команды соответственно в одной из таких продуктовых кампаний вы ск я и возглавляю команду по машинному обучению вы ск начал как стартап 10 лет назад united kindom с очень простой идее дать возможность сайтом которые публикуют рецепты вставлять на эти рецепты кнопку которая позволяет пользователю превратить рецепт список покупок который и с этим списком покупок идти в онлайн игра шире соответственно идея очень простая но вокруг нее очень быстро выросла партнерская сеть из больших реперов такие как волмарт от sk и десятки других таких как паблишеры контента это уровня би-би-си good food recipes и многие другие независимых фудблогер of и компаний-производителей еды и такие как крафт хайнц unilever и многие другие да вот они на слайде и для самсунга как одного из крупнейших производителей бытовой электроники food industry я понятно она им очень важно цифровой контент все сильнее оказывает влияние на продажи в продуктовом ритейле иногда доходит до абсолютно анекдотических ситуаций когда ви реальный tick tock приводит к тому что с полок сметают сыр фета и упр или улетай возникают даже проблемы с этим какие то понятно это анекдот но тенденция явная цифровой контент все сильнее влияет на продажу соответственно на пересечении этих интересов мы с самсунгом и организуем какие-то коллаборации в частности мы являемся основным провайдером контента для их умных холодильников у нас есть набор проектов с samsung research по созданию эмаль моделей для других их smart девайсов и в частности на последнем cs все что касалось концепта smart kitchen во многом опирается именно на нашей технологии в то же время команда вы ск создает клиентское приложение для организации пользовательской книге рецептов список покупок мяу планов вот это вот всего и коммуникации вокруг кулинарии в целом зачем же визг нужен машин лирник если совсем вкратце то для умного распознавания и понимания контента рецептов по факту же почти каждая фича приложения так или иначе опирается на результаты машины орден га начиная от продуктового кейса о котором я уже упомянул превращение рецептов список покупок заканчивая такими вещами как рекомендательная система умный поиск насчет nutrition информацию много-много-много из этой схемы уже понятно что рассказать о всех архитектурных решениях в рамках одного доклада было бы довольно как-то глупо поэтому я постараюсь сфокусироваться только на одном и это та проблема с которой войск начал как компания это как превратить рецепт в список покупок то есть имея ассортимент магазина и текст рецепта как подобрать набор продуктов из этого магазина который позволит приготовить этот рецепт на первый взгляд кстати эта задача даже не кажется реально чрезмерно сложной я думаю многие инженеры придумали бы просто навскидку какое-нибудь решение взяли полнотекстовый поиск все это как-то закрутили это все работает столкновение с реальностью конечно жесткая потому что люди не хотят писать тексты рецептов каком-то нормализованном виде в частности очень часто они добавляют информацию которая вообще не связано с самим рецептом а связаны уже с процессом готовки иногда даже человеку не очень легко понять вообще какие продукты прицепить к этой строке да что говорить иногда человеку сложно даже просто дочитать это до конца не говоря разных странных комбинациях ингредиентов в равной в одной строчке как здесь например указано несколько альтернатив вот и что надо вешать и как сложно ну я надеюсь я вас убедил что без машины ордынка здесь просто не обойтись и ну давайте попробуем ее решить как вводные данные простые у нас есть ассортимент магазинов какое-то и описание каждого из продуктов у нас есть сыр и строчки ингредиентов из рецептов и надо понимать эти два массива постоянно обновляются то есть решение как эта классификация наверное здесь не заряжает нужно как-то это все связывать ну прошли курсы на курса ли курсы носки в боксе машин ирвингу соответственно отлично понимаем как эта задача решается по учебнику это фактически в некотором виде задача машина метрик ленинград то есть мы и хотим для каждого нашего объекта из огромной выборке научиться создавать какое-то векторное представление имбилдинг геометрическая интерпретация очень простая этот embedding эта позиция в каком там нога многомерном пространстве и мы хотим конечно чтобы эти позиции были не совсем рандомные а чтобы похожий по смыслу продукты в этом пространстве как-то компактно рядом лежали соответственно учить мы это будем даже не одну модель и две модели которая ищет эти mb денги для продуктов из магазинов и ищет этим бединге для наших сырых строчек и в таком сетапе организовать именно сам процесс выбора просто элементарно мы вокруг nb деньга нашего ингредиента просто найдем какие то похожие продукты из магазинов это будет отличный матч как это конкретный организовать я обещал не вдаваться в детали но в целом наш выбор огромный то есть мы можем использовать классический машин learning мы можем пойти в state-of-the-art вообще без разницы и смотрите сейчас в слух мы произнесли очень красивую схему она в целом абсолютно легитимно и абсолютно рабочие давайте подумаем хорошо как этот метрик learning превратить в конкретную технологию которая решает задачи как научить эту сетку ну вообще довольно просто особенно с позиции мыли инженера мы заряжаем огромную задачу по аннотации данных то есть для каждой строчки ингредиентам и подцепляем набор продуктов из магазина который подходит для этой строчке ну и они трудятся потихонечку пока млн дженнер наслаждается всеми благами автоматизации 2021 год собрать эмаль pipeline можно просто на коленке абсолютно и для инженера все абсолютно прекрасно он просто ждет пока разметить много новых данных запускает автоматом pipeline остальное время наслаждается свободой и просто ждет новых данных ну кайф но на самом деле это конечно рукотворный от и вот почему в нашем случае вариативность данных по настоящему зашкаливает потому что для каждой строчки ингредиента нужно прицепить набор продуктов из магазина но нужно понимать что есть строчке где не 225 грамм говядины а 400 грамм говядины или 500 грамм говядины и получается она татару придется все время искать по огромной базе продуктов из магазина и подцеплять каждой строчке очень часто один и тот же набор продуктов ну и люди умные мы инженеры в конце концов давайте как-то упростим им жизнь например добавим рига xp и нормализирует данные тогда мы немножко снизим эту вариативность станет совсем чуть чуть полегче но на самом деле если сделать хороший дата анализ внезапно оказывается что по легче не стало вообще потому что люди пишут контент очень по разному соответственно в теории можно было бы забить наверняка это какие-то эти кейсы большинство и напишет просто 200 грамм говядины но всегда сложно сказать а будет ли нормально модель генерализированных вот этих конкретных примеров это в целом философски очень большая проблема как подобрать данные которые нужно разметить соответственно мы можем легко прошляпить и плохо решить эту задачу ну и в то есть худшей ситуации нам реально надо разметить просто какие-то адские объемы данных о как сварить разлетелся вторая большая проблема с этапа заключается в том что м м в этом сетапе и умирает молча у него всегда для вас есть какой-то результат и эта проблема потому что в какой-то момент вы начнете получать известия косяках м м лучшем случае от вашего quay в худшем случае от ваших клиентов и пользователей тут я конечно немножко лукавлю всегда есть методы как эта модель и добиться такого поведения как отказ от классификации абсолютно любой но чуть дальше я затрону это момент снова и расскажу почему на самом деле этого добиться очень сложно вот и вторая проблема в том что у вас да будут оффлайн метрики вы видите как ваша модель улучшается но оффлайн метрики на размеченных данных и реальное поведение на всем огромном объеме данных которые приходят в модель это не всегда сильно коррелирующие вещи потому что может быть очень разные распределение этих данных вот а теперь посмотрим как вот эти две упомянутые проблемы отражаются на бизнес-процессах то есть наши союзы приходят к марту заключать с ними соглашение продавать наше волшебное решения мы делимся метриками которые мы получили на наших предыдущих клиентах и они говоря долги и нам нравится нам нравится user engagement нам нравится то какой у вас примерно покрытие контента какой процент ошибок вашей модели они говорят да да все здорово нам нужно провести внутреннюю и всегда что-то такое будет нельзя просто так доверять метрикам и вот их внутри некий возвращается с результатами так как юзер engagement померить они не могут потому что ничего не подписано они просто сделают какую-то трастовую выборку в вас вообще никакого контроля нету над тем какие данные они выберут и посчитают какую-то свою цифру в худших анекдотических вариантах какой-нибудь топ-менеджер выберет 4 свои любимые рецепты на трех из них вашу модель накосячит и он придет скажет вы знаете 25 процентов от вы ничего не можете с этим сделать так что и главная проблема в том что это с компрометирует и user engagement метрика метрику которая естественно гораздо более важное чем то на каком количестве контента это все работает вот и ваши силы возвращаются и говорят смотрите у нас вот есть такой набор проблем на таком-то контенте наша модель косячек что вы будете делать по большому счету вариантов не так много надо сидеть и до размечать данные получится ли у вас их хорошо да разметить это очень большой вопрос получится ли это сделать за разумное время это ж как бы не всегда можно прогнозировать а слезы говорят нам нужен очень конкретный срок за какое время вы сможете это все починить если вы хороший инженер скорее всего вы скажете не знаю за какой-то нам нужно интераций вот и весь контракт может встать под вопрос помимо этого молча кася чаще имел это еще и большая проблема для развития продукта в целом потому что когда дело доходит до b каких-то unix вич у вас будет сложно разделять эффект плохого м л и плохих weeks решений на практике это просто означает что ваша дисперсия растет ваше обед с ты удлиняется если у вас нету миллиарды юзер bass которая генерирует какие-то огромные объемы объемы интеракции у вас будут проблемы с абэ просто весь ваш цикл разработки будет удлиняться вот такая картина и в итоге оказывается что вы создали прекрасное решение которым гордился бы and ruin но на самом деле у вас просто тихо ненавидят все в вашей команде и в какой-то момент скорее всего все закончится очень грустно вот можно ли сделать лучше это хороший вопрос ну нам никто не мешает по крайней мере поразмышлять как улучшить ситуацию и я бы предложил подумайте от двигаться от хотел их бизнеса во первых ему конечно нужно нужна прозрачность то есть мы в любой момент должны четко понимать мы взяли набор контента клиента за какое качество мы можем поручиться то есть хотя бы иметь какую-то нижнюю оценку во вторых даже если наша система косячит и не достаточно хороша для контрактов в этом случае желательно хотя бы понимать за какое время мы можем все это починить ну и конечно да нужно масштабируемость иногда хотелось бы все-таки жертвовать качеством ради масштаба это тоже не хочется терять и внезапно оказывается что чисто теоретически мы можем обеспечить два из трех свойств просто организовав грамотно ручной труд как достигается прозрачность полностью затащив себе систему content клиентом и всегда мы знаем сколько контента мы уже разметили сколько осталось контента это может быть хороший нижней оценкой качества когда появляется новый контент мы примерно представляем сколько времени занимает разметить один рецепт то есть у нас еще и появляется какая-то прогнозируемость то есть даже зная за сколько времени один человек размечает один рецепт простое умножение дает нам примерно оценки за какое время мы можем справиться исправить ситуацию мог проблема конечно в масштабировании в тут об этом даже речи не идет но давайте еще все-таки чуть-чуть капнем в эту сторону и подумаем а можем ли каким-то инженерными практиками чуть-чуть улучшить эту ситуацию мы начнем сначала то есть возвращаясь к тому как мы размещали данные для каждой строчке мы подвешиваем набора продуктов из магазина кажется что это не очень оптимально потому что очень много похожих строчек с одной стороны очень много похожих сущностей с другой стороны идут может напрашиваться очень простое и эффективное улучшение давайте создадим какое-то внутреннее представление и разобьем задачу на 2 с одной стороны мы прикрепляем на вот эти внутренние представления наши ингредиенты а с другой стороны списки покупок то есть мы раз параллели войти два процесса и улучшаем эффективность кажется уже стала совсем чуть чуть полегче естественно это все хорошо на словах на практике это чуть тяжелее потому что у вас какой-то момент может начаться house этих внутренних представлений все будут создавать и их так как считает нужным но этот хаос все-таки у более управляемый потому что вы всегда можете создать что-то вроде онтологии продуктов и сделать эти структуры чуть чуть более прозрачные для вашего процесса идем далее тут есть один небольшой но на самом деле довольно принципиальный вопрос вот у нас есть строка ингредиента как нам найти это внутреннее представление то есть в теории можно сделать какой-то выпадающий список где наши она татар забьет название и выберет что-то похожее ну кстати мы тут можем быть совсем чуть-чуть эффективнее вместо того чтобы заставлять она татар разбивать руками мы можем позволить выделить просто подстроку в оригинальной строке по которой можно однозначно найти наш продукт конкретно вот здесь везде говядину выделю и без всякого машинного обучения мы нашли нужны объект нашей продуктовые онтологии и понятно бывают кейсы по сложнее когда один и тот же продукт называется совсем по-разному есть разные языки сложной морфологии но это тоже легко решается абсолютно инженерно давайте для каждого продукта теперь иметь какой-то списочек так называемых лексика этого продукта как этот продукт называется in a wild соответственно да чуть чуть сложнее но все еще не так уж и обременительно и получается что с ростом нашей вот этой продуктовой онтологии наполнение его лексика me задача нашего она татары сводится к тому что просто выделить мышкой правильный кусочек под строки вот зачем я вообще ударяюсь во все эти детали на самом деле я думаю некоторые из вас начинают догадываться что то что я описал это типичная эпичная задача абсолютно просто тоже по учебнику но немножко другая вот эта задача sequins ты ginga она многим известна также как на им данте терек огни шин частный случай в ней нейросеть по сути должна раз категоризировать слова в строке по разным типам по факту это будет что-то типа подсветки нужных сегментов информации в рамках вот некоторые строки нашем случае это конечно в первую очередь название продуктов по которому мы проводим matching однако мы можем быть чуть чуть умнее выделять дополнительные сегменты информации которые нам нужны вот сделать такую подсветку мы без труда извлекаем данные интересующие нас из нашей строки даже не вижу смысла останавливаться на этом слайде и вот внезапно оказывается что мы собрали вполне себе рабочий процесс он ручной но достаточно эффективный и он помогают убить сразу двух зайцев с одной стороны мы сдвигаем бизнес мертвой точки то есть мы можем с некоторыми маленькими клиентами уже реально заключать контракты продаваемого волшебные мель на самом деле просто загрузив она татаров по полной а с другой стороны мы начинаем копить данные для модели машинного обучения и эти данные за них заплачено на мне так жалко потраченного времени на это и самое классное что в какой-то момент накопив достаточное количество данных мы просто заменяем она татара моделью машинного обучения которое будет делать этот sequins tracking конечно в только в идеальном мире так все происходит во первых en el модем все равно будет довольно сильно косячить бы выделять какие-то странные подстроки а иногда еще и будет выделять продукты абсолютно правильно но просто эти продукты еще не существует в нашей базе знаний которую мы все еще вручную все-таки собираем но здесь есть один очень важный момент из-за того что мы комбинируем алгоритм машинного обучения янович bass у нас возникают очень естественный от класс от классификации то есть если какие-то извлеченные данные не кладутся в нашу строгую жесткую структуру в этом случае поднимаем тревогу и по этой тревоги прибегает она татар и либо он создает новый продукт в антологии либо добавляет лексики существующему продукту либо же просто правит результаты алгоритма машинного обучения создавала данные для новых циклов тренировки и самый наверное важный аспект здесь с моей точки зрения это то что у нас появляется понятие отказа от классификации то есть мы либо с очень высокой уверенностью провели матч от либо же при малейшей неуверенности нашу модель говорит нет я отказываюсь с этими данными работать и это кардинально меняет картину для бизнеса но перед тем как я расскажу почему хотелось бы вернуться к тому моему утверждению что в классическом м м да тоже можно организовать отказ от классификации потому что любая модель так или иначе выдаст confident score мы всегда можем поставить происходит и говорить если conference ниже 3 схода та модель явно предсказывает что-то не то на практике конечно если мы выставим действительно высокую строгость классификации скажем чтобы количество ошибок не превышала пяти процентов мы чудовищно нарастим количество отказов классификации это вот такая природа машинного обучения можно философский порассуждать почему так но не в рамках этого доклада видимо и аккуратности и количество отказов классификации очень сильно тянут друг на друга одеяло поэтому это будет работать не так здорово как может показаться на первый взгляд и теперь все таки вернемся почему этот отказ от классификации так важен для бизнеса а дает и нам самое что ни на есть колоссальное преимущество теперь имея набор контент откатки конкретного пользователя клиента не проводя никакой ручной работы в полностью автоматическом режиме мы делаем очень хорошую нижнюю оценку нашего качество сколько контента покрыта нашей моделью то есть просто со scrappy в сайт до всяких контрактов до переговоров мы уже видим эту цифру и понимаем стоит ли нам ввязываться в эту историю а если стоит то сколько работы у нас еще предстоит сделать чтобы это все хорошо работала если же у нас есть статистика по трафику все становится просто замечательно потому что мы еще и мы сможем посчитать не просто количество рецептов например покрытых нашей моделью а количество пользователей которые увидят хороший рецепт и эта метрика она совершенно крышесносное на и и базе можно общаться с другим бизнесом просто на другом уровне вот и мы получаем очень простой предсказуемый бизнес-процесс то есть до того как мы начали работу с клиентом мы получили его данные каким-то образом мы посчитали метрики качества возможно даже провели какую-то ручную работу в итоге ну и скорее всего подписываем контракт мы можем объяснить в общем методологию как мы откуда берутся эти цифры и почему им стоит доверять и после этого возможно нам придется все таки улучшать dota доводить до ума этот контент но это будет обзор абсолютно прогнозируемое количество работы мы понимаем сколько рецептов затронута теми или иными проблемы и мы просто правим их и самое главное данные пойдут еще и в до тренировку моделей машинного обучения а значит получается синергия эти два процесса будут вместе улучшать всю нашу ситуацию и это да и в итоге метрики растут все радуются контракты подписаны самое интересное что нас никто не заставляет в итоге вернуться к первоначальной идее метры clear дин к нашему красивому pipeline у до которого очень хочется сделать потому что это красиво с точки зрения инженерии потому что имея вот этот базовый pipeline который я только что описал мы можем решать проблемы бизнеса в целом довольно предсказуемо но в том случае если наша модель не работает на каком-то куске контент это в принципе мы можем натренировать интуит модель потому что данных у нас накопилось просто огромное количество и это интуит модель может пытаться хоть как-то хоть какой-то prediction выдать и показать ее пользователю при этом очень крутой его экспортером что в этом случае мы всегда можем еще и показать какую-нибудь плашку что вы знаете мы не уверенны в этом результате это создает огромное доверие с клиентом и это действительно очень может повысить ваши метрики вот и тут хоть можно было бы в принципе и закончить доклад по большому уровнем у папы большому счету верхней уровня у нас получается вот такой гибридный процесс который берет лучше от автоматического и ручного подхода и мой основной пойнта заключается в том что придумать такой процесс будучи чисто эмаль инженером в майн сети m-elle инженера наверно немножко сложновато то есть всегда очень хорошо взвешивать какие-то альтернативные возможности не забывать что что это можно делать вручную где-то можно подкрутить инженерии и где-то можно договориться с бизнесом о каких-то док процессах поэтому в моем понимании в продуктовый команде дата-сайентистов или m-elle инженер должен глубоко понимать концепцию бизнеса сидеть на скучных митингах с продуктами на первый взгляд скучных и как-то участвовать в этом процессе иначе вас ждет очень большие проблемы вот как я сказал можно было бы закончить но известно что дьявол кроется в деталях и о паре деталей мне все-таки хотелось бы поговорить и этот они все связаны с данными как предыдущий докладчик рассказывал данные это важнее чем или алгоритмы в чем абсолютно согласен и первая такая проблема это вот как выбрать набор классов для задачи sequence ты king напомню у нас есть строка для каждого элемента строки слова хотим навесить какой-то clans чтобы извлечь потом этот чтобы извлечь этот сегмент информации потом эта подсветка вот таким образом будет использоваться и на первый взгляд выбор тегов здесь очевиден вот мы хотим продукты достать мы хотим информацию о количестве достать может быть даже бренд достать но рано или поздно ваши на товар столкнется с каким-то очень проблемным кейсом который не укладывается в эту схему разметки в частности вот здесь вот что тут нужно подсветить как количество то есть это не две черные фасолины это не 12 унций фасолью это реально вот две банки по 12 унций и вот она татар встречать такой кейс и что ему делать у него есть два пути либо он идет команде инженеров и говорит вы знаете ваша схему разметки полная хрень давайте вообще все это как-то переделаем с очень понятным откликом модем или инженеров второй вариант просто забить на все это и сказать и выделить какую-то фигню то есть взять и испортить данные на будущее нужно еще понимать что он же не просто для своего удовольствия над этим работает во первых ему платят за количество контента который он разметил во вторых нему прибегают союз и которые говорят вы знаете у нас в горит контракт своим артам очень интересно что вы там хотите что-то внутри поменять на самом деле нас это не волнует и вот этот несчастный человек стоит перед таким тяжелым выбором на мой взгляд это просто понятный рецепт катастрофы причем избежать этой катастрофы на самом деле очень просто во-первых давайте дадим возможность она татару обходить схему разметки то есть когда он встречает какой-то непонятный очки из он может руками забить всю эту информацию прямо текстом это позволит ему избавиться от одной из его головных болей это давление со стороны продукты из и грузов в то же время она татар сможет начать собирать какую-то информацию по разным кейсом и приходить уже с цифрами к инженерам что вот у нас есть под пятьдесят примеров с такой конкретной проблемой давайте с ней что то сделать вот а во-вторых чуть более философский что между она татарами инженерами должно быть все таки выставлены очень хороший коммуникации и желательно если у вас большая продуктовая проблема которую вы явно будете долго решать чтобы либо лета на татаров либо ядро команды она татаров все-таки были какие-то in-house люди которые заинтересованы в финальных результатах и заинтересованы в том чтобы давать очень хорошие качества и фидбэк соответственно при этом со стороны инженеров надо уважать их мнения и на нашей практике каждый раз когда она татары что-то на спросил и мы это игнорировали буквально через годы мы начинали понимать насколько сильно вызов а копились вот и вторая история про трудности построения онтологии я так вскользь пробежался что да вот есть продукты между ними есть взаимосвязи на самом деле строит любую антологию это просто ад на земле и здесь опять нужен какой-то сильный ли ты тот команды потому что у вас постоянно будут возникать проблемы вот нужными нам например органические версии продуктов нужны ли нам какие-то гигантские версии продуктов или можно добавить это прикрепить какому-то существующему то есть этих вопросов будет миллион и если у вас не будет какого-то централизованного централизованного человека который будет принимать финальное решение у которого есть changelog который может посмотреть что вообще происходило у вас будут проблемы и соответственно очень важно вести хорошую документацию потому что объяснять каждому она татару будем честны у она татаров будет очень жесткая текучка либо это будет круто на аутсорс и на них должна быть очень хорошая документация элит команды должен приглядывать и смотреть вообще чем они занимаются вот иначе создание какой-то базы знаний может оказаться совершенно неподъемной задачей вот и соответственно если подытожить то так как данные важнее самих эмаль алгоритмов это значит только то что ваши инвестиции в процесс аннотации если вы сами занимаетесь аннотации они очень сильно окупаются вот и на этом в общем-то все хотелось бы подытожить вот такой суп ревматической схемы которые по факту является не более чем классической диаграммой технология продукты переложены в домен машинного обучения и если бы мне нужно было рассказать о цели доклада в одном предложении я бы сказал что она заключается в том что стоит все-таки сфокусироваться не на том что вы можете сделать и какую красивую ней ромку затащить к себе она том какие проблемы есть у бизнеса и научиться говорить нет если в общем то эти проблемы не стоит решать алгоритмами машинного обучения потому что нам имел инженером всегда очень соблазнительно забить на вопросы эксплуатации наслаждаться state-of-the-art моделями и в общем-то кайфовать от этого процесса но это бомба замедленного действия которую наверно вам не хотелось бы в итоге разминировать вот так вот можно эту стрелочку развернуть и все будет хорошо соответственно этом красивом слайде со снимком нашей команды вы не все попали в кадр мне бы хотелось закончить свой доклад надеюсь он был для вам на вас полезным и всем спасибо за ваше внимание и время так пока можно готовить какие то вопросы то поднимать руки спасибо поблагодарил артёма за выступление я понял как круто быть e-mail инженерам вот пара пожалуй пожалуй менять профессии так вопрос из зала так с кого начнем у кого нас микрофон ребята хелперы давать выбирайте любого человека с вами на ваш вкус и давайте ему микрофон так пожалуйста артём спасибо за доклад андрей кузнецов колосники хочу для победить спросить продуктовый вопрос с которого плавно вытекает вопрос технический ты упомянул о том что вы для небольших клиентов с большими требованиям по качеству продаете принципе она татаров место имели вот как вообще решаете каком конкретно кейси лама мы вообще не нужен его можно продать сенаторов и вытекающей из этого вопрос если допустим кейс предполагает из все-таки использованием или у вас большие нагрузки на какой стороне вы энтерите своих трансформеры отдаете ли вы это им или делать эту себя и вкратце расскажите как вы это делаете с какими проблемами сталкиваются спасибо да спасибо большое за вопрос отличные ну во первых у нас никогда на самом деле уже не получается продавать ручной труд просто потому что это было скорее в каком-то очень начале кампании десятки лет назад когда никакого мель не было соответственно сейчас это всегда имели алгоритм и какой-то небольшой чанг работая на татаров просто но в целом мы понимаем что семьдесят восемьдесят процентов работы конечно должно проводиться им или алгоритма в полностью автоматическом решение режиме и переходя ко второму вопросу то есть вот эти вот это наше решение это би ту би продукт который мы полностью сервер внутри и продаем по модели saas там нашим партнерам вот если надеюсь ответил на вопрос да в третьем ряду синей футболке артем запоминая и лучший вопрос ты должен будешь наградить спасибо за доклад мне вопрос вы сказали вы уходили от классификаторов потому что была сложность выборе 3 школ до о выборе порогового значения но по итогам вашей модели говорить то что иногда она не уверены на чем основана и и неуверенность то есть восстановить какой-то трешолд границ пряди решения когда он говорит что он не работает вот этот одежде да да да тоже отличный вопрос в общем разница с классическим млм что в классической модели происходит эта вещь такая плавающие вы можете ее подвигать вас при сижу на рекламу как то начинает между собой прыгать в этом случае появляется очень дискретный ответ либо да либо нет то есть он извлек кусок строки этот кусок строки мы поискали в нашей базе знаний либо этот кусок нашелся и тогда мы уверены просто вот из того как продукт устроен мы уверены что это хороший матч очень высоким качеством либо же если это строка не нашлась то тогда мы вообще никак не классифицируем и сравниваем вот эти два подхода предположим у нас одно и то же количество данных вот у нас есть первый подход где есть какой то транспорт и есть 2 в теории второй подход даст меньше и меньше метрики качества потому что это очень строгая строгий сетап в котором ему нужно работать то есть в классическом можно даже там по и поиграться и как-то найти хороший престижен recall но тут вот возвращаясь к философской проблеме почему м м почему нельзя доверять confidence карамель модели и ну как бы как что делать любая модель она строит в гипер плоскость с одной стороны там мы классифицируем как позитивно с другой негативно и если у нас вот в окрестности этой гипер плоскости лежат все данные а вот там вот где-то лежит outlier модель с очень высокой вероятностью скажет да вот это вот позитивный пример даже если он негативный то есть confident скоро это очень условная вещь поэтому на нее тяжелую операцию и вам нужно просто надеяться что данные который вам приходят от клиента из того же распределение на котором вы учились вот поэтому ему веры нет поэтому вот мы предпочли совсем другой вариант добрый день я к сожалению только в конце доклада присутствовать но бальзам на душу касаемо того что там данный возник что нужно копать глубже собственно бизнес-процесса у меня всегда стоит вопрос как данные которая используемый или алгоритма мы можем отслеживать с точки зрения изменений контент очень часто заполняется далекой команда иногда они меняют правила заполнения контентом и мы постфактум об этом узнаем очень частых есть когда нужная для себя строит новую хранилище этого контента но его дорого обслуживают иногда навешивать какие-то там барсы как например мы с этим работе сюда что ваши получается то много магазин новые правила и название продукта раньше буксовали с брендом теперь нет как вам об этом очень опасен залатать на самом деле у нас таких больших проблем нету потому что мы изначально строили схему которая может до переваривать более менее все ну да я понимаю о чем у нас была такая ситуация 1 вот придумали схему разметки набор классов и тут оказалось нам нужно добавить новый класс ну дальше все было очень тяжело и плохо то есть мы пришли к бизнесу и говорим смотрите мы примерно придумали как находить данные которые просто нужно с нуля ремонтировать это там 10 процентов datasette а и сказали вот нам нужно выделить столько времени на что они сказали нет мы не будем этим заниматься то есть пускаем дальше косячит мы будем знать об этой проблеме но извините это слишком дорого соответственно ну в идеальном мире ну конечно про store анонсировали все то есть обычно как бы как получается есть классы и он разрезы разбивается на два класса соответственно взяли все данные с этим классом прошлись по ним по поводу мониторинга тоже есть идея в целом можно строить какие-то распределения например классов у нас будет там какая-то гистограмма и когда нам приходит новый контент можно просто сравнивать гистограмму и смотреть что эти распределения не сильно разъехались вот это даже в автоматическом режиме можно по хорошему кандидата so in this должен этим заниматься вот место так еще у нас вопросики добрый день картон роста в леруа мерлен очень интересная была тема про антологию и и построение вопрос у нас получается есть два источника данных для того деле это непосредственно рецепт из которых можно выделить разные сущности также некоторые иерархии продуктов на которые мы используем вот соответственно вопрос вот как вы выделяли как вы строили вашу антологию на основании чего что для вас было перед лично людей построение что вторичным как вы насколько вы широко использовали иерархию продуктов которые у вас есть у ваших поставщиков вот или вы наоборот больше ориентировались на ваши рецепты что-то пытались в первую очередь сущностям из рецептов привязывали спасибо да спасибо за вопрос я прям чувствую боль практическую реализацию в этом вопросе и отлично понимаю да мы решили этот вопрос просто исторически мы начинали все-таки с контента рецептов с довольно небольших магазинов и мы понимали что мы не добьемся хорошего качества в принципе поэтому но решили рецепты это первичная то есть да это приводит большим кейсом проблемным то есть например там какой-то микс салатов и там 10 типов этого салата соответственно иногда мы могли бы немножко невпопад классифицировать сказав но это просто салат и надеяться что все хорошо вот но со временем это превратилось в достаточно гибридную модель в нашем случае просто мы создавали новые продукты иногда они выглядели очень странно то есть это действительно не один продукт это была смесь из там 5 продуктов не знаю набор для приготовления чего-то и у нас в антологии иногда бывали совершенно сумасшедшие строки которые вот по-хорошему конечно надо было как-то разделять но несколько продуктов ну вот это вот плата за legacy но у нас большой плюс что это все-таки какие-то речь кейсы то есть мы можем позволить себе немножко за полетел антологию но как бы основные кейсы работают хорошо ну возвращаясь к основному вопросу мы все таки начали с рецептов ну это скорее legacy я бы не сказал что это было провод какой-то супер продуманное решение просто с этим живем так у нас еще остался последний вопрос артем здравствуйте государства скажите вы используете где-то учитывать эту цену продуктов чтобы сказать чтобы например он номер метриках чтобы и запускать чтобы мы допустим дорогие рецепты до 99 процентов обрабатываем дешевые допустим вы как наш спасибо за вопросы вы как наш род matpat смотрели да конечно хотелось бы это делать но как бы просто ей есть другие приоритеты вот и но это просто да хорошая продуктовая идея я даже ничего не могу сказать но вы сейчас нет чтобы рекомендовать допустим какие то похожие рецепты написал они дешевле более доступно или наоборот более кенди лет да ну это тоже до одной из продуктовых фич туда просто вас да хорошая идея и до которые надо передать продуктом приоритизирует и эти штуки да спасибо просто кто-то посмотрел ваш boklok и решил сдать тогда как статус по проекту вообще один из наших продуктов я не успеют разговор"
}