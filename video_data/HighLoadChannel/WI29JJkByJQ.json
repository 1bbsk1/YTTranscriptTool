{
  "video_id": "WI29JJkByJQ",
  "channel": "HighLoadChannel",
  "title": "TechTalk с Neoflex / Евгений Овчинцев",
  "views": 372,
  "duration": 639,
  "published": "2021-10-04T02:45:36-07:00",
  "text": "добрый день меня зовут евгения птенцов и я работаю в компании neoflex мы создаем цифровой платформу для наших заказчиков начинает с тысячи пятого года и фокусируемся рассказанной разработке программного обеспечения и внедрение сложных информационных систем используя передовые технологии и подходы наши заказчики преимущественно относится к финансовому сектору это крупные банки и кредитные бюро нам доверяют российские и зарубежные банки из топ-100 а 9 и 10 заказчиков продолжаю сотрудничеству сняв лекс после первого проекта немного обо мне я работаю в компании neoflex более пяти лет и являюсь ведущим консультантом отдела de valls который занимается разработкой сложных инфраструктурных решений и построением процесса вся и сиди для наших заказчиков и внутренних продуктов компании моя специализация и так обернется я являюсь сертифицированным разработчикам и администраторам кубер notice и развиваю экспертизу по его внедрению эксплуатации внутри отдела и компании в целом теперь переходим чуть ближе к теме данного тех толка сегодня я хотел бы поделиться опытом одного из сложных современных проектов рамках которого наша компания создала аналитическую платформу для крупного бюро кредитных историй перед командой проекта стояло несколько задач создание контуру для потоковой обработки данных создания контуров долговременного хранилища и запуска пакетных заданий а также аналитической песочнице для дата-сайентистов в контуре поток обработки данных размещаем с у критичными для бизнеса продукты предоставляющие клиентам дыра данные в режиме времени близкого к реальному в связи с этим к нему определились особые требования к высокой доступности и отказывай устойчивости его компонентов контур хранилище должен быть горизонтальным масштабируемым для обеспечения расширения по мере появления новых данных и связанных с ними задачу а для аналитической песочница требовалось построить процесс dehors для моделей машинного обучения с возможностью разрабатывать модели на продуктивных данных и в дальнейшем проводить полученные артефакты через полный цикл тестирование на тестовых средах и обратно впрок для эксплуатации само собой на всех разрабатываемых артефактов требовалось настроить процесса непрерывной интеграции и доставки на все имеющиеся тестовые продуктивные среды реализации аналитической платформы получилось технологичный удовлетворяет современным тенденциям настроение высоко доступных распределенных систем одна из интересного технологии которые мы внедрили на проекте называется клауд flow в своей сути это целая экосистема состоящие из фреймворка для разработки микро сервисов потоковой обработки данных на базе ак spark ev link их оркестра таро инструментов сборки развертывание в кубер нить из класса работает в связке с apache кафка которую используют для организации обмена сообщениями между микро сервисами разрабатывают и поддерживает ее компании olight band ответственное за создание скала а к сбт и других продуктов этого стека клауд flow можно выделить три основных концепций первое это pipeline совокупность вас дата приложений представляющих собой конвейер потоковой обработки данных classflow на высоком уровне оперирует под лайнами которые представляют себе отдельное приложение каждый pipeline это отдельный проект в кодовой базе внутри которого описаны входящие в него в кремле ты а также blue print для описания связи между ними собираются и тепло и ци pipeline и как единое целое classflow гарантирует корректный схем в точках взаимодействия между стремления 2 это стрим лет более мелкие блоки потоковой обработки данных каждый стрим лет представляет собой независимый компонент обработки потока данных которые реализуют автономные tabs логики работы приложения третье это blueprint extremely это могут быть объединенными более крупные системы с помощью blueprint который определяет как не могут быть соединены вместе чтобы сформировать единую топологию он представляет собой отдельный файл внутри проекта написанные на декларативным языке хакон описывающий входящие в проект стрим лето и связи между ними через какие-то пик как происходит взаимодействие и какие консьюмер групп при этом используются теперь передем к составу компонентов входящих flow flow первую очередь это набор библиотек для разработки и плагинов для сбт набор библиотек используются для генерации структуры проекта импортируется в коде отдельных стрим летов для упрощения и стандартизация процесса разработки с помощью плагинов для спд осуществляется сборка проекта и локальный запусков позволяющий на рабочей машине запустить кластер кафка и все стрим лето текущего pipeline а результатом сборки такого проекта является набор образов докер для каждого extreme летов и jetsam файл проекта который необходим где плов кубер notice 2 компонента кьюб ситель classflow который представляете себя плагин для кимчи дверь консольная утилита управление губернатор с помощью которого осуществляется deploy pipeline of fluid flow а также получение статуса тепло и и другие операции центральным компонентом вклад flow является classflow оператор это приложение которое устанавливается в кубер notice и отвечает за beat white line of обновлениях между версиями а также оркестрацию стрим летов написанных на ок streams если немного углубиться в детали то приди твои проектов кубер найти с помощью учитель classflow происходят две вещи сохранение конфигурации диплом в виде секретов кубер натиск публикации оставшейся части описания проекта в виде кастомного ресурсы club all applications которое проводилось с помощью голосовал оператор и превращается в набора лорен extreme летов на окко и кастомных ресурсов для других операторов о них и поговорим помимо classflow оператор состав клал сафари tv link оператор из парка оператор это операторы для управления жизненным циклом стрим летов на базе технологии fling и spark от внешних поставщиков google и лифт данный момент call of law использует их но в новом релизе ставлена поддержка нативного diplo & frank из парковку берна this пустил экспериментальном режиме spark уже давно имеет надежную поддержку тепло и свет убавку bernette is a fling она появилась в последней версии в том числе стараниями live band кроме того состав клад в холле стринги и более развитый открытый дистрибутив тепло и бочках то обернитесь и управление его с сущностями его использование опционально развертывание клад flow можно указать адрес уже имеющегося кластера кафка но для быстрого старта с нуля небольших инсталляций он отлично себя зарекомендовал класса умеет много встроенных функций прощающих его эксплуатацию одна из важнейших атаги поэтому фигура циона я модель позволяющая настраивать портланд flow на разных уровнях артак лавина в целом да дельного инструменты любого его контейнера она дает возможность при deploy передавать переменное окружение которые отличаются для разных сред а также задавать различные параметры общие для сущности и как обернуть из например запросы и лимиты подсыпал epam клипа специфичные для отдельных framework of к примеру параллелизм задачу для фрэнка причем при тепло и можно указать любое количество файлов конфигурации содержимое которых будет объединена при публикации что позволяет отделить параметры которые относятся к в целом группам сред например все тестовые от параметров индивидуально для каждой отдельно взятой среды второй важный fitch является наличие встроенного в trim лето по металась экспортер его наличие дает возможность динамически собирать метрики со всех развернутых стрим летов и отображать их на информационные панели в grafana для визуализации происходящего в кластере за счет механизма метров метров про металась может быть создан идеи мы тоже борт с возможностью выбора конкретных pipeline of easter метов из него для отображения реализация эффективного для в и упрощения навигации также в коммерческой версии classflow помимо технической поддержки доступен графический интерфейс для визуализации pipeline of их работы и статусов отдельных стрим летов наконец есть очень полезная функция виде встроенных стрим лет и агентов для дебага они позволяют запустить отладчик на работающем стремление при локальном закуски и удаленно в кластере купер нить из используя стандартные механизмы djawadi буква р протокол для запуска стрим лето в режиме отладки его требуется лишь правильно сконфигурировать передав нужные параметры при дипломе не оставим без внимания и проблемы которые имеются у кого flow как и у любого другого горка первый из них это высокая доступность fling при использовании оператора стандартными средствами клан холл ее невозможно обеспечить а ручка и модификации они это реально ситуация должна улучшиться с появлением нативные поддержки клинков кубер notice но это требует дополнительного исследования второй проблемой является отсутствие нативной поддержки нет контейнер для stream летов кубинцы они используются этой странице акции этих задач тепло и например дождаться доступностью баз данных выгрузить данные подключение из внешнего хранилища и осуществить миграцию схемы базы данных данный момент поддержки возможности добавить нет контейнер скелеты нет это может стать проблемой при внедрении клал слова вашей организации случае наличия специфических требований к тёплую или обеспечение безопасности при реализации аналитической платформу это стало камнем преткновения с отдела информационной безопасности поскольку с их стороны было обязательное требование по хранению всех данных отключения сертификатов ключей шкур пол и переменных окружения для котлов данный момент можно настроить только получения их на этапе деплоя как войну сохранением весь клетку вернется в целом классов быстро развивается с большой вероятностью эти и другие проблемы будут устранены в заключение хотелось бы сказать пару слов о собственной аналитической платформе используемых технологий позволило обеспечить высокую надежность отдельных его компонентов и платформы в целом этого запуск всех рабочих нагрузок в кубер notice значительно упростил и и масштабирование а также обеспечивать смерти за акцию в построение процессов devops клаус край вот немалую роль позволив упростить и ускорить процесс разработки приложения поток наработки данных также разместить их обернитесь вместе с остальными микро сервисами получения всех его преимуществ"
}