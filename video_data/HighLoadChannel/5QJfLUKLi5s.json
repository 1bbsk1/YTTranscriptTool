{
  "video_id": "5QJfLUKLi5s",
  "channel": "HighLoadChannel",
  "title": "Разработка аналитической системы для высоконагруженного медиа / Олег Новиков, Илья Салтанов",
  "views": 106,
  "duration": 2285,
  "published": "2017-04-22T11:40:26-07:00",
  "text": "меня зовут олег новиков я аналитик и я расскажу сегодня о том как на sports.ru удалось в короткий срок разработать свою аналитическую систему зачем на велосипед какие бизнес инструменты мы получили в итоге внедрение такого решения во сколько это нам все обошлось обходится сейчас каждый месяц и как мы его развиваем дальше почему вообще взялись за свою энергетическую система когда вокруг так много разных хороших сервисов изначально sport.ru был небольшой сайт для спортивных болельщиков но потом мы стали запускать разные сайты в разных странах станет запускаем новые мобильные приложения потоки социальных сетях и постепенным обрастали все новыми и новыми сервисами и встал очень много везде были я ют свои аккаунты все они по-разному считали сессии уников и другие метрики нельзя был выгружать сырые данные счета как правило центрировали си набор метрик был очень ограниченным а нам хотелось получить очень много специфичных для медиа и социальных сетей метрик хотелось иметь возможность строить отчета нанесу природных данных потому что иногда нужно посчитать какие-то метрики сегменты пользователей которые составляют очень маленькую долю от всего трафика что очень плохо считается на сэмплах и нам хотелось собрать в одном месте все данные из разных источников то есть посещаемых сайтов обычной в метрике подписчики в соцсетях их динамика их пересечения подписок на разные группы хотелось также собрать информации об установках мобильных приложений собрать это все в одном месте и так чтобы этим инструментом могли пользоваться самые разные люди не только аналитики но и аналитики но и маркетологи менеджер по продажам журналисты кто угодно хотелось получить очень простой интерфейс и единое хранилище данных так чтобы могли делать запросы к нескольким запроса к данным из нескольких источников сразу же и первая проблема с которым мы столкнулись конечно был выбор технологии для хранения данных потому что нам нужно было получить какой-то удобный интерфейс для работы с хранилищем очень хотелось чтобы это было из кого ли что-то похоже чтобы аналитика мне пришлось писать код хотелось иметь возможность хранить очень много данных например посещаемость сайт и потому что у нас пример 12 миллионов уников месяце 400 миллионов хитов это только своего не считаю предложений и каждый год на 2 мин трафик поэтому нам также хотелось иметь возможность легко масштабироваться просто добавляя новые сервера не вкладываясь переделка архитектуру ли и другие сложные вещи и конечно не хотелось потратить слишком много времени на разработку в итоге мы остановились на колоночка 7 управления базами данных от amazon которое 20 вт она была основана на восьмой версии пост грессов поэтому в чем-то похожи и на этом были очень рады потому что на сайте на свой спор грыз ее расшивка держит очень много функции типов используется поэтому не нужно переучиваться врача в те очень быстро выполняются типично аналитические запросы когда вам нужно посчитать например средняя или сумму какой то какой то метрики в динамике по дням или и сгруппировав по какому-то другому полю то есть у вас есть гигантская таблица и он уже получить изменение одного поля и типично аналитические запросы с грубой ами агрегатным функциями на больших таблицах против ты работает очень быстро и она очень-очень быстро и легко масштабируется потому что оплата идет за объем данных и если вы хотите добавить пару новых серверов сделать это в два клика они сами переставляются несколько часов downtime при этом нет то есть мы так переезжали несколько раз с объемами 1 2 терабайта за ночь все данные переносятся ваши задачи просто web-интерфейсе сделать два клика хочу еще несколько серверов несмотря на то что рад shift это родственник пост длится очень многие вещи использованием не поддерживаться например такие типа данных как массивы джейсон serial некоторые функции вроде регулярных настроках все это врач в тени работают на самом деле не так уж и часто это нужно очень медленно работают запрос на получение большого числа полей и одиночной вставки потому что таково ночная база и это особенность архитектуры но с другой стороны для аналитической хранилищ нам не крайне нужны такие запросы и загрузка данных хранилище всегда происходит каким-то большими пачками из файлов которые предварительно загружаются amazon и строительной это типичный сценарий для аналитики розовой страны это означает что мы не сможем сделать совсем real-time загружая по каждому клику по отдельности и еще уроков то есть с некой особенности потому что вычислительный кластер состоит из нескольких вычислительных нот на которых происходит со магия и 1 вычислительного узла одну управляющего узла который распределяет данные на вычислительные узлы и по умолчанию он раскидывает данные так чтобы объем данных на всех узлах был ровный то есть просто каждой записи дроби нам раскидывать санации сервера чтобы у нас загрузка сидоров была одинаковая это может быть не очень хорошо с точки зрения производительности поэтому если мы знаем что у нас есть этой таблице и колонки которые постоянно джонса мы можем одну колонку в таблице указать в качестве дистрибьюшен кей и тогда все записи из разных таблиц с одним и тем же значениями срубишь nikkei будут все время попадать на одну и ту же надо чтобы при выполнении запроса joy нами нам не приходилось перераспределять данные между ног между нотами и это очень сильно ускорит выполнение запросов кроме есть возможность указать всю таблицу как-то объяснять дистрибьюции то есть мы сможем хранить полную копию всей таблице на всех нотах против то естественно это очень очень очень сильно увеличивает объем данных и стоимость для небольших таблиц которые постоянно джонни ца иногда бывает смысл это делать и можно указать какой-то из полей таблицы в качестве ключа для сортировки если мы знаем что по нему постоянно делаются фильтры условиях или постоянных комитетов сортировки и данные будут храниться в таком порядке при загрузке нему сортироваться и при добавлении новых данных после вакуум они будут вставляться в сортир нам проекты нужно места кроме этого против те можно очень гибко настраивать пользователей база данных и ресурсы которые выделяются то есть мы можем ограничить число одновременно выполнением запросов от пользователя и долю памяти которые выделены конкретным полета ли база данных этого мы хотели сохранить хорошо все данные из четырех разных источников во первых это типичный в метрике данное посещение сайтов и поведения людей на них ивенты во вторых нам нужны были данные об активности пользователей то есть регистрации комментарии лайки все что угодно все что делают пользователей в социальных сетях и в на любых сайтах с рейтингами после этого нам хотелось собрать к себе данные о подписчиках наших семистах потоков в социальных сетях примерно 500 твиттеров остальное vkontakte facebook задача минимум было хотя бы отслеживать динамику по дням в идеале еще хранит сами данные о пользователях чтобы мы могли взять пересечения или что-то узнавать чем они отличаются друг от друга выбрать какие-то сегменты и нам также хотелось выгружать к себе наших общих хранилище данные об установках предложений нашем случае мы их хранима пение и выгружаем и , не для того чтобы сохранить данная посещаемость сайтов нам нужен какой-то завод скриптовый счетчик который отправлял бы к нам запросы о посещениях то есть url просмотренных страниц и реферера из очень перехода и так далее но мы решили не изобретать велосипед взяли готовые счетчик певек new jams китовую часть папин собственный счетчика piwik практически без изменений дрели к себе и он работает так что отправляет данные с нужной информации на наши сервера сын венцами где пишутся обычные практически обычные джинсы axis логин джинса если отличие то что там еще добавлен модуль grp чтобы мы сразу же в access логах видели в каком городе и стране находится пользователь логе ротируется 1 час посчитали что это достаточно для нас частота обновлений и чаще нам не нужно после чего они очень простым парсером в один проход обрабатывается и превращаются в текстовые файлы которые можно загружать загружать врачи вскрик не делать ничего кроме того что парсит стандартный формат ajax и слога и делать и преобразование вроде получения операционки и версии браузера из визир агента в итоге мы получаем все эти файлы которые потом загружается amazon s3 и откуда загружается команды копия в назван решив вся эта цепочка занимает не очень много времени то есть у нас часовая ротация логов парсинг занимает ну пару минут загрузка вайс 3 еще секунд 30 и загрузка уже данных врачи вт пару секунд то есть в принципе мы могли бы интервал обновления скорость и обновлять данный пример 1 5 минут раз 15 минут но сделать реальный real-time не получится просто странам будут сетевые задержки все равно потребуется какое-то время на обработку logo и так далее еще одна проблема с которой мы столкнулись при получении данных было ограничение на число запросов в api и twitter потому что год назад они обновили api не сделали очень строгое ограничение на частоту запросов и мы могли получить данные даже о числе подписчиков со всех наших потоков раз в сутки но так как она слишком много потоков 509 вам сейчас это цена их могло то есть если нас 500 аккаунтов можно обработать запись 500 аккаунтов и запрашивать данные правильно таким образом мы получили в нашем аналитическом хранилище данные о посещении сайтов об активности пользователей то есть логе лайков логе комментариев поставки регистрации и так далее при этом мы не стали выгружать в redshift данные о практически практически не выгружаем тексты то есть нам для аналитики сам не пригодятся полный текст и постов или комментариев или хэши паролей поэтому никакие текстовые данные мы не выгружаем и еще у нас есть данные по подпискам установкам то есть установки приложений по дням и данные о подписчиках на 700 потока в соцсетях но такие сырых данных занимает очень много места то есть если мы каждый каждый поэзию каждый event каждый события на страницах раним отдельной строчкой то такие таблицы будут расти очень быстро поэтому естественных нужно как-то агрегировать чтобы запросах работали быстрее чтобы хранилище не снималось много места тем более что мы платим пропорционально объему поэтому мы стали агрегировать данный самый простой способ с агрегировать данная пища и масти разбить экстрим на сессии то есть если у нас человек посмотрел семь страниц за сессию мы можем заменить всем записей и одной записи где будет написано что просмотрел 7 странице какое было первое последние какой не был источник перехода какой подсчет номер визита и так далее ну так делают принципе все системы аналитики кроме этого мы также стали группировать данные по дням и неделям и месяцам по дням это было очень важно для рекламы чтобы мы могли оценивать рекламный янтарь в расчете на человека в день то же самое мы сделали с данными об активности оп оп активностях и подписках то есть у нас есть готовые недельные и месячные отчеты и получения выполнения таких запросов занимает очень мало времени там все данные уже периода рассчитан кроме того если мы агрегирует данные очень легко добавлять какие-то новые метрики например есть несколько типов активности на сайте есть комментарии есть плюсы из регистрации например мы хотим посчитать число активных людей которые делали хотя бы что-то если мы выполняем такие легирующих запрос мы можем посчитать какие-то новые метрики например долю людей которые сделали хотя бы одно действие первый же день после регистрации таким образом мы накопили все данные прошивки и даже с этим нужно делать то есть мы в принципе могли сразу же работать с этими данными при помощи screen но этого было недостаточно мы хотели сделать это удобный инструмент не только для аналитиков и технарей но мы также хотели отдать данные всем нашим коллегам журналистам продакт менеджером по продажам и так далее поэтому нам нужен был какой-то сервис визуализация и в итоге вас попробовали несколько разных остановились на сервис черта смысл в том что он имеет напрямую канальцы с шифтом кешировать результаты запросов у себя и у очень простой интерфейс для создания и просмотра графиков чуть позже я расскажу про нем поподробнее кроме этого так как у нас появилось огромное количество информации об активности пользователей мы решили их использую для персонализации сайт email-рассылок то есть например мы знаем что человек постоянно приходит нам с какого-то фан-сайта мы можем это сопоставить с данными о списках футбольных команд и понять что вероятно это человек интересуют футбольной командой и так как у нас есть профили пользователей ужас агрегированный содержащие информацию о том что человек раньше постоянно пользуется сайтом например предстал пользуется на последней неделе мы можем использовать эти данные для того чтобы вернуть его например с помощью email рассылки и такой результат данных такой результат запросов мы обычно записываем в мангу потому что с ней работает сайт и такие данная дается мгновенно в итоге мы получили возможность сделать произвольные сколь запросы на 3 мин данными без сэмплирования абсолютно любые мы можем запрашивать данные сразу же из нескольких источников то есть мы можем в одном запросе использовать данные я посещаемости сайта и увлечённость или в соцсетях потому что нас все связано между собой каждый поток соцсетях привязан или какому-то клубу или турниру короче говоря книгу на сайте и то же самое работать с мобильными приложениями каждом мобильном приложении посвящено или турниру или клубу или каком-то спортсмену и все это можем связать между собой и людей пользователей наших потоков соцсетях или мобильных приложений и посетители сайта мы почти также можем связать полить ради мы сделали удобны это сбор до для всех отделов компании где они могут смотреть интересующих данные без написания кода если вы запросов ничего так же мы научились использовать это хранилище для персонализации и поиска ботов системе рейтингов на сайте потому что нас большой сайт и на все больших сайтах с лайками и систему рейтингов возникает одна и та же проблема люди начинают накручивать себе рейтинг регистрировать миллионы аккаунтов рога ли у нас был случай когда мы нашли одного человека который зарегистрировал за пять лет три тысячи аккаунтов он это дело вручную это точно не были роботы так как у нас есть блоги и перила день его и на сайте есть блоги всех плюсов и создания аккаунтов и есть возможность сделать очень быстрые запросы к ним с помощью нескольких простых эвристик мы научились у являть в значительное число накруток в нашей системе рейтингов эвристики очень простые мы можем если у нас есть таблица с информация только такого прессовал мы сразу же можем определять какие то кластер на кончиков где какие-то непонятные активности постоянные рейтинге с одних и тех же печников с одних и тех же кук при лаги в браузер и потому что у каждого плюс есть две куклы которые 1 соответствует браузеру и не авторизован нам пользу по 2 мы можем явно определять use ради значит мы можем определять при логине ваня и это очень сильно помогает в борьбе с ботами и это не только может быть представлен в виде таких таблицы с подозрительным пользователями у нас каждый день модераторы получают списке людей которые много представлено них интерес так далее избитая проблема в аналитике сэмплирование данных подсчётах но мы ее решили так как у нас есть сырые данные о просмотрах посещениях и единственное проблем с которым и здесь столкнулись это то что таблица сырыми данными росла очень быстро стоимость хранилище прямо зависит от объема хранимых данных поэтому мы решили что мы будем хранить сырые данные о просмотрах страниц только за последний месяц все что старше мы или храним уже об считанных агрегированных данных последствиями по дням или каким-то другим срезом или же сырые данные старше 1 месяца мы отправляем в виде бэкап файлов хранилище на базе amazon глаша откуда мы их можем выгрузить обратно врач shift за несколько часов то есть если вдруг нам понадобится сделать какой-то очень сложный запрос на данных по прошлом ноябре за одну ночь мы можем выгрузить просто ноябрь обратно shift и делать абсолютно любые запросы над своими данными мы сделали выяснили и узнали какие метрики наиболее важны для наших коллег из других отделов и и сделали для оказывать за дело в несколько сборов так например редакция может отслеживать то что популярно прямо сейчас популярность отдельных авторов кликабельность текстов которые находятся прямо сейчас на главной странице продакт менеджер может могут отслеживать динамику в активности пользователей и смотреть как какие-то новые фишки на сайте влияют на активность увлеченных людей социальная редакция отслеживать то что расширяется и прессуются чаще всего прямо сейчас научились считать статистика по нашим соц сетям я там это не просто кита общие цифры оси местах потоках это удобные фильтры где мы можем получить например число подписчиков с учетом пересечении потоках посвященных только российской футбольной премьер-лиги то же самое работать с мобильными приложениями у нас 230 приложений и очень часто нужно посчитать на трафик охват в приложениях посвященных конкретному турниру и мы научились делать удобный фильтр так как все приложения привязаны к каким-то т.к. на сайте отдел продаж получил данные об инвентаре и редакция используют статистику каждый день теперь в общем и стали распространять дайте дрейвен подход по всей компании дальше несколько примеров таких дашбордов привычный график с посещаемостью который строится на сессиях можно создавать какие угодно срезы исправить какие угодно данные потому что при записи каликст рима в рот shift мы из url а понимаем айдишник записи то есть если например какая-то новость мы уже при записи просмотров страниц выделяем когда о блокаде и обжиг той мы можем дальше это привязывать с данными используется можно делать какие угодно фильтры по по географии по привязка страниц по тематике каким-то клубом или темам сюжетом о сайте следующий пример это активность научились верить динамику по регистрации лайкам и комментариям и другим важно для нтс метрикам долю активных пользователей активных новых пользователей и все это надо надо сборки очень понятно этим паспортом пользу продукт-менеджер такие же графики доступны по неделям и месяцам для наших регулярных отчетов котором состоянии проводим данное подписка в социальных потоках подбираются самые популярные наши потоки динамика самые популярные за последние дни динамика в виде графиков можно делать фильтры по клубам по командам к турнирам все работает очень быстро есть данные по динамика по дням и по неделям редакция получил возможность смотреть кликабельность сетях текстов которые находятся на главной странице прямо сейчас и они используются для того чтобы понимать какие тексты уже выиграли когда их пора за меня это что-то новое потому что главная страница нашего сайта формируются живыми людьми редакторами и для них важно понимать какие тексты популярнее других при этом не дожидаясь статистике за день или за неделю и в какой момент текст нужно снимать потому что все уже прочитали и никто на него не примет данные по установка мобильных приложений фильтра по датам фильтры по тематике приложений можно выбирать как угодно отдельные турниры отдельные страны типы приложений по турнирам по кругу и так далее создание график очень простое очень сильно напоминает кастом reports в google analytics и или конструктор отчетов яндекс метрики у вас есть набор метрик у вас есть на борде маус и и набор фильтров и вы просто драган дропом перекидываете колонки из таблиц и создаете нужными обрывки актуальный слайд с 1 января вступает закон на хранение персональных данных на территории россии и amazon и естественно нет таких серверов россии но из-за текущий формат формулировки этого этого закона довольно распил в 4 совершенно не следует то что данный нельзя храни за рубежом на самом деле там только вирус о том что данные должны храниться в россии но это не значит что купе можно отправлять за рубеж например но даже если такая проблема возникнет и будут какие-то поправки к этому закону это не станет проблемой мы используем американского центра от шифта ничто не мешает хранить нем только эти снимки пользователей персональных данных например имя фамилию брать из-под гарса и совмещать их уже на этапе формирования таблицы или графика сервисе визуализации потому что чертова сможет приконнектиться и кроссов тур по адресу из joy не данные уже у себя то есть никакие персональные данные при этом не будут храниться за пределами россии как я уже сказал мы научились использовать аналитическое хранилище не только для аналитики на для персонализации классический пример с рекомендациями по теме странице можем подбирать страницы которые часто смотрятся вместе с конкретным постом часто прессуют вместе с конкретным постом рекомендации для пользователей например у вас 20 общих друзей из пользователям либо постоянно ставите плюсую этому пользователю ли этому блогу подписывайтесь и так далее все это работает очень быстро потому что несмотря на то что таблица большие базы колодочные и запросы с и группировками на получение для количество общих друзей работает мгновенно и так как у нас есть таблица с профилями пользователей где мы храним такие данные как сколько раз человек заходил к нам за последнюю неделю когда он последним заходил чем интересуется переходил ли он сайтов приходило ли он с контекста посвященному какому-то конкретному клубу все сигналы из которых мы можем извлечь какую-то информацию о предпочтениях пользователей хранятся таблицей с профилем полетели поэтому можем использовать это для нарезок на рассылки например рассылки для людей которые к нам ходили на при стали ходить мы можем им напомнить мы можем рассказать что что они пропустили за неделю течение которых не было можно напомнить людям которые начали когда-то играть делать ставки прогнозы начали играть на тазе футбол что скоро будет новый матчем пора сделать замену и так далее все это очень удобная и происходит очень быстро потому что у нас уже готовы при агрегированные данные нам не нужно ничего заново считать сколько раз человек заходил на кита конкретной страницы примерный примерные затраты на всю эту историю на самом деле может получится намного дешевле потому что если вы знаете что будете это использовать очень долго времени vasif там амазона будет осени скидки чертова делает очень сильно скидки за большое число пользователей сервера у нас так своей есть но смысл в том что за меньше чем две тысячи долларов мы получаем инструмент который намного мощнее например чем премиум версия google analytics или какие-то сервисы типа kissmetrics а потому что kissmetrics на нашем трафике стоил будет в районе семи тысяч долларов но не умел доработать с мобильным приложением и социальными сетями и кроме этого того что мы храним все данные у себя это означает что мы можем как угодно развивать эту тему дальнейшем разработка системы заняло меньше трех месяцев меньше 3 человека месяцев то есть уже через два месяца после того как у нас появился к еде и понимание на основе каких технологий мы будем это строить появились первые прототипы дашбордов для коллег из других отделов поэтому нельзя сказать что это была очень сложная система и это можно сделать каждый благодаря современным технологиям а мне нужно подписываться когда свою инфраструктуру изучать новые технологии поподробнее про то как это все технические устроена можно почитать блоги sports.ru на хабре или спросить у меня прямо сейчас здравствуйте и спасибо за доклад 2 вопрос скажите пожалуйста сколько ивентов в сутки вы собираете второе какой размер и datasette а просто ну там в гигах например гигабайтов например но изначально мы хранили в районе двух терабайт но после как мы стали превышать поставок мы стали понимать что это стоит объем постоянно растет и деньги растут мы стали себя ограничивать и стараемся не держать очень хотел больше одного терабайта мы это сделали за счет ограничения охраняется когда находим месяц вообще объем полностью зависит нет ни трафика который вас на сайте от жадности и аналитиков и то есть число я с вами не согласен он от обеих вещей зависит но конечно он зависит от трафика но если у вас есть одни просмотр а дальше все зависит от того сколько ивентов вас будет на этом одном просмотры поэтому число в число хитов она на самом деле может быть каким угодно и тем не менее вот сколько ивентов вы сохраняете в эта система сутки вот я сказал 400 миллионов в месяц это только свобо улучшает рисовали вместе за это приблизительно там не за 10 миллионов для да где то так понятно сего спасибо за доклад несколько вопросов последовательно наверно собственно первый вопрос вы говорили про персонализации какие персонализации для пользователей вы делаете честную скелету youtube а грубой ордер бай ничего более хитрого дали нам так но река медленно снимает вообще отдельная история записан в том что дополнение экономической системе мы получили вы приятный бонус что мы можем ее также использовать и для персонализации поэтому здесь нет каких-то сложных историй с собрать инфильтрации мы не можем делать 7 для разложение матриц посещений страниц пользование здесь все носки елина грубо их а и второй вопрос вы в грубая для прыгать или сразу хранить большое количество данных вы чисто вот все сами персонализации еще кучу от всего что вы по сути из аналитики можете выдернуть примерно объем вот тупо количество фактов которые хронически активным пользователям очень сложно сказать потому что у хотя порядок 10 тысяч сто тысяч на пользователя 10000 чего ну фактов про пользователя ну октябрь полюсе ли которые вас много ходит много чего то где-то собирается смотрит так далее вот сколько с профилем таких данных хранится просмотр сосчитать ну вот и меня какие-то счетчики и прочие факторы вас хранятся возможно там не на его вакф форматов политик платящие там формат несколько тысяч на самом деле для нас важно не число потому что любые 1000 просмотров новостей по одному и тому же тегу равняется 10 тысяч просмотров на все потому что здесь важно именно какие-то сигналы которые можно получить по источников переходов по каким-то отклонением от других пользователя тоже человек постоянно читает про один и тот же так и это отличает его от среднестатистического полете так далее средне средне цифры просто здесь ничего не скажет потому что это быстрее не цифры по улицам естественно большинства пользователей записи 1 что человек нам пришел и вскрыл какое-нить реклама объявление понятный и третий вопрос вы упоминали чтобы kissmetrics рассматривали на отказались насколько понимаю в отличие от но словно cookies метров есть раньше на и прочие клевые штуки у которых вас гугла и нет звука я понимаю ну вот какие последние 10 или просто не вписывается в идеологию сквера как бы они нужны ли они бизнесу и планируете ли вы их внедрять спасибо ну мы рассмотрим сам не только из метрик снова new relic несколько других систем чадвик потому что человек сделан специальный для медиа сайтов и у нас была задача ни в коем случае не копировать какой-то чужой другой сервис ни в коем случае не к 1 бесплатные сервисы типа analytics или метрики потому что это бессмысленно зачем тратить время разработчик нужно так есть поэтому вот тот набор fitch который у нас есть на который рассказал который отличается от стандартных систем аналитики возможно смирите theory ли возможность делать это фильтры с мобильными приложениями с потоком соцсетях это именно то чтобы вас для нас конечно kissmetrics орбит есть много fitch которых у нас нет возможно какие-то в течение времени мы к себе перетащим например реал тайме обновления данных которые есть у чарли и потому что на самом деле там может быть важно для редакции так далее но в целом я бы не сказал что мы хотим скопировать себя кислый dex меня такой вопрос вот вы упоминали что можно использовать персонализацию в частности там искать похожие интересы пользователей по лайкам а потом звучало такая цифра в 10 миллионов ивентов и что там все это можно считать за 30 дней и вот кажется что это работа ну для графа так в целом и на самом ли деле но целесообразно использовать вот такой подход как упомянули вы именно для этой цели и если вы используете ту какие там сроки вычислений какой-нибудь сроки усиления странице похоже на страницу ну скажем срок вычисления похожих пользователей с интересами пользователя смотреть мы стараемся максимально использовать специфичность нашего сайта потому что у нас довольно характерной аудитория направления исследования что например у больше больше чем у половины наших полицейских явные клубные предпочтения поэтому мы всем возможным способом стараемся сократить объем вычислений и соответственно расходы на аналитику и рекомендации поэтому там есть возможность ну например переходим от просмотра в конкретных странице конкретных людей к темам поэтому вместо например миллионы страниц у нас есть 100 тысяч тегов и вот все эти вычисления думает не так что много времени расчет например похожих пользователей по плюсам поразительным ну такой запрос за сутки может занимать на три минуты то есть не очень много то есть это в любом случае не real-time это какая-то спасибо за доклад а скажите вы используете какие технологии по выявлению пользователя то есть грубо говоря то что он зашел своего ноутбука из дома или вы используете просто вагин пароль много в голове плагины вот выделять в идентификации пользователей помню вам принципу но по какому-то ну вы можете определить что это один и тот же пользователь хотя он не залогинился у себя дома достоверно для всех в общем случае нет конечно но как initial гайки на используйте время самые примитивные подхода ну то есть переходы интересы но в целом здесь еще очень много работы впереди а для мобильных что-нибудь для мобильных мы только начинаем сейчас внедрять счетчик наши знака в приложении чтобы считать все событие которое есть могли простите за заранее глупый вопрос какой смысл в 100 500 приложений то есть взяли просто как бы открыть одно приложение и сделать там тему по сути они как бы идентичны вопрос очень хорошие спасибо на самом деле приложение 230 они отличаются по типу то есть у нас есть главное приложить главное приложение сайта для всех сайтов дальше есть предложение по турнирам приложение по клубам и приложение с курсом видео которое в качестве and suck on screen для век а то смотреть матч прямо сейчас он целиком посвящен статистики и видео большая часть из этих 230 приложение это клубное приложение которое сделано для болельщиков конкретных клубов и наша проблема была в том что у нас слишком много контента и даже на небе если человек заходит на главную страницу и болеет за какой-нибудь соус контент он скорее всего увидит там в такой популярный спартак в лучшем случае ливерпуль поэтому для нас персонализация очень важно потому что 97 процентов контента на сайте сгенерированы пользователями поэтому нас очень много контента про какие-то не популярные темы например 2 итальянский дивизион футбол в дании так далее и чтобы дать возможность людям футбольным фанатам смотреть как именно тот контент который интересует и плюс общаться именно с болельщиком того самого клуба за которой не болеют а это очень важно для нашей аудитории мы сделали большое колеса приложений и судя по статистике extreme открылся здрасьте а я вот хотел спросить про деньги вы сказали цель redshift у стоит 180 долларов в месяц это это создано старше сергей говорит ssd на 106 гибрид а вы не думали посмотреть например бесплатную лицензию вертите которые try not бани полна 1 093 на терабайт дается бесплатно то есть вы сказали что вы ограничите данные все равно 2 ed типа вам больше не надо вот так что можно наверно не платить ну и все будет работать и увертки вроде и возможности больше external таблицы с ходу по можно помню создавать ну и там аналитические функции расширенную сколько вот такой вот у меня вопрос верьте к очень нравится и вообще очень нравится кола ночная базы поэтому я целиком за за такой подход но год или года полтора назад так возможность видимо не было смерти кай и плюс нам очень нравилось интеграция была любом случае нам очень нравилось интеграция с другими сервисами амазона и возможность экономить на сетевых задержках при пересылке данных и снова сервисов другой и нас качество цена которым мы платим сейчас для этого функционала которого системы очень низко 0 в случае спасибо что сказать за городскую про графику точно можно сказать что рачев это не единственная технология для таких систем которые могут быть для систем потому что там если смотреть посты на хабре за последние полгода было очень похожее решение на глуби кэри было два разных решений на vertica мы сделали рот shift и еще кто-то сделал раз shift колоночный базу и вообще облачные хранилища для данных а была ли яма звонок очень подходит так что верьте к вполне могла быть вариантом"
}