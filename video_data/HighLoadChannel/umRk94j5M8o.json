{
  "video_id": "umRk94j5M8o",
  "channel": "HighLoadChannel",
  "title": "Высокая производительность и нативное партиционирование / Андрей Гущин (Zabbix)",
  "views": 2712,
  "duration": 2365,
  "published": "2019-12-05T12:55:12-08:00",
  "text": "я меня зовут андрей я с технический инженер технической поддержки zabbix тренер работы более 6 лет технической поддержки и напрямую сталкиваться производительность сегодня буду рассказывать о производительность которая может дать там скилл бибер в большинстве при сравнении с обычным пожгли сам десятым также никто не которое вводная часть про то как вообще работает то есть начнем что есть определенный вызову производительности как с которой встречается каждая система мониторинга 1 вызова производительности это быстро сбор данных и обработка сегодня коллеги многие об этом уже рассказывали с хорошей система мониторинга она должна оперативно получать все данные своевременно обрабатывать их согласно триггерного выражением то есть как это обрабатывать по каким-то критериям в разных системах это по-разному и сохранять эти данные в базу данных чтобы в дальнейшем это использовать второй вызов производительность который необходимо это хранение история так хранить это в базе данных зачастую и иметь удобный и быстрый доступ к этим метрикам которые были собраны за какой-то период времени и самого чтобы это было удобно получать эти данные использовать их в отчетах в графиках триггерах каких-то пороговых значениях для оповещений и так далее третий вызов производительность это очистка историю то есть когда у вас наступает такой день что с вам не нужно хранить какие-то метрики которые были собраны 5 лет их подробные даже не даже не пять лет а месяц или два месяца какие-то узлы сети были удалены или мы там какие-то хасты метрики они уже не нужны потому что они устарели перестали собираться то есть это все нужно вычищать чтобы у вас база данных не разрослась до большого размера и вообще очисткой истории чаще всего является очень серьезным испытанием для мои хранилища то есть вы очень сильно зачастую влияет на производительность как решить эти проблемы то есть я чего буду говорить конкретно записи то есть записи первые 2 вызовы а не решены с помощью кэширования то есть сбор и обработка данных мы используем оперативную память для хранения всех этих данных сейчас об этом будет подробнее рассказана и также на стороне базы данных зачастую есть определенное кэширования для основных выборах для графиков для других вещей то есть кашира нес на страницу забег сервера это у нас присутствует configuration cache wip кэш history тренд кэш что это такое configuration конечно это основном укажу в котором мы храним метрики то есть мы храним хасты элементы данных триггер и все что нужно для обработки при процессинга для сбора данных то есть каких ростов собирать как с какой частотой все это хранится в configuration к чтобы не ходить в базу данных и все облегчать не создавать лишних вопросов базу данных то есть после старта сервера мы обновляем этот кэш создаем и обновляем периодически зависимости от настроек конфигурации здесь схема достаточно большая но основная проблема основная проблема основные в схеме это вот эти сборщики то есть это сами процессы сборки это различные полер и которые отвечают за разные виды сборов там они собирают данные по стенам ppm ой по разным протоколом и передают это все на при processing также если у нас есть вычисляем элементы данных я думал кто знакомым zabbix он знает из вычисляемые гарика ционные элементы данных которые нужны агрегировать проверки мы их забираем напрямую лукаш котором я расскажу каким образом наполняется чуть позже то есть вот эти все сборщики они используют конфигурация накажи для получения своих заданий и дальше наполняет передает на при processing при processing обрабатывать согласно также использовать конфигурациям кэш для получения шагов при processing обрабатывать такие данные различным способам скажу большое поступление что начиная с 42 у нас при processing вынесен на прокси это очень удобно потому что сам при процессе на достаточно тяжелой операция и если вы используете у вас очень большой zabbix с большим количеством элементов данных и большим частотой сбора то это сильно облегчает работу средством после того как мы обработали эти данные каким-либо образом с помощью при процессинга мы сохраняем их history кэш для того чтобы их дальше обработать и то есть вот на этом заканчивается с сбор данных получается и мы переходим главного процессу то есть главное в записи процесс так как эта монолитная архитектура history сингер ис-3 сингер это главный процесс который занимает сильно атомарной обработкой каждого элемента данных то есть каждого значения приходит значение он уберет из history кэш проверяет в configuration сингари если какие-то триггеры для вычисления вычисляют их если есть создает событие создает эскалацию для того чтобы оповещения создать если это необходимо по конфигурации и записывает раз у него есть триггеры для последующего последующей обработки при следующем агрегации какой-то если вы агрегируются за час за последние так далее то значение он запоминает вли-5 что вы не обращаться в таблицу истории то есть таким образом в конечно пал няются нужными данными которые необходимы для вычислений триггеров вычисляемых элементов и так далее таким образом мы и дальше history синкер записывает все данные уже в базу данных база данных записывать их диск и на этом процесс обработки заканчивается на стороне б.д. то есть когда вы хотите посмотреть графики либо какие-то отчеты по событиям есть различные кашин в рамках этого доклада я не буду о них рассказывать то есть вот где мы искали это если нам и надо б buffer pool там еще куча различных кэшей который тоже можно устроить но это основные то есть этот шарик буфер сиф актив кэш союз и шарик пол то есть для урока то есть я для всех баз данных привел что есть определенный конечно который позволяет держать в оперативной памяти те данные которые часто необходимы для запросов того них свои технологии для этого соответственно из конкурентная среда то есть зафиксирую поставил собирать данные записывает их при перезапуске он тоже читает из история для наполнения в лукаш и так далее то есть тут же у вас могут быть какие то скрипт и отчеты которые используют либо забился пей который на базе web-интерфейса построен он самих себя и ходит в базу данных и получает необходимые данные для получения графиков отчетов либо каких-то списка событий последних проблем и так далее также очень популярное решение для визуализации отобрав она которые используют наши пользователи она умеет как напрямую ходить через zabbix опять так и напрямую базу данных и тоже она создает определенную конкурентность для получения данных соответственно для этого нужно более тонкая и хорошая настройка базы данных для чтобы соответствовать и быстрый выдачи результатов и тестирования соответственно третий вызов который используется в zabbix это очистка истории с помощью housekeeper housekeeper вполне он соблюдает все настройки то есть у нас в элементов данных указано сколько хранить в днях сколько хранить тренды то есть это динамику изменений динамика же мнения мы считаем я не рассказал про тренд кэш который мы высчитываем на лету то есть как поступает данным их агрегирует за один час восьмом это числа за последний час количество средняя минимальная и записываем раз в час это все в таблице для динамика изменений тренд и и housekeeper запускается и удаляет обычным select a mi данные из базы данных что не всегда эффективна как понять что это неэффективно вы можете на графиках производительности внутренних процессов видеть такую картину то есть вас history синкер постоянно занят это красный график и рыжий график который в полки видно по верху идет и the housekeeper который постоянно запускается и ждет выполнение от базы данных то есть когда она удалит все строги которые он задал то есть он у нас есть сайт и меди например возьмем какой-то магии нужно удалить последний там пять тысяч больше чем как такой все это конечно по индексам но обычно это dts это очень большой база данных все равно это считывается диска и поднимает в кэш это всегда занимает очень это очень дорогая операция для баз данных и в зависимости от ее размеров это может приводить к определенным проблемам производительность соответственно отключить housekeeper можно простым способом то есть у нас web-интерфейс есть всем знакомая настройка в administration general для housekeeper а настройки мы отключаем внутренней housekeeping для внутренней истории трендов соответственно housekeeper больше не управляет этим то есть что можно дальше делать то есть вы отключили у вас графики выравнялись и какие в этом случае могут быть дальше проблема то что может помочь позиционирование есть акционирования еще называется обычно это настраивается на каждой базе данных которое пречистую реляционная база данных различным способам там на мои сколь своей технологии но в целом они очень похожи если говорить о пузырь из 10 и мой сколь нет конечно там очень много таких о внутренних внутренне разницы как это все реализовано и как это влияет на производительность но в целом создание например новой партиции часто тоже приводит к определенным проблемам обычно настраивают зависимость конечно от вашего сет-апа насколько у вас много создается данных за один день то есть обычно выставляет самый минимальный это за один день партицию и для трендов для динамика изменений это один месяц новые партиции это может применяться если у вас очень большой сетап сразу давайте скажу размерах сетапы то есть наверное до 5000 новых значения секунды на vps так называемых это будет считаться малость это средний это аппетитом надо 25000 значений в секунду и все что слушает она она уже большие и очень большие инсталляции которые действительно требуют очень тщательно настройки на базы данных соответственно на очень больших инсталляциях один день это может быть не оптимально потому что я лично видел mais quel и партиции по 40 гигабайт и больше могут быть заденем соответственно это очень большой а также объем данных который может приводить к каким-то проблемам и он нужно уменьшать то есть что дает портишь ionic я думаю все знают это секционирование таблиц то есть это зачастую это отдельные файлы на диске и говорим план запросов он более оптимально выбирает одну партицию если это входит в какой-то обычно позиционирование но для записи в частности используется паранджу по диапазону то есть мы используем timestamp у нас число это обычные то есть timestamp это время с начала эпохи и вы задаете начало дня конец дня это является партиции соответственно если вы обращаетесь за данными двухдневной давности это все выбирается из базы данных быстрее потому что это всего лишь один файл нужно загрузить в кэше выдать чем очень большую таблицу соответственно парке шоппинг в этом плане и зачастую многие баз данных также ускоряют insert то есть это вставка опять же в одной child таблицу пока я говорю пока абстрактно поэтому это тоже возможно против портишь о нем часть зачастую это тоже помогает также у нас есть было лишь недавно в 34 мы внедрили решение новый сквер то есть мы добавили возможность признать власть актер то есть вы можете писать например отдельные какие-то типы то есть вы выбираете либо числа пишите либо какие-то у нас есть string текст логан логии можете писать ластик search и соответственно web-интерфейс тоже будет уже обращаться к лосяшу это отлично на каких-то случаях работает но данный момент это можно использовать но недавно для 42 мы обратили внимание на такую вещь как там сказал тебе что то такое то есть это расширение для по сгрыз то есть она имеет нативный интерфейс по игре сколь который позволяет плюс это расширение позволяет намного намного более эффективнее работать во первых там series данными также и соответственно иметь автоматической партиции партиции рования как-то выглядит то есть это гипер ты был есть такое понятие в томске а то есть то гипер таблице которую вы создаете и в ней находится чанг ко чанг и это партиции то есть это чем таблицы если я не ошибаюсь но завтра коллега будет рассказывать о это более подробно я думаю как работает омске л д б и это действительно эффективно то есть как заверяют производители томские тебе что они используют более правильные алгоритм обработки запросов в частности insert of который позволяет иметь примерно постоять на постоянную производительность при увеличивающимся размере до тасс это вставки после 200 миллионов строк postgres обычно начинают очень сильно проседать и теряют производительность буквально до нуля в то время как temple тебе позволяет insert и при любом количестве объема данных позволяет вставлять как можно более эффективно как его установить все достаточно просто то есть есть у них в документации писано там можно поставить его из пакетов для любых он зависит от социальных пакетов по адресу либо можно собрать из скомпилировать вручную ну у меня так получилось что мне пришлось компилировать для базы данных на zabbix мы просто активируем station думаю что кто пользовался позвали thinkstation просто создаете для активировать extension создаете его для база данных zabbix которые используют и последний шаг вам нужно создать гипер ты был то есть для этого есть специальная функция creed гипер ты был которая в которой первым параметром указывать таблицу которую в этой базе данных нужно для которой нужно создать гибер таблицу по какому полю создать и long time interval то есть это интервал чанков вот этих партиций которые нужно использовать то есть вот 8 6400 это один день и параметрами great да да если выставлять их труд а это переносит текущие все данные в в чанки заранее созданный я сам именно использованы грейда то но этот занимает достаточно приличное время там зависимости от того на каких размеров у вас база данных у меня было около терабайта это заняло там больше часа создание ну и даже каких-то случаях при тестировании я удалял на исторические данные для текста я стрингах чтобы их не переносить о нем на самом деле были неинтересно и последний апдейт мы делаем в нашем в extension мы ставим там скилл baby чтобы база данных и в частности наш zabbix понимал что есть extension он его активирует и вы можете он он использует соответственно правильно синтаксис запросы уже к базе данных то есть используя уже тысячи которые необходимо для томская lgb конфигурация сервера которого использовал то есть я использовал два сервера первый сервер это было 22 января в машина была виртуальная машина достаточно маленькая с 20 процессоров 16 гигабайт оперативной памяти настроил я ныне под grease поставил после здесь 8 персон с тем было debian файла система xfs у нас правилам минимальные настройки для того чтобы использовать именно эту базу данных но за вычетом того что будет использовать сам zabbix то есть на этом на этой же машине стоял самих сервер мозга низкой и нагрузочные агенты то есть я использовал 50 активных агентов которые все которые используют молодую модуль чтобы очень быстро генерировать различные результаты то есть этого места генерировали числа строки и так далее то есть я забивал базу данных большим количеством данных то есть изначально конфигурация будет содержала 5 тысяч элементов данных на каждый хост и примерно каждый элемент данных содержал триггер то есть для того чтобы это был реальный сетап то есть иногда даже больше требуется триггеров чем один для использования интервал обновления соответственно самом саму нагрузку я регулирую тем способом что на самом деле не только 50 агентов использовал я добавлял еще и нагрузку регулировал с помощью элементов данных динамически и снижал отдать интервал до 4 секунд первый сет апу на первый запуск на чистом поле сквозь в десятом на этом железе то есть 35 тысяч значений в секунду в целом как видно на экране вставка данных занимает фракции секунды все достаточно хорошо и быстро то есть там вы создали ски 200 гигабайт но единственно что то есть и гигабайт достаточно быстро заполняется то есть вот будут дальше достаточно много таких графиков это стандартный даже борт производительности zabbix сервер первый график там количество значений в секунду вот голубой голубой вот это значение количества значений в секунду 35000 в данном случае эта загрузка вот процессов сборки а это загрузка именно внутренних процессов то есть это history синкер и и housekeeper который вот здесь выполнялся достаточное время остальные фактически вот этот график показывает валу кэш используя несколько хитов валы кэш для триггеров творчество несколько тысяч значений в секунду но остальные графики и наверно важный график еще 4 который показывает использование history тише которого про который рассказал который является скажем таким буфером перед вставка в базу данных дальше увеличил нагрузку до 50000 значение в секунду на этом же железе при загрузке house кипром появились уже вставка занимала то есть 10000 значений записывалась две-три секунды и так далее с вычислением что собственно показывает на следующем экране что housekeeper уже начинает мешать работе но в целом загрузка трапперов и сестры тинкеров пока еще является находится на уровне 60 процентов то есть вот третий график обратите внимание и history кашу же начинает во время работы и housekeeper a history кришна начинает достаточно активно заполняться то есть он был около пол гигабайта заполнялся на 20 процентов дальше увеличил до 80 значений 80000 значений в секунду то есть это было 400000 примера элементов данных 280000 триггеров и вставка уже как видите по загрузке history singer of их там было 30 штук было уже достаточно высокая даже увеличивал различные параметры там history синкера увеличил кэш и различное чтобы это все умещать но но на данном железе то есть вы видите уже загрузка history's тинкеров начала увеличиваться до максимума практически в полку и соответственно history кэш пошел очень высокую загрузку я обнаружу все это время конечно наблюдал за всеми параметрами системы то есть как процессор используется оперативная память и обнаружил что через ация дисков было максимально то есть я добился максимально возможным на этом железе на этой виртуальной машине возможности этого диска то есть в пожгли сначал с при такой интенсивности сбрасывать данные достаточно активно и соответственно диск уже не успевал на запись и чтение так далее я взял другой сервер который уже имел 48 процессоров 128 мегабайт оперативной памяти также я его знать у него поставил history синкер 60 штук и уже добился приемлемого быстродействия то есть фактически мы не в полки но есть уже наверное это предел производительности я уже необходимо что-то с этим предпринимать главная задача у меня была использовать томске l2 то есть вот видно на графике на каждом графики виден провал этот провал как раз миграция данных и после этого zabbix сервер профиль загрузки из трясин киров как вы видите очень сильно изменился то есть практически в три раза позволяет быстрее вставлять данные и использовать меньший history кыш соответственно вас своевременно будут поставляться данные но даже как говорю 80000 значений в секунду это достаточно большой рейд ну конечно не для яндекса но в целом это достаточно большой сетап который с одним сервером то есть понятно что этот тест дальше я увеличил значение как количество элементов данного до полумиллиона получил расчетный значение в секунду 125000 и получил такие графики то есть в принципе я там рабочий сетап он может достаточно длительное время работать но так как у меня было всего полтора терабайта диск то в принципе я его выбирал за за пару дней гипертонию причем что сама тоже важно наверное это что в это же время создавались партиции новые томский гибели это было для производительности совершенно незаметно что не скажешь там для каких ничем а сколько создается обычно портится сдают ночью потому что это блокирует вообще вставку и блокирует работа с таблицами это может экране создавать деградацию сервисов в данном случае этого нет то есть главная задача была проверить возможности томский олди бен и получила такую цифру 120000 значение в секунду также есть комменте примеры то есть множество минут один график я хочу вам показать а там тоже человек включил там скилл биби и у него загрузка по видите по использование и white упала на процессоре и использование внутренних элементов внутренних процессов тоже снизилась благодаря включению там сказал baby причем это обычные блины и диски то есть обычно виртуалка на обычных дисках не ssd то есть для каких-то сетапов для маленьких которые упирается в производительность диска томске ole db как мне кажется очень хорошее решение которое позволит неплохо продолжать работать до того как мигрировать на более быстрое атом железа для маза данных приглашаю вас всех на наши события то есть конференция в москве саммит в риге осенью используйте наши каналы telegram форум rc если у вас есть какие то вопросы приходить к нам на в стойку мы можем поговорить обо всем спасибо и андрей спасибо большое у меня для тебя официальная благодарность от оргкомитета от программного комитета за твой рассказ пусть и и даже подарок у нас еще есть для каждого кто выступает имейте ввиду спасибо а и исчез твоя задача будет выбрать лучший вопрос задавайте вопросы первый ряд как всегда выигрывает следующий поднимите руку кто хочешь сказать спасибо за доклад у меня вопрос если time steel тебе так просто на стройке и он ну дает такой прирост производительности возможно это стоит использовать как ну лучшую практику настройки zabbix а с возрастом и если какие-то подводные камни и минусы этого решения или все-таки если я решил себе сделать запись я могу спокойно брать после вставить туда time steel сразу и пользоваться и не думать ни о каких проблемах и так далее да и я наверное бы сказал что это хорошая рекомендация использовать под grease и сразу с расширяем time scale baby как я уже говорил множество хороших отзывов несмотря на то что пометка есть экспериментально фича но на самом деле тесты показывают что это отличное решение томске алгебре я думал что она будет развиваться и и мы соответственно будем мы следим за тем как решение развивается и соответственно будем править то что нужно то есть мы даже во время разработки опирались на одну его их известного фичу то есть там можно было с чулками немножко по-другому работать но потом они это в следующем релизе выпили лень и нам пришлось также изменить этот не операцию уже на этот код поэтому и да я я бы рекомендовал на многих сетапах использовать но если вы используете моя сколь то в принципе а также какие сетапы вас интересует то до средних сетапа вполне любое решение неплохо работает спасибо вот я вижу у нас вопрос от докладчику который прежде выступал и еще будет первым рядом спасибо за доклад на последних графиках которые от коммьюнити там был график с хаос кипером если я не ошибаюсь и он продукт да вот этот oll он продолжил работать что в случае с тем скилл baby onda он делает housekeeper skipper я сейчас не могу точно сказать для сегодня посмотрел код и скажу более подробному он использует запросы на там сказал любит для не для удлинил для удаления чанков я думаю что что то как то агрегирует удаляю то есть я сейчас пока нам не готов на ответить на этот вид один технический вопрос их один раз новым спасибо на стенде тогда сегодня или завтра . спасибо за доклад а у меня на самом деле был похожий вопрос про производительностью именно операции удаления в time scale тебе приходите завтра в иркутском 10 часов на мой доклад протеанский эллис расскажу и я могу помочь этот вопрос суть в том что когда вы удаляете данные из таблицы и если вы это делаете через делит то вам само собой нужно пройтись по таблице и удалить почистить память и все на вакуум будущее так далее в time steel дебита как вы имеете чанки то вы можете их дропать то есть грубо говоря вы просто говорите файлу который лежит там в пиджи да то удались ну и рымарев грубо говоря и and help росту понимать что такого чанка больше нет и так как он интегрируется в планировщик запроса он на руках ловит ваши условия в селекции там или в других операциях и сразу понимают что но этого чанка больше нет я туда больше не пойду то есть данные отсутствуют вот и все то есть это просто скан таблица заменяется на удалении файла бинарного поэтому это быстро отфильтруйте рымарев не надо и джон оттуда еще вопросы она файла repens спасибо за доклад мне вопрос такой уже затрагивали тему низкий и в принципе насколько понимаю записку не очень нужно модифицировать именно данные все это что-то вроде logo можно ли использовать это какие-нибудь более специализированные базы данных которые не могут менять свои данные но при этом скажем гораздо быстрее сохраняет а накапливают и отдает типа ну и house допустим или не знаю очередь кафка образная то есть кафка это же тоже как бы log можно ли как то из-за intrepid за ценить пировать ну в целом выгрузку можно сделать у нас во первых есть определенная сейчас версии 34 вы можете писать файл и все исторические данные винты все прочее и дальше каким-нибудь обработчиком отсылать в любую другую база данных то есть на самом деле это много кто переделывает пишет напрямую сразу в какой не базу данных то есть там на лету history синкер и это все пишут файлы гарантируют эти файлы и так далее то есть вы можете и это перекидывать cliff house я думаю что не могу конечно сказать что о планах каких-то но возможно даже дальнейшая поддержка других но искали решение таких как ли house или еще что-то будет продолжаться вообще можно полностью избавиться от пользоваться получателем ну фактически ну конечно самая сложная часть в записи это с исторические таблицы то есть которые может создают проблемы и события конечно то есть в этом случае если вы не будете хранить долго события и будет хранить в каком-то другом в быстром хранилище историю с трендами то в целом я думаю никаких проблем не будет можете оценить сколько быстрее все будет работать если перейти так ли house допустим я не знаю я честно говоря тестировать не тестировал я думаю что например на как минимум тех же цифр можно будет достичь достаточно просто учитывая что crack house имеет тайской интерфейс но не могу сказать однозначно уже в лучше протестировать все зависит опять же от конфигурации то есть сколько у вас состав и так далее то есть как это все будет как как бы то ставка это одно но нужно еще забрать все данные то есть сарафана или еще чем-то то есть это все может калечить это равной борьбе стали они о большом преимуществе вот этих быстро баз данных ну я думаю что когда за интегрируем будет более точно это stm андреева что он прям как запрос на еще тестирование правительстве с другими брендами дают нам есть еще вопросы да на первом ряду и знаю наверно немножко дополнен предыдущий а такой вот вопрос а куда делся старой доброй рады что заставило перейти на escape база данных правда нет зато ты все по моему граждане когда ну может очень в италию в древней персии был то есть всегда были вот эти школьные базы классический подход я слайд убрал классический подход этом sql пузырь искали очень давно существует у нас общие такое скажем интерфейс для сколь баз данных и роддома практически никогда не использовали а сейчас-то а тут туда же ну возьми микрофон там вы с начесом не путаете по моему nagios и был rrd карл священные тоже можно чем акте ну да вот я тоже 18 о работы с алексом и не помню там никакого рода чтобы отдать должное ради над сказать что норрис плюс плюс мая приезжал то ли эти горы не рассказывал каком уровне поживает ног автор и создатель этого дела посмотрите записи доклад какие вопросы еще докладчику андрей у тебя есть еще одна задача выбрать лучше вопрос из тех что прозвучали давайте про клик house про клин house ходи сюда автор расскажи пожалуйста как тебя звать где-то работаешь и почему для тебя так было важно узнать про новый стиль здравствуйте меня зовут репин файла я работаю сбербанке принципе я работаю там скажем на легаси проекте но меня уже несколько лет интересуют всякие наиболее продвинутые решение по большой нагрузке и микро сервисы и прочие поэтому очень сильно интересуется всеми инструментами которые работают быстро так кафка и легли house потому что они очень интересными свойствами файлов оперирует что позволяет все писать быстро и читать спасибо за ваш вопрос спасибо большой настоящий интерес это находит свою награду"
}