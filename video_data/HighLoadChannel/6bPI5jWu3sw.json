{
  "video_id": "6bPI5jWu3sw",
  "channel": "HighLoadChannel",
  "title": "Высокопроизводительная графовая база данных на основе Couchbase / Дмитрий Леванов (Яндекс)",
  "views": 4400,
  "duration": 3028,
  "published": "2019-01-14T00:10:10-08:00",
  "text": "меня зовут не я хочу вам рассказать мы делали высоко производитель графу базу данных на основе коуч бейяза я разработчик в сервисе крипто это такой сервис про которые раньше все думали что мы занимаемся криптографией теперь все думают что мы делаем криптовалют on но ни то ни другое не правда на самом деле крипто это такой внутренний сервис который отвечает на вопрос кто то есть по поведению пользователя в интернете определяют его характеристики пол возраст уровень дохода интересы и так далее потом эти данные используются естественно для таргетинга рекламы план доклада сначала я расскажу немного про то какую задачу вообще мы хотели решить потом обсудим как мы выбирали базу данных почему именно взяли коуч bass и не какую-то другую затем расскажу как мы придумали хранить граф внутри коуч бейяза который для этого общем-то не предназначен изначально ну и в конце наверно самая интересная часть это проблема масштаба с которыми мы столкнулись и как мы их лечили окей как вообще работает реклама в интернете чтобы что-то узнать про пользователя надо просмотреть какую-то историю его действие например на какие сайты он заходил что покупал по каким ссылкам кликал что искала так далее но индекс какой любой другой робот не видит пользователя как не знаю номер паспорта или фотографию мы видим пользователей как набор идентификаторов идентификатор браузер этом какая-то кука идентификатор устройства не секатор приложения может быть логин на самом деле таких идентификаторов очень много и история копится именно по этим идентификатором тем не менее обычно у людей больше чем один браузер больше чем один девайс и хотелось бы как-то уметь объединять устройство различные индикаторы всю эту историю для одного пользователя вместе тогда мы можем слить историю получить более полный профиль пользователя и потом с использованию этого профиля показать ему релевантную рекламу вот собственно один из проектов крипто которым мы занимаемся это склейка как раз процесс который различными эвристическим и вероятностными там мощные ленин голыми средствами пытаются понять что различные идентификатором принадлежат одному пользователю ну например там самое простое вы залогинились под своим логином на двух разных браузерах мы поняли что это один человек разных правил очень много кучи эвристик это все довольно сложно в общем некоторым образом мы умеем варить вот эти графы пользователей то есть гров это набор идентификатора в качестве вершины и рёбра это связи между этими вершины ну например факт что вы залогинились под одним логином это может быть ребро и собственно когда мы хотим показать рекламу обычно к нам приходит какой-то один идентификатор или пары идентификаторов например мы хотим показать рекламу в приложении и к нам приходят индикатор приложений индификатор девайса чаще всего что нам нужно сделать в этот момент нам нужно сходить нашу базу найти граф пользователя в которые попадают один индикатор найти граф пользователя в который впадает другой день секатор если это разные графы а мы уверены что идентификатор и про одного пользователя этому можем их прямо сейчас онлайн не склеить и возвращаем вот этот большой граф тому кто у нас его запросил ну там это некоторый рекламный движок который потом возьмет историю по всему графу и из мер получает агрегированные профили покажет рекламу обычно когда вы заходите на сайт и реклама тому же есть вы ждете пока ну там загрузится это потому что реклама должна работать очень быстро чтобы успели посмотреть до того как посмотрите что-то полезное вообще весь процесс показа рекламы от там первого запроса до того как пользователь видит рекламу должен занимать до 100 миллисекунд в идеале и на вот эту часть которая достает граф остается там примерно 50 секунд потому что весь процесс очень большой сложный нам остается всего лишь 50 секунд это 99 процентили и как вы понимаете в рекламной сети яндекса довольно много запросов на показ рекламы то есть это при мир на 500 крп с который мы должны держать почти на каждый запрос рекламы дергается наш сервис плюс еще есть несколько кейсов когда он нужен мы должны отвечать девяносто девяти процентов случаев быстрее чем за пять миллисекунд и нам нужно хранить примерно 4 миллиарда идентификаторов нашей базе это все довольно много как мне кажется для того чтобы это сделать нам нужно использовать довольно большие ресурсы во первых для того чтобы иметь возможность быстро ответить нашим потребителям мы должны ставить инсталляцией нашего сервиса в тех же дата-центрах где стоят потребителя потому что там за 5 миллисекунд или даже до 10 сходить в какой-то удаленный дата-центр простите просто невозможно поэтому нам нужно стоять в 5 дата-центрах в каждом дата-центре нам нужно иметь полную реплику данных это вот нам получается нужно 10 терабайт оперативной памяти и все это вместе обслуживает примерно 250 серверов больших толстых машинок с 128 или 256 гигабайт оперативной памяти зависимости от модели хорошо вот мы решили сделать такой сервис такую как бы базу в которой можно искать графы по вершинам нужно выбрать технологию на основе которой мы это будем делать но поскольку нам нужно отвечать за 5 миллисекунд это не только один запрос базу несколько запросов в общем случае плюс какая-то логика понятна что нам нужны какие-то базы которые держат все в памяти потому что почитать с диска за такое время мы просто не успеем начинался проект там где-то на рубеже 2013 и 2014 годов и тогда у нас были еще дополнительные требования вот про которые забыл сказать наши стандарты отказоустойчивости требует чтобы мы могли переживать отказ одной машинки в дата-центре ну потому что когда у вас есть несколько сот серверов что-нибудь постоянно ломается просто по теории вероятности и еще иногда происходят разные проблемы с дата центрами целиком excavators перекапывают оптоволоконные кабеля и знают плеча случается отказа электричество какие-нибудь масштабные на пол страны мы должны иметь переживать то есть -1 машинка в dc или -1 дата-центр целиком как вы понимаете показа рекламы происходит все таки довольно часто гораздо чаще чем ситуации когда пользователь покупает себе новый телефон или там ставить новое приложение и защищают cookies в браузере поэтому все-таки большая часть запросов у нас на чтение то 97 процентов на чтение против трех процентов на запись и так был 2014 год мы стали смотреть на от того какие in memory базы данных бывают вообще мы рассмотрели несколько вариантов основных наиболее популярных тогда ну тарантул тогда честно говоря не был популярным он был в каком состоянии не знаю бед и используйте его в продакшене было страшно поэтому его сразу отвели редис очень хорошие быстрый но у него есть существенная проблема он не умеет в репликацию между дата центрами по крайней мере тогда не умел нужно было это делать как-то руками сейчас какой-то touring для этого появился но все равно это не нативной репликации нужно как-то приседать это может сломаться отдельно общей не хотела заморачиваться кассандре коуч bass в принципе довольно близки по своим характеристикам и в интернете есть много бенчмарках где побеждает один и другой поэтому я тут никакие будешь марки не показываю можете найти какой вам нравится если он нужно обосновать какой-то точка зрения на наши нагрузки лучше был к уж bass и мы его и выбрали так скажите кто когда-нибудь пользовался коуч без вообще слышал про такую базу данных довольно много людей отлично но для остального полпроцента аудитории которые никогда не слышали я расскажу вкратце что это такое это такая на узкий аль база данных по сути это большой key value сторож вообще коуч bass от дальнейшее развитие memcache то memcache что-то такой распределенные 100 дема просто в памяти коуч bass это memcache плюс репликация внутри дата-центра плюс репликации между date in центрами еще там куча всякой полезной обвязки в общем случае коуч bass хранит документы которые имеют ключ ключ это какая-то произвольность строка длиной до 200 56 и байт а значением и может быть одно из двух или это джейсон документ который каждый сумеет там как-то парсить и потом по нему можно искать или можно сделать просто блок если вы не хотите использовать json документы в ковш бы езде нету транзакции в чистом виде но там весь механизм comparing своп который позволяет вам ну более-менее транзакции он давно взять записи скажем так к вич bass поддерживает автоматическое автоматически expiration документов и может и устроить тель например там неделю если за документом не будет ходить неделю он удалится автоматически то очень удобная фича каждый сумеет в репликацию внутри кластера и в репликации между кластерами коуч бейяза причем она работает довольно хорошо если у вас там упадет машинка он не сотрет crosse bc репликации все данные которые не были в остальных мастерах и там будет ждать пока она поднимется потом налил в него данные соседнего класть совсем работает все круто там есть вторичные индексы даже несколько видов есть какой-то простейший мапри deus на java скрипте который можно писать есть из quelle подобный язык и что очень важно там есть отличная rest api все что можно сделать через в морду коуч бэйза можно сделать через rest api мы просто потому что вам морда через растопи и работает это довольно важный факт который нам потом пригодится ok вот мы выбрали базу данных теперь нам нужно как-то туда граф запихать вообще существует довольно много вариантов как можно представить граф в памяти этому не в базе как хотите но нам нужно было учесть некоторые требования самое главное что мы хотим это чтобы мы могли довольно быстро то есть за минимальное количество запросов к базе доставить целый граф по вершине второе что нам нужно это как я показывал иногда мы хотим прям в онлайне объединять графы и нам нужно делать это быстро и удобно и третье поскольку мы упираемся в оперативную память и нам нужно чтобы все данные влазили оперативную память нам нужно какое-то представление которое будет по возможности компактным ну какие есть варианты там классических матрицы смежности можно там список ребер хранить потом их там joy нить много запросов ну или можно сделать что-то свое свое делать всегда веселее особенно если он еще лучше работает поэтому мы придумали такое представление мы храним граф как два списка первый список это список вершин просто список идентификаторов второй список это список ребер каждый ребро это пара яндекс и вершин который нас соединяет вот здесь полный граф из трех вершин думаю понятно в чем фишка такого представления допустим нас есть еще один граф тоже полный граф но из двух вершин и мы хотим их объединить на лету чтобы это сделать нам достаточно провести довольно простую операцию нам нужно взять все вершины старого графа и скопировать их в список вершин 1 графа в конец и тоже самое с ребрами теперь нам нужно немножко подправить ребра которые приехали старого графа нам нужно просто к ним всем добавить количество вершин в исходном график первым и у нас получается объединенный граф склеенный см это очень круто и быстро работает то что вы можете там куски память копировать и вам не нужно там по одному элементу когда сложную структуру вставлять отлично вот мы научились один граф как-то хранить и на теперь еще нужно уметь его искать как и говорил в комбезе есть вторичные индексы но во первых они работают все таки медленнее чем поиск по первичному ключу во вторых они работают только для джейсон документов для блогов не работают в третьих нужно чтобы у вас там была какая-то структура желательно похоже на дерево чтобы было проще пони построить индекс но самое плохое что они медленно работает так что мы решили не использовать а просто руками сделать псевдо индекс у нас и записи двух типов первая запись запись первого типа это ключ идентификатор графа значение сам граф записи 2 типа такой как бы яндекс это ключ от один диктатор а значение этот индикатор графов тогда по идентификатору мы можем за два обращение к базу достать граф всегда хорошо теперь перейдем к проблемам масштаба с которой мы столкнулись но для того чтобы обсуждать проблему масштаба нужно сначала рассказать про то как как выглядит наша инсталляции мы взяли в каждом дата-центре развернули по кластеру коуч bass включили в них репликацию с фактором 2 то есть каждый кластер у нас есть мастеркопия реплика на этих же машинках на которой стоит к у тебя есть мы развернули наш сервис но наш сервис это не просто там что то что ходит базу это еще довольно там развесистая логика который имеет в онлайне клеить графы некоторым оптимальным образом искать когда вам передали много идентификаторов нам нужно много графов достать логика который умеет заливать граф это же там некоторыми противоречивым и более-менее быстрым способом поставили сервис на те же ошибки где стоит коуч bass на самом деле не обязательно не на те же машинки это не так важно просто коуч без у нас упирается в память сервис упирается в циpкa и мы их так здорово скомпоновали следующим шагом нам нужно было настроить crosse bc репликацию гораздо с и репликацию можно сделать разными способами можно там сделать куни звезду можно сделать полный граф мы попробовали разные топологии пришли к выводу что лучше всего работает репликация по кольцу причем мы взяли такое кольцо у которого суммарная сетевой watenshi минимальный и теперь нам нужно еще чтобы пользователи как-то ходили в наш сервис такой классный распределенный для этого мы поставили перед ним балансер причем балансе у нас конечно умный он всегда отправляет пользователя в ближайший дата-центр от него если какой-то дата-центр ломается по весь трафик уходит другой ближайший дата-центр если ломается машинка тут опять же в нее трафике перестает идти идет другие машинки в общем наверное как обычно бывает балансиры все просто работала так ну и напомню что это 250 машинок примерно 10 терабайт памяти 4 миллиарда документов чтобы вы понимали средний вопрос на форуме поддержки к убей звучит как-то так я сделал amazon клаудии сервер из 4 узлов я там 25 тысяч документов все тормозит помогите так что с нашими проблемами туда было даже бессмысленно обращаться никто кажется не пробовал сделать такой большой кластер коуч бы за ну и есть единичные примеры в больших компаниях но в целом кажется он не задумывался чтобы настолько масштабироваться и первая проблема с которой мы столкнулись когда у нас был о том что то в районе 12 машина в каждом кластере и какой-то неприлично маленький по нашим меркам рпс это мы положили все данные в память ходим туда запрос амина чтения и внезапно у нас все упирается в диск диск уходит в полку и непонятно почему мы делаем только чтение напомню никакой записи оказалась проблема в следующем в к уж базе есть там два типа таблице они называются bucket и чем раньше был только один тип по сути не считают одним кажется это legacy это близ который не буду рассматривать коуч bass bucket он устроен так что на каждое изменение которое вы делаете в боккетти он сливает его на диск ну на всякий случай вдруг у вас там сервис кучей за упадет тогда можно будет его или стартовать он с диска все прочитает и будет дальше работать но во первых при наших объемах данных чтение с диска обратно в памяти длится так долго что терпеть нельзя и нам это было не очень нужна а во-вторых самая неприятная не очевидная особенность что если вы устанавливаете то тельно записи то на каждые чтение коуч bass должен запомнить о за этой записью входили мне нужно продлить tt линию и это тоже как бы right то есть ваш fps на чтение райан рпс у на запись и внезапно вы долбите себе диск и все начинает тормозить наверное это не проявляется когда вас не очень большой рпс как ты люди в целом не жалуются но нам пришлось с этим бороться что мы сделали мы сделали собственную поддержку от отеля мы стали писать таймс темп когда запись будет просрочена прямо в документ этом сверху повесили некоторую логику которая зависимости от того как скоро заканчивается отель либо я реально продлевает записи срок жизни либо там просто читает и не продлевать отель и даже после этого это все на заработала только на ssd причем не на всех и создана хороших ssd на некоторых ssd все равно тормозило например диски от самсунга некоторые нас работали недостаточно хорошо и при этом коуч без грузила ssd очень сильно не у нас все время были нагружен там процентов на 40 и быстро выходили из строя за два года мы уничтожили примерно там 150 дисков ssd дорогущих серверных у нас была такая котельная которому топили ssd дисками чтобы она работала потом вышел коуч bass 45 в котором кое что пофиксили и он стал меньше насилуя диск но все равно и в общем это нам не очень нравилась и к счастью совсем недавно в 5 версии коуч бэйза появился новый тип пакетов и эфемерные bucket и это то же самое что коучи бы из bucket поклон на диске ничего не пишет все данные в памяти на диск ничего не сен каяться что произойдет если вас кончится память логичный вопрос будет очень плохо там есть два варианта которые вы можете выбрать либо новой записи не будет записываться либо будет удаляться самые старые ничего из этого нам не подходит так что мы просто следим чтобы память не кончалось и все работает отлично использование диска ушло практически в ноль это очень круто потому что теперь мы можем затащить нашу инсталляцию в облака какие-нибудь то что обычно в облаках изоляция по диску плохая если ваш сервис требовательных диску то он там начнет сразу тормозить ok следующая проблема построили новый дата-центр классный современный там поставили свои инсталляции наши потребители и нам нужно было тоже развернуть свой сервис там один недостаток в этом дата-центре и пиво 6 он для сеть то есть там вообще не той пиво 4 адресов в культ базе вообще нет поддержки а пиво 6 мы пытались с различными шантажом угрозами заставить админа все таки нам сделать как-то city u4 там и знаки над поднять они сопротивлялись в общем наверное были правы нам пришлось как-то с этим жить к счастью коуч bass это опыт собственная система она исходный код под лицензией apache 2 0 довольно свободный значит можно взять исходите их поправить сожалению авторы да да сделали не знаю некоторых защиту от и лицензионного копирования они написали полы наноси половины ирландии вот разработчиков на эрланге вообще не очень много и похоже они все работают уже в коуч bay wing инкорпорейтед но нам все-таки удалось пропатчить к вич bass так чтобы он как-то работал цепи в 6 то была версия ты 302 по моему потом вышла версия 45 которой поправили много багов и нам нужно было ее пропатчить тоже но видимо как-то в комбезе узнали о том что где-то русские про пачелли к вич bass они добавили степень защиты они переписали еще половину нога теперь она была почти ирландские г то есть понимаете что там недостаточно просто поправить код надо еще как-то пересобрать там шланг пересобрать год чтобы он тоже сам умел вцепившись работать но нам это тоже удалось недавно вышел 5 коуч bass в котором есть как раз эфемерные baked и теперь видимо уже из отчаянии они стали выносить часть кода в приватной репозитории нам пришлось струна немного про почти дописать код но она все еще работает на самом деле какая-то поддержка ipv6 ковать базе сейчас появляется она есть в исходных кодах там ее нет пока в бинарных собранных пакетах но что-то они там сделали правда я так все как бы в enterprise версии поэтому если вы хотите это из исходников собрать вам придется немного приседать вот но нам это удалось и все в итоге заработала поехали дальше я говорил что у нас примерно 4 миллиарда идентификаторов хранится на самом деле это не какая-то константа пользователи постоянно там чистят cookies не знаю покупает новые телефоны зачем ты в общем рождается куча новых идентификаторов постоянно и вопрос сколько их у нас хранится в базе это только вопрос отелей каких-то политик парту хания и задач которые мы хотим решить и вот в какой-то момент у нас там появилось несколько новых задач и нам пришлось хранить больше идентификаторов их количество выросло из четырех миллиардов до 7 и внезапно стал оказывается что память у нас остается не так уж много мы конечно захотели купить еще немного серверов но нам это сделать не дали и пришлось решать проблему как-то softwear на что мы придумали мы посмотрели что у нас принципе сейчас там на тот момент лотность и был довольно низкий около там 3 миллисекунд из 5 то есть у нас был довольно большой запас по производительности и тогда мы решили взять просто наши документы которые хранились джейсоне их там закинуть про табу и пожать сверху z либо про the buff это на самом деле неважно можно как угодно главное за хлебом пожать в итоге мы потеряли полмиллисекунды на декомпрессии при чтении но зато выиграли 30 процентов оперативной памятью мы решили что-то неплохо и так и оставили это в продакшн ok вот у нас есть большая инсталляция в нескольких дата-центрах там много серверов постоянно происходят какие-то непредвиденные ситуации и если никакой автоматику не делать то вы будете просто каждую ночь получать звонок мониторинга вставать недовольно ворчит и включать ноутбук чтобы все починить мы так пожили какое то время но про каждого очень конечно немного преувеличил ну каждую неделю и решили что нам нужно все таки как то все автоматизировать что умеет коуч bass плане отказоустойчивости он умеет поддерживать реплики и ещё там есть такая функция кто называется авто failover если какая-то надо перестает отвечать только уж bass и и отстреливает все больше он ничего не делает говорит ой тут нужность что то сделаете ручное вмешательство требуется с тех пор как у вас отстрелялась но да у вас данные также хорошо читаются но часть данных у вас больше не реплицировали поскольку реплики потерялись для них и если упадет второй сервер кто вас потеряется данные и вторая проблема у вас данные становится распределены неравномерно по нодам что тоже не очень хорошо с точки зрения производительности поэтому мы сделали с помощью как раз rest api дополнительный векторы сервис который опрашивает все кластер аккаунт пэйза спрашивает какие серверы сейчас уже есть кластер и смотрят что все серверы уже в кластер если какой-то сломался то он его удаляет из кластер и если какой-то починился тон его возвращает кластер запускает перебалансировку если требует требуется тут нужно сказать что у нас в яндексе есть тоже сервис общей инфраструктурной который умеет определять что железной машинки плохо себя чувствуют их пытаться починить автоматически то есть он следит за пинками если пинге не идут по автоматика пытается как то отремонтировать сервер сначала пытается его перезагрузить если это не помогает питается опере налить если и это не помогает тогда там запускается более глубокий тест железо если он выявляет проблемы призываются в ticket реальные админы которые сне дата-центрах они идут там крутят гаечными ключами и отвертками сервер он начинает работать он автоматически подхватывается дальше этим сервисом и снова пингуется вот нам же нужно увидеть что он начал пинга ваться его подхватить вернуть обратно в кластер запустить перебалансировку вот мы это все сделали и она как-то работает очень даже хорошо еще одна интересная ситуация которая нас произошла когда у нас стало там около 30 серверов каждом кластере мы столкнулись интересной проблемой мы стали видеть что один из серверов до цен в каждом дата-центре начал тормозить в коуч базе есть графики которые можно смотреть там рисуется разные метрики количество документов там количество запросов на чтение на запись очереди в диск мы открыли эти графики стали в них смотреть в общем очень долго смотрели пытаясь найти какие-то аномалии ничего особенно видно не было кроме того что одна из нас тормозит и что на эту моду приходит довольно большой трафик никакого подозрительного трафика различных источников трафика на этой ноги не было только connect и с другими модами там и с клиентами ничего такого общем в итоге потом пришло озарение мы решили попробовать закрыть эти графики и машинки перестали тормозить что произошло в морда коуч и рисует графики каждую секунду их пытается обновлять и каждую секунду она с каждой ноты кластер а вот помаду на которой сейчас открытого морда собирает метрики метрик там довольно много но тоже много и она просто забиваешь сетевой канал тратится пу в кучу и начинает реально тормозить наверное опять же никто не пытался никогда сделать такой большой кластер и потестить как там будет работать графики насколько быстро вот был у этих графиков на самом деле и другие проблемы кроме того что они тормозят супер во первых если вы переустанавливайте полностью кластер то вас все данные теряются а вы наверное хотите иметь историю там за год за два года назад как у вас был размер базы и так далее и вторая проблема графики там сделан довольно плохо честно говоря то мне неудобно масштабируется общем пользоваться ими по большому счету невозможно поэтому мы решили их никогда больше не открывать и вместо этого через растопи и стали сами доставать регулярно эти метрики и отгружать их графит потом смотреть в графа не в красивых дашбордов с историей за ограниченное время помимо каких-то оперативных мониторингов и графиков бывает полезно смотреть на аналитику если у вас маленькая база то наверно вы там можете все по selected что-то посчитать когда база большая нужно каким-то образом данные уметь агрегировать считать например сколько у нас каких идентификаторов там какое распределение размеров графов и делать какие-то там выводы надо там самый борщи графу удалите какие есть варианты ну первое что пришло в голову это использовать коуч bass views это как раз тот механизм apple deus вы можете построить там view описав map на java скрипте и применив там один из фиксированных радиусов он там каунт сумму и еще один 100 тн общем они не очень полезны и можно только количество считать по большому счету или сулу ну и кроме того если у вас блог по сжато и z либо то вы можете посчитать какую-то аналитику по ключам наверное можно попытаться как-то затащить реализацию зад либо в java script но и даже не хочу пытаться это делать поэтому мы решили пойти другим путем в комплекте сквозь бальзам есть специальная утилита которая позволяет делать бэкапы базы она подключается в кластер как еще одна реплика как будто бы работаете те же механизмы через которые реплики синхронизируются внутри кластер и удивительным образом она не тормозит вообще не влияет на производительность кластер и и за конечное время позволяет с дам 5 все данные на диск формате и склей light дальше мы берем эти таблички их закидываем в нашем определюсь индекса вы и там уже можем считать какой угодно аналитику любой сложности ну а коуч бы иисус мы удалили я еще освободили куча ресурсов потому что они тормозили что на каждую запись к действию должен как-то обновиться так но это были проблемы масштаба как бы величину а есть еще другие проблемы масштаба про которые обычно не думают когда хотят сделать что-то большое и быстро и это проблема масштаба как бы в меньшую сторону когда у вас есть какое-то большая определенная система вы хотите ее как-то тестировать чтобы она работала и обычно поднятием что-то большое распределенное локально или там как-то еще в ограниченном окружении это довольно сложно сложный процесс который там тратит время и вообще чаще всего просто берут делать куни тестовый стенд и его использует но использовать тестовый стенд в тестах это не очень удобно во-первых удобно иногда ходить нам локально что-то делать во вторых у вас нету изоляции между тестами они могут как то пересечься случайно вот поэтому удобно когда вы можете свою большую распределенную систему поднять нам какой-то маленькой версии и вот с кучей за мы нашим сервисом так можно сделать поскольку у нас есть там вся обвязка который умеет управлять коуч бальзам его артисты жевать мы можем также автоматически поднять одну ногу к вич бейяза на одной машинки например локальный ее настроить запустить наш сервис это все занимает 10 секунд буквально и дальше можно работать там все работает как в большой инсталляции более того можно поднять даже ни одной машинки тома меньше чем родной машинки в контейнере и загонять там 10 тестов параллельно мы так и делаем нас есть интеграционные тесты которые запускаются в контейнерах там поднимается полностью как бы наш стенд и он не отличим от большого кроме того что там меньше данных залитом так ну и напоследок немного про и технические скорее такие административные меры которые позволяют нам вот иметь много железа много сервисов и чтобы она не ломалась 24 на 7 вообще за тут сколько сервис живет ни разу не было чтобы он полностью был недоступен иногда естественно выключается какие-то локации на чтобы сервис полностью перестал отвечать такого не было ни разу в общем если у вас долго ничего не ломается это плохо почему но прежде всего потому что люди которые должны чинить проблемы они теряют квалификацию забывает как чинить его там на ниле новых людей ничего не ломалось на их памяти они не знают что делать когда все взорвалось во вторых ломаются не только люди но и роботы то есть у вас падает база у вас есть бэкапы но оказывается что автоматика которая должна backup накатывать она уже там по версиям разъехалась основной базой и она бы копы не может поднять и там скрипты которые есть у дежурных они тоже уже немного устарели и они не работают и там нужно еще конфиг настроить это как раз тот момент когда вы ночью пытаетесь починить там горящий дата-центр это все очень плохо ну и кроме того накапливается проблемы коуч bass общая очень классная база но когда читаешь или снос между мажорную версиям становится страшно как она раньше вообще работала есть такие баги было не проявляется довольно редко но если у вас большая инсталляция они все-таки проявляются с некоторой регулярностью и постепенно там эти проблемы накапливаются и но может там сломаться так что чем чинить проще заново все налить ну и кроме того у нас есть требование что все сервисы должны уметь без одного дата центра и если ваш сервис работает слишком хорошо то те кто им пользуется начинает расслабляться и думать но он всегда работает мы тут не будем легко отказоустойчивость делать и когда ваш сервис ломаются они прибегают такие а мы так не договаривались потом оказывается что договаривались на уже поздно и нужно сочинить вот все чтоб так не происходило мы ввели механизм учений что мы делаем то есть каждую неделю мы берем один дата-центр полностью выключаем там сервис выключаем машинки запускаем на них тесты железо которые там смотрят что ничего не перегревается что производительность всех компонентов нас нормальная прошивает bios и там ваша сетевые карты и так далее обновлять железо делала все то что нельзя сделать на горячую на работающей машинке затем полностью перри наливается эти серверы там от состояния чистого диска до состояния что все сервиса запущены работают дальше у нас оркестрация все глостера разворачивают машинки туда добавляют включаем репликацию соседнего дата-центра наливаются данные открываем сервис для балансира все у нас все работает ну за счет этого понятно все эти проблемы которые были на следующем слайде решаются всем приходится как-то переживать то что мы все время выключаемся у нас все автоматика апдейт она все время работает все дежурят по очереди и проделывают учения могут всегда починить по памяти все что сломается окей и того как без это классный инструмент но кажется никто не проектировал его на такие большие масштабы для которых мы решили использовать тем не менее приложив достаточно и усилия и старания напильником нам удалось довести вас до такого вида когда мы смогли выполнить вот эти наши требования мы реально держим 5 миллисекунд при таких нагрузках все работает стабильно мониторинге на мне звонят вообще сервис стал одним из самых стабильных в округе все спасибо ваши вопросы а если вы делали выбор база данных сейчас заново это было бы снова коуч bass или есть какие-то лучи да конечно и слушай кандидаты у нас внутри яндекса есть свой севилью сто раз сейчас и мы будем на него переезжать следующий самый крутой в нем то что нам не надо будет его администрировать на ощупь наверное я спасибо за доклад я так понял то что там довольно таки много чего было до пелена напильником самой базу реки и ну например а пиво пиво 6 это вы пытались как-то закон трибетить обратно потому что я так понял что вы просто себе и делали форк и там допиливание обратно не кантри или да мы действительно не кантри beauty ли обратно если вы прочитаете тезисы к моему доклада там написано что что-то вроде что индекс эта компания которая обладает сложную трудно воспроизводимыми технологиями вот и поскольку наши технологии трудно воспроизводимы ну то есть там нас есть некое количество костылей который вот работают в ограниченном окружении это сделать поддержку а пиво 6 в общем виде довольно сложно гораздо сложнее чем там было как-то запилить чтобы она работала там при определенных условиях которые у нас выполняются поэтому мы не делали общее решение его обратно не кантри бить или но там мы много раз просили разработчиков кучу бизнес чтобы они это запилили так что сделали моральный кантри бьют в то что это теперь есть спасибо включите микрофон у вас там бегуночек я хотел попросить вернуться к слайду где вы объединяете графа как тык-тык какому из них да вот к этому к этим какой это серии у меня вопрос такой почему вы при объединении графов не добавляйте ребро которая собственно объединяет этих графа между собой и еще один маленький вопрос то есть много вершины этих графов по сути своей являются случайными когда пользователь зашел из какого-то интернет-кафе и если какой-то механизм удаления лишних вершин из этих граф да спасибо хороший вопрос ребром а на самом деле действительно добавляем я просто тут чтобы не усложнять его не стал дорисовывать чтобы было понятно откуда что взялось что касается случайных вершины их действительно много ощутимое количество например как в браузере там примерно 20 процентов день это cookies однодневки какой-то там интернет-кафе не знаем что открыли браузер закрыли мы применяем специальные там механизмы чтобы их хранить мало мы выставляем там сначала я маленький tt если они там в течение суток заново за ними не приходит они сгорают плюс у нас там на самом деле процедура удаления под дыхания вершина такая более сложная и плюс у нас есть главный оффлайновый процесс который как раз строит вот эту склейку у нас есть онлайн склейка которыми добавлять вот ребра между графами а есть еще оффлайн склейка которая берет большие массивы данных там мама придется их как-то мешает и получаю вот граф и она может тоже удалять случайные вершины случайные ребра и заливать к нам более правильные версии графов на при удалить куата ребро который была по ошибке сделано у кого еще вопросы есть давайте сначала твой потом вам слышно у меня вопрос тоже по структуре данных на самом деле для меня лично просто графа вы базы данных это очень горячая такая тема и цель том что вот этот пример он на самом деле очень очень упрощенной потому что карета случай когда есть в реальной жизни только узлы и отношения между ними но в реальном мире все сложнее есть некоторый метра информации уточняющие которые точнее тузлы уточняет отношений и причем очень очень глубоко детализировано у вас ведь наверняка тоже самое есть тот каким образом в это храните и причем чтобы поиск по этой детализации может быть был более быстрый когда у вас там 10 миллиардов документа все же да действительно у нас есть атрибуты у вершин и рёбер тут надо понимать как эти графы у нас используется обычно нужно по нескольким вершинам найти и графы их объединить потом сделать какой-то хитрый обход поэтому графу ну например там взять только те вершины которые склеились внутри одного девайса пони уделить профили там что-то показать какую-то рекламу вот то есть атрибуты действительно есть они там хранятся на самом деле не очень важно как это не глубокая структура просто по сути словарь привязанный каждой вершине и ребру и искать по атрибутам нам не нужно нам нужно фильтровать наш обход по атрибутам то есть мы когда граф обходим мы можем глядя на атрибуты в какие-то вершины ходите в какие-то не ходите в основном используется так поэтому проблема поиска по атрибутам кем-то глубины у нас не возникало на самом деле тут как бы проблем даже может быть очевидно и когда вы прогнозируете рекламу вы же выстраивая маршрут объединяете фактически устройство с мобильных устройств десктопов и наверняка есть какая-то корреляция типа показываемой рекламы в зависимости от устройства а это опять же атрибут который налагается на вершину ли на отношения вот это такие вещи не учитываете они учитываются но там уже на следующем уровне вот там где по идентификаторам из графа собираются профили там есть дополнительную информацию про устройство а вы дальше заглядываются но индификатор уже производит сначала выделяется графа потом покажу могильнику собирать агрегируются данные и там сортировать уже до выделяем граф обходим его выбираем подмножество графа которые нам сейчас интересно потом по каждому едешь нику из-под множество идем там другую базу и собираем ну а информацию тоже какое-нибудь значение хранитель отчета атрибутивную другой таблицы был да она хранится в другом сервисе в виде там до ключ-значение огромного map и это тоже к тебе нет это не это не кучи тебе к вич без это разные вещи вот там как раз на индекса вам key value стороны сделано это на которое вы собираетесь приходить спасибо спасибо за доклад вопрос по поводу автоматики которые я чинит сервера или точнее даже наоборот она отстреливать то есть предусмотрена защита от сценария когда будет каскадный файл то есть один сервер перестал отвечать и его пристрелили остальные серой от нагрузка поднялась кто-то снова перестал отвечать его пристрелили и так далее да некоторая защита есть во первых вот автоматика который очень от железа у нее есть ограничение например там пристрелить мне больше чем n серверов за единицу времени по например один за час мы считаем что один за час мы можем представить если 2 сломался тоже нужно ручное вмешательство то надо что то делать как раз для защиты от ситуации когда автоматика там сошла с ума или мониторинге сломались и началось все убивать ряд да и в коуч базе тоже есть защита он не отстреливает больше нот чем реплики шин фактор потому что иначе у вас может ну понятно да потеряться данные следующий вопрос а 30 процентов назад либби это за клип в классический или с предопределённым словарем как в ттп 20 я честно говоря не знаю я ничего не предопределил я взял за клип и им пожалуйста там с каким-то дефолтным и настройками я могу посмотреть код и найти какой там уровень компрессии но мы не делали специальные словари на наших данных чтобы он же лучше можно еще вопрос как он сработает кольцевая репликация в условиях того что отключайте постоянно хоть этот центр когда дата-центр отключаем репликацию в обход него запускаем мне такой вопрос по поручениям собственно ну так на первый взгляд кажется что двояко то есть эти учения можно автоматизировать то есть починку тестирования и но с другой стороны тогда потеряется фактор обучения персонала то есть где граница то есть как у вас это все происходит но вот учением и целенаправленно делаем руками там на самом деле много делается автоматикой то есть то что при реальной поломки будет делать автоматика она делается автоматикой то что нужно делать руками делается руками мы специально не перри автоматизируем этот процесс понятно можно бы конь скрип написать чтобы запускали он там дергал по очереди но как раз для того чтобы люди не теряли навыки и этом вас фактор увеличивался еще около вопросы есть спасибо за доклад хочу уточнить что является праймари ким грубо говоря коуч тебе и какие индексации используются еще раз уж тебе кучу без это разные базы круче легко запомнить давайте я сейчас перейду на слайд про это у нас есть записи двух типов они хранятся в одной таблице товар называется bucket коуч bass устроен так что там нет смысла делать несколько пакетов они даже не рекомендую делать много bucket of потому что я поиск работает так же быстро о каждой баки требует некоторые фиксированные ресурсы на его а там инфраструктуру у нас я записи двух типов первый тип записи это ключ эпиграфа тело граф 2 тип записи это как бы мы сами строим индекс такой ключ это идентификатор ну например индикатор вашего устройства скота в этом реклама будет показываться не фиксатор приложения не знаю к в браузере логин значение это виде графа то есть если вы хотите по там покупки найти граф вы сначала дети в базу покупки достаете граф айди потом идет второй раз достаете граф ну и там есть еще всякие хитрые оптимизации как не ходить много раз за графом если вам дали пачку идентификаторов и они там все есть в одном графе например сразу пожалуйста 1 граф это 1 запись как бы графа и еще сколько в нем решил столько записей индекса я не уверен что точно понял какого рода данные вы храните в графе но и к шуруйте ли вы запросы в graph скажем если вы показать им не рекламу там я же кука не так часто меняется вы можете один запрос в graph сделать и за кэшировать для меня результаты наверное так можно было бы сделать есть некоторые клиенты которые копируют вызова к нам на своей стороне действительно но наш сервис работает так быстро что часто работает быстрее чем выше которые там кто-то саму себя напилил и еще к тому же содержит более актуальные данные поэтому можно просто ходить в наш сервис они парят понял спасибо нас серый с человеческим лицом следующий здравствуйте спасибо за доклад не сравнивали про the buff например с другими протоколами сериализации например с массаж потому я говорил что там на самом деле про the buff не очень важно использовать просто надо там что то что можно пожарить либо на самом деле вот наша сигнализация у нас там есть несколько версий в коде в цивилизацию потапов есть реализация сейчас jason wu цивилизаций джейсон работает быстрее чем силе зация в протокол потому что не надо промежуточное представление формировать сначала только это просто бурный объект до потом его силе завывать но когда мы писали вот этот сжатие сигнализация автобус работала быстрее и вы взяли ее сейчас можно было бы взять что ни другое на самом деле неважно что главное чтобы это можно было за клип натравить то есть у нас там идентификаторы там довольно много ключей повторяющихся этом чисел я не очень хорошо жмутся понятно так если у кого-то еще остались вопрос их можно будет уже задать на дискуссионные зоне сейчас хотим благодарить дмитрия за его доклад спасибо"
}