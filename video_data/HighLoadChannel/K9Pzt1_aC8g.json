{
  "video_id": "K9Pzt1_aC8g",
  "channel": "HighLoadChannel",
  "title": "Warden — зачем нам свой service mesh? / Ильяс Нежибицкий (Ozon)",
  "views": 1566,
  "duration": 2855,
  "published": "2024-04-17T01:10:28-07:00",
  "text": "раз раз отлично Всем привет давайте познакомимся Меня зовут собственно Ильяс как меня представили ранее и сегодня мы с вами проговорим про наше собственное решение для обеспечения сервис-меш в компании озонтех вот собственно я как раз таки работы в отделе сервис-меж департаменте платформы и как раз обсудим наш продукт который мы реализуем вот но чтобы объединить наш с вами контекст Давайте сначала поговорим немножко про текущее состояние сантех вот собственно Наш бизнес Юнит на данный момент обслуживает около 4000 микросервисов которые располагается суммарно более чем на 70 тысяч котиков все это дело располагается в трех больших дата-центрах которые суммарной мощностью располагает более чем 6100 серверами пишем в основном на горшке и на шарпах У нас есть Наш замечательный маскот Гоша который как раз таки характеризует два эти языка вот ну и межсервисное взаимодействие осуществляется через Достаточно давно пользуемся этим протоколом мы его умеем варить во всех только во всех каких можно представить себе каких-то проблемах потребностях и так далее вот ну и Да собственно варден это наша собственная сервисное ощущение про которое сегодня пойдет речь вот собственно обсудим мы с вами сегодня механизмы реализации сервис mash Какие они бывают какие они были Почему все так вышло рассмотрим процесс создания собственного сервиса сервис С какими проблемами можно столкнуться Ну и собственно обсудим функционал который мы решали те или иные проблемы в ходе разработки нашего продукта Ну и начнем по порядку собственно Механизм реализации сервис mash посмотрим такую историческую хронографию всех этих процессов и Собственно как все мы знаем сначала были динозавры у нас с вами как только вы вымерли динозавры и больше не осталось на земле появились первые решения это были собственно монолиты я называю это такое доклаудэнтив решение эпохой Вот соответственно были первые сайты первые сервера на которых располагались какие-то приложения и в целом на самом деле монолит это идеальное по своему штука поскольку ей никуда ходить не надо никаких проблем нет она сама реализует весь нужный вам функционал Вот и как бы сами сама по себе существует это такой первый этап но в какой-то момент достаточно большим игрокам на рынке возникла потребность как-то все-таки этот Монолит распилить хотя бы на какие-то кусочки поскольку он просто мог бы не вмещаться там виртуалки или на сервера и так соответственно появились условно говоря монолиты но состояли из нескольких частей почему я отнес это все в одну назвал это монолитом поскольку суть заключалась в том что у вас было какое-то достаточно Малое количество частей и все эти части как правило располагались на конкретных железках на конкретных местах и имели как правило статические ip-адреса В итоге для того чтобы организовать вот это вот между ними взаимосвязь вам достаточно было написать какой-то простенький балансировщик и ваш этот балансировщик либо за хардкодить какие-то IP адреса этих конкретных нот либо например положить Файлик Host Ну или если вы совсем крутые сходить за ними в DNS Вот но суть все-таки всего этого была в том что у вас было четкое связанность между частью сервиса или сервисом и конкретным ip-адресом вот собственно таким образом никакого discovering как такового пока что не было Вот но собственно внедрение микросервисной архитектуры и появлением Вот таких вот ребят возникла проблема связанная с тем что как раз таки все сервисы начали переезжать ip-адреса уже перестали за ними фиксироваться и сопровождалось всё это как правило такой некоторые болью и надо было решать как-то проблемы с дискаврингом и уже с такой более серьёзной более серьёзным распределением нагрузки и собственно Когда появилось много инстансов первым самым очевидным решением было просто выделить отдельный сервис который взял бы на себя всю эту задачу так появились первые реверс прокси Вот это был самый простой вариант Ну и собственно самая популярное решение которое пришло к нам это был инженекс самый популярный когда-то да И ныне вариант как все это дело решить как сбалансировать нагрузку на него складывалась задача поиска обстрелов на него закладывалась задача балансировки нагрузки Ну и решение каких-то дополнительных требований например по каким-то ретрам политикам может быть Джексоном и так далее вот он располагался скорее всего на отдельных серверах и решал все эти поставленные задачи Вот Но все-таки это сопровождалось известной проблемой связанной с лишними сетевыми хопами всё-таки с выделением каких-то машин под всё это дело в общем как-то эту ситуацию хотелось бы обыграть основное конечно же избавиться хопов Итак появилось следующее решение популярное на данный момент это сайт-кары и Первый из них были сайдкары для каждого котика суть заключалась в том что мы вот это вот нашу реверс прокси кладем рядом с сервисом Да вот самый популярный на данный момент это инвой в связке с истио и на него заворачивает трафик пускаем все все запросы через него на наши бэкенды Ну и как раз таки вся вот эта вот логика которую мы с вами обсудили она складывалась уже на вот этот дополнительный сайт Car все как бы ничего Окей стало в целом лучше сетевых опов избежали но поймали очень существенную по ресурсам поскольку какой бы он не был маленький этот сайт Car все равно он занимал достаточно много памяти относительно до Больших инсталляциях у нас напомню 70 тысяч кодов он требовал обеспечения какого-то дополнительного собственного жизненного цикла его приходилось разворачивать его надо было правильным образом закрывать и надо было как-то его обновлять и соответственно эти проблемы также нашли некоторые решения конкретно по производительности и по оверхеду по ресурсам было решение положить уже этот сайт Car не для каждого подвига А например на ноду таким образом появился сайт карппер нода суть которого заключалась в том что у вас имелось нода и соответственно все сервисы на этой ноте проксировали трафик до этого инстанция точнее двое например данном случае а он уже свою очередь это все прокидывал до другой ноды и отправлял запросы на нужные сервисы мы сэкономили на этом достаточно много памяти на таком решении но все равно продолжаем кушать достаточно много семью на обработку всех этих запросов и также все-таки это сайт Car который имеет свой собственный жизненный цикл Вот соответственно это на самом деле на данный момент такой популярный Flow которым пользуются многие но есть такое некоторое ответвление возможно его можно назвать новым решением можно назвать развитием старого это clineside суть которого заключается в том что вот если раньше нас вот балансеры жили прямо внутри клиента то сейчас мы соответственно разрабатываем фреймворк который уже на современных технологиях все это дело реализует Вот соответственно выглядит это все как-то так у вас детоклей да к слову тот механизм который находится рядом с клиентом это называется дата плейном А вышестоящий который обеспечивает его нужной информации называется Control plain так вот Data Plane Мы встраиваем в клиента клиент подключает его как библиотеку или как фреймворк и соответственно через него уже пускает весь этот трафик Вот соответственно все это зашивается в один единый бинарный релиз и это библиотека практически ничего не стоит поскольку вся эта балансировка осуществляется на высоком уровне мы не скачиваем Full State всего нашего мира который вокруг нас в на каждого клиента А можем только скачать только те сервисы которые он использует вот ну и соответственно мы как бы начинаем использовать гораздо меньше семью поскольку уже нет необходимости как-то держать это приложение дополнительный фоне а просто например там раз пять секунд делать запросы получать новый стоит вот Но конечно же это все-таки не идеальное решение поскольку оно существенно усложняет клиентскую часть и нет возможности как было раньше по-быстрому обновить все наши сайты или там все наши прокси и добавить какие-то новые дополнительные там может быть Discovery или балансинг политики вот Окей приступим наверное уже к основной части закончим наступление и попробуем подумать А что же нам все-таки нужно для того чтобы обеспечить сервис меш Ну и собственно основная задача которая вообще нам нужна это обеспечить связность между сервисами для этого нужно нам в первую очередь понять где находится бэкенды в котором мы хотим хотим ходить но Откуда это узнать И тут на самом деле приходит голову очевидная идея просто пойти и спросить у того А кто знает Вот поскольку у нас вот это вот все клаудейцев есть механизмы которые располагают наши под и знает какие у них IP адреса да В данном случае мы в принципе можем взять сделать к нему запрос и попросить отдать айпишники всех например всех инстансов 72 вот в целом валидный Поинт можно так делать но как нам подсказывает собственно Гоша вот здесь вот кубапе у нас не резиновый и при большом росте количество сервисов Мы очень быстро исчерпаем все ресурсы наших мастернод и просто-напросто не вывезем все-таки у cubernetis есть поважнее задача а не просто рассказывать о том где кто Находится и собственно таким образом приходим к очевидному решению это просто добавить некоторые кэш в виде прокси Ну которым после назовем Control plain нам основной задачей которой первая Задача будет кэшировать весь стейт кубернатиса Вот и соответственно клиентам уже отдавать информацию о том из собственного Кошель отдавать информацию Где находится бренды в котором надо ходить и собственно Таким образом мы получаем на самом деле первую версию Service mash которая была реализована вазон реализованном она была достаточно быстро наверное где-то порядка за неделю Вот соответственно и уже на тот момент Она решила достаточно много проблем вот ну и собственно да как я и сказал У нас все копии будут подключаться к нашему Control Plane и получать из него состояние Окей супер мы достигли механизма Discovery у нас уже есть связанность но в какой-то момент к нам приходит разработчики говорят что у них как бы есть и как бы квантили слишком высокие Ребята посмотрите что вы можете сделать Итак мы соответственно приходим к вопросу об алгоритмах балансировки когда мы полезли ковыряться в grpc вот собственно мы написали для него механизмы discovering полезли за алгоритмы алгоритмами балансировки мы обнаружили что по дефолту у grpc самый такой простой алгоритм балансировки который использует это раунд Робин очень в целом такой хороший механизм но на данный момент Уже немного неприемлем поскольку не учитывают очень много информации которую можно получить начинаем думать над возможными решениями накидываем себе какой-то списочек каких алгоритмов и собственно Да принимаем супер крутое стратегическое решение взять и реализовать все что можно вот если в целом с первыми двумя алгоритмами все более-менее понятно они статичные вы просто указываете для например в веса и у вас таким образом начинает трафик чуть неравномерно распределяться А например Чтобы побыстрее обрабатывать запрос то соответственно статистическими алгоритмами балансировки которые Как лист он есть ряд проблем А именно когда у вас был один единственный балансировщик он достоверно знал сколько запросов он отправил каждому из инстансов бэкэнда Вот соответственно он четко в любой момент времени он четко мог был определить кто из них менее нагружен и соответственно отправить на него новый текущий запрос но как только мы переходим к более таким распределенным системам более сложным они перестают знать о том насколько загружен каждый из брендов поскольку каждый из них не знает куда отправил запрос Сосед и того в какой-то момент появляется такая известная проблема супермаркета суть которой заключается в том что когда у вас открывается например касса И вам кричат там Седьмая коса открыто проходите то в какой-то момент на неё через буквально там несколько секунд прибегает очень много людей и очередь на ней оказывается сильно больше чем на всех остальных вот ну и плюс у нас как бы есть проблема быстрого обновления политик которому решим за счет отправки конфигурации с балансировки с нашего Control Plane сведения о том Какой балансер надо использовать Окей но все-таки статистическая проблема как ее решить и есть на самом деле ряд решений первый самое такое наверное известный популярный это алгоритм Power of touchsis называется суть которого заключается в том что для алгоритма листкон вы начинаете балансировать нагрузку точнее при Когда делаете новый запрос вы начинаете выбирать не из всего списка инстансов а делаете Выбор только например из двух таким образом вы ну 2 эти инстанса выбирается рандомно делается из них запрос о том сколько сейчас открыток к ним запросам от нашего клиента и потом уже делается выбор вот собственно у нас был меньше здесь и накрементьем счетчик таким образом сохраняется механизм листкон но в него добавляется определённая составляющая рандома которая позволяет размазать эту нагрузку пиковую которая может возникнуть когда один из бэкендов сообщить что там ну или мы поймем что там к нему меньше всего запросов вот плюс соответственно еще такая фича которая очевидно то что нам не нужно сравнивать загруженность тех инстансов а только двух соответственно Таким образом мы ускоряем этот механизм Я в презентации прикреплю ссылки потом когда можно будет скачать почитать более подробно о том как работает этот механизм вот собственно это первое решение данный проблемы с нехваткой статистических данных но есть еще ряд проблем соответственно это более современный алгоритм балансировки Первый из них это согласованный листкон и пики в ММА согласованный листкон работает Каким образом Когда вы делаете запрос до какого-то инстанса каждый сервер он четко может посчитать сколько на данный момент он обрабатывает запросов Вот и соответственно зная эту информацию делая Запрос к нему сервер Может вам положить в метаданные ответа эту информацию вот а соответственно стороне клиента можно дело спарсить таким образом Когда мы будем делать уже следующий запрос у нас будет информация о том сколько было на этом бэкенде запросов и таким образом мы более точно сможем определить какой из бэкендов менее нагружен это что касается согласованного листкон что касается пики vma суть данного алгоритма заключается в том что мы перестаем смотреть именно на количество инфлайт запросов а начинаем следить за тем как долго нам отвечает каждый из инстансов бэнда так Ну поскольку мы делаем запрос и можем померить респондстайм данного инстанса вот ну и соответственно когда мы потом пытаемся понять нагруженность данного бэкэнда Мы берем скользящее среднее от там последних нескольких запросов и таким образом отправляем определяем А кто из них отвечает медленнее кто из них отвечает быстрее Вот соответственно про пик его мама можно почитать тоже будет По ссылкам данный механизм пока что не реализован есть только открытые еще на его реализацию вот именно так вообще это данный алгоритм был описан в сервис-мешлин кирди Вот соответственно ссылочка как раз на него вот Ну и как раз таки в описании linkerdi есть вот такой замечательный график на котором они говорят о том что пикима лучше обрабатывает крайне квантилии было бы на самом деле странно не проверить это заявление поэтому поставим с вами эксперимент суть которого будет заключаться в том что мы возьмем какой-то пул инстансов каждый из которых отвечает чуть медленнее предыдущего и посмотрим влияние вот мы посмотрим собственно на согласованный лист он барабанная дробь мы получаем какой-то такой результат собственно видно что вот паста нас был изначально раунд дробин и мы переключили на листкон соответственно не так много но в целом Прогресс есть вот ситуация стала все-таки чуть-чуть Но лучше для того чтобы точно понять что наш алгоритм работает ведем еще один дополнительный график на котором мы отметим точечками котики по оси абсцисс будет их респондстайм а по оси ординатор PS которую мы на них направляем вот ну и соответственно можно видеть что алгоритм листон как раз таки выстраивает все наши инстанции вот такой вот линии и соответственно Чем медленнее отвечает наш плодик тем меньше на него запросы мы отправляем ну и соответственно наоборот самый быстрый получает больше РС вот Окей с лист он как бы результат не такое впечатляющий собственно мы его ожидали исходя из этих графиков посмотрим на Самое интересное это пиковая и опять конечно же барабанная дробь получаем Вот что-то вот такое вот собственно можно видеть что вот у нас был раунд Робин потом листком и на пике в Ома прям видно существенное снижение квантилей Вот соответственно тут чуть больше в цифрах выглядит супер круто вот посмотрим на график и достигается все это достаточно просто как раз таки тем что те инстанции которые отвечали быстрее всего просто начинают получать больше запросов Исходя из этого алгоритма балансировки таким образом как раз таки и получается удерживать более низкие квантили Окей супер смотрите Мы с вами уже обсудили Discovery мы обсудили алгоритм балансировки А что же дальше Ну для джентльменского набора нам не хватает самого главного В современных технологиях это всеми известный канарейный диплой Ну или диплоидная новых релизов на какой-то процент трафика Вот соответственно решает проблему выгодки и тестирования каких-то новых релизов Вернемся опять же прокси с которой Как ни странно все понятно у нас есть релиз один У нас есть релиз 2 сообщаем про все что отправка пожалуйста где 90 процентов трафика на релиз один на старый А на новый Я хочу всего лишь 10 процентов поскольку у прокси есть инфа о том сколько было какие релизы были подняты в каком количестве ей достаточно просто сделать такую фичу вот просто подбрасывать кубик Каждый раз когда она делает запрос в случае если у нас есть какой-то новый релиз Вот Но с клиентами чуть сложнее Вот и есть несколько решений данной ситуации вот поскольку наш Control plain дата плейно отправляет список адресов приходит такое первое решение к сожалению но не самое хорошее Но почему-то именно первым приходит в голову это изменять ответ от серверной части вот суть которой заключается будет том что вот у нас есть изначальный ответ без канарейки мы отправляем сведения про 10 подвигов нового релиза если мы хотим выкатить канарейку а давайте-ка докинем просто-напросто в этот список еще например instance нового релиза Вот и наш клиент будет соответственно балансировать трафик уже не только по новому релизу но еще и какую-то часть попадать на ой соответственно не только на старом а на новую еще лить вот ну и соответственно Если хотим на половинку то просто половину инстансов кидаем старого релиза и половину нового вроде как бы Окей но есть очевидные проблемы у данного решения Первое это то что процент зависит процент который мы можем залить трафика зависит от вашей инсталляции От количества бэкэндов он должен быть ему кратен вот а это мне всегда бывает так получается сделать не всегда получается достичь нужный процент Вот и второе это соответственно нельзя реализовать поход на конкретную версию Вот Но об этом чуть позже и собственно да как я сказал есть несколько решений и второе решение уже Чуть более такое решающее все эти проблемы это реализовать ту же логику прокси только на клиенте соответственно с серверной стороны мы отправим сведения про все инстанции всех релизов но мы их подпишем о том кто из них является каким и плюс метаданные положим информацию о том сколько нам нужно процентов отправить на новый релиз Вот соответственно в таком случае у нас как бы дублируются логика всё и мы соответственно тоже кидаем кубик и можем уже гранулярно выставлять процент трафика который мы хотим отправить на новый релиз вот И как я сказал ранее да про выбор конкретной версии Было бы странно на самом деле реализуя вот этот вот весь механизм не добавить каких-то своих интересных фичей Вот и поэтому мы вели такое понятие как нулевая канарейка суть которой заключается в том что мы точно также отправляем все инстанции всех релизов Вот но говорим о том что на Новый релиз пока что трафик боевой лить не надо вот а соответственно со стороны клиентов вот или тестировщиков ведем такую фичу по которой в закладывая в заголовок нужные сведения про нужную версию какого-то сервиса мы соответственно сможем сделать запрос именно на новый релиз таким образом до того как мы Пустим боевой трафик тестировщики могут зайти на наш сайт выставить нужный заголовок Пусть он будет например сервис вершин и в итоге Получить ответ от Нового релиза и таким образом глазами просмотреть что все работает хорошо и да получилось такая супер фича для тестирования проверки релизов которые пользуются как раз таки на момент выкатки нового релиза Окей круто смотрите у нас уже есть Discovery есть алгоритмы балансировки есть канарейка пока мы все это с вами делали у нас компания подросла инсталляции подросли у нас уже стало там супер много кодиков уже Мы балансируем не там между единицами и десятками инстансов а переходим к сотням и соответственно на самом деле вроде бы казалось но Окей но все-таки такой рост приносит ряд некоторых проблем поэтому мы с вами обсудим такой механизм как сапсатинг решаемая проблема заключается в том что когда мы ходили в какой-то ограниченное число инстасов Ну например 3 на 3 Да у нас было не так много соединений да В данном случае 9 каждый клиент открывал каждому бэкэнду новый за этот новый Коннект и соответственно еще немаловажный такой такое условие которое у нас было в этом месте то что например у нас каждый подвиг сервис 1 отправляется по запросов на сервис 2 и соответственно ну так у средних получаем что каждый из этих инстансов получал по 33 фпс и клиент используя статистические балансировщики которые мы говорили ранее мог был сделать точный выбор поскольку его данные были достаточно свежие актуальные и не было никаких старых данных но когда мы собственно переходим несколько сотенсов Да вот например 100 на 100 то появляется проблема во-первых соединение И тут я нарисовал только 25 опять Так как еще в четыре раза больше Вот соответственно это большое количество tcp соединений и соответственно балансировщики статистические которые отправляют мало запросов да те же 100 rps мы уже отправляем на каждый instant сервиса 2 не по 33 rps А всего лишь по одному и в итоге получается что наша балансировщики не могут набрать нужную статистику для того чтобы сделать правильный выбор вот поскольку когда мы кинем запрос один РПС свой да потом когда следующий раз мы придем Через секунду на этот же instance за Вот эту вот секунду его ситуация могла Была кардинально измениться по нагрузке вот таким образом получается что мы в итоге вырождаемся в какой-то Рандом а не в какую-то осознанную не в какой-то осознанное поведение Ну и собственно решение данной проблемы А что если поскольку у нас все наши инстансы бэкендов идентичны между собой что будет если мы нашим клиентам будем высылать не весь список а только например его часть какую-то рандомную Вот и будем мешать их все таким образом чтобы в результате клиенты все получали Рандомные позы в определенном количестве Вот но суммарно все это складывалось такую картину что все наши бэкенды в итоге были отданы хотя бы какому-то клиенту вот в идеале в одинаковом количестве они должны повторяться на клиентах таким образом из вот этой страшной картины от которой мне даже маг иногда бывало подлагивал мы получаем что-то вот такое вот в результате чего мы как бы много ни мало но все-таки сэкономили порядка 60 процентов соединений что в целом считаем достаточно хорошим результатом Ну и самое главное это то что мы набрали нужное количество запросов для балансировщиков и позволили дальше свою работу корректную в условиях больших инсталляций супер на самом деле мы уже достигли такого достаточного обширного количества фичей которым реализуем которых достаточно для реализации современного сервиса mesh А что же дальше А дальше больше Как ни странно поскольку у нас есть большая платформа у нас Мы заходим там в ПАЗ и в прочее решим заняться такими вещами как балансировкой и Discovery не только сервисов и каких-то просто подав в нашем окружении но будем их рассматривать как ресурсы конкретные Вот и реализуем какие-то дополнительные политики которые реализуют наши разработчики каждый день Просто теперь переложим и рутинную работу на платформу сделаем это все единым стандартом для всех таким образом чтобы сделать данную фичу помимо Куба в наши наш серверную часть добавим источник данных не только куб но и например дополнительные источники данных такие как менеджеры наших ресурсов Да вот собственно можно видеть то что у нас уже имеется это msql Click House caf caradis и POS вот таким образом наш сервер будет теперь хранить сведения о том где конкретно располагается ресурсы собирать с них какую-то дополнительную метадату если она у них имеется Да например случайных баз и так далее и Давайте все это клиенту и таким образом на стороне клиента на стороне балансировки мы сможем во-первых нужным образом отправлять трафик на нужные ресурсы и также мы сможем реализовать такие популярные механизмы например для кошей Как кольцо или для постгрыса можем разделить нагрузку на всю пишущую нагрузку автоматически отправлять на мастер реплику А если это какая-то читающая нагрузка то на Синг реплику вот собственно Таким образом мы реализуем как раз таки балансировку трафика до каких-то ресурсов Окей супер уже даже подумали про это Но в какой-то момент у нас появляется неизбежный Челлендж суть которого заключается в мульти DC Когда мы жили в одном дата-центре все было как бы хорошо поскольку весь трафик ходил внутри этого дата-центра никуда Ему больше не надо было И никаких проблем не возникало вот сколько есть у нас инстансов только мы отправляем и в них ходим Но как Только у нас появляется например еще какие-то дополнительные дата-центры Да вот Второй третий и так далее наши алгоритмы уже данный момент если будут работать точно так же как обычно то они будут в какой-то момент отправлять трафик не только внутри DC но еще и на другие дата-центры что соответственно не есть хорошо поскольку помимо того что у нас есть лишний трафик между центрами все это сопровождается повышением letency для наших клиентов Вот соответственно тут появляется требование на локализацию трафика и вот эти вот все связанности нам говорят что надо было брать по-хорошему Вот и в целом на самом деле посмотрим на графике как это все происходит собственно вот у нас как подвиг из первого дата-центра отправлял трафик во все дата-центры и можем видеть его квантили и мы например локализовали трафик и видим что у нас 50 quantile очень сильно упала вот на несколько миллисекунд что собственно неплохой результат Как же это все реализовать Но на самом деле ситуация такая же как с канарейкой реализуем режим авто поскольку наш сервер знает о том Кто где находится то по IP адресу клиента который к нему пришел он может определить о том где этот клиент находится в каком-то центре Вот соответственно таким образом в ответ Он может ему положить сведения только про инстанции в его дата-центре в случае если вдруг они упали или их в общем могло бы не быть в этом центре то соответственно мы этом на северной стороне определяем и в ответ клиенту складываем не только его инстанцию но и удаленные instance из других дата-центров вот все бы ничего но что произойдет если наш сервер упадет что собственно Мы периодически видели во время наших учений тут появляется требование на дополнительные резервирование данной логики поскольку ситуация не очень приятная и как бы хотелось бы все-таки чтобы мы жили дальше И в данный момент мы вводим механизм резервирования системы которую назовем DC priority суть которого будет заключаться в том что мы в ответе точно также подпишем Где находится инстанции данного бэкенда в каком-то центре является ли они для этого клиента локальными Или это для него удаленные инстансы таким образом на клиенте как раз таки реализуем такую фичу суть которой будет заключаться в том что сначала он будет устанавливать коннекты к локальным котикам если с ними то трафик будет лица на них И ничего делать больше не нужно на случай если соединение к ним обрывается по каким-то причинам то наш клиент должен перевести трафик на удаленный дата-центр сначала открыв к ним соединение а потом уже плавно пустив трафик Вот но параллельно вместе с этим он должен отслеживать состояние локального дата-центра потому что в момент когда локальные инстанции начнут оживать то мы сделаем к ним ретрай и пусть им плавно трафик с удаленных на локальный вот коннектик удаленно дата центром через какой-то момент закроем вот в целом на самом деле как-то так сейчас и работает наш сервис mesh и уже что как вошло в традицию зададимся вопросом что же дальше И тут мы переходим уже к нашим Future Plants А может быть на данный момент часть из них уже это наша текущие планы и самое главное цель это Федеративная архитектура которую мы хотели бы у себя вытащить вот собственно на данный момент наши дата-центры живут в одном большом коммунальном кластере найти соко 8S comman который мы хотели бы разделить на несколько кластеров Вот и самая простая это распилить его горизонтально по дата-центрам и соответственно уже использовать кубапе каждого из этих кластеров и реализовывать сервис таким образом на рынке есть уже решение ряд самый популярный Наверное это есть его вот и соответственно его Механизмы как они это реализуют у них уже есть из-под коробки из под капота поддержка Федеративной архитектуры суть которой заключается в том что в Data Plane могут ходить до теплейны могут ходить в Control plain из других кластеров вот а соответственно discovering осуществляется за счет того что каждая известие ходит в во все кубапе во всех кластеров которые будут описаны очевидный минус такой архитектуры заключается во-первых в том что на картинке когда там два кластера Это все как бы хорошо красиво но Что будет если мы перейдем в десятки кластеров или не дай Бог сотни то мы вернемся опять же к той же проблеме которую озвучили еще в самом начале это перегрузку бапе каждого поскольку каждый из них Будет отдавать сотни клиентов свой стейт что в моменты каких-то больших шатаний больших изменений может оказаться критичным для кубапе перегрузив его по ресурсам плюс еще второй минус который как бы тоже в целом очевиден это торчащий наружу API из кластера Да это может быть конечно внутри нашей сетки Но все-таки для кластера этапе будет торчать наружу что все-таки из-за этого могут возникнуть возникнуть вопросы со стороны безопасности поскольку еще меньше открытых портов а особенно таких важных тем лучше У нас есть на все это свое чуть-чуть иное видение суть которого будет заключаться в том что наш Control Plane будет располагаться в каждом кластере и все подвиги этого кластера будут ходить в Control plain своего кластера вот а docobapp мы реализуем как ни странно про Ксю решение чуть-чуть повторяется и из предыдущих глав Вот и соответственно Discovery возложен на такую сущность которую назовем информер которая будет открывать один единственный Connect до кластерного кубапе своего собственного Вот Ну а соответственно для реализации кросс кластерных походов наши сервера наши Control plain будут и находить информацию получать информацию не напрямую с кластеров и из их кубапе а как раз таки через нашу вот таким образом мы опять же кэшируем стоит между нашими Control plain и не вытаскиваем нарушена наш апе вот Ну и конечно же не забудем поддержку ресурсов которую мы также перенесем на наши информеры вот и соответственно реализуем все это для многоклассной системы Я думаю мы еще с вами встретимся когда мы во все это дело зайдем и Когда у нас будет итоговое решение мы расскажем вам о том что у нас получилось вот но пока что мой доклад подходит концу и не нужно немножко поговорить о выводах соответственно в итоге что мы получили первое это мы уменьшили responstane за счет современных политик балансировки мы сэкономили соединение на больших инсталляциях мы сделали механизм локализации трафика и добавили плюс ему еще один резервный слой который защищает эту логику добавили фича для тестировщиков ну и соответственно самый главный плюс всего нашего проекта заключается в том что мы кастомизировали всю эту структуру конкретно под зон тех и под всю нашу систему презентация приложил список литературы где можно более подробно прочитать про все что мы сейчас с вами проговорили Вот Ну а на этом У меня все спасибо большое за внимание Спасибо 99 но тем не менее думаю вопрос все-таки будут пожалуйста у нас Два подарка за лучший вопрос Это зона Итак давайте Спасибо за доклад хотелось спросить момент когда клиенты ходят в 2D это центра нету ли проблем с тем что алгоритма балансировки сходит с ума отличающегося у разных плодов до разных плодов Бывает такое Да соответственно если использовать пики vmo это ситуация каким-то образом решается за счет того что удаленные дата-центры отвечают медленнее но все равно не так как это железно зарезать локализации вот вопрос из чата Если дата плейно интегрирована в приложении в виде библиотеки то как разделяются разделяются жизненный цикл этой Лиды и пользовательского кода тут смотрите жизненный цикл Мы обеспечиваем за счет того что у нас есть единая платформенная структура единая платформенная библиотека для всех команд вот она реализована на разных языках и соответственно как всегда такой некоторые административный ресурс суть которого мы когда хотим какой-то важный релиз мы поддерживаем старый на момент переезда говорим всем командам что вот ребят надо бы за месяц вам обновиться Ну или за какой-то срок Вот и соответственно ждем пока все обновятся вот таким образом мы обеспечиваем наш жизненный цикл что из чатик вопрос как работает локализация трафика под это центром если используется одинаковая маска под сети для подав разных кластерах разных дата-центров Ну тут на самом деле все просто мы можем определять Где наш находится наш подвиг не только по адресу но и по каким-то лейблом вот плюс мы соответственно в информере от кубапе можем использовать сведения про ноды и соответственно когда мы получаем какие-то обновления от нот или от котиков там соответственно есть между ними связанность и можно привязать конкретные котики конкретные ноги ноды уже как бы просто определить где Какая из них находится в каком-то центре Давайте вот там микрофон молодого человека Привет Спасибо большое за доклад у меня вот такой вопрос смотри у нас получается Если женщина релизы вопрос про то что как быстро варн сможет определить что вот я выкатился на сотку увидел что проблемы откатился Вот как вот перепрыгивание как быстро не происходит Ну ты по опыту знаешь достаточно быстро реализован реализовано за счет того что выставляются лейблы для новых релизов Вот соответственно вешается лейбл на сервисного релиза И в нем как раз таки содержится метаданные про вес соответственно переключение 10000 Ну или вообще просто любого процента происходит за счет того что мы изменяем лейблы как только в куб мы сделали эту запись сразу же в этот же момент поскольку у нас до кубапе открыт Стрим А не пул-модель то есть у нас push-модель Куба пином сразу же сообщает эту информацию Мы сразу же оставляем стоит то есть занимает это всё ну там секунды если не меньше То есть получается просто вот чем за обновлениями круто Всё спасибо Просто джинсов до контекста большая проблема с этим есть Давайте в самый конец там последний ряд там по-моему Привет меня зовут Сергей спасибо за доклад есть два вопроса один маленький про балансировку когда говорили вот в эксперименте менялись ли там времена ответа да там некоторые мебели некоторые быстрее вот происходило лечение времени ответа чтобы понять Как это остается ли график таким же офигительным это вопрос номер один и второй про канарейку Когда выпускаем новый релиз и допустим оставляем Ну там 50% э-э от там снова версии релиза и там 50% старые Ну достаточно легко понять А что новый релиз например замедлил там условно говоря всю систему или в принципе тормозной его можно было бы откатить так вот вопрос как это работает в условиях уже э Федерации Когда у нас несколько DC Когда у нас есть информер А как свести э концы с концами понять что это не сетевые лаги что-то а действительно тормозной релиз спасибо Так ну по первому вопросу соответственно в эксперименте нам надо было убедиться в том что у нас держится квантилей и в эксперименте те там всё-таки была статичная э статичная РТ вот каждого из котиков вот поскольку это всё-таки эксперимент в жизни ситуация похожая соответственно если у Вас как бы э какой-то кодик болеет Может у него там какие-то лаги посетили ещё что-то он всё равно типа имеет э статическую задержку Вот но графики с соответственно с каким-то более переменным респонд-стаймом они могут чуть колебаться Но самое главное что тенденция останется Вот это самое основное что мы наблюдаем Зачем следим это по первому вопросу По второму вопросу По поводу responstime это все-таки ответственность на командах когда они катят релиз и они сами должны следить за тем что у них все произошло медленнее или быстрее Ну пошли запросы вот что касается Федеративной архитектуры тут пока что Я не готов ответить поскольку мы в это все только въезжаем и как раз только-только набиваем свои шишки на этой истории Вот но переезд скорее всего будет аналогичный как раньше соответственно Ну точнее переключение трафика собственно Если вы замечаете что у вас начались какие-то проблемы жмете кнопку вернуть обратно меняете лейблы и мы соответственно рассылаем стейт тут так теперь спереди Вот первый ряд спасибо очень хороший доклад вопрос вы говорили что мы меряем свои показатели Как там CPU Pernod и память фернаду и сравниваем с истио которые диплоится одним там котиком на ноту получается Если мы в библиотеку загружаем в каждый instant сервиса по таблице маршрутов а то мы используем больше памяти и непонятно почему мы должны экономить ее можете рассказать вот по производительности это решение получилось эффективнее или Оно просто получилось удобнее но так что касается памяти Да вот у таких сайтаров были раньше проблемы во всяком случае с тем что Они грузят Full State вот кластера и это сразу очевидно что большой оверхед по памяти просто потому что как я ранее сказал у нас достаточно большой кластер и в нем крутится много кодов и Например у нас если клиент ходе там в один БК там или в десяток Да зачем ему грузить информацию про остальные 3990 сервисов Вот и хранить в себе это первое Вот соответственно по памяти очевидно выигрыш поскольку мы можем определить куда мы хотим сделать этот запрос и запросить сведения только про него что касается по CPU то поскольку мы вшиваемся в приложение и не требуем вообще запуска какого-то дополнительного бинаря и все эти фоновые процессы происходят уже вот в основном нашем бинарнике то тут получается экономия по CPU просто за счет того что мы не обрабатываем и не ошидулем какой-то дополнительное приложение в фоне нашего фоне работы а делаем просто на текущем приложении запросик там раз какое-то время и все вот и даже скажу больше это на самом деле у нас используется push-модель Вот соответственно которая в обычном режиме в принципе не потребляется пиво просто ждет фоне какие-то пакеты по сети которые к ней придут условно он работает без блокировок в том же трейдера да Вопрос не понравился Бывают ли несовместимые изменения между версиями Control plain как производится обновление откат версии Control plain и самое интересное Расскажите какую-нибудь историю факапа или успеха Я думаю лучше собственно и как раз таки это основная такая проблема именно поддержка старых версий вот поскольку переехать сразу обновить Control plain и Data Plane единомонта невозможно поскольку Надо редиплоинить всех клиентов и у них все это дело пересобрать обновить соответственно происходит обычно все это дело через плавный переезд соответственно мы поддерживаем когда мы обновляем Control plain добавляем новую фичу мы ее складываем отдельно и она живет отдельным Flow вот а соответственно старые фичи также приходится какое-то время поддерживать вот собственно факапов было очень много по этой истории поскольку бывало могли были просто не уследить за этим или забыть или поменять семантику и все отваливалось у всех потому что на нас такая достаточно большая ответственность за весь сервис мышь лежит Вот соответственно как то так еще и зала что-то есть у нас да давайте вот молодой человек вы выйду Ну вроде не зелененький Ладно синяя же Ладно вопрос смотри продолжай тему факапов у вас по сути ваш Control Plane это такой сингл пойнтов фейла Как вы защищаете его от падений потому что допустим если он перестанет отдавать актуальные ответы ваши клиенты будут знать только о старых адресах плодов какие-нибудь пады начнут перелоцироваться вы будете терять сетевые вызовы Что вы делаете в этом случае все так есть такое некоторая точка отказа для этого во-первых если мы вдруг не дай Бог падаем какое-то время вся наша структура продолжает жить до момента пока кто-то не редиплоится вот поскольку весь этот стоит кэшируется на стороне клиентов о клиенты продолжают текущей инсталляции жить Вот соответственно но нам Да конечно вот этот вот временной гэп Когда нам надо починиться откатиться он конечно же достаточно маленький Вот соответственно поскольку когда кто-то покатится катится у нас постоянно непрерывно и в в свое время можно потерять вот связанность между сервисами Да есть такая проблема боремся в основном с тем что просто выкатываемся по Вот как я говорил про канареечный диплой через канарейки через DNS вот поскольку именно сам чтобы зарезал ведь Control plain нужно куда-то сходить и понять где он существует Вот соответственно Мы подмешиваем в DNS записи про новую версию и на нее пускаем часть трафика таким образом проверяем отвалится на или нет Вот Ну и конечно же если вдруг что-то идет не так быстро откатываемся вот дополнительных каких-то фолбеков пока что у нас не предусмотрено то есть появится запись новых подарков но мы не сможем получить из них информацию поэтому и никуда ничего не будем проливать нет смотри мы наш вот клиент должен установить Connect controplay Ну начальный момент времени Ну либо впоследствии Если вдруг Control Plane катится происходит через DNS мы просто если Например у нас есть там не знаю пусть будет 15 инстансов нашего Control Play на 15 штук они все как бы идентичны между собой Мы просто когда выкатываем новую релиз выкатываем его например еще в плюс 3 пода таким образом появляется 18 Control Plane of и какая-то часть трафика ребалансница на них вот таким образом мы получим часть трафика на нас давай выберем Два лучших вопроса какие тебе понравились мне кстати вот как раз таки последний вопрос понравился что подарим политика и еще был Вот как раз вопрос конца это подарок от нас вот да да"
}