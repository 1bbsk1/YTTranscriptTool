{
  "video_id": "L0ZH25b5YK4",
  "channel": "HighLoadChannel",
  "title": "Трансляция HighLoad++ Весна 2021, 17.05, зал 5",
  "views": 536,
  "duration": 33258,
  "published": "2021-10-04T02:49:43-07:00",
  "text": "на то смысле первая профессиональная конференция разработчиков высоконагруженных и сложных систем проектов highload плюс плюс объявляется открытой я бесконечно рад вас всех видеть я бесконечно рад видеть вас вживую я не знаю как я ни пытался мы попытались сделать порядка 20 онлайн of и сделали хорошее и многие очень необычные я не смог его полюбить ну я не смог я пытался честно все-таки мы пандемию показала что мы все люди вот такой нежданчик что мы все люди что нам нужно общение что даже для того чтобы впитать в себя информацию чистой информацию на все равно нужна какая-то эмоция что потом прийти и и например применить мало что-то узнать на конференции ты должен еще потом по этим ножкам убедить начальство том что нужно сделать по-другому сотрудников коллег вообще что-то открыть скачать новые не знаю репозитории запустить нужна энергия и драйв и мы собираемся в оффлайне вот здесь вот такой красивой обстановке такой драйвовый обстановке именно для того чтобы эту энергию получить вот почему мы идем вперед потому что мы профессионалы этот этот гимн аж мы придумали в 2014 году я вчера специально посмотрел 2014 году и он очень простой он про то чтобы профессионализм состоит из двух вещей это любви энергии и знаний и опыта вот именно такие наши конференции добро пожаловать так а теперь небольшая экскурсия о том как пользоваться конференцию всем привет если что меня зовут олег бунин организаторы конференции очень много одни одни из организаторов конференции ребят нас а 50 человек над конвой сейчас в залог 150 волонтеров помощников хакимов кто угодно 150 самая большая наша маленькая армия да вот и первым делом пожалуйста надевайте маски обязательно когда вы ходите в фойе когда общайтесь с людьми соблюдайте социальную дистанцию в общем мы вас бережем мы очень много сил приложили чтобы дезинфицировать все-все рисунку ли ровать но вы тоже пожалуйста следите за этим смотрите по маскам там по маскам есть одна важная вещь кто переболел ребят нам с вами ничего не угрожает но мы все равно будем носить маски ну у нас же на лбу не написано что мы переболели и человек который перед нами он может волноваться может беспокоиться того что чувствую без маски ходим и так далее поэтому и просто оденем маску из из-за того чтоб бы из уважения для того чтобы создать и для него в тоже безопасное пространство чтобы он не парился по этому поводу так хорошо и если вдруг у вас нет маски у нас на территории множество масок на всех выходах на стойке регистрации у любого организатора спрашивайте вам дадут даже с красивой маски на каждого дальше кто вакцинировать парня девушке но нам с вами точно ничего не угрожает но мы тоже будем носить маски из уважения для того чтобы для всех а не только для нас было безопасно чтобы никто не беспокоился и не волновался еще пара вопросов мы никому это не покажем трансляцию не пойдет здесь есть к виды диссиденты но то есть том плане что ну это просто же гриб ну то есть немножечко медийной раздутый есть такие a1 мы с тобой ведь все равно наденем маску да просто чтобы никто не беспокоился мы понимаем что они все ошибаются реально но мы ну понятно что грипп сезонность слушай это все ясно мы умнее ну маску мы наденем хороша так а есть те кто уверен что маски не работают потому что ну вообще но не работает понятно мы понимаем что все что это истерика на то есть как бы они все все все беспокоятся нужно их вирус не понимает что вирус маленький он пройдет через поры маски элементарно но мы сами тоже оденем маску у нас их много меняйте их каждый час если они там не знаете что-то выходите на улицу подышать но пожалуйста всегда и везде всегда и везде из уважения к другим людям спасибо а теперь когда мы так долго говорили про маски давайте быстренько поговорим обо всем остальном пожалуйста прямо сейчас выключите звук своих телефонов чтобы не мешать спикеру и не мешать сидящим рядом возле вас звука телефонах их тут три страницы олег паралича его раз ел программа комитет harlot очень большая структура очень большая структура то есть мы проработали импланту более 200 то кладов под 300 что лес во все правильно программно комитетов несколько работает на несколько цифр то есть есть программный комитет по архитектуре по machine learning у и так далее ну неважно да то есть мы готовили ивану год год то есть сначала мы он был полностью готов в ноябре ну его перенесли обновили ну в общем короче эта программа выстрадана лучшая программа за все время которое минимум за год до минимум за год идем дальше расписание у всех у вас есть чудо книжечка на шее в ней много полезной информации это но самое важное это расписание этим очень удобно пользоваться не надо вертеть мы специально обучили наш типографии переворачивать листочки они научились встретил пару раз ну один раз перепечатывали один раз мы разбирали кольца перри собирали в общем обратите внимание пожалуйста у нас есть три расписание расписание в залах зала всего 8 в них записываются доклады это будет следующий за следующий слайд есть расписание выставки у нас огромная выставка это тоже по-моему самое большое количество партнеров которые у нас есть за последние годы есть отдельное расписание дыма выставки где партнеры будут разыгрывать призы где вечером будет хаббард награждение компания пробует награждать за лучшие блоги обещают концерт и вечерняя программа и и вы можете посмотреть в брошюре выдается в зоне раздатки вот в конце брошюры также есть оглавление вообще брошюры такая толстенькая книжечка в которой написано много чего о докладах и в том числе как выглядит спикер чтобы подойти к нему и задать ему вопрос какой нибудь мы сделали оглавление он кофе имени и по секциям доклады собственно мы находимся в зале 1 и по кругу пошли зал и все доклады записываются бухгалтерия у нас получается справа от входа в выставку около петр зал да так же вы можете увидеть кофе-брейк кофе-брейк у нас постоянный уже работает можно пить означать что в любое время можно прийти там будет кофе и немножечко перекусить а сейчас вот наша гордость это гибридные конференции скажешь да мы попытались сделать так чтобы перемешать online so fly нам то есть у нас здесь будут перед каждыми докладами будут онлайн вставки для нас для оффлайновых ребят а оффлайновые ребята могут прийти к нам сюда в зал почти ножками а то есть они могут задать вопрос мы его увидим мы потом после каждого доклада выходим цифровые кулуары да то есть это специально оборудованное место куда тоже можно подключиться можно подключиться из онлайна и увидеть как мы стоим вокруг докладчика задаем ему какие-то вопросы мы это попробовали это выглядит очень прикольно попробуйте сами как-нибудь накройте из наших конференций в онлайне зайти то есть ты стоишь в кулуарах ты видишь кулуары там камера специальная которая выйдет фокусироваться на том кто к сейчас говорит носит выглядит очень прикольно ты начинаю задавать вопрос тебя в кулуарах слышат тебя слышат видят и отвечают а те кто нас смотрит онлайн это я в камеру обращаясь обратите внимание у каждого зала снизу есть две кнопки задать вопрос спикеру в эфире это значит вы попадете на экран сюда прежде чем пройдете фейс-контроль наших помощников и 2 подключиться в дискуссионную зону то есть после того как спикер закончит отвечать на вопросы на сцене он пойдет в цифровые кулуары старая дискуссионная зона и там зум конференции оффлайн онлайн сможете пообщаться на онлайн ребята не стесняйтесь а теперь наша будущая теперь так будет всегда да то есть мы это сейчас внедрили через какое-то время ты внедрят с остальные организаторы вот так теперь будет научитесь использовать возможности онлайна более полноценно нас смотрит две с половиной тысячи человек на доложи рекламки две с половиной тысячи в онлайне а здесь 1900 и 2000 онлайн дальше обеды у вас в пиджак в кармашке сзади должно было быть два талончика если вдруг нет обратитесь на стойку регистрации кормим из 12 15 до 16 талончики можно менять кормим на втором этаже просто подойти к лифту мы на четвертом спуститься на два этажа вниз прямо под нами спускаетесь открывается и вы в центре импровизированные не знаю в столовой да если что на территории крокус экспо если вы хотите вдруг множество кафешек о том же втором этаже талончики с обедами можно менять время можно менять приходите на регистрацию меняйте на любой другой или в чате конференции устраивается торги обратите внимание наш хештег наш чат где можно общаться наш канал наш канал пожалуйста на него подпишитесь мы туда будем писать если вдруг что-то отменится если что-то перенесется или какие-нибудь другие организационные новости и чат и возле плееров но это больше для онлайн участников партнеры я говорила их много большое спасибо нашим партнерам и сейчас некоторых из них мы хотим пригласить на сцену чтобы они рассказали чего нас ждет вы же видели этот мини город который построен очень очень быстро поднимайтесь пожалуйста спасибо на самом деле на самом деле реально большое спасибо потому что мы выжили как команда как компания как конференции вообще благодаря им то что был период когда нам ну никто все остановилось деятельность нам сообщает о том что ребята а теперь вы закрыты теперь у вас нет и вы ничего больше не делаете ничего не умеете и ну смысле ничего и никому не нужны и продавать вам ничего нельзя и только благодаря партнерам вот этим вот это это представители только на мне за четверть тех кто нас поддержал за этот год поэтому им реально бесконечно благодарны каком-то смысле жизнью спасибо всем привет у настроение ребят татьяна сверкай компания select all безумно рада наконец-то видит живых людей очень соскучились пожалуйста приходите на наш стенд давайте общаться давайте обсуждать все что было ненавидеть онлайн-площадки и обязательно участвовать в нашем квесте будут классные призы и ждем всем привет я наверное присоединюсь тоже к уже сказанному наконец-то очень круто видеть всех в оффлайне потому что от онлайна действительно очень сильно устаешь я желаю всем и каждому сегодня для себя и сегодня и завтра на самом деле знать что-то новое обязательно послушать спикеров и поиграть наверное большинство игрушек которые делают команды компании партнеров но и конечно же приходите на наш стенд тоже там тоже есть игрушки в общем-то очень даже интересно но глобально наверное хочешь сказать что за эти два дня мне кажется 1 не побоюсь он оффлайн конференции за последние полтора года найдите что-то свое и унесите его домой и дальше рассказывает друзьям коллегам и обязательно посещая такие мероприятия в будущем у меня все спасибо спасибо еще раз доброе утро всем черно-белый тандем дует языком бей меня зовут настя сшиваю и чар директор компании компании моя нам пресно речь будет очень короткой и вас нам наверно опять связаны со словами благодарности во-первых большое спасибо кончика за то что дали нам возможность побыть генеральным партнером такой крутой всеми любимый конференций себя это вам спасибо за доверие в первый раз генерального партнера придумали и тут и тут вы большое вам спасибо это была ответственность челленж и очень было любопытно и сложные надеюсь что все получится а безусловно большое спасибо всем нам за терпение всем вам за то что мы дождались все-таки оффлайн невского формата за то что дождались живой конференции живых выступили выступления ну я буду не я если благодарю нашу dream team и компании за подготовку конференции за ваше выступление горжусь вами помашу вам там на стенде и конечно же одному из выступающих тебе удачи удачи всем выступающим сегодня легкой аудитории нам да друзья всем реально очень рад всех видеть в живую наконец-то и огромное спасибо программному комитету за то что отобрал больше сотни крутейших докладов не денни стендами едиными и конференция это не только общение это еще и самый крутейшие доклады самое крутейшее спикера поэтому ходить и слушайте впитываете новые знания и уходите более лучшими самими собой ура всем привет всем привет меня зовут максим я представлюсь этим угол и у меня сразу вопросик такое кто сегодня на конференцию fly нам смог добраться нашим сервисом поднимите руки есть люди ну не очень много да спасибо вам спасибо за offline спасибо организаторам вообще что интересно сити мобила ассоциируется у многих просто с такси у нас намного намного больше работы мы всевозможные интеграции делаем по mac мобильной доступности и по по настоящей такой городской мобильности поэтому классно что все здесь спасибо всем приходите к нам на стенд приходите пообщаться голосом поиграть рассказать про себя послушать про нас всем спасибо да всем огромное спасибо меня зовут стас образовательная платформа skillbox мы здесь для того чтобы помочь вам развить ваш личный бренд чтобы помочь собрать команду мечты и если у вас есть ваши проектов которые требуются молодые специалисты это к нам приходите на наш стенд спасибо организаторам спасибо вам всем а еще сегодня вечером skillbox наливает всем привет меня зовут алексей я представляю integrity solutions мы разрабатываем высоконагруженные сервис продукты на базе некоторые платформы о которой мы поговорим лучше на стенде с вами мы очень ждём мне будет приятно наверное большинством из вас пообщаться поговорить узнать кто вы и узнаете что вас там ждет тоже и прехождение к нам вот то что я уверен сегодня будет очень интересное для вас конференция так что отличного настроя успехов и вынести здесь как можно больше и контента который позволит вам стать лучше спасибо всем привет я повел я представляю mail.ru и представлять не только тарантул который меня на спине но еще и mail.ru клауд solutions стандартно у нас есть стенд у нас есть мелочь вы знаете что делать давайте просто послушаем классные доклады мы уже достаточно затянули и кстати первый доклад наши он будет здесь не уходите доброе утро всем верну штерна ли ты digital наш стенд находится перед этим выходом из этого зала перед входом в этот зал мы занимаемся ускорением изменений в командах в людях и культуре организации если вы встречаетесь своей трудовой деятельности с токсичностью с сопротивлением ригидность их со всякими такими вещами ну что жизнь то все равно продолжает идти вперед добро пожаловать канал мы нон-стоп два дня решаем поднимаем эти темы и решаем ваши кейсы всем инсайтов всем обмен энергии и новых знаний dice десант культуры на нашем в нашем технологической технологическом мире большое спасибо еще раз благодарю вас и спасибо спасибо большое ну что поехали мы рассказали о том как пользоваться конференцией и последнее что нам остается сделать это ещё раз выполнить традицию представить нашего бессменного ведущего лишь у образца алексей сейчас мы тут технически заминки вся и начнем отлично всем привет меня зовут станислав я буду сегодня помогать нашим докладчиком выходить во время на сцену помогать с вопросами и рассказывать о том как можно задать свои вопросы если вы нас смотрите онлайн либо как можно поговорить как можно связаться с докладчиком вот для тех кто нас смотрит онлайн у нас сегодня немного поменялся механизм кулуаров вот после доклада можно будет переподключиться в зум конференцию где непосредственно докладчику можно будет задать вопрос либо можно будет задать вопрос онлайн подключившись вместе с микрофоном с видеокамерой и задать вопрос который мы про транслируем зал и собственно докладчик ответит на этот вопрос прямо для всех в зале и поскольку мы немного задержались я сразу перехожу к нашему первому докладчику конкретно это дмитрий павлов дима привет о чем ты нам сегодня расскажешь сегодня но прежде всего всем спасибо что пришли в такой ранний час всем спасибо кто подключился к трансляции сегодня попробуем совершить невозможное пройти по сложной технической теме всего за 30-40 минут просмотреть все основные механизмы которые используются в определенные базе данных и механизмы и структуры в идеале после доклада будет некоторое понимание как эту базу написать с нуля меня зовут дмитрий павлов я являюсь вице-президентом продукта подчеркнуто камерам естественно тоже участвую в проекте апачи тренинг и работают в сбербанк технологиях земли дом команды каста мир саксэс apache игнайт достаточно давно в раза в разработке в джаве давно первая версия java на n14 на которой работу стандартный дисклеймер что я выступаю своего имени и от имени фонда почини от имени фазбер тех а любой компании то есть доклад это мой опыт и мое личное мнение не используйте услышанную сегодня информацию для принятия стратегических решений о чем поговорим ну что такое игнайт конечно если не знаете как подобрать идеальную моду среди а точнее выбрать идеальную ноду для конкретной партиции посмотрим на устройство памяти на устройство старриджа как положить данные как считать данные выглядит ряду лак в пачек найти и зачем apache и гнать тормозит сам себя начнём с очень бегала поговорим о том что продукты себя представляет прежде всего это распределенная база данных для высокопроизводительных вычислений исторически это in-memory datagrid то есть первая версия на это не умели хранить данные был просто метод put get положили данные на ноду читали данные с этой ноты и храним в памяти но я сказал распределенная база тоже верно в версии достаточно давно можем хранить данные самостоятельно диски и естественно это все сканируется если у нас добавляются ноды мы начинаем использовать новые ноты для хранения и поддерживается сиквел он конечно же есть хотя и гнать не полностью ведется как делать реляционная база данных например для вторичных индексов нельзя обеспечить уникальность то есть сказать какому то поле что она уникальна нельзя между кашами читать таблицами сделать constraint силами игнайта хотя вторичные индексы конечно же есть под ним запросы прекрасно оптимизируется и это все работает в терминах in-memory дейта города было прежде всего мы храним данные memory в нам persistent сценария таким образом становимся datagrid если мы поскольку мы можем отправлять код к данным и делать какие-то трансформации мы становимся компьютере дом все вместе это in memory datagrid с появлением persistent а достаточно давно храним на диске с версии 21 умеем это все хранить причем конечно когда у нас есть persistent каждая но да хранит свой кусочек то есть у нас нет центрального 100 раджи на который мы должны сходить причем вот 2 таки ипостаси продукта они могут быть скомбинированы у нас часть кашей может быть в под persistent най памяти а часть in memory есть ли у нас какое-то внешнее хранилище где лежит основной источник правда это зависит от кейси в кейсе кэширования конечно же дарует воркаута 0 любая базы данных позволять неважно а это может быть сторонний система это может быть сторонний сервис в кейсе когда мы поймали столь же естественно источника правда нет а кстати в кейсе кыша бывают инсталляции когда игнайт является ковшом но при этом persist оснащен то есть мы сохранили какие-то сторонние данные но при этом еще и в персис ты их тоже храним так да про игнайт овский кластером образуют топологию кольцово как кольцо из server not серверы это те ноты которые умеют хранить данные если вот так их определить а клиенты это те ноты которые данные хранить ними на самом деле клиенты толстой в этом случае являются нодами есть еще тонкие клиенты под разные языки достаточно много разных платформ поддерживается толстый клиент понятно умеет больше чем тонкий но например не входят в топология распределение как раскидать данные по кластеру определяется affinity функций в случайной ты рандеву affinity функции и про нее как раз поговорим в игнайт persistent когда я сказал каждая нота хранить только свой кусок данных нет единой точки отказа нет единой точки в которой мы упремся по производительности если что вдруг и но без persist он сам естественно часть данных хранят в мире лучше если in-memory будет больше чем больше памяти доступна на нотах тем в целом лучше когда продукт нужен или когда нужно скорость или когда особо скорость не нужна но сейчас но она может понадобиться в будущем то есть нужно скалер у имость тогда игнайта будет удачным решением введём термин кэше он нам понадобится простыми словами кэш это какое-то отображение ключ от значения джавис там будет понятно это что-то вроде java util map только распределенные с транзакциями и со всеми этими плюшками на конечно также можно смотреть примерно как на таблицу и складывать туда обычно туда складывается одна и та же бизнес сущность одинаковая технически можно положить в кэше разные сущности но на самом деле так почти никто не делает так у нас с презентацией какая-то заминка сейчас все вернем дальше сейчас технические специалисты на восстановят пока более-менее понятно пока ждем восстановления спасибо это здорово потому что дальше будет сложнее нам придется пережить многое и я буду очень рад если в конце я спрошу вы поняли и кто так хотя бы там артик поднимет руки это будет просто супер на самом деле готовьте вопросы самый лучший вопрос будет подарок книга атман иванов и фербер так что да ладно на самом деле про partition думаю это все таки highload все все знаете про партиции можно без слайдов рассказать как делятся на партиции такие независимые кусочки данных которые не пересекаются в партиции лежат n 3 января это пара ключ-значение если я говорю entry это key + вэлью ну что-то типа риккардо в таблице кэш обычно разделяется на n партиции n число постоянно его время жизни кэша mapping как мы собственно партицию на узел отправим мы выбираем на какой узел положить партицию не напрямую из ключа даже не так здесь двухуровневая affinity функции мы из ключа определяем его хэш из сша определяем партицию в которой будет принадлежать этот ключ во время жизни этого ключа всегда когда он живет в этом кэш и он всегда будет принадлежать этой самой партиции достаточно частый вопрос пока у нас восстанавливается слайда немножко отвлекусь достаточно частый вопрос а можно ли там портится распухла можно ли руками куда то перенести вы играете нет выгнать этого сделать нельзя потому что ну во первых эта ситуация не очень часто я в случае если у нас достаточно хорошо написано finiti fun функция то есть у нас нет такого что у нас хэш-код какой-то убогий он постоянно бьется воду в одну и ту же портите все партийцы будут примерно равны по объему данных и такой задачи переносить вручную партийцы вручную этим управлять не так знает этим занимается самое неплохо в этом преуспевает как у нас дела кстати с презентацией наснимали специалистов кто нам сможет перезапустить экран но онлайн презентацию видят поэтому хорошо идет она давно кто смотрит нас здесь оффлайн придется представлять что нам рассказываешь это продолжать до на самом деле у нас много много народов мы мой сеньор специалиста позвали или там лиц специалиста возможно нам нужен chef специалист я думаю что тут очень много очень хороших специалистов как минимум поэтому придется придется представлять в голове ну все нормально да на самом деле давайте пойдем дальше в портится и представим два типа каша кварте цианирование и реплицировали реплицировали кэш он будет хранить все свои данные на всех своих новых то есть ну под капотом он там все равно позиционирована но не запоминайте он нет полной реплику на всех нотах достаточно редко используется в основном для каких-то словарей где у нас очень мало данных которые нам легко записать на все ноды запись будет в этом случае очень дорогое потому что надо раскидать на весь кластер это естественность часто и чтение но редкая запись это хороший кейс например если нам нужно за joy нить в распределенной формате с какими-то данными то есть у нас есть таблица на н-надо парте цианирования на разных родах и мисс джонс какой-то таблицы возможно эту таблицу стоит сделать реплицировать хотя конечно более популярный кейс это проти цианирования кей кэш когда мы храним независимой пачки данных на нотах в играете дефолтное количество партийцы 1024 можно настраивать то 65000 по моему если не ошибаюсь если у нас хочется обеспечить надежность мы не готовы терять данные если у нас выходят какие-то ноды мы можем использовать backup backup фактор а он определяет сколько раз еще хранить эти штаны так здесь все сказал и так вот в общем про продукт наверное все игнайт распределенные базы данных предназначенные для скорости скалер у имости cached а в каком смысле распределенной map данные распределяются по узлам через affinity функцию она определяет куда-куда какая к партийцами отправиться сейчас поговорим о том что нужно сделать для того чтобы подобрать нашу идеальную ноду так и на самом деле да здесь чтобы объяснить нужно ну нужны слайды онлайн видят презентацию и в записи потом если придется пересматривать запись запись будет конец так с на трудно окей показываем на руках там там просто так если что экрана уже занимаются поэтому если есть полегче слайд можешь прийти туда одно вернуться вдруг так можно так щас секунду давайте попробуем у нас есть ключ если ключ является примитивом int бланк дабы привести его бинарный формат несложно в но это тривиальная задача если у нас ключ сложный он состоит из нескольких полей у нас есть наш бизнес объекта в нем есть силы то чтобы преобразовать его использовать базе данных нам нужно как-то к на вернуть его в баню на баннере представление и в играйте обычно это делает встроенный с реализатор так называемый бояре маршале в ключе можно выделить sap сет полей который будет отвечать за то чтобы распределять данные по нодам а кстати вы на самом деле почти все видите там внизу ничего нету так что вообще шикарно будем так в ключе выделяемся все данных это affinity ключ та часть ключа которая определяет куда едут данные по дефолту естественно неравных ключ при для это получили бинарное представление и от него можем посчитать некоторых и функцию профи широт и в принципе достаточно наивно поделить на количество партиций получим партицию куда этот ключ надо положить вот до сих пор вот эта часть affinity функции она прекрасно работает потому что количество партиций во время жизни каша as постоянно вот первая часть чуть более просто вторая часть первую часть какие-то портишь им можно назвать статической вторую часть можно назвать динамической партий shen tu not партий shantou not рассмотрим подробнее кроме ключа вот я не знаю видно ли в кроме affinity ключа такие же бинарные преобразование делаются из ключом а вот отлично спасибо огромную видно сердца все-все видно в вылью если у нас есть вторичные индексом это же и реализуем каким-то образом поля оттуда что делать с динамической частью но можно взять наивную но вообще сразу отказать ей объясню почему можно взять consist in fishing и он когда-то даже в продукте был если интересно там про него почитать ссылки оставлю выгнать используется рандеву рандеву affinity функции или hiace трендом weight хай стран давай ты мне лично проще запомнить потому что он на сном он основывается на весах сейчас поговорим про него пока про наивную что если мы возьмем и поделим коллить хэш-код партиций на количество нот пусть у нас там один cache partition и запишем номера партиций просто от 0 до и так далее и посчитаем остаток отделение на 3 на 4 и получим вот что синяя часть она полностью поменялось у нас все почти партиции поменяли свои ноты на которых они должны лежать это значит они все должны переехать между 7 и поэтому наивный подход сразу отказать эту проблему минимизации ребаланса решает михай страндом weight и посмотрим на примере одного каша и 1 партиции для некоторого каша возьмем его айдишник возьмем park shin айтишник и из конфет конкатенировать not айди для первой ноты для второй и так далее ну что это за едешь не кину в принципе int и какие-то но та иди но не неважно в принципе любые любые данные можно использовать потому что потом мы посчитаем от этого хэш то есть мы возьмем комбинаций украшайте с одной нотой с другой ну да и так далее посчитаем ряд лесов вот этот ряд весов он нам будет говорить о том насколько для нас для этой партийцы 0 но до привлекательно насколько она нам идеальная пара одышка ноды может быть например тот же самый айпишник а вот получили псевдослучайный вес дальше дальше можем отсортировать все полученные веса и вот в нашем случае для но дойди вес на то есть вес оказался мы с максимальным то есть наша partition partition 0 поедет на первую ноту это наша идеальная пара максимально привлекательно и если нам вдруг нужны бэкапы то есть нам нужно хранить праймари данной и какие-то backup а еще то можем взять серебряного и бронзового призера вот этого соревнования и сказать но как будто ты нам не идеальная но да но на случай может пригодиться храни бэкап и вот она не приключилось сразу на еще один слайд и как же минимизируется ребаланс если входит еще одна четвертая но до в нашем случае но 3 что будет на самом деле ответ зависит от того насколько она вдруг окажется по весам привлекательной для нас и это естественно не рандом его этот вид псевдослучайный вес но его сложно предсказать это действительно как будто рандом поэтому победа вот этой новой ноды в соревновании за за нашу идеальную ноду она вероятность победы будет где тает на 4 то есть для каждой отдельной партиции для каждого куска данных только 1 4 вероятности что новые надо будет ее новым мэром про affinity функция тоже немножко неточно но я немножко вру потому что affinity функции она определяет туда куда в идеале мы должны поехать это процесс нему ментальный в то есть мы может идеальную выбрали но еще вещи не перине перевезли поэтому на самом деле по факту мы смотрим по таблице какие какие партийцы где сейчас лежат процесс переезда тоже вы гноить и естественно предусмотрен автоматический называется ребаланса это когда мы выбрали какую-то новую ноту для партийцы три и семь нашем случае победила но до 2 мы на нее начинаем переезжать и в но до 2 начинает затягивать данные с остальных нот при том что важно еще понимать этот процесс может быть еще не быстром потому что у нас индексы по вторичным полям они жарятся на всю партицию то есть partition строится по пора им или ключу а что там то есть если у нас праймари ключ допустим синтетический клайн пойди а вторичный ключ номер паспорта какие там будут номера паспорта с общим сложно понять и поэтому индексы строится по всем локальным партийцы когда у нас уезжает partition с одной ноты и приезжает на другую в старой ноги мы должны почистить в энтри в этих индекс h1 добавить на таблицу партийцы где реально лежат короткие партийцы в каких сайтах можно смотреть просто как нам эту то есть что-то типа ноту map и все надо об этом знать так над самом деле все наверное про ой-ой-ой в секунду эту у меня как эта проблема не как будто запала кнопка перемотки сейчас восстановим так перекрывает видно уже отлично спасибо про глобальный кластер на этом все двухуровневая finiti вы знаете используется статическая и динамическая часть статической остаток от деления второй уровень хай стран давай посмотрим более прицельно на конкретную ноду на устройство памяти в ней на устройство персис танца как собственно найти значение как его обновить сначала как найти значение так у меня почему-то по-прежнему западает кнопка наклейки ok давайте попробуем мышка переключать в что такое посмотрим на одну моду на одну партицию и нам нужно найти какой-то кивали прежде всего ключи вылью также си реализуется бояре марша lerom в бинарный вид но зарезервировать в файлах мы говорим здесь про persistent определенный офсет про под них наверное сложно целью может худеть увеличиваться и так далее поэтому изначально можно поделить поделить на все снова у нас да да рассказывай дальше но отлично сейчас прям починит на самом деле сейчас можно даже почти без слайдов рассказать давайте поделим блоки в смысле поделим данные на чанки пищеблоке одинаковой длины прежде всего это делается потому что все жесткие диски так или иначе блочное устройство мы пишем 1 байт на самом деле запишем в худшем случае один блок пишем два байта в худшем случае два блока и так мы приходим концепция организации памяти на ноги который пользуется играет в терминах на этой дуры был моим арину синоним ps memory там надежно ли страничной памяти блог или страница обычно 4 килобайта для файловых систем и для хдд на практике другого не встречал может вам встречались но если вдруг встретиться на практике блог по боль что возможно вы найти тот тоже сделать страниц по-больше чтобы оно кратно было нам надо каким-то образом связать построить структуру нам прежде всего надо научиться связывать странице здесь вы знаете все максимально просто в устраниться есть номер от нуля до бесконечности они пронумерованы 1 2 а если к этому номеру добавить айди партиции которой относится эта страница то мы уже получаем некоторые пи джей ди который идентифицирует страницу рамках кэша а если еще и кошачьи добавить то вообще в этом full поезжай и которая в рамках моды уникальный идентифицирует страницу если вот такой пи джей ди вписать в определенное поле страницы то можно сделать ссылку между двумя страницами причем это что-то типа по интера но этот принтер будет переживать сброс на диск и в установку с диска потому что это просто номер страницы это никакой там адрес ла-манш памяти или новым в случае джавад conservancy ли это просто достаточно постоянный адрес как только мы научились сделать указатель и мы можем построить в принципе любую структуру и играет использовать старые проверенные b плюс дерево которая рид optima ест если сравнивать с сэмом которая в которой ну может быть чуть сложнее писать в моменте потому что мы как-то очень случайно будем писать в но зато читать из него здорово потому что на него можно смотреть как на линк от лист и из упорядоченных not у порядочных значений по которому может бежать мы можем бежать в случае fusca на по этому листу или если мы говорим про индексы при при силу в случае рейнджа франческо на нам не надо там ходить по нескольким деревьям если говорить про первичный индекс то он строится наши шахты тот ключа вторичные индексы по полям у там на самом деле ничего интересного пока нет по полям ключа мы и строим по вылью или по старту в или поначалу вылью сына все были в яндекс не влезай про дерево это in our на и дерево в котором перемежаются вершины и линки здесь почти все видно там посередине там тоже блоки в каждом блоке целью между вылью нас линки и линк нам указывает на странице направо и налево относительно каждой вылью мы поднимаем страницу смотрим на вылью интересуемся по ней если искомое велю меньше идем налево больше идем направо то есть на самом деле у нас процесс похож на обычное бинарное дерево в только у нас несколько вершин в конечном счете мы добежим до какой-то конечного листа почти все видно вот здорово да бежим до листа в котором будет вылью то есть наше значение которое мы искали мы можем его почитать если говорить в конкретных примерах с конкретными значениями то вот статическая статическая демонстрация такая давайте я попробую сделать динамическую сейчас переключусь на на браузер если можно вы видите пожалуйста браузер вот отлично это сталь сайт сан-францисского университета там много на самом деле разных алгоритмов давайте начнем ставим допустим какое-то значение 6 а у меня уже чет что то есть дерево ну ладно все равно вставим вставили значение 6 у меня здесь максимум кардинале тему дерево стоит 2 то есть в нем может быть два в илью и 33 link если вставим ещё там значения 5 допустим то мы пойдем в страницу расщепил и в каким-то образом давайте еще поставим сразу 1 и 3 у нас будет вот такое красивое красивое дерево нет не очень красиво но но все равно таким образом в при раб то есть на нижнем уровне есть все валью так сейчас я попробую еще увеличить немножко масштаб чтобы это было чуть более видно чуть чуть меньше даже меньше вот так вот наверное так но можно еще 0 вставить он он явно уйдет у нас в первую страницу что еще можно вставить ну наверно так оставим то есть в нижнем уровне у нас все вылью которые есть таблицы а на верхних уровнях они еще повторяются то есть такой link at лист с шорткат амину почти скит лист map но в целом естественно отличается от него можно еще что-нибудь поудалять чтобы посмотреть что произойдет вот пятерку удалим с удалением как когда происходит удаление дерево схлопывается когда происходит добавление там операции сплита происходит так что мы ещё можем добавить давайте семерку добавим и и прям восьмерку добавим чтобы у нас еще еще уровень был она еще уровне не получилось потому что нас картина лети хватает но более менее понятно как она строится но и таких операции вы знаете происходит огромное количество так сейчас вернёмся к презентации да все b плюс деревья используются для поиска разобрали как дойти до странице найти нам нужный ключ теперь посмотрим на запись на диск обещания надо выполнять доклад называется до записи на диск надежная или страничную память состоит из регионов как сконфигурируем а каждый регион он содержит ряд страниц они имеют разный тип какие-то дата странице какие-то страницы бы плюс деревьев какой тип где лежит мы заранее предсказывать не можем они все выделяются в перемешку и и более тем они могут более того они могут перерождаться в новый тип то есть раньше это была дата страница и она переквалифицировалась у страницы хедиры понятно у определенного типа странице есть тоже свои гидры и если посмотреть на примере дата страниц это в природе у нас будут уже лежать наши наши entry наши ключи и значения причем значение заполняются с конца в начало а в начале есть внутренний указатели так называемые в терминах игнайта айтемы которые это 2 байта вы указатель который говорит странице вэлью лежит там и это нужно для того чтобы как раз в или могло худеть там а набирать и мы постоянно ссылались на один и тот же на один и тот же ой там страницы а этом лежит всегда в одном и том же месте down основа выключилась презентация смысле выключился экран зале как определить как определить куда дописывать как определить где есть нужность нужный объем свободного места для этого есть та же структура free листы которая является отображением каспийском страниц в которых есть определенное количество свободных памяти свободной памяти с точностью до восьми байт то есть когда нам надо дописать в отлично теперь видно когда нам надо дописать двадцать три байта мы сразу понимаем что нам вот во второй пакет этого free листа берём от туда страницу что-то дописываем куда-то переставляем во фри листе эту страницу таким образом нам не надо не надо перед перебирать постоянно страниц куда дописать с короткими объектами надеюсь понятно с длинными история похоже только мы из длинных собираем уже некоторую 1 односвязный список когда конец одной странице нам указывает на продолжение объекта причем неформатный вот этот кусочек мы тоже берем is free листа чтобы максимально утилизировать память если смотреть на регионы более верхние уровни если разложить вот у нас наша перед перемешку страницы в какую-то структуру то мы увидим примерно и b плюс деревья у нас образуются и free листы но здесь упрощения естественно не 25 процентов более гранулярными гранулярный делению в free листах ну понятно что в да как это все хранится в памяти вот еще что то что нужно обязательно сказать в памяти в память это поднимается в достаточно рандомизированном порядке в сегменты сегмент это набор страниц памяти у которых есть определенные хэш-код у их айтишников хэш-код условно дает 7 и они все пойдут там 7 сегмент количество сегментов в раме равно по дефолту можно настроить равно количеству цпу то есть чтобы у нас разные коры не но максимально распределились но такой строй pink происходит между страницами в памяти чтобы мы максимально эффективно использовали меньше били за один сегмент в естественно слинки которые мы обсуждали они кровь сегментные то есть они никак не зависит от сегмента и могут ссылаться 11 на другой до сегмент таким образом это то каким где именно у нас строения страница доступна в памяти так на сегмент это на самом деле не только хэш-таблицы которая по старой плена по одному плохо skoda где странице это еще способ но без картинка на сложно будет понять но это еще внутри каждого пакета сегмента лежит хэш мапо с открытой адресации по которой мы пойди странице понимаем адрес ван север то есть мы берем пдд считаем 1 хэш-код выбираем bucket в боккетти выбираем там хэш мапу это же за константное время на находим адресу уже конкретно иван заяви куда сейчас это странице пони поднята причем эта штука не только разыменовывает нам поезжайте в адрес в once i even она еще позволяет быстро понять какие страницы у нас на руках то есть она же может быть persistent мод и в этой таблице мы можем быстро проверить а у нас есть вообще такое иди или нет посмотрим еще на изменение то есть как как изменяется страница тут с нам слайды на самом деле не супер нужной как изменяется страница и записывается на диск конечном счете в играйте mapping айди жки страницы в адрес солнце и вам происходит а там arm на с захватом локону эту страницу пока мы держим этот лог мы не скинем эту страницу мы и не не запишем на диск не выкинем из памяти то есть пока она живет лодку нас живет-адрес это все синхронизировано когда мы перестанем со страницы работать мы локоть должны опустить в саму страницу мы идем через набор утилит ных методов которые реализованы выгнать и но в конечном счете они все попадают в сан мескан сейф для для кучи примитивов такие методы есть но еще можно обернуть нашу страницу с дайрект буфер в кровавый и работать через его api как происходит в запись немножко новые темы дана без лайков может сложно понять в общем если представить stack trace в верху стектрейсы будут наши классы которые отвечают за вот вы в этом все вы все что угодно файл и а дальше мы используем файл чем в в райт файл финал это java api для низкого уровня низкоуровневые работы с файлами в файл channel в райт он проваливается в его util если открыть код и а у тела можно обнаружить что там проверяется просто наш буфер который мы прислали инстансов he буфер ну ja вести хип есть мэнш память сам мескан сейф и вот это все и сам вниз в конце iv это дайрект буфер то есть то что у нас ван - памяти хранится и java порт проверяюсь что если у нас пришел байковый массив типа their мы можем просто взять адрес этого буфера и отдать а в операционку то есть на самом деле вот эти странички которые мы рассматривали в durable mamoru у них есть сегменте определенный адрес им и игнайт просто в операционную систему отдает фактически этот адрес и оттуда происходит запись но естественно пока держится лак никаких копирований не ничего в этом плане не производится окей рассмотрели как то более менее странично организована как странице друг на друга ссылаются кое-что используется бы плюс дерево что и структура которую мы построили она в целом переживает спрос на диск и теперь можно перед типы поговорить о том как устроен сторож и в рай тычат лог кто кто знает что такое в right ahead лог здорово примерной очень даже треть наверное даже треть наверное тут принципе пока слайде нужный но скоро ts core прямо не нам нужны будут там там есть обсудить в рай the heat look ahead потому что мы пишем в перед с запись с нам в основной сторож на этом этапе когда мы пишем вал странице даже они не записаны никуда не есть просто в in memory в видите да типа j после того как запись в right ahead лоб прошла мы можем отпустить транзакцию сказать что он тут прошел транзакцию закомитить а уже запись в основную сторож произойдет потом как-то по расписанию либо по количеству до грязных страниц произведет произойдет процедура чекпоинта в right ahead лог дает нам из эйсида он нам дает и иди нам дает durability даже если все упало там и поэтому логу можно мне его посмотреть и понять по операции она прошла она не прошла она там прошла частично как to eat a more ность мы можем понять вот эта транзакция на таки случилось или нейтрон не случилось и сделать либо все либо ничего в играйте в right ahead логе есть два типа записей физическое и логическое на логическое то про нашу бизнес сущность допустим у нас есть юзер который в какой-то момент заходил messenger то есть юзер last last life than last visit at times с тем мы хотим его записать мы мы делаем сет и там put в кэш в в вал попадет логической запись что у юзера поменялся time spent сделай такую операцию а есть еще физическая запись который говорит о том какие страницы поменяли как своем значении то есть п с таким-то айтишником по все тут а кому-то теперь имеет вот это такое новое состояние в какую-то попадет этот timestream зачем это все нужно рассмотрим чуть позже теперь попробуем все вместе рассмотреть в как происходит операциях я смотрю у ведущий нас улыбается потому что у меня в зале нем по-прежнему нету нету экрана а там такая схема пока без схемы ключ в из него выделили affinity ключ из него выделили партий шин из него выделили ноду таким образом мы понимаем куда нам идти этого каста мира юзера обновлять ему таймс т.н. придя на конкретную ноду мы можем во-первых захватить лопну эту янтру можем записать логическую запись в в рай ты setlock вот там вот внизу от этого тура это хит лак и логическая запись этого зелененькая отлично после после этого мы идем в b плюс дерево которое мы посмотрели как работает и ищем конкретно конкретно где какие надо произвести правки потом возможно идем по даты по играм если длина объект находим нужную дтп модифицируем его и пишем в рейд этот лак что вот эта страница модифицировала с определенным образом после этого можем вызвать файл channel force или который на самом деле в пасек пасек совком api переносится в sing или of date a single а кто знает в чем отличие между ними я книга я мне кажется слышал правильный ответ метаданные данные спасибо действительно действительно так игнайт использует сколько я смотрел все таки да to sing без метаданных вот насколько часто он его использует зависит от модов все-таки после каждой транзакции вызывать sing с диском будет очень дорого почему два типа записей если мы смотрим на в right ahead лак упавши ноты которая не писала сброс на диск не писала чекпоинт она в общем то основное сторож не меняла мы можем посмотреть на это и скажи основной сторож прекрасном состоянии с ним все хорошо давайте просто не докатим операции поставим каста миру таймс темп нужный и таким образом у нас все страницы поменяются случай простой если у нас но до в момент крыша писала писал основную сторож то что она туда дописала там могут быть 0 это может быть мусор там может быть да вы всех все что угодно в этих страницах которые в этот момент писались вот здесь на сцену выходят физические записи по которым мы бежим по в right ahead логу и в те же места основного 100 роджер прописываем нормальные правильное значение но естественно самцы в red heat look там сердце control но в нашем случае в нашем случае у нас в рай ты хит логе были страница 1 из 0 партиции 13-14 и и из первой партиции ему все их запишем в чем есть полностью пшат когда мы полностью страницу пишем есть дельта чтобы канал экономить память то есть не все изменения они записывают с полным snapshot am страницы в вал что же происходит получается в случае 1 пуд of cash мы пишем одну логическую запись одну физическую запись если у нас еще поле поменяла значения нам все листы надо изменить они же тоже persist от если у нас произошло там если у нас длинный объект то у нас несколько обновлений несколько страниц поменяют свое значение если у нас еще индексные поле за зацепилась то нам еще надо индекс поменяйте в этом индексы тоже проезжает произойдет то ли операции расщепления слияния еще чего то там может быть там сплит мертвый счетом 2 3 5 страниц изменится еще под капотом там мы это не обсуждали там модификации трек трассирую ца и вот это все представляете сколько нужно изменить страницы сколько надо записать данных для одного простого в принципе пута хорошая новость том что последние версии более-менее это оптимизируют то есть если у нас есть физической и логической запись они а не шарят между собой повезло то есть одна на другую ссылаются так сейчас извиняюсь но тем ни менее нам надо достаточно много написать на диск написать во вред и hotlog имеет ли смысл каждый раз говорит диску за синкай все файлы описательно прямо до железа после каждого каждого put a tape так можно делать вы знаете это мод i've seen который самый хардкорный он переживает вообще все падение ноды и падения с после падения сервака падения операционки принципе все что угодно ну естественно он синкай все каждый раз но он очень дорогой по дефолту стоит такой режим логан ли который дает управление операционки то есть он говорит операционки в райт вызывает в п в рай нет воле фрейд умру в истории поверит в валя вызывает в рейд и операционка разбирайся сама в принципе разбирается если процессы на это за крошиться то все прекрасно работает если закрыть и сама операционка но тут может потеряем какие-то последние записи самый расслабленный режим background ну просто по таймеру сбрасываем там 1 3 секунды что ну что происходит что происходило последние три секунды в худшем случае мы эти три секунды можем не не потерять если у нас был краж по ур лосс на примерно на серваке естественно я говорю в голову вал вал это не один файл это набор файлов или сегментов и причем сегменты делятся на те в которых с которыми мы сейчас работаем них опишем записи и те сегменты которые нам в принципе уже не нужны мы их за финализирован ими очень здорово что сейчас работает экран потому что без него сложно понять верхняя work директория в которой у нас сегменты пишутся в нашем случае пишется третий сегмент и worker и добавляют добавляют туда рекордов из периодически туда сбрасывают сегменты по дефолту 10 штук в word директории 64 мегабайта размером но это все естественно настраивается и моей цикличный бежим по этой ворот директории записываем в последней когда мы записали мы отпускаем сегмент и он доступен фоновому процессу архиве rar архиве забирает сегменты и перекладывает там откладывают в папочку архив но папочка архив может не очень удачно названа потому что ее периодически удаляют в считаю ее ненужной хотя на самом деле естественно она может пригодиться когда чистить архив есть старая настройка по числу чп поинтов есть более новая настройка по размеру волок то есть мы можем настроить коко мы готовы под bright i hit лог выделить просто просто волгин мегабайта гигабайт провал поговорили некоторые весь такой оперативное некоторое скользящее окно над нашими последними операциями думаю уже сейчас понятно что в базу лишние выписать не стоит это касается естественно не только игнайта любой базы данных и если у нас есть pdf-файл наверное это не самая лучшая идея сразу его кидать в базу или если у нас есть какой-то string который на самом деле in the наверное лучше не том же записать но я понимаю что я глупости говорю и вы так не делаете но бывает что что возникают такие кейсы вторая идея которые уже можно в принципе из этого доклада вычленить что в right ahead лак и основной сторож их можно разделить чтобы диски тормозили независимо и про основной скорость как раз и поговорим как она устроена здесь принципе не очень сложно вы знаете организована каждая partition to find каждый кэш это папка в right ahead лог он общий для всех кашей но это понятно потому что если бы это было не так мы бы не могли сделать крост каштан анзак цию естественно вы знаете не поддерживаются плюс индексы это отдельные файлы и как мы уже обсуждали они жарятся между всеми локальными партийцами то есть они не принадлежат к определенной партиции если нам что-то надо поднять в оперативную память из файлам и мы сразу можем понять из какого файла из какой портите нам нужно поднять данные и обратиться конкретно к этому файлу аврааме естественно все каши и партийцы они вперемежку могут существовать как они там сегментах разлом разложится непонятно читаем естественно методом basics basics методом перед мы рассматривали запись когда мы делаем pv райт здесь парит в каком месте файла читать здесь принципе тоже ничего сложного никакой магии берем индекс который мы ввели в самом начале умножаем на размер страницы вот нам и офсет после оксовский метод перед будет нам читать определенное количество байт с определенного места он не не работает курсора она в этом случае файл нарисована вертикально то есть у нас есть страницы там не все начинать мета поищи tracking поезда ты вот это ну и так далее по возрастанию индекса мы можем сразу считать нужную страницу и и с ней начать работать то есть файлах нефть не все так сложно как в этих сегментах там никаких хэш-таблицы не надо мы сразу узнаем куда идти за диском куда идти за страницы на диске чем pointing процесс сброса на диск мы не говорили о том как записывать мы в говорили что что запись происходит а как именно ну либо по таймеру либо потому что мы запачкали весь регион первый первый шаг мы знаем какие страницы грязные у нас есть сет на это короткая пауза которая полностью останавливает все операции над но дай на копирование этого сета в подушку то есть у нас есть от грязных страниц и мы из него копируем их сет в то что мы должны сейчас сделать это наш план на день когда сбрасываем ставим флаг тети в ноль и удаляем из коп а за сколько записываем их страниц в принципе пока я думаю что понятно на посмотрим для поверхности еще на примере запишем 2 страницы в два файла с первой страницы в принципе все понятно мы дошли дона до нашего дела списать страницу 1 пишем и все хорошо страница 13 счастлива и потому что мы ее писали в файл 1 но при этом кто-то захотел в нее еще записать то есть там уже модифицированные данные грязные которые надо списать на диск естественно нам нужен срез начала чекпоинта нам не нужно то что нам еще worker у нее напишет то есть за неё был получился какой-то конфликт конфликт решается копиям в райтон это страница берется откидывается в отдельный сегмент памяти check point пул который как раз таки и конфликтные страницы и хранит в этом чекпойнт пули как раз лежит то что мы должны сбросить и check point ул он по памяти ограничен то есть он не бесконечен может так случиться не анлоки что мы очень много используем пишем вот именно именно те конфликтные страницы которые только что пошли в check point поэтому если вдруг мы начнем заполнять эту память то включится экспоненциальный букаф играет будет просто нажимать на тормоз он будет тормозить ну да и это к вопросу о том как игнайт тормозит окей разобрали 100 рассчитаем парит пишем по в райт в конце f fd to sing в для волос для чипа индиго естественно тоже и тут уже можно догадаться что чек pointing как так как он мы не предсказан не можем предсказать какие страницы грязные это рандом запись это рандом в райт то есть волку в момент работы кластером и пишем быстро мы делаем секвенцию когда мы делали чик-чик pointing это случайная запись какие выводы но наверное если есть возможность ставить ssd достаточно очевидный вывод не использовать сразу несколько нот на одном игнорить и потому что у нас одна в виртуальную not to knit на не использовать несколько нот на одном серваке то есть мешает железный сервер на 8 но тогда это будет тормозить еще как потому что кучу надо сбрасывать ее случайной записи и тут две ноты будут случайную запись сделать опять же говорю простые вещи но такое случалось на извести и еще о том как еще и гнать тормозить сам себя такой же педаль тормоза есть для всего рейнджа для всего нашего региона если у нас бежит check point мы спрашиваем где на диск странице прилет и скоростью то мы можем предсказать когда примерно этот процесс будет закончен когда мы закончим этот чек-поинт если у нас скорость пачканья страниц му татарам выше она обычно выше потому что память то изменить гораздо проще чем на диск потом скинуть игнайт опять-таки нажимаем нажимает педаль тормоза и не в зоне over спида он будет тоже тормозить worker тормозить worker и чтобы они не работали быстрее быстрее чем мы сбрасываем на диск но теперь ты тогда когда вы увидите файл layout игнайта или другой базы данных я думаю что вам уже будет гораздо проще узнать какие-то знакомые вещи естественно там вы знаете папки настраиваются очень многие мы не рассматривали какие-то бинарные метаданные каши и чекпоинт маркеры на которые можно смотреть просто моим танец темпы но по-крайней мере это узнаваема как вы в этом не пишите в базу лишнего длина в байтах все еще имеет значение принято говорить пусть железо так опытом и программисты программировать как умеем будем но на самом деле с точки зрения база это не так лучше разделять воле повторы не использовать одну ноту но используется создает а поговорили ну и самый главный вывод который я бы хотел чтобы вы сделали не пишите свою базу данных это это сложную если вам все еще хочется в этом разбираться хочется хардкора вот-вот чтобы разбираться ещё более подробно естественно многом они рассмотрели присоединяйтесь к сообществу apache игнайт в на слайдах ссылка статья как как кантри beauty выглядит в ну и ссылка надев лист оставлю несколько ссылок ну понятно на игнайт на то что мы рассматривали сегодня чтобы спокойно посмотреть как это все устроено team там чуть больше информации и последняя ссылка на визуализацию алгоритмов очень залипательная тема там красно-черные деревья можно подстраивать строить в общем весело спасибо ребятам за это вам огромное спасибо что послушали если будут любые вопросы пишите на мне на почту просто погуглите дмитрий павлов apache и больше кейсов использования игнайта более такие жизненные жизненные простые доклады от к костюмеров которые его используют можно послушать на игнайт саммите совсем скоро бесплатно но требует естественной регистрации можно потренировать он английский добро пожаловать на юзер лись с вопросами если какие-то проблемы возникают или надевали есть если хотите что-то внести и спасибо огромное тогда к вопросам дим спасибо тебе большое у нас для тебя есть небольшой подарок во-первых грамота то что ты здесь выступал и я так понимаю что это фирменные худи 2021 10 2 просо будет перенесена из зала поскольку мы немного задержались она перейдёт сразу в зону цифровых кулуаров это прямо вот здесь вот за дверью там онлайн те кто нас смотрят тоже смогут задать свои вопросы никаких проблем нету и ребята из зала тоже могут подойти задать свой вопрос и те кто смотрят онлайн его увидят и и может быть тоже кстати давай давай спросим у аудитории удалось ли понять вот мне мне главное чувство кому удалось понять хоть что не насколько был легкий доклад или сложный удалось это очень здорово здорово апатично сдадим спасибо тогда до встречи там и вас на конференции сейчас на экране те кто захотят остаться смогут посмотреть тех толку от компании баду конкретно технолог александра барановского вот он будет идти около 8 минут и после этого мы будем готовиться к следующему докладу дедушка всегда говорил мне как важно трудиться и заниматься чем-нибудь настоящим где должна о чем говорит он был агроном и всю жизнь занимался сельским хозяйством и я продолжаю его дело все начинается с дети еда которую мы одежда которую мы носим лекарства в которые нам так необходимы сельское хозяйство обеспечивает нас всем даже удивительно как многого мы добились так каждый день мы создаём что-то новое изобретая планирую есть и мне нравится быть к этому причастна ведь когда ты занимаешься чем-нибудь настоящему это всегда ну привет я артем я бывший редактор хабре сейчас ведущий подкаста мы обречены познакомиться привет я саша 5 бит команде могу занимаюсь processing дано наша задача взять всю всю всю статистику доставить ее но нет где у нас есть ты говорил что-то про культуру кода в чем ваша особенность что такое используйте культура в моем случае я имел ввиду именно подход я приверженец теории что не бывает ни возможных решений не бывает ни не интересных решений во втором этом можно найти какую-то составляющую которое понравится либо конкретно тебе либо в целом команде и на этом драме можно делать безумные вещи выстраивать безумные системы которые будут потом удивлять весь мир если о них рассказывал мне скучно не будет никогда важно это просто понимать если идти с этой тенденции с этой этим пониманием дробить людей-то использованием этого все можно построить прямо гигантскую интересную систему расскажу что-то конкретно что-то между под этим безумен тут безумными не скучно вершина да без проблем одна из систем которые мы делали это аномалии то также система поиска аномалией на графику тем они не новая но мы и решили для универсального видит для миллионов графиков это собственно и будет темой мы доклады я буду рассказывать именно о том как какие запросы мы говорим не о самой системе а ее подходе мы здесь очень много веселились со всякими научными статьями с поиском информации у нас не было изначально там большого опыта построения подобных систем но мы взяли cliff house мы взяли и реализовали на чистым холстом вы сколько ни численно кирха у нас на этом используем реализовали модели предсказаний воткнули туда сотни миллионов графиков и она считается процессе с минимальным шагом в 10 лет и это все еще при этом не на самых больших страх ok проект расскажу подробнее там сушат кузов еще такую ты берешь в себе такую силу для такого подхода ну просто люди когда начинают чем дольше работать в индустрии тема не давайте возьмем приняты давайте будем делать так как надо не давайте не будем лезть за пределы того что за что обычно не лают на тип откуда взять себе drive чтобы делать реально не скучные безумные постоянно придумывать и изобретать но здесь есть такая знаешь фраза андрич то есть когда ты находишься на самом краю индустрии это не какое-то физическое положение что вот я проработал 20 лет теперь я могу ступить первые ряды и начать драйве нет это не так происходит так как тогда когда ты начинаешь падать на индастри лавал структур киты делаешь работу при ее сделал поставил галочку без мы я умею делать или рассказал об этом какой-то доклад до что нового изобретена что нового продвинут как продвинулась инфраструктура в indis индустрия в целом если ты просто сделал то же самое что делали другие ведь намного интересней погрузиться во внутрь какой-то новой вещи взять что-то новое как-то по-другому повернуть под новым ракурсом сделать какие-то новые выводы используя те же самые инфраструктурные вещи о которых говорят там очень многие но повернуть и по таким углом под которым никто еще не поворачивал увидит что это работает может быть немножечко где-то подкаст и не без этого но результате добиться того что никто никогда не делал и благодаря тебе благодаря тому что ты привнес и рассказал о чем ты с подвигал кого-то двину двинуться дальше расширить горизонты своего восприятия мира но сейчас узнаешь как думают что особенно чем больше работал чем больше изучают вещей таки да все уже изобретено и все что изобретена довольно тривиально и придумано не лучшим способом да и особые улучшать никуда давайте просто этим пользоваться и не собственно можно так сказать если взорвать возьмём ситуацию десятилетней давности начала тогда тоже говорит но тогда не был отлетался не было как не было куча языков которые сейчас используются повсеместно да тогда уже тоже было все изобретено но это не так мы двигаемся мы развиваемся и когда-то в древние века люди считали компьютеры что необходимо я не помню точную фразу что по-моему 2 мегабайта оперативной памяти будет достаточно всем и люди в это верили вопрос ваша вера если вы не будете подвергать свою веру сомнения не будете критически мыслить а действительно ли все изобретено а действительно ли нельзя эту конкретную тузов улучшить или как-то повернуть под неизвестным углом таким образом она начала приносить пользу еще где-то без этого да можно действительно сказать что все изобретено сложить лапки просто начать это использовать а можно попытаться но что сейчас думаешь про индустрию вот она сейчас ты ее видишь что тебе мне кажется где надо изобретать где как слабые места чтобы ты стал понять вот даже в тех подходах который вы построили той системе который вы построили где те решения где тебе приходится идти на компромиссы такой блин здесь не круто надо здесь сделать круче вот этого не хватает этого не хватает да я понял вопрос на самом деле это абсолютно нетривиальный вопрос можно выстраивать что-то новое во всех сферах и очень многие это делают тот же самый house продолжает развиваться и они решают основную нашу боль а если уже не решили честно не могу точно сказать это звуки пир к примеру за кибер им боль у всех наших последний бой к нам приходил он киллер звуки первым так вот потому что он немножечко разросся в памяти всего лишь 16 гигабайтами каждая система невозможно сделать совершенно нету совершается это только цель к нему к ней можно стремиться да мы сделали мы процессе миллиона графика но мы это не делаем бесплатно мы это делаем за счет конкретно известных там ресурсов которые мы на этот раз есть узкие места которые для нас являются проблемы тоже за мы самый звуки пир для нас эта проблема невозможно постоянно горизонтально масштабироваться соответственно рано или поздно придется дальше развивать эту штуку чтобы оно было быстрее и эффективнее поэтому нет абсолютно во всех сферах есть куда расти только для того чтобы это сделать необходимо обладать знанием и опытом в этой сфере конкретно в нашем случае да мы очень не хотим избавиться в закипел у нас практически к любой сфере при так или иначе последовал на привязан и он доставляет большую часть проблем вы уже пытались пока нет малая но то хотя бы когда-то в этом думаешь как ты думаешь какую сторону двигаться как избавляться я думаю именно менять собственное решение решение которые были сделаны у нас таким образом чтобы и покрыть задачу и меньше ушатать за кипр поскольку он нужен нам о последованном нас нет задачи сделать его идеальным то есть нас нет задачи на него тратить и собственно нас есть задача именно нашу проблему решить а ее можно решить в том числе к примеру уменьшив нагрузку на звуки пир предыдущую идею которую мы реализовывали она это не учитывал будущее будет когда вы строили вот система которая рассказывала у вас были какие-то камни преткновения из-за чего то вы спорили чтобы сложного всего проблемный да наверное вот лично для меня это было проблема ранжирование аномалий я говорю конкретно про аннабель это так что систему которая оля для чем нужно объяснить проблему комбинаторного взрыва у нас есть примеру там график с параметрами нас есть страна оператор пользователь там и еще с десяток разных параметров каждый из них если примеру 10 параметров каждой из них по 100 то мы получаем 10 в 20 комбинации параметров и каждый из них может потенциально обладать цифры это безумные объемы и с этим как бы ну никто работать не будет но как при условии того чтобы примеру определяете 99,9 процентов всех значений то есть три девятки это вас немножечко нем много мало но 10 в семнадцатой аномалий и вот как как найти среди них аномально естественном есть ложноположительные естественно там есть обычная нам они естественно там есть изменение ожидаемые которые как бы попали под аномалию но это все нас ранжировать до цифры естественно взяты с потолка никто не работает с 10 семнадцатой степени графиков потому что ну это прям очень жестко так но даже с 1000 графиков проблема ранжирования она стоит очень остро можно сделать самый простой и понятный способ это когда вы берете и говорите что чем больше цифра в графике и реальным тем важнее нормально но в этом случае какой-нибудь интегральный график пользователей во всем мире скакнет на полтора процента вверх и вы визуально даже дома нет ну да скок ну ладно но это будет самая большая аномалия за счет того что цифра само по себе больше нежели так дела у вас какой-нибудь стране количество пользователь упала в половину там это катастрофа поэтому аномалии ладно муки будем жить дальше и вот именно эту проблему я пытался решить это было две недели когда я просто среди с гигантским объёмом данных и просто писал запросы разными вариантами разными случае вытаскивал какие-то дополнительные параметры метрики из данных для того чтобы хоть как-то вытащить ну и вкратце примерно как что было завершение я получил коэффициент немножечко в попугаях но коэффициент который говорил о разводе графиков графика предсказаний и графика реальных значений использую его из используя нормализацию на общий вес графика отношении его числа к общей сумме всех графиков внутри там какого-то report и еще нескольких других коэффициентов я получил более менее функцию которая мне позволит выдать цифру по которой могу сортировать и это цифра мне уже сделала что график с большим разлет am графика с большей аномалий визуально именно визуальный будет выше чем график с меньшим визуальным разлет успехов вам в работе над этим до строить систему изобретает посему больше надеюсь вы избавитесь от руки перо и сделать это отличные других научить и тоже будем посмотреть так продолжаем нашу сессию 5 зала и сейчас во первых я бы хотел попросить тех кто с нами во flyme зале одеть надеть маски пожалуйста вот хотя бы на какое-то время да мы должны следить за безопасностью друг друга и я приглашаю на сцену 2 докладчиков с докладом как мы change дата коптер делали вы видите это на экране также на сцену василий тюбик и александр доволен пожалуйста прошу рассказывайте коллеги привет начнём немножко с рекламы тарантула да у нас собрана и все материалы по докладам вот поэтому qr коду вот меня зовут александр деринг компания nexen я тимлид команды фабрики микро сервисов мы разрабатываем решения под ключ на базе микро сервисной архитектуры для целиком оператора для компании мегафон доклад у нас совместный мы давно работаем фактически как одна команда уже около трех лет командой mail.ru вот но и расскажем собственно сегодня про то как мы вместе чинче to capture сделали этот доклад фактически продолжение предыдущего доклада где мы взяли тему вширь рассказали каким образом появилось появились микро сервисы и каши и ландшафте телеком оператора зачем это вообще нам была нужна ну а сегодня продолжение предыдущей темы и мы капнем вглубь как видите архитектура микро сервисного слоем как раз текстурами кратеров достаточно многослойная и очень важную роль в ней играет слой кашей для чего он нужен но он прежде всего нужен для того чтобы готовить удобно данное делать нужное представление для наших каналов мы поднимаем достаточно большой слой данных и score систем в каше и дальше уже делаем нужные композиты и отдаем уже быстро и с хорошим в этом собственно в конце концов канал и наши данные вторая проблема которая решает слой к шее это изоляция данных совсем недавно у нас появились два высоконагруженных очень требовательных потребителей это триггер и от системы комплексы за процессинг где мы в пике видим четыре с половиной миллиона событий в секунду часть триггера входят в эти каши и arrows engine от проекта real-time маркетинг вот которые выставляют требования на 50 миллисекунд в этом сена композитных запросах и просят 30к рпс получить так также но без деградации сервисов вначале мы делали достаточно простые вещи с кашами мы либо просто забирали каким-то условием из master system данные поднимали их тарантул либо так же подписывались на какие-то события в любом брокере сообщение да и так и у нас еще работала над налаженный процесс поставки данных по поставке данных из аналитических хранилищ все это достаточно было просто типовые решения раскатывали там в течение недели-двух мы получали результат но все все было прекрасно до тех пор пока не случился упс нам потребовалось сделать систему витрину данных над продуктом да извините за тавтологию правда product инвентарь и это такая master system в которой лежат все данные по подключенным продуктам и услугам абонентов компании что у нас был мастер системе на входе ворог ли лежал около 30 терабайт сырых данных от трех до пяти ктп с изменения в секунду и самое интересное что эти данные кроме как и 40 невозможно было забрать изменения происходили изменены изменение клиента написали напрямую в базу задача была в следующем создать традиционно целостную витрину и обеспечить и солей по задержке не более 30 секунд задержка репликация от master system и ну и понятно что в кэш нужно было поднять не все данные нам нужно было фильтрация но и где-то 130 терабайт нам нужно было взять где-то 1 терабайт ну и кэш достаточно часто обновлялся ну собственно мы приступили к задачей сели там понаписали себе запросов разных да и пошли на нагрузочный стенд чтобы погреть кэш посмотреть как это происходит в результате мы прогрели oracle oracle стало плохо в это большая монстр образная система вот не любит вам запрос и твоя вот ну и время в общем то там прогрева нашего каша оказалась порядка двух недель то есть к моменту загрузки мы уже моменту прогревом мы бы получили уже там полный полный не актуальный срез данных ну и плюсом к этому до отсутствия отсутствие любого брокера но нас тоже немножко остановила мы начали думать как каким образом нам делать решение сначала мы вообще думали может быть мы откажемся от каша давайте поднимем еще один стенд бай почитаем данные напрямую 40-го первое не получилось потому что данное разложено по разным табличкам нам нужно joy нить а как я уже говорил о нас 50 миллисекунд на композитный запрос то есть нам нужно еще до богатеть эти данные чем-то вот и отдать за 50 миллисекунд 40 а у нас это не получилось ну и второе собственно во все банально просто система большая значит много ядер и получается что мы увеличиваем лицензионную нагрузку то есть нам нужно нужен еще бюджет на то чтобы за лицензировать эти дополнительные ядра отказались от этого решения пошли смотреть бесплатные версии того как мы можем получить поток изменений и оказывается оракул сделал такую технологий она называется континиус коварен notification изначально у нас все прекрасно работала когда мы проводили тесты на функциональных зонах когда у нас не было большой нагрузке секрет при прекрасно справлялся кратко в общем-то суть его заключается в том что вор ecли есть тоже внутреннюю очередь и на эту очередь можно тут можно подписаться нотификации которые про из происходит в базе когда мы вышли на нагрузочный стенд в общем то обнаружили интересную историю про то что про то что против цианирование таблицы изменения на протекционизм в таблицах не отлавливаются секретом если вы закрываете одним кометам более 100 изменений мы сразу получаем историю с разрушением традиционной целостности она не поддерживается то ли это баг или фича не знаем открывали request oracle собственно там нам ничего хорошего не предложили мы на этом закончили потому что там бесплатные бесплатный сыр только в мышеловке не хочется наступить какие-то грабли непонятные навроде ну и тут на сцену вышел наш старый добрый golden gate казалось бы где микро сервисы модно молодежно да и старый добрый golden gate но оказалось что в общем то нам придется нарастить экспертизу и погрузиться в эту технологию потому что он только с помощью goldeen где-то мы решили эту задачу в обеспечиваю традиционную целостность мы получили нормальную поддержку и тель процессы где можно по фильтровать по трансформировать данные мы сделали в общем-то кэш самым малоинвазивным способом мы не да не давали никакой нагрузки на базу не вмешивались работу мастер системы мои плюсом получили экспертизу его debate потом оказалось что в общем-то это решение стало масштабируемым потому что кроме вот первый ты первый мастер система у нас еще появилось еще появилась задача сделать 22 кэша в разных предметных областях и в общем-то наш oracle golden gate работает теперь нам наполняет каши для логически разных систем мы подключаемся к разным базам и делаем в общем то но захватываем изменение легко и непринужденно ну а для дополнительных потребителей но все же любят работать с данными этот поток изменения интересен как кроме нас интересен еще многим потребителям мы еще плюсом бонусом сделал еще одну точку в каску вот и теперь у нас такой вот получился универсальные слой сидиси да где есть 40 в golden gate который в общем-то поддерживает загрузку данных тарантул вот и есть еще кафка которая для для тех потребителей кто не может подключиться кто кто кому интересно и к кому интересен этот поток также вот первый поток подход снаряду у нас был в общем то через выгрузку csv-файлы файлов то мы решили проблему с нагрузкой все таки вот начали сделали по простому грузили из оракла в csv и погружали ладдер погрузил все это все это в тарантул и репликацию настроили виде значит преобразование трое файлов xml формат вот второй вариант у нас получился более такой технологичная скажу расскажу расскажу более более промышленные которые мы сейчас везде используем это прогрев каша напрямую из оракла и использование процедуры из exid это фактически . кастомизации в голдэн гете вот на практике ничего сложного с голодным гей там нет надо просто почитать документацию пообщаться с baby i'm и в общем то вперед у вас все получится вот дальше про мясо рассказываешь расскажет василий тюбик команда mail.ru вася тебе слово отлично слышно так коллеги меня зовут васили тюбик я расскажу про технические аспекты реализации этой штуки во первых с самого начала обычно представляет из себя что обычно кэш работает от запроса да то есть у нас есть какое-то приложение которое сначала пытается достать данные искушают затем если не находит пытается сходить в мастер систему болот класс складывает данные обратно в кэш и уже от этого работает в нашем случае историю слегка отличается на то есть вот этот концепция каша сбоку так называемого когда мы не переделываем уже существующие приложения которые ходят в мастер систему oracle существующей а все новые приложения общаются столько спешим на достают данные только оттуда соответственно что в этом случае представляет из себя работающий кэш он прогрет на то есть он заранее загружен данными эти данные актуальны и актуальность этих 9 данных поддерживается регулярно причем поддерживается за счет репликацию из мастер системы ну и он обвешен всякими разными характеристиками типа он абдирова был maintain a ball потому что нам нужно понимать до работает он актуальные данные в нем насколько он сильно отстал от master system и вот это все поэтому по порядочку первый наш доход был прогрев с выгрузкой с вы на то есть что нам нужно было да то есть требования к этой выгрузки они довольно просты и во-первых нам нужен был только срез данных исключительно за то есть не весь 30 терабайтный набор а только его часть во-вторых мы должны были в процессе выгрузки данных из ого класса сдавать на него минимальную нагрузку и в-третьих выпуска должна была происходить за какую-то адекватное время на то есть там например время две недели явно неадекватные такой каши никому просто не нужен первое что мы пытались сделать да это выгрузки по условия выгрузки по условиям просто не сработали то есть мы получили время вы выборок такое что и нагрузку еще на исходную базу такую что это неприемлемую история что еще нам эта штука обломала она нам обломала возможность раз параллели со по условиям на то есть если бы мы хотели выбрать вот из этого 30-ти работнова массива на данные кусками нам чтобы например ускорить выгрузку мы могли сделать мы могли данные починкой да например пользователи выгружать там по тысяче но здесь мы этого сделать не можем потому что условия просто тормозят что у нас здесь послал нас спасло парте цианирования на то есть исходную таблицу исходные данные были парте цианирования причем позиционирование довольно хорошо то есть несколько сотен прямо партиции до которые мы начали в общем-то выгружать целиком на соответственно мы выгружаем каждую партицию параллель но соответственно единственное что здесь важно важно ограничить количество этих процессов которые в параллель выгружают партиции потому что банальные смысл баню выгрузку в 100 потоков вы вытер 100 потоков нагрузим баз данных источник и второй момент мы по-прежнему здесь работали без условиях на тристану выгружаем все данные которые у нас портится их лежат на круг мы получили вот такой вот pipeline на то есть первым шагом для выгрузки мы проходимся по всем сучков карте всех таблиц партиции sap партиций которая у нас есть в базе данных источники из этих данных мы создаем пачку иска или запросов каждый из которых под простой select на либо всего либо набор полей конкретную партицию дальше мы набор запросов скармливаем некоему процессу экспортеру который уже начинает там несколько потоков выгружать данные опции свои файлы чему все свои файлы ну потому что их довольно удобно данная этапе отладки гонять ты один раз выгрузился дальше ты их можешь загружать экспортировать и импортировать дело с ними что хочешь в итоге чем мы получили чтобы выгрузить данные 40-го быстро без нагрузки во первых никаких фаеров вообще на плечо только на загрузке фильтры во вторых должно быть адекватно и парте цианирование на самой базе данных источники на то есть если мы мы сами сталкивались на самом деле у нас была табличка в 2 по птице буквально то есть причем одна partition была маленькая 2 на несколько ярдов записей ну понятно да выгружали мы это долгое важное значение имеют всякие настройки у акула в нашем случае нам помог пресечь при подключении тоже такие детали непосредственно подключение к уроку но тоже важный момент и для себя мы ограничили количество потоков на выгрузку в штатном режиме это 10 если мы грузимся экстремальная экстренно максимум 30 для нас вот такие цифры сработали уроков мы не нагибаем мы получили привет таких вот водных выгрузку за шесть часов в зависимости от того с какой таблицу мы работаем от 60 до 700 тысяч скорость выгрузки в cs вышки и это одна осваивая две десятых терабайта сырых данных csv на выходе собственно данные выгрузили теперь нужно их загрузить здесь что важно здесь важно учитывать модель хранения этих самых данных с которыми мы работаем во первых в нашем случае так как данных многом и сразу из коробки приняли решение что будем садиться на соответственно у нас данные локализованы по каждому абоненту и шарди раваны то есть на каждом чарте лежат лежит набор данных того пользователя которого там лежит не смешаны в кучу что важно важно дальше сама модель данных есть абонент да у которого есть вот эти желтые khaman и это платные услуги его подключенные и синие кругман и это все что как-то привязана к этим платным услугам особенность в чем самих платных услуг там 4 ярда записи дополнительных данных синих кружочков 12 на то есть 13 м в чем особенность особенность в том что когда мы вставляем платные когда мы пытаемся загружать уже данные платных услуг в наш кэш мы точно знаем в какой черт они кладутся у каждой платные услуги есть поле в котором написано с об скайпе ради такой то соответственно можем сразу вычислить нужный чарт и отправить данные туда все остальные данные приходится загружать с поиском а то есть у них нет ни с адской пироги не они только знают о своей платные услуги соответственно чтобы данные загрузить нам нужно сначала найти к чему их привязать на соответственно вся загрузка в этом случае превращается в мо придешь на поиск шарда в которой нам нужно положить дополнительные данные и insert в один соответственно в чем вот этот самый момент на где мы начинаем уже грузить c с вышки где вот все это происходит у него есть вот такая вот особенность да то есть мы грузим данные поэтапно сначала мы загружаем основной массив данных затем все остальное к чему идти до не привязывается ужин в общем то такая вот особенность до спас моделью данных нужно считаться для нас это что во что вылилось для нас то вылилось то что у нас данные продуктов подключенных загружаются буквально за час с копейками на то есть не просто в лед 400 гектар все остальные данные загружаются еще 11 часов просто потому что мы их сначала ищем потом загружаем вот это все дальше и вот здесь уже как раз появляется golden gate с чем ждет коптером данные загрузили нужно поддерживать как-то актуальность сам golden gate сам из коробки довольно простая штука условно простая если в квадрате к кружочках его рисовать вот зелёный квадрат посередине этот golden gate его задача реплицировать данные из базы данных источниками soros db в таргет db применяя какие-то там провел и конфигурации важно нам что было важно что она умеет работать с разными топология my на то есть она умеет агрегировать данные в одну банку разливать данные по нескольким банкам в общем все что надо и поддерживает семантику отеля до то есть на каждом этапе можем объявить какие-то фильтры трансформации сказать что нам эти данные не нужны а вот те данные нам нужно преобразовать во что-то другое нас это несколько раз вытаскивала особенно при работе с датами да то есть при проведении дат которые горок и более в приведении до от которого у нас падают в tarantul на крыше работает это все довольно просто на на базе данных источники происходит какая-то транзакция происходит commit дальше глубин готовой процесс extractor эту транзакцию ловит и складывает получившиеся данные в файл вью файл что это такое это лог транзакции ну то есть как его golden gate ведет для себя то есть insert и дали ты andate и по порядочку как они происходили на мастер системе ну этих файлов может быть много да то есть по мере там добавление transition не просто дописываются от нуля двое дальше golden gate овый процесс replicate эти трэйл файлы слушают на соответственно учитывает из них эти транзакции и накатывает их на базу данных целевую уже собственно простая довольно штука до чего важно знать реплицировать данные позволяют трансформировать и самое важное для нас штука оказалась это он реплицировать только законченные транзакцию не за комичные транзакций мы просто не увидим из коробки сам по себе golden gate из коробки умеет oracle oracle для того чтобы запилить что-то в тарантул мы немножечко извернулись на первый заход мы сделали вот такую штуку на то есть был golden gate как он есть зеленый квадрат банка источник банка целевая мы половину golden gate а по сути отрезали на ту часть которая накатывает изменения на целевую базу и запилили ее собственную на таран туле на своею под под себя что называется и вот это вот красный квадрат тарантино репликатор это вот та часть которая заменяет golden gate а вы процесс replicate и пишет в общем-то в целевую базу она же тарантул это сработало потому что троил и в которое пишется лог транзакции могут быть в нескольких основных форматах из коробки это бинарный проприетарный формат какой-то ski риску или есть и для нас сработал xml xml сам по себе выглядит вот так да то есть не просто список добавляет есть данные есть мета-данные есть понимание что это за таблиц на за таблицы какого типа операции прилетели какие-то данные то или после транзакции сами данные выглядят довольно просто то есть мы знаем что это за колонка какое значение в мета данных мы можем увидеть всякие дополнительные прикольные штуки например время коми то надпись когда произошел commit на базе данных источники все это на этом можно заканчивать да то есть мы просто написали xml парсер который разбирает троил файловая сомали и накатывает это все на тарантул было бы сильно просто если бы было так просто чем получили на первый заход на первый заход мы получили загрузку данных и средств то есть цель и сливаем в cs мышки загружаемый с вышек мы получили репликацию через xml просто написали xml парсер все круто на можем посмотреть сами в этот xml чик увидеть что там происходило понять почему у нас выше такие данные теперь второй раунд это было у нас первый заход на 1 кэш дальше у нас появилась кастами 40 индекс так называемый системы и специализированный индекс для поиска абонентов тут мы решили подумать чем можно сделать лучшее из того что у нас есть потому что у нас было несколько нюансов во первых во первых нам не нравилось вот этот machinery загрузкой да то есть вот эти хореография с валиками файлики выгрузив алики загрузи файлики там сохрани и так далее во вторых мы написали половину golden gate то есть в буквальном смысле мы остановили там ту часть которой на golden gate может на трейлах и остальную половину мы просто написали в ручками самостоятельно чу это означает это означает что мы часть функциональных возможностей априори потеряли потому что golden gate этот матерый продукт который развивается очень давно мы наступили на всякие разнообразные прикольные штуки связанные с самим форматом xml на то есть например вот так вот выглядит поддержка снобов на то есть блобов соловов xml есть прямо посередь xml golden gate фига чивает нам ошибку что он дед не поддерживает все мы даже это распарсить не можем мы еще наступили на всякие прагер ские ошибки да то есть все равно это файлик который нужно по хитрому читать да вот так вот это это лак на репликацию вот так выглядел наш первый подходит снаряда то есть красная планка это наше сало и видно да то есть каждый раз если там посмотреть на время это ночь каждый раз в ночь мы это соло и пробивали в чем был прикол на причем до ближе к выходным да то есть тренд такой что чем ближе к выходным тем выше мы пробиваем тем больше у нас лак репликации в чем подвох был подвох был в том что мы когда данные из xml и читаем их читаем пачками это по 1000 записей пока тыщу записи не наберём мы не отправляем их дальше в процессе соответственно ночью или ближе к выходным нагрузка с базы источника спадает и мы априори автоматически получаем лак выше чем могли бы это тоже нужно закончить на то есть мы похудели мы сделали но с этим тоже нужно считаться это тоже нужно иметь ввиду что есть вот такие штуки от этого всего хотелось избавиться переложить это все на golden gate ну их последний момент наверное самые важные во всей этой истории мы сломали эксплуатационные домино то есть есть гибели есть специалисты по golden gate у которые поддерживали каждый слой загонщиков и тут пришли мы мы пересеклись с golden gate коми начиная от настроек операционной системы прямо от создания образов учетные записи безопасность на и те и те должны иметь доступ к одним и тем же файликом одни должны писать другие считать короче в общем этого всего хотелось избежать с прогревом версии 2 подходить было довольно просто да то есть мы просто вырезали файлики мы оставили исходную часть как она есть потому что с партициями работать так и так приходится вот так на соответственно здесь место файликов мы сделали escort то есть у нас была очередь загрузки файлов осторож или загрузка и стоит ограничение все те же самые на то есть порядок партийцы здесь ничего нового с самим golden gate там вот здесь мы зашли немного серьезнее мы запилили юзер exit так называемый чуть такое из коробки golden gate выглядит вот так первой итерации мы обрезали половину 2 мы сделали вот так вот мы его дополнили golden gate позволяет расширить позволяет расширить за счет использования зиракс чуть такое это просто смешная библиотека которую мы можем в конфигурации golden gate у сказать использую юзер exit вот такой то и путь до сушки там в сушке мы можем под закончит свое нося на где мы можем получать транзакции которые golden gate обрабатывать как ты их по-своему обрабатывать то есть угодно делать мы сделали вот так то есть мы перекрыли основной поток нас на на целевую базу на сказали что все не надо туда писать все окей и развернули собственно tarantul ным клиентам запись непосредственно в tarantul ные кашель и на то есть здесь тоже в целом ничего сложного есть нюансы там сканированием насер там и так далее в общем все укладывается в целом доки расскажу немного про то как мы с этим совсем боролись за наши веселые как мы обслуживание этого всего налаживали в общем все это самая интересная часть дома первый заход на репликацию у нас выглядел вот так это график логарифме кации в секундах на соответственно там вот видно что слева это уже минуты и целый план как красные внизу вот так выглядел наш первый заход такая вот пила медленно нарастает и потом резко уходит вниз до дому жену и на цифры в чем проблема проблема в том что есть уроков исходный к нему golden gate мы подключили есть такое понятие интегрированный экстракт так называемый с точки зрения настройки golden gate а это означает что база данных источник помимо того что она занимается тем чем она должна заниматься на накатывает транзакции так далее начинает работать лук майнером то есть оракал база данных сам по себе ведет свой блог транзакцию и вот когда мы подключаем golden bee в токио федерации интегрированного extractor какой мы его подключили мы получаем что база данных источник начинает сама разбирать свои логе подготавливать их для уроков google это короче мы его опять начали греть чтобы это обойти надо соответственно чтобы этого не происходило мы получили поток архивных логов то есть просто 30 минут условно нам отстреливается новый лог на то есть 30 минут мы сидим курим бамбук ничего не делаем ждем пока к нам подъедет этот влог пока начнет разбираться в общем чтобы не грузить основной базу данных так жестоко обходится это довольно просто для того чтобы не греть базу данных источник можно поставить отдельную грелку на то есть на которого мы сливаем эти лаги и где мы их парсим то есть по сути мы проблему с циpкa на базе данных источники меняем на проблему с сетью на то есть если у нас терабайт изменений шутки значит этот терабайт изменений сутки теперь нужно будет прогонять по сети на базу данных майнинг она уже там как то это дело обработает очень как казалось проблему сетью решить гораздо проще на то есть инфраструктур щеки и учили за нас делать там ничего не пришлось за счет того что мы с архивных логов перепрыгнули наряду vogue так называемые в этом режиме мы получили вот такой вот лак на то есть 18 секунд это полка в штатном режиме которую мы видим в обычный день не нагруженный день она еще меньше бонусом бонусом мы получили майнинг работает как слой изоляции ну то есть если в конфигурации подключение golden gate а напрямую базе данных oracle случае если урока отвалится мы получим собственно говоря какой-то там эксплуатационный сценарий на восстановление этого всего в случае если у нас стоит майнинг перед нами маненько этому id может выступать слоем изоляции у нас есть основной источник есть резерв случай если основной источник происходит свищей r или failover мы за счет того что перед нами станет майнинг мы даже не нужны такой хороший финт ушами в общем за счет вот так вот небольшого find a важный момент в этой во всей истории в чем вот этот база данных майнинг это не реплика да то есть это числа грыз который не хранит полную копию данных он просто получает блоге с базы данных источниках разбирает их и отправляет golden gate все вот это важно потому что иначе бы мы залипли на те же самые терабайт которая у нас есть вывод из этого всего по умолчанию если вам не нужно сильно быстро реал тайме можно работать на архивах вот это вот этого всего можно избежать если нужно как в нашем случае это вот так вот можно сделать и тогда мы будем получить реальное время среду блогами всего хорошо дальше дальше вот такая вот фигня 21 год казалось бы на вроде уже решено несколько раз нет а когда мы делали все на xml все было очень просто мы в golden gate of конфигурации говорим encoding у tf и забываем как страшный сон получаем получаем просто нормальный валидный xml super foam в случае с юзеры axe там с golden gate am golden gate сам может конвертировать из кодировки в кодировку на то есть он детектирует что кодировка источника и целевой базы расходится значит мы ее с конвертом есть несколько ограничений по этому поводу например что там целевая кодировка не может быть уже посимвольно му составу чем исходные на то есть мы например цепи 1251 можем сказать вот f8 без потерь утаив 8 обратно в себе 1251 уже нет нюанс на нашем сочетание версий golden gate а оракла это не сработало у нас появились баги нам пришлось скатиться в историю сайта но в этом случае нам повезло то есть у нас на тарантула есть встроенный модуль arcconf то есть мы же делаем с базы данных источника через golden gate мы получаем данные как они есть той кодировке которые они есть конвертируем уже у себя то есть иже с ним вопрос закрыли и того данные загрузили real-time сделали проблему с целостностью данных порешали выводы на этот момент xml самый простой вариант бороться с кодировками юзер exit конвертирует но не без нюансов айкон надежный вариант тогда когда iconv работает на то есть aig он запросто может там за 20 лет работы базы данных в энтерпрайзе там скапливается много всего неожиданного мы пару раз выхватывали что а иконку нас просто падает то есть это нужно просто предусматривать и один наверное из самых сложных моментов failover всей этой машины rain сам по себе кэш само по себе витринах его верится из коробки на то есть у нас вот эти серые квадраты это допустим 22 стойки там две машины как удобно есть мастер часть каша зелененький квадрат и есть реплика то есть синенький квадратик большой соответственно прилагается всего у нас там автоматически написано это все на тарантул картриджи у него есть встроенный механизм переключения мастеров реплик в общем все это работает базы данных источники тоже работают потому что она стоит рэкласте как там себе через файл улицу и вообще его в области ответственности дебилов мы об этом ещё не знаем вот эта вот часть самое интересное первое что мы сделали само собой мы поставили просто резерв этого всего и завели потоки репликации из источников вот так вот крест на крест баба майнинга чтобы каждый manning в любом случае мог получать и основного около из резервного роковым данные дальше вопрос что делать когда это все падает например там падает making или падает волан gate так как все это держится на файликах на то есть trail ее логе транзакции вот это все то есть штатный вариант да это подключиться ходы между основным и резервным фондом то есть репликация дисковых массивов и все нюансы этого всей истории в чем у нас с аллой по-прежнему должен был оставаться 30 секунд со хода само по себе штатные переключение во первых 30 минут заявленное время во вторых эта процедура чуть не полу ручная то есть идем от монтируем примонтируем подключаем запускаем и так далее она круг получаем theory сала и забыли конечно же неактуальной чем мы сделали мы перевели проблему собственно из вышестоящих компонентов на себя мы сделали два активных потока репликации на то есть в каждый конкретный момент времени и майнинг их golden gate в обоих судах работают если в случае с и ходы в случае с ходы работает только один при переключении 2 включается в нашем случае работают оба разница в чем разница в том что работает только зелененькая часть да то есть у нас в кэше на запись доступен мастер соответственно в мастер мы пишем в реплику мы получаем оббивку с мастера нам поступают данные о тех транзакциях и стенах которые мы уже отработали на для того чтоб реплика могла резервному потоку golden gate и отвечать что да там вот эта часть отработали дальше все очень просто мы для триггеров и лавера мы переключаем мастер на своей стороне в кошель витрине на соответственно таким образом у нас одна половина за становится доступной на запись на второй половине у нас запись перекрывается автоматически мы получаем переключения потока репликации то есть там где краник был моего закрутили открутили в соседнем судят автоматически вода полилась история довольно сложные с точки зрения реализации но она во первых дешевле за счет исключения из хода репликации дисковых массивов этого всего во вторых она она срабатывает в рамках снг то есть переключение мастера на крыше у нас происходит в рамках 5 или 10 секунд все и дальше может дальше работаем своего миром как-то так дела обстоят то есть в рамках осаго и решили единственное что мы его вот так вот сами сделали каким-то нештатными механизме но она автоматическое быстрой и последнее наверное что я хочу рассказать это про эксплуатацию кратенько важный момент во всей этой машине в том что у этой штуки обратной связи нет никакой на то есть транзакция произошла на одном конце на другом конце а она накатилась и как-то там она через что-то пробежала обратной связи нет да то есть мы из тарантула не подключены вокал не проверяем ничего что это означает это означает что если например происходит разрыв где-нибудь между golden gate а мы тарантулом для нас для каша для тарантула это будет неотличимы от отцовской транзакции то есть транзакции нет сеть порвала одна и та же история соответственно мы не узнаем до что нужно что-то предпринимать чет переключить на а нам это важно чтобы сохранить наши силы чем мы сделали мы включили хоббит хоббит транзакции это синтетические транзакции который раз в минуту бегают на в какую-то левую табличку которая так и называется херби соответственно туда вставляется запись важно что она происходит 1 минуту важно что там есть какой-то танками time stamp из которого мы можем понять то что теперь мы можем на эту штуку положиться мы знаем что раз в минуту у нас пробегает какая-то транзакции и в общем то от этого мы можем уже смотреть мониторинг да то есть если мы видим что последнее было две минуты назад значит у нас что то не так соответственно и последний момент это мониторинг intent лога рипли кации то есть к кому там произошло на источники и до кыша как она доехала это важно в первую очередь для потребителей в кэше потому что они могут полагаться на это время здесь все очень просто кусок аксонального отрыва то есть те же самые данные побегают через визируется мы знаем время коммита на базе данных источники соответственно для того чтобы посчитать лак нам достаточно просто из времени здесь сейчас у себя витрине вычесть время капитан на базе данных источники и все теперь мы знаем лак собственно касательно мониторинга и наверное вот две самые важные вещи на то есть можно там обложиться разные всякие метриками лагами и так далее но две штуки обеспечить непрерывность на которую можно положиться раз в какой-то интервал времени и лак репликации мониторить причем лак рипли catia мониторить не на каждом там участке and winter компликации этого технически важно при построении таких штук держать в уме характеристики источника если у вас нет парте цианирования там еще какие-то ограничения на это можно запросто наступить важно что именно да какую именно витрину мы строим от этого может пострадать там время загрузки витрина во время создания витрины вот эти вот нюансы xml с golden gate am легальный и самый простой способ на то есть проще просто не тут берем пишем по всех xml сделать репликацию куда угодно по сути юзер exit способ более промышленный но он же и более сложный в общем-то и последний момент важно эксплуатации то есть вот эти вот несколько моментов по которой рассказал на них нужно обращать внимание на что в витрины работали все по технической части sage подведи итог что мы получили на круг 1 раз но в итоге наверное можно сделать такой вывод что если у вас есть большой монолита вы не знаете как к нему подступиться поставьте кайт сбоку это новый архитектурный паттерн вот и меньше страдайте получайте удовольствие спасибо коллеги диски какие вопросы вопросы есть это хорошо добрый день у меня такой вопрос не зовут ан и прах орбиты интересная технология на самом деле и у меня такой вопрос существует то есть два параллельных каких-то процесса inserto до 1 процесс это идет вставка через вот эти три ресурса как вы показали схемку в конце автор антон ложится и параллельна параллельна получается фиксируется какая-то транзакция раз в минуту вот соответственно вопрос может ли получиться так что первая транзакция где-то провалилась то есть не прошла полностью по схеме до тарантула при этом фиксация in sort of прошло корректно то есть мы со своей стороны считаем что у нас все в порядке insert и каждую минуту продолжается но фактически данные валяться где-то там по каким-то причинам спасибо да смотрите целостность транзакции которая происходит на базе данных источник и их согласованность и вообще что там происходит это задача непосредственно приложение того которое транзакции там поворачивает соответственно если она хилит а то она будет вылетит для клиента то есть эти данные нам априори в кэше точно не нужны а потому что клиент точно также увидеть заваливайся транзакцию это я думаю что должны мониторить де пере не уже на тебе разработчики приложений которые в oracle пишут до нас важно что эти штуки не доезжают до то есть чтоб там не взорвалось мы получаем только валидные за комичен и в общем как то так но и мы наверное в каком-то горизонте времени все таки получим деградации по херби там соответственно тоже поднимем alert а есть еще вопросы да есть вопрос александр василий спасибо большое за презентацию я хоть я встану и что так лучшую половину вопрос нора больше к александру каким но поскольку кашу нас не резиновый да каким образом кэш чистится и как это повлияло на техническую составляющую хороший вопрос спасибо или вы не чистите кст копится мы очистки же говорят его накинут смотрите из реально реально я считаю вина была было миграцию на базе данных источники которые поднимала все данные вообще на что начиная там с начала времен на соответственно вот это все скопом начали получать и мы запилили процедуру очистки которые вот так вот раз в какое-то время массово расходится по всему кастовый начинает по каким-то условиям выпиливает данные потому что рост пошел вот так вот прям на то есть у нас был там словно наш терабайт штатный уютный которого мы привыкли плюс минус там и тут вдруг поехала поэтому да мы запилили очистка очистка на уровне тарантула это ваш наконечник который раз в какое-то время запускается и данные по какому-то критерию удаляет как то так а почему не почистить все и заново погреть долл там потому что миграция которую мы вот в том конкретном случае миграцию она была длинная там чуть чуть ли не месяц на то есть это оплот целый месяц вот этим заниматься соответственно вычистить там терабайт гораздо проще чем трогать залить заново на то есть это было было бы опять холодная загрузка до их догнать репликацию вот эти там 12 часов на загрузку вот это все почувствует дешевле спасибо 1 раз коллег и спасибо александра компаний sky box у меня такой вопрос я так понимаю у вас кейс если использование то есть вы храните актуальные сведения по абонентам да например 1c свой парик на 1 абонента да и там описываются какие-то услуги нет мы мы мы не храним это только используется при прогреве нам нужно это один раз выгрузить то есть ну как как работает вообще весь процесс то есть мы сначала подписываемся на изменениях к там вот а параллельно делаем выгрузку вот и у нас эти два процесса сходятся то есть мы сначала но подписались на изменения у нас уже есть блок транзакций который нам нужно будет проиграть на базу в начале нам нужно забрать весь объем терабайт данных поднять в память вот и вот эти cs лыжники да когда мы первые в реализацию делали мы их выгружали и 40 поделывали экспорт в csv импорта тарантул вот и копили лог изменений то есть сначала ну как бы вот накатывали вот базу базовую часть потом проигрывали накопленный лог изменений на всем этим вот а потом уже после этого у нас ну кыш стабилизировался мы понимали что он прогрет там все все транзакции мы догнали он там попадает уже василий по влагу репликации в нужное после этого мы туда переключаем запросов пользователей а вот такой вопрос а как собственно у вас витрина формируется то есть если у нас есть изменение какие-то базе при следующем запросе нам нужно метаданные у допустим какого-то клиента связать то есть вытащить из oracal и как их хранить где-то чтобы frontal вас просто хранятся файлики по сути то есть там никаких аналитический запросов мы не сделаем то есть вот вот вот карты это сделано смотрите во первых наших лишь и конечно же это не просто хранил к на тарантулы байтов да и конечно же лист приложения до искру да там есть они доступны на чтение для потребителей всегда то есть вы всегда можете сделать get запрос в сторону витрины и получить данные из кэша то есть ну там не надо писать коннектором полу это во первых во вторых но василий про это она быстро проговорил мы подготавливаем средств данных то есть вот в исходной системе данные лежат вообще не компактно скажем так то есть для того чтобы нам собрать данные по оппоненту по всем его услугами по всем связанным сущностям нам надо joy нить достаточно много то есть берем данные из разных таблиц janym вот этот процесс join a мы фактически перенесли на загрузчик то есть когда у нас есть то есть мы забираем полностью все партиции а дальше мы меняем модель данных потому что нам нужно поменять представление сделать его компактным чтобы в один запрос в один хлоп получить все данные которые относятся к но к нашему ну как бы к нашему запросу к нашему оппоненту вот и мы провели достаточно большую аналитическую работу чтобы вот взять из мастер системы эти разрозненные данные и положить в нужную структуру данные рядышком в 1 шард чтобы можно было это эти данные забрать мы над этим есть естественно rest и вот так всё это работает то есть это не просто кэш там нолик им единичками да это полноценное приложение которое работает отдает даны на чтение с очень хорошими показателями в прекрасном real-time am a вот и и сторичный саму вот у нас какие то данные поменялись она мне надо вот смотрите вот в кэше как раз нам нужны нам не нужны исторические данные то есть от каша требуется отдать актуальный срез данных но так чтобы он ну вот не вышел за 30 секунд то есть наши потребители требовательные готовы ждать 30 секунд их устраивает вот эта задержка вот поэтому у нас там только актуальные данные именно поэтому нам приходится и фильтровать ну кроме того что там для нас много лишних данных есть вот мастер системе да там мастер системе как раз хранится вся история за историей пожалуйста холодные а не лечи можно к мастер системе обратиться можно потом в 9 ходить потому что все там отбрасывают ну отбрасывается потом аналитические базы вот наша задача была сделать в общем то горячие поднять горячие данные в кэш потому что всех интересует горячие данные а историю в кашину 30 терабайт ну куда мы по памяти съедим ну в паркете если хранили бы они же молись вместо zeiss вы не стал заниматься с в это за занимает смотрите cs вы это все-таки жесткий диск мы в любом случае жесткий диск он дешевле чем память все-таки хдд но они еще не сравнялись по стоимости в памяти александр спасибо спасибо большое за ваш доклад он был технически очень не танси вот я думаю что всем очень понравилась дискуссию можно продолжить у нас есть кулуарно дискуссионная зона которая также позволит подключиться участникам онлайн задать вопросы и мы вам сразу вручил подарок который вручите за самый интересный вопрос поэтому те вопросы которые были заданы здесь они не останутся без подарка они могут быть также лучшими по сравнению с теми спасибо ещё раз большое водку ладно зон там вам помогут все настроить и для тех кто смотрит нас онлайн подключаетесь через зум вы сможете задать свой вопрос его смогут увидеть в эфире и вы сможете выиграть также сможете выиграть книгу и мы вынуждены всех попросить покинуть этот зал на 10 минут мы сделаем профилактику и в 1240 будет тех tolko vot авито и после в 1250 будет следующий доклад спасибо оптимальная система уже в твоей голове она продумана до мельчайших деталей готово просто нагрузки и защищена от боев только ты знаешь как твоя инфраструктура решить поставленные бизнес-задачи собери свой идеальный сервер онлайн selected were привет я артём и снова здрасьте да я редактировал бывшие рукой я бы уж редактор хабра сейчас ведущий подкаста мы обречены раз познакомиться чем занимаешься сейчас начнем работать над чем работаешь глобально я как бы маленький предводители мама группы разработки просто в поисках овечки которые мы растим за грехи мои тяжкие мы все еще гоняем замшелые самописный движок since который я когда-то тоже видимость грехе будь она неладна писал и мы побежим поддерживаем и развиваем всякому дописываем ты жива сделал давно и не для vita ты просто он вообще как ты считаешь выдержал тетива некоторым сейчас у него есть то есть api тоже тоже меняется видом сейчас 80 миллионов объявления завтра будет 160 миллионов но при этом у нас как бы боевой поиск это 80 миллионов объявления это то что оперативно доступно каждую секунду в каждом первом пользователь у вас высокие внутренние системы которые нужно сфинксов кроется в которых и побольше данна миллиардами измеряется например админ ты с архивом всех объявлений но что интересно это принципе тоже не сильно я знаю это на светлом прошлом были инстанции в которых и еще больше до сотни тысяч серверов и этому засвечено большому количеству детьми по большому счету узкие лилась дано достаточно некомфортно оперировать и был тогда и до сих пор может когда ничего с этим наконец сделаем вот но как бы я к тому что масштаб там порядка 100 миллионов документов модного 10 миллиардов документ дома привычным но сейчас таких боевых условиях есть моменты на которые ты смотришь такой боли ну почему я тогда там 8 лет назад не сделал по-другому я 20 а что выгляжу на все 13 ментальные возраст и вообще 11 но 3:20 а во вторых на эти моменты они есть понимаете постоянно все эти последние 20 лет в любой конкретно взятый момент времени хочется взять и все переписать на хрен вот 0 нет надо держать себя в руках нельзя все ломать надо на чем-то сидеть а некоторые моменты наверно там наоборот тут удивляешься блин там ipod какой-то замши а ты меня не работает до сих пор и честно говоря нежелание люду бешено полностью переписать а в основном скорее ну наверно больше половины года который делается это все таки что то что будет меняться можешь например рассказать в какие-то вещи которые ты был меньше всего готов который было сложнее всего этот движок поиск полтонны ты говоришь сейчас у вас мы там включает общем m-elle модули я не думал что 20 лет назад об этом думал что такое 20 лет назад как никогда не догадался о том что есть такая штука как имели которая по большому счету над статистиками цена стероидов и там линейная модель с сотней входов они там с тремя входами пайк не как ни странно в этой части все достаточно легко как раз интегрировать то есть интеграция той же самой модели ранжирование это достаточно штука оказалась простая потому что привело бы к нему к подобному с 1 готов многое steam один прекрасный момент уже там вырос там концепции под названием utmost сигнал оранжевая форма выраженными так далее выросла некая считалка этих самых сигналов форма выражения и все что оставалось делать это просто чтобы обеспечить возможность подцепить удэ функцию и в этому да я функцию передавать достаточно большой бинарный блок совсем сигнал беранже нами которые мы хотим туда передавать достаточно тривиальное занятие вот поэтому он еще десять лет назад опять таки дев действует назад по моему и первый раз какие такие боль менее мои обычной модели ухаживали делалось это в тот момент не для авито делалось для одного тогдашнего клиент которые строил там маленький региональный поисковик по одной среднего размера европейской стране вот там был соответствует уже сфинкс там выберем модели и нам первый раз на эти самые мобиль кручу ли у тебя вопросы лежал определенного момента в open source 7 после определенных увлекательных событий переживаний сэм с одной стороны с другой стороны я внезапно понял что прямо сию секунду никакого прока с этого конкурса не будет ни для какой заинтересованной стороны нам смысле для проекта роток не вижу для себя так уж тем более вот пока вот таком закрытом режиме может быть к лене купин source вернемся может расскажут что такое случилось так что он там это длинные увлекательный или наоборот длинная не очень интересная история вкратце и как бы это давай совсем большими масками следующим образом очень не просто зарабатывать open source nova 2 шт а который ты абсолютно за бесплатно дело лишь раздаешь и и пытаешься зарабатывать хрен пойми чего нельзя все отдавать за бесплатно надо что ты продавать вот с продавать у нас как бы всегда были некоторые сложности и поэтому на самом деле текущую версию которых разрабатываемые тем бы поступить я ее прикрыл еще в годы когда попытки зарабатывается танцор снова движка не кончились уже там не знаю группу а летом четырнадцатом году если при помощи уже было понятно так что то менять в кавычках бизнес модель бизнес в гигантских кавычках потому что особого бизнеса в этом утра диска счастью не было а и уже тогда искать решила что маг будет делать где-то разрез версия за деньги вот версия без денег и поэтому некие большие фундаментальные перья белки которые были за тельны выше тогда дома в четырнадцатом году надо их прикрыть и потом где провести линию разрез соответственно после всех этих перипетий названием кассовый разрыв довольно бога получается жили до 1 нормального кассового разрыва с одной стороны но здравый говорят там 95 процентов так называемых стартапов в это дело заезжают на дистанции в 1 1 2 3 года дергались несколько дольше в свое время но научу затвора оказался достаточно фатальным очередной разрыв читы деньги кончились совсем самое главное что притока денег кончилось тоже ставьте там было еще массу неприятных моментов научно как как сказать как в любом разводе скажем так но это уже наверное тема для отдельного рассказа и обычно там окладом рассказанным с углем и мечами за четырьмя литрами пиво и постепенным переходом от и оон когда он был в open source его легче было ним работать был какой-то вклад от сообщества значимый интересный вопрос вещь или нет я бы сказал что вороха нетушки ттт 7 комфортнее наоборот правда ну то есть понятно ним в целом себя удобнее работать когда ты не сам там какая . поддержку тут копеечку так отливку а вот снова нихера когда задник теперь проверим гигантская компания со всеми ресурсами и возможностью эти ресурс так или иначе использовать могут будет понятно дело сильно более комфортно режим жизнь вот понятное дело что тут как бы палка о двух концах и естественно если у тебя твой проекта люто бешено взлетает и сам начинает генерировать сильно больше денег чем у при большой компании на него в принципе когда не забудем за бюджете вы то наверно пара некие спин-офф open учинять от этой самой большой компании случае со сфинксом это случается сфинкс могут служить достаточно мало зарабатывал всю жизнь как бы это соответственно его независимая жизнь была не сказать чтобы как бы усеяна розовое или питание и корпоративными с черной икрой с соответственно выдающиеся в золотых чашечках бриллиантовыми ложечками вот поэтому в рамках большой компании ну честно говоря одну жить легче балога чем по меньшей мере вот на этой там стартовые фазе под названием и еще пока там свои 100 миллионов долларов с share via не делаем вот чисто теоретически чисто теоретически наверное можно построить разработку следующим образом что у тебя есть достаточно большое количество компания интерес антов каждая делает важность которых делает счет достаточно новое хорошее и интересное и которая можно скажем так в общую формулу хорошо уложить а его проект замерз теоретически это возможно какие то вот прям супер комьюнити проекты такие есть тот же пост бриз например по большому счету вот такой суперкар венцы проект на котором трудиться в далеко не одна компания и каждая из которых по 2 ливает что там вот вообще devil , а swings до такого масштаба черт его знает то ли не дорос то ли в принципе невозможно что он до такого масштаба дорос потому что насколько я смотрел и изредка смотрю на более другие проекты которые тоже про поиск в основном и понятное дело люсин и все что поведает нам библиотечка люсин и тот сервер который в этом сезоне модны строить поехали set а они всегда у меня конечно может неверное впечатление пошли недостаточно хорошо там умею распарсить 250 мегабайт джавс кого года 220 мегабайт из которого это в основном там ненужные тривиальные комментарии и там тривиальный фабрик но у меня такое ощущение что по меньшей мере в ядре скажем так движка библиотек и так далее где-то процентов 90 кода делается был бы в этом крайне ограниченным кругом лиц который возможно формально ходит по разным компании но их там допустим да если думает об opensource что это тоже очень мало люди на самом деле то есть он такой открытый контролю реальному а большой рассказ контрибьютором пар человек странных именно так большое количество контрибьютором при этом одновременно с этим может возникать в какой части там типа а вот ядром и лезть опасаемся но зато мы прикрутили вот этот плагин вот этот плагин вот этот план вот такая вот штука она конечно цветёт и пахнет сильно сказать все сели на шепча чем попытки кого привлечь к разработке ядра при каких условиях ты повернул его вы пантерз сложный вопрос вот на данный момент я натурально не вижу никакого там объективного плюс от open source а кроме никого имиджа и даже уже не уверен насколько как бы это важно и не важно для конкретных пользователей для того чтобы этот имидж был вот если бы сейчас ты мог вернуться в прошлое с текущими своими знаниями о том во что превратится в проект и что-то одно сделать по-другому чтобы это было не ну это ответ на этот вопрос мне к несчастью готов еще до того как я придумывал сфинкс и он звучит примерно как в момент ваучерной приватизации я бы украл я щепотки украл ящик водки много ваучер на которой там вкладывается в словами газпромом потом поверти руется в биткойны и в принципе на данный момент был он маску меня где-то уже в подметки если стаки признанием ну ладно успеха теперь хорошо готовится докладов надеюсь получится круто хорошо выступать ай да надеюсь дивы пасибо разные услуги для за ваш например сдать биометрию в систему можно пойти в любой банк у нас куча банков подключен у вас там сфотографирует голос запишет и пришлют всё к нам чтобы воспользоваться соответственно тот сервис который интегрируется с нами работает вот тут какие примеры есть но это все про бизнес давайте пойдем дальше с чем мы столкнулись у нас возникли такие простые вопросы а давайте посмотрим что есть на рынке мы не хотим изобретать велосипеды мы знаем отлично очень много коллег работают с биометрии самый разный мы говорим о windows кириши не здорово есть куча различных характеристик у каждого процессора 1 работает лучше другое хуже ту этот в темноте отчеты видит этот не видит ничего ведь и уют ребята с голосом дружить понятно зоопарк полный не россетти сами знаете модная штука развиваются все время растут тот 4 обучает используют здорово но у нас задачках быть пендрагон ости к нам надо работать на государство поэтому ну что-то с этим зоопарком делать надо с другой стороны эти вопросы безопасности когда к нам приходит человек он для нас здесь как давай платформа находится удаленном канале его мы не видим мы не знаем что происходит с ним где он как он нам надо как понять что это вообще на не фотографию прислали не просто человека там не знаю листочек сфоткали поставлены в стакан воды еще что-нибудь а может злоумышленники видео смонтировали нам тоже представляются кем-то ну с этим надо бороться и третья проблема это бизнес который всегда хочет узнать дорогие друзья у вас тут всякое распознавание вероятности а как с этим жить то вообще говорим ну хорошо давайте посчитаем риски выводы посмотрев на рынок мы сделали примерно такие давайте работать сразу со многими модальности не сразу со многих вин дарами будем брать от каждого лучше да надо учесть что надо отбиться от атак посмотрим как это сделать ну и все это конечно надо сделать и без потерь данных и отказывай устойчивые и под нагрузкой не разъехаться ну как то так давайте посмотрим что мы делаем для начала маленькая история про нейросети все знают как они работают и работают загадочно если мы возьмем и кинем пару фоточек попросим какого-нибудь вендора сравнить один нам скажет 42 другой скажет 78 3 скажет 33 мы такие скажем макияж тоже это значит венгер вам хорошо скажет слушай ну вот если у вас скоро 42 то соответственно ошибка первого второго рода у вас будет вот такая ну ладно хорошо если 43 ну ну вот такая потом ты думаешь ну хорошо все у вас как бы там пять девять десять минут седьмую точность чудесные графики в маркетинге вы все приносите но когда ты берешь и проверяешь все немножко не так никого не хочу обидеть жизнь сурова и нам пришлось что сделать собрать собственную базу образцов на который все мерить самим мы берем считаем берем замечательный гост открываем пишем кучу кода ага здорово давайте посчитаем теперь реальной вероятности для каждого скоро этого вендора после этого когда мы будем работать с такими венграми нам будет понятно что они говорят то есть он скажет 42 мы поймём эти вот это вы vendor 42 это хорошая история там точность 10 минус 7 например ну классно ошибка второго рода понятны можно пользоваться ну нас чуть-чуть про архитектуру архитекторы любят рисовать квадрат и вот план квадратов примерно такой один квадратик мы пробежали вот да мы померили показателем чего еще делаем ну у нас есть куча венгров они их применяют тет-а-тет все им делают у каждого своя платформы своя фишка ухо ну всему того что мы государственными сказали ну слушайте друзья давайте вот вам стандартная пищи к очень простая всего пара методов будьте доволен кто хочет нам встать пожалуйста ее реализуете и как ни странно многие смогли сделать для того чтобы использовать разных вендоров вставить их в разное время у нас есть отдельные процессы переиндексации данных и перерегистрации как это все выглядит выглядит примерно так для нас гендер это такой black box который мы выставим куда-то закидываем перед ним ставим замечательным образом любимый всеми индекс игр ну вот у нас есть балансировка классно этого вендором можно поставить 10 копий 20 так вот при эксплуатации посмотрим даже если он медленный ну хорошо размажем нагрузку что происходит когда к нам приходит биометрия ну например фоточка сначала она пришла откуда-то издалека мы берем читаем окей о чем фотка хорошо берем смотрим в конфиг говорим о кей сколько у нас вендоров но например 6 хорошо каждому из них говорим на тебе пожалуйста фоточку дай пожалуйста вектор он же шаблон вентр чинить отвечает ну к сожалению не всегда не все вендоры из этих фоток извлекают данные ну ничего бывает мы запишем все что не смогли сделать соберем сложим у себя куда-нибудь когда приходит к нам какой-то новый вендор мы берем ну вы со конечно же сохранили надежным образом эту фоточку сохранили все извлеченные виктора поставили нового вендора взяли зук прогнали все вход в котором нас актуальны через этого вендора тоже самое делаем и со звуком и с чем угодно систем можно просто накликать какая у тебя там модальность ну вот не знаю все четко глаза да пожалуйста нам все равно это все не зависит вот модальности как выглядит а фишка которую делают вендор ну вот примерно как-то так все совсем просто мы берем говорим дорогие друзья для того чтобы получить вектор вот вам соответственно фотографии может быть к не какие-нибудь там метаданные прилеплены эта пешка слева например экстракт когда нам надо сравнить две фоточки мы кинем ген друг другу я писичку скажем вот пожалуйста два вектора скажи пожалуйста это вообще похоже или не похоже вот примерно так мы закрыли следующий квадратик ну хорошо сделали мы разных вендоров ну классно а как что еще если биометрии мы говорили что надо проверять что-то про безопасности давайте посмотрим на рынке есть опять куча разных решений много хороших например что можно проверить можно проверить в живой человек стоит нам не подставили фотку и правее когда нам кто-то прислал фотографию мы можем сверить ну кинуть эту фоточку на специальный 2 жучек он скажет скорее всего это живой человек настоящая фотка все здорово таких решений очень много очень простых делают много компаний разница в чем какие-то хорошо видят подделки например на веб-камере какие-то видит хорошо подделки на фотке сняты с телефона поэтому приходится обязательно их комбинировать для того чтобы действительно удостовериться человек живой другой вариант можно не по фотке можно по голосу третий вариант можно вообще скомбинировать эту историю и сказать окей а давайте вот видео возьмем а давайте сразу и по голосу и по лицу и по видео и уж про посмотрим в человек рот открывает и правильные буквы говорит и цифры произносит хорошо и вообще это не монтаж ну как быть ну как как приходится делать все наберем делаем подход применяем абсолютно такой же как только что я рассказал про вин даров как то точно также считаем life на с обычным windovs ким решением с единой опечаткой кому интересно может пойти на портал прочитать эту записку ну ладно вроде тут вот как-то мы разобрались с вендорами и так ну более менее понятно но что же такое за биометрия к нам приезжает а жизнь оказалась такого что мы хотим проверять человека который хочет например открыть счет как вы операция так и не самая простая да как бы хочется очень надежно проверить что действительно он поэтому приходится с устройства получать данные в виде видео ну потому что самый надежный лови нас все таки такой это видео весит немножечко мегабайт 20 на транзакцию соответственно если подумать нам нужно транспортировать и фотографию что такое фотография хороший час ну легко мегабайт а еще вендоры работают чудные вендоры в некоторые по звуку например ты ему звук даешь 30 килобайт он тигре тот тебе вектор метровый что ну ладно как ты это надо передвигать по системе давайте посмотрим что может быть здесь я думаю что здесь история такого отличного решения которым все знают на хай-лоу лида артур игрищ расскажешь нашей особенностью или может мы пропустим и все знают как работает кафка даже не знаю все знает как работает катка если переходить конкретно к сути того как она работает у нас по факту мы взяли совершенно довольно подходящие стандартные решения для передачи данных как сказал сергей раз уже нас летают бега байтики то и десятки мегабайт и к вто давайте возьмём что-нибудь подходящее для передачи про и стресс не очень хотелось поэтому давайте возьмем что не сделаем в качестве шин взяли соответственно в кафку почему взяли кафку потому что она довольно проста и эффективна вот нам показалось на тот момент для решения таких задач да и до сих пор пока что вполне справляется со своими задачами обязанностями в частности ну нарезали в очереди поставили модуль key module by там с двух сторон стоят один пишет второй читает может быть их с одной из сторон их может быть очевидно там несколько мужчин несколько пишем несколько читают за счет этого мы как бы посмотрели на кафку и подумали что нам вполне подходит дать дайте две ну и дальше вот как на картинке можете видеть понеслось там куча машин куча очередей много читателей и писателей то есть это такая среда обмена данными между модулями то есть это в чистом виде мы ее называем шин так как кафка но она вроде довольно просто но при этом 1 она одновременно с этим оно еще имеет ряд механизмов внутри себя такие там как то что она не децентрализованное за счет этого нам позволяют позволил нам просто взять там кучку машин дисочки в них понапихать и вот собственно при тем самым вроде как малой кровью закрыв возможность во первых а масштабирую вторых воспользоваться ее там стандартный механизм балансировки который за счет которых в общем то читатели имеем имеет полное право там то отваливаться приходить и уходить как бы но им там сами решает чимин отдел давай добавлю здесь смотрите история какая мы говорили про надежность да штук в чем здесь можно что делать если отлетел какой-нибудь консьюмер да это один экземпляр одного модуля то ничего страшного капканом даст возможность когда этот модуль грохнулся пусть вся мода упала пусть весь сервак такие же копии этого модуль автоматически получит все механизмами канавки все данные к себе если они не если у нас потребитель не обработал сообщений он для кафки его не комитет ну все соответственно если он сдохнет ну ладно кто-нибудь другой подхватит сделает ну соответственно постольку поскольку она основана в первую очередь на том что нам просто тупо живет в основном на диск то есть это такой в чистом виде очень похоже на некую этом по факту это реально журнал больше чем наверное очередь по крайней мере мне так кажется отсюда нам в общем то она позволяет записали в нее до на наши там сложил на диске все и она лежит как про не сказал сергей и страну от реплицироваться мы осознанно идем на то что ждем при записи с каждого из наших модулей мы там осознанно идем на то что мы ждем аки от всех имеющихся в кластере брокеров ну и соответственно и самом во всех записалась значит там потерять ну как минимум там хотя бы треть тех же реплик ну вот так скорее всего будет работать даже не особо заметит опять же так как в силу того что кафка поделен внутри себя еще не просто совсем там плоский такой поток данных там еще есть разделение на партиции за счет этого там можно даже кусочки это там выпал у нас там портится что поделать рынку это время без них в живем на на оставшихся partition на опять же тем самым за счет качества портится увеличим просто потенциально возможно коллегу количество читателей ну и как я в самом начале про репликацию говоря сказал что там есть диски ну нам там быстрые дорогие диски не нужны поэтому мы взяли там обычные шпинделе дешевые относительно поставили как бы любо-дорого посмотреть называется соответственно диски можно точно также вполне себе менять за счет того что репликация позволяет это делать но если у нас там что-то выйдет из строя чисто там механический или там совсем не восстановим по софту мы заменим значит ничего страшно ну и вполне наверное логичный вопрос почему то мне что-нибудь кроме кафки там чему например не тот же rabbit ну основное скажем так основное отличие ну точнее основная разница которое нам сказала что вам нужно кафка ребята это вот было ровно таки такой первый пункт децентрализации потому что у того же например рыбе то у них есть центр all star да у них он вполне себе там иметь свои механизмы отказоустойчивости но с одной стороны во первых там он не очень на наш взгляд кажется все таки до сих пор ищу предназначен то что в него довольно буквально совать про из какого-то ощутимого объема сообщение при этом еще и разному постоянно объема там-то верху вниз к чем как бы не очень понятны кон все будет вести плюс соответственно центральный штор и довольно такая плотная связь с памятью ну и также как кроме этого в особенность других решений типа того же там кролика заключается в том что у них механизм чтение общение с очередями он там он построен на том что если потребитель забрал то что отправили то ну это считается замурованным в кафе и в силу того что она ближе к журналу она там немножко не так там прочитал потребитель хорошо не прочитал неважно но там так и будет лежать до тех пор пока не наступит этом определенная политика по месту и по время ну тогда уже будет вычищать ну и соответственно дает этот такой основаны 2 вот именно пункт того что на мне очень хотелось устраивать там сложный можете зации какие-то там хитрые съемки строить проще записать один раз все коммун одну придут прочитают ну еще добавлю что капканом чем оказалось просто мы всю архитектуру системы построили в основном в режим pipeline of то есть это прямой поток когда нам не нужно над очереди роутинг но вот в тех случаях когда нам стало его немножко надо по моему кавказ к решение ничего ну была идея что может быть не пойдет мне как сказал не погодите у нас на этот случай есть выход вот стримы мы вам привезли там какой-то из версий кафки они давно уже давно появились ну и собственно вопрос сможете зация он в общем целом отпал то есть так как есть кавказ 3 мы поставили воткнули там где нам надо поменять некий pipeline либо сделать у него какой там отдельную логику обработки состояния ну соответственно просто воспользовались уже встроенным логикой самой катки и вполне удобным д с элем с возможностью если что потом опять же за счет тех механизмов поведения как журнал пири-пири обработать если что-то пошло не так ну и в целом ограничение на мне притащила задачу по сну поставили 1 model x как стримами с агрегировать то что нужно в общем то получили конечный результат сказали что обработано логику надо рассказать коллегой точно если у нас на вход что-то пришло нам надо где-то работу разветвить и собрать воедино дождаться результата например здесь нарисована картиночка будет дальше еще увидим что мы работаем параллельно там с несколькими вендорами как говорили и сладостями все результата нам надо собрать вот прям отличный кейс когда нам помогают стримы именно вот в таком режиме и так мы достроили еще один квадратик нашей замечательной архитектурой когда построить то построили транспорт есть хорошо а таскать по систем может ну какой у нас вопрос ну теперь надо это когда когда есть дороги до что-то перемещается давайте куда-нибудь это все-таки привезем видел ли положим ну мы вот как-то посмотрели сказали что есть вот эти вот странные данные какие-то которые у нас ходят очень неструктурированные непонятны ну для странного непонятного ну вполне себе есть отличное решение которое не знаю все говорят ходу в ходу hb и сном и вот казалось бы все говорят big data технолоджи но нет мы и мы просто пользуемся совершенно неправильно но нам почему-то понравилось давайте попробуем разобраться почему ну собственно основная эта идея заключалась в том что почему опять же те же самые тот же самый аж bass поверх того же самого ходу все довольно просто и банально силу того что ваш bass вот такая некая скажем так column арка выросшего из big time of в ней есть свой ряд особенностей в том как она хранится на самом деле по дискам самом низу так как там внизу есть есть преимущество xk tfs им соответственно он может жить на распределенный fest получается так что в силу того что есть такое понятие как регион сервера ваш базе есть такое понятие как регионы они по факту являются таки минут по большей части там такая единица хранения при этом они мало того что хранятся такими обособленным самостоятельными крышками так еще и каждый это довольно большой кусок может развалиться живем на cfs может развалиться на блоке gdfs а что дальше уже развалится на файлы в обычной флешки в диск на машинах что опять нас возвращать к тому что у нас есть кучка дешевых шпинделей почему не попользовать их примерно для того же самого что и вставки у меня дроздова сами диски ровно те же совершенно спокойно кладем раскладываем соответственно логика сбора данных вот она как-то так выглядит соответственно и регион сервер отвечает за регион раскладывает он управляет одним или несколькими регионами дальше это все проваливается в dfs здесь здравствуйте тот реплика фактор который ты настроил потерять что-нибудь очень трудно ну если посмотреть как это все бьется с тем что говорили про передачу биометрии там про прогон сообщение с биометрии по кафке все опять же довольно просто так как у нас есть некий не некие однотипные данные ну однотипные с точки зрения того как они выглядят то есть могут быть например данные размером там в 10 мегабайт а то и больше могут быть например данные килобайта войну вполне в принципе логично их по какому-то никому признаку между собой разделить чтобы не перемешивать и более или менее равномерно и все сложить ну и соответственно в качестве механизм решение этой проблемы взяли что для ли просто таблицы с боязни так как у них есть такое понятие как калум families являющаяся как чуть ранее смотрели они по факту это просто такое объединение скажем так данных которые дальше уже внизу разваливать собственно опять же на регионы но тем ни менее хранится на одним единым куском - каролина почему нет давайте поделим грубо говоря один колумб family одна какая-то модальность то есть там это может быть либо звук отдельно там либо голос либо еще что-нибудь но при этом там покрутим чуть-чуть параметры настроек сбои за чтобы он чувствовал себя чуть-чуть попроще по подкрутим у размер региона постоянно 10 гигабайт и там не будем умирать на об стоянок compaq шинах либо на там сложных перебалансировка таблиц регионов будет не очень много данных тяжелые тяжелые ну в 10 гигабайт ну да мне миллион и миллион ские владеют поэтому в принципе вполне немного опять же дешево сердито получается я тут добавлю что до рекомендация стандартно если вы посмотрите для hdd по настройкам делать регионы поменьше причиной тому является логика того как он работает когда вы что-то пишете минут ответ весь каллум family начинается хлопнуться и собираться или в разбиваться наоборот это одна из самых тяжелых операций для hp и за и кушает памятью ну а кушает он ее по количеству объектов в силу того что у нас объект достаточно крупный мы как раз и можем себе позволить сказать окей мы возьмем сделаем бассейн регионы они будут поменьше и мы просто потратим сильно меньше ресурсов на них но при этом опять же за счет того что она довольна таким равномерным слоем ляжет в феску размажется долго на диски на машины мы не приедем опять же в то что у нас там какая-то одна машина все время красно из за того что там на ней одна большая таблица одним большим региону который там никак не отмасштабировать здесь с этим все несколько проще ну и чем заканчивается в итоге отделение как-то там достичь этого разбиения на хранение разбиение на машины все остальное мы начали с того чтобы поговорили про регион сервера и про региону соответственно да мы поделили просто скажем так по логике получи получаемых данных мы их разделили между собой на модальности то есть фото звук видео например если опять же видео тоже храним в случае оригиналов случае шаблонов так как опять же вин даром на модель разные виктора разного размера разных там объемы характеристиками и хранить их тоже хотелось бы наверное не в перемешки между собой мы их точно так же просто поделили на колонну family сказать что там у той аккаунт family будет у нас такой то такой то венда точнее виктора такого the vendor или там соседней таблицы с оригиналами там в таком family это будет колумб families модальностью от vendor то кого то есть это фотки но там такого the vendor каким образом от все раскладывать так чтобы опять же не приезжать не делать кентом ботаники не приезжать перебалансировки еще что нет такой здесь подход то он стандартный так как ваш базе все привязано к руки и соответственно чем чем больше у вас чем заранее чем лучше вы заранее подготовили то какие ключи у вас будут использоваться в качестве ключей для строк тем равномернее можно распределить о чем речь ну то есть если взять корень там round robin например или ждет там при при сплит таблицы и начать его просто проворачивать эти ключи так чтобы они не шли непосредственно приманка ментально друг за другом + 1 до поворачивать их можно просто на дроби на меня этом первый последний байт как мы сделали то есть начинаем отсчет там даст 0 ну дальше пуск меняем местами байтики и получаем циферки уже не от 0 там да и на инкремент нас несколько другого другой лайки это позволяет там наполнять довольно равномерно наполнять каждый из ирисок размазывая при этом опять же нагрузку на запись в том числе на разные машины диски и ноды в самом кластере давай на этот нам надо немножко пояснить вам штука в чём если кто-то каждый регион региона набитый просто аж boyzone по кускам он не думает ни о чем он говорит такие вот этому диапазон айдишник of от 0 до суда во все вот он так работает и если вы водите инкрементальные крутите речники да там каким-то авто инкрементом вы просто всю запись будете класть в один регион сервер он будет вас приезжать нагреть одни и те же диски какой-то момент он скажет горя и раз плети цена газа до потом он скажет все мне надоел пошли делить и вот это будет тяжело да вот простая замена в инкрементальный мои техники вот так поменять два байта местами если кто-то помнит дави что у нас ни один байт в целом числе прекрасно работает ну что у нас получилось с тобой да вроде бы еще один квадратик дорисовали вроде все что несли донесли сложили да хорошо теперь нам нам поговорить о том что же с этим работает здесь у нас история такая во-первых кафка во вторых у нас куча модулей которые работают сами по себе вот здесь нарисованы чуть чуть больше квадратов чуть чуть подробнее и например есть какой то фронт которым мы взаимодействуем когда человек хочет пройти биометрическую верификацию мы делаем следующий сценарий у нас фронт просит инструкции одноразовые персонально под этого человека сгинь ирины и сейчас дергает их с модами инструкций который кстати тоже пишут всю историю полностью всего чего по кому выдан в тот же самый hbs отвечает наружу человек выполняет там не знаю улыбается приседает вот все чего мы его просим должен сделать присылает нам прекрасные видео и мы начинаем это видео разбирать во-первых мы дергаем из него фотографию в мы отрезаем от него звук мы разрезаем если проверок несколько какой life нас какую будет проверять все это вот так вот распределяем и раздаём пол исполнительным частями к по которым про которым мы поговорили чуть раньше после этого получаем результат собираем его и нам его надо отдать наружу ну в общем вроде бы понятно давай говорил вот ну какая история возникает для нас мы хотим что-то про нагрузку делать и у нас куча куча куча модули каждый модуль должен быть запущен точно не в одном экземпляре много больше и начинается интересная история вот у нас пришел асти kipi запрос на предыдущем слайде нам надо в него дать им ответ кафка куча партий сонов все пишется не пойми как и если понять что вот этих вот квадратиков api не один а вот как нибудь например хотя бы 2 мы понимаем что на одну ноту нам запрос прилив как на слайде слева видно да пришел запрос нам надо точно ответить у ровно в этот типичный connect ответ может прийти как здесь опять нарисованы совсем в другую ноду ну что делать почесали голову слушайте есть хорошая история называется родис простой как валенок решение у него есть хороший механизм пабы в самом мы берем просто по идентификатору у нас по системе гоним все пакетики с идентификатором а вот от той нижник вот айдишник этого запроса все дальше по кафке все путешествуют союзникам этого запроса когда какая-то is not получает этот ответ она смотрит у себя это мой конёк или нет если таней окон и акт она просто толкает данный в rides the note которая изначально получила запрос на эту информацию подписано соответственно при изменении данных в одессе через механизм попса во все получили нужно отвечать наружу по-моему просто как апельсин но зато очень приятно работает ну как бы раз мы поставили редис мы такие думаю слушать у нас куча настроек по системе как-то вот все это админу настраивают сидят ну пусть настраивают админ приходят в админку что делает как оповестить кучу модули который нас стоят да все просто мы когда настраиваем мы знаем как и у нас настройки могут быть мы грм окей ребят вот эти модули им нужен реестр например вендоров мы просто-напросто подписываемся на нужный ключик в одессе когда у нас произойдет event того что админ чтоб настроил модуль ничего не надо ни перезапускать никуда он он получил от тренд через редис пошел болтаясь там своем докере сходил на нужный рез забрал нужно и обновление все здесь закону как бы в механизм сделан так что это все обновляется сразу же без остановки ну да так как здесь у нас настройки поддельные немножко между собой на те настройки которые можно покрутить в рандами там не требуется перезапускать модуль ки и там очевидно есть настройки которые при котором придется перезапускать модуль ну соответственно если админы хотят поменять что-нибудь например там не знаю настройках рендера например какого нибудь там пороге модальностям еще жизнь по настройке ходили по настраивали в модуле приехала работаем дальше не останавливаемся ну да ну и еще на на история 1 да нет повести печальнее на свете ну так как из предыдущих пары наверное тезисов можно было догадаться что мы довольно активно пользовались х дубовыми около х дубовыми сервисами когда-то исторические танцы довольно давно мы приняли идею загрузить конфиге взк какое-то время пожили так пока модули было не очень много и пока там не было такого постоянного скажем так изменении каких-либо там сторонних настроек для модулей там например настройки аж вендоров модальности еще чего не такого ну какое-то время она жила вполне себе там успешно хорошо то есть балансировка было построен на том чтобы учились безу типирует учились кафе все хорошо все между собой подружилась и синхронизировалась вот как только появилась такая штука как какие-либо настройки отличающиеся от технических настроек модуля настройки там так называемых между собой реестрами то появилась проблема в том заключающейся в том что то что хранится в зуке перед довольно сложно посмотреть скажем так человеку который звуки пир видит там ко второй да даже если третий раз приходится команда собирает все время ругаться а чего ж ты мне не подсказываешь консоль ничего ну и опять же так как мы уехали с головы голых живые машину ехали в контейнер и возникла вполне закономерно предположить давайте откажемся просто де прикинемся логику работы с за кефиром и переедем на отдельные конфиге на коробочное решение которые в общем то предлагает нам больших так как мы переехали в него чего получили выпилили кучу кода взаимодействие звуки первом синхронизации подключения конфигов опять же объем там уменьшили плюс в общем-то перестали заботиться о том что у нас там наши какие-нибудь кривые модули либо ещё что-нибудь случится произойдет так что он насчет нам долбить звуки пир ну и сложим вообще весь половину х дубового кластера который музыки при завязано ну и по итогу посмотрев на кафку мы увидели что парни написали мы отказываемся от звуки рассказали о класс мы тоже хотим ну и отказались соответственно в совке больше нет такого прыжок жесткое завязки на продукты и мы переехали просто в тупые обычные плоские рисунки конце выкатили модуль в в шив сказали мол тебя новый конфиг map а вот пожалуйста он там при подъеме из контейнера засосал джейсон q все пошел работать да вообще стал поприятнее и многие задачки по конфигурированию системы эксплуатации в итоге стал решать сама они бегают к разработчикам гриву как нам затащить этого звуки pir это и и как попроще стал попроще что получается ну вот мы почти пришли к финалу осталось поговорить про внешние описки давайте посмотрим что у нас тут так техника техника не подводи мне вот урок и так у нас есть внешние взаимодействия для нашей системы мы не находимся внутри не находимся в бункере хотя многие этого вы хотели до был в очень здорово не взламывая систему было бы ну и мы поняли что есть еще потребители сервисов надо им чего-то как-то помочь наверное давайте поможем нас есть всякие разные сложные вот эти вот все проверки слои вы сами какие-то там инструкции надо делать мы поняли что если идти клиентам и те которые хотят воспользуюсь платформы сказать ребята вам тут если мы пришлем инструкцию в которой написано что вы должны произвести такой то текст вы вот это вот так вот на фронте должны нарисовать ну сами принимать то конечно не работает поэтому мы изолировали просто процесс в себя поэтому фронт у нас частично тоже свой мы как бы клиенту отдаем кусочек например если это ma bell кто это sd qashqai через наше приложение можно сделать все который реализует вот эту сложную мутную логику плюс также для нас является то что мы полностью контролируем фронт а значит если нас ломают если нам надо срочно внедрить новый лавины с новой проверке мы делаем сами мы не ждем контрагента не ждем пока он строит там свое приложение новую нашу версию нет делаем все сами соответственно протокол один общий и на веб и на мобилку мы внутри уся виден кто к нам ходит зависимости от того какие инструкции проверки не знаю сигналы от аномалии пришли мы можем сформировать для конкретно этой связи для конкретно этого человека свою историю скажем не знаю при ты всегда с этого телефона ходил да мы тебя не будем заставлять прыгать на одной ноге если ты вдруг телепортировался куда-то и хочешь как-то очень подозрительно выглядишь для нас ну давай мы тебя бросим сначала сплясать станцевать да может быть больно человеком зато его денежку за него никто не получит ну хорошо вот ну и соответственно мы наружу отдаем всего это пару простых интерфейсом говорим ok если вам нужно на выбери директ нити пожалуйста вот сюда и тем самым закрываем кучу проблем и норматив и всем остальным что это мы работаем с клиентом напрямую и вам не нужно ничего сертифицировать ну в итоге картинка выглядит примерно так с точки зрения инфраструктуры самый тупой докер он прекрасно работает для биометрических вендоров потому что эти прекрасные люди используют замечательнейший библиотеки собрать которые самому примерно невозможным просим всех говорим друзья дайте пожалуйста как вот оба разочек мы как нить вот с ним а все остальное мы как бы сказали ну хорошо поставим класс стр ходу по какое положено догадались это соответственно транспорт в к кафка хранил кеты может быть какой-нибудь говорим хорошо хорошая база данных hadoop классно а все остальное просто вращаем его пунктов понравилось пользуемся прижилась до прижилось на этом наверное основная часть закончена ждем ваши вопросы да задавайте ваши вопросы надеюсь вам понравилось доклад ребят давайте начнем с конца вот идеально спасибо за доклад у меня два вопроса первый я так и не понял мотивации краски они просто хотят за кучей пунктов для надежности который решит вас проблема того что вам надо возвращать ответ человеку который ждет и так далее смотрите когда и ну то есть смотрите есть до вариант сделать все это наростах в глубину провалиться да и разница будет следующим что если у нас мы получаем к сожалению данный не только изразцов вынуждены говорить ребят мы приняли такие то данные и положить да хорошо кладем ответь приняли как только положили что-то очередь отучаем наружу 200 ок до свидания человек не ждет проработать то есть у нас мы тем самым позволяем себе еще и очередь организовать то есть если у нас жестокий пик и к нам прилетела не знаю там пачка данных смело ну там не знаю прессуя это несколько тысяч регистрации сразу мы их можем оттуда забрать выгрести очередь на той стороне алярм не поднимется мы просто сделал люся очередь то есть если синхронный интерфейс у вас до второй вопрос вот вы говорили про надежность что вы делаете когда что-то пошло не так как вы синхронизируете между всеми вендорами шо вы там у кого-то из легше шаблон у кого-то не извлек себя там сохранилось не сохранилось и так далее хорошо смотрите в ендер у нас ничего не хранит храним и все сами то есть у нас ничего не переложена на венгерскую сторону мир вас просто нет это просто докер-контейнер который выполняет две ровно две операции соответственно когда к нам приходит человек мы gryce контакт когда он зарегистрируем нас да у нас есть некий шаблон когда он приходит пользуются системой есть некоторым примет биометрическая пробы мы из этой пробы точно также пытаемся извлечь вектор соответственно есть пусть там не знаю 7 вендоров 6 извлекла для шаблона и вот для нового происшедшего извлекла 5 очевидно есть пересечении да когда есть пересечении все мы можем сравнить пару пару сравниваем отличным дальше приоритет по вендорам поехали у всех математикой стандартизованной поэтому мы точно знаем какая вероятность ну и до некоторых процессов иногда ну есть еще так чтоб ограничений что если например нам прислали биометрии весь который мы обязаны извлечь из звук обработать и фото при этом гондара по звуку например не смогли злить что если процесс того требует и иметь такие игры дженет мы можем просто отбить попытку там зарегистрироваться они успешно ну просто в силу того что мы не смогли удовлетворить критерием конкретно в этом процесс но при этом саму сохраним все что прислал все что получили так есть ли еще вопросы ну вот они войсках расклева просто идеально спасибо за доклад очень интересный вопрос это все генерит огромное количество лагов как у вас как у вас организовано хранение log off и как мониторингом обстоят дела с бизнес метриками с железными метриками спасибо спасибо за вопрос так значит попробуем ответить с точки зрения логов логов много часть мы лакируем сами то есть во первых чем еще для нас понравилась нам кафка тем что мы просто на неё сверху на все очереди которых где что-то происходит да вот процесс его данные пролетают мы совершенно спокойно под другой группой читателей навешиваем на эту . еще один модуль который забирает от добра складывает в чудесную штуку про которому не говорили hive называется и там дальше бери переваривай чем хочешь эти логе соответственно есть хотите в бизнес мониторинга берем spark утилитку пишем вы паршиво им нужную историю выплевывала погнали естественно вся эта история ну shift мониторится тасс обмазана там мониторингом снаружи не переживайте соответственно по железу у нас там это ним и мы люди за софт ребята взялись у нас отдельно там много цодов делают как они сами тут некоторые коллеги знаю и есть из тех с кем работаем вот поэтому тут проблем не особо какие-то так ничего не забыл ну краткой пробежаться из только по ключевым словам что там у польши вт эта связка фуфло винт польский банан для оперативного перекопали логов админами соответственно чтения до долгосрочных условно говоря журналов именно то есть там читается реально просто вот все все очереди которые нарезали мы все заслуги в один модуль все прочитаю все сложили ну и дальше там трансформируем ничего хотим то делаем с этими какие метрики можем считать все что надо мы как-то считали мониторинга на читали все пять сказали базовых хватит так еще полу возле села вопрос прямо еще один а можно давайте его коллега евгений сбербанка два вопроса стало практически ответ смотрите можно поближе микрофон был онлайн слышать так лучше осмотрите специфических есть поскольку вы государства допустимо приходит уважаемые люди в погонах говорят нужно обмен тубуса сделать идентификации один-ко-многим как-то сделать называли все такие кейсы были нет смотрите для того чтобы делать идентификацию схема отдельная но у нас пока уважаемые коллеги с такими вот запросами совсем же не переходят да я знаю что у вас там специалистов в плане поиска побольше чем у нас ну да мы отдельно эту функцию мы честно выносим в отдельный кусок то есть оно не находится здесь у нас есть механизма управления там идентификационными базами отдельные как только в которой мы там можем поставить вот хотите там идентифицировать давайте мы сюда управляю вас этого ядра поставим кусок . отказ является самарское решение то есть они они 15 штук ну и просим эти kuben дорога вали или вы имеете виду идентификационным ну допустим коробка работает на бизнес процессы старения у нас их просто много то есть мы просто вот так размазать ничего страшного конечно они все три этот резервируем то есть там как еще раз и например некоторые vendor работают быстро достаточно хотя бы минимум два понятна стоит даже системе а некоторые настолько быстро что надо поставить 8 чтобы они посмели за теми двумя они еще вот такие вот в ресурсами воды ну тогда они кое-как поспеваю поэтому нет обязательно все дублируются мы не верим честно мне одному вендору как-то задание нет честно эксплуатации вендров это очень тяжелые вопросу которым мы столкнулись то есть люди хороши в биометрии обычно да но у них в платформе насти решение как-то очень трудно она почему-то не работает почему-то падает зачастую ну вот приходится поднимать илим пингвинов подрабатывать на самом деле отличный вопрос и я вижу вот здесь был вопрос у вас не отменился еще вы хотели задать вопрос нет да давайте я вам микрофон свой дом просто до коллеги смотрите как вы у принцев через импортозамещения протаскивали зачем нам протаскивать вот вот не надо сувать то куда не надо вставать смотрите относительно импортозамещение и всех остальных список 91 р там вот выше днем находитесь по самые уши и очень интересно как вы его купили ну что ты начинаешь рассказывать ну вообще говоря зачем его сердце сертифицировать вы должны то что нужно сертифицировать если вы выиграли сейчас я запишу смотрите вы можете закрыть с одной стороны инфраструктуры с другой стороны софтом если вы построить все вокруг у вас у вас все хорошо это это прикладной софт понимаете если это не средство защиты вы видимости импортозамещение как не так представление не забрасывать в чем вопрос кто будет вардуи мышление вы имеете право просто шучу ну хочешь расскажешь два раза ван дамму шкилев у нас инфраструктура занимается уголь организация то есть ростелеком соответству них есть свой форк который называется не знает там вы ответили на вопрос спасибо да и он есть да и второй вопрос класс для configuration management и используется как минимум три решения да это звуки пир для кафки редис вот для управления настройками до его подшивки у вас это cnr на по умолчанию вам нормально да что у вас три решения используется для одного и того же ну смотрите на муки первым из гипера мужа больше не сталкиваемся с ним луковки как бы она же есть можно как-то там сам с ним разбирается слава богу нас они нас они не беспокоит они там дружат нормально нам хорошо с точки зрения управления наоборот стала еще сильно лучше потому что ну например к крайне маловероятно что вы будете вот как пользователь там система имеет админа пользователи вы вряд ли будете ходить там по модулям раз там не знаю 15 минут или там в 20 минут зачем то там менять в них там не знаю тайм-аут и url и коннектов там что-то было настройки подключения куда-то там не знаю название баз данных или еще что не такой ну как бы соответственно статика вот оно все живет и живет под управлением шрифта перека теле и новое обновление летом привезли новую версию конфигов анонса до становилось то что там рабочие данные администратора меняют там опять же добавляют например нового вендора ну ок добавили одну там фронтами просто пол перри получила новый список вин даров продолжил работать дальше просто 2 разных группу настроек абсолютно родис ray диск в этой части он выступает очень просто для шифта из мой и все in fresh ft он не нужен совсем он там никак не участвовать статические конфиге лежат под управление шрифта и лежат себе у нас он конкретно используются именно для того чтобы быть точки синхронизации о том что модули нужно получить новые новую версию конфигов сходите за братьями просто о том что что что-то поменялось надо перед воздухе пир тоже также это умеет дав какой-то момент да он работал точно также но и звуки первым мы использовали именно для статичных конфигов раньше что есть для технических конфиг модулей потом просто сказали что зачем если все равно в docker и едем давайте шут возьми я понял спасибо ребята спасибо большое за ваш доклад как всем мы вынуждены вам вручить и будем рады вручить подарки так сейчас как подготовить и ваш доклад очень интересный я уверен что у ребят еще остались к вам вопросы поэтому приходите все в зону цифровых кулуаров сейчас мы вам вручил подарки и если остались вопросы либо если вы уже придумали какой вопрос был лучший вы можете сейчас выбрать либо дождаться уже и в зоне кулуаров передать подарок как бы вы сами хотели потому что можно отдать сейчас да кому у тебя какие мысли я бы за последний вопрос наверное отдал подарок наверное да про соответственно используя низу keeper релиз и все остальное но я здесь предвзято это больная тема поэтому больная вольно я указал сюда коллеги если что готовы ответить на ваши запросы вопрос как в кулуарах если что ищите у нас на стенде подходить наши девчонки позовут да обязательно если даже не успеете сейчас-то на стенд можно всегда будет пройти и дальше у нас тех толк с компанией нашим генеральным спонсором и компе вот и после этого зал будет закрыт поскольку один доклад отменился в этом зале как и у вас тех долг не вдох я не слежу за тех дай право деформации привет я артем я бывший до краха бы сейчас вы подкаст на обречены при этом знакомиться приятно наконец меня зовут ольга и не я занимаюсь в компании компаний безопасности приложений безопасностью приложений это что-то особенное ну как сказать что-то особенно я стоял где-то в таком важном моменте который связывает собственно мир разработки и мир и безопасность потому что зачастую как присылаются себя себе и люди делают безопасности это ребята которые не знаю периодически запускают какие-то сканер уязвимостей и дальше приходит предположим к ребятам структуры со словами ребята у вас здесь не знаю какой нибудь узел мое приложение но обычно эти со сканера связанные с безопасностью vendors кого по если не знаю вы предположим на капельку им тапочки он может быть старой вес если у вас есть компании своей разработка то разработчики пишет уникальные уязвимости которые сканер уже не найдут обычные то есть предположение знает о дженесс с которыми пользуется большинство компаний для лары длительно нужен при собственно вот я пытаюсь внедрять различные практики безопасные разработки а поиска узи масти собственно в разработке которой ведется в компании работает и в чем заключается процесс как мы пользуемся различными во-первых с камерами которые именно сделаны для аптечных гирек это статический анализаторы к 1 безопасность мимический анализаторы кода на безопасность различные сканер зависимостей которые проверяют и вообще фреймворке какие библиотеки используются и все ли там хорошо безопасности также пишем свои большие инструменты не слизь какая-то специфическая позже логика который не может осилить динамический анализатор из коробки то есть предположим тот же групп sief enterprise брукс юта прокаченного либо enterprise они не всегда могут качественно проскользить на безопасность то есть например динамический сканер как работают они отправляют какие-то нелады с кавычками и дальше смотри какая то это пришел и не всегда таким сканером предположим по зубам какие-то специфичные приложение какие-то специфичных запросы предположим одних мы пишем код свою логику и также проводим ручное тестирование потому что 1 делает безопасность когда не знаю какой нибудь кавычки ты можешь зайти админом другое дело то что есть должен какое-то бизнес логика и предположим она может немножко дни сикер на реализована и уже предположим какого-то типа узи масти надо проверять рука ну и также проводим какие тренинги и пытаемся всячески просвещать разработчиков помогать правильно составлять с техническое задание консультировать на каких моментах чему не могли подумать как это сделал безопаснее на моменте именно ну вот именно когда ты проводишь в кедре view года такой еще существует что ты учишься бочеков как писать код так чтобы было безопасно чтобы не было у известий мы проводим тренинги с точки зрения любви кода мы спали используем подход грей бокса тестирования когда мы одновременно имеем ее исходный код приложения положим понято дебаг режиме и дальше предположим отправляем поднимаем приложение локально подключаемся к и берёзки и дальше смотрим а как же на себя пойдет тот или иной пилот который мы отправились клиента и как он пройдет в приложении вот примерно с точки зрения такого региона безопасно ну плюс поиск каких-то типичных небезопасных функций который практически во всех языках программирования есть различные магические методы и валы которые ну плохая идея использовать мало разработчики периодически во всех компаниях что-то использовать бездумно хотя не знаю вы х мануале к их языку написано что ребят если вы это используете на 10 раз подумать но не всегда там уступает и до 200 раз подумайте собственности такие пункте мы тоже ищем глазами если предположим по каким-то причинам с этим не справилась экстатический анализатор но чаще всего статические анализаторы справляются с таким review еще мне кажется я часто встречаю такое отношение к безопасности что это ну какие то просто формальности перестраховки паранойя нет ну я в принципе наверное могу конечно бассейна штаты перестраховки паранойя но если у вас есть команда ищите кереть который занимается именно безопасностью вашего приложения вашего кода то мне кажется разработчикам если они научатся дружить и правильно понимаете эту команду ставить потому что куда наверное проще когда тебе принесли уязвимость которую нашли еще на стадии тестирования над столицей джан чем когда какой-то хакер вывести ты знаешь что-нибудь через приложение перебежит бизнес а посреди ночи сослали надо срочно что-то фиксить мне кажется без опеки сферы помогает чуть спокойнее жить разработчик ну вот как на твой практики до них это доносить как мы это объяснять приходится ли на самом деле в большинстве своем я сталкиваюсь с разработчиками которые сами хотят в нефтянке самих разобраться потому что очень быстро до людей доходит то что если самостоятельным в этом всем разобраться если самостоятельно вникнуть и приходить ко мне по любому вопросу и консультировать то скорее всего у них получится написать безопасный код и и когда он едет до меня что пел а там уже будет минимальное количество проблем и им не придется это исправлять здесь же есть какие то еще не только какую потребность безопасности какие-то еще требования регуляторов например да конечно конечно требование от регуляторов есть мы например и компании gess компонент и мы собственно должны использовать вот все что связано с жизнь циклом долга по разработке это и нам статическим для завтра динамически это можно подходить к этим требованием абсолютно по-разному и соблюдать как по разному мы стараемся дамы этих кривыми соблюдаем мы но мы стараемся делать больше чем требует регулятор потому что же больше о chery да потому что это надо не для того чтобы быть вся действия компании да понятно это надо но в первую очередь как бы это безопасность который влияет и на нас и на наших клиент и мы хотим мы предоставляем качественный безопасный продукт может быть расскажу как именно до скиллами было чтобы заниматься тем чем ты занимаешься наверное понимать собственно как пишется код как работает приложение понимать собственно работе база данных как строится запросы как наверное работает уязвимости и общем и целом как как работает в моем случае как работает приложение потому что надо во первых еще иметь но не определенную фантазию и наверное желание бесконечное желание узнавать что-то новое ну вообще звучит это вроде как что это надо уметь чтобы уметь разрабатывать тоже имеют может 10 особенности чтобы именно вот ведь нюх на безопасность и если я не меня верны сложно про это судить а потому что я ведь про себя и про друзей и коллег но я наверное мне сложно сказать если безопасники чем-то отличаются но возможно это просто будет специфически специфическое мышление с большим желанием что-то сломать снова но но мать она опять же без с одним желанием что-то сломать мне кажется для уехать нельзя а поскольку надо еще понимать собственно как написан код потому что одно дело отправлять кавычки блага боксом когда ты видишь незнакомец этих и просто кидаешь кавычки другое дело разобраться и распутать общее а что же происходит может быть даже небольшой короткий ликбез такой вкратце пару советов как писать так чтобы у тебя было меньше вопросы к разработчикам у меня было ну такие его наверное самый главный совет это хорошо знаете язык на котором ты пишешь если есть какое-то сомнение по поводу использования той или иной функции пойти еще раз прочитать на сайте посвященном языку про это например для php в большинстве большинстве функции если они предположению безопасные также on сериала из большими красными больше большой такой текст выделены красным или были сказаны не использовать эту функцию если бы именно не понимаете что она делает не понимаете как сделать я безопасный наверное основное это самое главное просто хорошо знать язык и также читать материалы про то лежат такие специфичные для того языка и вообще насколько то чтобы хакерские скиллы прокаченного безопасника так интересно грань что вы не теряете и другие должны иметь и умеет что-то похожее ну мне кажется что хорошо запасников должна быть очень хорошая хакерских строить потому что в любом случае когда ты работаешь внутри какой-то компании и занимаюсь с значит и если ты не понимаешь как ломать ты вряд ли поймешь как защищать и туда так ну ладно спасибо тебе за рассказ жима по словам пусть расскажет пишут безопасный код и чтобы проблем было поменьше и возможно когда это это будут лучше что выкрутил добрый день меня зовут александр сергиенко я ведущий разработчик направлении потоковой обработки и больших данных компаний neoflex наша компания имеет более чем 15 летнюю историю и обладает обширной экспертизой в области финте х банковском секторе сфере кредитных бюро не секрет что этот сегмент айти является одним из самых технологичных и требовать иных с точки зрения объемов данных скоростью обработки танту market масштабируемости отказоустойчивости вместе эти требование дают разработчикам широкие возможности для технического творчества и примения новых концепций подходов и технологий в этом тип толк я бы хотел осветить тему монетизации кредитных историй и выделить наиболее яркие с технической точки зрения моменты с которой мы сталкивались проект компания flex связанные с построением аналитической платформы крупнейшего российского кредитного бюро позволяет раскрыть тематику обработки и колоссального объёма данных на фоне высоких требований к отзывчивости стабильности и горизонтальные масштабируемости системы законодательства российской федерации обязывает финансовые организации передавать сведения о кредитных историях заемщиков в так называемые кредитные бюро каждый приобретенный кредит будь то покупка нового автомобиля или ипотека каждый платеж или просрочка даже сам факт запроса отчета по кредитной истории выполнены через интерфейс на веб-сайте все это становится частью истории и входят в обширный и непрерывно расширяющийся массив данных кредитного бюро случае рассматриваемой аналитической платформы речь идет о сотнях миллионах хранимых кредитных историй и связанной с ним информации каждый день кредитное бюро обрабатывает десятки миллионов запросов отчетов по кредитным историям сотни гигабайт новых изменений от кредитных организаций и формирует миллионы уведомлений о полученных обновлениях для банков клиентов в основе бизнеса кредитного бюро лежат три типа продуктов обслуживание запросов отчетов по кредитным историям анализ изменений в историях и формирования уведомлений различных типов это так называемые триггеры а также оценка заемщика с точки зрения его надежности и платежеспособности так называемые спарринге триггер это некоторые события который является реакцией на то или иное изменение в кредитной истории чем меньше временной отрезок между изменениям и производным событиям тем выше вероятность успешной монетизации этих данных рассмотрим реальный пример михаил открыл счета в двух банках каждый из которых занимается потребительским кредитованием оба банка хранят кредитной истории своих клиентов в одном и том же кредитных бюро но банк номер два назовем его west best offer дополнительно приобрёл продукт триггеры в отношении ряда своих клиентов том числе и нашего героя михаила михаил приобретает в кредит новый смартфон и по случайности для расчета процентов и переплат обращается к менеджеру банка номер один клиентам которого самый является банк запрашивает кредитную историю михайлов бюро и после получения ответ и предлагает ему кредит под восемь процентов запрос кредитной истории от банка номер один также является ее частью аналитической платформы бюро обрабатывает запрос с точки зрения триггеров и генерируют уведомление для второго банка то есть банка в с best offer который ранее проблему солдаты соответствую услугу реагируя на полученную давление банк номер два присылает михаил с мсс выгодным контур предложением кредита под более низкий процент и клиент с радостью его принимает просмотренный сценарий описывает лишь малую часть возможных вариантов монетизации данных по кредитным историям ходе анализа требований и предпроектного обследования эти ландшафты кредитного бюро мы поняли что технический 100 кв asdasd а в основе которого лежит симбиоз уже ставший классикой big data и потоковых подходов к работе с данными может решить существующие проблемы и дать бизнесу возможность реализовывать принципиально новые продукты при разработке аналитической платформы критически важными для нас являлись следующие требования первое это снижение той тумаркин для новых продуктов второе переход от пакетные к потоковой обработки и real-time продуктом с минимальными задержками обработки третье внедрение технологий машин в обучения и жизненный цикл разработки моделей так называемый м.л. abs для задач с харинга и 4 надежность гибкая горизонтальная масштабируемость и высокая отказоустойчивость платформы для достижение поставленных целей мы применяли лучшей практики devops и m black работаем с репозиторий моделей мой flow и тепло реализуем процессы соседей используем современные фреймворке библиотеки потоковый как стать вас такой state hwy обработки данных batman клауд fluo пачек нинка патчей spark а к streams оперируем дата лайк на базе hadoop используем apache cassandra до оперативного ханин данных и c в качестве хранилища файлов масштабирование отказоустойчивость обеспечиваются рядом подходов и технологий в основе которых лежит платформа артист рации контейнеров опыт shift центральной части топологий аналитической платформы находится высоко нагруженные потоковые приложения который также называется pipeline нами они разработаны с использую приборка апачи frank который располагается под зонтом продукта облачная регистрации разнородных потоковых сервисов которые 20 band клауд flow структур платформы полностью соблюдает концепции реактивной архитектуры само действие между отдельными сервисами и pipeline и полностью асинхронно и реализовано с помощью apache и кафка экзотическая платформа разделена на технологические под модули которые обладают слабой связностью независимо масштабируются и строго изолированной можно выделить следующие основные модули аналитической платформы первый это pipeline и подавались на обработки данных которые обслуживают процессы захвата анализа и трансформации входных данных второй этап а система master data management которые идентифицируют изменения или запрос и определяет к какому субъекта кредитной истории он относится 3 этапа планы триггеров и поклонись корнаков это основные и самые нагруженные потоковые приложения платформы который обслуживает соответствующий бизнес продукции в том числе оперируют модели машинного обучения в школе нга система выявления изменений и формирование гектаров данных для бизнес-планов и модели обучения это наш последний под модуль источники данных и магической платформы можно разделить на два сегмента первый сегмент это онлайн потом который включает запросу скоринга и отчеты по кредитную историю томасу these руется в платформу при помощь юриста и пиа и построенном на базе той крикет ловок это поток обслуживается stateless микро сервисами и выделенными pipeline амин основе like being light wool & ака string на данный момент они обрабатывают около трех с половиной 5 миллионов запросов в сутки тросик мент источников это пакетные данные которые состоят из файлов с изменением по кредитным историям пакетным запросов спаррингов отчетом по историям а так же с сервисным файлами которые обслужен из продукта платформы например списке клиентов для отслеживания в отношении триггеров этот сегмент обслуживается высоко нагруженными потоковыми приложениями на основе патчи фринк и в данный момент обрабатывает 80 миллионов изменений в сутки с равномерным распылением нагрузки с пиками до 15000 событий в секунду каждый из сегментов и модуля аналитической платформы спроектирован с учетом гибкое горизонтальные масштабируемости пакетные данные 2 сегмента анализируются и разделяются на отдельные события с момента появления такого события платформа функционирует в рамках событий на ориентирована архитектура каждое обновление или запрос проходит идентификацию в подсистеме master data management и обращается сведений о субъекте изменения эти обогащенные дискретные события в потоковом режиме передаются в под систему выявления изменений и далее обрабатывайте специфическим зависимости от типа при обработке изменения кредитных историй рассчитываются дэн ты так называемые состояние было стола и соответствии с текущей настройками формируются новые события для дальнейшего анализа в pipeline их триггеров и формирование онлайн уведомлений для клиентов дура давайте вспомним наш кейс с михаилом его покупкой подсистема оперативной обработки событий также занимается расчётами викторов а так называемых печей для модели сколь инга при поступлении запроса на скоринг вектор извлекает из оперативного хранилища и подается на вход модели видео из запроса сама же модель при этом сзади плана как обычный под кластера опыт shift разработка модели машинного обучения для скоро выполняется в отдельной области так называемой аналитической песочнице это 1-ый класс строкам shift и инсталляция cf или hadoop оснащенные инструментами до работы специалистов в области дата сайнс проект гипотез валидации моделей а также механизмы гиннеса моделей в продакшен на базе репозиториев модели имели flow результата работы бизнес сегмента фанатической платформы . результаты запросов кредитных историй спален гав а также события по триггером могут передаваться к ментам в режиме онлайн через и пео или с помощью services and events или пакет на с помощью файлов механизм получения результатов зависит от возможности и потребности кометы и никак не ограничивается стороны платформы в ядре технологического стыка платформы лежит фреймворк артист рацией гетерогенных потоковых park live live band плавать flow фактически это зонтичный фреймворк объединяющую к верните с операторы apache spark а почерк pink & ака который позволяет строить разнородные с точки зрения бэкенд pipeline в контексте единого метаописания и процесс в диплом этап среди выпускают или каберне tissot взаимодействия между компонентами pipeline of асинхронная для этого используется пачиков как единый цикл apache web link и apache spark делегируется соответствующим кубер найти с оператором подавляющее большинство потока и приложений аналитической платформы работают сохранением состояния так называемый state фил обработкой 90 процентов straight pull обработки выполняется с помощью apache и fling остальные десять с помощью apache и spark и в основном это касается работает до толик и hadoop потоки встретил обработки на по чаплин зачастую шарнира ванны с высоким максимальным параллелизмом что позволяет быстро менять степень параллелизма операторов на более на горных участках проекты и выполнять горизонтальное масштабирование системы с появлением нативной поддержки губернаторе vizio против фильм 13 надцать перспективе мы планируем отказаться от текущего купить из операторов рынка от компании не вт и реализовать динамическое масштабирование falling гробов тоже настал момент делать выводы проект аналитической платформы для активного бюро позволит полностью перевести существовавшие ранее бизнес продукты на real-time обработку радикально повысило производительность отказоустойчивость масштабируемость за счет новые реактивные событий на ориентированный архитектуры ключевой бизнес продукты триггеры теперь выполнять в режиме онлайн и задержка между получением обновление и формированием события для клиентов 90 процентов случаев не превышает 10 секунд при пиковых нагрузках аналитическая платформа обрабатывает десятки миллионов изменений ежедневно от службы и высокие пиковые нагрузки до 15000 событий в секунду и при этом имеет возможности для гибкого горизонтального масштабирования с ростом числа клиентов средства разработки проверки и вы в продакшен для модели машину обучения также позволяют повысить качество продуктов скоринга и снизить тайм ту марки для новых моделей и продуктов технологии фас дата и потоковой обработки в целом позволяют достичь минимальный задержек и значительно повысить монетизацию ваших бизнес данных олег привет я артем я бывший редактор хабра сейчас ведущий подкаста мы обречены рад познакомиться за росте добрый день меня зовут сметанин олег я технический архитекторы и delivery лид практики разработки заказных приложений и сервисов компании akcent akcent я слышал очень большая компания да действительно компания в санчи это глобальная компания официальным метрикам в ней больше 500 тысяч сотрудников 50 странных 200 крупнейших организациях города компании глобальной это глобальность видно когда ты находишься в диалоге или можешь обратиться там в базу какую-то нас есть базы база знаний и ты можешь посмотреть как примерно подобные проекты решались в японии там недавно или в испании как такие проекты делались такая хорошая к система который естественно приходится управлять это управление выглядит может выглядеть примерно следующим образом сформировали новое направление клад first то есть это стратегическое направление в котором сейчас компания развивается определили в этом направлении там 70 тысяч сотрудников всех обязали это кстати не то что обязали способствовали тому что все начиная от аналитиков и заканчивая исполняющими директорами получили сертификаты официальные то есть прям это от рен даров сертификаты все по-честному со сдачи экзаменов и все это в массовом масштабе да то есть это это работает действительно и соответственно таким образом и идем и delivery мы то есть историю дальше раз каждая каким проектом занимается да ну вот наши заказчики это топовые компании из таких индустрий как банками то есть финансовой сферы ритейл ресурсы они приходят к нам не улетал чтобы мы помогли ему развить новые направления бизнеса технологических обеспечить или модернизировать существующем бизнесе нет из тех проектов которые сделаны с микро сервисной архитектурой нашим заказчикам могиле very glad на эти приложения с микро сервисной архитектурой для современных регистраторов таких как к бернейс лучших вот из таких приложений с которым вы могли наверно столкнуться можно отметить такое решение как кредитный конверт для банков то решения позволяет с учетом рисковых моделей данных о клиенте данных и о доходе данных профиля клиентов банки разноплановых данных из внешних источников система анти фродо рассчитать перед удобренная предложил предложения по кредитам для десяткам миллионов потенциальных заемщиков и за 40 секунд например автоматизировано принять решение о выдаче кредита превращений заемщика по существующим каналам связи ну то есть мобильном банке там обратиться и соответственно получит за 40 секунд ответ другим каким-то проектом решением с которым вы могли столкнуться является тот логистическая логистический сервис который позволяет заказать на алиэкспрессе какие-то товары онлайн и забрать их в ближайшем магазине это система которая интегрирует и большое количество лидеров и коммерса и предоставляет интерфейс и и опять для скажем минорных участников этого века мир с таких мелких скажем интегрировать систему управления складами систему управления транспортом система управления лагерными сетями поста матными сетями вот и уже сейчас это решение перевозит порядка двух миллионов ваших заказов привозят их в магазине но вот как жить как делать правильно чтобы вместо монолитного да не получить интеграционные ну есть да ряд методик которые и мы рекомендуем скажем так тогда когда мы внутри системы по сервиса наши мы там формируем некую микро сервисную поставку она включает себя имплементацию самого сервис это та всем понятно дальше клиенты к нему на том нативном языке на котором будет потребитель с большой долей вероятности работать то есть он в простейшем случае просто берёт нашего клиента который может работать по синхронным протоколом по асинхронным протоколом и мы считаем что мы транспортом такой глупой микро сервиса умные и мы подставляем красивого удобного понятного клиента так чтобы на этапе компиляции уже было понятно где этом потребитель и и им этот поставщик то допустим расходимся это вот там одна из первых мир 2 мера значит но если это потребитель какой-то внешней очистим эту самую спецификацию поставляем типа об анапе а если например истовой история для того чтобы он смог на любом другом языке который там считают нужным использовать своих системах так по практике мы интегрируем ся совершенно разными технологиями бывает там на той стороне и поэтому например у нас java то там поэтому там допустим для них сразу там об анапе схему поставляем причем важно тут два момента несколько текущую схему поставить да сколько договориться о будущих изме и никто есть вот этот самая большая проблема сказать что те и вот к такому-то релизу у нас будет вот такая ситуация и пожалуйста под нее подстраивать значит это очень важный аспект который я во многих корпорациях ну скажем так как на базе базовой базового менеджмента api не вижу частая история это когда смешней интеграции вот у нас есть условный confluence и мы там документацию пишем там какой то плюс минус произвольной форме не компьютер на читаем не компьютера или the new нельзя формальной спецификации щит считать естественно там много расхождений может быть таким подходом и когда и выясняется то всем на гораздо ну на поздних этапах таких как фпс . стенды только там потом поняли что серьезно разошлись в понимании происходящего потому что человек читал не компьютер не машина вот-вот в эту же микро сервисную поставку входит там блоки связаны том числе съем то есть там перри используем компания каждый как бы микрофон свой делают для своего домена то есть разные аспекты и в том числе как это легкая интеграция и связям внутри компоненты которые прибиты гвоздями если по-простому говорить каким-то сервисом который легко использовать чуть-чуть под конфигурировал и все вот тебя есть элемент выбора из справочника не знаю локаций точки доставки с картами со всеми штуками вот есть другие практики такие как вот контрактные тестирования и это еще гораздо более сложная история и и надо сказать что тоже корпорация многие к этому не готовы то есть на уровне методологии мы этого не видим когда например консьюмер потребитель сервиса может выставить свою часть контракта сказать что вот пожалуйста провайдер я жду от тебя вот такие вот там поля такие-то значения в каких-то местах в таких-то структурах и ты не можешь выпустить обратно не совместим и сервис не учтя этого опять же управление версиями в общем набор техник вот виде микросфер из на поставки которые правильно артефакты для консьюмер а для потребителя выдает контрактные теста вот они все помогли бы в значительной степени все это интегрировать без шума ну куда бы не завел нас прогресс я желаю вам успехов всем спасибо до свидания спасибо мы все спасибо что пригласили сами так отличный звук есть мы продолжаем нашу трансляцию я вот единственно хочу получить подтверждение что в трансляции есть супер отлично итак сейчас мы продолжаем с докладом про база данных у нас видимо сегодня много про база данных вот и мы поговорим про майский эль вот для этого я приглашаю на сцену как меня слышно в супер всем привет спасибо что пришли на мой доклад несмотря на его такое странное название меня зовут константин регунов я руководитель группы эксплуатации интернет-магазина эльдорадо и сегодня я вам хочу рассказать немножко про внутренности в нашего mais quel заглянуть под капот но сильно глубоко заглядывать мы не будем мы посмотрим сверху на то что там происходит поэтому не бойтесь глубоко технических терминов не будет но начнем с предыстории я к вам немного даже случайно попал мне в марте позвонили девушки с незнакомого номера я подумал что это оказались девушки и зонтика которые пригласили меня на конференцию ну начнем последние несколько лет мы распиливаем наш монолит в на базе битрикса ни для кого это не секрет платформа достаточно старая и тяжелая сразу сделаю пометку такую со звездочкой когда я говорю битрикс я имею ввиду очень-очень старую версию битрикс и к современному битрикс у она может не иметь никакого отношения потому что у нас версия которая последний раз обновлялась примерно в 2012 или тринадцатом году где-то в этом районе это совсем не тот битрикс который сейчас и есть огромная часть которая сейчас пилится на новом стеки и так uber куча сервисов на ноги кошки и других языках но мы будем смотреть сегодня промо и сквер который находится под основным монолитом на него нагрузка не падает несмотря на то что мы распиливаем потому что трафик растет спасибо пандемии в последнем году у нас там чуть ли не 100 процентный рост по онлайн продажам и перед тем как погружаться дальше поднимите пожалуйста руки те кто использует москве в продакшен отлично много людей значит точно что-то полезное для себя вынести сразу скажу что битрикс это в нашем варианте такая тяжелая система которая на одной странице без кэша может генерить сотни тысячи запросов в зависимости от того какая там сложная логика завязано это все выливается в огромный рпс на весь кластер это примерно в районе 50 fps если говорить про текущий момент времени высокий сезон это может быть еще в два раза больше легко поэтому этот кластер мы должны очень хорошо оптимизировать поддерживать и есть еще такой нюанс у битрикса он может генерить нагрузку на чтение с мастеров потому что после любого модифицирующие во запроса он переключает поток select запросов тоже на мастер как вообще обычно масштабируется такая система когда растет нагрузка естественно добавляют слоев добавляют другой мастер активный например об чаще всего конечно это пассивный стендбай или слоев на который потом переключается мастер и остальные слои бы вот но в нашем составе был именно активный мастер мастер на каждой зоне был свой мастер и как-то у нас добавился 2 сот поскольку система высоконагруженные и постоянно должна быть доступна онлайн по 2 сот прилепили к этому мастер мастер кластеру из чего получился такой франкенштейн такой сетап в котором кольцо из четырех мастеров первый мастер пишет во второй второй мастер пишет в 3 3 мастер пишет в 4 и 4 пишет в 1 вот такой вот франкенштейн вроде бы на четырех ногах стоит но если мы любую ногу этого франкенштейна подпилим то наверное он все таки упадет упадет сильно много ли это нам добавляет вообще стабильности скорее создает проблемы и вот с этими проблемами с этими болями мы жили очень долго жили даже не если не преувеличивать то лет 7 наверное жили вот в таком сетапе какие же проблемы во первых если у нас любой мастер отказывает то начинаются пляски с бубном у нас поток репликации перестает писаться и соответственно весь кластер становится не консистентных на одних словах есть данные которые писались в 4 мастер например она других словах нет этих данных просто потому что связь между этими мастерами разорвана мастер вывод вышел из строя это естественно не единственная проблема а если придут прилетел тяжелой апдейт до точно также репликация начинает лагать начинает тормозить транзакции выполняется долго она не попадает в бинарный лог очень долго даже если попало то потом нужно подождать еще кучу времени чтобы она попала на следующий мастер потом еще время чтобы на следующий потом еще время что попало нас life на самой отдаленной зоне то есть как минимум четыре шага это должно пройти это должно записаться и в табличке на типичные в этот сторож и в репутационный логе если посчитаете сколько их щенков должно выполнится чтобы это все прошло по такому сетапом то можно схватиться за голову на все это еще нужно наложить то что у нас достаточно много товаров но если не сравнивать marketplace сами там конечно побольше и у каждого товара в каждом регионе может быть своя цена их нужно обновлять это обновление помимо того что вызывает обновление самой цены еще вызывает обновление кучу связанных сущностей поэтому поток записи в этот кластеров в это кольцо он тоже достаточно большой кроме цены еще есть и остатки и логистические цепочки когда один остаток может перемножаться еще на 100 складов и обновлять автоматом доступность по сотне точек и чтобы подлить еще масла в огонь и стала совсем больно у нас была версия 55 на мастерах и как вы понимаете в таком сетапе когда мастера работают в кольце обновить тоже не так просто и вдобавок еще и белок роу имидж full когда пишется все полях которые были до все поля которые были после в бинарный лак и соответственно объем бинарных логов тоже из-за этого у нас был достаточно большой буквально перед конференцией я специально посмотрел сколько же у нас в момент когда идет интенсивная запись рпс на обновление всех этих сущностей это вывод греппа из миски и альбин logo поминутный соответственно цены здесь далеко не в топе да они в топ-5 входят но намного больше апдейтов проходит по другим таблицам это мой блог элемент проб с 31 если кто-то с битрикс им работала кстати поднимите руки кто сбит рексом работал вот вам должны быть знакомы эти таблички естественно у нас 31 инфоблок в которой тоже пишется много чего это там хранятся детальное описание товаров если просуммировать то что то в районе двух тысяч модифицирующих рпс у нас прилетает в этот кластер в отдельные минут и естественно может быть и больше может быть и меньше я специально не искал а просто выбрал перед конференцией произвольный момент долго думали что же с этим делать как поступить рассматривали разные варианты думали насчет галеры думали насчет экстра тебе глостера может быть на них переехать вроде как есть совместимость и все должно быть замечательно хорошо но у нас были свои нюансы использования кластер а про которые я вам расскажу сейчас обязательно может быть они вам пригодятся энди бьют мы сразу отмели это совсем было не в ту степь а когда изучали описание галеры то в ней было важное ограничение что она работает с точки зрения репликации бинарных логов только с движком и на тебе к сожалению или к счастью мы используем не только и no debe используем активно еще и black hole и так как гарантий что там это все будет работать нормально не в галлерею не в экструдере кластере тоже нет поэтому в чем основные плюсы этих систем то что они позволяют осуществлять синхронную репликацию и гарантировать консистентной состояния во всем кластере но при этом такая запись тогда будет очень долгой и придется дожидаться от всех мастеров слоев подтверждения транзакций поэтому современном мире а синхронная репликация остается преобладающей для того чтобы масштабировать скорости доступность теперь чуть подробнее про black hole за что мы его так любим поднимите пожалуйста руки кто вообще знает что такое зачем это нужно применять отлично все теперь узнают это специальный движок в москве ли он встроен по умолчанию обычно даже включен не надо ничего делать он работает сразу из коробки в этом движке он реально представляет из себя черную дыру ты в него пишешь а он ничего никуда не пишет в таблицах на диске будет лежать пустота в чем же его фишка и особенность он не пишет ничего в таблице но пишет в репликации он эй log за счет этого мы можем на одном из своего в кластере например или на нескольких за артрите джонс и на тебе и тогда эти данные появятся в этой таблице на отдельном сервере при этом они будут не содержаться на всем кластере это очень полезно если вы например пишите какие нибудь архивные данные которые не нужно просто хранить к ним очень редко идут обращения и в этом случае это может пригодиться но конечно же есть нюансы например если у вас есть праймари ключей обычные софта инкрементом в этой таблице то все инсульт и всегда будут с этим одинаковым праймари ключом и поэтому это может для вас не работает для вашего кейсы нужно адаптировать приложение чтобы оно могло использовать эту фишку у нас она используется очень активно и когда мы планировали обновление тоже был ряд ограничений конечно админы у нас не хотят что-то делать лишний раз руками они любят надежны и устойчивы и решения которые не падают и фишки репликации нам нужны обязательно это одно из главных ограничений и с точки зрения эксплуатации мы хотим сохранить совместимость со всеми нашими инструментами которыми осуществляется мониторинг и диагностика проблем и так далее ну и конечно обновление должно пройти без downtime официальная документация мускуле говорит что для того чтобы обновить мастер в репликации нужно чтобы все слои вы были 57 поэтому злобный тролль над нами посмеялся взглянул на наше кольцо мы почитали голову подумали а как же его обновить думали очень долго придумывали разные варианты даже пошли сначала на рынок поискали подрядчиков которые могут помочь нам в этом но к сожалению таких подрядчиков не нашлось кто бы придумал надежный гарантированный способ позволяющий выполнить такое обновление ну а для обновления что нам требовалось если с клиентом все понятно клиенты совместимы между версиями то несовместимая частью это как раз бинарные логе которые пишутся в разных форматах есть несколько опций в бинарном логе которые позволяют плюс-минус организовать идентичность форматов между версиями их можно покрутить включить и получить в 57 практически такие же реплика ционные логин как и в 55 мы это естественно не могли просто вкрутите и пустить на продакшен мы это очень активно тестировали для тестов нам понадобилось кольцо там мы это кольцо развернули на одной из виртуала чик примерно вот конечно вряд ли вам видно слишком мелкий шрифт но с помощью например москве льда мульти можно прямо на одном посте сделать несколько разных дата директорий для инстансами sql и поднять на разных портах эти инстанции после этого взять и подменить версию отдельным пинар ником конкретного инстанса и попробовать как же это будет работать мы сделали очень простой тест мы взяли развернули такое кольцо подменили версию и попробовали залить dunk нашей же базы в один из мастеров в этом кольце это базовый самый простейший случай когда хотя бы мы пройдем по всем нашим данным по всем типам колонок что они точно запишутся точно от реплицируется проверим на всех этих инстансах что конкретно произойдет не будет ли падение не будет ли несовместимости и конечно мы такую несовместимость нашли она в принципе есть в официальную документацию москве но чтобы ее найти нужно ни один час посидеть в этой документацию а это несовместимость полейте падает time есть еще несколько кроме daytime а идиte в том числе и time у нас таких полей оказалось всего 240 и любой ддл запрос который модифицирует эти поля он автоматом падал и клоуном репутацию почему потому что начиная с 5 6 эти поля имеют другую версию них другой идентификатор у них другая суть почему потому что добавились микросекунды в эти поля все что создано ранее в целом работает и и следы дела нет то можно попробовать и полететь на такой схеме но только в случае если вы гарантируете отсутствие ддл чтобы никто не модифицировал эти колонки эти поля тогда это в целом вроде бы даже работает и по нашим тестом могло бы так поехать но рисковать мы не хотели брать на себя ответственность если вдруг репликации развалятся потому что починить ее это не один час в таком варианте мульти source для нас показался волшебной пилюли которая решит сразу огромный пласт проблем которые в этом сетапе в кольце есть обычно люди делают нормальные кластеров к вич когда делают один мастер делает пачку слоев но если решение нормальная нам это не подходит неинтересно надо что-то оригинальное придумать мы решили сделать всё наоборот и мой стиль такую конструкцию поддерживает можно писать в 4 разных мастера и все эти изменения сливать напрямую в конкретный slave более того не нужно даже переучиваться почему все команды которые работают с репликации те же самые абсолютно этот cinch мастер единственное изменение мы добавляем в этот cinch мастер face ну это именованные каналы которые можно назвать как угодно и с ними работать таких каналов тоже может быть сколько угодно у каждого канала отдельный поток репликации отдельный белок отдельная позиция таким образом получилось вот такая вот красивая схема она может быть кажется немного запутанной на самом деле у каждого мастера появилась условно 15 слоев при этом это все мастера активные мы в любой можем написать и изменения сразу же напрямую миную бинарные логе через logs for days которые прокачиваются попадают напрямую slave важный нюанс у нас есть специальные технические славы внизу они выделены это слои вы на которой не попадает боевая нагрузка пользователи который заходит на сайт и используются они для разных целей либо для бэкапов либо для того чтобы делать аналитические выборки тяжелые и не блокировать базу для остальных пользователей также есть специальный отстающий slave который содержит все состояние кластер а но на несколько часов назад схема мне показалось очень хороший может быть выменем в вопросах потом разубедить и и расскажите а и и минусах начали думать как же мигрировать на такую схему и решили что один из технических flyleaf как раз станет мастером для нового кластер а единственный минус что нам понадобилось примерно столько же железо сколько уже было затрачено на этот кластер чтобы развернуть на этом железе новый мы подняли новый multimaster временно на нем включил огс life апдейт для того чтобы через его бинарной логике тать весь кластер который будет уже по мульти мастерскими построен так у нас добавились все остальные мастера здесь это было уже многопоточная репликация у каждого мастера свой канал их для простоты назвали канал мастер один канал мастер 2 канал мастер 3 канал мастер 4 и естественно вся обвязка из слоев тоже ну для того чтобы схему не усложнять я ее не показываю на слайде вроде бы все хорошо кластер получился в состоянии prado в реальном времени обновляемый целиком и мы в любой момент времени можем на него переключиться единственный минус у нас нет пути обратно поэтому это нужно было тщательно протестировать и в первый раз когда мы это развернули мы тестировали очень долго и проводили нагрузочные тесты проверяли что все работает дать у него или конфигурацию в том числе по выполнению запросов в параллельном режиме но есть нюанс и конечно же во первых нужно подумать про балансировка нагрузки как эта нагрузка идет и какой ее характер у нас честный round robin пользователь приземляется на абсолютно любой мастер и его поток записью раскидывается и на мастера in если вы даже если следующий запрос пришел на другой мастер то это не имеет никакого значения принципиального подчеркнув нормальном состоянии кластер а когда нет отставания отставание может быть всегда потому что никто не отменял тяжелые запросы и нужно учитывать возможный лак репликации если вы разрабатываете системы которая работает смысле в кластере то очень полезная опция которую я советую вам применять это поставить на d в стендах slave который будет отставать хотя бы на одну секунду вы возможно найдете сразу очень большое количество фантомных багов которые всплывают на продуктивен у которой вы не можете воспроизвести в тесте и конечно нужно учитывать что инкрементные полях закончится быстрее о чем речь каждый мастер чтобы он был активный имеет свое значение auto increment of сета и у них у всех авто инкремент инкремента 4 то есть они все про мире ключи увеличивают не на единицу как обычно она 4 но каждый со своим смещением поэтому про мире ключи которые записаны на разных мастерах друг с другом не пересекаются про эти во все то надо не забывать особенно обратите внимание на нагрузку на сеть на мастерах почему потому что эти 15 каналов репликации они могут уберется все это легко особенно если вы что-то большое пишите поэтому перед тем как такое делать обязательно прочитайте хватает ли вас канала позволяет лететь если у вас ресурсы для того чтобы например 100 мегабит записи умножить на 15 и конечно еще большой очень пласта вопросов наверняка будет про онлайн миграции онлайн миграции будут затронуты на следующем слайде и чтобы эту нагрузку на сеть минимизировать нужно еще выставить параметр для того чтобы бинарной логе тоже занимали минимум места белок рау имидж минимум в этом случае мы в бинарный ловко распишем не весь набор полей да и весь набор полей после а только одно конкретное измененное поле автоматом уменьшая в десятки раз размер блин логов который почти бегают теперь к онлайн миграция на рынке есть много инструментов которыми пользуются большая часть пользуются пир клонов skype лозой потом онлайн ский матч кто-нибудь в зале пользуется перуанской тузами вот это был за на самом деле очень похоже на то что мы используем мы используем гост это тоже широко распространенное известное решение но у них есть некоторое отличие из лепреконов скоту за работает на триггерах то есть на таблице вешаются триггеры на апдейт триггеры наделит и создается отдельная таблица которая сохраняет чулок и этот чин влог формируется по этим триггером то гост этот утилита которую сделали в гитхабе в этой утилите нету триггеров за счет чего это достигается один из слоев тоже начинает писать бинарные логе включается logs for dates он и все события модификации таблице они нативным способом без каких-либо дополнительных телодвижений приходят в бинарном логе либо далее ты либо апдейты и соответственно не нужны никакие промежуточные таблицы которые будут хранить измененное состояние по записям в этой таблице рядом формируется как и везде во всех этих утилитах а рядом формируется таблица в новой структуре и в нее потихонечку копируются данные если вдруг по бинарному логу для этой же таблице пришли какие-то изменения то выкачиваются нужные ряды и эти изменения тоже применяются и к гост таблицы которая рядом всегда готова до за лица важный нюанс который нам пригодился очень сильные которого нам не хватало в пир клонов sky тулга это контроль отставания репликации по другим словом то есть мы можем задать список слов которые мы хотим проверять и в случае если эти слои вы начинают отставать на примерно 300 миллисекунд или на секунду мы можем задать этот порог и можем сказать что если хоть на каком-либо из этих слоев есть такой отставанию ты пожалуйста вот эту миграцию и копирование данных в гост таблицу прекрати приостановить подождите пока это отставание уйдет и только потом продолжай за счет этого онлайн миграции можно делать в любое время их можно делать днем их можно делать в час и высокой нагрузки можно делать ночью и откладывать switch этих таблиц на любой момент времени вперед например сделать в миграцию ночью и отложить на рабочие часы можно проконтролировать что в этой новой таблицы все корректно с данными все корректность в кодировками ничего не пропало есть драй раны и так далее в общем мы очень много пользуемся этой утилитой она доказала свою работоспособность и она по сути единственная которая может применяться в multimaster схеме потому что триггеры повешены на одном активном мастере ничего не дают изменение пишутся и на другие в том числе поэтому возможно вам это тоже будет полезно ну конечно без ложки дегтя не обошлось есть и минусы конечно это сложнее настраивать сложнее поддерживать сложнее мониторить но надо сказать что не сильно сложнее ну да у вас четыре теперь потока репликация ни один вы мониторите в четыре раза больше но для любой нормальной системы мониторинга это непринципиально сколько там метрик важный минус который мы поймали и которым я хотел бы поделиться это то что берлоге проигрываются с разной скоростью если вы вывели один из слоев обслуживания захотели что то найдем сделать оффлайн и потом через час включили то поскольку у каждого из бинарных логов есть свой worker свой процесс который этот бинарный лог применяет он процесс синхронизации между применением разных бинарных логов не производит он применяет свой белок с той скоростью с которой может его произвести из-за чего набор данных при таком вот выключение и включение может резко отличаться у вас нарушается транзакционных и порядок выполнения транзакций у вас может прилететь апдейт для которого еще не прилетело insert соответственно этот апдейт не применится и все это приводит к не консистентной sti но если у вас кластер работают нормально вы мониторите отставания вы оперативно принимаете меры то таких проблем быть не должно не сколько еще опции которые полезно было бы вкрутить для того чтобы немножко быстрее репликация работала это использовать параллельные worker и больше 5 наверное в целом никому не нужно там обычно они не загружены можно в performance схеме посмотреть насколько они сильны используются главные плюсы для нас это то что такая схема позволяет любой мастер в целом выключить в любой момент если вдруг что-то с ним не на его произойдет упадет сгорит железо все остальные мастера при этом продолжают работать в них работают прекрасно запись кластер тоже сохраняют работоспособность все слои вы получают все обновления и даже переключать свои вы из них на другие мастера не надо поэтому с точки зрения эксплуатации даже упрощается поддержка такого кластера меньше размер бен логов про это я уже говорил и главное что у нас всегда теперь только одно плечо для репликации используются и поэтому изменения попадают быстрее ну и наверное важный фактор 25 процентов записи которые в этот момент теряются когда падает мастер точно также можно спроецировать на то что когда лагает этот мастер он точно так же влияет только на 25 процентов потока записи и 75 при этом процентов пользователей прекрасно себя чувствуют и даже не замечают что то идет не так доклад не был бы интересным если я в нем не рассказал про fa cup of a cup у нас был и ни один самый интересный и самый жесткий который привел в этом году к часовому downtime и даже несколько часовому это были плановые работы по переключению линий питания и эти линии питания переключались под из хадаш к их как вы понимаете отказала по и без хода школе globe полностью на этой скале жки крутилки весь кластер а кроме этого кластера крутилась еще много всего включая и гид лабы и много других сервисов но нам понадобилось несколько часов чтобы все все все поднять считаю в таком варианте это не самый плохой результат если у вас есть вопросы готов по хули варить пообсуждать и и волкам в а можно у меня появился газ пышно сила спасибо за доклад вопрос про данная консистентной после сбоев данные расходились и и как вы с этим боролись конечно расходились конечно они расходятся регулярно и без сбоев на самом деле если постараться все проанализировать есть несколько вариантов вообще как с этим бороться во-первых можно максимально изолировать пользователя и привязать его к конкретному мастеру то есть весь поток данных который он пишет он пишет только на один мастер другой пользователь пишет на другой мастер и в таком случае расхождение данных практически не будет происходить но для этого нужно адаптировать приложение почему не будет происходить потому что все транзакции которые тут пользователи производила не и выполнится вот в том же порядке в котором он их накидывал если нельзя сортировать что что если сортировать нельзя пользователя по если сортировать нельзя ну тут остается только надеяться и ждать до optimistic стратегия как говорится меня вопрос еще вопросы можно я задам вопрос а два вопроса как у вас трафик что вам нужно 15 слоев и второй вопрос это все в одном ну да центре на текущий момент это стало в одном раньше это было в нескольких и скоро это тоже будет в нескольких снова насколько будет мастер удалены друг от друга что касается вообще количество серверов таких и общей нагрузки трафик относительно небольшой но это трафик тяжелый почему потому что это битрикс у которого в среднем на одну табличку приходится еще 10-15 дронов из других таблиц это запросы как правило двух страничные с кучей условий кучи выборок и так далее естественно мы можем ехать и на меньшем количестве но нам нужен небольшой запас еще поцелуи по всем остальным параметрам чтобы мы были гарантированно уверены в том что кластер не упрется в capacity как и когда будет два дата-центра насколько будет удален и мест мастера друг от друга я предполагаю что это будет в пределах москвы спасибо поэтому там минимальный лот на все должен быть скажите пожалуйста 23 раза три допустим такая ситуация у нас есть продукт сойди с ником 1 и ценой 100 и у вас приходит 2 апдейта одновременно на 1 и 3 мастера в 1 обновляется цена на 200 в другом на 300 мастера примет этот апдейт тут на самом деле это типичный рэс кондишен и гарантировать результат тут нельзя именно поэтому сам процесс применения цен у нас всегда идет на конкретный один мастер но я допустим и процент я вообще про любые апдейты просто по моему опыту когда мастер ну точнее slave принимает запись берлоге в нем говорится с какого на какое значение поменялось поле если предыдущее значение не совпадает она будет из банок если кто-то конечно транзакций отклониться да тут вопросов нет все будет отвлекаться становится придется пропускать на и потом восстанавливать консистентную по этим конкретным данным на самом деле мы это практически не делаем мы скорее адаптируем приложения чтобы таких ситуаций не возникало какие спасибо так а вот давайте сразу передам большое спасибо за доклад андрей прокофьев раз севастополь вы сказали что вот на уровне приложения вы заранее идентифицируете пользователей привязываете его сразу со потому что он писал свой свои действия на щеке там определенный мастер но поскольку сказали что это битриксе вас интернет магазин ту более бомбы там еще есть где-то учетные системы остатки обмен и как вот это вот все вместе живет живет прекрасно на самом деле все фоновые процессы у нас всегда работают с одним мастером и вся интеграция соответственно тоже завязано один мастер этого такая адаптация для такой системы не получится что там какой-то вот 3 пользователь до него еще не дойдет вот это дельта там товара количество не будет ну на самом деле у нас есть онлайн подтверждения из другой внешней системы по остаткам поэтому на финальном шаге корзины он случае проверится и другой вопрос как часто то система обновляет эти остатки и вот здесь есть проблема спасибо я вот хочу немножко продолжить историю про файл с рипли кации вы явно указали что до может быть ситуация у нас пришел insert одном было blade и до какого-то мастера который на самом деле слои в данной ситуации апдейт пришел после inserto это стоп репликации или она автоматически не запустится раскрыть это круто что вы заранее готовых такой ситуации вот расскажите как автоматизирует если автоматизируйте или как вы не сходите с ума если руками как вы справляетесь ситуация на самом деле мы просто и банально выключаем игнорируем ошибки прямо на уровне в конфигурации мускуле и отслеживаем логин который мускул пишет про ошибки применения таких транзакций то есть у вас помочь и нари руются эти ошибки и репутация идет дальше а в качестве деле routan смотрите за тем что происходило до такого вопроса да спасибо за доклад вот есть такой вопрос большое количество серверов то есть между ними настроена логическая публикация каким образом осуществляется контроль идентичности данных на этих серверах собственно наблюдая за logo мимо и сквера можно понять какие данные начинают расходиться если вы посмотрите в гирлок там будет конкретная транзакция который не применилась и эту транзакцию можно предлогом потом отследить что конкретно в этой транзакции не обновилась посмотреть поэтому идентификатору что конкретно содержится в базе на одном сервере на другом на всем кластере по этой записи сравнить и принять решение то есть тут арбитром выступаете вы их сами вы можете это фиксить руками можете использовать паузу и типа перк он овская туза есть для синхронизации но в нашем сетапе пока это не применимо спасибо спасибо за доклад уточните пожалуйста вы начали с предыстории что вы используете один из битрикс принципе я с ним я с ним постоянно работаю я знаю что он пишет огромное количество данных о что использованием простите я услышал чтобы говорить о что использовать один из битрикс тем более старой версии а и за ним работаете вы с ним семь лет вопрос за все это время у вас не возникло желание заменить битрикс на что то другое но если он действительно такой сложный и тяжелый но если вы обратили внимание на один из первых слайдов то желание конечно возникла и сейчас ну не меньше чем половина сайта это уже не битрикс совсем другой микрофибру снасть так который и на кубе работает и сервисы на кошке но на самом деле мы пока в начале пути у нас нет десятков тысяч сервисов какого вида или еще где-нибудь и это пока еще всего лишь в районе сотни может быть две сотни сервисов не больше спасибо за доклад дмитрий зайцев м3 два небольших вопросы 1 вы сказали что в некоторых ситуациях привязываете запросы конкретному мастеру вы это вручную делаете следите за нагрузкой этих мастеров и так далее что делаете если он там перегружен то есть как масштабируете да и второй вопрос не думали ли уже об обновлении на восьмёрку и если вдруг думали то это будет такая же схема значит начну с обновление обновляться на восьмёрку мы конечно же думали но пока ещё не решились и для того чтобы это движение началось нам нужно какой-то очень весомый аргумент почему нам стоит влаж вложить ресурсы и начать двигаться туда end of life хороший критерий да но пока еще 57 не windows live а первый вопрос повторите пожалуйста по распределению нагрузки есть хитрости есть данные которые для нас критичные это данные заказы все что связано с заказом пользователя в этом случае для получения такой информации мы всегда знаем номер заказа а по номеру заказа мы можем всегда получить офсет и узнать по офз эту на каком же мастере он изначально зайонц остался то есть мы можем был просто по номеру заказа всегда значит что а вот этот с первого мастер пришел а вот этот со второго и приложение может сама подключиться к конкретному мастеру и данные по этому заказу вытащить себе игнорируя вообще весь остальной кластер таким образом у нас по крайней мере по тем данным которые мы считаем для себя критичные мы всегда получаем точно именно тот набор данных который нам нужен так я вижу еще вопросы есть один вопрос здравствуйте спасибо не нарбут самый холивар на такой вопрос там был вопрос из зала по поводу замены битрикса у меня будет вопрос насчет замены свободы сторону погреться простите если можно чуть чуть погромче холивар ный вопрос насчет смены sbd сторону postgres конкретно в сторону пас грецию или в сторону какой-либо другой базы данных мы пока такой процесс в принципе не рассматриваем да у нас есть по с горя которая под сервисами крутится в кубе есть еще несколько других бостон и in memory все подряд но для того чтобы мигрировать просто так битрикс на пост грю ресурсы того не стоит на самом деле да это можно сделать но зачем у нас битрикс там условно через какое то время уже не будет поэтому сейчас нецелесообразно спасибо здравствуйте спасибо за доклад я вот хотел спросить вопрос у вас было там перка надо вы рассматривали там несколько вариантов вот почему то я не увидел мой успел есть там групповая репликация и вообще но свое как бы стандартное решение именно деби кластер вот смотрели ли вы в эту сторону как бы и почему не выбрали если смотрели энтеббе смотрели но даже на слайде было где-то она не в ту степь немножко это больше про то как размазать данные на несколько серверов они-то как сделать независимый сервер в который был бы полностью идентичен другому сказал что же им сказано да да это групповая репликация мне кажется новинка другой нет но по крайней мере мы пока они не увидели для себя зачем просто там много фишек и как бы стандартной комплектации уже там всякие мои скилле роутера используются и там в общем все это как-то само решается без вот этих мне кажется всяких разных схем на верном работа смотрели и стоит смотреть всем спасибо так есть ли вопросы еще вот это что вижу подойду и это будет уже во и мой последний вопрос спасибо за доклад у меня такой момент о технике репликации вот 55 когда вы использовали там понятно традиционная было 57 ну и собственно даже 56 сюжете айди global транзакцию найди по ее переключались на нее или так на традиционное остались на джетте один не переключались тут есть несколько субъективных причин нам просто не понравилось когда мы видим эти j10 а если в них есть еще skip и то шел sleeve tabs превращается в такую простыню из этих типов и пока это наверное более субъективная вещь да он полезен да он хорош но не захотели так константин спасибо большое за ваш доклад вам был задан очень много вопросов но если какие-то вопросы еще вы не успели задать или хотите задать уже лично непосредственно нашему докладчику то предложу проследовать в зону цифровых коларов там также можно будет онлайн вопрос задать так что если смотрите нас в трансляции то в общем то вас еще осталось возможность задать вопрос константин спасибо большое за твой доклад было очень интересно у нас для тебя есть подарки показать всем так и у нас есть подарок для самого интере вопросов и сам интересом интересный вопрос здесь то ты можешь уже выбрать выбирай про jukedeck progetti а иди до подойдите пожалуйста сюда у вас будет подарок год и дальше в этом зале будет тех толк в и после мы перейдем к следующему докладу в 1650 будет по расписанию это будет доклад уже валерия разном азова про проблемой согласованности моделей приходите accenture технологическая компания которая работает 120 странах и лидирует в областях разработка программного обеспечения искусственный интеллект аналитика данных devops безопасности облака системная интеграция управление приложениями и инфраструктуры в россии мы работаем в москве двери ростове-на-дону и удаленно из других городов сейчас нас более 1500 человек ежедневно наши идеи дизайна и код выходят в продакшн результатами нашей работы пользуются миллионы человек мы делаем высокопроизводительные find эко-системы которые помогают банком быстрее взаимодействовать с клиентами а мне канальные решения которые ускоряют процессы ритейл компании и делают электронную торговлю удобный во всех городах страны системы автоматизации и роботизации которые трансформируют производственные предприятия в большом сообществе инженеров мы работаем на современных технологиях и применяем гибкие методы управления проектами обмениваемся опытом встречаемся с коллегами из разных стран выступаем на конференциях и митапов присоединяйтесь к нашей команде будем делать большие и амбициозные проекты вместе павел привет йоркер нет я бывший до краха вы сейчас ведущий подкасте мы обречены при этом знакомиться на видно чем ты занимаешься я архитектор в решении работы в московском офисе компании redhead последние года 4 наверное я делаю всякие штуки вокруг devops а вокруг убираете с вами красивой архитектурой cell 5 тыс да я прочитал что ты учу вас компании популяризатора микро сервисов это это маркетинговый ход да смысле но это видение нашего маркетинга я более скромное прошествии персоне но в принципе да ну и что микро сервис итоге действительно хороши как они все говорят последнее время потому что я частенько начинают слушать критику критика была есть и будет это неизбежно но в моем понимании это это неизбежно ну на ближайшие какой-то обозримый там перспективу горизонт событий все равно все там будем часто бывает что действительно замечательная технология но технология подразумевает присутствие какой-то такой тур и каких на навык вокруг этих технологии часто не хватает но какие-то проблемы именно вылил их тут понимать что-то как бы кто и такое чтобы критиковать с одной стороны с другой стороны в неформальном общении я часто вижу часто понимаю то что допустим вот ситуация с abs с командой сопровождении каких-то там технологических платформ часто бывает то что с административной точки зрения руководства не готовы инвестировать в эту команду люди несколько оторваны от общего какого-то глобального цикла им через забор передают задачи и говорят справляется как хотите с ними не ведутся какие-то диалоги о прекрасно получается на выходе то что у нас такая борьба за псевдо стабильность мы боремся за то чтобы просто продолжала гореть лампочка на самом деле мы сидим своем отсеке славы понимаем что вообще происходит и что делать что делать есть такая идея то что давайте попробуем переделать психологию методологию работа нашего без команды в сторону и сэргэ чуть-чуть про наверно терминологий зачем это вообще нужно сырья по сразу сырья это сайт кривая бегите же милен я очень плохо собой и фразы дальше-то будет аббревиатура а зарыдает стране по сути это специальная редакция за самом деле devops практик потому что делится devops абсолютно те же фундаментальные принципы концепции главная разница то что мы как параноики пытаемся выстроить более отказывай устойчивую структуру с одной стороны с другой стороны мы принимаем перспективу наших конечных потребителей и это безумно логично моем понимании то есть мы мы воспринимаем любую операцию проблему как сортовую проблему то есть с перспективы того же пользователя абсолютно самое каком уровне у вас что-то сломалось нас просто и доступен сервис против нашего бизнеса на самом деле приблизительно то же самое поэтому все проблемы приступ write софтовые проблемы что порождает сдвиг в сознании abs команда садиться за 11 вместе с продуктами и разговаривать с ним на равных про и фактически получается что у нас разработчики становится функциональными заказчиками наш как решить я не очень понимаю зачем этот отличается просто культура devops потому что dls они вместе работы для справедливы да здесь мы можем устроить глобальный холивар на тему разночтений именно терминология предлагают вы не делать то есть ситуация такая то что по факту да действительно devops описывает все все все на самом деле что подразумевается и в сырые по сути на но по факту у нас не происходит вот этого сдвига но все равно есть некая изоляция команда нету понимания кто за что отвечает если мы идем в сторону и среде и разделяем вот фундаментальный парадигме скажем так и сергей когда у нас все у нас ведь одна большая софтовой проблемы тогда у нас не будет разночтений кто за что отвечает но ok например я понял что у меня в команде есть это проблема и я такое говорю давайте строить и сырья как это давайте давайте нам нужен человек с определенным административным рычагом который в принципе сможет вернуть эту историю который сможет объяснить зачем это делать и что изменится это во первых во вторых наверное нужно следовать хорошим культурным практикам по в плане создания именно в посреди к мельнице сырья каких-то команд хотя на самом деле практике также применимы в принципе создание любых команд пятну большей частью да это про культура про людей да я буду первым сказал то что провал это нормально ошибаться это это очень по-человечески все мы люди и дело не ваши деньги в качестве ошибки мне в масштабах от ошибки а в том насколько мы поняли где мы ошиблись и что нужно делать чтобы эта ошибка не повторялось следующий момент наверное я бы предостерег гоняться за звездами ванной webmoney тиной членов команды звезды я подразумеваю не просто одаренных и компетентных людей история когда определенный набор софт скилов 9 человек в вот именно в какую-то такую звездность болезни когда он порождает какую-то информацию борьбу за власть или как вариант и или на самом деле мы своими руками нанимаю звезду или звезд загоняем себя в рамках нашей предприятию в частность случай winder лоб и тогда там один или несколько человек действительно понимает как работает наливная систему ну вот про звезд я как бы понимаю когда слышу говорят вот проблема звезд это очень сильно технические специалисты которые ни с кем не считаются загрызли в секунду с практиками справили объект роста очень так стараюсь деликатно эту тему потому проговорить потому что это тоже надворная тему то есть с одной стороны до звезды позволяет очень быстро начать но звезда с с перспективы стороннего наблюдателя будет для нас аномалий потому что у нас такой глобальную всплеск компетенция как любой аномалия бы достаточно писателей спит катастроф поэтому нужно отыскать какие-то такие середину все и ну очевидно вот как как вывод из этого будет абсолютно готовы вкладываться в развитие своей команды пригодятся не за идеалом гоняться за потенциалом смотреть на софте килы причинам салфетки выявление не только моменте слышно парень хорошо умеет рассказывать какие смешные истории но то что он действительно понимает как как из что он делает в плане бизнеса чтобы он чувствовал бизнес на самом деле все звучит безумно прагматично но акцент же в реальной жизни этого очень не хватает и я думаю если об этом говорит и может быть что-то изменится вопросы доверия вот например частности то есть очевидно то что команда способна сделать гораздо больше чем каждый из нас по отдельности но без вес выстраивания доверия внутри команды без пропагандировали вот такого рода культурных практик но мало что получается на самом деле мало того должно быть доверие со стороны руководства потому что без доверия люди теряют способность принятие самостоятельных каких-то решений и мы его получаем от командами не очень сообразительных робот что тоже нехорошо мы вроде наняли людей мы долго беседовали мы выдворили с их навыками но с другой стороны постоянным объем их рукам и не даем принимать ему стать на решение лайка должна в моем ума ниоткуда что на быть такая то что на тех и специалист берешь на себя ответственность ты делаешь эксперимент понимаешь получилось не получилось но объясняешь сопутствующие риски какие-то чем мы можем поплатится за это мы так или иначе у тебя есть свобода самостоятельно принимать решения но это требует очевидно лирик мне кажется здесь немного по-другому эту проблему чаще слышу о том что доверие как раз очень мало при найме а уже после найма бросаю свою как буду учить плавать сам обычно впечатление складывается прямо моменте на именно момент первом собеседовании когда все жутко строги и спрашивать не всегда адекватные вещи и человек находится работа и продолжает жить в такой же парадигме то есть он боится как высунуть голову бы боится проявить инициативу bad login as раз повторюсь да звучит банально бумаги по имени действительно важен вот наверно еще бы хотел рассказать про момент что этого классика fans are so i am unity быть не согласны мы следовать курсу это на самом деле то же вытекает вот из из смелости из доверия из-за какой умеренной борьбы системы здесь как-то противоречиво звучит вот здесь мысль заключается в том то что кей для того чтобы развиваться нам нужно экспериментировать для того чтобы для того чтобы экспериментировать нам нужно какое-то направление для эксперимента потому что мы но очевидно не можете экспериментировать во всех направлениях сразу быть несогласным это нормальный ничего ужасного нету но идей заключается в том то что раз мы приняли какое-то направление мы должны ему следовать до того момента когда мы поймем то что либо шаги в этом направлении либо направлении целиком ошибочно когда мы фактически в реальном времени меняем вот это вот нашу направленность экспериментов в общем другими словами дают мы должны избегать аналитический паралич иначе мы будем вечно натыкаться на одни и те же грабли до бесконечности причем таким серьезный глобальные грабли которые нам не позволяют действительно развиваться не просто какие-то мелкие штучки мы что-то там подхватили нас не получилось а именно таких концептуальный большие вещи новые как твои успехи вот в внедрение от культуры а это неизбежно происходит потому что так или иначе как вот с чего мы начали то что есть запроса и со стороны бизнеса и стороны разработчиков страны безопасности откуда угодно есть запросы на имплементацию вот каких-то практических вещей с культурой заре так или иначе это нужно делать просто если это делать более и неосмысленное если понимать то что рано или поздно мы туда придем то это наверное жизни наши станет не может попроще но какие-то проблемы сейчас основные на твоём пути моем пусть они сами проблемы лак в понимании наверное бизнес и руководящего состава в в сознании проблематике то есть опять же вот это вот порочная практика то что пока пока у нас каптерке горицвет это буквально равно то что у нас все в порядке хотя на самом деле мы уже серьезно опоздали в нас уже есть большие какие-то комплексы проблемы то есть ты чувствуешь что сопротивление идет не от с персонала обычных разработчиков о псов и прочего а именно за руководство да но это не то что сопротивление это отсутствие такого осознанного понимания что происходит того что очевидно из-за своей роли людям тяжело вникнуть во все нюансы и пока не случится что-то из их вот показатели которые близки очевидно ничего не случится и вот с чего я тоже начинал по поводу того то что в реальной жизни чудес не бывает для того чтобы случилось изменение нужен человек с властью чтобы двигать эти изменения вот нужно найти холодное когда кто нас услышит о нас поймёт и о том одними тогда знает я желаю тебе успехов чтобы красиво большим лак непонимание исчезал и почти все получалось спасибо за рассказ спасибо валерий нам всем расскажет про проблемы согласованности моделей микро сервисный архитектуре работает компании accenture поднимаясь ну вперед давай всем привет меня зовут валерий разном azov я работаю в компании accenture вот наша к маленьком компания это консалтинговая компания которая предоставляет широкий спектр айти услуг нашим заказчикам в ряду которых являются крупные компании крупный бизнес и отличительной нашей особенностью является то что мы стараемся всегда сохранить первоначальную бизнес-идею заказчика то есть не испортить нашим внедрением наша эти системы каким-то нашим предыдущим experience on the что заказчик хотел изначально сделать дело все в том что когда мы следуем этой идеи мы нередко приходим именно к микро сервиса да почему микро сервис очень просто и это довольно гибкое решение которое в отличие от монолита не заставляет перекраивать все подряд казалось бы да и вот хотелось бы привести такой вот случай из жизни допустим у нас есть три банка один банк у нас занимается обслуживанием физических и юридических лиц другой банк у нас занимается выдачи ипотеки физическим лицам а третий банк у нас занимается допустим автокредитования все они являются составными частями единой банковской группы и вот регулятор выпускают требования о том что нужно им объединиться в одно юридическое лицо что за этим следует за этим следует то что все три системы пойти системы до нужно объединить в одну со всеми вытекающими отсюда неприятными последствиями его значит что у нас получается у нас есть такой объект как номер счета физического лица у нас тут же есть номер счета физика кто работает на банковских проектах тот знает то есть такие сленговые слова как физик и юрик кто в банках работает их вынужден понимать тут же у нас выплывает 20-значных счет физика тут же у нас 12 значный счет физического лица потом номер счета отделение в котором открыт счет и номер счета физического лица уже без физика да просто без привязки физическая это лицо или юридическое и все это в конечном счете одно и то же и вот это вот явление мы назвали семантическим bezumie которая возникает войти и систему у вас получается следующая вещь что одному определению начинает соответствовать несколько объектов и одному объекту может соответствовать несколько определений и вот в своем докладе я бы хотел вам рассказать о семантическом безумие на проектах спецификациях почему оно возникает как в таких условиях вести модели данных как использовать онтологии да потом привести пример что чтобы вы ни делали как бы вы не согласовывали модели данных между командами у вас все равно эти модели будут разъезжаться все равно эти онтологии оказываются неточными вот что делать в такой ситуации расскажу про то как мы на наших проектах компании accenture с этим боремся то есть мы для этого используем и математические методы методы кластеризации методы математики и статистики и также расскажу о том какие метрики данных мы использовали и что из этого всего потом последует на этом слайде я бы хотел вам привести такую аналогию с легенда из ветхого завета о том как люди строили вавилонскую башню и что люди вроде бы вооружены были одной идеи до но в конечном счете всевышний по перемешала my языки они перестали друг друга понимать и башня так достроена не было вот этот х заветную легенду и ее очень легко перенести на эти системы крупных как в литературе говорят социум технических компаний в условиях редких вы спросите в условии гибких методологий до таких как и джайлз кран вся эта ситуация обостряется потому что если например мы берем какой-то микро сервисной конвейер у нас вполне возможна такая ситуация что одни микро сервисы на конвейере делает один подрядчик другие микро сервисы делает другой подрядчик разные команды используют различный сленг используют различные документации в конечном счете перестают друг друга панд понимать всё это приводит к бесконечному делание адаптеров к бесконечному составлению ума пингов и в итоге расходуются средства как людские так и финансовые и команда постоянно и постоянно уходит на новый спринт вот и бесконечно эту башню строит у нас есть вот бизнес сущности до которые о которых я говорил например в одном случае вот номер счета да это у нас может быть атрибутом клиента то есть у нас например есть объект клиент и номер счета является его атрибутом при этом у номера счета может быть целый набор определение и другая ситуация вот которую хотел бы привести в пример когда у нас номер счета является объектом самим по себе и вот представьте себе у вас есть два микро сервиса которые нужно друг с другом каким-то образом соединить и характерной чертой микро сервисной архитектуры является то что у каждого микро сервиса своя база данных обмениваются они друг с другом сообщениями формате джейсон там или xml там или какой-то другой формат но то что топология в итоге оказывается разные и вам как-то надо с этим жить и у вас постоянно идет обновление атрибутов и в итоге все это выливается в бесконечное переписывание документации в бесконечные какие-то доделки со стороны разработки это всё ситуация с которой я думаю что многие слушатели ну неоднократно сталкивались и вот как мы предложили бороться с этим самым семантическим безумием я здесь не зря поместил портрет карла лены который написал известный свой научный труд о классификации видов животном мире ну давайте вот весь вот этот вот зоопарк объектов сущностей атрибутов каким-то образом приведем какому-то единому знаменателю то есть просто пойдем по методу классической философии составим список субъектов составим список объектов снабдим их соответствующими атрибутами которые будут удовлетворять любому бизнес процессу и будем дальше с этим работать дело все в том что когда мы пришли к такому вот подходу до важно было понять что что у каждый глаз как бы есть три основных кейса это передача данных эта обработка и это хранение информации и вот когда мы говорим о передаче нам необходимо строить сообщение определенной топологии то есть мы как правило работаем с джейсоном да мы работаем с xml вот мы используем жало класс для того чтобы обрабатывать и у этих java классов тоже есть соответствующий набор атрибутов и все у нас начинается таблицей база данных таблицей база данных же и заканчивается и если мы используем подобный подход дробление предметной области на субъект и объект и связи между ними до то нам соответственно вот эту вот топологию которая пришла из исходного бизнес-процесса мне нужно сохранять в топологии сообщения в топологии классов и в топологии таблиц баз данных которые мы используем для хранения соответственно очень удобно при таком подходе использовать схемы xsd если мы работаем с xml ом и схемы джейсон если мы работаем джейсоном классы языков программирования точно также имеют такой же набор атрибутов такой же набор столбцов имеют таблицы здесь на этих слайдах я показал пример для таблицы ну при при попытке охарактеризовать клиентов и вот значит к чему приводит на семантическое безумие прежде всего если у нас конвейер имеет набор микро сервисов уже довольно большой у нас работает множество команд вас возникает что у нас прежде всего возникает дублирование данных в сообщениях и таблицы то есть по факту невозможно привести таблицы баз данных нормальную форму из-за этого мы испытываем отсутствие единстве единство и согласованности терминологии в документации на которой все это описано очень просто каждая команда пишет свой документ на свой микро сервис в итоге когда мы начинаем разбираться то есть какой-то там какая-то авария произошла нужно понять что вообще откуда произошло мы начинаем смотреть маппинге понимаем что их нет просто напросто вот или они сделаны таким образом что понять ничего нельзя вот и испытываем из-за этого в определенные затруднения и самое главное на определенном этапе мы перестаем понимать суть микро сервисов которые используем неоднократно с этим сталкивались и при изменении функционала мы не вносим его в существующие микро сервисы а добавляем новый то есть оптимизируем работу конвейера не экстенсивно а интенсивно его значит какие здесь конкретные примеры можно привести допустим нам нужно интегрироваться с внешней системой то есть у нас появляется новая master system которую нужно связать с другой системой нам нужно построить адаптер и вот как показывает практика 60 процентов времени здесь будет потрачено на то что аналитики перед тем как дать задание в разработку будут составлять маппинге и уяснять семантическую суть всех данных которые нужно из 1 эти системы другую передать дальше что здесь будет хочется сказать что вот ну на наших проектах используются системы компании atlassian это confluence да это вики систему к вике системы которые можно страницах которых могут редактировать разные люди которые которые принадлежат различным командам и используют различный сленг и часто бывает так что одну один какой-то объект один какой-то процесс они начинают называть разными словами начинают вот это вот свою терминологию которая родилась внутри команд писать в разных частях вот это вот системы конструируется в итоге документ становится абсолютно нечитаемым из него вообще ничего невозможно понять то здесь я привел пример с командой вот который мы используем в качестве регистратора микро сервисных систем и кто-то этот процесс называют вилами кто то говорит что это триггер кто то говорит что это набор шлюзов но вот для кого-то это просто и hills или switch и вот представьте себе что вот у вас есть описания страниц где все вот это вот добро друг за другом начинает быть указано то есть новому джеков который эту страницу начинает читать понять ничего из этого нельзя еще один случай который встречается в последнее время довольно часто это поглощение одного бизнеса другу другим это часто бывает в банковской сфере например у нас банк становится собственником какого-нибудь ритейлер стало быть у них были независимые друг от друга эти системы которые развивались независимо друг от друга и вот их надо бы объединить в одну что здесь получается здесь во-первых используются различные языки программирования вот используются разные набор объектов вернее по факту талон может быть один но название могут быть абсолютно разные разные фреймворке использовались для разработки стало быть у каждого объекта разные атрибуты например для банка там может могут быть интересно текущие обязательства клиента и поэтому он как под объект затягивает их до для бизнеса который он захватил вот ну например там какую-нибудь не знаю какой пример привести ну допустим тот же самый какой-то ритейлер у которого есть система личных кабинетов объект с текущими обязательствами он не нужен но нужны какие-то другие вот и все это нужно учитывать и в адаптере передавать эти сведения вот относительно клиента ну какие каким-то наиболее адекватным способом следующий пример у нас новая команда начинает заходить на платформу и сталкивается с какими вещами что у нас во первых не известная модель данных вот у нас плохо описаны справочники и словари вот у нас используются разные нотации везде используются различные фреймворке ису бды у каждой команды может быть абсолютно разная стратегия тестирования почему потому что те команды которые на проекте уже взаимодействуют друг с другом они пользуются различные терминологии различным сленгом при описании этих процессов и просто ну невозможно сопоставить одну сущность другой и на уяснение сути вот бизнес сути некоторых объектов требуется вот дополнительное время и так что мы для начала сделали то есть всегда когда начинается какая-то работа верхние уровни во описывается документации где вроде бы как все объекты с которыми будет вестись работа описаны до соответствующим набором атрибутов но все равно вот проработав там несколько месяцев разные подрядчики во-первых со стороны заказчика постоянно идут изменения вот разные подрядчики выясняют что им нужно атрибутивной состав менять как правило все это происходит в условиях и джейла ну вот а это всегда ведет к тому что без какого-то злого умысла просто информация о изменение атрибутивного состава не всегда адекватно доносится до остальных членов разработки было предложено построить антологию его значит когда антологию сделали вот все начали ей пользоваться использовать ее для построения каких-то общих схем протокола взаимодействия все равно наступал такой момент когда онтологии которые используются различными командами они начинали разъезжаться и вот тогда пришел пришла в голову идея что если нам использовать какие то какие то экспресс иные механизмы кластеризации вот на основе каких-то математических и методик для того чтобы производить оценку вообще текущего состояния моделей данных которые мы используем ну и как-то численно попытаться охарактеризовать вот эти вот расхождения все дело все в том что это важно почему ну во первых у мы на основе модели данных строим от схемы документов до которые у нас идут в информационную систему у нас если мы пойдем по такому подходу мы сможем в парадигме ди ди ди да строить какие-то об анапе а на основании их делать маппинге вот и вообще понятие мэппинга при построении адаптеров или в микро сервисной архитектуре она становится центральным значит как мы строили антологию то с чем мы работали у нас всегда была документация у нас бы было описано верхние уровни в архитектура да у нас был конфликт всегда в такой документации когда идет описание атрибутивного состава сообщения кириллическими буквами русскими словами описано семантика передаваемых данных и на основании вот этого вот описание да тоже не название самого атрибута до или объекта который как правило используют в том или ином виде английски язык или там в некоторых случаях немецкие а именно описание на русском языке кириллического на основании этого мы строили антологию то есть что мы понимали под онтологии мы проводили с одной стороны семантическую разметку с другой стороны мы проводили кластеризацию то есть для того чтобы провести тематическую разметку нам необходимо было провести анализ семантики языка определить семантические ядра и на основании этого определить глобальные сущности и бизнес-объекты на основании которых мы будем строить вот сообщения классы и таблицы баз данных с другой стороны с другой стороны антология для нас было это вот как раз таки и субъект и объект и связи между ними да и на основании вот этого всего мы строили концептуальную схему взаимодействия которую пытались ну вернее не пытались а в итоге сделали мы использовали онтологические моделлеры которые использовали языка уайлда и все это у нас перекочевала в джейсон схемы и в xsd на основании которых мы вот генерировали класса генерировали таблицы пользовались только ими и вот когда все это начинало разъезжаться мы предложили использовать вот такой вот конвейер да то есть у нас всегда было два кейса первый кейс связан был с тем что у нас единая модель единая антология вообще не построены мы берем существующей модели и через какие-то виктора признаков прогоняем а вот и раскладываем все по полочкам а другой кейс который сверху изображен это тот случай когда у нас есть новая модель да и мы прогоняя ее через виктора признаков определяем сходство и соответствие уже тем объектам которые уже существуют и вот если брать те метрики сходство для для строковых величие их можно разделить вот на 3 группы да то что здесь можно использовать можно искать просто сходство строк для этого можно использовать там различные дистанции редактирования выравнивания фонетику можно использовать метрические расстояния не вот можно использовать сходству отношений при этом как бы здесь определенную роль играет наличие соседей и анализ вот этих вот соседей которую у нас получились при кого кластеризации то есть первое что мы попытались сделать это автоматически поискать соответствие при помощи алгоритма левенштейн а то есть искали поиск редакционных расстояний то есть выглядело это каким образом у нас было тематическое описание со стороны 1 эти системы также тематическое описание со стороны другое эти системы и вот мы этот алгоритм запускали и пытались найти соответствие с одной стороны и найти соответствие с другой стороны то есть здесь для примера я хочу привести такие объекты как номер что-то физического лица номер что-то физика и номер счета юридического лица как бы соответствующие расчетное редакционное расстояние на самом деле в ходе работы мы пришли к выводу что если мы работаем в условиях 1 предметного поля да то есть в моем случае это был банкинг где в общем то все довольно просто относительно да все хорошо изучена ну давайте пойдем более простым способом мы начнем просто факторизовать высказывание то есть факторизовать их каким образом мы будем строить вектор а вот в 30 трехмерном алфавитном пространстве то есть мы возьмем тематическое описание например нам расчета физического лица и отложим на соответствующий оси которая отвечает за каждую букву русского алфавита то количество букв которые у нас встречается в описании таким образом мы получаем такой вот вектор если мы возьмем другое высказывание номер счета физического лица ну это вот номер что-то физика мы увидим что в конечном счете они друг от друга отличаются например в номере счета физического лица у нас есть буква g вот а в номере что-то физикой у нет то есть если мы эти два вектора построим найдем между ними разницу-то по величине этой разнице мы сможем оценить таким образом соответствие одного вектора другому то есть если у нас есть один вектор вот на данном слайде я привел проект этих докторов на плоскость а и и показал что разница действительно существует если вот этот вектор дельта s он маленький вот ну меньше чем до другого соответствующая вектора то мы можем посчитать что эти два высказывания они друг другу каким-то образом соответствует далее пошли следующим путём а что если нам использовать для оценки соответствия вот просто векторное произведение вот которая фактически включает в себя вот косинус угла между векторами и стало быть если у нас ищется проекция одного вектора на другой если директора получено таким образом то чем больше эта проекция тем больше соответствия что дальше нужно делать то есть если мы возьмем и попытаемся построить вот этот вот граф соответствие вот мы можем в принципе определять как евклидова расстояния как и так монах японское расстояние расстояние минковского и прочие метрики и если взять и построить граф предметной области до вспомнить там мое лично астрофизическая прошлое попытаться применить те методы которые используются для описания каких-то скоплений до в космосе да даже глазом это видно что вот эти вот самые атрибуты они начинают кучковаться вокруг определенных точек и когда мы первый раз вот мы зашли на конвейер нам общем то про него ну так сложилось сложился проект что заказчик не дал исчерпывающую информацию об атрибуте в нам составе но когда мы и увидели ну вот в принципе стало понятно с чем мы начали иметь дело и вот и собственно как мы посчитали у нас время анализа сократилось на 30 процентов хотя бы уже потому что у нас появилось средства визуализации предметного поля еще что хочется сказать а дело все в том что мы ввели такое понятие как вот семантической орбита да то есть это вот воображаемая линия если у нас атрибуты попали за границу этой линии то мы считаем что они имеют примерно одинаковую бизнесу теперь возник вопрос а как эту как эту семантическую орбиту посчитать ну вот тоже лукавить не стали решили взять классическое распределение случайной величины вот по гауссу то есть если мы возьмем оценим а все что у нас есть до построим вот этот вот купол вот у нас есть величина допустим номер счета до метрический обозначим ее за 0 вот посчитаем полу ширину на полу высоте таким образом вот ширина купола то есть 2 2 средних среднеквадратичного отклонения верни среднеквадратичное отклонение то у нас будет радиус этой символической орбиты а стало быть двоих это будет диаметр таким образом если брать например номер депозитного счета он попадет сюда и мы как бы четко будем знать что одно соответствует другому да номер карточного счета тоже сюда попадает а вот номер отделение в котором открыт счет клиента уже попадает сюда условно потому что он как раз вот на вот этой вот семантической орбите лежит а номер телефона клиента очевидно как-то к этому относятся но за пределы семантической орбиты выходит и если мы визуализируем вот это вот пространство минковского да в принципе мы можем искать здесь как пересечение и вот то есть если например нам нужно найти пересечение двух множеств одно из которых соответствует номеру счета физического лица другой паспортные данные мы можем уже это сделать мы можем таким образом сделать объединение то есть если например нам нужен номер что-то физического лица и паспортные данные клиента вот такое тоже банковской сфере бывает мы можем уже это сделать и самое главное анализируя любой бизнес процесс до определив его субъекты и объекты которые в нем участвуют мы в принципе можем набрать любое сообщение из таких вот глобальных бизнес-объектов которые мы упаковали схемы xsd и джейсона да со всеми атрибутами которые там есть всем вам соответственно мы присваиваем обязательность фолз и начинаем по конвейеру туда-сюда между всеми микро сервисами гонять вот естественно у нас на наших проектах появилась новая роль которая стала называться архитектор модели данных то есть каждая ветка и вот ну мы использовали так как мы использовали продукты компании atlassian мы использовали гид вот и у нас стало быть вот для от протоколов взаимодействия да каждый раз все обновления меня есть менялся атрибутивной состав у нас появлялся новый релиз и все это оформлялась то есть в соответствии с какими то там требованиями виде пули квестов и каждая ветка у нас было соответственно релизом новым и что происходило дальше если возникала надобность внести какой-то новый атрибут от требования бизнеса такие были он помещался в конец старой атрибуты не удалялись ни в коем образом вот новая схема отправлялась форме pull request a в мастер ветку и ответственное лицо вот архитектор он ну или там группу архитекторов там целый архитектура комитет итоге получился они либо принимали эту прав куда-либо отклоняли и вот что дальше а дело все в том что она у нас мы стоим как бы на пороге того что у нас либо уже начал появляться интернет вещей либо он вот вот вот наступит но нам приходится вот интегрировать всех со всеми и нужно будет рано или поздно мы к этому придем в том числе и наша компания к этому готовиться к тому что нам понадобятся какие-то методы экспресс най стандартизации классификации для того чтобы вот довольно быстро все эти объекты друг с другом интегрировать конечно же то что то чего я сейчас рассказывал у этого всего есть много изъянов там например когда мы работали скажем так с системами которые описывались но года 2-3 назад вот и вендоры подрядчики описывали их довольно скрупулезно то есть пару раз было так что описание было настолько подробно вот вот в этом вот маппинге что прогоняет через наш алгоритм который мы реализовали на языке python можно было автоматически получать mapping до отдать его в разработку не глядя пару раз так было все у нас получалось хорошо а вот в последнее время когда ну все больше и больше популярность начал приобретать джейл вот эти вот скрою скрам команды то есть описание становилось все более и более безалаберной а то есть вот этот алгоритм он начинал давать сбои то есть а ну грубо говоря он уже не понимает разницы например там курица и яйцо и допустим петух то есть можно в принципе сказать что ну довольно тяжело вот таким вот экспертным методом найти здесь какое-то вот соответственно тем не менее нужно над этим работать то есть как это сделать дальше следующий момент мы фактически проведя вот эту вот работу сделали попытку как-то определить границы микро сервисов и попытаться таким же образом на основании анализа их работы с различными объектами провести кластеризацию и каким-то образом наладить маршрутизацию внутри конвейеры и вот собственно говоря к чему мы в итоге пришли да то есть на всех наших проектах нужно составлять онтологический словари вот и делать api до делать адаптеры делать мапперы на их основе дальше ни один онтологический словарь и он не будет идеальным то есть мы все равно находимся в таких условиях что нужно будет что то менять все у нас развивается нужно нужны какие-то средства оценки для того чтобы постоянно оценивать их адекватность для этого мы предлагаем использовать статистические и математические методы в для того чтобы как то постоянно контролировать их сходимость этот метод мы в конечном счете вот предлагаем и третье все становится гораздо проще если для передачи данных и построения таблиц построение классов мы используем вот эти вот глобальный бизнес сущности которые были таким образом получен на этом я наверно закончу хочу сказать что постоянно мы эту тему описываем нашем блоге ищите нас на хабре подписывайтесь вот готов буду ответить на все ваши вопросы спасибо тебе за твой доклад я смотрю что вопросов очень много поэтому мы наверно начнем так вот пока мы ждём микрофон и я сам свой а там давайте спасибо за доклад что новичка на один россельхозбанк на каких объемов примерно начинает это становится выгодным еще раз на каких объемов примерно то есть мы там имеем в словаре имеем там 5000 сущностей 140 сервисов таких объемах имеет смысла заводить мучиться я могу сказать цифру 3 с половиной тысячи атрибутов вот тут уже надо это в совокупности по всем этим самым объектом так еще вопросы и пока мы несем микрофон напоминают а что за лучше добрый оси подарок книга вот задавайте спасибо большое за доклад и за смелую попытку применить достаточно большой пласт онтологического инжиниринга соответственно программной инженерии но маленькая критика еще десять лет назад майкл стоун breaker написал порядка там десятка статьи сделал около 10 выступлений по тематике до таки решен в баре холдинге которым подробно рассматривал как раз вопрос от того когда данные нужно очищать трансформировать консолидировать интегрировать и по сути вводя термин семантическое безумие вы вводите новый стандарт который уже ранее индустрии был описан возможно имеет смысл все-таки придерживаться классических терминологий да такие рейды на второй вопрос уже вопрос наверное заключается в том что вы сейчас использовали достаточно очевидные метрики близости между текстами которые опять же можно было бы значительно улучшить за счет применения более современных нлп механизмов например напрашивается применение sequence им беден гав как направление которое бы вам ушло и разницу между курицей и яйцом если это надо и наоборот семантическую близость между не что безусловно качество повысило ну и наверное самый интересный третий вопрос в первую очередь наверно оперируете все-таки имеющимися сущностями в базе данных соответственно этих сущностей есть много-много прецедента вхождения в таблицу если у вас есть похожие по названию сущность то почему мы не можем сравнить распределение этих сущностей в двух колонках по дивергенции курбе калибра и посмотреть похожи ли они или нет грубо говоря идти в нашем сравнении не только от лингвистики но и от статистики тех данных которые имеются опять же все три подходы были описаны как раз там брекером и в этом смысле хотелось бы узнать как ваше предложение reference они цена и его работы спасибо большое ну давайте так скажу что наверное есть и более ранние работы на этот счет например тот же самый левенштейн можно открыть википедию посмотреть когда он этими идеями озадачивался вот дело все в том что вы поймите тоже что как бы я уверен что то что вы предлагаете это тоже там не единственный подход там много людей в мире над этим работают мы изучили ряд работ вот но в итоге пришли к тому что вот конкретно в банковских проектах вот мы работаем на проектах банков когда у нас есть хорошо ну как бы известное нам предметное поле у нас определенный опыт есть зачем нам использовать какие-то специфические математические методы если можно взять простое и понятное вот для нас для нашей команды до выпускников скажем так физического факультета ну вот понятно что наверное нам следует ознакомиться по внимательны со всеми этими работами и наверно мы это в итоге сделаем но скорее всего мы ну ничего такого вот там сверхестественного до конкретно в этих проектах для себя не найдем а вот когда полезен дальше то есть когда нам нужно будет совмещать банки там с другим бизнесом да например там рано или поздно возникнет такая задача когда нам нужно будет скопировать банк да и ритейлер который там допустим занимается там производством алкоголя час у нас в стране все идет вот тогда скорее всего мы к этому придем мы будем это осваивать вот как то так нет конечно она будет дальше развиваться так если еще они не здравствуйте спасибо хотелось бы узнать следующее по поводу построения онтологии хотелось бы понять то что онтологии строится для каждого из подрядчиков но вот вы говорите что совмещаете много подрядчиков для каждого из-за бизнес-процесс подрядчика отдельная или строится одна общая антология потому что ну в принципе если один business process the anthology скорее всего будет ну плюс-минус 1 значит смотрите где мы говорим антология там мы понятия бизнес-процесс убираем вообще у нас его там нет когда мы говорим антология мы имеем в виду подрядчика . правила есть задача мы всегда от задачи идем не от бизнес-процесса под задачу приходит подрядчик и вот он использует уже свой набор объектов с которыми работает и антологию мы делали под подрядчик окей получается что ну под каждого конкретного подрядчика свои антология хорошо хотелось бы понять также с введенными метриками и тому подобным как вообще происходит связь объектов но вот например примеры с курицей и допустим петухом и тоже семантические могут быть в разных структурных областях совершенно разные вещи то есть курицы и петух могут быть ну допустим если мы описываем царство животных они относятся ну потому к одному виду но если мы вдруг описываем 2 палата это совершенно разные сущности насколько я понял у вас используется сопоставление побуквенно того если используем побуквенно и сопоставление то она в принципе и там и там будет далеко хотя в одном случае они достаточно близкие сущности в другом совершенно разное значит докладываю заставляли всех использовать одно семантическое ядро то есть когда вы избегаете вот название курица цыпленок и петух да а например говорите сам к курице самец курицы детеныш курицы вот она начинает работать ну то есть да еще раз говорю поймите пожалуйста одну вещь и что у нас как бы задача она была не глобальная мы работали в рамках хорошо изученного вот предметного поля поэтому она у нас работала если бы мы пошли бы дальше она бы понятно бы все посыпалось здравствуй спасибо за доклад вы рассказывали что вы строите виктора на основе попадания бук там в яндекс есть там вы используете при этом нормализацию потому что разные длины предложение да они могут давать разные по длине виктора нет не использовали вот вот это вот мы не делали и собственно говоря задавались этим вопросом но как показала практика она не сильно влияло но эту проблему мы рассматривали то есть и еще раз говорю когда у вас вокруг нам одного набора от атрибутов там на самом деле в банковской сфере тех объектов их не так-то много вот она работает но при этом мы прекрасный себе отдаем отчет чтобы пойдем куда-то в другую область или вот сейчас вот у нас например задача это возникли что нам нужно будет интегрироваться с чем то о чем мы ничего не знаем вот тут уже скорее всего вряд ли будем этот мир принимать какие-то другие метрики не смотрели например пары триплеты букв но при построении смотрели у нас все в конечном счете упирается на то что у нас есть единомышленники на все равно так или иначе многие аналитики приходят к онтологии вот мы просто предварительную работу с ними ведем и уже у нас будет такая же антология или подобие ее и нам уже проще будет смотреться а так конечно же вот коллега вот назвал мне математические методы я бы попросил бы конечно их назвать мы с удовольствие с ними ознакомимся я не скрою мы просто всего знать не можем мы здесь сидят специалисты в этом которые больше понимают именно в математике приветствую большое спасибо за доклад было достаточно интересно вопрос наверное людям которые будут применять такой метод или не будут применять такой метод хочется каких-то конкретных кейсов как применение для применения такого метода влияет на конечной time ппу марки ну то есть грубо говоря стоит ли это того еще раз про сиделось плохо слышу ну вопрос к ее такое что если я хочу взять на вооружение данные методологии да по составлению онтологии по поиску похожих сущностей иди производства этого глобально хочется понять стоит ли это с точки зрения тайм ту маркета то есть есть какое-то позитивное и негативное влияние еще раз стоим чего time по марке ну то есть более быстрое завершение процесса разработки различных подрядчиков значит я вот этот вот момент проговаривал у нас как бы вот это согласовывали моделей данных а но в итоге там заняло три или четыре спринта но когда мы начали эту тему использовать вот конкретно строить онтологии и когда мы вот эту вот галактики и туманности получили у нас процесс пошел сначала на 30 процентов быстрее потом когда мы это поставили на поток в принципе мы за один спринт делали модель данных то есть оно стоит того у вас глазом графически информация воспринимается всегда лучше чем вы получаете вот экселевскую таблицу с описанием этой семантики которые абсолютно нечитаемое начинаете в ней взорваться и разбираться так вот у нас есть еще один вопрос давайте им будет последний вопрос из зала можете пожалуйста микрофон нести аха супер сейчас принесут микрофон здравствуйте это спасибо за доклад у меня такой вопрос перевод продуктов на новую модель никогда не стал кавс ким проблемами в плане объяснения зачем им надо переходить на что-то а не проще ли там воткнуть какой-нибудь mapper там над ними и оставить людей в покое и не лезь со своими новыми моделями значит это вопрос не идти это вопрос со стороны бизнеса то есть иногда в момент заключения договора эти моменты прорабатываются и там просто из требования заказчика никакие изменения не вноси и вот проще создать адаптер где все это будет напиться я думаю что ни один крупный бизнес вообще на изменение своей внутренней модели данных ради того чтобы кому-то другому было хорошо не пойдет но опять же это мое мнение я во всяком случае не сталкивался с спасибо спасибо большое за вопрос валерий тебе спасибо за твой доклад коллеги большое спасибо так не уходи раньше времени сейчас те принесут подарок а также если остались вопросы то предлагаю пройти после в зону цифровых кулуаров там тебе могут еще онлайн задать вопросы там тебе помогут соединиться и ты сможешь еще поговорить с нашими онлайн зрителями и за лучшего проросшей вопрос я бы отдал вот коллеги который посоветовал использует математический метод где этот коллегам он скорее всего уже ушел она супер в вам будет вручена книга спасибо большое спасибо спасибо тебе так следующий доклад будет шесть часов вечера дубль смывай да я в ту дай его в туре вида санчо из эра одну заслон из people feel канате твое чадо и к но так что connections под стол был да и авто дай мегафон makes диска на чем штанга штанга а ну дай вас там полтава одолевает мегафон мегафон он пройдет открытая твой король mouth and sunday million вскоре которого c2 сустав с твоим ваша implement свечей л т а л т и и 20 гб ddr2 мегафон к стенду гоночный купить от а тут этот шанс fate of a и гигабайт способен в состав фича ведь битва идти снг и балтии поймет когда соседи пойдем мой бан аккаунта личинками . business solutions смотри ночей шанс пор агро колчан ты задавать ионы цинка и а ведь мегафон с ценами и размещенным желательно чай назад линза people войны выдумать usa испеку но очень не к титул зависит от него почти на треть мегафон и skylink ты читал bout так ха ха я в эфире супер добрый вечер это наш будет последний доклад на сегодня в первый день и на сцену приглашается владимир узоров из компании clarify labs расскажет нам про добавление скилов hazel каст привет привет ну рассказывай да спасибо спасибо кирик коллеги что пришли мой доклад будет про то каким образом как мы добавили поддержку иску или в хазел каст здесь важно сделать несколько дисклеймер of потому что доклад этот готовился еще до пандемии иди словом и имелось ввиду инженеры кизил костра потому что на момент подачи заявки я и был инженером это компании и наша группа занималась тем что разрабатывал и проектировал а с нуля распределённый скорби жег для ну для продукта хейзел каст и а другой другая важная вещь то что доклад это делается примерно год назад и с тех пор ах некоторые утверждения про архитектуру продуктах из lacoste они тоже изменились поэтому в докладе я буду делать скорее фокус на топ как по какому принципу мы принимали те или иные решения но это далеко не означает что это решение валидно до сих пор если это так то я буду особым образом делать на этом акцент на 4 я руковожу компанией кури flaps в которой мы занимаемся разработкой компонентов субд м для технологических компаний то есть мы делаем из калины оптимизаторы мы делаем стоишь и прочие компоненты и поэтому одни едем в одним из наших основных инструментов является apache кальцит и в хабблкасте тоже на самом деле использоваться pouch кальцит и поэтому это доклад а также будет иметь некоторые пересечения с докладом романа кондакова про внедрения пачкаться этого папочек знает потому что некоторые концепции ну а не пущу то применялись одинаковые томатом значит давайте начнем мы с вами живем в эпоху победившего из клея и если изначально искали был прежде свечой классических таких классических субботы как массе composers oracle то со временем он проникает совершенно другие data management продукты мы видим очень большое влияние скрыли в стриминговых системах таких как apache пленка или киевской или ставки более того есть даже отдельная группа который занимается проработкой стриминговых расширений вы сказали да то есть мы можем смело сказать что общем то вскоре практически полностью крайне клиринговая система на кроме этого вы можете видеть искали speak to the решениях таких как например hive мы видим его в батарейках мы видим его даже в новой сколь системах таких как например кассандра в таких как коуч bass и что интересного иску или очень много в в продуктах и мы мария datagrid таких как а посчитает хейзел касты гигас пресса поживет у них у всех если бы склонен интерфейс либо искали like подобный какой-то язык и вполне понятно с чем это связано потому что сколь является достаточно по достаточно популярным языком с очень мощным просто инфраструктуры вокруг поэтому если вы делаете какой-то дату менеджмент продукта с огромной вероятностью вы захотите иметь или москва или в том числе и поэтому такая скажем так и вскоре listeria не обошла стороной и хазел каст сам по себе хэйзел каст является основы хазел костра является продуктах резинка ставим digic которые представляют собой по сути распределенную хэш мапу то есть имеются пары ключ-значение которые организованы в так называемый пар тишины шарды которые в свою очередь распределены по узлам тем самым вы можете распределять данные по большому количеству узлов и обеспечивать горизонтальное масштабирование основным инструментом доступ к этим данным является классический киев или выпей где у вас есть операция get по кто где он может получить значение по плечу и операция put для того чтобы записать пара ключ-значение но если вы посмотрите на то каким образом развивались 7g решение то вы увидите что со временем им стало тесно находиться в парадигме ки ки вылью и поэтому они стали стремиться добавить какие-то дополнительные расширения фичи которые позволили бы анализировать данные с разных сторон да и какие то продукты такие как о пощаде на и сразу стали делать из к войне интерфейсы входил кости для того чтобы адресовать вот это you space скажем так да вполне сечения на самом деле это первое и второе что в козелка стенам момент когда мы начали заниматься разработкой сколь и имелись уже вторичные индексы они были спроектированы краски для того чтобы ускорять вот это самый приди к теперь их зависимости от того в каком виде данных хранятся пластыри хотел газ написано джаве они могут хранитель боржава теперь его в них его не hippo эти вторичные индексы представляли собой и представляют либо классическую конкор на флешмоб и саджа вы либо же кастомное как раз то черное дерево это была стартовая . и поверх этого мы стали делать иск о или какие проблемы у нас были спереди кэти перри и что в общем-то привело к идее создания скурили первая проблема самый большая заключалась в том что теперь был изначально спроектирован не виде итераторов или курсоров а.в. он был спроектирован таким образом что давал полный сет данных всегда то есть фактически если вы работаете с большим сэтом данных и отправили какой-то предикат которая дает притекать низкой эффективностью то вы могли обратно получи допустим миллионы записей из-за чего ваш узел там упадет out of memory другой проблемой было то что сам по себе этот и 5 был достаточно ограниченный то есть там можно делать предикату им исполнять мой можно делать это простая агрегации но были сложены операторы такие как join и или или сортировки проще возможности из порядке операция отсутствовала наконец еще одна проблема то что это некий кастомный перри которую пользователь нужны изучат с нуля и конечно это проигрывает в юзабилити обычно вы сказали о которые так практически все знают в сумме это привело к решению создавайте сколь ни движок и что мы сделали мы с примерно среди 2019 года по середину двадцатого года против прапти пировали и разрабатывали сквозь движок который появился в 1 соберись и пример по осени 2020 года в версии ходил к 100 41 он имеет достаточно простой 5 где вы просто отправляете некий искали запрос на выходе получаете курсор то есть мы тем самым решили практически все проблемы которые имелись предыдущем предикаты 5 да то есть мы теперь работаем с курсорами мы работаем сосиску или никакой новые первом изучать не не требуется и это был очень такой хороший шаг вперед для продукта и сегодня соответственно в докладе я расскажу про основополагающие какие-то моменты проектирование и создание этого движка значит первое когда вы отправляете запрос в какую-то собой первое что происходит это оптимизация запроса процесс оптимизации представляет собой конвертирование оригинальной спокойной строки в некий план который может исполнить backend вашей системы и для того чтобы сделать очевидного мне необходимо провести синтаксический анализ парсинг потенциальный семантический анализ возможно применить какие-то трансформации чтобы найти более оптимальный план исполнения и за все это отвечает и скудные и сколь оптимизаторов и здесь если вы задумаетесь каким образом можно это сделать то конечно всегда присутствует возможность написать оптимизатор с нуля то есть сделать свой парсер сделать свой тематический анализатор свой своих это правило трансформации оптимизации но это достаточно трудоемкое да потому что даже элементарно написали парсер это достаточно большая боль и дабы что вам даже если вы используете какие-то паркер генераторы все равно это надо тестировать надо интегрировать и поэтому здесь 7 всегда конечно хочется срезать углы и мы стали делать анализ того какие решения присутствуют на рынке которые будут вскоре ли создание этого компонента и естественно первое что мы увидели это был продукт apache кальцит на тот момент я счастливыми не был их хорошо знакомым но забегать вперед apache кальцит это некий tool-box до который состоит из индивидуальных компонентов с помощью которых вы можете создать полноценный школьный движок и к таким компонентам важным для данного доклада относится парсер которые есть там из коробки это семантический анализатор это специальная логика по изменению внутреннего intermediate репрезентация плана транслятор и непосредственно оптимизатора который позволяет применять различные правила оптимизации к запросам для того чтобы эти боли оптимальный план исполнения и в кольце являются очень расширяемым то есть вы практически у любой компонент вы можете добавить какие-то свои дополнительные вич или определения то есть вы можете предоставить собственную схему для парсера вы можете добавить собственный синтаксис для правил оптимизации можете создать собственные правила или собственные операторы и прочее поэтому кальцит в этом плане является очень гибким и он уже в тот момент когда мы его рассматривали он уже использовался в огромном количестве продуктов из таких наиболее популярных про которого возможно слышали это почти хайфа патч link древнего и поэтому если вы работаете с данными с каким-то продуктами . невероятно что где-то внутри вы и так уже используете кальцит просто напрямую вы с этим не сталкивались вот поэтому здесь мы взяли кальцит с пониманием того что конечно использование другой стране продукта может предпримите определенные риски и проблемы и как каким образом выглядит играться с концертом то есть первый шаг представляет собой парсинг в этом случае мы просто провели мы берем оригинальную строку скармливаю его в партер кальцита и на выходе парсер кальцита выдает нам абстрактные выдает синтаксическое дерево запроса на первых этапах мы использовали парсеры кассеты который идет из коробки то есть он поддерживает на себе скальные синтаксис с 2003 года и в различные возможности там изменения его павел поведение но в дальнейшем по мере развития продукта мы мы в этот парсер также добавили дополнительные команды в основном связаны с а стримингом потому что впоследствии в кофре зал кости появился возможность использования сковали для и для стриминга и поэтому там были созданы разные дополнительные недели команда дальше после того как вы получили все синтаксическое дерево необходимо провести его с тематической валидацию которое необходимо для того чтобы понять что дерево которых есть руках валидно имеет имеет смысл до в частности самое главное что есть происходит это разрешение имен объектов дату если вы ссылаетесь на какую-то таблицу лигита колонки необходимо убедиться что они есть не пойдем убедиться что у них корректные типы кроме того в на этом же этапе происходит разрешением функцией точно также проверка того что те операнды которые вы передаете функции неправильные типы и прочее прочее в кольце те то про сделана прямо отдельным компонентам который называется сколь валидатор этот достаточно сложный класс там все ну то есть анализ синтаксического дерева достаточно нетривиальной процессы и кальцита есть в этом плане сохраняет огромно количество времени нам как разработчикам потому что он берёт все это головную боль на на себя но тем не менее в процессе разработки нам пришлось сделать достаточно большое количество расширений к валидатор а потому что не всегда нас устраивало то каким образом концы допустим выводит типы функции и высоко или допустим кальцит но семантика кальцит она больше близко к массе кулу в том плане что она достаточно расслабленно и мы же хотели сделать продукт которые семантически ближе допустим к по сбросу который более строгие поэтому нам пришлось ввести достаточно большое количество расширений в него чтобы это заработало но тем не менее кальцит изначально был спроектирован и с такой идеей в голове что такие расширения могут потребоваться поэтому это не составило большого труда дальше одна из больших проблем с которым мы столкнулись это каким образом можно представить неструктурированные данные хазел каста виде таблице атрибутов для из ковеля потому что как и сказал базовой структурой данных в хотел кастом ниже является м.м. это распределенная кошма по которым может хранить просто произвольный пары ключ-значение когда вы сохраняете или читаете не происходит никакой валидации нет никаких гарантий о том какие данные там именно как ну какими именно данные находятся в ней поэтому они не совсем понятно каким образом можно из этой неструктурированной информации получить схему которую можно использовать в сквере о кольце требуют имена строгую схему таблица колонка и прочее мы решили проблему следующим образом мы сделали гипотезу что все данные которые находятся в в конкретном в конкретной раз правильно хэш mapi все ключи и значение имеют одни и те же типы то есть это далеко не всегда так как искал валидации нету но мы исходим из того что для целей сколько эта гипотеза должна выполняться благодаря ней что мы можем сделать можем взять первую попавшуюся пару ключи значения из нашей распределенных хэш map и провести ее некую ретроспекцию ну допустим так как ходил к статье продукт написано на джаве очень часто объекты которые хранятся в нем это просто царские объекты можно взять reflection of java вытащить информацию во всех полях который присутствует в этих объектах и составить но и превратить их и и приду предоставить и вокалисту в плоском виде то есть для каждого допустим от поле объекта мы делаем соответствующий атрибут и сообщаем ним кальцит он и в дальнейшем если вдруг оказывается что в этой же в маппет хранятся объекты друг других типов то мы исходим из того что движок должен просто ошибку это позволяет нам и завязать зафиксировать схему на момент начала оптимизации запроса это же позволяет нам избегать какой-либо как как конфигурации в принципе дату все работает из коробки с другой стороны мы это дает им достаточный уровень гибкости скажем так но при этом ряд проблем и здесь остался нерешенными например на данный момент сколько сил кости не имеет получат доступ к вложенным полям то есть вы можете работа только с полями верхнего уровня которые определены в java классе вот сам объект и верхнего уровня то включили в значении дальше одна из интересные особенности кальцита это то что для оптимизации он не использует синтаксическое дерево а вместо этого он работает с деревом реляционных операторов и в кольце tied специальная утилита который может транслировать синтаксическое дерево в это само дерево или сонных операторов сделано это для того что так как синтаксиса сквозь них достаточно сложный то соответственно структура синтаксического дерева она достаточно нетривиальна если вы посмотрите что если представляет в этом дереве оператор select the это некий узел небольшим количеством child узлов там vr грубое heaven и прочее прочее и какие-то оптимизации к нему применять не всегда понятно как и несмотря на то что многие базы данных используя синтаксически деревья для дальнейшей оптимизации у них это как правило вызывает большое количество проблем то есть правило написать правил оптимизации для таких деревьев не очень просто поэтому кальцит в кассете принято такое фундаментальное решение что все оптимизации они производятся преимущественно над деревом реляционных операторов в которую мы можем использовать встроенный компонент кальцита транслировать нашей синтаксическое дерево и операторы в этом дереве представляют собой не классический там select грубая и прочее а вместо этого это классические реляционные операторы со строго ограничено семантика и которые просты в имплементации соответственно простые в использовании для целей оптимизации таким оператором относятся оператор сканирование то есть это сканирование произвольного источника данных к ним относится оператор project который допустим берет набора входных атрибутов и может изменить порядок этих атрибутов или применить какие-то функции к этим атрибутом оператора фильтра делает только фильтрацию до то есть отбрасывает apple и которые не прошли некий предикат оператор оператор агрегации делается только описывать столько непосредственно агрегацию и ничего более не тем самым мы получаем достаточно небольшой набор очень относительно простых операторов поверх которых потом легко описать правила оптимизации для примера если вы пишите запрос cтоимость грубой и having да то для кальцит это будет два отдельных оператора кооператор эта информация указана грубая и соответствующие агрегатные функции в селе gti превратятся в оператор в оператор агрегат а having превратиться просто в фильтр который находится на d5 надо оператором над оператором агрегация далее что интересно что кальцит это некий абстрактный by жег то есть все операторы которые в нем есть это некие абстрактные операторы то есть это может быть jojen но там не будет спецификацией является ли это хэш джоуи там или мер черным или места тут же нам тоже самое для агрегатов во мне никто не скажет это хэш агрегаты стриминговый агрегат для сканирования там не будет информацией это им сканирование по индексу или по таблице и прочего поэтому в качестве если вы хотите интегрировать концепту вам необходимо такие необходимо определить физические операторы которые специфично для вашего бренда и определить правила специальные правила которые транслируют логические операторы кальцита в физические операторы вашей системы и в козел кости в том числе пришлось это сделать да то есть для оператора сканирования мы допустим определили операторы сканирования пойме по или сканирование по индексу мы и прочее далее финальное целью оптимизации в конце является трансфер трансформация оригинального дерево логических операторов в дерево физических операторов специфичен для вашей системы до которая уже непосредственно описывает конкретные шаги которые вы должны сделать вашем бренде и поэтому здесь как и сказала вы пишете правила вы пишете в определять и кастомные операторы которые в вас к этому приводят каким образом эти трансформации происходят в как в calcetin большая часть всех трансформаций в конце те им лимитированного с помощью улов или или правил то есть правило это некая пара паттерн плюс сама трансформация которая во первых описывает сам паттерна которую вы ищете в дереве на этом примере мы ищем паттерн агрегат который находится поверх join и и если вы встретили тку паттерн ту применяется правило которое трансформирует дерево в какую-то другую форму в нашем случае наши правила делает пункту ждал агрегата пота join соответственно результатам работы правило является агрегат которое находится снизу на то есть такая пример оптимизации очень часто применяется для того чтобы уменьшить количество данных которые доходят до оператор join a вот и в кольце те эти трансформации могут применяться двумя способами первый способ они могут применяться в эвристическому они могут применяться эвристическим это означает то что как только мы видели этот паттерн ну вот слепо применяемым получаем какое-то новое дерево и мы последовательно переходим от одного дерева к другому пока не перейдем какую-то финальную точку альтернативно в кольце ти есть так называемый qsb с оптимизатором который вместо того чтобы переходить это ну а дерева к другому вместо этого он пытается закодировать все потенциальные деревья которые мы встречали в процессе вызова правило в одну структуру данных которые в литературе называется мимо и эта структура данных представляют собой последовательность непосредственно реальных операторов и групп и групп эквивалентности и вот здесь на рисунке эти группы показаны кружками да и в частности вот наверху вы можете увидеть что группой ag4 имеет два эквивалентных оператора агрегат то есть это то что было то применение правила или некий там оператор project который появился после применения правила и эквивалентность здесь означает то что эти два оператора всегда вернут один и тот же с данных для любого входного набора данных то есть они производят абсолютно одно и то же и все эти альтернативные пути исполнении закодированы в одну структуру данных кальцит присваивает им касты на основе только с функцией которую вы сами определяете ли ваши операторов и в конце концов кальцит может выбрать наиболее дешевый план исполнения и в этом плане кальция является достаточно продвинутым по сравнению скажем с оптимизаторами которые используются в парке или оптимизатора просто потому что в этих продуктах как правило все трансформации происходят в происходят эвристический той стене рассматривают один план исполнения в текущий момент времени в то время как кальцит может рассматривать множество планов ну да несмотря на это их прессы с паркетом при присутствует конечно такой эгоист оптимизации на уровне определенных рунов но квест buy stop темизации между полами для всех от альтернатив они рассматривать не в состоянии это приду принципиальное отличие лучшую сторону продукт apache кальцит и последнее что интересно и что кальцит можно использовать чтобы скажем так сделать композицию неких фас оптимизации потому что сама сам процесс оптимизации является сложной задачей что означает что вам нужно фактически перебрать ну для того чтобы найти оптимальный план вам нужно перебрать все планы которые только есть эти планк может оказаться очень и очень многое поэтому в практических оптимизаторов сам процесс поиска плана как правило бьется на отдельной фазой чтобы позволяет уменьшить общую сложность процесса планирования цены того что вы можете пропустить какой-то оптимальный план и в хабблкасте соответственно это сделано по такому же принципу то есть там есть набор фаса эвристических набор фас кость bass которые следуют одна за другой в конечном счете приводит никому финальному физическому плану далее по части конкретных физических оптимизации прибыли сделано в хабблкасте из самого главного во-первых мы сделали оптимизацию которая ищет индекс который можно бы использовать для исполнения конкретного предиката для этого мы ищем фильтр поверх оператора скан фильтр нас к нам и зависимости от того какой какие предикаты присутствуют фильтры мы ищем индексы которые могли бы удовлетворить эти предикаты и ускорить их и поэтому по итогам эта оптимизации мы можем вместо того чтобы рассматривать только сканирование базовой структуры данных от самого распределенного хэш мапо мы можем добавить в пространство поиск еще дополнительные альтернативные планы которые задействуют тельные индексы другая важная темизация которое присутствует практически во всех распределенных и сквозь движках это оптимизация связанная с пой с поиском оптимальной оптимального пути передачи данных в кластере потому что она из очень больших скажем так проблем любого распределенного скрыли это то что данные у вас в классе я каким-то образом распределены это распределение далеко не факт что подойдет для исполнения произвольного join a или произвольной группировки произвольно сортировки прочего поэтому вам необходимо не только планировать классические реляционной пературы но кроме этого вам необходимо понять каким образом перераспределять данных кластере до чтобы иметь возможность исполнить эти операторы которые присутствуют вас в плане и поэтому здесь в касселе что мы сделали в хабблкасте мы определили три типа распределение которым может иметь каждый оператор в плане первое распределение называется пар тишинке это классическое сортирование это значит что весь resulted оператора распределен по узлам и каждый каждая запись из этого резал сет находится в одном экземпляре на одном узле второй тип распределение реплика этот необходим тогда когда вы хотите чтобы весь резался от оператора находился полна копия такого результата находилась на всех узлах чаще всего используются для того чтобы делать к лакированные join и и такими такое распределение чаще всего используется для таблицы справочников потому что они как правило занимают небольшой размер поэтому очень выгодно их скопировать на все узлы да и делать соответственно скала церовани joiner и наконец в хабблкасте есть третий вид распределение называется синглтон это он означает что весь resulted находится на одном узле и последнее используются для того чтобы смоделировать доставку данных в в конечный курсор которая дает данные по уже непосредственно пользователю и идея заключается в том что с помощью кальцита вот эти все распределения можно закодировать с помощью специального интерфейса который называется trade и в дальнейшем операторы могут некий период оператор может запросить конкретное распределение у child оператора и то есть представьте что вот верхний оператор руб это оператор которые моделируют доставку данных пользователю и очевидно что мы хотим все все данные свести в одну точку иначе иначе мы просто не сможем из курсора их отдать если под ним находится оператор допустим сканы который имеет parties and распределение это означает что он всех данных на текущем если у меня нет вы мне нужно каким-то образом их доставить и с помощью кальцита можно смоделировать вот это свойство так называемые дистрибьюшен и сказать что если один узел запрашивают у другого зла свойства какой-то допустим синглтон и черт узел не может этому свойству удовлетворить то можно инструктировать апачи кальцит вставить специальный оператора в нашем случае операторы ченчик который смоделируют скажем так переход от одного свойства к другому то есть в данном случае мы моделируем переход от партии шин распределения кастингу том распределению и для этого мы вставляем операторы качаешь который моделировать передачу данных со всех узлов на один узел в кластере вот и это была интегрирована тоже хотел кости с нуля и это пожалуй одна из самых сложных физических оптимизации которой было сделано и в дальнейшем на этом по оптимизации это все теперь мы больше переходим уже к тому каким как каким образом сколь из запроса исполняются в хабблкасте что мы делаем получив финальный план от кальцита мы имеем набор операторов среди которых встречаются операторы качению и так и кощей моделируют передачу данных между узлами там и имплементировать специальный из visitor который идет по этому дереву снизу вверх и как только он встречает оператора качаешь он создает отдельные фрагменты фрагменты операторов которые могут быть исполнены независимо друг от друга и который связан специальными операторами сендер и ресиверы то есть сендеров как следует из названия отправляю данные ресивер данные принимают и идея заключается в том что эти фрагменты могут в общем-то исполняться независимо друг от друга и тем самым группу ряд нарезая план по границам котеджи можно смоделировать исполнении склеили произвольной сложности то есть абсолютно любой запрос которую только можете придумать можно смоделировать таким образом потому что качаешь позволяет вам в перемещать данные в кластере и в дальнейшем что происходит что в такие фрагменты по 100 как бы получили список фрагментов мы определяем на таких узлах мы мы хотим их исполнить и дальше эти фрагменты начинают исполняться независимо друг от друга и зная связи между центрами и и ресиверами мы можем создавать подсчитанных который мы отправляем из центра в ресивер и тем самым постепенно доставляет финальный результат в курсор в cursor пользователя то есть это вот общий подход который на самом деле вы можете встретить практически в любом в распределенном скале мышки будь так как roach нам fling drill время что угодно то есть они плюс-минус работают все под ком принципу поэтому в этом плане ну как каких-то больших новшеств и за костей сделано не было но для продукта было очень важно получить именно такой движок который потенциально может переваривать запросы произвольной сложности и даже несмотря на то что в первой версии мы поддерживали буквально там операторы сканирования фильтрации и project на будущее это была очень хорошая такая очень хорошая база сам фрагмент что что если представляет он представляет собой некие промежуточные операторы которые берут данные из одного или более им путов и потому могут являться либо индексы либо могут являться м.п. или же это ресиверы и фрагмент всегда имеет один out put out put это или сендеров или либо же пользовательские курсор ну и пример вот каким образом сможет таких операторов можно смоделировать выполнение даже достаточно сложного запроса вот представьте что мы хотим исполнить запросы с этим сиди с юты номер 3 в котором как видите у нас есть jointech таблиц у нас есть какая-то агрегация у нас есть я сортировка то есть запрос достаточно сложные и как правило данные которые участвуют и не всегда скала ци раваны и с помощью вот этих операторов очень что мы мы можем сделать мы можем это разбить на три отдельных фрагмента в первом фрагменте мы можем определить 2 2 из 3 таблицы как репликейт что позволит нам сделать эскалации раваны join узлах независима друг от друга то есть каждый узел какую-то часть своих данных там джойнер потом найти же узлах можем сделать при от при а агрегацию после этого мы можем поставить вот эти сам император и качанчик при превращаются в центры и ресиверы и отправить это в следующие фрагменты следующий фрагмент сделать финальную агрегацию сделать предварительную сортировку и уже перешли данный на один узел финальный где произойдет финальный мерки 600 то есть но конкретных озил касту ты меня этот сценарий на данный момент не поддерживает это но тем не менее это демонстрация того каким образом такой подход может использован для того чтобы смоделировать достаточно сложный scoin далее в плане исполнения все операторы входил кости были сделаны на основе так называемого в итераторов в волками это идея которое было предложено в середины 90-х заключается в том что для всех операторов вы можете определить общий интерфейс с помощью которых вы можете по сути вытягивать в следующей записи вытягивать следующей записи из из из текущего оператора и так как все операторы реализуют один и тот же интерфейс вы можете делать композицию таких операторов то есть представьте что вы хотите сделать операторов фильтр фильтр переданы из какого-то другого оператора поэтому вы можете просто сказать что одно одним из полей два оператора является другой оператор и когда вызывается опираться next на фильтре мы вызываем нефть на child операторе смотрим прошел ли он смотрим удовлетворяет ли он предикату если дату моего даем при тем случаем у цикле продолжаем вытягивать данные с child оператора поэтому эта модель является достаточно к удобный и простой в реализации мы взяли его за основу и поэтому всех наших операторов есть общий интерфейс который в общем то напоминает вот этот классический volcano стоял и траве и операторами другое дело что иса делать такой подход в лоб тут возникает ряд проблем и потому что в оригинальном теперь и таки итераторы отдают по 1 по одному то плов что не всегда эффективно потому что представьте если у вас 1000 записей в таблице то вам нужно будет вызвать операцию next операторы сканирования одну тысячу раз что может повлечь за собой большие накладные расходы поэтому первое что мы сделали мы сделали бочонка то есть наши операторы отдают и один дрого дает сразу пачку ru это привнесло определенной проблема потому что теперь необходимо лоцировать под них память не понимаю думать о том когда эту память можно освободить то есть кто кто владеет этим большим но в целом с точки зрения производительности это был достаточно хороший шаг другая проблема с которым мы столкнулись это то что так система является распределенная может казаться что для текущего фрагмента нет данных потому что они допустим сейчас выполняются на удаль нам и зле и этот узел еще не завершил обработку и поэтому мы в общем-то не не хотим висеть на операции next и блокировать какой-то поток который сейчас исполняет наш фрагмент поэтому мы переделали вот этот классический дервейс вне блокирующий режим которые заключаются в том что теперь операция next отдает не конкретно кортежи а вместо этого оно сигнализирует нам если какие-то кортежи которые мы можем вытащить из операторы прямо сейчас или же мы должны по и же этих картах же нету ни мы должны пока что приостановить исполнение текущего фрагмента чтобы может быть возобновить его когда-то в будущем вот поэтому перед ему сделал такую переделку мы смогли реализовать как реализовать исполнения фрагментов и в кооперативном пули идея заключается в том что для каждого фрагмента вы мы там через простейший compressed можем его поставить на исполнение фрагмент всегда исполняется строго в одном потоке и если фрагмент вдруг понимает что он либо закончил исполнении либо данных не хватает в том и то фрагмент перестает исполняться или от другому фрагменту в этом же потоки продолжить свое исполнение и здесь ну так вот так как продукт написано джаве мы использовали в форум джен паул и идея заключается в том что наши операторы никогда не блокируют потоки что общем-то достаточно тоже достаточно хорошо сказывается на производительности и наконец последний это сам сетевой протокол который мы сделали для запуска исполнения запросов идея заключается в следующем что при исполнении каждого запроса мы выбираем некий узел который будет являться координатором мы или в данном случае инициатором этого запроса это узел имеет особую роль потому что он выбирает какие другие узлы будут принимать участие в запросе он и он координирует все исполнение и здесь для того чтобы запустить запрос мы просто рассылаем специальную команду ig секунд на узлы на узла участники как только узел получает команду он был мгновенно начинает исполнять эти фрагменты за которые он отвечает далее как только участники начали исполнении они начинают обмениваться патчами данных и здесь здесь если вдуматься то вот этот алгоритм так как у нас нету какой-либо синхронизации времени старта времени старта исполнения запросов на отдельных узлах может получиться так что один узел отправляет опустим watch на другой а это другой узел а еще даже не в курсе что что он должен что-то принять ну потому что еще просто не успел получить сообщение от координатора поэтому здесь нам пришлось побороться с рядом гонок которые приводили там либо к потере по чьей либо утечкам памяти но конечном счете это все решаемо и и алгоритм был спроектирован на так чтобы у нас не было каких-то блокирующих этапов здесь то есть чтобы нам не пришлось допустим ждать сначала всех узлов папа подтверждения того что они получились будут запрос и только после этого уже разрешать им продолжить исполнения без этого как только не получает и пьют они мгновенно стартуют и тем самым мы экономим время на вот этих самых сообщениях далее очень часто получается так что центр и ресивер работают на разных скоростях например может получиться так что сендер генерирует пакеты быстрее чем ресивер может их принять и обработать поэтому нам потребуется реализовать алгоритм в некий некое подобие flow control алгоритма который заключается в том что сендер и ресивер изначально договариваться на неком количестве условных кредитов которые описывают сколько данных сендер может отправить на ресивер и скажем пакет с каждым отравленным пакетом на сендере уменьшается и количество рисом и кредитов если же она достигает нуля ту sander перестает отправлять данные на ресивера refer же в свою очередь может он отслеживать сколько кредитов осталось на сендере если увидишь их осталось мало но при этом ресивер готов продолжать исполнении запроса то он периодическая брат отправляет называемый ок сообщение которое увеличивает обратно количество кредитов на с эндрю и тем самым вы всегда поддерживается некий баланс того сколько пакетов находится гру горя в пути к ресиверу что позволяет нам избегать перегрузки этого самого ресивера далее последний часто протокола но тем не менее очень важно является отмена запросов потому что всегда может возникнуть некая ситуация когда необходимо остановить исполнение запросов на всех узлах например из-за того что пользователь явно от меня запроса или из этого что на ком безуглов возникла ошибка и проще и здесь протокол выглядит тоже достаточно просто любой узел который участвует в исполнении запроса может инициировать остановку запросы для этого он отсылает к лицу команду на узел координатор после чего координатора делает бродкаст сообщение на отмену всем остальным узлам и сделано это в три фазы для того что мы заметили что очень часто бывают ситуации когда все участники могут захотеть остановить запрос плюс-минус одновременно и потому что допустим они все столкнулись с одной и той же ошибкой допустим сериализации в jabber ноги вас не какие-то проблемы с данными да и в этом случае если бы все участники напрямую отсылали запросы всем остальным то могло бы легко легко получится так что у нас есть n участников и они отправляют н квадрат сообщений каждой каждому и чтобы этого избежать мы сделали вот такой двухфазный протокол как который нам гарантирует что мы никогда не отправил больше чем 2 and сообщение вместо n квадрат сообщения поэтому такая небольшая оптимизация позволяет нам избегать этого шквал от запросов на отмену вот ну и последний очень важный момент который необходимо понимать по текущему состоянии дэш к это то что в нем на данный момент отсутствует какое-либо я скажу так fault tolerance в том плане что если вдруг возникает какая-то проблема на одном из узлов допустим падает из-за проблем с сетью или там из-за кита других проблем то мы можем только отменить запрос то есть мы можем гарантировать то что вы никогда не получите некорректные данные но восстановиться с произвольного падения на данный момент в козелка стене возможно и связано это в первую очередь с тем что мы пытались оптимизировать ожог под лтп нагрузки то есть мы предполагаем что запросы которые исполняют пользователя недостаточно быстры и они не бегут вам минут имеют часами прочим поэтому вероятность отказа достаточно невелика и альтернативой этому как альтернативу можно было бы делать какие-то промежуточные материализации результатов которые создают тельные фрагменты это позволило бы нам в общем то сделать сделать и скажем так порты сделать движок таким образом чтобы вы могли восстанавливаться с произвольного падения во первых это достаточно не просто дела с точки зрения времени инженеров в во вторых для у типе нагрузок это может оказаться в общем-то избыточный потому что зачастую проще заново запустить вот этот самый короткий вопрос и получить уже финальный результат чем тратить время на то чтобы эти данные на то чтобы создавать какие-то промежуточные материализации поэтому на момент проектировали мишка было принято решение что проблем should a fault tolerance а не является настолько актуальной актуален является обеспечение гарантий того что мы никогда не дадим некорректные данные юзерам поэтому на данный момент если вы используете скользкой за кости то вы вы должны иметь ввиду что потенциально любой запрос может упасть из-за проблем с сетью поэтому ваш код если вы хотите гарантированно и восполнить должен делать некие ретро и там и прочее это конечно очень важно понимать что медики как как компромисс и конечно в идеале мы бы хотели чтобы пользователь никогда с такими проблемами не сталкивался всегда получал результат но как и сказал обеспечение этого достаточно нетривиальная и для у тебя нагрузок мы приняли решение что пока что это ставить в стране но не исключено что это изменится состав со временем то есть это не какое-то решение которое высечена в камне скорее тут о каким образом работала по крайне мере первая версия сквозь в хазел костя так ну на этом все то есть если подвести итог то примерно за полтора года мы сделали с нуля и сквален движок которые используют кальцита для оптимизации вы сделали свой протокол мы сделали свои полностью свой backend для исполнения где у всех операторов есть общий интерфейс может делать произвольную как-то композицию этих операторов и в первой версии которая вышла осенью 2020 года поддерживались только простые операторы такие как сканирование фильтрации проекция но в будущем на вот эту инфраструктуру очень легко и очень коп расширить с помощью для того чтобы поддерживать join и агрегации сортировки и допустим в новых версиях там уже появились и и агрегации сортировки дальше появится join и поэтому здесь то каким образом был сделан божок предполагает его достаточно легкую и беспроблемную эволюцию для поддержки были сложных были сложных и сколь запросов прям но на этом все спасибо за внимание мне него спасибо владимир спасибо большое за ваш доклад сейчас мы сможем задать вопросы из зала вам давать такой вопрос больше руслан у нас если кластер начинает расти по нагрузке начинает масштабироваться появляются новые ноды период нагрузки прошел он начинает скукоживается как реагирует собственно вот этот механизм пересчета его надо инициировать как-то или интеграция с окружением вы спрашиваете про сам продукт их hotel casa то есть не происходит правильно да да да ну смотрите в хабблкасте это устроено следующим образом что там есть специальный протокол которые связывают какие узлы в данный момент есть в кластере и если узел приходит и уходит то инициируется специальная процедура которая переросли дэва и данные соответствии с текущим и распределением то что сделали за последнего дополнительно еще еще раз видимся что сделали за последние год-два потому что полтора-два года об это это проектировалась некрасиво вы знаете я не уверен может быть вы сами гриб про разные вещи но ты меня в сном их хазел кости вот этот механизм который может перри шариди ровать данные в соответствии с новой топологии кластера он и чуть ли не с первых дней продукта то есть это не что-то новое это всегда присутствовала и следить может быть можем отдельно пообщаться может быть просто про разные вещи говорим спасибо так вот еще вопрос и еще вопрос здравствуйте алексей подскажите пожалуйста какова вертеп данного механизма сколько надо родным и извините-ка что неудивительно вот так держать микрофон так нормально слышно да то подскажите пожалуйста есть ли какой-то overhead и измерялся ли он относительно родного опять вы сколь доступ к относительно много чего родного дня ну то есть это все ели по извините да да смотреть мы делали ряд beach park of где мы пытались сравнить что было и что стало да естественно так как это абсолютно новой инфраструктуры там было большое количество проблем которой мы чинили но в итоге я я бы сказал так что фундаментального ускорения не произошло потому что не было просто прочти для этого пошли стали движок использовать яндекс и допустим новый но тем не менее на каком-то то есть здесь главное преимущество заключалось в том что этот движок так вот стриминговый по сути и работаю с курсором она может перепоя скажем так перемалывать потенциально неограниченное количество данных в отличие от предыдущего который работает с коллекциями который всегда строго ограничен в своих возможностях но performance оказался плюс-минус одинаковое то есть в каких-то запросах там но мы бы знать мы сделали разные запросы допустим запрос который там один роу там из иных свернет там 10 вечера у там иными проще да и пытались посмотреть на систему под под разными углами и получилось что где-то старые 5 чуть-чуть был быстрее где-то новую быстрее но в целом они плюс-минус одинаковое по крайней медленнее не стала бы не стал это понять а softworks hard марс как вообще никак не отразились на скорости да да да да да да там видите там например в клане с половиной сколь запросов одна из очень у таких тяжелых вещей это оптимизация вот я к сожалению докладе это не упомянул ее видимо зря что мы используем там кэширование планово запросов что позволяет нам избегать этого перехода это тоже на самом деле не совсем премиальному что вам необходимо отслеживать изменения конфигурации кластера горный плана его лидировать все там по сделано по уму но тем ни менее отдыхать на оптимизацию на устоявшийся стабильной системе сведён практически к нулю то есть это просто лука попа стринги за запроса в могу дать поэтому финальный результат по производительности был сопоставим с тем чтобы в будущем этой каше планы запросов а то всю инфраструктуру снова кальцита да то есть это не ваш код ну там идет не кэшировать сми запросов а каширования именно в каширование ну ладно запросу да да да то есть там мы у каждого узла есть независимый такой кэш ну здесь настолько ки запрос кому приходят и как каждый узел опять же слушая события реконфигурации кластер а принимать решение о том что планы надо ее mba лидировать спасибо так он еще вопрос если сразу еще вопрос следующий спасибо за доклад вопрос какой уровень изоляция spain этот вопрос на самом деле к этому движку не совсем применим потому что потому что я призвал кости понять и транзакции их нет в принципе то есть они возможно появятся в дальнейшем не исключено но на текущем этапе вы можете считать что это что-то уровня рядками that грубо говоря да потому что есть это данных приходится кластере но вы не можете гарантировать что если этом я 2 2 записи сохранил до во-первых самосохранению уже само по себе не атомарная поэтому чтение не атомарного по определению тоже спасибо а можно сразу 2 we're sure его не классов когда часть записи с новым классом там добавлено поле есть вероятность что модель загрузиться с прошлой версии класса ну вот здесь я сходу не отвечу потому что я не совсем хорошо помню как работает механизм этого перехода между версиями классов но в целом я скажу так что скрыть про java тут там каких-то хитрых механизмов работы с класса ударами у нас на тот момент когда я занимался разработкой не происходило то есть предполагалось что есть одна версия классу в игре все другое дело что я входил кости есть разные форматы хранения данных их можно хранить либо виде java объектов то есть когда у вас там одна версия класса альтернативно там и специальный формат называется португал который позволяет вам хранить данные как просто абстрактные групп кури аппаратом имя атрибуты и значение атрибута и в нем конечно вы можете хранить разные версии да то есть два значили с разным набором атрибутов но если помните но там первом слайде я сказал что но одном из переводов и я говорил про схему вот здесь я сказал что мы играем первую пару ключ-значение которые мы увидели в системе и на ее основе принимаем решение атрибуты присутствуют если получилось так что мы взяли старую версию мы будем исходить из того что только три пуда старой версии присутствуют но в таблицах в этих виртуальных поэтому в этом плане какого-то механизма гарантировать что именно там новая схема будет это за снова изначально не было но в дальнейшем мы добавили специальные команды вы можете посмотреть документацией заказ и называется create mapping она позволяет вам строго определиться с это атрибутов которые вы хотите видеть в таблице то есть даже если в каком-то объекте этого атрибута нету он будет вам представлен в виде нам значение и это позволяет вам всегда иметь какую-то скажем так фиксированную схему для конкретной для конкретного объекта и map и это в каком-то смысле эту проблему решает но породил что пользуют этот остается сложнее потому что он сам должен создав новую версию объекта но должен явно вызвать вот эту команду creed мэппинг или от фирмы пин кода который сменит схему спасибо спасибо за ваш вопрос владимир спасибо за ваш доклад было очень интересно у нас для вас есть как для всех спикеров подарок памятный и как обычно можно будет пройти в зону цифровых кулуаров там вам могут задать еще онлайн вопросы либо вы можете продолжить дискуссию уже более детально и к вам сразу вопрос прозвучал для такой вопрос за которое вы хотели бы отдать подарок и либо нет дадут и еду последний вопрос который был схемы в металле вот и тогда проходите нам для быть вам все подскажут и помогут всем спасибо на этом докладе данный зал будет закрываться но пока runner расходиться в семь вечера 20 минут от компании skillbox будет пивная вечеринка вот благодаря нашему спонсору можно будет провести хорошо этот вечер и всем до завтра в других залах еще могут быть доклады поэтому смотрите программку и приходите всем спасибо"
}