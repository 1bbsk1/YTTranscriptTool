{
  "video_id": "qNL9jliFWSw",
  "channel": "HighLoadChannel",
  "title": "A/Б-тестирование: от сегментирования до профита / Кирилл Котов (Superjob)",
  "views": 557,
  "duration": 1688,
  "published": "2017-04-22T14:48:24-07:00",
  "text": "всем привет меня зовут кирилл котов я работаю в компании superjob руководил отделом разработки многие думают что superjob это всего лишь один сайт по поиску работы и сотрудников отчасти это так на самом деле у нас большое количество продуктов а внутри этих продуктов современные технологии интересные технологические решения и сегодня я расскажу об одном из таких решений это система оба тестирования расскажу наш опыт построения такой системы которые хорошо масштабируется работать с большим количеством пользователей и большим объемом данных я думаю все тут понимают что о своих пользователях нужно знать максимально многом любые продуктовые изменения должны приносить пользу и бизнесу и пользователям и абэ тест как раз такой инструмент который может нам помочь оценить пользу от изменений в тестах много пишут и много говорят но как правило статьи фиксации акцентируются на либо на сегментирование пользователей либо на мат аппарате например расчет статистической значимости но довольно мало статьи о том как выстраивать эффективную инфраструктуру рассчитанную на большое количество пользователей рассчитаны на большое количество платформ и данных перед нами superjob стала как раз одна из таких задач superjob это во-первых большая до 100 персия написано на php это мобильная версия сайта написаны на стыке но джесс это более девяти мобильных приложений на самых популярных мобильных платформах каждый день к нам приходят порядка миллиона уникальных посетителей также у нас есть своя система рассылки почты написаны на языке ярланд мы каждый день рассылаем более 4 миллионов писем и несколько сотен тысяч sms и push-уведомления и я рад поделюсь с нашим опытом как мы в таком многообразии платформ нагрузки и данных построили прошли путь по построению своей инфраструктуры по а по тестированию и аналитики поделюсь проблемами с которыми столкнулись на самое интересное ошибки которые совершали первые попытки проведения оба тестирований начинались где-то в 2011 году годах у нас они шли со стороны продуктовых менеджеров все что они сделали это взяли внешние инструменты такие как виза вебсайт optimizer optimizely ком эксперименты гугл аналитике попробовали их запустили таких инструментов есть определенные плюсы то есть это быстро вы просто ставите джейс код на сайт вам не нужны разработчики вы в визуальном редакторе меняете элементы как вам нужно для теста и даже не нужны какие-то глубокие знания теории а bt став им от статистики системы сама за вас рассчитает необходимые размеры аудитории продолжительность теста и статистическую значимость полученных результатов но не обходится и без минусов во-первых такие системы заточены в первую очередь под клиентские тест и во вторых вы не сможете после проведения эксперимента рассчитать какие-то новые метрики потому что у вас банально нет метрик нет необходимых данных либо вы предусматриваете все возможные метрики и записывайте их перед началом теста либо вы проводите тест еще раз ну и третье это цена чем больше вас пользователей тем дороже вы платите менеджер это все дело посмотрели потестировали мы поняли что нам такие системы не подходят и на какое-то время это отложили в долгий ящик следующая вторая операция пошла уже со стороны разработки нам потребовалось тестировать разные алгоритмы ранжирования поисковой выдаче мы начали делать свою систему первое с чего начали это пользователя нужно сегментировать поскольку у нас с экспериментах участвовать не только зарегистрированные пользователи но и гости мы при первом заходе вешаем вечную куку которая уникальна идентифицирует браузерах до конца пользовательской жизни к ней есть ряд требований к ней и к системе сегментирования во первых такой и не диффе катар должен иметь равномерное распределение чтобы не было всплесках непосредственно сама система сегментирования должна работать так что пользователь всегда находится для одного теста в одном и том же варианте он не должен сказать для одного теста между вариантом а и b например для разных вариантов для разных экспериментов он не должен находиться в одном варианте то есть нельзя делать так чтобы пользователь всегда находился варианте а или варианте b это плохо также варианты разных тестов должны быть распределены случайно и сегментирование должно быть и терменировали то есть имея идентификатор пользователя например 9 в кадр пользователя и название теста мы должны в любом в любом месте системы точно назвать вариант тест которым попал пользователи он не должен меняться как правило для этого используется хэш-функция от название теста от конкатенации название теста и и не диффе катара пользователям мы взяли вот на тот момент мы взяли готовый библиотеку я цехе чем сейчас она уже не поддерживается ну мы ее использовали для управления сегментами пользователей вариантами тестами и прочим чтобы нам знать как можно больше и иметь возможность пересчитать любые метрики пост-фактум уже после проведения эксперимента мы решили писать максимально много о пользователях начали писать все взаимодействие пользователей с сайтом ну так называемый экстрим на самом деле чуть больше туда входили также какие вакансии пользователь увидел на сайте какие вакансии откликнулся какие резюме получили приглашение так далее мы взяли на тот момент знакомую нам базу данных току д.б. у нас не был положительный опыт некоторые на серверной стороне через сервер очередей мы посылали данные обрабатывали и первое время все было хорошо все было хорошо пока они пришли менеджеры и не стали говорить давайте больше давайте проводить больше тестов давайте писать больше данных ну вот давайте и постепенно стало понятно что только db нас не устраивает очень быстро запросы которые считают метрики стали выполняться долгие часы и даже несколько суток следующая проблема то что система разрабатывалась разработчиками для разработчиков и точно также приходили менеджеры каждый день практически с просьбами уточнение какие сейчас тесты запущены а давайте включим тест давайте выключим тест давайте поменяем распределения это отвлекает от работы и сильно не удобно ну и третья проблема это то что платформа у нас была всего одна да стоп версия сайта а очень быстро появилась потребность тестировать на всех наших платформах это в первую очередь рассылки и мобильная версия сайта стало понятно что в таком виде система нас не удовлетворяет и жить больше не будет поэтому стало очевидно что отдельная часть этой системы нужно выносить сервисы можно сказать что-то сервисной архитектура но на самом деле здесь не все сервисы нарисовалась два отдельных сервисов во первых это сегментирования это сервис который получает на вход индификатор пользователей какие-то ещё дополнительные данные и возвращают вариант которым принесут пользователя сервис сбора данных которые агрегирует всем все данные со всех наших платформ и записывает их хранилище также у нас есть те процессы которые данные обрабатывают и хранилище которая поверх которого работают аналитические процессы к сегментированию у нас были довольно простые требования во первых это производительность у нас порядка миллиона пользователей каждый день при этом более десятков тестов на бою происходит регулярно одновременно и сервис должны отвечать быстро не должно быть узким местом также все изменения которые происходят в тестировании включение тестов выключения тестов распределение пользователей должны происходить моментально со всеми пользователями и система должна быть гибкой настройках потому что тестов проходит много и нужно уметь очень четко управлять сегментирование пользователей так как у нас был положительный опыт работы с эликсиром с орлан вам о нем написано наша система рассылок мы взяли похожий стек мы реализовали сервис на платформе elixir это язык программирования которое работает поверх виртуальной машиной long соответственно он имеет все плюсы эрланга и добавляет еще несколько своих плюсов во первых у него если хозяйственные процессы он умеет менять код на ходу то есть без перезапуска сервисом есть утилиты для работы для сборки и диплом кода и наши ожидания оправдались в девяносто процентов случаях время ответа укладывается менее чем в 3 миллисекунды верхней 10 процентов там максимальное время ответа порядка 20 миллисекунд что не очень хорошо но более-менее приемлемый далее сервис работает по протоколу джейсон open почему именно джейсон api почему вообще не записать один раз информацию на каждую платформу и забыть у нас изначально была условии что мы хотим как можно быстрее уметь управлять тем как устроены тесты если у нас тест показывает плохие результаты то нету смысла его продолжаете это потеря для бизнеса это потеря деньгах потери в пользователях мы выключаем тесты хотим что он выключился на всех платформах также мы долго боролись с разработчиками запрещая им кэшировать результаты работы с этим сервисом они пытаются оптимизировать зачем делать лишний запрос можно сохранить в qq или не дай бог в базу но в 95 процентах случаев это не нужно и приносит только только проблемы также одним условием это была гибкая сегментирование мы добавили так называемые фильтры например эксперимент может работать в эксперименте могут участвовать например пользователи только нижнего новгорода какой-то фильтр по гео признаку также симитировать пользователи мы можем по произвольному параметру это уникальный индификатор браузера из примера выше либо например это e-mail пользователя либо например идентификатор кампании чтобы пользователи одной компании видели всегда один вариант эксперимента кроме того потому что экспериментов проходит много постоянно возникает проблема может возникать проблема их пересечения и этим нужно очень аккуратно управлять есть такой документ от google вкратце что на себя представляет у вас появляются виртуальные сущности такие как домен слой и эксперименты содержатся в слоях но при этом и домены и слои могут друг друга включать при этом доме ну нас делят трафик и эксперименты в разных доменах не могут пересекаться никогда а в разных слоях могут пересекаться это все гибко управляется например на мы проводим эксперименты для соискателей и для работодателей то они вполне могут пересекаться но это разные метрики и пользователь скорее всего эти эксперименты вообще не увидят также в этом сервис мы сделали административный интерфейс больше менеджеры не приходят любой может зайти посмотреть какие эксперименты проводились такие эксперименты с какими это не закончились какие текущие настройки сегментирования какие варианты существуют также можно быстро его там выключить либо наоборот включить есть ряд вспомогательных инструментов например на наших сайтах есть такая скрытая странице где администратор может увидеть все тесты которые сейчас проходят соответствии с кратким описанием со всеми вариантами может посмотреть какой вариант конкретно достался ему и при необходимости переключить на тот вариант который ему нужен например для тестирования плюс также здесь различные вспомогательные фишки вроде того что мы разрешаем показывать конкретный вариант теста при указании специального урла но опять же для тестирования либо если нужно передать какому-то внешнему подрядчику показать недостаточно просто сегментировать пользователей нужно данные которые от них поступают как-то собирать собственно у нас есть сервис коллектор который также написано lexer и который агрегирует данные со всех наших платформ в качестве клиентского трекера мы взяли трекеры из проекта снова план они существуют для самых популярных языков ну в нашем случае по крайней мере и довольно простой установки вы точно так же ставить и джесс код на сайт добавляете какие-то события которые вам нужно открывать дополнительно и собираете данные коллектор не пишет напрямую в базу он пишет файловое хранилище во первых это быстрее вторых нам в любом случае нужны сырые данные и зачастую это хранение их дешевле чем базе после того как файлы записанные они сектор и периодичностью раз в пять минут 1 минуту обрабатываются с помощью этой процессов в качестве цели инструмент у нас используется пинтах да и что мы делаем с данными во первых это очистка мы вычищаем ботов мы вычищаем некорректные данные мы делаем дедупликации данных после этого данные а богачи обогащаются стадии in richmond когда мы мир по айпи адресу добавляем дело информацию о пользователе и наконец они загружаются хранилище в качестве хранилища у нас используется аналитическая база данных йурид packard vertica это платное решение но его плюсы перевешивают его плотность во-первых она практически не требует администрирования по крайней мере на первых этапах ставится по гайдам и работает из коробки и при этом работает довольно быстро вы можете поставить кластер из трёх нот и помимо прироста скорости и производительности вы получите отказоустойчивость когда кластер переживет падение одного из сервер и серверов при этом есть бесплатная версия комменте дешин бесплатно позволяет размещать 1 терабайт данных работать на трёх серверах есть альтернативы бесплатные этому решению это берен план конечно и недавно выпущенная выпущенный продукт от яндекс crack house возможно стоит их тоже попробовать мы никак не нормализуем данные у нас с абсолютно плоские таблицы это с одной стороны нам немножко мешает потому что нормировать данные мы наверное будем занимать меньше места уменьшили целина 2 место но с другой стороны такая плоская структура там порядка 70 колонок позволяет нам упростить и загрузку данных и скорость выполнения запросов это немножко повышает нагрузку на аналитиков потому что приходится писать немножко более сложные запросы и горизонт хранения данных у нас до года все данные которые превышают в год они агрегируются в заранее предопределенные метрики но при этом так как мы храним данные в сыром виде в файловом хранилище в любом случае у нас есть всегда возможность эти данные загрузить и сделать с ними определенные вычисления ну и в качестве резюме тут скорее такие советы которые не были бы самому интересно и если смотреть в прошлое во первых пишете тест и потому что то же самое сегментирование пользователей вроде как простая простая история но в ней легко можно швеца и если вы заметите это очень поздно на через неделю через две можно это время просто выкидывать всегда проводить и контрольный а а тест то есть вы выделяете какую-то небольшую группу пользователей и проводите на ней фактически пустой тест два абсолютно одинаковых варианта таким образом вы проверяете целиком свою из инфраструктуру сегментирования пользователей до сбора аналитики хранение аналитики то есть если у вас в тестах закон в таком тесте произошло расхождение значит что-то у вас работает неправильно также храните сырые данные они вам в любом случае пригодятся хранение довольно дешево с сегодняшними ценами на жесткие диски не откладывайте разработал административного интерфейса может показаться что это довольно такая второстепенная вещь но на самом деле людям удобно этим пользоваться и это снимает много отвлекающих нужны факторов и обязательно назначить ответственного человека который бы во-первых вел backlog экспериментов во вторых подбивал в него результаты тестов в третьих этот человек и наверно только он должен знать какие тесты сейчас идут с какими распределениями что с чем пересекается чтобы в дальнейшем не было каких-то неприятных сюрпризов когда мы одному пользователю показываем белый шрифт на белом фоне спасибо за внимание привет кирилл во-первых я очень рад тебя здесь видеть при этом у меня вопрос а бывает ли так что тесто становится вечные ты вот начал говорить о том что у вас есть фильтры и предположим вы провели эксперимент увидели что немного стал все хорошо но прям тот же эксперимент показал там в питере ухудшение и как вы принимаете решение о том что теперь этот эксперимент остаются навсегда он в новом городе активно в питере другой или просто разница в просите перевешивает ну сложный вопрос скорее разница в профите перевесит но по хорошему нужно правильно выбирать свои группы на которых мы проводим тесты за выборка должна быть все таки репрезентативный почему здравствуйте спасибо за доклад такой вопрос вот все эти фигурки для оба экспериментов исходя из моего опыта рано или поздно становится таким средством управления функционалом то есть когда вносить а например эксперимента гарсиа он какой-то функциональность включает например на сайте экспериментом версии bad как отключает какой-то например там новые фичи ли вообще какой там какой-нибудь важный функционал вот вашей точки зрения вот это правильное или неправильное использование и направление развития скорее неправильная по-хорошему нужно заставлять своих разработчиков просить ее и обучать чтобы вместе светка которая выливает эксперимент они также выливали ветку которая эксперимент отключает в негативный или позитивный момент но если это единственная задача которая не возлагается на неправильно если сопутствующая то почему нет добрый день кирилл ты упомянул что первым вашем варианте сбор статистики занимал до нескольких дней после перехода на вертик какие цифры стали надо понимать что вертик это все-таки колоночный аналитическая база данных и те запросы которые отрабатывали очень долго на классической только тбн на вертите это максимум час и даже менее она не real-time какие-то метрики в реал тайме зависит от продолжительности а есть какие-то столкнулись с ограничениями минусами какими-то вернике новыми инновациями она наверно требовательна к объему памяти на серверах то есть того объема которой не рекомендуют минимальным для наших данных не хватало на желательно нажать на 2 а действительно ли линейное увеличение количества нот в кластере плечо то линейное увеличение скорости загрузки не на всех запросов ну да спасибо здравствуйте и спасибо за доклад я хотел спросить вы использовали указывали в презентации от гугл аналитике эксперименты а там используется алгоритм нога рукава бандита это когда между группами а и b трафик наливается неравномерно и иногда на одну группу больше на другой меньше потом может поменяться для того чтобы ускорить результат apts вы что-то проводили ну в своих тестов хит из исследования использовали или такой алгоритм для того чтобы ускорить исход и быстрее определить успешные варианты пока только в планах а какое файлохранилище вы использовали ветки не понял ну типа хранилище flex или обычно не от обычно flexo мы практически не пользуемся ну просто не задачи таких данные вы архивируйте именно последовательно у вас не бывает того что вам нужно кусок данных пересчитать пересчитываем но в вертепе нас хранится срез за последний год если нам что-то нужно пересчитывать больше ну как правило это посмотреть на сезонность данных то мы загружаем из файлового хранилища и проекцию вы тоже верстки используйте проекции довертесь меня есть вопрос один спасибо за доклад вопросов сна если его ситуации когда разные пользователи заходят сразу начать использовать заходит с разныx клиентов и пример заходит мобильного приложения и сайты и мы должны показать один и тот же вариант вот как вы с этим стало количество курсе как решали так и если такие ситуации бывают у нас одно место генерирование тот в уникальной cookies и она она сквозная для всех пользователей это раз для пользователей и мобильной версии или 100 перси сайта едва мы можем проводить тесты не по которым браузером а по индикатору пользователям если мы хотим именно отслеживать переходы между платформами в том числе между мобильными приложениями такой счет вопрос вот ваш инфраструктуре время отклика между временем тогда когда мы например включили эксперимент и когда мы уже видели какие то данные то есть как быстро вы на это реагировать ну пример простой мы запускаем две версии эксперимента об этом вообще хорошо в пользователю 404 мы отключили для 5-ти процентов пользователей мы хотим эту ведь как как можно быстрее вполне логично ну смотрите у нас в 1 реализации были самописные дашборде на ява скрипте там они показывали кита графики значимой статистическую позже мы от этого ушли и стали использовать инструмент визуализации дабл он и сейчас у нас настроены там дашбордов которые любой менеджер любой сотрудник может зайти посмотреть поиграться с параметрами статистической значимости и если не ошибаюсь там настроенные с интервалом в час в час если нужно чаще то значит турками возможно лезть и вот а спасибо добрый день всего за доклад скажите вы используете перемешивание аудитории ну то есть перевода чем вариантов там то есть ну такую улыбку что перри выдать например группе а чтобы они увидели вариант b вот или может как-то так понятен вопрос понятен но нет мы не используем и еще один вопрос вот вы выбрали эликсир по каким-то по каким причинам вот новости кнопку на php то есть почему не использовали ну смотрите во первых нам было не очень интересно писать сервис на php которые вызывает другой сервис на php во-вторых у нас был большой опыт работы с ерлан вам эликсир это язык который работает поверх виртуальной машиной ланга ну поэтому взяли понять почему здравствуйте спасибо за доклад вопрос такое вы сказали что нужно делать административный интерфейс вопрос сколько как какие возможности дает администратор они могут только посмотреть результаты тестов остановить или даже может быть создать новый тест вот что что у вас в этом заложена ну мы не разделяем правами те пользователю кого из доступа они могут и смотреть и создавать новые тесты останавливать старые тесты удалять нельзя а вот создание нового теста как она осуществляет же нужно чтобы на сайте был какой-то код определенный или или как это вот создание теста просто задаются параметры теста и при обращении к описать и названием теста и определенным и нить котором пользователя система возвращает вариант до тех пор пока тест не запрашиваются одного из клиентов ничего не происходит соответственно если нету поддержки со стороны клиентов то и запрашивать его не будут всем спасибо за внимание"
}