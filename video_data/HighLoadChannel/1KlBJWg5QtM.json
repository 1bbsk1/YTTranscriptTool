{
  "video_id": "1KlBJWg5QtM",
  "channel": "HighLoadChannel",
  "title": "Inhouse-система аналитики: руководство для начинающих / Иван Зерин (Scentbird)",
  "views": 1382,
  "duration": 3071,
  "published": "2020-04-27T12:25:06-07:00",
  "text": "всем привет я рад вас видеть несмотря на столь поздний час для сегодняшнего так и я рад я вставляю брянцев для клик хаоса который идет соседнем слоте сегодня я ближайший 40 минут вам поведаю о том опыте которые мы испытали когда строили свою систему аналитики внутри нашей компанией sunbird и небольшой дисклеймер как водится это не best practice это наш опыт мне кажется он позитивный и именно по этому я его здесь вам буду рассказывать с какими-то выводами которые мы сделали на этом пути немножко про меня я уже почти десять лет занимаясь разработкой программного в течение большая часть моего опыта она связана с прям рафинированным бэндом я разрабатывал на джаве и больший опыт большей части опыта она связана с инвиз банкингом специфическая сфера два года назад я пришел в компанию sunbird и мне предложили попробовать построить систему аналитики это то чем я до этого не занимался никогда поэтому опыт он такого начинающего аналитика строителя ну и собственно говоря давайте перейдем уже немножко ближе к докладу к самому внезапный вопрос я уверен что здесь все имеют хотя бы один парфюма поднимите руки у кого есть хотя бы два парфюма дома которая не использует а3 парфюмы и больше так а теперь смотрите такой вопрос а кто из вас когда-либо ходил в парфюмерный магазин покупал parfum он казался прямо классный вообще огонь приходили домой пробовали и файл подставляли и не использовали ну короче вот эти четыре человека вы как раз наша целевая аудитория значит компания снг чем мы занимаемся на слайде наш продукт это то чем мы зарабатываем и к чему мы живем это кейс в котором находится колпачка с парфюмом объем 8 миллилитров одни ребята на ю тубе делать анбоксинг и они посчитали что 8 литров это 120 пшиков но примерно как то вот у них такие метрики и они решили что да окей это где-то на месяц хватает суть сервиса в следующем что цена ошибки при покупке парфюмов в большой емкости в магазине она достаточно высоко и чтобы снизить ее можно подписаться на сервис выбрать парфен который вы хотите получить каждый месяц получать какой-то новый parfum который вы хотите попробовать если вам нравится parfum то вы покупаете уже полноразмерную бутылочку с этим парфюмом не нравится пробуйте дальше понравился купили полноразмерную бутылочку ради бога никто не мешает дальше продолжать выбирать что-то еще чем пользователи продолжают увлекаться и делают это собственно говоря у нас подписанный бизнес по доставке парфюма делаем это в сша и на данный момент у нас около 270 тысяч активных пользователей это те кто заказывает parfum каждый месяц работаем с 2013 года теперь немножко про нагрузку который у нас есть около 100 тысяч сессию нас в сутки проходит на наш сайт и эти пользователи делают где то пол миллиона событий в сутки нефти какие нагрузки но дает вам представление о том что у нас происходит немножко про техническую команду мы состоим на данный момент у нас почти 50 человек техническая команда работает удаленно в разных часовых поясах это отдельная тема разговора как мы там ухе таимся друг другом ладить но есть у нас а ходу офис в нью-йорке там находится снова бизнесовые ребята связаны этапа двумя причинами прежде всего мы доставляем и делаем бизнес штатах и второй момент многие парфюмерные бренды имеют свой штаб квартира в нью-йорке и чтобы с ними договариваться такой модели бизнеса нужно часто вести разговор фашистов с что важно для сегодня доклада то что мы живем в амазоне мы живем в amazon узком облаке и это достаточно сильно влияет на выбор решений которые мы начинаем делать немножко про специфику подписанного бизнеса вообще любого не обязательно нашего в отличие от обычного ecommerce сайта где разовая покупка она включает себя маржу которая оправдает существование бизнеса в подписчик бизнесах это не так одна покупка она убыточна вам необходимо приводить пользователя снова и снова на сайт что делать повторные покупки обычно нужно там 3 4 5 6 у всех сервисов по разному количество покупок разное дальше важный момент который здесь тоже присутствует это то что большая часть клиентов подавляющая часть клиентов не хочет комитета деньгами они не хотят покупать вперед например на шесть месяцев ваш сервис на 12 месяцев они покупатель из помесячно с возможности уйти в любой момент и это заставляет вас постоянно находиться в определенном напряжении потому что вас в этом месяце все хорошо в следующем люди могут уйти когорты это основано летите в подписанных бизнесах потому что это очень естественный способ анализа такого бизнеса как подписка на когорты с точки зрения технической реализации требует большое количество исторических данных и не так просты с точки зрения обсчета этих данных и приготовления этой метрики на мощностях базы данных или какого другого сервиса но и как следствие этого всего нам необходимы исторические данные в большом объеме больше чем для обычного и комель сайта мы должны собирать это все теперь немножко уйдем на два года назад я пришёл в сендер ты мне предложили по простроить сервис аналитики все начиналось с такого сетапа ничего сложного основной сайт который кидает веб статистику mixpanel и google analytics пишет своих данных по сброс и сбоку пристроен самописный портал который строит какие-то отчёты по продажам делает какие-то построения графике все это читает из той же базы которая у нас была для нашим нашего основного сайта как-то работал а вот как то так это скриншот нашего даже барда на нашем сам описанном аналитическом портале иногда все выглядел действительно именно так потому что причины ясны одну базу шариат между двумя сервисами аналитически запросто достаточно тяжелые ну и мы тоже не совсем опытные ребята в основном у нас b конный опыт и соску или им мы иногда творили такие вещи которые нам казались вполне нормальными но иногда мы стреляли себе в ногу вот я сейчас не большой позор вам дам вот смотрите обычный сколь запрос ничего сложного по большому счету если мы посмотрим на сложно наводить ладно не буду в общем первая строчка да у нас искать запрос очень простой который ограничивает выборку по дате ну или по таймс темпу любой запрос аналитики практически любой он так или иначе вращается вокруг поле даты дел ускорение мы делаем индекс практически по дефолту всегда на это поле все работает все классно потом как я уже сказал у нас в нью-йорке ребята сидят и смотрят на эти данные которые находятся в виде считаем злыми и они говорят ну как бы нам бы хотелось new york times зоне смотреть эти данные давайте что-то сделаем мы говорим не проблема продвигаемся по всем нашим искать запросам делаем кастинг и переключаем на юшкой time зону вопрос что происходит все происходит да вот здесь правильно говорят по нашим замерам запросы начинают работать где-то на два порядка тяжелее почему так происходит вот здесь я чувствую сидит специалист есть идеи да а почему индексы используются да абсолютно верно но я не слишком силен в том что происходит под капотом баз данных но на пальцах у нас фактически виртуально появляется новая колонка да куда мы скостили данная милашкой time зону и и соответственно не просто индекса нет вот так вот мои себе иногда стреляли в ноги это абсолютно реальный случае абсолютно как бы вот из моей практики как мы делали поначалу набираясь опыта вот ну собственно говоря пройдя этот этап мы пришли к выводам который мы решили обобщить и понять что у нас происходит что мы что мы узнали прежде всего мы научились делать первые метрики мы построили первые когорты узнали как это работает нам стало понятно что это не так просто есть какие-то вещи которые но действительно не так простыл аналитики что еще важно что performance у нас так себе у нас был случай когда мы запилили когорты и далее пользователям на растерзание один пользователь взял и решил построить когорту за четыре года он ее не дождался через 15 минут балансировщика отрезала его соединения я потом уже сам поигравшись узнал что такое когорту нужно строить 45 минут на нашем сетапе что как бы вообще не приемлемо мы прокачали навык миску или как я показывал на предыдущем слайде иногда это прямо на проводе происходило ли сюда тролл фэйс transparent фоном чё-то как-то так себе но в целом но вот но по-прежнему на тот момент я считал что аналитика это очень простая штука вот у нас есть база мы не пристраиваем портал аналитический начинаем читать данные пожалуйста показываем результаты вот как то так ну вот по итогам этой итерации у нас был примерно вот такой ну не надо использовать рабочую базу для аналитических запросов это моветон это так себе ну и собственно говоря мы начинаем от этого сетапа дальше развиваться делаем все естественно добавляем readonly реплику пробуем что из этого выходит получается примерно вот так нагрузка с основного портала ушла но запрос как были тяжелые так они тяжелые остались сильное ничего не изменилось система растет развивается данных собираем больше время от времени начинаются какие-то проблемы мы придумаем какие системы кэширования такие случаи случаются все реже но тем не менее они есть выводов по этому этапу сильно у нас никаких нет все те же самые только мы перестали прокачивать свой скилл напротив самый главный вывод который мы здесь получили что похоже нужно брать что-то более более заточенная под специфику аналитики так как мы живем в структуре амазона а в с мы сразу начинаем смотреть что amazon может нам предложить под это дело и быстро натыкаемся на 1 shift пробуем смотрим cola ночная база данных все как положено инфраструктура амазона все как нам нравится низкий порог входа redshift основан на движке по фгос вы прямо берете скальники спазган сможете запускать нарушив практически ничего не преобразовывая это очень классно происходит все прозрачно и собственно говоря мы сделали очень простой тест такой в лоб взяли перевезли пару табличек с данными врач shift взяли и сколь запрос такой вот полотно выполнили на пастбище выполнили на решив те получили рост производительности на порядок классно подумали мы надо переезжать и здесь мы сталкиваемся следующей проблемой как перевозить данный врач shift узнаем авиатуры и тел я думаю все в зале знает что такое тел ну и собственно говоря мы читаем что с этим делать как это готовят приходим как обычно в любой технологии есть два лагеря тех кто говорит надо брать готовое и те кто говорит да там ничего сложного я здесь и сошник накидаю эти две таблички перевезу будет вообще огонь зачем платить там деньги кому-то что-то еще в общем надо делать как то так в этот момент я натыкаюсь на интересную статью посвященную таким же изысканием человека насчет того как бы сделать гибкое решение но при этом не сильно углубляться в написании каких своих велосипедов и он рассказывает про сервис amazon а do the pipeline который достаточно гибок для того чтобы прям конкурировать с каким-то сам описанным решением за точным чисто под тебя и не настолько хардкорным ну и мы решаем почему бы нет давай попробуем do the pipeline ну и практически сразу мы понимаем что это гибко но мать его сложно вот как-то так выглядит граф для компонентов для перевозки данных и спас город прямо в redshift то есть там ничего не происходит данные читаются пик лация враг shift вот столько вращающийся там кубиков находится под капотом у каждого кубика куча параметров но и соответственно как вы понимаете чем больше кубиков механизме шестеренок тем больше возможности стрелять по ногам не только себе вот ну и собственно говоря мы в этих попытках стрелять по ногам начинаем ходить к суппорту support нас уже знает мы с ним достаточно часто общаемся по моему за два месяца когда мы пробовали переходить на ты the pipeline мы разговаривали с суппортом по серьезным проблемам раз шесть или семь мы с ужасом думали что будет когда мы захотим начать преобразовывать какие-то даны в промежутке между тем как укладываем их в redshift и мы представляли что граф такой наверное будет вырастать раза в два крайней точкой был вот такой вот ticket когда-то у нас была мысль что нам возможно понравится но да the pipeline некоторых джаббы стали время отрывания падать при этом они после падения не оставляли за собой логов то есть узнать почему они упали было невозможно мы идем в support спрашиваем что нужно было делать почему теряются логе из опор дает нам вот такой ответ ребята напишите вот такую строчку и будет все огонь и вот ну как бы я здесь так думаю но учета похоже сервис чересчур прям overkill какой то здесь надо прям так сильно разбираться и в какой документация должен был это прочитать вот но в общем в итоге на этой ноте мы закрываем свои общение за the pipeline ум и начинаем искать альтернативы понятно что поймем дтп планом и достаточно быстро натыкаемся на популярный ресурс стич популярный сам сервис он в целом острова нас приятное впечатление но он очень сильно заточен на юань создание этих компонентов у них есть реальная не помню почему то у нас там не сильно их опять порадовал мы именно разработчики нам хочется все это достаточно классно интегрировать свой процесс именно continues delivery они там на клики во что-то кроме того у них было достаточно высокая цена они берут деньги за количество перевезенных строчек что почитав примерные наши те объемы а на тот момент мы как бы так но немножко расстроились параллельно с этим мы знаем что amazon выкатывает новое свое детище углу на тот момент это был достаточно молодой сервис у него были какие-то проблемы детские проблемы болячки были но они достаточно активно и лечились активно пытались и он достаточно гибок нам это подходило мы решили попробовать и знаете нам понравилось мы втянулись оказалось все не так плохо у амазона достаточно оперативно по нашим запросам ну как нам кажется мы приходили к спорту и говорили вы знаете вот здесь вот такой косячок неплохо бы его сделать и с удивлением обнаружили such as какое-то время достаточно обозримое мы даже еще не успевали забыть о том что мы обращались на этот счет а эти фишки появлялись в амазонии но мы надеемся то благодаря нам там кто его знает но собственно говоря вот таким сетапом мы начинаем дальше развиваться и переходим вот от такого сайта по переходим к такому теперь наши данные поступают в глу там перемалываются кладутся в redshift некоторые данные приезжают нам на s3 это как правило сторонние сервисы туда складывают данные и в итоге наш аналитический портал начинает работать с шифтом только для получения каких-то real-time метрик он ходит в нашу редон для базу какие выводы что что вы добились на этом этапе прежде всего у нас performance стал совсем по-другому заиграла все когорта мы смогли уже выгружать там не за десятки минут а это уже были минуты без всякой оптимизации просто складывая данные так как они были у нас также перекладывая получили минуты по моему что то минут 12-13 но это просто вот что я помню у нас продакшен перестал быть связан с аналитики вообще как-либо мы полностью ушли от того чтобы влиять на наш production пользователи им стало нравиться то что аналитика работает быстро то что многие отчеты можно уже получать как то не по 40 минут ожидая а можно что-то там действительно посмотреть к нам стали приходить с какими-то вопросами предложениями и новыми отчетами ну и что самое важное мы в этот момент стали сознавать что аналитика это не просто что построить систему аналитики это не совсем так как нам казалось сам начале вывод этого этапа он достаточно простой найти ели можно убить кучу времени можно попробовать перед что-то свое поначалу это будет казаться очень простым каким-то путешествием не самым сложным действительно можно что-то на коленке на ваять но правда здесь здесь лучше не влезать дальше будет только хуже поэтому наш опыт это использовать готовое на этом этапе дальше как я уже сказал пользователи входят во вкус и начинают поставлять на новые задачи список задач довольно обширен прежде всего поддержка старых репортов создания новых репортов так как это у нас было самописная система аналитики то мы делали еще и ей соответственно в этой системе аналитики и backend писали и данными занимались и работы набиваем занимали достаточно большой большой процент времени нам приходилось писать всякие визуализации прикручивать фильтры java скриптовые липки какие-то подставлять которые позволяли там перестраивать графики в том или ином виде в общем все это отнимало достаточно большое количество времени кроме того к нам приходили по всевозможным одноразовым выгрузка сырым допустим нас просили выгружать имейлы пользователей которые проживают в определенном регионе чтобы сделать по ним таргетированную рассылку не такая уж большая и сложная проблема тем не менее время отнимает разновидность одноразовых в игру зак это были какие-то проверки гипотез ну например там у нас было гипотеза о том что пользователи из южных регионов они покупают parfum чаще и больше чем пользователей из северных регионов для соответственно для того чтобы это проверить нужно выгрузить данные по продажам северных и южных регионов как-то разделить эти регионы дать эти данные на валидацию человека который будет строить на основании этого какие-то выводы делать вот по этой гипотезе кстати правда жители южных регионов чаще покупают парту еще одна разновидность репортов которые нам приходилось делать это одноразовые репорты то есть не нужен никакой ей просто нас просили выгрузить эти данные в excel q там чуть-чуть причесать данные отдать этот reporting и он когда ты уходил на сторону в итоге количество задач у нас было большое на тот момент над аналитикой трудились два человека соответственно мы всего не успевали стали думать что делать вариантов был не так много прежде всего была возможность ввести жесткие контроль над задачами а именно отсекать все задачи которые выглядели как ну такие не не очень уверенные скорее всего которые будут сделаны зазря но это классно в компания где уже устоялись процесса где это можно сказать прямо в ходе для большого количества задач у нас недавние стартапы и компании активно развивается и сказать это уверенно нельзя поэтому этот ряд нам не подходил второй вариант это расширять команду разработки способ небыстрый достаточно дорогой и не сильно гарантирующий результат четыре человека делают не обязательно два раза больше делать чем два человека сильно зависит и третий вариант это дать инструмент какой-то пользователям с помощью которого они смогут сами находить решение своих проблем мы плавно пришли к вопросу поиска своего bio инструмента начале мы искать с me the bass это опыт собственная тула у концов на и решение для bio я она оказалась достаточно сырым и прежде всего она нам сразу не подошло потому что наш существующий функционал в нашем сам описанном портале мы не могли туда переложить прям сходу это сразу поставила крест потом всем известное табло которое оказалось прям гибко для нас и хорошо но стоило как крыло от боинга просто для пользователя для одного учитывая что у нас там пользователей где-то с десяток то мы просто все не могли это позволить дальше мы посмотрели на amazon крик сайт тоже достаточно свежая штука от амазона на тот момент было но с его с wix там были прям проблемы и тоска печаль а так как это не tool для разработчиков для пользователей в это был достаточно важным моментом параллельно с этим мы решили посмотреть еще на looker и здесь был достаточно прикольно нам понравилось он достаточно гибкий оказался по цене он составлял меньшую стоимость одного разработчика для нас при этом у ребят действительно классный support я сейчас никому толкаю если есть ребята из looker и я потом подойду за деньгами support вообще отличный у них потому что не только они поддерживают пользователей которые приходят использовать looker но вы можете к ним обратиться с вопросами как разработчик как сделать какие-то сопряжения с локи рам и они ищут ответы на эти вопросы возвращаются к вам и даю действительно дельный совет собственно говоря на локере мы остановились и наш сетап стал выглядеть примерно вот так что по итогу это итерации у нас получилось прежде всего у нас большая часть задач стала решаться без разработки вот эти вот спонтанные запросы от пользователей теперь можно было решить нак ликованием в лагере и делали это ну отчасти разработчики частицами пользователя но тем ни менее времени это стало экономить прямо прилично у нас был вполне естественный период когда количество задач которые на нас свалились резко вырос это период когда у нас происходил активное внедрение looker а у нас было две системы мы должны были перевозить старые порты в новую систему делать новые репорты и при этом еще справятся с толпой пользователей которые приходили и спрашивали как вообще всем этим пользоваться потому что никто не ходит на всевозможные онлайн тренинги и прочие весь этот стаф все ходят к разработчикам спрашивают как сделать то или другое из плохого у нас какое-то время было два источника отчетов в процессе перевозки отчетов мы безусловно нашли как водится какое-то количество мелких багов какие-то неточности в данных мы их исправляли и всем пользователям говорили что теперь правда находится вот в нашем новом инструменте но тем не менее это нас не спасало пользователь приходили пересушите я вот здесь вот открыл и здесь открыл и данные не сходится чо за фигня и пользователям приходилось объяснять искать прямо rudkus почему именно в конкретно в этом случае какой из какая из проблем повлияло вот на именно это расхождение это отнимало время но и само собой мы стали точно понимать что аналитика это еще и дорого не только сложно дальше вывод по итогам этого этой итерации это то что я инструмент дорогое удовольствие но при должном использовании и самое главное при использовании инструментов во время он начнет экономить вам прилично времени с этим придется немножечко побороться свои жабой внутренние но bio инструмент того стоит теперь немножко про то как мы получали эксперт в области обработки данных приходящих к нам проблема в том что изначально мы думали что данные достаточно братья способов прикладывать в redshift пристроить какой системой визуализации все будет классно но потому что эти данные они же приходят оттуда где все правильно но это не так в качестве иллюстрации вот такой тем график покажу у нас есть на сайте есть такая очередь куда пользователь накидывают parfum который не хотели бы получить следующий месяц через месяц и так далее есть у нас уникальные пользовали который себе расписали parfum на 13 вперед мы таких находили при помесячной получению парфюма но есть пользователь который себе ничего не положили в очередь и мы таких пользователей пытаемся мониторить потому что явно эти пользователи то ли не знаю что выбрать то ли с ними что-то не так . ки это проблемы вот это график показывает количество пользователей с пустой очередью 10 прослежу за определенный паттерн это абсолютно такое нормальное поведение пользователей ничего страшного нет в этот момент мы еще не делаем тестов на данными на на данными мы просто их перевозим и храним и здесь происходит такая штука мы видим какой то всплеск мы его увидели постфактум стали разбираться что там не так и не смогли найти рут коз не смогли потому что к этому моменту когда мы стали копаться в этом мы только увидели автор шок а саму причину вот так и не нашли то это была проблема вышестоящий с теми то ли это было бага в нашей схеме данных то ли еще что то неважно в общем как бы мы этот момент упустили в итоге мы заканчиваем покрывать тестами вот этот кусочек данных находим эту бабу и правил эти данные назад к нормальному значению как видите график опускается примерно до приемлемого уровня потом происходит следующая штука ребята на нашем основном сайте вводят новый функционал и у нас все выглядит вот так здесь все еще пока что нормально но вот этот вот двойной спайк который вы видите в конце это ненормальное поведение дело в том что когда у пользователя parfum который он заказал отправляется к нему этот парфюмы изымается из очереди в итоге длина очереди сокращается на единичку что в принципе абсолютно логично и ok и вот эти спайки которые происходят они как раз и говорят о том что он был момент доставки парфюма очередь у людей схлопнулась но такой спать должен быть один в итоге выяснилось что ребята запилили новый функционал и по какой-то причине пока что тоже мы знаем что это баг и ребята на основном сайте следует почему это происходит так почему то два раза парфен был изъят из очереди но отправлен был всего один в итоге мы получили вот такую ошибку с данными которую мы будем думать что будем с ней делать когда ребята объяснят нам природа происхождение этого бага потом мы видим вот такую штуку думаем что ага опять и табак но нет оказывает что это успешная рекламная кампания большой поток трафика и как бы все нормально вот эта иллюстрация к тому что просто данные перекладывать смысла особо нет данные постоянно будут как-то вам портить жизнь не сами данные о люди которые на них влияют и собственно говоря с данными нужно что то делать а что делать с данными нужно делать следующие действия преобразовывать данные мы преобразовываем данные в dimension модель вы можете преобразовать это в какую-то другую модель но демедж модель самое известное для аналитических данных и самое удобное вот дальше вам нужно будет хранить какие-то исторические срезы потому что скорее всего у вас ваша оперативная база данных анахронизм текущее состояние по многим вещам например пользователи который вас сегодня живут вы храните просто их текущее состояние а сказать что с ними было вчера были они подписаны отписан и вы можете ну так опосредованно или приближённо поэтому вам придется делать snapshot таких таблиц ежедневно и ежечасно неважно это зависит от того как вы решите но придётся с этим что то делать нужно будет делать фильтрацию данных и делать обогащение данных здесь все достаточно понятно иногда приходится работать с метаданными ну например самый простой способ это сбор данных после приезда очередного патча новые порции данных вам нужно почитать сколько у вас новых колодок прибавилось каждой таблицы не колонок извините строк и для особо тяжелых репортов вам придется делать при калькуляцию при калькуляция позволяет там ускорить работу каких-то репортов но это все тоже придется делать и еще один момент вам придется во лидировать данные это как раз очень сильно соотносится с тем графикам который вам показал до этого нужно будет детектив что происходит с данными находить какие-то аномалии на них как-то реагировать то ли репортить то ли исправлять то ли просто приду бежать пользователя о том что вы здесь у нас есть аномалия мы с ней ничего не можем сделать вы имеете в виду вот собственно говоря список того что нужно делать мы примерно такой опыт набрали и преобразования данных вот в этой аббревиатуре это буковка п и теперь мы стали искать чем мы можем эту буковку т закрыть каким solution нам попробовали тот же glu оказалось что глуп для transformation подходит так себе мы даже смогли в несколько раз отправить world of memory support подтвердил что это бага пока что они с этим ничего не могут сделать и остается только ждать может быть они уже починили не знаю но мы стали искать другие решения и нашли 9 tool достаточно прикольная штука она использую другую концепцию преобразования данных происходит не в памяти как допустим углу а после переезда данных сырых free shift при воззвание данных происходит в раньше все как-то выглядит вот примерно так у вас есть схема с таблицами с сырыми данными откуда вы просто переносим данные как есть потом 9 запускает постоянно скриптов из куриных которые преобразуют данные перекладывать другую схему и на эту схему же смотрит бей найтула собственно говоря вы делаете такое преобразование данных не in memory and plays кто знает что такое 9 тула если вообще есть люди такие в зале окей тогда я пробегусь быстренько по вечерам все что в 9 то ли делается это делается и способности select of результат любого selecta он может быть запустите как табличка или как табличка в памяти и select и можно выстраивать в цепочке ссылаясь один select на другой таким образом вас делать с абсолют такая логично и понятная цепочка из преобразований на данными которые можете делать это очень удобно там из коробки есть инкрементальный обработка то есть вы можете пробовать только новые данные который приехал с очередным бачок и вы можете делать снапшоты тоже из коробки снимать как раз ты сама real-time данные с напишу так что очень мне нравится как разработчика это то что через эту толу можно съезжать сложности сколь запросов фактически вы выстраивать цепочкой select of вы переходите на новый уровень абстракции работы с select a mea не делая такие полотна на самом деле под капотом это будет конструкция виз сити е конструкция гиперфункция возможно не так классно но читабельность улучшается прям вообще на порядок там есть стройный механизм проверки приехавших данных по constrain там это очень круто это позволяет ловить кучу ошибок и кучу проблем в данных и кроме того вы можете написать кастомные тесты на данные это то что позволяет вам делать специфику своего бизнеса внутри данных вы лидировать ее как-то собственно говоря а ну да поэтому консоль снова тула разрабатывает ребят ипсвич таун analytics у них есть свой флаг channel достаточно активная комьюнити и тула развивается это дает такую надежду что все будет гуд с этой штукой пока что мы используем и нам нравится и собственно говоря с этой тулой масштаб стал выглядеть примерно вот так вот мы и добавили крик shift ap и пока что живем с этим с этапом аналитический портал старый мы практически за диками сели в него уже никто не ходит мы пока что испытываем такой период в котором мы ждем вот этот санитарный период когда точно это не нужно будет некому и будем его выключать оставаться навыки что по итогам ну да да вы вывод об а это итерации то какой вывод что данных не бывает идеальных вам придется всегда иметь дело с какой-то проблемой идеальные данные то лишь идеала которому стоит стремиться но такого не будет никогда по итогу с таким сетапом чего вы добились прежде всего наши когорты сейчас строит свои где-то около 2 минут чуть меньше но примерно типа того у нас появились пользователей которые сами через looker задают вопросы сами находят ответы на них и даже делают очень классные графики намного лучше чем это могут сделать разработчики это сильно разгружает команда разработки у нас достаточно мощная гибкость появилась благодаря 9 туле мы можем строить такие pipeline и бы по образованию данных которые просто ну больше нашей фантазии ограничены и потребностями и все это масштабируется за счет vs по большому счету преобразования данных и работа всей аналитике сейчас завязано народ shift решит стелется достаточно классно и мы пока что не испытываем проблем с тем как омские лица просто добавляем новые машины когда нам нужно и это работает мы храним данные на максимально доступную и возможную глубину многие сервисы берут дополнительные деньги за то чтобы хранить данные например на период больше чем год мы делаем это на глубину вообще своего существования мы храним данные насколько насколько хотим это стоит достаточно дешево по сравнению со сторонними сервисами но тем не менее и аналитика аналитика это просто это это как кататься на велосипеде до который горит и ты горишь и все горит и ты в аду но на самом деле это это сложно и дорого правда это сложно и дорого не все так просто но если вам нужна гибкость если вам нужны какие то нужно готовность переменам то вам вряд ли подойдет solution который вам будут давать из коробки и толпа консультантов которые будут приезжать обследовать ваш бизнес настраиваете пробивать мазями какую-то большую систему за бешеные деньги скорее всего вам так или иначе придется касаться этого момента как построить аналитику в итоге на последнем слайде я свел все выводы которые я на протяжении всего доклады рассказывал но ездить кратко остановлюсь на том что все классно в свое время то что не нужно использовать рабочих б.д. это прям можно вообще прям вы только стартанули прекращаете использовать рабочую базу данных для аналитические запросов специализированные б д можно использовать когда вы там чуть-чуть подрастете там же и и тел вы начнете использовать с bio инструментом нужно четко понимать что это дорого его мы туда нужно переходить когда вы уже действительно созрели когда вы чувствуете что это вам нужно потому что до этого момента вы вполне можете обходиться каким-то по собственным решением или каким-то на коле ночным решением не очень сложного там строения то есть в целом здесь сразу кидаться на bio инструмент смысла нет ну это что самое важное наверное самое возможно и очевидно это что данные придется постоянно мониторить и с ними придется делать что то чтобы они были правильные вам постоянно будут мешать постоянно вкидывать какую-то простите дичь в эти данные и с этим придется как-то жить поэтому собственно говоря нужно быть к этому готовым и что здесь какой вывод можно сделать то что данные нужно начинать тестировать как можно раньше чем раньше вы начнете тем меньше у вас будет legacy данных который вы не можете использовать свои аналитической системе пожалуй у меня все давайте передём к вопросам спасибо спасибо за доклад иван скажи пожалуйста собственно объем данных с которым вы работаете это какой-то миллиарды миллионы о чем речь если мы говорим в строках я не скажу в терабайтов мы сейчас подбираемся к ему первому терабайту у нас около что-то 800 гигабайт данных на данный момент накоплено в нашей энергетической системе так и еще вопрос сталкивались ли вы с необходимостью защиты данных я просто прослушал там сколько у вас пользователи этих данных раздаете ли вы их кому то и нет нет если необходимость в защите пользуются необходимости в защите у нас на данный момент как таковой нет то есть мы пользуемся стандартными средствами лукора который делает там логин и пароль и раздаются соответственно внутри компании пользователям до пока что над этим вопросом мы не задумывались то есть мы используем просто looker как готовое решение в которыми встроенные механизмы для контроля доступа пользователей примерно где-то на полтора десятка у нас наверное со стороны бизнес новых ребят а в лагере если механизмы шифрования и таки низации такой вопрос один легендарные скрывать не скажу честно не интересовался этим вопросом пока что не сталкивались то есть я не готов ответ на этот вопрос но можно поискать я думаю что luger что что-то на этот счет сто процентов имеет там уже достаточно интересная тула большая росте спасибо за доклад я может прослушал сколько по времени это история заняло почти два года а второй вопрос вы как-то реализовали такой кейс когда пользователь хочет как-то сам обогатить данные с какой-то своей группировкой приходит нет такого кейса мы не реализовывали но мы честно говоря не стоит с таким keys чтобы пользователь пришел ага этот я хочу обогатить как право к нам приходят и говорят мне здесь есть данные и можно мне еще сюда вот что-то добавить есть у вас такое и мы смотрим в нашей рабочей базе примерно прокидываем когда мы можем добавить и мы перевозим то есть а что пользовать пошел со своим там cs ваш ником что такое то есть то кого-нибудь из неба спасибо за доклад скажите пожалуйста тот этап когда вы говорите что требуется валидация данных да ну что он тестировать данные как можно раньше кто этим занимается то есть этим занимается разработчики или какие-то уже коллеги ваши от аналитики там не знаю кто наиболее озабочен данными здесь смотрите здесь нужно разделять что вы подразумеваете под словом тестирования потому что я сын докладе говорил про автоматизированное тестирование то есть baby титул о котором я рассказывала позволяет делать автоматизированные тесты вы при каждой заливки новых данных прогоняете тесты и верифицировать и что новые данные они по этим тестам пройдут что не будет таких проблем а если мы говорим про то что есть какое-то ручное тестирование какая-то валидация того что там паттерн и вот как я показывал на графике да они устраивают то безусловно эти вещи так или иначе они всплывают процессе использования бизнес пользователь на специализированной людей которые мы с тестированием данных нет то есть процессе эксплуатации системы так или на что-то вылезает мы стараемся эти кейсы которые вылезают при таком при ручном наблюдение ручные наблюдения учитель из термин мы пытаемся покрытиях автоматизированным тестами что больше наступать на эти грабли но на самом деле даже там тесты на constraint и они покрывают такое количество кривых данных что вообще то есть на новые тесты появляется в момент когда вас расширяется модель данных и то есть когда происходит изменение в бизнес-процессах они появляются в двух случаев это как с uni тестами у вас появился новый функционал или вы наступили на какую-то бабу которая выстрелила вы ее починили и вы хотите убедиться что она больше не будет воспроизводиться то есть вы пишете тест которым потом чинить и эти данные с помощью которого чинить эти данные и таким образом вы лидируете что больше вы в этой ситуации попадете и вот еще тоже задавал коллега вопрос про безопасность то есть у вас в системе какие-то персональные данные вообще полицейский есть или они как-то отрезаются как-то агрегируются вот с точки зрения вот этой персональные данные пользователей да есть платежные данные которые связаны там масс с карточками скручивающие мида они безусловно отрезаются но данные например адрес человека и имя фамилия это у нас хранится то есть и она находится на данный момент пока что она доступна всем пользователям по ну каким причинам наверное больше историческим и на таком на подъеме мы учимся ходить да как-то с этими данными там сталкиваться и не так много людей пока что хотят эти данные как правило и так окуните кастомный support которым обращается что вы знаете у нас посылка потерялась им нужно пойти данные заглянуть чтобы понять куда нашла каким бы чем оно было отправлено где потерялась то есть как-то так пока что мы не решаем эту проблему вопрос такой получается вы используете readonly базу для генерации отчетов а если какие-то тузы у вас разработанные которая обеспечивает can системность данных между обычай базой и базой для отчета смотрите здесь не совсем так мы используем readonly базу для того чтобы она была источником для и дел процесса если вы про вопрос как мы обеспечим конец данных между мастером и редон и базой то есть на уровне мозга роста это все решается средствами амазона там редон реплика разворачиваться в два клика и даже если от него амазона по сгрыз поддерживает создание readonly реплики сейчас из коробки сделать проблем никаких нет там у вас будет небольшой глеб где то секунд и там 45 между данными в мастере в сливе и по большому счету на этом все ну там есть конечно свои приколы если там делать тяжелые запросы но если просто для чтения такого восточного то проблем сильно никаких небом здравствуй спасибо за da code pour вопрос по поводу выбора и теле инструментов да ну это вы я вижу не рассматривали всякие enterprise этель инструменты например пинтах у там что-то питах у китов например то что там еще но неважно не рассматривали да почему потому что мы не мы не enterprise это другие сцены они они большие и бесплатные я не уверен что я знаю о чем вы говорите да но просто слова enterprise мне сразу ассоциируется что это такая толпа людей которые приходят врываются берут много денег и потом начинаются это внедрять возможно я не прав если это конкурсное решение она enterprise но такое странное сочетание получается тогда например вы наверняка знаете компания red hat она последует такие цели что вроде бы как enterprise но она у кан source укладываться но у нас в бинтах а то же самое вот такой вот путь мы прошли его вот я постарался показать то есть что она попадала на радар и да с чем мы поработали на что мы посмотрели из чего мы сделали выбор он не конечно не окончательный с тем будет развиваться возможным переходить на другие решения то что мы не смогли смотреть все но мне кажется тоже естественно есть и области знаний в которых все альтернативы очень сложно покрыть как-то так я вспомнил джаспер report тоже не сталкивался не знаю хорошо вы сказали вы строили модели поди меньше нам это я про не понимают olap кубы до использовали вот там по поводу безопасности скрытия там есть встроенные расширение в лапах поэтому так сказать и вы можете этот принцип применить если вдруг из но я думаю да есть если мы подойдем к этому решению если я когда да мы подойдем к этому вопросу то мы будем смотреть на какие-то решения сто процентов что то есть готовы мы не первые ходим не первые катаемся на этой карусели и последним что-то спросить ну вот вы говорите о том что нужно делать срезы вот ну типа мастер базу нас хранит но текущей стаями пользователи да вот вы хотите типы хранить временные какие-то срезы а как то сейчас это делаете мы делаем это на данный момент посредством найдется достаточно просто вычитаете q состоянии таблицы и в рот шифти в целевой базе вы просто это текущее состояние снабжаете дополнительным дополнительно колонкой где поставляете сегодняшнюю дату то есть дату среза мы снимаем среза раз в сутки в итоге у нас просто есть таблица в которой мы такие партиции складываем да и фактически имеем срез по истории 1 таблиц чтобы с ней потом работать можно было сказать каком он был состоянии флота геннадий понятно то есть изменение течение дня вас не интересует на данный момент нет то есть нас устраивает суточная cry ментальность вот у нас такая гранулярный пока что вполне устраивает спасибо что до спасибо за доклад хотелось поблагодарить что как бы рассказали свои стоя j последовавшего докладов наверное количество подписчиков увеличится и если какой-то предел отшив тогда чтобы там крутить данные то есть там больше терабайта и сколько насколько вы рассчитывать и жить на этом инструменте честно скажу что я не знаю какой предел верхней шифта на данный момент мы масштабируем рад shift исходя из объема который решив нам дает потому что наращивать сервера решив то там такая система что когда добавляешь новый instance у вас объем хранилища ещё увеличивается то есть этими хотите хранить больше что вам нужно наращивать мощность кластер а вот и вторая метрика это скорость преобразования данных которую мы получаем мы стараемся поддерживать где-то в промежутке 20-30 минут на вот это весь процесс преобразования сырых давно готовы как только мы выходим за этот порог мы начинаем смотреть что мы можем оптимизировать если мы не можем то мы добавляем новую машину у нас сейчас по моему 6 6 машин по-моему стоит shift и вских и пока что мы не чувствуем что где-то могу убираться но у нас данный объем еще не те поэтому мы как бы не чувствуем вас количество connection of как-то ограничено вышла парящих то направо под брестом 200 уже там нужно думать что то но на самом деле у нас здесь количество connection of очень лимитировано в плане не плане того что решив не позволяет больше по моему у нас сейчас около 20 connection of college of the это просто сводится как раз к тому что не так много пользователей которые ходят в redshift и они ходят через абсолютно понятные нам пути они туда попадают проблем с connection а это же нет идеал инструмент он не учил инструментом и урусов то есть интересная штука это очередь запросов она там настраивается особым образом и мы под эти ел настроили отдельный к ее запросов у него отдельный пользователь и там как бы контролирует это все прямо на пользователи подачи чтобы он имел отдельный приоритет по запросам и не нагружал не забирал ресурсы у людей которые сейчас например работы этой системы это можно устроить да спасибо за вопросов время их вышло вы можете продолжить дискуссии в зоне для дискуссий все выберите пожалуйста лучший самый интересный вопрос как обычно это сложно мне запомнился вот вопрос у молодого человека я думаю что можно туда приз передать спасибо спасибо большое за доклад спасибо"
}