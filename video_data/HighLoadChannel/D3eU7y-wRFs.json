{
  "video_id": "D3eU7y-wRFs",
  "channel": "HighLoadChannel",
  "title": "Архитектура рекомендательной системы Дзена / Дмитрий Кондрашкин",
  "views": 4932,
  "duration": 2906,
  "published": "2022-03-21T14:03:09-07:00",
  "text": "всем доброе утро меня зовут дима в зоне я руковожу отделом инфраструктуры и качество и работаю здесь уже больше пяти лет сегодня я расскажу про то как про архитектуру наши рекомендательные системы и про то как мы строим рекомендации для пользователя за несколько сотен миллисекунд на каждый его запрос вот так он выглядит в приложении индекса цен это персональная ленты или как сейчас модно говорить fit и в нем представлены разные форматы контента это может быть видео короткий пост или статья и цель дзена это посту найти для пользователя интересный материал именно для этого мы развиваем нашу рекомендательную систему пары чисел про дзен мы встроены на главную страницу яндекс яндекс браузер в приложении яндексом и по сути весь трафик с этих поверхностей приходит нашу рекомендательную систему это нет но это около 10 тысяч запросов в секунду в нашем хранилище около 100 миллионов пользователи регионе в день генерируют больше 10 миллиардов событий взаимодействуя с сервисом как принципиально устроены взаимодействия пользователя с системой пользователь открывает приложение получает набор карточек ну скажем 10 20 штук дальше он с ними как-то взаимодействует может поставить лайк дизлайк там просто посмотреть карточку покликать куда-нибудь и все эти взаимодействия они отправляются на сервер и сохраняются в key value хранилища по мере того как пользователь скролить ленту мы ему подгружаем следующую порцию карточек fit у нас мультиформатный и каждый формат он рекомендуется своим отдельным река менеджером они в принципе устроены все одинаково просто заведуют каждый своим форматом каждый такой рекомендован формирует набор из тоже из 10 20 карточек отправляется эти карточки в специальный компонент блендер и он их может как-то переупорядочить и учесть то что пользователю например больше нравится видео смотреть чем статьи читать и дальше мы будем рассматривать вот один такой кубик который рекомендует отдельный формат что у нас есть вообще что нужно подать на вход рекомендательной системе для того чтобы отобрать интересные материалы ей нужен пользователи его история взаимодействий системой то есть события которые он совершал с документами и база документов из которых мы будем отбирать вот эти карточки их порядка там 10 миллионов документов этой базе теперь для того чтобы эту рекомендательную систему описать нам потребуется пару кубиков из машинного обучения имбилдингом им бединге документов у пользователей что такое embedding это набор чисел или вектор в каком-то к мерному вещественном пространстве сейчас не так важна как они получаются как они строятся важно то что с помощью машинного обучения мы можем добиться следующих таких замечательных свойств а именно вектора документы виктор виктора которых близки к вектору пользователя будут ему релевантное ну или интересно а те которые где-то далеко находятся они типа нам не нужны и если мы будем считать косинус между этими векторами то это будет некая такая мера близости но чем ближе век виктора друг другу находится тем как бы у них косинус ближе к единице и на самом деле мы можем много таких векторных пространств построить с помощью разных m-elle моделек и для пары пользователей документ получить целый набор таких вот значение косинусов набор таких вот релевантности вот у нас есть набор этих значений и нам нужно теперь предсказателя документ будет интересен пользователи или нет вот оценить эту релевантность документа для пользователя и это можно представить себе как задачу классификации будет документ интересен или не будет для того чтобы задач классификации решать в машинном обучении есть куча разных тоже алгоритмов мы для этого используем котбус такая open source разработка тоже от яндекса есть аналогия например и boost можно хоть на тензор flow тут какой-то нейросеть собрать и для решения этой задачи в принципе тут простор довольно большой так получается что у нас вот есть такая общая схема есть вектор а пользователей документов на верху обведены и непосредственно рекомендации сначала поговорим про вот это вот нижнюю часть про рекомендации которые происходят в runtime и непосредственно значит у нас есть в 10 миллионов документов мы хотим из них отобрать штук 20 наиболее интересных ну мы могли бы взять посчитать для каждого документа вот эти вот косинус и запустить котбус потом отобрать из этого топ но понятно что это будет работать очень медленно и нас это не устраивает нам нужен какой-то дешевый грубый метод для того чтобы сузить пространство поиска и для этого мы вспомним что наши виктора они обладают вот этим вот замечательным свойством что чем ближе вектора документов к вектору пользователя тем наверное эти документы будут более релевантным и таким образом нам нужно для пользователя найти как бы ближайшие вектора документов а это задач поиска ближайших соседей и существует тоже куча разных эффективных методов там из структур данных которые позволяют и задачи решать мы для этого используем кнн индекса конкретную реализацию воешь nsw вот здесь вот я ссылку на архив привожу кому интересно можете про него почитать его реализация есть в upon source библиотеки нам asleep там еще куча есть других разных методов которые позволяют задачу решать и есть еще библиотечка facebook фаиз тоже в ней можно посмотреть разные методы для решения этой задачи и фишка в том что все эти методы они позволяют там за 10 20 миллисекунд из этих 10 миллионов но там из миллионов викторов отобрать а чё это там такое из этих 10 миллионов гектаров отобрать тысяч десять ближайших так значит вот мы отобрали 10000 ближайших документов дальше уже вполне реально там за еще сотню миллисекунд посчитать для них косинус и запустить котбус предсказать релевантности взять топ как теперь вот эту вот всю схему принципиальную реализовать в runtime и нам нужны виктора документов и нам нужно вот от структуры кнр индекс если мы вектора документов положим в какой внешние киева или хранилища то это будет не очень эффективным потому что нам на каждый запрос нужно доставать 10000 векторов и дальше с ними работать мы просто так эффективно будем использовать сеть забьем весь канал поэтому виктора документов и структуру кнн индекс мы положим прямо в память тех падов на которых у нас скрутиться наша рекомендательная система векторов у нас 10 миллионов ну допустим они будут в сто мерные вещественные это меньше 4 гбайт принципе влезает с запасом с учетом того сколько памяти в современный сервера ставится но на самом деле тут еще важный момент такой что этот это документная база она со временем не очень быстро растет потому что не все документы постоянно попадают в рекомендации есть какие то там новостные сюжеты которые вообще интересные там в какой-то короткий промежуток времени они просто постоянно из рекомендации вываливаются так это про нашу runtime часть а теперь давайте поговорим про то как строить вот эти вектора пользователей документов и тут сейчас будет немного математики давайте рассмотрим такую вот матрицу оценок в ней по строкам у нас записаны пользователи по столбцам документы и в ячейки матрицы мы записываем единичку если пользователь положительно при взаимодействовал с документом и минус единичка если негативным проезжаем взаимодействовал с документом ну например единичка если лайка и минус единичка если дизлайк и теперь мы хотим приближённо эту матрицу представить в виде произведения двух матриц меньшего размера у иды пользователи документа строки в матрице у могу им считать как раз векторами пользователей а столбцы в матрице д как раз будем считать виктора им документов и мы хотим чтобы произведение этих двух векторов была приближена равно ячейки в матрице который соответствует и эту задачу можно вот выписать виде такой задачей оптимизации мы тут записали типа такую среднеквадратичную ошибку и хотим и эту функцию теперь at me минимизировать повод этим да и у виктором и для этого как раз есть такой подход файл с интернете ntfs кратенько как он работает он состоит из двух шагов которые попеременно чередуются сначала мы зафиксируем все виктора документов как-то их прыгну как-то их проинициализирован и увидим что вот если мы эту функцию выпишем то она по переменному который соответствует пользователям будет квадратичной функции то есть типа такой многомерный параболы а у нее есть как-бы один минимум и для того чтобы ее найти мы эту функцию продифференцируем приравняем производную нулю и обнаружим что у нас получилось систем линейных уравнений ее уже можно решить каким нибудь стандартным численным методом дальше делаем тоже самое только для документов зафиксировали пользователи которые мы получили на предыдущем шаге посчитали производную решили систему уравнений систему линейных уравнений и нашли вектора документов и эти шаги будем повторять пока не достигнем сходимости сходимость мы можем определить например посчитав разность между векторами пользователи на двух последовательных шагах если вы ничего не поняли здесь то это нормально можете загуглить и почитать более подробно как эта штука работает здесь важно вынести два один момент если у нас есть вектор а документов то мы можем посчитать вектор пользователя и нам для того чтобы вектор пользователю посчитать нужны виктора документов и наоборот для того чтобы посчитать вектор а документов нужны виктора пользователей это нам будет дальше важно матрица большая оно порядка 100 миллионов пользователей на 10 миллионов документов но она разреженная подробно не буду рассказывать как именно мы эту задачу решали но за несколько часов нам определюсь и можно этот метод айла запустить и добиться того чтобы он нормально работал но он работает несколько часов и связи с этим есть проблемы во первых за эти несколько часов могут появиться новые документы в системе во вторых пользователем продолжают взаимодействовать с документами то есть появляются новые элементы в нашей вот этой матрицы которые мы раскладываем что с этим делать мы решили поступить следующим образом мы 1 2 недели запускаем полный метод которого долго работает полностью эту матрицу раскладывает с нуля раз полчаса мы решили делать только шаг который находит виктора документов и мы делаем только лишь такой один шаг он тоже нам определюсь она работать уже гораздо быстрее и учитывает весь все события и все новые документы которые появились за вот тот период после того как мы матрицу исходно разложили по kei оказалось что можно зафиксировать виктора пользователей на две недели для того чтобы искать виктора документов но можно ли зафиксировать так вот виктора пользователей и в рекомендациях из их использовать что нам дело с пользователями которые пришли в последние две недели у которых вообще нет никакого вектора что нам делать с тем что пользователь за последние две недели мог какой-то новый фидбэк оставите ли у него вообще могли измениться его интересы и предпочтения мы решили что для пользователя вектора мы будем считать в runtime и точно так же на каждый запрос что нам для этого нужно нам для этого нужно история событий пользователя и вектора документов с которыми он взаимодействовал история события у нас лежит в севилью хранилища и на самом деле попадают туда вот сразу же как пользователи с документами взаимодействовал виктора документов у нас есть в памяти пода на котором работают наши рекомендательные системы и мы можем там же перед тем как запустить непосредственно отбор поиск вот этих 10 20 карточек которые мы хотим пользователя отдается запустить поиск вот этого вектора польза подсчет вектора пользователя а это вот как раз ls шаг решение системы линейных уравнений для которой парк мокротой про которым мы только что поговорили получилась такая схема 1 2 недели мы раскладываем матрицу целиком вектора документов мы обновляем раз в 30 минутном определюсь и вектор пользователям и на каждый запрос считаем в runtime у такой схемы с подсчетом вектор пользователь в runtime и есть один плюс он реально учитывает в самые последние самые свежие события пользователя но у него есть куча минусов во первых это на замедляет этот метод он увеличивает latency а если мы хотим например несколько векторов для пользователя строите хотим несколько таких шагов запустить чтоб разные виктора построить то кратного увеличивает время ответа 2 вторая проблема заключается в том что мы навыки мы перестраиваем этот вектор на каждый запрос мы самые свежие данные используем для того чтобы его построить но между двумя запросами пользователь вообще мог никак системы не при взаимодействовать и зачем нам как бы тогда считать этот вектор если пользователь не взаимодействовал мы зазря просто сжигаем процессор и еще одна проблема заключается в том что для того чтобы вот этот вектор пользователь построить нам нужно все документы с которым с которыми он про взаимодействовал они должны лежать у нас памяти этого года на котором на все это крутится как я уже говорил в рекомендациях не все документы участвуют какие нить новостные сюжеты которые там протухли уже месяц назад они не рекомендуются но для того чтобы вектор пользователя построить они нам нужны потому что он мог как раз месяц назад с ними как то при взаимодействовать и мы решили что так не пойдёт мы хотим больше векторов для пользователя строить а это у нас фронтам не влезает и решили построить такой не real-time processing который бы где-то в бэкграунде работал на latency runtime и никак не влиял и строил нам достаточно свежие виктора пользователи которые учитывают самый последний его фидбэк как при принципиальная схема этого процессинга у нас есть очередь событий по типу кафки надо этой очереди стоит такой компонент ришар der который и и разбивает на партиции и в каждую партию по сути шарди руют по пользователю то есть в каждой partition оказывается определенный набор пользователей над этими партиции мы работают worker и worker приписан партиции и он оттуда забирает последние события пользователя у себя в памяти он кэширует историю пользователя для того чтобы снизить нагрузку на key value сторож которым она хранится и опять же у себя в памяти он держит виктора документов у него как бы теперь все есть для того чтобы сделать от tls шаг и посчитать вектор пользователям вектор пользователи он сохраняет в другой киеве лю сторож которую уже наш runtime входит и вместо того чтобы в runtime и считать делать орешек мы ходим в киеве или сторож получилась такая схема теперь у нас документы считаются на ну как бы так же как и раньше до документу на считаются нам определюсь и пользователям мы перенесли в processing ну и вот runtime у нас как был так и остался но здесь появляется еще одна проблема которая связана с тем что мы раздвинь и деле полностью эту матрицу раскладываем заново и получаем там совсем новые виктора документов и пользователей и на самом деле мы не можем из взять вектор пользователя какой-то старый который был получен месяц назад его перемножать с векторами новыми который мы только что получили заново вот перри запустив весь этот процесс они на самом деле получаются из разных векторных пространств потому что то задача которую я записывал этот метод он может какие-то разные минимум и вот этой функции попасть после того как он сойдет и возникает проблема вот у нас есть киева или сторож в нем виктора дуб виктора пользователи как нам их обновить значит в исходный момент времени у нас виктора пользователей документов вам читать что они версии 1 теперь мы запустили вот этот вот и же двухнедельный а л с который полностью нашу матрицу раскладывает и у нас виктора документов теперь обоих версий мы запускаем копию вот этого вот 30 минутного процесса который виктора документов обновляет то есть сейчас у нас какая какой сетап получается в те вылез тораджи у пользователя версия 1 запущен две копии быстрого л.с. а который считает виктора документов 1 30 минут и обновляет их для обоих версий теперь нам нужно в киеве люс тораджи все виктор обновить для пользователей мы запускаем копию процессинга пользовательского и у нас теперь для всех новых пользователей которые сейчас системой взаимодействуют вектора начинают обновляться но у нас есть еще хвост пользователи которые там сегодня не зайдут завтра не зайдут там через неделю может не зайдут на сервис никак с ним при взаимодействует нужно их тоже обновиться распускаем определю стандартных пересчитываем для них вектора загружаем в келью сторож все теперь у нас в киеве или старриджа хранятся вектора пользователей обоих версий processing пользовательский запущен двух копиях обновляя для обоих версий и документы у нас тоже обоих версий обновляются и нам остается только рекомендательную систему переключить на новую версию мы могли бы взять просто и притащить вектора 2 версии поднятия в память кодов и начать использовать но это не очень то же оптимально потому что тогда нам придется двойной запас памяти всегда держать мы берем просто и вместе с виктором документов хранил версию и отправляя и когда band perry поднимает как бы новую версию он старую удаляет новую себе поднимает знаешь что это версия 2 и в и вылью хранилища отправляет какой версии ему нужен вектор пользователя после того как все коды обновили базу можно версию 1 удалять и все эти копии процессинга восстанавливать все мы переехали а на следующую версию за счет такой миграции от подсчета векторов пользователя в ран тайме к нашему тот процессингу мы смогли время ответы уменьшит процентов на 25 и кратно увеличить количество векторов которые мы теперь для пользователя строя мы теперь не ограничены этим лапкам си и ресурсами в runtime и в 10 раз практически увеличили количество викторов раньше был порядка десяти стала около сотни мы ускорили внедрение новых моделей которые считают эти вектора потому что раньше это нужен было протаскивать в runtime гораздо сильнее следить за надежностью того как эта вся конструкция работает в смысле вот когда люди именно внедряют ее а теперь в какой-то background процесс который ну не так страшно если он там упадет на несколько минут и мы не потеряли в качестве мы когда делали эту миграцию проводили apts ты убедились что в качестве не теряем в моменте но на как бы длинном горизонте мы конечно же выиграли потому что мы смогли куча новых моделей внедрить на этом все спасибо вопросы то есть раз в две недели вы пересматриваете потоки информации для моей мамочки мы нет система да ладно хорошо это не личный вопрос девчонки вот на втором ряду на пятом ряду можно дать микрофону пожалуйста и друзья из онлайна нажимайте кнопочку подключиться к эфиру и задавайте вопросы спикеру пожалуйста спасибо большое за доклад а вот у меня два вопроса первый как вы боролись с дедупликации не вернулся с повторениями документов или у вас бо дизайн так не может быть потому что киева илью и второе вот вы упомянули о bts ты как вот именно вот эту систему раз катить чтобы вот часть пользователей были там по старому начать по-новому пара первый вопрос не очень понял про какие дубликаты вот я просматриваю лента как обеспечить чтобы я не просматривал постоянно одно и то же да я понял спасибо за вопрос да для того чтобы дубликаты ну дубликаты действительно мы фильтруем у нас есть кай вылью сторож в котором лежат все события пользователя то есть мы вот когда пользователь с ленты взаимодействуют мы знаем том что он посмотрел на карточку записали события просмотра дальше в процессе рекомендации вот мы когда исккон индекса даст достаем вот эти там 10 тысяч документов мы берём их фильтруем то есть те которые пользователь уже видел мы выкидываем все дальше мы их не используем рекомендациях а по второму вопросу до ну вообще про тестирование можно целый отдельный доклад сделать как разбиваем пользователи и ну чего приходит запрос мы берем мальчишник пользователя считаем хэш вот он развивается на баке ты на на какое-то количество пакетов врубается новая система на какое-то там на 5 процентов одно на 5 процентов другое в общем как то так давай утром спасибо за доклад все понятно с лайками дизлайками активные действия тут легко посчитать история с досмотра my то есть вот вы считаете процентов q сколько пользователей досмотрел или как-то по-другому это учитывайте и собственно вторая часть вопроса когда вы перестраиваете вектор я могу только дизлайками показать что вот это мне не надо никогда показывать или просто про скроле вайлент у я тоже даю сигнал о том что нафиг-нафиг первый вопрос про что про досмотр досмотр и пластик лайки джeйкoб единица минус единица а вот досмотр и они как-то да но я сказал что можно много таких разных векторных пространств построить и на самом деле можно много матриц таких собрать то есть вот на этом примере было лайк-дизлайк а на самом деле мы можем придумать там длинный просмотр и и вообще не просмотр или короткий просмотр или просто показ и кликнут эй показ или просто показ и длинный досмотр ну досмотр считаются на клиенте да то есть мы можем там примерно посчитать сколько времени пользователь посмотрел а тогда конечно все эти разные сигналы они учитываются многом можно много таких разных матриц собрать в которых разные вот эти вот паттерны и пользовательского взаимодействия учесть и не только дизлайки влияют влияет еще куча разных других каких-то поведенческих паттернов дмитрий здравствуйте спасибо за доклад а вот вопрос такой вы показали в начале что у вас есть блендер пищу кажется что это очень важный компонент системы не расскажите пару слов вот как он у вас работает или может быть ссылочку на доклад мне кажется про него мы еще не рассказывали до но это довольно действительно важный компонент системы ну там суть в том что во первых нам нужно для пользователя понять что ему больше нравится опять же да по смысле понять какой формат ему больше нравится опять же по каким-то поведенческим его сигналом которым можем вычислить ну там например больше всего времени проводил видео или там видео всегда дизлайка этой ману не нравится то есть вот такая штука в блендере есть которая то есть он как бы примерно подсчитывает пропорции в которых ему нужно разные форматы пользователю отдать дальше сэмплер uid из них вот расстановку карточек а потом берет вот эти вот пачки карточек которые каждый из река менеджеров отдал и их вместе с мир живут по скором релевантности которые они предсказали есть отдельные как бы тоже там тема про то как сделать так чтобы вот эти разные модели разные капусты которые из каждого река менеджера у нас предсказывают вероятность вылез калиброван этой чтоб мы могли вообще эти числа сравнивать ну и дальше вот он их пири-пири упорядочивает и вставляет на в вот в итоговый в этот набор карточек нутка я очень кратко если то так перемешать но не взбалтывать типа того дмитрий большое спасибо за супер доклад скажите с точки зрения нагрузки что больше сжигает процессор исполнение моделей или подготов к данных для этих моделей спасибо ну скажем так на за исполнением моделей который происходит в ран тайме мы конечно следим гораздо более пристально то есть сюда идут все усилия там на оптимизацию ну и собственно поэтому мы вот выносим все что можем куда-то менее требует требовательные палатам все места подготовка данных я думаю суммарно больше ресурсов занимает вся подготовка данных а наработанным определюсь а у нас ну мне кажется тоже индекс сделал про этот доклад есть свои кластером определился уайти называется система ну там я думаю что больше суммарно если посчитать вот все це пау время которое тратится на подготовку данных это будет больше чем то что в runtime и используется дмитрий здравствуйте спасибо доклад можете пожалуйста немножко рассказать про то каким образом вычисляется что документ должен присутствовать рекомендациях ну что он актуально неделю там или коды и каким образом они вытесняются оттуда да спасибо но это тоже огромная тема разными способами то есть как у куча разных сигналов есть про это есть например какие новостные сайты и у них как бы там таким редактор ским видением ограничено время жизни есть классификаторы которые обучены тоже на ну вот есть например яндекс толока до которая позволяет кроутер сам размечать какие-то задания и часть документов она они различаются в толоке потом там из разных вот этих вот людей которые ставят оценки как-то агрегируется общая оценка запускается на получается такой datasette на этом дата с этим можно обучить классификатор и классифицировать документ сколько будет жить то есть ну текстовый классификатор который на вход получает текст на выходе предсказывает там либо время жизни либо то что документам актуальна на один день ну и и тут как бы простая интуиции есть если в документе есть как как какие-нибудь фразы типа сегодня там 1 апреля произошло вот это вот это вот можно как бы с помощью амелия вычленить и моделька на это научиться есть еще другой подход это смотреть на то как пользователи в интернете вообще заходят на этот документ то есть например есть вот какой то на 8 документ на него пользователи вот сегодня заходят и трафик вот так вот растет на него а потом он падает потому что все он перестал быть интересен пользователям которые вот в интернете просто на него приходят и наверное да все этот документ потерял актуально всего можно выкидывать в общем какие-то такие простые пару простых подходов вот я так описал вообще тоже большая тема доброго вопрос в принципе следующие и да еще раз привет сейчас есть во первых блокираторы всякой рекламы которые затрудняют сбор пользователей аналитики которые при этом часто моду тлеют шумовые данные есть накрутка но есть такой то есть когда сидела мама посидел ребенок и соответственно собрались 2 разной модели поведения как вы работаете таких ситуациях то есть фильтруете как-то пытаетесь даже если пользе зашел с одним логином разделять что есть ситуации когда может два человека под одним логином сидеть и так далее когда знаешь почему он спрашивает потому что это наш коллега из озона из одного и того же значит устройство у них заходит сначала ребенок попытки заказал потом жена зашла заказала носки для мужчин потом уж зашел такой так блин отвертку себе заказал и они в итоге то к кому мне что рекомендовать и все они пьют один какао 2 кофе 3 молоко и тоже твоя очень жалобы постоянно приходят да вот что там не тот странный архозавров больше для мамы которая пользуется ценам нет но конечно если человек залогинен и выдает свой ноутбук или телефон другому человеку то мы не умеем разделять за одним логином разных пользователей там был еще вопрос про то что бывает накрутки накрутки мы вычисляем да то есть есть команданте фродо которая всякие разные паттерны выявляет по этим накрутка чтобы их полностью удалять из вот именно обучение моделек доброе утро спасибо за доклад вот смотрите какой вопрос как в ранжировании ваших карточек участвуют проплаченные статьи но те которые рекламные не секрет что как бы индекс это продвигая да то есть и вот в алгоритме ранжирование какую роль они играют то есть рекламодатели за это еще и заплатили эти карточки они отделены полностью от вот этого ранжирования то есть есть органическое ранжирование это про релевантность для пользователя среди вот всего контента который но как бы не рекламный а есть отдельно до отдельно рекомендую который занимается этими рекламными карточками которые встают на какие-то позиции в ленте ну да действительно в ленте есть реклама есть реклама которая от рекламной сети яндекса и раз я а есть вот эти вот карточки как проплаченные но они вместе с ней конкурируют с рекламой которые вот обычная яндекс и этот ну вы понимаете да что это стало частью нашей жизни то есть вот представим что я дзэн и у меня есть список партнеров которые я должен значит продвигать во время в ленте конференции и сейчас тут пока тиму стоит здесь я должен вам напомнить про генерального нашего партнера и про золотого спонсора клауд mail.ru solution вот если вы хотите в облаках строить нормальную систему вы идете mail.ru вот и офигенно выглядит пожалуйста доброе утро спасибо за доклад вопрос такой как вы заполняете пропуске в матрице если можете поделиться там где нет никаких оценок и как решаете проблемы холодным стартом для новых документов о новых пользователей которым нет никого фидбэк ну фишка в матрице в том что она разряжена в ней есть пропуске и как раз за счет этого разложения мы можем эти пропуски потом заполнять по второму вопрос сейчас второй вопрос какой второй вопрос по холодному старого холодному старту тоже очень большая тема про холодный старт для документов холодный старт мы для документов мы делаем такую штуку мы научились по тексту предсказывать вот этот вектор который внутри этой матрицы из-за из разложения матрицы получается то есть мы собрали такую нейро сеточку который на вход получает текст а на выходе дает вектор который вот из этого же векторного пространства это для для документов для пользователей все сложнее потому что тут нужны как бы продуктовые решения потому что вот так просто пользователь пришел про него ничего не знаем мы ему дали что популярная самая или что-то случайное ну типа это не работает тут нужно какие то делать ну вот мы сейчас разрабатываем новый такой подход к холодному старту отбираем тематике отбираем контент для этих тематик и будем пользователю показывать разные набор тематик чтобы он мог вот как-то влиться в систему подсказать ей что ему интересно вот исходя из этого то есть увеличивайте с порочным таким образом чтобы все не слопал искать этого максимум до для новых ну типа для новых пользователей вообще есть только exploration и мы вообще про пользователь ничего не знаем мы им показываем вот что-то что может нам помочь потом ему сделать exploration да и что-то похожее на это уже показывать но вообще говоря проблемой exploration а она актуальна и для существующих пользователей то есть что пользователь не сидел в этом пузыре ему тоже нужно иногда подкидывать там что-то новые какие-то другие тематики которые он пока что еще не раз кликал типа условно не раз кликал который пока ему еще не рекомендуется но над этим тоже работа ведется диму спасибо закончим вот этим вопросом нас нашу сессию здесь тебе надо подумать какой из вопросов был самым ценным чтобы подарить книжку и ты как человек из индекса ты много- процессный поэтому мы один процесс запустили вот второй пожалуйста здрасьте меня зовут максим я хочу спросить учитываете ли вы как-то тональность постов но при ранжировании и второй вопрос немного такой заковырка и раз вы можете детектировать накрутки то наверно вас есть системой и ручного вмешательства например можете ли вы понять какие-то темы как банят их twitter например так но это не про выбор да ты спрашиваешь мы не можем не но конечно слушайте ну во всех там соц сет очках их рядах да даже на ю тубе там конечно есть модерация которая ну условно там порно нельзя на ю тубе показывает в рекомендациях ну кыш такой есть да так а первый вопрос какой был про тональность про то что алиса да я б на миг взрослом а с детьми нормально разговаривать нет сейчас мне кажется мы тональность только в комментариях учитываем в ранжировании в ленте нет не учитывал но там есть разные другие категории типа не вот прям тональность но ну типа условно опять же там порно нельзя в ленте показывать короче это примерно вот есть какие-то серые зоны в которых да как-то алгоритмы и ну короче они учитываются ответ без заковырка тебе короче друзья давайте возьмем вопрос из с просторов в мирового интернета юзер 58 37 привет как тебя зовут и задавай вопрос схему включить где у вас общая структура рекомендательная система так илья слайд правда не вижу очень попробую по памяти у вас там был капусту казан я так понимаю нас пользуюсь правильно я понял алла а мне слышно алого прокат boost вопрос вашего повторить пожалуйста да получается или в ранжировании вы его применяете я не понял да можно еще раз маш громко пожалуйста еще раз сказать да скажете по поводу кампус то вы его используете для ранжирования или для блендеров разбираете мы его используем для ранжирования вот тут вот на этой схеме да ему на вход подаются ну как бы признаки пары вот user документ ну вот тут для простоты в этом докладе я говорю shit просто косинуса там может быть ещё куча разных других каких-то признаков жирование вместе с малым или от от обучаем о его отдельно для того чтобы его обучить тоже не так просто потому что ну типа для того чтобы обучить нужно datasette собрать datasette в котором у нас есть реакция пользователя на то что мы ему показали и вот эти вот все значения признаков в значение косинуса которые в данный момент были и для того чтобы отдаться от собирать мы все вот что мы на вход как boost подаем мы планируем ран тайме история взаимодей ну вот все взаимодействия пользователя с документами они тоже лаги руются потом это все нам определюсь и радиусе ца и получается datasette в как по сути такаяма . в которой есть строчки с этими косинусами и ответ как бы который нужно предсказать который из лога событий получается на этом обучается котбус что как понимаем когда надо берем котбус ты ли л.с. котбус мы понимаю ну как эмпирически понимаем типа вот месяц уже работает наверно надо переобучить давайте перри обучим запустили в б/у и выросли метрики в окей надо переобучать почаще специально они как а по расписанию да-да-да ну типа по расписанию да ну то есть переобучение л.с. а вот который раз две недели перри обучаются но вместе с ним короче они нужно переобучать как boost котбус можно переобучать как-то синхронно отдельно тоже по своему расписанию спасибо большое круто спасибо тебе ты создал историю на питерском хайло де то что москве мы подключали а вот во всяком случае в гриффиндоре это первое подключение дима но и тебе тоже спасибо за то что оставил 15 минут на вопросы не многим это удается все хотят говорить говорили да теперь кому отдаем книжку за лучше вопрос ну давай за вопрос заковырка отлично то есть просто вот по ключевому слову да ведь о себя как директные слайд вот отлично супер тебе тоже будут памятные призы спасибо благодарим спикера друзья спасибо сейчас спикер отправляется в цифровые кулуары"
}