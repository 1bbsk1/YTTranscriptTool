{
  "video_id": "0aWSea98rpc",
  "channel": "HighLoadChannel",
  "title": "Внутреннее облако в Яндексе — от прототипа до платформы / Дмитрий Липин (Yandex Infrastructure)",
  "views": 475,
  "duration": 2908,
  "published": "2024-04-17T01:10:23-07:00",
  "text": "друзья мы до танцевали С вами до финального доклада первого дня дальше только автопати видеть себя хорошо потому что завтра в 10 мы встречаемся здесь в 10 голова должна работать наш финальный спикер уже здесь уже на месте Еще один пирожочек горячий из Яндекса Давайте Пошумим Пошумим Пошумим Поднимите руки кто соскучился по теме и пришел просто гости да фанаты здесь 40 минут чистого кайфа погнали Ну что ж Спасибо большое что пришли Рад вас видеть рад что вам интересно внутренне облака история их появления и сегодня как раз об этом и пойдет речь я расскажу о том как появилась внутреннее облако в Яндексе посмотрим на его историю через призму жизненного цикла продукта и соответственно расскажу как продуктовый подход спас нас от того чтобы часть чтобы стать частью истории поехали но Начну с того что представлюсь зовут Меня Дмитрий Липин Работая в Яндексе уже девятый по-моему год начинал я разработчикам писал на питоне плюсах разрабатывал системы мониторинга скелевых до 10 миллиардов метрик обрабатываемых в параллельно а со временем переключился на ледовую роль и сейчас выполняю отвечаю за разработку в команде platform-инжиниринг суть наша в том чтобы предоставлять разработчикам самого Яндекса то есть тем ребятам которые делают бизнесы Яндекса инструменты для разработки чтобы ребятам было где писать код и куда этот код диплоить и делать это эффективно и собственно одном из этих инструментов сегодня пойдет речь а именно о внутреннем облаке а внутренние облака появились как необходимость вот эти замечательные сервера которые вы можете видеть на фото так или иначе эффективно утилизировать с одной стороны особенно если их десятки тысяч а с другой стороны дать пользователям удобную эффективную и понятную абстракцию диплоя в конце концов Нужно же каким-то образом тем разработчикам о которых я говорил как-то запускать и где-то запускать свой код собственно миссия внутреннего Облака в этом состоит дать удобный понятный и приятный инструмент диплоид а Посмотрим мы на историю внутреннего облака через концепцию жизненного цикла продукта Кстати кто с этой концепцией знаком Поднимите руки отлично лес рук в кавычках чуть-чуть напомню тогда суть концепции Она кстати далеко не новая появилась она где-то в 1965 году или даже раньше можете поискать статьи в интернете суть концепции примерно в следующем есть несколько этапов каждый этап имеет свои характеристики чтобы понять Где мы сейчас находимся и собственно свои вызовы зная которые можно более эффективно развивать продукт начнем с этапа развития Этап развития характеризуется тем что на нем довольно много в нём довольно много хаоса то есть непонятно в точности каким будет продукт кем этот продукт делать как его разрабатывать какими силами воспримет ли позитивный рынок этот продукт или нет И собственно Что нужно делать в этом случае нужно двигаться итеративно потому что мы не знаем многого и двигаясь оперативно Мы потихоньку снижаем рынки риски риски простите и соответственно получаем какие-то новые знания и до этого мы перенесемся и чтобы посмотреть Каким было внутреннее Облако на этом этапе мы перенесемся чуть в прошлое и на момент конечно большого взрыва Зачем так далеко а 2017 год Почему 2017 год Потому что именно тогда мы поняли что существующие в Яндексе системы диплоин А мы начинаем не С чистого листа справедливости ради оставлю возможность коллегам поделиться приквелом так сказать именно в этот момент мы поняли что существующие системы диплоин попросту не выполняет свои роли делают свою работу плохо пользователи недовольны сервера которые эти системы диплоид утилизируют утилизируются плохо и нужно соответственно пересмотреть то как мы подходим к задаче диплоя Давайте чуть-чуть поделюсь контекстом можете видеть те системы диплоид с которыми сталкивался разработчик в то время в 2017 году слева видно виден кулауд киллаут Эта система deploy для простых сервисов в нем можно было удобно просто в пару кликов на самом деле запустить сервис получить логирование получить мониторинги получить простую балансировку все это по клику Но если вам необходимо было запустить какое-нибудь сложный сервис тут начинались драконы потому что не дай Бог вам придется какой-нибудь стейт клауди засовывать Добро пожаловать команде с просьбой прибить эти подает этого сервисам и получить кучу проблем в эксплуатации с другой стороны на Золотой середины как его уже догадываетесь не было есть няня это такой конструктор в том плане что он специально разрабатывался для сервисов сложных сложных состоящих из тысяч поводов имеющих какой-то сложную логику диплои Поэтому с масштабом никаких проблем не было Но поскольку эта конструктор то если вы хотите логов настраивайте сами Если вы хотите мониторингов тоже настраивайте сами Если хотите балансировку настраивайте сами Ну вы поняли и получается что золотой середины у нас нету И я помню Кстати когда мы завозили те самые системы мониторинга которые разрабатывал в итоге мы допросились выделенного SE чтобы самим не кликать кнопочки потому что чтобы выделить ресурсы тут мы переходим к Ген цг нужно было коммитить репозитории А это довольно-таки болезненная операция хочешь добавить в поход к сервису Будь добр делать коммит репозитории и конечно же оставить в таком виде это было невозможно поэтому начали мы с того что посадили команды Лауда И ныне рядом и попросили придумать какое-то решение первым этапом была так называемая платформа по факту единый интерфейс надо но этот это решение имело как технические проблемы потому что все равно под капотом Оставались две системы диплои так и организационные проблемы а делали мы все это ради того потому что в это время в Яндексе разработчики по факту начали не только заниматься написанием кода но еще и начали отвечать за об своих сервисов в том плане что перестали существовать выделенные администраторы чем соответственно больше времени Меньше времени уходят на Общая часть тем больше времени разработчик может заниматься холдингом В общем помучились мы квартал над этим решением и по факту ни к чему не пришли А кроме того мы поняли что если посадить две команды которые имеют диаметрально противоположные взгляды друг на то как делать свои продукты Мы скорее всего получим конфликт и я помню что одного из коллеги даже был топ-3 людей которые навредили инфраструктуре коллегам смежные поэтому треку до сих пор в этом списке находятся возможно списки взаимные по факту поэтому мы подумали квартал и решили что нужно вернуться к нашему излюбленному решению а именно сделать ещё одну систему которую уж точно решит все проблемы которые перечислил и этой системы стал Яндекс Drag мы умеем в нейминг поэтому со временем переименовали яндекс.драг яндекс.диплой не за слишком агрессивного названия и Давайте попробуем подытожить к чему Мы Собственно как мы видели будущее системы тепла в 2017 году ныне и Клауд по факту закрывается в пользу Яндекс диплоя все пользователи должны будут переехать в новую систему gent cfg который был планировщиком работающим по комету репозиторий должен со временем перестать существовать в пользу Яндекс планера Яндекс планера это система которая под капотом Яндекс диплоид занимается как раз планированием кодов и предоставляет сторож которая хранит все объекты Яндекс диплоин сам Яндекс должны со временем заехать все все сервера в Яндексе И тем самым достичь более эффективной их утилизации Так что мы примерно сформировали видение нашего будущего Пора начинать стройку Но для перед этим чуть-чуть теории Я думаю вы знакомым с одним из его законов которые гласит следующее команды проектируют те системы которые повторяют структуру коммуникации в организации и например хорошо видно система получились довольно монолитными и чтобы этого не допустить и собственно найти ресурсы настройку Мы решили начать собрать Витим Витим который бы состоял из команд имеющих весь необходимый набор экспертизы для того чтобы построить такой сложную систему как новое внутреннее облако или яндекс дисплей Но в эту точнее в этот Витим вошли довольно разные команды сам Яндекс планер делали ребята и зайти за уруса Кому как не ребятам из мапрыгинса делать соответственно планировщик и базу данных Тем более что ребята Называйте зауруса необходимо было заезжать в внутреннее облако как раз для повышения его утилизации когда они пришли посмотрели на то что из себя представляет внутреннее облако ребята решили нам помочь потому что внутреннее Облако которое было в 2017 году они Заехать по факту бы не смогли соответственно другие Кроме того Витим вошли команды Нэнни и кулауда важно было чтобы ребята не разбежались и они помогали нам делать Собственно сам Яндекс диплоид его интерфейс контроллеры которые взаимодействует с пользовательской спектейкой и соответственно агент который диплоид который разворачивает поды на нодах а ребятам было тяжелее всего потому что по факту именно их продукты закапываются в пользу новой системы диплоир и Кроме этого к витиму присоединились ребята из поискового портала который тоже не могли въехать на или нормально жить своими сервисами в системе диплоин и были по факту нашими первыми или адаптерами и одной из проблем витима является как раз коммуникация для того чтобы помочь ребятам начать взаимодействовать мы собрали несколько страстей так или иначе вы могли ребятам сломать лёд А чтобы не повторить ошибки кулауда и ныне выбрали человека который в случае проблем и в случае невозможности принять какое-то решение помог бы это решение принять и соответственно решили что нужно двигаться и тратимно итеративно в том плане что не начать решили не начинать сразу делать Яндекс дисплей А Начать интеграции ныне и Яндекс планера и собственно сначала яндекс.планер нужно было сделать так вооружившись командой планами на будущее мы отправились сделать звездолёт Так что давайте двигаться дальше переходим в 2018 год посмотрим на наш инкремент и так мы видим наших пользователей после того как у нас появилась ныне и интеграция ныне с Яндекс планером в принципе те сервисы которые так или иначе страдали от выделения ресурсов сами поехали без необходимости как-то призывать с нашей стороны на новую функционал Потому что если раньше тебе нужно было коммитить репозитории теперь можно было пойти и в интерфейсе на кликать всё необходимое но когда мы пришли ровно с тем же Давайте попробуем новую интеграцию пользователям клауда понятное дело пользователя кулауда ответили Где наш простой интерфейс Где логика из коробки где балансировка ничего этого ныне по-прежнему не было и тогда мы решили что необходимо перенаправить все наши силы на Яндекс типовой как планировали раньше и мы фокусируемся как раз на его разработке теперь мы переходим к следующему этапу к этапу роста его характерные черты состоят в том что аудитория начинает расти резкий рост аудитории потому что пользователь уже попробовали продукт начинают активно на него заезжать конечно каких-то вещей все еще не хватает Но мы же активно работаем над тем чтобы дефици появились но резкий рост аудитории продукта это конечно же и резкий рост нагрузки на систему а резкий рост нагрузки всегда ведет к пожарам так или иначе хорошо что внутренние сервисы имеют довольно лояльную аудитория которая так или иначе готова этим смириться если инциденты чинятся максимально быстро и системно а мы свою очередь переходим к 2019 году и посмотрим опять же что случилось за это время за это время мы довели интеграцию ныне и Яндекс планер до того состояния когда готовы перевозить всех пользователей на Яндекс планер не по факту мы начинаем очередной виток миграции и Кроме этого запустили Яндекс диплоит точнее доработали Яндекс диплоида того состояния когда он готов принять первых пользователей А это собственно наши пользователи которые узнали о том что пора в очередной раз переезжать Помню был такой сервис Web который в принципе даже был готов переехать поскольку у него болело выделение ресурсов но как и для команды Нэнни как и для самого сервиса переезд был максимально болезненные вещи просто потому что сервис был достаточно большой поднять две копии этого сервиса было тяжело приходилось сколоцировать коды которые подняты в Яндекс планере и в конце и плавненько переключает нагрузку А собственно все такие процедуры так или иначе ведут пожарам про которые сейчас и расскажу как-то раз мы решили все-таки отдать тот тег долг который создавали в рамках резкого роста И для этого надо было унифицировать конфигурацию хостов между няней и диплоин точнее и кулаудом Простите Это был совершенно рутинная операция нужно всего лишь было переконфигурировать с агенты которые поднимал ноды точнее поданох и ничего не предвещало беды но коллега который делает ошибся ошибся вышиванках то есть то куда нужно было катить Комет и вместо хостов клауда выкатил новый комит с агента на весь дата центр за 5 минут стартовав на всем дата в центре увидела что новый контек указывает на пустой стоит то есть на директорию где лежал список кодов по факту и поднявшись и подумал что подаст на хостах быть не должно по факту все данные в этом дата-центре удалил где там минут за 5 он справился с этой задачей Вполне себе эффективный софт и это дата-центр конечно же закрыли очень хорошо что пользователи внешний то есть не наши пользователи не пользователи внутреннего облака пользователи Яндекса ничего не заметили потому что Яндекс регулярно практикует ученьки то есть такой набор мероприятий который заставляет сервисы рассчитывать на отказ от одного до центра это конечно все хорошо но Вот наши пользователи то есть разработчики самого Яндекса Они конечно этому не обрадовались потому что хоть мы их точнее клиента ничего не заметили разрабатывать времени у них теперь не было нужно было идти срочно чинить до центра э-э состоит из сервисами в принципе восстановиться было довольно-таки легко Нужно было лишь подождать пока данные на целый дата центр скачаются а целый этот центр - это 1.000 машин которые в принципе не то чтобы рассчитаны на сценарий поднятие с нуля обычно сервисов является итеративные А тут надо было принести все ресурсы поэтому упирались во все возможные проблемы скорости жёстких дисков хуже было ребятам которые имеют сервисы Потому что им необходимо было откуда-то эти данные скопировать это не всегда было возможно в итоге через сутки примерно мучений дата-центр мы все-таки открыли но После этого мы сильно поменяли наше приоритеты потому что надежность это по факту при реквизит хорошего продукта А про это мы несколько забыли если посмотреть на эту ситуацию и Давайте попробуем подытожить Какие уроки Мы из этого вынесли во-первых для того чтобы системно решать проблемы с надежностью в нашем случае пришлось на самом деле жить организационные проблемы ведь та команда которая хотела коммит на дата-центр по факту страдала из-за нехватки ресурсов и у ребят не было времени то чтобы системно решать проблемы с надёжностью не было слишком много разных компонентов за которые нужно было отвечать и местами не хватало экспертиза чтобы делать Это довольно хорошо и без этого на самом деле все остальные меры вроде Понятно Практик вроде выстраивания Хмм инцидентов никакого толка в принципе не было То есть это инцидент был далеко не первым в серии после того как мы переформатировали эту команду мы на самом деле практически полечили проблемы с надёжностью особенно в видеорегулярный разбор инцидентов выполнение экшн-айта и к эта проблема после этого в принципе возвращались довольно-таки редко А Давайте пойдем дальше пойдем к двадцатому году посмотрим на то что случилось в это время Яндекс диплой до рост до состояния когда он был готов принять в принципе всю нагрузку всех пользователей в Яндексе и мы Соответственно объявляем что парамигрировать и пора всем пользователям из кулауда переехать в диплоид вы бы видели вспоминаем картинку с Томом хэнксом сколько это негатива создала потому что зачем людям переезжать сильно нового они не получают а президент потратить кучу сил тем не менее мы вы наняли выделенного менеджера который обходился команды эскалировал случай чего создали немного много негатива но считали что это было необходимо И через некоторое время буквально через несколько месяцев А мы принципе хотели сделать ровно то же самое с пользователями ныне но посмотрев на реакцию кулаудой учитывая то что пользователи нэне было несколько раз больше решили что это не самая умное что мы можем сделать в принципе поэтому мы решили изменить нашу стратегию и отказаться от идеи того что Яндекс диплоид станет единой системой для всего Яндекса и перевели ныне а мы переходим к следующей фазе к фазе поддержки взросления в этой фазе мы достигаем насыщения рынка то есть по факту новых клиентов уже неоткуда взять рост системы приостанавливается в нашем случае это означает что либо все кто мог уже заехали в систему либо уже прямо сейчас заезжают и по факту мы сталкиваемся с новым вопросом на которые нужно ответить А что делать дальше а смысл своей очереди движемся в двадцать первый год Давайте попробуем чуть рассказать какой был контекст в этом году мы имели по факту три системы диплоин ныне диплой и киллаут который закрывается пользователю нужно было выбирать куда ехать Несмотря на то что мы рекомендовали теплой стандартном стандартной системой на которой нужно заезжать по умолчанию по факту фьючерпарити между ними не было и нужно было Для каждого сервиса принимать решение Подойдет ли тебе эта система диплоя или нет Мы кстати даже посчитали на самом деле Сколько стоит миграция всех пользователей из ныне в диплой и она и оценка получилась около сотни человек лет что в принципе громадные числа OK раз мы не можем победить Мы решили возглавить это движение и вместо того чтобы заставлять пользователей ныне переезжать в теплой решили подойти более техническим путём к этой проблеме и сделать так что само переезда не потребуется или потребуется набор гораздо более лайтовых миграций а достигли мы этого за счёт того что кишки ныне по факту переносятся на Яндекс дисплей то что под капотом мы переделываем и реализуем поверхность тепло и Яндекс планера То есть можно сравнить на самом деле ныне и теплой как просто sdk поверх общих компонентов а мы свою очередь сможем перспективе не тратить двоих с усилий на поддержку двух систем deploy оставив ныне тонкой оберткой поверх Яндекс диплоя правда справедливости ради после этого пользователя не стали нам верить больше И до сих пор на самом деле спрашивает о ныне как таковая будет закопана или нет И кроме технических долгов на самом деле нужно разобраться из организационным долгом потому что Витим который помог нам начать движение в самом начале без него принципе не справились стал на самом деле обузой потому что для того чтобы делать какие-то рутинные вещи нужно было ходить договариваться С командами у которых уже изменились приоритеты и не то чтобы это было удобно поэтому со временем те компоненты которые мы разрабатывали в разных кусочках компании собрали под одним крылом для того чтобы не тратить время на коммуникацию Окей мы примерно понимаем Как нам высвободить ресурсы из состояния в стратегию собственно В чем заключается стратегия ведь мы так и не ответили на вопрос что делать дальше А как смысле ответить на этот вопрос Давайте спросим пользователей Все ли у них есть для того чтобы эффективно выполнять свою работу помните миссия внутреннего облака с которой начинал и ответов внезапно будет негативный отрицательный потому что сервис пользователя это далеко не только развернуто в Облаке приложения это в том числе и возможность описать этот сервис кодом Это несколько контуров которые нужно поддерживать этой кафе Степаненко то есть гораздо больше чем просто запущенная в Облаке приложения и таким образом на свет появляется инфрактерий инфрак отель это как раз более упрощенный более простая абстракция которая позволяет за счет того что лишает пользователя гибкости многие вещи делать за пользователя предоставить ему например заранее сгенерированные возможности как раз те самые описывать в ходе и так далее так собственно появился наш сервис по кнопке А мы в свою очередь движемся 22 год в котором инфрак отель как раз запустился в продакшн и на нем привезли первого пользователя Но в отличие от Яндекс диплоя он оказался несколько другом ландшафте потому что если у диплоид в принципе все конкуренты скажем так были под нашим видением то теперь нам приходилось приходится уже конфигурировать Точнее конкурировать с решениями других бизнес-юнитов в Яндексе то есть других команд Яндексе это такое может быть а проблема в том что пользователь реально не хватало этого функционала и многие уже успели поверх внутреннего облака напилить какие-то свои решения свои автоматизацию которая как раз начала перетягивать пользователей с внутреннего Облака на себя и теперь нам нужно соответственно думать как существовать с этими решениями и как не создать очередную миграцию которая потратит кучу си л компании в никуда а мы в свою очередь переходим к последнему этапу фазе отказались на себя Мы ещё не попробовали суть этой фазы в том что аудитория падает конкуренты захватывают рынок ну и соответственно опускается занавес А Мы остановимся частью истории благодаря как раз инфрактерию мы эту фазу на себя не попробовали надеемся что останемся в фазе взросления давайте я чуть расскажу про то к чему Мы пришли 23 году до третьем году мы как раз оказались ситуации когда большая часть сервисов на самом деле переехала в Яндекс диплом или вне Клауд выключен практически Вы можете на картинке как раз видите раз финал скриншотов и ими буду заканчивать то как выглядит диплоид мы постарались в Яндекс диплом соединить мощь Лао точнее ныне и удобство клауда и в принципе по вопросам пользователям видим что они готовы скорее рекомендовать тепло и своим друзьям и Давайте посмотрим помог ли нам канвеи сделать архитектуру более модной чем она была в начале поэтому чуть-чуть расскажу про то как дисплей устроен Яндекс диплоид позволяет описать спецификацию сервиса декларативно и соответственно пользователь указывает Какое приложение ему нужно поднять каких кластерах каждый кластер в свою очередь представляет себе инсталляцию Яндекс планера Яндекс планер это с одной стороны интерфейс над базы данных в лице Дин таблицу войти за ауруса а с другой стороны это планировщик который планирует и раскидывает под нодам анодагент или Агент про который как раз и рассказывал во время нашего крупнейшего пожара смотрит в Яндекс планер и поднимает коды на реальных серверах пользователь в свою очередь волен использовать тот слой абстракции который лучше подходит для его задачи То есть если сервис сложный можно пойти напрямую Яндекс планер минуя диплоид и создавать под самостоятельно и Давайте чуть-чуть поделюсь цифрами для понимания нашего масштаба это один из главных ответов Зачем в принципе мы все это делаем у нас около нескольких тысяч пользователей которые ежедневно нажимают кнопочки более чем на 100 тысяч серверах около 5 миллионов ядер ежедневно случается около 100 тысяч изменений спецификациях этих сервисов которые создали пользователи и мы умеем на самом деле не только в сепишную нагрузку но и в gpuшную то есть один из крупнейших кластеров в мире суперкомпьютер в мире червоненткинс до сих пор находится в топ-30 крупнейших кластеров по версии топ-500 и Давайте подытожим куда мы пришли за 6 лет на самом деле нашего движения мы всех пользователей клауда мигрировали в ныне или диплоид да Яндекс диплоид не стал тем сервисом точнее тем облаком в которые съехались бы все поскольку это было бы слишком дорого но по крайней мере большая часть пользователей внутреннего облака с мигрирована Яндекс планер Так что задача утилизации в каком-то виде Мы решили Мы также поняли что единая абстракция которая должна подойти всем на самом деле такое не является простым сервисом нужно что-то более высокоуровневое а именно инфрак-отель которая позволит лучше автоматизировать их работу Хоть и за счет какого-то ограничения в возможностях этого сервиса Так что продуктовый подход помог нам избежать фазы отказа А что такое продуктовый подход Давайте можно про это конечно долго достаточно говорить но суть достаточно простая продуктовый подход в первую очередь означает то что нужно ставить себя на место пользователя думать про его проблемы ему совершенно все равно Насколько крупный сервис можно запустить в вашем облаке или если у вас гэпоушный кластер важно что вместе с внутренним облаком он может решать свою задачу более эффективно то есть проще удобнее с меньшим отвлечением диплоид своей сервисы Так что Будьте прагматичные вместо того чтобы строить думаете как помочь вашему пользователю Давайте закругляться и соответственно подытожим то что мы сегодня обсудили во-первых подведем так сказать итоги во-первых Если вы начинаете делать какой-то продукт помните что на первом этапе будет много коммуникаций много споров Но именно за счет них можно нащупать правильный курс правильный Вектор движения Если вы его нащупаете то роста аудитории Особенно для внутренних сервисов вам обеспечен а внутренний сервис точнее А рост аудитории это всегда пожары Будьте готовы их тушить Но со временем Вы придёте к ситуации когда в очередной раз придётся задать себе вопрос что делать и именно продуктовый подход возможно Взглянуть на свой сервис через призму жизненного цикла продукта а позволит на этот вопрос получить ответ Так что помните про своих пользователей делать их счастливее И на самом деле не вступайте на те Грабли на которые наступили мы Спасибо большое пойдём к вопросам так отлично красиво бежит поехали Спасибо Дима Спасибо классный доклад я первый получил микрофон поэтому спрашиваю первый А как же cubernetics и второй вопрос я ожидал этого вопроса И второй вопрос в генцев.г ты сказал что нам не нравится так сказать что-то комедитесь чтобы у нас что-то заливалось а потом в 2022 году это достижение или там как по-другому комедием В чём разница Смотри когда я начну с губернатится проект на самом деле был слайд но я понял что если начинаете эту тему мы идём совершенно в другой степени а Поэтому если коротко то по бернете до сих пор не выдерживать эти объёмы которые есть у нас то есть не так давно на хаббре была статья от ребята из яндекс.планера и текущий ванильный губернете с выдерживает раз в шесть меньше нагрузки чем нужно нам не говорят что мы вкладывались многие многие годы в то чтобы адаптировать внутреннее облако под наши э нужды и представить себе Сколько времени мы потратили в миграцию Мы в смысле две системы диплоились а нам нужно соответственно к губернате чтобы перевести пользователей Но это хороший вопрос смысле поэтому можем про него поговорить чуть попозже более подробно расскажу детали А про агентств г смотри инфраструкцию за код подразумевает что всю спецификацию ты можешь положить в репозиторий и управлять сервисом в целом в данном случае ты управлял одной небольшой частью именно выделением ресурсов и было это сделано максимально больно то есть был планировщик который по факту работал поверх репозитория это в принципе сам по себе само по себе это нонсенс скажем так и ни один сложный сервис который хотел управлять гибко на такой конструкцию Конечно бы не заехал Потому что ты комиссия ждешь 20 минут в лучшем случае прорастание новой топологии и если что-то случилось не так Ты даже ошибки не получишь А потом конфигрюшь руками потом конфигуришь руками которые сварились где-то там В дебрях сидишь на части Спасибо большое за доклад продолжение вопроса про Купер он скорее всего маленький такой не думали про кластер Куба по кнопке и проблема наша в том что мы хотели получить кластер растянутый на весь дата-центр что пользователям было удобно как раз запускать свои сервисы как маленькие так и большие с одной стороны то есть надо Если у тебя сервис много больших сервисов как их уместить в много маленьких менеджеров губернатисов непонятно С одной стороны а с другой стороны мы хотели доедать эти ресурсы и в принципе это и делаем то есть рядом с этими менеджер кластерами запустить ещё им придётся которая бы доедал ресурсы и получается что надо было много менеджеров глубинетисов растянутых на поверх общего железного парка И это была бы ещё более сложная конструкция чем то что получилось у нас Да понятно А вот на самом деле он не столько технический Вопрос сколько скорее организационный То есть вы скажем есть предположим там ямы в файлик в котором можно описать всю структуру там Баски используемые кластера и тому подобное есть такой маленький нюанс как бы как сетевые доступы вот когда нужно сервису сходить куда-то вообще ну стороннюю кто ревьювит эти доступы как как вот сделано вообще не умеем Расставь Всё я захваты справедливость это да это отдельный вопрос отдельный доклад обязательно надо позвать ребята из иншак это Эля рассказать про то что у них есть сейчас а про доступы В смысле инфраструкции код так или иначе это надстройка на текущими системами текущая система отряды заказываешь дырки ты в каком-то плане спрашиваешь ованеров того макроса которым заказываешь доступ готовы ли они тебя дать доступ э вся эта механика под капотом остаётся и если соответственно дырки надо просить то к сожалению придётся зайти в интерфейс и фактор всё равно остаётся автоматики нету да надо делать так чтобы просто эти дырки просить не надо было это тоже можно Спасибо Дмитрий Спасибо за доклад только что слушал доклад ваших коллег про из Яндекс вертикалей про их пас Правильно ли я понимаю что вот вы тоже упоминали конкурента диплоид Вот как раз Шива это и есть конкурент с которым вам сейчас надо будет как-то жить да потому что мы по факту строили звездолёт немного забыли про проблемы пользователей и пользователи Ну в смысле у них сами кинулись спасательный круг Спасибо за доклад расскажите пожалуйста про менеджмент ресурсов вот допустим в том же теплое да у вас явно там ресурсы простаивают полезные какое-то время или вот как вы управляете ими конкурентный вопрос задать Прости не вижу тебя я вот здесь уже далеко далеко в конце концов Что именно под управлением ресурсов выполняют какие-то сервера правильно вы каждому проекту свою конфигурацию серверов Представьте Прости и Соответственно в этом центре есть много много серверов про которые знают планировщик пользователь заказывает коды определенной геометрии планировщик его задача на самом деле набить этот рюкзачок и соответственно ты можешь заказывать любые коды которые хочешь они могут не поместиться есть определенные гарантии на геометрию когда мы обращаем запланировать эти коды и когда соответственно гарантине получается какие-то отложенные ресурсы есть да то есть если сейчас мне не хватило выдаем квоты таким образом то есть Понятно У каждого потребителя есть некоторые квота в рамках которой он может лоцировать себе под если соответственно даем кого-то таким образом что у нас нет То есть тут квоту который пользуется получил она гарантирована может провоцировать ресурсы адекватного размера Да там есть какие-то но в том плане что прям стопроцентную набивку кластера мы не обещаем но где-то 95 процентов достижимо Ну то есть я заранее знаю какая у меня квотам спасибо спасибо за доклад у меня такой шкурный вопрос я как раз в семнадцатом году Яндекс пришел и все это прочувствовал на себе Вот интересно что там в двадцать четвертом ожидается Это в смысле в 24 ожидается смысле сингулярность технологической надеюсь И второй вопрос вот инфракрал я правильно понимаю сейчас это просто яму программирования в пользу кода там на том же питончике что-то сделать обычным императивным кодом объекты которые как раз лежат под капотом этот слой планируется да Спасибо передайте мужчине в желтом пожалуйста а Спасибо Алла еще раз здравствуйте Спасибо за доклад за доклад Вот вы говорите дата центр но я так понимаю что вы используете не один дата-центр хотя бы из принципа теоретивирования Что такое для автопати Вот вы говорите И как у вас происходит выбор ресурсов вот вашим планировщикам ресурсов выделение дата-центров пользователь явно указывать это центр который ему нужны явно запрашивает в них воду То есть мы это приложение на пользователя автоматического переезда там сама инфраструктура пользователя на другой это центр если все пока нет автопилоте от Microsoft Если не ошибаюсь меты точнее уже нет такого что мы за пользователей выбираем регионы в которых они запускают сейчас указывает коллеги соскучились по тебе вот стажёр из Яндекса пожалуйста вот Дима привет Спасибо за жизни доклад скажи я уже правильно понимаю что сам диплоид живет в диплои мусол в хостинг Да и Если да я надеюсь туда то на том таймлайне собственно где-то метка Когда вы как разработчик Когда разработчики диплои начали катать релиза диплои в диплои Ну и начинать на себе всю эту историю чувствовать ради кольцевые зависимости мы как раз губернатисом разрываем Я так понимаю есть ua есть там бэк То есть наверное они все части отдельно живут нам самим то есть какая-то часть диплоид катается диплом но в целом для того чтобы разорвать кольцевые зависимости мы используем губернатиз сейчас активно переезжаем в него мы вопрос скорее был про то что вот это говорил про какие-то секреты успеха Да как прийти Вот конкретно В вашем случае я так понимаю сильно не помог поскольку у вас было своё естественно то есть если не про сам если говорить в принципе про разработчиков внутреннего блока то мы конечно используем своей же системы но проблема в том что мы не лучше целевая аудитория нас нет необходимости запускать сотни сервисов одинаковых наши сервисы довольно ограниченного размера и мы получаем с такими выплатами если смотреть на нашу в этом Трабл и еще два вопроса пожалуйста вот да Привет Спасибо большое за доклад Вопрос такой снова три рюмки прошло Можно спросить про губернат снова в общем с учетом всех затраченных человеческих усилий на то чтобы написать систему пересадить разработчиков не рассматривали ли вы просто альтернативу взять ванильный cubernet заработать его под нужные компании за то чтобы он выдерживал эту нагрузку и также посадить разработчиков искать Все Вопрос решен навсегда Спасибо это классический вопрос опять же зависит от того какой год ты бы его задал этот вопрос Прости что ты сейчас я думаю мы к этому гораздо более готовы Чем были готовы в семнадцатом году но для понимания опять же на наших масштабах обычных в интернете не завёлся бы и в любом случае под капотом яндекс.планер бы остался губернасе как интерфейс Ну на самом деле тот самый инфрактерик который рассказывал тяжело использует в качестве свой BD cubernets для того чтобы не переизобретать человеку систему так что мы к этому стремимся просто несколько другими путями Ну то есть оно это будет некоторое композитная система где какой части мы делаем сами потому что наш сценарий Отлично от того что на что таргетс сам сами разработчики по берете никому не нужно на 100.000 серверов запускать свое собственное облако таких компаний в мире можно попасться пересчитать но понятно что успевать за фичами cubernetics которая разрабатывается сотнями разработчиков в мире мы конечно же не сможем и думаем про то как этот успех как этот опыт переиспользуется у себя вот используем кубернации и я думаю не только так что движемся в эту сторону просто это медленное довольно таки движение потому что прямо сейчас если дать губернатиз на самом деле никаких проблем именно бизнесовых мы не решим Спасибо ставь точку Да Дмитрий Спасибо два вопроса Первый оказалось ли эта история в тотале выгодный Яндекс диплоид и второй Могут ли команд разработки Яндекс использовать для Яндекс Клауд для своих и почему не используют Почему не используют потому что в любом случае переезд куда-либо особенно если уже в этой системе находишься это некоторый Кост я соответственно смотреть на задачу практично чтобы переехать нужно чтобы Кост Ну был меньше чем польза которая получит от переезда прямо сейчас это не так и наши интересы сделать так чтобы это так и оставалось потому что мы предлагаем если более специализированное решение чем куберетесь каком-то плане А если говорить про разработчиков на самом деле какая-то часть сервисов например из-за проблем компании могут ехать в яндекс-клауд это хорошо потому что мы какие-то вещи в силу того что целимся на весь Яндекс а не на конкретные команды можем не успевать делать поэтому выбираем практично а не на основе какой-то религии Дима Спасибо большое спасибо вам за вопросы давайте выберем Кому мы подарим замечательную книжку победители помнишь кому да первый вопрос потому что Про cubernetis это лучший вопрос который сегодня задавали Так что кто первый не произойдет пожалуйста ты герой потому что выступать когда в зал Все время заглядывают едой или с бутылками вообще помню свой первый опыт на самом деле выступления Я выступал где-то в 9:00 или 10 часов вечера в Минске Вот это было тяжело потому что после рабочего дня на какую-то аудиторию она естественно не такая большая классная как эта но надо было прийти вечером уже уставший э-э после всех докладов последним ещё что-то выступить Разумное рассказать А этот доклад гораздо менее технический чем тот что был в тот раз так что всё хорошо тебе тоже памятник И как только ты спустишься сцены обнимашки"
}