{
  "video_id": "y7SRGkZemw4",
  "channel": "HighLoadChannel",
  "title": "Построить Continuous Delivery в ML / Антон Якунин, Николай Фоминых (S7)",
  "views": 911,
  "duration": 2618,
  "published": "2020-04-14T11:20:42-07:00",
  "text": "м добрый день меня зовут антон и кунин я руководитель разработки в smm tech lab и мой коллега привет меня зовут николай фомин и я являюсь разработчиком вас avanti глав взаимодействую с пятью командами дата-сайентистов и мы хотим вам рассказать про confidence delivery машин верным для вот вам вернусь чуть чуть попозже чтобы рассказать как сделать жизнь проще а сейчас давайте послушаем пропан play еще раз добрый день сначала пару слов о компании чтобы вы понимали целом tech lab это эти компания которая обеспечивает инновации в холдинге мы разрабатываем продукты которые связаны с предикативной аналитикой всевозможных поломок детали и и так далее мы занимаемся различными рекомендательными системами кросс продажами также оптимизация my складских запасов расхода топлива и так далее всевозможный анализ текстов и блокчейн и всевозможные развлечения и сервисы на борту самолета как вы видите большинство из этих продуктов так или иначе связаны с машинным обучением сначала это была лишь какая-то аналитика но в течением времени все это привело к появлению продуктов что привело нас к тому что нам надо постоянно улучшаться и адаптироваться поэтому мы пришли к тому что хотим сейчас поделиться своей истории о том как мы внедряли практике continuous delivery из мира разработки в машинное обучение кстати говоря а кто из вас считает себя дата-сайентистов нет таких до кто так или иначе инженер в любой отлично ну да больше для вас доклад вообще как изменился сам рабочий процесс раньше это были представители бизнеса и команды разработки бизнес ставил задачи разработчики как-то их понимали выкатывали результат получали фидбэк и круг замыкался ну естественно здесь так или иначе коммуникации мешали выстроить этот процесс но в общем то все понимали как с этим жить и ценились люди которые понимали и этой то что изменилось с приходом машинного обучения и до кадре он подхода главная ценность стали представлять данные и это сантис ты это люди которые могут извлечь эту ценность из данных и посредством каких-то проверок математических гипотез до улучшать и предоставлять все большую и большую ценность для клиентов в нашей компании зачастую даже дантисты делали прототип потому что у нас было много аналитических задач особенно в продуктивной аналитики и в задачах оптимизации различных но потом надо было делать продукт и появилась еще две роли в команде разработки это даты инженеры кто предоставляет данные качественно и своевременно и так далее ну и также остались разработчики которые ценность извлечены из данных красиво упаковывали и доносили до клиента и скилы у этих людей начинают все больше различаться да это не backend и фронт-энд да где так или иначе все программисты и если с даты инженером все более менее понятно его контракт общения с другими людьми это данные то между куда-то самцы разработчик девелоперами инженерами тут все не так однозначно нам хочется убыстряется нам хочется сделать наши продукты все более и более классными для клиентов поэтому мы пошли по пути автоматизации так как автоматизация позволяет сглаживать наши точке взаимодействия это позволяет улучшить синергию команды и чаще и безопаснее инкрементироваться экспериментировать и воспроизводимость релизов улучшается до рельс любое время но вы все это знаете вы все разработчики практически до короткий цикл адаптации многие на самом деле шли немного по-другому пути по пути такому что data science только проводит аналитику разработчик все переписывает но для нас это не тот выход у нас небольшая команда именно разработки у нас больше дата сайнса мы хотим больше проверять гипотез чаще лучше все больше и больше в продакшн но вообще как разработчик я не мыслю продукта без континиус галерей потому что он позволяет сделать жизнь проще гораздо гораздо проще и так или иначе его надо внедрять даже через боль в проекты с машинным обучением теперь поговорим об их планах это вы все прекрасно знаете код гипс контейнер тест рот всевозможный мониторинг биой так далее цикл замкнулся что происходит в машинном обучении у нас все так же есть кот но к это не только приложения код для поставки данных код который может создать модели который делает множество разных моделей какой-то синергию их код который может сделать тестовый datasette на котором мы проверим наши модели получим какие-то метрики и первый цикл замкнется мы хотим улучшать и улучшать наши метрики как только мы достигли чего-то мы все это запакован в контейнер мы все так же это тестируем хорошо на тех же данных на которых мы получили наши метрики идем в рот и незабываемо мониторинге зачастую это одно из основных вещей о которых забывают а теперь николай расскажет о наших первых шагах как мы делали нашу жизнь проще так всем привет я вернулся как и обещал на самом деле у нас есть инструменты для каждого шагов машин горный pipeline например у нас есть инструмент для выгрузки данных из внешних источников когда мы его делали мы предъявили к нему некоторые ожидания например что нам будет удобно мониторить за груз ну как бы про металась графа на это что-то как-то скучно мы решили потом еще по своему сделать через overhaul или что у нас все загрузки будут оформлены в едином стиле что получилось забросе кто у нас действительно оформлены в едином стиле а вот мониторинг нагрузок как-то не использовался поэтому во второй версии фреймворка мы там всякие дополнительные статусы про загрузки просто выпилили то же время мы этим создали некоторый разрыв от рынка даты инженерии то есть у нас дата инженер да ты инженер перед тем как начать работу должен немножко изучить наш чудесный храм но зато все оформим едином стиле удобно еще мы ведь сделали выгрузили сырые данные нам 1 них посмотреть не для этого сделали инструмент назвали его data access or a и ожидали что у нас будет описание всех источников данных ну так удобно также ожидали что data so in this сможет сразу приступить к работе ему не надо будет знать какие у нас источник данных не нужен были только изучить как работать с нашими access арам и соответственно с помощью аксессуаров можно будет применять позы грустно хайфе наоборот реальность как бывает в случае с ним немножко другая во-первых дантисты не использовали описание данных которые лежат в access or off вообще ни разу во вторых оказался писать искать запросов из источников гораздо проще то есть делаем простую штуку которая превращает искать запросу dataframe этого на самом деле для аналитики достаточно love dat инженер у нас потратил много времени на написание этих процессоров и был не очень этому рад также у нас есть библиотека после того как не посмотрели на сырые данные мы их превращаем некоторые факторы которые можно сразу использовать в моделировании ну идея была в том что все факторы будут едином формате то есть на сырые данные по-разному в разных форматах лежат факторы в одном формате лежат и что их будет удобно использовать при моделировании но мы быстро столкнулись с реальностью у нас получилось очень низкая производительность то есть проведение факторов к единому формату реально нас сильно замедлил и также мы писали эти этому фактору библиотеку в один момент времени а потом нам стали появляться добавлять новые факторы там например у нас есть фактор полета у нас еще фактор погода есть там фактор аэропорты это все абсолютно разные данные они их по-разному надо готовить ну вот получилось что с ними очень сложно работать вот и думай факторы эти при моделировании просто избегаем а ещё у нас есть машин бернинг фреймворк это набор инструментов для моделирования то есть идея была в том что мы сделаем that's in this там некий единый интерфейс для моделирования и будет прям хорошо что они смогут между собой модель или легко обмениваться вот это все и что можно будет сразу модель передать разработчику вот дантиста между собой договорились как у них модель работает на передаем это разработчик все отлично на самом деле в реальности такой интерфейс естественно не заработал она оказалась просто не достаточно гибок то есть получил что мы пады методом predict например у простой каскадной модели прячем в несколько моделей и разработчику все равно в это надо залезать смотреть как она там все работает и это требует доработок некоторых действий оптимизации стороны разработчика и самое страшное что cfs машин вернет фреймворк это не название конкретного продукта это те г каждые два месяца у нас но сейчас мы уже стараемся от этой пропасти отходить на это была наша ошибка мы на под каждый проект делали и вот эти единый интерфейс и самом деле тратили уйму времени как я считаю впустую но не все со мной могут быть согласно как они также мы захотели сделать библиотеку для того чтобы это сын tests могли сразу выгружать результаты моделирования заказчик они у нас были ожидания в реальности естественно the scientist и стали быстро понимать что такой инструмент для них просто опасен что не бояться сломать продакшн и так далее а мы со своей стороны получается простую это или операцию сделали сложно раза работая над инструментами мы сделали ряд выводов например тоже инструменты они всегда получаются заточки этот проект и тогда мы хотим переизобрести мой flow мы его глины делаем заточенный под проект а если быть точнее мы делаем его заточенную под ситуацию на проекте текущую потому что когда проект будет дальше развиваться инструменты тоже надо правильно все подтягиваете это очень сложно и сделали такой вывод не очень очевидный но open source инструменты если вы смотрите их надо платить не так что посмотрел как бы натягивается на мой процесс моделирования или нет а надо смотреть его в течение двух недель то есть вы посмотрели пять минут на новомодный какой-нибудь инструментом не знаю нептун имели и вот дайте себе пять минут и еще две недели просто спокойно медленно по себе поживите с этим посмотрите меню может быть кто-то тема за который вы захотели посмотреть на инструмент для моделирования вас не устроит но может вы что то и другое интересное в нем найдете что будет вам интересно не пригодится и самое важное что мы сделали это вывод что dots and scott это вообще не продакшен код это очень кстати вот тут мало dtc чистов много разработчиков тех которые не сталкивается с data so in this to me это может быть неочевидно то есть когда смотришь на ты-то светиться кажется это по той разработчик на стероидов в реальности не совсем так например однажды меня заколебалась ситуация с сырыми низко или запросами в коде я ребятам рассказал про р-н и потом случилась такая тема что вот я пошел поспать возвращаюсь утром работу смотрю в репозитории там лежит такой чудесный монстр которого есть класс внутри класса есть метод внутренне тогда объявляется схема вот кстати кто за джангле работал ну понятно да вот представьте что у вас в ваш файлик мода у спою лежит внутри это да вот классная тема ребят и вот это все наследуется от классика который тоже лежит вот в этом внутри этого класса да и все это записывается вся эта схем поп словарик внутри классиков который лежит соответственно в атрибуте классов объект который наследуется от другого tu as a и я не буду показывать исходник вот этого родителям я хочу что будет жили в хорошем мире я надеюсь они все живым хорошем мире и продолжим жить не просто это был году объект во плоти 3 в общем пришлось вести некоторую беседу и узнать о какая была мотивация вот это все написать тут я понял что не до конца веснушка к евреям то есть ребята сделали армор move и как бы мотивация это была простая работать с sql lite использовать одновременно ну как бы что-то пошло не так пришлось объяснишь на но это уже у ворот смотри как это использовать сюда то есть кстати если кто не узнал это был и легковесный арам пиве и ну вот что-то пошло не так его модифицированный получился супер монстр так и 2 темы почему получился в предыдущем примере супер монстров где-то . назад потому что дантисты на самом деле не сильно любит копаться котлы разработчики не нова и пиа и внутрь ах тыж как фреймворков вот это вот все они нацелены на результат например если нужно право лидировать данные входные для этого нужно вызвать меня то третий вид оценить из не будет смотреть там есть вызов базу или нет он будет работать на точность его точность важнее город и потом ensures соответственно совершенно запросто таких проверок может сделать сколько угодно то есть тут у меня на сайте заголовок и на x x это фантазия дата-сайентистов и потом соответствует через свой чудесный метод запросто ставить все строчки в таблицу то есть такой построчный insert но с кучей проверкой с кучей selecta внутри получается не взяли и соответственно это все дело переписали во-первых мы вытащили проверки валидацию параметров иметь или декоратор вторых не заменили подстрочный цирк на бал кольце работает гораздо быстрее было н на их запрос встал и 3 в данном случае я хочу рассказать про некоторой практики который имеет смысл при не начать применять прямо сейчас если вы взаимодействуете с data so in this to me потому что что это имеет смысл одна из практик это типизация 2 практика этого лидировал параметры через что-то выглядели лидеров параметры функции через что-то уже существующие 3 практика этого лидировать схемы dataframe of 4 практика это проверять цикла магическую сложите года ну просто потому что иначе проект в какой-то момент встанет и есть такой спорный подход пациентов деревень делает его тоже имеет смысл применять давайте поговорим подробней про практике покажу друзей например типизация данных вас реально спасет от таких ситуаций когда у вас модель обучается сутки а потом выясняется что она падает там перед обучением следующий модель просто потому что произошло сложение числа со строкой или как здесь с болевым значением как бы очень обидно нас сутки что-то работает считается считается читаете потом бац и flow whirlpool тоска падает и выясняется что из-за какой-то дурацкой ошибки мой пай защищает от дурацких ошибок вот прямо в такой формы то есть ничего вообще не настраивал очень надо или использовать вылядит имеет смысл чтобы убирать вот эти проверки валидацию параметров из тела функций потому что удастся цените став на самом деле кот такой сложный получается там всякая математика хитрая вот то что то что мы его университетах забываем там может встречаться риме и лучше если у нас функция максимально легкой получается вылетает с этим помогает во лидировать или него лидировать схему dataframe а это такое или важная штука тем более что например dataframe а pandas и ведут себя очень по-разному ну я рекомендую все же посматривать в эту сторону потому что опять же у вас может падать каскадное обучение именно из за того что у там какой-нибудь метод вас ковер не ожидает не пустой dataframe а ему приехал пустой он падает можно было как-то пропустить пойти дальше и проверку с калом а тической сложности я делаю с помощью инструмента radan позволяет проводить некую разведку то есть приезжает отдать с in this the code меж просто запускаем инструмент смотрим с помощью флага nb вот этого вот мы отсеиваем весь нормальный кот у которого циклом а тической сложность ильская и подсвечиваем весь код у которого травматическая служить уровень bay выше винтер деревень development это для разработчиков это холивар на я тема то есть вели давать или не линковать код это вопрос открытый случай из data so in this to me важно понимать что у дантиста у него две стадии работы 1 когда он моделирует очень активно продумывает модели 2 когда он делает что-то еще очень хорошо если это что-то еще это наведение порядка в коде очень плохо если это что-то еще это сочинение нового фреймворка поэтому начать можно применять в интервью гривен development с помощью тампе майк паттон стреляет и fly half-life hell чтобы зафиксировать текущее состояние текущей от которые скорее всего есть есть вы раньше этого не делали здесь также стратегические практике один из одной стороны будут капитанство например применять простые абстракции что может быть более очевидно у нас в практике встречается наследование недовесов там до 10 уровней то есть если что-то сломается до босса будем заходить очень долго также имеет смысл хранить избегать локальное хранение данных ну тоже вроде для нас очевидно для адресов нет нашей практике ds и забивают терабайт и но я скажу на серверах да потому что среда разработки удаленная там допустим r-studio развернуты носить на сервере там есть несколько терабайт данных и там лежит какое чудо например одно из чудес которые мы встречали называется золотой кэш что это такое это кэш который надо накопить понимаете классная тема мне очень нравится поэтому нужно сразу строить разработка таким образом чтобы у вас данной хранились удаленную это для разработчиков для нас очевидно для ds ахмед это реально обращайте на это внимание и желательно pipeline и абстрагировать от среды исполнения например сейчас популярен air flow кстати кто вы верху использует зале ну вот не скажу что лес рук но есть люди так аналогов то особое нету из мы так думаем сюда нам сейчас можем также использовать например но чуть-чуть попроще в любом случае по и play желательно абстрагировать из среды исполнения то есть отель фол абстрагировать сразу я для этого применяю подходит ralph lauren and programming в мире питона для этого есть библиотека драй python stories очень важно dat ass in this там на берегу договориться а что именно он сделает потому что лучше сразу договориться что ты обучаешь модель ты сделаешь predict этой загрузить свои результаты работы потому что у вас может быть не очевидно что он несколько моделей обучит она там каким-то фатальные входе работают тишина создает и еще что то я вот это все в продакшн выводить очень сложно давайте продолжим строить pipeline спасибо но николай вам рассказал о том как работать с кодом до чтобы это не превращалась в бой большую большую боль как настроить работа с входящими данными теперь поговорим о том о выходе самый первый выход которой есть это метрики и всевозможные метаданные гипер параметры параметры какие-то конфигурации которые позволят получить данные модели подумали классно они всегда появляются давайте их фиксировать все fit всегда фиксировать для чего чтобы обеспечить некую воспроизводимость а она как мы знаем понадобиться в любой рандомный момент можно будет сравнить все эксперименты можно будет отслеживать качество модели и сразу сходу отчитываться результатах можно для этого построить какой собственный небольшой фреймворк это кажется не сложно данные небольшие почему бы нет но зачем делать то что уже есть сейчас мы для этого внедрили м альфа tracking да там есть все основные абстракции которые нужны это и эксперимент и запуск в котором можно проставлять какие-то теги любые параметры любые метрики и любые артефакты хранить до встраивается за час вообще в легкую и любой ваш запуск любого моделирования кстати может кто уже использует нет да любой запуск сохраняется в единое место при разработке при запуске pipeline и тестирования при prada вам обучение все сохраняется в единое место и принципе удобно отслеживать там под низом может быть разные хранилище ну вот мы по сгрызть настроили ис-3 для артефактов in-house менее он может кто знает у каждого продукта есть свой bucket и очень удобно данными апеллировать вообще понравилось то что это не зависит от среды не как у нас даже есть еще р там тоже можно тоже самое настроить два разных д с а могут делать примерно одно и то же в разных средах и сравнивать свои эксперименты главное договориться о метриках так как блокировать можно по мере получения вы видели там примитивы вообще простейшие не надо как-то настраивать что-то менять появились какие-то данные которые ведут к результату сохрани их проект достаточно молодой на самом деле по моему первый коммент года два назад появился если ничего не путаю и у него есть конечно ей но в нем удобно отслеживать три ключевых параметров которые интересно показать бизнесу больше лучше выгрузить и проанализировать но это не большие данные для того чтобы обеспечить полную воспроизводимость мы хотим сохранять модели и данные входящие исходящие любые и тоже могут быть файлы огромной в размеры но это позволит обеспечить полную воспроизводимость если у вас несколько людей работают над одним и тем же это позволит понизить бат фактор и легко передавать результат своей работы друг другу особенно если это позволит versio не ровать данные мирно как кот и спокойно переключаться и проводить одновременно в разных разработки для этого можно использовать тоже множество фреймворков можно как-то при настроить на моих flow есть всякие вещи там как из кредит git lfs так далее в им альфа можно сохранять артефакты вот сейчас конкретно мы тестируем 9 3 кстати будет доклад от разработчиков я думаю там более подробно все расскажет а сейчас чем он нам помог он очень хорошо помогает когда есть каскадное обучение когда длинный pipeline когда данные меняются меняются меняются и вы хотите что-то поменять в конце чтобы не прогонять все заново вы можете используя там 9 запустить только вот конечный кусочек он отслеживает эти изменения ну и обмениваться данными команде дадли ценить санте 100 взошло и мы одна команда и у них актуальные данные но и опять же сохраняем в stren house вот очень удобно если че ну вот еще раз говорю да позволит экономить время и следит за изменением в ходе данных не требует отдельного сервиса сервера это особенно удобно когда вы комитете и хотите проверить white line да не надо никуда ничего но да перекидывать там где-то отдельно запускает верху еще что-то об запустили проверили что все хорошо но и из этого же и недостаток там сложно распараллелить процесс постоянно надо комитет при каких то изменениях ну я думаю все впереди теперь немножко про тестирования кстати заметьте produto немножко сдвинулось объясню почему чуть позже сейчас про тестирование если вы решились на линкор и проверьте не надо в это залезать чуть чуть лучше потихоньку но стабильно стабильно стабильно сначала это больно но сейчас нас в паре продуктовых команд это хорошо заходит ну про эти типы были делайте это упрощает жизнь особенно когда есть несколько моделей которые делаются разными людьми нет контракта пока что между до цен this to me то есть я сделал я сделал свои метки и при тестах можно запустить тест в этой план это написал на тестовых данных но эта дата дали вам данные могут постоянно изменяться все таки хорошо если во время коми то вы сможете какой-нибудь рандомный кусок прудовых данных если они у вас большие взять и попробовать обучиться потому что в любой момент может все поменяться схема сам состав данных все что угодно ну проверьте метрики по последнему обучению мало ли может они там в ноль упали кто-то не заметил но и скорость модель может 99 но она работает не 30 секунд а 30 минут ну всяко бывает ну и замыкаем нашу цепь мониторинг в мыле также обязательным технический качественный качественный мониторинг моделей он обязательный потому что вся команда работает на какой-то результат и не надо чтобы инженер говорил вот у меня данных хорошие все должно быть отлично данный в любой момент могут поменяться доцент искала у меня классная метрика данные в любой момент могут поменяться и это метрика уйдет в ноль ну и мы все-таки делаем бизнес поэтому нужно бизнес-аналитика бей тоже нужен и каждый член команды должен понимать как это эти метрики эти это аналитика влияет на его работу так не забывайте все-таки ваша цель это получить бизнес ценность всей команды спасибо вот будем рады новым сотрудникам и вопросам давайте сначала поблагодарим наших замечательных докладчиков николая ii антона так так и перейдём к образом здравствуйте спасибо за интересный доклад у меня вопрос вот на какую тему по поводу связи да ты инженер и дата-сайентистов то есть они вот обмениваются данными и вот здесь в принципе могут быть какого рода проблем как с какими проблемами столкнулись то есть во первых эти данные которые передаются от даты инженеров дата-сайентистов они очень часто меняются это первый проблему вторых это большие объемы данных и если мы там говорим о каких-то табличных данных то зачастую это такое количество колонок на которые скажем обычно там реляционной субд и не очень хорошо поддерживает то есть это сотни колонок и там приближаются аж к тысячам колонок вот соответственно здесь вопрос как какие инструменты используются для того чтобы передать как сформировать dataframe и передать дата-сайентистов чем вы пользуетесь как вы решаете эту проблему у нас это не решается через парк dfs этом сильно не погружался но в общем и целом works этим справляется естественно что тысячи по лунок на самом деле у нас есть витрины и в возрасте в которых по тысяче колонок она живет вполне но единственное важный момент что у нас есть например datasette которым терабайт данных мы заранее агрегирует по тем параметрам в котором проценте space если у тебя есть не знаю как они параметрическая высота в самолете которая меряется там доли секунд то хорошо бы ее просто агрегировать там по минутам по 5 минутам ну то есть агрегацию считаешь в ходу до спарты потом закидываешь по сброс для аналитики как вариант то есть тут на самом деле множество решений на это и бред обработка то есть сначала смотрят на данные оба понимают что надо какой-то пациент сможет сделать тут некое задание уже да потому что я хочу видеть вот так такие данные договориться и уже использовать spark выгрузки dfs то есть множество and самом деле хочу всем напомнить что у нас предусмотрены подарки для лучшего кто задаст вопрос кажется несколько вопросов коллеги спасибо за доклад вопрос вот пробей вы упомянули если правильно понимаю это у вас измеряется продуктовая метрика какая то ну или группа метрик и вы смотрите как они меняются в зависимости от того какая версия pipeline а нос дано выключена скажите много ли вас продуктов от покрыты таким вот замкнутым циклом с учетом проверок не только технически мной продуктов и насколько сложно было сделать но сейчас таким замкнутым циклом ну да я минимум два его сейчас думаю еще два к этому приближаются говорит что уже все или нет но на самом деле те что есть там достаточно легкие там бизнес метрики г.г. люди покупают или не покупают билеты вот и в качестве да и если там интересно у нас табло это если выгрузки или там кастомные приходится делать какие-то дашборд кстати да спасибо за интересный доклад вот я как раз хотела спросить поподробнее рассказать про мониторинг я так понимаю вы достигли никого консенсунс и контракт с дата с античными с бизнесом вот расскажите подробнее приведите пример просто очень интересно что именно вы замеряете в части технической эффективности модели и и качественный не нарушив при этом так так так так очень сложно очень сложно просто самый лучший пример под индии попадает извиняюсь да смотри любой дата цен с продуктами с какой-то целью делается там выручку увеличить может убить дата-сайентистов у него же пока это задача все-таки есть когда он продукт делает вот сначала основной метрику продукты можно как-то затащить но также естественно грядку главное технически главной технически это скорость на самом деле актуальность доставки данных актуальность эдиктов вот потому что зачастую это важно в кросс продажах в момент знать что порекомендовать клиенту что ему дать для того чтобы он повел нужным нам павел в нужную сторону так скажем свое поведение мне кажется вся команда целиком то есть у нас достаточно такие бизнес ориентированные доцент из ты вот давайте договоримся что с одного участника один вопрос потому что но другим тоже надо оставить время на свои вопросы добрый день и спасибо за доклад было интересно у меня вопрос к вам такой вот у вас какая-то проблема вы ее решаете пытаетесь решить при помощи какой-то модели вы делаете сбор данных сделайте модель стройте допустим проблема решена и вы через ваш мониторинг наблюдаете за тем как модель performer насколько часто приходится возвращаться потом ее перед тренировать модель через какой промежуток времени это обычно происходит если такое бывает и насколько сложно это спасибо ну каждый день каждый день у меня наоборот наоборот это камина перед тренировать ну вот новые данные каждый день надо перед тренировать каждый день всё понял значит он у каждый день до у нас 1 2 месяца примет нас проект перетренированность сложность ну там как это изначально если не вдаваться в детали обучение могло и 30 часов длится потом по оптимизировать код и все уже пару часов у меня такой вопрос среди ваш сквозь ваш доклад сквозить такая вот идея что есть вот мы есть они dat ass in this ты даты инженеры у вас есть какое-то внутренне там делаете ли вы мит апы например где рассказывать этот is in this там про винтер или как там внутреннее обучение нет мы стараемся этого избежать может быть в этом проблем и я мы они смотри мы они нет такого такое стараемся избежать внутреннее обучение до есть мы вот кстати недавно до организовали обучение как раз именно для достаньте став чтобы прототипы которые они делают можно было использовать сразу то есть как раз внедряем инженерной практике ну так если коротко сделать небольшой проект чист режиме инженерный важно понимать что вот эта тенденция чисто год scientist она будет идти на спад чем будут нужны те кто умеют чуть-чуть моделировать и разрабатывать но такая тенденция появление профессия моей инженера но последние два года сколько я слежу давайте тогда зададим ребятам еще один вопрос долго протянули руки и остальные все вопросы оставим на дискуссионную зону я думаю они задержатся и выделяют вам время в дискуссионной зоне здравствуйте подскажите пожалуйста как вы решаете проблему того чтобы стоек вы внедрили модель она меня это как бы реальный мир потому что люди начинают по-другому себя вести потому что они видят другие рекомендации это что вы раньше обучали по данным который этой модели мини эффекте листа теперь мы дали может переучиться понятно нет если я правильно понимаю тушь это вопрос именно когда the scientist им то есть это они должны оценивать как изменились данные по столу как мы внедрили модель как это вопрос мониторинга это вопрос мониторинга то есть правильно поставленных метрик моделирование тоже ну да естественно то есть надо понимать когда надо что-то менять николай антон теперь остался самый сложный вопрос какой по вашему вопрос из зала был самым интересным давай рабочими кто про обучение спрашивал давайте мы вручим наш подарок от спонсора wargaming вот так спасибо большое за ваш интересный вопрос все остальные вопросы дискуссионной зоне всем спасибо спасибо"
}