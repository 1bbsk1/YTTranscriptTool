{
  "video_id": "8v0HOMrGixY",
  "channel": "HighLoadChannel",
  "title": "Компилируем 200 000 файлов быстрее, чем distcc / Александр Кирсанов (ВКонтакте)",
  "views": 1413,
  "duration": 2321,
  "published": "2023-01-19T05:55:18-08:00",
  "text": "привет с вами александр кирсанов из вконтакте я руковожу командой кпп внутрь его к вообще когда выступал конференция на этом вступление можно заканчивать но здесь у нас неплохо пышная конференция поэтому я чуть-чуть поясню весь в к весь backend написан на php ну реально здесь многие удивляются но это так окопах об этом наш компилятор который переводит php с плюсы за счет чего все быстрее работает раз в десять чем на обычном php и наши самые неразлучные враги и заклятые друзья это пах опросники bug in der и который php код и пишут в хадж ников много на самом деле их действительно очень много и они пишут очень много кода а главное их становится все больше я на самом деле мне это не нравится я против бесконтрольного расширения компании команды против того чтобы накачивать людьми но так уж происходит бизнеса виднее новые спецпроекты какие-то новые направления в общем по хорошенько становится больше больше больше а главное что приходят и начинают писать больше кода я говорю остановитесь хватит ну сколько можно уже пять миллионов строк кода 10 миллион строк кода бедный к php вот прикиньте он же все это переваривает компилирует пропускает через себя по моему уже просто любую последовательность символов можно нашим бы кант коде найти но нет кода меньше не становится и вас становится больше больше больше и как-то нам нужно уметь выживать вот сейчас я расскажу несколько трюков как в этой спецоперации по написанию php кода наша маленькая команда все-таки остается победителям когда я говорю про то что мы конвертируем покупайте плюс плюс совершенно очевидно что чтобы получить из этого бинарник я не буду говорить о том как мы из php получаем плюсы этого краска php это как раз таки компилятор на тему я об этом рассказывал больше на всяких пока пышных конференциях я не буду говорить как из объект ников получить бинарник потому что это просто венков к я расскажу об этом этапе как из плюсов получить объект ники потому что оказывается когда у нас очень много плюсов то вот здесь можно придумать много интересного и так я расскажу как для этой задачи мы раньше использовали существующие решения я расскажу как мы написали свое что нам это дало и что отсюда вы можете извлечь для ваших проектов пять минут на то чтобы описать что у нас было раньше давайте поймем почему большие объемы это все проблема вот представим что у нас проект плюсовой обычный мы запускаем на нем майк к примеру у нас 48 ягер 48 потоков получается моих запускает 48 компиляторов они параллельны это сидело обрабатывают потом один закончился 149 потом 50 и так далее пока не обработается все есть проект скомпилировалось а плюс упрётесь в объект ники у нас очень много файлов как вы думаете вот если вот взять и также запустить к примеру там тот же миг на нашем объеме кода с кода генри он нам сто пятьдесят тысяч файлов примерно сколько это займет просто локально ну вот на самом деле я не знаю потому что я так не делал и потому что это принципе бесполезно не хватит памяти не хватит вообще ничего ресурсов можно очень медленно короче примерно 12 часов может меньше может больше в любом случае на таких объемах кода локальной компиляции не подходят по этому еще давно мы использовали кое-что другое но это не только наша проблема любые большие плюсовые проекты они долго компилируются v8 мода clang и так далее любые огромные проекты и вы когда с ними работаете очень долго компилируется есть такая штука который называется де стация дистанция это вещь которая умеет вызывать компилятор не локально а на другой машине вместо g плюс плюс что-то вы пишете тест с его плюс тут что-то и вот это вот вызывается на другой машине работает примерно так что локально disciple прогоняет сидите файл через препроцессор эту огромную простыню посылает на сервер там эта простая компилируется возвращается обратно объект ник и следовательно вся фишка в том что серверов много и мы локально можем запускать не 48 к примеру job а значительно больше чем 48 потому что они идут на сервера и чем больше серверов тем теоретически мы можем больше парализации достичь итак у нас была действительно так было до 2019 года на тот момент вы cable примерно 50 тысяч файлов примерно 30 минут собирался с нуля когда говорю про сибири файлы этого как раз из php кода полученные файлике и был еще такой эффект что вот к примеру мы копы хоп и обновим ночью потом приходит php разработчик с утра какой-нибудь проснется и думает пойду-ка я сайт дальше делает нам в каком писать начинаешь выписать ему на скомпилировать а мы-то обновили раз компилировать все ладно начал потом просыпается 2 3 4 все начинают писать и начинают компилировать и это все отправляется на одни и те же ноты и бедные дистанции ноты аниме вывозят у них там циpкa заканчивается каждому остается по чуть-чуть его то и каждому приходится ждать два часа потому что все одновременно хотят все сразу в 2019 году мы поняли что это уже долго а мы растем мы тогда про пачелли диске c мы внедрили туда поддержку при compact заголовков я думаю вы знаете что это такое но все-таки поясню когда си плюс плюс видит компилятор видит in cloud какой-то аж файл он просто берет этот наш файл и вставляет его содержимое вместо этого in куда и так происходит всегда но вот если взять этот файл обработать отдельно плюсовым компилятором получить из него прикопать заголовок gch файл случайно плюс тогда компилятору видео runtime аж и видя что рядом есть gchq он подключит эту кашку что значительно быстрее чем хэдер мы научили дистанция чтобы он понимал там наш runtime поташ мы научили так чтобы при процессов дистанция не наш on time аж не вставлял вместо этого там gchq пересылом на серваке мы это не open source или потому что была очень жесткая привязка к php и к нашим путям но тем не менее это дало нам действительно очень стильно и ускорение на тот момент и так мы жили еще два года за два года мы выросли стало уже 150 тысяч файлов сборка уже 12 минут а мы растем и как я рассказал вначале больше больше больше что будет дальше не понятно поэтому мы сели и подумали а сможем ли мы быстрее оказалось что сможем так что следующие 15 минут я расскажу как мы вместо дистанция написали собственное решение и как она работает но у сети я так назвал нашу разработку на усики вызывается идеологически как и дистанция вместо g плюс плюс что-то мы пишем на усе stiga присутсвует что-то на этом сходство заканчивается рассмотрим на маленьком примере как это дело работает у нас пример истефи книжка которая подключает один . аж если один . аж мы вызываем новую сисек и плюс плюс 174 клиент носите поднимается понимает что мы конкурируем 173 анализирует его понимает что он зависит от 1 . аж city p&h файл пересылает на сервер на сервере происходит компиляция посылается обратный объект ник самое главное отличие от дистанции в том что мы препроцессор не гоняем локально мы посылаем сами файлики точно так же как и в случае дисфункции у нас много но у сиси сидоров точно также носить и клиенты они запускаются запускаются посылая исходные файлы на сервер а те комбинируют посылают обратно на самом деле но у сиси клиенты они даже не конектится к серверам потому что есть демон который работает в фоне которые держат connection и она у сиси вот эти маленькие клиенте ки которые являются префиксами такие маленькие процессы на плюсах которые просто поднимаются пайпа unix сокетов демон свою командную строчку дожидаются результаты и умирают и самое главное за счет чего мы можем выигрывать это то что мы поскольку посылаем файлы мы не вызываем процессор локальном посылаем файлы значит мы можем придумать очень умные ремонт крыши чтобы не делать два раза то что мы когда-то сделали к примеру мы послали один цивики и 1h один раз потом если где-то кто-то хочет скомпилировать то же самое мы понимаем эти файлики совпадают мы их не будем больше посылать и более того мы это уже компилировали даже компилировать больше не будем потому что у нас уже есть объект нет моего и вернем то есть вот первый раз мы запустили это все послала скомпилировалось второй раз если где-то кто-то запустит то же самое новости про чакры о файлики те же самые не буду посылать и вообще объект не книг можно взять готовый не буду компилировать вот этот ssd cache и обожаю крыш за счет этого у нас происходит очень гигантский скорости то есть на первом запуске происходит честная компиляция а второй и следующие работать значительно быстрее если исходники не менялись даже если мы это запустим очистим папку запустим заново компиляцию даже на другой машине на другом агенте другого пользователя в другой папке все равно нам сесть и прочекает поймет что эта работа двойной а она уже была проделана можно взять прошлый результат почему это важно это важно потому что к примеру на build агентах они же выполняются все билды выполняются в докере то на 1 день титана другом и если один агент когда-то что-то сделал и потом запускается на втором 2 будет из рима утка шею же сразу брать это важно при дет разработки к примеру вы ведете какой-то branch постоянно его компилируете компилируете а когда вливаете в мастер работает а уже была проделана поэтому то что оказалось к мастере можно больше не компилировать и можно больше не посылать сейчас я расскажу про то как это устроено внутри несколько алгоритмов связаны с плюсами я разбил это на стене таких этапов коротких примерно по минуте вот эту картинку мы уже видели что есть какие-то клиенты есть демон есть сервера но у сети клиенты написаны на плюсах это такие очень-очень маленькие процессы задача которых умирать они запускаются ждут умирают умирают умирают умираю зато они очень легкие их очень легко запускать демон написан нога его задача жить он запускается когда запускается самый первый stickers процесс поднимается живет до окончания билда и умирает потом остера тоже написано на год и задача жить даже когда не живет уже демон то есть их задача обслуживать много клиентов сегодня завтра в течение недели месяца они просто никогда не перри запускаются и и живут себе то есть запускается какой-то build процесс там к php семейка неважно начинает запускаться дому свести процесса вместо g плюс самый первый процесс запускает демона демон устанавливает connection и и в общем живет новости процессы запускаются умирают запускаются умирают потом когда бил закончился процесс и запускаться перестали демон это понял тоже умер был закончиться мы получили объект ники те же самые как будто бы мы это скандировали локально все только значительно быстрее дальше собственно про то как каким образом но у сиси определяет что делать вот у него есть задача один процесс запустился там у него есть какие-то скидки какие-то зависимости я уже говорил про то что он посылает файлики посылает физики посылает хадера то есть ему нужно определить что вообще посылать на сервер для того чтобы компиляция могла произойти удаленно то есть он анализирует командную строчку он анализирует вести реки файл с находит все зависимости рекурсивно посылают это на сервер сервер говорит окей я понял у меня вот этого нет клиент закачивает того что сервер сказал что нету и когда на сервере все появляется серый компилирует посылает обратно объект ник следовательно если клиент все посчитал отправил на сервер стер же сказал то что у меня уже все есть работа дальше никакая не делается на самом деле взять посчитать зависимости которые есть у сити файла это не так-то просто на самом деле к примеру когда мы говорим им cloud там острым или intel какой-то другой аж файл steam cloud и надо раскрыть рекурсивно и по-честному если это делать по честному нужен плюсовой препроцессор потому что иначе никаким образом не узнать а что там внутри по дереву где за какими if in the fame игроки макросами раскроется но если запускать препроцессор это будет долго это будет реально долго поэтому в нау сесть и встроен собственный парсинг in cloud of он работает примерно так же как и свой препроцессор он не умеет макросы он допустим не сможет boost проанализировать но когда input и статические он знает все правила раскрытия там айклауд а системным плод директорий где надо искать какие файлики как их матчи системными х дырами в общем для того чтобы получить список зависимостей тот же самый который выдал бы пришел эй компилятор по-честному теперь что касается удаленной компиляции вот например мы все-таки нашли зависимости переслали все это дело на сервер а следовательно чтобы там это дело на сервере скомпилировать надо это куда-то сохранить но вот это куда-то мы же не можем взять и сохранить файлики по тем же путям в котором они были и запустите компилятор также как он как он планировался запускаться на клиенте на сервере для каждого клиента выделяется папочка и все файлики которые заливают клиент они складываются в эту папочку ну типа якобы такой сосуд получается и но у сиси знает все особенности вызова всех плюсовых компиляторов где надо подменить какие пути он их подменяет подменять сын cloud постах подменяет где нужно короче для того чтобы запустивших другой папке рисовый компилятор отработал точно так же как если бы пути были другими изначально локальными клиентскими кэш исходников за счет чего мы как раз таки и очень сильно выигрываем это когда клиент вычислил то что вот у нас есть файлики говорит серверу я хочу их отослать а клиента остера помнит ты их уже отсылал следовательно не надо их отсылать и просто берет хардинг у из-за сердце каша делает в ту же самую папочку куда он сохранил бы эти файлики и таким образом получается что клиент как будто бы их уже отослал и объектный кэш работает примерно так же стервой понимает что объект ник был уже скомпилирован с таким такой-то степи такие-то зависимости он и объект никита же сохраняет и следовательно если в другой раз получится тот же самый файлик с теми же зависимости на стиме же опциями компиляции он просто сделает картинку и отправит его клиенту как будто бы он был по честному скомпилирован если акции компиляции меняются он это дело понимают к примеру одни и те же исходники можно скомпилить отдельности бак символами отдельно без дебаг символов получить два объект не к это будет просто 2 валютных объект не к для разных опций это тоже нормально и отдельным образом в нос обрабатывается при compact в заголовке опять-таки помните я рассказал что дистанциям потеря для прикопаю заголовков чтобы он отсылал это дело там на сервера носите под не поступает с ними еще хитрее он локально вообще ничего не делается он умеет делать так чтобы сервер сам комбинировал при compal заголовок каждый из серверов соответственно ничего не отсылая по сети и это работает и для gps + и для клан во потому что если вы для г плюс еще можно там взять локально скомпилировать отослать иван даже подхватит а если там могилку какую провернуть с клан вам так вообще не получится склад гонг единственный путь это компе личке compact заголовок прямо на месте и там его использовать и на у сиси это умеет все делать есть конечно еще вещи не буду об этом рассказывать это не для презентации об этом можно будет потом посчитать собственно мы придумали эту штуку мы сделали на тот момент когда мы это придумывали у нас не было уверенности на самом деле что будет что-то быстрее не будет что-то быстрее вполне могло не получиться вот самый яркий наверное пример того что у нас получилось никогда это делал мы с до техниками запустили ее в тихую никому не сказали просто запустили она начала работать потом недели через две-три камни пошли в личку странные вопросы мол что то к php как то как то слишком быстро собирается наверно что-то сломалось что-то по всем графиком сборки по всем графиком тепло и какие-то просадки что то наверное идет не так поди ка посмотри вот этот самый главный point когда запускаешь никто не знает или догадывается в этом по косвенным признакам но все-таки если говорить про цифры на нашем реальном коде в каждом который миллионы строк пока пышного кода 150000 там плюсовых файлов мы сравним сейчас дистанция оригинальный до 2019 года который был дистанция наш почин ай ноу сессии первый запуск и no se si последующие запуски потому что они же быстрее и вот это быстрота она чаще всего нужно цифры у нас получается примерно такие если бы мы в девятнадцатом году дистонии про пачелли мы выждали сейчас уже 2 часа с нашей текущей кодовой базы с нашим текущим runtime он очень долго первый запуск много сисек примерно в 2 иногда в двойной до 3 раза быстрее дистанция починила нашего а последующие запуски вот полторы минуты готов весь в таком это очень быстро это гигантский бинарник на самом деле гигантские объемы кода всего лишь полторы минуты сеть в полку и в каком готов и помимо этого помимо скорости мы получаем все то что говорили неважно мы сменим build машину мы сменим процесс сборки деплоя все локальные все под домены всех локальных разработчиков точно так же быстро собираются когда мы обновляем как вы больше нет спайк of потому что один раз мы это сделали все остальные просто скачали не нужно сдать два часа с утра можно просыпаться и сразу работать наконец-таки шапошников не всегда на самом деле все так красиво кира писал у нас действительно цифры классные у нас действительно все сильно ускорилось на усе стиль не спасает от некоторых вещей к примеру если есть файлик который очень долго компилируется минуту компилируется г + + и в процессе получилось так что он тоже интере компилироваться что будет ждать эту минуту не важно где неважно локально distance to no se si неважно будешь сидеть и ждать минуту линков к опять таки происходит локально то есть но система на компилирует объект ники где-то там потом все это дело собирает локально ленку its венков к больших бинарник of долгая ты все равно ждешь зенковку это не входит во время на у сиси ну да и это личная к примеру если взять ни в каком если взять какой-то другой большой плюс альфред примеру clang и сравнить диске c сноу сиси там мы увидим конечно ускорение но далеко не такое гигантское тот мы видели в как ломе почему так происходит а по тем же самым причинам что процесс сборки фланга он он типа немножко бы компилировать что-то локальный ленку это конкурировал локально клада генерит вот это локальные работы очень много даже если 0 вверх относить 0 overhead на какую-то удаленную компиляцию все равно локально это очень долго и вот если вычесть всё локальную работу и сравнить только цифры удаленной работы мы увидим те же самые абсолютно пропорции тот же самый выигрыш что мы видели для века то есть у кпп с горки в случае век опроса параллелизм значительно выше чем чаще всего встречается поэтому выигрываем сильно обычно в обычных проектах выигрыш не такой заметный но он все-таки есть и вычесть вычтена локальную работу он будет примерно таким же как у нас в общем почему это все так значительно ускорилось относительно дистанция потому что есть демон который держит connection и есть очень легкий плюсовые рам обертки которые умирают мы не используем препроцессор мы используем то собственные всякие штучки умные ремонт крыши умные там прикопают серверные хадера ну и наконец как это можно у вас использовать я думаю что тут целом ответ очевиден это дело все лежит в конкурсе на гитхабе где то в каком носите все как это поставить как это использовать какие есть настройки вся документация там лежит в красивом форме нам виде 7x нинзей с обычным майком это тоже все плюс-минус работает ну по крайней мере на тестах на которых я проверял в бою это работает у нас по прежнему кпп + + но оно должно по крайней мере из того что я делал тестировалась работает на с другими тут системами забыл кстати да чуть чуть не забыл сказать почему но у сиси так называется наушники сползают на самом важном вопросе потому что у нас в концовке тоже от века лежит linder ну were five есть валидатор he архитектуры на у кого я на плаху параша прошлом об этом рассказывал очень кило кстати темы можете посмотреть и сейчас появился но у стихи распределенный компилятор просто мне очень нравятся такие названия для кода написано wanna go так что компания может и дальше продолжать нанимать шапошников которые дальше могут продолжать творить какую дичь с объемом кода ну а мы у нас еще будет время над этим подумать тут должен быть еще один слайд с контактами но он почему-то почему-то его нет ну ладно остановить без контактов надоест продать значит в тестировщики пойду спасибо а сразу есть вопрос о это интересно нас здесь сейчас смотрите и даем вот этот человек пару вопросов флешку комментариев вот эти вот на усе сервера сколько их вообще сколько их всего сколько их задействована в процессе 1 сборки всех ваших исходников и еще про кэш я не до конца понял этот кэш он локальный на каждом отдельном сервере или меж серверный конечно все таки есть хорошие вопросы серверов компенсационных not у нас сейчас 30 штук мы в 30 использовали для disciple и в на те же самые сервера я установил на у сиси сервера как минимум во первых чтобы вы были честны и замеры в общем 30 понятное дело что чем их меньше тем скорость дольше но больше чем 30 нашем случае не нужно а про меж серверный кэш нет он на каждом сервере отдельный но у сиси клиент делает так чтобы 1 этаже сидите файл независимо от пути просто по названию на самом деле попадал всегда на один и тот же сервер то есть даже если ты возьмешь тот же самый проект свой будешь компилировать на другой машине в другой папке зерно для одних и тех же стихи хищников ты будешь попадать всегда на один и тот же сервер поэтому все зависимости там достаточно один раз за кэшировать и все еще такой вопрос слышь комментарии вот избавиться от факта пересылки исходников между клиентами и вот этими серверами можно если считать что вы собираетесь всегда из одной и той же кодовой базы почему бы но у сиси серверах не держать всю кодовую базу мало-мальски в актуальном состоянии и просто как бы избавиться от вот этого вот сеть в полку в моменте компиляции ну на самом деле сеть в полку идет в обратный в обратную сторону на ведьм 3d потому что чаще всего когда вот допустим у тебя не меняется кодовая база и просто запускать какой-то клин build там в докере на отдельном build агенте он понимает что ничего пересылать не надо ничего компилировать не надо просто сидит пойдет объект ники к примеру чтобы скомпилировать в каком с девак символами он пересылает обратно на клиент суммарно 26 гигабайт в 26 гигабайт объект ников вот это вот сеть в полку там стоит и все кодовая база она на самом деле очень сильно меняется но и если ее не родить куда-то на серверную сторону это уже получить не расширяемое решение это будет какое-то вот такая привязка к кодовой базе нельзя будет запустить на произвольных проектах мы теряем да если у вас какой единому мнению предложение отпустить микрофон продолжить excursions зоне конкретно 7 я просто вижу как ним еще один вопрос давайте попробуем немножко жулить эту историю здравствуйте сквозь за доклад у меня вот такой вопрос на слайдах не ну как-то не прозвучало компилятор бывает выводят всякие вардинге error и и как вы когда у нас это параллельная распределенная история хотелось бы в результате разобраться вот этой каше и так сказать что было понятно какие вардинге от какого файла и там и так далее вот как-то этот порядок учитывается во всей системе вардинге имеются ввиду который выводит + новый компилятор когда да вот непосредственно когда но у сиси клиент берет тире печник и зависимости посылают на сервер сервер это дело компилирует и обратно посылает не только объект не кино еще и роста дают стр и клиент завершается на самом деле с тем же кодом ошибки что и завершился + новый компилятор с тем же страдал с тем же 100 т.р. получается что полностью весь output сохраняется как будто бы каплю ствует был запущен локально потому что он берется от туда и там пути подменяются опять таки чтобы пути совпадали с клиентками а вот пути уже не серверными александр смог ответить на твой вопрос там еще один вот у на здравствуй спасибо за доклад я так понял что нация решает целый ряд проблем которые приходилось раньше решать по отдельности там сисек ешь при компании трейдер с 10 и это все здорово not про вопрос про линков q все-таки ленку это все файлы в один объект ник не пробовали вы разделить это на динамические библиотеки это бы значительно собственно ускорило процесс окончательной линковки уже объект не к ну как я говорил что линков как она у сесть и отношения не имеет потому что носите рак раз про компиляцию степях и в объект ники а что касается линковки потом финального бинарник а у нас на самом деле используется именно промежуточная линков к то есть у нас есть куча куча куча объект ников там 150 тысяч мы из этого условно говоря сначала получаем 150 промежуточных объект ников там по тысяче по папочкам их бьем в этом эти 150 объект ников уже линкуем в такой большой финальный финальный бинарник мы более того там весь процесс компиляции разбивается на то чтобы параллельно можно было запускать но у сиси на отдельных папочках при этом линковать уже собранные папочки то есть это все там относится к скажем внутренностям к php или внутрен стендом бил системы в общем случае монет на ухе си а тогда чтобы ускорить линков q мы более того когда 150 тыс файлов без промежуточных линков ок не обойтись это правда кажется что это очень круто звучит у нас еще один вопрос из зала роста спасибо за доклад такой вопрос про third-party зависимости какая гадость и папу 119 это как-то переварит или это нужно пусть будет тянуть на все эти сервера third party зависимости ну смотри если там использовать какие-то зависимости которые нормальные невус носите это все дело прочекает он найдет все зависимости по всем аж файлом все это дело перешлет они будут она серии валяться boost почему не рам не сработает вот просто так потому что там нет in cloud какого-то там файла там in cloud какой-то макрос то есть без честного плюсового препроцессора ты не получишь какие вообще файлики нужны у нас есть специальный режим чтобы запустить и чтобы вот эти зависимости получал не своим алгоритмам не своими плут бартером очэс напрессован и процессором то есть он там вызывают газ и минус m который выдает там миг файл со всеми зависимостями и тогда он использует его но это работает просто значительно дольше и то есть можно короче не используя вот это использовать в плюс минус m будет работать дольше но я boost не люблю если честно в целом надо любить boost ничего страшного у меня к тебе вопрос в догонку а вот ну тут говорили про пуск такие видим августа при ну а нам еще 150 разных знает библиотек существует мире а как с пакетный менеджер канон поддерживается не поддерживается я не вижу повода почему нет ну просто у тебя перед сборкой обычно проект у тебя происходит запуск как он он на на пакетный менеджер начнете зависимости отсюда вопрос это надо будет на каждом сервере сделать перед сборкой или это как-то там умную или это никак кисни обрабатывался это ну скорее всего эта часть бил системы то есть перед тем как непосредственно запускаю компиляцию все равно там там условно говоря семейка если если это все дело будет красить днем он поставит установит пакет и прежде чем непосредственно запускать г + + или новости в нашем случае исследовать на к моменту его запуска это уже бил системой будет установлена и следовательно у сиси это все разрулит про чекать что вот оно есть от мира рид это дело на удаленные серваке и там запустится просто компиляцию это очень круто прям круто круто уроку у нас как раз время есть на пару вопрос спасибо за доклад вопрос следующий собственно список как я знаю появились модуль который в общем призваны уменьшить макрос файлами и шить хедер кого так далее поэтому что вопрос о том числе когда появится вас там транслятор спички в си плюс плюс 20 source и но все же вопрос насколько поддержка модули упростит вам жизнь или наоборот усложнит вам процессы которые вели вновь сисек я на самом деле на модуле надеюсь это с ними часть проблем но не снимет все в любом случае самое главное за счет чего мы выиграем это ремонт кашель что не нужно делать 2 раза 1 этаже поэтому модули условно говоря они могут упростить жизнь на серверной части но они не не упростят весь pipeline когда мы учитываем там гид разработка учитываем build агенты и так далее ну и к тому же когда они все-таки там станут стабильными и насколько будут применимы в авто гения тоже не очень пока что делаем эту ставку но мы все ждем мы все молимся на то чтобы модули появились давайте ног у нас привет спасибо за доклад я посчитала чёрных человечков на слайде 192 розовых 3 вот у меня вопрос связи с этим а какая команда большая кпп разработчиков пять человек там еще два беленьких а у тебя короткий вопрос если короткий то давай вопрос просто странный процесса рынка удав они пробовали делать совсем lightweight процесса рынку дав которые бы с избытком может быть и генерал гипотезы днк удав то есть вообще не обрабатывает мвд рф и допустим пусть даже он генерит in cloud который за их тифом но не дешевле ли будет от того что это все перри молится в параллель с избытком как бы вообще это ровно так и работает не какой-то мунай логике там просто очень аккуратно написанный поиск всех in cloud of с учетом с учетом icloud постав с учетом всяких in клубных системных х дырах и так далее но да никаких и фильтров of то есть он получает список больше чем реальный 343 процессор если он получит список меньше пересечении этого списка обратно будет нет ненулевым тогда эта ошибка а так он получает список больше пересылает это все просто часть из них в итоге не используются но по-честному без процессора и препроцессора никак так часто передайте микрофон кажется это будет последний вопрос здравствуйте спасибо за доклад от короткий опрос а что если в заголовке уже есть макрос как он заголовки ну то есть include дальше в путь и истина макрос который нужно развернуть как и в случае буста не справится то есть без плюсового препроцессора никак не развернуть то есть случае со статическими путями это все дела нормально разворачивается в случае с не статическими как и boost надо запускать условие препроцессор но это не очень не очень ход сам по себе но в библиотечных иногда встречается да спасибо"
}