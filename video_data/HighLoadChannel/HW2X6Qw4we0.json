{
  "video_id": "HW2X6Qw4we0",
  "channel": "HighLoadChannel",
  "title": "Функциональное тестирование высоконагруженных проектов / Илья Пастушков (2ГИС)",
  "views": 335,
  "duration": 2575,
  "published": "2017-04-10T04:44:06-07:00",
  "text": "для начала расскажу один кто примерно знает чем занимается наш компаниях а ну тогда комментарии излишни давайте сразу начнем сегодня я расскажу что можно извлечь из тестов так экспеллиармус почему результаты одиночного тест они являются показательными как не потеряться среди огромного количества тестов какими инструментами все это можно сделать и что примерно должно получиться в итоге немного о себе я специалист по тестированию в компании 2гис два года больше двух лет работаю в команде unix поясню у нас unix это значит linux поэтому холивары лучше оставить чем занимается наша команда тут два примера наших сервисов то есть первые это сервер и обновлений второе это поисковые сервисы как вы видите на схеме что между пользователем и нашими блендами есть некоторое количество инстанций который должен пройти сигнал и который в аппаратную можно пройти ответ то есть это накладывает на нас такую вещь как и слой и требование очень быстро отвечать потому что задержка в какой-нибудь десяток миллисекунд на стороне сервера это задержка в пару секунд на стороне клиента клиенты это обычно бесит то есть если мы рассмотрим сервера обновлений которые обновляются допустим с мобилок то это про про паблик про проблемы с лет инси в сетях вай фай проблемы с 3g сетями если все-таки через них перед ними стоит еще балансировщик с которыми с которым тоже может быть что-то не так кластеры только из всего этого состоит инфраструктура далее поисковый сервис epn с которыми взаимодействие идет через open то есть наши поисковые сервисы это некая обертка над библиотекой которая из библиотеки делает сервис здесь тоже есть инстанция как api которая передает нам запросы и выводит пользователю ответ маленько вперед тестирование в одессе и в частности в нашей команде это как наверное и везде у нас есть и не тесты и вы не поверите их пишут разработчики регрессионные тест нагрузочные ну хай-лоу же все-таки функциональные частично все это ну а довольно большую часть это все автоматизировано и сейчас немножко отвлечемся от тестирования целом я немножко заспойлерил тестирование самолетов компания как-то нам проводила экскурсию на завод где это такие самолеты испытывают как это примерно происходит строят опытный образец ставят и опыт нагрузку то есть огромный ангар в нем стоит самолет обвешанные грузами которые его всячески выгибают выгибают растягивают оказывают давление и так оставляют лет на так оставляет лет на 5 10 запуск в это время другую модель и уже запускают в эксплуатацию если все это все остальные испытания пройдены самолет стоит на стенде то что мы имеем в принципе даже если даже если на стенде что-то что-либо случается то авиакомпании есть такой запас на 5 10 лет как состав воздуха по которым летает самолет в принципе не меняется мысе мы не можем сделать то есть чего нельзя сказать о о запросах в наши сервисы тут немножко статистике топ-5 запросов за за прошлые за этот год как видите ну есть совпадение но при этом они довольно разительно отличаются и это только за последний год то есть строки 5-10 лет для нас просто дадут просто фантастическую разницу если мы говорим про сервер обновлений то платформы которые сна скачают практически все передвинулись на пару единиц по версиям если смотреть на 5 10 лет то мы увидим что вообще не совпадают то есть было только windows ну по крайней мере в нашей глухой сибири собственно про почему функциональное тестирование вообще почему я сегодня про это рассказываю мы столкнулись парой проблем как раз таки проблема о которой я буду говорить так clicker немножко спешит проблема которую мы назвали проблема 34 кто-нибудь слышал это название нет хорошо кто-нибудь пользовался наши мобильные версии падаю с есть руки но лучше рассказать о чем когда мы только запустили выпустили нашу мобильную версию мы выпускали на ios и windows phone произошла такая не очень приятная ситуация markets appstore и про прочие ресурсы на которых агрегировать отзывы там везде пестрела цифра 34 пользователи за рук жаловались что загрузка у них обрывалась на 34 процентов то есть большинство пользователей вот называли именно эту цифру происходило это не потому что наши сервера не справлялись происходило это по той причине что платформа ios не совсем корректно обрабатывалась вопрос-ответ от индекса перенаправления получилось так что в то время как скачивались файлы размазанные по нашему кластеру покачивался один файл за другим файлом он шел на какой-то другой сервер или пытался получить его на этом же и вот там не оказывалось джинкс посылал redirect на другой сервер ews просто обрывала соединение то есть это не проблема функционала именно мобильного это не проблема проблема того что сервера него на его возили нагрузку это проблема когда нагрузка и функциональным шли рука об руку следующая проблема на этот раз и сходными запросами у нас на наш поисковую следовать пришел запрос и выполнялся как вы думаете сколько цифр и три-четыре дня хорошо еще варианты будут неделя хорошо десять дней десять дней у нас до сих пор висит в кабинете это страшная цифра в миллисекундах дефекты слова request многозначная цифрам собственно струшу что произошло библиотек библиотека который вы лежит внутри нашего бэг-энда на не все это была отлажена на ней-то все работало наш бэкон также работал а вот вместе вышло вот такая интересная проблема я могу конечно сказал сказать что это был вопрос но вы полезете в интернет и будете натравливать ну это не страшно потому что мы уже этапа пиксель поэтому если кому то интересно могу назвать этот запрос а ну хорошо запрос итальянская кухня то есть вы можете конечно позадавать на сайте этого просто запрос но должного эффекта это не возымеет то есть мы понимаем то есть эти две проблемы это понимание того что функциональные тесты каким бы вы холодам не были они все равно для вас важны так забыл спросить тестировщики или около того в зале присутствует счета маловато но ладно напомним напомню что такое ну все наверное знают что так функциональный test that is который проверяет определенный функционал то есть по сути он отвечает на вопрос да или нет если подумать что еще из этого можно получить вот-вот проводите тест который отвечает на вам на этот вопрос что еще можно извлечь из этого ответа отлично время во первых если это backend время отклика сервера затем время получения ответа клиентам то есть время полного цикла от запроса до ответа и время отклика компонент если речь идет о какой-то довольно сложной системе теперь откуда мы извлекаем время но ноги у нас обе собирается voxtel также у нас есть мониторинг ну он у всех есть поэтому нет ничего такого сверхестественного иногда данные собираем сами этого особо военное время когда что-то очень сильно ломается такое было давно так также еще есть такая вещь как утилизация ресурсов и при прогоне тестов и и неплохо бы учитывать то есть тут приведены на самом деле довольно общие характеристики наверное раз уж тут не так много тестировщиков тут есть люди которые различают типы памяти которые используются по различает типа типы использованы зримой памяти в.м. сайт rss есть такие люди отлично они есть они еще не вымерли операции чтения записи в секунду и различные сетевые характеристики как итог этот тест не будет ровным счетом ничего значить потому что это может происходить потому что кто-то кошмарит соседей по virtual по виртуалке то есть у нас обычное дело запускается импорт все ника никаких тестов потому что все буду все будут красными даже нас на самой стабильной версии просто потому что ну системы виртуализации с хорошей изоляции это уже не тот не то прям что можно использовать для совсем тестовых версий то есть обычно это какой-нибудь open возник вымыли бокен но изоляции помоему изоляцию по одесскую никто так сильно не предоставляет из них это может быть из-за проблем сетью то есть либо у нас все все массово что-то обновляют либо просто идет нагрузка на сеть можно конечно все это все это помнить и проводить тесты с учетом всего этого то есть смотреть на часы так вот сегодня там со скольки то тальки это будет импорт потом админы буду делать бэкап потом можно запустить тест на можно держать это в голове можно мониторить но это будет огромная куча метрик притом метрику для мониторинга буду делать в метрике для импорта или backup а будут делать те кто делает этот импорт или бэкап и разобраться с ними вам будет ну довольно проблематично можно уточнить чтобы не держать все это в голове но для этого нужно больше тестов как как их организовать то есть их много им нужна какая-то организация чтобы мы просто не не запутались то есть мы организуем но при этом их немножко делаем хаотичными вносим некоторую терапию мы не фиксированные запроса просто категории кейсов то есть мыслям категориями не конкретными запросами зачем все это делать потому что например для негативных кейсов они могут быть зак заткнут иска исключениями у нас и притом исключениями не на уровне кода которые написали вы на уровне кода используемых компонент нас была проблема когда на уровне джинсы у нас была закинута исключение вот и я могу боюсь ошибиться но и то есть это все проверялась потом мы обновились это проверяется перестала и мы несколько огребли зачем нужна рандомизация у нас сервис по крайней мере те что я упомянула сном стоительство то есть поисковый сервис ну одних и тех же данных выдаст один и тот же запрос один тоже ответ по запросу сервис поиска проезда сделать аналогичные с маршрутом но однако не стоит забывать про то что есть кэширование поскольку если у нас есть кеширование то подача одного и того же запроса нам дает вообще не точную картину вот если все-таки вносим state full то мы просто можем фиксировать состоянии как мы не делаем и делаем как в предыдущем слайде методы которыми это можно сделать но самый топорный метод попросту тупы берем рандомизированы в авто тестер все это этот подход называется fighting от английского фас шум но на русский его часто переводят вот мне попадалось книжка facing тестирование методом грубой силы не знаю почему так перевели но суть этого метода в том что мы просто скармливаем различную рандомную фигню нашему сервису и как вероятность найти бак таким способом ну крайне мало то есть вернее на не то что крайне мало оно не определено никак то есть да это можно использовать ну вот у нас это выстрелило один раз в мой самый первый рабочий день когда ну то есть я не особо не особо в этом всем шарил и просто вбивал рандомные запросы и сервер меня упал пал на пустом запросе ну ничего удивительного а теперь такой более хардкорный случай ортогональные массивы вот здесь подписано цвета но на самом деле в наших реалиях красный это негативный тест зеленый позитивный голубые там у нулевое значение или отсутствующие значение как составляется ортогональный массив то есть мы перебираем все сочетания сначала для 1 2 столбца потом так же для второго и третьего для первой для 2 и 3 и получаем что у нас для по сути трех вариантов для трех полей есть ну двадцать семь вариантов перебора это несколько много то есть и если брать какую-нибудь валидацию сообщение или файл и ну вот у нас городов допустим если мы говорим про сервер обновлений порядка сотни платформ ну чтоб 5 точно и если все это считать то ну мы просто создал боимся все это вводить то есть дай у нас были тесты которые все это пытались перебрать но их читать и поддерживать было довольно сложно ну и теперь тот способ который позволяет обойтись без а то канальных массивов по и вайс комбинации пар то есть мы уменьшили число таких переборов казалось бы зачем нам уменьшать число если мы ратуем за увеличение количества тестов просто потому что за тестами удобнее следить и то есть мы можем пробую прогонять их без большим количеством итерации и при этом сохранять покрытие то есть у нас тесты используют библиотеку pages у нас пишутся на питоне и автотесты немножко позже про это тоже скажу вот ей очень удобно делать вот такой перебор и это все получается лаконично и при этом обеспечивает покрытие как можно визуализировать результаты тестов потому что если кто-то пользовался дженкинсом на котором у нас теста запускаются кто пользовался дженкинсом для запуска тестов не для сборки то читать выхлоп дженкинса на linux новой машине который у которой плохо со шрифтами но это верный способ сломать глаза и психику то есть есть такие средства визуализации которые помогают обобщить результаты просто при одном взгляде понять что вообще происходит можно это сделать цифрами тут немножко такой такой консольной магии ну что делает эта команда в принципе понятно то есть просто сортировка списка что делает вот это есть соображение да какая aug не-не-не она не останавливает процесс это команда просто которые это эта команда выводит как раз таки то про что я буду говорить 95 процентиль то есть величина котлы которую не превышает как которая больше чем 95 процентов запросов то есть у нас мы сортируем выборку то есть выборки у нас время отклика затем с помощью этой команды мы получаем вот как раз показательную 90 95 процентиль по которой можно судить укладываемся мы высолы или не укладываемся ну то есть график у нас используется zabbix но zabbix настраивать обычно сложно то есть у нас даже какой-то тестовый zabbix на котором мониторится стайлинговые сервера делать на нем отдельный график это ну это во-первых время во вторых это здорово отвлекает у нас была проблема что мы что постоянно тестировщики создавали графике но в нашей команде они краснели естественно и постоянно сыпалось кучу куча писем от zabbix а что ребят вот у вас там поломка это то есть получался такой мальчик который кричал волк ну естественно мы это быстро разделили сейчас мы используем систему отчетов в в наших тестов называется аллюр сделана она в яндексе и дружит ну вот насчет остальных языков программирования не скажу у нас все пишется на питоне с питоном она очень сильно дружит тут можно заметить что как тесты там помечаются как сломанные то есть сломаны есть файл сломанные когда у нас сломан сам тест как кот field и именно что мы при проверке не обнаружили как у нас не совпало ожидания с реальностью это довольно здорово потому что при несовпадении копать питоне лог который при разрастании park auto тестов становится просто огромным это но несколько неудобно так же тут указано время выполнения каждого теста и можно посмотреть какие какие то особо выдающиеся кейса вот здесь выхлопа собран по тестам то есть ну вот допустим мы сломали у нас с тесты красные как на предыдущем слайде тесто не сработали внимательно смотрим во первых на запрос во время и ресурсы ч я забыл время ресурса сам запрос я что-то забыл на самом деле забыл про такую вещь как предыдущие запросы у нас с поисковым сервисом был случай мы как нас поисковый сервер но тестов падал то есть и все время падал на различных запросов мы не могли понять чем дело ну и тут кто-то догадался посмотреть что предыдущий то какой то есть и у нас предыдущие запросы по моему ленина да это был запрос ленина на новосибирске хотя и для любого другого города россии в принципе подойдет потому что объектов с названием ленина довольно много на постсоветском пространстве и на запросе ленина у нас он что-то выдавал и при этом падал и уже следующий не проходил ни потому что не проходил запроса именно потому что не проходил предыдущий допустим у нас все тесты прошли все хорошо если тесты прошли мы смотрим еще внимательнее то есть особенно пике тут пике нарисованы красным они обагрены кровью при севших на них разработчиков которые вот эти по той вот эти пики которые вылезли на продакшене то есть на тестах это можно отследить еще не падениями а просто какими-то пиковым значениями теперь про процентили 95 лучше 98 процентиль то лучший показатель ну тут немножко капитанство потому что уже я не первый про это говорю самый первый доклад на который я пришел пришел на этой конференции там так там про выбор in memory database кто-то слышал его вот по-моему в этом же зале вот и там докладчик рассказал что почему средний брать плохо там еще не несколько уже сейчас не вспомню кто в общем не буду приводить банальный пример со средней температурой по больница у нас был случае вот с обновлениями когда не только начинались сервер обновлений когда он только эта версия когда только начинала разрабатываться у нас получалось так что куча запросов с с двухсотым кодом просто обрывалась то есть время 0 код 200 все хорошо но а те что проходили но это как раз таки была связана с платформами те тесты которые проходили они очень долго выполнялись virtual koch ну и то есть по среднему мы вообще за и силы укладывались в действительности у нас половина запросов не обрабатывалась половина обрабатывалась медленно то есть вот пример из практики ну то есть вот я вам что-то рассказываю но тут файлов же все таки вот где где как бы highload в рассказе все очень просто мы просто нагружаем сервер делаем это линейная ну на самом деле зависит от но линейно проще следить и не обязательно это делать какой-нибудь нагрузочной утилитой мы сейчас используем гатлинг то есть штука написанное на скале в которую включены и отчеты на которых можно видеть вот здесь допустим отправка сообщений 95 процентов 134 а средняя у нас чуть-чуть вот за и силой выходит лишнее подтверждение то есть готовим вообще довольно удобная штука там можно делать различные профили нагрузки и не обязательно знать скалу то есть там довольно простой dsl который позволяет описать профиль нагрузки скалу нужно знать если вам нужна какая-то кастомная фича для отправки до отправки или скачивания либо мы можем сделать еще проще просто отзеркалить трафик сбоя на какой-нибудь хост через им прокси или гор теперь так как так как у нас виртуалке все-таки то есть если делать это на боевых серверах то там все просто ну в им прокси там можно указать какую часть трафика слать арифметика масштабирование просто можно зайти на любой хостинг ппс of посмотреть различные конфигурации у себя попытаться на инфраструктуре их воспроизвести то есть выстроить зависимость то есть это вот нашего поискового сервиса сделанные на коленке то есть на самой низкой конфигурации у нас просто не хватает памяти сиквел птица падает все запросы не проходят дальше запросу медленных запросов больше и вот и вот здесь можно отследить зависимость на ее основе вычислить соотношение какой-нибудь как какой у нас будет на bayou ну все теперь можно функциональным проверять действительно так ну сегодня я рассказал что можно извлечь из тестов почему результат одиночного теста не показательны как с этим всем разобраться и что примерно должно получится как-то так теперь готов ответить на ваши вопросы так не работает вот избирать спасибо большое за доклад скажите как вы решаете самую главную проблему вот этих всех функциональных тестов это уст реване и функциональных тестов и ошибки функциональных тестах какого рода ну такого рода что они вроде как написанные вроде как работают а зелененькие все но приложение просто лежит на они зелененькие или приложение выдает 500 ошибку они как бы зелененькие ним и вообще следим за этим я говорю что у нас не только данные которые поступают из тестов чтобы мониторить то что приложение лежит допустим в том же питоне есть утилита пошутил если знакомы с максом то есть команда ps который выдает информацию по процессам с помощью этой штуки можно мониторить состояние процесса то есть это во первых во вторых ответы сервиса но такое что сервиса дает пипец 500 стенд показывает что все правильно но вот с таким мы наверное не встречались но как это что сервис лежит можно проверить ps utils или ну просто просто логик для науки то есть их это никто не запрещает делать ответил на наши вопросы или нет так тогда можете поподробнее сказать что вы все-таки имели ввиду так вы слышали что-нибудь про мутационные тесты вот такую технику вы не применяете это понимаю нет к сожалению пока нет ну то есть если в тестах допущенные ошибки вы никак их не исправите почему как дней тестов обнаруживаются ошибки мы это исправляем а как вы их обнаруживаете но у нас у нас во первых есть station на котором это все можно посмотреть ну и плюс на пока показание только авто тестов сложно полагаться поэтому у нас параллельно с тестами идет мониторинг то есть так чтобы врал и мониторинг и локи и сами тесты но вот такого не встречалось то есть но если кто-то один вред это всегда можно отследить и исправить но у вас руками прокликивайте все тысячи тысячи тестов что ли этот метод это автоматически то есть тест тесты все автоматизировано на кнопку у нас тесты написаны на питоне это автоматические проверки то есть никто вручную это все по чек-листу не делает а кто говорит что тестах написано правда кто за это отвечает тестировщик которых пишут его никто не проверяет то есть он напишет все что угодно там и все и вперед так что но программиста проверяет тестировщик ну знаете это получится что программиста проверяет тестировщик кто там нужен чтобы проверять тестировщиками кто-то нужен что проверять того кто проверяет тестировщика но как строчек это ну человек должен быть ответственным то есть у вас все на человеческом факторе держится до нет авто тесты проходят review то есть тут двойная проверка то есть авто тест а также проходит проходит review как код который разрабатывает тестировщик всмысле разработчик работу разработчики проверять тестировщик то есть если татуировка пишет автотесты это вот у нас выносится на review команды команда делать какие-то замечания вы вы хотя бы на это хорошо такие спасибо здравствуйте спасибо за доклад здесь вопрос такой вы заявили тему функционального тестирования но коснулись ещё нагрузочного вот скажите где у вас проходит грань и мне показалось что у вас эти процессы как бы смешаны в один верно ли ну здесь да вот как раз для отлова таких случаях их приходится смешивать потому что я опять же говорю вот те две проблемы это не не именно функциональная проблема не именно нагрузочная проблема этого лично что происходит на стыке то есть запрос который у нас на нагруженном нашем сервере сервисе застрял на библиотеки он отрабатывался нормально то есть тут с плафоне вот этих двух факторов позволяет выявить вот такие проблемы да конечно да гости спасибо за доклад у меня может быть немножко частный вопрос вот я знаю дубльгис я им пользуюсь и будут коснулись того что вот вас были запросы ленина то есть вы проверяли полнотекстовый поиск с помощью теста мне вот интересно как вы проверяете что это вот ну что выборка который вас получила с помощью тестов она валидная вас есть какой-то мастер выборка что она должна совпасть потому что просьбой так выборка по тестам да то есть он 1 и потестируйте запрос ленина да и ну а если например запрос будет короткий просто лиан как вы проверяете что это выборка она адекватный понятно по изъятию я вас понял дело в том что реван релевантность поиска то есть это проверяется на уровне библиотеки у нас гигиены и в основном запросах которые основаны в частности на то есть есть у нас такая вещь как слова ге то есть какой-то хранилище запросов на карты с которыми мы в свое время имели проблемы это ну при регрессе естественно все прогоняется вот но так что прям покрытие вот именно по потёк по тексту но то есть наша задача это обеспечить чтобы библиотека нормально отрабатывала ну в условиях считала то есть ты просто смотрите валидность же сам ответов или что но он просто нет интересно как именно что эта выборка она адекватные понятно пользователя потому что там же еще нечеткость накладывается какой-нибудь поиск с ошибками выгода до поиск по ошибке но у нас вот такие кейсы новых кеес там допустим поиск ну то есть выбираем слова в питоне скрипт делает специальную ошибку вот такой кейс проверяется там пустой запрос или там есть у вас есть какой то вот вы делаете запрос и вам приходит выборка и и сравните с какой-то идеальной как дамы мы сравним с выборкой от которой которой именно выдача библиотеки то есть вытащить затем я teka но в библиотека это наша разработка огня здравствуйте вы запускаете тестов на продакшен серверах естественно есть какие-то тесты которые модифицируют данным например так так так мы на продакшн серверов не запускаем тест не запускайте просто речь шла о том что я так понял на продолжим см и наоборот вся вся эта все это масштабирование она то есть это проблема которую мы схватили уже нам уже при боевом использование проект проблема про который я говорил я понял он тогда вопрос снимается потому что речь шла о том что вы вначале тестируете на одних данных потом на реальных данных возникают проблемы которые нет нет нет нет вот и вот именно вот эти проблемы которые отчасти сподвигли несколько как такому подходу ну хорошо спасибо спасибо за доклад не вопрос примерно следующее в какой момент вы запускаете тесты то есть это релиза на и тесты перед тем как делать релиз это какая-то регрессионных по вещам или это например там какой-то постоянный процесс континент играешь или так далее у нас эти тесты как они встроены дженкинс то есть при каждой сборки они прогоняются как в процессе тестирования пока метильные фактически а сборочный посмотришь на это скорее да добрый день спасибо за доклад вопрос такой вы сказали про эту итальянскую кухню злополучную ваша вот как то что там то что вы в докладе описывали можете вот на конкретном примере сталинской кухне каким образом вам бы помогло заранее найти эту проблему двора не вояки эту проблему но я такой не что к этому да да то есть но с этой проблемой нет но вот допустим как давайте я сейчас расскажу как это так у вас или у меня хорошо я сейчас расскажу как это бы помогло нам с серверами обновлений и чуть позже стивеном на линии это нам помогло бы тем что если в моего то то действительно нормально проверили на конфигурации близкий к бою там и естественно не получили бы этой проблемы то есть либо ее как-то бы обошли с запросом итальянской кухни ну то есть мы бы заметили что этот запрос у нас не отрабатывается и ну и уже вопрос дали бы команде которая разрабатывает библиотеку что что вот у нас когда все происходит возникает проблема то есть и мы бы сейчас то есть мы бы в таком случае работали уже с нашим сервисом зная о такой проблеме мы могли бы ее воспроизвести то есть и получить полную картину того почему это произошло не очень понятно просто как можно вообще догадаться вести именно итальянскую кухню ну как я говорю что этот подход возможно не дал бы прям сто процентов нам этот запрос но как такое покрытие на с большей вероятностью позволило бы нам напороться на это не на продакшн а на каких то на начальном этапе то есть если я не ответила на ноутбуке и понятно спасибо спасибо за доклад как я понял у вас одну и ту же функциональность с прогонять несколько тестов правильным вот аж то происходит если вот один тест какое-то в одной функциональности упало все другие сработали вы это игнорируете или нет нет ну если он упал значит на то есть причина эту причину неплохо бы выяснить то есть даже если это сеть или еще что-то вы всегда выясняете ну во первых это все мониторится и можно посмотреть сеть это или нет во вторых этот вопрос можно запомнить и уже провести сессию тестов именно с этим запросам спасибо илья большое спасибо за также еще один вопрос коллеги ловите докладчика на выставке большое спасибо"
}