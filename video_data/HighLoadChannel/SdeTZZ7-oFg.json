{
  "video_id": "SdeTZZ7-oFg",
  "channel": "HighLoadChannel",
  "title": "Как мы делали отказоустойчивый Redis в Yandex Cloud / Евгений Дюков (Yandex Cloud )",
  "views": 821,
  "duration": 1986,
  "published": "2023-10-06T07:23:23-07:00",
  "text": "Всем привет Сегодня мы с вами про отказоустойчивость в редисе поговорим вот я сразу сре скоп то есть мы с вами будем говорить про редис про Сель про кластер имм см будем не поговорим про альтернативные реализации типа kdb или dragonfly db мы не поговорим про экспериментальную штуку R raft и мы не будем пытаться справиться с ситуациями Когда у нас проблемы с дисковым IO и план у нас с вами сегодня вот такой Сначала мы поговорим о том Зачем вообще в редис отказоустойчивость Ну для случаев Если вы например предыдущий доклад В этом зале пропустили и не знаете что можно вреди такого интересного хранить можно потерять потом мы поговорим о том как отказоустойчивость сделана в селе как она сделана в кластере какие у этих решений проблемы как мы с ними боролись в момент когда запускали Яндек Cloud Потом посмотрим на альтернативный подход который применяется сейчас рассмотрим как в этом подходе реализован бытует такое мнение что дис Это только кэш то есть в редисе можно хранить только какие-то данные которые Вы не боитесь потерять кото можете откуда Из какого-то основного хранилища восстановить Ну в начале когда Мы начинали делать для тоже так думали нони пользовательские сессии там его использу для митинга и так далее и Давайте вот с вами один пример посмотрим с очередями Представьте что у вас интернет-магазин и в этом интернет-магазине у вас примерно такое устройство То есть у вас есть пользователь он делает какой-то заказ он прилетает в ваш энд вы в этом энде в какой-то постоянной сто там типа что-нибудь сохраняете данные шике которые будут делать посылку письма Они сделаны сбоку и для того чтобы им послать пись вы в очередь вре складывайте Ну пример такого воркера может быть код НАТО который на Сере реализован например и по какой-то причине если дис потеряет эти данные то пользователь письмо не получит Конечно можно сказать Ну да конечно Ниго вмагазине дать возможность купить что-то не регистрируясь регистрацию сделать тоже в фоне она у вас тоже будет в очереди вы пользователю отошёл в личный кабинет Если вы ещё и это письмо продол бае Ну к сожалению пользователь не получит информации о вашем заказе например не сможет его отменить Окей коне э проблема Не новая и в самом рее Ири были решения Такой проблемы Вот например первым появился Ну в составе самого редиса Что такое это специальный такой механизм запуска сервера То есть вы можете взять бинарник сервера переименовать его запустить как некая сущность отдельно от самого редиса То есть это отдельный процесс тоже однопоточный он тоже общается таким же протокола и с точки зрения клиента сенлем всё выглядит примерно следующим образом вы приходите в сентинель спрашиваете А где там ри или где реплика такого-то ключа ну этот ключ это собственно Имя вашего и он м отвечает вот он и коте к этому работаете с ним если у вас Коннект порвался то вы начинаете всю процедуру заново То есть вы коннекте к сенне опять спрашиваете и идёте опять в й возможно в тот же самый при этом са он может много таких вот кластеров обслуживать то есть вы можете к нему там хоть их сотню хоть тысячу подключить Главное чтобы вы там на самом Сен или в сетку Не упёрлись ну или в его одно поточность всего этого вытекают ну примерно такие фи во-первых вам не надо указывать какие у вас там реплики вы просто СН показываете primary реплики он найдёт сам при этом он может да вот множество таких кластеров обслуживать там есть паса для топологии во многих библиотеках это используется То есть вы можете при коннектится к Сен Нелю и он вам в фоне Если вы конект продолжаете держать сам Ну и подпишитесь при этом конечно на события но вам сам будет рассказывать что вот в таком-то КСТ сменился мастер теперь такой-то или там в таком-то кластере появилась новая реплика это Удобно вам позволяет не делать три дополнительно вот там тот же самый протокол 2 и 3 и соответственно с точки зрения там клиента интеграция выглядит проще потому что вам не надо реализовывать дополнительно какой-то ещё сес Discovery Если вы умеете котиться к редис Том Вы общаться тоже умеете следующий если мы по истории будем идти механизм это кластер суть его в том что у вас есть ное количество шардов вы коннекте к шардам дела специальные запросы для топологии и э ы Хосты этих шардов они друг дружко обмениваются госпо информацией о своей топологии о живости о том как они вообще видят этот кластер и так далее И при этом там происходит кворум мастеров можете проголосовать и выбрать себе нового мастера если у вас каком-то из шардов Мастер упал ва сам кластер встроено вам достаточно просто опцию включить при этом благодаря тому что вы голосуете именно мастерами вы можете шарды делать не очень там равномерными например у вас может так оказаться что в одном шар у Вас могут быть реплика Ну там например у вас есть две реплики один и вот реплика и в одно дас это пере жит это марити ваших мастеров и при этом с точки зрения клиента Если вы умеете работать среди с кластером то отказоустойчивость у вас есть из коробки есть вам это не так как с сенлем Где у вас может быть кластер с редисом обычным Вы с ним работаете но так как там нет то нет отказоустойчивости Ну конечно же эти решения не без проблем Иначе мы бы с вами сегодня здесь не встречались и первая проблема у них общая partitioning primary не закрывается от нагрузки эта проблема известна давно про неё в рассылке ещё писал такой товарищ с Ником аир который потом сделал сайк jepson давайте мы на пример конкретный посмотрим представим что у вас есть вот такой вот допустим шарт или это ваш польный редис У вас есть там некий дис О он является у вас с ним приложение общается Потом у вас происходит и так вот вам не повезло что у вас приложение вместе с этим вашим редисом осталось отрезанным от всего остального ваше приложение продолжит писать в этот редис Если вы там не используете специальных всяких механизмов а И когда у вас партишен прекратится То есть он захи если в той половинке где остались остальные Хосты выбрался новый праймери все данные которые вы записали на время партишен будут потеряны следующие проблемы они немножко различаются Ну для нас сентинель был проблемной штукой потому что вы не можете запустить один большой сентинель на всех как бы в Яндекс клауде и сказать ребята все живём вот здесь есть пробле с изоляцией Ну например вы не сможете скрыть клиентов друг от друга все клиенты будут видеть всех ну и там есть ещ всякие команды которые могут быть тоже опасными например можете попросить сделать в современном Реди это можно закрыть вот следующая проблема Это если вы не вы може породить не отказоустойчивый конфигурации Ну например вас приходит Клиент говорит Я хочу чех ядерные вот меня на одном ядре будет на одном но я хочу таких хостов два К сожалению это не изза голосования только пра имеет значение количество шардов один шард не отказоустойчивый потому что единственный способный голосовать если упадёт то всё Никто не проголосует за выбор нового и тут же опять же из-за этого есть следующая проблема что распределение их по доменам отказа иние ВНО Остане в пока не прит человек и не разрулит эту ситуацию нам надо было облако запускать поэтому мы не могли сидеть придумывать какое-то супе умное решение мы решили придумать такой набор костылей которые все эти проблемы каким-то образом порешает и потом уже думать над правильным решением и бы чуть-чуть данных Те кто не согласен они там делают специальные конфигурации типа используют Wi команду поэтому мы можем парти primary закрывать то есть на машинах с редисом крутится специальный демок который проверяет доступность всего остального кластера если он заметил что случился Network Паше такой конфигурации что там в оставшейся части будет выбран новый primary то он локальный переводит в protected Mode ну отрывает все клиенты вот там по ссылочки э есть демка на гитхабе суть её в том что там небольшой кусочек кода который вот мы в продакшене использовали он там Заимка которая сетку ломает собственно можно посмотреть как э будет кластер работать с клозе как он будет работать без клозе И сколько данных будет теряться спойлер разница на пару десятичных порядков вот следующая вещь - Это мы клиентам говорим Ну ребята давайте вы будете ставить рядом срем а мы просто в документации напишем что два ста не отказа устойчивы вы данные будете терять к нам приходить мы вас будем документацию тыкать и говорить смотрите мы там документации написали что вы делаете неправильно следующее это с шардирование ТХ шардов клиент просто не скау кон за тем расположены в доменах отказа и соответственно приводить равномерно распределению понятно что все эти решения не очень хорошие Да во-первых так как мы закрываем закрываем не сразу клиент чуть-чуть данных вс-таки теряет следующее Ну тяжело объяснить пользователю который потерял данные что на самом при Это для других клиентов которые хотели бы использовать кластеры хотели бы расти как-то органично Да прийти создать один кластер с одним Шарм потом там сделать два шарда три шарда и так далее для них это дорого они сразу вынуждены начинать с трх шардов поэтому люди сейчас приходят и создают три шарда по одному хосту Вот и распределение пово ме происходит то есть вы только что повелись потом приходит этон смотрит горит Так тут както неравномерно распределено сейчас мы ещё раз сделаем поэтому клиент просто будет двара подряд им это тоже неудобно Ну у нас уже есть решение для Масик и для поса давайте мы просто храним Ну запускаем такой агент назвали его RD syn он по аналогии там с PG синком My сиком э для постгрес и Масик соответственно Он держит к в DC Ну dcs - это если примеры приводить то это etcd Z Keeper consol В общем распределённая конфигурационное система Да а и в ней держит небольшие ключи с информацией о том что он знает о кластере при этом так как вот остаётся механизм мы заменили на специальную сущность которая называется и о ней мы чуть-чуть подробнее там попозже рассмотрим так Ну у ролей представленная сущность держит и при этом он следит за состоянием стера принимает решение о том что надо делать Ну и соотвественно производит необходимые действия для того чтобы произошел и плюс он же делает всё тоже само Что делает кандидат вот кандидат - это нода которая пытается стать менеджером есть она пытается взять при этом что был вид е со стороны кандидатов на случае если у вас там какие-то странные сетевые неполадки Когда например Prim не видит какую-то реплику но при этом сама реплика видит dcs то есть чтобы мы там лишний раз кластер не размыва вот и он обновляет состояние в локальном чтобы работа при этом получилось что кандидат оказался на машине с и он потерял конект с DC то он локальный закроет такая же та же самая закрывашка которая раньше была вот значит с с антиш значит в чём проблема да можете пойти и написать код там какой-то с нуля Да например изобрести нашем любимом языке программирования тотже сай проко всеми же теми же самыми командами но Беда в том что разные клиенты делают это по-разному есть какие-то Клиенты они приходят и просто на pops подписываются и ожидают что им в паса всё будет приходить какие-то приходят и говорят Get Master by name а какие-то приходят и листает просто всех мастеров и там дальше найдут какие-то из них наоборот там реплик хотят полистать а какие-то вообще заходят в инфо и там в конце в последней строчке в инфо тоже есть информация о том кто мастер её же можно просить прекрас вот поэтому мы просто сделали следующее мы взяли отрезали оттуда ВС то что про И вообще про какие-то внешние коннекты то есть мы оставили только те команды которые читают Вот это внутреннее состояние которые нужны для и сделали отдельную сбоку команду которую дёргает сам О вот это внутреннее состояние соответственно обновляет Ну и это же команда она генерирует сообщени в случае если состояние поменялось то есть ни у кого ничего не сломается если они будут использовать Ну давайте мы с Вами рассмотрим как будет происходить то есть вот у нас конфигурация слева такая была жил се был какой-то кластер у него был на этом на этой же машине был расположен и он был менеджером DC и е реплики вот отрезан от всего остального значит что будет происходить первым делом произо два процесса практически одновременно сначала так как г потерялся DC то один из кандидатов его схватит и станет новым менеджером при этом тот вот пере специальный ойн режим тут звёздочка Не просто так этот олан режим Он не доступен в обычном редисе это наш пач на суть его в том что это такой же про как обычный про но он не Перси в ко все редис всегда взлетают в про в о режиме и сам снимает это нужно для того чтобы ЕС откры два мастера которы принимают на запись или не оказались ситуации когда у вас выключен Вы перезапустили у вас на Мастере пустые данные реплики к нему радостно подсоединили и все свои данные по удаляли так идём дальше выбранный нами Вот этот менеджер он пытается выяснить вообще в каком он состоянии оказался есть вообще может ли он делать может так казаться что осталось слишком мало нот чтобы выбирать потому что репликация как бы мна вы там можете данные потерять Ну это зависит от настроек можете настроить Так что Ну давайте терять данные соотвественно нано вешает там находит Какая из них самая последняя и дальше он делает следующее действие он останавливает репликацию То есть вы берте Горите зачем это нужно Затем что у вас вот э потеря может быть не полный может быть такой что вам недостаточно работоспособности сети для того чтобы держать или для того чтобы проходить чеки но по какой-то причине репликация у вас иногда умудряется просачиваться тогда ко остановили репликацию то есть на Мастере у вас даже если ом там как-то частично доступен запись станет колом и вы дальше можете смотреть на эти Осе их как-то сравнивать друг с другом вот теперь когда у нас понятно кто самый последний на самом демы можем приоритетную ноду они недат эту саю приоритетную до самой последней поету догнать тут тоже звёздочка понятно это тоже недоступно вре тоже там не очень большой не очень сложный па то есть начинаем делаем вот эту машину репликой органи реп если у вас реплика которой вы подключаетесь мастера не видит просто запретит это делать соответственно мы получаем такую машину на которой У нас есть максимальная максимальный приоритет прекрасно мы её можем проти и мы её пром но сначала она будет находиться в режиме чтоэто выставляете взнание Нида в жизни не будет например 65535 реплик все клиенты которые будут пытаться эту реплику писать они будут отваливаться зачем это нужно для того чтобы вы сделали следующее действие чтобы вы повернули реплики на этот пра Ну те которые Понятно можно синком догнать и у вас кода как только вы откроете сразу же мастер примет запись и упадёт вы данные не потеряли Ну дальше мы соответственно дожидаемся пока там всё за синка ется и открываемся на запись после этого в какой-то момент времени в будущем у нас почини сеть Что произойдёт вот этот RDS который там остался Он увидит доступный dcs и сможет прочитать информацию о том что он уже не мастер мастер вон там э и ему надо бы поворачиваться он делает следующее он берёт э поворачивает свой вот этот оффлайновый редис в новый ри дожидается пока этот редис до синка ется и оффлайн соответственно снимает получает редон реплику Вот вот и весь как бы механизм ну понятно что тут недостаёт информации ещё об одном патче этот патч Он про кворум ную репликацию в редисе так всё это тестировать не так просто как хотелось бы поэтому у нас есть два набора тестов первый набор тестов - это функциональные тесты где у нас предопределенные сценарии Да ну такие там се берм ставим кластер из двух хостов убиваем дожидаемся что второй стал или там берём кластер делаем отставание искусственно убиваем пра убеждаемся что никто не запл и так далее Вот и у нас есть отдельный сет тестов с Джеп где мы поднимаем пачку контейнеров и дальше джепсон там развлекается ломает по разному эти Хосты но он делает только есть делатт штуки с убивания девяткой или там с нарушениями на диске по той причине что в реальности мало кто использует в редисе прямо Син на каждую команду потому что это очень медленно поэтому мы тут реалистичный сценарий тестим Вот и вот эти джепсон тесты они очень похожи на те тесты которые в манке и там в нке я Пропой Да в там Яндекс треке вечером сегодня будет доклад про My там можно будет тоже просон тесты послушать и их на гитхабе посмотреть вот собственно Итого очевидно что наш путь это не что-то новое первая такая Академическая работа о том это в проше используется писали суть такая что вы берёте в вашей системе консенсус выносите в некую систему которая вот только вот вам распределённые Локи там и value Stage обеспечивает а всё остальное у вас работает полагаясь на эту систему и собственно по этому Перу был написан zuk второе - это то что Пать дис в принципе не так сложно там Всё достаточно просто просто пишешь на си и там всё одно поточно Вот и если вы данные терять не хотите то Используйте джепсон Это хороший фреймворк для написания тестов единственная его проблема то что он на к ажуре Спасибо за внимание тут вот можно будет оставить обратную связь Вопросы Спасибо друзья первый вопрос Да здравствуйте Спасибо за доклад Угу Угу У меня вопрос видимо немножко не в тему доклада очень долго работал Следующий вопрос пожалуйста Нет он как бы про редис И про всё прочее просто про это не было упомянуто шардирование То есть как решили проблему шардирование Когда клиенты собираются кластер расширять они сами руками делают или вы автоматические механизмы предоставляете там есть при добавлении шарда автоматического шардирование Нет там есть команда когда Ну вы её нажимаете и у вас шардирование произойдёт в фоне нужно это затем что не все клиенты готовы к тому что у них при расширении кластера будет ещё какая-то дополнительная нагрузка часто бывает ситуация когда вы например добавляете новые шарды А шардирование вы будете делать чуть попозже Когда у вас нагрузка спадёт То есть вы можете это процесс контролировать это конт второй вопрос дополнительный в документации есть какие-то гарантии чёткие на фловер на все сценарии там допустим мы там Гарантируем доступность там поднятие там не знаю мастера через полторы секунды и всё такое Нет мы гарантируем что вы данные не потеряете а то что у вас мастер будет мы вам не гарантируем у нас ЦП система а не ап Спасибо Спасибо большое спасибо Вот здесь пожалуйста по центру Евгений Спасибо большое за интересный доклад такой вопрос как кейс из жизни можно даже сказать был смотрите у нас есть допустим приложение которое общается с стром вот у нас всё работало потом в один прекрасный момент у нас сеть просто пропала вообще между всеми нодами сеть восстановилась ноды с приложением восстановились кластер обраться то есть снова собраться не смог приложение фактически не выполняет ту функцию которая должно вот в вашем решении в случае полного пропадания сети и полного восстановления кластер соберётся заново Да соберётся на это есть функциональные тесты Ну мы прямо специально этот сценарий Тестируем Мы тоже на это наступали вот справа от вас и слева от нас Здравствуйте спасибо за доклад а два вопроса Первый А вопрос Вы сказали в случае партишен а данные потеряются и там бизнес Может с этим смириться клиенты могут смириться А почему не используется параметр Right concern majority или как-то Так он называется когда идёт запись и на Мастер и на количество реплик ра N попом п о смотрите во-первых нет Con maity в редисе там есть только с числом это число Вы должны сами Вот и Например если вы говорите 1 то у вас большая проблема потому что вы можете оказаться в ситуации когда у Вас например шесть хостов 3 D по два Хоста в D ва вот вре сре остальные все проголосуют выберут новый й А вот этот парень со своим дружком которые остались в МДЦ они продолжат успешно писать подтверждать записи в случае кластера есть параметр чтобы CL следил за тем что у мастера всегда есть минимальное количество реплик если например у нас шесть хостов а у мастера Останется только одна реплика он не сможет быть мастером этот механизм работает го и вы часть данных потеряете Ну пока он догадается что там есть conc вы в общем всё что было там в промежутке И второй вопрос да спасибо И второй вопрос по поводу того что при рестар Вы ждёте если у вас мастер упал вы сказали что могут данные потеряться если мастер быстро переподписать стандартная достаточно практика не помню там Cloud FL что ли его используют что если мастер упал то даётся там минут на п например чтобы он приподнялся и тогда соответственно мастер пере выберется другой А этот просто в качестве реплики уже подтянется спасибо ну по сути так и происходит Просто типа мы не ждём пока сервис запустится Он просто запускается в закрытом режиме и мы дальше там посмотрим как как пойдёт и вопрос из тика Правильно ли я понимаю есть только на уровне Яндекса а портится на каждую новую версию редиса Да ну мы сейчас поддерживаем три ветки мы готовимся к появлению 72 70 и 62 Ну то есть вот 62 оно в продакшене там давно 7.0 внутри и сейчас скоро будет снаружи доступно Ну и 72 скоро будет готово к релизу там уже финальные правки со стороны редис ребят мы эту ветку тоже трека и там соответственно наш пат Рем на неё Евгений дюков дамы и господа Жень Скажи кому подарим за вопрос Ну давайте вот товарищ который про конр спросил был в принципе логич нормальный вопрос махни рукой к вам вот Баш Челове подойдёт и всё подарит Ага спасибо большое тебе тоже памятные призы от конференции Спасибо тебе большое за доклад прекрасно"
}