{
  "video_id": "NTk0qL3NUL4",
  "channel": "HighLoadChannel",
  "title": "Low Latency при работе с данными / Евгений Журавлев (GridGain)",
  "views": 848,
  "duration": 2990,
  "published": "2020-04-14T11:24:52-07:00",
  "text": "давайте определимся с планом сначала мы посмотрим что и как мы будем измерять дальше мы определимся с показателем ул отнеси для базовых операций такие как сети диск которые безусловно будут участвовать в вашем доступе к данным и дальше мы рассмотрим три кейса 1 будет включать себя обработку большого количества данных и ответ мы будем выдавать за миллисекунды но при этом объем данных будет очень большой второй кейс будет попроще в плане бизнес-логики но в плане лотность и там будет все потяжелее потому что нам будет нужно выдавать ответ зоосад миллисекунд на и время и примером такого кейса может быть например хранение сессии но хранение чтения сессии для какие-то telekom компании это нужно делать быстро просто потому что хранение сессии это доступ к этим это первая операция которую делает систему перед тем как взаимодействовать с другими какими сервисами api и 5 и если это будет выполняться медленно то и все остальное взаимодействия будет тоже замедляться ну и третий сет то уже десятки микросекунд ну здесь могут быть такие примеры как тот же high-frequency трейдинг торговля акции акции на бирже ну а кейсы по high frequency трейдингу на самом деле разнообразные там могут быть и требования в латексе в единицу микросекунд она где-то это десятки а потом мы перейдем к некому самаре и так полотенце здесь лотность это время за которое будет выполняться одна операция и мы будем говорить про раунтри платности и при этом ваша система будет обрабатывать 1000 или 1000000 транзакций в секунду и здесь наверное стоит говорить не про какую-то среднюю лад и хитрого плута именно про распределение разброс этих транзакций разброс этих ватный и здесь мы будем говорить поэтому про перцентиле и те перцентиле которые я буду упоминать стояли изначально в требованиях проекту от клиентов поэтому если вы что то не увидите значит это это не требовалось оптимизировать и здесь мы будем измерять ватности при устойчивой пропускной способности это значит что мы будем следить за общий нагруженности ресурсов и не будем допускать ситуации когда какие-то операции просто стоят в очереди потому что предыдущие заняли все ресурсы нашей системы такой ситуации общая латные себя ответа будет вырастать и за того что просто операция не выполняется стоят в очереди так определились что и как измеряем давайте дальше показателям платных базовых операций начнем сети и так 1 гигабитный ethernet может выдавать лотность и до 125 микросекунд 10 гигабитные от 5 до 50 микросекунд и есть специальные решения для ультралайта через кейсов такие как infiniband is a la fleur который позволяет достигать латексе менее трех микросекунд и тот же салон fleur достигает этого например за счет кинул байпас и за счет этого помогает сэкономить тоже те же микросекунда дополнительно также здесь я указал латексе для записи между москвой и парижем это было сделано для того чтобы показать что если ваши части вашей системы будут находиться в разных дата-центрах которые находятся на большом расстоянии друг от друга то основное время как раз будет уходить на это меж сетевое взаимодействие между вашими party всем и ни о каком серьезном улыбнись и здесь речь и быть особо не может давайте дальше переходить к дискам здесь нас будет интересовать 4-ки рандом redneck марк ну просто потому что когда вы работаете с данными и ваша система постоянно производят и чтение и запись то скорее всего даже если вам нужно будет прочитать много записей одновременно то эти записи не будут лежать подряд на вашем диске они будут лежать в разных секторах диска это конечно можно исправить выполнять какую-то дефрагментацию все семь и но это будет влиять на общую производительность тоже системы и либо вам нужно какой-то момент он с windows для этого поэтому здесь мы это учитывать не будем здесь все просто я зашел просто в лабу взял какие-то сервера с простеньким хдд довольно среднем довольно среднем тоже ssd и у меня получилось что 4-ки randomly benchmark вода для hdd шесть миллисекунд для ssd в среднем 180 микросекунд и есть решение intel optane ssd дает в среднем 20-25 микросекунд но здесь все не так просто и эти результаты мерились по сути без нагрузки если кто знаком с утилиты фио там это значит что настроенный кодекс был равен единице это значит что все запросы выполняли синхронно но если мы добавим нагрузку и по сути добавим такую очередь на выполнение то мы получим ситуацию похуже для хдд там уже нечего нам интересного нету для ssd мы уже начинаем как-то стремиться больше одной миллисекунды и это среднее значение всякие перцентиле две три четыре девятки там на самом деле еще хуже и для обт она при довольно высоком тропу ти мы можем достигать во всяком случае по их заверениям сто сто пятьдесят микросекунд эти показатели помогут нам в дальнейшем при понимании тех или иных решений давайте первый день здесь довольно все просто мы обрабатываем платежи используем исполь использование карты а конкретно здесь нас интересует кейс где мы вычисляем риски для той или иной транзакции и делаем фронт detection давайте представим что у нас клиент приходит магазин выбирает товар идет продавцу оплачивать и воспользуюсь у карты за терминал этот платеж улетает в шлюз платежей дальше он идет на processing дальше в систему провайдера карт после этого он идет в банк и в банк который выдал карту пользователя именно на этих двух этапах системе провайдер картой на этапе банк выдавшего карту пользователя и может происходить риск-менеджмент это зависит от того банка и от того провайдера который вы используете и здесь нам нужно вычислить является ли транзакция которая нам пришло от пользователя реальный то есть я выполнил реальный пользователь и мы можем продолжить процессить либо мы можем определить что эта транзакция который стартовал какой-то мошенник и мы должны ее отменить и в процессе работы над транзакций нам необходимо проанализировать историю предыдущих транзакций как для пользователя так и продавца и вычислить довольно большое количество параметров там от сотни до на самом деле нескольких тысяч и на основе них в дальнейшем мы и вычислим то является ли это фрод то есть транзакций который выполнил мошенник или реальная транзакции и как видно на нашем предыдущем слайде вот здесь в процессинге транзакции участвует довольно много разных узлов и даже на этапе в системе провайдер карты в банке происходит не только риск-менеджмента происходит много других операций и чтобы наш пользователь не стоял перед терминалом десятки секунд или там минут и мы должны это выполнить довольно быстро а здесь конкретно было заложено 50 миллисекунд на одиннадцатую перцентиль давайте посмотрим какие проблемы несет в себе этот кейс мы здесь очень много данных для того чтобы хранить эти данные на одной машине по сути здесь мы должны для начала хранить десятки терабайт транзакции но во первых в дальнейшем этот объем будет расти по мере процессинга и такие системы в любом случае подразумевает хранение дополнительных бэкапов это значит что общий объем данных будет еще больше здесь мы должны обрабатывать десятки тысячи транзакций в секунду и каждая транзакция подразумевает себя анализ до 50000 исторические транзакции для пользователей и такое же количество транзакций для продавца что в принципе довольно много для той же одной машины для новых сервера если мы захотим работать с диском в этом случае то мы должны понимать что тесто 100 мегабайт данных который нам будет необходимо проанализировать для одной транзакции а это возьмем мы возьмем размер транзакции в один килобайт возьмем количество транзакций которые нам нужно проанализировать в истории и получим как раз эти 100 мегабайт эти 100 мегабайт довольно много и прочитать диска на самом деле их можно можно не так уж и быстро так же если мы возьмем общий объем транзакций которые мы будем обрабатывать секунду то мы получим что в секунду нам нужно обрабатывать 50 гигабайт чистых данных и передавать по сети такой объем данных ну не то чтобы хорошее решение и даже если мы отбросим все проблемы сетью с диском то получим что нам все еще нужно обрабатывать эти 50 гигабайт в секунду и это довольно много а если мы возьмем тот факт что на самом деле это только чистые данные любой системы он даст вам overhead и помимо этого когда вы работаете с базой вам эти данные как-то нужно достать а для того чтобы их доставить вам придется пробежаться по индексу то данных для обработки становится еще больше 1 первую проблему решить можно довольно просто вместо того чтобы хранить все данные на одной машине мы здесь используем распределенную систему и конкретно здесь это как я говорил будет тапочек гнать и этим же способом решиться и вторая проблема проблема того что нам нужно обрабатывать много транзакций в секунду есть здесь смысл в том что вместо того чтобы масштабировать вертикальном и в дальнейшем при росте количества загс и будем еще и может обернуться горизонтально при этом это будет линейным ну допустим мы записали все эти данные на диск но для того чтобы начать процессить эти транзакции первое что нам нужно сделать это прочитать их я зашел опять-таки в нашу лабу взял первую первый попавший сервер там стоял довольно треть и disco the intel ssd 540 с и он выдает 77000 аутсов и соответственно это порядка двухсот двухсот шестидесяти мегабайт в секунду немного больше и здесь я также показал другие диски примерно из той же категории и если на них посмотреть то получится что для обработки того объема данных что нам нужно только для того чтобы прочитать чистые данные нам понадобится несколько десятков таких дисков и на самом деле довольно новое не то чтобы хотел использовать так много железа но делать какие-то вы на основе довольно средненький дисков это не лучшее решение поэтому давайте посмотрим на что-то более мощное я зашел на сайт и создают руби в партком там пользователи выкладывают результаты бенчмарков тех или иных дисков которые они имеют и гонять бенчмарки для них локально я взял сортировку по максимальному утра опыту и первый диск там это intel optane 905 общей тропу под нагрузка у него порядка полутора тысяч гигант секунду это уже поинтереснее таких дисков нам понадобится очевидно меньшей давайте посмотрим подходит ли он нам по другим критериям чтобы это понять нам нужно посмотреть на график и вал отойти на этом графике он синий и мы видим что средняя латексе у него без особо большой нагрузки без нагрузки дела начинать деградировать для 4-ки randomly да это 25 микросекунд и чтобы прочитать допустим те же самые 50 мегабайт которые нам нужны для анализа со стороны клиента история со стороны клиента нам понадобится больше 300 миллисекунд и это уже больше чем те 50 миллисекунд которые мы имеем всего 99 персик или и мы не можем себе это позволить так как нам еще делать processing и другие операции поэтому мы по идее здесь можем как-то распараллелить от чтения но это будет значить что пока несколько потоков будут обрабатывать одну транзакцию все остальные транзакции будут ждать в очереди ну потому что процессить это параллель мы не сможем потому что у нас десятки тысяч строки таких транзакций и именно поэтому нам придется перенести все данные в памяти и выполнять чтения только оттуда и так решили проблему с чтением данных теперь нас есть проблема с сетью вспоминаем что нам нужно передавать эти 59 секунду и мы хотим от этого избавиться того чтобы от этого избавиться нам достаточно пересылать не данные по сети а просто запрос на выполнение какой-то джо бы им на к самим данным то есть по сути в данном кейсе мы берем распределенную систему отправляем по некому запросы на выполнение процессинга на каждую из нот в кластере там выполняется processing и каждая нота возвращает результат свои показатели эти показатели мир жить на клиентской нодди и мы получаем результат в таком случае вместо огромного количества данных мы передаем по сути маленькие запрос на выполнения и не особо большой объект с результатами но это все конечно хорошо но это будет масштабироваться не настолько хорошо насколько хотелось бы потому что в процессинге каждой транзакции в таком случае будет участвовать все ноды кластера из с ростом соответственно кластера количество нот участвующих процессинге тоже будет расти но для того чтобы нам это обойти нам нужно сбалансировать данные а конкретно складировать всю историю транзакции одного пользователя с самим объектом этого пользователя нужно удостовериться чтобы все эти данные лежали на одном узле то же самое нам нужно сделал для объекта продавца и для истории транзакций этого продавца том же опачки на этот можно сделать довольно просто указав offense функцию и после этих изменений мы получим то что процессинге одной транзакцией будет максимально участвовать две ноты в кластере 1 для процессинга транзакции по пользователю 2 для процессинга транзакций по продавцов и даже с ростом кластера это число будет к нас будет оставаться констант нам и будет масштабироваться линейно но даже после всех этих архитектурных изменений у нас остались проблемы памятью а точнее это было java и это были проблемы с gc соответственно наши перцентиле то что было больше двух девяток вели себя не очень хорошо и поэтому нам пришлось провести ряд оптимизации которые были связаны именно с самим проектом и с платформой для из java и целом ну например тоже специально обертка для бра для работы со строками которые помогли нам понизить нагрузку на джесси и за счет этого мы смогли прийти к тем требования которые нам были нужны но при этом на этом этапе нам не нужно было дополнительно масштабироваться и в итоге мы получили то что 99 перцентиле мы уложились в эти 50 миллисекунд на 10000 в tps на 6 инстанциях ой 316 x-large но эти результаты у нас получились на тех входных данных которые оказывал вначале а когда мы начали работать с реальными историческими данными там оказалось все немного иначе оказалось что пользователи намного чаще совершают покупки каких-то магазинах которые имеют большую историю транзакций но на самом деле больших retail сетях каких-то и получается что в процессинге каждой транзакции участвовать намного больше данных и за раз таки больших продавцов и на этом этапе нам пришлось все-таки масштабироваться чтобы поддержать тоже сама tps но полотенцем и остыли оставили то же самое и давайте посмотрим на вывод поэтому кейсу мы получаем что при обработке больших объемов данных нам нужно выбрать правильную архитектуру которая позволит избегать узких мест таких так как занимать избыточное потребление сети избыточное взаимодействие с диском и некоторых случаях вам может понадобиться какие-то дополнительные оптимизации которые связаны либо с самим проектом который вы делаете либо софтом который вы дополнительно используйте это все по первому кейсу давайте переходить ко второму здесь все намного проще в бизнес локи это может быть какой-то взаимодействиями сессиями того же телеком какой целиком компании и давайте посмотрим где мы находимся на нашем графике здесь мы уже видим что часть тех вещей которые будут и могут участвовать процессинге они нам не подходят та часть которая казалось бы подходит она уже отжирает у нас огромное количество времени поэтому здесь тоже нужно что-то будет думать и здесь из-за того что бизнес-логика намного проще здесь казалось бы меньше проблем и в первую очередь вроде нам по нашему графику и можно работать с диском но как я уже говорил до этого при работе с базой данных все не так просто и для того чтобы доставить туземную за именно ту запись и прочитать именно тот сектор с диска вам нужно его сначала найти а для того чтобы его найти надо его найти в яндексе и если вы возьмете просто базу и никакие дополнительно не настроить этого получится что эти индексы они будут у вас скорее всего на диске ну или хотя бы их часть и получается что он уже надо прочитать ни один сектор диска несколько или там даже больше и здесь чтобы решить эту проблему вы можете либо взять какое-то готовые номере решения качество дополнительного слоя кэширования чтобы вы брали и читали это прямо из памяти не взаимодействие напрямую с диском а именно это решение будет ответственна за синхронизацию данных между этими двумя слоями и также здесь придется асинхронный взаимодействовать с диском либо же вы можете просто настроить довольно хорошо вашу любимую базу данных просто выдав я ему максимально много оперативной памяти чтобы она смогла запиши ровать все что нужно ну или как альтернатива на рынке есть решение которые позволяют хранить данные на диске но при этом они гарантируют что все построены индексы хранятся у вас памяти то есть вот такое как бы гибридное решение но для части кейсов они максимально требовательных клад найти как допустим вот этот они могут подойти и это и это не единственная проблема есть еще проблема того что нагрузка на ресурсы скорее всего будет портить ваши перцентиле ваши старшие перцентиле это две три четыре девятки это зависит от вашей нагрузки и поэтому во первых вам здесь может быть нужно следить за нагрузка на ваши ресурсы чтобы удостовериться что ваша система не перегружены начала пенсий будет расти для всех транзакций но и в случае джавы вам нужно будет за оптимизировать вашу работу с джесси либо что-то совсем интересно с этим придумать и это нужно делать не всегда а только в тех случаях если в требованиях к вашему проекту существуют определенные требования для вот этих старших перцентиле я не существует далеко не всегда и не всегда стоит на это тратить время и в качестве примера решения проблемы с джесси можно привести вот этот вот мы можем использовать какие-то не дефолтные гмс какие-то какой-то другой имплементации для джесси ну например здесь используется азов things его сефор и можно по графику увидеть что уже после после трех девяток это 99.9 дживан начинает довольно сильно расти и в дальнейшем это же продолжается в то время как азул sing for но продолжает не значительно увеличиваться и в принципе довольно логично и в этом кейсе я была не особо большая нагрузка внизу увидите что это было порядка 40 тысяч записей на 40 тысяч запись и на записи 40 и 20 тысяч записи на чтение в секунду ну это как один из вариантов решения проблем с перцентилями и что получаем в итоге получаем что если вам нужно сад миллисекунд на и время то вам придется уже подумываете о том чтобы работать с памятью вместо прямой работы с диском и я говорю как а чтение так и записи вам нужно будет следить за перегруженностью ресурсов но это в том случае если вам больше нужно им на лотосе а не какой-то хай про опыт и если у вас есть специальные требования для старших перцентиле и случае джавы как так расширение предыдущего пункта это скорее всего при необходимости вам придется использовать ползовать россии в случае джавы так все с этим кейсом и переходим к еще более жестким требованиям вернёмся к графику получается что ssd у нас теперь обычно ssd совсем мимо по идее нам подходит 10 деятельный ethernet но на самом деле он возьмет слишком большой процент вашего доступна во времени и если у вас требования как-то немного уже меньше чем 100 микросекунд а вы уже совсем не можете его использовать ну и здесь скорее всего все таки нужно придумать что-то другое и давайте посмотрим какие проблемы несет в себе этот кейс здесь проблем на каждом из этапов несет себе просадку и довольно сильно во времени ответа и в первую очередь здесь также совершенно нет возможности работы с диском ну какие то синхронный варианта все-таки остаются но это не самая главная проблема самое главная проблема здесь сеть потому потому что лотность и в средней сети которые используются скорее всего вы это уже десятки микросекунд и это имеется ввиду локальная сеть и здесь уже стоит задуматься даже о времени перехода в корму потому что это уже тоже микросекунда что это может быть порядка семи восьми миллисекунд и здесь имеется ввиду приход в тюрму при взаимодействии сеть для того чтобы что-то отправить мы переходим в крыло из пользовательского потока и опять таки стоит думать о том чтобы избавляться от переключения контекста которые может занимать те же самые семь восемь микросекунд а в некоторых инвариантов даже больше это могут быть даже десятки микросекунд и здесь качестве простых решений в первую очередь мы храним данные в памяти второе для того чтобы избавиться от проблем сетью мы можем просто скопировать данные которые вы храните с самим приложением и здесь вы можете это либо делать внутри 1g в случае использования джавы либо просто хотя бы на одной машине и вот такой простой подход конкретно будет этот выглядеть вот так случае того же great game он выдаст сразу же что-то порядка двадцати от 20 до 100 микросекунд зависит от того какие у вас данные и смысл здесь в том что это только одна но да и также будет выглядеть весь вас ваш класс стоп то есть вы можете стартануть несколько нот и вокруг каждой ноты страттон и свое приложения и уже потом именно как крутить ваши запросы на конкретное приложение которые находятся вокруг ваших not вокруг ваших данных и это один из вариантов но этот вариант не всегда подходит и не для всех кейсов если же вам все еще придется использовать какие-то сетевые взаимодействия а скорее всего он придется то вам придется использовать специальное сетевое оборудование для таких взаимодействий как я уже упоминал это solar flare с его софтом up on a lot который как раз таки позволяет овладеть kernal байпас и сохранять вот эти драгоценные микросекунды либо тот же infiniband ну и все-таки так как вы можете использовать джаву на этом этапе и все проблемы с джесси также остаются то вам нужно решать и проблемы тоже но опять таки это те варианты которые подходят для чего-то от 20 до 100 микросекунд и тут еще есть вопрос с тем как работать со старшими перцентилями и если вам нужно латексе уже меньше 20 микросекунд либо вам нужно совершенно какие-то жёсткие условия для джиттера и для каких-то старших прицепили то здесь уже придется писать какие-то свои кастомные решения в которых вы будете вручную управлять выделений выделениями памяти и это придется делать даже в джаве если вы решите делать это на ней для того чтобы избегать генерации вообще всякого мусора иначе опять таки проблемы с gc использует вам те самые перцентиле за которую вы собираетесь бороться также дефолтные или какие-то готовые решения для общего назначения как те же готовые in-memory базы данных они скорее всего уже не смогут выдать нужная лотность если вы стремитесь к чему-то уже меньше 10 микросекунд и здесь вам либо нужно будет использовать какие-то готовые решения конкретно под вашу задачу такие как high-frequency трейдинг либо уже писать какие-то свои кастомные нами структуры очень сильно заточены под ваши алгоритмы и благодаря этому они будут выдавать максимально низковаты и ну и на самом деле чем большую часть своего кода пишите вы сами тем оптимальнее она будет работать это всегда то здесь же для решения проблем в контексте ченгом ну нужно будет делать repining и опять таки это можно делать и в java тоже вы можете заменить конкретные и 3d конкретным процессором свой контент по для того же чтобы никакого контексте витченко не происходило и вы не останавливать свой процессе на те же на тот же десяток микросекунд но если у вас требования идут все ниже и ниже по вам придется использовать какие-то специальные решения такие как в пиджей или и с оси и это уже совершенно низкоуровневые вещи например в пиджей это программируемые интегральные схемы специального назначения и вам придется спускаться не максимально конечно разработке уже своего железа но довольно близко к этому уровню потому что они поставляют не некое железо которое вы можете до программировать до своих нужд по сути вы туда ваш счете свой алгоритм который будет повторяться снова и снова и довольно низкого уровня и это был третий кейс давайте приходить к самаре и получается что требования к проектам которые у вас есть сразу же могут подсказать вам правильную архитектуру и то оборудование которое вам стоит использовать тоже необходимость обработки большого количества данных за малое количество времени скорее всего потребуют какой-то специальной архитектуры и возможно дополнительных оптимизацией для работы именно с памятью лад эти требования полотенце в меньше миллисекунды скорее всего потребуют от вас слежением за тем чтобы ваши ресурсы не были перегружены и в случае джавы это будет проблема с джесси которую тоже будет надо как-то решать и требования classic уже меньше 100 микросекунд потребует либо архитектуры для клонирования в ваших приложений с вашими данными для того чтобы как-то избегать сетевых взаимодействий либо использование специального оборудования для именно уже ultra low latency кейсов такое как сетевое оборудование тоже infiniband лицо флеш или еще что еще лучше низкого уровня вещи типа f и j и аси asi все всем спасибо за внимание евгений спасибо что факты красивую структурированном рисковал на нарисовал шкалу по которой мы можем определиться официальную благодарность от оргкомитета поселение маленький презент друзья у кого из вас появились вопросы поднимите пожалуйста руку вот у нас целый ряд вопросов спасибо за доклад наброс первый такой вот говоря про отказа от жестких дисков микрофон бриза переход к использованию данных которые вы противном памяти хранятся имели ввиду in memory do the bass или что когда persistent данные они все равно как бы на диске хранятся потом загружаются при старте да там и живыми мари базе хранятся и досмотрите конкретно в этих кейсах конкретно фирмы втором где процессе большого количества данных во втором где те же самые сессии там все еще использовался диск но он использовался асинхронную еда там был ли in memory решения вот тапочек night он как и хранить данные на диске так и подгружает их кэш для быстрого доступа соответственно чтение происходило всегда есть крыша а запись происходила но сначала в кэш потом вал писался ну понятно то есть решение чисто in memory дату базу использовать ее например persistent базу для на пир систем хранения до абсолютно то есть а по скорости то как будет примерно то же самое или быстрее счет но смотрите по скорости от будет зависеть от базы которые вы будете использовать под in memory примерно это будет то же самое но вам нужно будет дополнительно следить за синхронизации именно между ними мы освоим из за слоем базы данных для этого есть решение но это может не всегда находить как-то до понятным лучше второй вопрос тоже рассматривать такие варианты тоже есть сетевой карты интер милан огс который ремонт direct memory access использует и то есть там можно 25 гигабит и больше 100 гигабит и карты взять и то есть там младенцы будет гораздо ниже чем 10 га битных карт обычных то есть там они керна цепей с даже наверное не будут использовать если демотт а то есть я конкретность этой технологии не работал но когда готовился я смотрел графике это лотность которые они выдают они да они быстрее за мета но в то же время они получаются медленнее вот solar flare они полон заявляли что порядка пяти микросекунд на эту вот поэтому да под какие-то кисет без вам подойдет но опять-таки если это совсем ultra low там может быть не всегда есть что-то побыстрее нет спасибо у нас есть уже человек с микрофоном вопрос в ту же самое то же самое место мы говорили про то что объемы памяти очень объемы данных для чтения довольно большие типа порядке нескольких терабайта может быть десятков то будет как в этом случае ну то есть нужно очень много оперативки для того чтобы это все читать если если не столько оперативки то мы хотим делать рид кэш а для того чтобы ритка же делать нужно его подогревать как-то короче как как хранить столько данных на чтение в кашах на память и смотрите если у вас в требованиях такие запросы полотна которые вы видите что диск там совсем не уместится то уже хранить часть данных в памяти допустим не знаю 30 процентов остальные на диске она не всегда вам подойдет потому что в определенный момент вы захотите работать с теми данными которые на диске а как вы посчитали вы уже да нет так быстро не сможете получить доступ и получится что до вам придется все хранить в памяти да это много оперативной памяти но опять-таки когда такие требования к проекту выставляются люди готовы к этому они понимают что по-другому этого не добиться но опять-таки как я говорил есть другие решения которых где вы можете попробовать храните только индекс памяти а данные на диске то есть где то при не более слабых требования палаты этот вариант подойдет у меня спасибо дик лугар на и общем у меня вопрос то что ну представленных как бы примерах данные они больше похожи на того табличного вида а что если нам нужно бежать по какому-то графу например знакомство людей и там как бы colocation не работы потому что ну мы в конце концов игру говорит весь граф будем хранить у себя в одной машине как вот в таких случаях обходиться и ну и как с этим жить там конечно у нас и такие сильные требования по времени но это все равно как бы очень сильно кровь пьет и куда то тут 5 слушайте вот тут к сожалению я подсказать не смогу потому что с графами хранилищем данных как это вообще не работал ну я думал под это точно есть какие-то уже готовые решения ну что выгоняет нет там какой-то там штуки тоже она ли хотя бы хоть что-то это зависит очень сильно от данных то есть да то есть если таких если вы сможете хранить допустим всю эту весь этот объект весь этот граф как один то пожалуйста может положить от игнайт вы будете иметь доступ к нему быстро из памяти если это зависит от типа взаимодействия с данными если вам чаще нужен именно весь графы бегать по всему графу то это одно то вы можете хранить его вид всем объектам иметь его в памяти всегда по нему бегать и это будет довольно быстро но если вам иногда нужно хранить иногда нужно иметь доступ ко всему графу время от времени ну или там даже чаще иметь доступ конкретном узлам этого графа то тут уже надо по-другому это хранить иначе будет большой вверх от на чтение конкретных узлов да так следующий вопрос чуть левее спасибо за доклад меня из ваши выступления сложилось такое впечатление что нужно взять хорошие ssd диски и все у вас будет хорошо если все-таки не все так хорошо стало то давайте напишем кастомный код и тогда все равно все станет хорошо а не правильнее ли пойти с обратной стороны то есть начало подумать об архитектуре приложения подумать о тех уже готовых решениях которые существуют на рынке потому что если мы работаем с данными то значит наверняка есть замечательный суп у которых есть под каждый атом вариант запроса красивые решения там индексирования и nemo реек гоночные индекс сжатие так далее так далее опять таки если там работа с графами то есть гробовые субд и соответственно используя правильные технологии написали хорошую архитектуру получили приемлемую производительность и вот если здесь уже не хватило тогда давайте купим крутые дорогие создай диски с одной стороны это правильно но с другой стороны как вы сказали вы взяли уже готовую решение уже все написали и потом уже только поняли что что то не хватает то есть это вы потратили огромное количество времени и ресурсов и как-то уже кажется что это поздно то есть конечно покупать диски заранее и делать какую-то оптимизацию заранее которое в итоге окажется не нужно этого делать не нужно то есть надо взять требования взять те оборота оборудования с которым во первых вы можете работать во вторых который вы можете позволить где взять проанализировать все эти вещи возможно прогнать какие-то бенчмарки и понять хватает ли вам той производительность потому что после того как вы начнете писать именно бизнес лайку а все еще хуже у хочется потому что но поверьте некий вверх а сейчас вопрос из правой стороны зала добрый день и спасибо за замечательный доклад как бы у меня просто нескромная как бы немножко планируете ли вы продолжать изыскания если не секрет то в каком направлении до на самом деле время работы над докладом я несколько раз его переделал потому что находил что-то новое и более интересное даже в момент когда я стою на сцене я понимаю что здесь еще очень много вещей куда стоит копать и мне очень понравилась тема про high-frequency тренинг на джаве и конкретно про вот эти кастомной номере структуры и про программирования именно без мусора на джаве я вот хотел копать в ту сторону успеем еще два вопроса один здесь спасибо за доклад обычно таким систем предлагается большие требования к надежности и отказоустойчивости вот на каком уровне предлагается делать резервирование чтобы было минимальное влияние на власть ну по поводу резервирования тут же есть разные подходы мы можем делать то же дата тренд репликацию которые по сути будет постоянно поддерживать нам какой-то слепок данных в в другом кластере если вы можете себе позволить 2 класса ну это не влияет на производительность это не зависит это зависит конечно от вида репликации потому что есть синхронные и асинхронные и там возможно вам придется делать и синхронны но с намеком на то что вы можете потерять какие-то секунды данных но опять-таки но это тоже как-то можно обходить а конкретно по созданию backup of ну здесь зависит от зачастую в тех же банках существуют какие-то maintain its window фантом раз в день для больших бэкапов где они могут себе позволить те же самые небольшие небольшое влияние на перформанс потому что в общем нагрузка в этот момент у них намного меньше и транзакции не будут страдать особо спасибо хочется уточнить что-то не ну то есть смысл в том что оверхед будет конечно же всегда от этого никуда не деться надо сайте котором последний вопрос который мы успеем справа верхний ряд 1 раз спасибо за доклад хотелось бы узнать игроком ближе ok хотелось бы узнать как нестабильностью ведет себя племена нестабильных топология то есть допустим мы хотим от масштабироваться добавляем новый узел и у нас собственно запускается по м е который кластеры валите нафиг где все узлы смотрите да есть такая вещь сейчас по imei длится недолго но во первых изменения топология конкретно падение как каких-то нот это ненормально поведение системы и соответственно в это как раз те девятки которые иногда в системах могут быть повыше но как какое-то влияние будет но она во первых на чтение она не будет высоким но нажать на запись уже будет больше то что но на чтение мы опять-таки премье занимает не так много времени ребаланс нас не волнует ни как потому что во время ребаланса мы можем читать и писать также и 2 вопросик там был пунктик про внешнюю си реализацию хотелось бы узнать что это и по поводу какой-то кастомное к 100 обертки для хранения строк и такие-то особенности из бандере объектами а это было сделано в обход бы не работой я сказал что можно после презентации вот там где-нибудь обсудить у меня даже слайд по этому поводу есть могу рассказать хорошо спасибо друзья я еще полторы руки точно видел вот после презентации вот около того выхода противоположного от сцены вы сможете поговорить я сидел чтоб ты успел выбрать лучший вопрос который ты понравился молодой человек сначала не выходи к нам расскажи пожалуйста микрофон еще раз как тебя звать и что побудило тебя задать свой вопрос зовут меня руслан я снимков банка собственно вопрос побудил задать ну собственно проблемы с которыми столкнулся спасибо огромное спасибо огромное докладчику поздравление автор лучшего вопроса"
}