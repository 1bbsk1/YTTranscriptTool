{
  "video_id": "c-ySk8COI1c",
  "channel": "HighLoadChannel",
  "title": "Производительность запросов в PostgreSQL / Илья Космодемьянский (PostgreSQL Consulting)",
  "views": 13687,
  "duration": 2671,
  "published": "2017-07-29T13:02:52-07:00",
  "text": "как тут уже разок прозвучало рассказывать я буду про производительность запросов по с грейс quelle ну для начала как бы сразу пару слов о том о чем мы будем говорить во-первых что такую оптимизация запросов да то есть как бы люди редко формулируют и часто бывает так что недооценивают понимание того что они делают да то есть можно пытаться ускорить какой-то конкретный запрос но это при этом не обязательно будет оптимизация то есть как бы из помещики другие например медленные немножко мы на эту тему потереть и зеваем потом мы поговорим о том с какого конца вообще к этому вопросу подходить когда начинает оптимизировать собственный как это делать и как понять что какой-то запрос или там какой-то набор запросов вообще нельзя не как оптимизировать такие случаи тоже бывают и тогда надо просто переделать оптимизация там уже не сильно поможет как ни странно и я почти не буду давать примеров того как запросы оптимизировать потому что у нас в принципе небольшое достаточно время и ну как бы я могу дать 100 примеров 500 примеров и так далее так обычно не приближает так сказать к разгадке обычно самые такие вот такое узкое место это непонимание с какой стороны подойти к этому делу все говорят там смотри читаете explain читаете explain проверяете запрос explay нам в то же время мне часто задают вопросы о том что вот ну explain но я на него посмотрел и что на что там смотреть что теперь с этим делать вот об этих штуках я попробую рассказать немножко подробнее если как бы хочется уже более такой конкретики таких местных примеров приходите в 4:00 нами топаз гри совы где мы будем так сказать воли уже вальяжно в режиме показывать кучу разных примеров а здесь будет так сказать немножко в водная теория ну в качестве эпиграфа к данному докладу я хотел бы привести цитату из академика крыло который строил корабли в свое время цитате этой больше ста лет однако ничего не поменялось то есть как бы основная проблема с базами данных это либо что в базе данных лежит что-то ненужное либо не лежит чего-то нужного либо соответственно какой-то неправильный подход к ее эксплуатации да то есть в принципе мы можем поставить какой-нибудь супер пупер рейд контроллер с огромным кашам супер дорогие созда диски но если мы не будем включать голову как вот очень правильно предыдущий докладчик такой слайд показал где написано думаете это очень как бы важно если мы не будем этого делать то как бы результат будет плачевной ну поехали во первых что означает оптимизировать запросы как правило у вас такой задачи не возникает та ну кто приходит на работу с идею сейчас я по оптимизирую запросы конечном такие люди есть но обычно проблем немножко другая проблема заключается в том что просто есть уши psy и бабушки в какой то момент мы пишем пишем пишем наш замечательный проект приходит там раунда финансирования поднимаем деньги он работает приходит пользователь пользователь довольны в какой-то момент заказали чуть побольше рекламы пришло чуть побольше пользователей все упало потому что когда разрабатывает проект быстро обычно там используется как он там рельсы и django что такое и так в лоб более-менее да то есть как бы написали крм какие-то запросы извини релиз важно быстрее дать продукты это на самом деле правильно потому что никому не нужен вылизанный идеальный проект который не работает ну и дальше при приехали дальше нужно что-то понимать что происходит во первых как бы эти медленные запросы которые мы хотим оптимизировать от такой простой интерфейс которые видно наружу что вот вот вот она у нас тормозит но при этом запросто может быть причина в чем-то другом может быть хреновое железо может быть не настроенная база и в принципе в этот момент начинается оптимизации запросов наверное не стоит одна верно сначала посмотреть что все-таки происходит с базой что значит не настроенная база бывает просто грубые ошибки в и настройки и до того как они будут исправлены оптимизировать запроса бесполезно потому что battlelog в другом месте например вместо such идет в под прессом у вас может быть отключён of the vacuum почему-то люди это иногда делают этого ни в коем случае делать нельзя но когда он отключён у вас просто очень большая фрагментация таблицы да тут как бы не буду говорить много настройках в то вакуума но тем не менее у вас легко может быть табличка на 100 тысяч записей по размерам быть как табличка на миллиард записей естественно что как любые запросы к ней будут несколько медленнее чем вы ожидаете поэтому сначала нужно база настроить проверить что соответственно у вас все хорошо работает тоже часто я например очень ошибка когда 1000 worker of pace пресса работает потому что очень много подключения от приложений брокера connection of не стоит никакого ну надо понимать что если вас на 3 500 connection of у вас должно быть 500 лидер на сервере на котором вы работаете в противном случае конак шины будут друг друга мешать или будут все в ожидании проводить время когда вы вот этим все глупости исправили их может быть на самом деле довольно много ну как будут основные на самом деле их там 5 10 штук там правильной настройке памяти правильной настройке диска of the vacuum когда вы все эти вещи исправили вы можете переходить к оптимизации запросов и на самом деле только тогда не надо пытаться оптимизировать то что еще как бы вы только делаете какой алгоритм как подходить к оптимизации запросов во первых надо проверить настройки во вторых каким-то способом отобрать те запросы которые вы будете оптимизировать это важный момент и собственно говоря с оптимизировать чтобы как сказать проследовать в часть нам надо сесть в автобус и проследовать и после того как вы более-менее самые медленные запросы вылечили они стали более быстрыми у вас немедленно появляются новые медленные запрос и потому что как бы старый топ уступила место и в результате как бы вы так постепенно шаг за шагом повторяя этот алгоритм избавляетесь от медленных запросов в общем все просто тут как перед следите за руками ничего сложного нет серьезно и вообще как бы вот обычно такой доход нельзя прочитать на хай лоу дип на бы на большом все скажут ну как же это самое такие простые вещи а на самом деле как бы имеет смысл иногда повторяйте как бы об этих вещах иногда задумываться заработал опять значит соответственно очень важный момент какие запросы оптимизировать если вы будете оптимизировать все подряд ну во-первых вы имеете шанс и не угадать самыми проблемными запросами во вторых и вы имеете такую проблему что просто тупо потратить очень много времени и не доберетесь до нужных там задач по этому запросу нужно оптимизировать как бы по мере поступления проблем вот вы написали на своем там замечательному реями замечательный сайт все хорошо все работает посмотрите где работа перестала так сказать где стала медленно и плохо и вот этот кусочек оптимизируйте если там у вас есть какая-то фигня которая редко используется не надо ее просто вообще как бы трогать но работает и работает не тратьте время собственно говоря поэтому отобрано му топу берутся запросы и смотрится что с ними можно сделать раньше для этой цели нужно было использовать лука на лазер где badger и джеффу не теперь в принципе особенно в версии 94 правильный способ использовать extension пиджи стать statements который все это делает на лету в онлайне и можно все это дело посмотреть правильный способ это собственно говоря это дело каким-то образом засандалить и на это дело посмотреть ну давайте как бы будем разбираться с этим детально ну вот тут у меня такая штука есть вот по этому адресу это наши пиджи utils которые доступны в свободном доступе можно скачать воспользоваться в этой папочки лежат и не где лежит некая обвязка вокруг стандартного кантри papers that statement который позволяет генерить вот такие вот отчеты то есть грубо говоря за сутки нагрузки на базе мы соответственно смотрим что там происходило какой там был workload и видим соответственно некий топ запросов каким-то образом ранжированы ну здесь какие-то с реальной базы но анонимизирован ее запросы здесь видно следующее что нам важно знать что у нас есть там первые позиции 2 еще там их обычно десяток дан и мы видим что по каким-то из параметров например по себе you но в данном случае не пою у нас некий запрос выходит на первое место он занимает там 24 процента нагрузки базы то есть вот базар т.б. она стопроцентно времени работает и соответственно по процессу вот этот запрос соответственно занимает 24 процента и скорее всего это на самом деле довольно много и это надо как-то оптимизировать потому что ну вот вы смотрите на запросы думаете о сколько он денег проекты приносят если он приносит очень много денег да пусть хоть а половину всего отъедает а если он как бы денег не приносит вообще отъедает половину ресурсов это наверно плохо наверное с этим надо что то сделать вот и таким образом вы смотрите на этот топ запросов за предыдущий день и думаете что с этим делать хорошей практикой и у нас принципе считается что вот есть команды разработчиков которые делает что-то на проекте и раз в сутки по крону такой отчет приходит всем добра всем разработчикам всем админом и это очень как бы такая полезная штука то есть выложили гениальную фичу в пятницу ушли пить пиво в субботу с утра приходит письмо и вы видите что 80 процентов цикл разного сервера съеден а вашим любимым запросам вы пьете мини рамочку идете оптимизировать все хорошо что такое как бы плохую вообще медленный запрос ну во первых это тот запрос который у вас в топе да то есть он с одной стороны мы быть медленным другую страну может быть быстрым но как бы из у нас определяет ресурсы значит его надо скорее всего sap theme zero вать каким-то образом но чисто по времени это всегда как бы некий вопрос вот как вы считаете запрос работает 123 миллисекунды это быстрый запрос вот то есть в принципе я могу накидать очень много разных вариантов да ну например даже запрос который будет работать долю миллисекунды он все равно может быть медленным запросам например если у вас этих запросов очень много да и как бы много мелких запросов они в итоге подъедают очень большой процент ресурса в база то есть принципе вещь как бы это относительно и тут как бы нужно так сказать думать как было уже верно замечено а во первых как это насколько часто этот запрос работает до если это какая-то отдача чего-то на главной странице и этот запрос занимает там секунду надо понимать да что у вас будет эта секунда и еще плюс у вверх этот всего того что у вас нужно для того чтобы сформировать эту страничку это значит что уже как бы пользователь увидит результат гарантирован и медленнее чем через секунду и в принципе для онлайнового vepa высоко нагруженного это не приемлемые результаты а если при этом запросу вас для какой-то аналитики гоняется ночью присылается кому-то синхронный отчет то может быть он там может себе позволить работать сильно медленней то есть всегда надо как бы знать свои данные и как бы таки имейте силе и то есть думать ага а сколько нам вообще допустимо чтоб этот запрос работал ну и опять же характер нагрузки на базе потому что у вас есть какой-то длинный тяжелый запрос а вы вы можете гонять какое пиковое время а это например запрос или в какой-то аналитики для менеджеров что-то посмотреть какие то результаты ну посмотрите на профиль нагрузки на базовую вас есть перестать statements вы можете по нему увидеть топ медленных запросов с двух часов дня до 16 до четырех что у меня дан и например в это время не гонять длинные физические запроса ну и опять же да сколько этот запрос приносит денег и имеет ли он право занимать много ресурсов базы если вы сделали прикольную фичу которое не зарабатывает для проекта ничего а этот запрос съедает 50 процентов ресурсов значит вы написали плохой запрос значит вам нужно переделать эту идею и даже иногда объяснить менеджеру почему это технически очень сложно например штука она просто там кидает ресурса потому что как бы все говорят там хочу чтобы золотая рыбка была у меня на посылках но тем не менее как бы себе вон железной он имеет некие лимиты и резиновой растягивать его нельзя то есть как бы люди которые делают облака они вам скажут что можно я как зануда админ скажу что нельзя вот где вообще могут быть проблемы при исполнении одного конкретного запроса во первых это может быть передачи данных от клиента и это совершенно не так смешно как кажется в принципе как бы следующий слайд вам покажет где там может быть зарыта собака второй момент это парсинг то можно написать очень витиеватый запрос который просто будет долго парсится в новые версии подвеса если я не ошибаюсь будет в explay нее время парсинга и можно будет понять сколько на это дело времени уходит сейчас можно сделать ваши explain и посмотреть таймингом соответственно сколько у нас ушло на исполнения запроса а сколько статуса на парсинг потом запрос нужно оптимизировать и это на самом деле далеко не такая простая задача как кажется потому что оптимизатор это достаточно сложные алгоритмы то есть он например как вот у вас есть join вы хотите сделать join двух таблиц он берет одну таблицу выбирает метод доступа к данным которые нужны и при джоне от нее следующую если у вас еще один joins еще одной таблицей то сначала он звонит 2 потом срезал цветом с дженет еще одну если вы написали запрос в котором 512 join of дальше начинается очень интересная петрушка с оптимизацией этого дела для перебора того какие какой путь join of будет оптимальным ему потребуется n факториал в зависимости от количества join of вариантов планов и которых нужно это дело будет отобрать поэтому если у вас много join of вы как бы сразу понимаете что сам процесс оптимизации может быть очень и очень не маленький ну и дальше собственного может быть непосредственно исполнении если у вас запрос должен вернуть куда-то 10 гигабайт данных сложно рассчитывать на то что он будет работать миллисекунды он не будет работать миллисекунды с помощью какого волшебства вы это делать не будете да ну в зависимости от того какие машины но в принципе как бы 10 гигабайт меньше чем за секунду наверно отдать можно но там сильно быстрее вряд ли получится поэтому как бы если вам нужно отдать много данных сразу имейте в виду что как бы волшебства не бывает волшебства волшебство бывает в мире новый сквере здесь волшебства нету ну и возврат результатов опять же если вы несколько гигабайт данных гоняете по сети то будьте готовы к тому что это будет медленно потому что сеть опять же имеет некие там лимиты на то сколько через нее можно пропустить и в таких случаях такое маленькое замечание имеет смысл иногда подумать о вообще как бы нужны ли нам все эти результаты это очень частая проблема которая случается ну вот передачи запросов передача данных от клиента кто писал на груббе использовала всякие разные хитрые в м и знает что в принципе ну вот по этому запросу можно познать что-то нами на это было django да то есть как бы это фирменный стиль как бы почерк радиста ни с чем не перепутаешь как вы думаете какова максимально максимальной длины in список я видел в своей жизни у кого какие версия тепло но мало мало больше в гигабайтах гбайт их надо считать в принципе если не смотреть на то что делает вашу rain то вот это вот может быть легко не сколько байт и этот запрос никогда не исполнится и в принципе как бы это плохо это значит что у вас как-то совершенно не оптимальный доступ к данным и соответственно как бы жизнь очень сложно вот этот запрос плох еще по многим причинам но в принципе как бы основная причина что он может быть такой длины которые никогда в жизни в позвать вас не пролезет ну опять же самый главный слайд этой презентации и to explain после того как вы выделили топ запросов вы как-то удостоверились что вот эти запросы медленные например и вы хотите с ними что-то сделать вам нужно прогнать explain и собственно говоря загвоздка но как бы до этого этапа доходит многие а дальше как бы ну люди сеть нажаловаться я много слышал что ну чё мы посмотрели explain и что дальше с ним делать поэтому я вам сейчас расскажу что dejah торис с explay нам на всякий случай если вдруг вам это тоже интересно но раз вы сюда пришли наверно значит интересно здесь 2 x play на немножко разный синтаксис ну как бы можно вот так делать эксплей на нова и самба фирсон можно просто написать explay но новояз например что важно понимать что explain вам выведет просто план предполагаемый какой он должен быть и соответственно если вы укажете еще и она вайс то это запрос будет реально исполнен и будут показаны данные о том как он был исполнен то есть не просто explain а еще какая-то трассировка собственно где что происходило соответственно правильно когда вы вы отобрали топ медленных запросов использовать explain анализ потому что во первых может быть выбран не оптимальный план у вас может быть не выбрано стать не собрана статистика ну и вообще всякие вещи разные бывают под grease супер конвекционная штука если у вас есть пишущий запрос вы не хотите чтобы эти результаты записались пока вы там что-то оптимизируете говорите бегин соответственно баха я те так запрос но желательно как бы это самое смотреть что вообще происходит да то есть тяжелый запрос на боевую базу в пиковое время не всегда бывает хорошо то есть надо как-то с оглядкой это делать но тем не менее как бы это полезно смотреть при этом потом говорить о rollback чтобы вот эти данные не записались что важно важно что здесь показывается некие циферки вот эта часть как бы принадлежит к explay ну вот эта часть канала и за что эти циферки значит это очень как бы важные циферки в explay нее есть условный попугаи под названием cost один куст в подгрести по дефолту это стоимость это время время которое затрачивается на извлечение 1 1 блока размером 8 килобайт пресекли scania последовательным и в принципе в принципе как бы это величина зависит от машины до поэтому она условно и поэтому это удобно да есть вас быстрая диски это будет быстрее если медленные медленнее что важно понимать что в принципе cost 954 это означает что в девять и пятьдесят четыре сотых раза это будет медленнее чем достать один блок размером 8 к это вот как бы такие условный попугая при этом цифры 2 первая цифра обозначает сколько будет пойдет времени до момента начала возврата первых результатов а вторая это сколько пройдет времени до того как результат будет возвращен весь если вы достаете много данных то соответственно первая цифра будет какой-то относительно маленькой вторая цифра будет достаточно большой а вот это актуальное время сколько это на самом деле заняло и если по каким-то причинам например у вас cost очень маленький а вот это вот время очень большое это значит что у вас какие-то проблемы со сбором статистике вам нужно проверить например включенную вас of the vacuum потому что тот же самый демон то вакуума собирает еще и статистику для оптимизатора дальше и explain это более-менее такое дерево на то есть есть нижние варианты и так грубо говоря сколько как как достать данные с диска то есть там это скан табличек скан индексов и так далее и более верхние варианты когда наверх наслаивается какая-то агрегация джойана и так далее это такое дерево когда вы смотрите на такой xp задача очень простая во-первых понять насколько быстро он работает до посмотреть на runtime посмотреть сколько там чего происходило следующий этап вам нужно посмотреть какой узел этого дерева самый дорогой если у вас на нижнем этапе сразу уже где-то cost достаточно большой xl time в общем то большой то значит вам вот этот кусок надо оптимизировать например если у вас сканируется табличка целиком вам может быть там понадобится сделать яндекс может быть не понадобится может понадобиться но это вот то место которое вам нужно действительно оптимизировать на которую нужно смотреть если у вас например агрегация чудит как в нашем вот этом вот случае она там более тяжелое то вам нужно подумать как и от нее например избавиться то есть вы смотрите на explain и находите самые дорогие места после того как вы посмотрите на explain с полгодика вы в принципе как бы научитесь эти места видеть невооруженным глазом и у вас будет в голове такая голова рид какой-то бы набор рецептов что делать в каком случае опять же в принципе как бы вот эти вот набор рецептов это материал трехдневного курса поэтому подробно мы его сейчас рассматривать не будем я очень надеюсь что на пока дни летом в питере у нас будет большой подробный доклад вот именно с такими примерами но как бы вы будете например уже подготовленное вот этим докладом и сможете тогда это все он записать так сказать всех блокнотик и уже раньше на применять ну собственно говоря какими методами какими приемами можно пользоваться можно сделать яндекс в чем идея яндекса яндекс это меньший массив данных которые удобно отсканировать вместо того чтобы сканировать большую табличку поэтому все программисты любят индексы все программисты любят создать яндексе на все случаи жизни и считать что это дело поможет это неправильно потому что яндекс не бесплатен яндекс занимает место при каждом каждой записи в эту табличку индекс перестраивается балансируется и это все не бесплатно то есть если как бы вас вся табличка увешаны индексами которые не используются с большой вероятностью вы можете часть из этих индексов снести и будет быстрее тем не менее если в вашем запросе вам нужно например вытащить половину данных из таблички с большой вероятностью ваш индекс не будет использоваться потому что по яндекс имеет смысл спозиционироваться куда-то в достаточно точное место и эти данные достать если вам нужно большую простыню который сопоставима по размерам с таблицей sequence скан самой таблице будет всегда быстрее чем индекс can потому что вам надо будет сначала сделать яндекс can потом еще одну операцию достать данные по этому в принципе оптимизатор он конечно иногда подтупливает но большинстве случаев он в таких вещах не ошибается если вы смотрите создали яндекс и недоумеваете почему он не используется например может быть потому что без индекса будет тупо быстрее и вы можете на самом деле посмотреть в пожгли съесть такой параметр сессионная переменная лейбл индекс can поставить ее и соответственно wav или там наоборот закончу скан поставить вов и посмотреть с индексом без индексом быстрее работает медленный оптимизировать так запросы в бою я бы не советовал это все таки такой очень жестких костыль и очень такое серьезное ограничение функционала для оптимизатора но чисто поэкспериментировать посмотреть это полезно вы сделали запрос сделали для него индекс считаете что он будет работать отключитесь exchange lse к нам тебе так будет вынужден выбрать планом с индексом и посмотрите не получилось ли медленнее чем то что пост близ предложила вам сам большинстве случаев это именно так следующая история собственно говоря как написан запрос если у нас будет вот что-то вроде вот этого индекс браться не будет да потому что можно перенести это вот сюда и тогда индекс будет использоваться но автоматически конкурсе вот эту операцию сделать не может в принципе казалось бы что простое сложение но на самом деле как бы с таким же успехом можно предложить оптимизации вающие die for и порешать в подгрести большое количество типов данных на них можно определять любые операторы любые действия например алгебраически или каким-то еще и оптимизатор будет должен знать для всех этих типов как это действие выполнять то есть это как бы слишком для него задача тяжелая это никогда не будет работать следующая такая вещь например почему join работает плохо да один из важных узлов и to join join и все используют да там кто ни разу не использовал join так таких людей просто не бывает люди которые пришли из mais quel и джайнов боятся бывает такая штука но в принципе мы их обычно уговариваем не бояться написать join сначала 1 потом сам пойдет вот и дальше уже потихоньку потихоньку они тоже начинают писать join и и радуются как дети потому что на этом селе прикольно раз join работает хорошо но промывку или расскажет следующий докладчик и там тоже всего много интересного с оптимизации запросов и более того за последние пару лет оптимизатор майскую очень сильно улучшился но таких вещей как разрисовывай он покажется она делать не умеет поэтому вернёмся к адресам join и бывают разных типов и я говорю не о лев right in air и так далее оболгал ритмах как join и выполняются после сумеет три основных алгоритма джонов а именно на 102 название говорит само за себя мы берём данные из одной таблички и циклами собственно говоря их jonim он имеет хэш индекс когда собственно горя одна табличка чаще маленькая табличка хэшируется и поэтому хочу join с другой табличкой ну и соответственно merck join который тоже очевидно как работает и эти join и не всегда одинаково полезны оптимизатор может выбрать между ними например у вас join its и две таблички оптимизатор выбирает хэш join и в принципе вы понимаете что он работает медленно его вас не устраивает такая вещь и это как бы самая тяжелая часть запроса все дела на что имеет смысл посмотреть а индексированный ли у вас те поля по которым вы джо инете если у вас эти поля не индексирован и оптимизаторы может не выбрать место глуп который здесь будет очевидно выгодней если вы создадите этот индекс он будет использовать нас ты глуп и будет все работать быстро следующий момент у вас оптимизатор из каких то соображений выбирает in st 2 а вам кажется что одна табличка очень маленькая давай большой ореха из join там был бы очень уместен потому что маленькую табличку можно быстро прогрессировать и быстро с ней работать посмотрите сколько у вас в окне мо сколько памяти может занять один в архив под gresso если эта табличка хэшируется в например там 100 мегабайт а у вас в окне мо выдано только 30 мегабайт то в такой ситуации у вас сварки будет отапливаться на диск для того чтобы сделать это хэширование это будет медленно поэтому если вы чуть-чуть добавить и в окне мы и у вас хэширование будет влезать в память оптимизатор выберет правильный join хэш джоуи на он будет быстрой хороший то есть это как бы вот такое вот поле для экспериментов то есть тут как бы надо думать и не стесняться проверять пробовать и смотреть что происходит но опять же поскольку оптимизировать запросу нужно только на бою потому что воркаут на bayou этого полотна бою на тесте вы его не воспроизводите никогда настолько же точно то делать это надо с известной осторожностью вот пример такой оптимизации да я уже показывал этот запрос и очень ругался на него ну одна из особых причин для такой румыния состоит в том что все таки postgres не супер совершением down развивающейся есть там какие-то недостатки где-то что-то не доработала в принципе как бы сообщества всегда говорит что очень нужны разработчики оптимизатора то есть если как бы вы хотите потреблять по адресу то можете на это в ту сторону посмотреть такие усилия будут всегда как бы сопровождаться ну очень приветствоваться сообществом но тем ни менее какие-то вещи не доделаны а вот это вот случай с таким длинным массивом в вы очень распространенной потому что многие время это делают по идее поидее пост близ должен как-то хэшировать массив и соответственно осуществлять в нем поиск вместо этого он его перебирает и получается достаточно противно воле более-менее время растет для длинных этих штук очень существенное начинается проблемах часто бывает очень толсто эти списки если мы посмотрим на этот explain этого дела мы видим что у нас вот этот фильтр собственно говоря без хэша работает плохо несмотря на то что у нас тут индекс can для того чтобы что-то там сделать и выбрать на вот этом массиве мы на самом деле засчитаем и он работает как бы максимально плохим образом да и все у нас дела тормозит ну собственно говоря в этой ситуации запрос необходимо переписать да то есть вот какие-то такие финты типы войны был бы сейбл sex.com тут не помогут и переписать этот запрос можно так сказать включив немножко воображении я уже говорил что после сумеет х join но не умеет хэширование массива давайте мы тогда с конвертируем собственно говоря вот этот вот вот эту простыню так таким образом чтобы это дело можно было же джойнер результат вот это вот вот эти штуки в принципе в результате получится то же самое только оптимизатор выберет более разумный план как бы запросы не надо стесняться переписывать ну собственно говоря что можно сделать можно использовать такую конструкцию в льеж который как бы нам это дело превратит в resulted и в этой ситуации на самом деле будет индекс can i have join будет произведена хэширования и эта штука довольно существенно ускориться если мы возьмем те же самые запрос это вот переписанная уже нормальным образом оно будет примерно так же подать на коротких запросах но что самое главное оно будет не хуже практически работать на больших длинных списках и это в принципе достаточно легко переделать то есть вот как бы пример простой как посмотревшие на explay можно существенно как бы улучшить производительность тормозного запроса и соответствует запрос тогда уйдет из топа появятся новые запросы их тоже можно будет оптимизировать есть еще одна проблема это проблема очень существенно бывают такие запросы с которыми нельзя ничего сделать и первейший из этих запросов это аккаунт это просто моя любовь то есть если вы видите интернет-сайт у него есть главная страница она высоко нагруженная там отображая но там много пользователей они что-то делают там отображаются соответственно счетчики ну вот вы видите счетчик одна тысяча там 12 миллионов что-то там трам-па-пам и там 234 какую информацию пользователю несет это дело если это аккаунт по табличке который часто обновляется это означает что на тот момент когда он послал свой запрос цифра была такая да и эту цифру как правило пользователю не важно знать с такой точностью можно знать более-менее приближенную цифру и ничего от этого не изменится до а часто еще вообще можно просто знать что она растет или не растет например если это какой-то там финансовый баланс и так далее да можно соответственно это все делать но грубо говоря это обычно делается сильно реже это не выводится на главную страницу какого нибудь сайта чтобы при каждом обращении к und по табличке гонялся каунт он всегда медленный почему он медленно и почему это очень плохой запрос потому что по згрлс чтобы посчитать количество записей в табличке всегда сканирует и целиком и более того проверяет актуальна ли эта версия данных или ее уже обновили поэтому от к ун-тов как бы производительности ждать не приходится они очень медленные первый вариант решения этого дела не использовать каунта да то есть как бы ну полезность этого дела сомнительная ресурсов они занимают много второй момент можно использовать приближённый к und есть пока каталог из него можно по силе птиц сколько строчек в табличке была на момент последнего анализа когда был произведен последний сбор статистики и это приблизительная цифра она будет меняться достаточно часто но при этом как бы этот запрос по каталогу не стоит фактически ничего это select 1 целью по условию там название таблицы если вы не хотите пускать интернет юзера базы впг каталог вам ничто не мешает написать хранимую процедуру сказать и security дизайнер и дать право только на эту процедуру интернет пользователю и он соответственно бы совершенно спокойно доставать эти данные без всяких проблем security на следующий момент джоем на 300 таблиц ну как бы на этот вопрос вы уже сами можете мне ответить да то есть в чем тут будет проблемы у вас будет 300 факториал вариантов как это join сделать более того у меня как бы плохие новости для вас если вам понадобилось написать join на 300 таблиц это значит что-то у вас очень плохо с дизайном схемы то есть что-то очень конкретно непродуманное надо много чего переделывать в норме как бы join это на 2 на 3 таблицы иногда на 5 иногда на 10 но это как бы уже более-менее крайний случай когда там join of будут сотни любой базе данных не только после сварку тоже например станет плохо следующий момент клиенту возвращается миллион строчек ну кто то ли стал до последней страницы в google и часто это вообще делаете я как-то терпение никогда не хватило видел внушение тестировщик а вот если вы видите что онлайновый запрос который вас это результат его отображается на сайте так далее по каким-то причинам возвращает миллион строчек задумайтесь нет и здесь какой-то ошибки потому что ну может быть понадобится 10 строчек может быть там 20 может быть стону миллион строчек человек не читает и если у вас возвращается такое количество данных это значит что либо у вас какая-то выгрузка данных котором можно сделать ночью можно сделать с помощью дамб а можно сделать еще каким-то способом либо у вас просто неправильно написан запрос например в и сгенерировал римом запрос для какой то ли сталки и дальше соответственно вытаскиваете себе огромные этот массив а используете и из него реально только там 10 процентов в этой ситуации вам нужно использовать лимиты я все тт или ст там соответственно кем-то другим способом только вот определенным окном идти по этим данным и не тянуть их все на клиент потому что если вы тянете миллион строчек это всегда будет медленно чисто даже на передачу этих данных по сети и как правило это будет не осмыслена как правило это будет содержать какую-то логическую ошибку ну собственно говоря на этом более менее у меня все и если есть какие то вопросы я с удовольствием на них вам отвечу там сразу два добрый день спасибо за доклад вопрос 2 performance апдейта на огромном количестве записей в таблице наблюдением получается что делиться ensure там иногда может быть эффективнее иногда нет что по этому поводу мышц сказать ну во-первых если мы говорим об агрессии то на самом деле там всегда происходит делиться inserto апдейт под грейси это в принципе не 40 новой записи исключения из области видимости старый если у вас очень большая табличка и много конкурентных апдейтов это естественно как бы будет подтормаживать и как это оптимизировать это уже вопрос нужно смотреть на сам запрос смотреть сколько полей обновляется и смотреть нет ли там какой-то лишней работы очень часто апдейты можно сильно ускорить очень простым способом повесить триггер если в апдейте приходит данные такие же точно как старые данные не делать ничего postgres из коробки такой триггер умеет и соответственно таким образом нагрузку можно очень сильно снизить второй момент как такие тяжелые апдейты ускоряются это тогда ваймы метод ход апдейт хип only the poles апдейт что это такое по сгрыз внутри себя умеет одну хитрую штуку если это колонка этот apple не покрыт индексом он может внутри оптимизировать количество ввода-вывода то есть он просто дополняет в ту же самую страничку сильно более эффективно еще один соответственно тапу это работает сильно быстро но там возникает проблема что во-первых у вас не должно быть лишних индексов чтобы этот механизм работал во вторых с большой вероятностью вам нужно иметь место в этом же p&g чтобы этот топор туда добавился для этого есть настройка фил фактор ее можно покрутить в районе 70 80 процентов чтобы соответственно апдейта под ускорились но в принципе в принципе я бы вам как бы советовал все-таки посмотреть внимательно в чем именно причина там тормозов во-первых посмотреть explain во вторых пойти на наш сайт там есть get хабов ская ссылка пиджи utils по которой я уже сегодня говорил там есть такое скриптик ты был диск activity и там можно посмотреть сколько происходит апдейтов какой процент из них ход какой фил фактор и покрутиться поиграть с вот этими вещами посмотреть вообще от какая там запись есть спасибо и второй вопрос короткий по вашим наблюдениям производительность padre под линухом и виндой как-то принципиально отличается если да то как да она отличается принципиально под линуксом она есть под винду и нету спасибо к сожалению это некоторая проблема потому что под gres много процессная база данных и все происходит вокруг жареной памяти в unix о том смысле в windows она симулирована поэтому к сожалению со скоростью там большие проблемы прошкурили на windows спасибо за доклад у меня такой вопрос нас есть там табличка в нее там около миллиона записей там индексы все классно работает история из жизни и в какой-то момент табличка начинает тормозить смотрим explain что там вместо индексы начал использовать секс can и вот стало все плохо сделали индексацию опять стал использовать яндекс как вообще вот таким бороться сделать просто индекс периодически как понимаешь так тут ну конечно это до некоторой степени там гадание по собачий мозоли потому что как бы я только с ваших слов бабло знаю описание этой проблемы но с большой вероятностью у вас не донастроена вакуума потому что вот такой вот расползание blood индексов да когда он перестает использоваться когда считает оптимизатор что лучше использовать секрет шел скан и это лечится ли билдом intex а означает что индекс сильно дефрагментировали вам нужно просто по агрессивнее настроить of the vacuum как правило там есть такой параметр автор of the vacuum vacuum sky инфекта по дефолту он не достаточно агрессивные его нужно поставить где-нибудь в одну сотую чтобы когда изменится хотя бы один процент записей в табличке пришел of the vacuum и вычистил соответственно те самые вещи то есть вам нужно прежде всего настроить of the vacuum массивом из настроек авто вакуума там есть еще несколько и вкус ну как бы если хотите подойдите потом настойку на нашу я вам расскажу что там еще может быть долгая песня еще вопросы илья спасибо честь вопрос насколько я знаю postgres умеет использовать джейсон своих полях когда и как вообще лучше использовать в такие моменты осуществлять там различные опять же те же join и поезд сортировка me смотрите подвес хорошо умеет работать джейсоном ну как бы я говорю о 94 версии прежде всего ров там там такой если у вас есть данные по которым вы производите поиск выборки join и и так далее это должны быть отдельные колонки как правило но обычная история такая что вы имеете какие-то данные про которую об этом уверен это мой diy логин чуть в этом роде а есть какая нет там простыня прочих данных пользователя по которой вы не знаете будете ли вы когда-нибудь делать выборки и в такой ситуации вы можете добавить там джейсон поля назвать его экстра и складывать туда все эти параметры если вдруг вы замечаете что вам нужно делать какой-то такой поиск вы по этому полю можете построить джин индекс вы можете построить функциональный яндекс по определенному полю и в принципе это будет работать достаточно быстро но если процент таких запросов будет расти вам лучше это поле вытянуть в отдельную колонку то есть вот алгоритм примерно такой те вещи которые редко достаете отдельно можно хранить джейсоне большой простыню это будет хорошо быстро он там сжимается хорошо реализована если соответственно вам нужно будет делать частый поиск лучше в отдельную колонку спасибо так еще вопрос так вот там собственно когда вы говорили про запросы с которыми ничего нельзя сделать вот я хотела еще уточнить на тему join и на 300 таблицы вот что можно сделать такой бизнес логикой когда много таблиц смотрите как бы много таблиц это окей мой может быть зачем то вам нужно много таблиц это нормально но если вам часто приходится делать joint по всем таблицам вам нужно что-то де нормализовать если этот join делается часто он занимает какой то там процент в топе медленных запросов значит надо что-то переделать однозначно потому что когда нужно j300 таблиц просто как бы с реляционной логикой что-то сделано было сильно не так обычно как бы можно подставить костыль да можно результаты этого джойана складывать в какую-то отдельную табличку и там как бы их где на борзова нам виде таком кэшировать если это единичный случай если вам это приходится делать для каждого нового запроса которые там не знаю на сайте что-то показывает значит нужно переписать спасибо так ну если вопросов нет то большое спасибо и нас можно будет найти сегодня на митапе опускали совам в 4:00 либо соответственно вот у нас там как раз напротив выхода из зала наша стойка если что приходите мы с удовольствием на какие нить еще вопросы ответим спасибо и поприветствуйте следующего докладчика"
}