{
  "video_id": "ID_W5nMi8cE",
  "channel": "HighLoadChannel",
  "title": "Внутреннее устройство PostgreSQL / Григорий Смолкин, Сергей Петров (Postgres Professional)",
  "views": 10184,
  "duration": 2793,
  "published": "2017-04-22T14:48:17-07:00",
  "text": "таких очень зажигательных дуэта если я могу так выразиться ребята будут выступать парами и сейчас у нас будут доклады от компании по профессиональ ребята очень много занимаются всяческим Кингом и панго постгрес знают очень много про про устройство нам о том как работают в постгрес временные таблицы Как бороться с проблемами фрагментации памяти и как вообще со всем этим делом жить Давайте поприветствуем коллег и новые добавляем тоже раз раз раз добрый день всем мы сегодня рассказываем Вдвоём по-моему это для такого мероприятия нехарактерно Но на самом деле в этой работе принимало участие гораздо больше человек немножко о том что мы делали в общем коллеги из АГП делали для достаточно крупного заказчика 1С приложения и поскольку сейчас популярно импортозамещение и экономия они попытались в качестве лежащей 1С убд попробовать постгрес и для настройки этого постгрес пригласили нас стоит отметить что им удалось собрать такой стенд который не взрывается на котором действительно можно гонять тесты и результаты этих тестов в разных проходах можно между собой сравнивать для нашей практики это редкостный случай Если Вы посмотрите на версии софта то наверное заметите что это не самая свежая версия пос и не самая свежая версия 1С которая сейчас доступно Мы начинали над этим работать летом есть мнение для 1 не существует хороших тестов и опять же Большое спасибо коллегам из агру они видимо для приемочных тестов у заказчика сделали эмуляция с там временем подумать временем где-то даже покурить если кому интересен набор тестов которые которые Элит это мы можем показать тест довольно длинный он состоит из десяти часовых итераций мы начинаем работать там в разных приложениях от 15 до п виртуальных машин и с каждой итерации ступенчато увеличиваем нагрузку примерно на 10% опять же это не oltp нагрузка не синтетика какая-то У нас есть операции которые должны выполняться Как быстро с точки зрения пользователя порядка 1но секунды так какие-то достаточно длинные операции длительностью которые должны уложиться в 3 минуты объём оных баз Ну типично для суд уже такой что в память не влезает но на диске пока помещается отдельно хочу обратить внимание на хард конфигурацию Ну не у каждого под столом стоит такой десктоп и очень быстрый Fus это то самое которое сечас становится популярным это очень очень быстрый диск С такой богатой конфигурации мы рассчитывали Ну что может быть мы и не обгоним сразу но по крайней мере что-то хорошее покажем и вот что у нас получилось с первой попытки Мы дошли только до шестой итерации С постоянно увеличивающейся нагрузкой и дальше у нас тент отвалился 1 приложение отказа с наработать показал что мы почему-то почти половину времени проводим в ядре это Ну нехарактерно по крайней мере большой объём памяти очень я опять повторюсь очень-очень быстрый диск позволял надеяться что у нас всё будет Ну если не отлично то хотя бы хорошо и мы углубились в анализ этого кейса завтра с утра Саша Алексеев будет делать большой обзор различных инструментов для профилирования если вам такого набора инструментов кажется мало или вы хотите узнать что-то новое и интересное рекомендую сходить сейчас слово моему коллеге который умеет применять этот инструментарий Так ну собственно было немножко стало интересно что же мы там делаем в этом ядре и Граф показал Вот примерно такую картину то есть мы явно занимаемся дефрагментации памяти чтобы говорить о дефрагментации памяти нужно сначала ра как вообще работает локация памяти в линуксе Как работает памяти в линуксе и тогда уже можно переходить к фрагментации Итак напомню что память в линуксе локатор памяти в линуксе это локатор То есть он не работает с байтами он работает со страницами и более того он не работает напрямую со страницами работает с блоками этих блоков и память может выделяться только в очень ограниченном скажем так очень ограниченным набором блоков то есть длина выделяемой памяти равна двойке в степени от нуля до дев то есть вот столько страниц локатор памяти в линуксе Может вам выдать Зачем так сделано во-первых это всегда это позволяет легко разделить более старший блок на два блока меньшего порядка если они закончились То есть например у вас приложение которое а очень активно по 8 КБ что-то лоцируется не будем показывать пальцами Что же это за приложение такое А вот вам как раз в этой ситуации очень это нужно аа теперь как работает клейм памяти у вас память системе разделена на ноды Ну если это многонотка в каждой зоне есть определенные вотермарки терки это просто значение некое значение количество свободных страниц ничем не занятых страниц которые локатор в любой момент может использовать для удовлетворение запроса на выделение памяти соответственно зачем они нужны каждая вотермарка она приложение что с презентацией Ну ладно появилось приложение которое очень активно кушает память и вот мы достигли верхней темаки терр так называемой Что здесь происходит в принципе ничего такого не происходит но если у вас стоял с равны нулю то теперь локатор будет его игнорировать и будет по-прежнему будет рассматривать теперь вариант вытеснения страниц то есть анонимные страницы вашего приложения будут вытеснен всё равно не будет не будет это делать часто но тем менее он это будет делать Следующий пункт Когда мы достигаем уже то есть мы достигаем у нас запускается в ядре то есть сакар его запускает удовлетворяя очередной запрос на память видит что мы зашли слишком то есть количество свободных страниц сильно упало и пробуждает работает в фоне и потихонечку освобождает память но у вас очень простите за график видимо не пережил импорта вотже не справляется с работой и вы достигаете мин вотермарки что происходит здесь здесь уже а локация памяти становится синхронной и вот здесь всё становится очень печально И очень медленно то есть управление приложению не будет возвращено до тех пор пока трета локатора не найдёт нужную Память то есть какое-то время локатор вместе с CD вместе судорожно освобождает нашли нужную память и после этого видите ВС идт на лад до фоне продолжают работать к до тех пор пока мы не доходим до верхнего рки после этого опять засыпает и зона считается сбалансированной то есть для машин это нормально когда количество свободных страниц находится гдето меж Теперь мы можем вернёмся к старому слайду где мы занимались фрагментацией попробуем рассмотреть его более детально а опуская промежуточные этапы на что здесь стоит обратить внимание во-первых это pf то есть что произошло процессор а получил адрес странички прочитал адрес странички из регистра не нашёл при этом физической странички а потому что процесс работает с виртуальной памятью и сгенерировал фол и теперь ядро занимается обработкой этого фота пытаясь для на соответствующую страницу далее это сердце локатора памяти здесь принимаются все решения то есть здесь мы пытаемся как-то быстро удовлетворить запрос на память то есть либо быстро выде страницу из листа с минимальным количеством локов либо если уже свободной памяти нет то ри мы уже здесь ушли в Ко и пытаемся понять а имеет ли смысл вообще заниматься фрагментацией Итак рассмотрим частный случай ёлки-палки так рассмотрим частный случай зоны зоны памяти которая очень сильно фрагменти То есть вы можете посмотреть здесь страни из при этом свободных страниц 50% локатор не видит ничего в этом странного и считает Да всё здорово Не нужно ничего делать при этом предположим Мы хотим ровать какой-то протяжённый кусок этой памяти допустим сделать сразу че страницы Ну попросить страницы за раз что в Тай ситу 31 с просто выделяла какой-то кусок памяти и сбрасывала лишние странички сейчас пришли к пониманию Ну в версии 310 пришли к пониманию что каждая сброшенная страничка - Это лишнее ИО которое потом придётся делать в той или иной форме либо это выяснение страницы swop либо это страничку нужно заново просчитать с диска и вот собственно придумали comp что собственно делается сначала изолируется запускаются два сканера с двух с начала и с конца зоны первый сканер изолирует страниц котора можно мигрировать второй сканер изолирует изолирует свободные страницы с другого конца зоны когда два этих сканера встречаются ещё раз извиняюсь за качество видимо что-то сломалось Да значит происходит перемещение то есть содержимое страниц переливается в изолированные свободные странички в другом конце зоны у нас получается красивая сбалансированная зона в которой мы всё разложено по полочкам и мы можем аллоцировать протяжённый кусок памяти а применительно к нашему случаю что здесь что вы в первую очередь увидите если столкнетесь с этой проблемой это у вас если допустим Вы будете использовать ф а вы у вас на первом месте по нагрузке будет Вот этот вызов isolate fre pages Block То есть это очень дорогой вызов здесь мы берём на всю зону на лист свободных страниц зоне на этот Лог всегда много желающих Потому что постоянно происходит локации памяти и вы будете если у вас фрагментация памяти Вы будете очень много времени проводить именно вот в этом вызове что можно с этим сделать есть два параметра два параметра ид нужен Он участвует в расчёте значения минимальной ватер марки вот Min watermark а от неё уже считается значение всех остальных р марок в зоне А что увеличение её что нам даст во-первых кбд начнёт работу раньше то есть вы у вас Чем раньше начнёт работать тем меньше вероятность что вы прося дете в самый низ у вас перманентно будет всегда большее количество свободных страниц памяти системе Чем это плохо Вы не можете эти страницы отдать своему приложению или использовать опыт P То есть это те страницы которые ядро гарантировано должно хранить свобод свободными и есть параметр эстра О чём Зачем он вообще нужен он управляет агрессивностью фрагментации то есть вообще имеет ли смысл делать делать дефрагментацию памяти если у вас мало ни то есть вы будете просто тратить Зря время пытаясь вать в зоне которая просто забита полными страницами для чего вам это нужно допустим у вас очень медленные диски и для вас каждое ИО - это боль тогда вы Да действительно можете Уменьшить это значение Ну до самого минимума если наоборот у вас очень быстрые диски или вас вас просто раздражает дефрагментация вы хоте сбрасывать страницы можете выкрутить его наверх и тогда скорее всего фрагментация пропадёт локатор будет просто сбрасывать страницы а там приведён пример вывода А есть а userspace Cheat А через cfs а текущий индекс фрагментации А вот по нему можно определить насколько фрагментированное Итак мы попробовали выкрутить в 3% от общего количества памяти в системе это сразу же дало положительные результаты у нас не токо сильно улучшился результат по времени исполнения запросов но и мы смог протянуть до следующей итерации то есть какой-то результат это определённо дало и тут вот как раз-таки мы обратили внимание на временно таблиц потому что вот это странная нехарактерная нагрузка связанная с фрагментацией она была появлялась именно в те моменты когда происходила очень активная запись в временной таблиц что мы вообще знаем о временных таблицах мы знаем что они привязаны к конкретному Кэн мы знаем что они находятся в локальной памяти что они удаляются когда завершает свою работу и пятая сть самое главное То что вот мы внезапно выяснили это то что резет место для временных таблиц резервирует постранично как это выглядит Если вы подключитесь рейсом к серверному процессу поса и создадите временную табличку и начте туда писать вы видите Примерно это да выглядит не очень Итак что здесь происходит здесь мы нулями забиваем файл это несколько странно решение Как нам показалось потому что это приводит к следующим проблемам Вох приводи мента памяти потому что вся запись в системе она происходит через файловый кэш Если вы во-первых когда мы пишем в во временной таблице нам нужно найти место во-первых нам нужна память для собственно в которой и живёт временная таблица в посе и получается теперь нам нужно найти память в ше куда записать вот эти очень полезные нули потом если по проше какого-то времени таблица не будет удалена она ещё и упадёт на диск то есть она попадёт в кэш вытеснив какие-то данные она попадёт в дисковый кэш тоже вытеснив что-то полезное оттуда и после этого она упадёт на диск ещё и сгенерить какое-то ИО как бы Вишенка на торте всего этого процесса а так я не знаю имеет смысл продолжать рассказывать дальше а Может откроем в этом в в ПДФ Ну там что совсем месиво начинается То есть даже фантазии не хватит никакой понять что там происходит но вообще это близко к тому что Что случилось У нас в офисе когда мы показали это коллегам Да там была смешная картинка мы её потом вырезали потому что она была возможно оскорбляла чито религиозные чувства решили не показывать Но идея забивать нулями резервировать место для временных таблиц это сильно А если мы правильно понимаем механизм работы временных таблиц просто взяли существующих обычных таблиц там есть механизм рения действительно так давайте посмотрим что тут у нас а у него видимо клики работает опа Может я просто сно поставлю Извините пожалуйста что так получилось Ну ладно в общем основная идея всё вот это вот валится в самый нищая ваш полезный ш помещая ваш полезный дисковый кэш генер какое-то соответственно раз проблема вторая проблема Ну то есть целая пачка проблем следующая проблема - Это собственно фрагментация потому что нам теперь нужно в двойном объёме находить напомню страница в постс - это 8 КБ соответственно Вам нам теперь нужно в двойном объёме находить странички размером 2 в перво степени то есть они в страницах считаются поэтому 2 в пер степени это как раз д страни то есть КБ А и ну первая реакция любого человека на это она была О круто то что надо вот вот вот график график нормального человека до этого был график курильщика вот Вот видите здесь медленная локация происходит А вот мы там поболтали и здорово А вот как тоже нормально выглядит зона дефрагментации э вот супер Итак А мы доходим до буферизации Вот здесь мы рассказывали то что оно падает на диск я ускоряю потому что мы время потеряли на этом соответственно первая реакция наша Давайте всё это просто вынесем в Темп FS не знаем Зачем мне задавать вопрос Давайте просто это вынесем в Темп FS это решит все проблема а проблему фрагментации это естественно не решает потому что вы теперь пишете Ну не в page CR вы пишете в ТМП FS разницы никакой а тройная буферизация она с оговорками ушла и превратилась в двойную а но МП FS может уйти в swop поэтому не уверен что мы что-то решили на самом деле но чуть-чуть стало получше потому что временные таблички на самом деле Долго не живут точнее наоборот они живут какое-то время и всё-таки иногда падали на диск А когда мы это унесли в тем FS то что-то мы немножко выиграли и видите даже прошли до следующего теста ну супер но вот административными средствами Это всё что здесь можно было сделать И после этого мы отправились в отдел разработки потому что такой вариант нас не устроил А вот о приключениях разработки опять расскажет Сергей Ну если бы те кто пишет постс были богами они бы наверное сделали чтобы по совсем обходил файловую систему и как кол использовал РАУ девайс поэтому действительно эта задача оказалась не очень простой но Анастасия лубенко сделала вот Маси возы неть на ди тем не менее У нас осталась некоторая заглушка под таблицу на файловой системе индекс осталась остался то есть мы не исключили полностью запись всего Что относится к временным таблицам на диск этот патч не был принят сообщество но зато есть у нас в рй версиях этот сообщество а вдруг чтото вот поэтому не приняли как это стало работать пока у нас достаточно места в тем бафер сах Э теперь всё выглядит разумно и мы ничего не пишем на диск никакие нолики на диск не уходят если у нас не хватает места для в тем бафер сах для наших временных таблиц происходит Вот что мы пишем вытесняя на диск только то что у нас не помещается в тем бафер Ну вроде бы тоже Разумное поведение поскольку в наших тестах собственно объём ввода-вывода по временным таблицам не такой большой они и в ТМС удачно влиза мы получили не такое большое уменьшение объёма записи но за счёт лучшего использование системного ша у нас существенно уменьшился объём чтения это вот тот выхлоп которого мы нежи итерации и по окончании десятой итерации мы внезапно обнаружили что у нас теперь в базе есть 300.000 временных таблиц 1С очень-очень любит временные таблицы чем это страшно расскажет Мой коллега временные таблицы действительно страшная вещь особенно тем что они могут сделать вот так они могут осиротели осиротевших временной таблицы появляются есть несколько условий появления их в вашей системе если у вас пос крашнулся то есть допустим выдернули питание когда там было создано большое количество временных таблиц пришёл Киллер и убил какого-нибудь какой-нибудь серверный процесс и постгрес сразу аварийно завершился или всё работает корректно кн создал большое количество временных таблиц и попытался просто завершиться во время завершение работы бэнда он должен за собой почистить почистить все свои временные таблицы а накладывая при этом он пытается это сделать в одной транзакции накладывая Локи на все эти объекты и зависимые от них объекты если у вас там 100.000 временных таблиц А у вас банально Не хватает размера таблицы блокировки и пог падает Out of memory А какие симптомы этого явления внезапно бэнды начинают отдавать Out of shet memory и при этом так как это шари отвалился но память-то она уже она шарит она уже занята ин не работоспособен без перезагрузки То есть даже свеже подключив клиент на какие-то действия с ломи будет получать а далее ещё очень интересный вариант хорошо у вас instance перезагрузился по теперь все эре Тани в постс автовакуум их не вычищать Ну осиротели что они в системном каталоге присутствуют по-прежнему То есть у них есть какая-то статистика они есть по Г классе А у них есть какие-то там схемы То есть каждый клиент он в своей схеме создаёт временные таблицы у них есть тосты у них есть индексы вот всё вот это вот оно лежит в ПГ классе Теперь если у вас 300.000 было временных таблиц в нашем случае было примерно столько то он у вас во-первых Здорово распухает во-вторых автовакуум не знает что с ними делать на данный момент принцип подход автовакуум к встречным временным таблицам такой он встречает громко об этом жалуется влог и идёт дальше если у вас их 300.000 каждый клиент автовакуум считает своим долгом написать а каждый логи ротива очень быстро вот если у вас их особенно несколько соте как у нас ну собственно вот всё что я это писал Извините далее Что с этим можно сделать есть профилактическая профилактическое решение и уже собственно лечение Вы можете увеличить Table Вот его формула она в принципе прямо почти из исходников выдра можете увеличить любой параметр он даст какой-то эффект мы увеличивали Ma Trans в 10 раз это позволим нормально завершаться если проблема уже есть Что можно сделать можно отключить во-первых всех клиентов от постгрес и просто дропнуть все имеющиеся временные схемы Почему нужно отключить приложение потому что вы можете выбить у клиента из-под ног его временное таблиц ему Это наверно не понравится Вот но опять же этот подход он какой-то неполноценный и мы опять отправились в отдел разработки в отделе разработки Константин Пан любезно сделал нам патч который во-первых решает проблему с лока а во-вторых он добавил научил автовакуум удалять осиротевших таблицы и добавил параметр а добавил Go параметр который управляет поведением автовакуум а к встречным осиротевших таблицам То есть вы можете их как раньше сохранять вдруг там действительно что-то ценное осталось а какие-то данные с какой-то транзакции а либо можете удалять этот патч уже есть на комит видимо в каком-то виде он войдёт в астрим по крайней мере мы на это Надеемся и Ну он точно войдёт в одну в нашу Enterprise версию или рй версию для 1S а далее про статистику Если вы присутствовали на докладе Ивана фролкова то он там уже немножко упомянул про статистику я расскажу совсем кратко что статистика - это очень сжатая информация о том какие данные у нас в базе находятся Благодаря этой статистике оптимайз может придумать оптимальный план выполнения ваших запросов если статистики нет весьма велика вероятность что ваши планы будут далеки от оптимальных Если Вы внимательно слушали предыдущий доклад то знаете что вакуум не трогает временные таблицы вот это вот расширение оно собирает таки статистику для временных таблиц То есть то что по иде мог бы делать вакуум Вы конечно можете сами руками выполнять анала по временным таблицам но это не всем нравится у онлайн анала есть почти такие же ручки как у обычного вакуум Айза Вы можете тонко настроить там эти таблицы трогать чаще настроить пороги эти таблицы совсем не трогать в свою очередь вот тут есть небольшая змея кусает себя за хвост он полагается на статистику стале это совсем скажем ста просто число строк и время предыдущего выполнения анализа Давайте посмотрим чего это стоит отличная картинка здесь надо обращать внимание на ширину выделенной части видно что почти 50% онлан работает сам на себя и ну меньше Половина времени база данных занимается чем-то полезным МСТ файл со статистикой хоть он и небольшой но его чтение становится дорогим Тем более что это не специальный выделенный процесс который в одиночку там или небольшими группами бегает по базе и обсчитывают статистику этим занимается каждый энд который что-то сделал достаточно для того чтобы запустить анализ вот если Посмотрите на этот кусочек графа это вот собственно чтение файла вторая проблема которая относится не только к Ола Но всем базам в которых очень много таблиц мы раздуем каталог и вот этот вот Поиск выделенная часть он выполняется не только в онлайн анала но и для полезной работы этот поиск тоже важен то есть по таким способом ищет в своём каталоге какие-то интересующие его Дан Вот это ви когда он пытается схватиться за таблицу и е проанализировать ВС остальное относится исключительно к принятию решения пора её анализировать или нет Ну нам такое сочетание полезного и бесполезного показалось странным и мы подумали а не отключить ли это Ну поскольку база была в наших руках мы взяли отключили ИТ полу прико табли то практически любая СУБД она не будет там думать это ИК Access с ними хорошо работают всяческие джоны и тут у вас нет проблем и даже для клиентских запросов которые короткие мы получили существенное ускорение Но вот для длинных запросов которые должны были выполняться за минуту и больше мы мы к сожалению ули за те пределы которые хотел бы увидеть конечный пользователь наши коллеги из Альп группа сказали ну данные то у нас что со статистикой что без статистики одни и те же и в принципе наверное как-то можно убедить базу работать с ними правильно наши коллеги из АГП сказали что они смогут оптимально образом переписать запросы так чтобы они работали хорошо Ну а поскольку не всегда у вас есть возможность переделать приложени то мы опять-таки отправились в отдел разработки Фёдор сигаев ну тут как бы путь переделки онлайн анализа очевиден Давайте меньше думать надо нам анализировать или не надо и больше анализировать есть ещё дальнейшее место чтобы сделать Улучшение поскольку временные таблицы они живут скажем так локально для каждого бэнда то мы можем их статистику хранить только в памяти этого бэнда и не пытаться описать в общий файл со статистикой чем ло общий файл со статистики мы сейчас увидим вот у нас стал такой менее агрессивный он база данных получила больше процессорного времени для полезной работы а вот наша загрузка видно что начиная где-то с пятой шестой итерации мы опять уходим в ядро это вызвано тем что у нас хоть и небольшой файл но как поскольку онлайн Алам занимается каждый серверный процесс кажды серверный прос загружает это фай был порядка 50-60 гиб и для 300 процессов это занимает Уже довольно большую память в приложении и у нас начинает уменьшаться файловый кэш мегабайт тем не менее этот патч тоже принёс свои результаты мы успешно добежали до десятой итерации даже немножко улучшили Вот А вот здесь это уже скажем так совершенно нормальная картина видно что сюда можно там нагрузку Ну если не утроить то во всяком случае удвоить и это собственно тот вариант когда коллеги из агру переписали свои тяж запросы и заставили их нормально работать без статистики А вот я не знаю видно ли вам полученные результаты тут Наверно нужен логарифмический масштаб но всё остальное будет смотреться бледно это ещё раз говорит нам о том что Несмотря на все усилия д разработчики приложений могут как существенно улучшить ситуацию так и ухудшить спасибо вопросы есть какие-то а а Спасибо за интересный доклад Скажите пожалуйста а у вас пог жил в нескольких нома зонах или в одной И вообще почему не пытались ли вы отключить нума А да на самом деле там было четыре нума ноды мы не пытались отключить Ну я так понимаю под отключением нодами имеете в виду сделать Zone reclame включить а но в загрузчике там можно А я понял Можно но это мы мы пробовали не сильно много выигрываем мы выигрываем на том что память теперь да мы Обращаемся только к локальной зоне а точнее Нет извините я вру у нас Zone релей был отключен то есть мы если не хватает памяти в локальной зоне мы шли в другую зону Вот вы предлагаете это отключить или включить А я имею в виду вообще попытаться не использовать нума Может это ну а как вы може тация уменьшит а нет ну а как вы отключите ноду вы за скели на другое ядро и у вас там локальная память как вы её отключите не не Linux запустить без нума А ну память всё равно локальная То есть как это можно сделать Ну в загрузчике есть опция что-то там прон что ли Илин это даст Вот именно тот самый эффект то есть Вы теперь будете не свою локальную память не воспринимать как локальную это да это даст какой-то выигрыш но вы не забывайте что вы очень много выигрываете на локальной памяти если Вы посмотрите на num Hit он всегда на несколько порядков выше чем хождение в чужую память Ну в соседнюю память это дорого На самом деле и здесь выигрыш такой ну то есть вы на чём-то выиграли на чём-то проиграли Скорее всего вы даже больше проиграете потому что вы очень часто обращаетесь к своей локальной памяти Вот спасибо такой вопрос вот по поводу настройки выделения памяти в системе не получится ли Так что если мы поправим памет предлагали Ну когда поток который выделяет память будет у себя хранить большее количество памяти не Возьмёт ли он в первом доступном месте а именно в дисковом кэше и не будет ли в целом всё хуже после этого так то есть ещё раз в дисковом кэше что Он возьмёт Ну допустим если вот вы говорили о параметрах вотермарков по памяти Да соответственно если настроить более агрессивно чтобы менеджер памяти как бы хранил у себя большее количество доступных для выделения страниц соответственно их надо где-то взять Вот наиболее логичное место дисковый кэш Ну то есть скажем так доступное место для дискового кэша Вот и как бы так не получилось что при высокой нагрузке на дисковый кэш общее как бы ну то есть промах по этому дисково кшу окажется хуже чем всё что мы по наделали все это оптимизации это действительно как быт потому что дест банально меньше памяти становится доступной Да а действительно мы на этом что-то проигрываем но выигрываем гораздо больше то есть да это это трейдов как бы честный Можно вопрос Вот я здесь Спасибо за доклад мы вот тоже сталкивались с проблемой Out Of SH Memory и maxl transactions увеличением вы вот обмо что после возникновения Memory это нейт до перезагрузки кластера это действительно так есть тот процес который отвалился он оставляет Вот это блок занятой памяти в шаре это шарена память Да таблица локов она шаре памяти Ну то есть там есть и локальные Локи но конкретно вот для удаления схем он идт остатся дада да Ну это можно назвать утечкой по сути то есть здесь на самом деле он почти прекращает работать потому что новые клиенты не могут Ну много чего делать надо реб кластер получа если такая проблема возникла то да Жуть какая Какой ещё вот Может быть вы подскажете Побочный эффект от увеличения ма maxl transac ну больше памяти вам нужно шарена памяти то есть меньше памяти под шарен под файловый кэш и под что-то ещё Спасибо тут Наверное стоит сказать что увеличение таким образом объёма памяти оно ну как противоборство брони и снаряда когда-нибудь придёт приложение сделает ещё больше временных таблиц и возможно вам в этот момент памяти не хватит вот на самом деле нач сообщества Ну не приняли пач потому что сказали что Ну а вдруг мы что-то закатили у нас кончилось место и мы получается обманули пользователя то есть мы сказали да комит а потом извини чувак У нас как бы нет места чтобы записать твои данные это абсолютно валидная причина для обычных таблиц Но для временных таблиц нам показалось что это как-то очень притянуто за уши и вот есть для обычных таблиц Вот резервирование это нужно это важно без этого никуда а для временных таблиц нам непонятно зачем это нужно и вот ну поэтому это так вот отключили выпили точнее Спасибо за доклад вот у меня собственно Вопрос такой ну по докладу я понял что бы приня все они заключались в том что мы выпили Вот это и вот это И вот это и стало Зашибись Круто Ну кое и влили кое-что вс-таки ну в основном выливали ну 90% выпила грубо говоря да а это какие-то побочные эффекты возымело Потому что как-то магически так вы выпиливать проще чем вливать правильно на самом деле Ну приложение не падает то есть мы какие-то свои тесты провели они не падают не падают то есть всё хорошо данные Ну мы конечно думали об этом а не потеряем ли мы там как-нибудь что-то важное А конечно мы тоже это активно потестить Вроде бы ничего не теряем Вот то есть всё работает но конечно какое-то дополнительное тестирование Оно всегда нужно и в случае чего мы будем его проводить Конечно вот у вас в конце было что самый лучший вариант это Когда разработчики запросы переписали вы не пробовали Запустить вот просто новые запросы Без всяких ваших фишек может быть дело в запросах а не в улучшениях это интересно было бы посмотреть на Как скорость просто с переписанный деле это несколько уже архивные такие данные то есть мы немножко как бы уже не можем этого сделать к сожалению Но проблема с времи табли она бы никуда не ушла то есть мы по-прежнему если у вас их там 300.000 и каждый из них занимает Ну хотя бы не знаю пару страниц это ну уже значительная часть файлового кэша у вас вымыла и забита нулями то есть мы здесь очень сильно на ео проседает да Скажите если вот мы не слышали тысяч да временных таблиц использу Ну где-то так было Да мы видели А можете вкратце рассказать почему зачем А это я не знаю мы это же 1С и Для нас это был чёрный ящик то есть оттуда что-то прилетает туда улетает почему она делает временной таблицы Ну не знаю оно имеет право их делать почему бы 1С этого не делать то есть это законно статьи за это Нет а Не ну мы попробуем об этом сообщить как-нибудь при встрече Спасибо за доклад Если я правильно понял из текста одной из серьёзных проблем была проблема осиротевших таблиц их количество служите А вот конкретно с этой проблемой вы как-то боролись то есть там например просмотр по максимальному номеру транзакции и нафиг их всех то есть ну грубо говоря вот эту часть проблемы вы побороли этом быть второй патч от Константина Пана там даже ссылка на кофе предыдущей лекции нам сказали что не надо бояться врап раунда и действительно вра раунд он не только страшный был но он ещё был в чём-то полезный потому что вот эти вот осиротевших временные таблицы автовакуум удаляет только при наступлении в раунда когда-то он их удалит Если вы сможете доработать до этого времени в чём не факт я пытался отключать эту проверку на рауд и просто забивал там 00 временных таблиц и автовакуум просто падал на на ну то есть как если бы был Вуд Вот автовакуум бы вам не помог а здесь на него не стоит полагаться на самом деле А ещё маленький вопрос Алай не работает для временных таблиц Да он работает Просто автовакуум не работает для временных таблиц А это осно не работает для вре да а это основной источник статистики как правило Вы можете сделать анала явным образом Ну понятно что я могу да то есть олайн analiz - такой костыли который по сути делает э авто Алай для временных таблиц Ну там можно назначать и для обычных таблиц То есть если он вам нужен более агрессивный а но вот это Это всё что он делает вот он там принимает решение на самом деле на основе количества плов которые изменены в нынешние транзакции количество имеющихся плов и количество мёртвых плов и когда последний раз было нала То есть это вот и на основе этого там нав евристика вокруг всего этого и Ну вот у вас допустим 300 серверных процессов и они все лезут за этой статистикой а вся эта статистика она лежит в файле который пишет ц коллектор и Представьте 300 кэндо читают пятидесяти мегабайт файл себе в локальную память и ну умножьте 50 Мб на 300 вот получается приличный кусок вашей памяти уходит вот э на хранение в локальной памяти этой таблицы со статистикой откуда вам нужно буквально две строчки и вот мы хотим чтобы это хранилось мы хотим сделать чтобы это хранилось в локальной памяти Ну судя по всему вопросов пока что больше нет коллеги Давайте поблагодарим наших докладчиков"
}