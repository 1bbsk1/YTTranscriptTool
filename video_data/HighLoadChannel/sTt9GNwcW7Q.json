{
  "video_id": "sTt9GNwcW7Q",
  "channel": "HighLoadChannel",
  "title": "Распределенная трассировка — подключить всех и не умереть! / Филипп Бочаров (МТС Digital)",
  "views": 1487,
  "duration": 2304,
  "published": "2023-01-19T05:55:16-08:00",
  "text": "тогда сегодня мы поговорим про распределенную трассировку чему я об этом что-либо знаю потому что в мтс моя команда делает платформа наблюдаемости это такой набор сервисов которая позволяет сделать работу других продуктов мтс более понятные и прозрачные то есть наблюдаемый и распределенная трассировка это один из тех сервисов которые мы предоставляем что у нас сегодня ждет ну для начала мы начнем с того что поймем зачем нам вообще нужно распаренной трассировка какая в ней ценность после этого мы вместе с вами спроектируем коммунальную систему в которой будем собирать распределенную трассировку всей нашей крупные экосистемы мы ее отмасштабируем от 0 до 50 тысяч документов секунду процессе посмотрим как меняется наша архитектура и попробуем под этой нагрузкой не помереть поехали зачем мтс распределенная так господа включить пожалуйста презентацию да ну на тех слайдах не было еще интересного самый интересный этот и так зачем мтс распределенной трассировка зачем трассировать экосистему для этого надо чтобы ответить на это вопрос надо посмотреть на самую систему она довольно крупная это более 400 цифровых продуктов она гетерогенная то есть продукты написано на разных языках что-то очень современное что-то наоборот legacy но самое главное это именно экосистемам продуктов то есть продукты не изолированные они взаимодействуют друг с другом на ландшафте возникают такие длинные интеграционные цепочки когда продукты взаимодействуют чтобы пользователю какую-то ценность принести собственно что в этой системе может пойти не так на всего очень много это все очень разная это все связано между собой понятно что добавляя новые продукты к систему мы ее усложняем да у нас удлиняются этим интеграционной цепочки самая система становится более сложной как это можно представить но представьте у вас есть пользователь он хочет принести вам денег до сделать какую-то важную операцию например оформить подписку на услугу ваш экосистеме за эту услугу отвечает 4 продукта abcd все разработаны разными продуктовыми командами на разных стеках у пользователя ничего не получается почему не получается потому что между продуктом а и b постоянность никакой тайм аут бене отвечает продукту а на запрос при этом б в этом совершенно не виноват виноват сервис от которого зависит там возникает какая-то ошибка постоянные ретро и в общем итоге пользователь никак не может свою подписку оформить ну что делают жалуются да если бы мы с вами отвечали за эту систему и жалобы пользователя обрабатывали мы бы очень многое отдали за то чтобы вы такую картинку как то автоматически увидеть да то есть право посмотреть что там происходило с нашей экосистемы момент когда пользователь свою подписку оформлял как это сделать ну к счастью что-то подобное нам может дать распределенная трассировка это такая графическая древовидная структура данных которые описывают как наш интеграционный процесс и к системе выполнялся значит все это дерево называется trace'ом а каждая строчка каждый шаг называется с паном что здесь есть да то есть usb она есть чек а понятное название вот первый span называеться http get dispatch он соответствует какому-то get запросу к методу dispatch мы всегда знаем какой сервис породил наш span вот и сервис frontend касты маску или и так далее но это не главное главное то что у каждого spano есть тайминг мы всегда знаем сколько времени у нас выполнялся шаг да и тут справа timeline и и признак ошибки то есть если на этапе какого-то шага что-то пошло не так мы увидим признак ошибки в планах вот последний шаг обращение кризиса как раз содержит ошибку все это делает распределенную трассировку идеальной структуры данных для проведения локализации дефекта то есть по этой картинке мы можем понять какой продукт какой сервис и даже какой метод виноват в том что наша система либо слишком долго работает либо вообще не выполняет какой-то интеграционный процесс давайте чтобы немножко развлечься поднимите пожалуйста руки тех кто на своем проекте используют распределенную трассировку отлично ко мне пришли профессионалы итак я надеюсь я сумел вас убедить в том что растворено трассировка штука очень полезная интересное а теперь давайте подумаем а что мы хотим получить для нашей как системы какую систему мы сейчас с вами будем делать мы поняли что нам нужно локализация дефекта причем на уровне всей экосистемы нам нужен in the end такая сквозная трассировка через юко систему от первого продукта до последнего kotova нам мало мыльцем хотим понимать насколько качественно вас такая система как у нас работают продукты нам нужны метрики метрики производительности всей экосистемы продукта и даже там отдельного процесса ну то что называется pm метриками ну и наконец у нас 400 продуктов всех нужно подключить поэтому подключение должно быть дешевым поэтому мы все будем делать по модели пас чтобы вся инфраструктура была у на была у нас начнем конечно собой раз т.к. да на чем мы все это будем делать когда мы с команды начинали нашу работу над платформой у нас не было возможности там запереться на год в какой-то комнате и проанализировать вообще все доступные концертные и венгерские решения в области а п.м. поэтому мы сделали небольшой ограниченный и рэнди результатам которого выбрали два компонента это у концов система распределенной трассировки джаггер и elastic search как хранилище trace of джаггера почему джаггер ну во-первых мы посмотрели на его исходный код поняли что довольно простой и мы можем его дорабатывать да под собственные нужды во вторых он полагался на открытые стандарты тогда это было панд racing сейчас а то понте lamie3 но в общем у нас абстрагирован от самой реализации давал нам некий опеки стандарт который мы могли пользоваться он поддерживает несколько брендов это давало нам надежду что если свастик search у нас что-то не сложится мы всегда можем мигрировать на какой-то другой backend почему elastic ну во первых потому что elastic известен как хранилище логов на мы решили отлично меньше зоопарка у нас все трейси логе будут в одной системе хранится ну или самое главное в компании уже был опыт использования ластика были обучены инженеры то есть мы бери использовали их знания давайте посмотрим на старт в архитектуру там самую минимальную которую мы можем сделать из этих компонент у нас будет какая-то там пас на я часть давайте для простоты развернем ее вообще на одном посте в каком не докер композита чтобы там совсем помянем аллочке все было что там будет там будет джаггер коллектор это сервис который собирает распределенную трассировку почти псы умеет и и записывать в elastic search для работы с рейсами у нас будет джаггер ю ай да вот скриншот из него вы как раз видели в начале презентации и у нас будет киба на кибо на будем использовать для создания разных даже городов по распилено трассировки для того чтобы различные аналитику собирать на стороне продукта на стране нашего потребителя у нас будет к это приложение которое инструменти равана пан телеметрии леопон прессингом не столь важна и она описывает нам распределенную трассировку здесь мы можем принять одно довольно важное архитектурное решение которое нам будущем поможет мы можем разделить поток трассировки от продуктивных стендов и от тестовых то есть мы создаем два паса один называется прот другой стричь почему номер потому что можем обычно трейси обычно тестовые системы работают с тесными системами продуктивны из продуктивными да у нас не получится ситуация когда один trace развалился на две части там половина на вроде половину раз ты че что мы получаем какие бонусы мы снижаем нагрузку на прот немножко там на 10 процентов но тем не менее это приятное такое снижение и кроме того мы получаем возможность тестировать все наши релизы все наши изменения на в общем-то реальных пользователях реальных данных полученных из тестовых стендов уменьшая вероятность того что мы какую-то ерунду зальем на наш продуктивный стенд а что с оппой метриками ну самый простой и дешевый способ их вычислить это сделать даже городские бани что мы делаем мы берем индекс с распределенной трассировкой ищем там те span и которые нам интересны и группируем по определенным признакам ну например мы можем взять все запросы к нашему приложению и сгруппировать их по звони сервиса контроллера и собственно метода посчитаем для каждой такой группы количество вызовов там какой пир сенти длительности вот наши а по метрике готовы они считаются прям по сырым данном режиме онлайн а в общем наши пользователи счастливы счастливы они ровно до тех пор пока мы не начинаем нашу систему нагружать пока мы не начинаем не подключать реальные продукты давайте подадим на нашу систему нагрузку в 3000 спама в секунду вообще много это или мало 3000 спа на секунду да правильно это очень мало спойлер почему значит но примем за аксиому что на один сетевой вызов в трассировки обычно приходится два спа на это span который соответствует исходящим запросу испан который соответствует входящему пуля вылетела пули прилетела если мы с вами возьмем как анти продукт с микро сей раз на яхте гту рай там допустим 10 сервисов то один запрос к этому продукту будет порождать соответственно 2 на десять-двадцать планов пример нагружая такой продукт 150 запросами секунду мы получим поток в 3000 spano в секунду нашу сторону это на самом деле очень мало и один продукт может вам спокойно обеспечить такой трафик даже на этом небольшом трафике мы начинаем терять span и вообще привыкайте с этого момента мы постоянно будем терять речь будет идти только о том какой процент потерь у нас чтобы сделать этот процент потерь приемлемо одно дело там терять 10 span of из то другое 10 из миллиарда почему мы их теряем и как вообще это чувствует пользователь на пользователь жалуются что него дерево там разваливается на части или у нее там половина дерева этого trace а или trace и нет совсем почему это происходит дело в том что внутри джаггер коллектора который испан и принимает есть буфер этот буфер имеет конечный размер если мы пытаемся в этот буфер впихнуть больше чем нужно джаггер начинает эти span и просто дропать из этого буфера пытается все предложить бочками власти все если он не успевает это делать span и просто отвергаются ну отлично у нас один джаггер коллектор который не справляется с нагрузкой что с ним можно сделать можно сделать два джека коллектор да отлично теперь наша нагрузка распределяется равномерно по двум джаггер коллектором буфер не переполняется все успешно записывается власти все но теперь мы с вами понимаем что такую операцию нам придется делать на каждые там 3000 span of нагрузки соответственно мы заменяем наш dk campus на нормальный к бернейса чтобы можно было это масштабировать на кластере м до бесконечности ну и кроме этого мы как не хотим узнавать о проблемах с группами от наших пользователей поэтому делаю доставил мониторинг собственно метрику количество дробных span of которую джека коллектора почему-то сам прекрасно отдает формате prometheus отлично с тремя тысячами мы сами справились наша платформа становится популярной нам подключаются люди нагрузка выросло в пять раз теперь у нас 15 тысяч ну тут у нас не чает не выдерживать то я одна единственная несчастная но дай ластика который мы использовали нам нужно превращать в нормальный кластер собственно штабе ровать его как масштабировать но понятно добавлять ноты собственно ход ноты которые данные нас индексирует но это еще не все там индекс elastico состоит из городов до из кусочков соответственно если мы хотим чтобы у нас запись велась параллельно напустим на пять нот нам нужно сделать пять праймеры шар дафна чтобы каждый sharp лежал на свои ноги кроме этого ход но ты довольно дорогие да там и ssd диски они мощные все дела чтобы немножко разгрузить наш класс то и в то же время повысить его поглощать иную способность мы можем добавлять так называемые jest ноды это ноты которые данные не хранятся они занимаются чисто предобработки документов перед ставкой они берут на себя часть нагрузки и соответственно увеличивают позади нашего класса это что касается масштабирование ластика на запись но надо же интересно масштабирование на чтение да мы хотим чтобы наши ap м даже борды работали быстровки бани здесь примерно та же логика она добавлять новые ноды вместо праймеры шар дав мы увеличим количество реплик то есть копии наших данных которые тоже будут лежать на разных родах и мы можем параллельно читать с низких нот здесь тоже мы можем добавлять так называемый cardin и think но до которые тоже данный не хранят но они участвуют обработки запросов на чтение принимаются единение там соединяют кусочки ответов один большой ответ в общем разгружают наш класс то хорошо классные у нас может скушать 15000 spano в секунду но потери продолжаются периодически приходят пользователи говорят опять у нас половину трейси мы смотрим на нашу нагрузку и понимаем что 15 тысяч фанов секунду это средняя температура по больнице а на самом деле в наших данных есть пике они могут возникать по 1000 причин кто-то тяжелый матч запустил у кого-то очередь разгибается что все что угодно эти пики они кратковременны и недостаточно для того чтобы опять забить очереди наших буфера наших джаггер коллекторов там забить и очередь на вставку власти все оч и мы опять начнем терять наш espana что с этим делать надо как-то сглаживать пики нагрузки нужно куда-то класть этот избыточный трафик и потом его уже записывать власти именно так в нашей архитектуре появляется кафка собственно используется как промежуточный буфер джаггер коллектора смотрела записывает данные в кафка и у нас появляется дополнительный сервис джаггер g-star который эта очередь из кафки разгребает как мы все это масштабируем собственно мы создаем дополнительные партиции в кафки то есть параллельные очереди из которых мы читаем данные увеличиваем количество инвесторов увеличив количество коллектор что такая схема нам дает если нас возникает какой-то кратковременной пик нагрузки у нас просто растет очередь кафки джаггер джесс то все еще разгребает данные со скоростью 15 тысяч станов секунду если нагрузка наша система больше 15 тысяч собственно очередь начинает расти ничего страшного данные там какое-то время полежат но у нас с вами по является важнейшей индикатор собственно отставание обработки в кафки так называемый лак это наша главная дико то на которой мы будем настраивать мониторинг когда перезагрузки спадает очередь сгибается и мы снова продолжаем работать а что делать если пики нагрузки не уходят не хотят они быть кратковременными они превращаются в долговременные пике такое может быть вследствие каких-то аварийной ситуации да то есть это ненормальная ситуация надо помнить что наша система коммунальная если у нас есть какой-то потребителю которую проблема начинает нас заваливать распределен тусовкой то это повлияет на каждого нашего потребителя система коммунальная то есть нам нужен какой-то механизм который нам позволит понять с какого и пятам идет поток трассировки и что-то с этим потребителем сделать до чтобы он не мешал стальным ну к счастью господину трассировки если и пи адрес которого она была записана поэтому такой дашборд делать довольно легко и в случае у таких вот аварийных ситуаций мы просто берем там топ-10 айпи адресов с которых идет трафик что мы с ними делаем действием по принципу сначала стреляй потом спрашивать мы просто берем и пи адрес заносим его в сетевую политику кубер на етс по сути отрезаем блокируем этот трафик по ip-адресу мы снимаем таким образом то влияние которое он оказывает на всех наших потребителей и уже потом идем разбираться кому принадлежит той пи адрес почему это случилось там какая-то программная ошибка не знаю там какая-то авария на продукте вообще неважно там на что мы всем нашим остальным потребителем сделали хорошо итак до этого мы говорили о потере данных на наши как бы серверной части могут ли данная теряться на клиенте правильный ответ конечно могут это следует из самой вообще архитектура работы системы трассировки то есть у вас есть приложение а на инструменте равана в нем внутри есть тоже некоторые буфер куда кладется сгенерированная распределенная трассировка если ее больше чем ваше приложение может отправить то у вас как бы новые данные начали заменять старые надо начать теряться что с этим можно сделать но можно играться параметрами можно увеличивать размер буфера можно увеличивать частоту сброса но все это помогает до какого-то определенного момента наиболее продуктивной схемы является использование агента с агент это некая там отдельный процесс который ставится рядом по сути на той же машине что и ваш приложение и спирает допустим там погиб и забирает трассировку и потом уже более там крупными бочками прокол мейджер pc отправляет трассировку сторону нашего бэг-энда это вообще самая производительная схема а самое главное что она более наблюдаемая у джаггер агента тоже есть метрики дропов и в общем мы всегда можем отслеживать дропаются с панели не допус 30000 что на этот раз на этот раз у нас замедляется аналитика если пользователи раньше с помощью нашей дашбордов киба не могли там посмотреть за месяц какие-то пометки по всей системе . не жалуется что уже и за сутки в общем-то это притормаживает почему притормаживает банально стало больше данных до наш объем хранения трассировки приближается к терабайта в сутки что с этим можно сделать ну можно поиграться тем как мой трассировка храним можно нарезать индексы не подниму а допустим там по шесть часов или там по 100 50 гигабайт можно включить сжатие до места там дефолтного dev lite в эластики можно включить там z4 это нам там 20 процентов на двадцать процентов сожмёт трассировку но все это не решает кардинально нашу проблему да будет у нас там 60000 нагрузка все проблемы снова вернется нужно какое-то кардинальное решение нужно вообще сделать так чтобы elastic не участвовал в расчете up mp3 почему потому что ну то есть нас два варианта либо заливать проблемы железом масштабирует нашлась тысяч кластер это довольно дорого либо как бы исключить из этого процесса нам нужно считать метрики в ней ластика поток алла как это сделать в нашей схеме появляется еще одна веточка обработки распыленной дрессировки нас появляется сервис мы его называем streamed рик сервис собственно он обрабатывает каждый span пускай связь через себя каждый span распыленной дрессировки смотрит чему этот span относится например там к скале запросу или к запросу к нашего в приложению и вычисляет соответствующим не только там количество и сквозь запросов там длительность веб запроса в общем все что угодно он кладет в какое-то хранилище оптимизированный для метрик мы используем victory метрик для этого и дальше можем строить даже борды например той же самой графа не чем эта схема хороша она дешевая на то есть наш elastic вообще не обрабатывает запросы на вычисления по метрик это все происходит до него параллельно эта схема хорошо масштабируется мои тексты нет иксов можем на делать там десятки штук но вот они прекрасно будут считать наши метрики при этом метрики при doggie руются то есть мы вообще не используем старые данные для того что они таки вычислить мы можем хранить их там месяцами и годами виктория метрик с очень компактный вот пример даже бордов которые мы можем получить собственно первый график это пирсинг времени выполнения там ключевых методов второй график это тепловая карта это некая вообще агрегация по всему продукту насколько быстро он отвечает на запросы что все можно посчитать по распыленной трассировки что может пойти не так и что вышит у нас пошло не так надо следить за мощностью того множества метрик которые вы получите пример вы решили сделать метрику action duration метрика которая показывает время работы какого-то метода вашего api вы наверняка хотите считать ее в каких-то разрезах да там разрезе продукта сервиса контроллера собственно самого экшена у каждого из этих разрезов есть там количество уникальных значений и мощность этого может множество значений у нас 90 продуктов у каждого там по два контура по 10 сервисов и так далее если мы все это перемножим мы получим результирующее мощность нашего множество на сколько уникальных значений там в секунду мы отправляем наши хранилище метрик собственно если разрезы выбрать неправильно если они будут иметь слишком большое количество уникальных значений в общем то мы можем наше хранилище положить именно это у нас произошло с памяти лусон эта причина почему прометею заменили на виктории metrics ну вот представьте да что вы сделаете здесь разрез по там юзера иди по одни секатора пользователя у вас там миллион пользователей ну как бы все памяти взорвется так мы подошли к страшной черте 50000 spano в секунду это там чуть меньше чем наша нагрузка сейчас на проводе что у нас здесь происходит у нас полностью отваливается любой аналитика в ластики то есть об америке мы уже вроде вытащили из пластика но наши пользователи все еще делают какие-то кастомные запросы к распыленной трассировки используют для этого зачастую то подмножество иску или которая умеет выполнять ластик search ну например здесь считается количество документов которые сгенерировала система как нам пользователям помочь как поддержать возможность кастомных аналитических запросов по распределенной трассировки но на этом моменте мы поняли что нужно какое-то другое хранилище который нам позволит такие аналитические запросы выполнять в качестве такого хранилище мы выбрали пик house уже там первые наши эксперименты показали что с хаусом джаггери работает на 20 процентов быстрее treehouse во много раз компактнее хранит распаренную севку там в 4 более раза и самое главное в нем очень быстро работают аналитические запросы а я буду не только быстро они еще и там полноценное вот пример довольно сложного и сколь запроса который отлично работает при хаусе и которые в принципе невозможно сделать в ластики потому что он-то не поддерживает под запросы join a и много чего еще что здесь вообще происходит вот самый вложенные сквозь запрос доведенной рамочкой это мы находим трейси в которых есть определенная операция ардов ордер full film and trace и деревья определенного типа скажем так дальше мы для каждого такого trace а считаем его длительность датой длительность всего этого дерева время от 1 сп она до последнего и наконец самым внешним запросе мы считаем перестаньте это длительности то есть мы имеем возможность таким и вскоре запросам посчитать метрики не для один из планов а для всего от рейса целиком вот там такая аналитика дано в хаусе возможно вы ластики и сделать не получится ну кажется мы решали все наши проблемы этого момента кажется что нас нет никаких ограничений мы возьмем любую систему и прекрасно подключенные к нашей платформе конечно это не так у нас есть свои ограничение пределы и мы там столкнулись с продуктом когда мы подключить не смогли что это за продукт продукт который обрабатывает переключение мобильного телефона между вышками то есть как только телефон приключается от одной вышки в другой генерируются события на которой проходит через этот продукт можете себе представить какой там поток да там несколько миллионов событий в секунду все это проходит через большой класс стр кафки но давайте представим что будет если мы захотим трассировать как этот продукт отдал события какому-то другому продукту пусть там проходит миллион событий в секунду мы помним что один сетевой вызов у нас приходится два spano то есть в нашу сторону бы летит поток в 2 миллиона spano в секунду это там немножко больше чем та цифра который мы с вами до этого говорили и понятно что мы это не выдержим ну из таких кейсов у нас родилось эмпирическое правило что мы используем стопроцентный сбор распылен трассировки без сэмплирования для продуктов которых меньше 10000 apps можно было бы на этом закончить мой доклад но наша проблема не заканчиваются нас есть еще одна сложность это собственно длина trace а дело в том что мы подключаем все новые и новые продукты дерево наши растет и пользователям становится никак не комфортно с ним работать то есть дерева длиной там до 10000 из планов ночи более менее нормально и да она быстро работают люди могут него что-то найти там от 10000 до 100 уже вызывает проблемы интерфейс джаггера начинает тормозить мы просто ориентироваться в 100 тысячах очень сложно ну и все что больше это там дохлый номер там найти что-то невозможно вы наверное меня можете спросить откуда 100000 на что это за монструозный вас процесса вообще происходит к системе что я вам покажу 3 ст длиной в 1 миллион span of это конечно некое такое о некой аномалия даника и пограничное значение но она реально у нас встречало откуда это может появиться представьте себе сложный интеграционный процесс который работает по принципу там проверь и условия если она не выполнилось заснул на 10 секунд фас нулся основа проверяя условия заснул и так далее если такой процесс существует там допустим месяц то он вам там каждые 10 секунд описывает какой-то кусочек трассировки и запросто может на генерить вам миллион 10 там сколько угодно миллионов чтобы как-то справиться этой ситуации мы придумали процесс сокращения длины trace а он конечно работает только тех случаях если это ну не аномально ситуация просто там команда себе напридумывала слишком там какой-то подробную трассировку что мы делаем мы берем собственно trace и ищем их и группируем по названию операции то есть по сути получается табличка отсортированы по количеству сколько раз подобный span случается в нашем дереве обратите внимание что первые два spano в этой таблице имеют одинаковое количество вхождений наше дерево до 1446 это неспроста это значит что два этих сп она соответствует этому событию на самом деле до входящему запросу то есть первый раз пан соответствует просто по запросу 2 соответствует тому какую там action выбрал наш прибор чтобы этот запрос обработать соответственно что мы можем с этим сделать мы можем их объединить превратить это все в один span допустим скомбинировать как-то название чтобы не потерять никакую информацию таким образом мы сразу там большое количество обрезаем наш trace по длине кроме этого у нас могут быть по на которые нам не важны для диагностики мы можем пообщаться продуктовой команды они на могут сказать что ну там не знаю солдата это какая-то второстепенная хранимая процедура на мне очень там интересно называется она или нет для локализации это неважно можем там вообще вычеркнуть эти span и из дерева таким вот объединением и умиранием лишнего мы обрезаем наш план у нас реально удавалось сократить наше дерево на 40 процентов вроде бы все победили победили нагрузку длину trace а но в какой то момент вы заходите джаггер и что вы видите ваших станах номер кредитки номера телефонов паспортные данные iv отойти за голову да вы вроде хотели сделать какое-то общее средства диагностики дефектов которые будет доступна там всем инженерам вашей компании но то же время в это распланировать дозировки встречаются какие только официальные данные которые могут видеть не все праздника такой карнитин и диссонанс чтобы вы решить нужно вводить какую-то разграничение прав доступа на основании чего мы будем раздавать доступ джаггери нету никаких там значение из коробки которые привязывают trace к определенному продукту поэтому джаггеру надо немножко помочь чтобы это сделать мы попросили все наши продуктовые команды при подключении добавлять два специализированных тега нашу распыленной трассировку это т.к. продукт азии теннанта идея по сути это индификатор и из нашего корпоративного каталога продуктов и систем которые привязывают вот этот вот span к определенному продукту системе все с этого момента мы понимаем с кем мы имеем дело и можем раздавать доступ и отлично у нас есть trace там есть продукт а он содержит к официальной информацию у нас есть иванов иван который хочет а все просмотреть у него не должно быть по там каким-то корпоративным правилам доступ к этой информации как скрыть самое первое что приходит на ум просто взять и вырезать из трассировки для иванова span и от продукта а к сожалению это плохое решение потому что наш trace развалится на части да то есть наше дерево станет совершенно бесформенном потеряет причинно-следственную связь и какую-то локализацию будет производить после невозможно гораздо более правильным подходом является закрыть и самих тегов то есть мы еще на покиньте джаггера можем понять что иванова нет доступа к каким-то числительным данным и вырезать из тегов да или там закрыть их звездочками все нестандартные теги да все те которые там не генерится из коробки джаггеров наше дерево сохраняет форму его на все еще там понимает что в этом месте работал продукта может проводить локализацию отлично пора подводить итоги итак давайте вспомним что нам помогло на нашем длинном пути первое нам помогло разделение тестовых и продуктивных данных data что мы создали два контура стечь и провод это сняло нагрузку позволил нам лучше проводить тестирование второе мы с вами увидели что там неправильное использование распыленной трассировки может порождать нам слишком длинный trace может порождать какую-то паразитную нагрузку в общем нужно очень четко отслеживать как наш продуктовой команды используют за спиной тусовку нам уже средства диагностики нам нужны best practices иногда нужно просто как бы с командами работать ну и третье которая в общем вытекает из второго что распутин и трассировка это не тот инструмент который просто о долгом командам и оно само как-то все заработает нет нужны реально стандарты там нужно периодически с командами взаимодействовать чтобы помогать им сделать trace там достаточно подробно для диагностики но там достаточно коротким чтобы там в этом дереве все еще что-то можно было найти на этом у меня все материалы по ссылочке доступны готов ответить на ваши вопросы спасибо итак вопрос и я вот вижу там спасибо за доклад него практиков очень много потому что было очень интересную большая почва для размышлений вот меня задам несколько вопрос такое почему например вынес не использовали стандартные для обмен телеметрии метрики а использовали стоек с тонны решения там с учитывание мыс кафки перекладывания виктория метрик но дело в том что мы немножко старше тему фэнтези метры когда мы начинали в периметре еще не было в проекте вот поэтому мы реализовали собственное решение да действительно у конте метро коллектора есть собственный модуль который умеет такие метки читать и в общем там и планировать его перейти вопрос номер два как вы вырезаете теги вот поскольку джаггер его это вроде как опыт собственные решения и вам видимо надо какой-то код написать для того чтобы его ну там какие-то права разграничить и что-то звездочки витками как в эту проблему лишь форумов окна лиджанг доработали под себя хорошо спасибо и для получается для прикладывания free calls тоже какой-то свой сервис у вас видим и есть который формат обман телеметрии перекладывает в то что я кликал сможет съесть не совсем у джаггера есть плагин для клик хауса то есть там работает как некий там короче крепло плагин запускается рядом внутри контейнера с jakiro инвесторам он умеет складывать трассировку в crack house upon телеметрии мы прикрутили сбоку то есть у нас стоят у потеряемся коллектор который передается все джаггера джаггер уже записывает of house пока вот такая вот сложная конструкция да она возникла потому что нам как бы надо поддержать совместимости с теми клиентами которые там изначально наук андрей сингер и джаггери да и новыми клиентами которые сейчас уже на понте любит хорошо спасибо так еще вопросы туда спасибо за доклад очень интересно меня зовут андрей вопрос еще для меня и наверное тут тоже многих кто будет разрабатывать после вашего доклада что-то подобное с нуля сейчас что нам еще стоит сейчас думать и делать немножко по-другому не так как вы поскольку вот мы сейчас с нуля на чины года учитесь на наших ошибках во первых сразу на лт анти lamie3 да то есть сразу на новый как бы стек тому поделили метро действительно там крутая штука которая снимает кучу там проблему она сразу и про трассировку и прологе и про метрики пусть там пока они все ещё там production риги до конца вот но в общем эта штука которая обещает нам единообразный сбор телеметрии за сразу используйте crack house для спринта херов key вот наверно и все ну и как бы сразу задумываетесь о том как это будет масштабироваться на все продукты то есть сразу должны быть какие-то без практики какие-то правила игры для команд а чтобы то что эта вот история когда мы сначала значит всех подключаем потом мы пускаем стандарт всех просим значит под этот стандарт я подвести потому что то меняется опять просим команда переделать этот там довольно сложно история большое спасибо за доклад хотелось бы уточнить один момент вы вот маскируете данные уже на момент выдачи да я про официально а почему не маскируется этот момент записи вол момент записи но знаете у нас есть иванов у которого есть доступ к официально формат зачем их вообще хранить в логах этой информации трассировки да ну потому что есть jenner и которые которых есть доступ к функция информация нам может потребоваться до локализация вот поэтому мы как бы им позволяем эту информацию видеть позволяем им искать там по номеру паспорта например вот кому-то не даем у кого нет таких как ну то есть вы используете информацию влогах для там бизнес решили правильно бизнеса но не для для с локализацией диагностики ну там простой и сейчас пример который я придумаю да там жалуется пользователь и там жалобе указывает что вот тут там какие-то паспортные данные да он там пытался по этим поступком данным не знаю что нибудь там купить билет какой-нибудь и они ничего не получается на вот там инженер может по этим паспортом данном найти trace видео надо пытался сделать но ты там понять что происходило но это такой вот сферические 3-д в вакууме вопросик скажите какие серебряных пуль отлиты сервисы которые читают из кадки и пишут викторию metrics можно еще раз вопросы не слышно начала еще раз у вас есть сервисы которые читают кафку пишет викторию metrics а его не сделаны это довольно простой сервис он запущен тоже в кубер ней написано сишарпе собственного он обрабатывает тот же читает данность того же топика что и джаган jester берёт каждый спам там по сути есть некая такая некая последовательность да то есть несколько классов которые каждый из которых рассчитывает свою метрику он там смотрит подходит не подходит span под какие-то критерии там пример соответствует ли span какому-то искали запросу степи запросу еще чему-то и понимая чему span соответствует он ожидает увидеть там определенные теги в этом с пони и может посчитать нет куда там допустим разрезе этих тегов ну там с плане который соответствует и скай запросу может быть там не знаю что название базы данных в которой то запрос шоу да значит мы можем посчитать количество запросов там каждый базе данных"
}