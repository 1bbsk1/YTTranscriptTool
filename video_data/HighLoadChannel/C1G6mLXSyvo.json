{
  "video_id": "C1G6mLXSyvo",
  "channel": "HighLoadChannel",
  "title": "ClickHouse и тысяча графиков / Антон Алексеев (2ГИС)",
  "views": 4555,
  "duration": 2823,
  "published": "2019-12-05T12:51:24-08:00",
  "text": "сегодня я расскажу вам как сначала я не понимал хорошо ли работают мои сервисы потом начал складывать их сырые логи в creed house нарисовал тысячу графиков графа ним и понимание пришло если вы тоже любите понимать работу своих сервисов через графике то возможно crack house вам в этом сможет помочь и нам с вами сегодня по пути мы здесь не будем поднимать больших кластеров считать на них деньги мы поднимем маленький персональный crack house и будем показываю внешнюю миру через графа ну мы сами используемого порядка двух лет и у нас всего два сервера под него отдано да и кто 2 на радио отказоустойчивости вообще кто мы и что мы наша команда в 2гис заведуют сервисом транспорта транспорта данных от нас к пользователям и статистике от пользователей к нам если вы когда-нибудь пользовались мобильным приложением 2гис то вы скачивали себе на телефон и там на планшет файлы одного или нескольких городов вот это оранжевый стрелки на все наши приложения сайт и внутренней сервис и отправляют к нам статистику о своей работе это фиолетовые стрелки мы его принимаем во лидируем и отправляем дальше поговорим сначала про первый сервис то есть просидим 2гис есть мобильные приложения которые работают оффлайн и для оффлайн работы они скачивают себе файлы регионов то есть когда пользователь в мобильном приложении тыкает на хочу скачать новосибирск приложение идет на наш небольшой сидел и запрашивает все файлы входящие в этот регион карту файлы с карты со справочником с навигаторами так далее всего около семи файлов сидим достаточно простой десяток-другой кашель ющих и джинсов 1000 запросов прыжке десятки габит исходящего трафика но трафик в данном контексте не вашим что было и что болела до описываемых событий monitoring in джинсы как engine со садился к тому что раз сколько-то времени приходили крон скрипты parcel axis lock on джинса в триполи оттуда коды ответов считали количество по каждому кода с момента предыдущего запуска склада литва временный файл потом приходил zabbix файл забирал к себе попутно еще собирал всякие метрики стандартные типа трафика на интерфейсе познавательно жуть если надо было что-то расследовать то мы ходили на сервера греппа ли файлы был конечный ластик но его никто не любил он был медленный занимал много места типа глубина парафина хранения на пару недель занималась все-таки попал терабайта цифр очень грубый насколько вспомнил хотелось большего хотелось разных средств запросов и трафика например по версиям приложений чтобы понять что но в релиз android не принес деградации или по регионам чтобы понять что наша карта покрытие без дыр и все наши регионы скачиваются с нормальной скоростью они только новосибирска где наш головной офис хотелось строить разные процентили например время отдачи и скорость скачивания чтобы понимать что мы нормально обслуживаем пользователя а еще хотелось чтобы можно было централизованное удобно искать пологом на достаточную глубину по сырым лугам потому что периодически приходят люди говорят слушай я тут месяц назад ездил в москву там это москву качал и а нам немедленно скачалось давай разбираемся в чем была проблема ну мы разбираемся поднимаем ноги серверов принимай поднимаем ноги приложения сравниваем анализируем конечно проблем можно было бы закидать деньгами на колбасить кучу скриптов для подсчета агрегатов складывать эти агрегаты в прометею zabbix не важно поставить elastic на несколько zero байт для поиска по сырым лугам и тоже жить достаточно спокойно но конечно есть проблема чтобы закидывать деньгами деньги надо где-то взять а еще это будет как минимум две различные системы для агрегатов и для сырых данных а еще если вы придумали новый клёвый агрегат и то вам придется либо ждать несколько месяцев пока вы наберете данных на то чтобы меняем и какая-то история была чтобы можно было по анализировать проанализировать либо вам надо выдирать сырые данные считать агрегат заливать в хранилище агрегатов и то есть она поддерживает заливку задним числом геморрой ищем альтернативу ну во-первых access локон джинса отлично ложится на табличное представление это куча записей с одинаковой плоской структуры а еще там половина полей это числа или что-то близкое к ним авто во второй половине много повторяющихся коротких строк типа платформы или и мне региона а еще для запроса обычно нужна пара полей до то со временем то почему группируем ну это почему фильтру эмоционально из этого всего вырисовываются решение пока ло ночная база данных тогда как раз open source и позже вышел клик house у которого идеология хранить его мне все сырые данные агрегаты я вам быстро посчитаю поэтому решил попробовать его развернул на какой-то дохлый виртуалке типа 4 ядра 4g памяти непонятно какие шпиндельные диски вот создал на нем табличку с базовыми полями там дата со время код ответа тип запроса подумал что мы наверняка вопросы будем использовать дату наверняка будем использовать тип запрос данные или мета-данные и будем хотите знать использовать фильтровать по коду ответа ну потому что какой распространенный сценарий например посмотрим запрос успешные запросы данных за вчера то есть успешный код 200 ну и 206 тип запроса данные да то есть вот почему акцентирую на этом внимание потому что об этом редко рассказывают вот рассказывай может быть у меня в кулуарах поправит что все было не надо было не так делать в общем сделали такую табличку взял сырых лоты в сколько было сказал я знаю perl и налил этих логов в эту табличку тут надо сказать что есть очень удобный интерфейс заливки данных ты говоришь insert и внутри был форман 600 формат джей 100 метров потом на каждом новой на каждой новой строчке ты пишешь плоский джейсон где имена полей это именно карл он aqua целевой таблицы а значение это те значение которое туда хочешь положить в купе с опции скипа но он feels crack house из этого джейсона возьмет только те поля которые у него есть в таблице а тех полей которые в него нет он заполнит значению по умолчанию а те поляк тур есть sony в таблице нет он просто откинет очень удобнее быстро просто мне очень нравится так вот развернул налил данных вот икру джейс келим оно вело себя именно так как сказано на знаменитый футболки его разработчик то есть не тормозило я вижу уже несколько таких футболок зале так и посмотрел я как она не тормозит и решил к этому всему графа ну притащить потому что графике я очень люблю так значит поставил плагин от ребят из where the media тогда еще самая самая первая версия была 001 но на поставилась завелась из коробки заработала и графики нарисовала ну как вообще графики нарисовать вам надо сформировать такой запрос чтобы в результате вам вернулись вот такие данные первая строчка это количество миллисекунд с начала эпохи то есть unix там стив миллисекундах а вторая и последующие колонки это те точки которые вы хотите на чтобы были на графике то есть одна колонка это одна линия на графике при этом имя колонки это будет имя в легенде есть второй вариант там стенд также количество миллисекунд начало эпохи и вторая колонка это массив кортежей где первый элемент кортежа это имя в линии а второй элемент кортежа это собственно значение как спид писать такие запросы да просто мы чтобы сформировать там стемп мы временную шкалу делим на и термини равана делим на равные промежутки и каждую точку приводим к началу этого промежутка звучит может быть сложно но на самом деле мы просто берем дату со временем делим на цело на длину интервал а потом умножаем за на на этот интервал все привели к началу временного интервала теперь можно просто и удобно группировать по времени чтобы всякие агрегат строить ну а значение уже собственно просто это либо каунт для request of либо ник для уникальных пользователей все просто вот второй вариант реализовать который с массивом кортеж это же просто вот на слайде ну так обычно никто не пользует потому что проще первым вариантом воспользоваться зачем нужны массива с массивами можно делать всякие интересные штуки например ли house может за один заход затем за один проход таблички посчитать вам несколько квантиль эй через функцию кантеле например вы просите 3 квантили посчитать и он вернет вам результат в виде массива из трех значений но нам нужно массив кортежи помним да ну мы прогоняем этот результирующий массив через функцию rained мы сливаем его с этот массив с массивом имен и на выходе у нас массив кортежи все как надо просто удобно нужно открыть раздел документации функции для работы с массивами и идти прямо по порядку там очень много интересного ну в общем графики и но есть рисовать не умеем значит надо пользоваться напомним был вот так вот джинкс пишет access логин структурированные эти структурированные логе забираются file by там идут в лоб стаж через мост с они уходят власти значит я взял те регулярке которые я писал чтобы логе распарсить их добавил стаж и через простенький самописный скрипт тег отправил speakout в ту саму табличку на этом этапе уже мы уже начали входить продакшен тут мы сразу репетирование сделали то есть у нас стало два сервера и каждая табличка создавалась на каждом из серверов то есть по сути такой мастер мастер ну вот и небольшой спойлер ну потом в принципе отпилили схему с и ластиком из-за миксом и все мы имеем данную имеем табличку в эту табличку у нас льются данные из коробки получаем прикольные графики ну например разные срезы например по серверам вот тут видно как один из серверов взял и ушёл в бокал ну вот а запросы не перераспределились по другим серверам хотя мы должны были такие же срезы можно тросе встроить например по годам ответа по платформам можно например вот статуса каша смотреть тут виден скачок миссов когда он выложили новые данные и каши прогревались может дать устройте самые процентили которые мы хотели например вот скорость скачивания у нас качали качали пользователи тут какой-то момент нагрузка стало слишком большой мы не к сожалению не вытянули и просели по скорости ну вот отдавали меньше медленнее чем хотелось бы новый палят добавлять легко вы берете добавляйте это поле в лог engine ксо создаете табличку создаете поле там в имеющейся таблички вкладка вовсе все дальше все работает автоматом например переходили мой на hd ps мы добавили признак что это я чуть пи и вещь без в лоб создали соответствующие строковую поле в табличке все она автоматом туда начало наливаться мы не сразу начали смотреть графики и смотреть как у нас растет доля each теперь запросов или например договорились мы с мобильными приложениями что они нам начнут слать новый заголовок к стоны мы этот заголовок добавили в лог вот как написано как на сайте нарисована добавили колонку к таблички и все она поехала мы сразу смогли начать рисовать графики какие значения заголовков нам присылают и как они распределены вот я хотел сделать слайд в принципе со всеми полями которые у меня есть в табличке но понял что цитируем практически каждую пятую переменную из странички с переменными джинса вот многие из вас наверняка видели эту страничку поэтому имеете представление о чем я говорю вот эти графики в принципе просто большая часть из них это просто графике то есть мы смотрим на них течение дня или при внесении изменений и смотрим что ничего не взорвалось важные вещи типа 500 х годов ответа или медианы скрасить скачиваний с каждого сервера у нас забиться забирая через воде би си искать хаоса и на это навечно триггеры сработки влетают в почту slug всё как у всех время идет и нам хочется смотреть графики за все это время но на масштабах от пары недель отрисовка графиков подтормаживает при заниматься заметное время от пара месяцев отваливается по таймауту вот тут за неделю мы строим 7 секунд за месяц мы строим полминуты тот же график а за полгода мы строим три минуты график ну камон никто не будет ждать график 3 минуты особенно когда на дашборде еще 10 таких ну чё делаем смотрим и читаем документации просто утрирования клика а сохранить данные на диске отсортированные по полям входящим в первичный ключ если к первичному ключу добавить так называемый ключ сэмплирование то можно будет говорить отдай мне не все строки подпадающие под запрос а только часть из них либо в процентах либо абсолютных значениях мы например используем 100 миллионов тогда он отдаст вам примерно вот такое строк количество строк которые вы запросили постаравшись сохранить при этом соотношение между различными сочетаниями значений полей входящих первичный ключ вот например если 28 числа было в два раза больше 200 х годов ответа чем 304 он постарается это соотношение сохранить то есть в результате вон вам отдаст в два раза меньше строк и все равно 200 х годов ответа за двадцать восьмое число будет в два раза больше чем 304 потом при необходимости если вы там какие-то каунт считали ли сумму вы это дам наша идти на коэффициент supply рования то есть то во сколько раз меньше данных вы запросили то есть на предыдущем слайде мы спросили в два раза меньше данных значит результат нам надо будет умножить на 2 для этого есть специальный виртуальная колонка сэмпл фактор и все и вы получаете примерно то что надо мы долго сомневались долго не верили строили графики без сэмплирования с центрированием сравнивали ну вроде похоже на правду и нас apple раваном есть лишние пике но вроде не критично а если не видно разницы то зачем строить дольше важные вещи партнеры говорил там 500 коды ответов или медиана спроси скачивания у нас забег сам забираются за довольно небольшой промежуток времени поэтому вполне можно позволить себе забирать все строки а для графиков типа посмотреть как оно вело себя на масштабе полугода вполне вот этих хватает за глаза ну и цель достигнута все наши графики теперь строятся практически за константное время единицы секунд значит живем с этим живем смотрим на графике если кто-то примерно там android приходит на быть мы зарелизили нокии мы в течение дня смотрим на графике смотрим что ничего не поменялось если вдруг как-то они не характер мы начали меняться начинаем разбираться и если оказывается что это там та самая новый вес android моим reporting ребят чет не так они смотрят правим выкатываем fix все имена и совпадения случайны если что ну как а вчера следуем если на каком-то из за таких общих графиках появилась ступенькой или яма который быть не должно то скорее всего такую же ступеньку ульяну можно найти на других срезах таким образом или сразу вычислив виновника или сузить круг подозреваемых если сузили круг подозреваемых можно идти в таблицу уже делать ну в базу делать точечные запросы смотрите конкретное что что было вот разбираться вот например я вам показываю этот график один из серверов назовем его мистер оранжевый он ушел в бокал запросы на него уходили а никаких ответов даже this пересчитав не было по идее наше приложение написано так что они должны обрабатывать такую ситуацию и запросы должны были перераспределиться на другие сервера то есть общая кривая должна была остаться неизменной просто в какой-то момент оранжевого цвета должно было стать меньшим то есть должно было не стать других цветов стало бы больше а в момент когда серверов вернулся раньше вы снова появился других цвет цветов снова стало меньше но этого не произошло появилась яма давайте разбираться ищем корреляцию на других графиках например смотрим нас средств по типам запроса корреляции нет яма и на запросах на данные и на запросах на мета-данные ладно смотрим корреляцию по типам показом ответа это же нет ее не должно было быть это black hole и когда ответов но вдруг на всякий случай посмотрели смотрим дальше по платформам бинга а тут корреляция есть провал только у айфона начинаем разбираться и действительно когда мы провели когда через завез отправляли закачку запрос на закачку в сторону black hole сервера это закачка залипала и бесконечно ждала и ждала пока сервер вернется чтобы скачать причитающиеся и себе чтобы приложение могло скачать причитающиеся себе и когда сервер вернулся они все туда ломанулись до качали ну и дальше жизнь norma вошла в нормальную обычную колею иногда может захотеться поискать корреляцию на графиках на которых бы было слишком много линий ну например это средство и печника мальчишник ам или по версиям приложений в таких случаях мы рисуем графики только для какого-то top н или участников которые больше всего запросов или трафика зависит от чего средств делаем почему почти все сделаем вот то есть топ н который участников которые привели больше всего мы платили больше всего запросов или трафика вот как как делаем выбираем то почему делаем срез то есть в данном случае версию приложения это все делаем в том интер временном интервале который нам дает grafana и это все выбираем тот самый top н и в результате получаем в результате этого под запроса получаем топ и ну то есть вот то что задается переменный лимит номеров версии приложений и дальше можно их использовать впревые то есть нарисовать график только по этим версия приложения итак мы жили где-то год жили жили не тужили но нас одолевало любопытство что можно еще из этих данных вытащить ну как известно любопытство не порок любопытство это хобби напомню что у пользователю у нас скачивает ни один файл он скачивать несколько файлов все файлы входящий в регион я вам показывал же эту картинку и пока он не захочет последний файл наша работа не выполнил пользователь еще не удовлетворён как бы нам посчитать вот за какое время мы и свою работу выполняем в принципе посчитать то просто мы берем начала скачивания первого файла берем конец скачивание последнего файла вычитаем из конца начала группируем это все по пользователю по имени региона и по версии риге этого региона чтобы получить одну цифру сколько один конкретный пользователь скачал один конкретный регион конкретной версии все у нас есть одна цифра поэтому цифры уже можно строить про ценители например вот процентили времени скачивания москвы для таяма про которую я вам рассказывал чуть раньше те пользователи которым пить 8 5 процентиль скачи скакнул ему очень некрасиво те пользователи которым не повезло прийти вот самое начало то есть польского сервер только упал они пришли вот они 4 часа не ждали пока этот сервер вернется на место те которые пришли под конец мы обошлись получаса но тоже не сахар ну вот можно строить такие графики и примерно прикидывать что чувствуют пользователь скачивай условную москву если он скачивает ее полчаса ноет хреново если скачивают минуту ну или там несколько минут в принципе нормально но есть проблема пока сгруппирую что все по пользователям по регионам пока посчитать процентили ну опять же занимает какое-то время вот бы она как-нибудь фоне считалось а мы бы просто приходили быстро это забирали и рисовали график ну можно и так в семействе движков merge 3 клик house хранит данные на диске в кусках и периодически фоне эти куски сливает при этом пире упорядочивая в агрегате лишь три в этих кусках еще могут лежать промежуточные результаты от лидирующих функций мин-макс ну или каунт как на слайде и тогда при очередном фоном слияние куска двух кусков crack house не просто их переупорядочить а если были совпадающие строки ну то есть те для кого значения первичного ключа такое же он пересчитает это промежуточное значение оставит одну получается одну новую строку и сохранить вот это значение то есть если для 29 или 30 числа ничего не изменилось потому что они эти строки только в единственном экземпляре то для 28 числа и в том и в другом куски есть запись поэтому crack house это все сагре gear овал и у нас в результате получилась сумма аккаунтов ну то есть будут и 100 и 200 получилось 500 но каунта слишком просто давайте например пользователи посчитаем цифра для удобства те же самые опять же для 29 и 30 числа ничего не поменялось а для двадцать восьмого числа у нас результате получилось 400 почему потому что было сто пользователи которые были и в первом куске и во втором куски произошло слияние кусков перри считалось где дуплицировать мы уже уникальных пользователей считаем и дуплицировать получилось 400 все отлично ну и вот мы на основе вот этого движка сделали материала стью то есть материализованные представления когда происходит вставка в основную табличку вот этот материал айс кьюб еще в в рядышком складывают вот такую сгруппирован ую информацию ontrigger а ванную и уже можно делать графики которые направлять на вот эту результирующую табличку и получается что полугодовой график вот такой вот красивый со временем скачивание одного региона мы бы делали нет исходной таблице 3 минуты из материала стью мы бы делали его основ 16 секунд а и смотрелось союз дублированию чувствуете да как пошли на второй круг второй круг ускорение мы делаем это меньше чем за две секунды и все можно сидеть строить графики как условный пользователь скачивает условную москву и оценивать мы на них этой графики и такие общеобразовательные мы смотрим на них если сильно время поползло наверх то начинаем разбираться привлекаем нашу статистику который у нас тут наше приложение и другие тешу надежные но тяжелые медленные инструменты вообще удобно когда можно сравнить с данными из другого источника но как прошла в концепт она взлетела и меня радует то что у нас получилось вот это решение она конечно не без недостатков самый первый и главный естественно это отсутствие генерализации сейчас мы храним на всю глубину свои данные и на каждый год глубины хранение нам нужен условный терабайт на каждый из реплик можно конечно устроить вот такие вот материлась view и группировать и считать агрегаты но мы теряем ту самую фишку которая говорил что мы придумали новый агрегат и сразу можем построить его на всю глубину хранения 2 это вот я как когда-то написал вот этот вот скриптик прослойку между лаг station и клика усам кафе и все знаете нет ничего более постоянного чем времена вот он так работает и долгое время не доходили руки но я думал что вот есть есть лук stash house on put on the мне поможет но руки дошли я посмотрел оказывается он не умеет параллельную запись в несколько таблиц а чтобы это добавить придется вы практически полностью переписать ну нам не подходит сейчас думаю в другую сторону что мы будем использовать нативный и тебе коннектор то есть лоб стоять будет гулять одиночными этими запросами в специальную по всему типа kitan хаоса или как house быть а это прокси уже будет собирать пачки и вставляйте house потому что crack house очень не рекомендуется оставлять поодиночке надо собирать пачки вставлять пачками и у вас будут лист мы конечно консольщики но мышкой на крепить фильтр и сильно удобнее и а вот какой товар какого-то налагает сильно не хватает ну что мы все о сидении до сиденьем у нас второй сервис есть сервис статистики помните там фиолетовые стрелки значит что происходит все наши сервисы это приложение сайт внутренние сервисы шлют статистику свои работы а статистика это какие-то пачки тритонов через нас нан 1 наш герой фактический backend мы принимаем во лидируем не дуплицировать не складываем в кафку потом приходит в эту кашку те кому эти данные нужны забирают что с ними делают и например складывает свои долгосрочные хранилища кафка поток джейсон авто есть поток структурированной информации где-то у нас то такое было помните да у нас через boxter шел поток структурированных логов ничего сделали мы положили этот крик aus ну раз ситуация такая же она такая же ну только на порядок больше там был 1000 запросов прыжке тут где-то 20 тысяч сообщений в секунду так мы вот возьмем и это тоже начнем складывать столько us написали сервисов на скале который читает эти джейсон и из кафки из них делает плоские джейсон и и складывает как aus в специальную табличку в табличке мы взяли какие-то технические поля идти по всякие таймс темпы тип продукт версия продукта бизнес поля не трогали их оставим бизнесу нам тут технической информации интересно и все нас у нас поток вот этих джейсон of полился в нашу табличку из коробки можно будет рисовать всякие прикольные графики например сколько у нас сообщение сколько времени занимает проход сообщение через транспорт как посчитать очень просто берем время сохранения сообщения в кафку вычитаем из него время когда оно было принято индексом будучи получили одно число поэтому одному числу опять же можно построить всякие процентиля тут вот всплеск до двух минут это сервис который складывается кафку был погашен то есть целиком и данные копились на буферах приемников мы потом сервис подняли она всюду в каску доехала но тему сообщения которые пришли в самом начале вот этого downtime а они получаются через транспорт шли две минуты такой же срез можно такие же процентили можно делать например для времени задержки статистики мы вычитаем из времени при приема на приемнике на джинсе время генерации пользователям приложением пользователя опять же получаем одно число рисуем такой же график либо можно и рисовать всякие разбивки разбивка вот например по продуктам вот тут у нас лежал корпоративный rabbit и продукты номер 3 и 4 на статистику не присылали а если мы посмотрим средств по типам сообщения то увидим что к нам в этот же момент не приходили в сообщении 3 типа то есть точно такая же яма удобно на такие графики смотреть и нам и поставщикам статистике чтобы понимать что мы ничего не начали терять в нет нам объеме это и графики вообще из коробки пост рисуются быстро просто ну естественно центрирования потому что данных все таки много вот дублирование сильно ускоряет из константное время помним да за любой интервал но еще немножко напрягшись и наплодить материализованные представлений мы начали считать еще и дубликат и и потерям ну что такое дубликат это мы одно сообщение два раза сложили в кафку а если это сообщение например оклики пользователя в баннер то и мы в два раза сложили то с рекламодателя два раза спишутся деньги а так делать нельзя естественно где-то там есть бизнес дедупликации но нам нам мы хотим пораньше об этом узнавать поэтому сами решили заготовить у нас же все данные есть поэтому мы вылечили мгновенно посчитать берем хищник сообщения и выбираем только те о хищнике которых встретилась больше одного раза и вот оказалось что один из внутренних сервисов нам постоянно плодит какие-то дубликата мы начали разбираться и оказалось что у них сообщение это разные а вот айдишник периодически повторяется один и тот же и получаются дубликаты ну и сейчас мы думаем как сделать быстрее и проще и про при этом правильнее нам складывать например хэши сообщений чтобы честно дубликата искать или все таким почините сделать уникальные хищники вот это что касается дубликатов а с потерями чуть интереснее что такое потеря потерь а это когда мы меньше msi запрос приняли за просим нас пачка джейсон of а потом и сказки нет нового джейсона из этой пачки не прочитали ну если не было веских причин на вот это дело как посчитать например мы через знакомы уже нам механизм берем access логин джеймса через 2 с его пробрасываем доу crack house и складываем в специальную табличку и и сказки читаем сообщения и складываем в ту же табличку при этом в обоих случаях заполняем специальное поле lost когда мы складываем все слуги джинсы мы в это поле представляем единичку когда читаем и сказки и читаем сказки станут николс в поле представляем минус единичку потом в результате отреагируем это все по группируем по айдишник у и оставляем только тех у кого lost больше нуля значит они потерялись то есть мы вернемся приняли и скольким и их не прочитали а чтобы она у нас чтобы не надо было каждый раз полностью все вот это группировать мы это положили внутрь властью с движком сами мир 3 он работает примерно так же как я уже рассказывал про где эти ножки но у него лежат не не промежуточные результаты агрегируются функций а он просто складываете числа в общем случае он складывает те числовые поля которые не входят в первичный ключ вот и у вас на диске лежит уже уже циферка вот по этой цифре кино можно эту цепочку например впревые можно использовать если вам нужны были точные но очень быстрые графики вот но график выглядит так я вот например положил вот этот сервис который перекладывает из каких только us и у нас на графике поползли потеря ну как же и сын джинсам и за мной джинсами запрос получили сколько вас он есть а ничего из этого запросов мы не искать и не прочли нужность развлекался нас нету ничего когда я сервис поднял все и сказки про стал steakhouse эти потери исчезли ну к чему мы пришли получается что через каждый через любой поток структуре ну информации вот когда через нас он проходит структурированы структуру информация мы на это все смотрим с таким прицелом а если мы этот поток возьмем и положено в каком-то какие сможем какие-нибудь новые графики нарисовать и знаете получается что обычно придумываем такие графики и приходится складывать в crack house рисовать эти графики и радоваться вот если не пробовали попробуйте реально затягивает вот тут парочка полезных ссылок ну первое это естественно то чем рисуем аки то что на период ребята из where the media второе это та страничка с переменными и джинсах ну вдруг вы захотите на нас прочитать какие вы джинсы есть переменные что можно в лог писательская лавстык house ну и третье это естественно документации на crack house ваш вопрос спасибо спасибо я и буду коллекционировать и стопочки складывать спасибо я помню самой сложность сложная часть это кладезь еще здравствуйте спасибо за доклад меня зовут евгений скажите нет никаких проблем с тем что граф она напрямую ходит клик house не смотрели может по средней здесь нужно 1 графит и и уже к нему кликающий переживается все вот-вот в те трюки по которой рассказывал они позволяют все пережевывать и так никаких промежуточных результатов вы просто складываете сырые логика us я граф она немножко ухищрений рисуйте графики быстро и просто красиво при этом у вас все сырые данные есть вы если че вы можете отход запросы туда делать и расследовать конкретным то есть как вы обычно работаете с лагами всего 9 рублей спасибо просто я так понял что сервера который на которых крути приказал с они физически примеру ну там баре металл в бремен сверху и lxd просто чтобы небольшая изоляция контейнеры были и в этих контейнерах крутится клика us никакого купюрница как вот на предыдущем докладе нету низкого локальная или шарится диски локальные тогда вопрос а почему не спонсор ник пока не надо ну и спорила не взглянула чтобы чтобы за шарди ровать вам нужно как минимум больше одного сервера на реплику вот то есть он тут у меня два сервера они мастер мастер и на каждом серверов полной копии данных чтобы сделать sharding надо ну несколько серверов вот-вот смогла выдержать поребрики на крест накрест просто вы могли бы просто и при больших запросов одновременно читать собою все ну я думал на эту тему но решил что keep it simple pack но так работает пускай работает будет сложнее буду посмотреть как пересортировать вот пока мне все хватает на 1 чтобы она лежала грубая на одном сервере вот на самом деле есть вот то что я говорил я складываю статистику в табличку в отдельный по статистике рисую графики там данных много поэтому табличка пухнет вот и я думаю сейчас я теряю на отдельный сервер и тоже думал или по шарди ровать и все вот перетасовать или отдельный кластер зависти и чет пока склоняюсь к кластеру вот кажется что с этим проще будет работать а еще просто вы только вы читаете эти графики не то есть внутри компании из других потребителей ну мы якобы как я на самом деле сказал граф а ну мы им отдаем спокойно то есть мы говорим если что-то вот смотрите смотрите в наших графа ну например недавно когда выходил последний сезон игры престолов дорогих выпускал вестерос вот и тут мне стало интересно блин а как у нас аудитория растет я-то с помощью при всяких ухищрений нарисовал график как у нас росла аудитория вот и ну естественно не преминул поделиться этим на всю компанию потому что смотрите чуваки вот у нас вот так вот прикольно растет аудитория тех кто скачал установил себе вестерос почему что практика показывает что или кого так устроен что один запрос достаточно крупный может сожрать все ресурсы сервера и не возникает проблем если у вас несколько людей до времен захочется допустим за год за два построить графики и это укладывает один из выступов приказ такой вот иногда иногда мы стянули там я сам я сам делаю тяжелые запросы но обычно какой-то и txeq который укладывает ну потому что себе то я памяти побольше уделяю и так далее вот но это те запросы которые я пишу в графа не они обычно во-первых simply раваны выбирают мало данных памяти много не шут вот с графа на обычном и крика уж не роняем но вот опять вот эти все ухищрения либо либо сэмплирования либо какой integrity номер три либо и то и другое ну я понял грифа на вас как рестриктор выступает он ограничивает спасибо что вот справой стороны здравствуйте большое спасибо за доклад вы говорите что в принципе все это приводит к большому увеличению красивых прикольных график но главное проблема с гарантия камин что чем больше тем сложнее на них смотреть есть ли у вас какие-то детекторы аномалий для того чтобы не просто сидеть или стоять как миллионов графиков а понимать куда смотреть нужный момент времени так сейчас по порядку значит она maltex вот у меня за 10 лет системного администрирования это голубая мечта чтобы у меня какой-нибудь умный робот не находил всегда аномалии при этом не ошибался не было фолз позитив чтобы он еще учитывался к сезонности праздники т.д. и т.п. вот мечта беру не раздумывая нет пока вот не получилось ни разу нигде поэтому как и говорил на 1 а самой важной штуке есть триггер и с тупо с лимитами вот что такая-то метрика превысила такой элемент таких-то запросов например стало больше десяти процентов от общего количества всем не сработать caps lock прилетит я посмотрю вот а чтобы смотреть не миллиард графиков разом по каждому из сервисов есть такие overdue дашборде в которых графики как она работает в целом если вот там уже есть какая-то аномалия вот как я говорил где-то в середине вот какая какая-то ступенька или яма он уже начинаешь копать от нее то есть увидишь что чет не так смотришь другие срезы вот то есть триггер и на важные метрики плюс overview дашборд который там на телевизор выведены там ротируется ну всё как у всех такие важные небольшие дашборд и и все вот не то на мальте к сожалению нет спасибо спасибо встречи вопрос одеколон страна здравствуйте у меня вопрос такой крик aussi в документации по центрирования написано что как бы вы не заметите дисперсию она типа очень маленькая но цифра конкретных не сказано у меня вот вопрос к вам как к человеку который использовал на продакшене сэмплирование crack house а какая там дисперсия вот реально 2 в ощущениях помашите пожалуйста рукой я вас почему-то она во пасибо спасибо так какая там дисперсия я честно проект был по потир веру вот по моцарту поэтому дисперсия вам не посчитают но отклонения ресемплирование то есть насколько он точно показывает данные сильно сильно зависит от того насколько хорошо выбран ключ сэмплирования и насколько она вот срез делается по папе ну хорошо положиться первичные ключи или нет для наших нужд хватает вот я говорил мы в основном сравнивали это не так чтобы чисел как чисел q&a рисуем графики смотрим норм не норм вот посмотри пожили какое-то время пас порисовали графики по сравнивали решили что в субъективно укладывается в то что это можно использовать решили что можно больше к этому просто не возвращались просто тупо понял у меня еще один вопрос вот у нас тоже в компании возникала проблема с как логин накапливать мы использовали связку граф анны и эластики вот скажите почему именно власть не выбрано было elastico потому что ну вот вы показывали на графиках вас используется отправка часов документов из индекса и как бы на мой взгляд можно было сократить несколько пунктов типа workstation всего остального и направлять это сразу власти q потому что новые ластика напрямую может работать за часом документами сохранять и более того я даже перри конфигурировать не надо как в отличие от clit хаоса который по таблицам хранит почему было именно принято решение использовать как house ну что вот я не заметил каких-то вот прямых предпосылок для того что он лучше спасибо за вопрос elastic был во первых он был когда на тот момент когда я начал этим заниматься он был как-то катастрофически не настроилась урал кошмарно много места и там всякие дела эти данные лежали без компрессии это все был на каждое поле по кучу каких-то ключей вот много много места но мне если честно даже сейчас не верится что в elastic можно положить вот так вот данный за год он во первых мне не потребуется еще десяток серверов и что я вот за этот год за 2 секунды я смогу построить график вот по всем данную за год я graphics построить не смогу а у меня цель быстро и красиво построить графики вот то есть либо на кибо надо киба на огонь искать силу очень удобно в принципе он elastic у нас продолжает использоваться вы там где логе вот не так хорошо ложатся на табличное представление к к к к к к истокам джинсы там там elastic там власти киба на удобных хорошо вот ну там обычно логов поменьше а вот когда данных много вот engine а уж когда вот мы говорим 20 тысяч запросов в секунду вот эти сообщения статистики и это вообще тяжко мне оказал кажется складывать пластик может я вы как готовить не умею но вот на тот момент показалось что click on накликал больше ну она будет проще меньше очень важно и быстрее та еще задача докладчика я не смог про дисперсию ответить по чесноку из заметил что стиль вопрос москве в новосибе сэндвичи да прям по хардкору суровые да да да у них академгородке есть бургер да я сам же ходе мая по мнению да так сейчас вот здесь где-то в первых рядах один из первых вопросов был про я забыл да да где где кто здесь задолго до вы лицо вспомни вопрос забыл кади на сцену ты напомнишь вова первый вопрос и я тех прошу подготовить речь пока ты выбираешься свое место как тебя звать где-то работаешь и почему зрители этого мегафоне без насилия работа образом эти при house мы используем сразу в нескольких сферах в первую очередь на через год когда попытались иметь графит на что-нибудь интересненькое дерутся и пытались придумать бегать туда с помощью потом нам пришла в голову идея более сложные с мониторами а потом мы стали использовать recalls и для аналитики в к ходанович новый диск уже в этом сочи а прочего проступок уж точно точно да да да я я тоже про это думал вот ну как как уже сказал ладно за ваш вопрос вот вам прочитайте здоровья материалы следующий следующий раз осенью будет de vaux как стать ребят правда а расспросите антонова дискуссионные зоне как он готовился к как это происходит как программно комитет работают до корочки оказалось что довольно комфортно то ток похмелье бывает но в смысле уже сбавим сложный вопрос специально чтобы здесь вам было интересно ему тем не менее помогаем подготовить такой поэтому если он что-то приходит голову пришло чтобы кулон сказать сразу что потом вот эту гол расскажите что не всегда айтишники такой словно статичные люди мне тоже думаю что они сделают что товар и приходи расскажи что-то сделать и цветок руки шире домофон же пока не работает как мы хотим и никогда не заработает потому что перфекционисты рада да да да ок окажет что на самом-то деле ребята сделали такую штук который не сделал еще никто в мире я и они не думаю что что-то особенно это просто на это просто работала у нас творческая работа приходите рассказывать подавайте доклады мы поможем спасибо огромное о том спасибо огромное за вопрос и в 12 число будет котла такие суммы там про мониторим какие тренды модные обязательно вами неудачи обязательно приходить я вот поддержу слова андрея до программный комитет очень помогает вот и может из вашей идее сделать конфетку вот так что потом не стыдно будет выступить и давайте уже где-нибудь на ближайшие конференциях сделаем прям целый трек покликал supreme чтобы с первого сначала и до конца прям ли каас отвлекалась а ура"
}