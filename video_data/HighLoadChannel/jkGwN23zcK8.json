{
  "video_id": "jkGwN23zcK8",
  "channel": "HighLoadChannel",
  "title": "Синхронизация данных из PgSQL в Tarantool / Вениамин Гвоздиков (Calltouch)",
  "views": 1040,
  "duration": 1401,
  "published": "2018-08-16T04:47:12-07:00",
  "text": "здравствуйте меня зовут вениамин и я буду вам рассказывать как мы делали интеграцию спад греческий чтобы совершить умное кэширование для наших данных потому что иногда довольно необходимо быстро иметь доступ к данным получать их оперативно и показывать сразу пользователям чтобы разрезать не тормозило словно для этого мы бы использовали тарантул и в нашем проекте это довольно-таки успешно была внедрена мы уменьшили нагрузку и получили довольно таки хороший результат и что у нас данный момент сейчас имеется у нас имеется пять мастеров на postgres 5 своего в к этим мастерам и и пиджи bouncer на карту и из двух нот для этого мы используем данное оборудование довольно таки большие железки быстро работающие но к сожалению на мне довольно всегда не хватало производительность чтоб их использовать довольно-таки эффективно потому что в прогрессе нас происходит большое количество транзакций помимо тех которые клиентские так еще внутри самого подвесов срабатывает тригер и производится множество операций select of других операций кроме как с внешних запросов спа спички кода также около 10000 внутренних основная задача у нас было создание умного каша где мы использовали как заданием быстрый доступ данному консистентной данных быстрая синхронизации и во время применения апдейтов на все эти данные чтобы это ускорить мы быстренько сделали небольшие сервис на таран то ли не стали заморачиваться сильно с репликация данных как это делать в мазке лис использование блип слоев и просто написали на селе крах и на триггерах внутри подвеса репликацию в наш сервис для этого мы использовали тарантул и несколько модулях к нему это трандл postgres expiration d и чтить и про митоз это для мониторинга статистике то что происходит у нас внутри дронтовые сколько в список и какое количество памяти за занимают чтобы но вовремя понять что происходит системе и процедурной opel python это дополнительный модуль который необходимо поставить вас греться и активировать его и просто написать одну большую процедуру и ограничение с которыми мы столкнулись довольно таки не очень тривиальные у нас были проблемы связанные с небольшим то что мы не можем больше большое количество обновлений принимать от позы в связи с тем что допустим в каждом из каких-то полезно взять ставим стенд данные не изменяется и у нас возникает проблема что может быть возникнуть не консистентных данных и для этого мы можем использовать только наш проект в небольших не сильно изменяемых данных и это показало довольно-таки эффективно не без использования полностью синхронизации всех данных то есть у нас есть большой ящик в котором несколько терабайт данных мы не можем их всех загрузить в память и начать использовать потому что просто нет возможности север установить столько оперативной памяти основная еще проблемам нужно было согласовать все обновления между администраторами разработчиками в postgres чтобы не возникли проблемы при синхронизации потому что могли изменить какие-то типы данных и при приведении типов мы могли получить некоторые проблемы и в общем такая получилась небольшая схему работы у нас при обновлении каких-либо данных в postgres или добавления либо удаления мы получаем апдейт на этот апдейт и в данной таблице стоит какой-то триггер этот триггер срабатывает на эти данные но дал ему три группы отключена процедура на pl питон он уже подключается к нарк тарантул скидывает эти данные какие надо обновить то есть какой таблицы какое поле и сколько их необходимо сделать после этого тарантул начинает использовать expiration d и получается что берет все данные последовательно выгружают либо из вас gresso либо удаляет на нашей стороне плюс мы как-то их изменяем как нам необходимо и уже складываем наш space и после этого получается что печки берёт свежие данные уже ресторан твой мы имеем сниженную нагрузку на перебьем серое наши сервера уже справляется с данной нагрузкой основная проблема то что в перебьем siri довольно таки и небольшое количество потоков он может поддерживаться у нас кончается worker ее сессии поэтому здесь это решение помогает нам уменьшить нагрузку на перебьем сир и у нас не нет необходимости ходить напрямую либо базам данных если что-то пошло не так либо через пиджи бисер и в тут выходит что в этой схеме она как бы и очень корректно и не корректно и одновременно потому что мы не можем такие большие данных загрузить который очень часто у нас обновляются но мы можем использовать то что есть сейчас в данном виде вот здесь ещё у нас используется несколько файтеров которые следят за состоянием таблиц потому что иногда получалось что при обработке был python скриптов возникал к section эти exception ноги рвали в подписи и наш файбер обходил всегда плоскость смотрел состояние этих exception of если какие-то совершенно возникали см и блокировали все соединения к тарантул из печки кода и он уже ходил напрямую к подвесу через 5 бисер поэтому у нас получилось что довольно-таки надежная схема и ничего не ломается здесь еще используется дополнительная процедура синхронизации просто на каждом старте мы можем запустится полностью со всего с нуля все данные выгружаются из postgres которые нам нужны маленьких таблицах и начинает использование ну как бы все можно здесь уже начинать вопросы тут нора больше 2 доклад про то как это запрограммировать чем как это настроить я могу ответить на ваши вопросы это больший интерес придут а это схеме сразу вопрос почему на этапе это было не разделить поток данных и сразу писать санту для чего именно через прогресс немножко не понял просто то есть от левого верхнего угла оно тает от него стрелочку направить сразу в таранто мы не можем так делать потому что у нас приходит апдейт в прогресс из парень из печки печки пишет в postgres пришел апдейт этот апдейт у нас в таблице уже стоит какой-то триггер мы начинаем использовать этот триггер и это уже событие отправляем в трант у чтобы все данные не отправлять в него не нужно гонять большое количество трафика мы имеем только значение названия таблиц и и номер поле которая нам необходима навить либо удалить его либо сохранить но сделать insert либо обновить просто ему делам после этого select уже данного поля или просто одолеет вы можете сказать другой альтернативу который можно здесь использовать извините но трандл был выбран по той причине потому что в нем есть все необходимые модули и можно иметь набор на борту сразу базу данных нам нет необходимости писать дополнительного демона который будет хоть отдельно в postgres выгружать какие-то данные и складывать уже в другой демон то есть у нас получалось какое-то ненадежное звено в данном случае у нас есть одно звено которое вы мему имеет возможность как в себя взять данный так у себя их и сохранить и поэтому у нас нет необходимости гонять данных через какое-то посредника как прокси до умный кэш который мы можем музык закрывать все данные не все ими определенных данных нам не то что нужно их за кашель нам еще нужно уметь их обновлять потому что данный очень часто обновляется так как сервис которому то используется является как нагруженным и очень критичны и данные отображает пользователям они иногда меняется это напрямую связано на деньги нам необходимо иметь получать возможность обновления из самого пас gresso прям к нам green grain не то ну кому там за деньги ну здесь я не рассматриваю как сторонний разработчик который был приглашен для того чтобы как внедрение вводить это уже выбрана было все до меня коробочное решение под ключ еще какие-то вопросы есть еще вопрос можете конкретные цифры примерно назвать то есть по такой схеме сколько данных в пузыре и какой процент от них вы крашер уйти в тарантул насколько у вас увеличивается при этом производитель так из того последний раз что я смотрел в целом из позы и самок выгружаем где-то 250-260 мегабайт данных плюс строим по ним индексы по нужным нам полям но в целом у нас стоит 2 севера в которых мастер мастер репликация между собой то 2 виртуальной машины на которых еще установим 4 гигабайта памяти ну по одному ядро участь от и виртуалке полностью справляется стой нагрузка как на которая не справлялась 10 серверов 250 мегабайт а всего в игре разогретом терабайт и потому что там различные данные имеются мы выгружаем только необходимые нам поляне все подряд у нас вот transform где здесь написано мы изменяем полученные данные после selecta в том виде в котором нам необходимо уже отображать пользователям чтобы уменьшить нагрузку и как в postgres так и у на нашей стране не хранить больше этапы в самом тарантулы когда большие tab и он будет их большие данные распаковывать упаковать это будет большие накладные расходы вот как раз человек передо мной рассказывал про и то же самое но это как прирост производительности здесь дает том что у нас мы сняли нагрузку с пиджи бен серов достаточно всего лишь один джинкс перед ними стоит балансирует нагрузка между двумя тарантул этого нам достаточно то есть и две виртуалке назад вообще маленькие такие можно за разделить даже там полно гигабайт памяти сделать это сильно меньше чем сдержать больше сервера железяки нагруженными расти так вот человек вперед занял здрасьте такой вопрос а если моя задача состоит в обратном я хочу из тарантула данный друг копировать подвиг это еще проще будет сделать потому что вам не нужно будет обратная связь иметь и спал с автором ту вы можете напрямую прямо из тарантул используя пиджи коннектор подключаться к тарантул postgres у используя перебьем сир или прямо напрямую делать insert и как вам удобней это будет значительно проще условно схема будет сразу же тарантул и сразу напрямую в подвес ну или там у вас зависимости от вашей инфраструктуру как это устроено да да перед трандл пиджи называется так следующий она мне нужно его прогревать у нас же все данные сразу выражены в память у нас там прям выгружается целые таблички с идиш коми и сразу хранятся всех памяти нам не нужно его прогревать да она быстро пица мы включаем ноды они у нас либо мастер мастер работает либо полностью когда сначала когда всех данных нет при запуске когда вообще ничего нет мы выгружаем абсолютно все данные и у нас при мастер мастер публикации сразу на двух новых есть после этого нас через и джинкс про фиксируется бы было запросам две ноты ну модуль стрим который там через песок случай если одна из вод выходят из строя ну например мы обновляем какой то надо выключить выключили там что-то с не делаем все запросы идут на другой тарантул и мы не видим разницы после этого запускаем следующему дальше все работает тот упал на 700 упал твой бизнес компании полностью будет остановлен думаю это будет но мы просто запускаем снова ногу торопиться вообще у нас данном случае предусмотрена блокировка such если у нас нет данных в тарантул мы в предварительно начали идем в паз grease у них в по здесь у нас есть таблица внутри этой таблице у нас сохраняется номер таблички были ли на ней exception-ы и какие то есть ошибки при запросах из процедуры вот где триггер вот здесь он делает запрос в трандл если какие-то проблемы были мы делаем залакируем sex action в таблице если там были какие-то проблемы мы на таран туле прям пользователю который ходит печки блокируем доступ и не даем возможность считывать эти данные потому что они уже не консистентной ты в данный момент и мы не можем некорректной информации показать пользователю после этого мы уже начинаем запускаем процесс внутри 7 стран то синхронизацию в отдельном файле ли он обходит select a mi все нужные нам таблички сохраняет все данные и после этого только разрешает пользователю читать данные из тарантул в нашем случае это занимает две три секунды потому что у нас не очень много данных больше занимает индексы да да потому что яндекс уже заранее попросту ну как у нас есть структура space of которых уже его предусмотрен то что индексы будет там несколько таблиц некоторые бываю там есть одна таблица который занимаетесь синхронизации 10 секунд можешь это максимум не более объем данных около двухсот мегабайт 256 это так то кто-то еще хотел здрасте конечно можно и 4 последовательно 1 насколько понимаю пил python и танцев решение не страшно а почему там три там пять строк кода всего лишь там exception из питона надо выкидывать подключиться к таран тут в одном thrice и секции мы подключаемся и сразу записываем и в случае если какая-то проблема произошла мы просто кидаем exception exception уже лагерем в познать у всех разные требования безопасности на в такой сфере просто в контур база нельзя у всех разные решения второй вопрос вот эта вот схема у вас апдейт триггер триггерная функция это синхронно и асинхронно выполняется тут встаёт дилемма если синхронная то вы в общем то стоите по времени да вы держите нагрузку на диск если асинхронно есть риск того что данные не дадут здесь я вот прям ответ был мог бы вам сказать но я не у меня даже доступа к этой базе данных не было то что как сделана разработчиками кто умеет доступ но я делал конкретно решения на тран туле потому что я отдельно нанятый человек был и и все она решение сделано как у них там у конкретному 3 зеленого у меня нет никакой представлена реки короткие вопросы не будешь марка ли не было бы быстрее проще просто если у вас всего 250 мегабайт данных матвею сделать по этим данным и все или флешки и периодически но вот вот тут я не знаю там была проблема основная то что у нас за тыкался именно перебьем sir то есть нам нужно было решить проблему с пиджи бенстером то есть чтобы он держал большое количество connection of я не думаю что вы здесь бы помогло от map view потому что connection of бы осталось то же самое количество понял спасибо еще вопрос о кого-то а с запросы как бы то количество запросов я вот оно все то же самое осталось вот данный момент сейчас она работает параллельно в тестовом режиме на 10 процентов от этой нагрузки вообще нагрузки мы не ощущаем там процент 1 2 процента утилизации цпу на виртуальных машинах да там так его там большие за вторичный индекс так мы выгружаем просто данные select a mi все электро у нас есть и короткие и кишки какие-то значения по ним эти короткие одышки у нас за толпа его получается что много вопрос запросов от разных печки нот и большое количество connection of после этого когда мы подключаемся и джек бендер с этим исправлять потому что нагрузку на так ты сейчас покажу вот у нас в инфраструктуре пять баз данных мастеров 5 своего инок перед каждым стоит по одному пиджи бисер получается что перебьемся выставляется и у нас большое количество collection of мы постоянном переключаем либо какую-то конфигурации начинаем подправлять перезапускаем сервис и часть из часть системы становится колом после этого нам необходимо было сделать чтоб она работала мы поставили тарантул здесь и когда приходит к нам запрос и то есть у нас какая-то проблема с база данных мы можем этих эфирных кэшированные данные уже отображать пользователю хотя позарез у нас может даже не работать и после того как воскрес уже запуститься мы уже синхронизируем те данные которые по репликации допустим на гоняется и показываем уже актуальные данные там может быть небольшая задержка но чтобы не сильно влияло на потерю денег чего про скотта а там все силикаты joy нами у нас идет до у нас сразу один то пойдет как мы да мы получаемся надо мы трансформируем так каком таком виде нам уже нужно и хранить чтобы уменьшить количество запросов не услышал извините я не услышу вы рассказали что заданный вас хранятся втором туре я не могу это сказать да не но просто там какие-то пользовательские данные про которые не могу рассказать извините могу сказать что там они не большие у нас получается по 5-6 полей в некоторых из них есть строки в которых по 10 символов все но не всегда чаще нол все туда же еще вопрос у вас сели там они уже данной съели языке и делаю обычные select и из-под gres нет select именно я делаю в postgres из-под glees делаю select a mi который на скот и в печке были написаны их просто за дублировал у нас уже в tarantul этими же силикатами которым позже сделал я синхронизирует данные сохраняя уже готовый результат который был исполнив сам печки получив данные из плоскости ну то есть чтобы уменьшить количество запросов и получается что один запрос сразу получаешься данной который не плева подскажите еще смотрите допустимых краснодаре ситуации когда идет у нас мульти processing опустим много потоков идут и многом множество апдейтов ответит одну и ту же запись я сразу говорю что здесь блин закрылась извините у нас когда возникает изначально эта схема у нас получалось так что большое количество битов ты не можешь сделать по той причине что надо будет сделать очень большое количество select of мы решили сохранять данные только те которые не очень часто обновляются но критически к обновлению именно критических к обновлению но но не все подряд потому что если сохранять все подряд то там очень большое количество запросов возникает при мне релиз нереалистичного сон тому 10000 где-то select of и каких-то апдейтов идет по транзакциям внутри сама вас gresso на триггерах и как процедурах поэтому мы не можем делать обновления то что то муссон у нас таймс темп поле меняется в котором просто время хотя остальные поля не все не меняется и если это поле сменилось то нам придется делать select из базы и угрожать эти данные получается что обновление приходят тогда очень большое количество но эти обновления не актуальны простого допустим два потока не сильно обновляем и но тем ни менее правельно вычисление работал белок в таранто ли какие-то данные были но но не обновились получает запрос придёт им от 2 до ног и то в самом подвесе который возникнет там как просто не представляю как может быть там так возникнуть но если он не умрет как у меня еще есть реплика 2 еще могу ответь на вопросы"
}