{
  "video_id": "wuV5DLiUuaI",
  "channel": "HighLoadChannel",
  "title": "Взгляд изнутри на надежность сервисов Facebook / Элина Лобанова (Facebook)",
  "views": 7544,
  "duration": 3246,
  "published": "2020-02-26T12:03:27-08:00",
  "text": "здравствуйте меня зовут елена я уже четыре с половиной года работаю production инженером фейсбуке и сегодня я хотел бы вам рассказать о том чем именно занимается production инженеры фейсбуке немного про то как это понятие в принципе появилась у нас компанией чем занимается моя команда и как мы следим за надежностью и производительностью всего воздушного боген до фейсбук это моя первая работа в высоконагруженных системах все мы знаем что такого в институтах не учат и то этого все мои системы это было два компа под стола примерно пять лет назад меня позвали facebook обычным разработчикам а в facebook нанимают не в команду в фейсбуке нанимают в офис поэтому я такая приехала в лондон и выбрала команду которая следит за тем чтобы facebook.com работал и оказалась среди продакшен инженеров встает резонный вопрос почему вы так называемся почему не называемся google и как угла и сары делаем ли мы то же самое для того чтобы более понятно это рассказать нужно немножко удариться в историю эта стандартная модель которая до сих пор используется во многих компаниях разработчики тестировщики abs и не значит abs и зачастую не только ops iii тестировщики тоже сидят разделены сидят на разных этажах могут даже сидеть в разных странах между собой абсолютно не общаются это была присказка так вот давным-давно 2009 году фейсбуке уже были zara и если мы посмотрим на булет поинты из дубовой книжки у них и сары начались пораньше они знают как достичь devops так вот если мы примерим это на facebook 2009 года розлива можно с уверенностью сказать что ничего у нас такого не было хоть и назывались мы и сары делали мы абсолютно тоже самое что делают abs и в остальном мире все было ручной труд никакой автоматизацией deploy всех сервисов руками мониторингу и как on call за все набор женских скриптов что случилось дальше такая штука низки лилась потому что количество пользователей в то время росло примерно в 3 раза за год количество сервисов соответственно и в 2010 году волевым решением эту массу и псов побили на две группы оставили и сара где уже явно говорила что это operations они занимались capacity все я сайт они занимались автоматизации все я сайт и мониторингом все сайт а вот ap abs это были ребята которые были интегрированы в команды каждый большие сервисы и вот они уже были близки к еде и devops of это нас на некоторое время спасло 2012 году ap ap просто переименовали в продакшн инженер ничего не поменялось просто как вы яхту назовете так она и поплывет а плавать как abs и мы не хотели азаров всё ещё существовала facebook роз и мы уже не могли они уже не могли смотреть за всеми сервисами сразу для того чтобы тот человек который был он кол ему нельзя было даже сходить в туалет он просил кого-то его подменить потому что горело постоянно и в какой-то момент волевым решением наше начальство всех сделал long haul всех смысле разработчиков тоже ты пишешь свой код вот и за этот код ean кол самые важные команды те вот самые production инженеры уже были встроены и они им помогали остальным не очень повезло начали с больших команд и за пару лет сделали on-call для всех во всем фейсбуке среди разработчиков были большие волнения кто-то уволился кто-то писал плохие посты ну все улеглось и 2014 году зару закрыли потому что они были не нужны итак мы живем по сей день а обобщая все вышесказанное мы похожи на угловых и сары просто слова и сары у нас в компании premio дурную славу но все-таки немного мы отличаемся потому что история мы всегда встроены в команды у нас практически нет как в гугле например и сары поиск у нас будет и сары этого сервиса поиска этого сервиса поиска и этого сервиса поиск нас нет в продуктах у нас столько в инфопродукт справляется сам мы вместе с разработчиками shareman кол но так как у нас чуть больше опыта в системах и в сетях поэтому мы фокусируемся на мониторинге тушим сервисы когда ди ярко горят заранее исправляем косяки которые могли бы привести к падениям и влияем на архитектуру новых сервисов самого начала чтобы они потом все таки как то могли работать а теперь по каждому пункту самое важное мониторинг как мы это делаем как все никакой чёрной магии только все свое домашнее hand made но делал как обычно в деталях и вот про эти детали хотелось бы рассказать начнем с низов кому-то знакомая картинка топ думаю не верю что так мало участке больше да прекрасно так вот это топ знаком всем в линуксе а это а топ где а есть advance как написано в википедии это монитор производительности системы но основная фишка топа в том что он хранит историю можно и вас configure что он кидал снапшоты на диск вот у нас он работает на всех машинах 1 5 секунд например машины на которой в течение минуты наши виртуальные машины который запускает печки ничего не делала она просто и все и вот как с помощью от опыта можно легко посмотреть в первым же делом а топ нам дает понять что мы а мы запускаем о топ за пару минут до того как случился стол что-то явно не так у нас процессом с процессором слишком много моего живем и с памятью у нас та же беда вот в каше осталась справа всего лишь полтора гида в печь каши бежим на плюс 5 секунд смотрим в почках и осталось всего в 800 то есть мы поджигаем памяти и на следующем плюс эти все сепию белый все нет ничего не исполняется и как говорит нам о топ если мы посмотрим на самую нижнюю строчку мы пишем на диск что же мы пишем на диск мы пишем на диск свопа самое теперь главное кто это делает вот эти замазанные ребята это наши внутренние важные процессы не просто не дали вам их показать так вот если посмотреть то у них из памяти отжали пол бега и положили это в своп а на их место пришли два мутных питания чьих процесса которые потом можно посмотреть как командную строку и тоже скорее всего я бы там все замазала поэтому я просто вам это не показываю в общем отток прекрасен мы его используем постоянно и если у вас его нет я strongly нг кароч не знаю как по-русски вас это сделать и не бойтесь за диск он всего лишь эстампа 200 по 300 метров сзади если 1 5 секунд вот говоря о потопе мне вспомнился один забавный баг который мы де бо жили как раз с помощью а топы и стресса а еще у нас баги получают имена и большие инциденты тоже вот этот бак получил название молока ттп присказка мы используем шрифт как рпц везде в ранних версиях парсеры был восхитительный бак обработала это так приходилось сообщение первые четыре байта это размер потом само сообщение берем первые четыре байта ой простите берем первые четыре байта и ассоциируем на следующий месяц вот как-то раз этот замечать с бинали вместо того чтобы ходить в хребтом и сервис пошел от этапа сервис и получил ответ от request взял к ттп из аллоцировать молоком вот это да в количество байт и казалось бы ничего страшного у нас же есть товар commit ну зала цера валим и молоком пока мы туда не пишем мы не читаем реальную память нам не дадут но не тут то было пока вы не захотите for гнутся потому что форк вернет вам ошибку у вас нет памяти на память есть почему ковыряя маны на самом деле очень просто текущая конфигурация варка митя такая что это магическое эваристти к и ядро само решает когда это много когда это немного и для работающего процесса это нормально можно молоком выбрать себе там датора терабайта а вот для но выбраться за нет я запустила пару дней назад файл файл налог fork и меня выбросило с ошибкой на 200 гигах вот такие вот интересные вещи встречаются поехали дальше от низов звездам хотелось бы фраз рассказать про нашу базовую систему мониторинга назвали ее в честь назвали рфб free free назвали в честь стандартного басовый синтезатор и 82 года разлива потому что как бы чтобы это была базой для всех сервисов фейсбука так и вышло работает по принципу очень тупому простому поэтому видимо до сих пор каждый сервис тампль имитирует фруктовый интерфейс get caught с на самом деле он его не имплементировать потому что библиотеки уже написаны поэтому в коде все делают инкремент или свет и в итоге каждый сервис экспортирует нас на борту которой он регистрирует сервис discovery каунта вот это пример машины которая генерирует новостную ленту она экспортирует порядка 50 тысяч при этом там из-за памяти запросы и за все что угодно а на каждой машине работает бен орёт который ходит по всем сервисам вокруг собирает эти кантри кладёт их в сторож а так визгу из тораджа и вы наверное можете сказать мне что это кажется prometheus плюс grafana и это ничего нового и выйди вот почему во первых не prometheus они grafana потому что если посмотреть в генштабе it be free free первый камень был 2009 а prometheus по википедии в 2012 и это на самом деле объяснение всех хендмейда facebook а мы просто их делали когда ничего еще нормального упал собственного не было поиск и выглядит это примерно так у нас даже есть группа в которую мы внутренняя в которую мы постим красивые графики вот это оттуда а единственная фишка наверное нашего parameters плюс графа нас т.к. то что он хранит данные вечно он их перри sampler uid и через просто через две недели у вас будет 1 1 . на каждые 5 минут а через год на каждый час поэтому они могут столько хранить это автоматически даже не летний configure но если разговаривать об особенностях футбольного мониторинга то я бы описала это одной фразой и так это в принципе описывают все докладчики кто рассказывает английским словом обзор выбились это вот есть black box есть white box а у нас такой стеклянный прозрачный бокс мы не лакируем то что нужно чтобы попала в dash барду мы когда пишем код мы лоббируем все что можно неважно попадет она в dash барды не попадет иногда даже борды и так как сэмплинг настроен везде хорошо поэтому бэкенд для стороже каунта raw и всего остального живет нормально а мы при этом можем потом строить наши даже борды уже на имеющемся каунтер ах и даже борды это даже не случаях инвести гришина в даже борды это не конечная точка investigation где у тебя есть там 10 графов даже борды это начальная точка инвести конечно а потом мы идем в наш юань и находим там все что можно и вот апогеем идея герба бейте является наша скуба это наш кекс так принцип тот же пишем джейсоне без определенной схемы потом запрашиваем в виде таблиц таблицы или time series of или еще десятью видами визуализации и блокируется вс кубу порядка наверно сотен грамм в секунду и запрашивается это все очень быстро потому что от милости все и и она все это в памяти на очень жирных машинах да на это тратятся деньги но господи как же это прекрасно вот пример это наш мальчик это самая популярная таблица который лаги руются блокирует все клиенты всех рифтовых сервисов вот это один из сервисов вот у него что-то пошло не так под конец явно давайте посмотрим а какая была задержка в этот момент идем в список аккаунтов выбираем задержку выбираем агрегацию нажимаем дайв бум ответ приходит за 2 секунды до действительно в тот момент у него было что-то плохо или тысяч увеличилась значительно поэтому дальше можно посмотреть по группировать по всему чему угодно и таких таблиц сотни моя любимая таблица это когда на каждом на каждом посте раз в час делается псы кидается school поэтому мы в принципе знаем какая версия вина я такая версия пакета сколько она там памяти поела на всех миллионов машин в одной таблице туда же летит west мисок космосе в другую таблицу все corey дампы также перф можно мы запускаем раз в десять минут на каждой машине поэтому мы знаем какие стектрейсы у нас работают на ядре и можем знать кто там поджигает наш глобальный сепию а скупо выступает брендом для еще одной клёвой штуки которые у нас есть и это наш основной инструмент дебага печкой потому что печки пишут тысяч инженеров и надо как ты их это надо как-то спасать глобальный успешной репозитория от плохих вещей как это работает перед тем как положить в нашу школу то есть у наши ластик search мы мы не можем положить все логи и все стектрейсы этих логов мы делаем хаш от этого и кладем только хэш а сами стектрейсы мы кидаем в моем кэш и собственно это просто визуализация с группировкой по крышам от лагов и stack trace of и потом уже во внутренней друзья можно вытащить конкретный stack trace уже изменим каша достаточно быстро да очень центрированы но работает прекрасно и собственно дебаг здесь происходит по методу поттер начинка открываем слугу смотрим о ошибка спайк идем в labview группой stack trace а по очень похожая штучка нажимаем смотрим на мы смеем каша подсасывается stack trace ну и дальше уже по stack trace его можно найти div который был запущен примерно в это же время или еще что-нибудь и откатить его потому что нас коммунизм и откатывать и коммитить могут может кто угодно никаких permissions для этого не нужно закончить про мониторинг я бы хотела моей любимой даже бородой которые необычное я бы хотел вам про нее рассказать начнем с того это стандарт что в нем не так линия фиолетовая на одном графе на самом деле то же самое сервер что голубенькое на другом а еще time when do u у них разный нуклеации не видно мы используем вот такие даже борды это основная даже бар до того что facebook работает их у нас очень мало всего три это очень странно выглядит 50 оттенков зеленого я вам расскажу как это работает потом это один день по одному пикселю на минуту каждой линии это регион дата-центры которые находятся рядом отображают а несколько фейсбучный бэкенд пишет свой лоб байт секунду а внизу аннотации потому что у нас есть команда в америке когда мы им передаем что ну чтобы они видели что мы уже от депозита что случилось сегодня кубизм это open source на я java script ого библиотека которая выпущена под apache лицензией написано ребятами вскоре у них есть встроенная поддержка графита и куба но я легко расширить самому как мы сделали вот пыталась недавно yandex это продать посмотрим человек черти получится очень легко искать корреляцию вот это количество лагов которые мы пишем есть что-то слева есть в центре переходим это пятисотке сколько мы возвращаем 5 соток слева нет ничего это знали что то что было слева она в принципе для пользователей не имел никакого значения а вот это темно зеленая штука с центре она явно как ты мне понравилось а это лет инси пенальти nine и в этом же самом центре видно что был просил понижение понятно что для того чтобы вернуть ошибку много времени потратить не нужно все равно еще не очень понятно хотелось бы рассказать как это работает вот это граф 120 пикселей высоту все прекрасно видно восхитительно но много таких на одну даже барду не положишь зажмем его до 30 и ничего не видно какой то удав вернемся обратно и посмотрим что с этим делает кубизм кубизм бьет его на четыре части чем выше тем темнее а потом складывает получается что у нас есть то же самое граф что и раньше но при этом все очень хорошо видны и узенько и чем темно зеленее тем хуже теперь вам больше понятно что здесь происходит вот то что слева видно прям шейп как она там поднималась но это что в центре совсем темно зеленые значит там все было очень плохо кубизм это только начало это для визуализации чтобы бросить взгляд и понять плохо щас все или нет вот кубизмом для каждой то бы существует уже дай в душе с нормальными графами уже от каждой кубизм это просто вот самое начало мониторинг закончили с мониторингом мониторе нужен по себе сам для того чтобы понять состояние системы и отреагировать если она сломалась и фейсбуке on-call все и обязаны уметь видеть все но если горит ярко то все помогают ей особенно про lock же инженеры потому что production инженеры сисадмин ским бы kindom они знают как чинить быстро и ладно не буду продолжать тогда у вас огромная компания пахнет горелым пахнет горелым может в одном месте а гореть на самом деле в другом и нужно когда это все сорганизовать и помогает нам в этом деле и г ю а ина это у за которую тоже написали production инженеры кстати называется она инцидент менеджер портал он открыт для всех как только что-то случается мы заводим там инцидент где есть название начала и вы можете потом на слайдах посмотреть этого я кажется слишком долго буду рассказывать самая основная одна из основных важных штук в этом случае что у нас есть специальный обученный человек который называется инцидент менеджер oncol это человек который должен в случае больших пожаров с организовывать и координировать людей чтобы они чинили он не обязан чинить сам обычно это ротация менеджеров и его обязанность то есть как только создается инцидент с высоким горлом и мер женский мы приходит эсэмэска он приходит и начинает помогать все это организовывать такие люди очень нужны когда у вас очень большая система раз уж мы заговорили об инцидентах вам наверное интересно было бы послушать истории о том как facebook лежал обычно люди думают что фейсбук лежит потому что доз или потому что хакеры на самом деле за пять лет ни разу такого не было это всегда были наши инженеры да она не сидят машин а они не специально просто система очень сложный и она может сломаться в том месте в котором ты не ожидаешь я же говорила что у нас всем инцидентом даются имена большим чтобы было удобнее их упоминать и рассказывают новичкам дабы не повторялось этот в будущем чемпион по самому забавному имени получил инцидент уколы капс люди звонили в полицию лос-анджелеса и просили их поправить facebook потому что звук лежал а них да столько довели что шериф лос-анджелес и написал в твиттере пожалуйста не звоните нам мы за это не отвечаем это реальный скриншот мой любимый наверное инцидент я в котором я участвовала и называется получил название caps lock он прекрасен тем что показывает что случиться может все что угодно а случилось вот что первые шесть адрес обычный фейсбук использовать шеф для того чтобы настраивать ось шеф читает из текстового файлика конфигурацию hasta эту конфигурацию подсовывает как сервис инвентарь и который в базе данных от все хранится дико полинг все дела вот этот сервис инвентарь и поменял себе версию и стал читать api адреса сразу из базы данных масик вольном формате и подкладывать их файлик hf такой приходит смотрит файл о айпи адрес поменялся сравниваем строчкой зачем же маслом зачем же в бинарном ты видишь сравнивать новый api адрес надо опустить интерфейсе поднять интерфейс и на всех машинах на всех миллионов машин за 15 минут мы опустили интерфейсе подняли прекрасно казалось бы ничего страшного ну-ну-ну capacity поменьше стало пока у нас сеть лежала на некоторых машинах но нет тогда же был открыт баг в сетевом драйвере наших кастомных сетевых карт они при старте кастомные же не нужно же запариваться при старте они хотели пол giga последовательный физической памяти она кэш машинах пока мы опускали интерфейсе поднимали интерфейс этих пол гидрат уже пропадали поэтому на кэш машинах у нас сетевой интерфейс опустился и не поднялся без кашей ничего не работает и вот мы ходили но не ходили конечно сидели и ребута летие ой простите я не переключила и ребута ли эти машины руками это было очень круто фейсбук не так часто лежит как вы заметили и большую часть времени мы все таки не тушим пожар и или путаем кэш машины а пытаемся править баги заранее если можно для всех сразу и вот хотелось бы рассказать пример одного общем продуктивного фикса который мы накопали и собственно для всех даром его поправили проблему очереди количество request of увеличивается на 50 процентов а сервис начинает елозить 100 потому что ну никто же фатален complementi рует заранее особенно в небольших сервисах и мы поковырялись в нескольких и примерно определили модель поведения как это работает при нормальной нагрузке вас request приходится обрабатывается возвращается клиенту при высокой нагрузке красненькое этот тайм аут клиентский при высокой нагрузке request и ждут в очереди потому что фред пул им не хватает них еще все еще есть время до за лето все увеличивается но норм очередь растет нагрузка увеличивается и в какой-то момент все что сервер исполняет она на клиенте уже от тайма училась и моего выбрасываем и получается клиент еще перри повторяет и получается что все request и которые мы исполняем они все выбрасываются мусорку и никому уже не нужны как эту проблему решить для всех и сразу давайте введем them out watch стояние в очереди если request стоит в очереди больше чем x миллисекунд ну просто его сразу оттуда выбрасываем и не обрабатываем его на сервере в принципе то есть мы сипим на него не тратим и поэтому у нас получается честная игра все что мы не можем обработать мы выбросили все что смогли обработали поэтому если сервер сервис работает в полку то он получает плюс 50 нагрузки и и роллет этот эти 50 процентов нагрузки просто выбрасывает 30 процентов и ребята которые пишут писали фреймворк для dispacci на сервер сойди они от штуку имплементировать а мой продакшн и инженеры нежно за тепло или 100 миллисекундный тайм-аут в очереди на всех и таким образом дешевый базовый фото link все сервисы получили сразу я вам тут рассказала про то как мы де божим прецеденты но как говорит идеология угловых и сары и наша тоже если у вас большой флот машин куча сервисов руками ничего не сделать надо код писать автоматизировать себя от работы поэтому 50 процентов времени плюс минус зависимости от команды от человека мы пишем код и мы строим тузы я не могу перечислить всех но идея такая что пишем ее совсем разные штуки и ю ай мы пишем это вот кубизм интегрировали в нашу систему и и в бород это прекрасная вещь у нас никто не парится на тему одной сломанной машиной потому что в бар и the job engine который полетом приходит и просто пытается как-то пофиксить одну машину это было его основная задача суд делает гораздо больше но это прям прекрасно курить дампир вот куда берут я написала и двое моих коллег он мониторит корки на всех машинах и скидывает их в одно место вместе со stack trace omi и со всей информации о посте где окорочка лежит как ее найти какой у нее размер сколько она добилась самое главное там еще скидывается стектрейсы за бесплатно всем даже без дампе ни корки на диск потому что в би-би-си если вы знаете что это если нет при подходить и потом наношу ступе вам расскажу можно в ядро сделать хук прям перед в момент дампов вытащить оттуда stack trace за бесплатно и наверное последние что мы делаем инциденты мониторинг и код мы еще разговариваем с людьми это вроде как с одной стороны сложно оценить насколько это важно но это очень помогает и одна из основных вещей как мы помогаем людям так мы помогаем людям нашими разговорами это мы проводим reliability review by label сильвио это для уже работающих сервисов мы их спрашиваем а вообще надежные и вот спрашиваем их в этом ключе это цитата из опросника что основная responsibility системы это работать а то что она предоставляет какой-то сервис это уже такой дополнительный бонус мы им даем опросник в которой мы спрашиваем абсолютно базовые вещи но так получается что когда люди отвечают вопроснике текстом как то что написано пером в общем они они стараются ней даже в этот момент правят свои системы например мы спрашиваем их вопроснике что будет если ваша система получит 10 процентов нагрузки что случится они начинают думать о действительно что это для это мы это делаем для среднего размера сервисов крупный сервис они там сами разбираются они задумываются потому что до этого не об этом не думали а например мы спрашиваем а кто первый замечает обычно проблемы с вашим сервисом вы или ваши пользователи они начинают вспоминать когда такое было вспоминают и такие может быть надо алё ртов добавить и а потом мы испрашиваем а какая у вас самая большая окольная боль потому что особенно когда девелоперы он коллит и непривычные особенно кто вновь пришедшим тяжело они тут же говорят у нас много alert of давайте их почистим давайте уберем те которые ноги мы испрашиваем а как видите как часто вы делитесь и они такие мы движемся руками может стоит за он гордится в нашу континиус диплом а это делает и не долго потому что facebook для этого сделал опять же своих армий кастомный диплом берут и делают в общем прилла бились review хоть и не включает себя с нашей стороны никакого козья нога ничего мы просто разговоры даем им опросник они его помогаем им заполнять его в течение двух не двух-трех недель а потом устраиваем двух часовой митинг на котором мне это нам рассказывают и эта штука работает кажется я уложилась по времени море доклад подошел концу сегодня я попробовал рассказать кто такие продакшен инженеры раскрыть по каждому пункту наши обязанности показала как мы мониторим сайт веселило вас нашими файл в фейлами спасибо за внимание сейчас у нас будут вопросы если кто не успели задать вопрос подходите на нашу стойку она около 2 входа r11 и еще хочу вам сказать что 1245 у нас будет капча the flag если кто хочет поучаствовать мы запустим во всех соц сетях хай-лоу до первую подсказку а тот кто первые 5 получит около спасибо огромное мы соответственно хотелось своей страны сделать подарок от холода это сертификат участника и удобная тебе просьба сейчас люди будут задавать вопросы и тебе нужно будет выбрать тот вопрос который больше всего тебе понравится хорошо спасибо выбираю я по рукам не увидели кто первый видели-видели дайсон можно ее совершенно обычного им занимается спасибо большое за доклад было очень интересно меня интересует вопрос автоматизации вопросника мы делаем сейчас примерно то же самое в компании мы пытаемся максимально автоматизировать то есть записываем в виде в каком-то робота читаемом виде и потом проверяем каким-то образом то что люди ответили в этом вопроснике для того чтобы проверять деградацию перспективный анализ и прочее как вы работаете с этой информации как вы ее хранить и обрабатывать или вы ее автоматически проверяете ли со временем и так далее спасибо все руками у нас обычно даже своих буквы что у нас опросник всего моему 2 страницы у нас обычно назначается ответственный который работает с этой командой помогает им потом они приходят на митинг разговаривают и тот же ответственный записывает ответы и не атлет и рекомендаций по итогам митинга что им порекомендовали ну например 50 абортов неделю это не круто поэтому давайте вы сделаете до двух вот поработайте над этим вот так то так то тактных все с душой автоматизации вообще никакой нет а просите это же не масштабируется масштабируется потому что у нас разные группки этим занимаются группы людей и это не одна группа у нас в лондоне это одна группа людей в америке это несколько групп людей в разных офисах и например сервиса рекламы я понятия не имеют как они работают у них там есть свои люди которые опрашивают рекламщиков есть свои люди которые опрашивают там инфраструктуру есть враги люди которые опрашивают не знаю еще чего-нибудь это более детально но так а раньше это была одна группа часто из-за того что опросник уже стандартизирован на праздник меняется каждые там полгода плюс-минус она такой расползлось и теперь каждый делает это сам и это наверное так у нас гильзы или на привет спасибо большое лучшую презентацию этого high low dose of our прям прям очень круто на одном из слайдов где были роли в инциденте там где инцидент менеджер он кол и был еще несколько ролей причислена там был ник с ролью тихо гор можно чуть поподробнее об этой роли ибо об остальных ролях инциденте прекрасно от ригой и это замечательная роль печки очень большой пишут тут оочень много людей раньше этим занималось моя команда кто-то он запустил плохой печки dice и печали например не бил биться он сломал все или запустил такой div который за лагера волнам половину стороны логов сэмплинг там немножко отвалился поэтому нужно это срочно за ривер сити это специально обученные люди которые знают печки у них on-call 8 часов 1 2 недели на нужных очень много в это в обычной пищи и разработчики и эти 8 часов в день они ответственные за peach & push если в момент уже что-то вылезла не то а мы пушистый джами мы сначала пушем на работников потом мы пушит на 50 процентов работников чтобы спросить сравнить их с другими 50 процентными работников потом и пушин на 2 процента пользователей потом уже на всех и вот в дырке между двумя и всеми вот эти ребята если чего не так они должны откатить назад то есть их работа я так liberty div и и вот триггер он cool там для того чтобы если что то не так с пушем и надо срочно либо остановить push либо пропихнуть fix уж чуть чуть побыстрее потому что континиус бил его же можно там подтолкнуть на полчасика вот этот человек там ответственной за печкой push почему три highgear в то очень исторически потому что остальные аймаки а там был этой мокнет варкой мог это точно также как инцидент менеджер on call большой а тут областные сети реклама ем foundation там был это моя команда которая смотрит за 500 коми фейсбука и чтобы вместо того чтобы on call если совсем сильно горит ой мог не организовывал конкретных людей ой мог организовывать других аймаков они уже организовывают своих людей такой кто следующий большое спасибо за отличный доклад скажите пожалуйста если у вас политика zero lt и rt лоренс или пустых логов ошибок или вы допускаете какой-то фоновый уровень ошибок фоновый уровень ошибок есть всегда в нашем случае наши fresult и по моему 0.003 0 600 единиц а одну миллионную мы рисуем на графах и она всегда есть шум какой-то ну потому что мало ли чего ни у кого нет такого что 00 логов 0 ошибок увидели наш кубизм налоги он был темно-зеленый в основном все плохо если какие-то формальные правила при каком уровне ошибок должен быть откат или каждый решались сервисом каждый сервис решает сам например для фейсбука для печки или если на кирпич p.def вызвал какие-то увеличение 5 соток это обычно такой наш год filling от это вы были нет окей нет форвард и нет вообще можно регион подойдите нормально будет это вот весь такой год filling и если я например ошиблась и вместо того чтобы откатить push подождала форвард фикса который дольше и ты у меня за это не уходит спасибо добрый день спасибо большое за доклад учит желаю презентация спасибо алексей подкастами об последние наверно пару или тройку заметных падения фейсбук это что там было заметно на down детектор как правило падал и facebook и вас об instagram насколько общая инфраструктура с точки зрения production инженеров о ваш проект можно я право цап не скажу что что что может и хотя на самом деле нет не скажу потому что вас об совсем отдельно он не с нами он у него фоточки только с нами поэтому последний был как раз с фоточками и вот фоточки упали у всех потому что фото сторож приехать на фото сторож легко взяла поменял кол сервиса куда ты сохраняешь картинки как ты потом сидя ленку gelish более бизнес-логика как это называется сервисы перезжать сложнее поэтому воцап отдельно а инстаграм уже тоже с нами поближе но все равно у них джангл на спички у вас от мир long ну как не как же фоточки еще какие то там видео то что можно унифицировать легко у нас с инстаграма вообще поэтому если фоточки то фоточек не будет ни у кого последний раз были как раз они спасибо я здесь круто да классно вот вы показали слайд с очередью и там кружочками с приматами стрельцы не думали поменять очередь нас так и сифона лифа и очень интересно чтобы в сервисе обрабатывать запросы через стеком они очереди ну да никогда на прошлом холодной коллегой ваш дропбокс рассказывал что они такую штуку внедряли и тепло это прям очень круто решает много проблем знаете может быть в каких-то сервисах у нас это есть но очередь это дефолт и я даже об этом не думала я этого я не знаю если у нас стек не слышала про него это интересно спасибо спасибо здравствуйте лина у меня два вопроса первый вопрос мне просто интересно я знаю без крупной компании российских используя такую штуку когда вы работаете в своей команде у вас есть смежные команды других ну как допустим вот взаимодействуйте с разработчиками допустим как и котенка вы же все у вас есть такая практика что допустим вы можете на месяц уйти ну просто для интеграции работать именно с разработчиками по их функционал не по-своему по их или там сетевиками или там с баллистами ну как то вот так есть такая практика фейсбуке это первый опрос и второй вопрос опять же просто не знаю отвечает за это нет мне просто очень интересно про deploy когда рассказывает один из самых острых моментов для моей компании к примеру когда depo и msi приложением и спокойно как вот как у вас там переключаем на какую-то группу смотрим как отработала там половина трафика как вас за базы происходит потому что когда-то depois у тебя одна половина ну база должна быть старой друга но вы как вот актив актив что используется и какие технологии для такого решения так первый вопрос был про команды у нас так как мы интегрировали в командой у нас нет такого понятия работать с разработчиками они всегда работают с разработчиками там бывает у них митинги общее всеобщее просто менеджеры разные и это даёт людям больше свободы когда разработчики такие мы сейчас запилим фичу наши говорят нет знаете мы сейчас будем править потому что настройка не тронется в ирак тринити неделю мы сейчас идем мы пишем вот три милку нормальную и разработчики такие ну как же но фичей же а наши такие а нам пофиг у нас менеджер другой то есть он работаем с разработчиками вместе пойти сетевика ли поработать например если нужно у нас например сетевики сидят в другом офисе взял билет купил полетел посидел с ними две недели или там в америку слетал на 2 недели это абсолютно нормально второй вопрос с базой у нас очень как если что-то работает медленно добавьте кэш если работает еще мир медленно все равно там еще один вот у нас между базой и php большая тура которая называется то у и там внутри есть механизмы как создать как добавить потому что мать мы используем а сиквел как key value сарыч и поэтому там не нужно добавлять колоночки мы храним объекты христовый объект собрал его бинарный вид и положился вместе с ключом родишь ника все поэтому в этом случае база менять не надо надо менять только полям объекта а вот между php мазиком сидит а у которой все это знает и там все хитренько решает там в этом году мы нас нету реляционной базы данных как таковой в большом продакшене можно за использовать масику как таблицу но это уже ты сам выбирай как ты там будешь добавлять себе поля дорогие ещё два вопроса или на спасибо за доклад мне вопрос про внутренний сервиса которую вы разрабатываете для поближе да для ваших сотрудников то есть вы как produce тим вы делаете какой-то софт свой допустим для мониторинга и так далее у вас на постоянке есть команда который вы поддерживаете ли вы один раз сделали и как-то и все и забыли и как у вас коррелируется девственно следил как это работает есть команды которые например занимаются какой-то тулузой для мониторинга вот например кубизм написали на написал один чувак в америке в моей команде он потом вышел в другую команду оставил кубизм нам слава богу он написал о хорошо он работает прошло пять лет и какая-то команда который сказал может быть вот этим дата с аметистом будет интересна такая визуализация мои у вас забираем и мы сейчас ее переделаем так чтобы она работала мы скажем мы попросили их оставить нам старую версию потому что понятно что будет если они для dts саммите став переделают тот ю ай который мы используем для дебага это бы что-то другое поэтому они попросили их поддерживать две версии кори dapper например это вот ту за которую я написала чтобы мониторить все кордом в системе ан до сих пор наша и я вот сейчас уволюсь если вдруг то она останется на моих коллегах которых двух из них я научила как она работает но если мы все вдруг уйдём то скорее всего она просто стухнет и идеальное состояние такое ты пишешь что-то очень клевое и вовсе любит потом ты находишь команду который примерно этим занимаетесь хотите смотрите какая вещь и заберите и они забирают ну вот мою штуку собственно сейчас как дам пирс мы сейчас вот попробовали отдать одними они кажется ее заберут это будет прекрасно спасибо за доклад был вопрос про alert а как вы с ними боретесь один из примеров было что там у сервиса пистолет в недельном сделать 2 а что вы делаете когда там новый год праздник куинси регионе или там каникулы наступили и там профиль нагрузки совершенно меняется и что-то надо с этим делать у нас в основном стараются делать аборты на рейд количество error of относительно количества событий они не меняются в таком случае мы делали over the messenger и это была боль потому что send поттер меняется же постоянно в новый год мы просто терпим ну потому что новый год а в остальные времена ну например не знаю волдыри ооо там был недавно в алжире были экзамены они взяли интернет выключили на день молодцы вообще экзамен смысле школьников выпускные они достаточно нормальные пользователи поэтому нас просело то мы делаем мы написали новую формулу мы сравниваем минус день минус недели минус 2 недели -3 недели разницу и потом по ней делаем pide и fifty и тогда все предыдущие дни которые если там что-то было неделю назад она не попадет потому что мы сравним с минус 2 недели все еще остается проблемой если сейчас что-то приз нужно новый год за портит мониторинг если ты сравниваешь минус одну неделю если сейчас что-то происходит по странам у вас есть это россия такой печали знаю что здесь сделать но мы делаем по странным и если тут уже больше все-таки глазками но надо написать правильный лет в этом случае смотрим что если это в 80 процентах странах нет а в 1 ст вот в кубизме это хорошо видно если по группировать по странам там будет одна сторона тёмно-зелёная а другая как обычно поэтому а ну это опять там не знаю положили экзамены происходит а глобально на саму facebook'е вот то что мы мониторим мы это и wraith latency и логе она не меняется вот только на новый год и на инаугурацию трамп мы там испугались у нас все сломалось налеты завизжали это просто все смотрели инаугурация трампа спасибо огромное лин самый лучший вопрос нужно выбрать я бы наверное выбрала все-таки про с тех вместо очередь это было очень прикольно кружка и книга откопай от компании wargaming спасибо тебе огромное если есть ещё какие-то вопросы можно задать в кулуарах"
}