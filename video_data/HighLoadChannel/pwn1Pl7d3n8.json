{
  "video_id": "pwn1Pl7d3n8",
  "channel": "HighLoadChannel",
  "title": "Быстрый поиск на Redisearch в ленте операций для миллионов пользователей / Илья Сиванев (Т-Банк)",
  "views": 266,
  "duration": 2801,
  "published": "2025-01-17T02:25:14-08:00",
  "text": "Всем привет Меня зовут Илья Сегодня я расскажу вам про поиск в Ленте операции пользователей как мы это у себя сделали Меня зовут Илья Я работаю в ти банке пару слов о себе в ти банке я 2 с по года До этого работал в таких компаниях как Яндекс infowatch Acronis использую преимущественно c+ Plus уже лет 20 иногда под кожи Наго также на питон являлся разработчиком и архитектором ядра поиска по персональным типам которым также относились операции по этой причине я вам сейчас расскажу как у нас это устроено в начале краткое содержание расскажу что у нас было что мы хотели достичь и почему пошли именно этим путём как мы развернули редис и как его используем понятно что всегда бывают проблемы и у нас они тоже были расскажу также и про них и что в итоге из этого всего получилось большинство рассматривают редис как хранилища или для какого-то не знаю крыша для прох операций но ре достаточно сильная база у неё есть много возможностей сегодня на докладе хороший обзор редиса но также у него есть поддержка плагинов о которых не то чтобы все знают в что тако поиск по операциям бан - это бан приложение все пользователи совершают набор оци Ирано и позно по эмм в мобильном банке есть строка поиска куда пользователь может кнуть что там набить и ожидает увидеть там свои операции какие-то садже сы ещё что-нибудь в целом такой же механизм работает и через web при том что в банке порядка 40 млн клиентов и из них в Пике 450.000 в онлайне и готовы искать прямо сейчас мы ожидали порядка крпс на подру свежих операций и 200 rps на поиск при том что хотелось ВС это уложить в 300 миллисекунд Итак что у нас было И чего мы хотели получить решение у нас было работало но с небольшими оговорками было РТО на железных машинах лак но там не было репликации И как следствие уход любой железной ноды приходи приводил к потере поиску одной той части пользователей индекс строился по горячим пользователям То есть это те которые залоги в течение там 102 минут мы держим этот кш и по нему производится поиск на тот момент было порядка 2 с пос за ме этим машинам и ротации индексов лежала на клиенте и мы видели достаточно большую запись на диск которая нас не очень устраивала казалось Почему вообще не сложить всё на диск и не заморачиваться будет там у нас ластик и будет там потихонечку по мере активности пользователе читать данные с диска искать но по грубым расм это порядка 2004 данных и это всё хранится на дисках при том что данные уже подгружаются в системе они есть и их можно запросить они ВС время добавляются новые и так как это поиск если по какой-то причине потерялся индекс это очень болезненно Значит по-любому нужно думать про репликацию резервные копии и тому подобное На таком об много ресурсов при том что мы знаем что в онлайн обычно бывает в пиках 1% пользователей и ищут из них не более 10% что же хотелось достичь понятно что бизнесу нужно чтобы поиск работал быстро энергично без сбоев желательно за ВС время и чтобы проблем никаких не было но на практике ВС равно Приходится вводить какие-то технические ограничения мы для себя поняли что мы точно будем хранить всё в памяти диск не использовать поддерживать выход целого ДЦ строя или любой ноды как минимум искать хотелось более чем за 6 месяцев Почему мы пошли именно этим путём редис как я уже говорил достаточно популярная база данных многие с ней в томм виде умеют работать у неё есть достаточно большой функционал И если что-то нам вдруг потребуется ЭКО Мы понимали что Мы это можем скорее всего сделать также редис уже был в проекте и на с умели его разворачивать что оказалось в целом уже удобным также у редиса есть такой плагин онный лежит на гитхабе написан и легко подключается к ресу поддерживает полно текст И не только и казалось что его достаточно для покрытия наших нужд поэтому мы планировали следующие тивные шаги чтобы посмотреть как Реди справляется с нашей нагрузкой для начала попробовать сгрузить в редис только сами операции то есть сырой Контент это то что нужно фронту для отображения А сам поиск оставить на эластик как и был потом попробовать Если всё идёт хорошо и ре справляется с нагрузкой потащили на Реди сч посмотреть всё ли нас устроит насколько будет Хороший ответ оценить с тем что было в эластика И если всё пойдёт хорошо искать если всё пойдёт хорошо то Используйте если нет попробуйте найти другое решение маленький спойлер что решение другое искать не пришлось а а Поднимите руки кто вообще слышал что такое плагин дич а кто его пробовал использовать практи едини в зале В целом плагин написан Достаточно давно активно развивается для примера я привёл восем мажорных версий и из них вытащил самый интересный можно в целом пойти почитать на гитхабе Он поддерживает и геопоиск и агрегаты и мультинское у нас был чтобы поиск по операциям Работал без запинок и успевал быстро искать мы развернули ном режиме это тот режим который сегодня рассказывали на докладе Он поддерживает шардирование из коробки но мы отключили репликацию полностью То есть у нас только мастер работает при том что чтобы ожидать отсутствие проблем при выходе мастера из строя мы выставляем опцию которая требует чтобы все мастера были присутствовали также мы отключили у себя весь п и пой при лишняя нагрузка которая кажется нам не особо нужна потому что мы будем реплицировать немножко другим путём и если её включить то чтобы редис поднялся о начнёт пытаться Вычитать эти пы и это будет достаточно долго на наших объёмах при этом лучше е поды им вго сжи горн что Поль будет искать нежели те которые были 10 минут назад и скорее всего которые уже не нужны как же мы развернулись у нас ц при том что в каждом разн свой стер Они полностью независимые друг про друга ничего не знают Ире оста общение идт на клиентской стороне То есть со стороны клиентов у нас ко Up который загружает свежие операции выбирает по юзеру В какой ДЦ сложить его данные одинц идёт как основной другой как резервный и на основе того же ID выбирается шар при том что на поиске Мы также идм в эти же самые ДЦ в эти же самые шарды но мы вынуждены дождаться ответа потому что в одном из шардов данных может быть может не быть вот Ало считает что он загрузил данные если хотя бы один из ответил что он получил эти данные на каждого пользователя строим свой Независимый индекс делаем Это по причине как минимум безопасности чтобы ни по какой ошибке в коде мы не показали пользователю чужих операций также это даёт достаточно гибкую политику вытеснения То есть те пользователи которые ещё остались в системе игом вся э политика лежит фактически на плечах Диса также это упрощает клиентский код то есть нам не нужно сильно думать про и там подобные штуки как выбирается ключ рования очевидно по ID чтобы разными потому что в противном случае если выйдут две ноды в разных DC мы потеряем существенную долю поиска То есть как минимум Ну зависи От количества нот Но в нашем случае это Ту же самую 1/6 мы хотели это минимизировать Поэтому в другом ДЦ юзеры равномерно размазывается по кластеру ключ родирования в редис выбирается тем Что указано в фигурных скобочках у нас это DC а решётка User ID Какие ещё ключи складываются по пользователям мы хотели минимизировать их количество и на каждого пользователя мы заводим фактически два ключа первый который называется у нас Ops там лежат сжатые ээ документы пользователей Ну это те по которым фронт отображает сами операции то есть мы в качестве используем документ ID в качестве val сами документа и также на каждый документ мы строим подготовленные поля для индексации Они лежат в отдельном ключе которы называется на примере упп и также по этому ключу лежит Doc ID и уже подготовленная строка что вообще такая подготовленная строка У нас вот есть документ Мы хотим искать по определённым его полям у нас определённый экстрактор достают эти поля э и подготавливают в виде строки один документ одна строка схема индексов жёстко прописана в коде и типа полей там же для того чтобы мы не хранили лишние данные в редисе у нас поля лежат в виде после друг за другом справа идт Его длина в виде НТА потом контент длина контент и так друг за другом это некая упрощённая версия того что относительно короткие и почти всё укладывается в один байт если по какой-то причине поля нету Там просто лежит нолик и начинается следующее поле для того чтобы искать мы готовим поисковый индекс то есть нам все эти документы нужно как-то подготовить для нужно создать набор документов префиксом того что сложит он в индекс и он это проиндексируется как сегодня говорили редис однопоточный но модули работают в отдельных потоках поэтому дич для индексации используют независимые роды но нам ВС равно нужно подготовить набор вот этих вот документов которые будут индексироваться этот процесс у нас называется материализация или потрошение индекса то есть мы берём вот этот ключик опп и раскладываем его на набор ключей OPI с документами пользователя по которым потом в будущем будет поиск Как идёт создание индекса это простейшая команда в называется Create обрабатывается модулем туда передаётся два Ну то есть ключ для названия индекса и префикс ключей по которым документы будут в этот индекс собираться также указывается язык без него результат не будет обрабатывать русский язык в начале мы пропускаем начальное сканирование потому что мы сперм индекс потом складываем туда документы задаём ttl и задаём схему которая описана у нас в коде В какой момент имеет вообще смысл строить индекс мы знаем что у нас ищут далеко не все пользователи но у нас есть достаточно чёткий сигнал в тот момент когда пользователь своей лапкой тапает по поисковой строке Мы точно понимаем что он начнёт что-то набивать и искать и это чёткий сигнал того что нам нужно начинать уже строить индекс также в этот момент мы можем запросить дополнительные операции по пользователю за больший период времени и наши метрики показывают что у нас есть порядка секунды до того как пользователи начнут реально искать и за этот момент мы успеваем и запросить данные и построить индекс Итак индекси мы не только на момент активации ки поиска но также в тот момент е по какой-то причине индекса не оказалось например изза какого-то сбоя или если мы видим что погрузились ещё дополнительные документы которые у нас не лежат в индексе какой-то прине эти докумен также доклады Ири чами по сотен документов Почему именно так Потому что однопоточный и как следствие в тот момент пока у нас работает скрипт все другие операции Они ждут пока он закончит свою работу а индексация для нас не то чтобы приоритетная Поль вву орелу свой поиск в данном случае надо выбрать то количество документов которое разумно Как выглядит вообще скрипт Это скрипт в начале первой половины слайда это мы фактически готовим входные ключи и аргументы в качестве ключа мы получаем подготовленный ключ пользователя и ключа в котором мы планируем развернуть все документы также получаем курсор дальше командой мы пробега по сотням ключей которые лежат по сум документам которые лежат в ключе и вот где три точки мы фактически распаковываем нашу строчку раскладываем их её в WS и в качестве ключа выставляем вре и также выставляем expire с Лем который нам передали пользователю возвращаем следующий курсор и количество документов которые Мы отработали чтобы оно ушло в метрике работать с этим скриптом идт Командо ша редис туда скрипта и набор аргументов то есть в данном случае эти два ключа подготовленные строки и префикс для потрох документов нолик - это показатель курсора что мы планируем начать скан с нуля сначала и обрабатываем в данном случае по 500 документов на выход мы получаем продолжение с которого нам нужно сканировать это курсор следующий и количество документов которые было реально обработано последующий вызов мы прокиды полученное ранее нами значение курсора и продолжаем индексацию с того не индексацию а доставать документы с того момента где мы остановились и вот в этом промежутке между тем как закончилась команда выполняться и мы послали следующую отработают все команды поиска которые попали в редис Таким образом у нас индексация не тормозит а поиск и сигнал к тому что все документы закончились нам в качестве следующего курсор возвращают нолик Это значит что больше документов нету И можно дальше не искать поиск идёт команд fch Это команда обрабатывается м туда также передаётся индекс операций пользователя также передаётся язык опции которые мы будем использовать вроде сортировка по дате в обратном порядке ограничения скоры и в данном примере у нас идёт М поиск по префиксу либо по не точному совпадению и также мы выставляем так избранных операций Это пример в целом rch поддерживает достаточно большую строку поиска там у него много возможностей кому интересно всегда можно прочитать документацию она достаточно подробная и говорящая Итак как мы всё это дело кали Я надеюсь это э достаточно очевидная вещь для каждого В этом зале но на всякий случай я её явно проговори а полагаю что все осознают что катиться сразу на всех это совсем правильно Поэтому мы выкатываю на долю процента пользователей И постепенно её поднимали когда видели что мы держим нагрузку ничего не отломать всё работает как положено также мы так как работаем с поиском это уникальная возможность сходить и в старый индекс и в новый параллельно при том что пользователь увидит всё что он видел раньше как работает по старому индексу А из Нового мы получим документы и Э можем взять div сравнить результаты и понять всё ли Нас устраивает всё ли идёт так и если видим Что проблем нету уже можно э переключать поиск на новый Ну и все эти шаги Понятно Что можно делать на долю процентов постепенно её повышая и так мы переписали тот пост которы у нас был на ластике переписали его с использованием чисто редиса всё в памяти оно всем устроила работала достойно Но в момен в моменте переходного случая я вам сейчас расскажу Первое - это достаточно понятная вещь что в какой-то момент Вдруг мы осознаём что мы хотим искать ещё по какому-то одному Полю А до этого такой возможности не было и так как я уже говорил у нас м схема зашита в код нам нужно с этим как-то уметь работать а Поля могут например даже удалиться или поменять свой порядок это небольшая проблема а чтобы вся эта схема работала мы э вводим дополнительный ключ э с подготовленными полями на примере он называется opx А он также по пользователю хранит данные только а поля в Data отличаются А тем что у них немножко другая схема то есть там какое-то новое Поле добавилось а при том что всё остальное остаётся без изменений и никак эту проблему даже не видят поэтому на момент подгрузки у нас старый грузит ключи в старом формате новый грузит ключи в новом формате но при этом как основной так резерв выбирается тот же самый И шарт точно также выбирается тотже самый на момент индексации для поиска включается специальный режим называется режим совместимости он знает что в этот момент в редисе может лежать два формата документов и схему обоих он знает поэтому во время индексации он уже смотрит есть такой ключ если есть он начинает также подготавливать докумен из этого ключа таким образом в худшем случае выполним двойную работу на индексации Но самое важное что поиск от этого вообще никак не пострадал он как ходил в тец и шарды и в тот индекс так и продолжает ходить но понятно что результат он должен дождаться от обоих чтобы его смр и отдать пользователю иде ключа позволяет легко выкати на прод дежурном и в случае чего у нас даже есть возможность откатиться но если мы не хотим потерять иди момент на поиск там у доли пользователей на десятки минут то есть на время жизни тель мы должны сперва откатить Ало старый выждать вот эти вот 10 минут ког буде домен в старом формате не существует и только после этого откатиться на предыдущий следующая проблема которую мы увидели это деградация удаления индексов проблема в том что не рассчитан на такое использование как мы его используем а именно то что сода достаточно болье количество ключей они постоянно создаются удалятся то есть классический пользователь создаст пять индексов и уже будет добавлять удалять документы их там менять он с этим хорошо работает но в нашем кейсе мы увидели что через какое-то время операции удаления идут всё дольше и дольше для этого мы немножко подпалила чтобы он Уда используется и раз в какое-то время мы э производим эту операцию стоит учитывать что мы работаем в шарди режиме и её нужно провести на каждом шардена э немножко а поддержать то чтобы по какой-то э причине эта операция не запустилась одновременно в двух разных ДЦ чтобы не повредить индекс пользователя который может сейчас искать следующая штука с которой мы столкнулись это подсчёт метрик понятно что у нас есть там набор индексов хочется понимать их объём и кажется простейший наивный подход написать очередной сри налу который будет запускаться регулярно также пробежит боом по всем индексам соберёт их также на всех шарда отработает со агрегирующие мы видим нагрузку на базу пытаемся её снизить тем что запускаться не всё время на каждом рде А по очереди на разных шарда но при этом мы начинаем ещё терять в точности Потому что если эта операция запускается раз в 30 секунд то на шести шарда она будет запускаться раз в три минуты и у нас данные будут достаточно редко обновляться хотя мы поняли что м точность - это не самая большая проблема для нас нам важно чтобы поиск работал а поэтому мы сделали следующий приём мы сделали кэш на стороне э бэнда а и а собираем его при запросе э в поиск или при индексации при том что э мы используем sck Session То есть каждый пользователь у нас стремится обработать в конкретном ДЦ на конкретном поде бэнда и таким образом у нас пользователь не размывается по всем подам как результат мы не увидели практически никакой нагрузки на базу ть вообще никакой у нас есть неточности при выходка Потому что тот кэш который хранится в поде он очевидно обнуляется на стартах но в течение минуты там быстро набирается результат и мы видим почти те же самые данные которые были но главное что есть метрики если что-то законите не то чтобы повредить там какой-то баланс мы это сразу увидим и данные нас эти устроили Итак что же получилось для нашего сценария мы написали поиск который работает в разы лучше чем то что у нас было держит сильно лучше нагрузку у нас порядка 15000 индексов пользователей в моменте все цифры по пользователям мы увидели поиск укладывается в 30 ку на 699 ИТ 200 миллисекунд на дем НТИ в качестве тфа выхода нодов в разны мы выбрали такое количество шортов чтобы было задето менее о про пользователей но так я рассказывал про Когда возможном будет неплохо использовать и редис и редис это в том случае если у вас достаточно много часто меняющихся данных или у вас идёт поиск по некому подмножество но при этом достаточно большой объём данных либо у вас высокие требования по скорости или ходить какие-то какой-то гибкий поиск сегодня одно завтра другое Если э есть экспертиза по э сям или плюсам можно в том числе и пачи плагин к э для какого-то лучшего функционала Спасибо за внимание готов ответить на ваш вопрос Спасибо огромное голосуйте за доклад это хорошая подсказка программному комитету на самом деле можно не просто голосовать но и оставлять свои фидбек что было хорошо что было плохо и кстати что было хорошо тоже потому что на самом деле этого-то обычно и не хватает переходите по QR коду Итак А теперь у нас время вопросов я вижу руки Можно пожалуйста сюда Если вы слушаете нас онлайн то тоже задавайте А вопросы и нам нужно будет выбрать два а лучших вопроса чтобы подарить подарки один Отт банк и второй от онтика Итак первый вопрос прошу Здравствуйте меня зовут Мария Я здесь Я здесь почти перед вами А вопрос Почему вы сделали три независимых кластера ди Search а не добавили ещё два кластера эластик он тоже довольно быстро отвечает десятки миллисекунд вы существенно сэкономили по диску или в чём были преимущества преимущество в том что мы Ну это у нас бы железные машины как минимум хотелось бы собирать похожую конфигурацию то есть нужно эти железные машины ждать подключать также мы видели большой рейд записи на диск и он непрерывный То есть у нас всё время эти операции вымываются индексы удаляются этого хотелось тоже избежать в-третьих что ну нагрузку 3к мы уже тянем с трудом Ну если честно не тянем вообще вот решение на редисе полностью решило эту проблему и вот эти вот шесть железных машинок достаточно большие машинки были дис Там шесть одноцепных нодов и они спокойно тянут нагрузку Спасибо огромное Следующий вопрос пожалуйста Привет Илья Спасибо за доклад Меня зовут Дима вам выдалась возможность сравнить эластик и Ди с точки зрения качества поиска Ну наверное э удалось же вот э Какие отличия Нашлись ээ Соответственно что сделали там согласились или пофиксили вот и как вообще вы оцениваете качество поиска Каковы штрафы за неправильный результат неполный результат э если есть угу ну Если честно мы не увидели супер серьёзных отличий и практический результат был очень похож У нас есть ещё дополнительны вке функционал который отвечает за транслитерацию за отпечатки поэтому у нас фактически ВС было уже готово для каких-то особых кейсов это будет более заметно Спасибо огромное так прошу пожалуйста Следующий вопрос Здравствуйте спасибо за доклад смотрите Я правильно понял что у вас в ластике хранились все данные там 200-400 теб в редисе вы храните какой-то конкретный процент пользователей с их операциями правильно Нет не сос нет не правильно у нас в ластике также хранились все только горячи данные и мы рассматривали вариант перейти на то что ранить всё или на редис мы да я не понял этот момент с объёмом данных 200-400 теб это тогда к чему относилось Это к тому что Казалось бы мы могли всё условно сложить на диск на самом деле мы могли сложить на диск вопрос цены поддерживать ши с такими объёмами дисков они ну сильно дороже чем поднять лёгкие Наре понятно это весь объём данных который у вас есть видимо по операциям но в ластике У вас был точно такой же подход Вы тоже хранили определённый объём операций точно так же писали То есть вы логику не поменяли вы поменяли именно хранилище Да логику не поменяли спасибо супер спасибо большое так перед тем как передать следующему участнику слово я зачитаю вопрос чата Илья Спасибо за доклад Подскажи как часто обв проди Каждый раз когда Поль обращается к поиску или реже в тот момент когда пользователь ищет если индекса не было он строится заново Мы в момент поиска проверяем ели все документы в индексе То есть если по какой-то причине пользователь соверши ОЮ и достраиваем индекс мы его не перестраиваем мы просто добавляем фактически один документ Спасибо Следующий вопрос пожалуйста Да Илья Спасибо за доклад очень интересно хотел тоже про индексы немножко спросить про удаление А зачем в принципе вы реализовали удаление оценивали как-то если вот не удалять в принципе индексы а просто его пристраивать если допустим тот же самый пользователь ищет повторно и просто актуальны индекс строить объёмы То есть у нас данные долны теснятся как только прошло там 10-20 минут не активности пользователя данные вымываются нам не имеет смысла хранить ни документы ни ин от пользователя ничего но у нас же процент активных пользователей он в целом не меняется Это одни и те же люди не процент не меняется А вот люди разные Ну то есть вы исследовали этот момент да смотрели Конечно а как реализовали вот эту доработку что там конкретно сделали ТЛ какой-то для индекса просто нет там у него есть механизм самого удаления индекса по Проблема в том что когда мы этих индексов много содам удаляем А мы их создаём то есть в моменте у нас там 15000 индексов то Ну это на кластере соответственно 23 на ноде у нас начинает деградировать поиск то есть там внутри не очень оптимальные структуры были и мы пошли простым путём просто Флам все индексы но уреди нет такой возможности то есть есть шну вообще все данные что не хотелось нас дан грузили а мы просто немножко подпалили чтобы флаш только индексы Ну то есть просто по префиксу по сути их нашли эти ключи Да нет мы вообще флаш все индексы которые есть на данном рде Ага понял спасибо то есть он удаляет служебное структуры которые хранят Ну инфу О индексах спасибо огромное так если у нас ещё вопросы пожалуйста можно сюда микрофон пожалуйста раз раз меня зовут Сергей Маслов компания X5 вопрос лицензирование редис сейчас он стал коммерческим лицензия поменялась сильно что с этим у вас лицензия - это отдельная тема Несмотря что о поменялось сейчас уже есть пару фоков ин и больше волнует например патчи безопасности всё остальное не особо волнует функционал Понятно можно пот там как-то безопасность в основном это отдель тема которая ну в плане лицензии решается юридической точки зрения в плане безопасности У нас есть отдел безопасности который такие штуки может мониторить ну просто я про то что нельзя будет зать нечем Пать просто Либо формы на самом деле можем продолжить уже в дискуссионной зоне Спасибо огромное е у на е какието новы Во вот пожалуйста руку вижу вот прямо перед вами Привет спасибо чуть-чуть подброшу Вот у нас 200 миллисекунд на построение 30 миллисекунд на поиск 230 миллисекунд на операцию А зачем вообще нам внешний поисковый движок с рованием Когда мы можем запрос от пользователя обработать отдать и забыть так е Раз не помы можем вопрос то есть мы то есть ну схема с редисом она Понятно У нас есть движок где мы индекс строим каширу ВН 15 минут и им пользуемся для последующих поисков поисков Ну сколько там 1 2 10 Ну сколько-то будет но каждый из них занимает 230 миллисекунд Э не совсем так э эти данные вопервых нужно загрузить подкачать заранее И для этого мы сделали небольшой Трук но пе а его к слову сказать не было на изначальном решении но мы также попробовали Будет ли работать ластик и хватит лиму по скорости Вот но там были не очень красивые цифры и 200 мсн де денти есть ещё пользователя и для них ну это много Ну и при том что это 200 м секунд на построение всего индекса понятно что он не непрерывно идт а останавливается для того чтобы поиск работал Спасибо огромное И давайте последний вопрос прошу Спасибо за доклад Меня зовут Михаил компания МТС А вот хотел задать такой вопрос Какой средний объём индекса на пользователя То есть вы данные об операциях там полтора за 2 года храните Ну позволяете искать по ним точно по дефолту загружаем меся на поиск при том что пользователь в интерфейсе может выбрать галочку искать за весь период и поэтому все данные грузятся тут зависит от пользователя есть пользователь которые активно пользуются есть не очень в среднем там ну не знаю десятки мегабайт Может там плюс-минус я и такой вопрос ещё Почему эти данные нельзя дать на фронт и там как-то их Каширова хранить какое-то время Ну это же большие объёмы куда на фронт то есть и Кроме того Н он не поддерживает того полноте вобще того функционала который поддерживает Ну что спасибо огромное А теперь самая сложная часть надо выбрать Два лучших вопроса Итак первый подарок от тба кому дарим какой вопрос так мне понравился вопрос нано Андрея про то как мы Андрей поднимите руку пожалуйста Благодарю и второю подарок подарок от онтика та самая кастомизированная матрёшка нать которой собирать можно уже сегодня до этого такой возможности не было Давайте отдадим её Михаилу потому что Михаил поднимите руку пожалуйста вот всё верно Да су спасибо оно Спасибо огромное за такое классное выступление интересные ответы А спасибо поблагодарим спикера"
}