{
  "video_id": "bLBbzdKCheM",
  "channel": "HighLoadChannel",
  "title": "Пайплайны записи своими руками: думали — велосипед, оказалось — паттерны / Роман Щербаков (Т-Банк)",
  "views": 635,
  "duration": 3016,
  "published": "2025-01-17T02:22:47-08:00",
  "text": "Здорово народ очень рад вас всех видеть прям что-то много народо собралось Давайте знакомиться Меня зовут Щербаков роман Я ведущий разработчик в Sage это такая платформа мониторинга в это банке и мы работаем с петабайт телеметрии мы ребята простые есть задача Мы её решаем берём следующую но особое внимание уделяем постмортем и постоянно Сегодня я расскажу о том как мы строим нагруженные пайплайн записи надёжные пайплайн записи и о том э как было бы здорово ретроспективно точнее было бы здорово заранее знать что нам потребуется А так вот ретроспективно мы посмотрели и оказалось что это просто одни сплошные стандартные паттерны готовы друзья погнали погнали ещё раз отлично погнали третий раз короче слайды не переключаются супер недавно читал Надеюсь в зале есть эшники которые тоже читали Ну или вообще кто эксплуатирует свои системы самостоятельно и там была отличная цитата Бена трейнера слосса о том Ну в моём вольном переводе она означает звучит примерно так главная характеристика продукта Это Насть потому что система бесполезна если ей нельзя пользова Мне кажется это надо прямо реквизитам к архитектуре каждой системы добавлять Ну и после этого только не функциональные требования начинает собирать функциональные тоже так давайте разберёмся Что такое Надёжность я искал кучу разных определений они все разные непонятные предлагаю вот здесь сейчас договориться настроиться на одну волну и поднимать под надёжностью следующее это такая степень готовности Надёжность - это то насколько пользователи готовы доверять наше продукту свои задачи соответственно видами надёжности являются доступность и устойчивость это такая штука которая позволяет быть системе доступной по требованию к эксплуатации а также соответствовать заявленным характеристикам во время этой эксплуатации стоит внимание обратить ещё на отказы устойчивости такая способная система сохранять свою Надёжность во время этой эксплуатации Ну там если какие-то частичные компоненты отказывают чтобы продолжать работать с чем мы имеем дело в Sage напомню платформа в т банке и для таких систем основой являются данные телеметрии вот мы как раз процеси джентльменский набор логи метрики трейс И кстати для пайплайн записи не столько важно сколько эти данные занимают на дисках принципиальное значение имеет размер потока поэтому весь слайд в цифрах за одну секунду вот например логов мы процеси примерно 3 ГБ в секунду это где-то 3 млн ивентов метрики это 450 МБ пожа данных Ну там если разжать будет больше это 12 мл точек и рейсов это 500 Мб или 2 мл снов Как видите друзья довольно много как же мы справляемся с такой нагрузкой и как выглядит архитектура сжа текущая начнём с логов приложу либо сами в нас пушат данные через коллекторы либо какие-нибудь файл биты собирают логи заливают нам в каку Да спе про пласти для текстового поиска в Метрика Либо мы собираем данные с приложу метрики либо в нас пушат по протоколу рают всякие ВМ агенты И прометеус после этого это всё попадает в кафку потом специальный уже Риво эти данные процеси и складывают Викторию Обратите внимание на специальную стрелочку мимо Кафки Я сегодня обязательно про неё расскажу трейс приложу пут трейс Open колектор всё это тоже складывается в каку потом уже это всё процессе раскладывает по куче разных кликхаус Как видите друзья очень много общего этих пайплайн архитектура Очень удобная штука которая позволяет разделять логические логические слои в приложении и физические тиры да то есть деплоймент отделить от логики и таким образом очень гибко масштабировать систему повышать отказ устойчивость все всего палана в целом во время эксплуатации ре огромным количеством проблем и для каждой нашли решение я вам обещаю в конце доклада предоставить все материалы для углубленного изучения о которых я сегодня буду рассказывать начнём с первой проблемы - это масштабирование системы у нас много дата-центров у нас много клиентов под клиентами я подразумеваю команды которые пишут свои приложения соответственно телеметрия с этих приложений это вот то что для нас является клиентами у Этих клиентов может быть разные А у наших компонентов может быть разная производительность какая-то пропуская способность и так далее Как же это всё вместе объединить и порешать в первую очередь надо вести понятие Data Gravity очень классная история придумали её где-то 10-15 лет назад она говорит что большие данные похожие на большую массу и притягивают к себе другие данные приложения какие-то сервисы Вот и в контексте дата-центров Это означает что там где данные создались Там они должны и оставаться Да их не надо между дата-центра как-то двигать экономить на этом косты большие в контексте sji Это означает что приложение которое запущено в конкретном дата-центре должно пушить ну или там мы должны собирать с него телеметрию внутри этого дата-центра сжм После этого мы должны хранить эти данные внутри того же самого дата-центра после чего эти данные будут охлаждаться внутри этого дата-центра и в конце концов удаляться просто теншен то есть мы никуда ничего не двигаем это радикально повышает Надёжность системы и доступность данных также эта штука позволяет нам применять deployment sts pattern внутри дата-центров то есть грубо говоря у нас нет какого-то такого большого саджа который Один на всех не так всё это работает пайплайн записи они локализованы внутри дата-центров То есть каждый дата-центр - это прямо отдельный свой пайплайн и масштабируемый именно такими пайплайн запускаем новый дата-центр поднимаем отдельный пайплайн нужно каких-то клиентов отделить друг от друга какие-нибудь особые им там требования Ну для них выполнить построим Внутри дата-центра тоже отдельный па и эта штука Офигенно работает когда нужно посчитать ка то есть грубо говоря человек приходит говорит нам нужно там отливать вас не знаю 100 мб логов мы такие посмотрели Ага Капа есть заезжаем Если нет потому что мы знаем сколько у нас лазит мы говорим пора строить новый па Ну соответственно там уже другие совершенно работы ведутся сду с при чём в нашем случае это как бы такая очень неприятная история потому что у нас большое число писателей и у этих писателей совершенно разные профили нагрузки которые нам не подконтрольны то есть люди могут совершенно по-разному писать метрики логи и трейс и с этим очень трудно бороться также на нас очень сильно влияют массовые отказы например в каком-нибудь дата-центре каком-нибудь Луч питания отключился и соответственно куча приложений которые связаны с с этой частью инфраструктуры начинают там писать больше ошибок там ещё что-то и соответственно у нас какие-то там спайки начинают в системе появляться Также важно понимать что Sage занимает не больше 10% инфраструктуры Т банка А это означает что большой т банк пытается завалить телеметрией маленький сейдж что мы делаем в первую очередь изучаем поток входящий да то есть вот для примера поток логов это именно входящий поток и если посмотреть вот на размах этих колебаний то получается что это примерно 50% от того Рей которы Мы в среднем процессе внутри сежа это огромная разница что можно было бы сделать наверное можно было бы клиентов разделить на какие-то группы и таким образом как-то выровнить рейд но есть схема получше есть такой паттерн называется qbase level pattern грубо говоря у нас есть какой-то входящий рейд мы добавляем посередине буфер который накапливает себе данные и мы уже этот буфер вычитывать с каким-то удобным для нас рейм в нашей архитектуре эту задачу выполняет кавка У нас под каж у клиента есть отдельные топики Ну то есть очереди и мы соответственно Таким образом сглаживая разные профили и читаем с той скоростью с Котовой с которой готовы принять эти данные потому что мы используем собственно говоря и кавка эту штуку нам предоставляет л модель пул модель интересна тем что Неважно как как у тебя данные залетают важно как ты эти данные читаешь а самое слабое место пайплайн в записи - это хранилище поэтому наша глобальная цель - это защитить хранилище и всё направлено на в общем-то на это а какой бы не был надж Какие бы не были отдельно надёжные компоненты и даже допустим Q leveling паттен очень полезные всё равно нужно делать свои компоненты тоже очень надёжными потому что там возникает тоже куча своих проблем например консьюмер которые читают сообщения свки могут там частично отказывать очереди могут не успевать обрабатываться потому что там как изменился профиль у клиента или они просто разные вот также у клиентов вот как я сказал разный поток и это может прямо в десятки раз отличаться а то и больше что нам делать мы используем competing consumers pattern то есть что это означает у нас есть очередь мы к ней подключаем большой набор коню и каждый кон сюр имеет какой-то запас производительности поэтому мы не боимся там частичного отказа коню и будем продолжать обрабатывать данные даже если там был какой-то сбой и там часть инфраструктура пострадала А клиенты при этом даже не заметят что у нас внутри что-то происходит Исходя из этого паттерна мы построили вот эти вот воркеры о которых я говорил следующим образом то есть у нас на каждом инстанс есть отдельный какой-то воркер который состоит из множества Джов каждый Джоб - это каждый обс каждый Джоб обслуживает отдельного клиента и состоит из трёх слоёв это консьюмер который читает обрабатывает данные потом идёт диспетчер который решает Куда эти данные надо записать и C который занимается непосредственной записью данных в хранилище Помните я говорил что логов 3 млн ивентов в секунду примерно летит вот если в лоб решить задачу то получится 3 млн запросов БД ни одной БД это не понравится Поэтому нужно что-то придумывать своё а также бывают ситуации когда хранилище просто там разработчики хранилища рекомендуют снижать рейд на запись потому что там деградация большая такая есть рекомендация у Хауса что для этого делать па процесинг отличная техника то есть грубо говоря есть очередь есть комер он набирает вычитывает сообщения из очереди там по какому Трехо количество сообщений размер общей буфера там время на набор этого буфера и потом уже целиком отправляет этот буфер в хранилище причём там в ластике например есть специальный API для этого там бал API там в Хауса по-моему рекомендация по 100.000 строк писать за раз вот а стари пробле Нет там она в обратную сторону работает потому что мы когда с таге метрики собираем то они уже пачками нам прилетают и чаще приходится наоборот эти Бачи поменьше делать чтобы не 100 мб сразу БД записывать как только мы доходим до записи рано или поздно возникает проблема дублей от этого никуда не денешься и вот самый простой способ этого добиться Прочитать сообщение записать его в хранилище и не закоммитить Осе Прим миллион причин почему можем это не сделать какой-то любой отказ Может это спровоцировать Хотя события эти не очень частые но с этим всё равно нужно бороться что мы делаем точнее какие варианты есть первый вариант это как бы по классике это поднять поднять отделение хранилище там сохранять эти оффсеты и проверять что мы эти уже данные просили но я напоминаю про миллионы запросов значит эти миллионы запрос прилетят в это хранилище нам Такой вариант не подходит поэтому используем второй вариант мы обогащаем данные мто идентификатором в случае логов у спано такой идентификатор там у рейсов он уже по умолчанию есть а для Трик идентификатор наступает вся Сирия и мы доверяем дупликации самой то есть допустим у нас в ластике так настроены что там уникальность поддерживается внутри шардов Виктория по умолчанию сама из коробки поддерживает дупликации отложенную правда на записи то есть Она постепенно работает и вс лишнее одинаковое удается также есть компенсационные действия при поиске Вот например в рейсинге мы если получаем какие-то редкие дубли то тогда мы просто их выкидываем из общего ответа и соответственно клиенты не замечают какие-то маленькие проблемы повторной записи рано или поздно с ростом системы все сталкиваются с проблемой большого количества данных причём Ну данные могут не влазить в сервер Ну классическая история кластер ой BD может не иметь кластерную версию так долго было у Виктории ри наме или кластерная версия Может там быть неудобной для обслуживания или слишком большим кластер становится или он уже по своим характеристикам просто не вмещает тот объём данных который нужно в ём хранить если у вас один кластер то прям Это серьёзная проблема потому что отказ одного кластера - это вообще полная потеря данных также я добавил сюда особые требования к хранению там безопасности разных литов могут быть такие Туре знают шардирование отличная техника и обычно разработчики доверяют шардирование самой БД Ну у неё есть отлич у многих б есть отличные механизмы встроенные в нашем случае как я сказал мы не всегда используем кластерные версии Точнее они не всегда есть и нам доступны или нам подходит то мы используем гибридную схему когда то есть мы часть данных шарди внутри БД если есть такая возможность Это для оптимизации работы хранилища а также мы шарди на клиенте и сами решаем как в какую ноду или какой целый кластер данные записать таким образом Это позволяет горизонтально масштабировать хранилище Да просто неимоверных размеров у нас только логов под 7 пиб лежит таким образом также эта штука позволяет сделать первый шаг для мульти разделить клиентов по разным хранилищам следующая проблема связанная с данными это их доступность и там тоже куча всего может происходить отказ оборудования вывод оборудования обслуживание какие-нибудь там батарейки плашки памяти надо поменять и не очень очевидное но тоже связанное с доступностью данных - это охлаждение данных потому что мы не всё можем держать в Горячем хранилище нужно строить какие-то дата тиры где данные будут потихонечку остывать и там но дольше храниться при этом что можно сделать мы используем соответственно даты репликацию данных при этом как бы тоже гибридная схема работает обязательно внутри хранилища если есть такая возможность мы используем репликацию чтобы Надёжность самого кластера там поднять но при этом нам Никто не запрещает и в общем-то это нормальная штука там внутри БД тоже код Значит мы тоже можем написать код сделать репликацию на стороне клиента например Так мы сделали долгосрочное хранение для метрик То есть у нас прям два типа кластеров краткосрочное хранение долгосрочное хранение и мы льём туда одинаковый поток но при этом под этими кластерами разное железо у них разный профиль нагрузки там поисковый получается и соответственно разные другие разные характеристики самих кластеров эта штука прямо прекрасно работает и я могу сказать что не сомневайтесь репликация на клиенте это Окей если хочется больше узнать о том как мы работаем с данными Как выглядят наше хранилище изнутри как мы конфигурируется время е по-моему уже выгоняли просто со сцены то есть там прямо глубокая история о том как всё работает очень рекомендую вот мы подобрались к самой такой интересной части это запись непосредственная запись данных в хранилище и тут тоже свои проблемы нас поджидают один отказ может убить всю систему вообще надо признать что отказы - это норма к этому надо Быть готовым с этим надо спокойно жить и по этому поводу вообще никак не переживать второе хочется управлять влиянием отказов на систему и Быть готовым к этим нештатных ситуация а также хочется иметь возможность экстренного изменения состояния продакшена наверное любой срш к в зале скажет что рано или поздно надо где-то что-то руками стопа резко и это должна быть такая возможность пайплайн не должен от этого разваливаться в судостроении придумали такую технику добавлять перегородки на дно корабля для того чтобы одна маленькая пробоина не подола весь огромный корабль Не перепони он там водой в программирование это называется и означает примерно следующее Мы выбираем какой-то ресурс в системе в нашем случае это например там нода или кластер хранилища и добавляется Con который этот ресурс защищает эти миры очень чуткие но по сути конт костра могу сказать что вот такой conc liit работает в разы быстрее чем любой лимитер потому что у них совершенно разное получается назначение мы не й контролируем а прямо текущее состояние какое-нибудь изменение респонс тайма мгновенно забивает concurrency лимите И запись останавливается это прям супер полезная штука Как только мы отправили запрос рано или поздно придётся ответ ошибкой но они на самом деле постоянно приходят это вообще норма при тоже вагон целый это может быть проблема с сетью может быть сервер сломан может быть перегружен какой-то нагрузки может БД на сервере сломаться В общем миллион причин разбираться в общем иногда даже не особо Интересно какие они есть и все знают что хорошая стратегия потравить отправить ещё один запрос и в целом Я согласен но есть пара деталей де правиль все знат экспоненциальная задерж е добавить жи чтобы аккуратненько размазывать Раи чуваки из провели исследование оказалось что вот такая стратегия собирает ВС равно спайки и для крупных систем это становится критическим потому что вот Представьте вас БД очухалась вы начали Туда писать прилетает опять такой Спайк и опять заваливает БД опять сервис не работает проблема что делать Мы тоже поис следовали ситуации в ках случаях это проходит на самом деле есть два кейса первый всё хорошо но что-то моргну Ну моргнула и моргнула можно травить безопасно ничего страшного не произойдёт а вторая ситуация когда БД всё отказывает она либо там сильно деградирует либо просто её больше нет там выключилось там я не знаю сервера сгорели и так далее и можно соответственно не трать вообще говоря ретрай очень опасная штука они повышают то самое над и Именно они убивают е поэтому за этим Надо очень чётко следить В общем у нас рецепт такой мы ретра но один раз мы ретра без всяких задержек в надежде на то что это был просто какое-то мгновение что-то моргну а также у нас для в том числе для оптимизации инфраструктуры но чтобы меньше было компонент пайплайн балансе прямо в наш код Поэтому если кластер такую штуку поддерживает то мы просто меняем ноду и отправляем в следующую Ну допустим одна но сдохла мы отправляем будет Успех это пря радикально увеличивает количество успешной записи успешных записей Что делать если много ошибок напомню наши воркеры это множество Джов независимых под каждого клиента и там получается Какая история параллельно эти ды отправляют реквест и соотвественно один все они выбрали например нищего вго рего ито зад остановиться И как-то это отловить для этого используется C Breaker То есть это такая штука ставится между квестом добавляется между квестом и хранилищем в коде и он контролирует количество параллельно происходящих ошибок соответственно если какой-то трешхолд переполняется то мы просто его размыкают ответ сечас записать не полу ите другой способ следущая проблема друзья - это тайм-ауты могу сказать что таймаут вообще вот повсюду есть это как во фреймворка есть тайм-ауты в библиотеках есть тайм-ауты в приложениях есть тайм-ауты мы сами их постоянно добавляем эти флажки с таймаута и у них множество имён это какие-то деле это какие-нибудь Макс пол интервал это какой-нибудь просто интервал это какой-нибудь duration миллион имён и всё Это тайм-ауты в нашем случае тайм-ауты собирают в такую вот воронку её можно назвать бюджетом времени на исполнение и в общем что она из чего Она состоит мы читаем сообщени с Кафки у Кафки есть такой обязательный у консьюмер параметр Макс пол интервал то есть кавка требует от нас раз в какое-то время скачать сообщения из Кафки Иначе она подумает что мы померли и отключит нас поэтому это вот граница сверху А все следующие шаги например там ожидание свободного слота в concurrency лимите Или например задержка между трая Или например там ожидание максимальное Время ожидания ответа от БД там хочется же какой-нибудь 30 секунд поставить Представьте взяли 30 секунд просто на ожидани от общего процессинга съели Вот и даже время процессинга внутри самой БД тоже е этот бюджет поэтому а рекомендация очень простая когда мы пишем код и хотим добавить новую задержку новый тайм-аут ещё что-то надо внимательно согласовать его со всеми стайные остальными таймаута в пайплайн чтобы не вылезти за бюджет и чтобы нам хватило время на процессинг очень важная штука я рассказал о множестве полезных паттернов которые позволяют решать множество проблем но внимательный слушатель заметил что всегда была ситуация когда что-то пошло не так и у нас не получилось Там травить кончилось время или там concurrency limit там сказал что сарн нет слотов В общем что делать-то нужен План Б для этого есть такой специальный механизм называется fullback то есть переводится как резервный план резервный какой-то там что-то резервное процесс а и pipeline в записи в общем-то Стратегии тоже не очень много что можно сделать Ну можно удалить данные Я думаю ни один пользователь который в нас шлёт телеметрию не захочет чтобы мы их метрики или трейс удаляли как бы они же им нужны вторая второе решение неплохое кстати остановиться если какая-то ошибка есть Ну то есть получили ошибки остановились ничего не пишем база очухалась начали дальше в неё писать Ну вроде хорошо есть юнс если надолго остановиться Помните у нас там кавка буферы собирает в конце конв не место кончится и это тоже стратегия нам не очень подходит Что делать Можно ещё можно попробовать не блокирующие тра Ну то есть это какая-то отложенная работа а ещё есть такая штука как Но это типа перекладывать куда-нибудь в другое ме э во чтобы делать почему они там оказались в общем-то мы используем последние два Давайте смотреть как это всё вместе работает то есть есть какая-то в кафке Мы оттуда кон сюра вычитывает Ну там битые не битые соответствуют формату Там и так далее после этого если они не соответствуют складываем их в rq и если они хорошие то пробуем записать их в базу если по какой-то причине в базу Там записать не получилось Ну там я не знаю ето мы эти данные перекладываем в специальную для отложенной записи Ну то есть не получилось сразу записать попробуем в работать Позже дальше отдельным уже под процессом Мы из данные вычитывает уже совсем другие политики работают если по какой-то причине м особые условия изменились там версия BD поменялась какая-то несовместимость или ещё что-то в общем баг тогда мы эти данные складываем тоже в rq специальную Которую потом руками Разбираем и что-то фиксим потому что другой причины здесь быть не может стоит добавить что у вот этих кон сюмеййе коню потому что помните убивает если мы хранили данные в ретро очереди то потом взяли и начали параллельно писать то получится 2x нагрузки это очень много БД завалиться соответственно надо прямо жёстко их зажимать эти коню ничего что история подольше от качается самое главное что свежая быстрее подпадает это же телеметрия а также каждый rq добавляет и вот это ror Q добавляет копию данных то есть грубо говоря вот у вас в Source Q лежит сообщение плюс реплика Да потом мы когда переложили в rq это опять ещё одна копия сообщений ещё одна реплика eror - это ещё одно сообщение ещё одна реплика Надо чётко считать капасити и понимать сколько мы в таком режиме можем продержаться пока на кафке не кончится место она просто не начнёт дропать данные по ретеншн особая история у меня есть для вас про метрики про ту самую стрелочку изначально пайплайн создавался как замена прометеус чисто под скрейпинг то есть мы что-то читали с таргетом потом складывали в кафку процеси кером записывали в БД у на сначала даже Виктории были в Синг версиях даже не кластерные и вс было хорошо Пока поток начал расти начали Виктории отказывать чаще нам это не нравилось начали думать что с этим делать в это же время примерно начали заезжать у нас там такие крупные клиенты огромные кластеры ку Бернеса и они уже ехали по протоколу В общем начали думать что с этим делать я техлит Командо честно говоря это вот история про год моей жиз враз про по которому данные уже начали на тот момент поступать мы прочитали что в спеке протокола есть рекомендация о том чтобы на стороне писателей были специальные буферы для того чтобы переживать кратковременные отказы Мы подумали круто хорошие рекомендация проверили Кто на чаще всего пишет Это прометеус агенты по этому протоколу проверили их реализацию оказалось у них там есть действительно внутрен буже смто проце ничего не напоминает кавка воркеры буферы воркеры у них есть тоже самое как и у нас закрытая модель нагрузки прекрасно подумали мы и пустили этот поток напрямую в общем это всё хорошо работало до первого крупного отказа на Виктории и мы в этот момент накопили большой лак Ну и как вы понимаете пока лак не отча свежая телеметрия доступно не будет В общем Почему Потому Буе оказались маленькие то есть они готовы принимать и держать какой-то объём метрик но допустим там этого хватает на несколько минут А если клиент большой а буферы недостаточно большие для такого размера то они вообще мгновенно там переполняют какие-то секунды А также есть вторая проблема которая для нас была честно говоря немножко неожиданностью с одной стороны с другой стороны Мы не ожидали такой профиль скорее они резко отдают данные То есть как только база восстанавливается запись начинает идти клиенты нам Илу ом входя нам это проб боремся с ней что мы сделали подумали и сделали так весь основной поток Мы также пытаемся писать напрямую таким образом с минимальными задержками свежая телеметрия попадает в и доступна для поиска всем же хочется видеть свежие дашборды свежие арты там на свежих данных и так Дале подкрутили тайм-ауты зажали и если что-то стреляет На Виктории какая-то деградация Мы очень чутко за этим следим и сразу начинаем ехать фулбек механизмом и скидывать данные для отложенной записи на самом деле постоянно есть какой-то маленький фон фулка то есть грубо говоря там клиент пишет какими-то пиками мы это отлавливает запись занимает какие-то там десятки сотни миллисекунд то есть там Небольшая разница но когда градация посильнее это прямо радикально повышает Надёжность пайплайн в общем смотрите наверняка каждый из вас помнит историю когда сосед по лестничной клетке купил себе новый перфоратор и сообщает нам через стенку о своей покупке вот для нас тоже такие есть шумные соседи когда мы делаем системы которые эти клиенты могут быть шумными То есть даже хороший пайплайн можно сломать плохими данными Я предлагаю схему из четырёх шагов чтобы с этим бороться первое надо уметь мониторить поток клиентов Независимо друг от друга надо прямо видеть кто сколько льёт и что у него поменялось второе надо уметь изолировать клиенты друг от друга и таким образом можно будет свозить токсичный трафик например на отдельный кластеры обязательно надо добавлять какой-то механизм там квотирования троттлинга там миров и так далее в разные части пайплайн которые будут контролировать поток и как-то поджимать клиентов Независимо Ну и последнее самое неприятно но это необходимость для выживания систем нужно иметь рубильник для того чтобы кого-то чей-то процесс просто остановить лучше потерять данные одного клиента чем потерять весь пайплайн К сожалению это такая жизнь вот мы добрались до финала до развязки поэтому предлагаю пройтись по всему материалу закрепить его и разобрать два сценария когда всё хорошо И когда всё плохо начнём когда с того когда всё хорошо мы берём Из основной очереди читаем данные консмед пытается процессор набрать нам этот батч после этого диспетчер пытается определить куда же нам надо записать эти данные например там по какой-нибудь идентификатору клиента после этого bhe patter то есть conc сло для запи после этого проверяем кончили они у нас есть баже всё хорошо замкнут проходит Тай ещ не стрельнул то есть общее время не закончилось Ура друзья мы справились Мы записали данные второй кейс не такой прикольный потому что базе поплохело Вот и у неё по-другому работае для записи А дальше начинает отстреливать по одному на самом деле либо у нас кончатся слоты в conc это произойдёт практически мгновенно за какие-то миллисекунды либо у нас кончатся попытки 100% они кончатся сколько это их не дела Если база померла если оно кончится се Брекер разом когда поймает много ошибок и соответственно у нас может закончится просто временно выполнение пока мы все эти машинерии делали во всех этих случаях мы идём нашим фбк механизмом складываем данные в и потом уже попозже их просим как сможем так друзья как обещал я собрал все материалы и опубликовал их в нашем ко Это ссылка на Telegram переходите Давайте обсуждать паттерны там и может быть у вас есть какой-то интересный опыт Ну и в общем готовы там отвечать на всякие разные вопросы по Я подожду материалы уже все опубликованы в принципе на этом всё друзья я ещё подожду тогда смотри как Спасибо огромное это было замечательно голосуйте за доклад если нужно открутить слайд обратно Говорите вдруг кто не успел сфотографировать замечательный на Вот и сейчас время вопросов поднимайте руки задавайте вопросы так вот здесь вопрос Там вопрос тут вопрос Здравствуйте скажите вот новая телеметрия Она обычно имеет большее значение чем устаревшая и в случае когда у вас происходит отказ наполняются эти очереди и новые данные задерживаются дольше и не попадают в хранилище вы с этим что-то делаете Да как раз вот на па рассказывал о вот этом прямом маршруте и отложенном маршруте давайте я даже Отмотай покажу там такая картинка хорошая Во вот смотрите Внизу там Широкая Стрелка которая сразу Викторию пишет это как раз свежая телеметрия если по какой-то причине что-то идёт не так мы скидываем всё в кафку Но как Только всё восстанавливается ну или там приемлемый рейд появляется у БД то тогда свежи телеметрия сразу начинает поступать хранилище таким образом история где-то в хвосте остаётся А мы со свежей телеметрией идём в све светлое будущее наблюдаем как всё здорово крутится на продакшене срш неки выдыхают алёрты перестают стрелять и все довольны Так здесь был вопрос Спасибо за доклад очень интересно было Да очень много паттернов надёжности Да у меня вот вопрос Вот вы так много предусмотрели надёжности А что будет если кавка откажет Да если начнут очереди переполняли расти это вы как-то предусматривали в архитектуре или такому Не бывать вон стоит Мой коллега Макс Он знает как часто отстреливает кавка Вот Но она конечно довольно надёжная штука действительно кавка деградирует редко тут есть тоже стратегия но вот смотрите вот с метриками вообще всё классно мы без Кафки можем очень долго выживать она у нас там практически не используется в нормальной ситуации там какой-то там 99 читае что-то там процентов иногда через неё летит соответственно это вообще не страшно в случае например логов это более серьёзная проблема но слогами надо тоже понимать что в нас пишут всякие файл биты там скорее всего какие-то там у них тоже очереди на своей стороне они довольно долго могут выживать но опять же зависит от профиля приложения какие-то клиенты выживают дольше и не замечают вообще отказов какие-то могут немножко потерять то есть мы закладываем что на стороне клиента сколько-то можно эти данные придержать и это уже скорее даже наверное не наша ответственность А их ответственность они должны тоже понимать что ну у нас может снизиться доступность на какое-то время хотя мы стремимся к высокому SL но все знают что стопроцентно SL не бывает Окей так спасибо большое за доклад У меня вопрос не совсем по теме Вот вы записали там как-то куда-то по плану б или по плану с А как вы сообщаете всяким дашборда Где искать эти данные то есть они наверное рассчитывают их найти в каком-то одном месте А у вас оно в другом Ну на самом деле они супер вопрос Спасибо они повисает не в БД они повисает в кафке по ней искать нельзя Поэтому просто по факту на дашборда у людей дырка будет Ну или если уж Как практика показывает Там будет не дырка а там будет частичная деградация какая-то такой провал но с этим ничего не сделаешь то есть мы не можем как бы эти данные получается надо дбд тогда делать поэтому у нас вообще поиск очень круто организован То есть я рассказывал что пайплайн записи - это такая штука централизованная по дата-центра сконцентрирована по дата центрам и не зависимые друг от друга а поиск у нас Крос дата-центр и он так вот накрывает все всес всес дата-центры одновременно работает везде и поэтому потели Это примерно Так выглядит что у тебя там дата центр А и C вот в А всё хорошо и ты там на графика Всё видишь замечательно А в C у тебя какая-то деградация пока мы не восстановим потом БД восстанавливается графики выравниваются и прям видно как и становится О привет Меня зовут Кирил два раза была упомянута R один раз Просто после записи второй раз после вопрос это одна и та же очередь и сколько времени тратится на то чтобы её разгрести руками потому что как будто бы там много сообщений должно быть в общем практика показывает что там почти ничего никогда не бывает вот кото после я вижу Один раз в год несколько десятков сообщений это прямо вот какая-то у нас даже Арт специально есть Мы даже вот ни у нас никакой автоматики нет мы просто повесили Арт и проверяем когда что-то там появилось обычно там какая-то вот просто ерунда Ну Бага В общем а rq которая с форматом м там тоже на самом деле мало потому что у нас хорошие Там валидаторы хорошие правила записи и тоже скорее всего поток туда не попадает Но если мало защиты спереди поставить то конечно в эту будет сваливать всё что там по полям не подошло и так далее это могут быть конечно миллион сообщений классный вопрос Добрый день У меня вопрос по поводу бачева Бачи - это хорошая вещь но также они большая проблема вот например вот ба Да там 1000 записей одна из них по какой-то причине соответственно и все остальные как бы падают Как вы решаете э эти проблемы врезаем из боча то что нам не нравится Нет это понятно но как это определить там же бач Он полностью либо сохраняется либо нет как вы ловите из-за чего О не сохраняется Как вы вырезается что вам не нравится вот например такая проблема есть при записи в ластик То есть ты там собирал собрал какой-то бач тебя там куча разных независимых документов и например часть из них вот дупликации отрезала там он сказал конфликт документ уже есть прям это реальная история с продакшена Хороший вопрос эластико в ответ присылает что где пошло не так мы контролируем просто по ошибкам там по респонс пытаемся сообразить что что идёт не так вот как-то это там в частом порядке каждый раз обрабатываем вообще я должен сказать что хоть воркеры очень похожи и не зависят от имплементации Ну как бы структура их такая Да но в коде это всё по-разному конечно называется там какие-то есть особые ивки ну без этого никуда не денешься Все каждый постмортем - это новый набор ичико у нас в коде А постмортем мы очень любим разбираться Здравствуйте Меня зовут Иван Спасибо за презентацию всё было классно и Хотел бы уточнить как раз вот два вопросика по этому слайду и по Q Давай по вот этому смотрите вот допустим будет какой-то апокалипсис Да И вот по прямой викри будет не писаться Да какое-то время вот примерно какое время вы закладывается что у вас не будет основной пайплайн работать ну вот ну в случае каких-то Вот таких вещей какойто объём примерно Если мне память не ну у нас Понятное дело что есть селф мониторинг у нас там есть всякие с индикаторы вот эта вся правильная машинерия За тем чтобы следить как всё работает мы говорим что плохие минуты для нас наступают если в течение 5 минут у нас меньше 90% данных заезжает по прямой за ном ко даже Е 80% Ь лет Т 20 ле отложено Значит уже какой-то есть отставания Значит мы считаем что алерты могут работать уже не очень точно Для нас это уже плохая минута вот а так в среднем мы стараемся держать Ну вот не больше нескольких минут так оно в общем-то и получается обычно там всё рубильника внутри всё переключается когда что-то деградирует там нода вылетела бам-бам-бам уже в другую всё пишется там моргнул вот так и Всё вернулось и второй вопросик можно да сразу по вот вы когда Ну у вас есть такой паттерн что вы перекладывается вот да вот здесь consum какие-то сообщения которые не дошли Да чтобы второй раз их отправить и так далее И вот в этом случае какой примерно процент вы закладывает то что туда будет лететь и когда уже выше уже слишком плохо Вот примерно по практике И вообще адекватно классный вопрос контролируем к на ка на этих специальных эти я процент не могу сказать потому что мы Я сказал мы мониторим просто процент прямой записи Так мы это называем для нас вот 90 это прям черта Когда уже что-то нам не нравится как это работает Это мы считаем уже прям проблемой серьёзной А в кафке мы просто считаем Капа Сколько может влез есть ру гово по МХ без БД вообще чтобы ничего не потерять потому что метрики например важная история для капасити пнин там для какого-то разбора что пошло не так то есть даже сейчас мы не можем что-то записать Но мы потом Хотим посмотреть что было-то вокруг как потом чинить это всё Поэтому мы стараемся вот выдерживать ну хранить Как можно дольше Ну десятки часов короче Добрый день спасибо за доклад очень интересная насущная тема вот подскажите вот этот подход с Dead Letter Q retry Q Error Q он по сути допустим если допустима запись out of Order А есть ли какие-то стратегии кроме Stop on Error и retry Forever если out of Order запись не допустима если мне память не изменяет А в тех материалах которые вот в Sage Community есть там есть статья от confluent короче кто каку делает условно и там есть разные вот эти Стратегии в том числе Letter Там и так далее и Если я правильно помню там было было описание Как правильно сделать такую вот короче машинери с перекладывания по очередям чтобы ордер сохранить там такое есть но с ордером Мне кажется не получится вот э вот гибридную схему держать то есть ли быты должен более жёстко переключаться сюда туда Мне кажется там проблема будет как бы чтобы сжи данные доезжая не понимаю как ну то есть у меня цель была простая как я говорил мы ребята простые есть проблемы свежая телеметрия должна быть доступна максимально рано для поиска че бы не происходило часами ждать ничего нельзя ордер требует чтобы мы и процеси в этом ордере поэтому это короче может быть бедой Спасибо И если можно второй вопрос А вы упоминали проблему с тайм-аут самый большой самый первый самый самый в крайнем случае на паузу поставить так ничего не мешает но кроме того что в кафке просто всё будет накапливаться и она взорвётся Ну а вдруг рули Спасибо не это нормальная стратегия вообще сре кстати Прикольная штука есть можно делать реро каскадом то есть делать одну потом вторую задержка минута потом третью задержка час там и так далее тогда у тебя конр просто на паузе стоит периодически что-то вычитывает проверяет Ну вот fullback консьюмер например и дописывает но есть нюанс что это ещё больше копий в БД и так далее ой в кафке и так далее мы используем на самом деле вот в налогах эту схему с каскадом и она мне меньше нравится чем просто одна R IQ а ограни увеличивать время на процессинг Это означает что придерживать данные в кафке то есть свежая телеметрия притормаживает это нужно всег время искать этот компромисс между тем как бы лиш не процес с одной стороны а с другой стороны побыстрее свежие данные проталкивать чтобы на дашборда всё было хорошо спасибо Здравствуйте Меня зовут Константин Следующий вопрос Вы рассказывали по поводу бачей и уже Вопрос был по поводу бачей вы в случае если бач фели он обрабатывается из какой очереди То есть он будет обрабатываться из той же очереди первоначально или он вй утн ут вй и мы будем потом процеси его из трая но он не целиком в ретрай уйдёт не бо чом он опять покрошить на мелкие части и поедет отдельными сообщениями отлично А если у нас какой-то клиент постоянно посылает там батч и в нём два-три битых сообщений то у нас все будут уходить в Трай Ну не всё мы там разберёмся поскидали да про токсичный трафик и шумных соседей это тоже пример хороший как их надо вычислять и исправлять проблемы из друг от Друж Так у нас есть время на ещ один наверное вопрос Здравствуйте Меня зовут Ольга Я хотела спросить про размер Бача в Dead всё так размер Бача Мы в общем крутим Эти размеры постоянно это могут быть сотни мегабайт могут быть десятки мегабас даже налогах есть механизм который пытается вычислять гиме так чтобы максимально увеличить скорость Инжеста в эластик Ну то есть типа мы прикидывается какой есть Time и вот крутим побольше Ага помедленнее стало поменьше Ага типа там ну меньше поток в процессе и где-то вот ищем какое-то место Ну типа Хил ланга такого вот поэтому это не всегда просто Константа А в рейсинге по-моему там что-то несколько сотен мегабат Давайте е один вопрос но это будет уже у нас последний Добрый день меня зовут Антон А такой вопрос А вы пробовали прореживать данные которые подобные например одинаковые чтобы снизить нагрузку на базу данных и не потерять при этом качество метрик блин это крутая история сэмплирования я не буду таить Когда мы придумывали схему с фбм на Метрика Мы думали а можно ли прореживать мы делали долгосрочное хранилище А можно ли мы тоже думали а можно ли прожи прореживать поток в чём проблема у нас поток как я уже говорил это где-то 450 Мб в секунду Если ты хочешь проредить 450 Мб в секунду то ты должен подготовить память на как минимум окно в котором ты собираешься прореживать а так как это будут уже не пожа данные то 450 МБ превращается в 5 Гб такое короче огромное количество лоцирование будет не очень хорошее Потому что сейчас мы гибко делаем Ну там сколько инстан сов добавил Они все в балансировке Все что-то в процессе что-то делают а это надо как-то данные уже пытаться локализовать внутри этих инстан сов делать умные короче марше зации внутри это прям нетривиальная штука то есть на стороне BD сделать сильно проще потому что она на самом деле делает Тоже самое она какой-то только кусок свой Сплит если даже Викторию посмотреть у неё там в двух нох Ну может быть не очень хорошо сиди плино Если ты там как-то не очень удачно у тебя шардирование та сери распределяем сложная Задачка Мне она нравится Я бы ну я даже кусок её имплементировать кого-то с особо классным вопросом я Можно последний вопрос про сэмплирование потому что это прямо не в бровь А в глаз мне вот Спасибо всем за внимание голосуйте Спасибо большое"
}