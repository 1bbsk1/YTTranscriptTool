{
  "video_id": "X97icuNCRt0",
  "channel": "HighLoadChannel",
  "title": "Высоконагруженная отправка push уведомлений / Алексей Акулович (ВКонтакте)",
  "views": 2188,
  "duration": 2015,
  "published": "2017-04-08T13:46:46-07:00",
  "text": "итак компания в контакте с ним планом докладом проток как разослать 1 миллиард push-уведомлений сутки 1 а сколько почти 8 8 миллиарда сообщений хорошо всем привет аншлаг конечно в общем сегодня расскажу вам как мы доставляем push-уведомления архитектура проблема которые возникали с этим и некие компромиссы и борьбы с ними я призываю подпушь уведомлениями сообщения которые мы отсылаем сыров нашего проекта на мобильные устройства через промежуточные сервера платформ предоставляющих собственно функционал push-уведомление для приложений под android это уведомление через сервисах google для ios iphone приложения это платформа apple фнс по уши для windows phone и просто windows-приложений это 2 разных платформ придуманных майкрософтом они из похоже но вот всего 4 то есть когда там кто-то пишет вам приватное сообщение лично добавляет вас в группу или лайкает фото вашего котика то мы отсылаем пуш на все ваши привязанные устройства на каждой из платформ путь пушин начинается на сайте когда происходит какое-то событие формируется подробная информация по этому пушок то что отношение к чему сделал такой обобщенный формат к этому добавляется информация о всех ваших привязанных устройствах и по каждому из них отдельно специальные движки очередей складываются эти пуше для дальнейшей обработки собственно задачи push сервиса является взять эти пуше излишков очередей по отдельности отдельно обработать подготовить формат который понимает площадка обрабатывающая пуше и отправить на нее обработав ошибки для нас сообщение каждой то есть push-уведомление это независимое сообщение отсылает мои по индивидуальному каналу на каждое приложение каждого пользователя то есть случае если в какой-то группе скажем на миллион человек где у каждого пользователя и привязана по два устройства примерно то мы должны отправить именно два независимых миллиона сообщений некоторые площадки предоставляют возможность групповых рассылок когда мы указываем содержимое пуша я и список получателей но в нашем случае каждый push персонализированным и так сделать не можем это честно отрабатывать весь объем пушей мы отсылаем на четыре платформы я про них уже сказал на конкретный каждый из них каждый push для android приложений и тоха ттп спас запрос где все данные по пушу являются джейсон страховой передаваемой в теле для apple это тисе пи соединения и пакет представляет собой всю информацию по пышность бинарный пакет специальной структуры для windows platform обоих так или иначе то тоже этот эпос запросы с xml телом для платформы windows phone то есть мнс мы не укладываемся в лимиты бесплатному не ограничены доставки нам еще нужно сертификаты то есть для вот для каждого пуша надо вот оправить подобный что количество сейчас мы доставляем примерно вот это 770 половиной миллиардов пушей в сутки это именно доставленный пуше не все что мы пытаемся отправить я об этом еще подробно расскажу вот такие примерные цифры еще идет спад после летние такой поддаваться сколько быть максимум посмотрим теперь собственно рассмотрим как оно все работает начнем наверно с проблем с которыми столкнулись то есть если делать просто по документации платформ то как они описывают то все хорошо работает отлично до некого предела от правах когда мы не укладываемся в лимиты у нас кончаются ресурсы так собственно конференция здесь holod и есть большая разница между тем что мы отправили x сообщение одним сервером или мы отправили их сообщений и к серверами не хочется такого делать первые проблемы в котором можно столкнуться но она самая простая очевидное банальная это хан шейки все четыре платформы требуют цель соединений сертификатами и на каждый push устанавливать новые соединения это нереально мы упремся просто в процессор железо и вот соответственно банальная вещь это постоянные соединения через пул соединений и для х ттп запросов и to keep alive соединения так как мы отсылаем собственно вторая проблема не только пушина наше официальное приложение но и на всех кто у нас авторизуется и регистрируется на сайте то у нас есть проблема работает сертификатов неофициальных приложений за которыми не следят они просрочили силе вообще не заданы приложения растет глючит но мы стараемся отсылать сколько можем максимально как-то подойти к людям если они хотят пользоваться неофициально приложением но мои рады постараемся к это сервис оказать но проблемы есть я об этом тоже еще расскажу очень подробно другой проблемой является некая немного странная политика apple реализации протокола каждый пушат ссылается по тисе пи соединения но при этом если все хорошо то есть push корректно сформирован отправляется на устройство которое зарегистрировано с приложением рабочим то сервера apple нам ничего не отвечают они приняли push все замечательно давай еще в случае же ошибки по документации через некоторое время они вернут нам ошибку по тому же соединению через какое то время но в отличие от этого они еще не просто бывает возвращают ошибку они бывают молча рут соединение вообще ничего не присылая для борьбы с этим можно конечно отправлять push ожидать какое-то время там секунду-две если ничего не вернулась окей все хорошо но это но не реальные объемы коннектов чтобы этого избежать мы отсылаем сообщение пока на этом не переставая без пауз отправили отправили отправили но не просто отправив забываем про них мы их складываем специальные очереди отправленных но не подтвержденных доставки пушей и они там лежат некоторое время соответственно если к нам приходит сообщение об ошибке то мы находим этот push который можем узнать по ответу в очереди отправленных все которые были отправлены перед ним мы считаем доставленными так как ругнулась не на них а на то чтоб был отправлен позже их щит удаляем из очереди а все пуше которые были в очереди после ошибочного нам приходится при отправить заново в случае обрыва соединения ситуация похоже но мы просто чуть убегаем назад и и перри отправляем работает в общем то весьма неплохо других вариантов нет apple вроде как совет не советует обещает сделать цивилизацию как у других платформ через этот вопрос ответ ну посмотрим когда выпустят если рассматривать дальше платформой microsoft обито у них есть собственно сразу две проблемы первая проблема это очень очень медленная работа их серверов то есть отправить один push pack ттп и ждать ответа одну-две секунды это нормально для них даже собственно после того как мы дождались ответа бывает очень часто ситуация что при обработке их сервер упал и мы вместо ответа получаем какой-либо 500 код и товкач вместо нормального формата мы получаем html-страничку со stack trace мсп сервера это очень часто но даже если бы это происходило ну ладно получили 500 попробуем еще раз ческого это маленькое время проблема в том что они умудряются упасть так что иногда не успевает принять push иногда не успевает его принять ему это проверить не можем и если мы отправим еще раз то он в случае если пуш был принят и сервер упал уже после этого то на телефон у пользователей придет два одинаковых ушах и как показал опыт вас прощально мы делали именно с перед правкой то гораздо лучше пользовать носится к тому что к ним вообще ничего не пришло чем пришло два одинаковых то есть два одинаковых а не жалуется на не пришел но не пришел то есть пока они не перестанут либо падать либо возвращать не понятно что мы это исправить на своей стране не можем вот сосна 2 проблемы является довольно специфическая вещь что пока вы укладываетесь в лимиты отправок бесплатных ну в день нити лимиты то все хорошо это обычных и ттп даже не из соединения а вот если не укладываетесь нужен клиентский сертификат по которому устанавливается соединение и сервером microsoft требует тренинга station такая штука выпилено я почти везде 2009 году что на лице богам с или tls и но вот они требуют его использования приходится поддерживать собственно как она работает каждый процесс сушилки взаимодействует с очередями не напрямую сейчас а через наша стандартная питает это работал сопи контакта он представляет себе to access talking on эпоха ттп в общем стандартно на каждую пачку пуше делается отдельный запрос к питом сколько миллисекунд получаем там джейсон большой-большой резон там на несколько тысяч пушей причем в запросе мы указываем какие именно платформы сейчас интересует конкретную пушинку не все четыре которые у нас есть и поддерживаются а какие мы сейчас хотим это будет важно вот со следующим пунктом в общем получив этот джейсон мы его разбираем и раскладываем по очередям из эти очереди внутренним 3 процессов это не внешние сервисы очередей это просто внутри оперативной памяти так как запрос copy его разбор занимает там несколько миллисекунд из на чтобы не было задержек нас таких маркеров обрабатывающих а перед порядка пяти-шести на каждый процесс пушинки они параллельно запрашивают выгребают пачки и раз партию и складывает в очереди для каждого из них 4 сходясь общей общее то есть пять процессов пишут 4 очереди грубо говоря вот киры разбирающиеся череде по платформам в каждом конце очереди платформы есть свой отдельный worker который просто занимается тем что берет push и перекладывает его по значению приложения указанного выходящую очередь конкретного приложения конкретной платформы в этот момент он проверяет размер исходящий очереди и если она заполняется выше чем некий предел максимального допустимого то оно просто перестает перебрать хлопуша из входящего черти и складывать их исходящих ждет пока не рассосется до какого-то нижнего предела те worker и которые ходят папе видит что начала заполняться их исходящий очередь и просто перестают обращаться к пии выкидывая эту платформу из списка желаемых они перестают получать эти push и соответственно если проблема возникла на конкретной пушил key to the что она не забирает себе разберут остальные пушки если же проблему массовая глобальной все пошло не так то сработает мониторинг на размеры череде излишки движках очередей и там уже надо разбираться а у нас всего порядка но это очень грубой цифры 100 приложения официальных неофициальных очень примерные цифры соответственно нас получается четыре процесса варки рф и процесса процесса логических это не отдельные потоки или и процесс операционной системы это логический процесс они забирают из четырех очередей приложение показывают поста очередям приложений на том конце этих ста очередей есть свои 100 worker of который забирает пуше из входящих очередей и раскладывают их уже не по очередям а отправляют их в пул соединений конкретного приложения конкретной платформы так как отсылать все через одно и соединение нереально это было бы слишком медленно то у нас есть пул и потоков разные для каждых приложений из нас есть эта часть настроены в конфиге которые мы знаем там свои там белый список остальные минской дефолтные лимиты вот здесь та же самая ситуация по размеру очередей если исходящее сбиваются то мы перестаем за выгребать из входящих те четыре worker и видят что исходящая забивается но и понятна ситуация тоже одной особенностью является то что здесь идет учет что за приложение на которой мы отсылаем для официальных приложений ситуация понятно мы их можем полностью проконтролировать случай проблемы ну те же сертификаты и так как бы багов не случается вот для неофициальных приложений имеющих массу из селедки ты проблем нам нужно ограничить потребление ресурсов когда происходит что-то не так не допустим резко есть только сертификат вот он полчаса ищу было работать с он кончился и все connect обрываются сушилка не должна умирать перегружаться или мешать другим приложением из этого одно приложение ответственно есть некий лимит по числу ошибок я все скажу об этом превышении которого мы немного вырезаем желание этих приложений в итоге каждое соединение каждого приложения каждой платформы обрабатывается своим вор кирам который знает свою маленькую логику собственно работы уже соединением он не знает большими чё там от руки и х пулах ничего тон у него есть сетевой connect у него есть входящая очередь пушей все он маленькой логика который знает свою платформу таких маркеров у нас примерно от 5 до 20 тысяч на процесс с на ней работают не только входящим очередями но еще и с очередями на период правку очередями ошибочных семинарах ситуаций для apple там еще будет вещь и таких очередей у нас вот 10 20 тысяч на процесс вот примерно так это все выглядит в случае вот примеры если на скейт проблемы допустим скушай microsoft постоянные то вот мы просто перестаем их запрашивать и ждем пока рассосется теперь подробно про неофициальное приложение которое у нас вот собственно составляет на некоторые проблемы от лишних приложений которые банально уже запрошены на люди ими пользуются мы их поддерживаем но допустим если сертификата нет или он истёк ты мы не можем отправить больше чем свободные лимиты по требования площадке мы пытаемся их отправить сколько есть а потом просто ну получаем ошибки ошибки ошибки с другой проблемы являются приложение с просроченными сертификатами когда не резко заканчивается либо вообще не были указаны в этот момент тоже получается резкий рост ошибок еще одной проблемой является приложением которые выпустили люди ими пользуются но их довольно мал он там всех взял делал для себя для друзей потом это приложение уходит в массы разрастается и в какой-то момент она все еще допустим без сертификата но при этом оно уже выросла за пределы мы приходим к старой ситуации с проблемами а проблема сертификата в том что в общем то мы устанавливаем соединение мы уже превысили лимит и нам их обрывают и снова reconnect шейка он очень дорогое мы живем циpкa и еще довольно редкая ситуация но по но нам особо не сказывается довольно редкая но эта проблема в том что некоторые неофициально приложения могут банально не отписывать то есть мне отсылать нам информацию о том что пользователь разлогиниться выключила приложение пуше и мы продолжаем отсылать пытаться то приложение которого нет и можем получить обрыв соединение ошибки а apple придется единение часто при этом опять приходим к тем же собственным проблемам вот собственно для этих приложений ну тоже сама логика есть для наших официальных приложений у нас есть лимиты минимальный и максимальный ошибок и при превышении коннектор но ошибочных коннектов за единицу времени просто приложение выносится временный бан в пределах процесса данной пушинки вас какое-то время там порядка двух часов ну ограничиваем отправку чтобы во первых не занимать ресурсы которые бессмысленной бы нас опять оборвут нет смысла и кроме того есть площадки которые позволяют после некоторого времени отдохнув снова дать некий лимит нам небольшой меньше чем в день но вот еще до отправить вот это позволяет хоть как-то по максимуму отсылать несмотря на ограничение вот так приходится жить эта штука написано нога собственно она работает на 24 так себе серваках на каждом так как в принципе очень неплохо масштабируется по ядрам то на каждой машине по одному процессу мне как там по процессу не тронет из-за очень большого количества соединений постоянных нас приходится поднимать лимиты где то 10 на спам или одиннадцать тысяч стоит лимит на процесс при этом потребление памяти порядка 500 мегабайт гигабайт гигабайт практически предельное значение но цифры средние в основном из за того что мы очень большие очереди копим локальной теперь отправки очереди ошибочных о чем-то очень много данных хранится но при этом вот собственно потребление небольшое при этом так того это язык со сборкой мусора то у нас есть собственно паузы грач коллектора примерно вот до 10 пом 1 7 секунд бывает вполне сети можно жить при этом потребление процессоры от 200 до 500 процентов то есть это где-то на 16-ый фидер этот трехкратный рост есть по текущему железу если не профилировать ничего не делать и просто вот и жить дальше вроде как получается что мы можем сейчас отправить ну 20 25 миллиардов пушей вот на текущем железе при этом работка 1 пуша не отправить доставить то есть отправить там больше получается попытаться обработка пуша занимает от 40 одета миллисекунда секунды при этом секунду в основном из-за серков майкрософта они сбивают средний по больнице вот это да секунды раньше это работало на ноги джесси но вот это вот больше года уже переписана как нога и вот она но да не хватило 60 машин под эту задачу из приятных мелочей во-первых собирается огромное количество статистик статистики как глобально по процессу которые были на предыдущем слайде так и по работе каждого отдельного worker а очереди коннекта все это агрегируется из-за массивной многопоточности то агрегируется первоначально в локальных структурах каждого worker а и только время от времени они по восходящей агрегируются в общих структурах откуда мы уже отсылаем статистику то есть писать все со всех сразу в центр мы будем сидеть или бы с каких-то атомарных операциях либо там да толку мне блогах наведет иксах ожидать поэтому параллели c для того чтобы разбираться по факту о возникших проблемах когда что-то случилось а потом хочется посмотреть почему допустим ночью там или заняты у нас есть возможность для каждого конкретного push какому-либо условию сделать специальную отметку в перед тем как мы положим его в исходную очередь отправки в мешки которые первоначально отметить что это пуш особенный мы хотим за ними следить поэтому пушу собирается сведения о том про все стадии обработки которые он прошел от момента формирования обобщенного пошло складывания в очереди как api отдает этот уж пропушил ки и то ли это позволяет по факту посмотреть что с ним происходило на какой стадии были задержки проблемы когда мы получили ошибку разобраться с этим и самый довольно таки спорный момент это самая диагностика у пушки есть некие лимиты на отклонение основных электрические работы и когда что-то идет очень не так ты совсем какой-то полный вообще шлак the trash в общем происходит то пушил к перестает вообще принимать по уши и , входящий канал тех 4 5 6 worker of закрывается она некоторое ограниченное время пытается дата слайд то что у нее уже накопилось но если что-то пошло не так обычно это может уже и не удается отправить она пытается сделать какое-то время после часа мася гасит просто поднимается за но и пытается работать это помогает случае если подошла к это проблемам либо в ней самой либо произошла к это временные локальны там сбои на там машине или сети перезапускается из шанс случае же если проблемы массовой они все начинают по очереди падает то это хотя бы позволяет продержаться хоть как то до тех пор пока не среагировать человек ну там на мониторинг такая вот ситуация наверное все могу ответить некит вопрос если что-то не рассказал спасибо не знаем давайте вот вот такой достаточно крупный камень кинули в microsoft а я католик части к сожалению пользуясь вашим приложениями на этой платформы и на самом деле да нет жаль что я здесь есть и пользуясь нет их работы но вот смотрите на самом деле очень сильный проблемы спущен начались после вашего крупного обновления ну месяца три наверно назад и до этого их не было и то есть то ли в тот же день microsoft резко сломала свои серваке внутри alizade мы не меняли пружину очень ну не 3 месяц назад когда был очень били дизайн и после этого возможно просто выросла лимиты где там опять превышаем лимит ее макросов снова глючит ну в общем игры в день в день и как-то странно что ли ты хоть совпало с падением миг серваков вот может не все так плохо у них у вас тоже чуть не очень хорошо работает может быть это для желающих хороший вопрос могу радовать секира есть не мудрости по центру справа тасс а как реализовано вас очереди persistent ходе такой охоте менее свежие весь этот суп с на них работает всем здравствуйте спасибо за доклад здорово собственно проход к кое-каким вам у вас сделано я согласная логия то есть это у вас что-то очень свое аутентичный или какой-то там аналог pet с twitter ссылки на используется ли он сам или еще что нет такого рода для лохов для сквозных логов т.е. понять был ли снова приложения да просто как собрать вагиз система полностью водами сквозная достали которая выполняется на черном стране к phpbb нтов это суп на собирается ими же то есть это та стадия да вот отправки и сапиев ушел колпачки с прайсами а часть кушал кенн агрегирует логе успел локально а потом пачки подсылает вопи но то есть это несказанной лаги это раздельная логия склада нас от минус классный хотя нефтегазовая что это все статьи обработки пуша спасибо здравствуйте и спасибо за такого мне бы хотелось спросить по поводу работы с apple сервисом вы говорили вы ждете некоторое время перед тем как магнит мы не ждем в отправка вы отправляете push и держите его какое-то время в очереди отправлены до катил вас ли мы лимиты на это время на две секунды а и второй вопрос вы говорите после первой ошибки вы перри отправляйте все что было после первой ошибки даже если соединение не разорвана связи акира под консультацию и по указано что если они прислали пособ отец ошибкой то надо считать что этот уж и все последующие гарантировано непал поставленные не отправится спасибо здравствуйте я вас на первом слайде увидел крик php вот вопрос по нему хотел давно задать просто не было возможности планируйте как-то развивать его поддерживали для окон турция просто сейчас там на гитхабе у вас там все плюс плюсе все в исходниках надо собирать и куча магии вот если планах как вот facebook аж еще чего им развивает как известно есть сторону не от меня это зависит вас нам от наших сильных разработчиков их свободно времени но такие планы есть собственное копа копа и все движки которые есть на гитхабе но актуализировать спасибо рост вопросы просто не по теме я могу потом рассказать сейчас хочется вот именно в как то более менее по теме доклада задерживать добрый день я так понял вы используете их это tps протокол для работы с google им у него есть еще и к симбе которая дает фидбэк вот почему вы его не используете этот вопрос а второй вопрос тоже самое касательно oчереди я так понял его свой велосипед место какой он всё готово решений там тот же rabbit или еще что-нибудь первый вопрос ну так посмотрели по поводу xml но наш сейчас задержки на хоть это поезд запросы вполне устраивает он работает очень быстро не чета красовский сервером и на текущих объемов вполне то есть это будет переделка это преждевременной оптимизация если бы он представлял этот дополнительный функционал который нам нужен да стоило бы вы рассмотреть а так работает очень даже работает сейчас даже собственная знаю google рисовал внутри своего проекта платформы поддержку пушек для apple но письмо на сочи все-таки cool для apple не использовать в сипе но вроде как работает но работает излишне во втором вопросу да собственно как и практически все кишки и прочие мика сервис это собственно решение а почему обычно чем не прошел кроме готовые решения или это просто политика такая ну например тогда еще не было собственного уже не первый год же слишком эти спасибо привет где здесь вопрос такого плана допустим сидим мы в чатике через web-интерфейс рядом с нами лежит мобильник и там рядом с нами лежит планшет и как бы есть такая боль когда ты сидишь активно общаешься ну казалось бы зачем себе получать пушина мобильник он носителю слово держит до он лежит великой тайной ты читаешь это часть их вот можно бы когда это за анально хотя бы отключать отправка не на все на текущие и не отправка тех которые уже успел прочитать это обсуждается отлично и я также разделяю боль по поводу windows phone но и некоторые продолжение такой вопрос иногда задержки бывают реальном минут 15-30 это время у них такой или это время может быть уложен в очереди mba лимит когда начинается массу проблем и disconnect ами с их стороны мы просто взлетаем подсыпал на reconnect и хан шейки бессмысленных in шейки пока не сработает защита от числа ошибок потом нормализуется но для неё в приложении не очень наблюдаться у вас есть вот на этот случай какая ниц возможность там console этого пуше например реально бывает такая ситуация когда ты в этот период времени до уведомления ты успеваешь опять зайти web-интерфейс прочитать это на ведущем вопрос о это всегда получается то же самое спасибо здравствуйте зовут никита проект и затем у вас сообщение персонализированные так вот у вас есть еще какие-то очереди когда сообщение попадает очередь она обрабатывается и уже рассылается уже сформированы или как где где это происходит не знали заскочи не занимается изменениям сообщения страшно можно взять из того об общего числа под его платформы и и сформировать запрос под нужную то есть там же именно сформированным фрукта там уже готовый текст все красиво поэтому мы складываем отдельный пуш на каждая платформу каждому пользователю независимо очередь здравствуйте скажите пожалуйста почему вы не любите асинхронных уведомлений то есть как делает apple то есть фактически как я понимаю они уведомляют вас асинхронно ну то есть вы делаете запрос о ней там обрабатывают его как же поэтому закон а проблема в том что они могут по 1 не отвечают эти все хорошо и нет времени которые нужно дождаться чтобы узнать хорошо или не хорошо и даже если было нехорошо то можем не получить ответа наоборот соединение ну хорошо это все равно можно считать синхронными у давлениями ну да не приходит позже когда мы уже провели щепочка to sing ты хорошо просто смотрите мы в последнее время ну как бы любим мы перешли на асинхронное уведомление то есть не то чтобы сразу ответить это 2-го типа не бы скажем всегда отвечали хотя бы пойти ok или где планировали соединение молча нас был оба разница между отправленным и приходом ответа ну да то есть вы не отрини отрицаете что асинхронный уведомление это плохо и программистами книги в самой быстрой лизации всех четырех платформ да но у них есть проблема спасибо пожалуйста все еще один вопрос а подскажите пожалуйста как вы тестируете нагрузочное то что пусть доставлен то есть то что в коде проблем нет ох уж это сталина поверить не можем кроме как на софтом устройство вот только до отправки а тесты просто идут есть отдельные тестовые очереди на отправку с отдельными тостером кушал коми либо пушил к обычно запускается так что она выгребает из обычной очереди и с тестовой а все тестовых уж у нас лакируется тем складным логирование можем смотреть или лень обработанной как обработанную за сколько обработаны от тестовые push один никита ваши девайсы или пушки настоящие настоящий пушкин живые пользой тэнкан реальности по разного реально понять спасибо рост все всем спасибо а еще он там еще есть the clutch а не надо ну все тогда все спасибо"
}