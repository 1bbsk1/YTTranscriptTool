{
  "video_id": "BFylYQAYnus",
  "channel": "HighLoadChannel",
  "title": "Пишем свой Domain Crawler / Евгений Карагодин (Plesk)",
  "views": 671,
  "duration": 1906,
  "published": "2021-10-04T02:08:51-07:00",
  "text": "меня зовут евгений карагодин я работаю в компании плеск и я люблю собственно делиться знаниями и поэтому я сегодня расскажу вам таком необычном проекте для нас которым не дал и госкомпании заниматься так вообще причем здесь что-то там young роллер да и при чем здесь еще плеск мяско-то продуктовая компания и основной наш продукт это панель для управления сервером это все что связано с менеджментом сайтов конфигурацией веб-сервера и так далее и нас использую довольно много сайтов один примерно 11 миллионов сайтов это существенная с ума от в целом от общего количества сайтов держать и конечно же нас интересует а чем собственно пользуются наши клиенты потому что ну плеска это достаточно большой продукт с большой историей там backlog длиною в жизненно нужно как-то приоритизировать эти фичи и хочется понять что важно для наших пользователей что нет какие инструменты нужно поддержать с какие может быть менее менее важны для нашей аудитории и в целом хочется понимать о чем вообще в интернете люди польза какие инструменты сейчас популярны может быть мы что-то упускаем и так что конкретно нам бы хотелось знать использует например нам интересно использовать люди cdn для этого нужно знать айпи адреса сайтов какими используют ли миксера где они хотят name-сервера для этого нужно dns-записи все получать нам хочется знать это очень важный важная тема да кто-то псы и пушат хочется понимать использует ли наши клиенты это какие-то сертификаты бесплатные и платные у кого покупают и так далее и конечно же очень важно для нас это понимать какие инструменты используют в плане веб-сервера языка программирования какой движок они используют чтобы сделать с этими инструментами более хорошую интеграцию например для какой для вордпресса да там очень популярный движок и хочется чтобы это пользователем было более удобно им пользоваться как же это сделать нас есть три варианта мы можем собирать аналитику из продукта можем купить готовые какие-то отчеты можем в конце концов просто пойти по анализировать все сайты конечно же у нас есть аналитика из продукта достаточно много там всего всякой информации подробный но есть и как бы недостатки дав конкретно с продуктовой аналитикой есть вещи которые невозможно узнать внутри продукта такие как cd и вот подобные вещи мы хотим знать не только про наших клиентов до но в целом про интернет соответственно тут нам наш аналитика не поможет и такой технический момент это не блокер но важный достаточно для нас момент хотел сказать пресс достаточно большой продукт пилить отдельный какой-то небольшой проектик намного легче технически до чем добавлять это новые фичи в большой продукт мы можем и мы делаем это мы покупаем готовые отчеты над крафт это один из лидеров в отрасли вот именно по веб-аналитике но достаточно дорогой это вот 18 тысяч долларов в год и методика не раскрывается как я не собирайте ты данный вы можете не только либо доверять либо нет ну либо какие-то еще с чем-то сравнить еще что то делать какой-то анализ дополнительными это же важный момент для нас мы не можем выделить из этого она из этого отчета данные именно наших клиентов получается нужно парсить сайты возможны нет давайте разберемся что такое парсинг сайтов в общем у нас есть список доменов нужно послать на каждый домен запрос получить ответ что то из этого ответа на понять и сохранить результат задачи easy кажется да то есть легко решить но на самом деле прежде чем решать технические проблемы тут встает такой немножко эпический момент с парсинга это вообще законно да то есть мы когда я готовил свой доклад в компании даже меня спрашиваю людей может не будем про это рассказывать это вообще может вам что за это будет если люди узнают об этом смотрите я хочу тут прежде такую не технического налоги вот он может быть где-то встречались там на улице может быть или по телефону вы могли звонить да и вас права ли какие-то опросы то есть такие людям они обычно представляются да кто они говорят зачем они что они вас будет спросить как ваши ответы будут использованы вы можете отказаться но никто вас не заставит вас есть опция отказаться от этого даже если вы согласились никто не устроит вам 3-часовой интервью там по дороге на работу да то есть это будет какой-то быстрый опрос или по телефону небольшой опрос на несколько вопросов и это очень точно отображает то что собственно спартины да то есть все те же права можем применить и картинку сайтов во-первых не надо маскироваться вот первое что делают люди когда я писал свои парсеры any weather агент пишут и удирать копирует визер агентом скрыть браузер или там использовать это пакет для генерации easier агента смысла делать особо нет это во первых во вторых даже если вы ничего плохого не делаете если вы маскируете но это вызывают уже подозрением во вторых это бессмысленно делать он в прошлом году реки кажется был доклад про то как когда защищаться от парсинга если интересно посмотрите собственно поймете что бессмысленно вообще притворяться браузером ну вернее это очень сложно не достаточно просто поменять user agent в нашем случае мы пишем мы дети агент plus both второе для роботов есть robots.txt и его нужно уважать скорее всего если вы не компания размером там с google вряд ли в robots.txt кто-то напишет правило конкретно для вашего робота но в целом есть некоторое количество сайтов в которых парсинг и запрещен для всех роботов нужно уважать тут решение до владельца сайта у него были для этого причины и третье правило нельзя наносить урон сайту даже вот так сделаем это на самом деле самая важная дата есть так происходит урон для сайта вы просто создаете для него слишком большую нагрузку если это интернет-магазина примерно так не смог купить какой то товар для магазина это будет прямой урон в деньгах этом случае это какой-то как эта проблема для сайта если вы создали лишнюю нагрузку никто этого не любит соответственно этого нужно избегать и кроме того за это на самом деле это это не просто такой этически момента то есть вроде как нагрузкам и подумаешь потерпят но на самом деле ну за это можно могут наказать то есть человек реально может написать заявление в полицию да то есть его могут прийти и задавать вопросы там у стройке штрафы какие-то могут быть да там и так далее ну и как минимум даже если человек поленился если вы ведете себя вот ну агрессивно достаточно пасти сайт и вы очень быстро попадете какие-то черные списки и вам просто будет сложно выполнить свою задачу если вас начнёт банить клад флоры вот такого уровня провайдеры очень сложно потом от этого избавиться соответственно нужно нельзя наносить урон сайтом учитывать там если еще вы извлекаете как the contents сайтов нужно учитывать лицензии публикован соответственно какие-то локальные еще законные нужно учитывать и тут тоже могут меняться но на самом деле со всем этим можно вообще не заморачиваться есть такой проект есть когда пройден команд ролл это ребята уже собственно проделали этот алгоритм а у них есть список сайтов они по этим сайтом прошлись сохранили ответы выложили это все на ис-3 bucket это все публично доступно бесплатно пользуйтесь соответственно вы можете уже взять готовые ответы никакого урона ни для кого не будет можете это все анализировать и все будет отлично работать вас на этом можно было бы закончить но нам этот способ тоже не подошел тот момент когда мы сравнивали у них было порядка там 90 миллионов сайтов у нас там что-то около 80 миллионов и в общем общее пересечении был не очень большой и на самом деле там не было нужных для нас данных то есть это вот такие как dns-записи сертификаты то есть это достаточно специфичные вещи которые в общем-то не так чтобы сильно интересует людей при момент по всегда то есть это для нас интересно к сожалению в этом дата сайте этого не было поэтому нам все-таки пришлось писать свое решение чем парсить на самом деле по большому счету чем угодно можно парсить в нашем случае мы выбрали но джесс просто потому что у нас в этом есть экспертизам и плюсы тут понятно да это скриптовый язык легко разрабатывать быстро модель там асинхронного ее тоже прекрасно ложится на на эту предметную область и большая это система npn пакетов тоже как бы нам тут очень помогает есть решение готовые решения на все случаи жизни с одной только проблемы столкнули за все время если какая-то вот возникает проблем именно на уровне какого-то хищного модуля с этим поделать ничего не за это фатальная ошибка обработан обработать это никак нельзя я дальше про это расскажу отдельно когда тогда мы с этим столкнулись и что мы с этим все-таки поделали еще такой момент на джесс и голода то есть у нас были ребята которые тоже на голы любят писать и вот на коже все быстрее но конкретно в этом проекте тут и роста к особенно что мы больше всего ждем именно сетевые ответы да то есть время уходит на ожидание сети и время именно работы самого бикса макото бизнес-логики обработки ответов она там несущественное по сравнению с сетью да и тут как бы преимущество вообще сходит на нет и в общем из со спокойной совестью продолжили писать на java скрипте значит мы быстренько запилили прототип чтобы понять вообще это рабочие нет как бы от рабочей для нас можем ли мы собирать данные таким способом запилили довольно быстро все работало очень просто такая схематично так получилось у нас все это работал допинг в докер контейнеры там пара скрипта все в памяти поняли что все отлично это будет работать но с этой с этой съемка есть проблема да то есть это все запускается на одной машинки в одном докер процессе это очень плохо масштабируется да то есть это нужно чтобы масштабировать это нужно постоянно увеличивается именно саму сам сервер на котором это все кажется это очень не удобно не гибко значит у нас были какие требования то есть нам хотелось чтобы это более-менее гибко масштабировались не сильно отвлекала нас от основного продукта это вот мы на этом денег не зарабатывать до это просто насколько наш какой-то инструмент разработки и хотелось мне на него всегда выделяется времен такие вещи по остаточному принципу да то есть хотела чтобы это не не сильно тратить мое время и вот что у нас получилось а когда я немножко опустил некоторые незначительные детали чтобы не засорять деталями но принципиально она вот так вот получилось и сейчас мы пройдемся по этой схеме и так начинается всё с каких-то источников данных у нас есть собственно продуктовая аналитика это примерно один с миллионов сайтов мы парсим на регулярной основе несколько раз в месяц мы собираем по ним информацию второе это это просто текстовый файл где-то в истре боккетти в максимум у нас было порядка 140 миллионов доменов на данный момент так и третий момент это он может быть не очень такой важный ну как бы такой кажется зачем это вообще то есть какой то у нас в пиво есть куда можно в input вбить там домен и прокрутил пропарсить но на самом деле это супер удобно когда именно нужно протестировать какие-то из кейсы какие-то странные домены они бывают а в случае именно с пирсингом из ну то есть два совершенно разных вида то есть у вас может работать тут очень часто вот как раз тот случай когда у меня локально все работает да при парсинге из амазона не работает и вот тут должен быть удобный инструмент как раз проверить это дальше основной компонент нашей системы на котором счета вокруг которой все строится эта очередь это нам позволяет собственно гибко масштабироваться и делать ну слабо связаны с между элементами системы то есть мы разные worker и по большому счету у нас ничем не связаны кроме общего формата сообщений и в общем то при желании мы можем какие-то части переписать на других более подходящих языках если там где-то такая необходимость возникнет интересный момент с очередями есть мы когда разрабатывали у нас был уже редис мы такие дома dior cherie добавим взяли пакет bull это довольно известный ннп им к системе пакет это очередь на основе редисом там довольно много которых вещи с коротким но его очень легко подключить но оказалось что на наших объемах это он не справляется он просто упирается пасеку в итоге вся очередь работает очень медленно мы заменили это решение на рыбе тэнгу там пришлось чуть-чуть кода дописать чтобы поддержать и фичи которыми мы пользовались из пула но в итоге на том же железе да то есть у нас запас еще по производительности там вина еще очень приличный дальше часть прорисован доменов то есть отдельный worker который рисует айпи адреса и dns-записи этот также скрипт он ходит через inbound и получает все dns-записи зачем здесь он bound в этой схеме возникла у нас такая проблема на самом деле если массированно начинать эльза ловить домены не каждый dns резольвер это выдерживает у нас там был случай например мы поднимали траулер в кибернетике а там есть свой локальный рессор и ну он прилег буквально там в первую же секунду как мы начали проводить соответственно клуб флоровский клад фировский нам сирота же интерес себя ведут то есть они в принципе отвечают там если деньгам вы локально попробуйте вы можете получить все записи но как только вы начинаете делать это массированно да то есть они все айпи адрес результат но остальные записи уже не возвращают они говорят нет извините не работает так соответственно мы подняли альбом довольно известное решение именно как к ширу щедрина серверу там нужно появляться немножко с настройками но в целом в итоге вы получили там очень хорошее решение вообще от нас не требуют по ресурсам он очень производительны получился и вот покрывает наши запросы текущие то примерно 1000 запросов в секунду он вообще совершенно без проблем обрабатывает дальше такой момент а за дичь и вообщем это вынесли вот то есть у нас такой помпончик получается да и зачем у нас вообще-то вначале мы делаем оризонт айпи адресов тут такая вот как раз проблема с тем чтобы не наносить урон сайтом то есть у нас наши клиенты это хостеры в том числе шарит хостеры и у них получается возможный случай когда на одном сервере могут быть сотни сайтов а то и тысячи сайтов соответственно если мы пойдем на эти сайты одновременно парсить для сервера создастся достаточно серьезная нагрузка как это можно порешать ну очевидно это можно перемешать перемешивать но это работает только на большую data set of у нас по-разному было то есть мы можем маленький datasette и какие-то парсить и большие их хочется более надежного решения поэтому мы делаем лоб по ip-адресу для этого мы соответственно сначала рисуем все ip адреса дальше делаем блог по ip адресу в одессе и в том числе мы еще делаем паузы между запросом чтобы подряд не ходите на один и тот же сервер следующий у нас компоненты the scheduler собственно он занимается вот этим вопросом полок лаком по ip-адресу если если ip-адрес сейчас не залогом то он добавляет этот домен в очередь на обработку и и собственно вот этом маме процессор это собственно основная часть ради чего все затевалось да и то при этом происходит парсинг и вот это место у нас очень хорошо как раз масштабируются так как тут нет никакого узкого места дамы не упираемся не в базу него что мы зависим только от очереди соответственно мы можем очень легко здесь масштабируется мы используем лиц с в амазоне это amazon омска и решение как раз для для запуска докер-контейнер в облаке и тут она она очень хорошо подходит потому что мы просто говорим вот такой докер в такой докер-контейнер запустилась столько-то инсов скейлится пасеку и как как только нагрузка растет автоматически лица в общем работает easy и может быть перформанс 1 worker они очень большой там сто-двести запроса но разброс большой потому что зависит от очень большого количества факторов но за счет того что мы можем это очень хорошо масштабировать в сумме получается достаточно хорошая скорость и в конце результаты 105 схоронил там очередь и дальше там в базу данных в манге тут такой тоже интересный момент у нас это планомерно развивалась и на самом деле не все сразу тут у нас в амазонии было и когда мы работаем с большим объемом данных получается что у нас просто большой трафик да и желательно чтобы вот все вот эти вот компоненты между которыми основной трафик не то чтобы они были поближе друг другу и мы попытались том числе вот эту вот тут справа которая mongo db база тоже и amazon затащить в амазоне есть документ деби такое решение она совместима с мангой очень легко ее поднять удобно прям супер но очень дорого то есть мы там за месяц просто потратили 2 тысячи долларов дороговато для нас вышло но это было года два-три назад кажется с тех пор ценный поменять возможно можно еще раз посмотреть на этом собственно про amazon немножко еще пару слов о если почитать лицензионные соглашения в с с которым вы соглашаетесь когда начинаете пользоваться этим сервисом там вообще то написано что парсится это нельзя из амазона но как это работает этот нужен чтобы если на вас жалуются был бы официальный повод у вас из из облака выгнать но на самом деле если вы ведете себя хорошо да то есть вот соблюдать вот эти вот права в которой вначале расскажу никому не вредите то проблем у вас не будет то есть у нас вот за четыре года было всего 33 жалобы на нас было в amazon и во всех случаях собственно мы с людьми договорились объяснили что почему для поддержки амазона важно чтобы как раз решить проблему человека который обратился если проблема решена все к вам больше никто не пристает ну и всеми подытожу вот этот инфраструктура в амазоне нам стоит примерно 300 долларов это получается один с миллионов доменов раза три-четыре в месяц мы проходим несколько таких технических моментов по большому объему данных конкретные примеры будут на наджас но они в принципе применимы к любому языку значит нужно давать она же сразу перейдем значит когда у вас большой бен данных нельзя просто загрузить все в память до их желательно их стримить и в ноги есть вот так собственно для этого есть хороший пилот стрим су и вот здесь примерно то есть вот мы читаем этот и застревать это наш текстовый файлик 140 миллионов доменов это даже просто список доменов ну там сотни сотни мегабайт даже просто простой списка доменов если вы прочитаете в память там эта структура данных это еще больше соответственно делаем стрим папину и обрабатываем последовательно супер 2 тут супер крутых фич у стримов это обед прошел то есть общая скорость и пайпа она выравнивается по самому медь наму за счет этого у вас никогда не будет переполнение по памяти и второй момент это в строчке где в свой парс то есть у нас на входе был вообще то текст ну поток байтов а потом он превратился в структура бетон в поток объектов с которым уже очень удобно работать дальше если вам захочется сделать какой-то свой стрим по может быть немножко неудобно опять но а также недавно появился появилась поддержка асинхронных генераторов по сути асинхронный генератор в ноги это и есть stream то здесь вот пример например мы сделали запрос в мангу получили курсор завернули этого синхронный генератор и в итоге получили стрим который дальше можем попить и получить получаем все те же + 1 bresser там и прочие вот эти вот фичи ну из коробки просто в три строчки и еще один такой интересный момент например api ребята не поддерживает добавление задача в очередь и патч когда только по одному если делать это вот по одному это будет очень долго да то есть 140 миллионов сообщений последовательно добавлять это очень долго ну и там например не выйти ну это же aside for на операция ноги мы должны забыть и до результат если мы не выйдем не ждем окончания цитата то очень легко мы не контролируем какой объем данных сколько сейчас сообщение висит сколько отправил скука не отправилась в итоге у нас получаем опять out of memory тут простое решение в данном случае мы воспользовались готовым npm пакет promise pools of что мы говорим вот под наша задача от 500 активных промазав как только один форме завершается он стартует следующий но соответственно под свои ресурсы можно там это цифру подогнать каком удобно и эти же принципы это мы говорили на уровне 1 но даже скрипта носом деле этот же принцип по крайней мере прошло можно применять на уровне всей очереди на то есть желательно чтобы тот кто добавляет задание в очередь он проверял какой-то проверял сколько там уже есть сообщение и не добавлялась лифтом слишком много а ждал пока вот этот количество сообщений уменьшится несколько моментов который мы столкнулись именно во время парсинг а сайтов вообще там очень много все равно страну встречается и конечно нужно обязать вообще данным этим нельзя доверять исходите из этого да то есть нельзя доверять этим данным всегда пишете код так и соответственно два таких основных момента этот тайм аут тайм аут и могут на любом этапе при установке соединения во время ответа и так далее то есть везде надо жестко выставлять лимиты и на тело ответ естественно то есть у нас были случаи когда с главной страницы сайта отдается pdf к там на сотни мегабайт но спасибо почитаем другой раз и вот эта проблема с фатальной ошибкой в нашем случае это была проблема с сертификатами то есть нашлось несколько сайтов у которых такие составе сертификаты от которых надо просто разваливается с этим ничего нельзя поделать на этот случай нам нужно просто добавить такой механизм в ноги вернет вот этом механизме работы варваров которые достают задание из очереди что если мы там берем это задание уже там например в третий раз готов значит всё это плохой плохой домен простоте его ему в отдельную очередь и дальше уже потом а кто-нибудь отдельно посмотрит что не так с этим доменом может быть можно какой-то фильм сделать то может быть ничего нельзя сделать как и в случае с с сертификатами это вот мы сделали на уровне от красоты интеграция между очереди задачи маркером немножко капитанство если что-то может пойти не так она обязательно пойдет не так особенно когда нагрузка меняются на порядке то есть когда вот с миллиона там 10 миллионов 100 миллионов будет ломаться танк делают вы вообще не могли представить что может поломаться для этого нам нужно обязательно нужно иметь мониторинг причем мониторинг не просто по ресурсам там сколько там happy утратится там или памяти понятно это нужно но это не главное главное нужно выбрать некоторые продуктовые метрики в нашем случае это количество раз партийных сайтов и от него мы смотрим в процентах количество например неуспешных резонов проблемы с рисованным понятно что всегда будут какое-то качество сайтов которые не резолвится но если вдруг из двух процентов стала там 80 процентов ну что-то сломали значит нужно нужно разбираться что пошло не так значит наши оповещения приходят флаг мы разбираем их там из центре и вот из из мониторинга и так далее я тут не буду сейчас подробно строить у нас есть отдельный доклад если вам интересно прочитать про наш подход можно посылочки пойти посмотреть итак подытожим если вы делаете бота то делайте его этичным если есть возможность не делать год не делайте его восполнить воспользуйтесь готовыми да по сетами знаете те инструменты которыми пользуетесь из найти их преимущества и недостатки где они могут вас подвести нельзя вообще доверять никому в интернете и обязательно предусмотрите возможность отсеять по автоматически отсеивать какие-то плохие домен и потому что ну всегда найдут случай которые вы не могли даже представить что они могут вам сломать обязательно делайте мониторинг и оповещения у меня все спасибо за внимание так переходим к вопросам вспоминать какие вопросы вы хотели задать я пока хочу поздравить наградить евгения карагодина за выступление спасибо тебе большое отличный доклад а очень много я узнал про crawling как можно парсить доменные домену информацию как нельзя про amazon и про все остальное и так первый вопрос пожалуйста вопрос такой сама просто наверное откуда вы взяли 40 миллионов доменов тут я наверно вам не отвечу то есть в разработку этот список уже пришел готовым отличный ответ кстати да как как можно можно наверно празднуем например как как стартовой точкой может быть вот команд куда я привел пример там порядка 80 90 миллионов доменов ну это открытые данные то есть их можно брать оттуда можно можно просто по вы его пройтись по сайтам как пауком с сайта на сайт сайта на сайт он связанный или где то получим ну мы все мы в своем именно краулеры таким не занимаемся мы не мы не собираем ссылки из вот контента страниц но в целом наверно тоже можно пойти конечно но это довольно долгий путь так еще вопросы да да конечно так микрофон пожалуйста у нас онлайн есть нужно чтобы онлайне тоже был звук поэтому вопрос касается не парсинга можно задать или вот то касается плеска пожалуйста сейчас набирают популярность такая история что у нас накручивается pft поведенческий фактор вот и сейчас очень много среди вебмастеров баны с точки зрения яндекса то есть яндекс версия банят за то что якобы человека накручивает в день ческие факторы и google тоже также adsense но . с точки зрения вебмастеров блеска же про веб-мастеров и я хочу сказать что это сейчас большой ком набирает это проблема и история такая что поездки накручивают собственно не сам человек а накручивают скорее всего кто то конкуренты или еще кто-то и вот было бы здорово если вы может быть в крупных компаниях блеск может пойти ваши конкуренты может быть давали какие-то интересные решения потому что сейчас достаточно большое сообщество и мастеров страдать за в том числе потому что их им самим скликивают рекламу то есть на и заходит значит робот и скликивают рекламу тельцам банят аккаунт арся и adsense но и соответственно это тот человек собственно кто-то заказывает и это никак не осветить то есть по факту по факту это нужна защита от ботов правильно то есть ну на самом деле ну такие сервис средством числе я не могу сказать именно про поведенческий фактор дано обнаружением ботов занимается много кто то есть такие services том числе club flyer например детектив ботов ну окей тут на сайт есть pm он себе запишет хороший день взять его взять прямо на доклад я считаю так а еще кто-нибудь интересуется так у меня вопрос не пожалели ли выше то взяли моду вот на данном этапе все ли вас устраивает нет ли идей что абсолютно нет вот я собственно в докладе этого упомянул то есть у нас была единственная проблема с этими сертификатами в остальном вообщем у нас проблем не было с этим и папе фомс у нас полностью устраивал как он работает то есть при работе с сетью при crawling in оду в целом такой идеальный инструмент наверное можно рекомендовать да то есть тут очень моделью тогда синхронного и она очень подошла помогает а как альтернатива еще кроме голлинга может рассматривали или как взяли моду потому что лучше знака но да ну собственно мы выбирали из тех языков которые более-менее есть экспертиза в команде это были там . но do i go long но собственно на печке не очень хотелось писать потому что это будет немножко посложнее пары делать такой такой partir вот собственно из этих трех вариантов выиграл но джесс окей так же лучший вопрос он был единственный наверное да из зала больше нас не появился желающих задать вопрос какие нибудь так вот конкурент здравствуйте внимательно а вы сказали что стоят 300 долларов в месяц до вот этой вот именно вот эта машина просто прогоняет 100 миллионов или нет это это про эта оценка вот этих регулярного парсинга 11 миллионов доменов но мы их несколько раз в месяц там примерно можно прикинуть 40 50 миллионов примерно там оперативка процессор какой нужно там ну сами worker и они не очень большие то есть там либо самый маленький да либо 2 там по размеру инстанции в защиту если смотреть ему сравнивал почту то есть они достаточно нетребовательны именно как ресницы я начала не слушал это облако сейчас даже у нас в амазоне она работает"
}