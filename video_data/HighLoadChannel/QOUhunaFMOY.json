{
  "video_id": "QOUhunaFMOY",
  "channel": "HighLoadChannel",
  "title": "От 0 до 200 000 000 игроков — об эволюции бэкенда за 40 мин / Андрей Михеев (Pixonic)",
  "views": 13278,
  "duration": 2185,
  "published": "2023-04-28T06:21:30-07:00",
  "text": "Всем привет Меня зовут Андрей я работаю в компании pixonic там я занимаюсь развитием бэкенда для игры War robots Ну кто не знает это такой мобильный шутер в котором игроки с помощью больших ходячих роботов могут выяснить кто из них круче сейчас я занимаюсь игровым бэндом но вообще разработкой занимаюсь более 15 лет и за это время успел попробовать разные в хорошем смысле конечно же хорошо когда у вас в команде есть большой опыт в разработке конкретной задачи архитектура выверено библиотеке фреймворки отлажены вы просто можете взять и выполнить задачу но что делать когда в команде не хватает опыта готовых решений нет проект потенциальных highload А запуститься желательно было бы уже вчера собственно Мы оказались в такой ситуации Я хочу вам рассказать про наш опыт разработки развития бэкенда для большого игрового проекта О чем я не буду говорить я не буду говорить про код я не буду говорить про конфиги про настройку базы данных про схему миграции про настройку облаков я вам расскажу про наш выбор наше решение на наши ошибки и выводы которые можно из этого сделать О чем я вообще говорю что такое игровой бэкент Ну банально это набор сервисов которые обеспечивает работоспособность игры их множество условно их можно разделить на две большие части корр часть Это все что касается активного геймплея то есть игровой мир в котором перемещаются игроки стреляют друг друга что-то добывают выполняют какие-то задания имя это часть Это все что обслуживает саму игру эти сервисы занимаются хранением информации об игроке его вещах каких-то там танках роботов мечах все что у него есть они занимаются работой с деньгами и Здесь также очень важна социальная составляющая сервисах которые обеспечивают чаты кланы Лиги и прочие активности игроков вы начинали проект 2013 году на чем тогда можно было сделать игру в принципе если у вас медленный какой-то игровой Геймплей шашки шахматы или там пошагово какая-то стратегия выбрать технологию у вас огромный фактически вам подойдет любая технология которая позволит написать классический веб-сервис порыв http протокола который jeson Коми обменивается но если мы говорим про шутер выбор резко сужается фактически классическим выбором на тот момент для построения бкнд был Java или C Sharp на бэкэнде для написания сервисов и какая-то реляционная база данных для хранения информации Мне нравится постресс лично поэтому я его здесь отметил но также мой стиль или другие базы тоже вполне используются Когда Вы начинаете проект вы не знаете выстрелит он станет ли популярным и вам хочется сэкономить на старте поэтому многие выбирают на старте Облачное решение Фотон таких готовые сервисы которых не надо писать код они предоставляют какую-то функциональность для вашего бэкенда таким образом вот на 2013 год классический стейк для старта игры был Unity в качестве игрового движка Java или C Sharp в качестве платформы разработки и Фотон для каких-то частей Game сервиса и pastgress для хранения информации но мы выбрали кассандру если с шарпом и Java все понятно это популярная технологии индустрия по ним накопила огромнейший опыт то почему собственно говоря Кассандра Ну первое Кассандра это полностью децентрализованное решение означает что у Кассандры нет какой-то мастерноды или мастер сервера проблемы с которым может сказаться на всем кластере Кассандра дает повышенную надежность и масштабируемость ну смасштабируемостью Кассандры вообще все отлично Кассандра может масштабироваться практически линейно можно ноды добавлять на горячую в кластер даже версию Кассандра можно обновить не останавливая кластер компания netflix проводила эксперимент а не масштабировали кластер Кассандры от одной ноды до более чем 300 и на всем протяжении эксперимента получили практическую линейную рост производительности к плюсам Кассандра Также можно отнести то что она написана на Джаве Да поджали накоплен огромный опыт это удобно как его опсом так и разработчикам Понятно Как запускать как тюнить GLM все вот это логи ошибки также плюсом кассандр можно отнести то что она является пылесосом решением разработчик всегда может залезть вход и уточнить какие-то нюансы часто это бывает полезно у Кассандра конечно же не является Серебряной пулей у нее есть свои минусы первое с чем сталкивается разработчик Кассандра это то что у Кассандры свой собственный язык запросов в сиквель Да он похож на SQL внешне это создает ложное ощущение что вы уже умеете строить запросы в кассандре но нет придется изучать новый язык хоть он не очень обширный но тратить на это время придется второй момент который хочется выделить это то что в кассандре не предназначена для каких-то сложных выборок Когда у вас большие связи между таблицами вот это вот все не для Кассандры еще Кассандра нет полноценных транзакций нет полноценной поддержки Да у Кассандра есть какие-то свои гарантии на записи но это не то к чему Мы привыкли в классических базах типа Ну и к минусам относятся то что Кассандра написано на Джаве Конечно же это Java приложение и все минусы Java приложений кассандре вполне присуще немаловажным выбором в пользу Кассандра стало то что наша компания уже имеет опыт работы с кассандрой того как мы начинали так как нам хотелось запуститься побыстрее не тратить много ресурсов мы выбрали Облачное решение Фотон для Core части которая обеспечивает гейм и но сами решили писать Мета часть конкретно профиль его было достаточно для начала И для него выбрали Java в команде уже были джависты поэтому выбор как бы простой на тот момент команда разработки сервера была всего два человека пару слов хочется сказать о фотоне почему он это полностью готовый Облачное решение которое не требует разработки соответственно они дают максимально быстрый Старт в проекте нам нужно было не все от него мы использовали комнаты для объединения игроков и синхронизации состояния между ними обмен сообщения между пользователями чатик был Ну и конечно же Фотон как и любой полностью готовый Облачный сервис дает какое-то определенное количество боли в чем-то ограничивает для нас самым критичным было то что невозможно написать свою сложную бизнес логику для фотона то есть мы не можем загрузить туда какой-то код который будет выполняться в комнате и как следствие мы не могли обеспечить полностью честную игру для этого нужно авторитарный сервер который занимается отчетом игровой ситуации на старте архитектура выглядела минималистично просто наш сервис профилей который занимался хранением информации об игроках и Фотон сервер с профилем клиент на тот момент общался поверх http xml обычными запускались профиль вместе с нодами Кассандры на сервере и это простое решение вполне отлично работало внимательные зрители здесь сейчас наверное уже заметили что я сказал профиль не позволяет написать свою игровую логику А на схеме отсутствует сервис который обсчитывает игровую логику возникает резонный вопрос А где же наша игровая логика Кто занимается ее обсчетом так как Фотон не может профиль для этого не предназначен нужен кто-то третий участник кто будет заниматься этим отчетом придумать здесь можно разные но мы выбрали один из популярных вариантов это мастер клиент в этом подходе один из клиентов во время игры становится сервером для других участников игры он занимается определением начала окончания матча занимается определением точек спавна это места где появляются игроки на карте также определяют победу и поражение команды он занимается матчмейкингом матчмейкинг опытные игроки наверняка знают Это просто процесс набора игроков команды наверняка многие из вас помнят в школе учитель вызывает двух учеников они становятся капитаном они по очереди набирают себе игроков в команды по разным критериям там самый быстрый самый Ловкий и так далее как и в игре так и в жизни критерии отбора могут быть самые разные вплоть до какого-то машина который сможет подобрать идеальных партнеров игру чтобы было интересно не сильно легко и не сильно сложно как вообще может работать матчмейкинг на клиенте ведь это же ну по логике чисто для сервера тема Очень просто первый игрок который попадает на сервер он становится мастер клиентом и начинает набирать к себе приходящих игроков как только он набрал команды Он передает эстафету следующему выбирает самого старого клиента на сервере передает ему эстафету матчмейки на сам вместе с командами уходит в бой и там занимается вообще там это повторяется история и в общем-то кажется что эта схема идеально просто мы можем круто экономить на серверах мы перекладываем часть работы на клиента на тот момент у нас могло быть игроков порядка 12 человек только на карте на одной поэтому нагрузка на клиента в общем-то небольшая кажется что это идеальная схема ну всем удобно но Конечно же нет проблем В этой схеме хватает первое из-за того что у нас не два участника клиенты сервера три участника мы имеем проблемы определенной синхронизации стоит игроков У нас есть такой режим в котором по карте разбросаны флаги и игроки должны захватывать эти флаги и удерживать Чья команда удерживает большее количество флагов та команда и победила и были такие проблемы Что разные игроки внутри одного матча наблюдали разное состояние флагов также в теме шутеров невозможно сказать про стрельбу стрельба это критически важный момент но на тот момент попадание регистрировал сам клиент представляете ситуацию клиент слет сообщения и запиши там мамкин Киллер нанес мне 3000 урона записал и каждый клиент естественно вел свой собственный бой куда записывал все что с ним происходит в конце игры они скидывали это профилю профиль собирал информацию со всех игроков и решал кому что начистить кому награды Какие выдать и так далее вы понимаете да у нас верят на слово Это порождало вся эта подход порождал достаточно много багов то что флаги не захватываются там кого-то там нельзя убить что-то не начислили и так далее сюда нужно добавить еще момент что мобилки ненадежны Да мобильный интернет постоянно улучшается у нас там 4G 5G но история мобильного интернета это по сути история боли то есть там мы проблемы с пингами и с потерями какими-то сюда Нужно еще добавить что и игроки тоже ненадежны вообще никто не может заставить игрока доиграть бой А может любой момент психануть закрыть игру вообще удалить два клика он может заехать какой-нибудь туннель прерваться связь у него может батарейка банально сесть вот представьте себе классическая ситуация игрок заходит в игру он становится мастер клиентом набирает всех команду уходит в бой и тут ему звонят он естественно берет трубку игра сворачивается со всеми вытекающими проблемами для всех остальных игроков кажется что это вообще не может работать вообще никак проблем куча как вообще синхронизации там баги люди вливают но нет может и это даже неплохо работало саппорты тех лет говорят что было даже терпимо я уверен сейчас многие из вас подумали Да конечно все мы понимаем набрали джунеров там по объявлениям после курсов они там на коленке на каких-то облаках непонятных что-то понаделали Ну короче здесь может быть Результат чего вы ожидаете вообще но нет ребята поверьте Глупые люди у нас не работают все было просчитано Заранее у нас была задача нам нужны были максимально простые быстрые решения на тот момент мы еще не знали что игра не то что станет хитом что она хоть какую-то популярность наберет в игровых проектах вообще конкуренция очень большая игроки довольно требовательные здесь важно уметь быстро двигаться быстро находить свою нишу свои какие-то игровые механики быстро проверка гипотез это наверное ключевой момент который двигал нашими решениями в тот момент важно уметь не только быстро двигаться важно правильно выбирать направление и уметь быстро его поменять Если вы ошиблись механика на игрокам не зашла чтобы нащупать свою аудиторию со своими игровыми механиками на тот момент у нас было порядка 15-20 тысяч игроков и стали появляться проблемы с матчмейкингом одной из таких простых эффективных решений было по идее вот Любой человек который давно занимается разработка скажет вот у вас есть проблема нужно садиться ее решать разрабатывать архитектуру а если там это интерпретит нужно собирать там какой-нибудь архитектурный комитет что сначала выбрать что мы вообще решаем и так далее но у нас не было времени на это вылезла проблема с матчмейкингом что мы сделали Unity клиент Unity движок позволяет запустить Клиент не только на мобилках Но и на десктопе мы взяли Windows Клиент от нашей игры запустили его на офисном компе прямо на винде и запретили ему входить в игру в результате он занимался исключительно матчмейкингом он очень быстро остановился самым старым игроком на сервере у него идеальное подключение проводное с минимальным пингом он никогда не ливнёт из игры и в целом Казалось бы хорошо Ну там тема клиента это отдельная тема Но это решение работало полгода Отлично Когда нам понадобилось его масштабировать мы просто запустили несколько импульсов клиентов на Windows машинах на тот момент мы получили фичеринка Google игра набирала популярность запустили нашу маркетинговую компанию и получили кратный рост игроков на тот момент где-то порядка 300 тысяч игроков было конечно вылезли проблемы с нашей архитектурой вылезли проблемы с читерами Ну в любом популярном проекте количество нечестных игроков достаточно большое с этим тоже нужно будет что-то делать в дальнейшем Но самое главное момент мы получили проблему с пациентом на тот момент мы хостились не очень центре и у нас были проблемы с железом сетью стало понятно что нужно переезд в другой дата-центр в тот момент у нас состоялся первый переезд между дата центрами А всего будет два здесь Нам очень сильно помогла Кассандра Кассандра полностью децентрализована конечно тема переезда довольно обширна но я Коротко расскажу как мы смогли переехать без простоев мы запустили новый бкнт в новом дата-центре запустили Там новое кольцо Кассандры кольцо Кассандра это кластер в одном дата-центре синхронизировали со старым бэкендом Так что у нас Кассандра стала единым кластером и переключили на старом бэкенде сервера в режим когда там новые игры не создаются в результате игроки доигрывали на старом бэкенде игры а новые они уже запускали на новом бэкенде Так мы плавно Переехали из одного до центра в другой и игроки даже не заметили что в процессе игры они переехали из одной страны в другую тот переезд у нас прошел без проблем что нельзя сказать про второй Об этом я подробнее чуть позже скажу и здесь же нам стало понятно что Фотон Клауд не позволяет нам развивать проект так как бы мы его хотели стало понятно что Фотон клауду придется избавляться и разрабатывать свое собственное игровое решение первое чем мы подумали это конечно же Unity Он позволяет запустить сервер таким образом максимально переиспользуя код игры но на тот момент он был не очень хорош у него были проблемы с производительностью память тепла его нужно было регулярно перезапускать люди делали что дуллеры которые перезапускали с определенной частотой сервера отказались нам не подходит обратились свое внимание на Фотон СДК у фотона помимо облачных решений есть свой с помощью которого можно разработать свое игровое решение и запустить на своих серверах получив авторитарный сервер конечно же нам весь sdk не нужен был мы взяли какие-то части и разработали свой Game сервер в итоге получили вторую версию своей архитектуры в которой помимо профиля появился курс сервер который обсчитывал игровую логику мастер сервер здесь занимается балансировкой Game сервисы рассчитывают саму игру прочитывают Ну и в общем-то стало все намного лучше но оставалось по-прежнему одна проблема игрок все еще регистрировал попадание по себе сам конечно же с таким количеством игроков с читерами вылезла прям серьезная проблема стало понятно что ее надо решать быстро здесь мы тоже не стали изобретать грандиозных решений потому что полноценно сервер который позволит обсчитывать стрельбу это означает нужно переписать пол клиенты инвестировать мы придумали другое решение что-то среднее между авторитарным сервером и расчетом урона на клиенте изменили всего одну вещь в нашей схеме теперь игрок регистрирует попадание не сам по себе а все игроки в комнате регистрируют попадание по всем другим игрокам в комнате и отсылают эту информацию на сервер у сервера появляется кворум решение от всех участников и они соответственно уже не могут так просто читерить и говорить Что по ним нанесен какой-то там мифический урон или не нанесен вообще Глядя на график можно заметить Как изменилась количество синий график показывает количество обращений учителем как только мы запустили свой авторизованный сервер мы получили снижение количества жалоб там был еще небольшой хонфикс не убивашками когда игроки манипуляции сетевых пакетов добивались того что в какой-то момент нельзя было убить но после небольшого ход фикс все было исправлено говоря про игровой проект Ну и в принципе это касается любого развивающего проекта невозможно не сказать про мониторинг Мониторинг это очень важная тема важно знать что происходит с игрой Что делают игроки у нас был свой проект уже Мы здесь положили себе соломку Называется он отметр Он позволяет собирать игровую аналитику Он построен на кассандре именно в работе над этим проектом мы получили большой опыт с кассандрой об этом проекте рассказывали в 2019 году на хайлоуди надо сказать что в данный момент на нашем проекте порядка одного миллиарда событий в сутки собирается это все вместе игра продолжала развиваться стало понятно что от всех решений Фотон нужно отказываться потому что даже с текущим решением у нас были проблемы с производительностью он плохо использовал железо проблемы с многопоточкой были и Мы приняли решение сказаться от всех решений фотона и разработать все сервисы которые нам нужны полностью с нуля сами для Геймс сервера мы выбрали iconet Ну надо сказать что историю когда игроки объединяются комнаты обмениваются сообщениями между собой Она отлично ложится на отторную модель мы разработали все сервисы которые нам нужны говоря про сервисную архитектуру невозможно и бурно развивающийся проект невозможно не затянуть не затронуть тему себя сиди конечно же игрокам не нравится когда они заходят на проект а там табличка подождите Мы находимся на обслуживании это также не нравится бизнесу потому что простое это прямые убытки убытки ключевым моментом здесь является обратная совместимость кода и конфигурации Потому что нельзя в один момент зарядить и серверы клиент всегда будет какой-то лад между ними я говорю даже не про то что в AppStore там и Google Play невозможно быстренько выкатить релиз зачастую это не занимает я говорю про то что у вас 200 игроков 200 миллионов игроков Как быстро они обновят свои клиенты Как быстро все это произойдет поэтому сервер должен уметь работать как со старой версии клиента так И с новой как мы этого добиваемся да у нас есть план и мы его придерживаемся У нас есть план не просто релизов у нас план на каждую версию релиза куда мы заносим все что надо сделать изменить конфликт настройку запустить какой-то скрипт что-то еще сделать у каждого плана каждой версии есть свой ответственность за релиз который занимается только реализацией этого плана и Мы также следим за чистотой кода мы постоянно удаляем старый код который уже не нужен прям в ходе помечаем аннотация депрессии код который нужно удалить ссылкой на таску в джире и тоска попадает в план по плану я там через зритель выпиливают также Мы серьезно продумываем миграцию данных в этом процессе и у нас есть несколько уровней тестирования есть соответственно есть ручной тестирование тестирование мы проверяем естественно и работу со старыми с новыми версиями и мониторинг ошибок конечно же является очень важным моментом получили архитектуру в результате 30 изменение здесь не так много появились новые необходимые нам сервисы которые обеспечивают работу игры как многие уже наверное заметили У нас появился подгресс Да есть сервисы у катка для которых возврасть подходит гораздо лучше у них сложные связи между объектами нужно строить сложные запросы данных Там намного меньше чем в кассандре во время разработки новых сервисов Мы конечно же не удержались экспериментов и написали таки пару сервисов на скале также попробовали еще котлин но котлин нам в итоге не зашел и у нас остались на проекте Ну говорить про бурно развивающиеся проект и не сказать про какие-то факапы просто невозможно первое что мы сделали Мы за дедосили сами себя выкатили новый релиз он делал довольно жирненькие запросы бэкэнду и бэкенд не выдержал тем паче что это происходило вообще просто по классике пятничный релиз вечером у нас корпоратив мы там разливаем шампанское буквально и мониторинг нам такой Ребята вы не хотите посмотреть у вас на сервера складывается выводом из этого стало то что у нас появилось такое понятие как фьюче флаг новая фича разрабатывается с учетом того что у нас есть рубильник который мы можем включить и выключить эту фичу раскатывается она в релизе в выключенном состоянии мы проверяем что все по старому хорошо работает включаем ее причем У нас есть диммер мы можем включить на 10-15 20 процентов игроков насколько нам надо и когда убедились что все хорошо мы запускаем на всех игроков второй момент в 2018 году у нас остался второй переезд в дата-центр здесь уже не Обошлось без проблем были ошибки в конфигурировании Кассандры что привело к потере части данных тот момент мы восстанавливались из бэкапа Да это привело к тому что мы стали гораздо гораздо тщательно прорабатывать схемы миграции данных на данный момент у нас больше 170 серверов разбросанных по всему миру больше 200 миллионов игроков три с половиной миллиона игроков играют каждый месяц и полмиллиона играют каждый день в кластере Кассандры больше 80 терабайт данных на 65 нодах и мы обеспечиваем 45 релизов в год без простоев команда на севере разработки на данный момент порядка 10 человек архитектура на данный момент выглядит вот так внешне не сильно изменения но принципиальные изменения произошли внутри профиля мы его сильно префакторили И теперь мы разрабатываем по ddrs по красоте все делаем это конечно отдельная обширная тема очень интересная Возможно мы в будущем расскажем о том как мы это делаем архитектуру устоялась все хорошо Казалось бы можно успокоиться развивать уже непосредственно игру какую-то но мы не остановились на развитие нашей архитектуры наметили для себя определенные точки роста Первое это из-за пессимистичных блокировок у нас очень много из-за того что в кассандре нет транзакций у нас много пессимистичных блокировок происходит этот тормозит в целом систему хотелось бы облегчить и улучшить у нас много взаимодействия И хотя мы над ним постоянно работаем вначале Это был какой-то xml сейчас у нас место Шпак здесь все равно еще есть куда улучшать схему также внутри профиля это самая нагруженный сервис у нас Мы хотим перейти к кластеру это позволить уменьшить позволит уменьшить время вызовов приблизить в данные как непосредственно вызывающему коду но это тоже отдельная Тема и вместе с ddd мы об этом Может быть расскажем следующих каких-то докладах как мы это делаем как все это связано также мы оптимизируем игровой протокол в начале у нас были довольно таки запросы между клиентом и сервером А сейчас мы переходим к ситуации когда у нас состояние между клиентом и сервером синхронизировать небольшими сжатыми дельтами это очень серьезно оптимизирует работу сетью Ну и мы перевозим часть логики с клиентом на сервер как это сейчас модно говорить для улучшения игрового опыта архитектуру которую мы стремимся следующая версия это 5.0 Как мы называем условно Центральная часть что здесь изменилось это появилась Кафка для межсервисного общения появился как кластер на профиле и протокол заменяется на grpc других каких-то принципиальных отличий от предыдущей версии здесь Нет в основном улучшение внутренней идут какие выводы можно сделать из нашего опыта Ну первый банальный где-то даже капитанские вы не Google вовсе не обязательно строить свой проект самого начала с расчетом на то чтобы утром завтра проснетесь к Вам пришел миллиард игроков вы к этому готовы не придут Хотя с другой стороны второй важный момент это из нашего опыта переездов и развития бкнда сложнее всего менять данные с кодом достаточно Просто вы можете что-то пофиксить что-то улучшить Вы можете даже предыдущую версию выкатить в большинстве случаев если что-то пошло не так с данными так быстро откатить не получится если вы зафокапите данные это практически гарантированное простое вплоть до того что вы можете потерять данные вообще в принципе и даже если у вас есть бэкап Ну представьте вот у вас 100 ТБ Backup Как быстро он катится на ваш кластер Сколько времени пройдет сколько это будут простое занимать как следствие из этого всегда нужно перепроверять конфиги схемы миграции к этому нужно относиться максимально тщательно Ну и конечно же нет каких-то абсолютно верных универсальных решений которые вы можете просто брать и не глядя к себе применять всегда нужно переосмыслять для вашей ситуации то что вы делаете не всегда стоит опираться на какие-то готовые решения из учебников в своей работе Мы всегда стараемся исходить из наших конкретных задач и потребностей а впрочем Вы можете не использовать наш опыт Вы можете выбирать свой путь выбирать свои шишки собирать свои грабли это порой бывает конечно болезненно Но зато очень интересно удачи Спасибо за этот интересный рассказ и ваши вопросы поднимайте руки и микрофоны к вам придут Вот я вижу здесь первую руку Да здравствуйте Я хотел спросить про не думали вы о замене Кассандры на более производительное решение на сциллу db это в принципе та же Кассандра на написанная на оси плюс плюс сейчас в данный момент Вполне устраивает и производительности поэтому Пока не рассматривали Спасибо еще вот здесь вот у нас есть вопрос в этой же секции Здравствуйте спасибо за доклад Анатолий зовут А вот у меня два вопроса Первый акка исишарплеев шаг А почему нет у нас в команде используется C Sharp Sharp мы Пока не рассматривали Как вариант а второй вопрос а правильно услышал что вы мисочку используете сейчас для хранения данных для транспорта да для транспорта не смотрели в тарантул Нет пока не смотрели Ну у них тоже место Шпак где транспорта используется Ладно спасибо большое было очень интересно Спасибо вот там я вижу руку а пока идет микрофон Мне кажется не так интересен вопрос почему одновременно начинали проект мы с жабой так как у нас команде А в дальнейшем для гейма это удобно потому что можно использовать код банального клиентам спасибо а потому что Unity Можно пожалуйста пару слайдов назад еще Да вот здесь нарисовано достаточно развесистая схема куча взаимосвязи кучей сервисов и 200 миллионов игроков почему выбрали разные хранилища И как вы основываясь на прошлом опыте с потерей данных Как вы сейчас все это бы копите обеспечиваете сохранность сервисная архитектура сервиса независимы используются то хранилище которое максимально эффективно для задачи которые выполняет сервис Backup У нас есть Поэтому подстрахованы и как я уже сказал мы очень тщательно Подходим к миграциям и к работе с данными в целом можете рассказать про ошибки какие-то может быть подводные камни которые с этим делали и как обеспечиваете я понимаю чтобы капы есть но когда бэкапы многих хранились Как вы целостность их обеспечиваете это очень обширная тема Давайте ставим после доклада пообщаемся я расскажу вот здесь вот у нас есть руки в этой секции Здравствуйте а почему выбор архитектуре у вас запланировано применение Кафка она не например панда есть опыт работы с капкой замена Кафки но написано на Расте и при этом значительно производителями возможно но мы его не рассматривали Пока не рассматривали Да не рассматривали Спасибо за доклад Я уже на втором докладе слышу про выключатели фич Ну то есть про то что гриль вы отключаете фичу включаете на 10-15 процентов клиентов второй раз слышу про это и вот вопрос такой вот не связано ли это с какими-то может проблемами в тестировании потом выключатель фич зачастую наверное приводит к дублированию кода и не знаю Вы выпускаете 100 фич вас то выключателей потом выпускаете еще 100000 у вас еще 100 выключатели Как вы этим управляете Ох это тоже довольно обширный вопрос если коротко мы подчищаем старые вещи они уже работают постоянно Ну это короткий ответ на ваш вопрос собственно говоря А длинный можем общаться пообщаться с вами еще вопросы если у нас Да вот здесь вот по поводу план релиза и одновременно итеративное удаление старого кода вы включили этот пункт план релиза или он выполняется маленькими командами разработки И вообще сколько вас команда разработки команды разработки там 10 человек на данный момент удаление старого кода как я сказал в коде прямо помечаем аннотацией ссылкой над жиру задача с жира попадает в план попадает к какому-то разработчику он вычищает старый код который уже не нужен"
}