{
  "video_id": "RtiJbb8Kz98",
  "channel": "HighLoadChannel",
  "title": "Когда нужно делать свою базу данных / Александр Бирюков (Тинькофф)",
  "views": 1427,
  "duration": 2435,
  "published": "2024-10-29T03:07:37-07:00",
  "text": "Всем привет давайте начнём Меня зовут Саш Бирюков и сегодня расскажу когда делать свою базу данных а коротко познакомимся программирую на Java последние 7 лет инженер программист а последние 2 с по года работаю на проекте S над собственной базой данных для логов немного контекста платформа нь of Sage - это observability платформа в которую сливаются логи метрики и трейс со всего банка и система обслуживает интересы мониторинга всякую автоматизацию вокруг него контекст закончен поговорим о плане сначала рассмотрим Что такое логи после этого посмотрим на рынок готовых решений поговорим про реч а в конце обсудим как сделать поиск быстрым а хранение эффективным перед тем как начать Давайте дадим определение что такое собственно логи логи - это хронологически упорядоченные записи о каких-то событиях такая текстовая телеметрия 10 лет назад логи выглядели следующим образом у нас есть колонка timestamp и есть поле mess в котором написано всё-всё-всё сейчас логи уже так никто не пишет логи пишут структурированном виде для этого Хорошо подходит формат типа G и типовой конвейер работы с логами состоит из следующих трёх частей Первое - это сборка нам надо как-то доставить логи приложений в хранилище второе надо хранить логи каким-то образом чтобы они были доступны для поиска и третье собственно поиск нужно предоставить AP чтобы пользователи разработчики аналитики могли делать запросы и получать необходимые данные Так давайте начнём с обзора решений Но перед тем как будем составлять список проговори требования что мы ожидаем от таких систем первое мы ожидаем быстрый поиск у которого есть богатый язык второе мы ожидаем что логи можно присылать в разном формате потому что приложений много они все пишут по-разному третье мы ожидаем масштабируемости потому что бизнес постоянно растёт ну и соответственно мы должны за ним успевать четвёртое - Это стоимость мы не должны превратиться в чёрную дыру для бюджета пятое - это безопасность в системе должен быть аудит поддержка титон шестое нужны какие-то интеграции внешние и седьмое нам нужно чтобы система не превратилась через полгода год в тыкву начнём с проприетарный решений это крутые продукты но у них есть одна проблема их нельзя купить даже До двадцать второго года купить их было проблемно Они не хотели работать в РФ А после уже и подавно поэтому рари не будем а просто поговорим про Open Source решение на доклад у нас будет следующий список elastic sech ly и Open observe существуют и другие решения например Victoria logs Но их на докладе мы рассматривать не будем и здесь важно упомянуть контекст в котором мы рассматриваем такие системы это Enterprise контекст мы считаем что наше хранилище имеет хотя бы размер 1 пиб а поисковый поток запросов 10 rps может показаться что 10 ПС - это очень мало но один запрос может запросто привести к анализу нескольких терабайт логов начнём с эластика это наверное такая первая система которая приходит на ум когда мы говорим слово логи это король универсал которого все пытаются убить у эластика очень много эластико заменителей все они в лом они все очень похожи это универсальные реше главное их достоинство и в то же время проблема и небольшое демо из нашей системы Sage которая на текущий момент построено на базе elastic sech на слайде Вы можете видеть Запрос который считает Сколько за последние сутки пришло Лог записей в систему если мы возьмём средний размер записи за 1 кб у нас получится 1,3 теба логов Но что самое интересное время запроса такого ставляет меньше о секунды тоже самое происходит с точечным поиском тот же самый объём данных тот же самый поисковый диапазон время поиска меньше оно секунды почему это так быстро работает эластик использует обратные индексы они позволяют обрабатывать терабайты данных за запи деградирует Но тогда возникает вопрос вроде бы несущественные минусы какие-то может показаться за такую супер быструю скорость но это не так обратные индексы - Это очень дорого системы типа эластика не разделяют сто и компьют в итоге когда у вас становится очень нхм приди вы достигаете того что масштабирование системы происходит уже не дисками цпу а целыми серверами для контекста предыдущие запросы выполнены на следующей конфигурации серверов так с ластиком закончили поговорим про Локи это крутое решение коробочное которое хорошо интегрировано в общую экосистему графана Ключевое нововведение Локи - это разделение потоков записи и чтения У нас есть выделеные приложения которые пишут данные и читают данные и складывают и всё это хранится в каком-то объектном хранилище Ипа S3 такой такая архитектура позволяет Независимо масштабировать все три ключевых аспекта системы то есть поиск хранение и сбор второе Ключевое отличие Локи - это отсутствие обратных индексов то есть Локи просто сказали мы не будем использовать обратный индекс и мы будем искать данные форсо это позволило добиться степени сжатия около 10 раз но у этого как бы есть цена как бы у нас получается куча данных по которым как-то надо вот искать вместо этого Локи предлагает концепцию Log Stream Что это значит в логе мы берём некоторое поле и используем значение из этого поля как дискриминатор то есть например логи с уровнем Ио один ф с уровнем в другой файл Ну и таких полей мы можем выбрать несколько тут Важно заметить что нельзя выбирать высока поля потому что это приведёт к экспоненциальному взрыву файлов Ну вроде бы 10 и по месту круто но есть проблема Даже несмотря на не может обрабатывать большие об данных для аналитики и точного поиска представим следующую ситуацию У нас есть тот же самый запрос сколько записей было за последние сутки это 1,3 траб мы сжимаем их в 10 раз получаем 130 ГБ теперь эти 130 ГБ нужно доставить из хранилища распаковать И после этого обработать если мы возьмём скорость обработки за 3 ГБ в секунду нам потребуется 430 вычислительных я если таких запросов будет как бы 10 нам потребуется в 10 раз больше Ну и понятно проблема запросы будут исполняться минутами в целом Локи - это хорошее готовое коробочное решение и если вы готовы использовать Локи таким образом как задумали авторы Локи то у вас всё будет хорошо Но если вам нужна аналитика или точечные поиски на больших данных то Локи не подходит Окей закончили теперь поговорим про проект появился этим летом Давайте нанм с описания Нам обещают систему которая будет в 10 раз проще в 140 раз дешевле по охранению там супер быстрая В общем короче интригующе звучит Давайте посмотрим что там вообще находится Локи архитект обм приложение для записи есть объектное хранилище пое это видели уже в локе есть А в чём тогда секрет здесь чтобы ответить на это вопрос надо спуститься на уровень ниже в проекте используется под названием который помогает разрабатывать распределенные вычислительные системы ком которая описывает протокол общения распределённый с движок Data Fusion протокол для передачи сетевых данных и паркет формат хранения коротко это можно обозначить как в D ключевой отличие от Локи - это формат хранения паркет паркет не отказывается от идеи обратных индексов Точнее он не отказывается от идеи индексов в формате паркет присутствуют вспомогательные структуры данных которые позволяют ускорять запросы за счёт координации поискового слоя и слоя хранения при этом формат тоже поддерживает сжатие и в среднем позволяет сжимать данные в 5 тире 10 раз а ну у этого как бы есть небольшие минусы проект является набором библиотек это не готовый продукт а второе паркет - это колоночные формат с жёсткой схемой Поэтому если у вас будет происходить изменение логов Вам нужно будет как-то обновлять схему данных продумывать её эволюцию и третье э Data Fusion - это универсальный SQL движок поэтому некоторые специфичные оптимизации о которых мы поговорим дальше может быть сложно добавить в среднем в целом э проект очень крутой и я думаю в ближайшие несколько лет появится э ещё больше решений на его основе именно для рынка хранения логов уже сейчас помимо Open на перешли inf db в третьей версии и проект В итоге получаем следующее эластик супербыстрый но дорогой Локи с крутой экосистемой но не хватает скорости поиска и которого тоже всё замечательно Но это конструктор зде Вот это сравнение оно сво для значили в начале то есть у нас есть точечные поиски аналитика 1 петабайт данных в целом если у вас сценарий отличается надо проводить сравнение самостоятельно на своих данных и на своих шаблонах использования Окей посмотрели что есть на рынке Давайте перейдём к рес здесь надо ненадолго вернуться в прошлое в девятнадцатом году в тенькове активно использовался проект н то есть вся инфраструктура хранения логов банка была построена на сплан и в какой-то момент сплан сказал мы уходим из России Вот и в команде разработки поставили цель нужно написать свой сплан который будет похож на сплан работать Как сплан выглядеть как сплан ну короче сплан нужно Это для того чтобы перевести все тысячи систем которые пользуются системой сбор и хранение логов Ну безшовна чтобы люди ничего не делали вот мы сделали такое же сравнение посмотрели что есть на рынке и лучше всего для этих целей подошёл elastic сч а подошёл он почему в сплан есть полнотекстовый поиск и возможность делать аналитику на больших диапазонах второе сплан не имеет никакой схемы и позволяет лить логи в произвольном формате вот через 2 года проект вырос и полностью заменил сплан в теньков но при этом выросла его вырос его размер То есть если говорить в цифрах это 10% всех серверов теньков на тот момент такой объём серверов очень большая операционная сложность и подробнее про это можно почитать в статье Рома Николаева он делится советами как её побороть для эластика прим проблемы с элам на таком объёме не только мы одни столкнулись с такими проблемами например в д втором году СК объявил что разрабатывает собственную базу данных как замену elastic примерно по тем же причинам В итоге в двадцать первом году мы поняли что надо что-то с ластиком делать первое что мы решили попробовать это поискать альтернативы там какую-то другую базу данных из уже существующих но всё упиралась в требования напомню что нам нужен полнотекстовый поиск нам нужна аналитика и Нам нужен формат данных который нас не ограничивает вот мы думали например использовать ха но в кликхаус очень жёсткая схема поэтому он нам не подошёл также мы думали над форком elch но здесь нужно понимать что проек это такой Монстр на несколько миллионов строк кода команде разработки из чех человек внести архитектурные изменения в такую кодовую базу за короткий срок просто нереально В итоге приняли решение вписать свою базу данных цель быть проще стоить меньше и хорошо масштабироваться в два первом году появляется проект HB первый прототип был очень пож концептуально на эк за несколькими исключениями вопервых Master система то есть такую систему очень гко добавлять сервера и удалять по требованию но раз это мала система то нам нужна какая-то синхронизация вот обычно для этого используются алгоритм консенсуса но мы решили пойти немножко другим путём и убрали консенсус вместо этого появилось состояние которое контролирует S иннер другой важной фишкой первого прототипа была поддержка У нас есть богатый язык запросов в котором можно делать аналитику но иногда пользователям Этого не хватало То есть им хочется добавить какую-то преобра отку постобработка вклиниться куда-то посередине и мы подумали что будет прикольно сделать DSL язык э например на дсе и через платформу ль VM э исполнять Вот но эта идея провалилась э потому что ль VM при взаимодействии разных ран таймов конвертирует все объекты через внутреннее представление Л В итоге на такой конвертации мы теряем очень много ресурсов и когда мы убрали производительность выросла где-то на 50% сделали какие-то тесты поняли ошибки и внесли следующие изменения в новом прототипе во-первых У нас появился отдельный маршрут для записи существует такая проблема когда запись поиск происходит на одном узле потоки поиска и потоки записи дерутся За ресурсы и в итоге происходит Котен и начинает деградировать что поиск что запись а мы обратили э внимание на такой факт что логи неизменяемые То есть их можно обработать один раз и положить м в специальном какой-нибудь формате в какое-то хранилище Ну и как бы сделать вот такой выделенный поток а мы начали хранить логи небольшими кусочками по 100 мб как такой последовательный поток И последнее что мы сделали убрали обратные индексы наоборот сделали обратные индексы но не на основе а на основе Ro db они получились Чуть более легковес снова сделали тесты и упёрлись в некоторую производительность поиска Ro db в jav не поддерживает частичную дереализацию данных есть у нас по ключу в значении лежит какой-то массив Мы обязаны прочитать его целиком Например если нам нужен только сотый элемент там мы не можем его прочитать то же самое происходит с пум вот ну и в итоге мы пришли к такой развилке надо что-то делать первый вариант писать своё qv хранилище мы изучили опыт других команд из и иро db и поняли что это супер долго и не факт что у нас получится написать быстрее чем ну поэтому мы от этого варианта отказались второй вариант переходить на язык с памятью ну здесь ситуация аналогична у нас уже есть какие-то наработки это снова такой стоп проекта на какое-то время и не факт что это поможет остаётся искать третий вариант Мы подумали несколько недель и решили пересмотреть конп прое в это мы разли ь То есть у нас появились некоторые узлы которые занимаются только поиском и узлы которые только вот пишут в объектное хранилище типа S3 Мы ушли от обратных индексов но вместо них добавили структуры которые дают примерно такой же эффект но за гораздо меньшую стоимость в итоге мы получили архитектуру которая очень похожа на Локи самом такая архитектура этото она называется SH Nothing и была придумана ещ в прошлом веке подробнее про такие архитектуры можно послушать на докладе Олега Бондаря про дизайн выхо нагруженных систем Окей архитектуру придумали теперь надо понять как сделать поиск быстрым а охранение эффективным для распределённых систем существует три основных подхода ускорений это уметь обм трафика у на Узел это ускорить декодирование данных и последнее мы должны максимально это ВС параллели у SH Nothing есть одна такая проблема по сути мы вот разделили Stage и компью у нас теперь можно Независимо масштабировать поиск можно Независимо масштабировать хранилище но возникает вопрос А что делать с пропускной способностью сети то есть у нас вот раба данных хранятся не обладает способностью даже в крупном дата-центре первое что мы сделали мы начали сжимать данные то есть мы берём 100 мб и Превращаем их в 10 ключевыми параметрами алгоритмов сжатия данных являются скорость сжатия скорость разжатия коэффициент сжатия И сколько ресурсов мы на это потратим для подобного рода задач на текущий момент существует два основных алгоритма это ZD и4 з std лучше сжимает но разжатие медленней lz4 наоборот хуже сжимает но супер быстро разжимает например ну как как выбрать что использовать zstd очень хорошо подходит для сетевых задач потому что мы экономим трафик lz4 Хорошо подходит для локальных вычислений например он используется в Click House и elastic чтобы экономить место на диске и другое важно мен разные алгоритмы ведут себя по-разному с разными данными например зст очень хорошо сжимает текстовые данные поэтому мы можем добиться экономии В 11 раз то есть 1 теба превращается в 90 гиб но одного сжатия мало а хранение должно быть дружелюбным к поиску то есть чтобы что-то найти надо иметь какую-то структуру данных и слогами у нас получается сдуй ша у нас на входе неизменяемые данные мы их один раз сохраняем А после этого много много много раз читаем и декодируй получается что нам нужен формат в котором можно избежать декодирование и при этом Мы помним наши исходные требования он должен иметь любой формат мы посмотрели на про вообще вот всё что можно и столкнулись с такой ситуацией все форматы поддерживают либо одно требование либо другое вот поэтому мы приняли решение написать простенький свой бинарный формат хранения этот формат обладает важным свойством Z Что это значит Это значит что мы не используем язык есть както храним поля вме этого в конструктор приходит просто массив бай и мы над этим массивом пишем какие-то простенькие акцессорное будет но её будет сильно меньше и она будет происходить по требованию другой важный момент 90% данных в логах - это строки поэтому мы написали Точно такую же обёртку и для строк назвали её она обладает точно таким же свойством а О'кей Теперь мы имеем структуру но можем ли мы зажать логи ещё сильнее если мы посмотрим на типичную Лог запись мы увидим что Она состоит из ключей и собственно значений полей если мы запишем ещё одну Лог запись мы увидим что а значения будут отличаться а ключи будут повторяться А давайте заменим ключи на числа сделаем такое словарное сжатие интернирование может показаться что Ну как бы заменили небольшие строки на небольшие числа что там изменится но тут лучше всегда посчитать запись справа имеет размер 300 байт запись слева 230 байт разница составляет 20-30 про Когда мы применили это на практике мы получили точно такие же цифры в итоге вот к тем оди одиннадцати кратному сжатию мы можем добавить е вот эти 20% и получим уже сжатие 15 ти 20 раз Ой храним теперь оптимально но теперь у нас возникают проблемы в ран тайме то есть ограничение надо Боро как-то ограничение сети стандартная практика является пропуск данных Давайте вот как бы мы вот сжали данные у нас 1 траб превратился в 130 ГБ но если мы укажем поисковый диапазон за 14 дней мы полум снова теже самые 1 вернулись в начало чтобы это побороть для таких больших диапазонов нужно вычленять только нужные данные то есть в формате хранения нужно организовать дополнительную структуру в локе это сделано в концепте Log Stream в apch паркет - это функция заложена просто по умолчанию формат мы не стали изобретать что-то новое и просто повторили оптимизацию у нас есть некоторый дискриминатор по которому входной поток логов нарезается по группам то есть в секции где систем рано А будут лежать логи в которых систем рано А ну и так далее В итоге такая оптимизация позволила сократить трафик примерно на 50% Окей на больших диапазонах теперь научились экономить память но возникает другая проблема точный поиск Допустим у нас есть полет его уже не получится как-то пропуск данных не работает чтобы понять как решать эту задачу нужно немножко изменить условия нам нужно понять блок данных содержит ли заданный токен Вот если мы поставим задачу таким образом то сразу становится понятно что её нужно решать фильтром Блума это вероятностная структура данных в которой иногда может быть POS но никогда нети в итоге мы весь входной поток логов тонизирует рядом с каждым блоком данных накладные расходы на такой фильтр составляют 1-2 про в не сжатом виде и где-то 5-10 про сжатым получается также что такой фильтр можно использовать как упрощённую версию полнотекстового поиска и использ это ФТ можно см об за сутки 1,3 раба логов мы их сжимаем получаем 130 ГБ используем фильтры это ещ в 10 раз меньше 13 ГБ и перед тем как скачивать блоки данных Мы скачиваем фильтры получается что фильтры откидываются ненужные нам блоки и Мы скачиваем только те где собственно есть нужный ID итоговая экономия трафика для точечных поисков составило до 10 раз и количество таких запросов в общем об и последняя на сегодня оптимизация сейчас у нас в основе поискового движка лежит некоторая распределённая распределённый движок распределённый движок на основе задач в своей сути он превращает вот на запрос на нашем языке в некоторое вот дерево Прим в нашем языке сотиров Ну по тапу пользователь может задать свою но она всегда есть и в итоге в этом дереве в самом корне будет соро всегда находиться сортировка слиянием но при этом пользователи часто забывают указать правильный поисковый диапазон А как мы знаем большие поисковые диапазоны это много данных система начинает задыхаться но при этом пользователю не нужны все эти сотни гигабайт данных ему нужны последние 500 записей в итоге поиск превращается в анализ вот 40 ГБ из которых нам нужно достать 500 КБ так как в самом верхнем узле у нас находится сортировка слияния и она ограничена по размеру у неё есть левая и правая граница что если мы будем рассылать вот эту информацию НТА информацию дочерним узлам получается что дочерние узлы смогут отфильтровать данные за счёт того что логи хорошо партиционирование одинаковому анализу блоков данных Вот но эта оптимизация работает только для хронологических данных собственно в этом её минус Окей поговорили про историю поговорили про системы хранения но так и не ответили на вопрос Когда нужно делать свою базу данных делать своё Нужно когда другое не подходит а не подходить оно может потому что его в принципе нет оно может слишком дорого стоить в обслуживании или его сложно поддерживать а при этом даже одной проблемы достаточно чтобы сделать больно а также есть стратегический вопрос А можем ли мы позволить себе делать своё нужно понимать что исследования - это всегда риски То есть реч может провалиться то есть нет гарантии что произойдёт успех второе - это долго а то есть наша разработка Идёт уже 2 с по года и третье есть некоторый поиск проблемы с поиском сотрудников Потому что работа в каком-то смысле наукоёмкость бизнесу напомню что текущая система составляет примерно 10% всех серверов теньков в цифрах это кластер из 350 ластиков достаточно крупных а общий размер хранилища 7 пиб Давайте просто посчитаем Сколько это может стоить например в каком-нибудь облачном провайдере А я понимаю что это цифры примерные но выходит что чтобы такой кластер обеспечить нам нужно 1,3 млрд руб в год а берём те же самые цены а убираем э точнее берём те же самые цены немножко правим цифры по серверам и диском и получаем что теоретическая экономия может достигать 1 млрд руб ещё раз скажу что цифры примерные но они позволяют оценить порядок вот а но как бы цифры - это одно а насколько оно быстро работает то есть Может ли такая распределённая система с внешним хранилищем побороть локальные обратные индексы А сейчас у нас есть тестовая инсталляция в которую 24x 7 зеркалит запросы А на небольшом подмножество групп а тестовая инсталляция примерно 4 ТБ и по цифрам мы пока конечно не можем догнать эластик но как цель мы себе поставили следующее на отметке 3 секунд Мы хотим перегнать эластик и у нас в принципе есть всё необходимое чтобы сделать это а левую часть графика сдвинуть влево Вот на этом У меня всё можете проголосовать за доклад готов ответь вопро подарка поэто времени мало поэтому быстро так вот сюда второй ряд и кто ещё вот туда в конец Спасибо большое за доклад очень любопытно по скажи пожалуйста вот Поиск под строки с помощью Таких вот течений вот там просто было регулярное выражение написано да медж звёздочка текст я может быть пропустил Вот это как-нибудь у вас сделано или не сделано сначала работает фильтр потому что это собственно такн но он тоже может не гарантировать Ну в зависимости от положения звёздочки и наличия пробелов вот если самый худший случай когда эта звёздочка слитая с под строкой тогда мы не можем дать использовать фильтр Сейчас вы получается для всех токенов сделали фильтры уже сразу в данных да а токен - это все слова Да но он очень маленький получается В итоге я понимаю но все слова нужно перебрать Откуда вы все слова знаете видимо неправильно объяснил Ну вот там у тебя было написано медж звёздочка текст Вот этот текст - это какой-то поисковый запрос это какое-то случайное сообщение да Вот его же не может быть в индексе Давай сейчас откроем вот да вот это вот вот ме вот конкретно здесь фильтры не будут работать а то есть такой фильтрации нету я пойду подскажу спасибо Вот там в конце Да и Давайте вот тому человеку наверху В прошлый раз ему не досталось Угу А есть ли планы на Open Source данные базы или хотя бы формата вот этого вашего Z ко Это сложный вопрос который треке уже будете рассказывать про это да да ну в идеальном варианте конечно хотелось бы это выложить Но это нужно как-то решать не нам вот но мы будем стараться чтобы это оказалось в опенсорс Ну вы хотите этого ну я бы хотел мы бы хотели с вами видишь уже заказы принимаются так Спасибо за доклад такой мясной по-настоящему хайло одной грудой А вопрос кажется что основные Ваши проблемы связаны с тем что на старте разработки решили что формат логов может быть любым вот сейчас на третий год разработки не считали Ну возможно кто-то пойдёт по вашим стопам вот если вернуться назад на момент принятия решения может быть всё-таки уговорить загнать все логи в какой-то конкретный формат и вот не проходить вот эти Все круги ада которые вам пришлось пройти из-за того что на старте были сформулированы именно такие требования Мы тоже об этом много раз думали э сложно ответить что было бы наверное мы бы взяли что-то готово то есть на самом деле в начале разработки я рассматривал apch и предлагал его использовать но всё ломалась о необходимость вот этого требования Ну то есть в деньгах не пробовали считать что будет если всё-таки заставить всех остальных ребят писать логи по формату и при этом гораздо дешевле и быстрее сделать вот эту хранил нет потому что ну в компании очень много разного софта и Ну сходу да непонятно сколько мы не считали Спасибо отнесите вот наверх микрофон поста СБО Вопрос такой в начале ты говорил что есть у CB некоторое состояние которым управляет дежурная сре что это за состояние как дежурный им управляют Я потерял тут тут тут а всё да состояние простое нужно сказать что узел находится в кластере или не находится оно максимально легковесные было ну мы там хитрым образом его сидит нон-стопом это чекает и как-то переключает м Ну не совсем это просто быстро не объяснить К сожалению в кулуарах тогда в я потом спрошу Да спасибо за доклад нейминг в программировании очень важен а вот с hdb Что значит звучное название И что это есть ли какое-то Ну у нас проект называется Sage мы делаем свою собственную базу данных То есть получается п само слово к придумал Зачем что это честно я не помню появление названия продукта То есть он появился вот в ВОМ году я ещё даже здесь не работал поэтому не могу ответить Понятно спасибо Кто ещё можно Уви есть например написать запрос Покажи мне количество ошибок за какой-то интервал она вот так уже не делает есть агрегацию не считает Нет наоборот считает это в требования заложено на самом деле это поисковый движок который умеет и с метриками работать плюс отдельно хранилище просто для метрик мы используем сейчас Вирия в том ле Ну то есть если я хочу посчитать пологам количество ошибок запросто строить там всё без проблем спасибо спасибо за доклад Вопрос номер один это вот вокруг всяких эластиков Локи Придумано много утилит вот вас види Прим что в какой-то момент придумают там lck 2 или ещё что-то и Блин у вас столько работы было проделано а под мониторингом и утилитами что имеется в виду ну Ну к тому же ластик сбор логов и ну как бы уже уже весь придуман А у нас в системе Sage уже написан свой сборщик логов и доставки это обз ability платформа А с hdb - Это небольшой компонент ну небольшой большой компонент Но доставка путь доставки логов уже сделан вопрос был скорее про то что эти системы они как бы коммьюнити их спонсирует за счёт своей работы у вас же будет ну чисто пока разработка в тинко и не боитесь ли вы Ну вот от того что в какой-то момент в пото Нова тех которая за счёт опен сорса за счёт комьюнити просто вас перегонит и вы будете либо Блин мы потратили 4 года на эту штуку нельзя выкидывать жалко Вот не боитесь попасть в такую ситуацию Ну если случится то случится как бы пока не случилось Вот и второй вопрос у вас Ну точных цифр не надо но руководство вас поставило то что вот вы достигаете вот таких-то целей и после этого показателе мы переходим на него или вот ещё непонятно В какой момент будет этот переход Мы в целом сейчас обкатываем на демо стенде наше решение и вот Готовимся в следующем месяце выкатывать это в прот на ограниченном числе пользователей дальше больше спасибо на этом всё надо выбрать три лучших вопроса Давайте про имя про индекс так про имя про имя это вот туда носочки Давайте про имя там у нас отдельно кто ещ Давайте Вот про фильтрацию и вот сюда кружечку так и вот там был вопрос про формат данных Да вот там да да Молодой человек вы по-моему да да туда и тебе Саш тоже подарок Сейчас вручат у вас мало подарков много да а тебе тоже подарок от организаторов спасибо очень классный доклад И вообще вы молодцы я вам желаю удачи вот а ответим эластик сечу Спасибо"
}