{
  "video_id": "3fJ5ptx5g7M",
  "channel": "HighLoadChannel",
  "title": "ТОП ошибок в инфраструктуре, мешающих высоким нагрузкам / Андрей Половов (Флант)",
  "views": 112210,
  "duration": 2825,
  "published": "2018-01-16T13:39:09-08:00",
  "text": "Здравствуйте друзья Меня зовут Андрей и я работаю в компании флан в качестве руководителя архитектора проектов на Ну а в зале сидит коллега который помогал мне делать Этот доклад его зовут Андрей клов и в случае чего он мне по содействует Наша компания занимается технической поддержкой им для лисо проектов и обычно это выт обм мы берм на обслуживание некий проект доводим его до ума и продолжаем обслуживать но теперь уже с круглосуточными дежурными и с гарантиями среди наших клиентов немало проектов которые может назвать высоконагруженные Так о чём же доклад Дело в том что на этапе доведения дома мы обнаружили многие чуют из проекта проект а иногда имеют общие корни А так вот мы эти кейсы решили собрать систематизировать и поделиться с вами собственно в течение доклада мы затронем кейсы которые связаны с базами с кодом с архитектурой сетью и не обойдётся без человеческого Фактора многие проблемы покажутся вам примитивными и очевидными и вы будете правы Но несмотря на это мы продолжаем с ними сталкиваться из проекта в проект и поэтому имеет смысл о них говорить а начнём Мы наш обзор с проблемами которые связаны с базой и начнём с приёма который игнорируют очень многие программисты речь идёт О транзакциях я думаю все вы знаете что это такое и я их раскрою с точки зрения производительности предположим У нас есть некий сайт который платит авторам деньги за просмотр их статей и нам для того чтобы показать одну страничку требуется выполнить четыре запрос в некую абстрактную базу данных и что за запрос мы берём собственно этот текст обновляем счётчик просмотров начисляем автору денег а потом эти же деньги списываем из бюджета проекта и в данном случае мы получим если мы эти запросы выполним напрямую в базу безо всяких транзакций мы получим четыре абстрактные дисковые операции в тоже время если мы завер эти четыре запроса в одну транзакцию то вместо все апдейт этих апдейт на диск только в том случае если мы выполним комит и таким образом вме операций мы получим две дисковые операции и таким образом мы сократим заметно нагрузку на систему особенно серьёзный прирост производительности вы заметите на операциях загрузки больших объёмов данных То есть например если у вас есть интернет-магазин вам наверняка приходится парсить прайс-листы поставщиков и заливать эти данные в свою базу так вот если вы все запросы все свои инсерты апдейты делаете по одиночке то наверняка ваша база справляется но реализует эту задачу Достаточно долго Но если вы завете все свои за Ну разобьёшь то дело пойдёт гораздо быстрее и база вам за это скажет Спасибо онно голом ptp понял дело в том что в mysql из коробки а включён автокомис запросы в данном случае прозрачны для пользователя заворачиваются в отдельные транзакции и программист об этом не думает и Лепит запросы как ему удобно так вот А если бы программист пользовался фреймворка то он бы незаметно для себя этой проблемы избежал потому что многие фреймворки все запросы которые генерирует программист как правило заворачивает в отдельные большие транзакции и данная проблема Ну для таких проектов просто не актуальна Как быть если под вашей ответственность оказалась база данных а вы при этом админ база данных которая генерирует большую нагрузку на диск и при этом не так уж много обрабатывает Ну по вашим ощущения алгоритм тут достаточно простой вам потребуется вытащить из базы запросов в случае Вы можете посмотреть или в и если вы увидите что количество апдейт то скорее всего ГТО чтото моп часто игнорируют многие программисты особенно на этапах когда проект молодой Дело в том что если проект маленький то и база данных у него скорее всего маленькая и с лёгкостью влазит в оперативку в таком случае любые запросы выполняются достаточно быстро Несмотря на то что не настроена никакая индексация и связано Это с тем что просто в оперативке пережать вся табли не так уж и накладно Но как только база подрастает то в этом случае таблички перестают влазить в оперативку и базе приходится всё чаще за ними ходить на диск и выгружать соответственно полностью но индексация у нас не настроена и из-за этого диск начинает проседать а вместе с ним проседают ваши запросы избежать всего этого можно было бы если бы программист уже на этапе Сония таблички хорошенько продумал возможные индексы которые м могут пригодиться но я понимаю что это в принципе не всегда возможно и поэтому правильным решением будет держать эти индексы в актуальном состоянии а то есть если вы добавляете в свой проект некий запрос то актуализирует индекс который у вас есть и всё у вас будет хорошо Итого а забыл про диагностику Если вы админ и в вашем хозяйстве вдруг оказалась база данных которая вдруг ни с того ни с сего начала медленно выполнять Казалось бы простые запросы даже без даже без Джо инов как же и пользоваться то для вас алгоритм тоже достаточно простой вам потребуется выяснить эти самые жирные запросы в случае поможет SL Если же либо какой-нибудь профайлер А если у вас поз гря Да ещё и настроен омер то вам Здорово повезло у вас уже есть замечательная табличка где все эти запросы аранжировать его эксплей вашей базы данных и добавляете недостающий индекс о котором Вам Этот expl скажет следующий кейс встречается достаточно редко но если встречается то выглядит он следующим образом есть у нас проект обслуживание у которого между базой и приложением перманентно летит по 200 мегабит трафика в то время как конечный пользователь получает всего 5 мегабит куда же делись все эти данные которые база отправил сторону приложения Дело в том что программисты поленились и все запросы в проекта сделали через звёздочку и в принципе эта схема Рабочая и не такая страшная Но в данном случае они рискуют тем что рано или поздно их Ну они просто упрт в канал И что кстати Однажды с этим проектом произошло Ну и плюс в этом случае запросы будут выполняться несколько медленнее просто за счёт того что придется по сети гонять линие данные как итог с проектами немножко подытожим рассмотрели два кейса мораль которых такова что держите А что делайте свои запросы более однозначно чтобы в базе не приходилось слать лишние данные Да тут лучше видно А и держите ваши индексы в актуальном состоянии Когда вы добавляете новый запрос свой проект а также транзакции вам помогут даже в том случае если вам не нужна какая-то особая Ну у вас нет каких-то особых требований к консист ВНО хранения данных то транзакции вам скорее всего помогут с точки зрения производительности А в следующем разделе мы собрали кейс пару кейсов которые связаны с кодом и так как мы в первую очередь всё-таки админы а не программисты то и кейсы подобрали более системные И начнём с нашего любимого связанного с внешними запросами актуален тогда когда например перед программистом встаёт задача обратиться к какой-то внешней опиш например он хочет где-нибудь в уголке разместить последнюю новость с какого-нибудь стороннего сайта он добавляет в код нечто подобное и радуется у него всё хорошо но только до тех пор пока этот внешний сайт не начнёт тормозить ведь вместе с ним начнут тормозить ваши странички А в конечном итоге с очень большой долей вероятности ваш сайт просто почему так происходит Дело в том что любой веб-сервер мы для примера возьмём патч для обработки каждого отдельного запроса выделяет воркера то есть выделяет отдельный процесс для обработки конкретно этого запроса и в нашем случае эти воркеры будут Заниматься тем что будут висеть и ожидать ответа от стороннего сайта и соответственно будут висеть а запросы м временем будут все прилетать Илеть вынужден платить оплатить эти воркеры а бесконечно Он этого делать не может потому что у любого веб-сервера есть лимит в случае Ача это ну и в конечном итоге Когда воркеры кончаются а то тот перестаёт принимать соединение ваш сайт упал А Фишка в том этого кейса что его не так-то и просто продиагностировать То есть когда у вас упал сайт Вы заходите на сервер и вы видите что у вас особо не оперативки полно А даже база данных выполняет ваши запросы А всё равно не работает тут вам в диагностике блин тут вам в диагностике поможет профайлер например в случае есть замечательная владо а в которой все внешние забросы отражены и отражены результаты их выполнения Ну или если у вас нет возможности поставить профайлер то хотя бы Посмотрите в nstat а и а возможно вы что-нибудь обнаружите А как же правильно поступать с этими запросами А обязательно с этими запросами надо Ну поступать Осторожно если вам требуется сделать Ну забрать с какой-то сторонней ошки какие-то данные то обязательно керуйте ответы которые она гери Если же вам надо данные отправлять через записку например вы хотите отправить смску или почтовое сообщение то Используйте какой-нибудь менеджер очередей Ну или если совсем припёр И вам Ну у вас уже вы уже столкнулись с этой проб тохо постан критичность будет снята следующий кейс актуален тогда когда перед программистом встаёт задача реализовать какую-нибудь фоновую процедуру и наша практика говорит о том что проще всего сделать это программисту на движке сайта Почему Да потому что он так привык у него под рукой все необходимые обеты уже ирова баз данных остатся только написать процедур спрятать её в какой-нибудь секретный улик Типа такого выключить лимит на выполнение ПХП например и всё это дело уложить в крон но у этого метода есть подводные камни Дело в том что фоновая процедура - Это задача достаточно ресурсом как правило и этой задачей вы заставляете пошевелить ач чтобы тот выделил лишний воркер но и если кроно процедур таких у вас будет достаточно много то у вас перманентно в памяти будут висеть какие-то воркеры которые будут Заниматься тем что рендерить ваши фоновые процедуры Но самое страшное произойдёт в тот момент когда какая-нибудь из этих процедур повиснет по какой-то причине Ну из ошибки программист и в этом случае И если в этом случае крон будет продолжать тикать и вызывать всё новые и новые процедуры то ач будет плодиться и плодиться пока не упрётся в лимит а правильно поступать здесь следующим образом если у вас Ну Старайтесь использовать консольную версию своего движка следите обязательно за временем выполнения ваших фоновых процедур и обязательно ставьте соответствующие тайм-ауты а также совершенно не повредит ставить блокировки на случай если одна и та же фоновая процедура решит запуститься несколько раз Итого с кодом опять же Будьте осторожны с крон заданиями и всегда делайте ваши внешние зас с осторожностью и не делайте их напрямую следующий кейс следующий раздел посвящён тем или иным архитектурным проблемам И начнём мы с кейса с которым просто устали бороться Дело в том что многие админы и программисты любят организовывать сайт таким образом чтобы его веб-сервер висел восьмим портом в интернет и обслуживал запросы пользователей напрямую побочные эффекты здесь вполне очевидны А - это штука тяжёлая и вы заставляете его заниматься не интеллектуальным трудом по рендеру страниц а отдачей файлив с вашей файловой системы но проблема реальная наступит в тот момент когда к вам придёт клиент у которого очень медленный интернет и тогда он будет выгружать ваши файлики очень дого воркеры будут очень долго висеть и если таких клиентов к вам прит десяток точ скорее всего умрёт решение тут элементарное никогда не оставляйте ач одного и ставьте перед ним Он с радостью возьмёт на себя задачу по отдаче статичных файлив и воз на себя медленных клиентов без пробк которую собрал netcraft Судя по ней 46% серверов в интернете представляются как пач и в принципе можно считать что все эти сервера находятся А в группе риска по данному кейсу следующий кейс я взял из нашего чек-листа по обслуживанию пхпх проектов Извините а дело в том А что PHP из коробки хранит сессии пользователей в файловой системе и в этом случае чем больше к вам приходит пользователей тем больше ПХП вынуждено ворочить файлика и соответственно вы рискуете тем что ваш диск просят Но самое страшное произойдёт в тот момент когда у вас кончатся аноды и сайт ваш гарантировано ляжет мы в этом случае поступаем следующим образом если нет особых требований по надёжно хранению сессий пользователей то мы используем либос либо ш по обстоятельствам следующий кейс актуален например случае если у вас есть сервер на котором крутится энд высоконагруженные манипуляции по его оптимизации но ресурсов вам всё равно не хватает Какое здесь может быть логичное решение для того чтобы снять нагрузку с такого Нда А я на самом деле имел в виду масштабирование действительно вы покупаете ещё один или несколько серверов А копируете на них приложение и балансирует между ними нагрузку таким образом вы не только снизить среднюю нагрузку на один сервер но и м получите некую отказоустойчивость но скорее всего сделать это у вас не получится просто так Наверняка у вас есть какая-нибудь админка через которую вы загружаете картинки или вы генерить какие-нибудь документы ПДФ например и храните их в локальной файловой системе и в таком случае если вы решите скопировать приложение на другой сервер то вам придётся ещё решить задачу по синхронизации файлив которые вы нагели А это на самом деле нормальная такая головная боль ещ Не дай Бог вы завязались на какую-нибудь экзотическую базу данных например на sqlite А в этом случае вы её не то что отрепьеве и соответственно финт с масштабированием не пройдёт а решение такое Если вы проектируется приложение и чувствуете Что рано или поздно его придётся масштабировать а то организуйте его таким образом чтобы она хранила файлики в S3 и речь тут идёт не о конкретно Amazon S3 многие могли подумать А о любом сервере Ну любом сервисе сервере собственном который умеет протокол 3 например ф Ну и не завязывайте ни на какие сомнительные базы данных это вам не раз спасёт ситуацию следующий кейс Это буквально неотъемлемая часть любого нагруженного проекта Дело в том что действительно самый надёжный способ снять нагрузку с экенда - это не слать эту нагрузку на него а зашивать ответы которые он сгенерировал потому что далеко не всегда есть смысл генерить для каждого отдельного пользователя страничку заново потому что они банально не меняются Ну или даже если они меняются то всегда есть возможность воспользоваться каким-нибудь ванишем но сейчас о самом простом случае за примером Далеко ходить не надо если вы были на лоде прошлой осенью То могли заметить что страничка с расписанием в первый день изрядно так тормозила Дело в том что она Гене десятки а запросов из-за которых Кен захлебнулся вот подобных И решение было очень простым мы просто вли зава их на минут во было Даже их зашивать на одну на 10 секунд и ВС равно НД сказал бы нам Спасибо Итого Если вы проектирует приложение которое чувствуете что когда-нибудь будет испытывать нагрузки то проектировать его таким образом чтобы в будущем вы без проблем могли эти странички зашивать Ну и ни в коем случае Не заставляйте обрабатывать запросы пользователей напрямую если у вас ПХП проект то Рассмотрите возможность принести сессии в какой-нибудь кеш или редис пишите приложение так чтобы их без проблем можно было масштабировать по-моему всё да Если же ой если жи в следующем разделе мы собрали кейсы которые так или иначе связаны с сетью и сеть - это достаточно штука объёмная и в ней куча нюансов но мы собрали кейсы которые более-менее применимы для нагруженных проектов И начнём мы с самого распространённого Дело в том что во многих проектах так сложилось что типичные сессии между разными узлами между фронт и эндом например между приложением и базой живут очень недолго и открываются на каждый внешний ный запрос есть на самом деле подводные камни и начнём с очевидного Что линуксу для того чтобы создать новый соке приходится немножко пошевелить процессором и при этом по вашей сети будут гулять лишние типичные служебные пакетики Но это на самом деле зачастую копейки настоящая проблема наступает в тот момент когда вы заставляете на каждый новый внешний запрос базу данных точнее приложение открывать соединение с базой данных и в этом случае базе приходится не только создать сот Ей приходится ещё реализовать кучу всяких служебных процедур там проверить права пользователя там выделить какое-нибудь окружение или какие-нибудь блокировочным случае что-то придётся поделать связана она с тем что если у вас в системе МРТ много сокетов то скорее всего она у вас переполнена сокетами в режиме та о них я расскажу чуть попозже так вот из всего этого реальную настоящую угрозу несут короткие соединения между базой и приложением и если вы решите с ними бороться то скорее всего вам при лезть в логику приложения в принципе Но если у вас пагр то вам Здорово повезло опять же для Пари есть специальная прося которая создана буквально для этой задачи ставите перед баунсер и снимаете с него лишнюю нагрузку Это хороший метод также в случае отдель случаях имет перманентное соединение но Будьте осторожны не все веб-сервера такое умеют например по-моему Unic не умеет ну Неважно а как обещал расскажу немножко о та сокетах а Суть в том что Linux устроен таким образом что когда тот закрывает соединение закрывает сот то он не стремится дать его из системы бесследно а оставляет его ещ повисеть минутку в режиме та и в принципе это несёт Ну одну небольшую угрозу Дело в том что в этом случае да и в принципе в любом случае линуксу приходится на каждый входящий пакетик искать соответствие среди всех сокетов которые у него есть в наличии А так как среди сокетов ещ полно мтх душ в виде Тай то ему приходи перебрать это Но это на самом деле не такая уж серьёзная проблема Да и по другим параметрам эти сокеты толком на вашу систему не влияют Почему я о них говорю Дело в том что админы зачастую любят очень с ними бороться и когда они заходят на сервак и видят Ну заходит на сервак чтобы решить какую-то витх и идут в интернет советом и первое что они видят это совет включить это два параметра в ядре речь идёт о и и если Первый параметр вам не навредит и в принципе можно считать его полезным есть случаи когда он поможет То есть за второго вы затесь деть Почему Поль други Казалось бы не могут подключиться к вашему сайту Прим таких будет процента и вы не сразу об этом узнаете при этом проблема в том что эти два параметра толком никак не задокументировано и чтобы разобраться как они работают придётся немножко попотеть и если вам любопытно вс-таки как они работают подходите На наш стенд я м обус буде льно решение для борьбы с этими сокетами будет Первое не паниковать и комплекс из двух ещё мер Включите вс-таки он вам не повредит и старайтесь вашей системе свести к минимуму короткие шные соединения то есть Старайтесь как можно больше использовать конек они полезным несёт мораль которая подойдёт для любого более-менее серьёзного проекта А есть у нас проектное обслуживание а которого есть специфика он состоит из двух виртуалок а которые хост хостилис давнего времени в дижитал оушене и эти виртуалки перманентно испытывали одинаковую нагрузку в течение дня ну специфика такая и как-то раз совершенно неожиданно Этот проект вдруг начал тормозить причём ночью работает хорошо а днём тормозит за Ну когда мы зашли в профайлер мы увидели что запросы к базе данных выполняются в течение дня Ну пока солнце светит очень долго В то время как но всё хорошо И эти же самые запросы в это же самое время по версии базы данных выполняются быстро немножко пора мы выяснили что в ди между виртуалка начала проседать сеть причём днём она тормозит а ночью всё хорошо и мы не стали разбираться и просто уехали на собственный гипервизор а Мораль такова что если у вас более-менее серьёзный проект то Старайтесь вести к минимуму использования коммунальных инфраструктур сюрпризы Ну либо пристально следите за ними чтобы опять же Быть готовым в случае чего проговорили итог про коммунальную инфраструктуру Старайтесь подытожим сетевой раздел постарайтесь использовать как можно меньше коротких соединений между вашими компонентами не перестарайся в борьбе сй а ну да три кейса Всё верно в следующем разделе мы собрали ошибки которые могут помешать вашему проекту И начнём мы с самый банальный и самый очевидной но почему-то многие программисты или админы уверены что если они добавят в проект какую-нибудь новую технологию то настройк из коробки им обязательно хватит и а выясняется что это не так как правило уже на этапе первых нагрузок и решение тут тоже простое и очевидное А если добавляете свой проект какую-то новую технологию то обязательно разберитесь в ней и настройте превентивно на Ну чтобы она вас не подвела а в том же хабре полно статей для той же муски а о том как по-простому а настроить её так чтобы она держала хорошие нагрузки ладно Кстати о хаб если у вас большой проект то у вас уже Наверняка есть маркетологи которые любят дать рекламную компанию и либо разместить где-нибудь рекламную ссылку на том же хабре например и как правило выясняется что когда приходит новый поток пользователей инфраструктура бывает к этому не готова изго если бы ну маркетолог предупредил команду администраторов и те произвели а какой-нибудь нагрузочное тестирование и либо поднадзорной деньги м очень больной для нас кейс а также больной для нас кейс связан с проектами в которых есть свои команды программистов Дело в том что те любят делать себе недельные планы и выкатывать свои Ну подели по пятницам и причём как правило это происходит вечером они это всё дело выкатывают быстренько проверяют и довольные собой убегают домой но тут выясняется что программисты внесли какие-то изменения из-за которых мы больше не держим нагрузки и нам админам напоминаю это Пятница вечер приходится инфраструктуру под новые условия подстраивать и хорошо если мы справимся но возможна ситуация когда нам понадобится помощь того самого программиста который внёс эти изменения и мы его в трезвом ме просто не найдём поэтому Старайтесь перенести свои выкат с пятницы куда-нибудь только не в пятницу пожалуйста Итак мы с вами закончили разборы кейсов сейчас я подниму вопрос о самых необходимых задачах которые надо решить в абсолютно каждом проекте и я думаю никто со мной спорить не будет что в первую очередь это бэкапы объяснять Я думаю не надо мониторинга и вы никогда не дадите гарантию что с вашим проектом в данный момент всё в порядке а ещё если что-то пойдёт не так вы замучить с ним разбираться это к слову о статистике мониторинге Ну и если вы деплоить по пишки то вы рискуете своим аптайм и тоже я думаю многие этого понимают но как думаете Много ли проектов которые пришли к нам на обслуживание хотя бы попытались хоть как-то решить вопрос сбора бэкапов как оказалось 40% проектов настолько уверены в себе что решение вопроса бэкапов у них просто не стоит с статистикой и мониторингом всё хуже Дело в том что у на Есть вки проекты которые побо и поставили хотя бы базовую инсталляцию за бекса а либо настроили монитори мониторинг в том же в той же Яндекс метрике но таковых всего 30% и по поводу последнего последней задачи есть небольшая завершающая история связана она с клиентом которых до недавних пор деплоя по FTP есть у него программист который Однажды уехал в отпуск и купил там местную сим-карту и тут как-то вечерком под настроение он решил поть И выкатить это всё на сервак но в момент выкатать по какой-то причине и всё что он успел это залить Файлик нулевого размера и соответственно умер и с нашей стороны ВС выглядело совсем странно программист в отпуске Не от кого и соответственно разбор этой ситуации занял Ну достаточно серьёзны объём времени но мы вс-таки разобрались и достали скрип ска так вот Много ли считаете таких клиентов которые в принципе не не позаботились хотя бы о кастра в своём проекте оказалось только он только прох литов обходимость грамотного деплоя самостоятельно остальные не парятся Итого мы рассмотрели с вами массу кейсов которые я надеюсь найдут применение в ваших проектах и найдут применение в ваших будущих проектов а Подписывайтесь на наш блог на хабре там он активно сейчас развивается и я думаю вы тоже там что-нибудь почерпнуть интересно спасибо Я думаю всё было настолько очевидно что спорить со мной никто не станет верно о молодой человек хочет А как Алло сес дадут у нас есть три у нас есть три кружечки Я думаю за вопрос по одной не больше трёх вопросов передумал доклад А слышно да А хорошо вопрос такой один всего будет Да вот вы говорите что давайте ставить перед ам engin А зачем тогда apch apch - это веб-сервер который рендерит странички рендерит код Ну извините engin - это веб-сервер да рендерит код engin - это не Сосем веб-сервер это реверсивный прокси сервер О'кей он может выполнять функции веб-сервера он может он может выполнять функции веб-сервера а рендеринг кода будет осуществляться каким-то эндом например PHP про совсем не слышу попробуйте А мы можем использовать engins в качестве веб-сервера а рендеринг страниц будет осуществлять PHP fpm например я понял вопрос под веб-сервера в в рамках данного доклада Я имею в виду ту штуковину которая непосредственно занимается рендеров тут выступает Юкон в качестве рего прокси выступает А простите кружечку обещал вот так вот Да добрый день спасибо за доклад вот у меня вопрос вы упоминали о системах деплоя Ну понятно всё а просто интересен технологический стек которым вы пользуетесь для автоматизации сбора бэкапов и развёртывания этих бэкапов в обратную сторону и как всё это происходит в ваших кейсах Я правильно понял что вопрос про то как мы реализуем вопрос за бэкап Ну фактически Да никто не добавлял замечательно ну в двух словах Если прямо на пальцах мы автоматизировано настраиваем балу и достаём файлики из балы безо всяких изысков в случае чего но в бале у нас всегда в всё под рукой то есть и база данных там же и различные конфигурации и всё проче и база данных ну в отдельном случае разные базы данных Пим по-разному и заставляем ну пишем какую-то программу кото достатка из забираем бало Ну то есть вы используете какие-то свои такие самописный решения скажем да Для этого ну как если скрипти можно написать самописный решением Ну да да очень интересно было услышать про ошибки что мешают а такой ещ момент Были ли ошибки которые помогали неожиданно лоду но это выя постфактум уже то есть что ты сделал думали что Ошибка неожиданно это как-то помогло выделить нагрузку которая пришла неожиданно Ну например бывали случаи когда мы Ну там оперативки больше Виту виртуалки давали Хотя е не надо было но Ну на самом деле когда такие ситуации происходили мы о них просто не знаем Ну собственно Да как валось постфактум честно говоря не припомню таких кесов сходу Но вопрос интерес не обращ внимания хорошо И вот не знаю создалось впечатление что вы так достаточно разделяете понятие там грубо программистов и админов то есть моменты Это как-то осознанное решение или вы их не используете ли это такой подход Ну мы на самом деле на джоре сейчас находимся и и кейсы соответствующие но тут я имею в виду программистов как команду которая относится к клиенту которая может преподнести нам добра то что наша Как устроена наша инфраструктура при этом я не упоминаю Ну хотя в принципе возможно имелось Ну я в общем не вижу способа как воткнуть в этот доклад то как уместно сказать в этом докладе что наша инфраструктура такая замечательно она все на гипсе просто это ну речь не об этом сейчас теперь бесплатный вопрос я же обещал ой Ребята а вот вы привели пример с выставлением минуту а используете ли вы в своих приложениях заголовки http cash Control там и например да то есть приложение ваше знает ли о том что надо кэшировать его данные или всё на откуп фронтенду в виде eng насчёт того что приложение не наше а приложение нашего клиента Ну проекта который мы обслуживаем мы его не развиваем а и ш Control это Ну то о чём Надо подумать на этапе проектирования вашего приложения если вы делаете приложение которое будет когда-нибудь исполь испытывать нагрузки и вы захотите его кишить рекомендации Ну тут по обстоятельства универсального совета я вам не дам когда использовать когда не использовать это отдельная история можем обсудить на докладе ой на стенде А который час кто-нибудь знает да очень часто это уместно Господи Добрый день А подскажите А почему вы не рекомендовали использовать НФС в качестве распределённой хранилки на всех трёх серверах а использовать тот же S3 Ну у нас возможно субъективное мнение но мы считаем что это небольшой Костыль несколько Ну в общем NFS в данном случае это сложно сделать достаточно отказу устойчивы и Ну как правило я добавлю вручаю слово как правило и S3 как опять же как правило решение на S3 удобнее бэкапить удобнее разворачивать и ну субъективно и ими удобно удоб пользоваться из приложения Ну с точки зрения программиста то есть сплошные плюс Ну да но как временное решение Вполне себе СОШ фс пожалуйста только потом переделайте на3 это гораздо удобнее с точки зрения админа Господи надо было подольше доклад сделать это спасибо за доклад А в продолжении вопроса коллеге про кпы такой вопрос Вот вы КП собрали вот всё хорошо а как вы проверяете что бкп собрался верно что он полный что из них можно установить проект Как часто вы эти бэкапы разворачивается и Какие среды используете для этого сразу про среды скажу честно говоря толком никакие среды мы не используем мы используем регламенты и дежурных которые регулярно ходят по проектам и убеждаются что всё хорошо у нас есть много людей и много рук Здравствуйте А вот вы рассказывали про голо про Тай сокеты да сказали что Linux устроен так наверное было бы более справедливо сказать что это tcp да устроен так та сот они всё-таки везде существуют насколько я знаю А Да вы правы и почему вы рассказывая тог об этом да не упомянули про тайм вей тайм-ауты И хотя бы Local P Range например Я пожалел мозги слушателей и опять же если кому любопытно про Тай послушать а немножко про та сот подходить я вам расскажу как они работают на сцена Понятно спасибо за доклад Да очень приятно"
}