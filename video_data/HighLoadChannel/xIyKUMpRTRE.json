{
  "video_id": "xIyKUMpRTRE",
  "channel": "HighLoadChannel",
  "title": "Эксплуатация container-based-инфраструктур / Николай Сивко (okmeter.io)",
  "views": 1010,
  "duration": 3095,
  "published": "2018-08-16T04:34:58-07:00",
  "text": "но собственно я блин а я долго хотел сделать подобный доклад но все не решался ждал чтобы сделать кто-то другой во время пришло на самом деле начинал я тема была примерно такая как жить если devops пришел вашу компанию если вы при этом админ devops ну и все что с ним связанно это контейнер и микро сервиса они как вы пришли и этом уже сопротивляться поздно я сейчас быстренько расскажу что изменилось а потом расскажу свои мысли идеи чего нужно доделывать чтобы с этим можно было там более-менее комфортно жить к сожалению я не успел часть вопросов которая заявлял в тезисах осветить но я надеюсь будет и так интересно в общем то что у нас было до того как появились микро сервис у нас были железки на них что ты работала и там приложение база данных все живое на отдельных серверах как правило там когда проект начинался директора говорилось купить там 3 сервера 2 под базу 1 или там 4 по приложениям и все это развернем это будет работать отказа устойчиво производительные так далее соответственно какой-то момент но это вопрос про культуру про требования бизнеса я тут особо не селян это вот коллеги из экспресс 42 обычно рассказывают нам в общем-то появились проблемы почему такой подход перестал устраивать бизнес бизнес сказал я хочу быстрее выпускать код то есть мы хотим разрабатывать быстрее гибче мы хотим уметь масштабирует разработку то есть посадить толпу разработчиков чтобы она работала вместе они упёрлись в одно место в коде и решили что так жить нельзя в общем я считаю что девелоперы всё-таки не админ и предложили микро сервис и соответственно будет как бы то что у нас получилось в итоге это независимой куски кода которые хорошо разрабатывать несколькими там командами большим количеством разработчиков одновременно как-то зона ответственности там или фича делятся по сервисам они все разрабатываются все хорошо соответственно нет проблем и теперь это все релизе и по мнению разработчиков нет проблемы чтобы этот трабл шутить потому что ну я то думал что она есть а потом когда я прихожу на доклады говорят что нет мы у нас есть какие-то метрики мы по ним все понимаем и все хорошо вот я с этим не особо согласен ну да посмотрим ну и соответственно цитата которая очень сильно подходит под это все вопрос из законов сохранения массы вышибать соответственно сложность системы вот таким ходом к ним она не могла снизится чисто вот логически она просто перетекла в другое место если в это место разработчики теперь не смотрят потому что это каким-то причинам не газона ответственность значит все эти штуки огреб кто то другой то есть ну abs или как назвать естественно раньше было у нас монолит был кот были какие-то пакеты модули и так далее они взаимодействовали между собой просто вызовом функции там публично функции каких-то модулей соответственно в коде было черным по белому написано кто с кем как взаимодействует на таких условиях чего передает чего возвращает соответственно стала то же самое только все это стало по сети появились какие-то это и с какими-то контрактами появились с discovery то есть это стало ну искать динамично ничего не сказать соответственно когда разработчики начали вообще все это выкатывать это мои дома 100 все вот как это дело было я ж не знаю я же на душе не стоял соответственно пришлось решать какие-то острые проблемы придумали infrastructure за код когда нам нужно просто за за зафиксировать описание взаимодействия без этого ну вообще выжить нельзя было придумали как вот это вот все кусочками выпускать придумали докер чтобы решить проблему там пакетирования зависимости каждого сервиса потом кто-то придумал что это все еще надо динамически этим управлять появился регистрация и всякие прямо конкретное решение купюрницы впрочем соответственно докер как я уже сказал изначально на мой взгляд решали проблему пакетирования то есть когда вам нужно from scratch сделать сервис то есть кто делал де проблем пакеты знает что это сложно особенно если вы будете прям debian выйти и dependency брать из других пакетов они к себе в пакет затаскивать это вообще адище то есть особенно если вас queen питон а если вам он требует конкретного пакета этого пакета еще нет ваши репе я вам это все собирать это в общем то задача такая ну не для слабонервных но вместе с докером явно докер делали не админы разработчики они еще решали проблему как нам несколько контейнеров запускать одного и того же на хвосте а если у то них порты одинаковые как нам от коллизии портов избавиться давайте сеть еще но мудрым там за виртуализировать и получилось там не все просто но по сути на низком уровне докер как мы все знаем это namespace и все группы слоеная файловая система и в общем то в основном touring то есть с точки зрения физики с точки зрения low level с linux ничего придумано не было здесь важно не то что у нас есть докер а то что последствия каким из этого получили у нас появилась возможность собрать контейнер быстро и его запустить где-то у нас убрался overhead на то что ранен виртуалкой все таки сильно тяжелее штука на нее нужно памяти на нее нужно там какие-то средства которые добавляют оверхед поцелуи так далее случае с контейнером это просто процесс и самое важное что здесь я отмечу это то что убрался барьер в порождении микро сервисов то есть теперь сделать микро сервис действительно легко и это с одной стороны плюс а с другой стороны эта проблема которую мы должны с ней соответственно жить итак что же нам пропагандируется у нас в пределе нам обещают что у нас будет некая операционная система уровня дата-центра мы будем туда деплоить наши контейнеры они все будут работать и в общем-то мы будем просто докупать железо до арендовать не знаю через записку в амазоне заказывать с танцы это все будет масштабироваться на практике я это сужу по своему опыту по а потому что мы наблюдаем у наших клиентов на практике все гораздо скучнее есть база данных которые живут на отдельных железках потому что контейнер рядом с ними никто не решается подселить есть фоновые задачи которые там не знаю ходу по аналитика чего так считается они живут на отдельные железка чтобы никому не мешать есть критичные сервисы которые отвечают за авторизации у них целый там 50 миллисекунд их тоже ни с кем не вешает как правило а всякое вот такое бизнес-логика которая там пачками выходит она живет на каких-то машинах толпой и соответственно другу на друг друга как то как то влияет и вот типичная ситуация когда нас один из клиентов ставят мы говорим вот у нас докер мы ничего не хотим знать и тёплым на кластер машин наши контейнеры а потом они хотят все таки виде теперь контейнер летом все и замечают что у них 2 инст нас ведут себя как то не так и собственно начинаются вопросы как почему вот конкретно эти два из нас ведут себя не так может там слабее машина может там рядом какой-то сервис нагружает нужно найти и посмотреть соответственно топологию мы все-таки хотим знать вот в такие моменты мы нашу абстракцию которую мы так строили-строили мы начинаем ее разрушать следующим шагом мы хотим все таки объяснять нашему оркестра таро что давай вот эти в этом секретиков сервисы мы отнесем и соседние машины то есть мы хотим управлять топологии и это как бы не клеится с начальной постановкой задачи вот я решил подумать и поиграться с бенчмарками посмотреть можно ли этого не делать соответственно первое что я полез смотреть как известно amazon и google нам предоставляют контейнер на и облака куда мы диплом наши контейнеры но очень грустно оказалось что это просто они отменят за вас кубер нет с вы покупаете на ноги у них виртуалке и они там как все размазываются вас то есть они не предлагают вам никакого подхода никакого решения я решил вспомнить свой опыт с гугла бенджен это такое true гоблака когда вы не знаете что у вас там есть что вас там есть присутствием вы просто покупаете некий инстанса своего приложения я думал что губернатор это вот что то такое классное похоже на это когда у вас реально нет обмaна вот об engine делает так что он говорит выбирай желез ну выбирай характеристику ресурсу на котором ты будешь запускать с на свое приложение ты говоришь я хочу шестьсот пятьдесят мегагерц я хочу 2 giga памяти и плачут за это по часам соответственно мегагерц и в данном случае это не то что они вам запускают на старых машинах это просто какой то кусок от одного ведра от двух ядер и так далее соответственно мой весь посыл доклада что давайте подумаем как нам ограничивать ресурсы наших контейнеров то что их ограничивать нужно скорее всего правда но вот возможно ли вообще это сделать соответственно все devops модные тузы умеют ограничивать ресурсы но фишка в том что они не заставляют вас та девочка google вот она дабы то есть я сформулировал задачу так мы хотим распределить весь наш пункт допустим у нас есть сотни машин у него не каждый из них есть сколько-то процесс как-то памяти сколько-то диска мы хотим ее порезать распределить между нашими сервисами сервисы друг на друга влиять не должны хотим понимать не уперся какой-то сервис у нас в ресурсы хотим понимать сколько у нас осталось лоток для масштабирования и не хотим чтобы ресурсы простаивали соответственно вообще-то спич даже не про докер опросе групп вот и как оказалось про всякие линуксовые планировщики ну вот к этому перейдём к groups это способ ограничивать ресурсов группа процессов каким-то образом назначаете группе процессы которые в нее входят и соответственно дальше вы навешивайте разные ограничения на на эти процессы соответственно google начал это разрабатывать в ядре linux это в первом версии появилась 2008 году соответственно docker и прочие штуки на все контейнеры под автоматом навешиваются группы если вы не задали ограничения все группы все равно навешано но ограничение там нет соответственно начнем с циpкa все groups степи есть возможности задать весах процессом то есть пропорцию выделения процессор на времени между ними есть способ задать квоты есть способ прибить гвоздями группа процессов к каким-то ядрам здесь же есть возможность прибить их канун анодом то есть сказать что вот эти процессы должны работать на ядре 12 и прибить прибитые быть окном и ноги 0 это когда вам совсем запаривайтесь на latency вы не хотите чтобы ваша память бралась из соседней нуман оды и было соответственно в этом все больше вы можете как бы ее зажать и насильно сказать что использует ту память но соответственно просто читать вам доку было не круто я подумал что я бенчмарки какие то сделаю и соответственно я взял машину в него семья до 32 гигов памяти hyperthreading не отключил чтобы но вообще иначе сложно все будет написала простенький сервис на гошке которые 50 процентов времени ждет чего-то 50 процентов времени молотят соответственно эту машину соседней машины по быстрой сети нагружал танком и чтобы не было претензий про то что я там в танце как не знаем не так замерил я взял гистограмму достаточно с достаточно там мелким порогом поэтому будет все разноцветная и начнем с у нас есть два сервиса мы запускаем один и тот же код на разных портах и просто начинаем грузить 1 и 2 соответственно верхняя это у нас будем называть гистограмма по оси y у нас запросы в секунду по оси x время цветами отмечено время ответа естественно самая зеленая темно-зеленая это меньше 20 миллисекунд красное это больше 100 миллисекунд соответственно на этом на этой картинке мы видим что здесь работал у нас сервис в одиночестве потом мы начали грузить и с удивлением обнаруживаем что под нагрузкой и первый сервис стал отвечать быстрее соответственно меня не было никаких идей но я тупо взял перф вот я вывел вам значимой колонки и мы видим что сработал power сейф и у нас в случае без нагрузки частота проца была понижена как только началась нагрузка соответственно разогнался и в сервис начал отвечать быстрее соответственно включаем режим performance чтобы на это больше не индикации на самом деле там звучит достаточно просто я на эту убил мэр на полдня если не целый день соответственно с perform там очень долго пытался понять была идея что может быть из за того что там какие-то миграции между ядрами еще что то но в итоге выяснилось что соответственно это просто режим энергосбережения был соответственно второй тест мы разобрались здесь с тем что у нас выдался было какое-то не такое я вывела на стабильно сюда это водах момента сервис работал в одиночестве но с хорошие гистограммы здесь началось грузил его мы видим как начал сервис отвечать медленнее то есть количество совсем зеленого начала падать и мы видим когда там более-менее уперлись в ресурсы у этого сервиса циpкa потребления понизилась и соответственно там началась вообще деградация по времени ответа и соответственно мы увидели что сервисы друг другу мешают что и требовалось доказать в данном конкретном кейсе то есть по факту по дефолту у нас была настроена одинаковая циpкa пролить эту обоих сервисов 1024 они должны были по идее scheduler поровну поделить их время но единственное что пока нет конкуренции вас никто не ограничивает и это соответственно проблема то есть когда у вас сервис работает работает работает приходит его сосед начинает работу вас слитности падает потому что вы отбирали много ресурсов вас придавили просто и соответственно если мы хотим стабильности если мы хотим не думать про то что они запустился ли там сервис 2 на этой машине момент какого-то спайка нам нужен стабильный худший случай вот его мы и будем добиваться соответственно циpкa квоты то есть идея в том что давайте зажмём сервис жестко по циpкa мы будем знать где у него предел и будем масштабировать его ну как-то объясним балансировщик у что на него больше чем он может мы не будем отправлять мы будем мониторить что он потребляет там не больше 90 процентов от своего предела но мы будем масштабировать его просто количеством инстансов все групп есть такое понятие кого-то то есть мы определяем период допустим одну миллисекунду мы говорим что за эту миллисекунду ты можешь съесть две миллисекунды процессор на во времени это значит что мы ему отдали два ядра целиком соответственно если процесс эту квоту потратил то наступает но он продлится то есть ему его ему не дают просто процессор на времени до тех пор пока не кончится этот период пробуем вдоль кирито называется параметр циpкa период спа-уход здесь мы поставили просто мы хотим в одну миллисекунду две миллисекунды потратить то есть моему два ядра отдаем соответственно делаем нагрузочный тест по чтобы определить его предел то есть здесь у нас график гистограмма здесь у нас потребление конкретного сервиса в процентах естественно 88 ягер это 800 процентов естественно мы здесь нарисовали красненькой предел мы начали выгрузить вот так вот линейной нагрузкой возрастающей мы увидели что растет тротлинг этого сервиса то есть эти метрики можно снять мы увидели как он уперся как у нас начало деградации то есть мы знаем примерно что на 2 при ограничений в два ядра этот сервис то может нормально обслужить ну чуть больше старый ps соответственно мы теперь знаем его предел мы можем мониторить ниц и будет слышно машине можно мониторить потребление циpкa в процентах сервиса от его квоты и это достаточно круто потому что вы можете как бы точно определять что вот этот сервис уперся все остальные не убирались вот соответственно фактическое потребление вы можете взять и грудных метрик если вы умеете снимать метрики по процессам вы можете понять что процесс 1 citigroup ли просуммировать их usage ну тоже самое будет соответственно период и квоту мы знаем то есть если у нас период одна миллисекунда кого-то две миллисекунды значит мы можем потратить 2 секунды в секунду то есть два ядра естественно одно с другим можем сравнивать триггер на мой взгляд должен выглядеть как-то так сервис такой это цепную such у него больше там 90 процентов от его лимита таким образом вы все-таки абстракцию оставляете вы даже можете это не разбивать по машинам и вы можете как бы просуммировать эти по машинам соответственно если мы уперлись и мы тратимся у нас и счётчик сколько периодов мы были сколько-то трот лились и второе это набор тратит и второе трат летаем это кумулятивный счетчик времени в на на секундах сколько мы были потрачены то есть если мы рейта тратил то имбирем то мы видим сколько в секунд в секунду мы мы соответственно ничего не делали это вот нижний график это производная тратами соответственно вообще подход я предлагаю такое мы делаем делим машину на slade и фиксированные и не допускаем перья раздачи ресурсов то есть овербукинг гавер селин как угодно мы не допускаем это мы делаем для критичных ресурсов для некритичных ресурсов мы мы по этой орше потом расскажу слайд не про это соответственно опять же мы знаем потребление мы как ты лучшим оркестра tor балансировщик не превышать запуская новые инстанции или что то еще мы знаем наш запас количество слотов то есть если у нас 100 машин поделена на флотов и мы знаешь у нас забита столько-то слотов то мы знаем что насколько слотов пустых осталось ну там вариациях можем slade и делить там я драм по памяти и так далее мы знаем сколько у нас осталось то есть точки зрения планирования структуры тоже получается достаточно круто мы допустим вводим политику что мы хотим чтобы у нас всегда оставалось еще там не знаю сотней order и там скромный сколько-нибудь гигов на будущие проекты будущее сервисов и соответственно когда этот показатель начинает снижаться на загорается лампочка давай звонить вендору заказываете или там что-то включать и так далее но проблема-то в том что мы slade и поделили как бы простаивающий ресурсы у нас остались то есть если на какой-то сервис нет нагрузки его слот ничем не занят и это как бы проблема я попытался предположить что ее можно решить таким образом мы ставим не только квоту но и циpкa шар то есть мы говорим что критичным сервисом моего задираем в планку и говорим что его прилетят максимальный фоновым сервиса мы ставим минимальный шер но не ограничиваем их ресурсах таким образом возникла идея что мы можем запустить пожирал q циpкa и она никак не помешает нашим в этом сеансе в сервисом соответственно от протестировать максимальный параметр это вот такой я не знаю не помню по моему это все groups of shit них дагера а соответственно минимальный параметр это два то есть этот сервис 200 тысяч то есть 100000 раз приоритетнее чем на шифоновая задача соответственно тест фоновая задача у нас просто процесс стресс который в 12 потоков чтобы там было совсем что настоящему молотит против соответственно взяли запустили и и ни хрена то есть мы видим что у нас гистограмма провалилась время ответа у нас вскочила и соответственно на мы видим вот как наш стресс собрал весь просто что у него был наш боевой сервис он подсыпал просел потому что ему не выдавали как флотов времени здесь я долго долго парился прочего там происходит внутри scheduler а scheduler а в линуксе сейчас самый современный этот cfs соответственно там есть куча ручек которые можно покрутить там но смысл в том что он discrete он то есть он не время она вообще в принципе дискретно то есть вы он выдает вам время какими-то салатами и по дефолту там настраиваются slade и сколько вы гарантированно если у вас за schedule один опрос сколько вы гарантированно там проработайте через сколько время возможно оттуда вытеснить и так далее и тому подобное а я решил что ручки крутить не буду ну там быстренько покрутил там эффекта значимую не было а я решил что мы слишком мы слишком зажали размер окна на котором мы выделяем квоту соответственно эта мысль пришла из-за того что как бы ну то есть нам выделяют вот у мы работаем с допустим две миллисекунды и соответственно нас вытесняют и потом тратил период у нас ну короче решил я попробовать ограничить нас теми же двумя ядрами но на окне 10 миллисекунд то есть latency нашего сервиса она там 10 20 30 миллисекунд и в такое окно в принципе для нас приемлемо то есть здесь выбор пал именно так потому что я считаю что 100 миллисекунд окно это многовато потому что на 8 ядерной машине мы можем собрать всю квоту за 50 миллисекунд то есть наша в этом если мы будем активно пожирать проц составит 50 миллисекунд для нашего сервиса уже ощутимо то есть я поставил 20 миллисекунд за на окне 10 миллисекунд и соответственно начали тестить то есть те же самые параметры мы просто нолик добавляем здесь все остается без изменений и мы видим во первых что над не 10 миллисекунд гистограмма стала быстрее потому что мы быстрее можем сваливать наши ресурсы но на таком потоке нагрузки которые мы подавали это еще и приемлемо то есть в принципе такое такая квота она ускорила нам сервис здесь мы видим что сервис который мы запустили что пожирать проц оказывает конечно влияние потому что во первых не было конкуренции вторых появилась нагрузку на scheduler но время все таки и как будто влияние на в танце которые получили оно более менее приемлемо я не говорю что прямо совсем подходит но от случая к случаю этим можно пользоваться соответственно у нас получилось машине ресурсы да жрать у нас получилось более-менее наш сервис который критичен к задержкам оградить от таких грузилах соответственно если вы вас другие требования другой слой полотенце вы можете как бы сами поиграться на тесте именно с вашей нагрузкой и посмотреть и соответственно гипотеза о том что делить машину на слоты и добивать фоновой нагрузка она оправдала себя на мой взгляд вот поэтому можно как бы от нее отталкиваться дальше память то есть все groups можно сказать что вот эта группа процессов не должна вылезать за лимит памяти который мы и далее там есть куча разных ручек как-то можно ограничивать память который мы выделяем на сетевые буфера и так далее но я подумал что нас интересует только самый общий кейс просто вот размер памяти второе по крутизне этой под систему из игру в том что оно предоставляет статистику по тому сколько сейчас потребляет ваша группа процессов и на мой взгляд самый крутой человек давно хотел но не знал как снять мы можем посмотреть сколько какой процесс у нас поцеловал . ш linux то есть мы знаем дефолту мы смотрим на графике мы видим что у нас на нашем хостел 20 гигов занята ковшом но мы не знаем кто там сидит и в каких пропорциях а теперь если у вас все важные сервисы находятся все группах замечу не обязательно в dota рах просто все группах то выйдет статистику можете получить соответственно зачем вообще память ограничивать память нужно ограничивать ну просто для контроля если вы не хотите ходить и совершенно машинку и что-то там делать соответственно вам нужен контроль вам нужно жесткие квоты и полная гарантия что один сервис на другой не повлияет но вот кейсы которая придумал то есть у вас появляется сервис который живет память он всю память на машине у вас подводит там под сто процентов но он киллер считает что не он виноват а более как бы более прожорливы до памяти сервис но которые не течет и прибивают его или приходит какой-то сервис которая читает активность диска не знаю вы пришли влоги игре путь и вы вымыли кыш вашей базе данных это тоже не круто я считаю вот поэтому все таки давайте попробуем память ограничить для этого кейса в сервисе был сделан а кот мы просто мы сделали большой файлик мы сделали сервис который на каждый запрос берет рандомное смещение в этом файлики чтобы он как бы будем смотреть на кришне кэш и отдает оттуда там сколько тобой там по моему несколько мегабайт читалось вот запускаем этот сервис прогреваем ему конечно сто процентов то есть мы и spo2 гости группы берем и читаемого целиком нас памяти много проверяем что файл у нас целиком в каше если кто не знал такие утилиты есть это можно все выяснить вот мы теперь знаем что у нас файл в каше мы проверяем что все группы по мониторингу что си группа именно конкретно series 1 зала сыра вала весь этот кэш это кэш по контейнерам видим что была куча свободной памяти она ушла в кэш и соответственно запускаем в соседнем контейнере утилитку которая читает другой файл ответственно гистограмма нагрузки на первый сервис то есть пока все в каше была зеленая зеленая зеленая видим как сервис два начала лоцировать свой кэш вот какой то этот момент наступил а у нас драка за кэш и то есть сервис 2 начал вымывать кэш у график надо было перевернуть я чуть не догадался там было бы видно что в этот момент а ну вот у них сумма констант на этот растет значит этот уменьшается то есть в этот момент сервис 2 вымыл кусок к шоссе 1 1 а так как у нас нагрузка размазана рандомным об этом по всему файлу это для нас явилась проблемой и у нас в этом всем поехала вот соответственно теперь делаем то же самое но ограничиваем одним гигом этот контейнер series 2 соответственно мы видим что вот он начал аллоцировать себя кэш и уперся в свой гиг памяти достаточно и кэш того контейнер не затронут чего собственно и следовало доказать то есть памятью я придумал только такой кейс другие кейсы решил не рассматривать на не достаточно очевидно то есть подсистема памяти круто тем что просто работают лимиты там есть еще всякий софт лимиту не решил вам голову себе не забивать этой темы и соответственно метрики процесса все группах более мы о них по их потребления памяти знаем больше чем от обычных процессов потому что обычные процессы допустим про себя не рассказывают сколько они молодцы роли поиск сша вот и пачкаешь он как бы если вы из из 2-х групп его юзаете то он приписывается считается тому контейнеру кто его за первым это границу к ней обратился и соответственно вот она легла в кэш и соответственно ему и засчиталось про диск на самом деле редко встречаются люди которые диск на таких вот серверах с контейнерами юзает потому что сервисы не знаю там логику дата пишут еще что-то я же топлю за то что мы запускаем ее базы данных там тоже и все такое поэтому с диском надо тоже разобраться а все группах есть возможность также как ступу задать приоритет можно задать квоты квоты можно задать на трафик то есть сколько байт вы читали или записали на диск или в операций в секунду соответственно также как сцепу поступим мы отрежем процесс ну как бы все группам квоты на диск мы поймем их производительность под этим лимитом оси весь остальной нагрузку на диск мы добавим фон ими второстепенными задачами с маленьким приоритетом и посмотрим что из этого вы лица но случае с процом у нас есть понятный предел то есть мы знаем что это ядро может в секунду по хоть одну секунду а сколько может по хадис кого не знаем поэтому надо как-то это выяснить соответственно просто взяли тот же самый сервис зарезали ему кэш да там не знают 10 мегабайт нагрузили его чтобы всегда читал с диска соответственно мы видим что у нас идет идет растет количество операций чтения с конкретного диска мы видим что по времени которая мы ждем диск ну таким за так называемые процент и утилизации диска мы видим что он вот здесь уперся в сто процентов времени это значит что в секунду мы секунду ждали ответа от диска то есть диск был занят сто процентов времени соответственно мы здесь выяснили что чуть больше 200 операций в секунду на такой таких запросах у нас есть это как бы не значит что больше двухсот и опусов на чтение этот диск не даст просто это это характеристика для конкретной нагрузки и соответственно давайте попробуем отрезать 100 рецептов на этот диск и посмотреть что с сервисом станет но мы видим что ограничение работают то есть на 100 100 и отцев мы уперлись мы видим что сервис там с какого-то момента на приближение к 100 процентов у нас начала скакать в этом 7 в общем это то чего мы хотели собственно дальше соответственно хорошо мы отрезали slade и и пока профанного нагрузку не будем говорить что мы можем за мониторить мы можем мы знаем наш лимит вепсов и мы знаем факт факт мы можем снять если мы будем снимать факт по из по системным вызовом рид допустим конкретных процессов мы получим ряды которые не все доходят до диска например они все-таки из кошачьего читают а именно сколько си группа слева видов на конкретный девайс мы можем и сми трикси группы взять то есть там вообще это точно статистика там и счетчики по в разных разрезах есть в операция в секунду есть трафике есть во времени ожидания есть времени ожидания самого диска и во времени ожидания из очереди планировщика мы соответственно триггер вида сервис один скоро упрется в лимит iops of он тоже как бы достаточно облачный для нас то есть мы не не ходим смотреть метрики машины мы оперируем понятиями использования ресурсов конкретным сервисом ну и соответственно наша задача осталось добить наши диски фоновой нагрузкой здесь в этом примере просто мы делаем два контейнера первый наш сервис зажатом по искушен 2 зажатым печка шум сервис который пытается нагрузить диск пока никаких паритетов мы не ставим смотрим что будет то есть наш сервис один работал работал себе спокойно с зеленой гистограммой потом пришел сервис 2 и все нам взорвал на соответственно пробуем вставить vesa мы говорим что сервис один у нас будет иметь максимальный вес это 1000 наш второстепенный сервис убийца будет иметь вес 10 смотрим что происходит видим что стало лучше но все равно что то есть какая-то вот соответственно как всегда я полез разбираться что там вообще в линуксе происходит всюду лингам почитал покрутил дефолтный scheduler у меня диск обычные sata то есть не создаёт для него стал deform нас dollar сливку соответственно там есть параметры которые его заставляют работать ну планировать немножко по другому там у нее тоже есть дискретные времена когда он считает что такое чтение должно отвечать там примерно за столько-то поэтому на как там устраивает очень не получилось у меня заставить его работать на на этом war клади я нашел описание того что scheduler дедлайн работает чуть точнее когда вам нужно предсказуемой latency он менее производительный нас руку то есть вы не получите максимальной производительности на на трафике но вы получите более грамотное планирование отдамся это вот то что я сделал с его настройками соответственно запустил тест получилось все не сильно идеально но допустим а то есть мы все-таки получили гистограмму достаточно приемлемую для нас мы получили диск загружены на сто процентов при нормальном достаточно хорошему этом си соответственно результаты про блок его лимиты работают точно настройки под вашу в тунисе можно подобрать планировщик его они есть разные у них разные ручки вам нужно на свой workload это все крутить но в целом все неплохо ну и соответственно подбираемся концу написал какое-то количество выводов основной вывод то что вы получив микро сервис и вы если вы админ у вас появилось много новой работы вам мало того что надо заботать новые слова которые вы до этого не знали разобраться с этими подсистемами как-то уметь с ними оперировать но в целом вам придётся это делать и надо просто убрать и вкалывать короче до работы много технические выводы из планировщика my в линуксе все достаточно неплохо можно покрутить ну то есть я ожидал чтобы в какой-то из подсистем будет ну реально хреново то есть когда вы не можете никак добиться приемлемой в этом все оказалось все не так плохо и соответственно жить можно можно что-то покрутить есть экспериментальные патче которые заточены на то чтобы вам именно в этом системности в сервис и запускать мешали я думаю что они постепенно как то я так на глаз посмотрел какую-то примерно какие-то штуки их определенную после определенного уровня зрелости в ядро втаскивает какие-то удачные моменты из них там все так активно развивается я тестировал если кому то это важно на ядре 413 что-то последнее нашел чтобы на столе совсем не нарываться вот за планировщик вы можете следить если вас там совсем прям не устраивает вы можете какие-то экспериментальные почитаете и смотреть что там можно сделать ну и соответственно вывод самой главной ну то есть я сколько мог за вас павич марка у нас равно если вы хотите у себя отчет вменяемая стабильная и вы хотите по этому пути пойти вам нужно это делать соответственно если кто не умеет перс вам пора учиться потому что linux очень много потрясена всяких важных классных событий то есть вы первым можете посмотреть кучу всякого особенно если вы разбираетесь там слоты со спайками соответственно вывод который ну мне немножко греет душу то что все таки hadoop можно запустить рядом с базой и при этом ничего не взорвать но придется под запариться придется поднастроить придется протестировать все хорошенько ну в общем то если мы идем числе вам облачному будущему ну надо идти в ту сторону ну и соответственно я как мог докер по минимуму потреблял так что доклад не совсем хипстерский получился и в общем спасибо за внимание спасибо большая сейчас вот вопросы хватит сил за доклад а можно показать слайд где про про прос а там куча слов ну в общем где они там конкурировать я хотел спросить о не пробовали планировщик для каждого процесса вуза давать то есть тот который например должен получить да вот у вас там за вперед да то есть если поставить там другой планировщик для там критичного сервиса она вот это ямочка на родине выровняться то что его будет там быстрее запихивать это я вам оставил интересно ipad и передана я могу мог бы там под заморочиться и добиться там совсем ровного чего-то но это было бы решение для моего конкретного кейса я просто решил показать вам парочку там примеров бывают вот так и бывает вот так то есть вы знаете примерно чего покрутить теперь вы знаете что вам нужно для стресса пойти и попробовать его зажать потом миллисекунду в секунду ну как бы если вы этого не знали конечно спасибо за доклад у меня больше не вопрос просто дополнение по поводу планировщиков дисков до нашему опыту на самом деле это все работает для хдд ussd совершенно другая планировка linux сейчас не готов для того чтобы делать это для ssd это все абсолютно не работает ну вот вам еще информацию наполнитель внутрь рисуем об этом сказал прямо у меня добился то я решил что я и так на самом деле вот с этими тестами сильно прям шлось долго заморачиваться добрый день алексей вопрос такой а если в качестве дисков мы используем она по шару и шумный неф с собой assistance между нотами обеспечить и работает ли вообще было пришить думаю что вы так делать вам мало tense гарантированном забыть надо просто ну ну ну серьезно то есть я вот ещё не рассказал про сеть но сеть на самом деле очень мало кейсов но сами почитайте а пра-пра-пра latency с нфс он ничего не могу сказать знаю что плохо будет чувствую себя станислав мегагруп вопрос такой вы говорили про он киллер и то что вы все группе зажимаете память вопрос такая судьба процессов которые все групп зажаты если потребуется больше у нас нет если все пошли си групп сработает ограничение памяти работают следующим образом когда у вас кто-то внутри групп хочет больше памяти то стандартный механизм высвобождение не используем это ну как бы памяти которые можно за рекламить условно если у вас еще кэш используется то вымывается кэш если вы если память можно внутри группы высвободить то она высвобождается если соответственно вы упираетесь уже в харде лимит и ничего нельзя как бы высвободить то приходит к вам локальным филиалом киллера и делать свою грязную работу николай спасибо за доклад а можете немножко сказать может быть встречали я краем уха слышал что какие-то приложения например живьем до какой-то по версии вообще не учитывались все группы вы не встречались с таким си группы это вы хотите чуть-чуть потому что ими тоже ягель это снаружи снаружи живым и это ядерная вся история то есть сделать какой-то специфический процесс который по кладет на все ваши ограничения но я думаю что нельзя иначе она крута меня возьмите эту штучку добрый день спасибо за доклад скажите пожалуйста решали задачу распределения контейнеров машинам зависимости от ресурсов которые не потребляют не как работают оркестра то рыку бернерс это специальным обычным людям вам надуть я не специалист добрый день спасибо за доклад а вот такой вопрос а какой смысл запускать что-то рядом с критичным по времени сервисов с базы не знаю тот же ходу пропускать рядом с базой какое чтобы ресурсы да есть ну как бы чтобы деньги сэкономить но если она база там не должна большая часть ресурсов съедать больше час ресурса уже съедает зачем зачем там туда еще что то прихоть не смотрите у вас есть ресурсы вы хотите их размазать по машинам может получиться так что вас появится сервис который прямо очень критично его в одиночестве на машину повесите а потом ваш отдел разработки вам выдаст 40 таких сервисов вы запустите ну с минимально отказоустойчивость 80 машин который будет ничего не делать но всегда готова и быстро ответить этот сервис если у вас есть bubble такое то делайте если вы хотите бабло поэкономить и вы заморочились на то что вы покрутить ограничение и делаете так что фоновый сервис молотит вам процесс до тех пор пока не пришел запрос на этот критичный сервис то есть если вы сумели этого добиться то у вас дохренища ресурсов утилизированы ну заняты делом просто то есть это случай когда критичный сервис не весь сервер за занимает условно говоря какую-то часть или вот это условно мы идем числом облачно будущему в этом будущем вы говорите вот мой сервис вот его образ контейнера он ахренеть какой критичный запусти его 5 инстансов и мы знаем что после этого наша система сделает так что он будет нам отвечать с более-менее стабильной штукой хочу происходит рядом с ним и думать не хотя вот ну классно же да но было бы так да то есть не понимает у нас уклон garena на железке там 16 гигов памяти а нам нужно 8 на критически сервера отдать и куда ты куда-то оставшиеся восемь использовать вот такой случай или или мы хотим под завязку мы хотим чтоб наш процесс молотил на сто процентов чтобы диски hre и ночами тоже на сто процентов и чтобы память была тютелька в тютельку вот так вот вся за за логичен и тогда ну круто мы приходим директору смотри какой эконом понятно спасибо ну да кстати вот пока сервис отдыхает можно майнить чем тоже нормально нога и сразу на еще выйти и не майнить добрый день и спасибо рассказываете про бокс и его облачно и будущее если у вас опыт мониторинга просадки производительности некий неких ресурсов вычислительных там сыпью дисков и так далее с вне то есть не из машины как бы изнутри облака понятно чем мне некогда когда характеристики машины они становятся хуже да вот но при этом как бы других процессов которые вы на этой машине который влияет на эту производительность я такое знаю только про диски то есть у вас временем диски стареет у них появляются там возможность необходимость ли лоцировать сектора у них там в туз и другая это смарт смарт тулс короче снимать про диска про россию я такое не знаю если на одной в системе виртуализации улучшенного провайдер до другая кайт машину начинает потреблять ресурсы да вот ваш сервис проседает папа до этой нагрузкой в вашей виртуальной машине вот такие ступе умеете мониторить смотрите perfumed такие штуки мониторить я вот пример показывал вы можете увидеть что до этого вы столько то процессор ных циклов выполняли за столько ты миллисекунд а теперь за столько-то либо потому что у вас процессор на и соответственно частота проца снижена там power софия то что я показывал либо у вас спирали просто процесс то есть в каких-то штуках в каких-то гипервизорах вам покажут стол сталинскую times то есть сколько вам не додали проц а в каких-то не покажут то есть тут очень много кейса всяких возможно давайте последние два вопроса здравствуйте и спасибо за доклад подскажите пожалуйста подскажите пожалуйста у вас сейчас это все на стадии исключительно экспериментов или у вас уже есть пять система собственно система скажем регистрации планирования централизованного запуска вот это всего с параметрами немым и money вот конкретно я делаю мониторинг у нас есть мониторы который все группы знают эти метрики снимают оркестр от armani дела но потому что все от конечно любопытно но если ты чем запускать массовый смысле вот докер запускается руками же работают вот есть не руками я поняла старый штанину не руками запускайте вот коллеги там шанс всего лишь вами парке много всяких чтобы спасти большое тебя подловили использующий ты это про такси не смысле все группы до сперва добейся поля у меня еще один вопрос а вот тут настройки чисто все по миллисекундам но у нас елочное будущая там где-то одни процессор и другие где-то мдм откопали стойку карта армандо вообще обнаружился там 705 стойки вот как это все на разные процесс и арка вот кстати каждый процессор найти группы получают ну смотри вообще если у тебя есть процессор частоты x то отделяя половину этого ядра ты по факту выделяешь процессор x пополам можно в таких попугаях мерить то есть ты говоришь я выделяю не какие-то там планируем ягер такого такой-то машины я выделяю 500 мегагерц и тогда запускаешь на 500 мегагерц на армия но гранулярный сам подбираешь вот а сейчас запускать что если вы все-таки процессы вот если вам надо прям latency critical сервис отделить вы его вешаете на эти процессы в своей фоновые задачи вешаете на остальные проц и то они практически вообще в этом не влияет то есть там orchid scheduler этом незаметные получается но это не тру способ на мой взгляд думать про то сколько вас процов какие они кто на каких сидит но если вам прям надо может еще в эту сторону покопать это уже был последний вопрос да у нас вышло время поэтому коллеги ловите калио на его стенде компании от метр и кулуарах да по силам спасибо большое поле"
}