{
  "video_id": "ro5elDuwrn4",
  "channel": "HighLoadChannel",
  "title": "Создаём отказоустойчивый деплой приложений в Kubernetes / Олег Вознесенский (Газпромбанк Тех)",
  "views": 1450,
  "duration": 2664,
  "published": "2024-10-29T03:08:44-07:00",
  "text": "Всем привет в этот пасмурный зимний ветреный день очень рад вас всех видеть под уютной крышей сколкова а буквально пару слов о себе в it индустрии Я работаю большую часть жизни и опыт полученный за это время позволил занять мне должность исполнительного директора по разработке в Газпромбанк в департаменте который занимается Machine Learning и biga а Газпромбанк - это крупнейший банк с очень мощным it прекрасное место работы От всей души рекомендую Аа мы в газпромбанке очень большую роль отводим надёжности тех решений которые мы делаем И вот этот вот доклад он а на самом деле является продолжением а предыдущего доклада который я делал На прошлом хайло я по докладу буду а раскладывать некие ссылочки кто захочет сможет скачать посмотреть А ссылка на презентацию будет на последнем слайде о чём этот доклад глово сре установили блин глово сре установили что Порядка 70 Проблем прон Проблем происходит во время изменений на уже работающей системе то есть они как бы рекомендуют создавать постепенно выкат быстро и точно анализировать проблемы и если что-то случается откатываться и Согласно моим собственным ощущениям если у вас хорошо отлаженная инфраструктура если у вас хорошо написанно приложение то вот эти вот данные примерно совпадают с реальностью Да именно плой новой версии приложения - это та тонкая то тонкое место вот которое стоит улучшить мой доклад про кубернетес Почему Потому что кубернетес - это самая популярная инфраструктурная платформа которая встречается везде от облаков до Бари Metal и уже имеет ряд встроенных возможностей которые мы вполне можем использовать А вот небольшой планчик по которому мы пойдём И начнём мы с девятого Фактора девятый фактор двенадцати паа Торно приложения а говорит нам максимизирует завершения работы мы должны помнить что экземпляры нашего приложения эфемерные что старт и остановка - это абсолютно нормальная операции которые могут быть в том числе не во время деплоя новой версии что старт и остановка должны быть быстрыми и надёжными и что приложения виснут и падают а поды вится снот ноды виснут приходит ум Killer и вот это вот всё И это но и эту норму девос должны донести до разработчиков потому что очень часто разработчики живут в таком знаете мире сферических СВ вакууме где их приложения работают Вне времени да Или просто живут в масштабах программ запущенных там на своём тестовом машине на своём тестовом рабочем месте поэтому давайте проговори как запускает и останавливает поды прекрасно изложен в книге марка лукша кубе in Action и давайте мы сейчас Это проговори для тех кто не читал эту книгу Если Вы захотели запустить ваше приложение в кубернетес Что произойдёт произойдёт какое-то событие на основании которого кубернетес контроллер менеджер А создаст события создаст задание на создание пода и через кубер cpi запишет это в etcd А дальше его подхватит shed и под перейдёт в ннг далее когда Дин Это значит что для пода подыскивает нода под значит нода найдена и это происходит в рамках коп далее начинают запускаться и контейнеры и Когда они пройдут под переходит в статус и далее запускаются контейнеры рабочие нашего пода под переходит контейнер Ready потом запускаются пробы стартап проба после не когда они проходят на под идт трафик под переходит в рейде что мы можем здесь ускорить прежде всего нит контейнеры стоит помнить что они запускаются друг за другом друг друга ждут и в них нужно делать только то что нельзя сделать другим способом Да поэтому минимизируйте их количество и Используйте ИТ контейнеры только тогда когда это нельзя делать в коде например Недавно мы с коллегами отлаживать запуск подов в которых запускаются задание airflow это популярный ATL Sher и мы смогли ускорить запуск на 20 секунд в кубес убрав и контейнер который на основании делал дела В том чтот для доступа к внешним сервисам нужен был в считанных единицах шагов Да но убрав его мы сэкономили вообще кучу времени на ожидание следующий момент время от инициализации до того как на поино можем сэкономить хорошие пробы - Это экзистенциальный вопрос и каким образом сделать хорошие пробы Я говорю в предыдущем докладе но мы можем ускорить процедуру инициализации первая возможная проблема - это прогон миграций в ИТ процедуре это очень плохая но очень частая практика Да миграции мы должны делать один раз при старте деплоя далее какое-то скачивание асетов установка конне В общем кто-то что-то поленился сделать на этапе сборки а сборки имиджей да И сейчас оно нам это мешает Не надо так и последний момент Т компиляция если вы не знаете что это такое хорошо Если вы знаете что это такое Оцените так ли это вам нужно а столько ли вам это даёт бонусов да в сравнении Да с тем что это очень сильно задерживает Старт нашего контейнера Окей остановка пода это на самом деле гораздо более важно чем старт и Давайте разберёмся как это происходит Значит у нас событие под стоп в контейнеры пода посылается ситер ожидается какое-то время по умолчанию 30 секунд и в контейнер посылается сил Что может пойти не так Прежде всего это обработка ситер Если ваше приложение Не обрабатывает ситер может прийти и сделать Вам больно Когда в приложение приходит сите оно должно обработать все запросы вернуть результат закрыть сессии удалить подписки на очереди закрыть соединение с БД В общем сделать всё чтобы его завершение было не замечено остальными участниками обработки А наших нагрузок Да а на самом деле это не очевидный момент потому что ну например у нас есть Java со сприн бутом и вот эта вот связка получив ситер она просто убьёт всё что внутри jav машины но в спринг недавно появилась опция secm shutdown graceful и Вот выставив её мы можем перехватить тем и корректно его обработать то есть нужно знать ваш ранта нужно знать ваши фреймворки чтобы корректно делать остановку пода следующий момент Стоп хуки так называемые Что такое сигналы в Linux это способ межпроцессное их великое множество вот некоторые которые посвящены остановке У нас есть SIG это интерактивное завершение процесса допустим Если ваше приложение работает в гуе получив Син оно может спросить А Вы точно хотите закрыть моё окошко и проигнорировать если вы скажете Терм - это штатное завершение процесса sec - это чуточку более настойчивое завершение процесса сил - это как бы безусловное завершение которое мы не можем перехватить Но вот эти вот соглашения они не всегда очевидные не все их придерживаются и например он SH делает как раз по sec то же самое PHP fpm Если вдруг у кого-то он ещё есть там штатное завершение это Это sec что мы можем сделать мы можем сделать стоп хуки которые будет выполняться до остановки пода для джинса мы можем использовать jle для того чтобы триггернуло недостаточно PHP fpm работает по модели когда у него есть мастер процесс есть воркеры и без настрое просто Control Timeout вот эти вот связанные процессы Да он просто прибьёт да то есть нужно кроме ран тайма фреймворков знать особенности вашего базового программного обеспечения и последний момент удаление endp endp как правило у нас делается кубе сервисом сервис - это как бы сущность которая в кубес делает множество функций но Нас интересуют Сейчас две Service Discovery и маршрутизация Service Discovery - это когда сервис на осново переданных ему меток А ищет поды и делает на основании них эндпоинты то есть эндпоинты - это поды фактически которые соответствуют ме меткам и прошли нис пробы вот тогда вот на них идёт трафик то есть мы их можем посмотреть C Get ends и удаление энпо у нас делается совместно с остановкой но нас интересует как это происходит в общем то есть когда у нас на Plane появляется задание на удаление пода записывается задание на удаление НТА тоже в etcd на ноде у нас работает лет который периодически через рне API скачивает конфигурацию своей ноды и пытается её применить Да через контейнер он посылает сигналы Да останавливает контей дальше у нас есть Proxy который через cni плагин удаляет endpoint То есть endpoint у нас делается cni плагином и как правила делается при помощи правил AP tables с использованием cont но проблема в том что энпо есть это те White сущности и они есть на каждой ноде кластера вот эти вот правила tables То есть даже если на ноде нет контейнера там производится удаление НТА но у насл основанная схема поэтому некоторые ноды могут пропить с удалением нпои со скачиванием применением конфигурации Кроме того в kubernetes У нас есть Ире и серс Маши которые точно также следят за эндпоинт свою конфигурацию в зависимости от того что нашли то есть при а получени сик Терм мы а должны понимать что трафик может продолжать идти на под после получения сик Терм и мы должны уметь обрабатывать этот трафик если мы у нас приложение которое этого не делает мы можем использовать вот такой вот лайфхак добавить в преп хуки какую-то задержку кстати ВН по умолчанию в официальных имиджа jing сейчас вот эта вот проблема sec устранена Да поэтому можно просто слип оставить в этой команде Вот Но вот эта вот схема Она плохая она увеличивает время остановки она жрёт ресурсы Поэтому если мы самостоятельно разрабатываем приложение мы должны это делать самостоятельно мы можем либо обрабатывать принимать запросы и обрабатывать их Надеюсь что они в йф период обработают либо возвращать ошибку обработки запроса то есть нам лучше получить ошибку и сделать ретрай чем ежели приложение просто закончит слушать сеть Да мы Отвали вся по тайм-аут и всё равно сделаем ретрай кстати про таймаут ретрай я рассказываю в предыдущей а лекции резюмируя всё вышесказанное быстрый старт и корректная остановка подов кубернетес - это та база на которой делается не только а отказоустойчивый выход приложения но нормальная стабильная эксплуатация приложений это стоит помнить это стоит практиковать Окей стратегии деплоя вот наиболее популярная стратегия деплоя сейчас мы разберём их все но прежде чем их разбирать Давайте сформулируем критерии по которым мы можем их сравнить и выбрать лучшую Первое - это толерантность к сбоем простое Ну ради этого мы здесь собрались следующий момент консистентность в рамках деплоя у нас в рамках некоторых стратегий у нас могут работать Две версии приложения между ними может перебрасывать трафик рандомно и если их функционал различается это может приводить к некоторым коллизия Да неприятным следующий момент ресурсо емкость Сколько нам нужно оборудования для того чтобы реализовать ту или иную стратегию следующий момент прогрев инфраструктуры у нас могут быть кэши которые требуют заполнения у нас могут быть агрегаторы соединений Да которые могут ломаться при пло у нас могут быть авторы которые работают на основании Трик которые могут сбрасывать при деплой новой версии приложения и у нас есть длительное соединение есть такое понятие метастабильное состояние системы это когда система на при одних и тех же внешних условиях может быть либо стабильна либо нестабильна и переходить из одного состояния в другое из-за каких-то внутренних А возмущений И вот это вот метастабильное состояние классический объясняется на основе длительных соединений допустим у нас Hot который где клиенты используют Ну допустим весо да И тут происходит какое-то событие неаккуратный деплой и вот эти вот длительные соединения установлены должны массово пере соединиться Переустанови у нас испытывают повышенную нагрузку н да Потому что им нужно сделать защищенную сессию обменяться сертификатами сгенерировать сессионные ключи вот это вот всё у нас система аутентификации авторизации испытывает повышенные нагрузку потому свою корректность поэтому система может лечь и самостоятельно не подняться об этом стоит помнить и простота отката Ну Мы помним что глово сырье рекомендует откатываться если что-то прошло не так Итак что есть в кубернетес из коробки У нас есть recreate Rolling update и частично caner а два объекта два примитива при помощи которых мы эксплуатирует это dipl для stateless и stateful для stateful Но как правило версии приложения Да используют для Ну они Да А обновление обновление приложений оно достаточно сложное и не сводится к тому чтобы выбрать какую-то стратегию обновления да Там слишком всё завязано на способ с которым приложение работает со ФМ там нану лею ВМ дамы прожим sle части как наиболее а частого кейса а Итак recreate при recreate У нас есть старая версия приложения мы его Выключаем деплоя и обновляемся а для её настройки мы должны в деплоймент выставить Strategy Type recreate и по критериям у нас толерантность к сбоям и простоям recreate - это гарантированный outage да это гарантированный простой консистентность всё хорошо в одно время работает только одна версия приложения по ресурсом кости тоже всё хорошо нам не нужно дополнительного оборудование по прогрева по прогреву инфраструктуры понятно всё плохо простота отката неоднозначная Ну кто-то может сказать А давайте возьмём gitops и будем откатываться просто git rever но обновление приложения Да обновление выход новой версии - Это не просто поменять подики на новую версию имиджа часто с этим идёт изменения схемы данных да накат миграций И когда мы делаем recreate у нас нет стимула а делать вот э вот с совместимы для старой новы приложений поэтому старая версия приложения может просто не заработать на новой схеме данных и Ну за свою карьеру Я не видел хорошо написанных откатов миграции то есть откат нужно продумывать отдельно для Rec Когда стоит использовать Когда нужна строгая консистентность допустим у нас валидатор крипты и мы понимаем что дублировать подтверждение для нас гораздо хуже чем немножко полежать далее У нас есть технологическое окно в кото мым нашу инфру И приложение не обрабатывает входящие запросы допустим у нас л воркеры Да которые подписываются на очередь берут оттуда задания и выполняют И если мы можем перекати быстрее чем наступит SL на обработку очереди recreate - это дёшево и сердита окей Rolling update при Ring update мы постепенно Выключаем как бы старые экземпляры нашего приложения на их место выкатываем новое трафик берут соседние Ну работающие экземпляры Вот и таким об выва для его настройки мы должны выставить STR Type Rolling update далее У нас опции Ma количество подов которое мы можем отключить Да Ma sech количество подов которое мы можем поднять дополнительно то есть мы можем либо отключать старые версии приложения на их месте запускать новое либо поднимать новое потом отключать старое либо как-то комбинировать это поведение далее У нас есть период после которого под считается работающим это можно использовать для прогрева инфраструктуры далее У нас есть Progress deadline Seconds это та после которого если выход не прошёл деплоймент откатится но а как правило в релизе мы катим много объектов и откатить один деплоймент недостаточно то есть Может у нас идти deployment и config Map которая в котором содержится конфигурация для новой версии нашего приложения и в откате всего релиза если что-то пошло не так нам может помочь helm package maner с ключом Atomic и та выставленным тайм аутом он откатывается релизы если что-то пошло не так и в одном из своих предыдущих докладов я рассказываю Как правильно трекать релизы в package maner А что по критериям толерантность к сбоям и простом потенциально очень хорошая консистентность плохая Да у нас Две версии приложения между которыми лапает трафик Прошу прощения ресурсом мы можем сделать сценарий как с дополнительным оборудованием так и без прогрев инфраструктуры потенциально очень хороший и простота отката тоже хорошая пару слов о том как мы можем улучшить консистентность Rolling update если у нас приложение которое предоставляет API мы можем версионирование в одной веб-студии в которой фн и были совмещены в одном поде и были достаточно длительные Выка здесь мы описываем ингресс с Вот такими вот аннотациями на основе них ингресс контроллер раздаёт клиентам ки и на основании этих кук связывает клиента с каким-то конкретным подом Что может пойти не так э как бы ситуация характерна не только вот для этой схемы она характер вообще для всех длительных соединений где есть связь клиента см допустим у нас старая версия приложения и трафик на него идеально отбалансировать Round Robin разбрасывает трафик А ну вот такая вот да соседние поды испытывают повышение трафика мы перекатывает торой а L balancer па Robin перенаправляет трафик и мы видим что на старой версии приложения трафик увеличился больше чем в два раза далее мы перекатывания вот такой вот дисбаланс А это как бы нужно помнить и либо закладывать дополнительные ресурсы либо не использовать L banc с Round Robin Да некоторые сервес мыши они умеют балансировать трафик на основе состояния серверов на основе состояния экземпляров И следующий момент - это фича тогл или фича флаги эта фишка пришла к нам из trank based development методики разработки через git при которой фича ветки очень коротко живущая то есть буквально один 2 дня Вы должны смержить фича ветку но запилить фичу за 2 дня очень сложно поэтому вводят некоторые переключатели фича флаги которые могут включать или отключать новый функционал соответственно когда фича готова Мы выкатываем на продакшн выкатили новую версию потом включаем новую новый функционал коллизий не происходит когда стоит использовать Rolling update когда мы решили проблему с консистентность деплоя когда мы нужно минимизировать простое И когда у нас частый релизный цикл Rolling update прекрасно автоматизирует и Ну достаточно быстро работает резюмируя вышесказанное стратегии деплоя которые есть кубер по умолчанию мы можем использовать совместно в рамках одного релиза то есть допустим фн и мы можем перекатывать Rolling update Да л воркеры мы можем перекатывать и вот это знание того как работа ложение оно необходимо для того чтобы сделать нормальный отказоустойчивый выход Окей blue green blen вроде как достаточно Просто у нас есть старая версия приложения У нас есть новая версия приложения а мы просто переключаем траффик Если всё Нас устраивает останавливаем старую версию приложения живём на новой что по критериям толерантность к сбоем и простоем неоднозначно тут есть нюанс который мы сейчас обсудим консистентность высокая фик одновременно у нас идёт только на одну версию приложения ресурсо емкость плохая Да Нам нужна двойная инфраструктура чтобы его реализовывать прогрев инфраструктуры Ну потенциально плохой и простота отката экстремальная Да Нам нужно просто переключить трафик назад А что может пойти не так прежде всего Нам нужно обеспечить СХ совместимость схем данных поскольку у нас Две версии приложения работают одновременно Да Далее мы должны помнить что есть не только фи на наши приложени наши приложения сами могут делать какие-то исходящие действия как я уже говорил да могут быть л воркеры которые подписываются на очередь и берут оттуда задание и вот если мы делаем blen И у нас в системе есть такой элемент да то новая версия может подворот деплой новой версии и остановка старой классический Прим который прил к нам е с состоит в том что лаем и попеременно то в то в один то в другой И если мы не обложило автоматизации то Пере деплоить рабочий это просто вопрос времени в куберто мы можем создавать окружение с нуля и Ну например мы можем для новой версии приложения общем делать для нашего приложения используя версию приложения в качестве суфикса таким образом не про махнёмся следующий момент переключение трафика для переключения трафика Есть десятки возможностей мы можем использовать DNS да И на самом деле DNS - это не самая хорошая схема переключения из-за общей инертности DNS Как таковой Да если мы работаем в Облаке мы можем использовать облачные лансе мы можем управлять нпои куберто сервис и таким образом переключать трафик для внешних клиентов мы можем использовать и и IP для внутренних клиентов можем использовать сервис мыши но при организации переключения трафика мы должны помнить что он должен быть корректным поясню это на примере вот у нас два на спейса для старой для новой версии приложения в Старом на спейсе у нас описан ингресс мы его удаляем и создаём в новом и вот в этом случае большая вероятность что сессии на старый namespace у нас порвутся и Клиент не получат ответа на свои Запроси Это плохо что мы можем сделать мы можем описать так называемый осем дополнительный Ире вот с такими аннотациями и 100 то есть увидев такие аннотации и контролер переправи 100% нового трафика на наш новый Ире и когда трафик на старый спадёт мы можем просто удалить аннотации удалить старый и переключиться на новую версию таким вот образом Когда стоит использовать BL когда у на облака и дополнительная инфраструктура для нас достаточно немного когда у нас редкий релизный цикл всё-таки blue green он требует определённой раздумье что kry что AB выглядит следующим образом мы заменяем а экземпляры нашего старой версии нашего приложения на новое Смотрим как они работают И если всё хорошо мы продолжаем этот процесс и в итоге заменяем все экземпляры на новую версию а очень похожа на Rolling update правда kry от AB на технологическом уровне отличаются тем что как правило маршрутизация трафика при AB происходит на клиенте или на основе клиентов то есть мы выделяем группу клиентов которые а пускаем на новую версию нашего приложения и следим за этим cany - это как правило а какое-то вероятность распределение там 90% трафика на старую 10% трафика на новую версию Вот и прежде первое что мы должны понять когда делаем caner или AB что это скорее не стратегия деплоя это тесты это возможность проверить новую версию нашего приложения на реальном трафике то есть в AB мы оцениваем реакцию пользователей на наш новый функционал и здесь главную роль играет мониторинг с метриками пользовательской удовлетворённости caner testing - это тестирование новой версии нашего приложения на трафик и здесь важен мониторинг с метриками стабильности и производительности Вот и canary от recreate отличается как раз полнотой Рик и переключение в зависимости от того что у нас на мониторинге что по критериям оценки А caner может иметь проблемы с консистентность если мы распределяем трафик на основе весов Да ресурсо емкость Ну мы можем реализовать сценарий как с дополнительным оборудованием так и без по остальным а критериям но вроде всё достаточно неплохо какие здесь есть нюансы это управление трафиком и масштабирование версий и первый вариант Каким образом мы можем управлять трафиком - это на основе масштабирования версий классический пример реализации caner - это когда у нас есть два деплоймент в одном на спейсе деплоймент имеют разные имена разные версии имиджей но одинаковые метки и описан сервис который за счёт одинаковых меток может брать деплоймент от одного и от другого деплой И за счёт изменения количества реплик мы можем регулировать трафик на старую и на новую версию Но вот этот вот пример он хорош для примера Да я не видел чтобы в реальной ситуации это использовалось на реальном продакшене и для маршрутизации трафика как правило применяется что-то как бы более тяжёлое там Игрес серс и как бы времени нам не обсудить Всё Давайте разберём на основе инса и ну реализация маршрутизация она примерно одинаковы Да принцип реализации примерно одинаковые во всех этих системах Да разберём на основе игре прежде всего мы можем маршрути Зро трафик на основе весов А и мы это уже разбирали да когда говорили про а то есть а тфу про blen то есть blen от отличается просто как бы мониторингом и способом маршрутизации Рафиков да мы описываем дополнительный Ире где делаем аннотацию и описываем количество трафика который мы хотим пустить на собственно новый экземпляр нашего приложения Вот это применяется как правило для далее мы можем маршрути Зро трафик на основе того что приходит к нам в соединениях это может быть Ну например заголовки headers сци для маршрутизации по заголовкам мы описываем мы должны описать имя заголовка и его содержимое да для организации маршрутизации по ки мы должны описать имя ки то есть ну тут бинарная Логика есть ку нет Ку содержимое нас не интересует когда что использовать Это зависит ваших бизнес-процессов с хедера Да вы можете Как производить авторизацию клиента и говорить их и ну выбрать каких-то любимых клиентов и говорить Им типа вот эти вот клиенты да Давайте нам заголовок И мы вас спустим на новую версию нашего приложения да Либо мы можем раздавать печенки какому-то рандомно а народу Да и таким образом регулировать трафик Да кто пойдёт на ри Окей масштабирование версий А поскольку инфраструктура у нас не резиновая как правило мы не можем себе позволить дополнительный такой же экземпляр поднять поэтому масштабирование трафика у нас масштабирование версий у нас должно успевать за масштабированием трафика хороший момент здесь использовать авто скейлеры горизонтальный под авто встроенный в кубернетес если у нас стандартные метрики там CPU память либо если у нас кастомные метрики Ну например кеда или ка вот и в кубернетес и его экосистеме есть все компоненты Чтобы построить вот эти вот а но если вы не готовы самостоятельно собирать пазл Если вы не готовы автоматизировать да состыковать эти элементы Вы можете взять уже готовые программные комплексы которые могут реализовать вам нужную стратегию наме и тотже Лизет straty стратегии kry AB blue green трафиком он может управлять при помощи там большинства известных сервис мышей и ингрессо и облачных НСВ и переключать трафик на основе метрики с всех самых популярных систем мониторинга но к сожалению мы вот это вот не сможем обсудить поэтому давайте сделаем так а оценить пожалуйста мой доклад Если вы нашли его полезным Если вы хотите доклад со сравнением аррау и флаера Напишите об этом пожалуйста в комментариях Вот ссылочка на мою презентацию готов к вашим вопросам Спасибо олек Спасибо большое за нагрузочное тестирование кампуса Это первый доклад на котором стоят в проходах ребята обожаю Давайте зададим вопрос Пожалуйста поднимайте руки на первом ряду вот есть вопрос даже два Вот раз Да и потом два пожалуйста лучше говорить кто ты и чем занимаешься чтобы Network был настоящим Да спасибо большое за доклад Меня зовут ганцев Юрий компания клинта н разработчик А собственно У меня вопрос часто приложения на старте активно потребляют цпу особенно этим грешат СН сприн приложения и при массовых пях Ну да контейнеры могут драться за цпу соответственно и не успевать в Lin redn пробы ну и соответственно их перезапускает и цикл повторяется Что можете посоветоваться Аа скорее всего они жрут ресурсы из-за Аа плохой системы инициализации а процедуры инициализации там скорее всего миграция или вот что-нибудь типа такое тяжёлое далее у вас скорее всего там включена ДТ компиляция поэтому Оцените приложение с т компиляции без ДТ компиляции далее У нас в кубернетес есть реквесты и лимиты возможно Ну не знаю вам стоит перейти то есть есть две стратегии управления ресурсами это когда у нас реквесты меньше лимитов то есть по квестам поды забиваются на ноды лимиты - это просто какой-то предохранительный клапан чтобы под не сожрал всё Вот соответственно Вы можете выставить их реквесты меньше лимитов да либо можете выставить равными Да это ранти то есть мы гарантируем тот ту мощность которую запросили далее У нас есть стартап проба который обязательно нужно делать для springboot приложени Вот она как раз позволяет не перезапуска по пробе Вот какие ещё рекомендации блин что-то ещё хотел А можно как-то объяснить шедуле чтобы он не маршрути Зро там больше ДХ подов условно на од ноду спасибо Вот раз это те ска существует механизм под Anti affinity это когда мы одна поды имеющие одни и те же метки разбрасывая по разным нодамэ прогрессивный выкат Да когда мы попеременно выкатываем да сможет помочь решить эту проблему Спасибо делайте ролинг адет вот тоже на первом ряду только правее Олег спасибо большое за доклад Дмитрий Яндекс 360 вопрос Когда мы выкатываем канарейки грины нам важно понимать получилось или нет ну чтобы это понимать мы смотрим на графики Но каждый раз графики пере собирать под канарейки мы наверное не хотим потому что ну это частый процесс хотим готовое Вот какие Бест практис вот организации настройки мониторинга подг конаре флаер Об этом я могу рассказать в новом докладе про флаер по Метрика У нас есть авто Discovery Да мы можем описать метрики которые точно характеризирующий стабильность Вот и флаер он как бы может различать Какие метрики на старый Space пошли Какие метрики на новый най Ну он сам делает эти эти экземпляры вот таким вот образом Лагер добавляет теги нет теги добавляют сами приложения точнее нет теги у нас добавляют мониторинг когда считывается конкретного найса фик и Лагер по вот этим тегам по дополнительной Мета информации он может понять Да хорошо пошло или нет Вот это ели анализирует сигналы из мониторинга да А сейчас Да он может проте datadog Cloud wch New графит и вот это вот всё прикольно спасибо спасибо большое вот наверху смотри Прямо под вот правым центральным фонар сейчас сейчас попробую Вот вы светили Да да здравствуйте Тарасов Сергей компания Бей Спасибо за доклад в начале доклада вы упоминали ДТ компиляцию и в первом вопросе она опять звучала у нас как раз микросервисы на Java и jit компиляция активно используется всё-таки Какие конкретные рекомендации можете дать что с этим делать а jit компиляция - это когда Java берёт Исходный код Аа далее мелко перемалывает его в бинарную кашу попутно оптимизируя и таким образом потенциально приложение может работать чуть быстрее так вот рекомендация включить Т компиляцию прогнать нагрузочное тестирование отключить Т компиляцию прогнать нагрузочное тестирование и сравнить результаты и прикинуть да если Т компиляция на старте ваших контейнеров приносит больше проблем чем пользы оптимизации при обработке трафика то лучше отключить наверное слушайте Ну это очень странно компиляция Она же в нативный код преобразует там производительность в разно даже в порядке быстрее работает поэтому странно Так что ки делать Нет нет нет ну не в разы не в разы и очень сильно всё зависит режим интерпретатора и компиляции Да ну в общем стоит оценить В общем это очень сильно зависит от того как написана ваша программа написан ваш код сделайте нагрузочное тестирование с ДТ без т и это снимет все вопросы Спасибо и не называй меня спикеров странными Ладно хорошо а передайте пожалуйста через проход микрофон на ту сторону Да спасибо большое так слышно Да здравствуйте Меня зовут Денис компания Сбербанк Технологии вопрос по поводу ингр сов какие есть плюсы и минусы между подходами использования кубовых ингрессо и сервис smh предположим какой-нибудь ИО или linkerd ингресс А это для клиентов которые находятся вне кластера как правило и это гораздо более легковес а схема да сервис Маш всё-таки тяжёлая штука хорошо Ну это в любом случае Понятно ели какие-то возможности которые может предоставить только in или возможности которые может предоставить только сеш в принципе схемы а алгоритмы по которым они работают они достаточно похожи ну сервис мыши в зависимости от реализации Да могут предоставить больше возможностей чем ингс на мой на мой взг Тут всё зависит от реализации и от ваших потребностей всё хорошо спасибо спасибо Вот там тоже сверху чуть-чуть левее и ниже нам машут фонари пожалуста Владимир Олег спасибо за доклад такой вопрос по стратегия деплой у вас в докладе было сказано что проблемы с миграци есть только в стратегии и ну по сути Она же никуда не девается и при то есть Нам нужно схему баз данных держать для нужной версии приложения Я не говорил что миграции есть про про blen это был вопрос про схему баз данных то есть схемы баз данных мы можем делать как совместимое так и несовместимое со старыми версиями приложения по вопросу запуска миграций в ИТ процедуре или ИТ контейнерах Ну на мой взгляд не стоит этого делать нужно запускать один раз в начале деплоя нашего приложения потому что запуск процедуры миграции в ИТ контейнере может вызвать просто больше проблем чем Спасибо Спасибо у нас на третьем ряду Следующий вопрос здесь в чатик пишут комментарии про Java Используйте gral VM лидирует VM - это наверное Vir Machine не сталкивался но я обязательно проработают вопрос Спасибо за буд добры Приве у нас друзья Привет меня зовут Спасибо за доклад компания я хотел роваться по поводу стоп хуков Да мы сами Просто на этом технически сказать подорвались у нас были проблемы в продакшене что у нас сервис завершался к нему шл соединение и Клинт не смог до него Достучаться потому реплику которая не прерывает соответственно Мы тоже так сказать добавили прип добавить там СП и вроде бы всё стало хорошо и такой вопрос ели какое-то систематическое решение этого вопроса выглядит немножко как такой Знаете ну Костыль грубое слово но какое-то Костыль решение есть Может там сервис СШ допустим как-то решает эту проблему систематически или какой-то другой подход к этому решению како проблемы потому что он э проблема достаточно очевидная а есть ли какое-то для этого систематическое решение А у нас есть тайм-ауты у нас есть ретра которые мы можем делать при помощи каких-то инфраструктурных элементов ингрессо в сервис мышей я рассказываю об этом в предыдущем докладе можете скачать доклад по ссылочки посмотреть ознакомиться с этим докладом но как бы если вы не используете сторонние программы Да сторонние сервисы в код которых не можете внести изменения А разрабатываете это самостоятельно Просто добавьте обработку трафика после получение сик Терм Да вот хорошим наверное решением будет просто отдавать ошибку А какую-нибудь на попытку входящего соединения и видя эту ошибку делать ретрай при помощи какого-нибудь сервис Маша ну то есть условно сервис smh это можно было бы разрулить А плюс-минус у вас была проблема в том что приложение завершали слушать порт да а это тайм тайм-аут - это всегда как бы увеличение времени обработки запроса Вот вот таймаут нужно исключить по возможности и лучше это делать Вот именно в коде приложения в коде именно клиента в данном случае а нет в коде сервера Угу сервер получил сите и отдаёт ошибки вот с Сервис Шом мы можем настроить А тайм-ауты да чтобы сервис МШ не сдал там дольше какого-то недопустимого времени когда приложение ответит и он может сразу же ретрай там на другой доступный бкд а наш запрос Вот но тайм-аут здесь основная плохая вещь - Это тайм-аут да Ясно спасибо большое спасибо Олег пока ты думаешь кому подарить книжку а кому сувенир за два лучших вопроса Я просто напомню друзья сейчас спикер выходит из зала направо в дискуссионную зону там можно подойти позадавать вопросы Ну и в целом у Газпром теха есть стенд поэтому Можно потом подойти э поговорить лично не публично Итак кого о дарим а книга называется проект Феникс Я думаю большинство здесь её читала но такое впечатление что вот человек который задавал первый вопрос Находится в таком самом начале пути и такое впечатление что ему проект Финикс подойдёт больше отлично драйв Спасибо за вопрос вот а второй вопрос человеку который задавал вопрос про Т компиляцию да про джаву А я очень надеюсь что он разберётся с пользой джит компиляции возможно Ну расскажет сообществу насколько джит компиляция полезна а Подойдите пожалуйста к волонтёрам они вам вручат мерч от конференции специально Олег Ну тебе тоже традиционно О спасибо очень приятно суперприз Спасибо большое"
}