{
  "video_id": "o3brXgHL3zQ",
  "channel": "HighLoadChannel",
  "title": "Как сделать поиск в интернет-магазине / Степан Родионов (X5 Digital)",
  "views": 1217,
  "duration": 2809,
  "published": "2024-04-17T01:09:41-07:00",
  "text": "Я безумно рада что все вы добрались Вот правда рады всех видеть Я понимаю что лето жара тяжелые выходные Здорово вы на конференции это обалденно Я думаю что все слышали инструкцию мы отключаем звук мы задаем вопросы Мы по максимуму пользуемся совершенно потрясающей инфраструктурой конференция Я точно знаю что многие скорее всего будут работать Поднимите руки у кого с собой ноутбуки Давайте по-честному Итак ребят Не надо я сама так часто делаю Это не очень классная история вы приехали самую крупную реально походу самая крупная А те конференция за много лет не надо работать что надо Можно конечно общаться Это здорово общаться можно со своими друзьями общаться можно со знакомыми и с незнакомыми тоже можно и нужно даже если вы воробушки классно но можно Внимательно слушать доклады Поверьте мне докладчики очень много и тщательно готовились Им будет приятно Если вы будете смотреть мобильные Им будет гораздо менее приятно если вы будете смотреть на докладчиков гораздо более приятно но и это тоже не идеально От всей души рекомендую задавать вопросы то есть не просто слушать а пропускать через себя и задавать вопросы чтобы вынести что-то действительно нужное для себя конкретно Короче я официально разрешаю мучить докладчиков прямо по жести вопросиками так чтобы ну не просто так да пришли на сцену надо как-то отрабатывать Вот как можно задавать вопросы после доклада поднимаем руки к вам подходит хелпер и задаете свой вопрос если вы стесняетесь либо если вы в онлайне за что вам огромное спасибо в онлайне Мне кажется сложнее слушать а-а Пишите в чат я буду читать и дублировать их голосом не гарантирует что все но я буду очень-очень стараться и за лучший вопрос а мы будем дарить подарки Итак всем докладчикам приготовиться надо запоминать вопросы выбирать лучший вот как по моему опыту докладчика это самое сложное Вот но я думаю что Вполне возможно с этим справится Вот и перед тем как начнем Я хотел бы представить еще раз нашего генерального партнера команда гараж эйт в этом году компания опять стала генеральным партнером питерского халота и все для того чтобы поближе познакомиться с участниками и показать какие возможности может принести это знакомство с 2011 года гараж прошли путь от гаражного стартапа до экосистемы и приобрели друзей с которыми успешно разрабатывают инвестиционные продукты которыми пользуются в Азии Латинской Америки Африки и Европе и это не предел сейчас гаражей - это международная продуктовая компания которая разрабатывает экосистему высоконагруженных финансовых сервисов Ну что На этом прекрасном моменте Я хотела бы уже передать слово нашему первому спикеру Степану родиону из X5 1 1 Всем привет Я надеюсь что все проснулись если что я не увижу что вы смотрите в телефон и не расстроились меня слепит этот свет Давайте начинать Значит сегодня мы с вами поговорим о вечном мы поговорим о поиске в интернет-магазине в любом якоме такая задача встает эта задача Типовая и как любая другая Типовая задача Она имеет типовое решение о чем будет вообще в моем докладе около десятка и коммерц проектов я запускал и в каждом из них делали поиск и вот обобщение этого опыта Я как раз постараюсь облачить некую инструкцию по созданию подобного рода систем чего в докладе не будет не будет какого-то жесткого хайлоада потому что все проекты они скорее относятся к размеру средних Да и в принципе крупные проекты вроде озона там Яндекс Маркет Например я не знаю как их обобщить можно ли вообще так сделать поэтому говорить Будем о проектах среднего размера а какой мы с вами будем делать поиск есть два основных сценария кассетные и полнотекстовый что такое фасетный поиск фассетный Когда у вас есть какие-то категории какие-то фильтры вы их накликиваете и получаете какой-то результат Ну вот можно представить Это в виде такой визуализации весь слайд Это молоко есть какие-то фильтры на пересечении у нас сами товары которые попадают под все условия в полно текстом все еще проще вы просто набираете запрос текстом Ну и система пытается угадать Какие товары под него подходят все думаем пользуются и о Проекте я говорил что проектов много но чтобы было интересно будут ссылаться на последние самые крупные собственно мой текущий проект Это prok.ru что такое prok.ru Мы входим в Digital и все вместе занимаем на российском рынке третье место конкретно в проку цифры можете видеть здесь примерно 10 регионов в присутствии в Питере тоже есть Можете опробовать если кто Местный и среднего размера Такой крепкий проект давайте к содержательной части И с чего мы начнем когда мы создаем какую-то систему у нас как правило уже что-то есть редко создаем систему прям с нуля немногим так везет и у нас тоже что-то было впрок начинал давно-давно с стартапа на ла равеля и первой версии поиск был сделан прямо на этой лаве на рынке это естественно Никуда не годится поэтому очень быстро накрыли все решением нас финксе Что позволило худо-бедно держать пользовательскую нагрузку у этого решения был ряд недостатков во-первых Это был только поисковый индекс в нем хранились данные непосредственно для поиска перед тем как отдавать на витрину их надо было обогащать обогащали прямо из Мастер базы то есть нагрузка с нее толком не сняли и каждый каталожный запрос нагружал основную базу данных очень сложно мы вообще честно говоря так и не научились обновлять все документы по одному только переналить целиком весь поисковый индекс со всеми товарами и вы не можете заменить какие-то отдельные документы Ну если масштабированием сфинкса тоже все не так просто задача достаточно сложная и вызывало огромное количество геморроя в общем стал вопрос над тем чтобы сделать что-то новое салон двадцатом году когда нагрузка на онлайн очень резко выросла и мы стали выбирать варианты А какие вообще варианты есть их на самом деле много Можно например сделать все сами руками берете команду хороших офферов берете пару кварталов времени и прям вот руками запиливаете систему поиска звучит страшно так делают в этом нет ничего Сверхъестественного крупные компании наверное все Однажды к этому приходят Это самый дорогой способ сделать систему поиска но у него есть существенный плюс в случае если вы берете какую-то платформу она вас ограничивает причем вы как правило не Эксперт в этой платформе и вы сталкиваетесь с этими ограничениями ровно тогда когда уже поздно в случае разработки своей системы с нуля Вы сами выбираете Какими будут эти ограничения Вы можете сделать их под себя Вот и таким образом Эта система будет чуть более хорошо удовлетворять вашим требованиям но повторюсь Это очень дорого есть диаметрально противоположный способ это вообще ничего самим не разрабатывать И подключиться к системам такие saas Search и сервис который будет искать за вас я сейчас не говорю о том чтобы запустить поиск Яндекс на своем сайте Но так тоже делали есть компании которые предоставляют прям услугу поиска вы им товарный Фит подключаетесь им попишке кидаете свои поисковые запросы они вам возвращают ответ в чем плюс такого решения это очень быстро то есть задача двух недель одного разработчика сделать фид И подключиться попишке к какой-то другой платформе минусов тоже вагон вы не управляете этой системой вообще вы не знаете как ее масштабировать вы не знаете насколько она устойчива вам остается только верить Вы не знаете как ее доработать обычно никак особенно если вы небольшой бизнес если вы не их мажорный клиент ваши хотелки попадут в какой-то далекий Быков и скорее всего никогда не будут реализованы Ну и это платная все истории и в данном случае Вы деньги платите не на развитие своего сервиса на развитие какого-то другого чужого проекта что тоже не есть хорошо но что это решение Вам даст вы можете Вот если у Вас вообще ничего нет буквально за неделю получить более-менее сносный поиск на вашем сайте а что еще можно было сделать можно было взять Сфинкс Или например перейти вообще на монтикору начать его тюнить начать его настраивать под себя залезть прям его кишочки здесь в принципе если там глубоко синксон укоренились если уже его как-то даже может быть под себя переделали вариант рабочий но во-первых специалистов на рынке не так много технология с кривой хайпа уже можно сказать слетела и в новых проектах Я не знаю кто-нибудь Сфинкс использует или нет кажется что только в легасе В общем мы не смогли найти людей которые были бы заинтересованы и могли бы нас все нам поиск доработать Ну и последний вариант - это брать уже какую-то специализированную платформу их тоже много и делать решение на ней с нуля мы так поступили выбрали ластик Search вообще elastiksearch выбор по умолчанию если отбросить всякие битриксы то там 8 из 10 и Комов может быть даже 9 будут на эластике А почему так вообще почему все берут эластик во-первых Он легко масштабируется есть Sharing есть репликация в традиционных хранилищах Это довольно сложные истории люди доклады читают на хайлоде люди проходят курсы получают сертификаты что они умеют со всем этим работать в случае с власти кёрчим количеством шардов реплик это два винтовых параметра их просто задаете и все работает естественно есть свои подводные камни Но задача на порядки более легкая нежели при настройке аналогичных вещей традиционных хранилища у эластика отличная фишка и она покрыта прекрасной документацией наверное Любой Ваш продуктовый вый запрос любая фича которая захотите реализовать будет делаться с помощью API которая доступна в коробке будет делаться без боли и у вас будут отличные примеры того как это должно работать в частности там есть языковые пакеты для русского языка то есть если говорить про поиск полна текстовый все что вам нужно уже есть там это же является следствием этого является то что проекты сильные комьюнити вы никогда не столкнетесь с тем что по вашей проблеме есть один единственный вопрос настолько верфлоу в 2017 году который написали по нему ни одного ответа Больше вообще ничего не гуглится потому что вам выдал эластик очень много есть очень много вопросов на них часто отвечают отвечают даже разработчики в гитхабе нам вот например закрыли бак буквально через две недели после того как мы его открыли у проекта действительно комьюнити прекрасные Ну и последний но не самый не наименее важный пункт такой немножко субъективный команда разработки умела и хотела работать с этим проектом Если вы встраиваете в свою архитектуру что-то с чем Ваши ребята работать не хотят вы столкнетесь с тем что они начнут увольняться грустить что Новые люди на собеседованиях начнут вертеть носом что мы с таким работать не хотим с пластиком вам это не грозит не грозит Еще довольно долго а какие эластика минусы не может быть плюсов без минусов во-первых это платформа у него есть свои ограничения вы с ними Обязательно столкнетесь мы столкнулись во-вторых у него нет встроенного индексатора то есть что такое вообще индексатор вот у вас данные ваши Они где-то лежат Вам их оттуда надо выластик засунуть для того чтобы эта процедуру провести вам нужен индексатор в данном случае вам придется спилить его Руками не могу сказать что это какой-то большой минус задача не очень сложно но это надо иметь ввиду и ластик довольно прожорлив то есть вам нужно Быть готовым к тому что даже на не очень большой каталог вам придется довольно много ресурсов на него выделить гораздо больше чем на аналогичные и другие хранилища то есть вот ваш каталог размещенный в SQL базе наверное порядок меньше ресурсов будет потреблять чем размещённые власти и Да вот маленькая Ремарка мы не смотрели Open Search он появился после того как мы сделали принципиальный выбор но сегодня я бы Настоятельно рекомендовал как минимум подумать об этом что такое opensearch Это тот же эластик но отвс однако ребята обещают что фичи которые власти доступны только в платной версии а стало быть недоступной для нас с вами у них есть паблик собственно Именно поэтому они ластик форкнули что они были согласны с тем что ребята начинают новые фишки делать платными что у нас получилось вот такая вот получилась архитектура очень простая с левым Монолит в котором лежат мастер данные по центру системы поиска тот самый индекс про который я вам говорил эластик Search в котором лежат данные и Finder приложение которое обрабатывает клиентские запросы с витрин а витрины это мобильный приложение интернет-магазин обрабатывает запросы витрин ну и соответственно ищет товары отдаёт их на витрины приложение написанные на Go это тоже выбор по умолчанию Особенно для тех кто начинал на PHP стандартный переход с PHP на Go он у нас тоже как раз на поиски произошел О чем еще надо подумать сейчас все приложения не живут на одном дата-центре там мало наверное компании которые живут в одном DC все ваши приложения должны уметь по умолчанию жить на нескольких дата-центров самим приложениями все легко они ставят вас на каждых дата-центрах просто независимые копии Что делать с ластиком это какой-то стейт и вы можете захотеть его растянуть на несколько DC или например не растягивать мы выбрали не растягивать почему это в принципе базово сложная история то есть межсервисная репликация межсерверная репликация гораздо сложнее чем сделать два независимых кластера и обновлять их по отдельности это в принципе нам не особо ничего дает Зачем вообще может захотеться растягивать эластик Ну не потому что мы можем а потому что мы хотим чего-то добиться добиваемся мы таким образом консистентности данных Потому что если мы не растянули то естественно в двух независимых кластерах данные у вас будут разъезжаться в нашем случае это оказалось не так важно данные важные Да клиент видит их каждый день по многу раз но нет требования чтобы они идеально совпадали на нескольких дата-центрах более того если вы все сделаете правильно то сильно данные у вас разъезжаться не будут а ну и наконец независимая инсталляции независимые кластера нам дали возможность во-первых очень легко вводить новые дата-центры не надо ничего дотягивать растягивать перетягивать просто запускаете новый кластер заливаете на него товар и также точно гасите Например если в каком-то дата-центре Вы перестали работать Ну и в принципе их можно почкованием вот так горизонтально размножать до бесконечности главное только вовремя наливать в них данные еще один вопрос который мог возникнуть при взгляде на предыдущую схему а делаем мы одно приложение для поиска или два мы говорили в начале что поисков У нас два типа это две очень разные задачи фассетный поиск Это история очень простая она сводится грубо говоря К числу дробилки То есть у вас есть массивы айдишников товаров привязанных к каждому фильтру вы находите их интерсект задача очень простая полна тексты Вы же поиск Задача в порядке более сложное вам нужно обработать строку разбить её на токены а отбросить окончания стоп слова там синонимы вот то что происходит в квадратики Full текста это люди поэтому диссертации пишут Это по-настоящему сложный вопрос более того эти два поиска имеют разные профильные нагрузки в нашем случае например Это 10% запросов полна текста и 90 процентов соответственно также ещё одна лампочка загорается мы можем хотеть Независимо их масштабировать звучит так как будто надо делить но мы все равно сделали одно приложение Почему так так проще два разных приложения это два дипломимента два мониторинга две разные базы данных потому что они у вас не могут делить одну базу данных если делать все правильно Ну примерно вдвое больше геморроя в то же самое время Мы понимали что мы хотим запуститься быстро что в этот момент надо сделать если вы приняли такое решение так как приложение Однажды все-таки сможете захотеть разделить по причинам озвученным ранее надо наметить шов по которому вот этот микромонолит Finder будет разрезан когда до этого дойдет собственно Так мы и сделали Окей базовые архитектурный вопрос разобрали давайте начнем работать с эластиком Раз уж мы его выбрали как его можно использовать можно использовать его просто как поисковый движок то есть также как мы до этого использовали sings загоняете туда только те данные по которым хотите фильтровать по которым хотите искать А все остальное не поисковые так называемые данные лежат где-то еще и вы перед тем как отдать ответ на витрину оттуда обогащаетесь Ну или витрина сама идет и обогащает тут можно сделать по-разному или какая-нибудь бффка кто во что горазд можно использовать его по-другому как surgen + Data storage то есть тогда вашим эластике будет все что нужно витрине как поисковые данные так и не поисковые и в тот момент когда ваше приложение сходит в поисковый сервис в ответ оно получит уже полный набор данных сможет начать с ними работать больше никуда не ходить чуть меньше точек отказа чуть быстрее за счет меньшего количества запросов общее время работы собственно мы выбрали такой вариант во-первых он избавлял от необходимости делать еще один микросервис обогатить или не было из мастер-базы мы обогащаться условия задачи не могли мы хотели её разгрузить Ну и это давало быстрый Старт как бы выглядела архитектурная схема Если вы все-таки решили такой сервис сделать всё то же самое но есть еще какой-то кубик неважно микросервис в котором есть свое хранилище с этими самыми поисковыми данными Почему такой сервис все-таки может понадобиться Потому что если у вас его нет может возникнуть ситуация при которой поиск станет тем самым сервисом обогатителем мы с ней столкнулись в какой-то момент мы поняли что люди к нам ходят за уже найденными товарами потому что мы можем быстро их обогатить ситуация во всех смыслах неприятная потому что поиск это поиск он должен искать он не должен обогащать обогащение в интернет-магазине нужно на самом деле очень большом количестве мест Там на витрине на карточке товаров каких-то подборках там где вам не надо искать товары где Вы точно знаете какие они у вас У вас есть наборы идентификаторов вам нужно показать по ним данные поэтому создание такого сервиса на самом деле кажется во-первых идеи хорошие во-вторых Если все-таки вы его не создали одно из первых оптимизаций ций для того чтобы поиск не стали использовать не по назначению Хорошо Давайте тогда начнем с ластиком все-таки работать с чего мы начнем начнем мы с создания схемы данных эластик может работать без схемы все Наверное это слышали Это ложь даже если вы думаете что эластик работает без схемы он работает со схемой просто эту схему создали не вы А эластик И создал он ее на основании своих предположений о том как ваши данные выглядят Он про них не знает ничего он не знает как вы собираетесь с ними работать он не знает изначально их формат он просто получает первую запись пустой индекс который уже есть какие-то поля какой-то формат и создает под нее индекс если вторая запись будет отличаться от первой неудачи она в уже сформировавшийся индекс не влезет поэтому схему данных мы создаем руками Мы про свои данные знаем все про то что мы хотим с ними делать знаем все соответственно за схему отвечать нам они эластику возникает вопрос что с обратной совместимостью традиционных хранилищах Мы обычно носимся С обратной совместимостью запрещаем переименовывать колонки удалять вообще харам вот что здесь власти в системе поиска мастер данных быть не должно не знаю кто-нибудь хранит Я думаю никто мастер данных там нет поэтому я предложил на обратную совместимость просто забить мы своей компании раз пять переделывали индекс целиком просто полностью с нуля Потому что понимали что текущая его версия Ну она не удовлетворяет потребностям бизнеса они либо менялись Либо мы их плохо предугадывали как это стандартно бывает вот в этот момент вы просто переливаете данные целиком и миграция миграция ваших данных это уничтожение одного индекса создание другого точнее в обратной последовательности чтобы мы с вами не получили Down Time чтобы это все работало каждая версия приложения знает точно версию индексов который будет работать и она зашита прям его название То есть у нас не индекс product а индекс продукта и там Хеш А вот этот хэш это как раз версия одновременно может жить несколько разных продуктов разных версий и разные приложения каждый знает в какой индекс Ему идти поэтому всё это происходит без downtime Ну а чтобы работала отладка используем Алисы это тема тоже постоянно звучащая на любых докладах по эластику чтобы все это быстро работало нужно чтобы запись происходила быстро то есть мы по каждому типу берем и переналиваем индекс целиком Это довольно долгая история если это будет длиться час даже там Полчаса это плохо потому что изменения будут происходить долго тут есть стандартные советы их дают на любом докладе поэтому я очень быстро их проговорю во-первых не пишем ничего лишнего то есть если вы не следуете этому совету вам вообще ничего не поможет в любом случае у вас есть диск сеть и они вас будут ограничивать как бы Вы круто не затюнили эластик используем балка апдейт если можно то есть если можно обработать документы пачками делайте пожалуйста Так ну и на время каких-то больших интеграций мы увеличиваем refration интервал зачем чтобы тоже ускорить запись Давайте строить схему как это можно сделать Мы решили что нас дата storage данных много создаем просто вот такой большой джессон 50 Кб в котором все данные товаре его атрибуты картинки Ну естественно не файлы ссылки на них категории и так далее что получилось получился большой документ с большими документами ластик работает плохо на нашей стандартной нормальной нагрузке без всяких Load тестов получилось 200 миллисекунд по 90 процентов хотел вдвое меньше Что с этим можно сделать отказаться от данных мы не можем у нас дата сторож нам их хранить все равно придется мы нормализуем схему эластика Да не знаю насколько это применимо документ ориентированным хранилищем у нас есть в документе товара вложенные документы так называемые словарные сущности это категории это вот как раз свойство это бренды их на самом деле много около десятка и вот они дублируются если просто в лоб залить в каждый товар у вас будет огромное количество дублирующиеся информации в вашем индексе который вам на самом деле не нужна оставляем от словарных сущностей в индексе только идентификаторы основном выносим их в отдельные индексы индексы засовываем в память и обогащаемся данными оттуда уже на последнем этапе перед тем как отдать ответ на витрину получилось очень здорово размер индекс уменьшился вдвое мы смогли Независимо обновлять эти сущности раньше не могли если изменилась какая-то категория надо ждать полный переналивки и в целом ускорились на 30 процентов и Да я не знаю какая у нас нормальная форма власти скорее всего никакой потому что не все объекты вынесли вынесли только часть вот здесь можно посмотреть на визуализацию до и после stongs Да и еще советы по улучшению чтения и записи у меня была идея принести сюда какие-то типсом Трикс скороговоркой зачитать Но кажется что это не запомнится во-первых во-вторых их очень много и они все описаны на самом деле в документации которые очень сильно советую прочесть вы можете мне сказать кому он Степан то тут на сцене стоишь и говоришь там читайте документацию все это знают надо читать документацию Я бы этот слайд вообще бы не принес если бы не одно но как уже говорил десяток проектов с ластиком видел разные были команды разные были Лиды и вот с каждым буквально в каждом из них какие-то рекомендации оттуда были нарушены и случаев когда это был осознанный трейдов я помню два все остальное это просто непрочненное документация не надо изобретать велосипед ребята разработчики сделали набор крутых чертежей можно просто по чертежам его собрать и вот эту мысль Я хочу внедрить тех кто сегодня пришел потому что это действительно самый простой способ заставить ластик работать хорошо сделать так как советуют сделать его разработчики так двигаемся дальше Вот в этом месте у нас есть рабочий сервис на него пошли первые запросы сервис начал зарабатывать деньги для компании он в проде отлично Победа как мы обновляем данные вот та же самая схема по красной стрелке раз 4 часа прокатывается весь каталог все товары их там порядка 100 тысяч был плавает число плюс так как 10 складов там документу на каждый склад вот весь этот набор данных прокатывается по красной стрелке залезает власти ксюрч число 4 условно его можно поставить два можно поставить час можно даже 30 минут всегда будет что всегда будет какое-то окно когда данные могут проткнуть и они будут потухать обязательно если это окно есть чему это может привести Ну вот ситуация запустили акцию молоко по 49 рублей по 50 Вот таких цен давно нет я думаю многие из вас ходят в магазин знают Сколько стоит молоко и понимают что надо брать и вот наш клиент тоже это понимает и вот прям не думая жмет в корзину максимальное количество товара кладет на рефлексах спинного мозга что он может увидеть может быть все хорошо но может увидеть что-то такое плохо закончилось его раскупили либо оно не закончилось но закончилась акция есть еще третий вариант я вам его не нарисовал это когда он ничего не заметил Все купил и потом в чеке увидел что у него молоко было посадки это вообще самый плохой вариант потому что в этот момент мы клиенты потеряли он понял что мы его обманули мы мошенники покупать у нас никогда ничего нельзя я всем друзьям расскажу что вот впрок - это Фу как этого избежать надо научиться обновлять данные по событиям что-то изменилось мастер системе что-то изменилось поисковым индексе желательно сразу хорошо что вообще обновлять по событиям Можно Все можно берете тьюринг полный язык и на нем можно сделать все что угодно но нужно ли я считаю что нет Вот я для вас нарисовал график он не претендует на научность здесь на нем нет нуля нет осей это некая визуализация правило Парето вам будет очень легко и очень полезно обновить наиболее чувствительные данные но по мере того как Вы будете двигаться дальше в изменении ваших данных по событиям вы будете понимать что это сделать всё сложнее а пользы все меньше Вы точно абсолютно захотите менять цены и наличие сразу как только это поменялось мастер-система Возможно вы захотите менять название и Наверняка вы не захотите менять Real Time рейтинг товара потому что он меняется редко и вообще от него мало что зависит Вот потому предлагаю сконцентрироваться на наиболее чувствительных горячих данных а остальные по мере необходимости уже добить как мы это делаем Что поняли Давайте решим как Ну все очень просто нужен продюсер нужна машина данных берем шину данных продюсер располагаем там где данные меняются в нашем случае Монолит консьюмер в индексе как только что меняется сообщение попадает в шину данных обрабатывается индексером и сразу же переиндексируется измененные данные А что мы будем шину данных слать есть два основных варианта можно послать данные целиком вот что поменялось то есть шлем там всю сущность или какое-то Диф можно послать сигнал типа дружище У тебя обновился товар с таким-то айдишником сходи и Скачай новую версию я не знаю что там поменялось там что-то поменялось оба таких подхода имеют право на жизнь но Давайте все-таки решим какой мы хотим мы не можем два одновременно запустить почему надо слать Сигнал во-первых это проще реализовать на клиенте никакой див рассчитывать не надо у тебя есть ID измененной сущности кидаешься им шину дальше индексатор сам все разрулит не важен порядок событий То есть если 10 раз у вас одна и та же сущность изменилась вам нужно по-хорошему 10 раз в том же порядке изменения обработать в случае с сигналом это неважно Почему каждый раз когда вы обрабатываете сигнал вы автоматически скачиваете самую новую версию документа и даже если он между получением сигнала и получения вами данных успело ещё 10 раз поменяться вы всё равно скачали самую последнюю Ну и можно объединять обработку таких событий можно вообще все 10 не обрабатывать обрабатывать только одно ровно по той причине что вы автоматически получите самую новую версию Из минусов Я думаю всем понятно дополнительные сетевой вызов дополнительная точка отказа если у Вас например какая-то жирная интеграция можно вообще доснуть вашу мастер систему вот этими запросами особенно если она шлёт много событий хорошо почему надо слать контент а не сигнал Все очень просто все данные Есть сообщения вы просто их берете вставляете в индекс и не паритесь никаких сетевых вызовов никакого доса никаких дополнительных точек отказа Из минусов соответственно то что было в предыдущем слайде в плюсах за порядком сообщений надо следить есть способы как это победить можно использовать версию можно использовать таймс темпы но в целом это геморрой который с которым вам придется поработать Это сложнее В реализации То есть то что шлет сообщения должно уметь обработать этот div А у нас помните Монолит у нас там 7 разных местах может меняться данные могут меняться они даже какими-то триггерами сложными и вот не везде и не всегда будет удобно это считать Ну и не получится у вас объединять несколько сообщений по одной сущности потому что вы не знаете заранее какой у них контент он может очень сильно отличаться вам придется все обработать вот визуализация объединение событий У вас есть какой-то поток постоянные события из Мастер системы вы их не обрабатываете по одному фрезуете там Например размер страницы 10 штук или 5 секунд буферезуете оставляете только уникальные здесь видно что некоторые повторяются и обрабатываете соответственно пачку уникальных сигналов итого итого Я предлагаю слать сигнал собственно мы шлем Сигнал это история гораздо легче в реализации там гораздо меньше подводных камней вот конкретно в нашем случае такой вариант оказался гораздо лучше нежели чем слать все данные целиком и еще один момент связанный с переиндексацией частичная переиндексация у нас индекс по прежнему состоит из нескольких сущностей которые меняются Независимо это данные о товаре это цены это наличие Ну еще ряд сущностей все вынести мы их не можем из индекса потому что все Почему вы хотите искать должно лежать в поисковом индексе он для этого и был сделан и всегда будет необходимость обновить не весь документ целиком а какой-то его кусочек вот ластик так не умеет власти не умеет частичную переиндексацию вам придется переиндексировать весь документ сразу что с этим делать принципе можно ничего не делать если это какой-то значительной нагрузки не создает Если вы на своих мониторингах видите что никаких проблем нет то решать вам ничего не надо Ну у нас проблема возникла события много и необходимость часто переиндексировать она вот такие красивые волны на графиках рисовала в виде нагрузки эластика что мы со всем этим сделали Здесь тоже есть решение частичные переиндексацию можно сделать с помощью скрипта скриптов есть в эластики возможность не просто писать туда запросы на апдейт там или нет а прям скрипты какие-то в нем выполнять примерно так это выглядит как на слайде вы пишете скрипт на языке Появилась Это что-то типа Java Горько Ирония зашита в этом названии потому что Боль это как раз достаточно с подобного рода решением вот новый с помощью скрипта можете буквально все сделать какие здесь нюансы Ну во-первых если вы не джористы то Будьте готовы к тому что у вас новый язык в стеке это ну суть Java во-вторых отлаживать и тестировать такие скрипты очень сложно Вы имеете дело просто со строкой исполняется она прямо в эластике и тестировать и отлаживать вы это можете только в ластики нашем случае геморрой оправдался тем что мы смогли с помощью этой технологии сделать частичную индексацию наших данных без необходимости весь гигантский джисон А помните что у нас большой переиндексировать целиком плавно мы подходим к концу доклада и в конце у меня такой провокационный вопрос а вот у кого вообще есть Монолит 2023 году Поднимите руки Ну есть такие где-то треть навскидку А кто его вот прямо сейчас распиливает вот не знаю сейчас в ноутбуке сидит и пилит Монолит Так а кто его распилил нет Монолита О вот я третий раз подниму руку Пусть это вас не смущает потому что на самом деле картинка выглядит вот так есть какие-то остатки Монолита недобитые и есть куча сервисов которые из него выделены и работа с мастер данными она уже там в них вот и это гораздо сложнее чем все предыдущие картинки Почему потому что налить данные из одного источника больше нельзя нет этого источника они в разных сервисах лежат эти данные в разных басках и мы должны когда мы наливаем индекс клеить их из нескольких источников а там очень много неприятных моментов с тем что во-первых может целостность данных нарушиться Ну вот например у вас есть пришли вам данные по ценам Пришли данные по наличию А по товару данных нет Или наоборот и вот что с этим всем делать миграции индекса еще больше боль потому что вам надо прям с нуля на лица во все четыре сервиса сходить все их целиком скачать поклеить эти данные и заложить в индекс это сложно это сложно геморройно это больно более того некоторые сервисы вообще не поддерживают подобного рода операций Я прихожу к ребятам из сервиса остатков говорю Вот так и так нам нужно делать Вот так и на что получаю ответ мы вообще это не для того сервис сделали чтобы раз в 4 часа нас доселе и скачивали 300 метров данных давайте вы не будете так делать никогда и что с этим делать как в предыдущем примере не делать ничего не получится Это просто не будет работать решение есть если у вас нет Монолита Вы должны им стать Ну или симулировать его хотя бы для того чтобы все это работало для того чтобы все это не упало вот такое решение предлагаю сервис фейк что это такое это какая-то база по взгляд в которой которая агрегирует данные из микросервисов работает с ними по их протоколам с кем-то по старинке скачивая все сразу по расписанию с кем-то только по событиям она в себе это агрегирует она следит за целостностью данных а индекс работает своих монолитом как будто ничего не поменялось по той же опихе ходит У него все хорошо У него просто поменялся URL на который надо ходить таким образом фейхом аналитинг капсулируется сложность по работе со всем вот этим вот за парком многоцветным который у нас слева на слайде представлен единственное еще момент который надо не забыть когда шины данных попадает какое-то событие мы его обрабатываем сразу прокидываем в поисковый индекс нам надо не забыть ещё фейк-монолит его засунуть иначе При следующей переиндексации этих данных там не будет вот собственно всё это конец и Да я очень много про что не рассказал А вот примерный список того о чем я не рассказал Это тоже не все слайд Просто у меня закончился поиск это сложная вещь поиск Это важная вещь собственно вот на эти темы Мы можем с вами поговорить здесь или например в кулуарах тоже есть Про что рассказать здесь прекрасные байки а вот последняя особенно поэтому жду ваших вопросов Спасибо за внимание и все Спасибо огромное Итак у нас сейчас секция вопросов и ответов А пока мы это делаем Вы можете пройти по qr-коду вот левый это qr-код с голосованием и оценить доклад Вот и так если у нас вопросы в зале я вижу руки пожалуйста прошу Степан Здравствуйте во-первых спасибо за доклад а во-вторых интересует вопрос вы говорили по поводу того что решили не растягивать эластик в разные дата-центры но в то же самое время говорили о том что используем в одном центре Это позволяет использовать его неограниченные репликации почему не ограниченной репликации в одном дата-центре сложнее чем продублировать их двух разных в разных дата центрах Вы должны быть в любом случае просто потому что один дата-центр может упасть тут несколько центров нужны не для масштабирования а для надежности для доступности вашего сервиса Да именно поэтому в этом просто говорит что вы решили не растягивать его а мы решили не растягивать на каждом дата-центре своя свой Независимый кластер который Независимо обновляется то есть они они друг с другом не реплицируются они абсолютно независимы друг от друга вообще ничего не знают а использование вот этого фейк Монолита который был не позволило бы как-то согласовать два кластера смотрите он очень поздно появился То есть это прямо сейчас можно сказать сделано начало доклада это там 21 год вот не знаю может быть Надо подумать Пока таких планов нет спасибо огромное еще вопросы в зале пожалуйста здесь вопросики есть а я пока зачитаю вопросы с чатом Даниил Почему решили обновлять критичные данные цена наличие в индексе они брать актуальность какого-то горячего хранилища мы рассматривали вообще такой вариант вот отличный вопрос да Такой вариант есть но у вас должно быть это хранилище То есть если мы говорим про цены наличие должен быть сервис который может отдать там за 10 миллисекунд цены на наличие если он есть если он готов к подобного рода работе то Здорово Какой еще момент по ценам и наличию мы фильтруем если мы почему-то фильтруем Ну или сортируем и сортируем тоже Мы хотим чтобы фильтровалась сортировалась правильно соответственно все горячие данные должны быть в поисковом индексе то есть мы поставили цену до 100 рублей у нас молоко туда попало потом Обновили его цены из горящего источника оно стоит 150 вообще некрасиво вообще не Здорово У клиента возникает вопрос А почему молоко по 150 попало фильтр до 100 Поэтому в поисковом индексе горячие данные быть должны и э-э Ну наверное нам важнее доставить горящий индексы до этого сервиса чем запустить какой-то сервис цен и обновляться из него супер Спасибо пожалуйста вопрос Спасибо большое доклад У меня три маленьких вопроса Первый кажется что приложение перекрёсток поиск гораздо хуже чем в прокачи Почему коллегами может потому что я месяц реально заметил там очень большая разница и почему так мне надо посоветоваться с официальными лицами X5 чтобы ответить на этот вопрос не могу так второй вопрос впроке уже если запрос какой-то более детальный чем просто хлеб или молоко часто возникает такое что написано по вашему запросу товар не найдено но возможно что-то из этого подойдет и обычно там есть то что подходит вопрос Это Кнопка не пугает пользователь не пробовали об это сделать потому что ну кажется что она реально отпугивает Ну это выходит за тем доклада насчёт аб-тестов не скажу Ну опять-таки нет наверное я вот в кулуарах только смогу ответить на этот вопрос Итак мы продолжаем У нас есть ещё вопросы большая просьба держите себя в руках один человек один вопрос я вас верю вижу вот здесь вот руку давно достаточно а пока вы несёте микрофон а вопрос из зала Роман Селиверстов на какой абд Пим и распределён ли он пи на разные дата-центры или наливка в разные дата-центра идёт из одного DC с источником Ну смотрите пропим я вам ничего не скажу ровно потому что он опять таки выходит за рамки поиска поэтому нечего ответить Окей Сейчас передадим соус следующему задающему А я Напоминаю что придется выбрать лучший вопрос да спасибо Прошу Спасибо за доклад вы рассказывали про выбор между тем чтобы обновлять по сигналу и тем чтобы слать полный стейт и обновлять его полностью знакомая проблема а вот вы остановились на сигнале и были интересные особенности с тем то что по сигналу нужно правильно скачать данные не создать лишние нагрузки скачать актуальные данные Ну вот как раз да это может привести к созданию лишней нагрузки здесь помогает буферизация Ну то есть не ходить по каждому сигналу а ходить за пачкой то есть тот же балк только сетевой в нашем случае этого хватило в нашем случае вот не произошло момента при котором мы действительно создали огромное количество нагрузки Наверное это все нормально Сейчас сразу дополнительно Я предлагаю без дополнительных вопросов мы можем продолжить кулуарах у нас буквально время на два коротких вопроса максимум три Ну очень коротких хорошо и у нас очень много вопросов в чате Но никуда не убежит Я за этим проконтролирую в кулуарах Скажите как происходит захват обновления данных из бэк-офиса Какие технологии Да хороший вопрос хороший что я об этом не сказал по протоколу http мы ходим на определенную ручку скачиваем товары все Почему не делаете проверку цен и количество товаров в момент заказа делаем вот то что было на слайде как раз в корзине там актуальные цены актуальное наличие делайте что-то для L2 поиска еще раз делаете что-то для L2 поиска Ух Знать бы что такое два поиск вводить Итак Почему блиц вообще пошел классный Почему синхронизация данных между кластерами не важна Цена может мигать Почему Потому что повторюсь если все сделано правильно Если механизм транзита данных от Master системы до поискового индекса надежен то мигать она не будет Вот если он не надежен то надо опять-таки решать Это вопрос не репликации какой-то сложный а настраиванием надежного механизма Вот мое мнение супер Итак если у нас еще руки в зале У нас вот вижу руку у нас на один вопрос есть время но это к сожалению последний Helper Можно пожалуйста микрофончик Спасибо за доклад А подскажите как вы делаете Join то есть Я как понял при нормализации вы вынесли типа часть данных в другие индексы и Вам теперь нужен кросс индекс джойстик такого не умеет он кстати научился по-моему с 85 но мы этого не делаем мы Загрузили все словари в оперативку и просто пойдешь Нику и скажешь таблицу обогащаем результаты поисковой выдачи То есть получается что вы из словаря вычитываете там айтишники потом под их во второй поисковый запрос все Почему мы ищем оно лежит в поисковом индексе А все что должно на витрине быть мы этим обогащаемся из оперативки Итак супер Спасибо огромное на этом Давайте немножко завершим напоминаю Степан никуда не убегает уходит в кулуары А сейчас вот там на выходе Да вот на выходе это называется кулуара вот новое слово холодное а теперь самое главное тебе надо выбрать чей вопрос был самым интересным Ну вот мы до конца не договорили но мне кажется вопрос про обновление по сигналу он интереснее всего это был вопрос Это был вопрос Вот так отлично Итак дорогие хелперы пожалуйста подарок молодому человеку супер Спасибо огромное тоже хотела бы подарить небольшой подарок друзья пожалуйста Спасибо большое"
}