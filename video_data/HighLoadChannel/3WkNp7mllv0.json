{
  "video_id": "3WkNp7mllv0",
  "channel": "HighLoadChannel",
  "title": "Time series данные в реляционной СУБД / Иван Муратов (Первая Мониторинговая Компания)",
  "views": 8047,
  "duration": 3378,
  "published": "2019-12-05T08:48:02-08:00",
  "text": "меня зовут иван муратов я из краснодара и работы в пир мониторинговые компании наша компания занимается с путником мониторингом транспорта также я основатель букет митапов в нашем городе и член оргкомитета главной конференция краснодара краснодар dave days 24 туда с 5 августа у нас будет конференция приглашаю вас на юга кто хочет заодно съездить на море пожалуйста милости просим также спасибо конференции за то что я могу здесь выступить потому что я сам закончу забайкальский государства университет хотя сейчас живу в краснодаре увидел здесь много друзей и еще раз спасибо что networking и возможность проводить такие мероприятия позволяет людям приезжать в родные места вас замечательный город мой доклад оказался первым сегодня на 10 да никак не повлияет на его качество и заранее извиняюсь если возможно кашель редкий будет мешать воспринимать контент потому что я немного простудился окей мы готовы начать перейдем как рассказывать о расширениях который заявлен в теме доклада я хочу немножко индра во временные ряды хотя наверно это необязательно что вчерашний день практически многие доклады были про эту тему но временные ряды это собранные в разные моменты времени данные характеристиках исследуемого процесса временных рядов обязательно есть два компонента это временная метка когда они были зафиксированы и характеристики которые средством ее зафиксировали у временных рядов есть три основные особенности первая из которых как я уже сказал это наличие времени фиксации второе мы практически всегда стиме работы web and only режиме то есть мы их пишем пишем обычно в порядке времени то есть как монотонно возрастающая timestamp и мы практически никогда их не изменяю ну зачем их редактировать и чаще всего он просто удаляем устаревшие данные месяц назад год назад который нас больше не волнует и третья особенность мы с ними не работаем в отдельный записям мы работаем обычно с ними как с интервалами окнами периодами то есть агрегирует по каким-то интервалом в качестве примера можно использовать следующие например моя предметная область это мониторинг транспорта мы фиксируем в какое-то время местоположение широта-долгота скорость направления и все такое второй пример это метрики и инфраструктурные то есть нагрузка на процент количество свободной памяти количество свободного места на диске и так далее третий пример от различное оборудование температура морозильной камере напряжение электросети и так далее ну и телеметрии также относятся например местоположение курсора мыши клики и то есть то что мы собираем на клиентской стороне на фронте нди а потом наши пользователи жалуются почему сайт тормозит tm series имеет огромную популярность на следующем слайде мы то увидим без этих этой модели данных невозможно представить ни интернет вещей не умные дома не мониторинг широком смысле этого слова но само собой это предметную область не ограничена то есть любая статистика аналитика финансы и сейсмология метеорология все все все это протерм через данный если у вас в заменой модели есть какие то данные и обязательно во временной маркер то скорее всего это tm series и стоит задуматься о том чтобы перейти на именно эта модель хранение далее это тренда я думаю все из вас знакомы с этими графиками их очень часто показывают когда хотят доказать свою правоту и to say to die by jens там собирается различная статистика по разным подходом хранения данных и по непосредственно решения для разных моделей здесь конкретно тренды основные по модели хранения то есть мы видим что в топе там сели с данным причем отрыв очень большой на втором месте графа вы и базы и дальше по классике вылью реляционные так далее остальной графике я скрыл чтобы было не так ужасно смотреть почему это так ну само собой bigdata социальные сети и вообще интеграции а идти в жизнь нашу жизнь и деятельность она все больше и больше растет то есть там прогреть прогрессивное увеличение и поэтому данных приходится хранить все больше и больше если вы были на докладах индекс они там говорят о каких-то миллиардах миллионах то есть данных неограниченное количество и врачом они еще говорят что у них не удаляют второй график непосредственно решения именно в том сириус подхода то есть все кто работали stancy с данными наверняка слышали или использовали influx baby то есть это непосредственно лидер у него стабильная популярность это номер один решение дальше графин prometheus ну я думаю вы не слышали но здесь я хочу отметить непосредственно демский ltb несмотря на то что это всего лишь расширение к реляционной базе данных по сгрыз она очень хорошо борется за свое место под солнцем и у нее практически десятикратный рост это логарифмическая шкала популярности это очень отрадно что расширение она может конкурировать с решениями которые из коробки были написаны под time через данные были заточены под это хранение в эту модель и это не может не радовать давайте немного поговорим о моей предметной области я работаю спутникового мониторинга как я уже сказал мы собираем с навигационное оборудование стороны транспортных средствах телеметрию каждое транспортное средство в среднем при движении отправляет пять шесть точек в минуту сейчас у нас порядка 10 тысяч транспортных средств в основном это южный федеральный округ мы всё это собираем агрегирует и выдаем статистику аналитику нашим клиентам храним данные мы в среднем за два года какой у нас целый суммарно у нас порядка шести терабайт актуальных данных некоторое время назад мы начали модернизацию наших систем переходить на микро сервисные подходы где-то половину клиентов мы уже перенесли то есть это где-то пять тысяч объектов новой системе которым назвали выливать кто знает кстати откуда выражение что пользователи это главный анти паттерн высоконагруженных систем никто не знает никто на cpt не ходил и конкурсах у них не участвовал ok но это действительно так пользователи антипатр потому что у пользователь очень сильно сопротивляется к переходу на новую систему поэтому вот этот перенос он затягивается именно из-за них и этот логотип был специально нарисован к моему докладу на пиджаком в москве это грубо говоря логотип нашего стыка отгрыз как основная sbd пост без это расширение для геопространственных расчетов и time steel baby для хранения там серез данных в реляционной базе итак у вас наверное возник уже вопрос а почему не crack house но вернее почему нет м серия с решение почему мы пишем в реляционную базу данных если есть очень много решений которые для этого были заточены ну наверное потому что мы можем и не да если серьезно то у вас есть накопленная экспертиза у нас есть опыт работы с базой спас мы верим мы умеем говорить готовить и переход на какое-то решение которое нам было ранее неизвестно но она имеет некоторые риски потому что документация не всегда достаточно а наличие такого большого количества tm series решение намекает что либо у них есть какие-то особенности потому что каждый следующий хочет делать все с нуля и видимо ему что-то не понравилось предыдущем решения и вот чтобы понять где какие минусы в каком то ли через решение есть нужно их все перепробовать но это сложная задача требует очень много человеко-часов и очень нам нравится что puzzles с time steel тебе расширением позволяет нам использовать и другие расширения то есть пост гис pipeline дефициту сгибе какие-то frente это wrapper и то есть нам не нужен этель уровень то есть нам не нужно вытаскивать данные как-то их трансформировать загружать другое хранилище проводить с ними аналитику и гонять просить эти данные все это лежит физически на одном сервере или там на распределенную кластерной системе но данные не нужно перетаскивать то есть все вычисления которые нам необходимо выполняется как бы на одном уровне в качестве аргумента хочется привести недавний под tweet николай самохвалова так же ясно как поздравь мэн советую подписаться на его twitter если вам интересны новости в мире по сгрыз он привел ссылку на интересную работу который недавно выложили там 6 авторов писали про использование sql в потоковых вычислениях данных два из вернее пять из этих авторов работают в apache проектах такие как кальцит и так далее которые непосредственно и занимается потоковой обработкой и один из авторов работает в конфликт с разработка кейс qu'elle ну я про это чуть позже скажу но нас интересует не сама статья а обсуждение на hacker news ее туда пришел человек и пишет что все идеи которые описаны в этой статье уже давно реализованы мной на полюсе одиннадцатом и некотором наборе расширение то есть ему не нужно какие то писать умные статике то есть предстательную какую-то систему хранения он все это просто через гремучую смесь расширение реализовала себя все прекрасно работает но он говорит что у него есть возраст 11 cytus деби для горизонтального масштабирования шарди рования несколько фрейда тавр оперов pipeline xzibit для потоковых вычислений и для материализованные представлений и time steel baby для хранения time series данных большого объема и он ждет под газ-12 чтобы еще больше поднять производительность у него в базе порядка семи терабайт и он не жалуется и прекрасно живет безусловно как я уже сказал tm series решение очень много это какой-то топ который первым выводится там в гугле если пытаешься искать какие-то рейтинге топ и сравнения везде там мелькает индекс baby prometheus и так далее но как я уже сказал это немного пугает то есть не хочется затащить на продакшен какую-то систему в которой ты сюда не уверен мы не яндексом моей локальной краснодарская компания мы не можем себе позволить там адаптацию в течение полугода новой какой-то системы и так далее и последняя ссылочка out flux это разработка таймс кейл деви они выложили 1 апреля и кто скажет что она делает есть идея что может делать out flux верно эта штука позволяет одной командой мигрировать из info соус для ст м скилл гибель так что если вам чем-то не нравится influx и вы хотите на пост газ в принципе для этого touring уже есть ну и нельзя не говорить о хайпе то есть немного шутим по hyip гривен девелопмент мы много шутил про то что мы ведёмся на какие то там модные статьи и когда большие компании и корпорации перед какой-то технологий особенно это видно во франшизе я наверное но нельзя говорить что у нас это не касается то здесь находила воде много говорим про клик house да мы много говорим про тарантул много говорим про возраст и только не говорите что это никак не влияет на ваш выбор или хотя бы в какую сторону вы смотрите я не горю что это главный фактор когда вы что-то выбирается но я уверен что пока вы вчера ходили на доклады слышали слово crack house вы уже захотели посмотреть что это такое и как были может быть куда то это затащить ну я не кажет это плохо почему нет ну теперь давайте перейдем к основной части я думаю те кто опаздывали они уже потянулись time steel тебе и pipeline baby перед тем как мы начнём я хочу узнать кто нибудь слышал хотя бы в этих расширениях соли ну так но вчера ты мстил освещали один раз видимого на этот доклад не ходили второй вопрос использовать или кто-то вроде но учитывая что рук было 56 и мне светит в глаза лампа что я ничего не вижу и 3 просто считают что эти расширения делать именно на это же такие никто хорошо давайте познакомимся что говорят сами разработчики о своих расширениях там скилл тибета bad time series база данных с открытым исходным кодом оптимизированы для быстрой вставки и сложных вычислений на time series pipeline тебе это высокопроизводительные расширение сделаны для непрерывных вычислений и узкий над интерес данных то есть из этих названий мы понимаем что в принципе общем у них это работа стоим series но есть важное отличие немного фактов таймс киев была основана 2015 pipeline 2013 первые рабочие релизы которые у них можно где-то найти были в состав году 15 то есть им понадобилось среднем где-то 2 года чтобы что-то рабочие реализовать и релиз production редди у них случился в октябре прошлого года причем с разницей в неделю потому что люди которые не копаются именно как они работают очень часто их сравнивают и говорят что в принципе они делают примерно одна и та же никогда не рассказывают обстреле мне часто спрашивают о как pipeline вы его пробовали а почему не pipeline ну это разные вещи немножко мы об этом позже поговорим ну и количество звездочек то есть это очень важно у тайский ldpi звездочек даже больше чего под газ на гитхабе поэтому интересный факт здесь представлены основные тезисы ну ташкент тебе заявляют что у него вставка миллионов записей в секунду и хранение десятков терабайт данных у него скорость на сингл not конфигурации из коробки на одном железе быстрее чем influx чем кассандра чем от gdb и ванильный puzzles он поддерживает потоковую репликацию средства резервного копирования стандартный для по сгрыз он никак это не ломает и является расширением это очень важно портленде by заявляет про непрерывное вычисления в реальном времени на потоки данных он хранит только результат потоках вычислений без необходимости хранения самих данных которые поступают для этих вычислений об этом мы позже поговорим это очень важно он позволяет делать join и на потоках вычислений для вычисления каких-то контекста скажем вы потоком загружаете какие-то данные у вас есть видишь них например пользователя и пользователю вас самих тою series данных нет вы можете за jogi табличку с пользователями извиняюсь и это прекрасно работает и является расширением на самом деле pipeline и сначала изначально был for com но когда поняли всю силу расширения и что расширение из коробки получает свету эту систему форки начали потихоньку умирать стали переходить на расширение если это возможно ну спас гаспра я думаю реализации виде расширения вряд ли получится это все-таки форк давайте поговорим о time scale я с ним работаю уже более двух лет я затащил его на продакшен сырой обошлось и он прекрасно работает за него я могу поручиться если будет вопросов по нему на про использование в бою подходите поговорим предлагаю сразу же начать с примеров так проще понять зачем он нужен ну и сразу какая-то прикладная задача у нас есть инфраструктура очевидно мы все все пихаем в докер контейнеры - оркестре ру и мы так убирает а сами это все понятно и нам нужно как-то посмотреть по нашим контейнером к лично свободной памяти то есть грубо говоря у нас есть там табличка например в ней есть лишний контейнера есть количество свободной памяти ну и другие метрики или просто для простоты их убрал отсюда и время когда этими таки были зафиксированы с помощью этого запроса мы вытаскиваем метрики за последние 10 минут для каждого контейнера окнами по 10 секунд принципе все то есть этой сквере это не low сиквел это не синтаксис и которые ломают голову в том же prometheus и когда allure ты настраиваешь второй пример больше из моей предметной области это этот запрос позволяет посчитать количество покинувших город транспортных средств в данном случае краснодар по дням с то ножом который вывезли то есть это актуально для грузовых перевозок то есть мы хотим сколь узнать по дням сколько из краснодара выехала том чего либо с грузовым транспортом здесь так же можно заметить st визин и это запросы из-под гиса то есть это расширение участвуют в формировании этого запроса и все это прекрасно работает никаких ограничений здесь нет и третий пример я не стал делать вывод потому что говорят там несколько дней назад bitcoin опять превысил планку в 10 тысяч долларов я не хочу пить и hyip я не хочу видеокарты покупать за космические цены поэтому сами посмотрите если вам интересно этот запрос позволяет вывести динамику между эфиром и биткоинам и американским долларом за последние две недели с окнами в один день то есть это уже такие финансовые вычисления простейший заброс кто знакомится с килем прекрасно понимает что он делает ну и вы скажете ok у нас есть какой-то сквер но что же такого крутого там томске ldpi почему не используя стандартный по сбросу этот график кто был вчера на забег сетей скилл тебе видел это сравнение производительности на вставку между ванильным десятым по сбросом обычной таблицы и гипер таблицы time steel baby здесь вставляется 1 миллиард записей с бочками по 10000 на машину на и же в.м. с 8 ядрами и 20 8 гигами оперативной памяти и при а точеным сетевым ssd диском postgres ну как бы падает но он валится и вообще не работает почему это происходит но очевидно что когда у вас приставки необходимо обновить также индексы и они не помещаются в кэш базы вам нужно постоянно лазить на диск то есть грубо говоря в принципе на 400 400 миллионов строк и так происходит в этой таблице просто нужно все время с опыт на диск и читать с него поэтому там скилл baby из-за того что мы используем секционирование или паркет проецирование тут пытается как-то навязывать как надо правильно говорить этого не происходит потому что чанки автоматически создаются новые и как бы чан индекс чанка она всегда влазит в оперативную память и когда это не происходит на создает новый чан то есть секцию ну и вы скажете о кей нам вчера рассказывали коллеги спуск газ professional pro улучшение в 11 12 по здрасте про декларативно секционирования ну это сравнение секционирование декларативного 10 по сброса и опять же таймс келди беги по таблице 10 только завезли само собой секционирование через наследование медленнее чем декларативно поэтому не имеет смысла тут с наследованием сравнивать мы видим что у time steel тебе практически нет никакой деградации то есть просто какие-то болтание по сути по прямой при увеличении количества секций то есть здесь их там более 5000 при декларативно секционирование десятом возрасте супер форма стабильно падает валится надо провести сравнение с 11 11 версии но я практически уверен что там будет примерно такая же картина хотя и получше просто секционирование в подписи она заточена наверное про больше про бизнес данных то есть если вы хотите секционирование нтов пользователи и какие то товары да она вам прекрасно подходит но для там через марк лоло да там с кем тебе для этого и был написан ok надеюсь вас уже заинтересовалась расширение но давайте много подробнее об этом поговорим все то есть проецирование секционирования через гипер таблицы также тебе вводит свой термин гипер таблица гипер таблица является таблица который вы вызвали метод create a purple что это метод делает он создает он берёт верни эту таблицу делает ее родительской то есть таким прообразом для секций и все запросы и все alter ты бы все изменения будут направляться непосредственно вот в эту таблицу которую вы по сути и храните у себя в основной схеме в ней не будет данных то есть после какой-то версия не отказались от этой идеи то есть то что делаете квартиру sexy они растан дарт на когда у вас нет новой секции all business какую-то дефолтную но по мне так это отвратительно и решение и они не пишут туда далее она остается всегда пустой она используется просто как копия при создании новых секций и точкой входа для запросов создаются чанки так называемые чанки это в терминах time скелет те же самые секции time steel интегрируется в исполнители планировщик запроса через специальные хуки в которой есть под греси он прекрасно понимает когда обращаются к таблице который является гипер таблицей и анализирует запрос и направляет только в тир чанки которые необходимы то есть он еще на уровне запроса понимает куда нужно идти и вчера обсуждали про блоки когда мы пытаемся дать новую секцию удалите и так далее там есть новый механизм а также detach а но у меня так это тоже не очень в тайский о тебе не то их проблем секция создаются автоматически дроп секции происходит на лету без каких-либо блокировок это честная spiegel то есть все эти join и и агрегации оконные функции с это ешки все это работает вы можете создавать индексы составные вы можете создавать в 20 индексов на своей таблице ему в принципе без разницы вы можете создавать индексы на конкретных чанг ах вы можете создавать индексы на родительскую таблицу саму он автоматически через специальный механизм создаст индексы на всех дочерних то есть про oracle спрашивали по поводу там глобально статистики и так далее но здесь этого тоже нет то есть каждый человек рассматривается как отдельная таблица просто внутренние механизмы таймс кейла прячет от нас этот уровень и все чанки кстати они хранятся не в основной схеме ваших данных хранится специальной схеме internal timescape это очень удобно потому что в самой схемы данных когда вы смотрите на таблицы на диаграмму скажем вы не видите этих чанков то есть когда у вас их несколько тысяч но вы не хотите вот этот ужас видеть то есть и скролить если вы там ей какой-то используете это все прячется в отдельную съемку также там спел тебе добавлять свой background worker то есть есть какие-то службы которые можно на фоне выполнять и эти службы позволяет проводить какие-то операции фоновый то есть подчистку старых танков бери организации чанка в зависимости от того что если они набухают то есть если вы например начально указали секционирование неделям он видит что данных слишком много яндекс не влазит в память вы можете сказать прямо в ран тайме и теперь по дню и ему не нужно будет переформировать предыдущие то есть вы можете каждый день по-разному делать секции и он прекрасно это понимают они не должны быть одинакового интервала они могут плавать это дня от ко дню махать как же каждый час отменяете ну и интеграции то есть так как это расширение так как оно не ломает ничего встроенного в по сгрыз все эти иконки api числят не буду то есть они все прекрасно работают там skills by как бы их проверяют дружат с ними хочу отдельно отметить про прометей у них есть отдельно адаптер который позволяет с прометея сливать данные в подлеске lgb зачем это надо есть секс истории вот коллеги из крока в краснодаре они его использовали для того чтобы данные из прометея который там хранят скажем неделю а потом удаляют сливать в на медленные диски в пазле стоим скиллом и хранить там за год то есть это очень привыкаешь и для этого есть адаптер то есть я не думаю что кто то из вас там годами и данные в мозгу прометея будет хранить 2 и the telegraph плагин это недавно совсем появился очень крутая штука она позволяет вообще удалить прометей и данные с инфраструктуры сразу лить в тайский л д б а через телеграф потом ходить и все это прекрасно работает и нативно интеграция с grafana и забег сам граф она умеет из коробки понимать что в возрасте стоит м скилл и сразу в графическом билдере запросов она уже знает что там есть какие-то функции такие как time bucket гистограммы и так далее и вы можете прямо из реляционной базы с такими time series функциями строить графики и не нужно не придумывать какие-то большие гигантские запросы с да и танками и персонажами и так далее или zabbix а вчера доклад был от коллеги там есть тоже интеграция с этим то есть если вы используете под газ качестве храня хранилища для ты zabbix а ну я считаю что прям маст-хэв хотя бы попробовать time steel поставить ну и небольшие новости у них есть разные лицензии у них если подсоса лицензия под apache 2 все лежит на гитхабе бесплатно пользуетесь есть комьюнити лицензия они просто хотят штуки клевые которые не реализовали чтобы их не забрали так вот так же открыты можете использовать но то есть коммерческих целях переиспользовать нельзя интер справиться enterprise лицензия коммерческая код на самом деле также открыт просто если вы хотите узнать эти full фичи вам нужно лицензионный ключ и просто прописать в подписи в паз газ конфи там мы с этих функциональностей только какие-то автоматизации процессов то есть например удаление старых чанков или делаю перри организация порядка данных в отдельных чанков но это все можно через cron сделать руками то есть пока они так и есть клауд решение недавно они очень сильно за дружили с же и у них и свое облачные решения если вы стартап у вас еще не кончились деньги инвесторов и вы хотите успеть выйти на рынок то в принципе и зайти клауд там нормальные цены но из новостей у них миллион загрузок за 18 месяцев у них 31 миллион долларов уже инвестиций и они дружат и жир и сейчас у них очень сильно идет работа по поводу а-j решение иное же будет отдельный сервис или уже есть с postgres конфигурация для time series данных ну и самый главный point что ты мстил тебе это про хранение данных у него не так много функций для там серез вычислений это именно клюва секционирование с автоматическим созданием чанков с минимальным количеством ограничений в отличие от встроенных нативных в по сгрыз ну и это прекрасно работает теперь pipeline тебе pipeline совсем с другой стороны не нужно смотреть это расширение мы не успели сильно попробовать в бою потому что есть одна очень важная тонкость они я скажу после доклада чтобы сохранить интригу и так сразу же начнем с примеров у нас есть необходимость отслеживать скажем статистику нашего сайта то есть у нас есть какие-то углы у нас есть количество посещений то есть количество уникальных точно при покупка покупкам мы это определяем и представление all at once это здесь 99 берсин тилль само собой например нам не нужно какой-то сервис платный юзать или мы не хотим окрутить велосипеды то есть все просто по-простому описать в реляционную базу посмотреть как это работает ну принципе это все что необходимо сделать с paypal and baby чтобы это работало павел он тебе вводит такой абстракцию как continue свою это на русском языке наверно будет звучать как непрерывное представление и он позволяет делать агрегации и в принципе выводить данные которые вы хотели видеть второй пример который должен раскрыть в принципе функциональность этого расширения он будет не только continues юма ведь такую абстракцию как стримы так как мой он заявляет что он предоставляет потоку в обработку данных в условиях реляционной базы данных без потоках данных это невозможно грубо говоря в этом примере нам необходимо провести бы тестирования то есть скажем мы придумали какую-то интересную идею и решили прогони прогнать оба тесты и до хотим собирать статистику то есть конверсию в той и другой группе но при этом мы не хотим собирать сами данные то есть мы не хотим хранить вот все эти клики конверсию статистику нам нужен просто результат то есть мы вам ушки хотим просто посмотреть сколько пришло и сколько в каждой группе перешли уже в конверсию заплатили скажем деньги вашему бизнесу вот стрим и как раз это и есть этот поток году поток данных для обычного клиента базы это будет обычная таблица в нее также можно in certain из нее нельзя selected ну потому что это стрим кто знаком с этой концепцией там не знаю с потоком вычисления были может быть функционально программе никто это java стримы юзает это вот вот очень похожая концепция под капотом pipeline тебе взять зеро и мкф то есть он вместе с ним компилится вам не нужно про это думать и вот эти данные они поступают вот эту внутреннюю очереди рынке и соответственно на выходе попадают провоцирует обновления непрерывного представления второй запрос как раз создает вот это представление на основе этого стрима с какими-то агрегация my и полями то есть здесь у нас получается общее количество посещений и сколько из них перешло в деньги вашего бизнеса и количество уникальных ну и в продолжение то есть здесь ничего особенного здесь мы просто генерируем продукты набор данных чтобы было понятно что это как обычная таблица в него также все он сердится и делаю обычно select а то есть первый селектор просто достает группу а бык лично уникальных посетителей 2 select выдает рейд именно этой конверсии то есть соотношение между группами потому что у них была разное количество и наверное имеет значение минут вот этот рейд то есть все ну а бы тестирование на 5 сквере вызовах в реляционной базе и немного про топологию то есть чтобы было это понятно честно сворованный слайд из другого доклада здесь у нас данные поступает из какого-то топиков кафки то есть скажем у нас есть кафка в нее поступает телеметрия этот топик отправляет эти данные дальше в подброс тут вот все остальное это и мы уже внутри подвеса соответственно в stream попадает данные из топика кафки мы каким-то образом их агрегировать то есть например joy ним с какой-то таблицей обычной из-за по сгрыз а то есть скажем приклеиваем там не знаю имя пользователя и это всего перенаправляется в стримы вот этот transform это еще одна сущность в топологии pipeline тебе грубо говоря это такое же представление но оно сделано для того чтобы модифицировать входящий поток и на выходе что то делать то есть например менять агрегации отфильтровать ненужные данные или скажем менять их разреженность то есть у нас приходит каждую секунду мы хотим по 10 секунд вот трансформы или по-русски наверно изучать к коммутатор и преобразователи это вот она из transform и это все попадает в материализованные представление которое окончанию там мы делаем какие-то уже запросы важны для бизнеса то есть клиент по сброса там скажем высчитывает средняя и что нибудь еще и есть еще возможно навешивать триггеры то есть скажем мы можем на кантине свою повешать триггеры когда сработает какой-то условие кинуть концерт или еще что-нибудь сделать то есть и все это работает прямо внутри погрыз а ну и как и ставим скиллом давайте просто пробежимся по основным возможностям pipeline деби решает проблему потоковых вычислений в реляционной базе данных звучит наверно как костыль но это работает и для кого-то это может быть нормальным решением то есть я когда делал а тезисы к докладу я говорил что не у всех огромные доныне у всех миллиарда строк у кого-то не такие большие нагрузки зачем усложнять инфраструктуру если есть такие решения флатландии вот вводит вот эти абстракции стримов continues you transform of агрегатов и триггеров он также интегрируется в планировщик исполнитель запросов под капотом еще использовать зеленку в качестве очереди для стримов и делает эти потопа вычисления ну грубо говоря как это работает предположим самый простой пример мы высчитываем среднее у нас есть количество данных которые мы пришли и их сумма то есть мы сумму делим на количество получаем среднее если у вас есть обычно матери зона и представление есть огромная таблицы скажем и вам ее нужно обновить вы обновляете представление вам нужно опять просто не все таблицы 5 этапа новой посчитать ничто вам не мешает это делать по другому так как делают это высокопроизводительные решение для статистики они берут просто новую запись которая пришла просто + 1 количеству плюсы изначально к сумме а потом когда мы к нему обращаемся вам просто вычисляет на лету то есть принципе портленде именно это и делает это честная сквер вы также можете join its агрегироваться оконной функции никаких ограничений есть тонкости именно ограничения в самом pipeline тебе то есть вы не можете делать join между двумя стали маме но на самом деле это и не имеет особого смысла и у вас есть агрегации оконной функции join и это я уже все сказал и очень важно там есть вероятность на структуру данных это выходит за рамки данного доклада но если вы в теме там есть блум фильтры и топки хайбер лак лак то есть прямо в и склеили то есть если вам это надо вы хотите затем поиграться но там есть и сам pipeline тебе использую для различных аккаунтов distinct of для пирсинг или используют некоторые из этих структур это очень усиленно повышает производительность с минимальными ошибками этих структур ну и это решение репликации системы резервного копирования там любите патроне если там во лжи любите то это все работает прекрасно то есть можете использовать ну и про интеграции так как это потоково вычисления очевидно нужна интеграция с подобными вещами ну очевидно это интеграция с кафкой и интеграция с генезисом kinesis это сервис на амазоне если кто-то с ним работал то вы можете данное гонять прямо туда из pipeline гибискуса ну так же по лицензиям новостям это всего пан source все буду по чем все на гитхабе у них есть сатиры и платной поддержки у них есть кластерная версия распределенное коммерческое за денежки и straight это их сервис аналитики построены на их же решение но последняя новость вот это-то но которые я вначале сказал они короче купленный конкурент это та компания в которой разрабатывать ей square в которой работают сейчас те кто и начинали писать кафку принципе ждём от них каких-то интеграцией я надеюсь когда она завезут плата был старриджа conference сделать крутой а между кафка ip-адресом что для нас это значит по и блонди без заморозили то есть на версии 100 они сейчас выпускают только баг фиксы какие-то критические какого-то дальнейшего развития функциональности они не планируют хотя конкурент до сих пор не анонсировали свои планы на это расширение и вы можете использовать расширение она лежит на гитхабе она никуда не денется но то функционале с который нам есть она скорее всего такая и останется если кто-то не подберет этот проект или конфликт не решит вас с самостоятельно развивать но и основной point pipeline дебита про потоковую обработку данных еще раз когда вы отправляете какой-то поток данных по сброс в так называемый стрим в терминах pipeline это называется виртуальные данные вы не сохраняете их вы делаете на них агрегации вычисления и просто отбрасываете грубо говоря можете взять сервер там 200 гигабайта создать диск и просто через три мы через вычисления прогнать терабайта данных вы получите в результате свои вычисления то есть результат того что вы хотели увидеть но сами данные они просто позволят это вычислить и будут отброшены то есть это вот про это и я специально подготовил для вас дымку на гитхабе она поможет уже как разработчикам понятия мир наш как это может выглядеть осторожно там java и я сделал специально докер-образ на джокер хобби вы можете запулить попробовать запустить то все работает там внутри сборка из последнего возраста time склеила и pipeline тебе то есть можно подключиться писк верим потыкать попробовать я думаю вам должно интересно быть и к практический пример потому что эта практическая конференция как это может выглядеть например например нашей системы грубо говоря у нас есть транспортные средства на не ставятся навигационного оборудования по простому это gps tracker gps глаз помогает нам определить их местоположение и через gprs сети через обычные мобильные мы эти данные отправляем нашу платформу далее это все попадает в как топик для того чтобы эти данные как-то смягчить и вот эту нагрузку и разницу когда есть пике по нагрузке и когда система простаивает например ночью потому что мы юфо у нас один часовой пояс практически и дальше это все попадает уже в по адресу то есть грубо говоря исков кито попадает в мутатор там мы делаем разрежение данных то есть если бизнесу достаточно по 10 секунд она приходит каждую секунду мы это все в транс форме можем сделать и уже преобразованные данные как нам надо пишем в long term сторож то есть в гипер тибул time steel биби и также сразу в другим потоком эти данные отправляем в continues view pipeline тебе и в нем делаем real-time аналитику то есть в ней уже находится текущее состояние транспортного средства то есть самое актуальное его местоположение напряжения бортовой сети в этом вес водителя не знаку ряд вам салоне не курит данные с камеры то есть все это were all to me попадает через стримы в continues пью и грубо говоря для того чтобы зайти в систему посмотреть актуальное состояние системы нам даже в гипер таблицы лезть не нужно все это есть его вьюшки ну и какой профит от всего этого ну и сквер я думаю что это профит учитывая весь этот hyip на у сиквела все опять начинает с quellen трофей со пилить тот же клик house слишком много при хаоса у нас есть неструктурированные данные почему они есть скажем разные навигационном оборудовании разных ценового сегмента кто-то может отправлять 10 метрических каких-то записи характеристик транспортного средства дорогущие могут отправлять несколько сотен и создавать несколько сотен пустых столбцов но не очень хорошая идея а джой не какую-то таблицу отдельно тоже не хочется и вот джейсон без столбцы если они в толстой они улетают достаточно компактные у нас в принципе оно так и есть очень сильно выручают то есть мозга нам не нужно у нас все и так хорошо time series данные то есть вот этот workload это вот эта модель данных она предполагает некоторые особенностях и системы хранения и учитывая нашу любовь по сбросу и наличие отомстил baby переезжать на тот же influx но нет никакого желания и непрерывное вычисления то есть вот именно этот поток данных и отбрасывание его и сохранения только самих результатов вычисления то есть грубо говоря эта статистика и аналитика это очень крутой point экосистема под газ а то есть все эти эти решения все эти системы сдержано копирование мониторинге все такое оно все будет работать zabbix и и граф она вообще понимает что вы там томске и вырезаете то есть это уже о многом говорит если решение смотрят в сторону этого расширения открытый исходный код по большей части можно посидеть потыкать можно законтрить бьетесь это же упа source и свободное использование то есть грубо говоря мы не используем коммерческих версий используем только бесплатные и нам хватает с головой и полезняшки мои контакты то есть я общительный человек можете подходить спрашивать без проблем если есть какие-то замечания с удовольствием вас вы уж лучше портал нашего сообщества так как мне нужно рекламировать краснодарская и те ну там есть наш 5k телеграме 5 корпус gres специалистов в телеграме если у вас есть какие то вопросы там всегда рады помочь там очень интересное общение происходит 2 это блоги самих разработчиков расширения интересно пишут в основном там скилл тебе очень клёво пишет статьи советую почитать вот эти графики которые да то есть люди очень сильно боятся что в графике специально ну придуманные чтобы там пропиарить технология все это у концертная можно взять эти bunch марки запустить на своей машине все это проверить и убедиться что это реально так таймс келди бетьюн это что-то типа бюджету кто сталкивался только специально для таймс кейла то есть если у вас база ставим скилла вы не знаете как его готовить как конфигурировать базу на старте вот эта штука позволит вам сконфигурировать для вашего железо и им максимально оптимальным с каким то ну общем war клаудом для томске его подрядчиков это tool за для проверки вашего состояния это разработка puzzles и я и николай самохвалова известно как прогресс мэн мне очень нравится это решение если у вас по сгрыз и вы как-то его мониторить и посмотрите вот это решение поставьте ему звездочку очень клёвая штука она собирает статистику практически по всему что есть подлости и виде pdf ки markdown выводит просто гигантский отчет который понятен любому там тебе и даже разработчику которых возрастом хоть немного знаком очень крутая штука ну и еще раз ссылочки на дымку на гитхабе и докер-образ попробуйте не постесняйтесь то есть докер всегда контейнер можно убить или он сам умрет спасибо за внимание готов ответить на ваши вопросы это все ну погнали представляете пожалуйста у меня пореза у меня вопрос возникает ли проблемы с обновлением схемы данных потому что там спел все-таки это как бы релиз у нас традиционный подход не все-таки там есть схемы то то есть вот данные вас получается бизнес-моделями сидят они детерминированы получается то есть вы не обновляйтесь тему танк или вы используете или выставить кладете просто джейсон до ручки у нас я поняла про спасибо у нас есть стандартный набор данных то есть или метрическая запись она не имеет смысла без времени без широты и долготы высоты и скорости направления скажем и там есть флаг валидности gps-координат то есть каждые устройств практически до умеет и еще может быть я как-то забыл но их незначительное количество и все остальное это опциональные данные разные трекеры разными навигационное оборудование может их отправить а может не отправить его можно сконфигурировать чтобы он слал их возможно некоторые оборудование вообще не умеет их слать поэтому да то есть то что у нас опционально она решит джейсоне джейсон столбце то есть у нас есть бинарный джейсон конгрессе который очень хорошо работает не индексируется когда да там работает яндекс и есть piriform ну как бы какая-нибудь и perfomance test как работать выборка из этих я понимаю что time steel это все про складывание до металла карданный оттуда выбраться сколько это стоит ну во-первых так как у нас есть интеграция с планировщиком то когда мы достаем из разных чанков ну наверное мне можно там на следущей закладку эти план запросов накидать но можно зайти explain сделать грубо говоря он сам понимает куда лезть не надо и в чанки в которых данных ну априори нет он туда я не полезу он полезет в эти чанки как в отдельной таблицы из агрегирует их между собой вы можите вешать индексы на идиш не кино время то есть ну как обычной таблицы только из несколько там единстве появляется новый узел это нужно все замерз но так как мы обычно достаем из там серия с данных по времени то они уже отсортированы и индекс у нас b3 он отсортирован по времени все что нам нужно это просто их склеить снизу это практически никакого верха до не дает весь верх от это и о если вдруг она не лежит в памяти но возьмем tatul то есть данные в определенном все-таки танковой цены ну как бы но и даже по сгрыз это не редис то есть но вот у нас сейчас одна неделя весит по моему порядка 50 гигабайт и у нас есть основная реплика для быстрых вычислений у нее вся весь этот шаг полностью лежит в оперативной памяти в каше базы поэтому мы по сути на диск общение обращаемся спасибо так следующий раз надо спасибо за вопросу предыдущие можно я не вас ли либо просто клада и вопрос мне несколько если можно интересовал момент про удаления чанков я уже вчера слышал что подобные хотелось бы понять только как удалить начинки без блокировок о том что тот момент это может их читать ее очередь этих часов может быть очень большое как-то приварили будет счастливый момент захотим как удалить до само собой если их читают их удалять нельзя но обычно когда чанки удаляют удаляют самые старые чанки и то есть тут наверное расчет на то что мы удаляем устаревшие данные и скорее всего их никто не читает тут проблема там было сравнение между дэвид фронда и дропом просто файлами в пиджи дата то есть когда мы удаляем чанг мы удаляем целиком таблицу разом то есть грубо говоря это намного более быстрая операция чем проходить по всем строчкам вычищать их а потом еще вакуум придет я вот это понимаем не вопрос именно про блокировки на самом больше задел потому что я например представляю как это ворога сделала что можем поставить лайк и ждать пока у нас дойдет очередь до и все последующие я не станут за нами есть мы удалим они получат ошибку например так вот здесь вот если без блокировок то это будет просто по середине чего-то чтение жахнем файлы но согласен нет ну данная блокировка на при удалении чанка она есть но она есть когда из него читают ну то есть там планировщик в сам интеграция в хук по сброса то есть при мы отправляем команду на дроп чарт то есть это делается не через сквер средства через time steel функцию и внутри этой функции наверняка есть просто статистика откуда сейчас читаю если ниоткуда просто группы если оттуда читает скорее всего да он заботится подождет то есть ну я думаю что по другому но никак и не сделать то есть вопрос от эта история про там скилл ip-адрес и вчера был так лобанова хотелось бы немножко больше подробностей может вы скажете по поводу гипер ты был вы предлагаете переходить использовать пробовать используется забег сам для этого нужно как-то мигрировать домами или можно прям взять ее грудь таблицу премер замки вчера в докладе это было грубо говоря когда мы там есть creed ха ха и бёль болот эта функция до в ней стрингов передается имя таблицы далее передается интервал стандарты как разбивать секции по умолчанию там раньше месяц было сейчас по умолчанию неделя но можно свою указать и там есть отдельный флаг опциональной мигрировать и грубо говоря он смотрит на эту таблицу в ней если есть данные он создает смотрит какие какое-то время создает секции для этого времени грубо говоря он сам все это сделает то есть вчера был пример там говорили по моему про терабайт данных из за полтора-два часа он все это разбил на секции сам то есть он это все сделает не нужно да мы не нужно выгружать и нужно вот так вот перегонять и fathers будет воспринимать эту ручку коучем табличку да да да там вся идея этого расширения в том чтобы спрятать чанки будет тут эта гипер таблица пустая очанки на самом деле вообще лежат в отдельной схеме и она начинается с нижнего подчеркивания то есть идея вообще не лестниц не смотрите туда time скиллы все за вас обыграл квартирами и хуками сделать его да спасибо а можно вопрос куда кафки просто интересно потому что я так понимаю что все таки pipeline дебит навешивает какие-то дополнительные возможности при работе с потоками просто вот мы например используем до кафку и погрыз мы просто через конек тупо через обычное соеденение insert данные я увидел такую фразу как selecta во фронте рюкзачка фронта пик это абстракция пускай это или это реально грации это абстракция так там есть интеграция с кафкой то есть прямая то есть данные из кафки попадают в stream pipeline тебе там основная основной point в том что например наша кафка она просто эти данные собирает и как это просто потихонечку передается в как шина в адрес как это выглядит на стыке пазы и кафки вот что интересно то есть это push-pull или что это там получается pipeline debian selected из кафки то есть грубо говоря он знает как не подключится результ какой-то консьюмер то есть но у нас меня большой экспертизы именно вот интеграции с кафки нет поэтому я думаю что стоит лучше документацию посмотреть и возможно мне стоит доклад сделать на эту тему потому что учитывая что конфликт купили ее то есть я вообще жду от них какой нибудь интересного решение потому что вот их киевский если они опуститься на уровень ниже по сбросу я думаю сплава был сторожем это будет просто вау я вот жду жду анонса от них очень зови за старое университетская истинно хоть в чем-то разобраться начали преподавать да у кого спасибо за такой сергей индекс интересно насчет поддержки более сложных типов там за поддерживается инстаграм и да я про это там это было указано я это просто не проговорил извиняюсь time steel тебе предоставляет time bucket это по сути да и транг здорового человека туда можно передавать любые интервалу то есть там интервал тип поддерживается то есть да и транков говорит вам один день одна минута в той баки можно сказать 1 час 1 минуту 15 секунд 16 миллисекунд то есть кастомный интервалы по нему агрегация происходит там есть гистограммы из коробки то есть прямо метод гистограммы там есть first пласт то есть когда мы делаем select по интервалу там есть специальный агрегат first он возьмет просто первое значение в этом интервале или последнее значение в этом интервале если вы представление нас не интересует потому что у средняя на вычисление дела и the first например возьмет просто это значение и это будет быстрее там есть еще интерполяция то есть грубо говоря вот time series данных есть проблема когда эти интервалы пропускаются так скажем у нас creed контейнер он упал и и даны от него не приходили два часа а моделируем по десять минут у нас будет много нейтралов пустых что с ними делать непонятно и вот интерполяция она позволяет просто но обычные линейной интерполяции эти значения как бы ну на концах как бы объединить и интервалы внутри себя будут понимать эти значения то есть просто интерполируя и ещё там есть механизм с интерполяция не устраивает последнее известное лосс то есть он берет последнее значение то есть просто прямую делает от нее а потом когда новое значение приходят просто ступенька будет то есть интерполяции да вот это вот вы основные по сути функции который также дает спасибо и еще вопросы про сейчас поддержку многомерных пространств да как как с этим работать вот кстати спасибо что подсказали это очень важная тема вот проблема с тем же декларативным секционирование вчера был пример это был пример про то что если у нас есть разные две таблицы которые спицы они рт по отдельности но у них совпадает интервалы да и мы план запросы умеет joy не те типа интервалы но всем стрел тебе они могут быть динамические поэтому это работать не будет очевидно и проблема при реализации секционирование через наследования у нас она появляется то есть как в у пашки давно свет абстрактный класс какая-то базовая реализация и потом уже конечно имплементации то есть вас несколько уровней наследования это заставляет очень много вычислений делать на уровне работа с таблицами там спел тебе есть многомерное секционирование то есть грубо говоря если вы хотите делать секции по времени но при этом еще чтобы они делали спал айтишником клиентов то есть грубо говоря у вас будет секция первый клиент один день второй клиент там первый день и так далее то есть там это все есть то есть не обязательно секционирования данному полю можно несколько и тогда это будет составные секции то есть это очень крутая штука там сказал говорит скорее всего вам это не надо но возможность этого есть у меня тут такой вопрос возник вместе с планами если мы строим какое-то представление по стримам агрегирование суммирования там еще что-либо если мы спустя какой-то момент вводим еще один параметр работа это номер датчика примеру еще что-то и хотим получить агрегату чисто по нему сколько ну насколько нам дорого выйдет и да ну если эти данные как бы то есть нам нужно для начала чтобы поток данных понимал что они начали приходить то есть нам нужно но если они шли сам если ну если они шли самого начала но в самом continues в you мы его не обрабатывали то эти данные после вычисления без него они просто отбрасывались если мы их не сохраняли потом они начинают поступать если наша continues view мы просто alter делаем на нем добавляем это поле то она появится там вот вопрос в том насколько дорого будет этот . да не дорого но это эквивалентно наверное добавлению столбца в таблице то есть но он теперь будет делать еще один агрегат появится еще одно поле ну все ну и такой тупые вопросы если глаза быть одновременно происходят они как записаться если два события происходят совсем одновременно вплоть до наносекунд но они будут считаться разными кто из них привет будет тот кто придет первaя но очевидно я не ну это очень но это уже вопрос наверное высоконагруженных систем консенсусе я не знаю кран амбиции меньше будет вторым быстро задавая у нас время закончилось здравствуйте спасибо за доклад у меня такой вопрос про оптимизатора хранения вот вы сказали что-то искал д.б. это больше правление этом серии у меня вот интересный вопрос оптимизатора хранения вот как у гориллы это меняется оптимизатор там дельта дельта реки алгоритм и вот если это of time scale даже например нет я понял вопрос спасибо нет то есть да мы знаем в the misery данных то есть для быстрой вставки они используют там еще и в памяти и специальные деревья как-то это скажет да пятна диски использую какие-то специальные структуры time steel тебе работает все по классике по реляционной то есть это по сути обычно реляционной алгебры обычная таблица обычной кортежи все что ты мстил дает это нормально и секционирование свой background worker и своя интеграция в планировщик запроса то есть он не использует никаких хаков которые специфичны для двух сиквел решений спасибо и еще вопрос про что имелось ввиду под триггерами презентации видел на и так и не упомянули ну триггер грубо говоря ну обычно триггеров squire базе классический то есть когда у нас приходят какие-то данные мы можем повесить триггер на ставку на примерно апдейт на enter наделит и этот триггер он будет делать вы пост-процессинг или привет processing операции вставки у нас например у триггер абстрагируясь от обстрела если мы используем postgis там у него есть свой тип данных широты и долготы специальном формате виджей с 84 широта-долгота и отдельном полис широта-долгота микадо вставляем мы вот это поле заполняем триггером то есть грубо говоря это бы processing дополнительные то есть ждать декоратор можно это называется ну это обычная классикой а я не знаю как это объяснить ну я понял что обычно это это не связано даже pipeline бета обычно триггеры его насмотритесь tanya нет наоборот спасибо спасибо я не видала нет в сибири нет претензий это на юге может быть как она зависит здесь нормально от краснодара до красноярска тебе спасибо большое аплодисменты памятные призы"
}