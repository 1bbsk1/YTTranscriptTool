{
  "video_id": "1I33bUGfnSU",
  "channel": "HighLoadChannel",
  "title": "Почему всё сложно с оптимизацией и что с этим делать / Константин Шаренков (2ГИС)",
  "views": 438,
  "duration": 2232,
  "published": "2023-01-19T05:55:16-08:00",
  "text": "приветствую всех надеюсь вы сохранили силы концу второго дня если посетили много много разных презентаций вы практически на каждой наверное видели или слышали слова оптимизация оптимизация оптимизация те кто были честными зачастую говорили ну тут мы не понимаем что происходит тут мы понимаем но мы вообще этого не ожидали и вот про это я и хочу сделать доклад здесь каких-то сложностей не будет я постараюсь вас не напрягать сильно сложными конструкциями но тем не менее возможно мне удастся дать вам посмотреть на эту проблему немножко с другой стороны может даже поменять отношение к этому всему и чтобы все мы любители оптимизации немножко по-другому оптимизировали я ширинку в константин создавал поиск в 2гис с 2013 по 2020 первый год и наш поиск это не такой поиск когда мы пытаемся чужой продукт заставить работать быстро когда оптимизирует либо операционной системы как работает потом как либо чужой там поисковый движок у нас был свой мы заставляли процессор и память работать так как нам хочется но тем не менее даже те кто занимается оптимизацией чужих продуктов им будет тоже полезно чтобы они понимали в какой реальности мы находимся сейчас известен конечно тезис что все меряют производительность но вопрос заключается в том собственно что может пойти не так здесь и я вот пойду сейчас самых элементарных примеров и постепенно буду углубляться углубляться углубляться несмотря на всю кажущуюся простоту показа я постараюсь показать вам как глубока кроличья нора давайте посмотрим вот все знают оптимизацию разворачивание цикла более того программисты считают ну нам не надо этого делать все за нас компиляторы сделает все замечательные все хорошо будет тем не менее на кажущееся очевидно здесь что мы избавляемся от переходов ошибок в предсказании ветвления лишь и лишние инструкции но тем не менее давайте покопаем что бывает а что не бывает вот возьмем простую программку совершенно элементарно у нас тут какая-то структура с четырьмя числами с плавающей точкой и какая-то операция которая в цикле через с тогда transform просто 4 от них числа возводят степень других и возвращает эти совершенно казалось бы такая простая операция но и и было на самом деле не так просто выбрать по то чтобы вдруг какой-то компилятор решил не разворачивать это сразу же вот начало и конец функция убрал вниз а вот более крупная как раз сам цикл представил его не надо читать пытаться понять в чем то достаточно увидеть в конце метку l2 и в конце инструкцию перехода на нее чтоб понять что этот цикл вот мы представили что мы проверили наш код нашли это и поняли что четко компилятор не стал по каким-то причинам нам разворачивать этот цикл мы думаем ну чтож что что за компилятор такой не справился с такой простой задачей берем делаем все вручную трансформируем вместо цикла сделали четыре раза возвели в степень вернули посмотрели известным всем инструментам на сайте известным год болт увидели отлично все развернулась все пока по плану идет до у нас никаких сюрпризов мы молодцы дальше пошли на не менее известный сайт быстренько сбили наш код туда старый новый запустили померили вроде все у нас по прежнему замечательно с циклом мы медленнее работаем с развернутым быстрее все по-прежнему идет по плану это наш джесси стеба тут мы думаем так а что у нас в ситуации с тем же флангам допустим clang решил развернуть нам этот все-таки цикл у него все одинаково тем не менее что у нас получается 6 ничего не понимает когда надо разворачивать цикл окланд понимает вроде же очевидно что если сравнить здесь было бог 100 миллисекунд лишним развернутая 20 здесь оба версии 20 все замечательно но тем не менее мы берем нашу программу меряем и и в целом как она работает и такая типичная картина что джесси хищный код на несколько процентов быстрее работает но как он может в целом работать быстрее если он какие то вот такие странные решения принимает поэтому приходится вот в таких случаях коллеги также говорили ну когда идет что-то не так надо разбираться почему она идет не так ну давайте пустим по разбираемся такой типичный пример и разбираясь с ним чтобы понять что происходит надо немного углубиться конечно но на самом верхнем уровне что происходит процессоре если вы смотрели предыдущее доклады в этом зале первый второй доклад вы уже примерно представляете что происходит что наших самых популярных cypher процессорах идет нога уровню процесс упрощенная его так за brazil на самом деле этапов намного больше все сложнее но cisco инструкции декодируется в микро инструкции происходит исполнении работа с памятью для нашей задачи это достаточно чтобы понять и вот в этой точке происходит достаточно интересная штука тут мы узнаем что собственно сама декодирования она тоже оптимизировано и у него есть собственный кэш де кодированных инструкций и бывает так что если компилятор решает очень много про игла и нить очень много циклов по на разворачивать то в этот кеш собственно мы начинаем упираться и узкое место инструментарий нам покажет что именно вот это декодировали это еще по-другому называется фронт-энд процессора то есть все что там после этого можно назвать брендом нацепил но у процессора имеющейся свой фронт-энд бывает узким местом то есть если вы энтов ским ведь он инструментом или каким то подобным смотрите вы это можете увидеть что что является узким местом что произошло то есть фактически 2 оптимизации наша разворачиваем циклы и оптимизация разработчиков процессора между собой про взаимодействовали неожиданным для нас способом ну дальше что что с этим дальше происходит мы решили что оптимизация была плохая выкинули и и успокоились и дальше как бы живем но выводы вот которые мы сделали насколько они правильные происходит некоторая вещь допустим выходит новое поколение процессоров у мтс entry у интела 12 поколение вдруг они неожиданно становятся все прошлые поколения как бы шли шли-шли и там не сильно ускорялись здесь заметные такие ускорения мы читаем спецификацию что сделали разработчики процессоров и вдруг неожиданно мы читаем что фронт-энд процессора значит кэш и та и другая команда там кратно увеличили crashers именно декодирование инструкции и количество линий которые декодируют тоже увеличили и вдруг опять таки то что было справедливо у нас буквально еще некоторое время назад становится снова враньем в общем в результате по всем этим оптимизации непонятно кто под кого оптимизируется чаще разработчики компиляторы под популярные процессоры или уже потом популярные процессор и начинают смотреть что что-то у нас мы везде упираемся во front-end и давайте-ка мы архитектуру поменяем раз у нас все таки и компиляторы а в результате правильного ответа на то стоило эту оптимизацию делать или не стоило ну по сути дела нет еще один еще проще пример хочу раз прежде чем какие-то дальше двигаться но тоже поучительный то есть совершенная тривиальная задача есть у нас какая-то одна по точная программа делает последовательного два действия буквально одинаковых вот и при этом не по данным не почему они у нас друг от друга не зависит и вполне очевидно с нашими современными процессорами мы хотим задействовать все ядра и хотим ускорить это распараллелить все казалось бы что может тоже пойти не так берем 1 параллели вам сегодня зависим все замечательно но выясняется в процессе допустим что задача у нас как раз была упиралась в шину памяти это что мы считали что функционально они независимы и то про производительность никогда такого сказать нельзя что две задачи абсолютно независимо в плане времени выполнения друг от друга то есть одна задача на сто процентов использовала шину памяти 2 запускаемых в параллель получаем что у нас эта программа просто тупо медленнее работает из-за того что больше промахов в кэш начинается то есть память а также нагружена а с кэшем становятся хуже суммарным и даже проседаем на производитель ставшим совершенно не неожиданный эффект это все случаи из реальной жизни когда пытается люди могут оптимизировать что-то еще вот так если глубже чуть чуть чуть чуть глубже нырнуть вы сейчас не пытайтесь понять схему это просто такая картинка вот если на процессор грэма схем это не современный процессор достаточно старая схема мы видим много много много много блоков там который сейчас делаются процессорах это сейчас их еще больше и вот какие-то из этих блоков они занимаются тем что непосредственно исполняют в программу а какие то из этих блоков по сути дела сверху костылями докинув ну ладно костылями красивыми архитектурными решениями докинуть и занимается в той или иной мере оптимизации быстродействия вот какой процент этих блоков занимается оптимизацией если так кратко глянуть вот этот процент вот все что красным отмечены это вот занимается оптимизацией а все остальное занимается как бы исполнением и это не самый современный процессор оставаясь современный процесс занимается примерно тем что постоянно докидываем все новые и новые блоки которые занимаются оптимизацией но что самое плохое в этом деле что все оптимизации по сути влияют друг на друга то есть если функционально мы пишем там красивые функции чистые функции которые никак не влияет в плане времени исполнения у нас ситуация ровно обратная из-за того что очень много всяких блоков на совершенно разных уровнях то по производительности все влияют друг на друга плюс у нас еще начинают смешиваться дополнительные какие-то оптимизации когда мы оптимизируем энергопотребление те же самые вот бигль этого архитектуры когда у нас части order таких часть я деру других мы пытаемся что-то здесь оптимизировать где там и чистоту снижаем потому что энергию хотим подать это наоборот turbo boost включаем это все влияет причем влияет друг на друга но что хуже этого что все блоки они влияют еще не только друг они сами на себя но в течение времени влияют то есть самой типичной оптимизации это какие-то буферы или кеш и соответственно на вас начинает влиять история предыдущего исполнения то есть вы работали и скорость исполнения вашей текущей какой-то операции зависит от того какие операции вы делали до этого получается что все связано совсем как функционально так и по времени я вот сделал такой слайд который можно почитать то есть это некий рыб получается то есть если мы посмотрим кто занимается и кто портит нам понятность выполнения то собственно трудно сказать кто не занимается чем-то в общем а по результатам все программисты мягко говоря иногда удивляются иногда страдают и у меня большие сюрпризы к тем кто что-то про оптимизировал на основе веры что он верит что так лучше как в предыдущих там 2 примера их ждут большие сюрпризы то есть по сути дела вот такая мысль которую я хотел донести что с точки зрения времени исполнения и определения вот реального предсказания быстродействия мы с вами все живем в в аду просто это ситуация хуже который практически не бывает то есть все зависит от всего и конечные эффекты очень странные могут быть связаны это вот такой картиной это первая мысль мы с вами в аду если кто оптимизирует и по сути дела получается такой вывод что точно предсказать мы ничего не можем и второй важный вывод что с такими вещами которые все но все влияет просто это вероятностные некоторые величины работать будем с ними просто как с вероятностями много таких систем где все имеет вероятностный характер и с ними понятные методы какие работы это что касается первой части доклада как бы мысль такая теперь что мы с этим делаем обычно допустим понятно что без измерений вообще бессмысленно штата dead мы вот этих всех уникальных ситуаций вы без измерения не нашли и все понимают что надо мерить но система разной есть кто-то пишет библиотеку кто-то пишет конечное приложение кто-то какой-то steady and пишет который всю планету охватывает но как нужно мерить то есть если где-то у нас есть пользователь есть где-то функциональный код на между ними очень много стадий и этапов что мы можем из этого по мере что нам разрабатывать может быть мы померяем то что нам только будет мешать разрабатывать вот мы выработали для себя простой принцип мерить естественно максимально близко к пользователю но с одним условием что то что мы измеряем находится под нашим контролем то есть если мы не контролируем какой-то фактор то мерить ивану странно получается дальше вот такой принцип и поэтому вот можно потренироваться но не все так однозначно то есть допустим вот рассмотрим какие то случае вот если мы пишем просто библиотеку где ее померить можно вот если мы померим просто какой-то публичный api наш скорее всего у нас получится ситуация как с первым примером когда мы просто какой-то синтетический тест написали и в реальности он ну не будет работать по сути дела на нас повлияет во сколько потоков на каких системах мы это запускаем и по хорошему нам библиотеку оптимизировать надо под какой-то либо тестовой нагрузкой которая имитирует приложения либо в идеале уже какую-то вообще сняв нагрузку с каких то приложений библиотеку протестируем но тонкий момент чтобы оптимизации любых библиотек они конечных продуктов есть такой момент что у вас упиралась система в какое-то узкое место вы что-то перри оптимизировали как библиотеку она стала упираться в другое место а что это значит для пользователей библиотек это значит что кому-то вы узко или у кого-то кому было то подсистема новое уже нагружена и вы заметили поэтому с оптимизацией именно библиотек там все очень еще хуже в общем дальше сервис микро сервис то есть ну в идеале если у нас есть какой-то быстрая сеть то мы можем прям вот снаружи через эту сеть с минимальными задержками и протестируйте нет такой возможности протестируем максимально близко к сетевому интерфейсу то есть если вы просто мерите там какой-то в ваш функционалу насколько функция выполняется ну получите там сюрпризы что какой-то маршалинга или сетевая часть потом будет основную часть съедать а если вы пишете микро сервис как законченный продукт то вы контролируете как раз и стерилизацию детализацию сетевую часть там и прочие-прочие вещи по хорошим вам надо это все по мере ну и какой-то сложный случай который если вас дата-центр есть но по хорошему надо на балансиры дата-центра померить но это говорит о том что фактически вам надо иметь тестовый дата-центр а такое редко кто может себе позволить но зачастую это уже мериться по факту такие вещи то есть каждый компонент отдельно оптимизируется и мы перекрестившись надеемся что в целом будет все быстрее хорошо ну конечно сюрпризы будут . и разобрались но ещё хотел сказать пару слов про нагрузку то есть чем мы мере такой тоже всем известный поучительный детский пример когда мы имеем какой-то линейный массив памяти отсортированы и вдруг в коде видим что кто-то в нем ищет линейно умный программист говорит это непорядок заменяем на бинарный поиск заменяет но даже синтетические измерения тут покажут что если мы имеем 1000 24 элемента в нашем списке то естественно но бинарный поиск быстрее а если 16 то линейный поиск быстрее и вопрос надо нам так оптимизировать или нет здесь нам как раз подскажет то что мы имеем собственно какую нагрузку в реальных условиях то есть принцип такой который мы использовали максимально близкий к целевой то есть у нас какая целевая нагрузка которой мы оптимизируем кто-то оптимизирует среднюю нагрузку просто он где-то в облаках там у ножа средняя нагрузка кто-то просто знает что у меня вот вот в этот час максимальная нагрузка ему нужно нагрузку взять именно вот с этого часто именно ее оптимизировать если его и как обычно для того чтобы нагрузка была dither минирования нужно зафиксировать данные на которых работает нагрузка и зафиксировать собственно саму нагрузку тем самым мы получим некоторый инструмент дальше все вот эти проблемы которые возникают они не дают нам все равно стабильную картинку на сто процентов как вы поняли невозможно воспроизвести мы хотим понять допустим мы меряем каждый камень у нас приходит результаты измерений быстродействие они меняются постоянно это что это вот это по самое вероятное отклонение пляж или это мы что-то натворили с этим мы работали так то есть мы естественно отказались от виртуальных серверов взяли физические максимально изолировали программы все остальное остановили настройки делали то есть заключается все что можно гипер трейдинге выключается там понижение частот все-все-все максимум что можно сделать дети терменировали выполнения это повышает стабильность результатов ну не забываем даже температурный режим когда мы ставим специальные вентиляторы в специальную комнату а то очень интересно бывает когда вдруг летом у вас тут бенчмарки проседают это вот как-то странно но даже вот нашего под что мы все сделали что смогли 3 процента все ровно пляж кстати четвертый принцип показывает некоторые дребезг четвертый принцип это непрерывность измерений то есть идеал это каждый commit когда мы знаем вот где-то у нас были всплески где-то проседаем но тем ни менее дребезг постоянном всегда есть вам надо понимать что не знаю если вы сможете избавиться от этих трёх процентов это будет конечно шикарно поделитесь опытом вы посетили сделайте доклад мы не смогли раз уж мы поговорили начали говорить про систему вот это важно понимать что она требует достаточно серьезных инвестиций и она должна быть систем если вы следите за производительности я потом более детально вот в кулуарах могу рассказать сколько у нас стоил вот такая система вот но от системы кроме того что мы померили нам нужно понять что мы верим то есть на скриншоте здесь здесь представлены перцентиле да по запросам 50 и там несколько следующих вплоть до 99 такая традиционным плюс мы даже мирим 100 перцентиль вы также можете проще поступать мерить соответствует целей или несоответствие запросы от чуть-чуть попроще процент соответствия стал можно гораздо сложнее упороться и сделать количественная оценка чтобы ваша система оценивалась в попугаях но как оценить в попугаях быстродействия системы в целых когда какое-то странное распределение это тоже тема отдельного доклада если кто готов поделиться можете но даже сделав подобные оценки с ними не так просто по ним еще на принимать решение если у нас перцентиле куда-то пляж да мы когда разрабатываем систему как мы это ценим мы должны понимать что виды принимаем хороши неприемлемо неприемлемо нам надо требует или не требует она внимание вот такое изменение производительности пора нам заняться быстродействием или не пара зачастую ответы бывают очень неочевидными то есть у нас допустим 50 перцентиль ускорился на десять процентов а 99 замедлился на 15 чем мы с этим делаем оставляем или берем вроде суммарная нагрузка на сервер от этого упадет то что большинство запросов ускорилось но какие-то плохие случае у нас замедлится это как раз зависит от того как матнасе сколько у нас там железо и прочего и плевать ли нам на быстрое время такая подсказка бывает ещё хуже если вы качество америки и у вас показывает что качество растет быстродействие падает и тоже надо принять решить не приемлемо или нет мы у себя до конца это не внедрили мы принимали решение субъективно смотрели в этом плане но идеи были допустим попытаться оценить все в рублях или в долларах если измерить качество быстродействия мы так далее но это все не тривиально получается хочу сделать вот еще пару полезных замечаний в подобной системе надо следить за ее ценой то есть оно не очень дешевая получается то есть требует постоянно внимание и разработки это прям определенный процент зачастую на систему измерения оптимизм больше уходим на сами оптимизации то есть и но зато она понимает примерно дает понять вам возможность что из практики где-то процентов 60 идей по оптимизации вообще сразу идут в корзину то есть ними системы но они зачастую могут на веру оставаться в системе а любая оптимизации это строго ухудшения читаемости качества и прочее если вы сделали оптимизацию она еще программа улучшил это уже не оптимизация просто наведение порядка также тем кто строит систему всегда тоже призывая следить за тестовым набором это за размером его это позволяет как раз и на цену влиять и на то как быстро вы получаете результат то есть наша система допустим могла оценить в течение 10 минут полностью весь commit от начиная от качества быстродействия любых ресурсов на любых платформах то есть так называемые большой артефакт мы делали любой commit здесь через 10 минут полная раскладка и еще если вы вдруг после доклада решите завести систему и она разлетится заработает рекомендую проверить уже имеющиеся оптимизации выкинув их и посмотреть они работают в реальные картине леонид могут ждать вас большие сюрпризы и того хочу подвести итоги живем мы в мире где предсказать быстродействие реальное невозможно но строить все равно систему измерений надо и строить ее надо правильно выберите правильную точку правильную нагрузку боритесь за стабильность мерите непрерывно принимайте решение и успехов вам построение правильных систем анализа и в чудесах которые вы найдете по результатам ваших оптимизаций спасти ваш тем а ты говоришь чудес не бывает видишь весь доклад немножко про понятную магию и про чудеса и тоже хорошо если вопрос толкование подожди они часами придут я вижу горящие глаза охуели есть горящие глаза то тут во время для прямо сейчас спросят или иные экспертные зоне я пока те чуть-чуть помощью скажи а я правильно понимаю что ты по сути призывающую историю чтобы профиль и нагрузок и любые процессы делались непрерывно это да обязательный процесс потому что авт factum разбираться что или где ну вот соседние доклад был кто аксонов вам рассказывал вот мы замерили оттуда для доклада сделал не все поменялось хотя код один в один и оборудование один в один потом обнаруживать по факту то есть это уже немного другого уровень снижения когда ты каждое свое действие каждый камень у тебя оценен это совсем другой уровень за этим снижения то есть мы приходим к тому что вот у нас есть первые камни за перформанс анализа должны быть специальные инженеры кинете рф анализаторы ну то есть не прям первых а инженеры дефис а она analyst по деградации производительности у нас это как было встроено в нас систему сами разработчики делали со стороны программирование инструмент и devops и тоже всяко поддерживали настя и это все а анализ проводил любой человек то есть любой кто комитет кто настраивает систему он сразу видит все последствия кто программирует видит все последствия любой кто к мите система все оценивается все виде отдельно при мне мы прям вся команда таки вы работали звучит как очень хороший best practice а еще куда-нибудь и рассказать про это потому что вот про это я бы кажется что прям много рассказать потому что очень мало компактно я понял опять и очень тихо говоря да да прости пожалуйста кажется что надо сходить и рассказать про это чуть побольше потому что очень малое количество компаний и рассказывает о а ну на каждый коммент вот именно анализ производитель на каждый коммент делается очень редко и если вы так делаете это очень круто на самом я могу сказать что мы над этим очень много работали когда то была такая история что постоянно нагрузка растет и мы делаем камень результат через час над этим поработали чтобы результат так работать уже невозможно чтобы результат был через десять минут я скажу даже больше что нагрузка при проверке нашей системе она выше чем боевая но это кажется x10 по защите это очень круто так давайте попробуем а первый вопрос привет спасибо за доклад мне наверно больше будет про чистовые условия про которое говорили в которой мы проводим такой идеальный тест мало людей на самом деле задумываются одном анодов и о том что вы припевать их процессы каким-то определенным ядрам потому что если у тебя много процесс иная система там с двумя народами у тебя процессе хочу туда туда туда везде конечно у него по чуть-чуть и получается тестов прям совсем плохой вот иногда это даже не вопрос такой вот пожелание всем совет что правда думаете она монада потому что если ну вот шина памяти которые мы показывали их на самом деле она есть и миша пятна и и еще с моим либо съесть очень сильно влияет там и задержки пишу эту шину можно переполнить какой-то задачкой и вот как раз вот это же ну монада и приписывать процессы к ядрам процессора физически прямо tasks этом и вот гипертрейдинг еще до сверху отключить у нас прямо вот нагрузка если мы знаем как устроен допустим наши типовой серверов дата-центрах вот мы оптимизировали нагрузка одного сервера и нагрузку давали вот столько я der сколько в нем примерно в такое количество потоков то есть архитектура у них похожие то есть чем ближе мы к целевой нагрузки делаем тем отражение наших то что мы узнаем на бою с теми что мы прогнозируем больше коррелирует но вы тут думаете что планировщик операционной системы супер dither минирован и ну это не то нет мы не думаем у нас же все на вероятностях построена то есть в целом система когда она прогоняет допустим там полмиллиона запросов распределение достаточно стабильной остается плюс мы я уже не отражал здесь мы отдельно боремся со всякими выбросами и прочими то есть мы все выбросы отдельно собираем после прогона и они идут на повторный прогон чтобы посмотреть реально ли что-то происходит потому что там до уровня запросов все отслеживается что какие-то запросы куда-то поехали по быстродействию в целом дребезг есть но с ним достаточно успешно нам удалось побороться и нагрузку целевую прямо мы прогоняем его статистическое распределение мы же то есть по сути вы ищете джиттер просто ну как вероятностную то что я горел мы как вероятность на эту модель рассматривать всегда есть какая-то вероятность за сколько и сполна со времени смотрим распределения наших пирсинг или по времени если уже мы уверены что пирсинг или пошел города никуда мы до уровня запросов смотрим это мы тоже отдельный инструментарии explain а у нас есть бенчмарка мы смотрим какие блоки как поменялись по производительности вот и по то что говорили про облака это прям тоже интересно потому что обычно люди такие на железе голом протестировали запустили в облака картина вообще другая совсем прямо спасибо вопрос спасибо большое задаваться интересны и полезны и вы упоминали план высокие песен серии запросов и что там бывает выбросы по сути это хвостовая задержка то его лет оси и на нагруженные системе скажем миллион пользуйте там 99 посетили один пользователь и это но много до 10000 пользователи могут видеть высокий задержка причем это из и нормальное распределение то есть получается вот такой блок верх у вас все хорошо там скажем три сигма хорошо а дальше у вас пошел очень видны хвост да то есть там люди могут там скажем 100 или 1000 человек могут придавать задержки там могут может быть мыга секундный мы видели например нагруженных сильва когда планировщик операционно steam добавляет аж одну секунду задержку вот такими хвостовыми white нас выходной сити поступок зачислить и к отклонения как вероятность или же вы специально делать потому что обычными борется вообще другим систему до сеанса льна куда то есть есть все вот эти компоненты то есть пирсинг или допустим не по нашей причине а по причине планировщика случился а нам важно не реагировать на то что мы не контролируем допустим мы уже смирились тему нибудь мы не будем мы решили допустим что не будем вмешиваться в ядро у нас это вот решается все выбросы мы перри прогоняем повторно если они воспроизводятся стабильны тогда мы следим за ними и принимаем меры а так получается что повторным проходом в этих запросов мы их отсекаем от себя почему вы планировщик никогда льете вы его приказ интегрируйте не нет мы не хотим мы даже если у него есть недостатки нет смысла , короче что они риттер переходит форманты и священный зонда прошу продолжились условную не спасибо за доклад а как вы понимаете что у вас переполнилась шина данных ну вы упираетесь нее это уже вот по результатам мы допустим поняли что что-то пошло не так это уже сценарий ищется то есть мы наш инструментарий позволять до уровня запроса посмотреть на эту роль на уровне запроса воспроизводим смотрим какие блоки и потом этот уже по стандартной схеме пар филировки нет уроку уровень запросы и мы смотрим допустим то есть этот запрос да допустим сразу там 32 потока запускается под профилировщика мы смотрим и стандартным инструментом смотрим куда я что упирается то есть обычно если запрос узкое место когда его еще в кучу потоков запускаешь она ещё там сильнее начинается и мы увидим что допустим вот в бэг-энд процессорами на запись память или впечатление памяти мы упираемся итак определяем то есть до стандартного профилировки мы также доходим то есть эта вся система в целом за детектив нам помогает оценить целом но дальше дальше drill-down bring down и докапываемся до самого до самого"
}