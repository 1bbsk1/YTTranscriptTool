{
  "video_id": "ocdzyL7rBUU",
  "channel": "HighLoadChannel",
  "title": "Тернистый путь к единому хранилищу метрик экосистемы / Филипп Бочаров (МТС Диджитал)",
  "views": 1034,
  "duration": 2950,
  "published": "2025-01-17T02:18:37-08:00",
  "text": "Меня зовут черов Филипп в МТС моя команда создаёт платформу наблюдаемом всеми типами телеметрии У нас есть логи распределённая трассировка о которой я кстати рассказывал на предыдущих хайдах и конечно же метрики так вот единое хранилище метрик экосистемы - это часть нашей платформы зам зачем мы начали заниматься задачей единого хранилища чтобы это понять некоторую ретроспективу как выглядела экосистема МТС буквально там несколько лет назад во-первых МТС - это большая экосистема Она состоит из множества юрлиц дочерних компаний и так исторически сложилось что у многих этих дочерних компаний были свои it подразделения которые самостоятельно развивали мониторинг часто он был сделан на какой-то связке за абек приуса и мониторинг у нас получался децентрализованный для того чтобы узнать о здоровье того иного Ну было с понять какую систему мониторинга за этим Вообще идти нам это не очень нравилось что мы хотели получить в итог во-первых мы хотели наш мониторинг централизовать для того чтобы в единой точке знать о здоровье всех продуктов нашей экосистемы и о всех бизнес-процессах которые в ней протекают естественно Мы хотели чтобы наше решение хорошо масштабировать потому что наша экосистема постоянно раст у нас уже сечас более 600 продуктов Этот рост продолжается э нагрузку Ну и поскольку мы делаем платформу то наша Ключевая задача - это упрощать жизнь продуктовым командам Мы хотим чтобы продуктовые команды делали свой продукт не задумывались о мониторинге чтобы для них это было максимально дёшево поэтому всё должно быть из коробки всё должно быть максимально просто для команд Ну внимательный слушатель может увидеть Зак и спро но у нас это не получилось Мы упёрлись в вертикальное масштабирование закса уже на 30.000 НПС у него начались проблемы он потреблял довольно значительное количество ресурсов плохо сжимал данные Ну и Мы понимали что с нашим ростом он скорее всего не справится Кроме того у нас в экосистеме начал активно внедряться кубес который заплаче на другой стек мониторинга и мы поняли что закс не очень походит на наше целевое решение мы начали искать что-то другое проанализировали несколько вариантов посмотрели на кортек мер Танос и пришли к выводу что именно викри matx потребляет наименьшее количество ресурсов и лучше всего сжимает данные из всех этих альтернатив это вот хорошо видно из таблицы справа где для 10 млн уникальных рядов викри потребляет практически в пять раз меньше оперативной памяти чем ближайшие аналоги Роме этого нам очень нравилось что хоро масштабируется горизонтально может принимать данные по разным протоколам что для нас тоже важно потому что по сути мы делаем такой зонтик собираем метрики из множеств подсетей и различного стека и наша вири отлично справляется с данными высокой кардинально об этом мы ещё с вами поговорим дальше в докладе хорошо выбрали viia matx кажется пришло время научиться её готовить научиться её масштабировать делать её отказы устойчивой Давайте попробуем С чего вы начали начали с самой базовой архитектуры Victor Matrix который можно там посмотреть любое статье по ней как это выглядело У нас есть множество продуктов которые пушат свои метрики в наше хранилище через балансировщик это всё попадает на пул компонентов V insert это компоненты Victoria Matrix которые отвечают за вставку данных insert соответственно записывает данные в компоненты Stage которые занимаются хранением этих данных У нас есть в этой схеме два читателя один из них - это графана это дашборды на которые инженеры смотрят глазками и компонент VM Alert который собственно занимается правилами алер обсчитывают эти правила и предупреждает нас когда Метрика вышла за какой-то допустимый порог а вся эта нагрузка на чтение тоже через балансировщик попадает на компоненты VM Select Victoria Matrix который ответственный за обработку запросов на чтение Ну и они соответственно выбирают данные из стод Вот такая вот простая архитектура эти компоненты мо мать Независимо для того чтобы там улучшить чтение или улучшить запись проблемы начались Естественно с ростом нагрузки так кажется у меня перестал работать кликер проблемы начались уже на этапе кликера Итак проблемы начались естествено с ростом нагрузки у нас ло количество которых которые были поставлены на мониторинг соответственно увеличилось количество агентов которые на них стоят и количество соединений с нашей Виктори Matrix компонентами VM insert как оказалось VM insert довольно плохо реагирует на увеличение количества коннекто начинает деградировать и медленнее обрабатывать входящий трафик нам нужно было как-то наши компоненты VM insert от этого большого количества соединений защитить А к счастью у Victor Matrix есть ещё один компонент - это VM Агент это такой легковесный акен он умеет принимать данные метрики по разным протоколам умеет скрепить метрики такой Если хотите легковесный прометеус собственно мы реализовали некий буферный слой м агентов перед инсерта для того чтобы их защитить что нам это дало во-первых у нас радикально снизилось количество соединений на порядок это произошло за счёт того что у ВМ Агента есть внутренний буфер где он может метрики накапливать соответственно буферизированный помимо этого мы получили некоторую защиту от кратковременных сбоев на нашем контуре метрики могут полежать какое-то время в буфере ВМ Агента дождаться когда там у инсерта и ужа всё стабилизируется и до записаться и ещё одно преимущество - это сжатие гент умеет метрики пережимает вче раза то есть трафик который приходит на ра уменьшается и дальше уже записывается В общем одни преимущества Ну естественно это была не Единственная проблема Мы вроде порешали проблемы с записью тут же появились проблемы с чтением наших данных откуда они пришли Дело в том что нагрузка на чтение от двух наших читателей от графана и отлета периодически конкурировать любой Ар создать Сколь угодно сложный дашборд и эти за ле нагружать приводить к тому что допустим дашборды медленно загружались что с этим делать Ну хочется как-то эту нагрузку разделить Ну например сделать два отдельных контура Вик Matrix Пусть один занимается артин второй занимается дашборда Ну вот в эту историю мы пошли развернули два контура викри Matrix на один смотрел афана на другой Alert Единственное что нам нужно сделать Да это как-то зазерка трафик то есть Нам нужно чтобы в обоих контурах VI matx лежал на тот момент когда мы это делали такой возможностью зевания обладал только компонент мы соответственно реализовали это на нём наш РВ начал писать в два контура и всё было хорошо только это не работало как Казалось не очень хорошо справляется с проблемами конда проблемы Ну например падал storage Да перезагружался и соответственно его производительность на вставку падала то запись останавливалась и в другой Контур в котором этих проблем Нет причём речь может идти даже не о каких-то там аварийных ситуациях на контуре а о банально запуске н тасков да то есть у Victor Matrix есть фоновые активности когда она удаляет данные и в этот момент производительность VI Matrix немножко падает и даже в этот момент да Казалось бы довольно штатная работа vior Matrix мы ощущали Что начинает деградировать соответственно нас это не устраивало но к счастью возможность зеркалирование чуть позже появилось на компоненте гент мы заменили зеркалирование на минсер на зеркалирование на Генте наш трафик также зеркалит Да только он раскидывает теперь на м агентах и получили то поведение которое мы хотели да то есть у нас теперь в случае пробле одного контура данны продолжают писаться во второй метрики спокойно лежат в промежуточном буфере Агента дожидаются стабилизации проблемного контура и туда до записываются в общем красота всё стабильно так вот а но как Мы помним у нас один контур выделен под фану второй контур выделен под Alert то есть в случае если один контур у нас падает мы лишаем се либо дашбордов либо алер согласитесь Это как-то не очень хорошо для Mission Critical системы нам нужно сделать так чтобы при падении одного контура у нас продолжало работать И то и другое чтобы этого добиться мы сделали верхнеуровневый слой ВМ селекто А между нашими читателями И нашими контурами то есть для ВМ алерта был выделен отдельный пол VM селекто и для фаны отдельный пол VM селекто каждый из которых работал с обоими контурами викри Matrix Таким образом мы немножечко разделили нагрузку между этими пулами и при этом добились того что в случае падения одного из контуров запросы и от графана и от м алерта идут к тому контуру с которым Нет проблем то есть Таким образом мы разделили и запись и чтение но мы всё ещё не избавились полностью от проблемы потери данных а как я сказал у ВМ Агента есть внутренний буфер может накапливать метрики какое-то время но он не бесконечный мы не можем переживать какие-то длинные длительные простое делать какие-то длительные тенс потому что буфера аген просто не хватит что приходит в голову ну сделать какой-то внешний буфер какую-то внешнюю очередь Где наши метрики могут лежать дольше именно в эту сторону мы пошли и Рева запись наших Чере очеред ственные комне и это сервисы которые занимаются соответственно ставкой данных каку и чтением из неё те кто сталкивались сри могут спросить Позвольте зачем вы сделали свой велосипед вири и так умеет работать с како мы не любим велосипеды это было вынужденное решение Дело в том что мы тестировали ту реализацию там коню которо проблемы что и у VM инсерта в случае деградации одного из контуров этот консьюмер начинал медленнее записывать данные или вообще переставал их записывать И даже после восстановления в общем-то не восстанавливался соответственно нам пришлось делать собственную реализацию консьюмер и продюсера А в этой схеме у нас м агенты теперь пишут не на не в компонент V insert напрямую да А в компонент Фер который полностью повторяет интерфейс то есть гент Думает что он общается с iner а в обоих контурах у нас стоит комер который вычитывает данные из кавка собственно каждое сообщение в нашей Кафки это bch metric Примерно 100 мб размером Это от 10 до 100.000 сэмплов Кроме этого в кавка мы создаём отдельные топики Для важных продюсеров Трик например кластеров bernat это сделано для того чтобы их метрики не пересекались с метриками продуктов и обрабатывались во внеочередном поря Итак в нашей финальной архитектуре нам осталось добавить буквально небольшое усложнение Дело в том что экосистема МТС геора спредер сомнительной кажется идея гонять метрики там из Владивосток в Москву хочется как-то сделать так чтобы метрики максимально быстро доставлялись до нашей платформы не передавались между цода А для этого нужно чтобы продукт писал ближайшие ближайшее развёртывание платформы как этого добиться Ну мы это сделали с помощью gslb то есть балансировки трафика по географическому признаку наши м агенты мы их раскидали по каждому цду то есть в каждом цоде у нас стоит гент и продукт использует gslb пишет свои метрики в ближайший доступный ВМ Агент Ну и это ещё не всё ВМ агенты когда записывают в контур Виктори metrix тоже использует gslb То есть каждый гент записывает в тот контур Victory Matrix который ему ближе Ну географически а получается что в каждый контур vory Matrix у нас приходит только часть трафика но мы знаем что в каждом контуре у нас должно быть 100% данных чтобы этого добиться наши компоненты VM буфер работают со всеми кавка в каждом контуре то есть ВМ буфер в одном контуре vior Matrix получает данные из всех контуров Victory Matrix таким образом все данные все 100% фи попадают в каждый контур Ну что ж теперь когда мы узнали финальную архитектуру пора поговорить про то как это решение вообще поддерживать как обеспечивать там доступность на высоком уровне Для этого нам нужен само мониторинг Да мы должны как-то научиться это мониторить по классике мониторинг должен быть White Bo и Black Да мы должны получать метрики изнутри нашего решения и смотреть на него глазами пользователя снаружи если говорить обо Метрика то наверное там Ключевая Метрика - Это лак в кафке А если этот лак растёт да Значит мы не успеваем обрабатывать все наши метрики У нас есть какая-то проблема с производительностью нам нужно что-то масштабировать это одна из там ключевых метрик на которые мы смотрим конечно же мы смотрим на ошибки на процент ошибок на запись и на чтение а помимо этого мы хотим чтобы наши клиенты быстро получали ответы на свои запросы по Метрика поэтому смотрим на перцентиль времени ответа на запросы на чтение на самом деле это мониторить довольно удобно потому что все компоненты Victory Matrix умеют отдавать метрики в формате проте то есть само мониторинг настроить легко а Ну ещё одна Ключевая для нас Метрика - это объём трафика на ВМ Агенте поскольку система у нас геора спредер сети Да что-то где-то может гнуть и мы лишаем трафика с одного из сегментов нашей сети Поэтому вот этот объём трафика Нам очень хорошо подсвечивает эти проблемы как только мы видим что он упал там ниже какого-то допустимого Это значит что один из сегментов выпал и надо идти разбираться почему это произошло Ну и если говорить про Black метрики то понятно что мы щупаем доступность всех публичных интерфейсов это это доступность графана но остаётся ещё один вопрос А куда эти метрики складывать кто собственно будет мониторить мониторинг Да проверять за проверяющим Чтобы это сделать можем склады случится мы этих метрик лишимся поэтому мы решили развернуть рядом с каждым контуром Victory Matrix V sle Single - это по сути Victoria Matrix собранная в одном инстанс данных там не так много да то есть это чисто данные по мониторингу контура Виктории поэтому мы можем себе позволить всё это держать в одном инстанс V сингла и не лишаться этих метрик даже если у нас что-то произойдёт самим контуром Ну что ж пора похвастаться цифрами Это самый приятный слайд моей презентации что у нас получилось у нас получилась георесурс у нас лежат на SSD дисках Виктория мерик и потом мы перекладываем их в S3 хранилище А мы обрабатываем до 12 млн сэмплов в секунду это трафик приходит от более чем 300 продуктов нашей экосистемы и у нас около 2.000 активных пользователей Ну что ж мы с вами сделали классный контур научились его масштабировать хранить наши данные но этого Маловато нам нужно научиться наши метрики правильно собирать почему это важно Дело в том что экосистема у нас большая и очень разнообразная у нас более 90.000 различных хостов веб-сервера В общем довольно бой Зор личного более того мы Мерим собирать вй потом эти метрики можно и использовать для создания дашбордов алертов настройки мониторинга и Мы помним что мы делаем платформу соответственно этот сбор метрик для продуктов должен быть максимально дешёвым и простым как же этого добиться Ну классический подход с которым вы все наверняка сталкивались это экспорт Это нормальный зарекомендовавший себя временем подход когда мы для каждого рядом с ним скаем СБА Экспо ставим настраиваем где-то ставим ещё какой-то сборщик например проте который начинает эти митки скрепить подход нормальный но он очень многодет буу ет от инженера для каждого по поставить экспортёр настроить его причём для некоторых популярных типов по этих экспортёров может быть несколько Что приводит к тому что одна команда использует один экспортёр другая другой и мы получаем одинаковые по смыслу метрики с разным названием Да с этим неудобно работать но самая большая проблема заключается в том что этим нельзя централизовано управлять То есть никто вам не гарантирует что этот экспортёр будет обновлён до последней версии Да после обновления самого по никто не гарантировать что команда за ним достаточно пристально следит и там допустим поднимет его после падения поэтому мы пошли По другому пути этот путь основан на Агенте телеграф и небольшой толики магии значит что такое Агент телеграф это легковесный Агент написанный на го он умеет не только собирать метрики но и организовывать ы он умеет эти метрики агрегировать и отправлять в любое количество точек по разным протоколам собственно концепция телеграфа она выстроена вокруг плагинов то есть для каждого типа по есть и плагин который умеет работать с тем или иным типом по и все эти плагины встроены сразу в образ телеграфа то есть не нужно ничего дополнительно ставить как в случае с экспорт мы пошли чуть дальше и самф встроили в золотой образ операционных систем в этот ты любой виртуальной машины ВТС Телеграф на ней уже установлен и готов к работе но основная магия заключается даже не в этом а в том что мы научились этим телеграфом централизовано управлять Сейчас расскажу как это происходит для того чтобы управлять агентом Граф централизовано на каждом Хосте мы разработали свой сервис который называется он тоже встроен золотой образ разворачивается вместе сфом ан собирает нам кучу полезной статистики отлавливает все ошибки поднимает его в общем следит за здоровьем Агента Но самое главное То что он умеет из централизованного хранилища получать конфигурацию нашего агента по сути при запуске телеграфа и по расписанию T через запрашивает данные из нашего централизованного хранилища в централизованном хранилище лежат правила сбора метрик которые настраивают либо продуктовые команды либо профильные команды например администраторы баз данных А эти правила если упрощать выглядят как допустим для всех хостов по маске ПГ звёздочка Активируй плагин сбора Matrix pog То есть это правило действует сразу на какую-то группу хостов А и позволяет нам не настраивать для каждого Хоста отдельное правило более того для одного Хоста может действовать несколько правил То есть у нас вполне нормальная ситуация когда для какого-то юк Хоста профильная команда unix создаёт правила для сбора метрик операционной систе мы которые нужны для работы а команда dba да Для того же Хоста создаёт правило для сбора Matrix pog соответственно два этих правила действуют на один хост telegraf Help умеет их объединять и превращать в Валид конфигурацию Агента teleg соответственно вся эта конфигурация прогружается в Агент и Агент начинает собирать нужные нам метрики это радикально снижает затраты инженеров на настройку мониторинга то есть не нужно ничего Устанавливать можно сразу настроить допустим мониторинг на целый кластер поса если у вас там даже Появится какая-то новая нода какой-то новый сервер он автоматически под этот мониторинг попадёт А у такого централизованного сбора метрик Да по единым правилам есть несколько приятных последствий собственно Профит первый - это как раз то чего мы хотели достичь то что мы называем метрики из коробки у нас как и у многих Enterprise компаний есть внутренняя Облако которое предоставляет межд ресурсы это база данных как сервис maned cuber свка сервис и другие все эти средства разработки по умолчанию подключены к нашей платформе То есть их метрики собираются автоматически поэтому продукты выстраивая своё решение на базе этих сервисов получают не только базу данных как сервис Ну и мониторинг этой базы данных как сервис у них есть публичные дашборды куда складываются все метрики визуализируются все метрики по технологиям То есть им достаточно выбрать свою базу данных или свой кластер чтобы эти метрики увидеть также даются типовые правила артин да то есть команда об этом вообще не думает Она просто получает это как сервис Ну и второе последствие которое следует из предыдущего это типовые формулы индикаторов качества или serv lel для того чтобы отслеживать здоровье нашей экосистемы мы просим все наши продукты описывать своё здоровье набором индикаторов качества по сути это некая формула на языке яке кокава хо работает та или иная бизнес операция продукта собственно эта формула должна выдавать некий процент 100% это всё хорошо 0% всё м плохо вообще ничего не работает благодаря тому что у нас все метрики собираются в единое хранилище и в Едином формате мы можем эти формулы тоже делать типовыми Как это работает вот для примера что это такое Это процент ошибочных запросов поскольку если у нас продукт используют cuates то мы точно знаем что все его метрики попадают в Виктори Matrix и мы точно знаем что там есть метрики ining мы знаем как они называются соответственно Мы можем написать единую формулу которая берёт просто все успешные запросы к этому н контроллеру и делит на сумму всех запросов которые к нему приходили получаем как раз вот этот процент результативности успешности выполнения операции и это формула будет одинаковая для всех продуктов которые использует кубес то есть мы можем просто подставить туда название продукта Да и получить типовой индикатор нам не нужно выдумывать что-то там невероятное для каждого продукта Ну что ж мне кажется мой доклад слишком позитивный У нас всё хорошо мы решаем все проблемы пора добавить ложку дёгтя в нашу бочку с мёдом а рубрика Вредные советы Сейчас я расскажу вам как ломать коммунальное хранилище а поскольку хранилище у нас коммунальное кто угодно к нему может подключиться он может сделать это не совсем правильно Да допустить какую-то ошибку при подключении А эта ошибка Может в лучшем случае ухудшить а клиентский опыт этого продукта А в худшем повлиять на здоровье Всего нашего хранилища повлиять на другие продукты с этим надо бороться Вот одна из проблем которая влияет на на клиентский опыт - это метрики с огромным лагом То есть это время доставки метрик до нашего единого хранилища согласитесь Если ваши метрики достигают хранилища там за 10 минут то ни о каком оперативном мониторинге Ну говорить не приходится За эти 10 минут вам и так пользователи оборву все телефоны вашего контакт-центра и вы и так узнаете о проблеме без мониторинга А поэтому этот лак нужно стремиться сокращать лак у нас складывается из двух частей Это лак на стороне платформы да то за что отвечаем непосредственно мы там время нахождения метрики в Кака за ним мы следим Да мы понимаем как его мониторить но с лагом на стороне продукта да то есть временем которые уходит на скрей экспортера на передачу метрик В платформу всё значительно сложнее это инфраструктура продукта её не так просто мониторить и в конечном итоге нам нужно какое-то средство для того чтобы вот полное время доставки метрики контролировать К сожалению такой готовой метрики нет поэтому нам пришлось её делать самостоятельно для этого мы написали отдельный компонент он параллельно читает весь поток Трик из кавка находит для каждого замера время Когда произошёл сам замер и время доставки до нашей кавка сравнивает их получает Дельту вот эта Дельта и является нашим лагом Да той метрикой которая говорит Хорошо ли продукт доставляет метрики или плохо что мы с этим дальше делаем мы естественно отслеживаем этот лак смотрим У каких продуктов он превышает допустимые для нас показатели приходим в продукт и разбираемся почему это происходит там может быть на самом деле тысяча причин там ВМ Агенту на стороне продукта может быть выделено мало ресурсов не включено сжатие там какие-то настройки не выставлены то есть на самом деле масса вариантов поэтому надо работать с командой и помогать им правильно настроить отправку метрик вторая проблема - это высокая кардинальность о которой я вам обещал рассказать что это вообще такое вообще кардинальность - это количество уникальных временных рядов в нашей векторе matri У нас есть метрики да например htp requ Total количество htp запросов и у этих метрик есть разрезы вот в данном случае два разреза Да это instance и pu собственно наш кардинально здесь равняется двум потому что у метки instance одно уникальное значение - это цифра о и у метки па два уникальных значения wr если мы допустим в эту метрику добавим метку ID с уникальным инкато пользователе и пользователе у нас миллион то суммарная кардинальность получится 2 млн почему это важно Дело в том что для каждого уникального сочетания меток для каждого уникального временного ряда Виктория metrix тратит дополнительные ресурсы на его создание есть отдельная Метрика которая называется которая показывает как раз количество новых временных рядов в единицу времени вот здесь на графике как раз подсчет аварийный Когда у нас Метрика Чар какнула то есть кто-то создал очень много новых ременных рядов И поверьте в этот момент Виктори matx было очень плохо и показан момент когда мы поработали С командами и снизили эту кардинальность упростили жизнь нашему нашим контурам Виктории matx Окей как с этим работать как снижать кардинальность для того чтобы что-то снижать Надо сначала понять Чью кардинальность мы снижаем найти виновника этой проблемы для того чтобы это сделать можно воспользоваться канали экспортёром экром Извините это интерфейс vmu который нам показывает статистику по всем Метрика Victoria Matrix и позволяет нам найти метрики с наиболее высокой кардинальность вот в данном случае мы видим одну из метрик которая довольно сильно прирастает мы можем в неё провалиться и увидеть какие именно разрезы дают нам эту высокую кардинальность в данном случае это ре да то есть мы видим что там наибольшее количество уникальных значений если мы эту метку уберём а соответственно у нас кардинальность сильно снизится а ровно этим мы и занимаемся когда мы находим такую проблему Мы работаем с командой для того чтобы с этой меткой что-то сделать а для этого у ВМ Агента есть секция relabel которая позволяет Ну выполнять любые операции с метками в том числе их удалять А вот у нас есть реальный пример как мы поработали с командой dba у которых была Метрика связанная с посо и там реально в один из лейбов записывался текст и сколи запрос бы сделан Как вы понимаете текст запросов очень вариан поэтому кардинальность там была совершенно бешеная собственно мы эту метку удалили потому что она не очень была нужна команде и сократили на два порядка кардинальность Ну что ж пора самарова наш опыт и подумать чем мы можем какие выводы мы можем сделать че да В данном случае метрик вам нужно предвосхищать ошибки которые могут допустить ваши пользователи научиться их мониторить автоматически отлавливать Потому что эти ошибки подключения могут Ну либо ухудшить опыт самого продукта да либо вообще повлиять на ВС ваше коммунальное хранилище это вот к теме лага и высокой кардинальность нужно работать С командами приходить к ним и помогать вторая задача при создании коммунального хранилища это некие правила которые для всего вашего ландшафта Best практис и правила здорово если эти правила сделаны в виде какого-то инструмента который вообще не даёт ошибиться Да вот как например там телеграф с централизованным управлением то есть там этот стандарт вшит сам инструмент Но если этого нет то стандарты нужно фиксировать в виде какой-то там нормативной документации проводить демо обучать команды рассказывать им Как правильно подключаться третий поит который я хотел бы чтобы вы вынесли это Нае Enterprise версии VI matx Мы в своей работе используем комьюнити версию из-за лицензионных ограничений но в целом в Прай версии много хорошего в ней есть дамплинг есть расширенный сбор статистики есть компоненты занимающиеся машинным обучением Поэтому если вы можете справиться с лицензионными ограничениями Посмотрите на Прай версию она сэкономит вам много чеко часов и нервов ну и наконец чет Если вы делаете систему то Здорово сразу в неё заложить возможность распределения записи трафика по нескольким ВМ агентам разбросанным по собственно по вашим цом мы это заранее не сделали нам пришлось это делать уже постфактум подумайте об этом заранее чтобы не пришлось Спасибо вам большое что выслушали меня Вы можете оставить свой отзыв используя QR код также я Напоминаю что у ТС есть свой стенд Приходите чтобы узнать о других платформах МТС которые мы делаем Спасибо Спасибо большое Да друзья по поводу отзывов пожалуйста их оставляйте потому что программный комитет в отличие от многих других конференций их правда читает и сейчас время вопросов поднимите руку Задайте Задайте вопрос у нас времени не очень много но спикер потом пойдёт в дискуссионную зону и вот девушка первая подняла руку можно вот я вижу невооружённым взглядом что её зовут Настя да и через чат ботик тоже можно задавать вопрос через чат зала потому что на эти вопросы спикеры потом отвечают икро пожалуйста Привет Спасибо за доклад Меня зовут Настя Я разрабатываю Яндекс монитори у меня такой вопрос ты говоришь про кардинальность метрик высокую и насколько я понимаю вы живёте в кубернетес в кубернетес есть большая проблема с тем что у каждого пода есть уникальный хэш изза чего у мерик зачастую получается высокая кардинальность Как вы с этим живёте боретесь ли как-то или справляетесь Спасибо прежде чем отвечу на этот вопрос хочу представить вам нашего кото сегодня поможет мне отвечать на всякие каверзные вопросы Из зала Михаил Данко автор большинства доработок по Виктории которы о которых я сегодня рассказывал аплодирую Миша что мы делаем с метриками кубер ну с данными конкретными метриками мы к сожалению адекватных вариантов не нашли как с этим поступить то есть мым вость нормально отслеживать в принципе метрики по всем подам для То есть это зачастую опять же Это для деплоймент самое критично потому что там у них меняется хэш в конце то есть для йф сетов можно было бы убрать юид и юид мы как раз убираем из метрик но имя пода К сожалению ничего с этим не поделать по большому Спасибо Спасибо так раз раз спасибо за О нет Это человек в мерче хайлоу сейчас будет страшный вопрос подставной Да спасибо за доклад интересно меня Фёдор Васильев зовут итек Вот вы говорили про грах это ваша разработка или её где-то можно пощупать Да Это Наша разработка наш ты понимаешь Какой следующий будет Вопрос Да наверное когда будет Open Source потому что очень интересно Мы подумаем над этим на самом деле у нас есть планы не совсем на Open Source Но скажем так возможность это приобрести как решение было бы интересно посмотреть спасибо спасибо Так помогаем я Прибежал в центр зала давай давай давай кто быстрее я быстрее тебя бегу Здравствуйте Роман Васин компания Арена дата вот показана была очень интересная архитектура но хотел узнать всё-таки есть у него какой-то потолок или нет Вот если у вас 300 плюс продуктов А если их будет 3000 То есть как вы рассчитываете через года два-три может быть вы во что-то упр и куда тогда пойдёте Да когда станете крупной компанией Да ну по большому счёту сейчас у нас был новый контур запущен и у него уже там трёхкратный запас по производительности относительно текущего и опять же как говори Виктори очень хоро масштабируется вертикально Ну пока что пределов заметно не было Но даже если Мы в такие пределы утм её можно при желании шардирование объём хранения Рик Да потому что он тоже постоянно растёт и в общем-то мы пошли По пути удешевления этого хранения и вот перекладки Рик из vict Matrix на S3 хранилище вот чтобы как бы немножко удешевить всё это дело Спасибо будьте добры Здравствуйте спасибо большое за доклад небольшой дисклеймер сразу я не работал с к вот такой вопрос Вы сказали что Пите трики сразу в несколько они дублируются и Казалось бы система Рик она не особо должна быть консистентной возникает ли ситуация что из разных цдо разные клиенты прочитают разные метрики и Если да то как вы с этим боретесь ну у нас поверх обоих цдо стоят как раз селекты которые занимаются дедупликация этих метрик и опять же поток метрик в оба цода у нас полностью зеркаль то есть там не консистентность не должно быть по большому сч из-за того что опять же они там читают из одних и тех же кафк один и тот же поток метрик и одинаковым путём записывается в оба цода Ну просто допустим там в одном цоде ро упал и потерял все метрики остались VM Select Когда будет выполнять свой запрос он ну просто эти дырки затянет тем что осталось в другом цоде даже если там в двух цода Ну сначала в одном цоде там сторедж упал потерял полностью метрики Хотя для этого в принципе физически должен диск под ним рассыпаться а потом через какое-то время в другом цоде другой сторедж упал то даже в этом случае у нас дырок не останется плюс опять же если там редж упал и а мы не знаю вовремя это заметили как бы можно перезапустить запись из Кафки с самого начала из того что хранится у нас там где-то часа три-четыре хранится и тоже Дописать эти метрики Спасибо Спасибо будьте добры ребята Привет Спасибо большое за доклад компании чуть побольше Сбер А вопрос Следующий Правильно ли я понял Прости пожалуйста надо перпендикулярно лицу раз раз супер а Скажите пожалуйста Я правильно понял Что дзш используют Victory Matrix для экземпляров инфраструктурных продуктов и соответственно есть дашборды кастомные алерты Это первый вопрос и могут ли они использовать свои систе мониторинга и пушить вам и второй вопрос а Ели у вас дшд то есть грубо говоря смотрите ли вы за всем периметром своей экосистемы Спасибо смотри у многих начальных компаний действительно есть какие-то свои средства мониторинга которыми они пользуются мы настаиваем только на том чтобы они дублировали эти данные в наше централизованное хранилище то есть обычно процесс выглядит так они начинают дублировать данные убеждаются что там централизованное хранилище им подходит Да что они там могут этим пользоваться им удобно и после этого там своий системы мониторинга отключают мы на самом деле на этом не настаиваем мы делаем некий зонтик Да вот стягиваем все данные в одну точку а касательно второго вопроса Да у нас есть Даши ими пользуются Вот то подразделение про которое рассказывал mcc Mission Control Cent - это люди ответственные за эскалацию э роутинг различных проблем в экосистеме у них реально есть такой верхнеуровневый дашборд который показывает здоровье всех продуктов такая здоровенная плитка да такие огоньки красно-зелёный в них там можно провалиться и уже более подробно понять А с каким именно бизнес-процессов у этого продукта проблем вот так что да это отслеживается Ну естественно есть мониторинг этого здоровья то есть не обязательно глазами смотреть Да всё это превратится в инцидент Спасибо Давайте потестить Максим Семёнов интересуется Как вы храните данные В3 вроде бы такой штатной возможности нет плюс нет ли возможности хранить часть метрик дольше чем ГОИ Ду добавить слайды PS3 в мою презентацию но к сожалению она никак не Укладывала в тайминг Миш расскажешь Ну да штатной возможности такой нет хоть и все очень ждут этого от Виктории Мы в итоге пришли к тому что раз в месяц то есть у нас написан написано несколько дагов для airflow раз в месяц запускается экспорт Рик за прошлый месяц из Виктории всё это у нас там пережимает в брот складируют в S3 Это первый этап но соответственно запросы по этим Метрика гонять нельзя Это просто по большому счёту эп После этого у нас на отдельной виртуалке поднимается VM Stage куда мы заливаем метрики Ну собственно которые скачали То есть у нас получается Stage в котором хранится строго оди месяц со всеми индексами и там ну дата фол Виктории Вот и потом уже получившиеся э складываем в S3 и монтируем это через S3 фьюз потому что больше никаких вариантов адекватных нету Вот но в целом это достаточно хорошо работает И самое главное у нас ну ротацию данных можно проводить просто удаляя из Бакета S3 вот этот один месяц Ну либо там в какое-нибудь более холодное хранилище его переносить и в том числе там был вопрос про больше чем 1 год Ну опять же тут зависит от того насколько резиновый S3 тут можно хранить в принципе и вечно С таким подходом А и опять же из этих сторедж мы читаем с помощью всё того же ВМ селекта который просто помимо наших основных кластеров читает ещё из из всех этих Ред друзья значит по времени мы сейчас успеем задать вопрос Раз и два У кого в микрофоны остальное пожалуйста в дискуссионной зоне но после вопросов надо два сувенира отдать за лучшие вопросы пожалуйста Да здравствуйте Максим Семёнов Это я был там был мой вопрос хитрец Так нечестно Давай в дополнение Да давай наверняка чтение с этого S3 очень долгое и практически Ну не знаю На грани невозможного не смотрели ли в сторону собственного дарования кото Stage Вика поверх Вики которая будет хранить не такую разрядность а там не знаю часовую или минутную сам хранить там за год за два за три тут самый главный вопрос именно поиска данных по индексам до обращения к данным А тут Ну даже при даунс плива большого выигрыша мы не получим можно даунс плива вообще без проблем при Вот именно перекладки из S3 в вот в этот storage который мы запустили чтобы потом переложить там можно на нём выставить семплинг хоть 5 минут и они будут спли но честно говоря по экспериментировали смысла особого не увидели и по скорости чтения опять же там у нас вот этот он ещё потом поверх него запускается Ну вернее в нём запускается Force То есть у нас по большому счёту получается там за один месяц что-то порядка 30 файлов общим объёмом под 8 ТБ и Ну в принципе S3 нормально читает из Больших файлов есть Опя жеже и может прочитать только нужный кусок этого файла Ну как файла Спасибо Это приятно Да когда тебя спрашивают про какую-то А ты е уже или какой-то инструмент А ты е уже пробовал Здравствуйте смотрите Вы рассказали про метрики где это а вот отлично пожалуй Здравствуйте расказа протри Во почему вы сразу не Пошли в отель и второй вопрос Вот вы вскользь очень рассказали про контейнеризации Как вы контролируете деплоймент всех проектов как туда насаждать сайт кары агенты Ну разработчиков Много Они пишут каждый сам со своими библиотеками давайте я отвечу на первый вопрос мне кажется расказать про все три типа телеметрии в одном докладе на 30 минут практически невозможно про распределён ную трассировку рассказывал на предыдущих хайдах очень подробно можно послушать прологи надеюсь тоже в каком-нибудь ближайшем будущем рассказать вот а вторую часть вопроса я оставлю тебе нужно повторить Да там там уже микрофон Да там спикер из сбера спросил почему вы думаете что вы сможете нормальный банк построить да да Повтори пожалуйста вторую часть основной вопрос-то в первом был Почему вы пошли в Прометея не в отель не формат телеметрии а второй вопрос Вы сказали про виртуализацию но не рассказали как в контейнеризации вы контролируете отправку данных вы используете сайт кары используете агенты Ну то есть как вы гарантируете то что от определённого проекта в кубернетес вы будете получать данные в том формате в котором вы там регламентировали ну почему мы не пошли в отель на момент вот когда всё это у нас начиналось даже сам протокол ещё стабилизированная команды в принципе занялись отправкой телеметрии через отель коллектор и тоже столкнулись с определёнными проблемами в частности Он не умел трать метрики при отправке есть если попытался отправить и получил там 503 ошибку или что угодно он просто дропа этот кусок он не пытался повторно их отправить вот а второе насчёт контроля сборки Рикс Ну с кубера опять же у нас есть инфраструктурная команда которая за кубее кластера отвечает у них есть уже готовые конфиги и они своими ВМ агентами собственно со своих кластеров всё что им собирают для продуктовых команд которые Ну в интересах которых запущены эти кластера опять же есть инструкции по тому как это всё правильно собирать Ну а контролировать опять же по большому счёту Наверное это введение самой команды отслеживать Живой ли у них ВМ Агент и нет ли на нём ошибок пока что может быть в будущем что-то изменится в этом конференцию нормальные спикеры нормальные люди задают вопросы сейчас надо нормально раздать призы значит вспоминайте чей вопрос был максимально полезен для сообщества вместе с ответом не знаю мне понравился вопрос про S3 Вот это матрёшка Вот это матрёшка прям сразу про кото говори тоже понравился номы не можем одному человеку два и второй второй сувенир кому подарим за второй вопрос Какой рукой все все кто спрашивали махни рукой пожалуйста вот так легче предлагаю последний про отлично последний во Проша Придите пожалуйста за Да Придите за за сувениром пожалуйста И тебе тоже ребята Спасибо Это был кстати мастер-класс как провести сессию вопросов и ответов если не хоче на все вопрос отвечать Он сувениры от Хайда и Аплодисменты спасибо спасибо Мы продолжим здесь"
}