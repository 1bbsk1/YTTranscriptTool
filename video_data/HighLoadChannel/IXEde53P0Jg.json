{
  "video_id": "IXEde53P0Jg",
  "channel": "HighLoadChannel",
  "title": "Авторы в Дзене и как мы ищем их аудиторию / Анастасия Павловская (Дзен)",
  "views": 382,
  "duration": 1964,
  "published": "2023-04-28T06:19:52-07:00",
  "text": "Привет Меня зовут Настя вот если в первые пять минут свое выступление я не умру от волнения то я расскажу вам про то как мы ищем аудиторию для авторов дзене Ну давайте начнем с того что я просто расскажу кто я такая и как я дошла до такой жизни вот два года назад я закончила шатт и пошла Устроилась в Дзен чтобы делать рекомендательную систему Вот все это время я занималась счастьем авторов так называемых то есть тем как авторы представлены в ранжирующей системе Вот и вся эта деятельность выросла в такой большой трек под названием рост авторов вот которые я И лидирую в данный момент Давайте немного что это такое Zen это рекомендательная Лента в которой мы пользователи предлагаем ленту из разных материалов значит материалы могут быть разных форматов во-первых какие-то длинные статьи это короткие заметки это длинные видео это короткие вертикальные видео всё это смешиваем в одну в один единый и отдаем пользователю вот весь наш питон сделан так чтобы удовлетворять вашим интересам вот Давайте немножко про цифры мы уже достаточно большой сервис у нас 20 миллионов человек которые посещают Дзен ежедневно и проводят они примерно 35-40 минут в нашей ленте вот если говорить про то что это означает для нас как для системы то это означает 10 тысяч РПС на саму рекомендательную систему 10 миллионов пользователей 5 миллионов документов которые мы ранжируем и 10 миллиардов событий в день которые мы используем для того чтобы обучать наши модели Вот кроме этого есть достаточно жесткое ограничение на время ответа всей нашей системы это 500 секунд есть и другая сторона может быть чуть менее очевидная цен это также и продукт для авторов это платформа на которой автор выпускают свои материалы находят аудиторию и зарабатывают Вот и их счастье Нам тоже нужно заниматься у нас уже примерно 140 тысяч активно пользующих авторов и каждый месяц нам приходит еще 60 тысяч новых маленьких авторов вот Казалось бы 140 тысяч уже есть 60 приходят каждый месяц Зачем нам целенаправленно их как-то развивать как-то им помогать вот здесь у нас есть некоторые цепочки рассуждений которые она такая достаточно очевидная но ее нужно проговорить чем больше подписчиков автора тем чаще он возвращается на платформу и тем больше уникального контента он там делает чем больше уникального контента на вашей платформе тем больше Спектр интересов пользователей Вы можете покрыть и тем больше новых пользователей к вам приходит Ну и таким образом аудитория сервиса растёт То есть получается такая ситуация с одной стороны мы помогаем авторам найти их лояльную аудиторию которая будет их читать смотреть с другой стороны для пользователя мы находим какое-то делаем какое-то интересное уникальный контент вот При всем этом ещё и наш сервис растёт Вот наши аналитики посчитали оценили тот то количество подписчиков которые необходимо в том чтобы он возвращался в продукт И мы поставили себе следующую цель нам нужно помогать новым авторам собирать N подписчиков вот если смотреть на ту цель вот как она есть то выполнить ее достаточно просто значит смотрите Берем каждую пачку рекомендаций пользователю подставляем туда докидываем какую-то рандомную публикацию маленького автора Ну и как бы у нас большая аудитория явно кто-то из них подпишется все супер но кажется это не то решение которое мы идём поэтому у нас есть первое ограничение важное У нас есть некоторые бюджет на просадку пользовательских метрик мы не можем ухудшить xperience пользователей хорошо однако это не единственные ограничения есть еще и второе нам нужно чтобы все рекомендации Наши были объяснимыми Что такое объяснение рекомендации вообще говорится что это ограничение в целом вселенную систему для нас она тоже действует Итак объясним рекомендации что это такое Это означает что на любое на любой карточке которую мы вам порекомендуем мы должны уметь написать Почему конкретно мы ее вам порекомендовали вот такому ограничению нам также нужно удовлетворять Окей зафиксировали Давайте как-нибудь поговорим немножко про то как будем измеряется цель мысль сформулировали следующий kpi нам нужно растить количество авторов с подписчиками как только мы получили Китай мы задумались Окей А что будет если вообще ничего не будем делать Какой процент кипяем мы выполним вот не то чтобы мы решили там не знаю два месяца посидеть и потом посмотреть сколько авторов вырастет нет мы просто прикинули вот и получилось что примерно 20 процентов kpi можно достичь вообще ничего не делаю ну понятно что такая ситуация нас Категорически не устраивала поэтому мы решили каким-то образом дорабатывать систему но чтобы дорабатывать нужно понимать что конкретно как вообще выглядит вся система а нет понимать нужно не это для начала нужно понимать почему это все не работает из коробки Ну действительно перед нами классическая проблема холодного старта Как это работает у больших авторов значит большой автор делает какую-то публикацию эта публикация в первую очередь показывается подписчикам и на этих подписчиках собирают некоторые статистику взаимодействия пользователей и этим of это помогает данному у данной публикации появляются фичи какая-то статистика которая дальше наша модель учитывает это Помогает этим публикациям так сказать в ранжировании то есть подниматься выше кажется большому количеству пользователей вот для маленьких авторов понятно что такую хорошую статистику найти очень сложно Ну давайте что с этим делать Вот и теперь чтобы что-то делать нужно понимать как вообще устроен в целом paypaline рекомендации хотелось бы конечно же на каждый Это runtime рекомендации хотелось бы на каждый запрос пользователя умеете трансжировать все пять миллионов публикаций которые у нас есть но кажется это будет очень сложно сделать поэтому есть два таких понятных этапа ранжирования Первая это отбор кандидатов когда мы отбираем Некоторые подмножество из тысячи документов и второе - это уже непосредственно ранжирование э Где у нас работает Модель которая предсказывает вероятность того что пользователю понравится данная публикации вот затем мы все эти публикации сортируем в порядке убывания этой вероятности берём некоторые топ и отдаём как финальную рекомендацию вот в первом приближении так Мы понимали что проблема где-то не так ранжирования Мы решили встроиться сразу за ранжированием как это можно сделать но смотрите вот после ранжирования все документы все публикации выглядят следующим образом они лежат в некотором списке которые отсортируем в порядке убывания скоро модели вот здесь у меня рыжим отмечены публикации маленьких авторов а все остальные синим Окей Что можно делать можно просто взять и какой-то топ из этой ранжированного списка отдать пользователю можно делать чуть-чуть хитрее например взять и выложить отдельно собрать список из публикаций маленьких авторов тоже отсортированный в порядке убывания скоро модели и отдельно положите остальные публикации дальше зафиксировать некоторый процент некоторую Вот он сколько процентов публикаций маленьких авторов должно быть в финальной пачке Ну Измерьте эти два списка в соответствующих пропорциях вот ну звучит нормально кажется решает нашу проблему Вот Но если бы действительно работала То наверное я бы не приехала на конференцию вот поэтому после того как мы запустили Ну попробовали такой подход мы увидели некоторые улучшения но оно было скорее криминальное вот Ну конечно нас такое не удовлетворила мы себе разбираться Почему так что не работает какое было наше ожидание на этапе ранжирования к нам должно было прийти какое-то множество публикаций маленьких авторов которые мы просто не понимали как ранжировать вот Однако оказалось что ситуация намного хуже и до этого этапа просто не доходят публикации таких авторов Ну что мы сразу поняли Окей надо браться за отбор кандидатов Давайте подумаем вообще как можно рекомендовать маленького автора вот единственная информация которая про него имеется когда он приходит в Дзен это его публикации их контент так как мы не можем никак положиться на статистику взаимодействия пользователя с аитимами нового автора то все что мы располагаем это контент его публикации также вспомним что у нас есть важные ограничения все наши рекомендации должны быть объяснимыми Вот и всё это нас приводит к так называемой этим схеме Давайте посмотрим Итак пользователь приходит за своей пачкой рекомендаций и первое что мы делаем Мы достаем из его истории все эти айтимы с которыми он позитивно повзаимодействовал под позитивным взаимодействием можно иметь вообще все что угодно давайте пока будем считать что это просто лайки вот приходит пользователь достаем эти позитивные взаимодействия я буду называть их позитивами к каждому позитиву находим список похожих публикаций все эти публикации будут кандидатами в нашем ранжировании которые мы отдадим дальше модели которые их каким-то образом поспорит Вот в этой схеме все классно один вопрос как сказать похоже публикации самый простой способ берем Все публикации переводим их в некоторый в некоторые вектора такие что если две публикации близки по контенту то и когда будут близки Вот и тогда для каждой публикации мы находим к ближайших соседей и говорим что вот они похожие публикации Однако если вы большой сервис такой как Дзен то возможно у вас много разных контактных и бензингов и вы можете сфотографировать модель Давайте немножко расскажу про него подробнее смотрите Берем значит пару публикаций говорим что ставим соответствие единицу если две публикации похожи на всем этом обучаем модель в нашем случае градиентный бустинг давайте немножко остановимся на признаках признаков У нас есть две разных группы Первое это статистики по контенту насколько две публикации похоже по темам например или насколько Они похожи по длине а вторая группа признаков это косинус между контентными векторами которых У нас очень много разных и все они получаются применением разных сетевых архитектур Вот про которые тоже достаточно долго можно рассказывать вот таким образом получаем некоторые модель и для каждого этима эту модель скорим с остальными получаем какие-то вероятность похожесть двух этимов и таким образом строим списки из похожих вот примеры некоторые того как это работает Например у нас есть публикация в которой есть обзор разных свитеров Вот и такая модель очень классно находят что раз тут есть свитера Значит возможно это про осень Вот она находится публикации в которых описаны подборки одежды на осень Вот и здесь очень хорошо заметно что нам не важно насколько старый этим То есть у него может вообще не быть не такое статистике взаимодействия с пользователями и мы всё равно найдём похожие вот есть другой пример значит здесь публикации про акции мы находим публикации про инвестирование вот все классно Единственная проблема что такая модель не работает есть некоторые сложности реализации Дело в том что если мы хотим спорить все возможные пары публикаций то это будет очень дорого и как по времени так и по памяти мы делаем этот Весь процесс оффлайн и затем отправляем его в runtime и если у нас скорость все все публикации которые ездят здание то по памяти это будет очень дорого вот поэтому мы делаем немножко более сложную схему мы Добавляем еще один уровень с Так называемым якорными давайте посмотрим получается что на каждый запрос У нас есть два этапа первый шаг мы для каждого позитива делаем переход в векторную публикацию а затем из якорной публикации уже строим списки похожих похожих вот как мы решаем нашу проблему получается таким образом множество айтимов это некоторые репрезентативное множество множество всех документов всех публикаций наших вот поэтому нам теперь нужно скоро дни каждую публикацию с каждой А некоторые подмножество со всей базой вот Однако Давайте тут остановимся и вспомним что основная задача ранжирования основная Метрика которая у нас есть это то сколько человек проводит времени в Ленте вот поэтому если мы применяем такую схему для решения основной задачи то нам нужно сделать так чтобы вот эти вот якорные эти мы покрывали как можно больше позитивов пользователей Вот и вот именно Здесь начинается некоторые сдвиг в популярные то есть якорными чаще становится популярна эти тьмы а для нашей задачи это прям как бы популярно этим очень сложно найти этим новых авторов остановились вспомнили что публикации от Новых маленьких авторов на самом деле не очень много и мы можем этим воспользоваться давайте откажемся от якорной схемы и просто для всех публикаций которые есть в дзене построим список из похожих публикаций маленьких этимов маленьких авторов и будем этим пользоваться положим это в Бабку отправим в продакшн и на каждый запрос пользователь теперь мы будем доставать все его позитивы ходить в эту матку из матки доставать похожие публикации маленьких авторов и отправляйте их дальше нашей модели вот тут есть понятная спецэффект что не для каждой для каждого позитива можно построить такой список похожих этим но на практике покрытие оказалось нормальным для нас поэтому мы такую схему и выкатили Да эта схема она дала нам небольшое преимущество то есть цена действительно помогла нам как-то приблизиться к Китаю Однако Она все еще была не так хороша как хотелось бы вот но мы сели думать дальше причем ситуация реально выглядела Примерно вот так потому что в этот момент в моей команде кроме меня было еще два человека и вот так вот сели придумывались Окей решили решили понять в чем проблема Проблема оказалась достаточно понятной У нас нет для каждого пользователя можно найти вот по прошлой схеме не для каждого пользователя можно найти публикации маленького автора Давайте придумывать еще какой-то способ отбора кандидатов вот мы задумались какая у нас есть информация еще про авторов и поняли что с помощью нашего прошлого механизма мы получаем некоторые статистику взаимодействия пользователей и публикаций маленьких новых авторов и мы можем как-то с агрегировать до автора и использовать вот так родилась так называемая сорта сорт схемы Давайте чуть-чуть про неё Итак нам приходит снова пользователь у него есть какие-то позитивы от позитива мы идем к автору от автора находим похожих на него маленьких авторов и с них отбираем самые свежие или самые популярные публикации вот дальше отправляем это снова в ранжирование Там модель как-то определяет Какое должен быть порядок между этими публикациями опять же Остается только один вопрос Ну как искать похожих авторов вот сейчас расскажу про самый простой способ это делать и познакомили вас с так называемым коэффициентом жакара смотрите у нас есть автор А и автор б Давайте определим коэффициент жакара как мощность пересечения аудитории этих двух авторов на мощность объединения аудитории вот аудитории можно иметь разные вещи ввиду давайте пока подписчиков вот оказалось что чем больше такой коэффициент тем больше два автора Если мы друг на друга Вот и я кажется такой способ определения похожести классно работает например вот здесь мы для автора который пишет про путешествия и разные гаджеты нашли автора у которого есть магазин умных устройств и другого обозревателя гаджетов классно значит еще один пример допустим у нас есть Автор который пишет про путешествия и к нему мы находим авторов которые пишут про автодома про пикапы это может быть не очень сейчас очевидно Но это подсвечивают один классный одно классную фичу коэффициента жакара а именно то что он может находить не просто авторов которые пишут на одну и ту же тему Ну и может как-то мочить похожие темы благодаря пользовательского фидбэку вот таким образом получается что мы берем всех авторов строим из них пары считаем коэффициент жакара и для каждого автора подбираем самых ближайших понятно что нам нужны некоторые пороги на этот коэффициент чтобы убирать релевантные пары для тех авторов которые плохо пересекаются здесь мы снова столкнулись С небольшой проблемой Давайте посмотрим на такой график здесь каждая точка Это автор при этом его координаты X это то сколько у него подписчиков А координаты Y получается следующим образом мы берем этого автора берем считаем коэффициент жакара для всех маленьких авторов с этим автором и выбираем максимальный Вот и здесь видна такая нюшительная тенденция что чем больше автор тем меньше коэффициент жакара Что означает для нас значит если мы подберем какие-то глобальные пороги то мы оставим все еще оставим достаточно много нерелевантных пар Поэтому в зависимости от размера автора нам нужно подбирать разные пороги вот сделав все это значит мы скрестили пальцы выкатились это в продакшн И в этот момент получили вот такую картинку вот достижение внутри меня был просто Убит в этот момент потому что нам не хватало совсем чуть-чуть тут еще нужно понимать важную штуку что был уже август нам нужно было Показать наш кипяк концу сентября И чем дальше чем больше времени проходит тем более мощный механизм нужно разрабатывать поэтому мы были в максимальной фрустрации в этот момент ну окей Сели смотреть какие есть проблемы у этого механизма которые мы уже разработали и нашли следующую проблему Давайте посмотрим снова на авторов а и б Пусть автор а пишет про походы автор б такой автор Барт Вот это большие авторы и мы видим что они нравятся примерно одной и той же аудитории хорошо рядом есть два других автора а штрих-баштрих они пока Маленькие но по тематике они такие же Ну то есть Похоже на наших А и Б И мы видим что коэффициент жакара между ними ультрама маленький Вот почему захотелось спросить оказалось что как раз тот влияет то что они маленькие и мы их показывали разные аудитории но и просто так получилось что их аудитория не смогла пересечься то есть Таким образом мы поняли что на коэффициент жакара понятным образом влияет то как мы раньше показывали данных авторов Хорошо давайте подумаем может быть есть какие-то другие способы найти похожих авторов и вот Один из таких мы нашли это такой контентный подход Давайте возьмем автора возьмем несколько последних его публикаций переведем эти публикации векторное пространство с другими получим вектор для автора тогда два близких автора это те у кого Чьи вектора близки по верхнему расстоянию у такого подхода Есть плюсы и минусы плюс например такие такой вектор и похожесть по таким тарам можно построить вообще для любых авторов у которых есть публикации Кроме этого для них вообще неважно Ну Насколько большой автор вот даже здесь видно на примере что очень маленьком автору можем найти автор побольше Кроме того на контентный подход не влияет то как мы показывали автора до этого Из минусов тут есть такой что таким способом мы можем найти авторов которые пишут только на одну и ту же тематику А вот если тематики схожие но они одинаковые то уже будет очень сложно найти таких авторов Давайте еще раз Немножко срезюмируем значит у жакара плюсы Какие явно используют пользовательский фидбэк То есть можно найти что-то новое интересное Чего нет контенте минусы зависит от рекомендации в прошлом от того как мы показывали автор до этого контент этого не зависит и также он его можно за контентной похожесть этого не зависит и также их можно применять для разного размера авторов Вот Но есть минус понятно что похоже не будет только авторы внутри одной темы Мы решили как-то объединить плюсы этих двух подходов и придумали следующую схему значит пусть у нас есть автор А который пишет про спорт и автор б который пишет про Спортивные тачки Они пока маленькие и жакара между ними супер маленькие Давайте найдем какой-то какого-то автора C который пересекается с автором бы и похож на автора а по тематике Вот чем больше C тем лучше потому что большие авторы пересекаются количество маленьких Ну вот такой какую-то схему мы и сделали Значит теперь у нас есть два этапа перехода первый переход мы делаем в автора похожего по контенту а второй переход уже в авторов похожих по жакару маленьких авторов Окей Какие еще есть способы генерировать пары а нет стопури расширенная схема как она работает что мы получили действительно работает очень классно Например у нас есть Автор который снимает видео про то как делать всякие миниатюрные вещи для кукол вот делаем переход по контенту получаем автора который делает Тоже видео про то как рисовать лучше рисовать Вот и третий переход уже по жакару мы находим издательство которое издает книги детей причем что интересно между первым и последним автором очень маленький коэффициент жакара просто Потому что первый очень маленький там 140 подписчиков Окей как еще можно строить пары кроме вот всех изложенных выше способов можно развивать Ну дальше идею с коллаборативной информации то есть тем как пользователи взаимодействуется с автором например взять матрицу пользователь автор и сделать ее с разложения либо можно дальше пользоваться контентной информацией и использовать тематику автора для поиска похожих вот когда мы реализовали новый способ генерации похожих пар похожих авторов вот мы просто выполнили Даже его переполнили Почему бы не сказано рады и в этот момент Знаете я уже так всё я расслабилась значит открыл шампанское начало искать себе билеты в отпуск Вот но ко мне пришёл этим Лид И сказала мне типа Здорово Очень классно вы большие Молодцы только пожалуйста можно мне больше не показывать вам ленте Вот И в этот момент я как-то Очень остро прочувствовала что нужно думать только об авторах но и ощущается пользова тоже не подумайте что мы не выполнили то ограничение которое мы до этого должны были выполнить на один процент просадки Метрика там все было хорошо но у нас вскрылась такая неприятная вещь в сорта сорс неприятный спецэффект схемы которые заключается в том что на каждый запрос пользователя мы находим отбираем плюс-минус одних и тех же авторов вот чтобы это полечить сделали две штуки во-первых используем разные позитивы пользователи на разные запросы вот во-вторых фильтруем авторов которых мы уже несколько раз показали но положительных взаимодействие с ними так и не случилось Вот вторая схема пока в эксперименте а первая даёт падение лайков среди дизлайков среди пользователей и это почти конец истории Но мы продолжаем заниматься развитием в сеть системы и прямо сейчас занимаемся следующей штукой мы уже умеем на каждый запрос пользователя набирать публикации маленьких авторов но все еще пока не понимаем в каком порядке нужно их отранжировать чтобы и показать пользователю тут Важно уточнение которое состоит в том что Наша задача очень сильно отличается от задачи от основной задачи ранжирования мы не можем переиспользовать модель This просто потому что основная задача состоит в том чтобы пользователи как можно больше увлечь и увеличить время его нахождение в Ленте а Наша задача подписать пользователя на авторы поэтому мы учим отдельно ранжирующую Модель которая предсказывает подписку и сейчас вот у нас в оффлайне в оффлайн замерам она бьёт продам Модель которая основного ранжирования Окей давайте чуть-чуть к выводам чему же Мы научились Ну во-первых мы поняли что если вы решается какую-то задачу которая отлично основной задачи ранжирования то не получится просто при использовать paypeline ранжирование Азиз нужно быть в каждой из частей каждым этапов что-то свое привносить во-вторых нужно думать про то какую сдачу вы решаете и частоте фичи которые не жгут в основном ранжировании например вот схема которую мы несколько раз пытались завести и которые не давала нам никакого большого профита в Наша задача она очень классно показала себя Ну и последнее нужно оценить все данные которые у вас есть и особенно сдачи холодного старта нужно пользоваться всей информации про автора которая у вас имеется Вот это всё спасибо Да ваши вопросы коллеги хорошо рассказала да Понятно все было так Спроси да спрошу собственно счастье пользователей в каких штуках измеряется но мы хотим чтобы пользователь мы считаем что используется интересно то он проводит много времени в Ленте вот поэтому мы смотрим то сколько пользователей сидят нашей ленте вот наша я тут Ладно вопрос просто легко справляетесь это муторно особенно не знаю там для viba например это не легко к сожалению легко Да порядок такой Окей там может быть вопрос Классно А можно я вопрос задам А у вас в качестве фичей использовались только документы пробовали вы использовать картинки вот эти на превьюшках в качестве использования все что угодно но тем более у нас видишь кроме статей у которых есть тексты У нас есть видео и для них будут свои фичи то есть типа мы пытаемся всё что угодно отсюда информация выжимать А вы пробовали оценивать сколько Как какие фичи дают больше прирост вот документы видео картинки если просто по отдельности взять Ну смотри вот тут надо понимать что есть как бы опять же два этапа вот во втором где основной ранжирование там больше всего роляют фичи которые связаны с тем как этим взаимодействуют как пользователь вместо данным айтимом то есть там все около противная информация вот а именно на этапе отбора Ну там да там больше всяких контент на фичи Но вот именно внутри них я не скажу сейчас Какие из них больше всего роляют Спасибо Привет Спасибо за доклад Вопрос такой как боретесь кликбейтом собственно новые авторы наверняка могут словно подстраиваться под ваш алгоритм тоже да это правда смотри тут как бы такое что у нас достаточно много маленьких авторов вот им нужно между собой и как-то выдерживает конкуренцию И на самом деле этап который я говорю который мы сейчас делаем он очень помогает как раз этим бороться потому что подписаться бесполезно Вот и мы как в ту сторону Да спасибо за доклад на дзене есть реклама Да используете ли вы информацию которую вы получили на основе того что смотрел пользователь для того чтобы как-то ранжировать и подбирать под него персонализированную рекламу Да Только не реклама попрошу просто публикации Да конечно используем этот как раз происходит уже на этапе когда модель работает то есть одни свечей как раз история пользователей на котором конечно тоже смотрим даже больше того вот когда мы учили формулу модель на подписку первая модель которую мы обучили она больше всего смотрела на фичи которые связаны с историей пользователя То есть она на самом деле научилась отличать тех пользователей которые подписываются тех пользователей которые не подписываются Вот Но мы ее подкрутили немножко поменяли только мы ранжируем в смысле лосс В этой модели и у нас всё там выровнялось и стали действительно в топе стали те фичи которые похожи на то что говорят подписки Здесь вопрос Да спасибо за доклад у меня такой вопрос вот Насколько я понял да у вас источник источник там по авторов находите вы даете контент А нет ли у вас проблем когда там пользователи заходят Да вообще новую автору он размещает контент вот этот контент надо как-то проскорить показать его вот с новым контентом и с новыми авторами у вас нет проблем вот чтобы правильно проспорить показать и чтобы если что типа не с точки зрения самого автора Сам новый контент новость новая статья Ну да Либо это может быть новый контент либо авторы Вот про статьи еще у нас был другой подход мы пытались на этапе ранжирования не обращать внимание на коллаборативные фичи а только пользоваться контентами конечно такая проблема есть вот там ещё Вопрос Настя Спасибо вопрос в области абы тестирования был ли у вас что-то особенное или вы использовали стандарты процесс об тестировать для вашей задачки это клевый Вопрос вот данная задача мы используем обычные методы тестирования вот а ну потому что как бы у нас здесь по факту Мы же пытаемся подписки растить вот на них достаточно удобно смотреть в обычном Б Но вот до этого большая задача именно с рекомендацией новых публикаций новых айтимов и там нам пришлось строить свою систему которая делит все публикации на две части и отдельно ну эти две части они крутятся на разных подгруппах пользователей вот там нам пришлось что-то менять здесь этого не нужно было не требовалось"
}