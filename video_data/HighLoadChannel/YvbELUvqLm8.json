{
  "video_id": "YvbELUvqLm8",
  "channel": "HighLoadChannel",
  "title": "MySQL orchestrator, ProxySQL – это продукты, которые вам нужны /А.Яковлев, Н.Шуляковский (Ситимобил)",
  "views": 2211,
  "duration": 3145,
  "published": "2021-10-04T02:47:02-07:00",
  "text": "всем привет как уже рассказывали мы сегодня будем вещать о маске ели о том как его использовать большом проекте как мы его использовали немножко о своем опыте вот и в принципе о том как можно с ним жить и управляться довольно успешно и сегодня вам ним расскажет александр яковлев экс-руководитель эксплуатацию сити мобила да друзья меня зовут александр я хотел бы вам представить николая он руководитель отдела архитектурных решений компании стима бил и мы вот расскажем историю вот вообще про москве или и немножко просите ma bell с темой была совсем недавно было 14 лет и на самом деле это проект город старше но не чуть чуть старше чем яндекс такси все начиналось с того что там было это один сервер на который мы крутилась и приложения и москве вот и поездок мала мала и потом все это развивалось собственно да все начиналось как всегда с одного сервера там была и плетей шины базу все это как-то крутилась но со временем аппетиты растут наш applications разрастается его становится все больше появляется новый инстанции добавляется крон скрипты все это бежит в ту самую базу данных вот база конечно уже начинает бороться за какие-то ресурсы за системные с applications мы принимаем решение о том что база уже надо вынести куда-то отдельно все это разрастается уже на несколько серверов вот вроде как проблему решили залечили все хорошо но в какой-то момент появляется рядом как всегда делал аналитики у них свои аналитические запросы энергетические запросы как правило довольно тяжелые вот а со временем базу разрастается данных становится больше эти запросы еще тяжелее становится база начинает подтормаживать поступать соответственно начинает страдать applications он начинает тормозить ровно потому что как бы база не успевает отвечать всем вот и в какой-то момент конечно приходится решать как-то кардинально этот вопрос можно конечно на стороне там программного продукта решать эти проблемы придумывать какие-то разные вещи там не знаю аналитику уносить куда-нибудь другую сторону появляются какие-то договоренности но это все тяжело она не масштабируемой и все эти договоренности рано или поздно ломается поэтому конечно в этом случае проще обратиться опять-таки к эксплуатации попросить а давайте мы решим эту проблему как-то более кардинально что у нас есть на данный момент да и самое главное очевидное что мы сделали мы но добавили своего в том-то и не их изначально не было мы поставили много слоев даже до сих пор помню их название почему-то аналитический слоев назывался dos вот мастер был дб-3 славы db4 и так далее и на какое-то время мы проблему залечили то есть вот мы разбросали из приложения запросы на мастер нас life сделали эту руками и там продукт работал до значит первое что после взрывов мы сделали это очевидно добавили ho проксимы поставил локально на веб-сервера чтобы ходить в слои вы к прокси мы там на гол x паузе добавили маленький sage скриптик который просто проверял отставание слогов и если он отставал больше чем на 10 секунд его х праксис своего балансировщик выкидывал но в этом же и скрип текке была логика что если у нас абсолютно все отстают но по каким-то причинам кто-то сделал там на мастере апдейт безлимита либо еще что то то ну абсолютно все выкинуть не надо вот это вот такая вот та рация наверное которая вот достаточно очевидная мастер участвовав х прокси вот а дальше уже начинается самое интересное ну собственно ну да в этой схеме мы уже пришли к чему-то более менее ожидаемому очевидному мы уже научились резервировать как-то слой вы слой вы всегда немножко более слабые поэтому они чаще выпадают за ними не так сильно следят их много ничего страшного у нас появился вопрос вроде бы как все хорошо вот но конечно в какой-то момент мастер он тоже как бы не вечный не резиновый и он иногда имеет место падать и конечно же тут можно опять таки на стороне программного продукта решать очень много всяких вещей например там писать своих коннекторах базовой в тебя iq еще в чем-то о том что если мастер упал можно выбрать какую-то реплику ходить в неё то есть наворачивать какую-то логику но к этому моменту как правило проект уже разрастается до очень больших масштабов там появляются разные языки разные фреймворке разные подходы то есть все абсолютно разные и реализовывать такую сложную логику в каждом продукте по отдельности это очень тяжело конечно же хочется опять таки решить как-то кардинальным вопрос резервирование мастера для того чтобы при вылете мастеру мы страдали недолго чтобы убрать всю ручную работу потому что выпадение мастера это как правило очень много человеческого факторы ручной работы с точки зрения эксплуатации это надо выбирать какой-то слоев на него переключаетесь як в этот момент свой вы где-то там отстают что-то разваливается и так далее хочется это все убрать и конечно же наверное отдел эксплуатации нам должен опять очень сильно помочь да значит вот когда у нас был один мастер он постоянно с ним что-то случалось то адаб таковские контроллер там повиснет а еще что-то и это был downtime мучительный владелец бизнеса был не согласен с этим и вот в этот момент нам попалась статья о продукте orchestrator этот статьи о том как разработчик этого продукта продукты внедрил его в компании booking.com потом он с этим продуктом ушел в git лап продукт написано гол наш разработчик павел паршина взял и стал дописывать по требованиям эксплуатации но по требованию которым мы говорили что вот они плохо было бы его еще дописать вот добавить вот это вот это павел даже это к метил в репозитории разработчику его и там они там переписывались до соответственно примерно так мы строили регистратор то есть теперь все наши слои вы мастера и все остальное не завернулись такой продукт регистратор который сумел бал нам возможность обеспечивать работоспособность мастера ну и там конечно же есть очевидные задачи в эксплуатации перед этим решением о которых сейчас а что же победы да значит под мастер мы изначально всегда выбирали самые лучшую машину из всех вот там мы съели машин то есть это мая сейчас эта машина с 8 млн грн вами и дисками который в софтом raider 10 значит требования которые нам пришло от бизнеса сделать так чтобы если там что-то у вас происходит с вашим мастером не бизнес продолжала работать то есть нам надо сделать за резервирование мастера мастер мастер репликации нам не подходит по определенным причинам но вот самая простая причина следующее вы сделали мастер мастер аппликацию через балансировщик то догоните запроса на изменение данных и у вас там одна транзакция улетела на один мастер 2 улетела на друга и вот в этот момент потом там репликация между ними упала и у вас уже одна транзакция там а другая там мачин например там заказ пришел в один мастера а оплата пришла другой уже все вот этот момент не собрать и это мы решили что мы не будем так делать и как и еще мы подумали о том что сразу бы если мы слив какой-то выбираем мастер то он должен изначально то он должен перестать выполнять функцию слова в этот момент иначе на него будет двойная нагрузка нагрузка нового мастера и нагрузка слова но это можно решить по разному мы просто сделали мы просто взяли точно такую же машину как мастер который у нас там находится как slave и она не используется она ждет словно своего час вот как выглядит регистратор вот как выглядит его внук об этом как как как он как его открытие дабы посмотреть вот вот его топология вот слева это мастер а справа колонкой славы правее счастлив от слова если нужно вот в этой топологии можно много чего посмотреть например насколько каждый слоев отстаёт версию приложения но в том плане же москве ли дальше если например у вас что-то происходит вы понимаете что вы хотите заменить мастер прямо сейчас он тормозит вам хочется другую машину сделать вот здесь можно просто нажать одну кнопку на любом слове сказать про molto мастер и там через минуту этот слой встанет уже мастером то есть вот достаточно визуальное хорошие сделано приложение с помощью которого можно управлять всем вашим кластерам переключилась да все приключения когда собственно вот дальше как как работает orchestrator он работает следующим образом мы он выбирает в какой-то момент нужный вам slave slave выбран по вашим приоритетом то есть вы можете сказать вот эта машина я всегда хочу чтобы она выбиралась приоритетом номер один вот эти могут выбираться следующим приоритетам если первая машина умерла а вот какие то там например бы копны аналитически еслы вы не должны быть выбрана никогда дальше происходит все очень просто все слои вы кроме нового мастера начинают к нему перри подключаться и вот происходит вот такая вот цепочка слов от слова вот в код в тот момент когда оркестр атор понимает что все стрелы перепад уже подключились к новому мастеру он просто убивает slave он убил простите он убивает первый мастер значит да ну и я хочу еще добавить что такая цепочка позволяет не только в нам в момент аварии быстро переключаться на новый мастер то есть выбирать слоев но иногда случается так что у нас подъезжает нам новое железо и вот потому что старая начинает там не знает тормозить или она просто устарела и так далее я регистратор дает возможность нам еще и прям в режиме нормальной наших там функционирования сервиса поставить новую железку на нее налить данные аккуратненько переключить мигрировать на новый мастер это все происходит полностью автоматически это очень удобно тут конечно надо сделать небольшое отступление на тему того как то устроено все на уровне сети потому что разные машинки там надо менять ее печники все остальное но об этом больше саши нам расскажет поведует да значит подводные камни которые сразу мы увидели когда читали о продукте первое продукта основан на так называемом года иди если вспомнить счетом времена 2005 года мы с келли 323 the replication было так называем на бинарном знали когда масть когда sleeve читал определенной определенные журналы и знал тут ту позицию которой он читает сейчас уже там смысле ли 55 наверное внедрили gta иди global transaction и идентификатор то есть у каждой каждая транзакция есть свой идентификатор и оркестра тарзана может но это достаточно просто получить мастера список всех транзакций из получится его со слова дальше есть функция selects об трек с помощью нее можно проверить насколько master и slave консистенции вот в тот момент когда репликатор регистратор будет перепад новый слоев делать крем мастером он конечно же вот на это может споткнуться и сказать что ни один из слоев который вы хотите сделать мастером не консистенции что то что делать значит какой слой выбрать я уже рассказал что можно выбирать по приоритетам еще есть такое понятие сплит brain перепад при переключении вот нам надо в мастер каким-то образом ходить но то есть славы мы ходим а там через к прокси round robin как ходить в мастер но у нас это сделано по так называемой virtual айпи адрес то есть во всех конфигах стоит веб-адрес и когда мастер уходит мы его убираем вот этот веб-адрес снимается с мастера на дом мастере он ставится альянс со мной интерфейс запускается команда or pink чтобы в или два сеть сказать о том что этот ай-пи-адрес тут и вот тут может возникнуть некий сплит brain мы вроде бы там подумали что айпи адрес убрали а на новом и на новом поставили будет чёрти что то есть вот этот момент надо учитывать там можно по можно старую машину выключать из на коммутаторе гасить порт то есть какие-то вот такие сплит brain и чтобы не получилось что нас и новый и старый мастер одновременно живые не должны повториться так и еще есть очень важное понятие называется грязное чтение дети у вид когда при пришел запрос на изменение данных на мастер он на слив попадет но там 0 5 секунды но может быть меньше вот вот это и есть грязное чтение то есть в тот момент когда пришла транзакция из плей фо мир мастер умер и мы сделали какой-то новый стрейф мастером то в этот момент мы не можем гарантировать что все транзакции которые пришли на мастера они есть уже на этом славе это действительно так даже в рамках одного дата-центра из задержки а уж что говорить о нескольких дата-центров 1 один из путь решение этой проблемы это площадь хранна я репликации в мы съели можно включить пола синхрон q работает оно следующим образом комет на мастере применяется только тогда когда один из слоев сказал что да я себе эту транзакцию внес в бинарный журнал но другой способ как обеспечить целостность данных и предотвратить грязное чтением я расскажу чуть позже как раз когда мы будем говорить о следующих продукте да ну и собственно нашей схеме уже вроде все хорошо мы научились переключать умерший мастеру на какой-то выбранный нами slave в которой доехали там все транзакции он не отстаёт он самый мощный выбран по приоритетам ну в общем все мне кажется прекрасно в этот момент конечного продукта возникает некоторый взрыв в голове и они такие у нас тут все супер отказоустойчивые мы умеем классно масштабироваться на аналитику прилетела куча запросов там давайте у нас у вас уже своя база вы тут делаете что-то такое прилетает кучу запросов на то что надо продукт улучшать этот продукт начинает расти как на дрожжах соответственно apple кечинов получается просто тонна приезжает новые языки и вот новые решения новые задачи и так далее и мы сталкиваемся с очередной проблемой дело в том что до мы действительно научились резервировать мастер делать его вернее отказоустойчивые мы научились поднимать реплики для того чтобы делить нашу нагрузку чтобы приложение могли там много много потоков ходить в решать разные задачи и так далее но внутри фреймворков ни в какой момент никто там не думает о том что когда мы поднимаем приложения будет ли это приложение ходить мастер или не будет об этом задумываться иногда даже опасно поэтому как правило каждое запущенный instance приложение он поднимает connect и к мастеру и к слову соответственно так как слоев у нас много а мастер всего один мы получаем жуткий дисбаланс по connection а между мастер базой и репликой это приводит к каким-то проблемам и связаны они с тем что каждое подключение к мастеру этот ритм с келли и когда этих клеток становится очень много ну например там скажем десятки тысяч машинки становится тяжело потому что про это тоже надо schedule и отдавать там контекст тому или иному приду и так далее и вот эти накладные расходы на выбор нужного трейда переключения вообще scheduling операционной системе он становится довольно трудно затратным по сравнению с тем сколько работает запрос и базы начинает невольно подтормаживать ровно из-за того что туда просто много коннектов не из-за того что нагрузка большая коннектов много и когда мы стали анализировать мы осознали что большинство этих коннектов они просто простаивают то есть приложение запускается но это какая-то новая задача которого самом делает выборки с например с какого-то из слоев влад а в мастер он так держит постольку поскольку а вдруг надо будет сходить мы ж не знаем пойдем и в мастер или нет и соответственно как бы становится вопрос что же делать да конечно можно сейчас сделать кучу соглашений с разработчиками рассказать что каждое приложение должно знать какую нагрузку она там платить на мастер какую на реплики расставлять какие-то баланс и держать пулы коннектов вот наворачивать кучу разные логике но это опять таки тяжело потому что к этому времени как я уже раньше замечал продукт разрастается уже до неимоверных масштабов там есть и разные языки и разные подходы разные дел и все это плохо связано вот как правило все работает чисто на каких-то договорённостях регламента всем остальном поэтому конечно тут опять таки хочется чтобы это была решена раз и навсегда и наверное лучшим местом для решения этой проблемы есть такие опять-таки отдел эксплуатации которого мы обратились за помощью и спросили что же мы будем делать у нас столько коннектов а надо как-то их мультиплексирование может мы как-то можем уменьшить это централизованным да с проблемой мы на самом деле столкнулись декабре девятнадцатого года когда перед новым годом все поехали никто не хотела ехать на корпоратив на своей машине и буквально там за один день это мои количество поездок стала в два раза большим экстренно доставили слоев экстренно доставили в бмв там включили их в дата-центре мгновенно но количество connect of на мастере уже зашкаливал 30-40 тысяч мастер бедный тормозит и не от запросов вот и мы пришли к такому продукту который называется праксис quelle достаточно интересный продукт сейчас уже у него вторая версия начиналось это с первой версии вот одна из и сам но одна из вещей которых вы не у него есть в коробке у этого продукта это так называемое мультиплексирование когда вы отдаете весь трафик между приложением и тем же самым мастером в proxy сквер а дальше прокси с кейсом знает что с ним делать вот но у вас все вот эти 30000 прилетели в праксис келли а между прокси и спилим и мастером держится гораздо меньше коннектор так называемые перри использование connect можно предположить происходит вот и вот эти 30-40 тысяч коннектов которые нам укладывали мастер который просто вот коннектор а де connect он висит и ничего не делает по именно но по причине которые назвал николай они ушли я немножко дальше покажу на слайде график того как это произошло там через один слайд вот но праксис кель в тот момент уже очень хорошо решил проблему тем что вот там буквально за один день и проблема ушла ну да собственно как бы наши теперь схема выглядит немножко иначе у нас перед походами в мастер появился практически ель он дал нам возможность уменьшать просто количество активных коннектов к мастеру мастера очень сильно стало легче перед репликами у нас есть к прокси который умеет следить за отставанием и реплики балансировать нагрузку между ними и выкидывать какие-то там негодные реплики чтобы у нас не появлялась там гонок и всего остального вот и очередное то что то тоже с чем нам предстояло бороться это с некоторыми вещами например те которые разработчики изобрели в момент когда у нас появлялись еще свои вы то есть дело в том что когда мы делили нагрузку между мастером и слой вам это делалось все на уровне программного кода то есть мы такие а это наверное чтение пойдем слоев а я вот это наверно запись пойдем в мастер и так далее и в этот момент все героически боролись какими-то продуктовыми задачами и так же героические сделали кучу гонок потому что запрос на insert ушел в мастер тут же следующий select пошел slave ослабив еще не успел получить этих данных айби дай печаль-тоска и дальше мы начали расставлять какие-то странные вещи костыли типа вот эти select и все равно мастеру идут ну и так далее то есть все героически боролись с этими гонками и об этом немножко тоже позже расскажем как это можно было сделать централизовано но в тот момент у нас еще не было просто такого ресурса и знание о том что это можно сделать иначе и не бороться с этими всеми проблемами значит про ту проблему которой я говорил с connect амина мастер вот все элементарно шло то есть это было и семь с половиной тысяч на мастер и больше в тот момент когда мы это график того как мы потихоньку начинали включать на каждом виде по прокси успели вот это самый последний момент да уже по пятам в попец отеле я сказал там нор скатиться на самый большой дата-центры вот это просто упала из 30 тысяч коннектов тысячу действительно праксис кель очень хорошо на спас да но как я и говорил это отличный продукт практически lumia гораздо больше чем просто уменьшать количество коннектов к нашему мастеру и вот действительно могучая вещи знать бы они чуть чуть пораньше можно было бы конечно архитектурно выстроить всё гораздо более интересной и правильном вот с точки зрения программного кода ну и собственно сейчас мы попробуем пройтись по типовым задачам которые стоят перед разработкой посмотрим как можно было бы это решить при помощи прокси из кель анин огораживания там касты ликов в коде собственно первая проблема которая которую я уже озвучивал это чтение из слова и запись мастер очень часто как бы случается так что мы пытаемся прочитать те данные которые до слоев не доехали и как я говорил можно конечно в коде расставлять костыли ки то есть говорит что я вот тут сразу же чтения после инсульта поэтому пойдем-ка в мастер а я вот это вот очень быстро у нас работает или вот эта очередь да летает быстрее чем еще что-то и так далее и это все обрастает очень-очень много вильяме условностями а это все всегда плохо это тяжело поддерживается это тяжело читается и в принципе как бы но такой подход он ни к чему хорошему не приводит конечно же у нас появился практически ели саша прибежал и говорит что практически ели умеет намного лучше и давайте посмотрим что же это такое и как с этим можно жить да вот у него одна из действительно классных особенности ридера из сплита на но еще раз повторю вот то что николай сказал что иногда нужно это на самом деле очень часто что-то за интер тити потом это же прочитать это действительно частая вещь мы пользователи зарегистрировали и теперь надо его авторизовать раньше в коде это вот было все с 1 машина с мастера когда там 14 лет назад мастер был один и это действительно все работал норов но в тот момент когда бизнес растет растет растет очевидное задание давайте все select уносить на слои вы и вот тут получилось мы с мастера to insert сделали авторизацию на мужество его прочитать а если стала iv отстает на что же делать вот праксис qu'elle может эту проблему решить полностью если вы доверите у грубо говоря ему весь трафик то есть весь трафик во все ваши базы будете кидать через него то во второй то есть несколько решений это ну я добавлю этой во первых это и 7 прокся который внутри себя может абсолютно все первое решение у него есть ну совсем лоб если вы может он там можно написать регулярку и все что начинается на со словом select будет кидаться на слои вы все остальное кидается на мастере но совсем очень простой то есть регулярное выражение написал все работу второе еще более очевидное решение поднимается два порта на праксис целях 1 порт для мастера 2 порта листва и вов но ну кажется что еще чего-то нужны и вот во второй версии разработчик праксис келли сделать сделал совсем интересную вещь начинают осмыслили 57 в тот момент когда вы делаете commit на мастере вы можете в ответ запросить так называемые gta идиот вам будет выдан вот как раз вот этот номер транзакции года и дисней и когда его прокси sperg себе вон туда вот вниз получит он будет знать о том от лидеров которые стоят на словах где уже и то есть он гад идей огс мы спели получил с мастера осла и вы ему сказали какие транзакции до них долетели все это сравнив он горит ага мы про этот слив номер один это то что надо он сын храним на нем уже есть эта транзакция но есть ограничение вот в этом это как раз такое ограничение что это будет отлично работать когда вы в одном к когда в одном у коннекте к прокси сквере сначала сделали insert а потом тут же делаете селе кто тогда прокси скелет работает безупречно потому что он в этом же коннекте поймет что ему надо получить уже с но не грязные данные и направит дальше есть второй способ как это сделать как только вы получили какой идиот вы можете этот гад идиот передать в виде комментариев праксис келли праксис кель когда вы видит этот комментарий он поймет от меня требуют чтобы я отправил запрос на slave на котором транзакции не старше вот этой вот и тогда вот здесь это как раз вот второй в тот второй пример котором я говорил как можно использовать использовать как можно избавиться от грязных данных 1 1 1 упомянула это полу синхронная репликация которая позволяет это сделать второй способ это как раз использование 7 прокси прописи сквере да собственно следующая проблема с которой обычно сталкиваются в момент там разработки проектирования это каширования запросов и их ответа да конечно база у нас умеет кэшировать все об этом знает и все таки ой как хорошо мы тут можем делать одинаковые запросы вот тяжелое не бояться там база уже все за кашира вала и все окей но это все очень быстро разбивается ровно в тот момент когда у нас появляется куча реплик дело в том что мы не абсолютно не понимаем в какую из реплику летит этот запрос и мы можем сделать два одинаковых запросы они уедут в разные базы и в разных базах придется выделять под это кэш каким-то образом это сохраняет вымывать что-то из этого каша то есть это накладные расходы для базы и это конечно очень сильное и напрягает и опять-таки есть несколько решение то есть одно решение да мы можем избавляться от этих запросов до тяжелых однотипных и следующих друг за другом но как правило для разработки это довольно тяжелая вещь потому что у нас могут быть примерно одинаковые запрос в разных частях продукта например там что-то работает асинхронной в очереди что-то работает синхронно прям с пользователем и прокидывать данные из одной системы в другую это довольно проблематично их надо где-то сохраняются каком-то пули то есть появляется уже свои какие-то огороженные каши и вот или это какие-то усложнения каких-то интерфейсов что поднятые ранее данные должны куда-то там передаться и так далее это все приносит какие-то проблемы и как правило разработки со стороны продукты и гораздо больше никто из продуктов не хочет мириться с тем что о я тут какой технические долл килевой вы тут нагородили какую-то странную систему с которой теперь героически боретесь поэтому раз уж мы пошли по этому пути и у нас другого выбора не было надо строить эту систему дальше и делать так чтобы нам не приходилось отчитываться о том что мы тут что-то плохо настроили и у праксис кель есть действительно это каширование и вот саша немножко поведает о нем кэширование ответов в птт ли вполне очевидное решение например но с точки зрения системы была получения список таксопарков то что там устаревает например но не каждый минуту добавляется таксопарке еще что то вот почему это нельзя доверить например мы успели мы съели умеет и такаши ровать есть и надо бы буфер пол сайт которому это все отлично каши руется но в нем это все лежит по всем таблицам по всему он начинает это там доставать это не так быстро работу это очень быстро работает но в праксис келли это еще будет быстрее работать потому что вы можете заказ и ровать только один запрос который дальше не пойдет ну а дальше да какая то вполне себе нежная составляющая на на примерно 10 слоев в city mobile стоит 60 в баф очень дорогие машины там куча на войне кучи памяти вы бы подешевле да и зачем ходить в слив куда-то далеко по сети если ты сходил в proxy скальпа 100 27001 и там вот уже получил ответ ну то есть вот вполне очевидное решение которым со всех сторон надо пользоваться очередная задача перед разработкой обычно встречается когда прибегает отдел информационную безопасность все разработчики и вовсе все любят информационную безопасность вы уж там иногда очень странные выбивающиеся из продукта задачи которые тоже растут где-то рядом и одна из таких задач как правило это логирование запросов дело в том что как правило в любом бизнесе есть часть данных которые являются очень критичными то есть их там нельзя чтоб кто-то слил чтобы кому-то их отдавать вот и так далее и отдел информационной безопасности рано или поздно приходит к разработке говорит а давайте-ка мы посмотрим кто вообще вот в за этими данными ходит то есть как правило если решать задачу в лоб это выливается в куче опять-таки условий то есть мы по всему коду бежим расставляем условии что если мы ходим за этими данными надо залакировать там кто ходил зачем ходил в каком объеме получил и так далее но у этого подхода есть огромнейший минус дело в том что этот человеческий фактор опять-таки и мы можем не найти какого-то запроса или там не отыскать или он появился уже позже того как мы это делали кто-то забыл о том что надо залакировать и вот когда в очередной раз приходит надел информационная безопасность и горит ой ребята у нас тут кажется кто то чет сливает давайте-ка мы проверим мы идем что-нибудь гриппа и понимаем что блин а вот это запросто мы не заблокировали его и это всегда больно потому что задним числом это сделать вообще никогда не возможно ну вот мы начинаем втыкать или эти блокирования и дальше начинается кучу вещей типа вот может они уже вышли я может и не сливает а может все равно сливает и так далее и это очень сильно напрягает поэтому мы имеем праксис кельмы знаем что все запросы бегают через него наверное есть велика вероятность того что можно сделать это на уровне практически ну да если мы доверили все праксис квелли все общение между приложением и базой то логично что мы его и попросим логирование логированием искали конечно же есть можно сказать с и general лака равно он и он начнет абсолютно все транзакции писать ну зачем нам все транзакции нас интересует что-то другое можно лакировать как-то в коде еще помню работаю в 2005 году саша горной библиотеку тебя и перловую пропатчил чтобы работа страх с деньгами с денежными таблицами записывалась на каждом виде там архивировать но прокси скелета все элементарно имеет на что он умеет логировать из писать от каждого юзера и это очень важно например если иногда бывает нужно чтобы аналитику или кому-то еще поработать именно не с боевыми данными не с какими-то нагини rename где там они но именно на genero нами а именно с боевыми вы даете доступ в proxy сквере заводите пользователя от этого пользователь пишите файл все транзакции потом это сохраняете у вас всегда есть ну увел он ваши данные или нет именно вот это незаменимый инструмент но и 2 как раз я сказал что в general логе будет абсолютно для всех таблиц все запросы мне нужно допустим логировать запросы которые будут с какой-то там биллинговой таблицы тоже справиться да собственно следующий запрос обычно к разработке приходит тогда когда у нас уже есть огромная система из ней наверное сталкиваются все потому что невозможно создать такие в тестовых стендов которые просто полностью воспроизведут всего то что у вас в продакшене находится и так или иначе вы сталкиваетесь с той проблемой что на тесте все потребители все вроде бы хорошо все работает быстро летает выкатили на пруд и нет давайте откатим соответственно как бы чтобы иметь возможность это тестировать раньше нам нужны какие-то там канарейки еще что ты и к этому всему не хочется учитывать же боевую базу ну то есть мы можем конечно что-то куда-то выкатить посмотреть как это заработает но если она будет ходить боевую базу и и это же ушатает это тоже плохо поэтому поднимается вопрос о том что нам надо еще и копию базы иметь чтобы тестить на реальных данных и так далее то есть это некоторый конкурс который доступа уже у разработчиков нет потому что там боевые данные но разработчик так или иначе уже может выкатить свой код и посмотреть как будет работать там аналитический запросы или какие то другие прям на объеме продакшена соответственно тут нужно дублировать как-то трафик можно конечно придумывать всякие разные решения на тему того какой мы трафик дублируем как нам сохранять консистентной между этими двумя стендами и так далее можно это делать все в коде но опять таки тяжело долго проблемы остаются все те же библиотек много программных продуктов новое решение много и так далее наверное это нам не подойдет в полной мере потому что она будет постоянно разъезжаться его от ну и есть еще одна проблемка это то что когда у нас появляется новый слоев как правило этот слайд с непрогретом не там кашами и всем остальным наверное это тоже надо уметь решайте конечно здесь прогрев кашей можно делать на программном уровне ну то есть когда мы понимаем что нас появляется новая база можно конечно за дублировать какую-то нагрузку нагреть каши на этой базе чтобы она подключает в бой уже было там прогретое не тупил а потому что с появлением новой машину вас всегда начинается перекос что вроде все работает хорошо а парочка запросов там подтупливает какое-то время вот и это тоже можно решать с точки зрения разработки то есть понимая что появился появилась новая база давайте за дублируем какую-то нагрузку сначала потом уже включим ее в прод но мы опять таки вспоминаем что у нас все запросы ходят через прокси иски и наверное обе эти задачи можно решить при помощи праксис кель вот и для этого конечно мы обращаемся опять в отдел эксплуатации с просьбой помогите да можно дублировать очевидно трафик на чтение на запись на чтение трафика интересно дублировать когда мы хотим прогреть как николай сказал a cash нового слова мой стиль конечно умеет например если у вас просто вы хотите ребутнуть москве лес записать конечно диска потом его поднять но мы говорим именно о новом слове чтобы потом не возиться с при с весами в к прокси что мы его включили надо потихоньку поднимать веса вот чтобы этого не делать мы туда просто все запросам начинаем дублировать прогрели кэш пустили в бой 2 очень классная особенность для этого она действительно вот так часто случается допустим приходит человек и говорит а я вот хочу нашим микро сервис перевести на мозг через 5-7 на 80 а зачем но мне колонны и колонны оконные функция нужны ну ладно давай а у тебя вообще приложение это адаптирована к восьмерки там лайки используешь или еще что-нибудь да не не точно все адаптирована давай проверим и мы берем instance 8 и туда опускаем трафик на рид и сразу послал агу мы понимаем ага да слушай но у тебя вот тут вот часть запросов то на 5-7 прекрасно работают быстро здорово под восьмерка то их и вы их не грех переписать вот действительно два рабочих момента которые так вот используется регулярно 2 это рай трафик когда например хочется в момент выкатки либо еще там какого-то stay ja получить на базу боевой трафик на на запись и его использовать для каких-то тестов это сделано в proxy сквере через очередь что дублирующий трафик попадает в очередь очередь там манап ее надо задавать по умолчанию на не очень большая и главное разработчик праксис келли говорит что вам не гарантирует что вот трафик на райт будет полностью доставлен это все зависит от того что вот насколько вы правильно это сделаете потому что у вас очередь переполнилась все часть запросов профайла поэтому с этим о чем надо быть внимательным и действительно правильно конфу гридь ну и последний слайд да ну и собственно очередная проблема которая обычно возникает там при проектировании при разработке разных систем это то что я упоминал уже то есть мы пишем какой-то софт мы изобретаем какие-то странные запросы еще что-то тестируем это сначала на своей там девелоперским на своем окружении на своей базе очки видим что вроде все хорошо прогнали с explain это же все замечательно потом загнали это на тестовый стенд с проданными данными посмотрели там тоже все хорошо все замечательно все это выезжает в бой оно какое-то время даже работает все хорошо все рады и счастливы но в какой-то момент с учетом того что данные в базу пополняется таблица разрастается индексы там перекашивает у нас появляется куча там грязные записи и всего остального возникает проблем и что мы успели начинает вдруг использовать не те индексу например ну потому что планировщик решил что так будет выгодней хотя было уже много докладов на тему того что не всегда планировщик выбирает там правильные индексы строит правильной плана и все остальное и вот в момент когда происходит эта проблема это там как правило инцидент в бою потому что все тормозит базе стало плохо ну то есть что можно сделать можно конечно прибежать программистом и сказать ваши запросы плохо стали работать вот лампочка думаете часы тем сделать они конечно будут долго думая делать наверное что-то сделают но у нас же как бы инцидент кто-то страдает надо решать быстро программисты говоришь надо быстро сделать что делает программист он берет выискивать эти запросы вставляет туда использование правые правильных индексов которые облегчат сейчас хотя бы работу базы для того чтобы нас там будущем было время для того чтобы уже планомерно оценить почему так произошло решить проблему распилить запрос переделать их и так далее но как правило такой подход это гарантия нескольких выката к может быть даже десятка вы каток подряд потому что программе заходит а вот это запрос раз поправил давайте накатим накатили все вроде этому запросу полетел там еще оказывается есть запросы он опять идет грех опять находится так далее это много итераций а это тяжело и в конце такого инцидента ты такой сидишь так сколько нос раскладок было если надо откатываться то куда вот где там и так далее и конечно это довольно такое проблемное место и она всегда появляется внезапно то есть нет каких-то решений которые бы говорили делаете вот так и у вас не будет этих проблем нет такие проблемы в большом проекте они возникают повсеместно всегда находится какой-то запрос который вы можете построить более правильно чем там планировщик мы с келли и так далее и мы опять вспоминаем что у нас же все запросы летят через прокси из кель и возможно в момент инцидента можно было бы эту проблему потушить как-то более правильно они разработчикам то есть разработчикам отдать проблему что да у вас вот эти запросы плохие с ними надо что то делать но самый инцидент раза вот например по-другому ну и конечно мы бежим к саше и говорим сашу давай подумаем как мы будем с этим жить и что можно сделать но на самом деле тут это возникает вот самый большой и самый лучший пример для данного слайда это если у нас запрос строится динамически и вот в этот запрос у нас только вот его итерацию вот варя вариации настолько много что ты говоришь разработчикам не надо вот чтоб ты поправил только вот этот вариант все остальные ты не трогай здесь вроде на и из яндекс не нужен а вот только в этом условии нужно он такой думать да ты что меня тут динамически запрос он строится на 10 экранов это сложные того шоке и я сделаю это сам и ты в proxy успели только для одного типа запросов добавляешь ему из яндекс это еще чем полезна например в тот момент когда представьте разработчика нету но он там летит в самолете это произошло ночью это произошло на корпоративе вас разбудил какая у вас вам позвонил какой-нибудь op je не сказала что время ответа вашего приложения выросла вы зашли нашли его в лоб и вот вы можете здесь и сейчас его поправить сами в explay нам посмотрели запрос так вот здесь вот надо только для этого запроса сделать yous embed вам не нужен никто вы сделали только для этого запроса сделали you send выглядели в праксис келли все полегчало вот вот такое последний слайд и по большому счету мы закончили мы рассказали о двух продуктах первый продукт продукт это регистратор для того чтобы зарезервировать мыс мастер мы с келли в случае его ухода второй продукт это ис-7 прокси праксис гель который может очень много и без которой действительно сложно сейчас зимой берете много кластеров мастерства и free application там в районе 5 машину в районе 50 и все это работает как раз благодаря благодаря оркестра тару все спасибо спасибо огромное будем рады если это кому-то поможет да спасибо большое так как обычно у нас вопрос задается таким образом что вы можете поднимать зале руки также приносим прощения у онлайн зрителей кажется выпекать во время первого доклада функция того чтобы задать вопрос не работала поэтому вы сможете пообщаться с ребятами в кулуарах после сессии вопросов и ответов давайте начнем мы как обычно мы вручать книжки за лучший вопрос так что вы тоже следите какой вопросам понравится больше всего здравствуйте александр о компании sky box спасибо за доклад у меня вот вопрос по схемке да мы поставили праксис келли все хорошо теперь у нас стоит вопрос как его собственно резерв сделать то есть если у нас один праксис гель упадет нам нужно иметь что-то резерв и пускать трафик через ним вот то есть надо перед про xix quelle опять поставить какие них а я говорил об этом праксис келли у вас стоит на вебе и вы локально ходите в него 100 27001 у вас web ушел у вас ушел именно праксис цель этого в небо я так понимаю что смысл практически он собирает эти запросы да и несколько запросов там составляет emerged и делает один да запрос меня количество connection нет не нет неправильно то есть нет она конечно правильно ну то есть смотрите на каждом вебе у нас много инстансов приложения и если пойти по пути когда твой маг своем вебе ставите один праксис кель у вас получается в мастер базу один connect с одной машины ну один максимум там 2 connect а потому что все коннекта из приложений идут свой локальный прокси риски ель и у вас connect не от каждого приложения от одного праксис келли на одном небе этого достаточно то есть у нас масштабы не такие большие то есть у нас там 80 левов еще чего то и это не десятки тысяч инстансов приложения поэтому практически ель ставится на выбор на каждом вами но даже если рассмотреть вот вашу идею то можно 24 их поставить это мука кону сделать отказоустойчивости а вот можно схемку показать где вас три практического была внизу давайте попробуем до пота и соответственно бен мол коридор до у нас передает позицию в какой-то праксис кричат который была запись наврать например базу и собственно это и тот же прокси искал имеет собственно это трагично и может сравнивать какой своих дошёл до этой позиции на этот своим собственно киназа проза а как вот этот собственные slim и через один прокси риску передаем на запись как на на остальные мы их на на остальных инстансов практической ли мы получаем а я это говорил что вот два пути если вы все это делаете в один connect вы вот этот практически или держите cotoons знает в какой ну какое масло выбрать а второй путь вы когда с мастера получили вот этот года идиот это ответ вы его все когда делаете другой connect и попадаете на любой другой проксей успел вы все лекции в комментарий передаете gt идиот практически любой другой поймал его и и он начнет по словам искать какой на каком же славе гарантированно этот эта транзакция уже выполнилась другой приложение на другом войдя на знает вот этот хищник увата можно организовывать разными способами да конечно если он надо соблюдать такую штуку туда вы это как-то передаете любыми способами но то есть если это скажем там платежная форма или еще какая-то форма вы это можете пробрасывать этот айдишник прямо через клиент ничего страшного в этом не будет в этом гадюшнике нет какой-то конфликт конфиденциальной информации которую нельзя было бы показать клиенту соответственно в момент когда вы сделали запрос на мастер сенсор там вы в ответ клиенту можете отдать этот gt идиот собственно следующий запрос этого клиента прилетит уже с этим gt идиот и не важно в какой прок сельский попадет вы его в комментарии добавляйте все работает понял почему и последний короткий вопрос у вас там было схемка где много слоев да и собственно да там база б д аналитиков она вас отдельно вынесены это просто очередной стоит ли это что то вы сами развешиваете очередной слив на котором может быть даже больше индексов чем на всех остальных ну на самом деле до изначально это sleeve какое-то просто со своим набором там индексов данных и всего остального в будущем это как правило разрастается в то что появляется репликаторы в другие базы то есть как правило эти данные реплицируются еще в какой-нибудь клик house там вдв худые жает еще куда-то и так далее потому что у аналитиков запросов иногда очень тяжелый и не обязательно он там мы съели это лучшее решение для них проще напилить какие-то продукты которые дадут возможность аналитиком работать правильно и и легко но у нас репликатор сделано в клик house и последними вопросик созрел вы сказали вас праксис криль стоит ну локально да на 1 колхас титана и тоже машинки а как вы вас наверняка есть micro сервисе да как в этом случае поступаете вас отдельный pods проксей skyrim который слушает или как у него я бы вы в этом же контейнер вы еще нет не отменено der praxis гель на одну железную машину на одну железным ого кубер не this или это у вас нету приложений к участку вернетесь этого нет понял спасибо еще вопрос много вопросов скажите пожалуйста лог запросов вы в адрес он формате используйте или в бинарном формате если бинарный то утилита для парсинга стандартная или что-то свое и она концов соли нет выгодные запрос делов-то манеру прокси иску или он не как мы ускорили вы доверяете раньше текстом он пишет своем бинарном формате мнения но там близко к текстовому то есть если мы говорим о логирование запросов правильно да конечно но даже в москве или логирование это план текста есть если мы включаем логированием с келли это будет плен текст и в праксис келью абсолютно тоже самое и не там либо джейсон вы можете включить во втором до или и в первом и во втором он может писать в свой бинарный формат который вы еще посинение джейсон"
}