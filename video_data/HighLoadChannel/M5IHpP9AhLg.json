{
  "video_id": "M5IHpP9AhLg",
  "channel": "HighLoadChannel",
  "title": "Раздача контента с HDD: быстро, увлекательно и надежно / Кирилл Шваков",
  "views": 1016,
  "duration": 2207,
  "published": "2022-03-21T13:56:53-07:00",
  "text": "привет меня зовут кирилл я был в компании сеть доставки контента нашу так мы video streaming форма это наша цифра только принимала поехали собственно что нужно до сеть доставки контента от канала связи в первую очередь надежного there are диски что беру и масть по канал связи сегодня говорить мы не будем вот он слишком много всего надежного все же статические the jinks тоже как бы диска рейд убегаешь . ишь как масштабируем собственно шестеро схема была мы работали с индексом массы диском все достичь классических у нас есть собственные клиент который мы видео показываем и что достаточно просто к нам приходит запрос мы генерируем код плеера и соответственно можем выбрать сервер конкретность которому будем раздавать контент и это хорошо работало хорошо масштабировал проблем особых не было но к нам пришли клиенты которые хотели только сидел вот они не хотели пользоваться другими нашими услугами и соответственно мы использовали их как origin а проблема в том казалось что заднем origin нам вернет за нашими очень сервер он сервером который раздает контент но стать ориджен а origin это может быть вполне себе цех то есть там целые кластеры и данных очень много а проблемы начались когда проблемы начались в нашей схеме когда мы достигли где-то 4 гигабит на сервер и мы в принципе упали мы упали ним и упала часть сети который раздавал ок антон пользователь там есть проблемы в чем собственно были проблемы которые у нас то есть это было очень много файлов это количество файлов на сервере застряла с миллиардами соответственно не работал ни как кэш открытых файлов то смотрящего открывали постоянно сочеталось с разных кусков диска то есть был супер удобно и и мы постоянно что-то писали постоянно что-то удаляли by cash который работал в принципе он ничего нам не помогал как работает ну вообще не было понятно и нам нужно было с этим что-то делать со 100 мы составили небольшой план то что мы хотим от сервера вообще потому что то есть у нас есть текущая система и есть некоторые требуют наши требование достаточно простые были то есть мы хотели хранить наш терой больше 100 терабайт данных мы хотели некоторую логику доступ к контенту это подписи время жизни лимит различные мы хотели больше метра чем у нас чем нам дает они джинкс и мы хотели еще дешевые логе дешевые в том плане что данных постоянно пишем странно много их тоже как хотелось ножки оптимизироваться а хранить больше информации о контенте который у нас есть мы хотели горизонтально масштабироваться потому что в один серым и в принципе не вылезали ну я имею ввиду что один сервер не мог хранить всю информацию какого то origin у клиента а и хотели это делать не очень дорого если не дорого и тут в любом случае жесткие диски обычные старые который крутится то есть никакого он есть везде там или что нет такого так как мы в принципе писали на гол у нас достаточно хорошая ну скажем сразу экспертиза в этом в бой с кнопку через коробки то есть искать пцр и countless там все это есть и есть то что низ коробки так как у нас но наверное все сервисы написано сейчас на год почти то у нас полностью выставим нормальный план по сборке оркестрацию мониторингу логом с этим проблема не было бы поняли что такой серо спасательным нужно а мы стали решать проблему с мелкими файлами то есть ну логичностью эту часть проблемы с мелкими файлами нужно от них избавиться то есть мы что сделали мы стали создавать на диске просто сразу же партиции несколько больших куда в них писали файлики вот то есть это просто большой файл то есть а на самом деле два два файла один файлик у нас был с метаданными который он хранит он фиксированного размера хранится там по большому счету это едешь к файла его смещение и признаки да лен не удалял ну там checksum еще и файл с данными файл с данными это куда мы пишем все и дополнительно пишем еще информацию в порто баффи о файле который нужно вот с мелким файлами факт принципе проблем и все решили мы очень много читаем много чего пишем то есть я уже говорил да и одно из того что мы сделали мы полностью отказались от 3 до что мы сделали так и вели еще два понятия у нас это быстрый диск и обычные диски быстрые диски создаст где-то индиски но тем не менее как напишем у нас мы создаем у нас есть общая очередь на запись который к нам приходит из каждым диском работает процесс отдельный вот одни процесса рутина и кто свободен соответственно пишет на диску получается достаточно равномерно и пишется хорошо мы понимаем 90 находит файлы нас есть некоторой оптимизация так что у нас очень много мелких файлов то все нормальные файлы мы сразу же пишем на hdd вот это файлики должны быть больше двухсот 25 мегабайт там нет с кину и так далее то есть некоторая эвристик а все остальное у нас пишется нас избе изначально а нос с бета дорого и не такое быстро рандомное и как нам хотелось бы потому что в принципе в нашей схеме когда у нас миллиардов мелких файлов на сосуде тоже обретаем некоторые проблемы учета плане очень нормальные файлы которые мы пишем на создать то есть это обычно мелкие части одного и того же файла то есть это фрагментированное видео этот тест этом либо там шум по 4 порезать на куски вот они как бы являлись причины сверкай рандомного и о быстро говорю поэтому пересыхает что мы делаем мы делаем мир то есть мы собираем статистику по файлам где они лежат на каком диске в каком файле не лежат и стараемся сделать последовательность файлов из него ослепить отдельный большой кусок то есть мы кто приходит колтер одном на порядки видео когда смотрят мы берем этот файлик и но по большому счету мы сортируем чтобы он был примерно похож на нормальный файл и потом от последовать из кусков пишем уже на hdd вот то есть мы перемещаем поэтому нас получается где-то 1 наверно в 10 снизили random area который был на дисках собственно как мы удаляем файл и потому что забыла проблемы с тем что когда работал anjing у него был процесс пушка шинга мелочь постоянно из каша что-то вымывал что тоже создавала некоторые нагрузку на диске этого 1 2 нации вот поэтому мы вообще не удаляем файл и вот у нас есть партиции как я уже говорил в файликах несколько на диске расположена и когда у нас партиции все закончились вот и без то больше нет мы просто в партиции ставим к богам на свет у него смещаем на начало и получается на перезаписываемые тут есть как бы две клевых штуки в том плане что мы это делаем это смещение у нас физически файлы остаются то есть мы их не теряем и вот мы продолжаем читать пока мы их не перетерли поэтому не получается такого что вы когда портится освобождаем нас там типа все сразу каша и становится вот с дисками вроде бы все более менее норм вот если есть вопросы можете их запомнить и потом спросим меня но файл еще нужно отдать вот потому что мы как бы даем видео наружу как бы нужно было что-то сделать упрощенная схема выглядит так есть интернет к нам приходит запрос то есть мы его через dns там как-то до нашего сервера давили и он его отдает мы используем ктп 11 сейчас очень хорошо подходит для отдачи видео в нашем случае и он очень простой вот так как он очень простой взяли написали свой веб сервер собственно мы прикрутили то что он сумеет работы с дисками и мы прикрутили веб-сервер что мы делаем так как мы не можем в один сервер вместить все данные одного региона клиента или там клиентов да они разные есть то мы данные сортируем то есть у нас запрос может пройти на любой из серверов edge в группе дат который мы мы его определили когда к нему приходит запрос мы строим ключ и понимаем на каком из серверу из серверов этот файлик должен был бы находиться и если он есть локально то мы его отдаем с локального диска который у нас есть если нет там этот запрос по xy равна другой сервер и отдаем клиенту вот как мы получаем доступ к файлу то есть у нас есть свой первый который принимает запрос и когда мы определили что тот файл нужно отдать мы сначала делаем лука по индексу то есть это примерно по времени ничего не занимается там считать мы читаем эту информацию и читаем уже потом data file индекс у нас хватит с памяти эта информация у нас поплина файл читаем просто обычным ридом сейчас потому что у нас есть некоторые проблемы с этим не попозже но собственно об этом сказали да что как бы у нас есть кэш объекта в памяти а да у нас еще есть дополнительно кэш объекта в памяти который мы строим у каждого ja то есть мы не сразу читаем с диск потому что это дорого как вылился где неважно у нас есть небольшой кэш-памяти около 30 гигабайт сейчас туда файлики как попадают они попадают туда просто расистом простейшую которая нас спасает от того что мы там смотрим какой форекс очень активный то есть у нас есть клиент при этом которые запускают рекламной кампании вот и трафик резко может там несколько сотен гигабит быть вот поэтому мы просто сразу вы классически помещаем у нас и они попадают туда еще мы считаем статистику то есть у нас много всего хранить спекался так уж получилось вот и мы с какое-то время у нас это у нас часть логика эджа вынесена на отдельный контроллер условно грамм живописи делает запрос там считает стата то есть штату себе он получает список ключей которые ему нужно было бы поместить память вот работать не настолько тоже хорошо как хотелось бы но тем не менее и того что у нас получилось то есть у нас сервер стандартной конфигурации сейчас это 32 гиг ядра 195мм памяти там плюс минус и два сетевых адаптеров ну то есть мы стараемся сейчас примерно так у нас есть как legacy что у нас достаточно много ssd потому что мы брали небольшим запасом то сейчас мы создадим самом деле очень мало используем вот то есть них идет дед 20 процентов чтения все остальное у нас считается и т.д. сервера разные по нагрузке то есть зависит от времени от клиентов всего остального но в общем то они выдают достаточно то есть мы иногда упирались в полтинник нож под катом фотографии полтинник их не очень интересно смотреть вот потому что но не просто в полку как бы сеть забита поэтому ничего не используем на диске нифига но не все так хорошо то есть как бы обычно не интересно слушать про то как у всех все хорошо хочется потока плохо вот мы тоже как бы в некоторые не очень хорошо попали говорил что нас очень хороший экспертиза в блог и мы стали писать на нем он нам местами подложил вот первая проблема которая как бы мы не то чтобы столкнулись когда она была немножко понятная но очевидно да как tps то есть сейчас благодаря всем весь трафик практически он шифруется до редко где уже можно встреть трафик который не шифруется и соответственно нужно брать без запросы и в бой есть встроенный tls вот у него очень клёвая pr и у нас очень хорошо устраивает потому что мы можем брелоки сертификатом на лету например даже да то есть нам долго останавливать сервер что приводит вот но он не очень быстрый мы стали смотреть что чем можно тир минировать вот получилось что очень хорошо терменируют ps трафика на стоит это heach это от varnish а вот он ничего не умеет кроме того терменировали л.с. и пихнуть его обратно там либо в тисе пи либо unix окита еще он умеет распределена кэшировать тика stuxnet вот но тут есть некоторая особенность опять же в года которая если смотря когда мы запросу между машинами проектируем мы на это не тратим очень много ресурсов ну то есть она есть конечно но условно говоря как докер у да только dos сетью работал раньше тату прокси вот там делается я копий если у нас два соединения то нет то там делаются splyce и просто то есть мы в user space не тащим данные практически да то есть там ну типа за рок-опера копи там есть ссылки в конце будут можно будет почитать но если у нас unix окита делаем классический лук среды в рай там их соединений то есть и просто качаем эти данные в user space это дорого и затратный как бы не очень быстро вот при этом недавно вышел по нас цель 3 и у него есть там kernal тестом и прочие штуки то есть скорее всего вот tls который будет еще он будет еще быстрее найдут попробую пересобрать его проблема номер два это garbage collector то есть vga есть горбач коллектора до сочи круто вот но мы изначально когда мы строили индекс мы естественно построили дерево чего там что-то придумать было как и данной стали приходить когда у нас было где-то наверное около 80 миллионов может или там 50 миллионов файлов на сервере у нас начало я у нас какая тепло вот и в общем цикл мы утратили в большинстве своем только на то что он просто делал garbage collector вот мы искали чувствуете можно сделать и к сожалению самое то что мы смогли за использовать обычный map вот мы съедаем больше памяти то есть мы за все вообще платим памятью но не и пспу мы не можем использовать достаточно памяти для кеша ну то есть потому что опять же у нас есть garbage collector и мы мелких объектов могут в память не можно втыкать как бы как мы не хотели потому что сразу начинается есть спу вот плюс из-за того чтобы в горе есть garbage collector то есть по дефолту мы тратим два раза больше памяти чем хотелось бы вот соответственно мы вымываем пэйдж и это тоже не очень хорошо потому что париж кошачьих достаточно клевая штука в линуксе плане того что он нам помогает . взгляд у нас нет директа и поэтому мы говоришь то пачкаешь хорош пока штука вот проблема номер 3 ст который мы столкнулись товары driving я уже говорил что у нас есть там часть логике вынесен на отдельный сервер а там с контроллерами которые там считают различную статистику и как бы когда мы это все дело задумывали было было как бы ну понятно то есть у тебя есть данные на основе данных мы можем что-то посчитать как бы более правильно спрогнозировать какой конечном нужен там в память еще что сделает а вот на деле оказалось что задача то хорошее но работает это все не настолько прекрасна и придумывать за пользователь что он сейчас будет смотреть как бы учитывая то что нужен от смотрел на первом видео не всегда хорошо получается мы сильно больше данных загружаем в память чем нужном то есть мы загружаем данные которые потом в принципе не используется это просто так так стоп вот у нас естественно накопились планы по этой все штуки то есть что мы ну то есть как бы уже сейчас понимаем их нужно переделать да то есть как говорила что у нас есть фаза мир же когда мы собираем файлики в одни кусками на основе статистики это все хорошо но нам нужно накопить достаточно большой промежуток времени чтоб понять сейчас что этот файлик можно склеить то есть мы обычно запускаем этот процесс раз несколько часов и это очень долго каком плане долго то есть во первых эти файлики могут там из а здесь закончится мы их обратно да там вытрем либо ещё что-то сделаем но самое главное что у нас получается достаточно большой объем который мы должны записать то есть мы сейчас делаем растягиваем его на час вот по времени а что данные которые нам нужно переместить будут писаться другом там шейпинг на ее вот что не будут писаться в течение часа но там всегда получается достаточно много и в это время диск сильно нагружен то есть мы видим прям потребление именно цпу по ожиданию с диска то есть если мы это сделаем немножко по-другому у нас есть понимание примерно как сделать то мы можем скидывать части быстрее вот ну опять же к тому что не писать данные на ssd a magic сразу же в куски их вот есть уже то есть мы можем фариг некоторых мелких нам приходят оставлять в памяти вот на какое-то время и сбрасывать их то есть склеивать ни один кусок писать оклеить их немножко побольше размерами вот мы в принципе тоже можем делать сейчас ну вернее еще не можем как мы будем делать план номер а вот так как у нас есть достаточно большие проблемы с директа и ладно то мыска мы не скорее всего то есть у нас джина гопала через как бы это в принципе получился такой пруд в концепт работает достаточно хорошо есть понимание как сделать очень хорошо вот соответственно у нас есть план разобраться с tls у нас есть планы на денег то ей вообще асинхронное и у linux нативный которой есть я минута мою ринг там и прочие прелести гораздо больше данных памяти потому что сейчас он в данных мало говорила что у нас 30 гигабайт отведенного на хранение в памяти ну по факту употребляем 60 и больше потому что он из год вот это изменение структуры хранения файлов как мы храним их на диске то есть там есть некоторые планы как это можно поменять как-то сделать видно лучше потому что у нас есть примерно год опытной эксплуатации вот этого сервиса продакшне и гораздо меньше ssd то есть мы сейчас понимаем что ssd которые у нас есть они в принципе практически их объем можно сократить там не на 1 5 легко скорее всего даже больше если мы сможем нормально работать памятью но для этого нам скорее всего потребуется поменять годы что-то другое процентов 99 это будет раст вот хочу сразу передавать перед лишь палачем вот что почитать то есть что что-то вынести дальше мы тут говорили то есть есть ссылки я скину куда-нибудь презентации у меня попросили сделать вот такую штуку вдруг то стразу захочет о чем можно почитать ну так вот там не все ссылки есть потому что не влезли но и вообще все все ссылки которые хотелось не влезу могу потом еще чуть рассказать вот ведут переговоры вот и есть очень хорошие на самом деле статья о а нету совсем нет ну ладно удалили уже вот есть очень хорошая статья у сциллы в блоге это там рассказывается как раз про доступа которая есть к файлам в linux . диском который они используют вот там очень хорошо описано это по-моему единственная нормальная статья где описана о том что как работает map да и какой там трейдов у него но в принципе мы даже решили его пунктом на своей шкуре тоже ощутили всю эту штуку вот там все все ок вот у много статей уклад flair потому что не очень много заниматься сетью и есть хорошая штука ватасук по пятому никогда по моему в кино услуг то есть это очень клёвая штука как раз для фиксирования так когда мы не занимаемся копированием юзер space нищего то есть в linux есть различные способы то есть классический это был сплошь да если для файлов и tencent файл то сейчас на основе там фильтров и бпф есть сок мод который реально true за рукой ну и просто сгиб потому что мы работаем с sd у нас их не так много на чтобы их победить нам пришлось достаточно много сделать всего почитать посмотреть и даже по консультироваться с различными людьми вот удалось поджаться кстати по времени вопросы давайте отлично спасибо очень здорово что у нас получилось немножечко поджаться давайте девушки давайте вот практически практически самого-самого начала нет сначала давайте попросим примем микрофончик да привет привет меня зовут максим лапшин собственном интересно смотреть как эволюционирует решение вашей компании потому что диск лет назад как раз рассказывали как от нашего софта выходили в пользу как раз рейда bp shot это все за tfs free bsd ну было интересно когда же это вы откажетесь хорошо отказались до фри без дома недавно последний потушили это очевидно да и теперь у вас то же самое что и было раздельных орды нас отсюда вопрос смотри когда мы как раз работали с вами еще возможно не был так вот выпивает компаниям уперлись такую штуку что hard это конечно хорошо но у него есть очень четкая эта способность и ты должен четко понимать что-то про следующий запрос уже может идти с него там никита миллисекунды а уже много вели секунд или секунды ну то есть все он уже в стал кол им и но при этом при этом например отправляющему один запрос от прогресс раза второй запрос на диск и они все еще быстро читаются и вот их можно там скажем 200 отправить то есть есть какое-то количество запросов которые можно отправить на хард чтобы он пришёл и ушёл печать вас на вопрос как вы сейчас с этим работаете то все это какая-то эвристик а просто вы руками знаете примерно сколько там кайт константа вколоть или ты уже динамически рассчитывайте сколько можно запросов а чтения отправить на диск чтобы она туда приехала и второй вопрос что вы с этим делаете потому что у вас была серьезная прайма с теплым контентом то который не горячее на и создай его не положишь нас но и не холодный внутри какая история то есть у нас действительно проблема сейчас это не то что вы проблема одной из особенностей которые мы используем да то есть но том что у нас сейчас сера действительно то в 100 плюс терабайт у нас процентов 70 это контент который смотрит каждый день ну то есть вот он в любом случае с то есть он может быть не горячий на его поднимут в любом случае вот и вот эти там 20 30 процентов которые иногда запрашивают то есть если мы сравним классическая когда там тонг-ашер на сутки до кашель точно вообще не работает например вот что мы сделали у нас просто есть друг адам сортируем данные поэтому нам мы можем объем вот этих данных держать которые ну достаточно долго который мы каширу им который мы не вытесняем вообще вот что касается чтение у нас нет никакой эвристики сейчас у нас есть просто промежуточный кэш которым хранить в памяти который в принцип отрабатывает запросы и у нас есть и нам от очень хорошо действительно помогает пэйдж я сюда график него тому например если мы говорим о жестком диске то жесткий диск в грубо гая может отдавать сколько там 200 мега 10 мегабайт даст где короче около но меньше гигабита да то есть там 800 это получается вот прям очень летный как бы день но из-за того что там поешь все остальное у нас получается там иногда других битва с него поднимаем и такая нагрузка действительно него идет а так как у нас мы файлики укладываем стараемся уложить на один и тот же диск ну то есть куски файла да получается то как машине диск снова тебя нагрузку вылетает на один из дисков по большому счёту который отдает он в принципе справляется а другие запросу уже ходят другим диск мы получается потому что файлики так разложили то есть редко когда бывает такое что тебя на одном диске оказалось сразу же много горящего контента на везет пока вот час нас спасибо большое за заряди везет так поднимите сразу вот здесь бы сейчас здесь вопрос и потом вот здесь будет мальчик вопрос секундочку а можно вот везет до какая-то логика есть раскладывании файлов . особым хитрым способом расскажу ну чтобы везло чтобы везло мы просто стараемся части одного файла положить на один диск и получается да что как бы в один момент не так много видео популярного бета хусейном привет александр и сбер тех и смотри я правильно понял что вот какие то мелкий файлик упаковывается в один большой у нас все файлы пора его пока вот в один большой до внимание вопрос размер этого большого файлы фиксирован дату он какой нет там там какая плотно размер фиксировано потому что мы их создаем когда я не этим диск и вот у нас создается другая протестует из двух файлов и там как угодно может назвать мы назвали против то есть первый файлик он вообще фиксированного размера то есть он никогда не меняется и там потому что все данные которые хранятся они эффективно размера то есть это int и достанет строк например да то есть мы не храним вот он там получается мегабайт 200 наверно да как мы там хотим эту информацию только и создается файл мы просто берем жесткий диск и делим его на 50 чувстве нас копоть вот это кстати тоже ошибка была вот мы делим его на 50 частей и одинаковых и вот они лежат то есть один файл там сколько ты понял то есть грубо говоря то есть нет такого чтобы этот определенный тип файлов вот этот вот общий файл вот определенного размера то есть вот она у нас примерно той темы который я занимаюсь тоже мелкие файлики хранятся в крупных файликах вот экспериментальным путем у нас просто даже крупных кроликов очень много у нас там их несколько миллионов как бы и нам будет нужно хранить как то есть мелкие мелкие той миллиарды как бы большие это миллионы как будто то есть так как видео то на весь этому стендом гигабайт да там ну к примеру ролики там среднем можно меньше кто-то больше на серве плюс 100 терабайт поэтому там всегда файлов мода вот поэтому не разделяем какой файл на большой маленький то есть мы единственно что делаем эти мелкие файлы сейчас пишем на сидит тут а что если мы вписали на хдд то вот этот супер рандомный aion простых убивает то есть получается что мы если так вот мы можем кое-что нам везет ему там до двух гигабит читаем с диска хотя так нереальный цифр то есть мы там читаем спичка шанс самом деле вот но мы уходим в disk to success рандомным моё самых просто раскидаем не будем их именно к сортировать правильно склеивает не фишка не в том чтобы файл положить а именно порядок сохранить вот то мы с дисков женщина может читать то есть у нас умирают за шутки спасибо так и вот и молодой человек из той стороны еще будет вот потом вы будете да хорошо роста лексей timeweb у меня два вопроса первый вы написали самописные программное обеспечения для чтения для кипятите не то есть да вот о чем не устроил он жениться уперлись в то что не хватило функционала или может быть производительность вы достаточно было но на самом деле у нас проблема была с джеймсом не столько с индексом а именно сохранением на файлов на диске дает нужно было обеспечить нужен зубы какой-то доступ это первое 2 нас в джинсе была некоторая логика что-то мы там запихнули в аусле квест что там еще куда-то запихнули матроса сильно вверх и дела и написать свое решение грубо говоря уже была штука которая умеет с диском работать вот этот раскидывать да и привернуть к ней ттп было не сильно сложность вот и мы наивно полагали в свое время что мы вообще не будем использовать ничего сверху как бы и кошки tls справится но и к башне tls не вынес не вытащил наш трафик то есть вы не могли такое количество мы на 20 процентов примерно теряли количество таких которые можем служить машину и второй вопрос как и какие файлы система вы используете какие рейды на секс 4 райда нет вообще а cпасибо и вот та сторона как конца зала пожалуйста будет вы спасибо большое за так вот спасибо за упоминание того что вам везет и то что на самом деле есть косяки это прям великая вещь на докладах собственно пас вам везет есть вообще понимание и какая-то статистика у вас во первых как часто везет а как часто не везет и насколько всех уже в тех ситуациях когда не везет вы полностью ложитесь или там но мы какую-то работоспособны полностью не ложимся мы полностью можем не отвечать если у нас забьются канал и вот у нас ни один сервер вот у нас их много поэтому у нас мы ложимся полностью да то есть у нас бывает что клиент может действительно выживать полосу например на g на каком-то на группе j да то есть мы обычно делаем в этом случае если мы видим мы можем отключить для клиента что у него данные she родированное если не данных малым пост раздаём в каждой машины и все ну то есть так это обходится по статистике чего именно когда она мне везёт но сейчас пока хорошо везет я не знаю у нас нет такой статистики в рим невезение у нас это зависит от большим на самом деле то насколько хорошо мы читаем зависит от того сколько много в этот момент мы пишем потому что из диска ты можешь очень быстро и хорошо читать но так же быстро и писать на него ты сейчас не можешь до особенно ну в текущей этом варианте который у нас есть вот поэтому смотрим сторону синхронный нативной она нам даст мне который профит вот в литературе г до 60 процентов вот а на деле посмотрим вот и соответственно каток у нас начинается процесс записи мы немножко медленно начинаем отдавать но нас это устраивает потому что the latent сейчас которые у нас есть она все равно лучше чем она была эту мог так пасибо большое и вот здесь нет вопрос такие луни ещё такой вопрос вы вы упомянули что хотите заменить gonna раз можете поподробнее раскрыть этот вопрос то есть чем именно раз вам понравился вы проводили какие-то работы или может быть вы хотите быть ближе к железу или у вас там какие то на самом деле мы с языками мы их как бы нет если сравнивать как инструмент например да для того чтобы писать повседневные задачи на горе нарасти я выберу go ну потому что потому что как бы все видели раст вот и это сложно это больно как бы и ну в том плане что там гораздо больше нужно там даже не думать дам больше доставляет тебе неприятности чем год точно будет написано работает вот с раз там так быстро обычно не получается почему выбрали его нам нужна память то есть нам в любом случае инструмент которым будем свойство не должно быть garbage collector и всего остального и у него должна быть возможность работать с синхронным и о как таковым в россии сейчас есть с июля а ей ринг вот он поддержка для tcp для файлов как бы и вот смотрим винница но мы на самом деле пробовали бенин гиампа на социальное но из за того что у нас очень много конкурентных запросов у нас получается даже например там опыта состоит который за бензин до как бы и у него там в на гитхабе лежит там хороший башмак он работает не лучше чем обычно башни то есть мы тратим на это много ресурс нас тискала там же получается отдельный потому не процессов отдельный поток как бы есть в которых сегодня с ним ты обмениваешься а так как у нас много конкретных запросов много трафика как поэтому там не очень вот ну и если бы напишем на самом деле мы перепишем работу с дисками на 1 и все остальное то как бы прикрутить туда ттп отдачи это не так сложно к этому точно смажь спасибо большое и вот последний вопросик у нас сейчас будет привет меня зовут алексей и национальность ему платежных карт единство вопрос который возник еще на который не ответили это по поводу flower а соответственно если выпадают жесткие диски ваз и как понимаю sharding работают до какой-то самописный sharding или это что-то но дата самописный шарик мы используем просто кита муки там в плане и в плане того чтобы выбрать какой сервер мы сейчас хотим вот и если там сломался жесткий диск то у нас просто кэш мест вот деградация как если диск выплату деградации если если повезло то нет если там доныне еще да а если не повезло если не повезло да что на этом диске действительно есть какие то данные их много теплых да там или какие-то горячих которые сейчас нужно с горящими просто их они большое количество моих заряженный выпуск как бы забрали как бы вот они уже даются других диска все-таки а если там много данных нужен то есть у нас когда мы потеряем жесткий диск у нас может очень сильно возрасти запись вот в этом получается деградация но ты мне всегда плюс у нас есть некоторая деградация когда например у нас выпадает сервер вот и до некоторого момента мы еще как мы пытаемся коннекте то есть как бы но тони недолго как бы все порой коротенький вопрос ты сказал что вы всех мелки файл объединяем если происходит перезапись помеченных на удаление файлов соответственно фрагментацию есть такая проблема мы не вижу - ну то есть мы еще не видим мы периодически смотрим то что нас нет метриками специально снимаем но когда мы на сервис залезаем на досмотр ну то есть мы не все мониторим да то есть поэтому вы смотрели на самом деле потому что было интересно как бы и в датской будем давать ему спасибо спасибо за вопросы и давайте поблагодарим кирилла за выступление а сего им большое и мы вручаем подарок от конференции и кирилл ты не уходи со сцены хоть какой-то успеешь ещё какой-то вопрос тебе прям понравился найму поблагодарим кого выберем кого кого-нибудь один вопрос в зале которые больше всего запала в душу как всегда последние вот всегда последний небольшой презент еще раз бабло делаем и вы знаете мы сейчас мы заканчиваем с кириллом потому что кирилл сейчас выйдет конечно водички пойдет дискуссионную зону"
}