{
  "video_id": "zLmb6xgsAm0",
  "channel": "HighLoadChannel",
  "title": "Как построить высоконагруженное и отказоустойчивое S3-хранилище / Дмитрий Анисов",
  "views": 7217,
  "duration": 2990,
  "published": "2022-03-21T12:55:00-07:00",
  "text": "всем привет приветствуем надеюсь у всех еще не силы слушать так сказать и давайте немножко соберемся и напоследок поработаем сегодня хочу рассказать как построить однако нагруженный отказоустойчивые стреха не лечи и мы начнем с практически самых основ давайте немного обо мне и я являюсь ведущим богат разработчиков компании джесс labs моя команда разрабатывает на данный момент новости pingu платформу для триколор а который в будущем будет так же поддаваться на горизонте в целом наша компания занимается разработкой для цифрового тв и у нас много клиентов в том числе и триколор а сны языки разработки это python go также им пишу немножко нарасти есть ножка сие ну и прочий стык конечно же я обожаю drops администрирование в частности доклад сегодня будет немножко и об этом если кому интересно у нас все купюры докер себя и сиди и вот это все думаю остановится на этом не стоит контактная информация представлена слайде кто захочет пообщаться я буду рад отвечу всем давайте же начнем наш доклад и первое на что стоит обратить внимание это какие системы хранения данных и сходи на данный момент у нас существуют для построения стри кластера это cf меню see with office и впрочем есть другие панели и там левого и tfs вроде и так далее из этих системах не данных мы выбирали что же нам нужно для того чтобы построить высоконагруженных 3-х не лишь я останусь на каждом из них почему мы конкретно это решение не выбрали менее интересное системам для построения с 3 облака но у нее если от недостатков во первых она не поддерживает полностью из тряпья и есть некоторые ограничения конечно же базового она все поддерживает но есть определенные ограничения с которым вы должны также ознакомиться также меню хранить все свои данные на традиционные фазовой системе типа иксов x x x x 4 и при сохранении одного объекта создает несколько файлов и каталогов на файловой системе из-за чего когда вы храните там миллионы десятки миллионов объектов это становится болью и меню начинает тормозить также есть вероятность что вас могут закончить свои ноты конечно же она не очень высокая и в последнем обновлении меню сделал шаг чтобы этого не происходило на теперь 1 hour нет для маленьких объектов данные данные месте смита файлом но для большинства объектов вы будете получать несколько операций чтения диска и так далее все вид fs интересная файловая система она отличие от lime него может быть как с 3 хранилищем так и традиционные файловые системы как и c впрочем но у нее есть и недостатки в том что надо момент слишком слаба на освещена нету большого комьюнити этой файловой системы но в целом интересно экспериментальное решение но нам оно не подходило так как в случае каких то проблем все знают как работать с цехом все знают как как его готовить есть много книг документации его поддержит red hat samsung микрон intel и прочие большие компании sea with office к сожалению не очень но интересно но решение в целом интересно и я хочу немножко рассказать о цехе вообще кто знаком с тем кто с ним работал хоть когда-то понятно в целом не очень много руб поэтому если я опишу совсем кратко и базово цех эта система хранения данных которые имеют несколько интерфейсов взаимодействия с собой вы можете хранить там данные с помощью cfs это пасек совместимая файловая система с заменой блокировками так далее орбите это блочное устройство на на которой вы можете потом накатить определенную фазовую систему и радость это объектно я конечно про которую сегодня тоже будет идти речь эти все три интерфейса они работают на слой родос и радость отвечает как раз за сохранение объектов в цехе главное из этого слайда понимать что cf это не только про ис-3 но это про все про все хранение данных следующий механизм это алгоритм краж который позволяет сохранять данные в цехе это тоже немаловажно как он это делает когда вы загружаете большой объект в цех допустим гигабайтный файл он не сохраняется как гигабайтный файл на 3 каких-то диска естественно он дробится дробится по объектам по 4 мегабайта на самом деле внутри есть еще один механизм страйков но я про него тут говорить небуду тоесть базовым объект гравицапа 4 мегабайта и с помощью алгоритма краж вариантами каждый клиент понимает куда ему сохранить данные на какой диск это все работать через пул и please fon группы но это слишком долго и я не смогу это все сейчас объяснить но базового чтобы было представление общее разбивается по 4 мегабайта с помощью определенного хэш-функции определяется placement группа после этого выбирается алгоритме краж с помощью с помощью карты краж убирается некоторые диск куда он должен сохраниться после этого он сохраняется нас и канале диск отдает соответ клиенту что объект был сохраненный потом реплицируется уже внутри на третий диск если вы не изменили стратегию по количеству копий софи по дефолту это три копья и давайте же начнем посреди типа строения нашего кластера и первое что стоит учесть эту структуру и рассчитать мощности так как мне кажется это одно из самых важных зацепок и в целом если у вас цех плохо работы скорее всего вы что-то сделали не так с инфраструктурой с расчетом мощностей сетями и прочим и самое главное к угольный камень у шефа это оперативная память тут приведены краткие сводки как мы сейчас используем cf и какие лимиты мы ему выставляем по употреблению как видите значение достаточно большие допустим если мы возьмем sd sd это равно у нас диск но ты может быть не всегда так но в этом контексте будем говорить что это так каждый диск каждый демону sd потребляет до 8 гигабайт в штатном режиме что это значит в целом цех может очень сильно попортить нам жизнь так он может выходить за заданные лимиты по употреблению памяти и эти 8 мегабайт в определенном случаях могут превращаться в 20 а то и 30 гигабайт на один диск поэтому если вас кластер из допустим на одной ноте 10 дисков умножаете 8 на 10 получаете 8 гигабайт оперативной памяти как минимум нужно для нормальной работы помимо этого есть другие демоны мониторы которые отвечают за хранение получения краж карты и так далее они тоже требуют ресурсов на первом слайде ссылочка на документацию цеха там так же можно ознакомиться с рекомендациями эти же рекомендации вывели нашим опытом и в целом можете ознакомиться в случае построения вашего собственного 3 хранилища следующий параметр это характеристики центрального процессора и одна из фразу цеха есть что чем больше вы даете ему гигагерц чем больше я ядер тем лучше он работает надо понимать что цех это не только про хранения данных но это ещё и про программное обеспечение поэтому если вы будете чем больше вы дадите ему мощности тем лучше она будет работать и если вы ограничены в вашей ноги центральным процессором то конечно же стоит выносить определенные части на другие ноты и распределять мощность то есть одни ноты то просто надо хранение другие ноты этой банды мониторов третье это ноды rgb также одна из рекомендаций является отключение всех функция энергосбережения процессора так как это может также увеличить в целом производительность вашего класса но конечно же это из-за этого идет лишние нагрев и личное потребление электричества возможно для вас это может быть критичным следующий также немаловажный момент это диски в 2021 году конечно же строят стоит 100 строить кластерная ssd и я не рекомендую устроить его на хардов но не у всех есть средства для хороших создашь ников поэтому кто-то может строить и на обычных картах поэтому если вы строите такой класс app то я вам советую ознакомиться с выносом определенных частей для поезда этого урок с биби для файл стоит определенный журнал на отдельные ssd-диски тем самым увеличить производительность кто незнаком я хочу привести пример свою сторону file storage делать двойную запись начал он записывает данные в журнал после этого скидывает на диск то есть вы получаете двойную запись поэтому при использовании ssd вы естественно увеличите производительность сохранение данных следующий немаловажный пункт это использование ssd с конденсаторами в чем очень большой плюс таких источников несмотря на то что они естественно дорогие это в том что когда цех сохранять любые данные особенно через blue star он делает очень много операций псинка даже больше чем сохранение на диск и с одесском нас адр-ами могут игнорировать эти операции так как они знают что из кэша не всегда сбросят во флэш-память и данные будут уже сохранен и поэтому одна из рекомендаций по ускорению cf это переезд на хороший с конденсаторами и прошу заметить не все фирменные диски имеют конденсаторы к сожалению и нет смысла особого использовать in wine and latin так как они настолько быстро и что когда вы их если вы вставите в пастор вы не увидите никакой никакого выигрыша так как вы будете терять производительность носите допустим несколько миллисекунд вы будете терять на программном коде cf тоже допустим миллисекунд или полмиллисекунды и это все будет так наслаиваться что итоговая разница даже в 10 раз от 2 млн the latin там в 5 несколько раз вы не заметите так как программный код сэв выполняется то же время сеть делает задержки сохранение но езда делать задержки и вот это все и следующий пункт вы можете прочитать в интернете следу советуют изменять планировщик лично я не увидел особой разницы по сравнению со стандартным планировщиком ну и следующий пункт это сеть я сразу скажу вам не стоит строить класс торцов она гигабитной сети это боль для вас и конечно же минимум это должна быть 10 гигабитная сеть а лучше 20-40 и если их охватили сустав сто и один из самых важных пунктов многие про него забывают это построение цеха на одной сети когда у вас и клиенты ходят по одной сети и и репликация идет по одной сети и когда у вас одна из нот умрет cf насчет реплицироваться и это за эффект от всех ваших клиентов и это будет болью поэтому используйте 200 для цеха это проявит и public networks многие про и забывают поэтому я это на и так центрирую внимание тогда когда у вас будет репликации восстановления данном случае отказа одну из нот ваша производительность для конечных клиентов не пострадает по сети есть другие нюансы я них расскажу чуть позже вот так представлена сеть тут я хочу показываю кто работать шесть публичную сеть кто работу через приватную сеть и нет иных источников вы можете прочитать что приватная сеть должна быть более жирный нет публичности должна быть более жены так через не общаются и клиенты и демоны по приватной сети идет лишь репликация данных восстановление кластеров случае отказа также один из самых дешевых способов увеличить сеть кластеры это используя бонды в режиме active актив и мы также это используем так как это действительно не станет действительно дешевый способ быстро и легко увеличить вашу сеть также рекомендуем следующий момент это сточная стратегия цех изначально хранит копию данных и . отказу не валяется хост и получается что если выстроить какие-то данные они будут на 3-х стах допустим вот на этих но допустим представим что вы изменили . отказано диск и тогда на одном хостел могут быть все треки ты все три копии данных и в случае отказа этого hasta вы потеряете песен группы и цех не сможет нормально записывать данные и читай данный с на этих данных нету и вы получить действительно большие проблемы поэтому не меняйте . отказа с диска на с их астана диск оставляйте как минимум на хвосте если у вас классно очень большой из сотен тысяч машин и у вас они физически разбиты на стойке эту топологию тоже нужно сохранить если вот в этом и в этом режиме он автоматически находит то вот это вам нужно делать руками разбивать на стойке ваших аст и так чтобы если одна из стоек по питанию отключится копия данных была на других стойках и тогда в целом вы будете спать спокойно и вы не получите такого что вас данные пропали цех не работает и одни проблемы сплошная сплошные давайте приступим к развертывается и я расскажу как это делаем и и для этого я хочу привел сводные таблицы какие системы сейчас есть для того чтобы развернуть эту систему хранения данных у нас есть в dipline уже устарел он больше не работает у нас есть система рук которая позволяет развертывается внутри кубер найдется но я также не советую в это использует но несмотря на это мы используем в одном из проектов вот такую систему она обладает некоторыми минусами cf очень сложны в эксплуатации и в администрирование поэтому когда вам нужно напрямую работать систем де когда вам нужно прямую посмотреть какие файлы открыты данным процессом конечно через докер то можно сделать но это сложнее рук делать некоторые вот такие нагромождения из-за которых вы можете страдать плюс купер найти сможет убивать воды в случае нехватки оперативной памяти допустим это также наносит свою боль cf едим это новый инструмент развертывание цеха рекомендованный самими разработчиками на рекомендован он по одной простой причине он очень простой для демонстрации каких-то небольших проектов вы не можете единообразно развернуть его везде на всех ваших кластерах плюс это развертывания опять же в докере не так удобно работать систем дени так удобно работать процессами напрямую поэтому я также не особо рекомендую несмотря на то что за год он прошел очень большой путь в развитии с момента релиза он до сих пор так же не все поддержку подержит у него встречается некоторые проблемы и мы используем как и все на рынке используются франции был для развертывания цехам это прекрасное решение того чтобы взять обычный шаблон и везде одинаково накатывать пусть этот df кластер пульс успеешь production не важно как вы это называете у вас везде будет одинаково и развертывание с одинаковыми параметрами которые вы можете изменить случай необходимости и эта система лишь на человеческого фактора это все работают просто через once i был прекрасный инструмент и он активно поддерживается сейчас хорошо хочу рассказать как мы это готовим у нас есть некий докер-образ который собирается пушиться в регистры просто копируется фаз и было устанавливаться зависимости и так далее после этого у нас создается репозиторий которой обладает некоторыми общими сотнями с базовым репозиториями да то есть у нас есть vitlab сядь . не ямал там есть у нас дроби которые разворачивают весь класс по нодам есть папочка инвентарь и в которой хранятся настройки хранятся хасты на которой это нужно развернуть достаточном слайде я сейчас представлю вот так вот выглядит внутри структура inventory есть групп wars тут хранятся настройки цеха в различных файликах их a scene там указывается просто хасты куда что установить то есть какие роли выполнить на каком посте все очень просто тут настройки тут тут всего лишь касты и дроби запускается вот следующим образом ваш ключ и прикидывается на строчку не обращайте внимание это наша внутренняя штука и просто запускается с хоз . не определенные определенные play google и развертывания для обновления для удаления кластера в случае необходимости и вот так представлена конфигурация в паццини то есть мы видим какие хасты какие роли выполнить на каком посте какие диски подключить на каких но дахно можно сделать of the discovery также ansa было предоставляет графа ну сервер с коробкой и удачный демон rgb для того чтобы подключаться по ис-3 хранилищу также там могут быть другие настройки различные так выглядит общий конфигурационный файл тоже все очень просто мы соответственно делаем с какого репозиториям и берем цех откуда до делаем какие сети у нас должны быть вот публичной сети вот приватные сеть они разные какие интерфейсы то есть тут есть некое смешение 200 где-то сети вот дальше мы можем настроить определенные параметры цеха который будет везде во всех ваших новых во всех ваших мастерах и определенные параметры ядра на этом я стану чуть чуть подробнее также включить или выключить дашборд то есть там на самом деле много различных параметров которые вы можете использовать и это все вот в одном файлике и очень удобно с этим работать особенно хочу сделать акцент на настройках ядра linux как система не предназначены изначально по дефолту как система для высоких нагрузок то есть параметр ядра зачастую там вы страны не оптимальными так как вам это нужно поэтому изменение параметров ядра особенно для cf который использует все от файловую систему до сети очень очень нужно я не буду останавливаться на всех вот этих настройках их очень много это то что мы сейчас на данный момент используем но опять же не все опции них суждение сюда не влезли вы можете посмотреть и я крайне рекомендую ознакомиться со всеми этими настройками чтобы сделать правильный конкретно под вашу сеть под ваш кластер что вам конкретно нужно и для того чтобы это сделать правильно я подготовил несколько ссылок вы можете ознакомиться у радха то пройти по главам посмотреть какие параметры ядра они рекомендуют изменять вы можете посмотреть как это делает микрон то есть там есть как раз тестовый класса со всеми настройками для того чтобы вы могли вот посмотреть как это они делают от самсунга есть другие сучки и советую книгу мастер не cfc кондишен глава 9 также познакомиться прекрасная книга почитайте вы множество много чего пройти процесс и как я ранее сказал потребление оперативной памяти очень большого цеха и она может выбиваться за лимиты которые вы рассчитали заранее как искала диск может потреблять вплоть до 20 30 гигабайт поэтому для того чтобы это ограничить мы используем систем де как я ранее сказал для ограничения потребляемых ресурсов конкретным демоном и если вы используете кластер как мы на данный момент для того чтобы у вас на одном большом кластере много памяти процессора вы туда загнали кубер нить из вы туда загнали cf я советую вам разделять по вот таким вот системы процессом конкретно сколько потребляет цех сколько потребляет кубер нить из есть различные настройки следующий момент рождения тут люди не знакомил так полноценно с.ф. но возможно вы посмотрите в записи тоже что-то почерпнете что лучше для хранения blue star или файл старта есть цепи есть две системы 2 бэг-энда для хранения данных конечно же blue star на данный момент выгоден он в два раза быстрее чем файл star in огда даже больше но на данном слайде я хотела дополнительно принести показать что есть прекрасно статья отца твои когти у них blue star и какие настройки можно используются цепи для того чтобы на 30 до 50 процентов производительности у блюз тора по этой строчке также тут статьи насколько она быстрее но я не просто так привел файл стар как в пример повтор может быть быстрее чем blue star в определенных ситуациях допустим когда у вас кластер храниться на жестких дисках соответственно у вас есть дополнительные создать диски на которых хранится журнал либо володи barracks baby которая позволяет ускорить вот производительность и вот в этом случае фаста месте ssd cache им будет быстрее плюс тора при пиковых нагрузках если у вас есть пиковые нагрузки допустим вот такой вот график то в этом случае файл спор может водоем вот допустим тысячу aiop saw в то время как blue star будто выдавать 300мб saw если же идти будет идти долго нагрузка на кластер то в этом случае plus top конечно же будут выигрывать то что files тору придется в ssd cache и пойдет скидывание данных на диск уже а полноценная и соответственно blue star будут выдавать 300 и вепсов files корпус вызывать 100 x 100 x of и на этом сайте хочу сказать что что не верьте всем моим словам которые я вам говорю тут и в целом говорят в интернете иногда какие то конкретные решения могут быть выгодны конкретно вам ipad так допустим если под такую нагрузку вам файл storm может быть даже в более выгоден чем plus top хотя везде а пропагандирует использовать blue star то есть обращайте на это внимание и тестируете объект на хранилищ давайте перейдем к объектам уронили шефа модем совместим с amazon s3 sapiens лакцев интерфейсами демон rgb который отвечает за получение данных за сохранение данных требует очень много ресурсов и эти демоны рекомендуется выносить на отдельные ноты для того чтобы не нагружать ваш кластер в целом либо используйте космические центральные процессоры для того чтобы эту нагрузку всю распределяйте то пусть вместе вас там множество множество ядер также the fans и было почему это прекрасно инструмент есть из коробки на насколько х прокси когда вы можете назначить определенные виртуальные печники для всех демонов вашего цеха разве твой и связать их х прокси с виртуальными печники в режиме active актив для того чтобы случае если одна из нот падает на данный виртуальная пишет переместился и вы получаете отказа устойчивую систему следующие условия необходимы для того чтобы ваш ис-3 кластер был максимально производителем конечно же это вынести вынести индексы на отдельный создав случае если вы все же используйте карты потому что это дешевле также есть один важный параметр который не часто мелькает и торговым ок макс конкуренции request почему он важные допустим если у вас огромное количество клиентов то вы прочесть в это значение допустим вас 1000 24 одновременно подключения к вашему демону вы допустим возите по скорости отдачи и так далее но сам это демон не будет отдавать уже ответы вы будете сталкиваться 500 ме ошибками мы тоже с этим столкнулись на тестовых la страх и не понятно что было с этим делать и вот как раз этот параметр и отвечал за то чтобы ускориться следующий момент это три других параметрам а не на тот момент все являются дефолт нами но я также крайне рекомендую вам их посмотреть на ваших кластерах случае если у вас старый цех и изменить так как эти значения также повысит вам производительность также цех очень много лакируют данных везде пишут логи на каждом уровне и вы можете получить прям солидный выигрыш если отключить и просто все веси дебат и так делать те ребята которые я показала выше микрон samsung так это действительно увеличит производительность логов он пишет очень многое может засорять вам целым ваш системный диск есть конечно же другие параметры я них конечно не смогу во всех рассказать так как их очень много в настройках и могу рекомендовать обратиться к тем ссылкам которые были представлены выше для того чтобы ознакомиться с ними и применить уже в ваши конкретные работе следующий момент это был settings это обратная засыпка одна из проблем к с которым вы можете столкнуться в цехе это допустим отказ из одной из нот и тогда допустим вы подумали что вас одна из но тот отказывает и подготовили вторую сеть и вы думаете все будет хорошо репликация будет идти по 2 сети и все здорово но на самом деле вы будете получать проблемы с производительности дисков и будете получать проблемы с производительностью железо и ваши конечные клиенты также будут страдать от падения производительности и эти настройки очень сильно влияют на то что ваши конечные клиенты не будет страдать от восстановления вашего кластера следующий следующие настройки это скрабирование многие знают язык тем что такое скрабирование но я повторю это восстановление данных в случае их повреждения не могут повредиться как при записи так и при каких-то любых условиях допустим даже от активности солнца как бы это смешно не звучало данный могут повреждаться на дисках и это типичная ситуация и есть две стратегии как чинить эти данные это очень ресурсоемкая операция поэтому вы можете делать ее либо ночью либо делать весь день но очень медленно поэтому зависимости от вашей нагрузки какая у вас в кластере выбирайте именно ту стратегию которую вам более-менее подходит следующий момент это не все знают но цех может быть формате мастер мастер масса слоев то есть вы можете поднять два кластера один во владивостоке другой в москве и связать их это делается очень просто вы соответственно по тому что я был показывал раньше поднимаете два кластера в одном из них указывает сезон мастер true в другой функция к на ветру и с помощью ключей и других настроек которым можно все почитать по этой слышу вас будет идти автоматической репликация данных вы можете реплицировать не только полностью все данные в цехе но и частично то есть конкретные bucket и допустим не знаю bucket с каким-то нужным вам контентом опять же рекомендую ознакомиться к сожалению не смогу тут показать все нюансы но если вы поднимете кластер у вас на локальном хосте настройка вот именно конкретно этого займет у вас минут пять не больше и давайте же я расскажу с какими проблемами в процессе эксплуатации мы столкнулись у нас были следующие проблемы у нас были сломанную sd что это значит в одной из версий 15 22 мы столкнулись с такой проблемой что при бэкапе машин особенно виртуальных при различных сетевых проблемах мы сталкивались с тем что определенные диски просто отключались и больше не восстанавливались и если мы их даже рефери с помощью специальных механизмов цеха то они больше не работали и мы нам приходилось их удалять из кластера и заново уже запихивать это вот такая была проблема в 15 22 в 15 2425 эта проблема была решена дальше у нас была проблема с удалением данных допустим у нас вас три хранится там один терабайт данных мы удалили эти данные с 3 и данные как бы пропали с пакетов но физически они остались на дисках и остались на слой родос многим не скажут что есть гараж коллектору цеха который подчищает за вот этим всем но он не сработал мы выпускали вручную и ничего не отрабатывал поэтому нам пришлось весь на более низкий уровень родос удалять руками эти данные чтобы в целом почистить наши диски вот такая вот проблема была к счастью большим и на последних версиях актуальных и и не наблюдаем но вы можете с ним столкнулся также я рассказала про утечку памяти она также встречается в руки в кубер на эти но более страшное потому что cf aig обернитесь будет удалять воды в случае нехватки памяти и так далее также у них не стоит никаких лимитов если вы вручную их не установите у нас была также утечка сокетов у цеха есть в бэг-энд обработки с 3 запросов bist написаны на си плюс плюс и и соответственно у него была какая проблема когда мы делали множество запросов через какой-то момент мы сталкивались с тем что наши ac3 хранилище не работает и не отдает данные то есть всегда выдает 500 ошибки мне пришлось залезть в код цифры начать изучать почему он это делает а делал он из-за того что bist после разрыва соединения или каких-то других причин не удалял socket файлы тащили за усов так далее я нашел что у этого процесса файлы были топит файлы они были но них не было ни connection они чего они были просто пустые и нам пришлось писать специальный скрипт который бы чекал соответственно количество вот этих ракет файлов открытых и перезапускать этот сервис такая вот проблема была тоже на одной из старых версий то есть 15 22 этом 15 23 но впоследствии она также ушла ушла и именно из-за этих причин я и рекомендую сновидцев непосредственно на голое железо для того чтобы уже осмотреть и оперативно решать все проблемы уже с помощью стандартных инструментов инструментов linux и я крайне рекомендую следить за выпуском релизов цеха допустим посмотрите на релиз 15 27 и вы увидите что они fixed десятичные критичные баги когда вы могли получить удаление реальных данных здесь и сейчас из-за каких-то вот багов самого цехам и я хотел бы подвести краткие итоги тут описано то что мы с вами сегодня посмотрели и изучили и хотел бы донести одну из самых главных мыслей экспериментируйте с цехом и больших большинство неполадок которые вы можете встретить у вас в кластере это не потому что цех плохой он не работает или еще что то что то это все из за того что у вас что-то съесть у вас что-то с памятью у вас приходит а он вас мог быть еще какие-то проблемы но в основном это именно то что вы что-то не так сделали ли какая-то сторон не проблема вплоть до того что ваш какой-то микро сервис может начать доносит цех каким-нибудь лесом и вы будете получать проблемы в цехе из за того что у вас какой-то компонент много потоков начинает какие-то запросы в цеху и он начинает этого страдать на этом у меня все я надеюсь вам понравился мой доклад и он был вам полезен и будет вам полезен в работе спасибо всем за внимание спасибо дмитрий я вижу вопросы давайте я начну расскажите большой класс старцев а до большой ну смотря с чем сравнивать сколько но ты сколько петабайт у нас не петабайт у нас сотни терабайт соответственно у нас десятки серверов более точно не могу назвать мне не разрешили сказать но это достаточно большой кластером возможно не такой как у игроков типы радха то самсунга микрону но и не маленький команды который поддерживается команда смотри так как я настроил я сам занимаюсь цехам и занимаясь его администрированием я настроил вот такую систему c шанса было когда все настройки и все она как бы является неким сервисом который потом передается в развертывании то есть мы готовим цех вот таким вот образом мы делаем небольшую инструкцию по администрированию этого цеха передаём его заказчику и заказчика уже его администрировать но также мы это в этом не вмешивайся там сложная система распределения триколор а мы естественно вместе работы вместе поддержим решаем вопросы но в целом цифры не strut несколько людей не более я отвечаю лишь за общую в за общее видение за общее расчеты и в вмешиваюсь там в крайних случаях когда это нужно но пока у нас проблем с цехом вообще никаких не было можно продолжить просто набор мелких вопросов работает этот река бира на нет у нас есть один из один из проектов где cf работают внутри кубер найти со через рук но это не очень хорошее решение и я стриминге платформы cf работает отдельно от кубер не tissot но на одних и тех же серверах но на голом железе надо набор металле да не совсем понятно фраза на одних и тех же серверах ну мы накатываем cf и кубер нить из на 1 этаже кластер они работают как бы может сказать гиперконвергентное режиме но на не совсем корректно то есть это не относится на самом деле терминологии ну кто так может выразиться то есть они работают вместе 9 ресурсы ну хорошо еще вопрос про вот реально кейсы о том что один цех работает в хабаровске 2 и в москве мы проводили мы приводили эксплуатацию опытные тестирование на тот момент у нас нет вот такого механизма но в будущем мы планируем именно работать по такому методу опять же нам не важна скорость передачи данных надо понимать что конечно же данный реплицироваться и а небольшие там очень много данных они будут долго но для того чтобы конфликт конкретные клиенты получали данные быстрее это как один из способов ускориться также можно использовать в качестве бы копирования цеха допустим если вы переживаете за ваши данные то есть вы можете использовать по разному этот механизм он существует ok финальный вопрос просто про мелкие файлы сказали что все видео или в меню меню про него говорили большая проблема вот файлов действительно такой есть что в цепи с мелкими они все разбиваются по вот по блокам по 4 мегабайта и сохраняются соответственно непосредственно блюд через blue star и уже на диск то есть там нет такой проблемы там свой backend хранения данных и собственно структура сохранения она не использую традиционную фазовую систему этом сама peace условно говоря поэтому проблемы с мелкими файлами там не существует как таковой как это делается в меню спасибо большое за доклад очень интересно планируем тоже внедрение цифр у меня такой вопрос если какой-то смысл пытаться понятно что боевая конфигурацию должна быть развернута на железных сервера с отдельно сетью рекомендацию производитель это сказать вот ну вот например для предварительного расчета и для интеграции с нашим кумиром для такой тестовой площадке можно ли его разворачивать в рамках интеко например не понял последнее слово в рамках openstack а можно но мы так не делаем конечно же можно рамках окон столько развертывать но лично мы так не делаем поэтому какие-то более подробно формации вам не скажу вот спасибо здравствуйте спасибо за доклад такой вопрос вот вы отдаете инсталляцию цеха заказчиком или клиентам да да вы потом делайте какое-то сопровождении то есть возникает ситуация например что клиент говорит у меня медленно чита работает вы потом как-то достать да конечно то есть и случае необходимости в случае каких то проблем с эхом мы действительно оперативно вмешиваемся и решаем те или иные проблемы потому что проблем может быть много отказ диска отвал сети репликация дополнительной настройки потому что могут настроить допустим не совсем корректно или что-то забыть убрать параметры ядра еще что то то есть мы естественно помогаем но предоставляем инструкцию как это сделать сразу правильно и какие конкретные инструменты используются для trouble shooting a и дебага какие инструменты что инструменты какие используйте для travels у тинга для поиска и устранения проблем ну естественно мы используем стандартный инструмент active на тот момент а там смотрим сначала ну состоянии дальше от состояния мы понимаем пологом какие проблемы возникают у шефа да то есть какая-то sd по какой-то причине отвалилась значит дальше мы или какой-то демон потреблять лишнюю память значит мы можем посмотреть какие там что он конкретно делает какие файлы у него открыты как я приводил пример и так далее то есть на самом деле все стандартные инструменты которые можно можно на себе там представить мы используем в некоторых случаях мы можем отключить ну обратно включить логирование у цех мы же его отвечаем и уже посмотреть пологом чуть более детально сделать лак уровне там 20 и посмотреть детальном что происходит почему не так дмитрий спасибо за доклад очень интересно меня зовут леонид вопрос такой вот вы говорили рекомендуете используйте с конденсаторами да они существенно дороже и в какой-то момент целесообразность переплаты и преимуществ от использования накопителей с конденсаторами становится целесообразно и собственно это стоит изображена когда вы вот хотите уже максимальную производительность у вас позволять ресурсы конечно же нужно понимать что любое создает должны быть надежными так как диски отваливается постоянно это штатная ситуация если у вас плохие диск они будут валяться просто постоянно поэтому любом случае вы не сможете прям сильно сэкономить купив обычный сдс dns оккультную не реклама вот и вам придется покупать дорогие сады и если у вас есть ресурсы конечно же рекомендуется делать ну покупать именно с конденсаторами для увеличения производительности но опять же это если у вас кластер большой у вас большая нагрузка на cf у вас неплохие центральные процессоры потому что ssd в целом требует больше мощности чем обычные харды и когда у вас вот эта совокупность факторов складывается конечно же стоит покупать в конденсаторами и если вы страдаете того что вам не хватает производительности если вам хватает то конечно же покупайте надежные просто создаёшь некие как бы у вас будут все хорошо вопрос добрый день спасибо за доклад хотела узнать при построении мастера цеха для клиента даете ли вы какие-то рекомендации конкретно там по моделям железо дисков и вообще сравнивать или как-то диски которые есть на рынке на данный момент триколор самостоятельно закупает железо поэтому мы не не вмешивались этот процесс но и случае для других клиентов которые также будут интегрировать нашу систему мы соответственно конечно же будем сопровождать и документации и рекомендациями по покупке того или иного железа если заказчик сам купит конкретное железо то мы просто подберем необходимую конфигурацию под это железо и все а если же он у нас просит совета какие диски и какие что купить зачем сколько оперативы нужно то конечно же мы в итоге мы выдадим рекомендательные там письма и так далее спасибо вопрос под с этой стороны уже идут может быть у кого нить еще спасибо большое за докладывая было очень интересно вот скажите пожалуйста по вашему именно вот эксплуатационным опыту какой оверхед дает диски в плане емкости относительно полезного то есть грубо говоря вот на 1 терабайт полезной емкости сколько мне нужно будет купить жестких дисков потому что есть там количество реплик есть количество там объем столь же который должен быть зарезервированы должен заполняться есть там дополнительные нельзя мы вот по по вашему опыту и как это зависит от размера в этом 100 гигабайтный вот так вот терабайтный вот так вот там 100 терабайтный вот так ну я начну с того что цех сам по себе и у него есть лимиты то есть вы покупаете терабайтный диск и вы не можете заполнить больше чем на 95 процентов это первое пять процентов и сразу теряет на самом деле там не совсем так то есть там есть последняя граница где-то 97 процентов до которой он может дойти ну вот берем 95 как вот среднее значение это первое второе это вот конечно количество репликаций вы можете поставить либо двери кликается либо 3 libre кации соответственно тоже либо вам на 1 терабайт нужно три диска 3 ты работника на самом деле уже чуть больше то что 5 процентов это уже там нужно считать по матери ческий так не скажу либо уменьшить количество репликации до двух новых вашу вас страдает вот отказоустойчивость и так далее что вы можете потерять копии и либо такой либо использовать механизм н шура coding который тоже может сэкономить место но в целом вот при стандартном развертывание у вас должно быть для одного терабайта это там три целых не знаю одна сотая может быть что то такое но еще один момент забыл сказать что цех не правильно распределять данные так как данный он всегда в real time высчитывать куда сохранить конкретный объект то распределение по дискам не будет всегда одинакова тоесть у вас один диск будет заполнен на 15 процент другой на 25 10 процентов разница между сама заполненным и самым незаполненным диском она также присутствует поэтому один из дисков вас всегда будет заполнен быстрее чем остальные и чтобы этого механизма ну чтобы вот этой проблемы избежать успев есть настройка вот может подойти я выхожу из ес по памяти не помню которая отвечает за то чтобы нормализовать как раз вот это распределение до четырех процентов по моим тестом то есть не больше четырех процентов будут между самым большим и самым незаполненным диском вот но это требует много ресурсов со стороны cf а так как он начинает менять веса дисков для того чтобы постоянно перекидывать данные с одного диска на другой диск вот поэтому это так же накладывают ответ котлету вашим вопросу накладывает некоторые вот накладные расходы на место в вашем диске вот реально три с половиной получить ну я бы сказал да дави наверное где-то три с половиной надо чуть больше больше считать так я не прочитал где-то примерно до понятно спасибо у нас есть вопрос по центру спасибо за выступление хотелось уточнить существует ли сейчас такая практика как использование для репликации и ждите накопителя соответствие как основной ssd или это слишком замедлит работу ну вот есть практика когда вы можете использовать в кластере ssd пулы и hdd пул то есть вас могут быть данные на ssd и на хардар естественно для репликации у вас желательно должны быть более-менее одинаково кластера но хотя в целом на самом деле неважно то есть у вас может быть один два диска в другой на ssd конечно же репликация будет идти медленно скорее всего упретесь канал возможно либо еще где то причинам в целом нет таких требований чтобы вас кластера были одинаковые там были создали там были ждите вы можете собирать разные пастора и для backup используется совсем дешевые диски но объемные а для вашего продакшн и там которым клиенты ходят используется создает нормальная практика также то есть получается на этом можно существенно сэкономить на конечно да то есть если у вас вы хотите сделать поднять два кластера то вот такой механизм позволит вам сэкономить деньги спасибо спасибо еще вопросы справа здравствуйте у меня вопрос если у вас а цифра развёрнут вниз нескольких судов которые далеко друг от друга на находится и при репликации возникают эти проблемы расскажу что у нас в целом сейчас не тут вот этой системы про репликацию данных она пока что у нас не готова не используется но мы возможно и и внедрим у нас просто есть сети генов через которая дается а некоторые данные поэтому мы пока что не выдвигаем но если есть сетевые проблема между двумя кодами то конечно же цех с ними тоже борется то есть один цех не может прекратиться к другому репликации остановлено когда опытов в виде друг друга репликация происходит или я неправильно понял не все правит просто мы использовали все сия вид на одном из проектов и отказались в него как раз таки потому что у нас мы не имели возможность использовать только один соты приходилось развертывать не менее нескольких ну вот по нашему по моему опыту да в целом такой механизм он более-менее работает это способен вопрос по расширению кластеру возможно ли на ходу и расширять конечно то есть вот еще один из минусов для меня вот меню когда вы используете вы должны поднять вы должны используйте сервера одинаковые с одинаковым количеством дисков с одинаковым объёмом и не должны быть прямо вот одинаковые и там есть проблемы из при питаться и с восстановлением кластера с удаления дисков и цех таких проблем нет вы можете поднять 11 сервер где там 100 дисков и один сервер где два диска и спокойно жить вы можете сделать так чтобы вас в разных нотах было разное количество этих дисков и по разных но разного объема разных вендоров разное железо то есть цех можно собрать из любого из любого железо и в случае если у вас допустим закончилось место и вам нужно что-то срочно сделать можно даже пока соседа поставить в цех и она будет работать с увеличением место его харда то есть цех может это сделать естественно это плохо и это не рекомендуется на вот но в целом можно собирать и из любого желез и кластер когда мы пойдем совсем в отчаянии мы можем не то что пока сосед убрать мы еще и мобилку него и нам в кластер добавим последний вопрос скажите вы у клиентов обновляйте цех да как я показывал есть jobo по обновлению кластера и там указывается версия которые мы рекомендуем допустим рекомендую вместе 15 213 в случае если мы протестировали себя новую версию допустим какой нибудь 15-го 414 вышла мы ее тестирую что все хорошо там нет каких-то новых проблем мы протестировали говорим заказчик вот тут поменяете строчку вот тут нажмите кнопочку и класса обновляется каждый раз обновлялась успешно или бывали проблемы вот самое сложное это пир 1 1 развертывание потому что там начинается проблемы не то сеть еще что-то еще какие-то проблемы возникать пусть этого класса уже работает нормально то в целом всегда развертывание происходит успешно а бывали у нас какие-то проблемы но повторный запуск джо бы мог эти проблемы как бы решить но иногда конечно же допустим у вас может быть какой то диск допустим в дауне потому что не работает или какой-то демон монитора не работает еще что то есть иногда приходится что-то руками дополнительно поправить поднять чтобы класс app был в состоянии хаоса то есть полностью здоровый и после этого если он в таком состоянии то накал к происходит без проблем спасибо"
}