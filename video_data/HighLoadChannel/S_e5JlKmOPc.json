{
  "video_id": "S_e5JlKmOPc",
  "channel": "HighLoadChannel",
  "title": "Все домены мира в RAM процесса / Евгений Буевич (RU-CENTER)",
  "views": 491,
  "duration": 2205,
  "published": "2020-04-14T11:16:26-07:00",
  "text": "меня зовут людей не боюсь как уже сказали я сейчас хочу рассказать вам о том как мой в компании ru-center создавали инструмент для хранения и проверки состояния доменных имен для пользователей нашего сайта и для некоторых наших сервисов очень часто нужно проверить в каком состоянии находится доменное имя было ли оно зарегистрировано если на него специальная цена или возможно она запрещена к регистрации но честный заброска поставщику этой услуги достаточно долгий и как правило пользователей сайта пользователям сайта приходится слишком долго ждать ответа на этот вопрос поэтому мы поддерживаем базы данных состоянием доменов и во многих случаях когда нам не нужно очень точная информация используем информацию из нее данные в нее в основном поступают ночью в виде списков домена вход поставщиков услуг это от реестров и от брокера вторичного рынка как это работало старые добрые времена несколько машин и у нас выкачивали информацию ночью различные списки и заливали их в 2 поиска или одна из покрышек была оптимизирована под сайт имела свой набор индексов 2 повод работу сервисов но поскольку мы постоянно открываем регистрацию новых зонах предлагаем новые услуги и списке сами по себе растут то в какой-то момент нам потребовалось заливает 430 миллионов домена в сутки это дает нагрузку на запись 5000 запрос в секунду и поиграть на является перестала фактически она заливала дольше суток то что нужно было то что изменилось за эти сутки мы стали искать другое решение и попробовали на этот роль на эту роль редис редис нас в принципе вполне устроил но было два неудобства первое что обновление данных она конечно быстрее стала снимать его два часа в день но это все равно не то чтобы много но ощутимо и второе неудобства его потребление памяти то есть для нашей базы данных при любой 40 гигабайт памяти соответственно для полноценного кластер одесса потребовалось три машины сорок восемь гигабайт имеющих мы засели что это многовато для подобной задачи и решили попробовать разработать свое решение она выглядит так некотором сервере разделяемой памяти находится храм хэш таблица с библиотекой для работы с ней написано на языке си на этом же сервере работает в их серверов ночи он получает архетипе запросы на проверку домена от клиентов нашего сайта и от наших сервисов ищет в этой хэш-таблицы состоянии домена если находит возвращает если не доходит то запрос выходит дальше к поставщику информации это хэш таблица наполняется в основном ночью скрипты скачивать эти списки и заливают до новые данные характеристики которые мы получили для прототипа памяти мы использовали всего пять целых с небольшим гигабайт скорость записи было 14 миллиона запрос на секунду скорость чтения 18 миллионов запросов в секунду потом мы оптимизировали код и память естественно осталась такая же а чтение и запись несколько ускорились и стали одинаковые практически два целых восемь десятых миллиона запросу секунду и фактически мы все это обернули робот матриксом и наша бизнес задача на этом фактически было решено все это на замечательное устраивала но осталось несколько вопросов почему у чтение и запись работает с одной и той же скоростью почему хэши моего любимого пирло работает практически с той же скоростью для случайного чтения и почему 60 процентов времени процессор проводят функции search an index которая бежит по цепочке коллизий дальнейшая разработка в основном делалась из любопытства ну ответы в принципе лежит достаточно на поверхности потому что нас тормозит памятник потому что все наши данные намного превышают кэш процессора и фактически мы имеем очень много кэш промахов попробуем исследовать это с этой точки зрения сначала расскажу о том с какими данными работает наш род сервер это ключ у нас доменное имя максимально на двести пятьдесят четыре символа но в нашем случае последний символ . можно отбросить и двести пятьдесят три символа мы используем и значение от 0 до 12 байт то есть там может быть специальная цена там могут быть какие-то флаги его состояния может не быть ничего значит момент просто зарегистрирован без каких-либо особых условий вот и так же ты тут скажу о распределении блин цепочек коллизий при коэффициенте заполнения таблички равным единице вот вы видите на слайде это ответа можно вывести ты и величины которые нам понадобятся в дальнейшем что заполненная часть таблички это 0643 64 процента ячеек заполнены и средняя длина цепочки в заполненной части таблицы 16 рассматриваем самую простую хэш-таблицы с цепочками количес точки зрения кэш промахов 1 из наших задач она наполнит пустую таблицу включая в ней нету с вероятностью единицы поначалу но и в дальнейшем его тоже нету потому что дубликаты в списке которых мы получаем это очень большая редкость этаж и поставщика и надо просто удалить первое обращение к этой табличке поскольку она тоже весьма большая данных у нас много она всегда дает промах и это 1 грамма который мы получаем если табличка пустая то этим промахом собственно все ограничиваются но если табличка не пустая там есть ссылка на какую-то цепочку то мы получаем второй промах при проходе по этой цепочке потом получаем третий промах и столько промахов ска насколько шагом насколько зрения в этой цепочке конце концов мы обнаружим что нашего ключ к в этой цепочке нету и его добавляем формула выглядит число промахов для работы для добавления новых ключа выглядит так соответственно величины zafira филипп правд это заполненная часть отменяется от 0 до 0 64 очень line это длина не пустой цепочки меняется от единицы до 1 и 6 соответственно их произведения меняется от 0 до примерно единицы и число промахов меняется по мере наполнения таблички а вот единицы до двух и рассмотрим вторую задачу это сверка с новым файлом то есть выключили не какой-то файл и нам надо узнать что в этом списке изменилось за сутки что удалил и что добавилась в этом случае ключик в нашей табличке есть вероятность и близко к единице потому что для больших zone типо ковром новые регистрации составляют очень небольшое число от общего объема зона меньше процента вот рассмотрим с точки зрения этой задаче мы имеем тот же промах при первому обращению и обязательно имеем второй промах потому что ключи на заведомо есть то есть пустой ячейкам мы не попадем и в какой то момент мы можем найти свой ключик и скорее всего его найдем и прекратим движение по цепочке больше промахов совершать не будем таким образом формула выглядит так и равна примерно двум целым трем десятым рассмотрим с этой точки зрения открытую операцию которая казалось бы более перспективно с точки зрения кэш промахов хэш-таблицы с открытой адресации они отличаются тем что хэш их дающий коллизию размещается свободных ячейках таблицы по какому-то алгоритму на много разных игре по существует мы будем в общем попытаемся посмотреть итак мы имеем тот же промах при первом обращении если ячейка повторят то мы соответственно на этом заканчиваем если она не пустая то скорее всего следующие обращения будет тоже кэш перо махом но последующие вращение сколько их сила будет кэш попаданием потому что современный процессор при регулярном движение по памяти может предсказывать ищейки которыми мы обратимся дальше и доставить требуемые данные в кэш таким образом формула выглядит так соответственно при наполнении меняется от единицы до двух количество каш промахов и равно ровно 2 для полной таблица это выглядит получше но для регулярных обращение к памяти данные должны быть фиксированной длины в нашем случае максимальный объем объем данных у нас 265 байт и если мы выделим будем выделять еще типа 206 5 будь то мы получим большой ехать по памяти значительно хуже редиса поэтому попробуем ещё одну идею разделим ключ на две части небольшую фиксированную часть и большую часть переменную небольшую часть разместим в таблице и посмотрим что нам это даст точки зрения каш промаха при отличие начала ключа то есть заголовка мы можем быть уверены что ключи не совпадают пока что все у нас промахи те же самые но вот мы заголовок ключа у нас совпал и мы обязательно должны обратиться к остатку ключа потому что совпадениях и шеи совпадения заголовков не дает гарантии того что это тот же самый ключ и таким образом получаем еще один к шрамах предыдущая формула у нас становится на единичку больше и это много посланий со всем остальным что мы рассматривали однако идея с заголовками выглядит весьма неплохо вернемся к таблицам с цепочками и посмотрим что может получиться здесь отделим открытия 4 байта и дополним их ссылкой на продолжение тоже четыре байта я потом расскажу почему соответственно тоже при обращении к пустой ячейке промах первое обращение к таблице всегда пером ах дальше процессора при обращении к памяти в кэш попадает только не только тот байт которому мы обратились но некая порция данных называемое колени и для современных это 64 байта таким образом до восьми наших заголовков могут располагаться в одной кошеле ней ну и соответственно идею что вся наша цепочка коллизий будет в одно икаешь лени и мы получим 1 ключ промах на проверку всей цепочке у нас для экономии памяти в одной линии может располагаться несколько цепочек но одна цепочка занимает больше обновлений только если оно реально больше 8 ячеек вот ну и таким образом мы получаем еще один промах при обращении к остатку ключа однако формула уже выглядит немножко по-другому соответственно при наполнении пустой таблице 1 плюс филипп по ст нас пока мы помним член у нас больше единицы поэтому мы получили выигрыш здесь от 1 до 64 эта величина меняется но сверх к по-прежнему дает три промаха что хуже но неужели мы ничего не добились но однако вот такой организации есть одно полезное свойство которой мы можем посмотреть на следующем слайде здесь синие линии это хэш-таблицы с цепочками зеленые линии это хэш-таблицы с группировкой как мы видим количество кашмира махов и соответственно и быстродействия таблицы практически не зависит от коэффициента заполнения то есть если в начале наших групп наши группировка немножко проигрывает то потом как кота пока коэффициент меняется в пределах от 0 5 до 8 мы практически не теряем ничего быстродействия нам еще остался последний шаг до окончательного решения здесь мы глядя на эту таблицу выбрали коэффициент 3 с половиной как целевой вот если дым что происходит при этом коэффициенте длинный цепочек распределяются таким образом что мы можем сказать из этого распределения первое что наиболее вероятная сумма глен двух цепочек это 7 второе что сумма длин двух цепочек равна шести или семи вероятность 30 процентов что две цепочки в сумме будет длиннее семьи вероятность 40 процентов но ключей в этих превышающих частях этих цепочек будет всего 10 процентов и рассмотрим наконец-то самый лучший на мой взгляд способ организации этой табличке ну собственно говоря идея тоже только заголовки теперь группируются не только в цепочках колизей а непосредственно самой хэш-таблицы на слайде вы видите одно каши линию в хэш-таблице она разделена между двумя крышами цепочка одного из них растет вверх цепочка 2 растет вниз когда они сталкиваются то вот там есть chilling ссылка на продолжение на самом деле в 1 вечерки помещаются два таких чем ленка один для верхних 2 для нижних и там продолжения таких каш промахи мы имеем мы имеем 1 промах при обращении к таблице второй промах мы имеем в том случае если мы нашли включу в той части цепочки которая находится самой таблица или мы его имеем если мы нашли продолжение этой цепочке ну и соответственно перейти промах мы можем получить обращению к остатку включая как выглядит формулы формула выглядит так при наполнении пустой таблице у нас количество каш промахов 1 plus long порты long part у нас меняется от 0 до всего 0 4 то есть всегда меньше полутора каспера махов мы при наполнении и при сверке с новым файлом у нас 2 plus size нло во рту насколько мы помним что кислород марта у нас очень небольшая величина и таким образом мы немножко похуже 2 имеем результаты но остальные достоинству это организации перевешивают и именно ее мы используем своем конечном решение что нам это все дало нам это дало прирост к растению соответственно для одиночного запроса для проверки или добавление 1 ключ к мы имеем теперь такие результаты 38 mega millions запросов в секунду на запись или 46 миллионов запросов на чтение то есть мы уже обогнали перловую реализацию и поскольку у нас и записи и чтения происходит пакетами записи огромными пакетами там по миллионам ключей а чтение небольшими пакетами по 800 1000 ключей надо так оно и происходит вот то мы сделали пакетный режим он чечерский соответственно поскольку мы знаем что основные задержки нам дают кэш промахи нам поступает на вход несколько ключей и мы еще один ключ цепочки одновременно можем командами при выборке подтягивать в кэш-память для другого ключа и все это нам дает для некоторых наборов данных более чем двукратный прирост скорости до вот таких величин пока что на 1 про точно попадать на поточной работу все о дальнейшем мой к ней вернемся там сбив марта как у нас устроено многопоточные работы соответственно у нас есть указатели которые мы можем это мэр на переключатель и все это находится в память естественно нам захотелось попробовать log of liverpool что такое алгоритме рту я кратце расскажу несколько слов соответственно на слайде мы видим как видим как три потока первый поток пытается читать какую-то область данных 2 пытается или заменить записать туда новые данные в этот момент первый поток читает данные о пишущий поток где-то создал область и записал нее новые данные но эта область данных пока в структуре данных не видно потом пишущий потока там р-на заменяет указатель соответственно читающий продолжаю читать старые данные а другой читающий поток пришедший позже читают уже новые данные пишущий поток в это время ожидает пока первый поток данные дочитает как только он их дочитал пишущий поток может данные удалять как не сложно догадаться в этом алгоритме достаточно слабое место это вот период этого ожидания он используется в ядре linux эффективно используется но там с определением периодов этого ожидания проблем нет то есть там есть просто некий тайма поскольку игра узнает состоянии процессов и никаких неожиданностей случиться не может и есть реализации дают rsp с этого алгоритма но они многопоточное вот мы попробовали его реализовать для многой процесс най среды с какими сложностями мы с этим столкнулись я сейчас скажу но первая сложность она вполне очевидно и сигнал секвилл который может любой процесс в любой момент удалить и ничего мы с этим поделать не можем предположим что мы используем некий счетчик числа читающих процессов для того чтобы сигнализировать пишущим о том что читающие процессы завершились можно писать вот в этом случае читающий процесс получив сетки он не сможет это счетчик уменьшить мы получим рассинхронизацию реального числа читающего процессов и счетчика пишущий процесс в этом случае может ждать до бесконечности пока это счетчик обнулится он не обновится никогда но соответственно очевидным решением обновлять это счетчик после какого тайм-аута но тут вторая проблема я сигнала sextape носик 100 км это предельный случай перегрузки и машины когда процесс очень редко получается об этом мы будем говорить в этих стойках соответственно любой процесс может быть остановлен любой момент на неопределённое количество времени вот есть тут эта ситуация тоже показано то есть в какой то момент мы обнулили счетчик после тайм-аута процесс на самом деле не был удалён com и он в какой-то момент продолжить свою работу это тоже приводит к рассинхронизация этих данных как это происходит более подробно я расскажу низких слайдах соответственно вот остановлюсь читающий процесс начал читать и останавливается пишущий процесс удаляет лего данные данных нет пишущий процесс записывают туда новые данные читающий процесс продолжают чтения и получает не известно что все это приводит к трём сценариям первый сценарий это сиквел если мы хотели прочитать не данные о какую то ссылку соответственно эта ссылка будет вести неизвестно куда и она вполне может вывести за пределы выделенной памяти в этом случае процесс будет ударом пусти к форту второй случай чисто теоретически это бесконечный цикл если эта ссылка ведет не за пределы внутрь выделенной памяти там тоже какие-то случайные данные и теоретический процесс может зациклиться и без конца прыгать по этим ссылкам но на практике это случае либо приведет к дефолту либо приведет к третьему случаю которые с точки зрения процессы самый лучший мы вернем какие-то случайные данные бы считаю что все хорошо но потребитель данных естественно не будет доволен как затем можно бороться можно ли бороться с причиной то в принципе можно то есть мы можем пинговать процессы например сигналом 0 для того чтобы узнать реально ли они удалены или все-таки находятся в системе потом каким-то образом под над их оповещать о том что мы сбросили блокировки но для лука реализации это все достаточно сложный путь и я выбрал несколько контур интуитивное решение лечить последствия можем ли мы лечить последствия как оказалось это не так сложно соответственно проще всего лишь so sick фолд мы поскольку у нас наша структура данных может попасть в адресное пространство любого процесса не каким конкретным адресам она не привязана все внутренние ссылки это некие индексы которые требуют разыменования при разыменование мы можем проверять куда ведет эта ссылка если она ведет не выделенную область соответственно мы чтение начинаем сначала вот и бесконечный цикл и чтения мусора лечится некой процедура которая называется проверка блокировок на следующем слайде я расскажу как у нас встроенной блокировки расскажу в чем заключается эта проверка соответственно наши блокировки состоят из двух бит масок одна активная 2 неактивная в каждый по 16 бит и 32-битном му номе по последовательности фактически номеру операции записи младший бит этой последовательности управляют номером активной бит маски вот мы видим что читающий процесс начала чтения установил 5-ку активной без маски и был остановлен пришел пишущий процесс подождал пока читающие закончил свое чтение он этого не дождался истер его бить их переключил маску их выполнил какую-то операцию если читающий проснётся в этот момент отсутствие вела биты сигнал о том что необходимо начинать перечитывать но это простой случай если очень более сложных он продолжает спать пишущий процесс пришел еще раз переключил маску обратно и пришел еще один читающие увидел свободный бит захватил его в этот момент просыпается 1 читающий и считаю что все нормально раз для этого и нужен номер последовательности если он отличается больше чем на единицу соответственно это сигнал к тому что нужно перечитывать на самом деле с нашей скоростью работы то есть нужно всего несколько минут чтобы последовательность переполнилась и началась начала поэтому для полной гарантии там есть еще одна величина которая считает количество переполнение той последовательности которые тоже нужно проверить однако это можно легко выключить и в принципе на практике она мне кажется не нужно но если нужно прямо полная стопроцентная гарантия той можно и включить я рассказал как у нас синхронизируется читающие пишущие процессы и теперь расскажу как синхронизируется пишущая между собой их соответственно первое что начинает пишущий процесс при операции чтения он получает некий процесс минут x это робот mod x он нужен для того чтобы определить что сам процесс был удалён сиквелом или упал и что потом необходимо выполнить некие действия вот у нас здесь два процесса один из них состоит из трех потоков 2 имеет всего один поток ли простоты соответственно все три потока мировой процесса получил этот смогут дальше работать по своему усмотрению они начинают захватывать блокировки цепочек зачем нужны блокировки цепочек для того чтобы каждый поток мог верить своим регистром потому что чтобы не было ситуации что какой-то поток забрался писать эту цепочку которую мы сейчас читаем у нас данные эти уже находится в регистрах но можно работать через память на это будет значительно медленнее поэтому блокировки на них очень редко происходит столкновение потому что цепочку у нас много но не дают гарантии от того что мы можем использовать верить своим регистру соответственно первый поток у нас начался почитать цепочку 1 2 поток начал читать цепочку два третий поток ожидает цепочку один потом мы оба процесса пел оба потока 1 2 решили что надо что-то поменять и соответственно один хочет выделить память 2 хочет там предположим освободить память и работа с памятью у нас управляется с блокировкой тоже соответственно и в тут видно зачем нужен как раз процесс меток что если эта блокировка найдено в установленном состоянии то соответственно значит сиквел был и необходимо прихоть переходить процедуре восстановления которые я чуть позже расскажу вот соответственно один один из потоков получил блокировку и начал работать с памятью 2 его ожидает теперь блокировка отпущено начал работать памяти второй ответ я начал читать свою цепочку потом все три потока завершились освободили меток и второй процесс нашел чтения но там может быть последующей записью насколько все это эффективно к сожалению все это не очень эффективно тесты показывают что одно ядро естественно используется настой процентов добавление еще одного ядра дает всего 80 процентов 3 игра дает 50 процентов а четвёртое ядро если честно но иногда даже вредит почему это происходит рассмотрим на примере чуть и читателя потому что он попроще что делает читатель когда начинаешь чтения ставит свой билетик что делает когда заканчивать чтение бить их снимает что делать когда начинает следующую чтение в виде вставит опять предположим что все четыре кадра занимаются этим одновременно что получается все эти бить и кирас расположены в одной кошеле не и каждая игра упал и пытается получить эту к селению к себе в кэш состоянием одевает и таким образом это кормление начинает кочевать между играми вызываю задержки на 1-ю передачу через третье время кеша между я мирами а вот соответственно что еще хочется сказать про это что для режима одиночных запросов все это не так страшно потому что это задержка по отношению к глине операции значительно меньше и ядра используется более эффективно а вот этот для пакетного режима можем ли мы как-то с этим бороться мы попытаемся соответственно для пакетного режима для записи если у нас достаточно много ключей обычно у нас достаточно много ключей мы можем канве рисовать их обработку одно ядро будет заниматься кэшированием и сжатием ключ к второе ядро будет собирать кэш промахи чтением и записи эти операции занимают примерно одинаковое количество времени и таким образом это все достаточно хорошо конви рисуется если у нас достаточно много ключей на обработку чтобы постоянно не очень часто переключать буфера вот и все это вместе дает позволяет нам эффективно использовать второе ядро но использование двух таких парочек одновременно не настолько эффективна как использование двух ядер но все-таки для записи это дает некоторый выигрыш для чтения есть еще более эффективной чит он виден на следующем слайде но как вы помните постановка обидчика удаления бить и к постановкам beauty к самое естественное решение петька этот не снимать вообще только проверят не собирается ли кто-то писать соответственно если кто-то собирается писать он изменит номер последовательности и это будет сигнал потому что мысль убить их должны снимать таким образом это пришли не и практически не меняется и в идеальном случае который выглядит так она находится в состоянии шарик между всеми лидерами и я играю на руку не задевает при своей работе и ну используются практически со стопроцентной эффективностью на самом деле не надо сталкиваются на других данных когда работают в таблице но тем ни менее эффективность очень которое решения очень высоко вот но и драться перо процедуру восстановления если какой-то из пишешь процессов был убит но и также нам бы хотелось чтобы наши структура данных переживала выключение питания машины в рабочем состоянии для этого мы периодически пишущие процессы в некий вид маски отмечают и удар измененные области и потом после завершения операции мы скидываем их на диск вот в нормальном режиме это происходит просто в процессе операции записи но если в том случае уже мы обнаружили что какой-то пишущий процесс был удален или вверх уверенно завершён то мы определяем в какой момент он было виррейна завершён если при сохранении на диск у нас в памяти синхронизированная копия и мы воспитываем если в процессе работы с памятью то она находится на диске и мы поднимаем ее за диском работы решения что хочу сказать сначала мы пытались использовать просто дисковые файл из map леной в память и это отлично работало для свежей созданных табличек потому что linux на выделил ровно столько дискового кэша сколько мы хотели мы создавали этот файлом фактически вся наша работа вылазит из кромкой же linux и это все работало достаточно быстро и работала это все очень быстро ровно дыры бута машины после чего лину становился не столь же мира и мы работали с уже существующим файлам и памятью в зеленом не столько сколько бы нам было нужно по фактам и работали в окне то есть он откачивал нужной страницы в дисковый кэш и мы с ними работали вот но это решается административными способами но мы от этого отказались чтобы не усложнять и сделали свою собственную систему синхронизации и используя и того что у нас получилось получилось немножко не то что мы хотели получилось некое быстро и не душу pd получилось некое быстро и ловко описей и получилось кошмар библиотека который настоящий момент может использоваться все их perlen в плюсах естественно тоже но она написана на 70 перли я написал клиенту потому что вас на основных за которыми я пользуюсь на работе этапе сейчас вкратце а то о каждом результате значит если это хотите рассматривать это как библиотеку хэш-таблицы какие у нее есть достоинства у нее есть постоянно копия на диске которая дополняется в процессе работы в отличие от например плюсовых контейнеров которые могут только целиком сохранится реализацию она разделяемая причем они разделяемые не только между потоками но между процессами и она потока и процесса безопасно попробуем сравнить ее производительность чем-нибудь вот мне было интересно сравнить ее с открытой адресации потому что как из первой части доклада помнится что она показывала наименьшее число каш промахов что тут хочется сразу сказать почему он мы проигрываем по записи почему у нас такая медленная записи потому что у нас есть хвост ключа и в процессе добавления ключа мы вынуждены выделять под него память на мою конечно не молоком выделяем но тем не менее каких какой-то цикл на этапе рати поэтому запись у нас несколько медленнее но на самом деле вот этот хвост ключа он нам дает возможность работать с ключами переменной длины с которыми sporting сходишь от гугла работа не умеет вот в тесте в тестах мы не можем показать выигрыш по памяти из-за этого это было бы нечестно но тем не менее вот собственно говоря на это у нас какое-то время записи тратится потом еще очень интересные результаты по памяти соответственно spores hash это табличка которой оптимизирована под использование памяти я на закрытый адресацией шарит из так называется то о чем мы говорим и как видимо использование памяти практически одинаковы в том что мы знаем что у нас на каждый ключ выделено как минимум на четыре байта больше на указатель как так получилось подойти указатель растворились но на самом деле этот немножко отомстил страх ушел выбрав 30 бойцами 132 за то что мы не можем использовать ключи с переменной длиной у них там есть padding два байта у нас его нету соответствие несколько память и память о не пират несколько больше чем мы но из-за того что наши колючки сжимаются соответственно тоже это как-то экономит памяти по быстродействию dance хэш конечно же недостижим потому что он пытается свести количество каш промахов единиц за счет того что выделяет память и и минимизировать коллизий слишком много памяти вот a sports вполне сравним с нашей реализации соответственно для одиночного режима чтение у нас даже чуть-чуть быстрее запись конечно же медленнее для читерского нашего пакетного режима мы в принципе превосходим на записи немножко мили им все-таки как как проводилось тестирование тестирование проводилось в один поток конечно же 10 миллионов ключи и фиксированной длины 30 байт ли мы выключили синхронизацию за диском потому что это но на самом деле оно дает около 10 15 процентов задержки вот и если говорить об этом как о судьбе говорить об этом как о свободы нельзя потому что функционал практически нет никакого крайне беден она что сравнивать лопату с бульдозером но поскольку мы все-таки это используя в качестве сободы то по крайней мере можем поверить в америке с какой скоростью наша лопата умеет копать соответственно копать она умеет с такой скоростью чтение мы можем выполнять 21 миллион запрос в секунду запрос в нашем случае это обращение копье или почти со скоростью 80 миллионов ключи в секунду на восьмиядерном к фионе до чистота его гипертрейдинг не используется потому что hyperthreading для поточного режима и практически ничего не даёт на кэш промахи мы обрабатываем сами ямки миру просто некогда простаивать numa очень тоже отрицательно влияет то есть если эту штуку запускать то надо постараться чтобы все потоки были процесса были на одном но мало ли соответственно у меня там в тезисах был за сколько мы определяем что изменилось за не ком мы это можем определить примерно за две с половиной секунды вот ему и соответственно для своих доменах мира на самом деле не всех потому что мы все таки не сто процентов покрываем их за 6 половиной секунд мы можем определить что поменялось у них в их состоянии за сутки и записи конечно же медленнее мы имеем 15 миллионов запросов в секунду обращение к пин для 8 ядер 30 миллионов ключи всего в секунду ну и то же самое для за на ком для всех домен вот если говорить об этом какой песне но она достаточно быстро то есть она работает фактически со скоростью футокса и копирования памяти вот это мы там сделали лоб free очереди но об этих лагерей очередях надо рассказывать отдельный к нам уже мы сделали достаточно давно последней итерации разработки не не затронули но тем не менее они там есть я просто говорю об этом как факт но проблема наши в том что у нас вообще нет блокировок никаких и для того чтобы синхронизироваться приходится постоянно либо перечитывать очень ради либо перечитывать ключ процесса синхронизируются по схеме который вы можете видеть на слайде почему они так синхронизируются чтобы два процесса которые пишут одновременно в одно и то же базу данных между собой не взаимодействовали таким образом на каждый процесс есть своя база данных которой он может писать все остальные из нее могут читать вот что дальше ну соответственно если развивать это как зубы д то он неплохо бы добавить как минимум вторичные индексы и неплохо бы добавить какой-нибудь яндекс по которому можно было бы сортировать свои вторично индекса на базе хэша выглядит эта задача не сложно а вот вторичная индекс сортировка это практически вся та же работа только с другим типом индексом с каким-то деревом тоже анализировать как они там мышлением размещаются пытаться то оптимизировать то есть это долгая работа если развивать это сторону лук в песне то необходимо добавить блокировки на самом деле вот я поскольку работаю сверлом эта штука самое лучшее из того что я могу сперли использовать потому что реально у него синхронизации процессов и стандартно библиотеках очень страдает вот если это развивать как шмаль библиотеку то мои коллеги собирались написать модуль для питон ближайшие несколько месяцев ноги для go может быть напишут несколько попозже вот что еще можно об этом сказать то что ну в ближайшего наверное неделю может быть месяц мы собираемся выложить это вот на source и вы сможете с нами поиграться с этим проверить все что я вам рассказал вот когда это случится если вы хотите чтобы вас об этом оповестили можете написать мне письмо видно на слайде мои рабочие почта и тогда я вам пришлю когда мы все это выложу ну или поискать это на нашем сайте я думаю что об этом тоже там будет сказано вот спасибо у меня все можете сдавать свою опросу можно в микрофон подождите пожалуйста практическое смесь изменения к могильники шею вас системы как вы вводили да но там же был был слайд на котором было быстродействие версии с цепочками простой и быстродействия конечно версии мы это методы через профилирование то есть фактически и задержки на максимально занимали это занимали те функции в которых выполнялось обращения к памяти на обращение к памяти вот ну я вот их посчитал как бы теоретически на самом деле так как манере нет но как и с кого увеличение скорости быстродействия также то что скорость записи скоро чтения stroller стали различаться они в принципе на практике от теории подтверждают я дома практически измерения ещё вопросы есть евгений здравствуйте прежде всего хотелось бы сказать что работа какое-то очень колоссальную проделали конечно не все слушать космический корабль вопрос мне следующий вы не рассматривали вероятностью возможность использования других типов данных вроде как при висках деревьях которые казалось бы на эту задачу очень хорошо ложатся имея каких-то таких для рефлекс на и деревья но в общем то она просто революционный развивалась то есть мы сначала сделали некое простое решение с хэш-таблицы потом уже фактически решив бизнес-задачи мы удовлетворили свое любопытство поэтому я и рассказываю о том что получилось на самом деле другие индексы мы будем пытаться использовать и будем проводить на туалет на ту же самую работу вот но так что до ответ что мы не рассматривали потому что у нас как бы не было к этому каких-то мотивов я понял пасибо вопросов больше нет ну если вдруг возникнут то у нас есть дискуссионная зоны то можете их задать а так спасибо вам большое вот благодарности подарок спасибо и нужно выбрать лучший вопрос ведь во все таки вот этот вопрос получше"
}