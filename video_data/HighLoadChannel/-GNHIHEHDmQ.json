{
  "video_id": "-GNHIHEHDmQ",
  "channel": "HighLoadChannel",
  "title": "Типовые ошибки в приложениях, которые ведут к bloat в postgresql / Андрей Сальников (Data Egret)",
  "views": 5970,
  "duration": 3087,
  "published": "2018-11-20T12:26:40-08:00",
  "text": "nazik препятствовать и а не такой тический как предыдущая теги этот доклад ориентирован на разработчиков бэкон систему в основном потому что у нас достаточно большое количество клиентов и все они совершают одни и те же ошибки о них я вам расскажу и расскажу почему фатальный мой бахрома ведут эти ошибки почему совершаются такие ошибки совершают свой они по двум причинам на 8 может так пара кальцит и от не знание каких-то механизмов которые происходят на уровне между базой и приложениям и в самой базе я вам три примера приведу с ужасными картинками того как все стало плохо кратце расскажу о механизмах которые там происходит и как с ними бороться когда они случились и какие берлин тивные методы использовать для предотвращения ошибок немножечко помогать сильные инструменты и полезные ссылки буду итак начнем первая история которой мы забываем про закрытой транзакции про открытой транзакции пол згрлс sql я использовал тестовую вас заданных где у меня было две таблички одна табличка с счетами клиентов другая с операциями по этим счетам и с какой-то периодическом периодичностью мы обновляем остатки на этих счетах исходные данные таблички она достаточна небольшая 2 мегабайта время ответа по базе и конкретно по табличке тоже очень хорошая и достаточно хорошая нагрузка две тысячи операций секунду по табличке и сквозь издал как я буду вам показывать графики чтобы наглядно было понятно что происходит всегда будет два слайда с графиками первый слайд это у нас что происходит в общем на сервере и в данной ситуации мы видим то что у нас действительно табличка небольшого размера индекс небольшой это первый вид слева график 2 мегабайт и как положено среднее время ответа по серверу она тоже стабильное небольшое это справа верхний график левый нижний график это длительность самый длинный транзакции мы смотр видим что транзакция быстро выполняются и авто в комнату тут он еще не работает потому что это был старт теста дальше он будет работать и будет полезен нам второй слайд всегда будет посвящен испытуемые таблички в этой ситуации мы обновляем постоянно остатки по счетам у клиента и мы видим то что средние время ответа операция обновления она достаточно хорошие меньше миллисекунды видим что брат ресурсы процессора это справа верхний график потребляется тоже равномерное и достаточно небольшие справа снизу график показывает сколько памяти мы памяти операционной и дисковый перебираем в поисках нашей нужные строчки прежде мы ее обновить и количество операций по табличке 2000 секунду как игр вначале говорил и теперь у нас происходит трагедия по какой-то причине возникает длинная забытое транзакция причин на самом деле бывает все они банальные и укладываются в это сам одна из самых распространенных то что мы в при уважении в коде начали обращаться к внешнему сервису и этот сервис нам не отвечает мы открыли транзакцию сделали изменению базы и пошли не знаю там из приложения почту почитайте или все к другому сервису в рамках нашей инфраструктуры и он по какой-то причине нам не отвечает и у нас повезу сессия в состоянии неизвестно когда разрешится вторая ситуация когда у нас коде по какой-то причине произошел exception-ы мы в эксепшен и не вы работали закрытие транзакции и у нас он получилось светящиеся сессия с открытой транзакцией и последний тоже довольно дочь частые случаи это ничего не некачественный к довольно часто некоторые фреймворке открывают транзакцию и она висит и вы даже можете не знать приложение что она о зависит к чему ведут такие вещи то что у нас начинает резко раздуваться таблицы и индексы это как раз тот самый эффект болта для базы это будет выражаться в том что у нас очень резко увеличится время ответа база данных увеличится нагрузка на сервер базы данных и как итог у нас будет страдать приложению потому что если у вас в коде вы строитель 10 миллисекунд на запрос базу 10 миллисекунд на свою логику у вас функция отработал 20 миллисекунд а сейчас у вас ситуацию будет совсем печальная и давайте посмотрим что происходит левый нижний график и нам показывает то что у нас есть длинная долгая транзакция если мы посмотрим на левый верхний график то мы видим что размер таблицы ю с 2 мегабайта у нас резко скакнул 300 мегабайт при этом количество данных таблицы не изменилось то есть там достаточно большое количество мусора общая ситуация по среднему времени ответа сервера тоже у нас изменилась на несколько порядков все запросы по серверу начали капитально председатель и при этом запустили с внутренней процессору процесс ip-адреса видеть в лице автор вакуума который что тут пытается делать и потребляют ресурсы что же с нашей табличке происходит тоже самое зрение время ответа по табличке у нас скакнул на несколько порядков вверх если конкретным употребляемым ресурсам то мы видим что очень сильно увеличилась нагрузка на процессор и увеличилась а нам это правую правый верхний график увеличилась а нам потому что процессору переходится перебирается кучу бесполезных строчек которые в поисках 1 нам нужны это правый нижний график и как результат количество вызовов секунду у нас начало просаживаться осень сильно потому что база просто не успею не успевает обрабатывать тот же количество запросов собственно нам надо возвращаться в жизни лезем в интернет узнаем что длинные транзакции приводят к проблеме находим мы убиваем эту транзакцию и у нас все становится нормально сервисного задышал всё работает как надо мы успокоились но через некоторое время начинаем замечаем что приложение на самом деле работает не так же как это было до аварийной ситуации запросы обрабатываются все равно медленнее причем существенно так может обрабатываться полтора-два раза конкретно в моем примере нагрузка на сервер тоже выше чем было до аварии и вопрос что же на самом деле произошло что там с базы происходит в этот момент а с базы происходит следующее ситуация на графике с транзакций вы видите что она остановилась и действительно там нету длительных транзакций но размеры таблички во время аварии у нас фатально выросли из тех пор не уменьшились и они не уменьшится у нас среднее время по базе стабилизировалась и ответы вроде ходят адекватно и с приемлемой для нас скоростью of the vacuum стал более активным и начал что-то делать с табличкой потому что ему нужна перелопачивать больше количество данных конкретно по иску и toomai таблички с читами где мы заменяем остатки не знаю насколько вам хорошо видно время ответа на запрос у вроде бы вернулась норму но на самом деле она в полтора раза выше но вот по нагрузке на процессор мы видим что нагрузка на процессор она не вернулась точно в нужную величину до аварии и причины там кроется как раз вот в этих прав графиках правым нижним видно что там происходит все равно перебор какое-то количество памяти то есть для поиска нужны строчке мы тратим ресурсы сервера базы данных для перебора каких-то бесполезных данных количество транзакций секунду стабилизировалась но в общем хорошо на ситуацию хуже чем было явное деградация как бы база данных как следствие нашего приложения который работает с этой базой данных и чтобы разобраться что там происходит если вы не были на предыдущем докладе то сейчас немножечко теория теория о процессе внутренним of the vacuum зачем он и что он делает буквально вкратце для понимания какой-то момент времени мы имеем таблицу в таблице у нас находится строчки эти строчки могут быть состояние нужные нам активные живые прямо вот сейчас нужны на картинке они помечены зеленым цветом и есть строчки мертвые которые уже отработали были обновлены по ним появились новые записи анапа меч и на как уже не интересны и базе данных но лежит таблицы из особенностей модели вести поиск по сгрыз а зачем нужен of the vacuum of the vacuum какой-то момент у нас приходит обращается к базе данных и спрашивает ее дай мне пожалуйста 1 самой старой транзакции которая открыта на данный момент базе данных базы данных возвращает этот айди и of the vacuum опираясь на него перебирает строчке в таблице и если видит что какие-то строчки были созданы изменены транзакциями куда более старыми он имеет право их пометить как для приз строчки которые мы можем переиспользовать в будущем записать туда новые данные мы в это время это фоновый процесс мы в это время продолжаем работать с базой данных какие-то изменения в таблице производить и вот на эти строчки которым можем переиспользовать мы постоянно мы записываем новые данные и таким образом у нас получается круговорот место в табличке то есть все время там возникают какие-то мертвые старые строки вместо них мы записываем новые строки которые нам нужны и это нормальное состояние для работы по сгрыз sql что же произошло у нас во время нашей аварии как там парк происходил этот процесс мы имели табличку в каком-то состоянии какие-то живые какие-то мертвые строчки пришел of the vacuum он также спросил базу данных о том какая у нас самая давняя транзакция какой у нее айтишник получил этот айдишник который может быть многочасовой давности может там 10 минутный все зависит от того насколько сильной нагрузку вас базе данных и пошел искать строчки которой он может помечен как перри используемые и не нашел таких строчек наши таблицы но мы в это время продолжаем работать с таблицей что-то делаем обновляем меняем данные а что в базе данных в это время делать и ничего не остается как дописывать новые строчки в конец существующей таблицы и этим самым у нас размер таблицы начинает раздуваться реально нам для работы нужны зеленые строчки новое время вот такой проблемы у нас получается что процент зеленых он крайне низок во всем объеме таблицы когда мы выполняем запрос базе данных переходится пробегаться по всем вот этим вот и и красным и зеленым строчкам в поиском поисках нужные нам строчки и вот этот эффект раз раздуть и таблица бесполезными данными называется как раз blood который еще и живет наши дисковое пространство ну то есть помнится 2 мегабайта 300 мегабайт а теперь мегабайты на гигабайт и поменяйте и вы так достаточно быстро решитесь всех запасов своих дисковых ресурсов собственно как как как этот болт какие последствия для нас таблицы яндекс вот в моем примере 150 раз выросли у некоторых наших клиентов бывали более фатальной случай когда просто места на диске начинало заканчиваться размер размер таблиц сам по себе никогда не уменьшится of the vacuum некоторых случаях может отрезать хвостик таблицы если там только мертвые строчки но так как происходит постоянная ротация и 1 зелененькой строчка может конце зависнуть и не обновляться а все остальные они там где в начале таблички будет записываться но чем это настолько мала вероятность события что у вас само по себе таблицы уменьшится в размерах что не стоит на это надеется соответственно базе данных нужно перебирать вот эту вот всю кипу бесполезных строчек уже ненужных и этот мы тратим дисковые ресурсы тратим ресурсы процессора и собственно говоря электроэнергию и это непосредственно влияет на наши приложению потому что если вначале мы тратили действие или секунд на запрос 10 миллисекунд на наш код во время аварии мы стали строить тратить секунду на запрос 10 миллисекунд на код то есть как бы на порядок у нас производительность при выражении напрямую снизилась то когда разрешили аварию у нас 20 миллисекунд на запрос 10 миллисекунд на код все равно мы просили в полтора раза по производительности и все собственно говоря из-за какой-то одной транзакции которую подвисла причем панель во наши живи нем вполне возможно и вопрос собственно как эту ситуацию вернуть назад чтобы нам стало все хорошо и у нас ну достаточно быстро за бегали за быстро также когда варить обед или запросы и мы были могли спокойно спать собственно для этого есть определенный цикл работ который проводится 1 на перво нам необходимо найти и проблемные таблицы которые раздулись ну мы понимаем то что как каким-то таблицам запись идет более активно по каким-то менее активно и для этого используется расширение и g-100 от apple в подгрести установив это расширение вы можете написать запросы которые помогут вам найти таблицы которые раздули за достаточно сильно после того как вы нашли эти таблицы их необходимо сжать для этого есть уже инструменты наши компании мы используем три инструмента 1 встроенный вакуум full жестокие суровы и беспощадны но иногда он очень полезен при джерико крепок и пиджака по ногтей бал это сторонние утилиты для сжатия таблиц и они более бережно относятся к базе данных используются в зависимости от того что вам удобней но это я расскажу в самом конце главное что три инструмента есть есть из чего выбрать ты хорошо и после того как мы все поправили убедились что все хорошо стало у нас снова мы должны знать как предотвратить нам эту ситуацию будущем предотвращается она достаточно легко нужно следить за акции длительностью сессий на мастер сервере особенно опасны и сессии в состоянии down transaction это те которые как раз открыли транзакцию что-то сделали и ушли курить и пить чай и там что то делать ожидать другой сервис или просто повелись потеряли один и для вас как для разработчиков важно тестировать код на момент возникновения данных ситуаций принципе это не сложно сделать моделировать ситуацию очень полезное важная проверка будет для вас избежите достаточно большинство детских проблем вот таких связанных с длительным транзакциями на этих графиках я вам хотел показать как изменилась табличка и поведение база данных после того как я прошел в данном случае wacom форум по табличке ну вот у меня все таки не продакшен видите что размер таблицы вернулся сразу нормальное состояние рабочее там пара мегабайт на средние время ответа по серверу это не сильно повлияло ну вот конкретно по нашей испытуемой таблички где мы обновляли остатки на счетах мы видим что среднее время ответа по запросу обновления данных таблички она сократилась до уровня до аварийного уровня ресурсы потребляемые процессором на выполнение этого запроса тоже упали до аварийного уровня и правый нижний график нам показывают что сейчас мы находим ровно ту строчку которую нужно нам сразу не перебирая вот этот вот скоб мертвых строчек который был дожать и таблицы и среднее время запрос примерно на том же уровне осталось ну тут у меня скорее погрешность моего железо на этом первую историю закончилась она самое распространенное и случается у всех вне зависимости от опыта клиента на сколько там квалифицированные программисты рано или поздно это происходит история вторая мы уже выросли стали серьёзными ребятами и понимаем что у нас есть как у серьезных ребята реплика и что хорошо бы нам сбалансировать нагрузку писать на мастер с реплики читать то что мы можем читать и обычно эта ситуация возникает когда мы хотим готовить какие-то отчеты или тел и возник и бизнес этому очень радуется он хочет хочет разнообразных отчетов с кучей аналитики всякой сложный и мы говорим хорошо мы ну а чё там многочасовые потому что сложную аналитику не почитают за миллисекунды мы как бы ребята пишем код делаем в приложении вставки то что запись мы идем на masters отчеты выполняем на реплики распределяем нагрузку все у нас хорошо и все работает отлично мы молодцы и как эта ситуация выглядит конкретно на этих графиках я еще для длительности транзакций добавил длительность транзакции с реплики все остальные графики они относятся только к мастер серверу как бы акцентирую на это внимание таблички со щитами к этому моменту у меня подросла я стал больше но мы видим что средние время ответа сервера она стабильна и мы видим что на реплики у нас есть длительная транзакция которая работает два часа по моему до 2 часа видим спокойную работу авто ваку может который обрабатывает мертвые строчки и все у нас хорошо конкретно по испытуемый табличке мы продолжаем там обновлять остатки на счетах этаже у нас стабильное время ответа по запросу стабильные потребление ресурсов все у нас хорошо все хорошо до момента пока у нас эти отчеты не начинают отстреливаться по конфликту с репликации и отстреливаются они с постоянной периодичностью мы-то лезем в интернет и начинаем читать почему это происходит и находим решение первое решение увеличить за задержку рипли кации мы знаем что у нас отчет работает три часа ставим задержку репликации три часа запускаем все но у нас все равно продолжается проблемы с тем что отчета иногда отстреливаются мы хотим чтобы у нас все было идеально лезем дальше читаем в интернете находим такую классную настройку как вот стенд бай фидбэк включаем его вот стенд бай фидбэк позволяет нам придержать работу авто вакуума на мастере тем самым она мы совсем избавляемся от конфликтов репликации и у нас все работает хорошо с отчетами а что же в это время у нас происходит с мастер сервером а с мастер сферу раму нас происходит тотальная беда сейчас мы наблюдаем графики когда я включила убийцу настройки извините и мы видим что сессия на реплики у нас каким-то образом стал влиять на ситуацию на мастер сервере действительно ли а потому что она приостановил of the vacuum который вычистить вычищает мертвые стройке у нас размер таблицы снова скакнул в дебеза средние время выполнение запросов по всей базе данных не конкретно по наш таблицами по всей базе данных тоже скакнул в небеса of the vacuum и чуть-чуть под напряглись конкретно по нашей табличке мы видим то что по ней обновление данных тоже скакнул в небеса потребление ресурсов процессора аналогично очень сильно увеличилась опять же мы перебираем большое количество мёртвых бесполезных строчек и время ответа по этой табличке количество загса секунду упала снова просел как это будет у нас выглядеть если мы не знаем о том что о чем я говорил до этого мы начинаем искать проблемы если мы сталкивались с проблемой в первой части мы знаем что это может быть причина в длины транзакций и лезем на мастер проблема у нас на мастер и колбасит его он греется у него или под 90 под сотню запросы там тормозят но мы там не видим никаких длительных транзакций не починить не понимаем в чем дело где где же искать начинает подцеплять всех специалистов очень проверяем серверное оборудование может у нас развалился рейд может у нас горела планка памяти да что угодно нет сервера новые все работает отлично бегают все администраторы разработчики даже директору там в итоге приходит может он поможет ничего не помогает и в какой-то момент все на неожиданно сама начинает исправляться как это дело происходит на практике на реплики у нас в это время запрос отработал ушел мы получили отчет бизнес все еще довольны выправление ситуации как видим табличка у нас выросло с новой и не собирается уменьшаться на графике сессиями вы видите я оставил специально кусочек вот этой длины транзакции с реплики чтобы вы могли оценить насколько длительное время проходит пока ситуация стабилизируется сессия ушла и мы не сразу а только через какое-то время сервер приходит более менее в порядок и средние время ответа по запросам на мастер сервер и приходят в норму потому что наконец-то of the vacuum получил возможность вычищать помечать эти мертвые строчки и он начал делать свою работу и насколько быстро он ее делает настолько быстро мы придем в порядок по испытуемые таблички где мы обрамляем остатки по счетам мы видим что точно такую же картину средние время обновление счета по иску тоже нормализуется постепенно но ресурсы потребляемые процессором перебор памяти дисковых систем он тоже уменьшается и количество транзакций секунду возвращается в норму но опять-таки в норму не такую какая она была у нас до аварии мы в любом случае получаем просадку пары производительности как и в первом случае там в полтора-два раза а иногда и больше и вопрос собственно гора а как делать правильно мы вроде сделали все правильно распределили нагрузку как бы оборудование не простаивает пуму разбили запросы и все равно все плохо получилось не включать фото нба и фидбэк до его в принципе никогда без специально особых сильных причин не рекомендуется включать потому что этот крутилка который непосредственно влияет на мастер сервер и приостанавливает работу авто вакуума там включив его на какой-то реплики забыв про этого может себе убить мастер и получить большие проблемы с приложением увеличивать max and streaming белый до для отчетов это так если у вас трехчасовой отчет вы не хотите чтобы он у вас подавал язык конфликтов репликации просто увеличьте задержку длительный отчет о он у вас никогда не требуют данных которые пришли базу прямо сейчас если вы его запуск он у вас трехчасовой значит вы его запускаете за каким-то старым периодом данных и вам что три часа задержки что 6 часов задержки никакой роли не сыграет но зато вы будете стабильно получать отчеты и не знать проблем с падением их естественно нужно контролировать длительные сессии на репликах особенно если вы все таки решили включить hot 100 нба и фидбэк на реплики что может быть что угодно дали эту реплику разработчику чтобы он протестировал запросы он написал сумасшедший запрос запустил и ушел пить чай а мы получили сложившейся мастер или мы туда пустили не то приложение ситуации разнообразны здесь и на репликах необходимо контролировать также тщательно как на мастер и и если у вас есть быстрые и длительные запросы которые вы отправляете на реплику то в данном случае лучше для распределения нагрузки разбить их это как бы ссылочка как streaming davey для быстрых иметь одну реплику с небольшой задержкой репликации для длительных запросов отчетных иметь реплику который может отставать на шесть часов на сутки это вполне нормальная ситуация устраняем последствия все тем же способом находим раздутые таблицы и сжимаем наиболее удобным инструментом которые нам подходят истории 2 на этом завершилась переходим к истории 3 тоже довольно обычный для нас который мы делаем миграцию любой программный продукт он растет меняются к нему требования мы в любом случае хотим развиваться и в некоторых ситуациях возникает некоторые ситуации бывают такие то что нам необходимо обновить данные в таблице именно прогнать апдейт в плане наши миграции под новый функционал который мы для этого который мы внедряем в рамках нашего развития старый формат данных не устраивает допустим сейчас мы обратимся к 2 таблички мои тестовые базы данных где у меня операции по этим счетам и давайте допустим они были в рублях а мы решили повысить точность и делайте в копейках и для этого нам нужно сделать апдейт полиса суммы операции умножив его на 100 мы современном мире используем естественно автоматизированные средства контроля версий данных допустим liked bass прописываем туда нашу миграцию тестируем ее на наши тестовые базе все отлично апдейт проходит блокируют работы на некоторое время но зато мы получаем обновленные данные вот и можем запускать новый функционал на этом все тестировали проверили все подтвердили провели плановой работы провели миграцию вот собственно говоря миграция с апдейтом представлена перед вами то есть да да это мы имели в этот раз так как это у меня операции по счетам табличка 15 гигабайтный была там в таком пределе соответственно так как мы обновляем каждую строчку мы апдейтом раздули табличку в два раза потому что мы перезаписали каждую строчку на время миграции мы естественно ничего не могли делать с этой табличкой потому что все запросы к ней встали в очередь и ждали пока закончится там д ну тут я хочу вас просто обратить внимание на цифры которые на графике на вертикальных на вертикальной оси мы имеем средние время запроса о миграции в районе 5 миллисекунд и нагрузки на процессор и количество булочных операций по чтению памяти дисков в районе меньше чем семь с половиной что ж у нас провели миграцию мы получили снова проблемы операция прошла успешно у нас все хорошо но старый функционал который мы просто повесили точность он стал выполнялся дольше все равно ну как и таблица снова выросла размерах нагрузка на сервер снова стало больше чем было ранее и естественно как бы мы еще пока возимся с тем функционалом который работал хорошо мы его немножечко улучшили и это сноуборд который нам снова и портит жизнь вот собственно тут я демонстрируем то что таблица как в предыдущих двух случаях не собирается возвращаться к предыдущим размером средняя нагрузка по серверу вроде бы адекватная а вот если мы обратимся к таблице сочетаем со щитами то мы увидим что в летнее время запроса у нас выросло в два раза этой табличке нагрузка на процессор и нагрузка на и количество перебираем их строчек памяти скакнул выше семи с половиной а была ниже и скакнул случае процессора 2 раза в случае брошенных операций в полтора раза то есть мы получили деградацию производительности сервера и как следствие деградацию производительности нашего приложения при этом количество вызовов а например на уровне осталось и тут главное понимать как правильно делать такие миграция их приходится делать как бы мы довольно постоянно делаем эти миграции 1 на 1 такие большие миграции никогда не делаются автоматически они всегда должны быть подконтрольны и необходим контроль со стороны знающего чувак человека если у вас есть деньги команде пускай это делает себе это его работа если нет то наиболее опытный человек который знает как работать с базами данных новую схему базы данных даже в случае если мы обновляем один столбец мы по всегда подготавливаем этапами то есть заранее до того как выкатиться новые приложения версия приложения конкретно с обновлением поли таким большим мы всегда добавляем новую поле в которой будем записывать как раз обновленные данные и переносим данные старого полю в новые поля небольшими частями адекватными почему мы это делаем первый на пиру мы всегда контролируем прогресс этого процесса мы знаем что мы перенесли уже столько baci и нам осталось только там а второй положительный эффект чтоб между каждым таким бо чем мы закрываем транзакцию открываем новую и это дает возможность авто вакуума отработать по табличке и пометить мертвые строчки каперии использованию для строчек которые будут появляться в процессе работы приложениям у нас еще работает старое приложение добавляем триггер который записывает сразу и старой формате которые приложения передал данные и в новую поле уже там нашем случае умноженное на 100 если мы совсем упертые хотим то же самое имя поля то по завершению всех миграций и перед накатом но версии версии приложения мы просто переименовываем поля старая там в какой-нибудь придуманное название новые полю переименуем старое и после этого уже только запускаем новую версию приложения и при этом мы не получим болота и не про сядем по производительности на этом третья историю закончилась и сейчас немножечко более подробно в инструментах которые я упоминал самой первой истории для того как искать бот нужно обязательно поставить расширение пиджи 100 от того чтобы вам не придумывать запросы мы в своей работе уже написали эти запросы вы можете их использовать тут представлен два запроса 1 довольно длительно работает но зато он вам покажет точные значения болото по таблице 2 он работает побыстрее и очень эффективен когда нужно быстро оценить есть голод не будет болтон по таблицам если у вас ну еще вы должны понимать что блок в таблицах под бриз есть всегда это особенностью его модели и в сети и 20-процентный голод это нормально для таблиц большинстве случаев то есть вам не стоит переживается сжимать эту таблицу очень как выявлять таблицы которые у нас распухли мы разобрались причем распухли бесполезными данными о том как из исправлять болт если у нас небольшая табличка и хорошие диски на о чем на табличках там до гигабайта вполне возможно использовать вакуум full возьмет он у вас блокировку на таблицу эксклюзивную на несколько секунд и ладно зато быстро все сделать жестко что делает вакуум full он берет эксклюзивную блокировку на таблицу и из файлов старых старых файлов таблицы переписываются живые строки в новую таблицу и в конце подменяет их местами старые файлы удаляют новый старт подставляет вместо старых но на время своей работы он берет эксклюзивную блокировка таблицы это означает для вас то что вы с этой таблице ничего не сможет сделать ни писать ни и не читать в нее не модифицировать и и следующий и как сами понимаете вакуум full требует дополнительное место на диске чтобы записать данные куда-то следующий инструмент пиджи репак по своему принципу он очень похож на вакуум full потому что он тоже берет переписывать данные из старых файлов новый и подменяет их таблицы но при этом не берет эксклюзивную блокировку на таблицу в самом начале своя работа оберет только в момент когда у него уже готовые данные для того чтобы просто подменить файлики требования по дисковым ресурсам у него аналогично какого кумполу вам нужно дополнительное место на дисков а это иногда бывает критично если у вас терабайтный таблицы и довольно прожорлив по процессору потому что как бы ведет активную работу с вводом-выводом 3 утилиты пиджи компактный была она более бережно относится потому что к ресурсам потому что работает немного по другим принципам эти комплекты вел основная суть у него в том что он апдейтами в таблице переносит все живые строки в начало таблицы и потом запускает вакуум по этой таблице потому что мы знаем что у нас начали живые а в конце мертвые строки его там уже сам отрезает этот хвостик то есть дополнительного дискового пространства он не сильно требует и при этом его еще можно по ресурсам ужимать потребляемым с инструментами все если вам тему blow то покажется интересной пони покопаться дальше внутрь то вот вам некоторые полезные ссылки первые ссылка этот доклад моего коллеги он вообще общее о том куда девается место тупо згрлс процессе его работы и жизни и там очень большой подробный кусок технически для администраторов баз данных есть область вторая ссылка это ссылка на наш repository где мы храним кучу полезных скриптов на проверку состояния база данных там вы можете найти скрипты и по поиску голод и третья ссылка это третье-четвертое на инструменты которые вам помогут ужимать таблички и последнее это пост моего коллеги там он довольно серьезный подробно технически разбирают болт именно уже на уровне ближе близким к администраторам я тут постарался показать больше страшилку для девелоперов потому что они являются непосредственными нашими клиентами именно базы данных и должны пониматься почему какие действия ведут надеюсь у меня это получилось спасибо за внимание на этом я все вопрос спасибо за доклад по поводу висячих вопросов и говорили о том как можно выявлять проблемы а как их можно предупреждать то есть у меня была ситуация когда запросы висели не только по причине того что они обращались каким-то внешним сервисом это были просто какие-то дикие join и например невероятно были какие-то просто в малюсенькие запросы безобидные которые сутки висели например потом они начинали творить какую-то ерунду то есть но очень похоже на то что вы описываете ну ну то есть как это отслеживает сидеть постоянно смотреть какой запрос завис или как вообще это все предупредить но в данном случае это задача для администраторов ваша компания не обязательно де беф это может быть просто для администратор нужно мониторить запрашивают в postgresql есть такое представление пиджи startactivity в котором показаны висящий запросы и вы можете и вы можете увидеть на сколько долго он там висит если он у вас бить по крону настройте короны проверяйте если у вас возник длительный запрос пишете письмо и всего то есть вам не нужно как бы глазами смотреть это можно автоматизировать вам придет письмо вы уже как на alert на него реагируете а можете автоматически отстреливать отец и ну вот я не которые перечислил другие они просто более сложные примеры и там разговор надолго просто может быть спасибо за доклад я вот сзади про утилиту пиджи рипа если он не делает эксклюзивную блокировку получается я он делает эксклюзивную где потенциально могу потерять данные то есть мое приложение в это время не должно ничего запись записывать with the blind она спокойно работает с таблицей то есть и жили по переносят сначала все живые строчки которые есть естественно там какая-то запись таблиц происходит он просто хвостик закидывает то есть вам в конце все-таки делать в конце он берёт эксклюзивную блокировку на то чтобы поменять местами вот эти файлы у нас или кратковременная лаком full он как стартанул за эксклюзивную блокировку и пока он сегодня сделает он и не отпустят и и опять же рыбак берет эксклюзивную блокировку только на момент замены файлов то есть в этот момент вы туда не запишите но как бы данные не потеряете все в порядке будет здравствуйте я сзади у вас да да да да просто к вы рассказывали про работу of the vacuum и там была график красная желтая и зеленая тщательная записи да да то есть вот эти желтые тона пометил как удаленные и вследствие в них можно что-то записать новый да смотрите как происходит вести модельки мозга раз он не удаляет строчки специфика такая у него то есть если мы обновили строчку мы старые пометили как удаленно там встает айтишник транзакции который который изменил эту строчку и записываем новую строчку какой-то момент вот эти старые у нас есть если которые могут потенциальных читать какой-то момент мы уже но они совсем старыми становятся и of the vacuum его суть работы в том что он продвигается вот по этим строчкам и помечает их как ненужными и туда можно перезаписать данные я понял на вопрос немножко не в этом говорил предположим что у нас таблица мне есть поля переменного мира там джейсон б xd varchar или что нибудь такое бинарные просто грубо говоря если я попытаюсь что-то вставить новые то он может просто 2 3 чикконе влезть получается что в таком для таких нет там любом случае вся строчка обновляется ей postgresql есть две модели хранения данных ну то есть он там выбирает от типа данных есть данные которые хранятся непосредственно таблицы а есть еще так называемый тос данные это большие какие-то объемы данных там текст те же самые джейсон и они хранятся в отдельных табличках и по этим табличкам происходит та же история с болтом то есть все то же самое вот просто отдельно не вынесено спасибо за доклад я здесь позади вас да да да да подскажите пожалуйста на сколько приемлемо использовать для ограничения длительности запроса очень приемлемо мы везде это используем причем так как мы но у нас своих сервисов нет мы как бы удаленную поддержку от source а оказываем то есть довольно разнообразны и клиента и всем вполне достали творят это из у нас есть задание в короне который проверяет просто с клиентом оговаривается длительность сессии которые но раньше которой мы не прибиваем это может быть минута это может быть 10 минут зависит от нагрузки на базу ну и и цели для чего она используется но у всех мы используем бюджета стать 100 единиц до этого поста то activity спасибо за доклад я тут пытаюсь примерить ваш доклад к своим приложением и вроде бы мы везде стартуем транзакцию везде явное и завершаем если какой-то exception тату все равно rollback происходит вот но тут я задумался и ведь им может транзакция стартануть они явно это подсказку опять же к девушке да наверно если я просто делаю обновление записи транзакция стартанет ведь по сгрыз курили и завершится на только тогда когда произойдет отключение соединения это зависит если вы говорите сейчас об уровне приложения это зависит от того драйвер который вы используете а то время который используется там очень много настроек если у вас включен авторами тонда таунта там на транзакцию ну просто на апдейт он стартует транзакция тут же закрывается закрывается она сразу после апдейта зависит очень от настроек вот одну настройка сказал авторами тон она довольно распространенная то есть если она включена то открылось закрылась транзак если вы явно не сказали 100 шт анзак шин ён транзак а просто запустили там сессию запрос ну-ка хорошо спасибо 1 раз здравствуйте спасибо за доклад а у меня к вам такой вопрос а представим что у нас есть база которую пухнет пухнет и пахнет и тут на сервер кончается место вот если инструмента чтобы исправить такой ситуации вообще если жизнь после такой ситуация вообще места на сервере надо в хорошем мониторить теперь пошел пить чай был на грудь но смотрите когда создается файловая система там как минимум какое то резервное место резервируется место куда не пишется данные оправился 7 под ноль ну там пока называется резерве dspace то есть его можно освободить и вы получите в зависимость от того насколько большим его создали честно говоря по умолчанию не знаю сколько а в другом случае ну доставлять диски чтобы у вас было место провести операции восстановительные нее можно tranque пнуть таблицу какую-нибудь которое вам вы знаете что гарантированно не знаю или вы решите ее восстанавливать из бекапа или yandex.ru таких инструментов милан это всегда ручная работа и по месту тому выявляется что лучше сделать тому что есть данные критичные есть некритичные и как бы для каждой базы ну и приложение которые с ней работают это от бизнеса зависит то есть всегда по месту решается понятно спасибо что спасибо за доклад можно тоже задавала за нет или два вопроса во-первых вы и демонстрировать слайды там показывалась что в случае даришь как транзакций растет как и объем табличного пространства так размер индексы и дальше по докладу была куча утилит которые такую табличку хочу с индексом он так и остается они тоже покрытых вакуум не затрагивает яндекс сейчас некоторые пиджи репак magic компакты был работают с индексами случае с вакуум как это не затрагивает он пересадки бампере создает in its сюда затрагивает их вакуум full перестраивать не просто вакуум вакуум fall ваккун пул у него суть то в как раз все перезаписать из то есть он совсем работает и второй вопрос я просто на самом деле не понял почему отчеты на репликах так сильно зависит от самого репликации мне казалось что отчет это чтение репликации смотрите в чем возникают конфликты репликации ну вы вроде виктора слушали у нас есть мастер на котором происходит процесс у нас происходит of the vacuum of the vacuum по факту что делает он выпилил выпиливает какие-то старые строчки если у нас в это время на реплики идет запрос который читает эти старые строчки она мастер и произошла ситуация что авто wacom пометил эти строчки как возможны к перезаписи мы их перезаписали и у нас пришел этот пакет данных когда мы должны перезаписать те строчки которые нужны запросы на реплики то процесс репликации он подождет тот тайм-аут которая произволен по умолчанию 5 минут не по умолчанию как настроить и и потом по сбросу сказал будет решать что важнее для него а репликации для него важнее чем запросы он отстрелит запрос чтобы выполнить эти изменения на реплики андрей вопрос тоже вот эти вот замечательные графики которые показывали так так так так да во время презентации это результат работы который какой-то ваши утилиты можно получить а чем строили графики чем я строю графики там стенд и есть ребята ок метр называются это как раз сервис коммерческий продукт нет дальний коммерческий продукт к сожалению нас уже не осталось времени на вопросы скажите пожалуйста вы можете выделить какой-то один которого возможно понравился больше всего мне в принципе все вопросы понравились давайте вы кому-то одному дайте наклеечку а остальные подходите к нам на стенд и получите наклеечки за вопрос так нормально будет спасибо сям"
}