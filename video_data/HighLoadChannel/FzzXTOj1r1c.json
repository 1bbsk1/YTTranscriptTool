{
  "video_id": "FzzXTOj1r1c",
  "channel": "HighLoadChannel",
  "title": "Архитектура поиска в Avito / Андрей Смирнов (Avito)",
  "views": 3305,
  "duration": 2351,
  "published": "2017-05-14T22:53:06-07:00",
  "text": "Всем привет Меня зовут Андрей я работаю в компании Авита и занимаюсь развитием и поддержкой поисковых решений на нашем сайте У кого есть поиск на сайте кто использует н о их Трое в нашем прекрасном мире становится ВС больше больше больше информации и с каждым днм настолько много становится что люди уже меняют свой паттерн поведения То есть если раньше человек Думал как там сварить кашку Да он звонил своей бабушке бабушка бабушка как сри кашку А теперь все лезут в Google в Яндекс в байду Ну и когда что-то хотят продать купить лезут на Авито как у нас всё работает у нас всё работает на сфи sech Почему S sech все спрашивают Почему я не буду говорить почему я расскажу следующее что нет смысла у нас всё работает всё почти всё устраивается Сфинксом и мы не видим причин переходить на какие-то другие решения мы пробовали другие решения и мы пробовали н в Сор поднимали Ну это было давно он не очень хорошо тогда работал может быть он сейчас работает хорошо если сейчас появится задача дело поисковый сервис Попробуйте может быть у вас будет ВС прекрасно у нас ВС прекрасно со Сфинксом У нас есть следующая группа поисковых сервисов собственно основной поиск он отдельно Он большой он быстрый он ну это ядро нашей ядро нашего сайта и всё от него зависит поэтому он очень стабильный отказов Ну за год доклад Димы Он рассказал достаточно подробно тоже очень много Office Office большое Некоторое количество индексов которые нужны для модераторов например там все всесв айтемы которые когда-либо создавались навита то есть вот там сейчас лежит 800 млн это работает быстро все довольны есть небольшие сервисы фаз подсказки ошибки гео есть техническая логи логи у нас эластик Киба а собственно рассказ про основной поиск основной поиск - это 30 млн объявлений 150 млн запросов в день 17000 запросов в секунду в пик всё это лежит в 14 гигабайтах индексов и оно работает для того чтобы вот вы предположим вы взяли и создали некий сайт вы решили поставить поиск на этом сайте вот у вас маленький маленький компания один сервер вы запихнули ВС на один сервер ВС прекрасно вс хорошо работает Ну через какое-то время надо будет расширяться Первое что обычно делают Да выносит базу собственно А да про Сфинкс СН состоит из двух частей Это скрипт индексе который индексирует и готовит индексы для того чтобы дальше демон мог с ними работать и отдавать резуль по поисковым запросам работает и отдаёт поиск вот дальше наша архитектура ещ предположим растёт растёт мы вынесли мастер отдельно с Отдельно Ну собственно Ну Собственно уже здесь есть некая проблема индексацию нужно проводить параллельно нагрузка сильно сильно растёт и следующее логичное решение - это вынести индекс хите эндо много на каждом энде есть свой локальный Хаси который перенаправляет случайным образом запросы на наши поисковые сервера и есть ещё индексе иксер - это отдельная машина которая генерирует индексы для наших поисковых сервисов что важно Вот видите я тут нарисовал Мастер и сходят кочи чтото сво когда пишут они все ходят на Мастер и для индексе есть своя Репка это решение необходимо для того чтобы нам индексировать быстрее зачем же нам нужно индексировать быстрее всё очень просто бизнес бизнес пользователи платят за то чтобы поднимать объявление в поиске как выше и они хотят видеть это очень быстро сейчас когда вы поёте объявление на сайт есть некая задержка задержка е из Даго Даго прошлого в самом начале Когда было Авито была следующая проблема что не было никакой задержки появлялись новые объявления они появлялись на сайте и начали активно спамить спамеры то есть есть две большие проблемы это спамеры И парсеры вот спамеры это просека поняли как принцип Как работает выдача и начали спамить какими-то некрасивыми объявлениями рекла и так далее поэтому есть задержка на тобы ривали скрипты антифрод проверили объявление своими аналитическими алгоритмами и определили там спам не спам времяни стоит на месте сейчас антифронт работает очень быстро очень хорошо то есть до модераторов доходит очень небольшое количество объявлений и в целом в течение там 5-6 минут после подачи объявления уже мы уже знаем спам оно или не с ещ важный момент у нас для того чтобы всё быстро быстро работать все индексы на всех серверах лежат в памяти и что если вдруг что-то случается почти такого не случается что новый сервер нужно вывести в бой скорость индексации как бы позитивно работает на то чтобы сервис у нас поднялся То есть сейчас если с ну Ну через 10 минут мы можем егове уже в собственно проблема ускорение индексации делится на две части первая ускорение индексации вторая ускорение деплоя этих индексов на наши сервера Как вы в той схеме видели серверов у нас поисковых серверов у нас много каж из этих серверов чтобы ускорить индексацию следующее первая придумка что у нас своя база для индексации мы её полностью контролируем своими скриптами и важно что что она во-первых своя во-вторых там уже в юхи готовые для индексации то есть лишних Никаких данных там нет мы когда высчитывается второе для того чтобы в эти ВХ писать У нас логическая репликация с мастера то есть с мастера идут только те данные которые нам нужны когда они попадают на базу на нашу базу репки они ещё немножко дорабатывается там делятся на подкатегории категории ират на база кода инже нашу репликацию то есть в процессе индексации никакие инсерты никакие апдейты Ничего Ничего туда не идт мы в это время только читаем за счёт этого индексация происходит вычитка данных из базы происходит очень-очень быстро следующая проблема что если взять сейчас и запустить индексацию последовательно Она займёт 1 час 1 час нас не устраивает поэтому делаем параллельную индексацию в целом на этом нам позволяет достаточно мощные машины ядер много мы поставили количество потоков количество ядер минус д чтобы какие-то остальные сервисы нормально работали в это время и дальше следующий всё такой мини Хак если взять и параллельно индексировать просто В случайном порядке Кате индексы то может получиться Так что последний индекс будет самым большим и он будет тормозить общее время индексации Поэтому мы сортируем все индексы по времени индексации вот мы взяли отсортировать смотрим и мы видим то есть по оси X у нас просто ашки категории А по оси Y у нас секунды кото какое время требуется для инде этой категории Мы видим что у нас есть Прямо Явный Лидер Ну ещё так некоторые мелкие не такие явные лидеры Ну 650 секунд это очень долго Что же делать делаем очень просто берём и Режем этот индекс на четыре части и вот ещё тоже Которую следующее тоже Режем там на две части в итоге за счёт того что мы просто взяли и порезали мы получили вот такой график по времени индексации разных индексов сразу видно что мы теперь не ура Вот в эти 600 секунд и пока когда мы делаем параллельную индексацию всё время индексации проходит сейчас скажу вот конкретно время индексации проходит где-то минут за 5 с половино Да нет меньше за Че за 4 с по минуты в сфинксе есть прекрасная штука называется дистрибутивный индексы Вот наши индекс который мы взяли порезали на четыре части Он просто один для всего внешнего мира выглядит как один единственный индекс но внутри он разделен на четыре части это очень удобно таким же образом у нас есть устроено подкатегории То есть подкатегории - это категории у которых множество потомков отдельных Ну собственно и основной индекс самый большой это то есть в основном индексе У нас по-моему сейчас 64 под индекс следущий вопрос как быстро задеплоить много разных способов самый простой способ переноса большого количества данных с одного сервера на другой это всем известен Он про прост надёжен вс все умеет с ним делать но он это медленно надо на каждый сервер взять перенести наши 14 ГБ очень долго всякие программы все наверняка знают что в сво время компания называется программка которая ставишь на сервера и все сервера общаются друг с другом и как по принципу торрента передают большие файлы но мы оно забивает сеть проблема Какая что Несмотря на то что с центрального индексе вы всё равно отдадите все ваши 14 гиб и дальше они будут ещё ходить вши мы берм и бродкаста посылаем все индексы на некий адрес то есть пр прям сразу на все сервера звучит очень хорошо проблемы нет гарантии доставки нужно чтобы был по-хорошему свой коммутатор нужно человек который будет хорошо его настраивать Потому что если вы плохо настроите коммутатор как-то не так сделаете сеть все сервера в вашем дата-центре будут получать все эти индексы Это конечно не нужно Слава Богу у нас есть такие люди которые всё настраивают и при п рассылке получают только те сервера которые нужно Да дальше мы много экспериментировали с настройками скорость передачи то есть проблемы м проблемы со скоростью у нас особо нет то есть мы можем взять и ссылать наши индексы на максимальной скорости нашей сети но Мы помним что в Дан в текущий момент на все сервера иду приходят нормальные живые запросы о них надо помнить их в принципе немало их много если мы всю сеть заберём под наш передачу данных то это всё закончится печально у нас сервера боевые сервера боевые будут получать тайма поэтому немножко принижать дальше мы экспериментировали с параллельной рассылкой выглядело Это хорошо хорошо выс что очень БФА в что после того как вы ФП разослали обязательно всё проверяете пере проверяете что Вы получили именно те файлы которые вы ожидали бывает да там пакеты теряю Ну постоянно время от времени пакеты теряются и вы не получаете консистентность теперь объединяем вот мы индексацию индексацию ускорили деплой ускорили объединяем объединили что-то так медленно что как ускорить понятно что вот у нас Параллельная индексация какое-то количество потоков когда она заканчивается мы пересчитали чек суммы и задеплоил все файлы на все наши сервера Где же у нас найти время оказывается что как только мы индекс проиндексировали его сразу можно рассылать нет смысла ждать поэтому вот примерно наша схема деплоя индексации то есть параллельно индексация затем для больших файлов мы их сжимаем считаем чек сумму и добавляем список для деплоя и параллельно работает процесс деплоя который в один поток важно что он работает в один поток в один поток смотрит если у него есть в списке файлы то он его пересылает на все сервера компрессия у нас не для всех файлов потому что иногда время самой компрессия оно оно не даёт выигрыша то есть мы сжимаем только достаточно большие файлы и занимаем им быстро попробовали архиватор тли может быть кто-то слышали он очень хорош тем что он очень быстро разжимает То есть в принципе на сжатие у нас так как всё происходит параллельно у нас на индексе Мы у нас есть достаточно времени у нас мало времени на разжатие на каждом отдельном сервере именно там это разжатие влияет на общее время индексации дальше собственно важно первый вариант у нас был следующим образом устроен что после того как мы разослали все файлы через ft Мы проверяли Какие же файлы у нас побились или не побились Инком их догоняли тоже медленно Почему почему медленно потому что начали анализировать логи Выяснилось что если файл какой-то бьётся бьётся он обычно на на всех сразу файлах то есть где-то если сбой происходит какой-то в сети то на всех серверах у нас придут какие-то кривые файлы поэтому мы сделали следующим мы собираем список файлов из каждого сервера какие файлы у нас побились считаем количество файлов побиты Точнее не так то есть если мы увидели что один и тот же файл побился на большом количестве серверов то есть на 70% то мы е раз пересылаем через это будет быстрее если меньше то мы рассылаем НМ Почему так есть шанс что мы второй раз пересыла этот файл он побьёт ещё на новых серверах А это добавит нам Ну лишних работ по нку до качки этого файла поэтому вычислили список файлов которые большие которые побились на большом количестве серверов второй раз по и то что ВС синхронизировались ВС проверили сейчас весь этот процесс происходит за 5 с по минут то есть каждые 5 с по минут у нас индекс основной тиру и новые данные в нём появляются что в будущем в будущем мы думаем над т индексами с кластером серверов это сложно в компании и тогда это было неудачно он постоянно решился пока предварительно то что мы сейчас Тестируем пока у нас всё нормально ещё хотел бы вам очень рассказать как мы оптимизировали пояс Как делали чтобы он работал быстрее первое самое необходимое - это мониторинг Потому что если у вас нет мониторинга Вы не узнаете вообще Есть ли у вас проблемы это очень важно монин ри от сфинксов Ну поис аномали Я имел в виду что есть идея сделать какие-то автоматические системы которые будут искать аномалии но пока мы ещё в сторону них смотрим пока мы ищем аномалии самостоятельно анализ медленных запросов анализ медленных запросов показывает что да В некоторых категориях очень часто люди ищут с помощью дополнительных патче вид есть одна проблема которая нас пока беспокоит это то что нет индексов по атрибутам Да индексы атрибуты есть в лисне и jav подобных поисковых сервисов с этим можно легко бороться мы подмешивают буу поисковую выдачу и получается полнотекстовый поиск по атрибутам это очень быстро это очень удобно Какие случаи мы оптимизировали что что у нас получалось сразу прям как мы стали мониторить сразу мы улучшили вначале заметили пики врен то есть вот у нас был пик о происходит и возрастает время отклика что делать посмотрели покрутили выяснили что в этот момент у нас был следующий технология кэша был префикс кэша который при роте менялся то есть вот у нас индек случился кэш практически обнулили и вот все полезли в кэш подумали подумали посчитали и выяснили Ну в общем решили что для нас не критично чтобы в момент индексации обновлялся кэш какие-то пользователи Пускай они полезут в старые немножко данные это не так Для нас страшно поэтому размазали кэш всё стало прекрасно то есть теперь кэш то есть мы знаем примерно время следующей индексации и Кэш выставляем на время индексации плю минуты немножко его растягиваем и получается вс хорошо дальше тут у меня графиков нет начали смотреть выяснили увидели что в Пике трафика только в Пике трафика какие-то запросы какие-то сервера вдруг начинают адски тормозить что делать долго общались с нашими псами сказали ну може сделали запись Апа и мы увидели что оказывается на тех же серверах у нас были институции редиса и Да всем известно что дис - это такая штука которая потребляет мало CPU Но много памяти а sing такая штука которая с одной стороны потребляет мало памяти но много CPU и в целом они должны вместе хорошо существовать и никто никому не мешать но Выяснилось что время от времени R начинает э было два процесса сохранение спта когда выжил всю память настолько сильно что Сфинкс уходил и очень-очень медленно всё тормозило второй вариант - это когда вдруг приходили пере выбора мастера такое время от врем происходит и когда пере выбора мастера большое количество данных копируется по сети и чеки в ха прокси чеки - это очень удобная вещь то есть сервер ха прокси каждый Ну какое-то установленное время опрашивает ваши сервера А Вы ему говорите насколько сервер готов принимать запрос как он говорит он говорит типа там 100% 10% 1% или вообще сервер в Дане не надо мне запросов за счёт этого мы отдаём ки следующим образом что если мы видим что на данном сервере у нас сильно большой ла Это значит что сейчас запросы которые будут приходить будут тормозить мы выставляем маленький процент для этого сервера и на этот сервер попадает Совсем немножко запросов и всё становится хорошо дальше что ещё у нас было интересно ещё интересно ну включили слоги начали смотреть Выяснилось что нас очень любят парсеры парсеры приходят Прим нехорошие приходит Час пик в пик нашего трафика и начинает смотреть какие-то айтемы на там тысячных страницах и так далее но это достаточно быстро просто в начале прикрыли сейчас у нас ещё есть автоматическая программа которая ищет Вот таких вот нехороших людей и блочит сразу перфома улучшился значительно а да Во ещё интересное вот очень важное что такое сфинкс сфинкс - Это полнотекстовый поиск если у вас поиска нет у вас идёт и есть сортировка какая-то хитрая внутри у вас идёт поиск по всему индексу то есть вот 30 млн человек открывает первую страницы без поиска и по 30 миллионам у нас идёт сканирование Ну потому что у нас там ещё там сортировка по времени а как поборолись Ну мы знаем для каждого объявления что оно свежее добавляем мето в полнотекстовый поиск И теперь когда мы видим что запрос идёт без поискового запроса мы подставляем это как будто бы ищем только свежее только по свежим это очень быстро сразу стало всё прекрасно летать Да важно важно поиск у нас очень много людей очень много школ и очень много школ в которых люди не учат русский язык это большая проблема для поиска Представьте один человек продаёт что-то а другой покупает и они разговаривают на разных языках Они просто не могут найти то что о них один не может найти то что написал другое Почему не может найти Да потому что он тот написал с ошибками Этот написал с ошибками у нас был достаточно большой проект мы взяли все объявления которые у нас актив были которые не поме как см и определили отпечатки ошибки топ наших опечаток циферка - это Количество слов которые мы нашли с отпечатками вот к слову комбинезон там 71 причём важно Это была вторая версия первая версия показала что комбинезонов 92 Но мы потом подумали и решили что те которые встречаются не небольшое количество раз мы не будем включать то есть это не один человек это как минимум 10 человек написали неправильно вот пожалуйста читайте из этого слайда я убрал там всякий комбез который там сокращатель ласкательный видите как видно что есть любитель мягкого знака Вот вот вот мне нравится ком инезон А да вот ещё хороший пример вчера нашёл коньки девчачие Да у нас пояс по всему тексту объявления Казалось бы вот если бы человек здесь внизу написал хотя бы коньки правильно Нет у него шанса нет чём самое смешное Оказалось что в больше всего Таких вот слов в запчастях то есть там существуют прямо свои свои сленговые слова для каких-то запчастей Ну то есть в общем очень интересно причём сленговые слова ещё сложнее сленговые слова потому что сленговые слова Никто не знает как они правильно пишутся и каждый пишет их по-своему Ну ну я молчу что там iPhone iPhone русский iPhone латинский мы мам Да и как iPhone тоже пишут Это очень смешно и забавно Так мы помогаем пользователям которые подают объявления пользователи которые ищут мы помогаем следующим мы во-первых меняем раскладку исправляем отпечатки показываем показываем какие были популярные запросы по с тем же префиксом как как человек начал набивать пытаемся аккуратно убрать лишние слова мне не очень нравится как сейчас сделано но как сделано так сделано то есть если человек вёл какие-то лишние слова которые нас обрубили наш поиск мы это слово выкинем и попытаемся показать без этого слова О спасибо за внимание Спасибо за доклад такой вопрос по поводу ошибок То есть вы сказали что вы Эти ошибки то есть каким-то скриптом прогоняете да и ну находите типовые случаи а потом делаете алиас то есть да то есть Это правильное слово и все варианты его неправильные Какие могут быть Вот вопро скрипт находит ошибки вот а вторая часть этого вопроса используете ли вы какие-нибудь алгоритмы типа там фон или ещ что-нибудь Ну для русского языка то есть фон не используем да Или вообще есть какие-нибудь случаи То есть как вот ну чтобы без асов то есть чтобы он смотрите вот по умолчанию в сфинксе внутри есть прям дефолтная морфология этон Да когда он Берт и нормализует слово достаточно простым он не очень хорошо работает наме слово очки он преобразуется в о потому что он считает что и это окончание к это суфикс Ну собственно остаётся в общем ничего не ищет поэтому у нас Мы перешли на морфологию это более такой Более сложный большой словарь который нормализует слова а про ошибки про мефо Нет мы не используем но Томы количество случаев ну которые собственно фон покрыл бы то есть фон для английского языка по-моему существует да то есть он можно сделать свой для русского это не очень большое не Rocket Science А как вы ищете ошибки то есть ошибки Это Маши lear всё очень так долго тяжело Да ну то есть на самом деле у нас есть две технологии Первая - это Ma мыс кото определяет просто кластера слов Да к сожалению он это тоже не решает все проблемы нужно потом все слова просматривать ещё глазами увы это уже проще чем просто искать выска в тексте и второй есть второй у нас вариант - это когда мы ключевые слова выделяем в тексте и для них становится Понятно сложно этоже математика операци вот ну мы планируем это проводить где-то раз полгода Спасибо пожалуйста Спасибо за доклад А вопрос такой вот в сфинксе есть как бы имен ещё индексы Почему вы их не используете Я так понял вы пол Нет там есть полный индекс А есть как бы инкрементальный индекс Ну да дада да Ну тут есть проблемы в самом сфинксе то есть ме много данных меняется много Тут даже ту вычитка будет намного дольше проходить из базы чем Ну в нашем случае в вашем случае каждые 5 минут вы делаете полный индекс 5 минут Сколько объявление добавляется тут Вопрос не в том что добавляется А во-первых вас Запрос к базе теперь ЕС сеча ва запрос про тепер т сечас за сч того что этого индекса Нет мы вычитка приходит максимально быстро потом есть быстрее получается каждые 5 минут полный индекс по 8 милна объявлений проводить Мы так не делаем для как раз у нас используются Дельта индексы это в нормально работает а для Нда нде потому только у вас есть Дельта индексы это падение скорости выдачи то есть вот вот основной индекс с дельтами он бы был не 64 А 128 индексов должен был состоять и плюс накладывается необходимость наличия Кил листов И сами сами выдача результатов Ну сильно просела по моим прикидкам раза в три по скорости это не стоит Спасибо а у меня вот такой вопрос Если не РТ индексы вы используете когда человек совершает Там ну навита есть платные услуги там не знаю поднять в топ или что-то в этом роде А то есть когда он совершает эту операцию его объявление появится в топе через 5 минут или Ну через 6 минут на самом деле через 6 минут Да ну то есть нет такой проблемы Что не знаю там начинают пользователи истерить суппорт и говорить Я тут деньги заплатил а мо моё объявление до сих пор не в топе Нет проблем На самом деле тут штука такая что у нас большой очень большой трафик и как только человек пару раз применяет платные услуги он видит насколько у него вырастает количество просмотров объявлений причём Ну прям действительно как несколько Я не пробовал несколько моих друзей пробовали они говорят что да в десятки раз больше объявлений Ну собственно у него вопросов к тому к тому что оно там появилась не сразу а там вот там 5 минут собственно э про это там когда человека поднимает там написано через какое время он появится То есть вы его предупреждайте что да да конечно он предупреждён потому что у нас примерно та же тематика и у нас если там в топе не появилось за минуту пользователь уже звонит в суппорт Ну вот переход к РТ индексам придёт приведёт КК тому что оно вот будет появляться то есть м мы пока ещё далеки для того чтобы внедрять это но всё посмотрим то есть в сфинксе в 3.0 уже есть Т индексы более-менее Т индексы для кластера то есть а да ну вроде только Т Ну на самом деле вы можете Т использовать как обычный индекс но в общем да и в 3.0 там будет то есть проблема сейчас какая что у нас есть 16 серверов и нужно сейчас В текущей версии надо лить на каждый сервер апдейты то есть в 3:0 они Аксёнов обещает что это будет Вы можете лить на любой сервер а дальше уже внутри сам кластер разберётся Как доставить на все остальные сервера Здравствуйте спасибо за доклад У меня два вопроса Первое - это правильно ли я понял что каждый индексатор в каждый момент времени либо индексирует либо раскладывает Ну либо отсылает индекс Вот но не занимается этим как бы одновременно нет одновременно Ну то есть то есть ну как бы я для примера показал что вот мы вначале индекси параллельно индекс а потом раскладываем а потом мы параллельно индексируемых сразу раскладываем Ну ладно я наверно тогда попозже подойду и второй вопрос были у вас проблем Ну если у вас много кусков в распределённого индексе и вы Их достаточно часто индексируется нет ли проблем что слишком часто ротация происходит А в чём проблема ну ну короче говоря ничего страшного в этом нет я так понимаю ничего страшного нет хо То есть если у вас нет запов каких-то внутренних то всё нормально я понял СБО А да е важно для те кто использует с любира Поэтому по-хорошему нужно брать исходники и собирать их самостоятельно Здравствуйте тут здесь я так понимаю что Сфинкс у вас уже очень давно выбора в пользу сфинкса был сделан Да со временем даже не так претензии Вот вы сказали есть одна претензия какая была Том сеча Неу Ну есть мелкие претензии но это так Хорошо не возникал вопрос по ходу Вот уже сейчас смены движка по каким-то причинам То есть даже не стоит такой вопрос Да нас всё устраивает Да ну я хотел бы вот если если бы у вас были какие-то исследования на этот счёт Я бы хотел узнать результат и производительность Что самое главное Вот у нас есть некие партнёры у них меньше запросов больше примерно больше Да у нас 17000 в секунду нас серверов 16 да то есть 1000 на сервера в секунду на запас Да ну это сер а 17 серверов это с запасом смотрите если бы у нас были какие-то проблемы Прям у нас всё валилось падало не работало не отдавалось да тогда исследовали другие варианты на не проб на такой же нагрузке попросил бы ластик там или или ещ что-то 100 серверов и вы считали это проверяли Да вот Спасибо Ром проверял можно такой вопрос Вы делаете роте индексов По мере того как они загрузились или вы както дожидает дожидаемся момента нужно чтобы все индексы были примерно в одно время то есть иначе у нас получится что в основно основной вы од категории Бут Вы другие ниже Вот вы у вас сейчас есть небольшая видимо там я не знаю может быть фича такая скажем так проблема с геокоординаты поставленное в Туле оно может написать что в Москве Это как-то вы реша Ну там это можно как-то решить вопрос потом вот с учётом чтобы вот геокодирование какое-то да было потому что допустим если я открываю скажем Ну например Я хочу купить будет показывать на карте до тех пор пока я буду удаляться от Москвы То есть если кто-то поставил что я продаю где-нибудь в Краснодаре но при этом вручную в Москве то вот так общем Напишите нам барер посмотрим зна Маленький вопрос ошибки чем вы исправляется вот у вас есть коррекция опечаток по ошибки отдель индекс сами популярными словами там триграммы и мы по ним то есть там чуть-чуть сложнее чем триграммы но в общем устраивает вас всё круто работает с исправлением не предлагает глупостей Ну предлагат глупости Это тоже хорошо всё устраивает Здравствуйте Скажите пожалуйста как вы монитори Сфинкс Как вы собираете какую-то статистику по его использованию Ну и так далее а мониторим Сфинкс своими средствами во-первых То есть у нас написано на на питон скрипты которые раз там в какое-то время опрашивают Сфинкс и Пересылаю эти характеристики там в графити в графити мы уже всё видим для причём Да есть такая СНК проблема Мы давно просили исправить что есть хорошие статистики для дистрибутив индексов да для да для дистрибутивный индексов а для обычных индексов хороший Хороших статистик нет поэтому у нас есть один сервер который чуть-чуть меньше нагружен мы там пишем все логи и смотрим вообще что у нас происходит то есть по гпм логи и собираем среднее время выполнения запроса Там центили и так далее У спасибо обещали сделать когда-нибудь То есть для всех индексов можно было будет смотреть э процентили и так далее Спасибо Андрей Авита Андрей соответственно Андрея Потом можно будет поймать если какие-то вопросы у вас будут"
}