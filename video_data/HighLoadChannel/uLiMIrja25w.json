{
  "video_id": "uLiMIrja25w",
  "channel": "HighLoadChannel",
  "title": "Найди свой Vector в построении высоконагруженной системы логирования / Илья Вазем (СберМегаМаркет)",
  "views": 3257,
  "duration": 2070,
  "published": "2023-01-19T07:03:35-08:00",
  "text": "итак меня зовут илья мне 29 лет так старым смог покинуть омск отвечай инфраструктуру эксплуатацию в компании сбер мегамаркет у меня в команде 23 человека поделены они на 8 групп да у меня есть группы с одним из двумя людьми но мы покажем в духе стартапа имеют два красных диплома один технический один экономический три раза был на море и что удивительно практически бесплатно и у меня есть три основных обе это плавание серфинг и дрифт на я люблю воду доски и автомобили так я работал в компании сбр мегамаркет а это marketplace настоящий marketplace высоконагруженные онлайн-платформа соединяющие продукты покупайте ли состоящие из кучи микро сервисов работающую гибридной инфраструктуре на слайде бизнесовые показатели которые всю эту нагрузку по сути и генерят и так ближе к теме я вам вкратце расскажу историю развития нашей системы логирования простой системы и в конце мы немного остановимся на постулатах культуры логирования как все-таки к ней относиться чтобы вы ни страдали или страдали ваши коллеги тестировщики разработчики часть 1 брелок весна 2018 год когда я прихожу в компанию объем данных планированию нас небольшой в районе 15 гигабайт сообщений в районе 400 в секунду и схема выглядит следующим образом он все находится на одной ноги там игрок с мангой там и и ластик и все да как-то крутится и у нас проблем нет ну откуда ты к проблема да в таком объёме данных но мы понимаем что существуют определенные предпосылки которые к нам их подтянул до компания растет вспоминаем то что но всё-таки стартап с ростом компании растет трафик когда генерит трафик тем или иным образом вы все-таки влияет на количество заказов которые нужно обслуживать мы обслуживаем заказы большим количеством сервисов для того чтобы как-то занимать долю на рынке мы выкатываем новые фичи который собственно крутится на новый сервис орда и все это генерит больше рост логов которые оседают в общем объеме данных и так время идет движемся данные подросли схемка остается прежней но мы сталкиваемся со следующими проблемами нам не хватает ресурсов какое-то время мы вертикально масштабировались да и уперлись в определенные границы гипервизора далее с вместе с ростом нагрузки у нас начинает копиться очередь буфере которую мы тем или иным способом толкаем в ручном режиме при этом теряем еще йоги плюс ноги порой терялись и сами что мы делаем решение простое мы берем ластик выносим у вас этого х 103 нового инсталляции по дефолту версия 5 все данные кушают переваривается едем дальше проблемы уходят но проходит время что же делает проходит полгода данные кратно подросли схем от остается то прежние а проблемы возвращаются причем возвращаются в общем объеме и все те же самые этом я уже говорил решение опять же простое мы добавляем not используя к идее мы начинаем манипуляцию с нодами да и из эту манипуляцию нас отвечают куратор который суть по сути является простейшей утилитой менеджером индексов работающим в кроне по заданному сценарию и таскает индекс из горячих на холодные ноды и проблема уходит на проходит время проблема возвращаются вместе с ростом данных да она уже становится в районе одного терабайта сутки количество сообщений порядка 20 а то и более тысяч и наша съемка перестать вывозить и проблемы остаются тут мы с ребятами решили маленько остановиться собрать все в кучу и посмотреть что же нам мешает двигаться дальше и сети негодование заключались в следующем мы использовали старую версию грога вторую который отсутствовал кастри зация можно было собрать стальным способом федерацию нам этого не делали и не хотели мы используем 5 ластик который стоит свое нестабильностью отсутствие иных на мента и еще рядом преимуществ у нас есть куратор про который по сути ничего плохого тане скажет как топорная машина сценарий ему задал он крутится работает и все хорошо нам хотелось большего нам хотелось культа кастомизацию больше функционала и последний момент gaga отсутствовал модуль парсинга логов да мы нашли в коммьюнити игры логос cryptic мы этот скриптик добавили он как-то крутился но это было больше похоже на костыль нежели на решение далее прошло время все-таки мы взглянули на существующей системы в этот момент уже на хайпе движется рука написано ряд докладов где сравнивают урок stage of людей приступы который мы все-таки понимаем что френди нам интересен и мы выбираем его схема вырисовать следующим видом мы собираем лаги с контейнеров до используя драйвер drive это был гейб теперь the driver free винде брелок мы выбрасываем вместо у него настает встает партий к балансиров на практике бэг-энда у которых являются собственно надо сильвен де и все это пишется в 7 астика смм с ролями и менеджер за счет кибом там же мы визуализируем свои объемы также к этому моменту у нас возникает потребность что нужно забирать вагиз файлов для этого мы используем модуль friendee под названием т.д. агент который эти объемы у нас довольно переваривает нормально но есть один нюанс вспоминать то что до этого мы все-таки использовали игрок и поднимали что у нас есть виртуальная машина которую крудс игры wog в единственном экземпляре что мы сделали да мы взяли и сделали также с контейнерами у нас есть одна виртуальная машина с этим контейнером который обслуживает логирование всех систем отсюда получается у нас две проблемы проблема номер один обслуживая все системы одним набором контейнеров напишем в один индекс который растет становится гигантским не мобильным неуправляемым и ластик страдает какой бы он версии не было чтобы ты снизил и проблема номер два заключается в том что когда тебе нужно внести изменения в конфигурации логирования одного сервиса те приходят перекатывать все клиенты ну потому что t1 аборта 1 до конфигурационный файл он больше похож на некий талмуд состоящий с кучей конфигов что мы делаем используем подход номер 2 мы берем один набор контейнеров с лю индии которые обслуживают один сервис тем самым мы получаем кучу индексов каждый сервис пишет свой индекс за который хорошо мантой нить и второй момент когда нам нужно поменять конфигурацию что нет нет да и произвести или грохнуть мы влияем только на один сервис который нам нужен немного внутренностях здесь вкратце код я убрал оставил основные моменты которые в том или ином виде озадачили нас со временем это режим нам blocking у докера который позволяет нам спастись той ситуации когда мы попадаем под агрессивно и давление потока флагов наши заданные буферы дабу фирмы до можем контролировать конечно и по дефолту он один мегабайт ран он забивается и сервис который куется в этом контейнере пытается выпрыгнуть влоги в наружу он испытывает шок он может завершиться с ней очевидной ошибкой возврата и кодом ответа и чтобы этого не было на решили использовать режим нам блоки который в угоду новым сообщением потирает старые дамы здесь как вы приняли решение что мы все-таки готовы в критических ситуациях потерять немного ожёгов нежели полить потерять бизнес новый сервис и второй момент это теги всем известный теги до которые добавляют уникальности твоему сообщению позволяют маршрутизировать твое сообщение см игр про систему логирования тот же ключ индии и также за счет тегов мы фильтруем областя по нужным space самом власти крики боли у клиента момент створки раме как известно многие плагин флинта просто не умеют работать с маркерами они по дефолту используют один и больше не могут например легенда так как он поочередно вычитывает файлы синхронно более одного ядра он использовать по сути это не может но есть сервисы которые щедры на поток логов как обработки которых одно выдра никак не хватает тут подходит нам опция worker мы и задаем нужном количестве и тем самым удачно утилизируем циpкa на той виртуальной машине где кроется наш контейнер и лэйбл не путаем с тегами о bim нам помогает маршрутизировать набор конфигов объединяющиеся в общих основных файлов у индии при сборке и соответственно он включает в себя конфигурации сервисов и различные коды с настройками собственно конфигурация сервисов тот лейбл который используется для его идентификации однозначно да цепочки далее в боки фильтр мы используем несколько модулей модуль 1 это koh kood модуль который конкретизирует наше сообщение то есть из склеивает если драйвер клиента при отправке их разорвала по той или на причину стандартная ситуация и модуль 2 с помощью которого мы генерим та самая деккер шин для однозначной идентификации сообщений в будущем используя его для отправки власти к собственно сам матч до плагин elastico которые включают себя набор параметров необходимых для отправки тот самый и дикий хэш с помощью которого мы решаем вопрос дедупликации и у нас все сообщение становится уникальным и также сюда можно добавить там стенд и различные опции но это основная и pipeline тут немного стоит остановиться при первом подходе с пользования friendee мы полагались на его встроенный парсинг джейсону логов которые изначально нам показался прикольным а потому что он есть draught в гриву киева не было тут он есть но при средней нагрузке и чуть больше потока флагов о которых и говорю до этого он начинает выжрать огромные ресурсы при этом его эффективность оживает оставляет желать лучшего тут мы используем золотую курочку виде pipeline а когда мы решаем вопрос парсинга на стороне астика да вы можете сказать что мы тем самым грузим у вас тег но и во всех такой молодец что его процессора хватает спокойно и переваривать сообщение если они придут правильная структура джейсона и складывать их ну и далее соответственно все манипуляции которые на позволяют самого stick вот но в данном случае именно мы прописывали в текущее время мы прописывали конкретно pipeline который будем использовать ластики на текущий момент мы уже пошли немного дальше и задавая дефолтную структуру шаблона индексом и вне уже указываем нужный индекс pipeline который будет использован для сообщения того конкретного сервиса и настройки буфер стандарт надо когда мы хотим что-то отправить им все-таки должны написать какими пакетиками будем отправлять гусли у нас ретро и тайм-аут и тому подобное как мы готовим структуру elastico опять же все просто мы создаем шаблоны индекса назначаем ему нужно политикой в яндекс менеджмент указываем тот самый корректный енджэ spine который будет нашу структуру правильно раскладывать по нужным нам полям и садам пространство в киба не и формируем первый индекс с чётным номером который послужит нам дальнейшем для ротации когда оба бы сын все больше больше да и у нас есть политика ротации которые отсекают далее рабочий процесс выкатки изменений у нас выглядит следующим образом все это основано у нас на механизмах триггера гид лобо которые дергают запуск джаббы по изменению в компьютерных файлов сервиса и соответственно строки лагерь вниз лежат это также рядом сервисом репозитории собственно сами папой надо состоящий из следующих шагов шаг номер один мы формируем конфигурационный шаблонный файлик для х прокси которые включают себя связку фронт принимаемая сторона да и бег в данном случае этому контейнеров ливень д далее мы формируем структуру конфигурационного файла тот того большого флинте снова которые в себя включает include include и сервисов конфигурации и дополнительные опции настройки логирования и также мы здесь задаем структуру будущего нашего шаблона в яндексе и space используя api икебаны elastico соответственно далее мы запихиваем это все в образ докер ный который не понадобится нам собственно для depo и в нужно окружении примеру тест прот отсюда мы имеем просто масштабировать да сколько тебе нужно контейнеров столько их надела и виртуальных машин а создавая еще расширяете и так далее превышать 7 астика он прост он понятен как раньше да но теперь имеет больший функционал а именно функционал управление индексами хороших менеджмент и все это заканчиваться таким радостным пунктом это парник джейсон логов да по сути которые как для галочки есть у флю индии но как мы поняли и он недостаточно но использовать его не стоит но вроде как все хорошо время прошел прошел год уже объемы данных кратно выросли вас уже в сутки порядка пяти терабайт в секунду это 150000 сообщений съемка нашей не менялась проблем это пришли как обычно и собственно первая проблема про который говорил уже да сам встроены модули парсинга джейсон лагов уфу индии вторая проблема это непрозрачность буферов людей которую при хорошем интенсивном потоки логов мог экспоненциально просто за летать вверх от чего это происходило непонятно но он точно выжрал ресурс он держал всю оперативную память что у него было что-либо что им было указано в лимитах у контейнера и тем самым у поражало некую стагнацию работы всего озеро далее на фоне этого нас возникали ретро и при попытке отправить сообщение и эти ретро они за кольцо вывалив тем самым и давку в буфере все усиливали усиливаем это сжимали этот самый ноутбуки нг который рассказывал про раньше уже с этим не справлялся и мы теряли логин но время это прошло и тишка двигалась вперед и сейчас мы посмотрели какие решения есть уже сейчас появилась ряд докладов ряд сравнительных статей и там смотрели на friendee и на то время актуальный флеминг биты новоиспеченный вектор который находился всем еще в бета-версии его практически никто не использовал он участвовать каких-то им в кишках и вот этих вот тестах на лэптопе своим но время прошло много требования от разработки и тестирования усилились мы уже не знали куда нам деваться от косых взглядов когда от нас просят хорошие систему логирование нужен комфорт и качество и доставка все-таки информации на решили с прогреется начнут любит а так как схема у нас практически не изменяется флинн бит ни капельки не отличается у нас от вектор в использовании да то мы его ночными перебежками подработками на выходных и дипломе в бой меняем на флебит один вид тем самым мы получаем удивительно результаты да и одних и тех же потоках логов для одних и тех же сервисов когда флю индии потреблял в районе 200 мегабайт от двухсот мегабайт до 4 гигов памяти тов любит обслуживая аоки этих же сервисов потреблял 5-30 5 мегабайт то есть нас вау кайф круто все давайте использовать но проходит немного времени и мы помним то что френди были проблемы и никуда не делись особо он там в своих новых релизах их как-то не фиксить и собирался соответственно боремся с буфером пока боремся теряем логин ну вот досада флебит мы с буфером то не боремся там пролетают логе быстро но куда не долетают не совсем понятно и мы снова сталкиваются потери ожёгов минут к радости поднимите руки у кого в компании принято хранить логии полгода год и более вот спасибо а теперь поднимите руки те которым приходится расписывался в особом журнале за сохранность этих логов вот к слову говоря 1с для нас является на один с написана для нас одна и самокритично систем процессинга заказов которой логе используется не только для аналитики и дебага просто посмотреть за эти интересны да но они используют для решения рабочих задач и к нам пришли эти ребята они говорят ну суши нам слишком дорого обходится обслуживание базе кино железе где мэтти логе храним плюс там где basic их постоянно вилами тыкаю давайте давайте съезжайте от нас они сделайте пожалуйста чтобы работала и пришлось решать решение будет следующим образом правая часть у нас неизменно да этот то время когда мы используем flew in beat в левую нас появляется один с . прекрасная который раскладывает все своего give a реки но как же к забирать от иды агентом решили все-таки отказаться к этому времени и завели диалог с разработкой давайте напишем своем в итоге мы наборщики написали сам описанную прокси которую в реал тайме снизит каталог с лагами scanid его и нужными балками с нужными тайм-аута my закидывает собственного прокси который уже своей балансировки и отправляют в нужны флебит и все это работает вот но у нас остается так проблема даст потери лагов и когда поток logo все-таки небольшой то потеря не так заметны соответственно мы с разработчиками они со своей стороны тестируют процессом описанную мы со своей стороны все таки еще раз хотели захотели взглянуть на флюенс бит и сделали тестирование когда мы отправляем балками в секунду 1010 1100 тысяч сообщений и мы получили специальные рост потерянных логов вектор сегодня маленько говорили про вектор до творения do the dog написан на расти очень быстро и эффективно использует память может работать что с метриками что слугами а безразницы на самом деле он хорош почему мы провели свои тесты не на востоке уже до теста на более мощном железе проводили с простой и утилиты я думаю многим знакома указ называется задаем и стандартные параметры продолжительно ставим 10 минут и все это гоняется нос в рамках одного контейнера то есть мы берем один контейнер флинт день один контейнер friend by ты один контейнер векторов все в равных условиях на одинаковых тачках запускаем получаем результаты слева флинте справа вектор возможного мелкая продиктую первые графики да это акебоно показывает нам количество сообщений которое пролетел за 10 секунд за 10 минут извиняюсь через один контейнер и мы тут видим что у вектора показатель более чем два с половиной раза больше опускаясь ниже мы смотрим на графике общего рпс а слева 4000 укрытие и в районе 11 тысяч вектора но сходится туда же более чем ближе к трем до разом отличие кратная и опять же она отображается на в этом все ответа самого контейнера когда a frenzy нам отвечает раян 230 миллисекунд то вектор 65 при этом в режиме стресс-теста вспоминаем нашу флинн бит года он не смог все-таки сколько мы его не пинали и не реанимировали но как только мы запускаем тест он падает внедряем вектор время прошло и текущие объёмы дано порядка семи терабайт сутки количество общение порядка 240 тысяч схема выглядящим образом может кажется мне ничего не поменялось но теперь мы вместо драйвера флинте используем драйвер sis logo вместо not с контейнерами флюенс бита эфендиев прошлом используем контейнеры с вектором и файлики состав собираем с помощью вектора отличный агент собирается парсится и все улетает у нас есть шутка программисты бывают рассказывают своим детям истории про обновление типовых 1с наши программисты будут рассказывать истории как они строили систему логирования с админами и как же оно там вектор сюда залетает на уран но она работает логе мы не теряем но в этот момент у нас появляется возможность открыть кранчик на полную открывая этот кранчик мы были с одной стороны приятно удивлены что система держит и выдерживает но с другой стороны мы немного задачи лись объемы логов у нас буквально за несколько дней неделю достигли 100 терабайт до в сутки это было немного в сутки один из косово время терабайта напомню это практически один сервис в сутки шлет 1 терабайт логов далее мы что мы открыли снова повторно диалог с разработчиками и использовали секретное оружие давайте будем хранить то что нам нужно и ура нас услышали разработка со своей стороны как раз самописная прокси добавляет механизм который помещает определенные сообщения в поле значением нужно приоритетом то есть это сообщение подходит но относится к транзакции это какая-то де важной информации и так далее на это поле мы соответственно делаем свой индекс папа ему добавляем условия парсинга и сообщения которые нам нужно хранить долго попадают в один индекс сообщение которые нам не важны просто им их там день два держим потом удалим попадают другой индекс тем самым вас появляется возможность легко ротировать эту информацию из кучи индексов и назначаете полисе то которое нам нужно и который решает нашу задачу немного про кубер вектор настолько прост и не стал даже сюда вставлять кусочек его я моего конфига откройте документацию посмотрите но он элементарный и настолько же просто он интегрируется в кубер вектор вы можете использовать как demands and site кары просто как агрегатор мы остановились на решении с demons этом которая позволила нам получить простую настройку и обновление масштабируемость аналогично до а и готовность большим нагрузкам и эффективность который нам дает сам вектор немного о культуре как и обещал вначале можно строить любую систему делайте отказывал стоит человек высокой нагруженной но если поток логов будет состоять из не пойми чего да вот он текст стектрейсы ошибки метода ты картинки объекты то участи не вы видите я думаю многие с этим сталкивались дачу и там происходит сейчас в разработке нет времени да они его лучше потратят место написания лаггера на выходку новые фичи они могут просто забивать им это неинтересно они могут распихивать на сторону эксплуатации требовать от них красивого парсинга вот новым шлем сделать чтоб меня было красиво чтобы это было здесь быстро появлялась на радовались и так далее но расскажу об идеальном варианте на конечно черном плату разработку не держали но определенные договоренности постулаты обозначили вред номер один да если мы хотим парсить же сон то все без исключения сообщения очевидно должно быть формате json второе мы точно знаем состав нашего джисона под которой мы настраиваем маппинг и третье мы выносим этот состав в качестве маппинга в шаблон индекса который со временем никак не меняется мы динамически мне добавляем новые поля по типу ой что там и новенькое захотели отправить нет у нас есть четкая статичная структура это 1 до момент что с этим делать а если все-таки не получается договориться вы можете пойти вторым путем писать сложные pipeline и пусть in jest pipeline и pipeline и эти можете размещать как на стороне агрегатора friendee модуль парсинга можете на векторе можете использовать для этого elastic от мы его сейчас используем то тогда для более сложной работы вам нужно будет следующее до вам нужно будет отделить мух от котлет соответственно вы должны понимать где jison где остальное а если джейсон в это просите да и все хорошо а если все-таки это остальное вы закладываете в текст мысли да и вот пусть мучаются не хотят следовать нашим правилам постулатом вот ты читать свои йоге как хотите вот но все же если это ещё и туда не проводи до наша картинка любимые бинарники то мы просто в отдельных записываем эту информацию об ошибке которые потом анализируем понимаем от кого что пришло и почему она так действуем точно собственно чтобы было все хорошо то мы используем статичную структуру логов неизменно до статичный mapping полей и статичный шаблон индексов и тогда ваша печка будет радоваться вы можете в нее лиц сколько угодно ведь всяких сложных решений к фак самописных прибудут и все норм отсюда выводы будьте ближе к разработке без хорошей синергии совместной работой над как бы системы вы не работали мониторинг логирование хотите с бассейна что-то интересное сделать будьте ближе и только вообще не достигнете интересного и качество результата второе стройте простые системы всем известно да эти стандартные постулат айтишника чем проще тем и выносливее этим стабильный тем легче менты не тем интереснее просыпаться ночью в том что может уже не просыпаться данном посту решение можно и просто автоматизацию навязать ну а чем сложнее делаем тем соответствующие выводы отсюда и получаем и простое кайфуйте кайфуйте от своей работы тут как бы хочется добавить что мы не являемся с сектантами вектора до показали свою space который живет с этой системы мы живем и сейчас она работает она стабильна выдерживает высокие нагрузки но если на рынке появятся более интересное решение которое будет эффективнее решает наши поставленные задачи то мы несомненно переметнулся на ее сторону поэтому выбирать эффективное решение которые нужны именно вам а это по сути рекомендация от нас вот я процент моими хобби а вот вам мега спасибо большое за внимание я спасибо за доклад и у нас вопросы пожалуйста вижу первый даже желаешь спасибо за доклад если я правильно понял сейчас последние можно souls скажу какие сейчас вот объемы данных вы льете и сколько железа используется чтобы свято хранить обрабатывается на текущий момент собственно когда готова призван в сутки порядка семи терабайт в секунду время 240 50000 в целом объему настроение 100 терабайт обслуживает это 25 26 и ластиков они распределены роли есть дата но дай этим детской радиаторе мастера но я выйду из смогу считали сколько примерно в ядер и не знаю памяти скачивать и ластики у нас стандартный обычно это двадцать четыре ядра и 32 памяти 32 под хит понял смотри еще один вопрос вот тест говорю что важно не терять сообщение от 1с и вот эта схема разве гарантирует доставку лагов она не гарантирует хорошо outros но она решила эту проблему мы логине теряем и то важно да как и говорю приоритетное она попадает в индекс и она есть к нам больше не приходят разработчики не приходят темы и продукты и я считаю то каким-то успехом смотря никакого нет там за резервирование и там retrieve ну грубо говоря у тебя упал просто но до вектора на которые то что управлял да и ты потерял не знаю блоге за 5 минут смотри мы логе за счет драйвер сиссоко да я вкратце про настройку говорю да там в нем также есть ретро я который вектор отправляют если вектор ему отвечает но нет человека со мной что-то не так то он делает по вторую попытку здесь наша прокси его например другой контейнер который проходит сборщику если все окей она пролетает если нету дальше по кругу ну то это стандартный механизм здесь ничего сам описанного нет она есть из коробки спасибо вот тут я вижу можно говорить спасибо большое за доклад на самом деле хотел бы просто уточнить может быть у вас вы рассматривали использование stk я не показаться ну локи grafana и вот это вот все вместо elastic search просто почему спрашиваю мы в моей предыдущей кампании когда начали делать свою собственную систему лагерь мы даже не стали брать elastic просто наслушавшись какое количество ресурсов он с что там в вазоне чуть ли не половина всего кластер занимает мелкое в итоге сразу начали делать налоги у нас это завелось и работала может быть не рассматривали вообще фриц а мы не рассматривали вот вы можете поделиться с нами своим достижениям и будет интересно пытались анализировать причины по которой воде пропадают лембит мы пытались нас не получилось то есть у нас корнем входили в разные стороны порой это заканчивать тем что сообщение просто пропала мы сначала думали до что мы столкнулись той же проблем который бы вафли винде забивается буфер да и он начинает сам очистка заниматься старых сообщений но с бутером все руки в него как влитая так и вылетает поэтому это осталось загадкой мы просто решили пойти дальше и но и не ошиблись по сути своим путем вот там х прокси у вас было это как балансировщик у вас получается да спать или так несколько получается экземпляров это набор волонтеров с к прокси да и каждый экземпляр векторы он равнозначен то есть она тоже конфигурация про это много нот на каждом ноги и куча контейнеров под каждый сервис набор и соответственно все равнозначные а сколько примерно ресурсов пожирает вектор вот прав лембит упомянули до проректор не указал он в районе free любит а то есть он очень энергоэффективны соответственно он через себя способен пропустить большой поток памяти но для его существования не нужно ресурсов в этом и фишка ну получив балансировка вас парам робин смотрите меня такой вопрос вы сначала упорно пытались писать все логе лаги лаги весь мусор а потом в конце как я понял у пришли к тому что нужно мусор какой-то сейвить удалять почему именно такой путь то есть почему не сначала посмотреть может быть нам этот мусор не нужен и зачем на вообще выписать ее добавлять там инфраструктуре с такие гигантское количество там серверов да а почему не такой путь очередной хороший вопрос напомню что мы до сих пор живем в духе стартапам и так получилось что мы на эту нишу немного позже вышли на чем тот же самый озон пример нам нужно было догонять и приоритете у компании стала выходка fitch нежели там заниматься этим долгом проработкой и собственно от называется от эксплуатации требовали чтобы это просто было и работала поэтому именно начальном пути занимали задачами как все это переварить и отдать и вот сейчас мы уже можем себе позволить входить в некую синергию с разработкой и делать хорошо еще вопросе спасибо за доклад там на схеме с 1с было прокси самописная почему не вектор такой же которых естественных файл забирает у один адский есть определенная специфика как она пишет свои йоги файл вектор с этим мы не могли приучить ну во-первых была сложена во-вторых из-за того что сама сам логина 11 босса написано было проще сам описано прокси она минимальная на кошечки там приложения чтобы она выполняла именно ту потребность который нужен забирать как вот этого по файл дыра сказано у нас сильно проще и доступнее просто подход такой выбрали моем браке логе я сначала подумал что какие-то отдельные канализации логов файл ему нестандартных 1с я потом нужно собирать сначала ну там структура непонятные 2 файла и еще 2 не вопрос один аспект за toyota chaser один из всех задач other я просто владивостока спасибо спасибо"
}