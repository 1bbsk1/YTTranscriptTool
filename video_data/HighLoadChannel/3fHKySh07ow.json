{
  "video_id": "3fHKySh07ow",
  "channel": "HighLoadChannel",
  "title": "GraphQL: как не выстрелить себе в ногу / Александр Поляков, Михаил Сурин (Яндекс)",
  "views": 2883,
  "duration": 2265,
  "published": "2023-01-19T05:55:18-08:00",
  "text": "всем привет но смотрите сегодня который называется граф quelle как не выстрелить себе в ногу вот это такой смузи доклад мне кажется как раз хорошо подходит вот закрытие еще раз кратко расскажу кто мы такие меня зовут александр поляков и более 8 лет практически 9 лет я работаю в яндексе первые шесть лет я работал в качестве руководителей разработки сервисы яндекс афиша вот и последние два года я работаю руководителем сервиса яндекс плюс меня зовут михаил сурен я тоже почти 9 лет уже работаю в яндексе начинала как бы кант разработчик команде нас афиша дальше был земли дом бэг-энда и тоже руководителем разработки и an exotic так собственно чем наш рассказ сегодня планируем рассказать про то как эволюционировала менялась архитектура сервис яндекс афиши и про то как мы переезжали средстве на графу или вот расскажу про то какие задачи проблемы решали и пытались решать с помощью графы также затронул вопросы подходы и методы которых следует придерживаться если вы там переходите начинать использовать технологию чтобы не выстрелить себе в ногу вот мы расскажем вам такие вопросы как типизация данных безопасность скорость работы и 5 и расскажем про концепт атолла ударов вот и еще послушать доклад мне кажется вы сформируете мнение о том какие плюсы и минусы есть в этой технологии и вообще в принципе подходит она не подходит для вашего сервиса или проектом прежде чем перейти непосредственно к рассказу про граф quelle и про переезд на него вот кратенько расскажу что такое индекс афиши и какие задачи он решает точки зрения нашего пользователя конечно индекс афиши это сервис который работает по всей россии то есть это покрытие больше ста городов это вот от калининграда до южно-сахалинска и до владивостока вот и он по сути решает две задачи пользовательские первые это по помочь пользователю выбрать куда ему сходить там это не знаю там какое-то кино концерт и вторая задача это собственно помочь ему купить билет на выбор выбранный сеанс вот так сервис работает на сегодня но так был не самого начала то есть и изначально мы изначально сервис я даст афиши был запущен более десяти лет назад и он решал только по сути перу задачу той задачу выбора куда ему сходить вот архитектура сервиса было довольно как бы такая типичная классическая трехизбенка то есть это был frontend написано но джесси в качестве бэг-энда использовался python вот и в качестве бдм использовали манга далее 2013 году как раз когда пришли мы вместе с мишей яндекс запускает еще один сервис это сервис яндекс билеты вот этот сервис как раз таки уже представлял собой агрегатор таких кино концертных операторов и он как раз пришла вторую задачу то есть он позволял приобретать билеты на выбранный сеанс вот архитектура сервиса тоже было довольно стандартная для яндекса то есть это frontend написано на джесс так называемый виджет как раз вот этот тот самый виджет который мы встраивали в различные сайты и сервисы ну точно пример он работал напиши yandex.ru он на кинопоиске нас них до сих пор работает и на сайтах наших партнеров и как раз этот виджет сохнут и происходило покупка билетов backend был написан на java и в качестве зубы да и мы тоже использовали манга со временем но с течением временем как бы эксплуатации и написание новых вещей каких то продуктовых мы начали сталкиваться с определенными проблемами вот перво-наперво нам стало понятно что нам нужен некий единый язык описания всей предметной области вот на на которые мы могли бы первых описывать эту предметную область которые могли бы пользоваться как там не знаю как тестировщики так и разработчики вот и на котором в том числе можно было писать запросах бэг-энда осознали что нам нужна единая но гибкая модель данных всего сервиса вот так же поняли что нам нужен единой 5 твой то есть мы не хотели развивать историю когда у нас торчит наружу множество сервисов со множествами поинтами про который знает все внешние потребители хотелось все это дело инкапсулировать за единым и шлюзом вот этим вот чтобы нам потом проще было не знаю менять там внутри нас сюда вот эти вот столкнулись также с проблемой взрыва методов что это означает что в наши бренды было довольно много разных различных потребителей то есть это не только само атома индекс афиша это кинопоиск это не знаю там и и морда поиска на самом деле много много кого еще вот и все вот эти потребителя не хотели видеть какие-то различные среды данных различные ответы и нам приходилось добавлять все больше и больше различных методов но вот например в случае вот у нас будут там на сущность место да там вот число методов выросла до 6 но продолжал расти вот то же самое с мероприятием это все тоже дадите видно что число методов 7 этаже на этом ну скорее всего не остановилась бы если бы не переехали на граф quelle и столкнулись проблема избыточных или не достаточных данных что это означает означает что у нас было несколько различных форматов ответов то есть вот например полный формат ответа краткий формат ответа до места проведения мероприятия и но очевидно что части потребителей клиентов вот этого ответа им было слишком много то есть им нужно было там не знаю несколько полей а для части наоборот не хватало поэтому приходилось делать дополнительные запросы в наши бренды но это во-первых трафик дополнительный какой-то гонялся по сети не нужны и понятное дело какая-то док нагрузка на бэг-энда вот пошли смотреть и что вообще есть на рынке и посмотрели и no rest in a soup не знаю там swagger который опен 5 вот и на самом деле ну как бы показалось что граф quelle как будто бы решает все вот озвученные проблемы которая выше сказал если в двух словах то граф quelle он представляет некий такой язык синтаксис с помощью которого можно делать запросы в бэг-энд и в основном использую как раз таки для получения данных с бэг-энда на клиент вот и у него есть такие там три основные характеристики первое он позволяет клиенту точно указать какие данные он хочет получить с бэг-энда но вот например здесь какой-то выраженный пример вымышленной то есть мы вот не знаю там хотим получить всех пользователей с именем алекс поляков там друзей его город проживания так далее вот вторая такая в оба на второе важное свойство это он облегчает агрегацию данных то есть вот случае работа со всяким различным местами нам необходимо знать как клиенту куда сходить как сходить как эти данные получить как x агрегировать лучше работают граф уильям мы ходим единый on point мы а он уже в свою очередь инкапсулирует всю вот эту вот логику знает как это все сделать общем всю эту сложно machinery он как бы в себе содержит и третье это он обладает система типов для описания данных вот ну вот здесь тоже какой-то вымышленный премьер то есть не знаю там есть там тип пользователя те город они там как-то связаны между собой сейчас немножко расскажу поглубже как это все работает вообще натолкнулся на хороший доклад в интернете в ютюбе владимир тсукури называется граф quelle опять в нью вей вот вы можете с ним познакомиться вот посылочки который на которых от qr-код в общем очень мощный доклад очень интересный я лишь какие-то но по пару моментов оттуда хочу посвятить во-первых еще раз граф quelle это не база данных и это не про то как работа с базами данных граф quelle это про это про про подхода работа сыпей и это прям ну то супер важно потому что разные люди ко мне приходили как бы общался у всех какое-то свое понимание что такое графой чтобы начать работать граф quelle им нужно сделать он вещей значит первые нам нужно определиться схемы данных ну вот опять да вот какой то вот вымышленные премьер если представить что мы там разрабатываем какой-нибудь социальной сети до то из нас там например есть пользователь юзер да там есть сити пользователя живет в городе пользователя есть там frends друзья которые на самом деле являются массивом из пользователя и в сети в городе живут синтеза граждане которые также являются массивом из тип юзеров здесь вот видно вот эти стрелочки что вот эти взаимосвязи как раз начинают образовывать граф это как раз тот самый граф quelle граф ковалевич который вот ну в названии этой технологии далее нам что нам надо с клиента запросить эти данные вот ну опять какой-то пример да вот вымышленный что мы хотим получить всех пользователей с именем алекс polyakov хотим там его друзей город проживания там и так далее вот делаем запрос получаем ответ и видим что backend который работает на графу или да вот он возвращает нам ответ семантика которого она соответствует семантики запросу то есть у них хорошо видно что граф кори возвращает те и ровно только те поля которые ну и сущности которой были запрошены с клиенты это прям очень крутая фича и да вся эта магия происходит за 11 stage типе под запрос то есть не надо там делаю запрос и вот ну по сути вот все те проблемы которые озвучил да они вот решаются такими историями так есть еще раз вот подсветить граф quelle irest случае работы с христом значит клиенту нужно знать еще раз про все наши бренды сервиса микро сервисы как туда сходить как получить эти данные как x агрегировать причем разные там раз ты могут работать словно там писались разными командами кто во что горазд и клиенту ну то есть там вот этому потребитель ему нужно во всем этом разбираться и все это знать случае работа с граф quelle им у нас тут есть вот этот вот единой 5 гид вей который инкапсулирует всю эту логику который уже под капотом знает как ему сходить куда сходить как все это среагировать и с которым мы общаемся на вот определенном языке с определенным синтаксиса и начнут есть еще раз подсветить основные плюсы граф coin о данном слайде то ну во первых как бы он позволяет прозрачным для клиента объедините вызова множество методов для получения данных вот это первое второе представляет возможность клиентам запрашивать различные композиции существующих данных причем что существенно доработана бэг-энде большинстве случаев дело делать не надо будет он представляет отлично задокументированная точку входа в сервис это тут самые пикеты как раз про который я рассказывал ранее вот и он представляет единый язык для запросов для описания предметной области вот который там понятные задокументированы с которым очень легко понятно работать очевидно что как у любой технологии у него есть свои минусы про которой ну тоже стоит помнить нужно знать то есть но например мы там позже ко мне хамишь и расскажет вам как как мы за оборвали там быть что вот этих вот проблем ну во-первых граф quelle он использует http как транспорт поэтому всегда возвращается 200 код вот поэтому в ну все ошибки нужно обрабатывать как самостоятельно по существующим контрактам во вторых у нас очевидно что у нас появляется какая-то еще одна абстракция до посередине вот которая увеличивает время ответа вот и ну то есть это время как раз которая требуется чтобы там сходить во все бэг-энда во всей сервиса микро сервиса чтобы сделать агрегацию чтобы сирии заводи связи ответ чтобы распарсить запрос и так далее в общем все это не бесплатно и например если для вашего сервиса критично время ответа и там какие-то должны быть миллисекунды то здесь хорошего-то хорошо нужно подумать стоит ли вообще использовать его а далее появляется такая штука как сложно запросов вот и про нее тоже очень важно помнить то есть есть ли из коробки поставить граф quelle то у наших потребитель клиентов я уж не говорю про злоумышленников появляется возможность просто сложить наш backend то есть они смогут послать какой-то сложный такое глубоко вложенный запрос и там одна сущность будет ссылаться на другую а то на нее же и как бы вот так до бесконечности на почту нас граф вот что свою очередь там мы положим положит на даже backend но там гру говоря можно спросить у вообще базу до разом вот и на самом деле как бы я говорил что один and point это хорошо но одновременно это этой плохо потому что из коробки опять же нам нам будет сложно следить за рейд и ограничивать или три митинг нам будет сложно мониторировать запросы вот и нам будет сложно кэшировать ответы это все решается мы дальше расскажем как как мы решали все вот эти проблемы но просто про это нужно помнить когда вы будете использовать начать использовать граф пыли в общем взвесив все плюсы и минусы мы поняли что плюсы перевешивают и мы соответственно сделали первый подход мы написали 1 и 5 gateway написали его на но уже с вот он у нас закрыл наши два бэг-энда то есть но от больших брендов backend афиши баком билетов вот и мы вот эта и пикет вы запустили основных наших потребителей то есть это афиши yandex.ru это приложение то кинопоиск но и на самом деле там еще всех остальных потребителей вот ну в общем я здесь рассказываю как будто бы все так хорошо гладко но на самом деле вот запустив 1 версию она работала не то чтобы прям очень хорошо то есть это кал там были проблемы с перформансом со скоростью вот и нам пришлось проделать довольно не много манипуляция чтобы эту штуку ускорить и потом было проще поддерживать вот проект дальше вам расскажет мишулин моя часть повествования берет свое начало в конце 2018 года когда в рамках оптимизации расходов на поддержку зоопарка всех api который у нас были мы решили объединить jaws скриптовая open graph quelle и на шубу темная пелена питоне в единое open graph quelle написанная на джаве нам важно было сделать это быстро потому что никто не хочет тратить на рефакторинг вы много времени получить то же самое просто пороть время разработчика но кроме того важно было выбрать метрики успешности главная метрика успешности была полная совместимость java скриптового api и нового api на джаве эта метрика wasting легко потому что граф quelle представляет стандартный запрос интроспекции через который вы можете получить схему и дальше через стандартный мертвую например сравниваете сортирую схему нового api и старые поддерживать таким образом схему совместимой и 2 2 метрика на который мы ориентировались это скорость работы то есть конечно же мы не хотели чтобы старая старая пи работала быстрее чем новое мы переписывали и оптимизировали поэтому за метрику успешности главного мы взяли скорость работы главной странице индекс афиши она составляла примерно 800 миллисекунд по старой схеме и мы целились в эту в это число теперь мы садимся на машина времени перемещаемся так далеко в будущее в мае 2015 года у нас написано игрока или пи на джаве мы проводим нагрузочное тестирование и ужасаемся результатом главная страница грузится за уже за секунду или даже больше чем за секунду и что самое ужасное примерно две три минуты после начала работы приложения она практически оказывается обслуживать запросы клиентов не выдерживает даже одного запроса в секунду это нас довольно сильно удручает но нужно с этим разобраться понять в чем причина мы начали разбираться с проблемы медленного старта на самом деле проблема медленного старта это нормальная ситуация для джавы эта картина на самом деле показывает работу прогрева just in time компилятора то количество циpкa которые мы выделили для наших машин граф крылья прогревает наш компилятор за две минуты мы можем конечно же залить все железом и выделить большее количество будут для нашего приложения но это плохо потому что только две минуты это эти c будут использоваться по назначению а дальше они практически сирии будут простаивать наше приложение не требует такого количества циpкa поэтому мы попытались решить эту проблему другими способами сначала мы попытались поменять жизнь компилятор мы заменили стандартный и ситу когда идет в комплекте с же в 11 на экспериментально гора ли вы какие-то на графике это дало нам прирост в производительности прогрева прогресс стала проходить за 30 секунд примерно вместо двух минут это гораздо лучше чем было вначале но все очень достаточно для того чтобы работать в продакшене следующим шагом было добавление специального скрипта прогрева то есть до того как открыть наши приложения в мир и дать доступ для него пользователям мы на протяжении минуты посылаем в него изнутри кода запросы которые составлены из логов пользователей за вчерашнее дни за вчерашний день и таким образом прогреваем наш компилятор заранее и когда приложение открыто в мир и в него уже пришли реальные пользователи она готова обслуживать запросы на максимальной производительности вот таким образом собственная мы решили проблему отложенного старта осталось проблема с очень медленным медленной работы приложения на самом деле когда мы анализировали медленно работу приложения мы выяснили что просто-напросто забыли одну очень важную часть которая была в городской липина но джесса именно там был лишь нарядись и который кошелек большие ответы мы добавили такой же точно кэш в нашем топе и обнаружили что запросы плана string срабатывает за 500 миллисекунд то есть мы кстати улучшили скорость работы нашего приложения получили более поддерживаемая pin технологиях который знает наш богатый готов поддерживать запустились в июне 2013 года в продакшен считаю это успехом дальше нам было этого мало мы конечно же захотели использовать всем всю мощь языка граф quelle для дальнейшей оптимизации работы нашего приложения мы взглянули на главную страницу яндекса пишет у на который на время работы который собственно мы ориентировались при переписывании и проанализировали то как она выглядит можно увидеть что здесь достаточно большой набор в списочной структур это рекомендованное событие редакции это событие которые будут ближайшие дни это какие-то персональные рекомендации для пользователей и если мы посмотрим на запросы клиентов то увидим что клиент никогда не используют данные полученные от сервера про pagination ему интересна только первая страница выдачи ему не интересно сколько запись всего находится в базе а в старом питонов мы пьем и принудительно так как это rest api и в нем по схеме должна быть должен быть данной пиги нации их вычисляли всегда принудительно это же поведение мы перенесли в наш игрушку или пи мы убрали из запроса данные о баге нации которые не были нужны и как вот видно на графике мы смогли про оптимизировать количество запросов в базу примерно в 4 раза то есть с 1200р ps да где-то 300 ps что было понятно как это работает я создал небольшой проект он занимается тем что возвращай информацию о топ 50 фильмах из топа кинопоиск а вот здесь перед вами типичный rest подобный граф коль запросто может вернуть данные про фильм и данной про pagination этого фильма мы видим модификатор фильма название рейтинг и данная про pagination всего фильмов 50 мы вернули 3 данный про pagination нам не нужны мы их убираем из запроса остается только информация про фильмы если мы посмотрим в логе работы приложения то увидим что первый запрос где мы вычисляли pagination принудительное запрашивали и требует 2 запросов в базу данных базы данных у меня выступал текстовый файл и видно что мы два раза читали этот файл фильмами во втором случае мы не запрашиваем total и только один раз читаем этот файл фильмами таким вот собсно нехитрым образом мы очень сильно уменьшили количество лишних запросов в базу это нас конечно окрылила обрадовало и мы подумали а где еще можно применить удобство этого языка граф коек для того чтобы еще лучше ускорить наши приложения мы снова взглянули на главную страницу здесь можно видеть что во всех списках для событий помимо собственного названия события и и нужно еще дополнительная информация это изображение это данные про наличие свободных билетов это стоимость билетов и вся эта мета информация должна быть запрошены из других источников данных то есть это не в одно и то же базе данных лежит например данная про цену билета или про наличие билетов меняется в реальном времени нам надо их обновляете в реальном времени это ведет к тому что перед нами в полный рост встаёт проблема m + 1 запросов то есть это мы должны сходить в базу данных за списком элементов и дальше по каждому элементу сходить в другой источник данных за метой информацией для решения проблемы n + 1 запросов в graph quelle и существует подход с дотла ударами довело до это такой специальный класс который позволяет объединять запросы по идентификаторам в низлежащие базы данных и посылать их туда патчами дальше из этого ответа составляется словарь идентификатор сам объект и дальше сервер при формировании отдачи клиента может из этого словаря получить объект вытащить эту информацию и сформировать уже результирующий джейсон эти data logger и работают асинхронно манере и в принципе вся библиотека граф quelle для джавы и для я думаю что для всех остальных языков предназначены для работы в асинхронной манере мы посмотрели на главную страницу и выделили части которые могут быть загружу загружены параллельно независима друг от друга здесь видно что баланс пользователя в программе лояльности индекс плюс меню сайта данные про подборки данные о рекомендациях и из системы рекомендации все вот это может быть загружено параллельно раньше за по реализации у нас отвечал клиент то есть когда у нас была старая схема с питом бэг-энда пи вся парализации выполнялась на клиенте мы перенесли ее на сервер и теперь клиент посылает один большой запрос а также граф quelle выполняет следующие действия сначала выполняется от модификация пользователя дальше с данными пользователя мы выполняем параллельный запрос в систему рекомендаций в систему лояльности в список избранного польза для того чтобы пометить что событие события избранные на в этом списке и собстна за своими событиями в списках по итогу такая парализация на сервере дает нам очень нехилый boost в плане производительность то есть тот запрос к с которой мы стартовали 500 миллисекунд стал работать 300 миллисекунд как видно на этом графике собственно помимо производительности перед пользователями crafter очень важный вопрос встает про безопасность работы граф queen как мы все знаем с большой силой приходит большая ответственность и если вы если ваш клиент может любым сложным запросом получить любой разреза данных из вашей базы данных то злоумышленник точно таким же образом может получить любой разрезан из ваших базы данных не знаю скачать всю вашу базу данных этим запросам или составить какой-нибудь сложный граф который вызовет отказ вашего приложения мы решаем такие проблемы через подход в от листов то есть вот минский интерфейс клиент перед тем как использовать запросу продакшене загружают тело своего запроса получает ключ этого запроса и дальше с этим причем и телом запроса может приходить в сервер и сервер в и проверив есть ли такое запрос в нашей базе данных от отдаст ему ответ если запрос не найден извините если запрос есть пожалуйста вот ваши данные по ним и безопасности в от листы дают нам много других преимуществ например клиенту не обязательно посылать собственно само тело запросов один из одни самых больших запросов которые у нас есть базе данных занимает около 20 килобайт при значимом рпц это достаточно значимый трафик и клиент на самом деле не обязательно его посылать можно просто использовать ключ запросам и вытащим сам запросы с базы данных и сможем его исполнить помимо этого это экономит время напарники запросов в горку или вы собственно парнем запроса это тоже достаточно значимая процедуры кроме того при загрузке запросов в список в от листов наш клиент может отправить его сразу же на нагрузочное тестирование и получить в итоге информацию о том сколько вы запрос будет работать на том железе пример который у нас ожидается в продакшене какой рпс наш сервер может выдержать при таком запросе и дальше соответственно с этой информацией мы можем оптимизировать производительность нашего приложения в том месте где это необходимо саша в своей части доклада упоминал про сложности граф quelle с мониторинга my и рейд лимитом на запросы из-за того что граф quelle использует только один point для обработки запросов эти проблемы мы решаем через уже упомянутые ключи запроса бывает листов то есть по ключу запроса мы можем например организовать мониторинг времени работы запроса по ключу и набора входных параметров мы можем организовать кэширование ответа пользователя потому что он зависит только от запросы и набора входных параметров ну и собственно рэй климент по ключу запроса имеет гораздо больше смысла чем рик лимит общей на все приложение целиком кроме того для безопасности в целом рекомендуется отключать где-то просто наград кайлин поинты и проверять равенство контента по значений applications джейсон кроме того для пользователей и граф quelle а очень важным является проблема обратной совместимости из коробки граф quelle не поддерживает версию version ность и за обратной совместимостью схемы нужно следить самостоятельно мы это делаем через юнит-тесты то есть у нас есть с примут у нас есть тестовый фреймворк приму то есть набор блоков данных и есть выгруженные из базы данных white листы по которым перед заливкой кода в основную ветку мы можем прогнать unit тесты и удостовериться что наша схема полностью обратно совместима с той на которой на которых выполняет свои запросы пользователей мы для себя получили удобный язык интерфейсов и удобная возможность для клиентов менять свое поведение свои желаемые данные без необходимости требовать какой-то разработки но не надо думать что граф коль это идеальная схема которой всем подойдет в любом случае например если у вас один клиент скорее всего open api даст точно такой же мощной типизации и точно так же будет работать как граф quelle если ваше приложение например требует ответов за единицы миллисекунд то время которое вы потратите на парсинг граф коль запроса может быть значительно ну и если у вас какая-то там простая предметной модель которая не требует каких-то многих вы вариантов отображения которые не требуют различных фильтров возможно тоже rest api или его по на пик будет работать и хуже чем граф quelle что же мы получили в итоге для себя в первую очередь мы получили удобный подход опередить в которая позволяет внутри себя инкапсулировать всю логику по работе с брендами это позволяет нам менять устройство наших брендов не обязательно перемещая об этом пользователь мы должны столько с сохраняется ввести мою схему а дальше мы можем например распиливать наши старые монолитные приложения на микро сервисы клиент даже об этом не узнает узнаю только что что-то стало работать быстрее или надежней ну и концепция подхода с дотла ударами очень полезно потому что она свела все общение с базами данных у нас к двум вещам первое это за какой-то сложный запрос по сложному фильтру за списком идентификаторов он может быть выполнен например на яндексе база данных вам даже не надо там в саму коллекцию база данных ходить изыматься можно вытащить список идентификаторов и второе это собственно запрос за самими данными базы данных по списку нотификатор который тоже выполняется точно быстро быстрее чем там как-то запрос премикс это все что мы хотели сегодня рассказать про игры вколем спасибо большое можно задавать вопросы спасибо большое вот наши финальные подарки вам держите разбираете кажется ибо подарка так да что-то меня софит ослепили совсем так не вижу где вопросы да вот давайте по центру спасибо за доклад вот такое просто вы говорили про то что запросы граф к или довольно большие 20 килобайт может быть мы не хотим их передавать по сети но вы не думали над тем что возможно как-то можно при компилировать заранее не парсить их каждый раз поставить их с база как я понимаю достаете из базы парсить их мнение вот как раз в этом и заключается на самом деле оптимизация то есть мы загружаем в от листы в базу данных дальше может быть при копировать и за сохранить в кэш приложения и клиентам точно передавать уже только ключ запроса а саму работу по обработке запросы которые должна выполняться при каждом запросе мы уже сделали заранее то есть получать как бы уже ну похоже на джипе это понимаю мы что на jit джексон также а да да спасибо так так так а не то я вижу тут бегают с микрофонами спасибо за доклад на счет сетевого кичи рования у вас есть такой лаэр то есть вы рассказали про этот и loader но скорпионам проблема в том что довольно сложно именно какие-то частые ответы чаровать то есть по моей практике несколько этому назад то есть если такие проблемы у вас я понял что вы запросы именно запросы кешируется а что она что насчет ответов мы каширу им большие ответы то есть у нас есть например небольшие ответ ну например там список актуальных экспериментов которые постоянно может меняться которые если запиши ровать то это может плохо закончится или например состоянии баланс пользователя которая тоже не очень хочется кэшировать потому что она может постоянно меняться если ответ небольшой то в принципе большой смысл ну конечно же кэшировать на на то что меняется не слишком часто и в принципе если это ответ не очень большой том то что он слабо ли пошел кэшировать его нет мы такой ник ширина привет спасибо за доклад не от два небольших вопросов первое у вас стоит граф киль в качество пегова аппетитная под ним какие-то бэг-энда кто перед бэг-энда и кто перед опеки твой смысле что за команды потому что чтобы не знает добавить какой-то сущность поля вам же придется его какие твои вносить изменения и в конечной сервисы то кто за что отвечает и как-то разруливаете у нас небольшая бэкон команда и поэтому там к вы такие как бы пустая получается разработчики которые мне она говорит времени у нас на спуске было для команды то есть одна там запишу отвечала другой отвечала за билеты вот но потом они как-то создавались смешались в итоге получилась одна команда которая отвечала за весь вот этот вот за все эти бэг-энда . загров quelle из бэг-энда там афиши билетов и так далее я могу привести пример сенью сервис у нас кинопоиск тоже использую краску или полностью там сервисов несколько побольше и там соответственно за графику отвечает выделенная команда и соответственно при разработке бэг-энда идет разработка микро сервиса а дальше идет дополнительная задача на поддержание работы вами по сервисов в графу или то есть это чуть чуть больше но зато это позволяет развивать верху или оптимизировать его очень лучше про что-то увидели будем занимается но потому что контракт фиксируется как бы между клиентом и игроку или мда и потом там не знаю мы передумали микро сервис выкинули какой-то добавили новый а контракт остался да то есть в общем у коллег рядом разные команды одна только граф калиостро зависит от того насколько большой или маленький сервис точки на поиск это огромный сервис там огромная команда опишет ну относительно небольшой сервис и второй вопрос про white list и это очень похоже на пытку automatic присутствует верес когда это она или вы что-то свою нет во первых в когда мы делали в офис ты автомат purchase так вырос еще не были поддержаны в рывком джаве и мы ждали чтобы он не посмотреть во вторых а то мы перешли через они работают как бы со стороны клиента то есть сначала клиент посылает запрос ему возвращается ключ а потом по этому ключу соответственно уже обслуживает запрос это как бы похожи но тут у нас запросто заранее за кошелева на сервере и клиент заранее знает ключ то есть это не не она какой момент у вас вот сохраняется вот через звать листы то есть соседи админка есть тогда у нас нет у нас есть прям специальная админка для этого то есть в три семьи клиент может гонять любые запросы там нет никаких white list of когда клиент построил свою свою работу он идет в продуктовую админку и в ней заливает свой white list дальше тесто может прогнать там на крыше инвестирование может получает ключ ну или задает ключ который инфицирует и клиента и соответственно и сам запрос и дальше уже с этим ключом может уходить заданными давайте вы наверное вот вопрос и другие завернем на цифровые кулуары да давайте еще раз благодарим ребят за отличный доклад"
}