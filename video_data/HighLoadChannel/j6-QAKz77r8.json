{
  "video_id": "j6-QAKz77r8",
  "channel": "HighLoadChannel",
  "title": "Репликация в Tarantool: конфигурация и использование/Георгий Кириченко (Mail.Ru Group)",
  "views": 1115,
  "duration": 3516,
  "published": "2018-07-19T13:23:05-07:00",
  "text": "так здравствуйте зовут георгий я программ mist за время которой работаю программистом я успел позаниматься различными технологиями занимался различными языками программирования и последние два с лишним года я являюсь членом картин проекта тарантул в этом проекте основном программировать на языке си и занимаешься различными вопросами частности репликация который я хотел сегодня с вами поговорить и так что такое репликация реплика ты сама по себе это процесс создание копий данных из одного места в другом соответственно реплика называются такие копии данных replicate используется для множества различных вещей например для создания хороших горячих и холодных резервов для создания аварийных копий для распределения нагрузки в рамках кластера и так далее какая же бывает репликация в репликации можно очень интересно итак репликацию можно классифицировать по двум признакам этапа и направлению то есть мастер slave когда мы имеем два члена кластера два члена репликации с разными ролями на одном происходит изменения он их реплицирует второму второй и к себе накатывать первый из них это мастер второе мы называем слой либо multimaster репликация когда изменения происходит на сразу на нескольких членов кластера и они этим изменили обмениваться между собой более интересная характеристика репликации является ее тип синхронная либо асинхронная если мы говорим об асинхронной репликации то мы имеем ввиду что фиксация транзакций происходит в согласовании с репликация этой транзакций на остальные члены кластера и в этом случае во всем кластер мы имеем одну версию данных который не разъезжается данный подход иметь такой недостаток что накладывает дополнительное ограничение на механизмы синхронизации между репликами на вычислительные ресурсы так далее и более простой способ это синхронная репликация когда фиксация транзакций происходит независимо от того были ли эти транзакции распространены по остальным членам кластера соответственно данная репликация приводит к тому что данные на reply нас лайвах появляются с некоторым запозданием более того если мы имеем multimaster конфигурации то версии данных на разных вселенных кластером могут различаться в силу того что операции могут перемешиваться процессе репликации и так в tarantul и мы имеем базовую имплементацию репликации с которой мы строим все остальные необходимые нам архитектуры и так replicate автор от ул она однонаправленная то есть настройка репликации всегда представляет из себя отношения slave мастер которым slave подключается к мастеру и получает от него изменения данных который применяет у себя 2 характеристика репликации в toronto является то что оно асинхронное когда фиксируется транзакция то изменённые строки записываются в журнал на сервере и транзакций считается зафиксированный в фоновом процессе репликатор читает эти строки из журнала и отправляет их слой вам также репликации в тарантул она построчно и то есть все изменения пишутся в журнал по одной строке о каждой измененной строке репликатор читать по одной строке и также по одной строке независимо отправляет их славу так же можно заметить добавить что каждый член кластера в кластере тарантул помечен своим собственным уникальным идентификатором который мы можем по которому мы можем определить конкретный instance и неким идентификатором в кластере либо порядковым номером данного данной реплики в самом кластере и так исходя из того что репликация в тарантула синхронная мы можем сделать вывод что данные всегда на репликах появляется запаздыванием и что возможна синхронизация данных здесь маленькая пиктограмм очка мастер slave дентифик атор и уникальный идентификатор указана для обоев реплик если же мы возьмем slave точнее мастер и подключим у в качестве слива по 2 реплики то мы получим 2 канала репликации и получится что обе реплики у нас игру играют ролик как мастера так если его и такое объединение канала в принципе ведет себя как банальная мастер мастер репликация в принципе нас никто не останавливаться чтобы добавить еще одну реплику в данную структуру и мы получим такой интересный треугольничек где каждые каждый из реплик связаны с каждым отношением master и slave также надо заметить что мастер транслирует свои сми не только свои локальные изменения которые были выполнены непосредственно на нем но и все изменения о которых он знает который к нему пришли со стороны других мастеров поэтому мы можем построить такую топологию где каждому мастеру мы подключим по персональному славу который банально может играть роль ход стенда и каждый слоев будет иметь копии всех данных всего бластера разумеется в данном случае если его не принимают врать операции потому что они своих никуда не реплицировать итак мы имеем класть и в котором у нас несколько мастеров каждый кластер производит врать операции нам необходимо уметь отличать на каком мастере данной операции было инициировано и пробовать каким-то образом эти операций упорядочивать для этих целей каждой операций приписываться два значения первое значение это идентификатор мастера на котором эта операция была произведена и второй это lsn это логично это монотонно возрастающей номер операции локальный для каждого мастера и исходя из л с н а в каждых мастеров мы можем составить представление некий ввести векторные часы которые описывают состояние каждой реплики в кулак и то есть вектор из lsn of где соответствующих позициях вектора находится известный нам lsn of каждого мастера нашего кластера итак после того как мы определились с общими понятиями репликации в тарантул рассмотрим вопрос как же создается кластер в нашей судьбе предположим и имеем 2 мастеров работают в режиме мастер мастер и к ним и приход хотим присоеденить третью реплику это реплика имеет свой уникальный идентификатор и но не имеет пока никакого назначить идентификаторы никаких данных для присоедини кластер существует специальный запрос join которая реплика выполняет одному из мастеров кластера в ответ на это join мастер отправляет реплики snapshot и регистрирует эту реплику в кластере как члена после получения проигрывания себя snapshot а реплика определяет свой идентификатор id3 мы видим на схеме и после этого она является равноправным членом кластера может подписываться на изменения и получать в себе репутационной потоки немножечко углубимся в то как происходит регистрация реплика в пластыри для этого она существует некий служебный space называемые удивления кластер в котором хранятся все члены кластера а конкретно хранится идентификатор назначенный этому члену при присоединении и его собственный глобальный дентифик атор вот пример с реального мульти мастера здесь мы видим однако джона не все так просто если мы вспомним о том что репликацию нас асинхронное то возможно такие ситуации когда две реплики независимо не выполняет joy на разных мастерах при joy не мастер выбирает первый паб свободны идентификатор и назначает его присоединяешься реплики случае которые мы видим на левой половине слайда оба мастера на знаем могут назначить двум репликам одинаково идентификатор что придет к конфликту в спейси кластер то есть каждый мастер будет иметь разные версии вот это вот space а это приводит конфликтами во-первых репликации между ними что мы видим в перекрещивающиеся стрелочках и в принципе делать невозможно как минимум для одной реплики подсоединения как макс но вы берете не будут работать и в принципе с мастера потеряет connect между собой для так что в этой ситуации избежать join должен происходить в строго на одном мастере мастер один на правой части слайда получает join запросы регистрируют обе реплики после этого данная регистрация изменив спейси кластер стандартным революционным протоколом расползаются по второму мастеру и принципе по всему кластер и все она становится хорошо и так каким образом нам сделать так чтобы все реплики и при подключения выбирали одного мастера таком воли такого мастера мы называем мы выбираем никого лидера который производит инициализацию всех reply как происходит выбор такого лидера это на самом деле очень простой реплика перед тем как выполнить джон выполняет подключение ко всем известным в конфигурации мастером после этого она опрашивает их состояние и выбирает из тех мастеров те которые уже являются проникались и равными потому что в ряде случаев конфиге могут использоваться использоваться могут быть указаны те реплики которые еще инициализируются после этого так как регистрация требуется запись в space кластер из всех мастеров выбираются те которые находятся в режиме bright white обл ну и в конце из получаю из полученного списка мастеров выбирается та который имеет наименьший uid таким образом мы выберем для всех реплик подсоединяю данный момент времени одного лидера который должен их успешно зовут trapper странице визировать отсюда мы делаем вывод что при поднятии кластера при массовом добавление реплик в кластер они должны иметь строго одинаковый список мастеров при инициализации иметь туда и именно инициализация когда реплика у нас изначально пустая но допустим у нас не получилось этого сделать мы забыли что-то поправить в конфигах у нас какой то остался артефакт на диске мы где-то ошиблись в системе тепло и в каком-нибудь сейфе и джон сделать не получается симптомами этой ситуации является то что какие-то из реплика может быть и все не создают у себя snapshot of и в логах от мастеров мы видим сообщение о конфликте в спейси кластер что же нам делать в этом случае в принципе наш кратер сейчас находится в не согласованном состоянии первым делом надо его согласовать нам необходимо сначала право лидировать так чтобы все подключаемые реплики имели строк одинаково конфигурацию по репликации чтобы нам эту стату не повторить после этого мы зачищаем space plaster от всех конфликтов мы находим в нем различающиеся записи на разных мастерах и удаляем их после этого наш кластер переходе согласовано состояние и с валютными конфигами мы можем повторить инициализацию реплик после того как мы с вами построили кластер мы переходим следующий этап каждая реплика каждый sleeve подписывается на изменение от мастер специальным запросам субскрайб и все мастера параллельно синхронно шлют ему свои изменения которые слоев накатывает у себя очевидно что все асинхронности операций при их накатывание на слове могут возникать различные конфликты операции могут накатываться в разном порядке давайте рассмотрим один из таких примеров а вот здесь нарисовано как у нас выполняется подписка с транзитивной передачи ученика стрелочкой надеюсь видно что допустим изменение с мастера 3 попадает на master 2 как напрямую так и через master 1 итак исходя из того что мы сказали то что каждая реплика имеет собственную историю в блог и соответственно порядок операций мы постулируем что глобального порядка операции у нас нет вот пример мы имеем два мастера будем считать что стартовое значение в клок их состояния равны 0 0 то есть 0 и тсн первого мастера 2 0 л с н 2 мастер оба мид одинаковой вы клоки и пусть чтобы мастера сделать ровно по две операции посмотрим что с ними может произойти на первом же шаге мы видим что вы клоки на об их мастерах разошлись так как оба мастера выполнили сначала пол своей локальный на них выполненной операции и получаем в и клоки 10 01 измененные блоки пока измененный в снг привыкла показано зеленым цветом после этого во второй период времени первая реплика первый мастер получать реплику от 2 а второй выполнять опять-таки локальной операции выплатят расходятся еще сильнее смотрим что происходит дальше дальше у нас первая реплика опять-таки реплицирует к себе данной со второй а вторая реплицирует к себе данные с 1 и наконец первая реплика выполнять свою последнюю операцию и 2 получает и и что же мы видим на этой картине у нас есть 2 мастера две реплики они имеют абсолютно одинаковый выплате в начале процесса и от тут одинаковые клыки в конце процесса 0022 но при этом истории заметных вы клоков истории операций разное а что если эти операции затрагивать одни и те же данные и при этом данной операции нетранзитивным скажем риплейс и делить между собой очевидно что обе реплики будут иметь различный различающуюся версию данных и на самом деле не всегда это хорошо и поэтому сейчас мы подумаем о том как мы можем эту ситуацию побороть а я предлагаю рассмотреть два способа первый способ это сортирования данных второй способ это логическую порядочной операции и введение специальных триггеров на репликацию что я подразумеваться родированием записи что если на разных мастерах мы будем изменять данные не пересекаются между собой в таком случае каждый данные каждый блок данных каждый такой домен будет обрабатываться одними и теми же операциями в одном и том же порядке после того как обе реплики обменяются между собой этим измененными данными мы получим а одинаковые версию данных то есть такая площадка и вершили consist of системы а недостатком данного подхода является то что во первых нам нужно необходим определять правила маршрутизации писать роутер который будет запросам уж тонизировать а данной диаграмме показана плети шнура тур вынесенными из тарантулов но на самом деле абсолютно необязательно нам никто не мешает ротор реализовать в самом таран в самых тарантулах и перебрасывать запросы между ними это на усмотрение пользователя программиста суть остается и второй аспект в ряде случаев мы можем себе позволить определить для операции некий логически таймс тем допустим если мы имеем большой парк рабочих мест на которых операторы изменяют данные то в принципе конечно таймс темпы мы можем использовать время и условно и считать то что данный таймс темп условно глобально монотонный для всех операций ну просто в силу специфики задачи такая задача у нас стояла на тонус проектов в этом случае нам необходимы можем писать выполнять операции записи на любом из мастеров но при этом нам необходимо каким-то образом изменять рипли к цию так чтобы при применении операции оставались только последние самые актуальные данные для этого мы можем использовать триггер и триггер будет сравнивать timestream хранящихся данных и данных пришедших публикаций и оставлять те данные которые актуальны они актуально отбрасывают данный подход в принципе всем хорош кроме того что он требует определять таймс темпы для операций что не всегда возможно и тем что он требует написание от пользователя триггера специфичного к тем данным которые он обрабатывает и данный триггер также замедляет процесс репликации но очевидно просто потому что нужно во-первых читать данные с локального из носа нужно их сравнивать нужно принимать решения и дальше действует соответствии с ситуацию 3 еще один аспект который я хотел бы рассмотреть это синхронизация данных раньше я сказал что что репликация синхронная то есть мастер в принципе не знает а какие за его данных ушли на slave какие там применились какие не применились для того чтобы эту ситуацию побороть в протокол репликации между мастером если вам были введены а а как пакеты пакеты с подтверждениями когда слоев получать пакет от мастера с некими лагами со строчками то после получения этих пакетов строчек он отправляет мосту специальный акт пакет который содержит в себе текущий локальный выхлоп данного слова вот допустим рассмотрим тот случай когда нас есть master и slave и мы покажем 3 колоночки первое это вы клок мастера 2 колоночка это сведение мастера а реплики ок это то что тот а тот последний вы клок который мастер получил от реплики и а вы клок слова здесь у нас мастер получает четыре строчки его эластин и соответственно растет что показано в клоки после этого он успевает отправить три строчки славу сливок у тебя накатывает и изменяется его вы clock после этого осторожно sleeve прочитал пакет изменений он отправляет ему ок пакет со своим выкл оком на предыдущем этапе платите вниманию был 30 данный пакет доходит до мастер и мастером avis у себя состояние и при этом отправлять последнюю четвертую строчку к своего в данный момент времени мастер точно знает что a slave скачал три первых операций успешно себя их применил и на финальном этапе след правит последний шаг теперь мастер точно знает то что вы клок слова сравнялся с выкл ока мастера что обе реплики синхронны это мы используем тоже в нескольких проектах для того чтобы убедиться что данные записаны на какую-то реплику на самом деле записались и при падении то реплики они не пропадут а теперь давайте посмотрим как же мы с вами будем мониторить кластер тарантулов и я предложу вам несколько рецептов которые можно использовать в реальной работе и так основной структуры для того чтобы мониторить тарантул в целом частности репликацию является бокс info это такая важная табличка которой в принципе введя в консоли любой из вас может увидеть и посмотреть а в этой структуре от нас применительно к репликаций указаны следующей вещи и d единичка это означает то что данный сервер является первым в кластере его lsn соответственно хранится на первой позиции в блоке дальше его уникальный идентификатор такая величина которая была сгенерирована примется лис от этого мастера и оставлю от это с ним на все время его жизни после этого мы видим lsn 5 это означает то что данный мастер до того как я сделал boxing выполнят пять операций и соответственно вы клок в данном вы клоки мы видим то что 15 и 21 это означает что есть еще один мастер который успел выполнить одну операцию следующим пунктом является нас реплики чем реплики что содержит в себе информацию о всех известных на данные реплики членах кластера для каждой реплики показанные идентификатор и и воюет это то что можно мы можем взять из space а кластер также если данные реплика является для нас мастером как данном примере replicate номером 2 является мастером для реплики номер один мы видим такой раздел как up stream в этом разделе покажу статус репликации follow это значит что у нас все хорошо что реплика slave следует за мастером видим пойду это время прошедшее с последнего взаимодействия между мастером если вам видим лак лак это как раз запаздывание последний принятой строки time stamp а от того момента как эта строка была выполнена на сервере ну если мы являемся мастером то мы видим в клок слайго как раз то что мы получим акт пакетах чем мы говорили до немножечко раньше с помощью с помощью бокс инфо можно в принципе оставлять базовый мониторинг бластера тарантулов теперь давайте посмотрим что же происходит с бокс инфо когда что то идет не так предположим мы потеряли одного из мастеров он у наступал у нас разорвалась сеть принц случился что угодно выключился электричество сразу же бокс инфо мы видим следующее изменение что поменялся статус об стрима он стал disconnected дальше мы видим idol 1600 2 секунды это означает то что с момента disconnect а продаж прошло уже 1600 две секунды и также мы видим место чп ну здесь банальная просто выключил strada и случилась ошибка на сокете как принципы поведения в данной ситуации вполне очевидная нужно понять почему мастер упал куда он делся тот снова починить его поднять и тогда а репликация становится сама так как слизь периодической фашист осуществляет запросы и пытается переподключиться случае если подключение не работает на очень частая проблема которая у нас происходит это потери к слога тарантул периодически пишет снапшоты и постоянно пишут их слоги этих блоков может быть очень много ее снапшоты x локи отбрасываться по определенной политики для того чтобы банально не забить и полностью диска и пространство предположим если некоторые репликах некоторых слоев какое-то время был не функциональным не скачал себе дельты с этого мастера то мастер мог данные к слоги отбросить но удалить просто собрать мусор реплика когда будет выполнять попытку подключения к мастер а получит от него ошибку о том что мастер не может оттранслировать ему требуемых слог что мы в принципе сразу же видим в бокс info статус у нас является стоп и место специфический метод для данного конкретного случая здесь я банально удалил одну запись лога все репликация встала что можно сделать данном случае на самом деле сценария развития событий у нас ровно 2 если нас много мастеров вполне вероятно что экологии заданный интервал времени есть на других мастера допустим на них больше места и либо просто банально не успел отработать garbage collection в этом случае у нас все хорошо реплика будет считывать их слоги с остальных мастеров так как а репликацию с является независимым со всех мастеров нас life догонит свой вы клок да никого не котором состояния соответствующего состоянию мастера после этого мы перезапустим репликацию и все станет хорошо все будет работать как бы полном порядке так как мы должны помнить о том что дельты операции логе хранятся на всех мастерах на всех членов кластер а то есть принципе нет никакой рад вас как именно мы в данный момент сделаем загрузка и а более неудачный сценарий когда данные к слоги были удалены на всех мастерах либо мастер был всего лишь один что нам делал данном случае на самом деле в данном случае сделать по большому счету ничего нельзя но есть сценарий по которому данную репликой можем ввести в строй так как бы так как будто бы с ней ничего не происходило для этого мы должны запомнить ее юид после чего реплику выключить японцев 10 и данные так чтобы реплика стала пустой не инициализирован и после этого мы заново нецелевым эту реплику использую маленькую хитрость для инициализации мы используем старый сохраненный uid для чего это нужно так как ни один из мастеров не знает ушла данная реплика совсем или нет the space кластер при удалении реплики не изменяется если бы мы инициализировали реплику своих заново он бы сгенерировать себе новый юит заново зарегистрировался в кластере получил бы новый тэн тифе катар но так как количество идентификаторов tarantul ограничено 32 32 а мы понимаем что это весьма ограниченные ценные ресурсы просто так разбазаривать этими дикими катарами мы не хотим в этом используем старый uid данное будет реплика данный sleeve получит опять свой старый газификатор скачается мастера snapshot из этого сна фото продолжит работу и в принципе мы опять переходим в нормальный рабочий режим нашего кластер а еще один случай который часто встречается у людей иногда реплика становится не нужна он допустим поменяли конфигурацию кластера и админы и либо пользователи без всяких сомнений банально удалю выключит эту реплику удаляет отовсюду не ударит вас конфигурации а потом у них возникают проблемы при дальнейшей работе что они допустим не могут сделать новый джон потому что них не хватает и нотификатором почему это происходит потому что тарантул мастер сам не принимает решение о том что данные реплики уже больше нет и никогда не будет и запись в спейси кластер остаются поэтому если вы хотите удалить полностью реплику либо если она безвозвратно потеряно а вам нужно что-то здесь со спайсом кластер с этим идентификатором на самом деле здесь есть два простых сценарий либо вы просто удаляете если она вам не нужна либо если вы хотите ввести в кластер новую реплику либо вереницы лидировать ту же самую да допустим вы можете банально перес пользоваться стараются реплики который был она получит новый тот же самый трети fi катар просто перри использует его и продолжит работу под старым именем здесь как бы на вкус и цвет хотите вы сохраняете юид либо вы хотите новую для новой реплики чтобы допустим отличать в какой-нибудь системе там внешнего мониторинга еще один из флотационный аспект предположим наша реплика долгое время была offline а при этом на других репликах на других мастерах происходило активная работа данные изменялись а теперь мы хотим эту реплику этот слив включить обратно в работу мы его починили допустим поменяли какие-то диски так далее но очевидно что данная реплика при включении будет иметь сильно отстающий набор данных и мы не хотим такую реплику сразу вводить в работу что вы могли бы сделать мы могли бы запустить эту реплику сидеть смотреть пока ее в клок не догонят адовы клок а мастера да после этого прикатили там какой нибудь там режим включите или сами что-то в таком духе но это тяжело нудно и неудобно для того чтобы она ситуацию побороть были введены три параметры аппликации связаны с кворума вот здесь показан пример и что эти параметры означают первый параметр означает минимальное количество мастеров с которыми данная реплика должна быть в синхронно в данном случае под синхронностью поднимая понимается отставания не более чем на 0 1 секунды при этом процесс старта ждет событий синхронизации не более чем 30 секунд за 30 секунд мы не сможем догнать двух мастеров как минимум на 0 1 секунды старт реплики закончится ошибкой либо если мы успеваем это сделать реплика переходит в рабочий режим он не включается листон она готова принимать запросы на самом деле очень удобно очень удобно казался механизм но с другой стороны если допустим у нас членов кластере недостаточно какие-то мастера у нас допустим не работают а админ забыл уменьшить параметр коннектору то данная реплика будет всегда выдавать по таймауту а если тайм-аут большой то будет возникать ощущение что данная реплика просто зависла найти параметр нужно всегда обращать внимание также для эксплуатации в протокол между мастером и с фреймом введены keep-alive пакеты ну в принципе думы всем знакома ситуация когда ну скажем установки состав счастью какой-то времени ничего не делать а потом с удивлением видите что она перестала работать просто потому что умный роутер решил эту сессию без активности и ее можно банально дропнуть либо допустим другие сценарии когда у вас slave завис просто завис и не отвечать и некие пакеты вы будете считать слать у него пакеты об этом никогда не узнаете но просто потому что пакета по сети уходят она ничего не происходит либо и ваш слоем завис вы об этом не знаете но когда вам приходит пакет на мастер да вы как бы установить о том что у вас порвался connect через два часа как а это произошло как бы неприятной ситуации для этого мастер периодически в случае отсутствия активности больше чем реплики шум тайм-аут живет специальный но пакет своего слоев получать получать данный ног пакет просто отправляет мастеру свой вы clock ну то есть такое тоже небольшой ремень синхронизации данный данный механизм как минимум позволяет вам мониторить состояние канала между мастером и с левым если вы видите то что у вас он вам гарантирует то что вот например от stream статус у вас адекватной текущей ситуации соответствуй текущей ситуации если же любой из пары мастер slave не получает пакет любой пакет пакет с записью пакет со ком-либо но пакет в течение четырех интервалов репликация time out the выполнять разрыв подключения и slay в данном случае если он еще живой попытается выполнить подключение заново ну то есть допустим у вас упал роутер у вас порвалась связь с лифтом в течение там скажем 4 секунд не получал таких пакетов от мастер он закрывает свой сок и подключается звонок мастер и репликация у нас восстановилась ну и последний момент который я хотел обсудить предыдущие диаграмме мы видели что мо мастер транслирует славу не только свои локальные изменения но и изменения всех мастеров которые пришли к нему как своего мужа исключением очевидно конкретно слова потому что стать отпираться обратно смысла нет если у нас три мастера то ситуация на самом деле не такая страшно нас всего лишь каждый slave получит каждую операцию два раза счастлив иметь их фильтровать используя вы клоки с этим проблем нет проблем возникает том что допустим у нас 6 мастеров объемных full меж тогда каждый sleeve получит каждую операцию пять раз а если мастеров еще больше то данная ситуация во первых вас нарастает объем избыточности его трафика во вторых у вас растет квадратичных количество коннектов в связи между репликами что можем мы сделать в данном случае давайте вспомним что условия на одинаковость списка мастеров применяется только к репликам на момент их и не целью отцы то есть когда мы находимся в состоянии субскрайб мы абсолютно не обязаны иметь одинаковые одинаков мастеров на который мы сейчас подписаны второй момент который мы должны определить что все мастера должны иметь маршруты ко всем своим чтобы любая произведена операция запись на кластере достигла всех его членов это понятно почему да то есть если мы вдруг в классе разделим на две части дата дано нас разъедутся очень быстро и третий момент что данные из бы избыточно не всегда плохо избыточность дает нам надежность если мы имеем нулевую избыточное что падения любого из членов кластера просто разделяется на две части поэтому мы должны сохранять баланс между избыточностью которую нам дает некой топология и и и надежностью вот например простой пример той топологии которые можно построить или 6 мастеров в данной схеме каждый slave получает изменения от мастера не более чем через два прыжка при этом избыточность равна всего 3 по сравнению с пятью если бы мы использовали структуру full меж ну и очевидно то что выпадение любого из членов данного кластера наверное даже 2 не приводит к тому что данный кластер разделяется на несвязанной часть и так как итог доклада я хотел бы порекомендовать достаточно очевидны простой список действий которые можно применять первое если у вас есть какие-то непредвиденные проблемы с репликации до которых вы не знаете что вам нужно сделать первым делом вам нужно проверить параметры репликации к ним я отношу список мастеров которым подписан данный slave первое второе кворумы 3 keep-alive что если у вас на мастере на основе разные keep-alive и отнесут пакеты другу с разным интервалом только когда их будете дорваться поэтому нужно всегда быть уверенным что keep-alive у нас сравнимый и на мастере и на слове если вы проверили настройки репликации как бы вам ни чего не помогло тон нужно очевидно сделать бэкап данных потому что если вы начинаете какие-то эксперименты своим кластером выполнять какую-то неосторожное действие это действие будет реплицироваться по всем репликам вы свои данные можете определять безвозвратно после этого можно попробовать каким-то образом разобраться что-то перезапустить перед стартовать может где-то что-то почистить ну и конечно же если ничего нам не помогло то есть два канала по которой вы можете получить помощь это наша тарантул этому все о нем знаю и страничке нашего проекта на гитхабе то есть если у вас есть какая-то проблема вы нашли ошибку в омске не помогли то лично я и я думаю вся наша команда будет вам очень благодарность вы заведете ticket чтобы мы об этой проблеме знали чтобы мы ее для вас починили выкатили вам апдейт она в принципе я то что хотел рассказать рассказал я готов отвечать на ваш вопрос в принципе у тарантула есть ряду журнал который мы называем валом когда вы производите некие действия с данными то в этот веду журнал впишется новая строка которая была получена то есть у нас каждый space состоит из staple of data by the pool газовой строкой новый получено вот эта данной операции the pale пишется в ряду журнал эйдан целиком то по то есть мы не пишем операции мы пишем таблы который мы получили данный этап после этого реплицируется в как есть так можно вопрос то конечно спасибо за интересный доклад скажите пожалуйста что будет происходить если при инициализации нескольких новых членов кластера помрет главный мастер которого они все нашли в конфиге хорошо на то есть вот несколько проинициализирована несколько получается нет и они наверное получается должны найти другого мастера внимание так спасибо за вопрос я понял смотри что получается а допустим мы присоединяем с вами четыре новых реплики которые выбрали себе одного лидера две реплики по успели получить снапшоты это означает то что в данном стоп шоке уже эти реплики зарегистрированы они там уже есть и наш лидер падает тогда у 2 реплик произойдет ошибка старта ну то есть они не смогут стартовать то конечно не смогут быть проинициализирован и эти две реплики запустят заново процедуру join и в принципе у них есть как бы есть такая ситуация что старый лидер мог успеть данный отрыв от реплицировать новыми членами либо не успеть если он не успел этого сделать да и и новым лидером является не тот кто только что подключился дата возможен конфликт этот конфликт можно придется решать вручную то есть данный момент у нас сожалению пока не покрыт но из опыта могу сказать что-то остается достаточно редкая но как бы я извиняюсь хотел дополнить как бы это вытекает из того что само по себе репликация синхронная то есть в идеале конечно же было бы добавление новых членов кластер синхронизировать перед тем как что-то отдавать дабы данная ситуация могла быть разрешено и я могу что мы над этим работаем но никаких сроков назвать не могу пока к сожалению такая нет с выбором разных мы стоить когда вы делаете диплом ну допустим вуди блоки сразу 10 реплик да то между собой пока мы не выбирали одного лидера они вполне впадали в конфликт такое было у меня есть вопрос спасибо за доклад два вопроса первый по пробы копы вот снять и backup а под нагрузкой возможно или это предполагает полную установку как бы нагрузки снятие и тем как что-то там восстанавливать смотрите у тарантула есть встроенный механизм snapshot а когда мы делаем snapshot то у нас старые записи перестоит удаляться то есть тарантул переходит в систему кабы versio нирования и snapshot делается именно по тому срезу данных который был но на момент вызова данного snapshot а при этом все новые данные вполне могут писаться десна из ограничение что сейчас во время snapshot а нельзя сделать в дельта есть нельзя создать новый space' эти создать новый space' удалить старый то данная операция у вас залипнет на время snapshot а скажем так над этим тоже работаем я думаю что когда-нибудь это появится да за деталями лучше конечно обращаться к юхи на кириллу и либо к стати но осипова но сейчас на момент насчет и как бы сейчас у нас backup используют механизмы snapshot а и на момент бэкапы на момент на фото processing не останавливается спасибо а на второй вопрос по поводу сплит brain вы сказали если там провел соседка пополам они довольно быстро зайдут допустим это произошло какая как микс морда или как не выбрать какую-то половинку то есть пять для этого или какие средствами смотрите на самом деле ответ на данный вопрос очень сильно зависит от той задачи которые вы решаете а предположим если вы использовали тот механизм который я предлагал ну ну секундочку здесь предположим у вас произошел сплит да но так как у вас в разные части кластера будут записываться непересекающиеся домены данных то при объединении членов кластер опять в одно целое рассинхронизацию вас не произойдет второй момент опять-таки зависит от того насколько какова вероятность того что данные одни и те же операции над одними и теми же данными попали в разные части кластера в принципе обнаружить такие конфликты сейчас достаточно тяжело потому что если они выполнены на разных мастерах они изменяют разные компоненты выкл акадо а в блоке мы сравнить ну в принципе не можем просто потому что они многокомпонентные то что они векторные величины и такие ситуации желательно конечно я думаю что как раз такие ситуации были у нас люди проводили инспекцию данных смотрели пологом что куда писалось в принципе есть встроенный механизм который позволит вам прочитать эту журнал им тарантул локально вы можете определить те данные которые менялись и банально посмотреть если пересечении этих данных между теми компонентами кластер и которые вас получились спасибо большой зал н да у меня вот немножко flava повод как раз этой картинке скажите возможно ли репликация нам больше чем один слоев разумеется смотрите вы можете к одному манок если мы посмотрим допустим на самом начале картинку которая предлагала с более сложной топологией до одну секундочку и жена у нас вот осмотрите репликация у нас сейчас это не прерогатива мастера и инициатором репликации всегда является slave slave инициирует рипли коту специальным запросами запрашивать у мастера его дельты начиная с никого момента времени сколько запросов таких получит мастер столько репутационных потоков он и создаст в принципе репутационной потоки от это не обязаны пересекаться по времени мы можем подключить 2 разных слова встают на разными начальными точками да и они будут независимо проекту себя логе вот допустим здесь мы видим то что мастер один реплицирует свои данные на три слева тогда вот вопрос следующем допустим у меня существуют два слои в один мастер так я просто возвращаюсь к докладу который был утром так как репликация асинхронная допустим у меня мастер упал в данный момент я не могу его поднять для там восстановление сервиса я решил принимаю решение про могут один из слайдов мастита что происходит в дальнейшем когда мой предыдущий мастер он вот я его починил то есть потенциального данные опять уже разъехались ты сидят на я так понимаю это тура вручена трейдеры ником смотрите вот дальше по докладу я рассказывал о том как мы можем с вами удостовериться что мастер свой донат реплицировать в ряде задач им это уже использовали но там задача тыкал с тем что данные можно операции правки можно было накатывать сколько угодно раз то есть если у вас операция прошла вы знаете что она вас от реплицировать если опираться не прошла в ее операцию повторяйте заново на любой другой реплики да и она вас там выпрет сможете быть уверены что она вас появилась но ситуация с конфликтом смотрите исходя из того что вы клоки у нас компонентов и клоков у нас разные для каждой реплики физического конфликта при репликации не происходит конфликт возможен по данным если же вы сначала записали на мастер одни данные он вас упал вы повторили нас ных другие данные то чудо не разъедутся если вы же настоев повторить а хотя у вас равно может произойти смешивании с новой как тут если я даже сортирую да она у меня более чем один slave мне нужно будет вам можно вы то вам желательно выбирать тот slave который наиболее далеко отошел спасибо пожалуйста там вот люди еще раз спасибо за доклад подскажи зачем понадобился водитель идентификатор кластера как порядковый номер почему всего 32 почему не используют для этих целей юнит о котором ты тоже упоминал смотри у нас каждая операция помечено тем сервером на которую она произведена идентификатор это один байт бьюти то 16б операция бывают очень маленький использованию дав качество дать efi катаров приводит к тому что у нас во первых разрастаются локи второй момент а нам нужно уметь очень быстро находить соответствующую компоненту в блоке если мы получили некую операцию с идентификатором одним-то поэтому идентификаторам и и прямо выбираем из вы клок а соответствующего лисин и сравниваем с сыном операции да допустим при репликации если же ты имеешь юид тебе нужно иметь уметь делать некий lookup этого you и данное д принять позицию в и клыки так далее почему 32 когда это заложили мы считали что это будет достаточно на самом деле это не так как бы это уже понятно но сейчас у нас уже как бы есть некоторые наработки по той теме чтобы отвязаться то идентификатора чтобы он перестал быть глобальным данные ли данная операция с ним и снижает нас ограничение на количество членов в кластере она позволяет развязать некоторые вещи например делать различные анонимные реплики и так далее и тому подобное то есть как бы тот образ который спрашиваешь это историческое наследство да и мы это наследство будем изменять исправления понял спасибо пожалуйста правильно я понимаю что репликатор работает на каждом tarantul и в одном потоке процессор если по архитектуре тарантула у нас есть тээкс поток tx3 это тот red который выполняет весь процессинг у нас есть в old red это тот тренд который выполняет взымать запись ряду журналы и на каждый канал на мастер создается еще один thread который мы называем relay данный relay читает последовательность диска журналы проекте проиграть их в сторону слайго да то есть у нас репликация и processing развязанный в том числе и по процессорным ядром там получается некая такая очередь входящих запросов от своего которые все равно обрабатываются одним потоком почему не понял ну ты сказал что есть процесс который пишет журнал есть процесс который обрабатывает репликацию а процесс который про таких процессов на каждую репликацию один такой поток то есть каждый канал то есть вот допустим здесь на мастере один мы будем иметь три потока relay а поток riley умеет принимать нотификации от потока который пишет журнал для того чтобы продвигаться дальше по журналу и этот вериллий на себя полностью берет все взаимодействие с счастливом на то время после того как репликации установлена от и x и живет своей отдельной жизнью то есть у нас транзакционный поток абсолютно ничего не знает о том что работу перекликаться кроме того что ему периодически доставляют ок пакеты с вы клоками вопрос в общем в том ключе задавался что есть у меня трясло его 300 его так они все запросили репутационные данные так вот в каком если к это не знаю логоритмика четкая в каком порядке эти потоки будут обработаны в каком порядке все слои вы получат полный набор публикационной смотрите когда slave запрашивать аппликационной данного это делает одной командой субскрайб эта команда изначально попадает в 3 x 3 x 3 создает на каждую такую команду отдельный поток и передает полностью управления каналом этому потоку соответственно каким-образом потоки будут взаимодействует с собой как их зашкурить ваша система да никто не знает и по нему пасибо то есть как бы slave не осуществляет постоянный pulling мастера он один раз установил субскрайб и в этом subscribe живет до тех пор пока connect не будет пор want спасибо за рассказ когда я в ситуацию которую вы описывали повторю не хватило ics lock для того чтобы копию поднять так и вы говорю что нужно почистить данные на этой реплики и подключить ее заново но у нее получается в клуб будет меньше чем записанного мастер смотрите когда мы поднимаем реплику что происходит-то сервер тарантул первым делом сканировать свою рабочую директорию над для того чтобы понять существует ли там уже snapshot есть он там существует он его проигрывает после него проигрывать все логи и приходит к некому состоянию до которые кодируются его вы клок а вот эту данный вы клок используется для того чтобы сделать субскрайб и чтобы мастер отправил нам все операции которые произошли на данном мастере не раньше этого вы клок а да как бы нему не может кое-что что после то что вы клоки не сравнимый но мы можем опуститься в истории назад до тех пор пока мы получим вы clock сто процентов меньше чем тот который прислал нам slave если же и вот смотрите и если мастер не может откатиться назад от возникает как раз таки такая ошибка если же мы заново делаем bootstrap инициализирован за лидером реплику the master отсылает своего quieres создающему всему свой актуальной текущей средств данных с другим выкл о камни с тем который был на слове а с новым с тем которые у него прямо сейчас еще про join зачистка мастеров кластер а при неудачном joy не это тоже было здесь ситуация описана когда в чем это выражать это нужен команда кита вычитала смотрите базу данных через файлы на самом деле там все гораздо гораздо проще служебный space кластер ведет себя как самый обычный space тарантула просто его не видно нас мы набираем бокс . space . подчёркивание кластер и этот класс этот space нам становится доступным то есть работать с ним можно самыми обычными командами replace деле это insert и так далее select get a единственное отличие от обычных space of them что на операции с этим кластер повешены а специальные триггеры когда вы своей splatter вставляйте строку тот триггер срабатывает и создаёт необходимые структуры для поддержания информации о свежесозданный реплики на данном мастере если строка удаляете the trigger находит соответствующий ему структуре которые хранятся в памяти тарантул и удаляет их то есть освобождает если вы допустим хотите сказать зачистить вы просто делаете бокс ps кластер select находите в нем перед те записи которые которых там бы сейчас не должно нам очевидно бы допустим знаете те виды тех reply которые не которые не смогли подключиться дави их space классе сразу же увидите и потом по 1 по 1 эти строчки удаляйтесь кластер эти изменения дальше расползаются по стальным мастером и в принципе достаточно зачастую зачистить только один мастер до чтобы получить консистенцию состояния пожалуйста можно спасибо за доклад как принц пожалуйста вот то что вы сейчас говорили и еще раньше упоминал что есть у меня мысль не оставляет что можно сделать вывод что возможен код вероятно ло котором можно на репликации как-то влиять на пример в каких-то сложных случаях там то есть вводить какую-то свой лайк это вообще дар чувствует да смотрите сейчас вы можете на любой space повесить он replace триггер который будет вызываться в том числе и для репликации данный триггер и используются нами в одном из проектов в нем мы решаем конфликты между операциями которые имеют некий логически таймс темп да по которым эти проц и разруливает в принципе сейчас у нас как бы есть уже наработки по тому чтобы вызывать влажный code page лидерский по разным событиям например установка соединения с мастером либо словам разрыв соединения смены состояния там follow на стоп на disconnected инициализации в том числе и на конфликты до нас есть он и если сейчас допустим в 110 этого не нету то я думаю что скоро то появится но опять-таки деталей когда это зашит урина когда это будет лучше спрашивать у менеджеров пожалуйста еще вопросы да быстро вопросик предположим что я хочу защититься от потери данных в случае если у меня упал мастер а вот можно ли как-то реализовать этот эскиз tarantul и если у вас какой-то навык не значит ванной репликации посмотрите про синхронную репликацию есть то что я рассказывал но к сожалению то вас не защищает от того что ваш тарантул внезапно умер то понятно да у нас есть ход стендбай когда вы на одно и то же железо очки да который шарит один диск поднимать рядом вторую реплику это реплика читает напрямую журналы и на катоффе у себя если ваш мастер выпал у каким-то данным допустим каким-то причинам не связанным с общим выходом из строя той машина которая исполняет ну допустим у него кучу золота в мемориале сиквел ты или кто-то там что-то намудрил да и он умер the hot стендбай у вас будет иметь ровно те же самые данные что и имел мастер так как он прочитает его за к меченый журнал у себя его проиграет а если же такой возможности нет то всегда чувствует ситуация когда ваш мастер совершил commit записал ряду журнал да но при этом данные отправить на слои вы не успел и в итоге вы потеряете свои данные как бы обойти эту ситуацию можно тем что требовать sing то есть в какие-то данные за к мите лидами вы получили ok данные достались пока сколько та реплика эти данные получат после этого ваш users кий код возвращает внешнему приложению кейда это вам может помочь но это не панацея и сухарной репликации она нужна то есть никто не спорит с тем что она нужна но какие-то случаи и и необходимости мы можем покрыть имеющимися механизмами спасибо пожалуйста буквально небольшой вопрос вы не рассматривали возможность причине звуки пера который в общем там все хоро количество на логичных продуктов которые не пятну используйте его как рублям esprit brain до которую да да достоинстве на кластер ну много чего я скажу вам даже больше звуки про мы используем вот у нас было утром доклад про выше орда в котором есть очень активное использование пера в принципе мы звуки при используем для того чтобы делать фолловер скажем у нас есть три мастером и два из них делаем readonly для того чтобы избегать конфликтов и когда в райт в рай то был мастер каким-то причинам падает и либо кто-то решает вывести из строя у нас есть уже написаны нами под проект коды которые допустим производит переключения мастера который производит мониторинг в том числе у нас есть некий проект который позволяет быстро пить лицензировать реплики не инициализировать в шарпа конфигом полученном звуке пера уже входит сейчас это не как бы это не в комьюнити этого нету это у нас дело с под конкретный проект но в принципе я думаю что сама библиотека для работы пиромана будет доступна как дополнение к текущей функциональности да да да ты так бы это не в ядре тарантула потому что завязываться на конкретную там систему хранения конфигов тип озу киперу но это как бы не очень хорошо потому что их система очень много они постоянно меняются иметь это как плагина у нас это будет и вот 2 варианта планируется что-нибудь типа двухфазного комета для тех случаев когда часть это из данные ну который вот хочется иметь от абсолютно верно у нас в принципе у нас планируется полноценной асинхронной репликации это будет как бы пока задача не самая острая и как бы по срокам я вам не могу ничего конкретного сказать но мы над этим работаем и рано или поздно она нас появится обязательно спасибо ."
}