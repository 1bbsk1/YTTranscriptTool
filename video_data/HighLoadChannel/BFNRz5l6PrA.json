{
  "video_id": "BFNRz5l6PrA",
  "channel": "HighLoadChannel",
  "title": "Как реклама Яндекса генерирует GPT-нейросетями заголовки для 3 миллиардов объявлений / Ольга Зайкова",
  "views": 463,
  "duration": 2667,
  "published": "2025-01-17T02:22:20-08:00",
  "text": "Всем привет друзья в очередной раз обращаю Ваше внимание у нас произошла замена и не будет рассказа про нейросети на китайских камерах мы желаем здоровья Максиму который хотел рассказывать про них Надеюсь он выступит на нашей следующей конференции и мы презентуем вам не менее интересный доклад про то как реклама Яндекса использует gpt вообще многих останавливает от использования gpt то что они супер ресурсо емкие и в лот сервисах их применение очень ограничено И вот Ольга сегодня расскажет нам про то как они в Яндексе смогли обойти эти ограничения Оля поприветствуем Всем привет И несмотря на то что мы сейчас на секции Сбер девайсов речь пройдёт про Яндекс и про то как мы генерируем рекламу используя достаточно небольшое количество GPU карт для начала хочу провести небольшой опрос скажите у кого есть не в продакшене поднимите руку воу много почти все А у кого в продакшене есть стриминговая контент инто Ага люди есть но мало процентов наверное 15 сегодня речь пройдёт именно про соединение тяжёлых процессинговый Давайте начинать о чём этот доклад мы поговорим Как устроена генерация рекламы в целом И как мы соединяли наш высоко нагруженный процессинг который обрабатывает миллиарды товаров и превращает их в рекламный и при этом мы используем тяжёлые модели такие как dssm бусты Яндек gpt и другие и фокус доклада будет направлен на то как были решены проблемы с нагрузкой которые возникали на нашем пути Ну примерно на каждом шагу сначала обсудим Что такое генерация рекламы Представьте что вы владелец крупного бизнеса к примеру У вас есть сайт где много-много ваших товаров представить себе такой сайт в интернете не составляет никакого труда это может быть яндексмаркет где миллиарды товаров это может быть Все инструменты ру Эльдорадо да впрочем любой сайт а также у вас может быть небольшой бизнес где вы тоже что-то продаёте и вы хотите продвигать Эти товары как это сделать Вы можете прийти в Яндекс Директ и завести рекламу руками то есть ввести заголовок ввести текст который будет отображаться на поисти добавить картинку и увидеть сво объявление на просторах интернета если у вас много товаров то наверное никаких эмко в мире не хватит чтобы завести такую рекламную кампанию поэтому вы можете принести нам описание ваших товаров в так называемых файлах фидах их как правило умеют выгружать различные модули на сайтах А если такого модуля нет то вы можете принести Нам лишь свой домен мы сами с помощью наших ль алгоритмов обойдём ваш сайт и поймём что какие сущности на нём похожи на товары и отправим их на генерацию именно ра моего доклада мы с вами и поговорим У нас стриминговая контент система Мы работаем на технологиях РТ поверх базы данных рус Но для простоты восприятия Вы можете представлять себе н Спарк или что вам привычнее для того чтобы рекламное объявление появилось должно сойтись два фактора во-первых должен быть активный товар то есть та веь которая в наличии на сайте А во-вторых должна быть задача на генерацию обявления Что такое задача на генерацию наверняка если у вас крупный бизнес вы не хотите рекламировать все все товары вместе по одной и той же ставке одной одним и тем же пользователем в одном регионе Вы хотите как-то гибко это разбивать Яндекс Директ представляет такую возможность Вы можете прийти в интерфейс разбить вашу рекламную кампанию на группы и для каждой группы задать свои настройки поэтому для каждого товара мы смотрим К какой группе он относится и также В задачах на генерацию в дальнейшем прорастут на банер такие как например информация о доставке мы совершим много-много Маги о которой мы с вами будем разговаривать весь этот доклад и получим рекламное объявление самой технологичной частью нашей генерации является подбор заголовка а именно та то что вы видите сверху крупным планом на поиске И то есть описание самого товара пори временем в даком 2001 году у нас была шаблонная генерация и как такового ранжировании не было мы выбирали подходящие по длине заголовки потом мы естественно захотели аранжировать все варианты заголовков которые у нас есть и выбирать лучший а потом у нас случился бум GP Нейро сеток и мир изменился нам пришлось совершить много-много изменений в нашей инфраструктуре чтобы заголовки у навались неями сейчас мы уже боремся за повышение качества поэтому внедряем тяжёлые берты в наше ранжирование чтобы сделать его ещё лучше посмотрим как мир выглядел до 2021 года представим У вас есть товар холодильник по цене 50.000 руб и какие заголовки благодаря этим шаблонам вы можете составить Ну холодильник по цене 50.000 руб холодильник в наличий выгодно купить и холодильник и у нас в процессинг был категори который понимал какой категории относится товар к примеру это может быть одежда или же техника и для каждой такой категории был заранее подобранный набор шаблонов и они были отсортированы по популярности с помощью опросов асессоров и раньше у нас не было ранжирование мы брали просто первый подходящий по длине шаблон Ну кажется что так реклама действительно появится у неё будет достаточно корректная заголовок но выглядело это ВС весьма Скучно поэтому мы быстро перешли к идее ранжирования сначала когда мы заказали у команды ML генерации какую-то модель которая будет ранжировать заголовки они принесли нам bert bert модель тяжёлая должна считаться на GPU Мы подумали Ну вот есть realtime Processing в нём десятки тысяч событий в секунду ну не будем мы на каждое событие ходить в Берт мы пока не умеем решать задачу Дружбы ритам процессинга и каких-то внешних походов поэтому мы попросили сделать что-то полегче что мы можем считать на CPU прямо в процессинг Так нам принесли dssm + catboost Который весил всего 3 ГБ и считался наравне с нашей продуктовой логикой то есть на тех же ресурсах в тех же машинках процессинга а потом настало время Яндекс gpt и здесь уже не попросишь принести что-то маленькое что считается на CPU и настало время больших новых инфраструктурных внедрений Давайте сначала подумаем как объяснить не сети что перед ней находится здесь вы видите пример нашего товара реализованного в Jon это Hyundai santafe и с помощью алгоритма генерации подводки неть уже может разобраться что перед ней Ну наверняка машина и сделать это она может по полям vender год modification ID То есть если бы мы рекламировали к примеру джинсы Ну венде бы точно не было выпуска вас бы вряд ли интересовал Давайте теперь подумаем Как сделать так чтобы наш процессинг узнал о несетевые заголовках естественно первый подход хотелось сделать максимально простым чтобы вообще понять есть ли деньги есть ли конверсии Есть ли счастье пользователей за этим внедрени и в группе ML генерации уже был процесс сбоку строящийся поверх мапри Дьюса который вычитывать через GPU и получал заголовки и они писали табличку заголовками и мы подумали А что если у нас процессинг уже умеет читать товары из очереди то Пускай он научится читать и табличку давайте сделаем это тогда pel обработки выглядит следующим образом Сначала мы берём батч товаров генерируем заголовки шаблонами получаются рекламные объявления эти рекламные объявления сохраняются когда-то в будущем подхватит их процесс оффлайн генерации перебой своим асом и сделает альтернативный заголовок к нам в процессинг придёт альтернативный заголовок мы с помощью dssm ПБ сравним этот заголовок и заголовок полученный шаблоном выберем лучший и поставим его на баннер чем такой подход плох Ну естественно что заголовки приходят нетай но при этом нас удивило насколько они конверсионные и за GT нейросетями действительно есть будущее чтобы не быть голословно Давайте посмотрим на пример того как выглядели рекламные объявление до появления Яндекс GP и после есть заметное отличие что Несе смогла вынести любимую киновселенную героев Marvel на передний план что наверняка привлечёт Ваше внимание а также сразу посветил какие-то важные атрибуты нашего товара то есть сказала что товар 12 дюймов шари размером 12 дюймов и их в коробке п штук снизу в описании добавила такие вещи как большой выбор выгодные цены что тоже привлекает глаз пользователей но порой нейросети имели свойство ошибаться и здесь вышел достаточно забавный пример нейрогенез манит модерация но на случай если всё-таки нейросеть где-то ошиблась и сделала с нашим товаром что-то некорректное У нас есть отдельные типы событий которые мы умеем подкладывать в процессинг которые блокируют несетевые заголовки И как только мы узнали что нейросети классные конверсионные нужно внедрять Мы подумали что нужно переходить в мир онлайн генерации То есть как только к нам приходит товар мы нашли его задачи на генерацию нужно идти в нейросеть и спрашивать какой заголовок Ты подберёшь для этого товара но случилась большая неприятность у нас карт на наш поток у нас 3,5 млрд объявлений а GPU карт 22 штуки надо как-то жить Ну вы Спросите ну Яндекс такая большая компания мы на хайлоу Ну почему 22 GPU Ну как так вроде огромная компании и действительно у нас в рекламе есть некоторый л GPU на которых мы и обучаемся и строим наши ратай процессы и большинство карт у нас уходит на подсчёт им бенго ин - это векторное представление некоторой сущности то есть сущностью Может быть как поисковый запрос так и профиль пользователя то есть на поисковой рекламе мы ищем ближайшее к запросу объявление а в рамках рекламной сети Яндекса Где нам где нет запроса который может нам помочь в выборе мы смотрим непосредственно на пользователя и подбираем рекламу персонально и есть л карт на которых проводятся эксперименты именно в таком ле мы провернули нашу оффлайн генерацию естественно это пул ограничен поэтому её оффлайн генерация не устраивала нас тем что она долгая и мы естественно хотим уложиться в наименьшее количество GPU карт Ну потому что ресурс дорогой нужно чтобы железо на внедрение досталось всем Давайте попробуем написать на наш сервис генерации и представим как он выглядит у нас есть realtime Processing который обрабатывает товары он получил для каждого товара несколько шаблонных заголовков и пошёл в сервис нейрогенез у нас маленький 22 GPU и 22 машинки сервис ответил дальше нейросетевой заголовок сравнивается с шаблонами посредством ранжирования выбирается лучший крепится на баннер Давайте посмотрим В чём плюсы и минусы двух подходов с одной стороны есть Неоспоримый плюс что для новых товаров мы мгновенно получаем нере сетевого кандидата и также мы не вредим нашей архитектуре то есть мы не заливаем внешние таблицы процен а из минусов могу выделить капасити нашего сервиса мы могли обрабатывать лишь 10.000 объявлений в секунду а всего на процессинг льётся порядка 70к rps и то в спокойном режиме когда не приходит больших заливок но о них мы поговорим чуть позднее Давайте разберёмся Как нам жить если у нас данных в процессинг много а капати сервиса небольшое Ну вообще Давайте разберёмся какие события у на нас есть что мы обрабатываем во-первых это обновление рекламных данных во-вторых это событие включения и выключения рекламных задач на генерацию то есть Если вы передумали рекламировать какую-то компанию нам придёт события по выключать такие-то такие-то баннеры и мы это мгновенно должны обработать и в-третьих это представим что у нас есть потоковая обработка и в нашей обработке поселился бак естественно мы попортили Некоторое количество баннеров После этого мы нашли бак его пофиксили А баннеры с ошибками по какой-то причине мы не можем найти к примеру у нас просто была Не очень удачная нейросеть и мы не можем разобраться Какие заголовки оказались испорченными и нейросеть мы выкатили на какой-то короткий промежуток времени и отловили ошибку с помощью разметки нам надо как-то починить наш стейт с рекламными объявлениями и в этом нам поможет переобувается мы восстановили то дальше восстановятся и сами рекламные объявления но Стоит задуматься к чему вообще здесь рассказ проо обход и про починку процессинга Ну вообще он к тому что можно здесь понять Как найти ключ к несоответствию нагрузке на процессинг и нагрузке на сервис Давайте подумаем вот если мы будем ходить в нейросеть только на на события переобладнати всё-таки подумаем Как сделать лучше потому что 3 по дня всё-таки долго во-первых хочется отбросить незначительные изменения в нашем процессинг То есть если например цена не влияет на итоговый формат заголовка ибо то не будем её добавлять в подводку и соответственно не будем ходить в нейросеть для таких объявлений во-вторых нам нужно дать приоритет генерации для новых товаров потому что как только к нам пришёл новый пользователь новый рекламодатель мы сразу хотим чтобы он на поиске видел красивые заголовки и видел что его реклама классная конверсионная его объявления быстро набирают статистику и в-третьих нужно добрать в квоту запросов сервис то есть в тот ба в который мы ходим те рекламные объявления для которых перег не было дольше всего зачем это нужно Ну во-первых это ключ к тому что чтобы мы быстро обновляли наши несетевые заголовки при изменении модели То есть если модель поменялась нам за какое-то конечное время нужно уже классно срезали большой поток событий и примерно уравнял что что-то могло пойти не так как вы думаете что это могло быть правильно это изменение в нашей инфраструктуре лта процессинга посмотрим как он устроен У нас есть шардирование позиционированный очередь с товарами которые мы читаем и сам процессинг обрабатывает одну очередь в один поток Как он это делает он вычитывает Ключи из таблицы поднимает профили их обрабатывает сохраняет записывает в базу данных результат и тут мы поняли что наш процессинг совершает очень много разной работы и эта работа по-разному влияет на ядро а именно мы делаем продуктовую логику мы делаем лупы во внеш во внешней таблице мы ходим в сервис генерации мы сами у себя в процессинг считаем достаточно CP модели и захотелось оптимизировать CP то есть такая про инфраструктурное внедрение способное нам помочь в процессинг и мы решили давайте у нас чтение из очереди будет синхронным дальше обработку мы будем параллели тем самым распределяя нагрузку на ядро более равномерно а затем соединять результаты и делать одну операцию записи и получались так называемые сарды То есть под шарды распределение шар несколько потоков Давайте посмотрим повлияло на сервис инфе если раньше у нас один шарт в обработке очереди давал один запрос с количеством товаров X на сервис Яндекс gpt то теперь всё изменилось у нас уже н потоков соответственно и запросов N штук А вот банеров в нашем баче стало намного меньше кратно количеству наших потоков как это повлияло на сервис Ну во-первых не трудно догадаться то что выросла нагрузка летит летит просто больше запросов кратно числу потоков во-вторых на GPU попадает меньше объектов за раз потому что батч наших запросов уменьшился и карта оказалась не дозагрузка GPU Мы просто не можем себе позволить он настолько дорогой Что использовать его эффективно нельзя в-третьих вырос CPU usage потому что наше ядро тем и занималось что брало бач с товарами раско ждало пока карта это посчитает запаковывают до того момента как на клиентском сервисе истечёт таймаут то есть ВС мы начинаем обработку А прон уже не ждт этого ответа кажется плохо Дава подумаем что здесь является ключевым на самом деле Ключевое здесь естественно GP и нужно оптимизировать расположение наших объектов на карте поэтому Давайте подумаем как нам вернуть большой бач естественно хочется сделать вание и делать его можно в двух местах во-первых в рамках самого процессинга То есть у нас есть много потоков которые собираются пой с товарами во внешний серс пому дава Мы подумали Ну вроде бы это должно работать но наверное если мы специально стараемся максимально оптимизировать U Time на процессинг то мы так делать не хотим Ведь мы добавим ещё одно блокирующее Ожидание и процессинг замедлится а с другой стороны у нас есть сервис inf Яндекс gpt и он очень маленький относительно процессинга там всего 22 пода а запросов него льётся море То есть процессинг сильно больше по количеству машин и по числу запросов чем сервис Яндекс gpt поэтому давайте сделаем перепони там перед тем как отправлять товары на карту Мы сначала соберём из нескольких запросов их в один большой батчи Таким образом мы с одной стороны загрузили карту целиком сделали это равномерно а с другой стороны у нас Появилась возможность не просаживается быстро сервис под большой нагрузкой Но что же ещё могло пойти не так мы реклама и мы очень зависим от наших клиентов когда к нам приходит большая пачка обновлений к примеру вы огромная компания и вы решили поменять цены на всех товарах в вашем сайте устроить огромную распродажу или же мы сами решили лак залетел до небес итерации процессинга становятся чаще тем самым если у нас есть с одной итерации ограниченный набор товаров с которыми мы идём на карту в карту мы начинаем ходить всё чаще и чаще за не регенерацией и сервис inf на GPU просто не справляется с нагрузкой И падает начинает много пятисот что мы решили делать раз мы страдаем от крупны клиентов то давайте пойдём от решени этой проблемы и Мы научились внутри системы понимать когда приходит большая заливка то есть научились отличать маленькие изменения от пачки от огромной пачки и получилось две очереди одна которую мы обрабатываем штатно это все изменения все перепродать с большими изменениями которые мы читаем с ограниченной скоростью действительно тогда мы с одной стороны не начинаем процессинг для неё сразу а делаем Это по кусочкам и возможно Вы подумаете Что ну рекламодатели же будут видеть что они приносят новые данные А мы их не подхватывает буквально в несколько минут и это уже позволяет нам снизить нагрузку на сервис вот здесь вы видите на графике пример того как стал выглядеть наш такой игрушечный график лага после внедрения теперь очередь с товарами не вызывает такого сильного дисбаланса на лаг чте тепер при то ме ровный а конфигурация процессинга никак не влияет на Ирен то есть мы разработали алгоритмы которые равномерно загружают наш сервис а также Мы научились масштабировать наш процессинг то есть менять в нём как количество шардов так количество сашар дов число потоков число машин что угодно теперь сервис Независимый что мы решили сделать дальше вспомним про ранжирование У нас есть маленькая ДСМ п CB которые говорят что они то есть я дистиллированной версие Берта и за то время пока мы внедряли Яндек gpt эта модель значительно выросла если раньше она весила 3 ГБ то теперь она весит 8 а также у нас более тысячи машин и это только в продакшене и у нашей команды ML генерации были амбициозные планы по развитию этих моделей то есть хотелось внедрять что-то новое хотелось учить новые модели хотелось растить эти модели и мы поняли что мы просто будем жечь ресурсы на то чтобы поддерживать их в процессинг тут мы уже понимали что у нас есть опыт регенерации отдельно от процессинга поэтому может быть и эти модели вынесем во внешний мир как тогда будет устроена наша система приходит бач с товарами мы идём за задачами на генерацию под каждую задачу делаем своё рекламное объявление подбираем шаблонами заголовки идём в сервис Яндекс gpt получаем ро сетевого кандидата на установление заголовком выбираем лучший но уже не в процессинг а идём в сервис Рен получаем от него ответ и победителя крепим на баннер Про Сервис Яндек gpt Мы уже поговорили поэтому Давайте сфокусируйся на сервисе ранжирования сервис вышел как и сервис Яндекс gpt небольшой всего 50 машин но он позволил сделать нам очень важную вещь экономить Рам и гибко масштабироваться теперь у нас репликация не x1000 по машинам процессинга А всего лишь x50 потому что в этот сервис можно безболезненно доливать я по и доливать раму и репликация будет не столь большой Да и на этом внедрении мы сэкономили 75 рамы естественно в рамках рекламных технологий это не так много но так как процессинг не использует столько рам обычно то Для нас это оказалось очень приятной экономией и мы решили пойти дальше вспомним что наша модель получена путём децим затесь поня вотре которых заголовки выбираются почему-то плохо Вот вроде бы смотришь глазами есть лучший кандидат но не справляются его выбрать тогда Давайте вспомним Давайте раз у нас уже есть некоторый сервис сделаем для него внешний поход в Берт то есть в оригинальную модель которая имеет намного Луч лучшее качество тогда получится следующая конфигурация Мы идм в сервис ранжирования для определённых товаров идм в может ответь и нашу заточен по то чтобы работать как с ответом Берта так и без него и таким образом у нас вообще благодаря этому сервису появилось пространство для того чтобы внедрять неопределённое бесконечное количество внешних вызовов то есть помимо Берта может появиться ещё внешне сетевой поход в другую нейросеть а сервис является такой кй которая в конечном итоге даёт ответ процессинга Давайте теперь подумаем А что будет если ответил вот у нас был сервис нейрогенез кандидата Ну хорошо но победить шаблонный может быть качество не то Ну да В целом нормальное наверное с таким можно жить а вот если не ответил сервис ранжирования то вот тут происходит беда потому что нет рекламного объявления Мы просто не понимаем какой заголовок выбрать для баннера Давайте подумаем как с этим бороться вот подход первый это просто идея которую мы даже не стали воплощать мы уже имеем опыт того что мы подсовывает что-то в наш процессинг сделаем следующее Пускай если мы пошли в сервис ранжирования сервис ранжирование нам не ответил запишем те ключи с рекламными объявлениями для которых не удалось выбрать заголовок и процессинг Пускай считывает их опять что тогда получится сервис ушёл в полный датам процессинг начинает читать товары превращает их в баннеры идёт в сервис генерации сервис генерации не отвечает они попадают в очередь очередь идёт обратно и так по кругу много раз получается что-то такое поэтому мы пришли к текущему решению Теперь если сервис ранжирование не ответил то давайте мы будем завершать с ошибкой итерацию всего процессинга то есть повторять процесс генерации как это будет выглядеть У вас есть очередь с товарами мы читаем оттуда небольшой батч начинаем обработку подбираем заголовки идём ранжировать проранжировать не получилось тогда Мы отменяем всю итерацию повторяем её заново чем это лучше чем предыдущая версия Ну во-первых тем что у нас не Копится вторая очередь с ошибками и нам уже не надо делать двойную работу потому что с одной стороны у нас прилетают новые товары а с другой стороны сыпятся ошибки создающие на нас нагрузку по кругу поэтому теперь получился своеобразный ретрай и если сервис не ответил разово То есть Был небольшой пик нагрузки то мы просто повторим итерацию на следующий раз всё заработает А вот если сервис по какой-то причине полностью лёг то уже поступит звонок дежурному с информацией о том что сервис пятисот с другой стороны о том что Копится лак дежурный придёт починит сервис и начнёт обра только те товары по которым реально произошли изменения а не те которые лежат в какой-то очереди сбоку на этом наше с вами путешествие заканчивается и Давайте подведём итог и обсудим чему Мы научились мы разработали сервис для инса моделей причём как GPU intensive моделей так и тех моделей которые считаются на ядре во-вторых мы наладили взаимодействие процессинга и сервиса вычислений мы равномерно распределили нагрузку придумали алгоритмы перехода победили большие заливки также мы разработали способ для равномерных распределений непосредственно больших заливок то есть Мы научились читать не всё сразу а разбивать это на кусочки тем самым грамотно утилизируем и наши ресурсы и не Додо внешние сервисы и в четвёртых мы сэкономили терабайты Ram на том что вынесли наши модели во внешний мир а также используем для генерации достаточно скромное количество GP карт чем наш опыт может быть полезен для вас во-первых я хочу подсветить что связывать тяжёлый процессинг и иренс каких бы то ни было моделей вполне реально Даже несмотря на то что нагрузка в вашем процессинг сильно превышает возможности вашего сервиса во-вторых самовосстановление системы может быть полезным для продуктовой разработки в случае нейрогенез помогло нам переохолодження которых не удалось получить Ниро сетевого кандидата и в-третьих я хочу подсветить что важно равномерно распределять нагрузку в момент обработки событий потому что это поможет как вам утилизировать ваши ресурсы полностью и не иметь большого запаса на всплески нагрузки так и экономить ресурсы во внешних сервисах и не получать тайм при наплыв новых клиентов новых событий в четвёртых нужно по возможности искать способ не блокироваться GP вычисления и здесь у меня пример было два примера первый пример с несете заголовками если нейросетевого заголовка нет значит используем заголовок который мы генерируем шаблонами всё-таки у нас В итоге получается баннер и свои продуктовой миссии мы достигаем А был второй пример где мы сделали сервис для ранжирования не ответ которого уже приводит к отсутствию генерации и в случае с ранжирования мы не придумали как обходить эту необходимость ити во внешний сервис поэтому возможно похожие кейсы есть и в ваших сервисах на этом У меня всё спасибо за внимание А спасибо Ольга пожалуйста голосуете за доклад э ваша обратная связь очень важна и для спикера и для организаторов а но Те у кого есть вопросы пожалуйста внимание у нас целых три подарка от Сбер Devices от лода и от спикера и поэтому нам нужны ваши вопросы те кто смотрит нас онлайн в плеере есть кнопочка которая ведёт в чат и там с хэштегом вопрос Вы можете задать свой вопрос подарки доступны даже для онлайн участников А давайте начнём из зала поднимайте руки Давайте вот молодой человек во втором ряду Большое спасибо за доклад Александр сиров хотел спро А у вас один заголовок для каждого товара если нет то как вы между собой их тестируется понимаете Какой лучше А спасибо за вопрос У нас есть целый ряд экспериментов Чтобы понять какой заголовок лучше ну во-первых у нас есть AB и AB оно контентной трудностей есть два подхода КБ можно поделить Наши все наши рекламные объявления на две части на А и Б И всем одной части поменять заголовки на какие-то другие к примеру выкатить другую нейросеть и посмотреть что будет и сравнить А и Б на непосредственно в отборе в движке посмотреть на какие объявления больше кликают на какие больше конверсий есть другой подход которому мы сейчас вот пришли а у нас есть возможность в момент кандидата генерации это уже после нашей подготовки данных йм процессинг поднять несколько версий баз то есть база с немыми заголовками и база например с шаблон заголовками и посмотреть от какого кандидата генератора наш рекламный движок полу лучше объявление я понял и я чуть подробнее могу обсудить это в ларах Мне кажется здесь давать прям сильно развернутый ответ будет ещё одна лекция на 40 минут Да после доклада у нас будет дискуссионная Зона на выходе из зала Давайте следующий вопрос Вот в этой части зала молодой человек Добрый день Спасибо большое за доклад я хотел уточнить по пайплайн именно по моделям первый вопрос гоня ли вы генеративную модель на каждый баннер или как-то отбирается Ну только те ситуации где она нужна Если да то как таква и можно сразу второй вопрос то тоже самое про ранжирование то есть там есть облегчённый Берт плюс ой п CB и вы говорили что потом ещё отправляете в большой Берт при необходимости тоже самое если какое-то того когда это надо делать спасибо ага давай спасибо за вопрос нану с конца жи в случае с рованием Нам действительно нужно подобрать заголовок на каждое событие Когда у нас произошла генерация то есть да для каждого баннера мы идём и смотрим какой заголовок для него самый классный Вт мы ходим только на определённом срезе на узком товаров которые которые мы считаем таким болезненным где мы хотим улучшить качество вот поэтому в ходим не всегда в за когда Входи коэффициент небольшой я не буду раскрывать сейчас здесь технические детали но алгоритм просто аналитический вот мы смогли разметить эти запросы таким образом что мы знаем что там нужно повысить качество Вот про выбор объектов для похода в не россеть Вот был слайд здесь мы тригрим действительно не на каждое событие Мы сначала отбросили то что не влияет на заголовок То есть к примеру Мы в не роевые заголовки никогда не пишем цены потому что цены очень волатильные могут меняться по несколько раз там даже в минуту порою также у нас преимущество есть генерации для новых объявлений и в квоту запросов мы добираемся по факту В базе но мы повторяем генерацию раз в какое-то время Угу спасибо спасибо спасибо ещё вопросы Из зала молодой чек на первом ряду Да добрый день спасибо за доклад А у меня есть такой вопрос он немножко схож наверное с вопросом из той части зала А у нас есть большое множество товаров и очевидно что есть достаточно большое количество товаров которые очень похожи друг на друга Угу а почему используете ли вы какое-то каширование со стороны нейросетей потому что допустим берём товары там с одного сайта джинсы одной и той же модели и с другого сайта и два клиента вам дают рекламу на один и тот же товар по факту почему бы вам не переиспользовать просто сгенерированные э тайтлы для баннеров и если не отличаются товары между собой вообще по вашим данным Ага тут ответ на самом деле тоже длинный потому что нам у нас много рекламодателей и представим что вот у тебя есть магазин и ты обращаешься к нескольким агентствам чтобы Заводить себе рекламу и каждое агентство пришло выгрузил фид и фиды могут быть разные и мы по требованию законодательства должны для каждого товара проводить генерацию потому что может быть просто какая-то разница то есть Может быть разная цена Могут могут быть разные атрибуты также в момент того когда ты заводишь нам заводишь рекламную группу в Яндекс директе ты указываешь определённый набор атрибутов которые тоже прорастут на баннер в той группе в которой ты вот принёс товары поэтому эти атрибуты тоже идут в подводку для нейросети и Да поэтому чаще всего Нам генерацию нужно проводить отдельно но каширование тоже есть но я имею в виду случаи именно когда эти атрибуты не отличаются дру Да вот да каширование Тоже есть действительно как в нейросеть так и в ранжировании есть подводка и мы берём просто хэши к этой подводки и в памяти Да мы знаем крупных клиентов знаем популярные товары вот для них как раз очень стабильный есть слой каширование Понятно спасибо пожалуйста Следующий вопрос у нас из онлайна Роман вьюнов используете ли вы для сервиса инфе какой-то готовый инструмент или это что-то собственной разработки у нас в Яндексе есть большая-большая команда которая занимается Ирен сом gpt моделей и естественно для почёта самой модели мы используем но сами сервисы вот эти маленькие кусочки мы пишем сами то есть ту инфраструктуру которая принимает запрос отправляет их на карту забирает и пакует и отдаёт пользователю это уже наша разработка Спасибо И следующий вопрос также из онлайна от Виктора люткино не пытались ли генерировать несетевые заголовки с разметкой добавлять метки для подставления цен цветов и подобного занимаюсь инфраструктурой во гото Я не занимаюсь обучением моделей и моя команда тоже этим не занимается К сожалению человек онлайн если есть у кого-то в зале такие вопросы то я могу вас познакомить с человеком который в Яндексе занимается как раз обучением моделей для нас Ваших заголовках Нет плейсхолдер генерирует Яндекс gpt там уже сразу готовый финальный текст Да ну наверное тогда это ответ Спасибо Ели у нас ещё вопросы Из зала Давайте вот девушка на первом ряду спасибо спасибо за доклад я хотела узнать про равномерное распределение больших заливок вот Большая заливка По каким критериям определяется как вы это выяснили и чем в модели вашей работы большая заливка отличается например от тысячи других обычных маленьких заливок Ага большая заливка отличается тем что она имеет большой объём и приходит У нас в одну ну в одну секунду То есть там нет размазывания по времени А когда к нам приходит новый пользователь там пока все товары проде там уже есть просто какой-то лак и какое-то естественное размазывания что заливка большая у нас сбоку есть процесс который знает сколько товаров У пользователя в фиде и И сколько у него задачек на генерацию то есть вот та такую сводную статистику мы знаем и так как баннер - это товары умноженные на задачи то мы можем оценить Какой это поток если он больше определённого трешхолд очень большого то мы отправляем это в отдельную очередь и немножко её тролим а такого чтобы рекламодателя таких средне пришли в од секунду не будет Нет я думаю это физически мало возможно Ну и средненький рекламодатели они всё-таки такого прилива не создают Ну то есть можно представить себе Если вдруг яндексмаркет решит все товары поменять что это будет никаких там бизне компании не могут себе позволить такой объём спасибо м большое Давайте последний вопрос вот молодой человек В третьем ряду Спасибо большое за доклад Скажите пожалуйста То ускорение которое В итоге получили достаточно для ваших целей и планируете ли вы дальше развивать Ну ускорять свои сервисы уменьшать количество G может идти в тюнинг именно модели уже и какие планы в этом общем направлении нам Конечно бы хотелось уменьшать количество используемых GP пробовать какие-то новые модели но опять же я не занимаюсь разработкой и обучением самой Яндек gpt мы здесь инфраструктур Поэтому если про план то да А если про вопрос Правда ли что нам этого хватает в продукте то Давай отвечу Так здесь есть таинственное число 22 то есть 22 GPU и возникает резонно вопрос А почему Ну именно столько а именно столько потому что мы покрыли все наши продуктовые сценарии которые были следующими длях товарах мы преимущественно должны там на 95 проте или всегда получать Нера вых кандидатов и мы должны за конечное время у нас это порядка 5 дней стат меньше то для многих новых товаров ни ростех заголовков уже не будет И это будет грустно То есть вы как рекламодатель пришли принесли нам свой домен мы там Илим что-то на парсли на вашем сайте и вот заголовки получились неинтересные вы к нам Приходите в поддержку Говорите Я хочу чего-то получше а мы говорим Ну подождите Мы вам потом наге нерим нельзя так так А есть сценарий что их станет ещ меньше Ну как их если модель уж то конечно хочется их перекидывать наме да то есть использовать их в нашем сервисе но просто для других внедрений я понял спасибо большое спасибо за вашу активность рад что много вопросов Давайте те которые мы не успели задать Мы после доклада переместимся в дискуссионную зону она прямо рядом с выходом из зала а сейчас нам нужно распределить три подарка давай начнём с подарка от Яндекса и от тебя Давайте Да мне очень понравился вопрос нет да про алгоритмы переобзор выбор А давайте отдадим этот подарок первому человеку Александр нам на сцену а Александр давайте Ой а меня не видно Наверное Давайте на сцену прямо Спасибо за вопрос"
}