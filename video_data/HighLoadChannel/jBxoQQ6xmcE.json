{
  "video_id": "jBxoQQ6xmcE",
  "channel": "HighLoadChannel",
  "title": "Революция в управлении данными — рассвет графовых баз данных / Денис Пчелинцев (Девелоника)",
  "views": 497,
  "duration": 3896,
  "published": "2024-04-17T01:10:21-07:00",
  "text": "погнали на сцене Денис черенцев Добрый вечер сегодняшний доклад будет тоже также посвящен как предыдущие графовым базам а точнее построению более продвинутой аналитики на основе графах моделей и инструментов как базы данных хочу представить Меня зовут Денис я являюсь архитектором компании которая входит в состав группы компаний мы являемся командой и процессинговой соответственно помогаем нашим клиентам заказчикам строить bien аналитические системы и в частности в свою профессиональную своей профессиональной деятельности я познакомился с антологическими моделями и графами структурами алгоритмами довольно-таки давно это рубеж 96 98 года но на тот момент эти инструменты были крайне развиты было доступно только математическая база для этого ну как бы основа а Конкретно реализации инструментария не хватало вот последние там несколько лет стали появляться в частности графовые базы И настал момент когда этими инструментами можно пользоваться для своих целей целью доклада или как бы разделами доклада будет рассказ о том Каким образом мы решали конкретный кейс Какие цели задачи для себя ставили и соответственно какими результатами каких результатов добились и соответственно как этот опыт можно тиражировать транслировать на другие подобные задачи где уже применяются эти инструменты где уже применяются эти логические модели и графы И соответственно где потенциально можно их применить говоря Отвечая на вопрос почему же все-таки графы задача была достаточно тривиальная Вот но были свои особенности и как решение достаточно амбициозные мы постарались его решить соответствующие амбициозным подходом не типичным у нас у заказчика это крупная организация у неё по всем регионам различные набор количество каких-то подразделений отделов направлений прочего в целом они занимаются своей деятельностью в этой деятельности большую роль играет экономическая деятельность соответственно есть некие поступления денежных денежных потоков финансов их надо распределять сначала учитывать и как-то классифицировать как-то соотносить с тем что происходит в реальности в компании и соответственно проводить распределение этой доходной части в соответствии с некими правилами и генерировать после этого правоустанавливающий документ текущей ситуации это сопряжено с экспоненциальным ростом тех объемов данных которые приходят данные становится Не структурированными потому что применяются различные источники мастер системы Откуда эти данные приходят там свои форматы свои особенности своей контракты по интеграции и взаимодействию свой транспорт соответственно как одно из ключевых требований к системе аналитики это получение из информации не просто данных или каких-то фактов Ну и генерация сведений непосредственно те конструкции те вещи которые отвечают на вопросы Что с этим делать дальше повторюсь потребность головаком анализе более продуктивным нежели стандартными средствами добиваемся одна из может быть не ключевых но очень интересных задач это то что необходимо было реализовать неизменяемую базу данных либо неизменяемое хранилище данных тем самым отойти от конкурентного доступа к каким-то элементам атрибутам либо самим объектом и в целом сама аналитика она тяготела к тому чтобы пользоваться не классическими семантическими моделями а более продуктивными онтологическими в частности скажу что для онтологических моделей Граф является наиболее приемлемой наиболее наверное полной и точной формой описания этой модели вот повторюсь Наш бизнес сценарий Это децентрализованное понятно что распределенное но в целом это децентрализованная система Центральный узел занимался тем что во-первых маршрутизировал все потоки данных Согласно там регионам отделом и подразделением в каждом регионе в каждом подразделении был развернут свой собственный инстанс как базы данных так аналитической аналитической системы и каждый в принципе занимался своим конкретным изолированным пулом задач полом данных и Центральный узел принимал только в форме отчетов статистику какую-то либо уже агрегированное бизнес отчеты соответственно каждый изолирован это по сути одно Узловая схема у каждого подразделения свойственность и он одну Узловой шарнирование нет кластера нет и в принципе как бы потребности в этом не было но было бы неплохо Если бы это было все распределенное но централизованной системой дефакт ситуация такова что режим обработки или получения погружения данных в систему Он носит характер пакетный не потоковый план аналитики он разделен на несколько этапов он последовательный по своей структуре и условно этот процесс настолько тяжелый для обработки что каждый инсус в час может обработать порядка 100 тысяч документов под документом здесь подразумевается файлы файлы формате xml и каждый документ он содержит данные или сведения о различных числе денежных поступлений эти денежные поступления входящие определяются как доходная часть и соответственно вся остальная аналитическая работа ведется по обработке вот этих вот первичных данных совокупно вся система во всех отдельных изолированных способно обработать не более 6 миллионов в день причем Это условный такой показатель Почему Потому что опять же проговорю о том что весь весь процесс разделен на две части и вот 6 миллионов документов в день Это получение парсинг обработка первичный фармакологический контроль и сохранение в учетной системе А вот непосредственно сам анализ то есть обогащение сравнение со справочниками с внешними системами и непосредственно распределение и последующие генерации документов это вторая часть Она настолько нагружалась система что это откладывалось на другой день то есть мы за сегодня получаем сведения анализируем и распределяем эту доходную часть завтра это привозило к тому что фактически в компании в целом в организации не было представления о том что же происходит с точки зрения финансовых потоков Вот Но это большие риски К тому же была была такая потребность была такая можно сказать задача что вот эти вот правила распределения финансовых потоков они не совсем формализованы до конца и это такая больше задача на исследование а соответственно необходимо что-то какая-то песочница на которой можно было бы проверять или выносить какие-то новые гипотезы по тому каким образом лучше или оптимизирование распределять эти средства соответственно их анализировать также необходимо было реализовать две концепции которые с точки зрения бизнеса были крайне важны Первое это так называемый прослеживаемость это когда грубо говоря у нас есть финальный какой-то результат какое-то состояние финансового потока и нам необходимо определить какие объекты события документы или что-то не было повлияли Непосредственно как напрямую так и косвенно на формирование вот такого состояния или такого объекта причем все что лежит между ними не всегда понятно мы не знаем иногда мы не знаем структуру мы не знаем кто В какой мере зависит И как часто это происходит прямого воздействия нет а вот именно косвенное воздействие оно является самым таким значимым и это в том числе перекликается с концепцией поведенческих паттернов сама по себе концепция очень тесно перекликается с механизмами антифрода когда грубо говоря У нас есть некий субъектов которые непосредственно влияют на состояние либо на какой-то факт но непонятно кто еще скрывается за кулисами кто может косвенно Но это косвенное воздействие может быть критичным соответственно исходя из этих целей исходя из этих потребностей мы сформировали некие цели сами для себя Ну и они обязательно перекликались с требованиями от конечного заказчика во-первых необходимо было подтвердить возможность применения онтологических моделей как для построения централизованных систем необходимо было подтвердить возможность обработки 12 миллионов документов в день причем под обработкой в этом случае мы подразумевали что будет не только получение документов обработка их смысле сохранение учетной системе но и также классификация полная и финальное распределение доходной части и генерации исходящих документов а под вот этой вот метрикой в день подразумевалось 8 часов операционный день также необходимо было подтвердить гипотезу что возможно построение неизменяемого хранилища для чего это необходимо было сделать необходимо было подтвердить то что система способна предоставить такую массивную таком массивный био-слой при котором нет потребностей отчуждать старые данные исторические В отдельной какой-то архив чтобы не было потом необходимости сверять операционные данные с архивом Для этого необходимо было реализовать подтвердить такую гипотезу что при росте объемов в системе объемов данных системе не наблюдается деградации производительности или хотя бы она держится в каких-то приемлемых рамках также необходимо было подтвердить гипотезу что система способная предоставить инструмент песочницы экспериментального полигона те самые бизнес задачи в реализации гипотезы прослеживаемости политических паттернов Ну и никто не отменял импортозамещение хотя бы в каком-то виде возможно может быть даже частично а после реализации реализовали мы этот Прототип на протяжении примерно полугода последние там два-три месяца мы занимались тем что мы проводили нагрузочное тестирование натурные тестирование и проводилось серия защиты нашей концепции нашего прототипа результатами можно по большому счету может не гордиться на косяк хвастаться а похвастаться есть чем для чистоты эксперимента мы произвели те же самые конфигурации То есть фактически наша система она была построена по 1 Узловой схеме кластер мы не строили но Мы надеемся на то что кластер не порушит нашу наши результаты по производительности а лишь предоставит больше гибкости в плане шарнирования масштабирования и соответственно больше погруженности в под нагрузкой Это имеется в виду что В текущей системе как есть нагрузки фактически Не осуществлялась потому что вот та самая нагрузка А в виде обработки классификации сравнения и обогащения сведений из различных сторонних справочников сторонних систем фактическое финальное распределение генерации документов она производилась в следующий день у нас это считалось нагрузкой и мы это производили в этот же день и соответственно 12 миллионов документов в час имеется ввиду полный весь цикл без отложенных операций продолжительность непрерывного тестирования под нагрузкой производилась на протяжении порядка 168 часов при этом финально у нас в учетной системе соответственно Bi оперировал более чем двумя миллионами документов объектов при этом мы подтвердили отсутствие деградации производительности при росте объемов фактически в некий момент у нас график ложился в полку А вот дребезг который мы наблюдали он укладывался в обычные погрешности это нам позволило уверенно уверенно защитить реализацию гипотезы о том что мы можем производить систему без отчуждения архива потому что финальными целевыми требованиями было хранение в системе одного миллиарда объектов на протяжении целого месяца по итогу у нас в системе располагалась объектов порядка 5 миллиардов там и прочего дополнительных атрибутов у нас объем где-то приближался к 50 миллиардам при этом показатель производительности 12 миллионов документов новых также сохранялся на протяжении одного часа косвенно это привело к тому что в результате нашего эксперимента мы отталкиваемся от того что у нас была большая потребность для работы с бесхином режиме этот бесхьемный режим Он конечно такая штука достаточно условная Почему Потому что для слоя oltp схемность все-таки применяется и даже в базах данных Где используются чистый Граф и так называемый бессемный режим схемы применяется минимальный объем ограничивается типизацией для объектов Вот Ну а соответственно часть которая биана там где производятся все поисковые запросы там где работают высокопроизводительные графовые алгоритмы она может и спокойно работать без схемном режиме это необходимо в частности для для реализации концепции прослеживаемости там где схема не то чтобы не нужна она кое-где даже мешает с одной стороны но и поведенческие паттерны в том числе косвенно мы пришли к тому что нам при использовании графовых баз данных у нас отсутствует необходимость в использовании и построении использования слоя orem Дело в том что графовые базы не все конечно но большинство из них они хранят и оперируют объектами в памяти соответственно объекты в смысле все сущности будь то вершины либо ребра это объекты и они уже хранятся в виде объектов и переводить данные из революционной модели к примеру в объектную как это делается между классической схеме Когда у нас есть свое хранение есть свой бизнес логики где-то на севере приложений у нас этой потребности нет потому что у нас данные что в системе хранения что бизнес логике они хранятся в объектной форме и преобразовывать их нет смысла ну после того как мы начали для слоя применять высокопроизводительные графы алгоритмы соответственно подтвердили возможность реализации прослеживаемости работать с поведенческими паттернами тем самым мы получили доступ глубокой семантической семантическому анализу в частности у нас был микро микротест он связан с тем что мы мы попробовали и это подтвердилось Мы работали с графом в котором все объекты Живут без без атрибутов Ну то есть совсем вот и получается что при этом семантика присутствует можно проводить анализ можно получать из такой структуры без атрибутивного состава можно получать довольно-таки серьезные аналитические результаты И тем самым подтверждается наличие глубокой семантики почему же нам наша гипотеза дала такие возможности Да необходимо провести некое сравнение конечно оно будет достаточно утрированно потому что у нас специфический кейс и не везде это подойдет Но несмотря на это мы посмотрим в чем же различие между моделями данных производительностью основные преимущества в нашем кейсе которые использовались Те недостатки которые мы для себя выявили при сравнении классических реляционных моделей и онтологических моделей в первую очередь как бы это странно не звучало но в реляционной модели реляции то есть связи как таковых Нет ну то есть они существуют но они не материализованы они существуют только в рамках сессии в рамках в границах запроса и по этой причине на самом деле в реляционной модели используется модель для моделей связанности используется ассоциативная модель Нам необходимо для того чтобы связать две сущности из двух разных хранилищ двух разных таблиц Нам необходимо произвести ассоциацию то есть сравнить соответствие или равенства значения из одной там из одного атрибута одной сущности со значением атрибута другой сущности это в частности приводит к тому что у нас избыточность появляется ненужная нам в революционной модели и появляется такой механизм как нормализация данных графовой же базе Как таковой в большинстве графовых баз модель объектная соответственно все вершины и связи является ребрами в графе соответственно и все вершины и все ребра это объекты Они отдельно могут параметризироваться они имеют свой уникальный атрибутивный состав поэтому Можно также работать по нему можно фильтроватся можно как-то связываться но этот механизм связывания что ли по атрибутам он не типичен для онтологических моделей и графов в целом и как правило это приводит к тому что необходимо будет сначала пропустить граф неподготовленный Граф через соответствующий алгоритмы которые фактически проведут вот этот анализ и по соответствия нужным нам атрибутам произведут формирование дополнительных новых связей не во всех но повторюсь в большинстве графовых баз данных особенно в тех которых используется чистый Граф там применяется без схемный режим соответственно данные могут эволюционировать это как раз таки отсылка к тому что можно сделать легко достаточно можно сделать ему табельное хранилище нам фактически сам Граф он не эволюционирует нам у нас отсутствует потребность в операциях удаление либо обновления самих вершин или ребер и все апдейты они сводятся к обновлению состояния атрибутов а соответственно мы можем просто добавлять делать ставку новых версий этих атрибутов И кстати в большинстве графов графовых допустим такой как Ford фактически мы ее в результате Долгих выборов метаний мы выбрали неоформ G для как основу базы данных для нашего прототипа так вот в этой базе данных есть ключевых таких Три больших хранилища отдельное хранилище для вершин отдельное хранилище для ребер и отдельное хранилище для всех атрибутов будь то атрибуты вершин либо атрибуты рёбер отдельно Конечно можно говорить про реализацию базы данных на Ford G но как бы то ни было там есть один хороший архитектурный паттерн который не очень хорошо реализован но задел как бы есть фактически вместо того чтобы делать реляционной модели таблицу для всех объектов графовой базе формируются некие кластера это те же самые хранилища Вот они также протекционируются могут переезжать там с узла на узел это достаточно легко если у нас запрос не шортируется то есть не распределяется по узлам пошардам Вот и в этом случае достаточно простые алгоритмы или простые поисковые запросы они хорошо отрабатывают до той поры как только у нас не появляется потребность переходить в запросе шардами еще одной такой особенности Почему мы отказались Ну не то чтобы отказались у нас просто не было потребности в рэме это потому что результатом в результатам запроса к реляционной модели всегда является плоская таблица более того если мы Обращаемся Ну то есть у нас результат запроса это некие агрегат либо композиции то у нас таблица становится разряженной у нас А это соответственно приводит к тому что результирующий набор из модели данных он фактически сырой у нас появляется потребность в дополнительный постобработке для того чтобы подготовить к финальной бизнес логике Нам необходимо этот результирующий набор как-то обработать как-то разложить на какие-то коллекции ну и соответственно перевести в объектную модель результатом же запроса к объектной графовой базе данных у нас всегда есть набор коллекций там уже объекты и соответственно у нас разряженных коллекций не существует у нас все лаконично и все просто в в этой в ассоциативной модели Ну соответственно и в реляционной самое главное операции для связывания является Джон она не секрет И на предыдущих докладах это было хорошо показано это очень дорогая операция Особенно для распределенных баз данных а мы к этому в принципе все стремимся вот так вот в объектной графовой базе Ну там где используется чистый Граф антологическая модель там операция Join не используется она конечно же есть вот допустим на примере на Ford G который мы которым эксплуатировали у нее язык запросов основной это специфический язык но тем не менее там операция Джейн есть но мало кто из разработчиков вообще знает о ней а ее существовании Почему Потому что модель связанности здесь такова что между ребром и вершиной осуществляется связь один к одному и она строится на линках либо на указателях на поинтах А это соответственно прямой указатель прямой адрес Нам необходимо нет необходимости пробегать там какие-то структуры для того чтобы сравнить поискать и получить Утверждение что Да действительно этот объект есть соответствующий То есть другими словами если у нас есть какое-то ребро у нас всегда в нем будет Начальная точка и конечная это всегда будет как минимум один объект но в случае если это ребро соответственно для этого у нас появляются появляются возможность применять более высокопроизводительные алгоритмы попозже поговорим вот и по поводу распределенных вещей коллеги готовят Ну как это в планах конечно но мы очень сильно надеемся что они Скоро нам сделают свою собственную графовую базу данных и архитектурно там шарнирование но устроена проще Почему Потому что в реляционной модели данных факта шарнирования это по сути контекст а соответственно он должен быть вынесен на прикладной уровень потому что ядро базы данных толком не знает ни о чем что там Какие данные то есть семантика для неё такая достаточно размытая и сформировать автоматическом режиме фактор соответственно распределять эти данные достаточно сложно самый простой пример это Просто берут и таблицы партиционирует как-то их размазывать так как графовой базе логической модели ее структура есть суть отображения семантики то фактор шардирования он напрашивается сам на себя это у нас фактически тот кластер который отвечает за тип вершины либо тип ребра отдельной строкой надо как бы поговорить о том насколько легко И это для нас стало таким ключевым моментом в качестве производительности это каким способом обходятся иерархические структуры с большой глубиной в реляционных моделях и как это делается в графе у нас был соответствующий тоже микромиокр мы проводили Ну понятно что это такая семантика Да ну синтетика какой-то вырожденный пример но тем не менее мы взяли из предметной области заказчика взяли конкретный пример сформировали структуру и попытались ее реализовать и обойти в реляционной базе данных и то же самое произвели в графе у нас пороговым значением глубина была пять для реляционной модели это стало смертью опять же когда у вас там сотни тысяч или миллионы записи объектов это еще куда не шло но когда мы говорим уже о миллиардах или десятках миллиардов у нас традиционная база данных на четырех уровнях начала отдавать запрос результат где-то порядка после нескольких часов 5-6 часов а на уровне 5 она просто съела все ресурсы так как основной метод обхода иерархических структур для реляционной модели это рекурсе то это все непредсказуемо Сколько памяти потребуется и даже более того тут вопрос такой что больше отжирается не столько Память сколько стек переключение контекста при вызове в рекурсии это очень страшно для реляционной модели в графике фактически Мы пришли к тому это Потом на следующих слайда будет на цифрах что ли показано мы пришли к тому что для нас по большому счету глубина вложенности иерархической структуры вообще не имеет значения То есть у нас в среднем глубина ложности была порядка 5-6-7 уровней в Пике она достигала 9 может быть 11 и деградация производительности при таких при обходе таких структур она была несущественной то есть это укладывалось какую-то погрешность соответственно дорогое крут в реляционных моделях и достаточно дешевый крут в объектах графах онтологических моделях что фактически толкает на то что нет необходимости апдейтить нет необходимости удалять в некоторых базах данных графах кстати сохранилась сохранилась возможность удалять там есть такая операция когда тач то есть прежде чем удалить какие-то вершины надо отвязать деталь приводит к тому что мы просто убиваем сначала ребра а потом мы можем уже убить вершины но в этом нет необходимости Почему Потому что деталь в первую очередь отцепляет атрибуты а уже потом работает с объектами удалять нам нет смысла Ну по большому счету взять какую-нибудь модель онтологическую любой Граф Ну допустим социальной сети все объекты которые попали в эту сеть в этот Граф они в принципе живут все что с ними происходит на протяжении какого-то времени это меняется состояние меняется состояние их свойств Ну то есть там какой-нибудь социальный статус возраст Но человек как существовал так и существует если у него какое-то отношение или взаимосвязь появилась то в принципе Она и так и остаётся жить приведена цитата она достаточно условная можно сказать холиварная кто-то с ней согласен кто-то нет но считается что в Neo for G при одном Узловой архитектуре предостаточном объеме данных достаточно объеме ресурсов имеется ввиду оперативной памяти она способна держать достаточно большой объем объектов это порядка там 278 степени объектов вот под объектами опять же подразумевается только ребра вершины и в эту метрику не входят атрибуты потому что сами атрибуты сами по себе они могут тоже представляться везде документов они могут представляться в виде неких тоже иерархических структур вложенных массивов и тому подобное отличительной чертой следующей является использование классическом виде есть Конечно есть различные версии для классического SQL для реляционных баз данных во многих во многих графах объектных базах данных применяются в том числе похожие Сколь язык но применяется также тинкер-поп Гремлин и его цафер цайфер специфический язык Дело в том что вообще инструменты такие как графовые базы данных это достаточно молодая такая тема и там стандартов Маловато поэтому каждый пишет Во что горазд сам по себе язык является декларативным А из сколь в сравнении допустим с афером он все-таки представляет императивным Почему Потому что мы этим языком описываем Что ядру необходимо сделать хранилищем для того чтобы выдать нам данные в том виде в котором мы хотим декларативном языке мы описываем некий путь который что-то может попасть Каким образом будет ядро обходить этот путь и собирать нам нужны данные остается за скобками соответственно в реляционных моделях данных никуда не деться от постобработки на клиенте в графовых базах данных практически всю большинство скажем так несложной или какое-то среднее средне сложной аналитики можно производить прямо на сервере то есть на самой базе данных по перформансу это конечно чем ближе чем ближе процесс к самим данным тем лучше соответственно вот Исходя из этого и практически мы это подтвердили у нас практически константная стоимость чтения при росте там при изменении роста объема данных по отношению к операции чтения в реляционной модели Ну и вот говоря о языке и о иерархических структурах этот такой вырожденный пример когда у нас есть некий продукт к нему цепляется иерархические структура с категориями продуктов тут дело в том что каждый новый Join он добавляет сложности коллеги на предыдущих докладах это ярко показали Можно конечно применять некие оптимизации но так или иначе это достаточно сложная штука сложность еще добавляется в том что не зная вот этих уровней вложенности то есть Каким образом построена этой иерархия иерархической структура получить такой результат Вообще практически невозможно более того если у нас иерархическая структура с непонятной влажностью количество ложности нам непонятно сколько у нас уровней то есть сам запрос написать достаточно проблематично динамически писать запросы генерации это просадка по производительность тот же самый запрос та же самая структура как она выглядит в языке цайфер То есть фактически матчем мы получаем некие данные То есть у нас есть вершины стартовые вершины этот продукт финальная вершина это категория все что между ними лежит относится к отношению родителя и наследника причем вот эта вот конструкция в Нижней строке где у нас связь звездочка и далее Она фактически определяет у нас степень вложенности в данном виде это неопределенная форма то есть нам нам неизвестно какая степень влажности в конкретном случае у нас она особо не волнует И тем самым мы можем пройти любую глубину более того здесь вот такой момент последние вершине у нас используется специальный аппарат со стрелкой тем самым мы определяем направление Дело в том что графы могут быть как направленными так не направленными нагруженными средневзвешенными допустим полными или разряженными и в том числе цикличными и вот когда мы говорили о том что революционных моделях можно каким-то образом хранить и обрабатывать графы это на самом деле такое немножко лукавство Почему Потому что хоть в каком-то виде реляционных моделях можно уложить только вырожденный случай графа это так называемый так ненаправленный цикличный Граф по сути это дерево всё что выходит за рамки описания дерева все остальные случаи более сложные графа в результате очень сложно живут и работать с ними неприятно как минимум вот тот самый результат сравнения обхода иерархических структур мы фактически повторили официальный бенчмарк он был реализован без относительно конкретной реляционной базе данных это просто какая-то классическая или часто встречаемая Вот и мы получаем вот те самые результаты что на уровне вложенности 4 при классической схеме организации иерархических структур рельсовка выдает просто невменяемый какой-то результат на уровне 5 она у нас просто умерла падение производительности у графовой базы она конечно тоже существенно в два раза даже больше Вот Но это не существенно вот в объемах больших объемах и на каких-то интервалах времени Это непосредственно вот это вот вся картинка она вызвана тем что я наверное повторюсь но в реляционных моделях данных основной как бы упор заключается в том что реляционная модель данных она хранит сущности Ну то есть объекты в виде сущностей И на самом деле она не хранит сущность она хранит только атрибутивный состав сущности Вот и представить себе реляционную модель в которой лежат объекты без атрибутивов достаточно сложная вещь непонятная чем с этим делать в онтологических моделях аграфа являются формой описания онтологических моделей так вот онтологических моделях основной как бы упор на что она смотрит с чем она работает Это связи соответственно чем больше связи у нас в модели данных тем больше сведений Мы из этих фактов из этих данных можем получить Ну и области применения это все конечно хорошо у нас было два доклада Спасибо кстати достаточно интересные доклады Вот и благодаря кстати коллегам которые реализуют уже конкретные инструменты с которыми можно работать это ну как бы это форма это методология графы и все такое это стало хотя бы доступно хоть как-то с этим можно работать потому что там 30 лет назад была только Ну как бы методика была какая-то теоретическая база была Может быть даже математическая основа к этому но в природе этого не существовало только там в каких-то отдельных случаях Вот соответственно мы Я сейчас вам расскажу про где уже применяется как графовые базы данных так и алгоритмы графовые И соответственно где можно их применить где потенциально их поле интерес а этот список не конечный но просто он слишком большой мы его долго резали раза 4 финансовом секторе и мы в принципе на некоторых конференциях финтеха мы предоставляли результаты как бы занимаемся сейчас пропагандистической деятельностью если так можно выразиться основное Ну вот то с чем мы сталкивались Это непосредственно распределение финансовых потоков то есть наш прототип он фактически стал прототипом Bi системы bi-платформы которыми в принципе развитием которые мы занимаемся вот и это прямо вот Must have для онтологических моделей косвенно такие инструменты способные фиксировать все всю историю событий каких-то операций все что происходило и давать давать более такую глубокую что ли аналитику по причине того что только в онтологической модели наблюдается такой эффект Когда мы можем хранить работать и хотя бы наблюдать не очевидные связи то есть грубо говоря вот тот самый схемный режим Он с одной стороны дает плюсы в Как в графах Так в реляционках Но с другой стороны он является неким ограничением То есть если мы не описали структуру мы не знаем как у нас объекты в базе данных связаны то нам сложно определить связи которых мы которые для нас является не очевидными которые мы не наблюдаем и вот сам Процесс поиска этих связей достаточно тривиален прогнозирование остатка движения денежных средств управления рисками Это то же самое что вот прямо основная задача для антологий выявление операций лиц и организаций это вот пику антифрода в частности У нас есть уже контакты и проводятся работа с отечественными компаниями которые занимаются в частности проблема у них в том что они занимаются антифродом Анализируя атомар на каждую транзакцию и это в принципе покрывает большой пул задач аналитических Но когда у нас возникает неочевидные связи Когда у нас появляются косвенные воздействия здесь анализ атомарных транзакций ни к чему толком не приводят потому что атомарная транзакция сама по себе может не попадать под критерии антифрода и соответственно она не бракуется но в совокупности это дает более широкие результаты ну в телекоме это как минимум ради частот и в сетях с помощью антологий и графов решаются проблемы минимизации задержек точно не уверен Но по слухам МТС как минимум пользуется графами для решения своих задач для производства сетевых процессоров уже встраивает графы и онтологические модели внутри прямо процессора Для более более оптимального распределения по входящей очереди пакетов и соответственно исходящий опять же в телекоме решение вопросов STP протокола решается через графы и так называемый динамический лацп тоже хорошо решается с помощью алгоритмов графов алгоритмов логистика и транспорт здесь как бы все и так понятно поиск кратчайшего пути дешевого пути задача Яндекс у нас занимается логистическими проблемами графы это то что они используют распределение ресурсов оптимизации перевозок и вот составление расписания в том числе полетных у нас в том числе сейчас проводится исследование мы готовим систему систему на которой на самом деле занимается тем что строит расписание в частности Это задача достаточно сложная Но она очень востребована в аэропортах там необходимо принимать борта отправлять борта Но самое главное То что происходит между ними борта надо куда-то распределять и пока они стоят и ждут вылета для них должны быть выполнены некие операции эти операции требуют ресурсов в том числе человеческих и это очень сложно запланировать особенно когда производятся какие-то корректировки вносятся по ходу дела Вот для решения подобной задачи есть группа уровнях графов алгоритмов называемый раскраска графов сама по себе задача сложная Вот И там нет никаких гарантий и фактически Она приводит к тому что мы сначала распределяем делаем варианты потом делаем смешивание и по итогу мы должны провести еще операцию выбора наиболее подходящего итогового расписания которые нам которые нас удовлетворяют хоть в каком-то виде маркетинг-аналитика индексация страниц поиск в рекомендательных сетях в рекомендательных системах поиск в различных социальных графах и тому подобное похожести общие там кластера или эгрегоры все это считается легко на структурах графовых и с помощью алгоритмов логических котировки туда это опять же классический топ наверное графовых алгоритмов часть из них является примитивными часть высокоуровневыми вот в частности поиск в ширину в глубину это примитивный алгоритмы которые так или иначе используются в алгоритмах определения кратчайшего дешевого пути в задаче прохождения всего графа задача Так называемая вот в телекоме то есть в сетях используется алгоритм обнаружения циклов это в протоколе STP более того сейчас во многих компаниях сетевых в телекоме в том числе и в отечественных производится работы по по разработке наверное сам так называемых самоорганизующихся и самоуправляемых сетях сетей и без вот алгоритмов обнаружения циклов там мало что можно сделать минимальное основное дерево оно также эксплуатируется в паре с алгоритмами обнаружения циклов и сильно связанных компонентов и топологическая сортировка она применяется в том числе в антифрозе она применяется для вместе с алгоритмом определения максимального потока Это для правильного распределения ресурсов для распределения финансовых потоков и в системах управления рисками отдельно стоит алгоритм пара сочетания мы его непосредственно можно пытались сказать Так что пытались использовать это на самом деле группа алгоритмов некоторые нам подошли хотелось бы рассказать отдельно про эту часть Дело в том что вот когда происходит финальное распределение денежных потоков Когда мы уже там консолидировали классифицировали мы понимаем Куда эти деньги потом совокупно куда-то денутся куда нам надо их разместить у нас компания большая организация большая соответственно у него большой план счетов счетов много этих банков много у каждого счета достаточно сложные массив счетов тоже большой более того есть еще внутренние скажем так казначейство есть внутренние счета и это тот же пул счетов нужно также учитывать и для того чтобы распределять финансы финансы до даже в консолидированном виде Нам необходимо каждый раз ну как бы это происходило в реляционной модели нам каждый раз приходилось бы пока некоторым по некоторым факторам по некоторым атрибутам делать выборку из плана счетов как-то группировать и перераспределять только после этого финансовые потоки финансовые финансовые объемы вот и это операция достаточно сложная потому что она производится большим массивом счетов Вот и так как это все-таки это очень дорогая операция как поступили Мы у нас план счетов такой же большой но мы зафиксировали этот план счетов соответственно прогнали его через алгоритм пара сочетание и получили для некой группы атрибутов То есть фактически эти группы атрибутов определяют для нас финальное распределение и привязали к нему соответствующие то этот алгоритм генерирует специфические связи и нам чтобы распределить консолидированные финансовые консолидированной суммы финансов нет нужды пробегать каждый раз план счетов у нас уже есть прямая связь отсутствие Join и всё тому подобное Давайте да кем используется да И кем потенциально это все может быть использовано в Штатах есть компания палантир многие они знают мальтега Это ее младший брат условно бесплатная банки различные в том числе ФРС гиганты наукоемки типа как НАСА Ну и различные производственные компании типа Airbus Volvo в том числе работает все все у них проводятся на онтологических моделях у нас на родине тут мало сведений каждый пытается как-то это реализоваться по-своему вот давайте агрегироваться давайте как-то кооперироваться так будет мне кажется лучше хорошо и быстрее но во всяком случае сейчас графы используются в том или ином виде онтологические модели графы используют Яндекс используют Росатом ран и использует целиком МТС Я в курсе точно есть такая компания метод у нас Отечественная антологические модели это их вообще конек потому что они производят так называемые изобретай изобретающие программы это вот есть каткам системы у них аналогов нет но это вот их самое главное понятно что мы команда не не продуктовая процессинговые и мы в этих продуктах нуждаемся Вот но у нас есть некий свой роддом потому что выбрать перебрали конечно инструмент достаточно много выбрать по итогу не так уж много из чего есть в доступе У нас есть некий свой род как мы будем это дело развивать свою платформу и соответственно вот этот он соответствует наиболее худшему исходу что если у нас ничего не получится вот по сути наверное все Большое спасибо за внимание Денис Спасибо большое закрывать конференцию очень непросто когда у всех уже пухнут головы от знаний супер приз за выступление с конференцией сувениры с собой а мы Сейчас переходим к церемонии закрытия друзья если Денису остались вопросы подойдите к нему в кулуарах это произойдет через несколько минут Проходите пожалуйста Потому что закрытие это шоу поблагодарить спикера еще раз аплодисментами великолепно все кто хотел войти в зал заходите Присаживайтесь это Это ненадолго но это кайфово не задавайте спорных вопросов пока еще включен микрофон что происходит сейчас мы с вами смотрим умопомрачительные видеоролик на одну минуту и потом на эту На этой сцене как и в начале душа хайлоуда внимание на экран и как говорит Хрюша Давайте смотреть Питер Питер мы это прекрасно Мы чемпионы с вами Давайте еще раз поаплодируем всем организаторам всем партнерам всем спикерам всем кто задавал вопросы всем кто нашел куда вопрос писать не надо Олег Буня со своим докладом на полтора часа Встречайте Так ребят Я мама бесконечно благодарны Спасибо вам большое нас очень много Это самый большой хайлоут в Питере который когда-либо не был ну то есть это прям рекорд рекорд в двух словах о том как это было Итак Спасибо всем тем кто работал над нашей конференцией над нашей совместной конференции это фантастические люди это это очень крутые ребята зачем они работают в ПК каждую неделю созваниваются на несколько часов потом с каждым докладчиком Я вообще не понимаю наверное просто от любви к искусству огромное вам спасибо друзья Просто Без вас бы ничего бы не было вы именно тот фильтр который делает конференцию конференции И кстати в этот раз Действительно получилось очень-очень-очень хорошая программа то есть прям топ во всем и в количестве людей и в программе тоже дальше несколько цифр несколько цифр нас 1910 человек на самом деле это нас 492 онлайн участника нас 510 тысяч полмиллиона онлайн просмотров И это тоже не шутка и это правда главного зала Понятное дело что главный запускаем в открытость самое интересное без проблем смотрите дальше и все все Да на 1510 слышите на 1510 квадратных метров больше Мы реально захватили всю площадку отвоевали вы бы знали как Мы сражались за парковки просто это же парковки Да здесь должны стоять машинки А теперь стоят Наши шатре в следующем году если мы останемся здесь мы присмотрели бункер друзья под нами бункер Я не шучу я подумал что это кстати наверное злая шутка на самом деле про бункер Я надеюсь что нам понадобится только мы его сделаем красиво неончики и так далее там будет какой-нибудь неоновый зал или что-нибудь такое реально огромный бункер подземный Вот я думаю что если мы остаемся здесь в следующем году мы пойдем Не только на улицу но еще и под улиц будет очень симпатично Так ну что немножко про то что будет дальше А дальше будет сейчас 5 минут я вам даю пока вы пройдете ладно я шучу на самом деле потому что за 5 минут и не пройдешь он большой но тем не менее пожалуйста Пройдите Мы каждый раз его читаем я Не устаю повторять мы читаем каждый пункт каждый каждое предложение про жару можно не писать давайте так то что было жарко нищетово потому что это как бы ну понятно мы мы знаем что мы не справились с охлаждением мы сделали все возможное вы бы знали сколько здесь реально кондиционеров сколько здесь вентиляторов и всего прочего тем не менее не хватило будем думать что делать с этим аквариумом в следующий раз покрасим окна в чёрный цвет Ну что-нибудь придумаем короче опрос проходите мы раздаем проходки если там будут какие-то Гениальные идеи мы можем раздать вечный проходки если у нас такие случаи да то есть как бы мы реально очень благодарны вместе с вами делаем эту конференцию Это не наш продукт мы себя называем как оператор сообщества то есть мы как бы вас слушаем и делаем то что вы хотите получается очень классно фотографии готовы они еще догружаются но тем не менее самые лучшие фотографы Мы с ними уже лет по-моему 10-15 смотрите скачивайте ищите себя это клёвая интересно видеозаписи будут у всех Это стандартный вопрос видеозаписи будут у всех все участники конференции получат видеозаписи бесплатно в своих личных кабинетах все разошлем и так далее helload Москва Вы знаете что нас действительно Юбилейный хайлоут мы тут задумались посчитали вот если все хайлоды просчитать следующий halogs Сколково или в Сколково потому что что-то как бы реально у нас очень много желающих попасть мы планировали реально в два раза меньше человек мы планировали тысячу пришло 1900 это очень приятно Но это создает некоторые логистические проблемы Как вы понимаете вот я рассказывал шатров не было изначально мы ничего не планировали там делать но пришлось площадка пошла на встречу Спасибо большое шатры уже не построишь сколько правда есть крыша можно будет с этим на эту тему поговорить и подняться наверх очень симпатично это будет 20 будет очень большим он будет огромным там будет по-моему 12 потоков Я понимаю что это выбирать Я понимаю что вы опять Напишите на в отзывах о том что ну как можно выбрать из 12 потоков но тем не менее мы планируем на данный момент 192 слота доклада будет 192 на любой вкус и один из слотов подавайте доклады еще есть время и закрытие программы реально через ну как бы через полтора месяца и еще одна конференция которая пройдет на той же самой площадке прямо вместе с хайлоудом в рамках хайлоада это конференция голанг туда тоже можно подавать доклады Давай расскажи бессменный програмный директор раз два три действительно у нас будет Наконец он будет в рамках хайло Да он будет в конце ноября мы действительно принимаем доклады до того же 14 августа мы обещаем вам хардкорную программу Вот и так-то хайлоут будет довольно жесткий А у нас будет еще вот еще ладно вот это вот все А если у вас есть доклад подавайте его потому что как мы понимаем это передний край сегодня Спасибо"
}