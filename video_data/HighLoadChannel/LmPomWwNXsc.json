{
  "video_id": "LmPomWwNXsc",
  "channel": "HighLoadChannel",
  "title": "Избавляемся от кэш-промахов в коде для x86-64 / Евгений Буевич (RU-CENTER)",
  "views": 1353,
  "duration": 1879,
  "published": "2023-01-19T07:01:39-08:00",
  "text": "добрый день меня зовут евгений буевич я работаю в компании ru-center нашей компании как наверное у любого другого доменного регистратора широко используются данные вида имя домена который и является ключом некоторые структуры как значение вот на слайде это видно для быстрой обработки больших объемов таких данных у нас есть библиотека с открытым кодом который работает с хэш-таблицы там есть ряд дополнительных возможностей эту б.д. но основное ее назначение это скорость то есть там миллион несколько миллионов там до 10 миллионов операций в секунду обычно у нас набор данных содержит вот одного миллиона до миллиарда записей в l3 cache конечно же не помещается доступ выполняется случайном порядке основным направлением оптимизации этого кода является оптимизации работы с памятью так как именно она является основной причиной задержек в ходе работы я сталкивался с различными вопросами некоторые удалось нагуглить ответы некоторые пришлось ставить эксперименты а некоторые вопросы так и остались неразрешенными вот про часть экспериментов я и хочу сегодня рассказать начнем самого простенького с какой скоростью данные будут читаться искавший различных уровней на различных архитектурных вкратце про и графикой шей в современных процессорах у нас в основном используется две архитектуры это более старая хеслов псилоны и более современные склеила был xeon и на этом слайде профессор серверных да и десктопных тоже процессора сейчас трехуровневая система каширования небольшой очень быстро или один кэш отдельно для данных и кода по 32 килобайта который обслуживает конкретное драться или пару логических ядер для кипр трейдинга одновременно многопоточности быстрый кэш l2 также привязаны к конкретному индру и общие для всех ядер кашель 3 или целом называется как последнего уровня самая медленная по скорости доступа и тарам вот тайминги обращения к данных найти сайт на этом слайде взятые в интернете по моему сын тульского сайта вот на слайде топологии кашель для офиса возьмем самый простой код который движется по связанному списку определенного размера и для получения нужных нам таймингов на конкретной машине перемешав этот список чтобы избежать hardware фитинга можно смоделировать доступ к памяти в нужном нам случайном порядке изменяя число элемента в списке мы можем добиться того чтобы этот список либо помещался в нужное нам кэш либо не помещался вот про низы инициализация там списка довольно сложный плод я не будут не стал выносить его на слайд скажи только что на каждый элемент есть ровно одна ссылка каждый элемент расположен свои колени и элементы равномерно перемешаны в память вот получится всем нам знакомый с график то есть высота и ширина этих палочек она определяет собственно время доступа и размер соответствующего каша как видно на графике примерно получились те цифры которые были на предыдущих слайдах то есть наш наша методология в принципе работает никаких ненужных оптимизации мы не получаем данном случае теперь поговорим про stale обл кэш l3 на нем имеет общий размер для всех этих на нашем именно xeon gold 10 17 22 мегабайта согласно документации кэш l3 на этих процессоров эксклюзивный то есть данная l2 которая есть дан в кошель данный который с кашель 2 в нем отсутствует он только знает о том что они есть куча l2 вот не звучит это немножко загадочное мы будем в этом разбираться если наслать посмотрите вы видите что для каждого каша там отдельный datasette и они как бы не обязательно пересекаются что у нас получилось да скрыла был тот же самый эксперимент видно что полочки эти у нас удлинились и сместились то есть размер кэша и эффективно гораздо больше там логарифмическая шкала шкала внизу там показанных размер для меня стал несколько неожиданным то что мы читаем в одно ядро в общем то но при этом процессор использует полный размер l3 кэша ситуация 2 мегабайта я ожидал что это будет не так но в этом он похож на haswell и ничем от него не отличается убедившись что результаты для будет процессоров соответствует заявленным характеристикам приведем более интересный эксперимент с несколькими играми загрузим данные во льду одного ядра и прочитаем и и другими лидерами будем использовать половину ультой размеры для каждого процессора для х 128 килобайт ничего неожиданного мы тут и не получаем первое обращение грузи данные из памяти повторное обращение того же ядра груди данные из 2 обращение 2 ядра грузит данные из altri общего ну и повторно опять же из 2 то есть все ровно так как можно было бы предположить для сказала был все гораздо интереснее повторим этот эксперимент и добавим еще 3 2 но нам тут понадобится видно что 2 ядра при первом обращении к данным получает за девушку очень большую похожие практически на доступ в крам по таймингу ему наличие данных валь 2 1 игра практически не помогает повторное выполняется с какой то странной средней скорости между или два или три не в 3 утра первое обращение уже похоже на честно в 3 скорости а повторный выполняется с той же странной скорости при повторном чтении вторым бедром ничего не изменять не меняется по сравнению с последней с предыдущим чтением и при повторном чтении первым ведром первое обращение опять же несколько замедленное а второе обращение не максимально быстро на этом графике все это выглядит очень загадочно и из скорости мы видим извлекли все что можно будем использовать перф профайлер посмотрим какие счетчики будут увеличиваться на каждом шаге в этом эксперименте на слайде на карте над каждым столбиком показан как промах такого уровня мы получаем на этом шаге мы рассмотрим что происходит по шагам на первом сроки понятно дело что мы получаем пророк последнего уровня данные поднимаются из памяти и попадают они судя по второму шагу в кэш l2 нашего ядра тут видно что они попали именно 02 вот здесь на этом все совпадения с esl заканчивается и дальше начинается самое веселое при чтении вторым бедром мы получаем l2 при дамах но при этом его тайминг ужасен если немножко забежать вперед то по повторному обращению к этим данным видно что он при этом обращении данные переместились в ультре этого ядра ну и так же надо сказать что здесь мы получили несколько промахов tlb и это тоже внесло свой вклад задержку и повторном чтении видно что данные не доехали до l2 того ядра которые читают и остались в альтере не посмотрим третье ядро промах стало значительно меньше он опять же 2 то есть данные видим они перемещаются в литре уже и соответственно из-за этого это выполняется быстрее трп промахи опять же оказывает влияние на скорость повторное чтение похоже на повторное чтение интро номер 2 и вернувшись к ядрам номер 2 мы уже получаем все та же самую скорость никаких не thb промахов не перемещение данных здесь их виде монету и самое интересное возвращаемся к первому ядру вот именно вот этот слайд доказывает что данные у нас уехали в альтере уровень и сейчас на этом обращении они возвращаются в л2 и следующий показывает то что читаются они из кэша второго уровня получаем честно или один промах теперь попробуем эксперимент записью попробуем в указанный момент времени на слайде модифицировать данные в торе мидером что получится до сих пор складывалось впечатление что данные хранятся только в одном месте систему пиши и протокол когерентности нужен только для юли один крыша но похоже что на этой диаграмме после модификации последующих чтение данные таки будут находиться в разделенном состоянии между 0 2 или 3 1 игра или 2 2 ядра так как мы видим что оба из ядра сумели получить и в своём 2 интересно что во втором гендри они остались в 2 даже после чтения третьем так как аль тарика шок естественно данные там дублироваться не могут то они соответственно прежде ней в литре перемещаться и не будут это выглядит логичным также нужно увеличить что задержки для первого и третьего едят при первом чтении увеличились я подозреваю что это как раз как вызвано протоколом tiger and nasty то есть они из состояния modify перемещают состоянии широко мере до первого чтения какие из всего этого можно сделать выводы первый вывод что скейлы был гораздо более лучше вознаградит вас за локализацию данных потому что время доступа к своим акколь два или три в ядре и значительно лучше чем третьем уровне в другом и в других играх нужно отметить что данные чтением получить если они уже есть другом ядре получите в свой конечно не возможно они остаются в другом бедре и и тайминги доступа к нему величины если говорить о применительно к этому а нашим связанном списке то либо первое его получению системах ушей либо запись желательно выполнял выполнять тем ядром которая будет потом выполнять последовательное чтение даже особенно если эти последователи чтения ожидается много то есть видно там примерно разница по скорости для 1000 чтения должны быть там ошибка на сайте вот что тут можно сказать тут вообще достаточно широкий простор оптимист для оптимизации то есть если мы предполагаем что данные находится в чужом кощея можно каким-то образом их модифицировать чтобы получить их слоем 2 ну и разные подобные приемы придумать но все таки это за точкой под конкретную архитектуру что наверно не очень правильно поэтому я постарался как сказать в общем и 2 практически вывод так бы следствия 1 но здесь скалы был троллинг и слова что прогрев altri из другого игра она сказала бы работать не будет общее так как задержка на поиск и шли не в другом галерея trd промах перемещение из r2 и r3 все это будет сравнима с доступа с доступом к памяти на слои так видно два последовательных 10 два варианта последовательности действий это из нашей библиотеке когда у нас запрос на несколько ключей происходит этот запрос конвейере суются 1 цифра 1 игровой считывает выше а 2 ведра выполняется запрос данным то есть фактически после того как мы получили адрес можно одним ядром либо предзагрузить эти данные файлы query cache либо этого не делать как видно что она хотели это дает определенный видимый глазом profits на scalable такого профита незаметно без микроскопа можно также еще упомянуть я не стал делать для этого слайда это общее место мне кажется что прибегать пренебрегать цвет affinity для thread'ов в принципе нельзя если мы заботимся о производительности потому что помимо рассмотренных эффектов привет может вообще попасть на другой socket процессора на машине и в этом случае задержки обращение к памяти любой оптимизацию уничтожить корню я не стал делать слайд потому что это принципе понятно немного разобравшись с тем насколько быстро мы получаем данные из различных кощей можно подумать что делать в случае если кэш промахи все-таки неизбежен ну как пример это вот этот наш с вами список по которому мы идем и каждый шаг будет давать кэш кромок если размер списка превышает какое-то значение в принципе это общая проблема для связанных списков они считаются cash and friendly структурами данных в intel и вам где тоже конечно же если набор инструкций позволяющие заранее получить данные в качестве выбранного уровня существуют их несколько разновидности они есть на слайде там вкратце про них можно сказать следующее что при фишки 0 она самая универсальная инструкция самая нетребовательная к промежутку между предвыборной используемым данных лишь бы этот промежуток был достаточно для того чтобы данные доехали в нужный кэш 631 и присесть и 2 почему-то во всех имперских архитектурах одинаковые вот это как раз та самая инструкция которое можно получить данные vl3 для использования другим ядром нашей воли кроме того именно ее можно использовать если у нас эти между запросом данным их получением есть интенсивной работы с эль 1 так как мы имя ей или денни засоряем прежде чем ты она берет самого и требовательная промежутка между запросом и данных их использованием он должен быть подобран очень точно так как данные попадают только вы один кэш это инструкция часто используется не для приду выборки а для нам тем караулит потому что это в принципе единственный способ для вреда от памяти на intel и пол из выполнить на тем переварит чтобы получить данные в обход льва аль тарика шейка и слепит есть предположение что эти данные нам больше не понадобятся мы их один раз используем ну и пришедшего как видно и название она нужна если предполагается запись в эту кушанье вот мы хотели ее нету как все эти предвыборные выглядят в коде понятное дело что но можно через а сам ставить но все есть обычно специальный интересен для ксс эта built-in prefetch у него есть опциональные параметры без них этапе вечен 630 на слайде показаны как бы хищник вот примерный его что он транслируется ключевым элементом в предвыборный ты упомянул упомянутая другая работа ду сама залог если мы придумываем чем занять процессор пока данные поступают он мы по идее должны получить выигрыш производительности но посмотрим на этот код тоже самое но придурки здесь нет и при помощи пьеха посмотрим этим мы получим задержку как ни странно сам задержка происходит не в момент обращения а собственно говоря в том же самом месте где мы получили в предыдущий раз почему так но потому что дав есть внеочередное выполнение на процессоры и если процесса виде что команда не получила данные он продолжает выполнять следующие команды почтение данных для отложенного использования иногда называют при загрузке то есть принципе и для использования при выборке и для внеочередного выполнения важно зависть отсутствие зависимости данных по кода между командами очевидно что для нашего связанного списка этой самой другой работы вроде бы как и нет мы просто движемся по нему все тело цикла это шаг к следующему элементу и ничего здесь придумать мы не можем но если мы знаем некоторые промежуточные точки этого связанного списка мы можем разделить его на несколько частей в таком виде тогда зависимость по данных ослабнет и собственно говоря другая работа это будет шаг по второй части списка модифицируем наш код чтобы он соответствовал нашим пожеланиям в этом плане то есть фактически это движение по нескольким связанным списком но поскольку это они все-таки связаны в один то мы их называем под списками посмотрим что будет без приду выборок по оси x и это число под списков на которое мы поделили наш список видно что по мере удлинения внутреннего цикла связанные с ним инструкции все дальше друг от друга отстоят и скоро чтение списка растет до определенного предела но он едва не достигает к потому что у нас есть некоторые потерянные организации такого чтения таким образом мы ускорили с чтение списка без каких-либо передовых бирок посмотрим что добавят нам приду выборки модифицируем код еще раз но тут мне сказали что немножко сложный слайд получился мы здесь развернули цикл вынесли первый шаг начала последний шаг вы отделили тоже вынесли в конец так в первом шаге у нас только перед выборках последним она не нужно в остальном это тот же самый код посмотрим как это скажется на скоростью результаты подсказывают показывают что явно я приду выборка может несколько ускорить ход но тут принципе 25 процентов ускорения то есть также мало если правильно подобрать расстояние между ней и использованием данных в in the sky документации сказано что это в основном достигается из-за того что команда не используют регистрации и собственный repair уходит из конвейера в нужное время в то время как этот загрузка в нем остается до получение данных и еще она занимает регистра назначению звучит на самом деле на мой взгляд мне не слишком многообещающей новый вирус действительно заметно однако слишком большое количество при этом выборок наоборот код замедляет гидроцикл может одновременно выполнять только определенное количество чтения данных для х ссылаться 12 по моему большее количество вызывает задержки в описании при фича написано что при отсутствии свободных буферов готовы брака будет просто проигнорирована это наш случай и в принципе при помощи пифа можно заметить что промахи последнего уровня появляются при большом количестве под списков и проведем еще про экспериментов связанных с адресом пред выборки раньше в линуксе но не раньше когда-то достаточно давно при движении по связанным списком ведре использовались придурки потом от этого отказались и одним из доводов для отказа от этого был в том что запрос ткнул был очень медленным вызывал промахи tlb и вызывал задержки поэтому интересно как сейчас с этим а будет обстоять дела и заодно посмотрим как будет вести себя перед выборка которая запрашивает данные на пересечении кыш леней вот на графике видно что запрос ткнул это желтая линия тут видимо команда просто игнорируется и никакого заметного влияния абсолютно не оказывает но полагаться на это все-таки нельзя и мне кажется что если возникает такой вопрос кто лучше проверить это на конкретные архитектуры потому что процессор виду все по разному но тем не менее в нашем эксперименте мы можем двигаться по спискам не проверяю этот выборкой на уста малинину апрелевка с предвыборной с пересечением границы к эш лени и так как придурками и выбирает минимум четыре байта то это вполне возможно серый график это здесь заметно замедляет код причем для этого эксперимента выбирались специально только такие границы которые не мог не являются границами странице чтобы какие-то тебе операции на это влияние не оказывали все вышесказанное применимо как хостел такой x-trail обл единственное что ускорило был оптимальный результат дают 16 при гробе рака не 8 потому что видимо больше этих буферов какие выводы из всего этого можно сделать самый главный вывод что надо устранять зависимости по данным наибольший выигрыш в производительности доказано достигается именно этим если их нет то без всяких предвыборных процессов состояний сами минимизировать задержки изменяя порядок выполнения иструкции если мы выбираем простые способы устранения разворот цикла приду выборки могут и видно пример разворот цикл могут или дать некоторые выигрыш в но достаточно заметны все-таки либо наоборот замедлить что зависит от числа доступа в памяти в этом цикле и времени выполнение шага как выигрыш так и проигрыш все-таки сравнительно невелики по сравнению с выигрышем от устранения зависимости по данным при более сложном и организации кода когда инструкции предвыборных когда инструкция предвыборных ходится например другой функции по сравнению с использованием данные предвыборного удобнее и также она удобнее когда нужно управлять уровнем кэширование данных второй вывод 2 связанный список гораздо более кэш френдли по сравнению с 1 связанным списком потому что мы можем двигаться по нему с двух концов и таким образом наша зависимость по данным ослабляется в два раза соответственно если тело не вырожденная там выполняется какая-то работает только уж промахом мы можем так и не получить при движении в подобный стиль а ну тут тоже пресечь можно принципе на 30 бруску заменить вот что еще можно об этом сказать посмотрим как мы ищем кэш местах уж промаха в при помощи верха опять модифицируем наш код развернем там вот это сложно 1 1 строчную инструкцию так чтобы было понятно а 7 дорна листинг какому именно место в ее будет относиться будем вызывать с одним под списком что получилось понагляднее для этой функции оптимизация у нас выключено так что листинг можно назвать буквальном получившийся получим достаточно сомнительный результат ног как сомнительными в принципе внеочередного выполнения он вполне естественной то есть у нас ошибка показывается кашпо мог показываться не на той инструкции которым как мы подозреваем его должна выполнить а на следующий и некоторые кэш промахи даже сместились дальше по ходу это выглядит совсем неправильным почему так происходит потому что как известно процессор выполняет несколько инструкций одновременно и лев не всегда может понять какая именно из них вызывать события явление называется либо скилл либо скит то есть за нос скос как с этим бороться бороться с этим можно при помощи цыпа уже в котором есть средства для определения точного состояния момент события для intel это называется b&bs пепс привет precise его in basic сэмплинг включается добавлением одной или нескольких п через двоеточие после названия события но к сожалению на целую от мисс с это не точное событие и вообще точные счетчики для конкретного процессора могут отличаться и можно быть даже придется лишь документацию задавать их номера мтс mask но сейчас поможет то четче который указан на слайде он вполне точный результат у нас получился тот который мы и в принципе ожидали то есть сто процентов куш промахов именно в этой строчке которые выполняют обращение к следующему элементу списка казалось бы об этом можно сказать все но такой идеальный результат у нас получается не всегда документации к процессорам сказано что даже эти счетчики не всегда показывает правильно к сожалению воспроизвести это в каком-то упрощенном коде меня не получилось но уме и в библиотеке у нас такое место было где именно purchase office вел возможно ошибочно показывал к штурмах последнего уровня на слайде это место кода показано видно что там два буфера cerca de ce и собственно буфер они очень маленькие и достаточно интенсивно идет с ними работы и предположить что они будут вытеснены из кэша последнего уровня ну наверное возможно но это должно происходить очень очень редко однако кэш промах у нас устойчиво показывался в этом месте я долго с этим возился и пытался понять каким образом он получается позже оказалось что если переместить код который стоит перед этим в другой трек то этот кэш промах мистический исчезает и более того он исчезает если перед ним перед этим местом вставить 16 но пав вот я и потом еще проверял как бы представляла эти но по перед местом где явный промах его там должен быть он не исчезает то есть 16 на пол для или три промаха маловато даже для любого внеочередного выполнения чтобы он совсем пропал и так и не понял чем это было связано и к тому же это уже не воспроизводится в текущей версии и не воспроизводится на скрыл обл так что я хотел бы сказать что ставка но перед проблемой инструкции помогает определить действительно ли проблема именно в этом месте но 2 примера у меня нету тем не менее если кому-то попадется неуловимых и штурмах то можно проверить не тот ли это случай именно вот таким способом возможно это поможет надеюсь было интересно я надеюсь кто-то что-то для себя услышал все спасибо скажите как ты когда работал над этим тебе было интересно вообще самому то что кажется что это огромный исследовательская работа у нас есть один проект в котором каждая микросекунда имеет некое денежное выражение ложь и поподробнее вот нет каких-то простая то есть бывают такие проекты которым быстродействия чем больше лучше вопросики я вижу одну руку 1 1 а как в итоге избежали миссов вот в том месте где двойная таблиц было не но позже оставили наверное я переместил просто там код который был перед этим и из-за которого видимо это все и происходило он уехал в другой трек и собственно пропал а есть какая-то гарантия в каком среди она в итоге будут исполняться точно надежно не скажешь про мартом явно был вот и после этого она еще стоит там был кот как бы он потом поделился конвейером между двумя ядрами соответственно в тон трети в котором он уехал тому же свои проблемы и своей оптимизации начались но вот эта проблема она исчезла еще бусы пока кто-то думает вопрос мезатон злой скажи а вот ты показал такими реалистичными кусочки кода это связано с тем что вы с производителем больше workflow де сложно я говорю маленькие кусочки кода чтобы воспроизводить было легче чтобы было понятно потому что если я пытался сначала сначала в первой версии так ладно я пытался вставлять куски кода из библиотеки но там абсолютно непонятно на что смотрите и в одной строчке там слишком много запросов к памяти обращение к памяти и в конце концов я попытался как можно больше упростить код чтобы понять о чем именно фокусироваться в контурном то конкретного прошлась ибо там есть вопрос здравствуй очень интересный доклад спасибо вот хочется что узнать вот вы все оптимизировали убрали все хэш мисс и все здорово и потом через какое то время там ваш коллега что не пришел этот код что он вставил и все развалилось то есть у вас есть какие то там мониторинг следите за тем что всё у нас есть ну скажем так если кэш мест и появятся то именно в этом коде они сразу сказываются на производительности и если делается какой-то к металла всегда проверяется не ухудшилось ли производительность каких конкретных операций то есть если она не ухудшилось ну значит но возможно они там появились но по-крайней мере этого не видно но скажу почему ты рассмотрел и эти два процессора ну почему и мне эти два поколения процессоров ты рассматривал потому что и и именно они у нас как это только такие сервера у нас есть на самом деле вот для вот этого критичного по скорости проекта он выполняется чисто на жилище без всякой виртуализации окей тут есть еще один вопрос спасибо за доклад был plaza интересно скажите какие там у ряд симуляторы процессов в использовали для исследования по объему снопами то есть могу ли там какая-то зависимость по данному уйти еще что то есть когда вы даете но понижаются как-то процессом там полно всем эти кодах будут работать может быть там просто процессы лучше поворачивается да я как бы вот именно эту причину я и подозревал на самом деле но в любом случае это все таки кэш промах был все-таки по факту показано неправильно именно вот эта строчка она не могла его вызвать и там вот этот пеппи он не помогал до были точны нет но это вот единственный случай как бы на протяжении всех там четырех лет когда бабой ошибся и не не удалось раскопать интересно сочно не можно вопрос пока к тебе скажи пожалуйста а нельзя ли вот когда мы сохраним сборку выполнены с отладкой по контурам эти контуры сохранить в логе мы же сможем то налоги по анализировать и разобраться где она большом claude страдает или так низзя не знаю я не думал об этом кажется что можно поэкспериментировать это хорошая идея так кажется у нас вопросы закончились или нет нет я вижу пару глаз который хотел задать вопрос о синицы стесняется вот еще хотел уточнить а вот код ведь тоже держится в или один нет что что код который загружается процессором он тоже были один находится один там два кэша один для данных 2 для кода а то есть тот размер которой или 1 у нас есть он кодом не использование продолжение предыдущего вопроса вот с данными это понятно а с кодом есть те же проблемы вот вскрыл был процессорах ответов я не исследовала 0 skyla был на самом деле нет проблем там есть по большей части выигрыш по сравнению с high school но вот с тем что данные вынуждены перекидываются вот так вот между ядрами то что то вот с кодом будет такая же проблема или нет то есть они тоже тоже такая уже может возникнуть или нет наверное не знаю не могу сказать надо проверять не было повода это что это этим вопросом заниматься но зато везде конференция повод чтобы еще пересечь утилита там это серж еще много в этом ну хорошо"
}